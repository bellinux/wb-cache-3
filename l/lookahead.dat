1214|13|Public
25|$|The LALR(1) parser is less {{powerful}} than the LR(1) parser, and more {{powerful than the}} SLR(1) parser, though they all use the same production rules. The simplification that the LALR parser introduces consists in merging rules that have identical kernel item sets, because during the LR(0) state-construction process the lookaheads are not known. This reduces the power of the parser because not knowing the <b>lookahead</b> symbols can confuse the parser as to which grammar rule to pick next, resulting in reduce/reduce conflicts. All conflicts that arise in applying a LALR(1) parser to an unambiguous LR(1) grammar are reduce/reduce conflicts. The SLR(1) parser performs further merging, which introduces additional conflicts.|$|E
500|$|In practice, {{computational}} addition may {{be achieved}} via XOR and AND bitwise logical operations {{in conjunction with}} bitshift operations {{as shown in the}} pseudocode below. Both XOR and AND gates are straightforward to realize in digital logic allowing the realization of full adder circuits which in turn may be combined into more complex logical operations. In modern digital computers, integer addition is typically the fastest arithmetic instruction, yet it has the largest impact on performance, since it underlies all floating-point operations as well as such basic tasks as address generation during memory access and fetching instructions during branching. To increase speed, modern designs calculate digits in parallel; these schemes go by such names as carry select, carry <b>lookahead,</b> and the Ling pseudocarry. Many implementations are, in fact, hybrids of these last three designs. Unlike addition on paper, addition on a computer often changes the addends. On the ancient abacus and adding board, both addends are destroyed, leaving only the sum. The influence of the abacus on mathematical thinking was strong enough that early Latin texts often claimed that in the process of adding [...] "a number to a number", both numbers vanish. In modern times, the ADD instruction of a microprocessor often replaces the augend with the sum but preserves the addend. In a high-level programming language, evaluating [...] does not change either a or b; if the goal is to replace a with the sum this must be explicitly requested, typically with the statement [...] Some languages such as C or C++ allow this to be abbreviated as [...]|$|E
2500|$|Generally, the LALR parser {{refers to}} the LALR(1) parser, just as the LR parser {{generally}} {{refers to the}} LR(1) parser. The [...] "(1)" [...] denotes one-token <b>lookahead,</b> to resolve differences between rule patterns during parsing. Similarly, there is an LALR(2) parser with two-token <b>lookahead,</b> and LALR(k) parsers with k-token lookup, but these are rare in actual use. The LALR parser {{is based on the}} LR(0) parser, so it can also be denoted LALR(1)=LA(1)LR(0) (1 token of <b>lookahead,</b> LR(0)) or more generally LALR(k)=LA(k)LR(0) (k tokens of <b>lookahead,</b> LR(0)). There is in fact a two-parameter family of LA(k)LR(j) parsers for all combinations of j and k, which can be derived from the LR(j+k) parser, but these do not see practical use.|$|E
2500|$|In the LALR table construction, {{two states}} will be merged into one state and later the <b>lookaheads</b> will be found to be ambiguous. The one state with <b>lookaheads</b> is: ...|$|R
5000|$|... {{where all}} the {{possible}} <b>lookaheads</b> must be enumerated. That {{is the reason why}} LR(1) parsers cannot be practically implemented without significant memory optimizations.|$|R
50|$|LALR parsers {{have the}} same states as SLR parsers, but use a more complicated, more precise way of working out the minimum {{necessary}} reduction <b>lookaheads</b> for each individual state. Depending {{on the details of}} the grammar, this {{may turn out to be}} the same as the Follow set computed by SLR parser generators, or it may turn out to be a subset of the SLR <b>lookaheads.</b> Some grammars are okay for LALR parser generators but not for SLR parser generators. This happens when the grammar has spurious shift/reduce or reduce/reduce conflicts using Follow sets, but no conflicts when using the exact sets computed by the LALR generator. The grammar is then called LALR(1) but not SLR.|$|R
2500|$|As {{with other}} types of LR parsers, an LALR parser is quite {{efficient}} at finding the single correct bottom-up parse in a single left-to-right scan over the input stream, because it does not need to use backtracking. Being a <b>lookahead</b> parser by definition, it always uses a <b>lookahead,</b> with [...] being the most-common case.|$|E
2500|$|An LR(1) parser {{will create}} two {{different}} states (with non-conflicting lookaheads), {{neither of which}} is ambiguous. In an LALR parser this one state has conflicting actions (given <b>lookahead</b> c or d, reduce to E or F), a [...] "reduce/reduce conflict"; the above grammar will be declared ambiguous by a LALR parser generator and conflicts will be reported.|$|E
2500|$|The windex of a graph {{measures}} {{the amount of}} <b>lookahead</b> needed to optimally solve a problem in which one is given a sequence of graph vertices si, and must find as output another sequence of vertices ti minimizing {{the sum of the}} distances d(si,ti) and d(t'i1,ti). [...] Median graphs are exactly the graphs that have windex 2. [...] In a median graph, the optimal choice is to set ti = m(t'i1,si,s'i+1).|$|E
40|$|Abstract: This article {{presents}} three methods to forecast accurately {{the amount of}} traffic in TCP=IP based networks: a novel neural network ensemble approach and two important adapted time series methods (ARIMA and Holt-Winters). In order to assess their accuracy, several experiments were held using real-world data from two large Internet service providers. In addition, different time scales (5 min, 1 h and 1 day) and distinct forecasting <b>lookaheads</b> were analysed. The experiments with the neural ensemble achieved the best results for 5 min and hourly data, while the Holt-Winters is the best option for the daily forecasts. This research opens possibilities {{for the development of}} more efficient traffic engineering and anomaly detection tools, which will result in financial gains from better network resource management...|$|R
40|$|We {{investigate}} nonlinear state-space models {{without a}} closed-form transition density, and propose reformulating such models over their latent noise variables {{rather than their}} latent state variables. In doing so the tractable noise density emerges {{in place of the}} intractable transition density. For importance sampling methods such as the auxiliary particle filter, this enables importance weights to be computed where they could not be otherwise. As case studies we take two multivariate marine biogeochemical models and perform state and parameter estimation using the particle marginal Metropolis-Hastings sampler. For the particle filter within this sampler, we compare several proposal strategies over noise variables, all based on <b>lookaheads</b> with the unscented Kalman filter. These strategies are compared using conventional means for assessing Metropolis-Hastings efficiency, as well as with a novel metric called the conditional acceptance rate for assessing the consequences of using an estimated, and not exact, likelihood. Results indicate the utility of reformulating the model over noise variables, particularly for fast-mixing process models...|$|R
40|$|Parallel {{computers}} {{today are}} designed with larger number of processors than ever before, connected by large scale Interconnection Networks (INs). Communication {{is the key to}} achieving high performance on such machines, making the study of Interconnection Networks more important. Parallel simulations of Interconnection Networks present a unique problem characterized by fine-grained computation and a strong dependence among events. The absence of large <b>lookaheads</b> makes it unsuitable to use a conservative simulation. Using an optimistic Parallel Discrete Event Simulation (PDES) allows us to extract reasonable parallelism from this simulation. In this paper we present BigNetSim, an Interconnection Network simulator. We analyze its performance and present techniques related to enhancing performance and scaling it to a large number of processors on different artificial traffic patterns and real application logs. In spite of the overheads of a parallel optimistic simulation, we have achieved a breakeven point with sequential simulation at 4 processors and demonstrate perfect scaling to 128 processors. 1...|$|R
50|$|The analyzers mainly perform two {{operations}} through tree traversal. The {{first is}} calculating strong <b>lookahead</b> sets for {{the elements in}} the grammar {{and the second is}} constructing <b>lookahead</b> paths from the <b>lookahead</b> sets. <b>Lookahead</b> paths group, factorize and perform many enhancements and optimizations to <b>lookahead</b> sets using special analysis. From <b>lookahead</b> paths, <b>lookahead</b> sets are transformed to a nested tree form, gaining a great overall efficiency and improvement in most cases.|$|E
5000|$|... parse_expression_1 (lhs, min_precedence) <b>lookahead</b> := peek next token while <b>lookahead</b> is {{a binary}} {{operator}} whose precedence is >= min_precedence op := <b>lookahead</b> advance to next token rhs := parse_primary (...) <b>lookahead</b> := peek next token while <b>lookahead</b> is a binary operator whose precedence {{is greater than}} ops, or a right-associative operator whose precedence is equal to ops rhs := parse_expression_1 (rhs, lookaheads precedence) <b>lookahead</b> := peek next token lhs := the result of applying op with operands lhs and rhs return lhs ...|$|E
50|$|<b>Lookahead</b> {{establishes}} the maximum incoming tokens that a parser {{can use to}} decide which rule it should use. <b>Lookahead</b> is especially relevant to LL, LR, and LALR parsers, where it is often explicitly indicated by affixing the <b>lookahead</b> to the algorithm name in parentheses, such as LALR(1).|$|E
40|$|In {{this paper}} {{we report on}} the LIMSI 1999 Hub- 4 E system for {{broadcast}} news transcription. The main difference from our previous broadcast news transcription system is that a new decoder was implemented to meet the 10 xRT requirement. This single pass 4 -gram dynamic network decoder is based on a time-synchronous Viterbi search with dynamic expansion of LM-state conditioned lexical trees, and with acoustic and language model <b>lookaheads.</b> The decoder can handle position-dependent, cross-word triphones and lexicons with contextual pronunciations. Faster than real-time decoding can be obtained using this decoder with a word error under 30 %, running in less than 100 Mb of memory on widely available platforms such Pentium III or Alpha machines. The same basic models (lexicon, acoustic models, language models) and partitioning procedure used in past systems have been used for this evaluation. The acoustic models were trained on about 150 hours of transcribed speech material. 65 K word language m [...] ...|$|R
40|$|To build useful {{applications}} based on large vocabulary continuous speech recognition systems, such systems {{have to run}} in real time on common platforms. However, with most research focused on further reducing the recognition error rates, the topic of speed has been neglected {{in the development of}} speech recognition algorithms. I will present a speaker independent system that has been designed for fast speech recognition using vocabularies up to 65, 000 words. Using the approaches presented in this thesis, this recognizer can now run in real time, 200 times faster than the original evaluation system. Important progress was made on the following topics: Tradeoffs: {{a better understanding of the}} tradeoffs between the computational effort and the accuracy of the acoustic modeling provides a foundation to methodically develop faster algorithms. Algorithms: a number of new or improved algorithms were introduced and analyzed in this work, such as: ffl Lookaheads: <b>Lookaheads</b> provide early est [...] ...|$|R
40|$|This article {{presents}} three methods to forecast accurately {{the amount of}} traffic in TCP=IP based networks: a novel neural network ensemble approach and two important adapted time series methods (ARIMA and Holt-Winters). In order to assess their accuracy, several experiments were held using real-world data from two large Internet service providers. In addition, different time scales (5 min, 1 h and 1 day) and distinct forecasting <b>lookaheads</b> were analysed. The experiments with the neural ensemble achieved the best results for 5 min and hourly data, while the Holt-Winters is the best option for the daily forecasts. This research opens possibilities {{for the development of}} more efficient traffic engineering and anomaly detection tools, which will result in financial gains from better network resource management. This work is supported by the FCT (Portuguese science foundation) project PTDC=EIA= 64541 = 2006. We {{would also like to thank}} Steve Williams from UKERNA for providing us with part of the data used in this work...|$|R
5000|$|At every parse step, {{the entire}} input text {{is divided into}} parse stack, current <b>lookahead</b> symbol, and {{remaining}} unscanned text. The parser's next action {{is determined by the}} rightmost stack symbol(s) and the <b>lookahead</b> symbol. The action is read from a table containing all syntactically valid combinations of stack and <b>lookahead</b> symbols.|$|E
50|$|<b>Lookahead</b> is an {{important}} component of combinatorial search, which specifies, roughly, how deeply the graph representing the problem is explored. The need for a specific limit on <b>lookahead</b> comes from the large problem graphs in many applications, such as computer chess and computer Go. A naive breadth-first search of these graphs would quickly consume all the memory of any modern computer. By setting a specific <b>lookahead</b> limit, the algorithm's time can be carefully controlled; its time increases exponentially as the <b>lookahead</b> limit increases.|$|E
50|$|Similar to an SLR parser and Canonical LR parser {{generator}}, an LALR {{parser generator}} constructs the LR(0) state machine {{first and then}} computes the <b>lookahead</b> sets for all rules in the grammar, checking for ambiguity. The Canonical LR constructs full <b>lookahead</b> sets. LALR uses merge sets, that is it merges <b>lookahead</b> sets where the LR(0) core is the same. The SLR uses FOLLOW sets as <b>lookahead</b> sets which associate the right hand side of a LR(0) core to a <b>lookahead</b> terminal. This is a greater simplification {{that in the case}} of LALR because many conflicts may arise from LR(0) cores sharing the same right hand side and <b>lookahead</b> terminal, conflicts that are not present in LALR. This is why SLR has less language recognition power than LALR with Canonical LR being stronger than both since it does not include any simplifications.|$|E
40|$|Usually, a parser for an LR(k) -grammar G is a {{deterministic}} pushdown transducer {{which produces}} backwards the unique rightmost derivation {{for a given}} input string x ∈ L(G). The best known upper bound for the size of such a parser is O(2 |G||Σ|k+ 1) where |G | and |Σ | are the sizes of the grammar G and the terminal alphabet Σ, respectively. If we add to a parser the possibility to manipulate a directed graph of size O(|G|n) where n is {{the length of the}} input then we obtain an extended parser. The graph is used for an efficient parallel simulation of all potential leftmost derivations of the current right sentential form such that the unique rightmost derivation of the input can be computed. Given an arbitrary LR(k) -grammar G, we show how to construct an extended parser of O(|G | + #LA|N| 2 k k log k) size where |N | is the number of nonterminal symbols and #LA is the number of possible <b>lookaheads</b> with respect to the grammar G. As the usual parser, this extended parser uses only tables as data structure. Using some ingenious data structures and increasing the parsing time by a small constant factor, the size of the extended parser can be reduced to O(|G|+#LA|N|k 2). The parsing time is O(ld(input) + k|G|n) where ld(input) is the length of the derivation of the input. Moreover, we have constructed a one pass parser. ...|$|R
40|$|Parallel {{simulation}} is a {{well developed}} technique for executing large and complex simulation models {{in order to obtain}} simulation output for analysis within an acceptable time frame. The main contribution of this thesis is the development of different adaptive techniques to improve the consistency, performance and resilience of the BSP Time Warp as a general purpose parallel simulation protocol. We first study the problem of risk hazards in the BSP Time Warp optimistic simulation protocols. Successive refinements to the BSP Time Warp protocol are carried out to eliminate errors in simulation execution due to different risk hazards. We show that these refinements can be incorporated into the BSP Time Warp protocol with minimal performance degradation. We next propose an adaptive scheme for the BSP Time Warp algorithm that automatically throttles the number of events to be executed per superstep. We show that the scheme, operating in a shared memory environment, can minimize computation load-imbalance and rollback overhead at the expense of incurring higher synchronization cost. The next contribution of this thesis is the study of different techniques for dynamic load-balancing and process migration for Time Warp on a cluster of workstations. We propose different dynamic load-balancing algorithms for BSP Time Warp that seek to balance both computation workload and communication workload, optimizing <b>lookaheads</b> between processors, as well as manage interruption from external workload. Finally, we propose an adaptive technique for BSP Time Warp that automatically varies the number of processors used for parallel computation based on the characteristics of the underlying parallel computing platform and the simulation workload. </p...|$|R
40|$|NEWS Versioning Releases will be {{numbered}} {{with the}} following semantic versioning format:.. And constructed {{with the following}} guidelines: Breaking backward compatibility bumps the major (and resets the minor and patch) New additions without breaking backward compatibility bumps the minor (and resets the patch) Bug fixes and misc changes bumps the patch qdapRegex 0. 2. 1 - 0. 3. 2 BUG FIXES explain used message to print to the console. explain now returns an object of the class explain with its own print method which uses cat rather than message. Additionally, the characters + and & were not handled correctly; this has been corrected. Documentation for TC "there is an incomplete sentence. It is as follows: TC utilizes additional rules for capitalization beyond stri_trans_totitle that includes [...] . " (found by rmsharp). This has been corrected. See issue # 8 cheat (and accompanying regex_cheat dictionary) contained misspellings in the words greedy and beginning. This has been corrected. rm_number incorrectly handled numbers containing leading or trailing zeros. See issue # 9 rm_caps_phrases could only extract/remove up to two "words" worth of capital letter phrases at a time. See issue # 11 NEW FEATURES %+% binary operator version of pastex(x, y, sep = "") added to join regular expressions together. group_or added {{as a means of}} quickly wrapping multiple sub-expression elements with grouping parenthesis and then concatenate/joins the grouped strings with regular expression or statement ("|"). rm_repeated_characters added for removing/extracting/replacing words with repeated characters (each repeated > 2 times). Regex pattern comes from: StackOverflow's vks ([URL] rm_repeated_phrases added for removing/extracting/replacing repeating phrases (> 2 times). Regex pattern comes from: StackOverflow's BrodieG ([URL] rm_repeated_words added for removing/extracting/replacing repeating words (> 2 times). MINOR FEATURES run_split regex added to the regex_supplement dictionary to split runs into chunks. IMPROVEMENTS Regular Expression Dictionaries (e. g., regex_usa and regex_supplement) are now managed with the regexr package. This enables cleaner updating of the regular expressions with easier to read structure. Longer files will be stored in this format. Files located: [URL] rm_caps_phrase has a new regular expression that is more accurate and does not pull trailing white space. CHANGES qdapRegex 0. 1. 3 - 0. 2. 0 BUG FIXES pastex would throw a warning on a vector (e. g., pastex(letters)). This has been fixed. youtube_id was documented under qdap_usa rather than qdap_supplement and contained an invalid hyperlink. This has been fixed. rm_citation contained a bug that would not operate on citations with a comma in multiple authors before the and/& sign. See issue # 4 NEW FEATURES is. regex added as a logical check of a regular expression's validy (conforms to R's regular expression rules). rm_postal_code added for removing/extracting/replacing U. S. postal codes. Case wrapper functions, TC (title case), U (upper case), and L (lower case) added for convenient case manipulation. group function added to allow for convenient wrapping of grouping parenthesis around regular expressions. rm_citation_tex added to remove/extract/replace bibkey citations from a. tex (LaTeX) file. regex_cheat data set and cheat function added to act as a quick reference for common regex task operations such a <b>lookaheads.</b> rm_caps_phrase added to supplement rm_caps, extending the search to phases. explain added to view a visual representation of a regular expression using [URL] and [URL] Also takes named regular expressions from the regex_usa or other supplied dictionary. MINOR FEATURES last_occurrence regex added to the regex_supplement dictionary to find the last occurrence of delimiter. word_boundary, word_boundary_left, and word_boundary_right added to regex_supplement dictionary to provide a true word boundary. Regexes adapted from: [URL] rm_time 2 regex added to the regex_usa dictionary to find time + AM/PM IMPROVEMENTS The regex_usa dictionary regular expressions: rm_hash, rm_tag, rm_tag 2 and rm_between pick up grouping that allows for replacement of individual sections of the substring. See ?rm_hash and ?rm_tag for examples. pastex picks up a sep argument to allow the user to choose what string is used to separate the collapsed expressions. rm_citation, rm_citation 2, and rm_citation 3 now attempt to include last names that contain the lower case particles: von, van, de, da, and du. qdapRegex 0. 1. 2 CRAN fix for oldrel Windows. Updated to R version 3. 1. 0 in Description file. NEW FEATURES bind added as a convenience function to add a left and right boundary to each element of a character vector. qdapRegex 0. 1. 1 First CRAN Release NEW FEATURES rm_citation added for removing/extracting/replacing APA 6 style in-text citations. rm_white and accompanying family of rm_white functions added to remove white space. rm_non_ascii added to remove non-ASCII characters from a string. around_ added to extract word(s) around a given point. pages and pages 2 added to the regex_supplement data set for removing/extracting/validating page numbers. IMPROVEMENTS rm_XXX family of functions now use stringi::stri_extract_all_regex as this approach is much faster than the regmatches(text. var, gregexpr(pattern, text. var, perl = TRUE)) approach. qdapRegex 0. 0. 1 - 0. 2. 0 This package is a collection of regex tools associated with the qdap package that may be useful outside of the context of discourse analysis. Tools include removal/extraction/replacement of abbreviations, dates, dollar amounts, email addresses, hash tags, numbers, percentages, person tags, phone numbers, times, and zip codes...|$|R
5000|$|The <b>lookahead</b> {{can also}} be helpful in {{deciding}} when to reduce a rule. The <b>lookahead</b> can help avoid reducing a specific rule if the <b>lookahead</b> is not valid, which would probably mean that the current state should be combined with the following instead of the previous state. That means that in the following example ...|$|E
50|$|In {{this case}} A, B {{will be reduced}} to A1 when the <b>lookahead</b> is a, b or c and an error will be {{reported}} when the <b>lookahead</b> is d.|$|E
5000|$|To avoid guessing, the shift-reduce parser often looks ahead (rightwards) at {{the next}} scanned symbol, before {{deciding}} {{what to do with}} previously scanned symbols. The lexical scanner works one symbol ahead {{of the rest of the}} parser. The <b>lookahead</b> symbol is the 'right-hand context' for each parsing decision. (Rarely, two or more <b>lookahead</b> symbols may be utilized, although most practical grammars can be designed to use one <b>lookahead</b> symbol.) ...|$|E
50|$|The {{choice between}} r1 and r3 can't be decided just from looking {{backwards}} at prior phrases. The parser has {{to check the}} <b>lookahead</b> symbol to tell what to do. If the <b>lookahead</b> is *, it is in rule 3, so the parser shifts in the * and advances to state 5. If the <b>lookahead</b> is eof, {{it is at the}} end of rule 1 and rule 0, so the parser is done.|$|E
50|$|<b>Lookahead</b> has two advantages.|$|E
50|$|Given a {{specific}} stack state and <b>lookahead</b> symbol, there are precisely four possible actions, ERROR, SHIFT, REDUCE, and STOP (hereinafter {{referred to as}} configurations). The presence of a dot, •, in a configuration represents the current <b>lookahead</b> position, with the <b>lookahead</b> symbol shown {{to the right of}} the dot (and which always corresponds to a terminal symbol), and the current stack state to the left of the dot (and which usually corresponds to a nonterminal symbol).|$|E
5000|$|If {{that carry}} {{is going to}} {{propagate}} {{all the way through}} the next group, the <b>lookahead</b> unit will already have deduced this. Accordingly, before the carry emerges from the next group, the <b>lookahead</b> unit is immediately (within one gate delay) able to tell the next group to the left that it is going to receive a carry - and, at the same time, to tell the next <b>lookahead</b> unit to the left that a carry is on its way.|$|E
5000|$|It is {{possible}} {{to have more than}} one level of <b>lookahead</b> carry logic, and this is in fact usually done. Each <b>lookahead</b> carry unit already produces a signal saying [...] "if a carry comes in from the right, I will propagate it to the left", and those signals can be combined so that each group of (let us say) four <b>lookahead</b> carry units becomes part of a [...] "supergroup" [...] governing a total of 16 bits of the numbers being added. The [...] "supergroup" [...] <b>lookahead</b> carry logic will be able to say whether a carry entering the supergroup will be propagated all the way through it, and using this information, it is able to propagate carries from right to left 16 times as fast as a naive ripple carry. With this kind of two-level implementation, a carry may first propagate through the [...] "slow road" [...] of individual adders, then, on reaching the left-hand end of its group, propagate through the [...] "fast road" [...] of 4-bit <b>lookahead</b> carry logic, then, on reaching the left-hand end of its supergroup, propagate through the [...] "superfast road" [...] of 16-bit <b>lookahead</b> carry logic.|$|E
5000|$|Generally, the LALR parser {{refers to}} the LALR(1) parser, just as the LR parser {{generally}} {{refers to the}} LR(1) parser. The [...] "(1)" [...] denotes one-token <b>lookahead,</b> to resolve differences between rule patterns during parsing. Similarly, there is an LALR(2) parser with two-token <b>lookahead,</b> and LALR(k) parsers with k-token lookup, but these are rare in actual use. The LALR parser {{is based on the}} LR(0) parser, so it can also be denoted LALR(1) = LA(1)LR(0) (1 token of <b>lookahead,</b> LR(0)) or more generally LALR(k) = LA(k)LR(0) (k tokens of <b>lookahead,</b> LR(0)). There is in fact a two-parameter family of LA(k)LR(j) parsers for all combinations of j and k, which can be derived from the LR(j + k) parser, but these do not see practical use.|$|E
5000|$|ERROR, then, {{represents}} a configuration {{where the state}} {{at the top of}} the stack, and the <b>lookahead</b> terminal symbol is not within the subject grammar. This presents an opportunity to invoke an error recovery procedure, perhaps, in its most simplistic form, to discard the <b>lookahead</b> terminal symbol and to read the next terminal symbol, but many other programmed actions are possible, including pruning the stack, or discarding the <b>lookahead</b> terminal symbol and pruning the stack (and in a pathological case, it is usually possible to obtain ...|$|E
50|$|The <b>lookahead</b> {{and input}} stream remain unchanged.|$|E
5000|$|The topmost {{state on}} the parse stack is some state s, and the current <b>lookahead</b> is some {{terminal}} symbol t. Look up the next parser action from row s and column t of the <b>Lookahead</b> Action table. That action is either Shift, Reduce, Done, or Error: ...|$|E
