25|3|Public
40|$|Various schemes are {{available}} to solve coupled transport/reaction mathematical models, {{one of the most}} efficient and easy to apply being the two-step split- operator method in which the transport and reaction steps are performed separately. Operator splitting, however, does not solve exactly the fully coupled numerical model derived from the governing partial differential and algebraic equations describing the transport and reaction processes. An error, proportional to Δt (the time step used in the numerical solution) is introduced. Thus, small time steps must be used to ensure that accurate solutions result. An alternative scheme is presented, which iterates to the exact solution of the fully coupled numerical model. The new scheme enables accurate solutions to be calculated more efficiently than the two- step method, while maintaining separation of the transport and reaction steps in the calculations. As in the two-step method, the reaction calculations are performed node-wise throughout the computation grid. However, because the scheme relies on <b>LU</b> <b>factorisation</b> of the coefficient matrix in the transport equation solution, the reaction calculations must be performed in sequence, the sequence order being determined by the ordering of the nodes in the grid. Also, because <b>LU</b> <b>factorisation</b> is used, the scheme is limited to solute transport problems for which <b>LU</b> <b>factorisation</b> is a practical solution method...|$|E
40|$|A {{strategy}} for computing aeroelastic solutions is proposed. An implicit <b>LU</b> <b>factorisation</b> scheme for solving the time dependent Euler equations on unstructured triangular meshes is presented and {{coupled with a}} typical section aeroelastic wing model. Efficiency is improved by coupling the <b>LU</b> <b>factorisation</b> scheme with a GMRES algorithm. In this case the LU scheme {{plays the role of}} a preconditioner. The fluid and structural models are simultaneously integrated in time in a fully coupled manner. The response of structural sections in different flow regimes is determined and flutter boundaries are computed. In the transonic regime and beyond the region of linear stability, the section is found to exhibit limit cycle behaviour. 1 Introduction In recent years, Computational Fluid Dynamics has reached a considerable level of maturity and has become an essential tool for aerodynamic analysis. With the latest developments in automatic unstructured mesh generation and efficient multigrid flow sol [...] ...|$|E
40|$|A {{variant of}} Gaussian {{elimination}} {{that is known}} as Gauss-Huard's algorithm behaves like Gauss-Jordan's algorithm {{in the fact that}} it also reduces the matrix to diagonal form and it behaves like <b>LU</b> <b>factorisation</b> in the fact that it uses the same number of floating-point operations and has practically the same numerical stability. This contribution presents a block-variant of Gauss-Huard's algorithm with favourable data locality...|$|E
40|$|The pseudofermion {{action of}} the Hybrid Monte Carlo (HMC) {{algorithm}} for dynamical fermions is modified to directly incorporate Incomplete <b>LU</b> (ILU) <b>factorisation.</b> This reduces the stochastic noise and allows a larger molecular dynamics step-size to be taken, cutting the computational cost. Numerical tests using the two-flavour Schwinger model are presented, where a two-step ILU preconditioning of the even-odd fermion matrix allows the step-size to be increased {{by a factor of}} two over the standard even-odd formulation. ...|$|R
40|$|This thesis {{describes}} {{a new approach}} for the solution of two-dimensional, time-dependent, surface-tension-driven free-surface flows involving domains of arbitrary shape that may undergo large changes in shape {{during the course of}} a problem. Both Stokes and Navier-Stokes problems are considered, a mixed Lagrangian-Eulerian finite element formulation being employed for the latter. All meshes are generated automatically using a Delaunay mesh generator, the onnly user input required being the specification of the initial free-surface shape. Very few constraints are placed on the shape of the initial domain and arbitrarily large deformations of the domain are permitted. A key feature of the new method is its ability to dynamically refine and de-refine the free-surface discretisation as and when necessary to maintain an accurate representation of the free surface, as is essential for surface-tension-driven problems. Full implementation details are included. Semi-implicit time integration schemes are employed for both Stokes and Navier-Stokes problems, the resulting systems of linear equations being solved by the conjugate residual method preconditioned using high-quality, thresholded, incomplete <b>LU</b> <b>factorisations.</b> A novel scheme for the automatic selection of the maximum time step size that ensures free-surface stability is described. A number of challenging problems are considered. First a Stokes-flow problem with a known analytic solution is employed to confirm that the expected rates of convergence in the solution are obtained. Next the Stokes-flow evolution of a film of viscous fluid on a rotating cylinder is investigated, the time-dependent case being modelled for the first time. Illustrations of the large free-surface deformations leading up to load shedding are presented. In addition, the unexpected existence of apparently stable oscillatory solutions is reported for certain configurations. Finally the axisymmetric oscillations of droplets at low Reynolds numbers (Re < 100) are considered. ...|$|R
40|$|In {{this paper}} we present an {{algorithm}} for computing a low rank approximation of a sparse matrix {{based on a}} truncated LU factorization with column and row permutations. We present various approaches for determining the column and row permutations that show a trade-off between speed versus deterministic/probabilistic accuracy. We show that if the permutations are chosen by using tournament pivoting based on QR factorization, then the obtained truncated LU factorization with column/row tournament pivoting, LU_CRTP, satisfies bounds on the singular values which have similarities with the ones obtained by a communication avoiding rank revealing QR factorization. Experiments on challenging matrices show that LU_CRTP provides a good low rank approximation of the input matrix and it is less expensive than the rank revealing QR factorization in terms of computational and memory usage costs, while also minimizing the communication cost. We also compare the computational complexity of our algorithm with randomizedalgorithms and show that for sparse matrices and high enough but still modest accuracies, our approach is faster. Ce papier introduit un algorithme pour calculer une approximation de rang faible d’une matrice creuse. Cet algorithme est basé sur une <b>factorisation</b> <b>LU</b> avec des permutations de lignes et de colonnes...|$|R
40|$|Numerical {{results are}} {{presented}} for the dynamical properties of a dilute, central force, triangular network with 60 degrees bond bending forces. The rigidity percolation threshold PR for such a network lies between the connectivity percolation threshold and the central force rigidity percolation threshold. A <b>LU</b> <b>factorisation</b> technique is {{used to determine the}} eigenvalues of the dynamical matrix and the results combined with finite size scaling to yield values for PR and the fracton dimensionality d of 0. 40 <or=PR<or= 0. 405 and 1. 25 <or=d<or= 1. 3...|$|E
40|$|A coarse-grain {{parallel}} implementation {{is presented}} of <b>LU</b> <b>factorisation,</b> {{forward and backward}} substitution for solving large, sparse linear sets of algebraic equations arising from network analysis. A block solution approach was chosen {{instead of the usual}} element-wise method, to reduce communication overhead and consequently to obtain a better performance of the parallel implementation. An inverse-based technique was used to further improve the overall efficiency of repeated solutions. Data exchanges among processors are kept to the minimum in the factorisation and solution phases. This method has been successfully applied to a realistic UK 811 -busbar power system network with up to 16 processors. Results are presented with detailed information on computation and communication. Department of Electrical Engineerin...|$|E
40|$|We {{describe}} a fully discrete high-order algorithm for simulating low to medium frequency electromagnetic waves scattered by an ensemble of perfectly conducting three dimensional particles with rough non-convex surfaces. A {{key component of}} our surface integral algorithm is the high-order approximation of the tangential surface current on each obstacle in the ensemble, which leads to linear systems with considerably fewer unknowns than low order boundary element methods. This allows us to obtain high-order solutions using a fast iterative solver for multiple scattering problems (based on reflections from the obstacles) that takes advantage of fast solution of single obstacle scattering problems with multiple right hand sides (corresponding to the reflections) using <b>LU</b> <b>factorisation.</b> 4 page(s...|$|E
40|$|Parallel {{implicit}} iterative solution {{techniques are}} considered for application to a compressible hypersonic Navier-Stokes solver on unstructured meshes. The construction of parallel preconditioners with quasi-optimal convergence properties {{with respect to}} their serial counterpart is a key issue in the design of modern parallel implicit schemes. Two types of non-overlapping preconditioners are presented and compared. The first one is an additive Schwarz preconditioner requiring overlapping of the mesh and the second one is based on a Schur complement formulation. Both are using incomplete <b>LU</b> <b>factorisation</b> at the subdomain level but scale differently. Results are presented for computations on the Cray T 3 D under the message passing interface MPI. Copyright © 1998 Elsevier Science B. V. info:eu-repo/semantics/publishe...|$|E
40|$|In {{this paper}} we {{investigate}} {{a method to}} improve the performance of sparse LU matrix factorization used to solve unsymmetric linear systems, which appear in many mathematical models. We introduced and used {{the concept of the}} supernode for unsymmetric matrices in order to use dense matrix operations to perform the LU factorization for sparse matrices. We describe an algorithm that uses supernodes for unsymmetric matrices and we indicate methods to locate these supernodes. Using these ideas we developed a code for sparse LU matrix factorisation. We conducted experiments to evaluate the performance of this algorithm using several sparse matrices. We also made comparisons with other available software packages for sparse <b>LU</b> <b>factorisation...</b>|$|E
40|$|Abstract: In {{this paper}} we {{investigate}} {{a method to}} improve the performance of sparse LU matrix factorization used to solve unsymmetric linear systems, which appear in many mathematical models. We introduced and used {{the concept of the}} supernode for unsymmetric matrices in order to use dense matrix operations to perform the LU factorization for sparse matrices. We describe an algorithm that uses supernodes for unsymmetric matrices and we indicate methods to locate these supernodes. Using these ideas we developed a code for sparse LU matrix factorisation. We conducted experiments to evaluate the performance of this algorithm using several sparse matrices. We also made comparisons with other available software packages for sparse <b>LU</b> <b>factorisation.</b> Key words: sparse matrices; linear algebra; LU factorisatio...|$|E
40|$|The Finite Element Method {{software}} system FMPS is briefly introduced and an overview is given of development {{work done by}} HLRS and VSB concerning the acceleration of solutions to problems yielded by FMPS using Intel’s Many Integrated Core architecture. HLRS implemented a hybrid MPI/OpenMP Conjugate Gradient solver. A different scaling behaviour when using Intel Xeon Phi cards due to a different message transportation (involving a PCIe 2. 0 bus) is revealed. VSB shows {{that the number of}} iterations of a Conjugate Gradient solver can be significantly reduced by using a Deflated Conjugate Gradient scheme, involving the need for an additional solution to a dense linear system by a <b>LU</b> <b>factorisation.</b> The solution to the dense system can be accelerated using MIC cards...|$|E
40|$|The ground heat {{exchangers}} (GHE) consist of pipes {{buried in the}} soil and are used for transferring heat between the soil and the heat exchanger pipes of the {{ground source heat pump}} (GSHP). This paper presents the development of a numerical tool for anlysing the behaviour of horizontal ground source heat pump system. The tool was developed in Visual C++ environment. Impicilit finite difference heat conduction method was employed. The numerical solution was obtained by <b>LU</b> <b>factorisation.</b> For certain heat demand in a house and for known horizontal ground loop length, the numerical tool analyses whether the available ground loop length would be suffient to supply heat energy for the life time of GSHP system without reaching subzero temperature at any time...|$|E
40|$|S University of Manchester/UMIST Manchester Centre for Computational Mathematics Numerical Analysis Reports Reports {{available}} from: Department of Mathematics University of Manchester Manchester M 13 9 PL England And {{over the}} World-Wide Web from URLs [URL] ftp://vtx. ma. man. ac. uk/pub/narep Performance of parallel methods for {{the solution of}} linear systems In many scientific and engineering problems large linear systems of equations occur. Gaussian elimination (GE) and <b>LU</b> <b>factorisation</b> (LU) are two well known sequential methods used to solve such systems. Parallelised versions of GE and LU using BLAS have been developed and widely implemented on parallel computers. Two parallel methods for matrix elimination and matrix factorisation have been presented in [1993]. The Parallel Implicit Elimination method (PIE) is a scheme that eliminates two matrix elements simultaneously (not one element as in GE). The Quadrant Interlocking Factorisation method (QIF) dec [...] ...|$|E
40|$|The use of {{threshold}} pivoting {{with the}} purpose to reduce fill-in during sparse Gaussian elimination has been generally acknowledged. Here we describe the application of threshold pivoting in dense Gaussian elimination for improving {{the performance of a}} parallel implementation. We discuss the effect on the numerical stability and conclude that the consequences are only of minor importance as long as the threshold is not chosen too small. Keywords: Gaussian elimination, <b>LU</b> <b>factorisation,</b> threshold pivoting, parallel applications. 1 Introduction The Parallel Scientific Computing and Simulation group - PSCS group - is involved in many aspects of Scientific Computing, which to a 'working definition' by Golub and Ortega can be described as: "the collection of tools, techniques, and theories required to solve on a computer mathematical models of problems in science and engineering" [4]. In many cases, these mathematical models contain (very) large linear systems; the size being determined by [...] ...|$|E
40|$|Abstract Incomplete factorisation {{methods can}} suffer from {{breakdown}} {{in that they}} may give zero or negative pivots where an exact factorisation would show only positive pivots. This breakdown effectively prevents the factorisation from being used in iterative methods such as Conjugate Gradients. We give an overview of strategies that have been proposed to prevent this breakdown, and we touch briefly on various related issues in incomplete factorisations. 1 Introduction For the efficient solution of sparse linear systems Au = b by an iterative method, {{the choice of a}} proper preconditioner is crucial. A preconditioner is a matrix M that approximates A, but for which solving the system M u = b is computationally cheap. In addition, M itself should be easily constructable. Since the original coefficient matrix A is sparse, people have sought to construct sparse factorisations M = LU ss A. The exact <b>LU</b> <b>factorisation</b> of A is not sparse, so M is constructed by a so-called incomplete factorisation, where the updat...|$|E
40|$|The aim of {{this paper}} is to show an {{effective}} reorganization of the nonsymmetric block lanczos algorithm efficient, portable and scalable for multiple instructions multiple data (MIMD) distributed memory message passing architectures. Basic operations implemented here are matrix-matrix multiplications, eventually with a transposed and a sparse factor, <b>LU</b> <b>factorisation</b> and triangular systems solution. Since the communication overhead of the algorithm inhibits an efficient parallel implementation, we propose a reorganization of the block algorithm which reduces the total amount of communication involved in linear algebra operations. Then, we develop an efficient parallelization of the matrix-matrix multiplication when one of the factor is sparse. Some other linear algebra operations are performed using ScaLAPACK library. The parallel eigensolver has been tested on a cluster of PCs. All reported results show the proposed algorithm is efficient and scalable on the target architectures for problems of adequate dimension, and it can be the computational kernel of a robust software for large sparse eigenvalue problems...|$|E
40|$|AbstractWe discuss {{aspects of}} {{implementation}} {{and performance of}} parallel iterative solution techniques applied to low Reynolds number flows around fixed and moving rigid bodies. The incompressible Navier–Stokes equations are discretised with Taylor-Hood finite elements in combination with a semi-implicit pressure-correction method. The resulting sequence of convection–diffusion and Poisson equations are solved with preconditioned Krylov subspace methods. To achieve overall scalability we consider new auxiliary algorithms for mesh handling and assembly of the system matrices. We compute the flow around a translating plate and a rotating insect wing to establish the scaling properties of the developed solver. The largest meshes have up to 132 × 106 hexahedral finite elements leading to around 3. 3 × 109 unknowns. For the scalability runs the maximum core count is around 65. 5 × 103. We find that almost perfect scaling can be achieved with a suitable Krylov subspace iterative method, like conjugate gradients or GMRES, and a block Jacobi preconditioner with incomplete <b>LU</b> <b>factorisation</b> as a subdomain solver. In addition to parallel performance data, we provide new highly-resolved computations of flow around a rotating insect wing and examine its vortex structure and aerodynamic loading...|$|E
40|$|Abstract—Processors {{with large}} numbers of cores are becom-ing commonplace. In order to take {{advantage}} of the available resources in these systems, the programming paradigm has to move towards increased parallelism. However, increasing the level of concurrency in the program does not necessarily lead to better performance. Parallel programming models have to provide flexible ways of defining parallel tasks and at the same time, efficiently managing the created tasks. OpenMP is a widely accepted programming model for shared-memory architectures. In this paper we highlight some of the drawbacks in the OpenMP tasking approach, and propose an alternative model based on the Glasgow Parallel Reduction Machine (GPRM) programming framework. As the main focus of this study, we deploy our model to solve a fundamental linear algebra problem, <b>LU</b> <b>factorisation</b> of sparse matrices. We have used the SparseLU benchmark from the BOTS benchmark suite, and compared the results obtained from our model to those of the OpenMP tasking approach. The TILEPro 64 system has been used to run the experiments. The results are very promising, not only because of the performance improvement for this particular problem, but also because they verify the task management efficiency, stability, and flexibility of our model, which can be applied to solve problems in future many-core systems. I...|$|E
40|$|Processors {{with large}} numbers of cores are {{becoming}} commonplace. In order {{to take advantage of the}} available resources in these systems, the programming paradigm has to move towards increased parallelism. However, increasing the level of concurrency in the program does not necessarily lead to better performance. Parallel programming models have to provide flexible ways of defining parallel tasks and at the same time, efficiently managing the created tasks. OpenMP is a widely accepted programming model for shared-memory architectures. In this paper we highlight some of the drawbacks in the OpenMP tasking approach, and propose an alternative model based on the Glasgow Parallel Reduction Machine (GPRM) programming framework. As the main focus of this study, we deploy our model to solve a fundamental linear algebra problem, <b>LU</b> <b>factorisation</b> of sparse matrices. We have used the SparseLU benchmark from the BOTS benchmark suite, and compared the results obtained from our model to those of the OpenMP tasking approach. The TILEPro 64 system has been used to run the experiments. The results are very promising, not only because of the performance improvement for this particular problem, but also because they verify the task management efficiency, stability, and flexibility of our model, which can be applied to solve problems in future many-core systems. Comment: Final version as appeared in "dx. doi. org/ 10. 1109 /ISPDC. 2014. 11...|$|E
40|$|A {{power system}} {{is a system that}} {{provides}} for the generation, transmission, and distribution of electrical energy. Power systems are considered to be the largest and most complex man-made systems. As electrical energy is vital to our society, power systems have to satisfy the highest security and reliability standards. At the same time, minimising cost and environmental impact are important issues. Steady state power system analysis plays a very important role in both operational control and planning of power systems. Essential tools are power flow (or load flow) studies and contingency analysis. In power flow studies, the bus voltages in the power system are calculated given the generation and consumption. In contingency analysis, equipment outages are simulated to determine whether the system can still function properly if some piece of equipment were to break down unexpectedly. The power flow problem can be mathematically expressed as a nonlinear system of equations. It is traditionally solved using the Newton-Raphson method with a direct linear solver, or using Fast Decoupled Load Flow (FDLF), an approximate Newton method designed specifically for the power flow problem. The Newton-Raphson method has good convergence properties, but the direct solver solves the linear system to a much higher accuracry than needed, especially in early iterations. In that respect the FDLF method is more efficient, but convergence is not as good. Both methods are slow for very large problems, due {{to the use of the}} LU decomposition. We propose to solve power flow problems with Newton-Krylov methods. Newton-Krylov methods are inexact Newton methods that use a Krylov subspace method as linear solver. We discuss which Krylov method to use, investigate a range of preconditioners, and examine different methods for choosing the forcing terms. We also investigate the theoretical convergence of inexact Newton methods. The resulting power flow solver offers the same convergence properties as the Newton-Raphson method with a direct linear solver, but eliminates both the need for oversolving, and the need for an <b>LU</b> <b>factorisation.</b> As a result, the method is slightly faster for small problems while scaling much better in the problem size, making it much faster for very large problems. Contingency analysis gives rise to a large number of very similar power flow problems, which can be solved with any power flow solver. Using the solution of the base case as initial iterate for the contingency cases can help speed up the process. FDLF further allows the reuse of the <b>LU</b> <b>factorisation</b> of the base case for all contingency cases, through factor updating or compensation techniques. There is no equivalent technique for Newton power flow with a direct linear solver. We show that Newton-Krylov power flow does allow such techniques, through the use of a single preconditioner for all contingency cases. Newton-Krylov power flow thus allows very fast contingency analysis with Newton-Raphson convergence. Numerical AnalysisElectrical Engineering, Mathematics and Computer Scienc...|$|E
40|$|Processors {{with large}} numbers of cores are {{becoming}} commonplace. In order to utilise the available resources in such systems, the programming paradigm has to move towards increased parallelism. However, increased parallelism does not necessarily lead to better performance. Parallel programming models have to provide not only flexible ways of defining parallel tasks, but also efficient methods to manage the created tasks. Moreover, in a general-purpose system, applications residing in the system compete for the shared resources. Thread and task scheduling in such a multiprogrammed multithreaded environment is a significant challenge. In this thesis, we introduce a new task-based parallel reduction model, called the Glasgow Parallel Reduction Machine (GPRM). Our main objective is to provide high performance while maintaining ease of programming. GPRM supports native parallelism; it provides a modular way of expressing parallel tasks and the communication patterns between them. Compiling a GPRM program results in an Intermediate Representation (IR) containing useful information about tasks, their dependencies, as well as the initial mapping information. This compile-time information helps reduce the overhead of runtime task scheduling and is key to high performance. Generally speaking, the granularity and the number of tasks are major factors in achieving high performance. These factors are even more important in the case of GPRM, as it is highly dependent on tasks, rather than threads. We use three basic benchmarks to provide a detailed comparison of GPRM with Intel OpenMP, Cilk Plus, and Threading Building Blocks (TBB) on the Intel Xeon Phi, and with GNU OpenMP on the Tilera TILEPro 64. GPRM shows superior performance in almost all cases, only by controlling the number of tasks. GPRM also provides a low-overhead mechanism, called “Global Sharing”, which improves performance in multiprogramming situations. We use OpenMP, as the most popular model for shared-memory parallel programming as the main GPRM competitor for solving three well-known problems on both platforms: <b>LU</b> <b>factorisation</b> of Sparse Matrices, Image Convolution, and Linked List Processing. We focus on proposing solutions that best fit into the GPRM’s model of execution. GPRM outperforms OpenMP in all cases on the TILEPro 64. On the Xeon Phi, our solution for the <b>LU</b> <b>Factorisation</b> results in notable performance improvement for sparse matrices {{with large numbers}} of small blocks. We investigate the overhead of GPRM’s task creation and distribution for very short computations using the Image Convolution benchmark. We show that this overhead can be mitigated by combining smaller tasks into larger ones. As a result, GPRM can outperform OpenMP for convolving large 2 D matrices on the Xeon Phi. Finally, we demonstrate that our parallel worksharing construct provides an efficient solution for Linked List processing and performs better than OpenMP implementations on the Xeon Phi. The results are very promising, as they verify that our parallel programming framework for manycore processors is flexible and scalable, and can provide high performance without sacrificing productivity...|$|E
40|$|Abstract Soft-field imaging methods, such as Optical Tomography (OT) and Electrical Impedance Tomography (EIT) have {{significant}} potential for medical imaging {{as they are}} non-invasive, portable and inexpensive. Possible clinical applications include epilepsy monitoring, cerebral stroke differentiation and screening for breast cancer. Recent advances in data acquisition instrumentation and image reconstruction algorithms raise the requirement to handle multiple large datasets from detailed large-scale geometric descriptions of biological objects. Thus, a major bottleneck lies in processing {{a large number of}} linear equations that result from the Finite-Element formulation of soft-field problems. Common numerical tools are not suited for large-scale problems, therefore alternative approaches are required. We propose the facilitation of an innovative multi-level inverse-based incomplete LU preconditioning approach to improve computational efficiency in processing EIT and OT system matrices. This combines static reordering and scaling, controlled growth of the inverse of triangular factors, and approximation of the Schur-complement in a multi-level scheme. Comparison with conventional incomplete <b>LU</b> <b>factorisation</b> provided a speed improvement of up to 11 times in preconditioner setup time, and up to 12 times in solution runtime for large-scale models. In addition, a new approach of monopolar current sources is introduced. Current sources and sinks are represented by linear combinations of a compact monopolar sources basis. Only the corresponding monopolar solutions are processed. These solutions serve as a basis for construction of the entire excitation pattern. This approach exploits the information content given in the system in an optimal manner and therefore avoids redundant computation. Key Words, complex-valued, large-scale problems, soft-field, multi-level preconditioner, Krylov-subspace, monopolar sources, modelling, EIT, DOT, high order radiation transfe...|$|E
40|$|The {{following}} work {{is concerned}} {{with the use of the}} Method of Least Squares in the parameter estimation of a discrete-time model of a system. In particular, the emphasis is upon both the initial convergence and accuracy of the estimates. The investigation is therefore pertinent to both the "cold-starting" of least squares estimators, and to systems in which "jump" changes in parameters occur, requiring resetting of the estimator. The work was approached from an engineering viewpoint, with the requirement that the theory be applied to a real system. The real system selected was a positional servosystem, using a DC motor. A number of least squares algorithms were compared for their suitability to such an application. The algorithms examined were: 1) A standard, non-recursive solution of the least squares equations by Lower-Upper Factorisation of the information matrix. 2) A standard, recursive solution, i. e. Recursive Least Squares, RLS. 3) Two reduced order solutions using a priori knowledge of the type number of the servosystem (<b>LU</b> <b>Factorisation</b> and RLS). 4) An Extended Least Squares Solution, using a recursive algorithm. 5) Several non-recursive solutions using instrumental variables. The methods were initially examined using a software simulation of the servosystem. This simulation was based on a linear, second-order model. It was concluded that the preferred methods were the reduced-order solutions using a priori knowledge. The following hypothesis was examined: By raising the rate at which the signals are sampled, more information is provided to the estimator in any given period of time. Increasing the sampling rate should therefore result in a superior, real-time parameter estimator...|$|E
40|$|PhD thesis {{deals with}} three {{separate}} topics. The first {{topic of the}} thesis is {{the description of the}} parallel implementation of the conjugate gradient method into the SIFEL open source project. The SIFEL open source project has been developed at the Department of Mechanics, Faculty of Civil Engineering, CTU in Prague. The project is written in C/C++ programming language and is based on the finite element method. The conjugate gradient method is an iterative method for solving systems of linear algebraic equations and was published in 1952. The method uses the matrix-vector multiplication and the vector product. Therefore, the method is suitable for parallel implementation and for using on clusters and massive parallel computers. The thesis describes the implementation which is based not only on the parallelisation of the matrix-vector multiplication but also on the parallelisation of the vector product. An incomplete <b>LU</b> <b>factorisation</b> is used for preconditioning of the conjugate gradient method. The PETSc library contains the incomplete <b>LU</b> <b>factorisation</b> which is used for preconditioning. Numerical experiments show that the implementation is effective up to 100 processors. The preconditioned method can be effective used for fourth-order problems. The second separate topic of the thesis is the description of the preconditioning into the FETI method. The Finite Element Tearing and Interconnecting (FETI) method is one of the nonoverlapping domain decomposition method which was published by Farhat et al. in 1994. The method was implemented earlier but without a preconditioning. The preconditioning is needed for achieving the scalability. The scalability of the FETI method was theoretically and numerically proved in the articles by Farhat et al. Two preconditionings was published in the articles, lumped and Dirichlet. The Dirichlet preconditioning is mathematically optimal and is based on the evaluation of the Schur complement of subdomain matrices. However, it has a large demands for time. The lumped preconditionig is computationally optimal and is based on the matrix-vector multiplication. Both of these preconditionings were implemented into the SIFEL code. The description of the implementation is in the thesis. Numerical experiments show that results are in agreement with published results in the articles by Farhat et al. The third and main topic of the thesis is development of the algorithm for the selection of the fixing nodes in the FETI-DP method. The Finite Element Tearing and Interconnecting Dual-Primal (FETI-DP) method is one of the nonoverlapping domain decomposition method which was published by Farthat et al. in 2001. The method was developed due to problems with singular matrices in the original FETI method. The method is a combination of the original FETI method and Schur complement method. The method divides unknowns in the problems into three groups. The first group contains of fixing unknowns, which are selected form interface unknowns, and enforce the non-singularity of subdomain matrices. The second group contains of remaining interface unknowns. Lagrange multipliers, which are defined on remaining interface unknowns, enforce the continuity conditions among subdomains. The last group includes internal unknowns. The selection of fixing unknowns deserve special attention. Two algorithms are described in the thesis. These algorithms use graphs, which are defined with the help of interface finite element nodes. Numerical experiments show that the minimal needed number of fixing nodes does not lead to the best time of the solution. The increasing number of fixing unknowns leads to the decreasing the number of iterations in the coarse problem, which is obtained after elimination of internal and remaining interface unknowns. However, a large number of fixing unknowns prolong the whole time of solution. The optimal number of fixing unknowns, which leads to the shortest time of the solution, exists for every. PhD thesis deals with three separate topics. The first topic of the thesis is the description of the parallel implementation of the conjugate gradient method into the SIFEL open source project. The SIFEL open source project has been developed at the Department of Mechanics, Faculty of Civil Engineering, CTU in Prague. The project is written in C/C++ programming language and is based on the finite element method. The conjugate gradient method is an iterative method for solving systems of linear algebraic equations and was published in 1952. The method uses the matrix-vector multiplication and the vector product. Therefore, the method is suitable for parallel implementation and for using on clusters and massive parallel computers. The thesis describes the implementation which is based not only on the parallelisation of the matrix-vector multiplication but also on the parallelisation of the vector product. An incomplete <b>LU</b> <b>factorisation</b> is used for preconditioning of the conjugate gradient method. The PETSc library contains the incomplete <b>LU</b> <b>factorisation</b> which is used for preconditioning. Numerical experiments show that the implementation is effective up to 100 processors. The preconditioned method can be effective used for fourth-order problems. The second separate topic of the thesis is the description of the preconditioning into the FETI method. The Finite Element Tearing and Interconnecting (FETI) method is one of the nonoverlapping domain decomposition method which was published by Farhat et al. in 1994. The method was implemented earlier but without a preconditioning. The preconditioning is needed for achieving the scalability. The scalability of the FETI method was theoretically and numerically proved in the articles by Farhat et al. Two preconditionings was published in the articles, lumped and Dirichlet. The Dirichlet preconditioning is mathematically optimal and is based on the evaluation of the Schur complement of subdomain matrices. However, it has a large demands for time. The lumped preconditionig is computationally optimal and is based on the matrix-vector multiplication. Both of these preconditionings were implemented into the SIFEL code. The description of the implementation is in the thesis. Numerical experiments show that results are in agreement with published results in the articles by Farhat et al. The third and main topic of the thesis is development of the algorithm for the selection of the fixing nodes in the FETI-DP method. The Finite Element Tearing and Interconnecting Dual-Primal (FETI-DP) method is one of the nonoverlapping domain decomposition method which was published by Farthat et al. in 2001. The method was developed due to problems with singular matrices in the original FETI method. The method is a combination of the original FETI method and Schur complement method. The method divides unknowns in the problems into three groups. The first group contains of fixing unknowns, which are selected form interface unknowns, and enforce the non-singularity of subdomain matrices. The second group contains of remaining interface unknowns. Lagrange multipliers, which are defined on remaining interface unknowns, enforce the continuity conditions among subdomains. The last group includes internal unknowns. The selection of fixing unknowns deserve special attention. Two algorithms are described in the thesis. These algorithms use graphs, which are defined with the help of interface finite element nodes. Numerical experiments show that the minimal needed number of fixing nodes does not lead to the best time of the solution. The increasing number of fixing unknowns leads to the decreasing the number of iterations in the coarse problem, which is obtained after elimination of internal and remaining interface unknowns. However, a large number of fixing unknowns prolong the whole time of solution. The optimal number of fixing unknowns, which leads to the shortest time of the solution, exists for every. katedra mechanik...|$|E
40|$|Network {{communication}} protocols {{such as the}} IEEE 802. 11 wireless protocol are currently best modelled as Markov chains. In these situations we have some protocol parameters α, and a transition matrix P(α) from which we can compute the steady state (equilibrium) distribution z(α) and hence final desired quantities q(α), which might be for example the throughput of the protocol. Typically the chain will have thousands of states, and a particular example of interest is the Bianchi chain defined later. Generally we want to optimise q, perhaps subject to some constraints that also depend on the Markov chain. To do this efficiently we need the gradient of q with respect to α, and therefore need the gradient of z and other properties of the chain with respect to α. The matrix formulas available for this involve the so-called fundamental matrix, but are there approximate gradients available which are faster and still sufficiently accurate? In some cases BT {{would like to do}} the whole calculation in computer algebra, and get a series expansion of the equilibrium z with respect to a parameter in P. In addition to the steady state z, the same questions arise for the mixing time and the mean hitting times. Two qualitative features that were brought to the Study Group’s attention were: * the transition matrix P is large, but sparse. * the systems of linear equations to be solved are generally singular and need some additional normalisation condition, such as is provided by using the fundamental matrix. We also note a third highly important property regarding applications of numerical linear algebra: * the transition matrix P is asymmetric. A realistic dimension for the matrix P in the Bianchi model described below is 8064 × 8064, but on average {{there are only a few}} nonzero entries per column. Merely storing such a large matrix in dense form would require nearly 0. 5 GBytes using 64 -bit floating point numbers, and computing its <b>LU</b> <b>factorisation</b> takes around 80 seconds on a modern microprocessor. It is thus highly desirable to employ specialised algorithms for sparse matrices. These algorithms are generally divided between those only applicable to symmetric matrices, the most prominent being the conjugate-gradient (CG) algorithm for solving linear equations, and those applicable to general matrices. A similar division is present in the literature on numerical eigenvalue problems...|$|E
40|$|The main {{objective}} of the research work presented in this thesis {{is the development of}} a single aerodynamic CFD code for the analysis of complex turbulent flow unsteady aerodynamics such as those encountered in horizontal and vertical axis wind turbines. The finite volume parallel CFD Optimized Structured multi-block Algorithm (COSA) research code solves the Navier-Stokes equations on structured multi-block grids and models turbulence effects with Menter's shear stress transport turbulence model. The novel algorithmic contribution of this research is the successful development of a Harmonic Balance (HB) solver which can reduce the run-time required to compute nonlinear periodic flow fields with respect to the conventional time-domain (TD) approach. The thesis also presents a semi-implicit integration based on <b>LU</b> <b>factorisation</b> and a successfully LAPACK libraries integration to massively improve the computational efficiency of the integration of the HB RANS equations and the turbulence model of Menter. The main computational results of this research are for two low-speed renewable energy applications. The former application is a turbulent unsteady flow analysis of a vertical axis wind turbine working in a low-speed turbulent regime {{for a wide range of}} operating conditions. The test case is first solved using the COSA TD turbulent solver to analyse and discuss in great detail the unsteady aerodynamic phenomena occurring in all regimes of this complex device. During the turbine rotation there is a generation of blade vortex shedding and wakes all around the rotor which interacts with the blades itself on the returning side. The most important features of the investigated devices were captured with CFD. In addition, a series of investigations have been conducted to analyse the effects of computational domain refinement, number of time steps per revolution and distance of the farfield boundary from the rotor centre on prediction accuracy. The solution of the turbulent flow solver is validated by comparing torque and power coefficients with experimental data and numerical solutions obtained with a state-of-the-art time-domain of commercial package regularly used by the industry and the Academia worldwide. A detailed selection of results is presented, dealing with the various investigated issues. Afterwards, the COSA HB turbulent solver is used to solve the problem and compare the HB resolution and speed-ups with the TD results. The main motivation for analysing this problem is to highlight the predictive capabilities and the numerical robustness of the developed turbulent HB flow solver for complex realistic problems with a strong nonlinearity and to shed more light on the complex physics of this renewable energy device. The latter application regards the turbulent unsteady flow analysis of horizontal axis wind turbine blade sections in yawed wind regime. The TD and HB turbulent flow analysis of a 164 m-diameter wind turbine rotor is performed. CFD represents an accurate design tool to get a better understanding of the physical behaviour of the flow field past wind turbine rotors and the importance of accurate design is increased as the machines tend to become larger. A study at 30...|$|E

