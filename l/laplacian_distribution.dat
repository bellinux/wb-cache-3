172|89|Public
2500|$|Research {{has shown}} that Bayesian methods that involve a Poisson {{likelihood}} function and an appropriate prior probability [...] (e.g., a smoothing prior leading to total variation regularization or a <b>Laplacian</b> <b>distribution</b> leading to -based regularization in a wavelet or other domain), such as via Ulf Grenander's Sieve estimator ...|$|E
2500|$|Although Gauss was {{the first}} to suggest the normal {{distribution}} law, Laplace made significant contributions. It was Laplace who first posed the problem of aggregating several observations in 1774, although his own solution led to the <b>Laplacian</b> <b>distribution.</b> It was Laplace who first calculated the value of the integral [...] in 1782, providing the normalization constant for the normal distribution. Finally, it was Laplace who in 1810 proved and presented to the Academy the fundamental central limit theorem, which emphasized the theoretical importance of the normal distribution.|$|E
5000|$|The <b>Laplacian</b> <b>distribution</b> {{has been}} used in speech {{recognition}} to model priors on DFT coefficients [...] and in JPEG image compression to model AC coefficients [...] generated by a DCT.|$|E
30|$|Note that Gaussian and <b>Laplacian</b> <b>distributions</b> {{are just}} two special cases of the GGD with β = 2 and β = 1, respectively.|$|R
30|$|Compared {{with the}} OLS method, the LAD method is robust to {{outliers}} [30].In this paper, we assume the error vector follows an additive {{combination of two}} independent distributions: Gaussian and <b>Laplacian</b> <b>distributions.</b>|$|R
3000|$|DCT {{coefficients}} of selected subimage of original image and Gaussian, <b>Laplacian</b> <b>distributions</b> for DC, AC coefficients, respectively. Then, the original watermark {{is embedded in}} the created synthetic image using any DCT-based visible watermarking algorithm to create used watermark.|$|R
50|$|The {{addition}} of noise {{drawn from a}} <b>Laplacian</b> <b>distribution,</b> with scaling parameter appropriate to a function's sensitivity, to the output of a statistical database query {{is the most common}} means to provide differential privacy in statistical databases.|$|E
5000|$|Research {{has shown}} that Bayesian methods that involve a Poisson {{likelihood}} function and an appropriate prior probability (e.g., a smoothing prior leading to total variation regularization or a <b>Laplacian</b> <b>distribution</b> leading to -based regularization in a wavelet or other domain), such as via Ulf Grenander's Sieve estimator [...] or via Bayes penalty methods ...|$|E
5000|$|Although Gauss was {{the first}} to suggest the normal {{distribution}} law, Laplace made significant contributions. It was Laplace who first posed the problem of aggregating several observations in 1774, although his own solution led to the <b>Laplacian</b> <b>distribution.</b> It was Laplace who first calculated the value of the integral ∫ e−t ²dt [...] in 1782, providing the normalization constant for the normal distribution. Finally, it was Laplace who in 1810 proved and presented to the Academy the fundamental central limit theorem, which emphasized the theoretical importance of the normal distribution.|$|E
30|$|The {{normalized}} Laplacian matrices {{generated on}} the Noordin Top terrorist network {{are displayed in}} Fig.  1 (right panels), which are new to our analysis. We can visually see a larger dissimilarity, both in the early and late steps compared to adjacency and <b>Laplacian</b> <b>distributions</b> of Fig.  1 (left and middle panels). Notice the progressive convergence towards the eigenvalue distribution in the final step, for all three matrices.|$|R
40|$|In {{this paper}} we propose a new method for image segmentation. The new {{algorithm}} is applied to the video segmentation task, where the localization of moving objects is based on change detection. The change detection problem in the pixel domain is formulated by two zero mean <b>Laplacian</b> <b>distributions.</b> The new method follows the concept of the well known Seeded Region Growing technique, while is adapted to the statistical description of change detection based segmentation, using Bayesian dissimilarity criteria in a way that leads to linear computational cost of growing. 1...|$|R
30|$|In this article, we {{consider}} only the Gaussian and <b>Laplacian</b> angular <b>distributions,</b> {{the most popular}} ones in the literature. However, our approach is still valid with other angular distributions.|$|R
30|$|In the paper, the {{reconstructed image}} is {{projected}} into the shear wave domain, and the <b>Laplacian</b> <b>distribution</b> model {{is used to}} characterize the shear wave coefficients. The <b>Laplacian</b> <b>distribution</b> model is used as the prior probability density function of the shear wave coefficients.|$|E
40|$|The <b>Laplacian</b> <b>Distribution</b> {{has been}} widely used to {{characterize}} the distribution of DCT coefficients in {{a great deal of}} research on statistical attributes of DCT for the reason that <b>Laplacian</b> <b>distribution</b> can achieve a good balance between the simplification of the model and fidelity to the real empirical data. But in our research, we found that there is a large discrepancy between the real data and the distortion model based on <b>Laplacian</b> <b>distribution.</b> Furthermore, the higher the rate, the larger the distortion. In this paper, we proposed a new distortion model based on mixed Laplacian and Uniform distributions. Experimental results show that the MLQ distortion model can approximate the real empirical data and has a higher degree of accuracy than the conventional distortion model based on <b>Laplacian</b> <b>distribution.</b> Compared with the conventional distortion model based on <b>Laplacian</b> <b>distribution,</b> the new model can decrease the MSE distortion by 2 – 6 units. The MLQ distortion model can represent the relationship of rate and distortion of the Mpeg- 4 FGS enhancement layer with a higher degree of accuracy...|$|E
40|$|International audienceMedian type filters {{take the}} main stream in suppressing impulse noise, and the <b>Laplacian</b> <b>distribution</b> {{assumption}} lays {{the basis for}} it. We however demonstrate in this paper that the Gaussian distribution assumption is more preferable than <b>Laplacian</b> <b>distribution</b> assumption in suppressing impulse noise, especially for high noise densities. This conclusion is supported by numerical experiments with different noise densities and filter model...|$|E
40|$|In this paper, we analyze {{statistical}} and rate-distortion (R-D) {{properties of}} MPEG- 4 Fine-Granular Scalability (FGS), which has recently {{become an important}} scalable compression framework and a de-facto standard for Internet video streaming. We first propose a novel statistical model of DCT residue that accurately captures {{the properties of the}} input to the MPEG- 4 FGS enhancement layer. Our results show that FGS residue concentrates a lot of probability mass near zero and cannot be accurately modeled by Gaussian or <b>Laplacian</b> <b>distributions.</b> We then model the distortion of each bitplane based on the proposed statistical framework and further demonstrate that our R-D model significantly outperforms current distortion models...|$|R
40|$|Transform domain denoising, noise {{filtering}} {{based on data}} from a local neighborhood and linear prediction are three important signal processing tasks. In this paper we treat these tasks from a maximum a posteriori estimation (MAP) perspective and address the problem of robust estimation. The Student-t and <b>Laplacian</b> <b>distributions</b> are used to model the noise to permit robustness to outliers. Independent Gaussian distributions with different variances are used as the prior distributions for the parameters to be estimated. This provides a mechanism to incorporate into the solution certain desirable properties such as the sparseness constrain in transform domain denoising and regularization in linear prediction. EM algorithms are developed for the three signal processing tasks. Applications are demonstrated. 1...|$|R
40|$|T wave alternans (TWA) {{has been}} {{proposed}} as a marker for cardiac instability and high risk of malignant ventricular arrhythmias. In this work, we analyze a Generalized Likelihood Ratio Test (GLRT) approach to TWA detection. We used several noise models considering Gaussian and <b>Laplacian</b> <b>distributions</b> as well as three stationarity degrees. Another novelty of the proposed detectors {{is the use of}} the data from the P wave. The GLRT detectors for all the models were derived and implemented. Their detection performance was evaluated using real ECG signals with simulated TWA, showing that models accounting for the non-stationarity of the noise obtained best results. We also found that Laplacian-based detectors outperformed those based on Gaussian noise assumption. 1...|$|R
3000|$|... in the {{following}} way. The value is replaced with a random variable drawn from a <b>Laplacian</b> <b>distribution,</b> [...]...|$|E
30|$|It {{has been}} shown that the <b>Laplacian</b> <b>distribution</b> is the best model for speech samples during voice {{activity}} intervals compared to the Gaussian, generalized Gaussian and gamma distribution [16], which has been taken into account for the estimation of entropy for speech signals in [10]. However, since the noise is typically Gaussian, assuming a <b>Laplacian</b> <b>distribution</b> for the noisy microphone array outputs is questionable, particularly for low SNR conditions.|$|E
3000|$|... has <b>Laplacian</b> <b>distribution</b> Laplace(0,b)[29]. So, we can {{estimate}} {{the variance of}} noise with the residual images from the sequential frames.|$|E
30|$|Estimate the {{parameters}} of the <b>Laplacian</b> and Cauchy <b>distribution</b> for each AC coefficient using (20) and (24), respectively.|$|R
40|$|Abstract—This report {{addresses}} {{the problem of}} speech enhancement employing the Minimum Mean-Square Error (MMSE) of β-order Short Time Spectral Amplitude (STSA). We present an analytical solution for β-order MMSE estimator where Discrete Fourier Transform (DFT) coefficients of (clean) speech are modeled by <b>Laplacian</b> <b>distributions.</b> Using some approximations for the {{joint probability density function}} and the Bessel function, we also present a closed-form version of the estimator (called β-order LapMMSE). The performance of the proposed estimator is compared to the state-of-the–art spectral amplitude estimators that assume Gaussian priors for clean DFT coefficients. Comparative results demonstrate the superiority of the proposed estimator in terms of speech enhancement / noise reduction measures. Index Terms — Laplacian speech modeling; spectral amplitude estimation; speech enhancement...|$|R
5000|$|Often the {{solution}} to these problems can be equivalently (or approximately) expressed and solved by converting the formulation to the unconstrained problem [...] where the Lagrange multiplier [...] is a non-negative constant that establishes the appropriate balance between rate and distortion. Solving the unconstrained problem is equivalent to finding a point on the convex hull {{of the family of}} solutions to an equivalent constrained formulation of the problem. However, finding a solution - especially a closed-form solution - to any of these three problem formulations can be difficult. Solutions that do not require multi-dimensional iterative optimization techniques have been published for only three probability distribution functions: the uniform, exponential, and <b>Laplacian</b> <b>distributions.</b> Iterative optimization approaches can be used to find solutions in other cases.|$|R
30|$|In Eq. (5), α is the <b>Laplacian</b> <b>distribution</b> {{parameter}} {{for each}} DCT coefficient and Δ is the quantization bin size.|$|E
3000|$|..., {{the center}} of the Gaussian or <b>Laplacian</b> <b>distribution</b> is assumed to be the LoS direction, which is in contradiction with our observation.|$|E
40|$|It {{is known}} that the {{distribution}} of the discrete cosine transform (DCT) coefficients of most natural images follow a <b>Laplacian</b> <b>distribution,</b> and this knowledge has been employed to improve decoder design. However, such is not the case for text documents. In this letter, we present an analysis of their DCT coefficient distributions, and show that a Gaussian distribution can be a realistic model. Furthermore, we can use a generalized Gaussian model to incorporate the <b>Laplacian</b> <b>distribution</b> found for natural images. published_or_final_versio...|$|E
3000|$|... + φ. Indeed, {{we assumed}} the same {{parameter}} values at the different array elements. However, {{by considering the}} wrong distribution type, the obtained mean AoAs would be different {{and as a result}} show high standard deviation. The same reasoning is adopted for the ASs estimates (19). One can argue that the mean of the AS estimates could be used instead of the standard deviation in (19). Actually, the mean of the obtained estimates would not give us any information about the angular distribution of the received signal. For instance, for the array structure illustrated in Figure 2 b, we obtain two AS estimates associated to the Gaussian and <b>Laplacian</b> <b>distributions.</b> In this case, we cannot select the right angular distribution. This is why we consider the standard deviation of the AS estimates.|$|R
40|$|We present {{two methods}} for variable-rate trellis quantization. Both methods utilize trellis codes based on linear congruential (LC) recursions. LC code trellises have good {{pseudo-random}} properties and are easily adapted to serve reconstruction alphabets of different sizes. The first method finds an entropy-constrained code only by optimizing over a scale factor. The scale factor modifies an initial reproducer alphabet {{in order to}} skew the associated set of codeword lengths. Using a Lagrangian formulation and the maximum a posteriori (MAP) heuristic, we also develop an entropy-constrained trellis quantizer suitable for short blocks of data. Here the tailbiting BCJR algorithm is used to find the MAP path in the trellis. Simulation results for the Gaussian and <b>Laplacian</b> <b>distributions</b> show that the proposed method is competitive with {{the best in the}} literature...|$|R
40|$|In {{this paper}} we address two {{problems}} crucial to motion analysis: the detection of moving objects and their localisation. Statistical and level set approaches are adopted in formulating these problems. For the change detection problem, the inter-frame difference is modelled by a mixture of two zero-mean <b>Laplacian</b> <b>distributions.</b> At first, statistical tests using criteria with negligible error probability are used for labelling as changed or unchanged as many sites as possible. All the connected components of the labelled sites are used thereafter as region seeds, which give the initial level sets for which velocity fields for label propagation are provided. We introduce a new multi-label fast marching algorithm for expanding competitive regions. The solution of the localisation problem {{is based on the}} map of changed pixels previously extracted. The boundary of the moving objects [...] ...|$|R
40|$|The {{proposed}} Generalised Directional <b>Laplacian</b> <b>Distribution</b> (DLD) is {{a hybrid}} be-tween the <b>Laplacian</b> <b>distribution</b> and the von Mises-Fisher distribution aiming at mod-elling multidimensional sparse directional or angular data. The essential algorithms {{to estimate the}} proposed distribution’s parameters as well as Mixtures of DLD (MDLD) are presented. The proposed DLD mixture model is used to cluster sound sources that exist in an underdetermined instantaneous sound mixture, offering a fast and viable solution to the general K × L (K < L) problem. 1...|$|E
40|$|Abstract — Assuming a <b>Laplacian</b> <b>distribution,</b> {{there exists}} a well known method for optimally biasing the {{reconstruction}} levels of the quantized AC DCT coefficients in the JPEG decoder. This, however, requires {{an estimate of the}} <b>Laplacian</b> <b>distribution</b> parameter. We derive a new, maximum likelihood estimate of the Laplacian parameter using only the quantized coefficients available at the decoder. We quantify the benefits of biased reconstruction through extensive simulations and demonstrate that such improvements are very close to the best possible resulting from centroid reconstruction...|$|E
40|$|By {{extensive}} {{analysis with}} several video sequences, we {{observed that the}} statistical distribution of the DCT coefficients in typical video coding applications is closer to a Cauchy distribution than to a <b>Laplacian</b> <b>distribution.</b> We developed the rate and the distortion expressions {{as a function of}} the video coder quantization parameter based on this observation. Experiments with an H. 264 codec demonstrate that the Cauchy distribution based expressions provide better estimates for the actual rate and distortion than those that are based on the <b>Laplacian</b> <b>distribution.</b> 1...|$|E
40|$|This papers {{presents}} {{a framework for}} detecting multiple moving moving objects in a sequence of images. Using a statistical approach, where the inter-frame difference is modeled by a mixture of two <b>Laplacian</b> <b>distributions</b> and a deformable contour-based energy minimization approach, we reformulate the motion detection problem as a front propagation problem. Following the work of geodesic active contours [2], we transform the detection of moving objects problem into an equivalent problem of geodesic computation, which is solved using a level set formulation scheme. To reduce the computational cost required by a direct implementation of the formulation scheme [5] the Narrow Band technique is used. In order to further reduce the CPU time, a multi-scale approach has also been considered. Very promising experimental results are provided using real video sequences...|$|R
3000|$|..., {{sometimes}} called the shade parameter, controls the tail decay rate. The GGD model contains the <b>Laplacian</b> and Gaussian <b>distributions</b> as special cases, that is, for [...]...|$|R
40|$|An {{extensive}} boundary element {{method code}} {{has been developed}} to calculate <b>Laplacian</b> field <b>distributions</b> in axially symmetric, multielectrode, multidielectric systems and extended to cases where space charges produced by the developing discharge are sufficiently large to distort the applied field. Experience with using these codes to evaluate surface fields and to model discharge development is reporte...|$|R
