0|299|Public
25|$|If it {{is desired}} to save memory, the storage {{can be reduced}} to one array plus 3 <b>line</b> <b>buffers.</b> One <b>line</b> <b>buffer</b> is used to {{calculate}} the successor state for a line, then the second <b>line</b> <b>buffer</b> is used to calculate the successor state for the next <b>line.</b> The first <b>buffer</b> is then written to its line and freed to hold the successor state for the third line. If a toroidal array is used, a third buffer is needed so that the original state of the first line in the array can be saved until the last line is computed.|$|R
40|$|The on-chip <b>line</b> <b>buffer</b> {{dominates the}} total area {{and power of}} line-based 2 -D DWT. Therefore, the <b>line</b> <b>buffer</b> wordlength has to be {{carefully}} designed to maintain the quality level due to the dynamic range growing and the round-off errors. In this paper, a complete analysis methodology is proposed to derive the required wordlength of <b>line</b> <b>buffer</b> given the desired quality level of reconstructed image. The proposed methodology can guarantee to avoid overflow of coefficients, {{and the difference between}} predicted and experimental quality level is averagely 0. 06 dB in terms of PSNR. 1...|$|R
40|$|In {{this paper}} we {{evaluate}} {{the performance of}} high bandwidth caches that employ multiple ports, multiple cycle hit times, on-chip DRAM, and a <b>line</b> <b>buffer</b> to find the organization that provides the best processor performance. Processor performance is measured in execution time using a dynamic superscalar processor running real-istic benchmarks that include operating system references. The results show that a large dual-ported multi-cycle pipelined SRAM cache with a <b>line</b> <b>buffer</b> maximizes processor performance. A large pipelined cache provides both a low miss rate and a high CPU clock frequency. Dual-porting the cache {{and the use of}} a <b>line</b> <b>buffer</b> provide the bandwidth needed by a dynamic superscalar processor. In addition, the <b>line</b> <b>buffer</b> makes the pipelined dual-ported cache the best option by increasing cache port bandwidth and hiding cache la-tency...|$|R
5000|$|... stream {{buffering}} state indicator (unbuffered, <b>line</b> <b>buffered,</b> fully buffered) ...|$|R
5000|$|Sprite capabilities: <b>Line</b> <b>buffers,</b> {{vertical}} position buffer, sprite-scaling, sprite flipping, mid-frame palette swap ...|$|R
5000|$|... #Caption: The {{exterior}} of the KL Monorail's Titiwangsa terminal station, with the terminating <b>line's</b> <b>buffer</b> stop.|$|R
40|$|Abstract—This paper {{presents}} a reconfigurable particle filter design methodology for a real-time bearings-only tracking application. The methodology provides {{the capability of}} selecting a single particle filter from multiple particle filter realizations with maximum resource sharing. The autonomous <b>buffer</b> <b>controller</b> mechanism for the architecture ensures correct operation of the particle filters. Parameter adaptation and algorithm reconfiguration can be accomplished with negligible reconfiguration overhead through <b>buffer</b> <b>controllers</b> {{and a set of}} switches for transforming dataflow structures such that any desired particle filter can be implemented. Two target particle filters, sample importance resample filter (SIRF) and Gaussian particle filter (GPF), are realized using field programmable gate array (FPGA) based on the proposed methodology. However, the architecture can be extended {{for a wide range of}} particle filters with different sets of dynamics. This paper successfully demonstrates that implementation of a domain specific processor for particle filters is feasible with performance that is much higher than that of commercially available digital signal processors (DSPs). Index Terms—Buffer controller, field programmable gate array (FPGA) design methodology, particle filter, reconfigurable design. I...|$|R
40|$|Abstract- This paper {{describes}} new {{optical switching}} architectures supporting asynchronous variable-length packets. Output line contention is resolved by optical delay <b>line</b> <b>buffers.</b> By introducing a WDM technology, parallel buffer can {{be equipped with}} multiple wavelengths on the optical delay <b>line</b> <b>buffer.</b> Using an ultrafast photonic label processing technique, an implementation of our architecture would be fast enough for packet scheduling that selects the appropriate output port, wavelength, and delay <b>line</b> <b>buffer.</b> To evaluate the switch performance, we model an output port of our switch as a multi-server and multi-queue system where each server corresponds to a wavelength and where each arriving packet joins the shortest queue. We use an approximate analytic approach to evaluate the switch performance. The results of the analysis and of simulation experiments show {{that the use of}} the WDM technique can greatly improve the switch performance in terms of packet loss probabilities. I...|$|R
5000|$|More strictly, zero or more {{lines are}} {{accumulated}} in the <b>line</b> editing <b>buffer,</b> separated by <b>line</b> delimiters (which {{may or may}} not be discarded once [...] comes around to reading them), and line editing operates upon the part of the <b>line</b> editing <b>buffer</b> that follows the last (if any) line delimiter in the buffer. So, for example, the [...] "erase" [...] character (whatever that has been programmed to be) will erase the last character in the <b>line</b> <b>buffer</b> only up to (but not including) a preceding line delimiter.|$|R
40|$|Abstract—Energy {{efficiency}} plays {{a crucial}} role in the design of embedded processors especially for portable devices with its limited energy source in the form of batteries. Since memory access (either cache or main memory) consumes a significant portion of the energy of a processor, the design of fast low-energy caches has become a very important aspect of modern processor design. In this paper, we present a novel cache architecture for reduced energy instruction caches. Our proposed cache architecture consists of the L 1 cache, multiple <b>line</b> <b>buffers,</b> and a prediction mechanism to predict which <b>line</b> <b>buffer,</b> or L 1 cache to access next. We used simulation to evaluate our proposed architecture and compare it with the HotSpot cache, Filter cache, Predictive <b>line</b> <b>buffer</b> cache and Way-Halting cache. Simulation results show that our approach can reduce instruction cache energy consumption, on average, by 75 % (compared to the base line architcture) without sacrificing performance I...|$|R
40|$|In this paper, {{we propose}} new optical {{switching}} archi-tectures supporting asynchronous and variable-length packets. Output line contention is resolved by optical delay <b>line</b> <b>buffers.</b> By introducing a WDM technology, parallel buffer can {{be equipped with}} multiple wavelengths on the optical delay <b>line</b> <b>buffer.</b> Differently from existing approaches, a main feature of our proposed architecture is that by employing a ultra-fast photonic label processing tech-nique, an implementation is realistic for packet scheduling, which selects the appropriate output port, wavelength and delay <b>line</b> <b>buffer.</b> For evaluating the switch performance, an output port of our proposed switch is mo deled as a multi-server and multi-queue system where each server corresponds to the wavelength. The arriving packet joins the shortest queue according to the scheduling policy of our switch. The switch performance is studied by utilizing an approximate analytic approach. Through the analysis and simulation experiments, we show that {{the introduction of the}} WDM technique can much improve the switch performance in terms of packet loss probabilities. 1...|$|R
5000|$|Sprite capabilities: <b>Line</b> <b>buffer,</b> 8x8 to 16x16 sizes, 4 colors per sprite, 15 sprites (7 main sprites, 7 shells, 1 missile) per scanline, 240 sprite pixels per scanline, sprite flipping, sprite {{animation}} ...|$|R
50|$|I/O {{devices were}} {{connected}} to the system via the Q-Bus, whose 22-bit address space was mapped onto the 24-bit memory address space of the Firefly by using mapping registers controlled by the master processor. The devices used direct memory access (DMA) to access the memory though the cache of the main processor. The Firefly's I/O devices were: a monochrome display <b>controller</b> (MDC), a <b>buffered</b> <b>controller</b> for magnetic disk drives, the RQDX3 and an DEQNA Ethernet controller.|$|R
40|$|Abstract—In this paper, three generic RAM-based {{architectures}} {{are proposed}} to efficiently construct the corresponding two-dimensional architectures {{by use of}} the line-based method for any given hardware architecture of one-dimensional (1 -D) wavelet filters, including conventional convolution-based and lifting-based architectures. An exhaustive analysis of two-dimensional architectures for discrete wavelet transform in the system view is also given. The first proposed architecture is for 1 -level decomposition, which is presented by introducing the categories of internal <b>line</b> <b>buffers,</b> the strategy of optimizing the <b>line</b> <b>buffer</b> size, and the method of integrating any 1 -D wavelet filter. The other two proposed architectures are for multi-level decomposition. One applies the recursive pyramid algorithm directly to the proposed 1 -level architecture, {{and the other one}} combines the two previously proposed architectures to increase the hardware utilization. According to the comparison results, the proposed architecture outperforms previous architectures in the aspects of <b>line</b> <b>buffer</b> size, hardware cost, hardware utilization, and flexibility. Index Terms—Discrete wavelet transform (DWT), lifting scheme, line-based method, recursive pyramid algorithm, VLSI architecture. I...|$|R
50|$|Under the Ulster Transport Authority, {{the engines}} were painted black with {{vermilion}} and yellow <b>lining.</b> <b>Buffer</b> beams, {{name and number}} plate backgrounds were red {{and the practice of}} putting the number on the front buffer beam was continued.|$|R
40|$|The goal of {{this project}} is to develop an Application Specific Integrated Circuit (ASIC) {{for use in the}} control {{electronics}} of the Spacecraft Optical Disk Recorder (SODR). Specifically, this project is to design an extendable memory <b>buffer</b> <b>controller</b> ASIC for rate matching between a system Input/Output port and the SODR's device interface. The aforementioned goal can be partitioned into the following sub-goals: (1) completion of ASIC design and simulation (on-going via ASEE fellowship); (2) ASIC Fabrication (at ASIC manufacturer); and (3) ASIC Testing (NASA/LaRC, Christopher Newport University) ...|$|R
40|$|This paper {{proposes a}} new MPEG- 4 rate control {{algorithm}} for single or multiple object video sequences. The algorithm aims {{to achieve an}} accurate bit rate with the maximum picture quality while efficiently handling buffer fullness and scene change. In addition to estimating the bit budget of a frame based on its global coding complexity, the algorithm dynamically distributes the target bits for each object within a frame according to its coding complexity. Even though the VM 8 solution and other algorithms adopt a simple proportional <b>buffer</b> <b>controller,</b> their control ability is rather ineffective. The proposed algorithm exploits a novel Proportional Integrated Differential (PID) <b>buffer</b> <b>controller</b> to effectively minimize the buffer overflow or underflow. The PID based controller reduces the deviation between the current buffer fullness and the target buffer fullness, mitigates the overshoots, and improves the transient response. The combined effect is a more smooth and effective buffer control. Furthermore, the algorithm defines a new and effective coding complexity of an object and dynamically optimizes several parameters. Overall, the proposed algorithm successfully achieves accurate target bit rate, provides promising coding quality, decreases buffer overflow/underflow and lowers {{the impact of a}} scene change. Keywords: MPEG- 4 video coding, rate control, bit allocation, multiple video objects, PID buffer control. 1...|$|R
50|$|However, the livery {{that the}} UTA finally adopted saw the engines painted black with {{vermilion}} and yellow <b>lining.</b> <b>Buffer</b> beams, {{name and number}} plate backgrounds were red {{and the practice of}} putting the number on the front buffer beam was continued.|$|R
40|$|As cache {{constitutes}} the {{major part of}} power dissipation of processor system, energy efficient cache design has attracted much attention. Combined with the characteristics of traditional Predictive <b>Line</b> <b>Buffer</b> (PLB) cache and Trace cache, we define the Key Instruction Trace (KIT) which will make the utilization of instruction trace more effectively. A novel predictive schema-“Key Instruction Trace Predictive Strategy (KITPS) ” is also implemented for traditional PLB cache at a modest cost. KITPS improve the hit ratio of <b>line</b> <b>buffer</b> effectively and present advantages in both performance and energy consumption. In the experiments, compared to the traditional PLB cache, the PLB cache with KITPS could provide about 31. 5 % improvement of performance and 18. 9 % energy saving...|$|R
50|$|The State owns {{extensive}} acreage {{throughout the}} state, which is sometimes required for roads, utility <b>lines,</b> <b>buffer</b> areas, or other uses to assist nearby community development. In other cases, property {{is no longer}} needed by {{the state in the}} short or long term.|$|R
50|$|A second key {{concept is}} that {{movement}} along a <b>buffer</b> <b>line</b> must correspond {{to a change}} in PCO2. Thus, like the isopleths, the <b>buffer</b> <b>line</b> as drawn on a typical Davenport Diagram (e.g., Fig 6) is actually the projection of a line existing in three-dimensional space onto a two-dimensional plane. As with the isopleths, <b>buffer</b> <b>lines</b> in their actual three-dimensional orientation are confined to the surface representing the values of PCO2, HCO3− and pH that satisfy equilibrium for the system. In Fig. 10, the dark red lines are the actual <b>buffer</b> <b>lines</b> in three-dimensional space, while the light red lines are the projections of the <b>buffer</b> <b>lines</b> onto a two-dimensional plane. (We will see later how multiple, parallel <b>buffer</b> <b>lines</b> can be determined for a given system).|$|R
30|$|In this paper, we have {{proposed}} high-performance FMA, PMA and RMA with dual-pixel scanning method for computing multi-level 2 -D DWT. The architectures are compared {{on the basis}} of resources utilized and speed. Micro-pipelining is employed in predict/update processor element to reduce the critical path to Ta[*]+[*]Ts and Ta[*]+[*]Tm for lifting (5, 3) and (9, 7) filters, respectively. Optimized single-level 2 -D DWT blocks (B 1), (B 2), and (B 3) are proposed to design multi-level architecture. The proposed FMA for lifting (5, 3) and lifting (9, 7) uses only 2 N and 4 N <b>line</b> <b>buffers,</b> respectively. The proposed PMA is simple, regular, modular, and can be cascaded for n-level decomposition. The PMA for lifting (5, 3) has a critical path delay of Ta[*]+[*]Ts. Moreover, it requires only 4.8 N <b>line</b> <b>buffers</b> for five-level decomposition, thus reduces <b>line</b> <b>buffer</b> approximately 50 % than other similar designs. The proposed RMA uses 16 multipliers and 24 adders for n-level decomposition. Moreover, a requirement of <b>line</b> <b>buffers</b> is independent of level of decomposition. The proposed architectures are implemented on Xilinx Virtex family devices. The proposed FMA and PMA operate with frequency of 537 MHz, which is sufficient to handle 518 full-HD frames with 1, 920 [*]×[*] 1, 080 resolution. The proposed PMA, when implemented on FPGA for five-level DWT, utilizes 1, 178 slices and provides a throughput rate of 4, 080 frames (512 [*]×[*] 512) per second, which is almost five times than that of the existing design. The proposed RMA uses unique buffer management and only single processing element for computing predict and update to save area and power. The Xilinx Virtex- 4 implementation of RMA uses 1, 822 (4 %) and 1, 040 (2 %) slices for lifting (9, 7) and (5, 3) filters, respectively.|$|R
40|$|This letter proposes {{an exact}} and simple method to {{optimize}} the fiber lengths of fiber delay <b>line</b> <b>buffers</b> in an asynchronous network with variable packet length. Existing algorithms required considerable calculation, which can be avoided by using the closed-form loss probability expressions we obtained, valid for general traffic conditions...|$|R
40|$|Scaling {{an input}} video stream to {{multiple}} output resolutions {{is common in}} many video conferencing and studio multiviewer products. Dedicating a full scaling engine, such as the Altera Scaler II MegaCore ® function, to each output resolution can lead to inefficient solutions, because the design can share the video <b>line</b> <b>buffers</b> that each IP core require across all the scaling engines. Depending on the output resolutions, the design may time-division multiplex the algorithmic IP core of a single scaling engine to produce multiple output resolutions. The Multioutput Scaler reference design demonstrates how to perform the following actions: Combine IP cores from the video and image processing component library to create flexible scaling solutions. Share <b>line</b> <b>buffers</b> across multiple algorithmic functions. Use time-division multiplexed (TDM) algorithmic functions across multiple outputs...|$|R
40|$|We {{revisit the}} idea of using small <b>line</b> <b>buffers</b> in-front of caches. We propose ReCast, a tiny tag set cache that filters a {{significant}} number of tag probes to the L 2 tag array thus reducing power. The key contribution in ReCast is S-Shift, a simple indexing function (no logic involved just wires) that greatly improves the utility of <b>line</b> <b>buffers</b> with no additional hardware cost. S-Shift {{can be viewed as a}} technique for emulating larger cache blocks and hence exploiting more spatial locality but without paying the penalties of actually using a larger L 2 cache block. Using several SPEC CPU 2000 applications and a model of an aggressive, dynamicallyscheduled, superscalar processor we demonstrate that a practical ReCast organization can significantly reduce power in the L 2. Specifically, a 64 -entry ReCast comprising eight sub-banks of eight entries each can filter about 50 % of all tag probes for a 1 Mbyte L 2 cache. A conventional <b>line</b> <b>buffer</b> of the same size filters only 32 % of all tag probes. The resulting average reduction in L 2 tag power is 38 % and 85 % with writeback or writethrough L 1 caches respectively. This translates to a reduction of 16 % or 52 % of the overall L 2 power respectively. We also analyze a few representative applications explaining why S-Shift works well. ...|$|R
50|$|<b>Line</b> <b>buffer</b> or FIFO-based {{receivers}} {{will require}} that the transmitter adhere to strict line timing requirements of the display. Since the display horizontal scanning must be precise, the arrival time of lines will {{also need to be}} precise. ARINC 818 intends that timing parameters such as these be captured in an ICD specific to the video system.|$|R
5000|$|The [...] "word erase", [...] "literal next", and [...] "reprint" [...] {{characters}} (by default , , and [...] - [...] ASCII , , and [...] ) performed {{additional line}} editing functions. [...] "word erase" [...] erased {{the last word}} {{at the end of}} the <b>line</b> editing <b>buffer.</b> [...] "literal next" [...] allowed any special character to be entered into the <b>line</b> editing <b>buffer</b> (a function available, somewhat inconveniently, in Seventh Edition Unix via the backslash character). [...] "reprint" [...] caused the line discipline to reprint the current contents of the <b>line</b> editing <b>buffer</b> on a new line (useful for when another, background, process had generated output that had intermingled with line editing).|$|R
40|$|Abstract—The on-chip <b>line</b> <b>buffer</b> {{dominates the}} total area {{and power of}} line-based 2 -D {{discrete}} wavelet transform (DWT). In this paper, a memory-efficient VLSI implementation scheme for line-based 2 -D DWT is proposed, which consists of two parts, the wordlength analysis methodology and the multiple-lifting scheme. The required wordlength of on-chip memory is determined firstly by use of the proposed wordlength analysis methodology, and a memory-efficient VLSI implementation scheme for line-based 2 -D DWT, named multiple-lifting scheme, is then proposed. The proposed wordlength analysis methodology can guarantee to avoid overflow of coefficients, and the average difference between predicted and experimental quality level is only 0. 1 dB in terms of PSNR. The proposed multiple-lifting scheme can reduce not only at least 50 % on-chip memory bandwidth but also about 50 % area of <b>line</b> <b>buffer</b> in 2 -D DWT module. Index Terms—Discrete wavelet transform (DWT), image compression, JPEG 2000, MPEG- 4, VLSI architecture. Fig. 1. General line-based scheme for single-level column-row 2 -D DWT. I...|$|R
50|$|Fully Buffered DIMM (FB-DIMM) modules {{are used}} in some systems with large maximum memory capacities. In normal registered/{{buffered}} memory only the control <b>lines</b> are <b>buffered,</b> whereas in fully buffered memory the data <b>lines</b> are <b>buffered</b> as well with all transfers performed in a serial fashion; the additional logic present on each FB-DIMM module transforms serial input into parallel signals required to drive memory chips.|$|R
50|$|Tralee and Dingle {{locomotive}} livery was a {{dark green}} lined out red between two cream <b>lines.</b> <b>Buffer</b> beams were red. Following the 1925 amalgamation the livery followed that of the GSR in that locomotives were painted plain grey with red buffer beams. It carried this livery, in common with other TDLR locos, on into CIÉ days, retaining it (though in filthy condition!) to the end.|$|R
40|$|Abstract—Image {{pipeline}} processing {{is crucial}} to generating high quality images in applications using complementary metaloxide-semiconductor (CMOS) /charge-coupled device sensors. The on-chip <b>line</b> <b>buffer</b> normally dominates the total area and power dissipation due to the needed filter window buffering. As image resolution and filter support increase, the area and power requirement increase accordingly. This paper presents a novel pyramid architecture to efficiently process a system that the image pipeline is between an image sensor and video coding engine. By utilizing {{the features of the}} pyramid structure and block-based video/image encoders, the proposed architecture is scalable from low to high image resolution and filter size. The input image is first partitioned into floors of tiles to reduce the frame <b>line</b> <b>buffer.</b> Two computing schemes, immediate result reuse and vertical snack scan, are utilized to reduce the overlapping redundant computations. A 90 nm CMOS chip design with 7 × 5 filter support for 3840 × 2160 quad full high definition video at 30 frames/s is designed to demonstrate the performance of power and area efficiency. Compared with traditional architectures with frame <b>line</b> <b>buffers,</b> the proposed design has shown that the power consumption is reduced by 25 % to 108 mW from 145 mW. The chip area is reduced by 65 % to 309 K from 888 K logic gates. The external memory bandwidth increases to 8286 Mbit/s from 5972 Mbit/s for YUV 4 : 2 : 0, from 7963 Mbit/s for YUV 4 : 2 : 2, and is reduced by 30 % from 11 944 Mbit/s for YUV 4 : 4 : 4. Index Terms—Camcorder, digital image processing pipeline, digital still camera, high definition video, VLSI architecture. I...|$|R
30|$|The ZSAD {{matching}} {{is performed}} twice, once using the left image as reference and once using the right image as reference window. Although this doubles the necessary hardware resources for ZSAD units and for searching the best match, {{it allows for}} a consistency crosscheck performed in the highest resolution stage. The buffer size remains largely identical since on-chip <b>line</b> <b>buffers</b> are implemented for both images in any case.|$|R
3000|$|... dB) for {{endoscopic}} images. Especially, it has low complexity hardware overhead (only two <b>line</b> <b>buffers)</b> {{and supports}} real-time compressing. In addition, the algorithm can provide lossless compression {{for the region}} of interest (ROI) and high-quality compression for other regions. The ROI can be selected arbitrarily by varying ROI parameters. In addition, the VLSI architecture of this compression algorithm is also given out. Its hardware design has been implemented in [...]...|$|R
30|$|In {{terms of}} {{resource}} usage, the upsampling, downsampling, and synchronization require <b>line</b> <b>buffers</b> and hence on-chip SRAM memory resources. This {{is well suited}} for FPGAs, which are typically equipped with abundant SRAM memory blocks. However, {{the size of the}} synchronization buffer grows exponentially with the number of stages, which renders architectures with a high number of stages still too complex even for large FPGAs, unless external memory resources can be used.|$|R
5000|$|... #Caption: Figure 8. The {{presence}} of strong non-bicarbonate buffers {{results in a}} <b>buffer</b> <b>line</b> with a steep slope, while the {{presence of}} weak non-bicarbonate buffers results in a <b>buffer</b> <b>line</b> with a slope closer to zero.|$|R
40|$|This paper {{develops}} hardware modules {{for rapid}} prototyping of video processing systems {{based on the}} Xilinx video frame <b>buffer</b> <b>controller</b> (VFBC). This implementation allows the storage of video frames in memory external to the programmable device, {{as well as its}} proper handle for designing spatio-temporal processing systems using the Xilinx System Generator model-based design flow. The hardware modules are responsible for the configuration and control of writing and reading VFBC interfaces, as well as the manipulation of video synchronization signals for interconnecting input and output peripherals. The article also include the description of the elaborated modules and the analysis of the results of its use {{for the development of a}} temporal video processing demonstrator using a simple motion detector on a Spartan- 6 SP 605 Evaluation Platform board. Peer Reviewe...|$|R
