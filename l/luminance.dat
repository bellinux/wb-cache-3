8771|149|Public
5|$|The Sun is a G2V star, with G2 {{indicating}} {{its surface}} temperature of approximately 5,778K (5,505°C, 9,941°F), and V that it, like most stars, is a main-sequence star. The average <b>luminance</b> of the Sun is about 1.88gigacandela per square metre, but as viewed through Earth's atmosphere, this is lowered to about 1.44Gcd/m2. However, the <b>luminance</b> is not constant across the disk of the Sun (limb darkening).|$|E
5|$|The use of Yehudi {{lights to}} {{camouflage}} aircraft by matching their <b>luminance</b> with the background sky was developed, in part, by the US Navy's Project Yehudi from 1943 onwards, following pioneering {{experiments in the}} Canadian diffused lighting camouflage project for ships early in the Second World War. A Canadian professor, Edmund Godfrey Burr, had serendipitously stumbled upon the principle when he saw an aircraft coming in to land over snow suddenly vanish; {{he realized that the}} reflected light had increased its brightness just enough to match the background sky. The ships were fitted with ordinary projectors mounted on small platforms fixed to their sides, with the projectors pointing inwards at the ship's side. The brightness was adjusted to match the brightness of the sky. The Canadian experiment showed that such counter-illumination camouflage was possible, arousing interest in both Britain and America, but the equipment was cumbersome and fragile, and neither the Royal Canadian Navy nor their allies brought it into production.|$|E
25|$|The CIE model capitalises on {{this fact}} by {{defining}} Y as <b>luminance.</b> Z is quasi-equal to blue stimulation, or the S cone response, and X {{is a mix}} (a linear combination) of cone response curves chosen to be nonnegative. The XYZ tristimulus values are thus analogous to, but different from, the LMS cone responses of the human eye. Defining Y as <b>luminance</b> has the useful result that for any given Y value, the XZ plane will contain all possible chromaticities at that <b>luminance.</b>|$|E
40|$|Lighting experts viewed {{a series}} of {{greyscale}} images of a typical open-plan partitioned office, and rated them for attractiveness. The image was projected onto a screen at realistic <b>luminances</b> and 54 % of full size. The images in the series were geometrically identical, but the <b>luminances</b> of important surfaces were independently manipulated. Initially, the combinations of <b>luminances</b> were random, but as the session continued a genetic algorithm was used to generate images that generally retained features of the prior images that were rated most highly. As a result, the images presented converged on an individual's preferred combination of <b>luminances.</b> The results demonstrated that this technique was effective in reaching a participant's preferred combination of <b>luminances.</b> There were significant differences in room appearance ratings of the most attractive image compared to an image of average attractiveness, and the differences were in the expected direction (e. g., more pleasant, more spacious). Furthermore, factor analysis of ratings of the most attractive images revealed a factor structure similar that obtained when people rated real office spaces. Preferred <b>luminances</b> {{were similar to those}} chosen by people in real settings...|$|R
50|$|By {{increasing}} {{the levels of}} pre-adapting <b>luminances,</b> the duration of cone mechanism dominance extends, while the rod mechanism switch over is more delayed. In addition the absolute threshold takes longer to reach. The opposite is true for decreasing the levels of pre-adapting <b>luminances.</b>|$|R
40|$|The {{relationship}} between pupil size and perimetric sensitivity {{was investigated in}} a group of clinically normal emmetropic subjects using the Dicon AP 3000 computer-assisted perimeter at bowl <b>luminances</b> of 10 asb and 45 asb. Pupil size was modified with the miotic thymoxamine 0. 5 % and the mydriatic phenylephrine 10 %; saline was used as the control. Perimetric sensitivity increased with an increase in pupil size. The effect was greatest for peripheral locations for both bowl <b>luminances.</b> The fluctuations in perimetric sensitivity increased with peripheral angle and with decrease in pupil size for both bowl <b>luminances...</b>|$|R
25|$|Like {{most other}} types of subpixel rendering, ClearType {{involves}} a compromise, sacrificing one aspect of image quality (color or chrominance detail) for another (light and dark or <b>luminance</b> detail). The compromise can improve text appearance when <b>luminance</b> detail {{is more important than}} chrominance.|$|E
25|$|This {{technique}} {{allows the}} SSEP to directly control the stimulus that elicits the SSEP without the conscious {{intervention of the}} experimental subject. For example, the running average of the SSEP can be arranged to increase the <b>luminance</b> of a checkerboard stimulus if the amplitude of the SSEP falls below some predetermined value, and to decrease <b>luminance</b> if it rises above this value. The amplitude of the SSEP then hovers about this predetermined value. Now the wavelength (colour) of the stimulus is progressively changed. The resulting plot of stimulus <b>luminance</b> versus wavelength is a plot of the spectral sensitivity of the visual system.|$|E
25|$|JPEG {{compression}} artifacts blend {{well into}} photographs with detailed non-uniform textures, allowing higher compression ratios. Notice how a higher compression ratio first affects the high-frequency textures in the upper-left {{corner of the}} image, and how the contrasting lines become more fuzzy. The very high compression ratio severely affects {{the quality of the}} image, although the overall colors and image form are still recognizable. However, the precision of colors suffer less (for a human eye) than the precision of contours (based on <b>luminance).</b> This justifies the fact that images should be first transformed in a color model separating the <b>luminance</b> from the chromatic information, before subsampling the chromatic planes (which may also use lower quality quantization) in order to preserve the precision of the <b>luminance</b> plane with more information bits.|$|E
5000|$|A GTIA color {{interpretation}} mode {{can generate}} 16 <b>luminances</b> per color providing a 256 color palette.|$|R
50|$|This page lists {{examples}} of <b>luminances,</b> measured in candelas per square metre and grouped {{by order of}} magnitude.|$|R
40|$|A {{study is}} {{reported}} of human binocular rivalry and fusion over {{a range of}} <b>luminances</b> from scotopic to photopic. At scotopic light levels, rivalry alternations were very slow and complete. Suppression spread over much larger areas of the visual field than at photopic light levels. As <b>luminances</b> decreased from photopic to scoptopic levels there was a rod-cone break for binocular rivalry. Mean suppression durations became abruptly greater as light levels dropped below those allowing the cones to be active. Horizontal disparities allowing fusion were 4 to 6 times greater at scotopic than at photopic light levels. Binocular vision at scotopic <b>luminances</b> was sluggish and of low resolution. It is as though connections to, and within, binocular vision are changed when light levels allow only rod input...|$|R
25|$|Tetrahedra {{are used}} in color space {{conversion}} algorithms specifically for {{cases in which the}} <b>luminance</b> axis diagonally segments the color space (e.g. RGB, CMY).|$|E
25|$|High-dynamic-range imaging (HDRI) {{is a high}} {{dynamic range}} (HDR) {{technique}} used in imaging and photography to reproduce a greater dynamic range of luminosity than is possible with standard digital imaging or photographic techniques. The aim is to present a similar range of <b>luminance</b> to that experienced through the human visual system. The human eye, through adaptation of the iris and other methods, adjusts constantly {{to adapt to a}} broad range of <b>luminance</b> present in the environment. The brain continuously interprets this information so that a viewer can see {{in a wide range of}} light conditions.|$|E
25|$|Variables such as pupil size, {{background}} adaptation <b>luminance,</b> {{duration of}} presentation, type of optotype used, interaction effects from adjacent visual contours (or “crowding") can all affect visual acuity measurement.|$|E
40|$|Abstract Traditional {{industrial}} luminaires possess {{little if}} any uplight component. As a result, ceiling surface <b>luminances</b> {{and in some cases}} wall <b>luminances</b> in industrial settings tend to be low, giving the overall environment a cave-like appearance. Although this type of lighting can provide the required quantity of light on the work surface, it does little to address other design issues including the psycho-logical needs of the industrial worker. Can room surface brightnesses in an industrial environment affect an industrial worker’s visual perception and sense of satisfaction with that environment? This study compared four commercially available industrial lighting systems, each with a different percent-age of uplight. Actual industrial workers from various companies evaluated the systems in an industrial-like setting. Both a semantic differential scaling technique and a lighting-specific evaluation technique were used in the study. The results indicate a preference on the part of industrial workers for an environment with higher average room surface <b>luminances.</b> Impressions of spaciousness, brightness and stimulation correlated with an overall preference for higher surface <b>luminances.</b> The implication is that the psychological impact of lighting in the industrial environment should be an important consid-eration during the design process for industrial spaces. ...|$|R
5000|$|A {{more general}} concept {{is that of}} [...] "discrimination ellipsoids" [...] in the entire {{three-dimensional}} color space, which would include the ability of an observer to discriminate between two different <b>luminances</b> of the same color. Such measurements were carried out, among others, by Brown and MacAdam in 1949, Davidson in 1951, Brown in 1957, and by Wyszecki and Fielder in 1971. It {{was found that the}} discrimination ellipsoids yielded relatively unchanging discrimination ellipses in chromaticity space for <b>luminances</b> between 3 and 30 cd/m2.|$|R
40|$|We {{address the}} tone {{reproduction}} problem by integrating local adaptation with global-contrast consistency. Many previous works {{have tried to}} compress high-dynamic-range (HDR) <b>luminances</b> into a displayable range in imitation of the local adaptation mechanism of human eyes. Nevertheless, while the realization of local adaptation is not theoretically defined, exaggerating such effects often causes unnatural global contrasts. We propose a luminance-driven perceptual grouping process to derive a sparse representation of HDR <b>luminances,</b> and use the grouped regions to approximate local properties of <b>luminances.</b> The advantage of incorporating a sparse representation is twofold: We can simulate local adaptation based on region information, and subsequently apply piecewise tone mappings to monotonize the relative brightness over only a few perceptually significant regions. Our experimental {{results show that the}} proposed framework gives a good balance in preserving local details and maintaining global contrasts of HDR scenes. 1...|$|R
25|$|Computer graphic {{techniques}} {{capable of}} rendering high-contrast scenes shifted the focus from color to <b>luminance</b> {{as the main}} limiting factor of display devices. Several tone mapping operators were developed to map high dynamic range (HDR) images to standard displays. More recently, this work has branched away from utilizing <b>luminance</b> to extend image contrast and towards other methods such as user-assisted image reproduction. Currently, image reproduction has shifted towards display-driven solutions since displays now possess advanced image processing algorithms that help adapt rendering of the image to viewing conditions, save power, up-scale color gamut and dynamic range.|$|E
25|$|The {{resulting}} normalized {{color matching}} functions are then scaled in the r:g:b ratio of 1:4.5907:0.0601 for source <b>luminance</b> and 72.0962:1.3791:1 for source radiance {{to reproduce the}} true color matching functions. By proposing that the primaries be standardized, the CIE established an international system of objective color notation.|$|E
25|$|Another use of {{weighting}} is in television, {{where the}} red, {{green and blue}} components of the signal are weighted according to their perceived brightness. This ensures compatibility with black and white receivers, and also benefits noise performance and allows separation into meaningful <b>luminance</b> and chrominance signals for transmission.|$|E
30|$|High CRIs (80 – 88) at {{practical}} <b>luminances</b> (≥ 1000  cd m− 2) were obtained, with a CRI of 88 {{being the}} highest among hybrid WOLEDs.|$|R
40|$|Purpose To {{evaluate}} rod and cone {{contributions to}} the dark-adapted 15 -Hz flicker electroretinogram (ERG) across {{a broad range of}} stimulus <b>luminances</b> by compar-ing rod-isolating (ERGR), cone-isolating (ERGC), and non-receptor-specific (ERGR?C) responses. Methods Dark-adapted, full-field 15 -Hz ERGs were obtained from four normally sighted subjects (ages 29 – 36 years) using a four-primary LED-based stimulat-ing system. The primaries were either modulated sinusoidally in phase (ERGR?C) or were modulated in counter-phase to achieve rod isolation (ERGR) or cone isolation (ERGC) by means of triple silent substitution. Measurements were made for a broad range of <b>luminances</b> (- 2. 5 to 1. 8 log scot. cd/m 2 in 0. 2 log uni...|$|R
30|$|These greater {{punctual}} <b>luminances</b> {{present in}} the devices with directly visible leds (Gled, Mled, type II devices) compared to the “homogeneous” Type I lights seem {{to be responsible for}} the discomfort feeling obtained from the subjective experience.|$|R
25|$|When {{judging the}} {{relative}} <b>luminance</b> (brightness) {{of different colors}} in well-lit situations, humans tend to perceive light within the green parts of the spectrum as brighter than red or blue light of equal power. The luminosity function that describes the perceived brightnesses of different wavelengths is thus roughly analogous to the spectral sensitivity of M cones.|$|E
25|$|FM is {{also used}} at {{intermediate}} frequencies by analog VCR systems (including VHS) to record the <b>luminance</b> (black and white) portions of the video signal. Commonly, the chrominance component is recorded as a conventional AM signal, using the higher-frequency FM signal as bias. FM is the only feasible method of recording the <b>luminance</b> ("black and white") component of video to (and retrieving video from) magnetic tape without distortion; video signals have a large range of frequency components – from a few hertz to several megahertz, too wide for equalizers to work with due to electronic noise below −60dB. FM also keeps the tape at saturation level, acting {{as a form of}} noise reduction; a limiter can mask variations in playback output, and the FM capture effect removes print-through and pre-echo. A continuous pilot-tone, if added to the signal – as was done on V2000 and many Hi-band formats – can keep mechanical jitter under control and assist timebase correction.|$|E
25|$|Modern HDR imaging uses a {{completely}} different approach, based on making a high-dynamic-range <b>luminance</b> or light map using only global image operations (across the entire image), and then tone mapping the result. Global HDR was first introduced in 1993 resulting in a mathematical theory of differently exposed pictures of the same subject matter that was published in 1995 by Steve Mann and Rosalind Picard.|$|E
50|$|Grating {{elements}} {{can have}} <b>luminances</b> {{other than that}} of sharp-edged bars. If the graph of a grating is sinusoidal (see top panel in the illustration), the grating looks like a set of blurry light and dark bars and it is called a sine-wave grating.|$|R
50|$|As with sRGB, {{the color}} {{component}} values in wide-gamut RGB are not {{proportional to the}} <b>luminances.</b> Similar to Adobe RGB, a gamma of 2.2 is assumed, without the linear segment near zero that is present in sRGB. The precise gamma value is 563/256, or 2.19921875.|$|R
50|$|In 1996, the Polish demo group Atari Programming Champions {{released}} Champions Interlace (CIN), {{a viewer}} which shows pictures in 160x192 bitmap mode with 64 colors. The technique involves switching between Graphics 15 and Graphics 11 every scanline, giving off 16 colors at 4 <b>luminances.</b>|$|R
25|$|An {{important}} limitation for HDR {{photography is}} that any movement between successive images will impede or prevent success in combining them afterwards. Also, as one must create several images (often three or five and sometimes more) to obtain the desired <b>luminance</b> range, such a full 'set' of images takes extra time. HDR photographers have developed calculation methods and techniques to partially overcome these problems, {{but the use of}} a sturdy tripod is, at least, advised.|$|E
25|$|The idea {{of using}} several {{exposures}} to adequately reproduce a too-extreme range of <b>luminance</b> was pioneered {{as early as the}} 1850s by Gustave Le Gray to render seascapes showing both the sky and the sea. Such rendering was impossible at the time using standard methods, as the luminosity range was too extreme. Le Gray used one negative for the sky, and another one with a longer exposure for the sea, and combined the two into one picture in positive.|$|E
25|$|HDR {{images can}} {{represent}} a greater range of <b>luminance</b> levels {{than can be}} achieved using more 'traditional' methods, such as many real-world scenes containing very bright, direct sunlight to extreme shade, or very faint nebulae. This is often achieved by capturing and then combining several different, narrower range, exposures of the same subject matter. Non-HDR cameras take photographs with a limited exposure range, referred to as LDR, resulting {{in the loss of}} detail in highlights or shadows.|$|E
5000|$|Mesopic {{vision is}} a {{combination}} of photopic vision and scotopic vision in low but not quite dark lighting situations. [...] Mesopic light levels range from <b>luminances</b> of approximately 0.001 to 3 cd m−2. Most night-time outdoor and traffic lighting scenarios are in the mesopic range.|$|R
40|$|This paper {{describes}} {{a computer program}} for calculating the contrast image on the human retina from an array of scene <b>luminances.</b> We used achromatic transparency targets and measured test target's <b>luminances</b> with meters. We used the CIE standard Glare Spread Function (GSF) to calculate the array of retinal contrast. This paper describes the CIE standard, the calculation and the analysis techniques comparing the calculated retinal image with observer data. The paper also describes in detail the techniques of accurate measurements of HDR scenes, conversion of measurements to input data arrays, calculation of the retinal image, including open source MATLAB code, pseudocolor visualization of HDR images that exceed the range of standard displays, and comparison of observed sensations with retinal stimuli...|$|R
40|$|Limited {{research}} comparing participant {{ratings of}} luminous environments to ratings {{of images of}} those environments indicates that images can be a reasonable surrogate for the real space, particularly on ratings related to aesthetics. However, the realism of such images when presented on computer screens is potentially limited by conventional display technologies that cannot reproduce {{the full range of}} <b>luminances</b> in real spaces. In this pilot experiment we used a new, high dynamic range (HDR) computer monitor capable of producing screen <b>luminances</b> and contrasts comparable to those in a real space. Fifty-four participants viewed three images of a conventional office in two display modes: HDR monitor and conventional monitor. Participants rated each image for room appearance, environmental satisfaction and realism. These ratings were also compared to similar ratings made by participants in an earlier experiment (reported in 1998) who occupied the real spaces depicted in the images. Results indicate that computer screen images are perceived in a similar way as real luminous environments. HDR images are perceived differently than images on a conventional monitor: they are rated as brighter and less attractive, as expected. Given their more authentic <b>luminances,</b> HDR images should be perceived as more similar to the real space, but our results neither support nor refute this...|$|R
