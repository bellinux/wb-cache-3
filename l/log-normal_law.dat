11|19|Public
40|$|International audienceWe {{report on}} wind tunnel {{measurements}} of the saltation length in aeolian sand transport. Using both particle tracking techniques and innovative sand trap, {{we were able to}} extract key properties of the saltating particle trajectories. We find in particular that the distribution of the saltation length is almost invariant with the wind speed and exhibits a long-tail statistic that can be well approached by a <b>log-normal</b> <b>law.</b> This long-tail statistic is shown to be intimately connected to the collision process of the saltating particles onto the sand bed (the so-called "splash" process"). The velocity distribution of the resulting ejected particles is indeed shown to obey as well a <b>log-normal</b> <b>law.</b> As a conclusion, an accurate description of the saltating particle properties requires to go beyond the classical Gaussian approximation and account for the long tail statistics...|$|E
40|$|We {{study the}} pricing of options on {{realized}} variance {{in a general}} class of Log-OU stochastic volatility models. The class includes several important models proposed in the literature. Having as common feature the <b>log-normal</b> <b>law</b> of instantaneous variance, the application of standard Fourier-Laplace transform methods is not feasible. We derive extensions of Asian pricing methods, to obtain bounds, in particular, a very tight lower bound for options on realized variance...|$|E
40|$|We {{study the}} model of (2 + 1) -dimensional {{relativistic}} fermions in a random non-Abelian gauge potential at criticality. The exact solution shows that the operator expansion contains a conserved current - a generator of a continuous symmetry. The presence of this operator changes the operator product expansion and gives rise to logarithmic contributions to the correlation functions at the critical point. We calculate the distribution function of the local density of states in this model and find that it follows the famous <b>log-normal</b> <b>law.</b> Comment: 24 pages, LaTe...|$|E
40|$|International audienceWe {{study the}} {{dynamics}} of a nonlinear one-dimensional disordered system from a spectral point of view. The spectral entropy and the Lyapunov exponent are extracted from the short time dynamics, and shown to give a pertinent characterization of the different dynamical regimes. The chaotic and self-trapped regimes are governed by <b>log-normal</b> <b>laws</b> whose origin is traced to the exponential shape of the eigenstates of the linear problem. These quantities satisfy scaling laws depending on the initial state and explain the system behaviour at longer times...|$|R
3000|$|... {{in either}} un{{directed}} or directed graphs, the distribution is often Poisson, <b>log-normal,</b> power <b>law,</b> or double Pareto log-normal (Reed and Jorgensen 2004), {{some of which}} possess expectations such that [...]...|$|R
50|$|In general, {{processes}} {{characterized by}} Gibrat's law converge to a limiting distribution, {{which may be}} <b>log-normal</b> or power <b>law,</b> depending on more specific assumptions about the stochastic growth process.|$|R
40|$|In {{this paper}} we propose a “scaling-based” {{empirical}} approach to assess the scientific performance of heterogeneous academic disciplines. It relies on the idea that if we take into account for their two main sources of heterogeneity, the bibliometric distributions of different academic fields can be superimposed and collapse to a unique master curve by a single scaling parameter. By using data on the scientific production of around 2, 500 scholars of the university of Rome “La Sapienza” from the Web of Science (WoS) over 2004 – 2008 we i) demonstrate the existence of a master curve; ii) determine the scaling factors which are the cornerstone to compare different academic fields; and iii) show that the master bibliometric distribution follows a <b>Log-normal</b> <b>law...</b>|$|E
40|$|Magnetic and {{structural}} properties of magnetite nanoparticles stabilized in polyvinyl-alcohol thin films are investigated by using X-ray diffraction (XRD), {{transmission electron microscopy}} (TEM), electron paramagnetic resonance (EPR) and static magnetometry techniques. The nanoparticles have well-defined crystallinity, and are superparamagnetic at room temperature. Their size distribution {{is characterized by the}} distinct <b>log-normal</b> <b>law</b> (with average diameters near 5 - 7 nm) and slight maximum near 70 - 80 nm. The EPR spectra and static magnetization data demonstrated pronounced anomalies in the interval between 130 K (corresponding to Verwey transition) and 200 K. The experimental data obtained can be understood {{on the basis of the}} half-metallic electronic structure, complex temperature behavior of the magnetic anisotropy, along with effects of "weak magnetic-electron" sublattice of magnetite. Comment: 10 pages, pdf, Journal of Alloys and Compounds, accepte...|$|E
30|$|Moreover, we {{extracted}} {{the photographic}} {{activity at the}} local scale comparing attraction patterns for residents, domestic and foreign tourists within a city. Spatial distribution of photographic activity of all those user categories follows the same universal pattern - activity density distributions {{of all types of}} users follow <b>log-normal</b> <b>law</b> pretty well while the shapes of the curves for area size vs. activity quintile appear to be strongly consistent. However, the areas covered by tourist activities are always smaller compared to the areas covered by residents with the only exception of Los Angeles where domestic tourist activities cover larger areas compared to city residents. The ratio between areas covered by tourists and city residents is different for domestic and foreign tourists and is always higher for domestic tourists with only exception of Berlin where those factors are almost the same.|$|E
40|$|The Cauchy-Rayleigh (CR) {{distribution}} {{has been}} successfully used to describe asymmetric and heavy-tail events from radar imagery. Employing such model to describe lifetime data may then seem attractive, but some drawbacks arise: its probability density function does not cover non-modal behavior {{as well as the}} CR hazard rate function (hrf) assumes only one form. To outperform this difficulty, we introduce an extended CR model, called exponentiated Cauchy-Rayleigh (ECR) distribution. This model has two parameters and hrf with decreasing, decreasing-increasing-decreasing and upside-down bathtub forms. In this paper, several closed-form mathematical expressions for the ECR model are proposed: median, mode, probability weighted, log-, incomplete and order statistic moments and Fisher information matrix. We propose three estimation procedures for the ECR parameters: maximum likelihood (ML), bias corrected ML and percentile-based methods. A simulation study is done to assess the performance of estimators. An application to survival time of heart problem patients illustrates the usefulness of the ECR model. Results point out that the ECR distribution may outperform classical lifetime models, such as the gamma, Birnbaun-Saunders, Weibull and <b>log-normal</b> <b>laws,</b> before heavy-tail data. Comment: 30 page...|$|R
40|$|International audienceWe {{propose a}} method to {{determine}} the active particle distribution of nucleation undercooling in a refined alloy. The experimental data used in this work are inferred from solidification experiments on a refined Al- 3. 5 wt% Ni alloy performed with X-ray radiography at the European Synchrotron Radiation Facility. These in situ and real time observations allow the accurate and direct determination of the grain origin (heterogeneous nucleation on particles or fragmentation), of the density and of the equiaxed front growth rate. The LGK classical dendrite growth model is {{used to evaluate the}} front undercooling (ΔTC) corresponding to the measured equiaxed front growth rate. Then, the corresponding cumulative distribution of active refining particles is determined. From this cumulative distribution, we derive the corresponding Gaussian and <b>log-normal</b> <b>laws</b> to obtain the nucleation undercooling distribution of active particles. Results are discussed and compared to available measurements in the literature. The standard particle distribution parameters (density of nuclei, mean nucleation undercooling and standard deviation) are determined. We plan to use the determined nucleation undercooling particle distribution in a stochastic CAFE model for the grain structure without preliminary adjustment of the nucleation undercooling...|$|R
40|$|In sensory {{psychophysics}} {{reaction time}} {{is a measure of}} the stochastic latency elapsed from stimulus presentation until a sensory response occurs as soon as possible. A random multiplicative model of reaction time variability is investigated for generating the reaction time probability density functions. The model describes a generic class of hyperbolic functions by Piéron’s law. The results demonstrate that reaction time distributions are the combination of <b>log-normal</b> with power <b>law</b> density functions. A transition from <b>log-normal</b> to power <b>law</b> behavior is found and depends on the transfer of information in neurons. The conditions to obtain Zipf’s law are analyzed. I thank Dr. Jose A. Diaz (University of Granada, Spain) for helping me clarify the text and the discussion of the issues. This work was supported by the Fundacao para a Ciencia e a Tecnologia and by the Center for Physics, University of Minho, Portugal...|$|R
40|$|In {{the present}} paper we {{construct}} stock price processes with the same marginal <b>log-normal</b> <b>law</b> {{as that of a}} geometric Brownian motion and also with the same transition density (and returns' distributions) between any two instants in a given discrete-time grid. We then illustrate how option prices based on such processes differ from Black and Scholes', in that option prices can be either arbitrarily close to the option intrinsic value or arbitrarily close to the underlying stock price. We also explain that {{this is due to the}} particular way one models the stock-price process in between the grid time instants which are relevant for trading. The theoretical result concerning scalar stochastic differential equations with prescribed diffusion coefficient whose densities evolve in a prescribed exponential family, on which part of the paper is based, is presented in detail. ...|$|E
40|$|We perform {{population}} synthesis {{studies of}} different types of neutron stars (thermally emitting isolated neutron stars, normal radio pulsars, magnetars) taking into account the magnetic field decay and using results from the most recent advances in neutron star cooling theory. For the first time, we confront our results with observations using simultaneously the Log N [...] Log S distribution for nearby isolated neutron stars, the Log N [...] Log L distribution for magnetars, and the distribution of radio pulsars in the P [...] Ṗ diagram. For this purpose, we fix a baseline neutron star model (all microphysics input), and other relevant parameters to standard values (velocity distribution, mass spectrum, birth rates [...] .), allowing to vary the initial magnetic field strength. We find that our theoretical model is consistent with all sets of data if the initial magnetic field distribution function follows a <b>log-normal</b> <b>law</b> with ∼ 13. 25 and σ_ B_ 0 ∼ 0. 6. The typical scenario includes about 10...|$|E
40|$|The {{frequency}} {{distributions of}} elements in rocks and ore deposits do {{not conform to}} a universal scaling law, but vary in dependence of the mechanism of element enrichment. In the present contribution a dynamic model is proposed that describes element enrichments taking place by metasomatic processes causing the formation of hydrothermal ore deposits. It is shown that metasomatic element enrichment can result in a fractal distribution of element abundance data in the low concentration region with a smooth truncation at higher concentration values due to the existence of physical upper concentration limits imposed by the mineralogical nature of the ore. The developed model is tested on the basis of base and precious metal concentration data determined on diamond drill core samples collected from the Waterloo massive sulfide deposit, Australia. It is shown that the frequency distributions of Zn, Pb, Cu, and Ag conform relatively well to truncated power–law relationships as predicted by the model. In contrast, the frequency distribution of the Au data was found to be better described by the <b>log-normal</b> <b>law,</b> presumably due to syn-genetic processes of element redistribution that have not been modeled by the proposed dynamic model...|$|E
40|$|Abstract. The {{luminosity}} function (LF) of the Pleiades cluster stars {{was constructed}} {{for the study}} of the LF fine structure related to pre-MS stellar evolution. Theoretical luminosity functions based on present-day pre-MS and MS stellar models were constructed and compared with observations. We tested both power- and <b>log-normal</b> <b>laws</b> describing the cluster star IMF. Both single star formation burst- and age spread-models were examined. The agreement between the observed Pleiades CMD with the new HIPPARCOS distance and the theoretical ZAMS for a normal metallicity is excellent when the model positions in the HRD are corrected to the helium abundance Y= 0. 34. The corresponding age of the cluster is log t = 7. 95. Three features (dips) were found in the observed cluster LF in a magnitude range MV = 5 m – 12 m. Two of them (at MV = 7. 5 m and 9. 5 m) are assumed to be field LF features: Wielen and Kroupa dips. Theoretical models fail to reproduce them. We attributed the third (brightest) detail (the dip at MV = 5. 5 m) to the pre-MS evolution of Pleiades stars. The observed Pleiades LF corresponds in its brighter part to the standard Population I IMF. The log-normal IMF fits the observations much better than a simple power-law IMF. The brightest LF feature could be reproduced in the theoretical LF if a substantial age spread of order of several tens of Myrs is supposed to exist among the Pleiades stars. Key words: open clusters and associations: individual: Pleiade...|$|R
40|$|In {{this report}} we study the {{dynamics}} characteristics of conversations among several participants, analyzing trunked mobile telephony databases. We {{find that the}} duration of the dialogue sessions deviates systematically from the predictions of Poisson statistics, following probability distributions with either <b>log-normal</b> or power <b>law</b> tail. We propose that such a behavior can be described using the Bouchaud-Mezard (B-M) stochastic model, which suggests that the two probability distributions correspond to different types of human networking in conversations. We discuss the implications of our results in risk assessment in communications. (C) 2009 Elsevier B. V. All rights reserved...|$|R
40|$|In this paper, {{the minimal}} base-station density for a code-division multiple-access (CDMA) {{cellular}} radio network is determined {{such that the}} outage probability does not exceed a certain threshold. Base stations {{are assumed to be}} located on a regular triangular grid of minimum distance d, while mobiles are randomly distributed according to a two-dimensional Poisson point pattern. Each mobile may be connected to, at most, one of four surrounding base stations, effectively connecting and applying power control to the one with least attenuation. Thus, we model the use of macroscopic selection diversity. We obtain a normal approximation to the total interference power at a reference base station for a correlated <b>log-normal</b> shadowing <b>law.</b> The base station distance we obtain is proportional to the inverse of the square root of the traffic intensity, and we obtain the constant of proportionality, which is itself a function of the minimum acceptable carrier-to-interference (C/I) ratio and the maximum tolerable outage probability. Our formula for this distance can be used in network planning and design. 8 page(s...|$|R
40|$|This {{contribution}} aims at {{studying the}} behaviour {{of the classical}} sample moment estimator, S(n,q) = ∑_k= 1 ^n X_k^q/n, {{as a function of}} the number of available samples n, in the case where the random variables X are positive, have finite moments at all orders and are naturally of the form X= Y with the tail of Y behaving like e^-y^ρ. This class of laws encompasses and generalizes the classical example of the <b>log-normal</b> <b>law.</b> This form is motivated by a number of applications stemming from modern statistical physics or multifractal analysis. Borrowing heuristic and analytical results from the analysis of the Random Energy Model in statistical physics, a critical moment q_c(n) is defined as the largest statistical order q up to which the sample mean estimator S(n,q) correctly accounts for the ensemble average X^q, for a given n. A practical estimator for the critical moment q_c(n) is then proposed. Its statistical performance are studied analytically and illustrated numerically in the case of i. i. d. samples. A simple modification is proposed to explicitly account for correlation amongst the observed samples. Estimation performance are then carefully evaluated by means of Monte-Carlo simulations in the practical case of correlated time series. Comment: 34 pages, 17 figures, submitted to Signal Processin...|$|E
40|$|On a stepped {{spillway}} at large flows, the waters skim over the pseudo-bottom {{formed by the}} step edges with very strong recirculation vortices in the step cavities. The effects of step roughness on the flow properties are little known despite the practical relevance : e. g., gabion stepped chutes, unprotected roller compacted concrete spillways, damaged concrete steps on older structures. In the present study, the effect of step roughness was investigated systematically in {{a new series of}} experiments. The work was performed in a large size laboratory facility, with step height of 0. 10 m, step length of 0. 25 m and chute width of 1 m, based upon an undistorted Froude similitude. Four configurations were thoroughly tested with identical flow conditions : a smooth stepped chute, and three configurations with rough step faces. The latters were achieved by placing rough screens on the step faces : i. e., on the vertical faces only (Config. B), on the horizontal step faces only (Config. C) and on both vertical and horizontal step faces (Config. A). Detailed air-water flow measurements were performed with a dual-tip phase detection probe (sensor size: 0. 025 mm). Basic results included the vertical distributions of air concentration, bubble count rate, air-water velocity, turbulence level, and the air and water chord size distributions at each sampling point. The results showed some similarities between all four stepped configurations. Three basic flow regimes were observed, and the flow conditions at the change from one flow regime to another were identical for all four geometries. In skimming flows, visual observations showed that the step roughness affected the recirculation patterns in the step cavities. For the roughest configuration A, clear-water recirculation regions were observed downstream of the inception point of air entrainment. Seepage was also observed through the rough screens. At a macroscopic level, the effects of step roughness were two-fold. The location of the inception point of free-surface aeration was further downstream than for a smooth stepped chute for an identical flow rate. In turn the residual energy at the downstream end of the chute was greater on the rough stepped chute. At a microscopic level, the experimental results showed consistently several trends. The void fraction distribution results were very close for all stepped configurations, although there seemed to be slightly less entrained air in the rough stepped chute flows. Bubble count rate distributions indicated systematically lesser bubble count rates in the rough stepped chute flows. At step edges, the rough stepped chute flows were faster than smooth chute flows for a given flow rate and dimensionless location from the inception point of free-surface aeration. This was associated with lower turbulence intensities in rough stepped channel flows. A detailed analysis of air and water chord size distributions showed that, at each sampling location, the distributions of air and water chords were broad and spanned over two to three orders of magnitude. In the bubbly flow region (C < 0. 3), the probability distribution functions of air chord sizes followed closely a <b>log-normal</b> <b>law</b> for all investigated configurations and flow conditions...|$|E
40|$|Martian craters in {{the size}} range 10 - 250 km follow a <b>log-normal</b> size-frequency {{distribution}} <b>law.</b> Analysis techniques based on the log-normal model yield possible evidence for the size-frequency evolution of crater-producing bodies. Some regions on Mars display excessive depletions of either large or small craters; the most likely causes of the depletions are considered. Apparently, eolian sedimentation has markedly altered the population of small craters south of - 30 deg latitude. The general effects of crater obliteration in the Southern Hemisphere appear to be confined to diameters of less than 20 km. A strong depletion of large craters in a large region centered at 35 deg latitude and 10 deg W longitude may indicate locations of subsurface ice...|$|R
50|$|Gibrat's law (sometimes called Gibrat's rule of {{proportionate}} {{growth or}} {{the law of}} proportionate effect) is a rule defined by Robert Gibrat (1904-1980) in 1931 stating that the proportional {{rate of growth of}} a firm is independent of its absolute size. The law of proportionate growth gives rise to a distribution that is <b>log-normal.</b> Gibrat's <b>law</b> is also applied to cities size and growth rate, where proportionate growth process may give rise to a distribution of city sizes that is log-normal, as predicted by Gibrat's law. While the city size distribution is often associated with Zipf's law, this holds only in the upper tail, because empirically the tail of a log-normal distribution cannot be distinguished from Zipf's law. A study using administrative boundaries (places) to define cities finds that the entire distribution of cities, not just the largest ones, is log-normal. But this last claim that the lognormal distribution cannot be rejected {{has been shown to be}} the result of a statistics with little power: the uniformly most powerful unbiased test comparing the lognormal to the power law shows unambiguously that the largest 1000 cities are distinctly in the power law regime.|$|R
40|$|Using Monte Carlo simulations, we {{model the}} {{luminosity}} distribution of recycled pulsars in globular clusters as the brighter, observable {{part of an}} intrinsic distribution and find that the observed luminosities can be reproduced using either log-normal or power-law distributions as the underlying luminosity function. For both distributions, {{a wide range of}} model parameters provide an acceptable match to the observed sample, with the log-normal function providing statistically better agreement in general than the power-law models. Moreover, the power-law models predict a parent population size that is a factor of between two and ten times higher than for the log-normal models. We note that the log-normal luminosity distribution found for the normal pulsar population by Faucher-Giguère and Kaspi is consistent with the observed luminosities of globular cluster pulsars. For Terzan 5, our simulations show that the sample of detectable radio pulsars, and the diffuse radio flux measurement, can be explained using the <b>log-normal</b> luminosity <b>law</b> with a parent population of ∼ 150 pulsars. Measurements of diffuse gamma-ray fluxes for several clusters can be explained by both power-law and log-normal models, with the log-normal distributions again providing a better match in general. In contrast to previous studies, we do not find any strong evidence for a correlation between the number of pulsars inferred in globular clusters and globular cluster parameters including metallicity and stellar encounter rate. Comment: Accepted for publication in MNRAS; 14 pages, 10 figures and 5 table...|$|R
40|$|Citation {{distributions}} {{are crucial}} for the analysis and modeling of the activity of scientists. We investigated bibliometric data of papers published in journals of the American Physical Society, searching {{for the type of}} function which best describes the observed citation distributions. We used the goodness of fit with Kolmogorov-Smirnov statistics for three classes of functions: <b>log-normal,</b> simple power <b>law</b> and shifted power law. The shifted power law {{turns out to be the}} most reliable hypothesis for all citation networks we derived, which correspond to different time spans. We find that citation dynamics is characterized by bursts, usually occurring within a few years since publication of a paper, and the burst size spans several orders of magnitude. We also investigated the microscopic mechanisms for the evolution of citation networks, by proposing a linear preferential attachment with time dependent initial attractiveness. The model successfully reproduces the empirical citation distributions and accounts for the presence of citation bursts as well. Comment: 8 pages, 5 figure...|$|R
30|$|The {{distribution}} is heavy tailed {{which is an}} important factor behind the efficiency of the crowd to cope with errors. We fit a power <b>law,</b> <b>log-normal</b> and exponential models to the data following the procedure of [68], and compare them using the Vuong test [69]. The Vuong test is a likelihood ratio test able to discriminate which of two models better fits the data and is able to tell whether it can confidently do so. While close fits do not provide a proof that the data follow the best model, they nevertheless pose a basis for studying the generating process. The log-normal model is the most supported one, with a high test statistic and p-value close to zero, indicating that it is a better fit than the power law. The fitted model has a location (i.e. mean in a logarithmic scale) of 6.89 and a shape (i.e. standard deviation in logarithmic scale) of 1.92. This distribution has a mode of 24  s but is heavily skewed with a median of 27 min and a mean of 1.75 hours.|$|R
40|$|Power laws arise {{through many}} natural processes. Zipf {{showed that the}} {{frequencies}} of words, as they appear in Shakespeare’s Hamlet, follow a power law distribution. Mandelbrot explained this effect {{as a result of}} an underlying information-theoretic optimization problem. Miller invoked doubt by showing that a very simple mechanism could also explain the presence of power laws: A monkey typing words with uniformly and independently selected letters would also produce word frequencies following a power law. In consequence, several other researchers proposed and investigated rankfrequency distributions of randomly generated text. In this paper, we first present a literature overview over this exciting topic. We then propose a class of Hidden Markov Models (HMMs) which generalizes the models previously investigated, generating power <b>law,</b> <b>log-normal</b> and other behavior. We extend a result of Conrad and Mitzenmacher for computing the power law exponent of zero order Markov processes to a setting which captures random walks in d-regular graphs. In an extensive empirical evaluation, we investigate convergence of rank frequency distributions for randomly generated text to those of natural language corpora, for increasing orders of Markov Processes and HMMs with an increasing number of hidden states. Our analysis uses four real-world corpora: the Reuter...|$|R
40|$|Two {{models of}} binary {{fragmentation}} are introduced {{in which a}} time dependent transition size produces two regions of fragment sizes {{above and below the}} transition size. In the models we consider a fixed rate of fragmentation for the largest fragment and two different rates of fragmentation for the two regions of sizes above and below the transition size. The models are solved exactly in the long time limit to reveal stable time-invariant solutions for the fragment size distributions. A rate of fragmentation proportional to the inverse of fragment size in the smaller size region produces a power law distribution in that region. A rate of fragmentation combined of two terms, one proportional to the inverse of the fragment size and the other proportional to a logarithmic function of the fragment size, in the larger size region produces a log-normal distribution in that region. Special cases of the models with no fragmentation for the smaller fragments are also considered. The similarities between the stable distributions in our models and power <b>law</b> <b>log-normal</b> distributions from experimental work on shock fragmentation of long thin glass rods and rupture of mercury droplets are investigated. Comment: 22 pages, no figure...|$|R
40|$|We {{investigate}} {{the role of}} pressure solution in deformation of upper- to mid-crustal rocks using aggregates of halite as a room temperature analog for fluid-assisted deformation processes in the Earth's crust. Experiments evaluate the effects of initial grain size distribution on macroscopic pressure solution rate of the aggregate and compare the results to theoretical models for pressure solution. We find that the grain size exponent deviates significantly from the theoretical value of 3 for diffusion-controlled pressure solution. Models typically assume mono-dispersed spherical particles in pseudo-regular packing. We infer that the discrepancy between experimentally determined grain size exponents and the theoretical values {{are a result of}} deviation of experimental (and natural) samples from regular packs of mono-dispersed spherical particles. Moreover, we find that compaction rates can vary by up to one order of magnitude {{as a function of the}} width of the grain size distribution for a given mean grain size. Wider size distributions allow for higher initial compaction rates, increasing the macroscopic compaction rate with respect to more narrow grain size distributions. Grain sizes in rocks, fault gouges, and hydrocarbon reservoirs are typically <b>log-normal</b> or power <b>law</b> distributed and therefore pressure solution rates may significantly exceed theoretical predictions. Spatiotemporal variations in pressure solution rates due to variations in grain size may cause the formation of low porosity zones, which could potentially focus deformation in these zones and produce pockets of high pore pressures, promoting nucleation of frictional instability and earthquake rupture...|$|R
40|$|Several {{types of}} extra-galactic high-energy {{transients}} have been discovered, which include high-luminosity and low-luminosity long-duration gamma-ray bursts (GRBs), short-duration GRBs, supernova shock breakouts (SBOs), and tidal disruption events (TDEs) without or with an associated relativistic jet. In this paper, we apply a unified method to systematically study the redshift-dependent event rate densities {{and the global}} luminosity functions (ignoring redshift evolution) of these transients. We introduce some empirical formulae for the redshift-dependent event rate densities for different types of transients, and derive the local specific event rate density, which also represents its global luminosity function. Long GRBs have a large enough sample to reveal features in the global luminosity function, which is best characterized as a triple power law. All the other transients are consistent with having a single power law luminosity function. The total event rate density depends on the minimum luminosity, and we obtain the following values in units of Gpc^- 3 yr^- 1 : 0. 8 ^+ 0. 1 _- 0. 1 for high-luminosity long GRBs above 10 ^ 50 erg s^- 1, 164 ^+ 98 _- 65 for low-luminosity long GRBs above 5 × 10 ^ 46 erg s^- 1, 1. 3 ^+ 0. 4 _- 0. 3, 1. 2 ^+ 0. 4 _- 0. 3, and 3. 3 ^+ 1. 0 _- 0. 8 above 10 ^ 50 erg s^- 1 for short GRBs with three different merger delay models (Gaussian, <b>log-normal,</b> and power <b>law),</b> 1. 9 ^+ 2. 4 _- 1. 2 × 10 ^ 4 above 10 ^ 44 erg s^- 1 for SBOs, 4. 8 ^+ 3. 2 _- 2. 1 × 10 ^ 2 for normal TDEs above 10 ^ 44 erg s^- 1, and 0. 03 ^+ 0. 04 _- 0. 02 above 10 ^ 48 erg s^- 1 for TDE jets as discovered by Swift. Intriguingly, the global luminosity functions {{of different kinds of}} transients, which cover over 12 orders of magnitude, are consistent with a single power law with an index of - 1. 6. Comment: 35 pages, 12 figures, accepted to Ap...|$|R

