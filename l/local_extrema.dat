547|36|Public
2500|$|The {{constrained}} extrema of [...] {{are critical}} {{points of the}} Lagrangian , {{but they are not}} necessarily <b>local</b> <b>extrema</b> of [...] (see Example 2 below).|$|E
5000|$|... non-creation of <b>local</b> <b>extrema</b> (zero-crossings) in one {{dimension}} ...|$|E
5000|$|Perform {{polynomial}} interpolation and re-estimate {{positions of}} the <b>local</b> <b>extrema.</b>|$|E
40|$|Existing {{methods for}} bar code signal {{reconstruction}} {{is based on}} either the local approach or the regularization approach with total variation penalty. We formulate the problem explicitly in terms of change points of the 0 - 1 step function. The bar code is then reconstructed by solving the nonlinear least squares problem subject to linear inequality constraints, with starting values provided by the <b>local</b> <b>extremas</b> of the derivative of the convolved signal from discrete noisy data. Simulation results show a considerable improvement {{of the quality of}} the bar code signal using the proposed hybrid approach over the local approach. EDICS Category:IMD-ANAL, SAS-SYST I...|$|R
30|$|The {{works of}} [12, 13, 14] {{demonstrated}} that hybridized schemes perform {{better than the}} existing schemes by taking advantages of each of their components. For example, the authors in [15, 16, 17] proposed the use of limiters in conjunction with ENO reconstructions. The numerical experiments described in those works show that the modified scheme reduced smearing near discontinuities and gave good resolutions of corners and <b>local</b> <b>extremas.</b> Furthermore, different ENO-type methods have been extended to multi-dimensional problems, see for example [15, 18, 19, 20, 21], and Serna and Marquina [15] noted that some ENO methods combined with limiters performed better than conventional ENO methods of similar order for multi-dimensional problems where fine structures appear to be important.|$|R
40|$|A global {{optimal control}} {{algorithm}} is developed {{and applied to}} an omni-directional mobile robot model. The aim is to search and find the most intense signal source among other signal sources in the operation region of the robot. In other words, the control problem {{is to find the}} global extremum point when there are <b>local</b> <b>extremas.</b> The locations of the signal sources are unknown and it is assumed that the signal magnitudes are maximum at the sources and their magnitudes are decreasing away from the sources. The distribution characteristics of the signals are unknown, i. e. the gradients of the signal distribution functions are unknown. The control algorithm also doesn't need any position measurement of the robot itself. Only the signal magnitude should be measured via a sensor mounted on the robot. The simulation study shows the performance of the controller. Publisher's Versio...|$|R
5000|$|... #Caption: A graph {{in which}} <b>local</b> <b>extrema</b> and global extrema have been labeled.|$|E
50|$|The {{interest}} of this {{notion lies in}} the fact that the points where the function has <b>local</b> <b>extrema</b> are critical points.|$|E
5000|$|The {{constrained}} extrema of [...] {{are critical}} {{points of the}} Lagrangian , {{but they are not}} necessarily <b>local</b> <b>extrema</b> of [...] (see Example 2 below).|$|E
40|$|Reconstruction of a bilevel {{function}} {{such as a}} {{bar code}} signal in a partially blind deconvolution problem is an important task in industrial processes. Existing methods are based on either the local approach or the regularization approach with a total variation penalty. This article reformulated the problem explicitly in terms of change points of the 0 - 1 step function. The bilevel function is then reconstructed by solving the nonlinear least squares problem subject to linear inequality constraints, with starting values provided by the <b>local</b> <b>extremas</b> of the derivative of the convolved signal from discrete noisy data. Simulation results show a considerable improvement {{of the quality of}} the bilevel function using the proposed hybrid approach over the local approach. The hybrid approach extends the workable range of the standard deviation of the Gaussian kernel significantly. Key words: Bar code, 0 - 1 step function, nonlinear least squares, constrained optimizatio...|$|R
40|$|Manual {{fingerprint}} classification proceeds {{by carefully}} inspecting the geometric characteristics of major ridge curves in a fingerprint image. We propose an automatic approach of identifying the geometric characteristics of ridges based on curves {{generated by the}} orientation field called orientation field flow curves (OFFCs). The geometric characteristics of OFFCs are analyzed by studying the isometric maps of tangent planes as a point traverses along the curve {{from one end to}} the other. The path traced by the isometric map consists of several important features such as sign change points and locations as well as values of <b>local</b> <b>extremas,</b> that uniquely identify the inherent geometric characteristics of each OFFC. Moreover, these features are invariant under changes of location, rotation and scaling of the fingerprint. We have applied our procedure on the NIST 4 database consisting of 4, 000 fingerprint images without any training. Classification into four major fingerprint classes (arch, left-loop, right-loop and whorl) with no reject options yields an accuracy of 94. 4. % 1...|$|R
40|$|In this paper, {{we propose}} a {{technique}} for segmenting visual textures using features {{extracted from the}} reponses of Ga,bor filters, appropria. tely selec tecl to be tuned to texture components of the input image. In the proposed method segmentation is achieved by detecting boundaries between adjacent textured regions, and this segmentation algorithm works as follows. The input image is first filtered using a small set of Gabor filters, each tuned {{to one of the}} textures composing the original image. Abrupt changes in the obtained Gabor filter output images are found by detecting the underlying <b>local</b> <b>extremas.</b> For this purpose, a gradient operator is applied to output ima. ge of each Gabor filter, yielding a. set of gradient images. The textcrre gradient is sul>sequently obtained by grouping gradient images from all channels. Thresholding the texture gradient and thinning the result yields the expected texture boundaries. Experimental results on synthetic and natural textures, demonstrate the efficacy of the proposed technique. ...|$|R
5000|$|In {{order to}} {{maximize}} the expression above we apply Fermat's theorem (stationary points), according to which <b>local</b> <b>extrema,</b> if exist, must be at critical points (partial derivatives vanish): ...|$|E
5000|$|At each scale, {{interest}} {{points are}} those points that simultaneously are <b>local</b> <b>extrema</b> {{of both the}} determinant and trace of the Hessian matrix. The trace of Hessian matrix {{is identical to the}} Laplacian of Gaussians (LoG): ...|$|E
50|$|All {{conditions}} for the Parks-McClellan algorithm are based on Chebyshev's alternation theorem. The alternation theorem states that the polynomial of degree L that minimizes the maximum error will have at least L+2 extrema. The optimal frequency response will barely reach the maximum ripple bounds. The extrema must occur at the pass and stop band edges and at either ω=0 or ω=π or both. The derivative of a polynomial of degree L is a polynomial of degree L-1, which can be zero at most at L-1 places. So {{the maximum number of}} <b>local</b> <b>extrema</b> is the L-1 <b>local</b> <b>extrema</b> plus the 4 band edges, giving a total of L+3 extrema.|$|E
40|$|Detailed {{experimental}} {{surface pressure}} coefficient measurements, obtained for a hemisphere-cylinder-flare model {{in a low}} supersonic flow (freestream M = 1. 2) at various angles of attack (0 deg to 27. 5 deg), have been analyzed. The pressure values for each angle of attack were smoothed and checked against their respective oil-flow photographs. The smoothed results were then used to validate a theory which relates the number and type of singular points observed in the oil-flow patterns with <b>local</b> surface-pressure <b>extrema...</b>|$|R
30|$|The {{concepts}} of LQP [40] and DLEP [35] have motivated us to propose the <b>local</b> quantized <b>extrema</b> patterns (LQEP) for image retrieval application. The main contributions {{of this work}} are summarized as follows. (a) The proposed method collects the directional quantized extrema information from the query/database image by integrating the {{concepts of}} LQP and DLEP. (b) To improve {{the performance of the}} CBIR system, the LQEP operator combines with RGB color histogram. (c) The performance of the proposed method is tested on benchmark databases for natural and texture image retrieval.|$|R
40|$|International audienceWe {{introduce}} the N-buffer {{as a tool}} for multiresolution depth map representation. This neighborhood buffer encodes the value and position of <b>local</b> depth <b>extrema</b> at different scales in an image cube, in contrast to the image pyramid. The resulting increase in storage space is largely compensated by the following benefits: objects of any size can be culled in constant time against an occlusion map using four depth lookups; visibility-like queries can be performed in vertex and fragment programs; N-buffers can be computed very efficiently with graphics hardware. We present three applications of this datastructure, and in particular a novel approach for shadow volume acceleration...|$|R
5000|$|The {{statement}} {{can also}} be extended to differentiable manifolds. If [...] is a differentiable function on a manifold , then its <b>local</b> <b>extrema</b> must be critical points of , in particular points where the exterior derivative [...] is zero.|$|E
50|$|For a {{continuous}} function {{on the real}} line, one branch is required between each pair of <b>local</b> <b>extrema.</b> For example, the inverse of a cubic function with a local maximum and a local minimum has three branches (see the adjacent picture).|$|E
50|$|For {{the purpose}} of {{detecting}} grey-level blobs (<b>local</b> <b>extrema</b> with extent) from a watershed analogy,Lindeberg developed an algorithm based on pre-sorting the pixels,alternatively connected regions having the same intensity, indecreasing order of the intensity values.Then, comparisons were made between nearest neighbours of either pixels or connected regions.|$|E
40|$|Variational {{calculus}} is used {{to determine}} the design that maximizes the resistance of classical symmetric laminates against buckling. The orientations of the constituent orthotropic laminae with respect to the principal axes of the laminate are the design variables. It is shown that the optimal design may not be a point of analyticity of the buckling load. <b>Local</b> analytic <b>extrema</b> are obtained from the design derivatives of the buckling load. Nonanalytic extrema occur whenever the buckling load is a repeated eigenvalue. A novel approach, using a directional design derivative, is employed to determine nonanalytic extrema. Specific examples are presented for biaxial buckling for several different boundary conditions...|$|R
40|$|We used density {{functional}} and many-body perturbation theory {{to calculate the}} quasiparticle band structures and electronic transport parameters of p-type SnSe both for the low-temperature Pnma and high-temperature Cmcm phases. The Pnma phase has an indirect band gap of 0. 829 eV while the Cmcm has a direct band gap of 0. 464 eV. Both phases exhibit multiple <b>local</b> band <b>extrema</b> within an energy range comparable to the thermal energy of carriers from the global extrema. We calculated the electronic transport coefficients for single-crystal and polycrystalline materials to understand previous experimental measurements. We also discuss the dependence of the transport coefficients on doping concentration and temperature to identify doping conditions for optimal thermoelectric performance...|$|R
40|$|We {{propose a}} novel method for the {{refinement}} of Maximally Stable Extremal Region (MSER) boundaries to sub-pixel precision by {{taking into account}} the intensity function in the 2 × 2 neighborhood of the contour points. The proposed method improves the repeatability and precision of Local Affine Frames (LAFs) constructed on extremal regions. Additionally, we propose a novel method for detection of <b>local</b> curvature <b>extrema</b> on the refined contour. Experimental evaluation on publicly available datasets shows that matching with the modified LAFs leads to a higher number of correspondences and a higher inlier ratio in more than 80 % of the test image pairs. Since the processing time of the contour refinement is negligible, there is no reason not to include the algorithms as a standard part of the MSER detector and LAF constructions...|$|R
5000|$|For {{one-dimensional}} signals, {{there exists}} quite a well-developed theory for continuous and discrete kernels that guarantee that new <b>local</b> <b>extrema</b> or zero-crossings cannot {{be created by}} a convolution operation. For continuous signals, it holds that all scale-space kernels can be decomposed into the following sets of primitive smoothing kernels: ...|$|E
5000|$|The {{conclusion}} {{from several}} different axiomatic derivations {{that have been}} presented is that the Gaussian scale space constitutes the canonical way to generate a linear scale space, based on the essential requirement that new structures must not be created when going from a fine scale to any coarser scale.Conditions, referred to as scale-space axioms, {{that have been used}} for deriving the uniqueness of the Gaussian kernel include linearity, shift invariance, semi-group structure, non-enhancement of <b>local</b> <b>extrema,</b> scale invariance and rotational invariance.In the works, the uniqueness claimed in the arguments based on scale invariance originally due to Iijima (1962) has been criticized, and alternative self-similar scale-space kernels have been proposed. The Gaussian kernel is, however, a unique choice according to the scale-space axiomatics based on causality [...] or non-enhancement of <b>local</b> <b>extrema.</b>|$|E
50|$|<b>Local</b> <b>extrema</b> of {{differentiable}} functions can {{be found}} by Fermat's theorem, which states that they must occur at critical points. One can distinguish whether a critical point is a local maximum or local minimum by using the first derivative test, second derivative test, or higher-order derivative test, given sufficient differentiability.|$|E
50|$|In {{mathematical}} analysis, the maxima and minima (the respective plurals {{of maximum}} and minimum) of a function, known collectively as extrema (the plural of extremum), {{are the largest}} and smallest value of the function, either within a given range (the <b>local</b> or relative <b>extrema)</b> or on the entire domain of a function (the global or absolute extrema). Pierre de Fermat {{was one of the}} first mathematicians to propose a general technique, adequality, for finding the maxima and minima of functions.|$|R
5000|$|Ideally, h1 should {{satisfy the}} {{definition}} of an IMF, since the construction of h1 described above should have made it symmetric and having all maxima positive and all minima negative. After {{the first round of}} sifting, a crest may become a <b>local</b> maximum. New <b>extrema</b> generated in this way actually reveal the proper modes lost in the initial examination. In the subsequent sifting process, h1 can only be treated as a proto-IMF. In the next step, h1 is treated as data: ...|$|R
40|$|Abstract—We {{propose a}} novel method for the {{refinement}} of Maximally Stable Extremal Region (MSER) boundaries to sub-pixel precision by {{taking into account}} the intensity function in the 2 × 2 neighborhood of the contour points. The proposed method improves the repeatability and precision of Local Affine Frames (LAFs) constructed on extremal regions. Additionally, we propose a novel method for detection of <b>local</b> curvature <b>extrema</b> on the refined contour. Experimental evaluation on publicly available datasets shows that matching with the modified LAFs leads to a higher number of correspondences and a higher inlier ratio in more than 80 % of the test image pairs. Since the processing time of the contour refinement is negligible, there is no reason not to include the algorithms as a standard part of the MSER detector and LAF constructions. Keywords-discretized contour, contour refinement, curvature estimation, curvature extrema I...|$|R
50|$|In the ex-ante analysis, optimal {{portfolio}} problems {{based on}} the Rachev ratio are, generally, numerically hard to solve because the Rachev ratio is a fraction of two CVaRs which are convex functions of portfolio weights. In effect, the Rachev ratio, if viewed {{as a function of}} portfolio weights, may have many <b>local</b> <b>extrema.</b>|$|E
5000|$|A corner {{solution}} is an instance where the [...] "best" [...] solution (i.e. maximizing profit, or utility, or whatever value is sought) is achieved {{based not on}} the market-efficient maximization of related quantities, but rather based on brute-force boundary conditions. Such a solution lacks mathematical elegance, and most examples are characterized by externally forced conditions (such as [...] "variables x and y cannot be negative") that put the actual <b>local</b> <b>extrema</b> outside the permitted values.|$|E
50|$|There {{are many}} other multi-scale signal {{processing}}, image processing and data compression techniques, using wavelets {{and a variety of}} other kernels, that do not exploit or require the same requirements as scale space descriptions do; that is, they do not depend on a coarser scale not generating a new extremum that was not present at a finer scale (in 1D) or non-enhancement of <b>local</b> <b>extrema</b> between adjacent scale levels (in any number of dimensions).|$|E
40|$|Feature {{detection}} and matching {{is a fundamental}} problem in many applications in computer vision. We propose a novel approach that improves repeatability and precision of Local Affine Frames (LAFs) constructed on discretized contours detected by Maximally Stable Extremal Regions (MSERs) detector. Proposed method reconstructs a discretized contour of extremal region by {{taking into account the}} intensity function in local neighborhood of the contour points. Additionally we propose a new method for detection of <b>local</b> curvature <b>extrema,</b> based on the refined contour. The extensive experimental evaluation on publicly available datasets showed higher number of correspondences and higher inlier ratio in more than 80 % of the image pairs. Since the procesing time of the contour refinement is negligible, there is no reason not to include the proposed algorithms as a standard extension of MSER detector. Powered by TCPDF (www. tcpdf. org...|$|R
40|$|This paper {{presents}} a theoretical {{study of the}} disturbed isobaric surface shape in the geostrophic state of the atmosphere. It has been shown that, depending on the overheat sign at the equator, the isobaric surface has {{the shape of an}} oblate or prolate geoid. If the geostrophic wind velocity is nonzero at the poles, the <b>local</b> pressure <b>extrema</b> (minima for oblate geoid and maxima for prolate geoid) appear at the poles in the geostrophic state. This result correlates with the well-known polar vortex phenomenon and possibly can refine our understanding and interpretation of the phenomenon. In other words, the existence of polar minima and maxima of the pressure field can be the peculiarity of the geostrophic state of the atmosphere. It has been found that air must be colder than the surrounding atmosphere for initiation of the zonal eastward transport. For warm air mass, only easterly winds will be observed...|$|R
40|$|International audienceThis article {{presents}} a new algorithm for spatial deinterlacing {{that could easily}} be integrated in a more complete deinterlacing system, typically a spatio-temporal motion adaptive one. The spatial interpolation part often fails to reconstruct close to horizontal lines with a proper continuity, leading to highly visible artifacts. Our system preserves the structure continuity {{taking into account that}} the mis-interpolated points usually correspond to <b>local</b> value <b>extrema.</b> The processing is based on chained lists and connected graph construction. The new interpolation method is restricted to such structures, {{for the rest of the}} image, a proper traditional directional spatial interpolation gives satisfactory results already. Although the number of pixels affected by the extrema interpolation is relatively small, the overall image quality is subjectively well improved. Moreover, our solution allows to gain back one of the major advantages of motion compensation methods, without having to afford their complexity cost...|$|R
