14|3616|Public
50|$|Under {{the policy}} of {{priority}} inheritance, whenever a high priority task has to wait for some resource shared with an executing <b>low</b> <b>priority</b> <b>task,</b> the <b>low</b> <b>priority</b> <b>task</b> is temporarily assigned the priority of the highest waiting priority task {{for the duration of}} its own use of the shared resource, thus keeping medium priority tasks from pre-empting the (originally) <b>low</b> <b>priority</b> <b>task,</b> and thereby affecting the waiting high priority task as well. Once the resource is released, the <b>low</b> <b>priority</b> <b>task</b> continues at its original priority level.|$|E
50|$|Care must {{be taken}} not to inhibit {{preemption}} during this search. Longer critical sections should be divided into small pieces. If an interrupt occurs that makes a high priority task ready during the insertion of a <b>low</b> <b>priority</b> <b>task,</b> that high priority task can be inserted and run immediately before the <b>low</b> <b>priority</b> <b>task</b> is inserted.|$|E
50|$|For every {{specific}} project, requirements {{can vary}} significantly. For example, ROM and RAM footprints {{can be a}} very serious constraint and limit the choices of the system designer. C++ or JVM availability for the system can be another constraint. Frequently performance is an issue, because typical embedded systems run multiple simultaneous tasks and an HTTP server is only one of them and may be configured as a <b>low</b> <b>priority</b> <b>task.</b>|$|E
50|$|This {{violates the}} {{priority}} model that high <b>priority</b> <b>tasks</b> {{can only be}} prevented from running by higher <b>priority</b> <b>tasks</b> and briefly by <b>low</b> <b>priority</b> <b>tasks</b> which will quickly complete their use of a resource shared by the high and <b>low</b> <b>priority</b> <b>tasks.</b>|$|R
40|$|A common {{practice}} in system design is to treat features intended to enhance performance and reliability as <b>low</b> <b>priority</b> <b>tasks</b> by scheduling them during idle periods, with the goal to keep these features transparent to the user. In this paper, we present an algorithmic framework that determines the schedulability of non-preemptable <b>low</b> <b>priority</b> <b>tasks</b> in storage systems. The framework estimates when {{and for how long}} idle times can be utilized by <b>low</b> <b>priority</b> background <b>tasks,</b> without violating pre-defined performance targets of user foreground tasks. The estimation is based on monitored system information that includes the histogram of idle times. This histogram captures accurately important statistical characteristics of the complex demands of the foreground activity. The robustness and the effectiveness of the proposed framework is corroborated via extensive trace driven simulations under a wide range of system conditions and background activities, and via experimentation on a Linux kernel 2. 6. 22 prototype...|$|R
40|$|Fixed-priority {{scheduling}} with deferred preemption (FPDS) {{has been}} proposed in the literature as {{a viable alternative to}} fixed-priority preemptive scheduling (FPPS), that both reduces the cost of arbitrary preemptions and removes the need for non-trivial resource access protocols. This paper shows that existing worst-case response time analysis of hard real-time tasks under FPDS, arbitrary phasing and relative deadlines at most equal to periods is both pessimistic and optimistic. This paper provides a revised analysis, resolving the problems with the existing approaches. The analysis assumes a continuous scheduling model. It is shown that the critical instant, longest busy period, and worst-case response time for a task are suprema rather than maxima for all tasks, except for the <b>lowest</b> <b>priority</b> <b>task.</b> Moreover, it is shown that the analysis is not uniform for all tasks, i. e. the analysis for the <b>lowest</b> <b>priority</b> <b>task</b> differs from the analysis of the other tasks, because only the <b>lowest</b> <b>priority</b> <b>task</b> cannot be blocked. To build on earlier work, the worst-case response time analysis for FPDS is expressed in terms of known worst-case analysis results for FPPS. The paper includes pessimistic variants of the analysis, which are uniform for all tasks...|$|R
50|$|In {{priority}} inversion a {{high priority}} task waits because a <b>low</b> <b>priority</b> <b>task</b> has a semaphore, but the lower priority task is not given CPU time to finish its work. A typical solution {{is to have the}} task that owns a semaphore run at, or 'inherit,' the priority of the highest waiting task. But this simple approach fails when there are multiple levels of waiting: task A waits for a binary semaphore locked by task B, which waits for a binary semaphore locked by task C. Handling multiple levels of inheritance without introducing instability in cycles is complex and problematic.|$|E
5000|$|In some cases, {{priority}} inversion {{can occur}} without causing immediate harm—the delayed {{execution of the}} high priority task goes unnoticed, and eventually the <b>low</b> <b>priority</b> <b>task</b> releases the shared resource. However, there are also many situations in which priority inversion can cause serious problems. If the high priority task is left starved of the resources, it {{might lead to a}} system malfunction or the triggering of pre-defined corrective measures, such as a watchdog timer resetting the entire system. The trouble experienced by the Mars lander [...] "Mars Pathfinder" [...] {{is a classic example of}} problems caused by priority inversion in realtime systems.|$|E
40|$|In this paper, {{we present}} a new {{approach}} to synchronization in real-time systems. Existing methods for synchronization in real-time systems are pessimistic, and use blocking to enforce concurrency control. Protocols such as the priority ceiling protocol have been proposed to reduce the priority inversion that occurs when low priority tasks block high priority tasks. However, the priority ceiling protocol still allows a <b>low</b> <b>priority</b> <b>task</b> to block a high priority task, and requires the use of a static-priority scheduler. We propose optimistic synchronization methods as an alternative to pessimistic synchronization methods. Our synchronization algorithms never allow a <b>low</b> <b>priority</b> <b>task</b> to block a high priority task, and can be used with dynamic-priority schedulers. We show how the current research in non-blocking concurrent objects and in low-overhead uniprocessor synchronization can be synthesized to implement low-overhead optimistic synchronization. 1 Introduction The schedul [...] ...|$|E
5000|$|... {{workload}} debt - {{which is}} when an individual’s cognitive workload is too high to complete all relevant tasks in the time available and they decide (either consciously or subconsciously) to postpone one or more <b>tasks</b> (usually <b>low</b> <b>priority</b> <b>tasks)</b> {{to enable them to}} make the decision in the required timeframe.|$|R
40|$|We {{present a}} new {{approach}} to synchronization on uniprocessors with special applicability to embedded and realtime systems Existing methods for synchronization in realtime systems are pessimistic and use blocking to enforce concurrency control While protocols to bound the blocking of high <b>priority</b> <b>tasks</b> exist high <b>priority</b> <b>tasks</b> can still be blocked by <b>low</b> <b>priority</b> <b>tasks</b> In addition these protocols require a complex interaction with the scheduler We propose interruptible critical sections ie optimistic synchronization as an alternative to purely blocking methods Practical optimistic synchronization requires techniques for writing interruptible critical sections and system support for detecting critical section access conicts We discuss our implementation of an interruptible lock on a system running the pSOS real time operating system Our experimental performance results show that interruptible locks reduce the variance in the response time of the highest <b>priority</b> <b>task</b> with only a small impact on the performance of the <b>low</b> <b>priority</b> <b>tasks</b> We show how interruptible critical sections can be combined with the Priority Ceiling Protocol and present an analysis which shows that interruptible locks improve the schedulability of task sets that have high <b>priority</b> <b>tasks</b> with tight deadline...|$|R
40|$|Multi-core CPUs {{have become}} the {{standard}} in embedded real-time systems. In such systems, where several tasks run simultaneously, developers can no longer rely on high <b>priority</b> <b>tasks</b> blocking <b>low</b> <b>priority</b> <b>tasks.</b> In typical control systems, <b>low</b> <b>priority</b> <b>tasks</b> are dedicated to receiving settings from the control room, and high <b>priority</b> real-time <b>tasks,</b> triggered by external events, control the underlying hardware based on these settings. Settings' correctness {{is of paramount importance}} and they must be modified atomically from a real-time task point of view. This is not feasible in multi-core environments using classic double-buffer approaches, mainly because real-time tasks can overlap, preventing buffer swaps. Other common synchronization solutions involving locking critical sections introduce unpredictable jitter on real-time tasks, which is not acceptable in CERN's control system. A lock-free, wait-free solution to this problem based on a triple buffer, guaranteeing atomicity no matter the number of concurrent tasks, is presented. The only drawback is potential synchronization delay on contention. This solution has been implemented and tested in CERN's real-time C++ framework...|$|R
40|$|There is a {{mismatch}} between the properties required from priority driven realtime {{systems and the}} property required for mutual exclusion. A priority scheduled real-time system must ensure that the highest priority runnable task can start to run in a bounded time — and the bound needs to be small. A mutual exclusion mechanism must ensure that every task requesting a certain resource wait {{as long as it}} takes for the task that owns the resource to release it, no matter what the priorities of the tasks. These two constraints can easily conflict causing priority inversion — a scheduled task that is waiting for a lower priority task. The classical nightmare case here is when a <b>low</b> <b>priority</b> <b>task</b> owns a resource, a high priority task is blocked waiting for the resource, and intermediate priority tasks keep preempting the <b>low</b> <b>priority</b> <b>task</b> so it cannot make progress towards releasing the resource. Here we have unbounded priority inversion. In 1980, Lampson and Redall concisely described the problem with reference to exclusive entry monitors. Unless care is taken, the assignment of priorities can be subverte...|$|E
40|$|The {{replication}} of the non-structure data from one data center to another is an urgent task in HBase. The paper studies the priority growth probability of the priority replication queue and proposed a dynamic priority replication task queue algorithm {{based on the}} earliest deadline first algorithm (EDF). The experiment {{results show that the}} proposed algorithm can balance the replication overhead between the high and low priority tasks and avoid the <b>low</b> <b>priority</b> <b>task</b> starving to death as well as ensure the high priority task’s interests...|$|E
40|$|Priority {{inversion}} is {{an important}} concern in providing robust synchronization in real-time systems. When a highpriority task attempts to acquire a lock held by a <b>low</b> <b>priority</b> <b>task,</b> it is often necessary to momentarily resume {{the execution of the}} <b>low</b> <b>priority</b> <b>task</b> so as to allow it to leave the critical region safely, ensuring that shared resources are not in an inconsistent state. Once these resources are properly released, the high priority task can proceed. In pathological cases, the priority of several threads may have to be increased, and the high priority tasks can experience unbounded delays. An alternative approach would record the original values of shared objects whenever they are modified, restoring them if the executing thread is interrupted by a higher-priority one. This approach thus treats the critical section as a lightweight transaction. This paper presents an extension to the Real-time Specification for Java with transactional lock-free (TLF) objects. Atomic methods of TLF-objects can be accessed concurrently without risking priority inversion. The semantics of our transactions are such that a high-priority thread will always succeed when trying to enter an atomic section. The time to enter is bounded by the number of locations updated within the atomic section. Experimental results undertaken in the context of Ovm, a virtual machine framework for Java that implements the Real-Time Specification for Java, indicates that transactional lock-free objects can improve the responsiveness of high priority threads compared to priority-inheritance based approaches at the cost of a reduction throughput. 1...|$|E
50|$|Priority {{inversion}} {{can also}} reduce the perceived performance of the system. <b>Low</b> <b>priority</b> <b>tasks</b> usually have a <b>low</b> <b>priority</b> {{because it is not}} important for them to finish promptly (for example, they might be a batch job or another non-interactive activity). Similarly, a high <b>priority</b> <b>task</b> has a high priority because it {{is more likely to be}} subject to strict time constraints—it may be providing data to an interactive user, or acting subject to realtime response guarantees. Because priority inversion results in the execution of a lower <b>priority</b> <b>task</b> blocking the high <b>priority</b> <b>task,</b> it can lead to reduced system responsiveness, or even the violation of response time guarantees.|$|R
50|$|The iRMX for Windows RTOS {{loads and}} runs on a {{standard}} Windows system. Upon initialization, it sets up a separate execution environment, takes over the CPU, and encapsulates Windows as the <b>lowest</b> <b>priority</b> iRMX <b>task.</b> The iRMX operating system scheduler then determines which tasks will run; whenever a real-time task is ready to run, it preempts Windows, handles all real-time activities, and then resumes Windows (the <b>lowest</b> <b>priority</b> iRMX <b>task)</b> after all real-time activities have completed.|$|R
40|$|Abstract—This paper {{describes}} a generalized approach for compensating just the required yaw moment of a humanoid robot about the Zero Moment Point (ZMP) while performing an arbitrary motion, {{in order to}} prevent unwanted / unexpected yaw rotations. This is done by modifying the motion of any set of joints with <b>low</b> <b>priority</b> <b>tasks</b> that can be arbitrarily selected before-hand. Finally, some simulation results are provided, which intend to show the validity of this approach. I...|$|R
40|$|For {{part-time}} sysadmins, {{a record}} of past actions is an invaluable tool that provides guidance in repairing or extending system services. However, requiring sysadmins to keep a detailed log of changes made to a live system can often seem like a <b>low</b> <b>priority</b> <b>task</b> when compared to addressing long and growing to-do lists. This problem is worse if the system administrator is a part-time volunteer and an overworked student. In this paper we present Trackle, an integrated trouble ticket and solution tracking system which takes the legwork out of creating and maintaining this sort of institutional memory. Furthermore, Trackle is designed to allow untrained student sysadmins to bootstrap their knowledge by peeking over the shoulders of their more experienced colleagues – even if those colleagues graduated years earlier. We accomplish this by tracking the exact actions taken by sysadmins, showing what lines were changed and in which configuration files. We allow experienced and inexperienced sysadmins alike to freely annotate and cross-reference these shell session logs through an integrated Wiki web interface...|$|E
40|$|PREFACE A unique {{sequence}} of events made {{the subject of this}} thesis possible. In June of 1974 my supervisor (at Xerox Corporation) asked me to develop a specification for a general purpose data acquisition system (D. A. S.). This was a <b>low</b> <b>priority</b> <b>task</b> and required about six months of spare time to complete. The D. A. S. system was not continued because of higher priority work. Because of my interest in D. A. S. systems, I continued to develop the system design on my own. In July of 1975 I transferred to a new department. An engineer in this department {{was in the process of}} ordering three chart recorders to be used for a series of experiments. After showing him the advantages of using my D. A. S., he cancelled his order and gave me the go-ahead to build the D. A. S. Since this was not my primary assignment, I got my supervisor's approval to undertake this task on the condition that it would be operational in four months, would be 100 % designed, built, and debugged by me, and would not interfere with m...|$|E
40|$|Human {{exploration}} of space will involve remote autonomous crew and systems in long missions. Data to earth will be delayed and limited. Earth control centers will not receive continuous real-time telemetry data, {{and there will be}} communication round trips of up to one hour. There will be reduced human monitoring on the planet and earth. When crews are present on the planet, they will be occupied with other activities, and system management will be a <b>low</b> <b>priority</b> <b>task.</b> Earth control centers will use multi-tasking "night shift" and on-call specialists. A new project at Johnson Space Center is developing software to support teamwork between distributed human and software agents in future interplanetary work environments. The Engineering and Mission Operations Directorates at Johnson Space Center (JSC) are combining laboratories and expertise to carry out this project, by establishing a testbed for hWl 1 an centered design, development and evaluation of intelligent autonomous and assistant systems. Intelligent autonomous systems for managing systems on planetary bases will commuicate their knowledge to support distributed multi-agent mixed-initiative operations. Intelligent assistant agents will respond to events by developing briefings and responses according to instructions from human agents on earth and in space...|$|E
5000|$|Aging is used {{to ensure}} that jobs with lower {{priority}} will eventually complete their execution. This technique {{can be used to}} reduce starvation of <b>low</b> <b>priority</b> <b>tasks.</b> [...] There are many ways to implement aging, but all have the same principle that the priority of a process should increase as it waits in the ready queue. The increase in priority {{may or may not be}} equal to the waiting time of the process.|$|R
5000|$|Exec 8 was {{primarily}} a batch processing system that gave applications (called [...] "tasks") very fine control of CPU scheduling priority for its threads (called [...] "activities"). Processor switching was preemptive, with higher priority threads gaining control of the processor currently running the <b>lowest</b> <b>priority</b> thread of any program. Except in realtime systems, even the <b>lowest</b> <b>priority</b> <b>tasks</b> got some processor time. It was a multiprogramming and multiprocessing operating system with fully symmetric processor management. A test-and-set instruction built into the hardware allowed very efficient and fine-grained locking both within the OS and within multi-threaded applications.|$|R
40|$|International audienceAlthough many {{multiprocessor}} {{resource sharing}} protocols have been proposed, their {{impacts on the}} schedulability of real-time tasks are largely ignored {{in most of the}} existing literature. Recently, work has been done to integrate queue locks (FIFO-queue-based non-preemptive spin locks) with multiprocessor schedulability analysis but the techniques used introduce a substantial amount of pessimism. For global fixed <b>task</b> <b>priority</b> preemptive multiprocessor systems, this pessimism impacts <b>low</b> <b>priority</b> <b>tasks,</b> greatly reducing the number of tasksets that can be recognised as schedulable. We develop a new schedulability analysis lp-CDW to target this issue specifically. By combing lp-CDW with existing techniques, we significantly increase the number of tasksets that can be recognised as schedulable...|$|R
40|$|In a singleprocessor {{real-time}} {{system the}} question whether a taskset is schedulable or not is essential and {{not always easy to}} answer, and it is even more challenging in multiprocessor real-time systems. To determine the schedulability of a taskset the maximum blocking time for each task must be known. When considering schedulability of tasks on a multiprocessor with a shared bus, both local blocking and interprocessor blocking must be known and considered. To reduce the time high priority tasks are blocked by <b>low</b> <b>priority</b> <b>task</b> on a shared bus multiprocessor system we propose a dynamic priority based arbitration of processors. In our proposal, a processor's priority is a direct mapping of the relative priority of all tasks currently executing. The mapping of priorities onto processors is managed by a hardware operating system kernel which continuously updates the arbiter with priority changes. The information shared between the hardware operating system and the arbiter is done in parallel and does not put additional strain on bus trac. The solution is implemented by augmenting an hardware realtime scheduler and an arbiter unit with added functionality. Systems-on-a-Chip (SoC's) oers the design freedom needed for our proposed solution to reduce occurrences of priority inversion in Multiprocessor SoC (MSoC) ...|$|E
40|$|Operational {{procedures}} are typically initially designed at the spacecraft manufacture site by the system/AIV engineers, tested with the spacecraft database, and then {{published in the}} flight operation manual. The Flight Control Team (FCT) takes the delivered procedures to build the LEOP, commissioning and routine operation procedures. These procedures however are not always sufficiently validated, {{due to lack of}} time. Testing and validation of procedures is often left as a <b>low</b> <b>priority</b> <b>task</b> performed late in the development process. Once developed, there is the need to allow easy (re) validation of the procedure in an automated or semi-automated manner. This validation is not only necessary for checking the consistency of the procedures during their development, but also to verify that the procedures achieve their objective, are safe, and do not endanger the integrity of the spacecraft. Moreover, automatic regression testing needs to be carried-out whenever the S/C database is updated, Mission Control System (MCS) or operational simulator versions are updated, or when Mission Planning System (MPS) outputs need validation. In order to improve the level of testing and reduce associated effort and costs, ESA has conducted a study the prime objective of which was to develop innovative concepts and tools to automate the validation of operations procedures for current and future missions. The developed concepts allows automatic validation of procedures at all stages of their development: initial development, upgrade to accommodate a new database or On-Board Software (OBSW) version, modification resulting from test campaign activities, and regression testing. Tools using validation models have been designed, prototyped, and evaluated with extensive involvement of perspective users. These tools can be shared between industry, spacecraft manufactures, the operations teams and any party for the validation of procedures such that the effort for procedure development and maintenance is reduced, and that procedures developed by one party can be provided and re-used by the other parties with minimum effort...|$|E
50|$|Implementing {{required}} {{changes to}} organisational {{culture is a}} major challenge, since records management is often seen as an unnecessary or <b>low</b> <b>priority</b> administrative <b>task</b> that can be performed at the lowest levels within an organization. Reputational damage caused by poor records management has demonstrated that records management {{is the responsibility of}} all individuals within an organization.|$|R
50|$|Minicomputers, {{particularly}} in the 1970s onwards, when built into dedicated embedded systems such as CAT scanners, increased the need for low-latency priority-driven responses to important interactions with incoming data and so operating systems such as Data General's RDOS (Real-Time Disk Operatings System) and RTOS with background and foreground scheduling as well as Digital Equipment Corporation's RT-11 date from this era. Background-foreground scheduling allowed <b>low</b> <b>priority</b> <b>tasks</b> CPU time when no foreground task needed to execute, and gave absolute priority within the foreground to threads/tasks with the highest priority. Real-time operating systems would {{also be used for}} time-sharing multiuser duties. For example, Data General Business Basic could run in the foreground or background of RDOS (and would introduce additional elements to the scheduling algorithm to make it more appropriate for people interacting via dumb terminals.|$|R
40|$|This work {{introduces}} a utility model (UM) for resource allocation on computational grids and formulates the allocation problem as {{a variant of}} the 0 – 1 multichoice multidimensional knapsack problem. The notion of task-option utility is introduced, and it is used to effect allocation policies. We present a variety of allocation policies, which are expressed as functions of metrics that are both intrinsic and external to the task and resources. An external user-defined credit-value metric is shown to allow users to intervene in the allocation of urgent or <b>low</b> <b>priority</b> <b>tasks.</b> The strategies are evaluated in simulation against random workloads as well as those drawn from real systems. We measure the sensitivity of the UM-derived schedules to variations in the allocation policies and their corresponding utility functions. The UM allocation strategy is shown to optimally allocate resources congruent with the chosen policies...|$|R
50|$|From the programmer's {{point of}} view, RTLinux {{originally}} {{looked like a}} small threaded environment for real-time tasks plus the standard Linux environment for everything else. The real-time operating system was implemented as a loadable kernel module which began by virtualizing guest interrupt control and then started a real-time scheduler. Tasks were assigned static priorities and scheduling was originally purely priority driven. The guest operating system was incorporated as the <b>lowest</b> <b>priority</b> <b>task</b> and essentially acted as the idle task for the real-time system. Real-time tasks ran in kernel mode. Later development of RTLinux adopted the POSIX threads application programming interface (API) and then permitted creation of threads in user mode with real-time threads running inside guest processes. In multiprocessor environments threads were locked to processor cores and {{it was possible to}} prevent the guest thread from running on designated core (effectively reserving cores for only real-time processing).|$|R
40|$|Task {{execution}} in cloud computing requires obtaining stored data from remote data centers. Though this storage process reduces the memory {{constraints of the}} user’s computer, the time deadline is a serious concern. In this paper, Adaptive Cost-based Task Scheduling (ACTS) is proposed to provide data access to the virtual machines (VMs) within the deadline without increasing the cost. ACTS considers the data access completion time for selecting the cost effective path to access the data. To allocate data access paths, the data access completion time is computed by considering the mean and variance of the network service time and the arrival rate of network input/output requests. Then the <b>task</b> <b>priority</b> is assigned to the removed tasks based data access time. Finally, the cost of data paths are analyzed and allocated based on the <b>task</b> <b>priority.</b> Minimum cost path is allocated to the <b>low</b> <b>priority</b> <b>tasks</b> and fast access path are allocated to high <b>priority</b> <b>tasks</b> as to meet the time deadline. Thus efficient task scheduling {{can be achieved by}} using ACTS. The experimental results conducted in terms of execution time, computation cost, communication cost, bandwidth, and CPU utilization prove that the proposed algorithm provides better performance than the state-of-the-art methods...|$|R
40|$|Principles of {{real-time}} executives for microcomputer {{systems are}} discussed, together with some secondary functions. Salient features {{and limitations of}} three commercially available executives for 8080 / 5 and Z 80 systems are described. An example is given illustrating {{the use of an}} executive in a multitasking application involving a simple data logger with a high <b>priority</b> data acquisition <b>task,</b> a <b>low</b> <b>priority</b> data converting <b>task</b> and storage task...|$|R
40|$|It {{has been}} shown by A. -L. Barabasi that the {{priority}} based scheduling rules in single stage queuing systems (QS) generates fat tail behavior for the tasks waiting time distributions (WTD). Such fat tails are due to the waiting times of very <b>low</b> <b>priority</b> <b>tasks</b> which stay unserved almost forever as the <b>task</b> <b>priority</b> indices (PI) are "frozen in time" (i. e. a <b>task</b> <b>priority</b> is assigned once for all to each incoming task). Relaxing the "frozen in time" assumption, this paper studies the new dynamic behavior expected when the priority of each incoming tasks is time-dependent (i. e. "aging mechanisms" are allowed). For two class of models, namely 1) a population type model with an age structure and 2) a QS with deadlines assigned to the incoming tasks which is operated under the "earliest-deadline-first" policy, {{we are able to}} analytically extract some relevant characteristics of the the tasks waiting time distribution. As the aging mechanism ultimately assign high priority to any long waiting tasks, fat tails in the WTD cannot find their origin in the scheduling rule alone thus showing a fundamental difference between the present and the A. -L. Barabasi's class of models. Comment: 16 pages, 2 figure...|$|R
40|$|Real-Time Application Interface (RTAI) is a {{real-time}} Linux implementation {{based on}} RTLinux. It adds a small real-time kernel below the standard Linux kernel and treats the Linux kernel as a <b>low</b> <b>priority</b> real-time <b>task.</b> RTAI provides a large selection of inter-process communication mechanisms and other real-time services. Additionally, RTAI provides a LXRT module for easy developement of real-time applications in user space. LXRT {{makes it possible}} to dynamically switch between real-time and non-real-time operation in the user-space. Finally, we give a small example of using RTAI and LXRT. ...|$|R
50|$|Specialized {{routines}} in {{the file}} system are included to optimize or repair these structures. They are not usually invoked by the user directly but triggered with{{in the file}} system itself. Internal counters {{of the number of}} levels of structures, number of inserted objects may be compared against thresholds. These may cause user access to be suspended to a specific structure (usually to the displeasure of the user or users effected) or may be started as <b>low</b> <b>priority</b> asynchronous <b>tasks</b> or they may be deferred to a time of low user activity. Sometimes these routines are invoked or scheduled by the system manager or {{as in the case of}} defragmentation.|$|R
40|$|Problem statement: One of the Cloud Services, Infrastructure as a Service(IaaS) {{provides}} a Compute resourses for demand in various applications like Parallel Data processing. The computer resources {{offered in the}} cloud are extremely dynamic and probably heterogeneous. Nephele is the first data processing framework to explicitly exploit the dynamic resource allocation offered by todays IaaS clouds for both, task scheduling and execution. Particular tasks of processing a job can be assigned to different types of virtual machines which are automatically instantiated and terminated during the job execution. However, the current algorithms does not consider the resource overload or underutilization during the job execution. In this study, we have focussed on increasing {{the efficacy of the}} scheduling algorithm for the real time Cloud Computing services. Approach: Our Algorithm utilizes the Turnaround time Utility effieciently by differentiating it into a gain function and a loss function for a single task. The algorithm also assigns high <b>priority</b> for <b>task</b> of early completion and less priority for abortions /deadlines issues of real time tasks. Results: The algorithm has been implemented on both preemptive and Non-premptive methods. The experimental results shows that it outperfoms the existing utility based scheduling algorithms and also compare its performance with both preemptive and Non-preemptive scheduling methods. Conculsion: Hence, a novel Turnaround time utility scheduling approach which focuses on both high <b>priority</b> and the <b>low</b> <b>priority</b> <b>tasks</b> that arrives for scheduling is proposed...|$|R
