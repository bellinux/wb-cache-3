20|10000|Public
25|$|Each {{client has}} the same <b>list</b> <b>of</b> <b>identifiers</b> , one for each server.|$|E
25|$|The LANGUAGE pragma was specified. By 2010 {{dozens of}} {{extensions}} {{to the language}} were in wide use, and GHC (among other compilers) provided the LANGUAGE pragma to specify individual extensions with a <b>list</b> <b>of</b> <b>identifiers.</b> Haskell 2010 compilers are required to support the Haskell2010 extension, and encouraged to support several others that correspond to extensions added in Haskell 2010.|$|E
50|$|A list command returns a <b>list</b> <b>of</b> <b>identifiers</b> for objects {{within a}} partition, {{optionally}} filtered by matches against their attribute values. A list command can also return selected {{attributes of the}} listed objects.|$|E
40|$|MatchMiner is a freely {{available}} {{tool for}} the navigation among gene and gene product Identifiers. It has two functions: 1) LookUp: translates from one type <b>of</b> <b>Identifier</b> to another, either interactively or in batch; and 2) Merge: Identifies and outputs the one-to-one, one-to-many, and many-to-many relationships between two <b>lists</b> <b>of</b> <b>Identifiers</b> <b>of</b> either the same or different types. This is done by translating the input into an internal gene index and then retrieving the requested information linked to that index...|$|R
40|$|Abstract Background In many {{genomics}} projects, numerous lists containing biological identifiers are produced. Often it {{is useful}} to see the overlap between different lists, enabling researchers to quickly observe similarities and differences between the data sets they are analyzing. One of the most popular methods to visualize the overlap and differences between data sets is the Venn diagram: a diagram consisting of two or more circles in which each circle corresponds to a data set, and the overlap between the circles corresponds to the overlap between the data sets. Venn diagrams are especially useful when they are 'area-proportional' i. e. the sizes of the circles and the overlaps correspond to the sizes of the data sets. Currently there are no programs available that can create area-proportional Venn diagrams connected {{to a wide range of}} biological databases. Results We designed a web application named BioVenn to summarize the overlap between two or three <b>lists</b> <b>of</b> <b>identifiers,</b> using area-proportional Venn diagrams. The user only needs to input these <b>lists</b> <b>of</b> <b>identifiers</b> in the textboxes and push the submit button. Parameters like colors and text size can be adjusted easily through the web interface. The position of the text can be adjusted by 'drag-and-drop' principle. The output Venn diagram can be shown as an SVG or PNG image embedded in the web application, or as a standalone SVG or PNG image. The latter option is useful for batch queries. Besides the Venn diagram, BioVenn outputs <b>lists</b> <b>of</b> <b>identifiers</b> for each <b>of</b> the resulting subsets. If an identifier is recognized as belonging to one of the supported biological databases, the output is linked to that database. Finally, BioVenn can map Affymetrix and EntrezGene identifiers to Ensembl genes. Conclusion BioVenn is an easy-to-use web application to generate area-proportional Venn diagrams from <b>lists</b> <b>of</b> biological <b>identifiers.</b> It supports a wide range <b>of</b> <b>identifiers</b> from the most used biological databases currently available. Its implementation on the World Wide Web makes it available for use on any computer with internet connection, independent of operating system and without the need to install programs locally. BioVenn is freely accessible at [URL]. </p...|$|R
50|$|Structures are {{declared}} {{with the}} struct keyword and unions are declared {{with the union}} keyword. The specifier keyword is followed by an optional identifier name, {{which is used to}} identify the form of the structure or union. The identifier is followed by the declaration of the structure or union's body: a <b>list</b> <b>of</b> member declarations, contained within curly braces, with each declaration terminated by a semicolon. Finally, the declaration concludes with an optional <b>list</b> <b>of</b> <b>identifier</b> names, which are declared as instances of the structure or union.|$|R
50|$|Downloading files is {{the reverse}} of the {{publishing}} process: a user either sends a query to a content tracker and gets a <b>list</b> <b>of</b> <b>identifiers</b> in response or obtains a file identifier out of band, then asks block servers for the appropriate blocks, and then inverts the IDA and encryption algorithms to recover the original file.|$|E
5000|$|The Software Package Data eXchange (SPDX) {{project was}} started in 2010, to create a {{standard}} format for communicating the components, licenses and copyrights associated with software packages. [...] As part of the project, there is a team that currates the SPDX License List, which defines a <b>list</b> <b>of</b> <b>identifiers</b> for commonly found licenses and exceptions used for open source and other collaborative software.|$|E
5000|$|In {{rendezvous}} hashing, {{also called}} highest random weight hashing, all clients {{use the same}} hash function h (...) (chosen ahead of time) to associate a key {{to one of the}} n available servers.Each client has the same <b>list</b> <b>of</b> <b>identifiers</b> , one for each server.Given some key k, a client computes n hash weights [...]The client associates that key with the server corresponding to the highest hash weight for that key.A server with ID [...] owns all the keys [...] for which the hash weight [...] is higher than the hash weight of any other node for that key.|$|E
5000|$|Under the US Health Insurance Portability and Accountability Act (HIPAA), PHI that {{is linked}} {{based on the}} {{following}} <b>list</b> <b>of</b> 18 <b>identifiers</b> must be treated with special care: ...|$|R
50|$|IID {{defines a}} simple HTTP GET request that {{contains}} in the URL either a patient <b>identifier</b> or a <b>list</b> <b>of</b> study <b>identifiers,</b> {{and a small}} set of additional parameters to dictate display behavior.|$|R
5000|$|There is {{a unique}} court {{identifier}} code for most courts. A <b>list</b> <b>of</b> the court <b>identifiers</b> include: ...|$|R
5000|$|According to IV, [...] "this {{method of}} {{filtering}} emails {{is used to}} address the problems of spam e-mail and the use of e-mail to deliver computer viruses." [...] The court began by applying the first step of the two-step analysis prescribed in Alice Corp. v. CLS Bank Int’l, and Mayo Collaborative Services v. Prometheus Labs., Inc., the so-called Mayo/Alice methodology, which is to determine whether the claim is based on an abstract idea. The court stated: [...] "We agree with the district court that receiving e-mail (and other data file) identifiers, characterizing e-mail based on the identifiers, and communicating the characterization—in other words, filtering files/e-mail—is an abstract idea" [...] because [...] "it was a long-prevalent practice for people receiving paper mail to look at an envelope and discard certain letters, without opening them, from sources from which they did not wish to receive mail based on characteristics of the mail," [...] and [...] "characterizing e-mail based on a known <b>list</b> <b>of</b> <b>identifiers</b> is no less abstract." [...] In the Alice case, the Supreme Court had held that [...] "fundamental [...] [...] [...] practices long prevalent" [...] are abstract ideas. The Federal Circuit therefore proceeded to the second step of the Alice methodology, which is to determine whether the patent adds anything inventive to implement the abstract idea. The court held the claimed steps [...] "routine and conventional," [...] despite IV's argument that because the prior art did not disclose [...] "determining [...] [...] [...] whether each received content identifier matches a characteristic" [...] or [...] "outputting [...] [...] [...] an indication of the characteristic of the data file," [...] the implementation must not be routine and conventional. The court responded that the idea of [...] "determining" [...] and [...] "outputting" [...] is abstract and noninventive in computer programs, even though applying them {{in the context of the}} patent claim was not in the prior art, so that the claimed implementation was routine and conventional. The fact that the [...] "particular prior art references do not disclose all the limitations of or render obvious the asserted claims does not resolve the question of whether the claims embody an inventive concept at the second step of the Mayo/Alice" [...] analysis. This was a case in which the claimed method steps just [...] "use generic computers to perform generic computer functions." [...] Therefore, the claimed method is patent ineligible.|$|E
30|$|Finally, our {{proposed}} method {{could also}} be easily used in different languages that have similar features to English, especially Germanic languages (such as, German, Dutch, Danish, Norwegian, etc.) and Romance languages (such as, Spanish, French and Italian). Replacing the English <b>list</b> <b>of</b> <b>identifiers</b> for each category with the equivalent list from the target language would yield similar results with little to no complications.|$|E
40|$|Abstract {{data type}} {{declarations}} appear in typed programming languages like Ada, Alphard, CLU and ML. This form of declaration binds a <b>list</b> <b>of</b> <b>identifiers</b> to a type with associated operations, a composite “value ” {{we call a}} data algebra. We use a second-order typed lambda calculus SOL to show how data algebras may be given types, passed as parameters, and returned as results of function calls. In the process, we discuss the semantics of abstract data type declarations and review a connection between typed programming languages and constructive logic...|$|E
5000|$|ISO/IEC 19788 - In a MLR (metadata for {{learning}} resources) triple, {{the subject is}} always the literal <b>of</b> an <b>identifier</b> <b>of</b> the learning resource, such as a URI or ISBN. The predicate is also a literal, the MLR data element specification identifier. Finally, the object can be a literal or a resource class (a set of accepted values, such as a <b>list</b> <b>of</b> terms <b>identifiers</b> from a controlled vocabulary list).|$|R
50|$|STANAG 4586 (NATO Standardization Agreement 4586) is a NATO Standard Interface of the Unmanned Control System (UCS) Unmanned Aerial Vehicle (UAV) interoperability. It defines architectures, interfaces, {{communication}} protocols, {{data elements}} and message formats. It includes data link, command and control, and human/computer interfaces. The current revision is STANAG 4586 Edition No 4 with mission phase enhancements, an updated <b>list</b> <b>of</b> vehicle <b>identifiers</b> etc.|$|R
5000|$|IDREF or IDREFS: the {{effective}} {{value of the}} attribute can only be a valid identifier (or a space-separated <b>list</b> <b>of</b> such <b>identifiers)</b> and must be referencing the unique element defined in the document with an attribute declared with the type ID in the DTD (or the unique element defined in an XML document with a pseudo-attribute [...] "xml:id") and whose effective value is the same identifier; ...|$|R
40|$|In {{this thesis}} we will {{investigate}} how a popular {{new way of}} distributed computing called service orientation can be used {{within the field of}} Knowledge Discovery. We critically investigate its principles and present models for developing withing this paradigm. We then apply this model to create a web service caled Fantom, that mines subgroups in a ranked <b>list</b> <b>of</b> <b>identifiers,</b> based on their score. The descriptions of these subgroups are done in ontologies to provide the scientist a description in a standardized and familiar language. Finally, Fantom is tested on two different data sets from the field of life-sciences; one concerning gene data, the other concerning SNP data. Promotor: J. N. KokWith summary in Dutc...|$|E
40|$|During {{the last}} few decades {{biological}} and biochemical research methodology has changed significantly and provides more and more diverse and complex data. The integration of this data is now a crucial issue in life science research. One basic building brick in representing a biologically meaningful relationship between two data records is a pair of identifiers. A computationally supported way of preparing custom lists of these bricks can facilitate different use cases in data integration. We present TransID, a web-based and easy to use tool for the preparation of mapping tables. TransID unifies the usage of different data sources via the BridgeDB framework. The user is able to supply a <b>list</b> <b>of</b> <b>identifiers</b> via the browser and receives a custom mapping table via e-mail, containing relevant mappings as well as links to corresponding data sources. TransID is available by browser using th...|$|E
40|$|Ray tracing {{dynamically}} changing scenes with unstructured motion {{has long been}} a problem for ray-traversal acceleration schemes. When polygons are transformed arbitrarily, the cost of updating tradi-tional spatial data-structures can be quite high [TL 03][IW 03]. We propose a ray traversal scheme that is well suited to scenes with {{dynamically changing}} objects during rendering with ray tracing, using a data structure that exploits coherence in view space. The main operation for handling arbitrary trans-formations of objects reduces to low resolution 2 D polygon rasterisation. Data Structure Find the smallest bounding cuboid that encloses the scene, and divide the bottom face (parallel to the XY-plane) into NxN 2 D square tiles. Each tile can be considered as one end of a 3 D beam parallel to the Z-axis that intersects a number of polygons. The tiling is represented as a 2 D array, where each array el-ement stores a <b>list</b> <b>of</b> <b>identifiers</b> of polygons intersected by that beam. This tiling is easy and fast to compute – since the scene can be orthographically projecte...|$|E
5000|$|ID Mapping: Quickly maps PATRIC {{identifiers}} {{to those}} from other prominent external databases, such as GenBank, RefSeq, UniProt, etc. Alternatively, researchers {{can start with}} a <b>list</b> <b>of</b> external database <b>identifiers</b> and map them to the corresponding PATRIC features.|$|R
30|$|Γ, x:τ is the {{standard}} notation for extending typing context Γ with a new assumption, after deleting from Γ any type assumption for x. We let Γ (x)=τ if x : τ∈Γ. Typing contexts are represented in Coq by <b>lists</b> <b>of</b> pairs <b>of</b> <b>identifiers</b> and types. Definitions of typing contexts, functions and properties over them (and their corresponding lemmas) are straightforward.|$|R
50|$|In a MLR triple, {{the subject}} is always the literal <b>of</b> an <b>identifier</b> <b>of</b> the {{learning}} resource, such as a URI or ISBN. The predicate is also a literal, the MLR data element specification (DES) identifier. For example, ISO_IEC_19788-2:2011::DES0100 tells us that this DES {{can be found in}} part 2 of the standard and DES0100 is the data element used to identify the title of the learning resource. Finally, the object can be a literal (in this example, the book title) or a resource class (a set of accepted values, such as a <b>list</b> <b>of</b> terms <b>identifiers</b> from a controlled vocabulary list).|$|R
40|$|Nowadays, genomic and proteomic studies produce {{vast amounts}} of data. To get the {{biological}} meaning of these data and to generate testable new hypothesis, scientists must use several tools often not designed for ruminant studies. Here we present ProteINSIDE: an online tool to analyse lists of protein or gene identifiers from well-annotated species (human, rat, and mouse) and ruminants (cow, sheep, and goat). The aims of ProteINSIDE modules are to gather biological information stores in well-updated public databases, to proceed to annotations according to the Gene Ontology consortium, to predict potentially secreted proteins, and to search for proteins interactions. ProteINSIDE provides results from several software and databases in a single query. From a <b>list</b> <b>of</b> <b>identifiers,</b> ProteINSIDE uses orthologs or homologs to extend analyses and biological information retrieval. As a tutorial, we presented how to launch, to recover, to view, and {{to interpret the results}} provided by the two types of analysis available with ProteINSIDE (basic and custom analyses). ProteINSIDE is freely available using a simple internet browser at www. proteinside. org. The results of this article are provided on the home page of ProteINSIDE website as the example of an analysis results...|$|E
40|$|Experimental {{methods of}} the {{application}} case: Cells of P. aeruginosa PA 14 were grown as biofilm on sterile membranes with LB medium for five days, harvested by washing and centrifugation, resuspended in buffer and broken by a passage through a french pressure cell {{in the presence of}} benzonase for DNA digestion. The membrane proteome was analyzed as described for Listeria monocytogenes before (Wehmhöhner et al., Electrophoresis 2005). In brief, membranes were isolated by sucrose density centrifugation and two opalescent membrane fractions were separated and analyzed separately. Unspecifically associated proteins were removed with Na carbonate at pH 11, and remaining proteins were digested with trypsin over night. The resulting peptides were separated by reverse phase chromatography and automatically sequenced by tandem mass spectrometry on a QTOF instrument (Waters). In total, 796 unique proteins were identified unambiguously as part of both investigated fractions by searching the peptide fragmentation patterns against a Pseudomonas genome database with MASCOT (version 2. 1). This <b>list</b> <b>of</b> <b>identifiers</b> was submitted to ProdoNet and queried against the available PAO 1 data. The resulting 567 matches (see table below) were then visualized and analysed. Dataset of the application case...|$|E
40|$|BACKGROUND: As public {{microarray}} repositories {{are constantly}} growing, {{we are facing}} the challenge of designing strategies to provide productive access to the available data. METHODOLOGY: We used {{a modified version of}} the Markov clustering algorithm to systematically extract clusters of co-regulated genes from hundreds of microarray datasets stored in the Gene Expression Omnibus database (n = 1, 484). This approach led to the definition of 18, 250 transcriptional signatures (TS) that were tested for functional enrichment using the DAVID knowledgebase. Over-representation of functional terms was found in a large proportion of these TS (84 %). We developed a JAVA application, TBrowser that comes with an open plug-in architecture and whose interface implements a highly sophisticated search engine supporting several Boolean operators ([URL] User can search and analyze TS containing a <b>list</b> <b>of</b> <b>identifiers</b> (gene symbols or AffyIDs) or associated with a set of functional terms. CONCLUSIONS/SIGNIFICANCE: As proof of principle, TBrowser was used to define breast cancer cell specific genes and to detect chromosomal abnormalities in tumors. Finally, taking advantage of our large collection of transcriptional signatures, we constructed a comprehensive map that summarizes gene-gene co-regulations observed through all the experiments performed on HGU 133 A Affymetrix platform. We provide evidences that this map can extend our knowledge of cellular signaling pathways...|$|E
40|$|KRIPO {{stands for}} Key Representation of Interaction in POckets, see {{reference}} for more information. Subset of Kripo fragments and distance matrix of all G protein-coupled receptor in the Protein Data Bank. 	pdbs. txt [...] <b>List</b> <b>of</b> GPCR PDB <b>identifiers</b> 	kripo. gpcr. sqlite [...] Fragments <b>of</b> PDB <b>identifiers</b> 	kripo. gpcrandhits. sqlite [...] Fragments <b>of</b> GPCR PDB <b>identifiers</b> and their most similar fragments from whole PDB 	kripo. gpcr. h 5 [...] Distance matrix <b>of</b> GPCR PDB <b>identifiers</b> and their most similar fragments from whole PD...|$|R
50|$|In {{the control}} plane, Evolved Node B (eNB) is {{responsible}} for LWA activation, de-activation and the decision as to which bearers are offloaded to the WLAN. It does so using WLAN measurement information reported by the UE. Once LWA is activated, the eNB configures the UE with a <b>list</b> <b>of</b> WLAN <b>identifiers</b> (referred to as the WLAN Mobility Set) within which the UE can move without notifying the network. This is a tradeoff between fully network controlled mobility and fully UE controlled mobility.|$|R
50|$|SEDOL {{stands for}} Stock Exchange Daily Official <b>List,</b> a <b>list</b> <b>of</b> {{security}} <b>identifiers</b> {{used in the}} United Kingdom and Ireland for clearing purposes. The numbers are assigned by the London Stock Exchange, on request by the security issuer. SEDOLs serve as the National Securities Identifying Number for all securities issued in the United Kingdom and are therefore part of the security's ISIN as well. The SEDOL Masterfile (SMF) provides reference data on millions of global multi-asset securities each uniquely identified at the market level using a universal SEDOL code.|$|R
40|$|International audienceWe {{study the}} {{following}} scenario of online graph exploration. A team of k agents is initially located at a distinguished vertex r of an undirected graph. At every time step, each agent can traverse {{an edge of}} the graph. All vertices have unique identifiers, and upon entering a vertex, an agent obtains the <b>list</b> <b>of</b> <b>identifiers</b> of all its neighbors. We ask how many time steps are required to complete exploration, i. e., {{to make sure that}} every vertex has been visited by some agent. We consider two communication models: one in which all agents have global knowledge {{of the state of the}} exploration, and one in which agents may only exchange information when simultaneously located at the same vertex. As our main result, we provide the first strategy which performs exploration of a graph with n vertices at a distance of at most D from r in time O(D), using a team of agents of polynomial size k = D n^ 1 + ϵ 0. Our strategy works in the local communication model, without knowledge of global parameters such as n or D. We also obtain almost-tight bounds on the asymptotic relation between exploration time and team size, for large k. For any constant c> 1, we show that in the global communication model, a team of k = D n^c agents can always complete exploration in D(1 + 1 /c- 1 +o(1)) time steps, whereas at least D(1 + 1 /c -o(1)) steps are sometimes required. In the local communication model, D(1 + 2 /c- 1 +o(1)) steps always suffice to complete exploration, and at least D(1 + 2 /c -o(1)) steps are sometimes required. This shows a clear separation between the global and local communication models...|$|E
40|$|Abstract Background The {{computational}} {{analysis of}} regulatory SNPs (rSNPs) {{is an essential}} step in the elucidation of the structure and function of regulatory networks at the cellular level. In this work we focus in particular on SNPs that potentially affect a Transcription Factor Binding Site (TFBS) to a significant extent, possibly resulting in changes to gene expression patterns or alternative splicing. The application described here {{is based on the}} MAPPER platform, a previously developed web-based system for the computational detection of TFBSs in DNA sequences. Methods rSNP-MAPPER is a computational tool that analyzes SNPs lying within predicted TFBSs and determines whether the allele substitution results in a significant change in the TFBS predictive score. The application's simple and intuitive interface supports several usage modes. For example, the user may search for potential rSNPs in the promoters of one or more genes, specified as a <b>list</b> <b>of</b> <b>identifiers</b> or chosen among the members of a pathway. Alternatively, the user may specify a set of SNPs to be analyzed by uploading a list of SNP identifiers or providing the coordinates of a genomic region. Finally, the user can provide two alternative sequences (wildtype and mutant), and the system will determine the location of variants to be analyzed by comparing them. Results In this paper we outline the architecture of rSNP-MAPPER, describing its intuitive and powerful user interface in detail. We then present several examples of the use of rSNP-MAPPER to reproduce and confirm experimental studies aimed at identifying regulatory SNPs in human genes, that show how rSNP-MAPPER is able to detect and characterize rSNPs with high accuracy. Results are richly annotated and can be displayed online or downloaded {{in a number of different}} formats. Conclusions rSNP-MAPPER is optimized for large scale work, allowing for the efficient annotation of thousands of SNPs, and is designed to assist in the genome-wide investigation of transcriptional regulatory networks, prioritizing potential rSNPs for subsequent experimental validation. rSNP-MAPPER is freely available at [URL]. </p...|$|E
40|$|Background: We {{report the}} Gene Normalization (GN) {{challenge}} in BioCreative III where participating teams {{were asked to}} return a ranked <b>list</b> <b>of</b> <b>identifiers</b> of the genes detected in full-text articles. For training, 32 fully and 500 partially annotated articles were prepared. A total of 507 articles were selected as the test set. Due to the high annotation cost, it was not feasible to obtain gold-standard human annotations for all test articles. Instead, we developed an Expectation Maximization (EM) algorithm approach for choosing {{a small number of}} test articles for manual annotation that were most capable of differentiating team performance. Moreover, the same algorithm was subsequently used for inferring ground truth based solely on team submissions. We report team performance on both gold standard and inferred ground truth using a newly proposed metric called Threshold Average Precision (TAP-k). Results: We received a total of 37 runs from 14 different teams for the task. When evaluated using the goldstandard annotations of the 50 articles, the highest TAP-k scores were 0. 3297 (k= 5), 0. 3538 (k= 10), and 0. 3535 (k= 20), respectively. Higher TAP-k scores of 0. 4916 (k= 5, 10, 20) were observed when evaluated using the inferred ground truth over the full test set. When combining team results using machine learning, the best composite system achieved TAP-k scores of 0. 3707 (k= 5), 0. 4311 (k= 10), and 0. 4477 (k= 20) on the gold standard, representing improvements of 12. 4 %, 21. 8 %, and 26. 6 % over the best team results, respectively. Conclusions: By using full text and being species non-specific, the GN task in BioCreative III has moved closer to a real literature curation task than similar tasks in the past and presents additional challenges for the text mining community, as revealed in the overall team results. By evaluating teams using the gold standard, we show that the EM algorithm allows team submissions to be differentiated while keeping the manual annotation effort feasible. Using the inferred ground truth we show measures of comparative performance between teams. Finally, by comparing team rankings on gold standard vs. inferred ground truth, we further demonstrate that the inferred ground truth is as effective as the gold standard for detecting good team performance...|$|E
40|$|This {{compilation}} of ERIC abstracts dealing with {{recreation and entertainment}} is the 13 th in a series that identifies research and instructional materials in selected occupational clusters. Approximately 125 documents were identified by means of computer searches of "Research in Education " from 1967 to December 1972. Instructions {{on how to use}} ERIC reference products are included. Intended for use in career education curriculum development, these abstracts include <b>lists</b> <b>of</b> descriptors, <b>identifiers,</b> and other pertinent information about documents in the occupational cluster dealing with recreation and entertainment. This document is related to 14 other cluster groupings, available as V...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedOrganizations {{would like to}} be able to identify the fast rising executive at an early age. This paper is a pilot study in developing a method for identifying this "rising star". The authors first developed a <b>list</b> <b>of</b> capacity <b>identifiers</b> for observing executive ability or potential. From this list a sample set <b>of</b> nine capacity <b>identifiers</b> was selected and questions developed by the authors to determine an executive's capacity in those selected areas. Methods for validation of the questions are presented and suggestions offered for developing a composite capacity score which can be used to identify the rising star. [URL] Commander, United States NavyLieutenant, United States Nav...|$|R
40|$|Abstract Background Document gene {{normalization}} is {{the problem}} <b>of</b> creating a <b>list</b> <b>of</b> unique <b>identifiers</b> for genes that are mentioned within a document. Automating this process has many potential applications in both information extraction and database curation systems. Here we present two separate solutions to this problem. The first is primarily based on standard pattern matching and information extraction techniques. The second and more novel solution uses a statistical classifier to recognize valid gene matches from a <b>list</b> <b>of</b> known gene synonyms. Results We compare {{the results of the}} two systems, analyze their merits and argue that the classification based system is preferable for many reasons including performance, simplicity and robustness. Our best systems attain a balanced precision and recall in the range of 74 %– 92 %, depending on the organism. </p...|$|R
