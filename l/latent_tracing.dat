0|35|Public
40|$|Many {{practical}} problems {{over a wide}} range of domains require synthesizing information from time series data. Two distinct, yet related, problems in time series data are those of alignment and difference detection. These tasks may be coupled together so that a solution to one is difficult without a solution to the other. We introduce a unified, probabilistic approach to the problems of alignment and of alignment with difference detection. This approach {{takes the form of a}} class of models called Continuous Profile Models for simultaneously analyzing sets of sibling time series – those which contain shared sub-structure, but which may also differ. In this type of generative model, each time series belonging to one class is generated as a noisy transformation of a single <b>latent</b> <b>trace</b> in the model. A <b>latent</b> <b>trace</b> can be viewed as an underlying, noiseless representation of the set of observable time series belonging to one class, and is learned from the data. If multiple classes of data exist, then one <b>latent</b> <b>trace</b> per class is learned, and these are aligned to each other during inference. The <b>latent</b> <b>traces</b> lie at the core of this class of models, and provide the basis for alignment and difference detection. Our approach to alignment has several benefits over traditional approaches. It provide...|$|R
40|$|We {{theoretically}} and experimentally investigate tensor-based regression and clas-si cation. Our {{focus is}} regularization with various tensor norms, including the overlapped <b>trace</b> norm, the <b>latent</b> <b>trace</b> norm, and the scaled <b>latent</b> <b>trace</b> norm. We rst give dual optimization methods using the alternating direction method of multipliers, which is computationally efficient {{when the number}} of training sam-ples is moderate. We then theoretically derive an excess risk bound for each tensor norm and clarify their behavior. Finally, we perform extensive experiments using simulated and real data and demonstrate the superiority of tensor-based learning methods over vector- and matrix-based learning methods. ...|$|R
40|$|In the {{original}} CPM paper (Listgarten et al., 2005), the CPM was a generative {{model for a}} set of scalar time series,. We here extend the CPM to accomodate vector time series rather than just scalar time series, and we do so in the simplest way possible. Please refer to {{the original}} CPM paper for details upon which these extensions depend. Let a multi-dimensional observed LC-MS run (i. e., with more than one m/z bin – not just the TIC) be, with entries where runs from 1 to (length of the time series), runs from 1 to, the dimensionality of the vector at each time point (in the Difference Detection paper, and# runs from 1 to, the number of experimental LC-MS samples. Let the be <b>latent</b> <b>trace</b> with entries,, where runs from 1 to * (the number of hidden time states), and runs from 1 to. The emission probabilities of the original CPM become multi-dimensional Gaussians with (spherical) and the log likelihood,Ł]_^, stays the same as in the CPM, except for i) the emission probabilities just listed, and ii) the smooting prior/penalty on the <b>latent</b> <b>trace,</b> which now sums over all dimensions,...|$|R
40|$|We assess pre-outbreak and during-outbreak {{vaccination}} as control {{strategies for}} SARS epidemics using {{a mathematical model}} that includes susceptible, <b>latent</b> (<b>traced</b> and untraced), infectious, isolated and recovered individuals. Scenarios focusing on policies that include contact tracing and levels of self-isolation among untraced infected individuals are explored. Bounds on the proportion of pre-outbreak successfully vaccinated individuals are provided using the the basic reproductive number. Uncertainty and sensitivity analyses on the reproductive number are carried out. The final epidemic size under different vaccination scenarios is computed...|$|R
40|$|The {{detection}} of traces is a main task of forensics. Hyperspectral imaging {{is a potential}} method from which we expect to capture more fluorescence effects than with common forensic light sources. This paper shows {{that the use of}} hyperspectral imaging is suited for the analysis of <b>latent</b> <b>traces</b> and extends the classical concept to the conservation of the crime scene for retrospective laboratory analysis. We examine specimen of blood, semen and saliva traces in several dilution steps, prepared on cardboard substrate. As our key result we successfully make <b>latent</b> <b>traces</b> visible up to dilution factor of 1 : 8000. We can attribute most of the detectability to interference of electromagnetic light with the water content of the traces in the shortwave infrared region of the spectrum. In a classification task we use several dimensionality reduction methods (PCA and LDA) in combination with a Maximum Likelihood classifier, assuming normally distributed data. Further, we use Random Forest as a competitive approach. The classifiers retrieve the exact positions of labelled trace preparation up to highest dilution and determine posterior probabilities. By modelling the classification task with a Markov Random Field we are able to integrate prior information about the spatial relation of neighboured pixel labels...|$|R
40|$|Part 1 : Research PapersInternational audienceThe age {{determination}} of <b>latent</b> fingerprint <b>traces</b> {{is a very}} important challenge for forensic investigations, which has not been solved satisfyingly so far. Based on prior work, we use the novel and very promising aging feature of counting binary pixel for the approximation of a mathematical aging function to be used for the {{age determination}} of <b>latent</b> fingerprint <b>traces.</b> We first show the feasibility of this feature in a test set of nine test series (each comprised of a fingerprint sample scanned continuously over four days) using three different optical sensors (CWL) of the same model and varying resolutions (3, 5, 10 μm). We then approximate the aging function for each test series, showing an average error of approximation between 13 % and 40 % for an optimal approximation. We discuss the prospects and restrictions of such a function for the age determination of <b>latent</b> fingerprint <b>traces</b> and identify future research challenges...|$|R
40|$|Multiple realizations of continuous-valued {{time series}} from a {{stochastic}} process often contain systematic variations in rate and amplitude. To leverage {{the information contained}} in such noisy replicate sets, we need to align them in an appropriate way (for example, to allow the data to be properly combined by adaptive averaging). We present the Continuous Profile Model (CPM), a generative model in which each observed time series is a non-uniformly subsampled version of a single <b>latent</b> <b>trace,</b> to which local rescaling and additive noise are applied. After unsupervised training, the learned trace represents a canonical, high resolution fusion of all the replicates. As well, an alignment in time and scale of each observation to this trace can be found by inference in the model. We apply CPM to successfully align speech signals from multiple speakers and sets of Liquid Chromatography-Mass Spectrometry proteomic data. 1 A Profile Model for Continuous Dat...|$|R
40|$|Communicated by Yang Kuang) Abstract. We assess pre-outbreak and during-outbreak {{vaccination}} as control {{strategies for}} SARS epidemics using {{a mathematical model}} that includes susceptible, <b>latent</b> (<b>traced</b> and untraced), infectious, isolated and recovered individuals. Scenarios focusing on policies that include contact tracing and levels of self-isolation among untraced infected individuals are explored. Bounds on the proportion of pre-outbreak successfully vaccinated individuals are provided using the the basic reproductive number. Uncertainty and sensitivity analyses on the reproductive number are carried out. The final epidemic size under different vaccination scenarios is computed. 1. Introduction. Severe acute respiratory syndrome (SARS) is a viral respiratory illness caused by SARS coronavirus (SARS-CoV). SARS {{is believed to have}} emerged in the southern China province of Guangdong in November of 2002 [1]. The 2003 SARS epidemic was initially driven by international travel and lack of knowledge of the disease’s etiological agent. The outbreak in Toronto, Canada, wa...|$|R
40|$|The {{detection}} of <b>latent</b> <b>traces</b> {{is an important}} aspect of crime scene investigation. Blood stains on black backgrounds can be visualized using chemiluminescence, which is invasive and requires a darkened room, or near-infrared photography, for which investigators need to change filters manually to optimize contrast. We demonstrated the performance of visible reflectance hyperspectral imaging (400 - 720 nm) for this purpose. Several processing methods were evaluated: single wavelength bands, ratio images, principal component analysis (PCA), and "SIMPLe-to-use Interactive Self-modeling Mixture Analysis" (SIMPLISMA). Using these methods, we were able to enhance the contrast between blood stains and 12 different fabrics. On black cotton, blood dilutions were visible with a minimal concentration of 25 % of whole blood. The hyperspectral camera system used in this study is portable and wireless, which makes it suitable for crime scene use. The described technique is noncontact and nondestructive, so all traces are preserved for further analysi...|$|R
40|$|We study a {{multitask}} learning {{problem in}} which each task is parametrized by a weight vector and indexed {{by a pair of}} indices, which can be e. g, (consumer, time). The weight vectors can be collected into a tensor and the (multilinear-) rank of the tensor controls the amount of sharing of information among tasks. Two types of convex relaxations have recently been proposed for the tensor multilin-ear rank. However, we argue that both of them are not optimal in the context of multitask learning in which the dimensions or multilinear rank are typically het-erogeneous. We propose a new norm, which we call the scaled <b>latent</b> <b>trace</b> norm and analyze the excess risk of all the three norms. The results apply to various set-tings including matrix and tensor completion, multitask learning, and multilinear multitask learning. Both the theory and experiments support the advantage of the new norm when the tensor is not equal-sized and we do not a priori know which mode is low rank. ...|$|R
40|$|Repetitive, {{unilateral}} {{stimulation of}} Aplysia induces long-term sensitization (LTS) of ipsilaterally elicited siphon-withdrawal responses. Whereas some morphological effects of training appear only on ipsilateral sensory neurons, others appear bilaterally. We tested {{the possibility that}} contralateral morphological modifications may have functional significance. Therefore, we examined whether LTS training primes subsequent sensitization. Twenty-four hours after LTS training the effects of brief shock treatment (BST) were examined. BST failed to sensitize animals that had previously received either 4 -d control treatment or 4 -d ipsilateral LTS training. In contrast, BST did sensitize animals that had previously received 4 -d contralateral LTS training, suggesting {{the presence of a}} <b>latent</b> <b>trace</b> that primes the animal for further learning. The siphon withdrawal reflex of Aplysia is a useful model system for understanding the neurobiology of learning and memory. The reflex exhibits sensitization, a simple form of learning, in which responses elicited by weak test stimuli are augmented by training with strong, usually noxious, stimuli (Carew et al. 1971; Pinsker et al. 1973; Scholz and Byrne 1987). Short-term sensiti-zation (lasting from seconds to minutes) relies on covalent modi...|$|R
40|$|It {{is shown}} that {{differential}} equations {{given by the}} author may be used recursively to construct certain multivariate null distributions in reduced form. These include the distributions of individual latent roots of B = S 1 (S 1 + S 2) - 1, and distributions of Tr B and Tr S 1 S 2 - 1, for small numbers of variates. exact distributions random matrices individual <b>latent</b> roots <b>trace</b> differential equations Laplace transforms...|$|R
40|$|The {{polymerase}} {{chain reaction}} (PCR) technique brought about a major advance in DNA study, and criminology experts have obviously noticed the possibilities that imple-mentation of this technique can contribute to investigat-ing criminal cases. It is now possible to extract and study DNA from very small samples, even those that are invisible or latent. Although preferred samples from which to obtain DNA are those from biological fluids, {{it is possible to}} obtain DNA from fingerprints (1). The possibility of studying profiles of DNA obtained from fingerprints allows us to consider that invisible or latent lip prints (that is, lip prints from protective lipstick or long-lasting lipstick that does not leave any visible mark) may provide cell remains from which DNA can be extracted. The following study demon-strates an attempt to obtain DNA from latent lip prints on porous surfaces (paper handkerchiefs). When dealing with <b>latent</b> <b>traces,</b> the first step is visualizing them by a developing process. The developing of latent lip prints on porous sur-faces is more recent than that for fingerprints. The first research showed that traditional reagents used for fingerprints are not successful (2). It has recently been determined that lysochrome...|$|R
50|$|The {{activities}} of mind, speech and body, according to Jain philosophy, lead to Asrava, that is, the influx and imprint of karmic residues to the jiva (soul) {{of the living}} being. These residues bind (bandha), forming karma sarira, which can be stopped (saṃvara) and released (nirjara). The operating mechanism, consistent with the dualism premise of Jainism, is not Saṃskāra as <b>latent</b> mental <b>trace,</b> rather karma bandha to the soul. The rituals and rites of passage, called Samskara in Jainism, {{are part of the}} saṃvara and nirjara initiation process, in order to free the soul from the crust of karmic residues.|$|R
50|$|Synaptic tagging {{is likely}} to involve the {{acquisition}} of molecular maintenance mechanisms by a synapse that would then allow {{for the conservation of}} synaptic changes. There are several proposed processes through which synaptic tagging functions. One model suggests that the tag allows for local protein synthesis at the specified synapse that then leads to modifications in synaptic strength. One example of this suggested mechanism involves the anchoring of PKMzeta mRNA to the tagged synapse. This anchor would then restrict the activity of translated PKMzeta, an important plasticity related protein, to this location. A different model proposes that short-term synaptic changes induced by the stimulus are themselves the tag; subsequently delivered or translated protein products act to strengthen this change. For example, the removal of AMPA receptors due to low-frequency stimulation leading to LTD is stabilized by a new protein product that would be inactive at synapses where internalization had not occurred. The tag could also be a <b>latent</b> memory <b>trace,</b> as another model suggests. The activity of proteins would then be required for the memory trace to lead to sustained changes in synaptic strength. According to this model, changes induced by the <b>latent</b> memory <b>trace,</b> such as the growth of new filipodia, are themselves the tag. These tags require protein products for stabilization, synapse formation, and synapse stabilization. Finally, another model proposes that the required molecular products get directed into the appropriate dendritic branches and then find the specific synapses under efficacy modification, by following Ca++ microconcentration gradients through voltage-gated Ca++ channels.|$|R
40|$|From the {{earliest}} ages at which infants search for hidden objects, {{they make the}} AKB error, searching perseveratively at previous rather than current hiding locations (Piaget, 1954). This paper presents a parallel distributed processing (PDP) model that instantiates an explicit set of processing mechanisms to account for a large and diverse set of data on infants’ AKB errors. The model demonstrates how basic processes – the formation of <b>latent</b> memory <b>traces</b> and their interaction with developing active memory traces – can provide a unifying framework for understanding why and when infants perseverate. Novel predictions from the model are discussed, together with its challenges for theories that posit a concept of object permanence {{in the first year}} of life...|$|R
40|$|Severe acute {{respiratory}} syndrome (SARS) is a viral {{respiratory illness}} caused by SARS coronavirus (SARS-CoV). The first cases {{were reported in}} the Southern China Province of Guangdong [?]. The 2003 epidemic was driven by international travel and {{lack of knowledge of}} its etiological agent. The World Health Organization re-ported 8, 422 cases with 916 deaths as of August of 2003. Containment of the SARS epidemic was possible by rapid diagnosis and effective isolation of infectious cases. SARS symptoms include high fever, headaches, body aches, mild respiratory symptoms at the outset, diarrhea, and usually a development of a dry cough within seven days of infection [?]. Most SARS patients develop pneu-monia [?]. SARS is transmitted by close person-to-person contact [?]. The mean incubation period for SARS (the period that a person is infected but not infectious) is ap-proximately 6. 4 s days [?]. Suspected cases are hospital-ized at rate 1 / 4. 85 days− 1 and recovered individuals leave hospitals on average 23. 5 days after diagnosis, or die on average 35. 9 days after diagnosis [?]. We assess pre-outbreak and during-outbreak vaccina-tion as control strategies for SARS epidemics. Our model includes susceptible, <b>latent</b> (<b>traced</b> and untraced), infec-tious, quarantined/isolated and recovered classes. We take parameter estimates from published literature. We explored different scenarios for control including the effects of levels of pre-outbreak successfully vacci-nated individuals as the number of secondary cases by a primary infectious case (R 0) and the final epidemic size. The basic reproductive number is given by R 0 (σ) = β(1 −σ) ((1 −ρ) lθδ+ γ 2 + (1 −ρ) l(1 −θ) α (δ+ γ 2) (α+δ+ γ 1...|$|R
40|$|Libraries support {{individuals}} {{working through}} the many facets of complexity that constitute the human condition. The collections as data conversation {{is an extension of}} this tradition - provision of the means for meaning making. Disposition toward the work is unadorned, grounded by engagement with community need and vested in the challenges and opportunities <b>latent</b> in the <b>traces</b> of human action gathered, described, preserved, and provided access to. Typically, these traces are called collections. What might be gained by thinking of the digital objects that comprise them as data? Within this question lies the potential of a collections as data imperative...|$|R
40|$|Memory re{{activation}}, {{the activation}} of a <b>latent</b> memory <b>trace</b> {{when we are}} reminded of a past experience, strengthens memory but can also contribute to distortions if new information present during reactivation is integrated with existing memory. In a previous study in young adults (St. Jacques & Schacter, 2013; Psychological Science) {{we found that the}} quality of memory reactivation, manipulated using the principle of encoding specificity and indexed by recollection ratings, modulated subsequent true and false memories for events experienced during a museum tour. Here, we examined age-related changes in the quality of memory reactivation on subsequent memory. Young and older adults reactivated memories for museum stops immediately followed by the presentation of a novel lure photo from an alternate tour version (i. e., reactivation plus new information). There was an increase in subsequent true memories for reactivated targets and for subsequent false memories for lures that followed reactivated targets, when compared to baseline target and lure photos. However, the influence of reactivation on subsequent memories was reduced in older adults. These data reveal that aging alters reactivation-related updating processes that allow memories to be strengthened and updated with new information- consequently reducing memory distortions in older compared to young adults...|$|R
40|$|The aim of {{this paper}} is to {{investigate}} the role of Knowledge Management (KM) for the innovation success of firms. It is assumed that the functional chains of KM lead directly and indirectly to more innovative success via enhancing the recombination of internal and external knowledge assets. To analyse the embedding of KM in a firm 9 ̆ 2 s internal system of innovation we establish a structural equation model. We capture KM as <b>latent</b> concept and <b>trace</b> different functional chains by which KM impacts. Using data on KM and innovation success of 351 German firms of the manufacturing sector and knowledge-intensive services located in Thuringia and Hesse, our findings confirm the (dynamic) capability function of KM, which leads via improving exploitation of internal and external innovation assets to more innovation success...|$|R
40|$|Econometric {{modelling}} {{of decision}} uncertainty has received extensive {{attention in the}} contingent valuation literature, but these methods are not directly transferable {{to the realm of}} multi-attribute stated preference studies. In this paper, an integrated choice and <b>latent</b> variable model <b>tracing</b> the impact of decision uncertainty on the valuation of flood risk reductions in the Netherlands is developed. The proposed model structure is not subject to the potential endogeneity bias and measurement error issues associated with most applied methods. The driving factors of decision uncertainty are identified through stated choices and a set of self-reported decision uncertainty follow-up questions. The model simultaneously accounts for the impact of decision uncertainty on individual choices and welfare estimates. In the presented case study uncertain respondents are found to make more random choices and select the opt out option more often. Willingness-to-pay for flood risk reductions increases after accounting for these behavioural responses to decision uncertainty...|$|R
40|$|Knowledge {{discovery}} and data mining commonly rely on finding salient patterns of association from {{a vast amount}} of data. Traditional citation analysis of scientific literature draws insights from strong citation patterns. Latent domain knowledge, in contrast to the mainstream domain knowledge, often consists of highly relevant but relatively infrequently cited scientific works. Visualizing latent domain knowledge presents a significant challenge to knowledge {{discovery and}} quantitative studies of science. We build upon a citation-based knowledge visualization procedure and develop an approach that not only captures knowledge structures from prominent and highly cited works, but also <b>traces</b> <b>latent</b> domain knowledge through low-frequency citation chains. We apply this approach to two cases: (1) identifying cross-domain applications of Pathfinder networks (PFNETs) and (2) clarifying the current status of scientific inquiry of a possible link between Bovine spongiform encephalopathy (BSE), also known as mad cow disease, and a new variant Creutzfeldt-Jakob disease (vCJD), a type of brain disease in human...|$|R
40|$|Aim. The canis lupus familiaris, {{due to his}} {{particular}} olfactory characteristics, {{is used by the}} police to detect a wide range of substances (explosives, gunpowder, narcotics, etc.). Trained dogs to the discovery and reporting human remains or not visible cadaveric blood, can be of great help. This study set out to investigate and validate with scientific method, a training protocol of dogs specialized for research, tracking and reporting of cadaveric <b>latent</b> blood <b>traces</b> of blood. Methods. We used two Labrador Retriever. The study was conducted for sixteen months, with about 200 hours of simulation and 6240 surveys, within a room suitably equipped. We used blood of four patients who died due to trauma, collected in sterile and VOCs free tubes. The first phase of the training focused on the ability of the two dogs to hold the smell target and signal their presence at concentrations always decreasing. In the second phase confounding factors were introduced. Results. The study found the real effectiveness of dogs trained to identify human cadaveric blood in very low concentrations. Tests conducted have shown a good ability to discriminate human cadaveric blood in combination with confounding factors in high concentrations (olfactory accuracy). Conclusion. The use of dogs in this area necessarily requires standardization of training procedures in order to achieve “certified” for this specialized biological device the same rigorous level of reliability and reproducibility required for all methods of investigation in the forensic field, through an optimized and tightly controlled training, through the evaluation of olfactory sensitivity, the ability of olfactory discrimination and olfactory accuracy...|$|R
40|$|The {{starting}} point of this thesis is a neural definition of consciousness, independent of attention or other cognitive functions that are required for a behavioral report. It is defined as recurrent processing (RP) - which is needed for integration of information - as opposed to unconscious feedforward processing. As RP is mediated by NMDA receptors, it is hypothesized that consciousness (according to the neural definition) {{plays a role in}} learning. Using EEG, I showed that stimuli that evoked RP yet were unattended (and therefore unreportable) are learned at the perceptual level, whereas attended yet masked stimuli (for which RP was blocked) do not show any learning effects. Interestingly, the behavioral learning effect only became apparent when performance feedback was given. This suggests that the memory trace formed during inattention was latent until reactivated by behavioral feedback. A follow-up fMRI experiment revealed that performance feedback boosts neural learning effects as well. In addition, when NMDA receptors are manipulated with ketamine (thereby reducing RP), visual feature integration is diminished and perceptual learning precluded. Together, these results provide a first step in understanding the benefit of defining the distinction between unconscious and conscious processing as the divide between feedforward and recurrent processing respectively. It allows us to understand consciousness on a more fundamental level, by understanding its function: consciousness is needed for learning. It would be interesting to investigate how far the current findings extend beyond the perceptual learning domain, and to further elucidate the role of feedback in reconsolidating <b>latent</b> memory <b>traces...</b>|$|R
40|$|When we use {{the term}} "psychology," we are using a Euro­ westem term about how the mind works that has no {{equivalency}} in Aboriginal understandings concerning healing. However, there are areas in both Aboriginal and Euro-western practices of healing where we may draw some parallels concerning mental health. This paper will attempt {{to address some of}} the similarities and differences between the two with an emphasis on Aboriginal understandings of healing in mental health using a model of the psyche developed by Dr. Carl Jung. According to Jungian psychology as espoused by Dr. Carl Jung, there are three levels to the psyche; in other words, there are three levels on which the mind works. These are the ego conscious, the personal unconscious, and the collective unconscious. Jung (1989) believed that a person's ancestral past was locked up in the collective unconscious. Like Jung, Dr. A. C. Ross, a Lacota educator and psychologist, in his book Mitakuye Oyasin: "We are all related," relates his understanding of Jungian psychology. Dr. Jung declared that the mind could be divided into three levels [...] . The top part of the psyche, or the mind, Dr. Jung called the conscious, also known as the ego. This is the active thinking part of the mind, the part you use when you are awake. Below that level he called the personal unconscious where all the memories since birth are [...] . This area of the mind is repressed or suppressed. The lower level of the mind Dr. Jung called the collective unconscious. He felt that <b>latent</b> memory <b>traces</b> from your ancestral past are stored in this area (Ross 1989, p. 12...|$|R
40|$|Abstract—Knowledge {{discovery}} and data mining commonly rely on finding salient patterns of association from {{a vast amount}} of data. Traditional citation analysis of scientific literature draws insights from strong citation patterns. Latent domain knowledge, in contrast to the mainstream domain knowledge, often consists of highly relevant but relatively infrequently cited scientific works. Visualizing latent domain knowledge presents a significant challenge to knowledge {{discovery and}} quantitative studies of science. In this paper, we build upon a citation-based knowledge visualization procedure and develop an approach that not only captures knowledge structures from prominent and highly cited works, but also <b>traces</b> <b>latent</b> domain knowledge through low-frequency citation chains. We apply this approach to two cases: 1) identifying cross-domain applications of Pathfinder networks (PFNETs) and 2) clarifying the current status of scientific inquiry of a possible link between Bovine spongiform encephalopathy (BSE), also known as mad cow disease, and a new variant Creutzfeldt–Jakob disease (vCJD), a type of brain disease in human. Index Terms—Citation chains, knowledge discovery, knowledge domain visualization (KDViz), latent domain knowledge. I...|$|R
40|$|Farmed grayling, Thymallus thymallus (L.), are {{susceptible}} to atypical Aeromonas salmonicida (aAS) infections. Interactions between bacteria and parasites were studied using grayling subjected to concomitant exposure to aAS bacteria and the digenean parasite Diplostomum spathaceum. Atypical AS was detected from fish {{by a combination of}} bacterial cultivation and polymerase chain reaction techniques. A detection level of 17 aAS cells per 100 ?mg intestine tissue sample was obtained. Concomitant bacterial exposure did not enhance the severity of grayling eye rupture and nuclear extrusion induced by D. spathaceum, but D. spathaceum invasion into grayling increased the proportion of fish carrying aAS in their heart tissue. However, the number of aAS cells detected in heart tissue was low. Atypical AS did not cause acute disease or mortality during 15 ?days post-exposure. There was a higher prevalence of aAS in grayling heart samples than in intestinal samples, indicating that the intestine is not favoured by aAS. We suggest that heart tissue would be a good organ from which to isolate aAS when <b>tracing</b> <b>latent</b> carrier fish. We conclude that penetrating diplostomids can enhance bacterial infections in fish and that diplostomids can cause serious eye ruptures in grayling. V 2006 o...|$|R
40|$|This {{dissertation}} explores {{two major}} {{works of the}} twentieth century: Marcel Proust's A la recherche du temps perdu and Jean-Luc Godard's Histoire(s) du cinéma. Both of these works explore the expressiveness of their own medium {{in relation to other}} media, thereby opening up diverse channels of sensory experience within their own particular deployment of aesthetic form. In each case, these works draw upon sensory multiplicity in order to develop new ways of conceptualizing the present as well as new ways of generating acts of memory that relate past and present. Most studies of Proust's novel focus on one single medium that becomes a catalyst for the narrator's transformative experience. On the contrary: Proust's text does not make any particular medium the absolute (including the novel's own medium of writing), but develops its own perspective by dramatizing the tensions between multiple regimes of sensuous experience, e. g. between text, music, photography, painting, and optical technologies. Ultimately, the novel shows how any attempt to use one particular medium to capture or master reality fails. Moreover, every act of expression in one medium indexes the partiality of its own opening onto the world, thereby creating a space in which an other medium or an other image of the world becomes possible and desirable. Every particular medium foregrounds the blindspot of other media while simultaneously opening up a zone of attraction toward which other media tend. This movement toward other sensuous channels reveals not only the limits of a particular medium, but constitutes the depth of a medium by holding open an inexhaustible reserve of data that it can never fully capture. The text therefore moves in a space that is characterized by a tension between media that seek to totalize their own points of entry into the world and the inexorable detotalization that ensues when these points of entry are revealed to be incomplete, partial, and revisable. Drawing on the models of the kinetoscope and the kaleidoscope in the early pages of A la recherche du temps perdu, the intermedial configuration of the novel points toward its main task for thought: the relation between the one and the multiple. The novel interrogates the very integrity of perception [...] how humans are able to perceive identity in difference and how individuals are the same and yet different over time [...] by drawing upon the multiplicity of forms of individuation across different media. Ultimatley, the act of writing recovers the past not by capturing the essence or fullness of time, but by revealing how the same world is modulated over time in differentiated sensuous forms. Intermediality also lies at the core of Jean-Luc Godard's filmic production. Godard interweaves texts, images and sounds in order to explore the power and limits of cinematic language. Godard's filmic productivity prioritizes showing rather than saying and thereby seeks to vanquish the subordination of the image to forms of narrativization specific to textuality. In Histoire(s) du cinéma, Godard constructs an intermedial space that seems at first glance to aim at a redemption of past moments of suffering and injustice (in particular associated with the Holocaust). However, as in Proust's novel, a double gesture emerges in Godard's film: a movement that oscillates between totalization and detotalization. Whereas cinema aims to represent "everything," Godard continually frustrates this tendency by using intermediality to achieve a radically different goal: video, montage, and formal fragmentation produces an act of memory that is simultaneously an act of dispossession. By refusing a complete or full representation of the past, Godard's film keeps viewers {{in a constant state of}} tension, longing, attentiveness, and ultimately, creativity. For Godard, cinema does not regain time and cannot redeem reality. Cinematic memory is not restorative. Instead, cinema provokes multiple acts of memory that do not merely reproduce that which is gone, but allow <b>latent</b> <b>traces</b> from the past to re-enter human practices and perceptions through the work of art. Working upon the image bestows on the past a new form of existence rather than restoring that which has irrevocably disappeared...|$|R
40|$|BACKGROUND: Contact tracing {{plays an}} {{important}} role in the control of emerging infectious diseases, but little is known yet about its effectiveness. Here we deduce from a generic mathematical model how effectiveness of tracing relates to various aspects of time, such as the course of individual infectivity, the (variability in) time between infection and symptom-based detection, and delays in the tracing process. In addition, the possibility of iteratively tracing of yet asymptomatic infecteds is considered. With these insights we explain why contact tracing was and will be effective for control of smallpox and SARS, only partially effective for foot-and-mouth disease, and likely not effective for influenza. METHODS AND FINDINGS: We investigate contact tracing in a model of an emerging epidemic that is flexible enough to use for most infections. We consider isolation of symptomatic infecteds as the basic scenario, and express effectiveness as the proportion of contacts that need to be traced for a reproduction ratio smaller than 1. We obtain general results for special cases, which are interpreted with respect to the likely success of tracing for influenza, smallpox, SARS, and foot-and-mouth disease epidemics. CONCLUSIONS: We conclude that (1) there is no general predictive formula for the proportion to be traced as there is for the proportion to be vaccinated; (2) variability in time to detection is favourable for effective tracing; (3) tracing effectiveness need not be sensitive to the duration of the <b>latent</b> period and <b>tracing</b> delays; (4) iterative tracing primarily improves effectiveness when single-step tracing is on the brink of being effective...|$|R
40|$|Measuring {{turbulent}} fluxes {{with the}} eddy covariance method {{has become a}} widely accepted and powerful tool for the determination of long term data sets for the exchange of momentum, sensible and <b>latent</b> heat, and <b>trace</b> gases such as CO 2 between the atmosphere and the underlying surface. Several flux networks developed continuous measurements above complex terrain, e. g. AmeriFlux and EUROFLUX, with a strong focus on the net exchange of CO 2 between the atmosphere and the underlying surface. Under many conditions basic assumptions for the eddy covariance method in its simplified form, such as stationarity of the flow, {{homogeneity of the surface}} and fully developed turbulence of the flow field, are not fulfilled. To deal with non-ideal conditions which are common at many FLUXNET sites, quality tests have been developed to check if these basic theoretical assumptions are valid. In the framework of the CARBOEUROFLUX project, we combined quality tests described by Foken and Wichura (1996) with the analytical footprint model of Schmid (1997). The aim was to identify suitable wind sectors and meteorological conditions for flux measurements. These tools were used on data of 18 participating sites. Quality tests were applied on the fluxes of momentum, sensible and latent heat, and on the CO 2 -flux, respectively. The influence of the topography on the vertical wind component was also checked. At many sites the land use around the flux towers is not homogeneous or the fetch may not be large enough. So the relative contribution of the land use type intended to be measured was also investigated. Thus the developed tool allows comparative investigations of the measured turbulent fluxes at different sites if using the same technique and algorithms for the determination of the fluxes as well as analyses of potential problems caused by influences of the surrounding land use pattern...|$|R
40|$|This is {{an attempt}} to {{investigate}} the causal relationship existing between the psychedelic literary genre in fiction and the application of trauma theory in the study of One Flew over the Cuckoo's Nest. Trauma theory, which is a psychological theory in essence; has been widely linked to the study of literature since traumatic responses take narrative forms. Scientifically, many studies have proven that the psychedelic trip leads to a deepened exploration of the unconscious <b>tracing</b> <b>latent</b> emotional traumas. Henceforth, I am going to explore this novel as a psychedelic example of science fiction through a generic analysis due to the numerous parallels I have noticed with the effects of drug administration on real life patients. I will base my claim on a medical theory known as Psychedelic Information Theory which investigates psychedelic hallucinations, expanded consciousness and their impact on the metaphysical aspects of self-exploration. Consequently, I shall presuppose that psychedelics act metaphorically on the text of One Flew over the Cuckoo's Nest inducing character-based hallucinatory narratives. Hallucinations are caused by an eruption of a psychedelic consciousness that is the antithesis of the normal state of a mind. Hallucinations range from happy enjoyable experiences laden with kaleidoscopic colourful streams of visions to painful manifestations of latent trauma. I endeavour to analyze this novel as a traumatic example of psychedelic fiction through establishing a cause-result relationship between information theory and trauma theory as a fluid encounter between literature and science within science fiction framework. Finally, I attempt to link the cultural integration of psychedelics to the shift of the traumatic experience from cultural to structural. This paper explores primarily the manifestations of Chief Bromden’s historic trauma. It traces secondarily the psychedelic characteristics of the novel. Lastly, it studies the effects of Bromden’s psychedelic journey on his traumatic recovery...|$|R
40|$|In this {{dissertation}} I analyse {{the transformation}} of the South African law on the warranty against <b>latent</b> defects. I <b>trace</b> the development from pre-classical Roman law through to the enactment of the Consumer Protection Act 68 of 2008 (“the CPA”). Society’s ever-changing economic requirements and moral ideals serve as the driving forces behind these continuous legal developments. Under Roman law the rules on latent defects initially applied to the sale of slaves. In contrast, modern South African law, as per the CPA and the values of the Constitution of the Republic of South Africa, 1996, specifically aims to protect the most vulnerable members of South Africa’s unequal society. The conservative approach adopted by the judiciary when adjudicating contractual matters hinders {{the transformation of}} the law of sale. Legal rules and legal thinking which reinforce traditional distributive patterns require reconsideration if societal-wide change, as demanded by the Constitution, can be imagined and accomplished. If the economic role of the contract and its power to divide and (re) distribute wealth is viewed as important, the link between poverty and the contract, and by association the consumer agreement, cannot be ignored. Contracts, and specifically basic consumer and credit agreements, are often concluded in order to facilitate survival in our current social reality. The law as it relates to consumer protection and the sale of defective goods {{is directly related to the}} contract’s role in wealth distribution. Where sales agreements are in question, the unequal bargaining power of the parties can impede the purchaser/consumer even further. The consumer’s right to good quality and safe goods creates uncertainty regarding whether or not the seller’s liability under the common law warranty against latent defects may be excluded in instances where the CPA and the common law apply simultaneously. This uncertainty, if addressed as being part of the national project of transformative constitutionalism, the only conclusion that can be drawn is that the exclusion of the seller’s liability is, paradoxically, detrimental to the very subject that the CPA and Constitution aim to protect, namely the purchaser. Dissertation (LLM) [...] University of Pretoria, 2015. tm 2015 Private LawLLMUnrestricte...|$|R
40|$|Questioned {{documents}} are often received into the forensic laboratories of the NSW Police Force requiring examination for both <b>trace</b> DNA and <b>latent</b> indentations using the Electrostatic Detection Apparatus (ESDA®). Recently, these documents have included extortion notes, threatening letters and white powder instances. Debate often arises {{as to what}} is the best sequence of examinations. This is a difficult question to answer and assessments need to be made on a case-­‐by-­‐case basis. The difficulty arises because unless there is an obvious bloodstain on the document it is impossible {{to determine whether or not}} trace DNA may be present. The other important consideration is that the tape lifting process adversely affects the recovery of indentations from a questioned document. This leaves investigators with the quandary of which evidence type to risk compromising. The results of this research confirmed that it is inherently difficult to recover trace DNA from a document using the tape lifting method. Even when relatively large quantities of DNA were placed in a specified area on a document, the recovery rate was extremely low. Despite the placement difficulties, two significant findings were made. Firstly, successful DNA profiles were obtained from tape lifted samples taken after an ESDA® examination had taken place. Secondly, DNA can be transferred from a questioned document to the underside of the Mylar® film during an ESDA® examination. Swabs taken from the Mylar® showed that full and partial DNA profiles were successfully obtained. The research also showed that tape lifting a document prior to an ESDA® examination had a severely adverse effect on the ability of the ESDA® to recover and develop indentations. At worst, the tape lift can cause tears and areas of the paper’s surface to be lifted whilst at the same time effectively ‘pulling’ the indentations out of the paper (making them difficult to detect). At best, there is fibre disturbance that causes the development of background noise on the ESDA foil reducing the visibility, definition and legibility of the developed indentations. Given these findings, important consideration needs to be given to documents requiring examinations for both <b>latent</b> indentations and <b>trace</b> DNA to ensure that neither examination is compromised. In cases where it is decided that both examinations are required, the ESDA examination should be conducted before tape lifting for trace DNA...|$|R

