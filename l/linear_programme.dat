72|48|Public
5000|$|A major {{strength}} of goal programming is its simplicity {{and ease of}} use. This accounts for {{the large number of}} goal programming applications in many and diverse fields. Linear Goal programmes can be solved using linear programming software as either a single <b>linear</b> <b>programme,</b> {{or in the case of}} the lexicographic variant, a series of connected linear programmes. [...] Goal programming can hence handle relatively large numbers of variables, constraints and objectives. A debated weakness is the ability of goal programming to produce solutions that are not Pareto efficient. This violates a fundamental concept of decision theory, that is no rational decision maker will knowingly choose a solution that is not Pareto efficient. However, techniques are available [...] to detect when this occurs and project the solution onto the Pareto efficient solution in an appropriate manner.|$|E
40|$|We {{show how}} to obtain bounds on the mean {{treatment}} effects by solving a simple linear programming problem. The {{use of a}} <b>linear</b> <b>programme</b> is convenient from a practical point of view because it avoids the need to derive closed form solutions. Imposing or omitting monotonicity or concavity restrictions is done by simply adding or removing sets of linear restrictions to the <b>linear</b> <b>programme...</b>|$|E
40|$|A <b>Linear</b> <b>Programme</b> (LP) {{involves}} a conjunction of linear constraints {{and has a}} well defined dual. It is shown that if we allow the full set of Boolean connectives {and, or, sim} applied {{to a set of}} linear constraints we get a model which we define as a Logical <b>Linear</b> <b>Programme</b> (LLP). This also has a well defined dual preserving most of the properties of LP duality. Generalisations of the connectives are also considered together with the relationship with Integer Programming formulation...|$|E
40|$|Geometric duality {{theory for}} {{multiple}} objective <b>linear</b> <b>programmes</b> {{is used to}} derive a dual variant of Benson’s outer approximation algorithm to solve multiobjective <b>linear</b> <b>programmes</b> in objective space. We also suggest some improvements of the original version of the algorithm and prove that solving the dual provides a weight set decomposition. We compare both algorithms on small illustrative and on practically relevant examples...|$|R
40|$|The {{decomposition}} algorithm for {{the solution}} of large-scale <b>linear</b> <b>programmes</b> has been interpreted by Baumol and Fabian (Management Science, September, 1964) as a procedure for decentralized decision by the multi-division company or the multi-sector economy. While commenting {{on the possibility of}} decentralization in this context, they maintain that an economy's optimum point will not in general yield a sectoral optimum. The present note demonstrates that this contention is not valid. ...|$|R
40|$|It {{is pointed}} out {{that a number of}} {{practical}} problems can be formulated as <b>linear</b> <b>programmes</b> whose duals are network flow models. The interpretation of these networks in relation to the original problem can be highly illuminating. If, as is frequently the case, the objective of the original problem is monetary, the network dual concerns the optimal pattern of re-allocation of money. It is suggested that the conceptual simplicity of a network makes this an attractive way to view problems as well as indicating efficient computational procedures...|$|R
40|$|We {{consider}} pricing of American contingent claims (ACC) as well {{as their}} special cases, in a multi-period, discrete time, discrete state space setting. Until now, determining the buyer's price for ACCs required solving an integer programme unlike European contingent claims for which solving a <b>linear</b> <b>programme</b> is sufficient. However, we show that a relaxation of the integer programming problem that is a <b>linear</b> <b>programme,</b> can be used to get the same lower bound for the price of the ACC. © 2009 Taylor & Francis...|$|E
40|$|The subtour centre {{problem is}} the problem of finding a closed trail S of bounded length on a {{connected}} simple graph G that minimises the maximum distance from S to any vertex ofG. It is a central location problem related to the cycle centre and cycle median problems (Foulds et al., 2004; Labbé et al., 2005) and the covering tour problem (Current and Schilling, 1989). Two related heuristics and an integer <b>linear</b> <b>programme</b> are formulated for it. These are compared numerically using a range of problems derived from tsplib (Reinelt, 1995). The heuristics usually perform substantially better then the integer <b>linear</b> <b>programme</b> and {{there is some evidence that}} the simpler heuristics perform better on the less dense graphs that may be more typical of applications...|$|E
40|$|In the {{previous}} section, we presented the Simplex Method. This method {{turns out to}} be very efficient for solving linear programmes in practice. While it is known that Gaussian elimination can be implemented in polynomial time, the number of pivot rules used throughout the Simplex Method may be exponential. More precisely, Klee and Minty gave an example of a <b>linear</b> <b>programme</b> such that the Simplex Method goes through each of the 2 n extreme points of the corresponding polytope [5]. In this chapter, we survey two methods for solving linear programmes in polynomial time. On the one hand, the Ellipsoid Method [4, 2] is not competitive with the Simplex Method in practice but it has important theoretical side-effects. On the other hand, the Interior Point Methods compete with the Simplex Method in practice. First of all, we define the input size of a <b>linear</b> <b>programme.</b> Recall that an integer i ∈ Z can be encoded using = log 2 (|i | + 1) + 1 bits. For a rational number r = p/q ∈ Q, the size of r is = + . Similarly, any rational matrix can be encoded using = ∑ m i= 1 ∑ n j= 1 bits. Also, multiplying two integers a and b runs in time O( + ). In what follows, we consider the <b>linear</b> <b>programme</b> L defined by: Maximize Subject to: cT x Ax ≤ b x ≥...|$|E
5000|$|The initial goal {{programming}} formulations {{ordered the}} unwanted deviations {{into a number}} of priority levels, with the minimisation of a deviation in a higher priority level being infinitely more important than any deviations in lower priority levels. This is known as lexicographic or pre-emptive goal programming. Ignizio gives an algorithm showing how a lexicographic goal programme can be solved as a series of <b>linear</b> <b>programmes.</b> Lexicographic goal programming should be used when there exists a clear priority ordering amongst the goals to be achieved.|$|R
40|$|In {{this paper}} we propose the {{integration}} of column generation in the revised normal boundary intersection (RNBI) approach to compute a representative set of non-dominated points for multi-objective <b>linear</b> <b>programmes</b> (MOLPs). The RNBI approach solves single objective <b>linear</b> <b>programmes,</b> the RNBI subproblems, to project a set of evenly distributed reference points to the non-dominated set of an MOLP. We solve each RNBI subproblem using column generation, which moves the current point in objective space of the MOLP towards the non-dominated set. Since RNBI subproblems may be infeasible, we attempt to detect this infeasibility early. First, a reference point bounding method is proposed to eliminate reference points that lead to infeasible RNBI subproblems. Furthermore, different initialisation approaches for column generation are implemented, including Farkas pricing. We investigate {{the quality of the}} representation obtained. To demonstrate the efficacy of the proposed approach, we apply it to an MOLP arising in radiotherapy treatment design. In contrast to conventional optimisation approaches, treatment design using column generation provides deliverable treatment plans, avoiding a segmentation step which deteriorates treatment quality. As a result total monitor units is considerably reduced. We also note that reference point bounding dramatically reduces the number of RNBI subproblems that need to be solved...|$|R
40|$|AbstractThe {{fractional}} analogues {{of domination}} and 2 -packing in a graph form an interesting pair of dual <b>linear</b> <b>programmes</b> {{in that the}} feasible solutions for both are functions from the vertices of the graph to the unit interval; efficient (fractional) domination is accomplished when one function simultaneously solves both LPs. We investigate some structural properties of the functions thus defined and classify some families of graphs according to how and whether the sets of functions intersect, developing tools that have proven useful in approaching problems in domination theory...|$|R
40|$|The {{augmented}} Lagrangian and Newton {{methods are}} used to simultaneously solve the primal and dual linear programming problems. The proposed approach {{is applied to the}} primal linear programming problem with a very large number (≈ 106) of nonnegative variables and a moderate (≈ 103) number of equality-type constraints. Computation results such as the solution of a <b>linear</b> <b>programme</b> with 10 million primal variables are presented...|$|E
40|$|Lots of {{combinatorial}} {{problems are}} very close to linear programmes. Indeed they can be formulated as a <b>linear</b> <b>programme</b> with the extra requirement that some of the variable be integers (and not real). Such programmes are called integer linear programmes. For example, consider MAXIMUM MATCHING, which is the problem of finding the largest matching in a graph. Recall that a matching in a graph is a set of pairwise non-adjacent edges. The size of a largest matching in a graph G is denoted by µ(G). With any matching M of a graph G, we may associate its (0, 1) -valued indicator vector x (that is xe = 1 if e ∈ M and xe = 0 otherwise). Since no matching has more than one edge incident with any vertex, every such vector x satisfies the constraint ∑e v xe ≤ 1, for all v ∈ V. Thus an instance of MAXIMUM MATCHING may be formulated as the following integer <b>linear</b> <b>programme.</b> Maximize ∑e∈E xe subject to: ∑e v xe ≤ 1 xe ∈ IN for all v ∈ V for all e ∈...|$|E
40|$|The <b>linear</b> <b>programme</b> and its {{constraints}} {{are split}} into two parts. The first consists of the traditional structure, the second being akin to goal programming. SOFT constraints are weighted relative {{to each other and}} then approximately weighted relative to the HARD constraints. The LP is run four times giving different emphasis to the SOFT and HARD constraints. The manager requesting the LP has then to decide which gives the most appropriate solution. ...|$|E
40|$|Systems {{of energy}} technology, {{encompassing}} processes of supply, conversion, transport and final use, can be modelled by <b>linear</b> <b>programmes</b> with annual flows and capacities as variables. In other national or international projects highly disaggregated and comprehensive {{models have been}} developed, each model being designed to solve a broad class of problems. A different but complementary approach has been taken by ECN: rather than one such general model software tools have been constructed facilitating implementation of a general class of simple specific problem-oriented models. This approach was chosen {{in order to have}} a more flexible response to the varying needs of policy makers...|$|R
40|$|This study breaks {{important}} new {{ground in the}} analysis of financial institutions. It {{is one of the first}} empirical uses of Stochastic Data Envelopment Analysis (SDEA) in the efficiency literature. The pattern of efficiency is examined for the year 1999. The purpose of stochastic setting of DEA is two-fold: to accommodate both the inefficiency and the presence of measurement errors; and to convert the resulting stochastic <b>linear</b> <b>programmes</b> for DEA into deterministic non-linear DEA programmes. The results show that there are wide variations in the DEA efficiency scores and SDEA results suggest that these are due to measurement errors or other stochastic factors in the raw data, probably attributable to macroeconomic shocks and issues of changes in banking regulations...|$|R
40|$|The article {{deals with}} {{findings}} concer­ ning {{development of a}} programme for adult learners, the term programme being used along with the term curriculum. An educational programme for adults is a process and as such always in progress. It encompasses preliminary procedures and content programming as well as planning the programme and evaluation. Program­ me models can be either integral or no­ nintegral, integral being those which ma­ ke use of professional findings for pro­ gramme development. Integral program­ mes can be further divided into linear and nonlinear ones. <b>Linear</b> <b>programmes</b> seem to be mostly focusing on adult education didactics while the nonlinear ones are more open since they integrate many other factors...|$|R
40|$|Multiplicative {{programming}} problems (MPPs) are global optimization problems {{known to}} be NP-hard. In this paper, we employ algorithms developed to compute the entire set of nondominated points of multi-objective linear programmes (MOLPs) to solve linear MPPs. First, we improve our own objective space cut and bound algorithm for convex MPPs in the special case of linear MPPs by only solving one <b>linear</b> <b>programme</b> in each iteration, instead of two as the previous version indicates. We call this algorithm, {{which is based on}} Benson’s outer approximation algorithm for MOLPs, the primal objective space algorithm. Then, based on the dual variant of Benson’s algorithm, we propose a dual objective space algorithm for solving linear MPPs. The dual algorithm also requires solving only one <b>linear</b> <b>programme</b> in each iteration. We prove the correctness of the dual algorithm and use computational experiments comparing our algorithms to a recent global optimization algorithm for linear MPPs from the literature as well as two general global optimization solvers to demonstrate the superiority of the new algorithms in terms of computation time. Thus, we demonstrate that the use of multi-objective optimization techniques can be beneficial to solve difficult single objective global optimization problems...|$|E
40|$|The Dependency Diagram of a <b>Linear</b> <b>Programme</b> (LP) {{shows how}} the {{successive}} inequalities of an LP depend on former inequalities, when variables are projected out by Fourier–Motzkin Elimination. It is also explained how redundant inequalities can be removed, using the method attributed to Chernikov and to Kohler. Some new results are given. The procedure also leads to a transparent explanation of Farkas’ Lemma, LP Duality, the dual form of Caratheodory’s Theorem as well as generating all vertices and extreme rays of the Dual Polytope...|$|E
40|$|Outcome space methods {{construct}} {{the set of}} nondominated points in the objective (outcome) space of a multiple objective <b>linear</b> <b>programme.</b> In this paper, we employ results from geometric duality theory for multiple objective linear programmes to derive a dual variant of Benson’s “outer approximation algorithm” to solve multiobjective linear programmes in objective space. We also suggest some improvements of the original version of the algorithm and prove that solving the dual provides a weight set decomposition. We compare both algorithms on small illustrative and on practically relevant examples...|$|E
40|$|This paper {{considers}} fluid analogues for {{the standard}} linear programming problem and for a separable nonlinear programming problem. In the former case the usual duality results are demonstrated using the principle of minimum potential energy. In addition by examining {{the dynamics of the}} system a new method, referred to as the R-method, is derived for solving <b>linear</b> <b>programmes,</b> although it is not demonstrated that this has any computational advantages over the standard simplex method, except that degeneracy causes no problems. In the nonlinear case the weak Lagrangian principle is derived. The purpose of the paper is to demonstrate that analogue methods, while being impracticable as a physical method of solving optimisation problems, may give some insight into computational algorithms via dual energy concepts and/or dynamic behaviour. ...|$|R
40|$|AbstractThis article {{proposes a}} {{multi-currency}} cross-hedging strategy that minimizes the exchange risk. The use of derivatives in {{small and medium-sized}} enterprises (SMEs) is not common but, despite its complexity, can be interesting for those with international activities. In particular, the reduction in the exchange risk borne through the use of natural multi-currency cross-hedging is measured, considering Conditional Value-at-Risk (CVaR) and Value-at-Risk (VaR) for measuring market risk instead of the variance. CVaR is minimized using <b>linear</b> <b>programmes,</b> while a multiobjective genetic algorithm is designed for minimizing VaR, considering two scenarios for each currency. The results obtained show that the optimal hedge strategy that minimizes VaR is different from the minimum CVaR hedge strategy. A very interesting point is that, just by investing in other currencies, a significant risk reduction in VaR and CVaR can be obtained...|$|R
40|$|Linear {{programming}} {{model and}} general reciprocity theorem in mathematical programming {{are used to}} ap-proach utility functions of six large-scale Russian (the Moscow Region) case farms representing different production patterns. Technological coefficients of <b>linear</b> <b>programmes</b> are defined by means of linear regression. The data over 311 farms operating in the Moscow Region in 1999 are used. The utility functions include depreciation, wages and social costs. These attributes are about as desirable for the farms as profit. Milk production is associated with hidden utility amounting to a quarter of total utility. Vegetables market imperfections result from high price elasticity with respect to supply (– 0. 46). The scarcity of operating capital severely hampers agricultural production. linear programming, general reciprocity theorem, Leontieff technologies, farm behaviour, Russian agriculture, case farm, utility function, operating capital. ...|$|R
40|$|In {{this thesis}} we propose {{the use of}} network coding to improve the energy {{efficiency}} in core networks, by reducing the resources required to process traffic flows at intermediate nodes. We study the energy efficiency of the proposed scheme through three approaches: (i) developing a mixed integer <b>linear</b> <b>programme</b> (MILP) to optimise the use of network resources. (ii) developing a heuristic based on minimum hop routing. (iii) deriving an analytical bounds and closed form expressions. The results of the MILP model show that implementing network coding over typical networks can introduce savings up to 33...|$|E
40|$|The Dependency Diagram of a <b>Linear</b> <b>Programme</b> (LP) {{shows how}} the {{successive}} inequalities of an LP depend on former inequalities, when variables are projected out by Fourier- Motzkin Elimination. This is explained in a paper referenced below. The paper, given here, extends the results to the Mixed Integer case (MILP). It is shown how projection of a MILP leads to a finite disjunction of polytopes. This is expressed {{as a set of}} inequalities (mirroring those in the LP case) augmented by correction terms with finite domains which are subject to linear congruences...|$|E
40|$|Multi-document {{summarization}} involves {{many aspects}} of content selection and sur-face realization. The summaries must be informative, succinct, grammatical, and obey stylistic writing conventions. We present a method where such individual aspects are learned separately from data (without any hand-engineering) but optimized jointly using an integer <b>linear</b> <b>programme.</b> The ILP framework allows us to combine {{the decisions of the}} expert learners and to select and rewrite source content through a mixture of objective setting, soft and hard constraints. Experimental results on the TAC- 08 data set show that our model achieves state-of-the-art performance using ROUGE and signifi-cantly improves the informativeness of the summaries. ...|$|E
40|$|We {{develop a}} {{queueing}} model characterizing explicitly {{the impact of}} interference on end-to-end performance measures such as throughput in ad hoc networks, emphasizing the performance trade-off between single-path and multi-path routing. It may seem attractive to employ multi-path routing, but as all nodes share a single channel, efficiency may drop due to increased interference levels thus yielding singlepath performance for some topologies. We formulate a nonlinear programming problem to optimize network performance. Next, we focus on network capacity and show that for this objective the optimum could be found by solving an exponential number of <b>linear</b> <b>programmes.</b> We propose a greedy algorithm that efficiently searches these programmes to approximate the optimal solution. Numerical results for small topologies provide structural insight in optimal path selection and demonstrate the excellent performance of the proposed algorithm. Besides, larger networks and more advanced scenarios with multiple source-destination pairs and different radio ranges are analyzed...|$|R
40|$|The {{earlier version}} of this study was {{presented}} at the INFORMS International Hawaii Conference, Maui, Hawaii, USA, June 17 - 20, 2001. This paper is also available from the EPRU website at [URL] study breaks important new ground in the analysis of financial institutions. It {{is one of the first}} empirical uses of Stochastic Data Envelopment Analysis (SDEA) in the efficiency literature. The pattern of efficiency is examined for the year 1999. The purpose of stochastic setting of DEA is two-fold: to accommodate both the inefficiency and the presence of measurement errors; and to convert the resulting stochastic <b>linear</b> <b>programmes</b> for DEA into deterministic non-linear DEA programmes. The results show that there are wide variations in the DEA efficiency scores and SDEA results suggest that these are due to measurement errors or other stochastic factors in the raw data, probably attributable to macroeconomic shocks and issues of changes in banking regulations...|$|R
40|$|Abstract. We {{develop a}} {{queueing}} model characterizing explicitly {{the impact of}} interference on end-to-end performance measures such as throughput in ad hoc networks, emphasizing the performance trade-off between single-path and multi-path routing. It may seem attractive to employ multi-path routing, but as all nodes share a single channel, efficiency may drop due to increased interference levels thus yielding singlepath performance for some topologies. We formulate a nonlinear programming problem to optimize network performance. Next, we focus on network capacity and show that for this objective the optimum could be found by solving an exponential number of <b>linear</b> <b>programmes.</b> We propose a greedy algorithm that efficiently searches these programmes to approximate the optimal solution. Numerical results for small topologies provide structural insight in optimal path selection and demonstrate the excellent performance of the proposed algorithm. Besides, larger networks and more advanced scenarios with multiple source-destination pairs and different radio ranges are analyzed. Keywords: Ad hoc networks, Interference, Capacity, Multi-path routing, Network optimization...|$|R
40|$|The {{purpose of}} this paper is to explain the {{property}} of Disjunctive Formulations for Mixed Integer Programmes in a simpler way, relying on the <b>Linear</b> <b>Programme</b> (LP) definition of a dual. Disjunctive Formulations are contrasted with standard formulations. They have proved a very powerful way of modelling Integer Programmes. If a ‘complete’ disjunctive formulation is carried out we have a model whose LP Relaxation yields an integer solution. It is shown that a Disjunctive Formulation has a natural dual which is an LP. Therefore the dual of the dual is an LP representation of the original Disjunctive Model. It is in fact a Disjunctive Formulation...|$|E
3000|$|The {{objective}} function contains a deterministic term c^T x and {{the expectation of}} the second-stage objective q([...] ω)^T y([...] ω) taken over all realizations of the random event ω. The first-stage decisions are represented by the vector x and matrices c, b and A. In the second stage, a number of random events ω∈ (Ω denotes the set of all possible scenarios and ω a particular scenario) may be realized. For each ω, the value y([...] ω) is the solution of a <b>linear</b> <b>programme.</b> For a given realization ω, the second-stage problem data q([...] ω), h ([...] ω), and T ([...] ω) become known. Each component of q, h, and T is thus a possible random variable.|$|E
40|$|We {{explore the}} robust {{replication}} of forward-start straddles given quoted (Call and Put options) market data. One {{approach to this}} problem classically follows semi-infinite linear programming arguments, and we propose a discretisation scheme to reduce its dimensionality and hence its complexity. Alternatively, one can consider the dual problem, consisting in finding optimal martingale measures under which the upper and the lower bounds are attained. Semi-analytical solutions to this dual problem were proposed by Hobson and Klimmek (2013) and by Hobson and Neuberger (2008). We recast this dual approach as a finite dimensional <b>linear</b> <b>programme,</b> and reconcile numerically, in the Black-Scholes and in the Heston model, the two approaches. Comment: 20 pages, 20 figure...|$|E
40|$|The {{concept of}} {{maximising}} present value {{is applied to}} the timing of activities in a network. The mathematical form {{of the problem is that}} of maximising a nonlinear function subject to linear constraints and can be solved as a succession of <b>linear</b> <b>programmes.</b> By application of duality principles the problem can be treated as a form of maximum value flow problem in which discounted cash flows are distributed along arcs from pay events to receipt events. The solution is aided by the "equilibrium theorem" of dual linear programming in that in the optimum condition flows occur only along arcs whose corresponding activity has zero float. The flows which occur in the optimally scheduled solution are directly proportional to the marginal cost which would be incurred by lengthening the activity corresponding to the arc along which the flow occurs. Some implications derived from the model are discussed and a number of possible applications are proposed. ...|$|R
40|$|In the paper, {{a typical}} coal trade process is {{described}} and modelled, where one logistics enterprise with blending equipments {{lies in the}} core and two types of common contracts are elucidated to define constraints. A mixed-integer model is built and featured by addressing contract violation, blending operation, real-time price information and arbitrarily distributed stochastic demands. To deal with the stochastic demands, probabilistic constraints are formed. Accordingly, stochastic model predictive control strategy with both receding horizon and decreasing horizon formulations is developed to handle the probabilistic constraints and exploit the value of newest price information. By solving a series of mixed-integer <b>linear</b> <b>programmes,</b> optimal coal trade decisions for the logistics enterprise can be obtained, including procurement decision, selling decision and operational decision of the blending equipments. Thorough simulation experiments are carried out and compared with three different strategies, which interpret {{the effectiveness of the}} proposed strategy. In part by the National Natural Science Foundation of China [61304090] and the Department of Education of Liaoning Province, China [L 2013132]. [URL]...|$|R
40|$|Most {{approaches}} to multi-project scheduling {{are based on}} the assumption that resources can be transferred between projects without any expense in time and cost. As this assumption often is not realistic, we generalise the multi-project scheduling problem (RCMPSP) by additionally including transfer times and cost. To integrate this aspect, in a first step, we develop a framework for considering resource transfers in single and multi-project environments. It includes managerial {{approaches to}} handle resource transfers, a classification of resource transfer types and new roles that resources can take in these transfers. Afterwards, we define the multi-project scheduling problem with transfer times (RCMPSPTT) and formulate it in a basic and an extended version as integer <b>linear</b> <b>programmes.</b> Eventually, it is supplemented for the first time by cost considerations and introduced as resource constrained multi-project scheduling problem with transfer times and cost (RCMPSPTTC). Computational experiments compare the presented managerial approaches and prove the necessity of explicitly considering transfer times in project scheduling. Moreover, the experiments evaluate the presented MIP models and show that specialised solution procedures are vital. project scheduling - combinatorial optimization - mathematical model - transfer times - transfer cost - setup - resource flow...|$|R
