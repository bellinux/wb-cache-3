20|36|Public
50|$|Electric Word was a bimonthly, English-language {{magazine}} {{published in}} Amsterdam between 1987 and 1990 that offered eclectic {{reporting on the}} translation industry, <b>linguistic</b> <b>technology,</b> and computer culture. Its editor was Louis Rossetto and it featured avant-garde graphics by the Dutch graphic designer Max Kisman.|$|E
5000|$|Research & Development is {{the core}} of the company’s {{activities}} and so MLS Multimedia has been engaging in various partnerships and research programs while providing its expertise to third parties by developing and supporting applications in the fields of educational technology, <b>linguistic</b> <b>technology,</b> telematics and multimedia applications. A non exhaustive list of European projects where MLS has participated in is shown below: ...|$|E
50|$|<b>Linguistic</b> <b>technology</b> {{generally}} includes {{at least}} translation memory and terminology database; some systems also integrate machine translation technology. Translation memory is {{a database of}} all previously translated sentences. While a translator performs translation, {{he or she is}} automatically prompted with similar sentences from the memory that were previously translated. A terminology database is a glossary that contains specific words and phrases and their context-appropriate translations. A machine translation system is a program that uses natural language processing technology to automatically translate a text from one language to another.|$|E
30|$|Other {{technologies}} exploited in the Butler’s scenario {{range from}} <b>linguistic</b> <b>technologies</b> to geo-localisation, information grabbing, geo-mapping technologies, up to artificial intelligence.|$|R
40|$|AbstractThe {{earliest}} {{and most}} basic <b>linguistic</b> <b>technologies</b> are frequency lists and the concordance lines from a corpus. Although these technologies {{have been available}} for many years we are only now discovering their uses in language instruction. My talk will present the main instructional uses of lists and lines that are emerging, and show ways that language instructors are not only employing these <b>linguistic</b> <b>technologies</b> but also contributing to their further development through incorporation of the cognitive and affective dimensions of language learning. All ideas and theories will be presented {{in the context of}} real-life applications (mainly via the Compleat Lexical Tutor website (at www. lextutor. ca), and participants will leave with ideas and tools for immediate use in course design and execution...|$|R
40|$|The paper {{entitled}} «Linguistic, {{psychological and}} methodical aspects of using argumentative phrases to render {{and interpret the}} text» deals with the <b>linguistic</b> <b>technologies</b> of influence, {{as well as the}} methods employed to teach them in classroom. The article gives an abound number of phrases having a pragmatic potential in argumentative articles and speeches and dwells on the necessity of their comprehensive psycholinguistic classification...|$|R
5000|$|A {{globalization}} {{management system}} (GMS) {{is a type}} of software for automating many parts of the human language translation process and maximizing translator efficiency. The ideal of a globalization management system is to automate all repeatable and non-essential work that can be done by software/systems and leaving only the creative work of translation and review to be done by human beings. A globalization management system generally includes at least two types of technology: process management technology to automate the flow of work, and <b>linguistic</b> <b>technology</b> to aid the translator.|$|E
40|$|In this article, we {{pretend to}} show a series of {{software}} applications on <b>Linguistic</b> <b>Technology</b> (ATL is the acroym in Spanish) and others Spanish-like-foreign-language (ELE) teaching/learning resources on-line (Internet resources). Our classification has four kinds of resources: a) writing helpers, b) verbal conjugers, c) verbal gramatic information webpages, and d) verbal practice exercises. We identify the contexts of the ELE classroom development where it's suitable to use these resources. At last, we offer a scholars template to evaluate this resources usage...|$|E
40|$|By {{the time}} Machine Translation Summit X {{is held in}} September 2005, our group will have {{released}} an open-source machine translation toolbox {{as part of a}} large government-funded project involving four universities and three <b>linguistic</b> <b>technology</b> companies from Spain. The machine translation toolbox, which will most likely be released under a GPL-like license includes (a) the open-source engine itself, a modular shallow-transfer machine translation engine suitable for related languages and largely based upon that of systems we have already developed, such as interNOSTRUM for Spanish—Catalan and Traductor Universia for Spanish—Portuguese, (b) extensive documentation (including document type declarations) specifying the XML format of all linguistic (dictionaries, rules) and document format management files, (c) compilers converting these data into the high-speed (tens of thousands of words a second) format used by the engine, and (d) pilot linguistic data for Spanish—Catalan and Spanish—Galician and format management specifications for the HTML, RTF and plain text formats. After describing very briefly this toolbox, this paper aims at exploring possible consequences of the availability of this architecture, including the community-driven development of machine translation systems for languages lacking this kind of <b>linguistic</b> <b>technology.</b> The development of the toolbox is funded by project FIT- 340101 - 2004 - 3 (Spanish Ministry of Industry, Commerce and Tourism) ...|$|E
40|$|This paper {{presents}} an on-going project aiming at enhancing the OPAC (Online Public Access Catalog) search {{system of the}} Library of the Free University of Bozen-Bolzano with multilingual access. The Multilingual search system (MUSIL), we have developed, integrates advanced <b>linguistic</b> <b>technologies</b> in a user friendly interface and bridges {{the gap between the}} world of free text search and the world of conceptual librarian search. In this paper we present the architecture of the system, its interface and preliminary evaluations of the precision of the search results. 1. The problem In this paper, we present the MUSIL (MUltilingual Search In Libraries) system developed within an on-going project on the enhancement of an OPAC (Online Public Access Catalog) search system with multilingual access. The project aims at integrating advanced <b>linguistic</b> <b>technologies</b> in a user friendly interface and bridging the gap between the world of free text search and the world of conceptual librarian search...|$|R
40|$|There are {{numerous}} projects at the University of Memphis Institute for Intelligent Systems (IIS) that involve {{a marriage of}} natural language processing, computational linguistics, psychology, and educational technologies. We use natural language and computational <b>linguistic</b> <b>technologies</b> to accomplish a variety of goals related to psychology and educational practice, including text analysis {{and the development of}} interactive tutoring systems. This paper describes these technologies and some of our computational methods. ...|$|R
40|$|Part 8 : ADVANCED FORENSIC TECHNIQUESInternational audienceBiometric {{technologies}} offer a new {{and effective}} means for securing computers against unauthorized access. <b>Linguistic</b> <b>technologies</b> and, in particular, authorship attribution technologies can assist in this effort. This paper reports {{on the results of}} analyzing a novel corpus that was developed to test the possibility of active linguistic authentication. The study collected the one-week work product of nineteen temporary workers in a simulated office environment. The results demonstrate that techniques culled from the field of authorship attribution can identify workers with more than 90 % accuracy...|$|R
40|$|In {{the first}} part of this paper text mining (TM) is {{examined}} following three main dimensions: sectors of interest, from financial domain to health sector, from media and communication to public administration; kind of applications, from customer relationship management (CRM) and market analysis to technology watch (TW) and patent analysis (PA); paradigmatic scheme of strategy (document pre-processing, lexical and TM processing). We also report some results of a survey on text analysis traditions in Italy and some of the most relevant Italian company experiences in the domain of production of <b>linguistic</b> <b>technology</b> and TM solutions. In the second part of the paper, we describe briefly some examples of TM applications in particular for CRM, TW, and PA, mined from the Internet...|$|E
40|$|Language {{operates}} {{according to}} rules. Rules mean prediction. The {{application of these}} language rules to persuasive campaigns through <b>linguistic</b> <b>technology</b> can result in major gains in advertising, political and marketing outcomes. For qualitative researchers in communications, marketing and messaging, one area of persuasive language technology {{can be found in}} the linguistic feature of symmetry. Language has many forms of symmetry, and most persuaders are unaware that a great deal of persuasion depends upon symmetrical message structures. In persuasion, a mirror image or symmetrical reflection of an attitude or opinion is more persuasive than a random or non-symmetrical message or idea. Reading the subtle features of language to create symmetrical responses can create extraordinarily successful results for research and applied persuasive efforts ranging from single interviews to mass marketing campaigns...|$|E
40|$|Motivational {{profiling}} {{is commonly}} done in both marketing and forensic contexts. In an unabashed quest for creativity, many marketer s use projective psychological techniques {{to search for}} inspiration that leads to ad concepts that will, ultimately, sell more products. Forensic professionals also seek predictive information about motivation in search of facts that will effectively lead to the capture and handling of criminals by using the recent advances found in <b>linguistic</b> <b>technology.</b> Projective profiling techniques produce very soft, opinionated data that are open to interpretation and which has only random relevance to predicting customer behavior. In contrast, linguistic profiling techniques produce hard data that are reliable, valid and very powerful in predicting behavior. The differences in process and results between the creative versus linguistic profiling are compared. Linguistic profiling is clearly the superior approach if prediction of behavior is at issue...|$|E
40|$|In {{this paper}} we present the European Union-funded eContent project WebALT?Web Advanced Learning Technologies. The authors 2 ̆ 7 group is {{building}} a "significant application which exploits a combination of existing standards for representing mathematics on the web (e. g. MathML and OpenMath) and <b>linguistic</b> <b>technologies</b> in order to enable the creation of language-independent mathematical content" {{in the form of}} a web-based repository of exercises for mathematics students. This mathematical content will be particularly well suited for localization in a multilingual and multicultural environment, because problems will be stored in the language-independent form of content markup and generated for several linguistic and cultural contexts...|$|R
50|$|After the bankruptcy, Nuance Communications (known then as ScanSoft) {{acquired}} all of {{the speech}} technologies. The revenues of the company grew sharply from $17.1 million in third quarter of 2001, to $216 million in Q3 2008. Vantage Learning acquired {{all of the}} proofing, spelling, and <b>linguistic</b> search <b>technologies.</b>|$|R
40|$|The Open University of Catalonia (UOC) {{has set up}} a {{programme}} for {{the integration}} of automatised translation techniques and assisted translation in order to process the large amount of Catalan and Spanish teaching documents that its virtual courses produce. After revising the problem and various experiences with the application of these <b>linguistic</b> <b>technologies</b> when the bilingualism is actually implemented in organisations and units in the Catalan-speaking areas, this contribution explains the project’s nature and the work that has been carried out during its first year in operation. This work includes tasks like creating and administrating schemes of translation memories and of terminological databases, personnel training (of both users and professionals of the Linguistic Service), as well as designing and creating tools to automatise the pre-editing and post-editing of texts...|$|R
40|$|We give an {{overview}} of a MT research project jointly undertaken by Xerox PARC and XRCE Grenoble. The project builds on insights and resources in large-scale development of parallel LFG grammars. The research approach towards translation focuses on innovative computational technologies which lead to a flexible translation architecture. Efficient processing of "packed" ambiguities not only enables ambiguity preserving transfer. It {{is at the heart}} of a flexible architectural design, open for various extensions which take the right decisions at the right time. 1 Introduction Most of the existing high-performance MT systems are based on <b>linguistic</b> <b>technology</b> of the 60 s, whereas research in NLP has established "higher-level" syntactic formalisms which allow for specification and processing of declarative, reversible grammars that assign rich structures to natural language sentences. Syntactic theories like Lexical-Functional Grammar (LFG), Head-Driven Phrase Structure Grammar [...] ...|$|E
40|$|This article {{outlines}} our {{participation in}} the Question Answering Track of the Text REtrieval Conference organised by the National Institute of Standards and Technology. Having not taken part before, our objective was to study the task and build a simple working system capable of answering at least some questions correctly. Only three person weeks was available for the work but this proved sufficient to achieve our goal. The article is structured as follows. Firstly, some preliminaries such as our starting point, tools and strategy are described. After this, {{the architecture of the}} Documents and <b>Linguistic</b> <b>Technology</b> Group's DLT system is outlined. Thirdly, the question types analysed by the system are described along with the named entities with which they work. Fourthly, the runs performed are presented together with the results we obtained. Finally, conclusions are drawn based on our finding...|$|E
40|$|Professional patent searchers are {{traditionally}} rather {{suspicious of the}} alleged "black box" effect inherently attached to intelligent software engines relying upon linguistic technologies for patent analysis and mapping. In this article, the authors propose that such prejudices can be overcome by setting a realistic business objective while experimenting with these new linguistic tools, {{as well as by}} applying serious methodology for validating the results of the analysis. The strengths and weaknesses of a particular text mining tool are assessed with reference to a practical business case in the field of packaging technology, and a comparison of the outcome of such an analysis with a traditional one, carried out using conventional patent classifications, is also described. Text mining Data mining Patent mapping Patent analysis Clustering techniques Competitive intelligence Intellectually assigned patent classifications Results validation <b>Linguistic</b> <b>technology</b> Packaging technology...|$|E
50|$|The {{language}} {{system used}} in Praht Thai follows the British genre of English curricula with {{input from the}} developments of language instruction dating {{as far back as}} the 1970s combined with modern <b>linguistic</b> learning <b>technologies.</b> Much of the course design also reflects European language training methodologies which have been used successfully throughout Europe for decades.|$|R
40|$|Introduction This chapter {{explains}} the theory underlying the lexicon learning system which was implemented at the University of Stuttgart, and reviews the {{experiment with the}} induction of a German lexicon which were performed in the Sparkle project. 1 The problems which motivate our work relate to the complexity {{and size of the}} lexicon; to the massive ambiguity in grammatical analysis which is observed in naturally occurring language, particularly written language; and to the scale of the texts which we would like to analyze computationally. We believe that in order to address these problems, computational <b>linguistic</b> <b>technologies</b> should be based on a combination of symbolic and numerical modeling, should embody approximations together with exact theories, and should constructed in a way which makes it possible to learn much of the information which is deployed from large samples of language use. In the research described in this chapter, probability theory a...|$|R
40|$|The growing {{availability}} of multilingual resources, like EuroWordnet, has recently inspired {{the development of}} large scale <b>linguistic</b> <b>technologies,</b> e. g. multilingual IE and Q&A, that were considered infeasible {{until a few years}} ago. In this paper a system for categorisation and automatic authoring of news streams in different languages is presented. In our system, a knowledge-based approach to Information Extraction is adopted as a support for hyperlinking. Authoring across documents in different languages is triggered by Named Entities and event recognition. The matching of events in texts is carried out by discourse processing driven by a large scale world model. This kind of multilingual analysis relies on a lexical knowledge base of nouns(i. e. the EuroWordnet Base Concepts) shared among English, Spanish and Italian lexicons. The impact of the design choices on the language independence and the possibilities it opens for automatic learning of the event hierarchy will be discussed. ...|$|R
40|$|Since the eighties, new {{approaches}} {{in machine translation}} have been explored. These {{new approaches}} are usually based on statistical and pattern matching techniques. Currently, all SMT approaches are based on very large parallel corpora or bitexts. A statistical model is trained on these bitexts and then used to translate new sentences. One big disadvantage for this approach {{is the fact that}} for most languages, there are almost no large bitexts available. On the other hand, more and more reasonably large monolingual corpora are becoming available {{for a wide range of}} languages. The novelty in the METIS project is the elimination of the use of bitexts altogether. It aims to investigate the possibility of developing a reasonable SMT system without relying on bilingual corpora. Instead, the proposed system will rely on large corpora of monolingual texts, together with some standard <b>linguistic</b> <b>technology</b> and the use of a bilingual lexicon and tag-mapping rules. ...|$|E
40|$|Advances in {{statistical}} {{machine learning}} encourage language-independent approaches to <b>linguistic</b> <b>technology</b> development. Experiments in “porting ” technologies to handle new natural languages have revealed a {{great potential for}} multilingual computing, but also a frustrating lack of linguistic resources for most languages. Recent efforts to address the lack of available resources have focused either on intensive resource development for {{a small number of}} languages or development of technologies for rapid porting. The Linguistic Data Consortium recently participated in an experiment falling primarily under the first approach, the surprise language exercise. This article describes linguistic resource creation within this context, including the overall methodology for surveying and collecting language resources, as well as details of the resources developed during the exercise. The article concludes with discussion of a new approach to solving the problem of limited linguistic resources, one that has recently proven effective in identifying core linguistic resources for less common studied languages...|$|E
40|$|Abstract. We {{present the}} current status of {{development}} of an open-source shallow-transfer machine translation engine for the Romance languages of Spain (the main ones being Spanish, Catalan and Galician) {{as part of a larger}} government-funded project which includes non-Romance languages such as Basque and involving both universities and <b>linguistic</b> <b>technology</b> companies. The machine translation architecture uses finite-state transducers for lexical processing, hidden Markov models for part-of-speech tagging, and finite-state based chunking for structural transfer, and is largely based upon that of systems already developed by the Transducens group at the Universitat d'Alacant, such as interNOSTRUM (Spanish—Catalan) and Traductor Universia (Spanish—Portuguese). The possible scope of the project, however, is wider, since it will be possible to use the resulting machine translation system with new pairs of languages; to that end, the project also aims at proposing standard formats to encode the linguistic data needed. This paper briefly describes the machine translation engine, the formats it uses for linguistic data, and th...|$|E
40|$|We discuss {{problems}} with the standard approaches to evaluation for tasks like visual question answering, and argue that artificial data {{can be used to}} address these as a complement to current practice. We demonstrate that with the help of existing 'deep' <b>linguistic</b> processing <b>technology</b> we are able to create challenging abstract datasets, which enable us to investigate the language understanding abilities of multimodal deep learning models in detail...|$|R
40|$|This paper {{presents}} the platform targeted in the PROGRESS-IT project. It represents an Enterprise Semantic Search engine tailored for Small and Medium Sized Enterprises to retrieve information about Projects, Grants, Patents or Scientific Papers. The proposed solution improves the usability {{and quality of}} standard search engines through Distributional models of Lexical Semantics. The quality of the Keyword Search has been improved with Query Suggestion, Expansion and Result Re-Ranking. Moreover, the interaction with the system has been specialized for the analysts by defining a set of Dashboards designed to enable richer queries avoiding the complexity of their definition. This paper shows the application of <b>Linguistic</b> <b>Technologies,</b> such as the Structured Semantic Similarity function to measure the relatedness between documents. These are then used in the retrieval process, for example to ask the system for Project Ideas directly using an Organization Description as a query. The resulting system is based on Solr, inheriting its highly reliability, scalability and fault tolerance, providing distributed indexing, replication and load-balanced querying, automated failover and recovery, centralized configuration and more...|$|R
40|$|This poster {{features}} a digital collection of American Indian Sign Language (AISL) lexical signs, grammatical features, and discourse genres developed {{with support from}} the NEH and NSF’s Documenting Endangered Languages (DEL) program. The project involves the first fieldwork in over fifty years to focus on the linguistic status of AISL, today classified as a highly endangered language variety. The project brings together sign language linguists and members of the AISL signing communities to make sign language studies more accessible. It is incorporating emergent documentary <b>linguistic</b> <b>technologies</b> and using captions, voice-over, slow motion and careful explanation to share the AISL digital corpus with scholars and community members for linguistic and cultural studies and for language revitalization; thus, drawing attention to an important, yet sometimes overlooked part of American Indian cultural and linguistic heritage. A hallmark of the AISL digital corpus is that it encompasses two major types of data: historical linguistic legacy material and language documentation based on contemporary ethnographic fieldwork. Hence, the digital corpus includes both signed and spoken languages, spanning different cultural and geographic areas, and encompassing multiple linguistic modalities. It shows how indigenous sign language serves as an alternative to spoken language, how it is acquired as a first or second language, how it is used among deaf and hearing tribal members, as well as being used internationally as type of lingua franca. It brings attention to the urgent need to document both signed and spoken indigenous languages and for linguists and other scholars to collaborate with Indian communities where sign language continues to be learned and used. The project involves expert signers from different American Indian nations (Blackfeet/Blackfoot, Cheyenne, Crow, and Assiniboine, among others). It provides descriptions of indigenous sign language patterns of use and lexical-grammatical features. In this manner, the AISL project’s digital corpus encompasses more than one endangered language and demonstrates that language spans multiple linguistic modalities: written, spoken, and signed. In brief, the presentation addresses the challenges that sign language linguists encounter to effectively make information on sign languages available and comprehensible to hearing non-signing audiences. For instance, the AISL project is utilizing <b>linguistic</b> <b>technologies</b> for transcription, translation, annotation, subtitling, and voice-over; as well as following best practices for documentation, description, and revitalization. This approach contributes to the training of students from multiple fields of study, offering individuals and audiences the first-hand opportunity to explore the linguistic forms and properties of indigenous sign language...|$|R
40|$|This paper {{discusses}} {{the use of}} computational <b>linguistic</b> <b>technology</b> to extract definitions from a large corpus of German court decisions. We present a corpus-based survey of definition structures used {{in this kind of}} text. We then evaluate the results of a definition extraction system that uses patterns identified in this survey to extract from dependency parsed text. We show how an automatically induced ranking function improves the quality of the search results of this system, and we discuss methods for the acquisition of further extraction rules. 1. Definitions in Court Decisions Besides normative content, the statutes of code law systems comprise terminological knowledge. This terminological knowledge consists in definitions of concepts used to describe the facts sanctioned by the law. Article 1 of the German Federal Water Act e. g. captures a specific terminological sense of waters as follows: (1) Dieses Gesetz gilt für folgende Gewässer: 1. das ständig oder zeitweilig in Betten fließende ode...|$|E
40|$|The {{electronic}} {{forms of}} communication, such as e-mails, {{have in a}} brief time become extremely popular and are in wide use. The ease of electronic communication easily leads into the explosion of information, and the users soon notice that the management of communication becomes a challenge. The present study examined a way to alleviate this problem; an organizer for information management of e-mail messages was designed. The mail organizer uses <b>linguistic</b> <b>technology</b> and analyses {{the contents of the}} mail messages, producing for every message an index about key terms. Based on these key terms, a selforganizing map (SOM) analysis is run with the messages, producing a two-dimensional graph about them. The messages that have similar contents are shown close {{to each other in the}} graph. The results obtained suggest that a lot of work needs to be done before practical applications can be implemented based on this approach. The promises of the service as well as some challenges in it are also described in this study. 1...|$|E
40|$|We {{present the}} current status of {{development}} of an open-source shallow-transfer machine translation engine for the Romance languages of Spain (the main ones being Spanish, Catalan and Galician) {{as part of a larger}} government-funded project which includes non-Romance languages such as Basque and involving both universities and <b>linguistic</b> <b>technology</b> companies. The machine translation architecture uses finite-state transducers for lexical processing, hidden Markov models for part-of-speech tagging, and finite-state based chunking for structural transfer, and is largely based upon that of systems already developed by the Transducens group at the Universitat d'Alacant, such as interNOSTRUM (Spanish—Catalan) and Traductor Universia (Spanish—Portuguese). The possible scope of the project, however, is wider, since it will be possible to use the resulting machine translation system with new pairs of languages; to that end, the project also aims at proposing standard formats to encode the linguistic data needed. This paper briefly describes the machine translation engine, the formats it uses for linguistic data, and the compilers that convert these data into an efficient format used by the engine. Work funded by projects FIT- 340101 - 2004 - 3 (Spanish Ministry of Industry, Commerce and Tourism) and TIC 2003 - 08681 -C 02 - 01 (Spanish Ministry of Science and Technology). Felipe Sánchez-Martínez is supported by the Spanish Ministry of Science and Education and the European Social Fund through grant BES- 2004 - 4711...|$|E
50|$|AlphaSense, Inc. {{was founded}} by Jack Kokko and Raj Neervannan in 2008 to apply {{advanced}} <b>linguistic</b> search <b>technology</b> to assist investment professionals, to find information in company disclosures. In 2010, AlphaSense launched its search engine utilizing natural language processing to search through all major filings, earnings calls, conference transcripts and other related documents. In 2012, the search engine added company investor relations presentations for the Russell 3000 constituents to their database of searchable content.|$|R
40|$|AbstractThis paper {{focuses on}} {{teaching}} consecutive interpreting to foreign students (in Chinese-English language pair), {{by means of}} the use of new <b>linguistic</b> computer <b>technologies</b> (LCT) and information and communication technologies (ICT). These include: Moodle, MOOC, Flipped classroom, Tag cloud, Scratch, which have the potential to train and develop skills not only directly in the process of education, but also over the further professional life, regardless of the location of future linguists and interpreters...|$|R
40|$|AbstractIn {{the field}} of {{criminal}} proceedings a large quantity of textual material is frequently confiscated or secured by criminologists for evaluating and conserving of evidential information or fulfilling any judicial investigation mandate. The search for specific information or finding of correlations between virtually countless documents is currently a time-consuming handcrafted work. The difficulties remain {{in the identification of}} evidential documents and valid relations between entities {{on the one hand and}} the adherence to time limits and data privacy-protection on the other. In this work, an integrated computational solution developed by the authors for supporting the evaluation process of forensic texts using computer <b>linguistic</b> <b>technologies</b> is outlined. The application framework under construction is designed towards a QA- system and especially being able to solve a specific criminal issue, and visualize issue-centred case-relevant relationships. For this purpose, several state-of-the-art techniques in the fields of text categorization and information/event extraction are analysed with respect to their suitability for the peculiarities of the considered domain. Subsequently, several approaches for solving domain- specific problems are introduced. The results of this study will form the basis for constituent parts of the currently developed framework...|$|R
