6179|848|Public
5|$|At the time, {{the general}} method {{to compute the}} inverse square root was to {{calculate}} an approximation for , then revise that approximation via another method until it came within an acceptable error range of the actual result. Common software methods in the early 1990s drew approximations from a <b>lookup</b> table. The key of the fast inverse square root was to directly compute an approximation by utilizing the structure of floating-point numbers, proving faster than table lookups. The algorithm was approximately four times faster than computing the square root with another method and calculating the reciprocal via floating point division. The algorithm was designed with the IEEE 754-1985 32-bit floating point specification in mind, but investigation from Chris Lomont showed {{that it could be}} implemented in other floating point specifications.|$|E
5|$|Byte {{magazine}} {{published an}} assembly language version of Spacewar in 1977 that {{ran on the}} Altair 8800 and other Intel 8080-based microcomputers using an oscilloscope as the graphical display and a <b>lookup</b> table for orbits, {{as well as a}} three-dimensional variant in 1979 written in Tiny BASIC. More modern recreations of the game for computers have been made as well. An emulated version of the original game, based on the original source code made publicly available by Martin Graetz and running in a JavaScript PDP-1 emulator, was made available to play on the internet in 2012. The only working PDP-1s that are known to exist are kept in the Computer History Museum in Mountain View, California, where demonstrations of the machine are held, which include playing Spacewar.|$|E
25|$|Most {{distributed}} data stores employ {{some form}} of DHT for <b>lookup.</b>|$|E
50|$|Each Haar-like feature {{may need}} more than four <b>lookups,</b> {{depending}} on how it was defined. Viola and Jones's 2-rectangle features need six <b>lookups,</b> 3-rectangle features need eight <b>lookups,</b> and 4-rectangle features need nine <b>lookups.</b>|$|R
5000|$|Google BigTable, Apache HBase and Apache Cassandra, and Postgresql use Bloom filters {{to reduce}} the disk <b>lookups</b> for {{non-existent}} rows or columns. Avoiding costly disk <b>lookups</b> considerably increases {{the performance of a}} database query operation.|$|R
40|$|Encryption {{algorithms}} commonly {{use table}} <b>lookups</b> to perform substitution, {{which is a}} confusion primitive. The use of table <b>lookups</b> {{in this way is}} especially common in the more recent encryption algorithms, such as the AES finalists like MARS and Twofish, and the AES winner, Rijndael. Workload characterization studies indicate that these algorithms spend a significant fraction of their execution cycles on performing these table <b>lookups,</b> more specifically on effective address calculations. This study.. ...|$|R
25|$|The Partin tables predict {{pathologic}} outcomes (margin status, extraprostatic extension, and {{seminal vesicle}} invasion) {{based on the}} same three variables and are published as <b>lookup</b> tables.|$|E
25|$|The High Court of Australia {{supported}} {{that the}} reproduction of a <b>lookup</b> table in an EPROM in a third-party hardware lock was an infringement of a literary work.|$|E
25|$|BSD ar utility {{traditionally}} {{does not}} handle {{the building of}} a global symbol <b>lookup</b> table, and delegates this task to a separate utility named ranlib, which inserts an architecture-specific file named __.SYMDEF {{at the end of the}} archive.|$|E
25|$|Only <b>lookups</b> are needed.|$|R
30|$|Another {{part of the}} {{analysis}} is failed <b>lookups,</b> i.e., queries that do not result in keys. Although Chord has a better performance after specific network sizes in 4 -d, however, {{when it comes to}} failed <b>lookups,</b> SHAM noticeably outperforms Chord.|$|R
5000|$|IPv6 DNS <b>lookups</b> are disabled. {{preventing}} slowdowns experienced ...|$|R
25|$|Another {{advantage}} of Gradshteyn and Ryzhik compared to computer algebra systems {{is the fact}} that all special functions and constants used in the evaluation of the integrals are listed in a registry as well, thereby allowing reverse <b>lookup</b> of integrals based on special functions or constants.|$|E
25|$|<b>Lookup</b> {{based on}} the ldconfig cache file (often located at /etc/ld.so.cache) which {{contains}} a compiled list of candidate libraries previously found in the augmented library path (set by /etc/ld.so.conf). If, however, the binary was linked with the -z nodefaultlib linker option, libraries in the default library paths are skipped.|$|E
25|$|Most {{software}} applications will compute small factorials by direct multiplication or table <b>lookup.</b> Larger factorial values can be approximated using Stirling's formula. Wolfram Alpha can calculate exact {{results for the}} ceiling function and floor function applied to the binary, natural and common logarithm of n! for values of n up to 249999, and up to 20,000,000! for the integers.|$|E
5000|$|Air Force History Index.org, Individual {{squadron}} <b>lookups</b> in AFHRA archives ...|$|R
5000|$|Can index {{arbitrary}} directories with audio {{files for}} pronunciation <b>lookups</b> ...|$|R
5000|$|Supports <b>lookups</b> in Wikipedia, Wiktionary, or {{any other}} MediaWiki-based sites ...|$|R
25|$|Users {{generally}} do not communicate directly with a DNS resolver. Instead DNS resolution takes place transparently in applications such as web browsers, e-mail clients, and other Internet applications. When an application makes a request that requires a domain name <b>lookup,</b> such programs send a resolution request to the DNS resolver in the local operating system, which in turn handles the communications required.|$|E
25|$|In {{computer}} science, tabulation hashing is {{a method}} for constructing universal families of hash functions by combining table <b>lookup</b> with exclusive or operations. It was first studied {{in the form of}} Zobrist hashing for computer games; later work by Carter and Wegman extended this method to arbitrary fixed-length keys. Generalizations of tabulation hashing have also been developed that can handle variable-length keys such as text strings.|$|E
25|$|In practice, this {{relationship}} of streamed events is processed through a causal vector engine, which performs a <b>lookup</b> based on recently viewed events and assigns a causal vector {{to an event}} if a relationship is discovered. If A causes B, the causal vector engine checks if B’s causal vector rule index contains a reference to A. The engine may handle events for different transactions simultaneously, perhaps in a different order than they occurred.|$|E
5000|$|... it {{provides}} routing services, typically using Electronic Numbering (ENUM) <b>lookups</b> ...|$|R
40|$|Symmetric table {{addition}} methods (STAMs) approximate functions {{by performing}} parallel table <b>lookups,</b> followed by multioperand addition. STAMs require signi cantly less memory than direct table <b>lookups</b> and are faster than piecewise linear approximations. This paper investigates {{the application of}} STAMs to the sigmoid function and its derivative, which are commonly used in arti cial neural networks. Compared to direct table <b>lookups,</b> STAMs require between 23 and 41 times less memory for sigmoid and between 24 and 46 times less memory for sigmoid's derivative, when the input operand size is 16 bits and the output precision is 12 bits...|$|R
5000|$|Full {{support for}} integer and bitwise operations, {{including}} integer texture <b>lookups</b> ...|$|R
25|$|The {{best way}} {{to speed up the}} baby-step giant-step {{algorithm}} is to use an efficient table <b>lookup</b> scheme. The best in this case is a hash table. The hashing is done on the second component, and to perform the check in step 1 of the main loop, γ is hashed and the resulting memory address checked. Since hash tables can retrieve and add elements in O(1) time (constant time), this does not slow down the overall baby-step giant-step algorithm.|$|E
25|$|The {{key idea}} of {{tabulation}} hashing is {{to view a}} key as a vector of t r-bit numbers, use a <b>lookup</b> table filled with random values to compute a hash value {{for each of the}} r-bit numbers representing a given key, and combine these values with the bitwise binary exclusive or operation. The choice of r should be made {{in such a way that}} this table is not too large; e.g., so that it fits into the computer's cache memory.|$|E
25|$|The memory {{manager and}} {{processes}} scheduler have been improved. The scheduler was modified {{to use the}} cycle counter register of modern processors {{to keep track of}} exactly how many CPU cycles a thread has executed, rather than just using an interval-timer interrupt routine. This new CPU cycle-based thread scheduling gives a greater fairness and more deterministic app behavior. Many kernel data structures and algorithms have been rewritten. <b>Lookup</b> algorithms now run in constant time, instead of linear time as with previous versions.|$|E
5000|$|Network Search Engine: {{hardware}} accelerator used in routers for LPM <b>lookups.</b>|$|R
5000|$|... host (Unix), {{a simple}} utility for {{performing}} Domain Name System <b>lookups</b> ...|$|R
5000|$|URIBL <b>lookups</b> of senders IP, helo hostname, {{envelope}} sender, {{and message}} contents ...|$|R
25|$|Looking up {{data in a}} trie {{is faster}} in the worst case, O(m) time (where m is {{the length of a}} search string), {{compared}} to an imperfect hash table. An imperfect hash table can have key collisions. A key collision is the hash function mapping of different keys to the same position in a hash table. The worst-case <b>lookup</b> speed in an imperfect hash table is O(N) time, but far more typically is O(1), with O(m) time spent evaluating the hash.|$|E
25|$|A minor Second Revision {{was made}} during and just after World War II. This {{was used by}} most postwar lexicographers {{including}} Morohashi Tetsuji, who created his 12-volume Sino-Japanese dictionary, the Dai Kan-Wa jiten and included the Four Corner index among several other <b>lookup</b> methods. Oshanin (USSR) included a Four Corner index in his Chinese-Russian dictionary and in new China, an extraordinary project of the 25 Histories (Ershi wu shi) {{was published in the}} early 1950s with a Four Corner index volume containing the entire content.|$|E
25|$|Alternatively, the {{programmer}} may {{abandon the}} notion of representing the Life field with a 2-dimensional array, and use a different data structure, like a vector of coordinate pairs representing live cells. This approach allows the pattern to move about the field unhindered, {{as long as the}} population does not exceed the size of the live-coordinate array. The drawback is that counting live neighbours becomes a hash-table <b>lookup</b> or search operation, slowing down simulation speed. With more sophisticated data structures this problem can also be largely solved.|$|E
40|$|This chapter {{describes}} a longest prefix matching algorithm to perform fast IPv 4 route <b>lookups</b> in hardware. The chapter first presents {{an overview of}} previous work on IP <b>lookups</b> in Section 2. As we will see, most longest prefix matching algorithms proposed in the literature are designed primarily for implementation in software. They attempt to optimiz...|$|R
50|$|Many payment {{gateways}} {{also provide}} tools to automatically screen orders for fraud and calculate tax {{in real time}} prior to the authorization request {{being sent to the}} processor. Tools to detect fraud include geolocation, velocity pattern analysis, OFAC list <b>lookups,</b> 'black-list' <b>lookups,</b> delivery address verification, computer finger printing technology, identity morphing detection, and basic AVS checks.|$|R
50|$|Merriam-Webster Dictionary {{declared}} in December 2015, this word -ism {{to be the}} Word of the Year. A suffix is the Word of the Year because {{a small group of}} words that share this three-letter ending triggered both high volume and significant year-over-year increase in <b>lookups</b> at Merriam-Webster.com. Taken together, these seven words represent millions of individual dictionary <b>lookups.</b>|$|R
