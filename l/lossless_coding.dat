302|368|Public
25|$|The DC {{coefficients}} {{when taken}} together resemble a downscale {{version of the}} original image multiplied by a scaling factor. Well-known schemes for <b>lossless</b> <b>coding</b> of continuous-tone images can be applied, achieving somewhat better compression than the Huffman coded DPCM used in JPEG.|$|E
25|$|On {{the other}} hand, JPEG {{may not be}} as well suited for line {{drawings}} and other textual or iconic graphics, where the sharp contrasts between adjacent pixels can cause noticeable artifacts. Such images may be better saved in a lossless graphics format such as TIFF, GIF, PNG, or a raw image format. The JPEG standard actually includes a <b>lossless</b> <b>coding</b> mode, but that mode is not supported in most products.|$|E
5000|$|Also MPEG-4 Part 3 audio objects, such as Audio <b>Lossless</b> <b>Coding</b> (ALS), Scalable <b>Lossless</b> <b>Coding</b> (SLS), MP3, MPEG-1 Audio Layer II (MP2), MPEG-1 Audio Layer I (MP1), CELP, HVXC (speech), TwinVQ, Text To Speech Interface (TTSI) and Structured Audio Orchestra Language (SAOL) ...|$|E
40|$|Abstract—The {{performance}} of state-of-the-art <b>lossless</b> image <b>coding</b> methods [such as JPEG-LS, lossless JPEG- 2000, and context-based adaptive <b>lossless</b> image <b>coding</b> (CALIC) ] can be considerably improved by a recently introduced preprocessing technique {{that can be}} applied whenever the images have sparse histograms. Bitrate savings of up to 50 % have been reported, but so far no theoretical explanation of the fact has been advanced. This letter addresses this issue and analyzes the effect of the technique in terms of the interplay between histogram packing and the image total variation, emphasizing the lossless JPEG- 2000 case. Index Terms—Context-based adaptive <b>lossless</b> image <b>coding</b> (CALIC), histogram packing, image variation, JPEG- 2000, JPEG-LS, linear approximation, <b>lossless</b> image <b>coding,</b> nonlinear approximation. I...|$|R
5000|$|... #Subtitle level 3: Slepian-Wolf <b>coding</b> - <b>lossless</b> {{distributed}} <b>coding</b> ...|$|R
40|$|The Slepian-Wolf bound raises {{interest}} in <b>lossless</b> <b>code</b> design for multiple access networks. Previous work treats instantaneous codes. We generalize the Sardinas and Patterson test and bound the achievable rate region for uniquely decodable codes. The Kraft inequality is generalised {{to produce the}} necessary conditions on the codeword lengths for uniquely decodable-side information source code...|$|R
50|$|MPEG-4 SLS is {{not related}} {{in any way to}} MPEG-4 ALS (Audio <b>Lossless</b> <b>Coding).</b>|$|E
5000|$|Subpart 10: Technical {{description}} of <b>lossless</b> <b>coding</b> of oversampled audio (MPEG-4 DST - Direct Stream Transfer) ...|$|E
50|$|Direct Stream Transfer {{compression}} {{was also}} standardized as {{an amendment to}} MPEG-4 Audio standard (ISO/IEC 14496-3:2001/Amd 6:2005 - <b>Lossless</b> <b>coding</b> of oversampled audio) in 2005. It contains the DSD and DST definitions {{as described in the}} Super Audio CD Specification. The MPEG-4 DST provides <b>lossless</b> <b>coding</b> of oversampled audio signals. Target applications of DST is archiving and storage of 1-bit oversampled audio signals and SA-CD.A reference implementation of MPEG-4 DST was published as ISO/IEC 14496-5:2001/Amd.10:2007 in 2007.|$|E
40|$|This paper {{surveys the}} {{theoretical}} literature on fixed-to-variable-length <b>lossless</b> source <b>code</b> trees, called code trees, and on variable-length-to-fixed <b>lossless</b> sounce <b>code</b> trees, called parse trees. Huffman coding [l] {{is the most}} well known code tree problem, {{but there are a}} number of interesting variants of the problem formulation which lead to other combinatorial optimization problems. Huffman coding as a...|$|R
5000|$|... #Subtitle level 3: Fixed Rate <b>lossless</b> source <b>coding</b> for {{discrete}} time non-stationary independent sources ...|$|R
40|$|Zusammenfassung (dt.) Abstract: In {{recent years}} audio coding {{has become a}} very popular field for {{research}} and applications. Especially perceptual audio coding schemes, such as MPEG- 1 Layer- 3 (MP 3) and MPEG- 2 Advanced Audio Coding (AAC), are widely used for efficient storage and transmission of music signals. Nevertheless, for professional applications, such as archiving and transmission in studio environments, <b>lossless</b> audio <b>coding</b> schemes are considered more appropriate. Traditionally, the technical approaches used in perceptual and <b>lossless</b> audio <b>coding</b> have been separate worlds. In perceptual audio coding, the use of filter banks, such as the lapped orthogonal transform "Modified Discrete Cosine Transform" (MDCT), has been the approach of choice being used by many {{state of the art}} coding schemes. On the other hand, <b>lossless</b> audio <b>coding</b> schemes mostly employ predictive coding of waveforms to remove redundancy. Only few attempts have been made so far to use transform coding for the purpose of <b>lossless</b> audio <b>coding.</b> This work presents a new approach of applying the lifting scheme to lapped transforms used in perceptual audio coding. This allows for an invertible integer-to-integer approximation of the original transform, e. g. the IntMDCT as an integer approximation of the MDCT. The same technique can also be applied to low-delay filter banks. A generalized, multi-dimensional lifting approach and a noise-shaping technique are introduced, allowing to further optimize the accuracy of the approximation to the original transform. Based on these new integer transforms, this work presents new audio coding schemes and applications. The audio <b>coding</b> applications cover <b>lossless</b> audio <b>coding,</b> scalable <b>lossless</b> enhancement of a perceptual audio coder and fine-grain scalable perceptual and <b>lossless</b> audio <b>coding.</b> Finally an approach to data hiding with high data rates in uncompressed audio signals based on integer transforms is described...|$|R
50|$|Meanwhile, it is {{no longer}} {{developed}} because an advanced version of it has become an official standard under the name of MPEG-4 Audio <b>Lossless</b> <b>Coding.</b>|$|E
50|$|The encoder can {{use either}} {{floating}} point or Integer DWT. Integer DWT is the <b>lossless</b> <b>coding</b> scheme, while the floating point DWT {{contributes to the}} lossy scheme.|$|E
5000|$|... 32 bits per {{component}} as fixed-point {{numbers or}} full-precision {{floating point numbers}} packed into 96 or 128 bits (for which <b>lossless</b> <b>coding</b> is not supported due to the excessively high precision) ...|$|E
40|$|Hybrid {{predictive}}/VQ <b>lossless</b> image <b>coding</b> A multiplicative {{autoregressive model}} {{is used in}} a <b>lossless</b> predictive image <b>coding</b> scheme. The use of vector quantisation (VQ) for compression of the model coefficients leads to an improved compression ratio. Both image adaptive and universal codebooks are considered. A comparative analysis of the new coder is presented through simulation results...|$|R
40|$|This paper {{introduces}} one of {{the image}} transform methods using M-channel paraunitary filterbanks (PUFBs) based on Householder matirx. First, redundant parameters of PUFB are eliminated by us-ing {{the fact that they}} can be factorized into Givens rotation mat-ices. Next, we propose an eliminating redundant parameters method based on Householder matrix using relationship between Givens ro-tation and Householder matrices. In addition, PUFBs are factorized into the lifting structure for <b>lossless</b> image <b>coding,</b> and we call them as lifting-based PUFBs (LBPUFBs). LBPUFBs based on House-holder matrix have less number of rounding operators than Givens rotation matrix version, since proposed structure is efficiency for <b>lossless</b> image <b>coding.</b> Finally, we show some exsamples to vali-date our method in lossy/lossless image coding. Index Terms — Paraunitary filterbank, householder matrix, re-dundant parameters, lifting structure, <b>lossless</b> image <b>coding...</b>|$|R
50|$|The {{compression}} {{is based}} on lossless entropy reduction, by means of variousdifferentiation operations, followed by <b>lossless</b> entropy <b>coding</b> using theLZMA compression library.|$|R
50|$|The color representations, in most cases, are {{transformed}} {{to an internal}} color representation. The transformation is entirely reversible, so that this color transformation step does not introduce distortion and thus <b>lossless</b> <b>coding</b> modes can be supported.|$|E
5000|$|... reversible: {{a rounded}} {{version of the}} biorthogonal CDF 5/3 wavelet transform. It uses only integer coefficients, so the output does not require {{rounding}} (quantization) and so it does not introduce any quantization noise. It is used in <b>lossless</b> <b>coding.</b>|$|E
5000|$|The DC {{coefficients}} {{when taken}} together resemble a downscale {{version of the}} original image multiplied by a scaling factor. Well-known schemes for <b>lossless</b> <b>coding</b> of continuous-tone images can be applied, achieving somewhat better compression than the Huffman coded DPCM used in JPEG.|$|E
40|$|Recent {{papers have}} {{proposed}} linear prediction {{as a useful}} method for <b>lossless</b> audio <b>coding.</b> Transform coding, however, has hardly been investigated, although {{it seems to be}} more suited for the harmonic structure of most audio signals. In this paper we present some results on <b>lossless</b> transform <b>coding</b> of CD-quality audio data. One main aspect lies on a convenient quantization method to guarantee perfect reconstruction. We achieve bit rates which are lower than those obtained by lossless linear prediction schemes...|$|R
40|$|<b>Lossless</b> image <b>coding</b> {{deals with}} the problem of {{representing}} an image with a minimum number of binary bits from which the original image can be fully recovered without any loss of information. Most <b>lossless</b> image <b>coding</b> algorithms reach the goal of efficient compression by taking care of the spatial correlations and statistical redundancy lying in images. Context based algorithms are the typical algorithms in <b>lossless</b> image <b>coding.</b> One key probelm in context based <b>lossless</b> bi-level image <b>coding</b> algorithms is the design of context templates. By using carefully designed context templates, we can effectively employ the information provided by surrounding pixels in an image. In almost all image processing applications, image data is accessed in a raster scanning manner and is treated as 1 -D integer sequence rather than 2 -D data. In this thesis, we present a quadrisection scanning method which is better than raster scanning in that more adjacent surrounding pixels are incorporated into context templates. Based on quadrisection scanning, we develop several context templates and propose several image coding schemes for both sequential and progressive lossless bi-level image compression. Our results show that our algorithms perform better than those raster scanning based algorithms, such as JBIG 1 used in this thesis as a reference. Also, the application of 1 -D grammar based <b>codes</b> in <b>lossless</b> image <b>coding</b> is discussed. 1 -D grammar based codes outperform those LZ 77 /LZ 78 based compression utility software for general data compression. It is also effective in <b>lossless</b> image <b>coding.</b> Several coding schemes for bi-level image compression via 1 -D grammar codes are provided in this thesis, especially the parallel switching algorithm which combines the power of 1 -D grammar based codes and context based algorithms. Most of our results are comparable to or better than those afforded by JBIG 1...|$|R
40|$|Abstract. We {{address the}} problem of {{constructing}} a fast <b>lossless</b> <b>code</b> in the case when the source alphabet is large. The main idea of the new scheme may be described as follows. We group letters with small probabilities in subsets (acting as super letters) and use time consuming coding for these subsets only, whereas letters in the subsets have the same code length and therefore can be coded fast. The described scheme can be applied to sources with known and unknown statistics...|$|R
5000|$|Distributed Coding is {{the coding}} {{of two or}} more {{dependent}} sources with separate encoders and joint decoder. Given two statistically dependent i.i.d. finite-alphabet random sequences X and Y, Slepian-Wolf theorem includes theoretical bound for the <b>lossless</b> <b>coding</b> rate for distributed coding of the two sources as below: ...|$|E
50|$|LTAC {{will not}} be {{developed}} any further since it has been superseded by its successor Lossless Predictive Audio Compression (LPAC), {{which is based on}} linear prediction. This makes it much faster than LTAC and even leads to better compression results. LPAC has become official standard as MPEG-4 Audio <b>Lossless</b> <b>Coding.</b>|$|E
50|$|The CfP {{requested}} {{proposals for}} a lossless and scalable technology that was backward {{compatible with the}} existing MPEG AAC codec, and could operate efficiently at several different sampling rates and word length combinations. Institute for Infocomm Research (I2R) technologies were adopted for the scalable to <b>lossless</b> <b>coding</b> (14496-3/AMD5) architecture Reference Model 0.|$|E
40|$|Abstract—In this paper, we generalize the <b>lossless</b> <b>coded</b> side {{information}} problem from the three-node network of Ahlswede and Körner to more general network scenarios. We derive {{inner and outer}} bounds on the achievable rate region in the general network scenario and {{show that they are}} tight for some families of networks. Our approach demonstrates how solutions to canonical source coding problems can be used to derive bounds for more complex networks and reveals an interesting connection between networks with {{side information}}, successive refinement, and network coding. I...|$|R
40|$|Recent {{papers have}} {{proposed}} linear prediction {{as a useful}} method for <b>lossless</b> audio <b>coding.</b> Transform coding, however, hasn't been investigated so far, although {{it seems to be}} more adapted to the harmonic structure of most audio signals. In this paper we present first results on <b>lossless</b> transform <b>coding</b> of CD-quality audio data. One main aspect lies on a suitable quantization method to obtain perfect reconstruction. Using a codebook with different entropy codes for the transform coefficients we achieve bitrates, slightly better then those obtained by the lossless linear prediction schemes mentioned above. 1 Introduction <b>Lossless</b> audio <b>coding</b> is a topic of high interest for both professional and customer applications. Modern lossy coding standards (e. g. ISO MPEG I+II) can achieve large compression ratios with high subjective quality, however, multiple coding can reveal the originally masked distortion. Anyway, reproducing critical music items shows that even the best systems [...] ...|$|R
40|$|Abstract — The {{problem of}} joint {{universal}} source coding and modeling, {{treated in the}} context of <b>lossless</b> <b>codes</b> by Rissanen, was recently generalized to fixed-rate lossy coding of finitely parametrized continuous-alphabet i. i. d. sources. We extend these results to variable-rate lossy block coding of stationary ergodic sources and show that, for bounded metric distortion measures, any finitely parametrized family of stationary sources satisfying suitable mixing, smoothness and Vapnik–Chervonenkis learnability conditions admits universal schemes for joint lossy source coding and identification. We also give several explicit examples of parametric sources satisfying the regularity conditions. I...|$|R
50|$|The MPEG-4 Part 3 {{consists}} {{of a variety of}} audio coding technologies - from lossy speech coding (HVXC, CELP), general audio coding (AAC, TwinVQ, BSAC), lossless audio compression (MPEG-4 SLS, Audio <b>Lossless</b> <b>Coding,</b> MPEG-4 DST), a Text-To-Speech Interface (TTSI), Structured Audio (using SAOL, SASL, MIDI) and many additional audio synthesis and coding techniques.|$|E
50|$|OptimFROG DualStream is a lossy codec, {{aimed to}} fill the gap between perceptual coding and <b>lossless</b> <b>coding</b> as OptimFROG DualStream has an option to produce a {{correction}} file. This file can be used, in combination with the main lossy-encoded file, for lossless decoding, but not, unlike Wavpack hybrid for instance, for playback.|$|E
50|$|Similar to the {{previous}} <b>lossless</b> <b>coding</b> framework based on Slepian-Wolf theorem, efforts have been taken on lossy cases based on the Wyner-Ziv theorem. Theoretical results on quantizer designs was provided by R. Zamir and S. Shamai, while different frameworks have been proposed based on this result, including a nested lattice quantizer and a trellis-coded quantizer.|$|E
40|$|We here {{consider}} a theoretical {{evaluation of data}} compression algorithms based on the Burrows Wheeler transform (BWT). The main contributions include a variety of very simple new techniques for BWT-based universal <b>lossless</b> source <b>coding</b> on finite-memory sources {{and a set of}} new rate of convergence results for BWT-based source codes. The result is a theoretical validation and quantification of the earlier experimental observation that BWT-based <b>lossless</b> source <b>codes</b> give performance better than that of Ziv-Lempel-style codes and almost as good as that of prediction by partial mapping (PPM) algorithms...|$|R
40|$|For {{a family}} of network source coding problems, we prove that the {{lossless}} rate region is concave {{in the distribution of}} sources. While the proof of concavity is straightforward for the few examples where a single-letter characterization of the <b>lossless</b> source <b>coding</b> region is known, it is more difficult {{for the vast majority of}} networks where the <b>lossless</b> source <b>coding</b> region remains unsolved. The class of networks that we investigate includes both solved and unsolved examples. We further conjecture that the same property applies more widely and sketch an avenue for investigating that conjecture...|$|R
40|$|Abstract:- In this paper,we {{present an}} {{overview}} of the implementation of navel compound algorithm for efficient low bit rate lossy and ROI <b>lossless</b> Mix <b>Coding</b> of massive three dimensional images. Moreover the compound algorithm can be used for multitasking Remote Sensing field operations and efficient 3 -D image transmission applications such as overall image viewing at low bit rate lossy <b>coding,</b> nearly <b>lossless</b> ROI <b>coding</b> of most desired target area as well as efficient low memory storage or transmission/network transfer of such 3 -D images with volume reduction technique. In the navel compound algorithm, a modification to the conventional 3 D-SPIHT algorithm is implemented with 3 -D IWT, <b>lossless</b> ROI <b>Coding</b> and observer pre decide image size reduction using Volumetric Interpolation. Comparison to conventional 3 -D SPIHT with DWT, the compound algorithm results interpret high PSNR at low bit rate coding and efficient and better perceptive effects in the ROI coded images. Key-words:- Compound algorithm, Remote sensing (3 -D) images, Volumetric interpolation, 3 -D IWT, lossy an...|$|R
