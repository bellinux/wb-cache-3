5|24|Public
40|$|Current mode (ECL) logic {{has long}} been the option of choice in those {{applications}} requiring logic functions at multigigahertz rates. This trend continues despite the obvious very high static power consumption and small signal swing characterizing this logic. In this work we investigate a simple mechanism for Low-Voltage-Swing Logic (LVSL) to greatly reduce the power requirement of a CML <b>logic</b> <b>subsystem</b> while improving the reliability and signal integrity. For the presented circuits operating at 5 GHz, 50 % power reduction is achieved while improving the signal integrity. 1...|$|E
40|$|Researchers in {{artificial}} intelligence {{have recently been}} taking great interest in hybrid representations, among them sorted logics [...] -logics that link a traditional logical representation to a taxonomic (or sort) representation such as those prevalent in semantic networks. This paper introduces a general framework [...] -the substitutional framework [...] -for integrating logical deduction and sortal deduction to form a deductive system for sorted logic. This paper also presents results that provide the theoretical underpinnings of the framework. A distinguishing characteristic of a deductive system that is structured according to the substitutional framework is that the sort subsystem is invoked only when the <b>logic</b> <b>subsystem</b> performs unification, and thus sort information is used only in determining what substitutions to make for variables. Unlike every other known approach to sorted deduction, the substitutional framework provides for a systematic transformation of unsorted deductive systems [...] ...|$|E
40|$|The image {{sequence}} {{evaluation system}} Xtrack detects, initializes, and tracks images of moving road vehicles in video sequences recorded at innercity traffic scenes by a stationary camera. It recently has been supplemented, moreover, by subsystems which associate the geometric tracking results to conceptual representations of traffic situations at innercity intersections. Such conceptual representations can be exploited by a Fuzzy Metric-Temporal <b>Logic</b> <b>subsystem</b> {{in order to}} prepare a suitable conceptual description. A subsequent subsystem transforms this conceptual description into a natural language description of temporal developments in the recorded traffic scenes. Weintend to study such an approach {{as a component of}} a driver assistance system to be installed within a road vehicle. As a first step, we establish a link between Xtrack and a model-based vision system Ximage which tracks road models in video sequences recorded from within a driving vehicle. Both systems produce the same kind of r [...] ...|$|E
40|$|The {{research}} {{presented in}} this thesis examines {{the construction of a}} fuzzy logic controller for complex nonlinear system by control system decomposition into hierarchial fuzzy <b>logic</b> <b>subsystems</b> [...] . evolutionary algorithm (EA) based methods are proposed to determine the control system for the hieracrchical fuzzy system (HFS) " [...] Abstract...|$|R
5000|$|August: Basic {{demonstration}} system is operational. This includes simulators, test drivers and the Safetran Wayside Appliance and Signaling <b>Logic</b> Processor <b>subsystems.</b>|$|R
40|$|Microprogramming is an {{inherently}} elegant method for implementing many digital systems. It {{is a mixture}} of hardware and software techniques with the <b>logic</b> <b>subsystems</b> controlled by "instructions " stored in a memory. In the past, designing microprogrammed systems was difficult, tedious, and expensive because the available components were capable of only limited number of functions. Today, however, large blocks of microprogramsmd systems have been incorporated into a single I. C., thus microprograsuning has become a simple, practical method...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. Parallel signature analysis with bidirectional multiple-input signature registers allows the data flow at internal test points on complex digital ICs to be observed. The test data are sampled and coded on-line at the rated internal speed of the ICs. The information about the data flow at the test points is gathered without putting an additional burden on the high speed data transfer between the ICs under test and the tester. Pseudorandom test patterns generated with linear feedback shift registers are successfully used for detecting single stuck-at faults in a combinational circuit. By adding a few gates to a bidirectional multiple-input signature register, a multifunctional <b>logic</b> <b>subsystem</b> is obtained, which combines the advantages of builtin test and scan path techniques. When this structure is applied to pipelined structure circuits, testing time is reduced by almost half that of previous schemes...|$|E
40|$|In {{this work}} a motion control scheme, which {{belongs to the}} class of the control schemes known as a sliding mode control with {{disturbance}} estimation is proposed. Adaptive fuzzy disturbance estimator works as an identifier of variable part of a system dynamics. Adaptation algorithm is derived by using the Lyapunov stability theory and provides global asymptotic stability of the state errors. For the implementation on the robot, physically based fuzzy <b>logic</b> <b>subsystems</b> are proposed. With this estimators transparency is enhanced and complexity reduced. If linguistic knowledge is available, subsystems enable its systematic inclusion. The control scheme was successfully tested on a laboratory direct drive (DD) robot. ...|$|R
40|$|Girard's Light linear logic (LLL) {{characterized}} {{polynomial time}} in the proof-as-program paradigm with a bound on cut elimination. This logic relied on a stratification principle and a "one-door" principle which were generalized later respectively in the systems L^ 4 and L^ 3 a. Each system was brought with its own complex proof of Ptime soundness. In this {{paper we propose a}} broad sufficient criterion for Ptime soundness for linear <b>logic</b> <b>subsystems,</b> based on the study of paths inside the proof-nets, which factorizes proofs of soundness of existing systems and may be used for future systems. As an additional gain, our bound stands for any reduction strategy whereas most bounds in the literature only stand for a particular strategy. Comment: Long version of a conference pape...|$|R
40|$|In {{this paper}} the {{architecture}} of the MIX system is described. It was designed to investigate some of the factors involved in approving reconfigurable and/or fixed logic in a typical engineering algorithm. A matrix-vector multiplier of 32 bit floating point numbers, is used as a vehicle for the investigation. The results indicate that fixed logic is more suited for floating point units and memories while reconfigurable logic is useful for implementing control logic providing significant flexibility. It is also found that the additional delay in reconfigurable logic can very effectively overlap with the operating time of the fixed <b>logic</b> <b>subsystems.</b> The advantage of reconfigurability of the control is therefore combined with the high bandwidth properties of the fixed logic. Conference Pape...|$|R
50|$|Apple's RIP was {{of its own}} design, and was {{implemented}} using remarkably few ICs, including PALs for most combinatorial <b>logic,</b> with the <b>subsystem</b> timing, DRAM refreshing, and rasterization functions being implemented in very few medium-scale-integration PALs. Apple's competitors (i.e., QMS, NEC, and others) generally used a variation of one of Adobe's RIPs with their large quantity of small-scale-integration (i.e., Texas Instruments' 7400 series) ICs.|$|R
40|$|The aim of {{the present}} paper is twofold: first I am {{somewhat}} dissatisfied with current treatments of Bimodal Provability Logic: the models employed there are singled out by certain syntactical conditions, moreover they validate the logics under consideration only locally. In this paper I give a decent model- & frame-theory for these logics. Secondly I study the modal <b>logic</b> of <b>subsystems</b> of Peano Arithmetic whose axiom sets are bounded by non-standard numbers (to be specific: non-standard numbers specifiable as the smallest number satifying some A 0 -formula). These systems {{play a role in}} certain arguments concerning Relative Interpretability. Moreover the Arithmetical Completeness Theorem for these systems can be applied to characterize which formulas of the language of ordinary, 'unimodal', provability logic are E 1 (modulo provable equivalence in Peano Arithmetic) under all arithmetical interpretations [...] ...|$|R
50|$|Adobe's RIPs have, generally, {{been named}} for United States rockets (Atlas, Redstone, etcetera), but Apple's RIP was {{of its own}} design, and was {{implemented}} using remarkably few integrated circuits (ICs), including PALs for most combinatorial <b>logic,</b> with the <b>subsystem</b> timing, DRAM refreshing, and rasterization functions being implemented in very few medium-integration PALs. Apple's competitors (i.e., QMS, NEC, and others) have generally used a variation of one of Adobe's RIPs with their large quantity of low-integration (i.e., Texas Instruments' 7400 series) ICs.|$|R
40|$|Wind-energy {{researchers}} at Sandia National Laboratories (SNL) and the National Renewable Energy Laboratory (NREL) {{are developing a}} new, light-weight, modular system capable of acquiring long-term, continuous time-series data from current-generation small or large, dynamic wind-turbine rotors. Meetings with wind-turbine research personnel at NREL and SNL resulted in {{a list of the}} major requirements that the system must meet. Initial attempts to locate a commercial system that could meet all of these requirements were not successful, but some commercially available data acquisition and radio/modem subsystems that met many of the requirements were identified. A time synchronization subsystem and a programmable <b>logic</b> device <b>subsystem</b> to integrate the functions of the data acquisition, the radio/modem, and the time synchronization subsystems and to communicate with the user have been developed at SNL. This paper presents the data system requirements, describes the four major subsystems comprising the system, summarizes the current status of the system, and presents the current plans for near-term development of hardware and software...|$|R
40|$|Includes bibliographical {{references}} (p. 36 - 37) pplication layer, Middle layer, Radio Interface {{layer and}} Modem are the majorly most common terminologies we come across on smart phone's platform. The thesis here delves into such layers {{to analyze and}} debug panics caused due to kernel panics, Bus lock up issue, Memory leak Android, Dalvik abort with Excessive JNI references, GPU Hang issue, Page Faults, ASIC chip corruption and many more. The core logic here {{is not just to}} restrict the end user to know about some application layer dis-functionalities causing weird activities happening in the handset, but to make them to the core where we have all kinds of framework <b>logic</b> of <b>subsystems,</b> runtime framework and supported libraries which enhances the knowledge domain and educates the user to differentiate the bugs by layer specification. We also show real time issues due to the Dalvik Virtual machine and how the supported libraries can also be the culprits...|$|R
5000|$|Just like intuitionistic logic, minimal logic can be {{formulated}} {{in a language}} using → (implication), ∧ (conjunction), ∨ (disjunction), and ⊥ (falsum) as the basic connectives, treating ¬A (negation) as an abbreviation for A → ⊥. In this language, it is axiomatized by the positive fragment (i.e., formulas using only →, ∧, and ∨) of intuitionistic logic, with no additional axioms or rules about ⊥. Thus minimal <b>logic</b> is a <b>subsystem</b> of intuitionistic <b>logic,</b> and it is strictly weaker as it does not derive the ex falso quodlibet principle [...] (however, it derives its special case [...] ).|$|R
40|$|Sharing graphs are a {{local and}} {{asynchronous}} implementation of lambda-calculus beta-reduction (or linear logic proof-net cut-elimination) that avoids useless duplications. Empirical benchmarks {{suggest that they}} {{are one of the most}} efficient machineries, when one wants to fully exploit the higher-order features of lambda-calculus. However, we still lack confirming grounds with theoretical solidity to dispel uncertainties about the adoption of sharing graphs. Aiming at analysing in detail the worst-case overhead cost of sharing operators, we restrict to the case of elementary and light linear <b>logic,</b> two <b>subsystems</b> with bounded computational complexity of multiplicative exponential linear logic. In these two cases, the bookkeeping component is unnecessary, and sharing graphs are simplified to the so-called "abstract algorithm". By a modular cost comparison over a syntactical simulation, we prove that the overhead of shared reductions is quadratically bounded to cost of the naive implementation, i. e. proof-net reduction. This result generalises and strengthens a previous complexity result, and implies that the price of sharing is negligible, if compared to the obtainable benefits on reductions requiring a large amount of duplication...|$|R
40|$|This paper {{proposes a}} fuzzy {{terminal}} {{sliding mode control}} method for two-link flexible manipulators. Based on the singular perturbation method and two time-scale decomposition, the flexible manipulator system is firstly decomposed into two subsystems by modeling the joint angles and the corrected flexible modes as the slow and fast variables, respectively. A nonsingular terminal sliding mode manifold is proposed for the slow subsystem to realize fast convergence and better tracking precision. Meanwhile, a hybrid controller for the slow subsystem is proposed to ensure strong robustness, {{as well as to}} weaken chattering phenomenon using fuzzy <b>logic.</b> The fast <b>subsystem</b> is stabilized using a LQR control strategy. A reduced-order observer is proposed to estimate the corrected flexible mode variables that can not be measured directly. The simulation results are presented to validate the designed method...|$|R
40|$|Some {{potential}} application {{domains of}} hybrid multimodal logic suggest typing {{of states and}} imposing type–constraints on modalities. In [7] we have investigated the logical/computational cost of such an extension with a very simple system of types and concluded that there is none: both expressivity and complexity are preserved by the extension. Rewrite rules coping with state equality and state succession {{have been a major}} obstacle for efficient implementation of tableaux systems for hybrid modal logic. We handle state equality, state succession and valuation on the metalevel instead, constructing an explicit model–to–be in the process. Handling of types on the metalevel comes naturally in the presence of an explicit model, and it can considerably prune the search space. We present a prototype implementation of a tableaux–based theorem prover built along these lines. The prover handles type–free hybrid modal <b>logic</b> and its <b>subsystems</b> as well...|$|R
50|$|The Model 200 uses {{discrete}} components {{to implement the}} memory <b>subsystem</b> <b>logic.</b> In the Model 240, these {{discrete components}} are replaced by three ASICs, the MB ASIC, the MT ASIC and the MS ASIC. The MB (Memory Buffer) ASIC serves as an interface between the 40 MHz CPU module domain and the 25 MHz system module domain. It {{is connected to the}} MT ASIC, which serves as the memory controller. The MT ASIC provides memory control and refresh, handles memory DMA and transactions, and ECC checking. The MS (Memory Strobe) ASIC provides 15 sets of memory control lines and routes memory control signals from the MT ASIC to the destination SIMM. The MS ASIC replaces 16 discrete components used in the Model 200 and also generates the 25 MHz system clock signal, replacing a further three discrete components used in the Model 200.|$|R
30|$|The work in [48] sees a self-adaptive {{system as}} {{placed in an}} {{environment}} made up by physical and software entities and consisting of a two-layer architecture. It includes a first, managed, subsystem layer, that embeds the application logic, and a managing subsystem, {{on top of the}} first one, embedding the adaptation <b>logic.</b> The latter <b>subsystem</b> realizes a feedback loop that monitors the environment and the managed subsystem. The managing subsystem also adapts the managed one in the following cases: self-healing, when dealing with particular types of faults, self-optimizing, when operating conditions change, and self-reconfiguring, when a goal changes. Typically, the managing subsystem is conceived as a set of interacting feedback loops, one for each self-adaptation aspect (or concern). Other layers can be hierarchically added to the system, so that higher level managing subsystems manage directly underlying subsystems, which in turn can work as managing systems.|$|R
40|$|Hui-Yin Sung and Ho-Ching Lee This paper {{deals with}} the {{participation}} problem in the European environmental governance. Facing the critics of democratic deficit and the growing distrust of scientific knowledge, the enlargement {{of participation in the}} stage of policy formulation at the EU level is unavoidable, thus broadens the scope of participation from interest consultation to collective knowledge production. Treating the preparatory stage of policy formulation as a process of risk assessment, this paper seeks to analyze the question that if the enlargement of participation in knowledge production can better the effectiveness of European environmental governance in terms of policy learning. This paper argues that the features of a given environmental risk and different <b>logics</b> of societal <b>subsystems,</b> including political, economic, and social systems condition the influence of scientific knowledge. In spite of the consensual scientific knowledge will decrease the complexity of a given environmental risk, the policie...|$|R
40|$|A binary {{multiplier}} is {{an integral}} part of the arithmetic <b>logic</b> unit (ALU) <b>subsystem</b> found in many processors. Integer multiplication can be ine#cient and costly, in time and hardware, depending on the representation of signed numbers. Booth's algorithm suggests a technique for multiplying signed numbers that works well for both negative and positive multipliers. In this project, we have used Cadence-SMV for describing and verifying a hardware design based on Booth's algorithm. Cadence-SMV is a symbolic model verifier well suited to verifying combinational logic and interacting state machines and produces a step by step counter-example if a desired property is false. This allows for much easier debugging. Our analysis confirmed a special case in which Booth's algorithm is known to produce incorrect results. 1 Introduction Digital hardware design is a lengthy and costly process. Many CAD tools have been built to aid in finding faulty designs before production. In this project, we use a [...] ...|$|R
40|$|This thesis {{reports on}} {{work done in}} {{applying}} some of the concepts and architectures found in biological computation to computer algorithms. Biology has long inspired computer technology {{at the level of}} processing elements. This thesis explores the application of biologically inspired algorithms at a higher level-that of functional structures of the nervous system. The first chapter gives background on the attentional/awareness model of the brain, why it is important to biology and the advantages in real-time performance and in learning facilitation which we expect from applying it in computer algorithms. The second chapter examines the application of this model to a canonical computer science problem-the bin packing problem. Approaching this NP-complete problem when limited by computational resources and time constraints means that algorithms which throwaway large amounts of the information about the problem perform better than those which attempt to consider everything. The existence of an optimum in the size of a working memory needed to find the best solution under time pressure is shown. The transition between the regime of strict time constraints and more forgiving time constraints is quite sudden. Chapter 3 presents an analytical model for better understanding the performance of various bin packing algorithms. Chapter 4 examines the application of the attentional model to a real-time computer game testbed. This testbed is explained, and results are shown which illustrate that in a complex, unpredictable environment with tight time and resource constraints conditions, an algorithm which examines only that information which falls into a relatively small part of the playing area can win against player which addresses it all. Chapter 5 turns to an examination of the role of reduced informational representations upon learning. Solving of various logical-kinetic puzzles by a simulated segmented arm is done by a learning system. A <b>logic</b> supervisory <b>subsystem</b> utilizes attentional/awareness methods to train, and pass control of the different control levels of the articulate arm over to, the neural networks, adaptive resonance theory networks, and declarative computer memory which it trains. Finally, chapter 6 presents an overview and evaluation of the work. ...|$|R
40|$|As {{the scale}} of {{integration}} keeps growing, more and more sophisticated signal processing systems are being implemented on a VLSI chip. These signal processing applications not only demand great computation capacity but also consume considerable amounts of energy. While performance and area remain to be two major design goals, power consumption has become a critical concern in today’s VLSI system design. Multiplication is a fundamental operation in most arithmetic computing systems. Multipliers have large area, long latency and consume considerable power. Previous work on low-power multipliers focuses on low-level optimizations and has not considered well the arithmetic computation features and application-specific data characteristics. Binary multiplier {{is an integral part}} of the arithmetic <b>logic</b> unit (ALU) <b>subsystem</b> found in many processors. Booth's algorithm and others like Wallace-Tree suggest techniques for multiplying signed numbers that works equally well for both negative and positive multipliers. In this paper, we have used VHDL for describing and verifying a hardware design based on Booth's and some other efficient algorithms. Timing and correctness properties were verified. Instead of writing Test-Benches & Test-Cases we used Wave-Form Analyzer which can give a better understanding of Signals & variables and also proved a good choice for simulation of design...|$|R
40|$|This {{article was}} {{published}} in the journal IEEE Transactions on Reliability [© IEEE] and is also available at: [URL] Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. In safety critical applications, it is becoming quite common to improve reliability through the use of quadruplexed, redundant subsystems organized with 2 -out-of- 4 :G (2 oo 4 :G) <b>logic.</b> As the <b>subsystems</b> involved will generally be complex, comprising many individual components, they are likely to fail at a time-dependent rate λ(t). The maintenance schedule here is assumed to require failed subsystems to be repaired and workable within a given time τ of failure; and repairs are assumed to be minimal so that all functioning subsystems possess the same rate λ(t). Within this context, we consider the dependence of the system reliability measures on the allowed repair time τ by providing solutions to two integro-differential-delay equations (IDDEs) which bound the exact solution above and below; these bounds may be tightened by iterating the IDDEs to higher order. Results for the stationary system are used to investigate the order required to provide sufficiently tight bounds for the general case. In addition, we consider examples in support of the conjecture of Solov'yev and Zaytsev (Engineering Cybernetics, 1975) that if λ(t) τ is small, then the (asymptotic) instantaneous hazard function of the system hs(t), with a time-varying λ(t), will approach (λ(t) τ → 0) the limit hso(λ(t),τ), where hso(λ, τ) is the asymptotical hazard rate for the same system with constant failure rates. This method then allows for a simple analysis of the case of arbitrary time-varying λ(t) in terms of the much simpler stationary case...|$|R
40|$|This thesis {{presents}} resultsofmyresearchinthe fieldof {{programming control}} applications for robotic tasks. The main aimof thework hasbeen the definition {{and implementation of}} a control component framework for robotic applications tha uses a newly proposed middleware for networked embedded systems originated from the researchof European projectRUNES -Reconfigurable Ubiquitous Networked Embedded Systems. Component-based techniques in software development have manybenefits. Components arewell-defined entities that canbe replaced without affecting {{the rest of the}} systems, and can thus be developed separately, easily integrated, and are reusable. Such features are crucial for the development of large-scale complex systems. In this context, the component-based middleware developed by theRUNES project offereda flexible architecture for software development for sensor and mobile adhoc networks. Although the middleware already provides components to access network and operating system resources, there has been a need for control-oriented components necessary for the implementation of control applications. The definition, implementation and testing of the control technologies that have been used in the realization of a complex control applicationfor network reconfiguration in a disaster scenario environment will be described in detail. Forthesakeof concreteness, my workhasfocusedondevelopinga control component-based architecture foraspecific application, namely the navigation of autonomous vehicles using primarily vision forlocalization and for building a map of an unknown envirnment. Component-based design helps to separate <b>logic</b> functionalities in <b>subsystems</b> to build a complex architecture, improving reusabilityof code and reconfiguration of the application. Avisual servo scheme is used to steer the wheeled vehicle among locations using reference images. A topological image map is constructed to support this, based on images grabbed bythe on-board camera, along with a global feature-based metric map, obtained using extended Kalman filter techniques, that gives the robot the 3 D world perceptions, e. g. world geometry and obstacles. The combination of topological and metric maps allows the use of simple planners and, combined with a robust image processing technique like SIFT, to two important problems in the navigation of robots in unknown environments: the so-called kidnapped robot and closedpath detection problems. The solution here proposed also enables a team of multiple vehicles to merge their information, and to perform navigation using each other’s knowledge of the feasible paths. Experimental results on a laboratory setup are reported, showing the practicality of the proposed approach...|$|R
40|$|In every discourse, {{whether of}} the mind conversing with its own thoughts, or of the {{individual}} in his intercourse with others, there is an assumed or expressed limit within which the subjects of its operation are confined. Whatever may be {{the extent of the}} field within which all the objects of our discourse are found, that field may properly be termed the "universe of discourse" (UOD) (Boole, 1854 / 2003). According to Piaget, human adults normally know how to use properly classical propositional logic to manage their UOD. Piaget also showed that human propositional competence is realized via the integration of algebraic composition and relational ordering in formal logic based on the mathematical Klein group structure (KGS) (Inhelder & Piaget, 1955). In the last fifty years, many experiments made by psychologists of reasoning have often shown most adults commit logical fallacies in propositional inferences. They have so concluded, relying on many empirical evidences, that Piaget's claim about adults' competence in propositional logic was wrong and much too rationalist. In other words, according to experimental psychologists, Piaget was overestimating the logical capacities of average human adults in the use of classical propositional logical connectives. So, they abandoned his approach. Nevertheless, the KGS Piaget used can be reused to help us understand better what happens in spontaneous single human reasoning and in the production of fallacies. In fact, the KGS generates squares of opposition (SOO), and an important component of human rationality resides in the diagram of the SOO, as formal articulations of logical dependence between connectives. SOO are considered as important basic components of logical competence and of human predicative rationality (Beziau & Payette, 2012). The KGS captures all the fundamental transformations needed for the predicative proficiency of single human subject. But the formal rationality provided by the SOO is not spontaneous and therefore, should not be easy to learn for adults. By an abstract point of view, the Elementary Pragmatic Model (EPM) (De Giacomo et al., 2016) {{can be seen as the}} fundamental, logic description of two KGSs interacting with each other. In other words, EPM can model all the elementary interactions between two rational, interacting human subjects. Again, predicative competence for humans does not come for granted! This is the main reason why we need reliable and effective training tools to achieve full logic proficiency and competence, like EPM. EPM was developed in the late 1960 s following Gregory Bateson's constructivist participant observer concept in the "second order cybernetics". Later it was applied to develop interactive psychotherapy strategies, online counseling and E-therapy. EPM is a quite flexible tool for mapping cross- inter- and trans- disciplinary expertise. Since the beginning of the new millennium its application area has been extended to other disciplines and even to engineering problems like user modeling, constraint requirements elicitation, software creativity and adaptive system design and development. EPM allows predictive, predicative computation that facilitates anticipatory behavior (Nadin, 2014). As a further example, the KGS can be even interpreted as the complete transformation mapping of the human perception of our outer and inner universe representations, where the encoding process is carried out by human affectors (our biological sensors) and the decoding process is done by human effectors (our biological actuators). In this way, the single observer encoding and decoding of the classic Rosen modeling relationship (Rosen, 1985) can be computationally formalized at operative level (De Giacomo & Fiorini, 2017). The information process describing the dynamics of reality to anticipation means to acknowledge that deterministic and non­deterministic processes are complementary. Therefore, it is possible to conceive a convenient EPM-based schema for Ontological Uncertainty Management (OUM) System as in Fiorini (2015). Following neurophysiological findings by LeDoux (2002), we focus on ontological uncertainty (Lane & Maxfield, 2005) as an emergent phenomenon from a complex system. A dynamic ontological perspective can be thought of as an emergent, natural cross- inter- trans- disciplinary reality level (TRL) (Nicolescu, 1992; 1996) from, at least, a dichotomy of two fundamental, coupled, irreducible, and complementary computational subsystems: (A) reliable unpredictability, and (B) reliable predictability subsystem respectively. From a Top-Down (TD) management perspective, the reliable predictability concept can be referred to the traditional system reactive approach (lag <b>subsystem,</b> closed <b>logic,</b> to learn and prosper) and operative management techniques. The reliable unpredictability concept can be associated with the system proactive approach (lead <b>subsystem,</b> open <b>logic,</b> to survive and grow) and strategic management techniques. In fact, to behave realistically, the system must guarantee both Logical Aperture (to survive and grow) and Logical Closure (to learn and prosper), both fed by environmental "noise" (better… from what human beings call "noise"). EPM coupled to EPM extension as "Evolutive Elementary Pragmatic Model" (E 2 PM) represents a different implementation of the same OUM system concept as presented in Fiorini (2015). Therefore, traditional EPM can be thought as a reliable starting <b>subsystem</b> (closed <b>logic,</b> operative management (B)) to initialize a process of continuous self-organizing and self-logic learning refinement by E 2 PM (open <b>logic,</b> strategic management <b>subsystem</b> (A)). This approach can capture natural logic dynamics behavior, as a function of specific unpredictable perturbance, unknown at system design level. It is an original contribution to current evolutive modeling and simulation, offering an example of new forms of system self-evolutive behavior by cross- inter- and trans-disciplinarity modeling (e. g. forecasting, strategic foresight, anticipation, uncertainty management, embracing the unknown, creativity, etc.) for the children of the Anthropocene Era...|$|R

