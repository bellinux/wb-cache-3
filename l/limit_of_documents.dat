0|10000|Public
2500|$|... "A <b>limited</b> number <b>of</b> <b>documents</b> {{which have}} been {{analyzed}} by us, show that the agreement between the Austrian firm Vamed and Ukrmedpostach was signed without any mediators. The price for an Opel ambulance did not exceed that on a market’,- state Covington and Burling.|$|R
5000|$|The Library 2.0 blog {{notes that}} it could be very useful in {{education}} for marking assignments, but considers pricing a possible drawback as the free version <b>limits</b> the number <b>of</b> <b>documents</b> you can upload ...|$|R
50|$|Thompson joined {{hands with}} Senator Ron Wyden and {{introduced}} a bill to <b>limit</b> the number <b>of</b> <b>documents</b> that are classified and to overhaul the security clearance system in July 2014. The bill's fate is currently unclear.|$|R
50|$|Until 1852 {{no right}} existed {{for the general}} public to consult the records freely, even for {{scholarly}} purposes, despite the intention of the 1838 Public Record Office Act to enable public access. Fees were payable by lawyers who in return were permitted to consult a <b>limited</b> number <b>of</b> <b>documents.</b> These charges were abolished for serious historical and literary researchers after a petition was signed in 1851 by 83 people including Charles Dickens and the historians Lord Macaulay and Thomas Carlyle.|$|R
5000|$|On 13 November 2014, Hans-Joachim Eckert {{released}} a 42-page summary of his findings after reviewing Michael Garcia's report; the summary cleared both Russia and Qatar {{of any wrongdoing}} during the bidding for the 2018 and 2022 World Cups, leaving Russia and Qatar free to stage their respective World Cups. The summary noted that Russia provided [...] "only a <b>limited</b> amount <b>of</b> <b>documents</b> available for review", as the computers leased to the Russian team had been destroyed, and several email accounts were unable to be accessed.|$|R
2500|$|As {{early as}} 1983, the Center for the History of Chemistry {{expressed}} an interest in [...] "The Conservation of Historic American Chemical Instruments", in discussions of a possible joint project with the Smithsonian. [...] However, the center did not yet have exhibit or collections space to allow for the acquisition of any but the most <b>limited</b> quantities <b>of</b> <b>documents.</b> The center did curate a number of traveling exhibitions by collaborating with other organizations, including [...] "Joseph Priestley: Enlightened Chemist", [...] "Polymers and People", [...] "Scaling Up", [...] and [...] "Chemical Education in the United States".|$|R
40|$|We {{report on}} our {{examination}} of pages from the World Wide Web. We have analyzed {{data collected by}} the Inktomi Web crawler (this data currently comprises over 2. 6 million HTML documents). We have examined many characteristics <b>of</b> these <b>documents,</b> including: document size; number and types of tags, attributes, file extensions, protocols, and ports; the number of in-links; and the ratio <b>of</b> <b>document</b> size {{to the number of}} tags and attributes. For a more <b>limited</b> set <b>of</b> <b>documents,</b> we have examined the following: the number and types of syntax errors and readability scores. These data have been aggregated to create a number of ranked lists, e. g., the ten most-used tags, the ten most common HTML errors. Keywords: HTML, statistics, tools, World Wide Web...|$|R
40|$|This paper shows a novel {{approach}} to binarization techniques. It presents a way to obtain an optimum threshold using a semantic description of the histogram and a neural network. The intended applications of this technique are high precision OCR algorithms over a <b>limited</b> number <b>of</b> <b>document</b> types. The histogram of the input image is smoothed and its derivative is found. Using a polygonal version of the derivative and the smoothed histogram, a new description of the histogram is calculated. Using this description a general regression neural network is capable of obtaining an optimum threshold for our application. ...|$|R
50|$|The {{research}} on Okinawa's musical traditions {{was started by}} Tajima Risaburō {{at the end of}} the 19th century. He was followed by Katō Sango and Majikina Ankō among others. Under Tajima's influence, Iha Fuyū, who is known as the father of Okinawaology, conducted extensive {{research on}} a wide range of music genres of Okinawa, primarily by analyzing texts. Although he paid attention to Miyako and Yaeyama, his studies on these subfields remained in a preliminary stage, partly due to the <b>limited</b> availability <b>of</b> <b>documented</b> sources. In Miyako and Yaeyana, pioneering work in collecting and documenting folk songs was done by Inamura Kenpu and Kishaba Eijun, respectively.|$|R
40|$|Vesubia jugorum (Simon, 1881) (Araneae: Lycosidae) is a large-sized wolf spider {{that occurs}} in alpine rocky areas above 2, 000 m altitude. The species is stenoendemic, with a <b>limited</b> number <b>of</b> populations <b>documented</b> in the {{literature}} from the Maritime Alps (Italy, France). Due to the climate change, the current observed extent of occurrence (EEO 4, 412 km 2) and the area of occupancy (AOO 835 km 2) are declining...|$|R
40|$|Focused ethnographies {{can have}} {{meaningful}} application in primary, community, or hospital healthcare. They can be pragmatic and efficient ways to investigate specific phenomena important to individual clinicians or clinical specialities. While {{many examples of}} focused ethnographies are published, there is <b>limited</b> availability <b>of</b> guidance <b>documents</b> for conducting this research. This paper defines focused ethnographies, locates them within the ethnographic genre, justifies their use in healthcare research, and outlines the methodological processes...|$|R
40|$|There {{are several}} types of {{professional}} groups that provide tax advice in Australia: lawyers, accountants, and financial advisors, {{many of whom are}} registered tax agents. In many cases, the type of advice provided is the same; however, currently whilst lawyers can extend to their clients a blanket legal professional privilege (“LPP”) over confidential tax advice, clients of non-lawyer tax advisors (“NLTAs”) are presently only granted an administrative concession by the Australian Taxation Office (“ATO”) and then only over a <b>limited</b> range <b>of</b> <b>documents.</b> This article argues in favour of the enactment of a separate statutory tax advice privilege in Australia for accredited NLTAs and suggests a framework for determining which taxation professionals should be able to offer a tax advice privilege to their clients...|$|R
40|$|The city {{environment}} is rich with signage containing written language {{that helps us}} to define and understand {{the context of a}} given location. Unfortunately, almost all of this information is unreadable to current text recognition methods. Outside <b>of</b> the <b>limited</b> scope <b>of</b> <b>document</b> OCR, text recognition largely fails when faced with substantial variation in lighting, viewing angle, text orientation, size, lexicon, etc. This project aims to implement current techniques for image text recognition and expand on their shortcomings. The resulting algorithm is applied to Google Street View search results, in order to improve the initial viewport presented to the user when searching for local landmarks. The final success rate is low, and the negative results specifically highlight difficulties in performing this kind of recognition. 1...|$|R
40|$|We develop {{further the}} S-D {{threshold}} optimization method. Specifically, {{we deal with}} the bias problem introduced by receiving relevance judgements only for documents retrieved. The new approach estimates the parameters of the exponential-Gaussian score density model without using any relevance judgements. The standard expectation maximization (EM) method for resolving mixtures of distributions is used. In order to <b>limit</b> the number <b>of</b> <b>documents</b> that need to be buffered, we apply nonuniform document sampling, emphasizing the right tail (high scores) of the total score distribution...|$|R
40|$|One major {{difficulty}} in performing ad-hoc search on mi-croblogs such as Twitter is the <b>limited</b> vocabulary <b>of</b> each <b>document</b> due their short length. In this paper, two ap-proaches to addressing this issue are presented. The first is query expansion through pseudo-relevance feedback {{and the other}} is <b>document</b> expansion <b>of</b> tweets using web documents linked from the body of the tweet. Tweets are expanded by concatenating the contents of the title tag and the meta descriptor tags <b>of</b> the <b>document</b> to the tweet itself. These two approaches gave additive gains in MAP and Precisio...|$|R
50|$|On September 28, 2016 {{the defense}} team filed a subject motion to compel discovery, or to dismiss all charges. On January 17, 2017 Judge Pohl granted this motion in part, the {{government}} is to provide {{the defense team}} with specified information from a <b>limited</b> number <b>of</b> classified <b>documents</b> pertaining to the decommission of the black site. All other requests for compelling discovery were denied, as was the request for dismissal of charges.|$|R
40|$|This article {{deals with}} the bookstores {{established}} in Ankara until the year of 1960. The information about {{the first years of}} bookselling and the first bookstores in Ankara is considerably scarce because <b>of</b> the very <b>limited</b> number <b>of</b> written <b>documents</b> that survived to our day. Within this scope and by means of press clippings, book covers, bookmarks, interviews, advertisements and various sources, the article {{takes a look at the}} bookstores in Ankara, some of which also served as publishing houses, between 1930 - 1960...|$|R
40|$|Hierarchical {{multi-label}} classification assigns {{a document}} to multiple hierarchical classes. In this paper {{we focus on}} hierarchical multi-label classification of social text streams. Concept drift, complicated relations among classes, and the <b>limited</b> length <b>of</b> <b>documents</b> in social text streams make this a challenging problem. Our approach includes three core ingredients: short document expansion, time-aware topic tracking, and chunk-based structural learning. We extend each short document in social text streams to a more comprehensive representation via state-of-the-art entity linking and sentence ranking strategies. From documents extended in this manner, we infer dynamic probabilistic distributions over topics by dividing topics into dynamic "global" topics and "local" topics. For {{the third and final}} phase we propose a chunk-based structural optimization strategy to classify each document into multiple classes. Extensive experiments conducted on a large real-world dataset show the effectiveness of our proposed method for hierarchical multi-label classification of social text streams...|$|R
40|$|In {{order to}} realize {{seamless}} integration {{of paper and}} electronic documents, {{it is at least}} necessary to assure error free conversion from one to the other. In general, the conversion from paper to electronic documents is the task <b>of</b> <b>document</b> image understanding. Although its research has made remarkable progress, it is still a hard task without <b>limiting</b> the type <b>of</b> <b>documents.</b> This paper presents a completely different approach to this task on condition that printed documents have their originals in electronic form. The proposed method employs fine dots to represent data <b>of</b> electronic <b>documents</b> and places the dots on white space (backgrounds) of pages. Since the data is encoded with an error correcting code, it is guaranteed to be correctly recovered from the scanned images <b>of</b> <b>documents.</b> Experimental results show that a page with normal foreground objects (characters and other things) can contain more than 4 KB of data, even when errors up to 20 % of the data are permitted. 1...|$|R
30|$|Overcoming this {{uncertainty}} can {{be achieved}} by using universal training programmes such as the European Diploma in Radiology (EDiR), which offers the guarantee of standardisation in acquired knowledge and ensures the confidence of trainees. A significant percentage (59.7 %) of the trainees is aware of the diploma, but, on the other hand, although the diploma is based on the ESR European Training Curriculum, it is the trainees’ <b>limited</b> knowledge <b>of</b> this <b>document</b> that indicates that the diffusion and promotion of this information needs to be further improved [4, 5].|$|R
40|$|This {{document}} {{is intended to}} (1) identify separation technologies which are being considered for sludge treatment at various DOE sites, (2) define {{the current state of}} sludge treatment technology, (3) identify what research and development is required, (4) identify current research programs within either DOE or academia developing sludge treatment technology, and (5) identify commercial separation technologies which may be applicable. Due to the <b>limited</b> scope <b>of</b> this <b>document,</b> technical evaluations regarding the need for a particular separations technology, the current state of development, or the research required for implementation, are not provided...|$|R
40|$|AbstractThe {{internet}} {{and the emergence of}} social networks produce terabytes of data every day. In this big data scenario, the ability to outsource the data to a cloud storage facility saves the data management and storage facility cost. Some major challenges with this scheme are providing security and ensuring the privacy of the outsourced data. Although data security can be achieved through encryption, searching on encrypted data become a complex task. The proposed work suggests an efficient searching scheme for encrypted cloud data based on hierarchical clustering <b>of</b> <b>documents.</b> The hierarchical clustering method preserves the semantic relationship between the documents in the encrypted domain to speed up the search process. Consequently, the proposed system has linear computational complexity during the search phase in response to an exponential increase in the number <b>of</b> <b>documents.</b> The system also ensures data privacy by providing only <b>limited</b> access <b>of</b> the <b>documents</b> to the different types of users by implementing access control mechanisms resulting in more secured data storage in the cloud...|$|R
40|$|Most of the {{suggested}} {{solutions for the}} anaphora problem have been concerned with getting the correct answer in all situations. This means they must involve large amounts of syntactic, semantic and world knowledge, and therefore can only be applied to a <b>limited</b> scope <b>of</b> <b>documents.</b> These solutions do not scale well. We have designed and implemented a scalable heuristic approach to the anaphora problem. Our main concern was not to get the correct answer in all situations, but to create an easily scalable solution that will find the correct answer most of the time. We designed our heuristics in two stages. First we created the simplest possible solution we could. We then used this simple solution as a baseline against which to measure our more advanced heuristics. Our heuristic solutions work for both definite noun phrase anaphora and pronoun anaphora. We tested our implementations on two moderate-sized pieces of text, containing a total of 670 definite noun phrases and 95 p [...] ...|$|R
40|$|The {{breeding}} {{range of the}} Summer Tanager (Piranga rubra) is well documented and expands across the southern U. S. extending northward to New Jersey and west along {{and south of the}} Great Lakes to {{the eastern edge of the}} Great Plains (Terres 1991; Robinson 1996). In Nebraska the species is generally confined to the Lower Missouri and Platte River Valleys where it occurs locally (Sharpe et al. 2001). Because the species exists in relatively low numbers across southeastern Nebraska, there are few breeding and nesting records for the state. Fewer than 10 breeding records, including one historical account have been described for Nebraska (Ducey 1988, Mollhoff 2001, Sharpe et al 2001, Mollhoff 2004). Due to the <b>limited</b> number <b>of</b> <b>documented</b> reports, our understanding of the breeding distribution and nesting ecology of the Summer Tanager in Nebraska is incomplete. Here I describe a late-season breeding effort by the Summer Tanager in southeastern Nebraska and provide comments on nesting behavior...|$|R
40|$|The {{requirements}} for autonomous control of spacecraft functions {{have been well}} articulated by {{a wide selection of}} US Air Force mission analyses and architecture studies. The opportunities however, to implement these autonomy functions have been <b>limited.</b> An overview <b>of</b> <b>documented</b> requirements is presented to demonstrate the scope of autonomous functions needed, and potential time frames for implementation is derived. The missed opportunities are analyzed to provide lessons learned, and near term opportunities will be reviewed. The current initiatives at the Phillips Laboratory are described in terms of the requirements addressed and the proposed approaches will show program risk reduction for satellite autonomy technology insertion into space operations...|$|R
40|$|Content analysis, {{restricted}} {{within the}} <b>limits</b> <b>of</b> written textual <b>documents</b> (WTDCA), {{is a field}} which is greatly in need of extensive interdisciplinary research. This would clarify certain concepts, especially those concerned with "text", as a new central nucleus of semiotic research, and "content", or the informative power of text. The objective reality (syntax) <b>of</b> the written <b>document</b> should be, in the cognitive process that all content analysis entails, interpreted (semantically and pragmatically) in an intersubjective manner {{with regard to the}} context, the analyst's knowledge base and the documentary objectives. The contributions of semiolinguistics (textual), logic (formal) and psychology (cognitive) are fundamental to the conduct of these activities. The criteria used to validate the results obtained complete the necessary conceptual reference panorama...|$|R
40|$|The {{combination}} of the maturing technology of graphical user interfaces (GUI) with Advanced Information Systems (AIS) based on relational databases {{has made it possible}} to design an application which can cope with the document flow within a large organization. Such an application should allow for the creation <b>of</b> electronic <b>documents</b> in a user friendly way, automatic routing <b>of</b> these <b>documents</b> through the bureaucratic chain in the organization, pin-pointing <b>of</b> <b>documents</b> within the chain, detection of bottle necks in the <b>document</b> flow, archival <b>of</b> old <b>documents,</b> etc. The electronic document handling (EDH) application has been developed {{to address the problem of}} the flow of paper within CERN (around 500, 000 office documents per year). The tool is based on Oracle RDBMS, is fully integrated with our new AIS system and is based on a client-server architecture. The clients run on different platforms: a 'dumb terminal' client running on VM/CMS, and a graphical client running on Apple Macintosh, IBM-compatible PCs (under MS Windows) as well as X-Windows platforms. The graphical client, on which we will focus in this document, supports native look and feel. The first phase of EDH, which began in January 1992, addresses only a <b>limited</b> number <b>of</b> <b>document</b> types. There are presently 500 users of EDH who have created around 10000 documents. Some important topics about the client-server architecture will be described. The evolution to Oracle 7 will also be mentioned...|$|R
40|$|This paper {{examines}} the problems involved in subject retrieval from full-text databases of secondary {{materials in the}} humanities. Ten such databases were studied and their search functionality evaluated, focusing on factors such as Boolean operators, document surrogates, limiting by subject area, proximity operators, phrase searching, wildcards, weighting <b>of</b> search terms, <b>limiting</b> by type <b>of</b> <b>document,</b> controlled vocabulary indexing and ranking, and display of search results. The author suggests ways in which full-text searching might be improved, whether by enhancement of database records, by introduction of enhanced search functionality, or by the education of searchers in more effective search techniques. The conclusion is that current digitisation projects are not producing databases that {{meet the needs of}} scholars...|$|R
40|$|The {{sharing of}} caches among proxies is an {{important}} technique to reduce Web traffic, alleviate network bottlenecks and improve response time <b>of</b> <b>document</b> requests. Most existing work on cooperative caching {{has been focused on}} serving misses collaboratively. Very few have studied the effect <b>of</b> cooperation on <b>document</b> placement schemes and its potential enhancements on cache hit ratio and latency reduction. In this paper we propose a new document placement scheme, which takes into account of the contentions at individual caches in order to <b>limit</b> the replication <b>of</b> <b>documents</b> within a cache group and increase document hit ratio. The main idea of this new scheme is to view the aggregate disk space of the cache group as a global resource of the group, and uses the concept of cache expiration age to measure the contention of individual caches. The decision of whether to cache a document at a proxy is made collectively among the caches that already have a copy <b>of</b> this <b>document.</b> We refer to this new document placement scheme as the expiration age based scheme (EA scheme for short). The EA scheme effectively reduces the replication <b>of</b> <b>documents</b> across the cache group, while ensuring that a copy <b>of</b> the <b>document</b> always resides in a cache where it is likely to stay for the longest time. We report our initial study on the potentials and <b>limits</b> <b>of</b> the EA scheme using both analytic modeling and trace-based simulation. The experiments show that the EA scheme yields higher hit rates and better response times compared to the existing document placement schemes used in most of the caching proxies...|$|R
40|$|Abstract. Cross-language {{information}} retrieval (CLIR), where queries and documents are in di erent languages, needs a translation <b>of</b> queries and/or <b>documents,</b> {{so as to}} standardize both of them into a common representation. For this purpose, the use of machine translation is an e ective approach. However, computational cost is prohibitive in translating large-scale document collections. To resolve this problem, we proposeatwo-stage CLIR method. First, we translate a given query into the document language, and retrieve a <b>limited</b> number <b>of</b> foreign <b>documents.</b> Second, we machine translate only those documents into the user language, and re-rank them based on the translation result. We also show the e ectiveness of our method by way of experiments using Japanese queries and English technical documents. ...|$|R
50|$|The {{identification}} {{phase is}} when potentially responsive documents are identified for further analysis and review. In Zubulake v. UBS Warburg, Hon. Shira Scheindlin ruled that failure {{to issue a}} written legal hold notice whenever litigation is reasonably anticipated, will be deemed grossly negligent. This created the idea of legal holds, eDiscovery, and electronic preservation. Custodians who are in possession of potentially relevant information or documents are identified. To ensure a complete identification of data sources, data mapping techniques are often employed. Since the scope of data can be overwhelming in this phase, attempts are made to reduce the overall scope during this phase - such as <b>limiting</b> the identification <b>of</b> <b>documents</b> to a certain date range or search term(s) to avoid an overly burdensome request.|$|R
40|$|AND KEY WORDS The {{purpose of}} my thesis is {{to analyze the}} {{institute}} of criminal informant as a legal instrument {{in the fight against}} organized crime. I introduce the historical background of cooperation between criminals and state on uncovering criminal activities. Then I follow with the analysis of current Czech legislation of cooperating accused and the so far <b>limited</b> cases <b>of</b> its application and also offer a comparative view of the law and its application in United States, Great Britain and Slovakia. The thesis is composed of six chapters. Chapter One is introductory and defines basic terminology used in the thesis: cooperating accused and crown witness. In this chapter I argue that the terms can be used interchangeably In the second chapter I introduce the history of cooperation between criminals and the state. Special subsection deals with the development of Czech legislation on cooperating accused. Chapter Three examines relevant Czech legislation and the <b>limited</b> number <b>of</b> <b>documented</b> cases <b>of</b> application of the institute. Chapter Four offers a comparative view of relevant legislation and approach to decision-making by trial courts in the United States and Great Britain and also the legislation passed in neighboring Slovakia. Chapter Five concentrates on problems resulting from organized crime, [...] ...|$|R
40|$|International audienceThe {{work with}} almost extinct {{languages}} demands special strategies, and linguists {{are confronted with}} a number <b>of</b> <b>limits</b> in <b>documenting</b> and describing such languages. This paper presents two case studies of almost extinct Bolivian Tupi-Guarani languages, Jorá and Guarasu. The paper focuses on accounts of ethically difficult situations and discusses how the linguists have dealt with these challenges. It then shows our linguistic analysis <b>of</b> very <b>limited</b> datasets we have gathered and how with evidence from phonetics, morphology and lexicon, we can suggest an internal classification for these Tupi-Guarani languages...|$|R
40|$|In {{this paper}} we {{demonstrate}} {{that in an}} ideal Distributed Information Retrieval environment, taking the ability of each collection server to return relevant documents into account when selecting collections can be effective. Based on this assumption, we suggest {{a new approach to}} resolve the collection selection problem. In order to predict a collection's ability to return relevant documents, we inspect a <b>limited</b> number n <b>of</b> <b>documents</b> retrieved from each collection and analyze the proximity of search keywords within them. In our experiments, we vary the underlying parameter n of our suggested model to define the most appropriate number <b>of</b> top <b>documents</b> to be inspected. Moreover, we evaluate the retrieval effectiveness of our approach and compare it with both the centralized indexing and the CORI approaches [1], [16]. Preliminary results from these experiments, conducted on WT 10 g test collection, tend to demonstrate that our suggested method can achieve appreciable retrieval effectiveness...|$|R
40|$|International audienceThis paper {{describes}} a segmentation method <b>of</b> continuous <b>document</b> flow. A document flow {{is a list}} of successive scanned pages, put in a production chain, representing several documents without explicit separation mark between them. To separate the documents for their recognition, it is needed to analyze the content of the successive pages and to point out the <b>limit</b> pages <b>of</b> each <b>document.</b> The method proposed here is similar to the variable horizon models (VHM) or multi-grams used in speech recognition. It consists in maximizing the flow likelihood knowing all the Markov Models of the constituent elements. As the calculation of this likelihood on all the flow is NP-complete, the solution consists in studying them in windows of reduced observations. The first results obtained on homogeneous flows of invoices reaches more than 75 % of precision and 90 % of recall...|$|R
40|$|It was in 1953 {{that the}} train of events started which brought about my {{participation}} in the investigation which {{is the subject of}} this report. R. G. Thorne, of the Royal Aircraft Establishment, and I had been closely associated with the development of the Nationaal Luchtvaart- laboratorium Card Catalogue of Aerodynamic Data (Ref. 1). This was an index designed for the retrieval of information in answer to very specific requests, and was far removed from the systems used in conventional library indexing. In that the average time taken to index each document was 1. 5 hours, it was comparatively expensive, although the cost was shared out on a subscription basis amongst a number of organisations. Clearly, however, such an index could only be used for a relatively <b>limited</b> range <b>of</b> <b>documents</b> that were <b>of</b> particular significance, and Thorne and I were prepared to accept the possibility that in certain circumstances an organisation might be economically justified in maintaining two different types of indexes covering an overlapping range <b>of</b> <b>documents.</b> The Universal Decimal Classification was widely used in England and, in spite of many criticisms, was on the whole meeting the requirements of its users for a general indexing system. We were looking for another system which would fulfil the same function as the NLL scheme, but which might be less expensive and therefore more attractive economically for a single organisation to operate. An investigation supported by a grant to ASLIB by the National Science Foundatio...|$|R
