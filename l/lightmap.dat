22|43|Public
2500|$|The {{animation}} {{was done}} in Maya 8.5 with some motion capture animations tweaked in MotionBuilder. 3D artists, animators and level designers used Maya as their production environment, which is unusual considering that most 3D games are produced using 3ds max. A large library of custom Maya tools and scripts was created to support these different disciplines. Tools like [...] "Hyperion", a <b>lightmap</b> rendering software, were used in place of Mayaâ€™s viewport rendering software. In-game animation was assisted with another tool they created called [...] "AnimationBlender" [...] and particle effects were edited using a tool called [...] "Particle Editor". They also created a tool called [...] "ColorTweaker", which gave them the possibility to do color correction on the PS3 in real-time.|$|E
50|$|<b>Lightmap</b> {{resolution}} and scale {{are two different}} things. The resolution is the area, in pixels, available for storing one or more surface's lightmaps. The number of individual surfaces that can fit on a <b>lightmap</b> {{is determined by the}} scale. Lower scale values mean higher quality and more space taken on a <b>lightmap.</b> Higher scale values mean lower quality and less space taken. A surface can have a <b>lightmap</b> that has the same area, so a 1:1 ratio, or smaller, so the <b>lightmap</b> is stretched to fit.|$|E
5000|$|Pre-created {{materials}} and shaders, including pre-calculated <b>lightmap</b> support ...|$|E
50|$|<b>Lightmaps</b> {{in games}} are usually colored texture maps, or per vertex colors. They are usually flat, without {{information}} about the light's direction, whilst some game engines use multiple <b>lightmaps</b> to provide approximate directional information to combine with normal-maps. <b>Lightmaps</b> may also store separate precalculated components of lighting information for semi-dynamic lighting with shaders, such as ambient-occlusion & sunlight shadowing.|$|R
5000|$|... #Caption: <b>Lightmaps</b> and vertex {{lighting}} in Irrlicht, rendering {{a simple}} dungeon scene ...|$|R
50|$|Static, pre-computed radiosity may be {{displayed}} in realtime via <b>Lightmaps</b> on current desktop computers with standard graphics acceleration hardware.|$|R
5000|$|... #Caption: A complex {{scene with}} {{corresponding}} <b>lightmap</b> (shown on the right).|$|E
5000|$|... full <b>lightmap</b> control (UV2, import, export, {{built-in}} shadow mapper with Ambient occlusion support) ...|$|E
50|$|Lightmaps are {{composed}} of lumels (Lumination elements), analogous to texels in Texture Mapping. Smaller lumels yield a higher resolution <b>lightmap,</b> providing finer lighting detail {{at the price of}} reduced performance and increased memory usage. For example, a <b>lightmap</b> scale of 4 lumels per world unit would give a lower quality than a scale of 16 lumels per world unit. Thus, in using the technique, level designers and 3d artists often have to make a compromise between performance and quality; if high resolution lightmaps are used too frequently then the application may consume excessive system resources, negatively affecting performance. <b>Lightmap</b> resolution and scaling may also be limited by the amount of disk storage space, bandwidth/download time, or texture memory available to the application. Some implementations attempt to pack multiple lightmaps together in a process known as atlasing to help circumvent these limitations.|$|E
50|$|Unity Technologies has {{announced}} that the next Unity version 3.0 will feature built-in Beast <b>lightmapping</b> and global illumination off the shelf.|$|R
50|$|Static <b>lightmaps</b> and 3D light {{sources were}} also {{added in the}} BSP files storing the levels, {{allowing}} for more realistic lighting.|$|R
50|$|Quake also {{incorporated}} {{the use of}} <b>lightmaps</b> and 3D light sources, {{as opposed to the}} sector-based static lighting used in games of the past. id Software's innovation has been used for many 3D games released since, particularly first-person shooters, though id Software switched to a Unified lighting and shadowing model for Doom 3 (however, they switched back to a <b>lightmapped</b> or semi-lightmapped method starting with RAGE). After a map had been pruned of excess polygons, a second preprocessing system was used to precalculate and bake the <b>lightmaps</b> into the game map to further reduce load on the CPU when playing the game. However, full light processing could take an extremely long time, so for the initial map design process, lesser-quality light processing could be done, but at the cost of creating a jagged stair-step lightcast around lights.|$|R
50|$|The X3D {{extension}} supports multi-stage and multi-texture rendering; it {{also supports}} shading with <b>lightmap</b> and normalmap. Starting in 2010, X3D has supported deferred rendering architecture. Now X3D can import SSAO, CSM and Realtime Environment Reflection/Lighting. The user {{can also use}} optimizations including BSP/QuadTree/OctTree or culling in the X3D scene.|$|E
50|$|Version 0.6 was {{released}} on 8 March 2012. It comes with sRGB <b>lightmap</b> rendering, a new menu interface, 4 new maps, an integrated statistics system (XonStats), a Sandbox editing mode and the long-awaited feature of ClientSide QuakeC (CSQC) networked players. Bug fixes and optimisations have also been made.|$|E
50|$|After release, it {{immediately}} forked, {{as did the}} level design. Much of the engine remained in Quake II and Quake III Arena. The Quake engine, like the Doom engine, used binary space partitioning (BSP) to optimise the world rendering. The Quake engine also used Gouraud shading for moving objects, and a static <b>lightmap</b> for nonmoving objects.|$|E
40|$|We {{present a}} method that makes the use of photon radiosity methods {{feasible}} for complex scenes when a totally accurate solution is not essential. This is accomplished by using orientation <b>lightmaps,</b> which average the illumination of complex objects depending on the surface normal. Through this averaging, they considerably reduce the variance of the stochastic solution. For {{the use of these}} specialised <b>lightmaps,</b> which consume comparatively small amounts of memory, no changes have to be made to the actual photon tracing algorithm. Also, they can be freely mixed with normal <b>lightmaps</b> and inserted at any point in the scene description graph. This gives the user good control over the amount of inaccuracy he introduces by their application. The area computations necessary for their insertion are performed using a stochastic sampling method that performs well for highly complex objects. 1 Introduction In the field of photorealistic computer graphics a particular problem has be [...] ...|$|R
50|$|Real-time water {{rendering}} using pixel lighting, bump mapping and masking for smooth shoreline transitions. Generation of water layers masks with brushes or based on terrain heights. Coloring and <b>lightmapping</b> of water based on terrain texture layers.|$|R
50|$|John Carmack's Quake was {{the first}} {{computer}} game to use <b>lightmaps</b> to augment rendering. Before <b>lightmaps</b> were invented, realtime applications relied purely on Gouraud shading to interpolate vertex lighting for surfaces. This only allowed low frequency lighting information, and could create clipping artefacts close to the camera without perspective-correct interpolation. Discontinuity meshing was sometimes used especially with radiosity solutions to adaptively improve the resolution of vertex lighting information, however the additional cost in primitive setup for realtime rasterization was generally prohibitive. Quake's software rasterizer used surface caching to apply lighting calculations in texture space once when polygons initially appear within the viewing frustum (effectively creating temporary 'lit' versions of the currently visible textures as the viewer negotiated the scene).|$|R
50|$|A <b>lightmap</b> is a data {{structure}} used in lightmapping, {{a form of}} surface caching in which the brightness of surfaces in a virtual scene is pre-calculated and stored in texture maps for later use. Lightmaps are most commonly applied to static objects in realtime 3d graphics applications, such as video games, {{in order to provide}} lighting effects such as global illumination at a relatively low computational cost.|$|E
50|$|To {{optimize}} the software rendering engine, lightmaps were shared by polygons that were close in space, {{and in the}} same leaf of the BSP tree. This means that quite often polygons using the same main texture could not be rendered at the same time with the 3D acceleration, due to the multi-texturing second unit having to be reconfigured with another <b>lightmap.</b> This architecture decision reduced hardware-accelerated rendering performance.|$|E
5000|$|... 3D {{scenes are}} {{generally}} {{composed of two}} things: 3D geometry, and the textures that cover that geometry. Texture units in a video card take a texture and 'map' it {{to a piece of}} geometry. That is, they wrap the texture around the geometry and produce textured pixels which can then be written to the screen.Textures can be an actual image, a <b>lightmap,</b> or even normal maps for advanced surface lighting effects.|$|E
5000|$|Leadwerks Game Engine {{began as}} a free {{companion}} to the BSP map editor 3D World Studio. Version 1.0 of Leadwerks Game Engine was released in 2007. [...] The engine utilized OpenGL 2.1 and used a combination of texture-based <b>lightmaps</b> and per-vertex lighting.|$|R
5|$|According to John Carmack, {{the lead}} {{graphics}} engine developer at id Software, {{the technology of}} Doom 3 was supported by three primary features: unified lighting and shadowing, complex animations and scripting that showed real-time with fully dynamic per-pixel lighting and stencil shadowing, and GUI surfaces that add extra interactivity to the game. The key advance of the id Tech 4 graphics engine developed for Doom 3 is the unified lighting and shadowing. Rather than computing or rendering <b>lightmaps</b> during map creation and saving that information in the map data, most light sources are computed in real-time. This allows lights to cast shadows even on non-static objects such as monsters and machinery, which was impossible with static non-directional <b>lightmaps.</b> A shortcoming {{of this approach is}} the engine's inability to render soft shadows and global illumination.|$|R
50|$|<b>Lightmaps</b> {{can also}} be {{calculated}} in real-time for good quality colored lighting effects that are not prone to the defects of Gouraud shading, although shadow creation must still be done using another method such as stencil shadow volumes or shadow mapping, as real-time ray-tracing is still too slow to perform on modern hardware in most 3D engines.|$|R
50|$|Irrlicht was {{designed}} to be able to load and save the current scene to an XML file; this combined with the engine's open-source licensing model has attracted various programmers and developers to create world editors for Irrlicht to simplify the world-creation process. One such example is the irrEdit world editor, developed by Nikolaus Gebhardt {{and other members of the}} company Ambiera. IrrEdit contains a radiosity <b>lightmap</b> generator and a scripting interface using Squirrel scripts.|$|E
50|$|The base {{texture and}} the <b>lightmap</b> {{of a wall}} were {{rendered}} at the same time: a Surface Cache was creating new Surfaces, which are new pre-lighted textures which combines the base and light map textures baked together. Surfaces not used since a few frames were released, while new required Surfaces were dynamically created. Generating the surfaces was consuming less time than a secondary lighting pass would have.To save memory, smaller surfaces using mipmaps of the original texture were generated first for further walls.|$|E
50|$|In the 2000s, many {{companies}} like Bitmanagement improved the quality level of virtual effects in VRML {{to the quality}} level of DirectX 9.0c, but {{at the expense of}} using proprietary solutions. All main features like game modeling are already complete. They include multi-pass render with low level setting for Z-buffer, BlendOp, AlphaOp, Stencil, Multi-texture, Shader with HLSL and GLSL support, realtime Render To Texture, Multi Render Target (MRT) and PostProcessing. Many demos shows that VRML already supports <b>lightmap,</b> normalmap, SSAO, CSM and Realtime Environment Reflection along with other virtual effects.|$|E
50|$|The {{character}} {{models are}} lit and shaded using Gouraud shading while the levels (stored in the BSP format) are lit either with <b>lightmaps</b> or Gouraud shading {{depending on the}} user's preference. The engine is able to take colored lights from the lightgrid and apply them to the models, resulting in a lighting quality that was, for its time, very advanced.|$|R
50|$|The level format, as with {{previous}} id Software engines, used binary space partitioning. The level environments were lit using <b>lightmaps,</b> a method in which light data for each surface is precalculated (this time, via a radiosity method) and stored as an image, {{which is then}} {{used to determine the}} lighting intensity each 3D model should receive, but not its direction.|$|R
5|$|When {{creating}} {{the look of}} the Infected, the art team cycled through various iterations. Some early ideas included the Infected looking like aliens or zombies. The final design was chosen when lead character artist Michael Knowland incorporated images of diseases and fungal growth onto a human. He expressed the difficulty in changing the art from 2D to 3D, which would allow viewing from different angles. The process of sending completed concept art to the lighting and visual effects artists, who re-create the art within the game's engine. Due to the lack of artificial light sources in the game's world, the team was forced to work with natural light. To achieve high quality lighting, they used <b>lightmaps.</b> The use of <b>lightmaps</b> led to various problems, such as the discontinuities in the lighting; this was fixed by slightly modifying the texel intensities. When characters were added to scenes, they initially looked out of place; the addition of a shadow generally fixed this.|$|R
50|$|When {{creating}} lightmaps, any lighting {{model may}} be used, because the lighting is entirely precomputed and real-time performance {{is not always}} a necessity. A variety of techniques including ambient occlusion, direct lighting with sampled shadow edges, and full radiosity bounce light solutions are typically used. Modern 3d packages include specific plugins for applying light-map UV-coordinates, atlas-ing multiple surfaces into single texture sheets, and rendering the maps themselves. Alternatively game engine pipelines may include custom <b>lightmap</b> creation tools. An additional consideration is the use of compressed DXT textures which are subject to blocking artifacts - individual surfaces must not collide on 4x4 texel chunks for best results.|$|E
5000|$|The {{animation}} {{was done}} in Maya 8.5 with some motion capture animations tweaked in MotionBuilder. 3D artists, animators and level designers used Maya as their production environment, which is unusual considering that most 3D games are produced using 3ds max. A large library of custom Maya tools and scripts was created to support these different disciplines. Tools like [...] "Hyperion", a <b>lightmap</b> rendering software, were used in place of Mayaâ€™s viewport rendering software. In-game animation was assisted with another tool they created called [...] "AnimationBlender" [...] and particle effects were edited using a tool called [...] "Particle Editor". They also created a tool called [...] "ColorTweaker", which gave them the possibility to do color correction on the PS3 in real-time.|$|E
40|$|This bachelor's thesis deals {{the design}} and {{implementation}} of a <b>Lightmap</b> Generation Tool. The aim of this thesis is to describe and demonstrate all steps which are necessary for <b>lightmap</b> creation, specifically unwrapping 3 D object geometry process and consequently shading it by the ray-tracing method. The scene system and the used engine are also described in this thesis. This work is concluded by a several experiments, along with image documentation, followed by the possibilities of the future work...|$|E
40|$|We {{present a}} {{computer}} graphics simulation framework to pre-visualize and tune {{the parameters of}} an advanced lighting controller for a given illuminated environment. The objective {{is to show that}} the simulation framework makes it easy for a user to predict the controllerâ€™s behavior and modify it with minimal effort. Our methodology involves off-line pre-computation of <b>lightmaps</b> created from photorealistic rendering of the scene in several basis lighting configurations, and the subsequent combination of these <b>lightmaps</b> in a video game engine. We demonstrate our framework in a series of experiments in a simulation of a con-ference room currently under physical construction, showing how the controller can be easily modified to explore different lighting behaviors and energy use tradeoffs. The result of each experiment is a computer-generated animation of the lighting in a room over time from a single viewpoint, accompanied by estimated measurements of source input, light sensor output, and energy us-age. A secondary objective is to match the simulation as closely as possibl...|$|R
50|$|When {{creating}} {{the look of}} the Infected, the art team cycled through various iterations. Some early ideas included the Infected looking like aliens or zombies. The final design was chosen when lead character artist Michael Knowland incorporated images of diseases and fungal growth onto a human. He expressed the difficulty in changing the art from 2D to 3D, which would allow viewing from different angles. The process of sending completed concept art to the lighting and visual effects artists, who re-create the art within the game's engine. Due to the lack of artificial light sources in the game's world, the team was forced to work with natural light. To achieve high quality lighting, they used <b>lightmaps.</b> The use of <b>lightmaps</b> led to various problems, such as the discontinuities in the lighting; this was fixed by slightly modifying the texel intensities. When characters were added to scenes, they initially looked out of place; the addition of a shadow generally fixed this.|$|R
5|$|Graphically, F.E.A.R. uses normal mapping and {{parallax}} mapping to give textures a {{more realistic}} appearance; the latter is used to {{give the appearance of}} depth to flat bullet hole sprites on walls. Volumetric lighting and <b>lightmapping</b> are included {{with the addition of a}} per-pixel lighting model, allowing complex lighting effects to be developed. Vertex, pixel and high-level shaders, including a host of additional special effects, are also featured in Jupiter EX.|$|R
