100|65|Public
25|$|An {{important}} limitation for HDR {{photography is}} that any movement between successive images will impede or prevent success in combining them afterwards. Also, as one must create several images (often three or five and sometimes more) to obtain the desired <b>luminance</b> <b>range,</b> such a full 'set' of images takes extra time. HDR photographers have developed calculation methods and techniques to partially overcome these problems, {{but the use of}} a sturdy tripod is, at least, advised.|$|E
5000|$|Photographers use [...] "dynamic range" [...] for the <b>luminance</b> <b>range</b> {{of a scene}} being photographed, or {{the limits}} of <b>luminance</b> <b>range</b> that a given digital camera or film can capture, or the opacity range of {{developed}} film images, or the [...] "reflectance range" [...] of images on photographic papers.|$|E
5000|$|... 1. We {{know that}} each of the three R,G,B {{channels}} has a range of values from 0-255(8 bit). So consider a photo that has a <b>luminance</b> <b>range</b> of 0-255.|$|E
5000|$|A {{synonym for}} {{exposure}} value (EV) (e.g., Kyoritsu calibrated light sources, {{for which the}} <b>luminance</b> <b>ranges</b> are specified in terms of &ldquo;LV at ISO 100&rdquo;. Kyoritsu specify the <b>luminance</b> <b>ranges</b> of their multi-function camera testers in EV, presumably at ISO 100).|$|R
40|$|AbstractA {{rectifying}} {{transformation is}} required to sense variations in texture contrast. Various theoretical and practical considerations have inclined researchers to suppose that this rectification is full-wave, rather than half-wave. In the studies reported here, observers are asked to judge which of two texture patches has higher texture variance. Textures are composed of small squares, with each square being painted with one of nine different luminances. Different texture variances are achieved by manipulating the histograms of the texture patches to be compared. When the nine <b>luminances</b> <b>range</b> linearly from 0 to 160 cd/m 2, the transformation mediating judgments of texture variance {{takes the form of}} a negative half-wave rectifier: texture variance judgments are determined exclusively by the frequencies of luminances below mean luminance in the textures being compared. However, when the nine <b>luminances</b> <b>range</b> linearly from 60 to 100 cd/m 2, two of three observers use a full-wave rectifying transformation in making texture variance judgments; the third observer continued to use a negative half-wave rectifier. The unexpectedly asymmetric roles played by low versus high luminances in texture variance judgments suggest that the off-center system may play a dominant role in human perception of texture contrast...|$|R
40|$|A {{phosphorescent}} multiple emissive layer, {{in which}} a blue emissive layer is sandwiched between red and green ones, is employed in a white organic light-emitting device (OLED). This OLED has a maximum luminance of 48 000 cd/m 2 at 17 V, a maximum power efficiency of 9. 9 lm/W at 4 V, and a color rendering index of 82. In addition, the emission color of this device is fairly stable at high luminances: its Commission Internationale de l'Eclairage coordinate slightly changes from (0. 431, 0. 436) to (0. 400, 0. 430) when the <b>luminance</b> <b>ranges</b> from 2000 to 40 000 cd/m 2. © 2006 American Institute of Physics. Link_to_subscribed_fulltex...|$|R
50|$|The {{human eye}} can detect a <b>luminance</b> <b>range</b> of 1014, or one hundred {{trillion}} (100,000,000,000,000) (about 46.5 f-stops), from 10−6 cd/m2, or one millionth (0.000001) of a candela per square meter to 108 cd/m2 or one hundred million (100,000,000) candelas per square meter. This range {{does not include}} looking at the midday sun (109 cd/m2) or lightning discharge.|$|E
50|$|The <b>luminance</b> <b>range</b> {{of a scene}} maps to the focal-plane {{illuminance}} {{and exposure}} in a camera, not necessarily directly proportionally, as when a graduated neutral density filter is used to reduce the exposure range to less than the scene <b>luminance</b> <b>range.</b> The film responds nonlinearly to the exposure, as characterized by the film's characteristic curve, or Hurter-Driffield curve; this plot of optical density of the developed negative versus the logarithm of the exposure (also called a D-logE curve) has central straight section whose slope is called the gamma of the film. The gamma can be controlled by choosing different films, or by varying the development time or temperature. Similarly, the light transmitted by the negative exposed a photographic paper and interacts with the characteristic curve of the paper to give an overall tone reproduction curve. The exposure of the paper is sometimes modified in the darkroom by dodging and/or burning-in, further complicating the overall tone reproduction, usually helping to map a wider dynamic range from a negative onto a narrower print reflectance range.|$|E
50|$|An {{important}} limitation for HDR {{photography is}} that any movement between successive images will impede or prevent success in combining them afterwards. Also, as one must create several images (often three or five and sometimes more) to obtain the desired <b>luminance</b> <b>range,</b> such a full 'set' of images takes extra time. HDR photographers have developed calculation methods and techniques to partially overcome these problems, {{but the use of}} a sturdy tripod is, at least, advised.|$|E
50|$|Dynamic range: {{film and}} video systems have widely varying limits to the <b>luminance</b> dynamic <b>ranges</b> that they can capture. Modern video cameras are {{much closer to the}} dynamic range of film, and their use is better {{understood}} by directors.|$|R
40|$|The {{proposed}} colour image watermarking algorithm exploits {{the human}} visual system to optimise the trade off between the visibility and the robustness of the watermark. A less sensitive colour channel is selected to be watermarked and central watermarking {{is used to}} give the algorithm an extra robustness to image cropping. The DWT and DCT transforms are combined to pack the most energy into a few coefficients. The logarithmic sensitivity of the Human eye to luminance is exploited by assigning pixels into groups with different <b>luminance</b> <b>ranges</b> and watermarking them with different insertion powers. Test {{results show that the}} proposed algorithm has very good performance and is robust to several common image manipulations...|$|R
40|$|Purpose: Aging {{can affect}} {{many aspects of}} visual performance. In general, the effects become more {{significant}} in those older than 40 to 50 years, with increased intersubject variability and stronger dependence on ambient illumination. This study aimed to establish how healthy aging of the retina affects the detection of 15 -Hz flicker under photopic and mesopic lighting. Methods: We investigated 71 participants aged 20 to 75 years. Thresholds were measured for detection of 15 -Hz flicker at the fovea (0 °) and at an eccentricity of 4 ° {{in each of the}} four quadrants. The background <b>luminance</b> <b>ranged</b> from 0. 6 to 60 cd/m 2 and pupil size was measured continuously. Participants were excluded if they had signs/history of ocular disease, substantial interocular differences in flicker thresholds, or were unable to detect 100...|$|R
50|$|The NHK {{measured}} {{contrast sensitivity}} for the Rec. 2020 color space using Barten's equation which {{had previously been}} {{used to determine the}} bit depth for digital cinema. 11-bits per sample for the Rec. 2020 color space is below the visual modulation threshold, the ability to discern a one value difference in luminance, for the entire <b>luminance</b> <b>range.</b> The NHK is planning for their UHDTV system, Super Hi-Vision, to use 12-bits per sample RGB.|$|E
5000|$|The bottom {{section of}} the test pattern {{contains}} a square of 100% intensity white and a rectangle of 7.5% intensity black, for use in setting the <b>luminance</b> <b>range.</b> More modern versions of the pattern feature a [...] "pluge pulse." [...] The white square lines up {{so that it is}} below the green and cyan bars, on a waveform monitor this will show up with the white bar overlapping the peak of the yellow and cyan chroma at 100 IRE units. The pluge (short for [...] "Picture Line-Up Generation Equipment") pulse is positioned within the black rectangle, below the red bar (it is present in the illustration but may be hard to see). It comprises three small vertical bars, a rightmost one with intensity 4% above black level, a middle one with intensity exactly equal to black, and a leftmost one with intensity 4% below black (super-black or [...] "blacker than black"). The pluge pulse aids in adjusting the bottom of the <b>luminance</b> <b>range</b> to avoid either washing out the black tones into grays or collapsing picture information into the signal clipping that occurs a small distance below the black level (known as [...] "crushing the blacks"). When a monitor is properly adjusted, the rightmost pluge bar should be just barely visible, while the left two should appear indistinuishable from each other and completely black. Also in the bottom section are two sections that contain -In-phase and +Quadrature signals (see YIQ), centered on black level and having the same gain as the color burst signal; these show up on the pattern as a square of very dark blue, and a square of very dark purple. On a vectorscope, they appear as two short lines ninety degrees apart. These are used to ensure that the television receiver is properly demodulating the 3.58 MHz color subcarrier portion of the signal. The vectors for the -I and +Q blocks should fall exactly on the I and Q axes on the vectorscope if the chrominance signal is demodulated properly.These bars give rise to the former portion of the casual term, [...] "bars and tone". Typically, a television network, TV station, or other originator of video programming transmits SMPTE color bars together with a continuous 1000 Hz audio tone before sending program material, in order to assert ownership of the transmission line or medium, and so that receiving stations and intermediary telecommunications providers may adjust their equipment. Likewise, producers of television programs typically record [...] "bars and tone" [...] {{at the beginning of a}} videotape or other recording medium so that the playback equipment can be calibrated. Often, the name or callsign of the TV station, other information such as a real-time clock, or another signal source is graphically superimposed over the bars.|$|E
50|$|Eyesight is a {{particular}} characteristic of the owl that aids in nocturnal prey capture. Owls {{are part of a}} small group of birds that live nocturnally, but do not use echolocation to guide them in flight in low-light situations. Owls are known for their disproportionally large eyes in comparison to their skulls. An apparent consequence of the evolution of an absolutely large eye in a relatively small skull is that the eye of the owl has become tubular in shape. This shape is found in other so-called nocturnal eyes, such as the eyes of strepsirrhine primates and bathypelagic fishes. Since the eyes are fixed into these sclerotic tubes, they are unable to move the eyes in any direction. Instead of moving their eyes, owls swivel their heads to view their surroundings. Owls' heads are capable of swiveling through an angle of roughly 270°, easily enabling them to see behind them without relocating the torso. This ability keeps bodily movement at a minimum, thus reduces the amount of sound the owl makes as it waits for its prey. Owls are regarded as having the most frontally placed eyes among all avian groups, which gives them some of the largest binocular fields of vision. However, owls are farsighted and cannot focus on objects within a few centimeters of their eyes. While owls are commonly believed to have great nocturnal vision due to their large (thus very light-gathering) eyes and pupils and/or extremely sensitive rod receptors, the true cause for their ability to see in the night is due to neural mechanisms which mediate the extraction of spatial information gathered from the retinal image throughout the nocturnal <b>luminance</b> <b>range.</b> These mechanisms are only able to function due to the large-sized retinal image. Thus, the primary nocturnal function in the vision of the owl is due to its large posterior nodal distance; retinal image brightness is only maximized to the owl within secondary neural functions. These attributes of the owl cause its nocturnal eyesight to be far superior to that of its average prey..|$|E
40|$|The {{constancy}} of a 16 -step achromatic Munsell {{scale was}} tested {{with regards to}} background variations in two experiments. In experiment 1 three groups of observers were asked to find lightness matches for targets in simultaneous lightness displays by using a 16 -step achromatic Munsell scale placed on a white, black, or white-black checkered background. In experiment 2, a yellow-blue checkered background and a green-red checkered background replaced Munsell scales on the black and on the white backgrounds. Significant effects of scale background on matches were found only in experiment 1, suggesting that background luminance is a crucial factor in the overall appearance of the scale. The lack of significant differences in experiment 2, however, may stand for an overall robustness of the scale with respect to background luminance changes occurring within certain <b>luminance</b> <b>ranges...</b>|$|R
40|$|AbstractThe {{luminance}} {{dependence of}} spatial acuity in domestic fowl was measured directly over stimulus <b>luminances</b> <b>ranging</b> from 0. 06 to 57. 35 cdm− 2. At the highest luminance, acuity was around 6. 5 cdeg− 1, {{in agreement with}} previous studies in this species. As stimulus luminance decreased, acuity fell with increasing rate to 3. 2 cdeg− 1 at 0. 06 cdm− 2, following the same shape as acuity functions for other mammalian and avian species. These {{findings suggest that the}} rod–cone transition for domestic fowl is between 0. 45 and 1. 79 cdm− 2. Over the photopic range from 1. 79 to 57. 35 cdm− 2 the change of acuity for fowl was 1 %, compared with 32 % for humans. For domestic fowl, the Rovamo–Barten MTF model of contrast sensitivity accounted for the behaviour of acuity as a function of luminance down to mesopic levels...|$|R
40|$|The {{inability}} of the human visual system to adapt quickly to a wide <b>range</b> of environmental <b>luminances</b> poses a stiff challenge {{to the design of}} airborne displays. Using a repeated measures factorial design, the present study investigated the independent and interactive effects of adaptation luminance, contrast ratio, and display background luminance on this "eye adaptation mismatch " phenomenon. Adaptation <b>luminances</b> <b>ranged</b> from 1 fL to 10, 000 fL, with legibility defined as the time required by observers to recognize CRT symbols. Overall, response time increased systematically with increases in adaptation luminance, and decreased with increases in contrast ratio and display background luminance. Additional analyses revealed that contrast ratio and display luminance influence response time multiplicatively, such that quests to maintain large contrast ratios under bright ambient light at the expense of lowered display luminance could exaggerate the mismatch between adaptation luminance and display luminance and thus degrade symbol legibility...|$|R
50|$|The design {{motif of}} the Uniroyal Tire Factory {{would have done}} credit to a Cecil B. deMille Hollywood epic. With {{almost a third of}} a mile façade {{alongside}} a busy highway, crenellated and turreted like King Sargon’s palace, it mirrored the flapper era national infatuation with exotic foreign and architectural motifs. Serving only as a decorative but secure wall shielding the huge tire factory, it projected the strength and endurance that its owners hoped existed in their products. Surviving until 1978, when its nearly half century of tire production ended, it stood abandoned until redevelopment began on the site in 1989. Living in a nearby city at the time, no doubt regularly going by the factory, McSavaney became intrigued and decided to ‘check it out’. He was among the many fine art photographers of the time who viewed remnants from earlier ages, such as the Tire Factory, the Ancient Puebloan ruins, and Los Angeles bridges, as ‘Forgotten Places’. They had an ongoing quest to photograph them before they disappeared forever.Replete with dark corners, vast inaccessible coal-black interior spaces with barely visible detail, shafts of hazy light beaming through roof and wall breaks, the tire factory presented extremely difficult technical obstacles to making a satisfactory photograph. In terms of Adams’ Zone system, its luminance levels ranged ‘from DC to light’, that is, from Adams Zone I to Zone XVI or higher. Such a wide <b>luminance</b> <b>range</b> generally exceeded the film's recording abilities and extended far beyond that of extant print paper.Consequently, in order to make an expressive print, McSavaney faced the need to ‘open’ shadows and ‘compress’ highs into ranges that the film could handle, and enable him to make an expressive print. After extensive experimentation, by further diluting the most dilute of Adams’ compensating developers, he found that he could produce a satisfactory negative. Applying the photographer’s rule of thumb, ‘expose for the shadows, develop for the highlights’, he successfully handled those very difficult subjects. As shown by the accompanying photograph, his techniques worked effectively. Over a two-year period, he exposed more than 800 negatives in the factory. Parenthetically, an estimate of his lifetime production exceeds 50,000 negatives. Of those, about 30,000 remain in his archives. Clearly he didn’t believe that all his exposures were masterpieces. In that respect, he agreed with an assertion by his colleague John Sexton, that the single most important darkroom tool was his trash can.|$|E
30|$|Extreme <b>luminance</b> <b>range</b> in {{the visual}} field.|$|E
40|$|The dynamic <b>luminance</b> <b>range</b> of many {{real-world}} environments {{exceeds the}} capabilities of current display technology by several orders of magnitude. Recently, new display systems have demonstrated, which are capable of displaying images with a dynamic <b>luminance</b> <b>range</b> much more similar to that encountered in the real world...|$|E
40|$|International audienceTraditional {{capture and}} display devices can only support a limited dynamic range (contrast) and color gamut given the {{hardware}} limitations. As a result, the real physical luminance {{present in a}} natural scene cannot be captured by these. However, with the recent advancements in the related software and hardware technologies, {{it is now possible}} to capture or reproduce higher contrast and <b>luminance</b> <b>ranges.</b> Such scene-referred visual signals are known as High Dynamic Range (HDR) signals. They are visually more appealing because they can represent the dynamic range of the visual stimuli present in the real world. Not surprisingly, the emergence of HDR is seen as an important step towards improving the visual quality of experience (QoE) of the end users. However, HDR comes with its own set of challenges including storage, processing, display and so on. This chapter focuses on some of the issues related to HDR processing from a quality of experience (QoE) viewpoint...|$|R
40|$|Abstract. This paper {{presents}} a low <b>luminance</b> dynamic <b>range</b> converter that includes light recording and adjustment system for vehicle application under light insufficient environment. The development of vehicle electronic technology has improved traditional vehicle function. How {{to design a}} safety function system for vehicle {{become more and more}} important in vehicle industries. This work designs low <b>luminance</b> dynamic <b>range</b> converter circuit for vehicle application and provides a safety-driving environment. In the proposed method, we adopt video capture system to record light information from driving environment. An adaptive adjustment is adopted to re-arrange the histogram according to the distribution of luminance. Then, we use a series of test images and extract the characteristic value to train the system to reflect practical circumstances. Next, color calibrations and de-noise processing are performed to improve the visual quality. The presented approach considers the realistic driving situation and provides a bright and safe visual environment for driver under light insufficient environment...|$|R
40|$|The {{luminance}} {{dependence of}} spatial acuity in domestic fowl was measured directly over stimulus <b>luminances</b> <b>ranging</b> from 0. 06 to 57. 35 cd m? 2. At the highest luminance, acuity was around 6. 5 c deg? 1, {{in agreement with}} previous studies in this species. As stimulus luminance decreased, acuity fell with increasing rate to 3. 2 c deg? 1 at 0. 06 cd m? 2, following the same shape as acuity functions for other mammalian and avian species. These {{findings suggest that the}} rod–cone transition for domestic fowl is between 0. 45 and 1. 79 cd m? 2. Over the photopic range from 1. 79 to 57. 35 cd m? 2 the change of acuity for fowl was 1 %, compared with 32 % for humans. For domestic fowl, the Rovamo–Barten MTF model of contrast sensitivity accounted for the behaviour of acuity as a function of luminance down to mesopic levels...|$|R
3000|$|... [...]. LIP {{arithmetic}} has {{the important}} advantage of respecting the bounded <b>luminance</b> <b>range,</b> for example, [[...]...|$|E
40|$|The dynamic <b>luminance</b> <b>range</b> of many {{real-world}} environments {{exceeds the}} capabilities of current display technology by several orders of magnitude. Recently, new display systems have demonstrated, which are capable of displaying images with a dynamic <b>luminance</b> <b>range</b> much more similar to that encountered in the real world. The paper summarizes how the human eye perceives high dynamic luminance ranges, sources of high dynamic range data, how the new display systems work, {{as well as their}} limitations. The paper discusses the need for a high dynamic range window manager and presents an initial implementation. Finally, the results of a preliminary evaluation are presented. ...|$|E
3000|$|... 2 {{depending}} on whether the images are in the range [0, 1] or [0, 255]. For HDR content, our findings suggest that the value of these constants should be adjusted according the <b>luminance</b> <b>range</b> and {{depending on}} whether scaling of the values is performed or not.|$|E
5000|$|Very {{early in}} his career, McSavaney {{determined}} to master the 'craft of photography' in order to adequately express his vision of what his mental photograph should represent. Applying and sometimes extending Ansel's teachings in making an [...] "expressive print", Ray honed and matured his artistic seeing and technical skills in two especially striking Los Angeles locations. One was the abandoned Uniroyal Tire Factory alongside a then busy highway, now a much busier Los Angeles freeway; [...] the other a major construction project in the city center, known as Bunker Hill, Los Angeles Redevelopment.In working on those unusually contrasty scenes, McSavaney soon discovered that his photographic skills were grossly inadequate. He was challenged by the technical pitfalls presented by scenes with extreme <b>luminance</b> <b>ranges.</b> Adams had discussed in detail just such pitfalls in his book on the Camera. With all that in mind in preparation for those difficult projects, McSavaney thoroughly experimented with several of Adams’ techniques for developing film exposed under extreme tonal ranges and lighting conditions.|$|R
40|$|During night-time driving {{hazardous}} objects {{often appear}} at mesopic light levels, which are typically measured using light meters with a spectral sensitivity {{that is only}} valid for photopic light levels. In order to develop suitable mesopic models a target detection experiment was performed in a driving simulator. While subjects drove along a winding road they had to respond to randomly presented circular targets at various eccentricities. The background <b>luminance</b> <b>ranged</b> between 0. 01 and 10 cd/m², and was either white, yellow, red or blue. The RT, number of missed targets, and driving behaviour were measured. The results show that target detection and driving performance get poorer with decreasing background luminance and increasing eccentricity of the target, in particular for the red colour. At high driving speeds and low luminances subjects tend to neglect left off-axis targets. Luminance calculated with existing reaction-time-based mesopic models fits better to RT data than the widely-used photopic luminance. © 2006 The College of Optometrists Keywords: driving behaviour, driving simulator, mesopic vision, RT, traffi...|$|R
40|$|This paper {{proposes a}} prototypical {{environment}} for gamut mapping in spectral space. Images are rendered {{in terms of}} light and material parameters by a symbolic ray tracer, and the parameter ranges are adjusted, without re-rendering, to bring the image into the output device’s spectral gamut. There is a growing disparity between the high dynamic range images produced by spectral renderers and the limitations of display gamuts and lowdimensional colour management standards. While in rendering tone mapping has helped compress <b>luminance</b> <b>ranges,</b> and in colour science 3 D gamut mapping has helped compress chrominance ranges, only high-dimensional spectral methods will fully bridge the gap. This paper’s environment for gamuts in spectral space is a step toward spectral gamut mapping, which we demonstrate by using the ray tracer to predict feasible ranges of rendering parameters for an in-gamut image. The environment can be easily extended to support interactive or automatic image correction, and more sophisticated rendering and gamut-mapping methods of arbitrary dimensionality. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 7 [Computer Graphics]: Color, shading, shadowing and textur...|$|R
3000|$|... lie now in {{a limited}} range bounded above by a {{bell-shaped}} function of the average; the function takes its maximum value when the average is half the available range and falls to zero when the average corresponds to the minimum or the maximum of the <b>luminance</b> <b>range</b> [25].|$|E
40|$|CIE Division 8 {{concerns}} {{itself with}} suggesting methods for interpreting complex color stimuli, or more specifically images. To accurately model color appearance of images {{we can no}} longer consider pixels as simple patches viewed in isolation. TC 8 - 08 is tasked with examining spatial color appearance models, with an emphasis on high-dynamic range images. High-dynamic range (HDR) images are typically images that contain a large range of luminance information, and are represented by more than 8 -bits per channel. The <b>luminance</b> <b>range</b> of the “real ” world is typically much greater than the <b>luminance</b> <b>range</b> of any color reproduction device. Imaging technology has advanced so as to capture, or synthetically generate, this large <b>luminance</b> <b>range.</b> The question of how to reproduce the images on a lower dynamic range device has not been solved. TC 8 - 08 is examining the use of spatial appearance models to aid in this task. This paper discusses some of the many problems and pitfalls that TC 8 - 08 are looking into with regards to testing spatial appearance models. Among these concerns are: algorithm choices and implementations, psychophysical experimental design, HDR image availability, preference verses accuracy, and the use of next-generation HDR displays as validation. Keywords: High Dynamic Range, Tone-Mapping, HDR, CIE, Spatial Appearance Models, TC 8 - 08 1...|$|E
40|$|AbstractPhotometric {{constraints}} for {{the perception}} of transparency were investigated using stereoscopic textured displays. A contrast discontinuity divided the textured displays into two lateral halves, with one (reference) half fixed. Observers adjusted the <b>luminance</b> <b>range</b> within the other (test) half in order to perform two tasks: (i) indicate the highest <b>luminance</b> <b>range</b> for which the test side {{is perceived to be}} transparent, and (ii) indicate the lowest <b>luminance</b> <b>range</b> for which the test side is seen as being in plain view. Settings were obtained for multiple values of test mean luminance, in order to map out the perceptual locus of transition between transparency and non-transparency. The results revealed a systematic violation of Metelli’s magnitude constraint in predicting the percept of transparency. Observer settings were approximated instead by a constraint based on perceived contrast (which matched Michelson contrast for the textures used). The results also revealed large asymmetries between darkening and lightening transparency. When the test was darker than the reference, settings were highly consistent across observers and closely followed the Michelson-contrast prediction. When the test was lighter, however, there was greater variability across observers, with two observers exhibiting shifts toward Metelli’s magnitude constraint. Moreover, each observer’s setting reliability was significantly worse for lightening transparency than darkening transparency. These results suggest that (polarity-preserving) darkening serves as an additional cue to perceptual transparency...|$|E
40|$|Various {{applications}} in building lighting such as automated daylight systems, dynamic lighting control systems, lighting simulations, and glare analyzes can be optimized using {{information on the}} actual luminance distributionsof the surroundings. Currently, commercially available luminance distribution measurement devices are often not suitable for these kind of applications or simply too expensive for broad application. This paper describes {{the development of a}} practical and autonomous luminance distribution measurement device based on a credit card-sized single-board computer and a camera system. The luminance distribution was determined by capturing High Dynamic Range images and translating the RGB information to the CIE XYZ color space. The High Dynamic Range technology was essential to accurately capture the data needed to calculate the luminance distribution because it allows to capture <b>luminance</b> <b>ranges</b> occurring in real scenarios. The measurement results were represented in accordance with established methods in the field of daylighting. Measurements showed that the accuracy of the luminance distribution measurement device ranged from 5 % to 20 % (worst case) which was deemed acceptable for practical measurements and broad {{applications in}} the building realm...|$|R
40|$|The {{increasingly}} widespread {{availability of}} {{high dynamic range}} (HDR) technology has led to active study {{of the characteristics of}} the human visual system (HVS) in terms of brightness, lightness, contrast, and color perception and the application of the results of these studies to computer graphics. Because the development of HDR technology gives us display devices with much broader dynamic range for both high and low luminances, it is especially important to revise the models of HVS for the <b>luminance</b> <b>ranges</b> which are not covered by classical psychophysics, but required by the new HDR technology. In this dissertation, we focus on the evaluation and enhancement of the appearance of HDR images as reproduced on low dynamic range (LDR) media. First, we conducted a psychophysical experiment on seven tone mapping operators (TMOs) to assess how tone mapped images are perceived differently by human observers and to find out which attributes of image appearance account for these differences. The results show qualitative differences in TMOs, however, it also turned out tha...|$|R
40|$|AbstractThis paper investigates {{intensity}} coding {{in human}} vision. Specifically, we address the following question: how do different luminances influence the perceived total luminance of a composite image? We {{investigate this question}} using a paradigm in which the observer attempts to judge, with feedback, which of two texture patches has higher total luminance. All patches are composed of nine <b>luminances,</b> <b>ranging</b> linearly from 0 (black) to a maximum luminance (white: 160 cd/m 2 in one condition; 20. 2 cd/m 2 in another condition). Luminance histograms of the patches being compared are experimentally varied to derive, for each luminance ν, the impact exerted by texture elements (texels) of luminance ν on texture luminance judgments. We find that impact is approximately proportional to texel luminance; That is, a texture element exerts, on average, an impact on texture brightness (i. e. perceived texture luminance) that is proportional to its (the texel’s) luminance. The only exception occurs for texels of maximal luminance, which surprisingly exert an impact that is slightly, but significantly, less than that exerted by texels of the next lower luminance. We conclude that visual intensity coding for purposes of assessing overall luminance of inhomogeneous patches is approximately veridical. In particular, texture luminance judgments are not mediated by a significant, compressive nonlinearity...|$|R
