23|160|Public
40|$|A {{low-level}} <b>logic</b> <b>fault</b> test simulation environment targeted towards application-specific {{integrated circuits}} (ASICs) {{in particular is}} proposed in this paper. The simulation environment emulates a typical built-in self-testing (BIST) environment with test pattern generator (TPG) that sends its outputs to a circuit (core) under test (CUT) and the output streams from the CUT are fed into an output response analyzer (ORA). The developed simulator is very suitable for testing embedded digital intellectual property (IP) cores-based systems. The paper describes the total test architecture environment, including {{the application of the}} <b>logic</b> <b>fault</b> simulator. Results on simulation on some specific International Symposium on Circuits and Systems (ISCAS) 85 combinational and ISCAS 89 sequential benchmark circuits are provided as well for appraisal...|$|E
40|$|This paper {{describes}} {{the application of}} fuzzy logic in diagnosing the power quality problems in a three-phase induction motor. A fuzzy <b>logic</b> <b>fault</b> detector (FLFD) was simulated to identify normal and abnormal operating conditions of the induction motor and to classify the operation based on current measurements at different time intervals. The FLFD is simulated using fuzzy logic toolbox in MATLAB. The performance of fuzzy <b>logic</b> <b>fault</b> detector has been analyzed through simulation studies with different inference techniques such as Mamdani type inference, Sugeno type inference and Adaptive Neuro –Fuzzy inference system. It {{was found that the}} Sugeno type of inference yielded results, which approximated the desired values. This analysis paves the way towards an ultimate objective of developing an intelligent power quality diagnosis tool capable of predicting the abnormal operation of any power system...|$|E
40|$|ESIM is a {{simulation}} tool that integrates <b>logic</b> <b>fault</b> and design error simulation for logic circuits. It targets several design error and fault models, {{and uses a}} novel mix of simulation algorithms based on parallel-pattern evaluation, multiple error activation, single fault propagation, and critical path tracing. Several experiments are discussed to demonstrate the power of ESIM. 1...|$|E
40|$|Causes and {{symptoms}} of <b>logic</b> <b>faults</b> in digital systems. Reliable performance of hardware has been a require-ment for digital systems since {{the construction of the}} first digital computer. Improper functioning of the logic circuits in a digital system is manifested by <b>logic</b> <b>faults,</b> which are defined for this paper as "permanent or transient deviations of logic variables from the values specified in design. " Permanent faults are caused by physical changes in the components of a logic circuit which permanently alter the logic function specified by the designer. The most common permanent faults are the determinate faults of "stuck on zero " and "stuck on one " types. Less frequent is the indeterminate or "stuck on X " fault...|$|R
40|$|Delay faults are an {{increasingly}} important test challenge. Modeling bridge faults as delay faults helps delay tests to detect more bridge faults. Traditional bridge fault models are incomplete because these models only model the <b>logic</b> <b>faults</b> or these models are not efficient to use in delay tests for large circuits. In this {{paper we propose a}} physically realistic yet economical resistive bridge fault model to model delay faults as well as <b>logic</b> <b>faults.</b> An accurate yet simple delay calculation method is proposed. We also enumerate all possible fault behaviors and present the relationship between input patterns and output behaviors, which is useful in ATPG. Our fault simulation results show the benefit of at-speed tests...|$|R
30|$|The <b>logic</b> {{identifying}} <b>fault</b> {{is described}} as below: if the <b>logic</b> values of <b>fault</b> direction detected {{on both sides of}} HVDC line are equal to 1, an internal fault will be determined; if the <b>logic</b> value of <b>fault</b> direction on one side is 1, while that on the other side is − 1, an external fault will be discriminated; otherwise, it is normal.|$|R
40|$|We study recent {{developments}} in quantum computing (QC) testing and fault tolerance (FT) techniques and discuss several attempts to formalize quantum <b>logic</b> <b>fault</b> models. We illustrate the inherent need for fault tolerance in QC due to the decoherence problem. Further, we examine several ideas regarding random testing and examine the viability of built-insystem-test (BIST) in future QC circuits. 1...|$|E
40|$|A fault {{detection}} {{and analysis of}} stuck-at faults in multiple fault situation is developed in a combinational circuit with basic Boolean logic gates. Especially Boolean logic gate is proposed for the computation of multiple faults in parallel bus lines. During programming FPGA devices there is a probability of lines getting fused to either stuck at zero or stuck at one faults. Where conventional diagnosing tools analyze stuck zero and stuck one faults only multiple fault cases are not considered. Using eminent <b>logic</b> <b>fault</b> tolerant design problem is solved out in this paper...|$|E
40|$|Abstract – Fault {{in terms}} of Software Engineering is {{referred}} to as a bug, an error or a problem which causes a program to crash or generate invalid results. The problem is caused by either incorrect logic or insufficient <b>logic.</b> <b>Fault</b> localization technique plays a very important role in order to determine such errors and to attain the correct outputs. The objective of this work is to assess different fault localization techniques which are in existence. Thus, this can be favorable to the software tester for fault recognition in the program...|$|E
40|$|Aggressive process scaling and {{increasing}} clock rates have made crosstalk noise {{an important issue}} in VLSI design. Switching on long, adjacent bus wires can lead to timing and <b>logic</b> <b>faults.</b> At the same time system-level interconnects have also become more susceptible to other less predictable forms of interference such as noise induced by power grid fluctuations, electromagnetic interference, and alpha-particle radiation. Previous work has treated these systematic and non-systematic forms of noise separately...|$|R
40|$|This paper {{introduces}} {{a new concept}} called consecutive testability and proposes a design-for-testability method that makes a given SoC consecutively testable using integer lin-ear programming (ILP). A consecutively testable SoC can achieve consecutive application of arbitrary test sequence {{at the speed of}} system clock. The advantage is that it is pos-sible to test not only <b>logic</b> <b>faults</b> but also timing faults that require consecutive application of test patterns at the speed of the system clock. [URL]...|$|R
40|$|International audienceWith {{shrinking}} process technologies, {{the likelihood}} of mid-life <b>logic</b> <b>faults</b> is increasing. In this paper, we present an approach for mitigating the effects of <b>faults</b> in combinatorial <b>logic</b> through the selective addition of redundant logic. This approach {{can be applied to}} a generic digital circuit, protects against multiple fault models and offers a trade-off between area and fault coverage. The results show that fault coverage can be improved by 4 x with an area penalty of 50 % and only two additional layers of logic...|$|R
40|$|Abstract. Redundancy {{technique}} {{is an effective}} method to improve the ability of mission reliability, safety reliability and fault tolerant. With redundancy technique, it will increase additional system software and hardware resources, such as fault monitor module and channel switch module etc. In allusion to sensor fault, serial fault, controller fault and motor fault, this paper designs and researches the strategy of fault <b>logic,</b> <b>fault</b> management and fault reconstruction, appropriately distributes the system resources, thus effectively processes fault monitoring and isolating, and sufficiently improves mission reliability, safety reliability and fault tolerant ability of the dual-redundancy brushless direct current electric rudder loop...|$|E
40|$|This paper {{extends the}} CMOS {{standard}} cells characterization methodology for defect based testing. The proposed methodology allows {{to find the}} types of faults which may occur in a real IC, to determine their probabilities, and to find the input test vectors which detect these faults. For shorts at the inputs two types of cell simulation conditions – “Wired-AND ” and “Wired-OR ” – are used. Examples of industrial standard cells characterization indicate that a single <b>logic</b> <b>fault</b> probability table is not sufficient. Separate tables for “Wired-AND ” and “Wired-OR ” conditions at the inputs are needed for full characterization and hierarchical test generation. 1...|$|E
40|$|The {{integrity}} of gate oxide shorts (GOS) {{model is a}} key factor as quality and reliability indicator of CMOS. Gate oxide defects in MOS transistors {{can be considered as}} the layout and technology dependent failures for which <b>logic</b> <b>fault</b> models are not always available, requiring electrical models to simulate the defect characteristics. Previously the GOS have been modeled with split transistors technique using two minor transistors and lumped elements. However, it is problematic to study minimum size transistors affected by GOS failures using the existing unidirectional split model as the channel length is designed at minimum size in particular technology process. This paper presents a study to compare and correlate between split model and non-split model of GOS...|$|E
40|$|A key design {{constraint}} of circuits used in hand-held devices {{is the power}} consumption, mainly due to battery life limitations. Adaptive power management (APM) techniques aim to increase the battery life by adjusting the supply voltage (Vdd) and operating frequency, according to the workload. APM-enabled devices raise a number of challenges for existing manufacturing test and diagnosis techniques, as certain defects exhibit Vdd dependent detectability. This means that to achieve 100 % fault coverage, APM-enabled devices should be tested at all operating voltages using repetitive tests. Repetitive tests at several Vdd settings are undesirable as it increases the cost of manufacturing test. This thesis provides two new and cost-effective Design for Test (DFT) techniques to avoid repetitive tests thereby reducing test cost. The first technique uses test point insertion (TPI) {{to reduce the number}} of test Vdd settings. TPI capitalizes on the observation that each resistive bridge defect consists of a large number of <b>logic</b> <b>faults,</b> including detectable and non-detectable <b>logic</b> <b>faults.</b> It targets resistive bridges requiring test at higher Vdd settings, and converts un-detectable <b>logic</b> <b>faults</b> at the lowest Vdd setting, into detectable <b>logic</b> <b>faults</b> by using test points. Test points provide additional controllability and observability at the fault site. TPI has shown encouraging results in terms of reducing the number of test Vdd settings, however it does not achieve single Vdd test for all designs. Taking this issue into account, another gate sizing (GS) based DFT technique is proposed. It targets bridges that require multi-Vdd test and increases the drive strength of gates driving such bridges. The number of test Vdd settings are reduced minimizing test cost. Experimental results show that for all designs, the proposed GS technique achieves 100 % fault coverage at a single Vdd setting; in addition it has a lower overhead than the TPI in terms of timing, area and power. The Vdd dependent detectability of resistive bridges demands re-evaluation of existing diagnosis techniques, as all existing techniques use a single voltage setting for fault diagnosis, which may have a negative impact on diagnosis accuracy, affecting subsequent design cycle and yield. This thesis proposes a novel and cost-effective technique to improve diagnosis accuracy of resistive bridges in APM-enabled designs. It evaluates the impact of varying supply voltage on the accuracy of diagnosis and demonstrates how additional voltage settings can be leveraged to improve the diagnosis accuracy through a novel multi-voltage diagnosis algorithm. The diagnosis cost is reduced by identifying the most useful voltage settings and by eliminating tests at other voltages thereby achieving high diagnosis accuracy at reduced cost. All developed test and diagnosis techniques have been validated using simulations with ISCAS and ITC benchmarks, realistic fault models and actual bridges extracted from physical layouts. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
5|$|There were {{problems}} with batteries on some models from 2007 not being {{read by the}} MacBook. This {{is caused by a}} <b>logic</b> board <b>fault</b> and not a fault with the battery.|$|R
40|$|VI. CONCLUSION This paper {{investigated}} {{the impact of}} process variation on test quality of bridging faults. It {{has been shown that}} process variation influences two parameters (logic VT and gate drive strength) which affects the logic behavior of bridging faults leading to test escape. To quantify the impact of process variation on test quality, a metric called test robustness has been presented. The metric guides a novel PVAA method, which target the <b>logic</b> <b>faults</b> that have the largest impact on test quality. Experimental results show that for all consid-ered benchmarks, the proposed method achieves better results (less test escapes) than tests generated without consideration of process variation...|$|R
40|$|This paper {{presents}} a fault model for VHDL descriptions at the Register Transfer Level and its evaluation {{with respect to}} a logic level fault model (single-stuck-at). The proposed fault model may be used for early estimations of the fault coverage before the synthesis is made in the design process of an integrated circuit. The obtained results show a high correlation between the fault coverages achieved with the proposed fault model and <b>logic</b> <b>fault</b> models on a set of examples. The main contribution of this work is the proposal of a new fault model for VHDL/RT descriptions and the demonstration of its usefulness for estimating the achieved fault coverage with a set of test vectors in design phases previous to synthesis...|$|E
40|$|This paper {{presents}} an alternative {{modeling and simulation}} method for CMOS bridging faults. The significance of the method is {{the introduction of a}} set of generic-bridge tables which characterize the bridged outputs for each bridge and a set of generic-cell tables which characterize how each cell propagates a logically undefined input. These two sets of tables are derived dynamically for a specific design by using a SPICE circuit simulator. Then they can be used by any <b>logic</b> <b>fault</b> simulator to simulate bridging faults. In this way, the proposed method can perform very fast bridging fault simulation yet with SPICE accuracy. The paper shows how these two sets of tables are derived and used in a parallel pattern fault simulator. Experimental results on ISCAS 85 benchmarks are promisin...|$|E
40|$|Abstract- In this paper, {{we propose}} a novel Petri Net model for solving test {{generation}} and site of fault and fired logical value for combinational circuits. In {{order to improve}} the <b>logic</b> <b>fault</b> efficiency, the transitions of general Petri Nets (PNs) are modified according to the critical of truth table, called Logic Petri Net LPN. The LPN model can transfer complexity circuit problem to a local adjacent place and transition relational problem. Therefore, the site of fault and fired logical value problem is simplified and clearly. The LPN model has the properties of Boolean algorithm, collapsing fault with clear physical concepts, fast calculation speed, and high veracity. The approach contains site of a fault and fired logical value reasoning algorithm and test vector generation reasoning algorithm. Two examples are shown to demonstrate the effectiveness of our approach. I...|$|E
40|$|ISBN: 0769506135 IC {{technologies}} are approaching the ultimate limits of silicon {{in terms of}} device size, power supply levels and speed. By approaching these limits, circuits are becoming increasingly sensitive to noise {{as well as to}} small manufacturing defects that may result in spurious faults. Such faults are difficult to (or can not) be detected by manufacturing testing and will result in unacceptable rates of errors in the field. Self-checking design can be used to cope with this problem, but usually it addresses <b>logic</b> <b>faults.</b> This paper analyzes the behavior of self-checking circuits under various spurious faults likely to occur in very deep submicron technologies...|$|R
40|$|This paper {{presents}} {{process plant}} risk reduction support system modeling which including hazard identification,frequencies analysis, consequence analysis and hazard cost. The <b>logic</b> <b>faults</b> events tree and correspondingstochastic model were derived. The expression for remediation cost was defined. Process safety models help to buildapplications for loss prevention. As {{a case study}} the phenol plant for the phenol extraction by butyl-acetate was used. It purpose is to discover and locate the disturbance or faults {{which could lead to}} accidental situations. The obtainedresults indicate the influence of a single disturbance to registered symptoms, {{as well as to the}} safety of the wholeplant. The paper illustrated management reduction support system for developing risk assessment interface andremediation cost analysis...|$|R
40|$|Abstract — Ternary content {{addressable}} memory (TCAM) is one {{key component}} in the dedicated hardware modulars for high-performance networking applications. Symmetric and asym-metric cells are two widely used cell structures in TCAMs. An asymmetric cell consists of a binary {{content addressable memory}} (BCAM) bit and a mask bit. This paper proposes two march-like test algorithms, and, to cover the comparison faults of the BCAM cell and the comparison <b>logic</b> <b>faults</b> of the masking cell. requires 7 Write operations and (3 + 2) Compare operations to cover the comparison faults of an -bit TCAM with Hit output only. requires 4 Write operations and (3 + 2) Compare operations to cover the comparison faults of an -bit TCAM with priority address encoder (PAE) output. I...|$|R
40|$|In {{order to}} solve the <b>logic</b> <b>fault</b> of Internet of things {{technology}} applied in the supply chain system, this paper presents processing framework {{which is based on}} the context of complex event processing technology. At first, paper analysis the hierarchy of processing framework oriented supply chain applications, and then put forward the situation model of event flow based on complex event, including the establishment of the model, the definition of the event as well as the event description language. The context-aware framework based on complex event processing technology can solve the problem that the underlying data cannot be used efficiently bythe upper, which is proved bya typical case existingin the supply chain. As a result, it can improve the reaction speed of the supply chain system, reduce supply chain inventory as well as bullwhip effect. </p...|$|E
40|$|International audienceElectro Optical Techniques (EOFM: Electro Optical Frequency Mapping and EOP: Electro Optical Probing) and Dynamic Light Emission Techniques (TRE: Time Resolved Emission and TRI: Time Resolved Imaging) are dynamic optical probing {{techniques}} {{widely used}} at IC level for design debug and defect localization purpose. They can pinpoint {{the origin of}} timing issue or <b>logic</b> <b>fault</b> in up to date CMOS devices. Each technique has its advantages and its drawbacks allowing {{a common set of}} applications and more specific ones. We {{have been involved in the}} development of the most advanced techniques related to EOFM and TRI on various devices (down to 28 nm technology). What we can expect with each technique, which one to choose, what are the limitations are questions that must be answered regarding tooling cost and skills involved. Based on the understanding of the bases of each technique, their complementarities and their limitations have been identified. Even if these techniques can solve most of the issues we encountered, we can wonder if they can be applied on future technologies and this aspect will also be discussed...|$|E
40|$|As silicon {{manufacturing}} process scales to {{and beyond the}} 65 -nm node, process variation {{can no longer be}} ignored. The impact of process variation on integrated circuit performance and power has received significant research input. Variation-aware test, on the other hand, is a relatively new research area that is currently receiving attention worldwide. Research has shown that test without considering process variation may lead to loss of test quality. Fault modelling and simulation serve as a backbone of manufacturing test. This thesis is concerned with developing efficient fault modelling techniques and simulation methodologies that take into account the effect of process variation on manufacturing defects with particular emphasis on resistive bridges and resistive opens. The first contribution of this thesis addresses the problem of long computation time required to generate <b>logic</b> <b>fault</b> of resistive bridges under process variation by developing a fast and accurate modelling technique to model <b>logic</b> <b>fault</b> behaviour of resistive bridges. The new technique is implemented by employing two efficient voltage calculation algorithms to calculate the logic threshold voltage of driven gates and critical resistance of a fault-site to enable the computation of bridge logic faults without using SPICE. Simulation results show that the technique is fast (on average 53 times faster) and accurate (worst case is 2. 64 % error) when compared with HSPICE. The second contribution analyses the complexity of delay fault simulation of resistive bridges to reduce the computation time of delay fault when considering process variation. An accelerated delay fault simulation methodology of resistive bridges is developed by employing a three-step strategy to speed up the calculation of transient gate output voltage which is needed to accurately compute delay faults. Simulation results show that the methodology is on average 17. 4 times faster, with 5. 2 % error in accuracy, when compared with HSPICE. The final contribution presents an accelerated simulation methodology of resistive opens {{to address the problem of}} long simulation time of delay fault when considering process variation. The methodology is implemented by using two efficient algorithms to accelerate the computation of transient gate output voltage and timing critical resistance of an open fault-site. Simulation results show that the methodology is on average up to 52 times faster than HSPICE, with 4. 2 % error in accuracy...|$|E
40|$|In {{very deep}} {{sub-micron}} (VDSM) fault-tolerant busses, crosstalk noise and <b>logic</b> <b>faults</b> caused due to shrinking wiresize and reduced inter-wire spacing are major factors affecting {{the performance of}} on- chip interconnects, such as high power consumption and increased delay. In this {{paper we propose a}} bus optimization technique which reduce the energy and power-delay using Hamming Single Error Correcting Code. In this coding scheme we implement Fibonacci representation of optimal (7, 4) Hamming Code which is more efficient than Single Error correction (9, 4) Hamming Code. Also the proposed scheme eliminates crosstalk classes among the interconnects wires, there by reducing delay and energy consumption. The proposed techniques achieves an efficiency of 11 % in energy consumption and a reduction of delay with respect to the existing techniques...|$|R
40|$|This paper {{analyses}} the behaviour of resistive bridging faults under process {{variation and}} shows that process variation has a detrimental impact on test {{quality in the}} form of test escapes. To quantify this impact, a novel metric called test robustness is proposed and to mitigate test escapes, a new process variation-aware test generation method is presented. The method exploits the observation that <b>logic</b> <b>faults</b> that have high probability of occurrence and correspond to significant amounts of undetected bridge resistance have a high impact on test robustness and therefore should be targeted by test generation. Using synthesised ISCAS benchmarks with realistic bridge locations, results show that for all the benchmarks, the method achieves better results (less test escapes) than tests generated without consideration of process variatio...|$|R
40|$|As {{the demand}} on Computer-Aided Testing Systems (CATS) —Automatic Test Pattern Generation (ATPG) and <b>logic</b> and <b>fault</b> {{simulations}} {{as well as}} testability analysis—increases and the choice becomes more varied, a need to compare {{the merits of the}} different systems emerges. Benchmark circuits are used to carry out the comparisons...|$|R
40|$|The Systems Analysis Programs for Hands-on Integrated Reliability Evaluations (SAPHIRE) is a {{software}} application developed for performing a complete probabilistic risk assessment (PRA) using {{a personal computer}} (PC) running the Microsoft Windows? operating system. Herein information is provided on the principles used in the construction and operation of Version 6. 0 and 7. 0 of the SAPHIRE system. This report summarizes the fundamental mathematical concepts of sets and <b>logic,</b> <b>fault</b> trees, and probability. This volume then describes the algorithms used to construct a fault tree and to obtain the minimal cut sets. It gives the formulas used to obtain the probability of the top event from the minimal cut sets, and the formulas for probabilities that apply for various assumptions concerning reparability and mission time. It defines the measures of basic event importance that SAPHIRE can calculate. This volume gives an overview of uncertainty analysis using simple Monte Carlo sampling or Latin Hypercube sampling, and states the algorithms used by this program to generate random basic event probabilities from various distributions. Also covered are enhance capabilities such as seismic analysis, cut set "recovery," end state manipulation, and use of "compound events. ...|$|E
40|$|The Systems Analysis Programs for Hands-on Integrated Reliability Evaluations (SAPHIRE) {{refers to}} a set of {{computer}} programs that were developed to create and analyze probabilistic risk assessment (PRAs). Herein information is provided on the principles used in the construction and operation of Version 8. 0 of the SAPHIRE system. This report summarizes the fundamental mathematical concepts of sets and <b>logic,</b> <b>fault</b> trees, and probability. This volume then describes the algorithms used to construct a fault tree and to obtain the minimal cut sets. It gives the formulas used to obtain the probability of the top event from the minimal cut sets, and the formulas for probabilities that apply for various assumptions concerning reparability and mission time. It defines the measures of basic event importance that SAPHIRE can calculate. This volume gives an overview of uncertainty analysis using simple Monte Carlo sampling or Latin Hypercube sampling, and states the algorithms used by this program to generate random basic event probabilities from various distributions. Also covered are enhance capabilities such as seismic analysis, Workspace algorithms, cut set "recovery," end state manipulation, and use of "compound events. ...|$|E
40|$|Abstract—With {{increasing}} inter-die and intra-die parameter {{variations in}} sub- 100 -nm process technologies, new failure mech-anisms are emerging in CMOS circuits. These failures lead to reduction in reliability of circuits, especially the area-constrained SRAM cells. In this paper, we have analyzed the emerging failure mechanisms in SRAM caches due to transistor variations, which results from process variations. Also we have proposed solutions to detect those failures efficiently. In particular, in this work, SRAM failure mechanisms under transistor variations are mapped to <b>logic</b> <b>fault</b> models. March test sequences have been optimized {{to address the}} emerging failure mechanisms with minimal overhead on test time. Moreover, we have proposed a design for test circuit to complement the March test sequence for at-speed testing of SRAMs. The proposed technique, referred as double sensing, {{can be used to}} test the stability of SRAM cells during read operations. Using the proposed March test sequence along with the double sensing technique, a test time reduction of 29 % is achieved, compared to the existing test techniques with the same fault coverage. We have also demonstrated that double sensing can be used during SRAM normal operation for online detection and correction of any number of random read faults. Index Terms—Design for test (DFT), failure mechanism, March test, process variation, SRAM. I...|$|E
40|$|Abstract—This paper {{analyses}} the behaviour of resistive bridg-ing faults under process {{variation and}} shows that process variation has a detrimental impact on test {{quality in the}} form of test escapes. To quantify this impact, a novel metric called test robustness is proposed and to mitigate test escapes, a new process variation-aware test generation method is presented. The method exploits the observation that <b>logic</b> <b>faults</b> that have high probability of occurrence and correspond to significant amounts of undetected bridge resistance have a high impact on test robustness and therefore should be targeted by test generation. Using synthesised ISCAS benchmarks with realistic bridge locations, results show that for all the benchmarks, the method achieves better results (less test escapes) than tests generated without consideration of process variation. Index Terms—Resistive Bridges, Process Variation, ATPG I...|$|R
40|$|This paper {{speculates that}} {{technology}} trends pose new challenges for fault tolerance in microprocessors. Specifically, severely reduced design tolerances implied by gigaherz clock rates {{may result in}} frequent and arbitrary transient faults. We suggest that existing fault-tolerant techniques [...] system-level, gate-level, or component-specific approaches [...] are either too costly for general purpose computing, overly intrusive to the design, or insufficient for covering arbitrary <b>logic</b> <b>faults.</b> An approach in which the microarchitecture itself provides fault tolerance is required. We propose a new time redundancy fault-tolerant approach in which a program is duplicated and the two redundant programs simultaneously run on the processor. The technique exploits several significant microarchitectural trends to provide broad coverage of transient faults and restricted coverage of permanent faults. These trends are simultaneous multithreading, control flow and data flow prediction, and hierarchi [...] ...|$|R
5000|$|Functional Safety Synthesis, Add {{reliability}} enhancements to structured elements (Modules, RAMs, ROMs, Register Files, FIFOs) to improves {{fault detection}} / fault tolerance. These includes (not limited to), Addition of error detection and / or correction codes (Hamming), Redundant <b>logic</b> for <b>fault</b> detection and fault tolerance (duplicate / triplicate) and Protocol checks (Interface parity, address alignment, beat count) ...|$|R
