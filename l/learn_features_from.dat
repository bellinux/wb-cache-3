48|10000|Public
40|$|While {{there is}} an {{enormous}} amount of music data available, the eld of music analysis almost exclusively uses manually designed features. In this work we <b>learn</b> <b>features</b> <b>from</b> music data in a completely unsupervised way and evaluate them on a musical genre classi- cation task. We achieve results very close to state-of-the-art performance which relies on highly hand-tuned feature extractors...|$|E
30|$|Deep {{learning}} was investigated by researchers for machine fault diagnosis. Shao et al. developed a deep learning approach based on deep belief networks, {{in order to}} <b>learn</b> <b>features</b> <b>from</b> frequency distribution of vibration signals {{for the purpose of}} health condition evaluation of induction motors. Wang et al. investigated a motor fault diagnosis method based on short-time Fourier transform and convolutional neural network; its effectiveness was validated using experimental data.|$|E
3000|$|... a. This {{ensures that}} the input feature is {{embedded}} with enough time-frequency detail. But, meaningful features {{still need to be}} obtained from such a high-dimensional input. Restricted Boltzmann machines (RBMs) [15] provide a useful paradigm for accomplishing this, since they are unsupervised generative models with great high-dimensional modeling capabilities, and allow the model to <b>learn</b> <b>features</b> <b>from</b> data. Moreover, RBMs form the basis of current state-of-the-art deep neural networks (DNNs) [16], allowing seamless integration into the DNN framework.|$|E
50|$|Supervised <b>feature</b> <b>learning</b> is <b>learning</b> <b>features</b> <b>from</b> labeled data. Approaches include.|$|R
50|$|Unsupervised <b>feature</b> <b>learning</b> is <b>learning</b> <b>features</b> <b>from</b> unlabeled data. The goal of {{unsupervised}} <b>feature</b> <b>learning</b> {{is often}} to discover low-dimensional features that captures some structure underlying the high-dimensional input data. When the <b>feature</b> <b>learning</b> is performed in an unsupervised way, it enables {{a form of}} semisupervised <b>learning</b> where <b>features</b> <b>learned</b> <b>from</b> an unlabeled dataset are then employed to improve performance in a supervised setting with labeled data. Several approaches are introduced in the following.|$|R
30|$|Deng et al. [9] {{has used}} sparse-autoencoder for {{acoustic}} <b>features</b> extraction <b>from</b> human speech signal for human emotion recognition. Shu and Fyshe [12] has used sparse-autoencoder for <b>feature</b> extraction <b>from</b> magnetoencephalography signal. The <b>learned</b> <b>features</b> <b>from</b> autoencoders {{are in the}} form of its hidden layer weights.|$|R
30|$|This {{research}} {{addresses the}} aforementioned challenges {{by developing a}} novel and complete computer-aided diagnosis (CAD) system for tumour detection and localization from MRIs. In the tumour detection phase, the system combines a CNN, which is used for feature extraction due to its ability to <b>learn</b> <b>features</b> <b>from</b> raw data, with an error-correcting output codes support vector machine (ECOC-SVM), which is used for feature classification. The system is considered a two-phase multi-model artefact due to its detection and localization abilities using different CNN models.|$|E
30|$|To {{overcome}} {{the problems of}} handcrafted features for scene classification, unsupervised feature learning is reckoned as the potential strategy. It can automatically <b>learn</b> <b>features</b> <b>from</b> unlabeled input data and has made astonishing progress in remote sensing scene classification [16 – 18]. The unsupervised-learning-based features are more discriminative and better suited to the classification problem. PCA, K-means clustering, sparse coding, and autoencoder are typical unsupervised learning methods. These methods and their variants have achieved great success in the scene classification field.|$|E
40|$|Deep Autoencoder has the {{powerful}} ability to <b>learn</b> <b>features</b> <b>from</b> {{large number of}} unlabeled samples and {{a small number of}} labeled samples. In this work, we have improved the network structure of the general deep autoencoder and applied it to the disease auxiliary diagnosis. We have achieved a network by entering the specific indicators and predicting whether suffering from liver disease, the network using real physical examination data for training and verification. Compared with the traditional semi-supervised machine learning algorithm, deep autoencoder will get higher accuracy...|$|E
30|$|Instead of {{training}} networks on full images, {{we can use}} convolutional networks to reduce the computational cost of <b>learning</b> <b>features</b> <b>from</b> large-size images with autoencoders. First, small-size image patches are sampled randomly from the training set and trained with autoencoders. Then, the <b>learned</b> <b>features</b> should be convolved with larger images and different feature activations at each location can be obtained [11].|$|R
40|$|A {{new musical}} {{instrument}} classification method using convolutional neural networks (CNNs) {{is presented in}} this paper. Unlike the traditional methods, we investigated a scheme for classifying musical instruments using the <b>learned</b> <b>features</b> <b>from</b> CNNs. To create the <b>learned</b> <b>features</b> <b>from</b> CNNs, we not only used a conventional spectrogram image, but also proposed multiresolution recurrence plots (MRPs) that contain the phase information of a raw input signal. Consequently, we fed the characteristic timbre of the particular instrument into a neural network, which cannot be extracted using a phase-blinded representations such as a spectrogram. By combining our proposed MRPs and spectrogram images with a multi-column network, the performance of our proposed classifier system improves over a system that uses only a spectrogram. Furthermore, the proposed classifier also outperforms the baseline result <b>from</b> traditional handcrafted <b>features</b> and classifiers. Comment: 14 pages, 5 figures, 1 tabl...|$|R
40|$|We {{present a}} training/test {{framework}} for audio classification using <b>learned</b> <b>feature</b> representations. Commonly used audio features in audio classification, such as MFCC and chroma, {{have been developed}} based on acoustic knowledge. As an alternative, there is increasing interest in <b>learning</b> <b>features</b> <b>from</b> data using unsupervised learning algorithms. In this work, we apply sparse Restricted Boltzmann Machine to audio data, particularly focusing on <b>learning</b> high-dimensional sparse <b>feature</b> representation. Our evaluation results on two music genre datasets show that the <b>learned</b> <b>feature</b> representations achieve high accuracy. 1...|$|R
30|$|Extracting {{features}} from original signals {{is a key}} {{procedure for}} traditional fault diagnosis of induction motors, as it directly influences the performance of fault recognition. However, high quality features need expert knowledge and human intervention. In this paper, a deep learning approach based on deep belief networks (DBN) is developed to <b>learn</b> <b>features</b> <b>from</b> frequency distribution of vibration signals {{with the purpose of}} characterizing working status of induction motors. It combines feature extraction procedure with classification task together to achieve automated and intelligent fault diagnosis. The DBN model is built by stacking multiple-units of restricted Boltzmann machine (RBM), and is trained using layer-by-layer pre-training algorithm. Compared with traditional diagnostic approaches where feature extraction is needed, the presented approach has the ability of learning hierarchical representations, which are suitable for fault classification, directly from frequency distribution of the measurement data. The structure of the DBN model is investigated as the scale and depth of the DBN architecture directly affect its classification performance. Experimental study conducted on a machine fault simulator verifies the effectiveness of the deep learning approach for fault diagnosis of induction motors. This research proposes an intelligent diagnosis method for induction motor which utilizes deep learning model to automatically <b>learn</b> <b>features</b> <b>from</b> sensor data and realize working status recognition.|$|E
40|$|Transcriptional {{profiling}} on microarrays {{to obtain}} gene expressions {{has been used}} to facilitate cancer diagnosis. We propose a deep generative machine learning architecture (called DeepCancer) that <b>learn</b> <b>features</b> <b>from</b> unlabeled microarray data. These models have been used in conjunction with conventional classifiers that perform classification of the tissue samples as either being cancerous or non-cancerous. The proposed model has been tested on two different clinical datasets. The evaluation demonstrates that DeepCancer model achieves a very high precision score, while significantly controlling the false positive and false negative scores...|$|E
40|$|Building {{intelligent}} {{systems that are}} capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many computer vision-related tasks. We propose the multispectral neural networks (MSNN) to <b>learn</b> <b>features</b> <b>from</b> multicolumn deep neural networks and embed the penultimate hierarchical discriminative manifolds into a compact representation. The low-dimensional embedding explores the complementary property of different views wherein the distribution of each view is sufficiently smooth and hence achieves robustness, given few labeled training data. Our experiments show that spectrally embedding several deep neural networks can explore the optimum output from the multicolumn networks and consistently decrease the error rate compared with a single deep network...|$|E
3000|$|It {{has been}} shown that pooling {{operations}} can influence the performance of convolutional networks. For example, Scherer et al. have given the conclusion that a max pooling operation is superior for <b>learning</b> <b>feature</b> <b>from</b> image-like data [10]. However, this is not always true in our experiments with convolutional autoencoders. In [22], Boureau et al. have proved that max pooling performs better when the features in R [...]...|$|R
40|$|Machine {{learning}} can o er {{an increase in}} the exibility and applicability of robotics at several levels of control. In this paper, we characterize two symbolic learning tasks in the eld of robotics. We outline an approach for <b>learning</b> <b>features</b> <b>from</b> sensory data and for using these <b>features</b> to <b>learn</b> more complex ones. We illustrate our approach with rst experiments in the eld of navigation. ...|$|R
30|$|Selection of text feature item is a {{basic and}} {{important}} matter for text mining and information retrieval. Traditional methods of feature extraction require handcrafted features. To hand-design, an effective feature is a lengthy process, but aiming at new applications, deep learning enables to acquire new effective <b>feature</b> representation <b>from</b> training data. As a new feature extraction method, deep learning has made achievements in text mining. The major difference between deep learning and conventional methods is that deep <b>learning</b> automatically <b>learns</b> <b>features</b> <b>from</b> big data, instead of adopting handcrafted features, which mainly depends on priori knowledge of designers and is highly impossible to take the advantage of big data. Deep learning can automatically <b>learn</b> <b>feature</b> representation <b>from</b> big data, including millions of parameters. This thesis outlines the common methods used in text feature extraction first, and then expands frequently used deep learning methods in text feature extraction and its applications, and forecasts the application of deep <b>learning</b> in <b>feature</b> extraction.|$|R
40|$|Fingerprint {{recognition}} {{systems are}} vulnerable to impersonation by fake or spoof fingerprints. Fingerprint liveness detection is a step to ensure whether a scanned fingerprint is live or fake prior to a recognition step. This paper presents a fingerprint liveness detection method based on a deep belief network (DBN). A DBN with multiple layers of restricted Boltzmann machine is used to <b>learn</b> <b>features</b> <b>from</b> a set of live and fake fingerprints and also to detect the liveness. The proposed method is a systematic application of a deep learning technique, and does not require specific domain expertise regarding fake fingerprints or recognition systems. The proposed method provides accurate detection of the liveness with various sensor datasets collected for the international fingerprint liveness detection competition. clos...|$|E
40|$|In {{this work}} {{we present a}} system to {{automatically}} <b>learn</b> <b>features</b> <b>from</b> audio in an unsupervised manner. Our method first learns an overcomplete dictionary {{which can be used}} to sparsely decompose log-scaled spectrograms. It then trains an efficient encoder which quickly maps new inputs to approximations of their sparse representations using the learned dictionary. This avoids expensive iterative procedures usually required to infer sparse codes. We then use these sparse codes as inputs for a linear Support Vector Machine (SVM). Our system achieves 83. 4 % accuracy in predicting genres on the GTZAN dataset, which is competitive with current state-of-the-art approaches. Furthermore, the use of a simple linear classifier combined with a fast feature extraction system allows our approach to scale well to large datasets. 1...|$|E
40|$|This paper {{presents}} a Convolutional Neural Network (CNN) based page segmentation method for handwritten historical document images. We consider page segmentation as a pixel labeling problem, i. e., each pixel {{is classified as}} one of the predefined classes. Traditional methods in this area rely on carefully hand-crafted features or large amounts of prior knowledge. In contrast, we propose to <b>learn</b> <b>features</b> <b>from</b> raw image pixels using a CNN. While many researchers focus on developing deep CNN architectures to solve different problems, we train a simple CNN with only one convolution layer. We show that the simple architecture achieves competitive results against other deep architectures on different public datasets. Experiments also demonstrate the effectiveness and superiority of the proposed method compared to previous methods...|$|E
40|$|Abstract—To {{simplify the}} {{parameter}} {{of the deep}} learning network, a cascaded compressive sensing model “CSNet ” is implemented for image classification. Firstly, we use cascaded compressive sensing network to <b>learn</b> <b>feature</b> <b>from</b> the data. Secondly, CSNet generates the feature by binary hashing and block-wise histograms. Finally, a linear SVM classifier is used to classify these features. The experiments on the MNIST dataset indicate that higher classification accuracy {{can be obtained by}} this algorithm...|$|R
40|$|Abstract — This paper {{presents}} an approach for labeling objects in 3 D scenes. We introduce HMP 3 D, a hierarchical sparse coding technique for <b>learning</b> <b>features</b> <b>from</b> 3 D point cloud data. HMP 3 D classifiers are trained using a synthetic dataset of virtual scenes generated using CAD models from an online database. Our scene labeling system combines <b>features</b> <b>learned</b> <b>from</b> raw RGB-D images and 3 D point clouds directly, without any hand-designed features, to assign an object label to every 3 D {{point in the}} scene. Experiments on the RGB-D Scenes Dataset v. 2 demonstrate that the proposed approach {{can be used to}} label indoor scenes containing both small tabletop objects and large furniture pieces. I...|$|R
40|$|Abstract. In {{this work}} we propose a feature-based {{segmentation}} ap-proach that is domain independent. While most existing approaches {{are based on}} application-specific hand-crafted features, we propose a frame-work for <b>learning</b> <b>features</b> <b>from</b> data itself at multiple scales and depth. Our features can be easily integrated into classifiers or energy-based seg-mentation algorithms. We test the performance of our proposed method on two MICCAI grand challenges, obtaining the top score on VESSEL 12 and competitive performance on BRATS 2012. ...|$|R
40|$|We {{present an}} {{approach}} for learning low- and high-level fin-gerprint structures in an unsupervised manner, which we use for enhancement of fingerprint images and estimation of orientation fields, frequency images, and region masks. We incorporate {{the use of}} a convolutional deep belief network to <b>learn</b> <b>features</b> <b>from</b> greyscale, clean fingerprint images. We also show that reconstruction performed by the learnt net-work works as a suitable enhancement of the fingerprint, and hierarchical probabilistic inference is able to estimate overall fingerprint structures as well. Our approach performs bet-ter than Gabor-based enhancement and short time Fourier transform-assisted enhancement on images it was trained on. We further use information from the learnt features in first layer, which are short and oriented ridge structures, to ex-tract the orientation field, frequency image, and region mask of input fingerprints...|$|E
40|$|This report {{presents}} {{work done}} {{on the use of}} CRFs for image labeling. The project is based on the paper titled ‘Multiscale Conditional Random Fields in Image Labeling ’ by Xuming he et al [1]. Contextual information can significantly improve image classification. The paper proposes an approach to include contextual features for labeling images. The features defined in the framework encode information occurring at different scales in the image. The outputs of various features are then combined probabilistically to yield an image labeling. The contrastive divergence algorithm is used to <b>learn</b> <b>features</b> <b>from</b> labeled data and inference is done using the maximum posterior marginals (MPM) criterion. The advantages and limitations of this approach are discussed. The report also presents a brief survey of recent literature on using context in vision. 1...|$|E
40|$|This paper {{proposes to}} <b>learn</b> <b>features</b> <b>from</b> sets of labeled raw images. With this method, {{the problem of}} {{over-fitting}} can be effectively suppressed, so that deep CNNs can be trained from scratch with {{a small number of}} training data, i. e., 420 labeled albums with about 30 000 photos. This method can effectively deal with sets of images, no matter if the sets bear temporal structures. A typical approach to sequential image analysis usually leverages motions between adjacent frames, while the proposed method focuses on capturing the co-occurrences and frequencies of features. Nevertheless, our method outperforms previous best performers in terms of album classification, and achieves comparable or even better performances in terms of gait based human identification. These results demonstrate its effectiveness and good adaptivity to different kinds of set data. Zifeng Wu, Yongzhen Huang, Liang Wan...|$|E
30|$|We <b>learn</b> sparse <b>features</b> <b>from</b> the preprocessed data {{described}} above. This section {{explains the}} sparse filtering algorithm, activation function, and details {{about how we}} generated the sparse feature representation.|$|R
30|$|The RBMs are {{stochastic}} {{neural networks}} and <b>learn</b> the <b>features</b> {{of the data}} {{in terms of the}} weight of the network [6]. These weights are initialized by random values for training by training data. This random initialization of the RBM weights requires many training examples and large number of iterations to achieve a global minima by its cost function (energy function). If there are few training data, then the cost function might achieve a local minima only and this makes the <b>learned</b> weights or <b>features</b> inconsistent. This inconsistency will then reduce the classification performance. To overcome this problem, these weights are initialized by some values that are closer to the features of the training data. To <b>learn</b> these initial <b>features</b> or weights, an unlabeled data set is used. A restricted Boltzmann machine RBM 1 is trained on this unlabeled data set and <b>learned</b> <b>features</b> <b>from</b> this data sets are used as initial weights of RBM 2. Then, the RBM 2 with these initial features is trained with the labeled training data. The cost function of this RBM 2 achieves the global minima in a small time with only few training data. This way RBM 2 <b>learns</b> <b>features</b> <b>from</b> labeled training data quickly and with consistent features. This approach of use of unlabeled data set is also called “self-taught learning” and first proposed by Raina [16].|$|R
30|$|Citizen {{learning}} experiences {{can be understood}} as perceptions, reactions, and performances in learning environments. This study analyzes citizen <b>learning</b> experiences’ <b>features</b> <b>from</b> the perspective of learning engagement, learning approach, and learning achievement.|$|R
40|$|This paper {{presents}} a stacked sparse auto-encoder (SSAE) based deep learning method for an electronic nose (e-nose) system to classify different brands of Chinese liquors. It {{is well known}} that preprocessing; feature extraction (generation and reduction) are necessary steps in traditional data-processing methods for e-noses. However, these steps are complicated and empirical because there is no uniform rule for choosing appropriate methods from many different options. The main advantage of SSAE is that it can automatically <b>learn</b> <b>features</b> <b>from</b> the original sensor data without the steps of preprocessing and feature extraction; which can greatly simplify data processing procedures for e-noses. To identify different brands of Chinese liquors; an SSAE based multi-layer back propagation neural network (BPNN) is constructed. Seven kinds of strong-flavor Chinese liquors were selected for a self-designed e-nose to test the performance of the proposed method. Experimental results show that the proposed method outperforms the traditional methods...|$|E
40|$|This paper {{proposes a}} method that uses feature fusion to {{represent}} images better for face detection after feature extraction by {{deep convolutional neural network}} (DCNN). First, with Clarifai net and VGG Net-D (16 layers), we <b>learn</b> <b>features</b> <b>from</b> data, respectively; then we fuse features extracted from the two nets. To obtain more compact feature representation and mitigate computation complexity, we reduce the dimension of the fused features by PCA. Finally, we conduct face classification by SVM classifier for binary classification. In particular, we exploit offset max-pooling to extract features with sliding window densely, which leads to better matches of faces and detection windows; thus the detection result is more accurate. Experimental results show that our method can detect faces with severe occlusion and large variations in pose and scale. In particular, our method achieves 89. 24 % recall rate on FDDB and 97. 19 % average precision on AFW...|$|E
40|$|With the {{development}} of Internet of Everything such as Internet of Things, Internet of People, and Industrial Internet, big data is being generated. Clustering is a widely used technique for big data analytics and mining. However, most of current algorithms are not effective to cluster heterogeneous data which is prevalent in big data. In this paper, we propose a high-order CFS algorithm (HOCFS) to cluster heterogeneous data by combining the CFS clustering algorithm and the dropout deep learning model, whose functionality rests on three pillars: (i) an adaptive dropout deep learning model to <b>learn</b> <b>features</b> <b>from</b> each type of data, (ii) a feature tensor model to capture the correlations of heterogeneous data, and (iii) a tensor distance-based high-order CFS algorithm to cluster heterogeneous data. Furthermore, we verify our proposed algorithm on different datasets, by comparison with other two clustering schemes, that is, HOPCM and CFS. Results confirm {{the effectiveness of the}} proposed algorithm in clustering heterogeneous data...|$|E
30|$|Since the timbral {{differences}} among the same-pitched notes with distinct fingerings are not obvious, music transcription systems typically focus only on detecting the onset and pitch of a note, discarding the fingering information. However, it is valuable {{to figure out which}} fingering is used to generate a specific note, particularly for musical training purposes. Handcrafted audio features such as mel-frequency cepstral coefficients (MFCCs) are commonly used for musical timbre analysis, but there is an increasing interest in <b>learning</b> <b>features</b> <b>from</b> data in an unsupervised manner.|$|R
40|$|Motivated by the {{observation}} that coarse and fine resolutions of an image reveal different structures in the underlying visual phenomenon, we present a model based on the Deep Belief Network (DBN) which <b>learns</b> <b>features</b> <b>from</b> the multiscale representation of images. A Laplacian Pyramid is first constructed for each image. DBNs are then trained separately at each level of the pyramid. Finally, a top level RBM combines these DBNs into a single network we call the Multiresolution Deep Belief Network (MrDBN). Experiments show that MrDBNs generaliz...|$|R
40|$|Part 8 : Pattern RecognitionInternational audienceExtracting good {{representations}} from {{images is}} essential for many computer vision tasks. While progress in deep learning shows the importance of <b>learning</b> hierarchical <b>features,</b> {{it is also important}} to <b>learn</b> <b>features</b> through multiple paths. This paper presents Multipath Convolutional-Recursive Neural Networks(M-CRNNs), a novel scheme which aims to <b>learn</b> image <b>features</b> <b>from</b> multiple paths using models based on combination of convolutional and recursive neural networks (CNNs and RNNs). CNNs <b>learn</b> low-level <b>features,</b> and RNNs, whose inputs are the outputs of the CNNs, learn the efficient high-level features. The final features of an image are the combination of the <b>features</b> <b>from</b> all the paths. The result shows that the <b>features</b> <b>learned</b> <b>from</b> M-CRNNs are a highly discriminative image representation that increases the precision in object recognition...|$|R
