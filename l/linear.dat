10000|65|Public
5|$|The main divinities {{who appear}} to be of warlike nature were Ares (<b>Linear</b> B: A-re) and Athena Potnia (<b>Linear</b> B: A-ta-na Po-ti-ni-ja).|$|E
5|$|This {{article is}} about the history and {{development}} of passive <b>linear</b> analogue filters used in electronics. For <b>linear</b> filters in general see <b>Linear</b> filter. For electronic filters in general see Electronic filter.|$|E
5|$|Credits {{adapted from}} the Mariah Carey <b>linear</b> notes.|$|E
5|$|In 1857, Cayley {{introduced}} matrix notation, {{which allows}} for a harmonization and simplification of <b>linear</b> maps. Around the same time, Grassmann studied the barycentric calculus initiated by Möbius. He envisaged sets of abstract objects endowed with operations. In his work, the concepts of <b>linear</b> independence and dimension, as well as scalar products, are present. In fact, Grassmann's 1844 work exceeds the framework of vector spaces, since his consideration of multiplication led him to what are today called algebras. Peano {{was the first to}} give the modern definition of vector spaces and <b>linear</b> maps in 1888.|$|E
5|$|Later, von Neumann {{suggested}} a new method of <b>linear</b> programming, using the homogeneous <b>linear</b> system of Gordan (1873), which was later popularized by Karmarkar's algorithm. Von Neumann's method used a pivoting algorithm between simplices, with the pivoting decision {{determined by a}} nonnegative least squares subproblem with a convexity constraint (projecting the zero-vector onto the convex hull of the active simplex). Von Neumann's algorithm was the first interior point method of <b>linear</b> programming.|$|E
5|$|<b>Linear</b> {{search is}} a simple search {{algorithm}} that checks every record until it finds the target value. <b>Linear</b> search can be done on a linked list, which allows for faster insertion and deletion than an array. Binary search is faster than <b>linear</b> search for sorted arrays except if the array is short. If the array must first be sorted, that cost must be amortized over any searches. Sorting the array also enables efficient approximate matches and other operations.|$|E
25|$|PDIFF {{is mostly}} a {{technical}} point: smooth maps are not piecewise <b>linear</b> (unless <b>linear),</b> and piecewise <b>linear</b> maps are not smooth (unless globally <b>linear)</b> – the intersection is <b>linear</b> maps, or more precisely affine maps (because not based) – so they cannot directly be related: they are separate generalizations {{of the notion of}} an affine map.|$|E
25|$|More formally, <b>linear</b> {{programming}} {{is a technique}} for the optimization of a <b>linear</b> objective function, subject to <b>linear</b> equality and <b>linear</b> inequality constraints. Its feasible region is a convex polytope, which is a set defined as the intersection of finitely many half spaces, {{each of which is}} defined by a <b>linear</b> inequality. Its objective function is a real-valued affine (<b>linear)</b> function defined on this polyhedron. A <b>linear</b> programming algorithm finds a point in the polyhedron where this function has the smallest (or largest) value if such a point exists.|$|E
25|$|In <b>linear</b> algebra, an {{endomorphism}} of a {{vector space}} V is a <b>linear</b> operator V → V. An automorphism is an invertible <b>linear</b> operator on V. When the vector space is finite-dimensional, the automorphism group of V {{is the same}} as the general <b>linear</b> group, GL(V).|$|E
25|$|Steel, {{carbon fiber}} and glass among others are usually {{considered}} <b>linear</b> materials, while other {{materials such as}} rubber and soils are non-linear. However, {{this is not an}} absolute classification: if very small stresses or strains are applied to a non-linear material, the response will be <b>linear,</b> but if very high stress or strain is applied to a <b>linear</b> material, the <b>linear</b> theory will not be enough. For example, as the <b>linear</b> theory implies reversibility, it would be absurd to use the <b>linear</b> theory to describe the failure of a steel bridge under a high load; although steel is a <b>linear</b> material for most applications, it is not in such a case of catastrophic failure.|$|E
25|$|<b>Linear</b> {{programming}} (LP, {{also called}} <b>linear</b> optimization) {{is a method}} to achieve the best outcome (such as maximum profit or lowest cost) in a mathematical model whose requirements are represented by <b>linear</b> relationships. <b>Linear</b> programming is a special case of mathematical programming (mathematical optimization).|$|E
25|$|Polynomial {{interpolation}} is a {{generalization of}} <b>linear</b> interpolation. Note that the <b>linear</b> interpolant is a <b>linear</b> function. We now replace this interpolant with a polynomial of higher degree.|$|E
25|$|The inverse of a <b>linear</b> map, when defined, {{is again}} a <b>linear</b> map.|$|E
25|$|The <b>linear</b> {{feedback}} {{shift register}} {{has a strong}} relationship to <b>linear</b> congruential generators.|$|E
25|$|The region had bridges {{with the}} {{combined}} length of 23,775.49 meters <b>linear.</b> Surigao del Norte and Surigao del Sur had the longest bridge length 9,288.520 m <b>linear</b> and 7,853.4 m <b>linear,</b> respectively.|$|E
25|$|An {{important}} {{special case}} is when , {{in which case}} the map is called a <b>linear</b> operator, or an endomorphism of. Sometimes the term <b>linear</b> function has the same meaning as <b>linear</b> map, while in analytic geometry it does not.|$|E
25|$|Angular {{momentum}} can {{be described}} as the rotational analog of <b>linear</b> momentum. Like <b>linear</b> momentum it involves elements of mass and displacement. Unlike <b>linear</b> momentum it also involves elements of position and shape.|$|E
25|$|Homogeneous <b>linear</b> {{differential}} equations are a subclass of <b>linear</b> {{differential equations}} {{for which the}} space of solutions is a <b>linear</b> subspace i.e. the sum of any set of solutions or multiples of solutions is also a solution. The coefficients of the unknown function and its derivatives in a <b>linear</b> differential equation are allowed to be (known) functions of the independent variable or variables; if these coefficients are constants then one speaks of a constant coefficient <b>linear</b> differential equation.|$|E
25|$|The {{field of}} {{optimization}} is further split in several subfields, {{depending on the}} form of the objective function and the constraint. For instance, <b>linear</b> programming deals with the case that both the objective function and the constraints are <b>linear.</b> A famous method in <b>linear</b> programming is the simplex method.|$|E
25|$|A linear-phase {{system has}} {{constant}} group delay. Non-trivial <b>linear</b> phase or nearly <b>linear</b> phase systems are also mixed phase.|$|E
25|$|A unitary {{operator}} {{is automatically}} <b>linear.</b> Likewise an antiunitary transformation is necessarily antilinear. Both variants are real <b>linear</b> and additive.|$|E
25|$|The {{study of}} <b>linear</b> algebra first {{emerged from the}} study of determinants, which were used to solve systems of <b>linear</b> equations. Determinants were used by Leibniz in 1693, and subsequently, Gabriel Cramer devised Cramer's Rule for solving <b>linear</b> systems in 1750. Later, Gauss further {{developed}} the theory of solving <b>linear</b> systems by using Gaussian elimination, which was initially listed as an advancement in geodesy.|$|E
25|$|An ideal {{amplifier}} {{would be a}} totally <b>linear</b> device, but real amplifiers are only <b>linear</b> within limits.|$|E
25|$|Techniques from <b>linear</b> algebra {{are also}} used in {{analytic}} geometry, engineering, physics, natural sciences, computer science, computer animation, advanced facial recognition algorithms {{and the social sciences}} (particularly in economics). Because <b>linear</b> algebra is such a well-developed theory, nonlinear mathematical models are sometimes approximated by <b>linear</b> models.|$|E
25|$|Geometrically, the <b>linear</b> {{constraints}} {{define the}} feasible region, {{which is a}} convex polyhedron. A <b>linear</b> function is a convex function, which implies that every local minimum is a global minimum; similarly, a <b>linear</b> function is a concave function, which implies that every local maximum is a global maximum.|$|E
25|$|Given {{again the}} finite-dimensional case, if bases have been chosen, then the {{composition}} of <b>linear</b> maps corresponds to the matrix multiplication, the addition of <b>linear</b> maps corresponds to the matrix addition, and the multiplication of <b>linear</b> maps with scalars corresponds to the multiplication of matrices with scalars.|$|E
25|$|Least-squares {{problems}} {{fall into}} two categories: <b>linear</b> or ordinary least squares and nonlinear least squares, depending {{on whether or not}} the residuals are <b>linear</b> in all unknowns. The <b>linear</b> least-squares problem occurs in statistical regression analysis; it has a closed-form solution. The nonlinear problem is usually solved by iterative refinement; at each iteration the system is approximated by a <b>linear</b> one, and thus the core calculation is similar in both cases.|$|E
25|$|<b>Linear</b> algebra, {{in which}} the {{specific}} properties of <b>linear</b> equations, vector spaces and matrices are studied.|$|E
25|$|<b>Linear</b> {{programming}} (LP), {{a type of}} convex programming, {{studies the}} {{case in which the}} objective function f is <b>linear</b> and the constraints are specified using only <b>linear</b> equalities and inequalities. Such a constraint set is called a polyhedron or a polytope if it is bounded.|$|E
25|$|While doubly linked and {{circular}} lists have {{advantages over}} singly linked <b>linear</b> lists, <b>linear</b> lists offer some advantages {{that make them}} preferable in some situations.|$|E
25|$|The {{algebraic}} matroids are matroids defined from sets {{of elements}} of a field extension using the notion of algebraic independence. Every <b>linear</b> matroid is algebraic, and for fields of characteristic zero (such as the real numbers) <b>linear</b> and algebraic matroids coincide, but for other fields there may exist algebraic matroids that are not <b>linear.</b>|$|E
25|$|The {{equations}} of a <b>linear</b> {{system are}} independent {{if none of}} the equations can be derived algebraically from the others. When the equations are independent, each equation contains new information about the variables, and removing any of the equations increases {{the size of the}} solution set. For <b>linear</b> equations, logical independence is the same as <b>linear</b> independence.|$|E
25|$|In Dempster–Shafer theory, or a <b>linear</b> belief {{function}} in particular, a <b>linear</b> regression model may be {{represented as a}} partially swept matrix, which can be combined with similar matrices representing observations and other assumed normal distributions and state equations. The combination of swept or unswept matrices provides an alternative method for estimating <b>linear</b> regression models.|$|E
25|$|In <b>linear</b> algebra, a convex cone is {{a subset}} of a vector space over an ordered field that is closed under <b>linear</b> {{combinations}} with positive coefficients.|$|E
25|$|In <b>linear</b> regression, the {{relationships}} are modeled using <b>linear</b> predictor functions whose unknown model parameters are estimated from the data. Such models are called <b>linear</b> models. Most commonly, the conditional mean of y given {{the value of}} X {{is assumed to be}} an affine function of X; less commonly, the median or some other quantile of the conditional distribution of y given X is expressed as a <b>linear</b> function of X. Like all forms of regression analysis, <b>linear</b> regression focuses on the conditional probability distribution of y given X, rather than on the joint probability distribution of y and X, which is the domain of multivariate analysis.|$|E
25|$|In mathematics, {{the theory}} of <b>linear</b> systems is the basis and a {{fundamental}} part of <b>linear</b> algebra, a subject which is used {{in most parts of}} modern mathematics. Computational algorithms for finding the solutions {{are an important part of}} numerical <b>linear</b> algebra, and play a prominent role in engineering, physics, chemistry, computer science, and economics. A system of non-linear equations can often be approximated by a <b>linear</b> system (see linearization), a helpful technique when making a mathematical model or computer simulation of a relatively complex system.|$|E
