2884|1965|Public
5|$|The {{concept of}} a {{derivative}} can be extended to many other settings. The common thread is that the derivative of a function at a point serves as a <b>linear</b> <b>approximation</b> of the function at that point.|$|E
25|$|So, the Onsager {{relations}} {{follow from}} {{the principle of}} detailed balance in the <b>linear</b> <b>approximation</b> near equilibrium.|$|E
25|$|Calculus is {{also used}} to find {{approximate}} solutions to equations; in practice it is the standard way to solve differential equations and do root finding in most applications. Examples are methods such as Newton's method, fixed point iteration, and <b>linear</b> <b>approximation.</b> For instance, spacecraft use a variation of the Euler method to approximate curved courses within zero gravity environments.|$|E
40|$|Various {{authors have}} {{previously}} presented different approaches how to exploit multiple <b>linear</b> <b>approximations</b> to enhance <b>linear</b> cryptanalysis. In this paper {{we present a}} new truly multidimensional approach to generalise Matsui’s Algorithm 1. We derive the statistical framework for it and show how to calculate multidimensional probability distributions based on correlations of onedimensional <b>linear</b> <b>approximations.</b> The main advantage is that the assumption about statistical independence of <b>linear</b> <b>approximations</b> can be removed. Then we apply these new techniques to four rounds of the block cipher Serpent and show that the multidimensional approach is more effective in recovering key bits correctly than the previous methods that use a multiple of one-dimensional <b>linear</b> <b>approximations...</b>|$|R
5000|$|To provide higher {{resolution}} of discontinuities, Godunov's scheme {{can be extended}} to use piecewise <b>linear</b> <b>approximations</b> of each cell, which results in a central difference scheme that is second-order accurate in space. The piecewise <b>linear</b> <b>approximations</b> are obtained from ...|$|R
40|$|Average <b>linear</b> <b>approximations</b> for smooth {{functions}} using empirical and Gaussian probabilities are introduced. The {{convergence of}} these approximations {{is shown to}} be uniform, {{in the sense of}} the Weierstrass <b>approximation</b> theorem. Average <b>linear</b> <b>approximations</b> with prearranged error functions are finally studied...|$|R
25|$|Hooke's law {{is only a}} first-order <b>linear</b> <b>approximation</b> to {{the real}} {{response}} of springs and other elastic bodies to applied forces. It must eventually fail once the forces exceed some limit, since no material can be compressed beyond a certain minimum size, or stretched beyond a maximum size, without some permanent deformation or change of state. Many materials will noticeably deviate from Hooke's law well before those elastic limits are reached.|$|E
25|$|Hooke's law only {{holds for}} some {{materials}} under certain loading conditions. Steel exhibits linear-elastic behavior in most engineering applications; Hooke's law is valid for it throughout its elastic range (i.e., for stresses below the yield strength). For some other materials, such as aluminium, Hooke's law {{is only valid}} {{for a portion of}} the elastic range. For these materials a proportional limit stress is defined, below which the errors associated with the <b>linear</b> <b>approximation</b> are negligible.|$|E
25|$|Another way {{ergodicity}} can {{be broken}} is by the existence of nonlinear soliton symmetries. In 1953, Fermi, Pasta, Ulam and Tsingou conducted computer simulations of a vibrating string that included a non-linear term (quadratic in one test, cubic in another, and a piecewise <b>linear</b> <b>approximation</b> to a cubic in a third). They found that {{the behavior of the}} system was quite different from what intuition based on equipartition would have led them to expect. Instead of the energies in the modes becoming equally shared, the system exhibited a very complicated quasi-periodic behavior. This puzzling result was eventually explained by Kruskal and Zabusky in 1965 in a paper which, by connecting the simulated system to the Korteweg–de Vries equation {{led to the development of}} soliton mathematics.|$|E
40|$|In {{this paper}} the (e#ective) bias of certain {{generalised}} <b>linear</b> <b>approximations</b> to the S-box are considered. Whereas, in the literature, the cryptanalyst typically restricts this search to <b>linear</b> <b>approximations</b> over Z 2, we here consider <b>linear</b> <b>approximations</b> over Z 4 and, more generally still, consider <b>approximations</b> which are <b>linear</b> {{in the sense}} that they can be completely factorised into the tensor product of length-two vectors. Consequently, significantly higher biases can be found in comparison to Z 2 -linear approximations...|$|R
40|$|In {{this paper}} {{theoretical}} aspects of multidimensional linear distinguishing attacks are investigated. Using known examples of highly nonlinear Boolean functions we demonstrate how multidimensional <b>linear</b> <b>approximations</b> offer {{significant reduction in}} data complexity in distinguishing attacks. We also get concrete examples where one-dimensional <b>linear</b> <b>approximations</b> are never statistically independent...|$|R
30|$|From {{the above}} graphs, the {{following}} <b>linear</b> <b>approximations</b> are proposed.|$|R
500|$|If {{we assume}} that v is small and that the {{derivative}} varies continuously in a, then [...] is approximately equal to , and therefore the right-hand side is approximately zero. The left-hand side can be rewritten {{in a different way}} using the <b>linear</b> <b>approximation</b> formula with [...] substituted for v. The <b>linear</b> <b>approximation</b> formula implies: ...|$|E
500|$|To {{determine}} {{what kind of}} function it is, notice that the <b>linear</b> <b>approximation</b> formula can be rewritten as ...|$|E
500|$|Up to {{changing}} variables, {{this is the}} statement that the function [...] is the best <b>linear</b> <b>approximation</b> to f at a.|$|E
40|$|We {{present an}} {{approach}} to obtain nonlinear information about neuronal response by com-puting multiple <b>linear</b> <b>approximations.</b> By calculating local <b>linear</b> <b>approximations</b> centered around particular stimuli, one can obtain insight into stimulus features that drive the re-sponse of highly nonlinear neurons, such as neurons highly selective to a small set of stimuli. We implement this approach based on stimulus-spike correlation (i. e., reverse correlation or spike-triggered average) methods. We illustrate the benefits of these <b>linear</b> <b>approximations</b> with a simplified two-dimensional model and a model of an auditory neuron that is highly selective to particular features of a song. ...|$|R
40|$|In {{this paper}} the (effective) bias of certain {{generalised}} <b>linear</b> <b>approximations</b> to the S-box are considered. Whereas, in the literature, the cryptanalyst typically restricts this search to <b>linear</b> <b>approximations</b> over Z 2, we here consider <b>linear</b> <b>approximations</b> over Z 4 and, more generally still, consider <b>approximations</b> which are <b>linear</b> {{in the sense}} that they can be completely factorised into the tensor product of length-two vectors. Consequently, significantly higher biases can be found in comparison to Z 2 -linear approximations. I. Introduction and Basic Theory Linear cryptanalysis of a binary block cipher, as conceived by Matsui [3], attempts to recover key bits by approximating core rounds of the block cipher by a series of Z 2 -linear expressions, and then concatenating these <b>linear</b> <b>approximations.</b> The block cipher to be approximated is parameterised by a secret key which is typically (although not always) added into the cipher by means of XOR. If thi...|$|R
40|$|In {{this talk}} we {{consider}} <b>linear</b> <b>approximations</b> of layered cipher constructions with secret key-dependent constants that are inserted between layers, {{and where the}} layers have strong interdependency. Then clearly, averaging over the constant would clearly be wrong as it will break the interdependencies, and the Piling Up Ã¢â¬âlemma cannot be used. We show how to use <b>linear</b> <b>approximations</b> to divide the constants into constant classes, not necessary determined by a linear relation. As an example, a nonlinear filter generator SOBER- 128 is considered and we show how to extend Matsui 2 ̆ 7 s Algorithm I in this case. Also {{the possibility of using}} multiple <b>linear</b> <b>approximations</b> simultaneously is considered...|$|R
500|$|... {{which has}} the {{intuitive}} interpretation (see Figure 1) that the tangent line to [...] at [...] gives the best <b>linear</b> <b>approximation</b> ...|$|E
500|$|When f is a {{function}} from an open subset of Rn to Rm, then the directional derivative of f in a chosen direction is the best <b>linear</b> <b>approximation</b> to f at that point and in that direction. [...] But when , no single directional derivative can give a complete picture {{of the behavior of}} f. The total derivative gives a complete picture by considering all directions at once. [...] That is, for any vector v starting at a, the <b>linear</b> <b>approximation</b> formula holds: ...|$|E
500|$|In some {{situations}} such as numerical analysis, a piecewise <b>linear</b> <b>approximation</b> to the identity is desirable. [...] This {{can be obtained}} by taking η1 to be a hat function. [...] With this choice of η1, one has ...|$|E
40|$|Addition modulo 2 31 - 1 {{is a basic}} {{arithmetic}} operation in the stream cipher ZUC. For evaluating ZUC's resistance against linear cryptanalysis, {{it is necessary to}} study properties of <b>linear</b> <b>approximations</b> of the addition modulo 2 31 - 1. In this paper we discuss <b>linear</b> <b>approximations</b> of the addition of k inputs modulo 2 n - 1 for n ≥ 2. As a result, an explicit expression of the correlations of <b>linear</b> <b>approximations</b> of the addition modulo 2 n - 1 is given when k = 2, and an iterative expression when k > 2. For a class of special <b>linear</b> <b>approximations</b> with all masks being equal to 1, we further discuss the limit of their correlations when n goes to infinity. It is shown that when k is even, the limit is equal to zero, and when k is odd, the limit is bounded by a constant depending on k. © 2011 Springer-Verlag...|$|R
25|$|Because {{interest}} and inflation are generally given as percentage increases, the formulae above are (<b>linear)</b> <b>approximations.</b>|$|R
50|$|The {{procedure}} for constructing approximations is different for each cipher. In {{the most basic}} type of block cipher, a substitution-permutation network, analysis is concentrated primarily on the S-boxes, the only nonlinear part of the cipher (i.e. the operation of an S-box cannot be encoded in a linear equation). For small enough S-boxes, {{it is possible to}} enumerate every possible linear equation relating the S-box's input and output bits, calculate their biases and choose the best ones. <b>Linear</b> <b>approximations</b> for S-boxes then must be combined with the cipher's other actions, such as permutation and key mixing, to arrive at <b>linear</b> <b>approximations</b> for the entire cipher. The piling-up lemma is a useful tool for this combination step. There are also techniques for iteratively improving <b>linear</b> <b>approximations</b> (Matsui 1994).|$|R
500|$|In one variable, {{the fact}} that the {{derivative}} is the best <b>linear</b> <b>approximation</b> is expressed by {{the fact that}} it is the limit of difference quotients. [...] However, the usual difference quotient does not make sense in higher dimensions because it is not usually possible to divide vectors. In particular, the numerator and denominator of the difference quotient are not even in the same vector space: The numerator lies in the codomain Rm while the denominator lies in the domain Rn. Furthermore, the derivative is a linear transformation, a different type of object from both the numerator and denominator. [...] To make precise the idea that [...] is the best <b>linear</b> <b>approximation,</b> it is necessary to adapt a different formula for the one-variable derivative in which these problems disappear. If , then the usual definition of the derivative may be manipulated to show that the derivative of f at a is the unique number [...] such that ...|$|E
500|$|The {{derivative}} of {{a function of}} a single variable at a chosen input value, when it exists, is {{the slope of the}} tangent line to the graph of the function at that point. The tangent line is the best <b>linear</b> <b>approximation</b> of the function near that input value. [...] For this reason, the derivative is often described as the [...] "instantaneous rate of change", the ratio of the instantaneous change in the dependent variable to that of the independent variable.|$|E
500|$|Derivatives may be {{generalized}} to functions of several real variables. In this generalization, the derivative is reinterpreted as a linear transformation whose graph is (after an appropriate translation) the best <b>linear</b> <b>approximation</b> to the graph of the original function. The Jacobian matrix is the matrix that represents this linear transformation {{with respect to the}} basis given by the choice of independent and dependent variables. [...] It can be calculated in terms of the partial derivatives with respect to the independent variables. [...] For a real-valued function of several variables, the Jacobian matrix reduces to the gradient vector.|$|E
40|$|Abstract. The {{classical}} {{technique to}} perform key mixing in block ciphers is through exclusive-or (exor). In this paper {{we show that}} when the n-bit key is mixed in a block cipher of size n bits via addition modulo 2 n, the bias of the <b>linear</b> <b>approximations</b> falls exponentially fast. Experimental results have been provided to show that such a scheme cannot be cryptanalyzed using Linear Cryptanalysis. Keywords: Block Ciphers, Key Mixing, <b>Linear</b> <b>Approximations,</b> Piling-Up Lemm...|$|R
3000|$|Examining the {{derivation}} of (50), {{it can be}} {{seen that}} two <b>linear</b> <b>approximations</b> are made to the phase term ψ (f [...]...|$|R
3000|$|... [...]. The {{choice of}} time step is again {{small enough to}} {{suppress}} the influence of time discretization errors, and the computations are performed by piecewise <b>linear</b> <b>approximations,</b> subsequently.|$|R
500|$|If n and m {{are both}} one, then the {{derivative}} [...] {{is a number}} and the expression [...] {{is the product of}} two numbers. But in higher dimensions, it is impossible for [...] to be a number. If it were a number, then [...] would be a vector in Rn while the other terms would be vectors in Rm, and therefore the formula would not make sense. For the <b>linear</b> <b>approximation</b> formula to make sense, [...] must be a function that sends vectors in Rn to vectors in Rm, and [...] must denote this function evaluated at v.|$|E
500|$|The {{tangent plane}} to a surface {{at a point}} is {{naturally}} a vector space whose origin is identified with the point of contact. [...] The tangent plane is the best <b>linear</b> <b>approximation,</b> or linearization, of a surface at a point. on the surface to the plane is infinitesimally small compared to the distance from P1 to P in the limit as P1 approaches P along the surface. Even in a three-dimensional Euclidean space, there is typically no natural way to prescribe a basis of the tangent plane, {{and so it is}} conceived of as an abstract vector space rather than a real coordinate space. The tangent space is the generalization to higher-dimensional differentiable manifolds.|$|E
500|$|The {{simplest}} type {{of such a}} wave can be visualized by its {{action on}} a ring of freely floating particles. A sine wave propagating through such a ring towards the reader distorts the ring in a characteristic, rhythmic fashion (animated image to the right). Since Einstein's equations are non-linear, arbitrarily strong gravitational waves do not obey linear superposition, making their description difficult. However, for weak fields, a <b>linear</b> <b>approximation</b> can be made. Such linearized gravitational waves are sufficiently accurate to describe the exceedingly weak waves {{that are expected to}} arrive here on Earth from far-off cosmic events, which typically result in relative distances increasing and decreasing by [...] or less. Data analysis methods routinely make use of the fact that these linearized waves can be Fourier decomposed.|$|E
3000|$|... for {{piecewise}} <b>linear</b> <b>approximations</b> with a nonsymmetric {{variant of}} interior penalty Galerkin discretizations. In {{the case of}} the energy norm, we obtain the optimal experimental order of convergence.|$|R
3000|$|... of extremal functions. The {{parameter}} c is used {{to adjust}} to the sound level and hence to provide <b>linear</b> <b>approximations</b> at different levels to the non-linear behavior of cochlear signal processing.|$|R
30|$|Now let us {{assume that}} all {{coefficients}} are proportional. Such equations arise as <b>linear</b> <b>approximations</b> of nonlinear difference equations in mathematical biology. Then a straightforward computation leads to the following result.|$|R
