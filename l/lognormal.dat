4926|22|Public
25|$|For example, {{log-normal}} distributions {{are often}} mistaken for power-law distributions: a data set {{drawn from a}} <b>lognormal</b> distribution will be approximately linear for large values (corresponding to the upper tail of the <b>lognormal</b> being close to a power law), but for small values the <b>lognormal</b> will drop off significantly (bowing down), corresponding to the lower tail of the <b>lognormal</b> being small (there are very few small values, rather than many small values in a power law).|$|E
25|$|In {{reliability}} analysis, the <b>lognormal</b> {{distribution is}} often used to model times to repair a maintainable system.|$|E
25|$|SIDS has a 4-parameter <b>lognormal</b> age {{distribution}} that spares infants shortly after birth — {{the time of}} maximal risk for almost all other causes of non-trauma infant death.|$|E
25|$|The picture shows a large {{variation}} of -values measured with the augerhole method {{in an area}} of 100 ha. The ratio between the highest and lowest values is 25. The cumulative frequency distribution is <b>lognormal</b> and was made with the CumFreq program.|$|E
25|$|Using several {{data sets}} (including {{breeding}} bird surveys from New York and Pennsylvania and moth collections from Maine, Alberta and Saskatchewan) Frank W. Preston (1948) argued that species abundances (when binned logarithmically in a Preston plot) follow a Normal (Gaussian) distribution, {{partly as a}} result of the Central Limit Theorem (Figure 4). This means that the abundance distribution is <b>Lognormal.</b> According to his argument, the right-skew observed in species abundance frequency histograms (including those described by Fisher et al. (1943)) was, in fact, a sampling artifact. Given that species toward the left side of the x-axis are increasingly rare, they may be missed in a random species sample. As the sample size increases however, the likelihood of collecting rare species in a way that accurately represents their abundance also increases, and more of the normal distribution becomes visible. The point at which rare species cease to be sampled has been termed Preston's veil line. As the sample size increases Preston's veil is pushed farther to the left and more of the normal curve becomes visible(Figure 6). Interestingly, Williams' moth data, originally used by Fisher to develop the logseries distribution, became increasingly <b>lognormal</b> as more years of sampling were completed.|$|E
25|$|Models {{that can}} take into account {{variability}} of {{the rate of the}} molecular clock between different evolutionary lineages in the phylogeny are called “relaxed” in opposition to “strict”. In such models the rate can be assumed to be correlated or not between ancestors and descendants and rate variation among lineages can be drawn from many distributions but usually exponential and <b>lognormal</b> distributions are applied. There is a special case, called “local molecular clock” when a phylogeny is divided into at least two partitions (sets of lineages) and in each strict molecular clock is applied but with different rate.|$|E
2500|$|<b>Lognormal</b> {{distribution}} {{is a special}} case of semi-bounded Johnson distribution ...|$|E
2500|$|Preston's {{theory has}} an {{interesting}} application: if a community is truly <b>lognormal</b> yet under-sampled, the <b>lognormal</b> distribution {{can be used}} to estimate the true species richness of a community. Assuming the shape of the total distribution can be confidently predicted from the collected data, the normal curve can be fit via statistical software or by completing the Gaussian formula: ...|$|E
2500|$|Aitchison, J. and Brown, J.A.C. (1957) [...] The <b>Lognormal</b> Distribution, Cambridge University Press.|$|E
2500|$|For example, Gibrat's law about {{proportional}} growth processes produce distributions {{that are}} <b>lognormal,</b> although their log–log plots look linear over a limited range. An explanation {{of this is}} that although the logarithm of the <b>lognormal</b> density function is quadratic in , yielding a [...] "bowed" [...] shape in a log–log plot, if the quadratic term is small relative to the linear term then the result can appear almost linear, and the <b>lognormal</b> behavior is only visible when the quadratic term dominates, which may require significantly more data. Therefore, a log–log plot that is slightly [...] "bowed" [...] downwards can reflect a log-normal distribution – not a power law.|$|E
2500|$|... {{range over}} many orders of {{magnitude}} (the distribution is often considered to be <b>lognormal),</b> ...|$|E
2500|$|Shockley {{was first}} to propose a <b>lognormal</b> {{distribution}} to model the creation process for scientific research papers.|$|E
2500|$|The {{conditional}} expectation of a <b>lognormal</b> random variable X {{with respect to}} a threshold k is its partial expectation divided by the cumulative probability of being in that range: ...|$|E
2500|$|In {{wireless}} communication, [...] "the local-mean power {{expressed in}} logarithmic values, such as dB or neper, has a normal (i.e., Gaussian) distribution." [...] Also, the random obstruction of radio signals due to large buildings and hills, called shadowing, is often modeled as a <b>lognormal</b> distribution.|$|E
2500|$|The two {{parameters}} [...] and [...] are not {{location and}} scale parameters for a lognormally distributed random variableX, {{but they are}} respectively location and scale parameters for the normally distributed logarithmlnX. The quantity e is a scale parameter for the family of <b>lognormal</b> distributions.|$|E
2500|$|For highly {{communicable}} epidemics, such as SARS in 2003, if publication {{intervention is}} involved, {{the number of}} hospitalized cases is shown to satisfy the <b>lognormal</b> distribution with no free parameters if an entropy is assumed and the standard deviation {{is determined by the}} principle of maximum rate of entropy production.|$|E
2500|$|In neuroscience, the {{distribution}} of firing rates across a population of neurons is often approximately <b>lognormal.</b> This has been first observed in the cortex and striatum [...] and later in hippocampus and entorhinal cortex, {{and elsewhere in the}} brain.. Also, intrinsic gain distributions and synaptic weight distributions appear to be lognormalas well.|$|E
2500|$|This can {{be derived}} by letting [...] within the integral. However, the {{expected}} value [...] is not defined for any positive value of the argument [...] as the defining integral diverges. [...] In consequence the moment generating function is not defined. [...] The last {{is related to the}} fact that the <b>lognormal</b> distribution is not uniquely determined by its moments.|$|E
2500|$|In applications, [...] is a {{parameter}} to be determined. In {{cases that}} [...] {{there are no}} data to determine this parameter, {{it is possible to}} evaluate it from some universal principle. One is the entropy method. [...] For growing processes which are governed by production and dissipation, it was shown that one can use some extremal principle of Shannon entropy to determine this parameter to be [...] This value can then be used to give some scaling relation between the inflexion point and maximum point of the <b>lognormal</b> distribution. It is shown that this relationship is determined by the base of natural logarithm, , and exhibits some geometrical similarity to the minimal surface energy principle. These scaling relations are shown to be useful for predicting a number of growth processes [...] (epidemic spreading, droplet splashing, population growth, swirling rate of the bathtub vortex, distribution of language characters, velocity profile of turbulences, etc.). [...] For instance, the <b>lognormal</b> function with such [...] fits well with the size of secondary produced droplet during droplet impact [...] and the spreading of one epidemic disease.|$|E
2500|$|Let [...] be {{independent}} log-normally distributed variables with possibly varying [...] and [...] parameters, and [...] [...] The distribution of [...] has no closed-form expression, {{but can be}} reasonably approximated by another log-normal distribution [...] at the right tail. Its probability density function at the neighborhood of 0 has been characterized [...] {{and it does not}} resemble any log-normal distribution. A commonly used approximation due to L.F. Fenton (but previously stated by R.I. Wilkinson and mathematical justified by Marlow) is obtained by matching the mean and variance of another <b>lognormal</b> distribution: ...|$|E
2500|$|In {{probability}} theory, a log-normal (or <b>lognormal)</b> {{distribution is}} a continuous probability distribution of a random variable whose logarithm is normally distributed. Thus, if the random variable [...] is log-normally distributed, then [...] has a normal distribution. Likewise, if [...] has a normal distribution, then the exponential function of , , has a log-normal distribution. A random variable which is log-normally distributed takes only positive real values. The distribution is occasionally {{referred to as}} the Galton distribution or Galton's distribution, after Francis Galton. The log-normal distribution also has been associated with other names, such as McAlister, Gibrat and Cobb–Douglas.|$|E
2500|$|The same {{relationship}} {{occurs in}} many other rankings unrelated to language, such as the population ranks of cities in various countries, corporation sizes, income rankings, ranks of number of people watching the same TV channel, and so on. The appearance of the distribution in rankings of cities by population was first noticed by Felix Auerbach in 1913. Empirically, a data set can be tested to see whether Zipf's law applies by checking the goodness of fit of an empirical distribution to the hypothesized power law distribution with a Kolmogorov-Smirnov test, and then comparing the (log) likelihood ratio of the power law distribution to alternative distributions like an exponential distribution or <b>lognormal</b> distribution. When Zipf's law is checked for cities, a better fit has been found with exponent s = 1.07; i.e. the [...] largest settlement is [...] {{the size of the}} largest settlement. While Zipf's law holds for the upper tail of the distribution, the entire distribution of cities is log-normal and follows Gibrat's law. Both laws are consistent because a log-normal tail can typically not be distinguished from a Pareto (Zipf) tail.|$|E
50|$|For example, {{log-normal}} distributions {{are often}} mistaken for power-law distributions: a data set {{drawn from a}} <b>lognormal</b> distribution will be approximately linear for large values (corresponding to the upper tail of the <b>lognormal</b> being close to a power law), but for small values the <b>lognormal</b> will drop off significantly (bowing down), corresponding to the lower tail of the <b>lognormal</b> being small (there are very few small values, rather than many small values in a power law).|$|E
5000|$|The Black-Karasinski model (1991), {{which is}} <b>lognormal,</b> has [...] The model {{may be seen}} as the <b>lognormal</b> {{application}} of Hull-White; its lattice-based implementation is similarly trinomial (binomial requiring varying time-steps).|$|E
50|$|As {{the model}} generates a {{symmetric}} ("bell shaped") distribution of {{rates in the}} future, negative rates are possible. Further, it does not incorporate mean reversion. For both of these reasons, models such as Black-Derman-Toy (<b>lognormal</b> and mean reverting) and Hull-White (mean reverting with <b>lognormal</b> variant available) are often preferred. The Kalotay-Williams-Fabozzi model is a <b>lognormal</b> analogue to the Ho-Lee model, although is less widely used than the latter two.|$|E
50|$|The skew <b>lognormal</b> cascade distribution.|$|E
50|$|Living systems need {{to extract}} {{resources}} {{to compensate for}} continuous diffusion. This can be modelled mathematically as <b>lognormal</b> processes. The Black-Scholes equation is a deterministic representation of <b>lognormal</b> processes. The Black-Scholes model can be extended to describe general biological and social systems.|$|E
5000|$|The Kalotay-Williams-Fabozzi model (1993) has {{the short}} rate as , a <b>lognormal</b> {{analogue}} to the Ho-Lee model, {{and a special}} case of the Black-Derman-Toy model. This approach is effectively similar to “the original Salomon Brothers model" [...] (1987), also a <b>lognormal</b> variant on Ho-Lee.|$|E
5000|$|... #Caption: Cumulative {{frequency}} distribution (<b>lognormal)</b> of hydraulic conductivity (X-data) ...|$|E
5000|$|The <b>Lognormal</b> Distribution, Aitchison, J. and Brown, J.A.C. (1957) ...|$|E
5000|$|<b>Lognormal</b> kriging interpolates {{positive}} data {{by means}} of logarithms.|$|E
5000|$|... #Subtitle level 3: XS premium using <b>Lognormal</b> cost {{distribution}} ...|$|E
5000|$|<b>Lognormal</b> {{distribution}} {{is a special}} case of semi-bounded Johnson distribution ...|$|E
5000|$|... = the {{distribution}} for the annual returns, e.g., the three-parameter <b>lognormal</b> distribution.|$|E
5000|$|Preston's {{theory has}} an {{interesting}} application: if a community is truly <b>lognormal</b> yet under-sampled, the <b>lognormal</b> distribution {{can be used}} to estimate the true species richness of a community. Assuming the shape of the total distribution can be confidently predicted from the collected data, the normal curve can be fit via statistical software or by completing the Gaussian formula: ...|$|E
5000|$|... f(r) = the {{distribution}} for the annual returns, e.g. the three-parameter <b>lognormal</b> distribution ...|$|E
