7|10000|Public
40|$|Classification Abstract. An {{efficient}} ear recognition {{method by}} weighted wavelet transformation and Bi-Directional {{principal component analysis}} was proposed. First, each ear image was decomposed into four sub-images by wavelet transformation,the four sub-images were <b>low</b> <b>frequency</b> <b>image,</b> vertical detail image,horizontal detail image and high frequency image. Then the <b>low</b> <b>frequency</b> <b>image</b> was decomposed into four sub-images, the four-images were weighted by different coefficients, then,the four sub-images were reconstructed into a image. On this basis,the feature was extraction by the BDPCA method,and then we use the k-Nearest Neighbor Classification to recognition. Experimental {{results show that the}} method have high recognition rate and shorted training time...|$|E
40|$|In this work, {{we present}} a {{methodology}} for fusing high frequency and low frequency radar images. The goal of this system {{is to find the}} strong surface clutter which is common to high and low frequency radar images and to subtract (de-fuse) this common component from the <b>low</b> <b>frequency</b> <b>image</b> to extract subsurface information. 1 Introduction One of the most severe limitations of GPR detection of buried targets is the masking of these weak target returns by a strong surface clutter element. In this research effort we investigated methods for fusing high frequency radar data (strong clutter component, low penetration) and low frequency radar data (deeper subsurface penetration, but also strong clutter component) {{in order to reduce the}} effect of clutter. Since the clutter component is common to both sets of radar data, we focussed our efforts on subtracting this common component from the <b>low</b> <b>frequency</b> <b>image</b> to obtain the subsurface image. In the approach presented in this report we first a [...] ...|$|E
40|$|This paper proposes an {{interactive}} approach using joint image-noise filtering for achieving high quality image-noise separation. The {{core of the}} system is our novel joint image-noise filter which operates in both image and noise domain, and can effectively separate noise from both high and <b>low</b> <b>frequency</b> <b>image</b> structures. A novel user interface is introduced, which allows the user to interact with both the image and the noise layer, and apply the filter adaptively and locally to achieve optimal results. A comprehensive and quantitative evaluation shows that our interactive system can significantly improve the initial image-noise separation results. Our system can also be deployed in various noise-consistent image editing tasks, where preserving the noise characteristics inherent in the input image is a desired feature...|$|E
2500|$|... {{when the}} image was emitted. A similar {{calculation}} reveals that his twin was aging at the same reduced rate of εfrest in all <b>low</b> <b>frequency</b> <b>images.</b>|$|R
40|$|This paper {{outlines}} {{some new}} observational and data processing techniques for enhancing the dynamic range of <b>low</b> <b>frequency</b> <b>images</b> obtained with the Giant Metrewave Radio Telescope. We illustrate new software tools developed to facilitate visibility editing and calibration {{as well as}} other preprocessing required to enhance the dynamic range of images from a planned survey. Comment: 4 pages, 3 figures, Published in the Proceedings of The <b>Low</b> <b>Frequency</b> Radio Universe, an Astronomical Society of the Pacific Conference Serie...|$|R
40|$|Restricted Access. An open-access {{version is}} {{available}} at arXiv. org (one of the alternative locations) This paper outlines some new observational and data processing techniques for enhancing the dynamic range of <b>low</b> <b>frequency</b> <b>images</b> obtained with the Giant Metrewave Radio Telescope. We illustrate new software tools developed to facilitate visibility editing and calibration {{as well as other}} preprocessing required to enhance the dynamic range of images from a planned survey...|$|R
40|$|Time {{variations}} of Doppler shifts of the Ca+ 8542 Å emission in quiescent solar prominences have been measured. A {{new type of}} limb guider assures a highly constant distance of the spectrograph slit from the solar limb and furthermore removes <b>low</b> <b>frequency</b> <b>image</b> motion in the direction perpendicular to the slit. Abstract. Remaining image motion along the slit is usually removed by a correlation of subsequent spectra. This procedure, however, cannot be applied globally to the whole spatial height in the spectra if individual structures exhibit lateral motions along the slit or even decay or arise during the observation. We therefore correlate defined individual emission maxima from successive spectra. The finally obtained power spectra show oscillations {{with a variety of}} periods at restricted locations. The data favour theknown general presence of periods near 20 and 60 min, howeverthey give only slight indication for typical periods near 3 and 5 min...|$|E
40|$|Abstract. Time {{variations}} of Doppler shifts of the Ca + 8542 ˚A emission in quiescent solar prominences have been measured. A {{new type of}} ’limb guider ’ assures a highly constant distance of the spectrograph slit from the solar limb and furthermore removes <b>low</b> <b>frequency</b> <b>image</b> motion in the direction perpendicular to the slit. Remaining image motion along the slit is usually removed by a correlation of subsequent spectra. This procedure, however, cannot be applied globally to the whole spatial height in the spectra if individual structures exhibit lateral motions along the slit or even decay or arise during the observation. We therefore correlate defined individual emission maxima from successive spectra. The finally obtained power spectra show oscillations {{with a variety of}} periods at restricted locations. The data favour the known general presence of periods near 20 and 60 min, however they give only slight indication for ‘typical ’ periods near 3 and 5 min. Key words: Sun: prominences; oscillations 1...|$|E
40|$|Figure 1 : Given {{an input}} noisy image (a) and an initial {{denoising}} result (b) {{consisting of a}} latent image layer (top) and a noise layer (bottom) (this example is produced by Noiseware [Imagenomic Inc. 2008]), our system provides the user {{with a set of}} easy interactive control to achieve high quality image-noise separation shown in (c). The close-up comparisons show that our method can effectively restore from (d) high-frequency image structures, as shown in (e) where a sharper latent image is obtained. This paper proposes an interactive approach using joint imagenoise filtering for achieving high quality image-noise separation. The core of the system is our novel joint image-noise filter which operates in both image and noise domain, and can effectively separate noise from both high and <b>low</b> <b>frequency</b> <b>image</b> structures. A novel user interface is introduced, which allows the user to interact with both the image and the noise layer, and apply the filter adaptively and locally to achieve optimal results. A comprehensive and quantitative evaluation shows that our interactive system can significantly improve the initial image-noise separation results. Our system can also be deployed in various noise-consistent image editing tasks, where preserving the noise characteristics inherent in the input image is a desired feature. ...|$|E
40|$|In {{this work}} {{we try to}} obtain {{information}} about illumination changes by exploring only the <b>low</b> <b>frequencies</b> in <b>images.</b> Using this information we can code these illumination changes with a few number of coefficients. The results obtained give us an efficient coding algorithm when applied to image sequences...|$|R
40|$|Radio {{observations}} {{provide a}} unique view of black {{holes in the}} Universe. This thesis presents <b>low</b> <b>frequency</b> radio <b>images</b> and uses the radio sources in those images to study the evolution of black holes and galaxies through {{the age of the}} Universe. Promotor: H. J. A. Rottgering, Co-Promotor: R. J. van WeerenWith Summary in Dutc...|$|R
40|$|Modern radio {{interferometer}} arrays {{are powerful}} tools for obtaining high resolution, <b>low</b> <b>frequency</b> <b>images</b> {{of objects in}} deep space. An inverse Fourier transform of a model sky-intensity map will produce the corresponding Point Source Visibilities: the raw output of an interferometer. Simulated visibilities {{can be used to}} test models of factors affecting the accuracy of observed data, such as radio frequency interference. We describe a GPU/CUDA implementation of the Point Source Visibility calculation module within theMeqTrees software suite. For a large numbers of sources, we achieve an 187 speed-up over the existing CPU module, with the parallel component running up to 1207 faster. With modifications to the MeqTrees memory management system to incorporate GPU memory operations, a speed-up of 247 is achievable...|$|R
40|$|It {{has been}} known for nearly three decades that high {{redshift}} radio galaxies exhibit steep radio spectra, and hence ultra-steep spectrum radio sources provide candidates for high-redshift radio galaxies. Nearly all radio galaxies with z > 3 have been found using this redshift-spectral index correlation. We have started a programme with GMRT to exploit this correlation at flux density levels about 10 to 100 times deeper than the known high-redshift radio galaxies which were identified primarily using the already available radio catalogues. In our programme, we have obtained deep, high resolution radio observations at 150 MHz with GMRT for several 'deep' fields which are well studied at higher radio frequencies and in other bands of the electromagnetic spectrum, with an aim to detect candidate high redshift radio galaxies. In this paper we present results from the deep 150 MHz observations of LBDS-Lynx field, which has been already imaged at 327, 610 and 1412 MHz with the WSRT and at 1400 and 4860 MHz with the VLA. The 150 MHz image made with GMRT has a rms noise of ~ 0. 7 mJy/beam and a resolution of ~ 19 " X 15 ". It is the deepest <b>low</b> <b>frequency</b> <b>image</b> of the LBDS-Lynx field. The source catalog of this field at 150 MHz has about 765 sources down to ~ 20 % of the primary beam response, covering an area of about 15 degree$^ 2 $. Spectral index was estimated by cross correlating each source detected at 150 MHz with the available observations at 327, 610, 1400 and 4860 MHz and also using available radio surveys such as WENSS at 327 MHz and NVSS and FIRST at 1400 MHz. We find about 150 radio sources with spectra steeper than 1. About two-third of these are not detected in SDSS, hence are strong candidate high-redshift radio galaxies, which need to be further explored with deep infra-red imaging and spectroscopy to estimate the redshift. Comment: Accepted for publication in MNRAS, 24 pages (including 12 pages online material), 9 Figures, 5 Table...|$|E
40|$|In {{the last}} 5 - 10 years, wide-field imaging {{capabilities}} and effective mosaicing algorithms have made possible {{a variety of}} ambitious interferometric surveys of the Galaxy, resulting in images of unprecedented sensitivity and resolution. Here I discuss some of the highlights from these new surveys. Amongst the new results are the identification of many new supernova remnants in confused regions, spectacular <b>low</b> <b>frequency</b> <b>images</b> of the inner Galaxy with the VLA, and some remarkable {{new insights into the}} structure of the Galactic magnetic field from linear polarization. Comment: 7 pages, 3 embedded EPS figures, 1 JPG figure, uses newpasp. sty. To appear in "Milky Way Surveys: The Structure and Evolutoin of Our Galaxy", eds Clemens et al, ASP, in pres...|$|R
2500|$|The twin on {{the ship}} sees <b>low</b> <b>frequency</b> (red) <b>images</b> for 3 years. During that time, he would see the Earth twin in the image grow older by [...] He then sees high <b>frequency</b> (blue) <b>images</b> during the back trip of 3years. During that time, he would see the Earth twin in the image grow older by [...] When the journey is finished, {{the image of the}} Earth twin has aged by ...|$|R
40|$|Presented at the 21 st {{meeting of}} the Astronomical Society of India, Pune, 2002. Three Galactic HII regions, viz., S 201, S 206, and S 209 have been <b>imaged</b> at three <b>frequencies,</b> viz., 232, 327, and 610 MHz using the GMRT. The resolutions of these images are {{typically}} 15 " at 232, 10 " at 327, and 6 " at 610 MHz. These are the highest resolution <b>low</b> <b>frequency</b> <b>images</b> of these HII regions. We found that all three HII regions have core [...] envelope morphologies. We use the high resolution afforded by the data to estimate the electron temperatures of the compact cores of these HII regions. These estimates of the electron temperatures are consistent {{with an increase in}} the temperature with Galacto-centric distance; an effect attributed to a decrease in the heavy elements abundances at large Galacto-centric distances...|$|R
5000|$|Average {{the colors}} To get the <b>lowest</b> <b>frequencies</b> in the <b>image,</b> take only a smaller {{part of the}} already reduced image. For example, if the DCT (Discrete Cosine Transform, a Fourier-related transform) is 32x32, just keep the top-left 8x8.|$|R
5000|$|The twin on {{the ship}} sees <b>low</b> <b>frequency</b> (red) <b>images</b> for 3 years. During that time, he would see the Earth twin in the image grow older by 3/3 [...] 1 years. He then sees high <b>frequency</b> (blue) <b>images</b> during the back trip of 3 years. During that time, he would see the Earth twin in the image grow older by 3 × 3 [...] 9 years. When the journey is finished, {{the image of the}} Earth twin has aged by 1 + 9 [...] 10 years.|$|R
40|$|Three Galactic HII regions, viz., S 201, S 206, and S 209 {{have been}} <b>imaged</b> at three <b>frequencies,</b> viz., 232, 327, and 610 MHz using the GMRT. The resolutions {{of these images}} are {{typically}} 15 " at 232, 10 " at 327, and 6 " at 610 MHz. These are the highest resolution <b>low</b> <b>frequency</b> <b>images</b> of these HII regions. We found that all three HII regions have core [...] envelope morphologies. We use the high resolution afforded by the data to estimate the electron temperatures of the compact cores of these HII regions. These estimates of the electron temperatures are consistent {{with an increase in}} the temperature with Galacto-centric distance; an effect attributed to a decrease in the heavy elements abundances at large Galacto-centric distances. Comment: 2 pages, 2 figures, Poster presented in XXI meeting of the Astronomical society of India (ASI), submitted to BASI, LaTeX uses basi. st...|$|R
40|$|AbstractAn novel edge {{detection}} approach is proposed. Firstly, the nonsubsampled contourlet transform {{is used to}} decompose the original <b>image</b> into <b>low</b> <b>frequency</b> approximation <b>image</b> and the high frequency subbands. Then, because of nonsubsampled contourlet transform shift-invariance, the original image corresponding gradient magnitude is redefined in every scale. Finally, different scales gradient is synthesized into the image dege. The experimental results of {{edge detection}} for several test images are provided to demonstrate the approach...|$|R
40|$|In {{the last}} 5 – 10 years, wide-field imaging {{capabilities}} and effective mosaicing algorithms have made possible {{a variety of}} ambitious interferometric surveys of the Galaxy, resulting in images of unprecedented sensitivity and resolution. Here I discuss some of the highlights from these new surveys. Amongst the new results are the identification of many new supernova remnants in confused regions, spectacular <b>low</b> <b>frequency</b> <b>images</b> of the inner Galaxy with the VLA, and some remarkable {{new insights into the}} structure of the Galactic magnetic field from linear polarization. 1. Historical Overview In the 1930 s and 1940 s, the pioneering efforts of Jansky and Reber demonstrated that the disk of the Milky Way was a strong source of radio emission. In the 1950 s, a theoretical framework was developed which argued that this emission was due to the synchrotron process — this was soon confirmed when it was demonstrated that this emission was linearly polarized. Over the nex...|$|R
40|$|As of February 2012, {{approximately}} 46 % of American adults own a smartphone. The graphics {{quality of}} these devices gets better each year. However, they still have many more limitations in graphics processing and storage space than desktop computers. This means that applications on these devices should focus on optimizing their file sizes and graphics quality {{in order to maximize}} the number of devices that can run and store them. Unfortunately, there is no defined metric for graphics resolution on smartphones. This thesis explores what users believe to be the minimum acceptable graphics quality in smartphone games and graphics applications. By using a testing program we designed in OpenGL, we were able to find at what point in an image’s degradation users found it graphically unappealing and found the app unacceptable. Participants gauged four images that degraded over time. For our two high <b>frequency</b> <b>images,</b> participants found the minimum acceptable graphics quality to occur at 43 pixels per inch (ppi), while in <b>low</b> <b>frequency</b> <b>images</b> they found minimum acceptable graphics quality to occur at around 31 ppi, with the average minimum being 37 ppi...|$|R
40|$|Corner {{detection}} is {{a fundamental}} step in image processing, and it takes {{an important role in}} target tracking, image stitching and three-dimension reconstruction. Harris algorithm is widely used in corner detection for simple calculation and its detection result is not affected by image rotation and light intensity changes. Harris algorithm uses integral differential mask to extract the image gradient, and the edges information remains in the <b>low</b> <b>frequency</b> part of <b>images.</b> When dealing with images with a large number of edge information, integral differential weakens the <b>low</b> <b>frequency</b> part of <b>images</b> obviously, thus the detection result is not really good. Besides, Harris algorithm does not have the property of scale-invariant. For these reasons, fractional differential and multiple scale-space method are put forward in this article to improve Harris algorithm. Experiments show that the detection result of improved algorithm is better than original Harris algorithm in dealing with images of much detailed information...|$|R
40|$|Abstract. Radio {{emission}} from density plasma can {{be detected}} at <b>low</b> radio <b>frequencies.</b> An <b>image</b> of such plasma clouds of the entire inner interplanetary space is always a wanted input for space weather forecast and ICME propagation studies. To take such an image within the ecliptic plane may not fully explore what is happening around the Sun {{not only because of}} the blockage of the Sun, also because most of the ICMEs are propagating in the low-latitude of the Sun, near the ecliptic plane. It is then proposed to launch a solar polar orbit radio telescope to acquire high density plasma cloud images from the entire inner interplanetary space. <b>Low</b> radio <b>frequency</b> <b>images</b> require a large antenna aperture in space. It is, therefore, proposed to use the existing passive synthetic aperture radiometer technology to reduce mass and complicity of the deployment system of the big antenna. In order to reduce the mass of the antenna by using minimum number of elements, a zero redundant antenna element design can be used with a rotating time-shared sampling system. A preliminary assessment study shows the mission is feasible...|$|R
50|$|The Laplacian pyramid (LP) {{decomposition}} only produce one bandpass {{image in}} a multidimensional signal processing, that can avoid frequency scrambling. And directional filter bank (DFB) is only fit for high frequency since it will leak the <b>low</b> <b>frequency</b> of signals in its directional subbands. This {{is the reason}} to combine DFB with LP, which is multiscale decomposition and remove the <b>low</b> <b>frequency.</b> Therefore, <b>image</b> signals pass through LP subbands to get bandpass signals and pass those signals through DFB to capture the directional information of image. This double filter bank structure of combination of LP and DFB is also called as pyramid directional filter bank (PDFB), and this transform is approximate the original image by using basic contour, so it is also called discrete contourlet transform.|$|R
40|$|We {{consider}} the frequency dependence of seismic reflections from a thin (compared {{to the dominant}} wavelength), fluid saturated reservoir for the cases of oil and water saturation. Reflections from a thin, water or oil-saturated layer have increased amplitude and delayed travel time at <b>low</b> <b>frequencies</b> if compared with reflections from a gas-saturated layer. This effect was observed for both ultrasonic lab data and seismic field data. One set of field data revealed high correlation of <b>low</b> <b>frequency</b> processed <b>image</b> for two different production horizons represented by fractured shale and sandstone. Another set was processed {{for the purpose of}} contouring of oil/water contact, and reveal very good correlation with available well data. The frequency dependent amplitude and phase reflection properties can be used for detecting and monitoring thin liquid saturated layers...|$|R
3000|$|... 2 {{into four}} {{sub-band}}s [...] LL, LH, HL [...] and HH, where LL sub-band represents the <b>low</b> <b>frequency</b> of the <b>image</b> and approximation coefficients of DWT, and [...] LH, HL [...] and HH indicate the high <b>frequency</b> of the <b>image</b> and {{are known as}} the horizontal, vertical and diagonal coefficients respectively. These four sub-bands are approximation, horizontal details, vertical details and diagonal details of the image. One of the next sub-bands can be further processed to obtain the next scale of wavelet coefficients until some final scale is reached.|$|R
40|$|Abstract. This paper {{based on}} the {{peculiarity}} of wavelet transform that its transform only in vacuum region and <b>frequency</b> region, decompose <b>image</b> use the theory of wavelet, obtain a series sub-image of different resolution ratio. The value of high-resolution ratio sub-image is all verge on 0, the phenomenon is more obviously in high frequency, so that, the mainly proportion is <b>low</b> <b>frequency</b> to a <b>image.</b> Use wavelet decomposition {{get rid of the}} high <b>frequency,</b> only reservation <b>low</b> <b>frequency,</b> to realize the aim of condensation image. Through the simulation of contradistinctive image of cerebra framework remotion between three-dimensional ultrasonic imaging in course of OPS and MIR preceding OPS validated the feasibility by Matlab...|$|R
40|$|This paper {{proposes a}} robust image hashing method which is robust against common image {{processing}} attacks and geometric distortion attacks. In order to resist against geometric attacks, the log-polar mapping (LPM) and contourlet transform are employed {{to obtain the}} <b>low</b> <b>frequency</b> sub-band <b>image.</b> Then the sub-band image is divided into some non-overlapping blocks, and <b>low</b> and middle <b>frequency</b> coefficients are selected from each block after discrete cosine transform. The singular value decomposition (SVD) is applied in each block to obtain the first digit of the maximum singular value. Finally, the features are scrambled and quantized as the safe hash bits. Experimental {{results show that the}} algorithm is not only resistant against common image processing attacks and geometric distortion attacks, but also discriminative to content changes...|$|R
40|$|Abstract—In this paper, {{we present}} an {{analytical}} {{analysis of the}} representation of images as the magnitudes of their transform with the discrete wavelets. Such a representation plays {{as a model for}} complex cells in the early stage of visual processing and of high technical usefulness for image understanding, because it makes the representation insensitive to small local shifts. We found that if the signals are band limited and of zero mean, then reconstruction from the magnitudes is unique up to the sign for almost all signals. We also present an iterative reconstruction algorithm which yields very good reconstruction up to the sign minor numerical errors in the very <b>low</b> <b>frequencies.</b> Keywords—Wavelets, <b>Image</b> processing signal processing, Image reconstruction...|$|R
40|$|Dynamical images contain useful {{information}} {{of how the}} objects behave in time and space. When the system is in biological fluids, {{the motion of the}} object is much over-damped; the relaxation time is the characteristics in a diffusive time scale. We have found dynamical states of melting and forming of small nematic domains (10 — 30 μm) that are exhibited in the suspensions of fd-viruses under applied AC electric field amplitude at <b>low</b> <b>frequency.</b> Dynamic <b>image</b> correlation function is used for extracting the mes- oscopic relaxation times of the dynamical states, which can be employed as an application to other dynamic imaging process of biologically relevant soft condensed matter and biomedical systems...|$|R
40|$|This paper {{presents}} an approach for identifying recaptured image based on DCT coefficients. The <b>low</b> <b>frequency</b> of an <b>image</b> mainly reflect such information as texture and profile details. The difference between real live face images and recaptured {{images can be}} described by the <b>low</b> <b>frequency</b> of DCT coefficients. Characterized by {{the features of the}} simple and low complexity, DCT Transformation can be performed on common consumer mobile devices quickly. A large number of experiments show that using DCT coefficient as the feature vectors, the SVM classifier for training and test, the proposed method can efficiently classify the real live faces and recaptured photos...|$|R
40|$|Abstract. Image fusion can be {{effectively}} utilized to obtain image redundant information from sensors, hereby improving the {{accuracy and reliability}} of information. Based on multi-resolution decomposition of the traditional image fusion method is vulnerable to high frequency noise, fusion is often ineffective. An improved image fusion algorithm has been studied based on the wavelet multi-resolution decomposition. The principle of the algorithm is regional energy maximum for <b>low</b> <b>frequency</b> decomposition <b>image,</b> and the bivariate statistical model for high frequency part. Experimental {{results show that the}} bivariate statistical model for the high frequency band is robust to noise based on the joint probability of wavelet coefficient in the conditions of Daubechies wavelet basis function with decomposing level 5 multi-resolution decomposition. Simultaneously, the regional energy maximum for <b>low</b> <b>frequency</b> band can be effective on the high frequency band based on the bivariate statistical model. Fusion image have a larger contrast, the preferred details and the higher gray level resolution...|$|R
40|$|We {{describe}} a simple terahertz (THz) time domain spectrometer with a bandwidth extending up to 7. 5 THz. We show that {{by keeping the}} generation and detection crystals {{close to each other}} a high signal-to-noise ratio (SNR) can be achieved without using lock-in detection and dry nitrogen flushing. The observed spectra show very good agreement with the spectra calculated based on a simple model which includes phase matching and absorption in the generation and detection crystals. Using this set-up we have measured the absorption lines in D-tartaric acid from 0. 5 THz up to 7 THz. We show that the high frequency region > 3 THz is the better choice to measure small changes in the water content of a hygroscopic sample compared to the <b>low</b> <b>frequency</b> region. <b>Imaging</b> Science and TechnologyApplied Science...|$|R
40|$|In {{order to}} improve {{algorithm}} efficiency and performance, a technique for image fusion based on the Non-subsampled Contourlet Transform (NSCT) domain and an Accelerated Non-negative Matrix Factorization (ANMF) -based algorithm is proposed in this paper. Firstly, the registered source images are decomposed in multi-scale and multi-direction using the NSCT method. Then, the ANMF algorithm is executed on low-frequency sub-images to get the low-pass coefficients. The <b>low</b> <b>frequency</b> fused <b>image</b> can be generated faster in that the update rules for W and H are optimized and less iterations are needed. In addition, the Neighborhood Homogeneous Measurement (NHM) rule is performed on the high-frequency part to achieve the band-pass coefficients. Finally, the ultimate fused image is obtained by integrating all sub-images with the inverse NSCT. The simulated experiments prove that our method indeed promotes performance when compared to PCA, NSCT-based, NMF-based and weighted NMF-based algorithms...|$|R
40|$|In {{advance of}} the imaging {{capturing}} technology, large amount of similar images are created. Instead of compressing each similar image individually, removing the inter-image redundancy would reduce the storage and transmission time. However, only a few set redundancy methods are proposed {{to deal with the}} problem. In this paper, a new method was derived from a theoretical model by extracting the <b>low</b> <b>frequency</b> in an <b>image</b> set. For the similar images, the values of their <b>low</b> <b>frequency</b> components are very close to that of their neighboring pixel in the spatial domain. In our model, a <b>low</b> <b>frequency</b> template is created and used as a prediction for each image to compute its residue. This model proves the reduction in the entropy and hence the bit rates. Experiments were conducted and proved there were up to 30 % gains over the existing methods...|$|R
