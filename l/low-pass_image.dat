5|39|Public
40|$|We {{present a}} {{hardware-accelerated}} adaptive EWA (elliptical weighted average) volume splatting algorithm. EWA splatting combines a Gaussian reconstruction kernel with a <b>low-pass</b> <b>image</b> filter for high image quality without aliasing artifacts or excessive blurring. We introduce a novel adaptive filtering scheme {{to reduce the}} computational cost of EWA splatting. We show how this algorithm can be efficiently implemented on modern graphics processing units (GPUs). Our implementation includes interactive classification and fast lighting. To accelerate the rendering we store splat geometry and 3 D volume data locally in GPU memory. We present results for several rectilinear volume datasets that demonstrate the high image quality and interactive rendering speed of our method...|$|E
30|$|Laplacian pyramid {{image fusion}} is a {{technique}} in which local operators of many scales but identical shape (as proposed by Burt and Adelson (1983)) are applied to the input images. Pixel-to-pixel correlations are first removed by subtracting a low-pass filtered copy of the image from the image itself. The result is a net data compression since the difference image has low variance and entropy, and the low-pass filtered image may be represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the <b>low-pass</b> <b>image.</b> Iteration of the process at appropriately expanded scales generates a pyramid data structure. The encoding process is equivalent to sampling the image with Laplacian operators of many scales, which tends to enhance salient image features.|$|E
40|$|We {{describe}} a technique for image encoding in which local operators of many scales but identical shape {{serve as the}} basis functions. The representation differs from established techniques in that the code elements are localized in spatial frequency as well as in space. Pixel-to-pixel correlations are first removed by subtracting a lowpass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance and entropy, and the low-pass filtered image may represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the <b>low-pass</b> <b>image.</b> Iteration of the process at appropriately expanded scales generates a pyramid data structure. The encoding process is equivalent to sampling the image wit...|$|E
40|$|Abstract: An image {{classification}} method {{based on the}} lifting wavelet and PCA is proposed. First, several training images chosen from given classes are decomposed into <b>low-pass</b> and high-pass <b>images</b> by using wavelet transform. Applying PCA to all the <b>low-pass</b> <b>images,</b> principal component vectors are computed. The feature vectors of <b>low-pass</b> <b>images</b> are constructed by expanding the <b>low-pass</b> <b>images</b> {{with respect to the}} principal component vectors. The average of the obtained feature vectors in each class is calculated, and lifting parameters are learned so that the lifting feature vectors in each class approach to the average in the same class. Lifting <b>low-pass</b> <b>images</b> for training images are computed exploiting the learned parameters. PCA is applied again to these images for improving the feature vectors of training images. This process is repeated until the classes are separated sufficiently. Classification of a query image is accomplished by comparing its lifting feature vector with the feature vectors for training images. The validity of our method is checked using a benchmark data and object images captured by a robot camera. ...|$|R
5000|$|... #Caption: m-derived {{prototype}} shunt <b>low-pass</b> filter ZiTm <b>image</b> impedance {{for various}} values of m. Values below cut-off frequency only shown for clarity.|$|R
30|$|High-Frequency Injection family, which {{includes}} HPF and HPM, where these two methods inject high-frequency details extracted by subtracting a <b>low-pass</b> filtering PAN <b>image</b> {{from the original}} one.|$|R
40|$|In {{order to}} get an {{efficient}} image representation we introduce a new adaptive Haar wavelet transform, called Tetrolet Transform. Tetrolets are Haar-type wavelets whose supports are tetrominoes which are shapes made by connecting four equal-sized squares. The corresponding fast filter bank algorithm is simple but very effective. In every level of the filter bank algorithm we divide the <b>low-pass</b> <b>image</b> into 4 × 4 blocks. Then in each block we determine a local tetrolet basis which is adapted to the image geometry in this block. An analysis of the adaptivity costs leads to modified versions of our method. Numerical results show the strong efficiency of the tetrolet transform for image approximation. Key words: adpative wavelet transform, directional wavelets, Haar-type wavelets, locally orthonormal wavelet basis, tetromino tiling, image approximation, data compression, sparse representation 2000 MSC: 65 T 60, 42 C 40, 68 U 10, 94 A 08 1...|$|E
40|$|The aim of {{this study}} is to {{evaluate}} the effect of multiscale processing in digital chest radiography on automated detection of lung nodule with a computer-aided diagnosis (CAD) system. The study involved 58 small-nodule patient cases and 58 normal cases. The 58 patient cases included a total of 64 noncalcified lung nodules up to 15  mm in diameter. Each case underwent an examination with a digital radiography system (Digital Diagnost, Philips Medical Systems), and the acquired image was processed by the following three types of multiscale processing (Unique Image Processing Package, Philips Medical Systems) respectively: (1) standard image from the default processing parameter (structure preference, 0. 0), (2) high-pass image with structure preference of 0. 4, (3) <b>low-pass</b> <b>image</b> with structure preference of − 0. 4. The CAD output images were produced with a real-time computer assistance system (IQQA™-Chest, EDDA Technology). Two experienced chest radiologists established the nodule gold standard by consensus reading according to computed tomography results, and analyzed and recorded the detection of lung nodules and false-positive detections of these CAD output images. For the entire cases involved (each case with three types of different processing), a total of 348 observations were evaluated by the receiver operating characteristic (ROC) analysis. The mean area under the ROC curve (Az) value was 0. 700 for the standard images, 0. 587 for the high-pass images, and 0. 783 for the low-pass images. There were statistically significant Az values among these three types of processed images (p[*]<[*] 0. 01). Multiscale processing in digital chest radiography can affect the automated detection of lung nodule by CAD, which is consistent with effects from visual inspection...|$|E
40|$|We {{describe}} {{a new technique}} for image encoding in which Gaussian-like operators {{serve as the basis}} functions. The representation differs from established techniques in that the Gaussian code elements are localized in both space and spatial frequency. Pixel to pixel correlations are first removed by subtracting a low-pass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance, and the <b>low-pass</b> filtered <b>image</b> may be represented at reduced sample density. Further data compression is achieved by quantizing the difference image and repeating the encoding process for the <b>low-pass</b> filtered <b>image.</b> The encoding process is equivalent to sampling the image with Laplacian operators of many scales. Thus the code tends to enhance salient image features. A primary advantage of the present code is that it is well suited for many image analysis tasks as well as for data compression. Fast algorithms are described for [...] ...|$|R
40|$|Method for {{processing}} images of rural uplands produced by airborne multispectral scanner (MSS), semiautomatically classifies types of land cover, and involves selection of wavelength bands, radiometric calibration, correction for effects of scan angle and atmosphere, training, {{and assessment of}} accuracy. Basic version involves classification of each picture element according to spectrum. Augmented with five refinements to increase accuracy: per-field sampling; <b>low-pass</b> filtering; <b>image</b> texture; prior probabilities; and imagery from two dates...|$|R
40|$|Abstract- Chromatic {{adaptation}} transform {{is used to}} many color appearance models. Also, the iCAM 06 model, a highdynamic range (HDR) {{rendering process}} contains chromatic adaptation {{and is based on}} the CIECAM 02 model. The D factor or degree of adaptation in chromatic adaptation of the iCAM 06 model is the function of surround luminance or adapting luminance level, but does not consider visual white point shift according to the variation of luminance level. The iCAM 06 model acquires a white image from the Gaussian <b>low-passed</b> <b>image.</b> So, each pixel has different white value, and when some of colors cover the whole image, de-saturation effect appears around these colors. In addition, the scale factor used to reduce de-saturation effect causes unsuitable change of adaptation degree. Therefore, we propose the new method to find global illuminant information and degree of adaptation in the HDR image rendering process. By comparing the proposed with the conventional method, we confirm that the proposed method has better performance in illuminant estimation and color representation...|$|R
40|$|To {{find the}} {{diagnostic}} spatial frequency information in different painting styles (cubism, impressionism and realism), we have compared sensitivity (d') in distinguishing signal (subject of the painting) from noise with normal, high-pass and <b>low-pass</b> filtered <b>images</b> at long (150 ms) and short (30 ms) exposure. We {{found that for}} cubist-style images, d' increases with high-pass filtering compared with normal and <b>low-pass</b> filtered <b>images,</b> but decreases with low-pass filtering compared with normal images. These results indicate that channels with high spatial resolution provide the diagnostic information to solve the binding problem. Sensitivity for images in impressionist style was instead reduced by both low- and high-pass filtering. This indicates that both high and low spatial frequency channels {{play a role in}} solving the binding problem, suggesting the involvement of large collator units that group the response of small channels tuned to the same orientation. The difference between realism, which shows higher sensitivity for low-frequency filtering at short durations and cubism in which the binding problem is solved by high spatial frequency channels, has a corresponding difference in aesthetic judgment: the probability of judging a painting as 'intriguing' is larger with low-pass filtering than with high-pass filtering in realism, while the opposite is true for cubism. This suggests that the aesthetic experience is available during early processing of an image, and could preferentially influence high-level categorization of the subject of a painting...|$|R
40|$|A basic {{methodology}} for land cover classification using airborne multispectral scanner (MSS) imagery is outlined. This includes waveband selection and radiometric calibration; correction for scan angle and atmosphere; training and classification and accuracy assessment. Refinements to this basic methodology include per-field sampling {{and the addition}} of <b>low-pass</b> filtering, <b>image</b> texture, prior probabilities and two dates of imagery. For a study area in upland England, eight land covers were classified with a mean accuracy of 52. 6 percent using the basic methodology. This was increased to 79. 0 percent by using a suitability refined methodology. Per-field sampling accounted for the largest proportion of this increase...|$|R
40|$|In high dynamic range(HDR) imaging, artifacts, {{generated}} {{on the block}} boundaries, has been a puzzling problem all the time. A novel HDR imaging method is proposed to eliminate the fatal defect in this paper. Firstly, we segmented the <b>low-pass</b> filtered <b>images</b> using the region segmentation method. Secondly, the most informative one in corresponding regions is selected and all the selected regions are mosaiced. Finally, a weighted function is used to eliminating {{the effect of the}} artifacts. The experimental results show that the proposed algorithm can greatly enlarge the dynamic range without losing the details of images, which has a wide application prospect in both civil and military fields...|$|R
40|$|Suppression of ringing {{effect is}} a {{challenging}} problem. It is mainly caused by absence of effective methods of ringing artifact detection. In this paper we introduce a ringing esti-mation method based on scale-space analysis. The estimation shows good results for <b>low-pass</b> filtered test <b>images</b> and in adaptive image deringing. Index Terms — Ringing estimation, total variation, scale space, adaptive deringin...|$|R
30|$|The {{high-frequency}} injection family, {{described in}} Section 3.3, {{can be considered}} the predecessor of the methods based on the ARSIS concept. HFI methods <b>low-pass</b> filter the <b>image</b> using different filters. As we have seen, {{the use of the}} MTF of the sensor as the low-pass filter is preferable since, in our opinion, introducing sensor characteristics into the fusion rule will make the method more realistic.|$|R
40|$|In {{this work}} we propose a {{framework}} for image processing in a visual response space, in which contrast values directly correlate with their visibility in an image. Our framework involves a transformation of an image from luminance space to a pyramid of <b>low-pass</b> contrast <b>images</b> {{and then to the}} visual response space. After modifying response values, the transformation can be reversed to produce the resulting image. To predict the visibility of suprathreshold contrast, we derive a transducer function for the full range of contrast levels that can be found in High Dynamic Range images. We show that a complex contrast compression operation, which preserves textures of small contrast, is reduced to a linear scaling in the proposed visual response space...|$|R
40|$|Two {{experiments}} {{were conducted to}} examine {{the influence of the}} spatial frequency content of natural images on saccadic size and fixation duration. In the first experiment 10 pictures of natural textures were low-pass filtered (0. 04 - 0. 76 cycles/deg) and high-pass filtered (1. 91 - 19. 56 cycles/deg) and presented with the unfiltered originals in random order, each for 10 s, to 18 participants, with the instruction to inspect them in order to find a suitable name. The participants' eye movements were recorded. It was found that <b>low-pass</b> filtered <b>images</b> resulted in larger saccadic amplitudes compared with high-pass filtered images. A second experiment was conducted with natural stimuli selected for different power spectra which supported the results outlined above. In general, low-spatial frequencies elicit larger saccades associated with shorter fixation durations whereas high-spatial frequencies elicit smaller saccades with longer fixation durations. ...|$|R
30|$|In {{filtered}}-based methods, {{an input}} image is first filtered by a low-pass filter {{to smooth the}} structures and suppress the noise in the image [4]. The noise variance is then estimated from {{the difference between the}} noisy image and the filtered image. One fundamental problem of filtered-based methods is that the difference image is assumed to be the noise, but this assumption is not always true in general. This is because the <b>low-pass</b> filtered <b>image</b> is not equivalent to the original noise-free image, particularly when the image is with strong structures and complicated details. To minimize the influence and obtain a realistic basis for noise level estimation, Rank et al. [18] proposed to use the vertical and horizontal information of an image to extract the noise detail and histogram information in the corresponding components. However, it has a relatively higher computation load and many user-defined parameters to be set.|$|R
30|$|The model calculates a {{saliency}} map {{by considering}} intensity and edge orientation {{information from a}} given image. Saliency at a given location is determined primarily by the contrast between this location and its surroundings {{with respect to the}} image features. The image formed on the fovea of the eye is the central object on which a person is focusing his attention resulting in a clear and sharp image. Regions surrounding the central object have a less clearer representation on the retina. To simulate this biological mechanism, an image is represented as a Gaussian pyramid comprising of layers of subsampled and <b>low-pass</b> filtered <b>images.</b> The central representation of the image on the fovea is equivalent to the image at higher spatial scales, and the surrounding regions are obtained from the lower spatial scales. The contrast is thus the difference between the various feature maps at these scales.|$|R
40|$|We use the {{paraxial}} {{geometric optics}} model of image formation to derive {{a set of}} camera focusing techniques. These techniques do not require calibration of cameras but involve {{a search of the}} camera parameter space. The techniques are proved to be theoretically sound under weak assumptions. They include energy maximization of unfiltered, low-pass filtered, high-pass filtered, and band-pass filtered images. It is shown that in the presence of high spatial frequencies, noise, and aliasing, focusing techniques based on band-pass filters perform well. The focusing techniques are implemented on a prototype camera system named SPARCS. The architecture of SPARCS is described briefly. The performance of the different techniques are compared experimentally. All techniques are found to perform well. One of them [...] the energy of <b>low-pass</b> filtered <b>image</b> gradient [...] which has better overall characteristics is recommended for practical applications. 1 Preliminary version to appear in OE/TECHNOLOGY' 9 [...] ...|$|R
40|$|Contrast is an {{important}} factor affecting the image quality. In order to overcome the problems of local band-limited contrast, a novel image contrast assessment method based on the property of HVS is proposed. Firstly, the <b>image</b> by <b>low-pass</b> filter is performed fast wavelet decomposition. Secondly, all levels of band-pass filtered image and its corresponding <b>low-pass</b> filtered <b>image</b> are obtained by processing wavelet coefficients. Thirdly, local band-limited contrast is calculated, and the local band-limited contrast entropy is calculated according to the definition of entropy, Finally, the contrast entropy of image is obtained by averaging the local band-limited contrast entropy weighed using CSF coefficient. The experiment results show that the best contrast image can be accurately identified in the sequence images obtained by adjusting the exposure time and stretching gray respectively, the assessment results accord with human visual characteristics and make up the lack of local band-limited contrast. </p...|$|R
40|$|In this paper, {{a method}} for noise {{reduction}} in image sequences with sparse temporal sampling is proposed. The method combines motion compensation with an adaptive temporal <b>low-pass</b> filter. <b>Image</b> sequences are mostly temporally non-stationary due to sensor motion, the motion of individual objects in the scene and objects which disappear, (re) appear or chang their orientation. The motion component can be compensated for by estimating the optic flow through the sequence. This allows to greatly reduce the nonstationarities. However, not all non-stationarities can {{be accounted for by}} motion. Therefore, after motion compensation an adaptive filter is used to perform the actual noise reduction. Keywords [...] - restoration, noise reduction, motion compensation, image sequence I. Introduction Image sequences are used {{in a wide variety of}} applications: video communications, target detection and tracking, object recognition, medical imaging, etc... These sequences are mostly corrupted by random no [...] ...|$|R
40|$|Abstract The color, {{shape and}} texture {{are the basic}} {{intrinsic}} features of visual scene and important features for scene recognition and visual salient feature. The recognition of four targets of “bird”, “ball”, “butterfly ” and “flower ” under the color image, gray image, edge <b>image</b> and <b>low-pass</b> blurred <b>image</b> was completed in the paper through psychology experiment, and the experimental result showed that the speed to recognize the color image was quickest, {{it was a little}} slower to recognize the gray image with the same accuracy of the color image, the edge image had a great impact on the recognition of certain object, thus increasing the recognition time, the blurred image increased the time to recognize various objects while reduced the recognition accuracy. The cognitive research on the scene image’s visual feature is helpful to reveal the secrets of human information processing and explore the law for the formulation of human visual saliency...|$|R
40|$|In {{this paper}} we present {{prototype}} of cultural heritage virtual reconstruction method by extracting three color pattern projected on object’s surface. With rising accessibility to projecting devices and digital cameras new possibilities have risen. This paper focuses on automatizing active range scanner techniques with assumption to move pattern and {{not any of}} the scene elements including both object and devices. The goal was to acquire detailed point cloud for further reconstruction by determining shape of pattern lines. Results show that {{with the use of}} difference <b>images,</b> <b>low-pass</b> signal filters and line thinning methods a detailed high poly model can be obtained even without refining point cloud...|$|R
40|$|The {{article has}} {{objective}} {{to present the}} achieved results with {{the production of a}} landforms map used in the reclassification process of the geomorphology, pedology and vegetation thematic charts, and a soil use map, in which both are used like intermediaries steps for erosion process susceptibility geotechnical chart production. The study area is located a surrounding of the hydroelectric Corumbá IV´s dam, between the watersheds basins of the Pirapitinga and Sarandi streams, in Luziânia municipal city (Goiás, Brazil). The methodology carried out for landforms map production involved photo interpretation techniques using digital terrain model products like curvature model, hypsometry and slopes terrain and drape Quick-Bird over 3 d surface in an ArcGIS 9. 2. The landforms were digitizing in shapefiles format with polygon area calculation. The soil use map was obtained from Quick-Bird image, and was carried out a methodology that applied the following SPRING 4. 3 algorithms: registration image, principal components analysis, <b>low-pass</b> filtering, <b>image</b> segmentation, thematic classification using Isoseg and raster-vector format polygons conversion. The soil use classes were associated with their respective landforms which allowed a preliminary understanding of erosion process present in the area of study. Pages: 5563 - 557...|$|R
3000|$|In {{order to}} be able to compare the storage costs of our scheme with that of EPWT, we need to review how its {{algorithm}} works. In EPWT, after finding the complete path vector p, a 1 D wavelet transform is applied to the vector of function values along the path. As a result of a one-level decomposition, low-pass and high-pass wavelet coefficients are derived. The down-sampled low-pass part is used to form a <b>low-pass</b> filtered <b>image</b> with the same size as the original image and consisting of pairs of identical data points. The easy path algorithm is applied to the resulting image to find a path through the pairs of data points. The wavelet transform is again applied to the resulting path vector. The same strategy is repeated in further levels up to L decomposition levels, the extent of which depends on the data. After a sufficient number of iterations, a shrinkage procedure is applied to the wavelet coefficients at different decomposition levels. In order to reconstruct the image, one needs the wavelet coefficients, location of the wavelet coefficients (since it is a nonlinear approximation scheme), and the path vectors in each iteration step. According to this algorithm, the length of the path vector at decomposition level ℓ is [...]...|$|R
40|$|It {{is shown}} that an (M× N) -node planar {{resistive}} grid can be decomposed into two sub-grids; one {{made up of}} M N-node horizontal and the other of N M-node vertical linear resistive grids which corresponds to decomposing its nodal conductance matrix (NCM) into the Kronecker sum of the NCMs of horizontal and vertical linear grids. This enables the analytical expressions of the eigenvalues and eigenvectors of the NCMs of the sub-grids {{as well as those}} of the planar resistive grid to be expressed in terms of those of the two linear grids, whose analytical expressions are well known. For a Cellular Neural Network (CNN) Gabor-type filter (GTF) we define generalized nodal conductance matrices (GNCMs) that correspond to the NCMs of the resistive sub-grids, show that each Kronecker decomposition has a counterpart in CNN GTF and prove that each GNCM, its counterpart NCM and the corresponding temporal state matrices are related through unitary diagonal similarity transformations. Consequently, we prove that the eigenvalues of the temporal state matrix of a spatial band-pass CNN GTF are the same as those of its counterpart spatial <b>low-pass</b> CNN <b>image</b> filter, hence their temporal transient behaviors are similar in settling to a forced response. Publisher's Versio...|$|R
40|$|According to the {{rotational}} invariance of Harris corner detectorand {{the robustness}} of Sift descriptor. An improved Harris-Sift corner descriptor was proposed. At first, the algorithm given multi-scale strategy to Harris corner, improved corner counting method and removed redundant {{points at the}} same time, then, the corner was directly applied to <b>low-pass</b> Gaussian filter <b>image.</b> Based on the histogram of Sift feature descriptor, generates a new 128 -dimensional feature vector descriptor by multi-scale Gauss weighted. Through the above, Harris corner detectorand Sift descriptorwas normalizedin the scale layer and gradient features. The experiment results indicated that, the improved corner descriptorcomprised both advantage of Harris corner detection and Sift feature descriptor. The method reduced the computation time and the false match rate, which could be validly applied to the robotstereo vision matching andthree-dimensional reconstruction.      </p...|$|R
40|$|Scanned {{documents}} often contain {{noise that}} arises due to printer, scanner, print quality, {{age of the}} document, etc. Therefore, {{it is necessary to}} filter this noise before we process the image. The commonly used approach is to <b>low-pass</b> filter the <b>image</b> and to use it for later processing. The objective in the design of a filter to reduce noise is that it should remove as much of the noise as possible while retaining the entire signal. cellvalues within the current window, applies a specificset of functions to calculate an output value for thecentral cell, and writes the new value to thecorresponding cell in the output raster[4]. Thisprocedure is commonly referred to as spatial convolution filtering (fig. 1). Keywords-Spatial Convolution filtering, Filter window, Average filter, Weighted average filter, median filter...|$|R
40|$|This paper {{presents}} an optimal subband bit allocation {{based on a}} new rate distortion (R-D) model for multi-view image coding with disparity-compensated wavelet lifting. First, the distortion prediction of the reconstructed multi-view image with lifting scheme is presented. A new rate distortion model combining the exponential and power model is developed. Then, the analyzed prediction error and rate distortion model {{are used in the}} optimal bit allocation framework. The bit allocation framework allocates bit to all subbands with the goal to minimize distortion of the reconstructed multi-view <b>images.</b> <b>Low-pass</b> and high-pass subbands are compressed by SPIHT [4] with optimal bit solution. We verify proposed method with several test multi-view images. The results show that the bit allocation based on the proposed method provides close results to the exhaustive search in both allocated bits and PSNR. It also outperforms the uniform bit allocation over a wide range of target bit rate. Index Terms — Multi-view coding, wavelet lifting, SPIHT, rate-distortion model, bit allocatio...|$|R
40|$|In {{this paper}} {{an image sensor}} with 128 x 128 pixels and analog neural {{preprocessing}} is presented. It contains a two-dimensional neural network with next-neighbour con-nectivity and optical input capable of <b>low-pass</b> filtering of <b>images</b> combined with contrast enhancement, binarisation or segmentation in the spatial domain. The single neuron cell is implemented as a fully differential current-mode circuit. The parameters of the neurons (gain and linearity of the transfer function, self-feedback, coupling strength of photodetector input and next-neighbour output) are adjustable by external bias currents. Varying these param-eters, the behaviour of the network changes from a linear spatial low-pass filter with variable diffusion length to binarisation or segmentation. The neural network circuits can be operated in weak inversion for low power dissipa-tion and/or moderate or strong inversion for a larger sig-nal to pattern-noise ratio. The neuron outputs are read out via differential switched-capacitor column preamplifiers and analog output buffers driving an external AD-con-verter. All clocks for the analog readout circuitry and external video synchronisation are generated on-chip. ...|$|R
40|$|LiDAR {{technology}} provides {{two different}} kinds of data: elevation, obtained by differences in time of the emitted and received laser signal; and intensity, obtained by differences of reflected laser beam according to different material present on the surface. Focusing on {{the increasing use of}} LiDAR technology, this paper reports a research of segmentation applied to LiDAR intensity data. The integration of both LiDAR elevation and intensity data permits their combination to mine information of scanned surface integrating object-based classification. Our research hypothesizes that LiDAR intensity images contain significant information about the objects sensed by the LiDAR sensor, and that segmentation can be conducted to detect semi-homogeneous objects of interest. However within the intensity data there also exists noise and signal eccentricity caused by sensor scanning patterns and receiver’s adjusted gain response. Traditional low-pass filters have been used to minimize this problem, but caused blurred edges of objects of interest, which led to inefficient segmentation processing. Anisotropic diffusion filtering provides smoothing of intra-region areas preferentially over inter-region areas, thereby providing a good prospective tool for removing unwanted noise and preserving the edges of desired objects. This research compares different segmentation parameters over three images: an original LiDAR intensity image, a customized kernel <b>low-pass</b> filtered <b>image</b> and an anisotropic diffused filtered image. Kernel and anisotropic diffusion filtering parameters were adjusted to produce test images resulting in the effective removal of noise and artifacts as determined through visual inspection. Considering roads and buildings as objects of interest, comparisons between objects generated by segmentation and real objects were performed. 1...|$|R
40|$|ARSTRACT {{expanded}} imace obtained fmm the Iayer immediately ahnve gives rhecomspondine: {{layer of}} rhi Laptac~an pyr& The Lnplnrion pyrontid ci?din ~ {{is a useful}} image prormld. Thc expanded images fnrrn a pymid called exexsitt~ tool. !IS rrrnnine time widt o seq~~enrinf murhrnr is pand & Gaussian pyramid. 0 (n 2) H F ~ P n*n ~ P is the si:e ofrhr ori~inn / ima~r. This pnper dfsrrihes a pc~rrwllcl imp~~mrnrarinn of this ~lparithm on SIMD machinex like pymmidc and meshrs. In rhese The Gaussian pymid is thc wqucnce of the rcduccd mnrhinrs. rhr ronr~rnrd dnta ond a~sociat~rl oprralions <b>low-pass</b> liltcrctf <b>image?</b> {gk] = (gn. gl [...] . pH-, J;enenred or @ ollocoted m elernenru ~ processors, ad a nlell-fmm (the original imagc) by a REDUCE funcrron: orfanired scheduling is trsrd to ollou ~ an ~venlv disrrfbur 1. d roatpurarion executed In pamllrl. Wirli a prqerly sizrd pymrnid nufrhin ~ the nmnin ~ rime is reduced to OtH) uh~re H is the pvramid's hrighl. Whtn rhr nturhine is snrnller rhun rhr Lnplurirrn prmniid, fire rmnw rr divided into sqmenrr anci rhr compulurion B carried urlr sqrnen! hv se. cntmr, Hnn,r~ur, o prohl~nr on ~hepesiph~rv whcre H is thc hcigh al LhC pyrmid and w 0 is the of tach seRrnPnr IS ~ncol 4 nt~r~d. TO rrrnedv rhis prd~lem, weighting function. nun rn~rhods are propos~d. The hcsr one allnw a running rimn of fl(r?/m 2 + log nt) nphrrc mLm is fhr sir * of rhc Expanded Gaussian Pvrarnid pvrari~idmi~chinr's Imsr. The expandcd Gaussian pymid is Ihc scqucnce (if the expanded ima~cs {F'~} gcncmtcd fmm I&l hy "EX-PAND hnaic~n...|$|R
40|$|Abstract — In this paper, {{a method}} based on wavelet {{coefficients}} in low-pass bands is {{proposed for the}} image classification with adaptive processing of data structures to organize a large image database. After an image is decomposed by wavelet, its features can be characterized by the distribution of histograms of wavelet coefficients. The coefficients are respectively projected onto x and y directions. For different images, the distribution of histograms of wavelet coefficients in low-pass bands is substantially different. However, the one in high-pass bands is not as different, which makes the performance of classification not reliable. This paper presents a method for image classification based on wavelet coefficients in <b>low-pass</b> bands only. <b>Images</b> are arranged into a tree structure. The nodes can then be represented by the distribution of histograms of these wavelet coefficients. 2940 images derived from seven categories are used for image classification. Based on the wavelet coefficients in low-pass bands, the improvement of classification rate on the training data set is up to 11 %, and the improvement of classification rate on the testing data set reaches 20 %. Experimental results show that our proposed approach for image classification is more effective and reliable. I...|$|R
40|$|We {{present a}} robust FFT-based {{approach}} to scale-invariant image registration. Our method relies on FFT-based correlation twice: {{once in the}} log-polar Fourier domain to estimate the scaling and rotation and once in the spatial domain to recover the residual translation. Previous methods {{based on the same}} principles are not robust. To equip our scheme with robustness and accuracy, we introduce modifications which tailor the method to the nature of images. First, we derive efficient log-polar Fourier representations by replacing image functions with complex gray-level edge maps. We show that this representation both captures the structure of salient image features and circumvents problems related to the <b>low-pass</b> nature of <b>images,</b> interpolation errors, border effects, and aliasing. Second, to recover the unknown parameters, we introduce the normalized gradient correlation. We show that, using image gradients to perform correlation, the errors induced by outliers are mapped to a uniform distribution for which our normalized gradient correlation features robust performance. Exhaustive experimentation with real images showed that, unlike any other Fourier-based correlation techniques, the proposed method was able to estimate translations, arbitrary rotations, and scale factors up to 6...|$|R
