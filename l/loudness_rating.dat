13|42|Public
50|$|ITU-T {{recommendation}} P.79 has {{the frequency}} weighted sensitivity calculations {{in it for}} sending <b>loudness</b> <b>rating</b> (SLR) and receive <b>loudness</b> <b>rating</b> (RLR) for telephony.|$|E
50|$|The sending <b>{{loudness}}</b> <b>rating</b> (SLR) is {{a measure}} of the loudness of the transmit audio sent through the microphone of a communication device (for example, a mobile phone) It compares the Sound intensity of the sound waves into the microphone to the resulting audio signal. It is measured in dBV/Pa.|$|E
40|$|Presented at the 11 th International Conference on Auditory Display (ICAD 2005) Studies of {{loudness}} {{change for}} tones with linearly varying levels using different <b>loudness</b> <b>rating</b> methods, such as direct estimation or indirect estimation {{based on the}} start and end levels, have revealed an asymmetry depending on the direction of change (increasing vs decreasing). The present study examines loudness asymmetry between increasing and decreasing levels for 1 -kHz tones over the range 60 - 80 dB SPL and over four ramp durations (2, 5, 10 and 20 s) using direct global and continuous loudness ratings made by subjects. Three measures extracted from continuous ratings (loudness duration, loudness change, loudness slope), on the one hand, and the global <b>loudness</b> <b>rating,</b> {{on the other hand}} are examined and analyzed separately. Measures extracted from continuous ratings do not reveal any significant perceptual asymmetry between an increasing and a decreasing ramp. However, direct estimation of the global loudness is higher for an increasing ramp than for a decreasing ramp. This result can be explained by a short-term auditory memory effect called the ``recency effect''...|$|E
5000|$|Paralinguistic cues such as <b>loudness,</b> <b>rate,</b> pitch, pitch contour, and to {{some extent}} formant {{frequencies}} of an utterance, contribute to the emotive or attitudinal quality of an utterance. Typically, attitudes are expressed intentionally and emotions without intention, but attempts to fake or to hide emotions are not unusual [...]|$|R
50|$|What is {{considered}} a feminine or a masculine voice varies depending on age, region, and cultural norms. The changes with the greatest effects towards feminization, based on current evidence are fundamental frequency and voice resonance. Other characteristics that have been explored include intonation patterns, <b>loudness,</b> speech <b>rate,</b> speech-sound articulation and duration.|$|R
40|$|Individuals {{accommodate}} their communication behavior {{either by}} increasing similarity with their interlocutors (i. e. convergence) {{or on the}} contrary by increasing their differences (i. e. divergence). Speech accommodation has been observed at both linguistic and non linguistic levels. Several {{studies have been conducted}} on phonetic dimensions such as pitch, speech <b>rate,</b> <b>loudness</b> or dispersions of vocalic targets wit...|$|R
40|$|Studies of {{loudness}} {{change for}} tones with linearly varying levels using different <b>loudness</b> <b>rating</b> methods, such as direct estimation or indirect estimation {{based on the}} start and end levels, have revealed an asymmetry depending on the direction of change (increasing vs decreasing). The present study examines loudness asymmetry between increasing and decreasing levels for 1 -kHz tones over the range 60 - 80 dB SPL and over four ramp durations (2, 5, 10 and 20 s) using direct global and continuous loudness ratings made by subjects. Three measures extracted from continuous ratings (loudness duration, loudness change, loudness slope), on the one hand, and the global <b>loudness</b> <b>rating,</b> {{on the other hand}} are examined and analyzed separately. Measures extracted from continuous ratings do not reveal any significant perceptual asymmetry between an increasing and a decreasing ramp. However, direct estimation of the global loudness is higher for an increasing ramp than for a decreasing ramp. This result can be explained by a short-term auditory memory effect called the "recency effect". 1...|$|E
40|$|Loudness {{change has}} been studied for tones with linearly varying levels using {{different}} <b>loudness</b> <b>rating</b> methods, such as direct estimation or indirect estimation based on the starting and ending levels. The published results reveal an asymmetry depending on the direction of change (increasing vs. decreasing), the range of levels (high vs. low), and on the <b>loudness</b> <b>rating</b> method involved. The present study examines loudness asymmetry between increasing and decreasing levels for 1 -kHz tones over the range 60 - 80 dB SPL and over four ramp durations (2, 5, 10 and 20 s) using two additional loudness ratings: continuous ratings and global ratings. A continuous analogical/categorical (A/C) rating scale was used, which consisted of an analog scale subdivided into seven discrete categories labeled from very, very loud to very, very soft. Two measures are obtained, examined and analyzed separately: indirect and direct loudness measures that correspond to the loudness change extracted from continuous ratings and the overall loudness impression, respectively. Loudness changes do not reveal any significant perceptual asymmetry between an increasing and a decreasing ramp. In addition, results do not reveal any "decruitment" effect, i. e. the loudness of a continuously decreasing tone changes more rapidly {{as a function of}} sound pressure level, which is in agreement with previous results for this range of levels. [ [...] . ...|$|E
40|$|Purpose: Loudness {{is a major}} {{auditory}} {{dimension of}} tinnitus, and is used to diagnose severity, counsel patients or {{as a measure of}} clinical efficacy in audiological research. There is no standard test for tinnitus loudness, but matching and rating methods are popular. This article provides important new knowledge about {{the reliability and validity of}} an audiologist-administered tinnitus loudness matching test and a patient-reported tinnitus <b>loudness</b> <b>rating.</b> Method: Retrospective analysis of loudness data for 91 participants with stable subjective tinnitus enrolled in a randomised controlled trial of a novel drug for tinnitus. There were two baseline assessments (Screening, Day 1) and a post-treatment assessment (Day 28). Results: About 66 - 70...|$|E
40|$|During an {{interaction}} people {{are known to}} mutually adapt. Phonetic adaptation has been studied notably for prosodic parameters such as <b>loudness,</b> speech <b>rate</b> or fundamental frequency. In most of the cases, results are contradictory {{and the effectiveness of}} phonetic convergence during {{an interaction}} remains an open issue. This paper describes an experiment based on a children game known as speech dominoes that enabled us to collect several hundreds of syllables uttered by different speakers in different conditions: alone before any interaction vs. after it, in a mediated interaction vs. in a face-to-face interaction. Speech recognition techniques were then applied to globally characterize a possible phonetic convergence...|$|R
40|$|The present paper {{contains}} some data on acoustic speech variations due to different speaking manners {{found in the}} VeriVox speech database. The database was recorded using special software aimed at getting both voluntary and involuntary speech variations. Some involuntary variations, speech in noise and speech when other tasks interfere, has been studied. Data on speaking <b>rate,</b> <b>loudness,</b> F 0 and formant frequencies are discussed...|$|R
40|$|We proposed[1] {{nonlinear}} operators which decom-pose {{a changing}} energy of sound in wavelet domain into three orthogonal components: i. e., loudness and pitch as coherent changes, and timbre as inco-herent change. We showed {{that they could}} detect the discontinuity of a single sound stream with ex-cellent temporal resolution and sensitivity. In this paper, we extend the coherency principle {{so that it can}} describe and pursue the individual coherency of non-overlapping sound streams in wavelet do-main. It is realized by Parzen's non-parametric esti-mates and Kalman ltering of <b>loudness</b> change <b>rate</b> and pitch shift rate. Using this method, we show some experiments for extraction of the most salient stream from multiple sound streams. 1...|$|R
40|$|In this study, the {{influence}} of an additionally presented optical component on the auditory judgement of loudness was investigated. Particularly, the impact of different colors of trains on the loudness judgement was focused. Two train passings of ICEs served as acoustical stimuli. As optical stimuli there were available {{in addition to the}} alternative 'classical laboratory-situation ' (which means no additional optical component) and the original appearance of the ICE (white with one red stripe) three more colorings (red, green and blue) which were realized by digital image editing. At same acoustic stimulus, the color of an ICE train can influence the <b>loudness</b> <b>rating</b> in such way that red trains may be judged as being louder than green trains...|$|E
40|$|An {{improved}} {{test system}} for acoustical rating of air-movement devices was installed and evaluated at the Riverside Energy Efficiency Laboratory at Texas A&M University where measurements of sound pressure levels {{were carried out}} using an array of six microphones instead of the existing rotating boom- microphone setup. The new array setup did not generate any inherent transient noise peaks, which provided adequate signal-to-noise ratios suitable for low sone fan testing. The reverberation chamber was qualified for broad-band testing in the frequency range 50 Hz to 10 kHz. Important acoustical parameters, namely, reverberation time and natural modes of the chamber, were determined. The {{purpose of this study}} was to identify potential background noise sources by computing the coherence functions between microphones placed outside the chamber and a microphone placed within the chamber. No strong coherence was observed, thus indicating adequate sound attenuation characteristics of the chamber walls. The effect of background noise levels on the <b>loudness</b> <b>rating</b> of fans was evaluated. A low sone fan and a louder fan (loudness greater than one sone) were tested during night time when the background noise is the least and during daytime and with the air conditioners running (high background noise level). While both fan types showed no significant change in loudness when tested during daytime and during the night, accurate ratings were not obtained with the air-conditioners running due to inconsistent spectrum. Finally, it was observed that with the six decibels separation requirement between the fan and background noise spectra for a low sone fan, at very low frequencies (below 63 Hz), despite inadequate fan- background separation, the <b>loudness</b> <b>rating</b> of the fan does not change as the minimum perceived loudness at these frequencies is very high. At very high frequencies (greater than 5 kHz), the fan does not generate any noise and hence the fan and the background noise sound pressure levels are very close to each other...|$|E
40|$|Objective: In {{an earlier}} study (), {{detailed}} noise exposure measurements were obtained through individual dosimetry. In this further {{analysis of the data}} we ask the question “Can the effort required to converse in noise be used to estimate the experienced A-weighted noise level?” Design: The noise levels experienced during specific activities were obtained from the analysis of dosimetry results from personal noise exposure meters worn by study participants. The measured noise levels from particular events were compared to a subjectively judged ‘loudness rating’ reported by the person wearing the dosimeter during the measured event. Study sample: Volunteers (females = 20, males = 22) between 18 and 35 years (average age = 26. 8) willing to wear dosimeters and keep a simple activity log. Results: The relation between the objectively measured and the subjectively judged levels was consistent for the group over a large number of events. Conclusions: The subjective <b>loudness</b> <b>rating</b> index was shown to be a convenient tool that can be utilized for the retrospective estimation of noise levels from individual activities. 4 page(s...|$|E
40|$|Abstract — In this {{research}} paper, an algorithm is developed to produce better contrast enhancement which is inspired from nature and calculates {{the upper and}} lower limit for each sliding window. These upper and lower limits are used to calculate the local mean and global mean. It is based on contrast objective function; this is parabolic logarithmic threshold function. The results show that, the method is able to produce better contrast sensitivity and pleasing visuals as compared to older methods (histogram equalization, adaptive histogram equalization, fusion of pyramid and Gaussian, ant colony optimization method etc). The corpus of image consists of both gray and color images. Other than these other evaluation values like <b>loudness,</b> pulse <b>rate,</b> frequency show that this method provides better contrast ratio...|$|R
40|$|International audienceInterlocutors {{are known}} to {{mutually}} adapt during conversation. Recent studies have questioned the adaptation of phonological representations and kinematics of phonetic variables such as <b>loudness,</b> speech <b>rate</b> or fundamental frequency. Results are often contradictory {{and the effectiveness of}} phonetic convergence during conversation is still an open issue. This paper describes an original experimental paradigm - a game played in primary schools known as verbal dominoes - that enables us to collect several hundreds of syllables uttered by both speakers in different conditions: alone, in ambient speech or in full interaction. Speech recognition techniques are then applied to globally characterize phonetic convergence if any. We hypothesize here that convergence of phonetic representations such as vocalic dispersions is not immediate especially when considering common words of the target language...|$|R
50|$|Emotional prosody is {{characterized}} as an individual's {{tone of voice}} in speech that is conveyed through changes in pitch, <b>loudness,</b> timbre, speech <b>rate,</b> and pauses which is different from linguistic and semantic information. It can be isolated from linguistics and interacts with verbal content (e.g. sarcasm). It is perceived or decoded slightly worse than facial expressions but accuracy varies with emotions. Anger and sadness are perceived most easily, followed by fear and happiness, with disgust being the most poorly perceived.|$|R
40|$|To {{illustrate}} {{for a broad}} public acoustic magnitudes, level-thermometers can be used {{which show}} e. g. on the lower end whispering leaves and on the upper end a jet aircraft. When using instead a loudness-thermometer, the sequence of sounds sometimes can be reversed compared to a level-thermometer. From an engineering point of view, these differences frequently {{can be traced back}} to differences in the spectral distribution. However, also some cognitive effects might play a role, e. g. that musical sounds are preferred in comparison to technical sounds. In order to get a handle on possible cognitive effects, a procedure was used which keeps the loudness-time function the same, but largely obscures the information about the sound source. The loudness of 19 musical, natural, and technical sounds in both original and processed version was scaled by a magnitude estimation procedure. The information about the sound source, i. e. whether or not the sound source could be identified, had little effect on the <b>loudness</b> <b>rating.</b> In line with data from the literature, these results could be interpreted that cognitive effects like the recognition of the sound source might play a minor role in loudness evaluation. However, in some cases, the identification of the sound source may considerably influence the rating of its annoyance. ...|$|E
40|$|Advances {{in hearing}} {{instrument}} technology have permitted {{the development of}} non-linear prescriptive methods to prescribe amplification characteristics for the hearing- impaired individual. The dispenser’s task in selecting the most appropriate prescriptive procedure for the young child is of utmost importance to ensure optimum hearing aid benefit for communication development. It was {{the aim of this}} study to compare and describe the effect of the two most widely used methods, DSL (i/o) and NAL-NL 1, on speech recognition and loudness perception. An exploratory, descriptive research design was selected to realise this goal. Ten participants were selected using a convenient non-probability method of sampling. Articulation index calculations and a closed set speech recognition test were utilised in the evaluation of speech recognition, whereas functional gain results and <b>loudness</b> <b>rating</b> measurements provided an opportunity to describe loudness perception. The obtained results were analysed using the SAS (Statistical Analysis System). The study concluded that, although significant statistical differences existed in loudness perception, no statistical difference was observed in actual speech recognition measures. This effect may contribute to the individual amplification approaches of the two methods, which seem to reflect the uncertainties expressed by researchers as to the contribution of high frequency amplification to speech recognition in young children. Dissertation (M (Communication Pathology)) [...] University of Pretoria, 2006. Speech-Language Pathology and AudiologyUnrestricte...|$|E
40|$|Speech {{understanding}} in cochlear implants (CI) {{is good in}} quiet, but very poor in more adverse listening conditions. One {{of the reasons that}} normal hearing listeners have a better representation of the auditory scene in noisy environment than CI recipients, is the higher firing rate on the auditory nerve at onsets of signals. This is caused by the rapid adaptation effect that is present at the auditory nerve synapse. The better representation of the onsets leads to a better coding of the acoustical landmarks. The rapid adaptation effect is not present in CI stimulation, because the CI bypasses the synapse. An approach to improve speech {{understanding in}} noisy environment is mimicking the rapid adaptation effect of the auditory nerve synapse by emphasizing the onsets of the speech signal. Two CI processing strategies, enhanced envelope continuous interleaved sampling (EECIS) and transient emphasis spectral maxima (TESM), have been suggested before that include the mimicking of the adaptation effect. Both strategies show benefits in quiet, but fail in adverse listening conditions, when the access to acoustical landmarks seems to be most important. In this study, we investigate the influence of onset enhancement by comparing the EECIS, a variation of the TESM that was optimized to maximum gain at onsets, and the continuous interleaved sampling (CIS) as the reference strategy in two manners. The first manner, model based evaluation of CI strategies, compares the strategies by simulating the electrically evoked compound action potential (ECAP) response on the auditory nerve based on a model (collaboration with Laboratory of Experimental Audiology (LEA), Zurich). The second manner, evaluation with CI vocoder simulations, investigates the effect of onset enhancement in noisy environment by conducting subjective listening tests with vocoded speech with normal hearing listeners. A <b>loudness</b> <b>rating</b> experiment was performed to ensure that the influence of the enhanced onsets instead of the use of loudness cues is measured. The effect of the onset enhancement was present in the simulated responses of the ECAP model and differences between the strategies could be simulated. For the subjective listening tests, significant effects were observed for the strategies in comparison to the unprocessed signal under ideal conditions for the extraction of the enhanced signal. A speech reception threshold (SRT) improvement of 2. 5 dB for the EECIS and 1. 5 dB for the TESM strategy was obtained. The results of another series of subjective listening tests show that the EECIS strategy is applicable in noisy environment by introducing a noise reduction step and benefits in speech intelligibility were observed. In the <b>loudness</b> <b>rating</b> experiment, no significant effects between the strategies were obtained. The results of the evaluation based on an ECAP model show the potential benefits of the evaluation of CI strategies using simulations. The subjective listening test results demonstrate the importance of the onsets in speech and their contribution to speech intelligibility in noisy environment. Subjective listening tests have to be done in future to investigate the correlation between the simulated responses and the perception of onsets. status: publishe...|$|E
40|$|The present paper {{examines}} {{the effects of}} saturation on the time domain parameters that can be extracted from recordings of speech. The kinds of saturation {{we are going to}} discuss in the paper include clipping, zeroing and two’s complement whereas the parameters we will take into considerations include root mean square (RMS, as correlated with <b>loudness),</b> zero crossing <b>rate</b> (ZCR), auto correlation (as a tool to extract F 0 from speech samples), voice onset time (VOT) and rise time (RT) ...|$|R
50|$|Vocal AttractivenessJust as {{physical}} attractiveness is a visual cue, vocal attractiveness is an auditory cue {{and can lead}} to differing interviewer evaluations in the interview as well. Vocal attractiveness, defined as an appealing mix of speech <b>rate,</b> <b>loudness,</b> pitch, and variability, {{has been found to be}} favorably related to interview ratings and job performance. In addition, the personality traits of agreeableness and conscientiousness predict performance more strongly for people with more attractive voices compared to those with less attractive voices.|$|R
40|$|In spoken {{dialogue}} analysis, {{the speech}} signal {{is a rich}} source of information. We explore in this paper how low level features of the speech signal, such as pitch, <b>loudness,</b> and speaking <b>rate,</b> can inform a model of student interaction in collaborative learning dialogues. For instance, can we ob-serve the way that two people’s manners of speaking change over time to model something like rapport? By detecting interaction qualities such as rapport, we can better sup-port collaborative interactions, which {{have been shown to be}} highly conducive to learning. For this, we focus on one particular phenomenon of spoken conversation, known as acoustic-prosodic entrainment, where dialogue partners be-come more similar to each other in their pitch, <b>loudness,</b> or speaking <b>rate</b> during the course of a conversation. We examine whether acoustic-prosodic entrainment is present in a novel corpus of collaborative learning dialogues, how people appear to entrain, to what degree, and report on the acoustic-prosodic features which people entrain on the most. We then investigate whether entrainment can facili-tate detection of rapport, a social quality of the interaction. We find that entrainment does correlate to rapport; speak-ers appear to entrain primarily by matching their prosody on a turn-by-turn basis, and pitch is the most significant acoustic-prosodic feature people entrain on when rapport is present...|$|R
40|$|The {{purpose of}} the present study was to {{evaluate}} the relationship between several measures of the acoustic reflex [acoustic reflex threshold (ART), dynamic range of the acoustic reflex growth function, the 50 % point along the acoustic reflex growth function, and the maximum intensity value of the acoustic reflex growth function] and behavioral measurements of loudness [loudness discomfort level (LDL) and the loudness contour (LC) ]. The underlying objective was to determine if any of these measures can be used to predict the LDL. A finding of a strong relationship between these measures could potentially assist in the creation of an objective method to measure LDLs, which may have implications for hearing aid fittings. Prior research in this area has yielded conflicting results. However, very few studies examined measures of loudness growth and the dynamic range of the acoustic reflex. Twenty young adults ranging from 22 - 35 years of age (Mean age = 25. 85, s. d. 3. 07) with normal hearing participated in this study. Participants were required to provide a subjective <b>loudness</b> <b>rating</b> to warbled-tone stimuli in accordance with a categorical loudness scaling procedure adapted from Cox et al. (1997), as well as an LDL rating. Additionally, an ART was obtained from each participant, as defined by a 0. 02 mmho change in admittance. Following identification of the ART, the acoustic reflex growth function was obtained by increasing the stimulus until the termination point. Experimental measures were obtained over two test sessions. Results revealed no significant relationship between measures of the acoustic reflex and loudness. Analysis of test-retest measures revealed moderate to very high positive (0. 70 - 0. 92) correlations for the acoustic reflex and LDL measures over a period of 1 day to 2 weeks. Test-retest performance on the majority of loudness categories on the LC did not reveal stable results. Implications for these findings are that the ART cannot be used to reliably predict the LDL. Additionally, the LC may not be a reliable clinical measurement to assess loudness...|$|E
40|$|In Sweden, about 10 % of {{the adult}} {{population}} experienceshearing problems that cause them difficulties in everydaycommunication, and approximately 60 000 people are providedwith hearing aids each year. Despite the fact that modernhearing aids can facilitate speech communication in a widerange of listening environments, many hearing-aid users aredissatisfied with their hearing aids. It is likely that theclinical methods used for individual fitting of the hearingaids are not optimal. The current study investigates prescriptive methods fornonlinear, wide dynamic range compression (WDRC) hearinginstruments. The goal is to draw general conclusions about thepreferences of hearing aid users. Therefore, the prescriptionsare evaluated using well-established models of loudness andspeech intelligibility. Current methods differed considerably in prescribed gain. Evaluations in a laboratory test, with 20 hearing-impairedlisteners, showed that these differences led to largedifferences in perceived and calculated loudness, but only tominor differences in measured and predicted speech recognitionscores. The difference in loudness was explored in a studywhere 21 first-time hearing-aid users compared twoprescriptions. One method led to normal and the other toless-than-normal overall calculated loudness (according to theloudness model of Moore and Glasberg (1997)). The prescriptionthat led to less-than-normal overall loudness was clearlypreferred in field and in laboratory tests. Preferred overall loudness was then quantified. Hearing-impaired participants with mild to moderate hearingloss preferred considerably less-than-normal overall calculatedloudness in both eld and laboratory tests. There were nosignificant differences between inexperienced and experiencedhearing aid users. Normal-hearing participants, on the otherhand, preferred close-to-normal overall calculated loudness. Inaddition, a potential problem with the loudness model wasencountered: {{despite the fact that the}} hearing-impairedlisteners were provided with less than normal overallcalculated <b>loudness,</b> they <b>rated</b> <b>loudness</b> higher than thenormal-hearing listeners. The results refute the most commonly adopted rationale forprescriptive methods for WDRC hearing aids - that overallloudness should be restored to normal. Hearing-impairedlisteners with mild to moderate hearing loss preferredconsiderably less than normal overall loudness. This should betaken into account when deriving new prescriptive methods, andwhen providing clients with hearing aids. Key words:hearing impairment, hearing aid, nonlinear,WDRC, hearing aid experience, prescription, loudness, loudnessmodel, speech intelligibility, preference...|$|R
40|$|OBJECTIVES: Direct {{challenge}} of cortical serotonergic (5 -hydroxytryptamine, 5 -HT) availability by tryptophan depletion test (TDT) {{was used to}} assess the hypothesized inverse relationship between central 5 -HT function and loudness dependence of auditory evoked potentials (LDAEPs). Gender must be taken into particular account here, since there are gender differences in 5 -HT brain synthesis, with women reacting more strongly to TDT. METHODS: In a double-blind, controlled cross-over study, 16 healthy females were ingested two highly concentrated amino acid mixtures with (+TRP) or without TRP (-TRP). While monitoring TRP levels and mood states, the AEP of different loudness stimuli were recorded, followed by dipole source analysis. RESULTS: Under the -TRP condition, free plasma TRP levels decreased by 81. 10 % (+/- 5. 14). Most of the <b>loudness</b> change <b>rates</b> of the relevant N 1 /P 2 tangential dipole activities were significantly increased under -TRP, but calculated LDAEP did not differ significantly between treatments. LDAEP and states of mood were not correlated. CONCLUSIONS: Despite strong TRP depletion, the results did not reach sufficient evidence that LDAEP is a valid biological marker of central 5 -HT activity in females when using TDT. This agrees with the literature and supports the view that LDAEP indicates predominantly biological vulnerability in predisposed individuals. (c) 2007 John Wiley & Sons, Ltd...|$|R
40|$|Abstract: While the {{beneficial}} effect of levodopa on tradi-tional motor control tasks {{have been well}} documented over the decades, its effect on speech motor control has rarely been objectively examined and the existing literature re-mains inconclusive. To {{examine the effect of}} levodopa on speech in patients with Parkinson’s disease, it was hypoth-esized that levodopa would improve preparatory motor set related activity and alleviate hypophonia. Patients fasted and abstained from levodopa overnight. Motor examination and speech testing was performed the following day, pre-levo-dopa during their “off ” state, then at hourly intervals post-medication to obtain the best “on ” state. All speech stimuli showed a consistent tendency for increased <b>loudness</b> and faster <b>rate</b> during the “on ” state, but this was accompanied by a greater extent of intensity decay. Pitch and articulatio...|$|R
40|$|Prosody can be {{characterized}} as the rhythm and the melody of speech. Prosodic features convey emotions, thoughts and geographic origins of each individual. Spoken language without prosody would be monotonous, without variations in <b>loudness</b> and <b>rate.</b> Children with cochlear implants perceive speech in a different way than children with normal hearing. Consequently the speech produced by a child with cochlear implants may sound different. The {{purpose of this study was}} to examine prosodic skills in Swedish children with cochlear implants and to compare them with the prosodic skills in Swedish children with normal hearing. The purpose of the study was also to examine differences between these two groups and to characterize those differences. Eight children with cochlear implants and eight controls matched to age, sex and regional accent were included in the study. The children’s production and perception of prosody was tested. The results show that there are differences in prosodic skills between the children with cochlear implants and their matched controls at word, phrase and discourse levels. The differences were significant in production but not in perception. Observed differences in the speech of the children with cochlear implants included omission of unstressed syllables and function words, difficulties producing contrast of tonal word accents and pro-longed maintenance of phonological processes. The study contributes to the knowledge about prosodic and linguistic skills in Swedish children with cochlear implants...|$|R
40|$|Conclusions: Provox Vega {{prostheses}} demonstrate good short-term feasibility, {{and their}} optimized airflow-resistance design offers laryngectomy patients indwelling voice prostheses with more choices in outer diameters without sacrificing (too) much in voice quality. Objectives: Technological progress enables improvement of in vitro airflow characteristics of voice prostheses {{and design of}} voice prostheses with smaller outer diameters. This could potentially improve voice quality in users of Provox 2, and avoid diminished voice quality in users of prostheses with smaller outer diameters. Methods: This was a prospective clinical phase I/feasibility study of three newly designed indwelling voice prostheses (Provox Vega 22. 5 (Provox 2 successor), 20, and 17 Fr). Assessments consisted of patients' self-reported voice and speech, perceptual evaluation, acoustic analysis, maximum phonation time, <b>loudness,</b> speech <b>rate,</b> pull-out force and adaptation of the tracheoesophageal (TE) puncture to smaller diameter voice prostheses. Vega 22. 5 was assessed in 15 patients (all Provox ActiValve users, observation period 3 weeks), and 16 patients with Vega 20 / 17 (2 weeks each). Results: No voice prostheses problems were encountered. Half of the patients with Vega 22. 5 preferred that for its better voice quality. Voice and speech were considered equal to Provox 2 for Vega 20, but slightly less for Vega 17. Most TE punctures adapted well to the smaller diameter voice prostheses. <...|$|R
40|$|COMPUTER-CONTROLLED voice {{response}} systems {{can provide an}} important medium of communications from computer to student in computerassisted instruction (CAl) applications. The Institute for Mathematical Studies in the Social Sciences (IMSSS) has, {{over the last several}} years, utilized a linear predictive {{voice response}} system for its CAl demonstration project (see Sanders, Banbassat, & Smith, 1976; and Sanders & Laddaga, 1976). The Miscroprogrammed Intoned Speech Synthesizer (MISS) generates linear prediction encoded (LPC) speech to 48 student terminals (see Makhoul, 1975, or Markel & Gray, 1976, for a description ofthe linear prediction of speech, and Sanders & Levine, 1981, for a description of MISS). LPC encoding separates speech into four component contours: pitch, duration (<b>rate),</b> <b>loudness,</b> and spectrum. It is possible to manipulate these components individually to achieve various prosodic effects. Some students taking IMSSS courses hear phrases that were recorded as a whole phrase, LPC analyzed, compressed, stored, and resynthesized...|$|R
40|$|Prosody is {{the flow}} of speech created by {{controlling}} elements such as pitch, <b>rate,</b> <b>loudness,</b> and stress (Tiffany and Carrell, 1977). Prosody is vital to intelligibility of speech and also communicates meaning. Despite the importance of prosody, however, few tests for the adequacy of prosodic ability in young children have been published (Koike and Asp, 1981 a). To remedy this paucity of tools, Koike and Asp published the Tennessee Test of Rhythm and Intonation Patterns (T-TRIP). The clinical usefulness of the T-TRIP has been limited {{by a lack of}} normative data against which to compare individual children 2 ̆ 7 s performance. The {{purpose of this study was}} to collect normative data on the T-TRIP scores of normal four and six-year-olds. The question this study asked was: What are the means and standard deviations of T-TRIP scores from the samples of four and six-year-olds? A secondary question was: Are differences between the means of the two age groups statistically significant...|$|R
40|$|Language is not {{the only}} form of verbal communication. <b>Loudness,</b> pitch, {{speaking}} <b>rate,</b> and other non-linguistic speech features are crucial aspects of human spoken interaction. In this thesis, we separate these speech features into two categories [...] vocal Activity and vocal Emphasis [...] and propose a framework for classifying high-level social behavior according to those metrics. We present experiments showing that non-linguistic speech analysis alone can account for appreciable portions of social phenomena. We report statistically significant results in measuring the persuasiveness of pitches, the effectiveness of customer service representatives, and the severity of depression. Effect sizes of these studies explain up to 60 % of the sample variances and yield binary decision accuracies nearing 90 %. by William T. Stoltzman. Thesis (M. Eng.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2006. This electronic version was submitted by the student author. The certified thesis is available in the Institute Archives and Special Collections. Includes bibliographical references (p. 67 - 70) ...|$|R
40|$|About 90 {{percent of}} people with Parkinson's disease (PD) {{experience}} decreased functional communication due {{to the presence of}} voice and speech disorders associated with dysarthria that can be characterized by monotony of pitch (or fundamental frequency), reduced <b>loudness,</b> irregular <b>rate</b> of speech, imprecise consonants, and changes in voice quality. Speech-language pathologists (SLPs) work with patients with PD to improve speech intelligibility using various intensive in-clinic speech treatments. SLPs also prescribe home exercises to enhance generalization of speech strategies outside of the treatment room. Even though speech therapies are found to be highly effective in improving vocal loudness and speech quality, patients with PD find it difficult to follow the prescribed exercise regimes outside the clinic and to continue exercises once the treatment is completed. SLPs need techniques to monitor compliance and accuracy of their patients exercises at home and in ecologically valid communication situations. We have designed EchoWear, a smartwatch-based system, to remotely monitor speech and voice exercises as prescribed by SLPs. We conducted a study of 6 individuals; three with PD and three healthy controls. To assess the performance of EchoWear technology compared with high quality audio equipment obtained in a speech laboratory. Our preliminary analysis shows promising outcomes for using EchoWear in speech therapies for people with PD. Keywords: Dysarthria; knowledge-based speech processing; Parkinson's disease; smartwatch; speech therapy; wearable system. Comment: 8 pages, 8 figures, 1 table, 1 equation in Proceedings of the conference on ACM Wireless Health (WH 2015), National Institute of Health, Bethesda, Maryland, US...|$|R
40|$|Today, {{people are}} {{just as likely to}} have a {{business}} meeting remotely as they are face-to-face. Individuals obtain college degrees remotely and sick patients can visit the doctor from home. Especially important in light of this popularity, re-mote settings are posing communication challenges that are not present in face-to-face settings. Visual cues such as facial expressions and body language are either degraded or non-existent. In this paper, we are interested in how remote set-tings affect spoken dialogue when compared to face-to-face settings. We focus on entrainment, a phenomenon of conver-sation where individuals adapt to each other during the in-teraction. Specifically, we investigate acoustic-prosodic en-trainment, where individuals become more similar in their pitch, <b>loudness,</b> or speaking <b>rate.</b> We explore three differ-ent measures of acoustic-prosodic entrainment, comparing re-mote settings to face-to-face settings on a turn-by-turn basis. Our results indicate that the two settings do differ for different forms of entrainment, suggesting that {{the presence or absence of}} visual cues such as facial expressions and body language has an impact on the degree of entrainment. 1...|$|R
40|$|International audienceIndividuals {{accommodate}} their communication behavior {{either by}} increasing similarity with their interlocutors (i. e. convergence) {{or on the}} contrary by increasing their differences (i. e. divergence). Speech accommodation has been observed at both linguistic and non linguistic levels. Several {{studies have been conducted}} on phonetic dimensions such as pitch, speech <b>rate,</b> <b>loudness</b> or dispersions of vocalic targets with various experimental paradigms ranging from close-shadows of prerecorded stimuli to more ecological face-to-face conversations. Multiple objective and subjective characterizations of phonetic convergence have been proposed. This paper discusses limitations of current proposals, notably in terms of top-down strategies that may be used by labelers and listeners when characterizing/perceiving the stimuli. We put forward and evaluate here two novel techniques: objective characterization by speaker recognition techniques and subjective characterization by a novel paradigm named "speaker switching". We will illustrate these techniques with stimuli collected during an original experimental paradigm called verbal dominoes (Lelong and Bailly, 2011), a speech game that can be played by several interlocutors and consisting in chaining rhyming words...|$|R
