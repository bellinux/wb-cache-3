2450|360|Public
5|$|Shen Kuo was {{the first}} to discern {{magnetic}} declination of true north while experimenting with a compass. Shen theorized that geographical climates gradually shifted over time. He created a theory of land formation involving concepts accepted in modern geomorphology. He performed optical experiments with camera obscura just decades after Ibn al-Haytham {{was the first}} to do so. He also improved the designs of astronomical instruments such as the widened astronomical sighting tube, which allowed Shen Kuo to fix the position of the pole star (which had shifted over centuries of time). Shen Kuo was also known for hydraulic clockworks, as he invented a new overflow-tank clepsydra which had more efficient higher-order interpolation instead of <b>linear</b> <b>interpolation</b> in calibrating the measure of time.|$|E
5|$|Being {{the head}} {{official}} for the Bureau of Astronomy, Shen Kuo {{was an avid}} scholar of medieval astronomy, and improved the designs of several astronomical instruments. Shen is credited with making improved designs of the gnomon, armillary sphere, and clepsydra clock. For the clepsydra he designed a new overflow-tank type, and argued for a more efficient higher-order interpolation instead of <b>linear</b> <b>interpolation</b> in calibrating the measure of time. Improving the 5th century model of the astronomical sighting tube, Shen Kuo widened its diameter so that the new calibration could observe the pole star indefinitely. This came about due {{to the position of}} the pole star shifting in position since the time of Zu Geng in the 5th century, hence Shen Kuo diligently observed the course of the pole star for three months, plotting the data of its course and coming to the conclusion that it had shifted slightly over three degrees. Apparently this astronomical finding had an impact upon the intellectual community in China at the time. Even Shen's political rival and contemporary astronomer Su Song featured Shen's corrected position of the pole star (halfway between Tian shu, at −350 degrees, and the current Polaris) in the fourth star map of his celestial atlas.|$|E
25|$|<b>Linear</b> <b>interpolation</b> {{is quick}} and easy, {{but it is}} not very precise. Another {{disadvantage}} is that the interpolant is not differentiable at the point x'k.|$|E
30|$|The avatar used in {{this study}} was a {{representation}} of an Australian performance artist, Stelarc. This 3 D model was originally driven by a set of key frames controlling the visible and partially occluded speech facial articulators such as lips, jaw, and tongue. The full animation was originally created by <b>linear</b> <b>interpolations</b> between those key frames. Unfortunately, <b>linear</b> <b>interpolations</b> do not accurately replicate speech articulator movements. This {{is one of the reasons}} why we developed a new animation method.|$|R
40|$|Here {{the problem}} of a correct {{prediction}} of transient pressures and pulsations in reciprocating compressors is considered, with a particular approach to connecting pipes. The possibility of employing the method of characteristics for gas flow {{is well known for}} ideal flows. I am using for real flows a numerical solution method which, in comparison with other mesh methods, decreases the mathematical errors of smearing because the influence of <b>linear</b> <b>interpolations</b> is much less than these mesh methods. I suggest dividing pipes in three sections: - the sections at the right and left ends have to be very short (only one cell) and mesh methods are used to apply the boundary conditions; - the intermediate section is the longest part (more cells) and uses a modified inverse method which makes <b>linear</b> <b>interpolations</b> to determine Dl, Db and DAA along characteristic lines. <b>Linear</b> <b>interpolations</b> are not used to determine l, b and AA at initial points of characteristic lines...|$|R
30|$|Figure 4 {{shows that}} the plot of error due to <b>linear</b> spline <b>interpolation</b> {{is closer to the}} {{horizontal}} error free line than the plot of error due to linear regression. This reveals that <b>linear</b> spline <b>interpolation</b> estimator for two or more sequentially missing values have smaller error than the linear regression estimator. Therefore, for a such time series data with non-linear trend, <b>linear</b> spline <b>interpolation</b> brings a better estimate for two or more sequentially missing values than linear regression.|$|R
25|$|This is an acausal {{system in}} that the <b>linear</b> <b>interpolation</b> {{function}} moves toward {{the value of the}} next sample before such sample is applied to the hypothetical FOH filter.|$|E
25|$|Polynomial {{interpolation}} is a {{generalization of}} <b>linear</b> <b>interpolation.</b> Note that the linear interpolant is a linear function. We now replace this interpolant with a polynomial of higher degree.|$|E
25|$|A {{recursive}} {{definition for}} the Bézier curve of degree n expresses it as a point-to-point linear combination (<b>linear</b> <b>interpolation)</b> {{of a pair}} of corresponding points in two Bézier curves of degree n1.|$|E
30|$|In general, the {{deformation}} functions {{obtained with}} the formulation {{proposed in the}} present work will result in current configurations that are not characterized by a constant curvature within the single finite elements, even when restricting the shape functions on the Lie algebra to <b>linear</b> <b>interpolations.</b>|$|R
40|$|This paper {{describes}} the novel application of using <b>linear</b> fractal <b>interpolation</b> functions (FIFs) to model video signals represented as single-valued discrete-time sequences to compress video images. The problem is data compression of full-motion broadband television signals. The viability of using FIFs to model video signals {{is shown by}} modelling test static image frames. Compression ratios, SNRs and compression-decompression times are reported. Extension of this work to compress motion video is described. Finally the images are analysed by calculating and plotting the fractal dimensions of each line in the frame against the line for that image. Appendix F Using <b>Linear</b> Fractal <b>Interpolation</b> Functions to Compress Video Images 1. <b>LINEAR</b> FRACTAL <b>INTERPOLATION</b> FUNCTIONS (SELF-AFFINE FRACTAL MODEL) In <b>linear</b> fractal <b>interpolation,</b> a set of points is interpolated with a continuous, single valued function that passes through the given interpolation point...|$|R
5000|$|Multiple {{precision}} {{versions of}} <b>linear</b> algebra, <b>interpolation</b> and optimization algorithms (using MPFR for floating point computations) ...|$|R
25|$|From 1000ft AGL to 2000ft AGL, {{both the}} length scale and {{turbulence}} intensity {{are determined by}} <b>linear</b> <b>interpolation</b> between the low altitude value at 1000ft and the medium/high altitude value at 2000ft.|$|E
25|$|However, {{polynomial}} interpolation {{also has}} some disadvantages. Calculating the interpolating polynomial is computationally expensive (see computational complexity) compared to <b>linear</b> <b>interpolation.</b> Furthermore, polynomial interpolation may exhibit oscillatory artifacts, especially at the end points (see Runge's phenomenon).|$|E
25|$|Like {{polynomial}} interpolation, {{spline interpolation}} incurs a smaller error than <b>linear</b> <b>interpolation</b> and the interpolant is smoother. However, the interpolant {{is easier to}} evaluate than the high-degree polynomials used in polynomial interpolation. It also does not suffer from Runge's phenomenon.|$|E
40|$|Based on A-stable one-leg {{methods and}} <b>linear</b> <b>interpolations,</b> we {{introduce}} four algorithms for solving neutral differential equations with variable delay. A natural question is which algorithm is better. To answer this question, we analyse the error {{behavior of the}} four algorithms and obtain their error bounds under a one-sided Lipschitz condition and some classical Lipschitz conditions. After extensively numerically experimenting, we give a positive conclusion...|$|R
40|$|AbstractThe usual {{practice}} of forcing budget models by <b>linear</b> <b>interpolations</b> of mean data {{does not produce}} a forcing whose mean is the data value required. The usual third-order spline is modified into a fourth-order spline, called mc-spline, {{to cope with this}} issue. The technique provides a smooth and faithful continuous interpolation of the original data that is well suited for its graphical representations or for the forcing of numerical models...|$|R
40|$|In this paper, a {{high-quality}} concatenative synthesis system using the deterministic plus stochastic model of speech is described, {{in which the}} prosodic modifications are performed by means of very simple and efficient operations, as we reported in a previous work [11]. In particular, pitchsynchrony is not necessary, and <b>linear</b> <b>interpolations</b> substitute other types of estimation. The method for the concatenation of units has been improved {{in order to avoid}} waveform and spectral mismatches. 1...|$|R
25|$|One of the {{simplest}} methods is <b>linear</b> <b>interpolation</b> (sometimes known as lerp). Consider the above example of estimating f(2.5). Since 2.5 is midway between 2 and 3, {{it is reasonable to}} take f(2.5) midway between f(2) = 0.9093 and f(3) = 0.1411, which yields 0.5252.|$|E
25|$|Some iterate the <b>linear</b> <b>interpolation</b> (Newton's method) to {{calculate}} the time of collision with a much higher precision {{than the rest of}} the simulation. Collision detection utilizes time coherence to allow even finer time steps without much increasing CPU demand, such as in air traffic control.|$|E
25|$|The {{simplest}} {{interpolation method}} is to locate the nearest data value, and assign the same value. In simple problems, this method {{is unlikely to be}} used, as <b>linear</b> <b>interpolation</b> (see below) is almost as easy, but in higher-dimensional multivariate interpolation, this could be a favourable choice for its speed and simplicity.|$|E
40|$|The usual {{practice}} of forcing budget models by <b>linear</b> <b>interpolations</b> of mean data {{does not produce}} a forcing whose mean is the data value required. The usual third-order spline is modified into a fourth-order spline, called mc-spline, {{to cope with this}} issue. The technique provides a smooth and faithful continuous interpolation of the original data that is well suited for its graphical representations or for the forcing of numerical models. (C) 2002 Elsevier Science Ltd. All rights reserved. Peer reviewe...|$|R
40|$|The paper {{deals with}} {{convergence}} of solutions {{of a class}} of stochastic differential equations driven by infinite-dimensional semimartingales. The infinite-dimensional semimartingales considered in the paper are Hilbert-space valued. The theorems presented generalize the convergence result obtained by Wong and Zakai for stochastic differential equations driven by <b>linear</b> <b>interpolations</b> of a finite-dimensional Brownian motion. In particular, a general form of the correction factor is derived. Examples are given illustrating {{the use of the}} theorems to obtain other kinds of approximation results. Comment: 36 page...|$|R
40|$|The {{goal of this}} {{research}} is to study the performance of meshless approximations and their integration. Two diffuse shape functions, namely the moving least-squares and local maximum-entropy function, and a <b>linear</b> triangular <b>interpolation</b> are compared using Gaussian integration and the stabilized conforming nodal integration scheme. The shape functions and integration schemes are tested on two elastic problems, an elasto-plastic problem and the inf-sup test. The elastic computation shows a somewhat lower accuracy for the <b>linear</b> triangular <b>interpolation</b> than for the two diffuse functions with the same number of nodes. However, the computational effort for this interpolation is considerably lower. The accuracy of the calculations in elasto-plasticity depends to great extend on the used integration scheme. All shape functions, and even the <b>linear</b> triangular <b>interpolation,</b> perform very well with the nodal integration scheme and locking-free behavior is shown in the inf-sup test...|$|R
25|$|The {{field of}} {{numerical}} analysis predates {{the invention of}} modern computers by many centuries. <b>Linear</b> <b>interpolation</b> was already in use more than 2000 years ago. Many great mathematicians of the past were preoccupied by numerical analysis, as is obvious from the names of important algorithms like Newton's method, Lagrange interpolation polynomial, Gaussian elimination, or Euler's method.|$|E
25|$|Generally, {{if we have}} n data points, {{there is}} exactly one {{polynomial}} of degree at most n1 going through all the data points. The interpolation error {{is proportional to the}} distance between the data points to the power n. Furthermore, the interpolant is a polynomial and thus infinitely differentiable. So, we see that polynomial interpolation overcomes most of the problems of <b>linear</b> <b>interpolation.</b>|$|E
25|$|According to <b>linear</b> <b>interpolation</b> and {{extrapolation}} of UNDESA population estimates, the world population has doubled, or will double, {{in the years}} listed in the tables below (with two different starting points). During the 2nd millennium CE, each doubling took roughly half {{as long as the}} previous doubling, fitting the hyperbolic growth model mentioned above. However, after 2024, it is unlikely that there will be another doubling of the global population in the 21st century.|$|E
40|$|Abstract. This article {{presents}} uniform B-spline interpolation, completely con-tained on the {{graphics processing unit}} (GPU). This implies that the CPU {{does not need to}} compute any lookup tables or B-spline basis functions. The cubic interpo-lation can be decomposed into several <b>linear</b> <b>interpolations</b> [Sigg and Hadwiger 05], which are hard-wired on the GPU and therefore very fast. Here it is demonstrated that the cubic B-spline basis function can be evaluated in a short piece of GPU code without any conditional statements. Source code is available online. 1...|$|R
40|$|Three-dimensional medical images reconstructed from {{a series}} of {{two-dimensional}} images produced by computerized tomography, magnetic resonance imaging, etc., present a valuable tool for modem medicine. Usually, the inter-resolution between two cross sections is less than the intraresolution within each cross section. Therefore, interpolations are required to create a 3 D visualization. Many techniques, including voxel-based and patch tiling methods, apply <b>linear</b> <b>interpolations</b> between two cross sections. Although those techniques using <b>linear</b> <b>interpolations</b> are economical in computation, they need much cross-sectional data and are unable to enlarge because of aliasmg. Hence, the techniques that apply two-dimensional nonlinear interpolation functions among cross sections were proposed. In this paper, we introduce the curvature sampling of the contour of a medical object in a CT (computerized tomography) image. Those sampled contour points are the candidates for the control points of Hermite surfaces between each pair of cross sections. Then, a nearest-neighbor mapping of control points between every two cross sections is used for surface formation. The time complexity of our mapping algorithm is O(m + n), where m and II are the numbers of control points of two cross sections. It is much faster than Kehtamavaz and De Figueiredo’s merge method, whose time complexity is O(n’m~). 0 1991 Academic Press, Inc. 1...|$|R
40|$|The {{effect of}} meso-scale {{structures}} on the hydrodynamic behaviors of particle-fluid systems is considered in an Eulerian-Lagrangian model utilizing the detailed particle distribution {{information provided by}} such models. The fluid flow is distributed within each computational cell from pressure balance considerations according to weighted local porosities, rather than by using traditional <b>linear</b> <b>interpolations.</b> The drag on each particle is then calculated with its local porosity and slip velocity, which shows significant difference to traditional methods. Simulations in this model have reproduced multi-scale flow behaviors in better agreement with experimental results, suggesting {{the validity of the}} model. (c) 2007 Elsevier Ltd. All rights reserved. The effect of meso-scale structures on the hydrodynamic behaviors of particle-fluid systems is considered in an Eulerian-Lagrangian model utilizing the detailed particle distribution information provided by such models. The fluid flow is distributed within each computational cell from pressure balance considerations according to weighted local porosities, rather than by using traditional <b>linear</b> <b>interpolations.</b> The drag on each particle is then calculated with its local porosity and slip velocity, which shows significant difference to traditional methods. Simulations in this model have reproduced multi-scale flow behaviors in better agreement with experimental results, suggesting the validity of the model. (c) 2007 Elsevier Ltd. All rights reserved...|$|R
25|$|Physical {{simulators}} {{differ in}} the way they react on a collision. Some use the softness of the material to calculate a force, which will resolve the collision in the following time steps like it is in reality. Due to the low softness of some materials this is very CPU intensive. Some simulators estimate the time of collision by <b>linear</b> <b>interpolation,</b> roll back the simulation, and calculate the collision by the more abstract methods of conservation laws.|$|E
25|$|Polynomial {{interpolation}} can estimate local maxima and minima {{that are}} outside {{the range of the}} samples, unlike <b>linear</b> <b>interpolation.</b> For example, the interpolant above has a local maximum at x ≈ 1.566, f(x) ≈ 1.003 and a local minimum at x ≈ 4.708, f(x) ≈ −1.003. However, these maxima and minima may exceed the theoretical range of the function—for example, a function that is always positive may have an interpolant with negative values, and whose inverse therefore contains false vertical asymptotes.|$|E
25|$|The {{greenhouse}} gas emission reductions are calculated as a percent reduction based on the combined city/highway fuel economy ratings for both the hybrid and non-hybrid model according to the ratings published in EPA's fuel economy guide available online at www.fueleconomy.gov. The score is measured in a scale from 0 to 10, where 10 is the best rating. The scores are assigned in relative terms, then a 10 is assigned to the hybrid with the largest reduction in {{greenhouse gas}} emissions, while a zero is assigned to the hybrid with the smallest reduction. The values assigned to the models are calculated through <b>linear</b> <b>interpolation</b> between the two end points. For purposes of updating the scorecard, if new hybrid models are introduced during the year, the scale has to be re-calculated {{to take account of}} the new arrivals. For the 2011 Scorecard, the Lincoln MKZ Hybrid was rated a 10 while the Volkswagen Touareg Hybrid was rated 0. The Toyota Prius was rated a 9.4.|$|E
30|$|The {{key point}} of {{nonlinear}} filtering {{is to seek}} an effective <b>linear</b> approximation. <b>Interpolation</b> filtering utilizes interpolation polynomial to operate a linear approximation based on Stirling interpolation formula.|$|R
40|$|We {{present a}} novel {{approach}} to morph between two isometric poses of the same non-rigid object given as triangular meshes. We model morphs as <b>linear</b> <b>interpolations</b> in a suitable shape space S. For triangulated 3 D polygons, we prove that interpolating linearly in this shape space corresponds to the most isometric morph in R 3. We then extend this shape space to arbitrary triangulations in 3 D using a heuristic approach that utilizes belief propagation on junction trees and show the practical use of the approach in preliminary experiments. ...|$|R
40|$|In {{this paper}} are {{presented}} programming and simulation of workpiece through CNC Mikron Milling machine, with using {{of the machine}} software as such Heidenhain iTNC 530. Piece was making with Mastercam. In this issue will treating machining process with Milling and applying of Mastercam Software (CAD/CAM Family). Through Mastercam software, designed and drawn after working pieces will set all the movement trajectories of cutting Tools, such as: point to point <b>interpolation,</b> <b>linear</b> <b>interpolations,</b> circular and spline interpolation. Will be clarified the spline interpolation with third degree polynomial, through software to Heidenhain iTNC 530 Machine...|$|R
