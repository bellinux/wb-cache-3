43|64|Public
40|$|Multicollinearity is {{a problem}} that often occurs in {{multiple}} linear regression. The existence of multicollinearity in the independent variables resulted in a regression model obtained is far from accurate. <b>Latent</b> <b>root</b> regression is an alternative in dealing with the presence of multicollinearity in multiple linear regression. In the <b>latent</b> <b>root</b> regression, multicollinearity was overcome by reducing the original variables into new variables through principal component analysis techniques. In this regression the estimation of parameters is modified least squares method. In this study, the data used are eleven groups of simulated data with varying number of independent variables. Based on the VIF value and the value of correlation, <b>latent</b> <b>root</b> regression is capable of handling multicollinearity completely. On the other hand, a regression model that was obtained by <b>latent</b> <b>root</b> regression has   value of 0. 99, which indicates that the independent variables can explain the diversity of the response variables accurately. </p...|$|E
40|$|The {{objective}} {{of this study is}} to examine the potential benefits of using <b>latent</b> <b>root</b> regression techniques to improve the stability of appraisal coefficients (hedonic prices) over time. Another related objective is to more clearly identify the nature and implications of collinearity present in most appraisal models. The results indicate that the majority of the collinearity present in the data is of a predictive nature, hence <b>latent</b> <b>root</b> techniques will likely show little or no improvement over OLS models. Copyright American Real Estate and Urban Economics Association. ...|$|E
30|$|The matrix {{elements}} for solving the energy <b>latent</b> <b>root</b> of the impurity states {{can be found}} from Eqs. 1 and 5. The electronic structures and binding energy in the nano-structure can be calculated from the matrix elements.|$|E
40|$|An {{asymptotic}} expansion for large {{sample size n}} is derived by a partial differential equation method, {{up to and including}} the term of order n- 2, for the 0 F 0 function with two argument matrices which arise in the joint density function of the <b>latent</b> <b>roots</b> of the covariance matrix, when some of the population <b>latent</b> <b>roots</b> are multiple. Then we derive {{asymptotic expansion}}s for the joint and marginal distributions of the sample roots in the case of one multiple root. Asymptotic expansions distribution of <b>latent</b> <b>roots</b> of a covariance matrix hypergeometric functions multiple <b>latent</b> <b>roots</b> partial-differential equations...|$|R
40|$|Reasonably simple {{expressions}} {{are given}} for some hypergeometric functions when {{the size of}} the argument matrix or matrices is two. Applications of these expressions in connection with the distributions of the <b>latent</b> <b>roots</b> of a 2 - 2 Wishart matrix are also given. Hypergeometric functions matrix arguments <b>latent</b> <b>roots</b> Wishart distribution...|$|R
40|$|AbstractAsymptotic {{expansions}} of {{the joint}} distributions of the <b>latent</b> <b>roots</b> of the Wishart matrix and multivariate F matrix are obtained for large degrees of freedom when the population <b>latent</b> <b>roots</b> have arbitrary multiplicity. Asymptotic expansions of the distributions of the latent vectors of the above matrices are also derived when the corresponding population root is simple. The effect of normalizations of the vector is examined...|$|R
40|$|AbstractAn {{algorithm}} is presented for the numerical {{evaluation of the}} null distribution of the largest <b>latent</b> <b>root</b> of a beta matrix, based on a finite series recently given by Khatri [6]. The same method {{can also be used}} for the distribution of the smallest <b>latent</b> <b>root,</b> and it can be easily adapted to find percentage points. The method is only useful if the size of the matrix {{and the size of the}} denominator sample are small, and in this sense it complements some of the large sample approximations. Although the calculation may be fairly lengthy, the algorithm itself is quite short, and a Fortran coding of it will be submitted to the Journal of the Royal Statistical Society, Series C (Applied Statistics) for publication...|$|E
40|$|An {{algorithm}} is presented for the numerical {{evaluation of the}} null distribution of the largest <b>latent</b> <b>root</b> of a beta matrix, based on a finite series recently given by Khatri [6]. The same method {{can also be used}} for the distribution of the smallest <b>latent</b> <b>root,</b> and it can be easily adapted to find percentage points. The method is only useful if the size of the matrix {{and the size of the}} denominator sample are small, and in this sense it complements some of the large sample approximations. Although the calculation may be fairly lengthy, the algorithm itself is quite short, and a Fortran coding of it will be submitted to the Journal of the Royal Statistical Society, Series C (Applied Statistics) for publication. Algorithm Largest root of a beta matrix multivariate null distributions multivariate analysis of variance equality of covariance matrices cannonical correlations...|$|E
40|$|A lower (upper) bound {{is given}} for the {{distribution}} of each dj, j = k + 1, [...] ., p (j = 1, [...] ., s), the jth <b>latent</b> <b>root</b> of AB- 1, where A and B are independent noncentral and central Wishart matrices having Wp(q, [Sigma]; [Omega]) with rank ([Omega]) Distribution of latent roots lower bound Wishart Tintner's model tests for dimensionality canonical analysis...|$|E
40|$|It {{is shown}} that {{differential}} equations {{given by the}} author may be used recursively to construct certain multivariate null distributions in reduced form. These include the distributions of individual <b>latent</b> <b>roots</b> of B = S 1 (S 1 + S 2) - 1, and distributions of Tr B and Tr S 1 S 2 - 1, for small numbers of variates. exact distributions random matrices individual <b>latent</b> <b>roots</b> trace differential equations Laplace transforms...|$|R
40|$|The exact {{determination}} of the <b>latent</b> <b>roots</b> and <b>latent</b> vectors of a linear mapping supposes, {{in most of the}} cases, the outrun of serious calculation difficulties. Consequently, it is preferred their approximate calculation. We exemplify, in the hereby paper, the adjustment of the method of perturbations, used in quantic mechanic and oscillatios theory, for the approximate {{determination of}} the <b>latent</b> <b>roots</b> and <b>latent</b> vectors of matrix A, corresponding to a linear mapping...|$|R
40|$|The maximum entropy {{covariance}} matrix is positive definite {{even when the}} number of variables p exceeds the sample size n. However, the inverse of this matrix can have stability problems when p is close to n, although these problems tend to disappear as p increases beyond n. We analyze such problems using the variance of the <b>latent</b> <b>roots</b> in a particular metric as a condition number. Condition numbers {{covariance matrix}} estimation entropy <b>latent</b> <b>roots</b> ridge matrices...|$|R
40|$|A Bartlett {{adjustment}} factor is obtained for a statistic {{used to test}} the hypothesis that a specified set of m orthonormal vectors spans the same subspace as does the set of the first m principal component vectors. The adjusted and unadjusted statistics are compared via a simulation study. asymptotic expansion Bartlett {{adjustment factor}} <b>latent</b> <b>root</b> latent vector principal component subspace...|$|E
40|$|Percentile {{points of}} the largest <b>latent</b> <b>root</b> of a sample {{covariance}} matrix are given for the cases!p = 2, 3, and 4 when the population covariance matrix is the identity matrix; and also {{the power of the}} largest root test of the hypothesis ~ = I for the case p = 2. 2 1. Percentile Points of the Largest Latent Roo...|$|E
40|$|AbstractA simple {{relationship}} is given between the exact null distribution gm,n(J) of the J-th largest <b>latent</b> <b>root</b> of an m × m Wishart matrix on n degrees of freedom, {{and the distribution}} fm,n(J) of the ratio of this root to the trace of the matrix. Explicit expressions for certain fm,n(J) may thus be obtained from previous results for the corresponding gm,n(J) ...|$|E
40|$|Asymptotic expansions, {{valid for}} large error degrees of freedom, are {{given for the}} multivariate noncentral F {{distribution}} and for the distribution of <b>latent</b> <b>roots</b> in MANOVA and discriminant analysis. The asymptotic results are {{expressed in terms of}} elementary functions which are easy to compute and the results of some numerical work are included. The Bartlett test of the null hypothesis that some of the noncentrality parameters in discriminant analysis are zero is also briefly discussed. MANOVA and discriminant analysis <b>latent</b> <b>roots</b> asymptotic distributions...|$|R
40|$|AbstractAn {{asymptotic}} expansion for large {{sample size n}} is derived by a partial differential equation method, {{up to and including}} the term of order n− 2, for the 0 F 0 function with two argument matrices which arise in the joint density function of the <b>latent</b> <b>roots</b> of the covariance matrix, when some of the population <b>latent</b> <b>roots</b> are multiple. Then we derive {{asymptotic expansion}}s for the joint and marginal distributions of the sample roots in the case of one multiple root...|$|R
40|$|In {{this paper}} we derive {{asymptotic}} expansions for the distributions of some {{functions of the}} <b>latent</b> <b>roots</b> of the matrices in three situations in multivariate normal theory, i. e., (i) principal component analysis, (ii) MANOVA model and (iii) canonical correlation analysis. These expansions are obtained by using a perturbation method. Confidence intervals for {{the functions of the}} corresponding population roots are also obtained. Asymptotic distribution function of <b>latent</b> <b>roots</b> asymptotic expansions principal component analysis MANOVA model canonical correlation analysis perturbation method...|$|R
40|$|Abstract. In {{this paper}} we {{formulated}} and analyzed a predator-prey model with sparssing effect, {{analysis of the}} existing conditions of equilibrium point, and the sufficient condition of the local asymptotical stability of the equilibrium was studied with the method of <b>latent</b> <b>root,</b> and furthermore, by constructing a Liapunov function to get the boundary equilibrium and the positive equilibrium sufficient conditions for the globally asymptotical stability...|$|E
40|$|Abstract. In {{this paper}} we {{formulated}} and analyzed a eco-epidemiological model with {{disease in the}} predator, analysis of the existing conditions of equilibrium point, the sufficient condition of the local asymptotical stability of the equilibrium was studied with the method of <b>latent</b> <b>root,</b> the global asymptotical stability {{of two of the}} boundary equilibriums and the local asymptotical stability of the positive equilibrium is proved by using the Lyapunov function...|$|E
40|$|EnThe Principal Component Analysis onto References Subspaces is {{a multivariate}} method to analyze {{two sets of}} {{quantitative}} variables when between the two sets exists a directional relationship. When the explicative variables are affected by multicollinearity this technique is not recommended. In literature exist many methods to resolve this problem (Ridge Regression, Principal Component Regression, Partial Least Square, <b>Latent</b> <b>Root</b> Regression), this work shows an alternative method based on simple linear regression...|$|E
40|$|Asymptotic {{expansions}} {{are given}} for the density function of the normalized <b>latent</b> <b>roots</b> of S 1 S 2 - 1 for large n under the assumption of [Omega] = O(n), where S 1 and S 2 are independent noncentral and central Wishart matrices having the Wp(b, [Sigma]; [Omega]) and Wp(n, [Sigma]) distributions, respectively. The expansions are obtained by using a perturbation method. Asymptotic expansions are also obtained for the density function of the normalized canonical correlations {{when some of the}} population canonical correlations are zero. Asymptotic expansions density functions <b>latent</b> <b>roots</b> in MANOVA model canonical correlations perturbation method...|$|R
40|$|Designs {{of partial}} diallel crosses {{obtained}} by including parents based on rectangular and cubic association schemes have been presented. In addition, a simplified method of their analysis by {{making use of}} <b>latent</b> <b>roots</b> and idempotent matrices has also been presented. The method has been illustrated {{with the help of}} numerical data. ...|$|R
40|$|Contract No. AF 49 (638) - 213 It is {{well known}} that so f~r the joint {{distribution}} of the <b>latent</b> <b>roots</b> associated with normal multivariate analysis of variance has been considerably more difficult to derive if the effective number of variates is greater than the number of components of the linear hypothesis than if it is the other way around. This report offers both on the nUll and the non null hypothesis a simple method of derivation of the distribution for the former case by throwing it back on the distribution for the latter case, and in this tie-up a pivotal role is played by the distribution of the <b>latent</b> <b>roots</b> connected with the testing of the hypothesis of independence between two sets of variates. Qualified requestors may obtain copies of this report from the ASTI...|$|R
40|$|Factor {{analysis}} {{refers to}} a collection of statistical methods for reducing correlational data into {{a smaller number of}} dimensions or factors. In this study, factor analysis theory was used to determine the main influential factors of road traffic crashes with massive casualties. Twenty variables related to personnel, vehicles, roads, and environment were collected, and the significance of their correlations was tested for validity. A correlation coefficient matrix R was calculated, and its <b>latent</b> <b>root</b> λ was obtained based on the characteristic equation. A number of common factors were determined according to the value of <b>latent</b> <b>root</b> λ. Factor loading was used to express the relationship of each variable to the underlying main influential factors. An index system of accident factors was developed {{based on the results of}} factor loading, and the weight of each factor was calculated to classify the factor influence. The main influential factors of accidents were determined to be fault behavior, driving experience, condition of vehicle safety, purpose of vehicle, road lighting, driver, road surface condition, roadside protection facilities, and road terrain...|$|E
40|$|A simple {{relationship}} is given between the exact null distribution gm,n(J) of the J-th largest <b>latent</b> <b>root</b> of an m - m Wishart matrix on n degrees of freedom, {{and the distribution}} fm,n(J) of the ratio of this root to the trace of the matrix. Explicit expressions for certain fm,n(J) may thus be obtained from previous results for the corresponding gm,n(J). Exact distributions Wishart matrix ratio of root to trace Laplace transforms...|$|E
40|$|Abstract: The Principal Component Analysis onto References Subspaces is {{a multivariate}} method to analyze {{two sets of}} {{quantitative}} variables when between the two sets exists a directional relationship. When the explicative variables are affected by multicollinearity this technique is not recommended. In literature exist many methods to resolve this problem (Ridge Regression, Principal Component Regression, Partial Least Square, <b>Latent</b> <b>Root</b> Regression), this work shows an alternative method based on simple linear regression...|$|E
40|$|The {{purpose of}} this article is to review the {{findings}} of Professor Fujikoshi which are primarily in multivariate analysis. He derived many asymptotic expansions for multivariate statistics which include MANOVA tests, dimensionality tests and <b>latent</b> <b>roots</b> under normality and nonnormality. He has made a large contribution in the study on theoretical accuracy for asymptotic expansions by deriving explicit error bounds. A large contribution has been also made in an important problem involving the selection of variables with introducing "no additional information hypotheses" in some multivariate models and the application of model selection criteria. Recently he is challenging to a high-dimensional statistical problem. He has been involved in other topics in multivariate analysis, such as power comparison of a class of tests, monotone transformations with improved approximations, etc. Asymptotic expansions MANOVA Dimensionality <b>Latent</b> <b>roots</b> Growth curve model Selection of variables Error bounds Monotone transformations...|$|R
40|$|AbstractThis paper {{shows how}} the {{likelihood}} ratio for testing the equality of two variance-covariance matrices decomposes asymptotically into two separate tests, one for equality of the <b>latent</b> <b>roots</b> or eigenvalues, {{and the other for}} equality of the eigenvectors. The decomposition develops from the role of the orthogonal group and its related Lie algebra in multivariate normal theory...|$|R
40|$|The {{asymptotic}} {{variance of}} a statistic {{used to test}} the equality of the smallest <b>latent</b> <b>roots</b> of a correlation matrix is computed. This permits an approximation to its null distribution suggested by Lawley (1956). A simulation is used to compare the performance of this approximation with others currently in use. Some key words: Asymptotic variance; Principal component analysis. 1...|$|R
40|$|Let M be {{a square}} matrix over a {{commutative}} ring and let A be a principal submatrix. We give {{relations between the}} determinants of M and A based on an annihilating polynomial for one of them. The intended application is the size reduction of complex <b>latent</b> <b>root</b> problems, especially the reduction of ordinary eigenvalue problems if a matrix or its principal submatrix have a low degree minimal polynomial. An example is the spectrum of vertex perturbed strongly regular graphs...|$|E
40|$|Multivariable {{systems such}} as a finite-element model of {{vibrating}} structures, control systems, and large-scale systems are often formulated in terms of differential equations which give rise to lambda matrices. The present investigation {{is concerned with the}} formulation of the algebraic theory of lambda matrices and the relationship of latent roots, latent vectors, and latent projectors to the eigenvalues, eigenvectors, and eigenprojectors of the companion form. The chain rule for latent projectors and eigenprojectors for the repeated <b>latent</b> <b>root</b> or eigenvalues is given...|$|E
40|$|The {{author has}} {{identified}} the following significant results. It was observed that OLS was not adequate as an estimation procedure when the independent or regressor variables {{were involved in}} multicollinearities. This was shown to cause the presence of small eigenvalues of the extended correlation matrix A'A. It was demonstrated that the biased estimation techniques and the all-possible subset regression could help in finding a suitable model for predicting yield. <b>Latent</b> <b>root</b> regression was an excellent tool that found how many predictive and nonpredictive multicollinearities there were...|$|E
40|$|Self {{complementary}} graphs {{have many}} interesting properties {{with reference to}} their main and non-main eigcnvalues. Eigenvalues are a special set of scalars associated with a linear system of equations (i. e., a matrix cquation) that are sometimes also known as characteristic roots, proper values, or <b>latent.</b> <b>roots.</b> We consider the spectra of self complementary graphs. non peer-reviewe...|$|R
40|$|Asymptotic {{expansions}} {{are given}} for the distributions of <b>latent</b> <b>roots</b> of matrices in three multivariate situations. The distribution of {{the roots of the}} matrix S 1 (S 1 + S 2) - 1, where S 1 is Wm(n 1, [Sigma], [Omega]) and S 2 is Wm(n 2, [Sigma]), is studied in detail and asymptotic series for the distribution are obtained which are valid for {{some or all of the}} roots of the noncentrality matrix [Omega] large. These expansions are obtained using partial-differential equations satisfied by the distribution. Asymptotic series are also obtained for the distributions of the roots of n- 1 S, where S in Wm(n, [Sigma]), for large n, and S 1 S 2 - 1, where S 1 is Wm(n 1, [Sigma]) and S 2 is Wm(n 2, [Sigma]), for large n 1 + n 2. Asymptotic distributions <b>latent</b> <b>roots</b> asymptotic expansions partial-differential equations...|$|R
40|$|AbstractIn {{this paper}} we derive {{asymptotic}} expansions for the distributions of some {{functions of the}} <b>latent</b> <b>roots</b> of the matrices in three situations in multivariate normal theory, i. e., (i) principal component analysis, (ii) MANOVA model and (iii) canonical correlation analysis. These expansions are obtained by using a perturbation method. Confidence intervals for {{the functions of the}} corresponding population roots are also obtained...|$|R
