0|56|Public
5000|$|It {{can only}} swap numeric variables; {{it may not}} be {{possible}} or <b>logical</b> to <b>add</b> or subtract complex data types, like containers.|$|R
40|$|Copyright © 2006 BMJ Publishing Group Ltd & British Society of GastroenterologyGlucagon-like peptide 1 {{does not}} comfortably fulfil the {{criterion}} of a gut derived factor responsible for an enhanced meal related insulin response; it appears <b>logical</b> to <b>add</b> {{the definition of a}} "physiological incretin hormone". M Horowitz and M A Nauc...|$|R
5000|$|In an extension, new and {{different}} <b>logical</b> constants are <b>added,</b> for instance the [...] "" [...] in modal logic, which stands for [...] "necessarily." [...] In extensions of a logic, ...|$|R
40|$|The {{generalized}} LR parsing algorithm for context-free grammars, {{invented by}} Tomita in 1986, is extended {{for the case}} of Boolean grammars – a recently introduced generalization of context-free grammars with <b>logical</b> connectives <b>added</b> to the formalism of rules. A high-level description of the algorithm, an elaborate example of its operation and a suggested implementation are provided. The algorithm has been implemented in a parser generator. However, the proof of the algorithm’s correctness is so far incomplete, hence the preliminary status of this report. ...|$|R
40|$|Communicated by Editor’s name The {{generalized}} LR parsing algorithm for context-free grammars {{is extended}} {{for the case}} of Boolean grammars, which are a generalization of the context-free grammars with <b>logical</b> connectives <b>added</b> to the formalism of rules. In addition to the standard LR operations, Shift and Reduce, the new algorithm uses a third operation called Invalidate, which reverses a previously made reduction. This operation makes the mathematical justification of the algorithm significantly different from its prototype. On the other hand, {{the changes in the}} implementation are not very substantial, and the algorithm still works in time O(n 4) ...|$|R
50|$|The integer unit {{consisted}} of two integer pipelines and the integer register file. The two pipelines, the add pipeline and the multiply pipeline are not identical, each are responsible for executing different instructions, although both are capable of executing common <b>add,</b> <b>logical,</b> load, compare, and conditional move instructions. The multiply pipeline exclusively executes shift, store, and multiply instructions (in a non-pipelined multiplier). The add pipeline exclusively executes branch instructions.|$|R
40|$|An {{experience}} {{from the process}} of <b>adding</b> <b>logical</b> markup to visually tagged scanned data is presented. Method of gradual markup enhancement is outlined. Methods of navigation in a large hypertext document based on typesetting from logical markup are suggested [...] physical, logical and semantic user views. Their application to a 29, 000 page digitization project to create an electronic encyclopaedia is described. Problems faced in applying Adobe's Acrobat technology for encyclopaedia publishing are discussed...|$|R
40|$|This paper {{describes}} {{a tool for}} recombining the logical structure from an XML document with the typeset appearance of the corresponding PDF document. The tool uses the XML representation as a template for the insertion of the logical structure into the existing PDF document, thereby creating a Structured/Tagged PDF. The addition of <b>logical</b> structure <b>adds</b> value to the PDF in three ways: the accessibility is improved (PDF screen readers for visually impaired users perform better), media options are enhanced (the ability to reflow PDF documents, using structure as a guide, makes PDF viable for use on hand-held devices) and the re-usability of the PDF documents benefits greatly from {{the presence of an}} XML-like structure tree to guide the process of text retrieval in reading order (e. g. when interfacing to XML applications and databases) ...|$|R
40|$|My {{research}} interests {{are in the}} field of knowledge representation and reasoning (KRR). During and since my PhD (throughout my post-doc and lectureship) I have investigated graph-based KRR languages applied in different Artificial Intelligence (AI) fields. Syntactically, the objects I am interested in are graphs. Semantically these graphs represent different subsets of logics such that the logic operations are sound and complete with graph operations. This <b>adds</b> <b>logical</b> background to the well-known modelling capacity of graph...|$|R
40|$|Abstract — We {{introduce}} {{a new version of}} the widely studied survivable mapping problem in IP-over-WDM networks. The new problem allows augmenting the given logical topology and is described as follows: given a physical topology and a logical topology, compute a survivable logical topology that contains the given logical topology such that the minimal survivable mapping cost for the result logical topology is minimized. The problem is significant for two reasons: 1) If there does not exist a survivable mapping for the given logical topology, we can <b>add</b> <b>logical</b> links to the given logical topology to make it survivable; 2) Even if a survivable mapping for the given logical topology can be found, it is still possible to reduce the minimal survivable mapping cost by <b>adding</b> <b>logical</b> links selectively. We first prove the existence of a solution to the problem, then provide a straightforward Integer Linear Program (ILP) formulation for the problem. Moreover, we present a theoretical result that leads to a simple NP-hardness proof of the problem and an improved ILP formulation. Simulation results demonstrate the significance of both the new survivable mapping problem and the theoretical result. Index Terms — Network survivability, survivable mapping, IPover-WDM I...|$|R
40|$|We {{introduce}} {{a new version of}} the widely studied survivable mapping problem in IP-over-WDM networks. The new problem allows augmenting the given logical topology and is described as follows: given a physical topology and a logical topology, compute a survivable logical topology that contains the given logical topology such that the minimal survivable mapping cost for the result logical topology is minimized. The problem is significant for two reasons: 1) If there does not exist a survivable mapping for the given logical topology, we can <b>add</b> <b>logical</b> links to the given logical topology to make it survivable; 2) Even if a survivable mapping for the given logical topology can be found, it is still possible to reduce the minimal survivable mapping cost by <b>adding</b> <b>logical</b> links selectively. We first prove the existence of a solution to the problem, then provide a straightforward Integer Linear Program (ILP) formulation for the problem. Moreover, we present a theoretical result that leads to a simple NP-hardness proof of the problem and an improved ILP formulation. Simulation results demonstrate the significance of both the new survivable mapping problem and the theoretical result...|$|R
40|$|We present {{probabilistic}} {{logic programming}} under inheritance with overriding. This approach {{is based on}} new notions of entailment for reasoning with conditional constraints, which are obtained from the classical notion of <b>logical</b> entailment by <b>adding</b> inheritance with overriding. This is done by using recent approaches to probabilistic default reasoning with conditional constraints. We analyze the semantic properties of the new entailment relations. We also present algorithms for probabilistic logic programming under inheritance with overriding, and we analyze its complexity in the propositional case. ...|$|R
50|$|The Cray-1 had twelve pipelined {{functional}} units. The 24-bit address arithmetic {{was performed}} in an add unit and a multiply unit. The scalar portion of the system consisted of an <b>add</b> unit, a <b>logical</b> unit, a population count, a leading zero count unit and a shift unit. The vector portion consisted of <b>add,</b> <b>logical</b> and shift units. The floating point functional units were shared between the scalar and vector portions, and these consisted of add, multiply and reciprocal approximation units.|$|R
40|$|In {{a series}} of 41 pancreatoduodenectomies the Whipple {{procedure}} was done in 27 patients and total pancreatoduodenectomy in 14 others with two postoperative deaths. Among 39 survivors, seven developed evidence of stomal ulcer 20 days to six years after operation; details of their courses are summarized. Proven stomal ulcer occurred in five of 14 patients {{who did not have}} concomitant vagotomy with pancreatoduodenectomy (36 %). Each of these required vagotomy secondarily in management. When two patients with hematemesis in whom stomal ulcer was suspected but not proven are included, the incidence of stomal ulcer in nonvagotomized patients with pancreatoduodenectomy (7 / 14) is 50 %. There were no stomal ulcers in patients with pancreatoduodenectomy who had concomitant vagotomy (0 / 25). It is <b>logical</b> to <b>add</b> the protective effects of vagotomy to pancreatoduodenectomy, especially when the disease process favors prolonged survival...|$|R
40|$|It is a tacit {{assumption}} of much linguistic inquiry that all distinct derivations {{of a string}} should assign distinct meanings. But despite the tidiness of such derlvational uniqueness, {{there seems to be}} no a priori reason to assume that a gramma r must have this property. If a grammar exhibits derivational equivalence, whereby distinct derivations of a string assign the same meanings, naive exhaustive search for all derivations will be redundant, and quite possibly intractable. In this paper we show how notions of derivation-reduction and normal form can be used to avoid unnecessary work while parsing with grammars exhibiting derivational equivalence. With grammar regarded as analogous to logic, derivations are proofs; what we are advocating is proof-reduction, and normal form proof; the invocation of these <b>logical</b> techniques <b>adds</b> a further paragraph to the story of parsing-as-deduction...|$|R
30|$|The {{cause of}} the {{discrepancy}} between results for the two file formats might lie {{in the nature of}} attacks against them. Malicious PDF files often use features uncommon in benign files, i.e., their structure is different, while malicious SWF files mostly base their attacks on different values, i.e., content, at specific paths, although these paths are also common among benign files. While binary features suffice to describe <b>logical</b> structure, the <b>added</b> expressive power of numerical features enables the description, and consequently detection, of both structure- and content-based attacks.|$|R
40|$|International audienceWe {{propose to}} use the Knaster-Tarski least fixed point theorem as a basis to define {{recursive}} functions in the Calculus of Inductive Constructions. This widens the class of functions that can be modelled in type-theory based theorem proving tools to potentially non-terminating functions. This is only possible if we extend the <b>logical</b> framework by <b>adding</b> some axioms of classical logic. We claim that the extended framework {{makes it possible to}} reason about terminating or non-terminating computations and we show that extraction can also be extended to handle the new functions...|$|R
40|$|Formal {{theories}} of teamwork are typically treated as software design specifications of team behavior. We {{take a different}} approach to programming teamwork by directly executing logical specifications of joint commitment and joint intention. This approach leads to a domain-independent framework for programming teamwork where one can modify (or add new) behavior for a team of agents just by modifying (or <b>adding)</b> <b>logical</b> sentences. One may also be able to predict the behavior of an agent team offline using its team intention specification and verify it by running the actual system...|$|R
40|$|There is {{a burgeoning}} amount of {{research}} into happiness and greatly increased popular attention, so it seems <b>logical</b> to <b>add</b> a course on happiness to the university curriculum. We encountered, in developing and running such a course, a number of dilemmas that the topic of happiness makes especially acute. Should the teacher remain separate from the class, as an authority, or participate in group activities? Is {{the primary goal of}} the class to learn content or to change the relationship of students to the world? What does a mark for learning content signify if developing happiness habits is a goal? Should one goal of the class be for the teacher to be happy and, if so, does this conflict with student learning? These dilemmas reflect larger questions about the purpose of university education. This paper reflects on those questions through our experience of formulating and delivering a new university class on happiness...|$|R
40|$|We present {{probabilistic}} {{logic programming}} under inheritance with overriding. This approach {{is based on}} new notions of entailment for reasoning with conditional constraints, which are obtained from the classical notion of <b>logical</b> entailment by <b>adding</b> the principle of inheritance with overriding. This is done by using recent approaches to probabilistic default reasoning with conditional constraints. We analyze the semantic properties of the new entailment relations. We also present algorithms for probabilistic logic programming under inheritance with overriding, and program transformations for an increased efficiency. Comment: Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI 2001...|$|R
40|$|We {{propose to}} use Tarski's least {{fixpoint}} theorem {{as a basis}} to define recursive functions in the calculus of inductive constructions. This widens the class of functions that can be modeled in type-theory based theorem proving tool to potentially non-terminating functions. This is only possible if we extend the <b>logical</b> framework by <b>adding</b> the axioms that correspond to classical logic. We claim that the extended framework {{makes it possible to}} reason about terminating and non-terminating computations and we show that common facilities of the calculus of inductive construction, like program extraction can be extended to also handle the new functions...|$|R
50|$|Chamberlain's {{style is}} sober and objective, {{illuminated}} by {{an eye for}} the precise detail. The elements of this style are a sometimes artful, sometimes natural, blending {{of public and private}} information, of the serious and trivial, reported with care and exactitude and spiced with brisk remarks of his own. He explains and comments on his information, which he lays out as clearly as possible in a <b>logical</b> sequence, <b>adding</b> his own estimations {{of the value of the}} information and opinions he reports. His sentences are obviously crafted with care. Chamberlain's letters are those of an educated and cultivated man, who could quote French, Italian and Spanish, and who was familiar with old English and classical literature. Sometimes his humour is formulaic, however, and he was not above sending the same letter to two different correspondents. His figures of speech are not his own invention but taken from general use, often drawing on images of hunting, falconry, horseriding, farming, and seafaring. Chamberlain's style remains constant through the decades of his correspondence.|$|R
40|$|With {{the arrival}} of partial {{reconfiguration}} technology, modern FPGAs support swapping tasks in or out individually at run-time without interrupting other tasks running on the same FPGA. Although, implementing this feature achieves much better flexibility and device utilization, the challenge remains to quickly and efficiently place tasks arriving at run-time on such partially reconfigurable systems. In this paper, we propose an algorithm to handle this on-line, run-time task placement problem. By <b>adding</b> <b>logical</b> constraints on the FPGA and introducing our resources management solution, the simulation results show our algorithm has better overall performances compared with previous reported methods in terms of task rejection number, placement quality 1 and execution time. ...|$|R
40|$|Abstract. In 1959, Kreisel {{introduced}} {{a notion of}} “modified ” realizability that, among other things, provides an alternative technique to Gödel functional (dialectica) interpretation for establishing the connection between Peano Arithmetic and System T. While the dialectica interpretation has been widely studied in the literature, Kreisel’s technique, although remarkably simpler, has apparently been almost neglected (with the only exception of Troelstra). In this paper we give a modern presentation of modified realizability, and generalize it to arbitrary inductive types in a first order setting. This {{is part of a}} larger program, advocating the study of logical systems with primitive inductive types starting form weak, predicative <b>logical</b> frameworks and <b>adding</b> little by little small bits of logical power. ...|$|R
40|$|Abstract The {{generalized}} LR parsing algorithm for context-free grammars, invented byTomita in 1986, {{is extended}} {{for the case}} of Boolean grammars- a recently introduced generalization of context-free grammars with <b>logical</b> connectives <b>added</b> to the formalismof rules. A high-level description of the algorithm, an elaborate example of its operation and a suggested implementation are provided. The algorithm has been implemented in aparser generator. However, the proof of the algorithm's correctness is so far incomplete, hence the preliminary status of this report. 1 Introduction Knuth's discovery of the LR parsing algorithm [4] in 1965 {{became one of the}} most significantcontributions of formal language theory to software engineering. Being applicable to every deterministic context-free language and working in linear time, this algorithm possessed ex-actly the qualities in demand by the compiler industry, which ensured quick recognition and continued work in this direction. For technical details on Knuth's LR the reader is directed to the well-known textbook on compilers by Aho, Sethi and Ullman [1]. In short, the algorithm uses stack memory, whichcontains a string ff of terminals and nonterminals and the computation history of a certainDFA on ff. The algorithm performs actions of two types...|$|R
40|$|We {{present a}} {{straightforward}} source-to-source transformation that introduces justifications for user-defined constraints into the CHR programming language. Then a scheme of two rules suffices {{to allow for}} logical retraction (deletion, removal) of constraints during computation. Without the need to recompute from scratch, these rules remove not only the constraint but also undo all consequences of the rule applications that involved the constraint. We prove a confluence result concerning the rule scheme and show its correctness. When algorithms are written in CHR, constraints represent both data and operations. CHR is already incremental by nature, i. e. constraints can be <b>added</b> at runtime. <b>Logical</b> retraction <b>adds</b> decrementality. Hence any algorithm written in CHR with justifications will become fully dynamic. Operations can be undone and data can be removed {{at any point in}} the computation without compromising the correctness of the result. We present two classical examples of dynamic algorithms, written in our prototype implementation of CHR with justifications that is available online: maintaining the minimum of a changing set of numbers and shortest paths in a graph whose edges change. Comment: Pre-proceedings paper presented at the 27 th International Symposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2017), Namur, Belgium, 10 - 12 October 2017 (arXiv: 1708. 07854...|$|R
40|$|Multidimensional {{codesign}} is {{a recently}} proposed paradigm for integrating different system dimensions in sensor networks. Examples of such dimensions are logical and physical mobility, continuous and discrete transitions, deterministic and random evolutions and features resulting from their interaction, like deterministic and stochastic hybrid behaviours. In this paper, we propose a unifying computational model that considers multiple dimensions and an integration framework based on domain theory. In this framework new dimensions can be incrementally added, and we illustrate this technique by <b>adding</b> <b>logical</b> mobility to the computational model. The new model {{has a very}} promising modelling power, offering all formal ingredients of a neural network. We further investigate bisimulation for systems mixing physical and logical mobility. We identify and solve a compatibility problem between bisimulation relations arising from mobility and continuous behaviours...|$|R
5000|$|Some reviewers have {{commented that}} the story lacks {{originality}} and {{is not likely to}} stand up to the sort of probing literary criticism used in [...] "serious" [...] circles, while others argue that books appealing to a young-adult audience are critical for building a developing reader's appetite for reading. Karen Ray, writing in The New York Times, detects [...] "occasional <b>logical</b> lapses", but <b>adds</b> that the book [...] "is sure to keep older children reading". Young adult fiction author Debra Doyle was more critical, stating that [...] "Personal taste aside, The Giver fails the Plausibility Test", and that [...] "Things are the way they are (in the novel) because The Author is Making A Point; things work out the way they do because The Author's Point Requires It".|$|R
40|$|Abstract. Multidimensional {{codesign}} is {{a recently}} proposed paradigm for integrating different system dimensions in sensor networks. Examples of such dimensions are logical and physical mobility, continuous and discrete transitions, deterministic and random evolutions and features resulting from their interaction, like deterministic and stochastic hybrid behaviours. In this paper, we propose a unifying computational model that considers multiple dimensions, {{inspired by the}} Hilbertian Formal Methods paradigm. We couple this model with an integration framework based on domain theory. In this framework new dimensions can be incrementally added, and we illustrate this technique by <b>adding</b> <b>logical</b> mobility to the computational model. The new model has a very promising modelling power, offering all formal ingredients of a neural network. We further investigate bisimulation for systems mixing physical and logical mobility. We identify and solve a compatibility problem between bisimulation relations arising from mobility and continuous behaviours...|$|R
40|$|CHR is a committed-choice {{language}} {{consisting of}} guarded rules that rewrite constraints into simpler ones {{until they are}} solved. CHR can define both simplification of and propagation over user-defined constraints. Simplification replaces constraints by simpler constraints while preserving <b>logical</b> equivalence. Propagation <b>adds</b> new constraints which are logically redundant but may cause further simplification. The constraints acted upon by CHR are represented in a constraint store, much like tuples in a conventional data base. The evaluation of the condition part of CHR consists of finding sets of tuples in the constraint store which match the heads of a rule, resembling the relational algebra join operation. In the binding environments of these tuple sets, {{the applicability of the}} rules is decided by evaluating the guards. Rule applications may add and remove constraints. The anticipated interaction under an immediate update view leads to a small number of prototypical join evaluation c [...] ...|$|R
40|$|An {{experience}} {{from the process}} of <b>adding</b> <b>logical</b> markup to visually tagged scanned data is presented. Method of gradual markup enhancement is outlined. Methods of navigation in a large hypertext document based on typesetting from logical markup are suggested [...] -physical, logical and semantic user views. Their application on a 29 000 page digitization project to create an electronic encyclopdia is described. Problems faced in applying Adobe's Acrobat technology for encyclopdia publishing are discussed. Abstrakt: V prspevku jsou shrnuty zkusenosti z digitalizace dvou projekt u [...] digitalizace Ottova slovnku naucneho (temer 29 tisce stran) a Ottova slovnku naucneho nove doby (11 tisc stran). Je popsan poloautomatick y postup postupne konverze naskenovanych dat do tvaru vhodneho pro presazbu, ktery obsahuje informace o strukture a o logickych castech textu. Je navrzena metoda navigace v takychto rozsahlych encyklopedich, reflektujc ruzne pohledy uzivatele na data. Zmneny jsou t [...] ...|$|R
40|$|An {{experience}} {{from the process}} of <b>adding</b> <b>logical</b> markup to visually tagged scanned data is presented. The method of gradual markup enhancement is shown. Methods of navigation in a large hypertext document based on typesetting from logical markup are suggested [...] -physical, logical and semantic user views. Their application on a 28 000 page project to create an electronic encyclopædia is described and problems faced when using Adobe's Acrobat technology for publishing are discussed. Keywords: digital replica, markup, navigation, hypertext, Acrobat, CD-ROM, encyclop ædia, "Go forth and create masterpieces of electronic publishing art. " 1. Introduction Current computer technologies allow easy production and delivery of huge documents like encyclopædias on a CD-ROM for public, everyday use on cheap hardware. Digitizing such multivolume books in hypertext form is a challenge. Users accustomed to using paper editions for years often reject electronic media if their look and feel is totally [...] ...|$|R
40|$|We present {{probabilistic}} {{logic programming}} under inheritance with overriding. This approach {{is based on}} new notions of entailment for reasoning with conditional constraints, which are obtained from the classical notion of <b>logical</b> entailment by <b>adding</b> inheritance with overriding. This is done by using recent approaches to probabilistic default reasoning with conditional constraints. We analyze the semantic properties of the new entailment relations. We also present algorithms for probabilistic logic programming under inheritance with overriding, and we analyze its complexity in the propositional case. 1 Institut und Ludwig Wittgenstein Labor fur Informationssysteme, TU Wien, Favoritenstrae 9 - 11, A- 1040 Vienna, Austria. E-mail: lukasiewicz@kr. tuwien. ac. at. Acknowledgements: I am very grateful to Gabriele Kern-Isberner for valuable {{comments on an earlier}} version of this paper. This work has been supported by a DFG grant and the Austrian Science Fund under project N Z 29 -INF. Copyright c 2001 by the authors 2 INFSYS RR 1843 - 01 - 05...|$|R
40|$|Abstract: Due to {{disadvantages}} in manual inspection, {{an automated}} visual inspection system {{is needed to}} eliminate subjective aspects and provides fast and quantitative assessment of printed circuit board (PCB). Up to the present, {{there has been a}} lot of work and research concentrated on PCB defect detection. PCB defects detection is necessary for verification of the characteristics of PCB to make sure it is in conformity with the design specifications. However, besides the need to detect the defects, it is also essential to classify these defects so that the source of these defects can be identified. Unfortunately, this area has been neglected and not been given enough attention. Hence, this study proposes an algorithm to group the defects found on bare PCB. Using a synthetically generated PCB image, the algorithm is able to group 14 commonly known PCB defects into five groups. The proposed algorithm includes several image processing operations such as image subtraction, image <b>adding,</b> <b>logical</b> XOR and NOT, and flood fill operator...|$|R
40|$|Abstract. Periodicity {{constraints}} {{are present}} in many logical formalisms, in fragments of Presburger LTL, in calendar logics, and in logics for access control, to quote a few examples. We introduce the logic PLTL mod, an extension of Linear-Time Temporal Logic LTL with past-time operators whose atomic formulae are defined from a first-order constraint language dealing with periodicity. The underlying constraint language is a fragment of Presburger arithmetic shown to admit a pspace-complete satisfiability problem and we establish that PLTL mod model-checking and satisfiability problems are in pspace as plain LTL. The logic PLTL mod is a quite rich and concise language to express periodicity constraints. We show that <b>adding</b> <b>logical</b> quantification to PLTL mod provides expspace-hard problems. As another application, we establish that the equivalence problem for extended single-string automata, known to express the equality of time granularities, is pspace-complete. The paper concludes by presenting a bunch of open problems related to fragments of Presburger LTL. ...|$|R
40|$|Due to {{disadvantages}} in manual inspection, {{an automated}} visual inspection system {{is needed to}} eliminate subjective aspects and provides fast and quantitative assessment of printed circuit board (PCB). Up to the present, {{there has been a}} lot of work and research concentrated on PCB defect detection. PCB defects detection is necessary for verification of the characteristics of PCB to make sure it is in conformity with the design specifications. However, besides the need to detect the defects, it is also essential to classify these defects so that the source of these defects can be identified. Unfortunately, this area has been neglected and not been given enough attention. Hence, this study proposes an algorithm to group the defects found on bare PCB. Using a synthetically generated PCB image, the algorithm is able to group 14 commonly known PCB defects into five groups. The proposed algorithm includes several image processing operations such as image subtraction, image <b>adding,</b> <b>logical</b> XOR and NOT, and flood fill operato...|$|R
