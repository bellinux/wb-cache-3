524|10000|Public
5000|$|... #Subtitle level 2: Normalized <b>least</b> <b>mean</b> <b>squares</b> filter (NLMS) ...|$|E
5000|$|Bussgang methods {{make use}} of the <b>Least</b> <b>mean</b> <b>squares</b> filter {{algorithm}} ...|$|E
50|$|Another popular {{stochastic}} {{gradient descent}} algorithm is the <b>least</b> <b>mean</b> <b>squares</b> (LMS) adaptive filter.|$|E
40|$|This article {{investigates the}} {{adaptive}} filtered-U <b>least</b> <b>mean</b> <b>square</b> feed-forward algorithm for active resonant vibration {{control of a}} clamped-clamped flexible piezoelectric plate structure under persistent harmonic excitation. Different from the widely used filtered-X <b>least</b> <b>mean</b> <b>square</b> algorithm based on the finite impulse response filter, the filtered-U <b>least</b> <b>mean</b> <b>square</b> algorithm uses the infinite impulse response filter. An infinite impulse response filter can be constituted simply by using two adaptive transversal filters. The filtered-U <b>least</b> <b>mean</b> <b>square</b> algorithm can model the system accurately with much fewer coefficients. Moreover, the filtered-U <b>least</b> <b>mean</b> <b>square</b> algorithm has better control performance {{and stability in the}} presence of vibration control feedback, owing to the inherent zero-pole structure of the infinite impulse response filter. In this investigation, the filtered-U <b>least</b> <b>mean</b> <b>square</b> algorithm is implemented only in experiments. Two experimental cases are carried out, including the reference signal extracted from the function signal generator and the lead zirconate titanate sensor. A proportional-derivative feedback control algorithm is also applied as a comparison. The experimental results demonstrate the feasibility and performance of the designed proportional-derivative controller and filtered-U <b>least</b> <b>mean</b> <b>square</b> controller. © SAGE Publications...|$|R
3000|$|... of chaotic Lorenz {{time series}} and {{nonlinear}} channel equalization. Also the performance is validated {{in comparison with}} the <b>least</b> <b>mean</b> <b>square</b> algorithm, kernel <b>least</b> <b>mean</b> <b>square</b> algorithm, affine projection algorithm and kernel affine projection algorithm.|$|R
40|$|In this paper, the kernel {{proportionate}} normalized <b>least</b> <b>mean</b> <b>square</b> algorithm (KPNLMS) is proposed. The proportionate {{factors are}} used {{in order to increase}} the convergence speed and the tracking abilities of the kernel normalized <b>least</b> <b>mean</b> <b>square</b> (KNLMS) adaptive algorithm. We confirm the effectiveness of the proposed algorithm for nonlinear system identification and forward predict ion using computer simulat ions. Index Terms — Kernel normalized <b>least</b> <b>mean</b> <b>square</b> algorithm, proportionate-type algorithms, nonlinear system identification, forward pred iction. 1...|$|R
50|$|The Multidelay block {{frequency}} domain adaptive filter (MDF) algorithm is a block-based {{frequency domain}} {{implementation of the}} (normalised) <b>Least</b> <b>mean</b> <b>squares</b> filter (LMS) algorithm.|$|E
50|$|The FIR Wiener filter {{is related}} to the <b>least</b> <b>mean</b> <b>squares</b> filter, but {{minimizing}} the error criterion of the latter does not rely on cross-correlations or auto-correlations. Its solution converges to the Wiener filter solution.|$|E
50|$|Because high-dimensional {{feature space}} is linear, kernel {{adaptive}} filters {{can be thought}} of as a generalization of linear adaptive filters. As with linear adaptive filters, there are two general approaches to adapting a filter: the <b>least</b> <b>mean</b> <b>squares</b> filter (LMS) and the recursive least squares filter (RLS).|$|E
40|$|The <b>Least</b> <b>Mean</b> <b>Square</b> (LMS) Algorithm {{finds its}} {{application}} in System identification {{due to its}} simplicity. Reduction {{of the complexity of}} Adaptive Finite Impulse Response(FIR) filter had received attention in the area of adative filter. This paper proposes methods of system identification using adaptive filter which are based on a Quantised version of the LMS, namely the Clipped <b>Least</b> <b>Mean</b> <b>Square</b> (CLMS) and Modified Clipped <b>Least</b> <b>Mean</b> Square(QX-LMS) algorithms. In both Algorithms coefficients of the adaptive filter are adjusted automatically by an adaptive algorithm based on the input signals. This property makes the adaptive filter has an important application in system identification. the Quantized version of <b>Least</b> <b>Mean</b> <b>Square</b> Algorithm increases covergence property as compared to normal <b>Least</b> <b>Mean</b> <b>Square</b> Algorithm...|$|R
40|$|Abstract—This letter proposes two new {{variable}} step-size algorithms for normalized <b>least</b> <b>mean</b> <b>square</b> and affine projection. The proposed schemes lead to faster convergence {{rate and}} lower misadjustment error. Index Terms—Adaptive filters, affine projection algorithm, normalized <b>least</b> <b>mean</b> <b>square</b> (NLMS), variable step-size. I...|$|R
40|$|Abstract—Least <b>mean</b> <b>square</b> (LMS) -type {{adaptive}} sparse algorithms {{have been}} attracting much attention on sparse multipath channel estimation (SMPC) {{due to their}} two advantages: low computational complexity and reliability. By introducing � �-norm sparse constraint function into LMS algorithm, both zero-attracting <b>least</b> <b>mean</b> <b>square</b> (ZA-LMS) and reweighted zero-attracting <b>least</b> <b>mean</b> <b>square</b> (RZA-LMS) have been proposed for SMPC. It {{is well known that}} the performance of the SMPC is decided by regularization parameter which balances channel estimation error and sparse penalty strength. However, optimal regularization parameter selection has not yet considered in the two proposed algorithms. Based on the compressive sensing theory, in this paper, we explain the mathematical relationship between Lasso and LMS-type adaptive sparse algorithms. Later, an approximate optimal regulation parameter selection method is proposed for ZA-LMS and RZA-LMS, respectively. Monte Carlo based computer simulations are presented to show the effectiveness of our propose method. Keywords—regularization parameter selection, <b>least</b> <b>mean</b> <b>square</b> (LMS); adaptive sparse channel estimation; zero-attracting <b>least</b> <b>mean</b> <b>square</b> (ZA-LMS); reweighted zero-attracting <b>least</b> <b>mean</b> <b>square</b> (RZA-LMS). I...|$|R
50|$|This {{important}} {{special case}} has also {{given rise to}} many other iterative methods (or adaptive filters), such as the <b>least</b> <b>mean</b> <b>squares</b> filter and recursive least squares filter, that directly solves the original MSE optimization problem using gradient descent methods. These methods bypass the need for covariance matrices.|$|E
50|$|The {{idea behind}} a closed loop {{adaptive}} filter {{is that a}} variable filter is adjusted until the error (the difference between the filter output and the desired signal) is minimized. The <b>Least</b> <b>Mean</b> <b>Squares</b> (LMS) filter and the Recursive Least Squares (RLS) filter are types of adaptive filter.|$|E
50|$|Learning {{occurs in}} the {{perceptron}} by changing connection weights after each piece of data is processed, based {{on the amount of}} error in the output compared to the expected result. This is an example of supervised learning, and is carried out through backpropagation, a generalization of the <b>least</b> <b>mean</b> <b>squares</b> algorithm in the linear perceptron.|$|E
40|$|This {{paper is}} {{concerned}} with weighted <b>least</b> <b>mean</b> <b>square</b> design of two-dimensional (2 -D) zero-phase FIR filters with quadrantally symmetric and antisymmetric frequency responses. The optimal solutions are first characterized by certain integral equations, and the existence, and uniqueness of the weighted <b>least</b> <b>mean</b> <b>square</b> solution for 2 -D FIR filter design are then established using contraction mapping, and fixed point theorem [13]. Explicit solution in closed form for discretized weighted <b>least</b> <b>mean</b> <b>square</b> error is obtained for 2 -D zero-phase FIR filters which {{can be considered as}} an extension of [15, 1]. Further, two numerical algorithms are proposed to iteratively solve the weighted <b>least</b> <b>mean</b> <b>square</b> solution. Convergence of the iterative algorithms is established, and estimates of the convergence rate are also derived. Examples are used to illustrate the effectiveness of the proposed design algorithms. 1 Introduction An important research area for two-dimensional (2 -D) digital sign [...] ...|$|R
40|$|Most {{currently}} available active control algorithms target noise sources with relatively singular {{characteristics such as}} tonal or wideband noise. However, noise in some practical environments {{is a mixture of}} different sounds generated by different sources, where the existing algorithms designed for single noise sources may not be optimal. This kind of noise is generally referred to as mixed noise, and this paper develops a specific active control algorithm for mixed noise based on the recursive least square structure. By minimizing the weighted summation of the logarithmic transformation of posterior errors and taking the commutation error into consideration, the proposed algorithm not only reduces broadband, narrowband and impulse noise successfully, but also mixtures of them. Simulation results demonstrate the superiority of the proposed algorithm over existing algorithms such as the filtered-x <b>least</b> <b>mean</b> <b>square,</b> filtered-x logarithmic <b>least</b> <b>mean</b> <b>square,</b> filtered-x normalized <b>least</b> <b>mean</b> <b>square</b> and filtered weight filtered-x normalized <b>least</b> <b>mean</b> <b>square</b> algorithms in terms of convergence rate and noise reduction...|$|R
40|$|Interference {{reduction}} {{is needed for}} being able to effectively communicate with mobile users. One method that {{can be used as a}} solution to reduce interference is using smart antenna technology. Along with interference reduction there is increase in capacity and coverage. Adaptive beam forming techniques forms a narrow beam and directs it towards desired users and thereby forms nulls in interference directions This improves signal to noise ratio. The study documented in this paper shows the performance of variants of the <b>Least</b> <b>Mean</b> <b>Square</b> (LMS) Algorithm based approaches, in the realm of beam formation, used earlier in adaptive filtering, aiming at reduction in complexity, without considerable degradation in performance. The proposed algorithms namely Signum- Error <b>Least</b> <b>Mean</b> <b>Square</b> Algorithm along with LMS Algorithm are tested for computational complexity in weight vector updating and observed that the ones proposed perform better than the conventional <b>Least</b> <b>Mean</b> <b>Square</b> algorithm with respect to reduced complexity in beam formation, making them suitable for high speed digital communication systems. This paper will analyze <b>Least</b> <b>Mean</b> <b>square</b> algorithm and Sample Matrix Inverse algorithm for the performance. The consequence will demonstrate the <b>Least</b> <b>Mean</b> <b>Square</b> as a Solution to jammer cancellation when compared to Sample Matrix Inverse...|$|R
50|$|Among {{the most}} used {{adaptive}} algorithms is the Widrow-Hoff’s <b>least</b> <b>mean</b> <b>squares</b> (LMS), which represents {{a class of}} stochastic gradient-descent algorithms used in adaptive filtering and machine learning. In adaptive filtering the LMS is used to mimic a desired filter by finding the filter coefficients that relate to producing the least mean square of the error signal (difference between the desired and the actual signal).|$|E
5000|$|Bernard Widrow (born December 24, 1929) is a U.S. {{professor}} of electrical engineering at Stanford University. [...] He is the co-inventor of the Widrow-Hoff <b>least</b> <b>mean</b> <b>squares</b> filter (LMS) adaptive algorithm with his then doctoral student Ted Hoff. [...] The LMS algorithm {{led to the}} ADALINE and MADALINE artificial neural networks and to the backpropagation technique. He made other fundamental contributions {{to the development of}} signal processing in the fields of geophysics, adaptive antennas, and adaptive filtering.|$|E
5000|$|The main {{drawback}} of the [...] "pure" [...] LMS {{algorithm is}} that it is sensitive to the scaling of its input [...] This makes it very hard (if not impossible) to choose a learning rate [...] that guarantees stability of the algorithm (Haykin 2002). The Normalised <b>least</b> <b>mean</b> <b>squares</b> filter (NLMS) is a variant of the LMS algorithm that solves this problem by normalising with the power of the input. The NLMS algorithm can be summarised as: ...|$|E
40|$|High bit rates optical {{communication}} systems pose {{the challenge of}} their tolerance to linear and nonlinear fiber impairments. Digital filters in coherent optical receivers {{can be used to}} mitigate the chromatic dispersion entirely in the optical transmission system. In this paper, the <b>least</b> <b>mean</b> <b>square</b> adaptive filter has been developed for chromatic equalization in a 112 -Gbit/s polarization division multiplexed quadrature phase shift keying coherent optical transmission system established on the VPIphotonics simulation platform. It is found that the chromatic dispersion equalization shows a better performance when a smaller step size is used. However, the smaller step size in <b>least</b> <b>mean</b> <b>square</b> filter will lead to a slower iterative operation to achieve the guaranteed convergence. In order to solve this contradiction, an adaptive filter employing variable-step-size <b>least</b> <b>mean</b> <b>square</b> algorithm is proposed to compensate the chromatic dispersion in the 112 -Gbit/s coherent communication system. The variable-step-size <b>least</b> <b>mean</b> <b>square</b> filter could make a compromise and optimization between the chromatic dispersion equalization performance and the algorithm converging speed. Meanwhile, the required tap number and the converged tap weights distribution of the variable-step-size <b>least</b> <b>mean</b> <b>square</b> filter for a certain fiber chromatic dispersion are analyzed and discussed in the investigation of the filter feature...|$|R
40|$|Abstract—In {{this paper}} we provide a {{thorough}} ser(symbol error rate) analysis of two well known adaptive algorithms for equalization {{based on a}} novel least squares reference model that allows to treat the equalizer problem equivalently as system identification problem. An adaptive algorithm is a procedure for adjusting the parameters of an adaptive filter to minimize a cost function chosen for the task at hand. Here we firstly proposed a noise-robust optimal-step-size frequency domain LMS (<b>least</b> <b>mean</b> <b>square)</b> algorithm for estimating the equalizer coefficients and after the modified LMS algorithm which {{is an extension of}} the standard LMS (<b>least</b> <b>mean</b> <b>square)</b> algorithm which bypasses this issue by calculating maximum step size value. The proposed algorithms conclude that the stepsize ambiguity of the LMS (<b>least</b> <b>mean</b> <b>square)</b> algorithm is solved by the NLMS (normalized <b>mean</b> <b>square)</b> algorithm, which gives faster convergence speed as compared to the LMS (<b>least</b> <b>mean</b> <b>square)</b> algorithm. Computer simulation results a represented to show its improved performance for trained adaptive equalization. This paper focuses on the use of these two proposed algorithms to reduce this unwanted echo, thus increasing communication quality...|$|R
40|$|The Normalized <b>Least</b> <b>Mean</b> <b>Square</b> error (NLMS) {{algorithm}} is most {{popular due to}} its simplicity. The conflicts of fast convergence and low excess <b>mean</b> <b>square</b> error associated with a fixed step size NLMS are solved by using an optimal step size NLMS algorithm. The main objective {{of this paper is}} to derive a new nonparametric algorithm to control the step size and also the theoretical performance analysis of the steady state behavior is presented in the paper. The simulation experiments are performed in Matlab. The simulation results show that the proposed algorithm as superior performance in Fast convergence rate, low error rate, and has superior performance in noise cancellation. Index Terms: <b>Least</b> <b>Mean</b> <b>square</b> algorithm (LMS), Normalized <b>least</b> <b>mean</b> <b>square</b> algorithm (NLMS) 1...|$|R
5000|$|... 2D Recursive Least Square Adaptive Filters [...] can be {{developed}} by applying 1D recursive least squares filters along both horizontal and vertical directions. The RLS adaptive is an algorithm which finds the filter coefficients recursively to minimize the weighted least squares cost function. The RLS algorithm is different to the <b>least</b> <b>mean</b> <b>squares</b> algorithm which aim to reduce the mean square error, its input signal is considered deterministic. For this reason, the RLS algorithm has fast convergence characteristic.|$|E
50|$|The <b>Least</b> <b>mean</b> <b>squares</b> filter {{solution}} converges to the Wiener filter solution, {{assuming that}} the unknown system is LTI and the noise is stationary. Both filters {{can be used to}} identify the impulse response of an unknown system, knowing only the original input signal and the output of the unknown system.By relaxing the error criterion to reduce current sample error instead of minimizing the total error over all of n, the LMS algorithm can be derived from the Wiener filter.|$|E
50|$|<b>Least</b> <b>mean</b> <b>squares</b> (LMS) {{algorithms}} are a {{class of}} adaptive filter used to mimic a desired filter by finding the filter coefficients that relate to producing the least mean square of the error signal (difference between the desired and the actual signal). It is a stochastic gradient descent method in that the filter is only adapted based on the error at the current time. It was invented in 1960 by Stanford University professor Bernard Widrow and his first Ph.D. student, Ted Hoff.|$|E
40|$|Abstract—An interference-normalized <b>least</b> <b>mean</b> <b>square</b> (INLMS) {{algorithm}} for robust {{adaptive filtering}} is proposed. The INLMS algorithm extends the gradient-adaptive learning rate {{approach to the}} case where the signals are nonstationary. In particular, we show that the INLMS algorithm can work even for highly nonstationary interference signals, where previous gradient-adaptive learning rate algorithms fail. Index Terms—Adaptive filtering, gradient-adaptive learning rate, normalized <b>least</b> <b>mean</b> <b>square</b> (NLMS) algorithm. I...|$|R
40|$|A novel {{algorithm}} is developed based on fractional signal processing approach for parameter estimation of input nonlinear control autoregressive (INCAR) models. The design scheme consists of parameterization of INCAR systems to obtain linear-in-parameter models {{and to use}} fractional <b>least</b> <b>mean</b> <b>square</b> algorithm (FLMS) for adaptation of unknown parameter vectors. The performance analyses of the proposed scheme are carried out with third-order Volterra <b>least</b> <b>mean</b> <b>square</b> (VLMS) and kernel <b>least</b> <b>mean</b> <b>square</b> (KLMS) algorithms based on convergence to the true values of INCAR systems. It is found that the proposed FLMS algorithm provides most accurate and convergent results than those of VLMS and KLMS under different scenarios and by taking the low-to-high signal-to-noise ratio...|$|R
40|$|Abstract — In this paper, {{we propose}} a special fusion method for {{combining}} ensembles of base classifiers utilizing new neural networks {{in order to}} improve overall efficiency of classification. While ensembles are designed such that each classifier is trained independently while the decision fusion is performed as a final procedure, in this method, we would be interested in making the fusion process more adaptive and efficient. This new combiner, called Neural Network Kernel <b>Least</b> <b>Mean</b> <b>Square</b> 1, attempts to fuse outputs of the ensembles of classifiers. The proposed Neural Network has some special properties such as Kernel abilities, <b>Least</b> <b>Mean</b> <b>Square</b> features, easy learning over variants of patterns and traditional neuron capabilities. Neural Network Kernel <b>Least</b> <b>Mean</b> <b>Square</b> is a special neuron which is trained with Kernel <b>Least</b> <b>Mean</b> <b>Square</b> properties. This new neuron is used as a classifiers combiner to fuse outputs of base neural network classifiers. Performance of this method is analyzed and compared with other fusion methods. The analysis represents higher performance of our new method as opposed to others. Keywords—classifiers fusion; combining classifiers; NN classifiers; kernel methods; <b>least</b> <b>mean</b> square; I...|$|R
5000|$|Hoff {{received}} a bachelor's degree {{in electrical engineering}} from the Rensselaer Polytechnic Institute in 1958. He applied for his first two patents based on work done for the General Railway Signal Corp. of Rochester, New York during the summers of his undergraduate study. [...] He {{received a}} National Science Foundation Fellowship to enroll in Stanford University, where he received his master's degree in 1959 and his Ph.D. in 1962. [...] As part of his Ph.D. dissertation, Hoff co-invented the <b>least</b> <b>mean</b> <b>squares</b> filter with Bernard Widrow.|$|E
50|$|His {{research}} is broadly {{in the areas}} of communications, signal processing and control. Among other works, he has shown the h-infinity-optimality of the <b>least</b> <b>mean</b> <b>squares</b> filter, used group-theoretic techniques to design space-time codes and frames and to study entropic vectors, performed information-theoretic studies of various wireless networks (such as determining the capacity of the MIMO wiretap channel), constructed tree codes for interactive communication and control, developed various algorithms and performance analyses for compressed sensing and structured signal recovery, studied epidemic spread in complex networks, and co-invented real-time DNA microarrays.|$|E
50|$|Good {{cancellation}} {{depends upon}} the balancing network having a frequency-vs.-impedance characteristic that accurately matches the line. Since telephone line impedances vary depending upon many factors and the relationship is not always smooth, analog hybrids are able to achieve only a few dB of guaranteed isolation. For this reason, modern hybrids use digital signal processing to implement an adaptive <b>least</b> <b>mean</b> <b>squares</b> filter that automatically detects the line's impedance across the voice frequency range and adjusts to it. These may reach greater than 30 dB trans-hybrid loss, measured with white noise as the send signal.|$|E
30|$|In general, the {{convergence}} rate of standard <b>least</b> <b>mean</b> <b>square</b> (LMS) adaptive equalizer mainly {{depends on the}} step size of each iteration. Therefore, a series of variable step-size <b>least</b> <b>mean</b> <b>square</b> (VSSLMS) algorithms [3 – 5] were proposed, which adjusted the variable step-size by minimizing the error at each iteration. Tong et al. [6] proposed a data reuse <b>least</b> <b>mean</b> <b>square</b> (DR-LMS) algorithm, which reuse the known training sequences to achieve a better equalization performance. Cui et al. [7] combined LMS with recursive least square (RLS) algorithms to realize a faster convergence rate and simplify complexity of implementation at the same time. However, the initial coefficients of equalizer tap weights are always neglected among improved equalization methods, which are also critical to the whole iterations and convergence rate.|$|R
40|$|This paper {{presents}} {{the comparison between}} different adap-tive algorithms usages in acoustic echo cancellation. This comparison includes the cancellation of echo generated in room using different adaptive algorithms <b>Least</b> <b>Mean</b> <b>Square</b> (LMS), Normalized <b>Least</b> <b>Mean</b> <b>Square</b> (NLMS), Improved Proportionate Normalized <b>Least</b> <b>Mean</b> <b>Square</b> (IPNLMS) and Recursive Least Squares (RLS) Algorithms. The goal of this work is to choose an optimal algorithm for cancelling acoustic echo noise from the speech signal. There are many adaptive algorithms available in the literature for echo can-cellation and every algorithm has its own properties. Our aim is to achieve higher ERLE (amount of echo cancelled) in dB {{at a higher rate}} of convergence with low complexity and achieve good amount of SNR (signal to noise ratio). The results verified by using subjective analysis...|$|R
40|$|This paper {{describes}} {{the application of}} the <b>Least</b> <b>Mean</b> <b>Square</b> (LMS) algorithm in tandem with the Filtered-X <b>Least</b> <b>Mean</b> <b>Square</b> algorithm for controlling a science instrument's line-of-sight pointing. Pointing error is caused by a periodic disturbance and spacecraft vibration. A <b>least</b> <b>mean</b> <b>square</b> algorithm is used on-orbit to produce the transfer function between the instrument's servo-mechanism and error sensor. The result is a set of adaptive transversal filter weights tuned to the transfer function. The Filtered-X LMS algorithm, which is an extension of the LMS, tunes a set of transversal filter weights to the transfer function between the disturbance source and the servo-mechanism's actuation signal. The servo-mechanism's resulting actuation counters the disturbance response and thus maintains accurate science instrumental pointing. A simulation model of the Upper Atmosphere Research Satellite is used to demonstrate the algorithms...|$|R
