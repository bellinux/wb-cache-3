10|31|Public
50|$|There {{are four}} common ways of {{implementing}} the <b>lazy</b> <b>load</b> design pattern: lazy initialization; a virtual proxy; a ghost, and a value holder. Each {{has its own}} advantages and disadvantages.|$|E
50|$|Collections of data {{objects are}} {{typically}} stored in Java collection classes such as implementations of the Set and List interfaces. Java generics, introduced in Java 5, are supported. Hibernate can be configured to <b>lazy</b> <b>load</b> associated collections. Lazy loading is the default as of Hibernate 3.|$|E
50|$|ECO {{performs}} object-relational mapping {{based on}} metadata which {{is taken from}} the model or from an xml file. It implements such advanced object persistence features as caching, <b>lazy</b> <b>load</b> and others. Mapping scheme is configurable enough to use ECO with existing databases. Database reverse engineering wizard {{as a part of}} ECO helps with this task.|$|E
40|$|Abstract — In {{computer}} operating systems, {{demand paging}} (as opposed to anticipatory paging) {{is a method}} of virtual memory management. Mainly this paper focus {{on the process of}} execution of pages in physical memory. Mainly this paper tells that faulits of page. Mainly these paper exaplin the <b>lazy</b> <b>loading</b> technique. This <b>lazy</b> <b>loading</b> technique performs the evaluation of expressions in the virtual memory management. This paper attempts the Short-circuit evaluation KeyTerms: demand paging, virtual memory management, <b>lazy</b> <b>loading</b> technique, page fault, Short-circuit evaluation In computer operating systems, demand paging (as opposed to anticipatory paging) is a method of virtual memory management. In a system that uses demand paging, the operating system copies a disk page into physical memor...|$|R
50|$|The {{persistence}} {{layer is}} completely transparent and does performance acceleration like <b>lazy</b> <b>loading</b> and caching behind the scenes.|$|R
5000|$|Support for {{progressive}} {{rendering of}} pages, automatic script minification and on-demand <b>lazy</b> <b>loading</b> of client-side script and stylesheet files for faster loading of pages ...|$|R
5000|$|Sample {{code for}} a Professional Service Automation {{application}} (PSA) {{in which the}} resource object is implemented via composite entity pattern, may look like as follows (entity implements coarse-grained object):package corepatterns.apps.psa.ejb;import corepatterns.apps.psa.core.*;import corepatterns.apps.psa.dao.*;import java.sql.*;import javax.sql.*;import java.util.*;import javax.ejb.*;import javax.naming.*;public class ResourceEntity implements EntityBean { public String employeeId; public String lastName; public String firstName; public String departmentId; public String practiceGroup; public String title; public String grade; public String email; public String phone; public String cell; public String pager; public String managerId; [...] // Collection of BlockOutTime Dependent objects public Collection blockoutTimes; // Collection of SkillSet Dependent objects public Collection skillSets; ... private EntityContext context;// Entity Bean methods implementationpublic String ejbCreate(ResourceTO resource) throws [...] CreateException { try { this.employeeId = resource.employeeId; setResourceData(resource); getResourceDAO (...) [...]create(resource); } catch(Exception ex) { throw new EJBException("Reason:" [...] + ...); } return this.employeeId;} public String ejbFindByPrimaryKey(String primaryKey) [...] throws FinderException { boolean result; try { ResourceDAO resourceDAO = getResourceDAO (...) result = [...] resourceDAO.selectByPrimaryKey(primaryKey); } catch(Exception ex) { throw new EJBException("Reason:" [...] + ...); } if(result) { return primaryKey; } else { throw new ObjectNotFoundException(...); } } [...] public void ejbRemove (...) { try { // Remove dependent objects if(this.skillSets != null) { SkillSetDAO skillSetDAO = getSkillSetDAO (...) skillSetDAO.setResourceID(employeeId); skillSetDAO.deleteAll (...) skillSets = null; } if(this.blockoutTime != null) { BlockOutTimeDAO blockouttimeDAO = [...] getBlockOutTimeDAO (...) blockouttimeDAO.setResourceID(employeeId); blockouttimeDAO.deleteAll (...) blockOutTimes = null; } // Remove the resource from the persistent store ResourceDAO resourceDAO = new [...] ResourceDAO(employeeId); resourceDAO.delete (...) } catch(ResourceException ex) { throw new EJBException("Reason:"+...); } catch(BlockOutTimeException ex) { throw new EJBException("Reason:"+...); } catch(Exception exception) { ... } } public void setEntityContext(EntityContext context) [...] { this.context = context; } [...] public void unsetEntityContext (...) { context = null; } [...] public void ejbActivate (...) { employeeId = (String)context.getPrimaryKey (...) } [...] public void ejbPassivate (...) { employeeId = null; } [...] public void ejbLoad (...) { try { // load the resource info from ResourceDAO resourceDAO = getResourceDAO (...) setResourceData((ResourceTO) [...] resourceDAO.load(employeeId)); [...] // Load other dependent objects, if necessary ... } catch(Exception ex) { throw new EJBException("Reason:" [...] + ...); } } [...] public void ejbStore (...) { try { // Store resource information getResourceDAO (...) [...]update(getResourceData (...) [...] ); // Store dependent objects as needed ... } catch(SkillSetException ex) { throw new EJBException("Reason:" [...] + ...); } catch(BlockOutTimeException ex) { throw new EJBException("Reason:" [...] + ...); } ... } public void ejbPostCreate(ResourceTO resource) { } // Method to Get Resource Transfer Object public ResourceTO getResourceTO (...) { // create a new Resource Transfer Object ResourceTO resourceTO = new [...] ResourceTO(employeeId); // copy all values [...] resourceTO.lastName = lastName; resourceTO.firstName = firstName; resourceTO.departmentId = departmentId; ... return resourceTO; } public void setResourceData(ResourceTO resourceTO) { // copy values from Transfer Object into entity bean employeeId = resourceTO.employeeId; lastName = resourceTO.lastName; ... } // Method to get dependent Transfer Objects public Collection getSkillSetsData (...) { // If skillSets is not loaded, load it first. // See <b>Lazy</b> <b>Load</b> strategy implementation. return skillSets; [...] } ... // other get and set methods as needed ... // Entity bean business methods public void addBlockOutTimes(Collection moreBOTs) [...] throws BlockOutTimeException { // Note: moreBOTs {{is a collection of}} [...] // BlockOutTimeTO objects try { Iterator moreIter = moreBOTs.iterator (...) while(moreIter.hasNext (...) [...] ) { BlockOutTimeTO botTO = (BlockOutTimeTO) [...] moreIter.next (...) if (! (blockOutTimeExists(botTO))) { // add BlockOutTimeTO to collection botTO.setNew (...) blockOutTime.add(botTO); } else { // BlockOutTimeTO already exists, cannot add throw new BlockOutTimeException(...); } } } catch(Exception exception) { throw new EJBException(...); } } public void addSkillSet(Collection moreSkills) [...] throws SkillSetException { // similar to addBlockOutTime (...) implementation ... } ... public void updateBlockOutTime(Collection updBOTs) [...] throws BlockOutTimeException { try { Iterator botIter = blockOutTimes.iterator (...) Iterator updIter = updBOTs.iterator (...) while (updIter.hasNext (...) [...] ) { BlockOutTimeTO botTO = (BlockOutTimeTO) updIter.next (...) while (botIter.hasNext (...) [...] ) { BlockOutTimeTO existingBOT = [...] (BlockOutTimeTO) botIter.next (...) // compare key values to locate BlockOutTime if (existingBOT.equals(botTO)) { // Found BlockOutTime in collection // replace old BlockOutTimeTO with new one botTO.setDirty (...) //modified old dependent botTO.resetNew (...) //not a new dependent existingBOT = botTO; } } } } catch (Exception exc) { throw new EJBException(...); } } public void updateSkillSet(Collection updSkills) [...] throws CommitmentException { // similar to updateBlockOutTime..... } ...} ...|$|E
40|$|Chile. Abstract. In this paper, {{we present}} a study of {{information}} sharing policies used by well-known load balancing systems. Our approach comes from analyzing the performance scalability of: response time (time of reaction against instabilities) and bandwidth, from a communication-intensive application context. We divided the policies into: Centralized or Distributed oriented; and Eager or <b>Lazy</b> <b>load</b> in-formation sharing. We implement them with an asynchronous communication middleware called ProActive. Our experimental results show that Eager Dis-tributed oriented policies have better performance (response time and bandwidth usage) ...|$|E
40|$|The {{purpose of}} this {{bachelor}} thesis is to give a description of architecture of access to data sources in Zend Framework and its creation based on design patterns described by Martin Fowler. The first part introduces the creation of fundamental components of architecture for access to data sources; there are four possibilities offered by Martin Fowler: Table Data Gateway, Row Data Gateway, Active Record and Data Mapper. The first part also describes the implementation in Zend Framework and selection of patterns Table Data Gateway and Row Data Gateway. The posibility of their cooperation with domain objects is also discussed. The second part is about extending the architecture's structure and behavior of its objects. Pattern Query Object and its likeness with class Zend_Db_Select follows. There is also presented <b>Lazy</b> <b>load</b> pattern and the posibility of its implemetation with Zend Framework and domain objects. Lastly, the implementation of Identity Map pattern is described...|$|E
5000|$|<b>Lazy</b> <b>loading</b> {{allows the}} {{specification}} of modules {{that should not}} be loaded into memory by default when a project is started. Module elements are only loaded as they are specifically requested.|$|R
50|$|<b>Lazy</b> <b>loading</b> is {{a design}} pattern {{commonly}} used in computer programming to defer initialization of an object until {{the point at which}} it is needed. It can contribute to efficiency in the program's operation if properly and appropriately used. The opposite of <b>lazy</b> <b>loading</b> is eager loading. The performance gains are especially significant if the initialization of the object is costly, such as in case of accessing network services. This makes it ideal in use cases where network content is accessed and initialization times are to be kept at a minimum, such as in case of web pages.|$|R
50|$|If the {{requested}} data {{has already been}} loaded from the database, the identity map returns the same instance of the already instantiated object, but if {{it has not been}} loaded yet, it loads it and stores the new object in the map. In this way, it follows a similar principle to <b>lazy</b> <b>loading.</b>|$|R
40|$|International audienceNew {{applications}} where {{anyone can}} broadcast video are becoming very popular on smartphones. With {{the advent of}} high definition video, ISP providers may {{take the opportunity to}} propose new high quality broadcast services to their clients. Because of its centralized control plane, Software Defined Networking (SDN) seems an ideal way to deploy such a service in a flexible and bandwidth-efficient way. But deploying large scale multicast services on SDN requires smart group membership management and a bandwidth reservation mechanism to support QoS guarantees that should neither waste bandwidth nor impact too severely best effort traffic. In this paper, we propose a Network Function Virtualization based solution for Software Defined ISP networks to implement scalable multicast group management. Then, we propose the <b>Lazy</b> <b>Load</b> balancing Multicast (L 2 BM) routing algorithm for sharing the network capacity in a friendly way between guaranteed-bandwidth multicast traffic and best-effort traffic. Our implementation of the framework made on Floodlight controllers and Open vSwitches is used to study the performance of L 2 BM...|$|E
30|$|The API {{follows the}} Representational State Transfer (REST) {{architectural}} design [9]. We designed a RESTful API over HTTP using JSON. Hence, {{for each of}} the presented models we designed various methods to obtain data by providing certain parameters. Many of the parameters are common between the POIs, Events and Itineraries, such as the ability to search for each one of them using a category reference, a description or using geographic boundaries(e.g. coordinates and radius or a polygon). Also, we have provided limitation parameters to allow applications to <b>lazy</b> <b>load</b> the data presented by the API. Of course, there are some parameters that are specific to the data model (e.g. if we search using a description of the POIs, one can ask for either the minimal or complete version {{or in the case of}} the Events, we can search using time spans). Furthermore, and for both POIs and Events, one can also search for the relation of a single POI/Event with other POIs/Events. E.g. a set of concerts may be children of a music festival event, or a set of parishes may be children of a city POI. One final method is the ability to search using a Quick Response (QR) Code or an one-dimensional barcode. Using a single method and providing the textual or code information, we retrieve any POIs, Events or Itinerary that matches such information. As for the categorization models, we have provided methods to retrieve the categorical information {{for each of the}} aforementioned models.|$|E
40|$|International audience—New {{applications}} where {{anyone can}} broadcast {{high quality video}} are becoming very popular. ISPs may {{take the opportunity to}} propose new high quality multicast services to their clients. Because of its centralized control plane, Software Defined Networking (SDN) enables the deployment of such a service in a flexible and bandwidth-efficient way. But deploying large-scale multicast services on SDN requires smart group membership management and a bandwidth reservation mechanism with QoS guarantees that should neither waste bandwidth nor impact too severely best effort traffic. In this paper, we propose; (1) a scalable multicast group management mechanism based on a Network Function Virtualization (NFV) approach for Software Defined ISP networks to implement and deploy multicast services on the network edge, and (2) the <b>Lazy</b> <b>Load</b> Balancing Multicast (L 2 BM) routing algorithm for sharing the core network capacity in a friendly way between guaranteed-bandwidth multicast traffic and best-effort traffic and that does not require costly real-time monitoring of link utilization. We have implemented the mechanism and algorithm, and evaluated them both in a simulator and a testbed. In the testbed, we experimented the group management at the edge and L 2 BM in the core with an Open vSwitch based QoS framework and evaluated the performance of L 2 BM with an exhaustive set of experiments on various realistic scenarios. The results show that L 2 BM outperforms other state-of-the art algorithms by being less aggressive with best-effort traffic and accepting about 5 - 15 % more guaranteed-bandwidth multicast join requests...|$|E
5000|$|Time To First Byte is so {{important}} that some webpages have forgone eager <b>loading</b> for <b>lazy</b> <b>loading</b> {{in an attempt to}} make their content appear to load faster. This is helpful with webpages that have many images and large amounts of data. However, there are several reasons that TTFB can be high: ...|$|R
30|$|Additionally for the ONDMs, {{we observe}} an {{increase}} in read overhead for the more complex query on the single node for Kundera and Eclipselink. As it turns out EclipseLink is less efficient than Kundera in handling the more complex query. Furthermore, DataNucleus shows a higher increase in performance overhead, as the query is translated to a more complex expression tree first, and secondly due to the additional read from its <b>lazy</b> <b>loading</b> approach.|$|R
40|$|This diploma thesis {{deals with}} the design and {{implementation}} of a framework for the database persistence layer development. This framework is easy to use while keeping the code elegance. It supports object oriented programming features such as inheritance and collections. Other features include versioning of objects and <b>lazy</b> <b>loading.</b> The object metadata are obtained through reflection provided by the. NET framework. The framework is not using any literal for identification (classes, attributes) even in object queries. Most of checks are done by compiler...|$|R
40|$|The largest {{supercomputers}} have {{millions of}} independent processors, and concurrency levels are rapidly increasing. For ideal efficiency, developers of the simulations {{that run on}} these machines must ensure that computational work is evenly balanced among processors. Assigning work evenly is challenging because many large modern parallel codes simulate behavior of physical systems that evolve over time, and their workloads change over time. Furthermore, the cost of imbalanced load increases with scale because most large-scale scientific simulations today use a Single Program Multiple Data (SPMD) parallel programming model, and {{an increasing number of}} processors will wait for the slowest one at the synchronization points. To address load imbalance, many large-scale parallel applications use dynamic load balance algorithms to redistribute work evenly. The research objective of this dissertation is to develop methods to decide when and how to load balance the application, and to balance it effectively and affordably. We measure and evaluate the computational load of the application, and develop strategies to decide when and how to correct the imbalance. Depending on the simulation, a fast, local load balance algorithm may be suitable, or a more sophisticated and expensive algorithm may be required. We developed a model for comparison of load balance algorithms for a specific state of the simulation that enables the selection of a balancing algorithm that will minimize overall runtime. Dynamic load balancing of parallel applications becomes more critical at scale, while also being expensive. To make the load balance correction affordable at scale, we propose a <b>lazy</b> <b>load</b> balancing strategy that evaluates the imbalance and computes the new assignment of work to processes asynchronously to the main application computation. We decouple the load balance algorithm from the application and run it on potentially fewer, separate processors. In this Multiple Program Multiple Data (MPMD) configuration, the load balance algorithm can execute concurrently with the application and with higher parallel efficiency than if it were run on the same processors as the simulation. Work is reassigned lazily as directions become available, and the application need not wait for the load balance algorithm to complete. We show that we can save resources by running a load balance algorithm at higher parallel efficiency on a smaller number of processors. Using our framework, we explore the trade-offs of load balancing configurations and demonstrate a performance improvement of up to 46 %...|$|E
40|$|This major release {{includes}} {{five months}} worth of enhancements and bug fixes from 24 contributors, including some significant {{changes that are}} not fully backwards compatible. Highlights include: Coordinates are now optional in the xarray data model, even for dimensions. Changes to caching, <b>lazy</b> <b>loading</b> and pickling to improve xarray's experience for parallel computing. Improvements for accessing and manipulating pandas. MultiIndex levels. Many new methods and functions, including quantile(), cumsum(), cumprod() combine_first set_index(), reset_index(), reorder_levels(), full_like(), zeros_like(), ones_like() open_dataarray(), compute(), Dataset. info(), testing. assert_equal(), testing. assert_identical(), and testing. assert_allclose(). For more details, see what's new...|$|R
50|$|The proxy class ProxyImage {{is running}} on another system {{than the real}} image class itself and can {{represent}} the real image RealImage over there. The image information is accessed from the disk. Using the proxy pattern, the code of the ProxyImage avoids multiple loading of the image, accessing it from the other system in a memory-saving manner. It should be noted, however, that the <b>lazy</b> <b>loading</b> demonstrated in this example {{is not part of}} the proxy pattern, but is merely an advantage made possible by the use of the proxy.|$|R
30|$|Additionally, DataNucleus {{makes use}} of a <b>lazy</b> query <b>loading</b> {{approach}} to avoid memory conflicts. As a result, it executes a second read call to verify {{if there are any}} records remaining.|$|R
50|$|In {{computer}} operating systems, {{demand paging}} (as opposed to anticipatory paging) {{is a method}} of virtual memory management. In a system that uses demand paging, the operating system copies a disk page into physical memory only if an attempt is made to access it and that page is not already in memory (i.e., if a page fault occurs). It follows that a process begins execution with none of its pages in physical memory, and many page faults will occur until most of a process's working set of pages is located in physical memory. This {{is an example of}} a <b>lazy</b> <b>loading</b> technique.|$|R
40|$|ABSTRACT The Java Virtual Machine (JVM) has a {{novel and}} {{powerful}} mechanism to support <b>lazy,</b> dynamic class <b>loading</b> according to user-definable policies. Class loading directly impacts type safety, {{on which the}} security of Java applications is based. Conceptual bugs in the loading mechanism were found in earlier versions of the JVM that lead to type violations. A {{deeper understanding of the}} class loading mechanism, through such means as formal analysis, will improve our confidence that no additional bugs are present. The work presented in this paper provides a formal specification of (the relevant aspects of) class loading in the JVM and proves its type safety. Our approach to proving type safety is different from the usual ones since classes are dynamically loaded and full type information may not be statically available. In addition, we propose an improvement in the interaction between class loading and bytecode verification, which is cleaner and enables <b>lazier</b> <b>loading...</b>|$|R
40|$|Abstract. The Java Virtual Machine (JVM) has a {{novel and}} {{powerful}} mechanism to support <b>lazy,</b> dynamic class <b>loading</b> according to user-definable policies. Class loading directly impacts type safety, {{on which the}} security of Java applications is based. Conceptual bugs in the loading mechanism were found in earlier versions of the JVM that lead to type violations. A {{deeper understanding of the}} class loading mechanism, through such means as formal analysis, will improve our confidence that no additional bugs are present. The work presented in this paper provides a formal specification of (the relevant aspects of) class loading in the JVM and proves its type safety. Our approach to proving type safety is different from the usual ones since classes are dynamically loaded and full type information may not be statically available. In addition, we propose an improvement in the interaction between class loading and bytecode verification, which is cleaner and enables <b>lazier</b> <b>loading.</b> 1 Introduction The Java Virtual Machine (JVM) has a novel and powerful class loading mechanism. Class loading is the process of obtaining a representation of a class (declaration), called a class file, and installing that representation within the JVM. The JVM allows <b>lazy,</b> dynamic <b>loading</b> of classes, user-definable loading policies, and a form of name space separation using loaders. According to both the Java and JVM specifications [12, 15] distinct loaded classes may have the same name, and within an executing JVM each loaded class is identified by its name plus the class loader that has loaded it...|$|R
40|$|The models@run. time {{paradigm}} {{promotes the}} use of models during the execution of cyber-physical systems to represent their context and to reason about their runtime behaviour. However, current modeling techniques do not allow to cope {{at the same time}} with the large-scale, distributed, and constantly changing nature of these systems. In this paper, we introduce a distributed models@run. time approach, combining ideas from reactive programming, peer-to-peer distribution, and large-scale models@run. time. We define distributed models as observable streams of chunks that are exchanged between nodes in a peer-to-peer manner. <b>lazy</b> <b>loading</b> strategy allows to transparently access the complete virtual model from every node, although chunks are actually distributed across nodes. Observers and automatic reloading of chunks enable a reactive programming style. We integrated our approach into the Kevoree Modeling Framework and demonstrate that it enables frequently changing, reactive distributed models that can scale to millions of elements and several thousand nodes...|$|R
40|$|This paper {{presents}} a new, inexpensive, mechanism for constructing a complete call graph for Java programs at runtime, and {{provides an example}} of using the mechanism for implementing a dynamic reachability-based interprocedural analysis (IPA), namely dynamic XTA. Reachability-based IPAs, such as points-to analysis and escape analysis, require a context-insensitive call graph of the analyzed program. Computing a call graph at runtime presents several challenges. First, the overhead must be low. Second, when implementing the mechanism for languages such as Java, both polymorphism and <b>lazy</b> class <b>loading</b> must be dealt with correctly and efficiently. We propose a new, low-cost, mechanism for constructing runtime call graphs in a JIT environment. The mechanism uses a profiling code stub to capture the first execution of a call edge, and adds at most one more instruction to repeated call edge invocations. Polymorphism and <b>lazy</b> class <b>loading</b> are handled transparently. The call graph is constructed incrementally, and it supports optimistic analysis and speculative optimizations with invalidations. We also developed a dynamic, reachability-based type analysis, dynamic XTA, as an application of runtime call graphs. It also serves as an example of handling <b>lazy</b> class <b>loading</b> in dynamic IPAs. The dynamic call graph construction algorithm and dynamic version of XTA have been implemented in Jikes RVM. We present empirical measurements of the overhead of call graph profiling and compare the characteristics of call graphs built using our profiling code stubs with conservative ones constructed by using dynamic class hierarchy analysis (CHA) ...|$|R
40|$|Dynamic class loading is an {{integral}} part of the Java TM programming language, oering a number of advantages such as <b>lazy</b> class <b>loading</b> and dynamic installation of software components. Unfortunately, these advantages often come at the cost of decreased performance because certain optimizations become more dicult to perform when an optimizing compiler cannot assume that it has seen the whole program...|$|R
40|$|International audienceSmart {{systems are}} characterised by {{their ability to}} analyse {{measured}} data in live and to react to changes according to expert rules. Therefore, such systems exploit appropriate data models together with actions, triggered by domain-related conditions. The challenge at hand is that smart systems usually need to process thousands of updates to detect which rules need to be triggered, often even on restricted hardware like a Raspberry Pi. Despite various approaches have been investigated to efficiently check conditions on data models, they either assume to fit into main memory or rely on high latency persistence storage systems that severely damage the reactivity of smart systems. To tackle this challenge, we propose a novel composition process, which weaves executable rules into a data model with <b>lazy</b> <b>loading</b> abilities. We quantitatively show, on a smart building case study, that our approach can handle, at low latency, big sets of rules on top of large-scale data models on restricted hardware...|$|R
40|$|Smart {{systems are}} characterised by {{their ability to}} analyse {{measured}} data in live and to react to changes according to expert rules. Therefore, such systems exploit appropriate data models together with actions, triggered by domain-related conditions. The challenge at hand is that smart systems usually need to process thousands of updates to detect which rules need to be triggered, often even on restricted hardware like a Raspberry Pi. Despite various approaches have been investigated to efficiently check conditions on data models, they either assume to fit into main memory or rely on high latency persistence storage systems that severely damage the reactivity of smart systems. To tackle this challenge, we propose a novel composition process, which weaves executable rules into a data model with <b>lazy</b> <b>loading</b> abilities. We quantitatively show, on a smart building case study, that our approach can handle, at low latency, big sets of rules on top of large-scale data models on restricted hardware. Comment: pre-print version, published in the proceedings of MOMO- 17 Worksho...|$|R
40|$|The aim of {{this project}} is to {{investigate}} the feasibility of retrieving unstructured automotive listings from structured web pages on the Internet. The research has two major purposes: (1) to investigate whether it is feasible to pair information extraction algorithms and compute wrappers (2) demonstrate the results of pairing these techniques and evaluate the measurements. We merge two training sets available on the web to construct reference sets which {{is the basis for}} the information extraction. The wrappers are computed by using information extraction techniques to identify data properties with a variety of techniques such as fuzzy string matching, regular expressions and document tree analysis. The results demonstrate {{that it is possible to}} pair these techniques successfully and retrieve the majority of the listings. Additionally, the findings also suggest that many platforms utilise <b>lazy</b> <b>loading</b> to populate image resources which the algorithm is unable to capture. In conclusion, the study demonstrated that it is possible to use information extraction to compute wrappers dynamically by identifying data properties. Furthermore, the study demonstrates the ability to open non-queryable domain data through a unified service...|$|R
50|$|The {{following}} example {{represents an}} n-to-1 relationship between movies and their directors. It is shown how user-defined Python classes create corresponding database tables, how instances with relationships are created {{from either side}} of the relationship, and finally how the data can be queried—illustrating automatically-generated SQL queries for both <b>lazy</b> and eager <b>loading.</b>|$|R
40|$|XML Store is a {{distributed}} value-oriented {{storage facility}} for storing XML docu-ments. XML documents stored in XML Store {{can be accessed}} and manipulated using the Document Value Model (DVM). This thesis illustrates that such a storage facility can be constructed. The value-oriented programming model, proposed have shown advantages over traditional imperative models for work-ing with persisted and distributed XML document. These advantages are easy caching and replication (as no coherence protocols are needed), <b>lazy</b> <b>loading</b> of documents, transparent persistence and distribution and sharing of documents. Acknowledgements A few people have influenced this thesis and we are grateful for their contribu-tions. The guidance and advices (technical and non-technical) of our respective supervisors Michael R. Hansen and Fritz Henglein have been skill full and {{very important to the}} outcome of the thesis. Fritz Henglein provided the initial inspiration for the thesis, which we are grateful for. During the period of the thesis much time have been spent with the newly graduated candidates Mikkel Fennestad, Tine Thorn and Anders Baumann. We thank them for their inspiration and fruitful discussions of value-oriented programming, manipulation and storage of Extensible Markup Language (XML) documents and XML related technologies. A special thanks goes to Brian Christensen for spending his vacation on helping with setting up the report and to Thejs W. Jansen, Martin Skøtt, Petar Kadijevic and Kinnie Bak Pedersen for reviewing of the different versions of the thesis and giving valuable feedback. 1 Preface This Master Thesis concerns {{the development and implementation of}} a value-oriented Application Programming Interface (API), which is convenient for ac-cess, manipulation and storage of XML documents in distributed environments. The Master Thesis is the outcome of a project across Universities. It has been written by Jesper Tejlgaard Pedersen from the Technical University of Denmark (DTU) and Kasper Bøgebjerg Pedersen from the IT-University o...|$|R
40|$|Abstract Dynamic class loading is an {{integral}} part of the JavaTM programming language, offering a number advantages such as <b>lazy</b> class <b>loading</b> and dynamic installation of software components. Unfortunately, these advantages often come at the cost of decreased performance because certain optimizations become more difficult to perform when an optimizing compiler cannot assume that it has seen the whole program. This paper introduces thin guards, a simple but effective technique that uses lightweight runtime tests to identify regions of code within which speculative optimizations can be performed. One application of thin guards is described in detail, demonstrating how they can be used to perform speculative inlining in the presence of dynamic class loading. Our experimental evaluation shows that when used in combination with other traditional compiler optimizations, thin guards can eliminate most of the penalty dynamic class loading. Performance improvements of up to 27 % are observed, eliminating up to 92 % of the penalty imposed by dynamic class loading. 1 Introduction Dynamic class loading [19] is {{an integral}} part of the Java programming language, offering a number advantages such as <b>lazy</b> class <b>loading</b> and dynamic installation of software components. Unfortunately, these advantages often come at the cost of decreased performance because certain optimizations become more difficult to perform when an optimizing compiler cannot assume that it has seen the whole program. Object-oriented languages encourage data encapsulation through the use of methods, resulting in frequent method invocations. Additionally, object-oriented languages support dynamically dispatched (virtual) calls, where the method called depends on the runtime type of the receiver object. Efficient implementations of virtual dispatch [11, 14] help reduce the direct overhead of virtual method invocation, however, method inlining remains an important optimization for effective implementation of object oriented languages...|$|R
40|$|The CACAO Java Virtual Machine was {{designed}} as a 64 -bit Java Virtual Machine on the Institut für Computersprachen der Technischen Universität Wien in 1996. The primary intent of CACAO was to build the fastest Just-In-Time compiler available {{at this time of the}} Alpha architecture. This document describes some optimizations and enhancements implemented in CACAO like <b>lazy</b> class <b>loading</b> and instruction combining with constant operands to speed up compile and run time. Furthermore experiences of porting the CACAO Java Virtual Machine to two new architectures are presented. These new architectures are the IA 32 and AMD 64 architecture. Especially the porting to the IA 32 architecture is interesting because a 32 -bit architecture is not a preferred target architecture for CACAO. Finally the implemented optimizations and the ports are evaluated agains...|$|R
40|$|Dynamic class loading is an {{integral}} part of the Java programming language, offering a number advantages such as <b>lazy</b> class <b>loading</b> and dynamic installation of software components. Unfortunately, these advantages often come at the cost of decreased performance because certain optimizations become more dicult to perform when an optimizing compiler cannot assume that it has seen the whole program. This paper introduces thin guards, a simple but effective technique that uses lightweight runtime tests to identify regions of code within which speculative optimizations can be performed. One application of thin guards is described in detail, demonstrating how they can be used to perform speculative inlining in the presence of dynamic class loading. Our experimental evaluation shows that when used in combination with other traditional compiler optimizations, thin guards can eliminate most of the penalty dynamic class loading. Performance improvements of up to 27 % are observed, eliminating up to 92 % of the penalty imposed by dynamic class loading...|$|R
