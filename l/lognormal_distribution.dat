1557|791|Public
25|$|In {{reliability}} analysis, the <b>lognormal</b> <b>distribution</b> {{is often}} used to model times to repair a maintainable system.|$|E
25|$|For example, {{log-normal}} distributions {{are often}} mistaken for power-law distributions: a data set {{drawn from a}} <b>lognormal</b> <b>distribution</b> will be approximately linear for large values (corresponding to the upper tail of the lognormal being close to a power law), but for small values the lognormal will drop off significantly (bowing down), corresponding to the lower tail of the lognormal being small (there are very few small values, rather than many small values in a power law).|$|E
2500|$|<b>Lognormal</b> <b>{{distribution}}</b> is {{a special}} case of semi-bounded Johnson distribution ...|$|E
40|$|Problem statement: The {{modeling}} of claims {{is an important}} task of actuaries. Our problem is in modelling the actual motor insurance claim data set. In this study, we show that the actual motor insurance claim can be fitted by a finite mixture model. Approach: Firstly, we analyse the actual data set and then we choose the finite mixture <b>Lognormal</b> <b>distributions</b> as our model. The estimated parameters of the model are obtained from the EM algorithm. Then, we use the K-S and A-D test for showing how well the finite mixture <b>Lognormal</b> <b>distributions</b> fit the actual data set. We also mention the bootstrap technique in estimating the parameters. Results: From the tests, {{we found that the}} finite mixture <b>lognormal</b> <b>distributions</b> fit the actual data set with significant level 0. 10. Conclusion: The finite mixture <b>Lognormal</b> <b>distributions</b> can be fitted to motor insurance claims and this fitting is better when the number of components (k) are increase...|$|R
40|$|This paper {{studies the}} pricing of European-style options using mixed <b>lognormal</b> <b>distributions.</b> We {{advocate}} such distributions as a computationally {{efficient way to}} calculate prices of such options: we derive higher truncated moments in analytic form, explain {{how to use them}} to derive closed-form approximations of European-style options and construct sequence of mixed <b>lognormal</b> <b>distributions</b> that approximate the terminal distribution of a stock that follows either a Black-Scholes model with jumps or one with stochastic volatility...|$|R
3000|$|The {{normal and}} <b>lognormal</b> <b>distributions</b> are {{generally}} adopted as parametric statistical {{model in the}} analysis of mechanical properties. The probability density function [...]...|$|R
2500|$|Aitchison, J. and Brown, J.A.C. (1957) [...] The <b>Lognormal</b> <b>Distribution,</b> Cambridge University Press.|$|E
2500|$|Shockley {{was first}} to propose a <b>lognormal</b> <b>distribution</b> to model the {{creation}} process for scientific research papers.|$|E
2500|$|In {{wireless}} communication, [...] "the local-mean power {{expressed in}} logarithmic values, such as dB or neper, has a normal (i.e., Gaussian) distribution." [...] Also, the random obstruction of radio signals due to large buildings and hills, called shadowing, is often modeled as a <b>lognormal</b> <b>distribution.</b>|$|E
40|$|A {{simple method}} {{for using a}} random sample to select a {{sampling}} distribution model from between the <b>lognormal</b> and Weibull <b>distributions</b> is developed. Simulation studies demonstrate that it performs {{just as well as}} more complicated alternatives. <b>lognormal</b> <b>distributions</b> order statistics averages sampling distribution model selection Weibull distribution...|$|R
3000|$|The {{value of}} (R_i / P_i)- 1 {{increases}} and then decreases as a_i / (n+ 1) [...] increases when {{the alternative is}} normal and <b>lognormal</b> <b>distributions.</b> But the value of (R_i / P_i)- 1 decreases and then increases as a_i / (n+ 1) [...] increases when the alternative is Weibull and beta distributions. The normal alternative <b>distribution</b> and the <b>lognormal</b> alternative <b>distribution</b> are similar.|$|R
40|$|In this paper, {{we present}} {{data for the}} <b>lognormal</b> <b>distributions</b> of spike rates, {{synaptic}} weights and intrinsic excitability (gain) for neurons in various brain areas, such as auditory or visual cortex, hippocampus, cerebellum, striatum, midbrain nuclei. We find a remarkable consistency of heavy-tailed, specifically <b>lognormal,</b> <b>distributions</b> for rates, weights and gains in all brain areas examined. The difference between strongly recurrent and feed-forward connectivity (cortex vs. striatum and cerebellum), neurotransmitter (GABA (striatum) or glutamate (cortex)) or the level of activation (low in cortex, high in Purkinje cells and midbrain nuclei) {{turns out to be}} irrelevant for this feature. Logarithmic scale distribution of weights and gains appears to be a general, functional property in all cases analyzed. We then created a generic neural model to investigate adaptive learning rules that create and maintain <b>lognormal</b> <b>distributions.</b> We conclusively demonstrate that not only weights, but also intrinsic gains, need to have strong Hebbian learning in order to produce and maintain the experimentally attested distributions. This provides a solution to the long-standing question about the type of plasticity exhibited by intrinsic excitability...|$|R
2500|$|For highly {{communicable}} epidemics, such as SARS in 2003, if publication {{intervention is}} involved, {{the number of}} hospitalized cases is shown to satisfy the <b>lognormal</b> <b>distribution</b> with no free parameters if an entropy is assumed and the standard deviation {{is determined by the}} principle of maximum rate of entropy production.|$|E
2500|$|Preston's {{theory has}} an {{interesting}} application: if a community is truly lognormal yet under-sampled, the <b>lognormal</b> <b>distribution</b> {{can be used}} to estimate the true species richness of a community. Assuming the shape of the total distribution can be confidently predicted from the collected data, the normal curve can be fit via statistical software or by completing the Gaussian formula: ...|$|E
2500|$|This can {{be derived}} by letting [...] within the integral. However, the {{expected}} value [...] is not defined for any positive value of the argument [...] as the defining integral diverges. [...] In consequence the moment generating function is not defined. [...] The last {{is related to the}} fact that the <b>lognormal</b> <b>distribution</b> is not uniquely determined by its moments.|$|E
3000|$|... where P(·,·) is the {{incomplete}} gamma function. Nakagami is {{a general}} fading distribution that reduces to the Rayleigh for m= 1 and to the one-sided normal distribution for m= 0.5. It also approximates the Rician and <b>lognormal</b> <b>distributions.</b>|$|R
50|$|The skew <b>lognormal</b> cascade <b>distribution.</b>|$|R
3000|$|We {{can improve}} {{predictions}} from early votes {{by using the}} <b>lognormal</b> <b>distributions</b> of r-values, shown in Figure 9, as the prior probability to combine with the likelihood from the observations according to Bayes theorem. Specifically, instead of maximizing {{the likelihood of the}} observed votes, [...]...|$|R
2500|$|In {{probability}} theory, a log-normal (or <b>lognormal)</b> <b>distribution</b> is {{a continuous}} probability distribution of a random variable whose logarithm is normally distributed. Thus, if the random variable [...] is log-normally distributed, then [...] has a normal distribution. Likewise, if [...] has a normal distribution, then the exponential function of , , has a log-normal distribution. A random variable which is log-normally distributed takes only positive real values. The distribution is occasionally {{referred to as}} the Galton distribution or Galton's distribution, after Francis Galton. The log-normal distribution also has been associated with other names, such as McAlister, Gibrat and Cobb–Douglas.|$|E
2500|$|In applications, [...] is a {{parameter}} to be determined. In {{cases that}} [...] {{there are no}} data to determine this parameter, {{it is possible to}} evaluate it from some universal principle. One is the entropy method. [...] For growing processes which are governed by production and dissipation, it was shown that one can use some extremal principle of Shannon entropy to determine this parameter to be [...] This value can then be used to give some scaling relation between the inflexion point and maximum point of the <b>lognormal</b> <b>distribution.</b> It is shown that this relationship is determined by the base of natural logarithm, , and exhibits some geometrical similarity to the minimal surface energy principle. These scaling relations are shown to be useful for predicting a number of growth processes [...] (epidemic spreading, droplet splashing, population growth, swirling rate of the bathtub vortex, distribution of language characters, velocity profile of turbulences, etc.). [...] For instance, the lognormal function with such [...] fits well with the size of secondary produced droplet during droplet impact [...] and the spreading of one epidemic disease.|$|E
2500|$|The same {{relationship}} {{occurs in}} many other rankings unrelated to language, such as the population ranks of cities in various countries, corporation sizes, income rankings, ranks of number of people watching the same TV channel, and so on. The appearance of the distribution in rankings of cities by population was first noticed by Felix Auerbach in 1913. Empirically, a data set can be tested to see whether Zipf's law applies by checking the goodness of fit of an empirical distribution to the hypothesized power law distribution with a Kolmogorov-Smirnov test, and then comparing the (log) likelihood ratio of the power law distribution to alternative distributions like an exponential distribution or <b>lognormal</b> <b>distribution.</b> When Zipf's law is checked for cities, a better fit has been found with exponent s = 1.07; i.e. the [...] largest settlement is [...] {{the size of the}} largest settlement. While Zipf's law holds for the upper tail of the distribution, the entire distribution of cities is log-normal and follows Gibrat's law. Both laws are consistent because a log-normal tail can typically not be distinguished from a Pareto (Zipf) tail.|$|E
2500|$|The two {{parameters}} [...] and [...] are not {{location and}} scale parameters for a lognormally distributed random variableX, {{but they are}} respectively location and scale parameters for the normally distributed logarithmlnX. The quantity e is a scale parameter for the family of <b>lognormal</b> <b>distributions.</b>|$|R
40|$|The {{statistics}} involving random multiplicative stochastic processes {{have been}} studied empirically. Examples taken here are the duration distribution of disability for aged people, {{the life span of}} animals and the population distribution of prefectures in Post-World War II Japan. We found that <b>lognormal</b> <b>distributions</b> show excellent fit with various data for the duration distribution of disability and the life span of animals. The good data fitting for both cases by <b>lognormal</b> <b>distributions</b> indicates that the incidence of both events can be considered as many independent subprocesses in succession. We also found that a twolognormals distribution fits very well over the entire region for the population distribution of prefectures in post-war Japan. This result implies that in this case the size segregation is also relevant, in addition to the random multiplicative stochastic processes...|$|R
5000|$|... #Subtitle level 3: XS premium using <b>Lognormal</b> cost <b>distribution</b> ...|$|R
5000|$|The <b>Lognormal</b> <b>Distribution,</b> Aitchison, J. and Brown, J.A.C. (1957) ...|$|E
5000|$|<b>Lognormal</b> <b>{{distribution}}</b> is {{a special}} case of semi-bounded Johnson distribution ...|$|E
5000|$|... = the {{distribution}} for the annual returns, e.g., the three-parameter <b>lognormal</b> <b>distribution.</b>|$|E
40|$|Using {{probability}} {{plots and}} Maximum Likelihood Estimation (MLE), we fit <b>LogNormal</b> <b>distributions</b> to data compiled by Ershow et al. (1991) for daily intake of total water and tap water by 3 {{groups of women}} (controls, pregnant, and lactating; all between 15 - 49 years of age) in the United States. We also develop bivariate <b>LogNormal</b> <b>distributions</b> for the joint distribution of water ingestion and body weight for these 3 groups. Overall, we recommend the marginal distributions for water intake as fit by MLE for use in human health risk assessments. Introduction and Data In 1978, the US Department of Agriculture (USDA) conducted the Nationwide Food Consumption Survey (NFCS) to gather dietary information for 7 days on individuals living in randomly assigned nonmilitary households in the contiguous 48 states. (USDA, 1980). From the database for 30, 770 persons {{who participated in the}} survey, the NFC...|$|R
40|$|In {{previous}} work on unsupervised learning of morphology, the long-tail {{pattern in the}} rank-frequency distribution of words, {{as well as of}} morphological units, is usually considered as following Zipf’s law (power-law). We argue that these long-tail distributions can also be considered as lognormal. Since we know the conjugate prior <b>distribution</b> for a <b>lognormal</b> likelihood, we propose to generate morphology data from <b>lognormal</b> <b>distributions.</b> When the performance is evaluated by a tokenbased criterion, giving more weights to the results of frequent words, the proposed model preforms significantly better than other models in discussion. Moreover, we capture the statistical properties of morphological units with a Bayesian approach, other than a rule-based approach as studied in (Chan, 2008) and (Zhao and Marcus, 2011). Given the multiplicative property of <b>lognormal</b> <b>distributions,</b> we can directly capture the long-tail distribution of word frequency, without the need of an additional generative process as studied in (Goldwater et al., 2006) ...|$|R
40|$|The {{cumulative}} probability distribution {{used to describe the}} variability of stormwater pollutant concentrations has been a matter of interest in recent years. Many predictive models attempt to estimate appropriate stormwater constituent concentrations based on land use and the amount of impervious area. The most important study that characterized stormwater was the Nationwide Urban Runoff Program (NURP) (EPA 1983). NURP was conducted throughout the U. S. and included about 2300 events from 1978 thru 1982. One of the conclusions of the final NURP report was that the event mean concentrations (EMCs) of stormwater constituents were described by <b>lognormal</b> <b>distributions.</b> This finding has been re-evaluated recently, with the conclusion that not all stormwater constituents were adequately described by <b>lognormal</b> <b>distributions</b> (Van Buren, 1997; Beherra, 2000). Stormwater managers have generally accepted the assumption of lognormality of stormwater constituent concentrations between the 5 th and 95 th percentiles. Based on this assumption, it is common to use the log-transformed EMC values to evaluate difference...|$|R
5000|$|... f(r) = the {{distribution}} for the annual returns, e.g. the three-parameter <b>lognormal</b> <b>distribution</b> ...|$|E
5000|$|... may not exist. The <b>lognormal</b> <b>distribution</b> is {{an example}} of when this occurs.|$|E
5000|$|In {{reliability}} analysis, the <b>lognormal</b> <b>distribution</b> {{is often}} used to model times to repair a maintainable system.|$|E
40|$|Distributional {{analysis}} of river discharge time series {{is an important}} task {{in many areas of}} hydrological engineering, including optimal design of water storage and drainage networks, management of extreme events, risk assessment for water supply, and environmental flow management, among many others. Having diverging moments, heavy-tailed power-law distributions have attracted widespread attention, especially for the modeling of the likelihood of extreme events such as floods and droughts. However, straightforward distributional analysis does not connect well with the complicated dynamics of river flows, including fractal and multifractal behavior, chaos-like dynamics, and seasonality. To better reflect river flows 2 ̆ 7 dynamics, we propose to carry out distributional {{analysis of}} river flow time series according to three 2 ̆ 2 flow seasons 2 ̆ 2 : dry, wet, and transitional. We present a concrete statistical procedure to partition river flow data into such three seasons, and fit data in these seasons using two types of <b>distributions,</b> power-law and <b>lognormal.</b> The latter <b>distribution</b> is a salient property of the cascade multiplicative multifractal model, which is among the best models for turbulence and rainfall. We show that while both power-law and <b>lognormal</b> <b>distributions</b> are relevant to dry seasons, river flow data in wet seasons are typically better fitted by <b>lognormal</b> <b>distributions</b> than by power-law distributions. ...|$|R
40|$|An {{analysis}} of {{two days of}} in situ observations of ice particle size spectra, in convectively generated cirrus, obtained during NASA s Tropical Composition, Cloud, and Climate Coupling (TC 4) mission is presented. The observed spectra are examined for their fit to the exponential, gamma, and <b>lognormal</b> function <b>distributions.</b> Characteristic particle size and concentration density scales are determined using two (for the exponential) or three (for the gamma and lognormal functions) moments of the spectra. It is shown that transformed exponential, gamma, and <b>lognormal</b> <b>distributions</b> should collapse onto standard curves. An examination of the transformed spectra, and of deviations of the transformed spectra from the standard curves, shows that the lognormal function provides a better fit to the observed spectra...|$|R
40|$|With X^* {{denoting}} {{a random}} variable with the X-size bias distribution, what are all distributions for X {{such that it}} is possible to have X^*=X+Y, Y≥ 0, with X and Y independent? We give the answer, due to Steutel steutel, and also discuss the relations of size biasing to the waiting time paradox, renewal theory, sampling, tightness and uniform integrability, compound Poisson distributions, infinite divisibility, and the <b>lognormal</b> <b>distributions.</b> Comment: 30 page...|$|R
