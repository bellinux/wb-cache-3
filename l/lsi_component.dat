1|13|Public
40|$|Technologies {{required}} {{to support the}} stated OAST thrust to increase information return by X 1000, while reducing costs {{by a factor of}} 10 are identified. The most significant driver is the need for an overall end-to-end data system management technology. Maximum use of <b>LSI</b> <b>component</b> technology and trade-offs between hardware and software are manifest in most all considerations of technology needs. By far, the greatest need for data handling technology was identified for the space Exploration and Global Services themes. Major advances are needed in NASA's ability to provide cost effective mass reduction of space data, and automated assessment of earth looking imagery, with a concomitant reduction in cost per useful bit. A combined approach embodying end-to-end system analysis, with onboard data set selection, onboard data processing, highly parallel image processing (both ground and space), low cost, high capacity memories, and low cost user data distribution systems would be necessary...|$|E
50|$|IBM's System/370 {{follow-on}} to the System/360 used SSI ICs {{rather than}} Solid Logic Technology discrete-transistor modules. DEC's PDP-8/I and KI10 PDP-10 also switched {{from the individual}} transistors used by the PDP-8 and PDP-10 to SSI ICs, and their extremely popular PDP-11 line was originally built with SSI ICs but was eventually implemented with <b>LSI</b> <b>components</b> once these became practical.|$|R
40|$|Bit-slice logic blocks are {{fourth-generation}} <b>LSI</b> <b>components</b> {{which are}} natural extensions of traditional multiplexers, registers, decoders, counters, ALUs, etc. Their functionality {{is controlled by}} microprogramming, typically to implement CPUs and peripheral controllers where both speed and easy programmability are required for flexibility, ease of implementation and debugging, etc. Processors built from bit-slice logic give the designer an alternative for approaching the programmability of traditional fixed-instruction-set microprocessors with a speed closer to that of hardwired 'random' logic. (2 refs) ...|$|R
50|$|The {{engineers}} {{who designed the}} Fairchild F8 Microcomputer did so mindful {{of a set of}} goals. The computer needed to be electrically frugal. It needed characteristics that permitted easy interface to standard SSI and MSI components. It needed a moderate instruction set. It needed to be easy to incorporate into a design. The design needed to put the maximum number of computer components and circuits into the <b>LSI</b> <b>components</b> to minimize the package count. This approach reduced the time spent on designing support logic circuits.|$|R
40|$|Sixteen {{consecutive}} 12 -bit {{words from}} {{any part of}} a data stream are captured and held for display by a new Logic State Analyzer, greatly simplifying the task of monitoring program flow when troubleshooting complex digital processors. by William A. Farnbach AS LOW-COST MSI AND <b>LSI</b> <b>components</b> make feasible the use of more sophisticated digital processors in a broadening variety of applications, {{there is a growing}} {{need to be able to}} perceive what is happening in a digital process. With the increasing power of digital systems that is developing, the amount of data that must be understood to debug or check out a digital machine increases at a dismaying rate...|$|R
40|$|The {{structure}} of microprogrammed processors is largely {{determined by the}} state of (semiconductor) technology and the requirements of the task of emulation. We discuss the impact of <b>LSI</b> <b>components</b> on micruprogrammable processors and in par-ticular, the effect of large memory arrays, LSI microprocessors (bit-slices), programmable logic arrays, and high-speed shifters. A secondary theme of this article is that microprogramming differs very little from &quot;regular &quot; programming. We argue that the right approach to understanding microprogramming is to recognize that it is primarily applied to the task of emulation. We review the requirements of the emulation (interpretation) task and indicate what capabilities a microprogrammable processor needs to have {{in order to make the}} process of emulation efficient. We conclude with a taxonomy of microprogrammable processors...|$|R
50|$|On October 26, 2011, LSI Corporation {{announced}} {{the intent to}} acquire SandForce and by January 4, 2012, the deal was finalized with SandForce becoming the new Flash <b>Components</b> Division of <b>LSI</b> led by Michael Raam. On December 16, 2013, Avago Technologies announced its intent to acquire LSI and the deal was completed on May 6, 2014. On May 29, 2014, Seagate Technology announced it had entered into an agreement with Avago to purchase <b>LSI's</b> Flash <b>Components</b> Division.|$|R
40|$|In {{this study}} a {{comprehensive}} evaluation of two supervised feature selection methods for dimensionality reduction is performed- Latent Semantic Indexing (<b>LSI)</b> and Principal <b>Component</b> Analysis (PCA). This is gauged against unsupervised techniques like fuzzy feature clustering using hard fuzzy C-means (FCM). The main {{objective of the}} study is to estimate the relative efficiency of two supervised techniques against unsupervised fuzzy techniques while reducing the feature space. It is found that clustering using FCM leads to better accuracy in classifying documents in the face of evolutionary algorithms like LSI and PCA. Results show that the clustering of features improves the accuracy of document classification...|$|R
40|$|Numerical {{techniques}} for data analysis and feature extraction are discussed using {{the framework of}} matrix rank reduction. The singular value decomposition (SVD) and its properties are reviewed, and the relation to Latent Semantic Indexing (<b>LSI)</b> and Principal <b>Component</b> Analysis (PCA) is described. Methods that approximate the SVD are reviewed. A few basic methods for linear regression, in particular the Partial Least Squares (PLS) method, are presented, and analyzed as rank reduction methods. Methods for feature extraction, based on centroids and the classical Linear Discriminant Analysis (LDA), {{as well as an}} improved LDA based on the generalized singular value decomposition (LDA/GSVD) are described. The effectiveness of these methods are illustrated using examples from information retrieval, and 2 dimensional representation of clustered data. ...|$|R
40|$|Abstract. We {{show that}} {{eigenvector}} decomposition {{can be used}} to extract a term taxonomy from a given collection of text documents. So far, methods based on eigenvector decomposition, such as latent semantic indexing (<b>LSI)</b> or principal <b>component</b> analysis (PCA), were only known to be useful for extracting symmetric relations between terms. We give a precise mathematical criterion for distinguishing between four kinds of relations of a given pair of terms of a given collection: unrelated (car-fruit), symmetrically related (car- automobile), asymmetrically related with the first term being more specific than the second (banana- fruit), and asymmetrically related in the other direction (fruit- banana). We give theoretical evidence for the soundness of our criterion, by showing that in a simplified mathematical model the criterion does the apparently right thing. We applied our scheme to the reconstruction of a selected part of the open directory project (ODP) hierarchy, with promising results...|$|R
30|$|Grouped by {{filtering}} techniques, numeric rating based CF is broadly classified into: memory-based or neighbourhood-based and model-based. In memory-based approaches, {{recommendations are}} developed from user or item neighbourhoods, i.e. proximity (or deviation) measures between the ratings, e.g. cosine similarity, Euclidean distance and various statistical correlation coefficients. Memory-based CF {{can also be}} distinguished into: user-based and item-based. In the former, CF is performed using neighbourhood between users computed from the ratings provided by them. In item-based schemes, prediction is obtained using item neighbourhoods, i.e. proximity (or deviation) of ratings between various items. In model-based approaches, the original user-item ratings dataset is used to train a compact model, which is then used for prediction. The model is developed by methods borrowed from artificial intelligence, such as Bayesian classification, latent classes and neural networks; or, from linear algebra, e.g. singular value decomposition (SVD), latent semantic indexing (<b>LSI)</b> and principal <b>component</b> analysis (PCA). Model-based algorithms are usually fast to query but relatively slow to update.|$|R
40|$|We {{show that}} {{eigenvector}} decomposition {{can be used}} to extract a term taxonomy from a given collection of text documents. So far, methods based on eigenvector decomposition, such as latent semantic indexing (<b>LSI)</b> or principal <b>component</b> analysis (PCA), were only known to be useful for extracting symmetric relations between terms. We give a precise mathematical criterion for distinguishing between four kinds of relations of a given pair of terms of a given collection: unrelated (car - fruit), symmetrically related (car - automobile), asymmetrically related with the first term being more specific than the second (banana - fruit), and asymmetrically related in the other direction (fruit - banana). We give theoretical evidence for the soundness of our criterion, by showing that in a simplified mathematical model the criterion does the apparently right thing. We applied our scheme to the reconstruction of a selected part of the open directory project (ODP) hierarchy, with promising results...|$|R
40|$|Abstract Study 1 : The Faculty of Veterinary Medicine (FVM), Utrecht University, applies three {{selection}} methods {{with the}} aim of selecting motivated and well-performing students: â€˜direct admissionâ€™, â€˜weighted lottery procedureâ€™ (both based on secondary school GPA) and â€˜decentralised selection procedureâ€™ (based on non-cognitive criteria). As the weighted lottery will be repealed as a selection procedure in 2017, new selection methods are needed for the assessment of applicantsâ€™ study motivation and future academic performance. In this context, the first aim {{of this study was to}} evaluate the outcomes of the current FVM admission procedures, in terms of studentsâ€™ study motivation and academic performance. The second aim was to examine whether types and level of study motivation were related to academic performance, and hence whether these measurements could contribute to a selection procedure. Data from two cohorts (i. e., second- and third-year bachelor-students) at the FVM (n = 186) were obtained, including admission procedure, study motivation (measured by the Academic Motivation Scale(AMS)) and several academic outcome measures. Various univariable - and multivariable analyses were performed to examine differences in study motivation and academic performance between the three admission-groups. Spearmanâ€™s correlations and linear regression were applied to examine the relationship between study motivation and academic performance. All multivariable analyses were controlled for the effect of age and gender, if significant. The only difference in study motivation between the admission-groups regarded a stronger extrinsic motivation (EM) in lottery-admitted students, compared to decentralised selected students (P < 0. 05). Directly admitted students outperformed students from the other two admission-groups on several academic outcome measures (P < 0. 05). Only level of motivation was related to academic performance (P < 0. 05). Considering the predictive value for study success, selection based on secondary school GPA is supported; selection based on only non-cognitive criteria, however, is not recommended. The use of type of motivation as a selection criterion is not supported, considering the insignificant correlation with past academic performance. Future research should investigate the predictive validity of type of motivation for academic performance, and should reveal whether research findings are confirmed among larger samples. Abstract Study 2 : The Faculty of Veterinary Medicine (FVM), Utrecht University, applies three selection methods {{with the aim}} of selecting motivated and well-performing students: â€˜direct admissionâ€™, â€˜weighted lottery procedureâ€™ and â€˜decentralised selection procedureâ€™. As the weighted lottery will be repealed as a selection procedure in 2017, new selection methods are needed for the assessment of applicantsâ€™ study motivation and future academic performance. In this context, this study examined whether parts of the Learning Style Inventory (LSI) by Vermunt could contribute to a selection procedure. The first aim was to investigate the stability of learning components during the bachelor; the second aim was to investigate whether learning components in year 1 were related to study motivation, respectively academic performance during the bachelor. Data from two cohorts (i. e., second- and third-year bachelor-students) at the FVM (n = 177) were obtained, including scores on learning components from year 1 and year 3 of the curriculum, study motivation and several academic outcome measures. Paired T-tests were performed to examine the stability of learning components during the bachelor. Several analyses were applied to examine the relationship between learning components and study motivation, respectively academic performance, including Spearmanâ€™s correlations and linear regression. All multivariable analyses were controlled for the effect of age and gender, if significant. An increase was found in â€˜deep processingâ€™ and â€˜concrete processingâ€™ during the bachelor; a decrease was found in â€˜stepwise processingâ€™ and â€˜external regulationâ€™ (P < 0. 05). â€˜Self-regulationâ€™, â€˜deep processingâ€™ and â€˜stepwise processingâ€™ were positively related to study motivation (P < 0. 05). Furthermore, â€˜self-regulationâ€™ and â€˜stepwise processingâ€™ were positively related to academic performance (P < 0. 01), and â€˜concrete processingâ€™ and â€˜no regulationâ€™ were negatively related to academic performance (P < 0. 05). If the aim of using learning components as a selection criterion is â€˜to select students with specific learning componentsâ€™, selection based on these learning components is not recommended, due to the instability of these components. However, selection or rejection of students with specific learning components because of its relationship with study motivation or academic performance is supported. Future research should reveal whether similar conclusions can be drawn about the entire <b>LSI</b> (including four <b>components</b> of learning), and whether research findings are confirmed among larger samples...|$|R

