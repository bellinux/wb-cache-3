2783|10000|Public
25|$|This <b>logistic</b> <b>model</b> {{of growth}} is {{produced}} by a population introduced to a new habitat or with very poor numbers going through a lag phase of slow growth at first. Once it reaches a foothold population it will go through a rapid growth rate that will start to level off once the species approaches carrying capacity. The idea of maximum sustained yield is to decrease population density {{to the point of}} highest growth rate possible. This changes the number of the population, but the new number can be maintained indefinitely, ideally.|$|E
2500|$|This {{equation}} is mathematically {{equivalent to the}} <b>logistic</b> <b>model,</b> with a carrying capacity K given by ...|$|E
2500|$|For example, in {{the three}} {{parameter}} <b>logistic</b> <b>model</b> (3PL), {{the probability of a}} correct response to a dichotomous item i, usually a multiple-choice question, [...] is: ...|$|E
40|$|<b>Logistic</b> <b>models</b> are arguably one of {{the most}} widely used data {{analysis}} techniques. In this paper, we present analyses focussing on two important aspects of logistic models—its relationship with exponential family based generative models, and its performance in online and potentially adversarial settings. In particular, we present two new theoretical results on <b>logistic</b> <b>models</b> focusing on the above two aspects. First, we establish an exact connection between <b>logistic</b> <b>models</b> and exponential family based generative models, resolving a long-standing ambiguity over their relationship. Second, we show that online Bayesian <b>logistic</b> <b>models</b> are competitive to the best batch models, even in potentially adversarial settings. Further, we discuss relevant connections of our analysis to the literature on integral transforms, and also present a new optimality result for Bayesian models. The analysis makes a strong case for using <b>logistic</b> <b>models</b> and partly explains the success of such models for a wide range of practical problems. ...|$|R
40|$|The one-equation and the two-equation <b>logistic</b> <b>models</b> {{were used}} to predict subjects' {{susceptibility}} to motion sickness in KC- 135 parabolic flights using data from other ground-based motion sickness tests. The {{results show that the}} <b>logistic</b> <b>models</b> correctly predicted substantially more cases (an average of 13 percent) in the data subset used for model building. Overall, the <b>logistic</b> <b>models</b> ranged from 53 to 65 percent predictions of the three endpoint parameters, whereas the Bayes linear discriminant procedure ranged from 48 to 65 percent correct for the cross validation sample...|$|R
50|$|Late-life {{mortality}} deceleration can {{be modeled}} via modifications of the Gompertz law, using various <b>logistic</b> <b>models.</b>|$|R
2500|$|However, in {{the case}} of a <b>logistic</b> <b>model,</b> where [...] cannot be greater than 1, R1 is between 0 and : thus, Nagelkerkesuggested the {{possibility}} to define a scaled R2 as R²/R2max.|$|E
2500|$|With {{rescaling}} of {{the ability}} parameter, {{it is possible to}} make the 2PL <b>logistic</b> <b>model</b> closely approximate the cumulative normal ogive. [...] Typically, the 2PL logistic and normal-ogive IRFs differ in probability by no more than 0.01 across the range of the function. The difference is greatest in the distribution tails, however, which tend to have more influence on results.|$|E
2500|$|The latent trait/IRT {{model was}} {{originally}} developed using normal ogives, {{but this was}} considered too computationally demanding for the computers at the time (1960s). [...] The <b>logistic</b> <b>model</b> was proposed as a simpler alternative, and has enjoyed wide use since. [...] More recently, however, it was demonstrated that, using standard polynomial approximations to the normal cdf, the normal-ogive model is no more computationally demanding than logistic models.|$|E
40|$|This {{article is}} {{concerned}} with predictive distribution for polytomous <b>logistic</b> <b>models</b> with nonlinear link functions. Within a Bayesian framework, an approximation of the predictive distribution for determining probabilities is presented. We describe this method using nonlinear link functions. The generalized linear link function is simply a special case of nonlinear models. All of the generalized <b>logistic</b> <b>models</b> require nonlinear estimation procedures to evaluate maximum likelihood estimates. (1991) A. M. S. Subject Classification Codes. 34...|$|R
40|$|Continuous cost {{pressure}} causes companies to move production sites to low cost countries. Although production costs decline, logistic costs are negatively effected. Individual companies with limited shipment volumes {{do not have}} access to cost efficient and highly productive transport networks. Multi-modal, cross-company <b>logistic</b> <b>models</b> are one approach to open up the potentials of transport networks for companies. In the past similar approaches failed due to insufficient target and benefit structure of participating partners and missing organizational incorporation. This paper focuses on the critical success factor of cooperative <b>logistic</b> <b>models</b> concerning organizational aspects as well as forms and specifications of cooperation models. Therefore determining characteristics of <b>logistic</b> <b>models</b> and their specifications and dependencies among themselves are identified. Specific possibilities of organizational authorities for the cooperation are defined including contractual relationship...|$|R
40|$|We study {{development}} of mortality tables from 1950 to present in Czech Republic. Our {{aim is to}} look at the 6 basic models, which can be potentially used to describe behavior of dying for people over 60 years. Models that are being investigated vary from generally accepted Gompertz-Makeham <b>model</b> to <b>logistic</b> <b>models</b> of Thatcher and Kannisto. We also introduce Coale-Kisker and Heligman- Pollard model. Our analysis is concentrated mostly on projecting abilities of given models to the highest ages. Especially for women, where data do not show such dispersion as in the case of men, there is a visible trend that can be described better by using <b>logistic</b> <b>models</b> instead of Gompertz-Makeham model, which has a tendency to overestimate the probabilities of dying in higher ages. Keywords: projection of mortality tables, Gompertz-Makeham, <b>logistic</b> <b>models...</b>|$|R
50|$|With the 3-Parameter <b>Logistic</b> <b>Model.</b> Unpublished {{doctoral}} dissertation, University of Minnesota, Minneapolis, MN.|$|E
5000|$|Practical {{reasons for}} {{choosing}} the probit model over the <b>logistic</b> <b>model</b> would be: ...|$|E
5000|$|An {{extension}} of the <b>logistic</b> <b>model</b> to sets of interdependent variables is the conditional random field.|$|E
40|$|Several {{approaches}} {{have been proposed}} to model binary outcomes that arise from longitudinal studies. Most of the approaches can be grouped into two classes: the population-averaged and subject-specific approaches. The generalized estimating equations (GEE) method is commonly used to estimate populationaveraged effects, while random-effects <b>logistic</b> <b>models</b> {{can be used to}} estimate subject-specific effects. However, it is not clear to many epidemiologists how these two methods relate to one another or how these methods relate to more traditional stratified analysis and standard <b>logistic</b> <b>models.</b> The authors address these issues {{in the context of a}} longitudinal smoking prevention trial, the Midwestern Prevention Project. In particular, the authors compare results from stratified analysis, standard <b>logistic</b> <b>models,</b> conditional <b>logistic</b> <b>models,</b> the GEE models, and random-effects models by analyzing a binary outcome from two and seven repeated measurements, respectively. In the comparison, the authors focus on the interpretation of both time-varying and time-invariant covariates under different models. Implications of these methods for epidemiologic research are discussed. Am J Epidemiol 1998; 147 : 694 - 703. generalized estimating equations; longitudinal studies; random-effects regression models; repeated measurement Repeated measures designs or longitudinal studie...|$|R
30|$|In {{a related}} study, Krueger et al. (2014) analyze {{the role of}} {{unemployment}} duration on wages, reemployment chances, and labor force withdrawal. The structure of their paper is similar to ours, but these authors use <b>logistic</b> <b>models</b> to analyze how transition rates to employment and nonparticipation vary with duration. Unlike our case, the authors use data that allow a distinction between unemployment and nonparticipation, but the <b>logistic</b> <b>models</b> that they use do not control for unobserved heterogeneity, a shortcoming which could significantly bias the estimates of duration dependence.|$|R
40|$|Using {{long-term}} data on two kangaroo rats in the Chihuahuan Desert of North America, we fitted <b>logistic</b> <b>models</b> {{including the}} exogenous effects of seasonal rainfall patterns. Our {{aim was to}} test the effects of intraspecific interactions and seasonal rainfall in explaining and predicting the numerical fluctuations of these two kangaroo rats. We found that <b>logistic</b> <b>models</b> fit both data sets quite well; Dipodomys merriami showed lower maximum per capita growth rates than Dipodomys ordii, and in both cases <b>logistic</b> <b>models</b> were nonlinear. Summer rainfall {{appears to be the}} most important exogenous effect for both rodent populations; models including this variable were able to predict independent data better than models including winter rainfall. D. merriami was also negatively affected by another kangaroo rat (Dipodomys spectabilis), consistent with previous experimental evidence. We hypothesized that summer rainfall influences the carrying capacity of the environment by affecting seed availability and the intensity of intraspecific competition...|$|R
5000|$|This {{equation}} is mathematically {{equivalent to the}} <b>logistic</b> <b>model,</b> with a carrying capacity K given by ...|$|E
5000|$|For example, in {{the three}} {{parameter}} <b>logistic</b> <b>model</b> (3PL), {{the probability of a}} correct response to a dichotomous item i, usually a multiple-choice question, is: ...|$|E
50|$|In {{computer}} science, a <b>logistic</b> <b>model</b> tree (LMT) is {{a classification}} model with an associated supervised training algorithm that combines logistic regression (LR) and decision tree learning.|$|E
40|$|Abstract: This paper studies {{modeling}} of nonignorable nonresponse in panel surveys. A class of sequential conditional <b>logistic</b> <b>models</b> for nonresponse is considered. Model-based maximum likelihood estimation and imputation {{are used for}} estimating population proportions. Various models are evaluated, and comparisons are made with traditional methods of weighting and direct data imputation. Two cases are considered, (i) the population rate {{of participation in the}} 1989 Norwegian Storting election and (ii) estimation of car ownership in Norway in 1989 and 1990. Keywords: Nonignorable nonresponse, <b>logistic</b> <b>modeling,</b> imputation, election survey, consumer expenditure surve...|$|R
40|$|A {{generalization}} of the linear <b>logistic</b> test <b>model</b> of G. H. Fischer (1973), the random weights linear <b>logistic</b> test <b>model,</b> is presented. The generalization {{consists of a}} random coefficient contribution of item stimulus features to the item difficulties, with the coefficients varying over persons. Whereas in the common linear <b>logistic</b> test <b>model,</b> only the intercept (ability) is considered random over persons, in the random weights linear <b>logistic</b> test <b>model,</b> also {{some or all of}} the item stimulus features are considered as having random coefficients. It turns out that the random weights linear <b>logistic</b> test <b>model</b> is a special case of the multidimensional random coefficient multinomial logit model of Adams, Wilson, and Wang (1997). The model is applied to a deductive reasoning task. status: publishe...|$|R
40|$|In {{this paper}} {{logistic}} and non-logistic cumulative (sigmoidal) models that have fairly equal degree of predictions are compared for their peak point occurrences. It is discovered that only <b>logistic</b> (Hubbert) <b>models</b> have their peaks at half {{way to the}} ultimate recovery. Non-logistic models peak not necessarily at half way (but at some other point) to the ultimate recovery (see table 1). Peaking of <b>logistic</b> and non-logistic <b>models</b> are functions of the models, and not geology. Empirical experience revealed that even with different <b>logistic</b> <b>models</b> the same historical data gives different peaks and ultimate values; revealing that these values are mainly functions of the models, and not geology. When the historical data is large enough all the <b>logistic</b> <b>models</b> tend to peak at half way to the ultimate (central limit theorem). Peak production could therefore occur somewhere other than at half way to the ultimate recovery depending on the mathematical model used and is basically {{a function of the}} model if the historical data is not large...|$|R
50|$|The graph below {{shows the}} {{observed}} proportion of successes {{in the data}} versus the expected proportion as predicted by the <b>logistic</b> <b>model</b> that includes the caffeine^2 term.|$|E
5000|$|In {{plant disease}} {{epidemiology}} the logit {{is used to}} fit the data to a <b>logistic</b> <b>model.</b> With the Gompertz and Monomolecular models all three are known as Richards family models.|$|E
50|$|The <b>{{logistic}}</b> <b>model</b> (or logistic function) is {{a function}} {{that is used to}} describe bounded population growth under the previous two assumptions. The logistic function is bounded at both extremes: when there are not individuals to reproduce, and when there is an equilibrium number of individuals (i.e., at carrying capacity). Under the <b>logistic</b> <b>model,</b> population growth rate between these two limits is most often assumed to be sigmoidal (Figure 1). There is scientific evidence that some populations do grow in a logistic fashion towards a stable equilibrium - a commonly cited example is the logistic growth of yeast.|$|E
50|$|Commonly used loss {{functions}} for probabilistic classification include log loss {{and the mean}} squared error between the predicted and the true probability distributions. The former of these is commonly used to train <b>logistic</b> <b>models.</b>|$|R
40|$|Straightforward {{application}} of the Schmidt-Appleman contrail formation criteria to diagnose persistent contrail occurrence from numerical weather prediction data is hindered by significant bias errors in the upper tropospheric humidity. <b>Logistic</b> <b>models</b> of contrail occurrence have been proposed to overcome this problem, but basic questions remain about how random measurement error may affect their accuracy. A set of 5000 synthetic contrail observations is created to {{study the effects of}} random error in these probabilistic models. The simulated observations are based on distributions of temperature, humidity, and vertical velocity derived from Advanced Regional Prediction System (ARPS) weather analyses. The <b>logistic</b> <b>models</b> created from the simulated observations were evaluated using two common statistical measures of model accuracy, the percent correct (PC) and the Hanssen-Kuipers discriminant (HKD). To convert the probabilistic results of the <b>logistic</b> <b>models</b> into a dichotomous yes/no choice suitable for the statistical measures, two critical probability thresholds are considered. The HKD scores are higher when the climatological frequency of contrail occurrence is used as the critical threshold, while the PC scores are higher when the critical probability threshold is 0. 5. For both thresholds, typical random errors in temperature, relative humidity, and vertical velocity are found to be small enough to allow for accurate <b>logistic</b> <b>models</b> of contrail occurrence. The accuracy of the models developed from synthetic data is over 85 percent for both the prediction of contrail occurrence and non-occurrence, although in practice, larger errors would be anticipated...|$|R
40|$|An out-of-sample {{prediction}} of Kansas farmers' responses to five surveyed questions involving risk {{is used to}} compare ordered multinomial <b>logistic</b> regression <b>models</b> with feedforward backpropagation neural network <b>models.</b> Although the <b>logistic</b> <b>models</b> often predict more accurately than the neural network models in a mean-squared error sense, the neural network models are shown to be more accommodating of loss functions associated {{with a desire to}} predict certain combinations of categorical responses more accurately than others. Copyright 1996, Oxford University Press. ...|$|R
50|$|The multinomial <b>logistic</b> <b>model</b> {{assumes that}} data are case specific; that is, each {{independent}} variable {{has a single}} value for each case. The multinomial <b>logistic</b> <b>model</b> also assumes that the dependent variable cannot be perfectly predicted from the independent variables for any case. As {{with other types of}} regression, {{there is no need for}} the independent variables to be statistically independent from each other (unlike, for example, in a naive Bayes classifier); however, collinearity is assumed to be relatively low, as it becomes difficult to differentiate between the impact of several variables if this is not the case.|$|E
5000|$|However, in {{the case}} of a <b>logistic</b> <b>model,</b> where [...] cannot be greater than 1, R1 is between 0 and : thus, Nagelkerke {{suggested}} the possibility to define a scaled R2 as R²/R2max.|$|E
5000|$|Nader, I. W., Tran, U. S., & Formann, A. K. (2011). Sensitivity {{to initial}} values in full {{non-parametric}} maximum-likelihood {{estimation of the}} two-parameter <b>logistic</b> <b>model.</b> British Journal of Mathematical and Statistical Psychology, 64, 320-336.|$|E
40|$|Regularized Multinomial Logistic {{regression}} {{has emerged}} as one of the most common methods for performing data classification and analysis. With the advent of large-scale data it is common to find scenarios where the number of possible multinomial outcomes is large (in the order of thousands to tens of thousands) and the dimensionality is high. In such cases, the computational cost of train-ing <b>logistic</b> <b>models</b> or even simply iterating through all the model parameters is pro-hibitively expensive. In this paper, we pro-pose a training method for large-scale multi-nomial <b>logistic</b> <b>models</b> that breaks this bot-tleneck by enabling parallel optimization of the likelihood objective. Our experiments on large-scale datasets showed an order of mag-nitude reduction in training time. 1...|$|R
40|$|Nuisance {{parameters}} are parameters {{that are not}} of immediate interest to the experimenter. For log-linear and <b>logistic</b> <b>models</b> the null distribution of (most) statistics of interest depends on such parameters. Traditionally, nuisance parameters were eliminated by performing inference {{with respect to the}} chi-squared limiting distribution of common test statistics. An alternative solution is to eliminate the nuisance parameters by conditioning on their minimal sufcient statistics. The support of the resulting conditional distribution is often intractable, making null probability calculations challenging. An often feasible way to avoid complete enumeration of this support is to approximate conditional probabilities using Monte Carlo methods. In this article we survey recent developments in Monte Carlo conditional analysis for log-linear and <b>logistic</b> <b>models</b> focusing on the algorithms proposed by Booth and Butler, 1 Diaconis and Sturmfels, 2 Smith et al., 3 and Mehta et al. 4 We illustrate these algorithms with simple motivating examples. 1 Small sample inference for log-linear and log-linear and <b>logistic</b> <b>models</b> Traditionally, computational limitations have forced the analysis of categorical response data to rely on large sample approximations to the distributions of test statistics. These approximations have the benets that they are easy to apply and do no...|$|R
30|$|To {{determine}} {{the risk factors}} for rescue analgesic administration, we used single- and multiple-explanatory-variable <b>logistic</b> regression <b>models.</b> Variables that {{were significantly associated with}} rescue analgesia use in a single-explanatory-variable <b>logistic</b> regression <b>model</b> were entered and further analyzed in the multi-explanatory-variable <b>logistic</b> regression <b>model.</b> Single- and multiple-explanatory-variable <b>logistic</b> regression <b>models</b> were obtained with analgesic use as the outcome variable (1, used; 0, not used). The patients’ age, duration of surgical procedure, and tourniquet placement were analyzed as continuous variables. Sex, additional local anesthetic use during surgery, and the broadly classified surgical procedures were analyzed as single-indicator variables (1 or 0). The surgical site and narrowly classified surgical procedures were analyzed as categorical variables. Variables with P values less than 0.05 in univariate analysis were then evaluated in a multivariate <b>logistic</b> regression <b>model.</b> Odds ratios (OR), 95 % confidence intervals (CI), and P values were calculated. P values less than 0.05 were considered significant.|$|R
