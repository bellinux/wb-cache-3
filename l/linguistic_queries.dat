22|37|Public
40|$|Linguistic {{research}} and {{natural language processing}} employ large repositories of ordered trees. XML, a standard ordered tree model, and XPath, its associated language, are natural choices for linguistic data and queries. However, several important expressive features required for <b>linguistic</b> <b>queries</b> are missing or hard to express in XPath. In this paper, we motivate and illustrate these features {{with a variety of}} <b>linguistic</b> <b>queries.</b> Then we propose extensions to XPath to support <b>linguistic</b> <b>queries,</b> and design an efficient query engine based on a novel labeling scheme. Experiments demonstrate that our language is not only sufficiently expressive for linguistic trees but also efficient for practical usage. ...|$|E
40|$|Linguistic {{research}} and language technology development employ large repositories of ordered trees. XML, a standard ordered tree model, and XPath, its associated language, are natural choices for storing and querying linguistic data. However, several important expressive features required for <b>linguistic</b> <b>queries</b> are missing in XPath. In this paper, we motivate and illustrate these features {{with a variety}} of <b>linguistic</b> <b>queries.</b> Then we define extensions to XPath which support linguistic tree queries. We provide a relational representation for trees, and define an SQL translation for queries. Experiments demonstrate that the query system is significantly faster than other linguistic tree query systems {{for a wide range of}} queries. ...|$|E
40|$|We present CSNIPER (Corpus Sniper), a {{tool that}} {{implements}} (i) a web-based multiuser scenario for identifying and annotating non-canonical grammatical constructions in large corpora based on <b>linguistic</b> <b>queries</b> and (ii) evaluation of annotation quality by measuring inter-rater agreement. This annotationby-query approach efficiently harnesses expert knowledge to identify instances of linguistic phenomena {{that are hard to}} identify by means of existing automatic annotation tools. ...|$|E
40|$|Large {{and open}} multiparallel corpora are a {{valuable}} resource for contrastive corpus linguists if the data is annotated and stored {{in a way that}} allows precise and flexible ad hoc searches. A <b>linguistic</b> <b>query</b> language should also support computational linguists in automated multilingual data mining. We review a broad range of approaches for <b>linguistic</b> <b>query</b> and reporting languages according to usability criteria such as expressibility, expressiveness, and efficiency. We propose an architecture that tries to strike the right balance to suit practical purposes...|$|R
40|$|Language {{technology}} makes {{extensive use}} of hierarchically annotated text and speech data. These databases are stored in flat files and manipulated using corpus specific query tool or scripts. While the size of these databases {{and the range of}} applications has grown rapidly in recent years, neither method for managing the data has led to reusable, scalable software. The formal properties of the languages are not well understood. Hence established methods for indexing tree data and optimizing tree queries cannot be employed. We analyze a range of existing <b>linguistic</b> <b>query</b> languages, and adduce a set of requirements for a reusable, scalable <b>linguistic</b> <b>query</b> language. ...|$|R
40|$|<b>Linguistic</b> <b>query</b> {{systems are}} special purpose IR applications. As text sizes, {{annotation}} layers, and metadata schemes of language corpora grow rapidly, performing complex searches becomes a highly computational expensive task. We evaluate several storage models and indexing variants in two multi-processor/multi-core environments, focusing on prototypical <b>linguistic</b> <b>querying</b> scenarios. Our {{aim is to}} reveal modeling and querying tendencies – rather than absolute benchmark results – when using a relational database management system (RDBMS) and MapReduce for natural language corpus retrieval. Based on these findings, {{we are going to}} improve our approach for the efficient exploitation of very large corpora, combining advantages of state-of-the-art database systems with decomposition/parallelization strategies. Our reference implementation uses the German DeReKo reference corpus with currently more than 4 billion word forms, various multi-layer linguistic annotations, and several types of text-specific metadata. The proposed strategy is language-independent and adaptable to large-scale multilingual corpora...|$|R
40|$|The current {{trend in}} {{the rapid growth of}} on-line image {{databases}} has brought forth several innovative approaches to content-based image retrieval. Most current techniques retrieve images based on an example image or object shapes/features extracted from images. Retrieval based on <b>linguistic</b> <b>queries</b> has not recieved much attention. In this paper, we present a fuzzy connective approach to handle complex <b>linguistic</b> <b>queries</b> consisting of multiple attributes. We represent each (fuzzy) attribute in a complex query by a (multi-dimensional) membership function. The degree to which an image satisfies the attribute is obtained by finding the membership value of the feature vector corresponding to the image in the membership function for the attribute. We propose the use of fuzzy connectives to combine the degrees of satisfaction of multiple attributes in a complex query to arrive at an overall degree of satisfaction. This overall degree is used to rank images for retrieval. The membership functi [...] ...|$|E
40|$|A {{framework}} for modelling with words is introduced based on label semantics. It is shown how {{within this framework}} that linguistic prototypes, defined as vectors of mass assignments on sets of labels, {{can be used to}} evaluate <b>linguistic</b> <b>queries.</b> This provides a flexible knowledge representation {{framework for}} data mining and knowledge discovery as well as an environment well suited to information fusion and modelling with words in general. ...|$|E
40|$|In this paper, we {{evaluate}} two corpus query {{systems with}} respect to search functionality and query speed. One corpus query system is TIGERSearch from IMS Stuttgart {{and the other is}} our own Emdros corpus query system. First, we show how the database model underlying TIGERSearch can be mapped into the database model of Emdros. Second, the comparison is made based on a set of standard <b>linguistic</b> <b>queries</b> culled from the literature. We show that by mapping a TIGERSearch corpus into the Emdros database model, new query possibilities arise. ...|$|E
40|$|Abstract Over {{the past}} decade, {{a variety of}} {{expressive}} <b>linguistic</b> <b>query</b> languages have been developed. The most scalable of these have been implemented {{on top of an}} existing database engine. However, with the arrival of efficient, wide-coverage parsers, it is feasible to parse text on a scale that is several orders of magnitude larger. We show that the existing database approach will not scale up, and speculate on a new approach that leverages proximity search {{in the context of an}} IR engine. We also propose a simple syntax for <b>querying</b> <b>linguistic</b> annotations, avoiding the usability problems with existing tree query languages...|$|R
40|$|<b>Linguistic</b> <b>query</b> {{systems are}} special purpose IR applications. We present a novel {{state-of-the-art}} approach for the efficient exploitation of very large linguistic corpora, combining {{the advantages of}} relational database management systems (RDBMS) with the functional MapReduce programming model. Our implementation uses the German DEREKO reference corpus with multi-layer linguistic annotations and several types of text-specific metadata, but the proposed strategy is language-independent and adaptable to large-scale multilingual corpora...|$|R
40|$|Linguistic {{decision}} tree (LDT) is a tree-structured model {{based on a}} framework for “Modelling with Words”. In previous research [16], an algorithm for learning LDTs was proposed and its performance on some benchmark classification problems were investigated and compared {{with a number of}} well known classifiers. In this paper, a methodology for extending LDTs to prediction problems is proposed and the performance of LDTs are compared with other state-of-art prediction algorithms such as a Support Vector Regression (SVR) system and Fuzzy Semi-Naive Bayes on a variety of data sets. Finally, a method for <b>linguistic</b> <b>query</b> evaluation is discussed and supported with an example...|$|R
40|$|In {{this work}} we explore how {{applying}} graph-modifying algorithms to a Hierarchical Hidden Markov Model can simplify the specification of input-output mapping rules in a spoken language dialogue system. A set of state-chunking learning algorithms capable of inducing a stochastic context-free grammar {{from a small}} amount of question-and-answer training data have been created for use in the Speech Librarian, our test implementation. We quantitatively estimate the power of the system to induce a broad but accurate coverage of <b>linguistic</b> <b>queries</b> from a relatively small set of question-and-answer pairs, using subjective judgements of semantic relevance weighted by probability of occurrence...|$|E
40|$|This paper {{presents}} first {{results of}} a large inquiry upon young people language in Tuscany and Liguria, and the relational database that stores lexical entries retrieved from questionnaires distributed in many High Schools of these Regions. Each entry has been examinated from a lexical, morphological, sociolinguistic and geographical pont of view. Lexical entries can be divided according to the informants' sex, age or metalinguistic knowledge. In addition to that, many <b>linguistic</b> <b>queries</b> can be operated in order to study their relations with standard language, dialects, slang and innovations. First results of the research focus on dialectal persistence, gender differentiation and the measurement of the young people's creativeness in different experential areas...|$|E
40|$|Linguistic {{research}} and language technology development employ large data repositories of ordered trees, known as “treebanks. ” We define a path language for linguistic trees represented in XML called LPath, based on XPath, {{and provide a}} new labeling scheme for LPath query evaluation. We report a strategy for evaluating expressions of the language against treebank data. The language contains three expressive features which are important for linguistic query, namely immediate precedence, subtree scoping, and edge alignment. We motivate and illustrate these features {{with a variety of}} <b>linguistic</b> <b>queries.</b> This work provides a scalable and reusable model for linguistic tree queries, and relates it to well-understood semistructured and relational languages. January 2005 Open Acces...|$|E
40|$|There {{has been}} recent {{interest}} {{in looking at}} what is required for a tree <b>query</b> language for <b>linguistic</b> corpora. One approach is to start from existing formal machinery, such as tree grammars and automata, {{to see what kind}} of machine is an appropriate underlying one for the query language. The goal of the paper is then to examine what is an appropriate machine for a <b>linguistic</b> tree <b>query</b> language, with a view to future work defining a query language based on it. In this paper we review work relating XPath to regular tree grammars, and as the paper’s first contribution show how regular tree grammars can also be a basis for extensions proposed for XPath for common <b>linguistic</b> corpus <b>querying.</b> As the paper’s second contribution we demonstrate that, on the other hand, regular tree grammars cannot describe a number of structures of interest; we then show that, instead, a slightly more powerful machine is appropriate, and indicate how <b>linguistic</b> tree <b>query</b> languages might be augmented to include this extra power. ...|$|R
40|$|Annotated {{linguistic}} databases {{are widely}} used in linguistic research and in language technology development. These annotations are typically hierarchical, and represent the nested structure of syntactic and prosodic constituents. Recently, the LPath language has been proposed as a convenient path-based language for <b>querying</b> <b>linguistic</b> trees. We establish the formal expressiveness of LPath relative to the XPath family of languages. We also extend LPath to permit simple closures, resulting in a first-order complete language which we believe is sufficiently expressive {{for the majority of}} <b>linguistic</b> tree <b>query</b> needs. 1...|$|R
40|$|Abstract. Large {{databases}} {{of linguistic}} annotations {{are used for}} testing linguistic hypotheses and for training language processing models. These linguistic annotations are often syntactic or prosodic in nature, and have a hierarchical structure. Query languages are used to select particular structures of interest, or to project out large slices of a corpus for external analysis. Existing languages suffer {{from a variety of}} problems in the areas of expressiveness, efficiency, and naturalness for <b>linguistic</b> <b>query.</b> We describe the domain of linguistic trees and discuss the expressive requirements for a query language. Then we present a language that can express a wide range of queries over these trees, and show that the language is first-order complete over trees. 1...|$|R
40|$|The Web {{contains}} {{vast amounts}} of linguistic data. One key issue for linguists and language technologists is how to access it. Commercial search engines give highly compromised access. An alternative is to crawl the Web ourselves, which also allows us to remove duplicates and nearduplicates, navigational material, {{and a range of}} other kinds of non-linguistic matter. We can also tokenize, lemmatise and part-of-speech tag the corpus, and load the data into a corpus query tool which supports sophisticated <b>linguistic</b> <b>queries.</b> We have now done this for German and Italian, with corpus sizes of over 1 billion words in each case. We provide Web access to the corpora in our query tool, the Sketch Engine. ...|$|E
40|$|Abstract — In this contribution, a multiobjective genetic {{algorithm}} is proposed to automatically learn persistent fuzzy <b>linguistic</b> <b>queries</b> for text retrieval applications. These queries are able to represent user’s long-term standing information needs in a more interpretable way than the classical “bag of words” user profile structure. Thanks to its multiobjective nature, the introduced genetic fuzzy system {{will be able to}} build different queries for the same information need in a single run, with a different trade-off between precision and recall. The experiments performed on the classical CACM collection will show that although the different queries obtained from our genetic fuzzy system are less accurate in the retrieval task than those derived by one state-of-the-art bag of words method, they compose more flexible, comprehensible and expressive user profiles. 1 I...|$|E
40|$|More {{than half}} of the 6000 world {{languages}} have never been adequately described. We propose to create a database system to automatically capture and manage interested sound clips in Blackfoot (an endangered language spoken in Alberta, Canada, and Montana) for a phonetic and phonological analysis. Taking Blackfoot speeches as input, the system generates a list of audio clips containing a sequence of sounds or certain accent patterns based on research interests. Existing computational linguistic techniques such as information processing and artificial intelligence are extended to tackle issues specific to Blackfoot linguistics, and database techniques are adopted to support better data management and <b>linguistic</b> <b>queries.</b> This project is innovative because application of technology in Native American phonetics and phonology is underdeveloped. It enhances humanity with the digital framework to document and analyze endangered languages and can also benefit the research in other languages...|$|E
40|$|The {{availability}} of large multi-parallel corpora offers an enormous wealth of material to contrastive corpus linguists, translators and language learners, {{if we can}} exploit the data properly. Necessary preparation steps include sentence and word alignment across multiple languages. Additionally, linguistic annotation such as partof- speech tagging, lemmatisation, chunking, and dependency parsing facilitate precise <b>querying</b> of <b>linguistic</b> properties {{and can be used}} to extend word alignment to sub-sentential groups. Such highly interconnected data is stored in a relational database to allow for efficient retrieval and linguistic data mining, which may include the statistics-based selection of good example sentences. The varying information needs of contrastive linguists require a flexible <b>linguistic</b> <b>query</b> language for ad hoc searches. Such queries in the format of generalised treebank query languages will be automatically translated into SQL queries...|$|R
40|$|This paper {{proposes a}} {{methodology}} for <b>querying</b> <b>linguistic</b> data represented in different corpus formats. Examples {{of the need}} for queries over such heterogeneous resources are the corpus-based analysis of multimodal phenomena like the interaction of gestures and prosodic features, or syntax-related phenomena like information structure which exceed the expressive power of a tree-centered corpus format. Query languages (QLs) currently under development are strongly connected to corpus formats, like the NITE Object Model (NOM, Carletta et al., 2003) or the Meta-Annotation Infrastructure for ATLAS (MAIA, Laprun and Fiscus, 2002). The parallel development of <b>linguistic</b> <b>query</b> languages and corpus formats {{is due to the fact}} that general purpose query languages like XQuery (Boag et al., 2003) do not fulfill the changing needs of linguistically motivated queries, e. g. to give access to (non-) hierarchically organized, theory and language dependent annotations of multi modal signals and/or text. This leads to the problem that existing corpus formats and query languages are hard to reuse. They have to be re developed and re-implemented time-consumingly and expensively for unforeseen tasks. This paper describes an approach for overcoming these problems and a sample application...|$|R
40|$|AbstractThe paper {{proposes a}} {{linguistic}} based multi-view fuzzy ontology information retrieval model. It deals with multi-view <b>linguistic</b> based <b>queries</b> in multi domains. Such linguistics are user defined, reflecting his subjective view. The model also proposes a ranking algorithm that ranks {{the set of}} relevant documents according to some criteria such as their relevance degree, confidence degree, and updating degree...|$|R
40|$|For Many Years, {{achieving}} unambiguous {{knowledge has}} been turned to a serious challenge for human being. The aim {{of this paper is}} to emphasize situation when classical {true, false} logic is not adequate for data selection and data classification. Linguistic expression like: high salary, young etc are very often used in life and in statistics. The goal of this paper is brief study of fuzzy logic and sets and how to make it suitable for database queries and classification tasks. Fuzzy approach is introduced along with usual relational database model to handle <b>linguistic</b> <b>queries.</b> The purposed fuzzy approach provides flexibility when users cannot unambiguously set hidden boundaries between data. In this paper, we extend the work of medina et al. to implement a new architecture of fuzzy DBMS based on the GEFRED model. This architecture is based on the concept of weak coupling with the DBMS SQL Server...|$|E
40|$|The NLP {{community}} has developed many corpora with rich annotations but these resources {{are not easily}} accessible to researchers with little computer expertise. If the NLP community is eager to make available annotated corpora to a wider audience of non-specialists, {{it is imperative to}} design and develop user-friendly interfaces, which is not a trivial problem. In this article, in the framework of the Scientext project, we examine several criteria and methods in order to develop such an interface and we highlight the drawbacks of existing systems. We then present the ScienQuest system, dedicated to several kinds of <b>linguistic</b> <b>queries</b> : textual parts, part of speech, syntactic functions. As expected, a first evaluation shows that simple and assisted query modes are preferred to complex query languages. Beyond the Scientext Project, the ScienQuest environment, developed as a generic tool, is planned to be used with various free textual resources...|$|E
40|$|Persistent {{queries are}} a {{specific}} kind of queries used in information retrieval systems {{to represent a}} user’s long-term standing information need. These queries can present many different structures, being the “bag of words” that most commonly used. They can be sometimes formulated by the user, although this task is usually difficult for him and the persistent query is then automatically derived from a set of sample documents he provides. In this work we aim at getting persistent queries with a more representative structure for text retrieval issues. To do so, we make use of soft computing tools: linguistic information is considered for weighting the terms of Boolean queries by means of ordinal linguistic values (<b>linguistic</b> <b>queries),</b> and multiobjective evolutionary algorithms are applied to build the linguistic persistent query. Experimental results will show how using an expressive linguistic information-based query structure and a proper learning process to derive it, we can get more flexible, comprehensible and expressive user profiles...|$|E
40|$|Abstract. We {{describe}} {{design and}} implementation of the <b>linguistic</b> <b>query</b> language DDDquery. This language aims at <b>querying</b> a large <b>linguistic</b> database storing a corpus of richly annotated historic German texts. We use a graph-based data model that supports multiple independent annotation layers on a shared text layer as well as alignments of text layers representing the same text or related texts (e. g., translations). The corpus is stored in an object-relational database system with a text retrieval extension. DDDquery is based on XPath to leverage the familiarity of many users with this language. It is translated to SQL in a two phase compilation with first order logic as an intermediate language. This approach effectively decouples the query language from the schema of the underlying corpus. We provide an overview of DDDquery, the underlying ODAG data model, its implementation as relational schema, the predicates of the intermediate language, and describe both phases of the translation process. ...|$|R
40|$|Deposited with {{permission}} of the author. © 2006 Catherine LaiThe analysis of human communication, in all its forms, increasingly depends on large collections of texts and transcribed recordings. These collections, or corpora, are often richly annotated with structural information. These datasets are extremely large so manual analysis is only successful up to a point. As such, significant effort has recently been invested in automatic techniques for extracting and analyzing these massive data sets. However, further progress on analytical tools is confronted by three major challenges. First, we need the right data model. Second, {{we need to understand}} the theoretical foundations of query languages on that data model. Finally, we need to know the expressive requirements for general purpose query language with respect to linguistics. This thesis has addressed all three of these issues. Specifically, this thesis studies formalisms used by linguists and database theorists to describe tree structured data. Specifically, Propositional dynamic logic and monadic second-order logic. These formalisms have been used to reason about a number of tree querying languages and their applicability to the <b>linguistic</b> tree <b>query</b> problem. We identify a comprehensive set of <b>linguistic</b> tree <b>query</b> requirements and the level of expressiveness needed to implement them. The main result {{of this study is that}} the required level of expressiveness of <b>linguistic</b> tree <b>query</b> is that of the first-order predicate calculus over trees. This formal approach has resulted in a convergence between two seemingly disparate fields of study. Further work in the intersection of linguistics and database theory should also pave the way for theoretically well-founded future work in this area. This, in turn, will lead to better tools for linguistic analysis and data management, and more comprehensive theories of human language. Open Acces...|$|R
40|$|In {{this paper}} a new {{modelling}} for a weighted Information Retrieval System (IRS) in a linguistic context is proposed. This linguistic IRS (LIRS) achieves more precise and consistent relevance degrees that early weighted IRSs proposed [8, 9]. To do this, a new redefinition of matching function defined in [11] is used. Keywords: Fuzzy Information Retrieval, <b>Linguistic</b> Modelling, Weighted <b>Queries...</b>|$|R
40|$|Color {{features}} {{widely used}} in content-based image technologies for image indexing and retrieval are global, which means they are computed over the entire image. Since the features of partial images are included in those of other complete images, the major problem in partial image retrieval using a global feature is that the feature cannot be a discriminant for {{a small portion of}} an image. This paper presents a method of content-based partial image retrieval by using the measures of connected color regions. In a connected color region, the color density and maximum co-occurrence color probability are calculated and compared in order to find images from sequences of complete images that have the same image portion with a query image. 1. INTRODUCTION Content-based image retrieval techniques can be characterized into the following categories: query-by-visual sample, pictorial queries, and/or <b>linguistic</b> <b>queries</b> [1, 3]. In retrieving similar images using color, most of the existing techniq [...] ...|$|E
40|$|A typical {{content-based}} image retrieval (CBIR) {{system would}} need to handle the vagueness in the user queries {{as well as the}} inherent uncertainty in image representation, similarity measure, and relevance feedback. In this paper, we discuss how fuzzy set theory can be effectively used for this purpose and describe an image retrieval system called FIRST (Fuzzy Image Retrieval SysTem) which incorporates many of these ideas. FIRST can handle exemplar-based, graphical-sketch-based, as well as <b>linguistic</b> <b>queries</b> involving region labels, attributes, and spatial relations. FIRST uses Fuzzy Attributed Relational Graphs (FARGs) to represent images, where each node in the graph represents an image region and each edge represents a relation between two regions. The given query is converted to a FARG, and a low-complexity fuzzy graph matching algorithm is used to compare the query graph with the FARGs in the database. The use of an indexing scheme based on a leader clustering algorithm avoids an exhaustive search of the FARG database. We quantify the retrieval performance of the system in terms of several standard measures...|$|E
40|$|We {{report an}} {{approach}} for implementing predictive fuzzy systems that manage capturing both the imprecision of the empirically induced classifications and the imprecision of the intuitive linguistic expressions via the {{extensive use of}} fuzzy sets. From end-users ' point of view, the approach enables encapsulating the technical details of the underlying information system {{in terms of an}} intuitive linguistic interface. We describe a novel technical syntax of fuzzy descriptions and expressions, and outline the related systems of fuzzy <b>linguistic</b> <b>queries</b> and rules. To illustrate the method, we describe it in terms of a concrete educational user modelling application. We report experiments with two data sets, describing the records of the students attending to a university mathematics course in 2003 and 2004. In brief, we aim identifying the failing students of the year 2004, and develop a procedure for empirically inducing and assigning each student a fuzzy property "poor", which helps capturing the students needing extra assistance. In the educational context, the approach enables the construction of applications exploiting simple and intuitive student models, that to certain extent are self-evident...|$|E
40|$|An Information Retrieval (IR) model defined {{using an}} ordinal fuzzy {{linguistic}} approach is proposed. It accepts ordinal <b>linguistic</b> weighted <b>queries</b> {{based on two}} weighting elements: the query terms and the query sub-expressions. In such a way, users may easily express simultaneously several semantic restrictions in a query. A symmetrical threshold semantic is associated to the weights of the query terms and an importance semantic is associated to the weights of the query sub-expressions. The advantage of this IR model with respect to others is the facility for expressing different semantic restrictions on the desired documents simultaneously, incorporating more flexibility in the user-IR system interaction a...|$|R
40|$|Large {{databases}} {{of linguistic}} annotations {{are used for}} testing linguistic hypotheses, and for training language processing models. Linguistic annotations are often syntactic or prosodic and typically have a tree structure. Our goal {{is to develop a}} language that can express a wide range of <b>linguistic</b> tree <b>queries</b> and has an efficient implementation. We argue that by adding some simple closures to the LPath language, we can meet this goal. We call this new addition to the XPath family LPath +. We place LPath and LPath + in the hierarchy of XPath languages and conclude that LPath + is first-order complete over trees. This means LPath + is efficiently implementable in SQL. ...|$|R
40|$|In this report, we {{describe}} our experimental approach for the NTCIR- 9 GeoTime task. For our experiments, {{we use our}} experimental search engine, Newt. Newt is a ranked self-index capable of supporting multiple languages by deferring <b>linguistic</b> decisions until <b>query</b> time. To our knowledge, {{this is the first}} application of ranked self-indexing to a multilingual information retrieval task at NTCIR. Categories and Subject Descriptor...|$|R
