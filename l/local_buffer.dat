73|142|Public
50|$|Cache {{information}} (such {{as for a}} data base) that {{is shared}} among all attached systems (or maintaining coherency between <b>local</b> <b>buffer</b> pools in each system).|$|E
5000|$|CoDel works {{off of a}} {{parameter}} that {{is determined}} completely locally, so it is independent of round-trip delays, link rates, traffic loads and other factors that cannot be controlled or predicted by the <b>local</b> <b>buffer.</b>|$|E
5000|$|... 3270s had <b>local</b> <b>buffer</b> storage, some {{processing}} capabilities, {{and generally}} dealt with an entire screen of data at a time. They handled editing tasks locally, and then transmitted {{a set of}} fields (or the entire page) at once when the ENTER key or a program function key (PFK) was pressed.|$|E
40|$|This paper {{presents}} software synthesis {{techniques to}} deal with non-primitive data type from graphical dataflow programs based on the synchronous dataflow (SDF) model. Non-primitive data types, often used in multimedia and graphics applications, require buffer memory of large size. To minimize the buffer requirement, we separate global data <b>buffers</b> and <b>local</b> pointer <b>buffers.</b> The proposed approach first allocates the minimum size of global buffers and next binds the <b>local</b> <b>buffers</b> to the global buffers by setting the pointers. Static binding and dynamic binding techniques are devised. Experimental results prove {{the significance of the}} proposed techniques...|$|R
5000|$|Side-port {{memory as}} <b>local</b> frame <b>buffer,</b> {{supporting}} DDR2 and GDDR3 ...|$|R
40|$|Most {{approaches}} to verifying linearizability assume a sequentially consistent memory model, {{which is not}} always realised in practice. In this paper we study correctness on a weak memory model: the TSO (Total Store Order) memory model, which is implemented in x 86 multicore architectures. Our central result is a proof method that simplifies proofs of linearizability on TSO. This is necessary since the use of <b>local</b> <b>buffers</b> in TSO adds considerably to the verification overhead {{on top of the}} already subtle linearizability proofs. The proof method involves constructing a coarse-grained abstraction as an intermediate layer between an abstract description and the concurrent algorithm. This allows the linearizability proof to be split into two smaller components, where the effect of the <b>local</b> <b>buffers</b> in TSO is dealt with at a higher level of abstraction {{than it would have been}} otherwise...|$|R
50|$|A {{media player}} that {{is capable of}} {{progressive}} download playback relies on meta data located in the header of the file to be intact and a <b>local</b> <b>buffer</b> of the digital media file as it is downloaded from a web server. At the point in which a specified amount of data becomes available to the local playback device, the media will begin to play. This specified amount of buffer is embedded into the file by the producer of the content in the encoder settings and is reinforced by additional buffer settings imposed by the media player.|$|E
50|$|Fetching a row {{from the}} cursor {{may result in}} a network round trip each time. This uses much more network {{bandwidth}} than would ordinarily be needed for the execution of a single SQL statement like DELETE. Repeated network round trips can severely reduce the speed of the operation using the cursor. Some DBMSs try to reduce this effect by using block fetch. Block fetch implies that multiple rows are sent together from the server to the client. The client stores a whole block of rows in a <b>local</b> <b>buffer</b> and retrieves the rows from there until that buffer is exhausted.|$|E
5000|$|Another {{source of}} lock failure occurs when {{buffered}} I/O has buffers assigned in the user's local workspace, {{rather than in}} an operating system buffer pool. [...] "fread" [...] and [...] "fwrite" [...] are commonly used to do buffered I/O, and once a section of a file is read, another attempt to read that same section will, most likely, obtain {{the data from the}} <b>local</b> <b>buffer.</b> The problem is another user attached to the same file has their own local buffers, and the same thing is happening for them. [...] "fwrite" [...] of data obtained from the buffer by [...] "fread" [...] will NOT be obtaining the data from the file itself, and some other user could have changed it. Both could use [...] "flock" [...] for exclusive access, which prevents simultaneous writes, but since the reads are reading from the buffer and not the file itself, any data changed by user #1 can be lost by user #2 (overwritten). The best solution to this problem is to use unbuffered I/O ("read" [...] and [...] "write") with [...] "flock", which also means using [...] "lseek" [...] instead of [...] "fseek" [...] and [...] "ftell". Of course, you'll have to make adjustments for function parameters and results returned. Generally speaking, buffered I/O is unsafe when used with shared files.|$|E
40|$|The VC- 1 is a {{parallel}} graphics machine for polygon rendering based on image composition. This paper describes {{the architecture of}} the VC- 1 along with {{a parallel}} polygon rendering algorithm for it. The structure of the VC- 1 is a loosely-coupled array of 16 general-purpose processors, each of which is equipped with a <b>local</b> frame <b>buffer.</b> The contents of the <b>local</b> frame <b>buffers</b> are merged in real time for generating the final image. The <b>local</b> frame <b>buffers</b> are virtualized with a demand-paging technique, by which the image memory capacity for each <b>local</b> frame <b>buffer</b> is reduced to one eighth of full-screen capacity. Polygons are rendered in either pixel parallel or polygon parallel depending on the on-screen area of each polygon. The real performance of the VC- 1 as well as estimated performance for systems with up to 256 processors is shown...|$|R
40|$|Abstract- This paper {{presents}} software synthesis {{techniques to}} deal with non-primitive data type from graphical dataflow programs based on the synchronous dataflow (SDF) model. Non-primitive data types, often used in multimedia and graphics applications, require buffer memory of large size. To minimize the buffer requirement, we separate global data <b>buffers</b> and <b>local</b> pointer <b>buffers.</b> The proposed approach first allocates the minimum size of global buffers and next binds the <b>local</b> <b>buffers</b> to the global buffers by setting the pointers. Static binding and dynamic binding techniques are devised. Experimental results prove {{the significance of the}} proposed techniques. I...|$|R
50|$|Side-port {{memory as}} <b>local</b> frame <b>buffer,</b> {{supporting}} DDR2 and GDDR3 chips.|$|R
3000|$|... {{needs to}} be {{temporarily}} stored in a <b>local</b> <b>buffer</b> as shown in Figure 7. The buffer is vectorized as well and stores [...]...|$|E
40|$|Resource-sharing {{techniques}} {{are widely used}} by VOD servers. Stream merging {{is one of the}} most efficient resource-sharing techniques. ERMT is able to achieve merge trees with the closest cost of optimal merge tree. Full VCR support has become a “must have” feature for VOD services. This researcher proposed an algorithm to enable VCR support on ERMT. Furthermore, client <b>local</b> <b>buffer</b> and fixed-interval periodical multicasting were also deployed by the algorithm to improve the stream-client ratio. After thorough runs of simulations and numerous comparisons to BEP, the highly efficient resource- sharing technique, the proposed algorithm with client <b>local</b> <b>buffer</b> utilization and fixed- interval multicasting showed better performance in all simulations. The biggest discovery is that the best-performer is modified ERMT with client <b>local</b> <b>buffer</b> support for VCR without fixed-interval multicasting. Another discovery is that bigger client buffer size hurts the performance of ERMT...|$|E
40|$|Modern servers pay a {{heavy price}} in block access time on diskbound workloads when the working set {{is greater than the}} size of the <b>local</b> <b>buffer</b> cache. We provide a {{mechanism}} for cooperating servers to coordinate and share their <b>local</b> <b>buffer</b> caches. The coordinated buffer cache can handle working sets on the order of the aggregate cache memory, greatly improving performance on diskbound workloads. This facility is provided with minimal communication overhead, no penalty for local cache hits, and without any explicit kernel support...|$|E
5000|$|Side-port {{memory as}} <b>local</b> frame <b>buffer,</b> {{supporting}} DDR2 and GDDR3 chips (780G only) ...|$|R
5000|$|Side-port {{memory as}} <b>local</b> frame <b>buffer,</b> {{supporting}} DDR2 and GDDR3 chips up to 128 MB ...|$|R
3000|$|... {{consecutive}} timeslots. Clearly, this {{entails the}} use of <b>local</b> <b>buffers</b> but, in exchange, the distortion in the reconstructed random field is lower. To capitalize on this, we derive closed-form expressions of the distortion attainable in DT scenarios (unlike in [2, 6, 8], we explicitly take into account quantization effects). From this, we determine the optimal number of samples to be encoded {{in each of the}} [...]...|$|R
3000|$|... [...]. As a whole, each PE calculates the {{messages}} in parallel by accessing the <b>local</b> <b>buffer</b> or the layer buffer {{which is located}} in the neighboring PEs or PE groups.|$|E
30|$|During the {{elaboration}} of a generic layer, a certain v 2 c message is needed twice, and a <b>local</b> <b>buffer</b> or multiple memory reading operations were implemented in Arch. V-A and Arch. V-B, respectively.|$|E
30|$|Detecting {{congestion}} is {{the most}} difficult step of congestion control since there is not an exact congestion indicator available for WMSNs. Protocols which address congestion control mostly use specific metrics for congestion estimation. In WSNs, commonly used congestion indicators are <b>local</b> <b>buffer</b> occupancy, channel load, packet arrival rate, and packet service time. Event to Sink Reliable Transport (ESRT) [10] protocol and Fusion [11] detect congestion by monitoring <b>local</b> <b>buffer</b> occupancy, whereas Congestion Control and Fairness (CCF) [12] and Rate-Controlled Reliable Transport (RCRT) [13] protocols use packet service time to estimate congestion. Congestion Detection and Avoidance (CODA) [14] uses both <b>local</b> <b>buffer</b> occupancy and channel load for congestion detection. Similarly in [15], local queue lengths and channel conditions are used for predictive congestion control. Fuzzy-Based Congestion Estimation (FCE) [16] and SenTCP [17] calculate congestion level using the buffer occupancy and packet arrival rate. In [18], congestion is estimated by comparing the input traffic rate and the maximum allowable transmission rate. Interference-Minimized Multipath Routing (I 2 MR) [19] detects congestion by monitoring the size of data transmit buffer using exponential weighted moving averages. In [20], the occurrence of a congestion is decided when the queue occupancy is greater than a given threshold or when the collision rate is above a given threshold.|$|E
40|$|This {{paper is}} {{concerned}} with the effects of dispatching and routeing decisions on the performance of a flexible manufacturing system (FMS). Three routeing policies, no alternative routeings, alternative routeings dynamic, and alternative routeings planned are first considered with four dispatching rules with infinite buffer capacity. However, in real-life, the size of the <b>local</b> <b>buffers</b> in FMSs may be limited {{by the size of the}} part types. Therefore, further experiments to investigate the above three routeing policies with the four dispatching rules with finite buffer capacity are also conducted in order to study the impact of limited buffer capacity on system performance. In addition, the effect of changing part mix ratios is discussed with both infinite and finite buffer capacity. The performance measures considered are makespan, average machine utilisation, average flow-time, and average delay at <b>local</b> input <b>buffers.</b> The simulation results indicate that for infinite buffer capacity, the alternative routeing planned policy, combined with the shortest total processing time dispatching rule, gives the best results for all the above performance measures. For finite buffer capacity, the alternative routeings dynamic policy gives the best results in three performance measures, except for average delay at <b>local</b> input <b>buffers.</b> Further, the effect of changing part mix ratios is not significant. link_to_subscribed_fulltex...|$|R
40|$|In this paper, {{computer}} simulation {{is used to}} evaluate the effects of various control rules on the performance of a flexible manufacturing system (FMS) operating under different manufacturing environment. Alternative routings are available, if the operation of a part can be performed by more than one machine. Three control rules, namely, dynamic alternative routings, planned alternative routings, and no alternative routings, are proposed to control the selection of alternative routings for each part. The effects of the universal loading station and also those of the dedicated loading station are investigated. In addition, the impact of buffer existence on the system's performance is also examined by considering machines with and without <b>local</b> <b>buffers.</b> The effects of changing production ratios of different part types on the performance of various operational control rules are also investigated. Moreover, the effects of system having machine breakdown are also discussed. The simulation results indicate that the FMS with dedicated loading stations outperforms the FMS with universal loading stations in all aspects. The dynamic alternative routings generally produces the best results in system performance if the universal loading station is provided. The planned alternative routings generally gives the best system performance when both the dedicated loading stations and <b>local</b> <b>buffers</b> are available. The no alternative routings usually remains {{at the bottom of the}} rank, occasionally with some exceptions. Problems in actual implementation are also highlighted. link_to_subscribed_fulltex...|$|R
50|$|Tom Dempsey (born 1965 in Kilmuckridge, County Wexford) is {{a retired}} Irish sportsperson. He played hurling with his <b>local</b> club <b>Buffer's</b> Alley and with the Wexford senior inter-county team from 1984 until 2000.|$|R
30|$|As {{explained}} in the FBP algorithm, at each update time, {{the location of the}} buffer is shifted to p 0 axis being updated by the new cost. The newly updated messages and data cost in the <b>local</b> <b>buffer</b> should be stored in the layer buffer for the processing of the next Q(p 0 + 1). Thus, if the messages from all possible directions be saved in the <b>local</b> <b>buffer,</b> then some messages can be transferred to Q(p 0 - 1, l - 1). At the same time, some old costs in Q(p 0 - 1, l - 1) are moved to Q(p 0 - 2, l - 1) in a similar way. With this scheme, the number of propagation directions to be stored at the buffer is described at the store(Δ) part in Table 2.|$|E
40|$|Computer {{networks}} have experienced an explosive {{growth over the}} past few years and with that growth have come severe congestion problems. For example, it is now common to see internet gateways drop 10 % of the incoming packets because of <b>local</b> <b>buffer</b> overflows. Our investigation of some of these problems has shown that much of the cause lies i...|$|E
40|$|Partitioned video {{broadcast}} divides a video into segments and sends each segment over one channel in cycles. In this paper, we propose an active buffer management scheme to provide interactive functions in partitioned {{video broadcast}}. The scheme uses client side buffering {{in a novel}} fashion that relies on the simultaneous availability of "past", "present" and "future" parts of a video and lets the client selectively prefetch segments from broadcast channels based on the observation of the play point in its <b>local</b> <b>buffer.</b> The contents of the buffer are adjusted {{in such a way}} that the relative position of the play point is kept in the middle part of the buffer and a high probability of providing the interactive functions with the contents of the <b>local</b> <b>buffer</b> is achieved. Discontinuous interactive functions are used to deal with cases where the local buffering is not sufficient to provide some desired interaction. We design a new video partitioning that is more suitable for inter [...] ...|$|E
5000|$|William [...] "Willie" [...] Doran (born 1982 in Boolavogue, County Wexford) is an Irish sportsperson. He played hurling {{with his}} <b>local</b> club <b>Buffer's</b> Alley {{and was a}} member of the Wexford senior hurling team.|$|R
50|$|Mick Butler (born 1950 in Boolavogue, County Wexford) is an Irish former sportsperson. He played hurling {{with his}} <b>local</b> club <b>Buffer's</b> Alley {{and was a}} member of the Wexford senior inter-county team from 1969 until 1981.|$|R
30|$|In {{order to}} allow 802.11 devices to support the NC {{suggested}} schemes, besides the basic network operation such as coding and decoding messages or implementing the decision policy at the AP, only a few modifications which {{are related to the}} standard are required. Specifically it is required to: (I) allow users to accept packets of which they are not the addressee, and to realize <b>local</b> <b>buffers</b> to store such packets; (II) stop the automatic MAC layer retransmissions (i.e., to set the dot 11 LongRetryLimit to one); (III) modify 802.11 MAC headers to incorporate network coding information; and IV) design new MAC control packets which provide the status of each user.|$|R
30|$|Q(p 0, l) and Q(p 0, l - 1) {{belong to}} Q(p 0). Hence, given the layer buffer Q(p 0 - 2) and Q(p 0 - 1) and the <b>local</b> <b>buffer</b> Q(p 0, l - 1), the costs in Q(p 0, l) are updated at each layer l recursively, which {{sequence}} {{is described in}} Figure 6 a, b, and 6 c. That is, given M(Q(p 0 - 1)), M(Q(p 0 - 2)), and D(Q(p 0 - 1)), we can calculate M(Q(p 0)). The new costs in <b>local</b> <b>buffer</b> should be stored in the layer buffer to process the next set Q(p 0 + 1) in the next time. This sequence shifts the layer buffer to the p 0 axis direction. Then, for p 0 from 0 to N + L - 1, we can obtain the final iterated message M(Q(p 0, L)). For the example, as shown in Figure 6 b, and 6 c, {{the location of the}} buffer is changed from Q(p 0 = 5) to Q(p 0 = 6) by our sequence.|$|E
40|$|The {{effect of}} the size of <b>local</b> <b>buffer</b> packet memory on the {{throughput}} of FDDI adapters is examined. The analysis focuses on transmit buffer size and covers both the loaded and unloaded FDDI ring cases. A hypothetical EISA FDDI adapter design is used as a vehicle to demonstrate the throughput characteristics of different <b>local</b> <b>buffer</b> memory sizes. Calculations are done to size the buffer with respect to the latency of the EISA bus for the card in a target system configuration and with respect to the amount of effective bandwidth that the card can expect to receive. It is demonstrated that sizing a buffer based on these two methods results in poor throughput when the FDDI ring is loaded. As a solution to the performance problem, it is suggested that buffer sizing based on the TTRT value of the ring will result in an adapter that is capable of realizing high throughput. Finally, the AMD SUPERNET ™ 2 FDDI chipset is examined to show that it is able to meet a diverse set of buffer sizing needs. 1...|$|E
40|$|Audio and Video Coding Standard- Part 2 (AVS-P 2) is a video coding {{standard}} {{developed by the}} AVS Workgroup of China. In this paper, an intra prediction scheme for high definition (HD) AVS encoder is proposed to reduce the <b>local</b> <b>buffer</b> storage and computational complexity in hardware. Simulation results show that our scheme induces very little performance degradation in general frame structure. It can be easily and efficiently implemented for practical applications. Index Terms—AVS, H. 264 /AVC, intra prediction, hardware codec design. 1...|$|E
50|$|Ciarán Kenny (born 14 August 1984 in Kilmuckridge, County Wexford, Ireland) is an Irish sportsperson. He plays hurling {{with his}} <b>local</b> club <b>Buffers</b> Alley {{and has been}} a member of the Wexford senior inter-county team since 2006.|$|R
40|$|This {{paper is}} {{concerned}} with the evaluation of combined dispatching and routeing strategies on the performance of a flexible manufacturing system. Three routeing policies: no alternative routeings, alternative routeings dynamic and alternative routeings planned are considered with four dispatching rules with finite buffer capacity. In addition, the effect of changing part mix ratios is also discussed. The performance measures considered are makespan, average machine utilization, average flow time and average delay at <b>local</b> input <b>buffers.</b> Simulation results indicate that the alternative routeings dynamic policy gives the best results in three performance measures except for average delay at <b>local</b> input <b>buffers.</b> Further, the effect of changing part mix ratios is not significant. link_to_subscribed_fulltex...|$|R
40|$|Xr {{provides}} a vector-based rendering API with output {{support for the}} X Window System and <b>local</b> image <b>buffers.</b> PostScript and PDF file output is planned. Xr is designed to produce identical output on all output media while taking advantage of display hardware acceleration through the X Render Extension...|$|R
