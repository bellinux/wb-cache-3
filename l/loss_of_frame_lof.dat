0|10000|Public
50|$|The {{method used}} to {{transmit}} the alarm {{makes use of}} the fact that in telephone systems, transmission is always two way). Multiplexing/demultiplexing devices (known generically as multiplex devices) are installed {{at both ends of the}} communication for the transmission and reception <b>of</b> <b>frames.</b> An alarm must be sent to the transmitter when a device detects either a power failure or a failure of the coder/decoder, in its multiplexer; or any of the following in its demultiplexer: <b>loss</b> <b>of</b> the signal (LOS), <b>loss</b> <b>of</b> <b>frame</b> alignment (<b>LOF),</b> or a BER greater than 10−3.|$|R
5000|$|Back-to-back or burstability: {{measures}} the longest burst <b>of</b> <b>frames</b> at maximum throughput or minimum legal separation between frames that the device or network under test will handle without any <b>loss</b> <b>of</b> <b>frames.</b> This measurement {{is a good}} indication of the buffering capacity of a DUT.|$|R
5000|$|Informally, team play {{can also}} be {{conducted}} in [...] format. However, the disqualification rule does not apply, and three consecutive fouls by the team are a <b>loss</b> <b>of</b> <b>frame</b> (otherwise, {{the team with the}} hypothetically disqualified player would have an advantage, in no longer having to coordinate two players).|$|R
5000|$|With an {{analogue}} system, {{the visual}} fast-forward/rewind effect was generated simply by transmitting the frames faster and/or in reverse; {{there was an}} inevitable <b>loss</b> <b>of</b> <b>frame</b> synchronization or 'tearing' but this was accepted as the norm. With a digital system, {{it is unlikely that}} the decoder can process the digital stream significantly faster than normal, and certainly not backwards. Therefore, only a subset <b>of</b> <b>frames</b> can be presented to the decoder.|$|R
5000|$|In addition, 140 Mbit/s {{multiplexers}} also transmit {{an alarm}} indication {{when faced with}} the <b>loss</b> <b>of</b> <b>frame</b> alignment <b>of</b> the 34-Mbit/s signals received inside the 140 Mbit/s signals, {{as well as in the}} NFAS of the 34 Mbit/s signal that has lost its alignment (bit 11 of group I changes from [...] "0" [...] to [...] "1") in the return channel.|$|R
5|$|Dishonored 2 {{received}} generally favorable reviews {{according to}} Metacritic. On its release, PC players reported issues with performance such as <b>loss</b> <b>of</b> <b>frame</b> rate and display resolution, and system crashes. Three patches for the PC version were released {{to remedy the}} problem. The levels Clockwork Mansion and A Crack in the Slab were singled out to considerable praise. The game has been the recipient of over one hundred Best of 2016 awards.|$|R
40|$|This paper aims {{to address}} the issue of message deliv-ery {{reliability}} in real-time, wireless communication sys-tems. We discuss the provision of a probabilistic ad-missions control protocol that adapts retransmissions <b>of</b> <b>frames</b> to reflect the reliability of the medium and the re-quired timeliness of real-time data for transmission. We utilise a two-pronged approach: firstly, admissions con-trol to ensure transmission time is reserved such that re-transmissions are possible, and secondly, an exponential backoff process to reschedule failed transmissions on a station-by-station basis. Combining these measures, we ensure the fulfillment of real-time guarantees while toler-ating a limited <b>loss</b> <b>of</b> <b>frames</b> on the medium. ...|$|R
40|$|The five OAM flows are the following: F 5 : OAM {{information}} flows between network elements performing VC functions. From {{the perspective}} of a BISDN configuration, F 5 OAM operations are conducted between B-NT 2 /B-NT 1 endpoints. F 5 deals with degraded VC performance, such as late arriving cells, lost cells, cell insertion problems, etc. F 4 : OAM information flows between network elements performing VP functions. From {{the perspective of}} a BISDN configuration, F 4 OAM flows between B-NT 2 and ET. F 4 OAM reports on an unavailable path or a virtual path (VP) that cannot be guaranteed. F 3 : OAM information flows between elements that perform the assembling and disassembling of payload, header, and control (HEC) operations, and cell delineation. From {{the perspective of a}} BISDN configuration, F 3 OAM flows between B-NT 2 and VP cross connect and ET. F 2 : OAM information flows between elements that terminate section endpoints. It detects and reports on <b>loss</b> <b>of</b> <b>frame</b> synchronization and degraded error performance. From the perspective of a BISDN configuration, F 2 OAM flows between B-NT 2, B-NT 1, and LT, as well as from LT to LT. F 1 : OAM information flows between regenerator sections. It detects and reports on <b>loss</b> <b>of</b> <b>frame</b> an...|$|R
40|$|Abstract — In a WLAN {{subject to}} {{variable}} wireless channel conditions, rate adaptation {{plays an important}} role to more efficiently utilize the physical link. However, the existing rate adaptation algorithms for IEEE 802. 11 WLANs do {{not take into account the}} <b>loss</b> <b>of</b> <b>frames</b> due to collisions. In a WLAN with coexistence of multiple stations, two types <b>of</b> <b>frame</b> <b>losses</b> due to (a) link errors and (b) collisions over the wireless link can coexist and severely degrade the performance of the existing rate adaptation algorithms. In this paper, we propose a new automatic rate fallback algorithm that can differentiate the two types <b>of</b> <b>losses</b> and sharpen the accuracy of the rate adaptation process. Numerical results show that the new algorithm can substantially improve the performance of IEEE 802. 11 WLANs...|$|R
40|$|Streaming video over a {{wireless}} network faces several challenges {{such as high}} packet error rates, bandwidth variations, and delays, which could have negative effects on the video streaming and the viewer will perceive a frozen picture for certain durations due to <b>loss</b> <b>of</b> <b>frames.</b> In this study, we propose a Time Interleaving Robust Streaming (TIRS) technique to significantly reduce the frozen video problem and provide a satisfactory quality for the mobile viewer. This is done by reordering the streaming video <b>frames</b> as groups <b>of</b> even and odd <b>frames.</b> The objective <b>of</b> streaming the video {{in this way is}} to avoid the <b>losses</b> <b>of</b> a sequence <b>of</b> neighbouring <b>frames</b> in case <b>of</b> a long sequence interruption. We evaluate our approach by using a user panel and mean opinion score (MOS) measurements; where the users observe three levels <b>of</b> <b>frame</b> <b>losses.</b> The results show that our technique significantly improves the smoothness of the video on the mobile device in the presence <b>of</b> <b>frame</b> <b>losses,</b> while the transmitted data are only increased by almost 9 % (due to reduced time locality) ...|$|R
40|$|International audienceThe rise of Big Data and {{powerful}} mobile devices calls for libraries able to render {{a large number}} of visual elements and make fast animations without <b>loss</b> <b>of</b> <b>frame</b> rate. We introduce the FATuM library as a middleware for vi-sualization. With a single abstraction for visual elements {{based on the work of}} Bertin and adaptation of the double buffering technique, we enable animated visualization of large datasets in native applications and in the browser using the same codebase. Our system does not differentiate animated from static rendering, thus reducing code complexity and guaranteeing smooth animation. We show that our system maintains 60 fps for up to 200. 000 visual elements in a native application and 30 fps for 100. 000 visual elements in a web browser...|$|R
40|$|Abstract–Concurrent {{retrieval}} of continuous media from a physical storage device {{can be achieved}} by interleaving data and providing a suitable scheduling algorithm. Scheduling approaches that exploit gains from statistical multiplexing are susceptible to a non-zero probability <b>of</b> <b>frame</b> <b>loss</b> due to the variable-bit-rate characteristic of compressed video. With interframe encoding schemes (such as specified by the MPEG standard), the losses propagate, resulting in a net <b>loss</b> <b>of</b> <b>frames</b> that exceeds the fraction of missing data. In this paper we describe a mechanism for the storage and {{retrieval of}} MPEG-encoded video from a single disk storage system. The scheme balances the need for the reliable delivery <b>of</b> MPEG <b>frames</b> with the desire to support the largest number of sessions. Our approach reorganizes the MPEG-encoded video stream based on the relative importance <b>of</b> the <b>frames</b> and maps them to the storage device geometry. The reorganization reduces the impact <b>of</b> <b>frames</b> lost due to missed deadlines and distributes the frame losses over time and among sessions. Simulation results show that the new approach improves performance when compared to conventional storage and scheduling schemes...|$|R
5000|$|A {{combination}} of eight-ball and rotation, eight-ball rotation or rotation eight-ball requires that each [...] (...) , [...] versus , must be pocketed in their numerical order (some prefer descending order for stripes), {{aside from the}} [...] (...) , which is the [...] Eight-ball rotation is racked with the 8 ball in the center, not the 15, and the game does not count the numerical value of the balls for a score; the frame can only be won by legally pocketing the 8 (and a foul while doing so, or attempting to do so, depending upon specific rules use, is a <b>loss</b> <b>of</b> <b>frame).</b> This variation is appropriate for team {{as well as individual}} competition, and also used as a mutual practice game for both eight-ball and (because it integrates rotation strategy) nine-ball or ten-ball.|$|R
40|$|Video {{delivery}} from {{a server}} to a client across a network {{is an important}} component of many multimedia applications. While delivering a video stream across a resource constrained network, <b>loss</b> <b>of</b> <b>frames</b> may be unavoidable. Under such circumstances, it is desirable to find a server transmission schedule that can efficiently utilize the network resources while maximizing the perceived quality-of-service (QoS) at the client. To address this issue, in this paper we introduce the notion <b>of</b> selective <b>frame</b> discard at the server and formulate the optimal selective frame discard problem using a QoS-based cost function. Given network bandwidth and client buffer constraints, we develop an algorithm to find the minimum number <b>of</b> <b>frames</b> that must be discarded in order to meet these constraints. The correctness of the algorithm is also formally established. We present a dynamic programming based algorithm for solving the problem <b>of</b> optimal selective <b>frame</b> discard. Since the computational complexity of the optimal algorithm is prohibitively high in general, we also develop several efficient heuristic algorithms for selective frame discard. These algorithms are evaluated using JPEG and MPEG video traces...|$|R
30|$|We have {{evaluated}} and compared several well-known objective video quality algorithms using the videos and subjective {{results in the}} three databases. The objective algorithms are described below. The default values of the metrics were used for all the metrics. No registration problems, i.e., a misalignment between the reference and degraded videos due to the <b>loss</b> <b>of</b> entire <b>frames,</b> occurred in the dataset.|$|R
500|$|The {{original}} Dreamcast {{version of}} Crazy Taxi {{was one of}} the best-selling games for the console. The game was the second largest selling Dreamcast game in the United States in 2000, selling nearly 750,000 units, and is the third best-selling Dreamcast game in the United States with over a million units sold. The game was praised for capturing the arcade flavor, and possibly exceeding it by making the controls and execution of the crazy stunts easier to perform. The game did suffer from [...] "pop-up" [...] due to limited draw distances, and <b>loss</b> <b>of</b> <b>frame</b> rate when a large number of cars were on the screen. Critics noted the lack of depth given that it was a port of an arcade game, some difficulties with the destination arrow, and the poor [...] "Wolfman Jack" [...] impersonation of the in-game announcer.|$|R
40|$|Abstract—We {{consider}} {{the design of}} a P 2 P network for the distribution of real-time video streams through the Internet. We follow a multi-source approach where the stream is decomposed into several flows sent by different peers to each client. The goal is to resist to the frequent moves of the peers entering and leaving the network. We analyze our approach using the recently proposed PSQA technology which allows to obtain an accurate (and automatic) numerical evaluation of the quality as perceived by each client. Our transmission technique includes the use of an arbitrary amount of redundancy in the signal, whose specification {{is a part of the}} dimensioning process, and it works with very low signaling overhead. We illustrate with real data how the overall system allows to compensate efficiently the possible <b>losses</b> <b>of</b> <b>frames</b> due to peers leaving the network. I...|$|R
40|$|While {{delivering}} {{real-time video}} streams across a resource constrained network, <b>loss</b> <b>of</b> <b>frame</b> may be unavoidable. Under such circumstances, {{it is desirable}} to design smart video packet drop policies thattake into account {{the ability of the}} end terminals to recover totally or partially the corrupted data using forward error correction and error concealment feature. To address this issue, in this paper we introduce the concept of "Cell Drop Tolerance" at the switch node. This concept is supported by a new video slice drop mechanism named FEC-PSD, that adaptively and selectively adjusts cell drop level to switch buffer occupancy, video cell payload type and error correction/concealment ability of the destination. The aim of this proposal is twofold. First, minimizing loss for critical video data, and second, reducing the bad throughput crossing the network. This algorithm is evaluated using MPEG- 2 video traces...|$|R
5000|$|The {{original}} Dreamcast {{version of}} Crazy Taxi {{was one of}} the best-selling games for the console. The game was the second largest selling Dreamcast game in the United States in 2000, selling nearly 750,000 units, and is the third best-selling Dreamcast game in the United States with over a million units sold. The game was praised for capturing the arcade flavor, and possibly exceeding it by making the controls and execution of the crazy stunts easier to perform. The game did suffer from [...] "pop-up" [...] due to limited draw distances, and <b>loss</b> <b>of</b> <b>frame</b> rate when a large number of cars were on the screen. Critics noted the lack of depth given that it was a port of an arcade game, some difficulties with the destination arrow, and the poor [...] "Wolfman Jack" [...] impersonation of the in-game announcer.|$|R
40|$|This paper {{focuses on}} the {{rate-distortion}} optimization of low-delay 3 D video communications based on the latest H. 264 /MVC video coding standard. The {{first part of the}} work proposes a new low-complexity model for distortion estimation suitable for low-delay stereoscopic video communication scenarios such as 3 D videoconferencing. The distortion introduced by the <b>loss</b> <b>of</b> a given <b>frame</b> is investigated and a model is designed in order to accurately estimate the impact that the <b>loss</b> <b>of</b> each <b>frame</b> would have on future frames. The model is then employed in a rate-distortion optimized framework for video communications over a generic QoS-enabled network. Simulations results show consistent performance gains, up to 1. 7 dB PSNR, with respect to a traditional a priori technique based on frame dependency information only. Moreover, the performance is shown to be consistently close to the one of the prescient technique that has perfect knowledge of the distortion characteristics <b>of</b> future <b>frames...</b>|$|R
40|$|This paper {{describes}} {{the solution of}} a problem arising {{in the application of}} complementarity for physical simulations that occur within video games. The size of the problems is typically not very large, ranging from around 20 variables to a current limit of around 400 variables. The computational time available to solve each instance of the problem is limited by the <b>frame</b> rate <b>of</b> the simulation, and the memory allowed to solve each problem is severely restricted by the hardware available on many of the existing game (console) platforms. The typical time <b>frame</b> is <b>of</b> the order of milliseconds, while the amount of fast RAM available is 4 - 16 K. A further important feature of the solution technique is that worst case behaviour is very important - if large spikes in computation occur this can lead to <b>loss</b> <b>of</b> <b>frames</b> and jumpy screen animation...|$|R
40|$|Broadcast {{networks}} that are characterised by having different physical layers (PhL) demand {{some kind of}} traffic adaptation between segments, {{in order to avoid}} traffic congestion in linking devices. In many LANs, this problem is solved by the actual linking devices, either behaving like gateways or "intelligent bridges " that use some kind of congestion control/avoidance mechanism. In this paper, we address the case of token-passing fieldbus networks operating in a broadcast fashion and involving message transactions over heterogeneous (wired or wireless) physical layers. For the addressed case, real-time (bounded message response times) and reliability (<b>loss</b> <b>of</b> <b>frames</b> not allowed) requirements demand a new solution to the traffic adaptation problem. Our approach relies on the insertion of an appropriate idle time before a station issuing a request frame. In this way, we guarantee that the linking devices' queues do not increase {{in a way that the}} timeliness properties of the overall system turn out to be unsuitable for the targeted applications...|$|R
40|$|In {{this paper}} we {{address the problem of}} {{designing}} a P 2 P system for distribution real-time video streams through the Internet. The main advantage of this approach is to use the available bandwidth unused by the set of machines con-nected to the network. The main difficulty is that these machines are typically highly dynamic, they continuously enter and leave the network. To deal with this problem, we explore a multi-source approach where the stream is decom-posed into several flows sent by different peers to each client. To evaluate the impact of this approach on quality, we use PSQA, a recently proposed method that allows to obtain a good approximation of the quality as perceived by each client. In particular, we provide a variant of muti-source techniques using some redundancy in the signal, illustrating with real data how the methods allow to compensate effi-ciently the possible <b>losses</b> <b>of</b> <b>frames</b> due to peers leaving the system...|$|R
40|$|Recently we {{have seen}} {{research}} efforts on how to protect a real-time speech signal when transmitting over an unreliable packet-switched network like the Internet by open-loop error control. Research has covered the type of Foward Error Correction (generic or voice-specific), the protocol support needed and adaptivity to the current network congestion state. However, the sender {{does not take into}} account that some segments of the signal are essential to the speech quality, while others can be extrapolated at the receiver from data received earlier in the event <b>of</b> a packet <b>loss.</b> This is especially true for modern frame-based codecs like the G. 729 and G. 723. 1 which contain an internal loss concealment algorithm. Thus, the sender consumes additional bandwidth and aggravates the congestion in the Internet by sending unnecessary redundancy. In this paper we first analyze the concealment performance of the G. 729 decoder. We find that the <b>loss</b> <b>of</b> unvoiced <b>frames</b> can be concealed well. Also, the <b>loss</b> <b>of</b> voiced <b>frames</b> is concealed well once the decoder has obtained sufficient information on them. However the decoder fails to conceal the <b>loss</b> <b>of</b> voiced <b>frames</b> at an unvoiced/voiced transition because it extrapolates internal state (filter coefficients and excitation) for an unvoiced sound. Moreover, once the encoder has failed to build the appropriate linear prediction synthesis filter, it takes a long time for the decoder to resynchronize with the encoder. Using this result, we then develop a new FEC scheme to support frame-based codecs, which adjusts the amount of added redundancy adaptively to the properties of the speech signal. Objective quality measures (ITU P. 861 A and EMBSD) show that our speech property-based FEC (SPB-FEC) scheme achieves almost the same speech quality a [...] ...|$|R
40|$|ITU’s {{objective}} evaluation algorithm PESQ {{predicts the}} quality of speech transmissions. In this work we verify whether PESQ can measure the impact <b>of</b> single <b>frame</b> <b>losses</b> – a source of impairment for which PESQ has not been designed. To construct samples for experimental tests, we develop a tool that controls the <b>loss</b> <b>of</b> specific <b>frames,</b> e. g. only important or voiced frames. We conduct subjective, formal listening-only tests to verify PESQ’s prediction performance. The human ratings correlate with PESQ at a degree of R= 0. 94. Given the precision of speech quality measurements we show the equality of subjective and instrumental results...|$|R
50|$|Ding Junhui {{fell out}} of the top 16 prior to the tournament, and had to qualify to the Crucible {{for the first time since}} 2007. He did that at the <b>loss</b> <b>of</b> just seven <b>frames,</b> beating Greg Casey 10-4, Ross Muir 10-1, and the 1995 runner-up Nigel Bond 10-2.|$|R
5000|$|If a [...] is {{committed}} (other than a foul break or cue ball foul, as detailed below), the incoming opponent may either {{take the next}} shot or require the opponent to do so, with all balls as they lie in either case. If the exiting opponent's foul was [...] the cue ball into a pocket or off the table, the incoming player's shot is necessarily ball-in-hand, and must be taken from behind the [...] (in [...] ), although the incoming player may optionally require the fouling opponent to shoot again instead, with ball-in-hand behind the headstring. Shots taken from behind the head string must cause the cue ball to cross the head string; however, if the ball-on is behind the head string, the player with ball in hand (including a fouling player who {{has been forced to}} take the shot by the opponent) may optionally have that ball spotted on the foot spot before shooting. There is no point penalty for fouls Three consecutive fouls (i.e. on three consecutive turns at the table) by the same player is a <b>loss</b> <b>of</b> <b>frame.</b>|$|R
40|$|In {{this paper}} we {{investigate}} {{the properties of}} the PROFIBUS MAC protocol when operated over error prone links, like wireless links. In order to show that the protocol is very sensible to <b>loss</b> <b>of</b> control <b>frames</b> (e. g. token frames) we evaluate three performance measures, using a simulation approach: the mean delay, the mean station outage time and the cumulated outage time, i. e. the fraction of time where a single station is not member of the ring due to <b>loss</b> or error <b>of</b> control <b>frames.</b> The results indicate that the PROFIBUS MAC protocol is not really a good choice for use over error prone links. ...|$|R
30|$|At the decoder, {{the packet}} <b>loss</b> rate <b>of</b> each <b>frame</b> is {{evaluated}} {{based on the}} received video information. It is then {{sent back to the}} two Turbo encoders via the RTCP feedback packets. Depending on the channel packet loss rates conveyed, the two Turbo encoders adjust the parity data rates for encoding the motion information and the transform coefficients <b>of</b> the current <b>frame.</b>|$|R
40|$|The {{transmission}} of coded visual information over packet networks introduces fidelity {{problems related to}} the <b>loss</b> <b>of</b> <b>frames</b> during transmission. In standard block-based coding, such losses result in a wrong reconstruction of long block sequences, also due {{to the use of}} predictive and variable length source coding techniques. In video transmission, artifacts are even more visible due to the temporal propagation caused by prediction and interpolation schemes. In order to reduce the impact of these errors on visual quality, appropriate concealment algorithms should be applied, aimed at minimizing the appearance of block artifacts due to transmission errors. In this paper, a new concealment technique is presented, which aims at restoring the lost visual information by using a synthetic reconstruction of the high-frequency content of the damaged blocks. The method is funded on the theory of sketch-based encoders: for each block to be interpolated, the sketch information of the available surrounding blocks is extracted and propagated to the missing area. Then, the low-pass content is easily interpolated from the sketch. The proposed method uses only the spatial correlation, and has been applied with good results in the {{transmission of}} video data over non-reliable packet networks...|$|R
40|$|The paper {{presents}} a new method {{to set up}} energy performance requirements and energy classes for windows of all dimensions and configurations. The net energy gain of windows is the solar gain minus the heat loss integrated over the heating season. The net energy gain can be calculated for one orientation or averaged over different orientations. The averaged value {{may be used for}} energy labeling of windows of standard size. Requirements in building codes may also be based on the net energy gain instead of the thermal transmittance of the window. The size and the configuration of the window, i. e. number of glazing units, have a very large effect on the net energy gain. Therefore the energy labeling or the requirements based on the standard size may not give valid information on the energy performance of windows of non-standard size. The paper {{presents a}} method to set up requirements and classes for energy performance based on the net energy gain that includes the effect of window size and configuration. The net energy gain of windows can be divided into the net energy gain of the glazing unit and the heat <b>losses</b> <b>of</b> the <b>frame</b> and the assembly of the glazing unit and the frame. The glazing unit contributes proportionally to its area. The frame also contributes proportionally to its area, but as the area <b>of</b> the <b>frame</b> is the width times the length, the heat <b>losses</b> <b>of</b> the <b>frame</b> and the assembly both contribut...|$|R
5000|$|Like Hi-Vision, HD-MAC {{could not}} be {{transmitted}} in 8 MHz channels without substantial modification [...] - [...] and a severe <b>loss</b> <b>of</b> quality and <b>frame</b> rate. A 6 MHz version Hi-Vision was experimented with in the US, but it too had severe quality problems so the FCC never fully sanctioned its use as a domestic terrestrial television transmission standard.|$|R
40|$|Cooperative {{protocols}} {{are a new}} {{and promising}} research field {{that can lead to}} a better understanding of wireless ad-hoc networking. In this paper we focus on cooperative hop-by-hop ARQ (automatic repeat request) protocols. The main objective of a hop-by-hop ARQ is to prevent, by means <b>of</b> <b>frame</b> retransmission, the <b>loss</b> <b>of</b> <b>frames</b> due to transmission errors. Classically, when the receiver node detects errors in the received frame, it asks for a frame retransmission to the transmitter node. The key idea of cooperative ARQ is that nodes others than transmitter and receiver can play a role in the protocol operation, exploiting some of the characteristics of wireless media such as natural broadcast of wireless transmission, and leading to significant improvements in protocol performance. Examples of cooperative hop-by-hop ARQ protocol are [2], [3], [4] and [6]. In all cases, authors report significant improvements in terms of transmission power, transmission range or throughput. Cooperative ARQ protocols exploit receiver diversity [1], a well-known wireless transmission technique. The classical optimal way of exploiting receiver diversity is Maximal Ratio Combining (MRC). In MRC, nodes use an array of antennas with a minimal separation of around half wavelength. Signals received by each antenna are coherently combined before detection, using an estimate of the received SNR as weight for each branch. For Rayleigh channels, for instance, it can be shown that the Bit Error Rate (BER) versus?, the average Signal to Noise Ratio (SNR), is given by...|$|R
30|$|Although {{pin site}} infections are complications, severe {{problems}} may follow that could compromise treatment goals and increase patient morbidity [31, 36, 39]. These include pin loosening (with <b>loss</b> <b>of</b> fixation, <b>loss</b> <b>of</b> alignment, <b>frame</b> instability, and, in rare cases, abandoning external fixator treatment [26, 28]), osteomyelitis, joint or fracture site contamination, and increasing pain which limits patient function. Loose pins and wires, when identified, {{should be removed}} promptly to prevent progression to osteomyelitis and the pins and wires vital to construct integrity need to be replaced. Osteomyelitis may arise from superficial pin site infections in up to 4  % of cases and represents the most severe consequence of a superficial infection [36]. Timely, meticulous surgical debridement can prevent this from becoming chronic osteomyelitis.|$|R
30|$|Based on {{an opinion}} model from ITU-T[140], an {{automatic}} QoE monitoring method is proposed in[161]. It {{depends on the}} network level information derived from packet loss pattern and <b>loss</b> rank <b>of</b> a <b>frame</b> {{in a group of}} pictures (GOP) and a measure of motion vectors to represent motion activity to train an ANN model against subjective scores of expert viewers.|$|R
40|$|Wireless capsule video {{endoscopy}} is a {{novel and}} challenging clinical technique, whose major reported drawback relates to the high amount of time needed for video visualization. In this paper, we propose a method for {{the rejection of the}} parts of the video resulting not valid for analysis by means of automatic detection of intestinal juices. We applied Gabor filters for the characterization of the bubble-like shape of intestinal juices in fasting patients. Our method achieves a significant reduction in visualization time, with no relevant <b>loss</b> <b>of</b> valid <b>frames.</b> The proposed approach is easily extensible to other image analysis scenarios where the described pattern of bubbles can be found. 1...|$|R
