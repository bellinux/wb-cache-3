107|111|Public
5000|$|In 1994, Dell {{proposed}} {{a model of}} the <b>lexical</b> <b>network</b> that became fundamental in the understanding of the way speech is produced. This model of the <b>lexical</b> <b>network</b> attempts to symbolically represent the lexicon, and in turn, explain how people choose the words they wish to produce, and how those words are to be organized into speech. Dell's model was composed of three stages, semantics, words, and phonemes. The words in the highest stage of the model represent the semantic category. (In the image, the words representing semantic category are winter, footwear, feet, and snow represent the semantic categories of boot and skate.) The second level represents the words that describe the semantic category (In the image, boot and skate). And, the third level represents the phonemes ( [...] syllabic information including onset, vowels, and codas).|$|E
5000|$|Levelt further refined the <b>lexical</b> <b>network</b> {{proposed}} by Dell. Through {{the use of}} speech error data, Levelt recreated the three levels in Dell's model. The conceptual stratum, the top and most abstract level, contains information a person has about ideas of particular concepts. The conceptual stratum also contains ideas about how concepts relate to each other. This is where word selection would occur, a person would choose which words they wish to express. The next, or middle level, the lemma-stratum, contains information about the syntactic functions of individual words including tense and function. [...] This level functions to maintain syntax and place words correctly into sentence structure that makes sense to the speaker. The lowest and final level is the form stratum which, similarly to the Dell Model, contains syllabic information. From here, the information stored at the form stratum level {{is sent to the}} motor cortex where the vocal apparatus are coordinated to physically produce speech sounds.|$|E
50|$|Along with {{structural}} priming, {{clients with}} aphasia perform semantic priming, but they require {{more time to}} complete language tasks such as the lexical decision task. This {{is largely due to}} the large onset competitor effect, meaning the inability to distinguish words with shared semantic onsets (Yee, Blumstein & Sedivy, 2009). However, aphasic patients perform at chance levels for semantic judgment tasks. In comparison to normal patients, those with aphasia will increasingly fixate on words semantically related to the target. Therefore, they are able to access lexical entries and activate the <b>lexical</b> <b>network</b> but lack the ability to use such information within an offline task (McNellis & Blumstein, 2001, p. 162). Semantic representations decline largely due to the blurring of category boundaries, reduced difference between basic terms, incapability to judge semantic relatedness and abnormal activation of semantic representations of nonwords. Further, aphasia is characterized by deficits in lexical retrieval through the presence of nonword errors (Marshall, 2006, pg. 392). Nonword errors are typically substituted for content words and follow pauses. Many times, patients will not recognize their speech errors and continue communicating jargon with little to no self-monitoring of the speech output (Marshall, 2006, p. 398).|$|E
40|$|Between simple {{electronic}} dictionaries {{such as the}} TLFi (computerized French Language Treasure) 1 and <b>lexical</b> <b>networks</b> like WordNet 2 (Diller et al., 1990; Vossen, 1998), the lexical databases {{are growing}} at high speed. Our work is about the addition of rich links to lexical databases, {{in the context of}} the parallel development of <b>lexical</b> <b>networks.</b> Current research on management tools for lexical databases is strongly influenced by the field of massive data ("big data") and by the Web of data ("linked data"). In <b>lexical</b> <b>networks,</b> one can build and use arbitrary links, but possible queries cannot model all the usual interactions with lexicographers-developers and users, that are needed, and derive from the paper world. Our work aims to find a solution that allows for the main advantages of <b>lexical</b> <b>networks,</b> while providing the equivalent of paper dictionaries by doing the lexicographic work in lexical DBs. ...|$|R
40|$|This paper {{compares the}} "radial category" of image schemas derived for the polysemous word "over", by Brugman and Lakoff, 1987, with the <b>lexical</b> <b>networks</b> for "over" derived by the author, from Roget's International Thesaurus, 3 rd Edition, and The Oxford English Dictionary, 2 nd Edition. 1...|$|R
40|$|WordNet, {{conceptual}} vectors, lexical information, thematic information There {{is currently}} much research in {{natural language processing}} focusing on <b>lexical</b> <b>networks.</b> Most of them, in particular the most famous, WordNet, lack syntagmatic information and especially thematic information (“Tennis Problem”). This article describes conceptual vectors that allows the representation of ideas in any textual segment and offers a continuous vision of related thematics, based on the distances between these thematics. We show the characteristics of conceptual vectors and explain how they complement lexico-semantic networks. We illustrate this purpose by adding conceptual vectors to WordNet by emergence. Originally resulting from Ross Quillian’s work on psycholinguistics (Quillian, 1968), <b>lexical</b> <b>networks</b> are today {{the subject of much}} research in Natural Language Processing. They are employed in many tasks (lexical disambiguation (Mihalcea et al., 2004)) or field applications (machine translation with multilingual networks like Papillon (Mangeot-Lerebours et al., 2003) or (Knight & Luk, 1994), informatio...|$|R
40|$|The {{present study}} investigates the {{features}} of <b>lexical</b> <b>network</b> in Australian learners of Chinese {{as a second language}} (CSL) with the help of word association tests. Results show that as Chinese native speakers, the associations between words in Chinese learners ’ mental lexicon are primarily semantic-based. As learners grow in proficiency, they share more commonalities with the native speakers in word association behaviours. Compared with ESL <b>lexical</b> <b>network,</b> the CSL <b>lexical</b> <b>network</b> shows some unique features. Pedagogical implications for CSL vocabulary teaching and learning are also discussed...|$|E
40|$|The JDM <b>lexical</b> <b>network</b> {{has been}} built thanks to on-line games the main of which, JeuxDeMots (JDM), was {{launched}} in 2007. It is currently a large <b>lexical</b> <b>network,</b> in constant evolution, containing more than 310 000 terms connected by more than 6. 5 million relations. The riddle game Totaki (Tip Of the Tongue with Automated Knowledge Inferences), the initial version of which was elaborated with Michael Zock, was launched in a first version in 2010. The initial aim of this project is to cross validate the JDM <b>lexical</b> <b>network.</b> Totaki uses this <b>lexical</b> <b>network</b> to make proposals from user given clues, and in case of failure players can supply new information, hence enriching the network. Endogenous processes of inference, by deduction, induction, abduction, also allow to find new information not directly available in the network and hence lead to a densification of the network. The assumption about the validation is that if Totaki is able to guess proper terms from user clues, then the <b>lexical</b> <b>network</b> contains appropriate relations between words. Currently, Totaki achieves a 75 % success rate, to be compared to less than 50 % if the guessing is done by human users. One serious application of Totaki is {{to be viewed as}} a tool for lexical access and a possible remedy for the tip of the tongue problem. The Wikipedia encyclopaedia, built in a collaborative way, represents a very important volume of knowledg...|$|E
40|$|This article {{presents}} Propa-L, a freely accessible Web service that allows to semantically filter a <b>lexical</b> <b>network.</b> The language resources behind the service are dynamic and created through Games With A Purpose. We show {{an example of}} application of this service: the generation of a list of keywords for parental filtering on the Web, but many others can be envisaged. Moreover, the propagation algorithm we present here {{can be applied to}} any <b>lexical</b> <b>network,</b> in any language...|$|E
40|$|Abstract. There is {{currently}} much research in {{natural language processing}} focusing on <b>lexical</b> <b>networks.</b> Most of them, in particular the most famous, Word-Net, lack syntagmatic information and especially thematic information (”Tennis Problem”). This article describes conceptual vectors that allows the representation of ideas in any textual segment and offers a continuous vision of related thematics, based on the distances between these thematics. We show the characteristics of conceptual vectors and explain how they complement lexico-semantic networks. We illustrate this purpose by adding conceptual vectors to WordNet by emergence. Originally resulting from Ross Quillian’s work on psycholinguistics [1], <b>lexical</b> <b>networks</b> are today object of many researches in Natural Language Processing. They are employed in many tasks (lexical disambiguation [2]) or field applications (machine translation with multilingual networks like Papillon [3] or [4], information retrieval or text classification [5]). Most of these networks and specifically the most famous, Word-Net [6], miss syntagmatic information and, in particular, information concerning th...|$|R
40|$|We present {{heterogeneous}} networks {{as a way}} {{to unify}} <b>lexical</b> <b>networks</b> with relational data. We build a unified ACL Anthology network, tying together the citation, author collaboration, and term-cooccurence networks with affiliation and venue relations. This representation proves to be convenient and allows problems such as name disambiguation, topic modeling, and the mea-surement of scientific impact to be easily solved using only this network and off-the-shelf graph algorithms. ...|$|R
40|$|International audienceWe {{present the}} {{components}} of a processing chain for the creation, visualization, and validation of lexical resources (formed of terms and relations between terms). The core of the chain is a component for building <b>lexical</b> <b>networks</b> relying on Harris' distributional hypothesis applied on the syntactic dependencies produced by the French parser FRMG on large corpora. Another important aspect concerns {{the use of an}} online interface for the visualization and collaborative validation of the resulting resources...|$|R
40|$|Automatically {{inferring}} new relations from {{already existing}} ones {{is a way}} to improve the qual-ity and coverage of a <b>lexical</b> <b>network</b> and to perform error detection. In this paper, we devise such an approach for the crowdsourced JeuxDeMots <b>lexical</b> <b>network</b> and we focus especially on word refinements. We first present deduction (generic to specific) and induction (specific to generic) which are two inference schemes ontologically founded and then propose a trans-fer schema devoted to infer relations with and for word refinements. ...|$|E
40|$|In their comment, Dell and O'Seaghdha (1991) adduced {{any effect}} on phonological probes for {{semantic}} alternatives to the activation of these probes in the <b>lexical</b> <b>network.</b> We argue that that interpretation is false and, in addition, that the model still cannot account for our data. Furthermore, and different from Dell and O'seaghda, we adduce semantic rebound to the lemma level, where it is so substantial {{that it should have}} shown up in our data. Finally, we question the function of feedback in a <b>lexical</b> <b>network</b> (other than eliciting speech errors) and discuss Dell's (1988) notion of a unified production-comprehension system...|$|E
40|$|A <b>lexical</b> <b>network</b> is a {{very useful}} {{resource}} for natu-ral language processing systems. However, building high quality lexical networks is a complex task. “Jeux de mots” is a web game which aims at building a <b>lexical</b> <b>network</b> for the French language. At {{the time of this}} paper’s writ-ing, “jeux de mots ” contains 164 480 lexical terms and 397 362 associations. Both lexical terms and associations are weighted with a metric that determines the importance of a given term or association. Associations between lexi-cal terms are typed. The network grows as new games are played. The analysis of such a <b>lexical</b> <b>network</b> is challeng-ing. The aim of our work is to propose a multi-scale inter-active visualization of the network to facilitate its analy-sis. Our work builds on previous work in multi-scale vi-sualization of graphs. Our main contribution in this do-main includes (1) the automatic computation of compound graphs, (2) the proximity measure used to compute com-pound nodes, and (3) the computation of the containment relation used to exhibit the dense relation between one im-portant node and a set of related nodes...|$|E
40|$|We {{demonstrate}} {{an online}} application to explore <b>lexical</b> <b>networks.</b> Tmuse displays a 3 D interactive graph of similar words, whose layout {{is based on}} the proxemy between vertices of synonymy and translation networks. Semantic themes of words related to a query are outlined, and projected across languages. The application is useful as, for example, a writing assistance. It is available, online, for Mandarin Chinese, English and French, as well as the corresponding language pairs, and can easily be fitted to new resources...|$|R
30|$|Using our word {{frequency}} {{paradigm for}} measuring spreading activation, {{we have found}} increased spreading activation in individuals with relatively {{higher scores on the}} Beck Depression Inventory—II [30]. Further, patients with Alzheimer’s disease exhibit increased spreading activation in <b>lexical</b> memory <b>networks</b> and decreased spreading activation in semantic memory networks [31, 32]. Patients with Parkinson’s disease (PD) were also found to exhibit increased spreading activation in <b>lexical</b> memory <b>networks</b> [33]. We have also used this paradigm to investigate the effects of acetylcholinesterase inhibitors (AChEIs) on spreading activation, finding that AChEIs have the effect of reducing spreading activation in <b>lexical</b> memory <b>networks</b> [34]. Finally, we have recently reported a significant relationship between spreading activation and memory functioning. Specifically, our findings indicated that increased spreading activation was associated with better immediate and delayed recall of a word list [31, 32].|$|R
40|$|We {{present a}} new hybrid lexical {{knowledge}} base that combines the contextual information of distributional models with the conciseness and precision of manually constructed <b>lexical</b> <b>networks.</b> The computation of our count-based distributional model includes the induction of word senses for single-word and multi-word terms, the disambiguation of word similarity lists, taxonomic relations extracted by patterns and context clues for disambiguation in context. In contrast to dense vector representations, our resource is human readable and interpretable, {{and thus can}} be easily embedded within the Semantic Web ecosystem...|$|R
40|$|The French <b>Lexical</b> <b>Network</b> (fr-LN) is {{a global}} model of the French lexicon {{presently}} under construction. The fr-LN accounts for lexical knowledge as a <b>lexical</b> <b>network</b> structured by paradigmatic and syntagmatic relations holding between lexical units. This paper describes how morphological knowledge is presently being introduced into the fr-LN through the implemen-tation and lexicographic exploitation of a dynamic morphological model. Section 1 presents theoretical and practical justifications for the approach which we believe allows for a cogni-tively sound description of morphological data within semantically-oriented lexical databases. Section 2 gives {{an overview of the}} structure of the dynamic morphological model, which is constructed through two complementary processes: a Morphological Process—section 3 —and a Lexicographic Process—section 4. ...|$|E
40|$|International audienceThe French <b>Lexical</b> <b>Network</b> (fr-LN) is {{a global}} model of the French lexicon {{presently}} under construction. The fr-LN accounts for lexical knowledge as a <b>lexical</b> <b>network</b> structured by paradigmatic and syntagmatic relations holding between lexical units. This paper describes how morphological knowledge is presently being introduced into the fr-LN through the implementation and lexicographic exploitation of a dynamic morphological model. Section 1 presents theoretical and practical justifications for the approach which we believe allows for a cognitively sound description of morphological data within semantically-oriented lexical databases. Section 2 gives {{an overview of the}} structure of the dynamic morphological model, which is constructed through two complementary processes: a Morphological Process [...] section 3 [...] and a Lexicographic Process [...] section 4...|$|E
40|$|Abstract: We {{create a}} {{weighted}} <b>lexical</b> <b>network</b> {{derived from the}} cosine similarities of financial news feeds to compare two clustering methods, Newman's Modularity method and hierarchical clustering. We find that hierarchical clustering, clustering documents according to shared unique terms, shows results that are closer to expectation...|$|E
40|$|There is {{currently}} much research in {{natural language processing}} focusing on <b>lexical</b> <b>networks.</b> Most of them, in particular the most famous, word-Net, lack syntagmatic information and especially thematic information (“Tennis Problem"). This article describes conceptual vectors that allows the representation of ideas in any textual segment and offers a continuous vision of related thematics, based on the distances between these thematics. We show the characteristics of conceptual vectors and explain how they complement lexico-semantic networks. we illustrate this purpose by adding conceptual vectors to wordNet by emergence,...|$|R
40|$|This article {{describes}} MorphoClust and MorphoNet, two methods for the unsupervised acquisition of morphological families. MorphoClust builds families by iterative conflations, similarly to hierchical clustering methods. The MorphoNet method relies on community detection in <b>lexical</b> <b>networks.</b> The nodes of these networks stand for words while edges represent morphological transformation rules which are automatically acquired based on graphical similarities between words. The two methods {{are applied to}} a German-English bilingual lexicon, both in isolation and in combination. We evaluate the results using the CELEX lexical database...|$|R
40|$|This study explores how Latent Semantic Analysis (LSA) {{can be used}} as {{a method}} to examine the lexical {{development}} of second language (L 2) speakers. This year long longitudinal study with six English learners demonstrates that semantic similarity (using LSA) between utterances significantly increases as the L 2 learners study English. The findings demonstrate that L 2 learners begin to develop tighter semantic relations between utterances and words within a short period. The results have implications concerning the growth of <b>lexical</b> <b>networks.</b> This study also has important implications for inductive learning and contextualized vocabulary learning...|$|R
40|$|We {{propose a}} method for extracting {{semantic}} orientations of phrases (pairs of an adjective and a noun) : positive, negative, or neutral. Given an adjective, the semantic orientation classification of phrases {{can be reduced to}} the classification of words. We construct a <b>lexical</b> <b>network</b> by connecting similar/related words. In the network, each node has one of the three orientation values and the neighboring nodes tend to have the same value. We adopt the Potts model for the probability model of the <b>lexical</b> <b>network.</b> For each adjective, we estimate the states of the nodes, which indicate the semantic orientations of the adjective-noun pairs. Unlike existing methods for phrase classification, the proposed method can classify phrases consisting of unseen words. We also propose to use unlabeled data for a seed set of probability computation. Empirical evaluation shows the effectiveness of the proposed method. ...|$|E
40|$|The Integral Dictionary is a {{comprehensive}} <b>lexical</b> <b>network</b> for French, English, German, Italian, and Spanish. It is based on componential semantics and lexical functions. The network structure superimposes two graphs. A first graph consists of a hierarchy of concepts divided into classes and themes where the words form the terminal nodes of the graph. A second graph links the words together using lexical functions derived from the Meaning-Text theory. We first introduce the <b>lexical</b> <b>network</b> whose database for French words is. comparable in its size to that of WordNet. We then describe two semantic distances to evaluate the proximity of two. words in the graph and to find their distinctive semantic components. Finally, we give examples of applications we developed with it: the search of a word from a definition and the extraction of the semantic features of a text...|$|E
40|$|This ongoing {{research}} {{presents an}} alternative to the man- ual creation of lexical resources and proposes an approach towards the automatic construction of a lexical ontology for Portuguese. Tex- tual sources are exploited in order to obtain a <b>lexical</b> <b>network</b> based on terms and, after clustering and mapping, a wordnet-like lexical on- tology is created. At the end of the paper, current results are shown...|$|E
40|$|International audienceThere is {{currently}} much research in {{natural language processing}} focusing on <b>lexical</b> <b>networks.</b> Most of them, in particular the most famous, Word- Net, lack syntagmatic information and especially thematic information (”Tennis Problem”). This article describes conceptual vectors that allows the representation of ideas in any textual segment and offers a continuous vision of related thematics, based on the distances between these thematics. We show the characteristics of conceptual vectors and explain how they complement lexico-semantic networks. We illustrate this purpose by adding conceptual vectors toWordNet by emergence...|$|R
40|$|This paper {{introduces}} {{how human}} languages {{can be studied}} {{in light of recent}} development of network theories. There are two directions of exploration. One is to study networks existing in the language system. Various <b>lexical</b> <b>networks</b> can be built based on different relationships between words, being semantic or syntactic. Recent studies have shown that these <b>lexical</b> <b>networks</b> exhibit small-world and scale-free features. The other direction of exploration is to study networks of language users (i. e. social networks of people in the linguistic community), and their role in language evolution. Social networks also show small-world and scale-free features, which cannot be captured by random or regular network models. In the past, computational models of language change and language emergence often assume a population to have a random or regular structure, and there has been little discussion how network structures may affect the dynamics. In {{the second part of the}} paper, a series of simulation models of diffusion of linguistic innovation are used to illustrate the importance of choosing realistic conditions of population structure for modeling language change. Four types of social networks are compared, which exhibit two categories of diffusion dynamics. While the questions about which type of networks are more appropriate for modeling still remains, we give some preliminary suggestions for choosing the type of social networks for modeling...|$|R
50|$|The Bulgarian WordNet (BulNet) is a <b>lexical</b> {{semantic}} <b>network</b> of Bulgarian {{following the}} Princeton WordNet (PWN) framework which implements the traditional semantic networks whose structure consists of nodes and {{relations between the}} nodes.|$|R
30|$|In {{the review}} sections, we {{discussed}} from two perspectives why language {{should be a}} critical factor for consideration in using WAF tests to measure vocabulary depth, including the modality of administering the tests and L 1 -L 2 linguistic distance. Both perspectives were primarily concerned with between-group variabilities rather than the relationships between learners’ L 1 and L 2 <b>lexical</b> <b>network</b> and their implications for L 2 vocabulary depth assessment.|$|E
40|$|International audienceIn this paper, {{we focus}} on a {{particular}} task which consists in explaining the source and the target of sentiments expressed in social networks. We propose a method for French, which overcomes a fine syntactic parsing and successfully integrate the Conditional Random Field (CRF) method and a smart exploration {{of a very large}} <b>lexical</b> <b>network.</b> Quantitative and qualitative experiments were performed on real dataset to validate this approach...|$|E
40|$|This {{study used}} a new {{computational}} linguistics tool, the Coh-Metrix, {{to investigate and}} measure the differences in cohesion and <b>lexical</b> <b>network</b> density between native speaker and non-native speaker writing, {{as well as to}} investigate L 2 proficiency level differences in cohesion and <b>lexical</b> <b>network</b> density. This study analyzed data from three corpora with the Coh-Metrix: the International Corpus of Learner English (ICLE) as an L 2 higher proficiency group, the Louvain Corpus of Native English Essays (LOCNESS) as a native speaker baseline, and a collected EFL corpus from Indonesia for the L 2 lower proficiency data. Statistical investigation of the Coh-Metrix results revealed that five out of six Coh-Metrix variables used in this study did not detect proficiency level differences in L 2 but the tool was consistently able to distinguish between L 2 and native speaker writing. Differences included that L 2 writing contains more argument overlap, more semantic overlap, more frequent content words, fewer abstract verb hyponyms and less causal content than native speaker writing. </p...|$|E
40|$|International audienceThis paper {{explores the}} notion of lexicon {{embedded}} syntax: syntactic structures that are preassembled in natural language lexicons. Section 1 proposes a lexicological perspective on (dependency) syntax: first, it deals with the well-known problem of lexicon-grammar dichotomy, then introduces {{the notion of}} lexicon embedded syntax and, finally, presents the lexical models this discussion is based on: lexical systems, as implemented in the English and French <b>Lexical</b> <b>Networks.</b> Two cases of lexicon embedded syntax are then treated: the syntax of idioms, section 2, and the syntax of collocations, section 3. Section 4 concludes on the possible exploitation of syntactic structures that can be extracted from lexical systems...|$|R
40|$|Czesław Miłosz’s poems {{collection}} Child of Europe gives {{a testimony}} on {{a part of}} human History. These poems are part of a moral relation to the European modern world. The article focus on how the poet makes place to the human being in his work as an actor and witness of the historical events, putting it at the heart of his opus, using, among other lexical tools, the <b>lexical</b> <b>networks.</b> The aim of the study is especially to determine the processes at work to show the semantic fields. The theoretical bases of the enunciation linguistics and of the lexical semantics will be used to reach the aim of the study...|$|R
40|$|This paper {{presents}} a Graphical User Interface (GUI) mainly {{based on a}} graph visualization device and used for exploring and assessing lexical data found in the DiCoInfo, a specialized e-dictionary of computing and the Internet. Computer visualization devices {{have been used to}} present and browse data in many fields, but GUIs for electronic dictionaries have not evolved much. Very few take advantage of the fundamental nature of dictionaries: they are huge and ordered collections of lexical relationships (i. e. <b>lexical</b> <b>networks).</b> Graph visualization devices such as intertwined (directed) graphs present themselves as better tools to browse these relationships. They surely are well suited for assessing the consistency of encoded data...|$|R
