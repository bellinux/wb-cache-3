152|10000|Public
2500|$|Constant {{variance}} (a.k.a. homoscedasticity). [...] This {{means that}} different {{values of the}} response variable have the same variance in their errors, regardless {{of the values of}} the predictor variables. In practice this assumption is invalid (i.e. the errors are heteroscedastic) if the response variable can vary over a wide scale. In order to check for heterogeneous error variance, or when a pattern of residuals violates model assumptions of homoscedasticity (error is equally variable around the 'best-fitting line' for all points of x), it is prudent to look for a [...] "fanning effect" [...] between residual error and predicted values. This is to say there will be a systematic change in the absolute or squared residuals when plotted against the predictive variables. Errors will not be evenly distributed across the regression line. Heteroscedasticity will result in the averaging over of distinguishable variances around the points to get a single variance that is inaccurately representing all the variances of the line. In effect, residuals appear clustered and spread apart on their predicted plots for larger and smaller values for points along the <b>linear</b> <b>regression</b> <b>line,</b> and the mean squared error for the model will be wrong. Typically, for example, a response variable whose mean is large will have a greater variance than one whose mean is small. For example, a given person whose income is predicted to be $100,000 may easily have an actual income of $80,000 or $120,000 (a standard deviation of around $20,000), while another person with a predicted income of $10,000 is unlikely to have the same $20,000 standard deviation, which would imply their actual income would vary anywhere between -$10,000 and $30,000. (In fact, as this shows, in many cases—often the same cases where the assumption of normally distributed errors fails—the variance or standard deviation should be predicted to be proportional to the mean, rather than constant.) Simple linear regression estimation methods give less precise parameter estimates and misleading inferential quantities such as standard errors when substantial heteroscedasticity is present. However, various estimation techniques (e.g. weighted least squares and heteroscedasticity-consistent standard errors) can handle heteroscedasticity in a quite general way. Bayesian linear regression techniques can also be used when the variance is assumed to be a function of the mean. It is also possible in some cases to fix the problem by applying a transformation to the response variable (e.g. fit the logarithm of the response variable using a linear regression model, which implies that the response variable has a log-normal distribution rather than a normal distribution).|$|E
5000|$|... #Caption: The {{data sets}} in the Anscombe's quartet are {{designed}} {{to have the same}} <b>linear</b> <b>regression</b> <b>line</b> (as well as identical means, standard deviations, and correlations) but are graphically very different. This illustrates the pitfalls of relying solely on a fitted model to understand the relationship between variables.|$|E
5000|$|... {{where the}} {{parameters}} A and B {{are dependent on}} the particular type of samples under test, the bacterial strains, the type of enriching medium used and so on. These parameters can be calculated by calibrating the system using a set of samples whose bacterial concentration is known and calculating the <b>linear</b> <b>regression</b> <b>line</b> {{that will be used}} to estimate the bacterial concentration from the measured DT.|$|E
40|$|This paper {{describes}} a machine learning method, called Regression by Selecthtg Best P~’ttllll’es (RSBF). RSBF {{consists of two}} phases: The first phase aims to find the predictive power of each feature by constructing simple <b>linear</b> <b>regression</b> <b>lines,</b> one per each continuous feature and number of categories pen each categorical feature. Although the predictive power of a continuous feature is constant, it varies for each distinct value of categorical features. The second phase constructs multiple <b>linear</b> <b>regression</b> <b>lines</b> among continuous features, each time excluding the worst feature among the current set, and constructs multiple <b>linear</b> <b>regression</b> <b>lines.</b> Finally, these muhiple <b>linear</b> <b>regression</b> <b>lines</b> and the categorical features" simple <b>linear</b> <b>regression</b> <b>lines</b> are sorted according to their predictive power. In the querying phase of learning, the best lineal " <b>regression</b> <b>line</b> and the features constructing that line are selected to make predictions...|$|R
30|$|Additional file  1 : Figure S 1 a and b display, respectively, {{the scatter}} plots and <b>linear</b> <b>regression</b> <b>lines</b> for every {{individual}} WT–WSS relationship. Mean R 2 was 0.08 [*]±[*] 0.07. Additional file  1 : Figure S 1 c and d display the scatter plots and <b>linear</b> <b>regression</b> <b>lines</b> for every individual WT–diameter relationship. Mean R 2 was 0.09 [*]±[*] 0.15. Additional file  1 : Figure S 1 e, f display the scatter plots and <b>linear</b> <b>regression</b> <b>lines</b> for every individual WSS–diameter relationship. Mean R 2 was 0.11 [*]±[*] 0.12. For most subjects, a {{negative and positive}} relationship between WSS and WT and between diameter and WT, respectively, was found. For most subjects, a negative relationship was found between WSS and diameter. This is also displayed in Fig.  2.|$|R
40|$|Research on {{multiple}} comparison {{during the past}} 50 years or so has focused mainly on the comparison of several population means. Several years ago, Spurrier considered the multiple comparison of several simple <b>linear</b> <b>regression</b> <b>lines.</b> He constructed simultaneous confidence bands {{for all of the}} contrasts of the simple <b>linear</b> <b>regression</b> <b>lines</b> over the entire range (-infin, infin) when the models have the same design matrices. This article extends Spurrier's work in several directions. First, multiple <b>linear</b> <b>regression</b> models are considered and the design matrices are allowed to be different. Second, the predictor variables are either unconstrained or constrained to finite intervals. Third, the types of comparison allowed can be very flexible, including pairwise, many–one, and successive. Two simulation methods are proposed for the calculation of critical constants. The methodologies are illustrated with examples...|$|R
50|$|Assume that, say {{for several}} years, we have data {{on both the}} price and the traded {{quantity}} of this good. Unfortunately {{this is not enough}} to identify the two equations (demand and supply) using regression analysis on observations of Q and P: one cannot estimate a downward slope and an upward slope with one <b>linear</b> <b>regression</b> <b>line</b> involving only two variables. Additional variables can make it possible to identify the individual relations.|$|E
50|$|Correlation and {{association}} coefficients. Pearson’s {{product-moment correlation}} coefficient rij, for example, measures deviations from any <b>linear</b> <b>regression</b> <b>line</b> between the coordinates of i and j. Unless that regression line {{happens to be}} exactly 45° or centered, rij does not measure agreement. Similarly, while perfect agreement between coders also means perfect association, association statistics register any above chance pattern of relationships between variables. They do not distinguish agreement from other associations and are, hence, unsuitable as reliability measures.|$|E
50|$|Constructing a {{synthesizer}} build involves {{constructing a}} statistical model. In a <b>linear</b> <b>regression</b> <b>line</b> example, the original {{data can be}} plotted, and a best fit linear line can be created from the data. This line is a synthesizer created from the original data. The next step will be generating more synthetic data from the synthesizer build or from this linear line equation. In this way, the new data {{can be used for}} studies and research, and it protects the confidentiality of the original data.|$|E
40|$|Figure 7 - The {{ratio of}} forewing length (L) /width (W) vs. forewing length (in mm) of ten {{representative}} Families of Mecoptera. For all data points, the <b>linear</b> <b>regression</b> trend <b>line</b> {{is represented by}} Y 1 = 0. 036 *X + 2. 620. Excluding the data of Panorpidae, the <b>linear</b> <b>regression</b> trend <b>line</b> is Y 2 = 0. 056 *X + 1. 977...|$|R
30|$|The {{long term}} impact of attacks can already {{be seen in}} Figure  8, when {{comparing}} the panel of Puzzle 4 {{before and after the}} attacks. The overall reactivity of users measured by the <b>linear</b> <b>regression</b> <b>lines</b> decrease from its highest before attacks at 0.82 to its lowest after attacks at 0.66, thereby requiring more time to achieve a given number of moves.|$|R
40|$|International audienceIn {{this paper}} {{we look at}} the problem where we have two mixed sets of data on the same scatter plot. We want to {{calculate}} <b>linear</b> <b>regression</b> <b>lines</b> for each of the two sets, but first of all we need to decide which data belong to which set. We propose one possible solution to this problem involving data classification and parameters estimation...|$|R
5000|$|Pearson’s intraclass {{correlation}} coefficient rii is an agreement coefficient for interval data, two coders, and very large sample sizes. To obtain it, Pearson's original suggestion was {{to enter the}} observed pairs of values twice into a table, once as c-k and once as k-c, to which the traditional Pearson product-moment correlation coefficient is then applied. [...] By entering pairs of values twice, the resulting table becomes a coincidence matrix {{without reference to the}} two coders, contains n=2N values, and is symmetrical around the diagonal, i.e., the joint <b>linear</b> <b>regression</b> <b>line</b> is forced into a 45° line, and references to coders are eliminated. Hence, Pearson’s {{intraclass correlation}} coefficient is that special case of interval alpha for two coders and large sample sizes, [...] and [...]|$|E
5000|$|Constant {{variance}} (a.k.a. homoscedasticity). This {{means that}} different response variables {{have the same}} variance in their errors, regardless {{of the values of}} the predictor variables. In practice this assumption is invalid (i.e. the errors are heteroscedastic) if the response variables can vary over a wide scale. In order to determine for heterogeneous error variance, or when a pattern of residuals violates model assumptions of homoscedasticity (error is equally variable around the 'best-fitting line' for all points of x), it is prudent to look for a [...] "fanning effect" [...] between residual error and predicted values. This is to say there will be a systematic change in the absolute or squared residuals when plotted against the predicting outcome. Error will not be evenly distributed across the regression line. Heteroscedasticity will result in the averaging over of distinguishable variances around the points to get a single variance that is inaccurately representing all the variances of the line. In effect, residuals appear clustered and spread apart on their predicted plots for larger and smaller values for points along the <b>linear</b> <b>regression</b> <b>line,</b> and the mean squared error for the model will be wrong. Typically, for example, a response variable whose mean is large will have a greater variance than one whose mean is small. For example, a given person whose income is predicted to be $100,000 may easily have an actual income of $80,000 or $120,000 (a standard deviation of around $20,000), while another person with a predicted income of $10,000 is unlikely to have the same $20,000 standard deviation, which would imply their actual income would vary anywhere between -$10,000 and $30,000. (In fact, as this shows, in many cases—often the same cases where the assumption of normally distributed errors fails—the variance or standard deviation should be predicted to be proportional to the mean, rather than constant.) Simple linear regression estimation methods give less precise parameter estimates and misleading inferential quantities such as standard errors when substantial heteroscedasticity is present. However, various estimation techniques (e.g. weighted least squares and heteroscedasticity-consistent standard errors) can handle heteroscedasticity in a quite general way. Bayesian linear regression techniques can also be used when the variance is assumed to be a function of the mean. It is also possible in some cases to fix the problem by applying a transformation to the response variable (e.g. fit the logarithm of the response variable using a linear regression model, which implies that the response variable has a log-normal distribution rather than a normal distribution).|$|E
40|$|This paper {{describes}} two {{machine learning}} methods, called Regression by Selecting Best Feature Projection (RSBFP) and Regression by Selecting Best Features (RSBF). RSBFP projects the training data on each feature dimension and produces exactly one simple <b>linear</b> <b>regression</b> <b>line</b> on each continuous feature. In {{the case of}} categorical features, exactly one simple <b>linear</b> <b>regression</b> <b>line</b> per each distinct value of each categorical feature is produced. Then these simple linear regression lines are analyzed to determine the feature projection that is best among all projections. The best feature projection and its corresponding simple <b>linear</b> <b>regression</b> <b>line</b> is then selected to make predictions. RSBF consists of two phases: The first phase uses RSBFP to sort predictive power of each feature projection. The second phase calls multiple linear least squares regression for number of features times, each time excluding the worst feature among the current set, and produces multiple linear regression lines. Finally, these regression lines are analyzed to select the best subset of features. The best subset of features and its corresponding multiple <b>linear</b> <b>regression</b> <b>line</b> is then selected to make predictions...|$|E
40|$|This paper {{shows how}} to {{construct}} confidence bands {{for the difference}} between two simple <b>linear</b> <b>regression</b> <b>lines.</b> These confidence bands provide directly {{the information on the}} magnitude of the difference between the <b>regression</b> <b>lines</b> over an interval of interest and, as a by-product, {{can be used as a}} formal test of the difference between the two <b>regression</b> <b>lines.</b> Various different shapes of confidence bands are illustrated, and particular attention is paid towards confidence bands whose construction only involves critical points from standard distributions so that they are consequently easy to construct...|$|R
40|$|This paper {{describes}} a language independent method for alignment of parallel texts that {{makes use of}} homograph tokens for each pair of languages. In order to filter out tokens that may cause misalignment, we use confidence bands of <b>linear</b> <b>regression</b> <b>lines</b> instead of heuristics which are not theoretically supported. This method was originally inspired on work done by Pascale Fung and Kathleen McKeown, and Melamed, providing the statistical support those authors could not claim...|$|R
40|$|ABSTRACT- This paper {{describes}} a rotational angle estimation of dif-ferent color images. This estimation method is primarily based on weighted <b>linear</b> <b>regression</b> <b>lines</b> {{of the three}} color components of a color image {{as well as the}} influence of each component. Preservation of the chromatic information makes this method helpful to efficiently calculate the rota-tional angle between the referenced and sensed image pair. The experiments justify that the proposed method is ro-bust ensuring its applicability to any kind of color images. General Terms...|$|R
3000|$|..., and y are the Sq amplitude, {{the mean}} {{value of the}} Sq amplitude, and the one {{calculated}} with the <b>linear</b> <b>regression</b> <b>line</b> or the second-order least-square fitted curves, respectively. In this statistical analysis, we determined the second-order least-square fitted curves better than the <b>linear</b> <b>regression</b> <b>line</b> for the results that passed through the above F-test for the new additional terms and {{were satisfied with the}} large/small relation of the coefficient of determination of R 2 [*]>[*]R 1 (R 1 : <b>linear</b> <b>regression</b> <b>line,</b> R 2 : second-order least-square fitted curves). As a result of the statistical analysis, the Sq amplitude observed at 37 of 69 geomagnetic stations located in a region of less than 60 ° in terms of the geomagnetic latitude passed through the present statistical test. From these results, it can be inferred that the relationship between the solar F 10.7 index and Sq amplitude was approximately linear but there was weak nonlinearity for about 53 % of the investigated stations.|$|E
3000|$|... is {{the thermal}} resistance. We applied a <b>linear</b> <b>regression</b> <b>line</b> {{to the data}} of thermal {{conductivity}} with depth and used the linear trend to calculate thermal resistance values {{as a function of}} z.|$|E
30|$|Linear and angular {{coefficient}} values {{obtained from}} linear regression performed for the cDNA dilution curves of all genes {{are presented in}} Additional file 1, which also contains the <b>linear</b> <b>regression</b> <b>line</b> equations, and the formulas {{used to calculate the}} quantified variables shown in Table  1.|$|E
40|$|This note {{analyzes}} ozone standard exceedance days in Bakersﬁeld, Arvin, Oildale, and Shafter since 1989. We have plotted {{violations of}} both one-hour and eight-hour {{federal and state}} standards (data from CARB monitoring stations). We have also drawn <b>linear</b> <b>regression</b> <b>lines</b> to estimate trend. They show a modest long term improvement (around 20 %) in violations of one-hour state standards, but generally a smaller increase in violations of eight-hour state standards. They also show larger improvement in urban Bakersﬁeld than in the rural areas...|$|R
40|$|Total {{phenolic}} {{content and}} antioxidant capacity (FRAP method) of Ginkgo biloba L. leaves collected from {{male and female}} trees were determined and compared. Different water and aqueous ethanolic (water/ethanol 80 / 20, V/V) extracts were prepared by varying the time of infusing, boiling and steeping {{in order to determine}} the effect of the extraction method on the above parameters. Antioxidant activity and phenolic content of ginkgo leaf extracts correlated well with significant correlation coefficients. Slopes of <b>linear</b> <b>regression</b> <b>lines</b> were not statistically different for either se...|$|R
30|$|Symmetric nearest {{neighbour}} locally {{weighted regression}} (LOWESS; (Cleveland 1979)) {{was used to}} determine significant relationships between rainfall and NDVI and to establish patterns of correlation between rainfall and NDVI. LOWESS is a polynomial smoothing technique that fits weighted least squares <b>linear</b> <b>regression</b> <b>lines</b> to localized subsets of data to describe deterministic variation in the data point by point. The power of this technique is that it takes into account neighbouring points of each point in determining the fit and repeats the entire procedure for each data point until it achieves the best fit.|$|R
3000|$|... {{where the}} meaning of the {{notation}} for Y and y {{is the same as the}} variables of Equation  3. In the F-test, when this relationship is judged to be linear, the value y of Equation  4 corresponds to the one calculated with the <b>linear</b> <b>regression</b> <b>line.</b> For the nonlinear case, the value y is derived from the quadratic curve.|$|E
40|$|An anion-exchange {{extraction}} {{method was}} {{used in conjunction with}} high-pressure liquid chromatography for assay of ceftizoxime in 181 serum samples. Comparison of this method with bioassay gave a <b>linear</b> <b>regression</b> <b>line</b> described by Y = 1. 11 + 0. 98 X, with a correlation coefficient of 0. 984. The anion-exchange extraction method is a fast, reliable method of preparing serum samples containing ceftizoxime for assay by liquid chromatography...|$|E
30|$|In Fig.  5 a <b>linear</b> <b>regression</b> <b>line</b> was fitted. Despite of the {{moderate}} R 2 of 0.72 it is visible {{that the relationship}} is not linear, respondents classified the pictures in two groups and referred to the speed limits of 90 and 50  km/h on non-built-up and built sites resp. However {{in the range of}} low certainty scores (between about − 1.5 and + 1) there are deviations from these limits. In general, there is a reasonable coherence between the human and machine classification.|$|E
40|$|The {{validity}} of survivor curves for Leptospira autumnalis Akiyami A based on most-probable-number values {{is supported by}} the following observations: (i) <b>linear</b> <b>regression</b> <b>lines</b> fell within most of the 95 % confidence intervals; (ii) linear correlation coefficients (r) were consistently high (i. e., near - 1); and (iii) statistical tests for goodness of fit usually accepted the linear model. These tests are consistent with an exponential death rate for the test organism in defined solutions. The influence of temperature and pH on survival was demonstrated by showing a statistically significant difference in survivor curve slopes...|$|R
40|$|Ankara : Department of Computer Engineering and the Institute of Engineering and Science of Bilkent Univ., 2000. Thesis (Master's) [...] Bilkent University, 2000. Includes bibliographical {{references}} leaves 75 - 78. Two new {{machine learning}} methods, Regression by Selecting Best Feature Projections (RSBFP) and Regression by Selecting Best Features (RSBF), are presented for regression problems. These methods heavily {{make use of}} least squares regression to induce eager, parametric and context-sensitive models. Famous regression approaches of machine learning and statistics literature such as DART, MARS, RULE and kNN can not construct models that are both predictive and have reasonable training and/or querying time durations. We developed RSBFP and RSBF {{to fill the gap}} in the literature for a regression method having higher predictive accuracy and faster training and querying time durations. RSBFP constructs a decision list consisting of simple <b>linear</b> <b>regression</b> <b>lines</b> belonging to <b>linear</b> features and/or categorical feature segments. RSBF is the extended version of RSBFP such that the decision list consists of both simple, belonging to categorical feature segments, and/or multiple, belonging to <b>linear</b> features, <b>linear</b> <b>regression</b> <b>lines.</b> A relevancy heuristic has been developed to determine the features involved in the multiple <b>regression</b> <b>lines.</b> It is shown that the proposed methods are robust to irrelevant features, missing feature values and target feature noise, which make them suitable prediction tools for real-world databases. In terms of robustness, RSBFP and RSBF give better results when compared to other famous regression methods. Aydın, TolgaM. S...|$|R
40|$|Differences in {{antioxidant}} {{properties of}} ginkgo leaves collected from {{male and female}} trees Total phenolic content and antioxidant capacity (FRAP method) of Ginkgo biloba L. leaves collected from male and female trees were determined and compared. Different wa-ter and aqueous ethanolic (water/ethanol 80 / 20, V/V) ex-tracts were prepared by varying the time of infusing, boil-ing and steeping {{in order to determine}} the effect of the extraction method on the above parameters. Antioxidant activity and phenolic content of ginkgo leaf extracts corre-lated well with significant correlation coefficients. Slopes of <b>linear</b> <b>regression</b> <b>lines</b> were not statistically different for either sex...|$|R
40|$|Figure 2 a - Relationship between hook area {{estimated}} by the Meristogram and hook area measured using a digitising tablet in three species of the E. gadi group. The <b>linear</b> <b>regression</b> <b>line</b> is solid red. The line of equality is denoted by blue dashes. Analysis based on data in Suppl. material 2. E. gadi sp. A. 70 hooks from six worms (four females and two males). Equation of regression line: estimated = 1. 013 x measured + 46. 898. Coefficient of determination (R 2) = 0. 887...|$|E
40|$|Figure 2 b - Relationship between hook area {{estimated}} by the Meristogram and hook area measured using a digitising tablet in three species of the E. gadi group. The <b>linear</b> <b>regression</b> <b>line</b> is solid red. The line of equality is denoted by blue dashes. Analysis based on data in Suppl. material 2. E. gadi sp. B. 220 hooks from 18 worms (11 females and seven males). Equation of regression line: estimated = 0. 953 x measured + 39. 178. R 2 = 0. 882...|$|E
30|$|Figure 3 {{shows that}} {{the plot of the}} errors due to linear {{interpolation}} and linear spline interpolation are equally closer to the horizontal error free line than the plot of the error due to <b>linear</b> <b>regression</b> <b>line.</b> Hence, the error due to linear interpolation and linear spline interpolation are smaller than the error due to linear regression. This reveals that, for a such time series data with non-linear trend when missing values are not sequential, linear interpolation and linear spline interpolation brings a better estimate than linear regression.|$|E
40|$|Abstract. Within the {{framework}} of classical <b>linear</b> <b>regression</b> model integral optimal design criteria of stochastic nature are considered and their properties are established. Their limit behaviour generalizes that of the distance stochastic optimality criterion. As an example a line fit model is taken. Key words: classical <b>linear</b> <b>regression</b> model, <b>line</b> fit model, integral and dis-tance stochastic optimality criteria...|$|R
40|$|The {{ratios of}} amino acid {{to the total}} amino acids and those of {{nucleotides}} to the total nucleotides in genes or genomes are suitable indexes to compare whole gene or genome characteristics based on {{the large number of}} nucleotides rather than their sequences. As these ratios are strictly calculated from nucleotide sequences, the values are independent of experimental errors. In the present mini-review, the following themes are approached according to the ratios of amino acids and nucleotides to their total numbers in the genome: prebiotic evolution, the chronological precedence of protein and codon formations, genome evolution, Chargaff’s second pa- rity rule, and the origins of life. Amino acid formation might have initially occurred during pre- biotic evolution, the “amino acid world”, and amino acid polymerization might chronologically precede codon formation at the end of prebiotic evolution. All nucleotide alterations occurred synchronously over the genome during biolo- gical evolution. After establishing primitive lives, all nucleotide alterations have been governed by linear formulae in nuclear and organelle genomes consisting of the double-stranded DNA. When the four nucleotide contents against each individual nucleotide content in organelles are expressed by four <b>linear</b> <b>regression</b> <b>lines</b> representing the diagonal lines of a 0. 5 square – the “Diagonal Genome Universe”, evolution obeys Chargaff’s second parity rule. The fact that <b>linear</b> <b>regression</b> <b>lines</b> intersect at a single point su- ggests that all species originated from a single life source...|$|R
40|$|This paper {{describes}} a systematic procedure for recognizing corrugated asbestos-cement roofing sheets and evaluating their deterioration status {{related to the}} asbestos fiber air dispersion that can cause lung cancer. To develop this procedure, we made field and laboratory measurements and gathered airborne MIVIS data covering two industrial test areas in Italy. Laboratory analyses of asbestos-cement samples representing various levels of deterioration allowed for: (a) recognizing dominant minerals using XRD and FTIR instruments, (b) identifying their optical characteristics using portable field spectrometers (ASD and mu FTIR), (c) assessing the abundance of surfacing asbestos fibers using a high resolution scanner. Based on the spectral analyses, two <b>linear</b> <b>regression</b> <b>lines</b> were identified by relating optical asbestos-cement material characteristics (i. e. band-depth ratio of the continuum removed calculated for the two asbestos diagnostic bands at 2. 32 mu m and at 9. 44 mu m) to the relative percentage of surfacing asbestos fibers related to AC deterioration status. Suitable MIVIS spectral regions were used in a spectral classification procedure to map asbestos-cement roofs. The detected roofs were further analyzed using the obtained <b>linear</b> <b>regression</b> <b>lines</b> to estimate surfacing asbestos fiber abundance, using the MIVIS TIR range at 9. 44 mu m, selected {{by means of the}} asbestos-cement detection limit analysis. The results showed that a hyperspectral scanner with suitable operational characteristics allows for good clustering of AC roofs as a function of their deterioration status. Therefore, this technique can furnish government authorities with an efficient, rapid and. repeatable environmental mapping procedure that can provide information about the location of hazardous AC roofing sheet...|$|R
