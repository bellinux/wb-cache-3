5|20|Public
50|$|VEST ciphers {{consist of}} four {{components:}} a non-linear counter, a <b>linear</b> <b>counter</b> diffusor, a bijective non-linear accumulator {{with a large}} state and a linear output combiner (as illustrated by {{the image on the}} top-right corner of this page). The RNS counter consists of sixteen NLFSRs with prime periods, the counter diffusor is a set of 5-to-1 linear combiners with feedback compressing outputs of the 16 counters into 10 bits {{while at the same time}} expanding the 8 data inputs into 9 bits, the core accumulator is an NLPFSR accepting 10 bits of the counter diffusor as its input, and the output combiner is a set of 6-to-1 linear combiners.|$|E
40|$|Image Compression {{is solved}} by using Wavelet-Modified Single Layer Linear Forward Only Counter Propagation Network (MSLLFOCPN) technique. Form the wavelets it {{inherits}} {{the properties of}} localizing the global spatial and frequency correlation from wavelets. Function approximation and prediction are obtained from neural networks. As a result counter propagation network was considered for its superior performance and the research enable us to propose a new neural network architecture named single layer <b>linear</b> <b>counter</b> propagation network (SLLC). The combination of wavelet and SLLC network were tested on several benchmark images and the experimental results shows that an enhancement in picture quality, compression ratio and approximation or prediction comparable to existing and traditional neural networks...|$|E
40|$|AbstractImages {{and text}} form an {{integral}} part of website designing. Images have an engrossing appeal and that’s why they attract more and more visitors. But, due to expensive bandwidth and time-consuming downloads; it has become essential to compress images. There are various methods and techniques available to compress images. In this paper, an effective technique is introduced called Wavelet-Modified Single Layer Linear Forward Only Counter Propagation Network (MSLLFOCPN) technique to solve image compression. This technique inherits the properties of localizing the global spatial and frequency correlation from wavelets. Function approximation and prediction are obtained from neural networks. Consequently counter propagation network was considered for its superior performance and the research helps to propose a new neural network architecture named single layer <b>linear</b> <b>counter</b> propagation network (SLLC). Several benchmark images are used to test the proposed technique combined of wavelet and SLLC network. The experiment results when compared with existing and traditional neural networks shows that picture quality, compression ratio and approximation or prediction are highly enhanced...|$|E
40|$|International audienceCount-Min Sketch [1] is {{a widely}} adopted {{algorithm}} for approximate event counting in large scale processing. However, the original version of the Count-Min-Sketch (CMS) suffers of some deficiences, especially if one {{is interested in the}} low-frequency items, such as in text-mining related tasks. Several variants of CMS [5] have been proposed to compensate for the high relative error for low-frequency events, but the proposed solutions tend to correct the errors instead of preventing them. In this paper, we propose the Count-Min-Log sketch, which uses logarithm-based, approximate counters [7, 4] instead of <b>linear</b> <b>counters</b> to improve the average relative error of CMS at constant memory footprint...|$|R
40|$|Count-Min Sketch is {{a widely}} adopted {{algorithm}} for approximate event counting in large scale processing. However, the original version of the Count-Min-Sketch (CMS) suffers of some deficiences, especially if one is interested by the low-frequency items, such as in text-mining related tasks. Several variants of CMS have been proposed {{to compensate for the}} high relative error for low-frequency events, but the proposed solutions tend to correct the errors instead of preventing them. In this paper, we propose the Count-Min-Log sketch, which uses logarithm-based, approximate <b>counters</b> instead of <b>linear</b> <b>counters</b> to improve the average relative error of CMS at constant memory footprint. Comment: 7 pages, 3 figures. Some preliminary notes can be found on [URL]...|$|R
40|$|The Count-Min Sketch is {{a widely}} adopted {{structure}} for approximate event counting in large scale processing. In a previous work we improved the original version of the Count-Min-Sketch (CMS) with conservative update using approximate <b>counters</b> instead of <b>linear</b> <b>counters.</b> These structures are computationaly efficient and improve the average relative error (ARE) of a CMS at constant memory footprint. These improvements are well suited for NLP tasks, in which one is interested by the low-frequency items. However, if Log counters allow to improve ARE, they produce a residual error due to the approximation. In this paper, we propose the Count-Min Tree Sketch (Copyright 2016 eXenSa. All rights reserved) variant with pyramidal counters, which are focused toward {{taking advantage of the}} Zipfian distribution of text data. Comment: submitted to the second International Symposium on Web Algorithms (iSwag' 2016). arXiv admin note: text overlap with arXiv: 1502. 04885, In the proceedings of the Second International Symposium on Web Algorithms (iSWAG 2016), June 9 - 10, 2016, Deauville, Normandy, Franc...|$|R
40|$|Abstract. VEST {{is a set}} of four {{stream cipher}} {{families}} submitted by S. O’Neil, B. Gittins and H. Landman to the eSTREAM call for stream cipher proposals of the European project ECRYPT. The state of any family member is made of three components: a counter, a counter diffusor and a core accumulator. We show that collisions {{can be found in the}} counter during the IV Setup. Moreover they can be combined with a collision in the <b>linear</b> <b>counter</b> diffusor to form collisions on the whole cipher. As a consequence, it is possible to retrieve 53 bits of the keyed state of the stream cipher by performing a chosen IV attack. For the root ciphers, we present a “long ” IV attack which requires 2 22. 24 IV setups, and a “short ” IV attack which requires 2 28. 73 IV setups on average. The 53 bits retrieved reduce the complexity of the exhaustive key search by 53 bits. The chosen IV attack can be turned into a chosen message attack on a MAC based on VEST...|$|E
40|$|IN {{computations}} by abstract computing {{devices such}} as the Turing machine, head reversals are required for searching the input or retrieving intermediate results. Hence the number of head reversals {{is a measure of}} the complexity of a computation. This thesis is a study of reversal-bounded computation on three models of abstract computing devices. The first model is the 1 -tape Turing machine with finite bounds on head reversals. It is known that such machines recognize exactly the regular sets so that for recognition purposes, reversals can be eliminated entirely. For transduction purposes, that is, if an output is expected on the tape, a single reversal suffices. Hence these machines are most appropriately called finite automata. Clearly they are among the weakest possible computing devices, and many decision problems about them are solvable. We use this fact and a very simple input-output encoding scheme to obtain greatly simplified proofs of the decidability of some weak mathematical theories, including the weak monadic second-order theory of one successor and Presburger arithmetic. Similar techniques yield linear size bounds as well as linear time complexity bounds (on the multitape Turing machine model) for functions definable in Presburger arithmetic. As corollaries, we find applications in linear diophantine systems and linear integer programming. The second model is the multicounter machine with general bounds on counter reversals. By relating counter reversal to time and space, we show that recursiveness of reversal bounds implies recursiveness of the sets accepted. For bounds that are at least <b>linear,</b> <b>counter</b> reversal is polynomially equivalent to Turing machine time in both the deterministic and the nondeterministic cases. This result leads to a general deterministic reversal hierarchy and a natural formulation fo the P=?NP question on the multicounter machine model. It also suggests that on every reasonable universal computing model, there is a "natural" complexity measure that is polynomially equivalent to Turing machine time. For reversal bounds that grow more slowly than $n^{ 1 / 2 }$, we show that the nondeterministic 2 -way reversal complexity class is not closed under complementation and strictly includes the corresponding deterministic class. In contrast, the analogous questions are open for 2 -way 2 -tape Turing machines with logarithmic space bounds. Finally, we consider finite bounds on counter reversals. For both the 1 -way and the 2 -way models, we obtain very sharp upper bounds on the Turing machine time and space complexity of the languages accepted. In the 1 -way case, we present a unified account of the known results, interspersed with our contributions, which include (1) equivalence to 1 -way simple multihead finite automata, (2) an easy technique for proving nonrecognizability, (3) an abstract characterization of the power of finite reversal-bounded counters, and (4) an application to the theory of program schemes. Lastly, we consider finite reversal-bounded multitape finite automata. We show that over a single-letter alphabet, the languages accepted are exactly the unary encodings of Presburger relations. This result holds whether the model is determinisitic or nondeterministic, and even if it is augmented with, for example, finite reversal-bounded counters and an unrestricted pushdown store, or if the reversals are restricted to rewinds, that is, instructions that simultaneously position all heads at the beginnings of their respective tapes. For both deterministic and nondeterministic rewind automata, we establish exhaustive hierarchies based on the finite number of rewinds. When restricted to a single-letter alphabet, the deterministic hierarchy stands but the nondeterministic one collapses...|$|E
40|$|AbstractThe North-East {{model is}} a {{combinatorial}} model arising from statistical physics in which counters are placed at or removed from lattice points in a quadrant, according to certain rules, while bounding {{the total number of}} occupied sites. We show that any site may be reached with a number of <b>counters</b> <b>linear</b> in the distance of the site from the origin. We also show that in contrast with the one-dimensional East model, a <b>linear</b> number of <b>counters</b> is necessary. We extend the North-East model to n dimensions with corresponding linear upper and lower bounds. In two dimensions, a polynomial number of steps are sufficient to achieve the linear upper bound...|$|R
40|$|Any one counter {{language}} that is not nonterminal bounded must contain an infinite regular set; every generator {{of the family of}} one counter languages must contain an infinite regular set. Any {{language that}} is in the substitution closure of the <b>linear</b> and one <b>counter</b> languages but is not derivation bounded must contain an infinite regular set...|$|R
3000|$|Howard and Fast (1957) {{stated that}} since the {{fracturing}} fluid properties are reflected through the fracturing fluid coefficient, C, {{it is important to}} establish a method for the determination of this factor for various types of fracturing fluids. The fracturing fluid coefficient, C, defines the three types of <b>linear</b> flow mechanisms <b>countered</b> with fracturing fluids for which comprises of: [...]...|$|R
40|$|AbstractFor {{a family}} of linear {{operators}} A(λ→) :U→U over C that smoothly depend on parameters λ→=(λ 1,…,λk), V. I. Arnold obtained the simplest normal form of their matrices relative to a smoothly depending on λ→ change of a basis in U. We solve the same problem for {{a family of}} linear operators A(λ→) :U→U over R, {{for a family of}} pairs of linear mappings A(λ→) :U→V,B(λ→) :U→V over C and R, and for a family of pairs of <b>counter</b> <b>linear</b> mappings A(λ→) :U→V,B(λ→) :V→U over C and R...|$|R
40|$|Abstract. Dragon {{is a word}} {{oriented}} {{stream cipher}} submitted to the ECRYPT project, it operates on key sizes of 128 and 256 bits. The original idea of the design {{is to use a}} nonlinear feedback shift register (NLFSR) and a <b>linear</b> part (<b>counter),</b> combined by a filter function to generate a new state of the NLFSR and produce the keystream. The internal state of the cipher is 1088 bits, i. e., any kinds of TMD attacks are not applicable. In this paper we present two statistical distinguishers that distinguish Dragon from a random source both requiring around O(2 155) words of the keystream. In the first scenario the time complexity is around O(2 155 + 32) with the memory complexity O(2 32), whereas the second scenario needs only O(2 155) of time, but O(2 96) ofmemory. The attack is based on a statistical weakness introduced into the keystream by the filter function F. This is the first paper presenting an attack on Dragon, and it shows that the cipher does not provide full security when the key of size 256 bits is used. ...|$|R
40|$|We {{show that}} {{deterministic}} finite automata equipped with $k$ two-way heads are equivalent to deterministic machines {{with a single}} two-way input head and $k- 1 $ linearly bounded counters if the accepted language is strictly bounded, i. e., a subset of $a_ 1 ^*a_ 2 ^* [...] . a_m^*$ for a fixed sequence of symbols $a_ 1, a_ 2, [...] ., a_m$. Then we investigate <b>linear</b> speed-up for <b>counter</b> machines. Lower and upper time bounds for concrete recognition problems are shown, implying that in general linear speed-up does not hold for counter machines. For bounded languages we develop a technique for speeding up computations by any constant factor {{at the expense of}} adding a fixed number of counters...|$|R
40|$|A large set of {{variable}} coefficient linear systems of ordinary differential equations which possess two different time scales, a slow {{one and a}} fast one is considered. A small parameter epsilon characterizes the stiffness of these systems. A system of o. d. e. s. in this set is approximated by a general class of multistep discretizations which includes both one-leg and linear multistep methods. Sufficient conditions are determined under which each solution of a multistep method is uniformly bounded, with a bound which is independent of the stiffness {{of the system of}} o. d. e. s., when the step size resolves the slow time scale, but not the fast one. This property is called stability with large step sizes. The theory presented lets one compare properties of one-leg methods and linear multistep methods when they approximate variable coefficient systems of stiff o. d. e. s. In particular, it is shown that one-leg methods have better stability properties with large step sizes than their <b>linear</b> multistep <b>counter</b> parts. The theory also allows one to relate the concept of D-stability to the usual notions of stability and stability domains and to the propagation of errors for multistep methods which use large step sizes...|$|R
40|$|BACKGROUND: Telomerase, {{which is}} active early in {{development}} {{and later in}} stem and germline cells, is also active {{in the majority of}} human cancers. One of the known functions of telomerase is to extend the ends of <b>linear</b> chromosomes, <b>countering</b> their gradual shortening at each cell division due to the end replication problem and postreplication processing. Telomerase concentration levels vary between different cell types as well as between different tumors. In addition variable telomerase concentrations will exist in different cells in the same tumor when telomerase inhibitors are used, because of limitations of drug delivery in tissue. Telomerase extends short telomeres more frequently than long telomeres and the relation between the extension frequency and the telomere length is nonlinear. METHODOLOGY/PRINCIPAL FINDINGS: Here, the biological data of the nonlinear telomerase-telomere dynamics is incorporated in a mathematical theory to relate the proliferative potential of a cell to the telomerase concentration in that cell. The main result of the paper is that the proliferative capacity of a cell grows exponentially with the telomerase concentration. CONCLUSIONS/SIGNIFICANCE: The theory presented here suggests that long term telomerase inhibition in every cancer progenitor or cancer stem cell is needed for successful telomere targeted cancer treatment. This theory also can be used to plan and assess the results of clinical trials targeting telomerase...|$|R
40|$|AbstractWe {{study the}} time {{relationships}} between several models of computation (variants of counter machines, Turing machines, and random access machines). It is shown that counter machines augmented by a “copy” instruction can be simulated in <b>linear</b> time by <b>counter</b> machines without such an instruction, {{and that these}} counter machines can be simulated by RAM's with speedup by a fixed polynomial. Since the difference between augmented counter machines and RAM's lies partly in the latter's indirect addressing capabilities, we obtain bounds {{on the extent to}} which these capabilities speed up computations. We also show that unit-cost RAM's can simulate multi-dimensional Turing machines with speedup using their addressing capabilities to efficiently implement multidimensional arrays. Evidence is presented to show that on a restricted class of RAM's, “successor” RAM's, efficient implementation of multi-dimensional arrays is not possible...|$|R
40|$|International audienceWe {{consider}} {{the problem of}} scheduling Mixed Criticality (MC) job systems with an arbitrary number of criticality levels on a single processing platform, when job demands are probabilistic and their distributions are known. We develop a probabilistic framework for MC scheduling, where feasibility {{is defined as the}} risk of missing deadlines, which we express in terms of (chance) constraints on the probabilities that jobs of every criticality miss their deadlines. Our goal is to identify and compute " efficiently implementable " scheduling policies under which the given probabilistic constraints are satisfied. We model the problem as a Constrained Markov Decision Process (CMDP), and we show that a feasible Markov randomized scheduling policy exists if the given instance is feasible in a probabilistic sense. A feasible policy can be obtained by solving a <b>linear</b> program. To <b>counter</b> the potential state space explosion, we outline an approximation method that might trade feasibility for efficiency, but which performs well in practice...|$|R
40|$|A {{prototype}} of a {{liquid level gauge}} based on pulsed time-of-flight (TOF) method was developed for measuring liquid level accurately at distances from zero to 30 metres. The system consists of an optomechanical sensor head and electronics unit which are connected to each other by means of two optical fibres. The developed level gauge utilizes mirror-like reflection of the liquid surface and by proper design of the optics the received signal is constant in the whole measurement range. The losses in the optical path of the level gauge are relatively small, thus allowing {{the use of a}} 1 mW CW semiconductor diode laser as a light source. The pulsing frequency of the laser is 1. 5 MHz and the time interval between start and stop pulses is digitized by means of a simple and inherently <b>linear</b> synchronous digital <b>counter.</b> The correct orientation of the measurement head is achieved by using sensitive bearings and by allowing gravity to keep the correct orientation. An attenuation system based on e [...] ...|$|R
40|$|The {{study and}} {{examination}} of religion or relgions requires {{a multiplicity of}} tools. Since man's religions invariably reflect human experience and understanding, the study of religion encompasses history, ethnology, linguistics, literature, philosophy, economics, sociology, political science, and anthropology. Among the "Great Religions " of the world may be discovered repetition and similarity, as well as, variations and significant differences. This similarity becomes clear when it is understood that of the five great religions-Judaism, Christianity, Islam, Hinduism, Buddhism-a reduction to two may be made historically. Hinduism and Judaism may be considered {{the genesis of the}} other three: Hinduism as the seed ground for Buddhism; Judaism, for Christianity and Islam. The differences between the two major traditions may be viewed from a philosophical perspective as a springboard to theological developments. For instance, there is a fundamental difference in the way time is perceived. The Western orientation of <b>linear</b> time is <b>countered</b> by the Eastern orientation of cyclical time. In addition there is a vast gulf between the East and West in the perception o...|$|R
40|$|This paper draws {{together}} Hochschild’s (1979; 1983) {{concepts of}} emotional labour and feeling rules with Ahmed’s affective economies (2004 a, 2004 b; 2008; 2010) and queer phenomenology (2006 a, 2006 b) {{as a way}} to address wider questions about sexuality and schooling. It highlights the value of the everyday politics of emotion for elucidating and clarifying the specificities, pertinence and complementarities of Hochschild’s and Ahmed’s work for reimagining the relationship between sexualities and schooling. The combination of their approaches allows for a focus on the individual, bodily management of emotions while demonstrating the connectedness of bodies and spaces. It enables disruption of ‘inclusive’ and ‘progressive’ educational approaches that leave heterosexuality uninterrupted and provides insight into how power works in and across the bodies, discourses, practices, relations and spaces of schools to maintain a collective orientation towards heterosexuality. It also <b>counters</b> <b>linear</b> narratives of progressive change, elucidating how change is a hopeful but messy process of simultaneous constraint, transgression and transformation. Key moments from a three-year study with LGBT-Q teachers entering into civil partnerships (CP) in Ireland serve as exploratory examples of the theoretical ideas put forward in this paper. ACCEPTEDpeer-reviewe...|$|R
40|$|Model {{checking}} {{deals with}} the techniques of verifying whether a given formula in a suitably expressive logic is satisfied in a given abstract structure. The techniques {{as well as the}} cost for such task vary depending on the abstract formalism used to represent the model and the logic used to express the properties [CGP 00]. For abstract formalism, it is worth to note that most of the practical systems are infinite-state systems. The challenge is to manipulate infinite sets of configurations. Whereas many abstract formalisms for representing infinite-state system exist, most of them tend to have an undecidable model checking. Counter systems are such a formalism used in many places like, broadcast protocol [EFM 99], programs with pointers [BFLS 06], and data words (XML) [BMS+ 06], [DL 06]. But, alongwith their large scope of usability, many problems on general counter systems are known to be undecidable. For example, systems with two counters are known to simulate Turing Machine operations [Min 67]. We consider the Linear Temporal Logic for specifying properties. LTL is enough powerful to specify temporal properties like liveness or safety conditions and yet have many desirable properties. We consider here LTL with the basic Until and Next operator. Later we also look into basic LTL extended with <b>linear</b> constraints on <b>counter</b> as atomic propositions. The Problem Studie...|$|R
40|$|We {{present a}} family of {{efficient}} distributed deadlock avoidance algorithms with applications to distributed real-time and embedded systems (DREs), which subsumes previously known solutions as special instances. Then we use this family to study the reachable set of states and the allocation sequences allowed by the different protocols. This result enables a new proof method for showing freedom from deadlock of variations of deadlock avoidance protocols. Distributed deadlock avoidance is a hard problem and general solutions are considered impractical due to the high communication overhead. In previous work, however, we showed that practical solutions exist when all possible sequences of resource requests are known a priori {{in the form of}} call graphs; in this case, protocols can be constructed that perform safe resource allocation based on local data only, that is, no communication between components is required. The most basic algorithm Basic-P, performs only one operation per request using one counter per site. The protocol Live-P, which also guarantees liveness globally, needs to performs a logarithmic number of operations per request, using a <b>linear</b> number of <b>counters</b> in each site (in terms of the total ammount of resources). The family of algorithms that we introduce here, called k-Efficient-P, subsumes these as special cases. This family allows us to compare the protocols according to the set of reachable states and their legal allocation sequences. We prove that, even though the more liberal algorithms allow more concurrency, all algorithms can reach the same set of states. We capture this set of states as a network invariant...|$|R
40|$|Inflammation {{that occurs}} {{following}} {{acute myocardial infarction}} plays {{a pivotal role in}} 2 ̆ 2 healing 2 ̆ 2 by facilitating the creation of a supportive scar. (18) F-FDG, which is taken up avidly by macrophages, has been proposed as a marker of cell-based inflammation. However, its reliability as an accurate indicator of inflammation has not been established, particularly in the early post infarction period when regional myocardial perfusion is often severely compromised. METHODS: Nine adult dogs underwent left anterior descending coronary occlusion with or without reperfusion. Animals were imaged between 7 to 21 days post infarction with Positron Emission Tomography/Magnetic Resonance Imaging (PET/MRI) following: a) bolus injection of Gd-DTPA, b) bolus injection of (18) F-FDG, c) bolus injection of 99 Tc-DTPA to simulate the distribution of Gd-DTPA (which represents its partition coefficient in well perfused tissue) and d) the injection of (111) Indium-labeled white blood cells 24 hours earlier. Following sacrifice, myocardial tissue concentrations of (18) F, (111) In and 99 Tc were determined in a well <b>counter.</b> <b>Linear</b> regression analysis evaluated the relationships between a) the concentrations of (111) In vs (18) F and b) the dependence of the ratio of (111) In/(18) F to the apparent distribution volume of (99 m) Tc-DTPA. RESULTS: In seven of the nine animals (111) In increased as (18) F increased with the other two animals showing weak negative slopes. With respect to the dependence of (111) In/(18) F with partition coefficient four animals showed no dependence and four showed a week positive slope with one animal showing a negative slope. Further, in regions of extensive microvascular obstruction, (18) F significantly underestimated the extent of the presence of (111) In. CONCLUSION: In the early post myocardial infarction period, PET (18) F-FDG imaging following a single bolus administration may underestimate the extent and degree of inflammation within regions of microvascular obstruction...|$|R

