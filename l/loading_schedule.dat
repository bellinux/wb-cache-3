18|620|Public
40|$|With special {{reference}} to design of fuel tanks in space vehicles, {{the principles of}} fracture mechanics are reviewed. An approximate but extremely simple relationship is derived among the operating stress level, the length of crack, {{and the number of}} cycles of failure. Any one of the variables can be computed approximately from the knowledge of the other two, if the <b>loading</b> <b>schedule</b> (mission of the tank) is not greatly altered. Two sample examples illustrating the procedures of determining the allowable safe operating stress corresponding to a set of assumed <b>loading</b> <b>schedule</b> are included. The selection of sample examples is limited by the relatively meager available data on the candidate material for various stress ratios in the cycling...|$|E
40|$|Distortion during {{sintering}} {{has been}} a critical problem in the fabrication of hard materials such as tungsten carbide by the conventional press and sinter process. Until now, cures for the distortion problem have included changes in the polymer additives, tool motion, and various sintering tricks. This paper shows the sources of distortion can be modeled via computer simulation. As a consequence, we back-calculate the die shape to obtain precise final shapes. In this study, the simulation results by PMsolver (CAE design associated with the conventional P/M process) are verified. The compaction schedule is designed to obtain as uniform a green density distribution as possible {{and the effect of}} <b>loading</b> <b>schedule</b> on distortion during sintering are compared to experimental results...|$|E
40|$|Objectives: To {{determine}} {{factors influencing}} compliance {{in patients with}} neovascular age-related macular degeneration (n-AMD) undergoing intravitreal anti-vascular endothelial growth factor (VEGF) therapy. Materials and Methods: The files of n-AMD patients recommended treatment with ranibizumab were reviewed retrospectively. The treatment regimen was 3 consecutive monthly injections followed by monthly follow-up with intravitreal injections as needed (pro re nata, PRN). Demographic and ocular characteristics were recorded. The patients were categorized into 2 groups: full compliance to treatment, or incomplete <b>loading</b> <b>schedule</b> and/or irregular maintenance treatment. All patients were interviewed by phone about factors affecting continuation of treatment. Results: Mean age of the 314 patients (160 female, 154 male) {{included in the study}} was 71. 6 ± 9. 1 years. A total of 246 patients (78. 3...|$|E
40|$|In {{this short}} paper we {{consider}} the equivalence between various load-scheduling policies and continuous time Markov chains. It provides a basic unification of both divisible <b>load</b> <b>scheduling</b> and Markov chains {{for the first time}} in 15 years of research. This unification is suggested by the fact that both divisible <b>load</b> <b>scheduling</b> theory and Markovian queueing theory have common features...|$|R
40|$|AbstractA robust {{optimization}} model was proposed for smart home <b>load</b> <b>scheduling</b> {{to tackle the}} uncertain challenges brought by PV system, in which an adaption parameter, Γ, is defined to control the robust level of the final optimal solution. The proposed robust optimization is capable of producing <b>load</b> <b>schedules</b> with different electricity cost and robust levels. Final decisions can be made as a tradeoff according to users’ financial situation and risk preference...|$|R
40|$|This paper {{focuses on}} the <b>load</b> <b>scheduling</b> problem in both demand-side {{management}} and supply-side management for household users in a smart grid. Linear programming models have been developed either to minimize the energy cost in demand-side scheduling, or to maximize the load factor for supply-side scheduling. The proposed models provide various flexibilities to the end users {{by allowing them to}} define multiple time intervals for the operations of intended appliances, and to pre-set if an appliance should be operated with or without interruption. Simulations performed on the <b>load</b> <b>scheduling</b> of one individual household give promising and convincing results. The proposed model in its linear programming form promises a fast and convergent solving process with a guaranteed exact solution. These added features make the proposed <b>load</b> <b>scheduling</b> framework more practical and realistic for real world applications...|$|R
40|$|Wind tunnel {{force balance}} {{calibration}} is preformed utilizing {{a variety of}} different methods and does not have a direct traceable standard such as standards used for most calibration practices (weights, and voltmeters). These different calibration methods and practices include, but are not limited to, the <b>loading</b> <b>schedule,</b> the load application hardware, manual and automatic systems, re-leveling and non-re-leveling. A study of the balance calibration techniques used by NASA was undertaken to develop metrics for reviewing and comparing results using sample calibrations. The study also includes balances of different designs, single and multi-piece. The calibration systems include, the manual, and the automatic that are provided by NASA and its vendors. The results to date will be presented along with the techniques for comparing the results. In addition, future planned calibrations and investigations based on the results will be provided...|$|E
40|$|Abstract: Presented in {{the paper}} is MES (manufacturing {{execution}} system) architecture suitable for managing FMS (flexible manufacturing system) lines under an ERP (enterprise planning system) environment. An IDEF 0 -model of an ‘order handling ’ shop floor having an FMS line is developed to identify functional requirements of MES, and then a two-tier MES architecture satisfying the functional requirements is proposed. The proposed MES is composed of a Main-MES (for the main shop floor) and an FMS-MES (for the FMS line). BOP (bill of processes) {{is used as a}} means to represent process plans, and LS-Net (<b>loading</b> <b>schedule</b> network) is used as a mechanism for representing and manipulating loading schedules. Object models of BOP and LS-Net are presented, and the effectiveness of the proposed MES is demonstrated by applying it to two FMS lines, a stamping-die machining line and a mechanical part machining line. 1...|$|E
40|$|The {{optimization}} program (PMsolver) {{is developed}} {{to analyze and}} optimize the powder compaction. The optimization program has the capability to predict (1) the formation of cracks in the green compact, (2) the density distribution in the compact and (3) the tooling forces required to achieve these densities and (4) provide the optimum processing variables during powder compaction. The optimization program is applied to predict the density distribution and tooling forces. Based on the verification of the program, <b>loading</b> <b>schedule</b> is optimized to achieve uniform density distribution in the Hub shaped green part during die compaction. This part had been previously analyzed by several compaction simulation models through the European consortium MODNET. A new concept to predict crack formation during powder compaction is proposed. The numerical simulation results show excellent agreement with experimental data and the process conditions obtained by the optimization procedure remarkably {{improve the quality of}} product...|$|E
40|$|New <b>load</b> <b>schedules</b> for {{the machine}} {{calibration}} of a six-component force balance {{are currently being}} developed and evaluated at the NASA Ames Balance Calibration Laboratory. One of the proposed <b>load</b> <b>schedules</b> is discussed in the paper. It has a total of 2082 points that are distributed across 16 load series. Several criteria were applied to define the <b>load</b> <b>schedule.</b> It was decided, for example, to specify the calibration load set in force balance format as this approach greatly simplifies {{the definition of the}} lower and upper bounds of the <b>load</b> <b>schedule.</b> In addition, all loads are assumed to be applied in a calibration machine by using the one-factor-at-a-time approach. At first, all single-component loads are applied in six load series. Then, three two-component load series are applied. They consist of the load pairs (N 1, N 2), (S 1, S 2), and (RM, AF). Afterwards, four three-component load series are applied. They consist of the combinations (N 1, N 2, AF), (S 1, S 2, AF), (N 1, N 2, RM), and (S 1, S 2, RM). In the next step, one four-component load series is applied. It is the load combination (N 1, N 2, S 1, S 2). Finally, two five-component load series are applied. They are the load combination (N 1, N 2, S 1, S 2, AF) and (N 1, N 2, S 1, S 2, RM). The maximum difference between loads of two subsequent data points of the <b>load</b> <b>schedule</b> is limited to 33 % of capacity. This constraint helps avoid unwanted load "jumps" in the <b>load</b> <b>schedule</b> that can {{have a negative impact on}} the performance of a calibration machine. Only loadings of the single- and two-component load series are loaded to 100 % of capacity. This approach was selected because it keeps the total number of calibration points to a reasonable limit while still allowing for the application of some of the more complex load combinations. Data from two of NASA's force balances is used to illustrate important characteristics of the proposed 2082 -point calibration <b>load</b> <b>schedule...</b>|$|R
40|$|Slides of a {{presentation}} on Voice over ATM. Topics include: Performance Requirements N-Source Configuration Simulation configuration CDV Source Model Performance Metrics Multiplexing Gain Scheduling Policies Scheduling Results: 1 Buf/VC Scheduling Results: 1 Buf/VC (Cont) Scheduling Policies: Results I Scheduling Results: 2 Bufs/VC Scheduling Results: 2 Bufs/VC (Cont) Scheduling Policies: Results II <b>Scheduling</b> Results: Medium <b>Load</b> <b>Scheduling</b> Results: Heavy <b>Load</b> <b>Scheduling</b> Policies: Results III Drop Policies Drop Policies Results Drop Polices Results: Heavy Load Drop Policies: Result...|$|R
30|$|Upcoming {{work is the}} {{implementation}} of a controller that uses the PV power and load forecasts for efficient operational strategies for battery charging and <b>load</b> <b>scheduling.</b>|$|R
40|$|This paper studies a {{scheduling}} problem arising in a beef distribution system where pallets {{of various types}} of beef products in the warehouse are first depalletized and then individual cases are loaded via conveyors to the trucks which deliver beef products to various customers. Given each customer's demand {{for each type of}} beef, the problem is to find a depalletizing and truck <b>loading</b> <b>schedule</b> that fills all the demands at a minimum total cost. We first show that the general problem where there are multiple trucks and each truck covers multiple customers is strongly NP-hard. Then we propose polynomial-time algorithms for the case where there are multiple trucks, each covering only one customer, and the case where there is only one truck covering multiple customers. We also develop an optimal dynamic programming algorithm and a heuristic for solving the general problem. By comparing to the optimal solutions generated by the dynamic programming algorithm, the heuristic is shown to be c [...] ...|$|E
40|$|MES (manufacturing {{execution}} system) architecture for FMS compatible to ERP (enterprise planning system) BYOUNG K. CHOI and BYUNG H. KIM Abstract. Presented in {{the paper}} is MES (manufacturing execution system) architecture, which is suitable for managing FMS (flexible manufacturing system) lines under an ERP (enterprise planning system) environment. An IDEF 0 -model of an ‘order handling ’ shop floor having an FMS line is developed to identify functional requirements of MES, and then a two-tier MES architecture satisfying the functional requirements is proposed. The proposed MES is composed of a Main-MES (for the main shop floor) and an FMS-MES (for the FMS line). A BOP (bill of processes) {{is used as a}} means to represent process plans, and a LS-Net (<b>loading</b> <b>schedule</b> network) is used as a mechanism for representing and manipulating loading schedules. Object models of BOP and LS-Net are presented, and the effectiveness of the proposed MES is demonstrated by applying it to two FMS lines, a stamping-die machining line and a mechanical part machining line. 1...|$|E
40|$|This paper {{attempts}} {{to provide an}} optimum <b>loading</b> <b>schedule</b> of power generating units with the least cost by solving a unit commitment (UC) problem and to present good estimates of cost differences when UC problem is not applied. UC is a fundamental optimization problem of power generation systems which determines the optimum schedule of generating units which minimizes generation costs. However, for small power generation firms which are situated in developing countries, UC-based problems are poorly understood if not implemented and the scheduling of generating units is based on some methodologies which may provide results that are not optimal. Thus, {{a case study in}} a small power generation firm in central Philippines is carried out to elucidate these objectives. The case requires a solution of the mixed-integer nonlinear programming (MINLP) problem. Results show that the proposed UC-based problem yields optimal costs and the cost disparity from the current scheduling scheme is approximately at 27 % which may be considered as potential cost savings. This shows that UC-based problem provides a reliable platform in achieving minimal generation costs. These results are significant to decision-makers particularly in small power generation firms and to engineering practitioners in the Philippines and in some developing countries as these provide an overview of the disparity of cost figures of not implementing UC...|$|E
40|$|In recent years, {{researchers}} have proposed numerous advanced <b>load</b> <b>scheduling</b> algorithms for smart homes {{with the goal}} of reducing the grid’s peak power usage. In parallel, utilities have introduced variable rate pricing plans to incentivize residential consumers to shift more of their power usage to low-price, off-peak periods, also {{with the goal of}} reducing the grid’s peak power usage. In this pa-per, we argue that variable rate pricing plans do not incentivize consumers to adopt advanced <b>load</b> <b>scheduling</b> algorithms. While beneficial to the grid, these algorithms do not significantly lower a consumer’s electric bill. To address the problem, we propose flat-power pricing, which directly incentivizes consumers to flat-ten their own demand profile, rather than shift as much of their power usage as possible to low-cost, off-peak periods. Since most loads have only limited <b>scheduling</b> freedom, <b>load</b> <b>scheduling</b> algo-rithms often cannot shift much, if any, power usage to low-cost, off-peak periods, which are often many hours in the future. In con-trast, flat-power pricing encourages consumers to shift power usage even over short time intervals to flatten demand. We evaluate the benefits of advanced <b>load</b> <b>scheduling</b> algorithms using flat-power pricing, showing that consumers save up to 40 % on their electric bill, compared with 11 % using an existing time-of-use rate plan...|$|R
40|$|The aim of {{this paper}} is to provide a {{solution}} for <b>load</b> <b>scheduling</b> by implementing value stream mapping, which is a straightforward enough for production management. Decision makers in the industry should have a clear understanding about positive effect from <b>load</b> <b>scheduling</b> and its effect to production outcome and process availability. Value stream mapping is a well-known process optimization tool from lean production philosophy. The aim of value stream mapping is to shorten the lead time of industrial processes and to reduce the intermediate stock amounts. By complementing value stream map with process energy intensity and energy stored in intermediate stocks, we can promote <b>load</b> <b>scheduling</b> possibilities. Our methodology provides a tool that is understandable and traceable for industry-minded decision makers. Finally, we present a real life test example for the new methodology, which is based on the production process of a district heating plant...|$|R
40|$|Abstract—A simple {{modification}} of existing divisible <b>load</b> <b>scheduling</b> algorithms, boosting link speed by M for M parallel channels per link, allows time optimal <b>load</b> <b>scheduling</b> and performance prediction for parallel channel systems. The situation for multicore models {{is more complex}} but can be handled by a substitution involving equivalent processor speed. These modifications yield upper bounds on such parallel systems’ performance. This concept is illustrated for ideal single level (star) tree networks {{under a variety of}} scheduling policies. Less than ideal parallelism can also be modeled though mechanisms of inefficiency require further research. I...|$|R
40|$|The {{backfilling}} {{materials of}} borehole heat exchangers (BHE), particularly the grout material, must provide a suitable thermal contact and ensure durability to the induced thermal stresses {{because of the}} heat loading. In this paper, the thermal stresses that occurred in BHEs because of heat injection or extraction is investigated with an analytical solution of a hollow cylinder model that is adapted for time-dependent heat loading, the geometry of a BHE, and the thermo-mechanical properties of surrounding ground conditions. Firstly, the hollow cylinder model is solved with the considered boundary conditions in 2 D plane stress. Secondly, the temperature differences at {{the inner and outer}} circles of the cylinder are evaluated with the heat line source models for continuous and discontinuous loading to observe the impact of the heat <b>loading</b> <b>schedule.</b> The developed analytical solution for thermal stress investigation is validated with numerical models. It is demonstrated that the analytical solutions agree well with numerical results for two types of BHE configurations (co-axial and single U-shaped pipes). Furthermore, the calculated maximum stresses are compared with the tensile strength of grout materials obtained from Brazilian tests. It is predicted that the thermal contraction of the grout, partially constrained by the surrounding rock, generates tensile stresses that may lead to cracking in the BHE. According to the results, the stiffness of rock has a primary role on the developed tensile stresses, and the relationship between the thermal conductivity of the ground and of the grout induces a proportional impact on the magnitude of thermal stresses. SCOPUS: ar. jFLWINinfo:eu-repo/semantics/publishe...|$|E
40|$|PURPOSE: To develop {{recommendations}} about endocrine {{therapy for}} women with hormone receptor (HR) -positive metastatic breast cancer (MBC). METHODS: The American Society of Clinical Oncology convened an Expert Panel to conduct a systematic review of evidence from 2008 through 2015 to create recommendations informed by that evidence. Outcomes of interest included sequencing of hormonal agents, hormonal agents compared with chemotherapy, targeted biologic therapy, and treatment of premenopausal women. This guideline puts forth recommendations for endocrine therapy as treatment {{for women with}} HR-positive MBC. RECOMMENDATIONS: Sequential hormone therapy is the preferential treatment for most women with HR-positive MBC. Except in cases of immediately life-threatening disease, hormone therapy, alone or in combination, should be used as initial treatment. Patients whose tumors express any level of hormone receptors should be offered hormone therapy. Treatment recommendations {{should be based on}} type of adjuvant treatment, disease-free interval, and organ function. Tumor markers should not be the sole criteria for determining tumor progression; use of additional biomarkers remains experimental. Assessment of menopausal status is critical; ovarian suppression or ablation should be included in premenopausal women. For postmenopausal women, aromatase inhibitors (AIs) are the preferred first-line endocrine therapy, with or without the cyclin-dependent kinase inhibitor palbociclib. As second-line therapy, fulvestrant should be administered at 500 mg with a <b>loading</b> <b>schedule</b> and may be administered with palbociclib. The mammalian target of rapamycin inhibitor everolimus may be administered with exemestane to postmenopausal women with MBC whose disease progresses while receiving nonsteroidal AIs. Among patients with HR-positive, human epidermal growth factor receptor 2 -positive MBC, human epidermal growth factor receptor 2 -targeted therapy plus an AI can be effective for those who are not chemotherapy candidates...|$|E
40|$|OBJECTIVES: The use of tumor {{necrosis}} factor-alpha (TNF-alpha) antagonists {{has changed}} the therapeutic strategy for Crohn's disease (CD). Adalimumab (ADA), a fully human anti-TNF-alpha monoclonal antibody, is an effective therapy for patients with CD, both naive patients and those intolerant or refractory to Infliximab (IFX), a chimeric anti-TNF-alpha agent. However, the use of ADA is rarely reported in pediatric CD. We performed an open prospective evaluation of short-and long-term efficacy and safety of ADA in children with moderate-to-severe CD. METHODS: A total of 23 pediatric CD patients (9 naive and 14 intolerant or unresponsive to IFX) received ADA subcutaneously as a <b>loading</b> <b>schedule</b> at weeks 0 and 2, and at every other week (eow) during a 48 -week maintenance phase. Loading and maintenance doses were 160 / 80 and 80 mg eow in 13 cases, 120 / 80 and 80 mg eow in 2, and 80 / 40 and 40 mg eow in 8 cases. The primary efficacy outcomes were clinical remission and response at different scheduled visits along the maintenance phase. At baseline, 13 patients also received immunomodulators (IMs). RESULTS: At weeks 2, 4, 12, 24, and 48, remission rates were 36. 3, 60. 8, 30. 5, 50, and 65. 2 %, respectively, whereas response rates were 87, 88, 70, 86, and 91 %, respectively. Four patients at week 24 and 2 at week 48 received IMs; the mean daily corticosteroid dose, disease activity index, C-reactive protein level, and erythrocyte sedimentation rate decreased significantly throughout the trial. No serious adverse events were recorded. CONCLUSIONS: ADA {{can be an effective}} and safe biological agent for inducing and maintaining remission in children with moderate-to-severe CD, even in those with previous IFX therapy...|$|E
40|$|We {{consider}} joint {{energy storage}} management and <b>load</b> <b>scheduling</b> at a residential site with integrated renewable generation. Assuming unknown arbitrary dynamics of renewable source, loads, and electricity price, {{we aim at}} optimizing the <b>load</b> <b>scheduling</b> and energy storage control simultaneously {{in order to minimize}} the overall system cost within a finite time period. Besides incorporating battery operational constraints and costs, we model each individual load task by its requested power intensity and service durations, as well as the maximum and average delay requirements. To tackle this finite time horizon stochastic problem, we propose a real-time scheduling and storage control solution by applying a sequence of modification and transformation to employ Lyapunov optimization that otherwise is not directly applicable. With our proposed algorithm, we show that the joint <b>load</b> <b>scheduling</b> and energy storage control can in fact be separated and sequentially determined. Furthermore, both scheduling and energy control decisions have closed-form solutions for simple implementation. Through analysis, we show that our proposed real-time algorithm has a bounded performance guarantee from the optimal T-slot look-ahead solution and is asymptotically equivalent to it as the battery capacity and time period goes to infinity. The effectiveness of joint <b>load</b> <b>scheduling</b> and energy storage control by our proposed algorithm is demonstrated through simulation as compared with alternative algorithms. Comment: to appear in IEEE Transactions on Smart Gri...|$|R
40|$|This paper {{introduces}} {{an optimal}} load allocation approach for measurement and data reporting in wireless sensor networks. Using divisible load theory {{as a starting}} point, results in terms of minimum finish time (make-span) are obtained for di#erent measurement and reporting strategies. This work is novel as it introduces, for the first time, a new <b>load</b> <b>scheduling</b> strategy that considers the measurement capacity of processors and assumes negligible computation time which is radically di#erent from the traditional divisible <b>load</b> <b>scheduling</b> research to date. Performance results in terms of finish time (make-span) for homogeneous measurement and reporting speeds are also presented...|$|R
40|$|Developing multi- core {{computer}} technology made it practical to accelerate image processing algorithms via parallel running threads. In this study, performance evaluations for parallel image convolution filter on a multi-core computer using Java thread utilities was presented. For this purpose, {{the efficiency of}} static and the dynamic <b>load</b> <b>scheduling</b> implementations are investigated on a multi- core computer with six cores processor. Dynamic <b>load</b> <b>scheduling</b> overhead results were measured experimentally. Also the effect of busy running environment on performance which usually occurs on due to other running processes is illustrated by experimental measurements. According to performance results, about 5. 7 times acceleration over sequential implementation was obtained on a six cores computer for various image size...|$|R
40|$|Four {{full-size}} {{statically indeterminate}} reinforced concrete frames with two symmetrical bays were tested to obtain sufficient data {{to evaluate the}} adequacy of the current ACI-ASCE Committee 352 design recommendations, as well as to determine whether a relaxation of some of the limits in these guidelines can be justified. Each specimen contained three 8. 5 -foot-long columns, connected at mid-height by two 9 -foot-long beams. Initially, a constant axial load was applied to each column. The specimens were then subjected to a displacement-controlled <b>loading</b> <b>schedule</b> to simulate the type of displacements a frame may experience during a severe earthquake. In designing the specimens, the latest recommendations of the ACI-ASCE Committee 352 and the ACI building code ACI 318 - 83 were satisfied except for the following modifications: (1) the flexural strength ratio (M(R)) in the second specimen was reduced from 1. 4 to 1. 2, (2) the shear-stress factors (γ) in the joints of the third specimen were increased from 12 and 15 to 15 and 20 for the exterior and interior joints respectively, and (3) the number of the transverse reinforcements inside the right exterior joint in the fourth specimen was reduced from 4 to 2 sets of hoops. The conclusion inferred from the results indicate that for drift levels within the elastic range, the elongations and the rotations of the beam regions near the faces of the columns, in addition to the joint shear strains, were not affected by the design values for the primary variables in the last three specimens. For larger excursions into the inelastic range, the relaxation of the current Committee 352 design recommendations in the last three specimens not only showed a significant effect in reducing the elongations and the rotations of the beams, or in increasing the joint shear strains but led to lower energy dissipation of the specimens. Consequently, the current design guidelines by the ACI-ASCE Committee 352 yield statically indeterminate frames which exhibit sufficient ductility...|$|E
40|$|The {{consequences}} of rhythmical flow motion for nutrition and the oxygen supply to tissue are largely unknown. In this study, the periodic variations of haemoglobin oxygenation in compressed and uncompressed skin were evaluated with a reflection spectrometer using an in vivo Sprague-Dawley rat model. Skin compression was induced over the trochanter area by a locally applied external pressure of 13. 3 kPa (100 mmHg) via a specifically designed pneumatic indentor. A total of 19 rats {{were used in}} this study. The loading duration is 6 h per day for four consecutive days. Haemoglobin oxygenation variations were quantified using spectral analysis based on wavelets' transformation. The results found that in both compressed and uncompressed skin, periodic variations of the haemoglobin oxygenation were characterized by two frequencies {{in the range of}} 0. 01 - 0. 05 Hz and 0. 15 - 0. 4 Hz. These frequency ranges coincide with those of the frequency range of the endothelial-related metabolic and myogenic activities found in the flow motion respectively. Tissue compression following the above <b>loading</b> <b>schedule</b> induced a significant decrease in the spectral amplitudes of frequency interval 0. 01 - 0. 05 Hz during the pre-occlusion period on day 3 and day 4 as compared to that on day 1 (p < 0. 05). In contrast, at a frequency range of 0. 15 - 0. 4 Hz, prolonged compression caused a significant increase in spectral amplitude during the pre-occlusion period in the compressed tissue on day 3 (p = 0. 041) and day 4 (p = 0. 024) compared to that in the uncompressed tissue on day 1. These suggested that the variations of the haemoglobin oxygenation were closely related to the endothelial-related metabolic and myogenic activities. Increased amplitude in the frequency interval 0. 15 - 0. 4 Hz indicated an increased workload of the vascular smooth muscle and could be attributed to the increase of O 2 consumption rates of arteriolar walls. The modification of vessel wall oxygen consumption might substantially affect the available oxygen supply to the compressed tissue. This mechanism might be involved in the process leading to pressure ulcer formation. Department of Health Technology and Informatic...|$|E
40|$|ASPIRE {{designed}} the gravity, lateral, and foundation systems, utilized finite element software for structural optimization, designed steel and concrete connections, {{and studied the}} effects of creep and shrinkage during a year-long analysis of the Chicago Spire. Preliminary analysis included research of different lateral load resisting systems in order to select the system that would best suit {{the needs of the}} structure. The lateral system chosen was a central concrete core with outriggers and belt trusses connecting the core with the exterior steel columns. The gravity design of the structure explored the use of non-composite and composite beams and columns in the Spire. ASPIRE selected steel beams with a composite metal decking system. A column load takedown based on tributary areas was used for the preliminary column design. The Chicago Spire was modeled using MIDAS Gen, a structural finite element software, to accurately understand the lateral behavior of the building. A sensitivity analysis was performed to resize the concrete core, the outriggers, and the belt truss members from the initial hand calculation sizes. Core wall thicknesses were optimized across the height of the building. Vertical columns and transfer columns were redesigned as a series of steel built-up shapes through energy optimization methods. The foundation system featured the design of a seven level below-grade parking garage and a retaining wall along the site perimeter. Rock-socketed caissons were designed to support the tower, extending {{from the base of the}} building to the bedrock 119 feet below grade. There are hundreds of connections in the Chicago Spire ranging from standard steel connections to complex designs for the outriggers and the lobby level mega-columns. Several steel-to-steel and composite connections were designed throughout the tower. A study of concrete creep and shrinkage estimated differential settlement between the concrete core and the exterior steel columns using the GL 2000 model. Creep and shrinkage are dependent on variables such as <b>loading</b> <b>schedule,</b> curing period, and material properties, making it difficult to predict the actual amount of creep and shrinkage. However, failure to acknowledge these effects leads to cracks in the concrete and uneven floors. Through the course of the project, ASPIRE faced many challenges that required the design team to seek guidance from outside sources, including weekly meetings with our faculty advisor and bi-weekly conference calls with our professional advisors from Thornton Tomasetti. The structural design of the Chicago Spire was a collaborative effort of eighteen students and the advisors. The project provided a realistic design experience incorporating team management, iterative design, and professional reporting. For the final deliverable ASPIRE has prepared a cumulative design narrative, calculation book, and final structural drawing set...|$|E
40|$|Abstract—Large-scale {{distributed}} applications {{are subject to}} frequent disruptions due to resource contention and failure. Such disruptions are inherently unpredictable and, therefore, robustness is a desirable property for the distributed operating environment. In this work, we describe and evaluate a robust topology for applications that operate on a spanning tree overlay network. Unlike previous work that is adaptive or reactive in nature, we take a proactive approach to robustness. The topology itself is able to simultaneously withstand disturbances and exhibit good performance. We present both centralized and distributed algorithms to construct the topology, and then demonstrate its effectiveness through analysis and simulation of two classes of {{distributed applications}}: Data collection in sensor networks and data dissemination in divisible <b>load</b> <b>scheduling.</b> The results show that our robust spanning trees achieve a desirable trade-off for two opposing metrics where traditional forms of spanning trees do not. In particular, the trees generated by our algorithms exhibit both resilience to data loss and low power consumption for sensor networks. When used as the overlay network for divisible <b>load</b> <b>scheduling,</b> they display both robustness to link congestion and low values for the makespan of the schedule. Index Terms—Robustness, distributed computing, graph theory, fault tolerance, wireless sensor networks, divisible <b>load</b> <b>scheduling.</b> ...|$|R
40|$|This paper {{describes}} {{an effort to}} build and partially validate an energy model of an existing educational building located in Cambridge, MA, USA. This work was carried out {{as part of a}} research seminar for graduate architecture/design students and included four related tasks: Modelling the building’s geometry and thermal properties in DesignBuilder/EnergyPlus, generating a site-specific weather file based on nearsite measured data, assessing internal <b>load</b> <b>schedules</b> based on a detailed building survey, and collecting monthly metered data for heating lighting and cooling over a whole year. The purpose of the seminar was (a) to evaluate how effectively design students can use a state-of-the-art graphical user interface (GUI) such as DesignBuilder and (b) to quantify the value of using customized weather data and internal <b>load</b> <b>schedules</b> as opposed to default GUI inputs. The authors found that the students quickly learned how to navigate the DesignBuilder GUI but were frequently confused by the model data hierarchy/inheritance and frustrated that customized schedules cannot be assigned more efficiently. The benefit of using customized weather data as opposed to a local TMY 3 file turned out to be small whereas using customized as opposed to default internal <b>load</b> <b>schedules</b> reduced the relative error of predicted versus metered annual electricity use from 18 % t...|$|R
40|$|The {{justification}} {{issues and}} the capacity selection of autotransformers in the main electrical grids, which require the accounting of the operation regimes of power units {{for the future of}} 10 or more years are considered. Appropriate methodological provisions for justification and choice in terms of gen-eralized <b>load</b> <b>schedules,</b> <b>load</b> capacity of transformer equipment, as well as assessing the reliability of elec-trical installations in the design and development of the energy systems are proposed...|$|R
40|$|Introduction: Osteoporosis is a {{commonly}} observed medical condition in aging populations {{which results in}} {{an increased risk of}} skeletal fractures due to accelerated bone loss. Exercise has been suggested as a possible method for slowing the effects of aging on bone loss. The phenomenon of load induced bone growth is known as mechanotransduction. Obtaining {{a better understanding of the}} variables that affect mechanotransduction such as loading rate, loading frequency, loading magnitude, and rest between loading bouts allows a more effective exercise regimen to be created for patients with osteoporosis. This study utilized mouse models to explore the effects of mechanical loading on the ulna. Various loading schedules were executed and the resulting changes in mechanical properties of loaded bone were compared to the non-loaded bone. Materials and Methods: Utilizing a material testing apparatus, anesthetized mice underwent cyclical compressive loading on the right forelimb for predetermined periods of time. The number and frequency of loading bouts were determined based on prior published research (Robling et al. 2002). There were three groups of mice that were sacrificed at 15 weeks (No Loading: N= 8, Three Loading Bouts for One Week: N= 9, Three Loading Bouts for Three Weeks: N= 4). There were two groups of mice that were sacrificed at 18 weeks (No Loading: N= 6, Three Loading Bouts for Three Weeks, N= 6). The mice were sacrificed at completion of the <b>loading</b> <b>schedule</b> and both forelimbs were harvested. MicroCT (ÂµCT) imaging (ÂµCT: Skyscan, Kontich, Belgium) was used to provide cross sectional images of each ulna. CTAn (ÂµCT: Skyscan, Kontich, Belgium) and BoneJ (Bethesda, Maryland) software was used to calculate the cross sectional area along the length of the bone, as well as the minimum and maximum moment of inertia. Comparisons were made between loaded and non-loaded bone for each mouse, as well as comparisons between the various loading schedules. Results and Discussion: Among the three groups of mice that were sacrificed at 15 weeks (No Loading, Three Loading Bouts for One Week, Three Loading Bouts for Three Weeks), there was a trend toward increased bone apposition in the loaded limb compared to the non-loaded limb at the midshaft (3 % greater cross sectional area in loaded ulna compared to non-loaded ulna). However, this increase was not determined to be statistically significant. For the two loading groups of mice that were sacrificed at 18 weeks, there was a significant difference in the amount of bone growth observed in the loaded limb compared to the non-loaded limb at the midshaft (16 % greater cross sectional area in loaded ulna compared to non-loaded ulna). Further analysis of the ÂµCT data from the mice in the 18 week old age group showed increased bone apposition distal to the midshaft of the ulna in the loaded limbs. There was also an increase in the minimum moment of inertia both distal and proximal to the midshaft. The distal increase was due to increased cross sectional area, while the proximal increase was due to a change in the geometric shape of the bone. Conclusions: Application of compressive forces to bone increases the rate of bone apposition and results in a larger cross sectional area of the bone. Depending on the bone geometry and the nature of the forces experienced by the bone, varying amounts of growth are initiated. By understanding how force impacts bone growth, exercise regimens aimed at optimizing bone apposition can be created. Future work may include analysis of the cellular signaling pathways that are activated as a result of mechanical loading and the creation of therapeutics that can modulate the response of bone to mechanical loading. Acknowledgements: Special thanks to the Van Andel Institute and specifically to Bart Williams, PhD for allowing this research to be performed in his lab. Also, thank you to the members of the Williams lab for their assistance. Thank you to Phil Boonstra, PhD from the University of Michigan Cancer Center for providing statistical consulting, advice, and analysis of the ÂµCT data. Lastly, thank you to the National Science Foundation for supporting this research through a grant under the American Recovery and Reinvestment act of 2009 presented to Dr. Samhita Rhodes and Dr. John Farris...|$|E
40|$|Restricted until 09 Nov. 2011. For {{cells to}} proliferate, the genome must be {{replicated}} exactly once per cell cycle {{in a timely}} and accurate manner. Making this task difficult are multiple other genomic processes, such as transcription and DNA repair, that are concurrently operating on the same genomic template. Replication initiates at specific loci called replication origins that must undergo a series of protein loadings before they can begin to replicate. Although this <b>loading</b> <b>schedule</b> takes place at all origins, individual origins fire at distinct and conserved times during S-phase. It {{has been suggested that}} origin firing schedules are defined by their propensity to attract rate limiting replication factors from limited pools (where origins with higher propensities replicate earlier and origins with lower propensities replicate later). This model has not been validated and, furthermore, the factors determining an origin's propensity to attract replication factors remains poorly understood. In higher eukaryotes, replication timing has been linked to epigenetic inheritance and genomic stability. Thus, determining which factors dictate origin timing schedules is important for understanding the mechanisms driving development and healthy cell proliferation.; This current work investigates the molecular kinetics that drive the S. cerevisiae replication schedule and also begins to uncover what coordination they exhibit with concurrently operating genomic processes. To understand better these timing dynamics, we begin by developing molecular and computational tools to analyze replication timing genome-wide. Using these tools we produce a novel dataset that represents the highest fidelity temporal map of DNA replication to date. Next, to identify novel candidate limiting factors to DNA replication, we describe and analyze (in the context of this temporal map) two additional datasets designed to capture both pre-S-phase replication protein loading and global origin efficiencies.; Through analysis of these data we determine that, in G 1 -phase, the earliest replicating origins show a high propensity to attract Cdc 45 (a replication factor that is limited in its nuclear concentration G 1 -phase). Following this, we devise and computationally implement a detailed theoretical model of DNA replication to test the hypothesis that origin firing dynamics (and hence genome-wide replication times) are determined by their ability to recruit replication factors from limited pools. After validating this model we identify factors that, in unperturbed cells, are correlated with origin firing dynamics. These include nucleosome positioning around the origin and the clustering of origins in the nucleus in late G 1 -phase.; Previous work has demonstrated that histone acetylation around an origin promotes its early replication. Specifically, others have shown that when the histone-deacetylase Rpd 3 is removed from the cell several origins increase in their activity. To test the scope of Rpd 3 's action at origins, we have analyzed Rpd 3 mutant cells genome-wide for their origin replication activities. We determined that approximately one-third of origins are suppressed by Rpd 3 action. By targeting the individual complexes that Rpd 3 operates in, we determined that its action at origins is through its role in transcriptional repression at the gene promoter, as opposed to its broad action as a suppressor of spurious transcription events. Furthermore, we demonstrate that the regions surrounding Rpd 3 -regulated origns are deacetylated by Rpd 3 and also that these regions are enriched for Rpd 3 binding and Rpd 3 -regulated genes.; Finally, we introduce the forkhead transcription factors Fkh 1 and Fkh 2 as two novel regulators of origin function. We demonstrate that Fkh 1 alone regulates ~ 50 origins and that in cells where both Fkh 1 and Fkh 2 action is removed, over one-half of all origins show deregulation. Furthermore, these factors are the first to be identified that have both repressive and excitatory action at origins (~ 100 origins are activated by Fkh 1 and Fkh 2 while ~ 80 are repressed; Fkh-excited and -repressed, respectively). As mentioned above, Cdc 45 association at origins in G 1 -phase is predictive of their function. We demonstrate that in fkh 1 Δfkh 2 Δ cells, this factor is depleted at Fkh-excited origins. Furthermore, we demonstrate that Fkh-excited origins are not found near the centromere, in contrast Fkh-repressed origins include many origins that localize at the centromere. Finally, we determine that Fkh 1 and Fkh 2 likely have their action at origins by regulating the formation of long-range chromatin interactions. Furthermore, we show evidence suggesting (that to regulate these interactions) individual forkhead proteins bind at different origins and then dimerize to bring these origins together in the nucleus...|$|E
40|$|As an {{alternative}} {{and renewable energy}} source, the shallow geothermal energy evolving {{as one of the}} most popular energy source due to its easy accessibility and availability worldwide, and the ground source heat pump (GSHP) systems are the most frequent applications for extracting the energy from the shallow subsurface. As the heat extraction capacity of the GSHP system applications arises, the design of the borehole heat exchangers (BHE), which is the connected part of the system in the ground, become more important. The backfilling materials of BHEs, particularly, the grout material must provide a suitable thermal contact between the ground and the heat carrier fluid in the high density polyethylene (HDPE) pipes and ensure durability to the induced thermal stresses due to the heat loading. In addition, for the heating purposes of buildings, BHEs immerged in groundwater may be operated below the freezing point of water with anti-freeze mixture in the pipe, leading to freezing-induced ice pressure which may damage the grout. In order to propose a proper grouting for BHEs, the thermo-hydro-mechanical behavior of the grout and its interferences with the adjacent ground conditions must be evaluated in the near field, and the thermal interactions of each BHE in a multi-BHEs field in the long-term operations must also be considered at a further field. Primarily, we have evaluated the performance of various grouting materials, through thermal, hydraulic and mechanical laboratory characterizations. In particular, we have proposed a homemade grout material, with the addition of graphite powder to improve the thermal properties of grout material. In parallel, the characteristics of two different widely used commercial grouting materials (i. e. calcite-based and silica-sand based materials) have been also investigated. In the subsequent study, the heat flow rate per meter of a BHE and the borehole resistance of borehole heat exchangers are assessed experimentally in a 1 × 1 × 1 m 3 sandbox under, successively, dry sand and fully water-saturated sand conditions. During the operations, the monitored temperatures in the sandbox are in good agreement with analytical predictions. This study demonstrated that the homemade admixture prepared with 5 % natural flake graphite can be considered as an appropriate grout for BHEs regarding to its rheological and thermo-physical properties. Thermally-enhanced grouting can be of significant interest in a high thermal conductivity ground (such as saturated sand) because it minimizes the thermal resistance of the BHE. After characterizing and testing the efficiency of various grout materials, the thermal stresses occurred in BHEs due to heat injection or extraction has been investigated with the analytical solution of hollow cylinder model that is adapted for time-dependent heat loading, the geometry of a BHE, and the thermo-mechanical properties of surrounding ground conditions. Firstly, the hollow cylinder model has been solved for the considered boundary conditions in 2 D plane stress. Secondly, the temperature differences at the inner and outer circles of the cylinder is evaluated with the heat line source models for continuous and discontinuous loadings to observe the impact of the heat <b>loading</b> <b>schedule.</b> The developed analytical solution for thermal stress investigation is validated with numerical models. It is demonstrated that the analytical solutions agree well with numerical results for two types of BHE configurations (co-axial and single U-shaped pipes). Furthermore, the calculated maximum stresses are compared with the tensile strength of grout materials obtained from Brazilian tests. It is predicted that thermal contraction of the grout, partially constrained by the surrounding rock, generates tensile stresses that may lead to cracking in the BHE. According to the results, the stiffness of rock has primary role on the developed tensile stresses, and the relationship between the thermal conductivity of the ground and of the grout induces a proportional impact on the magnitude of thermal stresses. Another major concern is the freeze-resistance of the grout materials, when the system is operated for heating purposes. Firstly, we conducted an experimental setup in a small-scale sandbox to understand the behavior of the grout material by evaluating the permeability change during freeze-thaw cycles of a BHE. According to the results, the permeability of grout materials did not change after 10 freeze-thaw cycles due to the thermal transfer with the adjacent soil partially reducing the impact of freezing in the grout material. Therefore, in order to test the freeze-resistance of a BHE, we have investigated the freezing impact of pore water pressure and thermal stress with analytical models and experimental setups on BHEs. For the theoretical approach, an analytical solution has been developed by using the hollow cylinder model that accounts for both the HDPE pipe and the grout material. Firstly, the freezing pore water pressure is adapted to the generalized Hooke’s law equations in 2 D plane stress, and secondly the model is solved for the considered boundary conditions. In order to validate the developed model, the experimental setup is conducted in agreement with the geometry of the considered analytical model and the BHE probes are prepared with three different grout materials having large difference in the thermal and hydraulic characteristics (i. e. silica-sand based, calcite based and the homemade enhanced thermally with natural flake graphite powder). According to the experiments for 50 h of freezing operation, the calcite based grout and the homemade grout, having lower permeability and relatively higher porosity, are fractured. In contrast, the silica-sand based grout having higher permeability did not exhibit any damage. Compared with the theoretically obtained results, the observations from the experiments are consistent with the calculated stress results. The effective tangential stress induced by the freezing pore water pressure causes the crack development and agrees with the crack patterns. As a conclusion, the porosity and the permeability play a significant role on the grout failure. In a multi-BHEs field, the thermal interaction between each BHE may have a significant influence on the near-field investigation results in long-term operations. Therefore, in order to complete the near-field investigation, a far-field long-term operation study is required. However, existing analytical solutions for thermal analysis of ground source heat pump (GSHP) systems evaluate temperature change in the carrier-fluid and the surrounding ground in the production period of a single BHE only if a continuous heat load is assigned. In this study, we modified the Green’s function, which is the solution of heat conduction/advection/dispersion equation in porous media, for discontinuous heat extraction by analytically convoluting rectangular function or pulses in time domain both for single and multi-BHEs field. The adapted analytical models for discontinuous heat extraction are verified with numerical finite element code. The comparison results agree well with numerical results both for conduction and advection dominated heat transfer systems, and analytical solutions provide significantly shorter runtime compared to numerical simulations (approx. 1500 times shorter). Furthermore, we investigated the sustainability and recovery aspects of GSHP systems by using proposed analytical models under different hydro-geological conditions. According to the engineering guideline VDI 4640, a linear relationship between thermal conductivity of the ground and the sustainable heat extraction rate is demonstrated for multi-BHEs. In addition, we developed an MATLAB interface for users in which the analytical model can be used easily and more efficiently. In addition, in order to extend the case studies for a ground including several layers, we proposed a finite line source model for BHEs that takes into account conduction/advection/dispersion mechanism in multilayer porous media. Firstly, the anisotropy is added to the moving finite line source model, and we used an existing composite model approach for conductive multilayer ground. The comparison with the numerical model results demonstrates the suitability of the approach. The proposed model can provide a faster solution than classical numerical approaches and help to optimize the heat extraction rate in multilayer media. However, further investigations are required to validate the model with the field measurements. Doctorat en Sciences de l'ingénieur et technologieinfo:eu-repo/semantics/nonPublishe...|$|E
40|$|In an {{abstract}} framework, we examine how a tradeoff between efficiency and risk arises in different dynamic oligopolistic markets. We consider a scenario {{where there is}} a reliable resource provider and agents which enter and exit the market following a random process. Self-interested and fully rational agents can both produce and consume the resource. They dynamically update their <b>load</b> <b>scheduling</b> decisions over a finite time horizon, under the constraint that the net resource consumption requirements are met before each individual's deadline. We first examine the system performance under the non-cooperative and cooperative market architectures, both under marginal production cost pricing of the resource. The statistics of the stationary aggregate demand processes induced by the two market architectures show that although the non-cooperative <b>load</b> <b>scheduling</b> scheme leads to an efficiency loss - widely known as the "price of anarchy" - the stationary distribution of the corresponding aggregate demand process has a smaller tail. This tail, which corresponds to rare and undesirable demand spikes, is important in many applications of interest. With {{a better understanding of the}} efficiency-risk tradeoff, we investigate, in a non-cooperative setup, how resource pricing can be used as a tool by the system operator to tradeoff between efficiency and risk. We further provide a convex characterization of the Pareto front of different system performance measures. The Pareto front determines the tradeoff among volatility suppression of concerned measurements in the system with <b>load</b> <b>scheduling</b> dynamics. This is the fundamental tradeoff in the sense that system performance achieved by any <b>load</b> <b>scheduling</b> strategies induced by any specific market architectures is bounded by this Pareto front. by Qingqing Huang. Thesis (S. M.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2013. Cataloged from PDF version of thesis. Includes bibliographical references (p. 87 - 90) ...|$|R
40|$|The use of {{divisible}} <b>load</b> <b>scheduling</b> {{theory is}} proposed to model and design grid {{systems such as}} those arising in large physics experiments. Current divisible load theory is summarized. A typical application, the STAR experiment at RHIC is discussed. This includes a sample calculation based on existing infrastructure numbers...|$|R
40|$|We present our own {{research}} work that uses extents of Peer-to-Peer technology with {{a framework that}} allows reliable Grid computing (P 2 P Grid) over the Internet. We propose how to decide optimized redundancy level of group peers by using system cost function and grid local reliability. Moreover we discuss an effectiveness of SLA-constrained <b>load</b> <b>scheduling</b> policy with multi-probing technology {{in order to maintain}} group more stable. Especially SLA-constrained <b>load</b> <b>scheduling</b> policy is designed for handling divisible loads and indivisible loads simultaneously and guaranteeing the shortest time of completing task. Finally through the simulation, we provide that these two proposed schemes can be evaluated to the reasonable solution to overcome unexpected system fault or down regarding system dependability issues in redundant group peers based P 2 P Grid environment...|$|R
