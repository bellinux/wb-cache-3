65|10000|Public
5|$|In {{an attempt}} to imitate the {{conventions}} of silent cinema in its infancy, the staging and acting of the film are exaggerated and artificial. The equipment used by Acevedo had limitations, causing the indoor scenes to be underexposed and the outdoor scenes to be overexposed. The Pathé camera did not allow camera movement, had imprecise definition, and dark rendering. The Kodak Ektachrome lacked a <b>large</b> <b>depth</b> <b>of</b> <b>field,</b> producing a flat image, and required good lighting to operate effectively. Overhead shots are most commonly used, with some medium shots and {{a small number of}} large shots.|$|E
25|$|Due to {{the very}} narrow {{electron}} beam, SEM micrographs have a <b>large</b> <b>depth</b> <b>of</b> <b>field</b> yielding a characteristic three-dimensional appearance useful for understanding the surface structure of a sample. This is exemplified by the micrograph of pollen shown above. A wide range of magnifications is possible, from about 10 times (about equivalent {{to that of a}} powerful hand-lens) to more than 500,000 times, about 250 times the magnification limit of the best light microscopes.|$|E
500|$|Whedon used {{a variety}} of cinematographic {{techniques}} to achieve the dreamlike quality of [...] "Restless". He used tracking shots with a Steadicam to follow the characters from place to place, creating a flow in the way of real dreams, where there are no logical connections between places and things. In Giles' dream, he walks from a carnival grounds into Spike's crypt, then through a corridor and straight into The Bronze, three locations not related to one another. Whedon was able to do this by simply having actor Anthony Stewart Head walk through the sets as they were built; this effortlessly created a sense of dreamlike dislocation. Another example of this occurs when, in Xander's dream, he walks {{from the front of the}} moving ice cream van towards the back, crawls up and over some boxes, through a window, and drops into his basement. In the theater scene during Willow's dream, a Frazier lens was used to provide a <b>large</b> <b>depth</b> <b>of</b> <b>field,</b> allowing both the foreground and background to be in focus at the same time, while in Xander's dream, as he moves from room to room in Buffy's house to the university dorm rooms, Whedon used a 17mm lens to give a sense of motion as the camera passes by walls. Whedon also used unusual framing for shots, often leaving much of the frame empty, with a character being placed near the bottom or off to the side. The scenes in Spike's crypt, part of Giles' dream, were shot in black-and-white to emphasize that Spike is seen as [...] "an old 30s movie villain".|$|E
50|$|The <b>depth</b> <b>of</b> <b>field</b> used {{to record}} the scene {{in front of the}} colored screen should match that of the background. This can mean {{recording}} the actors with a <b>larger</b> <b>depth</b> <b>of</b> <b>field</b> than normal.|$|R
5|$|Principal {{photography}} {{took place}} between April 16, 1991 and September 27, 1991, using a mix of fixed sets and on-location footage. The production suffered {{from a lack of}} available set space because of shortages; the Starfleet Headquarters set was actually built a few blocks away from Paramount Pictures at the Hollywood Presbyterian Church. Meyer copied a technique used during filming of Citizen Kane, where the filmmakers let the set fall into darkness to save money on construction. The film was shot in Super 35 instead of anamorphic format, because of the former's greater flexibility in framing and lens selection, <b>larger</b> <b>depth</b> <b>of</b> <b>field,</b> and faster lenses.|$|R
2500|$|... where [...] is {{the focal}} length, and [...] is the {{diameter}} of the entrance pupil. By convention, [...] "#" [...] is treated as a single symbol, and specific values of # are written by replacing the number sign with the value. The two ways to increase the f-stop are to either decrease {{the diameter of}} the entrance pupil or change to a longer focal length (in the case of a zoom lens, this can be done by simply adjusting the lens). Higher f-numbers also have a <b>larger</b> <b>depth</b> <b>of</b> <b>field</b> due to the lens approaching the limit of a pinhole camera which is able to focus all images perfectly, regardless of distance, but requires very long exposure times.|$|R
5000|$|... #Caption: Portrait {{taken with}} an 18mm {{wide-angle}} lens with an aperture of ƒ/4.5, resulting in fairly <b>large</b> <b>depth</b> <b>of</b> <b>field</b> ...|$|E
50|$|Optical {{sectioning}} is underdeveloped in non-light microscopes. X-ray and electron microscopes {{typically have}} a <b>large</b> <b>depth</b> <b>of</b> <b>field</b> (poor optical sectioning) and so thin sectioning of samples is still widely used.|$|E
50|$|Sometimes {{the term}} is used when the <b>large</b> <b>depth</b> <b>of</b> <b>field</b> is {{simulated}} with digital post-processing; the name may derive from a perspective control lens (or tilt-shift lens) normally required when the effect is produced optically.|$|E
5000|$|A camera's {{aperture}} {{is measured}} by a unitless number called the f-number or f-stop, #, often notated as , and given bywhere [...] is the focal length, and [...] is {{the diameter of the}} entrance pupil. By convention, [...] "#" [...] is treated as a single symbol, and specific values of # are written by replacing the number sign with the value. The two ways to increase the f-stop are to either decrease the diameter of the entrance pupil or change to a longer focal length (in the case of a zoom lens, this can be done by simply adjusting the lens). Higher f-numbers also have a <b>larger</b> <b>depth</b> <b>of</b> <b>field</b> due to the lens approaching the limit of a pinhole camera which is able to focus all images perfectly, regardless of distance, but requires very long exposure times.|$|R
40|$|Although it {{has been}} {{reported}} that <b>depth</b> <b>of</b> <b>field</b> influences <b>depth</b> perception in nonstereo photographs, it remains unclear how <b>depth</b> <b>of</b> <b>field</b> affects <b>depth</b> perception under stereo viewing conditions. We showed participants stereo photographs with different <b>depths</b> <b>of</b> <b>field</b> using a Wheatstone stereoscope and a commercially available 3 D TV. The depicted scene contained a floor, a background, and a measuring probe at different locations. Participants drew a floor plan of the depicted scene to scale. We found that perceived depth decreased with decreasing <b>depth</b> <b>of</b> <b>field</b> for shallow <b>depths</b> <b>of</b> <b>field</b> in scenes containing a heightin-the-field cue. For <b>larger</b> <b>depths</b> <b>of</b> <b>field,</b> different effects were found depending on the display system and the viewing distance. There was no effect on perceived depth using the 3 D TV, but perceived depth decreased with increasing <b>depth</b> <b>of</b> <b>field</b> using the Wheatstone stereoscope. However, in the 3 D TV case, we found that the perceived depth decreased with increasing <b>depth</b> <b>of</b> <b>field</b> in scenes in which the height-in-the-field cue was removed. This indicates that the effect <b>of</b> <b>depth</b> <b>of</b> <b>field</b> on perceived <b>depth</b> may be influenced by other depth cues in the scene, such as height-in-the-field cues...|$|R
50|$|<b>Field</b> <b>of</b> {{view and}} <b>depth</b> <b>of</b> field: <b>Depth</b> <b>of</b> <b>field</b> is {{tangentially}} {{related to the}} size of the image plane, however, it is a popular misconception that the image plane is directly related to DOF. Smaller image planes (whether film or sensor) require a proportionally smaller lens to achieve a similar <b>field</b> <b>of</b> view. This means that a frame with a 12 degree horizontal <b>field</b> <b>of</b> view will require a 50 mm lens on 16 mm film, a 100 mm lens on 35 mm film, and a 250 mm lens on 65 mm film. And a 250 mm lens delivers much shallower DOF than a 50 mm lens does. It follows that standard lenses on most consumer video cameras with small sensors provide much <b>larger</b> <b>depth</b> <b>of</b> <b>field</b> than 35 mm film. Digital cinema cameras like the Red One or Panavision Genesis, as well as some digital SLR cameras with video capabilities, (such as the Canon EOS 5D Mark II), have sensors roughly equal in size to 35 mm film frames and thus show the same <b>field</b> <b>of</b> view characteristics.|$|R
50|$|The refocus feature {{differs from}} a plenoptic camera in that RealSense Snapshot takes {{pictures}} with <b>large</b> <b>depth</b> <b>of</b> <b>field</b> so that initially {{the whole picture}} is in focus and then in software it selectively blurs parts of the image depending on their distance.|$|E
5000|$|Deep {{focus is}} a {{photographic}} and cinematographic technique using a <b>large</b> <b>depth</b> <b>of</b> <b>field.</b> Depth of field is the front-to-back range of focus in an image — that is, {{how much of}} it appears sharp and clear. In deep focus the foreground, middle-ground and background are all in focus.|$|E
5000|$|Cameras with a bellows {{typically}} support 'tilt and shift' of the lens. Together with 1:1 focusing (via {{a ground}} glass screen mounted at the rear in the film plane position), this permits landscape photography with an extremely <b>large</b> <b>depth</b> <b>of</b> <b>field</b> [...] - [...] from closest foreground to the far horizon [...] - [...] to be achieved.|$|E
40|$|AbstractElectron {{tomography}} is {{an invaluable}} method for 3 D cellular imaging. The technique is, however, {{limited by the}} specimen geometry, {{with a loss of}} resolution due to a restricted tilt range, an increase in specimen thickness with tilt, and a resultant need for subjective and time-consuming manual segmentation. Here we show that 3 D reconstructions of needle-shaped biological samples exhibit isotropic resolution, facilitating improved automated segmentation and feature detection. By using scanning transmission electron tomography, with small probe convergence angles, high spatial resolution is maintained over <b>large</b> <b>depths</b> <b>of</b> <b>field</b> and across the tilt range. Moreover, the application of compressed sensing methods to the needle data demonstrates how high fidelity reconstructions may be achieved with far fewer images (and thus greatly reduced dose) than needed by conventional methods. These findings open the door to high fidelity electron tomography over critically relevant length-scales, filling an important gap between existing 3 D cellular imaging techniques...|$|R
50|$|Atomic {{resolution}} scanning transmission {{electron microscopy}} encounters similar difficulties, where specimen features are much <b>larger</b> than the <b>depth</b> <b>of</b> <b>field.</b> By taking a through-focal series, the <b>depth</b> <b>of</b> focus can be reconstructed to create a single image entirely in focus.|$|R
40|$|The {{atomization}} of an unsteady turbulent {{sheet of}} water in air is analyzed using a combination <b>of</b> light <b>field</b> imaging (LFI) and synthetic aperture (SA) refocusing techniques. This sheet collides with and initially flows along a solid inclined plate, and imaging is performed in the region where breakup and separation from the plate begin. Ligaments and droplets emanate from the sheet and break off due to capillary instabilities. Image volumes consisting of these flow features, as well as segments of the liquid sheet body, are captured using a multiple CCD sensor array consisting of ten cameras arranged in three rows. Synthetic aperture refocusing techniques are applied to the raw camera array images, each with <b>large</b> <b>depths</b> <b>of</b> <b>field,</b> to obtain a stack of post-processed images, with narrow <b>depth</b> <b>of</b> <b>field,</b> where each image in the stack is located on a specific focal plane. Simulations using a dark field imaging {{modified version of the}} aforementioned SA method with nine cameras show {{that it is possible to}} extract the center coordinates in three dimensions (3 D) and radii of spheres found in a scene being imaged. It is also demonstrated that for two camera arrays with the same number of cameras, a circular array with the same radius as the horizontal and vertical distance between cameras in the square array will result in a more accurate reconstruction...|$|R
50|$|The astronauts {{were well}} trained in {{photography}} before the mission. Because {{there was no}} weather to contend with and the bright sunlight allowed the use of small apertures, with consequent <b>large</b> <b>depth</b> <b>of</b> <b>field,</b> the equipment generally was kept at a single setting throughout the mission. All that was needed {{to take a picture}} was to open the shutter. Film winding was automatic.|$|E
50|$|Scanning {{electron}} microscopy (SEM) is method of photography which requires an instrument called the scanning electron microscope, which uses electrons rather than light {{to form an}} image. There are many advantages to using the SEM instead of a light microscope. Using SEM requires a <b>large</b> <b>depth</b> <b>of</b> <b>field,</b> which allows {{a large amount of}} the sample to be in focus at one time.|$|E
50|$|Due to {{the very}} narrow {{electron}} beam, SEM micrographs have a <b>large</b> <b>depth</b> <b>of</b> <b>field</b> yielding a characteristic three-dimensional appearance useful for understanding the surface structure of a sample. This is exemplified by the micrograph of pollen shown above. A wide range of magnifications is possible, from about 10 times (about equivalent {{to that of a}} powerful hand-lens) to more than 500,000 times, about 250 times the magnification limit of the best light microscopes.|$|E
40|$|Quantitative phase imaging {{has many}} {{applications}} for label-free {{studies of the}} nanoscale structure and dynamics of cells and tissues. It has been demonstrated that optical coherence phase microscopy (OCPM) can provide quantitative phase information with very high sensitivity. The excellent phase stability of OCPM is obtained by use of a reflection from the microscope cover glass as a local reference field. For detailed intracellular studies a large numerical aperture (N. A.) objective is {{needed in order to}} obtain the required resolution. Unfortunately, this also means that the <b>depth</b> <b>of</b> <b>field</b> becomes too small to obtain sufficient power from the cover glass when the beam is focused into the sample. To address this issue, we designed a setup with a dual-beam sample arm. One beam with a large diameter (filling the 1. 2 N. A. water immersion objective) enabled high-resolution imaging. A second beam with a small diameter (underfilling the same objective) had a <b>larger</b> <b>depth</b> <b>of</b> <b>field</b> and could detect the cover glass used as a local phase reference. The phase stability of the setup was quantified by monitoring the front and back of a cover glass. The standard deviation of the phase difference was 0. 021 rad, corresponding to an optical path displacement of 0. 9 nm. The lateral and axial dimensions of the confocal point spread function were 0. 42 and 0. 84 μm, respectively. This makes our dual-beam setup ideal for three-dimensional intracellular phase imaging. © 2013 Optical Society of America...|$|R
40|$|Bessel and conical {{beams and}} {{approximation}} with annular arrays Abstract — The Bessel beam {{is one of}} the relatively new limiteddiffraction beams that have been discovered. It is compared with the conical transducer which also gives an approximate limited-diffraction solution to the wave equation. It is shown that the conical transducer’s field deviates from the predicted field in the nearfield, where it is wider. Therefore the Bessel beam is better for use in a hybrid system where a limited-diffraction beam is used for transmission and a dynamically focused beam for reception. It is also shown that the limited-diffraction Bessel beam of order zero can be excited on an annular transducer with equal-area division of elements and with a fixed prefocus, i. e. conventional transducers used in commercial medical imaging equipment. The element division implies that the scaling parameter must be chosen to contain the first lobe of the Bessel function in the first element. In addition, the prefocus must be such that the array is steerable to infinite depth with minor loss. Even when the Bessel beam yields a <b>larger</b> <b>depth</b> <b>of</b> <b>field</b> than that <b>of</b> an unfocused transducer, we show that it has the advantage of a narrower beam. Simulated examples are shown where the approximate Bessel beam compares favorably with a spherically focused beam with a fixed focus, an unfocused beam, and a conical transducer. I...|$|R
25|$|The hyperfocal {{distance}} is the nearest focus distance {{at which the}} DOF extends to infinity; focusing the camera at the {{hyperfocal distance}} results in the <b>largest</b> possible <b>depth</b> <b>of</b> <b>field</b> for a given f-number (Ray 2000, 55). Focusing beyond the hyperfocal distance does not increase the far DOF (which already extends to infinity), but it does decrease the DOF {{in front of the}} subject, decreasing the total DOF. Some photographers consider this wasting DOF; however, see Object field methods above for a rationale for doing so. Focusing on the hyperfocal distance is a special case of zone focusing in which the far limit of DOF is at infinity.|$|R
50|$|Subminiature {{cameras are}} less suited to macro {{photography}} than larger cameras, although the relatively <b>large</b> <b>depth</b> <b>of</b> <b>field</b> at close distances is an advantage. Where concealment is required, subminiature cameras are required; they (particularly the various Minox models) {{are well known}} as spy cameras, where {{they were used to}} photograph documents close up. Minox cameras for these purposes come with a 24-inch measuring chain attached, with markings corresponding to certain distances, to assist in focusing at these short ranges.|$|E
5000|$|Images can be {{recorded}} and stored {{similar to a}} webcam on the computer. The camera is usually fitted with a light source, although extra sources (such as a fiber-optic light) {{can be used to}} highlight features of interest in the object. They generally offer a <b>large</b> <b>depth</b> <b>of</b> <b>field</b> and a range of magnification when examining the image file on the computer. The camera is so sensitive that it will generally work without the need for any extra light source.|$|E
50|$|In {{an attempt}} to imitate the {{conventions}} of silent cinema in its infancy, the staging and acting of the film are exaggerated and artificial. The equipment used by Acevedo had limitations, causing the indoor scenes to be underexposed and the outdoor scenes to be overexposed. The Pathé camera did not allow camera movement, had imprecise definition, and dark rendering. The Kodak Ektachrome lacked a <b>large</b> <b>depth</b> <b>of</b> <b>field,</b> producing a flat image, and required good lighting to operate effectively. Overhead shots are most commonly used, with some medium shots and {{a small number of}} large shots.|$|E
40|$|Abstract—The term periocular {{refers to}} the facial region in the {{immediate}} vicinity of the eye. Acquisition of the periocular biometric is expected to require less subject cooperation while permitting a <b>larger</b> <b>depth</b> <b>of</b> <b>field</b> compared to traditional ocular biometric traits (viz., iris, retina, and sclera). In this work, we study the feasibility of using the periocular region as a biometric trait. Global and local information are extracted from the periocular region using texture and point operators resulting in a feature set for representing and matching this region. A number of aspects are studied in this work, including the 1) effectiveness of incorporating the eyebrows, 2) use of side information (left or right) in matching, 3) manual versus automatic segmentation schemes, 4) local versus global feature extraction schemes, 5) fusion of face and periocular biometrics, 6) use of the periocular biometric in partially occluded face images, 7) effect of disguising the eyebrows, 8) effect of pose variation and occlusion, 9) effect of masking the iris and eye region, and 10) effect of template aging on matching performance. Experimental results show a rank-one recognition accuracy of 87. 32 % using 1136 probe and 1136 gallery periocular images taken from 568 different subjects (2 images/subject) in the Face Recognition Grand Challenge (version 2. 0) database with the fusion of three different matchers. Index Terms—Biometrics, face, fusion, gradient orientation histogram, local binary patterns, periocular recognition, scale invariant feature transform. I...|$|R
40|$|International audienceIncreasing {{the capture}} volume of visible cameras while {{maintaining}} high image resolutions, {{low power consumption}} and standard video-frame rate operation is of utmost importance for hand-free night vision goggles or embedded surveillance systems. Since such imaging systems require to operate at high aperture, their optical design has become more complex and critical. Therefore new design alternatives have to be considered. Among them, wavefront coding changes and desensitizes the modulation transfer function (MTF) of the lens by inserting a phase mask {{in the vicinity of}} the aperture stop. This smart filter is combined with an efficient image processing that ensures optimal image quality over a <b>larger</b> <b>depth</b> <b>of</b> <b>field.</b> In this paper recent advances are discussed concerning design and integration of a compact imaging system based on wavefront coding. We address the design, the integration and the characterization of a High Definition (HD) camera of large aperture (F/ 1. 2) operating in the visible and near infrared spectral ranges, endowed with wavefront coding. Two types of phase masks (pyramidal and polynomial) have been jointly optimized with their deconvolution algorithm in order to meet the best performance along an increased range of focus distances and manufactured. Real time deconvolution processing is implemented on a Field Programmable Gate Array. It is shown that despite the high data throughput of an HD imaging chain, the level of power consumption is far below the initial specifications. We have characterized the performances with and without wavefront coding through MTF measurements and image quality assessments. A depth-of- field increase up to x 2. 5 has been demonstrated in accordance with the theoretical predictions...|$|R
40|$|The {{invention}} {{relates to}} a projection display {{equipped with an}} image generator (30), {{which is designed to}} generate individual pictures in a distribution of sub-areas (33 - 1 to 33 - 7) of an image generation plane of the image generator (30). The projection display also comprises a multi-channel optical system (40), which is configured to image one associated sub-area (33 - 1 to 33 - 7) of the image generator (30) per channel (44 - 1 to 44 - 7) {{in such a way that}} the images of the individual pictures on a projection surface are joined to form a whole picture (5). At least some channels of the multi-channel optical system (40) are arranged along at least one curve, which is similar to at least one elongated picture feature of the whole picture (5), so that a two-dimensional anisotropic blurring behavior of each pixel is achieved. In this way, a <b>large</b> range <b>of</b> <b>depth</b> <b>of</b> <b>field</b> can be combined with relatively high projection brightness without having to accept losses regarding the focused display of picture features that should be projected with sufficient sharpness...|$|R
50|$|Webcams {{typically}} {{include a}} lens, an image sensor, support electronics, {{and may also}} include a microphone for sound. Various lenses are available, the most common in consumer-grade webcams being a plastic lens that can be screwed in and out to focus the camera. Fixed-focus lenses, which have no provision for adjustment, are also available. As a camera system's depth of field is greater for small image formats and is greater for lenses with a large f-number (small aperture), the systems used in webcams have a sufficiently <b>large</b> <b>depth</b> <b>of</b> <b>field</b> {{that the use of}} a fixed-focus lens does not impact image sharpness to a great extent.|$|E
50|$|As an image's {{depth of}} field is {{inversely}} proportional {{to the size of}} the lens's aperture, aperture priority mode is often used to allow the photographer to control the focus of objects in the frame. Aperture priority is therefore useful in landscape photography, for example, where it may be desired that objects in foreground, middle distance, and background all be rendered crisply, while shutter speed is immaterial. To obtain this <b>large</b> <b>depth</b> <b>of</b> <b>field,</b> a narrow aperture (identified by a high f-number, e.g. f/16 or f/22) is necessary. Aperture priority mode also finds use in portrait photography, where a wide aperture (identified by a low number, e.g. f/1.4 or f/2.8) and therefore smaller {{depth of field}} may be desired to throw the background out of focus and make it less distracting.|$|E
50|$|In {{terms of}} imaging, SHIM has several {{advantages}} over the traditional {{scanning electron microscope}} (SEM). Owing to the very high source brightness, and the short De Broglie wavelength of the helium ions, which is inversely proportional to their momentum, {{it is possible to}} obtain qualitative data not achievable with conventional microscopes which use photons or electrons as the emitting source. As the helium ion beam interacts with the sample, it does not suffer from a large excitation volume, and hence provides sharp images with a <b>large</b> <b>depth</b> <b>of</b> <b>field</b> {{on a wide range of}} materials. Compared to an SEM, the secondary electron yield is quite high, allowing for imaging with currents as low as 1 femtoamp. The detectors provide information-rich images which offer topographic, material, crystallographic, and electrical properties of the sample. In contrast to other ion beams, there is no discernible sample damage due to relatively light mass of the helium ion. The drawback is the cost.|$|E
5000|$|Focal {{length and}} {{diaphragm}} aperture affect the <b>depth</b> <b>of</b> <b>field</b> <b>of</b> a scene - that is, {{how much the}} background, mid-ground and foreground will be rendered in [...] "acceptable focus" [...] (only one exact plane of the image is in precise focus) on the film or video target. <b>Depth</b> <b>of</b> <b>field</b> (not {{to be confused with}} <b>depth</b> <b>of</b> focus) is determined by the aperture size and the focal distance. A <b>large</b> or deep <b>depth</b> <b>of</b> <b>field</b> is generated with a very small iris aperture and focusing on a point in the distance, whereas a shallow <b>depth</b> <b>of</b> <b>field</b> will be achieved with a large (open) iris aperture and focusing closer to the lens. <b>Depth</b> <b>of</b> <b>field</b> is also governed by the format size. If one considers the <b>field</b> <b>of</b> view and angle of view, the smaller the image is, the shorter the focal length should be, as to keep the same <b>field</b> <b>of</b> view. Then, the smaller the image is, the more <b>depth</b> <b>of</b> <b>field</b> is obtained, for the same <b>field</b> <b>of</b> view. Therefore, 70mm has less <b>depth</b> <b>of</b> <b>field</b> than 35mm for a given <b>field</b> <b>of</b> view, 16mm more than 35mm, and video cameras even more <b>depth</b> <b>of</b> <b>field</b> than 16mm. As videographers try to emulate the look of 35 mm film with digital cameras, this is one issue of frustration - excessive <b>depth</b> <b>of</b> <b>field</b> with digital cameras and using additional optical devices to reduce that <b>depth</b> <b>of</b> <b>field.</b>|$|R
40|$|This thesis {{focuses on}} the proof-of concept {{demonstration}} of smart optical imaging systems. Two systems have been investigated: first, a three-channel multi-resolution imaging system and in second place, a refocusing imaging system. The three-channel multi-resolution optical imaging system (Static System) has already been investigated by Ir. Gebirie. Y. Belay. The system possesses three optical channels with different resolutions and <b>fields</b> <b>of</b> view. The first channel has the highest resolution and the lowest <b>field</b> <b>of</b> view; the third optical channel has contrary properties, that is, the widest <b>field</b> <b>of</b> view and the lowest resolution. The second optical channel has intermediate properties. The experiments accomplished show that the system performs according to the expectations (simulations) {{and the quality of}} the images captured by the system is good. It has been observed two phenomena: distortion in the second optical channel and crosstalk in the third optical channel. The influence of misalignment errors of the components has been analyzed as well. The system is robust to longitudinal movements of the components, especially the first optical channel. Nevertheless, the system is less sensitive to rotational movements, becoming important the achievement of a good angular alignment. The refocusing system is a voltage-tunable refocusing optical imaging system. The voltage applied to an electrically tunable liquid lens allows obtaining a sharp image for a large range of object positions. This fact is an added value with respect to the Static System, where the object distances range is limited. The refocusing optical imaging system (Dynamic System) was designed by Lien Smeesters (et al.) and consists of two optical channels. The first channel is the third optical channel of the Static System and the second channel is the refocusing channel. This channel is compound of two passive lenses and the voltage-tunable liquid lens (Varioptic Arctic 320) in-between the two passive lenses. Each passive lens is composed of two aspheric surfaces (concave and convex). The lenses have been fabricated in PMMA by ultraprecision diamond tooling and they have been characterized (surface profile) by means of a measurement coordinate machine (Werth UA 400). After the characterization of the lenses, a setup of the channel with refocusing capability has been built up. In this setup it has been necessary to modify the distance between the tunable lens and the second passive lens, and between the second lens and the image sensor (uEye CMOS camera detector) with regards to the design specifications. Indeed, the fabricated lenses are not identical to the designed lens surfaces; there is one surface that has not been fabricated with the parameters of the design. The mounted refocusing channel performs well and the quality (contrast and ability to resolve fine details) of the captured images is high. In the experiments realized the working distances (object position) go from 0. 15 m to 3 m, which is similar to the distance span obtained in the simulations for almost all the voltage values considered (from 51. 1 Vrms to 60. The <b>depth</b> <b>of</b> <b>field</b> and <b>depth</b> <b>of</b> focus for different object distances and detector distances has been measured founding that the <b>largest</b> <b>depth</b> <b>of</b> <b>field</b> are obtained for low voltage values. In the experiments has been also observed that the tunable lens behaves hysterically (the optimal distance position where the image is sharp varies depending on the turning direction of the voltage, i. e., from higher to lower voltages values or viceversa. Ingeniería de TelecomunicaciónTelekomunikazio Ingeniaritz...|$|R
40|$|An {{instrument}} that functions mainly as a particle-image velocimeter provides {{data on the}} sizes and velocities of flying opaque particles. The instrument is being developed {{as a means of}} characterizing fluxes of wind-borne dust particles in the Martian atmosphere. The instrument could also adapted to terrestrial use in measuring sizes and velocities of opaque particles carried by natural winds and industrial gases. Examples of potential terrestrial applications include monitoring of airborne industrial pollutants and airborne particles in mine shafts. The design of this instrument reflects an observation, made in field research, that airborne dust particles derived from soil and rock are opaque enough to be observable by use <b>of</b> bright <b>field</b> illumination with high contrast for highly accurate measurements of sizes and shapes. The instrument includes a source of collimated light coupled to an afocal beam expander and an imaging array of photodetectors. When dust particles travel through the collimated beam, they cast shadows. The shadows are magnified by the beam expander and relayed to the array of photodetectors. Inasmuch as the images captured by the array are of dust-particle shadows rather of the particles themselves, the <b>depth</b> <b>of</b> <b>field</b> <b>of</b> the instrument can be large: the instrument has a <b>depth</b> <b>of</b> <b>field</b> <b>of</b> about 11 mm, which is <b>larger</b> than the <b>depths</b> <b>of</b> <b>field</b> <b>of</b> prior particle-image velocimeters. The instrument can resolve, and measure the sizes and velocities of, particles having sizes in the approximate range of 1 to 300 m. For slowly moving particles, data from two image frames are used to calculate velocities. For rapidly moving particles, image smear lengths from a single frame are used in conjunction with particle- size measurement data to determine velocities...|$|R
