289|41|Public
25|$|Besides JSL {{there are}} also Pidgin Signed Japanese and Signed Japanese. Both of these are signed forms of the Japanese language. The first is used between {{non-native}} signers, and the latter is sometimes used in schools for the deaf. However, up to 2002, most Japanese schools for the deaf emphasized oral education, i.e. teaching through <b>lip-reading.</b> Even now, at least officially, JSL is not taught. It has been only a decade since the official school ban {{on the use of}} JSL was lifted.|$|E
500|$|... (Parentheses) {{are used}} for indistinguishable utterances. They are also seen for silent {{articulation}} (mouthing), where the expected phonetic transcription is derived from <b>lip-reading,</b> and with periods to indicate silent pauses, for example (...).|$|E
2500|$|The {{premise of}} the series centres on a Royal Canadian Mounted Police (RCMP) constable named Benton Fraser (Paul Gross) who travels to Chicago to solve {{the murder of his}} father; this is how he meets his soon-to-be partner, Ray Vecchio (David Marciano), a tough, streetwise cop. Accompanied by his deaf <b>lip-reading</b> half-wolf Diefenbaker (whom Fraser adopted after Diefenbaker saved his life), the {{investigation}} leads Fraser to uncover a plot by a company building a dam that is slowly killing the environment. This leads to the dam being shut down and many people losing their jobs. He also implicates corrupt members of the RCMP in the affair. This along with the loss of so many peoples' jobs makes him persona non grata in Canada, and he finds himself stationed in Chicago. This plot line is referred to repeatedly during the series, and from season three on he introduces himself to many by saying: ...|$|E
5000|$|Visemes {{can often}} be humorous, as in the phrase [...] "elephant juice," [...] which when <b>lip-read</b> appears {{identical}} to [...] "I love you." ...|$|R
5000|$|Stefan Wong as Sau Fung (收峰; [...] "Get Wind") / Ng Sai-fung (吳世峰; Ng Saifung): the team's greaseman, {{in charge}} of {{collecting}} intel. He can <b>lip-read</b> and also works as a bartender.|$|R
40|$|<b>Lip-read</b> {{speech is}} {{integrated}} with heard speech at various neural levels. Here, we investigated {{the extent to}} which <b>lip-read</b> induced modulations of the auditory N 1 and P 2 (measured with EEG) are indicative of speech-specific audiovisual integration, and we explored to what extent the ERPs were modulated by phonetic audiovisual congruency. In order to disentangle speech-specific (phonetic) integration from non-speech integration, we used Sine-Wave Speech (SWS) that was perceived as speech by half of the participants (they were in speech-mode), while the other half was in non-speech mode. Results showed that the N 1 obtained with audiovisual stimuli peaked earlier than the N 1 evoked by auditory-only stimuli. This <b>lip-read</b> induced speeding up of the N 1 occurred for listeners in speech and non-speech mode. In contrast, if listeners were in speech-mode, <b>lip-read</b> speech also modulated the auditory P 2, but not if listeners were in non-speech mode, thus revealing speech-specific audiovisual binding. Comparing ERPs for phonetically congruent audiovisual stimuli with ERPs for incongruent stimuli revealed an effect of phonetic stimulus congruency that started at ~ 200 ms after (in) congruence became apparent. Critically, akin to the P 2 suppression, congruency effects were only observed if listeners were in speech mode, and not if they were in non-speech mode. Using identical stimuli, we thus confirm that audiovisual binding involves (partially) different neural mechanisms for sound processing in speech and non-speech mode. Keywords: N 1, P 2, Audiovisual speech, Sine-wave speech, Audiovisual integratio...|$|R
6000|$|... "A little, that is--not much, {{but enough}} to get along with. But she don't like talking somehow--dunno why. She's shy--and we think maybe she don't like to talk much because she can't hear her own voice. She don't ever speak except just when she has to. But she's been trained to <b>lip-reading</b> {{something}} wonderful--she can understand anything that's said when she can see the person that's talking. Still, it's a terrible drawback for the poor child--she's never had any real girl-life and she's dreadful sensitive and retiring. We can't get her to go out anywhere, only for lonely walks along shore by herself. We're much obliged {{for what you did}} the other night. It ain't safe for her to wander about alone as she does, but it ain't often anybody from the harbour gets up this far. She was dreadful upset about it--hasn't got over her scare yet." ...|$|E
50|$|Studies with pre-lingual {{infants and}} {{children}} use indirect, non-verbal measures to indicate sensitivity to seen speech. Explicit <b>lip-reading</b> can be reliably tested in hearing preschoolers by asking them to 'say aloud what I say silently'. In school-age children, lipreading of familiar closed-set words such as number words can be readily elicited. Individual differences in <b>lip-reading</b> skill, as tested by asking the child to 'speak the word that you lip-read', or by matching a lip-read utterance to a picture, show a relationship between <b>lip-reading</b> skill and age.|$|E
5000|$|... c) That {{speech and}} <b>lip-reading</b> {{so far from}} being lost, are {{developed}} by practice.|$|E
5000|$|... #Caption: Censor boxes, {{such as the}} one above, may be used {{along with}} the bleeps so that the {{audience}} would not <b>lip-read</b> the swearer's words. Above, the cartoon says [...] "Oh-", followed by the censor.|$|R
40|$|Individuals with {{developmental}} dyslexia (DD) may experience, besides reading problems, other speech-related processing deficits. Here, {{we examined the}} influence of visual articulatory information (<b>lip-read</b> speech) at various levels of background noise on auditory word recognition in children and adults with DD. We found that children with a documented history of DD have deficits {{in their ability to}} gain benefit from <b>lip-read</b> information that disambiguates noise-masked speech. We show with another group of adult individuals with DD that these deficits persist into adulthood. These deficits could not be attributed to impairments in unisensory auditory word recognition. Rather, the results indicate a specific deficit in audio-visual speech processing and suggest that impaired multisensory integration might be an important aspect of DD...|$|R
5000|$|When George {{finds out}} that Kramer knows sign {{language}} and Jerry's girlfriend Laura can <b>lip-read,</b> he asks them to come with him to a party that he knows Gwen will attend, so they can try to interpret her conversations and find out the real reason she dumped George.|$|R
5000|$|Nick DeNitto {{remarked that}} [...] "Laura's <b>lip-reading</b> isn't perfect, {{which leads to}} some funny moments of miscommunication." ...|$|E
5000|$|Hard {{of hearing}} {{people to call}} each other {{directly}} with voice and text and even video for <b>lip-reading.</b>|$|E
50|$|As hearing {{becomes less}} {{reliable}} in old-age people {{may tend to}} rely more on <b>lip-reading,</b> and are encouraged to do so. However, greater reliance on <b>lip-reading</b> may not always make good the effects of age-related hearing loss. Cognitive decline in aging may be preceded by and/or associated with measurable hearing loss. Thus lipreading {{may not always be}} able to fully compensate for the combined hearing and cognitive age-related decrements.|$|E
50|$|As a {{child he}} lost his hearing due to disease, thus finding it {{necessary}} to <b>lip-read</b> from an early age. He learned natural sciences through private lessons. After receiving vocational training as a bookbinder, he studied geology from 1884 under Karl von Fritsch (1838-1906) at the University of Halle. At Halle he also received training as a curator.|$|R
40|$|The {{correspondence}} between auditory speech and <b>lip-read</b> {{information can be}} detected based {{on a combination of}} temporal and phonetic cross-modal cues. Here, we determined the point in developmental time at which children start to effectively use phonetic information to match a speech sound with one of two articulating faces. We presented 4 - to 11 -year-olds (N = 77) with three-syllabic sine-wave speech replicas of two pseudo-words that were perceived as non-speech and asked them to match the sounds with the corresponding <b>lip-read</b> video. At first, children had no phonetic knowledge about the sounds, and matching was thus based on the temporal cues that are fully retained in sine-wave speech. Next, we trained all children to perceive the phonetic identity of the sine-wave speech and repeated the audiovisual (AV) matching task. Only at around 6. 5 years of age did the benefit of having phonetic knowledge about the stimuli become apparent, thereby indicating that AV matching based on phonetic cues presumably develops more slowly than AV matching based on temporal cues. Keywords: Audiovisual speech, Cross-modal correspondence, Phonetic cues, Temporal cues, Sine-wave speech, Developmen...|$|R
50|$|Mabel was the {{inspiration}} for her father's involvement in {{the founding of the}} first oral school for the deaf in the United States, the Clarke School for the Deaf. Having been educated in both the United States and in Europe, she learned to both talk and <b>lip-read</b> with great skill in multiple languages. She was also, due in great part to her parents' efforts, one of the first deaf children in the nation to be taught to both <b>lip-read</b> and speak, which allowed her to integrate herself easily and almost completely within the hearing world, an event virtually unknown to those in the deaf community of that era. In support of her parents' efforts to increase funding for deaf education, Mabel testified before a congressional hearing at a young age. Her avoidance of the deaf community until her middle age when her parents died and left her to assume their roles as benefactor to the societies for the deaf, would later lead to criticisms that she was embarrassed by her impairment.|$|R
50|$|Penelope (Beatriz Batarda) is {{the deaf}} <b>lip-reading</b> {{instructor}} who gives Frankie the tough love {{he never had}} and always needed.|$|E
5000|$|... 1778: Samuel Heinicke of Leipzig Germany, {{promoted}} Oralism, {{a method}} of teaching deaf children spoken and written language through speech and <b>lip-reading</b> exclusively without use of sign language.|$|E
50|$|While <b>lip-reading</b> silent speech poses a {{challenge}} for most hearing people, adding sight of the speaker to heard speech improves speech processing under many conditions. The mechanisms for this, and the precise ways in which <b>lip-reading</b> helps, are topics of current research.Seeing the speaker helps {{at all levels of}} speech processing from phonetic feature discrimination to interpretation of pragmatic utterances.The positive effects of adding vision to heard speech are greater in noisy than quiet environments,where by making speech perception easier, seeing the speaker can free up cognitive resources, enabling deeper processing of speech content.|$|E
50|$|Allyson {{was born}} on Yorke Peninsula in country South Australia, the {{daughter}} of Woolford Parsons and Marie Parsons, a former art teacher. She was born profoundly deaf, and her parents were {{faced with the prospect}} of moving from the farm which they had worked hard to establish in degraded, salt-affected soil. But she had learned to <b>lip-read</b> and with patience and hard work and help from the local school learned to speak clearly.|$|R
5000|$|Clarke Schools for Hearing and Speech, {{formerly}} Clarke School for the Deaf, {{operates a}} satellite school, [...] "Clarke Boston", in Canton {{for children who}} are diagnosed with deafness at an early age and then are mainstreamed to a public school. Clarke is the oldest school for the deaf in the country that teaches children to <b>lip-read</b> and speak orally, rather than use sign language; its main campus is located 80 miles to the west in Northampton, Massachusetts.|$|R
50|$|By {{this time}} Sykes had {{developed}} hearing problems; he subsequently {{lost most of}} his hearing, but learned to <b>lip-read</b> and watch other performers say their lines to get his cues. In 1957 he wrote and appeared in an edition of Val Parnell's Saturday Spectacular, {{the first of two}} shows in this series that he wrote for Peter Sellers. The first went out under the title of Eric Sykes Presents Peter Sellers, and the second, in 1958, was called The Peter Sellers Show.|$|R
5000|$|... (Parentheses) {{are used}} for indistinguishable utterances. They are also seen for silent {{articulation}} (mouthing), where the expected phonetic transcription is derived from <b>lip-reading,</b> and with periods to indicate silent pauses, for example (...).|$|E
50|$|Sue Thomas (born May 24, 1950) is an American {{woman who}} became the first deaf person to work as an {{undercover}} specialist doing <b>lip-reading</b> of suspects for the Federal Bureau of Investigation.|$|E
50|$|In the United States, adult aural rehab {{started as}} a result of the number of {{soldiers}} who incurred hearing loss in World War II and were in need of services. Back then, audiologists and speech-language pathologists would put emphasis on speech reading (<b>lip-reading)</b> auditory training, and would fit the soldiers with very primitive hearing aids. In the past, the main components of the rehab process were training clients in <b>lip-reading</b> techniques and listening exercises. Today, the list includes a thorough hearing evaluation, intervention with hearing instruments, and counseling for the client before and after the hearing device is selected.|$|E
50|$|Manchester United F.C. signed Patrice Evra in January 2006 {{for a fee}} of £5.5m. In March 2006, it was {{reported}} that Liverpool defender Steve Finnan had racially abused Evra in the match that had taken place between the two clubs on January 22. The abuse claims surfaced from two deaf television viewers lodging a police complaint. The viewers claimed to have <b>lip-read</b> Finnan abusing Evra during the televised match. Finnan denied the charge and, after an investigation, The Football Association (FA) decided against charging the player.|$|R
40|$|Early-onset hearing {{impairment}} {{is a common}} dis-ability in the United States. Persons with hearing loss, whether they use American Sign Language or <b>lip-read,</b> must look at those with whom they are speaking. Lip reading is not a reliable method of communication for most deaf persons. Reading and writing also {{limit the amount of}} communication between health care provid-ers and deaf patients. The best way to communicate with most deaf persons is through a qualified American Sign Language interpreter. This paper discusses com-munication with deaf persons and ways in which health care providers and hospitals can improve their interac-tions with deaf patients...|$|R
40|$|<b>Lip-read</b> speech {{suppresses}} and {{speeds up}} the auditory N 1 and P 2 peaks, but these effects {{are not always}} observed or reported. Here, the robustness of lip-read-induced N 1 /P 2 suppression and facilitation in phonetically congruent audiovisual speech was assessed by analyzing peak values that were taken from published plots and individual data. To determine whether adhering to the additive model of AV integration (i. e., A+V[*]≠[*]AV, or AV−V[*]≠[*]A) is critical for correct characterization of lip-read-induced effects on the N 1 and P 2, auditory data was compared to AV and to AV−V. On average, the N 1 and P 2 were consistently suppressed and sped up by <b>lip-read</b> information, with no indication that AV integration effects were significantly modulated by whether or not V was subtracted from AV. To assess the possibility that variability in observed N 1 /P 2 amplitudes and latencies may explain why N 1 /P 2 suppression and facilitation are not always found, additional correlations between peak values {{and size of the}} AV integration effects were computed. These analyses showed that N 1 /P 2 peak values correlated with the size of AV integration effects. However, it also became apparent that a portion of the AV integration effects was characterized by lip-read-induced peak enhancements and delays rather than suppressions and facilitations, which, for the individual data, seemed related to particularly small/early A-only peaks and large/late AV(−V) peaks...|$|R
5000|$|... 2. The Convention, {{considering}} that the simultaneous use of articulation and signs has the disadvantage of injuring articulation and <b>lip-reading</b> and the precision of ideas, declares that the pure oral method should be preferred.|$|E
50|$|Many factors {{affect the}} {{visibility}} of a speaking face, including illumination, movement of the head/camera, frame-rate of the moving image and distance from the viewer (see e.g.). Head movement that accompanies normal speech can also improve <b>lip-reading,</b> independently of oral actions. However, when <b>lip-reading</b> connected speech, the viewer's knowledge of the spoken language, familiarity with the speaker and style of speech, and {{the context of the}} lip-read material are as important as {{the visibility of}} the speaker. While most hearing people are sensitive to seen speech, there is great variability in individual speechreading skill. Good lipreaders are often more accurate than poor lipreaders at identifying phonemes from visual speech.|$|E
50|$|Omnilingualism: Mgann can speak, write, {{understand}} and communicate in any language, including computer codes, languages {{they have never}} been heard before, sign language (even <b>lip-reading),</b> illegible words, and backwards speech and writing with little or no training.|$|E
40|$|Two {{experiments}} critically re-examine {{the finding}} of Campbell and Dodd (1984, Experiment 2), which suggests that irrelevant speech disrupts the encoding of visual material for serial recall. Support is sought for the competing view {{that the effect of}} irrelevant speech is on storage by comparing the effect of a range of acoustic conditions on memory for graphic and <b>lip-read</b> lists. Initially, serial short-term recall of visually presented lists was examined with irrelevant speech that was both asynchronous with the visually presented items and of varied speech content (Experiment 1 a). In this experiment substantial impairments in recall of both graphic and <b>lip-read</b> lists were found. However, with unvarying asynchronous speech (Experiment 1 b) the effect of speech was small and non-significant. Experiment 2 examined the effect of changing state and of synchrony of speech with lip movements. When conditions of synchronous and asynchronous unvarying speech were contrasted, no significant effect of synchrony or irrelevant speech was found (Experiment 2 a and 2 c). In contrast, when the speech was varying in content, a strong effect of irrelevant speech was found; moreover, the effect was roughly the same for synchronous and asynchronous materials (Experiment 2 b). The contrast in outcome with varying and unvarying speech provides strong support for the “changing state” model of the irrelevant speech effect. Coupled with the absence of an effect of synchrony in Experiment 2, these experiments reinforce the view that disruption by irrelevant speech occurs in memory, not at encoding...|$|R
500|$|She ordered {{pamphlets}} {{describing the}} rooms of the house for tourists so they could understand everything, and had them translated into Spanish, French, Italian and Russian for foreigners. She had ramps installed for the handicapped and physically disabled. She instructed the police who served as tour guides to attend sessions at the Winterthur Museum, Garden and Library (to learn how tours were guided [...] "in a real museum"), and arranged for them to wear less menacing uniforms, with their guns hidden underneath. The tour guides were to speak slowly to deaf groups, {{to help those who}} <b>lip-read,</b> and Pat ordered that the blind be able to touch the antiques.|$|R
50|$|Nearing {{the end of}} the Rhapsody, he is {{in shock}} after turning to the finale page which consist of scrambled, quick playing, nearly {{impossible}} to read notes after which he takes off his shirt, oils his hands, and prays. Then, preparing to play the intense part, he is startled to hear the frenzied finalé playing, behind him. It is the mouse, complete with tie and tails, playing a toy piano that plays like a normal-sounding piano. Cut back to Bugs after the full-orchestra finalé, and he disgustedly plays the three single notes that actually end the piece, and then mutters inaudible profanity which can be <b>lip-read.</b>|$|R
