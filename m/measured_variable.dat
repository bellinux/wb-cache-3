307|9378|Public
25|$|The {{advanced}} type of automation that revolutionized manufacturing, aircraft, {{communications and}} other industries, is feedback control, {{which is usually}} continuous and involves taking measurements using a sensor and making calculated adjustments to keep the <b>measured</b> <b>variable</b> within a set range. The theoretical basis of closed loop automation is control theory.|$|E
2500|$|... {{is called}} the regressand, {{endogenous}} variable, response variable, <b>measured</b> <b>variable,</b> criterion variable, or dependent variable [...] (see dependent and independent variables). The decision as to which variable in a data set is modeled {{as the dependent variable}} and which are modeled as the independent variables may be based on a presumption that the value of one of the variables is caused by, or directly influenced by the other variables. Alternatively, there may be an operational reason to model one of the variables in terms of the others, in which case there need be no presumption of causality.|$|E
2500|$|To do this, a {{controller}} {{with the}} requisite corrective behaviour is required. This controller monitors the controlled process variable (PV), and compares {{it with the}} reference or set point (SP). The difference between actual and desired value of the process variable, called the error signal, or SP-PV error, is applied as feedback to generate a control action to bring the controlled process variable to the same value as the set point. Other aspects which are also studied are [...] controllability and observability. On this is based the advanced type of automation that revolutionized manufacturing, aircraft, communications and other industries. This is feedback control, which is usually continuous and involves taking measurements using a sensor and making calculated adjustments to keep the <b>measured</b> <b>variable</b> within a set range {{by means of a}} [...] "final control element", such as a control valve.|$|E
40|$|We {{address the}} problem of {{evaluating}} table queries from a summary database formed by a collection of pre-computed tables on certain <b>measure</b> <b>variables.</b> We assume that every table query asks for the distribution of a <b>measure</b> <b>variable</b> of interest, and that the summary database contains tables on the variable of interest as well as on other <b>measure</b> <b>variables.</b> If the requested distribution is none of the base tables and cannot be exactly derivable from none of them, then the answer to the query will be the result of an estimation procedure, which may bring up another <b>measure</b> <b>variable</b> that is correlated to the <b>measure</b> <b>variable</b> of interest. We give an estimation procedure that combines the “divide-and-conquer ” principle with tree computations...|$|R
30|$|Results {{also showed}} that the p factor [(the {{percentage}} of observations bracketed by the 95 % prediction uncertainty (95 PPU)] brackets 56 % of the observation and r factor (average number of <b>measured</b> <b>variables</b> divided by the standard deviation of these <b>measured</b> <b>variables)</b> equals 0.54.|$|R
5000|$|... #Subtitle level 2: <b>Measured</b> <b>variables</b> on {{a roller}} {{dynamometer}} ...|$|R
2500|$|The {{consistent}} application by statisticians of Neyman and Pearson's {{convention of}} representing [...] "the hypothesis to be tested" [...] (or [...] "the hypothesis to be nullified") with the expression H0 {{has led to}} circumstances where many understand the term [...] "the null hypothesis" [...] as meaning [...] "the nil hypothesis"– a statement that the results in question have arisen through chance. This {{is not necessarily the}} case– the key restriction, as per Fisher (1966), is that [...] "the null hypothesis must be exact, that is free from vagueness and ambiguity, because it must supply the basis of the 'problem of distribution,' of which the test of significance is the solution." [...] As a consequence of this, in experimental science the null hypothesis is generally a statement that a particular treatment has no effect; in observational science, it {{is that there is no}} difference between the value of a particular <b>measured</b> <b>variable,</b> and that of an experimental prediction.|$|E
2500|$|The {{need for}} {{instrumentation}} grew with {{the rapidly growing}} central electric power stations after the First World War. [...] Instrumentation was also important for heat treating ovens, chemical plants and refineries. [...] Common instrumentation was for measuring temperature, pressure or flow. [...] Readings were typically recorded on circle charts or strip charts. [...] Until the 1930s control was typically [...] "open loop", meaning {{that it did not}} use feedback. [...] Operators made various adjustments by such means as turning handles on valves. [...] If done from a control room a message could be sent to an operator in the plant by color coded light, letting him know whether to increase or decrease whatever was being controlled. [...] The signal lights were operated by a switchboard, which soon became automated. [...] Automatic control became possible with the feedback controller, which sensed the <b>measured</b> <b>variable,</b> measured the deviation from the setpoint and perhaps the rate of change and time weighted amount of deviation, compared that with the setpoint and automatically applied a calculated adjustment. [...] A stand-alone controller may use a combination of mechanical, pneumatic, hydraulic or electronic analogs to manipulate the controlled device. [...] The tendency was to use electronic controls after these were developed, but today the tendency is to use a computer to replace individual controllers.|$|E
5000|$|... is {{the value}} of the <b>measured</b> <b>variable</b> for theth case from the th group, ...|$|E
30|$|The {{primary purpose}} of {{exploratory}} factor analysis (EFA) is {{to arrive at a}} more parsimonious conceptual understanding of a set of <b>measured</b> <b>variables</b> by determining the number and nature of common factors needed to account for the pattern of correlations among the <b>measured</b> <b>variables</b> (Fabrigar et al. 1999). ROSE contained large number of variables in each of its hypothesized dimensions. The most effective analysis method in this case could be EFA. Methodologists have recommended that at least three to five <b>measured</b> <b>variables</b> representing each common factor be included in a study (MacCallum et al. 1999; Velicer and Fava 1998). As a result, a data reduction method was necessary to take scores on a large set of <b>measured</b> <b>variables</b> and reduce them to scores on a smaller set of composite variables that retain as much information from the original variables as possible.|$|R
40|$|The {{presence}} of latent variables can greatly complicate inferences about causal relations between <b>measured</b> <b>variables</b> from statistical data. In many cases, the {{presence of}} latent variables {{makes it impossible to}} determine for two <b>measured</b> <b>variables</b> A and B, whether A causes B, B causes A, or there is some common cause. In this paper I present several theorems that state conditions under which it is possible to reliably infer the causal relation between two <b>measured</b> <b>variables,</b> regardless of whether latent variables are acting or not. Comment: Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI 1991...|$|R
30|$|To {{examine the}} {{relationship}} between supply chain constructs and <b>measured</b> <b>variables.</b>|$|R
5000|$|In statistics, an {{empirical}} distribution function is the distribution function {{associated with the}} empirical measure of a sample. This cumulative distribution function is a step function that jumps up by [...] {{at each of the}} [...] data points. Its value at any specified value of the <b>measured</b> <b>variable</b> is the fraction of observations of the <b>measured</b> <b>variable</b> that are {{less than or equal to}} the specified value.|$|E
50|$|Factor {{loadings}} are {{numerical values}} that indicate {{the strength and}} direction of a factor on a <b>measured</b> <b>variable.</b> Factor loadings indicate how strongly the factor influences the <b>measured</b> <b>variable.</b> In order to label the factors in the model, researchers should examine the factor pattern to see which items load highly on which factors and then determine what those items have in common. Whatever the items have in common will indicate {{the meaning of the}} factor.|$|E
50|$|Another simple type of {{controller}} is a proportional controller. With {{this type}} of controller, the controller output (control action) {{is proportional to the}} error in the <b>measured</b> <b>variable.</b>|$|E
30|$|The paper {{applies the}} {{analysis}} technology of {{structural equation model}} (SEM) to test the hypotheses in the research. Structural equation model invokes a measurement model that defines latent variables using one or more observed variables and a structural model that imputes relationships between latent variables. The model consists of latent <b>variables,</b> <b>measured</b> <b>variables,</b> and a path. Latent variables cannot be directly observed but are rather inferred from other <b>variables.</b> <b>Measured</b> <b>variables</b> (manifest variable) can be directly measured and are usually used to explain latent variables [10].|$|R
5000|$|Item {{response}} theory: Models for (mostly) assessing one {{latent variable}} from several binary <b>measured</b> <b>variables</b> (e.g. an exam).|$|R
50|$|Manipulation {{checks are}} <b>measured</b> <b>variables</b> that show what the {{manipulated}} variables concurrently affect besides {{the dependent variable}} of interest.|$|R
50|$|A {{variable}} {{measured in}} discrete {{time can be}} plotted as a step function, in which each time period is given a region on the horizontal axis of the same length as every other time period, and the <b>measured</b> <b>variable</b> is plotted as a height that stays constant throughout {{the region of the}} time period. In this graphical technique, the graph appears as a sequence of horizontal steps. Alternatively, each time period {{can be viewed as a}} detached point in time, usually at an integer value on the horizontal axis, and the <b>measured</b> <b>variable</b> is plotted as a height above that time-axis point. In this technique, the graph appears as a set of dots.|$|E
50|$|For {{reference}} {{designation of}} any equipment in industrial systems the standard IEC 61346 (Industrial systems, installations and equipment and industrial products — Structuring principles and reference designations) can be applied. For the function Measurement the reference designator B is used, {{followed by the}} above listed letter for the <b>measured</b> <b>variable.</b>|$|E
50|$|The {{advanced}} type of automation that revolutionized manufacturing, aircraft, {{communications and}} other industries, is feedback control, {{which is usually}} continuous and involves taking measurements using a sensor and making calculated adjustments to keep the <b>measured</b> <b>variable</b> within a set range. The theoretical basis of closed loop automation is control theory.|$|E
5000|$|Given the <b>measured</b> <b>variables</b> with uncertainties, [...] and , and {{neglecting}} their possible correlation, {{the uncertainty}} in the computed quantity, , is: ...|$|R
30|$|The {{statistical}} analysis {{is a tool}} {{that can be applied}} to <b>measure</b> <b>variables</b> to identify groundwater pollution (Shrestha and Kazama 2007).|$|R
30|$|Treatment {{effects on}} <b>measured</b> <b>variables</b> in each {{experiment}} {{were analyzed using}} one way ANOVA (GenStat Discovery Edition 3 2003; GenStat VSNI 2011). Differences between treatment means were judged significant at p ≤  0.05 as determined by Fisher’s protected least significant difference (LSD) test. Flux data were log-transformed to normalize the distributions before the statistical analysis. Mean separation was performed using the LSD since there were not > 3 treatments in each set of experiment. Statistical significance {{of the differences between}} <b>measured</b> <b>variables</b> in plots subjected to single and seasonal split manure applications was established by performing t test for unpaired samples using the GenStat package. The Pearson coefficients of determination between <b>measured</b> <b>variables</b> and their r 2 values were computed using Microsoft Excel. Significance of correlations between selected variables was established using a linear model GenStat analysis of correlation at 5  % level.|$|R
50|$|EFA {{is based}} on the common factor model. Within the common factor model, a {{function}} of common factors, unique factors, and errors of measurements expresses measured variables. Common factors inﬂuence two or more measured variables, while each unique factor inﬂuences only one <b>measured</b> <b>variable</b> and does not explain correlations among measured variables.|$|E
50|$|The {{advanced}} type of automation that revolutionized manufacturing, aircraft, {{communications and}} other industries, is feedback control, {{which is usually}} continuous and involves taking measurements using a sensor and making calculated adjustments to keep the <b>measured</b> <b>variable</b> within a set range. The theoretical basis of closed loop automation is the discipline of control theory.|$|E
5000|$|The {{advanced}} type of automation that revolutionized manufacturing, aircraft, {{communications and}} other industries, is feedback control, {{which is usually}} continuous and involves taking measurements using a sensor and making calculated adjustments to keep the <b>measured</b> <b>variable</b> within a set range {{by means of a}} [...] "final control element", such as a control valve.|$|E
5000|$|The {{expected}} value (mean) of the derived PDF can be estimated, {{for the case}} where z {{is a function of}} one or two <b>measured</b> <b>variables,</b> using ...|$|R
3000|$|... 2 The idea is {{that the}} factors <b>measure</b> <b>variables</b> like the wage, {{employment}} opportunities, infrastructiure and local public goods, profit prospects for self-employed individuals, marriage prospects, etc.|$|R
30|$|Descriptive data {{represent}} mean ± SD. Peason {{product-moment correlation}} coefficients were computed {{to assess the}} relationships between the <b>measured</b> <b>variables.</b> The level of significance was set at p <  0.05.|$|R
50|$|Feedback {{systems can}} be combined. In cascade control, one control loop applies control {{algorithms}} to a <b>measured</b> <b>variable</b> against a setpoint, but then provides a varying setpoint to another control loop rather than affecting process variables directly. If a system has several different measured variables to be controlled, separate control systems will be present for each of them.|$|E
50|$|The {{derivative}} part {{is concerned}} with the rate-of-change of the error with time: If the <b>measured</b> <b>variable</b> approaches the setpoint rapidly, then the actuator is backed off early to allow it to coast to the required level; conversely if the measured value begins to move rapidly away from the setpoint, extra effort is applied—in proportion to that rapidity—to try to maintain it.|$|E
5000|$|Nelson {{rules are}} a method in process control of {{determining}} if some <b>measured</b> <b>variable</b> {{is out of}} control (unpredictable versus consistent). Rules, for detecting [...] "out-of-control" [...] or non-random conditions were first postulated by Walter A. Shewhart [...] in the 1920s. The Nelson rules were first published in the October 1984 issue of the Journal of Quality Technology in an article by Lloyd S Nelson.|$|E
50|$|NFDRS is {{a complex}} set of {{equations}} with user-defined constants and <b>measured</b> <b>variables</b> to calculate the daily index and components {{that can be used for}} decision support.|$|R
25|$|In astronomy, {{adaptive}} optics {{is a technique}} to <b>measure</b> <b>variable</b> image distortions and adapt a deformable mirror accordingly on a timescale of milliseconds, {{to compensate for the}} distortions.|$|R
30|$|In {{order to}} {{determine}} the <b>measured</b> <b>variables</b> for self-determined motivation, we first performed a stepwise multiple regression so that only statistically significant <b>measured</b> <b>variables</b> for L 2 listening proficiency were included in the measurement model. We then calculated Pearson’s correlation coefficients to examine the existence of significant correlations among the pertinent variables regarding L 2 listening proficiency. Following this, we conducted a structural equation model (SEM) in AMOS 22 using maximum-likelihood estimation to examine the causal relationships among the cognitive and affective variables thought to influence L 2 listening proficiency.|$|R
