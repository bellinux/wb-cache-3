27|3985|Public
25|$|In contrast, the Carathéodory way recounted {{just above}} {{does not use}} {{calorimetry}} or temperature in its primary definition of quantity of energy transferred as heat. The Carathéodory way regards calorimetry only as a secondary or indirect way of <b>measuring</b> <b>quantity</b> of energy transferred as heat. As recounted in more detail just above, the Carathéodory way regards quantity of energy transferred as heat in a process as primarily or directly defined as a residual quantity. It is calculated from the difference of the internal energies of the initial and final states of the system, and from the actual work done by the system during the process. That internal energy difference {{is supposed to have}} been measured in advance through processes of purely adiabatic transfer of energy as work, processes that take the system between the initial and final states. By the Carathéodory way it is presupposed as known from experiment that there actually physically exist enough such adiabatic processes, so that there need be no recourse to calorimetry for measurement of quantity of energy transferred as heat. This presupposition is essential but is explicitly labeled neither as a law of thermodynamics nor as an axiom of the Carathéodory way. In fact, the actual physical existence of such adiabatic processes is indeed mostly supposition, and those supposed processes have in most cases not been actually verified empirically to exist.|$|E
50|$|A {{voltameter}} or coulometer is {{a scientific}} instrument used for <b>measuring</b> <b>quantity</b> of electricity (electric charge). The SI {{unit of quantity}} of electricity is the coulomb.|$|E
50|$|The {{measurable}} {{variables in}} economics are quantity, quality and distribution. <b>Measuring</b> <b>quantity</b> in economics follows {{the rules of}} measuring in physics. Quality as a variable refers to qualitative changes in the production process. Qualitative changes take place when relative of different constant-price input and output factors alter. Distribution as a variable of the production refers {{to a series of}} events in which the unit prices of constant-quality products and inputs alter causing a change in income distribution among those participating in the exchange. The magnitude of the change in income distribution is directly proportionate to the change in prices of the output and inputs and to their quantities. Productivity gains are distributed, for example, to customers as lower product prices or to staff as higher pay.|$|E
50|$|As {{there are}} rules for {{determining}} the number of significant figures in directly <b>measured</b> <b>quantities,</b> {{there are rules}} for determining the number of significant figures in quantities calculated from these <b>measured</b> <b>quantities.</b>|$|R
40|$|This article {{presents}} a developed method for calibration of the inclination angle measuring devices (inclinometers) via {{the method of}} indirect comparing {{of the value of}} the <b>measured</b> <b>quantity</b> with the industry standard – optical quadrant. It is considered the mathematical model and the uncertainty of the <b>measured</b> <b>quantity</b> is analyzed...|$|R
50|$|Tensors are {{frequently}} used in engineering to describe <b>measured</b> <b>quantities.</b>|$|R
5000|$|Management {{involves}} {{identifying the}} mission, objective, procedures, rules and manipulationof the human capital of an enterprise {{to contribute to}} the success of the enterprise. This implies effective communication: an enterprise environment (as opposed to a physical or mechanical mechanism) implies human motivation and implies some sort of successful progress or system outcome. As such, management is not the manipulation of a mechanism (machine or automated program), not the herding of animals, and can occur either in a legal or in an illegal enterprise or environment. Management does not need to be seen from enterprise point of view alone, because management is an essential function to improve one's life and relationships. Management is therefore everywhere and it has a wider range of application. Based on this, management must have humans, communication, and a positive enterprise endeavor. Plans, measurements, motivational psychological tools, goals, and economic measures (profit, etc.) may or may not be necessary components for there to be management. At first, one views management functionally, such as <b>measuring</b> <b>quantity,</b> adjusting plans, meeting goals. This applies even in situations where planning does not take place. From this perspective, Henri Fayol (1841-1925)considers management to consist of six functions: ...|$|E
50|$|In contrast, the Carathéodory way recounted {{just above}} {{does not use}} {{calorimetry}} or temperature in its primary definition of quantity of energy transferred as heat. The Carathéodory way regards calorimetry only as a secondary or indirect way of <b>measuring</b> <b>quantity</b> of energy transferred as heat. As recounted in more detail just above, the Carathéodory way regards quantity of energy transferred as heat in a process as primarily or directly defined as a residual quantity. It is calculated from the difference of the internal energies of the initial and final states of the system, and from the actual work done by the system during the process. That internal energy difference {{is supposed to have}} been measured in advance through processes of purely adiabatic transfer of energy as work, processes that take the system between the initial and final states. By the Carathéodory way it is presupposed as known from experiment that there actually physically exist enough such adiabatic processes, so that there need be no recourse to calorimetry for measurement of quantity of energy transferred as heat. This presupposition is essential but is explicitly labeled neither as a law of thermodynamics nor as an axiom of the Carathéodory way. In fact, the actual physical existence of such adiabatic processes is indeed mostly supposition, and those supposed processes have in most cases not been actually verified empirically to exist.|$|E
40|$|The {{assessment}} of the uncertainty of measurement results, an essential problem in environmental acoustic investigations, is undertaken in the paper. An attention is drawn to the – usually omitted – problem of the verification of assumptions related to using the classic methods of the confidence intervals estimation, for the controlled <b>measuring</b> <b>quantity.</b> Especially the paper directs attention to the need of the verification of the assumption of the normal distribution of the <b>measuring</b> <b>quantity</b> set, being the base for the existing and binding procedures of the acoustic measurements assessment uncertainty. The essence of the undertaken problem concerns the binding legal and standard acts related to acoustic measurements and recommended in: ‘Guide to the expression of uncertainty in measurement ’ (GUM) (OIML 1993), developed {{under the aegis of}} the International Bureau of Measures (BIPM). The model legitimacy of the hypothesis of the normal distribution of the <b>measuring</b> <b>quantity</b> set in acoustic measurements is discussed and supplemented by testing its likelihood on the environment acoustic results. The Jarque-Bery test based on skewness and flattening (curtosis) distribution measures was used for the analysis of results verifying the assumption. This test allows for the simultaneous analysis of the deviation from the normal distribution caused both by its skewness and flattening. The performed experiments concerned analyses of the distribution of sound levels: LD, LE, LN, LDWN, being the basic noise indicators in assessments of the environment acoustic hazards...|$|E
5000|$|For <b>quantities</b> {{created from}} <b>measured</b> <b>quantities</b> by {{addition}} and subtraction, the last significant decimal place (hundreds, tens, ones, tenths, and so forth) in the calculated result {{should be the}} same as the leftmost or largest decimal place of the last significant figure out of all the <b>measured</b> <b>quantities</b> in the terms of the sum. For example, ...|$|R
50|$|A {{number of}} units were used to <b>measure</b> <b>quantities</b> like length and capacity.|$|R
50|$|Means or {{apparatus}} for <b>measuring</b> <b>quantities</b> {{of highly}} volatile liquids. No. 3490. 1904.|$|R
40|$|Past {{studies using}} {{acculturation}} to predict substance use in immigrants have yielded mixed findings, suggesting support for both acculturative and assimilation theories {{of substance use}} in immigrants. In this investigation, two variables from the cross-cultural literature, Marginalization and Perceived Discrimination, were {{used to examine the}} predictions of these theories. First- and second-generation Indian-Americans were recruited and completed questionnaires <b>measuring</b> <b>quantity,</b> frequency, and negative consequences of drug / alcohol use, Perceived Discrimination, and Marginalization. Information on demographics and depressive symptoms were used as covariates. Hierarchical regression and correlation analyses indicated that lower levels of Marginalization significantly predicted higher rates Alcohol Use in the first-generation; conversely, higher levels of Perceived Discrimination were significantly associated with increased Drug Use in the second-generation. It was concluded that both assimilation and acculturative theories may have merit for identifying substance users in an Indian-American sample when generation is considered as a moderator...|$|E
40|$|In this paper, {{the effects}} of the input {{quantity}} representations in linear and complex forms are analyzed to estimate mismatch uncertainty separately for one-port and two-port components. The mismatch uncertainties in power and attenuation measurements are evaluated for direct, ratio and substitution techniques {{with the use of a}} vector network analyzer system in the range of 1 to 18 GHz. The estimated mismatch uncertainties were compared for the same device under test and these values have verified that their evaluation is dependent on the representations of input quantities. In power measurements, the mismatch uncertainty is reduced when evaluating from the voltage standing wave ratio or reflection coefficient magnitudes in comparison to the complex reflection coefficients. The mismatch uncertainty in the attenuation measurements, are found higher and linearly increasing while estimating from the linear magnitude values than those from the S-parameters of the attenuator. Thus in practice, the mismatch uncertainty is estimated more accurately using the quantities measured in the same representations as of <b>measuring</b> <b>quantity...</b>|$|E
40|$|Free field {{microwave}} {{methods are}} {{well suited to}} characterize dielectric materials both in nondestructive and in contactless way. Variations of the distance between test object and the microwave sensor (air gap) are influencing the measuring values as the air gap {{is part of the}} system under test. By additional and independent air gap measurement with a laser triangulation sensor or with air coupled ultrasound it is possible to correct the air gap variations. One potential application is the online surveillance of the plastics coating process of steel pipes. Measurements have been performed using a FMCW radar with a carrier frequency of about 94 GHz in reflexion mode and in combination with air gap mearurements. The accuracy of thickness measurement is about 0. 05 mm or better. The characterization of thin metallic layers on dielectric substrate can be performed with quite inexpensive microwave sensors. While signal phase is the essential <b>measuring</b> <b>quantity</b> in monitoring of plastics coating, amplitude is essential in monitoring of thin metallic layers...|$|E
5000|$|Loading a <b>measured</b> <b>quantity</b> of polymer (usually in powder form) {{into the}} mold.|$|R
5000|$|Some Planck {{units are}} {{suitable}} for <b>measuring</b> <b>quantities</b> that are familiar from daily experience. For example: ...|$|R
50|$|Plackett-Burman {{design of}} {{experiments}} for investigating the dependence of some <b>measured</b> <b>quantity</b> {{on a number of}} independent variables.|$|R
40|$|In {{the context}} of high tool wear {{concerning}} machining of carbon fiber reinforced plastic (CFRP), it is desirable to study new processes and techniques which are able to lower the wear and thus induced costs. Therefore, this article presents a novel minimum quantity dry lubrication (MQDL) -process. It delivers minimal amounts of graphite powder, using compressed air as a conveying medium to its operating area between the tool and workpiece. For this purpose a prototypical fluidisation device for conditioning, dosing and conveying the graphite powder was built. The investigations {{have shown that the}} constructed prototype is already able to deliver tiniest amounts of graphite mass flows (less than 3 g/h) reliably. Furthermore, first results of drilling tests with internal MQDL-supply are presented. The cutting edge radius of the solid carbide drilling tools has been chosen as the wear <b>measuring</b> <b>quantity.</b> With the use of MQDL at drilling CFRP, a clear reduction in wear is shown, in comparison to pure compressed air. Finally the article shows further research and application areas of this new MQDL-technology...|$|E
40|$|Abstract. The {{current work}} investigates the {{electro-discharge}} machining (EDM) of plain woven carbon reinforced polymer composites with pulse durations of 100 µs, 200 µs, 300 µs, currents 1 A, 3 A and 5 A, and a voltage of 100 V. An x-ray computed tomography (CT) is employed {{to examine the}} delaminations, while a delamination factor model utilizing the equivalent delamination diameter provides the <b>measuring</b> <b>quantity</b> for assessment. Finite element simulations compute the stress concentrations around the holes by {{taking into account the}} delamination equivalent diameters of the open-holes, as monitored from the x-ray CT. The Whitney-Nuismer point stress criterion is utilised in order to predict the failure strength of the machined open-hole laminates and it is compared with the experimentally derived mechanical strength values. The results reveal that EDM is a feasible method for open-hole machining of composites, however proper selection of the operational parameters is needed. By accurately measuring the peripheral delamination areas of the machined holes, it is shown that the analysis of the mechanical behaviour of the plain woven laminates by the means of finite element method and the Whitney-Nuismer criterion can accurately predict the response of such composites when subjected to tensile loads...|$|E
40|$|Historically, {{the use of}} {{homework}} in psychotherapy has been a commonly used intervention. Several {{studies have demonstrated that}} homework is an effective intervention for clinical improvement (Bums 2 ̆ 6 Nolen-Hoeksema, 1991; Neimeyer 2 ̆ 6 Feixas, 1990; Persons, Bums, 2 ̆ 6 Pedoff, 1988). Moreover, researchers have demonstrated that those who comply with the homework assignment are clinically more improved at the end of treatment, than those who non-comply (Bums 2 ̆ 6 Spangler, 2000; Edelman 2 ̆ 6 Chambless, 1993, 1995; Holtzworth-Munroe, Jacobson, DeKlyen, 2 ̆ 6 Whisman, 1989; Leung 2 ̆ 6 Heimberg, 1996). There are a few studies (Addis 2 ̆ 6 Jacobson, 1996; Schmidt 2 ̆ 6 Woolaway-Bickel, 2000) that have measured homework compliance, both quantity and quality; however, a reliable and nomothetic instrument has failed to emerge. Moreover, an instrument, which attempts to ascertain whether or not the patient learned anything from doing the homework concomitant with <b>measuring</b> <b>quantity</b> and quality, appears to be absent in the literature. Given the presented information, thus far, and lack of a quick and reliable measure {{of homework}} compliance, the goals of this study are to develop and validate such a measure...|$|E
5000|$|Computation of many <b>measuring</b> <b>quantities,</b> e.g. {{diffusion}} coefficients, stress-strain diagrams, elastic constants, distribution functions, correlation {{functions and}} shortest-path-ring statistics ...|$|R
50|$|The {{equation}} is most conveniently {{expressed in terms}} of the <b>measured</b> <b>quantity</b> N(t) rather than the constant initial value No.|$|R
2500|$|The term [...] "margin of error" [...] {{is often}} used in non-survey {{contexts}} to indicate observational error in reporting <b>measured</b> <b>quantities.</b>|$|R
40|$|The {{application}} of electromagnetic, magneto-elastic techniques is recommended if stresses or stress gradients in surface near layers are of interest. The use of one <b>measuring</b> <b>quantity</b> allows {{the evaluation of}} stress states in parts with a controlled microstructure. The combined use of different electro-magnetic and magneto-elastic quantities enables the evaluation of stress states of parts with an inhomogeneous microstructure and characterization of microstructural states in terms of hardness of strength values. Consequently, the main application is to characterize stress and microstructure in mechanically or thermally treated surfaces of technical parts. The set-ups available on the market mainly differ in the measuring quantities used. In all cases, the quantities have to be calibrated using samples with a known microstructural state. The major area of ultrasonic applications covers the analysis of stress states in surface layers of about 5 mm of thickness and of stress states in the bulk of large components. The quantitative stress analysis presumes {{the knowledge of the}} material dependent elastic properties. Set-ups optizmized of the evaluation of stress states of bolts and screws, of railroad wheels and rails are on the market. Different laboratory prototypes are in use to evaluate stress states of specific components...|$|E
40|$|This study {{compared}} the application {{and reliability of}} 4 methods for biofilm quantification (computerized, paper-weighing, point-counting, and planimetric) in complete dentures, verifying the correlation between them. The internal surfaces of 62 complete dentures were stained (5 % erythrosine) and photographed. The slides were projected on paper, and the areas (total and biofilm-covered) were outlined with a pencil. These areas were measured with an equidistant point grid (point-counting method), a digital planimeter (planimetric method), and for the paper weighing method they were cut and weighed with a precision scale. For the computerized method, ImageTool software was used. In order to perform a validation test of the methods, {{all of them were}} applied to slide projections of geometric figures with known dimensions. The correlation tests showed high correlation values (r = 0. 82 to 0. 99) among the methods. The validation test (ANOVA) showed no statistically significant differences among the values obtained from the measurement of figures using all four quantitative methods and the real dimensions of these geometric figures. Quantitative methods were efficient and reliable for <b>measuring</b> <b>quantity</b> of biofilm in complete dentures, and may be useful in experimental studies on the efficacy of hygiene products. The computerized method was fast and easy to perform...|$|E
40|$|OBJECTIVE [...] To {{evaluate}} a new cross sectional echocardiographic method for estimating {{the volume of}} pericardial effusions. DESIGN [...] The volume of pericardial fluid removed by surgical drainage or paracentesis was compared with the volume estimated by the echocardiographic method. The pericardial sac volume and cardiac volume were calculated by applying the formula for the volume of a prolate ellipse (pi x 4 / 3 x L/ 2 x D 1 / 2 x D 2 / 2) where L is the major axis and D 1 and D 2 are the minor axes. The pericardial fluid volume was calculated as the pericardial sac volume minus the cardiac volume. PATIENTS [...] 13 patients with 14 large pericardial effusions (one recurrence) {{all of whom had}} tamponade and cross sectional echocardiography just before therapeutic full drainage of the effusion. RESULTS [...] The volumes of pericardial fluid drained ranged from 0. 5 to 2. 11. The correlation between these actual volumes and the volumes estimated by echocardiography was excellent (r = 0. 97); the correlation was good in four patients with intrapericardial adhesions. CONCLUSIONS [...] Because of certain approximations in <b>measuring</b> <b>quantity</b> of pericardial fluid drained, the echocardiographic estimations cannot be claimed to be definite. The data, however, indicate that the echocardiographic method is sufficiently reliable to provide useful estimates for practical clinical purposes...|$|E
5000|$|This {{is just a}} Fourier cosine transform. The inverse {{gives us}} our desired result {{in terms of the}} <b>measured</b> <b>quantity</b> : ...|$|R
40|$|The {{influence}} of different cementite contents and cementite modifications on micromagnetic <b>measuring</b> <b>quantities</b> of steels with ferritic-perlitic, martensitic annealed and martensitic soft annealed microstructure states and {{white cast iron}} are analyzed. For this, micromagnetic <b>measuring</b> <b>quantities</b> derived from the magnetic Barkhausen noise are used. By heating up to temperature values above the Curie temperature of cementite, characteristic changes of the <b>measuring</b> <b>quantities</b> are shown. Cementite produces actively its own magnetic Barkhausen noise, whereas it also influences the magnetic Barkhausen noise of the iron matrix as a foreign body and by its stress fields of the second kind. Both influences act {{in a different way}} as well in steel as in white cast iron. In steel, the stress induced effect is the dominating one; in white cast iron, the active contribution to Barkhausen noise dominates...|$|R
40|$|The {{paper is}} focused on {{theoretical}} analysis of the basic characteristics of dielectrics, especially on the examination of these qualities at samples of epoxy sealing compound filled with powder mica, and their dependance on the temperature {{and the content of}} filling in the material. The <b>measured</b> <b>quantities</b> are inner resistivity, relative permitivity, and loss factor. The paper also deals with the sensitivity of the material to humidity, and through the influence of humidity to the other <b>measured</b> <b>quantities...</b>|$|R
40|$|AbstractMany fuzzy number ranking {{approaches}} are {{developed in the}} literature for multiattribute decision-making problems. Almost all of the existing approaches focus on quantity measurement of fuzzy numbers for ranking purpose. In this paper, we consider the ranking process to determine a decision-maker's preference order of fuzzy numbers. A new ranking index is proposed to not only take quantity measurement, but incorporate quality factor into consideration for the need of general decision-making problems. For <b>measuring</b> <b>quantity,</b> several α-cuts of fuzzy numbers are used. A signal/noise ratio is defined to evaluate quality of a fuzzy number. This ratio considers the middle-point and spread of each α-cut of fuzzy numbers as the signal and noise, respectively. A fuzzy number with the stronger signal and the weaker noise is considered better. Moreover, the associated α levels are treated as the degree of belief about the α-cut and used as weights in the index for strengthening the influence of α-cut with higher α levels. The membership functions of fuzzy numbers are not necessarily to be known beforehand while applying this index. Only a few left and right boundary values of α-cuts of fuzzy numbers are required. We have proved the feature of the proposed index in a particular case. Several examples are also used to illustrate the feature and applicability in ranking fuzzy numbers...|$|E
40|$|Exposure to {{microwave}} radiation induces multiple organ dysfunctions, especially in CNS. The {{aim of this}} work was investigation of biological effects of microwave radiation on rats' brain and determination of increased oxidative stress as a possible pathogenetic's mechanism. Wis tar rats 3 months old were divided in experimental (4 female and 4 male animal) and control group (5 female and 4 male). This experimental group was constantly exposed to a magnetic field of 5 mG. We simulated using of mobile phones 30 min every day. The source of NIR emitted MF that was similar to mobile phones at 900 MHz. The rats were killed after 2 months. Biological effects were determined by observation of individual and collective behavior and body mass changes. Lipid per oxidation was determined by <b>measuring</b> <b>quantity</b> of malondialdehyde (MDA) in brain homogenate. The animals in experimental group exposed to EMF showed les weight gain. The most important observations were changing of basic behavior models and expression of aggressive or panic behavior. The content of MDA in brain tissue is singificantly higher (1. 42 times) in rats exposed to electromagnetic fields (3, 82 ± 0. 65 vs. control 2. 69 ± 0. 42 nmol/mg proteins, p< 0. 01). Increased oxidative stress and lipid peroxidation after exposition in EM fields induced disorders of function and structure of brain...|$|E
40|$|In 2005, the Ministry of Health in Rwanda, {{with the}} support of the Belgian Technical Cooperation, {{launched}} a strategy of performance-based financing (PBF) in a group of 74 health centres (HCs), covering 2 -m inhabitants. In 2006, PBF was extended to an additional group of 85 HCs, thus reaching 3. 8 -m inhabitants. This study evaluates the effect of PBF on HC performance from 2005 to 2007. Composite indicators for <b>measuring</b> <b>quantity</b> and quality of services were developed and evaluated through monthly formative supervisions by qualified and well-trained district supervisors. The strategy was based on a fixed fee per quality-approved service. The entire budget spent on the implementation of PBF amounted to $ 0. 25 /cap/year, of which $ 0. 20 /cap/year for subsidies and an estimated dollar; 0. 05 /cap/year for administration, supervision and training. A positive effect on utilization rates was only seen for activities that were previously less well organized; in this case, growth monitoring services and institutional deliveries. The quality of services, defined as the compliance rate with national and international norms, rose considerably for all services in both groups. A sustained level of quality between 80 % and 95 % was reached within 18 months in the first group. A similar result was reached in the second group in 8 months. © 2009 Blackwell Publishing Ltd. SCOPUS: ar. jFLWINinfo:eu-repo/semantics/publishe...|$|E
25|$|These {{physical}} constants (ε0, k0, e) {{are currently}} defined so that ε0 and k0 are exactly defined, and e is a <b>measured</b> <b>quantity.</b>|$|R
5000|$|... is a <b>measured</b> <b>quantity</b> {{that can}} be estimated. If one defines the mean free path in terms of {{momentum}} transfer, then one gets: ...|$|R
3000|$|... are {{the fitting}} {{parameters}} for the Drude-Lorentz model. The <b>measured</b> <b>quantity</b> is the reflectivity R, modeled using Berreman 4 × 4 matrix method [26].|$|R
