18|2443|Public
50|$|According to IDC, {{during the}} period between 2005 and 2009, 2.4 billion mobile phones {{equipped}} with video cameras were projected to enter the global marketplace. Veeker believed that <b>mobile</b> <b>video</b> <b>communication</b> will become pervasive, and was indeed {{one of a handful}} which were among the earliest adapters in that space. However, during May 2006, when Veeker's first demo was rolled out, difficulties in rapid-market adaption included potentially, that Internet-enabled smartphones and subscription plans were still highly expensive, small-screened, not user-friendly and unpopular, the primary modes of cellphone messaging being SMS, with few customers paying for MMS enabled plans. However, the website itself, with its Profile pages, and friends-of-friends ability to share selected videos or pictures, on a scrolling window, were considered innovative for its time. Many advanced features of Flash, integrated with then-emergent JavaScript libraries (before the popularity of JQuery today), were used, allowing users to interact intuitively with and organize their uploads or shares.|$|E
40|$|Abstract: A {{compressive}} sensing (CS) based <b>mobile</b> <b>video</b> <b>communication</b> {{system is}} proposed {{to meet the}} requirement that video service needs low-complexity video encoder in the mobile internet. In this system, the mobile client uses CS based video encoder having low computational complexity and power, and then its output bit-stream is decoded using CS recovery algorithm in the fixed base station or network server. The decoded video signal is transformed again as bits by the traditional H. 264 /MPEG video encoder, and the central base station transmits them to mobile clients so as to realizing low-complexity video decoding. The simulation experiments show that the proposed CS based <b>mobile</b> <b>video</b> <b>communication</b> system has the better rate-distortion performance, and can ensure high quality video reconstruction at low measurement rates. Copyright © 2013 IFSA...|$|E
40|$|International audienceThis paper {{presents}} an exploratory empirical {{study on the}} user's context in mobile videoconferencing {{in order to improve}} the user interface of mobile video devices. Through the rich exchange of information, <b>mobile</b> <b>video</b> <b>communication</b> can provide a better sense of presence than other means of communication. Yet the current mobile interfaces lack the flexibility required to be creative and more meaningful in a videoconference exchange. We conducted observations with 16 participants in three activities where their conversations, reactions and behaviours were observed. Two focus groups were used to identify habits formed from regular use. Results suggest an important difference between the use of the front-facing or back-facing camera and the importance of offering tools that provide more control over the video exchange. From theses results, the study proposes several design recommendations for <b>mobile</b> <b>video</b> <b>communication</b> interfaces in order to support the construction of the user's mobile context...|$|E
40|$|The current {{recommended}} {{video transmission}} standards, Telecommunication Standardization Sector (ITU-T) Q. 26 / 16, of 25 {{frames per second}} at 100 kilobits per second or higher make <b>mobile</b> sign language <b>video</b> <b>communication</b> less accessible than it could be with a more relaxed standard. The current bandwidth requirements are high enough that network congestion may cause lost information. In addition, capped data plans may cause higher cost to <b>video</b> <b>communication</b> users. To increase the accessibility and affordability of <b>video</b> <b>communication,</b> we explore a relaxed standard for sign language video transmission using lower frame rates and bitrates. We propose web and laboratory studies to validate lower bounds on frame rates and bitrates for sign language communication on small mobile devices. We introduce a new model, the Human Signal Intelligibility Model, for informing video intelligibility evaluations. Author Keywords <b>mobile</b> <b>video</b> communication; video compression...|$|R
40|$|Abstract-This paper {{describes}} {{the design and}} evaluation of two browser-based <b>video</b> <b>communication</b> prototypes that support sign language communication between Deaf people. The research explores combinations of technologies, protocols and architectures with the hope to eventually provide a <b>mobile</b> <b>video</b> system that Deaf people would want to use enough to pay for. Technology products, and in particular <b>mobile</b> and web-based <b>video</b> <b>communication</b> systems, are designed {{for the majority of}} people in general. These are not necessarily suitable for Deaf people who have very different physiological and cultural needs. We focus on browser-based video transmission because end-users need not struggle with application installation. Web-browsers are also common on mobile phones. This paper compares two prototypes built with Adobe Flex and HTML 5, H. 264 and H. 263 video codecs, and PC and mobile phone implementations. The paper {{describes the}} motivation, related work, methods, prototype design and finally analyses results of user experiments conducted with Deaf users. Index Terms — Network services, web services, mobil...|$|R
50|$|On October 2, 2008, MegaFon {{launched}} {{for operation}} the first Russian fragment {{of the third}} generation network in IMT-2000/UMTS (3G) at the territory of Saint Petersburg and Leningrad region. For {{the first time ever}} in this country the radio access sub-system UTRAN (UMTS Terrestrial Radio Access Network) was launched for trial commercial operation and included 30 base stations. And already on October 24, 2007, MegaFon announced about start of 3G service in Saint Petersburg and Leningrad region. For the first time in Russia, the following services became available for mass users: Internet access at the data transmission speed that is ten times higher than in the existing GSM networks (2G and 2,5G) of GPRS/EDGE technology, high-quality <b>Mobile</b> TV, <b>video</b> <b>communication.</b>|$|R
40|$|<b>Mobile</b> <b>video</b> <b>communication</b> faces {{a lot of}} {{challenges}} [2]. First, the enormous amount of data generated by video makes the use of efficient coding techniques vital. Second, the resources of mobile terminals, the processing power and battery life are very limited and scarce resources. Third, the mobile channel is a hostile environment with high bit error rates caused {{by a number of}} loss mechanisms, like multipath fading, shadowing...|$|E
40|$|There {{is a high}} need {{among older}} persons to {{maintain}} their social contacts and to stay involved in social life. In this area of social communication ICT and assistive technology can bring a significant support provided that the actual needs and preferences of the user groups are actually met. The paper describes an innovative solution consisting of a <b>mobile</b> <b>video</b> <b>communication</b> facility using a LED projector which is integrated in a social assistive robot system developed {{in the framework of}} the KSERA project...|$|E
30|$|In future works, {{we examine}} the JVCE for the videos of higher resolutions by {{exploiting}} more parameters such {{as the kind of}} the motion estimation algorithm and other video encryption techniques. Further, we study the design space of the JVDD (Joint Video Decompression and Decryption) while additionally investigating the QoS of the reconstructed video. Finally, we would like to explore the total design space of the combination of the JVCE and the JVDD in order to find the optimal condition for the <b>mobile</b> <b>video</b> <b>communication</b> services.|$|E
40|$|This paper {{describes}} {{the design and}} evaluation of two browser-based <b>video</b> <b>communication</b> prototypes that support sign language communication between Deaf people. The research explores combinations of technologies, protocols and architectures with the hope to eventually provide a <b>mobile</b> <b>video</b> system that Deaf people would want to use enough to pay for. Technology products, and in particular <b>mobile</b> and web-based <b>video</b> <b>communication</b> systems, are designed {{for the majority of}} people in general. These are not necessarily suitable for Deaf people who have very different physiological and cultural needs. We focus on browser-based video transmission because end-users need not fiddle with application installation. Web-browsers are also common on mobile phones. This paper compares two prototypes built with Adobe Flex and the fifth version of the HyperText Markup Language, H. 264 and H. 263 video codecs, and PC and mobile phone implementations. The paper {{describes the}} motivation, related work, methods, prototype design and finally analyses results of user experiments conducted with Deaf users. Telkom, Cisco, THRIP, SANPADDepartment of HE and Training approved lis...|$|R
5000|$|ICQ6 was {{launched}} on April 17, 2007, {{and offered a}} single communication platform that combines the various user options: instant messaging services, free SMS from ICQ to <b>mobile,</b> voice and <b>video</b> <b>communication.</b> The software's new sound gallery was orchestrated by the Israeli psychedelic trance duo Infected Mushroom. Among the new additional features in ICQ6 are Quick IM, which allows users to send a short message without opening a conversation window, a [...] "follow me" [...] service directly to the user’s mobile, a multi-chat service and support for Zlango, the animated icons language.|$|R
40|$|With {{the advent}} of Bluetooth {{wireless}} technology {{it is now possible}} to have <b>mobile</b> <b>video</b> and voice <b>communication.</b> However, mobile radio communication, such as Bluetooth, is not entirely suitable for current video encoding methods due to its varying signal strength. These compression methods need to be made more resilient to errors {{in order for them to}} be able to operate as part of a wireless communications device. This paper looks at the technology behind wireless video over Bluetooth and provides a solution to the current problems faced, so that they may be overcome in the future...|$|R
40|$|The {{mainstream}} {{adoption of}} <b>mobile</b> <b>video</b> <b>communication,</b> especially among deaf and hard-of-hearing people, is heavily reliant on cellular network capacity. Video compression lowers {{the rate at}} which video content is transmitted; however, intelligibility may be sacrificed. Currently, there is not a standard method to evaluate video intelligibility, or a good communication model on which to base evaluation. I am developing a better theoretical model, the Human Signal Intelligibility (HSI), to evaluate intelligibility of lowered video quality for the purpose of reducing bandwidth consumption and extending cell phone battery duration. The goal of my dissertation is to advance mobile sign language video communication so it does not rely on higher cellular network bandwidth capacities. I will conduct this work by (1) identifying the components in the HSI model that make up intelligibility of a communication signal and separating those from the comprehensibility of a communication signal; and (2) using this model to identify how low video quality can get before the intelligibility of video content is sacrificed. Thus far, I have evaluated the use of <b>mobile</b> <b>video</b> <b>communication</b> among deaf and hard-of-hearing teenagers; developed two new power-saving algorithms; and quantified battery savings and evaluated user perception when those algorithms are applied...|$|E
40|$|Most {{security}} systems, {{with their}} transmission bandwidth and computing power both being sufficient, emphasize their automatic recognition techniques. However, {{in some situations}} such as baby monitors and intruder avoidance by mobile sensors, the decision function sometimes can be shifted to the concerned human to reduce the transmission and computation cost. We therefore propose a binary video compression method in low resolution to achieve a low cost <b>mobile</b> <b>video</b> <b>communication</b> for inexpensive camera sensors. Shape compensation as proposed in this communication successfully replaces the standard Discrete Cosine Transformation (DCT) after motion compensation...|$|E
40|$|The {{introduction}} of the third generation wireless networks should result in real-time <b>mobile</b> <b>video</b> <b>communication</b> becoming a reality. The error prone nature of the wireless channel means that the video codec that is employed must be robust to channel errors. In this paper we analyze how the various MPEG- 4 video encoder parameters (video packet size, macro block refresh rate, AC prediction and macroblock level rate control) can be adjusted to provide improved error resilience. Simulations using W-CDMA channel error patterns are presented to confirm {{the benefits of the}} proposed scheme...|$|E
40|$|Mobile {{devices are}} lack of {{real-time}} <b>video</b> <b>communication</b> software {{due to their}} weak computational power, short battery lifetime, and in some circumstances, low bandwidth connections. We developed a real-time <b>video</b> <b>communication</b> system, Microsoft Portrait, which can run on PCs and Pocket PCs at local area networks, dialup networks and even wireless networks with bandwidths as low as 9. 6 kilobits/second. The system combines portrait video codec and low complexity full-color <b>mobile</b> <b>video</b> codec to realize <b>video</b> <b>communication</b> on <b>mobile</b> devices in {{the whole range of}} bandwidth conditions. 1...|$|R
40|$|Digital video {{communications}} have {{been characterized by}} an exponential growth in the last decades. The continuous growth causes an evolution of several new applications such as video conferencing, <b>video</b> e-mail, <b>mobile</b> <b>video,</b> video streaming over internet, and sign language <b>video</b> <b>communication,</b> etc. To transmit video over internet or wireless networks, such applications needs digital video coding algorithm such that video could be compressed to meet bandwidth requirements. In this paper, {{we focus on the}} study of motion estimation and compensation in sign language video coding. We discuss and identify the approach of utilizing such motion information of sign language video for efficient sign language <b>video</b> <b>communication</b> applications...|$|R
50|$|On Jan. 13, 2011, Syniverse {{became a}} private {{corporation}} after being acquired by {{an affiliate of}} The Carlyle Group for approximately $2.6 billion. Shortly thereafter at Mobile World Congress 2011 in Barcelona, Spain, Syniverse unveiled its <b>Mobile</b> <b>Video</b> Broadcast Service, the industry’s first <b>video</b> <b>communication</b> solution that is interoperable across platforms, devices and networks. This service enables an operator’s subscribers to send live <b>video</b> to <b>mobile</b> handsets, PCs and social networks, delivering live peer-to-peer <b>video</b> <b>communication</b> as easily as sending an SMS.|$|R
40|$|For {{communication}} using digital video, compression {{is mandatory}} {{because of the}} high bit-rate requiring a large bandwidth or storage capacity. Recent developments as well as upcoming standards like MPEG- 4, use not images but so-called video objects having an arbitrary shape. The contour of this shape has to be transmitted and therefore compressed as well. In <b>mobile</b> <b>video</b> <b>communication</b> transmission errors and loss of data will occur and this means that the compression has to be error-robust. This paper discusses the errorrobustness of a technique for contour coding using polar coordinates and the Discrete Cosine Transform (DCT). The recently proposed [11] polar technique transforms the Cartesian...|$|E
40|$|This video {{describes}} a cooperative design workshop on future <b>mobile</b> <b>video</b> <b>communication</b> for deaf people using sign language. One issue {{was to explore}} how {{an idea for a}} mobile interpretation-on-the-fly service could be designed for collaboration and communication. Besides the deaf sign-language users, other stakeholders participated, for example service providers and mobile phone manufacturers. The workshop started with users' narratives of their daily life. We encouraged them to narrate collaboration and communication situations that they had conceived as problematic. During the discussions after the stories were told ideas for solutions were constructed. Thereafter all participants collaborated in constructing video-prototypes, i. e. staged and videotaped visual representations of the ideas for solutions. The workshop methodology provided the telephone manufacturers, service-providers, etc. with first hand experience of the narrations and they brought the video prototypes into their own organizations for further development. QC 2012030...|$|E
40|$|Abstract—The primary {{challenge}} to enabling real-time twoway video conferencing {{on a cell}} phone is overcoming the limited bandwidth, computation and power. The goal of the MobileASL project is to enable access for people who use American Sign Language (ASL) to an off-the-shelf mobile phone through the implementation of real-time <b>mobile</b> <b>video</b> <b>communication.</b> The enhancement of processor, bandwidth, and power efficiency is investigated through SIMD optimization; region-of-interest encoding based on skin detection; video resolution selection (used to determine the best trade off between frame rate and spatial resolution); and variable frame rates based on activity recognition. Our prototype system is able to compress, transmit, and decode 12 - 15 frames per second in real-time and produce intelligible ASL at 30 kbps. Furthermore, we can achieve up to 23 extra minutes of talk time, or a 8 % gain over the battery life of the phone, through our frame dropping technique. I...|$|E
40|$|This paper {{gives an}} {{overview}} over {{recent advances in}} video compression and transmission. The new H. 263 video compression standard is an important milestone towards wide-spread use of personal <b>video</b> <b>communication.</b> For <b>mobile</b> <b>video</b> applications and video transmission over networks, error robustness and scalability are important issues. Structure-from-motion methods, region-based coding and model-based coding are research topics pointing into the future, towards MPEG- 4. 1...|$|R
40|$|Robust <b>video</b> <b>communication</b> for {{hand-held}} devices is {{a demanding}} problem {{because of a}} complexity constrained environment. Effective error control techniques suitable for H. 264 /AVC in such a complexity constrained conversational environment are proposed and evaluated by extensive subjective testing. Based {{on the results of}} the tests, suitable error control techniques are identified for the given application scenario that ensure an enhanced quality of service (QoS). Index Terms — <b>Mobile</b> <b>video,</b> subjective testing, feedback, error tracking, subsequence...|$|R
40|$|With {{the fast}} growing {{high data rate}} networks, such as UMTS, new {{communication}} types are provided by <b>mobile</b> commu-nication providers. <b>Video</b> <b>communication</b> as well as broadcast over DVB-H are only two examples of these new services. Video messages created from enhanced text messages also belongs to these new services. In this context, we have devel-oped a complete system for the automatic creation of talking head video sequences from text messages like SMS. Our system converts the text into MPEG- 4 Facial Animation Parameters and synthetic voice. A user selected 3 D character will perform lip movements synchronized to the speech. The 3 D models created from a single image vary from realistic people to cartoon characters. A voice selection for different languages and gender {{as well as a}} pitch shift component enables a personalization of the animation. The animation is shown using the 3 GPP player of mobile devices. Therefore, our system can be used in mobile communication for the conversion of regular SMS messages to MMS animations. ...|$|R
40|$|As well known, Wyner-Ziv codec has low {{encoding}} complexity, while AVS codec has low decoding complexity. In this paper, {{our goal}} is to get benefits from both AVS and Wyner-Ziv to fit well some applications, such as <b>mobile</b> <b>video</b> <b>communication.</b> We propose a fast video transcoder from Wyner-Ziv to AVS. The transcoder design aims at reducing encoding complexity of AVS. Taking into account that mode decision in AVS is very time-consuming, in the proposed scheme, we discard the mode decision and directly re-use the corresponding decision results of Wyner-Ziv decoder. At the same time, motion estimation in AVS encoder is speeded up by using the derived motion vectors in Wyner-Ziv decoder as searching origins. Then motion vector refinement is performed to further improve the accuracy of motion estimation in the transcoder. Experimental results demonstrate that the proposed transcoder can significantly reduce the encoding complexity of AVS, and meanwhile provide close compression performance compared with that can be achieved by performing mode decision and a full-scale motion search. © 2010 Springer-Verlag...|$|E
40|$|Modern {{wireless}} mobile {{devices have}} evolved to small computers that can render multimedia content, while desktop/laptop computers have become more computationally powerful with faster Internet access. As these computing devices getting more popular, users demand for more and higher quality videos in many communication applications, where clients are heterogeneous in terms of network bandwidth and computing power. The goal of this thesis is to improve client perceived-quality of various video communication systems by adopting scalable video coding tools that enable efficient rate adaptation. We seek to understand scalable coding standards and design optimization and streaming algorithms {{to make the best}} possible use of them in practical systems. We consider practical problems of video communication systems in three different environments: Internet streaming systems, TV broadcast networks, and <b>mobile</b> <b>video</b> <b>communication</b> systems. We propose efficient algorithms to solve the considered problems. We evaluate the proposed algorithms using numerical methods and/or simulations. Most importantly, we design and implement testbeds to validate our algorithms. The expected results of applying our algorithms to video communication systems are better video quality and higher user satisfaction as well as better bandwidth utilization and lower processing overhead...|$|E
40|$|Masters of ScienceThis thesis {{offers some}} prototypes to provide {{browser-based}} and <b>mobile</b> <b>video</b> <b>communication</b> services for Deaf people and evaluates these prototypes. The {{aim of this}} research is to identify an acceptable video communication technology for Deaf people by designing and evaluating several prototypes. The goal is to find one that Deaf people would like to use in their day-to-day life. The thesis focuses on two technologies | browser-based systems and mobile applications. Several challenges emerged, for example, specific Deaf user requirements are difficult to obtain, the technical details must be hidden from end users, and evaluation of prototypes includes both technical and social aspects. This thesis describes work to provide South African Sign Language communication for Deaf users in a disadvantaged Deaf community in Cape Town. We posit an experimental design to evaluate browser-based and mobile technologies in order to learn what constitutes acceptable video communication for Deaf users. Two browser-based prototypes and two mobile prototypes were built to this effect. Both qualitative data and quantitative data are collected with user tests to evaluate the prototypes. The video quality of Android satisfies Deaf people, and the portable asynchronous communication is convenient for Deaf users. The server performance is low on bandwidth, and will therefore cost less than other alternatives, although Deaf people feel the handset is costly. South Afric...|$|E
40|$|This paper {{focus on}} the {{organization}} of social action in a specific setting of distant work meeting openings. Early Conversation Analysis studies focused on openings in landline telephone. Further developments found differences in mobile phone with specifics sequences. In distant meetings, findings focused on dispositive where the multimodality is more pregnant such as videoconference or telepresence. Yet, webconference, where a computer & a telephone are used, is a privileged place to analyze {{the emergence of new}} forms of social encounter, where the material resource & social configuration reshape sequential order. To that end, this presentation is based on a collection of video recordings of webconference openings produced during field work in two departments of a company based in different locations. A conversation analysis perspective is used here to show in detail the emergent collective accomplishment of openings taking into account the technological context. I will point out that in webconference openings the answerers from an opening adopt a greeting response to the summons that include a term of address (which is not a toponym like in multipoint <b>video</b> <b>communication).</b> As a multiparty conversation, I will show how the answer to the summons is not systematically made relevant by prior turn and depend on the sequential placement of the summons in the course of action. Openings in webmeetings differ from landline telephone, <b>mobile</b> phone or <b>video</b> <b>communication</b> ones. Those new practices reflect how participants orient themselves to new configurations and affordances that technologies allow them...|$|R
40|$|Wireless <b>video</b> <b>communication</b> is {{becoming}} increasingly popular these days with new applications such as TV on <b>mobile</b> and <b>video</b> phones. Commercial success of these applications requires superior video quality at the receiver. So {{it is imperative to}} analyze the effect of a wireless channel on a video transmission. The aim of this research is to analyze the video transmission over Rayleigh fading channels for various bit error rates (BER), signal to noise ratios (Eb/N 0) and Doppler rates, and to suggest which source coding scheme is best at which BER, Eb/N 0 and Doppler rates. Alternative schemes such as hybrid (digital/analog) schemes were considered and their performances were compared with pure digital communication. It is also shown that the combination of digital and analog <b>video</b> <b>communication</b> does not yield any better performance compared to pure digital <b>video</b> <b>communication...</b>|$|R
40|$|In this {{tutorial}} paper, {{we consider}} the effect of errors in compressed video data, and discuss both standard and more novel techniques for increasing error resilience. We consider the performance of block based coding schemes such as MPEG 1, MPEG 2, and h. 26 x when transmitted over noisy channels, a subject of relevance to digital terrestrial television, <b>video</b> <b>communication,</b> <b>mobile</b> digital <b>video,</b> and video storage...|$|R
40|$|Digital Object Identifier 10. 1109 /TCSVT. 2005. 846433 Mobile devices {{performing}} video coding and streaming over wireless {{and pervasive}} communication networks {{are limited in}} energy supply. To prolong the operational lifetime of these devices, an embedded video encoding system {{should be able to}} adjust its computational complexity and energy consumption as demanded by the situation and its environment. To analyze, control, and optimize the rate-distortion (R-D) behavior of the wireless video communication system under the energy constraint, we develop a power-rate-distortion (PR-D) analysis framework, which extends the traditional R-D analysis by including another dimension, the power consumption. Specifically, in this paper, we analyze the encoding mechanism of typical video coding systems, and develop a parametric video encoding architecture which is fully scalable in computational complexity. Using dynamic voltage scaling (DVS), an energy consumption management technology recently developed in CMOS circuits design, the complexity scalability can be translated into the energy consumption scalability of the video encoder. We investigate the R-D behavior of the complexity control parameters and establish an analytic P-R-D model. Both theoretically and experimentally, we show that, using this P-R-D model, the video coding system is able to automatically adjust its complexity control parameters to match the available energy supply of the mobile device while maximizing the picture quality. The P-RD model provides a theoretical guideline for system design and performance optimization in <b>mobile</b> <b>video</b> <b>communication</b> under energy constraints...|$|E
40|$|Thesis (Ph. D.) [...] University of Washington, 2014 The {{proliferation}} of mobile devices {{is greater than}} ever; however, bandwidth and battery life have not grown accordingly to support mainstream use of <b>mobile</b> <b>video</b> <b>communication.</b> This dissertation contributes to the continued effort of making mobile sign language communication more accessible and affordable to deaf and hard-of-hearing people. I am optimizing the lower limits at which mobile sign language can be transmitted to reduce bandwidth and battery life, while maintaining intelligibility. This work presents the Human Signal Intelligibility Model (HSIM) to address the lack of uniformity {{in the way that}} intelligibility and comprehension are operationalized for evaluation. The HSIM influenced the design of four web studies: (1) investigating perceived intelligibility of sign language video transmitted at various low frame rates and low bit rates below the current recommended video transmission standards as prescribed in the International Telecommunication Standardization Sector (ITU-T) Q. 26 / 16 (at least 25 fps and 100 kbps); (2) investigating the relationship between response-time and video intelligibility, which {{led to the creation of}} the Intelligibility Response-Time Method; (3) evaluating perceived video quality of different power saving algorithms utilizing qualities unique to sign language; and (4) comparing objective video quality measures to subjective responses. Results revealed an "intelligibility ceiling effect" for video transmission rates, where increasing the frame rate above 10 fps and bit rate above 60 kbps did not improve perceived video intelligibility. These findings suggest that the recommended ITU-T sign language transmission rates can be relaxed while still providing intelligible American Sign Language (ASL) video, thereby reducing bandwidth and network load. I conducted a laboratory study in which pairs of fluent ASL signers held free-form conversations over an experimental smartphone app transmitting video at frame rates and bit rates well below the ITU-T standard, to investigate how fluent ASL signers adapt to the lower video transmission rates. Participants were successful in holding intelligible conversations across all frame rates, even though they perceived the lower quality of video transmitted at 5 fps/ 25 kbps. Also, video transmitted at 10 fps/ 50 kbps or higher was not found to significantly improve video intelligibility, which corroborates with web study findings. Finally, I conducted a field study observing everyday use of an experimental smartphone app transmitting video at rates below the ITU-T standard. The field study revealed that gathering in-the-moment information using mobile video chat was preferred over texting because of the faster response-time. Taken together, the findings from this dissertation support the recommendation that intelligible mobile sign language conversations can occur at video transmission rates far below the ITU-T standard to optimize resources consumption, video intelligibility, and user preferences. The thesis of my dissertation is: Mobile sign language video transmitted at frame rates and bit rates below recommended standards (ITU-T vs. 10 fps/ 50 kbps), which saves bandwidth and battery life by about 30 minutes, is still intelligible and can facilitate real-time <b>mobile</b> <b>video</b> <b>communication.</b> </italic...|$|E
40|$|An {{experimental}} {{investigation of}} an M level (M = 16, 64 and 256) Quadrature Amplitude Modulation (QAM) transmission system suitable for video transmission is presented. The communication system {{is based on}} layered video coding and unequal error protection to make the video bitstream robust to channel errors. An implementation is described in which H. 264 video is protected unequally by partitioning the compressed data into two layers of different visual importance. The partition scheme {{is based on a}} separation of the group of pictures (GoP) in the intra-coded frame (I-frame) and predictive coded frame (P frame). This partition scheme is then applied to split the H. 264 -coded video bitstream and is suitable for Constant Bit Rate (CBR) transmission. Unequal error protection is based on uniform and non-uniform M-QAM constellations in conjunction with different scenarios of splitting the transmitted symbol for protection of the more important information of the video data; different constellation arrangements are proposed and evaluated to increase the capacity of the high priority layer. The performance of the transmission system is evaluated under Additive White Gaussian Noise (AWGN) and Rayleigh fading conditions. Simulation results showed that in noisy channels the decoded video can be improved by assigning a larger portion of the video data to the enhancement layer in conjunction with non-uniform constellation arrangements; in better channel conditions the quality of the received video can be improved by assigning more bits in the high priority channel and using uniform constellations. The aforementioned varying conditions can make the video transmission more successful over error-prone channels. Further techniques were developed to combat various channel impairments by considering channel coding methods suitable for layered video coding applications. It is shown that a combination of non-uniform M-QAM and forward error correction (FEC) will yield a better performance. Additionally, antenna diversity techniques are examined and introduced to the transmission system that can offer a significant improvement in the quality of service of <b>mobile</b> <b>video</b> <b>communication</b> systems in environments that can be modelled by a Rayleigh fading channel...|$|E
40|$|Chair of Advisory Committee: Dr. Scott Miller Wireless <b>video</b> <b>communication</b> is {{becoming}} increasingly popular these days with new applications such as TV on <b>mobile</b> and <b>video</b> phones. Commercial success of these applications requires superior video quality at the receiver. So {{it is imperative to}} analyze the effect of a wireless channel on a video transmission. The aim of this research is to analyze the video transmission over Rayleigh fading channels for various bit error rates (BER), signal to noise ratios (Eb/N 0) and Doppler rates, and to suggest which source coding scheme is best at which BER, Eb/N 0 and Doppler rates. Alternative schemes such as hybrid (digital/analog) schemes were considered and their performances were compared with pure digital communication. It is also shown that the combination of digital and analog <b>video</b> <b>communication</b> does not yield any better performance compared to pure digital <b>video</b> <b>communication.</b> iii DEDICATION To my loving parent...|$|R
40|$|<b>Mobile</b> <b>video</b> {{is now an}} {{everyday}} possibility with {{a wide array of}} commercially available devices, services and content. These technologies promise to transform the way that people can consume video media in their lives beyond the familiar behaviours associated with fixed TV and video technologies. Building upon earlier studies of <b>mobile</b> <b>video,</b> this paper reports on a study using diary techniques and ethnographic interviews to better understand how people are using commercially available <b>mobile</b> <b>video</b> technologies in their everyday lives. Drawing on reported episodes of <b>mobile</b> <b>video</b> behaviour, the study identifies the social motivations and values underpinning these behaviours that help characterise <b>mobile</b> <b>video</b> consumption beyond the simplistic notion of viewing TV to kill time wherever you may be. Implications for adoption and design of <b>mobile</b> <b>video</b> technologies and services are discussed. Author Keywords <b>Mobile</b> <b>video,</b> <b>mobile</b> TV, diary study, interviews, mobility...|$|R
50|$|During the dot com boom O’Ferrall {{launched}} a <b>mobile</b> <b>video</b> portal (<b>Mobile</b> Media Club) whilst at Nokia Ventures and Oplayo <b>Mobile</b> <b>Video.</b>|$|R
