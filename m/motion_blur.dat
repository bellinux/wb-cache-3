1276|289|Public
5|$|The game's visuals and {{spectacle}} were lauded {{by critics}} who suspected {{that it would}} amaze players. Reed questioned {{whether it was the}} best looking game to have ever been made. Critics observed that the use high frame rate and <b>motion</b> <b>blur</b> helped convey an incredible sense of speed. Other aspects such particle effects, reflections, and real-time deformation drew praise as well. Critics expressed approval over the sound design of the cars and collisions. However opinions of the licensed soundtrack and DJ were less favourable. Some writers found the DJ's enthusiastic dialogue to be annoying and had mixed opinions on the songs included in the soundtrack, but were thankful for the available audio customisation options.|$|E
5|$|Enter the Voids {{post-production}} process lasted {{more than}} a year. Work on the digital effects was led by Pierre Buffin of BUF Compagnie. Every scene in the film includes computer-generated imagery (CGI)—even the flashback scenes, where the backdrops were digitally altered. Studio scenes, helicopter shots, and CGI were forged together in the hovering sequences with the intention that the viewer should be unable to determine which is which. For shots from high altitudes, the team started with helicopter footage from video, and then created computer models of the neighbourhoods with textures from photographs. Neon lights, reflections, and dark areas were consistently accentuated. Flickers were created through a mixture of <b>motion</b> <b>blur,</b> chromatic aberration, and focus effects. For scenes seen as through a fisheye lens, the team recreated the sets digitally and progressively increased the environments' reflection values along with the lens effect.|$|E
5|$|To {{promote the}} game, Valve has {{produced}} three machinima trailers depicting {{the game in}} play. The trailers are themed around wartime propaganda news reports for both Germany and the United States. To convey this effect, the trailers make extensive usage of the Source engine's capabilities for film grain, color correction, <b>motion</b> <b>blur</b> and depth of field, as well as sepia toning. The first trailer was released {{as part of the}} game's post-release marketing on December 20, 2005. Entitled Prelude to Victory, the trailer depicted a large firefight in the game as a report from the German perspective, complete with a commentator speaking in the German language. Two further trailers were released to promote the major update to Day of Defeat: Source {{in the second quarter of}} 2006. The trailers, both from the American viewpoint, displayed how the new detonation gameplay worked, emphasising teamwork as the key to success, as well as introducing the viewer to the two new maps added by the update. To further create interest in the game, Valve has opened Day of Defeat: Source to three free weekends, the first taking place on February 10, 2006, the second on July 8, 2006 and the third on July 4, 2008, where anyone with a Steam account could download and play the game for a maximum of 48 hours free of charge.|$|E
40|$|Conference Name:International Symposium on Information Science and Engineering. Conference Address: Shanghai, PEOPLES R CHINA. Time:DEC 20 - 22, 2008. Based on {{the models}} of image <b>motion</b> <b>{{blurring}}</b> and restoring, the element of image blurring caused by rotation motion is analyzed. Three widely used methods for the identification of blurred extent from the rectilinear <b>motion</b> <b>blurred</b> images, Fourier transform, error-parameter curve, and autocorrelation, are introduced in rotation <b>motion</b> <b>blurred</b> image analysis. The feasibility and effectiveness of the above methods' introduction are demonstrated. The computer simulation results prove that the autocorrelation algorithm is effective to identify the blurred extent of the rotation <b>motion</b> <b>blurred</b> images...|$|R
40|$|Abstract. Recovery of {{degraded}} images due to <b>motion</b> <b>blurring</b> is {{a challenging}} problem in digital imaging. This paper presents a new method of Dirac Delta function algorithm to restore <b>motion</b> <b>blurred</b> images {{based on an}} analysis of the characteristics of the inverse filter method and the traditional algebraic method. Experimental results show that the new method is effective in performing <b>motion</b> <b>blurred</b> images at arbitrary direction restoration and extensively validated with different amount of noise in the images...|$|R
40|$|Abstract—Recovery of {{degraded}} images due to <b>motion</b> <b>blurring</b> is {{a challenging}} problem in digital imaging. This paper presents a new method of Dirac Delta function algorithm to restore <b>motion</b> <b>blurred</b> images {{based on an}} analysis of the characteristics of the inverse filter method and the traditional algebraic method. Experimental results show that the new method is effective in performing <b>motion</b> <b>blurred</b> images at arbitrary direction restoration and extensively validated with different amount of noise in the images. Keywords-Motion blurred images; Dirac Delta function; Inverse filter I...|$|R
5|$|Type-0 HD was {{released}} on March 17, 19 and 20, 2015 for North America, Japan and Europe respectively. It came with both English and Japanese voice tracks for all regions. The game included a demo of Final Fantasy XV, titled Final Fantasy XV: Episode Duscae. The demo was only available in limited quantities: it was exclusive to physical first-print editions, and came with the digital edition for two months after release. The collector's edition, available through Square Enix's online store and at Amazon.com, came with a special CD featuring tracks from Type-0 and Agito, a calendar featuring official artwork, a Vermillion Peristylium ID card, a set of five cards modeled after those used by Ace in battle, and a cadet scarf. Limited editions of the game were produced for North America and Europe, for sale at selected high street and online stores. A PlayStation 4 hardware bundle was also produced for Japan, featuring {{a copy of the}} game and download code for the XV demo along with a console themed after the game. A port to Microsoft Windows via Valve Corporation's Steam platform was developed. This port was created in response to fan demands for a PC version. In contrast to the console version, the PC port allowed graphic adjustments, and included fixes for camera control and <b>motion</b> <b>blur</b> issues raised by players and reviewers after release. The port {{was released}} on August 18, 2015. As part of the promotion for the port, Final Fantasy-themed pre-order gifts for use in Dota 2 were created.|$|E
5|$|The {{game was}} {{initially}} going to feature online elements, offered through Square's PlayOnline service. The features, however, were dropped during production, and online gaming would not {{become part of}} the Final Fantasy series until Final Fantasy XI. Map director Nakazato wanted to implement a world map concept with a more realistic approach than that of the traditional Final Fantasy game, in line with the realism of the game's 3D backgrounds, as opposed to pre-rendered backgrounds. As a player of the games in the Final Fantasy series, battle director Tsuchida wanted to recreate elements he found interesting or entertaining, which eventually led to the removal of the Active Time Battle system, and instead, incorporated the strategy-focused Conditional Turn-Based Battle system. Originally, Final Fantasy X was going to feature wandering enemies visible on the field map, seamless transitions into battles, and the option for players to move around the landscape during enemy encounters. Battle art director Shintaro Takai has explained that it was his intention that battles in Final Fantasy X come across as a natural part of the story and not an independent element. However, due to hardware limitations, this idea was not used. Instead, a compromise was made, whereby some transitions from the field map to the battle map were made relatively seamless with the implementation of a <b>motion</b> <b>blur</b> effect that would happen {{at the end of an}} event scene. The desire for seamless transitions also led to the implementation of the new summoning system seen in the game. Kitase has explained that the purpose behind the Sphere Grid is to give players an interactive means of increasing their characters' attributes, such that they will be able to observe the development of those attributes firsthand. The developers experienced difficulty with the scene of Tidus and Yuna kissing, as they were not used to animating romance scenes. Visual Works director Kazuyuki Ikumori stated that this was due to the use of 3D models in the scene. Because of the negative response from female members of staff, the scene was remade multiple times.|$|E
25|$|GIMP has {{approximately}} 150 standard {{effects and}} filters, including Drop Shadow, Blur, <b>Motion</b> <b>Blur</b> and Noise.|$|E
40|$|Goal of {{this thesis}} is restauration of <b>motion</b> <b>blurred</b> images. <b>Motion</b> blurr {{is assumed to}} be only over a narrow line rotated by any angle to x axis. There are several methods which are {{theoretically}} explained and compared on synthetically blurred images in several different conditions. After that <b>motion</b> <b>blurred</b> images are restaurated with some of deconvolution methods...|$|R
3000|$|... are a {{depth and}} an opacity of a surface. To render <b>motion</b> <b>blurred</b> shadows, authors assign a random time for each sample and all samples {{at the same}} depth are {{averaged}} together to an opacity of a surface. Therefore, such surfaces are regarded as transparent blockers. This approach only works for static receivers. As receiver moves, the time dimension is collapsed and <b>motion</b> <b>blurred</b> shadows are rendered incorrectly.|$|R
30|$|A {{brute force}} method renders a scene with shadow {{many times and}} then averages the results to produce correct <b>motion</b> <b>blurred</b> shadows. However, this {{approach}} is extremely slow, {{so it is not}} suitable for the real-time rendering. Stochastic sampling based approaches use multi-samples per pixel, with each sample has a unique random time, to render <b>motion</b> <b>blurred</b> shadows. However, time mismatch when generating and sampling a shadow map causes visual artifacts.|$|R
25|$|Character {{animations}} {{were created}} by Blizzard's David Gibson. To help give more personality to the 3D-rendered animation, Gibson applied traditional methods used in 2D limited animation, such as smear animation, instead of relying on <b>motion</b> <b>blur</b> effects, creating more exaggerated animations that support {{the feel of the}} game.|$|E
25|$|For general photography, {{diffraction}} at DOF limits typically becomes significant only at {{fairly large}} f-numbers; because large f-numbers typically require long exposure times, <b>motion</b> <b>blur</b> may cause greater loss of sharpness than the loss from diffraction. The {{size of the}} diffraction blur spot depends on the effective f-number , however, so diffraction is a greater issue in close-up photography, and the tradeoff between DOF and overall sharpness can become quite noticeable (Gibson 1975, 53; Lefkowitz 1979, 84).|$|E
25|$|The aim {{of image}} {{restoration}} is {{the removal of}} noise (sensor noise, <b>motion</b> <b>blur,</b> etc.) from images. The simplest possible approach for noise removal is various types of filters such as low-pass filters or median filters. More sophisticated methods assume a model of how the local image structures look like, a model which distinguishes them from the noise. By first analysing the image data {{in terms of the}} local image structures, such as lines or edges, and then controlling the filtering based on local information from the analysis step, a better level of noise removal is usually obtained compared to the simpler approaches.|$|E
50|$|This {{effect can}} also be used to create <b>motion</b> <b>blurs,</b> as seen in The Matrix when {{characters}} dodge bullets.|$|R
3000|$|... (i) {{from only}} the <b>motion</b> <b>blurred</b> LR frames y. Furthermore, it is {{difficult}} to represent the original HR frame x [...]...|$|R
40|$|Human age can be {{employed}} in many useful real-life applications, such as customer service systems, automatic vending machines, entertainment, etc. In order to obtain age information, image-based age estimation systems have been developed using information from the human face. However, limitations exist for current age estimation systems because of the various factors of camera <b>motion</b> and optical <b>blurring,</b> facial expressions, gender, etc. <b>Motion</b> <b>blurring</b> can usually be presented on face images by {{the movement of the}} camera sensor and/or the movement of the face during image acquisition. Therefore, the facial feature in captured images can be transformed according to the amount of motion, which causes performance degradation of age estimation systems. In this paper, the problem caused by <b>motion</b> <b>blurring</b> is addressed and its solution is proposed in order to make age estimation systems robust to the effects of <b>motion</b> <b>blurring.</b> Experiment results show that our method is more efficient for enhancing age estimation performance compared with systems that do not employ our method...|$|R
25|$|Cubist and Futurist devices appear {{superimposed}} in Metzinger's At the Cycle-Race Track, {{creating an}} image that is readable yet essentially anti-naturalistic. Cubist elements include {{the reduction of the}} geometric schema to simplified shapes, and the juxtaposition of rotating planes to define spatial qualities, printed-paper collage, the incorporation of a granular surface and multiple perspective. Parallels with Futurism include the choice of a subject in motion (the bicyclist), the suggestion of velocity (<b>motion</b> <b>blur</b> on the wheel spokes), and the fusing of forms in a static picture plane. Metzingers's work integrates the idea of an aesthetic generated by the modern myth of the machine and speed.|$|E
25|$|In many cases, the DOF {{is fixed}} by the {{requirements}} of the desired image. For a given DOF and field of view, the required f-number is proportional to the format size. For example, if a 35mm camera required 11, a 4×5 camera would require 45 to give the same DOF. For the same ISO speed, the exposure time on the 4×5 would be sixteen times as long; if the 35camera required 1/250 second, the 4×5 camera would require 1/15 second. The longer exposure time with the larger camera might result in <b>motion</b> <b>blur,</b> especially with windy conditions, a moving subject, or an unsteady camera.|$|E
25|$|Response time: OLEDs {{also have}} a much faster {{response}} time than an LCD. Using response time compensation technologies, the fastest modern LCDs can reach response times as low as 1 ms for their fastest color transition, and are capable of refresh frequencies as high as 240nbsp&Hz. According to LG, OLED response times are up to 1,000 times faster than LCD, putting conservative estimates at under 10 μs (0.01 ms), which could theoretically accommodate refresh frequencies approaching 100nbsp&kHz (100,000nbsp&Hz). Due to their extremely fast response time, OLED displays can also be easily designed to be strobed, creating an effect similar to CRT flicker {{in order to avoid}} the sample-and-hold behavior seen on both LCDs and some OLED displays, which creates the perception of <b>motion</b> <b>blur.</b>|$|E
40|$|Visual {{tracking}} {{plays an}} important role in many computer vision tasks. A common assumption in previous methods is that the video frames are blur free. In reality, <b>motion</b> <b>blurs</b> are pervasive in the real videos. In this paper we present a novel BLUr-driven Tracker (BLUT) framework for tracking motion-blurred targets. BLUT actively uses the information from blurs without performing deblurring. Specifically, we integrate the tracking problem with the motion-from-blur problem under a unified sparse approximation framework. We further use the motion information inferred by blurs to guide the sampling process in the particle filter based tracking. To evaluate our method, we have collected a large number of video sequences with significant <b>motion</b> <b>blurs</b> and compared BLUT with stateof-the-art trackers. Experimental results show that, while many previous methods are sensitive to <b>motion</b> <b>blurs,</b> BLUT can robustly and reliably track severely blurred targets. 1...|$|R
30|$|This {{simulation}} {{study suggests}} that the MR-based motion-correction method using PET-MR greatly reduces <b>motion</b> <b>blurring</b> on parametric images and yields less K 1 bias without increasing noise level.|$|R
3000|$|... frames (Fig. 3). This {{effectively}} {{leads to}} <b>motion</b> <b>blurring</b> of the targets as mentioned before. To simulate the oversensing case, the collection interval {{is reduced to}} T [...]...|$|R
25|$|Ladislas Starewitch died on 26 February 1965, {{while working}} on Comme chien et chat (Like Dog and Cat). He {{was one of the}} few European animators to be known by name in the United States before the 1960s, largely on account of La Voix du rossignol and Fétiche Mascotte (The Tale of the Fox was not widely {{distributed}} in the US). His Russian films were known for their dark humor. He kept every puppet he made, so stars in one film tended to turn up as supporting characters in later works (the frogs from The Frogs Who Wanted a King are the oldest of these). For example, in Fétiche mascotte (1933) we can see puppets from The Scarecrow, The Little Parade, and The Magical Clock. The films are united, incredible imagination and development of techniques, like <b>motion</b> <b>blur,</b> replacement animation, multiple frame exposing, and reverse shooting.|$|E
25|$|Hansma (1996) and Peterson (1996) have {{discussed}} determining the combined effects of defocus and diffraction using a root-square {{combination of the}} individual blur spots. Hansma's approach determines the f-number that will give the maximum possible sharpness; Peterson's approach determines the minimum f-number that will give the desired sharpness in the final image, and yields a maximum focus spread for which the desired sharpness can be achieved.-number, though such an expression obtains from simple algebraic manipulation of his Equation3. In combination, the two methods {{can be regarded as}} giving a maximum and minimum f-number for a given situation, with the photographer free to choose any value within the range, as conditions (e.g., potential <b>motion</b> <b>blur)</b> permit. Gibson (1975), 64) gives a similar discussion, additionally considering blurring effects of camera lens aberrations, enlarging lens diffraction and aberrations, the negative emulsion, and the printing paper. Couzin (1982) gave a formula essentially the same as Hansma's for optimal f-number, but did not discuss its derivation.|$|E
500|$|Syndicate uses Starbreeze's {{in-house}} game engine, {{which had}} been modified {{for the creation of}} the game. The team used Beast to achieve global illumination and a realistic lighting system, and a new physics solver to deliver more physical interactions. The team aimed to maintain a consistent visual quality on all the platforms on which the game was released, even though the PC version had the advantage of [...] higher resolution and frame rate. The engine allowed the inclusion of post-process-effects previously used in Assault on Dark Athena, such as <b>motion</b> <b>blur</b> and depth of field. Their artstyle was changed to suit the game's overall style.|$|E
40|$|In {{order to}} see under low light {{conditions}} nocturnal insects rely on neural strategies based on combinations of spatial and temporal summations. Though these summation techniques when modelled are effective in {{improving the quality of}} low light images, using the temporal summation in scenes where image velocity is high only come at a cost of <b>motion</b> <b>blurring</b> in the output scenes. Most recent research has been towards reducing <b>motion</b> <b>blurring</b> in scenes where motion is caused by moving objects rather than effectively reducing <b>motion</b> <b>blurring</b> in scenes where motion is caused by moving cameras. This makes it impossible to implement the night vision algorithm in moving robots or cars that operate under low light conditions. In this paper we present a generic new method that can replace the normal temporal summation in scenes where motion is detected. The proposed method is both suitable for motion caused by moving objects as well as moving cameras. The effectiveness of this new generic method is shown with relevant supporting experiments...|$|R
40|$|This paper {{presents}} a novel blind motion deblurring algorithm {{for dealing with}} non-uniform <b>motion</b> <b>blurs</b> caused by camera shakes. Conventional motion deblurring algorithms assume the blur can be described by a uniform point spread function (PSF). However, this assumption is typically invalid in practice. We exploit a new representation of <b>motion</b> <b>blurs</b> which models the blur effects of camera shakes using a set of planar perspective projections (i. e., homographies). This representation can fully describe the motions of camera shakes in 3 D world which cause non-uniform <b>motion</b> <b>blurs.</b> Our main contribution is the blind motion deblurring algorithm associated with this representation. We solve the ill-posed PSF estimation problem by transforming it into a well-posed image registration problem that estimates homographies. To improve the robustness and to resolve the initialization problem of our algorithm, we use multiple input images for deblurring. Our algorithm is experimented with both synthetic and real world examples, and produces superior deblurring results compared to the previous algorithms using a uniform PSF...|$|R
40|$|Conference Name:International Conference on Materials Engineering for Advanced Technologies (ICMEAT 2011). Conference Address: Singapore, SINGAPORE. Time:MAY 05 - 06, 2011. This paper first {{introduces}} {{the history and}} research status of motion-blurred image restoration, and then establishes a rotating image degradation model. we present a fast algorithm for real-time hardware restoration of rotating <b>motion</b> <b>blurred</b> images, the algorithm is simulated and experimental platform is built for the actual verification. Through comparison {{and analysis of the}} recovery results, we verify the accuracy of the algorithm, and it shows that this rotational <b>motion</b> <b>blurred</b> image restoration algorithm can receive satisfactory results...|$|R
500|$|Dunlop {{had been}} seeking {{contract}} work {{when he was}} hired by Jones. Glancy was working at a computer shop in Scotland when he met Dunlop, who was working on Walker at the time. [...] "I had been working on pixel art games and projects for some years so offered to create an entire set of level graphics for the game", Glancy said. The Terminator (1984) and Akira (1988) influenced Glancy's design work, which he described as [...] "the most complex pixel graphics [...] had ever made", due to the addition of <b>motion</b> <b>blur</b> and dynamic lighting. While Jones was impressed by Glancy's designs, he selected alternative designs by the art department at DMA Design because Glancy was not an employee.|$|E
500|$|The {{graphics}} {{were highlighted}} positively. Kasavin {{was impressed with}} the amount of lighting and <b>motion</b> <b>blur</b> effects, and noted that the [...] "excellent character animation helps make the guns feel as powerful as they look." [...] Bryn Williams of GameSpy considered the graphics as a [...] "stunning look at what the 360 hardware is capable of", but also admitted that the animation [...] "is a little too slow and sometimes creates an unwelcome sense of cartoonishness". IGN credited the attractive gun models, explosions, and sprawling vistas, but felt that some areas such as the South American Ruins can unnecessarily look too shiny. The game's audio was said to feature [...] "heavy-hitting weapon effects [...] fantastic, moody soundtrack that gives each mission its own pulsing rhythms".|$|E
500|$|In Remastered, {{character}} textures were {{increased by}} a factor of four, shadows were doubled and a new lighting process was implemented. The <b>motion</b> <b>blur</b> when turning the camera, used to hide slower loading textures, was reduced, and the game's environments look [...] "crisper". In addition, new settings were introduced to allow players to customize the game's audio channels, and the loading times were reduced, due to the game streaming from the hard drive as opposed to the disc. One of the biggest developmental challenges was fitting all content onto one Blu-ray Disc. The changing of the in-game textures, and the inclusion of Left Behind, were the cause for this difficulty. According to lead developer Christian Gyrling, Remastered [...] "looked broken up until a week before shipping".|$|E
50|$|Motion artifact: This {{is seen as}} {{blurring}} and/or streaking, {{which is}} caused by movement of the object being imaged. <b>Motion</b> <b>blurring</b> might be reduced using a new technique called IFT (incompressible flow tomography).|$|R
40|$|Restoring a clear {{image from}} a single motion-blurred image due to camera shake {{has long been a}} {{challenging}} problem in digital imaging. Existing blind deblurring techniques either only remove simple <b>motion</b> <b>blurring,</b> or need user interactions to work on more complex cases. In this paper, we present an approach to remove <b>motion</b> <b>blurring</b> {{from a single}} image by formulating the blind blurring as a new joint optimization problem, which simultaneously maximizes the sparsity of the blur kernel and the sparsity of the clear image under certain suitable redundant tight frame systems (curvelet system for kernels and framelet system for images). Without requiring any prior information of the blur kernel as the input, our proposed approach is able to recover high-quality images from given blurred images. Furthermore, the new sparsity constraints under tight frame systems enable the application of a fast algorithm called linearized Bregman iteration to efficiently solve the proposed minimization problem. The experiments on both simulated images and real images showed that our algorithm can effectively removing complex <b>motion</b> <b>blurring</b> from nature images. 1...|$|R
50|$|Commotion set a high {{standard}} for a rotoscoping application, introducing rotosplines and offering features like motion tracking and <b>motion</b> <b>blurring</b> for masks.It was the first desktop application to allow real-time playback of full quality video clips from RAM.|$|R
