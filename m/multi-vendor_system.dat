4|21|Public
40|$|In {{creating}} a <b>multi-vendor</b> <b>system</b> that exhibits interoperability {{there is much}} more involved that just {{creating a}} detailed unambiguous specification. The current networking infrastructure exhibits a high degree of interoperability through a combination of several factors. This paper explains some of the lessons that can be learned from this previous networking industry experience. A framework is proposed of technical specification, management process, support tools and market factors. The framework is then used to analyze four networking industry positive examples. The activities {{in each of the four}} areas of the framework will be described with emphasis on the key attribute that drove the interoperability. From these examples some of the specific techniques used will b...|$|E
40|$|The Automated Welding Manufacturing System (AWMS) is a {{research}} and development testbed for automated {{gas metal arc welding}} technology. Its activities are aimed at developing and validating standards that will contribute to increased use of automated welding technology by manufacturers. The National Institute of Standards and Technology (NIST) plans to work with technology suppliers and manufacturing users to test systems in the AWMS. Our experiments and control system designs will test the feasibility of interface standards and intelligent control technology to increase productivity, improve quality, and reduce the cost of system integration. Further, we will explore integration techniques that make <b>multi-vendor</b> <b>system</b> solutions more effective and easier to build, program, and operate...|$|E
40|$|Abstract—A {{home network}} system (HNS) {{provides}} value-added services for home users by networking house-hold appli-ances and sensors. In the conventional architecture, the HNS appliances {{and services are}} tightly coupled. It is therefore difficult for users to freely choose their favorite appliances and services. In this paper, we propose a new HNS architecture that accommodates multi-vendor services by extensively using cloud technologies. The new architecture manages individual HNS operations and data as standard services within the cloud. The vendor services must go through the cloud to access the HNS. Thus, loose coupling among the HNS and services can be achieved. As a result, the proposed architecture realizes more flexible HNS beneficial for both users and vendors. Index Terms—home network system, cloud computing, smart city, <b>multi-vendor</b> <b>system,</b> HNS services I...|$|E
50|$|Online {{shopping}} malls are websites that enable a <b>multi-vendor</b> checkout <b>system</b> enabling retailers {{to sell in}} one portal and allow the consumer to check out with one single credit card transaction.|$|R
50|$|Dorado {{was founded}} in 1998 in El Dorado Hills, California as a {{provider}} of application development environments for OEM element management systems (EMS). The company used this experience to build a <b>multi-vendor</b> management <b>system</b> that evolved into the suite of Redcell products.|$|R
40|$|Advances in {{information}} and communication technologies are expected to bring large benefits in the healthcare domain. Personal telehealth is one such example that has the potential to address some of the important challenges currently faced by healthcare such as improvement in the quality of healthcare delivery {{while at the same time}} reducing the cost. However concerns about information security and privacy are primary reasons for the lack of deployment of personal telehealth systems, besides problems with regard to safety and integration of <b>multi-vendor</b> <b>systems.</b> In this paper we present consent principles crucial to the privacy protection of individuals. Further, based on these principles, we describe consent management and enforcement functionality as outlined by the Continua Health Alliance and elaborate on how it can enable different usage scenarios with different trust levels and security requirements...|$|R
40|$|ITC/USA 2010 Conference Proceedings / The Forty-Sixth Annual International Telemetering Conference and Technical Exhibition / October 25 - 28, 2010 / Town and Country Resort & Convention Center, San Diego, CaliforniaThis paper {{describes}} {{a model of}} how to configure settings on instrumentation. For any given instrument there may be 100 s of settings that can be set to various values. However, randomly selecting values for each setting {{is not likely to}} produce a valid configuration. By "valid" we mean a set of setting values that can be implemented by each instrument. The valid configurations must satisfy a set of dependency rules between the settings and other constraints. The formalization provided allows for identification of different sets of configurations settings under control by different systems and organizations. Similarly, different rule sets are identified. A primary application of this model is {{in the context of a}} <b>multi-vendor</b> <b>system</b> especially when including vendors that maintain proprietary rules governing their systems. This thus leads to a discussion of an application user interface (API) between different systems with different rules and settings...|$|E
40|$|This case {{describes}} the strategic {{challenges faced by}} CompuNet AG in 1995. After a phenomenal expansion from being a small IBM reseller to becoming a leading <b>multi-vendor</b> <b>systems</b> integrator in Germany, the company suffered, in the 1994 / 95 fiscal year, a dramatic decrease in profits. After a company overview and a description of CompuNet's management structure, the case analyzes the critical factors (both internal and external) {{that led to the}} company's success. These include winning prestigious projects, a remarkable public relations campaign, as well as the ability to adapt to rapidly changing customer demands and to manage the increasing business complexity. The case then focuses on the business and management factors that led to the new corporate results. It concludes by raising some issues concerning the business strategy that the company should follow in order to secure a better future in an increasingly competitive environment. ...|$|R
40|$|Abstract: Ontology driven {{architecture}} has {{revolutionized the}} inference system by allowing interoperability and efficient reasoning between heterogeneous <b>multi-vendors</b> <b>systems.</b> Sound reasoning support is highly important for sound semantic web ontologies {{which can only}} be possible if state-of-the-art Description Logic Reasoners were capable enough to identify inconsistency and classify taxonomy in ontologies. We have discussed existing ontological errors and design anomalies, and provided a case study incorporating these errors. We have evaluated consis-tency, subsumption, and satisfiability of DL reasoners on the case study. Experi-ment with DL reasoners opens up number of issues that were not incorporated within their followed algorithms. Especially circulatory errors and various types of semantic inconsistency errors that may cause serious side effects need to be de-tected by DL reasoners for sound reasoning from ontologies. The evaluation of DL reasoners on Automobile ontology helps in updating the subsumption, satisfi-ability and consistency checking algorithms for OWL ontologies, especially the new constructs of OWL 1. 1. ...|$|R
40|$|Optical data links {{are used}} in {{detector}} front-end electronics readout systems of experiments in the Tevatron and the LHC. Optical links in high energy particle physics experiments usually have special requirements such as radiation tolerance, ultra high reliability and low power dissipation. These requirements are often not met by commercial components which are designed for applications in non-radiation, accessible (for maintenance) environment, and for <b>multi-vendor</b> <b>systems</b> so the parts must comply with certain standards. Future HEP experiments such as the upgrades for the sLHC call for optical links with ultra high data bandwidth, higher radiation tolerance and ultra low power dissipation. To meet these challenges and in particular those in the upgrade for the ATLAS Liquid Argon Calorimeter readout that calls for an optical link system of 100 Gbps for each front-end board, we adopted a full custom front-end electronics system design based on application specific integrated circuits. Reported here are the development and test results of two circuits: a 5 Gbps serializer and a 5 GHz phase locked loop, and a block diagram design for the 100 Gbps optical link...|$|R
40|$|In the <b>multi-vendor</b> <b>systems,</b> a {{customer}} connected to an Access network (AN) must {{be capable of}} selecting a specific Service Node (SN) according to the services the SN provides. The multiplicity of technologically varying AN calls for {{the definition of a}} standard reference point between the AN and the SN widely known as the VB interface. Two versions are currently offered. The VB 5. 1 is simpler to implement but is not as flexible as the VB 5. 2, which supports switched connections. The VB 5. 2 functionality is closely coupled to the Broadband Bearer Channel Connection Protocol (B-BCCP). The B-BCCP is used for conveying the necessary information for dynamic resource allocation, traffic policing and routing in the AN as well as for information exchange concerning the status of the AN before a new call is established by the SN. By relying on such a protocol for the exchange of information instead of intercepting and interpreting signalling messages in the AN, the architecture of the AN is simplified because the functionality related to processing is not duplicated. In this paper a prominent B- BCCP candidate is defined, called the Service node Access network Interaction Protocol. © 2005 Copyright SPIE - The International Society for Optical Engineering...|$|R
50|$|The company {{develops}} high-performance communications {{simulation software}} {{to test the}} reliability and resiliency of networks in rapidly changing environments, design new communications technology, enable virtual systems test before significant physical investment, and train network architects on the effective design of dynamic <b>multi-vendor</b> communications <b>systems.</b> More recently, the company has made a transition to cyber defense training, launching its newest product to train all types of users how to navigate cyber attacks. The company emphasizes its mixed model in which it integrates virtual network models with live physical hardware {{in all of its}} products.|$|R
40|$|Creating safe Transportation Cyber-Physical Systems (CPSs) {{presents}} {{new challenges}} as autonomous operation is attempted in unconstrained operational environments. The extremely high safety level required of such systems (perhaps one critical failure per billion operating hours) means that validation approaches {{will need to}} consider not only normal operation, but also operation with system faults and in exceptional environments. Additional challenges {{will need to be}} overcome in the areas of rigorously defining safety requirements, trusting the safety of <b>multi-vendor</b> distributed <b>system</b> components, tolerating environmental uncertainty, providing a realistic role for human oversight, and ensuring sufficiently rigorous validation of autonomy technology...|$|R
5000|$|Complex {{software}} <b>systems,</b> especially <b>multi-vendor</b> distributed <b>systems</b> {{based on}} open standards, perform input/output operations to exchange data via stateful, structured exchanges known as [...] "protocols." [...] One kind of fault injection {{that is particularly}} useful to test protocol implementations (a type of software code that has the unusual characteristic in that it cannot predict or control its input) is fuzzing. Fuzzing is an especially useful form of Black-box testing since the various invalid inputs that are submitted to the software system do not depend on, and are not created based on knowledge of, {{the details of the}} code running inside the system.|$|R
40|$|Abstract — Creating safe Transportation Cyber-Physical Systems (CPSs) {{presents}} {{new challenges}} as autonomous operation is attempted in unconstrained operational environments. The extremely high safety level required of such systems (perhaps one critical failure per billion operating hours) means that validation approaches {{will need to}} consider not only normal operation, but also operation with system faults and in exceptional environments. Additional challenges {{will need to be}} overcome in the areas of rigorously defining safety requirements, trusting the safety of <b>multi-vendor</b> distributed <b>system</b> components, tolerating environmental uncertainty, providing a realistic role for human oversight, and ensuring sufficiently rigorous validation of autonomy technology. Keywords—Cyber-Physical System (CPS) safety; ultra-dependable systems; software safety; autonomous vehicles I...|$|R
40|$|The IEC 61850 based {{substation}} automation system (SAS) solution are being implemented by many providers to power industry which is open challenge to re-fine communication network, IED interoperability and HMI functionality to derive the improvement in SA protection,control and monitoring. The available <b>multi-vendor</b> SA <b>system</b> could not get uniform SAS functionality. Therefore, this paper will review the SAS engineering design, SA architecture, communication network & its interconnection with PRP and HSR protocol. The proposed SA architecture including HMI uniform functionality based on optimal solution have been {{presented in this paper}} in line with described design process methodology. the proposed scheme will helpful for diagnosis fault during maintenance, ease for operator to manipulate uniform SA system,got better performance, reduce cost of system and become reliable...|$|R
40|$|Abstract. Mapping and {{merging of}} {{multiple}} ontologies to produce consistent, coherent and correct merged global ontology {{is an essential}} process to enable heterogeneous <b>multi-vendors</b> semantic-based <b>systems</b> {{to communicate with each}} other. To generate such a global ontology automatically, the individual ontologies must be free of (all types of) errors. We have observed that the present error classification does not include all the errors. This paper extends the existing error classification (Inconsistency, Incompleteness and Redundancy) and provides a discussion about the consequences of these errors. We highlight the problems that we faced while developing our DKP-OM, ontology merging system and explain how these errors became obstacles in efficient ontology merging process. It integrates the ontological errors and design anomalies for content evaluation of ontologies under one framework. This framework helps ontologists to build semantically correct ontology free from errors that enables effective and automatic ontology mapping and merging with lesser user intervention...|$|R
40|$|Computer-based {{structural}} {{health monitoring}} (SHM) systems are deployed in complex civil structures for continual sanity checks and early warning purposes. Skyscrapers, overextended bridges, oil refineries and pipelines {{are examples of}} civil structures {{that need to be}} continually monitored for corrosions, decays, stress and temperature change. Integrating <b>multi-vendor</b> SHM <b>systems,</b> which are technologically different, in one global monitoring system is essential for geographically spread organizations. The integration task requires a dedicated network, leased public telecommunications lines, and a protocol stack to interconnect the dispersed SHM systems. In this paper, we propose a new architecture, based on the well-established and ubiquitous Simple Network Management Protocol (SNMP), to interconnect various SHM systems with a global monitoring system through the Internet. We describe the essential components and the basic structure of the corresponding management information base (MIB). Adopting an Internet-based standard yields economical and operational benefits, but with some security drawbacks. We shall also highlight the envisioned benefits and discuss means to mitigate the security concerns...|$|R
40|$|Electronic marketplaces (EMs) are virtual marketplaces where {{buyers and}} {{suppliers}} meet to exchange information about prices and product and service offerings, and {{to negotiate and}} carry out business transactions. They are at {{the centre of the}} current growth in Internet electronic commerce, both in business-to-business (B 2 B) and business-to-consumer (B 2 C) markets, although the value of B 2 B electronic commerce is proportionately five times B 2 C and is expected to exceed ten times its value by 2003. In this paper, we trace the evolution of EMs, from their initial beginnings as computer-tocomputer links between corporate trading partners, to their current forms as multi-vendor Webbased catalogs and ordering systems that service B 2 B customers. We also describe in detail B 2 B electronic marketplaces, including sell-side, buy-side, and intermediary-supported <b>multi-vendor</b> catalog <b>systems</b> that link customers and suppliers. We discuss the role of management in guiding firms through this difficult [...] ...|$|R
30|$|One of {{possible}} improvements of ETSI NFV-MANO is joining it with SDN-like management, see, e.g., [60, 61]. The systems are compatible {{because they have}} plane-based/layered structure and both assume centralized management. Another extension tries to simplify management in multi-domain, <b>multi-vendor,</b> and multi-tenant <b>systems</b> by introducing hierarchical management and orchestration structures (see e.g., [23, 62 – 64]). Such an approach enables application of the ETSI NFV-MANO system directly for a single domain or instance and provide a supervision over several management systems. It also enables virtual functions and slice chaining in heterogeneous environment or when a slice is built over several domains, see e.g., [65 – 67].|$|R
40|$|Abstract—The germ of the {{component}} idea arose in mass production as the interchangeable part, but in today’s information and communications technology (ICT) industries {{the component}} can connote considerably more, such as multiple uses, opportunistic combinations with other components, design by assembly, and incremental evolution through field replacement with upgraded components. In {{spite of its}} many advantages, the component has failed {{to keep up with}} increasing scales of integration, increasing use of software, and the resulting complexity and application diversity. A rethinking of the component and associated industry practices is needed in light of modern technology and applications. Componentization has many payoffs, including as a process for industry coordination, most notably in large <b>multi-vendor</b> complex <b>systems</b> with fragmented administrative and ownership domains. Invigorating componentization requires abandoning antiquated concepts such as components are exclusively hardware or software or even exclusively technological, are units of manufacture and packaging, or that each component is the responsibility of an individual firm. The system component, which incorporates hardware, software, and oftentimes even human process or organizational elements–whatever is necessary to achieve a coherent body of functionality–is the appropriate perspective toda...|$|R
40|$|Introduction: PACS {{has evolved}} from a {{technical}} difficult and expensive radiology based business towards the main driver in digital diagnostic imaging in healthcare. Emerging countries will not repeat this evolution but have {{to jump on the}} bandwagon of enterprise PACS the motor behind healthcare informatics. PACS will use rather of-the-shelf technologies like internet 1 + 2, commercial storage and communication solutions than special &quot;homemade&quot; technology. PACS will evolve from a local image-data center towards a regional and even countrywide medical imaging expertise and knowledge network. This will increase the role of the organ-based specialized radiologists in the diagnosis and treatment of patients. "nDevelopments: There exist 3 levels of PACS deployment with increasing technical complexities. At least all of them require a minimum of RIS and HIS to make them useful. "n&bull; Modality based PACS: supported by modality vendors and of increasing importance by the new 3 - 4 D image processing. Here all processing and storage is located around the MRI and CT. It has value for the radiologist but is not helping clinicians and it is costly because it has to be repeated for every modality and every vendor. "n&bull; Departmental PACS: integrates all modalities into 1 type of workstation, storage and communication, but communication towards clinicians and other hospitals is based on film, CD ROM or a kind of simple LAN. This has a very high cost and only helps the radiologist. The use of DICOM standards is mandatory. "n&bull; Enterprise PACS is the imaging part of a hospital-wide informatics strategy (called HIS) leading to an EMR (Electronic Medical Record), EPR (Electronic Patient record) or EHR (Electronic Health record), where neither paper nor film is used. All medical specialties (including the image-rich cardiology) are integrated into one system, improving treatment speed and quality. The main decision-takers are governments, health authorities, health insurances, and hospital chains. It is often used as a competitive and marketing advantage. HL 7 is now the dominant standard. Several enterprise PACS can be integrated into a multisite-PACS (even on remote distances) allowing doctors and patients to go wherever into the system. This approach requires new standards like the Master Patient Index (MPI) and a lot more intelligence and integration of the (<b>multi-vendor)</b> <b>systems.</b> The final goal of enterprise PACS is to look for knowledge, EBM and use of the semantic web in order to improve the treatment of patients even in remote locations. "nConclusions:"nFinally all PACS levels have to evolve towards enterprise PACS, integrated in a HIS, and images will be part of a kind of EPR. Modality and departmental PACS must be upgraded towards a hospital-wide PACS in a cost-efficient way without compromises about speed and capacity. Internet technology, database are integral parts of the solution. "nCompanies offering PACS should have this approach in their roadmap, rather than short term throw-away offers. RFPs have to written in respect to future upgrades towards enterprise PACS just to avoid dead-end streets and costly disappointments...|$|R
40|$|ITC/USA 2005 Conference Proceedings / The Forty-First Annual International Telemetering Conference and Technical Exhibition / October 24 - 27, 2005 / Riviera Hotel & Convention Center, Las Vegas, NevadaCreating a generic, <b>multi-vendor</b> data {{exchange}} <b>system</b> for transmitting telemetry configurations between various systems is a daunting task. To date many different {{systems have been}} proposed including relational databases (RDBMS), TMATS, and several different XML schemas. Although many of these systems have been implemented, a complete, flexible solution has not been developed. This paper describes an implementation that is currently in use for exporting and importing a complete telemetry system via XML. Using this system, an engineer can import an entire telemetry configuration, a partial telemetry configuration, or even just a single measurement (parameter). As a result, the gap between user database systems and the airborne instrumentation vendor’s configuration software (IVCS) is seamlessly bridged. This provides many benefits including: the ability to rapidly change configurations, data entry error avoidance, version control, the protection of sensitive information, and configuration reusability. This system allows for the configuration of {{all aspects of the}} telemetry setup including data acquisition hardware, transmitters, ground stations, and recorders. In addition, the recorder settings and the definition of the data that are to be recorded are coupled and linked {{to the rest of the}} telemetry configuration, which facilitates future data recovery...|$|R
40|$|Due to {{an urgent}} need for an {{international}} protocol for power protection and substation automation, the International Electrotechnical Committee (IEC) and Institute of Electrical and Electronic Engineers (IEEE) agreed to collaborate together to advance the existing communication protocols for substation automation system (SAS). The objectives were to achieve interoperability and free configuration in a multi-vendor environment substation. The outcome of this agreement was to announce {{the first edition of}} the IEC 61850 Standard as an international standard in 2004. The standard incorporates the use of logical nodes to resolve problems related to interoperability and interchangeability in <b>multi-vendor</b> zone substation <b>systems.</b> The standard also initiated a cost-effective Generic Object Oriented Substation Event (GOOSE) messaging technology to replace the traditional copper wiring. The second edition of the IEC 61850 Standard was published in 2014 which is encapsulated in a series of 20 documents spanning over ten sections. The last few years has seen numerous studies pointing to the IEC 61850 as a worthwhile international standard for substation automation system. There is still, nevertheless, resistance from utilities to welcoming the IEC 61850 implementation. This may perhaps be {{due to the lack of}} knowledge that engineers have about the standard and/or because of several ambiguous topics that still are not addressed in detail in the context of IEC 61850. Furthermore, it should go without saying that, the GOOSE technology has brought several benefits to the power protection and communication systems in the field of substation automation. However, the lack of tools and knowledge to take advantage of the GOOSE messaging technology in IEC 61850 -based zone substations is tangible. For instance, in order to test an Intelligent Electronic Device (IED), isolating a GOOSE message from substation is a main industrial challenge for engineers. When an IED is isolated from live substation for test purposes, its GOOSE message is not isolated yet, and the IED under test is still publishing the GOOSE trip signal to other IEDs. In order to isolate the GOOSE trip signal for IED test purposes, each vendor implements its own method and they use their proprietary configurator tools. This means that, engineers are desperately dealing with a lack of comprehensive tool or method to isolate the GOOSE trip signal in a multi-vendor zone substation. These challenges led to the slow migration of the standard into substations. Having acknowledged these difficulties and challenges the spotlight is seemingly in the path of developing a tool or program to be utilised for GOOSE isolation and GOOSE management in a multi-vendor relay environment. In doing that, a 66 / 22 kV Distribution Terminal Zone Substation is implemented accompanied with a SCADA centre as a model of an IEC 61850 -based Substation. Two bays with separate 66 kV sub-transmission lines, 66 / 22 kV step down transformers, 22 kV Bus 1 with Bus Tie Circuit Breaker and three 22 kV feeders per bay have been considered for the simulation. In the construction of the Substation Simulator, the aim is to take advantage of the IEC 61850 GOOSE messaging technology for protection, control, monitoring and communication purposes. Hence, the hardwire connections are replaced by GOOSE signals through optic cables as much as possible. This thesis will not only provide the design and configuration procedures of this substation, but also will cover the difficulties that engineers may encounter in IEC 61850 -based substations systems in terms of device configuration, testing and maintenance. In order to fully understand the concept of the 66 / 22 kV Distribution Terminal Zone Substation, it is very essential to be familiar with the structure of communication protocols and the IEC 61850 Standard. This thesis starts by exploring a synopsis of communication protocols and their development over the time. It elucidates core elements of telemetry communications, structures of protocols and the significance of standards for communication protocols within substation automation systems. This is followed by a comprehensive exploration of the fundamentals of the IEC 61850 -based substations. In particular, it will cover the GOOSE messaging technology and interoperability in a multi-vendor substation environment. The author also addresses the difficulties that engineers may encounter in IEC 61850 -based substations systems in terms of device configuration, testing and maintenance...|$|R

