6|55|Public
50|$|The Serval Project (often {{referred}} to as Serval) is a project financed by the Shuttleworth Foundation, as well as various other organisations and accepting individual donations. It is headquartered at Flinders University in Adelaide, Australia. The project aims to develop technology {{that can be used}} to create direct connections between cellular phones through their Wi-Fi interfaces, without the need of a mobile phone operator. The technology allows for live voice calls whenever the mesh is able to find a route between the participants. Text messages and other data can be communicated using a store and forward system called Rhizome, allowing communication over unlimited distances and without a stable live <b>mesh</b> <b>connection</b> between all participants.|$|E
40|$|Mechanically Stabilized Earth (MSE) walls {{restrain}} hillslopes to unnatural gradients using reinforced soil. Traditional MSE {{walls are}} constructed of large reinforced concrete panels bolted to steel strips for soil reinforcement. Segmented Retaining Walls (SRWs) are {{a form of}} MSE walls composed of precast concrete modular blocks that incorporate geosynthetic soil reinforcement. In comparison, traditional MSE walls have faster construction times and are typically stronger, but SRWs have increased in popularity because they are much cheaper to build. There are many precast companies that produce different SRW block designs, these blocks have facing areas that range from 1 to 13. 75 sq. ft. and can weigh approximately 90 to 2, 000 lbs. There are advantages to both block types {{that must be addressed}} during design. Typically construction costs are lower for small blocks because they can be placed by hand rather than using equipment. Large blocks require less construction time but are usually more expensive to fabricate. Oldcastle is a precast company that has several modular block designs. The newest model called the Mega Wall block is 5. 5 feet wide, 2. 5 feet tall and weighs approximately 2, 000 lbs. The block is designed to accommodate both welded wire mesh and geosynthetics soil reinforcement. Prior to being released to the market design strengths must be determined through laboratory testing. This report presents the results of the Mega Wall block welded wire <b>mesh</b> <b>connection</b> capacity. Three tests were performed by pulling the welded wire mesh to failure under simulated overburden pressures. Results of the testing show that welds in the wire mesh failed well below the yield strength of the steel. As the wires were pulled, the mesh applied stress concentrations to edges of the concrete grooves. Conical concrete failures were observed in the concrete after each test. After the concrete failed, the mesh was allowed to bend considerably, which began to apply a bending to the welds already experiencing shear stress. This excessive bending deformation caused premature failure in the welds during testing. In order to achieve higher connection capacities, several modifications to the Mega Wall block design were presented to Oldcastle. These suggestions were acknowledged but not implemented. Oldcastle was not interested in testing modifications to the block and testing was terminated. It is assumed that the Mega Wall block design will not be modified and that Oldcastle will not recommend using the welded wire <b>mesh</b> <b>connection...</b>|$|E
40|$|This study {{presents}} a meshless-based local reanalysis (MLR) method. The {{purpose of this}} study is to extend reanalysis methods to the Kriging interpolation meshless method due to its high efficiency. In this study, two reanalysis methods: combined approximations CA) and indirect factorization updating (IFU) methods are utilized. Considering the computational cost of meshless methods, the reanalysis method improves the efficiency of the full meshless method significantly. Compared with finite element method (FEM) -based reanalysis methods, the main superiority of meshless-based reanalysis method is to break the limitation of <b>mesh</b> <b>connection.</b> The meshless-based reanalysis is much easier to obtain the stiffness matrix even for solving the mesh distortion problems. However, compared with the FEM-based reanalysis method, the critical challenge is to use much more nodes in the influence domain due to high order interpolation. Therefore, a local reanalysis method which only needs to calculate the local stiffness matrix in the influence domain is suggested to improve the efficiency further. Several typical numerical examples are tested and the performance of the suggested method is verified. Comment: 18 pages, 31 figures, 13 tables,Reanalysis, Meshless, Kriging interpolation, Combined approximations, Indirect factorization updatin...|$|E
50|$|There will {{be three}} 802.11s {{wireless}} <b>mesh</b> <b>connections.</b> Each {{will be a}} USB device with a 3 meter (10 foot) cable, allowing good antenna placement (high, unobstructed) and good server placement (dry, secure).|$|R
5000|$|The {{number of}} {{connections}} {{needed to have}} fully <b>meshed</b> point-to-point <b>connections,</b> with [...] points, is given by [...] (see binomial coefficient). Thus, for ten applications to be fully integrated point-to-point, , or 45 point-to-point connections are needed.|$|R
30|$|Mechanical {{adhesion}} theory [43] {{indicated that}} the gaps or holes {{on the surface of}} objects were filled with liquid adhesive and <b>meshing</b> <b>connection</b> occurred at the interface after the adhesive cured. This is the fundamental basis to understand the bonding between adhesive and wood for wood-based composites. For a more porous woody material, such as poplar, a portion of adhesive can over-penetrate the woody surface and others stay on the veneer surface for bonding purpose. Hence, the adhesive materials can penetrate into the cells which upon curing form an anchor (see Fig.  5 b), at the same time leaving some parts of the adhesives on the veneer surface for adhesive transfer and bond formation with the adjacent veneer surface.|$|R
40|$|Because {{accuracy}} and efficiency {{are the main}} features expected within the finite element (FE) method, the current contribution proposes a six-node prismatic solid–shell, denoted (SHB 6). The formulation is extended here to geometric and material nonlinearities, and focus will be placed on its validation on nonlinear benchmark problems. This type of FE is specifically designed for the modeling of thin structures, by combining several useful shell features with some well-known solid element advantages. Therefore, the resulting derivation only involves displacement degrees of freedom as {{it is based on}} a fully 3 D approach. Some of the motivation behind this formulation is to allow a natural <b>mesh</b> <b>connection</b> in problems where both structural (shell/plate) and continuum (solid) elements need to be simultaneously used. Another major interest of this prismatic solid–shell is to complement meshes that use hexahedral solid–shell FE, especially when free mesh generation tools are employed. To achieve an efficient formulation, the assumed-strain method is combined with an in-plane one-point quadrature scheme. These techniques are intended to reduce both locking phenomena and computational cost. A careful analysis of possible stiffness matrix rank deficiencies demonstrates that this reduced integration procedure does not induce hourglass modes and thus no stabilization is required. Contrat EDF R&...|$|E
40|$|This thesis {{investigates the}} {{development}} of a low cost, component based facial virtual conferencing system. The design is decomposed into an encoding phase and a decoding phase, which communicate with each other via a network connection. The encoding phase is composed of three components: model acquisition (which handles avatar generation), pose estimation and expression analysis. Audio is not considered part of the encoding and decoding process, and as such is not evaluated. The model acquisition component is implemented using a visual hull reconstruction algorithm that is able to reconstruct real-world objects using only sets of images of the object as input. The object to be reconstructed is assumed to lie in a bounding volume of voxels. The reconstruction process involves the following stages:- Space carving for basic shape extraction;- Isosurface extraction to remove voxels not part of the surface of the reconstruction;- <b>Mesh</b> <b>connection</b> to generate a closed, connected polyhedral mesh;- Texture generation. Texturing is achieved by Gouraud shading the reconstruction with a vertex colour map;- Mesh decimation to simplify the object. The original algorithm has complexity O(n), but suffers from an inability to reconstruct concave surfaces that do not form part of the visual hull of the object. A novel extension to this algorithm based on Normalised Cross Correlation (NCC) is proposed to overcome this problem. A...|$|E
40|$|This thesis {{investigates the}} {{development}} of a low cost, component based facial virtual conferencing system. The design is decomposed into an encoding phase and a decoding phase, which communicate with each other via a network connection. The encoding phase is composed of three components: model acquisition (which handles avatar generation), pose estimation and expression analysis. Audio is not considered part of the encoding and decoding process, and as such is not evaluated. The model acquisition component is implemented using a visual hull reconstruction algorithm that is able to reconstruct real-world objects using only sets of images of the object as input. The object to be reconstructed is assumed to lie in a bounding volume of voxels. The reconstruction process involves the following stages: - Space carving for basic shape extraction; - Isosurface extraction to remove voxels not part of the surface of the reconstruction; - <b>Mesh</b> <b>connection</b> to generate a closed, connected polyhedral mesh; - Texture generation. Texturing is achieved by Gouraud shading the reconstruction with a vertex colour map; - Mesh decimation to simplify the object. The original algorithm has complexity O(n), but suffers from an inability to reconstruct concave surfaces that do not form part of the visual hull of the object. A novel extension to this algorithm based on Normalised Cross Correlation (NCC) is proposed to overcome this problem. An extension to speed up traditional NCC evaluations is proposed which reduces the NCC search space from a 2 D search problem down to a single evaluation. Pose estimation and expression analysis are performed by tracking six fiducial points on the face of a subject. A tracking algorithm is developed that uses Normalised Cross Correlation to facilitate robust tracking that is invariant to changing lighting conditions, rotations and scaling. Pose estimation involves the recovery of the head position and orientation through the tracking of the triangle formed by the subject's eyebrows and nose tip. A rule-based evaluation of points that are tracked around the subject's mouth forms the basis of the expression analysis. A user assisted feedback loop and caching mechanism is used to overcome tracking errors due to fast motion or occlusions. The NCC tracker is shown to achieve a tracking performance of 10 fps when tracking the six fiducial points. The decoding phase is divided into 3 tasks, namely: avatar movement, expression generation and expression management. Avatar movement is implemented using the base VR system. Expression generation is facilitated using a Vertex Interpolation Deformation method. A weighting system is proposed for expression management. Its function is to gradually transform from one expression to the next. The use of the vertex interpolation method allows real-time deformations of the avatar representation, achieving 16 fps when applied to a model consisting of 7500 vertices. An Expression Parameter Lookup Table (EPLT) facilitates an independent mapping between the two phases. It defines a list of generic expressions that are known to the system and associates an Expression ID with each one. For each generic expression, it relates the expression analysis rules for any subject with the expression generation parameters for any avatar model. The result is that facial expression replication between any subject and avatar combination can be performed by transferring only the Expression ID from the encoder application to the decoder application. The ideas developed in the thesis are demonstrated in an implementation using the CoRgi Virtual Reality system. It is shown that the virtual-conferencing application based on this design requires only a bandwidth of 2 Kbps. Adobe Acrobat Pro 9. 4. 6 Adobe Acrobat 9. 46 Paper Capture Plug-i...|$|E
40|$|We {{propose to}} develop and {{evaluate}} software support for improving locality for advanced scientific applications. We will investigate compiler and run-time techniques needed to achieve high performance on both sequential and parallel machines. We will focus on two areas. First, iterative PDE solvers for 3 D partial differential equations have poor locality because accesses to nearby elements in higher-level dimensions are spread far apart in memory. Careful tiling and padding can frequently recapture such reuse. Second, computations on adaptive meshes and sparse matrices experience many cache misses because they access data in an irregular manner. Data layout and access order can be rearranged according to <b>mesh</b> <b>connections</b> or geometric location to improve locality, with cost models used to guide frequency of transformations for adaptive computations. ...|$|R
40|$|Abstract—Long-reach hybrid WDM-TDM PONs connect {{far away}} service areas to center offices of service providers. Typically, {{multiples}} fiber cables {{run from the}} center office side to each service area in order to feed the service area with data flows. We believe that mesh topology in service areas allows AWGs feeding each other and consequently less fiber cables need to be run between center offices and service areas. In this paper, we show some typical cases where <b>mesh</b> <b>connections</b> between AWGs are useful. We propose also an efficient algorithm based on Local improvement approach for designing survivable longreach hybrid WDM-TDM PONs where mesh topology between AWGs is allowed. The experimental results show that {{a large percentage of}} PONs should use mesh topology in service areas in order to minimize the total PON deployment cost. I...|$|R
5000|$|Over the years, he {{was also}} active in {{research}} in parallel computation and VLSI theory. His 1979 paper (with J. Vuillemin), still highly cited, presented the cube-connected-cycles (CCC), a parallel architecture that optimally emulates the hypercube interconnection. This interconnection was closely reflected in {{the architecture of the}} CM2 of Thinking Machines Inc., the first massive-parallel system in the VLSI era. His 1991 paper with Zhou and Kang on interconnection delays in VLSI was awarded the 1993 [...] "Darlington Best Paper Award" [...] by the IEEE Circuits and Systems Society. In the late nineties, (in joint work with G. Bilardi) he confronted the problem of the physical limitations (space and speed) of parallel computation, and formulated the conclusion that <b>mesh</b> <b>connections</b> are ultimately the only scalable massively parallel architectures.|$|R
40|$|Due to {{low load}} factors of wind power generation，it is {{possible}} to reduce transmission capacity to minimize the cost of transmission system construction. Two VSC-HVDC schemes for offshore wind farm，called the point to point（PTP）and DC <b>mesh</b> <b>connections</b> are compared {{in terms of the}} utilization of transmission system and its cost. A Weibull distribution is used for estimating offshore wind power generation，besides，the cross correlation between wind farms is considered. The wind energy curtailment is analyzed using the capacity output possibility table（COPT）. The system power losses，costs of transmission investment and wind energy curtailment are also computed. A statistic model for the wind generation and transmission is built and simulated in MATLAB to validate the study. It is concluded that a DC mesh transmission can reduce the energy curtailment and power losses. Further benefit is achievable as the wind cross correlation between wind farms decreases...|$|R
40|$|A {{practical}} {{wireless network}} solution for providing community broadband Internet access services {{are considered to}} be wireless mesh networks with delay-throughput tradeoff. This important aspect of network design lies in the capability to simultaneously support multiple independent <b>mesh</b> <b>connections</b> at the intermediate mobile stations. The intermediate mobile stations act as routers by combining network packets with forwarding, a scenario usually known as multiple coding unicasts. The problem of efficient network design for such applications based on multipath network coding with delay control on packet servicing is considered. The simulated solution involves a joint consideration of wireless media access control (MAC) and network-layer multipath selection. Rather than considering general wireless mesh networks, here the focus is on a relatively small-scale mesh network with multiple sources and multiple sinks suitable for multihop wireless backhaul applications within WiMAX standard. © 2012 ICST Institute for Computer Science, Social Informatics and Telecommunications Engineering...|$|R
40|$|Abstract. The pyramid {{computer}} was initially proposed for performing high-speed low-level image processing. However, its regular geometry {{can be adapted}} naturally to many other problems, providing effective solutions to problems more complex than those previously considered. We illustrate this by presenting pyramid computer solutions to problems involving component labeling, minimal spanning forests, nearest neighbors, transitive closure, articulation points, bridge edges, etc. Central to these algorithms is our collection of data movement techniques which exploit the pyramid’s mix of tree and <b>mesh</b> <b>connections.</b> Our pyramid algorithms are significantly faster than their mesh-connected computer counterparts. For example, given a black/white square picture with n pixels, we can label the connected components in O(n 1 / 4) time, {{as compared with the}} i) (n / 2) time required on the mesh-connected computer. Key words, pyramid computer, graph-theoretic algorithms, image processing, component labeling, mesh-connected computer AMS(MOS) subject classifications. 68 Q 25, 68 Q 20, 68 U 10 1. Introduction. Pyramid-like parallel computers have long been proposed for performing high-speed low-level image processing [4], [17], [24 J, [32], [34]. Th...|$|R
40|$|The aim of {{this thesis}} has been: To {{demonstrate}} {{the superiority of the}} reconfigurable mesh architecture, especially for communication intensive algorithms, over existing fixed connection architectures. Reconfiguration has been considered by researchers for several years as a means of enhancing performance of parallel computers. Recently the most general model of reconfiguration for SIMD architectures was presented by Miller, Prasanna, Reisis and Stout [34]. The work presented in this thesis is based on the reconfigurable mesh model proposed in [34]. The main contribution of this thesis consists of algorithms for three basic applications [...] - sorting, routing, and connected component labelling. These algorithms are significantly faster compared to known algorithms for the same applications on fixed <b>connection</b> <b>mesh</b> architectures. Thus, this thesis has been successful in justifying the hardware cost of adding reconfiguration to fixed <b>connection</b> <b>meshes</b> by demonstrating the superiority of re [...] ...|$|R
30|$|Interestingly, mode-II/III meshing {{occurred}} even {{in cases}} of small connecting deviation. In actual task executions, the A-Gear approaches the P-Gear while rotating. Consequently, the initial pin contact of the A-Gear may be significantly eccentric despite the low connecting deviation, resulting in mode-II/III <b>meshing.</b> As the <b>connection</b> condition worsens, the rotation transmission ratio deteriorates, and the incidence of II/III modes increases.|$|R
40|$|The {{proximity}} compatibility principle (PCP) {{predicts that}} integrated displays will show superior performance to separated displays for integrated tasks. Hollands, Pierce, and Magee (1998) compared 2 D and 3 D displays for a trend estimation task {{and found that}} 2 D displays were better than 3 D displays for integrated tasks. These results were inconsistent with the predictions of the PCP. The present study added line and <b>mesh</b> <b>connections</b> to the integrated display format to make existing emergent features more salient. Four display formats were tested: 2 D, 3 D Control, 3 D Lines, and 3 D Mesh. Twenty-four participants completed 256 trials evaluating the effect of display format, vergence rate, vergence direction, and starting distance on trend estimation. Results showed advantages for the 3 D Mesh and 3 D Line displays. A general advantage was found for faster vergence rates, and converging trends when the lines start closer together. Individuals with a modern personal computer have access to advanced graphic capabilities that were once only possible with expensive graphical workstations. These capabilities {{make it easier to}} represent numerical information visually using three-dimensional (3 D) display formats. A 3 D display integrates and displays information about three different variables simultaneously. It can be used to combine information shown in separate 2 D displays into a single display (Hollands, Pierce, & Magee, 1998; Wickens, Merwin, & Lin, 1994). The proximity compatibility principle (PCP) predicts that object displays, due to their integrative nature, will show better operator performance for tasks requiring information integration (Carswell & Wickens, 1987...|$|R
40|$|The {{concept of}} the ideal {{transformer}} is presented in terms of flux relations contrasting a non-ideal transformer, which may be represented by an impedance matrix, to an ideal transformer which may not. The interchangeability of the considerations of a transformer, first, as a constraint on the currents (a "multiwinding" transformer) and, second, as a constraint on the voltages (a "multilimb" transformer) is formulated. Mesh and nodal analysis is extended to include networks involving ideal transformers {{by the use of}} Lagrange multipliers. These multipliers are eliminated from the equations by a procedure, in terms of compound matrices, that is facilitated by reduction of the transformers to a standard form. The procedure is also interpreted as a set of rules such that the mesh and nodal equations of a general network can be written by inspection. The possible degeneracies in network equations are considered, and a "scattering matrix" procedure presented to cover these cases. The orientation of the branches in a dual network is analyzed and the dual of an ideal transformer is given. The duality concept in electrical networks is considered in terms of matrices that describe the sets of branches belonging to the various <b>meshes</b> (<b>connection</b> matrix) and belonging to the various node-pairs (branch, node-pair matrix). Using the extension of the duality principle to nonplanar networks, a procedure is presented for drawing a network diagram from its connection matrix. As an application, a general procedure is given for finding the electrical analog of a mechanical structure. Also, the role of gyrators and network duality is mentioned. The problem of minimizing the number of transformers in a network is approached by a circuit reduction technique. Networks uniformly dependent on frequency are first synthesized by Cause's technique. The conditions are derived for then eliminating the transformers from this circuit, one by one, for the particular case of a network with three grounded terminal-pairs...|$|R
40|$|A patient-specific left atrium (LA) model {{extracted}} from intra-operative C-arm CT {{plays an important}} role in planning for transcatheter left atrial fibrillation ablation. Overlaying the LA model onto 2 D fluoroscopic images provides valuable visual guidance during the intervention. However, automatic segmentation of the LA, together with the left atrial appendage (LAA) and the pulmonary vein (PV) trunks, is challenging due to the large structural variations and imaging artifacts. In this paper we exploit a part based LA model to handle the structural variations and different parts are then merged into a consolidated <b>mesh.</b> The <b>connection</b> region between the PV/LAA and the LA chamber is segmented precisely by enforcing both image boundary delineation accuracy and mesh smoothness. Furthermore, the boundary between parts is optimized to improve the mesh part labeling accuracy...|$|R
40|$|Regularizing the {{deformation}} field {{is an important}} aspect in nonrigid medical image registration. By covering the template image with a triangular mesh, this paper proposes a new regularization constraint in terms of <b>connections</b> between <b>mesh</b> vertices. The <b>connection</b> relationship is preserved by the spring analogy method. The method is evaluated by registering cerebral magnetic resonance imaging (MRI) image data obtained from different individuals. Experimental {{results show that the}} proposed method has good deformation ability and topology-preserving ability, providing a new way to the nonrigid medical image registration...|$|R
40|$|We present {{algorithms}} for routing packets on {{a two-dimensional}} array of processors {{in the so-called}} k-k routing model. Each processor sends and receives exactly k packets. Using new techniques for the performance analysis we show that a simple randomized three phase algorithm performs optimally: For all k &ge; 8, the k-k routing problem is solved with k&middot;n/ 2 + O((k&middot;n&middot;log n) ^ 1 / 2) routing steps and constant size queues with very high probability, which nearly matches the lower bound of k&middot;n/ 2 steps. For k < 8 we present refined algorithms which come close to optimal. In addition, we prove interesting results for cut-through routing: the same randomized algorithm routes packets consisting of k flits each with k&middot;n/ 2 + n/k + 3 / 2 &middot;k + O(k&middot;(n&middot;log n) ^ 1 / 2) routing steps with very high probability. We can generalize the algorithm for routing on meshes of arbitrary dimension and nearly reach the trivial lower bounds for both classes of problems. For routing on <b>meshes</b> with wrap-around <b>connections</b> we present a four phase algorithm which can be generalized easily for routing on <b>meshes</b> with wrap-around <b>connections</b> of arbitrary dimension. The performance is close to optimal [...] ...|$|R
40|$|A {{low-cost}} hybrid wireless {{sensor network}} (WSN) that utilizes the 917 [*]MHz band Wireless Smart Utility Network (Wi-SUN) and a 447 [*]MHz band narrow bandwidth communication network is implemented for electric metering and room temperature, humidity, and CO 2 gas measurements. A <b>mesh</b> network <b>connection</b> that is commonly utilized for the Internet of Things (IoT) {{is used for the}} Wi-SUN under the Contiki OS, and a star connection is used for the narrow bandwidth network. Both a duty-cycling receiver algorithm and a digitally controlled temperature-compensated crystal oscillator algorithm for frequency reference are implemented at the physical layer of the receiver to accomplish low-power and low-cost wireless sensor node design. A two-level temperature-compensation approach, in which first a fixed third-order curve and then a sample-based first-order curve are applied, is proposed using a conventional AT-cut quartz crystal resonator. The developed WSN is installed in a home and provides reliable data collection with low construction complexity and power consumption...|$|R
30|$|Technical {{solutions}} for multi-hop wireless networks are being specified in IEEE 802.11 s [2]. IEEE 802.11 s is developed {{as an extension}} of the successful IEEE 802.11 standard for WLANs (wireless local area networks) [1]. IEEE 802.11 s defines the mesh operation in a single channel although multi-radio mesh routers can form different <b>meshes.</b> The <b>connection</b> between different <b>meshes</b> is provided via bridging. Mesh routers can initiate the channel switching mechanism which moves the mesh, or part of it, to another channel. The routers which do not want to follow the channel switch request may join another mesh. Channel switching may help mesh routers to avoid the external interference but does not reduce the internal interference between routers which belong to the same mesh basic service set (MBSS), since it moves the MBSS to another channel. However, frequent channel switching may degrade the mesh performance due to the high overheads that it implies [3].|$|R
40|$|The Connection Machine Model CM- 5 Supercomputer is a massively {{parallel}} computer system designed to offer performance {{in the range of}} 1 teraflops (10 12 floating-point operations per second). The CM- 5 obtains its high performance while offering ease of programming, flexibility, and reliability. The machine contains three communication networks: a data network, a control network, and a diagnostic network. This paper describes the organization of these three networks and how they contribute to the design goals of the CM- 5. 1 Introduction In the design of a parallel computer, the engineering principle of economy of mechanism suggests that the machine should employ only a single communication network to convey information among the processors in the system. Indeed, many parallel computers contain only a single network: typically, a hypercube or a <b>mesh.</b> The <b>Connection</b> Machine Model CM- 5 Supercomputer has three networks, however, and none is a hypercube or a mesh. This paper describes the [...] ...|$|R
40|$|Thesis (M. S.) [...] Wichita State University, College of Engineering, Dept. of Mechanical Engineering. Birdstrikes on {{aircraft}} pose a {{major threat}} to human life and {{there is a need to}} devolop structures which have high resistance towards these structures. According to the Federal Aviation Regulation (FAR 25. 571) on Damage-tolerance and fatigue evaluation of structure (Amdt. 25 - 96), an airplane must be capable of successfully completing the flight during which likely structural damage might occur as a result of impact with 4 -lb bird at cruise velocity at sea level or 0. 85 cruise velocity at 8000 feet. The aim of the research is to develop a methodology which can be utilized to certify an aircraft for birdstrike using computational techniques since the physical testing of birdstrike is expensive, time consuming, cumbersome and for sanitary purpose. The simulations are carried out in the LS Dyna, non-linear finite element analysis code, in which the bird is modeled using the Smooth Particle Hydrodynamics (SPH) technique. Initially to validate the bird model in the LS Dyna, the birdstrike is carried out on rigid and deformable plates. The results including displacement, Von-Mises stresses, forces, impulse, squash time and rise time are obtained from the simulation. Then the non-dimensional plots of force, impulse and rise time are plotted and compared with results from experimental test data. The detailed CAD geometry of the leading edge is modeled in CATIA V 5. <b>Meshing,</b> <b>connections</b> and material properties are then defined in the Altair Hypermesh 9. 0. The validated SPH bird model is impacted at the leading edge. The results obtained from the simulation are compared with the data from the experiments, and the process is validated. The parametric studies are carried out by designing the leading edge for different values of nose radius and by vii assigning appropriate thickness values for leading edge components. Then the SPH bird model is impacted at varying impact velocites and results are compared with test data. It is proposed that the results obtained from simulation can be utilized in the initial design stages as well as for certification of an aircraft for birdstrike requirements as per federal regulations...|$|R
40|$|Two {{spanning}} {{trees of}} a given graph G having the same root r {{are said to be}} independent if for every vertex v of G the two paths from r to v along these two trees are vertex-disjoint. A set of spanning trees of G is said to be independent if they are pairwise independent. A two-dimension torus is a <b>mesh</b> with wrap-around <b>connections</b> in both the vertical and horizontal directions. Any two-dimension torus has four independent spanning trees rooted at the same vertex. In this paper, a linear time algorithm is proposed to construct four independent spanning trees on a two-dimension torus...|$|R
50|$|The confederated AS is {{composed}} of multiple ASs. Each confederated AS alone has iBGP fully <b>meshed</b> and has <b>connections</b> to other ASs inside the confederation. Even though these ASs have eBGP peers to ASs within the confederation, the ASs exchange routing as if they used iBGP. In this way, the confederation preserves next hop, metric, and local preference information. To the outside world, the confederation {{appears to be a}} single AS. From this solution, iBGP transit AS problems can be resolved as iBGP requires a full mesh between all BGP routes: large number of TCP sessions and unnecessary duplication of routing traffic.|$|R
40|$|Click on the DOI link {{to access}} the article (may not be free). With the {{increase}} in air travel, the recent occurrences of birdstrikes on aircraft pose {{a major threat to}} human life; hence, {{there is a need to}} develop aircraft structures with a high resistance to such occurrences. According to the Federal Aviation Regulation (FAR 25. 571) on Damage-Tolerance and Fatigue Evaluation of Structure (Amdt. 25 - 96), an airplane must be capable of successfully completing a flight during which likely structural damage might occur as a result of impact with a four-pound (1. 8 kg) bird at sea-level cruise velocity or 0. 85 percent of cruise velocity at 8, 000 feet (2, 400 m). Since the actual physical testing of a birdstrike is expensive, time-consuming, and cumbersome, this paper presents a methodology, based on the use of analytical finite element modeling and analysis, to certify an aircraft for a birdstrike. In actual physical testing for birdstrikes the mass of the bird might not be accurate and hence for certification purpose the computational modelling technique is more accurate and standardizes the certification procedure. The modeling and simulations are carried out as follows: the bird is modeled using the smooth particle hydrodynamics (SPH) technique in the LS-Dyna nonlinear finite element code. To validate this model, birdstrikes are carried out on rigid and deformable plates. The results, including displacement, Von-Mises stresses, forces, impulse, squash time and rise time, are obtained from the simulation, and non-dimensional values are plotted and compared with results from the test data. The detailed CAD geometry of the leading edge of an aircraft is modeled in CATIA V 5. <b>Meshing,</b> <b>connections,</b> and material properties are then defined in the Altair Hypermesh 9. 0 program. The results obtained from the birdstrike simulations on this leading edge are compared to data from the experiments, and the process is validated. Parametric studies are carried out by designing the aircraft leading edge for different values of nose radius and by assigning appropriate thickness values for leading-edge components and impacting the SPH-modeled bird at different velocities. The methodology and results obtained from simulation can be utilized in the initial design stages as well as for “certification by analysis” of an aircraft for birdstrike requirements as per federal regulations...|$|R
40|$|We {{model the}} {{functioning}} of different wiring schemes in visual projections using artificial neural networks and so speculate on selective factors underlying taxonomic variation in neural architecture. We model the high connective overlap of vertebrates (where networks have a dense <b>mesh</b> of <b>connections)</b> and the less overlapping, more modular architecture of arthropods. We also consider natural variation in these basic wiring schemes. Generally, arthropod networks are as efficient or more efficient in functioning compared to vertebrate networks. They do not show the confusion effect (decreasing targeting accuracy with increasing input group size), and they train as well or better. Arthropod networks are, however, generally poorer at reconstructing novel inputs. The ability of vertebrate networks to effectively process novel stimuli could promote behavioral sophistication and drive the evolution of vertebrate wiring schemes. Vertebrate networks with less connective overlap have, surprisingly, similar or superior properties compared to those with high connective overlap. Thus, the partial connective overlap seen in real vertebrate visual projections may be an optimal, evolved solution. Arthropod networks with and without whole‐cell neural connections within neural layers have similar properties. This indicates that neural connections mediated by offshoots of single cells (dendrites) may be fundamental to generating the confusion effect...|$|R
40|$|Abstract: Land mass {{transport}} systems {{have an open}} architecture and are vulnerable to terrorist attacks. In case of an explosion inside trains or stations, the risk of injuries and fatalities may be mitigated by properly strengthening and optimizing these structures. This risk depends on the peak overpressure and impulse, which are estimated here using numerical simulations, and is determined by special probit functions using the pressure–time curve calculated at each fluid point. The geometry of the structures investigated is obtained using a three-dimensional laser-scanning technology. Fluid–structure interaction (FSI) calculations have been performed, and for long, tube-like trains channelling effects have been considered. Several materials are {{used to describe the}} structural part of the models. A special FSI technique is presented, whereby a structure can be embedded in a fluid <b>mesh</b> without <b>connection</b> to the fluid nodes. This procedure avoids problems after the element erosion due to failure of the structure, e. g. of the glass. The results of case studies are shown in terms of structural displacements and the risk inside a metro line station, a train carriage, and a long train. The effects of venting areas, internal obstacles, such as seats, and passengers themselves to the air blast wave and the associated risk are examined and assessed...|$|R
30|$|Mobile {{applications}} {{have become}} an integral part of modern life and their intensive use has led to an exponential growth in the consumption of mobile data, and hence the requirement for 5 G mobile networks. Fog computing can not only provide a 5 G network with better service quality, but they can also help in predicting the future need of mobile users [44]. Inherently, Fog nodes are distributed within the proximity of users; a characteristic that reduces latency and establishes adjacent localized connections. Broadly speaking, the diverse and multiple topological and <b>mesh</b> network <b>connections</b> among Mobile network, Fog nodes, and Cloud platform make Fog system beneficial for 5 G technology, NLV and SDN [45]. Fog computing is also able to handled load balancing issues of a 5 G network [46]. When many users are simultaneously requesting computation in a large-scale network, creating small cells of Fog nodes based on the size of requested task and system parameters can improve load balancing. This joint optimisation of multiple users can improve the Quality of Experience (QoE) and network performance by 90 % of up to 4 users per small cell. Edge computing is also being used for reducing network latency, ensuring highly efficient service delivery and offering an improved user experience by utilising programmable nature of NLV and SDN [47].|$|R
40|$|Land mass {{transport}} systems {{have an open}} architecture and are vulnerable to terrorist attacks. In case of an explosion inside trains or stations, the risk of injuries and fatalities may be mitigated by properly strengthening and optimizing these structures. This risk depends on the peak over-pressure and impulse, which are here estimated using numerical simulations, and is determined by special probit functions using the pressure-time curve calculated at each fluid point. The geometry of the structures investigated is obtained using a 3 D laser scanning technology. Fluid-structure interaction (FSI) calculations have been performed, and for long, tube-like trains channelling effects have been considered. Several materials are {{used to describe the}} structural part of the models. A special FSI technique is presented, whereby a structure can be embedded in a fluid <b>mesh</b> without <b>connection</b> to the fluid nodes. This procedure avoids problems after the element erosion due to failure of the structure, e. g. of the glass. The results of case studies are shown in terms of structural displacements and the risk inside a metro line station, a train carriage, and a long train. The effects of venting areas, internal obstacles, like seats, and passengers themselves onto the air blast wave and on the associated risk are examined and assessed. JRC. DG. G. 5 -European laboratory for structural assessmen...|$|R
40|$|To {{answer the}} need for an {{efficient}} and robust geothermal simulation tool going beyond existing code capabilities in terms of geological and physical complexity, we have started to develop a parallel geothermal simulator based on unstructured meshes. The model takes into account complex geology including fault networks acting as major heat and mass transfer corridors and complex physics coupling the mass and energy conservations to the thermodynamical equilibrium between the gas and liquid phases. The objective of this Cemracs project is to focus on well modeling which is a key missing ingredient in our current simulator in order to perform realistic geothermal studies both in terms of monitoring and in terms of history matching. The well is discretized by a set of edges of the mesh in order to represent efficiently slanted or multi-branch wells on unstructured <b>meshes.</b> The <b>connection</b> with the 3 D matrix and the 2 D fault network at each node of the well is accounted for using Peaceman's approach. The non-isothermal flow model inside the well is based on the usual single unknown approach assuming the hydrostatic and thermodynamical equilibrium inside the well. The parallelization of the well model is implemented {{in such a way that}} the assembly of the Jacobian at each Newton step and the computation of the pressure drops inside the well can be done locally on each process without MPI communications...|$|R
40|$|Planetary {{gearboxes}} generate considerable {{noise and}} vibration due to high bearing loads and nonlinear dynamic behaviors. Excessive vibration leads to gear tooth and bearing failures. Despite of archival gearbox research, {{there are a few}} research aspects that are not fully-developed. They are: 1) tooth wedging (tight tooth <b>mesh)</b> and its <b>connection</b> with planet bearing failures; 2) nonlinear dynamics of planetary gears with bearing clearance; 3) stiffness determination of rolling element bearings; and 4) multi-body gearbox modeling linking gearbox vibration and noise radiation. Analyzing dynamic bearing and tooth loads of planetary gears is essential to improve gearbox reliability. Chapter 2 focuses on tooth wedging in wind turbine drivetrains, which is a potential source for gearbox failures. Lumped-parameter and finite element/contact mechanics models of planetary gears with tooth wedging, grav-ity, aerodynamic excitations, and mesh stiffness variation are developed to compute dynamic bearing or tooth forces. Tooth wedging elevates planet bearing forces and disrupts load sharing. A method to quantify tooth wedging is developed and verified...|$|R
40|$|An {{overview}} {{is given}} of the QCDOC architecture, a massively parallel and highly scalable computer optimized for lattice QCD using system-on-a-chip technology. The {{heart of a}} single node is the PowerPC-based QCDOC ASIC, developed in collaboration with IBM Research, with a peak speed of 1 GFlop/s. The nodes communicate via high-speed serial links in a 6 -dimensional <b>mesh</b> with nearest-neighbor <b>connections.</b> We find that highly optimized four-dimensional QCD code obtains over 50 % efficiency in cycle accurate simulations of QCDOC, even for problems of fixed computational difficulty run on {{tens of thousands of}} nodes. We also provide an overview of the QCDOC operating system, which manages and runs QCDOC applications on partitions of variable dimensionality. Finally, the SciDAC activity for QCDOC and the message-passing interface QMP specified {{as a part of the}} SciDAC effort are discussed for QCDOC. We explain how to make optimal use of QMP routines on QCDOC in conjunction with existing C and C++ lattice QCD codes, including the publicly available MILC codes. 1...|$|R
