34|0|Public
50|$|Calcium stearoyl-2-lactylate is a food {{additive}} that {{is found}} in many food products, such as baked goods, desserts, powdered drink mixes, dehydrated potatoes, and chewing gums. In Canada, {{it is commonly used}} in yeast-leavened recipes as an emulsifier during bread making. In bread, calcium stearoyl-2-lactylate helps to improve the <b>mixability</b> of the dough and strengthen it. It also improves bread’s grain and texture, as well as the volume of the final loaf.|$|E
5000|$|In 2015 Vann {{created an}} {{evaluation}} system as the 21st Century award for quality and credibility called Liquor Rank. It exists {{to provide the}} definitive last word on spirits and beverage evaluation and provide you limitless opportunities to market your brand. Each product is reviewed under ideal tasting conditions {{by a panel of}} experts of which Vann is a seat member, who know what they and ultimately consumers, are looking for. Each product submitted to Liquor Rank is evaluated and ranked in blind tastings ensuring your rank is bias free. Beer wine and spirits industry trade buyers and consumers recognize and respond to the value of Liquor Rank's accolades and scores, setting itself apart from over saturated liquor competitions that will hand over a medal to almost anyone who enters, Liquor Rank is different; it's the last word on quality. A favorable Liquor Rank is easily and immediately recognized as a symbol of achievement as it was earned via the ultimate definition of balanced spirits evaluation. Your brand truly earns its score, it doesn't just get awarded a medal for showing up. Victoria has said this about how Liquor Rank works, [...] "Literally, you take a number, and we all know numbers are useful. They help us count; our money, our time, and just where we stand in the world. In the world of selling more liquor it is your Liquor Rank that counts. You put your heart and soul into this spirit, now it's time to tell everyone just how good it is. Your Liquor Rank is based on your product and your product alone. It's not about how you stack up against the next guy, not what another category is doing in terms of increasing their sales and market penetration, but, quite simply your Liquor Rank reflects the positive qualities your liquid brings to the glass. Liquor Rank is the defining number that, at a glance, allows buyers and consumers to know just what to expect when they pick up your bottle. Like well respected wine industry ratings systems Liquor Rank is based on a 20 point scale, set from 80-100. Your product is judged on its merits; taste, texture, color, aroma, <b>mixability,</b> and price. All of these factors are considered by our panel of experts." ...|$|E
40|$|The {{concept of}} ϕ-complete <b>mixability</b> and ϕ-joint <b>mixability</b> was first {{introduced}} in Bignozzi and Puccetti (2015), which is a direct extension of complete and joint <b>mixability.</b> Following Bignozzi and Puccetti (2015), we consider two cases of ϕ and investigate the ϕ-joint <b>mixability</b> for elliptical distributions and logarithmic elliptical distributions. The results generalize the corresponding ones of joint <b>mixability</b> for elliptical distributions in the literature. Comment: 10 page...|$|E
40|$|In this paper, we further {{develop the}} theory of {{complete}} <b>mixability</b> and joint <b>mixability</b> for some distribution families. We generalize a result of Rüschendorf and Uckelmann (2002) related to complete <b>mixability</b> of continuous distribution function having a symmetric and unimodal density. Two different proofs to a result of Wang and Wang (2016) which related to the joint <b>mixability</b> of elliptical distributions with the same characteristic generator are present. We solve the Open Problem 7 in Wang (2015) by constructing a bimodal-symmetric distribution. The joint <b>mixability</b> of slash-elliptical distributions and skew-elliptical distributions is studied and the extension to multivariate distributions is also investigated. Comment: 15 page...|$|E
40|$|Statistical {{learning}} and sequential prediction {{are two different}} but related formalisms to study the quality of predictions. Mapping out their relations and transferring ideas is an active area of investigation. We provide another {{piece of the puzzle}} by showing that an important concept in sequential prediction, the <b>mixability</b> of a loss, has a natural counterpart in the statistical setting, which we call stochastic <b>mixability.</b> Just as ordinary <b>mixability</b> characterizes fast rates for the worst-case regret in sequential prediction, stochastic <b>mixability</b> characterizes fast rates in statistical learning. We show that, in the special case of log-loss, stochastic <b>mixability</b> reduces to a well-known (but usually unnamed) martingale condition, which is used in existing convergence theorems for minimum description length and Bayesian inference. In the case of 0 / 1 -loss, it reduces to the margin condition of Mammen and Tsybakov, and in the case that the model under consideration contains all possible predictors, it is equivalent to ordinary <b>mixability.</b> ...|$|E
40|$|We {{introduce}} {{the concepts of}} ϕ -complete <b>mixability</b> and ϕ -joint <b>mixability</b> and we investigate some necessary and sufficient conditions to the ϕ -mixability {{of a set of}} distribution functions for some supermodular functions ϕ. We give examples and numerical verifications which confirm our findings...|$|E
40|$|<b>Mixability</b> of a loss characterizes fast {{rates in}} the online {{learning}} setting of prediction with expert advice. The determination of the <b>mixability</b> constant for binary losses is straightforward but opaque. In the binary case we make this transparent and simpler by characterising <b>mixability</b> {{in terms of the}} second derivative of the Bayes risk of proper losses. We then extend this result to multiclass proper losses where there are few existing results. We show that <b>mixability</b> is governed by the maximum eigenvalue of the Hessian of the Bayes risk, relative to the Hessian of the Bayes risk for log loss. We conclude by comparing our result to other work that bounds prediction performance in terms of the geometry of the Bayes risk. Although all calculations are for proper losses, we also show how to carry the results across to improper losses...|$|E
40|$|Predictive {{complexity}} is a generalisation of Kolmogorov complexity. In {{this paper}} we point out some properties of predictive complexity {{connected with the}} Legendre ( [...] Young [...] Fenchel) transformation. Our main result is that <b>mixability</b> {{is necessary for the}} existence of conditional predictive complexity (it is known to be sufficient under very mild assumptions). We formulate a differential criterion of <b>mixability</b> and show that it reduces to a very simple form if we employ the Legendre transformation. The Legendre transformation also turns out to have a probabilistic meaning which allows us to prove that a variant of predictive complexity specifies a unique (up to a parametrisation) mixable game. Keywords: <b>Mixability,</b> Convexity, Conjugated Function. CONTENTS 2 Contents 1 Introduction 3 2 Definitions 3 3 The Existence of Predictive Complexity 5 3. 1 <b>Mixability</b> as a Sufficient Condition. 5 3. 2 Necessary Conditions. 6 4 The Legendre Transformation 9 4. 1 Definition and Some Properties. 9 [...] ...|$|E
40|$|Empirical risk {{minimization}} (ERM) is {{a fundamental}} algorithm for statistical learning problems where the data is generated according to some unknown distribution P and returns a hypothesis f chosen from a fixed class F with small loss `. In the parametric setting, depending upon (`,F,P) ERM can have slow (1 / n) or fast (1 /n) rates of convergence of the excess risk {{as a function of}} the sample size n. There exist several results that give sufficient conditions for fast rates in terms of joint properties of `, F, and P, such as the margin condition and the Bernstein condition. In the non-statistical prediction with experts setting, there is an analogous slow and fast rate phenomenon, and it is entirely characterized in terms of the <b>mixability</b> of the loss ` (there being no role there for F or P). The notion of stochastic <b>mixability</b> builds a bridge between these two models of learning, reducing to classical <b>mixability</b> in a special case. The present paper presents a direct proof of fast rates for ERM in terms of stochastic <b>mixability</b> of (`,F,P), and in so doing provides new insight into the fast-rates phenomenon. The proof exploits an old result of Kemperman on the solution to the generalized moment problem. We also show a partial converse that suggests a characterization of fast rates for ERM in terms of stochastic <b>mixability</b> is possible. ...|$|E
40|$|Abstract: Complete {{and joint}} <b>mixability</b> has raised {{considerable}} interest in recent few years, {{in both the}} theory of distributions with given margins, and applications in discrete optimization and quantitative risk manage-ment. We list various open questions {{in the theory of}} complete and joint <b>mixability,</b> which are mathematically concrete, and yet accessible to a broad range of researchers without specific background knowledge. In addition to the discussions on open questions, some results contained in this paper ar...|$|E
40|$|International audienceMixability of a loss characterizes fast {{rates in}} the online {{learning}} setting of prediction with expert advice. The determination of the <b>mixability</b> constant for binary losses is straightforward but opaque. In the binary case we make this transparent and simpler by characterising <b>mixability</b> {{in terms of the}} second derivative of the Bayes risk of proper losses. We then extend this result to multiclass proper losses where there are few existing results. We show that <b>mixability</b> is governed by the maximum eigenvalue of the Hessian of the Bayes risk, relative to the Hessian of the Bayes risk for log loss. We conclude by comparing our result to other work that bounds prediction performance in terms of the geometry of the Bayes risk. Although all calculations are for proper losses, we also show how to carry the results across to improper losses...|$|E
40|$|<b>Mixability</b> of a loss {{is known}} to characterise when {{constant}} regret bounds are achievable in games of prediction with expert advice {{through the use of}} Vovk's aggregating algorithm. We provide a new interpretation of <b>mixability</b> via convex analysis that highlights the role of the Kullback-Leibler divergence in its definition. This naturally generalises to what we call Φ-mixability where the Bregman divergence D_Φ replaces the KL divergence. We prove that losses that are Φ-mixable also enjoy constant regret bounds via a generalised aggregating algorithm that is similar to mirror descent. Comment: 12 page...|$|E
40|$|In {{the recent}} years, {{the notion of}} <b>mixability</b> has been {{developed}} with applications to optimal transportation, quantitative finance and operations research. An n-tuple of distributions {{is said to be}} jointly mixable if there exist n random variables following these distributions and adding up to a constant, called center, with probability one. When the n distributions are identical, we speak of complete <b>mixability.</b> If each distribution has finite mean, the center is obviously the sum of the means. In this paper, we investigate the set of centers of completely and jointly mixable distributions not having a finite mean. In addition to several results, we show the (possibly counterintuitive) fact that, for each n ≥ 2, there exist n standard Cauchy random variables adding up to a constant C if and only if |C|<n (n- 1) /π. ...|$|E
40|$|<b>Mixability</b> is a {{property}} of a loss which characterizes when fast convergence {{is possible in}} the game of prediction with expert advice. We show that a key property of <b>mixability</b> generalizes, and the exp and log operations present in the usual theory are not as special as one might have thought. In doing this we introduce a more general notion of Φ-mixability where Φ is a general entropy (, any convex function on probabilities). We show how {{a property}} shared by the convex dual of any such entropy yields a natural algorithm (the minimizer of a regret bound) which, analogous to the classical aggregating algorithm, is guaranteed a constant regret when used with Φ-mixable losses. We characterize precisely which Φ have Φ-mixable losses and put forward a number of conjectures about the optimality and relationships between different choices of entropy. Comment: 20 pages, 1 figure. Supersedes the work in arXiv: 1403. 2433 [cs. LG...|$|E
40|$|Purpose: The aim of {{this study}} is to {{evaluate}} a newly developed polymethyl methacrylate (PMMA) powder. Methods: The particle size distribution, surface area, and particle shape of both new and traditional powders were compared. The shear bond strength of the resin cement with the new powder to a silver-palladium-copper-gold alloy was determined and compared to that for a cement with the traditional powder. Also, the weight of mixture held by the brush at one time of both powders was also calculated and compared as an index of <b>mixability.</b> Results: The surface area of the new powder was smaller than that of the traditional powder, while the particles size distributions were similar. The new powder included various-sized spherical particles as well as irregular particles, while the traditional powder consisted of only irregular particles. The new powder showed significantly higher <b>mixability,</b> although its bond strength was not significantly different from that of traditional powder. Conclusion: The results of this study show that the interminglement of spherical and irregular particles cannot influence the bond strength to the alloy but is helpful to improve the working properties...|$|E
40|$|Following {{the results}} of Rüschendorf and Uckelmann (2002) Â [20], we {{introduce}} the completely mixable distributions on and prove that the distributions with monotone density and moderate mean are completely mixable. Using this method, we solve the minimization problem for convex functions f and marginal distributions P with monotone density. Our results also provide valuable implications in variance minimization, bounds for the sum of random variables and risk theory. Complete <b>mixability</b> Variance minimization Multivariate dependence Monotone densities Optimal coupling...|$|E
40|$|We {{study the}} {{population}} genetics of Evolution in the important special case of weak selection, {{in which all}} fitness values {{are assumed to be}} close to one another. We show that in this regime natural selection is tantamount to the multiplicative updates game dynamics in a coordination game between genes. Importantly, the utility maximized in this game, as well as the amount by which each allele is boosted, is precisely the allele's <b>mixability,</b> or average fitness, a quantity recently proposed in [1] as a novel concept that is crucial in understanding natural selection under sex, thus providing a rigorous demonstration of that insight. We also prove that the equilibria in two-person coordination games can have large supports, and thus genetic diversity does not suffer much at equilibrium. Establishing large supports involves answering through a novel technique the following question: what is the probability that for a random square matrix A both systems Ax = 1 and A^T y = 1 have positive solutions? Both the question and the technique may be of broader interest. [1] A. Livnat, C. Papadimitriou, J. Dushoff, and M. W. Feldman. A <b>mixability</b> theory for the role of sex in evolution. Proceedings of the National Academy of Sciences, 105 (50) : 19803 - 19808, 2008...|$|E
40|$|AbstractThis paper {{resolves}} {{the problem}} of predicting {{as well as the}} best expert up to an additive term of the order o(n), where n is the length of a sequence of letters from a finite alphabet. We call the games that permit this weakly mixable and give a geometrical characterisation of the class of weakly mixable games. Weak <b>mixability</b> turns out to be equivalent to convexity of the finite part of the set of superpredictions. For bounded games we introduce the Weak Aggregating Algorithm that allows us to obtain additive terms of the form Cn...|$|E
40|$|For many Lap-on-a-Chip applications, {{rapid and}} {{homogenous}} mixing {{of two or}} more fluid species is inevitable. However, it is also of great importance to developing a quick and convenient method for monitoring the mixture processing, as well as the entire working process of the Lab-on-a-chip. In order to develop a quick and convenient method, this paper is dedicated to establish a non-contact image way for monitoring not only the liquid flow behavior, but also the <b>mixability</b> between each reactant. The far-infrared thermal imaging system was adopted to detect and map the surface temperature distribution of the micromixer, which consequently could help achieve the non-contact monitoring of the mixing process...|$|E
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. A low fat tortilla was developed by optimizing lipids, emulsifiers and fat replacers. Hot-press wheat tortillas were prepared from wheat flour with 11. 6 % protein. Lard, pie shortening (PS), all-purpose shortening (AP), liquid frying oil (LF) and salad oil (SO) were used at levels of 1, 4, 7, 10 and 15 %. Tortillas were made with 0. 5 and 1. 0 % glyceryl monostearate (GM), succinylated monoglycerides (SMG), ethoxylated monoglycerides (EMG) and diacetyl tartaric acid esters of mono- and diglycerides (DATEM). Finally, tortillas were made with commercially available, carbohydrate-based fat replacers: potato maltodextrins, tapioca maltodextrins, pregelatinized rice flour, modified rice solids, and pea starch. Dough water absorption, mixing time, <b>mixability</b> and machinability were determined. Tortillas were evaluated for puffing during baking, weight, moisture, diameter, rollability, penetrability and organoleptic properties. As lipid levels decreased, mixing time decreased, water absorption increased and <b>mixability</b> decreased. As lipid levels decreased tortilla puffing and diameter decreased, weights were similar and moisture increased. Rollabilities of tortillas containing 4 - 15 % lipid were better than those containing 1 % lipid. Rollabilities of tortillas containing lard, PS and SO were better than those containing AP and LF. Textures of tortillas containing > 7 % lard were significantly worse that those with 4 % lard were ranked higher than those containing 1 % lard. Tortillas containing SMG had better dough <b>mixability</b> and larger diameter tortillas during hot pressing than tortillas containing EMG or DATEM. Rollabilities of tortillas containing 1. 0 % SMG, GM and DATEM were better than the control after ten days of storage. Rollabilities of tortillas containing 0. 5 and 1. 0 % SMG were similar. Doughs containing fat replacers had increased water absorptions and excellent machinability. Rollabilities of tortillas containing tapioca maltodextrins were significantly worse than other treatments. Rollabilities of both control (1 % lipid and 10 % lipid) tortillas and tortillas containing potato maltodextrins were better than other tortillas. Textures of tortillas containing 10 % lipid were better than other treatments organoleptically evaluated. Tortillas containing 10 % lipid, 1 % lipid and potato maltodextrins were ranked similarly...|$|E
40|$|To {{maximize}} {{the efficiency of}} the Space Transportation System as a shared cargo launch system and to enhance the <b>mixability</b> and launch opportunities for payloads carried on the Space Shuttle, the National Aeronautics and Space Administration has developed a shared cargo standard launch window. The launch window is based on the transfer orbit sun angle requirements of an established, common class of geosynchronous communications satellites. This standard window is applicable to mixed cargoes launched from the John F. Kennedy Space Center into 28. 5 deg inclination orbits. The window consists of two time periods, each 2 hrs long and centered at 0023 and 1223 Greenwich mean time; it extends unchanged throughout the year...|$|E
40|$|The {{relative}} {{high cost}} remains an obstacle for wider commercial use of Engineered Cement-based Composites (ECC). By making {{extensive use of}} locally available, waste materials as ingredients, this may be overcome. In this paper, the use of large quantities of fly-ash (FA) and ground granulated blast furnace slagment (slag) is reported. Their influence on ECC mechanical response in direct tensile tests is quantified {{and the reasons for}} the different behaviours studied via scanning electron microscope (SEM) photos. This study is performed on ECC specimens containing varying amounts of slag and/or fly-ash to assist in rational ECC mix design strategies. Particular focus is on the beneficial effect of fly-ash on the fresh <b>mixability</b> and eventual toughness of ECC. To compensate for the slow early-age strength development, fine grounded slagment is blended into the mix. 1...|$|E
40|$|In {{this paper}} we {{consider}} {{a large family}} of random locations, called intrinsic location functionals, of periodic stationary processes. This family includes but {{is not limited to}} the location of the path supremum, the first hitting time, and the last hitting time. We first show that the set of all possible densities of intrinsic location functionals for periodic stationary processes is the convex hull generated by a specific group of density functions. Next, we focus on two special types of intrinsic locations, the invariant and the first-time intrinsic locations. For the former, we show that the density has a uniform lower bound, and the corresponding distribution can always be constructed via the location of the path supremum. For the latter, the structure of the set of the densities is closely related to the concept of joint <b>mixability.</b> Comment: 25 page...|$|E
40|$|This article {{deals with}} the design of {{redundant}} metering valves for mechanically signalled hydraulic actuators. The final aim {{of the work is}} to manufacture a new low-cost valve in replacement of the existing expensive valve with an additional leakage requirement in case of seizure. The new valve must ensure the same closed-loop behaviour of the actuator. The article presents the design of the valve according to the actuator specifications and to a criterion of <b>mixability</b> (capacity to replace the existing valve by a new one). The valve pre-design is based on the common sharp edges and rectangular orifice slots combined with a serial restrictor inserted on the supply line. After partial experimental validation, the proposed design process points out the interest of using a trapezoidal slot {{in order to get the}} required speed gain over the whole valve opening range. The proposal is validated through the experimental measurement of the actuator no-load speed as a function of the valve opening...|$|E
40|$|The {{guardians of}} {{children}} {{brought to the}} Port Moresby General Hospital's Children's Outpatient Department with a chief complaint of diarrhoeal disease were questioned regarding their preference of glucose-based vs rice-based oral rehydration solution (ORS) {{in order to determine}} the acceptability of a rice-based ORS. Of the 93 guardians interviewed, greater than 60 % preferred the glucose-based solution in its <b>mixability,</b> appearance and taste, and 65 % initially reported that their children preferred the taste of the glucose solution. However, after a 30 -minute trial, only 58 % of children still preferred the glucose solution. In a country where diarrhoeal disease is a leading cause of child death and guardians are the primary health care providers, the acceptability of an ORS is critical to the morbidity and mortality of Papua New Guinea's children. Killing an estimated 2. 9 million children annually, diarrheal disease is the second leading cause of child mortality worldwide. Diarrheal disease is also the second leading cause of child mortality in Papua New Guinea (PNG), killing an average 193 inpatient children per year over the period 1984 - 90. However, despite the high level of diarrhea-related mortality and the proven efficacy of oral rehydration therapy (ORT) in managing diarrhea-related dehydration, standardized ORT has been underutilized in PNG. The current glucose-based oral rehydration solution (ORS) does not reduce the frequency or volume of a child's diarrhea, the most immediate concern of caregivers during episodes of illness. Cereal-based ORS, made from cereals which are commonly available as food staples in most countries, better address the short-term concerns of caregivers while offering a superior nutritional profile. A sample of guardians of children brought to the Port Moresby General Hospital's Children's Outpatient Department complaining of child diarrhea were asked about their preferences on glucose-based versus rice-based ORS {{in order to determine the}} acceptability of a rice-based ORS. More than 60 % of the 93 guardians interviewed preferred the glucose-based solution for its <b>mixability,</b> appearance, and taste. 65 % initially reported that their children preferred the taste of the glucose solution. However, after a 30 -minute trial, only 58 % of children still preferred the glucose solution...|$|E
40|$|The primary {{objective}} of this task was to perform a variability study of the high activity waste (HAW) acidic feed to determine the impact of feed variability {{on the quality of}} the final grout and on the <b>mixability</b> of the salt solution into the dry powders. The HAW acidic feeds were processed through the neutralization/pH process, targeting a final pH of 12. These fluids were then blended with the dry materials to make the final waste forms. A secondary objective was to determine if elemental substitution for cost prohibitive or toxic elements in the simulant affects the mixing response, thus providing a more economical simulant for use in full scale tests. Though not an objective, the HAW simulant used in the full scale tests was also tested and compared to the results from this task. A statistically designed test matrix was developed based on the maximum molarity inputs used to make the acidic solutions. The maximum molarity inputs were: 7. 39 HNO{sub 3 }, 0. 11618 gallium, 0. 5423 silver, and 1. 1032 'other' metals based on their NO{sub 3 }{sup -} contribution. Substitution of the elements aluminum for gallium and copper for silver was also considered in this test matrix, resulting in a total of 40 tests. During the NaOH addition, the neutralization/pH adjustment process was controlled to a maximum temperature of 60 C. The neutralized/pH adjusted simulants were blended with Portland cement and zircon flour at a water to cement mass ratio of 0. 30. The mass ratio of zircon flour to Portland cement was 1 / 12. The grout was made using a Hobart N- 50 mixer running at low speed for two minutes to incorporate and properly wet the dry solids with liquid and at medium speed for five minutes for mixing. The resulting fresh grout was measured for three consecutive yield stress measurements. The cured grout was measured for set, bleed, and density. Given the conditions of preparing the grout in this task, all of the grouts were visually well mixed prior to preparing the grouts for measurements. All of the cured grouts were measured for bleed and set. All of the cured grouts satisfied the bleed and set requirements, where no bleed water was observed on any of the grout samples after one day and all had set within 3 days of curing. This data indicates, for a well mixed product, bleed and set requirement are satisfied for the range of acidic feeds tested in this task. The yield stress measurements provide both an indication on the <b>mixability</b> of the salt solution with dry materials and an indication of how quickly the grout is starting to form structure. The inability to properly mix these two streams into a well mixed grout product will lead to a non-homogeneous mixture that will impact product quality. Product quality issues could be unmixed regions of dry material and hot spots having high concentrations of americium 241. Mixes that were more difficult to incorporate typically resulted in grouts with higher yield stresses. The <b>mixability</b> from these tests will provide Waste Solidification Building (WSB) an indication of which grouts will be more challenging to mix. The first yield stress measurements were statistically compared to a list of variables, specifically the batched chemicals used to make the acidic solutions. The first yield stress was also compared to the physical properties of the acidic solutions, physical and pH properties of the neutralized/pH adjusted solutions, and chemical and physical properties of the grout...|$|E
40|$|We call {{a matrix}} {{completely}} mixable if the entries in its columns can be permuted {{so that all}} row sums are equal. If it is not completely mixable, we want to determine the smallest maximal and largest minimal row sum attainable. These values provide a discrete approximation of of minimum variance problems for discrete distributions, a problem motivated by the question how to estimate the α-quantile of an aggregate random variable with unknown dependence structure given the marginals of the constituent random variables. We relate this problem to the multidimensional bottleneck assignment problem and show that there exists a polynomial 2 -approximation algorithm if the matrix has only 3 columns. In general, deciding complete <b>mixability</b> is NP-complete. In particular the swapping algorithm of Puccetti et al. is not an exact method unless NP⊆ZPP. For a fixed number of columns it remains NP-complete, but there exists a PTAS. The problem can be solved in pseudopolynomial time for a fixed number of rows, and even in polynomial time if all columns furthermore contain entries from the same multiset...|$|E
40|$|Aqueous {{miscible}} organic layered double hydroxides (AMO-LDHs) {{can act as}} organophilic inorganic {{flame retardant}} nanofillers for unmodified non-polar polymers. In this contribution, AMO [Mg 3 Al(OH) 8](CO 3) 0. 5 ·yH 2 O LDH-oxidized carbon nanotube (AMO-LDH-OCNT) hybrids are shown to perform better than the equivalent pure AMO-LDH. A synergistic effect between the AMO-LDH and OCNT was observed; this endows the hybrid material with enhanced flame retardancy, thermal stability, and mechanical properties. The thermal stability of polypropylene (PP) was significantly enhanced by adding AMO-LDH-OCNT hybrids. For PP mixed with AMO-LDH-OCNT hybrids to produce a composite with 10 wt% LDH and 2 wt% OCNT, the 50 % weight loss temperature was increased by 43 [*]°C. Further, a system with 10 [*]wt% of AMO-LDH and 1 [*]wt% OCNT showed a peak heat release rate (PHRR) reduction of 40 %, greater than the PHRR reduction with PP/ 20 [*]wt% AMO-LDH (31 %). The degree of dispersion (<b>mixability)</b> between AMO-LDH and OCNT has {{a significant effect on}} the flame retardant performance of the hybrids. In addition, the incorporation of AMO-LDH-OCNT hybrids led to better mechanical properties, such as higher tensile strength (27. 5 [*]MPa) and elongation at break (17. 9 %), than those composites containing only AMO-LDH (25. 6 [*]MPa and 7. 5 %, respectively) ...|$|E
40|$|The {{speed with}} which a {{learning}} algorithm converges as it is presented with more data is a central problem in machine learning — a fast rate of convergence means less data is needed for {{the same level of}} performance. The pursuit of fast rates in online and statistical learning has led to the discovery of many conditions in learning theory under which fast learning is possible. We show that most of these conditions are special cases of a single, unifying condition, that comes in two forms: the central condition for ‘proper ’ learning algorithms that always output a hypothesis in the given model, and stochastic <b>mixability</b> for online algorithms that may make predictions outside of the model. We show that under surprisingly weak assumptions both conditions are, in a certain sense, equivalent. The central condition has a re-interpretation in terms of convexity of a set of pseudoprobabilities, linking it to density estimation under misspecification. For bounded losses, we show how the central condition enables a direct proof of fast rates and we prove its equivalence to the Bernstein condition, itself a generalization of the Tsybakov margin condition, both of which have {{played a central role in}} obtaining fast rates in statistical learning. Yet, while th...|$|E
40|$|Friction stir welding (FSW) is a {{solid state}} welding process used widely in the {{manufacturing}} industry, mainly with soft materials with poor fusion weldability such as aluminium. In this investigation the material behaviour of dissimilar friction stir welded 5 XXX and 6 XXX series aluminium alloys was examined. Both alloys are used extensively in the transport industry, however exhibit different properties. 5 XXX series are non-heat treatable, hard alloys with poor cold working ability. In contrast, 6 XXX series are softer, heat treatable alloys with better formability. FSW {{can be used to}} take advantage of these differences in mechanical properties to fuse dissimilar metals. It was found that the overall <b>mixability</b> of the two materials was low, with all of the non-solutionised dissimilar samples failing the bend test. However, with the pre-weld heat treated (solutionised) samples one of the dissimilar welds passed the bend test. This suggests greater mixing between the two materials when the Al- 6060 is in the solutionised and softened state. It was also found that the hardness profile of the solutionised samples was more uniform across the weld compared to the non-solutionised; {{this is due to the}} complete dissolution of precipitates before welding, meaning overaging in the HAZ does not occur. It was also found the pre-weld heat treated samples show the same grain structure as the non-heat treated, which differs from what has been found with post weld heat treatment...|$|E
40|$|Specific {{problems}} are posed by medicated premixes : {{stability of the}} active ingredient, homogeneity of the medicated premix distribution in the feed and cross-contammation due to dust emission These problems can have two major consequences· a treatment failure and a risk for human health with selection of res 1 stant strains CEVA Matrix Technology, an exclusive CEVA Sante Ammale manufacturing process, matches all expectations of an effective and modern medicated premix. CEVA Matrix Technology consists of an innovative protective granulation technology. Most non-protected medicated premixes available in the market do not provide good stability and may not reach efficient concentration as the active ingredient is not protected enough. First, the CEVA Matrix Technology guarantees that the active ingredient is protected during manufacture (pelleting) and storage of the medicated feed without altenng its bioavailability. Secondly, the particle size of CEVA Matrix Technology premixes {{is similar to the}} feed in which it is to be blended. Therefore the active ingredient is mixed homogeneously into the feed and remains homogeneous even after transportation and storage. This perfect <b>mixability</b> ensures the right active ingredient concentration and dosage in feed every time. Consequently, treatment failure resulting from unequal dosage distribution of the active ingredient in the feed is considerably limited. Thirdly, CEVA Matrix Technology guarantees that the premix does not release dust. Therefore, it reduces risks such as cross contamination between two medicated feed batches in mills and inhalation of antimicrobial by users. It protects the workforce and reduces the risk of selecting resistant strams. This article validates all these points by comparing a tiamulin medicated premix manufactured with the CEVA Matrix Technology and some non-protected tiamulin...|$|E
40|$|Aggregating {{financial}} assets {{together to form}} a portfolio, commonly referred to as "asset pooling", is a standard practice in the banking and insurance industries. Determining a suitable probability distribution for this portfolio with each underlying asset is a challenging task unless several distributional assumptions are made. On the other hand, imposing assumptions on the distribution inhibits its ability to capture various idiosyncratic behaviors. It limits the model's usefulness in its ability to provide realistic risk metrics of the true portfolio distribution. In order to conquer this limitation, we propose two methods to model a pool of assets with much less assumptions on the correlation structure by way of finding analytical bounds. Our first method uses the Fréchet-Hoeffding copula bounds to calculate model-free upper and lower bounds for aggregate assets evaluation. For the copulas with specific constraints, we improve the Fréchet- Hoeffding copula bounds by providing bounds with narrower range. The improvements proposed are very robust for different types of constraints on the copula function. However, the lower copula bound does not exist for dimension three and above. Our second method tackles the open problem of finding lower bounds for higher dimensions by introducing the concept of Complete <b>Mixability</b> property. With such technique, we are able to find the lower bounds with specified constraints. Three theorems are proposed. The first theorem deals with the case where all marginal distributions are identical. The lower bound defined by the first theorem is sharp under some technical assumptions. The second theorem gives the lower bound in a more general setup without any restriction on the marginal distributions. However the bound achieved in this context is not sharp. The third theorem gives the sharp lower bound on Conditional VaR. Numerical results are provided for each method to demonstrate sharpness of the bounds. Finally, we point out some possible future research directions, such as looking for a general sharp lower bound for high dimensional correlation structures...|$|E

