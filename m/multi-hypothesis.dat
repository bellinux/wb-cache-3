275|20|Public
5000|$|D Pederson, D Fanjoy. Solving {{the weapon}} target {{assignment}} problem with <b>multi-hypothesis</b> maximum marginal return. Military Operations Research Society Symposium. June 2007 ...|$|E
40|$|In this paper, we {{describe}} a <b>multi-hypothesis</b> prediction technique for disparity-compensated light field compression. Multihypothesis prediction {{has been used}} extensively in video compression. In this work, we apply <b>multi-hypothesis</b> prediction {{to the problem of}} light field compression. Most current techniques for light field compression utilize some form of disparity compensation with one hypothesis. We demonstrate that a <b>multi-hypothesis</b> approach, where two hypotheses are used, improves the overall efficiency of a light field coder. Our experimental results show an image quality gain of up to 1 dB in PSNR on our test data sets. 1...|$|E
40|$|<b>Multi-hypothesis</b> {{prediction}} extends {{motion compensation}} with one prediction {{signal to the}} linear superposition of several motion-compensated prediction signals. These motion-compensated prediction signals are referenced by motion vectors and picture reference parameters. This paper proposes a state-of-the-art video codec based on the ITU-T Recommendation H. 263 that incorporates <b>multi-hypothesis</b> motion-compensated prediction. In contrast to B-Frames, reference pictures are always previously decoded pictures. It is demonstrated that two hypotheses are eÆ-cient for practical video compression algorithms. In addition, it is shown that <b>multi-hypothesis</b> motion-compensated prediction and variable block size prediction can be combined to improve the overall coding gain. The encoder uti-lizes rate-constrained coder control including rate-constrained <b>multi-hypothesis</b> motion estimation. The advanced 4 -hypothesis codec improves coding eÆciency up to 1. 8 dB {{when compared to the}} advanced prediction codec with ten reference frames for the set of investigated test sequences...|$|E
40|$|We propose an {{approach}} to incorporating dynamic models into the human body tracking process that yields full 3 – D reconstructions from monocular sequences. We formulate the tracking problem in terms of minimizing a differentiable criterion whose differential structure is rich enough for successful optimization using a simple hill-climbing approach {{as opposed to a}} <b>multi-hypotheses</b> probabilistic one. In other words, we avoid the computational complexity of <b>multi-hypotheses</b> algorithms while obtaining excellent results under challenging conditions. To demonstrate this, we focus on monocular tracking of a golf swing from ordinary video. It involves both dealing with potentially very different swing styles, recovering arm motions that are perpendicular to the camera plane and handling strong self-occlusions. 1...|$|R
40|$|Optimal-partitioning and minimax risk inequalities are {{obtained}} for the classification and <b>multi-hypotheses</b> testing problems. Best possible bounds are derived for the minimax risk for location parameter families, based on the tail concentrations and Levy concentrations of the distributions. Special attention is given to continuous distributions with the maximum likelihood ratio property and to symmetric unimodal continuous distributions. Bounds for general (including discontinuous) distributions are also obtained...|$|R
40|$|This paper {{presents}} generalizations of Bayes likelihood-ratio updating rule which facilitate an asynchronous {{propagation of}} {{the impacts of}} new beliefs and/or new evidence in hierarchically organized inference structures with <b>multi-hypotheses</b> variables. The computational scheme proposed specifies a set of belief parameters, communication messages and updating rules which guarantee that the diffusion of updated beliefs is accomplished {{in a single pass}} and complies with the tenets of Bayes calculus...|$|R
40|$|<b>Multi-hypothesis</b> motion-compensated {{prediction}} extends traditional motion -compensated prediction used {{in video}} coding schemes. Known algorithms for block-based <b>multi-hypothesis</b> motion-compensated prediction are, for example, overlapped block motion compensation (OBMC) and bidirectionally predicted frames (B-frames). This paper presents a generalization of these algorithms in a rate-distortion framework. All blocks {{which are available}} for prediction are called hypotheses. Further, we explicitly distinguish between the search space and the superposition of hypotheses. Hypotheses are selected from a search space and their spatio-temporal positions are transmitted by means of spatiotemporal displacement codewords. Constant predictor coe#cients are used to combine linearly hypotheses of a <b>multi-hypothesis.</b> The presented design algorithm provides an estimation criterion for optimal multi-hypotheses, a rule for optimal displacement codes, and a condition for optimal predictor coe#cients...|$|E
3000|$|A <b>multi-hypothesis</b> SI {{creation}} method using four hypotheses as {{developed in}} [8] is used. The hypotheses {{are the two}} reference frames, [...]...|$|E
40|$|Anomaly {{detection}} {{in large}} populations is a challenging but highly relevant problem. It {{is essentially a}} <b>multi-hypothesis</b> problem, with a hypothesis for every division of the systems into normal and anomalous systems. The number of hypothesis grows rapidly {{with the number of}} systems and approximate solutions become a necessity for any problem of practical interest. In this paper we take an optimization approach to this <b>multi-hypothesis</b> problem. It is first shown to be equivalent to a non-convex combinatorial optimization problem and then is relaxed to a convex optimization problem that can be solved distributively on the systems and that stays computationally tractable as the number of systems increase. An interesting property of the proposed method is that it can under certain conditions be shown to give exactly the same result as the combinatorial <b>multi-hypothesis</b> problem and the relaxation is hence tight...|$|E
40|$|In appearance-based robot {{localization}} {{the environment}} map {{does not represent}} geometrical features but consists of an appearance map, which {{is a collection of}} robot poses and corresponding sensor observations. In this paper, we describe a concurrent map-building and localization (CML) system based on a <b>multi-hypotheses</b> tracker that is able to autonomously build and refine the appearance-map required for localization as the robot moves in the environment. The results included in the paper validate our approach...|$|R
40|$|This thesis {{presents}} the first automatic date processing system developed on a Canadian real-life standard cheque database. This system can process unconstrained handwritten dates written in English or in French, {{and it can}} also be applied to the recognition of any handwritten dates with similar format on many other kinds of documents. A knowledge-based module has been proposed for the date segmentation and a new cursive month word recognition system has also been implemented based on a combination of classifiers. The interaction between the segmentation and recognition stages has been properly established by using a <b>multi-hypotheses</b> generation and evaluation module. In addition, a verification module with two levels is designed in the postprocessing stage to correct some errors and reject invalid results, which further improves the reliability of the system. The segmentation of the date zone can be implemented in the knowledge-based segmentation module, the <b>multi-hypotheses</b> generation and evaluation module, or the verification module. An effective neural network ensemble system is proposed in this knowledge extraction stage to differentiate handwritten alphabetic words from numeric strings (A/N). We investigate the use of effective features extensively, and propose several new methods in the design of neural networks, creation of neural network ensembles, and combination methods for the ensembles created. For date recognition, the new cursive month word recognizer is implemented by combining a Hidden Markov Model classifier (HMM) with two Multi-Layer Perceptron (MLP) classifier...|$|R
40|$|Abstract — This paper {{presents}} an architectural overview of a robot-based visitor information {{system in a}} university building. Two mobile robots serve as mobile information terminals providing information about the employees, labs, meeting rooms, and offices in the building {{and are able to}} guide the visitors to these points of interest. The paper focuses on the different software components needed to meet the requirements of the multi-story office building. Furthermore, the integration of a <b>multi-hypotheses</b> person tracker is outlined, which helps the robots to interact with the people in their near surrounding. Besides first observations on interaction, the further development is outlined as well. I...|$|R
3000|$|... is unreliable. The derived <b>multi-hypothesis</b> motion {{field is}} {{employed}} in an analogous manner {{to estimate the}} chroma components of the side information frame from the chroma components of the reference frames R [...]...|$|E
40|$|This paper {{proposes a}} <b>multi-hypothesis</b> based Wyner-Ziv (WZ) decoder for the multi-view {{distributed}} video coding (MDVC). Two hypotheses, the intra-view SI and the inter-view SI, are fed together into the WZ decoder {{in the proposed}} scheme. A <b>multi-hypothesis</b> based correlation model (MHBCM) is presented to fully exploit the redundancy between these two SI frames and the original frame. The MHBCM is also applied on the optimal minimum mean-square error reconstruction of the quantized samples. The simulation {{results show that the}} proposed algorithms are able to significantly improve the coding efficiency of the MDVC system. Index Terms—multi-view video coding, distributed video coding, correlation model, reconstructio...|$|E
3000|$|... [...] "Self-Localisation and Stream Field Based Partially Observable Moving Object Tracking," [...] [...] "A POMDP Framework for Coordinated Guidance of Autonomous UAVs for Multitarget Tracking," [...] and [...] "Prioritized <b>Multi-Hypothesis</b> Tracking by a Mobile Robot." [...] [...]...|$|E
40|$|Abstract—In {{this paper}} {{we present a}} {{database}} correlation method combined with Bayes filtering as a pattern matching technique for mobile terminal localization in GSM suburban environments. A 3 D deterministic radio wave propagation prediction model {{is used for the}} database construction. Bayes filter provide a robust technique to deal with <b>multi-hypotheses</b> situations usually occur in cellular localization when the location dependent parameter considered is the radio power level. Furthermore, three methods used to yield a location estimate from the resulted hypotheses are presented and compared according to their performance. Results show very acceptable location accuracies relative to the considered suburban area, which is a typical environment in many populated parts of Germany. Keywords-Bayes filter; database correlation; mobile location I...|$|R
40|$|This paper {{presents}} a <b>Multi-Hypotheses</b> Tracking (MHT) approach that allows solving ambiguities that arise with previous methods of associating targets and tracks within a highly volatile vehicular environment. The previous approach {{based on the}} Dempster-Shafer Theory assumes that associations between tracks and targets are unique; this was shown to allow the formation of ghost tracks when {{there was too much}} ambiguity or conflict for the system to take a meaningful decision. The MHT algorithm described in this paper removes this uniqueness condition, allowing the system to include ambiguity and even to prevent making any decision if available data are poor. We provide a general introduction to the Dempster-Shafer Theory and present the previously used approach. Then, we explain our MHT mechanism and provide evidence of its increased performance in reducing the amount of ghost tracks and false positive processed by the tracking system...|$|R
40|$|International audienceThis paper {{addresses}} {{an important}} issue for intelligent transportation system, namely the ability of vehicles to safely and reliably localize themselves within an a priori known road map network. For this purpose, we propose an approach based on hybrid dynamic bayesian networks enabling to implement in a unified framework {{two of the most}} successful families of probabilistic model commonly used for localization: linear Kalman filters and Hidden Markov Models. The combination of these two models enables to manage and manipulate <b>multi-hypotheses</b> and multi-modality of observations characterizing Map Matching problems and it improves integrity approach. Another contribution of the paper is a chained-form state space representation of vehicle evolution which permits to deal with non-linearity of the used odometry model. Experimental results, using data from encoders’ sensors, a DGPS receiver and an accurate digital roadmap, illustrate the performance of this approach, especially in ambiguous situations...|$|R
40|$|Abstract — We {{present an}} {{approach}} to laser-based people tracking using a <b>multi-hypothesis</b> tracker that detects and tracks legs separately with Kalman filters, constant velocity motion models, and a <b>multi-hypothesis</b> data association strategy. People are defined as high-level tracks consisting of two legs that are found with little model knowledge. We extend the data association so that it explicitly handles track occlusions in addition to detections and deletions. Additionally, we adapt the corresponding probabilities in a situation-dependent fashion so as to {{reflect the fact that}} legs frequently occlude each other. Experimental results carried out with a mobile robot illustrate that our approach can robustly and efficiently track multiple people even in situations of high levels of occlusion. I...|$|E
40|$|This {{research}} {{examines the}} probabilistic <b>multi-hypothesis</b> tracker (PHMT), a batch mode, empirical, Bayesian data association and tracking algorithm. Like a traditional <b>multi-hypothesis</b> tracker (MHT), track estimation is deferred until more conclusive data is gathered. However, unlike a traditional algorithm, PMHT does {{not attempt to}} enumerate all possible combinations of feasible data association links, but uses a probabilistic structure derived using expectation maximization. This study focuses on two issues: {{the behavior of the}} PMHT algorithm in clutter and algorithm initialization in clutter. We also compare performance between this algorithm and other algorithms, including a nearest neighbor tracker, a probabilistic data association filter (PDAF), and a traditional measurement oriented MHT algorithm. Naval Undersea Warfare Cente...|$|E
40|$|Abstract—In {{this paper}} {{we present a}} {{probabilistic}} approach for mobile robot localization using an incomplete topological world model. The method, which we have termed <b>multi-hypothesis</b> localization (MHL), uses <b>multi-hypothesis</b> Kalman filter based pose tracking combined with a probabilistic formulation of hypothesis correctness to generate and track Gaussian pose hypotheses online. Apart from a lower computational complexity, this approach has the advantage over traditional grid based methods that incomplete and topological world model information can be utilized. Furthermore, the method generates movement commands for the platform to enhance the gathering of information for the pose estimation process. Extensive experiments are presented from two different environments, a typical office environment and an old hospital building. Index Terms—Bayesian, feature based, global localization, multiple hypothesis. I...|$|E
40|$|International audienceSince the use {{of systems}} of {{satellite}} positioning such as the global positioning system (GPS), applications have tried to locate vehicles on maps representing the environment with their attributes. For one decade, {{this has led to}} both localization and navigation services for users. Recently, new researches have begun in order to extend the functionalities of the existing systems and thus to develop new applications using these technologies in the design of driver assistance systems. These new systems will indeed allow us to anticipate road departures or prevent overspeed turn approaches. Nevertheless, to deploy such new functionalities, it is imperative to ensure the association of vehicle position with one of the roadmap segments. In this article, we propose a new approach based on the belief theory taking into account the imperfections of available data in order to ensure the positioning and tracking of a vehicle on a roadmap and to manage conflicts and ambiguities using a <b>multi-hypotheses</b> decision...|$|R
40|$|In {{this paper}} we study some modi cations of the Condensation algorithm. The case studied is feature based mobile robot {{localization}} {{in a large}} scale environment. The required sample set size for making the Condensation algorithm converge properly can in many cases require too much computation. This is often the case when observing features in symmetric environments like for instance doors in long corridors. In such areas a large sample set is required to resolve the generated <b>multi-hypotheses</b> problem. To manage with a sample set size which in the normal case would cause the Condensation algorithm to break down, we study two modi cations. The rst strategy, called with random sampling", takes part of the sample set and spreads it randomly over the environment the robot operates in. The second strategy, called with planned sampling", places part of the sample set at planned positions based on the detected features. From the experiments we conclude that the second strategy is the best and can reduce the sample set size by at least a factor of 40...|$|R
40|$|International audienceMap-matching {{can be used}} to {{estimate}} the Horizontal Uncertainty Level (HUL) of GNSS position fixes. Integrity monitoring is indeed an important issue for autonomous vehicles navigation. The method is based on the use of a high definition map that stores accurate information about theroad network. This additional source of information is crucial for autonomous navigation. The matched position is computed using proprioceptive sensors from the car and GNSS fixes that are handled using a precautionary principle with Horizontal Protection Levels (HPL). A Particle Filter is used for its ability to manage multiple hypotheses if needed. Estimating different likely map-matched hypotheses allows to determine the levelof uncertainty of the GNSS which is defined as the maximum distance between a map-matched hypothesis and a given GNSS position. This distance {{can be seen as a}} Map-Aided Horizontal Uncertainty Level (MA-HUL), providing a confidence indicator to the vehicle for integrity monitoring. This paper presents the <b>multi-hypotheses</b> map-matching algorithm and a method to compute the MA-HUL values in real-time. Experimental resultscarried out in open road conditions support the evaluation and show that this metric provides reliable confidence information...|$|R
40|$|<b>Multi-hypothesis</b> {{prediction}} extends {{motion compensation}} with one prediction {{signal to the}} linear superposition of several motion-compensated prediction signals with the result of increased coding efficiency. The multiple hypotheses in this paper are blocks in past decoded frames. These blocks are referenced by individual motion vectors and picture reference parameters incorporating long-term memory motion-compensated prediction. In this work, we at most employ two hypotheses similar to B-frames. However, they are obtained from the past. Due to the increased rate for the motion vectors, rate-constrained coder control is utilized. For this scheme, we demonstrate the coding efficiency of <b>multi-hypothesis</b> prediction in combination with variable block size and long-term memory and present bit-rate savings up to 32 % when compared to standard variable block size prediction without long-term memory motion compensatio...|$|E
40|$|Abstract—Transform Domain Wyner-Ziv (TDWZ) video coding is an {{efficient}} Distributed Video coding solution providing new {{features such as}} low complexity encoding, by mainly exploiting the source statistics at the decoder based {{on the availability of}} decoder side information. The accuracy of the decoder side information has a major impact on the performance of TDWZ. In this paper, a novel <b>multi-hypothesis</b> based TDWZ video coding is presented to exploit the redundancy between multiple side information and the source information. The decoder used optical flow for side information calculation. Compared with the best available single estimation mode TDWZ, the proposed <b>multi-hypothesis</b> based TDWZ achieves robustly better Rate-Distortion (RD) performance and the overall improvement is up to 0. 6 dB at high bitrate and up to 2 dB compared with the DISCOVER TDWZ video codec. I...|$|E
40|$|Damage {{diagnosis}} {{based on}} a bank of Kalman filters, each one conditioned on a specific hypothesized system condition, is a well recognized and powerful diagnostic tool. This <b>multi-hypothesis</b> approach {{can be applied to}} a wide range of damage conditions. In this paper, we will focus on the diagnosis of cracks in rotating machinery. The question we address is: how to optimize the <b>multi-hypothesis</b> algorithm with respect to the uncertainty of the spatial form and location of cracks and their resulting dynamic effects. First, we formulate a measure of the reliability of the diagnostic algorithm, and then we discuss modifications of the diagnostic algorithm for the maximization of the reliability. The reliability of a diagnostic algorithm is measured by the amount of uncertainty consistent with no-failure of the diagnosis. Uncertainty is quantitatively represented with convex models...|$|E
40|$|Deep LSTM is {{an ideal}} {{candidate}} for text recognition. However text recognition involves some initial image processing steps like segmentation of lines and words which can induce error to the recognition system. Without segmentation, learning very long range context is difficult and becomes computationally intractable. Therefore, alternative soft decisions are needed at the pre-processing level. This paper proposes a hybrid text recognizer using a deep recurrent neural network with multiple layers of abstraction and long range context along with a language model to verify {{the performance of the}} deep neural network. In this paper we construct a <b>multi-hypotheses</b> tree architecture with candidate segments of line sequences from different segmentation algorithms at its different branches. The deep neural network is trained on perfectly segmented data and tests each of the candidate segments, generating unicode sequences. In the verification step, these unicode sequences are validated using a sub-string match with the language model and best first search is used to find the best possible combination of alternative hypothesis from the tree structure. Thus the verification framework using language models eliminates wrong segmentation outputs and filters recognition errors...|$|R
40|$|This paper {{presents}} recent {{progress in}} developing speech-to-text (STT) and keyword spotting (KWS) {{systems for the}} 2014 IARPA-Babel evaluation. Systems {{have been developed for}} the limited language pack condition for four of the five de-velopment languages in this program phase: Assamese, Ben-gali, Haitian Creole and Zulu. The systems have several novel characteristics that support rapid development of KWS systems. On the STT side different acoustic units are explored based on phonemic or graphemic representations, and system combina-tion is used to improve STT performance. The acoustic models are trained on only 10 hours of speech data with manual tran-scriptions, completed with unsupervised training on additional untranscribed data. Both word and subword units (morphologi-cally decomposed, syllables, phonemes) are used for KWS. The KWS systems are based on the <b>multi-hypotheses</b> produced by a consensus network decoding or searching word lattices. The word error rates of the individual STT systems are on the or-der of 50 - 60 %, and the KWS systems obtain Maximum Term Weighted Values ranging from 30 - 45 % for all keywords (in-vocabulary and out-of-vocabulary (OOV)). Sub-word units are shown to be successful at locating some of the OOV keywords, and system combination improves system performance. Index Terms: STT, KWS, semi-supervised training, lattice, consensus network, sub-word lexical units, Morfessor...|$|R
40|$|Abstract—In {{the field}} of human-robot {{interaction}} (HRI), detection, tracking and re-identification of humans in a robot’s surroundings are crucial tasks, e. g. for socially compliant robot navigation. Besides the 3 D position detection, the estimation of a person’s upper-body orientation based on monocular camera images is a challenging problem on a mobile platform. To obtain real-time position tracking as well as upper-body orientation esti-mations, the proposed system comprises discriminative detectors whose hypotheses are tracked by a Kalman filter-based <b>multi-hypotheses</b> tracker. For appearance-based person recognition, a generative approach, based on a 3 D shape model, is used to refine these tracked hypotheses. This model evaluates edges and color-based discrimination from the background. Furthermore, for each person the texture {{of his or her}} upper-body is learned and used for person re-identification. When computational resources are limited, the update rate of the model-based optimization reduces itself automatically. Thereby the estimation accuracy decreases, but the system keeps tracking the persons around the robot in real-time. The person’s 3 D pose is tracked up to a distance of 5. 0 meters with an average Euclidean error of 18 cm. The achieved motion independent average upper-body orientation error is 22 ◦. Furthermore, the upper-body texture is learned on-line which allowed a stable person re-identification in our experiments. Index Terms—person tracking, upper-body pose estimation, person re-identification, appearance model I...|$|R
40|$|International audienceIn this paper, {{we propose}} a tightly-coupled map-matching {{algorithm}} without explicit road selection stage. By combining a geometrical and a topological approach, <b>multi-hypothesis</b> road tracking is achieved using a constraint Rao-Blackwellised particle filter that tightly merges raw GNSS measurements [...] Pseudo-ranges and Dopplers [...] with a 3 D navigable road-map...|$|E
40|$|<b>Multi-hypothesis</b> {{tracking}} (MHT) {{techniques can}} become prohibitively computationally expensive {{as the number}} of hypotheses increases. In order to maintain an estimate with bounded computational cost, <b>multi-hypothesis</b> methods often merge the estimates together. When the hypotheses are distributed according to a known probability then standard mixture reduction (SMR) methods exist for merging estimates. Also, covariance union (CU) has become a popular approach to merging hypotheses when their distribution is not known. This paper generalises CU to a new theory, which we refer to as generalised covariance union (GCU). GCU merges estimates when their distribution is not known precisely but is, instead, bounded above and below. We show that CU and the SMR approaches are limiting cases of GCU. We demonstrate the efficacy of the new approach via a Global Positioning System (GPS) tracking application with time delayed satellite signals. © 2006 IEEE...|$|E
40|$|Abstract- This paper {{introduces}} a <b>multi-hypothesis</b> multistatic sonar tracker for undersea surveillance. Multistatic sonar increases the data rate {{and has the}} potential to improve surveillance capabilities, provided effective target tracking is performed. Our multihypothesis tracker includes features not generally found in other <b>multi-hypothesis</b> trackers. Data association is based on an efficient linear programming approach, to which we introduce a novel modification that improves track continuation. We use equality constraints in the LP, and tracks are removed when they fail a confirmation criterion. Short duration tracks are classified as false and removed. System and measurement uncertainties are reflected through multistatic contact covariances. This uncertainty impacts the data association hypotheses that are considered, as well as their log-likelihood scores. We test the improved performance of this tracker over our earlier baseline tracker, with a number of benchmark examples of interest and through Monte Carlo evaluation. Keywords: Multi-sensor multi-target tracking, active sonar, multistatic sonar, undersea surveillance. ...|$|E
40|$|This thesis {{focuses on}} the problem of {{enabling}} mobile robots to autonomously build world models of their environments and to employ them as a reference to self–localization and navigation. For mobile robots to become truly autonomous and useful, they must be able of reliably moving towards the locations required by their tasks. This simple requirement gives raise to countless problems that have populated research in the mobile robotics community for the last two decades. Among these issues, two of the most relevant are: (i) secure autonomous navigation, that is, moving to a target avoiding collisions and (ii) the employment of an adequate world model for robot self-referencing within the environment and also for locating places of interest. The present thesis introduces several contributions to both research fields. Among the contributions of this thesis we find a novel approach to extend SLAM to large-scale scenarios by means of a seamless integration of geometric and topological map building in a probabilistic framework that estimates the hybrid metric-topological (HMT) state space of the robot path. The proposed framework unifies the research areas of topological mapping, reasoning on topological maps and metric SLAM, providing also a natural integration of SLAM and the “robot awakening” problem. Other contributions of this thesis cover a wide variety of topics, such as optimal estimation in particle filters, a new probabilistic observation model for laser scanners based on consensus theory, a novel measure of the uncertainty in grid mapping, an efficient method for range-only SLAM, a grounded method for partitioning large maps into submaps, a <b>multi-hypotheses</b> approach to grid map matching, and a mathematical framework for extending simple obstacle avoidance methods to realistic robots...|$|R
40|$|This thesis {{deals with}} the {{development}} of a fault detection algorithm that could be used online. It consists of a combination of several Kalman filters and a sequential <b>multi-hypotheses</b> test. The differential equations used in the Kalman filters describe the system with several fault conditions. The test used in this application is an extension of the Sequential Probability Ratio Test (SPRT) that decides between several hypotheses. It uses the innovations of the Kalman filters to find out, which filter fits best to the measured situation. The fault detection algorithm mentioned before is used to detect faults in the sensor system of the research aircraft of the Institut fuer Flugfuehrung of the Technische Universitaet Braunschweig. Several sensors give informations about the vertical motion of this aircraft: an inertial navigation system, the satellite navigation system GPS, the measurement of the barometric and the radio altitude. These sensor signals are coupled by a system of differential equations and therefore are analytically redundant. Several systematic faults have {{to be included in the}} differential equations used in the Kalman filters: rounding errors are estimated, time delays are approximated through Pade-approximants and the GPS position information is included by output equations with variant structure in the continuous-discrete Kalman filters. The performance of the fault detection algorithm is studied with simulated data that include bias faults, increased noise, drift and change in the dynamics of the plant. Two techniques are used to cope for a fault: extension of the state vector (Extended Kalman filter) or inclusion of a hypothetic fault in the output equations. The performance of the test is improved by an adaption algorithm. All Kalman filters are initialized with the most probable states after a decision is made. The improvement is shown using Monte-Carlo simulations. (orig.) SIGLEAvailable from TIB Hannover: RO 8542 (96 - 06) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
40|$|Handwritten {{signatures}} are behavioural biometric {{traits that}} are known to incorporate {{a considerable amount of}} intra-class variability. The Hidden Markov Model (HMM) has been successfully employed in many off-line signature verification (SV) systems due to the sequential nature and variable size of the signature data. In particular, the left-to-right topology of HMMs is well adapted to the dynamic characteristics of occidental handwriting, in which the hand movements are always from left to right. As with most generative classifiers, HMMs require a considerable amount of training data to achieve a high level of generalization performance. Unfortunately, the number of signature samples available to train an off-line SV system is very limited in practice. Moreover, only random forgeries are employed to train the system, which must in turn to discriminate between genuine samples and random, simple and skilled forgeries during operations. These last two forgery types are not available during the training phase. The approaches proposed in this Thesis employ the concept of multi-classifier systems (MCS) based on HMMs to learn signatures at several levels of perception. By extracting a high number of features, a pool of diversified classifiers can be generated using random subspaces, which overcomes the problem of having a limited amount of training data. Based on the <b>multi-hypotheses</b> principle, a new approach for combining classifiers in the ROC space is proposed. A technique to repair concavities in ROC curves allows for overcoming the problem of having a limited amount of genuine samples, and, especially, for evaluating performance of biometric systems more accurately. A second important contribution is the proposal of a hybrid generative-discriminative classification architecture. The use of HMMs as feature extractors in the generative stage followed by Support Vector Machines (SVMs) as classifiers in the discriminative stage allows for a better design not only of the genuine class, but also of the impostor class. Moreover, this approach provides a more robust learning than a traditional HMM-based approach when a limited amount of training data is available. The last contribution of this Thesis is the proposal of two new strategies for the dynamic selection (DS) of ensemble of classifiers. Experiments performed with the PUCPR and GPDS signature databases indicate that the proposed DS strategies achieve a higher level of performance in off-line SV than other reference DS and static selection (SS) strategies from literature...|$|R
