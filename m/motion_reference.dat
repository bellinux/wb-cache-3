75|412|Public
5|$|More {{money and}} {{resources}} were dedicated to Mermaid {{than any other}} Disney animated film in decades. Aside from its main animation facility in Glendale, California, Disney opened a satellite feature animation facility during the production of Mermaid in Lake Buena Vista, Florida (near Orlando, Florida), within Disney-MGM Studios Theme Park at Walt Disney World. Opening in 1989, the Disney-MGM facility's first projects were to produce an entire Roger Rabbit cartoon short, Roller Coaster Rabbit, and to contribute ink and paint support to Mermaid. Another first for recent years was the filming of live actors and actresses for <b>motion</b> <b>reference</b> material for the animators, a practice used frequently {{for many of the}} Disney animated features produced under Walt Disney's supervision. Sherri Lynn Stoner, a former member of Los Angeles' Groundlings improvisation comedy group, and Joshua Finkel, a Broadway actor, performed key scenes as Ariel and Eric respectively. Jodi Benson had already been cast as Ariel's voice actor by this time, and her recorded dialogue was used as playback to guide these live-action references.|$|E
25|$|<b>Motion</b> <b>reference</b> units, {{vertical}} reference units or {{vertical reference}} sensors, VRUs or MRUs or VRSs, determine the ship's roll, pitch and heave.|$|E
25|$|Ultra- or super- short base line, USBL or SSBL. This {{works as}} {{described}} above. Because the {{angle to the}} transponder is measured, a correction {{needs to be made}} for the ship's roll and pitch. These are determined by <b>Motion</b> <b>Reference</b> Units. Because of the nature of angle measurement, the accuracy deteriorates with increasing water depth.|$|E
40|$|This paper {{deals with}} the {{trajectory}} tracking control for quadrotor aerial vehicles equipped with a robotic manipulator. The proposed approach {{is based on a}} two-layer controller: in the top layer, an inverse kinematics algorithm computes the <b>motion</b> <b>references</b> for the actuated variables while in the bottom layer, an adaptive motion control algorithm is in charge of tracking the <b>motion</b> <b>references.</b> A stability analysis of the closed-loop system is developed. Finally, a simulation case study is presented to prove the effectiveness of the approach...|$|R
40|$|In {{this paper}} a novel {{hierarchical}} motion control scheme for quadrotor aerial {{vehicles equipped with}} a manipulator is proposed. The controller is organized into two layers: in the top layer, an inverse kinematics algorithm computes the <b>motion</b> <b>references</b> for the actuated variables; in the bottom layer, a motion control algorithm {{is in charge of}} tracking the <b>motion</b> <b>references</b> computed by the top layer. A simulation case study is developed to demonstrate the effectiveness of the approach in the presence of disturbances and unmodeled dynamics...|$|R
40|$|In {{this paper}} a three layer control {{architecture}} for multiple aerial robotic manipulators is presented. The top layer, {{on the basis}} of the desired mission, determines the end-effector desired trajectory for each manipulator, while the middle layer is in charge of computing the <b>motion</b> <b>references</b> in order to track such end-effectors trajectories coming from the upper layer. Finally the bottom layer is a low level motion controller, which tracks the <b>motion</b> <b>references.</b> The overall mission is decomposed in a set of elementary behaviors which are combined together, through the Null Space-based Behavioral (NSB) approach, into more complex compounds behaviors. The proposed framework has been tested conducting an experimental campaign...|$|R
500|$|Leslie Uggams {{said that}} she was in the film in July 2015, portraying Blind Al. Tim Miller stated that Jed Rees portrays [...] "The Recruiter", and [...] "did a good job of being creepy and syrupy sweet." [...] Miller {{explained}} that Colossus would be a solely CGI creation in the film because, as a fan of the character, he had never felt that Cudmore's version was accurate to the comics and wanted to show the character as [...] "this monstrous guy". Andre Tricoteux had been cast in the role, providing <b>motion</b> <b>reference</b> on set and the voice. In December, the voice of Colossus was revealed to have been recast, with Stefan Kapičić taking over the role. He completed his work eight weeks before the film was scheduled for release.|$|E
500|$|On July 7, 2014, Gunn {{announced}} {{on social media}} that he had completed work on the film. In August, regarding the post-credit scene, Gunn revealed that the scene did not involve Howard the Duck when it was originally filmed, rather he was added during post-production, a decision made by [...] "some combination of [...] and the editor Fred Raskin". As the decision to add the character was made late in the post-production process, {{he had to be}} designed that day, before being handed off to Sony Pictures Imageworks to animate. Also in August, regarding the pre-credit scene of Groot dancing, Gunn stated that he himself danced to provide <b>motion</b> <b>reference</b> for the animators, and that {{the decision was made to}} place the scene before the credits, rather than during or after them, because of positive responses from a test audience, which made Marvel and Gunn feel that they did not want [...] "people walking out and missing this thing". Marvel used design firm Sarofsky once again for the film's title sequences, after liking their work for [...] Sarofsky developed a custom typeface based on the font used in the teaser posters for the opening credits, which was tinted orange to offer a better contrast to the film's blue and grey imagery. One of the typography solutions offered before the final product wound up being repurposed as the locator cards seen throughout the film.|$|E
50|$|<b>Motion</b> <b>reference</b> units, {{vertical}} reference units or {{vertical reference}} sensors, VRUs or MRUs or VRSs, determine the ship's roll, pitch and heave.|$|E
40|$|In {{this paper}} a two-layer {{decentralized}} framework for kinematic control of cooperative and collaborative multi-robot systems is developed. The {{motion of the}} system is specified at the workpiece level, by adopting a task-oriented formulation for cooperative tasks. The first layer computes the motion of the single arms in the system. In detail, the control unit of each robot computes the end-effector <b>motion</b> <b>references</b> in a decentralized fashion {{on the basis of the}} knowledge of the assigned cooperative task and the <b>motion</b> <b>references</b> computed by its neighbors. Then, in the second layer, each control unit computes the <b>reference</b> joint <b>motion</b> of the corresponding manipulator from the end-effector <b>reference</b> <b>motion.</b> The approach is, then, tested in simulation on a work-cell composed by several manipulators, and experimentally on a dual-arm kinematically redundant work-cell composed by industrial manipulators...|$|R
50|$|Cooks {{followed}} {{big plays}} in the 2016 season with a bow-and-arrow motion. Cooks said the <b>motion</b> <b>referenced</b> a Bible verse in which a boy named Ishmael used his archery skill {{to survive in the}} desert after he nearly died there without water.|$|R
50|$|Hobie Billingsley {{is one of}} {{only six}} diving coaches {{mentioned}} in the American Red Cross's Swimming and Water Safety Manual, 2004; in the chapter {{on the history of the}} sport, Hobie {{is one of only}} two diving coaches with multiple mentions: he and Dick Kimball (University of Michigan) are credited with 'opening the door for women in varsity diving programs,' and he is cited as contributing to the sport of diving through analysis based on principles of physical laws of <b>motion</b> <b>references,</b> pg 20.|$|R
5000|$|... iXBlue Hydrins, and Phins-III are {{the main}} <b>Motion</b> <b>Reference</b> Units (Gyro's) used by the ship's {{standard}} Oceanographic sensors, with feeds available throughout the ship in UDP or Serial formats.|$|E
5000|$|<b>Motion</b> <b>reference</b> {{units are}} {{a kind of}} {{inertial}} measurement unit with single- or multi-axis motion sensors. They utilize MEMS gyroscopes. Some multi-axis MRUs are capable of measuring roll, pitch, yaw and heave. They have applications outside the aeronautical field, such as: ...|$|E
50|$|Ultra- or super- short base line, USBL or SSBL. This {{works as}} {{described}} above. Because the {{angle to the}} transponder is measured, a correction {{needs to be made}} for the ship's roll and pitch. These are determined by <b>Motion</b> <b>Reference</b> Units. Because of the nature of angle measurement, the accuracy deteriorates with increasing water depth.|$|E
40|$|Abstract. This paper proposes {{the use of}} unequally {{protected}} key {{pictures to}} prevent temporal error propagation in error-prone video communications. The key picture may either be an intra-coded picture or a picture using a long-term <b>motion</b> compensation <b>reference</b> picture through reference picture selection. The inter-coded key picture uses previous key pictures as <b>motion</b> compensation <b>reference.</b> Key pictures are better protected than other pictures using forward error correction in either source or transport coding. Simulation results show significantly improved error resiliency performance of the proposed technique compared to conventional methods. ...|$|R
40|$|This paper {{presents}} a control framework for arm/hand systems aimed at controlling internal forces exchanged between the fingers and the grasped object, and enforcing a compliant behavior in presence of environmental interactions. A dynamic planner computes the <b>motion</b> <b>references</b> for the fingers {{by using the}} feedback of the contact forces, while an impedance control, in which dynamic effects exerted by the hand on the wrist are explicitly taken into account, is designed for the arm. The approach is experimentally validated on a 7 -DOFs Barrett WAM with a Barrett Hand 280...|$|R
40|$|This paper proposes {{the use of}} unequally {{protected}} key {{pictures to}} prevent temporal error propagation in error-prone video communications. The key picture may either be an intra-coded picture or a picture using a long-term <b>motion</b> compensation <b>reference</b> picture through reference picture selection. The inter-coded key picture uses previous key pictures as <b>motion</b> compensation <b>reference.</b> Key pictures are better protected than other pictures using forward error correction in either source or transport coding. Simulation results show significantly improved error resiliency performance of the proposed technique compared to conventional methods...|$|R
50|$|The {{purpose of}} AHC {{is to keep}} a load, held by {{equipment}} on a moving vessel, motionless {{with regard to the}} seabed or another vessel. Commercial offshore cranes usually use a <b>Motion</b> <b>reference</b> unit (MRU) or pre-set measurement position detection to detect the current ship displacements and rotations in all directions. A control system, often PLC or computer based, then calculates how the active parts of the system are to react to the movement. The performance of an AHC system is normally limited by power, motor speed and torque, by measurement accuracy and delay, or by computing algortithms. Choice of control method, like using preset values or delayed signals, may affect performance and give large residual motions, especially with unusual waves.|$|E
5000|$|Leslie Uggams {{said that}} she was in the film in July 2015, portraying Blind Al. Tim Miller stated that Jed Rees portrays [...] "The Recruiter", and [...] "did a good job of being creepy and syrupy sweet." [...] Miller {{explained}} that Colossus would be a solely CGI creation in the film because, as a fan of the character, he had never felt that Cudmore's version was accurate to the comics and wanted to show the character as [...] "this monstrous guy". Andre Tricoteux had been cast in the role, providing <b>motion</b> <b>reference</b> on set and the voice. In December, the voice of Colossus was revealed to have been recast, with Stefan Kapičić taking over the role. He completed his work eight weeks before the film was scheduled for release.|$|E
50|$|More {{money and}} {{resources}} were dedicated to Mermaid {{than any other}} Disney animated film in decades. Aside from its main animation facility in Glendale, California, Disney opened a satellite feature animation facility during the production of Mermaid in Lake Buena Vista, Florida (near Orlando, Florida), within Disney-MGM Studios Theme Park at Walt Disney World. Opening in 1989, the Disney-MGM facility's first projects were to produce an entire Roger Rabbit cartoon short, Roller Coaster Rabbit, and to contribute ink and paint support to Mermaid. Another first for recent years was the filming of live actors and actresses for <b>motion</b> <b>reference</b> material for the animators, a practice used frequently {{for many of the}} Disney animated features produced under Walt Disney's supervision. Sherri Lynn Stoner, a former member of Los Angeles' Groundlings improvisation comedy group, and Joshua Finkel, a Broadway actor, performed key scenes as Ariel and Eric respectively. Jodi Benson had already been cast as Ariel's voice actor by this time, and her recorded dialogue was used as playback to guide these live-action references.|$|E
40|$|The modulus of {{continuity}} of a stochastic {{process is a}} random element for any fixed mesh size. We provide upper bounds for the moments of the modulus {{of continuity}} of Ito processes with possibly unbounded coefficients, starting from the special case of Brownian <b>motion.</b> <b>References</b> to known results for the case of Brownian motion and Ito processes with uniformly bounded coefficients are included. As an application, we obtain the rate of strong convergence of Euler-Maruyama schemes for the approximation of stochastic delay differential equations satisfying a Lipschitz condition in supremum norm...|$|R
30|$|A <b>reference</b> <b>motion</b> {{phase was}} {{selected}} {{for each type of}} motion, i.e., CM or CRM (end-diastole for CM; end-diastole/end-exhalation for CRM). The motion fields transforming the MR image volume from a given motion phase to the <b>reference</b> <b>motion</b> phase were obtained by applying a non-rigid image registration technique, which is based on the Demons algorithm [25 – 27].|$|R
40|$|Abstract — In {{this paper}} we discuss the {{integration}} of active and passive approaches to robotic safety in an overall scheme for real-time manipulator control. The active control approach {{is based on the}} use of a supervisory visual system, which detects the presence and position of humans {{in the vicinity of the}} robot arm, and generates <b>motion</b> <b>references.</b> The passive control approach uses variable joint impedance which combines with velocity control to guarantee safety in worst-case conditions, i. e. unforeseen impacts. The implementation of these techniques in a 3 -dof, variable impedance arm is described, and the effectiveness of their functional integration is demonstrated through experiments. I...|$|R
5000|$|On July 7, 2014, Gunn {{announced}} {{on social media}} that he had completed work on the film. In August, regarding the post-credit scene, Gunn revealed that the scene did not involve Howard the Duck when it was originally filmed, rather he was added during post-production, a decision made by [...] "some combination of Gunn and the editor Fred Raskin". As the decision to add the character was made late in the post-production process, {{he had to be}} designed that day, before being handed off to Sony Pictures Imageworks to animate. Also in August, regarding the pre-credit scene of Groot dancing, Gunn stated that he himself danced to provide <b>motion</b> <b>reference</b> for the animators, and that {{the decision was made to}} place the scene before the credits, rather than during or after them, because of positive responses from a test audience, which made Marvel and Gunn feel that they did not want [...] "people walking out and missing this thing". Marvel used design firm Sarofsky once again for the film's title sequences, after liking their work for Captain America: The Winter Soldier. Sarofsky developed a custom typeface based on the font used in the teaser posters for the opening credits, which was tinted orange to offer a better contrast to the film's blue and grey imagery. One of the typography solutions offered before the final product wound up being repurposed as the locator cards seen throughout the film.|$|E
5000|$|After {{the start}} of filming, Sean Gunn {{revealed}} he was involved with the films, serving again as the on-set stand-in actor and <b>motion</b> <b>reference</b> for digital character Rocket. He has also previously appeared in the Guardians films as Kraglin, while Pom Klementieff also revealed she would appear in Infinity War, reprising her role of Mantis. By early February 2017, Johansson was set to appear in Infinity War, Brolin revealed that Benicio del Toro would be filming scenes for Infinity War, reprising his role as Taneleer Tivan / The Collector, and Marvel confirmed that Holland would appear as Spider-Man in both films. Jim Starlin, creator of Thanos, Gamora, and co-creator of Drax, indicated {{he was interested in}} having a cameo appearance in the films. At the end of the month, Dan T. Cathy, co-owner of Pinewood Atlanta, noted the films were [...] "the largest film production ever with a $1 billion budget," [...] which Feige later stated was false. In March 2017, Terry Notary revealed he would appear in Infinity War as Thanos' right-hand man, and Isabella Amara revealed she would be reprising her role as Sally from Spider-Man: Homecoming in Infinity War. Also that month, in terms of the Guardians of the Galaxy's roles in the films, Gunn stated despite them being mainly Avengers films, the Guardians are [...] "a part of Thanos's stories, so, they are in there, and they have, not the biggest, but, an integral part to that." [...] At Wizard World Cleveland 2017, Anthony Mackie confirmed he would reprise his role as Sam Wilson / Falcon in both films.|$|E
40|$|In a {{simulator}} experiment, {{the potential}} benefits of perspective radar displays for situation awareness support were investigated. A target acquisition task was used in which fighter pilots were required to locate and intercept a target. The pilots were supported by a conventional plan-view radar display, or by two types of perspective exocentric radar displays - with outside-in or inside-out <b>motion</b> <b>reference.</b> Task performance was measured in terms of target acquisition time, tracking accuracy, and workload. The results indicated that pilots were able to perform the target acquisition task much faster when a perspective radar display was used, irrespective of the initial target position. With inside-out <b>motion</b> <b>reference,</b> the acquisition time was reduced by nearly 50 % as compared with the plan-view display. Experimental results and implications of the use of perspective radar displays in cockpits are discussed...|$|E
40|$|Reference-Frame-Independent quantum key {{distribution}} (RFI-QKD) {{is known to be}} robust against slowly varying reference frames. However, other QKD protocols such as BB 84 can also provide secrete keys if the speed of the relative <b>motion</b> of the <b>reference</b> frames is slow enough. While there has been a few studies to quantify the speed of the relative <b>motion</b> of the <b>reference</b> frames in RFI- QKD, it is not yet clear if RFI-QKD provides better performance than other QKD protocols under this condition. Here, we analyze and compare the security of RFI-QKD and BB 84 protocol {{in the presence of the}} relative <b>motion</b> of the <b>reference</b> frames. In order to compare their security in real world implementation, we also consider the QKD protocols with decoy state method. Our analysis shows that RFI-QKD provides more robustness than BB 84 protocol against the relative <b>motion</b> of the <b>reference</b> frames. Comment: 6 pages, 3 figures, comments and suggestions are welcom...|$|R
25|$|The Beyblade top Lightning L-Drago 100HF and its {{evolutions}} Meteo L-Drago LW105LF and L-Drago Destructor F:S {{are inspired}} by/based on the Draco constellation. They all feature three dragon heads chasing {{each other in}} a counter-clockwise <b>motion,</b> possibly <b>referencing</b> Ladon's multiple heads.|$|R
30|$|To {{evaluate}} {{the shape of}} the motion data compared to the <b>reference</b> <b>motion,</b> we use the R^ 2 values of the measured, filtered, and synthesized motion data and compared them with the <b>reference</b> <b>motion</b> curve. The R^ 2 values give the relative comparison of the shape of two motion curves on a scale of 0 – 1 after adjusting to the shift in time differences.|$|R
40|$|SuperMedia {{provides}} human operators rich environmental information, {{thus providing}} telepresence and enhances efficiency of operation. However, coupling human {{with the remote}} environment via SuperMedia over the Internet poses challenges {{for the design of}} bilateral teleoperator. These challenges relate to the issues of stability, transparency and synchronization. This paper explores a novel methodology to deal with these difficulties. The method proposed is quite different from traditional methodologies. Instead of using time as <b>motion</b> <b>reference</b> for the control and sensor signals, the method, called event based methodology choose another <b>motion</b> <b>reference</b> which can efficiently carry the sensory information of teleoperator. This method can guarantee the stability of teleoperator without any knowledge of delay since the signals are all referenced with the one which is different from time. Furthermore, stability of the system is independent on the dynamic model of human operator and environment. In this paper, analysis and design of event based methodology for the SuperMedia enhanced Internet-based teleoperation are described. Stability of teleoperator system is proved and stability conditions are also given. The algorithm is verified by a simulation and results demonstrate the effectiveness of this methodology. © 2006 IEEE. Link_to_subscribed_fulltex...|$|E
40|$|A new {{planning}} and control scheme for multi-robot coordination is presented. First, the event-based <b>motion</b> <b>reference</b> is introduced. It drives {{the system to}} achieve the best possible coordination. Based on the combination of general task space with the nonlinear feedback technique, hybrid position/force controllers are designed. To improve the performance of force control, the dynamic of joint motors is considered in the force control. For a given task, a task projection operator may be found for each robot with the consideration of redundancy management. Link_to_subscribed_fulltex...|$|E
40|$|In this paper, the {{feasibility}} of the altitude control of a seaweed harvester is examined. The harvesting system consists of a vessel and a suspended harvester device, the altitude of which is controlled by a winch. The goal of the control action is to maintain the harvester at a constant altitude {{with respect to the}} seabed profile. A control strategy is proposed, including a vessel motion feed-forward action, using a <b>motion</b> <b>reference</b> unit (MRU), and an altitude feedback loop, using a sonar device for altitude measurement...|$|E
5000|$|When tidying up {{the house}} [...] "March of the Swivelheads" [...] (a remix of [...] "Rotating Head") by The Beat plays and a vase is thrown in slow <b>motion,</b> a <b>reference</b> to the chase scene and {{trampoline}} jump in Ferris Bueller's Day Off.|$|R
40|$|Virtual Reality (VR) {{has emerged}} as one of the {{important}} and effective tools for education and training. Most VRbased training systems are situation-based, where the trainees are trained for discrete decision-making in special situations presented by the VR environments. In contrast, this paper discusses the application of VR to a different class of training, for learning exact motions, often required in sports and the arts. For correct evaluation of the trainee and effective <b>motion</b> training, the <b>reference</b> <b>motion</b> data need to be retargeted according to the body size of the trainee, and performance feedback should be provided to enhance the training effect. This paper focuses on the techniques for retargeting a given <b>reference</b> <b>motion</b> for an arbitrary trainee and providing analysis of how well the trainee has followed the <b>reference</b> <b>motion.</b> We assume that the overall posture of a <b>reference</b> <b>motion</b> is deemed to be more important than the absolute positional profile, and this makes our retargeting formulation different from the previous approaches. On-line quantitative analysis based on a moment by moment comparison between the <b>reference</b> and captured <b>motion</b> data is used to supply indication as to how well the trainee is doing during training. In addition, curve fitting and wavelet transformation are employed for off-line qualitative analysis to generate a corrective advice afterwards. An application of the proposed techniques to a simple swordsman training is demonstrated...|$|R
30|$|Estimation of the <b>reference</b> <b>motion</b> {{pattern of}} a gesture and {{definition}} of primitive motion elements to be synthesized in real-time.|$|R
