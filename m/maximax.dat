44|0|Public
5000|$|If [...] {{then the}} game is cooperative, and if [...] then {{the game is}} non-cooperative. Thus, this format {{represents}} four cases: two non-cooperative games (Maximin and Minimax) and two cooperative games (Minimin, and <b>Maximax).</b> The respective formulations are as follows: ...|$|E
40|$|This paper {{presents}} the necessary conditions for solving Chebyshev minimax (or <b>maximax)</b> problems with bounded control. The jump conditions obtained are applicable to problems with single or multiple maxima. By using Contensou domain of maneuverability, it is shown {{that when the}} maxima are isolated single points the control is generally continuous at the jump point in the minimax problems and discontinuous in the <b>maximax</b> problems in which the first time derivative of the <b>maximax</b> function contains the control variable. The theory {{is applied to the}} problem of maximizing the flight radius in a closed circuit glide of a hypervelocity vehicle and to a <b>maximax</b> optimal control problem in which the control appears explicitly with the first time derivative of the <b>maximax</b> function...|$|E
40|$|What are {{the best}} voting systems in terms of utilitarianism? Or in terms of maximin, or <b>maximax?</b> We study these {{questions}} for the case of three alternatives and a class of structurally equivalent voting rules. We show that plurality, arguably {{the most widely used}} voting system, performs very poorly in terms of remarkable ideals of justice, such as utilitarianism or maximin, and yet is optimal in terms of <b>maximax.</b> Utilitarianism is best approached by a voting system converging to the Borda count, while the best way to achieve maximin is by means of a voting system converging to negative voting. We study the robustness of our results across different social cultures, measures of performance, and population sizes. Voting, Scoring Rules, Utilitarianism, Maximin, <b>Maximax,</b> Impartial Culture Condition...|$|E
40|$|Which {{decision}} {{rules are}} the most efficient? Which are the best in terms of maximin or <b>maximax?</b> We study these questions for {{the case of a}} group of individuals faced with a collective choice from a set of alternatives. A key message from our results is that the set of optimal decision rules is well defined, particularly simple, and well known: the class of scoring rules. We provide the optimal scoring rules for the three different ideals of justice under consideration: utilitarianism (efficiency), maximin, and <b>maximax.</b> The optimal utilitarian scoring rule depends crucially on the probability distribution of the utilities. The optimal maximin (respectively <b>maximax)</b> scoring rule takes the optimal utilitarian scoring rule and applies a factor that shifts it towards negative voting (respectively plurality voting) ...|$|E
40|$|Abstract. What are {{the best}} voting systems in terms of utilitarianism? Or in terms of maximin, or <b>maximax?</b> We study these {{questions}} for the case of three alternatives and a class of structurally equivalent voting rules. We show that plurality, arguably {{the most widely used}} voting system, performs very poorly in terms of remarkable ideals of justice, such as utilitarianism or maximin, and yet is optimal in terms of <b>maximax.</b> Utilitarianism is best approached by a voting system converging to the Borda count, while the best way to achieve maximin is by means of a voting system converging to negative voting. We study the robustness of our results across di¤erent social cultures, measures of performance, and population sizes...|$|E
40|$|Contrary to Miller, Farquharson’s agenda trees do omit real {{parliamentary}} information. And {{the assumptions}} {{he uses to}} justify Farquharson’s definition of sincere (or naive) voting justify too little (e. g., he drops <b>maximax)</b> and rule out too much (e. g., non-pre-set agendas and principled sincere voting) ...|$|E
40|$|This paper proposes {{the method}} to obtain {{values of the}} {{coefficients}} of cause-effect relationships between strategic objectives {{in the form of}} intervals and use them in solving the problem of the optimal allocation of organization’s resources. We suggest taking advantage of the interval analytical hierarchy process for obtaining the ntervals. The quantitative model of strategic performance developed by M. Hell, S. Vidučić and Ž. Garača is employed for finding the optimal resource allocation. The uncertainty originated in the optimization problem as a result of interval character of the cause-effect relationship coefficients is eliminated through the application of <b>maximax</b> and maximin criteria. It is shown that the problem of finding the optimal maximin, <b>maximax,</b> and compromise resource allocation can be represented as a mixed 0 - 1 linear programming problem. Finally, numerical example and directions for further research are given...|$|E
40|$|In this paper, {{we present}} a simple axiomatic {{justification}} for indifference before opening, avoiding any expectation reasoning, which is often considered problematic in infinite cases. Although the two-envelope paradox assumes an expectation-maximizing agent, we show that analogous paradoxes arise for agents using difierent decision principles such as maximin and <b>maximax,</b> and that our justification for indifierence before opening applies here too...|$|E
40|$|There {{is a large}} {{theoretical}} {{literature in}} both economics and psychology on decision making under ambiguity (as distinct from risk) and many preference functionals proposed in this literature for describing behaviour in such contexts. However, the empirical literature is scarce and largely confined to testing between various proposed functionals. Using a new design, in which we create genuine ambiguity in the laboratory and can control the amount of ambiguity, we generate data which enables us to estimate several of the proposed preference functionals. In particular, we fit Subjective Expected Utility, Prospect Theory, Choquet Expected Utility, Maximin, <b>Maximax,</b> and Minimum Regret preference functionals, and examine how the fit changes when we vary the ambiguity. We find that the Choquet formulation performs best overall, though {{it is clear that}} different decision makers have different functionals. We also identify new decision rules which are not explicitly modelled in the literature. Ambiguity, Subjective Expected Utility, Prospect Theory, Choquet Expected Utility, Decision Making, Maximin, <b>Maximax,</b> Minimum Regret, Bingo Blower...|$|E
40|$|Abstract: A {{substantial}} body {{of empirical}} {{evidence shows that}} individuals overweight extreme events and act {{in conflict with the}} expected utility theory. These findings were the primary motivation behind the development of a rank-dependent utility theory for choice under uncertainty. The {{purpose of this paper is}} to demonstrate that some simple empirical rules of thumb for choice under uncertainty are consistent with the rank-dependent utility theory. 	 Keywords: rank-dependent utility, maximin, <b>maximax,</b> mid-rang...|$|E
40|$|In this paper, {{we present}} {{results for the}} rainbow {{neighbourhood}} numbers of set-graphs. It is also shown that set-graphs are perfect graphs. The intuitive colouring dilemma in respect of the rainbow neighbourhood convention is clarified as well. Finally, the new notion of the <b>maximax</b> independence, maximum proper colouring of a graph and a new graph parameter called the $i$-max number of $G$ are introduced as a new research direction. Comment: Figure 1, pages...|$|E
40|$|In {{the paper}} we {{consider}} an uncapacitated facility layout problem with stochastic demands. A framework of stochastic programming {{for the problem}} is constructed. We formulate it by the expected value models, the <b>maximax</b> and minimax chance-constrained programming models and the dependent-chance programming models. For solving these models eciently, we integrate stochastic simulations, neural networks and genetic algorithm to design a hybrid intelligent algorithm. Finally a numerical example is presented to illustrate the eectiveness of the proposed algorithm...|$|E
40|$|Pyrotechnic release {{devices such}} as {{explosive}} bolts are prevalent for many applications due to their merits: high reliability, high power-to-weight ratio, reasonable cost, and more. However, pyroshock generated by an explosive event can cause failures in electric components. Although pyroshock propagations are relatively well understood through many numerical and experimental studies, the prediction of pyroshock generation {{is still a very}} difficult problem. This study proposes a numerical method for predicting the pyroshock of a ridge-cut explosive bolt using a commercial hydrocode (ANSYS AUTODYN). A numerical model is established by integrating fluid-structure interaction and complex material models for high explosives and metals, including high explosive detonation, shock wave transmission and propagation, and stress wave propagation. To verify the proposed numerical scheme, pyroshock measurement experiments of the ridge-cut explosive bolts with two types of surrounding structures are performed using laser Doppler vibrometers (LDVs). The numerical analysis results provide accurate prediction in both the time (acceleration) and frequency domains (<b>maximax</b> shock response spectra). In <b>maximax</b> shock response spectra, the peaks due to vibration modes of the structures are observed in both the experimental and numerical results. The numerical analysis also helps to identify the pyroshock generation source and the propagation routes...|$|E
40|$|The {{original}} publication {{is available}} at www. springer. comAbstract: A substantial body of empirical evidence shows that individuals overweight extreme events and act {{in conflict with the}} expected utility theory. These findings were the primary motivation behind the development of a rank-dependent utility theory for choice under uncertainty. The {{purpose of this paper is}} to demonstrate that some simple empirical rules of thumb for choice under uncertainty are consistent with the rank-dependent utility theory. 	 Keywords: rank-dependent utility, maximin, <b>maximax,</b> mid-rang...|$|E
40|$|N ^ o o z(N) Z(N) = 0. cN jv'l m zW N l i m ± 111 / = j j m ^m = o. ~ CN NOTE. Given a {{partition}} of N {{in terms of}} 1 and 2, if we rearrange the summands so as to get {{the maximum number of}} max we getaZ ^ composition. If we rearrange to get the maximum number of min we get aZ ^ composition. Roughly a Zeckendorf composition is either a <b>maximax</b> or a maximin composition...|$|E
40|$|A {{number of}} methods of obtaining the {{distribution}} of the optimum of the 'wait and see' stochastic programming model have been proposed, but computational experience for these is currently limited to the solution of small problems. The {{purpose of this paper is}} to discuss the role of the 'wait and see' model in planning, and to propose a method of analysis based on the minimax and <b>maximax</b> decision criteria. The approach requires the solution of a special class of non-linear programming problems. Computational results to date suggest that it will be possible to analyse practically sized problems in this way. ...|$|E
40|$|Unbalanced bidding {{problem with}} mixed {{uncertainty}} of fuzziness and randomness is considered in this paper, where the bidding engineering quantities of each activity {{are assumed to}} be fuzzy random variables. Two types of fuzzy random models as expected value maximization model and <b>maximax</b> chance-constrained model are built to satisfy different optimization requirements. Then a hybrid intelligent algorithm integrating fuzzy random simulations, neural network and genetic algorithm is designed to solve these models. Finally, a numerical experiment is given to illustrate its effectiveness of the algorithm. The results show that the algorithm is feasible and effective. </p...|$|E
40|$|Abstract. We {{consider}} a cooperative model of bargaining where {{the location of}} the disagreement point may be uncertain. Based on the maximin criterion, we formulate an ex ante eciency condition and characterize the class of bargaining solutions satisfying this axiom. These solutions are generalizations of the monotone path solutions. Adding individual rationality yields a subclass of these solutions. By employing maximin eciency and an invariance property that implies individual rationality, a new axiomatization of the monotone path solutions is obtained. Furthermore, we show that an eciency axiom employing the <b>maximax</b> criterion leads to an impossibility result. Journal of Economi...|$|E
40|$|In {{decision}} making under uncertainty individual decision makers (winegrowers) must {{choose one of}} a set number of decision alternatives with ample information about their outcomes but, most of the times, have not enough knowledge or data about the probabilities of the several states of nature. This paper focuses on the classical <b>Maximax,</b> Maximin, Minimax Regret and Realism criteria. The different approaches are analyzed and compared in {{a case study of}} Port wine production and selling. The computational involvedness and efficacy of the criterion are also presented. The paper finishes with the results of all observed criteria and alternatives in the circumstances of uncertainty...|$|E
40|$|The {{response}} of a panel or {{window to the}} sonic boom and to other transient loads can often be found by deriving an equivalent lumped parameter model for the structure. The <b>maximax</b> {{response of}} such a mechano-acoustical system depends strongly upon the damping mechanisms of the components. This paper is concerned with finding realistic values for the lower bounds of the damping mechanisms in various mechano-acoustical systems. The results indicate that although part of the damping consists of radiation losses at openings, and radiation and viscous losses at narrow interconnecting hallways, the structural damping of the panel is of primary concern...|$|E
40|$|Abstract. An agent {{may have}} to choose between actions based on incom-plete {{knowledge}} of its environment. The incomplete knowledge is modelled as the local state of the agent, which represents the set of states of the envi-ronment that the agent deems possible. A policy determines a ranking (as a total preorder) of the set of actions {{as a function of the}} local state. A policy is maximin representable when it is based on a utility function via the max-imin principle. The theory of Brafman and Tennenholz on necessary and sufficient conditions for policies to be maximin representable is sharpened, extended, and related to <b>maximax</b> and Laplace representability. ...|$|E
40|$|In {{decision}} under uncertainty {{individual decision}} makers (farmers) {{have to choose}} one of a set number of alternatives with complete information about their outcomes but {{in the absence of}} any information or data about the probabilities of the various state of nature. This paper examines a decision making under uncertainty in agriculture. The classical approaches of Wald’s, Hurwicz’s, <b>Maximax,</b> Savage’s and Laplace’s are discussed and compared in case study of oil pumpkin production and selling of pumpkin oil. The computational complexity and usefulness of the criterion are further presented. The article is concluded with aggregate the results of all observed criteria and business alternatives in the conditions of uncertainty, where the business alternative 1 is suggested...|$|E
40|$|This paper {{investigates the}} {{existence}} of an editing phase and studies the com- pliance of subjects' behaviour with the most popular multiattribute decision rules. We observed that our data comply well with {{the existence of}} an editing phase, at least if we allow for a natural error rate of some 25 %. We also found a satis- factory performance of certain groups of subjects for the conjunctive rule, for the elimination{by{aspects rule, for the majority rule, and for the maximin rule. Our data suggest, however, rejection of the prominence hypothesis and of the <b>maximax</b> rule. Thus, our experiment sheds light on {{the existence of an}} editing phase and on the use of various multiattribute decision rules. ...|$|E
40|$|We {{present a}} logic for {{representing}} and reasoning with qualitative statements of preference and normality and describe how these may interact {{in decision making}} under uncertainty. Our aim {{is to develop a}} logical calculus that employs the basic elements of classical decision theory, namely probabilities, utilities and actions, but exploits qualitative information about these elements directly for the derivation of goals. Preferences and judgements of normality are captured in a modal/conditional logic, and a simple model of action is incorporated. Without quantitative information, decision criteria other than maximum expected utility are pursued. We describe how techniques for conditional default reasoning can be used to complete information about both preferences and normality judgements, and we show how maximin and <b>maximax</b> strategies can be expressed in our logic. ...|$|E
40|$|International audienceIn {{a voting}} context, when the {{preferences}} of voters are described by linear orderings over a finite set of alternatives, the Maximin rule orders the alternatives according to their minimal rank in the voters' preferences. It {{is equivalent to the}} Fallback bargaining process described by Brams and Kilgour (Group Decision and Negotiation 10 : 287 - 316, 2001). This article proposes a characterization of the Maximin rule as a social welfare function (SWF) based upon five conditions: Neutrality, Duplication, Unanimity, Top Invariance, and Weak Separability. In a similar way, we obtain a characterization for the <b>Maximax</b> SWF by using Bottom Invariance instead of Top Invariance. Then, these results are compared to the axiomatic characterizations of two famous scoring rules, the Plurality rule and the Antiplurality rule...|$|E
40|$|We {{describe}} {{a novel approach}} to incomplete information board games, {{which is based on}} the concept of metaposition as the merging of a very large set of possible game states into a single entity which contains at least every state in the current information set. This merging operation allows an artificial player to apply traditional perfect information game theory tools such as the Minimax theorem. We apply this technique to the game of Kriegspiel, a variant of chess characterized by strongly incomplete information as players cannot see their opponent’s pieces but can only try to guess their positions by listening to the messages of a referee. We provide a general representation of Kriegspiel states through metaposition trees and {{describe a}} weighed <b>maximax</b> algorithm for evaluating metapositions. We have tested our approach competing against both human and computer players. ...|$|E
40|$|This paper {{provides}} an axiomatic characterization of two rules for comparing alternative sets of objects {{on the basis}} of the diversity that they offer. The framework considered assumes a finite universe of objects and a priori given ordinal quadernary relation that compares alternative pairs of objects {{on the basis of}} their ordinal dissimilarity. Very few properties of this quadernary relation are assumed (beside completeness, transitivity and a very natural form of symmetry). The two rules that we characterize are the maxi max criterion and the lexi-max criterion. The maxi max criterion considers that a set is more diverse than another if and only if the two objects that are the most dissimilar in the former are weakly as dissimilar as the two most dissimilar objects in the later. The lexi-max criterion is defined as usual as the lexicographic extension of the <b>maximax</b> criterion. ...|$|E
40|$|Qualitative {{decision}} tools {{have been}} used in AI and CS in various contexts, but their adequacy is still unclear. To examine this question, our work employs the axiomatic approach to characterize the properties of various decision rules. In the past, we presented a constructive representation theorem for the maximin decision criterion, and we characterized conditions under which an agent can be viewed as adopting a qualitative decision-making approach (consisting of beliefs, goals, and a qualitative decision criterion). In this paper we show that the maximin representation theorem applies to two additional decision criteria: minmax regret and competitive ratio, and with slight modifications, to a third one, <b>maximax.</b> In addition, we characterize conditions under which an agent with a given qualitative utility function can be ascribed beliefs when we assume it adopts maximin as its decision criterion. Introduction Decision theory plays a central role in various disciplines, including e [...] ...|$|E
40|$|Qualitative {{decision}} tools {{have been}} used in AI and CS in various contexts. However, their adequacy is unclear. Following Brafman and Tennenholtz, we use the axiomatic approach to investigate the adequacy and usefulness of various decision rules. We present constructive representation theorems for a number of qualitative decision criteria, including minmax regret, competitive ratio, and <b>maximax,</b> and characterize conditions under which a maximin agent can be ascribed qualitative beliefs. Introduction Decision theory plays a central role in various disciplines, including mathematical economics, game theory, operations research, industrial engineering, and statistics. It is widely recognized by now that decision making is crucial to AI as well, since artificial agents are, in fact, automated decision makers (RN 95). However, many decision making techniques found in the AI literature are quite different from those found in other fields. Work in other disciplines has mostly adopted the v [...] ...|$|E
40|$|The {{most popular}} {{approach}} to decision-making {{in the setting}} of fuzzy sets is the maximin ranking of solutions. This method is natural when interpreting the fuzzy sets as flexible constraints that cannot compensate with one another. However the obtained ranking of solutions is very coarse. Two kinds of refinements to this ordering are introduced: a partial ordering according to the least satisfied discriminating constraint, and a lexicographical ranking. The latter refines the former and combines utilitarist and egalitarist points of view on the aggregation of feasibility degrees. These orderings are characterized in several ways and their representation by means of two place numerical functions is studied. Dual refinements of the <b>maximax</b> ranking are provided. KEY-WORDS: Fuzzy constraints, maximin problems, vector-maximization, partial ordering, leximin ordering. 1. Introduction In their seminal paper, Bellman and Zadeh [2] established a link between fuzzy set theory and multiple cr [...] ...|$|E
30|$|Multiple {{criteria}} {{decision making}} (MCDM) problems are studied mainly under two categories, namely multiple objective decision making (MODM) problems and multiple attribute decision making (MADM) problems. The MODM problems emphasize {{the design of}} best alternative wherein the alternatives are not predetermined. In contrast, the number of alternatives in MADM problems is predetermined and is usually limited. Hence, it can be stated that MODM problems are concerned with design whereas the MADM problems are used for selection (Hwang and Yoon 1981). The MADM methods are classified as non-compensatory and compensatory. Some of the non-compensatory methods include maxmin, <b>maximax,</b> dominance, conjunctive constraint method, and lexicographic method. These methods are simple but their applications are limited. The compensatory models are very popular. These methods can be described under three categories: (1) scoring methods (2) compromising methods and (3) concordance methods (Hwang and Yoon 1981). A taxonomy of methods for classical MADM problems and fuzzy ranking methods {{can be found in}} the study by Chen and Hwang (1992).|$|E
40|$|Decisions can be {{evaluated}} by sets {{of positive and}} negative arguments — the problem is then to compare these sets. Studies in psychology have shown that in this case the scale of evaluation of decisions is generally bipolar. Moreover decisions are often {{made on the basis of}} an ordinal ranking of the arguments rather than on a genuine numerical evaluation of their degrees of attractiveness or rejection, hence the qualitative nature of the decision process in practice. In this paper, assuming bipolarity of evaluations and qualitative ratings, we present and axiomatically characterise two decision rules based on possibilistic order of magnitude reasoning that are capable of handling positive and negative affects. They are extensions of the maximin and <b>maximax</b> criteria to the bipolar case. A bipolar extension of possibility theory is thus obtained. In order to overcome the lack of discrimination power of the decision rules, refinements are also proposed, capturing both the efficiency principle and the idea of order of magnitude reasoning...|$|E
40|$|The {{objective}} of this presentation is to give {{a brief overview of}} the theory behind the (DBA) method, an overview of the derivation and a practical application of the theory using the Python computer language. The Theory and Derivation will use both Acceleration and Pseudo Velocity methods to derive a series of equations for processing by Python. We will take the results and compare both Acceleration and Pseudo Velocity methods and discuss implementation of the Python functions. Also, we will discuss the efficiency of the methods and the amount of computer time required for the solution. In conclusion, (DBA) offers a powerful method to evaluate the amount of energy imparted into a system in the form of both Amplitude and Duration during qualification testing and flight environments. Many forms of steady state and transient vibratory motion can be characterized using this technique. (DBA) provides a more robust alternative to traditional methods such Power Spectral Density (PSD) using a <b>maximax</b> approach...|$|E
40|$|Necessity (resp. possibility) {{measures}} are very simple representations of epistemic uncertainty due to incomplete knowledge. In the present work, a characterization of discrete Choquet integrals {{with respect to}} a possibility or a necessity measure is proposed, understood as a criterion for decision under uncertainty. This kind of criterion has the merit of being very simple to define and compute. To get our characterization, it is shown that it is enough to respectively add an optimism or a pessimism axiom to the axioms of the Choquet integral {{with respect to a}} general capacity. This additional axiom enforces the maxitivity or the minitivity of the capacity and essentially assumes that the decision-maker preferences only reflect the plausibility ordering between states of nature. The obtained pessimistic (resp. optimistic) criterion is an average of the maximin (resp. <b>maximax)</b> criterion of Wald across cuts of a possibility distribution on the state space. The additional axiom can be also used in the axiomatic approach to Sugeno integral and generalized forms thereof. The possibility of axiomatising of these criteria for decision under uncertainty in the setting of preference relations among acts is also discussed...|$|E
40|$|This {{thesis is}} focused on the methods and tools which are helpful in {{decision-making}} under uncertainty and risk. The methods of decision-making for discrete and continuous values of risk factors are used in the thesis. In case of discrete values of risk factors and decision-making under risk, the thesis uses the rule of expected values, the rule of expected value and variance and also calculates the value of perfect information. In case of decision-making under uncertainty, the thesis {{is focused on}} the rule of maximin and <b>maximax,</b> Laplace's rule, Hurwitz's rule and Savage's rule. The following part of the thesis is devoted to decision-making with continuous values of risk factors. It utilizes the Monte Carlo simulation method and the sensitivity analysis with the help of Lumina Analytica software. The last part of the thesis is aimed at utilization of decision trees in case of multistage decision-making. It uses the Treeplan software which works as a plugin in MS office Excel. All the mentioned methods are practically applied to a concrete case of analysing and ex post evaluating the business plans of a company, which is based at Jindřichův Hradec market...|$|E
40|$|As {{recently}} argued by Diamond (1998), {{one of the}} {{key factors}} explaining the progressivity of an optimal non-linear income tax is the distribution of productivity among workers. Migration is one source of changes in the productivity distribution. How changes in the population’s ability distribution affect optimal income tax schedules has received little attention. Changing the distribution generally affects both the objective function and the government budget constraint. We first consider the comparative statics of the fraction of highly-skilled workers with maximin and <b>maximax</b> welfare functions (so that only the second effect is present) and a quasi-linear utility function. We also present some results for a utilitarian social welfare function. We then study the interaction between mobility and redistributive taxation. We consider mobility by either the skilled or unskilled population under majority voting where governments take the population as fixed. If individuals choose to relocate independently, having identical ability distributions is always a stable equilibrium when the unskilled are the mobile group. However, this is not always the case when the skilled are mobile. If groups of individuals can choose where to locate, having identical ability distributions across regions is only an equilibrium when the mobile type has an overall majority. Copyright Springer Science + Business Media, Inc. 2005 optimal income taxation, tax competition, migration,...|$|E
