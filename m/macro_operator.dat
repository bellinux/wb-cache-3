7|21|Public
50|$|One of {{the most}} {{powerful}} features of the xBase languages is the <b>MACRO</b> <b>Operator</b> '&'. xHarbour’s implementation of the <b>Macro</b> <b>Operator</b> allows for runtime compilation of any valid xHarbour expression. Such compiled expression may be used as a VALUE, i.e. the right side of an Assignment, but more interestingly, such compiled expression may be used to resolve the LEFT side of an assignment, i.e. PRIVATE, or PUBLIC variables, or Database FIELD.|$|E
50|$|Additionally the <b>Macro</b> <b>Operator</b> may compile {{and execute}} {{function}} calls, complete assignments, or even list of arguments, {{and the result}} of the macro may be used to resolve any of the above contexts in the compiled application. IOW, any xHarbour application may be extended, and/or modified in runtime, to compile and execute additional code on demand.|$|E
50|$|Additionally, the <b>Macro</b> <b>Operator</b> may compile {{and execute}} {{function}} calls, complete assignments, or even list of arguments, {{and the result}} of the macro may be used to resolve any of the above contexts in the compiled application. In other words, any Harbour application may be extended and modified at runtime to compile and execute additional code on-demand.|$|E
40|$|Despite major {{progress}} in AI planning {{over the last}} few years, many interesting domains remain challenging for current planners. This paper presents component abstraction, an automatic and generic technique that can reduce the complexity of an important class of planning problems. Component abstraction uses static facts in a problem definition to decompose the problem into linked abstract components. A local analysis of each component is performed to speed up planning at the component level. Our implementation uses this analysis to statically build <b>macro</b> <b>operators</b> specific to each component. A dynamic filtering process keeps for future use only the most useful <b>macro</b> <b>operators.</b> We demonstrate our ideas in Depots, Satellite, and Rovers, three standard domains used in the third AI planning competition. Our results show an impressive potential for <b>macro</b> <b>operators</b> to reduce the search complexity and achieve more stable performance...|$|R
40|$|Search {{permeates}} {{all aspects}} of artificial intelligence including problem solving, robot motion planning, concept learning, theorem proving, and natural language understanding [12]. Because search routines are frequently also a computational bottleneck, numerous methods have been explored {{to increase the efficiency}} of search by making use of background knowledge, search <b>macro</b> <b>operators,</b> and parallel hardware for search...|$|R
50|$|User-defined {{operators}} {{are similar to}} <b>macros.</b> <b>Operators</b> differ from functions in that their domain {{need not be a}} set: for example, the set membership operator has the category of sets as its domain, which is not a valid set in ZFC (since its existence leads to Russell's paradox). Recursive and anonymous user-defined operators were added in TLA+2.|$|R
40|$|By {{looking at}} the simple task of tossing a bean bag from hand to hand, we show how the <b>macro</b> <b>operator</b> method breaks down when formulating agent models that {{interact}} with an uncertain external world. A <b>macro</b> <b>operator</b> encapsulates a plan to reach an objective. Occasionally the objective will be found to be unachievable, requiring the <b>macro</b> <b>operator</b> and its plan to be rejected. Letting the <b>macro</b> <b>operator</b> interact with the external world does not, by itself, change this situation, {{but the fact that}} the results of the interaction are uncertain, and the agent's knowledge incomplete, does. The key idea is that the agent can't positively determine if progress towards the objective is being made in the external world, and thus errors will be made in rejecting a <b>macro</b> <b>operator</b> that would succeed. We show that there are a number of methods by which the agent can recover from such an operator rejection and continue toward the operator's objective. If we make operator rejection and recovery into a [...] ...|$|E
40|$|In {{this work}} we employ {{heuristic}} search to obtain macro operators for spaces defined in our production system. A <b>macro</b> <b>operator</b> is {{a sequence of}} original operators which reaches a subgoal from a state without search. A macro table has operators for each subgoal. Korf (Korf 1985) used macro operators to find suboptimal solutions for the Rubik’s Cube and the 15 -Puzzle. While the paths found by the macro method are not guaranteed to be optimal, once the macro table is calculated the search effort is negligible. Traditionally macro operators were found by uninformed search methods, {{because there were no}} obvious heuristics. We have devised a simple notation, PSVN (Hernádvölgyi & Holte 1999), to represent state spaces. In PSVN, states are vectors of labels and the operators are simple rewriting rules. For this notation we invented a technique to automatically generate admissibl...|$|E
40|$|Planning and {{learning}} at multiple levels of temporal abstraction {{is a key}} problem for artificial intelligence. In this paper we summarize an approach to this problem based on the mathematical framework of Markov decision processes and reinforcement learning. Conventional model-based reinforcement learning uses primitive actions that last one time step {{and that can be}} modeled independently of the learning agent. These can be generalized to macro actions, multi-step actions specified by an arbitrary policy and a way of completing. Macro actions generalize the classical notion of a <b>macro</b> <b>operator</b> in that they are closed loop, uncertain, and of variable duration. Macro actions are needed to represent common-sense higher-level actions such as going to lunch, grasping an object, or traveling to a distant city. This paper generalizes prior work on temporally abstract models (Sutton 1995) and extends it from the prediction setting to include actions, control, and planning. We d [...] ...|$|E
50|$|As seen in {{the example}} above, LFE {{expressions}} are written as lists, using prefix notation. The first element in the list {{is the name of}} a form, i.e., a function, <b>operator,</b> <b>macro,</b> or <b>operator.</b> The remainder of the list are the arguments.|$|R
40|$|Linda Briesemeister, Barbara van Schewick and Tobias Scheffer Technische Universitat Berlin 1 Introduction Most AI {{problem-solving}} systems, {{when presented}} with the same problem repeatedly, always solve {{it the same way}} and in about the same amount of time. It seems shortsighted that they do not adjust their behavior {{on the basis of their}} experience. Therefore, learning by observing the process of solving a problem can lead to some form of knowledge, which can be used when new problems arise. In recent years, attempts to improve the efficiency of a problem solver, especially to improve the speed with which it can solve problems (speedup learning), have been made by investigating mainly two techniques: One technique is to learn new <b>macro</b> <b>operators</b> by composing sequences of original <b>operators.</b> The <b>macro</b> <b>operators</b> are added to the set of operators considered by the problem solver, and they allow it to take "big steps" in the search space (e. g. an extension of Strips [FHN 72]). The o [...] ...|$|R
40|$|AbstractStarting {{with the}} notion of a {{deterministic}} automaton, we formalize and explore the concepts of <b>macros,</b> <b>operator</b> overloading and refinement. The category of automata whose arrows are refinements is defined and two closure operators (idempotent monads) on this category are given. The first monad arises as an adjunction with the category of concrete monoids and corresponds to closure by macros, while the other monad comes from an adjunction with the category of graphs and corresponds to closure by overloading. This theory explicates a connection (also called the Catalan construction) between monoids and graphs. Directions for further research are suggested...|$|R
3000|$|Further {{cost saving}} through {{possible}} reuse of spectrum bands licensed to the <b>macro</b> network <b>operator</b> and resource sharing {{over a number}} of LPNs (as opposed to having dedicated backhaul links to each LPN); [...]...|$|R
40|$|A {{relational}} graph structure {{based on}} a boundary representation of solid objects is described. In this structure, called Face Adjacency Graph, nodes represent object faces, whereas edges and vertices are encoded into arcs and hyperarcs. Based on the face adjacency graph, the authors define a set of primitive face-oriented Euler operators, {{and a set of}} <b>macro</b> <b>operators</b> for face manipulation, which allow a compact definition and an efficient updating of solid objects. The authors briefly describe a hierarchical graph structure based on the face adjacency graph, which provides a representation of an object at different levels of detail. Thus it is consistent with the stepwise refinement process through which the object description is produced...|$|R
40|$|This paper {{proposes a}} model of {{learning}} by discovery. The model consists of a program which discovers <b>macro</b> <b>operators</b> while conducting a best first heuristic search {{in the domain of}} puzzles. This work extends some recent work on permutation puzzles (Korf, 1982) and operator-decomposable puzzles (Korf, 1983), and is related to the earlier work on MACROPS (Fikes, Hart, and Nilsson, 1972). This work is part of a doctoral dissertation currently in progress at MIT, in which the model will be used to explore learning in conjunction with additional search paradigms and numerous alternative heuristics for macro generation and selection. The specific heuristic reported on here is that of using peaks of the evaluation function to segment the paths of the search tree in order to discover macros. The technique seems particularly valuable in difficult puzzles where only imperfect or approximate evaluation functions are available...|$|R
50|$|Macros {{are defined}} by the defmacro <b>macro.</b> The special <b>operator</b> macrolet allows the {{definition}} of local (lexically scoped) macros. It is also possible to define macros for symbols using define-symbol-macro and symbol-macrolet.|$|R
40|$|It {{is widely}} {{acknowledged}} {{that some of}} the most powerful algorithms for graph coloring involve the combination of evolutionary-based methods with exploitative local search-based techniques. This chapter conducts a review and discussion of such methods, principally focussing on the role that recombination plays in this process. In particular we observe that, while in some cases recombination seems to be usefully combining substructures inherited from parents, in other cases it is merely acting as a <b>macro</b> perturbation <b>operator,</b> helping to reinvigorate the search from time to time...|$|R
40|$|Deductive {{learners}} {{acquire knowledge}} that is implicitly available to improve {{the performance of the}} problem solver. One of the most known form of deductive learning is the acquisition of <b>macro</b> <b>operators.</b> Macro-operators carry cost as well as bene ts. When the costs outweigh the bene ts, we face the utility problem. The vast numberofmacrosavailable to the learner forces it to be selective toavoid the utility problem. The most common approach to selective macro-learning is using acquisition lters. Such lters try to estimate the utility of a macro before inserting it into the macro knowledge base. One problem with this approach isthatthe utility of a macro strongly depends on the problem being solved. In this work we suggest an alternative approach called utilization ltering. Instead of being selective when the macro is acquired, the learner is selective when the macro is utilized. We propose to use similarity-based ltering. A macro is considered as potentially useful for a particular problem if it proved to be useful for similar problems. Without further knowledge about the states in the search space,we suggest to use the heuristic function to determine similarity between states. Initial testing of this approach in the grid domain showed that indeed it is bene cial to delay selectivity tothe utilization stage. ...|$|R
40|$|An overall {{hierarchical}} automation philosophy {{along with}} the results of the radio frequencies automation effort undertaken 2 years ago are summarized. A brief description of each subassembly controller's salient features, the software development process, and the common software used by these controllers will be presented. Comments will be made with respect to the relative advantages of high-level language and assembly language, the operational effectiveness of <b>operator</b> <b>Macro</b> commands, and the program development, and a list of suggested future effort will be given...|$|R
40|$|We {{introduce}} the EPP extensible preprocessor and explain how it permits to integrate new constructs into the Java language in a modular way. We present experiments of data-parallel frameworks and reactive objects programming realized with this system. 1 Introduction The Java language [GJG 96] has recently become very popular among programmers and researchers: {{it is rather}} simple and makes a good synthesis of many ideas previously proposed in isolation in the programming language field. Java has socket and thread libraries {{which can be used}} on various platforms. Some Java virtual machines already support shared memory type multi-processors; in the near future, many more will, and the language will thus become a more interesting platform for parallel programming. On the other hand, Java lacks facilities for language extension, which are adopted by other object-oriented languages. For example, C++ provides a <b>macro</b> preprocessor, <b>operator</b> overloading and template facilities. Smalltalk and [...] ...|$|R
40|$|COMPOSER {{is one of}} {{a growing}} number of {{techniques}} for learning to plan. Like other approaches, it embodies a number of simplifications to overcome the complexities of learning. These simplifications introduce tradeoffs between learning efficiency and effectiveness. In this paper we relate COMPOSER to our general framework of simplifications for learning to plan [Gratch 92 a]. This discussion illustrates how such a framework may be used to analyzea particular approach, highlighting the learning system's strengths and weaknesses. 1 INTRODUCTION In machine learning there is considerable interest in techniqueswhichimproveplanning ability. Investigation in this area has identified a wide array of techniques including <b>macro</b> [...] <b>operators</b> [DeJong 86, Fikes 72, Mitchell 86, Segre 88], chunks [Laird 86], and control rules [Minton 88, Mitchell 83]. With these techniques comes a growing battery of successful demonstrations in domains ranging from 8 [...] puzzle to space shuttle payload processing. Unfortunatel [...] ...|$|R
40|$|In machine {{learning}} {{there is considerable}} interest in techniques which improve planning ability. Initial investigations have identified {{a wide variety of}} techniques to address this issue. Progress has been hampered by the utility problem, a basic tradeoff between the benefit of learned knowledge and the cost to locate and apply relevant knowledge. In this paper we describe the COMPOSER system which embodies a probabilistic solution to the utility problem. We outline the statistical foundations of our approach and compare it against four other approaches which appear in the literature. 1 Introduction Machine learning is often entertained as a mechanism for improving the efficiency of planning systems. Researchers have proposed a wide array of techniques to modify planning behavior, including <b>macro</b> [...] <b>operators</b> [DeJong 86, Fikes 72, Mitchell 86], chunks [Laird 86], and control rules [Minton 88, Mitchell 83]. With these techniques comes a growing battery of successful demonstrations in domains [...] ...|$|R
40|$|Abstract. Macroshavealong-standingroleinplanningasatoolfor {{representing}} repeating subsequences of <b>operators.</b> <b>Macros</b> {{are useful}} bothforguidingsearchtowardsasolutionandforrepresentingplans compactly. In this paper we introduce automata plans which consist of hierarchies of finite state automata. Automata plans {{can be viewed}} as an extension of macros that enables parametrization and branching. We provide several examples of the utility of automata plans,andprovethatautomataplansarestrictlymoreexpressivethan macro plans. We also prove that automata plans admit polynomialtime sequential access of the operators in the underlying “flat ” plan, and identify a subset of automata plans that admit polynomial-time random access. Finally, we compare automata plans with other representations allowing polynomial-time sequential access. ...|$|R
40|$|A {{combined}} University / Industry {{team has}} developed a prototype system for handling protein crystals aboard the space station. This system uses a miniature direct drive robot, CCD television cameras, and a client-server computing system using internet protocols to support the capture of protein crystals from aqueous growth solutions. The system was demonstrated between Huntsville AL. and Seattle WA. An operator in Huntsville controlled the mini robot by invoking pre-defined relative and absolute <b>macro</b> files. The <b>operators</b> observed results using video images sent through the internet link using Cu-SeeMe video conferencing software. In 3 of 4 trials, the operators successfully captured 0. 5 mm simulated protein crystals into a glass capillary. The system is a promising start {{for the development of}} a space-station based remote protein crysta...|$|R
40|$|Behavioral power {{estimation}} {{is required}} to help the designer in making important architectural choices. In this work we propose an accurate and general behavioral power modeling approach especially suited for synthesis-based design ows making use of a library of hard <b>macros</b> implementing behavioral <b>operators.</b> Power dissipation models are pre-characterized and back-annotated in a preliminary step. Accurate information on the power dissipation of the used macros can then be collected during behavioral simu- lation of the synthesized circuit. Our characterization and modeling methodology {{is based on the}} theory of linear regression. Optimal linear power models are obtained with methods of least squares fitting and their generalization to a recursive procedure called tree regression. The regression models can be used for pattern-based dynamic power simulation and for probabilistic static power estimation as well. Our behavioral simulator is integrated within PPP, a multilevel simulation engine for power estimation fully compatible with Verilog XL...|$|R
40|$|Macros {{have long}} been used in {{planning}} to represent subsequences of <b>operators.</b> <b>Macros</b> {{can be used in}} place of individual operators during search, sometimes reducing the effort required to find a plan to the goal. Another use of macros is to compactly represent long plans. In this paper we introduce a novel solution concept called automaton plans in which plans are represented using hierarchies of automata. Automaton plans can be viewed as an extension of macros that enables parameterization and branching. We provide several examples that illustrate how automaton plans can be useful, both as a compact representation of exponentially long plans and as an alternative to sequential solutions in benchmark domains such as LOGISTICS and GRID. We also compare automaton plans to other compact plan representations from the literature, and find that automaton plans are strictly more expressive than macros, but strictly less expressive than HTNs and certain representations allowing efficient sequential access to the operators of the plan. 1...|$|R
40|$|Abstract—In this paper, {{we propose}} {{applicable}} and comparative cost-capacity {{analysis of the}} heterogeneous wireless networks {{in order to determine}} the most cost effective radio network deployment strategies as a function of an extreme demand levels of even more than 100 GB per user and month. We perform the modeling by considering of the unit cost drivers relevant for the various base station classes which provide different coverage and high capacity performance, coming with the Long Term Evolution Release 10 (LTE-Advanced) radio access technology or IEEE 802. 11 ac Wi-Fi standard. Considering different amounts of available bandwidth in the 800 MHz and 2. 6 GHz bands, the key finding is that the small cell solutions like femto cells and Wi-Fi are more cost efficient when new macro base station sites need to be deployed or when very high demand levels need to be satisfied. In all other evaluated cases, the importance of the spectrum size comes to the highest level together with the introduction of the LTE-Advanced carrier aggregation functionality. Also, we evaluate the economic gains of a joint deployment of femto/Wi-Fi sites from one side and macrocells from other side. We determine that instead of investing in additional spectrum or deploying denser <b>macro</b> network, mobile <b>operators</b> could compensate the indoor wall penetration losses by deploying different number of femto sites per floor or user per femto site, for still satisfactory level of QoS. Keywords-Wireless Heterogeneous Networks; Cost modeling; LTE-Advanced; IEEE 802. 11 ac...|$|R

