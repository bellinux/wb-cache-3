4680|4101|Public
25|$|<b>Model</b> <b>validation</b> (MV) {{takes the}} models and methods {{developed}} by front office, library, and modeling quantitative analysts and determines their validity and correctness. The MV group {{might well be}} seen as a superset of the quantitative operations in a financial institution, since it must deal with new and advanced models and trading techniques from across the firm. Before the crisis however, the pay structure in all firms was such that MV groups struggle to attract and retain adequate staff, often with talented quantitative analysts leaving at the first opportunity. This gravely impacted corporate ability to manage model risk, or to ensure that the positions being held were correctly valued. An MV quantitative analyst would typically earn a fraction of quantitative analysts in other groups with similar length of experience. In the years following the crisis, this has changed. Regulators now typically talk directly to the quants in the middle office such as the model validators, and since profits highly depend of the regulatory infrastructure, <b>model</b> <b>validation</b> has gained in weight and importance with respect to the quants in the front office.|$|E
25|$|In sales & trading, {{quantitative}} analysts work {{to determine}} prices, manage risk, and identify profitable opportunities. Historically {{this was a}} distinct activity from trading but the boundary between a desk quantitative analyst and a quantitative trader is increasingly blurred, {{and it is now}} difficult to enter trading as a profession without at least some quantitative analysis education. In the field of algorithmic trading it has reached the point where there is little meaningful difference. Front office work favours a higher speed to quality ratio, with a greater emphasis on solutions to specific problems than detailed modeling. FOQs typically are significantly better paid than those in back office, risk, and <b>model</b> <b>validation.</b> Although highly skilled analysts, FOQs frequently lack software engineering experience or formal training, and bound by time constraints and business pressures tactical solutions are often adopted.|$|E
2500|$|Since the 1990s {{many more}} {{sophisticated}} {{models have been}} developed. In Europe much of the recent work was carried out {{as part of the}} SATSIE (Avalanche Studies and <b>Model</b> <b>Validation</b> in Europe) research project supported by the European Commission which produced the leading-edge MN2L model, now in use with the Service Réstitution Terrains en Montagne (Mountain Rescue Service) in ...|$|E
5000|$|TAPAAL, an {{integrated}} tool environment for <b>modeling,</b> <b>validation</b> and verification of Timed-Arc Petri Nets ...|$|R
5000|$|UPPAAL, an {{integrated}} tool environment for <b>modeling,</b> <b>validation</b> and verification of real-time systems modeled as networks of timed automata ...|$|R
5000|$|Roméo is an {{integrated}} tool environment for <b>modeling,</b> <b>validation</b> and verification of real-time systems modeled as time Petri Nets [...] or stopwatch Petri Nets, extended with parameters.|$|R
2500|$|A very {{extensive}} <b>model</b> <b>validation</b> report can {{be obtained}} using the [...] "What Check" [...] software which is one option of the [...] "What If" [...] software package; it produces a many page document with extensive analyses of nearly 200 scientific and administrative aspects of the model. [...] "What Check" [...] is available as a {{it can also be}} used to validate experimentally determined structures of macromolecules.|$|E
50|$|S-VIEW - {{post-processing}} {{tool for}} <b>model</b> <b>validation</b> and collaboration.|$|E
5000|$|... #Subtitle level 3: Power <b>model</b> <b>validation</b> through thermal {{measurements}} ...|$|E
50|$|UPPAAL is an {{integrated}} tool environment for <b>modeling,</b> <b>validation</b> and verification of real-time systems modeled as networks of timed automata, extended with data types (bounded integers, arrays etc.).|$|R
40|$|International audienceA compressible, multiphase, one-fluid Euler solver {{has been}} {{developed}} to study one-dimensional expansion problems with cavitation. A new model for the mass transfer is proposed and compared with a popular cavitation <b>model.</b> <b>Validations</b> are done with reference solutions computed with the two-fluid models...|$|R
30|$|The {{cross-validation}} of five folds {{is used to}} {{find the}} best value for kernel scale and to prevent overfitting [35]. The SCADA datasets described in “SCADA data for wind turbine performance curves” were randomly shuffled and split into training and testing datasets for training and SVR <b>model</b> <b>validations</b> purposes, respectively.|$|R
5000|$|Sophisticated {{workflow}} <b>model</b> <b>validation</b> features (e.g. deadlock detection at design-time).|$|E
5000|$|... 2000 OCC <b>Model</b> <b>Validation</b> (Bulletin 2000-16) note {{this was}} {{replaced}} in 2011.|$|E
50|$|Oreskes {{worked on}} {{scientific}} methods, in particular <b>model</b> <b>validation</b> in the Earth sciences.|$|E
40|$|In this paper, {{the compact}} {{modeling}} of power electronic devices is presented. Physical modeling using ANSYS {{is helpful to}} identify the compact model parameters. Thermographic measurements were applied to <b>modeling</b> <b>validation.</b> Compact <b>models</b> are very easy for computation, so they generate the results fast and with satisfactory accuracy. 1...|$|R
40|$|Adding {{functional}} {{information to}} anatomical CT-data {{by means of}} Computational Fluid Dynamics (CFD) is a non-invasive method for analyzing patient-specific respiratory dynamics. As CFD is based on numerical <b>models,</b> <b>validation</b> is required to obtain reliable results. For this purpose, 2 D PIV measurements are performed and compared to the CFD data...|$|R
3000|$|Four <b>models</b> for the <b>validation</b> sample are considered. Under <b>Model</b> 1, the <b>validation</b> {{sample is}} a simple random sample with {{probability}} π [...]...|$|R
50|$|Model {{diagnostics}} for Box-Jenkins {{models is}} similar to <b>model</b> <b>validation</b> for non-linear least squares fitting.|$|E
5000|$|Certification {{authorities}} {{such as the}} European Aviation Safety Agency, therefore, rely on <b>model</b> <b>validation</b> suites.|$|E
50|$|Some {{statistical}} problems {{come under}} the heading of mathematical geophysics, including <b>model</b> <b>validation</b> and quantifying uncertainty.|$|E
40|$|Methodologies, approaches, and {{techniques}} associated with software requirements analysis and definition; process for defining {{requirements of a}} system including feasibility study, requirements elicitation, formal specification, <b>modeling,</b> <b>validation,</b> verification, and documentation; other topics include cooperative teamwork and project management; first semester of a two-semester capstone project in which students work with a customer...|$|R
5000|$|Test Cases for <b>Modeling</b> and <b>Validation</b> of Structures with Piezoelectric Actuators (2001) ...|$|R
30|$|In {{addition}} to {{the advantages of the}} F 3 approach, F 3 T improves the framework efficiency and the application development, since the implementation steps of the approach are executed through code generation. It also results in better quality artifacts, due to the <b>model</b> <b>validations</b> provided by the tool and to the fact that code generated is less likely to contain defects.|$|R
5000|$|Naylor and Finger 1967 {{formulated}} a three-step {{approach to}} <b>model</b> <b>validation</b> {{that has been}} widely followed: ...|$|E
50|$|There {{are four}} steps to be {{followed}} for system identification: data gathering, model postulate, parameter identification and <b>model</b> <b>validation.</b> Data gathering is considered as the first and essential part in identification terminology, used as the input for the model which is prepared later. It consists of selecting an appropriate data set, pre-processing and processing. It involves {{the implementation of the}} known algorithms together with the transcription of flight tapes, data storage and data management, calibration, processing, analysis and presentation. Moreover, <b>model</b> <b>validation</b> is necessary to gain confidence in, or reject, a particular model. In particular, the parameter estimation and the <b>model</b> <b>validation</b> are integral parts of the system identification. Validation refers to the process of confirming the conceptual model and demonstrating an adequate correspondence between the computational results of the model and the actual data.|$|E
50|$|Other work {{includes}} {{studies of}} the evolution of market structures, including in the market for pollution permits; urban systems; and statistical <b>model</b> <b>validation.</b>|$|E
40|$|This report {{contains}} the detailed course of designing an ontology that formalises the domain knowledge of City Logistics {{and in turn}} facilitates relevant agent-based <b>modelling.</b> <b>Validation</b> and example of application are also included. The formal output of this work is an ontology document edited with Web Ontology Language (OWL) and is named as 'City_logistics_ontology. owr. TILTransport, Infrastructure and LogisticsDelft University of Technolog...|$|R
40|$|International audienceIn this paper, {{we present}} the <b>modeling,</b> <b>validation,</b> and {{verification}} of an industrial protocol for constraint-based path computation, called PCEP. From the PCEP specification defined by IETF, we divide the functionalities of PCEP into two parts: application and protocol. The protocol part of PCEP is then {{described in the}} IF language {{which is based on}} communicating timed automata. A number of basic requirements are identified from the PCEP specification and then described as properties in the IF language. Based on these properties, the validation and verification of the formal specification are carried out using the IF toolset. Test cases are generated by using an automatic test generation tool, called TestGen-IF, which uses partial state space exploration guided by test purposes. As a result of the <b>modeling,</b> <b>validation,</b> and verification, some errors and ambiguities are found in the PCEP specification. Also a number of test cases are obtained which will be used for testing implementation...|$|R
40|$|International audienceThe local {{statistical}} {{approach for}} fault detection and isolation {{is applied to}} fuzzy <b>models</b> <b>validation.</b> The method detects the inconsistencies between a fuzzy rule base and the modelled system. It can also identify which are the faulty parameters of the fuzzy model. The Fisher information matrix explains the detectability {{of changes in the}} parameters of the fuzzy model. Simulation tests illustrate the method's credibility...|$|R
5000|$|OMG BPMN 2.0 {{support with}} all three {{diagrams}} (Process, Collaboration and Choreography), <b>model</b> <b>validation</b> and reports are available with the Cameo Business Modeler plugin ...|$|E
50|$|Given {{that the}} {{validity}} of any conclusion drawn from a statistical inference depends on {{the validity of}} the assumptions made, it is clearly important that those assumptions should be reviewed at some stage. Some instances—for example where data are lacking—may require that researchers judge whether an assumption is reasonable. Researchers can expand this somewhat to consider what effect a departure from the assumptions might produce. Where more extensive data are available, various types of procedures for statistical <b>model</b> <b>validation</b> are available—e.g. for regression <b>model</b> <b>validation.</b>|$|E
50|$|Stat-Ease {{was used}} by Los Alamos National Laboratory {{researchers}} in designing a set of experiments designed to demonstrate the application of <b>model</b> <b>validation</b> techniques to a structural dynamics problem.|$|E
40|$|Many {{river ice}} {{processes}} {{associated with the}} design and operation of river engineering projects cannot be adequately analyzed by a one-dimensional model. A two-dimensional model is required for analyses related to sites with complex flow patterns and river geometry. In this paper, the two-dimensional model of the recently developed Comprehensive River Ice Simulation System (CRISSP) will be presented along with <b>model</b> <b>validations</b> and field applications...|$|R
3000|$|The {{model in}} taper {{recorded}} the best TP rate (82  %) amongst the single-variable models. The rate was considerably higher than TP rates of other single-variable <b>models</b> (<b>validation</b> dataset). However, <b>model</b> performance and accuracy metrics of the calibration dataset were less satisfactory. Similar accuracy metrics {{were found for}} the model with D[*]+[*]H. The TP rate was greatest (91  %) for two models: E[*]+[*]T and V [...]...|$|R
40|$|This report {{describes}} {{the outcomes of}} the Data Management Challenges in 3 D Electron Microscopy workshop. Key topics discussed include data <b>models,</b> <b>validation</b> and raw-data archiving. The meeting participants agreed that the EMDataBank should {{take the lead in}} addressing these issues, and concrete action points were agreed upon that will have a substantial impact on the accessibility of three-dimensional EM data in biology and medicine...|$|R
