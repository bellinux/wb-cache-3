12|113|Public
40|$|AbstractMutation {{analysis}} is usually {{used to provide}} indication of the fault detection ability of a test set. It is mainly used for unit testing evaluation. This paper describes mutation analysis principles and their adaptation to the Lustre programming language. Alien-V, a <b>mutation</b> <b>tool</b> for Lustre is presented. Lesar model-checker is used for eliminating equivalent mutant. A first experimentation to evaluate Lutess testing tool is summarized...|$|E
30|$|Delamare et al. [23] {{proposed}} an approach based on test-driven development concepts and mutant analysis for testing AspectJ pointcuts. Their {{goal was to}} validate pointcuts by means of test cases that explicitly define sets of join points that should be affected by specific advices. A <b>mutation</b> <b>tool</b> named AjMutator [20] implements a subset of our pointcut-related operators [12]. The mutant pointcuts are used to validate {{the effectiveness of their}} approach.|$|E
40|$|The {{impact of}} Aspect-Oriented Software Development (AOSD) on {{testability}} must be quantified {{before it can}} be considered for widespread adoption by industry. One way to measure testability is through mutation analysis (MA). In MA, a <b>mutation</b> <b>tool</b> generates faults for locations in software. Each fault is created in {{a new version of the}} software called a mutant. Testability of a location is measured by executing tests against mutants and counting the proportion of mutants that cause test failure. To quantify the testability of approaches to AOSD through MA, mutant generation tools are needed. This paper introduces MuAspectJ, a tool for generating mutants for AspectJ programs, to satisfy this need. The tool is evaluated in terms of the quality of mutants it generates. Assertions reached about the testability of the software under MA are derived by aggregating the testability of each location. The quality of the assertions that can be derived from MA results is only as good as the mutants on which the analysis is based. MuAspectJ is evaluated by benchmarking metrics that indicate the quality of generated mutants against the existing well known Java <b>mutation</b> <b>tool,</b> MuJava. The results validate the quality of the mutants generated by MuAspectJ. 1...|$|E
40|$|International audienceSoftware {{developers}} employ many {{tools in}} {{every step of}} the development. As automation progresses, tools take a more and more important place. A common and difficult problem is choosing a tool among every tool for a given task. As a particular instance of this problem, this paper considers <b>mutation</b> analysis <b>tools.</b> <b>Mutation</b> analysis is a way to evaluate the quality of a test suite. The quality is measured as the ability of the test suite to detect faults injected into the program under tests. A fault is detected if at least one test case gives different results on the original program and the fault-injected one. <b>Mutation</b> <b>tools</b> aim at automating and speeding both the generation of fault-injected variants, called mutants, and the execution of the test suite on those mutants. This paper proposes a methodology to compare tools and applies it for comparing <b>mutation</b> <b>tools.</b> This methodology proposes to dress a list of comparison criteria as well as a list of usage profiles. <b>Mutation</b> <b>tools</b> for Java are compared on paper and by experiments. The work is then extended to other languages to assert the pertinence of the comparison criteria and the usage profiles. Finally, lessons are drawn from our selection process...|$|R
40|$|Though {{mutation}} analysis {{is the primary}} means of {{evaluating the quality of}} test suites, though it suffers from inadequate standardization. <b>Mutation</b> analysis <b>tools</b> vary based on language, when mutants are generated (phase of compilation), and target audience. <b>Mutation</b> <b>tools</b> rarely implement the complete set of operators proposed in the literature, and most implement at least a few domain-specific mutation operators. Thus different tools may not always agree on the mutant kills of a test suite, and few criteria exist to guide a practitioner in choosing a tool, or a researcher in comparing previous results. We investigate an ensemble of measures such as traditional difficulty of detection, strength of minimal sets, diversity of mutants, as well as the information carried by the mutants produced, to evaluate the efficacy of mutant sets. By these measures, <b>mutation</b> <b>tools</b> rarely agree, often with large differences, and the variation due to project, even after accounting for difference due to test suites, is significant. However, the mean difference between tools is very small indicating that no single <b>tool</b> consistently skews <b>mutation</b> scores high or low for all projects. These results suggest that research using a single tool, a small number of projects, or small increments in mutation score may not yield reliable results. There is a clear need for greater standardization of {{mutation analysis}}; we propose one approach for such a standardization...|$|R
40|$|In this paper, {{we present}} several {{complementary}} computational intelligence techniques that we explored {{in the field}} of. Net component testing. Mutation testing, associated to a global testing-for-trust methodology, serves as the common backbone for applying classical and new artificial intelligence (AI) algorithms. With <b>mutation</b> <b>tools,</b> {{we know how to}} estimate the revealing power of test cases. With AI, we aim at automatically improving test cases efficiency. So, we looked first at genetic algorithms {{to solve the problem of}} test optimization and modeled it as follows: a test case can be considered as a predator while a mutant program (i. e. a program containing a fault) is analogous to a prey. The ai...|$|R
40|$|Although {{mutation}} testing {{is a well-known}} technique for assessing the quality of tests, {{there is not a}} lot of support available for model-level mutation analysis. It is also considered to be expensive due to: (i) the large number of mutants generated; ii) the time-consuming activity of determining equivalent mutants; and (iii) the mutant execution time. It should also be remembered that real software artefacts of appropriate size including real faults are hard to find and prepare appropriately. In this paper we propose a <b>mutation</b> <b>tool</b> to generate valid First Order Mutants (FOM) for Conceptual Schemas (CS) based on UML Class Diagrams and evaluate its effectiveness and efficiency in generating valid and non-equivalent mutants. Our main findings were: 1) FOM mutation operators can be automated to avoiding non-valid mutants (49. 1 %). 2) Fewer equivalent mutants were generated (7. 2 %) and 74. 3 % were reduced by analysing the CS static structure in six subject CSs...|$|E
40|$|This paper {{presents}} {{comparisons of}} the Minimal-MUMCUT logic criterion and prime path coverage. A theoretical comparison of the two criteria is performed in terms of (1) how well tests satisfying one criterion satisfy the other and (2) fault detection. We then compare the criteria experimentally. For 22 programs, we develop tests to satisfy Minimal-MUMCUT and prime path coverage. We use these tests in two separate experiments. First we measure {{the effectiveness of the}} tests developed for one criterion in terms of the other. Next we investigate the ability of the test sets to find actual faults. Faults are seeded via a <b>mutation</b> <b>tool</b> and then supplemented with mutants created by DNF logic mutation operators. We then measure the number of non-equivalent mutants killed by each test set. Results indicate that while prime path-adequate test sets are closer to satisfying Minimal-MUMCUT than vice versa, the criteria had similar fault detection and Minimal-MUMCUT required fewer tests...|$|E
40|$|Mutation {{testing has}} {{historically}} been {{used to assess the}} fault-finding effectiveness of a test suite or other verification technique. Mutation analysis, rather, entails augmenting a test suite to detect all killable mutants. Concerns about the time efficiency of mutation analysis may prohibit its widespread, practical use. The goal of our research is to assess the effectiveness of the mutation analysis process when used by software testers to augment a test suite to obtain higher statement coverage scores. We conducted two empirical studies and have shown that mutation analysis can be used by software testers to effectively produce new test cases and to improve statement coverage scores in a feasible amount of time. Additionally, we find that our user study participants view mutation analysis as an effective but relatively expensive technique for writing new test cases. Finally, we have shown that the choice of <b>mutation</b> <b>tool</b> and operator set can {{play an important role in}} determining how efficient mutation analysis is for producing new test cases. 1...|$|E
40|$|A <b>mutation</b> testing <b>tool</b> {{takes as}} input a system under test and a test suite and {{produces}} as output the mutation {{score of the}} test suite. The tool systematically creates mutants by making small syntactic changes to the system under test and executes the test suite to determine which mutants give different results from the original system. Almost all <b>mutation</b> testing <b>tools</b> {{have been developed for}} statically typed languages. The lack of tools for dynamically typed languages may be rooted in additional challenges that are caused by the lack of precise type information until the program is executed. Existing tools for dynamically typed languages mostly focus on mutation of literals because the type of literals are known statically. This paper presents SMutant, the first <b>mutation</b> testing <b>tool</b> for Smalltalk programs. In addition to literal replacement, SMutant supports many mutation operators that are commonly seen in tools for statically typed languages, such as operator replacement. Instead of applying mutations statically, SMutant postpones mutating until execution and applies mutations dynamically, when the types are available. Also, SMutant enables the user to define new mutation operators by sending a single message. The tool automatically generates code to support new mutation operators...|$|R
50|$|Mutation {{testing was}} {{originally}} proposed by Richard Lipton {{as a student}} in 1971, and first developed and published by DeMillo, Lipton and Sayward. The first implementation of a <b>mutation</b> testing <b>tool</b> was by Timothy Budd {{as part of his}} PhD work (titled Mutation Analysis) in 1980 from Yale University.|$|R
30|$|There {{are several}} <b>mutation</b> <b>tools</b> {{available}} for Java programs (Coles 2015; Ferrari et al. 2011; Just et al. 2011; Ma et al. 2005). We {{are using the}} set of mutation operators implemented by μJava system which supports MT for Java programs (Ma et al. 2005). It creates object-oriented mutants for Java according to 47 mutation operators specialized to object-oriented faults: 19 Traditional Operators responsible to model faults at method level (Ma and Offutt 2005), and 28 Class Operators, responsible to model faults at class level (Offutt et al. 2006). Besides the advantage of having a well defined set of program faults, generated by mutation operators, is that the faults introduced by the operators are not detectable by Eclipse IDE as the injected faults used {{in the work of}} (Daimi et al. 2013).|$|R
40|$|Off-The-Shelf (OTS) {{software}} components are {{the cornerstone of}} modern systems, including safety-critical ones. However, the dependability of OTS components is uncertain {{due to the lack}} of source code, design artifacts and test cases, since only their binary code is supplied. Fault injection in components’ binary code is a solution to understand the risks posed by buggy OTS components. In this paper, we consider the problem of the accurate mutation of binary code for fault injection purposes. Fault injection emulates bugs in high-level programming constructs (assignments, expressions, function calls, [...] .) by mutating their translation in binary code. However, the semantic gap between the source code and its binary translation often leads to inaccurate mutations. We propose Faultprog, a systematic approach for testing the accuracy of binary mutation tools. Faultprog automatically generates synthetic programs using a stochastic grammar, and mutates both their binary code with the tool under test, and their source code as reference for comparisons. Moreover, we present a case study on a commercial binary <b>mutation</b> <b>tool,</b> where Faultprog was adopted to identify code patterns and compiler optimizations that affect its mutation accuracy...|$|E
40|$|Aspect-oriented {{programming}} (AOP) languages {{introduce new}} constructs {{that can lead}} to new types of faults, which must be targeted by testing techniques. In particular, AOP languages such as AspectJ use a pointcut descriptor (PCD) that provides a convenient way to declaratively specify a set of joinpoints in the program where the aspect should be woven. However, a major difficulty when testing that the PCD matches the intended set of joinpoints is the lack of precise specification for this set other than the PCD itself. In this paper, we propose a test-driven approach for the development and validation of the PCD. We developed a tool, AdviceTracer, which enriches the JUnit API with new types of assertions {{that can be used to}} specify the expected joinpoints. In order to validate our approach, we also developed a <b>mutation</b> <b>tool</b> that systematically injects faults into PCDs. Using these two tools, we perform experiments to validate that our approach can be applied for specifying expected joinpoints and for detecting faults in the PCD. Keywords: Aspect-oriented programming, joinpoints, pointcut descriptors, mutation analysis, testdriven development, testing tool 1...|$|E
40|$|International audienceAspect-oriented {{programming}} (AOP) languages {{introduce new}} constructs {{that can lead}} to new types of faults, which must be targeted by testing techniques. In particular, AOP languages such as AspectJ use a pointcut descriptor (PCD) that provides a convenient way to declaratively specify a set of joinpoints in the program where the aspect should be woven. However, a major difficulty when testing that the PCD matches the intended set of joinpoints is the lack of precise specification for this set other than the PCD itself. In this paper, we propose a test-driven approach for the development and validation of the PCD. We developed a tool, AdviceTracer, which enriches the JUnit API with new types of assertions {{that can be used to}} specify the expected joinpoints. In order to validate our approach, we also developed a <b>mutation</b> <b>tool</b> that systematically injects faults into PCDs. Using these two tools, we perform experiments to validate that our approach can be applied for specifying expected joinpoints and for detecting faults in the PCD...|$|E
40|$|Mutation {{testing is}} used {{extensively}} {{to support the}} experimentation of software engineering studies. Its application to real-world projects is possible thanks to modern tools that automate the whole mutation analysis process. However, popular <b>mutation</b> testing <b>tools</b> use a restrictive set of mutants which {{do not conform to}} the community standards as supported by the mutation testing literature. This can be problematic since the effectiveness of mutation depends on its mutants. We therefore examine how effective are the mutants of a popular <b>mutation</b> testing <b>tool,</b> named PIT, compared to comprehensive ones, as drawn from the literature and personal experience. We show that comprehensive mutants are harder to kill and encode faults not captured by the mutants of PIT for a range of 11 % to 62 % of the Java classes of the considered projects...|$|R
40|$|Mutation {{testing is}} a fault based testing {{technique}} {{used to find}} the effectiveness of test cases. It is a powerful and computationally expensive technique to find the adequacy of test cases. One of the major disadvantages of mutation testing is compiling and executing the faulty versions of the original programs (called mutants) with all the provided test cases. Hence this process should be automated. Research {{has been done to}} generate the tools to automate the mutation process in procedural languages. Some projects have been based around extending mutation testing for Object-Oriented (OO) programming languages because of its growing importance. Some tools have been developed but are not reliable. In this research, we are trying to address the limitations of a current <b>mutation</b> testing <b>tool,</b> called MU, developed by Mattias Bybro. We are also building a tool to generate the test cases automatically and integrating this with the modified <b>mutation</b> testing <b>tool...</b>|$|R
40|$|In this paper, {{we present}} several {{complementary}} computational intelligence techniques that we explored {{in the field}} of. Net component testing. Mutation testing serves as the common backbone for applying classical and new artificial intelligence (AI) algorithms. With <b>mutation</b> <b>tools,</b> {{we know how to}} estimate the revealing power of test cases. With AI, we aim at improving automatically test cases efficiency. So, we looked first at genetic algorithms (GA) {{to solve the problem of}} test. The aim of the selection process is to generate test cases able to kill as many mutants as possible. Then, we propose a new AI algorithm that fits better to the test optimization problem we called bacteriological algorithm (BA) : BAs behave better that GAs for this problem. However, between GAs and BAs, a family of intermediate algorithms exists: we explore the whole spectrum of these intermediate algorithms to determine whether an algorithm exists that would be more efficient than BAs. : the approaches are compared on a. Net system...|$|R
40|$|The {{effectiveness}} of mutation testing depends {{heavily on the}} types of faults that the mutation operators are designed to represent. Therefore, {{the quality of the}} mutation operators is key to mutation testing. Mutation testing has traditionally been applied to procedural-based languages, and mutation operators have been developed to support most of their language features. Object-oriented programming languages contain new language features, most notably inheritance, polymorphism, and dynamic binding. Not surprisingly, these language features allow new kinds of faults, some of which are not modeled by traditional mutation operators. Although mutation operators for OO languages have previously been suggested, our work in OO faults indicate that the previous operators are insufficient to test these OO language features, particularly at the class testing level. This paper introduces a new set of class mutation operators for the OO language Java. These operators are based on specific OO faults and can be used to detect faults involving inheritance, polymorphism, and dynamic binding, thus are useful for inter-class testing. An initial Java <b>mutation</b> <b>tool</b> has recently been completed, and a more powerful version iscurrentlyunderconstruction. 1...|$|E
40|$|Several module {{and class}} testing {{techniques}} {{have been applied}} to object-oriented programs, but researchers have only recently begun developing test criteria that evaluate the use of key OO features such as inheritance, polymorphism, and encapsulation. Mutation testing is a powerful testing technique for generating software tests and {{evaluating the quality of}} software. However, the cost of mutation testing has traditionally been so high it cannot be applied without full automated tool support. This paper presents a method to reduce the execution cost of mutation testing for OO programs by using two key technologies, Mutant Schemata Generation (MSG) and bytecode translation. This method adapts the existing MSG method for mutants that change the program behavior and uses bytecode translation for mutants that change the program structure. A key advantage is in performance: only two compilations are required and both the compilation and execution time for each is greatly reduced. A <b>mutation</b> <b>tool</b> based on the MSG/bytecode translation method has been built and used to measure the speedup over the separate compilation approach. Experimental results show that the MSG/bytecode translation method is about five times faster than separate compilation...|$|E
40|$|Abstract—Mutation {{testing is}} a well {{established}} fault-based technique for assessing and {{improving the quality of}} test suites. Mutation testing can be applied at different levels of abstraction, e. g., the unit level, the integration level, and the specification level. Designing mutation operators is the most critical activity towards conducting effective mutation testing and analysis. Mutation operators are well defined for a number of programming (e. g., C, Java, etc.) and specification (e. g., FSM, Petri Nets, etc.) languages. In this paper, we design and classify mutation operators for the Abstract State Machines (ASM) formalism. The designed operators are defined based on the types of faults that may occur in ASM specifications and can be classified into three categories: (1) Domain operators, (2) function update operators, and (3) transition rules operators. Furthermore, a prototype <b>mutation</b> <b>tool</b> for the CoreASM language, has been built to automatically generate mutants and check their validity. We illustrate our approach using a simple CoreASM implementation of the Fibonacci series. Finally, an empirical comparison of the designed operators is presented and discussed. Keywords—Mutation testing; specification; mutation operator; Abstract State Machines (ASM); domain operators; function update operators; transition rules operators; CoreASM. I...|$|E
40|$|Mutation testing {{measures}} {{the adequacy of}} the test suite by seeding artificial defects i. e. mutants in the program. If the mutant is not detected by the test suite, is means that the test suite is not adequate. And new test suites are added until all the mutants have been detected. AspectJ is an aspect-oriented programming language that provides the concept of pointcut and advice. In this paper we proposed different <b>mutation</b> testing <b>tools,</b> their need and manner to implement and also at last we had developed a tabular comparison of different <b>mutation</b> testing <b>tools</b> like Ajmutator, Advice Tracer, MuAspectJ and Proteum/AJ. The uses of such tools in the a testing process enhances the feasibility of using it in real software development process and helped us to reason about the current functionalities and to identify future needs. The result includes the comparison of different testing tools and a number of parameters to judge their performance...|$|R
40|$|Model based {{software}} {{development is a}} common procedure within {{a wide range of}} embedded {{software development}}. To ensure the quality of software it is essential to ensure the quality of the model. Testing is an essential software quality assurance activity. The quality of testing activity depends on the quality of a test suite. Thus, the evaluation of the quality of a test suite is vital. Mutation testing is a powerful technique to measure the goodness of a test suite or drive test-data generation. A mutant is generated by slightly changing the model. A test suite is adequate if it is able to detect all mutants. Mutation operators decide the type of changes to use. This thesis explores a set of mutation operators for Matlab/Simulink/Stateflow models evaluating their adequacy. A prototype of a <b>mutation</b> testing <b>tool</b> for Matlab/Simulink/Stateflow models was implemented to generate mutants and to show how the mutation operators allow us to measure the adequacy of the test suite. We can say that a <b>mutation</b> testing <b>tool</b> for the software industry is within reach...|$|R
40|$|Despite {{the fact}} that over 90 % of HIV- 1 {{infected}} people worldwide harbor non-subtype B variants of HIV- 1, knowledge of resistance mutations in non-B HIV- 1 and their clinical relevance is limited. Due to historical delays in access to antiretroviral therapy (ART) on a worldwide basis, {{the vast majority of}} reports on drug resistance deal with subtype B infections in developed countries. However, both enzymatic and virological data support the concept that naturally occurring polymorphisms among different nonB subtypes can affect HIV- 1 susceptibility to antiretroviral drugs (ARVs), the magnitude of resistance conferred by major mutations, and the propensity to acquire some resistance <b>mutations.</b> <b>Tools</b> need to be optimized to assure accurate measurements of drug susceptibility of non-B subtypes. Furthermore, {{there is a need to}} recognize that each subtype may have a distinct resistance profile and that differences in resistance pathways may also impact on cross-resistance and the selection of second-line regimens. It will be essential to pay attention to newer drug combinations in well designed long-term longitudinal studies involving patients infected by viruses of different subtypes...|$|R
40|$|Mutation {{testing is}} a {{well-known}} method for measuring a test suite’s quality. However, due to its computational expense and intrinsic difficulties (e. g., detecting equivalent mutants and potentially checking a mutant’s status for each test), mutation testing is often challenging to practically use. To control the computational cost of mutation testing, many reduction strategies have been proposed (e. g., uniform random sampling over mutants). Yet, a stand-alone tool to compare the efficiency and effectiveness of these methods is heretofore unavailable. Since existing <b>mutation</b> testing <b>tools</b> are often complex and languagedependent, this paper presents a tool, called mrstudyr, that enables the “retrospective” study of mutant reduction methods using the data collected from a prior analysis of all mutants. Focusing on the mutation operators and the mutants that they produce, the presented tool allows developers to prototype and evaluate mutant reducers without being burdened by the implementation details of <b>mutation</b> testing <b>tools.</b> Along with describing mrstudyr’s design and overviewing the experimental results from using it, this paper inaugurates the public release of this open-source tool...|$|R
40|$|Mutation {{testing has}} been widely {{used to assess the}} fault-detection {{effectiveness}} of a test suite, as well as to guide test case generation or prioritization. Empirical studies have shown that, while mutants are generally representative of real faults, an effective application of mutation testing requires "traditional" operators designed for programming languages to be augmented with operators specific to an application domain and/or technology. This paper proposes MDroid+, a framework for effective mutation testing of Android apps. First, we systematically devise a taxonomy of 262 types of Android faults grouped in 14 categories by manually analyzing 2, 023 software artifacts from different sources (e. g., bug reports, commits). Then, we identified a set of 38 mutation operators, and implemented an infrastructure to automatically seed mutations in Android apps with 35 of the identified operators. The taxonomy and the proposed operators have been evaluated in terms of stillborn/trivial mutants generated and their capacity to represent real faults in Android apps, as compared to other well know <b>mutation</b> <b>tools.</b> Comment: Accepted at 11 TH Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE 17...|$|R
40|$|A brief {{overview}} of several recent model-based testing and verification projects that I’ve been involved in. These include our book on “Practical Model-Based Testing”, the Jumble <b>mutation</b> analysis <b>tool</b> for JUnit tests, unit testing of Z specifications with positive and negative tests, correctness checking of the JStar parallel programming language using SMT solvers, {{and work with the}} Whiley verified programming language in collaboration with Victoria University of Wellington. The common theme is getting computers to automate more of the checking for errors in our programs...|$|R
40|$|Estimating {{the quality}} of test suites is an {{important}} and difficult task. Mutation analysis is one approach to measure test quality by injecting faults in a correct version of the system under test and measuring the percentage of faulty systems that are detected by the tests. There are several automatic <b>mutation</b> analysis <b>tools.</b> Each of them, however, is restricted to a comparatively small range of execution environments. In this paper, we introduce a generic approach to run mutation analysis and present a corresponding prototype implementation...|$|R
40|$|Software testing plays {{a crucial}} role in {{software}} development life cycle. Without testing, quality of software product is questionable. Mutation testing, widely accepted fault based testing technique. Aspect Oriented Programming is a new methodology that introduces the concept of modularization. AspectJ is an aspect oriented programming language that provides the concept of pointcut and advice. With new features, AOP introduces new faults that can be easily handled by mutation testing. In this paper, we evaluate the available AspectJ based <b>mutation</b> testing <b>tools</b> and identify the basic requirements that must be satisfied by any developed tool...|$|R
40|$|Conclusion In my research, I studied three <b>{{mutation}}</b> testing <b>tools</b> for Java: MuJava, Jumble, and PIT. All of them use byte level mutation which {{speeds up}} {{the time it}} takes to generate the mutants and run the mutants against the test suite. Both Jumble and PIT have support for JUnit, the Java unit testing framework. However, PIT is the most capable for use in industry because it also integrates well with other Java tools such as ant and is the most actively supported project. Example Mutant Generated by MuJav...|$|R
50|$|Today, many {{different}} types of technologies exist in which splice sites can be located and analyzed for more information. The Human Splicing Finder is an online database stemming from the Human Genome Project data. The genome database identifies thousands of mutations related to medical and health fields, as well as providing critical research information regarding splice site <b>mutations.</b> The <b>tool</b> specifically searches for pre-mRNA splicing errors, the calculation of potential splice sites using complex algorithms, and correlation with several other online genomic databases, such as the Ensembl genome browser.|$|R
40|$|As {{the speed}} of {{microprocessors}} tails off, utilizing multiple processing cores per chip is becoming a common way for developers to achieve higher performance. However, writing concurrent programs {{can be a big}} challenge because of common concurrency faults. Because concurrency faults are hard to detect and reproduce, traditional testing techniques are not suitable. New techniques are needed, and these must be assessed. A typical method for assessing testing techniques is to embed faults in programs using <b>mutation</b> <b>tools,</b> and assess the ability of techniques to detect these. Although mutation testing techniques can be used to represent common faults, approaches for representing concurrency faults have not been created. In this paper, we introduce a methodology for injecting mutations related to concurrency faults, focusing on four common concurrency fault patterns as mutant operators. We implement the approach in the Eclipse IDE. We empirically study our approach 2 ̆ 7 s effectiveness by using it to seed various types of concurrency faults based on the four fault patterns in a set of programs. This approach generates many times more mutants than can be seeded by hand. We then execute the original programs and these mutants. We characterize the mutants in terms of detectability as part of our study. The results show that using the proposed tool, concurrent fault injection tool (CFIT) is feasible and efficient. Adviser: Gregg Rothermel and Witty Srisa-a...|$|R
40|$|Abstract—Verification of {{embedded}} multicore applications {{is crucial}} as these applications are deployed in many safety critical systems. Verification task {{is complicated by}} concurrency inherent in such applications. We use mutation testing to obtain a quanti-tative verification coverage metric for mullticore applications de-veloped using the new Multicore Communication API (MCAPI) standard. MCAPI is a lightweight API that targets heterogeneous multicore embedded systems. We developed a <b>mutation</b> coverage <b>tool</b> and performed several experiments on MCAPI applications. Our experiments show that mutation coverage is useful in measuring and {{improving the quality of}} the test suites and ultimately the quality of the multicore application. I...|$|R
40|$|Background: p 53 is {{commonly}} inactivated by mutations in the DNA-binding domain {{in a wide}} range of cancers. As mutant p 53 often influences response to therapy, effective and rapid methods to scan for mutations in TP 53 are likely to be of clinical value. We therefore evaluated the use of high resolution melting (HRM) as a rapid <b>mutation</b> scanning <b>tool</b> for TP 53 in tumour samples. Methods: We designed PCR amplicons for HRM mutation scanning of TP 53 exons 5 to 8 and tested them with DNA from cell lines hemizygous or homozygous for known mutations. We assessed the sensitivity of each PCR amplicon using dilutions of cel...|$|R
40|$|Current <b>mutation</b> {{analysis}} <b>tools</b> {{are primarily}} {{used to compare}} different test suites and are tied to a particular programming language. In this paper we present the Ex-MAn experimental mutation analysis framework – ExMAn is automated, general and flexible and allows for the comparison of different quality assurance techniques such as testing, model checking, and static analysis. The goal of Ex-MAn is to allow for automatic mutation analysis that can be reproduced by other researchers. After describing ExMAn, we present a scenario of using ExMAn to compare testing with static analysis of temporal logic properties. We also provide both the benefits and the current limitations of using our framework. 1...|$|R
40|$|This paper {{presents}} MuCheck, a <b>mutation</b> testing <b>tool</b> for Haskell programs. MuCheck is a {{counterpart to}} the widely used QuickCheck random testing tool for functional pro-grams, {{and can be}} used to evaluate the efficacy of QuickCheck property definitions. The <b>tool</b> implements <b>mutation</b> opera-tors that are specifically designed for functional programs, and makes use of the type system of Haskell to achieve a more relevant set of mutants than otherwise possible. Mu-tation coverage is particularly valuable for functional pro-grams due to highly compact code, referential transparency, and clean semantics; these make augmenting a test suite or specification based on surviving mutants a practical method for improved testing...|$|R
