27|544|Public
5|$|The user {{interface}} and game controls are unified across the PC and home console versions. Players {{have the option}} of using any combination of a keyboard, mouse, and game controller to play; the former two are achieved on PlayStation 4 via wireless or USB keyboard and mouse. By default, the system is navigated through drag and drop windows on PC. Navigation on the PlayStation version of Final Fantasy XIV is accomplished with a XrossMediaBar-like interface due to platform users' familiarity with the set-up. This bar is used to access all menus, maps, logs, and configuration options. The head-up display for both versions includes a <b>message</b> <b>log,</b> party status menu, mini-map, and action bar. The player may customize the location of all of these elements.|$|E
5000|$|DD Form 1765, Incoming Service <b>Message</b> <b>Log</b> {{would be}} used to record {{received}} messages.|$|E
5000|$|DD Form 1766, Outgoing Service <b>Message</b> <b>Log</b> {{would be}} used to record {{outgoing}} messages.|$|E
40|$|We {{present a}} number of {{experiments}} showing that for compute-intensive applications executing in parallel on clusters of workstations, <b>message</b> <b>logging</b> has higher failure-free overhead than coordinated checkpointing. <b>Message</b> <b>logging</b> protocols, however, result in much shorter output latency than coordinated checkpointing. Therefore, <b>message</b> <b>logging</b> {{should be used for}} applications involving substantial interactions with the outside world, while coordinated checkpointing should be used otherwise. We also present an unorthodox <b>message</b> <b>logging</b> design that uses coordinated checkpointing with <b>message</b> <b>logging,</b> departing from the conventional approaches that use independent checkpointing. This combination of <b>message</b> <b>logging</b> and coordinated checkpointing offers several advantages, including improved failure-free performance, bounded recovery time, simplified garbage collection, and reduced complexity. Meanwhile, the new protocols retain the advantages of the conventional <b>message</b> <b>logging</b> protocols with respect to output commit. Finally, we discuss three “lessons learned” from an implementation of various <b>message</b> <b>logging</b> protocol...|$|R
40|$|International audienceTo execute MPI {{applications}} reliably, {{fault tolerance}} mechanisms are needed. <b>Message</b> <b>logging</b> {{is a well}} known solution to provide fault tolerance for MPI applications. It as been proved that it can tolerate higher failure rate than coordinated checkpointing. However pessimistic and causal <b>message</b> <b>logging</b> can induce high overhead on failure free execution. In this paper, we present O 2 P, a new optimistic <b>message</b> <b>logging</b> protocol, based on active optimistic <b>message</b> <b>logging.</b> Contrary to existing optimistic <b>message</b> <b>logging</b> protocols that saves dependency information on reliable storage periodically, O 2 P logs dependency information {{as soon as possible}} {{to reduce the amount of}} data piggybacked on application messages. Thus it reduces the overhead of the protocol on failure free execution, making it more scalable and simplifying recovery. O 2 P is implemented as a module of the Open MPI library. Experiments show that active <b>message</b> <b>logging</b> is promising to improve scalability and performance of optimistic <b>message</b> <b>logging...</b>|$|R
40|$|<b>Message</b> <b>logging</b> is a {{transparent}} solution to provide fault tolerance for message passing applications. O 2 P {{is an extremely}} optimistic <b>message</b> <b>logging</b> protocol that is proved to tolerate multiple failures. Extremely optimistic <b>message</b> <b>logging</b> aims at combining the advantages of optimistic and pessimistic <b>message</b> <b>logging</b> to be well-suited for large scale applications while minimizing the overhead on failure free execution. In this paper, we present the O 2 P protocol and prove that it can handle concurrent failures...|$|R
5000|$|Loglevel {{specifies}} {{the type}} of message {{being sent to the}} kernel <b>message</b> <b>log.</b> The syntax with loglevel is:printk(KERN_DEBUG [...] "Debug message shown!\n"); ...|$|E
50|$|The {{first line}} is the void main {{function}} which is the function that a NWScript will start at. In the third line, the text Hello world {{is sent to the}} player's in-game <b>message</b> <b>log.</b>|$|E
5000|$|NWScript {{has no way}} to {{directly}} target the screen for output. Instead, for instance, in-game characters such as the player character {{can be made to}} speak the typical [...] "Hello world" [...] example message. This script puts a [...] "Hello world" [...] message in the player's <b>message</b> <b>log.</b> For it to work, it should be placed in the OnClientEnter event of the module's properties.|$|E
40|$|Manetho {{is a new}} {{transparent}} rollback_recovery {{protocol for}} long-running distributed computations. It uses a novel combination of antecedence graph maintenance, uncoordinated check pointing, and sender-based <b>message</b> <b>logging.</b> Manetho simultaneously achieves the advantages of pessimistic <b>message</b> <b>logging,</b> namely limited rollback and fast output commit, and the advantage of optimistic <b>message</b> <b>logging,</b> namely low failure-free overhead. These advantages {{come at the expense}} of a complex recovery schem...|$|R
40|$|With {{the growing}} scale of HPC applications, {{there has been}} an {{increase}} in the number of interruptions as a consequence of hardware failures. The remarkable decrease of Mean Time Between Failures (MTBF) in current systems encourages the research of suitable fault tolerance solutions. <b>Message</b> <b>logging</b> combined with uncoordinated checkpoint compose a scalable rollback-recovery solution. However, <b>message</b> <b>logging</b> techniques are usually responsible for most of the overhead during failure-free executions. Taking this into consideration, this paper proposes the Hybrid <b>Message</b> Pessimistic <b>Logging</b> (HMPL) which focuses on combining the fast recovery feature of pessimistic receiver-based <b>message</b> <b>logging</b> with the low failure-free overhead introduced by pessimistic sender-based <b>message</b> <b>logging.</b> The HMPL manages messages using a distributed controller and storage to avoid harming system’s scalability. Experiments show that the HMPL is able to reduce overhead by 34 % during failure-free executions and 20 % in faulty executions when compared with a pessimistic receiver-based <b>message</b> <b>logging...</b>|$|R
40|$|International audienceWith {{the growing}} scale of high {{performance}} computing platforms, fault tolerance {{has become a}} major issue. Among the various approaches for providing fault tolerance to MPI applications, <b>message</b> <b>logging</b> has been proved to tolerate higher failure rate. However, this advantage comes at the expense of a higher overhead on communications, due to latency intrusive logging of events to a stable storage. Previous work proposed and evaluated several protocols relaxing the synchronicity of event logging to moderate this overhead. Recently, the model of <b>message</b> <b>logging</b> has been refined to better match the reality of high performance network cards, where message receptions are decomposed in multiple interdependent events. According to this new model, deterministic and non-deterministic events are clearly discriminated, reducing the overhead induced by <b>message</b> <b>logging.</b> In this paper we compare, experimentally, a pessimistic and an optimistic <b>message</b> <b>logging</b> protocol, using this new model and implemented in the Open MPI library. Although pessimistic and optimistic <b>message</b> <b>logging</b> are, respectively, the most and less synchronous <b>message</b> <b>logging</b> paradigms, experiments show that most of the time their performance is comparable...|$|R
50|$|The GUI uses a double-paned layout, {{with the}} local {{filesystem}} in the left pane and the remote filesystem in the right pane. Below there is a transfer queue that shows the real-time status of each queued or active file transfer. At the bottom is a <b>message</b> <b>log,</b> which displays the text commands and responses between gFTP and the remote server. Sites are stored in a hierarchical collection of bookmarks, though a site bar allows connections to unbookmarked sites.|$|E
50|$|Version 0.4 of Miranda IM was {{released}} on April 7, 2005. This was the first version to have Yahoo! protocol bundled with the official release. Other major changes included the removal of contact list and database module from the core into plugins. As a result, there were 4 variations of contact list modules: the original clist_classic, multi-window contact list clist_mw, modern contact list clist_modern, and nicer contact list with extensive UI customization clist_nicer. Other popular plugins released within this period included tabbed message window (tabsrmm and scriver), HTML based <b>message</b> <b>log</b> support IE view, scripting plugin mbot, and the meta contact plugin.|$|E
50|$|The user {{interface}} and game controls are unified across the PC and home console versions. Players {{have the option}} of using any combination of a keyboard, mouse, and game controller to play; the former two are achieved on PlayStation 4 via wireless or USB keyboard and mouse. By default, the system is navigated through drag and drop windows on PC. Navigation on the PlayStation version of Final Fantasy XIV is accomplished with a XrossMediaBar-like interface due to platform users' familiarity with the set-up. This bar is used to access all menus, maps, logs, and configuration options. The head-up display for both versions includes a <b>message</b> <b>log,</b> party status menu, mini-map, and action bar. The player may customize the location of all of these elements.|$|E
40|$|Fault {{tolerance}} is a {{very important}} concern for critical high performance applications using the MPI library. Several protocols provide automatic and transparent fault detection and recovery for message passing systems with different impact on application performance and the capacity to tolerate a high fault rate. In a recent paper, we have demonstrated that the main differences between pessimistic sender based <b>message</b> <b>logging</b> and coordinated checkpointing are 1) the communication latency and 2) the performance penalty in case of faults. Pessimistic <b>message</b> <b>logging</b> increases the latency, due to additional blocking control messages. When faults occur at a high rate, coordinated checkpointing implies a higher performance penalty than <b>message</b> <b>logging</b> due to a higher stress on the checkpoint server. In this paper we extend this study to improved versions of <b>message</b> <b>logging</b> and coordinated checkpoint protocols which respectively reduces the latency overhead of pessimistic <b>message</b> <b>logging</b> and the server stress of coordinated checkpoint. We detail the protocols and their implementation into the new MPICH-V fault tolerant framework. We compare their performance against the previous versions and we compare the novel <b>message</b> <b>logging</b> protocols against the improved coordinated checkpointing one using the NAS benchmark on a typical high performance cluster equipped with a high speed network. The contribution of this paper is two folds: a) an original <b>message</b> <b>logging</b> protocol and an improved coordinated checkpointing protocol and b) the comparison between them...|$|R
40|$|Uncoordinated {{checkpointing}} for message-passing systems allows maximum process {{autonomy and}} general nondeterministic execution, but suffers from potential domino effect {{and the large}} space overhead for maintaining checkpoints and <b>message</b> <b>logs.</b> Traditionally, it has been assumed that only obsolete checkpoints and <b>message</b> <b>logs</b> before the global recovery line can be garbage-collected. Recently, an approach to identifying all garbage checkpoints based on recovery line transformation and decomposition has been developed. We show in this paper that the same approach {{can be applied to}} the problem of identifying all garbage <b>message</b> <b>logs</b> for systems requiring <b>message</b> <b>logging</b> to record in-transit messages. Communication trace-driven simulation for several parallel programs is used to evaluate the proposed algorithm...|$|R
40|$|AbstractWith {{the growing}} scale of High Performance Computing {{applications}} comes {{an increase in}} the number of interruptions as a consequence of hardware failures. As the tendency is to scale parallel executions to hundred of thousands of processes, fault tolerance is becoming an important matter. Uncoordinated fault tolerance protocols, such as <b>message</b> <b>logging,</b> seem to be the best option since coordinated protocols might compromise applications scalability. Considering that most of the overhead during failure-free executions is caused by <b>message</b> <b>logging</b> approaches, in this paper we propose a Hybrid <b>Message</b> <b>Logging</b> protocol. It focuses on combining the fast recovery feature of pessimistic receiver-based <b>message</b> <b>logging</b> with the low protection overhead introduced by pessimistic sender-based <b>message</b> <b>logging.</b> The Hybrid <b>Message</b> <b>Logging</b> aims to reduce the overhead introduced by pessimistic receiver-based approaches by allowing applications to continue normally before a received message is properly saved. In order to guarantee that no message is lost, a pessimistic sender-based logging is used to temporarily save messages while the receiver fully saves its received messages. Experiments have shown that we can achieve up to 43 % overhead reduction compared to a pessimistic receiver- based logging approach...|$|R
5000|$|CMC is {{examined}} and {{compared to other}} communication media {{through a number of}} aspects thought to be universal to all forms of communication, including (but not limited to) synchronicity, persistence or [...] "recordability", and anonymity. The association of these aspects with different forms of communication varies widely. For example, instant messaging is intrinsically synchronous but not persistent, since one loses all the content when one closes the dialog box unless one has a <b>message</b> <b>log</b> set up or has manually copy-pasted the conversation. E-mail and message boards, on the other hand, are low in synchronicity since response time varies, but high in persistence since messages sent and received are saved. Properties that separate CMC from other media also include transience, its multimodal nature, and its relative lack of governing codes of conduct. CMC is able to overcome physical and social limitations of other forms of communication and therefore allow the interaction of people who are not physically sharing the same space.|$|E
40|$|Causal message logging {{has many}} good {{properties}} such as nonblocking message logging and no rollback propagation. However, {{it requires a}} large amount of information to be piggybacked on each message, which may incur severe performance degradation. This paper presents an efficient causal logging algorithm based on the new <b>message</b> <b>log</b> structure, LogOn, which represents the causal interprocess dependency relation with much smaller overhead compared to the existing algorithms. The proposed algorithm is efficient {{in the sense that it}} requires no additional information other than LogOn to be carried in each message, while the other algorithms require extra information other than the <b>message</b> <b>log,</b> to eliminate the duplicates in log entries. Moreover, in those algorithms, as more extra information is added into the message, more duplicates can be detected. However, the proposed algorithm achieves the same degree of efficiency using only the <b>message</b> <b>log</b> carried in each message, without any extra [...] ...|$|E
40|$|Sender-based message logging {{is a new}} low-overhead {{mechanism}} for providing transparent fault-tolerance in distributed systems. It differs from conventional message logging mechanisms in that each message is logged in volatile memory on the machine from which the message is sent. Keeping the <b>message</b> <b>log</b> in the sender's local memory allows us to recover from a single failure at a time without the expense of synchronously logging each message to stable storage. The <b>message</b> <b>log</b> is then asynchronously written to stable storage, without delaying the computation, {{as part of the}} sender's periodic checkpoint. Maintaining the sender-based <b>message</b> <b>log</b> requires at most one extra network packet over non-fault-tolerant reliable message communication and imposes little additional synchronization delay. It can be applied transparently to existing distributed applications and does not require specialized hardware. It is currently being implemented on a network of SUN workstations. 1 Introduction Sen [...] ...|$|E
40|$|Recently, two <b>message</b> <b>logging</b> {{protocols}} {{that are}} neither optimistic nor pessimistic but combine the desirable {{properties of the}} two classical approaches have been proposed. These protocols, Family Based Logging (FBL) and Manetho, never allow orphans to be created but do not introduce blocking in failure free runs. In a recent paper, we presented the first precise specification of <b>message</b> <b>logging</b> protocols, and argued that the two protocols mentioned above are instances of {{a new class of}} <b>message</b> <b>logging</b> protocols, that we call causal. In the same paper we defined a <b>message</b> <b>logging</b> protocol to be optimal if it is causal and does not send any additional messages over those needed to mask transient link failures. Optimal message protocols do exact a price, however: they piggyback additional information on the application's messages. One parameter of <b>message</b> <b>logging</b> protocols is the number of crash failures f that can occur before one of the processes recovers. The two existing optimal <b>message</b> <b>logging</b> protocols are at opposite ends of the spectrum: FBL can tolerate only one crash at a time while Manetho can tolerate all processes crashing. FBL is a much simpler protocol than Manetho, however, and o...|$|R
40|$|A~p 1 Wixd bar Pub- lso Abstract I Uncoordinated {{checkpointing}} for message-passing systems allows maximum process {{autonomy and}} general nondeterministic execution, but suffers from potential domino effect {{and the large}} space overhead for maintaining checkpoints and <b>message</b> <b>logs.</b> Traditionally, it has been assumed that only obsolete checkpoints and <b>message</b> <b>logs</b> before the global recovery line can be garbage-collected. Recently, an approach to identifying all garbage checkpoints based on recovery line transformation and decomposition has been developed. We show in this paper that the same approach {{can be applied to}} the problem of identifying all garbage <b>message</b> <b>logs</b> for systems requiring <b>message</b> <b>logging</b> to record in-transit messages. Communication trace-driven simulation for several parallel programs is used to evaluate the proposed algorithm. DTIC QUALITY INSPECTED...|$|R
40|$|Abstract. Fault {{tolerance}} {{is becoming}} a major concern in HPC sys-tems. The two traditional approaches for message passing applications, coordinated checkpointing and <b>message</b> <b>logging,</b> have severe scalability issues. Coordinated checkpointing protocols make all processes roll back after a failure. <b>Message</b> <b>logging</b> protocols log {{a huge amount of}} data and can induce an overhead on communication performance. Hierarchi-cal rollback-recovery protocols based on the combination of coordinated checkpointing and <b>message</b> <b>logging</b> are an alternative. These partial mes-sage logging protocols are based on process clustering: only messages between clusters are logged to limit the consequence of a failure to one cluster. These protocols would work efficiently only if one can find clus-ters of processes in the applications such that the ratio of <b>logged</b> <b>messages</b> is very low. We study the communication patterns of message passing HPC applications to show that partial <b>message</b> <b>logging</b> is suitable in most cases. We propose a partitioning algorithm to find suitable clusters of processes given the communication pattern of an application. Finally, we evaluate the efficiency of partial <b>message</b> <b>logging</b> using two state of the art protocols on a set of representative applications. ...|$|R
40|$|This master's thesis in {{the first}} part {{describes}} the AS/ 400 and its message system and concentrates especially on the following areas: predefinition of messages and their storing, types of messages and levels of their importance, work with variables included in message text and ways of sending messages. On the basis of AS/ 400 message system is designed and implemented <b>message</b> <b>log</b> system for the application loggin for Aegis. s. r. o. The analysis of the <b>message</b> <b>log</b> systems is also a part of the work. The syslog and syslog-ngused in UNIX systems are described, concerning types of messages, importance of messages and filtering and storing of messages. It further describes possibilities of application logging based on Java in the specific case of the Log 4 jutility. In the second part thesis describes own log message systems design and implementation...|$|E
40|$|This paper {{illustrates}} how software fault-tolerant distributed applications are implemented within LiPS version 2. 4, {{a system for}} distributed computing using idle-cycles in networks of workstation. The LiPS system [SR 92,SR 93,STea 94,Set 95,SF 96,ST 96,SL 97,ST 97] employs the tuple space programming paradigm, as originally used in the Linda 1 programming language. Applications implemented using this paradigm easily adapt to changes in availability as they occur in workstation networks. In LiPS, applications are enabled to terminate successfully in spite of failing nodes by periodically writing checkpoints, freezing the state of a computational process, and keeping track of messages exchanged between checkpoints in a <b>message</b> <b>log.</b> The <b>message</b> <b>log</b> is kept within the tuple space machine implementing the tuple space and replayed if an application process recovers. This assumes deterministic behavior of the application process but allows independent checkpoint generation and alleviates the need [...] ...|$|E
30|$|In {{configuration}} C 1 {{a particular}} node (Node 1, Figure  5) in the WSN is {{selected as the}} broadcast-originator whose sole responsibility is to broadcast a message every 10 seconds. This node does not attempt to receive or retransmit any messages. The periodic interval of 10 seconds ensures that broadcasts between different experiment runs do not overlap and interfere with each other. Each broadcast message contains a unique identifier (uid) in its header {{that is used by}} a receiving node to differentiate between multiple messages. This identifier is part of the soft state saved in each node’s <b>message</b> <b>log</b> to detect duplicate messages (line 5 of Algorithm 1). Also included in the <b>message</b> <b>log</b> is the RSSI of each message, obtained through a query to the radio module of the TelosB motes for the received message’s network parameters. Only the RSSI value of the first arriving message is recorded and used as a threshold for the retransmission-based protocols.|$|E
40|$|This paper {{presents}} {{the influence of}} the fault tolerance configuration on different applications using performance metrics. Two configuration parameters are analysed: the heartbeat/watchdog interval and the checkpoint interval. In addition, even <b>message</b> <b>logging</b> is mandatory, an analysis of its overhead on different applications is presented. The impact of <b>message</b> <b>logging</b> on applications has been analysed according {{to the nature of the}} communication primitives used on the application. This analysis shows why for different applications the <b>message</b> <b>logging</b> introduces different overhead. Presentado en el IX Workshop Procesamiento Distribuido y Paralelo (WPDP...|$|R
40|$|Over {{the past}} decade the number of {{processors}} in the high performance facilities went up to hundreds of thousands. As a direct consequence, while the computational power follow the trend, the {{mean time between failures}} (MTBF) suffered, and it’s now being counted in hours. In order to circumvent this limitation, a number of fault tolerant algorithms as well as execution environments have been developed using the message passing paradigm. Among them, <b>message</b> <b>logging</b> has been proved to achieve a better overall performance when the MTBF is low, mainly due to it’s faster failure recovery. However, <b>message</b> <b>logging</b> suffers from a high overhead when no failure occurs. Therefore, in this paper we discuss a refinement of the <b>message</b> <b>logging</b> model intended to improve failure free <b>message</b> <b>logging</b> performance. The proposed approach simultaneously removes useless memory copies and reduces the number of logged events. We present the implementation of a pessimistic <b>message</b> <b>logging</b> protocol in Open MPI and compare it with the previous reference implementation MPICH-V 2. Results outline a several order of magnitude improvement on performance and a zero overhead for most messages. ...|$|R
40|$|<b>Message</b> <b>logging</b> {{protocols}} are {{an integral}} part of a technique for implementing processes that can recover from crash failures. All <b>message</b> <b>logging</b> protocols require that the state of a recovered process be consistent with the states of the other processes. This consistency requirement is usually expressed in terms of orphan processes, surviving processes whose states are inconsistent with the recovered state of a crashed process. Orphans are either avoided through careful logging or are eliminated through a somewhat complex recovery protocol. We give a specification of the consistency property "no orphan processes". From this specification, we describe how different existing classes of <b>message</b> <b>logging</b> protocols (namely optimistic, pessimistic, and a class that we call causal) implement this property. We then propose a set of metrics to evaluate the performance of <b>message</b> <b>logging</b> protocols, and characterize the protocols that are optimal with respect to these metrics. We give several examples of optimal <b>message</b> <b>logging</b> protocols that can tolerate f overlapping failures and recoveries for a parameter f: 1 < f < n, and discuss the tradeoffs that arise in the implementation of these protocols...|$|R
40|$|Abstract This paper {{illustrates}} how software fault-tolerant distributed applica-tions are implemented within LiPS version 2. 4, {{a system for}} distributed computing using idle-cycles in networks of workstation. The LiPS system [SR 92,SR 93,STea 94,Set 95,SF 96,ST 96,SL 97,ST 97] employs the tu-ple space programming paradigm, as originally used in the Linda 1 programming language. Applications implemented using this paradigm easily adapt to changes in availability as they occur in workstation networks. In LiPS, applications are enabled to terminate successfully in spite of failing nodes by periodically writing checkpoints, freezing the state of a computational process, and keeping track of messages exchanged between checkpoints in a <b>message</b> <b>log.</b> The <b>message</b> <b>log</b> is kept within the tuple space machine implementing the tuple space and replayed if an application process recovers. This assumes deterministic behavior of the application process but allows independent checkpoint generation and alleviates the need for application-wide synchronization in order to generate sets of consistent checkpoints. ...|$|E
40|$|International audienceGrid {{computing}} mutualizes more {{computing resources}} {{working in a}} calculation or a common task. The {{increase in the number}} of components in the system leads also increases the number of fault. These failures result in a loss of several cycles of running applications. It is therefore essential to be able to tolerate faults so that the computation can continue to execute and finish despite failures, all while maintaining maximum performance. One advantage of coordinated checkpoint is its capacity to have a very low overhead as long as the execution stays fault free. On the contrary, due to the fact that uncoordinated checkpoint requires being complemented by a <b>message</b> <b>log</b> protocol, this adds a significant penalty for all message transfers, even in case of fault-free execution. With <b>message</b> <b>log,</b> these problems do not arise simply because it processes checkpoint and restart autonomously. These differences suggest that the best approach depend on the fault frequency. In this paper, we propose a hierarchical composition of algorithms: Chandy-Lamport protocol and pessimistic message logging protocol. We have implemented and compared the performance of these protocols in grid computing using the Omnet++ simulator [3]...|$|E
40|$|Independent (uncoordinated) check {{pointing}} for parallel {{and distributed}} systems allows maximum process autonomy but suffers from possible domino effects {{and the associated}} storage space overhead for maintaining multiple checkpoints and message logs. In most research on check pointing and recovery, {{it was assumed that}} only the checkpoints and message logs older than the global recovery line can be discarded. It is shown how recovery line transformation and decomposition {{can be applied to the}} problem of efficiently identifying all discardable message logs, thereby achieving optimal garbage collection. Communication trace-driven simulation for several parallel programs is used to show the benefits of the proposed algorithm for <b>message</b> <b>log</b> reclamation...|$|E
40|$|<b>Message</b> <b>logging</b> {{protocols}} {{ensure that}} crashed processes {{make the same}} choices when re-executing nondeterministic events during recovery. Causal <b>message</b> <b>logging</b> protocols achieve this by piggybacking {{the results of these}} choices (called determinants) on the ambient message traffic. By doing so, these protocols do not create orphan processes nor introduce blocking in failure-free executions. To survive f failures, they ensure that determinants are stored by at least f + 1 processes. Causal logging protocols differ in the kind of information they piggyback to other processes. The more information they send, the better each process is able to estimate global properties of the determinants, which in turn results in fewer needless piggybacking of determinants. This paper attempts to quantify the tradeoff between the cost of sending more information and the benefit of doing so. Keywords: Fault-tolerance, <b>Message</b> <b>logging,</b> Causal logging, Rollback recovery 1. Introduction <b>Message</b> <b>logging</b> prot [...] ...|$|R
40|$|Causal <b>message</b> <b>logging</b> spread {{recovery}} information around the network {{in which the}} processes execute. This is an attractive property for wide area networks: {{it can be used}} to replicate processes that are otherwise inaccessible due to network partitions. However, current causal <b>message</b> <b>logging</b> protocols do not scale to thousands of processes...|$|R
40|$|This paper {{presents}} an analytical model using stochastic Petri nets {{for the performance}} of a priority based real-time protocol that uses data-link layer <b>message</b> <b>logging</b> for fast recovery in the event of station crashes. The advantage of using <b>message</b> <b>logging</b> at the data-link layer over traditional higher layer recovery mechanisms is demonstrated...|$|R
