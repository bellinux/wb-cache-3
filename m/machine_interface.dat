847|612|Public
25|$|The {{technology}} {{falls under}} the umbrella of BCIs (Brain Computer Interface) and also referred to as MMI (Mind <b>Machine</b> <b>Interface),</b> DNI (Direct Neural Interface), BMI (Brain <b>Machine</b> <b>Interface)</b> and aims to track cognitive performance, monitor emotions, and control both virtual and physical objects via machine learning of trained mental commands.|$|E
25|$|LZB is {{deprecated}} and to {{be replaced}} with European Train Control System (ETCS). It is referenced by European Union Agency for Railways (ERA) as a Class B train protection system in National Train Control (NTC). Driving cars mostly have to replace classical control logic to ETCS Onboard Units (OBU) with common Driver <b>Machine</b> <b>Interface</b> (DMI). Because high performance trains are often not scrapped ore reused on second order lines, special Specific Transmission Modules (STM) for LZB were developed for further support of LZB installation.|$|E
500|$|The upgrade {{programme}} {{resulted in}} the Sea King AEW fleet being upgraded with a new mission system, Comms, NavAids, JTIDS, Active Noise Reduction and Videographic recording. [...] The Mission System Upgrade (MSU) component (Radar and partial JTIDS integration) was based around the improved Searchwater 2000AEW radar, with an all-new man <b>Machine</b> <b>Interface.</b> [...] This MSU component was later termed [...] "Project Cerberus" [...] by Thales, after successful integration was conducted by Westland and GEC-Marconi. This variant was initially {{referred to as the}} Sea King AEW7, but renamed ASaC7 just before In Service Date. [...] (Airborne Surveillance and Control Mk.7). The main role of the Sea King ASaC7 is detection of low-flying attack aircraft; it also provides interception/attack control and over-the-horizon targeting for surface-launched weapon systems. In comparison to older versions, the new radar enables the ASaC7 to simultaneously track up to 400 targets, instead of an earlier limit of 250 targets. The effectiveness of the AEW7 was greatly increased via the addition of a Link 16 data link, allowing gathered radar information to be analysed and rapidly put to use by multiple allied platforms in range.|$|E
5000|$|In 2014, EBV {{announced}} JAKARTA: {{a hardware}} and software application Java platform ready for new areas of low cost Human <b>Machine</b> <b>Interfaces</b> based on FREESCALE KINETIS-L.|$|R
5000|$|GL Studio SC (Safety Critical): {{the tool}} for safety {{critical}} {{systems and the}} recognized industry standard for the rapid prototyping of safety critical Human <b>Machine</b> <b>Interfaces</b> (HMI).|$|R
40|$|This {{paper is}} {{a survey of}} changes to virtual <b>machine</b> <b>interfaces,</b> implementation, architecture, and {{simulation}} techniques as they affect IBM System 1370 and 303 X (3031, 3032, 3033) processors, the system control program to which virtual <b>machines</b> <b>interface,</b> and other virtual machines executing on the same real computing system or elsewhere. The paper seeks to summarize such changes and provide a perspective on the virtual machine environment. New uses of virtual machine subsystems are discussed {{as they relate to}} inter-virtual-machine communication. The changing virtual <b>machine</b> environment: <b>Interfaces</b> to real hardware, virtual hardware, and other virtual machines by R. A. MacKinnon When IBM introduced virtual machine products with CP- 67 on the System/ 360 Model 67, an early view of the uniqueness of virtual machines focused on the isolation of one virtual machine fro...|$|R
2500|$|... 2010 {{marks the}} year Honda has {{developed}} a machine capable of reading a user's brainwaves to move ASIMO. The system uses a helmet covered with electroencephalography and near-infrared spectroscopy sensors that monitor electrical brainwaves and cerebral blood flow—signals that alter slightly during the human thought process. The user thinks of one of {{a limited number of}} gestures it wants from the robot, which has been fitted with a Brain <b>Machine</b> <b>Interface.</b>|$|E
2500|$|In July 2017 Elon Musk {{founded the}} company Neuralink, {{which aims to}} create a Neural Lace, which is a concept invented by the novelist Iain M. Banks and {{basically}} refers to an <b>machine</b> <b>interface</b> woven into the brain, to allow the user to access all available human information. A core driver behind this business idea is Mr Musk’s argument, that human beings soon have to embrace brain implants to stay relevant in a world which, he believes, will soon be dominated by artificial intelligence. [...] The firm raised $27m from 12 Investors in 2017 [...]|$|E
5000|$|Universal Computer Protocol/External <b>Machine</b> <b>Interface</b> (UCP/EMI) ...|$|E
5000|$|Ethernet: Every Sercos {{device is}} a three-port switch and {{completely}} transparent for connected Standard Ethernet devices as Engineering systems, Human <b>machine</b> <b>interfaces</b> etc.. First of all a Sercos device is an Ethernet device.|$|R
50|$|Jose C. Principe is an American bioengineer, {{focusing}} in adaptive signal processing, kernel learning, information theoretic learning, neural networks, brain <b>machine</b> <b>interfaces</b> {{and cognitive}} architectures, currently Distinguished Professor of Electrical and Biomedical Engineering and BellSouth Professor at University of Florida.|$|R
40|$|The {{standard}} {{development of}} human <b>machine</b> <b>interfaces</b> needs {{the respect of}} ergonomic norms and rigorous approaches, which constitutes a major concern for computer system designers. The increased need on easily accessible and usable interfaces leads researchers in this domain to create methods and models that {{make it possible to}} evaluate these interfaces in terms of utility and usability. This paper presents a study about the simulation of a human machine interaction with an interface of a contextual assistant, using the cognitive architecture ACT-Remphasizingonthetimeexecutionoftasks. The results of our model were consistent with those obtained by the Fitts Law model which is a powerful analytical method for evaluating human <b>machine</b> <b>interfaces,</b> developed in this study mainly to support our results...|$|R
5000|$|Human <b>machine</b> <b>interface</b> (HMI) (operating devices, visualisation) ...|$|E
5000|$|... 2013 Amsterdam, [...] "Human <b>Machine</b> <b>Interface</b> and Flight Deck Design" ...|$|E
5000|$|ANSYS SCADE Display - Embedded {{software}} design for Human <b>Machine</b> <b>Interface</b> ...|$|E
40|$|Social robotics, brain <b>machine</b> <b>interfaces</b> and neuro and {{cognitive}} enhancement products are three emerging {{science and technology}} products with wide-reaching impact for disabled and non-disabled people. Acceptance of ideas and products depend on multiple parameters and many models {{have been developed to}} predict product acceptance. We investigated which frequently employed technology acceptance models (consumer theory, innovation diffusion model, theory of reasoned action, theory of planned behaviour, social cognitive theory, self-determination theory, technology of acceptance model, Unified Theory of Acceptance and Use of Technology UTAUT and UTAUT 2) are employed in the social robotics, brain <b>machine</b> <b>interfaces</b> and neuro {{and cognitive}} enhancement product literature and which of the core measures used in the technology acceptance models are implicit or explicit engaged with in the literature...|$|R
50|$|The IESR aims {{to provide}} a “Yellow Pages for the {{academic}} internet” accessible through web and <b>machine</b> <b>interfaces.</b> It provides a reliable source of information that other applications, such as portals, can freely access through machine-to-machine protocols, {{in order to help}} their end users discover resources of assistance to them.|$|R
5000|$|... #Caption: Time <b>Machine's</b> Retrieval <b>Interface</b> on OS X 10.10 Yosemite ...|$|R
5000|$|... #Caption: Fig. 4: Human <b>Machine</b> <b>Interface</b> (HMI) of care-providing robot FRIEND.|$|E
5000|$|Human <b>machine</b> <b>{{interface}}</b> with Vector Graphics, and Tilcon {{user interface}} (UI) ...|$|E
5000|$|Human <b>Machine</b> <b>Interface</b> (HMI) - Interface {{concepts}} for driver assistance, infotainment systems ...|$|E
40|$|Point process {{modeling}} {{has the potential}} to capture the specificity of neural firing where the information is contained in the spike time occurrence. We aim at building an adaptive signal processing framework for Brain <b>Machine</b> <b>Interfaces</b> working directly in the spike domain. However, the signal processing tools for continuous stochastic processes faces challenge when implemented directly on point processes. Under the Bayesian formulation, the effectivene ss of the decoding algorithm and the accuracy of the encoding model will affect each other recursively on kinematics recon struction. The finer time resolution of point process ra ises a higher computational complexity. This paper will review our recent work addressing these concerns. We implemented an instantaneous tuning model into a sequential Monte Carlo point process estimation to better reconstruct kinematics from neural spike trains for Brain <b>Machine</b> <b>Interfaces.</b> © 2009 ACA...|$|R
40|$|This paper {{reports on}} a first step towards the {{implementation}} of a framework for remote experimentation of electric machines ? the RemoteLabs platform. This project was focused on the development of two main modules: the user Web-based and the electric <b>machines</b> <b>interfaces.</b> The Web application provides the user with a front-end and interacts with the back-end ? the user and experiment persistent data. The electric <b>machines</b> <b>interface</b> is implemented as a distributed client server application where the clients, launched by the Web application, interact with the server modules located in platforms physically connected the electric machines drives. Users can register and authenticate, schedule, specify and run experiments and obtain results in the form of CSV, XML and PDF files. These functionalities were successfully tested with real data, but still without including the electric machines. This inclusion is part of another project scheduled to start soon...|$|R
50|$|JVMTI {{was defined}} through the Java Community Process by JSR-163, the {{specification}} for the Java Platform Profiling Architecture. The JVMTI replaces the JVMPI (Java Virtual <b>Machine</b> Profiling <b>Interface)</b> and the JVMDI (Java Virtual <b>Machine</b> Debug <b>Interface).</b> The JVMPI and the JVMDI are declared as being deprecated in J2SE 5.0 and were removed in Java SE6.|$|R
5000|$|... #Caption: Invention of the Brain <b>Machine</b> <b>Interface,</b> Reswick et al. - mid 1960s ...|$|E
5000|$|Software is {{designed}} for human <b>machine</b> <b>interface,</b> ease of maintenance and modification or enhancement ...|$|E
50|$|Astronauts {{can control}} the robot from {{both inside and outside}} the space station. Control from inside the space station (Intra Vehicular Activity-Man <b>Machine</b> <b>Interface</b> (IVA-MMI)) uses a laptop, which shows a model of the ERA and its surroundings. Control from outside the space station (Extra Vehicular Activity-Man <b>Machine</b> <b>Interface</b> (EVA-MMI)) uses a specially-designed {{interface}} that can be used while in a spacesuit.|$|E
30|$|General {{term that}} {{encompasses}} well-defined types of field devices, such as: (1) master terminal units (MTUs) and Human <b>Machine</b> <b>Interfaces</b> (HMIs), {{located at the}} topmost layer and managing all communications; (2) remote terminal units (RTUs), and programmable logic controllers (PLCs), controlling and acquiring data from remote equipment and connecting with the master stations; (3) sensors and actuators.|$|R
50|$|The RX {{family was}} {{launched}} in 2009 by Renesas Technology with the first product range designated the RX600 series and targeting applications such as metering, motor control, human <b>machine</b> <b>interfaces</b> (HMI), networking, and industrial automation. Since 2009 this MCU family range has been enlarged with a smaller variant the RX200 series and also through enhanced performance versions.|$|R
40|$|We are {{creating}} human <b>machine</b> <b>interfaces</b> which let people communicate with machines using natural modalities including speech and gesture. A problem with current multimodal interfaces is that users {{are forced to}} learn the set of words and gestures whichtheinterface understands. We report on a trainable interface which lets the user teachthe system words of their choice through natural multimodal interactions...|$|R
5000|$|... (2007) Researchers {{from the}} ACT {{test for the}} first time a brain <b>machine</b> <b>interface</b> in micro-gravity.|$|E
5000|$|Embedded HMI: Uses GL Studio {{to develop}} and deploy {{embedded}} and safety critical Human <b>Machine</b> <b>Interface</b> displays ...|$|E
50|$|Human - <b>machine</b> <b>interface</b> {{model has}} been prepared. New {{approach}} for analyzing and processing large scale information has been proposed.|$|E
40|$|The ROboMObil is DLR’s space-robotics driven by-wire electro-mobile {{research}} {{platform for}} mechatronic actuators, vehicle dynamics control, human <b>machine</b> <b>interfaces,</b> and autonomous driving (DLR = German Aerospace Center). Due to its four highly integrated identical Wheel Robots it exhibits an extraordinary manoeuvrability even allowing for driving sideward or rotating on the spot. Topics related to vehicle dynamics control are {{addressed in this}} article...|$|R
40|$|Many human [...] <b>machine</b> <b>interfaces</b> {{based on}} face {{gestures}} are strongly user-dependent. We want {{to overcome this}} limitation by using common facial features like eyes, nose and mouth for gaze recognition. In a first step an adaptive color histogram segmentation method roughly determines the region of interest including the user's face. Within this region we then use a hierarchical recognition approach to detect the facial features. Our system {{is based on a}} what [...] where neural network architecture and allows a fast and robust recognition rate. In the future we intend to use the conspicuous features for estimation of gaze directions. 1 Introduction Evaluation of head and eye actions can significantly contribute to the realization of more powerful and easier to use man [...] <b>machine</b> <b>interfaces.</b> Imagine the advantages if you can watch an object from another perspective only by changing your viewing position in front of the monitor. However, existing eye tracking hardware is unpleasant to wear and v [...] ...|$|R
40|$|Summary. This work {{presents}} a virtual platform {{created for the}} SILO 6, a sixlegged walking robot focused on the localization of antipersonnel landmines. The virtual platform is a Java-based module which includes the new concepts about human - <b>machine</b> <b>interfaces</b> design, and it’s main purpose is to satisfy three basic requirements: the robot’s state monitoring, the robot’s task definition and monitoring and the robot teleoperation. Peer reviewe...|$|R
