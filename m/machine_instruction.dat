159|723|Public
25|$|That such minimalism is {{possible}} {{does not mean}} that it is necessarily desirable; after all, computers theoretically need only one <b>machine</b> <b>instruction</b> (subtract one number from another and branch if the result is negative), but practical computers have dozens or even hundreds of machine instructions.|$|E
25|$|Assembly {{language}} uses a mnemonic {{to represent}} each low-level <b>machine</b> <b>instruction</b> or opcode, typically also each architectural register, flag, etc. Many operations require {{one or more}} operands in order to form a complete instruction and most assemblers can take expressions of numbers and named constants as well as registers and labels as operands, freeing the programmer from tedious repetitive calculations. Depending on the architecture, these elements may also be combined for specific instructions or addressing modes using offsets or other data as well as fixed addresses. Many assemblers offer additional mechanisms to facilitate program development, to control the assembly process, and to aid debugging.|$|E
500|$|On March 9, 2015, Google's Project Zero {{revealed}} two working privilege escalation exploits {{based on}} the row hammer effect, establishing its exploitable nature on the x86-64 architecture. [...] One of the revealed exploits targets the Google Native Client (NaCl) mechanism for running a limited subset of x86-64 machine instructions within a sandbox, exploiting the row hammer effect {{to escape from the}} sandbox and gain the ability to issue system calls directly. [...] This NaCl vulnerability, tracked as CVE-2015-0565, has been mitigated by modifying the NaCl so it does not allow execution of the clflush (cache line flush) <b>machine</b> <b>instruction,</b> which was previously believed to be required for constructing an effective row hammer attack.|$|E
5000|$|LOADALL, undocumented <b>machine</b> <b>instructions</b> purportedly used by Microsoft's RAMDRIVE.SYS ...|$|R
5000|$|... efficiency: a {{statistically}} dominant fraction of <b>machine</b> <b>instructions</b> must be executed without VMM intervention ...|$|R
5000|$|TXT records {{contain the}} <b>machine</b> <b>instructions</b> or data which {{is held by}} the module.|$|R
500|$|The second exploit {{revealed}} by Project Zero runs as an unprivileged Linux process on the x86-64 architecture, exploiting the row hammer effect to gain unrestricted {{access to all}} physical memory installed in a computer. [...] By combining the disturbance errors with memory spraying, this exploit is capable of altering page table entries (PTEs) used by the virtual memory system for mapping virtual addresses to physical addresses, which results in the exploit gaining unrestricted memory access. [...] Due to its nature and {{the inability of the}} x86-64 architecture to make clflush a privileged <b>machine</b> <b>instruction,</b> this exploit can hardly be mitigated on computers that do not use hardware with built-in row hammer prevention mechanisms. [...] While testing the viability of exploits, Project Zero found that about half of the 29 tested laptops experienced disturbance errors, with some of them occurring on vulnerable laptops in less than five minutes of running row-hammer-inducing code; the tested laptops were manufactured between 2010 and 2014 and used non-ECC DDR3 memory.|$|E
2500|$|Example: INC ( [...] rbase, index [...] ) {{effective}} address will be [...] + index, where the natural number [...] "index" [...] {{is derived from}} the finite-state <b>machine</b> <b>instruction</b> itself.|$|E
2500|$|Configuration space accesses {{often have}} a few cycles of delay {{in order to allow}} the IDSEL lines to stabilize, which makes them slower than other forms of access. [...] Also, a {{configuration}} space access requires a multi-step operation rather than a single <b>machine</b> <b>instruction.</b> [...] Thus, it is best to avoid them during routine operation of a PCI device.|$|E
40|$|Basic {{building}} blocks of the computer: logic gates, memory cells, wires. • Units built from these (like register units, control unit). • Other Hardware components (monitors, hard disks • Representation and manipulation of data. • <b>Machine</b> <b>instructions</b> and assembly languages. • Translation of high level languages into <b>machine</b> <b>instructions.</b> • High performance architectures like super scalar/pipelined architectures and instruction level parallelism...|$|R
5000|$|Efficiency / Performance: A {{statistically}} dominant {{fraction of}} <b>machine</b> <b>instructions</b> must be executed without VMM intervention.|$|R
5000|$|On {{a system}} that uses {{conditional}} branching, this might translate to <b>machine</b> <b>instructions</b> looking similar to: ...|$|R
2500|$|Each channel may {{support one}} or more {{controllers}} and/or devices, but each channel program may only be directed {{at one of those}} connected devices. [...] A channel program contain lists of commands to the channel itself and to the controller and device to which it is directed. [...] Once the operating system has prepared a complete list of channel commands, it executes a single I/O <b>machine</b> <b>instruction</b> to initiate the channel program; the channel thereafter assumes control of the I/O operations until they are completed.|$|E
2500|$|Computer {{systems that}} use channel I/O have special {{hardware}} components that handle all input/output operations {{in their entirety}} independently of the systems' CPU(s). [...] The CPU {{of a system that}} uses channel I/O typically has only one <b>machine</b> <b>instruction</b> in its repertoire for input and output; this instruction is used to pass input/output commands to the specialized I/O hardware in the form of channel programs. I/O thereafter proceeds without intervention from the CPU until an event requiring notification of the operating system occurs, at which point the I/O hardware signals an interrupt to the CPU.|$|E
2500|$|One {{feature that}} {{has contributed to}} the {{longevity}} of the IBM System i platform is its high-level instruction set (called TIMI for [...] "Technology Independent Machine Interface" [...] by IBM), which allows application programs to take advantage of advances in hardware and software without recompilation. TIMI is a virtual instruction set independent of the underlying <b>machine</b> <b>instruction</b> set of the CPU. User-mode programs contain both TIMI instructions and the machine instructions of the CPU, thus ensuring hardware independence. This is conceptually somewhat similar to the virtual machine architecture of programming environments such as Smalltalk, Java and [...]NET. The key difference is that it is embedded so deeply into the AS/400's design as to make applications effectively binary-compatible across different processor families.|$|E
50|$|Since there is, typically, a {{one-to-one}} {{relationship between}} assembly <b>instructions</b> and <b>machine</b> <b>instructions,</b> the instruction path length is frequently taken {{as the number}} of assembly instructions required to perform a function or particular section of code. Performing a simple table lookup on an unsorted list of 1,000 entries might require perhaps 2,000 <b>machine</b> <b>instructions</b> (on average, assuming uniform distribution of input values), while performing the same lookup on a sorted list using a binary search algorithm might require only about 40 <b>machine</b> <b>instructions,</b> a very considerable saving. Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 - a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length.|$|R
5000|$|... #Caption: A {{high-level}} illustration {{showing the}} decomposition of <b>machine</b> <b>instructions</b> into micro-operations, performed during typical fetch-decode-execute cycles.|$|R
40|$|Prolog {{has been}} widely {{recognized}} as a powerful programming language for artificial intelligence. It was also chosen as a kernel language for the Japanese Fifth Generation Project. The project is a large scale effort to initiate {{a new generation of}} computing. Due to the wide range of applications that Prolog has, many methods have been developed for extracting parallelism from standard Prolog in order to achieve faster execution on a multiprocessor. This project designs an execution model for Prolog, which attempts to exploit the parallelism mainly at the argument level through the unification operation. The model consisting of a number of virtual <b>machine</b> <b>instructions,</b> has been implemented in Occam 2 on a Transputer Development System. A few Prolog procedures have been hand compiled to the virtual <b>machine</b> <b>instructions,</b> and have been run on a Transputer Development System with a single transputer. This model of virtual <b>machine</b> <b>instructions</b> can be applied to a multiple transputer system. This project gives the details of the implementation of the virtual <b>machine</b> <b>instructions...</b>|$|R
2500|$|A NOP-sled is {{the oldest}} and most widely known {{technique}} for successfully exploiting a stack buffer overflow. It solves the problem of finding the exact address of the buffer by effectively increasing the size of the target area. To do this, much larger sections of the stack are corrupted with the no-op <b>machine</b> <b>instruction.</b> At the end of the attacker-supplied data, after the no-op instructions, the attacker places an instruction to perform a relative jump {{to the top of the}} buffer where the shellcode is located. This collection of no-ops is referred to as the [...] "NOP-sled" [...] because if the return address is overwritten with any address within the no-op region of the buffer, the execution will [...] "slide" [...] down the no-ops until it is redirected to the actual malicious code by the jump at the end. This technique requires the attacker to guess where on the stack the NOP-sled is instead of the comparatively small shellcode.|$|E
5000|$|In the {{top most}} {{simulation}} level the microcode simulator continuously executes micro instructions without interrupt. In this level, <b>machine</b> <b>instruction</b> by <b>machine</b> <b>instruction</b> is loaded. So, {{it is possible}} to focus on the interaction of the CPU with external devices.|$|E
5000|$|... #Subtitle level 3: Advantages of stack <b>machine</b> <b>instruction</b> sets ...|$|E
5000|$|Run-time control ... With all implementations, debug tools {{can start}} and stop the processor, modify registers, and single-step <b>machine</b> <b>instructions.</b>|$|R
5000|$|... {{simulating}} a few <b>machine</b> <b>instructions</b> {{that are}} present on some, but not all, {{models of the}} S/360 or S/370 computers, ...|$|R
50|$|From {{either of}} two 3-instruction base sets {{all the other}} counter <b>machine</b> <b>instructions</b> can be derived. Both have {{advantages}} and disadvantages.|$|R
5000|$|... #Subtitle level 2: Analogy to {{bytecode}} / virtual <b>machine</b> <b>instruction</b> set ...|$|E
5000|$|The NAR 2 {{processor}} uses 32-bit machine words. Each <b>Machine</b> <b>instruction</b> contains: ...|$|E
5000|$|Uses a non-virtualized, model-dependent <b>machine</b> <b>instruction</b> as {{a signal}} between CMS and CP: DIAG ("diagnose").|$|E
50|$|In 1936 Konrad Zuse {{anticipated}} in two patent {{applications that}} <b>machine</b> <b>instructions</b> could {{be stored in}} the same storage used for data.|$|R
50|$|Microcode {{typically}} {{resides in}} special high-speed memory and translates <b>machine</b> <b>instructions,</b> state <b>machine</b> data or other input into sequences of detailed circuit-level operations. It separates the <b>machine</b> <b>instructions</b> from the underlying electronics so that instructions {{can be designed}} and altered more freely. It also facilitates the building of complex multi-step instructions, while reducing the complexity of computer circuits. Writing microcode is often called microprogramming and the microcode in a particular processor implementation is sometimes called a microprogram.|$|R
50|$|In 1936, Konrad Zuse also {{anticipated}} in two patent {{applications that}} <b>machine</b> <b>instructions</b> could {{be stored in}} the same storage used for data.|$|R
50|$|In modern CPUs this is {{accomplished}} on the processor itself, in a single <b>machine</b> <b>instruction,</b> {{rather than having to}} go through RAM.|$|E
5000|$|Jasmin, takes text {{descriptions}} for Java classes, {{written in}} a simple assembly-like syntax using Java virtual <b>machine</b> <b>instruction</b> set and generates a Java class file ...|$|E
50|$|Cray {{supercomputers}} {{early on}} featured a population count <b>machine</b> <b>instruction,</b> rumoured {{to have been}} specifically requested by the U.S. government National Security Agency for cryptanalysis applications.|$|E
5000|$|User-accessible {{registers}} {{can be read}} {{or written}} by <b>machine</b> <b>instructions.</b> The most common division of user-accessible registers is into data registers and address registers.|$|R
40|$|We {{show how}} to {{generate}} {{the back end of}} an optimizing compiler from a formal description of the syntax and semantics of <b>machine</b> <b>instructions.</b> Our generated back ends for x 86, ARM, and PowerPC perform as well as their hand-written counterparts. Automatic generation is enabled by two new ideas: a model of machine-level computation that reduces back-end generation to the problem of finding implementations of about a hundred simple, machine-level operations; and an algorithm that finds these implementations by combining <b>machine</b> <b>instructions.</b> 1...|$|R
50|$|In 1991, the crashme tool was released, {{which was}} {{intended}} to test the robustness of Unix and Unix-like operating systems by executing random <b>machine</b> <b>instructions.</b>|$|R
