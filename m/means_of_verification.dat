75|10000|Public
2500|$|Galenism's final defeat {{came from}} a {{combination}} of the negativism of Paracelsus and the constructivism of the Italian Renaissance anatomists, such as Vesalius in the 16th century. In the 1530s, the Flemish anatomist and physician Andreas Vesalius took on a project to translate many of Galen's Greek texts into Latin. Vesalius' most famous work, De humani corporis fabrica, was greatly influenced by Galenic writing and form. Seeking to examine critically Galen's methods and outlook, Vesalius turned to human cadaver dissection as a <b>means</b> <b>of</b> <b>verification.</b> Galen's writings were shown by Vesalius to describe details present in monkeys but not in humans, and he demonstrated Galen's limitations through books and hands-on demonstrations despite fierce opposition from orthodox pro-Galenists such as Jacobus Sylvius. Since Galen states that he is using observations of monkeys (human dissection was prohibited) to give an account of what the body looks like, Vesalius could portray himself as using Galen's approach of description of direct observation to create a record of the exact details of the human body, since he worked in a time when human dissection was allowed. Galen argued that monkey anatomy was close enough to humans for physicians to learn anatomy with monkey dissections and then make observations of similar structures in the wounds of their patients, rather than trying to learn anatomy only from wounds in human patients, as would be done by students trained in the Empiricist model. The examinations of Vesalius also disproved medical theories of Aristotle and Mondino de Liuzzi. One of the best known examples of Vesalius' overturning of Galenism was his demonstration that the interventricular septum of the heart was not permeable, as Galen had taught (Nat Fac III xv). However, this had been revealed two years before by Michael Servetus in his fateful [...] "Christianismi restitutio" [...] (1553) with only three copies of the book surviving, but these remaining hidden for decades; the rest were burned shortly after its publication because of persecution of Servetus by religious authorities.|$|E
60|$|But German {{economists are}} of interest, inasmuch {{as they have}} {{established}} a new school who urge {{the use of the}} historical method in political economy, and it is about the question of method that much of the interest of to-day centers. In 1814 Savigny introduced this method into jurisprudence, and about 1850 it was applied to political economy. The new school claim that the English “orthodox” writers begin by an a priori process, and by deductions reach conclusions which are possibly true of imaginary cases, but are not true of man as he really acts. They therefore assert that economic laws can only be truly discovered by induction, or a study of phenomena first, as the means of reaching a generalization. To them Bagehot(80) answers that scientific bookkeeping, or collections of facts, in themselves give no results ending in scientific laws; for instance, since the facts of banking change and vary every day, no one can by induction alone reach any laws of banking; or, for example, the study of a panic from the concrete phenomena would be like trying to explain the bursting of a boiler without a theory of steam. More lately,(81) since it seems that the new school claim that induction does not preclude deduction, and as the old school never intended to disconnect themselves from “comparing conclusions with external facts,” there is not such a cause of difference as has previously appeared. Doubtless the insistence upon the merits of induction will be fruitful of good to “orthodox” writers, in the more general resort to the collection of statistics and <b>means</b> <b>of</b> <b>verification.</b> It is suggestive also that the leaders of the new school in Germany and England have reached no different results by their new method, and in the main agree with the laws evolved by the old English school. The economist does not pretend that his assumptions are descriptions of economic conditions existing at a given time; he simply considers them as forces (often acting many on one point or occasion) to be inquired into separately, inasmuch as concrete phenomena are the resultants of several forces, not to be known until we know the separate operation of each of the conjoined forces.|$|E
50|$|Ayer also {{distinguishes between}} {{practical}} and theoretical verifiability. Propositions {{for which we}} do not have a practical <b>means</b> <b>of</b> <b>verification</b> may still be meaningful if we can verify them in principle.|$|E
5000|$|Historical {{researcher}} Ian Wilson {{has criticized}} the reincarnation claims of Guirdham noting [...] "serious errors and inconsistencies" [...] {{in his book}} The Cathars and Reincarnation. Wilson wrote that [...] "Guirdham's claims lacking any <b>means</b> <b>of</b> independent <b>verification,</b> must be regarded as unacceptable." ...|$|R
50|$|FISINT (Foreign {{instrumentation}} signals intelligence) is a sub-category of SIGINT, monitoring primarily non-human communication. Foreign instrumentation signals include (but {{not limited}} to) telemetry (TELINT), tracking systems, and video data links. TELINT {{is an important}} part <b>of</b> national <b>means</b> <b>of</b> technical <b>verification</b> for arms control.|$|R
40|$|ISBN: 0444893679 The {{application}} of BDD-based proof methods {{to the formal}} <b>verification</b> <b>of</b> HDL constructs is discussed. Applications include the <b>verification</b> <b>of</b> combinational circuits specified by <b>means</b> <b>of</b> vector-expressions, the <b>verification</b> <b>of</b> the logic of processors, the equivalence-roof of synchronous finite-state machines, and symbolic model-checking...|$|R
50|$|The CTBTO runs an International Monitoring System (IMS) of MASINT sensors for verification, {{which include}} seismic, acoustic, and {{radionuclide}} techniques. See National technical <b>means</b> <b>of</b> <b>verification</b> {{for a discussion}} of the controversies surrounding the ability of the IMS to detect nuclear tests.|$|E
50|$|The Weapons Intelligence, Nonproliferation, and Arms Control Center {{provides}} intelligence support {{related to}} national and non-national threats, {{as well as}} supporting threat reduction and arms control. It receives the output of national technical <b>means</b> <b>of</b> <b>verification</b> and works with the Defense Threat Reduction Agency.|$|E
5000|$|In CMMI, {{peer reviews}} {{are used as}} a {{principal}} <b>means</b> <b>of</b> <b>verification</b> in the Verification process area and as an objective evaluation method in the Process and Product Quality Assurance process area. The results of technical peer reviews can be reported at milestone reviews. (See Milestone (project management).) ...|$|E
40|$|The B {{method is}} a formal {{specification}} method and a <b>means</b> <b>of</b> formal <b>verification</b> and validation <b>of</b> safety-critical {{systems such as}} railway systems. In this short paper, we use the B 4 MSecure tool to transform the UML models, fulfilling requirements of European Railway Traffic Management System (ERTMS) operating rules, into B specifications in order to formally validate them...|$|R
40|$|Abstract: The {{need for}} an {{automatic}} verification system {{is based on the}} reality that the signature is broadly used as a <b>means</b> <b>of</b> individual <b>verification.</b> Verification can be achieved either Offline or Online. Offline systems work on the scanned picture of a signature. Online systems use active information of a signature obtained at the moment the signature is prepared. This Paper explains a method for the Offline <b>Verification</b> <b>of</b> the signatures using, a set of simple shape based on the geometric features. The features used for offlin...|$|R
40|$|AbstractThe {{effectiveness}} {{of the use of}} satellite information for the early warning of meteorological and hydrological disasters and provision of transportation safety on the Black Sea in Georgia were investigated. The research of determination of Sea Surface Temperatures by <b>means</b> <b>of</b> satellite information, <b>verification</b> <b>of</b> the obtained results based on quality control/quality assessment procedures were carried out...|$|R
50|$|Sampling {{provides}} one rational <b>means</b> <b>of</b> <b>verification</b> that {{a production}} lot conforms {{with the requirements}} of technical specifications. 100% inspection does not guarantee 100% compliance and is too time consuming and costly. Rather than evaluating all items, a specified sample is taken, inspected or tested, and a decision is made about accepting or rejecting the entire production lot.|$|E
5000|$|The columns {{represent}} {{types of}} information about the events: a Narrative description, Objectively Verifiable Indicators (OVIs) of these events taking place, <b>Means</b> <b>of</b> <b>Verification</b> (MoV) where information will be available on the OVIs, and Assumptions. Assumptions are external factors that could have an influence, whether positive or negative, on the events described in the narrative column.|$|E
50|$|It is not {{currently}} known whether modern-day Lhoba peoples in fact inhabited Luoyu {{at the time}} of Tibetan conquest, nor whether languages spoken by modern-day Lhoba peoples are indigenous to this region or not. While most Tani tribespeople living in modern-day Arunachal Pradesh point to a traditional homeland in or around this region, there is currently no independent <b>means</b> <b>of</b> <b>verification.</b>|$|E
40|$|This study aims at {{comparing}} two quantitative precipitation forecasting techniques {{based on}} the meteorological analogy concept. Method A considers first a selection of analogous situations at synoptic scale. Second {{a subset of the}} most similar situations in terms of hygrometry is extracted. Method B extends method A by two innovative ways, which are restricting the search for analogues with temperature information instead of the common season criterion, and exploiting the information about vertical motion considering vertical velocity. Forecasts are evaluated in a perfect prognosis context and in operational conditions as well, by <b>mean</b> <b>of</b> <b>verification</b> measures (Continuous Ranked Probability Skill Score and scores computed from contingency tables). Results of the case study in France show that: (1) there is an increase in forecast skill when temperature and vertical velocity are included in the procedure, (2) it is possible to anticipate rainfall events up to one week ahead and (3) the introduction of new variables such as vertical velocity may be useless beyond few days ahead if the forecast of the weather model is not reliable...|$|R
40|$|Functional {{coverage}} {{is a well}} known <b>means</b> <b>of</b> measuring <b>verification</b> progress. However, approaches to coverage, such as Coverage Driven and Coverage Oriented approaches, are often difficult or impractical to implement. This paper presents the coverage methodology used in the <b>verification</b> <b>of</b> Merom, Intel's first converged-core microprocessor. We describe practical methods and applied techniques which enabled a high return on a significantly reduced investment in coverage measurement and analysis. Given the tight schedule, this approach provided a clear metric for measuring verification progress and for effectively steering resources {{to improve the quality}} of the design under test. Categories and Subject Descriptors 5 [Verification]: Functional verification, RTL modeling and <b>verification</b> <b>of</b> hardware designs...|$|R
40|$|Abstract — Signature {{is mostly}} {{used as a}} <b>means</b> <b>of</b> {{personal}} <b>verification</b> focused {{the need for an}} automatic verification system. Verification can be categorized either Offline or Online it depends on the application which is used. Online systems uses information which are dynamic in nature information are captured at the time the signature is performed. Offline systems work on the scanned image of a signature. In this paper we present a prototype for the Offline <b>Verification</b> <b>of</b> signatures using a set of simple shape based geometric features. The features that are used in this paper are The Baseline Slant Angle Of Th...|$|R
5000|$|National {{technical}} <b>means</b> <b>of</b> <b>verification</b> are monitoring techniques, such as satellite photography, used {{to verify}} adherence to international treaties. The phrase first appeared, {{but was not}} detailed, in the Strategic Arms Limitation Treaty (SALT) between the US and USSR. At first, the phrase reflected a concern that the [...] "Soviet Union could be particularly disturbed by public recognition of this capability photography...which it has veiled.". [...] In modern usage, the term covers a variety of monitoring technologies, including others used {{at the time of}} SALT I.|$|E
50|$|Technical <b>means</b> <b>of</b> <b>verification,</b> {{including}} space-based {{sensors that}} can scan {{large parts of}} the world, can provide early warning of long-range missile development. Space-based Staring Infrared Sensors can detect the heat of rocket launching motors. Various radars can monitor range and other characteristics, but they need to be in a place where they have line-of-sight to the missile trajectory. The United States, probably Russia, and possibly other nations have aircraft-based and ship-based sensors that can monitor such tests, {{but there has to be}} warning of potential tests so these sensors can be deployed.|$|E
5000|$|TELINT {{is one of}} the [...] "national {{means of}} {{technical}} verification" [...] mentioned, but not detailed, in the [...] Strategic Arms Limitation Treaty (SALT) between the US and USSR. The [...] treaty language [...] "the agreements include provisions that are important steps to strengthen assurance against violations: both sides undertake not to interfere with national technical <b>means</b> <b>of</b> <b>verification.</b> In addition, both countries agree not to use deliberate concealment measures to impede verification." [...] refers to, in part, a technical agreement not to encrypt strategic test telemetry and thus impede verification by TELINT.|$|E
40|$|This {{thesis is}} about the concept of Sustainable Development and its {{application}} in Thailand. Whilst many people and Thai Government itself accept the need for sustainable development {{as an integral part}} of the country's future, there is no clear consensus on what the application of sustainable development will actually mean for Thailand. Up until this point in time the most common referent for sustainable development in Thailand has been the United Nations´ "Our Common Future" and "Agenda 21 ". Even though this document contains many broad principles that are applicable, there are significant differences in Thai context, which require alternatives to be proposed. Buddhism supplies a Thai point of departure for such an alternative. This thesis purposes that the principle of Buddhism such as Arriyacca, Patticca-Samuppada, Tri- Lakkha and etc. are entirely appropriate for application on the Thai socio-environment development. This discussion is a key part of this thesis. As a <b>mean</b> <b>of</b> <b>verification</b> and <b>of</b> applied example, the last section of the thesis looks specifically at growth patterns of areas and spaces in "Central Academic Area" (CAD) in the main campuses of regional public-universities of Thailand...|$|R
30|$|The {{considered}} {{analytical model}} is verified by <b>means</b> <b>of</b> simulation. This <b>verification</b> shows an excellent accordance between the analytical and the simulation {{results in a}} wide range of parameter settings. Hence, our analytical model can be applied to model and analyze the delay of the uplink nrtPS traffic in IEEE 802.16 -based network.|$|R
50|$|Particularly {{for nuclear}} weapons and {{long-range}} missiles, there is a category <b>of</b> national <b>means</b> <b>of</b> technical <b>verification</b> that uses technical sensors that are operated by organizations other than the CIA. Satellites launched and operated by the National Reconnaissance Office and whose output is evaluated by the National Geospatial-Intelligence Agency, which absorbed the former CIA Office of Imagery Analysis and the joint CIA-military National Photointerpretation Center. The CIA, however, has {{a significant role in}} HUMINT collection and in analytic disciplines that help recognize the early parts of a weapons development program.|$|R
5000|$|TELINT {{is one of}} the [...] "national {{means of}} {{technical}} verification" [...] mentioned, but not detailed, in This data can provide valuable information on the actual performance of the missile and especially its throw-weight, i.e. the potential size of its nuclear warheads. The [...] treaty language [...] "the agreements include provisions that are important steps to strengthen assurance against violations: both sides undertake not to interfere with national technical <b>means</b> <b>of</b> <b>verification.</b> In addition, both countries agree not to use deliberate concealment measures to impede verification." [...] refers to, in part, a technical agreement not to encrypt strategic test telemetry and thus impede verification by TELINT.|$|E
50|$|One {{method for}} deduplicating data {{relies on the}} use of {{cryptographic}} hash functions to identify duplicate segments of data. If two different pieces of information generate the same hash value, this is known as a collision. The probability of a collision depends upon the hash function used, and although the probabilities are small, they are always non zero. Thus, the concern arises that data corruption can occur if a hash collision occurs, and additional <b>means</b> <b>of</b> <b>verification</b> are not used to verify whether there is a difference in data, or not. Both in-line and post-process architectures may offer bit-for-bit validation of original data for guaranteed data integrity. The hash functions used include standards such as SHA-1, SHA-256 and others.|$|E
50|$|Test {{coverage}} in the test plan states what requirements will be verified during what stages of the product life. Test coverage is derived from design specifications and other requirements, such as safety standards or regulatory codes, where each requirement or specification of the design ideally will have one or more corresponding <b>means</b> <b>of</b> <b>verification.</b> Test coverage for different product life stages may overlap, but will not necessarily be exactly {{the same for all}} stages. For example, some requirements may be verified during Design Verification test, but not repeated during Acceptance test. Test coverage also feeds back into the design process, since the product may have to be designed to allow test access.|$|E
40|$|An {{analysis}} of the probability of failure of beaches along the Catalan coast (Northwestern Mediterranean) is presented. The failure condition is defined when waves are able to overtop the beach and reach the backshore. The analysis is performed by <b>means</b> <b>of</b> a <b>verification</b> equation {{where most of the}} related variables are assumed to be stochastic. The probability of failure of beaches is calculated by <b>means</b> <b>of</b> MonteCarlo simulations for present conditions and different climate change scenarios. At present 14 % of the Catalan beaches fail the proposed protection function against storms. Under a high-end climate change projection (A 1 FI) 21 % of beaches will fail. Peer ReviewedPostprint (published version...|$|R
40|$|Biometric {{systems are}} {{becoming}} increasingly important, since they provide more reliable and efficient <b>means</b> <b>of</b> identity <b>verification.</b> Biometric gait recognition (i. e. recognizing people from the way they walk) {{is one of the}} recent attractive topics in biometric research. This paper presents biometric user recognition based on gait. Biometric gait recognition is categorized into three groups based on: machine vision, floor sensor and wearable sensor. An overview of each gait recognition category is presented. In addition, factors that may influence gait recognition are outlined. Furthermore, the security evaluations of biometric gait under various attack scenarios are also presented. ...|$|R
40|$|The Chip Multiprocessor (CMP) {{architecture}} offers dramatically faster {{retrieval of}} shared data which is cached on-chip {{rather than in}} an off-chip memory. Remote cache requests are handled through a cache coherence protocol. In order to obtain the best possible performance with the CMP architecture, the cache coherence protocol must be optimized to reduce time lost during remote cache and offchip memory accesses. This paper proposes a novel snooping cache coherence protocol for CMP in which each processor has both private and shared L 2 caches. The cache coherence protocol is proven by <b>means</b> <b>of</b> formal <b>verification</b> methods. 1...|$|R
50|$|An {{example of}} the {{implementation}} of such a strategy could be: Ballistic missile submarines are ordered to surface at periodic intervals to receive communications indicating that no change {{has occurred in the}} defense condition. Should the submarines be unable to receive the proper command and control signals indicating normal, peacetime conditions, their orders would be to launch their nuclear missiles under the assumption that command and control structures had been destroyed in a nuclear attack and that retaliation was therefore necessary. All available <b>means</b> <b>of</b> <b>verification</b> and all due caution would naturally be applied. This approach is obviously exceptionally dangerous for a variety of reasons. The strategy's true value is in deterrence against attack on command, control, communications, and computer (see C4I) networks by any potential adversary.|$|E
5000|$|In his {{definition}} of [...] "disarmament", David Carlton writes in the Oxford University Press Political dictionary, [...] "But confidence in such measures of arms control, especially when unaccompanied by extensive <b>means</b> <b>of</b> <b>verification,</b> has not been strengthened by the revelation that the Soviet Union in its last years successfully concealed consistent and systematic cheating on its obligations under the Biological Weapons Convention." [...] He also notes, [...] "Now a freeze or a mutually agreed increase is not strictly speaking disarmament at all. And such measures {{may not even be}} intended to be a first step towards any kind of reduction or abolition. For the aim may simply be to promote stability in force structures. Hence a new term to cover such cases has become fashionable since the 1960s, namely, arms control." ...|$|E
5000|$|The LFA is {{also used}} in other contexts, both {{personal}} and corporate. When developed within an organization, it can articulate a common interpretation of the objectives of a project and how they will be achieved. The indicators and <b>means</b> <b>of</b> <b>verification</b> force clarifications as one would for a scientific endeavor, as in [...] "you haven't defined it until you say how you will measure it." [...] Tracking progress against carefully defined output indicators provides a clear basis for monitoring progress; verifying purpose and goal level progress then simplifies evaluation. Given a well constructed logical framework, an informed skeptic and a project advocate {{should be able to}} agree on exactly what the project attempts to accomplish, and how likely it is to succeed—in terms of programmatic (goal-level) as well as project (purpose-level) objective.|$|E
40|$|This {{poster paper}} {{reports on a}} model-based {{framework}} for software quality assurance for cardiac pacemakers developed in Simulink and described in [3]. A novel hybrid heart model is proposed that is suitable for quantitative <b>verification</b> <b>of</b> pacemakers. The heart model is formulated {{at the level of}} cardiac cells, can be adapted to patient data, and incorporates stochasticity. We validate the model by demonstrating that its composition with a pacemaker model can be used to check safety properties by <b>means</b> <b>of</b> approximate probabilistic <b>verification...</b>|$|R
40|$|In today’s world, {{biometric}} identifications {{are gaining}} {{more and more}} importance. A biometric system provides more reliable and efficient <b>means</b> <b>of</b> identity <b>verification.</b> The physical dimensions of a human hand known as hand or palm geometry, contains information {{that is capable of}} authenticating the identity of an individual. The hand geometry based identity verification system is being widely used in various applications like access control, time and attendance. The goal <b>of</b> a biometric <b>verification</b> system consists in deciding whether two characteristics belong to the same person or not. It explores the features of a human hand, extracted from a color photograph which is taken when the user is asked to place his/her hand on a platform especially designed for this task...|$|R
40|$|Signatures are {{extensively}} {{used as a}} <b>means</b> <b>of</b> personal <b>verification.</b> Manual signature-based authentication of a {{large number}} of documents is a very difficult and time consuming task. Consequently for many years, in the field of protected communication and financial applications, we have observed an explosive growth in biometric personal authentication systems that are closely connected with measurable physical unique characteristics (hand geometry, iris scan, finger prints or DNA) or behavioural features. Human signatures provide secure means for confirmation and authorization in legal documents. So nowadays, automatic signature verification becomes an essential component. In order to convey the state of- the-art in the field to researchers, in this paper we present a survey <b>of</b> off-line signature <b>verification</b> systems. Griffith Sciences, School of Information and Communication TechnologyFull Tex...|$|R
