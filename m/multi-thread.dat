303|3366|Public
2500|$|<b>Multi-thread</b> {{functions}} {{should be}} made thread safe, for instance servlets or struts action classes must not have instance/non-final static fields ...|$|E
2500|$|In this model, {{beings and}} {{information}} are modeled as abstract information molecules carrying expressions of mathematical logic. They are quasi-randomly displacing {{due to their}} interaction with their environments with their intended displacements. Their interaction in abstract computational space creates <b>multi-thread</b> inference process which we perceive as collective intelligence. Thus, a non-Turing model of computation is used. This theory allows simple formal definition of collective intelligence as the property of social structure {{and seems to be}} working well for a wide spectrum of beings, from bacterial colonies up to human social structures. Collective intelligence considered as a specific computational process is providing a straightforward explanation of several social phenomena. For this model of collective intelligence, the formal definition of IQS (IQ Social) was proposed and was defined as [...] "the probability function over the time and domain of N-element inferences which are reflecting inference activity of the social structure". While IQS seems to be computationally hard, modeling of social structure in terms of a computational process as described above gives a chance for approximation. Prospective applications are optimization of companies through the maximization of their IQS, and the analysis of drug resistance against collective intelligence of bacterial colonies.|$|E
5000|$|Eustomias multifilis Parin & Pokhil'skaya, 1978 (<b>Multi-thread</b> dragonfish) ...|$|E
5000|$|Identification of {{unnecessary}} <b>multi-threading.</b> <b>Multi-threading</b> {{is an extremely}} large error source. The run-time behavior of <b>multi-threading</b> code is hard to comprehend meaning the cost and effort required for extensions or maintenance to it is correspondingly high. Thus, as a general rule, unnecessary <b>multi-threading</b> should be avoided.|$|R
40|$|Abstract It is {{generally}} acknowledged that developing correct <b>multi-threaded</b> codes is difficult, because threads may {{interact with each}} other in unpredictable ways. The goal of this work is todiscover common <b>multi-threaded</b> programming pitfalls, the knowledge of which will be useful in instructing new pro-grammers and in developing tools to aid in <b>multi-threaded</b> programming. To this end, we study <b>multi-threaded</b> appli-cations written by students from introductory operating systems courses. Although the applications are simple, carefulinspection and the use of an automatic race detection tool reveal a surprising quantity and variety of synchronizationerrors. We describe and discuss these errors, evaluate the role of automated tools, and propose new tools for use in theinstruction of <b>multi-threaded</b> programming. 1 Introduction <b>Multi-threading</b> is a powerful programming paradigm, use-ful in many problem domains. It is a convenient structurin...|$|R
50|$|While not all VCL {{components}} are thread-safe, VCL supports <b>multi-threading</b> too. One {{example is the}} built in <b>multi-threading</b> support of the OpenWire VCL library.|$|R
50|$|VisualAp uses <b>multi-thread</b> {{execution}} whenever multiple {{components are}} ready for execution simultaneously.|$|E
5000|$|Future {{trends in}} {{computer}} architectures Superscalar, Vector, <b>Multi-thread</b> and multicore processors; future trends.|$|E
5000|$|Puma {{does not}} feature {{clustered}} <b>multi-thread</b> (CMT), meaning {{that there are}} no [...] "modules" ...|$|E
40|$|AbstractSIGNAL, Lustre, Esterel, and a {{few other}} {{synchronous}} programming language compilers accomplish automated sequential code generation from synchronous specifications. In generating sequential code, the concurrency expressed in the synchronous programs is sequentialized mostly because such embedded software was designed to run on single-core processors. With the widespread advent of multi-core processors, it is time for model-driven generation of efficient concurrent <b>multi-threaded</b> code. Synchronous programming models capture concurrency in the computation quite naturally, especially in its data-flow multi-clock (polychronous) flavor. Therefore, it seems reasonable to attempt generating <b>multi-threaded</b> code from polychronous data-flow models. However, <b>multi-threaded</b> code generation from polychronous languages aimed at multi-core processors is still in its infancy. In the recent release of the Polychrony compiler, <b>multi-threaded</b> code generation uses micro-level threading which creates a large number of threads and equally large number of semaphores, leading to inefficiency. We propose a process-oriented and non-invasive <b>multi-threaded</b> code generation using the sequential code generators. By noninvasive we mean that instead of changing the compiler, we use the existing sequential code generator and separately synthesize some programming glue to generate efficient <b>multi-threaded</b> code. This paper describes the problem of <b>multi-threaded</b> code generation in general, and elaborates on how Polychrony compiler for sequential code generation is used to accomplish <b>multi-threaded</b> code generation...|$|R
40|$|AbstractIn this paper, we {{presented}} a dynamic management mechanism of hardware <b>multi-threading</b> for pipelined hardware <b>multi-threading</b> architecture. And {{a set of}} special instructions are provided. In view of the workload and traffic of network are uncertainty, the dynamic <b>multi-threading</b> architecture in this paper can adaptively adjust processor performance according to the workload, and achieve the effective power savings...|$|R
40|$|In recent years, <b>multi-threaded</b> {{processors}} {{have become}} more and more popular in industry in order to increase the system aggregated performance and per-application performance, overcoming the limitations imposed by the limited instruction-level parallelism, and by power and thermal constraints. <b>Multi-threaded</b> processors are widely used in servers, desktop computers, lap-tops, and mobile devices. However, <b>multi-threaded</b> processors introduce complexities when accounting CPU (computation) capacity (CPU accounting), since the CPU capacity accounted to an application not only depends upon the time that the application is scheduled onto a CPU, but also on the amount of hardware resources it receives during that period. And given that in a <b>multi-threaded</b> processor hardware resources are dynamically shared between applications, the CPU capacity accounted to an application in a <b>multi-threaded</b> processor depends upon the workload in which it executes. This is inconvenient because the CPU accounting of the same application with the same input data set may be accounted significantly different depending upon the workload in which it executes. Deploying systems with accurate CPU accounting mechanisms is necessary to increase fairness among running applications. Moreover, it will allow users to be fairly charged on a shared data center, facilitating server consolidation in future systems. This Thesis analyses the concepts of CPU capacity and CPU accounting for <b>multi-threaded</b> processors. In this study, we demonstrate that current CPU accounting mechanisms are not as accurate as they should be in <b>multi-threaded</b> processors. For this reason, we present two novel CPU accounting mechanisms that improve the accuracy in measuring the CPU capacity for <b>multi-threaded</b> processors with low hardware overhead. We focus our attention on several current <b>multi-threaded</b> processors, including chip multiprocessors and simultaneous multithreading processors. Finally, we analyse the impact of shared resources in <b>multi-threaded</b> processors in operating system CPU scheduler and we propose several schedulers that improve the knowledge of shared hardware resources at the software level. Postprint (published version...|$|R
5000|$|... in C++, OpenSG, a scene-graph {{system for}} {{real-time}} graphics, with clustering support and <b>multi-thread</b> safety ...|$|E
50|$|Powerline: <b>Multi-thread</b> {{conductors}} {{that run}} between electric pylons, used for high voltage long distance power transmission.|$|E
5000|$|Jaguar {{does not}} feature {{clustered}} <b>multi-thread</b> (CMT), meaning that execution resources are not shared between cores ...|$|E
40|$|Multi-processor {{computers}} {{are becoming increasingly}} popular and are important for improving application performance. Providing high-performance memory-management is important for <b>multi-threaded</b> programs. This thesis looks at memory allocation of dynamic-allocation memory in concurrent C and C++ programs. The challenges facing the design of any memory allocator include minimizing fragmentation, and promoting good locality. A <b>multi-threaded</b> memory-allocator is also concerned with minimizing contention, providing mutual exclusion, avoiding false-sharing, and preventing heap-blowup (a form of fragmentation). Several potential features are identified in existing <b>multi-threaded</b> memory-allocators. These features include per-thread heaps with a global heap, object ownership, object containers, thread-local free-list buffers, remote free-lists, allocation buffers, and lock-free operations. When used in different combinations, these features can solve most of the challenges facing a <b>multi-threaded</b> memory-allocator. Through {{the use of a}} test suite composed of both single and <b>multi-threaded</b> benchmark programs, several existing memory allocators and a set of new allocators are compared. It is determined that different features address different <b>multi-threaded</b> issues in the memory allocator with respect to performance, scaling, and fragmentation. Finally, recommendations are made for the design of a general-purpose memory-allocator...|$|R
40|$|The {{trend in}} Multi-core {{processors}} development has made <b>multi-threaded</b> software development for distributed memory applications pervasive. Unfortunately, writing correct <b>multi-threaded</b> programs is challengeable. Effective testing for <b>multi-threaded</b> programs {{plays an important}} role in the development life cycle. While coverage criteria to measure the quality of test cases for sequential programs are rich and mature, there are no adequate coverage criteria of <b>multi-threaded</b> programs. This project proposes a coverage criteria hierarchy for point-to-point <b>multi-threaded</b> programs testing, including seven (five new) coverage criteria. The property set of each criterion is formulated and the size of the coverage space for each criterion is formally mathematically examined and discussed. As for generating coverage tasks of each criterion, this project chiefly provides two main approaches, one for code coverage criteria and the other for structural coverage criterion. Regarding automatically extracting coverag...|$|R
40|$|While <b>multi-threading</b> {{has become}} commonplace in many {{application}} domains (e. g., embedded systems, {{digital signal processing}} (DSP), networks, IP services, and graphics), <b>multi-threaded</b> code often requires complex co-ordination of threads. As a result, <b>multi-threaded</b> implementations are prone to subtle bugs that are difficult and time-consuming to locate. Moreover, current testing techniques that address <b>multi-threading</b> are generally costly while their effectiveness is unknown. The development of cost-effective testing plans requires an in-depth study of the nature, frequency, and cost of concurrency errors {{in the context of}} real-world applications. The full paper will lay the groundwork for such a study, with the purpose of informing the creation of a parametric cost model for testing <b>multi-threaded</b> software. The current version of the paper provides motivation for the study, an outline of the full paper, and a bibliography of related papers...|$|R
5000|$|<b>Multi-thread</b> {{functions}} {{should be}} made thread safe, for instance servlets or struts action classes must not have instance/non-final static fields ...|$|E
5000|$|Java has {{built-in}} {{tools for}} <b>multi-thread</b> programming. For {{the purposes of}} thread synchronization the [...] statement is included in Java language.|$|E
5000|$|... 8, 32 or 256 {{priority}} scheduling <b>multi-thread</b> scheduling; Using the round-robin policy {{ensures that}} all threads {{having the same}} priority level will be scheduled equally; ...|$|E
40|$|We take {{a thread}} as the {{behavior}} of a sequential deterministic program under execution and <b>multi-threading</b> as the form of concurrency provided by contemporary programming languages such as Java and C#. We outline an algebraic theory about threads and <b>multi-threading.</b> In the case of <b>multi-threading,</b> some deterministic interleaving strategy determines how threads are interleaved. Interleaving operators for a number of plausible interleaving strategies are specified in a simple and concise way. By that, we show that it is essentially open-ended what counts as an interleaving strategy. We use deadlock freedom as an example to show that there are properties of <b>multi-threaded</b> programs that depend on the interleaving strategy used...|$|R
40|$|We {{present an}} {{extension}} of the polarized process algebra BPPA, an algebraic theory about sequential program behaviors. The extension is called thread algebra and is proposed as a tool for the description and analysis of <b>multi-threaded</b> program behaviors. Strategic interleaving refers to the form of concurrency where some interleaving strategy is used rather than arbitrary interleaving. Strategic interleav- ing is considered characteristic of <b>multi-threading.</b> <b>Multi-threaded</b> concurrency is more limited than general concurrency based on arbitrary interleaving...|$|R
40|$|It is {{generally}} acknowledged that developing correct multithreaded codes is difficult, because threads may {{interact with each}} other in unpredictable ways. The goal of this work is to discover common <b>multi-threaded</b> programming pitfalls, the knowledge of which will be useful in instructing new programmers and in developing tools to aid in <b>multi-threaded</b> programming. To this end, we study <b>multi-threaded</b> applications written by students from introductory operating systems courses. Although the applications are simple, careful inspection and the use of an automatic race detection tool reveal a surprising quantity and variety of synchronization errors. We describe and discuss these errors, evaluate the role of automated tools, and propose new tools for use in the instruction of <b>multi-threaded</b> programming. ...|$|R
50|$|In January 2012, Microsoft {{released}} two hotfixes (2646060 and 2645594) for Windows 7 and Server 2008 R2 {{that significantly}} improved {{the performance of}} Clustered <b>Multi-Thread</b> based AMD CPUs by improving thread scheduling.|$|E
5000|$|Provides fast {{inspection}} through <b>multi-thread</b> {{inspection and}} {{also provides a}} simulated hacking tool {{that can be used}} to simulate a security breach for security vulnerabilities found to provide a better understanding of the vulnerability.|$|E
5000|$|SMT (simultaneous multithreading) {{architecture}} {{allows for}} 2 threads per core, {{a departure from}} the CMT (clustered <b>multi-thread)</b> design used in the previous Bulldozer architecture. This is a feature previously offered in some IBM, Intel and Oracle processors.|$|E
5000|$|Platform-independent <b>multi-threaded</b> {{rendering}} system architecture: ...|$|R
30|$|The ETSI {{complaint}} Geonetworking {{protocol layer}} {{can be implemented}} using either a <b>multi-threaded</b> or monolithic single process programming model. Both programming models have their advantages and disadvantages, such as a <b>multi-threaded</b> approach can handle concurrent packets, while a single process approach is easier to implement. We based our implementation on the monolithic single process programming model, as initial tests showed that, <b>multi-threaded</b> extensions to the NCTUns framework were causing instability issues. We employed a modular approach and realized each module as a function.|$|R
40|$|<b>Multi-threaded</b> {{programs}} have many applications which {{are widely used}} such as operating systems. Analyzing <b>multi-threaded</b> programs differs from sequential ones; the main feature is that many threads execute at the same time. The effect of all other running threads must be taken in account. Partial redundancy elimination {{is among the most}} powerful compiler optimizations: it performs loop-invariant code motion and common subexpression elimination. We present a type system with optimization component which performs partial redundancy elimination for <b>multi-threaded</b> programs. Comment: 7 page...|$|R
50|$|Features of ODBPP include: full {{multi-process}} and <b>multi-thread</b> transaction control, auto real-time database recovery, hierarchical object data design, {{native code}} and script access, static hash index on object IDs, numerous supported index methods including full-text and biometric pattern matching.|$|E
50|$|In a {{drilling}} rig, the drill {{line is a}} <b>multi-thread,</b> twisted wire rope that is threaded or reeved through the traveling block and crown block to facilitate the lowering and lifting of the drill string {{into and out of}} the wellbore.|$|E
50|$|The {{run time}} manager {{controls}} the formalities of {{execution of the}} program; decides priorities within the operation; and manages the <b>multi-thread</b> and multiprocessor operations. It {{is made up of}} templates that define thread typologies according to the formalities of execution and from a part that manages the POU (Program Organization Unit).|$|E
5000|$|<b>Multi-threaded</b> MATLAB-compatible {{implementation}} of Boosted Trees ...|$|R
50|$|The {{programming}} control structures on which autoparallelization places the most focus are loops, because, in general, {{most of the}} execution time of a program takes place inside some form of loop.There are two main approaches to parallelization of loops: pipelined <b>multi-threading</b> and cyclic <b>multi-threading.</b>|$|R
5000|$|Support for hybrid <b>multi-threaded</b> and {{distributed}} simulation.|$|R
