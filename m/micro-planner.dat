15|2|Public
2500|$|Although it {{was based}} on the proof methods of logic, Planner, {{developed}} at MIT, was the first language to emerge within this proceduralist paradigm. [...] Planner featured pattern-directed invocation of procedural plans from goals (i.e. goal-reduction or backward chaining) and from assertions (i.e. forward chaining). [...] The most influential implementation of Planner was the subset of Planner, called <b>Micro-Planner,</b> implemented by Gerry Sussman, Eugene Charniak and Terry Winograd. It was used to implement Winograd's natural-language understanding program SHRDLU, which was a landmark at that time. To cope with the very limited memory systems at the time, Planner used a backtracking control structure so that only one possible computation path had to be stored at a time. Planner gave rise to the programming languages QA-4, Popler, Conniver, QLISP, and the concurrent language Ether.|$|E
2500|$|<b>Micro-Planner</b> had a construct, called [...] "thnot", which {{when applied}} to an {{expression}} returns the value true if (and only if) {{the evaluation of the}} expression fails. An equivalent operator is normally built-in in modern Prolog's implementations. It is normally written as not(Goal) or \+ Goal, where Goal is some goal (proposition) to be proved by the program. This operator differs from negation in first-order logic: a negation such as \+ X == 1 fails when the variable X has been bound to the atom 1, but it succeeds in all other cases, including when X is unbound. This makes Prolog's reasoning non-monotonic: X = 1, \+ X == 1 always fails, while \+ X == 1, X = 1 can succeed, binding X to 1, depending on whether X was initially bound (note that standard Prolog executes goals in left-to-right order).|$|E
50|$|A subset called <b>Micro-Planner</b> was {{implemented}} by Gerry Sussman, Eugene Charniak and Terry Winograd Charniak, and Winograd 1971 {{and was used}} in Winograd's natural-language understanding program SHRDLU, Eugene Charniak's story understanding work, Thorne McCarty's work on legal reasoning, and some other projects. This generated {{a great deal of}} excitement in the field of AI. It also generated controversy because it proposed an alternative to the logic approach that {{had been one of the}} mainstay paradigms for AI.|$|E
40|$|ABSTRACT: City-centres are {{replica of}} high energy {{intensity}} with growing building {{services as a}} consequence of rapid urbanization and ever-increasing urban densities. Energy for building services is increased owing to ‘urban heat island’. These higher heat sinks also elevate energy demand profile for downtown areas. Low energy system considerations for urban buildings in city centre require consideration {{of a wide range of}} factors including Urban Square design, geometry & orientation in context of micro-planning needs. Present paper evaluates city-centres enlisting existing shortcomings and proposes simultaneously design criteria’s citing examples from existing city centres across globe. This will help designers, <b>micro-planners,</b> architects in redefining building design criteria’s that correlates to city-centres & downtowns for energy efficiency...|$|R
40|$|International audienceIn this paper, {{we focus}} on how to create data-to-text corpora which can support the {{learning}} of wide-coverage <b>micro-planners</b> i. e., generation systems that handle lexicalisation, aggregation, surface re-alisation, sentence segmentation and referring expression generation. We start by reviewing common practice in designing training benchmarks for Natural Language Generation. We then present a novel framework for semi-automatically creating linguistically challenging NLG corpora from existing Knowledge Bases. We apply our framework to DBpedia data and compare the resulting dataset with (Wen et al., 2016) 's dataset. We show that while (Wen et al., 2016) 's dataset {{is more than twice}} larger than ours, it is less diverse both in terms of input and in terms of text. We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of generating text from KB data...|$|R
5000|$|Planner (often seen in {{publications}} as [...] "PLANNER" [...] {{although it}} is not an acronym) is a programming language designed by Carl Hewitt at MIT, and first published in 1969. First, subsets such as <b>Micro-Planner</b> and Pico-Planner were implemented, and then essentially the whole language was implemented as Popler by Julian Davies at the University of Edinburgh in the POP-2 programming language. Derivations such as QA4, Conniver, QLISP and Ether (see Scientific Community Metaphor) were important tools in Artificial Intelligence research in the 1970s, which influenced commercial developments such as KEE and ART.|$|E
5000|$|In 1971 Sussman, Drew McDermott, and Eugene Charniak had {{developed}} a system called <b>Micro-Planner</b> which was a partial and somewhat unsatisfactory implementation of Carl Hewitt's ambitious Planner project. Sussman and Hewitt worked together along with others on Muddle (later MDL), an extended Lisp which formed a component of Hewitt's project. Drew McDermott, and Sussman in 1972 developed the Lisp-based language Conniver, which revised the use of automatic backtracking in Planner which they thought was unproductive. Hewitt was dubious that the [...] "hairy control structure" [...] in Conniver was {{a solution to the}} problems with Planner. Pat Hayes remarked: [...] "Their and McDermott solution, to give the user access to the implementation primitives of Planner, is however, something of a retrograde step (what are Conniver's semantics?)" ...|$|E
5000|$|<b>Micro-Planner</b> had a construct, called [...] "thnot", which {{when applied}} to an {{expression}} returns the value true if (and only if) {{the evaluation of the}} expression fails. An equivalent operator is normally built-in in modern Prolog's implementations. It is normally written as [...] or , where [...] is some goal (proposition) to be proved by the program. This operator differs from negation in first-order logic: a negation such as [...] fails when the variable [...] has been bound to the atom , but it succeeds in all other cases, including when [...] is unbound. This makes Prolog's reasoning non-monotonic: [...] always fails, while [...] can succeed, binding [...] to , depending on whether [...] was initially bound (note that standard Prolog executes goals in left-to-right order).|$|E
5000|$|Although it {{was based}} on the proof methods of logic, Planner, {{developed}} at MIT, was the first language to emerge within this proceduralist paradigm. [...] Planner featured pattern-directed invocation of procedural plans from goals (i.e. goal-reduction or backward chaining) and from assertions (i.e. forward chaining). The most influential implementation of Planner was the subset of Planner, called <b>Micro-Planner,</b> implemented by Gerry Sussman, Eugene Charniak and Terry Winograd. It was used to implement Winograd's natural-language understanding program SHRDLU, which was a landmark at that time. To cope with the very limited memory systems at the time, Planner used a backtracking control structure so that only one possible computation path had to be stored at a time. Planner gave rise to the programming languages QA-4, Popler, Conniver, QLISP, and the concurrent language Ether.|$|E
5000|$|The Planner {{language}} was {{developed during the}} late 1960s as part of Hewitt's doctoral research in MIT's Artificial Intelligence Laboratory. Hewitt's work on Planner introduced {{the notion of the}} [...] "procedural embedding of knowledge", which was an alternative to the logical approach to knowledge encoding for artificial intelligence pioneered by John McCarthy. Planner has been described as [...] "extremely ambitious". A subset of Planner called <b>Micro-Planner</b> was implemented at MIT by Gerry Sussman, Drew McDermott, Eugene Charniak and Terry Winograd and was used in Winograd's SHRDLU program, Charniak's natural language story understanding work, and L. Thorne McCarty's work on legal reasoning. Planner was almost completely implemented in Popler by Julian Davies at Edinburgh. Planner also influenced the later development of other AI research languages such as Muddle and Conniver, as well as the Smalltalk object-oriented programming language.|$|E
40|$|<b>Micro-Planner</b> is an {{implementation}} of a subset of Cal Hewitt's language, PLANNER by Gerald Jay Sussman, Terry Winograd, and Eugene Charniak on the AI group computer in LISP. <b>Micro-Planner</b> is now a publically accessible systems program in the AI group systems ITS. The current version of <b>Micro-Planner,</b> embedded in an allocated LISP, may be obtained by incanting ':PLNR' or 'PLNR' to DDT. <b>Micro-Planner</b> is also available as EXPR code or LAP code. All questions, suggestions, or comments about <b>Micro-Planner</b> should be directed to Gerald Jay Sussman (login name GJS) who will maintain the program...|$|E
40|$|International audienceA {{generation}} system {{can only be}} as good as the data it is trained on. In this short paper, we propose a methodology for analysing data-to-text corpora used for training <b>micro-planner</b> i. e., systems which given some input must produce a text verbalising exactly this input. We apply this methodology to three existing benchmarks and we elicite a set of criteria {{for the creation of a}} data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text generators...|$|E
40|$|This manual is {{intended}} to be a guide to the philosophy and use of the programming language CONNIVER, which is "complete," and running at the AI Lab now. It assumes good knowledge of LISP, but no knowledge of <b>Micro-Planner,</b> in whose implementation many design decisions were made that are not to be expected to have consequences in CONNIVER. Those not familiar with LISP should consult Weissmans (1967) Primer, the LISP 1. 5 Programmer's Manual (McCarthy et. al., 1962), or Jon L. Whites (1970) and others (PDP- 6, 1967) excellent memos here at our own la...|$|E
40|$|Inspired by ACTORS [Greif and Hewitt] [Smith and Hewitt], we have {{implemented}} an interpreter for a LISP-like language, SCHEME, {{based on the}} lambda calculus [Church], but extended for side effects, multiprocessing, and process synchronization. The purpose of this implementation is tutorial. We wish to: (1) alleviate the confusion caused by <b>Micro-PLANNER,</b> CONNIVER, etc. by clarifying the embedding of non-recursive control structures in a recursive host language like LISP. (2) explain {{how to use these}} control structures, independent of such issues as pattern matching and data base manipulation. (3) have a simple concrete experimental domain for certain issues of programming semantics and style...|$|E
40|$|This paper s a'study i n {{the tactics}} of content {{selection}} and realization at the micro-planning level. It presents a. technique for controlling the content and phrasin g of 'complex sentences {{through the use of}} data derive d from a parser that has read through a corpus and taken note of which variations do and do not occur in the realization of the concepts in the genre the corpus is taken. from. These findings are entered as annotations on a' new representational. device, a 'saturation lattice', that provides. a systematic way to define partial information and is the jumping off point for the <b>micro-planner.</b> The generator and parser are both based. on a declaxative, bi-directional representation of realization relationship between concepts and tex...|$|E
40|$|A natural {{language}} generation system is typically constituted by two main components: a content planning component (e. g., text planner or dialogue act planner) and a linguistic realization component. But, this is not sufficient since, on the one hand, the message built by the content planning component is generally not adequately detailed {{in order to control}} the many possibilities for its expression and, on the other hand, the content planner cannot influence {{the way in which the}} message will be verbalized. Generation systems require a third component, called the micro-planning (or sentence planning or phrasing) component, which acts as an intermediary between the pragmatico-semantic level and the purely syntactic level. The <b>micro-planner</b> is responsible for transforming the message into a textual structure. For this transformation to be achieved, grammatical and lexical resources must be selected. 1 Introduction Traditionally, the architecture of a generation system is either pipeline [...] ...|$|E
40|$|Inspired by ACTORS [7, 17], we have {{implemented}} an interpreter for a LISP-like language, SCHEME, {{based on the}} lambda calculus [2], but extended for side effects, multiprocessing, and process synchronization. The purpose of this implementation is tutorial. We wish to: 1. alleviate the confusion caused by <b>Micro-PLANNER,</b> CONNIVER, etc., by clarifying the embedding of non-recursive control structures in a recursive host language like LISP. 2. explain {{how to use these}} control structures, independent of such issues as pattern matching and data base manipulation. 3. have a simple concrete experimental domain for certain issues of programming semantics and style. This paper is organized into sections. The first section is a short “reference manual ” containing specifications for all the unusual features of SCHEME. Next, we present a sequence of programming examples which illustrate various programming styles, and how to use them. This will raise certain issues of semantics which we will try to clarify with lambda calculus in the third section. In the fourth section we will give a general discussion of the issues facing an implementor of an interpreter for a language based on lambda calculus. Finally, we will present a completely annotated interpreter for SCHEME, written in MacLISP [13], to acquaint programmers with the tricks of the trade of implementing non-recursive control structures in a recursive language like LISP...|$|E

