15|473|Public
2500|$|... and {{function}} application {{corresponds to the}} detachment (<b>modus</b> <b>ponens)</b> <b>rule</b> ...|$|E
50|$|This is the <b>modus</b> <b>ponens</b> <b>rule</b> of propositional logic. Rules of {{inference}} {{are often}} formulated as schemata employing metavariables. In the rule (schema) above, the metavariables A and B can be instantiated to any {{element of the}} universe (or sometimes, by convention, a restricted subset such as propositions) to form an infinite set of inference rules.|$|E
50|$|In general, the {{procedure}} is that whenever the program contains an application of the form (P Q), we should first prove theorems corresponding to the types of P and Q. Since P is being applied to Q, the type of P must have the form α → β {{and the type of}} Q must have the form α for some α and β. We can then detach the conclusion, β, via the <b>modus</b> <b>ponens</b> <b>rule.</b>|$|E
40|$|AbstractWe study {{knowledge-based}} systems using symbolic many-valued {{logic and}} {{we focus on}} the management of knowledge through linguistic concepts characterized by vague terms or labels. In previous papers we have proposed a symbolic representation of nuanced statements. In this representation, we have interpreated some nuances of natural language as linguistic modifiers and we have defined them within a multiset context. In this paper, we continue the presentation of our symbolic model and we propose new deduction rules dealing with nuanced statements. We limit ourself to present new generalizations of the <b>Modus</b> <b>Ponens</b> <b>rules</b> dealing with nuanced statements...|$|R
25|$|Both {{premises}} and {{the conclusion}} are propositions. The premises are {{taken for granted}} {{and then with the}} application of <b>modus</b> <b>ponens</b> (an inference <b>rule)</b> the conclusion follows.|$|R
50|$|Backward {{chaining}} {{is implemented}} in logic programming by SLD resolution. Both rules {{are based on}} the <b>modus</b> <b>ponens</b> inference <b>rule.</b> It is one of the two most commonly used methods of reasoning with inference rules and logical implications - the other is forward chaining. Backward chaining systems usually employ a depth-first search strategy, e.g. Prolog.|$|R
50|$|The residuum of a left-continuous t-norm can {{explicitly}} {{be defined}} asThis {{ensures that the}} residuum is the largest function such that for all x and y,The latter {{can be interpreted as}} a fuzzy version of the <b>modus</b> <b>ponens</b> <b>rule</b> of inference. The residuum of a left-continuous t-norm thus can be characterized as the weakest function that makes the fuzzy modus ponens valid, which makes it a suitable truth function for implication in fuzzy logic. Left-continuity of the t-norm is the necessary and sufficient condition for this relationship between a t-norm conjunction and its residual implication to hold.|$|E
40|$|Fuzzy {{logic is}} based on the theory of fuzzy sets, where an object’s {{membership}} of a set is gradual rather than just member or not a member. Fuzzy logic uses the whole interval of real numbers between zero (False) and one (True) to develop a logic as a basis for rules of inference. Particularly the fuzzified version of the <b>modus</b> <b>ponens</b> <b>rule</b> of inference enable...|$|E
40|$|International audienceIn {{this work}} we {{consider}} a very general principle for fuzzy rule interpolation methods {{based on an}} interpretation of the generalized <b>modus</b> <b>ponens</b> <b>rule</b> in terms of closeness relations. Then we present two particular instances of the general principle when the closeness relations are defined from parametric families of similarity fuzzy relations on the input and output spaces. The case of multiple input variables is also considered...|$|E
40|$|The paper {{proposes a}} new {{approach}} to certainty factor of decision rules in knowledge based systems. The approach is based on rough set theory, and {{can be viewed as a}} generalization of Lukasiewicz’s ideas connected with multivalued logic and probability. In particular Rough <b>Modus</b> <b>Ponens</b> inference <b>rule</b> is defined and briefly discussed. Connection of the proposed concepts with rough mereology is pointed out. ...|$|R
50|$|In {{mathematical}} logic, the cut rule is an {{inference rule}} of sequent calculus. It is a generalisation {{of the classical}} <b>modus</b> <b>ponens</b> inference <b>rule.</b> Its meaning is that, if a formula A appears as a conclusion in one proof and an hypothesis in another, then another proof in which the formula A does not appear can be deduced. In the particular case of the <b>modus</b> <b>ponens,</b> for example occurrences of man are eliminated of Every man is mortal, Socrates is a man to deduce Socrates is mortal.|$|R
50|$|In type theory, {{the type}} of {{functions}} accepting values of type A and returning values of type B may be written as A → B or BA. In the Curry-Howard correspondence, function types are related to logical implication; lambda abstraction corresponds to discharging hypothetical assumptions and function application corresponds to the <b>modus</b> <b>ponens</b> inference <b>rule.</b> Besides the usual case of programming functions, type theory also uses first-class functions to model associative arrays and similar data structures.|$|R
40|$|The {{deductive}} {{validity of}} arguments from analogy is formally demonstrable. After a brief {{survey of the}} historical development of doctrines relevant to this claim the present article analyzes the “analogy of proper proportionality”, which meets two requirements of valid deduction. First, the referents of analogues by proportionality must belong to a common genus. Here it must be cautioned, however, that the common genus does not constitute the basis of the deductive inference. Rather, it is a prerequisite for the second and decisive requirement, that the different logical content to which an analogous middle term corresponds must exhibit the same proportional relation to this common genus. In Section II I translate a natural language argument with such an analogous middle term into the language of classical first-order predicate calculus, and show that its conclusion follows from its premises with the force of deductive necessity. The rule of inference justifying the analogical entailment of the conclusion from the premises functions much like the familiar <b>modus</b> <b>ponens</b> <b>rule,</b> and could be called “modus ponens analogice”. The validity of this rule ought to be judged on the same basis as that of the traditional <b>modus</b> <b>ponens</b> <b>rule</b> – immediate logical intuition. The present article endeavors to facilitate this logical intuition by making the logical structure of inference by analogy formally explicit...|$|E
40|$|Abstract. We {{show that}} binary orthologic becomes either quantum or {{classical}} logic when nothing but <b>modus</b> <b>ponens</b> <b>rule</b> {{is added to}} it, depending {{on the kind of}} the operation of implication used. We also show that in the usual approach the rule characterizes neither quantum nor classical logic. The dierence turns out to stem from the chosen valuation on a model of a logic. Thus algebraic mappings of axioms of standard quantum logics would fail to yield an orthomodular lattice if a unary|as opposed to binary|valuation were used. Instead, non-orthomodular nontrivial varieties of orthologic are obtained. We also discuss the computational eciency of the binary quantum logic and stress its importance for quantum computation and related algorithms...|$|E
40|$|Fuzzy {{logic is}} based on the theory of fuzzy sets, where an object’s {{membership}} of a set is gradual rather than just member or not a member. Fuzzy logic uses the whole interval of real numbers between zero (False) and one (True) to develop a logic as a basis for rules of inference. Particularly the fuzzified version of the <b>modus</b> <b>ponens</b> <b>rule</b> of inference enables computers to make decisions using fuzzy reasoning rather than exact. We study decision making problem under uncertainty. we analyze Max-Min method and Minimization of regret method originally developed by Savage and further developed by Yager. We generalize The MMR method by creating the parameterized family of minimum regret methods by using the ordered weighted averaging OWA operators...|$|E
5000|$|In {{the most}} common {{versions}} {{of the notion of}} formal proof, there are, in addition to the axiom schemesof propositional calculus (or the understanding that all tautologies of propositional calculus are tobe taken as axiom schemes in their own right), quantifier axioms, and in addition to <b>modus</b> <b>ponens,</b> one additional <b>rule</b> of inference, known as the rule of generalization: [...] "From K, infer &forall;vK." ...|$|R
5000|$|Rule of inference, detachment, <b>modus</b> <b>ponens</b> : The <b>rule</b> {{that allows}} the theory to [...] "detach" [...] a [...] "conclusion" [...] from the [...] "premises" [...] {{that led up to}} it, and {{thereafter}} to discard the [...] "premises" [...] (symbols {{to the left of the}} line │, or symbols above the line if horizontal). If this were not the case, then substitution would result in longer and longer strings that have to be carried forward. Indeed, after the application of <b>modus</b> <b>ponens,</b> nothing is left but the conclusion, the rest disappears forever.|$|R
40|$|We study some {{compatible}} {{operations that}} may be defined using the minimum operator {{in the context of}} a Heyting algebra and that turn out to be inter-definable with already known operations, to wit, the minimum dense (see [4]), the successor operation of Kuznetsov (see [3]) and the G operation of Gabbay (see [2]). We consider algebraic aspects such as polynomiality and affine completeness, and logical aspects such as axiomatizability with <b>Modus</b> <b>Ponens</b> as only <b>rule</b> and conservativeness. This study may be seen as a continuation of [1]...|$|R
40|$|In {{this paper}} we propose a propositional {{temporal}} language based on fuzzy temporal constraints which turns out to be expressive enough for domains like many coming from medicine where knowledge is of propositional nature and an explicit handling of time, imprecision and uncertainty are required. The language is provided with a natural possibilistic semantics to account for the uncertainty issued by the fuzziness of temporal constraints. We also present an inference system based on specific rules dealing with the temporal constraints and a general fuzzy <b>modus</b> <b>ponens</b> <b>rule</b> whereby behaviour is shown to be sound. The analysis of the different choices as fuzzy operators leads us to identify the well-known Lukasiewicz implication as very appropriate to define the notion of possibilistic entailment, an essential element of our inference system...|$|E
40|$|Progress in {{telecommunication}} networks needs new control and management techniques for the potential, by new protocols and architectures promising, to be achieved. Computational Intelligence (CI) gives an attractive way to this goal. From the hardware point of view, {{the main problem}} is CI based methods are computationally expensive. Optics gives a reasonable alternative for purely electronic hardware. Our main interest in {{this paper is to}} establish connections between Optics and Fuzzy Set Theory and develop a model of Fourier-holography setup as a neuro-fuzzy system. We formulate an algebraic description of both geometrical and Fourier- approximations of optics by using tnorms based approach to take into consideration non-linearity of real optical devices and recording media. We design logic for both approximations. We consider Fourier-holography setup as a neuro-fuzzy system. We present experimental realisation of General <b>Modus</b> <b>Ponens</b> <b>rule</b> and develop model of Partial Associations...|$|E
40|$|The {{observation}} that humans often appear {{to use a}} more sophisticated logic than the classical one has sometimes served as an argument against the fundamental role of Automated Deduction in Intellectics. In response to this challenge, a variety of non-classical logics have been developed especially over the last decade, {{in order to provide}} adequate formalisms that cover different aspects of commonsense reasoning. We argue that both classical logic and non-classical derivatives, though different in the details, are based on common grounds. This insight gives rise to the question whether and how calculi originally designed for classical deduction can be adjusted to the various kinds of non-classical logic. We illustrate such adjusting modifications in terms of the connection method. We elaborate two fundamental concepts, namely the one of a connection, which represents the application of the <b>modus</b> <b>ponens</b> <b>rule,</b> and the one of a path, which represents the current assumptions made in the co [...] ...|$|E
40|$|Modern {{software}} systems usually {{deal with}} several sorts (types) of data elements simultaneously. Some of these sorts, like integers, booleans, strings, and so on, {{can be seen}} as having an immediate, direct nature and therefore are called visible, and they are contrasted with the others, like types of objects (in OOP sense), which are called hidden sorts. A language used to specify such software system has to be heterogeneous. In addition, to reason about such computations, we have to consider k-tuples of formulas (for instance, pairs in equational reasoning). Consequently, a consequence relation used to specify and verify the properties of those systems must relate sorted sets of k-formulas with individual k-formulas. Logics usually employed in this process are called hidden k-logics and are very general in nature: they comprise several classes of logical systems, including the 2 -dimensional hidden and standard equational logics, and Boolean logic. In this paper we propose a generalization of the notion of deduction-detachment system for hidden k-logics. We introduce a syntactic notion of translation, which will be used to deﬁne an equivalence relation between hidden k-logics. We show that this notion of equivalence preserves some logical properties, namely the deduction-detachment theorem and the Craig interpolation property. We also show that if a speciﬁable hidden k-logic admits the deduction-detachment theorem then it admits a presentation whose only inference rules are the generalized <b>modus</b> <b>ponens</b> <b>rules</b> with respect to the deduction-detachment system...|$|R
40|$|A {{number of}} {{theoretical}} positions in psychology [...] including variants of case-based reasoning, instance-based analogy, and connectionist models [...] maintain that abstract rules {{are not involved}} in human reasoning, or at best play a minor role. Other views hold that the use of abstract rules is a core aspect of human reasoning. We propose eight criteria for determining whether or not people use abstract rules in reasoning, and examine evidence relevant to each criterion for several rule systems. We argue that there is substantial evidence that several different inferential <b>rules,</b> including <b>modus</b> <b>ponens,</b> contractual <b>rules,</b> causal rules, and the law of large numbers, are used in solving everyday problems. We discuss the implications for various theoretical positions and consider hybrid mechanisms that combine aspects of instance and rule models...|$|R
40|$|AbstractClassically, {{whether to}} effect {{inference}}, one uses a small set of axioms and <b>modus</b> <b>ponens,</b> or {{a set of}} rules of inference including <b>modus</b> <b>ponens,</b> one is going beyond what can be derived with the explicit operations of logic alone. Carrying this concept over to fuzzy logic we construct a fuzzy <b>modus</b> <b>ponens</b> and other <b>rules</b> of inference that include modus tollens and reductio ad absurdum. These in turn are based on (and greatly facilitated by) a choice for the operation of implication that preserves the (logic) symmetry implicit in its definition. Extensions including conditional quantification, cut rules (single, multiple, and implicitory), and fuzzy mathematical induction are sketched. As an example, a fuzzy-logic treatment of the Yale shooting problem is discussed. The results suggest that the implicit processes of inference, as distinct from the explicit processes of decision (control) theory and systems theory, can be effected in fuzzy logic if, as in classical logic, one ventures outside the scope of (fuzzy) logic operations...|$|R
40|$|In {{this paper}} we {{approach}} trust management systems in a fuzzy logical setting. The {{idea is to}} provide a generalization of the classical framework, where trust is understood via the dichotomy “true–false”. In order to overcome the classical approach proposed by Weeks, following the ideas used by Hájek, Esteva, Godo and others to deal with probability, possibility, and necessity in a many-valued logical setting, we introduce the modal logic FT n(Ł 1 / 2) built up over the many-valued logic Ł 1 / 2. In particular, we enlarge the Ł 1 / 2 language by means of a binary modality says acting on pairs (pi,) of principals and assertions, where a principal is a propositional variable and an assertion is a propositional formula of a suited many-valued logic. The idea is to regard the evaluation of the modal formula says(pi,) as the degree of confidence the principal pi puts in the assertion. For FT n(Ł 1 / 2) we introduce a syntax, a semantic and we show completeness. Then we discuss the validity of generalized <b>modus</b> <b>ponens</b> <b>rule</b> in our setting. Finally we deal with a Pavelka-style extension of our logic, and we also extend FT n(Ł 1 / 2) to allow principals to be hierarchically organized...|$|E
50|$|As {{a result}} of this trade-off, a great deal of early work on {{knowledge}} representation for artificial intelligence involved experimenting with various compromises that provide a subset of FOL with acceptable computation speeds. One of the first and most successful compromises was to develop languages based predominately on <b>modus</b> <b>ponens,</b> i.e. IF-THEN <b>rules.</b> Rule-based systems were the predominate knowledge representation mechanism for virtually all early expert systems. Rule-based systems provided acceptable computational efficiency while still providing powerful knowledge representation. Also, rules were highly intuitive to knowledge workers. Indeed, one of the data points that encouraged researchers to develop rule-based knowledge representation was psychological research that humans often represented complex logic via rules.|$|R
50|$|We call {{generalized}} possibility every function satisfying Axiom 1 and Axiom 3. We call generalized necessity {{the dual}} of a generalized possibility. The generalized necessities are related {{with a very}} simple and interesting fuzzy logic we call necessity logic. In the deduction apparatus of necessity logic the logical axioms are the usual classical tautologies. Also, {{there is only a}} fuzzy inference rule extending the usual <b>Modus</b> <b>Ponens.</b> Such a <b>rule</b> says that if α and α → β are proved at degree λ and μ, respectively, then we can assert β at degree min{λ,μ}. It is easy to see that the theories of such a logic are the generalized necessities and that the completely consistent theories coincide with the necessities (see for example Gerla 2001).|$|R
5000|$|In mathematics, a Heyting algebra is a bounded lattice (with join {{and meet}} {{operations}} written ∨ and ∧ and with least element 0 and greatest element 1) {{equipped with a}} binary operation a → b of implication such that c ∧ a ≤ b is equivalent to c ≤ a → b. From a logical standpoint, A → B is by this definition the weakest proposition for which <b>modus</b> <b>ponens,</b> the inference <b>rule</b> A → B, A ⊢ B, is sound. Equivalently a Heyting algebra is a residuated lattice whose monoid operation a⋅b is a ∧ b; yet another definition is as a posetal cartesian closed category with all finite sums. Like Boolean algebras, Heyting algebras form a variety axiomatizable with finitely many equations. Heyting algebras were introduced by [...] to formalize intuitionistic logic.|$|R
40|$|We {{present in}} this paper a formal theory of {{reasoning}} by analogy. We are mainly concerned with three subjects : a formal definition of analogy, a formalization of the reasoning in terms of deduction, and a method for realizing the reasoning in a logic programming system. First we assume that each domain for the reasoning is the least model for logic program. Then we consider an analogy as a partial identity between the models. Secondly we introduce a notion of rule transformation which transforms rules in one domain into those in the other. Then we can formalize the reasoning as a system with three inference rules : instantiation of <b>rules,</b> <b>modus</b> <b>ponens,</b> and the <b>rule</b> transformation. Finally, based on the formalization, we present an extended pure-Prolog interpreter which performs the detection of analogy and the reasoning by the partial identity at the same time...|$|R
50|$|When {{converting}} a <b>modus</b> <b>ponens,</b> if A {{is outside}} the scope of H, then {{it will be necessary to}} apply axiom 1, A→(H→A), and <b>modus</b> <b>ponens</b> to get H→A. Similarly, if A→S {{is outside the}} scope of H, apply axiom 1, (A→S)→(H→(A→S)), and <b>modus</b> <b>ponens</b> to get H→(A→S). It should not be necessary to do both of these, unless the <b>modus</b> <b>ponens</b> step is the conclusion, because if both are outside the scope, then the <b>modus</b> <b>ponens</b> should have been moved up before H and thus be outside the scope also.|$|R
5000|$|In logic, modus non excipiens [...] {{is a valid}} rule of {{inference}} that {{is closely}} related to <b>modus</b> <b>ponens.</b> This argument form was created by Bart Verheij to address certain arguments which are types of <b>modus</b> <b>ponens</b> arguments, but must be considered to be invalid. An instance of a particular <b>modus</b> <b>ponens</b> type argument is ...|$|R
5000|$|<b>Modus</b> <b>ponens</b> {{is closely}} related to another valid form of argument, modus tollens. Both have {{apparently}} similar but invalid forms such as affirming the consequent, denying the antecedent, and evidence of absence. Constructive dilemma is the disjunctive version of <b>modus</b> <b>ponens.</b> Hypothetical syllogism {{is closely related}} to <b>modus</b> <b>ponens</b> and sometimes thought of as [...] "double modus ponens." ...|$|R
5000|$|Deduction: Bobzien's paper [...] "The Development of <b>Modus</b> <b>Ponens</b> in Antiquity" [...] {{traces the}} {{earliest}} {{development of the}} most basic principle of deduction, i.e. <b>modus</b> <b>ponens</b> (or Law of Detachment).|$|R
5000|$|For example, we {{identify}} a superintuitionistic logic L with its standard consequence relation [...] axiomatizable by <b>modus</b> <b>ponens</b> and axioms, and {{we identify}} a normal modal logic with its global consequence relation [...] axiomatized by <b>modus</b> <b>ponens,</b> necessitation, and axioms.|$|R
40|$|Nowadays, {{people start}} to accept fuzzy rule [...] based systems as {{flexible}} and convenient tools to solve a myriad of ill [...] defined but otherwise (for humans) straightforward tasks such as controlling fluid levels in a reactor, automatical lens focussing in cameras and adjusting an aircraft's navigation to the change of winds and so on. Contrary to the intuition often seen as the feeding ground of fuzzy rule [...] based systems [...] -namely, that they realize {{an extension of the}} <b>Modus</b> <b>Ponens</b> (MP) <b>rule</b> of inference to an environment with more than two truth [...] values [...] -most actual applications rely at the base level on common interpolation techniques or similarity assessments to simulate the process of "calculating with words" perceived at the user level. It is doubtful whether these somewhat opportunistic approaches will perform well when more challenging requirements (e. g. aspects of logical consistency; incorporation of varying facets of uncertainty) are imposed in order to implement a successful artificial reasoning unit. Therefore, in this paper, starting from the notion of a fuzzy restriction (i. e. the basic building block of our rule [...] based system) we list some elementary consistency requirements that a fuzzy inference system should satisfy. Subsequently we describe a reasoning methodology based on a measure of fulfilment of the antecedent clause of an if [...] then rule. Inclusion [...] based approximate reasoning, as we coined it in [7], outperforms the traditional scheme based on the Compositional Rule of Inference (CRI) in terms of both complexity and of logical soundness. In terms of semantics it also o#ers a better solution to the implementation of analogical reasoning than similarity measures are able to do...|$|R
5000|$|In propositional logic, <b>modus</b> ponendo <b>ponens</b> (Latin for [...] "the {{way that}} affirms by affirming"; {{generally}} abbreviated to MP or <b>modus</b> <b>ponens)</b> or implication elimination is {{a rule of}} inference. It can be summarized as [...] "P implies Q and P is asserted to be true, so therefore Q must be true." [...] The history of <b>modus</b> <b>ponens</b> goes back to antiquity.|$|R
