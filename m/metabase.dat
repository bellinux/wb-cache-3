36|0|Public
25|$|A {{significant}} change from previous versions of IIS {{is that all}} web server configuration information is stored solely in XML configuration files, instead of in the <b>metabase.</b> The server has a global configuration file that provides defaults, and each virtual web's document root (and any subdirectory thereof) may contain a web.config containing settings that augment or override the defaults. Changes to these files take effect immediately. This marks {{a significant departure from}} previous versions whereby web interfaces, or machine administrator access, was required to change simple settings such as default document, active modules, and security/authentication.|$|E
5000|$|IIS 6.0 <b>Metabase</b> Auditing: Allowing the {{tracking}} of <b>metabase</b> edits.|$|E
5000|$|The <b>Metabase</b> {{can also}} be {{administered}} using the <b>Metabase</b> Explorer tool {{which is part of}} the Internet Information Services (IIS) 6.0 Resource Kit Tools ...|$|E
50|$|<b>MetaBase</b> is a user-contributed {{database}} of biological databases, listing all the biological databases currently {{available on the}} internet. The initial release of <b>MetaBase</b> was derived entirely from {{the content of the}} Nucleic Acids Research (NAR) 2007 Database Issue. <b>MetaBase</b> is a wiki, using the MediaWiki software as well as the Semantic MediaWiki extension.|$|E
5000|$|When Internet Information Service starts, {{it reads}} the two <b>metabase</b> files {{to create an}} in-memory cache of the web server's configuration, which is {{referred}} to as the in-memory <b>metabase.</b> [...] Changes to the IIS configuration via the IIS Manager or programmatic changes get written to the in-memory <b>metabase,</b> then are persisted to the on-disk MetaBase.xml file after a number of changes.|$|E
5000|$|Prior to IIS 7, Microsoft's Internet Information Services stores its {{information}} in an internal database called the <b>MetaBase.</b> The <b>metabase</b> is an inheritable, hierarchical database {{that allows for}} configuration of HTTP/HTTPS, FTP, SMTP, and NNTP at the server, the site, or the folder or file level. Different versions of IIS use different formats; prior to IIS version 6 this was always a proprietary format, whereas with 6.0 and later the data is stored in XML files. The <b>metabase</b> consists of two files, MetaBase.xml and MBSchema.xml, stored in the [...] directory. The <b>metabase</b> periodically gets backed up to the [...] subdirectory.|$|E
5000|$|Apo ten Ellada sten Kina, <b>metabase</b> kai epanodos, Exantas, 2002.|$|E
50|$|The IIS Manager interface, an MMC-based {{administration}} console, is {{the primary}} means of modifying the <b>Metabase.</b> IIS also optionally provides a web-based administration console. The XML files are human-readable, and when the Allow direct <b>metabase</b> edits feature is turned on (not recommended by Microsoft) it can be viewed and edited with simple text editing software like Notepad.|$|E
50|$|Currently <b>MetaBase</b> {{contains}} {{details about}} nearly 1000 biological databases and over 800 'web services' derived from NAR, {{as well as}} more than 50 'user-contributed' databases.|$|E
5000|$|The <b>Metabase</b> is also {{programmable}} {{through several}} APIs - Admin Base Objects (ABO), Active Directory Services Interface (ADSI), Windows Management Instrumentation (WMI), and the [...]NET Framework's System.DirectoryServices and Microsoft.Web.Administration.|$|E
50|$|<b>MetaBase</b> was {{developed}} {{as part of}} the BioWiki initiative, and was entered into the first International Openfree Bioinformation Contents Competition organised by BiO.CC, the top-level biological information web site operated by Genome Research Foundation.|$|E
5000|$|Internet Information Services' central <b>metabase</b> is {{eliminated}} in IIS version 7 {{in favor of}} a set of XML configuration files that are located centrally in the [...] and [...] files and within the web site's infrastructure using [...] files. This allows for easy synchronization of web sites across servers by including all configuration information within the web site's root directory.|$|E
50|$|NTBackup {{supports}} several {{operating system}} features including backing up the computer's System State. On computers {{that are not}} domain controllers, this includes the Windows Registry, boot files, files protected by Windows File Protection, Performance counter configuration information, COM+ class registration database, IIS <b>metabase,</b> replicated data sets, Exchange Server data, Cluster service information, and Certificate Services database. On domain controllers, NTBackup can back up Active Directory, including the SYSVOL directory share.|$|E
50|$|An {{important}} {{resource for}} finding biological databases {{is a special}} yearly {{issue of the journal}} Nucleic Acids Research (NAR). The Database Issue of NAR is freely available, and categorizes many of the publicly available on line databases related to biology and bioinformatics. A companion database to the issue called the Online Molecular Biology Database Collection lists 1,380 online databases. Other collections of databases exist such as <b>MetaBase</b> and the Bioinformatics Links Collection.|$|E
50|$|A {{significant}} change from previous versions of IIS {{is that all}} web server configuration information is stored solely in XML configuration files, instead of in the <b>metabase.</b> The server has a global configuration file that provides defaults, and each virtual web's document root (and any subdirectory thereof) may contain a web.config containing settings that augment or override the defaults. Changes to these files take effect immediately. This marks {{a significant departure from}} previous versions whereby web interfaces, or machine administrator access, was required to change simple settings such as default document, active modules, and security/authentication.|$|E
50|$|In Windows XP, {{there are}} some {{improvements}} made to System Restore compared to Windows Me. System Restore uses a copy-on-write file system filter driver for taking snapshots. In Windows XP, System Restore is configurable per volume and the data stores are also stored per volume. On NTFS volumes, the Restore Points are stored using NTFS compression and protected using ACLs. A Disk Cleanup handler allows deleting {{all but the most}} recent Restore Point. Besides the Registry hives and system files, COM+ and WMI databases and the IIS <b>metabase</b> can also be restored. System Restore supports Group Policy. System Restore in Windows XP also works without issues with EFS-encrypted files.|$|E
5000|$|Binary {{file and}} memory I/O are {{provided}} by the [...] "ADODB.Stream" [...] class, which {{can also be used}} for string builders (to avoid excessive string concatenation, which can be costly), and to interconvert byte arrays and strings. Database access is made possible through ActiveX Data Objects (ADO), and the IIS <b>Metabase</b> can be manipulated using the GetObject (...) function with sufficient permissions (useful for creating and destroying sites and virtual directories). XML files and schemas can be manipulated with the Microsoft XML Library Application Programming Interfaces (msxml6.dll, msxml3.dll), which also can be used to retrieve content from the World Wide Web via the XMLHTTP and ServerXMLHTTP objects (class strings [...] "MSXML2.XMLHTTP.6.0" [...] and [...] "MSXML2.ServerXMLHTTP.6.0", respectively).|$|E
5000|$|This {{system also}} {{supported}} a dynamically-generated [...] "Rich Media Reference" [...] (a.k.a. Google's Infobox) {{which not only}} displayed metadata about the searched entity pulled from the ontology and <b>metabase</b> but also provided what was termed [...] "blended semantic browsing and querying" [...] He also led efforts in other forms/modality of data, including social and sensor data. He coined the term Semantic Sensor Web and initiated and co-chaired the W3C effort on Semantic Sensor Networking [...] {{that resulted in a}} de-facto standard. He introduced the concept of semantic perception to reflect the process of converting massive amounts of IoT data into higher level abstractions to support human cognition and perception in decision making, which involves an IneelegO ontology-enabled abductive and deductive reasoning framework for iterative hypothesis refinement and validation .|$|E
40|$|In {{this paper}} we propose a new {{technique}} for processing the non state scales quantification questions. The method, AWMK (answering with <b>metabase</b> and knowledge base), handles heterogeneous information from a large data source which is scattered into several tabulated files. AWMK makes use of our new concept, namely, <b>metabase.</b> A <b>metabase</b> is a "rich" indexed file to facilitate the retrieval of information from the knowledge base and tabulated files. The architecture AWMK makes use of <b>metabase,</b> knowledge base system, database, decoder, encoder, lexicon and accommodator. The system that incorporates different components of AWMK is described in detail. As a result of this investigation, AWMK is applied to a real-world problem, the interpretation of laser-material experiments, this without using a database management system...|$|E
40|$|A {{system and}} method for {{creating}} a database of metadata (<b>metabase)</b> {{of a variety of}} digital media content, including TV and radio content delivered on Internet. This semantic-based method captures and enhances domain or subject specific metadata of digital media content, including the specific meaning and intended use of original content. To support semantics, a WorldModel is provided that includes specific domain knowledge, ontologies as well as a set of rules relevant to the original content. The <b>metabase</b> may also be dynamic in that it may track changes to the any variety of accessible content, including live and archival TV and radio programming...|$|E
40|$|Current {{state of}} Russian {{databases}} for substances and materials properties was considered. A {{brief review of}} integration methods of given information systems was prepared and a distributed databases integration approach based on <b>metabase</b> was proposed. Implementation details were mentioned on the posed database on electronics materials integration approach. An operating pilot version of given integrated information system implemented at IMET RAS was considered...|$|E
40|$|The article {{presents}} {{the features of}} the development, systematization and use of such secondary sources of epidemiological evidences as guidelines and decision analysis. The sources, classification and role of economic evidences were described. The advantages of finding evidences in TRIP computer <b>metabase</b> are proved. Conclusions about {{the current state of the}} problem of information support for evidence-based health care, primary care and preventive direction are given...|$|E
40|$|National audienceThe aim of {{this article}} is to create a unique medical record {{structure}} from the <b>metabase</b> of any medical record. The work proposes the design of transformation algorithms which consists in translating the legacy relational database (RDB) into a unique medical record structure by analysing the correlation between the legacy RDB keys and the classification of the relations into four types : base relation, dependent relation, inheritance relation and composite relation...|$|E
40|$|We {{describe}} a technique {{for the control}} of production rules firing in an object-oriented setting. This technique {{is based on the}} separation of control rules from ordinary domain rules. Control rules operate on "control objects " which are created during the reasoning process of the rule base under control. They constitute a separate and independent rule base which contains a declarative specification of the control strategy. Control objects build up an inheritance hierarchy and the associated <b>metabase</b> is constructed via rule base inheritance in a hierarchical manner which parallels the taxonomy of control object classes...|$|E
40|$|Information {{retrieval}} over semantic metadata {{has recently}} received {{a great amount}} of interest in both industry and academia. In particular, discovering complex and meaningful relationships among this data is becoming an active research topic. Just as ranking of documents is a critical component of today 2 ̆ 7 s search engines, the ranking of relationships will be essential in tomorrow 2 ̆ 7 s semantic analytics engines. Building upon our recent work on specifying these semantic relationships, which we refer to as Semantic Associations, we demonstrate a system where these associations are discovered among a large semantic <b>metabase</b> represented in RDF. Additionally we employ ranking techniques to provide users with the most interesting and relevant results...|$|E
40|$|Abstract. Our {{research}} and development activities in digital libraries raised relevant features in supporting Web information integration. Underlain by an in house multi-agent based architecture, the main achievements {{so far have been}} prototyped as services: (a) various semantic interoperability niches, by the use of inter-ontological relationships built onto iscapes (a means of specifying information requests using embedded context sensitive information); (b) integrated access to information, by automating <b>metabase</b> (a database of metadata) creation; (c) a framework for creating iscapes and metadata modeling; and (d) information processing, by query planning and cost modeling of Web sources. A real-world application scenario illustrates how geographical and environmental Web-based information systems can benefit from appropriating these facilities...|$|E
40|$|The {{methods and}} {{software}} for integration of databases (DBs) on inorganic material and substance properties have been developed. The information systems integration {{is based on}} known approaches combination: EII (Enterprise Information Integration) and EAI (Enterprise Application Integration). The <b>metabase</b> - special database that stores data on integrated DBs contents is an integrated system kernel. Proposed methods have been applied for DBs integrated system creation {{in the field of}} inorganic chemistry and materials science. Important developed integrated system feature is ability to include DBs that have been created by means of different DBMS using essentially various computer platforms: Sun (DB "Diagram") and Intel (other DBs) and diverse operating systems: Sun Solaris (DB "Diagram") and Microsoft Windows Server (other DBs) ...|$|E
40|$|We {{describe}} a technique {{for the control}} of production rules firing in an object-oriented setting. This technique {{is based on the}} separation of control rules from ordinary domain rules. Control rules operate on "control objects" which are created during the reasoning process of the rule base under control. They constitute a separate and independent rule base which contains a declarative specification of the control strategy. Control objects build up an inheritance hierarchy and the associated <b>metabase</b> is constructed via rule base inheritance in a hierarchical manner which parallels the taxonomy of control object classes. AI Topic: Knowledge Engineering Domain area : Explicit control of reasoning Language: Smalltalk- 80 Status: Research Application Effort: 1 person-years Impact: This architecture is used for real time monitoring of patients in intensive care units. 1. Introduction In 1987 Atkinson and Laursen showed how firstorder, forward-chaining rules could be accommodated in S [...] ...|$|E
40|$|Today we {{are faced}} with an {{increasing}} demand for more and more complex database applications. The rapid growth has stimulated the need for a high level concepts, tools and techniques for a database design, development and retrieval with a final goal: better information quality. One of the new possibilities is using a meta data model repository with reusable components (<b>MetaBase).</b> Even more, just as important as reusability is in such a concept the quality dimension of reusable components which enables more expedient and efficient design of the high quality data models. As a consequence, data quality as well as information quality of any information system improves. In the paper the influence of reusability on the information quality, quality dimensions of the meta data model repository and influence of TQM {{as well as some of}} Deming’s fourteen points will be presented and discussed in more details. ...|$|E
40|$|Syntax Tree (AST) or {{the more}} {{sophisticated}} Abstract Semantics Graph (ASG), to represent the semantic content of programs. Such a representation scheme appears to be appropriate to our needs as well. Because we wish to represent a variety of metamodels within a single <b>metabase,</b> the graph used to represent the metadata must be flexible. The approach we adopt {{is to use a}} regular, common structure for the graph plus a set of language-independent primitives from which multiple, language-specific representations can be defined. The primitives capture, in a language-independent manner, the structural and semantic concepts of the language being represented. The language-specific concepts are uniformly described within the representation (i. e., as data) to allow the development of general-purpose tools that can exhibit language-specific behavior by dynamically discovering the specifics within the representation. Language-specific tools can also be supported, if the representation is properly [...] ...|$|E
40|$|Translation studies {{researchers}} {{have for a}} long time critically engaged with the idea of translation being a mode of creative rewriting across media and cultural or temporal divides. Adaptation studies experts use a similar premise to study products, processes and reception of adaptations for specific locales. This article combines such perspectives in order to shed light on an under-researched area of comic adaptation: this is the <b>metabase,</b> or transfer, of Aristophanic comedies to the comic book format in Greek and their subsequent translation into English for an e-book edition (Metaichmio Publications 2012). The paper suggests a model for the close reading of creative transfer based on Lefèvre’s (2011; 2012) typology of formal properties of comics and Attardo’s (2002) General Theory of Verbal Humour. As is shown, visual rhythm and text-image relations create a rich environment for anachronism, parody, comic characterisation and ideological comments, all of which serve a condensed plot. The English translation rewrites cultural/ideological references, amplifies obscenity and emphasizes narrator visibility, always taking into consideration the mise en scène...|$|E
40|$|International audienceTrophic {{indicators}} {{were used}} to compare two Malian freshwater reservoirs whose main differences are based on their different fishing pressures. Data were collected from a scientific survey of small-scale fishery landings conducted in 2002 / 2003. The trophic levels of fish species caught by artisanal fisheries are estimated from observations of scientific fishing or from the <b>metabase</b> Fishbase. Important differences exist in the trophic structure of both reservoirs. In Selingue (with high fishing pressure), very few top predators {{are found in the}} catches while the low trophic level fishes increase in total catches. In Manantali (with low fishing pressure), the top predators contribute twice as much to catches compared to Selingue. Hence, the mean trophic level of catches in Selingue (2. 80) is lower than in Manantali (2. 97). When comparing these results with those of study made in 1994 / 1995, it clearly appears that the effects of the fishing pressure in Selingue are obvious through a decrease of 0. 12 in the mean trophic level while in Manantali this mean level has increased by 0. 33 due to a recent strategic targeting of top predators. Trophic spectra seem to be relevant tools to characterize exploited fish communities from multi-specific and multi-gear small-scale fisheries catch dat...|$|E
40|$|Biology is {{generating}} {{more data}} than ever. As a result, {{there is an}} ever increasing number of publicly available databases that analyse, integrate and summarize the available data, providing an invaluable resource for the biological community. As this trend continues, there is a pressing need to organize, catalogue and rate these resources, so that the information they contain can be most effectively exploited. <b>MetaBase</b> (MB) ([URL] is a community-curated database containing more than 2000 commonly used biological databases. Each entry is structured using templates and can carry various user comments and annotations. Entries can be searched, listed, browsed or queried. The database was created using the same MediaWiki technology that powers Wikipedia, allowing users to contribute on many different levels. The initial release of MB {{was derived from the}} content of the 2007 Nucleic Acids Research (NAR) Database Issue. Since then, approximately 100 databases have been manually collected from the literature, and users have added information for over 240 databases. MB is synchronized annually with the static Molecular Biology Database Collection provided by NAR. To date, there have been 19 significant contributors to the project; each one is listed as an author here to highlight the community aspect of the project. open 7...|$|E
40|$|De la Rosa et al. [...] Software version 2. 00. [...] Http://www. microleis. com Http://www. fao. org/AGLSDBm Plus: FAO-CSIC Multilingual Soil Profile Database is a {{derivative}} from the SDBm database (FAO-ISRIC-CSIC, World Soil Resources Reports 81, 1995) {{which has been}} developed by CSIC/IRNAS with the collaboration of FAO/AGLL through a joint project (Letter of Agreement PR 15621, 7. 12. 1999), during 1999 and 2000. The initial version of SDBm was the SDB database (FAO-ISRIC, World Soil Resources Reports 64, 1989). As its predecessors, SDBm Plus is an ‘open’ system which can be modified in the future. SDBm Plus has been totally re-designed and re-written as a WINDOWS application. It is a user-friendly software designed to harmonise, store and use large amounts of geo-referenced soil profile data, elaborated {{in the field and}} the laboratory, in an efficient and systematic way. The soil profile database can be utilised regardless of scale, at regional, national or local level, in soil monitoring and evaluation (M&E). The main characteristics of this database are the following: i) software development for WINDOWS platforms; ii) multilingual function and automatic translation from English, as source language, to other target languages (so far Spanish, French and German); iii) detailed soil profile characterisation following the conventional procedures of soil survey, making use of ‘assist menus’ in the selected language which greatly facilitates data storage; iv) possibility of monitoring the temporal variability of analytical, physical and hydraulic soil properties; v) <b>metabase</b> facility to describe the methods used in the laboratory analysis; and vi) interface facility to automatize the linkage of soil data to computerised information systems. FAO (Food and Agriculture Organization) CSIC (Consejo Superior de Investigaciones Científicas) MIMAM (Ministerio Español de Medio Ambiente) CEC DGXII (European Commission, Science DG) Peer reviewe...|$|E
40|$|The study {{analysed}} existing databases {{for agricultural}} market data on errors and discrepancies and to elaborate {{the possibilities to}} harmonise datasets for policy modelling. The study supports DG AGRI in improving quality and timely availability of data for market modelling and ensuring that data from different sources are consistent. This study aims to provide a structure for a consolidated database for policy modelling which does not alter existing databases. Within this report, existing databases are analysed to derive key insights for setting-up a harmonised <b>metabase.</b> As available databases comprise statistical databases as well as scientific model databases, both groups are studied. For {{the purpose of this}} study, statistical databases are defined as providers of the information that international institutes receive from their reporters, while the reporters are required to provide harmonised, complete, consistent, and where possible, timely data series for establishing models or other quantitative methods. Nevertheless, a statistical database can also serve as a model database, such as e. g. PS&D. Statistical databases from international institutions (FAO, USDA, Eurostat), as well as model databases (AGLINK/COSIMO, AGMEMOD, CAPRI/CAPSIM, ESIM, FAPRI, GTAP, FARM, IMPACT), were studied to find ways of consolidating data and providing insights that allow for a better comparison of model results. For this reason, various classification schemes used in agricultural statistics were reviewed (country, product, balance item, year, unit), as was {{the manner in which the}} different modelling groups have dealt with these classifications in their databases. Besides a common classification, a harmonised database for market modelling purposes will require further efforts to be applied to a consolidation effort for the original data. Such a procedure must be supplemented by methods dealing with completion and balancing. JRC. J. 5 -Agriculture and Life Sciences in the Econom...|$|E

