594|213|Public
5|$|The Itanium 2 {{processor}} {{was released}} in 2002, and was marketed for enterprise servers rather than for the whole gamut of high-end computing. The first Itanium2, code-named McKinley, was jointly developed by HP and Intel. It relieved many of the performance problems of the original Itanium processor, which were mostly caused by an inefficient <b>memory</b> <b>subsystem.</b> McKinley contains 221 million transistors (of which 25 million are for logic), measured 19.5mm by 21.6mm (421mm2) and was fabricated in a 180nm, bulk CMOS process with six layers of aluminium metallization.|$|E
25|$|In {{terms of}} its random-access memory, or RAM, the Nintendo 64 {{is one of the}} first modern {{consoles}} to implement a unified <b>memory</b> <b>subsystem,</b> instead of having separate banks of memory for CPU, audio, and video, for example. The memory itself consists of 4 megabytes of RDRAM, made by Rambus. The RAM is expandable to 8MB with the Expansion Pak. Rambus was quite new at the time and offered Nintendo a way to provide a large amount of bandwidth for a relatively low cost.|$|E
25|$|The {{first major}} {{commercial}} application of Cell was in Sony's PlayStation 3 game console. Mercury Computer Systems has a dual Cell server, a dual Cell blade configuration, a rugged computer, and a PCI Express accelerator board available in {{different stages of}} production. Toshiba had announced plans to incorporate Cell in high definition television sets, but seems to have abandoned the idea. Exotic features such as the XDR <b>memory</b> <b>subsystem</b> and coherent Element Interconnect Bus (EIB) interconnect appear to position Cell for future applications in the supercomputing space to exploit the Cell processor's prowess in floating point kernels.|$|E
5000|$|... 48-bit memory {{addressing}} {{to allow for}} 256 TB <b>memory</b> <b>subsystems</b> ...|$|R
2500|$|... by Ulrich Drepper— {{explains}} {{the structure of}} modern <b>memory</b> <b>subsystems</b> and suggests how to utilize them efficiently ...|$|R
30|$|Memtester 4.3 : It is {{a utility}} program for testing <b>memory</b> <b>subsystems</b> for faults. It {{is used to}} impose memory workload.|$|R
500|$|Xbox One {{is powered}} by an AMD [...] "Jaguar" [...] Accelerated Processing Unit (APU) with two quad-core modules totaling eight x86-64 cores clocked at 1.75GHz, and 8GB of DDR3 RAM with a memory {{bandwidth}} of 68.3GB/s. The <b>memory</b> <b>subsystem</b> also features an additional 32 MB of [...] "embedded static" [...] RAM, or ESRAM, with a memory bandwidth of 109GB/s. For simultaneous read and write operations, the ESRAM is capable of a theoretical memory bandwidth of 192GB/s and that a memory bandwidth of 133GB/s has been achieved with operations that involved alpha transparency blending. The system includes a non-replaceable hard drive and a Blu-ray Disc optical drive. 138GB of hard drive space {{is used by the}} operating system, with the remainder available for the storage of games. Since the June 2014 software update, up to two USB drives can be connected to Xbox One to expand its capacity. External drives must support USB 3.0 and have a capacity of at least 256GB.|$|E
50|$|The modules and the <b>memory</b> <b>subsystem</b> of the DEC 7000/1000 {{supports}} interleaving. Modules {{with more}} than two strings supports two-way interleaving. At a system level, the <b>memory</b> <b>subsystem</b> supports a maximum of eight-way interleaving. If the configuration results in more levels of interleaving than the <b>memory</b> <b>subsystem</b> can support, multiple memory modules are then grouped into larger banks so the level of interleaving in the <b>memory</b> <b>subsystem</b> does not exceed the maximum of eight ways.|$|E
50|$|The SIMMs are two-way {{interleaved}} {{using the}} low-order method, where even and odd memory addresses {{are treated as}} separate banks of memory. Interleaving the <b>memory</b> <b>subsystem</b> doubles the bandwidth of a non-interleaved <b>memory</b> <b>subsystem</b> using the same DRAMs, allowing the Model 200 Series to achieve an effective maximum bandwidth of 100 MB/s.|$|E
50|$|Improvements to the <b>memory</b> <b>subsystems</b> {{of these}} machines, {{replacing}} the 1.8µs core with 0.75µs core, were introduced as the F series.|$|R
40|$|Although {{there is}} {{variability}} in nonnative grammar learning outcomes, {{the contributions of}} training paradigm design and <b>memory</b> <b>subsystems</b> are not well understood. To examine this, we presented learners with an artificial grammar that formed words via simple and complex morphophonological rules. Across three experiments, we manipulated training paradigm design and measured subjects' declarative, procedural, and working <b>memory</b> <b>subsystems.</b> Experiment 1 demonstrated that passive, exposure-based training boosted learning of both simple and complex grammatical rules, relative to no training. Additionally, procedural memory correlated with simple rule learning, whereas declarative memory correlated with complex rule learning. Experiment 2 showed that presenting corrective feedback during the test phase did not improve learning. Experiment 3 revealed that structuring the order of training so that subjects are first exposed to the simple rule and then the complex improved learning. The cumulative findings {{shed light on the}} contributions of grammatical complexity, training paradigm design, and domain-general <b>memory</b> <b>subsystems</b> in determining grammar learning success...|$|R
40|$|Introduction to {{computer}} architecture, including <b>memory</b> <b>subsystems,</b> direct-mapped and set-associative cache and multi-level cache subsystems, direct-access devices including RAID and SCSI disk drives, processor pipelining including super-scalar and vector machines, parallel architectures including SMP, NUMA and distributed memor...|$|R
5000|$|The A6X {{features}} a 1.4 GHz custom Apple-designed ARMv7-A architecture based dual-core CPU called Swift, {{introduced in the}} Apple A6. It includes an integrated quad-core PowerVR SGX554MP4 graphics processing unit (GPU) running at 300 MHz and a quad-channel <b>memory</b> <b>subsystem.</b> [...] The <b>memory</b> <b>subsystem</b> supports LPDDR2-1066 DRAM, increasing the theoretical memory bandwidth to 17 GB/s.|$|E
5000|$|Multi-core device {{based on}} the MIPS {{architecture}} with integrated physics acceleration hardware and <b>memory</b> <b>subsystem</b> with [...] "tons of cores" ...|$|E
5000|$|Performance {{evaluation}} of highly concurrent computers B. Kumar and E. S. DavidsonObject of the simulation is CPU <b>memory</b> <b>subsystem</b> IBM 360/91.|$|E
40|$|Substantial {{effort is}} {{currently}} being devoted to speeding up hard-to-parallelize non-numerical applications such as SPECint codes. Designers build sophisticated out-of-order processors, with carefully-tuned execution engines and <b>memory</b> <b>subsystems.</b> Unfortunately, these systems tend to combine high design complexity with diminishing performance returns, motivating th...|$|R
40|$|We {{present a}} {{methodology}} for comprehensively evaluating architectural and technological alternatives of the processor, cache hierarchy, system interconnect, and main <b>memory</b> <b>subsystems.</b> We use the methodology {{to explore the}} design of an 8 -way superscalar microprocessor implemented in 0. 3 micron technology and employed in a high-performance workstation. We discuss the cache hierarchy design challenges encountered with a highly-integrated wide-issue processor, and evaluate new approaches to multi-porting first level data caches and pipelining large on-chip second level caches. Exploring Design Alternatives for a Highly-Integrated, Wide-Issue, Microprocessor-Based System Abstract: We present a methodology for comprehensively evaluating architectural and technological alternatives of the processor, cache hierarchy, system interconnect, and main <b>memory</b> <b>subsystems.</b> We use the methodology to explore the design of an 8 -way superscalar microprocessor implemented in 0. 3 micron technology and [...] ...|$|R
2500|$|A {{group of}} vendors, {{including}} Intel, Dell, and Microsoft, formed a Non-Volatile Memory Host Controller Interface (NVMHCI) Working Group. The {{goal of the}} group is to provide standard software and hardware programming interfaces for nonvolatile <b>memory</b> <b>subsystems,</b> including the [...] "flash cache" [...] device connected to the PCI Express bus.|$|R
50|$|Buses {{are often}} not emulated, either for reasons of {{performance}} or simplicity, and virtual peripherals communicate directly with the CPU or the <b>memory</b> <b>subsystem.</b>|$|E
50|$|Samson oversaw {{manufacturing}} and engineering for hardware, including the central <b>memory</b> <b>subsystem</b> for the ILLIAC IV supercomputer complex at the NASA Ames Research Center.|$|E
5000|$|HiFi EP Audio DSP — A superset of HiFi 2 with {{advanced}} optimizations for DTS Master Audio, improved voice pre- and post-processing, and improved cache <b>memory</b> <b>subsystem</b> ...|$|E
40|$|Abstract—Energy {{consumption}} and power draw pose two major {{challenges to the}} HPC community for designing larger systems. Present day HPC systems consume as much as 10 MW of electricity and this is fast becoming a bottleneck. Although energy bills will significantly increase with machine size, power consumption is a hard constraint that must be addressed. Intel’s Running Average Power Limit (RAPL) toolkit is a recent feature that enables power capping of CPU and <b>memory</b> <b>subsystems</b> on modern hardware. In this paper, we use RAPL to evaluate the possibility of improving execution time efficiency of an application by capping power while adding more nodes. We profile the strong scaling of an application using different power caps for both CPU and <b>memory</b> <b>subsystems.</b> Our proposed interpolation scheme uses an application profile to optimize the number of nodes {{and the distribution of}} power between CPU and <b>memory</b> <b>subsystems</b> to minimize execution time under a strict power budget. We validate these estimates by running experiments on a 20 -node (120 cores) Sandy Bridge cluster. Our experimental results closely match the model estimates and show speedups greater than 1. 47 X for all applications compared to not capping CPU and memory power. We demonstrate that the quality of solution that our interpolation scheme provides matches very closely to results obtained via exhaustive profiling. I...|$|R
40|$|Modern {{machines}} present two {{challenges to}} algorithm engineers and compiler writers: They have superscalar, super-pipelined structure, {{and they have}} elaborate <b>memory</b> <b>subsystems</b> specifically designed to reduce latency and increase bandwidth. Matrix multiplication is a classical benchmark for experimenting with techniques used to exploit machine architecture and to overcome the limitations of contemporary <b>memory</b> <b>subsystems.</b> This research aims at advancing {{the state of the}} art of algorithm engineering by balancing instruction level parallelism, two levels of data tiling, copying to provably avoid any cache conflicts, and prefetching in parallel to algorithmic operations, in order to fully exploit the memory bandwidth. Measurements show that the resultant matrix multiplication algorithm outperforms IBM's ESSL by 6. 8 - 31. 8 %, is less sensitive to the size of the input data, and scales better. The techniques presented in this paper have been developed specifically for matrix multipli [...] ...|$|R
40|$|The goal of {{the present}} study was to examine the extent to which working memory {{supports}} the maintenance of object locations during active spatial navigation. Participants were required to navigate a virtual environment and to encode the location of a target object. In the subsequent maintenance period they performed one of three secondary tasks that were designed to selectively load visual, verbal or spatial working <b>memory</b> <b>subsystems.</b> Thereafter participants re-entered the environment and navigated back to the remembered location of the target. We found that while navigation performance in participants with high navigational ability was impaired only by the spatial secondary task, navigation performance in participants with poor navigational ability was impaired equally by spatial and verbal secondary tasks. The visual secondary task had no effect on navigation performance. Our results extend current knowledge by showing that the differential engagement of working <b>memory</b> <b>subsystems</b> is determined by navigational ability...|$|R
5000|$|The PowerXCell 8i {{which is}} {{a version of the}} Cell BE with {{enhanced}} FPU and <b>memory</b> <b>subsystem.</b> It was only manufactured as a singe 65 nm version.|$|E
50|$|The Itanium 2 {{processor}} {{was released}} in 2002. It relieved many of the performance problems of the original Itanium processor, which were mostly caused by an inefficient <b>memory</b> <b>subsystem.</b>|$|E
5000|$|In a PCI Express (PCIe) system, a root complex device {{connects the}} {{processor}} and <b>memory</b> <b>subsystem</b> to the PCI Express switch fabric composed {{of one or}} more switch devices.|$|E
40|$|As {{internet}} routers {{scale to}} support next-generation networks, their <b>memory</b> <b>subsystems</b> must also scale. Several solutions combine static RAM and dynamic RAM buffering but still have major scaling limitations. Using a parallel architecture and distributed memory-management algorithms with hybrid SRAM/DRAM improves buffering performance. The parallel hybrid SRAM/DRAM memory system is also work conserving, which {{is particularly important}} under light traffic conditions...|$|R
40|$|In {{this paper}} we compare single-processor {{performance}} of the SGI Origin and PowerChallenge and utilize a previously-reported performance model for hierarchical memory systems to explain the results. Both the Origin and PowerChallenge use the same microprocessor (MIPS R 10000) but have significant differences in their <b>memory</b> <b>subsystems.</b> Our <b>memory</b> model includes the effect of overlap between CPU and memory operations an...|$|R
40|$|International SoC Design Conference (ISOCC 2008) : November 24 - 25, 2008 : Busan, KoreaEmploying a small L 0 -cache between anMPU {{core and}} an L 1 -cache {{is one of}} the most {{promising}} approaches for reducing the energy consumption of <b>memory</b> <b>subsystems.</b> Since the L 0 -cache is small, if there is a hit, the energy consumption will be reduced. On the other hand, if there is a miss, one extra cycle is required to access the L 1 -cache. This leads to a degradation of the processor performance. For resolving this problem, a Single cycle accessible Two-level Cache (STC) architecture is proposed in this paper. This architecture makes it possible to access to both the L 0 and the L 1 caches from an MPU core in a cycle. Experiments using several benchmark programs demonstrate that the STC architecture reduces the energy consumption of <b>memory</b> <b>subsystems</b> by 13 % without any performance degradation compared to the best results obtained by previous approaches...|$|R
50|$|About {{half of the}} {{performance}} boost over A8 comes from the 1.85 GHz frequency. About a quarter comes from the better <b>memory</b> <b>subsystem</b> (3× bigger caches). The remaining quarter comes from the microarchitectural tuning and smaller technology node.|$|E
50|$|Hardware {{interrupts}} {{were introduced}} as an optimization, eliminating unproductive waiting time in polling loops, waiting for external events. They may {{be implemented in}} hardware as a distinct system with control lines, {{or they may be}} integrated into the <b>memory</b> <b>subsystem.</b>|$|E
50|$|Downsides of the Intel's lockstep memory layout are the {{reduction}} of effectively usable amount of RAM (in case of a triple-channel memory layout, maximum amount of memory reduces to {{one third of the}} physically available maximum), and reduced performance of the <b>memory</b> <b>subsystem.</b>|$|E
40|$|Motivated by the {{increasing}} popularity of hosting in-memory big-data analytics in cloud, {{we present a}} profiling methodology that can understand how different <b>memory</b> <b>subsystems,</b> i. e., cache and memory bandwidth, are susceptible {{to the impact of}} interference from co-located applications. We first describe the design of the proposed tool and demonstrate a case study consisting of five Spark applications on real-life data set. Peer ReviewedPostprint (published version...|$|R
30|$|Since {{predictability}} {{of performance}} {{is critical in}} microprocessors design, simulation models {{can be used to}} evaluate architectural alternatives and assist in making informed decisions. Simulation is an acceptable performance modeling technique {{that can be used to}} evaluate architectural alternatives and features. In this work, we used Virtual System Prototyping and simulation to investigate the performance of the <b>memory</b> <b>subsystems</b> of both, the Opeteron, and the Xeon dual core processors.|$|R
50|$|A {{center of}} each cell is an ASIC called cell {{controller}} (CC), that connects to four processor sockets (providing an average of 1.6 GB/s of bandwidth per socket), to four local <b>memory</b> <b>subsystems,</b> and to the backplane. The CC itself contains a crossbar, and four CCs interconnect via a second-level crossbar. In maximum machine's configuration four second-level crossbars interconnect with each other, supporting in total 64 processor sockets.|$|R
