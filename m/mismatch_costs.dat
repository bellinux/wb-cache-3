11|38|Public
40|$|Many {{people believe}} that {{prevailing}} commission rates for residential real estate brokers are "too high" but do not offer a formal model. This paper presents a general equilibrium model of the housing market in which real estate brokers serve as matching intermediaries. We use this model to construct an illustrative example which is "calibrated" using data representative of a typical housing market. real estate brokers, commission rate, matching technology, <b>mismatch</b> <b>costs,</b> idiosyncratic tastes...|$|E
40|$|The newsvendor model {{captures the}} {{trade-off}} faced by a decision maker {{that needs to}} place a firm bet prior to the occurrence of a random event. Previous research in operations management has mostly focused on deriving the decision that minimizes the expected <b>mismatch</b> <b>costs.</b> In contrast, we present two methods that estimate the unobservable cost parameters characterizing the mismatch cost function. We present a structural estimation framework that accounts for heterogeneity in the uncertainty faced by the newsvendor {{as well as in}} the cost parameters. We develop statistical methods that give consistent estimates of the model primitives, and derive their asymptotic distribution, which is useful to do hypothesis testing. We apply our econometric model to a hospital that balances the costs of reserving too much versus too little operating room capacity to cardiac surgery cases. Our results reveal that the hospital places more emphasis on the tangible costs of having idle capacity than on the costs of schedule overrun and long working hours for the staff. We also extend our structural models to incorporate external information on forecasting biases and <b>mismatch</b> <b>costs</b> reported by the medical literature. Our analysis suggests that overconfidence and incentive conflicts are important drivers of the frequency of schedule overruns observed in our sample. newsvendor model, empirical research, health care, structural estimation, operating room reservation...|$|E
40|$|We {{study the}} {{competitive}} effects of restricting {{direct access to}} secondary care by gatekeeping, focusing on the informational role of general practitioners (GPs). In the secondary care market there are two hospitals choosing quality and specialisation. Patients, who are ex ante uninformed, can consult a GP to receive an (imperfect) diagnosis and obtain information about the secondary care market. We show that hospital competition is amplified by higher GP attendance but dampened by improved diagnosing accuracy. Therefore, compulsory gatekeeping may result in excessive quality competition and too much specialisation, unless the <b>mismatch</b> <b>costs</b> and the diagnosing accuracy are sufficiently high. Second-best price regulation makes direct regulation of GP consultation redundant, but will generally not implement first-best. gatekeeping, imperfect information, quality competition, product differentiation, price regulation...|$|E
40|$|In an {{experimental}} newsvendor setting we investigate three phenomena: Level behavior ? the decision-maker's average ordering tendency; adjustment behavior ? {{the tendency to}} adjust period-to-period order quantities; and observation bias ? the tendency to let the degree of demand feedback influence order quantities. We find that the portion of <b>mismatch</b> <b>cost</b> due to adjustment behavior exceeds the portion of <b>mismatch</b> <b>cost</b> due to level behavior in {{three out of four}} conditions. Observation bias is studied through censored demand feedback, a situation which arguably represents the majority of newsvendor settings. When demands are uncensored, subjects tend to order below the normative quantity when facing high margin and above the normative quantity when facing low margin, but in neither case beyond mean demand (a. k. a. the pull-to-center effect). Censoring in general leads to lower quantities, magnifying the below-normative level behavior when facing high margin but partially counterbalancing the above-normative level behavior when facing low margin, violating the pull-to-center effect in both cases. ...|$|R
40|$|We {{consider}} a commodity procurement problem where a firm satisfies a future customer demand with uncertainty risk via spot trading and forward sourcing. Although the firm can make demand forecast update and hence, remove demand uncertainty when the selling season arrives, {{it is still}} susceptible to a high emergency logistics cost at that time spot. Therefore, in this paper, the tradeoff between the <b>mismatching</b> <b>cost</b> of supply and uncertain demand (highest {{at the beginning of}} the planning horizon) and the high at-once delivery cost (highest at the ending of the planning horizon) is investigated. We develop a two-stage model and derive the optimal procurement policy for the firm. We also characterize the optimal parameters by assuming demand follows a bivariate normal distribution. Finally, extensive Monte-Carlo simulation is conducted and we quantify the value of forward contracts and the value of information update, using the crude oil data...|$|R
30|$|Our {{analysis}} {{investigates the}} relevance of the <b>mismatch</b> between labor <b>cost</b> and productivity in Belgium, and links it to differences (or lack thereof) in labor market institutions across the regions.|$|R
40|$|In volatile, long-lead {{time and}} short selling-season markets, a {{secondary}} market enables buyers to update their inventory during the selling season. The decision of when to update involves complicated trade-offs between forecast accuracy, expected lost sales, and average purchasing cost. We use a two-stage inventory replenishment model {{to identify the}} optimal trading time across different scenarios. Across most scenarios the optimal trading time is around {{the midpoint of the}} season and is sensitive to the expected profit margin and demand forecast errors. We discuss the impacts of the timing decision on upstream suppliers' sales and channel performance in terms of sales revenue and supply-demand <b>mismatch</b> <b>costs.</b> Specifically, secondary market trading always reduces upstream suppliers' sales no matter when trading occurs, but trading at an optimal time can maximize a secondary market's profit gain over the no-trade scenario through reducing supply-demand mismatch. Supply chain management Electronic surplus market Information learning Entry timing Two-stage inventory replenishment...|$|E
40|$|Online review aggregators, such as TripAdvisor, HotelClub and OpenTable help {{consumers}} {{identify the}} {{products and services}} that best match their preferences. The goal {{of this study is}} to understand the impact of online review aggregators on firms and consumers. We adopt Salop’s circular city model in which consumers initially do not know the locations of the firms in the product space. The firms decide whether or not to be listed on an online review aggregator’s website and choose their prices. When a firm resorts to the aggregator, its location and price become observable to the consumers who visit the website. We consider two different scenarios, depending on the possibility for online firms to offer discounts to the consumers who book online. We show that in equilibrium not all firms will go online – some will remain offline. Online firms attract more customers than their offline counterparts due to reduced <b>mismatch</b> <b>costs,</b> but face a tougher price competition. Comparing the equilibrium prices, profits and the number of firms that go online across the scenarios, we derive interesting conclusions from the private and the social standpoints...|$|E
40|$|DNA/DNA duplex {{formation}} {{is the basic}} mechanism that is used in genome tiling arrays and SNP arrays manufactured by Affymetrix. However, detailed knowledge of the physical process is still lacking. In this study, we show a free energy analysis of DNA/DNA duplex formation these arrays based on the positional-dependent nearest-neighbor (PDNN) model, which was developed previously for describing DNA/RNA duplex formation on expression microarrays. Our {{results showed that the}} two ends of a probe contribute less to the stability of the duplexes {{and that there is a}} microarray surface effect on binding affinities. We also showed that free energy cost of a single mismatch depends on the bases adjacent to the mismatch site and obtained a comprehensive table of the cost of a single mismatch under all possible combination of adjacent bases. The <b>mismatch</b> <b>costs</b> were found to be correlated with those determined in aqueous solution. We further demonstrate that the DNA copy number estimated from the SNP array correlates negatively with the target length; this is presumably caused by inefficient PCR amplification for long fragments. These results provide important insights into the molecular mechanisms of microarray technology and have implications for microarray design and the interpretation of observed data...|$|E
40|$|Adjoint-based {{methods have}} been {{successfully}} applied by us {{to a number of}} inverse problems in shallow-water geoacoustics and acoustic tomography. These inversions were all performed in a range-independent context, using a finite-difference formulation of the wide-angle parabolic equation. In this study we consider realistic, fully range-dependent cases, where the bathymetry is variable and, more importantly, the medium properties (sound speed, density, attenuation) are variable in depth and range and can exhibit discontinuities. We adopt a finiteelement formulation, recently proposed in, and adapt it to our purposes. The finite-element method permits a geometrization and discretization that are consistent with site-specific boundaries and discontinuities. Finally, a modular graph approach is applied for generating, in a semi-automatic manner, the tangent-linear model and the back propagation needed for the gradient-based minimization of a <b>mismatch</b> <b>cost</b> function. This approach overcomes the two major difficulties of the inversion: the adjoint code is easily obtained (when compared to other automatic differentiation tools) and the subsequent minimization is rapid and robust. Various test cases will be presented that show the versatility of this new approach...|$|R
40|$|A {{policy is}} more likely to be {{economically}} efficient when its costs and benefits fall on the same group, but politicians can allocate costs and benefits to different groups within their jurisdictional commons. This article examines the distribution of costs and benefits from desalination projects using examples from San Diego, Almería and Riyadh. The examples illustrate how <b>mismatches</b> between <b>costs</b> and benefits can persist or change as politicians adjust the policy portfolio to balance inefficiency and political risk...|$|R
40|$|One of {{the most}} {{effective}} ways to minimize supply/demand <b>mismatch</b> <b>cost,</b> with little increase in operational cost, is to deploy valuable resources in a flexible and timely manner to meet the realized demand. This notion of flexible processes has significantly changed the operations in many manufacturing and service companies. For example, flexible production system is now commonly used by automobile manufacturers, and work force cross-training system is by now a common practice in many service industries. However, there is a tradeoff between the level of flexibility available in the system and the associated complexity and operational cost. The challenge is to have the “right ” level of flexibility to capture the bulk of the benefits from a full flexibility system, while controlling for the increase in implementation cost. This paper reviews the latest development on the subject of process flexibility in the past decade. In particular, we focus on the phenomenon, often observed in practice, that a slight increase in process flexibility can reap a significant amount of improvement in system performance. This review explores the issues in three perspectives: design, evaluation and applications. We also discuss how the process flexibility concept has been deployed in several manufacturing and service systems...|$|R
40|$|Understanding {{constraints}} on phenotypic plasticity {{is central to}} explaining its evolution {{and the evolution of}} phenotypes in general, yet there is an ongoing debate on the classification and relationships among types of constraints. Since plasticity is often a developmental process, studies that consider the ontogeny of traits and their developmental mechanisms are beneficial. We manipulated the timing and reliability of cues perceived by fire salamander larvae for the future desiccation of their ephemeral pools to determine whether flexibility in developmental rates is constrained to early ontogeny. We hypothesized that higher rates of development, and particularly compensation for contradictory cues, would incur greater endogenous costs. We found that larvae respond early in ontogeny to dried conspecifics as a cue for future desiccation, but can fully compensate for this response in case more reliable but contradictory cues are later perceived. Patterns of mortality suggested that endogenous costs may depend on instantaneous rates of development, and revealed asymmetrical costs of compensatory development between false positive and false negative early information. Based on the results, we suggest a simple model of costs of development that implies a tradeoff between production costs of plasticity and phenotypeenvironment <b>mismatch</b> <b>costs,</b> which may potentially underlie the phenomenon of ontogenetic windows constrainin...|$|E
40|$|Abstract Background Studies on the {{distribution}} of indel sizes have consistently found that they obey a power law. This finding has lead several scientists to propose that logarithmic gap costs, G (k) = a + c ln k, are more biologically realistic than affine gap costs, G (k) = a + bk, for sequence alignment. Since quick and efficient affine costs are currently the most popular way to globally align sequences, the goal {{of this paper is to}} determine whether logarithmic gap costs improve alignment accuracy significantly enough the merit their use over the faster affine gap costs. Results A group of simulated sequences pairs were globally aligned using affine, logarithmic, and log-affine gap costs. Alignment accuracy was calculated by comparing resulting alignments to actual alignments of the sequence pairs. Gap costs were then compared based on average alignment accuracy. Log-affine gap costs had the best accuracy, followed closely by affine gap costs, while logarithmic gap costs performed poorly. Subsequently a model was developed to explain the results. Conclusion In contrast to initial expectations, logarithmic gap costs produce poor alignments and are actually not implied by the power-law behavior of gap sizes, given typical match and <b>mismatch</b> <b>costs.</b> Furthermore, affine gap costs not only produce accurate alignments but are also good approximations to biologically realistic gap costs. This work provides added confidence for the biological relevance of existing alignment algorithms. </p...|$|E
40|$|The aim of {{this thesis}} is to find {{possible}} outcomes and enabling factors for reshoring {{in the context of}} apparel supply chains through an extensive literature review. During the last decades, most labor-intensive production has been moved to low-cost countries. A reverse movement called reshoring has recently been observed. Companies have brought back some or all of their production from offshore locations. There are many possible reasons behind this phenomenon. Companies have experienced problems such as quality issues, uncertainty, long lead times, large inventories and hidden costs with offshore production. The most important reasons for reshoring cited in academic literature reviewed for the thesis are quality, flexibility, responsiveness, cost advantage changes, labor costs, transportation costs, control, monitoring and coordinating. The cost gap between low-cost country and developed country manufacturing has decreased. A long lead time can create <b>mismatch</b> <b>costs</b> originating from over-stock or lost sales. Supply and demand can be better balanced with a shorter lead time. The location of target markets is a key factor for achieving flexibility from reshoring. Reshoring is especially fit for time-sensitive products, which have a short selling season. However, as quality is cited as the most important reason for reshoring, there is also potential for reshoring the manufacturing of products that are not time-sensitive. The research in this thesis indicates that there is potential for increasing profitability, quality and customer satisfaction in the reshoring of labor-intensive apparel production...|$|E
5000|$|The {{matching}} principle {{allows for a}} more objective analysis of profitability. By recognizing costs in the period they are incurred, a business can see how much money was spent to generate revenue, reducing [...] "noise" [...] from timing <b>mismatch</b> between when <b>costs</b> are incurred and when revenue is realized.|$|R
40|$|Artículos en revistasWholesale {{marginal}} {{electricity prices}} {{are being used}} in several actual competitive generation markets worldwide, both to remunerate generators and to charge consumption. These prices must account not only for energy, but also for guarantee of supply in the long and the short term. This paper: a) provices a sound conceptual and quantitative foundation for wholesale pricing based on generation services, where any existing restrictions in operation or planning in real power markets are accounted for, b) clearly establishes the relationship between short term marginal costs, long term marginal costs and optimal wholesale electricity prices, and c) identifies the reasons for <b>mismatches</b> in <b>cost</b> recovery with marginal generation prices. The theoretical results are verified with a detailed realistic power system model. info:eu-repo/semantics/publishedVersio...|$|R
40|$|This paper {{describes}} a procedure for the simulation of passive filters using switched-current techniques, where sensitivity re-duction is obtained by swapping the positions and roles of pairs of identical elements at successive switching periods. The tech-nique can produce significant reduction of sensitivity to element <b>mismatches</b> at low <b>cost</b> {{in terms of}} added complexity and with-out reducing the operating speed of the circuit. The technique is exemplified for application to component-simulation switched-current filters. 1...|$|R
40|$|This {{dissertation}} contains three essays. The first essay, entitled 2 ̆ 2 Pricing and Production Flexibility: An Empirical Analysis of the U. S. Automotive Industry, 2 ̆ 2 uses {{a detailed}} dataset of the U. S. auto industry {{to examine the}} relationship between production flexibility and responsive pricing. Our analysis shows that deploying production flexibility is associated with a reduction in observed discounts and with an increase in plant utilization. Our results allow quantifying some of the benefits of production flexibility. The second essay, entitled 2 ̆ 2 An Empirical Analysis of Reputation in Online Service Marketplaces, 2 ̆ 2 uses a detailed dataset from a leading online intermediary for software development services to empirically examine the role of reputation on choices and prices in service marketplaces. We find that buyers trade off reputation and price and are willing to accept higher bids posted by more reputable bidders. Sellers primarily use a superior reputation to increase their probability of being selected, as opposed to increasing their prices. Our analysis shows that the numerical reputation score has a smaller effect in situations where there exists a previous relationship between buyer and seller, when the seller has certified his or her skills, when the seller is local, or in situations that prompt higher interpersonal trust. The third essay, entitled 2 ̆ 2 The Effects of Product Line Breadth: Evidence from the Automotive Industry, 2 ̆ 2 studies the effects of product line breadth on market shares and costs, using data from the U. S. automotive industry. Our results show a positive association between product line breadth and market share and production costs. Beyond the effects on production costs, we study the effect of product line breadth on <b>mismatch</b> <b>costs,</b> which arise from demand uncertainty, and we find that product line breadth has a substantial impact on average discounts and inventories. Our results also show that platform strategies can reduce production costs and that a broader product line can provide a hedge against changes in demand conditions. ...|$|E
40|$|There {{exists a}} {{substantial}} literature on how firms should manage inventory and capacity, but less {{is known about}} what firms actually do. In practice, there is considerable heterogeneity in inventory holdings, even across firms within a single industry. The main objective of this dissertation is to use field data on actual decisions to measure which are the main drivers of inventory and capacity decisions. ^ This dissertation is composed of three essays. The first essay develops a methodology to estimate the underlying costs of a Newsvendor model based on actual decisions. We present a structural estimation framework that captures the effect of uncertainty and <b>mismatch</b> <b>costs</b> on the decisions made by the newsvendor. This econometric model is applied to a hospital that balances the costs of reserving too much vs. too little operating room capacity. The results reveal that the hospital places more emphasis on the tangible costs of having idle capacity than on the costs of schedule overrun. Over-confidence and incentive conflicts are important drivers of the frequency of schedule overruns. ^ The second and third essays analyze finished-goods inventory holdings in the U. S. automobile industry. The second essay uses panel data to measure the effect of several factors on aggregate inventory holdings of new vehicles. Four of these factors—product variety, demand variability, production flexibility and sales volume—explain a large fraction {{of the differences in}} inventory across manufacturers. ^ The third essay estimates the effect of local market conditions on inventory holdings of automobile dealerships. We collected (via a web-crawler) an original dataset on inventory and sales of auto dealerships of a large manufacturer. Using cross-sectional variation of dealers in geographically isolated markets, we estimate the effect of market structure (number and type of competitors) and sales on inventory levels. The results suggest a strong positive non-linear effect of the number of rivals on the buffer stock carried by retailers, which increases inventory. Counterfactual experiments indicate that reducing the dealership network of this manufacturer (thereby reducing competition) could reduce the remaining dealers 2 ̆ 7 days-of-supply from 14...|$|E
40|$|This {{paper was}} {{accepted}} for publication in the journal Manufacturing and Service Operations Management and the definitive published version is available at [URL] paper investigates a practical batching decision problem that arises in the batch annealing operations in the cold rolling stage of steel production faced by most large iron and steel companies in the world. The problem is to select steel coils from a set of waiting coils to form batches to be annealed in available batch annealing furnaces and choose a median coil for each furnace. The objective is to maximize the total reward of the selected coils less the total coil'coil and coil'furnace <b>mismatching</b> <b>cost.</b> For a special case of the problem that arises frequently in practical settings where the coils are all similar and {{there is only one}} type of furnace available, we develop a polynomial-time dynamic programming algorithm to obtain an optimal solution. For the general case of the problem, which is strongly NP-hard, an exact branch-and-price-and-cut solution algorithm is developed using a column and row generation framework. A variable reduction strategy is also proposed to accelerate the algorithm. The algorithm is capable of solving medium-size instances to optimality within a reasonable computation time. In addition, a tabu search heuristic is proposed for solving larger instances. Three simple search neighborhoods, as well as a sophisticated variable-depth neighborhood, are developed. This heuristic can generate near-optimal solutions for large instances within a short computation time. Using both randomly generated and real-world production data sets, we show that our algorithms are superior to the typical rule-based planning approach used by many steel plants. A decision support system that embeds our algorithms was developed and implemented at Baosteel to replace their rule-based planning method. The use of the system brings significant benefits to Baosteel, including an annual net profit increase of at least 1. 76 million U. S. dollars and a large reduction of standard coal consumption and carbon dioxide emissions...|$|R
40|$|Provision of {{continuing}} vocational training is subject to several market failures: capital-market imperfections (credit constraints), risk arising from variability of future values of skills, <b>mismatch</b> of <b>costs</b> and returns owing to worker mobility, and general positive externalities of human capital. In the light of these market imperfections we evaluate the contrasting French and British systems of adult training. French policy is interventionist and includes an employer training levy. British policy has abandoned levies and emphasizes individual initiatives by workers and employers. Despite contrasting policies, the character of training provision is similar in both countries, being mainly arranged and financed by employers. Differences are that the French system offers both higher public subsidy and cost-sharing between training and non-training employers. Training provision is higher in France and occurs earlier in the working life-cycle. We conclude British policy could usefully reconsider employer levies for solving training under-investment...|$|R
30|$|This paper {{introduces}} a new coherent detector for target detection in the clutter model of interest, which has explicit {{dependence on the}} clutter parameters. It will be shown that this detector’s probability of false alarm and threshold relationship does not vary with the clutter power level. To achieve a CFAR detector, approximations are made to these clutter parameters, together with a <b>mismatched</b> threshold. The <b>cost</b> of this is then analysed, and conditions are established under which the resultant false alarm probability is not increased to an undesirable level in practice.|$|R
30|$|Genomic DNA {{was used}} to {{generate}} short-insert (500  bp) paired-end sequencing libraries according to the Illumina standard protocol. Genomic DNA from each species was sequenced using a HiSeq™ 2000 analyzer (Illumina, San Diego, California, USA) at Beijing Genomics Institute (BGI, Shenzhen, China).The raw reads (20, 777, 674 and 20, 787, 108  bp for P. chekiangensis and P. bournei) were generated with 125  bp length and assembled into whole chloroplast genomes in a multi-step approach employing a modified pipeline that involved {{a combination of both}} reference guided and de novo assembly approaches. First, paired-end sequence reads were trimmed to remove low-quality bases (Q < 20, 0.01 probability error) and adapter sequences using CLC-quality trim tool (quality_trim software included in CLC ASSEMBLY CELL package, [URL] before undertaking sequence assembly. Second, the contigs were assembled using CLC de novo assembler with the following optimized parameters: bubble size of 98, minimum contig length of 200, <b>mismatch</b> <b>cost</b> of two, deletion and insertion costs of three, length fraction of 0.9, and similarity fraction of 0.8. Third, all the contigs were aligned to the reference chloroplast genome of Machilus yunnanensis (NC 028073) using BLAST ([URL] and aligned contigs (≥ 90 % similarity and query coverage) were ordered according to the reference chloroplast genome. Then, contigs were aligned with the reference genome to construct the draft chloroplast genome of each species in Geneious 9.0. 5 software ([URL] Finally, clean reads were re-mapped to the draft cp genomes of two Phoebe species, and the mapping ratio were 3.41 % for P. chekiangensis and 2.15 % for P. bournei, and average coverage depth were 578.2 and 367.1 for P. chekiangensis and P. bournei, respectively. Using the Dual Organellar Genome Annotator (DOGMA) program (Wyman et al. 2004), the two Phoebe chloroplast genomes were annotated. Protein-coding genes were identified by using the plastid/bacterial genetic code. Intron/exon boundaries were further determined using MAFFT v 7 with those of the M. yunnanensis chloroplast genomes as a reference (Katoh and Standley 2013). Using the program tRNAscan-SEwith default settings (Schattner et al. 2005), tRNA boundaries were verified. The circular chloroplast genome maps of the Phoebe were drawn using the Organellar Genome DRAW (OGDRAW) software, with subsequent manual editing (Lohse et al. 2007).|$|R
40|$|Managers often {{experience}} {{problems with}} quantifying {{the value of}} reducing or extending lead time when assessing different sourcing alternatives. In practice, these decisions are often made considering only unit procurement cost, transportation cost, capital cost and storage cost. However, the lead time of suppliers highly influences a business' exposure to demand uncertainty. This can yield large monetary values that should be accounted for. This Master's Thesis presents a case study within the automotive industry to show the effects of exposure to demand risk when assessing different sourcing alternatives. Building on the work done in ProjectThesis 2013, the computer program is further developed to better fit real life applications. Extending the existing geometric Brownian motion and mean reverting process, a discrete ARMA model is incorporated allowing for more flexibility in connecting demand to demand risk. Additionally, new case specific variables are added to give a more holistic view of the sourcing decision. Kongsberg Automotive's plant in Hvittingfoss, Norway (KA), and their clutch servo produced for Scania is analyzed. A thorough assessment of KA's demand structure shows that the demand is stationary, normally distributed and best described by an ARMA(1, 3) model. However, due to the similarity between ARMA(1, 3) and the mean reverting Ornstein-Uhlenbeck process, the latter {{is used for the}} case study because of its continuous nature. The mean reversion rate and demand volatility is found to be high. Utilizing the expected supply-demand <b>mismatch</b> <b>cost</b> and real options theory enables for calculation of the cost curve - an indifference curve showing the costs at which you are indifferent between lead times. Three components of the clutch servo is evaluated - the piston, piston rod and aluminum casting. Based on the cost curve, this thesis concludes whether KA should change their supplier for each of them. The cost curves show that the majority of demand risk develops the last week prior to delivery, and little risk is added at longer lead times. Therefore, KA should either acquire a short lead time to mitigate this uncertainty, or choose a long lead time to benefit from the low obtained procurement cost. An assessment of other sources of risk that potentially could alter this conclusion is also presented...|$|R
40|$|Artículos en revistasThis paper {{presents}} an in-depth analysis of network revenues computed with marginal pricing, {{and in particular}} it investigates the reasons why marginal prices fail to recover the total incurred network costs in actual power systems. The basic theoretical results are presented and the major causes of the <b>mismatch</b> between network <b>costs</b> and marginal revenues are identified and illustrated with numerical examples, some tutorial and others of real-istic size. The regulatory implications of marginal network pricing {{in the context of}} competitive electricity markets are analyzed, and suggestions are provided for the meaningful allocation of the costs of the network among its users. info:eu-repo/semantics/publishedVersio...|$|R
40|$|This paper {{builds on}} {{previous}} work aimed at unraveling {{the structure of}} the speech signal using probabilistic representations. The context of this work is a multi-pass speech recognition system in which a phone lattice is created and used as a basis for a lexical decoding pass (search) that allows symbolic <b>mismatches</b> at certain <b>costs.</b> The focus is on the optimization of the costs of the phone insertions, deletions and substitutions that are used in the lexical decoding pass. Two optimization approaches are presented, one related to a multi-pass computational model for human speech recognition, the other based on a decoding that minimizes Bayes' risks. In the final section, the advantages of the two optimization methods are discussed and compared...|$|R
40|$|An {{analysis}} method {{was developed to}} study the impact of training-test mismatch due {{to the presence of}} additive noise. The contributions of individual observation vector components to the emission cost are determined in the matched and mismatched condition and histograms are computed for these contributions in each condition. Subsequently, a measure of mismatch is defined based on differences between the two histograms. By means of two illustrative experiments it is shown to what extent this emission <b>cost</b> <b>mismatch</b> measure can be used to identify the features that cause the most important mismatch and how in certain cases this type of information may be helpful to increase recognition accuracy by applying acoustic backing-off to selected features only. Some limitations of the approach are also discussed...|$|R
40|$|This study aims {{to measure}} the effect of {{accounting}} conservatism and to identify the business activities causing firms to undervalue owners’ equity. To estimate accounting conservatism, we have followed the hypothesis that no firm over time can generate a return greater than its cost of equity, i. e. CAPM. Thus, if a firm in fact generates an excess return over time, {{we assume that the}} excess return is an estimate of accounting conservatism within that firm. The hypothesis originates from the corporate valuation model “Economic Value Added®” which tries to adjust for accounting bias. The model assumes that excess return generated by a firm is due to business goodwill, but over time the business goodwill is said to fade away, and the remaining excess return will be a constant accounting bias. When testing the hypothesis on all of the thirty firms included in the Stockholm stock exchange (OMXS 30), we find that there is a measurable accounting bias caused by heavy investment activities in intangible assets. We conclude that the accounting practices for intangibles are outdated; as today’s practices lets you capitalize only on a few of these investment expenditures, thus causing <b>mismatching</b> of <b>costs</b> and revenues. Keywords: Accounting conservatism Accounting bias Accounting relevance Excess return Return on equity Cost of equity Economic Value Added...|$|R
40|$|High and {{persistent}} unemployment, {{as well as}} its composition, e. g., high youth unemployment, suggests underlying structural problems in the French labor market. Comparisons with other industrial countries, as well as time series and cross-section empirical evidence, point to a number of potential causes of structural unemployment in France. These Include the generosity of long-term relative to short-term unemployment benefits, the minimum wage, the level of employers’ tax wedge, skills <b>mismatch,</b> and the <b>cost</b> of capital. The paper assesses recent labor market measures in France that are considered, on the whole, as {{a step in the right}} direction, and puts forward a number of additional possible measures which could help to ensure that when the economic recovery gathers pace, unemployment will decline more quickly and more substantially than in the past. ...|$|R
40|$|The {{incidence}} of educational <b>mismatch</b> and the <b>costs</b> resulting thereof, are examined from theperspective {{of gender and}} nativity status, using Canadian census data. Mismatches arise whenindividuals are “over-educated” or “under-educated” relative to the normal levels of educationin their occupation of employment. We first estimate a multinomial logit to assess thelikelihood of educational mismatch, and examine the role gender, nativity status and, forforeign-born, language ability and length of residence in Canada, play in this regard. We thenestimate earnings functions, generalized to model educational mismatches, to estimate thecosts resulting from such mismatches, and to examine whether those costs vary across new andestablished foreign-born, and what role gender plays in this regard; also examined is thequestion of whether that penalty for foreign-born converges towards {{the same level as}} that ofnative-born, as the length of residence in Canada increases. </span...|$|R
40|$|Speech {{synthesis}} is {{the process}} of converting written text into machine-generated synthetic speech. Concatenative speech synthesis systems form utterances by concatenating pre-recorded speech units. Corpus-based methods use a large inventory to select the units to be concatenated. In this paper, we design and develop an intelligible and natural sounding corpus-based concatenative speech synthesis system for the Turkish language. The implemented system contains a front-end comprised of text analysis, phonetic analysis, and optional use of transplanted prosody. The unit selection algorithm is based on commonly used Viterbi decoding algorithm of the best-path in the network of the speech units using spectral discontinuity and prosodic <b>mismatch</b> objective <b>cost</b> measures. The back-end is the speech waveform generation based on the harmonic coding of speech and overlap-and-add mechanism. Harmonic coding enabled us to compress the unit inventory size by a factor of three. In this study, a Turkish phoneme set has been designed and a pronunciation lexicon for root words has been constructed. The importance of prosody in unit selection has been investigated by using transplanted prosody. A Turkish Diagnostic Rhyme Test (DRT) word list {{that can be used to}} evaluate the intelligibility of Turkish Text-to-Speech (TTS) systems has been compiled. Several experiments have been performed to evaluate the quality of the synthesized speech and we obtained 4. 2 Mean Opinion Score (MOS) in the listening tests for our system, which is the first unit selection based system published for Turkish. 1...|$|R
40|$|How have {{socio-economic}} resources been mobilized to pay {{for public}} works from the Roman age up to twentieth-century Europe? How have the infrastructure's fundamental <b>mismatch</b> between social <b>costs</b> and benefits been solved? This chapter tries to answer these questions, first by looking at finance in a broad sense, {{as a set of}} mechanisms bringing resources to infrastructure; second by focusing on some core factors as technological and organizational change, public and private involvement, national and international drivers. A final taxonomy then outlines the macro-types of infrastructure financing that are analysed in the book, showing clearly how it is impossible to identify a unique pattern of infrastructure finance that always and everywhere is superior in terms of long-term sustainability, growth, and welfare effects. History teaches us that there are no recipes, but only a set of stories that may suggest some analogies to contemporary problems and may represent a way of testing conventional hypotheses...|$|R
40|$|Firms {{that sell}} very short life cycle {{products}} often receive quantity discounts from their suppliers and transporters for placing larger orders. Practitioners and researchers {{have begun to}} recognize the need to decide {{the end of the}} season markdowns by studying the sales pattern. The use of these options can affect supply chain <b>mismatch</b> risks and <b>costs.</b> In this paper, we study the impact of quantity discounts and transportation cost structures on procurement, shipment and clearance pricing decisions through a stochastic programming with recourse formulation. We propose a solution procedure that efficiently solves this stochastic non-linear problem. Our computational experiments suggest that it is not always necessary to select the most complex action plan. Under some business environments, the conventional strategy of placing and transporting a single large order is a better option. We then identify situations where options such as markdowns and the use of quick response suppliers could be useful. (C) 2010 Elsevier B. V. All rights reserved...|$|R
40|$|Crohn's disease (CD) and {{ulcerative}} colitis (UC) challenge economies worldwide. Detailed health economic data of DRG based academic inpatient care for {{inflammatory bowel disease}} (IBD) patients in Europe is unavailable. IBD was identified through ICD- 10 K 50 and K 51 code groups. We took an actual costing approach, compared expenditures to G-DRG and non-DRG proceeds and performed detailed cost center and type accounting to identify coverage determinants. Of all 3093 hospitalized cases at our department, 164 were CD and 157 UC inpatients in 2012. On average, they were 44. 1 (CD 44. 9 UC 43. 3 all 58) years old, stayed 10. 1 (CD 11. 8 UC 8. 4 vs. all 8) days, carried 5. 8 (CD 6. 4 UC 5. 2 vs. all 6. 8) secondary diagnoses, received 7. 4 (CD 7. 7 UC 7 vs. all 6. 2) procedures, had a higher cost weight (CD 2. 8 UC 2. 4 vs. all 1. 6) and required more intense nursing. Their care was more costly (means: total cost IBD 8477 € CD 9051 € UC 7903 € vs. all 5078 €). However, expenditures were not fully recovered by DRG proceeds (means: IBD 7413 €, CD 8441 €, UC 6384 € vs all 4758 €). We discovered substantial disease specific <b>mismatches</b> in <b>cost</b> centers and types and identified the medical ward personnel and materials budgets to be most imbalanced. Non-DRG proceeds were almost double (IBD 16. 1 % vs. all 8. 2 %), but did not balance deficits at total coverage analysis, that found medications (antimicrobials, biologics and blood products), medical materials (mostly endoscopy items) to contribute most to the deficit. DRGs challenge sophisticated IBD care...|$|R
40|$|Designing longer lasting {{clothing}} {{helps to}} reduce unsustainable levels of product disposal and subsequent waste. This {{has led to}} a call for retailers to enhance clothing longevity, supported by new business models to reduce any impact on competitiveness. While some research suggests that a significant proportion of consumers would buy longer lasting clothes, this view is not necessarily accepted by industry strategists. This paper, which reports on research undertaken for WRAP (Waste and Resources Action Programme), explores conflicting priorities between commercial and sustainable practice, and problematic trade-offs in the supply chain between commercial, technical and design aspects of reducing the environmental impact of clothing. The study adopted a mixed methodology, incorporating qualitative interviews and a survey, and encompasses views of retailers, manufacturers and suppliers from different segments of the UK fashion market. The findings confirm that retailers and brands drive the new product development process and set standards for their supply chains, but globalization, product churn and testing regimes challenge the critical path schedule. Although current tests confirm product quality (WRAP, 2013), there is a perception within industry that designing for longevity increases testing, inflating the risk of failure and extending lead-times, resulting in a <b>mismatch</b> between <b>cost,</b> time and longevity priorities that limits adoption of design for longevity. Meanwhile, clothing longevity is not perceived to add value for many consumers and therefore is not prioritised. While it is technically possible to enhance clothing longevity, the findings demonstrate empirically that this deviates from current commercial drivers of global clothing supply chains. By combining different perspectives on supply chains, new product development and sustainability, inherent conflicts are revealed...|$|R
