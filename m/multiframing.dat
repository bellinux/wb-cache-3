3|337|Public
40|$|Before {{entering}} {{the world of}} research I assumed that the most rewarding part would be travelling to exotic places and sharing novel fi ndings with like-minded colleagues {{from all around the}} world. As I chose to study higher education organizations, I discovered soon that I and my like-minded colleagues might be the most fortunate researchers because our frameworks provide us with lenses through which we are able to see the exotic in our everyday environments. I want to extend my warmest thanks to my dissertation supervisor Professor Seppo Hölttä for guiding me to see this. Seppo’s way of supervising a dissertation is a true <b>multiframing</b> activity: not only has he shown me the structural and human resource orientation but he has also skillfully guided me {{to come to terms with}} the political and symbolic aspects of becoming an academic. I am also very grateful for the valuable comments and encouragement I received from my second supervisor Dr Jussi Kivistö...|$|E
40|$|A {{series of}} laser fusion {{implosion}} experiments of plastic hollow shell targets {{was performed by}} using the Gekko XII glass laser {{in order to achieve}} the required fuel areal density for ignition. Introducing random phase plates to improve illumination uniformity, high-density compression of more than 600 times deuterium liquid density has been achieved. The implosion dynamics and symmetry were observed with a spatially resolved x-ray streak camera and an x-ray <b>multiframing</b> camera. The three-dimensional emission profile of the laser-heated plasma was reconstructed from the x-ray images by use of computed tomography and was compared with the laser illumination profiles. The areal density of the imploded core was measured by the neutron activation of a silicon tracer, the secondary reaction method, and the knock-on proton method. Although the measured density and areal density were consistent with those from 1 -D hydrodynamic simulation, experimental neutron yields were significantly lower than those predicted by the simulation for convergence ratios larger than 20. This suggests that better implosion uniformity is required to create a hot spark...|$|E
40|$|At the HHT {{experimental}} area, strongly coupled plasmas {{are created}} by {{the interaction of the}} SIS heavy ion beams with solid targets. To obtain a high energy deposition in the target, the ion beam is focused by the plasma lens [1] to diameters smaller than 1 mm in the focus. The generated plasmas have densities close to the solid state density, volumes of several mm 3 and temperatures up to 1 eV. The characterization of the matter under such extreme temperatures and pressures is of relevance for equation of state (EOS) studies, in astrophysics for understanding the formation of heavy elements in supernovae, for designs of future heavy ion driven Inertial Fusion Experiments (IFE) and others. A wide range of optical diagnostics, such as shadowgraphy, time resolved spectroscopy in visible and VUV ranges, and schlieren techniques were recently developed to study the target behavior at the interaction with the ion beam. Up to now, metallic and cryogenic gas crystal targets [2] were used for the ion beam heating experiments, characterized by backlighting shadowgraphy and time resolved spectroscopy. For these experiments the backlighter was a high energy (250 J) Xe flashlamp and the target dynamics was detected with a fast <b>multiframing</b> camera, capable to acquire simultaneously eight frames with an exposure time above 10 ns...|$|E
5000|$|The {{receiving}} end {{has to know}} {{which is the first}} bit of the CRC-4 word (C1). For this reason, a CRC-4 <b>multiframe</b> alignment word is needed. Obviously, the receiver has to be told where the <b>multiframe</b> begins (synchronization). The CRC-4 <b>multiframe</b> alignment word is the set combination [...] "001011", which is introduced in the first bits of the frames that do not contain the FAS signal.|$|R
40|$|Scheduling {{analysis}} of real time systems {{has been studied}} by most re-searchers assuming the tasks of the systems have constant worst case execution time bounds during their cycle of execution. However, {{this is not the}} case in a <b>multiframe</b> task where the execution time could be dif-ferent from one instance to another, as in multimedia applications like MPEG. Some researchers have introduced sufficient scheduling analyses for a restricted model of <b>multiframe</b> tasks. The contributions in this thesis present scheduling analysis for a less strict model of <b>multiframe</b> tasks. The analysis is presented in two steps. In the first step, exact scheduling analysis is presented by response time analysis; where the worst case response time of <b>multiframe</b> tasks is formulated. This formulation is then extended to <b>multiframe</b> tasks that are subjected to blocking, release jitter and arbitrary deadlines. Another extension of the formulation i...|$|R
40|$|The <b>multiframe</b> {{model of}} hard-real-time tasks is a {{generalization}} of the well-known periodic task model of Liu and Layland (Scheduling algorithms for multiprogramming {{in a hard}} real-time environment. Journal of the ACM 20 (1), pp. 46 [...] 61. 1973). The feasibility analysis of systems of <b>multiframe</b> tasks which are assigned priorities according to the rate-monotonic priority assignment scheme is studied. An efficient sufficient feasibility test for such systems of <b>multiframe</b> tasks is presented and proved correct [...] - this generalizes a result of Mok and Chen (A <b>multiframe</b> model for real-time tasks. IEEE Transactions on Software Engineering 23 (10), pp. 635 [...] 645. 1997) ...|$|R
40|$|A {{simple but}} {{effective}} <b>multiframe</b> demosaicking method is proposed. Its {{primary goal is}} to replace more expensive mechanical motion compensation systems. Therefore, {{it is designed to}} be easily implemented in hardware for consumer devices. The described <b>multiframe</b> demosaicking algorithm is suitable for mass production devices such as mobile phones or digital cameras. It is compared to a <b>multiframe</b> noise reduction of similar complexity. The comparison is based on computerbased simulation of a camera being (unintentionally) shaken by a human operator. The following error measurements wer...|$|R
50|$|The FCCH {{generates a}} tone {{on the radio}} channel {{that is used by}} the mobile station to {{discipline}} its local oscillator. FCCH will repeat on every 0th, 10th, 20th, 30th and 40th frames of the 51 frame <b>multiframe.</b> So there are 5 FCCH frames in a 51 frame <b>multiframe.</b>|$|R
40|$|We have {{recently}} demonstrated {{a new approach}} to <b>multiframe</b> structure from motion from point features which, in the appropriate domain, provably reconstructs structure and motion correctly. The domain is one well suited to outdoor robot navigation scenarios where perspective effects are large. In this paper, we describe a version of our approach adapted to an important special case of motion: translational motion approximately in a constant direction (but not necessarily of constant magnitude) with arbitrary rotations. Experimental results are presented for real and synthetic image sequences. Keywords <b>Multiframe</b> structure from motion, nonlinear estimation, autonomous navigation, low level vision. Provably Correct Algorithms for <b>Multiframe</b> Structure from Motion: the Case of Constant Translation Direction Abstract We {{have recently}} demonstrated {{a new approach to}} <b>multiframe</b> structure from motion from point features which, in the appropriate domain, provably reconstructs structure and moti [...] ...|$|R
40|$|Abstract — <b>Multiframe</b> image {{reconstruction}} produces images {{beyond the}} native resolution of a digital image sensor {{by way of}} accurate sub-pixel registration of aliased images. We present a novel <b>multiframe</b> registration approach {{for the purpose of}} enhancing resolution of digital mammogram images. We demonstrate the ability to improve resolution while maintaining normal radiation dosages. I...|$|R
40|$|Our goal is {{to provide}} a {{sufficient}} schedulability test -ideally polynomial- for the scheduling of Non-Cyclic Generalized <b>Multiframe</b> Task Model using Fixed-Task-Priority schedulers. We report two first results: (i) we present and prove correct the critical instant for the Non-Cyclic Generalized <b>Multiframe</b> Task Model then (ii) we propose an algorithm which provides a sufficient (but pseudo-polynomial) schedulability test...|$|R
40|$|The {{problem of}} image {{registration}} subsumes {{a number of}} problems and techniques in <b>multiframe</b> image analysis, including the computation of optic flow (general pixel-based motion), stereo correspondence, structure from motion, and feature tracking. We present a new registration algorithm based on spline representations of the displacement field which can be specialized to solve all of the above mentioned problems. In particular, we show how to compute local flow, global (parametric) flow, rigid flow resulting from camera egomotion, and <b>multiframe</b> versions of the above problems. Using a spline-based description of the flow removes the need for overlapping correlation windows, and produces an explicit measure of the correlation between adjacent flow estimates. We demonstrate our algorithm on <b>multiframe</b> image registration and the recovery of 3 D projective scene geometry. We also provide results on a number of standard motion sequences. Keywords: motion analysis, <b>multiframe</b> image analysis, h [...] ...|$|R
5000|$|The MS initiates <b>multiframe</b> mode in SAP3 {{with the}} normal LAPDm SABM procedure.|$|R
40|$|Musical {{terminology}} {{is often}} used when discussing narrative forms of art. However, this is seldom accompanied by a systematic application of musical concepts for use by artists in these other mediums. Comics, in particular, parallel music {{in terms of the}} <b>multiframe,</b> where various individual elements are perceived at once. Therefore, a useful analogy can be made between the <b>multiframe</b> and thematic and vertical musical construction. The interactivity among jazz musicians during a collective improvisation exemplifies this musical simultaneity, and this article creates an analogy between improvisation and narrative comics, deriving several analytical tools {{that can be used to}} inform the creation of more meaningful <b>multiframes...</b>|$|R
40|$|We {{propose a}} new <b>multiframe</b> {{algorithm}} {{to enhance the}} spatial resolution of frames in video sequences. Our technique specifically accounts {{for the possibility that}} motion estimation will be inaccurate and compensates for these inaccuracies. Experiments comparing our results with other methods show that our <b>multiframe</b> enhancement algorithm yields perceptibly sharper enhanced images with significant SNR improvement over bilinear and cubic B-spline interpolation. ...|$|R
40|$|Super-resolution {{technique}} {{is used for}} resolution enhancement. In <b>multiframe</b> super-resolution multiple low resolution images are combined to get high resolution image. This paper addresses <b>multiframe</b> super-resolution in which one or more low resolution images are combined to get high resolution image which can increase spatial resolution of image and different image quality matrices to measure {{the quality of the}} original image and reconstructed image...|$|R
40|$|The {{real-time}} <b>multiframe</b> task model first {{studied by}} Mok and Chen {{assumes that the}} computation times of a periodic task vary instance by instance. They have derived an utilization bound for verifying the schedulability of <b>multiframe</b> task sets. Their schedulability test has since been improved by other researchers. In this paper we use {{the information about the}} relative period ratios between tasks in a system to derive a new schedulability condition. By considering the smallest and the largest period values in a system, we can show that the RM schedulability bound can be improved significantly. This method also can be applied to other test methods studied earlier to improve the schedulability of real-time <b>multiframe</b> systems. 1...|$|R
30|$|N) <b>multiframes</b> in {{a similar}} manner to the {{allocation}} of time slots in the SOHF of the FP.|$|R
40|$|This paper {{presents}} a practical framework for creating and visualizing interactive 3 -D media using {{a system of}} uncalibrated projector-cameras. The proposed solution uses light patterns that temporally encode the projector’s coordinate system to solve the traditionally challenging <b>multiframe</b> correspondence problem by straightforward decoding instead of computational <b>multiframe</b> optimization. Two sets of coded light patterns (black/white stripes and colored 2 x 2 blocks, both of varying spatial resolutions) are presented and compared. The resulting correspondences are directly used as a compelling form of interactive 3 -D media through described techniques including three-frame view synthesis, <b>multiframe</b> view synthesis using multiple three-frame groupings, and even single-camera view interpolation. It is shown that adapting the rendering order of the correspondences {{with respect to the}} projector’s coordinate system ensures the correct visibility for the synthesized views. Experimental results demonstrate that the framework works well for various real-world scenes, even including those with multiple objects and textured surfaces. The framework, along with the resulting correspondences, also has implications in many other computer vision and image processing applications, especially those that require <b>multiframe</b> correspondences...|$|R
30|$|N= 1 : 1 : 15). The {{length of}} one <b>multiframe</b> is 800 ms and {{consists}} of five TDMAframes.|$|R
30|$|N= 1 : 1 : 5). The {{length of}} a {{superframe}} is 12 s and consists of 15 <b>multiframes.</b>|$|R
3000|$|... <b>multiframes</b> as {{similarly}} as allocating {{time slots}} in the SOHF of the FP until {{the number of}} allocated time slots becomes 4 Δ [...]...|$|R
50|$|G.706 {{standard}} {{defines the}} frame alignment, the cyclic redundancy check(CRC), <b>multiframe</b> alignment and CRC bit error monitoring procedures {{to be used}} by such equipment.|$|R
40|$|To achieve {{high-resolution}} wide-swath imaging, {{the use of}} multichannel {{techniques in}} azimuth is effective for spaceborne Synthetic Aperture Radar (SAR). For azimuth multichannel systems, the signal in azimuth is nonuniformly sampled if the uniform sampling condition related to Pulse Repetition Frequency (PRF) is not satisfied, which makes it important to reconstruct the azimuth signal prior to image formation. In this study, to solve the azimuth signal reconstruction problem in multichannel SAR, we propose the innovative use of a <b>multiframe</b> super-resolution method in Digital Image Processing (DIP) and summarize the general <b>multiframe</b> super-resolution process. Our simulation results and real data experiments verify {{the effectiveness of the}} proposed method, which demonstrates some advantages in complexity performance. By establishing linkages between the problem of signal reconstruction of nonuniformly sampled signals and the <b>multiframe</b> superresolution concept, we provide a new approach to this traditional signal reconstruction problem...|$|R
40|$|Abstract—This paper investigates linearly {{combined}} motion-compensated signals {{for video}} compression. In particular, we discuss multiple motion-compensated signals that are jointly estimated for efficient prediction and video coding. First, we extend the wide-sense stationary theory of motion-compensated prediction (MCP) {{for the case}} of jointly estimated prediction signals. Our theory suggests that the gain by multihypothesis MCP is limited and that two jointly estimated hypotheses provide {{a major portion of}} this achievable gain. In addition, the analysis reveals a property of the displacement error of jointly estimated hypotheses. Second, we present a complete multihypothesis codec which is based on the ITU-T Recommendation H. 263 with <b>multiframe</b> capability. <b>Multiframe</b> motion compensation chooses one prediction signal from a set of reference frames, whereas multihypothesis prediction chooses more than one for the linear combination. With our scheme, the time delay associated with B-frames is avoided by choosing more than one prediction signal from previously decoded pictures. Experimental results show that multihypothesis prediction improves significantly coding efficiency by utilizing variable block size and <b>multiframe</b> motion compensation. We show that variable block size and multihypothesis prediction provide gains for different scenarios and that <b>multiframe</b> motion compensation enhances the multihypothesis gain. For example, the presented multihypothesis codec with ten reference frames improves coding efficiency by up to 2. 7 dB when compared to the reference codec with one reference frame for the set of investigated test sequences. Index Terms—Entropy-constrained vector quantization, linear prediction, motion-compensated prediction, <b>multiframe</b> prediction, multihypothesis motion-compensated prediction, rate-constrained motion estimation, video coding. I...|$|R
40|$|Abstract—In this paper, {{we present}} a {{framework}} for real-time mosaicing from video sequences recorded from an uncalibrated pan tilt zoom camera based on <b>multiframe</b> registration. To this end, a new frame alignment algorithm, the direct local indirect global (DLIG), is presented. The key idea of the DLIG alignment is to divide the frame alignment problem into the problem of registering a set of spatially related image patches. The registration is iteratively computed by sequentially imposing a good local match and global spatial coherence. The patch registration is performed using a tracking algorithm, so a very efficient local matching can be achieved. We use the patch-based registration to obtain <b>multiframe</b> registration, using the mosaic coordinates to relate the current frame to patches from different frames that partially share the current field of view. <b>Multiframe</b> registration prevents the error accumulation problem, {{one of the most}} important problems in mosaicing. We also show how to embed a kernel tracking algorithm in order to obtain a precise and extremely efficient mosaicing algorithm. Finally, we perform a quantitative evaluation of our algorithm, including a comparison with other alignment approaches, and studying its performance against interlaced videos and illumination changes. Index Terms—Interlaced, kernel tracking, <b>multiframe</b> align-ment, real-time, video mosaicing. I...|$|R
40|$|Abstract—Super-resolution (SR) is {{the process}} of {{combining}} multiple aliased low-quality images to produce a high-resolution high-quality image. Aside from registration and fusion of low-resolution images, a key process in SR is the restoration and denoising of the fused images. We present a novel extension of the combined Fourier-wavelet deconvolution and denoising algorithm ForWarD to the <b>multiframe</b> SR application. Our method first uses a fast Fourier-base <b>multiframe</b> image restoration to produce a sharp, yet noisy estimate of the high-resolution image. Our method then applies a space-variant nonlinear wavelet thresholding that addresses the nonstationarity inherent in resolution-enhanced fused images. We describe a computationally efficient method for implementing this space-variant processing that leverages the efficiency of the fast Fourier transform (FFT) to minimize complexity. Finally, we demonstrate the effectiveness of this algorithm for regular imagery as well as in digital mammography. 1 Index Terms—Digital X-ray imaging, <b>multiframe</b> deblurring, super-resolution (SR), wavelets, denoising...|$|R
40|$|This is {{a conference}} paper [© IEEE]. It is also {{available}} at: [URL] Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must {{be obtained from the}} IEEE. A simple but effective <b>multiframe</b> demosaicking method is proposed. It is compared to a <b>multiframe</b> noise reduction of similar complexity. The comparison was based on computer-based simulation of a shaking camera. MSE, PSNR and NCD errors measurements were taken. Further ways of enhancing the algorithm without significant increase in complexity are proposed. The described <b>multiframe</b> demosaicking algorithm is suitable for mass production devices such as mobile phones of digital cameras. Its primary goal is to replace more expensive mechanical motion compensation systems...|$|R
3000|$|... <b>multiframes</b> in {{a similar}} manner to the release of the time slots in method 4 (a) until the number of time slots {{released}} becomes 4 Δ [...]...|$|R
40|$|This {{dissertation}} {{is concerned}} with multiple-frame (<b>multiframe)</b> reconstructions using imagery acquired in dynamic imaging environments. Through several interesting examples, we address and relate the key concepts of information weighting, channel diversity and <b>multiframe</b> processing {{in the context of}} producing high resolution estimates from severely degraded imagery. For the problem of space object identification, we look at methods for preprocessing a collection of atmospheric turbulence-degraded short-exposure images to improve the resolving power of estimation algorithms. Specifically, we examine the performance of using frame selection to extract the least degraded subset of images from an ensemble for processing. Several measures of image quality are compared against idealized standards to demonstrate their relative effectiveness for ranking highly the least degraded image frames. We also examine the resolving implication of removing additive background noise, resulting from the sky and telescope. Specifically, we show that background compensation acts as a defacto restoration of the compact object support and leads to furthering the resolving power of estimation algorithms. In the context of dilute aperture imagery, we look at methods for inducing channel diversity into a collection of measurements. With a diverse image set, we compute estimates using both a joint <b>multiframe</b> objective and an aggregated objective. We then examine the implication of using joint or aggregate objectives in any estimation algorithm from a set-theoretic standpoint. Finally, we extend the classic Wiener filter for the <b>multiframe</b> case. The resulting formulation demonstrates that the appropriate weighting of image data allows for the worst frames to be included while improving the restoration. We discuss how this contradicts the earlier idea of frame selection and relates the <b>multiframe</b> Wiener filter to the dual information theoretic concept of "water-filling"...|$|R
3000|$|N) out of {{the five}} TDMAframes at the {{selected}} <b>multiframe</b> (see the dotted box (3) in Figure 5). If {{there are more than}} two TDMAframes whose N [...]...|$|R
40|$|A {{new model}} for {{sporadic}} task systems is introduced. This model [...] the generalized <b>multiframe</b> task model [...] further generalizes both the conventional sporadic-tasks model, {{and the more}} recent <b>multiframe</b> model of Mok and Chen. A framework for determining feasibility {{for a wide variety}} of task systems is established; this framework is applied to this task model to obtain a feasibility-testing algorithm that runs in time pseudo-polynomial in the size of the input for all systems of such tasks whose densities are bounded by a constant less than one...|$|R
30|$|The {{goal of this}} {{assignment}} behavior {{is to increase the}} possibility of benefiting from parallelism in the third phase of the approach as a way to reduce the response-time of the tasks. For instance, some parallel tasks may not fit into the cores in this first phase, and if this is the case, such tasks can be re-checked in {{the second phase of the}} approach by treating them as <b>multiframe</b> tasks. If an execution pattern is found for the <b>multiframe</b> task, then these tasks can benefit from work-stealing in the third phase.|$|R
30|$|Each {{migrating}} task {{is modeled}} as a <b>multiframe</b> task. The <b>multiframe</b> task model (as presented by Mok and Chen [17] and later generalized by Baruah et al. [18]) allows system designers to model a task {{by using a}} static and finite list of execution requirements, corresponding to successive jobs (or frames as they are named in this model). Specifically, by repeating this list (possibly ad infinitum), a periodic sequence of execution requirements is generated such that the execution time of each frame is bounded from above by the corresponding value in the periodic sequence.|$|R
40|$|A {{new model}} for {{sporadic}} task systems is introduced. This model [...] - the generalized <b>multiframe</b> task model [...] - further generalizes both the conventional sporadic-tasks model, {{and the more}} recentmultiframe model of Mok and Chen. A framework for determining feasibility {{for a wide variety}} of task systems is established# this framework is applied to this task model to obtain a feasibility-testing algorithm that runs in time pseudo-polynomial in the size of the input for all systems of such tasks whose densities are bounded by a constant less than one. Keywords: Recurring <b>multiframe</b> tasks, preemptive uniprocessor scheduling, hard deadlines, feasibility analysis. 1 Introduction <b>Multiframe</b> tasks were introduced by Mok & Chen [6], as a generalization to the well-known periodic task model of Liu & Layland [4]. Amultiframe task is represented by a tuple (~ E#P), where ~ E =[E o #E 1 #:::#E N; 1]i savector of execution times, and P is the minimum separation time. The task generates an [...] ...|$|R
40|$|A general {{framework}} for 2 D <b>multiframe</b> and 3 D surface-to-surface motion estimation {{is presented in}} this paper. By viewing a 2 D contour sequence as a pseudo 3 D surface, we solve the motion estimation problem for 2 D <b>multiframe</b> and 3 D surface-to-surface in a {{general framework}}, by estimating the motion of a ”surface”. The deformation of a ”surface ” is modeled using spline-based motion. This spline-based motion model does not constrain the motion type in the temporal domain for 2 D <b>multiframe</b> motion estimation. For 3 D motion estimation, {{we focus on the}} relationship between the underlying nonrigid motion and 3 D surface properties. The spline motion model provides our method certain advantages over other nonrigid shapebased methods. For example, we do not need approximation of the orthogonal parameterization. The small deformation constraint introduced by the previous surface-to-surface motion estimation methods is also relaxed in our method. Experiments on both synthetic and real motion are presented in this paper. ...|$|R
