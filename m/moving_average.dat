6800|852|Public
25|$|Plotted as a 3-period <b>moving</b> <b>average</b> of {{the surveys}} {{included}} in Opinion polling in the Philippine presidential election, 2010.|$|E
25|$|The {{model is}} usually {{referred}} to as the ARMA(p,q) model where p is the order of the autoregressive part and q is the order of the <b>moving</b> <b>average</b> part (as defined below).|$|E
25|$|Quacquarelli Symonds QS Global 200 Business Schools Report compiles {{regional}} {{rankings of}} business {{schools around the}} world. Ranks are calculated using a two-year <b>moving</b> <b>average</b> of points assigned by employers who hire MBA graduates.|$|E
40|$|It {{is shown}} that <b>moving</b> <b>averages</b> {{sequences}} are {{good in the}} mean for multiparameter strongly superadditive processes in L 1, and good in the pmean for multiparameter admissible superadditive processes in Lp, 1 p ! 1. Also, using a decomposition theorem in Lp -spaces, a. e. convergence of the <b>moving</b> <b>averages</b> of multiparameter superadditive processes with respect to positive Lp-contractions, 1 ! p ! 1, is obtained. Contents 1. Introduction 135 2. Convergence in the p-Mean 137 3. Almost Everywhere Convergence 143 4. Concluding Discussions 146 References 147 1. Introduction Beginning with the <b>moving</b> <b>averages</b> theorem of Bellow, Jones and Rosenblatt [BJR 1], determining the conditions that ensure a. e. convergence (or divergence) of <b>moving</b> <b>averages</b> of various processes has been a subject of intensive study. Subsequently, a. e. convergence of <b>moving</b> <b>averages</b> has been obtained in several different settings [AD, C¸ 2, C¸ F, JO 1, JO 2]. In [JO 1, JO 2] the <b>moving</b> <b>averages</b> theorem has b [...] ...|$|R
40|$|We {{survey the}} interplay between the Riesz means and Beurling <b>moving</b> <b>averages</b> of the title, obtaining Abelian and Tauberian results {{relating}} different Riesz means (or Beurling <b>moving</b> <b>averages)</b> whose defining functions have comparable growth. The motivation includes strong limit theorems in probability theory...|$|R
40|$|Taking {{some form}} of <b>moving</b> <b>averages</b> yields a {{smoothing}} of time series which is delayed. However, taking <b>moving</b> <b>averages</b> in the reverse time direction gives a smoothing which is in advance. The two resulting smoothed time series are pointwise averaged getting as result a smoothed version with "no delay"...|$|R
25|$|The {{dependence}} of X't on past {{values and the}} error terms εt {{is assumed to be}} linear unless specified otherwise. If the dependence is nonlinear, the model is specifically called a nonlinear <b>moving</b> <b>average</b> (NMA), nonlinear autoregressive (NAR), or nonlinear autoregressive–moving-average (NARMA) model.|$|E
25|$|In the {{statistical}} analysis of time series, autoregressive–moving-average (ARMA) models provide a parsimonious description of a (weakly) stationary stochastic process in terms of two polynomials, one for the autoregression and the second for the <b>moving</b> <b>average.</b> The general ARMA model was described in the 1951 thesis of Peter Whittle, Hypothesis testing in time series analysis, and it was popularized in the 1970 book by George E. P. Box and Gwilym Jenkins.|$|E
25|$|The main {{difficulty}} in applying {{this process is}} in determining the number of knots to use and {{where they should be}} placed. de Boor suggests various strategies to address this problem. For instance, the spacing between knots is decreased in proportion to the curvature (2nd. derivative) of the data. A few applications have been published. For instance, the use of B-splines for fitting single Lorentzian and Gaussian curves has been investigated. Optimal spline functions of degrees 3-7 inclusive, based on symmetric arrangements of 5, 6, and 7 knots, have been computed and the method was applied for smoothing and differentiation of spectroscopic curves. In a comparable study, the two-dimensional version of the Savitzky-Golay filtering and the spline method produced better results than <b>moving</b> <b>average</b> or Chebyshev filtering.|$|E
40|$|A common {{method in}} {{technical}} analysis is {{the construction of}} <b>moving</b> <b>averages</b> along time series of stock prices. We show that they present a practical interest for physicists, and raise new questions on fundamental ground. Indeed, self-affine signals characterized by a defined roughness exponent H can be investigated through <b>moving</b> <b>averages.</b> The density rho of crossing points between two <b>moving</b> <b>averages</b> is {{shown to be a}} measure of long-range power-law correlations in a signal. Finally, we present a specific transform with which various structures in a signal, e. g. trends, cycles, noise, etc, can be investigated in a systematic way. Peer reviewe...|$|R
40|$|This paper {{examines}} {{the accuracy of}} forecasts produced by mechanical forecasting techniques and three groups of analysts. The nine mechanical forecasting techniques are variations of exponentially weighted <b>moving</b> <b>averages,</b> naive models, simple <b>moving</b> <b>averages,</b> and regressions. One-, two- and three-year forecasts are used to evaluate these techniques. The mechanical techniques exhibit statistically significant differences {{in their ability to}} forecast earnings per share, with the exponentially weighted <b>moving</b> <b>averages</b> producing the best forecasts. One-year forecasts produced by the best of the mechanical forecasting techniques were compared to the corresponding analysts' projections. No statistically significant difference could be discerned. ...|$|R
5000|$|Time Series: naive methods, <b>moving</b> <b>averages,</b> {{exponential}} smoothing, Box-Jenkins method, decompositional methods ...|$|R
25|$|For January 2012, comScore {{reported}} the site had 11.7 million unique U.S. visitors, {{making it the}} fastest site ever {{to break through the}} 10 million unique visitor mark. comScore recorded a unique users <b>moving</b> <b>average</b> growth of 85% from mid-January to mid-February and a 17% growth from mid-February to mid-March. At the South By Southwest Interactive conference in March 2012, Silbermann announced revamped profile pages were being developed and would be implemented soon. On 23 March 2012, Pinterest unveiled updated terms of service that eliminated the policy that gave it the right to sell its users' content. The terms would go into effect April 6. According to Experian Hitwise, the site became the third largest social network in the United States in March 2012, behind Facebook and Twitter.|$|E
500|$|The autoregressive and <b>moving</b> <b>average</b> {{processes}} are types of stochastic {{processes that are}} used to model discrete-time empirical time series data, especially in economics. The autoregressive process or model treats a stochastic variable as depending on its own prior values and on a current independently and identically distributed stochastic term. The <b>moving</b> <b>average</b> model treats a stochastic variable as depending on the current and past values of an iid stochastic variable.|$|E
500|$|Stochastic {{models are}} {{formulated}} using stochastic processes. They model economically observable values over time. Most of econometrics {{is based on}} statistics to formulate and test hypotheses about these processes or estimate parameters for them. Between the World Wars, Herman Wold developed a representation of stationary stochastic processes in terms of autoregressive models and a determinist trend. Wold and Jan Tinbergen applied time-series analysis to economic data. Contemporary research on time series statistics consider additional formulations of stationary processes, such as [...] autoregressive <b>moving</b> <b>average</b> models. More general models include [...] autoregressive conditional heteroskedasticity (ARCH) models and generalized ARCH (GARCH) models.|$|E
40|$|Abstract. It {{is shown}} that <b>moving</b> <b>averages</b> {{sequences}} are {{good in the}} mean for multiparameter strongly superadditive processes in L 1, and good in the pmean for multiparameter admissible superadditive processes in Lp, 1 ≤p<∞. Also, using a decomposition theorem in Lp-spaces, a. e. convergence of the <b>moving</b> <b>averages</b> of multiparameter superadditive processes with respect to positive Lp-contractions, 1 <p<∞, is obtained...|$|R
50|$|Now {{calculations}} for 4 quarterly <b>moving</b> <b>averages</b> and ratio-to-moving-averages {{are shown}} in the below table.|$|R
40|$|Self-similar {{symmetric}} α-stable, α∈(0, 2), mixed <b>moving</b> <b>averages</b> can {{be related}} to nonsingular flows. By using this relation and the structure of the underlying flows, one can decompose self-similar mixed <b>moving</b> <b>averages</b> into distinct classes and then examine the processes in each of these classes separately. The relation between processes and flows involves semi-additive functionals. We establish a general result about semi-additive functionals related to cocycles, and identify the presence of a new semi-additive functional in the relation between processes and flows. This new functional is useful for finding the kernel function of self-similar mixed <b>moving</b> <b>averages</b> generated by a given flow. It also sheds new light on previous results on the subject...|$|R
500|$|Interactive {{graphics}} {{and other features}} were added in 1991 with version 2.0. Version 2 was twice the size as the original, though it was still delivered on a floppy disk. It required 2 MB of memory and came with 700 pages of documentation. Support for Microsoft Windows was added with version 3.1 in 1994. [...] Rewritten with Version 4 and released in 2002, JMP could import data from {{a wider variety of}} data sources and added support for surface plots. Version 4 also added time series forecasting and new smoothing models, such as the seasonal smoothing method, called Winter's Method, and ARIMA (Autoregressive Integrated <b>Moving</b> <b>Average).</b> It was also the first version to support JSL, JMP Scripting Language.|$|E
2500|$|The {{notation}} MA(q) {{refers to}} the <b>moving</b> <b>average</b> model of order q: ...|$|E
2500|$|The Durbin–Watson {{statistic}} {{is biased}} for autoregressive <b>moving</b> <b>average</b> models, so that autocorrelation is underestimated. But for large samples {{one can easily}} compute the unbiased normally distributed h-statistic: ...|$|E
40|$|In {{the present}} paper we obtain {{sufficient}} conditions {{for the existence of}} equivalent martingale measures for Lévy-driven <b>moving</b> <b>averages</b> and other non-Markovian jump processes. The conditions that we obtain are, under mild assumptions, also necessary. For instance, this is the case for <b>moving</b> <b>averages</b> driven by an α-stable Lévy process with α∈ (1, 2]. Our proofs rely on various techniques for showing the martingale property of stochastic exponentials...|$|R
40|$|In {{this paper}} we {{establish}} asymptotic normality of trimmed sums for long range dependent <b>moving</b> <b>averages.</b> Our results extend those of Ho and HsingÂ [Ho, H. -C., Hsing, T. 1996. On the asymptotic {{expansion of the}} empirical process of long-memory <b>moving</b> <b>averages.</b> Ann. Statist. 24, 992 - 1024] and Wu [Wu, W. B., 2005. On the Bahadur representation of sample quantiles for dependent sequences. Ann. Statist. 33 1934 - 1963]. ...|$|R
5000|$|... 1. Find the {{centered}} 12 monthly (or 4 quarterly) <b>moving</b> <b>averages</b> of {{the original}} data values in the time-series.|$|R
2500|$|Autoregressive–moving-average {{models can}} be {{generalized}} in other ways. See also {{autoregressive conditional heteroskedasticity}} (ARCH) models and autoregressive integrated <b>moving</b> <b>average</b> (ARIMA) models. [...] If multiple time series are to be fitted then a vector ARIMA (or VARIMA) model may be fitted. [...] If the time-series in question exhibits long memory then fractional ARIMA (FARIMA, sometimes called ARFIMA) modelling may be appropriate: see Autoregressive fractionally integrated <b>moving</b> <b>average.</b> [...] If the data is thought to contain seasonal effects, it may be modeled by a SARIMA (seasonal ARIMA) or a periodic ARMA model.|$|E
2500|$|Academic success (the {{proportion}} of students receiving nationally competitive awards) constitutes 10% of the score. Public reputation is not considered, which causes some colleges to score {{lower than in}} other lists. A three-year <b>moving</b> <b>average</b> is used to smooth out the scoring.|$|E
2500|$|ARMA is {{appropriate}} when {{a system is}} a function of a series of unobserved shocks (the MA or <b>moving</b> <b>average</b> part) as well as its own behavior. [...] For example, stock prices may be shocked by fundamental information as well as exhibiting technical trending and mean-reversion effects due to market participants.|$|E
40|$|New {{methods to}} {{forecast}} volatility are usually compared to simple methods like weighted <b>moving</b> <b>averages</b> or GARCH (1, 1) models. In this paper, we provide new benchmark methods {{which are more}} accurate but still very simple. In an empirical study of daily returns on major world indices, our new methods clearly outperformed the conventional methods. The superiority of our methods appears to be quite universal as it {{is not confined to}} certain markets or certain time periods. GARCH models, weighted medians, exponentially weighted <b>moving</b> <b>averages,</b> EWMA, averaging across windows, squared forecasting errors, absolute forecasting errors, volatility forecasting,...|$|R
40|$|Here we obtain Invariance {{principle}} for maxima in two particular cases. The time-intersections of considered sequences of random processes are maxima of properly ane transformed stationary nite or innite <b>moving</b> <b>averages.</b> The distribution {{function of the}} noise components belongs to the max-domain of attraction of Weibull distribution. The max-increments of such processes are dependent. The limiting process prove to be max-stable. For nite <b>moving</b> <b>averages</b> case its time-intersections have Weibull distribution. In the case of innite <b>moving</b> <b>averages,</b> they have Gumbel distribution. 1. Introduction. In 1964 J. Lamperty [4] proved Invariance {{principle for}} maxima (IPM) of independent identically distributed (iid) random variables (rv's). The maxima of a linear process with subexponential noise is investigated mainly by R. Davis and S. Resnick in [3] and [1]. Another IPMs are given in Theorem 5. 5. 11 in [5...|$|R
50|$|To {{smooth out}} natural {{volatility}} in bookings data, the report cites three-month <b>moving</b> <b>averages.</b> It is released approximately {{three weeks after}} the close of each month.|$|R
2500|$|The {{notation}} ARMAX(p, q, b) {{refers to}} the model with p autoregressive terms, q <b>moving</b> <b>average</b> terms and b exogenous inputs terms. This model contains the AR(p) and MA(q) models and a linear combination of the last b terms of a known and external time series [...] It is given by: ...|$|E
2500|$|Given a {{time series}} of data X't , the ARMA {{model is a}} tool for {{understanding}} and, perhaps, predicting future values in this series. [...] The model consists of two parts, an autoregressive (AR) part and a <b>moving</b> <b>average</b> (MA) part. [...] The AR part involves regressing the variable on its own lagged (i.e., past) values. The MA part involves modeling the error term as a linear combination of error terms occurring contemporaneously and at various times in the past.|$|E
2500|$|At base Silver's {{method is}} similar to other analysts' {{approaches}} to {{taking advantage of the}} multiple polls that are conducted within each state: he averaged the polling results. But especially in the early months of the election season polling in many states is sparse and episodic. The [...] "average" [...] of polls over an extended period (perhaps several weeks) would not reveal the true state of voter preferences at the present time, nor provide an accurate forecast of the future. One approach to this problem was followed by Pollster.com: if enough polls were available, it computed a locally weighted <b>moving</b> <b>average</b> or LOESS.|$|E
40|$|Electrocardiogram {{recordings}} {{are very}} often contaminated by high-frequency noise usually power-line interference and EMG disturbances (tremor). Filtering out the tremor remains a priori partially successful {{since it has}} a relatively wide spectrum, which overlaps the useful ECG frequency band by aperiodic noise. The proposed simple approach for tremor suppression uses heuristic relations between the ECG signal parts and parameters of the applied <b>moving</b> <b>averaging.</b> The results obtained are assessed and compared to tremor suppression obtained by <b>moving</b> <b>averaging</b> with constant sample numbers throughout the signal...|$|R
5000|$|... #Caption: Evolution {{of voting}} {{intentions}} since the 40th Ontario general election on October 6, 2011. Points represent results of individual polls. Trend lines represent three-poll <b>moving</b> <b>averages.</b>|$|R
40|$|Abstract—This paper {{presents}} an innovative approach for indicating stock market decisions that the investor should take for minimizing the risk {{involved in making}} investments. The system uses Adaptive Neuro-Fuzzy Inference System (ANFIS) for taking decisions based on the values of technical indicators. Among the various technical indicators available, the system uses weighted <b>moving</b> <b>averages,</b> divergence and RSI (Relative Strength Index). Detailed method and the rules defining the ANFIS architecture (which were developed using empirical examinations) are provided. Index Terms — Hybrid methods, neuro-fuzzy inference system, <b>moving</b> <b>averages,</b> relative strength index (RSI...|$|R
