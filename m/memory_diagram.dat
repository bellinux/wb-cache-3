4|41|Public
50|$|Example:Slow <b>memory</b> <b>diagram</b> {{depicts a}} slow {{consistency}} example. The first process writes 1 {{to the memory}} location X and then it writes 1 to the memory location Y. The second process reads 1 from Y and it then reads 0 from X even though X was written before Y.|$|E
40|$|Understanding the {{execution}} of an object-oriented program {{can be a challenge}} for a student starting a CS 1 course. We believe that a type of diagram that we call a <b>memory</b> <b>diagram</b> can aid the student in understanding object-oriented programming and can assist the instructor in assessing the student’s understanding. Memory diagrams focus on how, in an abstract sense, the memory of the machine changes as the program executes. Though memory diagrams are a simple idea, by careful use of shape and placement, a number of key points about the meaning of a program fragment can be conveyed visually. We have found a correlation between a student’s ability to construct these diagrams and that student’s comprehension of object-oriented concepts. We feel that this correlation indicates that memory diagrams can be used as an assessment technique that, in turn, can be used to improve student learning...|$|E
40|$|Understanding the {{execution}} of an object-oriented program {{can be a challenge}} for a student starting a CS 1 course. Diagrams are a key technique to help students understand object abstraction through visualization, as well as a useful metric for student understanding of object-oriented concepts. We believe that a type of diagram that we call a <b>memory</b> <b>diagram</b> can be an effective visualization tool for the beginning object-oriented programmer. Memory diagrams differ from more well-known object diagrams in that they focus on how, in an abstract sense, the memory of the machine changes as the program executes. Though memory diagrams are a simple idea, by careful use of shape and placement, a number of key points about the meaning of a program fragment can be conveyed visually. We illustrate how memory diagrams help students understand programming by showing how they cover some of the key concepts in an objectoriented CS 1 course. We have also found a correlation between a student's ability to construct these diagrams and that student's comprehension of object-oriented concepts. We are proposing to investigate this correlation further, which may lead to a practical metric for determining a student's future successes in CS 1 and CS 2, as well as pinpointing where certain students may require further assistance. Versions of memory diagrams have been used by other authors. However, we appear to have developed this approach further than others have...|$|E
40|$|We {{argue that}} the {{conventional}} approach of representing pointers as arrows in <b>memory</b> <b>diagrams</b> may have certain limitations for internalizing the semantics of OOP in CS 1 /CS 2. We introduce {{a new set of}} <b>memory</b> <b>diagrams</b> that are based on addresses rather than arrows. We show how these diagrams can be applied to reason about object manipulation in a variety of settings, from the simple one-component case to multiclass applications involving inheritance, aggregation, and arrays...|$|R
40|$|Time-based {{media in}} design, {{especially}} adaptations {{of film and}} television techniques, continue to hold much promise in emerging architectural design processes, one potential use is to overcome the conforming regularity of Building Information Modelling, or BIM technology, by guiding the ongoing implementation of design in the Building Information process. This research and its associated pedagogy explores {{the potential benefits of}} using video <b>diagrams,</b> or <b>memory</b> <b>diagrams,</b> in micro design environments, rather than as overall design compositions, to provide location specific design instructions within a larger conceptual framework to inform the BIM process. It also evaluates the related potential of architecture embedded with smart technology as an extension of <b>memory</b> <b>diagrams</b> in an expanded BIM function...|$|R
40|$|A {{persistent}} visual obsession in contemporary, digitally processed architecture instigated {{this design}} investigation. Neil Leach in The Anaesthetics of Architecture, identifies “aesthetic intoxication”, {{accompanied by a}} narcotic numbing effect, {{as a consequence of}} the fetishization of visual imagery. The inverse principle - sensory deprivation - completes the effect. Sensory deprivation results from miscues in the digital design process and from the intentional denial of sensory stimuli. A theater of the five sense was the design medium used to investigate sensory accountability. The issues addressed were: 1. Contextual factors of aestheticization and deprivation, particularly digital factors. 2. The effectiveness of Design Diagrams, graphic symbolic schematics, to address sensory deprivation and the anaesthetic effect. 3. The effectiveness of multi-sensory <b>Memory</b> <b>Diagrams</b> (engrams) as inhabitable Design Diagrams to address these effects. While the original intention was to study sensory accountability in digital design, the potential of multi-sensory <b>Memory</b> <b>Diagrams</b> re-centered the emphasis of this investigation...|$|R
40|$|Experimental {{techniques}} for nondestructive testing using nonlinear ultrasound stimulate the theoretical interest in wave propagation in materials containing crack-type defects (i. e. internal contacts). The presence of cracks invokes two major mechanisms of nonlinearity: an asymmetric {{reaction of the}} crack to normal compression/tension, and friction-induced hysteresis activated by shearing action. The generated nonlinear response of a sample highly depends on its geometry, for which a numerical description is most suitable. Our numerical tool consists of two components: a unit for solving the elasticity equations in the bulk volume and a unit that provides appropriate boundary conditions to be imposed at the internal boundaries in the material. The crack model has to provide load-displacement relationships for any value of the drive parameters. The traditional Coulomb friction law written for loads does not have this property, and therefore we use another concept that is, however, based on Coulomb’s friction law as well. The approach includes the account for roughness of the defect faces which results in the appearance of an additional contact regime of partial slip, when {{some parts of the}} contact zone slip and some do not. This situation is successfully dealt with by using the previously developed method of memory diagrams. In this method, the hysteretic load-displacement solution is constructed {{with the help of an}} internal system function (<b>memory</b> <b>diagram)</b> that contains all memory information. This displacement-driven solution can be easily extended to two other contact regimes (contact loss and total sliding) and is finally computed for any normal and tangential displacement histories. Memory diagrams have to be maintained at each discretization point on the crack surface and updated following the applied displacement fields. The load-displacement data provides input to the solid mechanics unit programmed in COMSOL®. We present an exemplar simulated configuration and discuss the results. status: accepte...|$|E
40|$|Two {{issues are}} {{addressed}} in this digital design and analysis investigation: First, the device of sequential memory (accessed using animation) is employed in the construction and in the reading of audio-visual design messages. Second, threedimensional Design Diagrams, audio-visual ideograms, are structured as memory schematics that are intended to organize an architectural digital/physical design schema. The accompanying presentation employs <b>Memory</b> <b>Diagrams</b> in audiovisual sequences demonstrating a methodology of structuring and restructuring memory in animation...|$|R
40|$|Learning and {{understanding}} of science instructional material was examined from a cognitive load perspective. It was suggested that instructions {{can be difficult to}} learn if multiple elements of information need to be simultaneously processed through limited working <b>memory.</b> <b>Diagrams</b> were expected to reduce cognitive load by allowing students to process information using fewer elements in working memory than an equivalent text-based format. However, if instructional information could be processed serially, then working-memory load should be light, and both diagrammatic and text-based instructions were hypothesized to be equally effective. Two experiments using different chemistry instructions confirmed these hypotheses and so highlight the role of cognitive load factors in instructional design...|$|R
5000|$|... #Caption: Schematic of circuit {{connections}} to the acoustic delay line used in NBS mercury <b>memory</b> (top); block <b>diagram</b> of the mercury memory system (bottom) ...|$|R
40|$|Modelling of elastic {{deformations}} {{in materials}} containing frictional cracks of known configuration is possible via modern finite element methods. However, {{it is necessary}} to define boundary conditions at crack faces considered as additional (internal) boundaries. The classical Coulomb friction law for flat contact surfaces does not provide explicitly the desired load-displacement relationship. Indeed, once the threshold condition is reached, the tangential displacement becomes undefined. Therefore we use another approach in which contact displacements are considered as arguments and not functions. This has been done for contact between rough surfaces. Surface relief engenders a partial slip regime (absent for flat faces) and makes it possible to express the tangential displacement as a sum of partial slip and total sliding components. The partial slip regime corresponds to the Hertz-Mindlin problem of contact between two spheres with friction, except that its solution should be extended for rough surface geometries and arbitrary loading histories. We build up this extension using the previously developed method of <b>memory</b> <b>diagrams</b> and finally obtain a semi-analytical load-displacement solution to the contact problem. The algorithm has been integrated into the COMSOL solid mechanics unit. We present several examples produced by our numerical code and also provide nonlinear analysis. status: accepte...|$|R
40|$|We {{introduce}} {{the notion of}} LImited <b>Memory</b> Influence <b>Diagram</b> (LIMID) to describe multistage decision problems in which the traditional assumption of no forgetting is relaxed. This can be relevant in situations with multiple decision makers or when decisions must be prescribed under memory constraints, such as in partially observed Markov decision processes (POMDPs). We give an algorithm for improving any given strategy by local computation of single policy updates and investigate conditions for the resulting strategy to be optimal. Local Computation, Message Passing, Optimal Strategies, Partially Observed Markov Decision Process, Single Policy Updating...|$|R
40|$|We {{propose a}} {{numerical}} tool for modeling elastic wave propagation in solids with cracks. A crack is approximated {{by a number}} of mesoscopic cells; in each of them we search for a link between loads (normal N and tangential T) and displacements (normal a and tangential b). The mesoscopic load-displacement relationship integrates the microscopic contact behavior and takes into account roughness of internal crack faces and friction between them together with the associated effects of memory and hysteresis. The normal reaction curve N(a) is obtained using conventional models of contact mechanics. The tangential reaction is calculated using the original method of <b>memory</b> <b>diagrams</b> 1 that automates and greatly simplifies the account for friction and hysteresis. Our constitutive model describes three different defect states: contact loss, total sliding, and partial slip when both stick and slip areas are present in the contact zone. The full constitutive model was implemented in MATLAB and introduced in the structural mechanics module of COMSOL Multiphysics. The latter uses the established load-displacement relationship as a user-supplied boundary condition at the internal crack surface and calculates wave stresses and strains in the whole sample. The ultimate goal is to use the model to assist in the further development of nonlinear NDT applications and, in particular, to estimate defect parameters using measured nonlinear indicators. status: accepte...|$|R
40|$|Our study aims at the {{creation}} of a numerical toolbox that describes wave propagation in samples containing internal contacts (e. g. cracks, delaminations, debondings, imperfect intergranular joints) of known geometry with postulated contact interaction laws including friction. The code consists of two entities: the contact model and the solid mechanics module. Part I of the paper concerns an in-depth description of a constitutive model for realistic contacts or cracks that takes into account the roughness of the contact faces and the associated effects of friction and hysteresis. In the crack model, three different contact states can be recognized: contact loss, total sliding and partial slip. Normal (clapping) interactions between the crack faces are implemented using a quadratic stress-displacement relation, whereas tangential (friction) interactions were introduced using the Coulomb friction law for the total sliding case, and the Method of <b>Memory</b> <b>Diagrams</b> (MMD) in case of partial slip. In the present part of the paper, we integrate the developed crack model into finite element software in order to simulate elastic wave propagation in a solid material containing internal contacts or cracks. We therefore implemented the comprehensive crack model in Matlab and introduced it in the Structural Mechanics Module of Comsol Multiphysics. The potential of the approach for ultrasound based inspection of solids with cracks showing acoustic nonlinearity is demonstrated by means of an example of shear wave propagation in an aluminum sample containing a single crack with rough surfaces and friction. status: publishe...|$|R
40|$|AbstractIn this paper, we {{analyze the}} contact {{interaction}} of axisymmetric particles {{subject to a}} subsequent application of a constant normal load and a tangential or rotational force. A rigorous solution to the frictional contact problem is given by the known Jäger theorem that presents a relationship between shear and normal stress distributions provided the latter is an exact solution to a normal contact problem. However, {{in the case of}} strong loading, when the normal displacement reaches a value of 5 – 10 % of the spheres’ diameter, exact solutions for the normal problem are absent; some model concepts exist instead. For instance, the rod model describes strong normal loading of spheres as a sort of combination of the Hertz problem (weak loading of spheres) with a compression of a pair of confined cylinder of the same radius as the Hertz contact spot. Here we propose a method that is based on considerations similar to the Jäger theorem but is appropriate for any model (or empirical) normal stress distribution. The resulting integral representations describe both shearing and torsion of prestressed particles with axisymmetric profiles. Rolling of particles, as well as plasticity and adhesion of the particles’ material, are not considered. We also analyze the asymptotic behavior of the integral representations for weak and strong strains. The obtained general solutions allow us to use the method of <b>memory</b> <b>diagrams</b> in order to calculate the reaction of the system on arbitrarily varying tangential or rotational actions...|$|R
40|$|This paper {{describes}} a new algorithm {{to solve the}} decision making problem in Influence Diagrams based on algorithms for credal networks. Decision nodes are associated to imprecise probability distributions and a reformulation is introduced that finds the global maximum strategy {{with respect to the}} expected utility. We work with Limited <b>Memory</b> Influence <b>Diagrams,</b> which generalize most Influence Diagram proposals and handle simultaneous decisions. Besides the global optimum method, we explore an anytime approximate solution with a guaranteed maximum error and show that imprecise probabilities are handled in a straightforward way. Complexity issues and experiments with random diagrams and an effects-based military planning problem are discussed. ...|$|R
40|$|We {{present a}} new {{approach}} to the solution of decision problems formulated as influence diagrams. The approach converts the influence diagram into a simpler structure, the LImited <b>Memory</b> Influence <b>Diagram</b> (LIMID), where only the requisite information for the computation of optimal policies is depicted. Because the requisite information is explicitly represented in the diagram, the evaluation procedure can take advantage of it. In this paper we show how to convert an influence diagram to a LIMID and describe the procedure for finding an optimal strategy. Our approach can yield significant savings of memory and computational time when compared to traditional methods. Comment: Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI 2000...|$|R
40|$|In {{this paper}} we compare three {{different}} architectures {{for the evaluation}} of influence diagrams: HUGIN, Shafer-Shenoy, and Lazy Evaluation architecture. The computational complexity of the architectures are compared on the LImited <b>Memory</b> Influence <b>Diagram</b> (LIMID) : a diagram where only the requiste information for the computation of the optimal policies are depicted. Because the requsite information is explicitly represented in the LIMID the evaluation can take advantage of it, and significant savings in computational can be obtained. In this paper we show how the obtained savings is considerably increased when the computations performed on the LIMID is according to the Lazy Evaluation scheme. Comment: Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI 2001...|$|R
40|$|This paper {{shows the}} {{applicability}} of LImited <b>Memory</b> Influence <b>Diagrams</b> (LIMIDs) for modeling pig production decision scenarios. Contrary to influence diagrams LIMIDs do not require remembering of previous information in multi-stage decision problems. An easy LIMID evaluation algorithm using existing software packages is presented. Furthermore, we adopt the techniques from Object Oriented Bayesian Networks (OOBNs) to LIMIDs resulting {{in the concept of}} Object Oriented LIMIDs (OOLs). With the OOL-tool we are one step closer to a coherent process of object oriented analysis, design and implementation of multi-stage decision scenarios. OOL modeling is illustrated through an example from pig production, where a veterinarian on a weekly basis has to decide about treatment of pigs in slaughter pens. ...|$|R
40|$|We {{consider}} {{the situation where}} two agents try to solve each their own task in a common environment. We present a general framework for representing that kind of scenario based on Influence Diagrams (IDs). The framework is used to model the analysis depth and time horizon of the opponent agent and to determine an optimal policy under various assumptions on analysis depth of the opponent. Not surprisingly, the framework {{turns out to have}} severe complexity problems even in simple scenarios due {{to the size of the}} relevant past. We propose an algorithm based on Limited <b>Memory</b> Influence <b>Diagrams</b> (LIMIDs) in which we convert the ID into a Bayesian network and perform single policy update. Empirical results are presented using a simple board game. ...|$|R
40|$|The {{stability}} of von Mises truss is investigated when the stress?strain {{diagram of the}} material constituting the rods displays hysteresis. This behavior, known as pseudo-elasticity, is common in such materials as filled rubbers and shape <b>memory</b> alloys. Loading <b>diagrams</b> are presented; these show that {{the upper and lower}} critical loads depend on the properties of the hysteresis loop for the truss material. Examples for trusses made of shape memory alloys are presented...|$|R
40|$|AbstractApplication Specific Instruction-set Processors (ASIPs) are a {{realistic}} solution for domain-specific applications. To reach optimal system-level performance, memory subsystem design is {{considered in the}} pre-architecture design stage, which narrows down the huge design space to applications of a specific domain. Source code profiling approach aims to understand the characteristics of applications to guide ASIP design. The memory profiler proposed in the paper uses dynamic profiling technique to generate memory traces, and the live intervals of memory objects are computed by load-store information. Then <b>memory</b> requirement <b>diagram</b> is plotted according to instruction counts. The minimum memory requirement of the application is acquired from the diagram and guides the design of memory subsystem. The profiler is tested using a computing kernel, and the memory subsystem design suggestions are given according to the profiling results...|$|R
40|$|In {{this paper}} we present three {{different}} architectures {{for the evaluation}} of influence diagrams: HUGIN, Shafer-Shenoy (S-S), and Lazy Propagation (LP). HUGIN and LP are two new architectures introduced in this paper. The computational complexity using the three architectures are compared on the same structure, the LImited <b>Memory</b> Influence <b>Diagram</b> (LIMID), where only the requisite information for the computation of optimal policies is depicted. Because the requisite information is explicitly represented in the diagram, the evaluation procedure can take advantage of it. Previously, {{it has been shown that}} significant savings in computational time can be obtained by performing the calculation on the LIMID rather than on the traditional influence diagram. In this paper we show how the obtained savings is considerably increased when the computations are performed according to the LP scheme. ...|$|R
3000|$|In {{the second}} stage, {{which is the}} actual {{crawling}} stage, we use the information acquired from the first stage to guide our focused crawler. For this stage, depending on the system's scale, we can choose to store the member profiles either on disk or in main <b>memory.</b> The system <b>diagram</b> is shown in Figure 9, and the process detail is shown in Algorithm 4. In Algorithm 4, similar to the cotagging stage, we classify page [...]...|$|R
40|$|We {{present a}} new {{approach}} to the solution of decision problems formulated as in- uence diagrams. The approach converts the inuence diagram into a simpler structure, the LImited <b>Memory</b> Inuence <b>Diagram</b> (LIMID), where only the requisite information for the computation of optimal policies is depicted. Because the requisite information is explicitly represented in the diagram, the evaluation procedure can take advantage of it. In this paper we show how to convert an inuence diagram to a LIMID and describe the procedure for nding an optimal strategy. Our approach can yield signicant savings of memory and computational time when compared to traditional methods. 1 INTRODUCTION Inuence Diagrams (IDs) were introduced by Howard and Matheson (1981) as a compact representation of decision problems. Since then, various authors have attempted to formalize their approach and develop algorithms for evaluating IDs. Olmsted (1983) and Shachter (1986) initiated research in this di [...] ...|$|R
40|$|LImited <b>Memory</b> Influence <b>Diagrams</b> (LIMIDs) are general {{models of}} {{decision}} problems for representing limited memory policies (Lauritzen and Nilsson (2001)). The evaluation of LIMIDs {{can be done}} by Single Policy Updating that produces a local maximum strategy in which no single policy modification can increase the expected utility. This paper examines the quality of the obtained local maximum strategy and proposes three different methods for evaluating LIMIDs. The first algorithm, Temporal Policy Updating, resembles Single Policy Updating. The second algorithm, Greedy Search, successively updates the policy that gives the highest expected utility improvement. The final algorithm, Simulating Annealing, differs from the two preceeding by allowing the search to take some downhill steps to escape a local maximum. A careful comparison of the algorithms is provided both in terms {{of the quality of the}} obtained strategies, and in terms of implementation of the algorithms including some considerations of the computational complexity. ...|$|R
40|$|A {{seismic signal}} {{processor}} {{was developed and}} tested for use with the NOAA-GOES satellite data collection system. Performance tests on recorded, as well as real time, short period signals indicate that the event recognition technique used is nearly perfect in its rejection of cultural signals and that data can be acquired in many swarm situations {{with the use of}} solid state buffer <b>memories.</b> Detailed circuit <b>diagrams</b> are provided. The design of a complete field data collection platform is discussed and the employment of data collection platforms in seismic network is reviewed...|$|R
40|$|Abstract. We {{present an}} {{application}} of HUGIN to solve problems related to diagnosis and control of autonomous vehicles. The application {{is based on a}} distributed architecture supporting diagnosis and control of autonomous units. The purpose of the architecture is to assist the operator or piloting system in managing fault detection, risk assessment, and recovery plans under uncertainty. To handle uncertainty, we focus on the use of probabilistic graphical models (PGMs) as implemented in the HUGIN tool. We describe the application of PGMs to three problems of diagnosis and control of autonomous vehicles. Based on the HUGIN tool, limited <b>memory</b> influence <b>diagrams</b> (LIMIDs) are used to represent and solve complex problems of diagnosis and control of autonomous ground and underwater vehicles. In particular, we describe how battery monitoring and control problems related to an underwater and a ground vehicle are solved and how {{to solve the problem of}} assessing the quality of a sonar image related to an underwater vehicle. ...|$|R
40|$|For {{offshore}} wind turbines (OWT’s) environmental and accessibility conditions make {{inspection and maintenance}} costly. Hence the potential of cost reduction when the planning of these actions can be optimized. Taking uncertainties into account, a risk based concept is adopted in which probabilities of failure and its consequences are balanced against costs of inspections and actions, including different inspection and maintenance methods. The evolution over time of the structure’s state is represented by {{a state of the}} art crack growth model that takes retardation effects into account due to possible overloads in the fatigue load sequences. Optimizations are obtained by a Bayesian Network schematization of the problem at hand and making use of the Limited <b>Memory</b> Influence <b>Diagram.</b> The paper describes the background of the procedures and illustrates their performance by presenting an example with OWT data. © 2017 Taylor & Francis Group, London. European Safety and Reliability Association; UK Safety and Reliability Society; University of Strathclyde, Scotlan...|$|R
40|$|The {{propagation}} of fire-induced domino effects in chemical plants largely {{depends on the}} primary fire scenario, on separation distances between the units, and {{on the presence of}} fire protection barriers. Passive and active safety barriers are widely employed to prevent or delay the initiation or {{propagation of}} domino effects. In the present study, a methodology has been developed based on Bayesian network to account for the impact of such safety barriers on the propagation of fire domino scenarios. The Bayesian network has been extended to a limited <b>memory</b> influence <b>diagram</b> in order to identify a cost-effective allocation of additional safety barriers to further mitigate the fire propagation. The application of the methodology has been demonstrated using a chemical tank farm. The results are in good agreement with the results of a graph theoretic approach developed in a previous study, proving the reliability of the developed methodology in cost-effective protection of process plants. Safety and Security Scienc...|$|R
40|$|Our study aims at the {{creation}} of a numerical toolbox that describes wave propagation in samples containing internal contacts (e. g. cracks, delaminations, debondings, imperfect intergranular joints) of known geometry with postulated contact interaction laws including friction. The code consists of two entities: the contact model and the solid mechanics module. Part I of the paper concerns the modeling of internal contacts (called cracks for brevity), while part II is related to the integration of the developed contact model into a solid mechanics module that allows the description of wave propagation processes. The contact model is used to produce normal and tangential load-displacement relationships, which in turn are used by the solid mechanics module as boundary conditions at the internal contacts. Due to friction, the tangential reaction curve is hysteretic and memory-dependent. In addition, it depends on the normal reaction curve. An essential feature of the proposed contact model is that it takes into account the roughness of the contact faces. On one hand, accounting for roughness makes the contact model more complicated since it gives rise to a partial slip regime when some parts on the contact area experience slip and some do not. On the other hand, as we will show, the concept of contact surfaces covered by asperities receding under load makes it possible to formulate a consistent contact model that provides nonlinear load-displacement relationships for any value of the drive displacements and their histories. This is a strong advantage, since this way, the displacement-driven model allows for a simple explicit procedure of data exchange with the solid mechanics module, while more traditional flat-surface contacts driven by loads generate a complex iterative procedure. More specifically, the proposed contact model is based on the previously developed method of <b>memory</b> <b>diagrams</b> that allows one to automatically obtain memory-dependent solutions to frictional contact problems in the particular case of partial slip. Here we extend the solution onto cases of total sliding and contact loss which is possible while using the displacement-driven formulation. The method requires the knowledge of the normal contact response obtained in our case as a result of statistical consideration of roughness of contact faces. status: publishe...|$|R
40|$|Research {{presented}} in this paper shows that while a person is recalling a line diagram he can more readily signal information about that diagram by speaking than by spatially monitored output (e. g., pointing to correct items in a column of symbols). When recalling a sentence, he can more readily signal information about that sentence by spatially monitored output than by speaking. These results suggest that spatial and verbal information is recalled and processed in a modality-specific manner. Recall of verbal information is most readily disrupted by concurrent vocal activity; recall of spatial information is most readily disrupted by concurrent spatially monitored activity. This differential conflict occurs even though the concurrent activity is a recoding of the information that is being recalled. A PEBSON is asked to describe from <b>memory</b> a <b>diagram</b> such as a map or floor plan, he is likely to say that he generated a mental representation of the diagram and then derived his description from that. Even in the absence of vivid mental imagery, there is a clear impression tha...|$|R
40|$|Many {{solutions}} to problems in machine learning and artificial intelligence involve solving a combinatorial optimization problem over discrete variables whose functional dependence is conveniently represented by a graph. This thesis addresses three types of these combinatorial optimization problems, namely, the maximum a posteriori inference in discrete probabilistic graphical models, the selection of optimal strategies for limited <b>memory</b> influence <b>diagrams,</b> and the computation of upper and lower probability bounds in credal networks. These three problems arise out of seemingly very different situations, and one might believe that they share {{no more than the}} graph-based specification of their inputs or the underlying probabilistic treatment of uncertainty. However, correspondences among instances of these problems have long been noticed in the literature. For instance, the computation of probability bounds in credal networks can be reduced either to the problem of maximum a posteriori inference in graphical models, or to the selection of optimal strategies in limited <b>memory</b> influence <b>diagrams.</b> Conversely, both the maximum a posteriori inference and the strategy selection problems can be reduced to the computation of a probability bound in a credal network. These reductions suggest that much insight can be gained by carrying out a joint study of the practical and theoretical computational complexity of these three problems. This thesis describes algorithms and complexity results for these three classes of problems. In particular, we develop a new anytime algorithm for the maximum a posteriori problem. Not only the algorithm is of practical relevance, as we show that it compares favorably against a state-of-the-art method, but it is the base of the proof of polynomial-time approximability of the two other problems. We characterize the tractability of the strategy selection problem according to the input parameters, and we show that the strategy selection problem can be solved in polynomial time in singly connected diagrams over binary variables and univariate utility functions, and that relaxing any of these assumptions makes the problem NP-hard to solve or even approximate within any bound. We also investigate the theoretical complexity of computing upper and lower probability bounds in credal networks. We show that the complexity of the problem depends on the irrelevance concept adopted, but is in general NP-hard even in polytree-shaped networks, and even in trees if we assume strong independence. We also show that there is a particular type of inference that can be solved in polynomial time in imprecise hidden Markov models, whether we assume epistemic irrelevance or strong independence...|$|R
50|$|The human {{processor}} model {{uses the}} cognitive, perceptual, and motor processors {{along with the}} visual image, working memory, and long term <b>memory</b> storages. A <b>diagram</b> is shown below. Each processor has a cycle time and each memory has a decay time. These values are also included below. By following the connections diagrammed below, along with the associated cycle or decay times, {{the time it takes}} a user to perform a certain task can be calculated. Studies into this field were initially done by Stuart K. Card, Thomas P. Moran, & Allen Newell in 1983. Current studies in the field include work to distinguish process times in older adults by Tiffany Jastrembski and Neil Charness (2007).|$|R
40|$|We {{present the}} main {{elements}} of a distributed architecture supporting diagnosis and control of autonomous robots. The purpose of the architecture is to assist the operator or piloting system in managing fault detection, risk assessment, and recovery plans under uncertainty. The architecture is generic, open, and modular consisting {{of a set of}} interacting modules including a decision module (DM) and a set of intelligent modules (IMs). The DM communicates with the IMs to request and obtain diagnosis and recovery action proposals based on data obtained from the robot piloting module. The architecture supports the use of multiple artificial intelligence techniques collaborating on the task of handling uncertainty. In this paper we focus on the application of Bayesian modeling to three problems of diagnosis and control of autonomous robots or vehicles. The paper describes and discusses how we use Limited <b>Memory</b> Influence <b>Diagrams</b> (LIMIDs) to represent and solve complex problems of diagnosis and control of ground and underwater robotic vehicles. In particular, we describe how battery monitoring and control problems related to an underwater and a ground vehicle are solved and how a sonar image quality assessment problem related to an underwater vehicle is solved. ...|$|R
40|$|Influence {{diagrams}} are intuitive and concise {{representations of}} structured decision problems. When {{the problem is}} non-Markovian, an optimal strategy can be exponentially large {{in the size of}} the diagram. We can avoid the inherent intractability by constraining the size of admissible strategies, giving rise to limited <b>memory</b> influence <b>diagrams.</b> A valuable question is then how small do strategies need to be to enable efficient optimal planning. Arguably, the smallest strategies one can conceive simply prescribe an action for each time step, without considering past decisions or observations. Previous work has shown that finding such optimal strategies even for polytree-shaped diagrams with ternary variables and a single value node is NP-hard, but the case of binary variables was left open. In this paper we address such a case, by first noting that optimal strategies can be obtained in polynomial time for polytree-shaped diagrams with binary variables and a single value node. We then show that the same problem is NP-hard if the diagram has multiple value nodes. These two results close the fixed-parameter complexity analysis of optimal strategy selection in influence diagrams parametrized by the shape of the diagram, the number of value nodes and the maximum variable cardinality...|$|R
