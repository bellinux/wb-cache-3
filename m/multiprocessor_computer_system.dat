15|10000|Public
50|$|In {{computer}} hardware, {{shared memory}} {{refers to a}} (typically large) block of random access memory (RAM) that can be accessed by several different central processing units (CPUs) in a <b>multiprocessor</b> <b>computer</b> <b>system.</b>|$|E
50|$|SCI is a {{standard}} for connecting the different resources within a <b>multiprocessor</b> <b>computer</b> <b>system</b> {{and it is not}} as widely known to the public as for example the Ethernet family for connecting different systems. Different system vendors implemented different variants of SCI for their internal system infrastructure. These different implementations interface to very intricate mechanisms in processors and memory systems and each vendor has to preserve some degrees of compatibility for both hardware and software.|$|E
50|$|In {{computer}} science, {{distributed memory}} {{refers to a}} <b>multiprocessor</b> <b>computer</b> <b>system</b> in which each processor has its own private memory. Computational tasks can only operate on local data, and if remote data is required, the computational task must communicate {{with one or more}} remote processors. In contrast, a shared memory multiprocessor offers a single memory space used by all processors. Processors {{do not have to be}} aware where data resides, except that there may be performance penalties, and that race conditions are to be avoided.|$|E
40|$|Abstract. This paper {{presents}} {{the use of}} Tabu Search algorithm for solving the problems of coherent synthesis of <b>multiprocessor</b> <b>computer</b> <b>systems.</b> The paper includes a coherent solution of both optimization of partition resources and optimization of tasks scheduling. This publication shows results of computational experiments for different instances of system synthesis problems...|$|R
50|$|In computing, Intel's Advanced Programmable Interrupt Controller (APIC) is {{a family}} of {{interrupt}} controllers. As its name suggests, the APIC is more advanced than Intel's 8259 Programmable Interrupt Controller (PIC), particularly enabling the construction of multiprocessor systems. It {{is one of several}} architectural designs intended to solve interrupt routing efficiency issues in <b>multiprocessor</b> <b>computer</b> <b>systems.</b>|$|R
40|$|Most of the {{existing}} relational database query optimizers generate multi-way join plans only from those linear ones to reduce the optimiza-tion overhead. For <b>multiprocessor</b> <b>computer</b> <b>systems,</b> this strategy seems inadequate since it may reduce the search space too much to gen-erate near-optimal plans. In this paper we present a framework for optimization of multi-way join queries in <b>multiprocessor</b> <b>computer</b> <b>systems.</b> The optimization process not only determines the order and method in which each join should be performed, but also determines the number of joins should be executed in paral-lel, {{and the number of}} processors should be allo-cated to each join. The preliminary performance study shows that the optimizer usually generate optimal or near-optimal plans when the number of joins is relatively small. Even when the number of joins increases, the algorithm still gives reasonably good performance. Further-more, the optimization overhead is much lesser compared to exhaustive search...|$|R
40|$|The work {{covers the}} {{algorithms}} of large mathematical {{operations for the}} spectral methods of solving integral equations. The aim is to develop the structure and algorithmic facilities of the specialized <b>multiprocessor</b> <b>computer</b> <b>system</b> oriented to the solution of complex integral equations by spectral methods and intended for construction of the super-high performance computer complexes. The parallel algorithms of large mathematical operations for the spectral methods of solving integral equations, parallel algorithm of the digital screen refresh and also the model of <b>multiprocessor</b> <b>computer</b> <b>system</b> have been developed. The structure of specialized <b>multiprocessor</b> <b>computer</b> <b>system</b> and its components has been developed. The methods and module library of the computer-aided program binding for specialized computer system have been developed. The library of the digital screen refresh algorithms has been developed. The results have been introduced in the Research Institute of Multiprocessor Computer Systems (c. Taganrog). Rostov Division of North-Caucasian Railway (c. Rostov), Production Association "AOMZ" (t. Azov). Application field: multiprocessor computer systemsAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|E
40|$|Design {{concept for}} <b>multiprocessor</b> <b>computer</b> <b>system</b> calls for digital {{electronic}} processing circuits of various functionalities contained within identically shaped and sized regular polygonal modules interconnected and stacked {{by use of}} rings around edges. Rings contain wide-band bus circuits configured to provide connections to adjacent modules in same layer of stack and/or to modules in different layers. Provides flexibility of configuration to implement any of large variety of designs...|$|E
40|$|A reaction-diffusion stereo {{algorithm}} {{consists of}} multi-sets of reaction-diffusion equations. Since the equations are described with time-evolving partialdifferential equations, they require much computation time. In addition, the previous algorithm does not state any criterion for convergence judgement; {{we need to}} compute the equations for enough duration of time until their solutions converge. In this work, for reducing computation time in the algorithm, we propose a criterion for convergence judgement and implement the algorithm on a <b>multiprocessor</b> <b>computer</b> <b>system.</b> ...|$|E
40|$|The halfsweep multigrid algorithm, {{introduced}} by Othman et al in 1998 for solving a linear system, {{is known as}} a fast multigrid poisson solver. In this paper, the implementation of the parallel halfsweep multigrid algorithm with several parallel strategies is discussed. The experiments were carried out on the shared memory <b>multiprocessors</b> <b>computer</b> <b>system,</b> Sequent S 27, and the results of the test problem are included...|$|R
50|$|In <b>multiprocessor</b> <b>computer</b> <b>systems,</b> {{software}} lockout is {{the issue}} of performance degradation due to the idle wait times spent by the CPUs in kernel-level critical sections. Software lockout is the major cause of scalability degradation in a multiprocessor system, posing a limit on the maximum useful number of processors. To mitigate the phenomenon, the kernel must be designed to have its critical sections as short as possible, therefore decomposing each data structure in smaller substructures.|$|R
40|$|Abstract — We study an M/G/ 1 retrial queue with {{negative}} arrivals and repeated attempts. This model {{is motivated by}} several practical applications. In <b>multiprocessor</b> <b>computer</b> <b>systems,</b> negative arrivals represent commands to delete some transactions. In Neural networks, primary and negative arrivals represent excitatory and inhibitory signals respectively. Such models {{can be used in}} relation with some problems of virus infection. We obtain the generating function of the number of primary customers in the system in stationary regime...|$|R
40|$|Abstract: The sun {{radiation}} transport in the atmosphere-ocean system (SAO) is simulated as {{the radiation}} transfer in two-media slab with air-water dividing border, reflecting and refracting of radiation on Frenel's law. The {{contribution of the}} media dividing interface and of the ocean as the scattering medium are evaluated by the influence functions method. Several models of taking account of the atmosphere-ocean interchange of short-wave radiation are suggested as the different approaches to the optical transfer operator of SAO. A new approach is effective in case when the atmosphere is dynamic and the ocean is conservative. Constructed algorithm is adaptable to the <b>multiprocessor</b> <b>computer</b> <b>system</b> with the parallel structure. Note: Publication language:russia...|$|E
40|$|The Rijnhuizen Tokamak Project RTP is a {{medium-sized}} tokamak experiment, {{which requires a}} very reliable data-acquisition system, due to its pulsed nature. Analysing the limitations of an existing CAMAC-based data-acquisition system showed, that substantial increase of performance and flexibility could best be obtained by {{the construction of an}} entirely new system. This system, called TRAMP (Transient Recorder and Amoeba Multi Processor), is based on tailor-made transient recorders with a <b>multiprocessor</b> <b>computer</b> <b>system</b> in VME running Amoeba. The performance of TRAMP exceeds the performance of the CAMAC system by a factor of four. The plans to increase the flexibility and for a further increase of performance are presented...|$|E
40|$|A {{high-performance}} {{platform for}} development of real-time helicopter flight simulations based on a simulation development and analysis platform combining a parallel simulation development and analysis environment with a scalable <b>multiprocessor</b> <b>computer</b> <b>system</b> is described. Simulation functional decomposition is covered, including the sequencing and data dependency of simulation modules and simulation functional mapping to multiple processors. The multiprocessor-based implementation of a blade-element simulation of the UH- 60 helicopter is presented, and a prototype developed for a TC 2000 computer is generalized in order {{to arrive at a}} portable multiprocessor software architecture. It is pointed out that the proposed approach coupled with a pilot's station creates a setting in which simulation engineers, computer scientists, and pilots can work together in the design and evaluation of advanced real-time helicopter simulations...|$|E
40|$|Abstract. The {{combinatorial}} algorithm of the Group Method of Data Handling is a compute intensive modelling method well proven {{for analysis}} and forecast {{of a variety}} of complex systems especially of the so-called “black-box ” type. The algorithm is highly dependent on computational power that makes the use of multiprocessing reasonable. To exploit efficiently different kinds of <b>multiprocessor</b> <b>computer</b> <b>systems</b> we propose an adaptive parallel implementation of the combinatorial GMDH algorithm and an example of its usage for the forecasting of the “Top 500 Supercomputer’s List”...|$|R
40|$|This paper {{describes}} the study about behavior of multithreading programming running over <b>multiprocessor</b> <b>computer</b> <b>systems</b> and extraction of data during multithreaded program executions for posterior analysis. The programming language selected for implementation of algorithms and study of work stealing scheduling method was Cilk, where {{we expect to}} obtain rough data about multithreaded computations, perform data analysis and finally obtained information from program execution must be represented graphically in a post mortem fashion to ease the programmer to visualize partially how the written code is processed...|$|R
40|$|The five-stage {{switching}} {{system with a}} parallel search is considered in the paper. It {{can be used in}} data networks and <b>multiprocessor</b> <b>computer</b> <b>systems.</b> The algorithm of a parallel search of free communication channels in the five- stage {{switching system}}, based on a theoretical and multiple model and representation {{of the structure of the}} switching system in the form of the data array is offered. The algorithm enables to fulfill a parallel adjustment of the switching system along with information transmission, and the search of connecting ways occurs inside this switching field...|$|R
40|$|Over {{the past}} decade, {{multiprocessor}} {{systems have been}} applied in computer technology. At present,multi-core processors are equipped not only with supercomputers, {{but also with the}} vast majority of mobile devices. This creates the need for students to learn the basic principles of their construction and functioning. One of the possible methods for analyzing the operation of multiprocessor systems is simulation modeling. Its use contributes {{to a better understanding of}} the effect of workload and structure parameters on performance. The article considers the features of the development of the simulation model for estimating the time characteristics of a <b>multiprocessor</b> <b>computer</b> <b>system,</b> as well as the use of the regenerative method of model analysis. The characteristics of the software implementation of the inverse kinematics solution of the robot are adopted as a workload. The given task consists in definition of turns in joints of the manipulator on known angular and linear position of its grasp. An analytical algorithm for solving the problem was chosen, namely, the method of simple kinematic relations. The work of the program is characterized by the presence of parallel calculations, during which resource conflicts arise between the processor cores, involved in simultaneous access to the memory via a common bus. In connection with the high information connectivity between parallel running programs, it is assumed that all processing cores use shared memory. The simulation model takes into account probabilistic memory accesses and tracks emerging queues to shared resources. The collected statistics reveal the productive and overhead time costs for the program implementation for each processor core involved. The simulation results show the unevenness of kernel utilization, downtime in queues to shared resources and temporary losses while waiting for other cores due to information dependencies. The results of the simulation are estimated by the regenerative method, which allows determining the average time spent searching for memory access in queues and the confidence intervals of these values for various degrees of trust. The given approach to the construction of the simulation model of a <b>multiprocessor</b> <b>computer</b> <b>system</b> and its analysis can be used to analyze the functioning of parallel computing systemsand for educational purposes for teaching students at the courses “Computer Systems” and “Simulation Modeling”.  </p...|$|E
40|$|AbstractIn this paper, {{performance}} measures of a <b>multiprocessor</b> <b>computer</b> <b>system</b> {{with a single}} bus are studied by a queueing theoretic approach. The processors and the shared bus are assumed to operate in independent Markovian environments. The time intervals from {{the completion of the}} previous bus usage to the generation of a new request for each processor as well as the times that a processor uses the bus as the result of arbitration are supposed to be exponentially distributed random variables with parameter depending {{on the state of the}} corresponding environmental process. Supposing that the arrival rate of the requests is much greater than their service rate (“fast” arrival), it is shown that the busy period length of the bus converges weakly, under appropriate norming, to an exponentially distributed random variable. As a utilization, the throughput, the mean delay time, the expected waiting time, the average number of requests served during a busy period, and the mean number of active processors are calculated. Moreover, exact and approximate validation results are presented to illustrate the credibility of the proposed method...|$|E
40|$|A {{processor}} utilization {{model for}} a simplified <b>multiprocessor</b> <b>computer</b> <b>system</b> is developed. Jobs are assumed to arrive according to a general input process, and each job is assigned randomly to an available processor. A finite capacity input buffer is used if no processor is available. The mathematical model {{is based on the}} busy period analysis, and two utilization measures are derived: (1) processor utilization when the system is busy (the fraction of processor occupation time during a busy period), and (2) global processor utilization (the fraction of processor occupation time during a busy cycle). Additionally, the arbitrary time state probability distribution is obtained and serves {{as the basis for the}} above measures in addition to others. Several approximations enable the development of a computational model from the mathematical model. Experimentation with the computational model reveals the sensitivity of the model to variability in the arrival process. Comparison of 2 -processor and 4 -processor systems from the operator perspective indicates a qualified preference for the behavior of the 2 -processor system. This preference must be carefully interpreted since processor costs, the increase in overhead with an increase in processors, and behavioral variables reflecting the user perspective are excluded...|$|E
50|$|The Cray Superserver 6400, or CS6400, is a {{discontinued}} <b>multiprocessor</b> server <b>computer</b> <b>system</b> {{produced by}} Cray Research Superservers, Inc., {{a subsidiary of}} Cray Research, and launched in 1993. The CS6400 was also sold as the Amdahl SPARCsummit 6400Ehttp://www.spikynorman.dsl.pipex.com/CrayWWWStuff/prfoldercomp/CRAY_AMDAHL_AGMT.950228.txt.|$|R
40|$|Deterministic, {{parallel}} set-term unification algorithms, {{of which}} set terms have the commutative and idempotent properties, are lacking. As a result, a concurrent, deterministic inference mechanism {{that can be}} used to compute unifiers of a pair of set terms is missing. To overcome these shortcomings, we propose a parallel set-term unification algorithm. The proposed algorithm not only computes all generalized ground unifiers of a given pair of set terms without duplicates, but also takes advantage of existing <b>multiprocessor</b> <b>computer</b> <b>systems</b> for computing all these unifiers in parallel. Cost analysis of the proposed algorithm is included in this paper...|$|R
40|$|The results {{presented}} here {{are based on}} many years of experience of development and application of DYANA – an environment for analysis of <b>multiprocessor</b> <b>computer</b> <b>systems</b> operation. The architecture and basic features of such an environments are discussed. Main problems arizing during such an environments design are highlighted and possible solutions are shown. The key features of the DYANA environment are: the possibility of both quantitative and algorithmic analysis of system to be modeled; the time complexity estimation subsystem which helps to avoid the instruction-level simulation of target computer system; support of program development through simulation. 1...|$|R
40|$|We {{describe}} {{the development of}} a real-time processing tool for hyperspectral imagery based on off-the-shelf equipment and higher level programming language implementation (C++ and Java). The algorithms we developed are derived from previously introduced spectra matching and feature extraction tools. The first group is based on spectra identification and spectral screening, a method that allows the identification of representative spectra from a data set. The second group is based on Principal Component Analysis (PCA) and Independent Component Analysis (ICA). When applied to multidimensional data, PCA linearly transforms them such that the resulting components are uncorrelated and their variance maximized. In ICA, given a linear mixture of statistical independent sources, the goal is to recover these components by producing an unmixing matrix. The effectiveness of the proposed real time algorithms were tested on an in-house system composed of a commercially available hyperspectral camera and a <b>multiprocessor</b> <b>computer</b> <b>system.</b> Preliminary results targeted at the feasibility of the tool show that reasonable accuracy can be maintained in the real time requirements. The described project supports the further development of hyperspectral imaging as a general tool in remote sensing...|$|E
40|$|Tomographic breast imaging {{techniques}} {{can be used}} to quantify radiotracer uptake in breast and tumor tissue. However, physical processes common to PET imaging can confound accurate quantification. In this investigation, we assessed the effects of these phenomena and tested correction schemes for our new positron emission mammography–tomography system (PEM–PET). The PEM–PET scanner utilizes two sets of rotating planar detector heads. Each unit consists of a 4 × 3 array of Hamamatsu H 8500 flat panel position sensitive photomultipliers coupled to a 96 × 72 array of 2 × 2 × 15 mm 3 LYSO detector elements (pitch= 2. 1 mm). Image reconstruction is performed with a 3 D-OSEM algorithm parallelized to run on a <b>multiprocessor</b> <b>computer</b> <b>system.</b> The reconstructed field-of-view is 15 × 15 × 15 cm 3. Much of the testing procedures were based on NEMA-NU 2 ∕ 2001 protocols. Count rate losses due to pulse pile-up, image contamination due to acceptance of random coincidences and Compton scatter, and image artifacts produced by photon attenuation were measured. It was found that the system was susceptible to count rate losses when moderate levels of radiation were present in the scanner due to the current design of the event trigger electronics. Application of corrections for Compton scattering, photon attenuation and dead time resulted in improved estimations of 18 F concentration in simplified phantom studies. Results from these preliminary studies indicate that the PEM–PET scanner will be useful for the quantification of radiotracer uptake in breast tumors, possibly facilitating early assessment of cancer treatments...|$|E
40|$|A {{fault-tolerant}} <b>multiprocessor</b> <b>computer</b> <b>system</b> of the hypercube type comprising {{a hierarchy}} of computers of like kind which can be functionally substituted for one another as necessary is disclosed. Communication between the working nodes is via one communications network while communications between the working nodes and watch dog nodes and load balancing nodes higher in the structure is via another communications network separate from the first. A typical branch of the hierarchy reporting to a master node or host computer comprises, a plurality of first computing nodes; a first network of message conducting paths for interconnecting the first computing nodes as a hypercube. The first network provides a path for message transfer between the first computing nodes; a first watch dog node; and a second network of message connecting paths for connecting the first computing nodes to the first watch dog node independent from the first network, the second network provides an independent path for test message and reconfiguration affecting transfers between the first computing nodes and the first switch watch dog node. There is additionally, a plurality of second computing nodes; a third network of message conducting paths for interconnecting the second computing nodes as a hypercube. The third network provides a path for message transfer between the second computing nodes; a fourth network of message conducting paths for connecting the second computing nodes to the first watch dog node independent from the third network. The fourth network provides an independent path for test message and reconfiguration affecting transfers between the second computing nodes and the first watch dog node; and a first multiplexer disposed between the first watch dog node and the second and fourth networks for allowing the first watch dog node to selectively communicate with individual ones of the computing nodes through the second and fourth networks; as well as, a second watch dog node operably connected to the first multiplexer whereby the second watch dog node can selectively communicate with individual ones of the computing nodes through the second and fourth networks. The branch is completed by a first load balancing node; and a second multiplexer connected between the first load balancing node and {{the first and second}} watch dog nodes, allowing the first load balancing node to selectively communicate with the first and second watch dog nodes...|$|E
40|$|As <b>multiprocessor</b> <b>computer</b> <b>systems</b> {{become more}} commonplace, and {{peripherals}} are built with on-board CPUs, {{we believe that}} new operating system models are required {{to make the most}} ecient use of such systems. At the same time, the role of computers is changing from a computational device to a communications tool, thus emphasising the ability to eciently support multimedia communication rather than computation alone. These changes prompted the development of Piglet, an asymmetric multiprocessor operating system. Piglet partitions processors into functional groups in order to better utilise multiple proces-sors. We describe the implementation of Piglet and show how it can provide ecient multiplexing of shared resources. ...|$|R
40|$|This paper {{covers the}} model of oil {{products}} transport in view the evaporation of light, neutral and no-evaporating pseudofractions of oil slick, dissolution of oil slick and biodegradation. Approximation of diffusion-convection problem {{was performed on the}} basis of schemes of high-order of accuracy. Experimental software was designed for mathematical modelling of possible scenarios of development of ecosystems of shallow waters for oil spills on the example of the Azov-Black Sea basin, based on <b>multiprocessor</b> <b>computer</b> <b>systems.</b> Decomposition methods of grid domains have been used for computationally laborious diffusion-convection tasks in parallel implementation. Maximum acceleration was equal to 228. 36 times on 512 computational nodes...|$|R
40|$|There {{the study}} objects are the <b>multiprocessor</b> <b>computer</b> <b>systems</b> and networks. The {{purposes}} are {{to develop the}} mathematical apparatus of mechanisms {{of control over the}} data flows and powers in the networks and multiprocessor systems; to develop the common methodological basis and the set of new mathematical simulators and methods for study, estimation of effectiveness and practical choice of control mechanisms of data flows and powers in the networks and multiprocessor systems. The application field is the introduction in development of MOST program sluice to construct the non-uniform networks and in creation of non-uniform information computer networks. Available from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|The {{ability to}} {{understand}} the behavior of con-current programs depends greatly on the facili-ties available to monitor execution and present the results to the user. Beyond the basic profil-ing tools that collect data for post-mortem view-ing, explorative use of <b>multiprocessor</b> <b>computer</b> <b>systems</b> demands a dynamic monitoring environ-ment capable of providing run-time access to pro-gram performance. A prototype of such an envi-ronment has been built for the Cedar multipro-cessor. This paper describes {{the design of the}} in-frastructure enabling run-time monitoring of par-allel Cedar applications and the communication of execution data among physically distributed machines. An application for matrix visualira-tion is used to highlight important aspects of the system. ...|$|R
40|$|In {{this report}} we {{describe}} the tools that we have used, developed, and implemented in a <b>computer</b> <b>system</b> for simulation of flows in porous media. Our goal {{was to create a}} simulator that uses various tools and that is based on discretization by finite elements and finite volumes and uses e#cient preconditioning iterative methods for the resulting large sparse system. Also important features are error control, adaptive grid refinement and parallel implementation on <b>multiprocessor</b> <b>computer</b> <b>systems</b> utilizing the concept of domain decomposition. The tools include (1) 3 -D mesh generator (NETGEN), (2) partitioning and load balancing software (METIS), (3) local error control and refinement procedures, (4) preconditioning methods based on domain decomposition and multigrid/multilevel, and (5) MPI and the OpenMP standards for massively parallel computations...|$|R
40|$|Particle {{filtering}} has a {{great potential}} for solving highly nonlinear and non-Gaussian estimation problems, generally intractable within a standard linear Kalman filtering based framework. However, the implementation of particle filters (PFs) is rather computationally involved, which nowadays prevents them from practical real-world application. A natural idea to make PFs feasible for "real-time" data processing is to implement them on distributed <b>multiprocessor</b> <b>computer</b> <b>systems.</b> This paper presents three schemes for distributing the computations of generic particle filters, including resampling and, optionally, a Metropolis-Hastings (MH) step. Simulation results based on a maneuvering target tracking scenario show that distributed implementations can provide a promising solution to the steep computational burden incurred when using {{a large number of}} particles...|$|R
40|$|Abstract: The system {{diagnosis}} {{has been}} extensively studied in the literature in connection with fault-tolerant <b>multiprocessor</b> <b>computer</b> <b>systems.</b> An original graph-theoretical model for system diagnosis was introduced in a classic paper by Preparata, Metze, and Chien in 1967. Yang and Masson extended the model to the case when the system has some intermittent faults, and gave a characterization of diagnosability under their model. However, their proof is not constructive, that is present no diagnosis algorithm for systems. In this paper, we present two diagnosis algorithms under the model by Yang and Masson: one is a polynomial-time algorithm for system with high connectivity, {{and the other is}} a linear time algorithm for system with high degree...|$|R
40|$|In {{order to}} exploit the {{capability}} and performance of modern processors in safety critical applications, it is desirable {{to be able to}} run software of differing integrity levels on the same processor. To do this safely, however, requires the ability to enforce partitioning between these different integrity levels. For certification, {{there is a need to}} demonstrate the effectiveness of these partitioning mechanisms. In practice, this means analysing the hardware, e. g. memory management units, and software, e. g. operating system functions, which implement the protection mechanisms – and analysing the hardware-software interactions. This paper describes a method, known as LISA, developed to analyse low-level hardwaresoftware interactions in <b>multiprocessor</b> <b>computer</b> <b>systems,</b> and draws some conclusions from experience of applying the method on a complex avionics system. ...|$|R
40|$|The {{complexity}} of modern <b>computer</b> <b>systems,</b> {{coupled with the}} diverse workloads that they must support, presents a challenge to researchers and designers who need to understand a system's behavior. We describe SimOS, a machine simulation environment designed for the efficient and accurate study of both uniprocessor and <b>multiprocessor</b> <b>computer</b> <b>systems.</b> SimOS simulates <b>computer</b> hardware in enough detail to run an entire operating system. By running a commercial operating system, SimOS provides the ability to investigate realistic workloads, which was not possible with previous simulation tools. SimOS also provides substantial flexibility in the trade-off between the speed and detail of a simulation. We employ fast simulation techniques to scan over the less interesting, time-consuming parts of a workload. To focus in on interesting sections of a workload's execution, we employ slower, more detailed levels of simulation. SimOS' ability to change levels of detail on-the-fly enhances its a [...] ...|$|R
