214|8799|Public
500|$|A <b>massively</b> <b>parallel</b> <b>processor</b> (MPP) is {{a single}} {{computer}} with many networked processors. MPPs have {{many of the same}} characteristics as clusters, but MPPs have specialized interconnect networks (whereas clusters use commodity hardware for networking). MPPs also tend to be larger than clusters, typically having [...] "far more" [...] than 100processors. In an MPP, [...] "each CPU contains its own memory and copy of the operating system and application. Each subsystem communicates with the others via a high-speed interconnect." ...|$|E
5000|$|Ambric Am2045, a 336-core <b>Massively</b> <b>Parallel</b> <b>Processor</b> Array (MPPA) ...|$|E
5000|$|<b>Massively</b> <b>Parallel</b> <b>Processor</b> (MPP), from NASA/Goddard Space Flight Center, c. 1983-1991 ...|$|E
50|$|Xetal is {{the name}} of a family of non {{commercial}} <b>massively</b> <b>parallel</b> <b>processors</b> developed within Philips Research..|$|R
40|$|PARCS is a {{declarative}} parallel constraint {{logic programming}} (CLP) language designed for efficient execution on distributed memory <b>massively</b> <b>parallel</b> <b>processors</b> (MPPs). As a language model, PARCS offers efficient parallel execution control via priority-based goal and constraint execution, powerful pruning mechanisms, and implicit OR-parallelism. Its MPPoriented implementation techniques include efficient load balancing, branching method and static compile-time optimization {{techniques such as}} mode-specific code generation, static ordering of deterministic constraints and determinacy analysis. Actual experiments have shown good speedups {{with respect to the}} number of processors for various kinds of programs, such as N-queens and paraffin problem. Keywords: constraint logic programming, <b>massively</b> <b>parallel</b> <b>processors,</b> load balancing, compilation techniques 1 Introduction Although <b>massively</b> <b>parallel</b> <b>processors</b> (MPPs) are available from various vendors these days, it is often cumbersome t [...] ...|$|R
50|$|Nervous systems {{differ from}} the {{majority}} of silicon-based computing devices in that they resemble analog computers (not digital data <b>processors)</b> and <b>massively</b> <b>parallel</b> <b>processors,</b> not sequential processors. To model nervous systems accurately, in real-time, alternative hardware is required.|$|R
5000|$|Microprocessor Report gave a 2006 MPR Analysts’ Choice Award for Innovation for the Ambric-{{architecture}} [...] "for {{the design}} concept and architecture of its <b>massively</b> <b>parallel</b> <b>processor,</b> the Am2045".|$|E
50|$|The Ambric Am2045 <b>massively</b> <b>parallel</b> <b>processor</b> array is a KPN {{implemented}} in actual silicon. Its 336 32-bit processors are {{connected by a}} programmable interconnect of dedicated FIFOs. Thus its channels are strictly bounded with blocking writes.|$|E
5000|$|While Kalb was the {{vice-president}} {{of the division}} of Digital Equipment Corporation (DEC) that built integrated circuits, some researchers in that division were building a supercomputer based on the Goodyear MPP (<b>massively</b> <b>parallel</b> <b>processor)</b> supercomputer. The DEC researchers enhanced the architecture by: ...|$|E
50|$|Graphics {{processing}} {{units have}} evolved beyond pure graphics accelerators {{with the addition}} of general purpose programmable floating point units applicable to general purpose computing. They differ from most CPUs in being <b>massively</b> <b>parallel</b> <b>processors</b> optimized for data-parallel throughput instead of rapid individual-instructions of low latency.|$|R
5000|$|Examples of {{distributed}} memory (multicomputers) include MPP (<b>massively</b> <b>parallel</b> <b>processors)</b> and COW (clusters of workstations). The former {{is complex and}} expensive: lots of super-computers coupled by broad-band networks. Examples include hypercube and mesh interconections. COW is the [...] "home-made" [...] version {{for a fraction of}} the price.|$|R
40|$|INTRODUCTION When Bellman {{introduced}} {{dynamic programming}} in his original monograph [8], computers {{were not as}} powerful as current personal computers. Hence, {{his description of the}} extreme computational demands as the Curse of Dimensionality [9] would not have had the super and <b>massively</b> <b>parallel</b> <b>processors</b> of today in mind. However, massive and super computers can not overcome the Curse of Dimensionality alone, but parallel and vector computation can permit the solution of higher dimension than was previously possible and thus permit more realistic dynamic programming applications. Today such large problems are called Grand and National Challenge problems [45, 46] in high performance computing. Today's availability of high performance vector supercomputers and <b>massively</b> <b>parallel</b> <b>processors</b> have made it possible to compute optimal policies and values of control systems for much larger dimensions than was possible earlier. Advanc...|$|R
50|$|On some <b>massively</b> <b>parallel</b> <b>processor</b> (MPP) installations, {{computational}} processors {{can access}} a Lustre file system by redirecting their I/O requests to a dedicated I/O node configured as a Lustre client. This approach {{is used in}} the Blue Gene installation at Lawrence Livermore National Laboratory.|$|E
5000|$|<b>Massively</b> <b>Parallel</b> <b>Processor</b> (16,384 custom bit-serial {{processors}} {8 to a chip} {{organized in}} a SIMD 128 x 128 processor array with additional CPU rows for fault-tolerance) which was {{located at the}} NASA Goddard Space Flight Center, {{and is now in}} the Smithsonian. This unit predates Danny Hillis' Thinking Machines Corporation's Connection Machine ...|$|E
50|$|A generous {{interpretation}} of the rule allows for the case in which an ideal device could contain hundreds of low-complexity cores, each operating at very low power and together performing large amounts of (processing) work quickly. This describes a <b>massively</b> <b>parallel</b> <b>processor</b> array (MPPA), which is currently being used in embedded systems and hardware accelerators.|$|E
40|$|Introduction We {{have been}} {{studying}} and developing a computational model and system which {{can be applied to}} solve real-world problems on <b>massively</b> <b>parallel</b> <b>processors.</b> As a target problem, we examine a large-scale real-world simulation which is considered {{to be one of the}} best applications for <b>massively</b> <b>parallel</b> <b>processors.</b> A real-world simulation is characterized by the need to derive useful results even with incomplete information. Not all of factors required for complete simulation are known at first. By providing new factors to the simulator, the precision of the simulation can be improved. Our objective is to establish a new programming paradigm suitable for <b>massively</b> <b>parallel</b> programming. We thus propose a "spacetime object model", which enables us to solve our large-scale real-world problems efficiently. 2. Space-Time Object Model A "space-time object model" provides a set of functions required to describe the structure and control of space and time for t...|$|R
40|$|The Myrinet {{local area}} network employs the same {{technology}} used for packet communication and switching within <b>massively</b> <b>parallel</b> <b>processors.</b> In realizing this distributed MPP network, we developed specialized communication channels, cut-through switches, host interfaces, and software. To our knowledge, Myrinet demonstrates the highest performance per unit cost of any ament LAN...|$|R
40|$|As the {{resolution}} of simulation models increases, scientific visualization algorithms which {{take advantage of the}} large memory. and parallelism of <b>Massively</b> <b>Parallel</b> <b>Processors</b> (MPPs) are becoming increasingly important. For large applications rendering on the MPP tends to be preferable to rendering on a graphics workstation due to the MPP`s abundant resources: memory, disk, and numerous processors. The challenge becomes developing algorithms that can exploit these resources while minimizing overhead, typically communication costs. This paper will describe recent efforts in parallel rendering for polygonal primitives as well as parallel volumetric techniques. This paper presents rendering algorithms, developed for <b>massively</b> <b>parallel</b> <b>processors</b> (MPPs), for polygonal, spheres, and volumetric data. The polygon algorithm uses a data parallel approach whereas the sphere and volume render use a MIMD approach. Implementations for these algorithms are presented for the Thinking Ma. chines Corporation CM- 5 MPP...|$|R
50|$|Ambric {{architecture}} and processors {{were developed by}} Ambric, Inc. Its Am2045 <b>Massively</b> <b>Parallel</b> <b>Processor</b> Array (MPPA) chips were primarily used in high-performance embedded systems such as medical imaging, video, and signal-processing. Ambric was founded in 2003, developed and introduced the Am2045 and its software tools in 2007, and fell victim to the crash of 2008. Ambric's Am2045 and tools remained available through Nethra Imaging, Inc., which closed in 2012.|$|E
50|$|The Goodyear <b>Massively</b> <b>Parallel</b> <b>Processor</b> (MPP) was amassively {{parallel}} processing supercomputer built by Goodyear Aerospacefor the NASA Goddard Space Flight Center.It {{was designed to}} deliver enormous computational power at lower cost thanother existing supercomputer architectures, by using thousands ofsimple processing elements, rather than {{one or a few}} highly complex CPUs.Development of the MPP began circa 1979; it was delivered in May 1983,and was in general use from 1985 until 1991.|$|E
5000|$|Mitrionics is a Swedish company {{manufacturing}} softcore reconfigurable processors. It {{has been}} mentioned as one of EETimes [...] "60 Emerging startups".The company was founded in 2001 by Stefan Möhl and Pontus Borg to commercialize a massively parallel reconfigurable processor implemented on FPGAs. It {{can be described as}} turning general purpose chips into massive parallel processors {{that can be used for}} high performance computing. Mitrionics <b>massively</b> <b>parallel</b> <b>processor</b> is available on Cray, Nallatech, and Silicon Graphics systems.|$|E
40|$|HPF is a data {{parallel}} Fortran dialect currently implemented on diverse hardware platforms {{ranging from}} workstations to <b>massively</b> <b>parallel</b> <b>processors.</b> To date, performance data are sparse. We will present preliminary measurements of selected benchmarks, comparing HPF applications against equivalent SPMD implementations {{and the same}} HPF implementation running with different compilers on different hardware. We will discuss software issues in light of how they affect performance. 1 Introduction High Performance Fortran (HPF) [3] is a data parallel Fortran dialect designed by the High Performance Fortran Forum (HPFF), a volunteer group of representatives from industry and academia. HPF is currently implemented by several commercial vendors and runs {{on a variety of}} platforms ranging from workstations to <b>massively</b> <b>parallel</b> <b>processors.</b> An interesting question is how HPF implementations compare against equivalent SPMD implementations. Some performance data can be found via the HPF home page: [...] ...|$|R
40|$|In {{this paper}} we review network related {{performance}} issues for current <b>Massively</b> <b>Parallel</b> <b>Processors</b> (MPPs) {{in the context}} of some important basic operations in scientific and engineering computation. The communication system {{is one of the most}} performance critical architectural components of MPPs. In particular, understanding the demand posed by collective communication is critical in architectural design and system software implementation. We discuss collective communication and some implementation techniques therefore on electronic networks. Finally, we give an example of a novel general routing technique that exhibits good scalability, efficiency and simplicity in electronic networks. 1 Introduction <b>Massively</b> <b>Parallel</b> <b>Processors</b> (MPPs) are a critical resource for large [...] scale computation in science and engineering. Accurate modeling require large data sets. For most applications, there is an inherent high degree of fine grain parallelism (data parallelism) in those data sets. Many [...] ...|$|R
40|$|Concurrent {{programs}} often exhibit nondeterministic behavior because execution {{order of}} concurrent events may involve some arbitrariness. Such indeterminacy {{makes it difficult}} to find the sources of program errors. We propose a debugging scheme for fine-grain <b>parallel</b> programs on <b>massively</b> <b>parallel</b> <b>processors.</b> It facilitates (1) replay of a specific execution {{with a small amount of}} log information, provided that the intra-node scheduling policy employed is deterministic and known, and (2) by using scalar timestamps, it also detects "race" conditions where message arrival order causes indeterminacy. We evaluate its performance through a prototype debugging system for a concurrent object-oriented language ABCL/f on a multicomputer AP 1000 + with 32 - 1024 nodes. 1 Introduction Recently, large-scale <b>massively</b> <b>parallel</b> <b>processors</b> (MPPs) such as CM- 5, AP 1000 +, and Cenju have been commercially available. The interest in parallel programming has grown significantly, and parallel programming broad [...] ...|$|R
50|$|The term {{also applies}} to <b>massively</b> <b>parallel</b> <b>processor</b> arrays (MPPAs), a type of {{integrated}} circuit {{with an array of}} hundreds or thousands of central processing units (CPUs) and random-access memory (RAM) banks. These processors pass work to one another through a reconfigurable interconnect of channels. By harnessing a large number of processors working in parallel, an MPPA chip can accomplish more demanding tasks than conventional chips. MPPAs are based on a software parallel programming model for developing high-performance embedded system applications.|$|E
5000|$|A <b>massively</b> <b>parallel</b> <b>processor</b> (MPP) is {{a single}} {{computer}} with many networked processors. MPPs have {{many of the same}} characteristics as clusters, but MPPs have specialized interconnect networks (whereas clusters use commodity hardware for networking). MPPs also tend to be larger than clusters, typically having [...] "far more" [...] than 100 processors. In an MPP, [...] "each CPU contains its own memory and copy of the operating system and application. Each subsystem communicates with the others via a high-speed interconnect." ...|$|E
50|$|A <b>massively</b> <b>parallel</b> <b>{{processor}}</b> array, {{also known}} as a multi purpose processor array (MPPA) is a type of integrated circuit which has a massively parallel array of hundreds or thousands of CPUs and RAM memories. These processors pass work to one another through a reconfigurable interconnect of channels. By harnessing a large number of processors working in parallel, an MPPA chip can accomplish more demanding tasks than conventional chips. MPPAs are based on a software parallel programming model for developing high-performance embedded system applications.|$|E
40|$|This paper {{presents}} rendering algorithms, {{developed for}} <b>massively</b> <b>parallel</b> <b>processors</b> (MPPs), for polygonal, spheres, and volumetric data. The polygon algorithm uses a data parallel approach whereas the sphere and volume renderer use a MIMD approach. Implementations for these algorithms are presented for the Thinking Machines Corporation CM- 5 MPP. 1 Introduction In recent years, <b>massively</b> <b>parallel</b> <b>processors</b> (MPPs) {{have proven to}} be a valuable tool for performing scientific computation. Available memory on this type of computer is far greater than that which is found on traditional vector supercomputers. For example, a 1024 node CM- 5 contains 32 gigabytes of physical memory. As a result, scientists who utilize these MPPs can execute their three dimensional simulation models with much greater detail than previously possible. Molecular dynamics simulations can consist of over 100 million atoms [8] and CFD simulations can contain over 23 million cells with numerous variables [9]. Wh [...] ...|$|R
40|$|Representation of Parallel Program Performance Oscar Na'im, Tony Hey, and Ed Zaluska Abstract Performance is a {{critical}} issue in current <b>massively</b> <b>parallel</b> <b>processors.</b> However, delivery of adequate performance is not automatic and performance evaluation tools are {{required in order to}} help the programmer to understand the behaviour of a parallel program. In recent years, a wide variety of tools have been developed for this purpose including tools for monitoring and evaluating performance and visualization tools. However, these tools do not provide an abstract representation of performance. <b>Massively</b> <b>parallel</b> <b>processors</b> can generate a huge amount of performance data and sophisticated methods for representing and displaying this data (e. g. visual and aural) are required. Performance views are not scalable in general and do not represent an abstraction of the performance data. The Do-Loop-Surface display is proposed as an abstract representation of the performance of a partic [...] ...|$|R
40|$|A {{use case}} model is an {{effective}} way of specifying how Reliability, Availability, and Serviceability (RAS) features would be employed in an operational <b>Massively</b> <b>Parallel</b> <b>Processors</b> (MPP) system. As part of a research project on RAS for MPPs, one such model was developed. A brief introduction to the use case technique {{is followed by a}} discussion of the developed model...|$|R
40|$|JUMP- 1 is {{currently}} under development by seven Japanese universities to establish techniques of an efficient distributed shared memory on a <b>massively</b> <b>parallel</b> <b>processor.</b> It provides a memory coherency control scheme called the hierarchical bit-map directory to achieve cost effective and high performance {{management of the}} cache memory. Messages for maintaining cache coherency are transferred through a fat tree on the RDT(Recursive Diagonal Torus) interconnection network. In this report, we discuss on the scheme and examine its performance. The configuration of the RDT router chip is also discussed. 1 Introduction JUMP- 1 is a <b>massively</b> <b>parallel</b> <b>processor</b> prototype developed by collaboration between 7 Japanese universities[4]. The major goal of this project is to establish techniques for building an efficient distributed shared memory on a <b>massively</b> <b>parallel</b> <b>processor.</b> For this purpose, a sophisticated methodology called Strategic Memory System (SMS) is proposed [11][4]. The cache direct [...] ...|$|E
40|$|Generating {{graphics}} to faithfully represent {{information can}} be a computationally intensive task. A way of using the <b>Massively</b> <b>Parallel</b> <b>Processor</b> to generate images by ray tracing is presented. This technique uses sort computation, a method of performing generalized routing interspersed with computation on a single-instruction-multiple-data (SIMD) computer...|$|E
40|$|An {{iterative}} solver for {{use with}} finite element codes was developed for the Cray T 3 D <b>massively</b> <b>parallel</b> <b>processor</b> at the Jet Propulsion Laboratory. Finite element modeling is useful for simulating scattered or radiated electromagnetic fields from complex three-dimensional objects with geometry variations smaller than an electrical wavelength...|$|E
40|$|Abstract — 3 -D {{integration}} of conventional <b>massively</b> <b>parallel</b> <b>processors</b> is challenging {{due to high}} temperatures and hotspots. An Associative Processor (AP) is a viable candidate for such applications as it exhibits close to uniform thermal distribution with lower temperatures and fewer hot spots. Performance and thermal analysis supported by simulation confirm that associative processing enables 3 -D {{integration of}} multilayer processing and memory cubes...|$|R
40|$|In {{this paper}} we {{describe}} a cellular automaton (CA) used {{to perform the}} watershed transform in N-D images. Our method is based on image integration via the Ford-Bellman shortest paths algorithm. Due to the local nature of CA algorithms we {{show that they are}} designed to run on <b>massively</b> <b>parallel</b> <b>processors</b> and therefore, be efficiently implemented on low cost consumer graphical processing units (GPUs). 1...|$|R
40|$|The Parallel Mesh Generation (PMESH) Project {{is a joint}} LDRD {{effort by}} A Division and Engineering to develop a unique mesh {{generation}} system that can construct large calculational meshes (of up to 10 {sup 9 } elements) on <b>massively</b> <b>parallel</b> computers. Such a capability will remove a critical roadblock to unleashing the power of <b>massively</b> <b>parallel</b> <b>processors</b> (MPPs) for physical analysis. PMESH will support a variety of LLNL 3 -D physics codes {{in the areas of}} electromagnetics, structural mechanics, thermal analysis, and hydrodynamics...|$|R
