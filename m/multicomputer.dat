839|454|Public
5000|$|Percolation routing in a {{three-dimensional}} <b>multicomputer</b> network topology using optical interconnection ...|$|E
5000|$|Design and {{analysis}} of a 3-dimensional cluster <b>multicomputer</b> architecture using optical interconnection for petaFLOP computing ...|$|E
5000|$|Lynx is a {{programming}} language for large distributed networks, using remote procedure calls. It {{was developed by the}} University of Wisconsin-Madison in 1984 for the Charlotte <b>multicomputer</b> operating system.|$|E
40|$|Dynamic load {{balancing}} in <b>multicomputers</b> {{can improve the}} utilization of processors and the efficiency of parallel computations through migrating workload across processors at runtime. We present a survey and critique of dynamic {{load balancing}} strategies that are iterative: workload migration is carried out through transferring processes across nearest neighbor processors. Iterative strategies have become prominent in recent years because of the increasing popularity of point-to-point interconnection networks for <b>multicomputers.</b> Key words: dynamic load balancing, <b>multicomputers,</b> optimization, queueing theory, scheduling. INTRODUCTION <b>Multicomputers</b> are highly concurrent systems that are composed of many autonomous processors connected by a communication network 1; 2. To improve the utilization of the processors, parallel computations in <b>multicomputers</b> require that processes be distributed to processors {{in such a way}} that the computational load is evenly spread among the processors [...] ...|$|R
40|$|Efficient routing of {{messages}} {{is the key}} to the performance of <b>multicomputers.</b> Multicast communication refers to the delivery of the same message from a source node to an arbitrary number of destination nodes. Wormhole routing is the most promising switching technique used in new generation <b>multicomputers.</b> In this paper, we present multicast wormhole routing methods for <b>multicomputers</b> adopting 2 D-mesh and hypercube topologies. The dual-path routing algorithm requires less system resource, while the multi-path routing algorithm creates less traffic. More importantly, both routing algorithms are deadlock-free, which is essential to wormhole networks. Keywords: <b>Multicomputers,</b> Heuristic Algorithms, Hypercube Topology, 2 D Mesh Topology, Multicast Communication, Wormhole Routing, NP-completeness, Grid Graphs. This work was supported in part by the NSF grants ECS- 8814027 and MIP- 8811815 ii 1 Introduction The performance of <b>multicomputers</b> is highly dependent on the underlying communicat [...] ...|$|R
40|$|In {{this paper}} we discuss the control flow of {{rendering}} algorithms in general purpose <b>multicomputers,</b> which are connected to specialised rasterizer hardware. In the first section, we present the MANNA / VISA system. In the next section we have a general look at the rendering process on <b>multicomputers,</b> and finally we construct a classification scheme and evaluate it on the MANNA / VISA system...|$|R
50|$|In Flynn's taxonomy, multiprocessors {{as defined}} above are MIMD machines. As they are {{normally}} construed to be tightly coupled (share memory), multiprocessors are not the entire class of MIMD machines, which also contains message passing <b>multicomputer</b> systems.|$|E
50|$|A similar {{application}} {{is found in}} the time scheduling of the run time of the processors.E.g. scheduling file transfers in a distributed network or scheduling diagnostic tests in a <b>multicomputer</b> system as well as scheduling tasks in an open shop system.Various algorithms are being developed for this purpose.|$|E
50|$|While {{designing}} a <b>multicomputer</b> operating system for Danish company GN Elmi, Brinch Hansen concluded {{he needed a}} new language, this time leveraging the message passing paradigm of Hoare’s CSP. The resulting language, Joyce, removed a major limitation of CSP by introducing parallel recursion. Brinch Hansen developed a portable implementation on an IBM PC.|$|E
5000|$|Model {{programs}} for computational science: A programming methodology for <b>multicomputers,</b> Concurrency—Practice and Experience 5, 5 (August 1993), 407-423 ...|$|R
40|$|In this paper, {{we present}} an {{algorithm}} for the reduction to block upper-Hessenberg form {{which can be}} used to solve the nonsymmetric eigenvalue problem on message-passing <b>multicomputers.</b> On such <b>multicomputers,</b> a nonsymmetric matrix can be distributed across processing nodes con gured into a network of two-dimensional mesh processor array using a block-scattered decomposition. Based on the matrix partitioning and mapping, the algorithm employs both Householder re ectors and Givens rotations within each reduction step. We analyze the arithmetic and communication complexities and describe the implementation details of the algorithm on message-passing <b>multicomputers.</b> We discuss two di erent implementations|synchronous and asynchronous|and present performance results on the Intel iPSC/ 860 and DELTA. We conclude with an evaluation of the algorithm's communication cost, and suggest areas for further improvement. ...|$|R
5000|$|The Posie project: {{studies to}} support the design of {{operating}} systems for <b>multicomputers,</b> Computer Systems Group, University of Edinburgh 1995 ...|$|R
5000|$|LAM (Local Area <b>Multicomputer)</b> is an MPI {{programming}} {{environment and development}} system for heterogeneous computers on a network. With LAM/MPI, a dedicated computer cluster or an existing network computing infrastructure {{can act as a}} single parallel computing resource. LAM/MPI is considered to be [...] "cluster friendly", in that it offers daemon-based process startup/control as well as fast client-to-client message passing protocols. LAM/MPI can use TCP/IP, shared memory, Myrinet (GM), or Infiniband (mVAPI) for message passing.|$|E
50|$|Born in Edinburgh, Scotland in 1969, Tweedie studied {{computer}} science at Churchill College, Cambridge and the University of Edinburgh, {{where he did}} his thesis on Contention and Achieved Performance in <b>Multicomputer</b> Wormhole Routing Networks. After contributing to the Linux kernel {{in his spare time}} since the early nineties and working on VMS filesystem support for DEC for two years, Tweedie was employed by Linux distributor Red Hat where he continues to work on the Linux kernel.|$|E
50|$|Mercury Computer Systems {{used the}} i860 in their <b>multicomputer.</b> From 2 to 360 compute nodes would reside in a circuit {{switched}} fat tree network, with each node having local memory {{that could be}} mapped by any other node. Each node in this heterogeneous system could be an i860, a PowerPC, {{or a group of}} three SHARC DSPs. Good performance was obtained from the i860 by supplying customers with a library of signal processing functions written in assembly language. The hardware packed up to 360 compute nodes in 9U of rack space, making it suitable for mobile applications such as airborne radar processing.|$|E
40|$|Dynamic load {{balancing}} in <b>multicomputers</b> {{can improve the}} utilization of processors and the efficiency of parallel computations through migrating the workload across processors at runtime. We present a survey and critique of dynamic {{load balancing}} strategies that are iterative: that is, workload migration is carried out through transferring processes across nearest neighbour processors. Iterative strategies have become prominent in recent years because of the increasing popularity of point-to-point interconnection networks for <b>multicomputers.</b> link_to_subscribed_fulltex...|$|R
40|$|Novel {{software}} technologies for implementing concurrent object-oriented languages on {{different types of}} <b>multicomputers</b> (including stock <b>multicomputers)</b> are presented. Performance numbers suggest that concurrent object-oriented programming on currently available <b>multicomputers</b> is highly viable and promising in performance, thus allowing us exploit the computing power and modeling power provided in the concurrent object-oriented paradigm. 1 Introduction The trend toward object-oriented (OO) software construction {{is becoming more and}} more prevalent. Important software concepts such as encapsulation promote a high degree of code re-use and clean architectural structuring of large software. High-performance parallel programming, previously performed in the context of more conventional programming languages, would also be able to enjoy the benefit from the OO technology with appropriate OO languages and systems. Although many OO languages currently in use today (such as C++[15] and Smallt [...] ...|$|R
40|$|Functional or Control {{parallelism}} is {{an effective}} way to increase speedups in <b>Multicomputers.</b> Programs for these machines are represented by Macro Dataflow Graphs (MDGs) for the purpose of functional parallelism analysis and exploitation. Algorithms for allocation and scheduling of MDGs have been discussed along with some analysis of their optimality. These algorithms attempt to minimize the execution time of any given MDG through exploitation of functional parallelism. Our preliminary results show their effectiveness over naive algorithms. Keywords : Macro Dataflow Graphs, Distributed Memory <b>Multicomputers,</b> Allocation and Scheduling, Parallelizing Compilers, Optimization. 1 Introduction Distributed Memory <b>Multicomputers</b> offer significant advantages over shared memory multiprocessors in terms of cost and scalability. Unfortunately, writing efficient software for them is an extremely laborious process for users. The PARADIGM compiler project at Illinois is aimed at devising a paral [...] ...|$|R
50|$|MOSIX {{has been}} {{researched}} and developed since 1977 at The Hebrew University of Jerusalem by the research team of Prof. Amnon Barak. So far, ten major versions have been developed. The first version, called MOS, for <b>Multicomputer</b> OS, (1981-83) was based on Bell Lab's Seventh Edition Unix and ran on a cluster of PDP-11 computers. Later versions were based on Unix System V Release 2 (1987-89) and ran on a cluster of VAX and NS32332-based computers, followed by a BSD/OS-derived version (1991-93) for a cluster of 486/Pentium computers. Since 1999 MOSIX is tuned to Linux for x86 platforms.|$|E
50|$|Activity at CERN in the {{meantime}} focussed {{on the construction of}} the Super Proton Synchrotron (SPS), and in 1972 Beck was invited back to Europe to design and build the SPS control room and its hardware and software in the environment of a revolutionary <b>multicomputer</b> control system being constructed by a very creative group under the late Michael Crowley-Milling. In 1973 he published a CERN document, along with his colleague Bent Stumpe, outlining the concept for a prototype touchscreen as well as a multi-function computer-configurable knob, both of which found their way onto the consoles of the finished control room. The CERN touchscreen was arguably the first practical device of its kind and used a matrix of transparent capacitative pads above a cathode-ray tube.|$|E
50|$|A distributed-memory system, {{often called}} a <b>multicomputer,</b> {{consists}} of multiple independent processing nodes with local memory modules which is {{connected by a}} general interconnection network. Software DSM systems can be implemented in an operating system, or as a programming library and {{can be thought of}} as extensions of the underlying virtual memory architecture. When implemented in the operating system, such systems are transparent to the developer; which means that the underlying distributed memory is completely hidden from the users. In contrast, software DSM systems implemented at the library or language level are not transparent and developers usually have to program them differently. However, these systems offer a more portable approach to DSM system implementations. A distributed shared memory system implements the shared-memory model on a physically distributed memory system.|$|E
40|$|The PARADIGM {{compiler}} project {{provides an}} automated means to parallelize programs, {{written in a}} serial programming model, for efficient execution on distributed-memory <b>multicomputers.</b> In addition to performing traditional compiler optimizations, PARADIGM is unique in that it addresses many other issues within a unified platform: automatic data distribution, synthesis of high-level communication, communication optimizations, irregular computations, functional and data parallelism, and multithreaded execution. This paper describes the techniques used and provides experimental evidence of their effectiveness. 1 Introduction Distributed-memory massively parallel <b>multicomputers</b> can provide {{the high levels of}} performance required to solve the Grand Challenge computational science problems [16]. Distributed-memory <b>multicomputers</b> such as the Intel iPSC/ 860, the Intel Paragon, the IBM SP- 1 and the Thinking Machines CM- 5 offer significant advantages over shared-memory multiprocessors in terms [...] ...|$|R
40|$|Recent multiprocessors such as Cray T 3 D support interprocessor {{communication}} using partitioned dimension-order routers (PDRs). In a PDR implementation, the routing logic and switching hardware is partitioned into multiple modules, with each module suitable for implementation as a chip. This paper proposes {{a method to}} incorporate adaptivity into such routers with simple changes to the router structure and logic. We show that with as few as two virtual channels per physical channel, adaptivity can be provided to handle nonuniform traffic in multidimensional meshes. Keywords: adaptive routing, mesh networks, <b>multicomputers,</b> multimodule routers, wormhole routing. 1 Introduction Many recent experimental and commercial <b>multicomputers</b> and multiprocessors [6, 14, 18] use grid topology based networks such as meshes and tori. Majority of these <b>multicomputers</b> use the dimension-order or e-cube routing with wormhole (WH) switching [8]. Wormhole {{is a form of}} cutthrough routing in which blocked [...] ...|$|R
40|$|Despite the {{performance}} potential of <b>multicomputers,</b> several factors have limited their widespread adoption. Of these, performance variability {{is among the}} most significant. Execution of some programs may yield {{only a small fraction of}} peak system performance, whereas others approach the system's theoretical performance peak. Moreover, the observed performance may change substantially as application program parameters vary. Data parallel languages, which facilitate the programming of <b>multicomputers,</b> increase the semantic distance between the program's source code and its observable performance, thus aggravating {{the performance}} problem. In this thesis, we propose a new methodology to predict the performance scalability of data parallel applications on <b>multicomputers.</b> Our technique represents the execution time of a program as a symbolic expression that is a function of the number of processors (P), problem size (N), and other system-dependent parameters. This methodology is based on [...] ...|$|R
5000|$|Working {{with his}} student Rangachari Anand, Joyce {{was moved to}} an Encore Multimax 320 {{multiprocessor}} at SU's Northeast Parallel Architectures Center. Recognizing the scaling limitations of multiprocessors, however, Brinch Hansen sought a suitable <b>multicomputer</b> for further work. Acquiring a Meiko Computing Surface in 1989, he began experimenting with scientific applications by developing parallel programs for Householder reduction and then n-body simulation as learning exercises, {{and was surprised to}} find that both programs had nearly identical control structures. Concluding that both fit an “all-pairs paradigm,” he then focused on exploring reusable parallel algorithm structures he termed [...] "programming paradigms" [...] or [...] "generic programs" [...] (later, popularly known as [...] "design patterns"). In 1995, Brinch Hansen’s fifth book, Studies in Computational Science: Parallel Programming Paradigms was published, with programs rewritten in SuperPascal, a fully implemented publication language he created for parallel algorithms.|$|E
50|$|Based on the Finite Element Machine's {{success in}} demonstrating Parallel Computing viability, (alongside ILLIAC IV and Goodyear MPP), {{commercial}} parallel computers soon were sold. NASA Langley subsequently purchased a Flex/32 <b>Multicomputer</b> (and later Intel iPSC and Intel Paragon) to continue parallel finite element algorithm R&D. In 1989, the parallel equation solver code, first prototyped on FEM, and tested on FLEX was ported to NASA's first Cray YMP via Force (Fortran for Concurrent Execution) {{to reduce the}} structural analysis computation time for the space shuttle Challenger Solid Rocket Booster resdesign with 54,870 equations from 14 hours to 6 seconds. This research accomplishment was awarded the first Cray GigaFLOP Performance Award at Supercomputing '89. This code evolved into NASA's General-Purpose Solver (GPS) for Matrix Equations used in numerous finite element codes to speed solution time. GPS sped up AlphaStar Corporation's Genoa code 10X, allowing 10X larger applications for which the team received NASA's 1999 Software of the Year Award and a 2000 R&D100 Award.|$|E
40|$|A <b>multicomputer</b> {{is defined}} as a set of tightly-coupled yet {{autonomous}} computers capable of synchronizing and communicating in parallel but also of operating independently. The architectural concepts and requirements for executing the Ada programs in a <b>multicomputer</b> system are discussed. Synchronization, commmunication, and protection of shared data between the Ada program entities are addressed. Decomposition or partitioning of the Ada program in a <b>multicomputer</b> system is also studied. Finally, a <b>multicomputer</b> and real time Ada environment is described using FLEX/ 32 <b>multicomputer</b> system...|$|E
40|$|A {{minimization}} of learning-algorithm {{completion time}} is sought {{in the present}} optimal-mapping study of the learning process in multilayer feed-forward artificial neural networks (ANNs) for message-passing <b>multicomputers.</b> A novel approximation algorithm for mappings of this kind is derived from observations of the dominance of a parallel ANN algorithm over its communication time. Attention is given to both static and dynamic mapping schemes for systems with static and dynamic background workloads, {{as well as to}} experimental results obtained for simulated mappings on <b>multicomputers</b> with dynamic background workloads...|$|R
40|$|Many {{parallel}} algorithms use hypercubes as {{the communication}} topology among processes. When such algorithms are executed on hypercube <b>multicomputers</b> the communication cost is kept minimum since processes can be allocated to processors {{in such a}} way that only communication between neighbor processors is required. However, the scalability of hypercube <b>multicomputers</b> is constrained by the fact that the interconnection cost per node increases with the total number of nodes. From the point of view of scalability, meshes and toruses are a more interesting class of interconnection topologies. This paper focuses on the execution of algorithms with hypercube communication topology on <b>multicomputers</b> with mesh or torus interconnection topologies. The proposed approach is based on looking at different embeddings of hypercube graphs onto mesh or torus graphs. The paper concentrates on toruses since an already known embedding, called standard embedding is optimal for meshes. In this paper we propose [...] ...|$|R
40|$|The {{pursuit of}} high {{connectivity}} in communication network design for <b>multicomputers</b> is often complicated by wiring constraints. The Mesh of Clos topology, which combines a multistage network with a mesh network, was proposed {{to address this}} trade-off between efficiency and realizability. In this paper, a simulation study is presented in order to evaluate wormhole routed Mesh of Clos communication networks. It is shown {{that this type of}} network can substantially reduce contention in comparison with more flat mesh networks. Furthermore, we found that increasing the number of flitbuffers on router devices does not necessarily lead to improved communication performance. For some application loads it may even result in a loss of performance. 1 Introduction Distributed memory MIMD <b>multicomputers</b> {{play an important role in}} the ever continuing pursuit of improving computational power. Usually these <b>multicomputers</b> are constructed by a network of nodes, where each node consists of a processor, l [...] ...|$|R
40|$|Efficient interprocessor {{communication}} {{is a key}} parameter to achieve high performance in distributed memory <b>multicomputer</b> networks. Thus. modelling and analysing message communication latency is critical for optimizing the performance of {{interprocessor communication}}s. To demonstrate how to achieve efficient (low latency) interprocessor communication. we have developed generalized stochastic Petri net (GSPN) routing models for congestion-prone communication patterns occurring in <b>multicomputer</b> networks. Under congestion-prone adjacent and non-adjacent node communication patterns, we use our developed GSPN routing models to {{study the effects of}} congestion (arising due to problems such as buffer overflow and traffic contention) on the message communication latency of <b>multicomputer</b> networks. This modelling has been carried out for mesh <b>multicomputer</b> networks employing the packet switching technique...|$|E
40|$|In {{order to}} {{efficiently}} share a <b>multicomputer</b> among multiple users, a job scheduler {{is used to}} allow control and monitoring of the programs executed on the machine. In this work, a job scheduler is designed and implemented for scheduling parallel jobs on a <b>multicomputer.</b> The scheduler {{can be adapted to}} support different multicomputers and scheduling algorithms. An implementation is provided for a virtual <b>multicomputer</b> on which parallel programs can be run, allowing experimentation with scheduling algorithms and aiding in providing simulation of a <b>multicomputer</b> environment for debugging parallel applications prior to running them on a production machine. i iiPreface This report is my Master’s thesis at the Parallel and Distributed Systems Group of th...|$|E
40|$|A {{physical}} <b>multicomputer</b> is {{a collection}} of computers of various architectures interconnected by some means. A virtual <b>multicomputer</b> is to a physical one as virtual memory is to physical memory, that is, there are as many instances of the required architectural resources as the problem demands. In this abstract we outline the requirements and design of a virtual machine architecture for distributed processing (the virtual <b>multicomputer)</b> supporting an architecture neutral representation of program and data and report on the status of the project...|$|E
40|$|Abstract /??<£<?//<? O 3 9 <b>Multicomputers</b> {{consisting}} of off-the-shelf computers connected by commercial high-speed networks form an economically attractive computing platform {{for a large}} class of applications. However, while high-speed networks are fairly widely available (e. g. HIPPI and ATM), many computer systems have problems delivering this high bandwidth to the applications, thus limiting the class of applications that can be supported by <b>multicomputers.</b> The Gigabit Nectar project developed a network interface architecture that supports efficient high-bandwidth end-end communication. This architecture has been implemented for workstations (DEC Alpha) and distributed-memory systems (iWarp) and has been deployed in the Gigabit Nectar testbed...|$|R
40|$|Abstract In this paper, we {{investigate}} a virtual memory man- agement technique for <b>multicomputers</b> called memory servers. The memory server model extends the mem- ory hierarchy of <b>multicomputers</b> by introducing a re- mote memory server layer. Memory servers are mul- ticomputer nodes whose memory {{is used for}} fast back- ing storage and logically lie between the local physical memory and disks. The paper presents the model, de- scribes how the model supports sequential programs, message-passing programs and shared virtual memory systems, discusses several design issues, and shows preliminary results of a prototype implementation on an Intel iPSC/ 860...|$|R
40|$|If {{the loop}} {{iterations}} of a loop nest cannot be partitioned into independent sets, the data communication for data dependences are inevitable {{in order to}} execute them on parallel machines. This kind of loop nests {{are referred to as}} Doacross loop nests. This paper is concerned with compiler algorithms for parallelizing Doacross loop nests for distributed-memory <b>multicomputers.</b> We present a method that combines loop tiling, chain-based scheduling and indirect message passing to generate e cient message-passing parallel codes. We present our experiment results on Fujitsu AP 1000 which show that low communication overhead and high speedup for Doacross loop nests on <b>multicomputers</b> can be achieved by tuning these techniques...|$|R
