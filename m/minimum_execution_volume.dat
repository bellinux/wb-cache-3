0|162|Public
40|$|Abstract. Sophisticated {{parallel}} matrix multiplication algorithms like PDGEMM {{exhibit a}} complex structure {{and can be}} controlled by a large set of parameters including blocking factors and block sizes used for the serial execution {{on one of the}} participating processors. But it requires a deep understanding of both the parallel algorithm and the execution platform to select the parameters such that a <b>minimum</b> <b>execution</b> time results. In this article, we describe a simple mechanism that automatically selects a suitable set of parameters for PDGEMM which leads to a <b>minimum</b> <b>execution</b> time in most cases. ...|$|R
40|$|Cloud {{computing}} {{is a new}} archetype {{that provides}} dynamic computing services to cloud users through the support of datacenters that employs the services of datacenter brokers which discover resources and assign them Virtually. The focus {{of this research is}} to efficiently optimize resource allocation in the cloud by exploiting the Max-Min scheduling algorithm and enhancing it to increase efficiency in terms of completion time (makespan). This is key to enhancing the performance of cloud scheduling and narrowing the performance gap between cloud service providers and cloud resources consumers/users. The current Max-Min algorithm selects tasks with maximum execution time on a faster available machine or resource that is capable of giving minimum completion time. The concern of this algorithm is to give priority to tasks with maximum execution time first before assigning those with the <b>minimum</b> <b>execution</b> time for the purpose of minimizing makespan. The drawback of this algorithm is that, the execution of tasks with maximum execution time first may increase the makespan, and leads to a delay in executing tasks with <b>minimum</b> <b>execution</b> time if the number of tasks with maximum execution time exceeds that of tasks with <b>minimum</b> <b>execution</b> time, hence the need to improve it to mitigate the delay in executing tasks with <b>minimum</b> <b>execution</b> time. CloudSim is used to compare the effectiveness of the improved Max-Min algorithm with the traditional one. The experimented results show that the improved algorithm is efficient and can produce better makespan than Max-Min and DataAware. Comment: 6 pages, 6 figures, Article publishe...|$|R
40|$|Microcode {{compaction}} is {{an essential}} tool for the compilation of high-level language microprograms into microinstructions with parallel microoperations. Although guaranteeing <b>minimum</b> <b>execution</b> time is an exponentially complex problem, recent research indicates {{that it is not}} difficult to obtain practical results. This paper, whic...|$|R
30|$|The fitness {{function}} allows {{the evaluation of}} the task scheduling performance according to specific objectives. The main goal here is to identify task assignments that guarantee maximum processors utilization, to balance the traffic load across processors and to guarantee <b>minimum</b> <b>execution</b> time of tasks.|$|R
5000|$|Opportunistic Load Balancing (OLB) is the {{algorithm}} that assigns workloads to nodes in free order. It is simple {{but does not}} consider the expected execution time of each node. Load balance Min-Min (LBMM) assigns sub-tasks to the node which requires <b>minimum</b> <b>execution</b> time. The pseudo-code is following: ...|$|R
30|$|In [11], authors propose task {{scheduling}} algorithm to achieve <b>minimum</b> <b>execution</b> time, maximum processor utilization and optimal load balancing across different processors by defining tree objective functions. In this work, we have demonstrated how {{two of these}} objective functions did not guarantee <b>minimum</b> <b>execution</b> time and maximum processor utilization and this independently of the virtualized application to which the scheduled tasks belong. We have proposed new objective functions that maximize resource utilization while minimizing task execution time. Several {{task scheduling}} methods based on modified genetic algorithm have been proposed [12]-[14]. In [12],[13], authors propose to modify GA to control the task duplication and reduce {{the length of the}} processor queues. In [14], a modified genetic algorithm is proposed to handle task scheduling in parallel multiprocessor systems. Unfortunately, these modified algorithms yield to task scheduling time greater than that obtained with non-modified GA.|$|R
40|$|Abstract. This paper {{addresses}} {{the problem of}} calculating optimum buffer size for a dynamic voltage scaling processor. We determine the minimum required buffer size giving minimum energy solution for periodic (single, multiple) or aperiodic tasks. The calculations are based on information about data size (maximum, <b>minimum),</b> <b>execution</b> time (best case, worst case), and deadlines. ...|$|R
40|$|This paper {{shows how}} to {{software}} pipeline a loop for minimal register pressure without sacrificing the loop's <b>minimum</b> <b>execution</b> time. This novel bidirectional slack-scheduling method has been implemented in a FORTRAN compiler and tested on many scientific benchmarks. The empirical results [...] -when measured against an absolute lower bound on execution time, and against a novel schedule-independent absolute lower bound on register pressure [...] -indicate nearoptimal performance...|$|R
40|$|Computational grids present many {{obstacles}} to their effective exploitation by non-trivial applications. We present a grid middleware, implemented using Java and Jini, that eliminates these obstacles through the intelligent use of meta-data {{relating to the}} structure, behaviour and performance of an application. We demonstrate how different problem sizes and selection criteria (<b>minimum</b> <b>execution</b> time or <b>minimum</b> cost) utilise different implementations for the optimal solution {{of a set of}} linear equations...|$|R
40|$|In {{practical}} applications we are frequently required {{to find a}} supervisor that can achieve certain optimal performance. Some performance such as maximum throughput or <b>minimum</b> <b>execution</b> time/cost can be specified in terms of weights. In this paper we first define a minimum-weight supervisory control problem on weighted discrete-event systems. Then we show that, the supremal minimum-weight controllable and normal sublanguages exist, and can be computed by a terminable algorithm...|$|R
30|$|In [8], genetic-based {{algorithm}} {{has been}} proposed where a dedicated processor {{has been used to}} schedule tasks across processors. This paper has shown that this algorithm outperforms a genetic algorithm based on first-in first-out scheduling approach. However, these performances depend on the number and the distribution of tasks being executed. Moreover, it uses the same objective function as defined in [11]. We believe that this objective function that allows minimization of the largest task completion time does not guarantee the <b>minimum</b> <b>execution</b> time.|$|R
3000|$|..., i.e., C_idef=∑ _k= 1 ^n_i∑ _q= 1 ^v_k e^q_s_i^k. Every sub-task {{is assumed}} to execute on at most one core at any time instant and can be {{interrupted}} prior to its completion by another sub-task with a higher priority. A preempted sub-task {{is assumed to}} resume its execution on the same core as the one on which it was executing prior to preemption. We assume that each preemption is performed at no cost or penalty. The <b>minimum</b> <b>execution</b> requirement of task τ [...]...|$|R
40|$|Motion Planning for mobile robots is {{concerned}} with providing a feasible and efficient path to accomplish a given task. Although many solutions may exist, a condition for obtaining the best (or near best) option may be imposed by the user, where a criterion {{in terms of the}} total distance traversed, energy expended or <b>minimum</b> <b>execution</b> time must be achieved. The planning procedure is made more complicated if the robot has to detect and avoid static or dynamic objects in the workcell...|$|R
40|$|In grid environment, the {{resource}} management system schedules the jobs to specific resources {{with trying to}} minimize some objective functions. This paper considers the hierarchical structure of grid with multiple level resource schedule model which divides the tasks into group according to <b>minimum</b> <b>execution</b> time assigns and these groups to {{the resource}}s. This grouping based algorithm is compared with non- grouped jobs and obtained better results in terms of completion time, expected performance and expected execution time than the non- grouped jobs...|$|R
40|$|We {{consider}} an asynchronous system with transitions {{corresponding to the}} instructions of a computer system. For each instruction, a runtime is given. We propose a mathematical model, allowing us to construct an algorithm for finding the minimum time of the parallel process with a given trace. We consider a problem of constructing a parallel process which transforms the initial state to given and has the <b>minimum</b> <b>execution</b> time. We show that it is reduced {{to the problem of}} finding the shortest path in a directed graph with edge lengths equal to 1. Comment: 6 page...|$|R
40|$|Blumofe and Leiserson [6] {{gave the}} first provably good work-stealing work {{scheduler}} for mul-tithreaded computations with dependencies. Their scheduler executes a fully strict (i. e., well-structured) computation on P processors in expected time T 1 /P + O(T∞), where T 1 denotes the <b>minimum</b> serial <b>execution</b> {{time of the}} multithreaded computation, and T ∞ denotes the <b>minimum</b> <b>execution</b> time with {{an infinite number of}} processors. This thesis extends the existing literature in two directions. Firstly, we analyze the number of successful steals in multithreaded computations. The existing literature has dealt with the number of steal attempts without distinguishing between successful and unsuccessful steals. While that approach leads to a fruitful probabilistic analysis, it does not yield an interesting result for a worst-case analysis. We obtain tight upper bounds on the number of successful steals when the computation can be modeled by a computation tree. In particular, if the computation starts with a complete k-ary tree of height h, the maximum number of successful steals is ∑...|$|R
40|$|In {{this paper}} we study {{the problem of}} eciently {{scheduling}} a wide class of multithreaded computations, called strict; that is, computations in which all dependencies from a thread go to the thread's ancestors in the computation tree. Strict multithreaded computations allow the limited use of synchronization primitives. We present the rst fully distributed scheduling algorithm which applies to any strict multithreaded computation. The algorithm is asynchronous, on-line and follows the work-stealing paradigm. We prove that our algorithm is ecient {{not only in terms}} of its memory requirements and its execution time, but also in terms of its communication complexity. Our analysis applies to both shared and distributed memory machines. More specically, the expected execution time of our algorithm is O(T 1 =P +hT 1), where T 1 is the <b>minimum</b> serial <b>execution</b> time, T 1 is the <b>minimum</b> <b>execution</b> time with an innite number of processors, P is the number of processors and h is the maxi [...] ...|$|R
40|$|This paper {{studies the}} problem of {{efficiently}} scheduling fully strict (i. e., well-structured) multithreaded computations on parallel computers. A popular and practical method of scheduling this kind of dynamic MIMD-style computation is "work stealing," in which processors needing work steal computational threads from other processors. In this paper, we give the first provably good work-stealing scheduler for multithreaded computations with dependencies. Specifically, our analysis shows that the expected time TP to execute a fully strict computation on P processors using our work-stealing scheduler is TP = O(T 1 =P + T 1), where T 1 is the <b>minimum</b> serial <b>execution</b> time of the multithreaded computation and T 1 is the <b>minimum</b> <b>execution</b> time with {{an infinite number of}} processors. Moreover, the space SP required by the execution satisfies SP S 1 P. We also show that the expected total communication of the algorithm is at most O(T 1 SmaxP), where Smax is the size of the largest activation [...] ...|$|R
40|$|Abstract: Clusters of {{commodity}} servers are increasingly the platform {{of choice for}} running computationally and IO intensive jobs {{in a variety of}} industries. It is expected that using clusters will reduce the average job response time. But improper submission of jobs to clusters may lead to two problems, first it leads to blocking of jobs (waiting for results from other jobs) second it leads to disturbing other jobs (i. e. other jobs may be blocked due to submission). Effective utilization of the resources in clusters can help to balance the load and avoid situations like slow run of systems. This paper addresses the principle of effective utilization of cluster resources by Machine Learning based profile driven scheduling. It avoids the above problems by allocating jobs to resources of cluster based on the SVM prediction profiling results. Some of the machines in the cluster run the IO bound jobs effectively with minimum waiting time and with the <b>minimum</b> <b>execution</b> time, while in some other machines run the CPU bound jobs effectively with minimum waiting time and with the <b>minimum</b> <b>execution</b> time. The system statistics like CPU utilization time, Memory space utilized, User and System time utilization are used as the parameters for Profiling. Job dependency analysis is used to prevent dependent jobs to keep blocking and disturbing other jobs. This paper uses the Resource profiling results based on machine learning prediction and Offline Job profiling to perform job allocation onto the resources of cluster...|$|R
40|$|We study {{an optimal}} {{execution}} problem with uncertain market impact to derive {{a more realistic}} market model. We construct a discrete-time model as a value function for optimal execution. Market impact is formulated {{as the product of}} a deterministic part increasing with <b>execution</b> <b>volume</b> and a positive stochastic noise part. Then, we derive a continuous-time model as a limit of a discrete-time value function. We find that the continuous-time value function is characterized by a stochastic control problem with a Levy process. Comment: 17 pages. Forthcoming in "Communications on Stochastic Analysis. ...|$|R
40|$|In {{this paper}} we {{describe}} Graph Traverse Scheduling as a loop partitioning method for shared memory multiprocessors. The partitioning method is considered {{in this paper}} for multiple nested loops including one or several recurrences. The aim of the method is to obtain a maximal partition while minimizing synchronization between blocks of the partition. GTS is an alignment-based technique that includes as many dependences {{as possible in the}} sequential execution of each block of the partition minimizing the number of them that require explicit synchronization. The method achieves <b>minimum</b> <b>execution</b> time of the parallel code generated assuming that a sufficient of processors is availabe and synchronization cost is negligible...|$|R
40|$|Immediate/on-line and Batch mode {{heuristics}} are {{two methods}} used for scheduling in the computational grid environment. In the former, task is mapped onto a resource {{as soon as}} it arrives at the scheduler, while the later, tasks are not mapped onto resource as they arrive, instead they are collected into a set that is examined for mapping at prescheduled times called mapping events. This paper reviews the literature concerning <b>Minimum</b> <b>Execution</b> Time (MET) along with Minimum Completion Time (MCT) algorithms of online mode heuristics and more emphasis on Min-Min along with Max-Min algorithms of batch mode heuristics, while focusing on the details of their basic concepts, approaches, techniques, and open problems...|$|R
40|$|The {{vast amount}} of {{high-frequency}} data heralds the use of new methods in financial data analysis and quantitative trading. This study delivers a proof-of-concept for a high frequency-based trading system based on an evolutionary computation method. Motivated by a theoretical liquidity asymmetry theorem from the market microstructure literature, grammatical evolution is used to exploit volume inefficiencies at the bidâ€“ask spread. Using NASDAQ Historical TotalView-ITCH level two limit order book data, <b>execution</b> <b>volumes</b> can be tracked. This allows for testing of the strategies with minimal assumptions. The system evolves profitable and robust strategies with high returns and low risk...|$|R
50|$|Amdahl's law {{is often}} used in {{parallel}} computing to predict the theoretical speedup when using multiple processors. For example, if a program needs 20 hours using a single processor core, and a particular {{part of the program}} which takes one hour to execute cannot be parallelized, while the remaining 19 hours (p = 0.95) of execution time can be parallelized, then regardless of how many processors are devoted to a parallelized execution of this program, the <b>minimum</b> <b>execution</b> time cannot be less than that critical one hour. Hence, the theoretical speedup is limited to at most 20 times (1/(1 − p) = 20). For this reason, parallel computing with many processors is useful only for highly parallelizable programs.|$|R
40|$|In {{performance}} evaluation or supervisory control, we often encounter problems {{of determining the}} maximum or <b>minimum</b> string <b>execution</b> time for a finite language when estimating the worst-case or best-case performance. It {{has been shown in}} the literature that the time complexity for computing the maximum string execution time for a finite language is polynomial with respect to the size of an automaton recognizer of that language and the dimension of the corresponding resource matrices. In this paper we provide a more efficient algorithm to compute such maximum string execution time. Then we show that it is NP-complete to determine the <b>minimum</b> string <b>execution</b> time. Keywords: Languages; Finite-state automata; (Max, +) semiring; Heap models; Computational complexit...|$|R
40|$|Cloud {{computing}} is {{a prominent}} {{way to support}} demand on services. It is a mode of computing where scalable resources are delivered as a service to customers over Internet. Scheduling in cloud is responsible for selection of best suitable resources for task execution, by taking some parameters and restrictions of tasks into consideration. From the users view, efficient scheduling may provide factors like fast service, <b>minimum</b> task <b>execution</b> cost etc. On the other hand Service providers should gain factors like to maximum profit, utilize their service efficiently and importantly regular customers. This paper proposes an efficient scheduling algorithm which addresses these major challenges of task scheduling in cloud. The incoming tasks/users can select their method {{on the basis of}} task requirement like <b>minimum</b> <b>execution</b> time or cost and then it is prioritized. So the algorithm is named as “TPD Scheduling Algorithm”, Here T stands for Task Selection, P Stands for Priority(in terms of cost) and D stands for Deadline. The proposed model is implemented and tested on simulation toolkit. Results validate the correctness of the framework and show a significant improvement over other scheduling methods...|$|R
40|$|Reconfigurable {{computing}} is {{a flexible}} way of facing {{with a single}} device {{a wide range of}} applications with a good level of performance. This area of computing involves different issues and concepts when compared with conventional computing systems. One of these concepts is context loading. The context refers to the coded configuration information to implement a particular circuit behavior. An important problem for reconfigurable computing is the scheduling of a group of kernels (sub-tasks) that constitute a complex application for <b>minimum</b> <b>execution</b> time. In this paper, we show how the different execution orders for these sub-tasks may result in varying levels of performance. We formulate an analytical approach and present a solution for this new problem through this work. 1...|$|R
30|$|General-purpose {{planners}} {{try to find}} {{plans with}} the minimum number of actions. Similarly, the Graphplan algorithm finds plans with <b>minimum</b> <b>execution</b> depth, i.e., the solution found should have the fewest layers possible. It {{is reasonable to assume}} that a faster plan is preferred in the general case (i.e., a plan with fewer levels). However, sometimes this leads to plans that do not make use of all information provided in the initial state. If we have services in the service repository that need no inputs, {{it is not uncommon for}} the planners to generate compositions that use none or just a few of the inputs provided. Although correct, these compositions may not be exactly what the developer intended, i.e., they may not contain the services the developer would expect to find given his/her specification.|$|R
40|$|Abstract — This paper {{describes}} {{the results of}} efficient measuring methods whereby the encryption capability of four algorithms are evaluated. Specifically this work focuses on measuring the encryption quality, the memory requirement and the execution time of the encryption as an indicator to the usage of the software and the hardware. Also, the security analysis of these schemes is investigated from cryptographic viewpoint; statistical and differential attacks. A number of requirements are therefore identified upon which the algorithms are evaluated. The results of the efficient measuring methods show that each algorithm has its own strengths and weaknesses and no single encryption mechanism is {{able to get the}} maximum security with <b>minimum</b> <b>execution</b> time. The paper proposes that {{it may be possible to}} develop new algorithms providing adequate means of efficiency with acceptable security...|$|R
40|$|Abstract-Array-based {{applications}} are normally computation-intensive and many customized designs {{have been proposed}} targeting FPGA (Field-Programmable Gate Array) implementations to accelerate their real-time solutions. Most often a time-consuming procedure to convert floating-point representations for a fixed-point implementation is necessary due to insufficient hardware resources. Recent remarkable advances in state-of-the-art FPGAs provide new opportunities. This paper presents a dynamic scheduling strategy that applies novel application characterization and adaptive allocation of processors among the active tasks; we show results for our in-house developed mixed-mode MPoPC (MultipProcessor-on-a-Programmable-Chip) HERA (Heterogeneous Reconfigurable Architecture) machine. The innovative adaptive parallelization technique combined with the unique flexibilities provided by the reconfigurable logic help to achieve high utilization of resources and potentially <b>minimum</b> <b>execution</b> times. Experimental results for parallel Singular Value Decomposition (SVD) on Xilinx Virtex II FPGAs are reported. I...|$|R
40|$|Abstract Scheduling {{real-time}} {{systems on}} multiprocessors introduces complexities {{that do not}} arise when using uniprocessors. If the processors do not all operate at the same speed, scheduling becomes even more complex. When scheduling using EDF on multiprocessors, breaking deadline ties in different ways can change the resulting schedule dramatically. We consider methods to resolve the ambiguities in EDF priorities due to coincident deadlines. We show that no optimal ambiguity resolver can be both on-line and priority-driven. When processor speeds differ, a job’s <b>minimum</b> required <b>execution</b> rate may also {{be considered in the}} scheduling decisions. We propose a modification of existing scheduling algorithms that considers processor speed and <b>minimum</b> required <b>execution</b> rate. We show that the resulting algorithm dominates EDF on identical multiprocessors and conjecture that it dominates EDF on uniform multiprocessors as well. ...|$|R
40|$|Digital wavelet {{transform}} based compression methods have higher compression rate with less amount of memory requirements, reversible {{and provide a}} better reconstructed images. In this paper execute image compression technique using EZW and SPIHT schemes. By using of different wavelet filters that is dmey, Symlets, Daubechies, Coiflets, reverse bi-orthogonal examine the compression performance. This method produces preserving most of the image information and the image is reproduced without degrading the image quality. Embedded zero tree wavelet is introduced by Shapiro and Amir Said introduced set partitioning in hierarchical trees. The best reconstructed images with better PSNR and <b>minimum</b> <b>execution</b> time provide by these techniques. Both techniques are compared by various parameters such as PSNR, CR, BPP, MSE & execution time. The results of image compression algorithm analyzed using MATLAB software and wavelet toolbox...|$|R
40|$|Scheduling {{real-time}} {{systems on}} multiprocessors introduces complexities {{that do not}} arise when using uniproccssors. If the processors do not all operate at the same speed, scheduling becomes even more complex. When scheduling using [DF on multiprocessors, breaking deadline ties in different ways can change the resulting schedule dramatically. We consider methods to resolve the ambiguities in [DF pri- orities due to coincident deadlines. We show that no optimal ambiguity resolver can be both on-line and priority-driven. When processor speeds differ, a job's <b>minimum</b> required <b>execution</b> rate may also {{be considered in the}} scheduling decisions. We propose a modification of existing scheduling algorithms that considers processor speed and <b>minimum</b> required <b>execution</b> rate. We show that the resulting algorithm dominates [DF on identical multiprocessors and conjecture that it dominates [DF on uniform multiprocessors as well. ...|$|R
40|$|Providing {{software}} qualities such as availability, adaptability and maintenability to long-running distributed applications, forms a {{major challenge}} for the configuration management of a software system. Modifications of system 's structure are expected to happen on-the-fly, to cause <b>minimum</b> <b>execution</b> disruption, and to be effected {{in a way that}} preserves a consistent state of the participating entities. This paper presents a novel algorithm for performing consistent dynamic reconfiguration of CORBA applications, where consistency refers to RPC integrity. The novelty of the algorithm is that it passivates the links affected by the reconfiguration, which causes the node activities that use them to block, but does not result in blocking the entire node. The consequent execution disruption is minimal, a fact that is practically verified by a performance evaluation done {{in a number of different}} reconfiguration scenarios. Keywords: Consistency, CORBA application, Dynamic Reconfiguration, E [...] ...|$|R
40|$|Software Pipelining is a loop {{scheduling}} {{technique that}} extracts parallelism from loops by overlapping {{the execution of}} several consecutive iterations. Most prior scheduling {{research has focused on}} achieving <b>minimum</b> <b>execution</b> time, without regarding register requirements. Most strategies tend to stretch operand lifetimes because they schedule some operations too early or too late. The paper presents a novel strategy that simultaneously schedules some operations late and other operations early, minimizing all the stretchable dependencies and therefore reducing the registers required by the loop. The key of this strategy is a pre-ordering phase that selects the order in which the operations will be scheduled. The results show that the method described in this paper performs better than other heuristic methods and almost as well as a linear programming method but requiring much less time to produce the schedules...|$|R
40|$|Abstract Embedded systems {{designers}} {{are turning to}} multicore architectures to sat-isfy the ever-growing computational needs of applications within a reasonable power envelope. One of the most daunting challenges for MultiProcessor System-on-Chip (MPSoC) platforms {{is the development of}} tools for efficient mapping multi-task appli-cations onto hardware platforms. Software mapping can be formulated as an optimal allocation and scheduling problem, where the application is modeled as a task graph, the target hardware is modeled as a set of heterogeneous resources, and the objective function represents a design goal α (e. g. <b>minimum</b> <b>execution</b> time, <b>minimum</b> usage of communication resources, etc.). Conditional task graphs, where inter-task edges rep-resent data as well as control dependencies, are a well-known computational model to describe complex real-life applications where alternative execution paths, guarded by conditionals, can be specified. Each condition has a probability associated with each possible outcome...|$|R
