179|20|Public
5000|$|MAK (<b>Maximale</b> Arbeitsplatz-Konzentration trans. Maximum Workplace Concentration) ...|$|E
5000|$|... "Über <b>maximale</b> Dosen der Arzneimittel" [...] -- On maximum {{doses of}} {{medicaments}} (in [...] "Transactions of the International Medical Congress", 1887) ...|$|E
5000|$|... "Variable, Objekte, Mengen von Universen und <b>maximale</b> Konsistenz in formalisierten Sprachen" [...] (Metakritik zur Diskussion von L.B. Puntel), in: Ethik und Sozialwissenschaften, Streitforum für Erwägungskultur 3 (1992), pp. 186 - 195.|$|E
40|$|International audienceThis work is {{to study}} an order D(P) on maximal antichains of a given order. D(P) is an order {{included}} in the order which defines the Lattice of maximal antichains AM(P), introduced by R. P. Dilworth, in 1960. In [3], T. Y. Kong and P. Ribenboim have proved that there exists an integer i such that Di(P) is a chain, where Di(P) =D(D(…D(P))), i times. We find the smallest i, noted cdev(P) such that Di(P) is a chain for some particular classes of orders and we approximate this parameter in the general case of order. Ce travail porte sur le développement d’un ordre D(P) sur les antichaînes <b>maximales</b> d’un ordre donné. L’ordre développé D(P) est inclus dans le Treillis des antichaînes <b>maximales</b> AM(P), introduit par R. P. Dilworth, en 1960. Dans [3], T. Y. Kong et P. Ribenboim ont montré qu’il existe un entier naturel i tel que Di(P) est une chaîne, où Di(P) =D(D(…D(P))), i fois. On note cdev(P) le plus petit i tel que Di(P) est une chaîne. Nous trouvons cdev(P) pour quelques classes particulières d’ordres et nous faisons une approche de ce paramètre dans le cas d’un ordre quelconque...|$|R
50|$|San Jose National High School in its twelfth year as {{learning}} institution is managed by Teacher Ana Marie M. <b>Maximales</b> as the School Head. The Faculty and Staff {{are composed of}} the following: Teacher Myra Samaco- Grade 7 adviser, Teacher Jocelle Banares -Grade 8 adviser, Teacher Lilibeth Francisco - third year adviser and Teacher Clarissa Feliscuzo - fourth year adviser. Teacher Almie Cabilin is the Technology and Livelihood Education subject teacher. Teacher Jhun Rino Betinol the Open High School Program Adviser. Teacher Maria Corazon Pelenio-subject teacher/School librarian.|$|R
40|$|AbstractLet φ:X→Y be an affine {{continuous}} {{mapping of}} a compact convex set X onto a compact convex set Y. We {{show that the}} induced mapping φ♯ need not map maximal measures on X to maximal measures on Y even in case φ maps extreme points of X to extreme points of Y. This disproves Théorème 6 of [S. Teleman, Sur les mesures <b>maximales,</b> C. R. Acad. Sci. Paris Sér. I Math. 318 (6) (1994) 525 – 528]. We prove the statement of Théorème 6 under an additional assumption that extY is Lindelöf or Y is a simplex. We also show that under either of these two conditions injectivity of φ on extX implies injectivity of φ♯ on maximal measures. A couple of examples illustrate the results...|$|R
5000|$|Whilst in the north, in the {{immediate}} neighbourhood zum noch gut 200 m höheren Kellerwald, noch Höhen von bis zu [...] (Hundskopf) erreicht, flacht der Höhenzug nach Süden auf die <b>maximale</b> Gipfelhöhe von [...] (Burgholz) ab.|$|E
5000|$|He {{is remembered}} for pioneer {{toxicological}} research he performed with Ferdinand Flury (1877 - 1947), {{of which the}} exposure limits of various substances encountered in the workplace were tested and defined. Their research formed a basis of what would later be known as MAK values (<b>Maximale</b> Arbeitsplatz-Konzentration) in Germany.|$|E
5000|$|In 1990 the Decennial Strategy (1990-2000) for the Mobilization of Water Resources and the Maximum Mobilization <b>Maximale</b> of {{available}} Resources was set up. This strategy was devised and implemented {{in order to}} provide integrated control of potential water sources. The cost of this ten-year strategy approached two billion US dollars.The following table shows the perspective concerning water resources in Tunisia: ...|$|E
40|$|Among other results, {{the purpose}} of this article is to show the {{existence}} of an R-space-vector with basis ω^i_j, i, j are integers such that every graph with n vertex n ≥ 3 is the vector: V(n) = ∑_j = 0 ^n- 1 α^n- 1 _jω ^ n- 1 _j Where α ^ n- 1 _j is the number of sub graphs of type ω^n- 1 _j. We deduce that two graphs are isomorphic if for any measure, they have the same number of maximal proper subset with this measure. Entre autres, le but de cet article est montrer l'existence d'un R-espace-vectoriel de base ω^i_j où i, j sont des entiers, tel que tout graphe V de cardinal n ≥ 3 est le vecteur : V(n) = ∑_j= 0 ^n- 1 α^n- 1 _jω^n- 1 _j Où α^n- 1 _j est le nombre de sous graphes de type ω^n- 1 _j. On en déduit que deux graphes sont isomorphes si pour toute mesure, ils ont le même nombre de parties propres <b>maximales</b> ayant cette mesure...|$|R
40|$|In the impact-echo method, the {{presence}} and the locations of defects in concrete are estimated from identifying peak frequencies in the frequency spectra, which {{are responsible for the}} resonance due to time-of-flight from the defects. In practical applications, however, spectra obtained include so many peak frequencies that it is fairly difficult to identify the defects correctly. SIBIE (Stack Imaging of spectral amplitudes Based on Impact Echo) procedure is developed as an imaging technique applied to the impact-echo, where defects in concrete are identified visually at the cross-section. In this study, the SIBIE procedure is applied to identify ungrouted post-tensioning ducts in prestressed concrete. Concrete slabs containing an ungrouted duct, a partially-grouted duct, and a fully-grouted duct of metal and polyethylene sheaths were tested. It is demonstrated that the defect can be identified with reasonable accuracy by SIBIE in all the cases tested. Résumé Dans la méthode impact-écho, la présence et les emplacements des défauts dans le béton sont évalués à partir de l’identification des fréquences <b>maximales</b> dans les spectre...|$|R
40|$|L’adsorption d’une {{solution}} aqueuse d’iode a été étudiée, en régime discontinu, sur quatre échantillons de charbons actifs des résidus de Moabi (Baillonella toxisperma Pierre) d’origine camerounaise (C 1, C 2, C 3, C 4) et sur trois échantillons de charbons actifs commerciaux (C 5, C 6, C 7). Le calcul de l’indice d’iode et l’analyse des isothermes d’adsorption par utilisation des théories de Langmuir et de Freundlich ont permis de déterminer le type d’adsorption. Il apparaît que la valeur de l’indice d’iode de l’un des échantillons des charbons des résidus de Moabi (C 4) est proche des valeurs de celui des échantillons commerciaux. De plus, l’adsorption de l’iode obéit aux isothermes de Langmuir avec des capacités <b>maximales</b> d’adsorption variant entre 9, 35  mmol∙g‑ 1 (C 4) et 13, 18  mmol∙g‑ 1 (C 7). The {{removal of}} iodine through adsorption on {{four types of}} activated carbon (C 1, C 2, C 3, C 4) obtained from local Cameroonian Moabi (Baillonella toxisperma Pierre) residues and on three commercial activated carbons (C 5, C 6, C 7) was studied in a batch mode. The calculation of the iodine index and the analysis of adsorption isotherms obtained using the Langmuir and Freundlich theories allow for {{the determination of the}} classification of adsorption. It was found that the iodine index of one activated carbon obtained from Moabi residues (C 4) is near to those obtained for the commercial activated carbons. Moreover, the iodine adsorption is clearly described by the Langmuir theory with the maximum capacity of adsorption varying between 9. 35  mmol∙g‑ 1 (C 4) and 13. 18  mmol∙g‑ 1 (C 7) ...|$|R
40|$|LES ETUDES SUR L'ORGANISATION DES SEQUENCES MOTRICES ONT MIS EN EVIDENCE L'EXISTENCE D'UNE PERIODE REFRACTAIRE (PR) CONSECUTIVE A L'INITIATION D'UNE ACTION ELEMENTAIRE : SI UNE SECONDE ACTION ELEMENTAIRE EST INITIEE PENDANT CETTE PR, D'UNE DUREE DE 230 MS, SA PERFORMANCE, EN TERMES DE VITESSE <b>MAXIMALE</b> ET DE DUREE, EST AFFECTEE. LE PREMIER OBJECTIF DE CETTE THESE ETAIT DE REPONDRE A LA QUESTION DE SAVOIR SI CETTE PR EST DUE A L'EXISTENCE D'INTERFERENCES DE CAPACITE, EN RAPPORT AVEC LA PROGRAMMATION DES ACTIONS SEQUENTIELLES, ET/OU D'INTERFERENCE DE STRUCTURE, EN RAPPORT AVEC LEUR EXECUTION. LE DEUXIEME OBJECTIF ETAIT D'ANALYSER L'ORGANISATION DIFFERENTIELLE D'UNE SEQUENCE MOTRICE COMPLEXE ENTRE NOVICES ET EXPERTS. LA SEQUENCE CHOISIE EST CELLE DE TOUCHE + FENTE EN ESCRIME. L'ANALYSE DU MOUVEMENT A ETE REALISE AU MOYEN D'ACCELEROMETRES MONO-AXIAUX ET DE L'ACTIVITE ELECTROMYOGRAPHIQUE DU DELTOID ANTERIOR. LES CONDITIONS EXPERIMENTALES ETAIENT LES SUIVANTES : TOUCHE, FENTE ET TOUCHE + FENTE. CHEZ LES NOVICES, LES RESULTATS ONT MONTRE QUE LA VITESSE <b>MAXIMALE</b> DU FLEURET PAR RAPPORT AU SUPPORT POSTURAL (VITESSE <b>MAXIMALE</b> RELATIVE, VRMAX) ETAIT AFFECTEE LORSQUE LA TOUCHE ETAIT DECLENCHEE PENDANT LES AJUSTEMENTS POSTURAUX ANTICIPATEURS (APA) DE LA FENTE. CHEZ LES EXPERTS, LA PERFORMANCE DE LA TOUCHE, EN TERME DE VITESSE <b>MAXIMALE</b> ABSOLUE DU FLEURET ETAIT COMPARABLE A CELLE DES NOVICES EN CONDITION TOUCHE. L'AMELIORATION DE LA PERFORMANCE CHEZ LES EXPERTS EN CONDITION TOUCHE + FENTE ETAIT DUE I) A CE QUE VRMAX N'ETAIT PAS AFFECTEE PAR LES APA DE LA FENTE ET II) A UNE REORGANISATION TEMPORELLE DES ACTIONS ELEMENTAIRES. L'ENSEMBLE DE NOS RESULTATS SUGGERE QUE LA PR SERAIT DUE A DES INTERFERENCES DE STRUCTURE ET QUE LE SYSTEME NERVEUX CENTRAL PROGRAMMERAIT LA VITESSE <b>MAXIMALE</b> DES ACTIONS ELEMENTAIRES D'UNE SEQUENCE MOTRICE COMPLEXE EN FONCTION DE CE CES INTERFERENCES. ORSAY-PARIS 11 -BU Sciences (914712101) / SudocSudocFranceF...|$|E
40|$|A {{restricted}} {{version of}} the Galois connection between polymorphisms and invariants, called Pol−CInv, is studied, where the invariant relations are restricted to so-called clausal relations. In this context, the relationship of maximal C-clones and maximal clones is investigated. It is shown that, {{with the exception of}} one special case occurring for Boolean domains, maximal C-clones are never maximal clones. Wir untersuchen eine eingeschränkte Variante der Galoisverbindung zwischen Polymorphismen und invarianten Relationen, bezeichnet mit Pol−CInv, wobei die invarianten Relationen auf sogenannte klausale Relationen beschränkt werden. In diesem Zusammenhang wird die Beziehung zwischen maximalen C-Klonen und maximalen Klonen betrachtet. Es wird gezeigt, daß, mit Ausnahme eines Spezialfalles für Boolesche Grundmengen, <b>maximale</b> C-Klone niemals <b>maximale</b> Klone sind...|$|E
40|$|We {{show how}} {{to compute the}} {{probability}} of any given local configuration in a random tiling of the plane with dominos. That is, we explicitly compute the measures of cylinder sets for the measure of maximal entropy on the space of tilings of the plane with dominos. We construct a measure {{on the set of}} lozenge tilings of the plane, show that its entropy is the topological entropy, and compute explicitly the - measures of cylinder sets. As applications of these results, we prove that the translation action is strongly mixing for and, and compute the rate of convergence to mixing (the correlation between distant events). For the measure we compute the variance of the height function. Resum'e. Soit la mesure d'entropie <b>maximale</b> sur l'espace X des pavages du plan par des dominos. On calcule explicitement la mesure des sous-ensembles cylindriques de X. De meme, on construit une mesure d'entropie <b>maximale</b> sur l'espace X 0 des pavages du plan par losanges, et on calcule explicitem [...] ...|$|E
40|$|ABSTRACT. New stratigraphic and chronometric {{data show}} that Bonnet Plume Basin, in northeastern Yukon Territory, was glaciated in late Wisconsinan time rather than during an earlier advance of Laurentide ice. This {{conclusion}} has important ramifications {{not only for the}} interpretation of all-time glacial limits farther north along the Richardson Mountains but also for non-glaciated basins in the Porcupine drainage to the northwest. The late Wisconsinan glacial episode in Bonnet Plume Basin is here named the Hungry Creek advance after the principal Quaternary section in the basin. Sediments beneath the till at Hungry Creek have produced well-preserved pollen, plant macrofossils, insects, and a few vertebrate remains. The plant and invertebrate fossils provide a detailed, if temporally restricted, record of a portion of the mid-Wisconsinan interstadial, while the vertebrate fossils include the oldest Yukon specimen of the Yukon wild ass. Some of the mid-Wisconsinan sediments have also yielded distinctive chert flakes that represent either a previously unreported product of natural fracturing or a by-product of stone tool manufacture by human residents of Bonnet Plume Basin. In addition to presenting new data on these diverse but interrelated topics, this paper serves as an introduction to a series of reports that will treat in turn the Upper Pleistocene record of Bluefish, Old Crow, and Bell basins, respectively. RESUME. De nouvelles donnees stratigraphiques et chronom 6 triques. indiquent que le bassin de Bonnet Plume situ 6 au nord-est du Yukon Btait glaciaire au Wisconsin suptrieur plut 6 t que lors de la crue anterieur de glace laurentienne. Les consequences entraine la revision des interpretations des limites glaciaires <b>maximales</b> en bordure des montagnes Richardson plus au nord et en bassin non glaciaire au reseau hydrographique de la Porcupine au nord-ouest. La phase superieure du Wisconsin dans le bassin de Bonnet Plume est connue ic...|$|R
40|$|We {{link the}} Picard group of SpecR to the {{question}} of conjugacy of maximal abelian diago-nalizable subalgebras of R ⊗ g. Nous faisons le lien entre le groupe de Picard de SpecR et la question de conjugation de sous-algèbres abéliennes <b>maximales</b> diagonalizables de R ⊗ g. Throughout k will denote a field of characteristic zero. Unless specifically mentioned otherwise all algebras, tensor products, vector spaces, and schemes are over k. One of the central results of classical Lie theory is Chevalley’s theorem establishing that all split Cartan subalgebras of a simple finite dimensional Lie algebra g are conjugate under its adjoint group. The analogous result for invariant (i. e symmetrizable) Kac-Moody algebras is due to Peterson and Kac (See [PK] and also Ch. 7 of [MP]). As a consequence of their work one knows that all maximal abelian k-diagonalizable subalgebras of the loop algebra k[t, t− 1] ⊗ g are conjugate (We reserve the terminology “Cartan subalgebra ” for nilpotent subalgebras which are self-normalized. See [BP]). Now it is reasonable to expect that conjugacy questions for loop algebras, or more generally for algebras of the form R⊗g, can be dealt with in a direct fashion. The following result is a small step in this direction 2. Theorem 1. Let g be a finite dimensional split simple Lie algebra and G its simply con-nected Chevalley-Demazure group scheme. Let R be an integral domain and X = SpecR its corresponding scheme. Assume that the Picard group of X is trivial and X(k) is not empty. Then all regular maximal abelian k-diagonalizable subalgebras of R⊗g are conjugate under G(R). Let g, G, X, and R be as in the statement of Theorem 1. The residue field of an element x of X will be denoted by k(x). For convenience in what follows the group G(k(x)) will be denoted simply by G(x), and the corresponding group homomorphism G(R) → G(x) b...|$|R
40|$|The {{main goal}} of this thesis is to explore the {{influence}} of sea surface temperature (SST), on surface wind at seasonal and intraseasonal timescales. At seasonal timescales, momentum and convergence budget were first documented by using a simple atmospheric mixed layer model, and two reanalyses. This approach allows us to identify the main processes that control the surface wind dynamics, in order to explore their sensitivity to the SST. Results show that these processes vary strongly in different regions of the tropical Atlantic. In addition, the comparison of the representation of theses processes in observations and reanalyses show that, as in all climate models (coupled or not), the reanalyses have the same flaws. Eventually, this work proposes a method to better assess the capacity of an atmospheric model to answer the SST fluctuations, and investigate potential wrong atmospheric parameterizations, such as boundary layers. The second part of this study focuses on tropical Atlantic regions of strong SST gradients, where SST intraseasonal variability is the largest. Several technics of spectrum and statistical analysis were performed in order to investigate the atmospheric patterns associated to these fluctuations of oceanic fronts. Except in the equatorial region (where we found a clear coupling already described in previous studies), no clear hint of a surface wind response to the SST fluctuations was observed in the two coastal upwelling fronts. In addition, the oceanic patterns associated to the SST indexes were also investigated. In all three upwelling fronts, as expected for such upwelling regimes, the vertical oceanic mixing clearly dominates the mixed-layer heat budget. In the equatorial band, as found in previous studies, the horizontal advection is equally important, while it appears surprisingly weak in the coastal fronts. Eventually, potential signals of equatorial and coastal Kelvin waves were also followed to these coastal fronts. Cette thèse vise à explorer l'influence des températures de surface de l'océan (TSO) sur les vents de surface en Atlantique tropical aux échelles saisonnière et intrasaisonnière. Nous avons commencé par étudier les bilans de moment cinétique et de convergence des vents de surface, avec un modèle simple de couche de mélange atmosphérique et des réanalyses, afin d'identifier les processus liés à l'influence des TSO sur le vent de surface. La comparaison de ces résultats avec les observations montre que les réanalyses souffrent de problèmes communs à tous les modèles de climat, couplés ou non : nous proposons donc au final d'appliquer notre méthode pour évaluer la capacité d'un modèle d'atmosphère à répondre correctement aux fluctuations de la TSO, et à indiquer quelles paramétrisations sont potentiellement à l'origine de défauts dans le modèle. Dans la deuxième partie de la thèse, nous avons mis en évidence les structures et les périodes où les variabilités océaniques et atmosphères sont <b>maximales,</b> à l'aide de différentes techniques d'analyse spectrale. Nous nous sommes ensuite focalisés sur les zones de fort gradient de la TSO (zones de front) afin d'étudier les caractéristiques des structures spatio-temporelles de la réponse atmosphérique liées aux fluctuations de ce front. Contrairement à la région équatoriale (ou on retrouve des résultats déjà évoqués dans des études antérieures), les deux fronts côtiers au large de l'Angola-Namibie et du Sénégal-Mauritanie ne montrent pas de signe de couplage actif avec l'atmosphère...|$|R
40|$|Abstract. We {{show how}} {{to compute the}} {{probability}} of any given local configuration in a random tiling of the plane with dominos. That is, we explicitly compute the measures of cylinder sets for the measure of maximal entropy µ on the space of tilings of the plane with dominos. We construct a measure ν {{on the set of}} lozenge tilings of the plane, show that its entropy is the topological entropy, and compute explicitly the ν-measures of cylinder sets. As applications of these results, we prove that the translation action is strongly mixing for µ and ν, and compute the rate of convergence to mixing (the correlation between distant events). For the measure ν we compute the variance of the height function. Resumé. Soit µ la mesure d’entropie <b>maximale</b> sur l’espace X des pavages du plan par des dominos. On calcule explicitement la mesure des sous-ensembles cylindriques de X. De même, on construit une mesure ν d’entropie <b>maximale</b> sur l’espace X ′ des pavages du plan par losanges, et on calcule explicitement la mesure des sous-ensembles cylindriques. Comme application on calcule, pour µ et ν, les correlations d’évenements distants, ainsi que la ν-variance de la fonction “hauteur ” sur X ′. 1...|$|E
40|$|In {{this paper}} we {{consider}} the Witten Laplacian on 0 -forms and give sufficient conditions under which the Witten Laplacian admits a compact resolvent. These conditions are imposed on the potential itself, involving the control of high order derivatives by lower ones, {{as well as the}} control of the positive eigenvalues of the Hessian matrix. This compactness criterion for resolvent is inspired by the one for the Fokker-Planck operator. Our method relies on the nilpotent group techniques developed by Helffer-Nourrigat [Hypoellipticité <b>maximale</b> pour des opérateurs polynômes de champs de vecteurs, 1985]. Comment: 24 page...|$|E
40|$|Beschrieben wird der Entwurf eines optimierten Datenerfassungssystem fuer Streuexperimente am Speicherring COSY (COoler SYnchrotron Juelich). Das C 40 -System mit der Programmiersprache OCCAM- 2 hat eine <b>maximale</b> Datenerfassungsrate von 26, 66 Mbytes/s. (HP) The report {{describes}} {{the design of}} an optimized data acquisition system for scattering experiments at the COSY storage ring (COSY = COoler SYnchrotron Juelich). The C 40 system uses the programming language OCCAM- 2; it has a maximum data acquisition speed of 26. 66 Mbytes/s. (HP) SIGLEAvailable from TIB Hannover: RA 831 (3013) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|E
40|$|Einführung: Die physikalischen Eigenschaften des intravenösen Anästhetikums Propofol (2, 6 -Diisopropylphenol) erlauben dessen fluoreszenzspektrometrische Detektion. Zur Entwicklung eines direkten Online-Monitorings im optisch dichten Medium Blut wird das Signalverhalten von Propofol im mit Blutprodukten gefüllten Kreislaufsystem untersucht. Material und Methoden: Der kontinuierliche Umsatz von 140, 2 ml Probenvolumen im Kreislaufmodell mit integrierter Durchflussquarzküvette bezweckt ein stabiles Fluoreszenzniveau des Messmediums, da Blutprodukte in statischer Versuchsanordnung unter der verwendeten Anregungsstrahlung (UV-C) starken photochemischen Bleichungseffekten ausgesetzt sind. Als Messmedien untersucht werden Gefrorenes Frischplasma (GFP), eine Suspension aus Erythrozytenkonzentrat und GFP (EK + GFP) sowie am Versuchstag gespendetes heparinisiertes Vollblut. Es erfolgt die standardisierte Injektionen von vier Propofolboli, durch die im System Konzentrationen von 35, 7 μg/ml bis 3, 6 μg/ml entstehen und den klinisch relevanten Wirkspiegeln bei Narkoseeinleitung sowie Narkoseaufrechterhaltung entsprechen. Unter Anregung mit Licht der Wellenlänge 274 nm liefert Propofol ein <b>maximales</b> Signal bei 300 nm. Anhand der in engen zeitlichen Abständen aufgenommen Fluoreszenzspektren werden die Propofoleffekte bei 300 nm im Summationsspektrum des Blut-Propofol-Gemischs analysiert. Ergebnisse: Die Signalanstiege bei 300 nm nach Injektion in das mit GFP bzw. EK + GFP gefüllte Kreislaufsystem sind hochsignifikant für die erzeugten Propofolspiegel von 35, 7 μg/ml bis 3, 6 μg/ml und weisen eine sehr gute lineare Korrelation von R 2 = 0, 73 bis zu R 2 = 0, 99 zwischen Fluoreszenzsignal und Propofolkonzentration auf. Allein für diese Messmedien kann durch den Einsatz des Kreislaufmodells ein ausreichend stabiles Fluoreszenzsignal zum Propofolnachweis erreicht werden. Dem Fluoreszenzanstieg nach Propofolinjektion folgt in allen Messmedien ein über 30 Minuten andauernder Signalabfall, für den nach fluoreszenzspektrometrischer Untersuchung von Schlauchproben des Kreislaufmodells die Adsorption des lipophilen Anästhetikums an Silikon als ein ursächlicher Faktor bestimmt werden kann. Schlussfolgerung: Der direkte konzentrationsabhängige Fluoreszenznachweis von klinisch eingesetzten Propofol-Wirkspiegeln gelingt allein in transfusionsmedizinisch aufbreiteten Blutprodukten. Background: The {{physical}} {{characteristics of the}} intravenous anaesthetic propofol enable to detect its specific emission spectrum with fluorescencespectroscopy. Striving for the goal of an instant Propofol-Online-Monitoring in the optically dense medium blood we developed an experimental setting for the research of the behavoiur of the Propofol-signal in circulation filled with blood products. Material and Methods: The designed circulation model allows a continous turnover of a samplevolume of 140, 2 ml in the integrated quartzcuvette under reproducible test conditions. To aim to achieve a steady level of fluorescence of the test-medium circultion is necessary, {{due to the fact}} that blood products are showing photochemical bleachingeffects in a static setting under the used excitation-wavelenght (UV-C). The used test-mediums are Fresh Frozen Plasma (FFP), a suspension of Erythrocyte Concentrate (EC) and FFP (EC + FFP) plus in a final step a whole blood donation rejected within 12 hours. The testarrangement is starting with the injection of four Propofol-boli, which are diluted to concentrations between 35, 7 μg/ml to 3, 6 μg/ml equivalent to clincally relevant levels under anesthetization and while maintaining anaesthesia. With the used exitation wavelength of 274 nm Propofols responses with a maximal signal of emission at 300 nm. With the fluorescence spectrums, detected in short intervalls, follows the analysis of the effect of Propofol at 300 nm in the summation spectrum of the blood-Propofol-mixture. Results: The rises of the fluorescence signal at 300 nm after injection in the circulation-model filled with FFP and EC + FFP are respectively high significant for the generated levels of Propofol between 35, 7 μg/ml to 3, 6 μg/ml and show a very good linear correlation between fluorescence signal an concentration of Propofol. These test-mediums are reaching an adaquate signal of fluorescence for the detection of Propofol. After fluorescence rises by addition of Propofol follows a constantly decrease of the signal about 30 minutes. One responsible factor for the drecrease ist he adsorption of the lipophilic anesthetic at silicone tubing in the circulation model. Conclusion: The successfull instant detection of clinically used Propofol levels with a fluorescence signal at 300 nm in dependance on concentration succeeds with transfusion medically treated blood products. The following decrease of fluorescence does not describe pharmacological kinetics of Propofol in blood, because the verifiable adsorption of Propofol at silicone tubings restricts the validity of the in-vitro-model...|$|R
40|$|In {{this thesis}} are {{exploited}} several instances {{of the relationship}} between convex Cauchy surfaces S in flat Lorentzian (2 + 1) -dimensional maximal globally hyperbolic manifolds M and the tangent bundle of Teichmüller space T(S) of the topological surface S. This relationship was first pointed out by Geoffrey Mess in the case of closed surfaces. The first case presented is the case of simply connected surfaces, and M is a domain of dependence in R^ 2, 1. We prove a classification of entire surfaces of constant curvature in R^ 2, 1 in terms of Zygmund functions on the circle, which represent tangent vectors of universal Teichmüller space T() at the identity. An important ingredient is the solvability of Minkowski problem for Cauchy surfaces in any domain of dependence M contained in the future cone over some point of R^ 2, 1, which is proved by analyzing the Dirichlet problem for the Monge-Ampère equation D^ 2 u(z) =(1 /ψ(z)) (1 -|z|^ 2) ^- 2 on the disc, where ψ is a smooth positive function. Moreover, when S is a surface of constant curvature, the principal curvatures are bounded if and only if φ is in the Zygmund class. The situation of S a closed surface, and M is a maximal globally hyperbolic flat spacetime diffeomorphic to S×R, is next discussed. We provide an explicit relation between the embedding data of any strictly convex Cauchy surface in M and the holonomy of M, which was used by Mess to parametrize the moduli space of manifolds M as above by means of the tangent bundle of T(S). The techniques used in this thesis are amenable to be extended to the case of globally hyperbolic flat spacetimes with n> 0 particles, namely cone singularities along timelike lines, where the cone angle is assumed in (0, 2 π). The analogue of Mess' parametrization is then proved, showing that the corresponding moduli space is parametrized by the tangent bundle of Teichmüller space of the closed surface S with n punctures. The above connections can be regarded as an infinitesimal version of the relation of Teichmüller space T(S) and universal Teichmüller space T() with surfaces in maximal globally hyperbolic Anti-de Sitter manifolds (either with the topological type of a closed surface, or with trivial topology) and in quasi-Fuchsian hyperbolic manifolds (or in H^ 3 itself). In {{the last part of the}} thesis this perspective is discussed, and the behavior of zero mean curvature surfaces in H^ 3 and AdS^ 3 close to the Fuchsian locus is discussed. The main result in hyperbolic space is a sublinear estimate of the supremum of principal curvatures of a minimal embedded disc in H^ 3 spanning a quasicircle Γ in the boundary at infinity in terms of the norm of Γ in the sense of universal Teichmüller space, provided Γ is sufficiently close to being the boundary of a totally geodesic plane. As a by-product, there is a universal constant C such that if the Teichmüller distance between the ends of a quasi-Fuchsian manifold M is at most C, then M is almost-Fuchsian, independently of the genus. In Anti-de Sitter space, an estimate is proved for the principal curvatures of any maximal surface with boundary at infinity the graph of a quasisymmetric homeomorphism ϕ of the circle. The supremum of the principal curvatures is estimated again in a sublinear way, in terms of the cross-ratio norm of ϕ. This also provides a bound on the maximal distortion of the quasiconformal minimal Lagrangian extension to the disc of a given quasisymmetric homeomorphism. Dans ma thèse doctorale, j'ai étudié principalement les plongements de surfaces dans des 3 -variétés Riemanniennes et Lorentziennes de courbure constante. J'ai écrit deux articles avec mon directeur de thèse Francesco Bonsante sur le cas des variétés Lorentziennes plates, l'un sur les surfaces convexes dans les espace-temps plats maximaux globalement hyperboliques, également quand on permet l'existence de singularités de type temps, et l'autre sur les surfaces convexes dans l'espace de Minkowski (qui est l'analogue Lorentzien de l'espace Euclidien) en relation avec la courbure Gaussienne. D'autre part, pendant mon séjour à l'Université du Luxembourg, j'ai commencé l'étude des surfaces à courbure moyenne nulle dans 3 -variétés à courbure sectionnelle constante et négative. J’ai écrit un article qui concerne les surfaces minimales dans l'espace hyperbolique et un autre article concernent des surfaces <b>maximales</b> dans l'espace Anti-de Sitter, qui peut être considéré comme l'analogue Lorentzien de l'espace hyperbolique. Dans plusieurs cas, il y a une forte relation entre les surfaces plongées et la théorie de Teichmüller, en particulier la théorie des applications entre surfaces...|$|R
40|$|New layered double {{hydroxides}} (LDHs) CoFe-Ac, CoNiFe-Ac, ZnNiFe-Ac and ZnCoFe-Acwith MII/MIII {{molar ratio}} of 3, and acetate ions in the interlayer region have been preparedusing forced hydrolysis of acetate metallic salts in a polyol medium. The structure,morphology and properties of as-prepared product were investigated by X-ray Diffraction(XRD), FT-IR Spectroscopy, elemental analysis, transmission Electron Microscopy (TEM),Scanning Electron Microscopy (SEM), thermal analysis (DTA, TGA) and V-visibleSpectroscopy: showed that these nanocomposites present the typical features of hydrotalcitelikestructure, exhibit a turbostratic {{character and the}} intercalation of acetate anions into theinterlayer domain has been successfully done, giving an interlayer spacing value of 12. 70, 12. 47, 13. 64 and 14. 69 Å for CoFe-Ac, CoNiFe-Ac, ZnNiFe-Ac and ZnCoFe-Acrespectively. We can note {{that there is some}} difference between the interlayer spacing for all synthesizedphases. That {{can be explained by the}} arrangement of inserted species (anions + water) indifferent orientation in the interlayer domain. 57 Fe Mössbauer spectrometry allows concluding the presence of Fe 3 + cations which occupyoctahedral sites and confirming the absence of Fe 2 + in the as-prepared compounds. In order to check the capacity of our materials synthesized in polyol medium to exchange theacetate anions inserted in their interlamellar space, anionic exchange in aqueous medium waseffected for CoFe-Ac compound as à model of synthesized LDH. All the physicochemicalmethods of analysis (DRX, IR, ATD/ATG and elemental analysis) carried out on the materialCoFe- Ac /EC (exchanged). The comparison with a lamellar phase containing oFeCO 3 /Asynthesized in aqueous medium, show a layered double hydroxide compound with aturbostratic disorder, and a new interlamellar distance d 003 = 7. 67 Å which correspondsperfectly with the presence of the carbonate anions and the water molecules in the interfeuilletfield. In the second part of this study, we are interested to examine the capacities of these kinds ofmaterials for the adsorption of an anion dye benzopurpurine- 4 B-. The adsorption of direct red 2 by CoFe-Ac, CoNiFe-Ac LDHs has been examined in order to measure the capability ofthis new organic/inorganic nanomaterial to eliminate this highly toxic azoic class of anionicdyes from wastewater. The sorption capacities of LDHs for Benzopurpurine 4 B are also compared with those of other adsorbents : CoFe- Ac /Ec, CoFeCO 3 /A (synthesized in aqueous medium), Mg-Al-CO 3 /A and its calcined product at 500 °C “Mg-Al- 500 ”. The quantity of dye eliminated was found to depend on contact time, pH, initial concentration of dye and heating temperature. The thermodynamic parameters ΔG°, ΔH° and ΔS° werecalculated to predict the nature of adsorption. Results suggested that the Benzopurpurine 4 B adsorption on different compounds was a spontaneous and endothermic process. Adsorption kinetic data were tested using pseudo-first order, pseudo-second order, Elovitch’sequation and intra-particle diffusion models. Kinetic studies for all cases showed that the adsorption followed a pseudo-second order reaction. Studies revealed that intra-particle diffusion played an important role in the mechanism of dye adsorption by MgAl- 500. Theequilibrium data were analyzed using Langmuir, Freundlich, Tempkin, Elovitch, Dubinin-Radushkevich, Redlich-Peterson and Toth isotherm models. [ [...] . ] Taking these results into account, we can conclude that prepared LDHs by forced hydrolysis in a polyol medium can be used successfully in the removal of anionic dyes from aqueous solutions. L’étude cinétique a permis de déterminer le temps d’équilibre atteint lors de la fixation du benzopurpurine 4 B sur chaque composé, ainsi que l’ordre de la réaction et la nature du mécanisme de diffusion. Cette adsorption est favorisée par un milieu légèrement basique, et l’augmentation de la température a un effet positif sur l’amélioration des performances <b>maximales</b> de la fixation. L’étude des isothermes d’adsorption de ce colorant, a été établie pour déterminer l’efficacité de cette nouvelle classe d’adsorbants. Ces dernières sont de type L, et les donnés de sorption ont été traitées selon plusieurs modèles, afin de mieux comprendre le mécanisme d'adsorption du colorant sur les différents matériaux. L’analyse des résultats de l’étude thermodynamiques a montré que l’adsorption du colorant sur les différents composés est un phénomène spontané, endothermique et favorable, régie par une adsorption physique pour les matériaux CoFe-CO 3 /Ec, CoFe-CO 3 /A et MgAl-CO 32 - et par une adsorption physico-chimique pour les matériaux CoFe-Ac/p, CoNiFe-Ac/p, et MgAl- 500. Ces résultats ont été confirmés par les analyses DRX et IR des différents matériaux avant et après adsorption. En comparant les résultats obtenus pour l’adsorption du colorant sur les différents matériaux, le composé CoNiFe-Ac/p constitue le meilleur adsorbant avec une capacité d’adsorption d’environ 593 mg/g. Par conséquent, et compte tenu de l’ensemble des résultats fournis par cette étude, l’hydrolyse forcée en milieu polyol, s’avère une méthode très efficace pour l’élaboration des hydroxydes doubles lamellaire à base de métaux de transition avec une morphologie contrôlée, de taille nanométrique présentant un faible taux d’agglomération, et par conséquent une bonne dispersion de particules et un meilleur pouvoir adsorbant. Ces caractéristiques peuvent être à l’origine de l’application de ces matériaux avec succès dans l’élimination des colorants contenant dans les effluents industriels...|$|R
40|$|Building on the {{kneading}} {{theory for}} Lozi maps introduced by Yutaka Ishii, in 1997, we introduce a symbolic method to compute its largest Lyapunov exponent. We use this method {{to study the}} behavior of the largest Lyapunov exponent for the set of points whose forward and backward orbits remain bounded, and find the maximum value that the largest Lyapunov exponent can assume. Nous étudions ici une nouvelle méthode pour calculer le plus grand exposant de Liapounov pour la famille des applications de Lozi, en utilisant la théorie du kneading pour ces applications, introduite par Yutaka Ishii. Avec cette méthode, on trouve la valeur <b>maximale</b> que cet exposant de Liapounov peut avoir dans la region des paramètres sur laquelle l’attracteur de l’ application est fractal...|$|E
40|$|Résumé. Nous déterminons le groupe de Galois de la pro- 2 -extension 2 -ramifiée <b>maximale</b> d’un corps de nombres 2 -rationnel. Abstract. We {{compute the}} Galois {{group of the}} maximal 2 -ramified and complexified pro- 2 -extension of any 2 -rational number field. Nota. This short Note is {{motivated}} by the paper “Galois 2 -extensions unramified outside 2 ” of J. Jossey and, at this occasion, we bring into focus some classical tech-nics of abelian `-ramification which, unfortunately, are often ignored, especially those developped by J-F. Jaulent with the `-adic class field theory, and by G. Gras in his book on class field theory, and which considerably simplify proofs in such subjects; for instance, the main Theorem 2, due to J-F. Jaulent, generalizes the purpose of Jossey’s paper in such a way...|$|E
40|$|We {{explore the}} link between {{dependence}} abstractions and maximal parallelism extraction in nested loops. Our goal is to find, for each dependence abstraction, the minimal transformations needed for maximal parallelism extraction. The result {{of this paper is}} that Allen and Kennedy's algorithm is optimal when dependences are approximated by dependence levels. This means that even the most sophisticated algorithm cannot detect more parallelism than found by Allen and Kennedy's algorithm, as long as dependence level is the only information available. In other words, loop distribution is sufficient for detecting maximal parallelism in dependence graphs with levels. Keywords: nested loops, automatic parallelization, dependence analysis, Allen and Kennedy's algorithm R'esum'e Nous 'etudions les relations entre repr'esentations des d'ependances et extraction <b>maximale</b> du parall'elisme dans les nids de boucles. Nous recherchons, pour chaque repr'esentation des d'ependances, la plus pe [...] ...|$|E
40|$|The topic treated {{along this}} thesis is the {{theoretical}} and numerical study of formalisms of Einstein equations, {{with the final}} aim of applications to black holes and gravitational waves. The General Relativity theory of Einstein (1915) postulated that light and trajectories of all particles are curved by the geometry of spacetime. Schwarzschild {{a few months later}} and Kerr in 1963 found solutions which describe non-rotating and rotating black holes. From an astrophysical point of view, a stellar black hole {{can be seen as the}} final result of some kind of collapse of massive stars or merger of compact binaries objects. One of the predicted consequences of General Relativity, not detected yet, is the existence of gravitational waves. This is the only direct method for detecting black holes. These waves can be viewed as ripples in the curvature of spacetime caused by non-spherically symmetric accelerations of matter. The first indirect detection was in 1974 by Hulse and Taylor, and they were awarded the Nobel. Huge experimental, theoretical and numerical efforts have been carried out in the last forty years, from the resonant bars of Weber to the future space-based interferometers as LISA. The General Relativity theory describes scenarios involving strong gravitational fields and velocities close to light velocity. The different formalisms lead to write Einstein equations as a set of partial differential equations. We must recognize the capability of the most used ones, as the so-called BSSN (Baumgarte-Shapiro-Shibata-Nakamura), crucial in the recent simulations of binary black holes. One of the recent formalisms is the FCF (Fully Constrained Formalism), which will be object of study along the thesis. In FCF, Einstein equations are written as a set of elliptic-hyperbolic equations, where the constraints are solved in each time step. It is a natural generalization of the relativistic approximation CFC (Conformally Flat Condition), used in many astrophysical applications. The theoretical work done in the thesis is very important, as the proof of the local existence of maximal slicings in spherically symmetric spacetimes. Moreover, the resulting equations in FCF have been studied mathematically. On one hand, the introduction of a new vector allows rewriting the elliptic equations such that local uniqueness is guaranteed and the equations form a hierarchical system. This is a very important in order to guarantee the well-posedness of the whole system. Numerical problems appear as consequence of the theoretical ones, and it was no possible to compute the migration test of a rotating neutron star and the spherical and rotational collapse to a black hole in the CFC approximation (and, so, in the FCF). The hyperbolic properties of the evolution system have also been studied. The explicit expressions of the eigenvalues are very useful in the study of inner boundary conditions of trapping horizons in which the singularity is removed from the numerical grid. The numerical work done in the thesis has as objective the extension of the CoCoNuT code to the FCF, in order to simulate non-vacuum dynamical spacetimes, including magnetic fields. We have performed the evolution of Teukolsky waves, analytical solution in vacuum and in linear regime, and the evolution of stationary rotating and perturbed rotating neutron stars. The next step will be the extraction of the gravitational signal in astrophysical scenarios and to compare the results with other approximations, as the quadrupole formula. El tema de la tesis es el estudio teórico y numérico de los formalismos de las ecuaciones de Einstein, con aplicaciones a la formación de agujeros negros y generación de ondas gravitatorias. La teoría de la Relatividad General de Einstein (1915) postulaba que la luz y las trayectorias de las partículas eran curvadas por la geometría del espacio tiempo. Schwarzschild (1915) y Kerr (1963) encontraron las soluciones que describen agujeros negros estático y en rotación. Desde un punto de vista astrofísico, un agujero negro estelar es el resultado de algunos tipos de colapso o la fusión de binarias de objetos compactos. Las ondas gravitatorias, predichas por la Relatividad General, aún no detectadas, son el único método directo para detectar agujeros negros. Son arrugas en la curvatura del espacio-tiempo. La primera detección indirecta por Hulse y Taylor (1974) les valió el Nobel. Enormes esfuerzos experimentales se han llevado a cabo en los últimos cuarenta años, desde las barras resonantes de Weber hasta los futuros observatorios espaciales como LISA. La Relatividad General describe escenarios que involucran campos gravitatorios intensos y velocidades próximas a la de la luz. En los diferentes formalismos las ecuaciones de Einstein se escriben como diferentes sistemas de ecuaciones en derivadas parciales. BSSN ha sido crucial en las recientes simulaciones de binarias de agujeros negros. FCF, introducido recientemente, ha sido objeto de estudio en la tesis. Las ligaduras se resuelven en cada paso de tiempo y es una generalización natural de la aproximación relativista CFC. El trabajo teórico realizado es muy importante: la prueba de la existencia local de foliaciones <b>maximales</b> en espacios-tiempo con simetría esférica; la introducción de un campo vectorial en las ecuaciones elípticas de FCF, que permite garantizar la unicidad local; el estudio de la hiperbolicidad de las ecuaciones de evolución en FCF, con aplicación a horizontes atrapados de agujeros negros. El trabajo numérico se centra en la extensión del código numérico CoCoNuT a la formulación FCF, para poder simular espacios-tiempo dinámicos con materia, incluyendo campos magnéticos. Varios tests satisfactorios permiten pensar en la extracción de la radiación gravitatoria en escenarios más complejos...|$|R
40|$|Les {{variations}} temporelles des concentrations en phosphore, celles des abondances bactériennes et de l'activité de la phosphatase alcaline (APA) ont été estimées in situ en chambre benthique placée en deux points du réservoir Sahela (Maroc) durant les mois de septembre et octobre 98. En période de faible oxygénation, nous avons enregistré des élévations relativement faibles des concentrations en orthophosphates (de 0, 020 à 0, 035 mg. l- 1 au point 1 et 0, 015 à 0, 025 mg. l- 1 au point 2) {{par rapport}} au phosphore total (0, 080 à 0, 100 mg. l- 1 au point 1 et de 0, 035 à 0, 040 mg. l- 1 au point 2). À cette période, les abondances bactériennes et l'APA montrent des valeurs <b>maximales</b> (8. 106 bact. ml- 1 et 0, 323 mmol. PNP l- 1. h- 1 au point 1 et 6. 106 bact. ml- 1 et 0, 438 mmol. PNP l- 1. h- 1 au point 2 respectivement). L'apparition des conditions anoxiques et la diminution du pH favorisaient la dissolution du phosphore particulaire et la libération du phosphore réactif soluble. Cette libération s'accompagne d'une élévation des abondances de bactéries anaérobies (de 5. 106 à 9, 2. 106 bact. ml- 1 au point 1 et de 3, 8. 106 à 7, 2. 106 bact. ml- 1 au point 2) et une diminution progressive d'APA (de 0, 200 à 0, 025 mmol. PNP l- 1. h- 1 au point 1 et de 0, 125 à 0, 077 mmol. PNP l- 1. h- 1 au point 2). Ce relargage du phosphore à partir du sédiment est accentué par les rejets domestiques et industriels de la ville de Taounate, ce qui accélère le processus d'eutrophisation de ce réservoir. Temporal variations of phosphorus concentrations, bacterial abundance and alkaline phosphatase activity (APA) were estimated in situ in a benthic chamber. The chamber used has a surface of 0. 4 m 2 and {{a volume of}} 90 l; it resembles those used in oceanography, with a tube connecting {{the interior of the}} chamber to the lake surface. The water in the chamber was permanently mixed by an electric agitation system. The chamber was placed at two points in the Sahela reservoir (Morocco). Point 1 was located near Guelta El Haila, a site that receives both domestic and industrial effluent, and point 2 was located in the centre of the reservoir. During the two incubations, eight samples were taken over 24 d in September and October 1998 from point 1, and seven samples were taken from point 2 over 29 d in October. After each sampling, an equal volume of water was injected into the chamber to avoid bubble formation. Under low dissolved oxygen concentrations in the benthic chamber, we noticed a relatively small elevation in orthophosphate concentrations (from 0. 020 to 0. 035 mg×L- 1 at point 1 and from 0. 015 to 0. 025 mg×L- 1 at point 2) in relation to total phosphorus (from 0. 080 to 0. 100 mg×L- 1 and from 0. 035 to 0. 040 mg×L- 1 at points 1 and 2 respectively). The low residual oxygenation of hypolimnic layer allowed the oxidation of iron, manganese and led to their binding to phosphorus released from the interstitial water. Dissociation of calcium-phosphorus complexes {{as a result of a}} pH decrease may have contributed to phosphorus release. The orthophosphate concentrations were relatively low, a situation that favours the synthesis of alkaline phosphatase by aerobic bacteria and facultative aerobic bacteria. In this period, the bacterial abundance and APA were comparable and showed the maximal values (8. 106 bact. ml- 1 and 0. 323 mmol. PNP l- 1. h- 1 (phosphate nitrophenol) in point 1 and 6. 106 bact. ml- 1 and 0. 438 mmol. PNP l- 1. h- 1 in point 2 respectively). The lack of a significant correlation between total APA and bacterial abundance at the two sampling points is probably due to the decrease of aerobic bacteria followed by a repopulation with anaerobic bacteria. However, the relative contribution of two bacterial populations that have different sizes, as at points 1 and 2, showed that the majority of total APA was produced by bacteria that are attached to organic matter. Therefore we suggest that attached bacteria contribute more than free bacteria to APA production. The beginning of anoxic conditions and the decrease in pH favored the dissolution of particulate phosphorus and the liberation of reactive phosphorus. We noted an elevation in orthophosphate concentrations (from 0. 035 to 0. 050 mg×L- 1 at point 1 and stabilised at 0. 025 mg×L- 1 at point 2) and total phosphorus (from 0. 100 to 0. 150 mg×L- 1 at point 1 and from 0. 040 to 0. 050 mg×L- 1 at point 2). This liberation followed an increase in anaerobic bacterial abundance (from 5 × 106 to 9. 2 × 106 bact×mL- 1 at point 1 and from 3. 8 × 106 to 7. 2 × 106 bact×mL- 1 at point 2) and the progressive decrease in APA (from 0. 200 to 0. 025 mmol PNP L- 1 ×h- 1 at point 1 and from 0. 125 to 0. 077 mmol PNP L- 1 ×h- 1 at point 2). The anaerobic bacteria did not activate their alkaline phosphatase and the synthesis of their enzyme was progressively inhibited by a de-repression phenomenon caused by high phosphorus concentrations. We conclude that low oxygen and a decrease in pH favoured the release of phosphorus by dissolution of chemical complexes: calcium-phosphorus, iron-phosphorus, manganese-phosphorus and aluminium-phosphorus. This release is also the result of bacterial phosphatase activity to which fixed bacteria contributed the most. The release of phosphorus from water-sediment interface is further amplified by phosphate import from domestic and industrial waste waters originating from Taounate, which accelerates the eutrophication process in this reservoir...|$|R
40|$|Depuis quelques années, un modèle stochastique de génération de hyétogrammes horaires est développé au groupement d'Aix-en-Provence du Cemagref, pour être couplé à une modélisation de la pluie en débit, fournissant ainsi une {{multitude}} de scénarios de crues analysés statistiquement et utilisés en prédétermination des débits de crues. L'extension de la zone d'application du modèle de pluies horaires au-delà de sa zone de conception, a fait apparaître une hétérogénéité dans les résultats. Ce constat a entraîné certaines modifications du modèle comme : la recherche d'une loi de probabilité théorique peu sensible aux problèmes d'échantillonnage pour une variable du modèle (intensité d'une averse), la prise en compte originale de la dépendance observée entre deux variables du modèle (durée et intensité d'une averse), et la modélisation de la persistance des averses au sein d'une même période pluvieuse. Ces différentes modifications apportées au modèle initial ont entraîné une très nette amélioration de ses performances sur la cinquantaine de postes pluviographiques du pourtour méditerranéen français. On obtient ainsi un outil beaucoup plus robuste et validé sur une zone étendue, capable de fournir de multiples formes de hyétogrammes, couvrant toute la gamme des fréquences, permettant ainsi de s'affranchir des pluies de projet uniques. On aborde aussi une nouvelle approche du comportement à l'infini des distributions de fréquences des pluies qui semble parfois supérieur à une tendance strictement exponentielle. De plus, l'étude de plusieurs événements par an dont chacun présente plusieurs réalisations des différentes variables du modèle augmente la taille des échantillons analysés, semblant rendre la méthode plus rapidement fiable qu'une approche statistique classique basée {{par exemple}} sur l'ajustement de valeurs <b>maximales</b> annuelles. A stochastic model for generating hourly hyetographs has been recently developed, in the Cemagref of Aix-en-Provence, to be {{coupled with a}} rainfall runoff conversion modelling. Thus, by simulation of very long periods (1000 years for example), we obtain {{a large number of}} hourly hyetographs and flood scenarios that are statistically studied and used in flood predetermination problems. The rainfall model studied is based on the theory that rainfall can be linked to a random and intermittent process whose evolution is described by stochastic laws. It is also based on the hypothesis of independence between variables describing hyetographs and on the hypothesis of the stationary nature of the phenomenon studied. Generating a rainfall time series involves two steps : descriptive study of the phenomenon (nine independent variables are chosen to describe the phenomenon and these variables are defined by a theoretical law of probability fitted to the observations) and creation of a rainfall time series using descriptive variables generated randomly from their law of probability. Initially developed on the Réal Collobrier watershed data, the model has been applied to fifty raingauges located on the Mediterranean French seaboard. The extension of the model applying area has shown heterogeneousness in the results. Therefore, modifications have been made to the model to improve its performances. Among these modifications, three of them have presented notable improvements. A study of the sensitivity of the parameters has been made. Parameters of shape variables and of some other variables had only a slight influence on depth of generated rainfalls. But, the law of mean rainfall intensities clearly differentiates the stations. Then, a theoretical probability distribution for the storm intensity variable, less sensitive to the sampling problems, has been searched. An exponential distribution is fitted to the value smaller than four times the mean of the variable. A slope breakage was then introduced to generate all the values beyond this limit. The breakage at the value four times the mean of the variable and modelling this breakage were based on a study of so-called "regional" distributions of the storm intensity variable. These distributions were designed by clustering the variable's homogenized values for all 50 studied stations. A second modification has been made to develop new model for the observed dependence between two variables (duration and intensity of the storm). The study of this dependence has been considered directly based on the cumulative frequency of the two variables. Then, an additional parameter was defined to model the dependence between the probabilities of the two variables. This parameter characterises the cumulative frequency curve of the sum of the probabilities of the two variables. This point, neglected during a long time, has been very important in the improvement of the model. Finally, the modelling of storm persistence in a same rainfall episode has been studied to generate some high 24 hours maximum rainfalls. Persistence modelling is entirely justified by the fact that "ordinary storms" cluster together around the "main storm" (the "main storm" is the greatest storm of an episode and the "ordinary storms" are the other storms of the episode). When the study of this phenomenon is extended, it can be observed that there is a certain positive dependency between occurrence probability of the "main storm" and occurrence probability of storms which come before or after it. Two combined effects occur : within one rainy episode, the strongest "ordinary storms" are preferentially clustered together around the "main storm", and considering the number of "ordinary storms" throughout all the episodes, the strongest storms close to the "main storm" are preferentially associated with the strongest "main storms" and vice versa. This modification improves the performances of the altitude raingauges, which are characterised by high daily rainfall accumulations. The different modifications added to the initial model, give very important improvements on the calibration of the fifty raingauges studied on the French Mediterranean seaboard. Its aptitude to generate rains observed in Mediterranean climate, strongly variables, consolidates us in the idea of its application on a zone much larger. The generation of hyetographs makes it possible to use the maximum the temporal information of the rain. Thus, we obtain a reliable tool, validated on a large area, for simulating hyetographs and hourly flood scenarios at all frequencies, and used instead of a unique design storm and design flood. The approach allows a new cumulative probability curve extrapolation, which seems sometimes greater than an exponential behaviour. Moreover, the study of many events per year, with many occurrences of the different variables of the model, increase the analysed sample size and seems to make the method more reliable than a statistical approach simply based, for example, on the fitting of annual maximum values...|$|R
40|$|Constant {{strain rate}} {{uniaxial}} compressive strength {{tests were conducted}} on saturated samples of six fine-grained frozen soils. The post peak compressive strength behavior of the frozen soils {{with respect to the}} variation in total water content, dry unit weight and the temperature conditions are studied. Test results indicated a ductile type of deformation for the frozen soils with generally low total water contents and at Fmperature conditions close to freezing. A brittle type of failure was observed for the frozen soils with high total water contents. The residual compressive strength of the frozen soils are found to be independent of the dry unit weight. However, for all the frozen soils the ratio of peak compressive strength to residual strength is found to decrease with increasing dry unit weight. An empirical relationship has been developed to express this behavior, which is also relatively temperature independent. Resume Des essais de dsistance B la compression uniaxiale ii taux de &formation constant ont dt 6 men & sur des tkhantillons satur 6 s de six sols gel & B grain fm. La r 6 sistance des sols gel & aprb compression <b>maximale</b> a 6 t 6 dtudi 6 e en fonction de la variation du contenu total en eau, de la masse unitaire sbche et de la temp 6 rature. Les rbultats indiquent que la d 6 formation est de type ductile pour les sols ayant en g 6 nQal une faible teneur totale en eau, au voisinage du point de congQation. Une rupture de type cassante fut obsew 6 e pow les sols gel & ayant un contenu en eau totale dlev 6 e. La rkistance r 6 siduelle B la compression des sols gelds est independante de la masse unitaire skhe. Toutefois. pour tous les sols gelb, le rapport de la r 6 sistance B la compression <b>maximale</b> B la r 6 sistance rdsiduelle diminue en fonction de la masse unitaire sbche. Une relation empirique a dtd dtablie pour exprirner ce comportement. lequel est relativement inddpendant de la temp&turd...|$|E
40|$|Die vorliegende Arbeit befasst sich mit den Leistungsgrenzen eines geschlossenen Zweiphasenthermosiphons mit Phasenseparator, der zur Erhoehung der Leistungsgrenze dient. Um einen physikalischen Eindruck ueber die Leistungsgrenzen und den Stroemungsvorgang zu erhalten, werden Experimente mit einem Glasthermosiphon zur visuellen Beobachtung durchgefuehrt. Die Interpretation der Beobachtungen bildet eine Basis fuer die Entwicklung der analytischen Modelle zu den Leistungsgrenzen. Die vorkommenden Leistungsgrenzen im Thermosiphon sind die Austrocknungsgrenze bei geringer Fuellmenge, und die <b>maximale</b> Leistung bei Erreichen einer kritischen Heizflaechenbelastung. Ein umfassendes Modell wird entwickelt, das die Mindestfuellmenge zur Vermeidung der Austrocknungsgrenze bei verschiedenen Startleistungen ermittelt. Zur Modellerstellung fuer die <b>maximale</b> Leistung wird zuerst die hydrodynamische Stabilitaet analytisch und experimentell beurteilt. Halbempirische Beziehungen zwischen der maximalen Leistung und den Parametern Betriebstemperatur und Massenstromdichte des Naturumlaufs werden aufgestellt. Die Massenstromdichte des Naturumlaufs wird analytisch berechnet. Diese Beziehungen basieren je nach Betriebsbedingung auf zwei Mechanismen, der Krise des hydraulischen Widerstands und der Wechselwirkungsgrenze. Der Vergleich zwischen experimentellen Daten und analytischen Ergebnissen zeigt eine gute Uebereinstimmung. (orig.) This work {{deals with}} the {{performance}} limitations in a closed two-phase thermosyphon with built-in phase separator which is utilized to enhance the maximum performance. In order to obtain an insight into the processes of performance limitation, experiments with a glass thermosyphon for visual observations are conducted. The interpretation of the flow visualization results provides {{a basis for the}} development of the analytical model for the performance limitations. The performance limitations in the thermosyphon are the dryout limit due to insufficient liquid fill charge and the maximum performance when a critical evaporator heat flux is reached. A comprehensive model is developed to calculate the minimum fill ratio to avoid the dryout for different starting heat flows. To analyse the maximum performance the hydrodynamic stability is estimated first, both analytically and experimentally. Semi-empirical relations are established between the maximum performance and the parameters operating temperature and mass flow rate of the natural circulation, which is analytically calculated. Depending on the operating conditions, these relations are based on two mechanisms, viz. the crisis of hydraulic resistance and the flooding-like limit. The analytical results agree well with theexperimental data. (orig.) SIGLEAvailable from TIB Hannover: RA 607 (5 - 244) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|E
40|$|We {{investigate}} the minimization of Newton's functional {{for the problem}} of the body of minimal resistance with maximal height M > 0 [4] in the class of convex developable functions dened in a disc. This class is a natural candidate to nd a (non-radial) minimizer in accordance with the results of [9]. We prove that the minimizer in this class has a minimal set {{in the form of a}} regular polygon with n sides centered in the disc, where the natural number n 2 is a non-decreasing function of M. The corresponding functions all achieve a lower value of the functional than the optimal radially symmetric function with the same height M. Resume Nous examinons la minimisation de la fonctionnelle de Newton pour le probleme de resistance minimale [4] d'un corps de hauteur <b>maximale</b> M > 0 dans la classe des fonctions convexes developpables denies sur un disque. D'apres les resultats de [9], cette classe est un candidat naturel pour la recherche d'un minimiseur non-radial. Nous demontro [...] ...|$|E
40|$|Dans les baies presque fermées de la Méditerranée, le taux de {{renouvellement}} et le pouvoir dispersif du milieu marin sont faibles. Ceci amène à des concentrations souvent élevées de bactéries califormes à la sortie des stations d'épuration, même munies de filières biologiques. L'élevage de coquillages dans ces baies constitue une contrainte supplémentaire aux concentrations <b>maximales</b> de bactéries permises selon les normes de la CEE. Le problème a été posé pour le fonctionnement de la station d'épuration de la ville de Thessaloniki. Le but de cette étude a été l'analyse quantitative de la dispersion et de la mortalité des bactéries coliformes. Pendant le premier semestre 1990, plusieurs campagnes de mesures ont permis l'échantillonnage et la détermination des concentrations de bactéries coliformes à quatre stations, situées au voisinage d'une source de contamination bactérienne. Parallèlement un modèle mathématique basé sur la simulation de la marche au hasard a été mis au point. Après étalonnage, ce modèle a servi comme outil pour simuler les impacts, sur les sites de conchyliculture, des eaux usées de la ville. In this paper, {{the contamination}} of coastal waters by coliform bacteria is considered. The problem is {{studied in the}} bay of Thessaloniki (N. Greece) using sampling, laboratory analysis and computerized mathematical modelling. The case study is typical for semi-enclosed bays in the Mediterranean sea. The water renewal and dispersion capacity of the sea are very low and high concentrations of coliform bacteria can be expected. This is the case when modern technology (biological treatment) {{is used in the}} sewage treatment stations and chlorination or other types of disinfection are kept low {{in order to avoid the}} formation of THM (Tri-Halo-Methanes). The problem of meeting the water quality standards is more difficult, when shellfish growing waters are to be protected. Impacts to marine environment from sewage and industrial effluents depend on 1) the degree of wastewater treatment, 2) the location of the disposal site and 3) the receiving capacity of coastal waters. The later means the maximum quantity of pollutants that a given area can receive without adversing effects (e. g. eutrophication, change of colour, odours). In the marine environment the receiving capacity is very difficult to assess, as it varies with very irregular way both in space and time. For coliform bacteria, the receiving capacity of a coastal area depends on the dispersive characteristics of the bay and the morality conditions of the bacteries. These are studied here for the case of the bay of Thessaloniki. The bay of Thessaloniki is located in the NW Aegean sea (Eastern Mediterranean). It is a shallow, semi-enclosed basin communicating with the open sea from the south boundary only. The northern part of the bay has a total area of 300 Km 2 and a maximum depth of 30 m. it is actually heavily polluted by untreated sewage coming from the city of Thessaloniki. Pollutant loads are estimated as 150 000 m 3 /d of sewage and 60 000 m 3 /d of industrial effluents. The sewage treatment station of the city has started now operating. The provisional disposal site is located in the west toast, three Km from Paliomana, where marine farms for mainly mussels and other shelffishes have been developed. In view of the economic importance of these activities and the need to protect the public health, it is important to assess the impacts from wastewaters to the coastal area. The main objective of the study is the quantitative evaluation of the dispersion and mortality conditions of coliform bacteria in the bay of Thessaloniki. The ain of the project is the choice of the disposal site of the sewage after treatment, by predicting the water impacts from sewage discharges. During the tire semester of 1990 (February-July 90) sampling and laboratory analyses of E. coli concentrations have been made every 15 days in 4 stations. Some of the samples have been taken during the night. Statistical analyses of the results gave the distribution in space of the max, min, median and C 80 values of E. coli (C 80 is the concentration which is not exceeded for 80 % cases). The tale of bacteries in the marine environment is described by the convective-dispersive equation, including the decay term. A linear dependance between bacterial morality and bacterial concentration is assumed. Over the years the advective dispersive equation has been extensively investigated and numerically approximated by numerous methods. Finite differences and finite elements have been used and produced stable numerical results. However, significant errors are introduced in ail these numerical simulations. These are due to the fact that only a limited number of terms in the Taylor series expansions are taken into account. Explicit algorithms suffer from the so-called numerical diffusion. This is an artificial diffusion related to the truncation errors. It is superimposed on the physical diffusion and leads to an excessive attenuation of the input signals. Implicit finite difference algorithms introduce trading effects because the initial signals are propagated at velocities that differ from the physical ones. It seems that particle methods based on random walks are more flexible and easy to use and lead to relatively accurate results. A random walk computerized mathematical algorithm is developed to simulate the dispersion and mortality of coliform bacteria in the bay. By use of a large number of particles (103 - 104) which move with the current velocities and by random dispacements following a Gaussian distribution, the contour lines of equal concentrations are obtained. The couple of values for the dispersion coefficient D and the mortality time T 90, which simulate better the space distribution of C 80 values is : D = 4 m 2 /s, T 90 = 5 h. The same value of the dispersion coefficient has been independently found by tracking flotting drogues in similar wind conditions (moderate wind). It is concluded that the above values of dispersion and bacterial mortality reflect the characteristic conditions of the bay and can be used to predict the impacts from sewage discharges...|$|R
40|$|La nappe aquifère de Hesbaye, logée dans les craies du Crétacé, est sollicitée à raison de trente {{millions}} de mètres cubes par an. Bien que naturellement protégée par une épaisseur de 5 à 20 mètres de limons, de nombreux indices montrent une dégradation de la qualité des eaux souterraines, notamment par les nitrates. Les concentrations en nitrates atteignent 15 à 25 mg. l- 1 dans la partie semi-captive de la nappe et sont systématiquement supérieures à 35 mg. l- 1 dans la partie libre. Malgré de fortes fluctuations temporelles, les teneurs augmentent en moyenne de 0, 35 mg. l- 1 à 0, 7 mg. l- 1 par an selon la situation semi-captive ou libre de la nappe. La détermination des paramètres hydrodynamiques et de transport de la craie par plus de 35 traçages répartis sur 11 sites, a permis de réaliser un modèle local (10 km 2) de transport simulant la propagation des nitrates dans la nappe. Le modèle a montré que cette dernière est, malgré une certaine homogénéisation, très sensible aux apports de surface engendrant une très forte variation spatiale des concentrations. La nappe réagit de manière très différente selon que les apports de surface sont d'origine ponctuelle ou diffuse. Pour les pollutions ponctuelles, les concentrations fluctuent rapidement avec des valeurs <b>maximales</b> et minimales observées respectivement en périodes de basses eaux et de hautes eaux. Cette situation est liée à un phénomène de dilution de la pollution par les eaux en provenance de l'amont. En cas de suppression d'une pollution ponctuelle, la qualité de la nappe s'améliore rapidement (délai de 1 à 2 ans). Pour les pollutions diffuses, les concentrations minimales s'observent en période de rabattement de la nappe : le front de nitrates migre plus lentement (environ 1 à 2 m par an) que les vitesses de rabattement de la nappe (jusqu'à 5 m par an) et les intrants restent nuls durant des périodes pouvant aller jusqu'à 3 ans. Différentes simulations mathématiques ont montré que si la quantité d'intrants d'origine diffuse diminue de manière permanente, la nappe mettra une vingtaine d'années pour se rééquilibrer. Ces constatations sont primordiales {{dans le cadre de}} la mise en œuvre de mesures de protection puisque, si les résultats de la suppression des pollutions ponctuelles sont rapidement mais localement observés, ceux liés à la diminution des pollutions d'origine diffuse sont observés dans des délais nettement plus longs (une à deux décennies). Ces résultats montrent clairement que toute gestion qualitative des aquifères doit être basée sur des actions à long terme. The Hesbaye area {{is located}} in the northeastern part of Belgium. The aquifer formations consist of chalk deposits. Groundwater provides about 80, 000 m 3 d- 1. Despite 5 to 20 meters of superficial loess deposits, the groundwater quality is threatened by increasing nitrate concentrations of 0. 35 mg×L- 1 per year in the semi-confined part of the aquifer to 0. 7 mg×L- 1 in the unconfined aquifer. Presently, nitrate concentrations are between 15 and 25 mg×L- 1 in the semi-confined part of the aquifer but are more than 35 mg×L- 1 (reaching locally 150 mg×L- 1) in the unconfined part that covers 95 % of the area. Nitrate concentrations have such a high spatial variation that various statistical treatments (such as kriging used to draw iso-concentration maps) have failed. This failure {{is due to the fact}} that the concentrations are highly influenced by surface land use (grass land, culture land, villages, point source pollutants, etc.). In addition, nitrate content in the aquifer varies vertically with decreasing values at depth (gradient of 0. 7 mg×L- 1 ×m- 1). Aquifer parameters were determined by 38 pumping and tracer tests conducted in radial convergent or cylindrical flow at 11 sites. Results showed that hydraulic conductivity values ranged from 1 × 10 - 6 m×s- 1 to 4 × 10 - 2 m×s- 1 and effective porosities from 0. 5 % to 7 %, showing that the aquifer was heterogeneous. Dispersivity values were affected by scale effects and varied according to chalk weathering or fracture zones. They ranged from less than 5 m in fractures to more than 60 m in weathered chalk (as in the upper part of the aquifer) and in the chalk matrix. In the chalk, transport processes were influenced by the immobile water effect due to diffusive transfer from the moving to the non-moving fluid. Non-effective porosity filled by non-moving fluid was estimated between 8 to 42 %. The transfer constant ranged from 0. 98 × 10 - 7 s- 1 to 10 × 10 - 7 s- 1. The determination of the transport parameters allowed simulation of nitrate transport at a regional scale. The SUFT 3 D (Saturated and Unsaturated Flow and Transport Model), developed by the Hydrogeology Section of the Georesources, Geotechnologies and Building Materials Department of Liege University was used. The modelled groundwater zone was defined as a 2. 0 x 4. 5 km rectangle of 10 km 2. The aquifer was subdivided into 6 layers of 3350 cells (50 x 50 m wide and 3 to 15 m thick). Boundary flow conditions were defined as a prescribed head (Dirichlet conditions) to the north and the south of the area modelled. As the model simulations run for a time period of 30 years, the northern Dirichlet conditions had to be adapted to the regional and seasonal water table fluctuations that were observed during this period. At the south boundary, as the aquifer is drained by the river Geer, the water table is fixed at the river bed altitude. The eastern and western boundaries were, according to the regional piezometry, assumed to be impermeable. For the transport boundary conditions, prescribed flux (Cauchy conditions) was used for the aquifer top. Elsewhere Neumann conditions were usedSimulations were run for the period from 1963 to 1992. Nitrate inputs were averaged yearly and estimated according to actual input conditions. These conditions were calculated by simulation of nitrate flows through the non-saturated part of the aquifer using the EPIC-Model and taking into account the amount of nitrate fertilisers used by farmers (given by the Belgian government Statistical Institute). Initial conditions were calculated according to the 1963 nitrate inputs. Simulations demonstrated that it is important to distinguish the origin of the pollution as either point or non-point (diffuse) sources. For point source pollutants (such as contaminated infiltration basins), aquifer nitrate concentrations increased during low water level periods due to weaker dilution linked with a poor regional water gradient. During high groundwater levels, dilution is more important and the nitrate concentration decreases. If a point source pollutant is suppressed, aquifer quality is improved within one to two years. This demonstrates the importance of protective actions that could be applied within the framework of the protection zones around collecting galleries and pumping fields. For diffuse contamination the mean input over the area (10 m depth below cropped areas) increased from 1. 32 × 10 - 7 mg×m- 2 ×s- 1 in 1963 to 5. 14 × 10 - 7 mg×m- 2 ×s- 1 (i. e., a factor of four). According to these values, concentrations ranged from 11 mg×L- 1 to 22 mg×L- 1 (i. e., increasing by 0. 5 mg×L- 1 per year) between 1963 and 1992. Predictive simulations, using 1992 input, show that it will take more or less 30 years for the aquifer to be in equilibrium with the 1992 input. At that time the mean concentration value will be around 30 mg×L- 1. The main results of the simulations clearly show that if actions are taken to decrease nitrate inputs, even if the aquifer nitrate contents rapidly react to the new input, nitrate levels will decrease slowly and take about 30 years to be in equilibrium with the new inputs. This long delay is due to the immobile water effect that is characteristic of the chalk aquifer. Thus it is important to inform environmentalists who work on action programs (such as the water directive imposed by the European Community in the vulnerable zones) that the effects of their actions must be based on 10 to 20 year scenarios. To this estimation, based on the reaction time of the aquifer to a new input, one must also add the time transfer of the pollutant through the unsaturated part of the aquifer...|$|R
40|$|Escherichia coli und Coliforme werden traditionell als Indikatororganismen für fäkale Kontamination in Wasser verwendet. Aufgrund des anhaltenden Ausbruchs von E. coli, besteht dringender Bedarf, {{alternative}} Methoden zu entwickeln, die die Bakterien zeitnah und präzise detektieren und identifizieren können. Bisher verfügbare Standardmethoden benötigen einen hohen Zeitaufwand (18 – 48 ℎ). In dieser Studie wurde ein empfindliches und schnelles Verfahren für den Nachweis von coliformen und E. coli Bakterien entwickelt. Das Verfahren ist eine Kombination aus einer enzymatischen und einer analytischenMethode. Die enzymatische Methode basiert auf der modernen Taxonomie von Coliformen und E. coli, in dem das Vorhandensein / Nichtvorhandensein von Coliformen und E. coli Bakterien werden über die Anwesenheit / Abwesenheit der Enzyme B-Galaktosidase bzw. B-Glucuronidase bestimmt. Die Analysemethode basiert auf der Kopplung von GC mit Differential Mobility Spectrometry betrieben werden. Anhand der Fingerprintanalyse ausgewählter flüchtiger Metaboliten wurde die Leistungsfähigkeit der Analysentechnik überprüft. Aus dem Head-space von Standard-Lösungen wurden ausgewählte Substanzen (2, 5 -Dimethyltetrahydrofuran, Dimethyldisulfid, 2 -Heptanon, 2, 5 -Dimethylpyrazin, Benzaldehyd, Dimethyltrisulfid, 2 - Nonanon, Nonanal, Decanal, 2 -Undecanon, Indol und 2 -Tridecanon), die als Metaboliten von E. coli in der Literatur beschrieben werden, bestimmt. 2 -Undecanon, Indol und 2 -Tridecanon konnten aufgrund der relativ geringen Flüchtigkeit nicht detektiert werden. Weiterhin wurden die experimentellen Parameter optimiert. Die Hochfrequenz-(RF-) Spannung beeinflusst die Peaktrennung und Signalintensität. Je höher die RF-Spannung, desto besser werden die Signale getrennt. Allerdings nimmt die Signalintensität ab; 1200 V	 (entspricht 24 kV /cm) wurde als die optimale HF-Spannung für die Detektion der oben genannten Verbindungen festgelegt. Ein wichtiger experimenteller Parameter ist die Wahl des geeigneten Nährmediums. Folgende Nährmedia wurden verwendet: Colilert- 18 ®, Glucose-Brühe, M 9 -Medium, tryptische Sojabrühe (TSB) und Tryptophan Brühe. Als optimal stellte sich Colilert- 18 ®- Medium heraus, da bei dessen Verwendung für E. coli spezifisch o-Nitrophenol (ONP) freigesetzt wird, welches mit GC-DMS empfindlich nachweisbar ist. Die Validierung erfolgte mit Gaschromatographie - Massenspektrometrie (GC-MS) -Analyse. Um die Analysenzeit zu verkürzen, wurden E. coli DSM 30083 Bakterien in Colilert- 18 ® unter verschiedenen Inkubationszeiten gezüchtet. Nach 2, 5 Stundenerfolgte die Spaltung von ONPG durch das Enzym B-Galactosidase. Nach dieser Zeit war es möglich, o-Nitrophenol aufgrund der hohen Nachweisempfindlichkeit mittels GC-DMS zu detektieren. Das Signal erscheint bei einer Retentionszeit von tr = 184. 9 s und Kompensationsspannungen von CVv, 1 = − 2. 82 V	 (im positiven Modus) und Cv, 2 = − 4. 09 V	 (im negativen Modus). Die Nachweis- und Bestimmungsgrenzen für die Bestimmung von o-Nitrophenol wurde mit dem Kalibrierverfahren nach DIN 32645 zu 45 ng (pos. Mode) und 49 ng (neg. Mode) berechnet. Da die gebildete Menge von der Konzentration der E. coli Bakterien in den Proben abhängt, wurde eine Korrelation zwischen der E. coli-Konzentration und der Signalintensität für o- Nitrophenol bestimmt. Nach 2, 5 h Inkubationszeit wurden 3. 37 × 10 ^ 7 bzw 3. 21 × 10 ^ 7 E. coli cells/ml erhalten. Um die Leistungsfähigkeit der entwickelten Methode zu untersuchen, wurden für die Differenzierung von E. coli von anderen E. coli und von anderen Bakterien 5 Arten von Bakterien in Colilert- 18 ® für 3 Stunden gezüchtet und die gasförmigen Metabolitemittels GC-DMS analysiert. Als Bakterien wurden (1) E. coli DSM 30083, (2) E. coli DSM 1576, (3) E. coli RV, (4) K. pneumoniae (ein coliform Bakterien), und P. aeruginosa (ein nicht-coliforme Bakterien) ausgewählt. Basierend auf der Anwesenheit / Abwesenheit von ONP konnte E. coli und K. pneumoniae von P. aeruginosa unterschieden werden. Basierend auf der Intensität des ONP-Signals und der endgültigen Zellkonzentration konnte E. coli von K. Pneumonie unterschieden werden. Mit der entwickelten Methode ist es jedoch nicht möglich, den Unterschied zwischen einzelnen E. coli-Stämmen zu unterscheiden. Um die Wirkung von saisonalen Einflüssen im Feld zu überprüfen (z. B. Änderung der Wassertemperatur) wurde die Inkubationstemperatur variiert. Wie erwartet, wurde bei einer Temperatur von 36 ° ein <b>maximales</b> Zellwachstum beobachtet. Abschließend wurde ein Algorithmus zur Detektion und Identifizierung von E. coli und Coliformen dargestellt. Mit der entwickelten Methode können die Zielorganismen erheblich schneller als mit bestehenden Methoden identifiziert werden. Somit ist ein hohes Potenzial für den Einsatz vor Ort gegeben. Einschränkend ist die relativ hohe Nachweisgrenze, die durch Verwendung von Mikroextraktionstechniken als Anreicherungsmethode verbessert werden könnte. Escherichia coli and coliform {{are traditionally}} used as indicator organisms for fecal contamination in water. Due to persistence outbreak of E. coli, {{there is an}} urgent {{need to develop a}} method that could detect the bacteria in timely and accurate manners. The main limitation of standard and alternative methods is the time to obtain the result (18 – 48 ℎ). An analysis time exceeding one day is often too slow for authorities to take a rapid response in case of an outbreak. There are emerging analytical methods which are relatively faster, but most existing analytical methods have some technical limitations, such as the need for vacuum, the need for oven, {{and the size of the}} analytical instruments which are not practical for on-site applications. In this study, a method for rapid detection and identification of coliform and E. coli bacteria was developed. The method is a combination of enzymatic and analytical methods. The enzymatic method was built upon the modern taxonomy of coliform and E. coli, in which the presence/ absence of coliform and E. coli is characterized by the presence/absence of β- galactosidase and β-glucuronidase enzymes, respectively. As E. coli is also a type of coliform, the presence of E. coli is indicated by the presence of both enzymes. The analytical method employed the use of microAnalyzer™ (a miniaturized Gas Chromatography – Differential Mobility Spectrometry (GC-DMS) system), which is an advanced gas detector that requires a low power consumption, has a built-in GC system, compact, portable, and could be operated using ambient pressure. Differential mobility spectrometry (DMS) is an ambient pressure ion-separation technique that characterizes chemical substances using differences in the gas phase mobility of ions in alternating strong and weak electric fields that are generated using a high frequency asymmetric waveform. In this study, at first the performance of GC-DMS in the detection of volatile metabolite compounds released by E. coli was investigated through “finger-print” recognition analysis. Twelve compounds known to be metabolites of E. coli (2, 5 -dimethyltetrahydrofuran, dimethyl disulfide, 2 -heptanone, 2, 5 -dimethylpyrazine, benzaldehyde, dimethyl trisulfide, 2 - nonanone, nonanal, decanal, 2 -undecanone, indole, and 2 -tridecanone) were prepared from standard solutions and the headspace gases were analyzed by GC-DMS. It was found that the last three compounds (which have relatively low volatility) could not be detected by the GC-DMS. This study, however, revealed the effect of radio-frequency (RF) voltage on the peak separation and signal intensity: the higher the RF voltage, the better the separation among the peaks, but the poorer the signals intensity; 1200 V	 (corresponds to 24 kV/cm) was found to be an optimum RF voltage for the aforementioned compounds. As the type and composition of metabolites released by bacteria are determined by many factors (such as the type of growth medium, the temperature of growth, and cell age), the study was continued by the determination of suitable growth medium, i. e. a medium which could stimulate E. coli in producing either unique “finger-print” compounds or unique biomarker compounds, which could be detected by the miniaturized GC-DMS. Five media commonly used to grow E. coli were examined: Colilert- 18 ®, glucose broth, M 9 -medium, tryptic soy broth (TSB) and tryptophan broth. It was found that unlike all other four media, Colilert- 18 ® medium stimulated E. coli growth in a way that it produced a unique biomarker, namely o-nitrophenol (ONP), and this biomarker was detectable by the GC-DMS. The finding was confirmed by gas chromatography – mass spectrometry (GC-MS) analysis. Colilert- 18 ® contains ortho-Nitrophenyl-β-galactoside (ONPG) and 4 -methylumbelliferyl-β-D-glucoronide (MUG) substrates. In the presence of ONPG substrate, β- Galactosidase enzyme in E. coli and coliform is activated and helped the hydrolysis of ONPG into β-D-Galactose and onitrophenol. In standard Colilert- 18 ® test, due to its appearance, o-nitrophenol (which is a yellow crystalline solid) is usually used as a chromogenic indicator which confirms the absence/ presence of coliform. In the presence of the MUG substrate, β-Glucuronidase enzyme in E. coli is supposed to be activated and helped the hydrolysis of MUG into β-DGlucuronate and methylumbelliferone. However, headspace analysis of E. coli metabolites by GC-DMS and GC-MS analysis performed in this work only detected and identified the presence of o-nitrophenol, not of methylumbelliferone, due to the poor volatility of methylumbelliferone. Therefore, up to this particular point, the developed method was able to detect and identify coliforms including E. coli, but not able to distinguish E. coli from other coliforms. To distinguish E. coli from non - E. coli, a standard Colilert- 18 ® test which involved the viewing of the sample under a 365 nm -. fluorescent UV lamp was needed; the presence of E. coli was indicated by a blue fluorescence effect. The time to perform standard Colilert- 18 ® test is usually between 18 and 24 ℎ, which is the main limitation of the method. To shorten the analysis time, E. coli DSM 30083 bacteria were grown in Colilert- 18 ® under various incubation periods. It was found that the cleavage opening (the cleaving of ONPG by β-galactosidase enzyme) took approximately 2. 5 ℎ, as indicated by the presence of o-nitrophenol which could be detected by the GC-DMS after E. coli was incubated for just 2. 5 ℎ. This means, the analysis time is 7 to 9 times faster than the standard Colilert- 18 ® test. This is because the GC-DMS could detect a very low amount of onitrophenol despite the subtle or insignificant color change of the chromogenic indicator in the sample. Signal peak of o-nitrophenol was detected by the GC-DMS at both positive and negative ion channels of the DMS detector. The signal appeared at a retention time of tr = 184. 9 s and compensation voltages of Cv, 1 = − 2. 82 V	 (in the positive mode) and Cv, 2 = − 4. 09 V 	 (in the negative mode). GC-DMS system has three-dimensional data; it consists of: (1) retention time and (2) compensation voltage(s) which are unique to compounds’ identity, and (3) signal intensity. Unlike similar spectrometry methods, the difference in retention times of compound signals in GC-DMS could be very small (a matter of seconds instead of minutes), and compounds could still be differentiated based on their unique compensation voltages. Overall, the work in this section showed that compared to the already shortened incubation period (2. 5 ℎ), the GC-DMS retention time (184. 9) is much shorter. Hence, the analysis time using GC-DMS does not affect much the overall analysis time, which is excellent. Detection limit of o-nitrophenol was determined by calibrating mass of o-nitrophenol standard against signal intensity using DIN 32645 method. Detection limits of 45. 11 ng and 48. 85 ng of o-nitrophenol were obtained for the positive and negative modes of the detector, respectively. As the amount of o-nitrophenol is a dependent variable (the amount of o-nitrophenol in the headspace depends on the concentration of E. coli in the samples), concentration of E. coli was calibrated against signal intensity. When E. coli was incubated for 2. 5 ℎ, detection limits of initial concentration of E. coli (concentration level before E. coli was incubated) of 3. 37 × 10 ^ 7 and 3. 21 × 10 ^ 7 cells/ml were obtained for the positive and negative modes, respectively. As E. coli growth curve showed the increase of final concentration of E. coli with respect to incubation period, it is concluded that the limit of initial concentration could be decreased if the incubation period is increased. To investigate the performance of the developed method in the differentiation of E. coli from other E. coli and from other bacteria, 5 types of bacteria were grown in Colilert- 18 ® for 3 ℎ and the metabolite gases were analyzed by GC-DMS. These bacteria were (1) E. coli DSM 30083, (2) E. coli DSM 1576, (3) E. coli RV, (4) K. pneumonia (a coliform bacteria), and P. aeruginosa (a non-coliform bacteria). Based on the presence/absence of ONP, E. coli and K. pneumoniae could be distinguished from P. aeruginosa. Based on the intensity of ONP and the final cell concentration, E. coli could be distinguished from K. pneumonia. The method, however, could not distinguish the difference of E. coli from one strain to another. To anticipate the effect of seasonal variation in practical application, e. g. change in water temperature, the effect of sample preheating temperature (i. e. incubation temperature) variation was investigated. It was found that the sample should be incubated at 36 ° to accommodate maximum cell growth and signal intensity. From the overall finding, an algorithm to detect and identify E. coli and coliform was presented. Overall, the developed method was significantly faster than existing methods, was able to differentiate target organisms from non-target organisms, and is potential for on-site application. The main limitation is the relatively high detection limit, which could be improved by improving the sample enrichment technique using membrane filtration technique, and by improving the sample extraction and introduction methods. Nevertheless, to the author’s knowledge, the method developed in this work is the first reported application of miniaturized (portable) GC-DMS technology for headspace analysis of volatile metabolite biomarkers in conjugation to enzymatic approach using a defined substrate media and the first one which is applied for the detection and identification of fecal contaminant in water samples...|$|R
