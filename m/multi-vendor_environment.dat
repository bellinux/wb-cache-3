33|24|Public
50|$|NEC markets its {{portfolio}} of voice and data products under the UNIVERGE brand. UNIVERGE solutions integrate products, applications {{and services in}} a <b>multi-vendor</b> <b>environment</b> to deliver traditional, hybrid and converged IP communication solutions.|$|E
50|$|RV-C is a {{communications}} protocol {{based on the}} Controller Area Network bus. The protocol is used in recreation vehicles to allow house and chassis components to communicate. RV-C is used for control, coordination, and diagnostics, in a <b>multi-vendor</b> <b>environment.</b>|$|E
5000|$|Ethernet passive {{optical network}} (EPON) is a {{technology}} for fiber to the x access networks, with millions subscriber lines. In response to rapid growth, the SIEPON project was formed in 2009 to develop system-level specifications, targeting [...] "plug-and-play" [...] interoperability of the transport, service, and control planes in a <b>multi-vendor</b> <b>environment.</b>|$|E
50|$|The IEEE 802.1AB or Link Layer Discovery Protocol that is {{supported}} on most Nortel equipment is a standards based (vendor-neutral) protocol that supports <b>multi-vendor</b> <b>environments.</b>|$|R
50|$|With {{increased}} {{sophistication of}} Business Communications/UC with new capabilities such as Multiplicity of devices, Application integration- CEBP and Heterogeneous, <b>multi-vendor</b> <b>environments</b> along with Consumerization expectations and New technologies, BCOM addresses problems like multiple configurations per event increases likelihood of missed configurations or mis-configured elements by providing single point of configuration and operational control features like single pane of glass.|$|R
5000|$|Integrated {{with the}} industry's top storage arrays to {{automate}} {{the creation of}} indexed, application-aware hardware snapshot copies across <b>multi-vendor</b> storage <b>environments.</b>|$|R
50|$|A {{network element}} state model {{facilitates}} cross domain network management and promotes a <b>multi-vendor</b> <b>environment.</b> The standard definitions and mappings allow Operations Systems to gather state information from NEs and integrate {{it into a}} consistent representation {{of the status of}} the entire managed network and each of the services that it supports.|$|E
50|$|It {{is exactly}} the {{findings}} that NetAcad case study revealed that make Kosovo a perfect ICT outsourcing country, and time difference with the USA makes it only more appealing for the U.S. market. Such {{is a story of}} 3CIS which provides highly specializedservices to major telecommunication carriers across the globe. This includes network architecture design, planning, consulting, implementation,integration and testing with a strong expertise on mobile backhauling. 3CIS also provides on-site consulting ser-vices as well as manages and coordinates the activities in a <b>multi-vendor</b> <b>environment</b> during the life-cycle of the complete project. On top of this, 3CIS also offers Project management services that are tailored to suit client needs from initial planning to project completions.|$|E
40|$|The {{objective}} of Open Distributed Processing (ODP) {{is to support}} the construction of distributed systems in a <b>multi-vendor</b> <b>environment</b> through the provision of an architectural framework that such systems must adhere to. However, without a means to assess conformance {{the value of this}} architecture is limited. This paper describes a conformance assessment methodology suitable for Open Distributed Processing, this methodology includes both testing and specification checking. We also discuss the scope of the methodology, which can be seen to support both de jure and de facto standards. 1 Introduction The current and next generation of distributed systems comprise some {{of the largest and most}} complex computing systems that have been considered. Developing such systems in a <b>multi-vendor</b> <b>environment</b> is an enormously demanding task and has naturally prompted the application of standardisation to the distributed systems domain. Standards have value in documenting both commonly accepted and hi [...] ...|$|E
40|$|Efficient use {{of limited}} radio {{resources}} (power, code space, spectrum, time) � Minimizing interference � Flexibility regarding services (Quality of Service, user behaviour) � Simple algorithms requiring small signalling overhead only � Stability and overload protection � Self adaptive in varying environments � Allow interoperability in <b>multi-vendor</b> <b>environments</b> Radio Resource Management algorithms control the {{efficient use of}} resources with respect to interdependent objectives: � cell coverage � cell capacity � quality of service 4 Slide 4 Context of Radio Resource Management System evaluation and standardisation activities on three levels: (E) -UTRA...|$|R
40|$|Programmable traffic now {{monitoring}} plays a {{very significant}} role in multi-service self-managing networks. The art of engineering programmable traffic now monitoring in such networks is a question requiring some research in order {{to come up with}} frameworks that include languages for programmable monitoring across <b>multi-vendor</b> <b>environments.</b> Inspired by the emerging monitoring paradigm dubbed On-Demand Monitoring (ODM) for multi-service self-managing networks, we developed a composition language for programmable traffic now monitoring in such networks. This paper presents the language, which is still evolving. It also provides an insight into the art of engineering programmable traffic flow monitoring in multi-service self-managing networks...|$|R
50|$|According to 3GPP TS 23.203, 9 QCI {{values in}} Rel-8 (13 QCIs Rel-12, 15 QCIs Rel-14) are {{standardized}} and associated with QCI characteristics {{in terms of}} packet forwarding treatment that the bearer traffic receives edge-to-edge between the UE and the P-GW. Scheduling priority, resource type, packet delay budget and packet error loss rate are the set of characteristics defined by the 3GPP standard {{and they should be}} understood as guidelines for the pre-configuration of node specific parameters to ensure that applications/services mapped to a given QCI receive the same level of QoS in <b>multi-vendor</b> <b>environments</b> as well as in roaming scenarios. The QCI characteristics are not signalled on any interface.|$|R
40|$|Open Distributed Processing (ODP) {{is a joint}} ITU/ISO {{standardisation}} {{framework for}} constructing distributed systems in a <b>multi-vendor</b> <b>environment.</b> Central to the ODP approach {{is the use of}} viewpoints for specification and design. Inherent in any viewpoint approach is the need to check and manage the consistency of viewpoints. In previous work we have described techniques for consistency checking, refinement, and translation between viewpoint specifications, in particular for LOTOS and Z/Object-Z. Here we present an overview of our work, motivated by a case study combining these techniques in order to show consistency between viewpoints specified in LOTOS and Object-Z...|$|E
40|$|A {{framework}} {{concept for}} {{design and implementation}} of medical workstations is described by (a) its underlying principles, (b) the handlers provided by the concept, (c) the available data structures and (d) the graphical user interface (GUI). The design principle takes care of a modular approach both for the framework and for the applications. The GUI provides a coherent look and feel for applications based on toolkits for displaying data objects and application control. The data handler allows management of n-dimensional data matrices in a <b>multi-vendor</b> <b>environment,</b> whereas the parameter handler {{takes care of the}} data object description. An implementation of a medical workstation exploiting the framework concept is presented...|$|E
40|$|Nowadays, the {{large-scale}} deployment of electronic health record systems and eHealth services {{has to face}} with a real <b>multi-vendor</b> <b>environment.</b> Even if each manufacturer supports an existing standard for communication and storage of ECG data, the large number of co-existing ECG standards is a major problem. In this direction, an online service operating as a gateway between SCP-ECG, the European standard for communication and storage of resting ECGs, and the DICOM waveform standard (Supplement 30), a common format for the communication of time series data including vital signs and ECGs, has been developed. The open availability of this service in the OpenECG portal is expected to facilitate digital ECG interoperability and contribute to the harmonization of ECG standards...|$|E
40|$|New {{content and}} service {{providers}} emerge every day. Each player offers new software components or services {{to support their}} technology. In these <b>multi-vendor</b> <b>environments</b> there is a genuine need for integration and interoperability. Integration and interoperability is a first step, once this is achieved components can seamlessly use services from different providers, {{and that is when}} service policies come into play. A policy mechanism allows fine grained control over the service usage. The OSGi Service Platform allows seamless integration of components and services but lacks a well defined mechanism for dynamic service policy management. Two approaches are presented for enhancing the OSGi Service Platform with policies. The first approach extends the platform while the second one adapts the plug-in components. Finally they are compared and evaluated against multiple requirements; usability, performance, transparency and backward compatibility...|$|R
40|$|A {{network model}} is a {{fundamental}} part of a network management solution. Traditional network models have provided views with static behavior and limited state of the network components that they represent. This paper presents an alternative approach to the creation and maintenance of network models that relies {{on the use of}} mobile agents and the principle of delegation. In the intelligent network model proposed, behavior and state are part of the model and both may be dynamically updated. A mobile code environment being used to support the research is briefly described. 1 INTRODUCTION The telecommunication networks that are in service today are usually conglomerates of heterogeneous, very often incompatible, <b>multi-vendor</b> <b>environments.</b> Management of such networks is a nightmare for a network operator who has to deal with the proliferation of human-machine interfaces and interoperability problems. Legacy network management systems are very strongly rooted in the client/server model of d [...] ...|$|R
40|$|This report {{describes}} the different implementations {{of the the}} Comandos platform. This report is published as Chapter 10. of The Comandos Distributed Application Platform Cahill, V., Balter, R., Harris, N. and Rousset de Pina, X. (Eds.), Springer-Verlag, Berlin, 1993. Document No. TCD-CS- 93 - 32 A strategic result of the Comandos project is the implementation and demonstration {{of a number of}} operational prototypes of the Comandos virtual machine, thus proving its feasibility in <b>multi-vendor</b> <b>environments.</b> Two basic approaches to the implementation of the platform were considered in the framework of the project: ffl The first approach consisted of implementing the virtual machine as a guest layer on top of Unix, without any modification to the Unix kernel. One such implementation, Amadeus, was designated as the reference platform for the project. Therefore it was the basis for the integration of the numerous system components, application services and management tools developed througho [...] ...|$|R
40|$|Introduction of new hard- and {{software}} techniques like Multi-Dectector Computed Tomography (MDCT) and 3 D imaging has put new {{demands on the}} Picture Archiving and Communications System (PACS) environment within the radiology department. The daily use of these new techniques requires a good integration of these techniques within the PACS environment. Requirements should {{be made for the}} accessibility (ease and speed) of the large amounts of data and for the availability of 3 D imaging. We feel that with good system integration of a <b>multi-vendor</b> <b>environment</b> these requirements can be met. This resulted in the environment proposed in this paper, which is installed at our institution. (C) 2003 Published by Elsevier Science B. V...|$|E
40|$|As {{organizations}} are increasingly outsourcing interdependent IT and business services to multiple vendors, {{the issue of}} knowledge integration between client and multiple vendors is becoming of high relevance today. This paper explores the antecedents and mechanisms which facilitate the success of knowledge integration across multiple stakeholders in multisourcing and the outcomes of successful knowledge integration in this context. The paper develops a conceptual framework of knowledge integration in the multisourcing arrangements, based on a detailed review of current literature on knowledge integration and applying it to the <b>multi-vendor</b> <b>environment.</b> This paper concludes by calling for further empirical study to examine the integrative framework of the key antecedents, mechanisms and consequences of knowledge integration in the multisourcing arrangements...|$|E
40|$|Abstract:- In {{response}} to major {{trends in the}} telecommunications market today and under influence of the emerging distributed computing technology the telecommunications industry is embracing distributed object platforms as a means enabling the successful participation in the open global services market of the foreseen era with new and advanced service offerings under increasing competition in a <b>multi-vendor</b> <b>environment.</b> In this realm, this paper presents an attempt to evaluate the performance of DCOM and CORBA under conditions which are common in telecommunications services engineered as distributed object applications. Finally, after the examination of important issues regarding the DCOM remoting architecture, some conclusions are drawn. Key-words:- Distributed object platforms, DCOM, CORBA, new telecommunications services...|$|E
40|$|Abstract – In {{recent years}} {{software}} development design {{shifted from the}} art of crafting a home tailored solution {{to the art of}} component composition. These components are offered in various formats, such as software libraries (Java Archives,. NET Assemblies) or web services and are provided by many different vendors. In these <b>multi-vendor</b> <b>environments</b> there is a genuine need for integration and interoperability. Integration and interoperability is a first step, once this is achieved components can seamlessly use services from different providers, and that is when service policies come into play. A policy mechanism allows fine grained control over the service usage. The OSGi Service Platform is a service container which allows seamless integration of components and services but its service layer lacks a well defined mechanism for dynamic service policy management. Two approaches are presented for enhancing the service layer with policies. The first approach extends the platform while the second one adapts the plug-in components. Finally they are compared and evaluated against multiple requirements; usability, performance, transparency and backward compatibility...|$|R
50|$|AppViewX ADC+ {{provides}} role-based management, automation, and orchestration of <b>multi-vendor</b> ADC <b>environments</b> {{that serve}} mode 1 and mode 2 applications across data centers. It offers state-of-the-art management capabilities that {{map to the}} needs of application owners, network engineers, and network operations. It simplifies version upgrades and enables self-service capabilities to lines of business. ADC+ supports A10 Networks, Akamai, Amazon Web Services (ELB), Avi Networks, Brocade, Cisco, Citrix, F5 Networks, HAProxy, NGINX and Radware.|$|R
40|$|Middleware {{platforms}} are in {{widespread use}} for distributed systems. Their quality {{is key to}} the stability and interoperabilily in <b>multi-vendor</b> heterogeneous <b>environments.</b> It is the aim of the EC IST project CORVAL 2 to enhance the techniques used to validate the conformance of OMG's CORBA technology. The paper investigates testability aspects of CORBA ORBs and considers CORBA based systems both from a theoretical and practical view on testing. Test strategies are proposed and a conformance test suite presented...|$|R
40|$|Contemporary {{organizations}} rely on outsourcing {{for success}} in today’s competitive marketplace, and selecting a vendor is an important process as developing new products. Vendor selection {{is one of the}} most important decisions of purchasing function. As organizations become more dependent on vendors, the direct and the indirect consequences of poor decision-making become more severe. Literature shows many vendor evaluation models. In this paper we have proposed a vendor selection model using Integer Linear Programming (ILP) Model for multiproduct, <b>multi-vendor</b> <b>environment.</b> The contribution of this research lies in the implementation of this model as a customized decision support system according to the expectation of any company. The model is validated with a case study by implementing the model for Agricultural equipments whole sale company. Key word...|$|E
40|$|The {{purpose of}} this work is to propose an {{extension}} to SON of specific use cases within LTE networks. Current wireless networks have become more complex, due to a higher number of base stations, convergence of different technologies (GSM/UMTS/LTE), greater number of parameters available and a <b>multi-vendor</b> <b>environment.</b> It has been proven that SON is a handful resource for mobile operators to decrease costs and save time on dreary optimization tasks, reducing human interaction needed to optimize a network and ensuring quality targets are met. A set of practical use cases are presented, followed by the analysis and actions taken in order to solve them. These solutions are taken as an input for the proposal of automated processes using SON...|$|E
40|$|As {{a result}} of years of {{geometrical}} advances in underlying electronics and photonics technology, traditional efficiency and performance considerations (which have been dominant activities in telecommunications research) will play a somewhat diminished role in the future. Simultaneously we are accumulating multiple standards, protocols, and transmission media, proliferating a variety of user-oriented applications, and seeing cost-effective software implementations and hardware systems with enormous complexity. These trends imply that an increasing barrier to progress in telecommunications is not cost or efficiency, but managing the tremendous complexity of heterogeneous networks, media, terminals, and applications in a <b>multi-vendor</b> <b>environment.</b> More generally, while complexity management has been a traditional issue in software engineering, and later in integrated circuit design, for the future {{it will be an}} increasingly important issue in large- 2 scale system design. Our hypothesis [...] ...|$|E
40|$|The DMTF Common Information Model (CIM) is a {{conceptual}} information model for describing computing and business entities in Internet, enterprise and service provider environments. It provides a consistent definition {{and structure of}} data, using objectoriented techniques. The CIM Schema establishes a common conceptual framework that describes the managed environment. This white paper describes the CIM Policy Model, {{as defined by the}} DMTF Policy Working Group, for the CIM Schema Release 2. 7. In today's complex, <b>multi-vendor</b> <b>environments,</b> successful, scaleable management of service levels depends on the specification of unified, scaleably administered policies. These policies must then map to the configuration of multiple heterogeneous systems, devices, applications, and networks, for the purpose of policy enforcement. The resulting cooperation of these multiple managed entities produces aggregate behavior consistent with the desired policies, and which, in turn, enables the delivery of service at agreedupon levels. The CIM Policy Model is a key component in enabling application developers, network administrators, and policy administrators to represent and manage policy across a spectrum of technical domains, including networking, security, and system admin. Policy-related work in other DMTF working groups and standards bodies is also referenced in this paper...|$|R
5000|$|In addition, {{the idea}} that cyber-attacks can be stopped at the {{periphery}} of the network has become a fool's errand. In today's Circa 2020 computing environment and cyber-threat landscape, individuals as well as corporations have recognized the fact that (i) threats are often distributed in nature both in time and space, making detection extremely difficult, and (ii) the working assumption is not that you can prevent infections (the goal of 100% prevention is no longer practical), but rather, given that your [...] "system" [...] will be compromised, how quickly can you detect the breach and how do you minimize the impact of such an event? In the future, the basis of competition for security products and services will be the ability to provide early warnings and execute countermeasures that minimize damage from cyber-attackers. The problem is not about single or even multiple independent security devices each providing some amount of absolute protection. Rather, information from all your security products and services need to be correlated, scrutinized and transformed into wide-angle actionable information in order to minimize the most likely threats of damage by cyber-attackers in your specific enterprise environment, see Figure 3. We call this approach the “Fabric of Security.” It is a layered model that easily accommodates distributed deployment of security in <b>multi-vendor</b> <b>environments.</b>|$|R
40|$|This paper {{focuses on}} unique {{longitudinal}} research within a <b>multi-vendor</b> outsourcing <b>environment</b> in the European Defence Sector. It describes the unfolding relationship between vendors {{and a major}} defence organization as the vendors developed, implemented and then managed a human resource management (HRM) system. This paper examines the apparent paradox between the wide scale adoption of outsourcing and its relatively poor performance and outcomes. The research suggests this comes from a loose coupling between the rational logic of outsourcing practice and the interpretation and enactment by interest groups that is exaggerated by the imposition of fixed deadlines and strong contractual governance...|$|R
40|$|In {{response}} to major {{trends in the}} telecommunications market today and under influence of the emerging distributed computing technology the telecommunications industry is embracing distributed object platforms as a means enabling the successful participation in the open global services market of the foreseen era with new and advanced service offerings under increasing competition in a <b>multi-vendor</b> <b>environment.</b> In this realm, this paper presents an attempt to evaluate the performance of DCOM and CORBA under conditions which are common in telecommunications services engineered as distributed object applications. Finally, after the examination of important issues regarding the DCOM remoting architecture, some conclusions are drawn. Key-words: - Distributed object platforms, DCOM, CORBA, new telecommunications services 1 Introduction The telecommunications industry is currently facing a number of challenges imposed by changes in the telecommunications market. Deregulation, liberalis [...] ...|$|E
40|$|Today's {{enterprises}} are accepting networked {{systems as}} a fundamental part of their information technology strategy. The constant growth in {{quantity and quality of}} networked systems and the thereby arising problems concerning complexity, heterogeneity and diversity of components in a <b>multi-vendor</b> <b>environment</b> require a sophisticated management of resources. Increasingly the automation of such management is being demanded. In this paper we introduce an architecture for the integrated management of all resources in a networked system, i. e. application, system and network resources. The architecture uses domains as flexible and pragmatic means of grouping resources and of specifying management responsibility and authority boundaries. It maintains a clear distinction between management objectives and the resources being managed in order to provide an integrated view of the various tasks of management as well as an integrated and uniform view of the distributed and heterogeneous managed envir [...] ...|$|E
40|$|This paper {{describes}} {{a translation of}} full LOTOS into Z. A common semantic model is defined and the translation is proved correct {{with respect to the}} semantics. The motivation for such a translation is the use of multiple viewpoints for specifying complex systems defined by the reference model of the Open Distributed Processing (ODP) standardization initiative. Key words: Open Distributed Processing; Z; LOTOS; Consistency. 1 Introduction The aim {{of this paper is to}} support the use of FDTs within distributed system design by providing a translation between full LOTOS and Z. An important example of open object-based distributed systems is the Open Distributed Processing (ODP) Reference Model. The ODP standardization initiative is a natural progression from OSI, broadening the target of standardization from the point of interconnection to the end-to-end system behaviour. The objective of ODP [12] is to enable the construction of distributed systems in a <b>multi-vendor</b> <b>environment</b> through [...] ...|$|E
50|$|This setup was {{developed}} in all three operators co-operation under national Telecom technology coordination group FiCom, and it is world's first system where a fully functional co-operating ETSI TS 102 207 roaming service mesh was established in <b>multi-vendor</b> software <b>environment.</b> Another national feature is that mobile phone numbers are portable across the operators, and thus the phone number prefix does not identify the operator. To make things easy for the Application Providers (see ETSI TS 102 204), they can purchase service from {{any one of the}} Acquiring Entity service providers (mobile network operators), and reach all users.|$|R
50|$|C-RAN may {{be viewed}} as an {{architectural}} evolution of the above distributed base station system. It takes advantage of many technological advances in wireless, optical and IT communications systems. For example, it uses the latest CPRI standard, low cost Coarse or Dense Wavelength Division Multiplexing (CWDM/ DWDM) technology, and mmWave to allow transmission of baseband signal over long distance thus achieving large scale centralised base station deployment. It applies recent Data Centre Network technology to allow a low cost, high reliability, low latency and high bandwidth interconnect network in the BBU pool. It utilises open platforms and real-time virtualisation technology rooted in cloud computing to achieve dynamic shared resource allocation and support of <b>multi-vendor,</b> multi-technology <b>environments.</b>|$|R
50|$|VOSS-4-UC is a {{real-time}} automated {{unified communications}} and collaboration service delivery platform. It {{is a policy}} based platform that supports centralised creation and management of unified communications services and applications. VOSS works in <b>multi-vendor</b> and hybrid <b>environments,</b> and it supports {{both private and public}} cloud. It is designed to provide management and provisioning of unified communications and collaboration services for large enterprises and service providers or telecommunication networks.|$|R
