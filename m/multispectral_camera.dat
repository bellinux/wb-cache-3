168|110|Public
5|$|The {{second major}} {{instrument}} was the MKF-6M <b>multispectral</b> <b>camera,</b> which carried out Earth-resources observations. An improved {{form of a}} camera first tested on Soyuz 22, the camera captured an area of 165220kilometres with each image, down to a resolution of 20metres. Each image was captured simultaneously in six bands in 1200-frame cassettes, which required regular replacement due to the fogging effects of radiation. Salyut 6 also featured a KATE-140 stereoscopic topographic mapping camera with a focal length of 140millimetres, which captured images of 450450kilometres with a resolution of 50metres in the visible and infrared spectra, which could be operated either remotely or by the resident crews. The photographic capabilities of the station were, therefore, extensive, and the Soviet Ministry of Agriculture had planted a number of specifically selected crops at test sites to examine {{the capabilities of the}} cameras.|$|E
25|$|In 1997, Ramon was {{selected}} as a Payload Specialist. He was designated to train as prime for a space shuttle mission with a payload that included a <b>multispectral</b> <b>camera</b> for recording desert aerosol (dust). In July 1998, he reported for training at the Johnson Space Center, Houston, Texas, where he trained until 2003. He flew aboard STS-107, logging 15 days, 22 hours and 20 minutes in space.|$|E
25|$|Ilan Ramon was Israel's first astronaut. Ramon was {{the space}} shuttle payload {{specialist}} on board the fatal STS-107 mission of Space Shuttle Columbia, in which he and the six other crew members {{were killed in a}} re-entry accident over the southern United States. Ramon had been selected as a payload specialist in 1997 and trained at the Johnson Space Center, Houston, Texas, from 1998 until 2003. Among other experiments, Ramon was responsible for the MEIDEX project in which he was required to take pictures of atmospheric aerosol (dust) in the Mediterranean area using a <b>multispectral</b> <b>camera</b> designed to provide scientific information about atmospheric aerosols and the influence of global changes on the climate, and data for the Total Ozone Mapping Spectrometer (TOMS) and Moderate-Resolution Imaging Spectroradiometer (MODIS) instruments. Researchers from Tel Aviv University (TAU) were responsible for the scientific aspect of the experiment. The TAU team also worked with a US company, Orbital Sciences Corporation, to construct and test special flight instruments for the project.|$|E
40|$|An {{automated}} band selection algorithm {{suitable for}} real-time application with fixed filter <b>multispectral</b> <b>cameras</b> is presented for multispectral target detection. Fixed filter <b>multispectral</b> <b>cameras</b> collect all bands {{regardless of the}} background. Background adaptive band is {{the selection of a}} subset of the bands for target detection processing. Fixed filter systems typically include a small number of general-purpose bands. The bands are chosen to enhance targetbackground contrast but are not keyed to specific target features. In some situations it is unlikely that all bands contribute to target discrimination. Using only a subset of the available bands can decrease false alarms while maintaining target detection performance and reduced processing requirements. The advantages are demonstrated using six band multispectral data and two distinct background categories...|$|R
40|$|This review {{covers the}} optical design of passive remote sensing optical instruments. The review {{concentrates}} {{on the design of}} spaceborne <b>multispectral</b> <b>cameras</b> and imaging spectometers. The major designs that have been produced {{over the past ten years}} are discussed, and new designs for future imaging spectrometers are presented...|$|R
50|$|Hyperspectral {{and most}} <b>multispectral</b> <b>cameras</b> are {{expensive}} {{and difficult to}} operate, requiring a computer acquisition and laborious post-processing. Modified digital cameras with the proper filtering avail some limited spectral sensing for geology/mineralogy, agriculture and oceanographic purposes. Most consumer cameras retain the red, green and blue micro-filters, thus limiting their usefulness in scientific imaging.|$|R
5000|$|Regional Chamber: CCS <b>multispectral</b> <b>camera</b> with 200 m {{resolution}} ...|$|E
5000|$|Global House: <b>multispectral</b> <b>camera</b> CCD {{camera with}} 1.1 km {{resolution}} ...|$|E
50|$|EarlyBird-1 was {{launched}} for Earth Watch Inc. on December 24, 1997, from the Svobodny Cosmodrome by a Start-1 launch vehicle. It included a panchromatic camera with a 3 m resolution and a <b>multispectral</b> <b>camera</b> with a 15 m resolution. Early Bird 1 {{was the first}} commercial satellite to be launched from the Svobodny Cosmodrome.|$|E
50|$|Alsat-1B is an Algerian {{satellite}} {{operated by}} the Agence Spatiale Algerienne for agricultural and disaster monitoring. The contract for the mission was signed in July 2014. The satellite {{is based on the}} SSTL-100 bus. The satellite weighs 103 kg and carries an earth imaging payload with 12 m panchromatic imager and 24 m <b>multispectral</b> <b>cameras.</b>|$|R
40|$|The {{results from}} the severe storm {{experiment}} over Texas and Oklahoma are presented. Correlation of data, soil moisture, water temperature, and cloud characteristics were considered. The sensors {{used in this study}} were <b>multispectral</b> band <b>cameras,</b> <b>multispectral</b> band scanners, infrared spectrometers, radiometers, and scatterometers...|$|R
40|$|A {{guide for}} {{producing}} accurate multispectral results for earth resource applications is presented along with theoretical and analytical concepts {{of color and}} multispectral photography. Topics discussed include: capabilities and limitations of color and color infrared films; image color measurements; methods of relating ground phenomena to film density and color measurement; sensitometry; considerations {{in the selection of}} <b>multispectral</b> <b>cameras</b> and components; and mission planning...|$|R
50|$|In 1997, Ramon was {{selected}} as a Payload Specialist. He was designated to train as prime for a space shuttle mission with a payload that included a <b>multispectral</b> <b>camera</b> for recording desert aerosol (dust). In July 1998, he reported for training at the Johnson Space Center, Houston, Texas, where he trained until 2003. He flew aboard STS-107, logging 15 days, 22 hours and 20 minutes in space.|$|E
50|$|Panchromatic and <b>Multi{{spectral}}</b> <b>Camera</b> (PANMUX). This camera records {{images in}} four spectral bands: 0,51 - 0,73 µm (panchromatic); 0,45 - 0,52 µm (blue); 0,52 - 0,59 µm (green); 0,63 - 0,69 µm (red); 0,77 - 0,89 µm (near infrared), with 5m spatial resolution for the panchromatic band and 10m spatial {{resolution in the}} other bands. It has 60 km of ground swath.It is possible to operate this camera both on nadir and off-nadir.|$|E
50|$|Ilan Ramon was Israel's first astronaut. Ramon was {{the space}} shuttle payload {{specialist}} on board the fatal STS-107 mission of Space Shuttle Columbia, in which he and the six other crew members {{were killed in a}} re-entry accident over southern Texas. Ramon had been selected as a Payload Specialist in 1997 and trained at the Johnson Space Center, Houston, Texas, from 1998 until 2003, for a mission with a payload that included a <b>multispectral</b> <b>camera</b> for recording desert aerosol (dust).|$|E
40|$|The article {{describes}} the experience of field biogeographic studies in the natural reserve "Belogorie" {{with the use of}} UAV in autumn, winter and spring seasons. Particular emphasis is placed on the zoogeographical problems. Also, the authors analyze the international experience of UAV’s use in geographical research and give suggestions for further development of biogeographic studies using thermal, <b>multispectral</b> <b>cameras</b> and gas analyzers. </p...|$|R
40|$|Standard RGB cameras have {{broadband}} {{spectral sensitivity}} functions {{corresponding to the}} colors red (R), green (G) and blue (B). They do not capture the world's colors {{the same way that}} humans do. This is caused by the spectral sensitivity functions of RGB cameras {{on the one hand and}} of the three sorts of cones present in the human retina on the other hand. These two sets of spectral sensitivity functions are not linearly dependent and images acquired using RGB cameras thus cannot present high color accuracy, as stated by the Luther rule. Therefore, <b>multispectral</b> <b>cameras</b> are utilized for certain applications requiring high color accuracy like painting automobile parts, controlling print products, measuring and representing textiles or furniture for online shops, or archiving culture heritage. <b>Multispectral</b> <b>cameras</b> feature more color channels with optimized spectral sensitivity functions in order to sample the visible wavelength range more precisely and to capture the complete spectral distribution of a color stimulus. In this work, multispectral imaging is performed using a monochrome sensor and several different color filters that can be inserted into a filter wheel and are brought successively in front of the sensor. As a result, several images corresponding to different narrowband wavelength ranges are acquired and form together a spectrally sampled multispectral image. Transversal and longitudinal aberrations then appear, because the color filters have slightly different parameters (thicknesses, refraction indices and tilt angles). For a convenient acquisition of multispectral images, the optical system is not modified during the capture of the different color channels. These defaults are rather corrected after the acquisition by means of image processing. The first aim of this thesis is the complete analysis and correction of aberrations in multispectral imaging featurng filter wheel cameras. As a result, the image points in the different color channel match and the image is sharp in each color channel. The transversal aberrations are compared for narrowband color filters positioned in front or behind the objective lens. The chromatic aberrations are analyzed and described in a model that includes their underlying wavelength-dependency. The loss of sharpness caused by the correction of transversal aberrations is measured and compared to the longitudinal aberrations. A method for the compensation of longitudinal aberrations without any calibration of the imaging system is also proposed. The second aim of this thesis is the enhancement of multispectral imaging by finding new, innovative ways to use multispectral technology in order to gather more information about the acquired scene. Two methods are developed to perform stereo multispectral imaging. In the first system, two RGB cameras are utilized with two different color filters, which enables the acquisition of 6 color channels in only one shot. The second system is a goniometric measuring setup that enables the convenient measurement of an object under different illumination and viewing angles. To complement these two aims, a well-founded analysis of the measurement and estimation of spectral sensitivity of <b>multispectral</b> <b>cameras</b> is presented. Additionally, the color accuracy of the different <b>multispectral</b> <b>cameras</b> and imaging systems utilized in the thesis is compared...|$|R
40|$|International audienceSnapshot <b>multispectral</b> <b>cameras</b> {{that are}} {{equipped}} with filter arrays acquire a raw image that represents the radiance of a scene over the electromagnetic spectrum at video rate. These cameras require a demosaicing procedure to estimate a multispectral image with full spatio-spectral definition. Such a procedure is based on spectral correlation properties that are sensitive to illumination. In this paper, we first highlight the influence of illumination on demosaicing performances. Then we propose camera-, illumination-, and raw image-based normalisations that make demosaicing robust to illumination. Experimental results on state-of-the-art demosaicing algorithms show that such normalisations {{improve the quality of}} multispectral images estimated from raw images acquired under various illuminations...|$|R
50|$|QuickBird, {{launched}} on October 18, 2001, was DigitalGlobe's primary satellite until early 2015. It {{was built by}} Ball Aerospace, and launched by a Boeing Delta II. It is in a 450 km altitude, −98 degree inclination sun-synchronous orbit. An earlier launch attempt resulted {{in the loss of}} QuickBird-1. It included a panchromatic camera with a 60 cm resolution and a <b>multispectral</b> <b>camera</b> with a 2.4 m resolution. On January 27, 2015, QuickBird was de-orbited, exceeding her initial life expectancy by nearly 300%.|$|E
50|$|After the {{successful}} 27 September 1973 launch, the craft was maneuvered to a 326 x 344 km orbit {{on the second}} day in space, which later proved to be the standard orbit for the Salyut 4 space station. A <b>multispectral</b> <b>camera</b> in the orbital module was used in coordination with aircraft to photograph the Earth. It was reported that the intention of the camera was to survey crop and forest conditions The cosmonauts also utilised the Molniya 1 satellite to communicate with ground stations when out of range.|$|E
50|$|The {{second major}} {{instrument}} was the MKF-6M <b>multispectral</b> <b>camera,</b> which carried out Earth-resources observations. An improved {{form of a}} camera first tested on Soyuz 22, the camera captured an area of 165&times;220 kilometres with each image, down to a resolution of 20 metres. Each image was captured simultaneously in six bands in 1200-frame cassettes, which required regular replacement due to the fogging effects of radiation. Salyut 6 also featured a KATE-140 stereoscopic topographic mapping camera with a focal length of 140 millimetres, which captured images of 450&times;450 kilometres with a resolution of 50 metres in the visible and infrared spectra, which could be operated either remotely or by the resident crews. The photographic capabilities of the station were, therefore, extensive, and the Soviet Ministry of Agriculture had planted a number of specifically selected crops at test sites to examine {{the capabilities of the}} cameras.|$|E
40|$|Ocean dumping {{of waste}} {{materials}} {{is a significant}} environmental concern in the New York Bight. One of these waste materials, sewage sludge, was monitored in an experiment conducted in the New York Bight on September 22, 1975. Remote sensing over controlled sewage sludge dumping included an 11 -band multispectral scanner, fiver <b>multispectral</b> <b>cameras</b> and one mapping camera. Concurrent in situ water samples were taken and acoustical measurements were made of the sewage sludge plumes. Data were obtained for sewage sludge plumes resulting from line (moving barge) and spot (stationary barge) dumps. Multiple aircraft overpasses were made to evaluate temporal effects on the plume signature...|$|R
40|$|International audienceCultural {{heritage}} is increasingly put through imaging {{systems such as}} <b>multispectral</b> <b>cameras</b> and 3 D scanners. Though these acquisition systems are often used independently, they collect complementary information (spectral vs. spatial) used for the study, archiving and visualization of cultural heritage. Recording 3 D and multispectral data in a single coordinate system enhances the potential insights in data analysis. Wepresent {{the state of the}} art of such acquisition systems and their applications for the study of cultural her- itage. Wealso describe existing registration techniques that can be used to obtain 3 D models with multispec- tral texture and explore the idea of optically tracking acquisition systems to ensure an easy and precise registration...|$|R
40|$|The {{research}} project with the working title "Design {{and development of}} a low-cost modular Aerial Mobile Mapping System" was formed {{during the last year}} as the result from numerous discussions and considerations with colleagues from the HafenCity University Hamburg, Department Geomatics. The aim of the project is to design a sensor platform which can be embedded preferentially on an UAV, but also can be integrated on any adaptable vehicle. The system should perform a direct scanning of surfaces with a laser scanner and supported through sensors for determining the position and attitude of the platform. The modular design allows his extension with other sensors such as <b>multispectral</b> <b>cameras,</b> digital cameras or multiple cameras systems...|$|R
50|$|Ilan Ramon was Israel's first astronaut. Ramon was {{the space}} shuttle payload {{specialist}} on board the fatal STS-107 mission of Space Shuttle Columbia, in which he and the six other crew members {{were killed in a}} re-entry accident over the southern United States. Ramon had been selected as a payload specialist in 1997 and trained at the Johnson Space Center, Houston, Texas, from 1998 until 2003. Among other experiments, Ramon was responsible for the MEIDEX project in which he was required to take pictures of atmospheric aerosol (dust) in the Mediterranean area using a <b>multispectral</b> <b>camera</b> designed to provide scientific information about atmospheric aerosols and the influence of global changes on the climate, and data for the Total Ozone Mapping Spectrometer (TOMS) and Moderate-Resolution Imaging Spectroradiometer (MODIS) instruments. Researchers from Tel Aviv University (TAU) were responsible for the scientific aspect of the experiment. The TAU team also worked with a US company, Orbital Sciences Corporation, to construct and test special flight instruments for the project.|$|E
5000|$|The ASTP-class Soyuz 7K-TM {{spacecraft}} {{used was}} {{a variation of}} the post-Soyuz 11 two-man design, with the batteries replaced by solar panels enabling [...] "solo" [...] flights (missions not docking to one of the Salyut space stations). It was designed to operate, during the docking phase, at a reduced nitrogen/oxygen pressure of 10.2 psi, allowing easier transfers between the Apollo and Soyuz. Six ASTP-class Soyuz spacecraft were built in total, including the one used. Before the actual mission, two craft were launched unmanned as Kosmos satellites. The third was launched as the manned Soyuz 16 flight as a rehearsal in order to test the APAS docking mechanism. Another craft was used fully fueled as a [...] "hot backup" [...] at the launch site - later it was disassembled. And the sixth craft was available as a [...] "cold" [...] backup; it was later used on the last [...] "solo" [...] Soyuz flight in 1976, but with the APAS docking adapter replaced by the MKF-6 <b>multispectral</b> <b>camera.</b>|$|E
30|$|We {{must avoid}} {{over-exposed}} and under-exposed areas when shooting a {{scene with the}} <b>multispectral</b> <b>camera.</b>|$|E
40|$|The high {{infrared}} quantum yield, continuous absorption spectrum, {{and band}} edge tunability of colloidal quantum dots (QD) {{has opened up}} new opportunities to use luminescent down shifting for multispectral imaging in the infrared. We demonstrate a QD sensitized short wavelength infrared (SWIR) camera which is capable of UV-SWIR multispectral imaging. The application of <b>multispectral</b> <b>cameras</b> for UV tagging applications is demonstrated and the extension of this technology to the mid infrared spectral region is discussed. Massachusetts Institute of Technology. Institute for Soldier Nanotechnologies (W 911 NF- 07 -D- 0004) United States. Air Force Office of Scientific Research (FA 9550 - 11 -C- 0028) American Society for Engineering Education. National Defense Science and Engineering Graduate Fellowship (32 CFR 168 a...|$|R
40|$|Cartosat- 1 is {{the first}} Indian Remote Sensing {{satellite}} able to collect in-track high resolution stereo images with a 2. 5 m pixel size. Since Cartosat- 1 has no <b>multispectral</b> <b>cameras,</b> it was mainly developed for topographic mapping and Digital Terrain Model (DTM) generation. In {{the framework of the}} Cartosat- 1 Scientific Assessment Programme, the Politecnico di Milano University (Italy) evaluated as Co-Investigator the performances of the Cartosat- 1 satellite in the generation of DTMs from stereo-couples. This paper describes in detail the outcomes for the Mausanne les Alpilles (France) test site, with respect to existing standards and products actually used in France and also provides a comparison with the global Shuttle Radar Topography Mission’s DTM supplied by NASA and widely used in the remote sensing community...|$|R
40|$|Abstract—Imaging spectrometers measure {{electromagnetic}} energy scattered in their instantaneous field view in {{hundreds or thousands}} of spectral channels with higher spectral resolution than <b>multispectral</b> <b>cameras.</b> Imaging spectrometers are therefore often referred to as hyperspectral cameras (HSCs). Higher spectral resolution enables material identification via spectroscopic analysis, which facilitates countless applications that require identifying materials in scenarios unsuitable for classical spectroscopic analysis. Due to low spatial resolution of HSCs, microscopic material mixing, and multiple scattering, spectra measured by HSCs are mixtures of spectra of materials in a scene. Thus, accurate estimation requires unmixing. Pixels are assumed to be mixtures of a few materials, called endmembers. Unmixing involves estimating all or some of: the number of endmembers, their spectral signatures, and their abundances at each pixel. Unmixing is a challenging, ill-pose...|$|R
40|$|A <b>multispectral</b> <b>camera</b> is {{characterized}} by the spectral responses of its camera channels. This research optimizes these spectral sensitivities for a measurement sensor. The resulting <b>multispectral</b> <b>camera</b> is used to estimate the wavelength of nearly monochromatic light. Target of the optimization is to reduce the overall measurement uncertainty of the estimation. To this end, the Bayesian Experimental Design is used. Furthermore, an heuristic approach is proposed to efficiently calculate a nonlinear integral during optimization...|$|E
3000|$|A fourth case {{example in}} Fig. 12 (d) is the typical <b>multispectral</b> <b>camera</b> {{scenario}} for computer vision, where 8 bands in the visible and NIR (380 − 830 n [...]...|$|E
40|$|Simplified, a {{chromatic}} confocal triangulation CCT sensor encodes different surface heights {{by different}} wavelengths. A height {{is measured by}} determining the corresponding wavelength of the optical signal. The CCT sensor concept solves this task using a <b>multispectral</b> <b>camera,</b> which is a camera with multiple channels, each characterized by a different optical filter. To measure the wavelength with high precision, these filters need to be optimized. For this purpose a physical model is introduced, which describes the <b>multispectral</b> <b>camera.</b> Based on this model, merit functions are developed that cover two aspects: increased resolution and statistical uniqueness of a measurement. These merit functions {{can be used in}} a next step to optimize a set of filters...|$|E
40|$|There is an {{increasing}} trend in crop production management decisions in precision agriculture based on observation of high resolution aerial images from unmanned aerial vehicles (UAV). Nevertheless, there are still limitations in terms of relating the spectral imagery information to the agricultural targets. AggieAir™ is a small, autonomous unmanned aircraft which carries <b>multispectral</b> <b>cameras</b> to capture aerial imagery during pre-programmed flights. AggieAir enables users to gather imagery at greater spatial and temporal resolution than most manned aircraft and satellite sources. The platform has been successfully used {{in support of a}} wide variety of water and natural resources management areas. This paper presents results of an on-going research in the application of the imagery from AggieAir in the remote sensing of top soil moisture estimations for a large field served by a center pivot sprinkler irrigation system...|$|R
40|$|The {{main purpose}} of this {{publication}} is to present the current progress of the work {{associated with the use}} of a lightweight unmanned platforms for various environmental studies. Current development in information technology, electronics and sensors miniaturisation allows mounting <b>multispectral</b> <b>cameras</b> and scanners on unmanned aerial vehicle (UAV) that could only be used on board aircraft and satellites. Remote Sensing Division in the Institute of Aviation carries out innovative researches using multisensory platform and lightweight unmanned vehicle to evaluate the health state of forests in Wielkopolska province. In this paper, applicability of multispectral images analysis acquired several times during the growing season from low altitude (up to 800 m) is presented. We present remote sensing indicators computed by our software and common methods for assessing state of trees health. The correctness of applied methods is verified using analysis of satellite scenes acquired by Landsat 8 OLI instrument (Operational Land Imager) ...|$|R
40|$|The article {{presents}} {{the problem of}} methane detection using <b>multispectral</b> IR <b>camera.</b> The project of such camera and some theoretical calculations regarding the possibility of methane detection are presented. The calculation of optical path: “camera-cloud of methane–background ” were also shown. Verification of theoretical result {{will be made by}} laboratory measurement. Some result of methane detection will be reported in article. 1...|$|R
