163|76|Public
5|$|Applications of {{matrices}} {{are found}} in most scientific fields. In every branch of physics, including classical mechanics, optics, electromagnetism, quantum mechanics, and quantum electrodynamics, {{they are used to}} study physical phenomena, such as the motion of rigid bodies. In computer graphics, they are used to manipulate 3D models and project them onto a 2-dimensional screen. In probability theory and statistics, stochastic matrices are used to describe sets of probabilities; for instance, they are used within the PageRank algorithm that ranks the pages in a Google search. <b>Matrix</b> <b>calculus</b> generalizes classical analytical notions such as derivatives and exponentials to higher dimensions. Matrices are used in economics to describe systems of economic relationships.|$|E
2500|$|... {{in which}} [...] is a {{shorthand}} notation for a vector of partial derivatives {{with respect to}} the indicated variables (see for example <b>matrix</b> <b>calculus</b> for this denominator notation), and possibly time , ...|$|E
2500|$|Today special {{relativity}} {{is seen as}} an application of linear algebra, but at the time {{special relativity}} was being developed the field of linear algebra was still in its infancy. There were no textbooks on linear algebra as modern vector space and transformation theory, and the matrix notation of Arthur Cayley (that unifies the subject) had not yet come into widespread use. Cayley's <b>matrix</b> <b>calculus</b> notation was used by Minkowski (1908) in formulating relativistic electrodynamics, even though it was later replaced by Sommerfeld using vector notation. According to a recent source the Lorentz transformations are equivalent to hyperbolic rotations. However Varicak (1910) had shown that the standard Lorentz transformation is a translation in hyperbolic space ...|$|E
50|$|<b>Matrix</b> {{differential}} <b>calculus</b> {{is used in}} statistics, {{particularly for}} the statistical analysis of multivariate distributions, especially the multivariate normal distribution and other elliptical distributions.|$|R
50|$|His {{research}} interests include major contributions to <b>matrix</b> inequalities, <b>calculus</b> of <b>matrix</b> functions, means of matrices, and connections between harmonic analysis, geometry and matrix analysis.|$|R
50|$|Using {{the same}} {{technique}} as with Bayesian linear regression, we decompose the exponential term using a matrix-form of the sum-of-squares technique. Here, however, {{we will also}} {{need to use the}} <b>Matrix</b> Differential <b>Calculus</b> (Kronecker product and vectorization transformations).|$|R
5000|$|... is {{a useful}} {{shorthand}} (see <b>matrix</b> <b>calculus</b> for this notation). Holonomic constraints ...|$|E
5000|$|This {{is an easy}} {{problem in}} <b>matrix</b> <b>calculus,</b> and its {{solution}} is ...|$|E
5000|$|To {{differentiate}} {{with respect}} to η1, we need the following <b>matrix</b> <b>calculus</b> identity: ...|$|E
30|$|Since the {{function}} _ 1 ϕ _ 1 (a; 0;q,z) is analytic for all complex numbers a and z, the <b>matrix</b> functional <b>calculus</b> tells that the matrix function _ 1 ϕ _ 1 (a; 0;q,A) is also convergent for all complex number a {{and for all}} matrices A∈C^r× r.|$|R
5000|$|An {{algebraic}} proof, {{based on}} the variational interpretation of eigenvalues, has been published in Magnus' <b>Matrix</b> Differential <b>Calculus</b> with Applications in Statistics and Econometrics. [...] From the geometric point of view, B'AB {{can be considered as}} the orthogonal projection of A onto the linear subspace spanned by B, so the above results follow immediately.|$|R
40|$|A {{common problem}} in multivariate {{analysis}} {{is that of}} minimizing a scalar function [phi] of a positive semidefinite matrix A subject possibly to AX = 0. In this paper it is suggested to replace A by B'B, where B is allowed to vary freely, subject possibly to BX = 0. Positive semidefinite matrices maximum likelihood estimation <b>matrix</b> differential <b>calculus...</b>|$|R
5000|$|<b>Matrix</b> <b>calculus</b> is {{used for}} {{deriving}} optimal stochastic estimators, often involving the use of Lagrange multipliers. This includes the derivation of: ...|$|E
5000|$|In <b>matrix</b> <b>calculus,</b> Jacobi's formula {{expresses the}} {{derivative}} of the determinant of a matrix A {{in terms of}} the adjugate of A and the derivative of A.|$|E
5000|$|... {{in which}} [...] is a {{shorthand}} notation for a vector of partial derivatives {{with respect to}} the indicated variables (see for example <b>matrix</b> <b>calculus</b> for this denominator notation), and possibly time , ...|$|E
40|$|This paper derives {{the exact}} {{distribution}} of the Wald statistic for testing general linear restrictions on the coefficients in the multivariate linear model. This generalizes all previously known results including those for the standard F statistic in linear regression, for Hotelling's T^{ 2 } test and for Hotelling's generalized T_{ 0 }^{ 2 } test. Conventional classical assumptions of normally distributed errors and nonrandom exogenous variables are employed. <b>Matrix</b> fractional <b>calculus,</b> Wald statistic, distribution theory...|$|R
40|$|This {{invaluable}} book offers {{engineers and}} physicists {{working knowledge of}} a number of mathematical facts and techniques not commonly treated in courses in advanced calculus, but nevertheless extremely useful when applied to typical problems in many different fields. It deals principally with linear algebraic equations, quadratic and Hermitian forms, operations with vectors and <b>matrices,</b> the <b>calculus</b> of variations, and the formulations and theory of linear integral equations. Annotated problems and exercises accompany each chapter...|$|R
40|$|This paper extends earlier results, {{which were}} {{reported}} in [7], to include non null distributions. As in [7], attention is concentrated on the Wald statistic for testing general linear restrictions on the coefficients in the multivariate linear model. The {{results of the present}} paper encompass the null distributions derived in [7] and generalize all previously known results for such statistics as the standard regression F test and Hotelling's T^{ 2 } test. Wald statistic, noncentral quadratic forms, distribution theory, <b>matrix</b> fractional <b>calculus...</b>|$|R
5000|$|Since {{this is a}} {{quadratic}} expression, {{the vector}} which gives the global minimum may be found via <b>matrix</b> <b>calculus</b> by differentiating {{with respect to the}} vector b (using denominator layout) and setting equal to zero: ...|$|E
50|$|Later Schouten wrote Tensor Analysis for Physicists {{attempting}} {{to present the}} subtleties of various aspects of tensor calculus for mathematically inclined physicists. It included Paul Dirac's <b>matrix</b> <b>calculus.</b> He still used part of his earlier affinor terminology.|$|E
50|$|In quantum mechanics, the {{momentum}} operator is given by(see <b>matrix</b> <b>calculus</b> for the denominator notation) with appropriate domain. The eigenfunctions areand eigenvalues ħk. Soand {{we see that}} {{the momentum}} representation is related to the position representation by a Fourier transform.|$|E
40|$|This paper {{addresses}} {{the problem of}} the design of a precoder for multiple transmit antenna communication systems with spatially and temporally correlated fading channels. Using the theories of <b>matrix</b> differential <b>calculus,</b> the paper derives a precoder for unitary space-time codes that can exploit the spatio-temporal correlation in the time-varying fading channels. The design criterion is based on minimizing the mean square error of the channel estimates. Computer simulation results show that a significant performance gain can be achieved by using the designed precoder. <br /...|$|R
40|$|International audienceIn this paper, {{we propose}} a new model, the kernel Kalman Filter, to perform various {{nonlinear}} time series processing. This model {{is based on}} the use of Mercer kernel functions in the framework of the Kalman filter or linear dynamical systems. Thanks to the kernel trick, all the equations involved in our model to perform filtering, smoothing and learning tasks, only require <b>matrix</b> algebra <b>calculus</b> whilst providing the ability to model complex time series. In particular, it is possible to learn dynamics from some nonlinear noisy time series implementing an exact expectation-maximization procedure...|$|R
40|$|AbstractIf C is an {{invertible}} matrix in Cr × r, the coupled wave equation initial value problem utt = C 2 uxx, −∞ 0, u(x, 0) = f(x), and ut(x, 0) = g(x) for −∞ < x < ∞ is studied. A matrix D'Alembert formula for the closed form {{solution of the}} coupled wave equation is given. The approach {{is based on the}} Fourier transform, the holomorphic <b>matrix</b> functional <b>calculus</b> and some elements of complex variable functions. For the scalar case, the proposed D'Alembert formula coincides with the classical one...|$|R
50|$|This {{means that}} the trace of a product of {{matrices}} functions similarly to a dot product of vectors. For this reason, generalizations of vector operations to matrices (e.g. in <b>matrix</b> <b>calculus</b> and statistics) often involve a trace of matrix products.|$|E
50|$|The final {{example is}} one where {{integration}} would be extremely difficult. This {{is the case of}} the Wishart distribution, which is defined over matrices. Even taking derivatives is a bit tricky, as it involves <b>matrix</b> <b>calculus,</b> but the respective identities are listed in that article.|$|E
5000|$|The rotated {{quaternion}} [...] {{needs to}} be differentiated {{with respect to the}} rotating quaternion , when the rotation is estimated from numerical optimization. The estimation of rotation angle is an essential procedure in 3D object registration or camera calibration. The derivative can be represented using the <b>Matrix</b> <b>Calculus</b> notation.|$|E
40|$|Thesis {{submitted}} {{were created}} during my post - graduate {{study at the}} Masaryk University of Brno. In the work there are some applications of matrices analysis mentioned (it {{is one of the}} subject of interests of my supervisor Prof. RNDr. Ladislav Skula, DrSc.) The introductory part of the work deals with historical background of studied theory together with basic information about all chapters. In the first chapter some basic concepts of the theory of structures, hyperstructures and matrices are summarised. In the second chapter the solution of the matrices equation A=BC-CB over the Galois points for quadrate matrices (n= 3 and n= 4) are described. The problem was solved both theoretically and numerically on PC. Third chapter deals with construction of the set of mutually commutable matrices solved for n= 2 and 3. The matrix of homogeneous system for arbitrary natural numbers is presented. By trying to solve the matrix we obtained elements mutually commutable matrices mentioned above. Fourth chapter is devoted to complex matrices A+iB, where A,B are quadrate real matrices n-th row with positive elements. Two hyperoperations defined on monounary algebra(Mreg,d) and their properties are mentioned also. The application of <b>matrices</b> <b>calculus</b> in the theory of linear regression is discussed in the fifth chapter together with solution of two examples. Available from STL Prague, CZ / NTK - National Technical LibrarySIGLECZCzech Republi...|$|R
40|$|The Workshop CIMPA-UNESCO "Orthogonal {{families}} and semigroups in analysis and probability 2 ̆ 72 ̆ 7 {{was held in}} 2006 in Mérida, Venezuela and was organized with the collaboration of three Venezuelian universities(UCV, USB and ULA). The objective of the Workshop was to present the modern theory of operator semigroups, related to polynomial orthogonal expansions. This theory comprises nowadays a vast body of knowledge and has interconnections with several other areas, including harmonic analysis, probability, random <b>matrices,</b> stochastic <b>calculus</b> and control theory. The chapters of this volume originate from the lectures of this Workshop and they stress the interplay of all these domains...|$|R
5000|$|His book on Generalized multivariate {{analysis}} (with Zhang) has extensive results on {{multivariate analysis}} for elliptical distributions, to which T. W. Anderson refers readers of his An introduction to multivariate statistical analysis (3rd ed., 2003). The Fang and Zhang monograph used <b>matrix</b> differential <b>calculus.</b> One of Generalized multivariate analysiss innovations was its {{extensive use of}} the multilinear algebra, particularly of the Kronecker product and of vectorization, according to Kollo and von Rosen. Fang and Zhangs Generalized multivariate analysis was honored as a [...] "most excellent book in China" [...] by the Government Information and Publication Administration.|$|R
5000|$|An {{alternative}} derivation of {{the maximum}} likelihood estimator can be performed via <b>matrix</b> <b>calculus</b> formulae (see also differential of a determinant and differential of the inverse matrix). It also verifies the aforementioned fact about the maximum likelihood estimate of the mean. Re-write the likelihood in the log form using the trace trick: ...|$|E
5000|$|... all treated on {{the same}} footing as an -component vector field, and use {{whichever}} form is convenient. All the above notations have a common compact notation [...] The calculus of such vector fields is vector calculus. For more on the treatment of row vectors and column vectors of multivariable functions, see <b>matrix</b> <b>calculus.</b>|$|E
50|$|In research, Mueller {{measured}} {{luminous intensity}} and studied polarization of light. He wrote several papers on Rochelle salts. The development of his <b>matrix</b> <b>calculus</b> was initially classified {{but he made}} an exposition to the Optical Society of America in 1948. His student Nathan Grier Park III wrote a thesis, Matrix Optics expounding the method.|$|E
40|$|Features aspects and {{solutions}} of problems of linear vibrating systems with {{a finite number}} of degrees of freedom. Starts with development of necessary tools in matrix theory, followed by numerical procedures for relevant matrix formulations and relevant theory of differential equations. Minimum of mathematical abstraction; assumes a familiarity with <b>matrix</b> theory, elementary <b>calculus.</b> 1966 edition...|$|R
40|$|Abstract. In {{this paper}} we {{consider}} {{a new model}} of multivariate lognormal diffusion pro-cess with a vector of exogenous factors such that each component exclusively affects the respective endogenous variable of the process. Starting from the Kolmogorov differential equations and Ito’s stochastics equation of this model, its transition probability density is obtained. A discrete sampling of the process is assumed and the associated conditioned likelihood is calculated. By using <b>matrix</b> differential <b>calculus,</b> the maximum likelihood matrix estimators are obtained and expressed in a computationally feasible form. This model, an extension of previously studied lognormal diffusion processes ([1],[2],[3]), ex-tends the possibility of applications of lognormal dynamic modelling in Economics, Pop...|$|R
40|$|Summary. The {{restoration}} of scalar-valued images via minimization of an energy functional is a well-established technique in image processing. Recently also higher-order methods have proved their advantages in edge preserving image denoising. In this paper, we transfer successful techniques like the minimization of the Rudin-Osher-Fatemi functional and the infimal convolution to matrix fields, where our functionals couple the different matrix channels. For the numerical computation we use second-order cone programming. Moreover, taking the operator structure of matrices into account, we consider a new operator-based regularization term. Using <b>matrix</b> differential <b>calculus,</b> we deduce the corresponding Euler-Lagrange equation {{and apply it}} for the numerical solution by a steepest decent method. ...|$|R
