19|24|Public
25|$|In the Nintendo GameCube version, {{they took}} {{advantage}} of the system's fast CPU to achieve a higher frame rate, and added more polygons to characters, especially Jango, who has roughly twice the polygon count on GameCube. The GameCube's texture compression allowed them to use high-resolution textures. Texture compression also allowed for improved color variance on textures. <b>Mip</b> <b>mapping</b> support across the board on all textures helped provide a rich and consistent environment. They exploited additional memory to improve load times. They implemented projected shadows on all the characters and an increased draw distance to allow for vista views.|$|E
25|$|Star Wars: Bounty Hunter began {{life when}} LucasArts {{was asked to}} make an Episode II-based game which {{featured}} Jango Fett. In March 2001 game design documents were presented, and development began shortly after. The PlayStation 2 and Nintendo GameCube versions of the game have different custom in-house graphics engines, each designed specifically {{to take advantage of}} the two platforms' unique strengths and work around their unique limitations, but the core game engine is identical. In the PS2 version they took advantage of both vector unit (VU) chips to drive the graphics to maximum performance. The DMA bandwidth was taken advantage of to use a high number of textures. There is full-screen antialiasing and texture <b>mip</b> <b>mapping</b> support. They used the second VU1 chip to handle all the character skinning and VU0 to handle all the skeletal animation transforms. Which enabled dozens of characters to be on-screen without bogging down the frame rate. They had 10 individually optimized rendering loops on VU1 to speed up the rendering process. Their PS2 graphics engine could move 10,000,000 triangles per second, and adding the gameplay, collision, logic, textures, sound would go down accordingly to around 30,000 to 50,000 triangles per frame, all at an average frame rate of 30 frames per second.|$|E
50|$|From {{this point}} forth, {{it is assumed}} the reader is {{familiar}} with <b>MIP</b> <b>mapping.</b>|$|E
50|$|Each {{anisotropic}} filtering probe {{is often}} {{in itself a}} filtered <b>MIP</b> <b>map</b> sample, which adds more sampling to the process. Sixteen trilinear anisotropic samples might require 128 samples from the stored texture, as trilinear <b>MIP</b> <b>map</b> filtering needs to take four samples times two MIP levels and then anisotropic sampling (at 16-tap) needs to take sixteen of these trilinear filtered probes.|$|R
5000|$|In layman's terms, {{anisotropic}} filtering {{retains the}} [...] "sharpness" [...] of a texture normally lost by <b>MIP</b> <b>map</b> texture's attempts to avoid aliasing. Anisotropic filtering {{can therefore be}} said to maintain crisp texture detail at all viewing orientations while providing fast anti-aliased texture filtering.|$|R
40|$|In this master's thesis I'm {{engaged in}} {{problematic}} of texture mapping in ray tracing. Ray tracing is shortly {{described in the}} beginning. Texture mapping methods are described then, solid textures first and 2 D textures follow. Implementation of <b>MIP</b> <b>map</b> method is deeply described in next chapters. The results are evaluated at the end...|$|R
5000|$|Additional features: bump mapping, fog, alpha-blending (transparency), <b>mip</b> <b>mapping</b> (polygon-texture auto switch), tri-*linear filtering, anti-aliasing, {{environment}} mapping, and specular effect ...|$|E
5000|$|Other {{options include}} blurry {{transparency}} and reflectivity, instance rendering, shadows, soft shadows, <b>MIP</b> <b>mapping,</b> specular highlight, anti-matter effects and stereoscopic rendering.|$|E
50|$|Bilinear and trilinear texture {{filtering}}, <b>MIP</b> <b>Mapping,</b> alpha blending, {{and video}} texture mapping. Trilinear filtering is full-speed on ViRGE/DX and later, termed 'SmartFilter' technology.|$|E
5000|$|The {{anisotropic}} filtering method {{most commonly}} implemented on graphics hardware is {{the composition of}} the filtered pixel values from only one line of <b>MIP</b> <b>map</b> samples. In general the method of building a texture filter result from multiple probes filling a projected pixel sampling into texture space is referred to as [...] "footprint assembly", even where implementation details vary.|$|R
50|$|Because {{their data}} access {{patterns}} are well-defined, texture decompression may be executed on-the-fly during rendering {{as part of}} the overall graphics pipeline, reducing overall bandwidth and storage needs throughout the graphics system. As well as texture maps, texture compression may also be used to encode other kinds of rendering map, including bump maps and surface normal maps. Texture compression may also be used together with other forms of map processing such as <b>MIP</b> <b>maps</b> and anisotropic filtering.|$|R
40|$|This work {{presents}} an approximate algorithm for computing light scattering within homogeneous participating environments in screen space. Instead of simulating the full global illumination in participating media we model the scattering process by a physically-based point spread function. To do this efficiently we apply the point spread function by performing a discrete hierarchical convolution in a texture <b>MIP</b> <b>map.</b> We solve {{the main problem}} of this approach, illumination leaking, by designing a custom anisotropic incremental filter. Our solution is fully parallel, runs in hundreds of frames-per-second for usual screen resolutions and is directly applicable in most existing 2 D or 3 D rendering architectures...|$|R
50|$|The Ticket to Ride (Imagine-3) {{supported}} WRAM {{and both}} the AGP and PCI buses, had a 3D floating point setup engine, bilinear filtering and perspective correction, Gouraud shading, alpha blending, interpolated fogging, specular lighting, double and triple display buffering, 16-, 24- and 32-bit Z-buffering, MPEG-1 and MPEG-2, and hardware <b>MIP</b> <b>mapping.</b>|$|E
50|$|The Ticket to Ride IV {{included}} an integrated 250 MHz RAMDAC, support {{for up to}} 32 MiB SDRAM, full scene anti-aliasing, per pixel fog, specular, and alpha effects, 10-level detail per pixel <b>MIP</b> <b>mapping,</b> bilinear and trilinear filtering, 8 bits per texel, 8 KB on-chip texture cache, hardware MPEG-1 and MPEG-2, and a full IEEE 754 floating point pipeline 3D rendering setup engine.|$|E
50|$|If we were {{to explore}} a more {{approximate}} anisotropic algorithm, RIP mapping, as an extension from <b>MIP</b> <b>mapping,</b> we can understand how anisotropic filtering gains so much texture mapping quality. If we need to texture a horizontal plane which is at an oblique angle to the camera, traditional MIP map minification would give us insufficient horizontal resolution due to the reduction of image frequency in the vertical axis. This is because in <b>MIP</b> <b>mapping</b> each MIP level is isotropic, so a 256 × 256 texture is downsized to a 128 × 128 image, then a 64 × 64 image and so on, so resolution halves on each axis simultaneously, so a MIP map texture probe to an image will always sample an image that is of equal frequency in each axis. Thus, when sampling to avoid aliasing on a high-frequency axis, the other texture axes will be similarly downsampled and therefore potentially blurred.|$|E
40|$|We {{introduce}} a tiled 3 D <b>MIP</b> <b>map</b> representation of global illumination data. The representation is an adaptive, sparse octree with a “brick ” at each octree node; each brick consists of 8 3 voxels with sparse irradiance values. The representation {{is designed to}} enable efficient caching. Combined with photon tracing and recent advances in distribution ray tracing of very complex scenes, {{the result is a}} method for efficient and flexible computation of global illumination in very complex scenes. The method can handle scenes with many more textures, geometry, and photons than could fit in memory. We show an example of a CG movie scene that has been retrofitted with global illumination shading using our method. 1...|$|R
40|$|International audienceModern {{games and}} {{applications}} use {{large amounts of}} texture data; the number and the resolution of textures also continues to grow quickly. However, the amount of available graphics memory is not growing at the same pace and, in addition to textures, GPU memory is also used for complex post-processing effects and lighting calculations. Virtual Texture Mapping (VTM) is a technique {{to reduce the amount}} of graphics memory required for textures to a point where it is only dependent on the screen resolution: for a given viewpoint we only keep the visible parts of the textures in graphics memory, at the appropriate <b>MIP</b> <b>map</b> level. In this chapter, we investigate how to implement a fully functional VTM system...|$|R
40|$|Molecular {{interaction}} potential (<b>MIP)</b> <b>maps</b> are {{a powerful}} tool to develop structure-activity relationships {{of a series of}} compounds. In the present study we have studied the effect of molecular polarization on the description of the toxicity of a series of dioxins and benzofurans using their MIPs. Specifically, we have used principal component analysis in an exploratory way to understand the common structural features that describe the toxicity of these molecules through the analysis of their MIPs and each of their components, i. e.; molecular electrostatic and polarization potentials. Moreover, we have developed a predictive model using PLS that permits to evaluate the toxicity of compounds belonging to any of the families of compounds studied in the present work {{on the basis of their}} molecular electrostatic and interaction potentials. Peer ReviewedPreprin...|$|R
50|$|The game {{features}} high-resolution 16-bit {{color depth}} graphics. The object modeling {{takes into account}} physics such as gravity, reflection, and wind. The game is true 3D with movement in six degrees of freedom. Optional Fast Phong- and Gouraud shading, perspective mapping, light-sourcing, real-time shadows, bump mapping, z-buffering, <b>MIP</b> <b>mapping</b> combine with multiple movable-point and spotlight light sources, view ports, and cameras to make the graphics an outstanding visual treat. Weather effects and underwater sequences add to the effects.|$|E
50|$|The V1000 {{was fairly}} popular {{when it was}} launched. At least four {{companies}} sold Vérité boards: the Creative Labs 3D Blaster PCI, the Sierra Screamin' 3D, the Canopus Total 3D, and the Intergraph Reactor (later renamed Intense 3D 100). A handful of software titles shipped with V1000 support. As the ATI Rage/3D, S3 Virge/3D, and Matrox Mystique delivered 3D/graphics of questionable benefit, id Software's vQuake and Eidos's Tomb Raider were influential in fueling consumer interest in 3D/gaming hardware. The Vérité (and Voodoo) ports added 16-bit color rendering, bilinear filtering, per-polygon <b>MIP</b> <b>mapping,</b> and edge anti-aliasing to the game's 3D visuals. Released in time for Christmas 1996, both vQuake and Tomb Raider demonstrated the V1000's 3D/hardware to be both faster and better-looking than software rendering on even the most powerful host CPU.|$|E
40|$|<b>MIP</b> <b>mapping</b> is {{a common}} method used by {{graphics}} hardware to avoid texture aliasing. In many situations, <b>MIP</b> <b>mapping</b> over-blurs in one direction to prevent aliasing in another. Anisotropic texturing reduces this blurring by allowing differing degrees of filtering in different directions, but is not as common in hardware due to the implementation complexity of current techniques. We present a new algorithm that enables anisotropic texturing on any current MIP map graphics hardware supporting MIP level biasing, available in OpenGL 1. 2 or through the GL EXT texture lod bias or GL SGIX texture lod bias OpenGL extensions. The new algorithm computes anisotropic filter footprint parameters per vertex. It constructs the anisotropic filter out of several MIP map texturing passes or multi-texture lookups. Each lookup uses MIP level bias and perturbed texture coordinates to place one probe used to construct the more complex filter profile. CR categories and subject descriptors: I. 3. 3 [Computer Graphics]: Picture/Image generation [...] - Display algorithms; I. 3. 7 [Computer Graphics]: Three-Dimensional Graphics and Realism [...] - Color, shading, shadowing and texture. Keywords: Graphics Hardware, Interactive Rendering, MultiPass Rendering, Anisotropic Texturing, Footprint assembly. # email:{olano,shm,dorbie@sgi. com}...|$|E
40|$|Scientific Session - Advanced Fetal & Pediatric CNS ImagingThis study aims to {{determine}} the differences of deep medullary venous between hypoxic-ischemic encephalopathy (HIE) and normal neonates by a quantitative method. 7 normal and 20 HIE neonates were examined by using an ESWAN (enhanced T 2 * weighted angiography) sequence. In the minimal intensity projection (<b>mIP)</b> <b>map,</b> 3 regions of interest (ROIs) were defined, including deep medullary veins in bilateral brain regions of centrum semiovale, deep white matters of frontal lobe and temporal-occipital junction. Vein-ROI ratio (VRR=vein area/ROI area) was calculated in these ROIs respectively. Results showed increased VRR values in deep medullary veins in HIE group versus normal group (p< 0. 001), which indicated that VRR may be a marker for the degree of hypoxia in neonates with HIE. This quantitative method is potentially valuable at depicting venous prominence for predicting degree of injury after HIE. (Abstract by ISMRM) link_to_OA_fulltex...|$|R
40|$|The {{focus of}} this thesis is the {{real-time}} rendering of participating media, such as fog. This is an important problem, because such media significantly influence {{the appearance of the}} rendered scene. It is also a challenging one, because its physically correct solution involves a costly simulation of {{a very large number of}} light-particle interactions, especially when considering multiple scattering. The existing real-time approaches are mostly based on empirical or single-scattering approximations, or only consider homogeneous media. This work briefly examines the existing solutions and then presents an improved method for real-time multi- ple scattering in quasi-heterogeneous media. We use analytically integrable den- sity functions and efficient <b>MIP</b> <b>map</b> filtering with several techniques to minimize the inherent visual artifacts. The solution has been implemented and evaluated in a combined CPU/GPU prototype application. The resulting highly-parallel method achieves good visual fidelity and has a stable computation time of only a few milliseconds per frame...|$|R
40|$|Figure 1 : We {{reproduce}} the blurring and colour shifts in participating media such as sea {{water from a}} single HDR image and its depth buffer (right) in real-time (4. 3 ms for the scattering, 40. 2 ms framebuffer generation (HDR, PCF soft shadows, SSAO), 2048 × 1024 resolution). This work presents an approximate algorithm for computing light scattering within homogeneous participating environments in screen space. Instead of simulating the full global illumination in partici-pating media we model the scattering process by a physically-based point spread function. To do this efficiently we apply the point spread function by performing a discrete hierarchical convolution in a texture <b>MIP</b> <b>map.</b> We solve the main problem of this approach, illumination leaking, by designing a custom anisotropic incremental filter. Our solution is fully parallel, runs in hundreds of frames-per-second for usual screen resolutions and is directly applicable in most existing 2 D or 3 D rendering architectures...|$|R
40|$|The {{standard}} <b>MIP</b> <b>mapping</b> technique halves {{the resolution}} of textures for each level of the MIP chain. In this thesis the bits per pixel(bpp) is reduced as well. Normal maps are generally used with MIP maps, and todays industry standard for these are usually 24 bpp. The reduction is simulated as there is currently no support for the lower bpp in GPU hardware. Objectives: To render images of normal mapped objects with decreasing bpp for each level in a MIP chain and evaluate these against the standard <b>MIP</b> <b>mapping</b> technique using a subjective user study and an objective image comparison method. Methods: A custom software is implemented to render the images with quantized normal maps manually placed in a MIP chain. For the subjective experiment a 2 AFC test is used, and the objective part consists of a PDIFF test for the images. Results: The results indicate that as the MIP level is increased and the bpp is lowered, users can increasingly see a difference. Conclusions: The results show that participants can see a difference as the bpp is reduced, which indicates normal mapping as not suitable for this method, however further study is required before this technique can be dismissed as an applicable metho...|$|E
40|$|The {{anisotropic}} filtering {{offered by}} current graphics hardware {{can be employed}} to apply motion blur to textures. The solution proposed here uses a standard texture together with a vertex and a pixel shader acting on a mesh with augmented vertex data. Our method generalizes the usual spatial anisotropic <b>MIP</b> <b>mapping</b> to also include temporal effects. It automatically processes any time series of affine 3 D transformations of an object. The application fields include animations containing 2 D lettering as well as objects such as spoke wheels that are cookie-cut from large polygons using an alpha channel. We present two different implementations of the technique. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 7 [Computer Graphics]: Animation 1...|$|E
40|$|We {{present a}} cache-based {{approach}} to handling the difficult problem of performing visually acceptable texture resampling/filtering while ray-tracing. While many good {{methods have been}} proposed to handle the error introduced by the ray-tracing algorithm when sampling in screen space, handling this error in texture space has been less adequately addressed. Our solution is to introduce the Convolution Mask Approximation Module (CMAM). The CMAM locally approximates the convolution region in texture space {{as a set of}} overlapping texture triangles by using a texture sample caching system and ray tagging. Since the caching mechanism is hidden within the CMAM, the ray-tracing algorithm itself is unchanged while achieving an adequate level of texture filtering (area sampling as opposed to point sampling/interpolation in texture space). The CMAM is easily adapted to incorporate prefiltering methods such as <b>MIP</b> <b>mapping</b> and summed-are...|$|E
40|$|Successful {{treatment}} {{planning in}} radiation therapy depends {{in part on}} understanding the spatial relationship between patient anatomy {{and the distribution of}} radiation dose. We present several visualizations based on volume rendering that offer potential solutions to this problem. The visualizations employ region boundary surfaces to display anatomy, polygonal meshes to display treatment beams, and isovalue contour surfaces to display dose. To improve perception of spatial relationships, we use metallic shading, surface and solid texturing, synthetic fog, shadows, and other artistic devices. Also outlined is a method based on 3 D <b>mip</b> <b>maps</b> for efficiently generating perspective volume renderings and beam’s-eye views. To evaluate the efficacy of these visualizations, we are building a radiotherapy planning system based on a Cray YMP and the Pixel-Planes 5 raster display engine. The system will allow interactive manipulation of beam geometry, dosimetry, shading, and viewing parameters, and will generate volume renderings of anatomy and dose in real time. 1...|$|R
30|$|Three-dimensional spoiled T 1 W GRE contrast-enhanced dynamic {{examinations}} {{with fat}} suppression are mainly used to exclude tumor development and grade esophageal varices. Controlling the bolus arrival interval {{time for the}} late arterial, portal and equilibrium phases is required. Maximum intensity projection (<b>MIP)</b> vascular <b>map</b> images reconstructed from the arterial and portal phases show the extent of collateral vessels due to portal hypertension, {{as well as the}} arteries that perfuse abnormal regions and lesions.|$|R
40|$|Besides {{presenting}} zoonotic potential, helminths of {{cats are}} responsible for gastrointestinal, hepatic, and pulmonary diseases. In order to identify the helminthic fauna, prevalence, mean intensity of parasitism (MIP), and mean abundance population (MAP), 146 cats from the metropolitan area of Cuiab&# 225;, Midwestern Brazil, were necropsied. In 98 these animals, 12 species of helminths were identified, comprising (species, prevalence, <b>MIP,</b> and <b>MAP,</b> respectively) : nematodes (Ancylostoma braziliense[50, 68 % - 53, 64 - 27, 18], Ancylostoma tubaeforme [10, 27 % - 3, 6 - 0, 37],Toxocara cati [4, 11 % - 28, 33 - 1, 16],Physaloptera praeputialis [2, 05 % - 6, 67 - 0, 14], Capillaria feliscati [3, 42 % - 7, 4 - 0, 25], and Aelurostrongylus abstrusus[1, 37 %]); cestodes (Spirometra mansonoides[4, 11 % - 2, 0 - 0, 08], Dipylidium caninum[3, 42 % - 5, 2 - 0, 18], and Taenia taeniformis[0, 68 % - 1, 0 - 0, 01]); trematodes (Platynosomum fastosum [26, 03 % - 179, 53 - 46, 73]); acanthocephalans (Centrorhynchus erraticus [3, 42 % - 3, 2 - 0, 11]). Ancylostoma spp., and P. fastosum were the most prevalent with the highest <b>MIP</b> and <b>MAP.</b> We observed the presence of species of helminths with zoonotic potential. This {{is the first time}} cats parasitized with Centrorhynchus erraticusare reported in the Americas. That genus is commonly observed in wild animals...|$|R
40|$|We {{present a}} new {{algorithm}} for efficient rendering of high-quality depth-of-field (DoF) effects. We {{start with a}} single rasterized view (reference view) of the scene, and sample the light field by warping the reference view to nearby views. We implement the algorithm using NVIDIA’s CUDA to achieve parallel processing, and exploit the atomic operations to resolve visibility when multiple pixels warp to the same image location. We then directly synthesize DoF effects from the sampled light field. To reduce aliasing artifacts, we propose an image-space filtering technique that compensates for spatial undersampling using <b>MIP</b> <b>mapping.</b> The main advantages of our algorithm are its simplicity and generality. We demonstrate interactive rendering of DoF effects in several complex scenes. Compared to existing methods, ours does not require ray tracing and hence scales well with scene complexity. Categories and Subject Descriptors (according to ACM CCS) : Generation—Display algorithm...|$|E
40|$|Procedural solid {{texturing}} {{was introduced}} fourteen years ago, but {{has yet to}} {{find its way into}} consumer level graphics hardware for real-time operation. To this end, a new model is introduced that yields a parameterized function capable of synthesizing the most common procedural solid textures, specifically wood, marble, clouds and fire. This model is simple enough to be implemented in hardware, and can be realized in VLSI with as little as 100, 000 gates. The new model also yields a new method for antialiasing synthesized textures. An expression for the necessary box filter width is derived {{as a function of the}} texturing parameters, the texture coordinates and the rasterization variables. Given this filter width, a technique for efficiently box filtering the synthesized texture by either <b>mip</b> <b>mapping</b> the color table or using a summed area color table are presented. Examples of the antialiased results are shown. CR Categories: I. 3. 1 [Computer Graphics]: Hardware Architecture [...] - Graphic [...] ...|$|E
40|$|We {{present an}} {{interactive}} GPU-based algorithm for accurately rendering high-quality, dynamic glossy reflection effects from both HDR environment maps and local scene objects. Our method uses hardware rasterization to produce primary pixels, and GPU-based BRDF importance sampling [CK 07] to quickly generate reflected rays. We utilize a fast GPU ray tracer proposed by Carr et al. [CHCH 06] to compute reflection hits. Our main contribution is an adaptive level-of-detail (LOD) control algorithm that greatly improves ray tracing performance during reflection shading. Specifically, {{we use the}} solid angle represented by each reflected ray to adaptively pick the level of termination in the BVH traversal step during ray tracing. This leads to 2 ∼ 3 x speedup over an unmodified implementation of [CHCH 06]. Based on the same solid angle measure, we derive a texture filtering formula to reduce reflection aliasing artifacts, taking advantage of hardware <b>MIP</b> <b>mapping.</b> This extends the filtering algorithm presented in [CK 07] from environment mapping to local scene reflection. Using our algorithm, we demonstrate interactive rendering rates for several scenes featuring dynamic lighting and material changes, spatially varying BRDF parameters, and rigid-body object movement. 1...|$|E
40|$|We are {{beginning}} to see an overload in the amount of information packed into a given visualization. In many cases, it is no longer possible to look at a single level of detail and obtain from it the answers we are looking for. This problem is especially relevant to datasets of high dimensionality. Not only does it become difficult to hone in on a particular dimension of possible interest, but even more difficult to find and understand the relationships among them. In traditional computer graphics aimed at 3 D rendering, varying orders of magnitude have traditionally been addressed by texture hierarchies known as <b>MIP</b> <b>Maps.</b> These hierarchies are extremely fast and provide a seamless transition from one level of detail to the next. Unfortunately, this approach does not carry over to textures full of scientific data. Instead, such an approach introduces a series of errors which not only misrepresent and corrupt the underlying data as visible to the viewer, but hide interesting features which warrant further investigation. We propose an alternative hierarchical approach, using statistical analysis to generate more representative macroscopic views of extremely high detailed data fields. Several variations of this approach are examined, showing that hierarchies generated strictly from base level data are superior, especially when used in conjunction with error diffusion. Additionally we provide multiple example metrics as possible filter functions for this approach...|$|R
40|$|The {{incident}} {{indirect light}} over {{a range of}} image pixels is often coherent. Two common approaches to exploit this inter-pixel coherence to improve rendering performance are Irradiance Caching and Radiance Caching. Both compute incident indirect light only for a small subset of pixels (the cache), and later interpolate between pixels. Irradiance Caching uses scalar values that can be interpolated efficiently, but cannot account for shading variations caused by normal and reflectance variation between cache items. Radiance Caching maintains directional information, e. g., to allow highlights between cache items, but {{at the cost of}} storing and evaluating a Spherical Harmonics (SH) function per pixel. The arithmetic and bandwidth cost for this evaluation is linear in the number of coefficients and can be substantial. In this paper, we propose a method to replace it by an efficient per-cache item pre-filtering based on <b>MIP</b> <b>maps</b> — such as previously done for environment maps — leading to a single constant-time lookup per pixel. Additionally, per-cache item geometry statistics stored in distance-MIP maps are used {{to improve the quality of}} each pixel’s lookup. Our approximate interactive global illumination approach is an order of magnitude faster than Radiance Caching with Phong BRDFs and can be combined with Monte Carlo-raytracing, Point-based Global Illumination or Instant Radiosity. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Color, shading, shadowing, and textur...|$|R
5000|$|In {{computer}} graphics, mipmaps (also <b>MIP</b> <b>maps)</b> or pyramids [...] are pre-calculated, optimized {{sequences of}} images, {{each of which}} is a progressively lower resolution representation of the same image. The height and width of each image, or level, in the mipmap is a power of two smaller than the previous level. Mipmaps {{do not have to be}} square. They are intended to increase rendering speed and reduce aliasing artifacts. A high-resolution mipmap image is used for high-density samples, such as for objects close to the camera. Lower-resolution images are used as the object appears farther away. This is a more efficient way of downfiltering (minifying) a texture than sampling all texels in the original texture that would contribute to a screen pixel; it is faster to take a constant number of samples from the appropriately downfiltered textures. Mipmaps are widely used in 3D computer games, flight simulators, other 3D imaging systems for texture filtering and 2D as well as 3D GIS software. Their use is known as mipmapping. The letters [...] "MIP" [...] in the name are an acronym of the Latin phrase multum in parvo, meaning [...] "much in little". Since mipmaps, by definition, are pre-allocated, additional storage space is required to take advantage of them. They are also related to wavelet compression. Mipmap textures are used in 3D scenes to decrease the time required to render a scene. They also improve the scene's realism, at the cost of 1/3 more memory per texture.|$|R
