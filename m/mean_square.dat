10000|10000|Public
5|$|The outputs of a {{structural}} alignment are a superposition {{of the atomic}} coordinate sets and a minimal root <b>mean</b> <b>square</b> deviation (RMSD) between the structures. The RMSD of two aligned structures indicates their divergence from one another. Structural alignment can be complicated by the existence of multiple protein domains within {{one or more of}} the input structures, because changes in relative orientation of the domains between two structures to be aligned can artificially inflate the RMSD.|$|E
5|$|Von Neumann made {{fundamental}} {{contributions to}} mathematical statistics. In 1941, he derived the exact {{distribution of the}} ratio of the <b>mean</b> <b>square</b> of successive differences to the sample variance for independent and identically normally distributed variables. This ratio was applied to the residuals from regression models and is commonly known as the Durbin–Watson statistic for testing the null hypothesis that the errors are serially independent against the alternative that they follow a stationary first order autoregression.|$|E
25|$|Vrms, {{the root}} <b>mean</b> <b>square</b> (RMS) {{value of output}} voltage.|$|E
40|$|We {{obtain a}} {{conditional}} prediction <b>mean</b> <b>squared</b> error {{for a state}} space model with estimated parameters. An important application of our results is the derivation of conditional forecast and interpolation <b>mean</b> <b>squared</b> errors for autoregressive-moving average models with estimated parameters. We also obtain the conditional <b>mean</b> <b>squared</b> error for filtered and smoothed estimates of the state vector...|$|R
3000|$|If the {{functions}} used in Eq.  19 a are {{chosen to be}} orthogonal, then the <b>mean</b> <b>squared</b> value of the error e_φ(t)ψ^- 1 (t)-ψ^- 1 (t) [...] is minimized by K independent minimizations of this same <b>mean</b> <b>squared</b> error w.r.t. to the K unknowns ak executed in any order. But this {{does not imply that}} the <b>mean</b> <b>squared</b> value of the error e(t) defined by Eq.  14 behaves similarly. In general, a full joint minimization of this <b>mean</b> <b>squared</b> error w.r.t. all K unknowns ak must be executed. Yet, a perturbation analysis suggests that, for sufficiently small eφ(t), K independent minimizations of the <b>mean</b> <b>squared</b> value of the error e(t) using orthogonal basis functions yields approximately the same result as a single joint minimization.|$|R
40|$|Summary Total planar {{area can}} be {{estimated}} based on sampling by a lattice of figures (e. g. point patterns, line segments, quadrats). General formulae are provided for the approximation of <b>mean</b> <b>squared</b> errors. The approximation formulae are products of the boundary length and of a parameter that depends only on the sampling scheme. An R package {{is provided by the}} authors for the numerical computation of the <b>mean</b> <b>squared</b> error formulae. The speed of convergence of the <b>mean</b> <b>squared</b> error approximation is assessed on the basis of several simulations. Several sampling schemes are compared in view of the approxi-mated <b>mean</b> <b>squared</b> errors...|$|R
25|$|Mean squared {{error is}} used for obtaining {{efficient}} estimators, a widely used class of estimators. Root <b>mean</b> <b>square</b> error is simply the square root of mean squared error.|$|E
25|$|S. Jo and S. W. Kim, Consistent {{normalized}} least <b>mean</b> <b>square</b> filtering with noisy data matrix. IEEE Trans. Signal Processing, vol. 53, no. 6, pp.2112–2123, Jun. 2005.|$|E
25|$|The neutron has a {{positively}} charged core of radius ≈ 0.3 fm {{surrounded by a}} compensating negative charge of radius between 0.3 fm and 2 fm. The proton has an approximately exponentially decaying positive charge distribution with a <b>mean</b> <b>square</b> radius of about 0.8 fm.|$|E
50|$|Forecast errors can be {{evaluated}} {{using a variety}} of methods namely mean percentage error, root <b>mean</b> <b>squared</b> error, <b>mean</b> absolute percentage error, <b>mean</b> <b>squared</b> error. Other methods include tracking signal and forecast bias.|$|R
40|$|Small area is an {{area with}} {{insufficient}} sample for direct estimation. Limited survey objects, cause direct estimation can not produce better parameter estimates. Based on this, an indirect estimation method called empirical Bayes is used to obtain a better estimate. This study will compare <b>means</b> <b>squared</b> error by  direct estimation method and empirical Bayes method {{to find a better}} method on a small area. Jackknife is used to get the <b>means</b> <b>squared</b> error in the empirical Bayes. The results is, empirical Bayes methods give a better parameters based on <b>mean</b> <b>squared</b> errors. Empirical Bayes can produce a smaller <b>mean</b> <b>squared</b> error more than direct estimation in small area. </p...|$|R
40|$|Several authors {{consider}} the optimization of linear combinations of independent estimators {{with respect to}} <b>mean</b> <b>squared</b> error. The minimization of variance for convex combinations of estimators having a known correlation coe±cient is also considered in the literature. We unify and generalize the results pertaining to these two problems by minimizing <b>mean</b> <b>squared</b> error for linear combinations of dependent estimators. We examine {{the role of the}} correlation coe±cient in establishing the optimal weights for these combinations and uncover a relationship between these optimal weights and those provided in the literature for minimizing the <b>mean</b> <b>squared</b> error of a single estimator. Key Words: Weighted estimator, coe±cient of variation, <b>mean</b> <b>squared</b> error. ...|$|R
25|$|Mathematically {{the radius}} of {{gyration}} is the root <b>mean</b> <b>square</b> distance of the object's parts from either its center of mass or a given axis, depending on the relevant application. It is actually the perpendicular distance from point mass to the axis of rotation.|$|E
25|$|These inequalities can {{be proved}} by {{bringing}} the matrix A to the diagonal form. As such, {{they represent the}} well-known fact that the harmonic mean {{is less than the}} geometric mean, which is less than the arithmetic mean, which is, in turn, less than the root <b>mean</b> <b>square.</b>|$|E
25|$|While the {{standard}} deviation does measure how far typical values tend {{to be from the}} mean, other measures are available. An example is the mean absolute deviation, which might be considered a more direct measure of average distance, compared to the root <b>mean</b> <b>square</b> distance inherent in {{the standard}} deviation.|$|E
40|$|The minimum {{discrimination}} information (MDI) {{procedure for}} lowering the <b>mean</b> <b>squared</b> error (MSE) {{of the minimum}} variance unbiased estimator (MVUE) of the normal mean is considered. The procedure is employed to shrink the MVUE toward a preliminary conjectured interval under the information measure of Kullback and Leibler (1951). MDI estimator and its <b>mean</b> <b>squared</b> error are derived. The suggested estimator compares favorably with the previously proposed estimators in terms of <b>mean</b> <b>squared</b> error efficiency. 1...|$|R
50|$|The use of <b>mean</b> <b>squared</b> error without {{question}} has been criticized by the decision theorist James Berger. <b>Mean</b> <b>squared</b> error is the negative of the expected value of one specific utility function, the quadratic utility function, {{which may not be}} the appropriate utility function to use under a given set of circumstances. There are, however, some scenarios where <b>mean</b> <b>squared</b> error can serve as a good approximation to a loss function occurring naturally in an application.|$|R
40|$|We {{propose a}} kernel-based {{multi-stage}} conditional median predictor for [alpha]-mixing time series of Markovian structure. <b>Mean</b> <b>squared</b> error properties of single-stage and multi-stage conditional medians are derived and discussed. [alpha]-mixing Conditional median Kernel Markovian <b>Mean</b> <b>squared</b> error Multi-stage predictor Single-stage predictor Time series...|$|R
25|$|Calculating the {{arithmetic}} {{mean of the}} errors diminishes the contribution of any single large deviation. Two light sources with similar CRI may perform significantly differently if one has a particularly low special CRI in a spectral band that {{is important for the}} application. Use the root <b>mean</b> <b>square</b> deviation instead.|$|E
25|$|Since {{the basic}} {{indicator}} system in either an analog or digital meter responds to DC only, a multimeter includes an AC to DC conversion circuit for making alternating current measurements. Basic meters utilize a rectifier circuit {{to measure the}} average or peak absolute value of the voltage, but are calibrated to show the calculated root <b>mean</b> <b>square</b> (RMS) value for a sinusoidal waveform; this will give correct readings for alternating current as used in power distribution. User guides for some such meters give correction factors for some simple non-sinusoidal waveforms, to allow the correct root <b>mean</b> <b>square</b> (RMS) equivalent value to be calculated. More expensive multimeters include an AC to DC converter that measures the true RMS value of the waveform within certain limits; the user manual for the meter may indicate {{the limits of the}} crest factor and frequency for which the meter calibration is valid. RMS sensing is necessary for measurements on non-sinusoidal periodic waveforms, such as found in audio signals and variable-frequency drives.|$|E
25|$|A peak-sensing {{compressor}} {{responds to}} the instantaneous level of the input signal. While providing tighter peak control, peak sensing might yield very quick changes in gain reduction, more evident compression or sometimes even distortion. Some compressors apply an averaging function (commonly root <b>mean</b> <b>square</b> or RMS) on the input signal before comparing its level to the threshold. This produces a more relaxed compression that more closely relates to human perception of loudness.|$|E
40|$|INTRODUCTION Antenna GainPhased Array AntennaPower Pattern Beam Steering Degree of Freedom Optimal AntennaAdaptive AntennaSmart AntennaSummary NARROWBAND PROCESSINGSignal Model Conventional BeamformerNull Steering BeamformerOptimal BeamformerOptimization Using Reference SignalBeam Space Processing Effect of ErrorsNotation and AbbreviationsReferencesADAPTIVE PROCESSINGSample Matrix Inversion AlgorithmUnconstrained Least <b>Mean</b> <b>Squares</b> AlgorithmNormalized Least <b>Mean</b> <b>Squares</b> AlgorithmConstraine...|$|R
50|$|Two {{naturally}} desirable {{properties of}} estimators are {{for them to}} be unbiased and have minimal <b>mean</b> <b>squared</b> error (MSE). These cannot in general both be satisfied simultaneously: a biased estimator may have lower <b>mean</b> <b>squared</b> error (MSE) than any unbiased estimator; see estimator bias.|$|R
5000|$|... where [...] is the squared {{magnitude}} of the wave vector variation caused by scattering,and [...] is the temperature-dependent one-dimensional vibrational <b>mean</b> <b>squared</b> displacement of the [...] emitter. In the Debye model, the <b>mean</b> <b>squared</b> displacement is calculated {{in terms of the}} Debye temperature, , as: ...|$|R
25|$|An {{attempt to}} predict the bulk melting point of {{crystalline}} materials was first made in 1910 by Frederick Lindemann. The idea behind the theory was the observation that the average amplitude of thermal vibrations increases with increasing temperature. Melting initiates when the amplitude of vibration becomes large enough for adjacent atoms to partly occupy the same space. The Lindemann criterion states that melting is expected when the vibration root <b>mean</b> <b>square</b> amplitude exceeds a threshold value.|$|E
25|$|The cosmic {{microwave}} background radiation is an emission of uniform, black body thermal energy coming {{from all parts of}} the sky. The radiation is isotropic to roughly one part in 100,000: the root <b>mean</b> <b>square</b> variations are only 18 µK, after subtracting out a dipole anisotropy from the Doppler shift of the background radiation. The latter is caused by the peculiar velocity of the Earth relative to the comoving cosmic rest frame as the planet moves at some 371km/s towards the constellation Leo. The CMB dipole as well as aberration at higher multipoles have been measured, consistent with galactic motion.|$|E
25|$|The {{quality of}} the {{homology}} model {{is dependent on the}} {{quality of the}} sequence alignment and template structure. The approach can be complicated by the presence of alignment gaps (commonly called indels) that indicate a structural region present in the target but not in the template, and by structure gaps in the template that arise from poor resolution in the experimental procedure (usually X-ray crystallography) used to solve the structure. Model quality declines with decreasing sequence identity; a typical model has ~1–2 Å root <b>mean</b> <b>square</b> deviation between the matched Cα atoms at 70% sequence identity but only 2–4 Å agreement at 25% sequence identity. However, the errors are significantly higher in the loop regions, where the amino acid sequences of the target and template proteins may be completely different.|$|E
40|$|International audienceWe {{analyze the}} <b>mean</b> <b>squared</b> {{displacement}} of a Brownian particle {{in a medium}} with a spatially varying local diffusivity which {{is assumed to be}} periodic. When the system is asymptotically diffusive the <b>mean</b> <b>squared</b> displacement, characterizing the dispersion in the system, is, at late times, a linear function of time. A Kubo type formula is given for the <b>mean</b> <b>squared</b> displacement which allows the recovery of some known results for the effective diffusion constant $D_e$ in a direct way, but also allows an understanding of the asymptotic approach to the diffusive limit. In particular, as well as as computing the slope of a linear fit to the late time <b>mean</b> <b>squared</b> displacement, we find a formula for the constant where the fit intersects the y axis...|$|R
40|$|In this work, {{recently}} derived theoretical approximations {{for high}} rate vector quantization (VQ) are reformulated to cleanly separate {{the effects of}} the VQ codevector density and the local Voronoi region shapes on overall VQ performance. Numerical evaluation of the resulting theoretical expressions is performed, which allows comparison of the relative importance of codevector density and Voronoi region shapes for a variety of different conditions. In particular, results are presented which compare root <b>mean</b> <b>squared</b> (RMS) vs. <b>mean</b> <b>squared</b> (MS) optimal quantizers, full band vs. partial band log spectral distortion (LSD) quantizers, LPC vs. K vs. LAR vs. ASIN vs. LSP vs. cepstral coefficients, 0 th order vs. 1 st order recursion, and optimal vs. weighted <b>mean</b> <b>squared</b> error (WMSE) vs. <b>mean</b> <b>squared</b> error (MSE) quantizers. 1...|$|R
40|$|When climate {{forecasts}} {{are highly}} uncertain, the optimal <b>mean</b> <b>squared</b> error {{strategy is to}} ignore them. When climate forecasts are highly certain, the optimal <b>mean</b> <b>squared</b> error strategy is to use them as is. In between these two extremes there are climate forecasts with an intermediate level of uncertainty for which the optimal <b>mean</b> <b>squared</b> error strategy {{is to make a}} compromise forecast. We present two new methods for making such compromise forecasts, and show, using simulations, that they improve on previously published methods...|$|R
2500|$|For a given bandwidth, [...] {{the root}} <b>mean</b> <b>square</b> (RMS) of the voltage, , {{is given by}} ...|$|E
2500|$|The one-sided power {{spectral}} density, or voltage variance (<b>mean</b> <b>square)</b> per hertz of bandwidth, {{is given}} by ...|$|E
2500|$|... where [...] is {{the root}} <b>mean</b> <b>square</b> {{deviation}} of the system Hamiltonian averaged over the interval of interest.|$|E
40|$|Graduation date: 1998 Measuring {{the source}} and {{magnitude}} of components of variation has important applications in industrial, environmental and biological studies. This thesis considers the problem of constructing confidence intervals for variance components in Gaussian mixed linear models. A number of methods based on the usual ANOVA <b>mean</b> <b>squares</b> have been proposed for constructing confidence intervals for variance components in balanced mixed models. Some authors have suggested extending balanced model procedures to unbalanced models by replacing the ANOVA <b>mean</b> <b>squares</b> with <b>mean</b> <b>squares</b> from an unweighted means ANOVA. However, the unweighted means ANOVA is only defined for a few specific mixed models. In Chapter 2 we define a generalization of the unweighted means ANOVA for the three variance component mixed linear model and illustrate how the <b>mean</b> <b>squares</b> from this ANOVA {{may be used to}} construct confidence intervals for variance components. Computer simulations indicate that the proposed procedure gives intervals that are generally consistent with the stated confidence level, except in the case of extremely unbalanced designs. A set of statistics that can be used {{as an alternative to the}} generalized unweighted <b>mean</b> <b>squares</b> is developed in Chapter 3. The intervals constructed with these statistics have better coverage probability and are often narrower than the intervals constructed with the generalized unweighted <b>mean</b> <b>squares...</b>|$|R
40|$|We study {{generalised}} {{anomalous diffusion}} processes whose diffusion coefficient D(x,t) ∼ D_ 0 |x|^αt^β depends {{on both the}} position x of the test particle and the process time t. This process thus combines the features of scaled Brownian motion and heterogeneous diffusion parent processes. We compute the ensemble and time averaged <b>mean</b> <b>squared</b> displacements of this generalised diffusion process. The scaling exponent of the ensemble averaged <b>mean</b> <b>squared</b> displacement is shown to be {{the product of the}} critical exponents of the parent processes, and describes both subdiffusive and superdiffusive systems. We quantify the amplitude fluctuations of the time averaged <b>mean</b> <b>squared</b> displacement as function of the length of the time series and the lag time. In particular, we observe a weak ergodicity breaking of this generalised diffusion process: even in the long time limit the ensemble and time averaged <b>mean</b> <b>squared</b> displacements are strictly disparate. When we start to observe this process some time after its initiation we observe distinct features of ageing. We derive a universal ageing factor for the time averaged <b>mean</b> <b>squared</b> displacement containing all information on the ageing time and the measurement time. External confinement is shown to alter the magnitudes and statistics of the ensemble and time averaged <b>mean</b> <b>squared</b> displacements. Comment: 19 pages, 10 figures, IOPLaTe...|$|R
3000|$|... where SNRR_s(0)/R_ñ(0) [...] is {{the ratio}} of <b>mean</b> <b>squared</b> signal to <b>mean</b> <b>squared</b> noise, and ρ_s^α(τ)R_ss^(∗)^α(τ)/R_ss^∗(0) [...] is the cyclic {{correlation}} coefficient (assuming the signal has zero mean value or, equivalently, contains no finite-strength additive sine-wave components), which has magnitude {{less than or equal}} to unity.|$|R
