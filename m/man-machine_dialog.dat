6|4|Public
40|$|This note {{presents}} {{a description of}} a time-sharing computer program written to implement a man-machine interactive algorithm for the solution of the multiple criteria problem. The interactive algorithm was suggested in a recent paper by Geoffrion, "Vector Maximal Decomposition Programming," Working Paper No. 164, Western Management Science Institute, University of California, Los Angeles, September 1970. A unique feature of this program is the <b>man-machine</b> <b>dialog</b> which obtains information from the decision-maker through a series of simple, ordinal comparisons. ...|$|E
40|$|To {{establish}} robotic {{applications in}} human environments as e. g. offices or private homes the robotic systems must be instructable by ordinary users {{in a natural}} way. In interpersonal communication humans usually apply different sensory information and are capable of integrating all perceptual cues fast and consistently. Additionally, knowledge acquired during the communication process is directly used to resolve ambiguities. As a step towards realizing similar capabilities in automatic devices this paper presents an integrated system combining automatic speech processing and image understanding. The system {{is intended to be}} an intelligent interface of a robot which manipulates objects in its surroundings according to the instructions of a human. The enhanced capabilities necessary for carrying out a multimodal <b>man-machine</b> <b>dialog</b> are realized by combining statistical and declarative methods for inference and knowledge representation. The effectiveness of this approach is demonstrated using an examplary dialog from our construction task domain...|$|E
40|$|In {{this paper}} we will {{describe}} the natural language and dialog {{component in the}} Waxholm system. Our parser, STINA, is knowledge based and is designed as a probabilistic language model. The dialog management, also implemented in STINA, is based on grammar rules and lexical semantic features. The parser is running with two different time scales corresponding to the words in each utterance and to the turns in the dialog. Topic selection is accomplished based on probabilities calculated from user initiatives. 1. INTRODUCTION Our research group at KTH is currently building a generic system in which speech synthesis and speech recognition can be studied in a <b>man-machine</b> <b>dialog</b> framework. The demonstrator application, which we call WAXHOLM, gives information on boat traffic in the Stockholm archipelago [1, 2]. In addition to boat time-tables, the database also contains information about port locations, hotels, camping places, and restaurants in the Stockholm archipelago. The system is prese [...] ...|$|E
40|$|The {{attractive}} use of {{new kinds}} of telecommunications services for information, learning and entertainment demands a multitude of features using not only text or graphics but also speech and still or moving pictures. The development of broadband transmission techniques is helpful for designing such systems. An overview of existing and planned systems is given. Possible contents of such <b>man-machine</b> <b>dialogs</b> or machine-aided communication are discussed. Classes of services for {{a great variety of}} applications are presented {{from the standpoint of the}} user. To serve a large number of subscribers, new concepts for the central computer-a multiprocessor system-and storage medium (especially for audiovisual material) are necessary...|$|R
40|$|Abstract—This paper {{describes}} {{how to use}} conventional parser generation tools {{for the development of}} JSON pro-cessing applications. According to the resulting gram-mar-driven development approach, JSON processing ap-plications are architected as syntax-directed translators. Thus, the core part of these components can be described in terms of translation schemata and can be automatically generated by using suitable parser generators. It makes it possible to specify critical parts of the application (those interfacing with JSON documents) by using high-level, grammar-oriented descriptions, as well as to promote the separation of JSON processing concerns from other appli-cation-specific aspects. In consequence, the production and maintenance of JSON processing applications is facil-itated (especially for applications involving JSON docu-ments with intricate nested structures, as well as for ap-plications in which JSON formats are exposed to frequent changes and evolutions in their surface structures). This paper illustrates the approach with JSON-P as the generic JSON processing framework, with ANTLR as the parser generation tool, and with a case study concerning the de-velopment of a player for simple <b>man-machine</b> <b>dialogs</b> shaped in terms of JSON documents...|$|R
40|$|International audienceIn this paper, {{we propose}} {{to add a}} model for NLU-related error {{generation}} in a modular environment for computer-based simulation of <b>man-machine</b> spoken <b>dialogs.</b> This model is jointly designed with a user model. Both of them {{are based on the}} same underlying Bayesian Network used with different parameters {{in such a way that}} it can generate a consistent user behavior, according to a goal and the interaction history, and been used as a concept classifier. The proposed simulation environment was used to train a reinforcement-learning algorithm on a simple form-filling task and the results of this experiment show that the addition of the NLU model helps pointing out problematic situations that may occur because of misunderstandings and modifying the dialog strategy accordingly...|$|R
40|$|In {{this paper}} we give an {{overview}} of the NLP and dialog component in the Waxholm spoken dialog system. We will discuss how the dialog and the natural language component are modeled from a generic and a domain-specific point of view. Dialog management based on grammar rules and lexical semantic features is implemented in our parser. The notation to describe the syntactic rules has been expanded to cover some of our special needs to model the dialog. The parser is running with two different time scales corresponding to the words in each utterance and to the turns in the dialog. Topic selection is accomplished based on probabilities calculated from user initiatives. Results from parser performance and topic prediction are included in the presentation. INTRODUCTION Our research group at KTH has, for some years, been building a generic system in which speech synthesis and speech recognition can be studied in a <b>man-machine</b> <b>dialog</b> framework. The demonstrator application, Waxholm, gives info [...] ...|$|E
40|$|Competent {{design of}} {{hierarchical}} interfaces for hardware/software systems needs {{the convergence of}} three concurrent research directions: the study of hierarchy types, the intelligent communication between different domains, the formalization of verification/test. We aim to extend the theory of hierarchy types, in order to integrate communication properties as well as correctness and testability, to suit the behavioral specification of today's complex system design. The high level approach of these problems permits the intervention of an intelligent agent for adapting techniques, models or methods to the particular design: a designer, assisted by <b>man-machine</b> <b>dialog</b> interface, or an artificial intelligence system. Behavioral design-for-testability offers a good startup. Testability measures the difficulty of test; it is used in this paper to emphasize the high-level strategy. Design-for-testability techniques (full and partial scan, test point insertion or builtin self-test) increase the fault coverage and reduce the test generation time; as they aim to modify the system's specification to improve testability, performing them at higher levels of the design hierarchy reduces the complexity of their generation and application. An intelligent use of the acquired knowledge on design for communication, verification and testability is enabled...|$|E
40|$|Colloque avec actes et comité de lecture. This {{paper will}} focus on the {{conceptual}} and technical design of a system architecture devoted to the integration of the various natural spoken language processing levels. Our goal is to avoid the well known constraints and limitations imposed by the usual combination of stochastic recognition models and statistical n-gram language models. To do so, we investigate the intensive use of weighted finite-state automata at each processing level to gather the static information. These automata are obtained directly or by linearizing tree structures and are then minimalized to get a optimal sharing of common substructures. Our hypothesis is that this property of sharing directly leads to a high processing factorization and consequently to an improved computational efficiency. Experiments are currently carried out to integrate an analytical segmentation system, a stochastic phonetic recognition module and a parser based on synchronous LTAG (Lexicalized Tree Adjoining Grammars) [Shieber 90] [Lopez 98] for syntactic and semantic descriptions to analyse a spoken task-oriented <b>man-machine</b> <b>dialog</b> corpus. The segmentation stage is based on hierarchical multi-level lattices and produces a weighted automaton of predicted broad phonetic classes [Husson 96]. The phoneme recognition stage is led by usual phonetic hidden Markov models. Minimilized phonetic automata are computed from the canonical phonetic transcription of all words of the corpus [Laporte 93]. The syntactic and semantic lexicalized tree grammar are semi-automatically built from a corpus collected by an wizard of Oz experiment. The trees are linearized and the resulting automata are minimalized with similar techniques as described in [Evans 98]. We provide some results which exhibit the high syntactical substructures sharing rate which is obtained. These different automata are synchronized with links between states. The decoding and parsing modules produce temporary concurrent analysis structures attached to at least one state of the corresponding automaton. Distributed control modules are needed to apply and exploit local synchronization constraints on the activated synchronized states. These synchonization techniques allow us to implement all kind of hypothesis manipulation for both deductive and abductive reasoning...|$|E

