616|1641|Public
5|$|One {{application}} of this principle arises in a film projector. In this application, {{it is necessary to}} advance the film in a jerky, stepwise motion, in which each frame of film stops for {{a fraction of a second}} in front of the projector lens, and then much more quickly the film is moved to the next frame. This can be done using a mechanism in which the rotation of a Reuleaux triangle within a square is used to create a <b>motion</b> <b>pattern</b> for an actuator that pulls the film quickly to each new frame and then pauses the film's motion while the frame is projected.|$|E
25|$|Defending {{against a}} penalty kick {{is one of}} the most {{difficult}} tasks a goalkeeper can face. Owing to the short distance between the penalty spot and the goal, there is very little time to react to the shot. Because of this, the goalkeeper will usually start his or her dive before the ball is actually struck. In effect, the goalkeeper must act on his best prediction about where the shot will be aimed. Some goalkeepers decide which way they will dive beforehand, thus giving themselves a good chance of diving in time. Others try to read the kicker's <b>motion</b> <b>pattern.</b> On the other side, kickers often feign and prefer a relatively slow shot in an attempt to foil the goalkeeper. The potentially most fruitful approach, shooting high and centre, i.e., in the space that the goalkeeper will evacuate, also carries the highest risk of shooting above the bar.|$|E
50|$|Foerster, F., & Fahrenberg, J. (2000). <b>Motion</b> <b>pattern</b> and posture: Correctly {{assessed}} by calibrated accelerometers. Behaviour Research Methods, Instruments, & Computers, 32, 450-457.|$|E
40|$|Abstract — This paper proposes an {{approach}} to hierarchy formation of human behaviors, extraction of the behavioral transitions, and their application to prediction and automatic generation of behaviors. Human demonstrator <b>motion</b> <b>patterns</b> are stored as motion symbols, which abstract the motion data by using Hidden Markov Models. The stored <b>motion</b> <b>patterns</b> are organized into a hierarchical tree structure, which represents the similarity among the <b>motion</b> <b>patterns</b> and provides abstracted <b>motion</b> <b>patterns.</b> Concatenated sequences of <b>motion</b> <b>patterns</b> are stochastically represented as transitions between the abstracted <b>motion</b> <b>patterns</b> by using an Ngram Model, and the transitional relationships of the human behaviors are extracted. The behavioral hierarchy and transition model {{make it possible to}} predict human behaviors during observation and to generate sequences of <b>motion</b> <b>patterns</b> automatically while maintaining a natural motion stream, as if the system is a “crystal ball ” to reflect future behaviors. The experiments validates the proposed framework by using a developed visualization system, which shows the demonstrator or the operator the established hierarchical tree and the transition network of the <b>motion</b> <b>patterns,</b> predicted behaviors and generated sequences of the <b>motion</b> <b>patterns.</b> I...|$|R
40|$|In this paper, I {{explore the}} {{presence}} and function of English <b>motion</b> <b>patterns</b> in a corpus comprising various narrative genres, and suggest ways in which research into their rhetorical function might complement other approaches in the literature as well as help teachers introduce Spanish learners of English as a Foreign Language (EFL) to this idiosyncratic feature of English narratives. The working hypothesis is {{that the use of}} <b>motion</b> <b>patterns</b> may also be influenced by genre. This genre approach to <b>motion</b> <b>patterns</b> may, on the one hand, shed some light on the rhetorical or communicative motivation of <b>motion</b> <b>patterns</b> in English and, on the other, help teachers choose and exploit the best input in order to include such patterns in the EFL classroom in a way that goes beyond a lexical- or grammatical-only approach, that is, one that focuses on the pragmatic aspects involved in the use of <b>motion</b> <b>patterns...</b>|$|R
30|$|<b>Motion</b> <b>patterns</b> are {{represented}} using prototype trajectories which are learned from data during a training phase. Subsequently prediction {{can be performed}} online given a partial trajectory by finding the most likely <b>motion</b> <b>pattern(s)</b> and using the prototype trajectories {{as a model for}} future motion.|$|R
50|$|The {{patterns}} of bacteria collective motion {{are very different}} from the <b>motion</b> <b>pattern</b> of an individual bacterium. When flagellated bacteria are moving in bulk liquid, where the locomotion of one individual doesn’t affect the others, this movement is called swimming. single Escherichia coli bacterium swims in a ‘run-and-tumble’ motion.|$|E
5000|$|... {{such that}} [...] is the {{activity}} of the complete biological <b>motion</b> <b>pattern</b> detector in response to pattern type [...] (e.g. walking to the left), [...] equals the time constant (used 150 ms in simulation), and [...] equals {{the activity of}} optic flow pattern detector at kth frame in sequence l.|$|E
50|$|One {{application}} of this principle arises in a film projector. In this application, {{it is necessary to}} advance the film in a jerky, stepwise motion, in which each frame of film stops for {{a fraction of a second}} in front of the projector lens, and then much more quickly the film is moved to the next frame. This can be done using a mechanism in which the rotation of a Reuleaux triangle within a square is used to create a <b>motion</b> <b>pattern</b> for an actuator that pulls the film quickly to each new frame and then pauses the film's motion while the frame is projected.|$|E
40|$|Abstract. The paper {{discusses}} Bifurcation Diagrams of rotor stator contact {{problems and}} the transition from synchronous whirl towards different asynchronous movement patterns. Bifurcation Diagrams based on Poincaré Maps are presented for the model consisting of a Jeffcott rotor and a flexible mounted rigid stator ring. The analysis methods are applied systematically with respect to various <b>motion</b> <b>patterns</b> that have been observed for rotor stator contact in the past. The type of motion is identified using the analysis methods. Also the influence of different parameters on the changes of <b>motion</b> <b>patterns</b> and the transitions that result are described. The unique identification of all <b>motion</b> <b>patterns</b> for rotor stator interaction based on Bifurcation Diagrams is focus of the paper. Further insight on the conditions {{that lead to the}} change of <b>motion</b> <b>patterns</b> is given. ...|$|R
40|$|Discovering {{repetitive}} patterns {{is important}} {{in a wide range}} of research areas, such as bioinformatics and human movement analysis. This study puts forward a new methodology to identify, visualise and interpret repetitive <b>motion</b> <b>patterns</b> in groups of Moving Point Objects (MPOs). The methodology consists of three steps. First, <b>motion</b> <b>patterns</b> are qualitatively described using the Qualitative Trajectory Calculus (QTC). Second, a similarity analysis is conducted to compare <b>motion</b> <b>patterns</b> and identify repetitive <b>patterns.</b> Third, repetitive <b>motion</b> <b>patterns</b> are represented and interpreted in a continuous triangular model. As an illustration of the usefulness of combining these hitherto separated methods, a specific movement case is examined: Samba dance, a rhythmical dance will? many repetitive movements. The results show that the presented methodology is able to successfully identify, visualize and interpret the contained repetitive motions...|$|R
40|$|The paper {{discusses}} Bifurcation Diagrams of rotor stator contact {{problems and}} the transition from synchronous whirl towards different asynchronous movement patterns. Bifurcation Diagrams based on Poincaré Maps are presented for the model consisting of a JEFFCOTT rotor and a flexible mounted rigid stator ring. The analysis methods are applied systematically with respect to various <b>motion</b> <b>patterns</b> that have been observed for rotor stator contact in the past. The type of motion is identified using the analysis methods. Also the influence of different parameters on the changes of <b>motion</b> <b>patterns</b> and the transitions that result are described. The unique identification of all <b>motion</b> <b>patterns</b> for rotor stator interaction based on Bifurcation Diagrams is focus of the paper. Further insight on the conditions {{that lead to the}} change of <b>motion</b> <b>patterns</b> is given...|$|R
50|$|Defending {{against a}} penalty kick {{is one of}} the most {{difficult}} tasks a goalkeeper can face. Owing to the short distance between the penalty spot and the goal, there is very little time to react to the shot. Because of this, the goalkeeper will usually start his or her dive before the ball is actually struck. In effect, the goalkeeper must act on his best prediction about where the shot will be aimed. Some goalkeepers decide which way they will dive beforehand, thus giving themselves a good chance of diving in time. Others try to read the kicker's <b>motion</b> <b>pattern.</b> On the other side, kickers often feign and prefer a relatively slow shot in an attempt to foil the goalkeeper. The potentially most fruitful approach, shooting high and centre, i.e., in the space that the goalkeeper will evacuate, also carries the highest risk of shooting above the bar.|$|E
50|$|Cable driven {{redundant}} parallel robots are a {{new generation}} of parallel robots in which instead of rigid actuators cable are used to produce the desired <b>motion</b> <b>pattern.</b> The fact of using cable arises a lot of challenge in analyzing the kinematics and dynamics of such a robot. Cable driven redundant parallel robots consist of a moving platform which is connected by the means of actuated cables to the base. Redundancy is an inherent requirement for such a mechanism {{due to the fact that}} cables can only pull but cannot push the moving platform. Thus, in a non-singular posture, the moving platform it can perform n Degree-of-freedom (DOF) by considering at least n+1 cables. Cable driven redundant parallel robots are special design of parallel robots that heritage the advantages of parallel robots such as high acceleration and high load carrying capability and at the same time, have alleviated some of their shortcomings, such as restricted workspace.|$|E
5000|$|Defending {{against a}} penalty kick {{is one of}} the most {{difficult}} tasks a goalkeeper can face. Some decide which way they will dive beforehand, giving themselves time to reach the side of the goalmouth. A 2011 study published in the journal Psychological Science found goalkeepers dived to the right 71% of the time when their team was losing, but only 48% when ahead and 49% when tied, a phenomenon believed to be related to certain right-preferring behaviour in social mammals. Others try to read the kicker's <b>motion</b> <b>pattern.</b> Kickers may attempt to feint, or delay their shot to see which way the keeper dives. Shooting high and centre, in the space that the keeper will evacuate, carries the highest risk of shooting above the bar. [...] If a keeper blocks a penalty kick during a match, there is a danger the kicker or a team-mate may score from the rebound; this is not relevant in the case of a shoot-out.|$|E
30|$|The {{recognition}} of <b>motion</b> <b>patterns</b> and interactions from trajectories is a challenging task, in particular when dynamics of moving agents are nonlinear through time and space. Moreover, a quick analysis of existent bibliography shows that current methods usually claim robustness and reliability for highly restricted scenarios, broad sensor availability and short video footages [17]. To alleviate these issues, a common {{approach is to}} represent the state of agents under a probabilistic framework and characterize the <b>motion</b> <b>patterns</b> by following a nonlinear Bayesian state estimation. This approach has been successfully applied in surveillance environments and complex <b>motion</b> <b>patterns</b> [12, 18].|$|R
40|$|We {{present a}} novel method for the {{discovery}} and statistical representation of <b>motion</b> <b>patterns</b> {{in a scene}} observed by a static camera. Related methods involving learning of patterns of activity rely on trajectories obtained from object detection and tracking systems, which are unreliable in complex scenes of crowded motion. We propose a mixture model representation of salient patterns of optical flow, and present an algorithm for learning these patterns from dense optical flow in a hierarchical, unsupervised fashion. Using low level cues of noisy optical flow, K-means is employed to initialize a Gaussian mixture model for temporally segmented clips of video. The components of this mixture are then filtered and instances of <b>motion</b> <b>patterns</b> are computed using a simple motion model, by linking components across space and time. <b>Motion</b> <b>patterns</b> are then initialized and membership of instances in different <b>motion</b> <b>patterns</b> is established by using KL divergence between mixture distributions of pattern instances. Finally, a pixel level representation of <b>motion</b> <b>patterns</b> is proposed by deriving conditional expectation of optical flow. Results of extensive experiments are presented for multiple surveillance sequences containing numerous patterns involving both pedestrian and vehicular traffic. 1...|$|R
40|$|We {{propose a}} method for {{learning}} models of people's motion behaviors in an indoor environment. As people move through their environments, they do not move randomly. instead, they often engage in typical <b>motion</b> <b>patterns,</b> related to specific locations {{that they might be}} interested in approaching and specific trajectories that they might follow in doing so. Knowledge about such patterns may enable a mobile robot to develop improved people following and obstacle avoidance skills. This paper proposes an algorithm that learns collections of typical trajectories that characterize a person's <b>motion</b> <b>patterns.</b> Data, recorded by mobile robots equipped with laser range finders, is clustered into different types of motion using the popular expectation maximization algorithm, while simultaneously learning multiple <b>motion</b> <b>patterns.</b> Experimental results, obtained using data collected in a domestic residence and in an office building, illustrate that highly predictive models of human <b>motion</b> <b>patterns</b> can be learned...|$|R
5000|$|The {{discernible}} {{motion of}} each diaphragm flexure is very small, {{but because of}} the folded structure, more air is moved than would be by a conventional cone or electrostatic driver of the same plotted surface area. As a matter of surface comparison, a standard 1 in AMT strip has a functional driver area comparable to an 8 in circular dynamic cone. The folded driver design, combined with the small motion range, means the AMT acts like a point source version of a larger driver, inherently resulting in lower sound reproduction distortion. As a result of its <b>motion</b> <b>pattern,</b> the AMT [...] "spits" [...] the air out in a way similar to the action of shooting a watermelon seed from your hand by squeezing it between thumb and forefinger. The speed of the air as it leaves the diaphragm is approximately five times faster than the speed of the actual driver structure, hence the name, Air Motion Transformer.|$|E
30|$|Starting from there, several {{possibilities}} {{exist for}} representing a <b>motion</b> <b>pattern</b> {{based on the}} sample trajectories. One solution is to compute a unique prototype trajectory for each <b>motion</b> <b>pattern,</b> by agglomerating the previously observed trajectories. For example, a stochastic representation of a <b>motion</b> <b>pattern</b> can be derived by computing the {{mean and standard deviation}} of the sample trajectories [[30]]. Another way to account for the variations in the execution of a <b>motion</b> <b>pattern</b> is to have several prototypes for each class, e.g. a subset of the training samples [[31]]. A different approach was proposed in [[32]], where the different behaviors were not represented by individual prototypes, but merged in a single graph structure, learned online using a Topology Learning Network.|$|E
30|$|The {{fundamental}} {{properties that}} are investigated {{in this paper}} hold for underwater snake robots that follow a sinusoidal <b>motion</b> <b>pattern.</b> In this section we present a general sinusoidal <b>motion</b> <b>pattern</b> for underwater snake robots proposed in [45] and a control law for making the joint angles track the resulting joint reference angles.|$|E
40|$|A {{study was}} {{undertaken}} to provide {{data on the}} three-dimensional tracking pattern of the patella, relative to the femur, in human knee-Joint specimens. For this purpose, a highly accurate roentgen stereophologrammetric analysis (RSA) method was applied. The three-dimensional <b>motion</b> <b>patterns</b> of the tibia and the patella were measured and represented in terms of three translations and three rotations each, during knee flexion in neutral (unloaded),endorotated, and exorotated pathways. We found that the patella displays complex but consistent three-dimensional <b>motion</b> <b>patterns</b> during flexion, which include flexion rotation, medial rotation, wavering tilt, and a lateral shift relative to the femur. The <b>motion</b> <b>patterns</b> are very much affected by tibial rotations accompanying flexion...|$|R
40|$|This work {{proposes a}} way to use a-priori {{knowledge}} on motion dynamics for markerless human motion capture (MoCap). Specifically, we match tracked <b>motion</b> <b>patterns</b> to training patterns in order to predict states in successive frames. Thereby, modeling the motion by means of twists allows for a proper scaling of the prior. Consequently, {{there is no need for}} training data of different frame rates or velocities. Moreover, the method allows to combine very different <b>motion</b> <b>patterns.</b> Experiments in indoor and outdoor scenarios demonstrate the continuous tracking of familiar <b>motion</b> <b>patterns</b> in case of artificial frame drops or in situations insufficiently constrained by the image data. 1...|$|R
40|$|The Information about cardiac {{mechanical}} {{performance is}} {{of critical importance}} in understanding the etiology of heart diseases. However, little {{work has been done}} to date, to understand the relationship of cardiovascular diseases to the global cardiac <b>motion</b> <b>patterns.</b> In this paper we address the problem of distinguishing between normal and abnormal <b>motion</b> <b>patterns</b> in cardiac echo videos. Specifically, we describe the overall motion of the heart using average velocity curves. We then detect characteristic patterns in these curves that help distinguish normal from abnormal <b>motion.</b> The <b>motion</b> <b>patterns</b> observed in normal and abnormal groups using the extracted features are found to be easily separable. 1...|$|R
40|$|The {{invention}} {{relates to}} a concept for reconstructing a motion {{of an object}} (302) from a sequence of <b>motion</b> <b>pattern</b> segments of a computer model of the object, wherein each <b>motion</b> <b>pattern</b> segment corresponds to a different time interval of the motion, and wherein the object (302) {{has at least one}} sampling point coupled to a position marker (304). A motion transition between a starting motion state and an end motion state of the object (302) in a time interval of the motion is recorded on the basis of position data of the at least one sampling point that are received from the position marker (304). Furthermore, at least one <b>motion</b> <b>pattern</b> segment corresponding to the motion transition is selected from a plurality of motion patterns of the computer model that are stored in a database (205), {{in such a way that}} the selected <b>motion</b> <b>pattern</b> segment leads from the starting motion state to the end motion state for the time interval with sufficient probability. In addition, a depiction of the motion of the object for the time interval is reconstructed by using the starting motion state and the selected <b>motion</b> <b>pattern</b> segment...|$|E
30|$|The {{remainder}} {{of this paper is}} organized as follows: firstly, in Section 2 we highlight some relevant works on <b>motion</b> <b>pattern</b> recognition and event detection in automatic video surveillance. Section 3 details the estimation of the Direction Model. Then Section 4 presents the <b>motion</b> <b>pattern</b> extraction algorithm using the direction model. In Section 5 we detail the event recognition module. We present the experiments and result of our <b>motion</b> <b>pattern</b> extraction and event detection approaches in Section 6. The experiments were performed using datasets retrieved from the web (such as PETS ([URL] and CAVIAR ([URL] datasets) and annotated by a human expert. Finally, we give our concluding remarks and discuss potential extensions of the work in Section 7.|$|E
30|$|Estimation of the {{reference}} <b>motion</b> <b>pattern</b> of a gesture and definition of primitive motion elements to be synthesized in real-time.|$|E
40|$|We {{propose a}} novel method for {{automatically}} discovering key <b>motion</b> <b>patterns</b> happening {{in a scene}} by observing the scene for an extended period. Our method does not rely on object detection and tracking, and uses low level features, the direction of pixel wise optical flow. We first divide the video into clips and estimate a sequence of flow-fields. Each moving pixel is quantized based on its location and motion direction. This is essentially a bag of words representation of clips. Once a bag of words representation is obtained, we proceed to the screening stage, using a measure called the ‘conditional entropy’. After obtaining useful words we apply Diffusion maps. Diffusion maps framework embeds the manifold points into a lower dimensional space while preserving the intrinsic local geometric structure. Finally, these useful words in lower dimensional space are clustered to discover key <b>motion</b> <b>patterns.</b> Diffusion map embedding involves diffusion time parameter which gives us ability to detect key <b>motion</b> <b>patterns</b> at different scales using multi-scale analysis. In addition, clips which are represented in terms of frequency of <b>motion</b> <b>patterns</b> can also be clustered to determine multiple dominant <b>motion</b> <b>patterns</b> which occur simultaneously, providing us further understanding of the scene. We have tested our approach on two challenging datasets and obtained interesting and promising results. 1...|$|R
40|$|This paper proposes an {{end-to-end}} {{system to}} recognize multi-person behaviors in video, unifying different tasks like segmentation, modeling and recognition {{within a single}} optical flow based motion analysis framework. We show how optical flow {{can be used for}} analyzing activities of individual actors, as opposed to dense crowds, which is what the existing literature has concentrated on mostly. The algorithm consists of two steps- identification of <b>motion</b> <b>patterns</b> and modeling of <b>motion</b> <b>patterns.</b> Activities are analyzed using the underlying <b>motion</b> <b>patterns</b> which are formed by the optical flow field over a period of time. Streaklines are used to capture these <b>motion</b> <b>patterns</b> via integration of the flow field. To recognize the regions of interest, we utilize the Helmholtz decomposition to compute the divergence potential. The extrema or critical points of this potential indicates regions of high activity in the video, which are then represented as <b>motion</b> <b>patterns</b> by clustering the streaklines. We then present a method to compare two videos by measuring the similarity between their <b>motion</b> <b>patterns</b> using a combination of shape theory and subspace analysis. Such an analysis allows us to represent, compare and recognize a wide range of activities. We perform experiments on state-of-the-art datasets and show that the proposed method is suitable for natural videos in the presence of noise, background clutter and high intra class variations. Our method has two significant advantages over recent related approaches it provides a single framework that takes care of both low-level and high-level visual analysis tasks, and is computationally more efficient than the competing approaches...|$|R
40|$|We {{present the}} {{biomimetic}} control scheme for the walking robot SCORPION. We used {{a concept of}} Basic <b>Motion</b> <b>Patterns,</b> which can be combined in a very flexible manner. In addition our modeling and simulation approach is described, which has been done based on the ADAMS(TM) simulator. Especially the <b>motion</b> <b>patterns</b> of real scorpions were analyzed and used for walking patterns and acceleration of the robot...|$|R
40|$|As a sub-task of {{the general}} gas source {{localisation}} problem, gas source tracing is supposed to guide a gas-sensitive mobile system towards a source by using the cues determined from the gas distribution sensed along a driven path. This paper reports on an investigation of a biologically inspired gas source tracing strategy. Similar to the behaviour of the silkworm moth Bombyx mori, the implemented behaviour consists of a fixed <b>motion</b> <b>pattern</b> that realises a local search, and a mechanism that (re-) starts this <b>motion</b> <b>pattern</b> if an increased gas concentration is sensed. While the moth uses the local airflow direction to orient the <b>motion</b> <b>pattern,</b> this is not possible for a mobile robot due to the detection limits of currently available anemometers. Thus, an alternative method was implemented that uses an asymmetric <b>motion</b> <b>pattern,</b> which is biased towards the side where higher gas sensor readings were obtained. The adaptated strategy was implemented and tested on an experimental platform. This paper describes the strategy and evaluates its performance {{in terms of the}} ability to drive the robot towards a gas source and to keep it within close proximity of the source...|$|E
40|$|Extremely crowded scenes present unique {{challenges}} to video analysis that cannot be addressed with conventional approaches. We present a novel statistical framework for modeling the local spatio-temporal <b>motion</b> <b>pattern</b> behavior of extremely crowded scenes. Our key insight is {{to exploit the}} dense activity of the crowded scene by modeling the rich motion patterns in local areas, effectively capturing the underlying intrinsic structure they form in the video. In other words, we model the motion variation of local spacetime volumes and their spatial-temporal statistical behaviors to characterize the overall behavior of the scene. We demonstrate that by capturing the steady-state motion behavior with these spatio-temporal <b>motion</b> <b>pattern</b> models, we can naturally detect unusual activity as statistical deviations. Our experiments show that local spatio-temporal <b>motion</b> <b>pattern</b> modeling offers promising results in realworld scenes with complex activities that are hard for even human observers to analyze. 1...|$|E
40|$|In this paper, a new {{methodology}} for optical flow estimation that {{is able to}} represent multiple motions is presented. To separate motions at the same location, a new frequency-domain approach is used. This model, based on a band-pass filtering {{with a set of}} logGabor spatio-temporal filters, groups together filter responses with continuity in its motion (each group will define a <b>motion</b> <b>pattern).</b> Given a <b>motion</b> <b>pattern,</b> the gradient constraints is applied to the output of each filter in order to obtain multiple estimates of the velocity at the same location. Then, the velocities at each point of the <b>motion</b> <b>pattern</b> are combined using probabilistic rules. The use of "motion patterns" allows to represent multiple motions, while the combination of estimates from different filters helps to reduce the initial aperture problem. This technique is illustrated on real and simulated data sets, including sequences with occlusion and transparencies...|$|E
40|$|We {{present a}} {{biomimetic}} control scheme for the walking robot SCORPION. We used {{the concept of}} Basic <b>Motion</b> <b>Patterns,</b> which can be combined in a very flexible mariner. Also reflexes are introduced to increase the reactivity. In addition our modeling and simulation approach is described, based on the ADAMS TM simulator. Especially the <b>motion</b> <b>patterns</b> of real scorpions were analyzed and used for walking patterns and smooth acceleration of the robot...|$|R
40|$|Object-to-camera motion {{produces}} {{a variety of}} apparent <b>motion</b> <b>patterns</b> that significantly affect performance of short-term visual trackers. Despite being crucial for designing robust trackers, their influence is poorly explored in standard benchmarks due to weakly defined, biased and overlapping attribute annotations. In this paper we propose to go beyond pre-recorded benchmarks with post-hoc annotations by presenting an approach that utilizes omnidirectional videos to generate realistic, consistently annotated, short-term tracking scenarios with exactly parameterized <b>motion</b> <b>patterns.</b> We have created an evaluation system, constructed a fully annotated dataset of omnidirectional videos and the generators for typical <b>motion</b> <b>patterns.</b> We provide an in-depth analysis of major tracking paradigms which is complementary to the standard benchmarks and confirms the expressiveness of our evaluation approach...|$|R
40|$|The final {{publication}} {{is available}} at Springer via [URL] paper presents an innovative solution based on Time-Of-Flight (TOF) video technology to <b>motion</b> <b>patterns</b> detection for real-time dynamic hand gesture recognition. The resulting system is able to detect motion-based hand gestures getting as input depth images. The recognizable <b>motion</b> <b>patterns</b> are modeled {{on the basis of}} the human arm anatomy and its degrees of freedom, generating a collection of synthetic <b>motion</b> <b>patterns</b> that is compared with the captured input patterns in order to finally classify the input gesture. For the evaluation of our system a significant collection of gestures has been compiled, getting results for 3 D pattern classification as well as a comparison with the results using only 2 D informatio...|$|R
