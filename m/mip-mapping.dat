20|32|Public
5000|$|... 90 million fully {{featured}} pixels/sec sustained fill rate for bilinear textures, with LOD <b>MIP-mapping,</b> Z-buffering, alpha-blending and fogging enabled).|$|E
50|$|Early drivers {{had some}} {{problems}} with Direct3D as well. In Unreal, for example, there were problems with distortions on the ground textures caused by a bug with the board's subpixel accuracy function. There were also some problems with <b>mip-mapping</b> causing flickering in textures. As drivers matured these problems disappeared.|$|E
50|$|Voodoo {{emulation}} is also emulated since PCem v10 and PCem v12, which {{added support}} for Voodoo 2 and various optimizations. However, there some shortcomings regarding Voodoo emulation {{such as the}} lack of <b>mip-mapping,</b> slightly wobbling triangles, lack of speed limiting, and wrong refresh rates on almost every resolution (except 640x480@60 Hz). As of PCem v11, a separate recompiler has been added for Voodoo emulation, making it faster to emulate the Voodoo graphics card.|$|E
5000|$|Perspective-correct <b>mip-mapped</b> {{texturing}} with chroma-key support ...|$|R
5000|$|... 800 million trilinear <b>mip-mapped,</b> textured, 16-bit texel, depth {{buffered}} pixels {{per second}} ...|$|R
5000|$|... 3 Million fully {{featured}} triangles/sec (Filtered, LOD <b>MIP-mapped,</b> Z-buffered, alpha-blended, fogging enabled, textured triangles).|$|R
50|$|This {{graphics}} processor {{was based on}} a region concept and had many similarities to Microsoft's Talisman architecture. The chip processed each region at a time and did on chip z-sorting and anti-aliasing. As a result, the chip did 24-bit floating point Z, sub-pixel anti-aliasing, order independent translucency, non-linear fogging and atmospheric effects and <b>MIP-Mapping.</b> Typically, such region based architectures are gated by the number of polygons that can be processed per region, but Oak claimed that there were no such limitations in the WARP 5.|$|E
5000|$|Nearest-neighbor {{interpolation}} is {{the simplest}} and crudest filtering method [...] - [...] it simply uses {{the color of the}} texel closest to the pixel center for the pixel color. While simple, this results in a large number of artifacts - texture 'blockiness' during magnification, and aliasing and shimmering during minification. This method is fast during magnification but during minification the stride through memory becomes arbitrarily large and it can often be less efficient than <b>MIP-mapping</b> {{due to the lack of}} spatially coherent texture access and cache-line reuse.|$|E
50|$|With AGAL, {{developers}} {{can write}} shaders that transform 3D models on the GPU (vertex shader), and shaders that render complex dynamic lighting {{effects on the}} GPU (pixel shader). AGAL also allows high-quality texture rendering with <b>mip-mapping.</b> AGAL is used extensively in Flash game engines such as Away3D and Flare3D for various effects. AGAL is commonly used to provide dynamic lighting, high dynamic ranging (HDR), alpha masking, multipass rendering, displacement mapping, and environment mapping. Flare3D extends AGAL with a proprietary Shader language called FLSL (FLare3D Shader Language), that makes writing Shader programs easier. HLAG {{is another example of}} a high-level Shader language that compiles into AGAL.|$|E
5000|$|... 750 million trilinear <b>mip-mapped,</b> textured, 16-bit texel, {{four by four}} {{sub-sample}} anti-aliased, depth buffered pixels {{per second}} ...|$|R
40|$|Figure 1. A visual {{representation}} of a virtual texture A virtual texture 2 is a <b>mip‐mapped</b> texture used as cache to allow a much higher resolution texture to be emulated for real‐time rendering, while only partly residing in texture memory. This functionality is already accessible with the efficient pixel shader capabilities available on the recent generations of commodity GPUs. In this chapter we will be discussing technical implications on engine design due to virtual textures use, content creation issues, results, performance and image quality. We will also cover several practical examples to highlight the challenges and to offer solutions. These include texture filtering, block compression, float precision, disk streaming, UV borders, <b>mip‐map</b> generation, LOD selection and more...|$|R
40|$|Texture mapping using trilinearly {{filtered}} <b>mip-mapped</b> data is {{efficient and}} looks {{much better than}} point-sampled or bilinearly filtered data. But trilinear filtering represents the projection of a pixel filter footprint from screen space into texture space as a square, when in reality the footprint may be long and narrow. Consequently, trilinear filtering severely blurs images on surfaces angled obliquely away from the viewer. This paper describes a new texture filtering technique called Feline (for Fast Elliptical Lines). Like other recent hardware anisotropic filtering algorithms, Feline uses an underlying space-invariant (isotropic) filter with <b>mip-mapped</b> data, and so can be built {{on top of an}} existing trilinear filtering engine. To texture a pixel, it uses this space-invariant filter at several points along a line in texture space, and combines the results. With a modest increase in implementation complexity over earlier techniques, Feline more accurately matches the desired projection of the pixel filter in texture space, resulting in images with fewer aliasing artifacts. Feline’s visual quality compares well against Elliptical Weighted Average, the best software anisotropic texture filtering algorithm known to date, but Feline requires much less setup computation and far fewer cycles for texel fetches. Finally, since it uses standard <b>mip-maps,</b> Feline requires minimal extensions to standard 3 D interfaces like OpenGL...|$|R
40|$|Figure 1 : Some {{real-time}} {{results obtained}} with our method showing large ocean scenes with whitecaps under different wave and illumination conditions. The whitecap contribution is correctly averaged as the viewing distance increases. We present a scalable method to procedurally animate and render vast ocean scenes with whitecaps on the GPU. The whitecap cov-erage {{on the ocean}} surface is determined using a wave deformation criteria which can be pre-filtered linearly. This allows us {{to take advantage of}} the fast <b>mip-mapping</b> and texture filtering capabilities of modern hardware and produce plausible and anti-aliased images for scales ranging from centimetric to planetary in real time...|$|E
40|$|Texture mapping is a {{fundamental}} feature of computer graphics image generation. In current PC-based acceleration hardware <b>MIP-mapping</b> with bilinear and trilinear filtering is a commonly used filtering technique for reducing spatial aliasing artifacts. The effectiveness of this technique in reducing image aliasing {{at the expense of}} blurring is dependent upon the MIP-map level selection and the associated calculation of screen-space to texture-space pixel scaling. This paper describes an investigation of practical methods for per-pixel and per-primitive level of detail calculation. This investigation was carried out as part of the design work for a screen-space rasterization ASIC. The implementations of several algorithms of comparable visual quality are discussed and a comparison is provided in terms of per-primitive and per-pixel computational costs...|$|E
40|$|We {{present a}} hardware-based, {{volumetric}} approach for rendering knit wear at very interactive rates. A single stitch {{is represented by}} a volumetric texture with each voxel storing the main direction of the strands of yarn inside it. We render the knit wear in layers using an approximation of the Banks model. Our hardware implementation allows specular and diffuse material properties to change from one voxel to the next. This enables us to represent yarn made up of different components or render garments with complicated color patterns. Furthermore, our approach can handle self-shadowing of the stitches, and can easily be adapted to also include view-independent scattering. The resulting shader lends itself naturally to <b>mip-mapping,</b> and requires no reordering of the base geometry, making it versatile and easy to use...|$|E
40|$|We study texture {{projection}} {{based on}} a four region subdivision: magnification, minification, and two mixed regions. We propose improved versions of existing techniques by providing exact filtering methods which reduce both aliasing and overblurring, especially in the mixed regions. We further present a novel texture mapping algorithm called FAST (Footprint Area Sampled Texturing), which not only delivers high quality, but also is efficient. By utilizing coherence between neighboring pixels, performing prefiltering, and applying an area sampling scheme, we guarantee a minimum number of samples sufficient for effective antialiasing. Unlike existing methods (e. g., <b>MIP-map,</b> Feline), our method adapts the sampling rate in each chosen <b>MIP-map</b> level separately to avoid undersampling in the lower level   for effective antialiasing and to avoid oversampling in the higher level  ¢¡¤ £ for efficiency. Our method {{has been shown to}} deliver superior image quality to Feline and other methods while retaining the same efficiency. We also provide implementation tradeoffs to apply a variable degree of accuracy versus speed...|$|R
40|$|In {{this paper}} we present the first {{practical}} method for importance sampling functions represented as spherical harmonics (SH). Given a spherical probability density function (PDF) {{represented as a}} vector of SH coefficients, our method warps an input point set to match the target PDF using hierarchical sample warping. Our approach is efficient and produces high quality sample distributions. As a by-product of the sampling procedure we produce a multi-resolution representation of the density function as either a spherical <b>mip-map</b> or Haar wavelet. By exploiting this implicit conversion we can extend the method to distribute samples according to {{the product of an}} SH function with a spherical <b>mip-map</b> or Haar wavelet. This generalization has immediate applicability in rendering, e. g., importance sampling the product of a BRDF and an environment map where the lighting is stored as a single high-resolution wavelet and the BRDF is represented in spherical harmonics. Since spherical harmonics can be efficiently rotated, this product can be computed on-the-fly even if the BRDF is stored in local-space. Our sampling approach generates over 6 million samples per second while significantly reducing precomputation time and storage requirements compared to previous techniques...|$|R
40|$|The goal of {{this thesis}} is to design a {{suitable}} method for lossy compression of heightmap terrain data. This method should accept blocks of float samples of dimensions 2 ^n x 2 ^n as an input, for which it {{should be able to}} perform progressive decompression of <b>mip-maps</b> (lower-resolution representations). It should keep the reconstructed data within a certain maximum per-sample error bound for each <b>mip-map</b> level. This bound should be in the unit of meters and adjustable by the user. Given these constraints, it should be as efficient as possible. Our method is inspired by the second generation of progressive wavelet-based compression scheme modified to satisfy the~maximum-error constraint. We simplified this scheme by factoring out unnecessary computations in order to improve the efficiency. Our method can compress a 256 x 256 block in about 30 ms and decompress it in about 2 ms. Thanks to these attributes, the method {{can be used in a}} real-time planet renderer. It achieves the compression ratio of 37 : 1 on the whole Earth 90 m/sample terrain dataset transformed and separated into square blocks, while respecting the maximum error of 5 m. Powered by TCPDF (www. tcpdf. org...|$|R
40|$|Filtering is {{critical}} for representing detail, such as color textures or normal maps, {{across a variety of}} scales. While <b>MIP-mapping</b> texture maps is commonplace, accurate normal map filtering remains a challenging problem because of nonlinearities in shading—we cannot simply average nearby surface normals. In this paper, we show analytically that normal map filtering can be formalized as a spherical convolution of the normal distribution function (NDF) and the BRDF, for a large class of common BRDFs such as Lambertian, microfacet and factored measurements. This theoretical result explains many previous filtering techniques as special cases, and leads to a generalization to a broader class of measured and analytic BRDFs. Our practical algorithms leverage a significant body of work that has studied lighting-BRDF convolution. We show how spherical harmonics can be used to filter the NDF for Lambertian and low-frequency specular BRDFs, while spherical von Mises-Fisher distributions can be used for high-frequency materials. ...|$|E
40|$|Volumetric textures {{are able}} to {{represent}} complex repetitive data such as foliage, fur and forests by storing one sample of geometry in a volumetric texel to be mapped onto a surface. This volume consists in samples of densities and reflectances stored in voxels. The texel can be prefiltered similarly to the <b>mip-mapping</b> algorithm, giving an efficient rendering in ray-tracing with low aliasing, using a single ray per pixel. Our general purpose is to extend the volumetric texture method {{in order to provide}} a convenient and efficient tool for modeling, animating and rendering highly complex scenes in ray-tracing. We illustrate our method with verdant landscapes such as forests and lawns. In our previous work, we have dealt with the multiscale volume representation and texel animation. In this paper, we show how to convert usual 3 D models into texels, and how to render texels mapped onto any mesh type. Solving these two issues makes the method usable for a designer. Key-words: volumet [...] ...|$|E
40|$|We present several {{techniques}} for efficiently gathering diffuse and specular reflection rays originating from hair, recently put in production at Rhythm & Hues. We refine the hair BRDFs from [Neulander 2004] {{into a new}} cone-shell model that is more generally applicable and realistic, yet remains simple and fast to evaluate. Next, we address the chief shortcoming of [Neulander 2004]’s hair occlusion model by coupling it with rigorous occlusion-testing of skin geometry. Finally, we deploy a per-strand shading cache to improve performance, adopting a filtering technique {{in the spirit of}} trilinear <b>mip-mapping.</b> For importance sampling, we can generate rays with density roughly proportional to our BRDF weight. 2 Assuming uniform incident radiance, full-sphere scattering would ideally draw ξ 1 from a Wigner Semicircle Distribution shifted to the interval [0, 1]. Since incident radiance varies in practice, we need a flatter distribution than this. Based on empirical trials, we selected a raised triangular distribution with a pdf of 4 9 (5 2 − |x − 1 2 |). We remap ξ from U(0, 1) as follows...|$|E
40|$|Texture mapping using trilinearly {{filtered}} <b>mip-mapped</b> data is {{efficient and}} looks {{much better than}} point-sampled or bilinearly filtered data. These properties have made it biquitous: trilinear filtering is offered on a $ 99 Nintendo 64 video game unit and on a multimillion dollar SGI InfiniteReality. But trilinear filtering represents the projectio n of a pixel filter footprint from screen space into texture space as a square, when in reality the footprint may be long and narrow. Consequently, trilinear filtering severely blurs mages on surfaces angled obliquely away from the viewer...|$|R
5000|$|G200 {{supported}} full 32-bit {{color depth}} rendering which substantially pushed the image quality upwards by eliminating dithering artifacts {{caused by the}} then-more-typical 16-bit color depth. Matrox called their technology Vibrant Color Quality (VCQ). The chip also supported features such as trilinear <b>mip-map</b> filtering and anti-aliasing (though this was rarely used). The G200 could render 3D at all resolutions supported in 2D. Architecturally, the 3D pipeline was laid out as a single pixel pipeline with a single texture management unit. The core contained a RISC processor called the [...] "WARP core", that implemented a triangle setup engine in microcode.|$|R
40|$|We {{present a}} {{technique}} for blending multiple images {{of an object}} into a single, view-dependent texture map for that object. This technique {{can be used for}} image-based rendering, when the object is known, or for "painting" a view-dependent texture map of an object. The technique provides a structured mechanism for combining images at different resolutions, producing a <b>mip-map</b> like structure with the different levels constructed from different images. The user controls the camera angles for which a given image is valid. The problem of gaps caused by self-occlusion and non-overlapping images is also dealt with. This technique is also suitable for use on an object that will be animated...|$|R
40|$|CSM with 7 x 7 blur and <b>mip-mapping</b> Figure 1 : Standard {{percentage}} closer filtering {{does not}} support tri-linear filtering and suffers from severe aliasing artifacts during minification. In contrast, Convolution Shadow Maps (CSM) enable tri-linear filtering of shadows and thereby achieve effective screen-space anti-aliasing. Additional convolution can hide shadow map discretization artifacts. We present Convolution Shadow Maps, a novel shadow representation that affords efficient arbitrary linear filtering of shadows. Traditional shadow mapping is inherently non-linear w. r. t. the stored depth values, due to the binary shadow test. We linearize the problem by approximating shadow test as a weighted summation of basis terms. We demonstrate the usefulness of this representation, and show that hardware-accelerated anti-aliasing techniques, such as tri-linear filtering, can be applied naturally to Convolution Shadow Maps. Our approach can be implemented very efficiently in current generation graphics hardware, and offers real-time frame rates. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 3 [Computer Graphics]: Picture/Image Generation–Bitmap and Frame Buffer Operations; I. 3. 7 [Computer Graphics]: Three-Dimensional Graphics an...|$|E
40|$|This paper {{presents}} {{a method of}} using texture mapping with <b>mip-mapping</b> to render a VLSI layout. Texture mapping is used to save already rasterized areas of the layout from frame to frame, and {{to take advantage of}} any hardware accelerated capabilities of the host platform. Mipmapping is used to select which textures to display so that the amount of information sent to the display is bounded, and the image rendered on the display is filtered correctly. Ad-ditionally, two caching schemes are employed. The first, used to bound memory consumption, is a general purpose cache that holds textures spatially close to the user's current viewpoint. The second, used to speed up the rendering process, is a cache of heavily used sub-designs that are precomputed so rasterization on the fly is not necessary. An experimental implementation shows that real-time navigation can be achieved on arbitrarily large designs. Results also show how this technique ensures that image quality does not degrade as the number of polygons drawn increases, avoiding the aliasing artifacts common in other layout systems...|$|E
40|$|International audienceSurface {{materials}} are commonly described by attributes stored in textures (for instance, color, normal, or displacement). Interpolation during texture lookup provides a continuous value field everywhere on the surface, {{except at the}} chart boundaries where visible discontinuities appear. We propose a solution to make these seams invisible, while still outputting a standard texture atlas. Our method relies on recent advances in quad remeshing using global parameterization to produce a set of texture coordinates aligning texel grids across chart boundaries. This property {{makes it possible to}} ensure that the interpolated value fields on both sides of a chart boundary precisely match, making all seams invisible. However, this requirement on the uv coordinates needs to be complemented by a set of constraints on the colors stored in the texels. We propose an algorithm solving for all the necessary constraints between texel values, including through different magnification modes (nearest, bilinear, biquadratic and bicubic), and across facets using different texture resolutions. In the typical case of bilinear magnification and uniform resolution, none of the texels appearing on the surface are constrained. Our approach also ensures perfect continuity across several <b>MIP-mapping</b> levels...|$|E
40|$|Procedural {{textures and}} image textures are commonplace in {{graphics}} today, finding uses {{in such places}} as animated movies and video games. Unlike image texture maps, procedural textures typically suffer from minification aliasing. I present a method that, given a procedural texture on a surface, automatically creates an anti-aliased version of the procedural texture. The new procedural texture maintains the original textures details, but reduces minification aliasing artifacts. This new algorithm creates an image pyramid similar to <b>MIP-Maps</b> to represent the texture. Whereas a <b>MIP-Map</b> stores per-texel color, however, my texture hierarchy stores weighted sums of reflectance functions, allowing a wider-range of effects to be anti-aliased. The stored reflectance functions are automatically selected based on {{an analysis of the}} different functions found over the surface. When the texture is viewed at close range, the original texture is used, but as the texture footprint grows, the algorithm gradually replaces the textures result with an anti-aliased one. This results in faster development time for writing procedural textures as well as higher visual fidelity and faster rendering. With the optional addition of authoring guidelines, the analysis phase can be sped up by as much as two orders of magnitude. Furthermore, I developed a method for handling pre-filtered integration of reflectance functions to anti-alias specular highlights. The normal-centric BRDF (NBRDF) allows for fast evaluation over a range of normals appearing on the surface of an object. The NBRDF is easy to implement on the GPU for real-time results and can be combined with procedural reduction maps for real-time procedural texture minification anti-aliasing. Ph. D. Committee Chair: Greg Turk; Committee Member: Blair MacIntyre; Committee Member: Irfan Essa; Committee Member: Jarek Rossigna...|$|R
40|$|This paper {{describes}} {{the architecture of}} a 3 -D Graphics Raster Processor called TAYRA. TAYRA consists of a Graphics Raster Pipeline with five major external interfaces: PCI Master/Target, Depth, Texture, Colour and Video Interfaces. The Graphics Raster Pipeline performs all the major OpenGL style raster functions: scan conversion of lines, spans, triangles and rectangles, perspective correction of texture co-ordinates, <b>mip-map</b> level of detail selection, and many other texture modes, alpha blending, and other functionalities. Further, through TAYRA's fast PCI to buffer access mechanisms it can do advanced stencilling, multi-pass antialiasing, and other algorithms; all accelerated in hardware with a sustained pixel write speed of 29 Mpixels/s (peak of 33 Mpixels/s). This translates to an estimated peak performance of 890 K/triangles/s for 25 pixel triangles...|$|R
40|$|Recent advancements in {{performance}} and programmability have made graphics hardware and important platform for performing general computation. In this research {{we examine the}} existing texture atlas methods available for the parameterization of triangulated meshed surfaces and show how they are limited with respect to processing surface data in graphics hardware. A new texture atlas method is proposed that is more amenable to graphics hardware allowing for seamless rendering as well as <b>mip-map</b> post-filtering. We further develop this parameterization method to be adaptable, allowing for the parameterization to be recomputed at interactive rates {{in the presence of}} both mesh deformations and changing surface signal information. Two new graphics hardware applications that used the new texture atlas scheme are discussed: a method for rendering real-time subsurface scattering effects, and a dynamic 3 D painting system...|$|R
40|$|Praca doktorska. Akademia Górniczo-Hutnicza im. Stanisława Staszica (Kraków), 2010. Zawiera bibliogr. Indeks. Dostępna także w wersji drukowanej. Tryb dostępu: Internet. Global Illumination, Applications, Light Transport Theory, Geometric Optics, Assumptions, Radiometric Quantities, Light Transport Equation, Surface Only Scattering, Volumetric Scattering Extension, Properties of Scattering Functions, Analytic Solutions, Simplifications, Image Formation, Importance, Integral Formulation, Image Function, Monte Carlo Methods, Statistical Concepts, Estimators of Integrals, Biased, Unbiased Methods, Variance Reduction Techniques, Multiple Importance Sampling, Russian Roulette, Splitting, Uniform Sample Placement, Quasi-Monte Carlo Integration, Desired Properties and Quality of Sample Sequences, Low Discrepancy Sequences, Randomized Quasi-Monte Carlo Sampling, Comparison of Monte Carlo, Quasi-Monte Carlo Integration, Limitations, Light Transport Algorithms, Ray Tracing vs. Other Algorithms, View Dependent vs. View Independent Algorithms, Ray Tracing Algorithms, Hardware Accelerated Rasterization, Radiosity Algorithms, Light Transport Paths, Classification, Construction of Paths, Local Path Sampling Limitation, Full Spectral Rendering, Necessity of Full Spectrum, Representing Full Spectra, Efficient Sampling of Spectra, Analysis of Selected Light Transport Algorithms, Path Tracing, Bidirectional, Metropolis Light Transport, Irradiance, Radiance Caching, Photon Mapping, Combined Light Transport Algorithm, Motivation, Merging of an Unbiased Algorithm with Photon Mapping, Parallel Rendering, Stream Processing, Stream Processing Basics, Extended Stream Machines with Cache, Stream Monte Carlo Integration, Parallel Ray Tracing, Algorithm Initialization, Scene Description, Frame Buffer, Output Stream, Multipass Rendering, Ray Tracing, Extended Stream Machine, Choice of Optimal Hardware, Shared Memory, Clusters of Individual Machines, Multiprocessor Machines, Graphics Processors, Future-proof Choice, Interactive Visualization of Ray Tracing Results, Required Server Output, Client, Server Algorithms, <b>MIP-mapping</b> Issues, Rendering Software Design, Implementation, Core Functionality Interface, Quasi-Monte Carlo Sampling, Ray Intersection Computation, Spectra, Colors, Extension Support, Procedural Texturing Language, Functional, Syntax, Semantic, Execution Model, Virtual Machine API, New Glossy Reflection Models, Properties of Reflection Functions, Derivation, Image Comparison, Full Spectral Rendering, Comparison of Rendering Algorithm...|$|E
40|$|This {{synthetic}} paper gathers {{and extends}} my previous ones at GI' 95, EWAS' 95 and EWR' 96 on ray-traced volumetric textures. It {{is a kind}} of summary of my (french) PhD. International audienceComplex repetitive scenes containing forests, foliage, grass, hair, or fur, are challenging for common modeling and rendering tools. The amount of data, the tediousness of modeling and animation tasks, and the cost of realistic rendering have caused such kind of scene to see only limited use even in high-end productions. We describe here how the use of volumetric textures is well suited to such scenes. These primitives can greatly simplify modeling and animation tasks. More importantly, they can be very efficiently rendered using ray tracing with few aliasing artifacts. The main idea, initially introduced by Kajiya and Kay [9], is to represent a pattern of 3 D geometry in a reference volume, that is tiled over an underlying surface much like a regular 2 D texture. In our contribution, the mapping is independent of the mesh subdivision, the pattern can contain any kind of shape, and it is prefiltered at different scales as for <b>MIP-mapping.</b> Although the model encoding is volumetric, the rendering method differs greatly from traditional volume rendering: A volumetric texture only exists in the neighborhood of a surface, and the repeated instances (called texels) of the reference volume are spatially deformed. Furthermore, each voxel of the reference volume contains a key feature which controls the reflectance function that represents aggregate intravoxel geometry. This allows for ray-tracing of highly complex scenes with very few aliasing artifacts, using a single ray per pixel (for the part of the scene using the volumetric texture representation). The major technical considerations of our method lie in the ray-path determination and in the specification of the reflectance function. Ce papier de synthese regroupe et etend mes papiers precedants a GI' 95, EWAS' 95 et EWR' 96 sur les textures volumiques en ray-tracing. C'est un peu un resume de ma these...|$|E
40|$|Texture caching {{systems are}} {{designed}} to overcome the texture budget limitations of 3 D games. Only the textures required to display the current scene are held in RAM. When new textures need {{to appear in the}} scene, they are loaded from a larger and slower repository, or they are dynamically generated. by Jonathan Blow WULFRAM, the multiplayer tank from Bolt Action Software. For example, textures can be pulled from disk into system RAM or downloaded from system RAM into the video RAM of a 3 D accelerator. Textures can be dynamically generated by combining illumination maps with unlit source textures. QUAKE {{was one of the first}} games to implement a texture caching system that interacts closely with the 3 D pipeline to cache graphics in an efficient manner (see References). DOOM cached textures as well, but its system was more of a solidstate approach, as was the data caching scheme in the 2 D side-scroller ABUSE. The source code to both ABUSE and DOOM is now available; see the References at the end of this article. This article is broken into two parts. First, we’ll discuss the nature of texture maps and the issues involved in implementing a texture cache. Then, we’ll look at some concrete implementations of caching systems used in games that are currently under development. Textures and <b>MIP-mapping</b> Texture storage is all about MIP-maps. MIP-maps are prefiltered versions of a texture map stored at varying resolutions. To simplify this discussion, we will focus on MIPmaps that are square and are a power-of-two in width (1 × 1, 2 × 2, 4 × 4,). We will speak of a MIP-map level (or MIP-level) as a nonnegative integer that describes the resolution of a MIP-map: a texture at MIP-map level n is 2 n texels square. MIP-level 0 is the smallest size at 1 × 1 texels, increasing with conceptually no upper bound (though we might voluntarily choose one to ease implementation) (Figure 1). Jonathan Blow is vice president of software development a...|$|E
40|$|Abstract. We {{demonstrate}} {{the use of}} highly parallel graphics processing units (GPUs) to accelerate the Superposition/Convolution (S/C) algorithm to interactive rates while {{reducing the number of}} approximations. S/C first transports the incident fluence to compute the total energy released per unit mass (TERMA) grid. Dose is then calculated by superimposing the dose deposition kernel at each point in the TERMA grid and summing the contributions to the surrounding voxels. The TERMA algorithm was enhanced with physically correct multi-spectral attenuation and a novel inverse formulation for increased performance, accuracy and simplicity. Dose deposition utilized a tilted poly-energetic inverse cumulative-cumulative kernel, with the novel option of using volumetric <b>mip-maps</b> to approximate solid angle ray-casting. Exact radiological path ray-casting decreased discretization errors. We achieved a speed-up of 34 x- 98 x over a highly optimized CPU implementation...|$|R
40|$|We {{present a}} new method based on GPU {{acceleration}} for real-time transparency and translucency rendering. Our method computes refraction {{at both the}} front and back sides of a transparent object, as well as internal reflection, thus delivering interactive realistic transparency effects on a commodity PC. The real-time performance is made possible by a new acceleration data structure, called geocube, that enables the use of GPU for fast ray-surface intersection testing. In addition, within the same framework, we introduce the novel use of the <b>mip-map</b> for a hierarchical representation of a sequence of key prefiltered environment maps to simulate translucency. By taking ray depth into account and using GPU to interpolate the key filtered maps to produce the desired blurring effects, we achieve real-time realistic translucency rendering of slightly scattering media that allows show-through of background details. © Springer-Verlag 2005. link_to_subscribed_fulltex...|$|R
40|$|Texture mapping is a {{technique}} for adding visual realism to the computer generated images. As the level of realism increases with the number and the resolution of textures, {{we are faced with}} the problem of limited texture memory space. Moreover, in order to alleviate the aliasing artefacts many graphics systems use the mipmapping technique which needs to store additionally the texture pyramid. We propose an algorithm for texture compression which is characterized by low computational complexity, random access to compressed data and the hierarchical texture representation. The proposed hierarchical texture compression algorithm (HiTC) is based on a block-wise approach, where each block is subject to the modified fractal compression method and is partly represented by Laplacian pyramid. This allows us to incorporate the <b>mip-map</b> structure into the compressed texture and perfectly suits for real-time computer graphics applications...|$|R
