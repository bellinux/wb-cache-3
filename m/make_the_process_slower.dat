1|10000|Public
40|$|A {{new image}} {{encryption}} {{scheme based on}} high dimensional compound chaotic systems is proposed in this paper. Common chaotic image encryption, will perform encryption algorithm on pixels one by one which <b>make</b> <b>the</b> <b>process</b> <b>slower,</b> {{in this paper we}} called logistic map to choose and encrypt appropriate number of pixels makes the algorithm swifter and much more reliable by enlarging the key length...|$|E
5000|$|The court opinion also {{fears that}} the {{activity}} of Manos Limpias can cause [...] "accusatory hypertrophy that may affect the right of defense and to <b>make</b> <b>the</b> <b>process</b> even <b>slower</b> and create a plurality of charges while they are not offended by the crime, they can not have in criminal proceedings a different interest to the Prosecutor [...] ".|$|R
40|$|One of the {{bottlenecks}} of <b>the</b> ontology construction <b>process</b> is <b>the</b> {{amount of}} work required with various figures {{playing a role in}} it: domain experts contribute their knowledge that has to be formalized by knowledge engineers {{so that it can be}} mechanized. As the gap between these roles likely <b>makes</b> <b>the</b> <b>process</b> <b>slow</b> and burdensome, this problem may be tackled by resorting to machine learning tech- niques. By adopting algorithms from inductive logic programming, the effort of the domain expert can be reduced, i. e. he has to label individual resources as instances of the target concept. From those labels, axioms can be induced, which can then be confirmed by the knowledge engineer. In this chapter, we survey existing methods in this area and illustrate three different algorithms in more detail. Some basics like refinement operators, decision trees and information gain are described. Finally, we briefly present implementations of those algorithms...|$|R
40|$|Abstract- BP {{neural network}} is {{generally}} serially trained by one machine. But massive training data <b>makes</b> <b>the</b> <b>process</b> <b>slow,</b> costing too much system resources. For these problems, one effective {{solution is to}} use the MapReduce framework to do the distributed training. Some methods have been proposed, but it is still very slow when facing the neural network with complex structure. This paper presents a new method for BP neural network training based on MapReduce, MR-TMNN (MapReduce based Training in Mapper Neural Network). This method puts most of <b>the</b> training <b>process</b> into Mappers, and then emits the variations of weights and thresholds to Reducer <b>process</b> to do <b>the</b> batch update. It can effectively reduce the volume of intermediate data created by Mappers, reducing the cost of I/O, thereby accelerating training speed. Experimental results show that MR-TMNN has a better convergence without losing too much accuracy, comparing with conventional training method, and it still performs well with the complexity of neural network structure increasing. Index Terms- MapReduce, backprogation, neural network, intermediate data...|$|R
5000|$|Overcome, Brock {{falls into}} a shark tank. He quickly discovers that he can now [...] "breathe" [...] in water but not in air. There are difficulties: the higher density of water <b>makes</b> <b>the</b> {{breathing}} <b>process</b> <b>slow</b> and laborious, normal speech is rendered impossible, the liquid environment is too cold for his body, and he tires easily, since his lungs cannot extract as much oxygen from the water as his metabolism is used to.|$|R
40|$|Abstract. One of the {{problems}} with proposals for substantial institutional change in water systems is that modification and irreversibility <b>make</b> <b>the</b> <b>process</b> <b>slow,</b> cautious and costly to society. In this paper, we discuss the role that experimental economics can play in evaluating proposed institutional changes to help facilitate a more rapid and smooth adoption of changes in the water system. Exper-imental economics yields a formal and replicable system for analyzing alternative market structures before they are actually implemented. For example, a water market can be developed and tested in the laboratory under supply and demand constraints that reflect drought conditions that might occur in California, or other arid regions in the world. We present a prototype of a California water transfer model and the results from a series of water market experiments. Results include realized market efficiency and surplus distribution, as well as an analysis of market price volatility. The implications of this research extend well beyond California water markets, not only to water markets in other arid regions, but also to the design of markets for other environmental goods, including tradable pollution permits and fishery ITQs...|$|R
30|$|Self-reporting {{is used as}} a {{subjective}} measure of usability study of technology solutions. In assistive technology research, more than often the ‘a coordinator’ directly assist the ‘subject’ in <b>the</b> scoring <b>process.</b> This <b>makes</b> <b>the</b> rating <b>process</b> <b>slower</b> and also introduces bias, such as, ‘Forer effect’ and/or ‘Hawthorne’ effect. To address these issues we propose to use technology mediated interaction between the ‘subject’ and ‘the coordinator’ in evaluating assistive technology solutions. The goal is to combine both the qualitative and quantitative scores to create a relatively unbiased rating system. Empirical studies were performed on two different datasets in order to illustrate the utility of the proposed approach. It was observed that, the proposed hybrid rating is relatively unbiased for usability study.|$|R
40|$|Amniotic Fluid Embolism (AFE) {{is a rare}} {{complication}} of the intra- and early post-partum period, which may also be encountered with cesarean delivery and during abortions. Its symptompatology includes respiratory distress with cyanosis, shock and possibly tonic-clonic seizures. Disseminated intravascular coagulation (DIC) frequently occurs and is usually fatal. The aim of this case report is to present the positive outcome and our gained experience from two cases suffering from AFE. Thus, we analyze the case of two patients, in the second trimester of pregnancy who presented symptoms of AFE. Our study reveals {{that in the case}} of patients with AFE, early diagnosis, prompt management and proper treatment increase survival rate and may ensure complete recovery in a relatively short period of time. However, DIC is a serious aggravating factor which <b>makes</b> <b>the</b> recovery <b>process</b> <b>slower...</b>|$|R
40|$|Students need {{to consult}} their {{problems}} such as final projects, academic problem, or personal problems to their lecturers. This consultation’s processes are helped by administrative staffs that <b>make</b> <b>the</b> <b>processes</b> relatively <b>slow</b> due to the high workload of the staffs. Therefore, this research tries {{to address this problem}} by creating intranet based information system to reduce the role of administrative staffs. This system provide several features such as schedule the regular consultation by lecturers, schedule the addition consultation by lecturers, cancel scheduled consultations, change the schedule of consultations by lecturers, register for consultation by students, record the implementation consulting by lecturers, and reports. The consultation software was implemented at Informatics Engineering department, University ‘X’ for one month. After one month, a test was conducted involving five lecturers and twenty students. Testing result showed that <b>the</b> consultation <b>process</b> becomes more efficient, effective and satisfying...|$|R
40|$|Iris {{recognition}} {{is regarded as}} a most reliable and accurate biometric identification system. Daugman’s Integro-differential operator is a linear search method which <b>makes</b> <b>the</b> identification <b>process</b> extremely <b>slow</b> as well as increases the false acceptance rate beyond an acceptable range. The present work uses distance regularized level set evolution (DRLSE) method on CASIA-V 3 -Interval database and applies a suitable algorithm to detect the iris from an image. The two techniques i. e., Daugman’s Integro-differential operator and DRLSE are compared based on accuracy and time taken to localize the iris...|$|R
40|$|Mining {{frequent}} patterns {{has always}} been a great field of research for investigators. Various algorithms were developed for finding out frequent patterns in an efficient manner. But the major drawback of all these researches is the increased number of database scans. Partition algorithm is one of the approaches for mining frequent patterns but the large number of database scans required in thisalgorithm <b>makes</b> <b>the</b> mining <b>process</b> <b>slow.</b> Few developments have succeeded in reducing the number of database scans to two. Here an attempt has been made to develop a K-Partition algorithm which requires one database scan. Whole database is compressed in the form of Karnaugh Map, having very small size i. e. a fraction of the whole database. Then partition algorithm can be used to identify frequent patterns using K-Map model. Thus this approach brings efficiency in terms of time taken by processor for mining frequent patterns...|$|R
40|$|Abstract — Adopting an Information Communication and Technology (ICT) {{system in}} an {{organization}} is somewhat challenging. User diversity, heavy workload, and different skill gap <b>make</b> <b>the</b> ICT adoption <b>process</b> <b>slower.</b> This research starts from a condition that a conventional ICT learning through short workshop and guidance book is not working well. This research proposes a model called ICT instruction design model (ICT-IDM). This model provides fast track learning through integration between multimedia learning and self-paced hands-on E-learning. Through this case study, we discovered that the proposed model provides 27 % rapid learning adoption rather than conventional learning model...|$|R
40|$|Iris {{recognition}} {{is regarded as}} the most reliable and accurate biometric identification system. Most commercial iris recognition systems use patented algorithms developed by Daugman and these algorithms are able to produce perfect recognition rates. These algorithms are based on linear search methods which <b>make</b> <b>the</b> identification <b>process</b> extremely <b>slow</b> and also raise the false acceptance rate beyond the acceptable range. The proposed iris recognition approach consists of an automatic segmentation system that is based on the various algorithms and is able to localise the circular iris and pupil region, occluding eyelids and eyelashes and reflections. Our proposed method has shown out performing results than existing Houghman algorithms...|$|R
40|$|Abstract- Travelling {{salesman}} problem (TSP) {{is one of}} {{the most}} popular real world combinatorial optimization problem in which we have to find a shortest possible tour that visits each city exactly once and come back to starting city. It ranges among NP hard problem so it is often used as a benchmark for optimization techniques. In this paper a hybrid of Ant Colony Optimization (ACO) and Cuckoo Search (CS) algorithm is proposed for travelling salesman problem. ACO is good metaheuristic algorithm but drawback of this algorithm is that, the ant will walk through the path where the chemical substances called pheromone density is high. It <b>makes</b> <b>the</b> whole <b>process</b> <b>slow</b> hence CS is employed to carry out the problem of local search of ACO. Cuckoo search uses single parameter apart from the population size because of this reason it works efficiently and performs local search more efficiently. The performance of new hybrid algorithm is compared with ACO. The result shows that new hybrid algorithm is better and efficient than simple ACO algorithm...|$|R
40|$|Digital mammogram is {{the only}} {{effective}} screening method to detect the breast cancer. Gray Level Co-occurrence Matrix (GLCM) textural features are extracted from the mammogram. All the features are not essential to detect the mammogram. Therefore identifying the relevant feature is {{the aim of this}} work. Feature selection improves the classification rate and accuracy of any classifier. In this study, a new hybrid metaheuristic named Ant-Cuckoo Colony Optimization a hybrid of Ant Colony Optimization (ACO) and Cuckoo Search (CS) is proposed for feature selection in Digital Mammogram. ACO is a good metaheuristic optimization technique but the drawback of this algorithm is that the ant will walk through the path where the pheromone density is high which <b>makes</b> <b>the</b> whole <b>process</b> <b>slow</b> hence CS is employed to carry out the local search of ACO. Support Vector Machine (SVM) classifier with Radial Basis Kernal Function (RBF) is done along with the ACO to classify the normal mammogram from the abnormal mammogram. Experiments are conducted in miniMIAS database. The performance of the new hybrid algorithm is compared with the ACO and PSO algorithm. The results show that the hybrid Ant-Cuckoo Colony Optimization algorithm is more accurate than the other techniques...|$|R
40|$|Motor vehicle {{accidents}} {{are one of}} the main killers on the road. Modern vehicles have several safety features to improve the stability and controllability. The tire condition is critical to the proper function of the designed safety features. Under or over inflated tires adversely affects the stability of vehicles. It is generally the vehicle 2 ̆ 7 s user responsibility to ensure the tire inflation pressure is set and maintained to the required value using a tire inflator. In the tire inflator operation, the vehicle 2 ̆ 7 s user sets the desired value and the machine has to complete the task. During <b>the</b> inflation <b>process,</b> <b>the</b> pressure sensor does not read instantaneous static pressure to ensure the target value is reached. Hence, the inflator is designed to stop repetitively for pressure reading and avoid over inflation. This <b>makes</b> <b>the</b> inflation <b>process</b> <b>slow,</b> especially for large tires. This paper presents a novel approach using artificial neural network based technique to identify the tire size. Once the tire size is correctly identified, an optimized inflation cycle can be computed to improve performance, speed and accuracy of <b>the</b> inflation <b>process.</b> <b>The</b> developed neural network model was successfully simulated and tested for predicting tire size from the given sets of input parameters. The test results are analyzed and discussed in this paper...|$|R
30|$|Having too few {{features}} {{within a}} feature vector will most often result in classification failure even {{when using the}} best of classifiers. On the other hand, having a very large feature vector will <b>make</b> <b>the</b> classification <b>process</b> <b>slow</b> and is not guaranteed to increase classification accuracy. This is especially true if the feature vector contains large amounts of redundant data. To solve this issue, a dimensionality reduction (DR) [40] technique is proposed {{to reduce the size}} of the feature vector, improving classification efficiency without compromising recognition accuracy. Principal component analysis (PCA) [22] is a technique that is used to transform existing features into a newly reduced set of features. PCA has widely been used for face and expression recognition [23, 41] with good accuracy and more recently has also been used as a DR technique [7, 14, 42, 43]. Using PCA, a covariance data matrix is used to compute eigenvectors for a set of data. A linear weighted combination of the topmost few eigenvectors is used to approximate each input feature. All the eigenvectors define the eigenspace, and each eigenvalue defines its corresponding axis of variance. Eigenvalues that are close to zero are discarded as they do not contain much discriminative information. The eigenvectors associated with the top eigenvalues define the reduced subspace, and the original feature vector can be projected onto this subspace to reduce its size.|$|R
5000|$|She and Her Cat was {{wrote and}} {{directed}} by Makoto Shinkai, who also provided {{the voice of the}} cat. He had the idea in 1997, but started it in 1998 while he was working as a graphic designer at Falcom, a video game company. Because he experimented with computer graphic animation during his work, he wanted to minimize complex procedures. So he opted to do a black and white film since a colored-one would use three times as much space in the computer and it would also <b>make</b> <b>the</b> <b>process</b> three times <b>slower.</b> He was working on a role-playing game, whose genre is known to have [...] "very rich and detailed" [...] surroundings, and this influenced the film's background details. He also took pictures of cityscapes and the streets, and used them as a basis for his hand-drawn animations. The composition of 3D scenes was done with Adobe After Effects and for other effects Shade, Illustrator and LightWave were used.|$|R
40|$|We {{investigate}} {{the applicability of}} image analysis {{to the problem of}} minefield detection using airborne remote sensing images. We have applied different image processing methods for the detection of minefields, minefield indicators and individual mines. The proposed algorithms involve the extraction of linear features (roads, paths, fences, wires, [...] .), detection of periodic patterns (e. g. regular minefields, regularly placed minefield indicators) and segmentation of the image in regions of interest. Different scales of airborne images (1 / 500 and 1 / 2000) have been investigated. The algorithms have been applied on images of a test field in Belgium and real minefields in Mozambique. Introduction Minefield detection is usually carried out using shortrange ground-based sensors. These are sometimes fairly effective, but without large-area coverage capability, which <b>makes</b> <b>the</b> whole <b>process</b> very <b>slow.</b> On <b>the</b> other hand, recent developments in airborne remote sensing open new perspectives for [...] ...|$|R
40|$|Abstract—Data {{races in}} multi-threaded {{programs}} are a com-mon source of serious software failures. Their undefined behavior {{may lead to}} intermittent failures with unforeseeable, and in embedded systems, even life-threatening consequences. To mit-igate these risks, various detection tools have been created to help identify potential data races. However, these tools produce thousands of data race warnings, often in text-based format, which <b>makes</b> <b>the</b> manual assessment <b>process</b> <b>slow</b> and error-prone. Through visualization, we aim {{to speed up the}} data race assessment <b>process</b> by reducing <b>the</b> amount of information to be investigated, and to provide a versatile interface that quality as-surance engineers can use to investigate data race warnings. The ultimate goal of our integrated software suite, called RaceView, is to improve the usability of the data race information {{to such an extent that}} the elimination of data races can be incorporated into the regular software development process. Index Terms—multi-threading; static analysis; data race detec-tion; user interface; graph visualization; graph navigation I...|$|R
40|$|Potential {{applications}} {{of a novel}} system composed of two oppositely-charged (meth) acrylate copolymers, Eudragit® ЕРО (EPO) and Eudragit® S 100 (S 100), loaded with indomethacin (IND) in oral drug delivery were evaluated. The particles based on drug-interpolyelectrolyte complexes (DIPEC), (EPO-IND) /S 100, were prepared by mixing aqueous solutions of both copolymers at fixed pH. Particles of drug-polyelectrolyte complex (DPC), (EPO-IND) have a positive zeta potential, pointing to the surface location of free EPO chains and IND bound to EPO sequences. The formation and composition of both DPC and DIPEC were established by gravimetry, UV-spectrophotometry, capillary viscosity and elemental analysis. The structure and solid state properties of the formulated DIPEC were investigated using FTIR/NIR, Raman spectroscopy, XRPD and modulated DSC. DIPEC is a chemically homogenous material, characterized by a single Tg. DIPEC have an IR absorption band at 1560 cm− 1, which can be assigned to the stretching vibration of the carboxylate groups (S 100, IND) that form ionic bonds with the dimethylamino groups of EPO. XRPD, NIR and Raman-shifts confirm that during {{the preparation of this}} formulation, IND is converted into its amorphous form. The release of IND from DPC EPO/IND (3 : 1) and DIPEC EPO/L 100 /IND (4. 5 : 1 : 1) is sustained and is completed within 7 hours under GIT mimicking conditions. However, S 100 within DIPEC <b>makes</b> <b>the</b> release <b>process</b> <b>slower</b> making this system suitable for colon-specific delivery. Finally, DPC and DIPEC with indomethacin were used to prepare tablets, which can be potentially used as oral dosage forms for their slower indomethacin release in case of DIPEC which could be suitable for sustained delivery...|$|R
40|$|International audienceConfiguration is a {{recurring}} problem in many domains. In our earlier work, {{we focused on}} architecture-level configuration of largescale embedded software systems and proposed a methodology that enables engineers to configure products by instantiating a given reference architecture model. Products have to satisfy a number of constraints specified in the reference architecture model. If not, the engineers have to backtrack their configuration decisions to rebuild a configured product that satisfies the constraints. Backtracking configuration decisions <b>makes</b> <b>the</b> configuration <b>process</b> considerably <b>slow.</b> In this paper, we improve our earlier work and propose a backtrack-free configuration mechanism. Specifically, given a cycle-free generic reference architecture model, we propose an algorithm that computes an ordering over configuration parameters that yields a consistent configuration without any need to backtrack. We evaluated our approach on a simplified model of an industrial case study. We show that our ordering approach eliminates backtracking. It reduces the overall configuration time by both reducing the required number of value assignments, and reducing {{the time that it}} takes to complete one configuration iteration. Furthermore, we show that the latter has a linear growth with the size of the configuration problem...|$|R
40|$|Purpose - In {{spite of}} facilitating and {{motivating}} {{factors in the}} external environment, the implementation of new management-accounting techniques as activity-based costing (ABC) in companies is disappointing. The aim {{of the study is}} to determine factors that catalyse, facilitate and motivate the decision to implement ABC in Jordanian industrial companies. Additional objectives include determining the problems associated with ABC implementation and assessing the degree of success of ABC implementation in Jordan. Design/methodology/approach - A sample of the Jordanian industrial companies was selected and a questionnaire survey was employed using a five-point Likert scale to collect data from the financial managers, descriptive and analytical statistics were used to analyze the collected data. Findings - The findings indicate that the most important factor that facilitates the decision to implement ABC was the provision of adequate training and the most influential factors which motivate <b>the</b> <b>process</b> of ABC implementation include an increasing proportion of overhead costs, and an increasing number of product variants. Consequently, this study found that the interaction of three types of factors (catalysts, facilitators and motivators) create the potential for change in these companies. Barriers to change could <b>make</b> <b>the</b> change <b>process</b> <b>slower,</b> hindering, and even preventing change; and barriers to change were identified that may explain the differing implementation rates of ABC in the Jordanian industrial sector. The greatest barrier to implementing ABC was found to be its high cost of implementation, followed by the high cost of ABC consultancy and computer staff time. Originality/value - The study adds new elements to the institutional approach, and integrates it with concepts from psychology and organizational culture, to create a better understanding of management accounting. The results of study contribute to existing knowledge in the area of understanding the factors which act as catalysts, facilitate, and motivate ABC innovation and of those factors that create barriers to ABC implementation in Jordan. No Full Tex...|$|R
50|$|In the past, {{letters rogatory}} could not usually be {{transmitted}} directly between the applicable courts, {{and had to}} be transmitted via consular or diplomatic channels, which could <b>make</b> <b>the</b> whole <b>process</b> very <b>slow.</b> There have been various international conventions in regard to service of process and taking of evidence. One of the earliest conventions to simplify the procedure of Letters Rogatory was the 1905 Civil Procedure Convention, signed at The Hague. Drafted only in French, it was only ratified by 22 countries. Later conventions, created after the institution of the Hague Conference on Private International Law, drafted in both English and French commanded more support. The Hague Service Convention, ratified in 1965, enabled designated authorities in each of the signatory states to transmit documents for service to each other, bypassing the diplomatic route. This convention has been ratified by 60 states including the United Kingdom and the United States, neither of whom had ratified the 1905 convention. The Hague Evidence Convention, ratified in 1970, formalised procedures for taking of evidence. This convention has been ratified by 43 states. For situations exclusively among Member States of the European Union, two regulations, 1348/2000 and 1206/2001 superseded the two Hague Conventions. These two regulations apply to each of the Member States of the European Union with the exception of Denmark, which opted out.|$|R
40|$|The {{dissociation}} {{behavior of}} methane hydrate in the porous media were studied {{when the temperature}} was above the quadruple phase[Hydrate(H) -Water(L(W)) -Ice(I) -Vapor(V) ] point temperature. The silica gels were applied as the porous media for the experiments, in which the diameter ranges of the silica gel particles were 0. 105 - 0. 150, 0. 150 - 0. 200 and 0. 300 - 0. 450 mm, and the mean pore diameters, 9. 03, 12. 95, 17. 96 and 33. 20 nm, respectively. The dissociation experiments were carried out by depressurization in the temperature range of 269. 15 - 278. 15 K and the initial formation pressure range of 4. 1 - 11. 0 MPa. The experiments indicated that the dissociation rate of methane increases {{with the increase of}} the initial formation pressure, the decrease of the bath temperature, the decrease of the particle range and the increase of the mean pore diameter. For relative big the particle diameter, the water in some pores becomes ice in <b>the</b> dissociation <b>process,</b> which <b>makes</b> <b>the</b> dissociation <b>process</b> relatively <b>slow.</b> 利用定容降压方法测定了在不同多孔介质中甲烷水合物的分解实验数据,所使用的多孔介质平均孔径分别为 9. 03, 12. 95, 17. 96 和 33. 20 nm,其中孔径为 12. 95 nm的多孔介质采用了 3 个粒径范围,分别为 0. 105 ～ 0. 150, 0. 150 ～ 0. 200 和 0. 300 ～ 0. 450 mm;其它孔径的多孔介质的粒径范围为 0. 105 ～ 0. 150 mm. 在封闭的条件下测定了不同温度与不同初始生成压力下甲烷水合物的分解实验数据（实验温度范围为 269. 15 ～ 278. 15 K,初始生成压力范围为 4. 1 ～ 11. 0 MPa）,结果表明,水合物的分解速度随着初始生成压力的增加和水浴温度的降低而升高,也随孔径的增加而升高,但随多孔介质粒径的增大而降低. 在孔径较大和分解温度较低时,多孔介质中水合物分解引起的温度降低会使水结冰,从而减缓水合物的分解速度. 国家自然科学基金（ 20773133 50874098 ）; 中科院知识创新工程重要方向项目（KGCX 2 -YW- 3 X 6 ） 中科院重大科研装备项目（YZ 200717 ）; 广东省科技计划项目（ 2009 B 050600006 ）; 国家“八六三”计划项目（ 2006 AA 09 A 209 ）; 国家“九七三”计划项目（ 2009 CB 219507...|$|R
40|$|Disruptions rarely {{occur in}} supply chains, but their {{negative}} financial and technical impacts <b>make</b> <b>the</b> recovery <b>process</b> very <b>slow.</b> In this paper, we propose a capacitated supply chain network design (SCND) model under random disruptions both in facility and transportation, {{which seeks to}} determine the optimal location and types of distribution centers (DC) and also the best plan to assign customers to each opened DC. Unlike other studies in the extent literature, we use new concepts of reliability to model the strategic behavior of DCs and customers at the network: (1) Failure of DCs might be partial, i. e. a disrupted DC might {{still be able to}} serve with a portion of its initial capacity (2) The lost capacity of a disrupted DC shall be provided from a non-disrupted one and (3) The lost capacity fraction of a disrupted DC depends on its initial investment amount in the design phase. In order to solve the proposed model optimally, a modified version of Benders' Decomposition (BD) is applied. This modification tackles the difficulties of the BD's master problem (MP), which ultimately improves the solution time of BD significantly. The classical BD approach results in low density cuts in some cases, Covering Cut Bundle (CCB) generation addresses this issue by generating a bundle of cuts instead of a single cut, which could cover more decision variables of the MP. Our inspiration to improve the CCB generation led to a new method, namely Maximum Density Cut (MDC) generation. MDC is based on the observation that in some cases CCB generation is cumbersome to solve in order to cover all decision variables of the MP rather than to cover part of them. Thus the MDC method generates a cut to cover the remaining decision variables which are not covered by CCB. Numerical experiments demonstrate the practicability of the proposed model to be promising in the SCND area, also the modified BD approach decreases the number of BD iterations and improves the CPU times, significantly...|$|R
5000|$|<b>The</b> <b>process</b> is <b>slow</b> due to {{the need}} to stop the train after each segment and reverse the switch.|$|R
40|$|Adapting the use {{of writing}} {{stations}} to <b>the</b> Latin classroom <b>makes</b> <b>the</b> <b>process</b> of reading and editing {{an integral part of}} <b>the</b> <b>process</b> of language instruction and learning. Whether used in the foreign language classroom or the English classroom, {{the use of}} writing stations <b>makes</b> <b>the</b> <b>process</b> of editing and rewriting less tedious and less isolated...|$|R
40|$|A nonperturbative {{theory of}} multiphonon anharmonic {{transitions}} between energy levels {{of a local}} mode is presented. It is shown {{that the rate of}} transitions rearranges near the critical level number $n_{cr}$: at smaller $n$ <b>the</b> <b>process</b> <b>slows</b> down, while at larger $n$ it accelerates in time, causing a jump-like loss of energy followed by the generation of phonon bursts. Depending on parameters, phonons are emitted in pairs, triplets etc. Comment: submitted to Europhys. Let...|$|R
5000|$|Despite {{continued}} {{contacts with}} the colonialists and prospectors, in their relatively inaccessible terrain the Chimas in the forest region were largely undisturbed until the later {{half of the nineteenth}} century, when the government started selling off concessions to exploit their [...] "vacant" [...] lands for timber and grazing. <b>The</b> <b>process</b> <b>slowed</b> with <b>the</b> revolution of 1910, then picked up speed in the 1970s with fresh immigrants moving into the region, often assisted by the government.|$|R
5000|$|It is {{important}} to do <b>the</b> review which <b>make</b> <b>the</b> <b>process</b> reliable; ...|$|R
50|$|A saw set <b>makes</b> <b>the</b> <b>process</b> {{of setting}} <b>the</b> teeth easier, more {{consistent}} or both.|$|R
50|$|Some {{dressing}} {{of final}} application {{may be needed}} to <b>make</b> <b>the</b> <b>processes</b> more readily understandable.|$|R
50|$|<b>The</b> <b>process</b> is far <b>slower</b> {{than that}} of Bessemer {{converter}} and thus easier to control and sample for quality assessment. Preparing a heat usually takes 8 h to 8 h 30 min to complete into steel. As <b>the</b> <b>process</b> is <b>slow,</b> {{it is not necessary}} to burn all the carbon away as in Bessemer <b>process,</b> but <b>the</b> <b>process</b> can be terminated at any given point when desired carbon contents has been achieved.|$|R
30|$|SDGs: a) Develop {{accountable}} and transparent institutions. Foresight: <b>Make</b> <b>the</b> <b>process</b> transparent and publish the contents.|$|R
40|$|This note reports {{research}} {{undertaken to}} establish whether the factor price for labour has converged across {{regions of the}} European Union between 1980 and 1994. A Markov chain is employed to examine relative average regional pay for a cross-section of 57 EU regions. Results suggest average regional pay converged over the whole period. This finding supports the hypothesis that economically integrating economies face a progressively similar level of factor rewards. However, <b>the</b> <b>process</b> <b>slowed</b> around 1992 {{and the reason for}} this warrants investigation. ...|$|R
