1346|5302|Public
25|$|Although Jaffe's name {{is synonymous}} with {{clinical}} creatinine testing, his paper only described the principle behind what would later become the enduring method. It was Otto Folin (1867–1934), a Harvard biochemist, who adapted Jaffe's research—abandoning the standard Neubauer reaction of the time—and published several papers using the Jaffe reaction to analyze creatinine levels in both blood and urine. Folin began using the picric acid procedure in 1901 and included it in his 1916 Lab Manual of Biological Chemistry. During his career, Folin modified and improved several quantitative colorimetric procedures, {{the first of which}} was for creatinine. He took advantage of technology available at the time, using a Duboscq colorimeter for <b>measurement</b> <b>precision,</b> and is credited for introducing colorimetry into modern biochemical analysis.|$|E
25|$|A serious {{difficulty}} arises if the variables are not {{measured in the}} same units. First consider measuring distance between a data point and the curve – what are the measurement units for this distance? If we consider measuring distance based on Pythagoras' Theorem then {{it is clear that}} we shall be adding quantities measured in different units, and so this leads to meaningless results. Secondly, if we rescale one of the variables e.g., measure in grams rather than kilograms, then we shall end up with different results (a different curve). To avoid this problem of incommensurability it is sometimes suggested that we convert to dimensionless variables—this may be called normalization or standardization. However there are various ways of doing this, and these lead to fitted models which are not equivalent to each other. One approach is to normalize by known (or estimated) <b>measurement</b> <b>precision</b> thereby minimizing the Mahalanobis distance from the points to the line, providing a maximum-likelihood solution; the unknown precisions could be found via analysis of variance.|$|E
2500|$|Optical {{tests of}} the {{isotropy}} {{of the speed of}} light became commonplace. New technologies, including the use of [...] lasers and masers, have significantly improved <b>measurement</b> <b>precision.</b> (In the following table, only Essen (1955), Jaseja (1964), and Shamir/Fox (1969) are experiments of Michelson–Morley type, i.e. comparing two perpendicular beams. The other optical experiments employed different methods.) ...|$|E
40|$|We {{consider}} the probability by which quantum phase measurements {{of a given}} precision can be done successfully. The least upper bound of this probability is derived and the associated optimal state vectors are determined. The probability bound represents an unique and continuous transition between macroscopic and microscopic <b>measurement</b> <b>precisions.</b> Comment: 3 pages, 1 figure, completely revised, content unchange...|$|R
40|$|The aim of {{the present}} study was to compare <b>measurement</b> <b>precisions</b> of the Oswestry Back Pain Disability Questionnaire (ODQ) and a {{computer}} adaptive testing (CAT) method. The ODQ has been regarded as one of the most reliable condition-specific measure for back pain for decades. Cross-sectional study was carried out with two independent convenient samples from two out-patient rehabilitation clinics for back pain (n 1 = 42) and non-back pain group (...|$|R
40|$|A present {{research}} investigated if an IRT-scored forced-choice personality questionnaire {{has the same}} normative data structures as a similar version that uses a 5 -point Likert scale instead. The study was conducted using a sample of 349 training delegates who completed both an IRT-scored forced-choice and a normative single stimulus version of the questionnaire. Results largely supported the scaling properties, <b>measurements</b> <b>precision</b> and equivalence of the data structures of the two scoring methods. [URL]...|$|R
2500|$|In {{addition}} to feed-forward, PID controllers are often enhanced through {{methods such as}} PID gain scheduling (changing parameters in different operating conditions), fuzzy logic, or [...] Further practical application issues can arise from instrumentation connected to the controller. A high enough sampling rate, <b>measurement</b> <b>precision,</b> and measurement accuracy are required to achieve adequate control performance. Another new method for improvement of PID controller {{is to increase the}} degree of freedom by using fractional order. The order of the integrator and differentiator add increased flexibility to the controller.|$|E
2500|$|In March 2009, NASA mission Kepler was {{launched}} to scan {{a large number}} of stars in the constellation Cygnus with a <b>measurement</b> <b>precision</b> expected to detect and characterize Earth-sized planets. The NASA Kepler Mission uses the transit method to scan a hundred thousand stars in the constellation Cygnus for planets. [...] It was hoped {{that by the end of}} its mission of 3.5 years, the satellite would have collected enough data to reveal planets even smaller than Earth. By scanning a hundred thousand stars simultaneously, it was not only able to detect Earth-sized planets, it was able to collect statistics on the numbers of such planets around Sun-like stars.|$|E
5000|$|Minimum {{and maximum}} {{expected}} values and <b>measurement</b> <b>precision</b> (...) ...|$|E
50|$|Seismic {{noise is}} a {{nuisance}} for {{activities that are}} sensitive to vibrations, such as accurate <b>measurements,</b> <b>precision</b> milling, telescopes, and crystal growing. On the other hand, seismic noise does have some practical uses, for example to determine the low-strain dynamic properties of civil-engineering structures, such as bridges, buildings, and dams; or to determine the elastic properties of the soil and subsoil in order to draw seismic microzonation maps showing the predicted ground response to earthquakes.|$|R
5000|$|<b>Measurement</b> of <b>Precision</b> {{attained}} in Sampling, Bulletin de l'Institut International de Statistique,(1926) 22, Suppl. to Book 1, 1-62. Gallica (after p. 451) ...|$|R
40|$|The {{ultrasonic}} material evaluation {{has been}} applied to composite materials and nonhomogeneous materials. In quantitative evaluation of these materials the ultrasonic velocity and attenuation are widely used. In addition acoustoelastic stress <b>measurement</b> requires high <b>precision</b> <b>measurement</b> of the ultrasonic velocity...|$|R
5000|$|The angle <b>measurement</b> <b>precision</b> and {{accuracy}} {{is limited to}} slightly better than one arcsec.|$|E
50|$|Dilution of {{precision}} (DOP), or geometric dilution {{of precision}} (GDOP), {{is a term}} used in satellite navigation and geomatics engineering to specify the additional multiplicative effect of navigation satellite geometry on positional <b>measurement</b> <b>precision.</b>|$|E
50|$|EMF probes {{may respond}} to fields only on one axis, {{or may be}} tri-axial, showing {{components}} of the field in three directions at once. Amplified, active, probes can improve <b>measurement</b> <b>precision</b> and sensitivity but their active components may limit their speed of response.|$|E
50|$|Super-Kamiokande started {{collecting}} data in 1996 {{and has made}} several important <b>measurements.</b> These include <b>precision</b> <b>measurement</b> of the solar neutrino flux using the elastic scattering interactions, the first strong evidence for neutrino oscillations, and a more stringent limit on proton decay.|$|R
40|$|By {{using the}} {{experimental}} design (DoE) technique, we optimized an analytical method for {{the determination of}} mercury isotope ratios by means of cold-vapor multicollector ICP/MS (CV-MC-ICP/MS) to provide absolute Hg isotopic ratio measurements with a suitable internal precision. By running 32 experiments, the influence of mercury and thallium internal standard concentrations, total measuring time and sample flow rate was evaluated. Method was optimized varying Hg concentration between 2 and 20 ng g- 1. The model finds out some correlations within the parameters affect the <b>measurements</b> <b>precision</b> and predicts suitable sample <b>measurement</b> <b>precisions</b> for Hg concentrations from 5 ng g- 1 Hg upwards. The method was successfully applied to samples of Manila clams (Ruditapes Philippinarum) coming from the Marano and Grado lagoon (NE Italy), a coastal environment affected by long term mercury contamination mainly due to mining activity. Results show different extents of both mass dependent fractionation (MDF) and mass independent fractionation (MIF) phenomena in clams according to their size and sampling sites in the lagoon. The method is fit for determinations on real samples, allowing {{for the use of}} Hg isotopic ratios to study mercury biogeochemical cycles in complex ecosystems...|$|R
50|$|Super-Kamiokande started data {{taking in}} 1996 {{and has made}} several {{important}} <b>measurements.</b> These include <b>precision</b> <b>measurement</b> of the solar neutrino flux using the elastic scattering interaction, the first very strong evidence for atmospheric neutrino oscillation, and a considerably more stringent limit on proton decay.|$|R
50|$|However, not all curves can be {{measured}} in this way. A fractal is by definition a curve whose complexity changes with measurement scale. Whereas approximations of a smooth curve get closer and closer to a single value as <b>measurement</b> <b>precision</b> increases, the measured value of fractals may change wildly.|$|E
50|$|Some {{easier to}} check {{predictions}} {{of quantum mechanics}} are the prediction of negative Wigner functions for certain quantum states, <b>measurement</b> <b>precision</b> beyond the standard quantum limit using squeezed states of light or the asymmetry of the sidebands in the spectrum of a cavity near the quantum ground state.|$|E
5000|$|Optical {{tests of}} the {{isotropy}} {{of the speed of}} light became commonplace. New technologies, including the use of lasers and masers, have significantly improved <b>measurement</b> <b>precision.</b> (In the following table, only Essen (1955), Jaseja (1964), and Shamir/Fox (1969) are experiments of Michelson-Morley type, i.e. comparing two perpendicular beams. The other optical experiments employed different methods.) ...|$|E
50|$|Ultracold atoms {{are also}} used in {{experiments}} for <b>precision</b> <b>measurements</b> enabled by the low thermal noise and, in some cases, by exploiting quantum mechanics to exceed the standard quantum limit. In addition to potential technical applications, such <b>precision</b> <b>measurements</b> may serve as tests of our current understanding of physics.|$|R
5000|$|A common path {{alternative}} to the Twyman-Green interferometer is the scatterplate interferometer, invented by J.M. Burch in 1953. The Twyman-Green interferometer, a double path interferometer, is {{a variant of the}} Michelson interferometer that is commonly used to test the precision of optical surfaces and lenses. [...] Since reference and sample paths are divergent, this form of interferometer is extremely sensitive to vibration and to atmospheric turbulence in the light paths, both of which interfere with the optical <b>measurements.</b> <b>Precision</b> <b>measurements</b> of an optical surface are also extremely dependent {{on the quality of the}} auxiliary optics.|$|R
5000|$|... #Subtitle level 3: <b>Precision</b> <b>measurements</b> of trapped Rydberg atoms ...|$|R
50|$|Positive-displacement (PD) meters {{can measure}} both liquids and gases. Like turbine meters, PD flow meters work best with clean, non-corrosive, and non-erosive liquids and gases, {{although}} some models will tolerate some impurities. Because {{of their high}} accuracy, PD meters are widely used at residences to measure the amount of gas or water used. Other applications include: chemical injection, fuel <b>measurement,</b> <b>precision</b> test stands, high pressure, hydraulic testing, and similar precision applications.|$|E
50|$|UTSL {{allows the}} user to set the {{instruments}} ranges and clamps in order to guarantee the <b>measurement</b> <b>precision</b> and to prevent the measurements from exceeding the instrument clamp values. The current UTSL capabilities can cover c.a. 70% of the required test specification for ASIC testing. For the remaining 30% one could use the option of writing comments in an informal form as {{it was done in}} the past.|$|E
50|$|It was {{well-known}} {{to classical}} test theorists that <b>measurement</b> <b>precision</b> is not uniform across {{the scale of}} measurement. Tests tend to distinguish better for test-takers with moderate trait levels and worse among high- and low-scoring test-takers. Item response theory extends the concept of reliability from a single index to a function called the information function. The IRT information function is the inverse of the conditional observed score standard error at any given test score.|$|E
40|$|International audienceIn {{this paper}} we present our {{advances}} in the scattering measurement of low electromagnetic signature objects. The targets under test are spheroids of low relative permittivities and of sizes comparable to the wavelength. The measurements were carried-out at the experimental facility of the “Centre Commun de Ressources en Microondes” (CCRM) in a bistatic configuration and using a hard gating noise reduction system. The measurements were further assessed through comparisons to computations obtained with a Finite Element Method code. Thanks to a careful control of the experimental parameters, a good <b>measurements</b> <b>precision</b> is obtained even with such low scattering objects...|$|R
40|$|This paper {{describes}} the calibration of five consumer digital cameras in still and movie modes. The cameras tested include a digital SLR, a compact digital still, a digital camcorder and two DV camcorders. The self-calibrations in still and movie modes were conducted sequentially using a single calibration fixture and consistent camera station geometry to minimise {{the influence of}} external factors. The variations in image quality are discussed {{in relation to the}} image resolution and operation mode. The analysis of the results includes the relationships between the calibration parameters and the <b>measurement</b> <b>precisions</b> for the two modes...|$|R
5000|$|Special signals for Sound Technology or for Audio <b>Precision</b> <b>measurement</b> systems ...|$|R
50|$|In {{addition}} to feed-forward, PID controllers are often enhanced through {{methods such as}} PID gain scheduling (changing parameters in different operating conditions), fuzzy logic, or computational verb logic. Further practical application issues can arise from instrumentation connected to the controller. A high enough sampling rate, <b>measurement</b> <b>precision,</b> and measurement accuracy are required to achieve adequate control performance. Another new method for improvement of PID controller {{is to increase the}} degree of freedom by using fractional order. The order of the integrator and differentiator add increased flexibility to the controller.|$|E
5000|$|The Hallstatt plateau is a {{term used}} in {{archaeology}} that refers to a consistently flat area on graphs that plot radiocarbon dating against calendar dates. Radiocarbon dates of around 2450 BP (Before Present) always calibrate to ca. 800-400 BC, no matter the <b>measurement</b> <b>precision.</b> [...] The carbon 14 dating method is hampered by this large plateau on the calibration curve from ca. 800-400 BC (at 2450 BP), a critical period in human technological development. Just {{before and after the}} plateau, calibration is accurate; during the plateau only techniques like wiggle matching can yield useful calendar ages.|$|E
50|$|In March 2009, NASA mission Kepler was {{launched}} to scan {{a large number}} of stars in the constellation Cygnus with a <b>measurement</b> <b>precision</b> expected to detect and characterize Earth-sized planets. The NASA Kepler Mission uses the transit method to scan a hundred thousand stars in the constellation Cygnus for planets. It was hoped {{that by the end of}} its mission of 3.5 years, the satellite would have collected enough data to reveal planets even smaller than Earth. By scanning a hundred thousand stars simultaneously, it was not only able to detect Earth-sized planets, it was able to collect statistics on the numbers of such planets around Sun-like stars.|$|E
5000|$|... the Ultra-Stable Oscillator (USO) {{for high}} <b>precision</b> <b>measurement</b> of {{distance}} and communication ...|$|R
5000|$|<b>Precision</b> <b>measurements</b> of Forbush {{decrease}} events including rigidity {{dependence of}} its amplitude ...|$|R
50|$|Baldwin’s main {{contributions}} as {{a research}} scientist pertain to two related fields of physics: the use of laser techniques (in particular the generation of vacuum ultraviolet radiation <200 nm) for the <b>precision</b> <b>measurement</b> of atoms and molecules; {{and the use of}} laser cooling to trap and manipulate metastable helium atoms to study fundamental quantum physics and for <b>precision</b> <b>measurement.</b>|$|R
