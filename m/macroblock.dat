834|382|Public
50|$|A <b>macroblock</b> is the {{smallest}} independent unit of (color) video. Motion vectors (see below) operate solely at the <b>macroblock</b> level.|$|E
5000|$|... where N is {{the size}} of the macro-block, and [...] and [...] are the pixels being {{compared}} in current <b>macroblock</b> and reference <b>macroblock,</b> respectively.|$|E
50|$|Distinct {{from the}} {{division}} into transform blocks, a <b>macroblock</b> can be split into prediction blocks. In early standards such as H.261, MPEG-1 Part 2, and H.262/MPEG-2 Part 2, motion compensation is performed with one motion vector per <b>macroblock.</b> In more modern standards such as H.264/AVC, a <b>macroblock</b> can be split into multiple variable-sized prediction blocks, called partitions. In an inter-predicted <b>macroblock</b> in H.264/AVC, a separate motion vector is specified for each partition. Correspondingly, in an intra-predicted <b>macroblock,</b> where samples are predicted by extrapolating from {{the edges of}} neighboring blocks, the prediction direction that is specified on a per-partition basis. In H.264/AVC, prediction partition size ranges from 4×4 to 16×16 samples for both inter-prediction (motion compensation) and intra-prediction.|$|E
5000|$|P-frames {{can contain}} either intra <b>macroblocks</b> or {{predicted}} <b>macroblocks</b> ...|$|R
40|$|In ATM {{networks}} cell loss causes {{data to be}} dropped, {{which results}} {{in the loss of}} entire <b>macroblocks</b> when MPEG video is being transmitted. In order to reconstruct the missing data, the location of these <b>macroblocks</b> must be known. We describe a technique for packing ATM cells with compressed data, with the aim of detecting the location of missing <b>macroblocks</b> in the encoded video stream. This technique also permits proper decoding of correctly received <b>macroblocks,</b> and thus prevents the loss of ATM cells from affecting the decoding process. We also describe spatial and temporal techniques for the recovery of lost <b>macroblocks.</b> The spatial techniques fall into two categories: deterministic and statistical. A deterministic spatial approach we provide aims at reconstructing each lost pixel by spatial interpolation from the nearest undamaged pixels. Another, recovers lost <b>macroblocks</b> by minimizing inter-sample variations within each block and across its boundaries. In the statistical approac [...] ...|$|R
50|$|The {{number of}} luma samples is 16x16=256 {{times the number}} of <b>macroblocks</b> (and the number of luma samples per second is 256 {{times the number of}} <b>macroblocks</b> per second).|$|R
50|$|The basic {{processing}} {{unit of the}} design is called a <b>macroblock,</b> and H.261 was the first standard in which the <b>macroblock</b> concept appeared. Each <b>macroblock</b> consists of a 16×16 array of luma samples and two corresponding 8×8 arrays of chroma samples, using 4:2:0 sampling and a YCbCr color space. The coding algorithm uses a hybrid of motion-compensated inter-picture prediction and spatial transform coding with scalar quantization, zig-zag scanning and entropy encoding.|$|E
5000|$|Include some {{prediction}} modes {{that form}} a prediction of a motion region (e.g., a <b>macroblock</b> or a smaller area) by averaging the predictions obtained using two different previously decoded reference regions. Some standards allow two motion compensation vectors per <b>macroblock</b> (biprediction).|$|E
50|$|In video compression, {{a motion}} vector {{is the key}} element in the motion {{estimation}} process. It is used to represent a <b>macroblock</b> in a picture based on the position of this <b>macroblock</b> (or a similar one) in another picture, called the reference picture.|$|E
40|$|Abstract. This paper {{presents}} a early mode decision algorithm, which is proposed {{to reduce the}} complexity of the mode selection process for enhancement layers in H. 264 Scalable Video Coding. The proposed algorithm consists of the following three main steps. We firstly divide all the <b>macroblocks</b> into 4 classes according to the mode of collocated <b>macroblocks</b> in the base layer. Then, the <b>macroblocks</b> are subdivided with trained BP (Back Propagation) network according to the mode of neighboring <b>macroblocks.</b> Finally, we choose different mode selection algorithms for different divided cases, and check whether the algorithms are agreeable. Compared to JSVM 9. 18, experiment results show that, with this algorithm, 30 % encoding time can be saved with a negligible loss in BDSNR, and BDBR can be significantly reduced...|$|R
5000|$|The CIF [...] "image sizes" [...] were {{specifically}} {{chosen to}} be multiples of <b>macroblocks</b> (i.e. 16 × 16 pixels) {{because of the way}} that discrete cosine transform based video compression/decompression is handled. So, by example, a CIF-size image (352 × 288) corresponds to 22 × 18 <b>macroblocks.</b>|$|R
5000|$|... #Subtitle level 2: Bi-directional {{predicted}} (B) frames/slices (<b>macroblocks)</b> ...|$|R
50|$|Each <b>macroblock</b> {{in such a}} frame can be {{compensated}} using global motion (no further motion information is then signalled) or, alternatively, local motion (as if GMC were off). This choice, while costing an additional bit per <b>macroblock,</b> can improve prediction quality and therefore reduce residual.|$|E
5000|$|JPEG uses {{a single}} {{quantization}} step size per DC/AC component per color plane per image. JPEG XR allows a selection of DC {{quantization step size}}s on a tile region basis, and allows lowpass and AC quantization step sizes to vary from <b>macroblock</b> to <b>macroblock.</b>|$|E
5000|$|P-frames {{provide more}} {{compression}} than I-frames because they {{take advantage of}} the data in a previous I-frame or P-frame - a reference frame. To generate a P-frame, the previous reference frame is reconstructed, just as it would be in a TV receiver or DVD player. The frame being compressed is divided into 16 pixel by 16 pixel macroblocks. Then, for each of those macroblocks, the reconstructed reference frame is searched to find that 16 by 16 <b>macroblock</b> that best matches the <b>macroblock</b> being compressed. The offset is encoded as a [...] "motion vector." [...] Frequently, the offset is zero. But, if something in the picture is moving, the offset might be something like 23 pixels to the right and 4 pixels up. The match between the two macroblocks will often not be perfect. To correct for this, the encoder takes the difference of all corresponding pixels of the two macroblocks, and on that <b>macroblock</b> difference then computes the strings of coefficient values as described above. This [...] "residual" [...] is appended to the motion vector and the result sent to the receiver or stored on the DVD for each <b>macroblock</b> being compressed. Sometimes no suitable match is found. Then, the <b>macroblock</b> is treated like an I-frame <b>macroblock.</b>|$|E
5000|$|B-frames {{can contain}} intra, predicted, or bi-predicted <b>macroblocks</b> ...|$|R
50|$|Individual slices {{still have}} to be {{continuous}} horizontal regions of <b>macroblocks,</b> but with FMO's slice groups, motion compensation can take place within any contiguous <b>macroblocks</b> through the entire group; effectively, each slice group is treated as one or more contiguous shaped slices for the purposes of motion compensation.|$|R
40|$|Reverse {{playback}} is {{the most}} common video cassette recording (VCR) functions in many digital video players. However, the predictive processing techniques employed in MPEG severely complicate the reverse-play operation. In this paper, we enhance our previously proposed compressed-domain approach for the efficient reverse-play operation of an MPEG video streaming system. In the proposed video streaming server, a novel macroblock-based algorithm is used to adaptively select the necessary <b>macroblocks,</b> manipulate the <b>macroblocks</b> and send the processed <b>macroblocks</b> to the client machine. The proposed approach only manipulates <b>macroblocks</b> either on the VLC-domain or DCT-domain to achieve the server with low complexity. Experimental results show that, as compared to the conventional system and the previously proposed compressed-domain system, the new streaming system reduces the required network bandwidth and the decoding complexity significantly...|$|R
5000|$|The {{ability to}} use {{multiple}} motion vectors per <b>macroblock</b> (one or two per partition) with a maximum of 32 {{in the case of}} a B <b>macroblock</b> constructed of 16 4×4 partitions. The motion vectors for each 8×8 or larger partition region can point to different reference pictures.|$|E
50|$|<b>Macroblock</b> is a {{processing}} unit in image and video compression formats based on linear block transforms, {{such as the}} discrete cosine transform (DCT). A <b>macroblock</b> typically consists of 16×16 samples, and is further subdivided into transform blocks, and may be further subdivided into prediction blocks. Formats {{which are based on}} macroblocks include JPEG, where they are called MCU blocks, H.261, MPEG-1 Part 2, H.262/MPEG-2 Part 2, H.263, MPEG-4 Part 2, and H.264/MPEG-4 AVC. In H.265/HEVC, the <b>macroblock</b> as a basic {{processing unit}} has been replaced by the coding tree unit.|$|E
50|$|<b>Macroblock</b> {{encoding}} {{methods have}} been used in digital video coding standards since H.261 which was first released in 1988. However, for error correction and signal-to-noise ratio the standard 16x16 <b>macroblock</b> size is not capable of getting the kind of bit reductions that information theory and coding theory suggest are theoretically and practically possible.|$|E
30|$|A {{hybrid of}} bitstream-based and pixel domain quality {{estimator}} is proposed in[186]. It {{has been argued}} that a video quality estimation merely based on the amount of impaired <b>macroblocks</b> could be erroneous as, in modern video decoders, some error concealment methods are applied to cure the impaired <b>macroblocks</b> and this concealment is not accounted for in such estimations. As the error concealment may not always be effective, the proposed method uses motion intensity and luminance discontinuity measures to estimate the number of impaired <b>macroblocks</b> for which error concealment remains ineffective. In essence, the visual quality, in terms of MSE, is estimated directly based on the <b>macroblocks</b> for which the error concealment could not perform well. The same authors have generalized this approach for three methods of error concealment and a different value of packet length in[187].|$|R
50|$|The term <b>macroblocking</b> is {{commonly}} {{used to refer to}} block coding artifacts.|$|R
40|$|Abstract—When {{transmitting}} {{compressed video}} over a data network, {{one has to}} deal with how channel errors affect the decoding process. This is particularly a problem with data loss or erasures. In this paper we describe techniques to address this problem in the context of Asynchronous Transfer Mode (ATM) networks. Our techniques can be extended to other types of data networks such as wireless networks. In ATM networks channel errors or congestion cause data to be dropped, which results in the loss of entire <b>macroblocks</b> when MPEG video is transmitted. In order to reconstruct the missing data, the location of these <b>macroblocks</b> must be known. We describe a technique for packing ATM cells with compressed data, whereby the location of missing <b>macroblocks</b> in the encoded video stream can be found. This technique also permits the proper decoding of correctly received <b>macroblocks,</b> and thus prevents the loss of ATM cells from affecting the decoding process. The packing strategy can also be used for wireless or other types of data networks. We also describe spatial and temporal techniques for the recovery of lost <b>macroblocks.</b> In particular, we develop several optimal estimation techniques for the reconstruction of missing <b>macroblocks</b> that contain both spatial and temporal information using a Markov random field model. We further describe a sub-optimal estimation technique that can be implemented in real time. Index Terms—ATM, cell loss, cell packing, error concealment, motion vectors, Markov random field, spatial reconstruction, temporal reconstruction. I...|$|R
5000|$|<b>Macroblock</b> - The basic {{processing}} unit used in several previous video standards ...|$|E
50|$|In {{addition}} to the slice length and the <b>macroblock</b> address of the 1st <b>macroblock</b> (MB) of the slice, the slice parser (Figure 4) need to extract the Slice Group (SG) of each slice. These informations, together with the slice itself, are stored in DRAM. As in the ASO case, the list of pointers (Figure 4) should be generated.|$|E
5000|$|Scattered or {{dispersed}} slice groups, type 1: Every <b>macroblock</b> is {{a different}} slice. With two slice groups, it creates a checkerboard pattern; four or more groups also interleave rows, and with six slice groups, no <b>macroblock</b> will ever touch another from the same slice group in any direction, maximizing error concealment opportunities. No vector prediction is possible.|$|E
5000|$|... #Subtitle level 3: Association of <b>macroblocks</b> {{to slice}} and slices to group of slices ...|$|R
3000|$|... luma samples {{with the}} {{corresponding}} chroma samples. The <b>macroblocks</b> may be intra- or intercoded. In the intercoding process, the <b>macroblocks</b> are further divided into sub-macroblock partitions of several different sizes for effective motion estimation. In the intracoding process, the spatial prediction based on neighboring decoded pixels {{in the same}} slice will be applied. The residual data will be divided into [...]...|$|R
40|$|When {{transmitting}} {{compressed video}} over a data network, {{one has to}} deal with how channel errors affect the decoding process. This is particularly a problem with data loss or erasures. In this paper we describe techniques to address this problem in the context of Asynchronous Transfer Mode (ATM) networks. Our techniques can be extended to other types of data networks such as wireless networks. In ATM networks channel errors or congestion cause data to be dropped, which results in the loss of entire <b>macroblocks</b> when MPEG video is transmitted. In order to reconstruct the missing data, the location of these <b>macroblocks</b> must be known. We describe a technique for packing ATM cells with compressed data, whereby the location of missing <b>macroblocks</b> in the encoded video stream can be found. This technique also permits the proper decoding of correctly received <b>macroblocks,</b> and thus prevents the loss of ATM cells from affecting the decoding process. The packing strategy can also be used for wireless [...] ...|$|R
5000|$|TYPE — {{identifies}} type of <b>macroblock</b> (intra frame, inter frame, bi-directional inter frame) ...|$|E
5000|$|In a video encoder, each record may be 256 pixels {{forming a}} <b>macroblock</b> of data; or ...|$|E
5000|$|SI‑frames/slices (Switching I): Facilitates {{switching}} between coded streams; contains SI-macroblocks (a special type of intra coded <b>macroblock).</b>|$|E
40|$|This paper {{presents}} a novel face-assisted video coding scheme {{to enhance the}} visual quality of the face regions in video telephony applications. A skin-color based face detection and tracking scheme is proposed to locate the face regions in real-time. After classifying the <b>macroblocks</b> into the face and non-face regions, we present a dynamic distortion weighting adjustment (DDWA) scheme to drop the static non-face <b>macroblocks,</b> and the saved bits are used to compensate the face region by adjusting the distortion weighting of the face <b>macroblocks.</b> The quality of face regions will thus be enhanced. Moreover, the computation originally required for the skipped <b>macroblocks</b> can also be saved. The experimental {{results show that the}} proposed method can significantly improve the PSNR and the subjective quality of face regions, while the degradation introduced on the non-face areas is relatively insensitive to human perception. The proposed algorithm is fully compatible with H. 263 standard, and the low complexity feature makes it well suited to implement for real-time applications. 1...|$|R
5000|$|Blockiness in [...] "busy" [...] regions (block {{boundary}} artifacts, {{sometimes called}} <b>macroblocking,</b> quilting, or checkerboarding) ...|$|R
40|$|This paper {{presents}} a multi-level error protection for H. 264 /AVC video frames {{based on the}} importance of <b>macroblocks.</b> It is basically accomplished by comparing motion activities of <b>macroblocks</b> with their neighbouring areas. Thosemacroblocks having higher motion activities than their neighbouring areas are highly protected. Two-level error protectionformed by this comparison is extended to construct a multi-level error protection for the video frames. In this case, an algorithm is implemented, which considers motion activities of <b>macroblocks</b> in two consecutive frames. Conducted analysis and simulation results express that the newly presented multi-level protection significantly improves the video performance compared to other motion-based error protection techniques, while similar code rates for channel codes are applied...|$|R
