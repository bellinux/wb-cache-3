11|13|Public
50|$|In {{addition}} to the macro-instruction cache memory {{also found in the}} ND-100, the ND-110 had a unique implementation of cache memory on the <b>micro-instruction</b> level. The step known as mapping in the ND-100 was then avoided because the first <b>micro-instruction</b> word of a macro-instruction was written into the control store cache.|$|E
50|$|The CPU {{instruction}} decoder, decoded {{machine level}} instructions (as opposed to micro-instructions). This {{was achieved by}} using map tables held in fast parity checked RAM which mapped one byte opcodes onto <b>micro-instruction</b> addresses. Control was transferred to these addresses using a special sequencer operation which was performed in parallel with other CPU functions. Hence instruction decoding overlapped instruction execution.|$|E
40|$|The bit {{steering}} technique {{reduces the}} number of bits in the partially enrolled mono-phase <b>micro-instruction</b> format. The concurrency matrix aids the detection of bit steering sots of technique-commands. In this paper, {{the applicability of the}} bit steering technique to the polyphase microinstruction format is investigated...|$|E
5000|$|In {{computer}} science, zero {{instruction set}} computer (ZISC) {{refers to a}} computer architecture based solely on pattern matching and absence of (<b>micro-)instructions</b> in the classical sense. These chips are known for being thought of as comparable to the neural networks, being marketed {{for the number of}} [...] "synapses" [...] and [...] "neurons".|$|R
50|$|Other more {{advanced}} forms of Control Units manage {{the translation of}} instructions (but not the data containing portion) into several <b>micro-instructions</b> and the CU manages the scheduling of the <b>micro-instructions</b> between the selected execution units to which the data is then channeled and changed according to the execution unit's function (i.e., ALU contains several functions). On some processors, the Control Unit may be further broken down into additional units, such as an instruction unit or scheduling unit to handle scheduling, or a retirement unit to deal with results coming from the instruction pipeline. Again, the Control Unit orchestrates the main functions of the CPU: carrying out stored instructions in the software program then directing the flow of data throughout the computer based upon these instructions (roughly likened to how traffic lights will systematically control the flow of cars data to different locations within the traffic grid CPU until it parks at the desired parking spot address/register. The car occupants data then go into the building unit and comes back changed in some way then {{get back into the}} car and returns to another location via the controlled traffic grid).|$|R
40|$|The Scheme 86 and the HP Precision Architectures {{represent}} different {{trends in}} computer processor design. The former uses wide <b>micro-instructions,</b> parallel hardware, {{and a low}} latency memory interface. The latter encourages pipelined implementation and visible interlocks. To compare the merits of these approaches, algorithms frequently encountered in numerical and symbolic computation were hand-coded for each architecture. Timings were done in simulators {{and the results were}} evaluated to determine the speed of each design. Based on these measurements conclusions were drawn as to which aspects of each architecture are suitable for a high-performance computer...|$|R
40|$|The {{development}} of a reconfigurable micro-assembler to provide the micro-programmer the capability to specify micro-instructions in concise, meaningful terms is discussed. The implementation plan for the {{development of}} the micro-assembler was predicted on the existing capabilities of the SUMC Reconfigurable Assembler. Utilizing the reconfigurable assembler as a base, new directives and existing directive modifications were implemented to provide the micro-assembly as a new capability of the reconfigurable assembler. The micro-assembler language allows the specification of all <b>micro-instruction</b> control field settings in one concise assembler source statement. The language appears very similar to a conventional machine instruction assembler language. The machine instruction assembler language has the characteristic of one operation specification per statement whereas, the <b>micro-instruction</b> assembler language allows multiple operations to be designated per statement...|$|E
40|$|A {{heuristic}} algorithm {{to perform}} path planning for single manipulator in 2 D environment containing deformable objects is presented. The environment is partitioned into a quadtree hierarchy for both sampling and space navigation use before combination of artificial potential field and heuristic reasoning are applied iteratively to generate feasible path for the manipulator. The algorithm specifically {{targets for the}} shortest path without damaging any objects due to deep collision depth between manipulator link and object. Resulting path is in turn {{to be used in}} generating <b>micro-instruction</b> controlling the manipulator. Implementation results show feasibility to solve problems involving simple object and manipulator configuration...|$|E
40|$|We {{describe}} a comprehensive simulation methodology and tool {{for evaluation of}} software energy for the pipelined DLX processor. Energy models for each module of DLX are built and the energy is evaluated during run time execution. The input to the simulator are the instructions {{of the program and}} the simulator estimates energy of each <b>micro-instruction</b> using the energy models. Our simulator allows exploration of energy by allowing architecture modification, experimentation with different software techniques (compilation optimixations, algorithm evaluation) and also al-lows simultaneous interplay of both hardware and software tech-niques. The usefulness of this simulator is demonstrated by eval-uating certain compilation optimizations (loop unrolling, soft-ware pipelining, recursion elimination etc.) and algorithms. 1...|$|E
25|$|Internally, the Athlon is a fully seventh {{generation}} x86 processor, {{the first}} of its kind. Like the AMD K5 and K6, the Athlon dynamically buffers internal <b>micro-instructions</b> at runtime resulting from parallel x86 instruction decoding. The CPU is an out-of-order design, again like previous post-5x86 AMD CPUs. The Athlon utilizes the Alpha 21264's EV6 bus architecture with double data rate (DDR) technology. This means that at 100MHz, the Athlon front side bus actually transfers at a rate similar to a 200MHz single data rate bus (referred to as 200MT/s), which was superior to the method used on Intel's Pentium III (with SDR bus speeds of 100MHz and 133MHz).|$|R
40|$|This project {{includes}} {{the design and}} implementation of a floppy disk drive exerciser. The design consists of two main parts: Hardware and software. The hardware allows control of drive selection, head loading, track seeking, formatting as well as reading and writing operations. The software consists of two levels, a lower level composed of <b>micro-instructions</b> to control the hardware and an upper level which consists of macro-commands executable from a key pad to perform user definable functions. The exerciser is intended for use with floppy disk drives that have either the ???ANSI??? [American National Standard Institute] interface or the ???Apple??? interface {Set forth by Apple Computers Inc. ] and uses 5. 25 inch diskettes for data storage...|$|R
50|$|Internally, the Athlon is a fully seventh {{generation}} x86 processor, {{the first}} of its kind. Like the AMD K5 and K6, the Athlon dynamically buffers internal <b>micro-instructions</b> at runtime resulting from parallel x86 instruction decoding. The CPU is an out-of-order design, again like previous post-5x86 AMD CPUs. The Athlon utilizes the Alpha 21264's EV6 bus architecture with double data rate (DDR) technology. This means that at 100 MHz, the Athlon front side bus actually transfers at a rate similar to a 200 MHz single data rate bus (referred to as 200 MT/s), which was superior to the method used on Intel's Pentium III (with SDR bus speeds of 100 MHz and 133 MHz).|$|R
40|$|Modern layer 3 {{networking}} {{technologies have}} mainly {{been designed for}} performance and for network providers. This report proposes a new network architecture called Active Protocol Label Switching (APLS) that combines the performance of current label switching technology with novel concepts that cultivate service provisioning. Novel features such as Virtual Label Space, APLS <b>micro-instruction</b> architecture, and micro-policy based forwarding provide a more powerful network model, facilitate better network level service engineering, and give tremendous flexibility to both network and service providers. The thrust of our study is to construct an APLS test-bed using open hardware and software and later use this test-bed for experimenting various fea- tures/options available with APLS. This report also describes our pro- totype implementation of APLS under Linux...|$|E
40|$|This paper {{presents}} {{the design and}} analysis of a floating-point arithmetic accelerator {{in compliance with the}} IEEE standard single precision floatingpoint format. The accelerator can be used to extend a general-purpose processor such as Motorola MC 6820, where floating-point execution units are unembedded by default. It implements standard and non-standard mathematic functions, addition/subtraction, multiplication, Product-of-Sum and Sumof- Product through a <b>micro-instruction</b> set supported by both single and multi-processors systems. The architecture of the unit is based on an instruction pipeline which can simultaneously fetch and execute an instruction within one clock cycle. The non-standard operations such as Product-of-Sum and Sum-of-Product are introduced to compute threeinput operands. The algorithm complexity and hardware critical delay are determined for each operator. The synthesis results of the accelerator on a Xilinx FPGA Virtex 5 xc 5 vlx 110 t- 3 ff- 1136 and on Faraday 130 -nm Silicon technology report that the design respectively achieves 200 MHz and 1 GHz...|$|E
40|$|Machine with {{a minimal}} set of {{features}} to support contexts; 3) Program representation-based approach: it exploits the program representation and the predicate addressing mechanism of a modular Prolog programming system, {{in order to}} implement contexts {{in the same way}} ordinary modules are. The main goal of the first work is to discuss and compare the first two approaches by considering both methodological and performance aspects. 146 In order to achieve comparable performance results, a simulator of the VLSI Prolog coprocessor described in [CIV 89] has been used. Two versions of such a simulator have been employed, the first supporting standard Prolog (i. e. implementing the standard WAM), the second supporting the S-WAM described in [LMN 89, LMN]. Since both machines share the same set of micro-coded instruction, this set has been used as unit of measure. Reliable measures of computational costs can also be achieved, since the execution time of each <b>micro-instruction</b> is known. The wor [...] ...|$|E
40|$|Predicting the {{execution}} times of straight-line code sequences {{is a fundamental}} problem {{in the design and}} evaluation of hard-real-time systems. The reliability of system-level timings and schedulability analysis rests on the accuracy of execution time predictions for the basic schedulable units of work. Obtaining such predictions for contemporary microprocessors is difficult. This paper presents a new technique called micro-analysis for predicting point-to-point execution times on contemporary microprocessors. It uses machine-description rules, similar to those that have proven useful for code generation and peephole optimization, to translate compiled object code into a sequence of very lowlevel instructions. The stream of <b>micro-instructions</b> is then analyzed for timing, via a three-level pattern matching scheme. At this low level, the effect of advanced features such as caching and instruction overlap can be taken into account. This technique is compiler and language-independent, an [...] ...|$|R
40|$|Security and {{reliability}} in processor based systems are concerns requiring adroit solutions. Security is often compromised by code injection attacks, jeopardizing even ‘trusted software’. Reliability {{is of concern}} where unintended code is executed in modern processors with ever smaller feature sizes and low voltage swings causing bit flips. Countermeasures by software-only approaches increase code size by large amounts and therefore significantly reduce performance. Hardware assisted approaches add extensive amounts of hardware monitors and thus incur unacceptably high hardware cost. This paper presents a novel hardware/software technique at the granularity of <b>micro-instructions</b> to reduce overheads considerably. Experiments show that our technique incurs an additional hardware overhead of 0. 91 % and clock period increase of 0. 06 %. Average clock cycle and code size overheads are just 11. 9 % and 10. 6 % for five industry standard application benchmarks. These overheads are far smaller than have been previously encountered...|$|R
40|$|Graduation date: 1976 REGTRAN (REGister TRANsfer), a {{hardware}} description language and SYSSIM (SYStems SIMulation), a simulator {{for the system}} described by REGTRAN were originally developed by Edward Pett, Jr [33] at the University of Texas at Austin. These two programs are successfully used to simulate many digital systems of complex nature. It is {{the primary purpose of}} this paper to describe the implementation of these two programs for KRONOS at Oregon State University. In this process, various problems, due to the differences in the operating systems, were faced. These problems are discussed in detail and the changes that were made are included. REGTRAN and SYSSIM are not capable of simulating <b>micro-instructions</b> or a microprocessor. For this reason, another simulator MICRO is developed. Detailed description of MICRO and its use as a general purpose simulator as well as a microprogram simulator are given in detail. As an example, partial emulation of DEC PDP- 8 is shown. Suggestions for the improvement of MICRO, REGTRAN and SYSSIM are mentioned...|$|R
40|$|ECTI TRANSACTIONS ON COMPUTER AND INFORMATION TECHNOLOGY VOL. 6, NO. 1 May 2012 This paper {{presents}} {{the design and}} analysis of a floating-point arithmetic accelerator {{in compliance with the}} IEEE standard single precision floatingpoint format. The accelerator can be used to extend a general-purpose processor such as Motorola MC 6820, where floating-point execution units are unembedded by default. It implements standard and non-standard mathematic functions, addition/subtraction, multiplication, Product-of-Sum and Sum-of-Product through a <b>micro-instruction</b> set supported by both single and multi-processors systems. The architecture of the unit is based on an instruction pipeline which can simultaneously fetch and execute an instruction within one clock cycle. The non-standard operations such as Product-of-Sum and Sum-of-Product are introduced to compute threeinput operands. The algorithm complexity and hardware critical delay are determined for each operator. The synthesis results of the accelerator on a Xilinx FPGA Virtex 5 xc 5 vlx 110 t- 3 ff- 1136 and on Faraday 130 -nm Silicon technology report that the design respectively achieves 200 MHz and 1 GHz...|$|E
40|$|Security and {{reliability}} in processor based systems are concerns requiring adroit solutions. Security is often compromised by code injection attacks, jeopardizing even trusted software. Reliability is of concern, where unintended code is executed in modern processors with ever smaller feature sizes and low voltage swings causing bit flips. Countermeasures by software-only approaches increase code size and therefore significantly reduce performance. Hardware assisted approaches use additional hardware monitors and thus incur considerably high hardware cost and have scalability problems. Considering reliability and security issues during {{the design of}} an embedded system has its advantages as this overcomes the limitations of existing solutions. The research work presented in this thesis combines two elements: one, defining a hardware software design framework for reliability and security monitoring at the granularity of micro-instructions, and two, applying this framework for real world problems. At a given time, a processor executes only a few instructions and {{large part of the}} processor is idle. Utilizing these idling hardware components by sharing them with the monitoring hardware, to perform security {{and reliability}} monitoring reduces the impact of the monitors on hardware cost. Using <b>micro-instruction</b> routines within the machine instructions, allows us to share most of the monitoring hardware. Therefore, our technique requires little hardware overhead in comparison to having additional hardware blocks outside the processor. This reduction in overhead is due to maximal sharing of hardware resources of the processor. Our framework is superior to software-only techniques as the monitoring routines are formed with micro-instructions and therefore reduces code size and execution time overheads, since they occur in parallel with machine instructions. This dissertation makes four significant contributions to the field of security and reliability on embedded processor research and they are: (i) proposed a security and reliability framework for embedded processors that could be included into its design phase; (ii) shown that inline (machine instruction level) monitoring will detect common security attacks (four inline monitors against common attacks cost 9. 21 % area and 0. 67 % performance, as opposed to previous work where an external monitor with two monitoring modules costs 15 % area overhead); (iii) illustrated that basic block check-summing for code integrity is much simpler and efficient than currently proposed integrity violation detectors which address code injection attacks (this costs 5. 03 % area increase and 3. 67 % performance penalty with a single level control flow checking, as opposed to previous work where the area overhead is 5. 59 %, which needed three control flow levels of integrity checking); and (iv) shown that hardware assisted control flow checking implemented during the design of a processor is much cheaper and effective than software only approaches (this approach costs 0. 24 - 1. 47 % performance and 3. 59 % area overheads, as opposed to previous work that costs 53. 5 - 99. 5 % performance) ...|$|E
40|$|This paper {{describes}} the design goals, micro-architecture, {{and implementation of}} the microprogrammed processor for a compact high performance personal com-puter. This computer supports a range of high level lang-uage environments and high bandwidth I/O devices. Besides the processor, it has a cache, a memory map, main storage, and an instruction fetch unit; these are described in other papers. The processor can be shared among 16 microcoded tasks, performing microcode context switches on demand with essentially no overhead. Conditional branches are done without any Iookahead or delay. <b>Micro-instructions</b> are fairly tightly encoded, and use an interes-ting variant on control field sharing. The processor imple-ments a large number of internal registers, hardware stacks, a cyclic shifter/masker, and an arithmetic/logic unit, together with external data paths for instruction fetching, memory interface, and t/O, in a compact, pipe-lined organization. The machine has a 50 ns microcycle, and can execute a simple macroinstruction in one cycle; the available 1 /O bandwidth is 640 Mhits/sec. The entire machine, including disk, display and network interfaces, is implemented with approximately 3000 MSI components, mostly ECL 10 K; the processor is about 35 % of this. In addition there are up to 4 storage modules, each with about 300 16 K or 64 K RAMS and 200 MS! components, for a total of 8 Mbytes. Several prototypes are currently running. 1...|$|R
40|$|Abstract Predicting the {{execution}} times of straight-line code sequences {{is a fundamental}} problem {{in the design and}} evaluation of hard-real-time systems. The reliability of system-level timings and schedulability analysis rests on the accuracy of execution time predictions for the basic schedulable units of work. Obtaining such predictions for contemporary microprocessors is difficult. First a summary of some of the hardware and software factors that make predicting execution time difficult is presented, along with the results of experiments that evaluate the degree of variation in execution time that may be caused by these factors. Traditional methods of measuring and predicting execution time are examined, and their strengths and weaknesses discussed. Second, we present a new technique for predicting point-to-point execution times on contemporary microprocessors. This technique is called micro-analysis. It uses machine-description rules, similar to those that have proven useful for code generation and peephole optimization, to translate compiled object code into a sequence of very low-level instructions. The stream of <b>micro-instructions</b> is then analyzed for timing, via a three-level pattern matching scheme. At this low level, the effect of advanced features such as caching and instruction overlap can be taken into account. This technique is compiler and language-independent, and retargetable. Finally, we describe a prototype system in which the micro-analysis technique is integrated with an existing C compiler. This early version predicts the bounded execution time of statement ranges or simple (non-nested) C functions at compile time. Keywords: Real-time systems, point-to-point execution time, best case time, worst case time, and predicting execution time...|$|R
40|$|This {{article is}} {{intended}} to provide some new insights about concurrency theory using ideas from geometry, and more specifically from algebraic topology. The aim of the paper is two-fold: we justify applications of geometrical methods in concurrency through some chosen examples and we give the mathematical foundations needed to understand the geometric phenomenon that we identify. In particular we show that the usual notion of homotopy has to be refined {{to take into account}} some partial ordering describing the way time goes. This gives rise to some new interesting mathematical problems as well as give some common grounds to computer-scientific problems that have not been precisely related otherwise in the past. The organization of the paper is as follows. In Section 2 we explain to which extent we can use some geometrical ideas in computer science: we list a few of the potential or well known areas of application and try to exemplify some of the properties of concurrent (and distributed) systems we are interested in. We first explain the interest of using some geometric ideas for semantical reasons. Then we take the example of concurrent databases with the problem of finding deadlocks and with some aspects of serializability theory. More general questions about schedules can be asked as well and related to some geometric considerations, even for scheduling <b>micro-instructions</b> (and not only coarse-grained transactions as for databases). The final example is the one of fault-tolerant protocols for distributed systems, where subtle scheduling properties come into play. In Section 3 we give the first few definitions needed for modeling the topological spaces arising from Section 2. Basically, we need to define a topological space containing all traces of executions of the con [...] ...|$|R
40|$|Proposal of Identity-Based {{cryptography}} by Shamir in 1984 {{opened a}} new area for researchers. Failing to provide a feasible implementation of identity based encryption (IBE), Shamir developed a signature scheme, whereby signatures can be verified by publicly available information such as signer's identity. Since the first efficient implementation of IBE realized using pairing operation on elliptic curves due to Boneh and Franklin a plethora of papers has been published and many {{studies have been conducted}} covering different aspects of pairing-based cryptography. Today, pairing is used in many cryptographic applications including, identity based cryptography, key exchange protocols, short signatures, anonymous signatures and in many other newly emerging protocols and schemes. Also, pairing is still a developing research field yielding important challenges for the research community. Pairing computation involves fairly complicated operations compared to classical symmetric and asymmetric cryptosystems. Multitudes of pairing types have been proposed after its first appearance in the literature. Also, each of them involves selection of many parameters such as the choice of the underlying field and its characteristics, order of the embedding degree, type of the elliptic curve etc. Therefore, different types of optimisations are possible rendering selection process extremely difficult. Because of the abundance of choices, for an efficient pairing implementation many criteria have to be examined. For instance, selection of pairing type, construction of finite fields and elliptic curves, coordinate systems to represent points on the curve and algorithms and architecture for arithmetic operations play a crucial role on the performance of the specific implementation of the pairing-based cryptography. A multitude of implementations regarding to pairing-based cryptography have been proposed in the literature. However, most of them are software realizations; the reason being is the complexity of the overall system. Some hardware implementations have already been proposed, but most of them are very specific, therefore lacks flexibility and scalability. Due to the complexity of the system, some researches advice to use dedicated implementations for specific set of parameters even in software, limiting the flexibility of the implementation further. In this thesis, we propose a very generic, flexible and compact hardware coprocessor for all kinds of pairing implementations intended for implementation on reconfigurable devices (e. g. FPGA). Our co-processor supports all types of pairing operations with different parameter classes via making use of highly-optimized hardware implementations of basic arithmetic operations common not only to pairing operations, but also to elliptic curve cryptography and other public key cryptography algorithms. Our design utilizes the idea of hardware-software co-design concept. To accelerate pairing computation we implement some units responsible for performing the most time-consuming operations as a generic, but highly optimized hardware circuits, whereas we prefer to implement some complex parts (unworthy of hardware resources) in low-level software of <b>micro-instructions.</b> Although we use two arithmetic cores running concurrently, our design still manages to be compact thanks to its careful and generic design...|$|R

