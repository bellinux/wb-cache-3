3453|873|Public
25|$|In 2009, PiGi {{projections}} and LED mesh screens, {{combined with}} special lighting effects will deliver <b>multimedia</b> <b>content.</b>|$|E
25|$|Since its start, the World Wide Web {{has been}} facilitating the {{technological}} convergence {{of commercial and}} self-published content, {{as well as the}} convergence of publishing and producing into online production through the development of <b>multimedia</b> <b>content.</b>|$|E
25|$|Archive content {{includes}} both peer-reviewed and non-refereed content; unpublished and published articles (preprints or postprints); conference proceedings; other grey literature, such as white papers, policy papers, and technical reports; <b>multimedia</b> <b>content</b> including audio, video, and images; and primary research data.|$|E
40|$|Abstract. <b>Multimedia</b> <b>contents</b> such as {{images and}} videos {{are widely used}} in social network sites nowadays. Sina Weibo, a Chinese {{microblog}}-ging service, {{is one of the}} first microblog platforms to incorporate mul-timedia content sharing features. This work provides statistical analysis on how <b>multimedia</b> <b>contents</b> are produced, consumed, and propagated in Sina Weibo. Based on 230 million tweets and 1. 8 million user profiles in Sina Weibo, we study the impact of <b>multimedia</b> <b>contents</b> on the popular-ity of both users and tweets as well as tweet life span. Our preliminary study shows that multimedia tweets dominant pure text ones in Sina Wei-bo. <b>Multimedia</b> <b>contents</b> boost popularity of tweet as well as users. Users who tend to publish many multimedia tweets are also productive wit...|$|R
40|$|International audienceCurrently, many <b>multimedia</b> <b>contents</b> are {{acquired}} {{and stored}} in real time and on different locations. In order to retrieve efficiently the desired information and to avoid centralizing all metadata, we propose to compute a centralized metadata resume, i. e., a concise version of the whole metadata, which locates some desired <b>multimedia</b> <b>contents</b> on remote servers. The originality of this resume {{is that it is}} automatically constructed based on the extracted metadata. In this paper, we present a method to construct such resume and illustrate our framework with current Semantic Web technologies, such as RDF and SPARQL for representing and querying semantic metadata. Some experimental results are provided in order to show the benefits of indexing and retrieving <b>multimedia</b> <b>contents</b> without centralizing <b>multimedia</b> <b>contents</b> or their associated metadata, and to prove the efficiency of a metadata resume...|$|R
40|$|Portable {{devices and}} {{wireless}} connections {{are creating a}} new scenario in which digital information is entering our lives in a massive way. In this article we consider MP 3 audiobook applications and propose an approach to completely restyle the applications to the current mobile and multimedia scenario. Our mechanism introduces <b>multimedia</b> <b>contents</b> (images and text) into the audiobook application and synchronizes them with the MP 3 audio stream. <b>Multimedia</b> <b>contents</b> are protected by a security system that ensures perfect audio quality and full access to <b>multimedia</b> <b>contents</b> only to a legal user. A distribution architecture and a player that use the proposed mechanism are also presented...|$|R
25|$|The Bentonville Public Library System {{consists}} of one central library, located at 405 S. Main Street, which provides residents {{with access to}} print books, publications and <b>multimedia</b> <b>content,</b> {{as well as a}} satellite location at the Bentonville Community Center in the southwestern section of the city.|$|E
25|$|Digital rights {{management}} (DRM) {{is a set}} {{of access}} control technologies for restricting the use of proprietary hardware and copyrighted works. DRM technologies try to control the use, modification, and distribution of copyrighted works (such as software and <b>multimedia</b> <b>content),</b> as well as systems within devices that enforce these policies.|$|E
25|$|ATAG {{is a set}} of {{guidelines}} for developers of any kind of authoring tool for Web content: simple HTML editors, tools that export content for use on the Web (for example, word processors that can save as HTML), tools that produce <b>multimedia,</b> <b>content</b> management systems, learning management systems, social media, etcetera.|$|E
5000|$|The {{technological}} revival works {{rather well}} with <b>multimedia</b> <b>contents</b> {{dating from the}} 90s, 80s or 70s.|$|R
40|$|This work {{describes}} {{the design and}} application of <b>multimedia</b> <b>contents</b> for web technologies-based training in minimally invasive surgery (MIS). The chosen strategy allows knowing the deficiencies of the current training methods so new <b>multimedia</b> <b>contents</b> can cover them. This study is concluded with the definition of three different types of <b>multimedia</b> <b>contents</b> accordingly to the development degree and didactic objectives that they present: Didactic resources are basic contents such as videos or documents that can be enhanced with contributions of users. On the other hand, case reports and didactic units have a defined structure. Didactic resources and case reports provide an informal training while didactic units are included in a more regulated training...|$|R
5000|$|Control and {{filtering}} {{of concrete}} audio-visual contents, like violent or pornographic material. Also, authorization for some <b>multimedia</b> <b>contents.</b>|$|R
25|$|Zune {{supports}} the Windows Media DRM {{digital rights management}} system, which is not compatible with other DRM systems and {{is not part of}} the PlaysForSure platform or program.   <b>Multimedia</b> <b>content</b> is transferred through Media Transfer Protocol (MTP); however, its proprietary MTP extensions ("MTPZ") place an interoperability barrier between the Zune and previous MTP-based software.|$|E
25|$|TV-Anytime {{is a set}} of {{specifications}} for the controlled delivery of <b>multimedia</b> <b>content</b> to a user's local storage. It seeks to exploit the evolution in convenient, high capacity storage of digital information to provide consumers with a highly personalized TV experience. Users will have access to content {{from a wide variety of}} sources, tailored to their needs and personal preferences. TV-Anytime specifications are specified by the TV-Anytime Forum.|$|E
25|$|The {{range of}} <b>multimedia</b> <b>content</b> {{includes}} guerrilla training clips, stills of victims {{about to be}} murdered, testimonials of suicide bombers, and videos that show participation in jihad through stylized portraits of mosques and musical scores. A website associated with al-Qaeda posted a video of captured American entrepreneur Nick Berg being decapitated in Iraq. Other decapitation videos and pictures, including those of Paul Johnson, Kim Sun-il, and Daniel Pearl, were first posted on jihadist websites.|$|E
40|$|Digital Library (DL) has {{facilitated}} {{the distribution of}} <b>multimedia</b> <b>contents</b> in the networked information environment. Designers of DLs have typically focused on development of sophisticated query algorithms and data structuring models. Without thorough understanding of users' information seeking behavior, designers of DLs are unable to address users' information needs. Existing studies do not specifically investigate the searching behavior of users who look for <b>multimedia</b> <b>contents,</b> therefore, we choose peer-to-peer (P 2 P) networks, where <b>multimedia</b> <b>contents</b> are extensively distributed, to study users' behavior. In this paper, we propose a methodology to overcome the difficulty in tracing individuals' searching activities, the obstacle brought by anonymity, one {{of the characteristics of}} P 2 P networks. We successfblly identify users' search sessions and study their searching behavior at the level of individuals in P 2 P networks. Our preliminary results show that-users searching for <b>multimedia</b> <b>contents</b> are likely to stick on the same topic and submit successive queries. The results of this study will be instrumental in providing ways of understanding users' information seeking behavior and incorporating human factors into the design of multimedia DLs...|$|R
30|$|To {{pursue this}} goal, {{we want to}} know how many bits are {{sufficient}} to convey quality <b>multimedia</b> <b>contents.</b> Lossless compression always ensures the highest possible quality, in which the objective redundancy in the <b>multimedia</b> <b>contents</b> is the only source of compression, and there is a limit, the Shannon entropy, the lowest possible bitrate with perfect decompression. Nevertheless, this limit is very hard if not impossible to compute due to the diversity and complexity of probability models of <b>multimedia</b> <b>contents.</b> By Huffman coding, run-length coding, arithmetic coding, and other entropy coding techniques, the state-of-the-art lossless audio coders today typically achieve a compression rate of 1 / 3 - 2 / 3 or 230 – 460 [*]kbps per channel for CD music [2].|$|R
3000|$|There {{has been}} little prior work towards emotion {{recognition}} using both audio and visual cues in <b>multimedia</b> <b>contents</b> [16], [...]...|$|R
25|$|The MPEG-4 Part 20 {{standard}} - Lightweight Application Scene Representation (LASeR) and Simple Aggregation Format (SAF) {{is based}} on SVG Tiny. It was developed by MPEG (ISO/IEC JTC1/SC29/WG11) and published as ISO/IEC 14496-20:2006. SVG capabilities are enhanced in MPEG-4 Part 20 with key features for mobile services, such as dynamic updates, binary encoding, state-of-art font representation. SVG was also accommodated in MPEG-4 Part 11, in the Extensible MPEG-4 Textual (XMT) format - a textual representation of the MPEG-4 <b>multimedia</b> <b>content</b> using XML.|$|E
25|$|The web and {{partnerships}} are two pivotal {{and dynamic}} aspects of EndingHunger. The campaign {{relies on the}} assistance of organizations and institutions that can facilitate the project's diffusion, by placing banners on their own websites or organizing events aimed {{to raise awareness of}} the project. In its 2011 season, the campaign expanded its <b>multimedia</b> <b>content,</b> pursued mutual visibility arrangements with partner organizations, and sharpened its focus on 14- to 25-year-olds, who were encouraged to understand their potential as a social movement to push for the end of hunger.|$|E
25|$|Global Memory Net (GMNet) {{is a world}} {{digital library}} of cultural, historical, and {{heritage}} image collections. It is directed by Ching-chih Chen, Professor Emeritus of Simmons College, Boston, Massachusetts {{and supported by the}} National Science Foundation (NSF)'s International Digital Library Program (IDLP). The goal of GMNet is to provide a global collaborative network that provides universal access to educational resources to a worldwide audience. GMNet provides multilingual and <b>multimedia</b> <b>content</b> and retrieval, as well as links directly to major resources, such as OCLC, Internet Archive, Million Book Project, and Google.|$|E
40|$|<b>Multimedia</b> <b>contents</b> are {{becoming}} the major information {{going through the}} Internet. Pervasive network infrastructure expedites data delivery with improved network throughput and response time performances. In the following, we investigate the passing of real-time <b>multimedia</b> <b>contents</b> (images and videos) {{with the help of}} pervasive network infrastructure. User's perceptual quality on images will be examined and justified based on the visual differences predictor metric. The experimental results validate the effective and proactive reactions of network infrastructure...|$|R
40|$|Ten {{years after}} the {{foundation}} book "Affective Computing" which proposed concepts and approaches related to the measure {{and the use of}} emotion in human computer interaction scenarios, several decades after the first psychological and physiological study on emotion and hundreds years after philosophical study about aesthetical emotion, very few automated systems are nowadays able to manipulate <b>multimedia</b> <b>contents</b> (selection, design, creation) according to the felt affective states and emotions (which can be measured by different means) by an individual. Among several limitations, we consider in this thesis that one important problem is the amount of inter-individual differences both in the indirect measure of emotion and in our affective evaluation of <b>multimedia</b> <b>contents.</b> In this thesis we propose enhancements of computer possibilities to manipulate media contents on the basis of felt affective states by modeling affective and emotional associations to <b>multimedia</b> <b>contents</b> and by automating the process of interpretation of emotion from indirect measure. This enhancement is achieved by the design of two user models which can take into account user's specificities toward a better adaptation. First we introduce the Embodied Affective Relationship to <b>Multimedia</b> <b>Contents</b> (EAR) as a model aiming at formalizing association between <b>multimedia</b> <b>contents</b> and emotional experience of individuals. This model is then presented in a practical way toward systematic affective handling of <b>multimedia</b> <b>contents.</b> Then we introduce the Psycho Physiological Emotion Map (PPEM) as a parametric model of emotion interpretation from physiological signals taking into account inter and intra-individual differences. Our technique aims at psychologically interpreting physiological parameters (skin conductance and heart rate), and at producing a continuous extraction of the user's affective state during Human Computer Interaction. An experiment is presented to estimate emotion from physiological signals. Both models are built upon an engineering cognitive science approach, i. e. implementing psychological and neuroscience knowledge to design a computer system. Finally, an experimental Application Programming Interface built upon the proposed models is presented to enable novel form of affective state and emotion driven-human multimedia interaction. Ten {{years after the}} foundation book "Affective Computing" which proposed concepts and approaches related to the measure and the use of emotion in human computer interaction scenarios, several decades after the first psychological and physiological study on emotion and hundreds years after philosophical study about aesthetical emotion, very few automated systems are nowadays able to manipulate <b>multimedia</b> <b>contents</b> (selection, design, creation) according to the felt affective states and emotions (which can be measured by different means) by an individual. Among several limitations, we consider in this thesis that one important problem is the amount of inter-individual differences both in the indirect measure of emotion and in our affective evaluation of <b>multimedia</b> <b>contents.</b> In this thesis we propose enhancements of computer possibilities to manipulate media contents on the basis of felt affective states by modeling affective and emotional associations to <b>multimedia</b> <b>contents</b> and by automating the process of interpretation of emotion from indirect measure. This enhancement is achieved by the design of two user models which can take into account user's specificities toward a better adaptation. First we introduce the Embodied Affective Relationship to <b>Multimedia</b> <b>Contents</b> (EAR) as a model aiming at formalizing association between <b>multimedia</b> <b>contents</b> and emotional experience of individuals. This model is then presented in a practical way toward systematic affective handling of <b>multimedia</b> <b>contents.</b> Then we introduce the Psycho Physiological Emotion Map (PPEM) as a parametric model of emotion interpretation from physiological signals taking into account inter and intra-individual differences. Our technique aims at psychologically interpreting physiological parameters (skin conductance and heart rate), and at producing a continuous extraction of the user's affective state during Human Computer Interaction. An experiment is presented to estimate emotion from physiological signals. Both models are built upon an engineering cognitive science approach, i. e. implementing psychological and neuroscience knowledge to design a computer system. Finally, an experimental Application Programming Interface built upon the proposed models is presented to enable novel form of affective state and emotion driven-human multimedia interaction. NICE-BU Sciences (060882101) / SudocSudocFranceF...|$|R
40|$|Making a {{decision}} among {{a set of}} items from compound and complex information has been becoming a difficult task for common users. Collaborative filtering has been the mainstay of automatically personalized search employed in contemporary recommender systems. Until now, {{it is still a}} challenging issue to reduce the gap between user perception and <b>multimedia</b> <b>contents.</b> To bridge user’s interests and multimedia items, in this paper, we present an intelligent multimedia recommender system by integrating annotation and association mining techniques. In our proposed system, low-level <b>multimedia</b> <b>contents</b> are conceptualized to support rule-based collaborative filtering recommendation by automated annotation. From the discovered relations between user <b>contents</b> and conceptualized <b>multimedia</b> <b>contents,</b> the proposed recommender system can provide a suitable recommendation list to assist users in making {{a decision}} among a massive amount of items...|$|R
500|$|In {{announcing the}} {{formation}} of 343 Industries, Microsoft also announced that Xbox Live would be home to a central hub for Halo content called Halo Waypoint. Waypoint is accessed from the Xbox 360 Dashboard and offers players access to <b>multimedia</b> <b>content</b> in addition to tracking their Halo game [...] "career". O'Connor described Waypoint as intended to be the prime destination for Halo.|$|E
500|$|The tweets {{were set}} to a largely constrictive 140-character limit for {{compatibility}} with SMS messaging, introducing the shorthand notation and slang commonly used in SMS messages. The 140-character limit also increased the usage of URL shortening services such as bit.ly, goo.gl, and tr.im, and content-hosting services, such as Twitpic, memozu.com and NotePub to accommodate <b>multimedia</b> <b>content</b> and text longer than 140 characters. Since June 2011, Twitter has used its own t.co domain for automatic shortening of all URLs posted on its website, making other link shorteners superfluous for staying within the 140 character limit.|$|E
500|$|The {{album was}} {{globally}} released on 13 November 2001 in nations including Australia, France, Italy, Switzerland and the United States. In Latin American countries like Mexico, {{the album was}} released as Servicio de Lavandería in January 2002. In the United Kingdom, Laundry Service was released on 11 March 2002. On 12 November 2002, a limited edition version of the album entitled Laundry Service: Washed and Dried was released; {{this version of the}} album features three additional remixes and a bonus disc which contains <b>multimedia</b> <b>content</b> related to [...] "Objection (Tango)".|$|E
40|$|Internet traffic {{trends and}} {{forecasts}} clearly show that audio-video streaming {{is a killer}} application for next generation networks. Providing multicast support within operators' managed networks is mandatory to sustain the exponential growth of demand for <b>multimedia</b> <b>contents</b> without saturating the bandwidth available in core, backhauling, and access infrastructures. This work presents an experimental setup, built {{on top of an}} open source platform called openBOXware, which enables protected delivery of <b>multimedia</b> <b>contents</b> over unprotected multicast IP networks...|$|R
40|$|International audienceThis paper {{describes}} a streaming architecture simulation model above Network Simulator 2 (NS 2) which allows to define specific transport properties. <b>Multimedia</b> <b>contents</b> are specific {{because they are}} time-dependent and they can undergo small deterioration if necessary. We simulate such a congestion control that {{has the ability to}} decrease the multimedia quality in case of network congestion in order to decrease packet losses and packet delivery delays. We integrate this video congestion control inside DCCP (Datagram Congestion Control Protocol) and TFRC (TCP Friendly Rate Control). The transcoding of the <b>multimedia</b> <b>contents</b> is realized thanks to the NetMoVie simulation model which is an RTP mixer. We compare the adaptive transport solution to the classic transport solution without any adaptive mechanism. The Peak Signal-to-Noise Ratio (PSNR) of the received <b>multimedia</b> <b>contents</b> is measured and compared for better visualization...|$|R
50|$|Flora Malesiana {{is divided}} into two main series: I. Seed plants and II. Pteridophytes. Later volumes include CD-ROMs with {{additional}} <b>multimedia</b> <b>contents</b> such as interactive keys.|$|R
500|$|DisplayPort audio/video {{interface}} {{was introduced}} in May 2006. In the recent years, DisplayPort connectors have become a common feature of premium products -- displays, desktop computers, and video cards; most of the companies producing DisplayPort equipment are in the computer sector. The DisplayPort website states that DisplayPort is expected to complement HDMI, but as of 2016 100% of the HD and 4K TVs had HDMI connectivity. DisplayPort supported few advanced features -- e.g. 5K, Adaptive-Sync -- which were quite useful for <b>multimedia</b> <b>content</b> creators or gamers. This was the reason most of the GPUs had DisplayPort on them. These features {{were added to the}} official HDMI specification bit later. But with the introduction of HDMI 2.1 these gaps are already leveled off.|$|E
500|$|A notable {{multimedia}} {{software program}} produced by Delrina was Echo Lake, an early form of scrapbook software {{that came out}} in June 1995. During development it was touted internally as a [...] "cross [...] Quark Xpress and Myst". It featured an immersive 3D environment where a user could manipulate objects within a virtual desktop in a virtual office and assemble video and audio clips along with images, and then send them as either a virtual book other users of the program could then access, or its content could be printed. It was an innovative product for its time, and ultimately was hampered by the inability of many users to easily input or playback their own <b>multimedia</b> <b>content</b> into a computer from that period.|$|E
2500|$|... {{opens the}} Devices charm for printing, {{connecting}} {{to a second}} screen/projector, or pushing <b>multimedia</b> <b>content</b> via Play To.|$|E
50|$|JTE <b>Multimedia's</b> <b>content</b> is {{available}} in print, on the web, and in eReader format. All of JTE Multimedia's print publications are brought out under American Brands.|$|R
40|$|<b>Multimedia</b> <b>contents</b> {{are more}} and more present in our life and their {{presentation}} usually rests on a text-based description that defines rules and properties of such contents and is produced by markup description languages (e. g., XML, MPEG 7 -DDL and SMIL). Although effective, the criticism to such approach regards the length of the produced description, which is considered too verbose. Since this may lead to performance problems for devices with limited resources, binary-based descriptions are being proposed. However, the simplicity of a text-based description cannot be underestimated and hence, the contribution of this paper is the proposal of a reduced, but extensible, markup <b>Multimedia</b> <b>Contents</b> Description Language (MCDL), which produces short text-based description of <b>multimedia</b> <b>contents.</b> MCDL is designed to organize and synchronize contents forthe mobile music scenario and a comparison study with other languages shows that MCDL describes the same contents with a much shorter description...|$|R
40|$|MDS) {{description}} tools [1]. The MPEG- 7 MDSs {{provide the}} description mechanisms of representing structural and semantic information embedded in <b>multimedia</b> <b>contents.</b> The structural and semantic information of <b>multimedia</b> <b>contents</b> {{can be described}} based on the content description such as Structure DS and Semantic DS, respectively. The information regarding the creation and production, media, usage of the <b>multimedia</b> <b>contents</b> are described using the Creation&Production description tools, Media description tools and Usage description tools. Audiovisual abstraction summary {{can be obtained by}} the Summary DS and content navigation and access can also be made possible via MPEG- 7 description (metadata) by the View description and Variation description tools On the other hands, the video descriptors and audio descriptors allow for describing the characteristics of audiovisual contents characterized as low-level features such as color, texture, shapes motion, tempo, rhythm etc. Figure 2 represents the overview of MPEG- 7 Visual Descriptors...|$|R
