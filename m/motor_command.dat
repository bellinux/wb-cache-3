404|958|Public
25|$|An efference {{copy of the}} <b>motor</b> <b>command</b> for song {{production}} {{is the basis of}} the real-time error-correction signal. During singing, activation of LMAN neurons will depend on the motor signal used to generate the song, and the learned prediction of expected auditory feedback based on that <b>motor</b> <b>command.</b> Error correction would occur more rapidly in this model.|$|E
25|$|While {{auditory}} feedback {{is most important}} during speech acquisition, it may be activated less if the model has learned a proper feedforward <b>motor</b> <b>command</b> for each speech unit. But {{it has been shown}} that {{auditory feedback}} needs to be strongly coactivated in the case of auditory perturbation (e.g. shifting a formant frequency, Tourville et al. 2005). This is comparable to the strong influence of visual feedback on reaching movements during visual perturbation (e.g. shifting the location of objects by viewing through a prism).|$|E
2500|$|The tuning of the {{synaptic}} projections between {{speech sound}} map and motor map (i.e. tuning of forward motor commands) is accomplished {{with the aid}} of feedback commands, since the projections between sensory error maps and motor map were already tuned during babbling training (see above). Thus the DIVA model tries to [...] "imitate" [...] an auditory speech item by attempting to find a proper feedforward <b>motor</b> <b>command.</b> Subsequently the model compares the resulting sensory output (current sensory state following the articulation of that attempt) with the already learned auditory target region (intended sensory state) for that speech item. Then the model updates the current feedforward <b>motor</b> <b>command</b> by the current feedback <b>motor</b> <b>command</b> generated from the auditory error map of the auditory feedback system. This process may be repeated several times (several attempts). The DIVA model is capable of producing the speech item with a decreasing auditory difference between current and intended auditory state from attempt to attempt.|$|E
40|$|Voluntary <b>motor</b> <b>commands</b> produce {{two kinds}} of {{consequence}}s. Initially, a sensory consequence is observed in terms of activity in our primary sensory organs (e. g., vision, proprioception). Subsequently, the brain evaluates the sensory feedback and produces a subjective measure of utility or usefulness of the <b>motor</b> <b>commands</b> (e. g., reward). As a result, comparisons between predicted and observed consequences of <b>motor</b> <b>commands</b> produce two forms of prediction error. How do these errors contribute to changes in <b>motor</b> <b>commands?</b> Here, we considered a reach adaptation protocol and found that when high quality sensory feedback was available, adaptation of <b>motor</b> <b>commands</b> was driven almost exclusively by sensory prediction errors. This form of learning had a distinct signature: as <b>motor</b> <b>commands</b> adapted, the subjects altered their predictions regarding sensory consequences of <b>motor</b> <b>commands,</b> and generalized this learning broadly to neighboring <b>motor</b> <b>commands.</b> In contrast, as {{the quality of the}} sensory feedback degraded, adaptation of <b>motor</b> <b>commands</b> became more dependent on reward prediction errors. Reward prediction errors produced comparable changes in the <b>motor</b> <b>commands,</b> but produced no change in the predicted sensory consequences of <b>motor</b> <b>commands,</b> and generalized only locally. Because we found that there was a within subject correlation between generalization patterns and sensory remapping, it is plausible that during adaptation an individual’s relative reliance on sensory vs. reward prediction errors could be inferred. We suggest that while <b>motor</b> <b>commands</b> change because of sensory and reward prediction errors, onl...|$|R
40|$|When {{we use a}} novel tool, the <b>motor</b> <b>commands</b> may {{not produce}} the {{expected}} outcome. In healthy individuals, with practice the brain learns to alter the <b>motor</b> <b>commands.</b> This change depends critically on the cerebellum as damage to this structure impairs adaptation. However, it is unclear precisely what the cerebellum contributes {{to the process of}} adaptation in human motor learning. Is the cerebellum crucial for learning to associate <b>motor</b> <b>commands</b> with novel sensory consequences, called forward model, or is the cerebellum important for learning to associate sensory goals with novel <b>motor</b> <b>commands,</b> called inverse model? Here, we compared performance of cerebellar patients and healthy controls in a reaching task with a gradual perturbation schedule. This schedule allowed both groups to adapt their <b>motor</b> <b>commands.</b> Following training, we measured two kinds of behavior: in one case, people were presented with reach targets near the direction in which they had trained. The resulting generalization patterns of patients and controls were similar, suggesting comparable inverse models. In the second case, participants reached without a target and reported the location of their hand. In controls, the pattern of change in reported hand location was consistent with simulation results of a forward model that had learned to associate <b>motor</b> <b>commands</b> with new sensory consequences. In patients, this change was significantly smaller. Therefore, in our sample of patients, we observed that while adaptation of <b>motor</b> <b>commands</b> can take place despite cerebellar damage, cerebellar integrity appears critical for learning to predict visual sensory consequences of <b>motor</b> <b>commands...</b>|$|R
40|$|Humans perform various motor tasks by {{coordinating}} the redundant motor elements in their bodies. The coordination of motor outputs {{is produced by}} <b>motor</b> <b>commands,</b> as well proper-ties of the musculoskeletal system. The {{aim of this study}} was to dissociate the coordination of <b>motor</b> <b>commands</b> from <b>motor</b> outputs. First, we conducted simulation experiments where the total elbow torque was generated by a model of a simple human right and left elbow with redundant muscles. The results demonstrated that muscle tension with signal-dependent noise formed a coordinated structure of trial-to-trial variability of muscle tension. Therefore, the removal of signal-dependent noise effects was required to evaluate the coordination of <b>motor</b> <b>commands.</b> We proposed a method to evaluate the coordination of <b>motor</b> <b>commands,</b> which removed signal-dependent noise from the measured variability of muscle tension. We used uncontrolled manifold analysis to calculate a normalized index of synergy. Simula-tion experiments confirmed that the proposed method could appropriately represent the coordinated structure of the variability of <b>motor</b> <b>commands.</b> We also conducted experiments in which subjects performed the same task as in the simulation experiments. The normal...|$|R
2500|$|Muscle fatigue is the neuromuscular {{adaptation}} to challenges {{over a period}} of time. [...] The use of motor units {{over a period of}} time can result in changes in the <b>motor</b> <b>command</b> from the brain. [...] Since the force of contraction cannot be changed, the brain instead recruits more motor units to achieve maximal muscle contraction. [...] Recruitment of motor units varies from muscle to muscle depending on the upper limit of motor recruitment in the muscle.|$|E
2500|$|During {{babbling}} the synaptic projections between sensory error {{maps and}} motor map are tuned. This training {{is done by}} generating an amount of semi-random feedforward commands, i.e. the DIVA model [...] "babbles". Each of these babbling commands leads {{to the production of}} an [...] "articulatory item", also labeled as [...] "pre-linguistic (i.e. non language-specific) speech item" [...] (i.e. the articulatory model generates an articulatory movement pattern {{on the basis of the}} babbling <b>motor</b> <b>command).</b> Subsequently an acoustic signal is generated.|$|E
2500|$|Each neuron (model cell, {{artificial}} neuron) {{within the}} speech sound map can be activated and subsequently activates a forward <b>motor</b> <b>command</b> towards the motor map, called articulatory velocity and position map. The activated neural representation [...] {{on the level}} of that motor map determines the articulation of a speech unit, i.e. controls all articulators (lips, tongue, velum, glottis) during the time interval for producing that speech unit. Forward control also involves subcortical structures like the cerebellum, not modelled in detail here.|$|E
40|$|Abstract — In {{an effort}} to ease the burden of {{programming}} <b>motor</b> <b>commands</b> for humanoid robots, a computer vision technique is developed for converting a monocular video sequence of human poses into stabilized robot <b>motor</b> <b>commands</b> for a humanoid robot. The human teacher wears a multi-colored body suit while performing a desired set of actions. Leveraging {{the colors of the}} body suit, the system detects the most probable locations of the different body parts and joints in the image. Then, by exploiting the known dimensions of the body suit, a user specified number of candidate 3 D poses are generated for each frame. Using human to robot joint correspondences, the estimated 3 D poses for each frame are then mapped to corresponding robot <b>motor</b> <b>commands.</b> An initial set of kinematically valid <b>motor</b> <b>commands</b> is generated using an approximate best path search through the pose candidates for each frame. Finally a learning-based probabilistic dynamic balance model obtains a dynamically stable imitative sequence of <b>motor</b> <b>commands.</b> We demonstrate the viability of the approach by presenting results showing full-body imitation of human actions by a Fujitsu HOAP- 2 humanoid robot. I...|$|R
5000|$|... the {{invariant}} <b>motor</b> <b>commands</b> sent to {{muscles to}} move the vocal tract articulators ...|$|R
5000|$|Spinal nerves: They are {{peripheral}} nerves {{that carry}} sensory information into and <b>motor</b> <b>commands</b> {{out of the}} spinal cord.|$|R
2500|$|The central fatigue is {{generally}} {{described in terms}} of a reduction in the neural drive or nerve-based <b>motor</b> <b>command</b> to working muscles that results in a decline in the force output. [...] It has been suggested that the reduced neural drive during exercise may be a protective mechanism to prevent organ failure if the work was continued at the same intensity. The exact mechanisms of central fatigue are unknown, though there has {{been a great deal of}} interest in the role of serotonergic pathways.|$|E
2500|$|On {{the basis}} of the articulatory and {{acoustic}} signal, a specific auditory and somatosensory state pattern is activated {{at the level of the}} sensory state maps (see Fig. 4) for each (pre-linguistic) speech item. At this point the DIVA model has available [...] the sensory and associated motor activation pattern for different speech items, which enables the model to tune the synaptic projections between sensory error maps and motor map. Thus, during babbling the DIVA model learns feedback commands (i.e. how to produce a proper (feedback) <b>motor</b> <b>command</b> for a specific sensory input).|$|E
2500|$|Central fatigue is a {{reduction}} in the neural drive or nerve-based <b>motor</b> <b>command</b> to working muscles that results in a decline in the force output.. [...] It has been suggested that the reduced neural drive during exercise may be a protective mechanism to prevent organ failure if the work was continued at the same intensity. There has {{been a great deal of}} interest in the role of serotonergic pathways for several years because its concentration in the brain increases with motor activity. During motor activity, serotonin released in synapses that contact motoneurons promotes muscle contraction. During high level of motor activity, the amount of serotonin released increases and a spillover occurs. Serotonin binds to extrasynaptic receptors located on the axon initial segment of motoneurons with the result that nerve impulse initiation and thereby muscle contraction are inhibited.|$|E
40|$|The frontal eye field (FEF) {{has been}} known as {{a key player in}} the {{generation}} of saccade <b>motor</b> <b>commands</b> and in the allocation of spatial attention. In this issue of Neuron, Schafer and Moore demonstrate that FEF microstimulation enhances the effect of a position illusion induced by visual motion on saccades. This finding suggests that FEF activity can modulate the deployment of spatial attention, which in turn can alter saccade <b>motor</b> <b>commands...</b>|$|R
40|$|On {{the basis}} of {{findings}} emphasizing the role of perceptual consequences in movement coordination, the authors tested {{the hypothesis that the}} learning of a new bimanual relative phase pattern would involve the matching of the movement-related sensory consequences (rather than the <b>motor</b> outflow <b>commands)</b> to the to-be-learned pattern. Two groups of participants (n = 10 in each) practiced rhythmically moving their forearms with a phase difference of 30 °. In 1 group, a difference in the arms' eigenfrequencies was imposed such that synchronous generation of the left and right <b>motor</b> <b>commands</b> resulted in the required relative phase (30 °), yielding incongruence between the <b>motor</b> <b>commands</b> and their sensory consequences. In the other group, the experimenter imposed no eigenfrequency difference so that the sensory consequences were congruent with the <b>motor</b> <b>commands.</b> Throughout the practice period, performance of both groups was assessed repeatedly for the congruent situation (i. e., no eigenfrequency difference). On those criterion tests, both groups performed the required pattern equally well. The authors discuss that result, which corroborated the hypothesis, from a dynamical systems perspective...|$|R
40|$|This paper {{presents}} {{a method to}} extract salient features from sensory-motor sequences for mobile robot navigation via teleoperation. Salient feature extraction consists of three steps: teleoperation, offline association, and evaluation. First, the mobile robot is teleoperated in an environment along a path several times. All sensory data and <b>motor</b> drive <b>commands,</b> are recorded. During an offline association step, these sensory-motor sequences are partitioned into episodes according to changes in <b>motor</b> <b>commands.</b> Salient features are then extracted by using two statistical criteria: consistency and correlation with the <b>motor</b> <b>commands</b> within the episode boundaries. Finally, these features are used to drive the robot in the learned environment. Some experiment results are also presented. M I...|$|R
5000|$|An inverse model behaves oppositely of {{a forward}} model. Inverse models {{are used by}} nervous systems to {{estimate}} either the <b>motor</b> <b>command</b> that caused a change in sensory information [...] or to determine the <b>motor</b> <b>command</b> that will reach the target state.|$|E
5000|$|... #Caption: [...] An efference copy {{is used to}} {{generate}} the predicted sensory feedback (corollary discharge) which estimate the sensory consequences of a <b>motor</b> <b>command</b> (top row). The actual sensory consequences of the <b>motor</b> <b>command</b> (bottom row) are used to compare with the corollary discharge to inform the CNS about external actions.|$|E
5000|$|An efference {{copy of the}} <b>motor</b> <b>command</b> for song {{production}} {{is the basis of}} the real-time error-correction signal. During singing, activation of LMAN neurons will depend on the motor signal used to generate the song, and the learned prediction of expected auditory feedback based on that <b>motor</b> <b>command.</b> Error correction would occur more rapidly in this model.|$|E
30|$|Secondly, <b>motor</b> <b>commands</b> {{from the}} HMI are valid during whole {{surgical}} process, while the main surgeon control mode is active {{only during the}} intraocular operation procedure.|$|R
50|$|With this knowledge, an {{experiment}} conducted by Smith and Shadmehr (2005) illustrated an impaired ability for cerebellar subjects to alter <b>motor</b> <b>commands</b> {{to compensate for}} applied force fields within a trial (i.e. modify an ongoing movement) {{as well as to}} use this error to update the following trial (i.e. changes in a following trial were unrelated to prior trial error). This agreed with prior work by Mascheke et al. (2004) who illustrated those with cerebellar degeneration had difficulty adapting <b>motor</b> <b>commands</b> when limb dynamics were altered.|$|R
40|$|During adaptation, <b>motor</b> <b>commands</b> tend {{to repeat}} as {{performance}} plateaus. It has been hypothesized that this repetition produces plasticity in the motor cortex (M 1). Here, we considered a force field reaching paradigm, varied the perturbation schedule to potentially alter {{the amount of}} repetition, and quantified the interaction between disruption of M 1 using transcranial magnetic stimulation (TMS) and the schedule of perturbations. In the abrupt condition (introduction of the perturbation on a single trial followed by constant perturbation), motor output adapted rapidly and was then followed by significant repetition as performance plateaued. TMS of M 1 {{had no effect on}} the rapid adaptation phase but reduced adaptation at the plateau. In the intermediate condition (introduction of the perturbation over 45 trials), disruption of M 1 had no effect on the phase in which motor output changed but again impaired adaptation when performance had plateaued. Finally, when the perturbation was imposed gradually (over 240 trials), the <b>motor</b> <b>commands</b> continuously changed during adaptation and never repeated, and disruption of M 1 had no effect on performance. Therefore, TMS of M 1 appeared to reduce adaptation of <b>motor</b> <b>commands</b> during a specific phase of learning: when <b>motor</b> <b>commands</b> tended to repeat. status: publishe...|$|R
5000|$|... #Caption: Figure 1. The desired {{position}} {{of the body is}} the reference input to the hypothetical controller, which generates the necessary <b>motor</b> <b>command.</b> This <b>motor</b> <b>command</b> is sent to the plant to move the body and an efference copy of the <b>motor</b> <b>command</b> is sent to a forward model. The output from the forward model (predicted body position) is compared with the output from the plant (body position). Noise from the system or the environment may cause differences between the actual and predicted body positions. The error (difference) between the actual and predicted positions can provide feedback to improve the movement for the next iteration of the internal model.|$|E
50|$|This efference copy, by {{providing}} the input to a forward internal model, is then used to generate the predicted sensory feedback that estimates the sensory consequences of a <b>motor</b> <b>command.</b> The actual sensory consequences of the <b>motor</b> <b>command</b> are then deployed to compare with the corollary discharge to inform the CNS about how well the expected action matched its actual external action.|$|E
50|$|Prior to movement, an animal's current sensory {{state is}} used to {{generate}} a <b>motor</b> <b>command.</b> To generate a <b>motor</b> <b>command,</b> first, the current sensory state is compared to the desired or target state. Then, the nervous system transforms the sensory coordinates into the motor system's coordinates, and the motor system generates the necessary commands to move the muscles so that the target state is reached.|$|E
40|$|The {{cerebellum}} may monitor <b>motor</b> <b>commands</b> {{and through}} internal feedback correct for anticipated errors. Saccades provide {{a test of}} this idea because these movements are completed too quickly for sensory feedback to be useful. Earlier, we reported that <b>motor</b> <b>commands</b> that accelerate the eyes toward a constant amplitude target showed variability. Here, we demonstrate that this variability is not randomnoise,butisduetothecognitivestateofthesubject. Healthypeopleshowedwithin-saccadecompensationforthisvariabilitywith commands that arrived later in the same saccade. However, in people with cerebellar damage, the same variability resulted in dysmetria. This ability to correct for variability in the <b>motor</b> <b>commands</b> that initiated a saccade was a predictor of each subject’s ability to learn from endpoint errors. In a paradigm in which a target on the horizontal meridian jumped vertically during the saccade (resulting in an endpoint error), the adaptive response exhibited two timescales: a fast timescale that learned quickly from endpoint error but had poor retention, and a slow timescale that learned slowly but had strong retention. With cortical cerebellar damage, the fast timescale of adaptation was effectively absent, but the slow timescale was less impaired. Therefore, the cerebellum corrects for variability in the <b>motor</b> <b>commands</b> that initiate saccades within the same movement via an adaptive response that not only exhibits strong sensitivity to previous endpoint errors, but also rapid forgetting...|$|R
5000|$|During 2004-2007 he led {{the project}} [...] "Brainloop", an {{interactive}} performance platform which allows a subject to navigate a virtual space merely by imagining specific <b>motor</b> <b>commands.</b>|$|R
40|$|Ballistic {{movements}} like saccades {{require the}} brain to generate <b>motor</b> <b>commands</b> {{without the benefit of}} sensory feedback. Despite this, saccades are remarkably accurate. Theory suggests that this accuracy arises because the brain relies on an internal forward model that monitors the <b>motor</b> <b>commands,</b> predicts their sensory consequences, and corrects eye trajectory midflight. If control of saccades relies on a forward model, then the forward model should adapt whenever its predictions fail to match sensory feedback {{at the end of the}} movement. Using optimal feedback control theory, we predicted how this adaptation should alter saccade trajectories. We trained subjects on a paradigm in which the horizontal target jumped vertically during the saccade. With training, the final position of the saccade moved toward the second target. However, saccades became increasingly curved, i. e., suboptimal, as oculomotor commands were corrected on-line to steer the eye toward the second target. The adaptive response had two components: (1) the <b>motor</b> <b>commands</b> that initiated the saccades changed slowly, aiming the saccade closer to the jumped target. The adaptation of these earliest <b>motor</b> <b>commands</b> displayed little forgetting during the rest periods. (2) Late in saccade trajectory, another adaptive response steered it still closer to the jumped target, producing curvature. Adaptation of these late <b>motor</b> <b>commands</b> showed near-complete forgetting during the rest periods. The two components adapted at different timescales, with the late-acting component displaying much faster rates. It appears that in controlling saccades, the brain relies on an internal feedback that has the characteristics of a fast-adapting forward model. Key words: saccade adaptation; forward model; internal feedback; optimal control; curved saccades; fatigu...|$|R
5000|$|In their {{simplest}} form, forward models {{take the}} input of a <b>motor</b> <b>command</b> to the “plant” and output a predicted position of the body.|$|E
5000|$|... the <b>motor</b> <b>command</b> of {{skeletal}} and branchial muscles is monosynaptic (involving {{only one}} motor neuron, respectively, somatic and branchial, which synapses onto the muscle).|$|E
50|$|An {{alternate}} viewpoint on {{the organization}} and control of motor programs may be considered a computational process of selecting a <b>motor</b> <b>command</b> (i.e., the input) to achieve a desired sensory feedback (i.e., the output). Selection of the <b>motor</b> <b>command</b> depends on many internal and external variables, such as {{the current state of}} the limb(s), orientation of the body and properties of the items in the environment with which the body will interact. Given the vast number of possible combinations of these variables, the motor control system must be able to provide an appropriate command for any given context. One strategy for selecting appropriate commands involves a modular approach; multiple controllers exist such that each controller is suitable for one or a small set of contexts. Based on an estimate of the current context, a controller is chosen to generate the appropriate <b>motor</b> <b>command.</b>|$|E
50|$|Inverse models use {{the desired}} and actual {{position}} of the body as inputs to estimate the necessary <b>motor</b> <b>commands</b> which would transform the current position into the desired one. For example, in an arm reaching task, the desired position (or a trajectory of consecutive positions) of the arm is input into the postulated inverse model, and the inverse model generates the <b>motor</b> <b>commands</b> needed to control the arm and bring it into this desired configuration (Figure 2). Inverse internal models are also in close connection with the uncontrolled manifold hypothesis (UCM), see also here.|$|R
50|$|This {{was later}} revised {{to include the}} phonetic {{gestures}} rather than <b>motor</b> <b>commands,</b> and then the gestures intended by the speaker at a prevocal, linguistic level, rather than actual movements.|$|R
5000|$|... #Caption: Figure 2. Inverse {{model of}} a {{reaching}} task. The arm’s desired trajectory, Xref(t), is input into the model, which generates the necessary <b>motor</b> <b>commands,</b> ũ(t), to control the arm.|$|R
