7|162|Public
40|$|James (1954), Ying Yao (1965), Ballin-Pesarin (1990) have {{proposed}} approximate solutions of the Behrens-Fisher p-variate problem. The last-mentioned {{is regarded as}} the best in approximating both the nominal significance level and the power. This solution is based on the nonparametric combination of p permutation tests, each referring to p marginal hypotheses. In Ballin-Pesarin solution, the marginal tests used are Welch's statistical tests, which, as is well known, do not strictly respect the principle of permutation inasmuch as they are quasi-invariant with respect to unknown variance ratios. &# 13; In this paper, I propose a marginal permutation test of sample medians. I believe that, in order to comply more fully with the invariant properties of permutational distribution of the median as opposed to the mean, such medians improve the approximation of the nominal significance level and the exact power. &# 13; It is proved, moreover, that the proposed <b>marginal</b> <b>test</b> is unbiased and consistent...|$|E
40|$|The Bayesian {{approach}} to model selection allows for uncertainty in both model spe-cific parameters {{and in the}} models themselves. Much of the recent Bayesian model uncertainty literature has focused on defining these prior distributions in an objective manner, providing conditions under which Bayes factors lead to the correct model se-lection, particularly in the situation where the number of variables, p, increases with the sample size, n. This is certainly the case in our area of motivation; the biological application of genetic association studies involving single nucleotide polymorphisms. While the most common {{approach to}} this problem has been to apply a <b>marginal</b> <b>test</b> to all genetic markers, we employ analytical strategies that improve upon these marginal methods by modeling the outcome variable {{as a function of}} a multivariate genetic profile using Bayesian variable selection. In doing so, we perform variable selection on a large number of correlated covariates within studies involving modest sample sizes. In particular, we present an efficient Bayesian model search strategy that searche...|$|E
40|$|Recent {{studies on}} highly mobile {{carnivores}} revealed cryptic population genetic structures correlated to transitions in habitat types and prey species composition. This {{led to the}} hypothesis that natal-habitat-biased dispersal {{may be responsible for}} generating population genetic structure. However, direct evidence for the concordant ecological and genetic differentiation between populations of highly mobile mammals is rare. To address this we analyzed stable isotope profiles (d 13 C and d 15 N values) for Eastern European wolves (Canis lupus) as a quantifiable proxy measure of diet for individuals that had been genotyped in an earlier study (showing cryptic genetic structure), to provide a quantitative assessment of the relationship between individual foraging behavior and genotype. We found a significant correlation between genetic distances and dietary differentiation (explaining 46 % of the variation) in both the <b>marginal</b> <b>test</b> and crucially, when geographic distance was accounted for as a co-variable. These results, interpreted in the context of other possible mechanisms such as allopatry and isolation by distance, reinforce earlier studies suggesting that diet and associated habitat choice are influencing th...|$|E
40|$|This article {{proposes a}} general class of joint and <b>marginal</b> {{diagnostic}} <b>tests</b> for parametric conditional mean and variance models of possibly nonlinear non-Markovian time series sequences. The use of joint and <b>marginal</b> <b>tests</b> is motivated {{from the fact}} that <b>marginal</b> <b>tests</b> for the conditional variance may lead misleading conclusions when the conditional mean is misspecified. The new tests are based on a generalized spectral approach and, contrary to existing procedures, they do not need to choose a lag order depending on the sample size or to smooth the data. Moreover, the proposed tests are robust to higher order dependence of unknown form, in particular to conditional skewness and kurtosis. It turns out that the asymptotic null distributions of the new tests depend on the data generating process, so a new bootstrap procedure is proposed and theoretically justified. A simulation study compares the finite sample performance of the proposed and competing tests and shows that our tests can play a valuable role in time series modeling. Finally, an application to the S&P 500 highlights the merits of our approach. ...|$|R
40|$|This {{is a minor}} {{release that}} fixes the {{following}} issues orditkplot passes CRAN tests. anova(, by = "axis") ignored partial terms. Function uses now forward testing which is less dangerously biased than the previous <b>marginal</b> <b>tests.</b> summary and inertcomp for RDA, CCA and frieds failed if constraints had zero rank. meandist labels are no longer cropped in plots. Canberra distance in vegdist can now handle negative entries in input...|$|R
40|$|We {{present a}} new {{computationally}} feasible {{test for the}} dimension of the central subspace in a regression problem based on sliced average variance estimation. We also provide a <b>marginal</b> coordinate <b>test.</b> Under the null hypothesis, both the test of dimension and the <b>marginal</b> coordinate <b>test</b> involve test statistics that asymptotically have chi-squared distributions given normally distributed predictors, and have a distribution that is a linear combination of chi-squared distributions in general. Copyright 2007, Oxford University Press. ...|$|R
40|$|The {{possibility}} of gene-environment interaction can be exploited to identify genetic variants associated with disease using a joint test of genetic main effect and gene-environment interaction. We consider how exposure misclassification and dependence between the true exposure E and the tested genetic variant G affect this joint test {{in absolute terms}} and relative to three other tests: the <b>marginal</b> <b>test</b> (G), the standard test for multiplicative gene-environment interaction (GE), and the case-only test for interaction (GE-CO). All tests can have inflated Type I error rate when E and G are correlated in the underlying population. For the GE and G-GE tests this inflation is only noticeable when the gene-environment dependence is unusually strong; the inflation can be large for the GE-CO test even for modest correlation. The joint G-GE test has greater power than the GE test generally, and greater power than the G test {{when there is no}} genetic main effect and the measurement error is small to moderate. The joint G-GE test is an attractive test for assessing genetic association when there is limited knowledge about casual mechanisms a priori, even in the presence of misclassification in environmental exposure measurement and correlation between exposure and genetic variants...|$|E
40|$|BACKGROUND: Despite {{widespread}} use of 6 and 30 second Wingate anaerobic tests (WAnT), performance reliability of these protocols over repeated trials in active males and females has not been determined. OBJECTIVE: This study assessed the performance reliability and test sensitivity of the 6 s and 30 s WAnT. METHODS: Twenty physically active participants (10 males and 10 females) completed a 6 s and 30 s WAnT against 7. 5 % body mass resistance on four occasions. RESULTS: Peak power output (PPO) and mean power output (MPO) did not differ across trials for either gender. Male PPO in both sprint durations demonstrated random variation (standard error of measurement (SEM)) ≤ 3. 9 % in all between-trials comparisons. For MPO, SEM was ≤ 2. 9 % in all comparisons. For females, random variation in PPO in both sprint durations was lower in trial 3 - 4 than earlier pairs of trials. MPO between trials in the 6 -s sprint was variable, with the smallest variation between trials 1 - 2. For the 30 -s sprint, MPO was more stable across trials. Across all four trials, only MPO in the 30 -s test for males displayed good test sensitivity. CONCLUSIONS: In conclusion, familiarisation may {{not be required to}} establish consistent performance in physically active males or females during the 6 and 30 s WAnT. Furthermore, general <b>marginal</b> <b>test</b> sensitivity in both tests and genders suggests that results of WAnT in physically active participants should not be used to investigate the genuine effect of an intervention...|$|E
40|$|As {{the facts}} {{that led to the}} Dow Jones/Gutnick-decision of the High Court of Australia (10 December 2002) illustrate, the Internet is a {{powerful}} platform for communication. Its continuous worldwide accessibility urges discussion of a number of questions regarding tort jurisdiction. These are the starting points for some critical remarks regarding states' reciprocal claims to cross-border activities {{and the way in which}} they deal with the interests of the involved parties. For tort jurisdiction, the paper proposes and applies criteria for the assessment of the place where the harmful event has occurred or may occur (art. 5, subsection 3 Regulation 44 / 2001), as explained by the European Court of Justice of the European Union. Special attention is hereby given to some particularities that characterize Internet torts. On the one hand it concerns the alleged global assignment of jurisdiction that art. 5, subsection 3 may lead to and on the other hand the scope of the assigned jurisdiction in the court of the place where the damage occurs. The European approach is confronted with the principles of personal jurisdiction that are embedded in long arm statutes and the Due Process Clause, as applied in some leading American cases regarding Internet jurisdiction. It leads to suggestions regarding the development of a <b>marginal</b> <b>test</b> for the reasonableness of the jurisdiction art. 5, subsection 3 could lead to in a particular case, as well from the point of view of the weight of the connecting factor as to the scope of the jurisdiction that is based upon it...|$|E
40|$|We {{propose a}} new {{approach}} for sparse regression and <b>marginal</b> <b>testing,</b> for data with correlated features. Our procedure first clusters the features, and then chooses as the cluster prototype the most informative feature in that cluster. Then we apply either sparse regression (lasso) or <b>marginal</b> significance <b>testing</b> to these prototypes. While this kind of strategy is not entirely new, a key feature of our proposal is its use of the post-selection inference theory of Taylor et al. (2014) and Lee et al. (2014) to compute exact p-values and confidence intervals that properly account for the selection of prototypes. We also apply the recent "knockoff" idea of Barber and Candès to provide exact finite sample control of the FDR of our regression procedure. We illustrate our proposals on both real and simulated data. Comment: 43 pages, 19 figure...|$|R
30|$|For {{each of the}} {{sufficient}} dimension reduction procedures, {{testing is}} done to determine the dimensions. These <b>marginal</b> <b>tests,</b> {{based on the work}} in Cook [52] and Shao et al. [53], are also available in R. The tests are done sequentially, where we first test 0 dimensions versus 1 dimension, 1 dimension versus 2 dimensions, etc. Based on these tests, the dimensions selected for each of the sufficient dimension reduction procedures are summarized in Table 3. The full test results are given in the Additional files 1, 2.|$|R
50|$|A test {{separator}} {{is used to}} separate and to meter the well fluids. The {{test separator}} {{can be referred to}} as a well tester or well checker. Test separators can be vertical, horizontal, or spherical. They can be two-phase or three-phase. They can be permanently installed or portable (skid or trailer mounted). Test separators can be equipped with various types of meters for measuring the oil, gas, and/or water for potential tests, periodic production <b>tests,</b> <b>marginal</b> well <b>tests,</b> etc.|$|R
40|$|The Bayesian {{approach}} to model selection allows for uncertainty in both model specific parameters {{and in the}} models themselves. Much of the recent Bayesian model uncertainty literature has focused on defining these prior distributions in an objective manner, providing conditions under which Bayes factors lead to the correct model selection, particularly in the situation where the number of variables, p, increases with the sample size, n. This is certainly the case in our area of motivation; the biological application of genetic association studies involving single nucleotide polymorphisms. While the most common {{approach to}} this problem has been to apply a <b>marginal</b> <b>test</b> to all genetic markers, we employ analytical strategies that improve upon these marginal methods by modeling the outcome variable {{as a function of}} a multivariate genetic profile using Bayesian variable selection. In doing so, we perform variable selection on a large number of correlated covariates within studies involving modest sample sizes. In particular, we present an efficient Bayesian model search strategy that searches over the space of genetic markers and their genetic parametrization. The resulting method for Multilevel Inference of SNP Associations MISA, allows computation of multilevel posterior probabilities and Bayes factors at the global, gene and SNP level. We use simulated data sets to characterize MISA's statistical power, and show that MISA has higher power to detect association than standard procedures. Using data from the North Carolina Ovarian Cancer Study (NCOCS), MISA identifies variants that were not identified by standard methods and have been externally 'validated' in independent studies. In the context of Bayesian model uncertainty for problems involving a large number of correlated covariates we characterize commonly used prior distributions on the model space and investigate their implicit multiplicity correction properties first in the extreme case where the model includes an increasing number of redundant covariates and then under the case of full rank design matrices. We provide conditions on the asymptotic (in n and p) behavior of the model space prior required to achieve consistent selection of the global hypothesis of at least one associated variable in the analysis using global posterior probabilities (i. e. under 0 - 1 loss). In particular, under the assumption that the null model is true, we show that the commonly used uniform prior on the model space leads to inconsistent selection of the global hypothesis via global posterior probabilities (the posterior probability of at least one association goes to 1) when the rank of the design matrix is finite. In the full rank case, we also show inconsistency when p goes to infinity faster than the square root of n. Alternatively, we show that any model space prior such that the global prior odds of association increases at a rate slower than the square root of n results in consistent selection of the global hypothesis in terms of posterior probabilities. Dissertatio...|$|E
40|$|Abstract Background Recent {{association}} analyses in genome-wide association studies (GWAS) mainly {{focus on}} single-locus association <b>tests</b> (<b>marginal</b> <b>tests)</b> and two-locus interaction detections. These analysis methods have provided strong evidence of associations between genetics variances and complex diseases. However, {{there exists a}} type of association pattern, which often occurs within local regions in the genome and {{is unlikely to be}} detected by either <b>marginal</b> <b>tests</b> or interaction tests. This association pattern involves a group of correlated single-nucleotide polymorphisms (SNPs). The correlation among SNPs can lead to weak marginal effects and the interaction does not play a role in this association pattern. This phenomenon is due to the existence of unfaithfulness: the marginal effects of correlated SNPs do not express their significant joint effects faithfully due to the correlation cancelation. Results In this paper, we develop a computational method to detect this association pattern masked by unfaithfulness. We have applied our method to analyze seven data sets from the Wellcome Trust Case Control Consortium (WTCCC). The analysis for each data set takes about one week to finish the examination of all pairs of SNPs. Based on the empirical result of these real data, we show that this type of association masked by unfaithfulness widely exists in GWAS. Conclusions These newly identified associations enrich the discoveries of GWAS, which may provide new insights both in the analysis of tagSNPs and in the experiment design of GWAS. Since these associations may be easily missed by existing analysis tools, we can only connect some of them to publicly available findings from other association studies. As independent data set is limited at this moment, we also have difficulties to replicate these findings. More biological implications need further investigation. Availability The software is freely available at [URL]. </p...|$|R
5000|$|The Stuart-Maxwell test is {{different}} generalization of the McNemar test, used for <b>testing</b> <b>marginal</b> homogeneity {{in a square}} table with more than two rows/columns.|$|R
40|$|Here is an ado {{file and}} a help file for calculating {{asymptotic}} and exact tests of symmetry for NxN contingency tables from dependent samples. This test {{is known in}} genetics as the TDT test. "symmetry" performs symmetry and <b>marginal</b> homogeneity <b>tests</b> on square NxN tables {{where there is a}} 1 to 1 matching of cases and controls (non-independence). ...|$|R
40|$|Abstract-Magnetoencephalography (MEG) is a {{non-invasive}} neurophysiological technique {{with high}} temporal resolution. Nevertheless, low {{signal to noise}} ratio may hamper its fullest capability. Many confidence tests already exist to detect strong responses for signals corrupted by noise, and we have explored their use with experimentally obtained MEG signals. We find that the tests demonstrating the most power are the F-test and Rayleigh’s phase coherence test. Due to the strongly non-Gaussian nature of the MEG noise, from both neural and external perspective, a signal which is purely noise often fails the <b>marginal</b> <b>tests</b> by exceeding the number of false positive allowed. A variation of the tests is suggested that ensures the average false positive for a large number of responses, excited at frequencies different than the frequency of interest, is below any desired threshold. This is implemented for the F-test, Rayleigh’s phase coherence test, and the union of the two. I...|$|R
30|$|This paper {{presents}} an empirical {{comparison of the}} growth characteristics of four code coverage measures, block, decision, c-use and p-use, as testing is increased. Due to the theoretical foundations underlying the lognormal software reliability growth model, we hypothesize that the growth for each coverage measure is lognormal. Further, since for a given program the breadth {{and the depth of}} the different coverage measures are similar, we expect that the parameters of the lognormal coverage growth model {{for each of the four}} coverage measures to be similar. We confirm these hypotheses using coverage data generated from extensive testing of an application which has 30 KLOC. We then discuss how the lognormal coverage growth function could be used to control the testing process and to guide decisions about when to stop testing, since it can provide an estimate of the <b>marginal</b> <b>testing</b> effort necessary to achieve a given level of improvement in the coverage.|$|R
40|$|In this article, {{we propose}} a new joint {{portmanteau}} test for checking the specification of parametric conditional mean and variance functions of linear and nonlinear time-series models. The {{use of a}} joint test is motivated for complete control of the asymptotic size since <b>marginal</b> <b>tests</b> for the conditional variance may lead to misleading conclusions when the conditional mean is misspecified. The new test {{is based on an}} asymptotically distribution-free transformation on the sample autocorrelations of both normalized residuals and squared normalized residuals. This makes it unnecessary to full detail the asymptotic properties of the estimates used to obtain residuals, which could be inefficient two-step ones, avoiding also choices of maximum lag parameters increasing with sample length to control asymptotic size. The robust versions of the new test also properly account for higher-order moment dependence at a reduced cost. The finitesample performance of the new test is compared with that of well-known tests through simulations. Research support from the Spanish Plan Nacional de I+D+I (ECO 2012 - 31748) is gratefully acknowledgedPublicad...|$|R
40|$|Test {{selection}} in psychological assessment is guided, both explicitly and implicitly, by how informative tests are {{with regard to}} a trait of interest. Most existing formulations of test information are sensitive to subpopulation variation, {{with the result that}} test information will vary from sample to sample. Recently, measures of test information have been developed that quantify the potential informativeness of the test. These indices are defined by the properties of the test, as distinct from the properties of the sample or examinee. As of yet, however, measures of potential information have been developed only for unidimensional tests. In practice, psychological tests are often multidimensional. Furthermore, multidimensional tests are often used to estimate one specific trait among many. This study develops measures of potential test information for multidimensional tests, as well as measures of <b>marginal</b> potential <b>test</b> information [...] -test information with regard to one trait within a multidimensional test. In Study 1, the performance of the metrics was tested in data simulated from unidimensional, first-order multidimensional, second-order, and bifactor models. In Study 2, measures of marginal and multidimensional potential test information are applied to a set of neuropsychological data collected as part of Rush University 2 ̆ 7 s Memory and Aging Project. In simulated data, marginal and multidimensional potential test information were sensitive to the changing dimensionality of the test. In observed neuropsychological data, five traits were identified. Verbal abilities were most closely correlated with probable dementia. Both indices of <b>marginal</b> potential <b>test</b> information identify the Mini Mental Status Exam as the best measure of that trait. More broadly, greater <b>marginal</b> potential <b>test</b> information calculated with regard to verbal abilities was associated with greater criterion validity. These measures allow for the direct comparison of two multidimensional tests that assess the same trait, facilitating test selection and improving the precision and validity of psychological assessment...|$|R
40|$|Abstract Background A multivariate {{genome-wide}} association test {{is proposed}} for analyzing data on multivariate quantitative phenotypes collected from related subjects. The proposed method is a two-step approach. The first step models {{the association between}} the genotype and marginal phenotype using a linear mixed model. The second step uses the correlation between residuals of the linear mixed model to estimate the null distribution of the Fisher combination test statistic. Results The simulation {{results show that the}} proposed method controls the type I error rate and is more powerful than the <b>marginal</b> <b>tests</b> across different population structures (admixed or non-admixed) and relatedness (related or independent). The statistical analysis on the database of the Study of Addiction: Genetics and Environment (SAGE) demonstrates that applying the multivariate association test may facilitate identification of the pleiotropic genes contributing to the risk for alcohol dependence commonly expressed by four correlated phenotypes. Conclusions This study proposes a multivariate method for identifying pleiotropic genes while adjusting for cryptic relatedness and population structure between subjects. The two-step approach is not only powerful but also computationally efficient even when the number of subjects and the number of phenotypes are both very large...|$|R
40|$|This paper {{considers}} a general heteroskedastic error component model using panel data, and derives a joint LM test for homoskedasticity against the alternative of heteroskedasticity in both error components. It contrasts this joint LM <b>test</b> with <b>marginal</b> LM <b>tests</b> that ignore the heteroskedasticity {{in one of}} the error components. Monte Carlo results show that misleading inference can occur when using marginal rather than joint tests when heteroskedasticity is present in both components. panel data, heteroskedasticity, Lagrange multiplier tests, error components, Monte Carlo simulations...|$|R
40|$|In {{the paper}} are {{presented}} results of testing electric detonators according to New European Standards. In {{order to establish}} real, <b>marginal</b> values, <b>testing</b> have been performed on suggested devices with extreme parameters applied. Consequently, sensitivity on impact of bridge wire, primary and secondary explosive charge, thermal stability, resistance to water and resistance to hydrostatic pressure of electrical detonators have been measured with wider range that proscribed by the standard. The results obtained by the research were used to evaluate reality of proposed values in New European Standards...|$|R
40|$|A {{major goal}} of genetic {{association}} studies concerned with {{single nucleotide polymorphisms}} (SNPs) is the detection of SNPs exhibiting {{an impact on the}} risk of developing a disease. Typically, this problem is approached by testing each of the SNPs individually. This, however, can lead to an inaccurate measurement of the influence of the SNPs on the disease risk, in particular, if SNPs only show an effect when interacting with other SNPs, as the multivariate structure of the data is ignored. In this article, we propose a testing procedure based on logic regression that takes this structure into account and therefore enables a more appropriate quantification of importance and ranking of the SNPs than <b>marginal</b> <b>testing.</b> Since even SNP interactions often exhibit only a moderate effect on the disease risk, it can be helpful to also consider sets of SNPs (e. g. SNPs belonging to the same gene or pathway) to borrow strength across these SNP sets and to identify those genes or pathways comprising SNPs that are most consistently associated with the response. We show how the proposed procedure can be adapted for testing SNP sets, and how it can be applied to blocks of SNPs in linkage disequilibrium (LD) to overcome problems caused by LD...|$|R
40|$|We {{propose a}} multivariate {{genome-wide}} association test for mixed continuous, binary, and ordinal phenotypes. A latent response model {{is used to}} estimate the correlation between phenotypes with different measurement scales so that the empirical distribution of the Fisher's combination statistic under the null hypothesis is estimated efficiently. The simulation study shows that our proposed correlation estimation methods {{have high levels of}} accuracy. More importantly, our approach conservatively estimates the variance of the test statistic so that the type I error rate is controlled. The simulation also shows that the proposed test maintains the power at the level very close to that of the ideal analysis based on known latent phenotypes while controlling the type I error. In contrast, conventional approaches-dichotomizing all observed phenotypes or treating them as continuous variables-could either reduce the power or employ a linear regression model unfit for the data. Furthermore, the statistical analysis on the database of the Study of Addiction: Genetics and Environment (SAGE) demonstrates that conducting a multivariate test on multiple phenotypes can increase the power of identifying markers that may not be, otherwise, chosen using <b>marginal</b> <b>tests.</b> The proposed method also offers a new approach to analyzing the Fagerström Test for Nicotine Dependence as multivariate phenotypes in genome-wide association studies...|$|R
40|$|An {{efficient}} testing strategy {{called the}} “focused interaction testing framework” (FITF) {{was developed to}} identify susceptibility genes involved in epistatic interactions for case-control studies of candidate genes. In the FITF approach, likelihood-ratio tests are performed in stages that increase {{in the order of}} interaction considered. Joint tests of main effects and interactions are performed conditional on significant lower-order effects. A {{reduction in the number of}} tests performed is achieved by prescreening gene combinations with a goodness-of-fit χ 2 statistic that depends on association among candidate genes in the pooled case-control group. Multiple testing is accounted for by controlling false-discovery rates. Simulation analysis demonstrated that the FITF approach is more powerful than <b>marginal</b> <b>tests</b> of candidate genes. FITF also outperformed multifactor dimensionality reduction when interactions involved additive, dominant, or recessive genes. In an application to asthma case-control data from the Children’s Health Study, FITF identified a significant multilocus effect between the nicotinamide adenine dinucleotide (phosphate) reduced:quinone oxidoreductase gene (NQO 1), myeloperoxidase gene (MPO), and catalase gene (CAT) (unadjusted P=. 00026), three genes that are involved in the oxidative stress pathway. In an independent data set consisting primarily of African American and Asian American children, these three genes also showed a significant association with asthma status (P=. 0008) ...|$|R
40|$|Graduation date: 1964 The {{impact of}} the {{electronic}} computer on the teaching of mathematics, science, and engineering has created {{the need for a}} relatively low cost instructional digital computer. SPEDTAC (stored Program Educational Digital Transistorized Automatic Computer) was designed specifically to fulfill this need. The prototype described is a serial, solid state, single address, binary type stored program digital computer. The magnetic disc memory has a capacity of 256 thirteen bit words, with an average access time of 8. 3 milliseconds. Registers are implemented from transistor flip-flops, and the diode-transistor NAND circuit is the principal logical gating element. Stroke and dagger functions are used to describe the logical design equations. PIug in printed circuit cards and a built in <b>marginal</b> <b>testing</b> facility provide ease of maintenance. There are no special cooling or power requirements. The computer has a repertoire of sixteen basic instructions which permit the handling {{of a wide variety of}} arithmetic and logical problems. A variety of programs and subroutines have been prepared and tested. Operation over a period of a year has shown reliability and results in the classroom to be good. Recommendation is made that consideration be given to doubling the word capacity of the memory in future models...|$|R
40|$|This paper {{develops}} a nonparametric procedure for <b>testing</b> <b>marginal</b> independence based on bivariate current status data. Asymptotic {{properties of the}} proposed tests are derived and their finite sample performance is studied via simulations. The method is applied to analyze data from a community-based study of cardiovascular epidemiology in Taiwan...|$|R
40|$|Where {{biological}} datasets are spatially limited, abiotic surrogates {{have been}} advocated to inform objective planning for Marine Protected Areas. However, this approach assumes close correlation between abiotic and biotic patterns. The Solitary Islands Marine Park, northern NSW, Australia, currently uses a habitat classification system (HCS) {{to assist with}} planning, but this is based only on data for reefs. We used Baited Remote Underwater Videos (BRUVs) to survey fish assemblages of unconsolidated substrata at different depths, distances from shore, and across an along-shore spatial scale of 10 s of km (2 transects) to examine how well the HCS works for this dominant habitat. We used multivariate regression modelling to examine the importance of these, and other environmental factors (backscatter intensity, fine-scale bathymetric variation and rugosity), in structuring fish assemblages. There were significant differences in fish assemblages across depths, distance from shore, and over the medium spatial scale of the study: together, these factors generated the optimum model in multivariate regression. However, <b>marginal</b> <b>tests</b> suggested that backscatter intensity, which itself is a surrogate for sediment type and hardness, might also influence fish assemblages and needs further investigation. Species richness was significantly different across all factors: however, total MaxN only differed significantly between locations. This study demonstrates that the pre-existing abiotic HCS only partially represents the range of fish assemblages of unconsolidate...|$|R
40|$|We {{develop new}} tests for the {{hypothesis}} of unit roots {{that are based on}} the marginal likelihood of the general linear model. The marginal likelihood allows the incorporation of invariance arguments in the likelihood function. It turns out that <b>marginal</b> likelihood <b>tests</b> for unit roots appear to be more powerful than other unit root tests. For some basic models power functions almost coincide with the power envelopes, even in small samples. General correlation structures can be incorporated, either by standard likelihood procedures or by adjustments of the test statistics on the basis of asymptotic distributions. © 2006 Elsevier B. V. All rights reserved...|$|R
40|$|Description Model-free {{selection}} of covariates under unconfoundedness for {{situations where the}} parameter of interest is an average causal effect. This package is based on model-free backward elimination algorithms proposed in de Luna, Waernbaum and Richardson (2011). <b>Marginal</b> co-ordinate hypothesis <b>testing</b> is used in situations where all covariates are continuous while kernel-based smoothing appropriate for mixed data is used otherwise...|$|R
40|$|This study {{documents}} {{evidence of}} a "quality effect " of financial liberalization on allocative efficiency, as measured by dispersion in Tobin's Q across firms. Based on a simple model, we predict that financial liberalization, by equalizing access to credit, reduces the variation in expected <b>marginal</b> returns. We <b>test</b> this prediction using a new financial liberalization inde...|$|R
40|$|Hypothesis: A {{change in}} tumor {{expression}} profile will be observed during {{the transformation of}} differentiated into anaplastic thyroid carcinoma. Design Cohort study. Setting Population-based sample (British Columbia). Patients Sequential archival cases of anaplastic thyroid cancer with an adjacent associated differentiated thyroid cancer focus, and with available paraffin blocks, that had been diagnosed and treated in British Columbia during a 20 -year period (12 cases; January 1, 1984, through December 31, 2004) were identified through the provincial tumor registry for tissue microarray construction. Main Outcome Measure Significant associations between marker staining and tumor pathologic diagnosis (differentiated vs anaplastic) were determined with contingency table and <b>marginal</b> homogeneity <b>tests.</b> A classifier algorithm was also used to identify useful and important molecular classifiers. Results :Overall, there were 3 up-regulated and 5 down-regulated markers when comparing the anaplastic carcinoma with associated differentiated thyroid cancers. Contingency table statistics identified 5 markers (thyroglobulin, Bcl- 2, MIB- 1, E-cadherin, and p 53) to be significantly differentially expressed by the anaplastic and differentiated tumor foci. These 5 markers and 3 others (-catenin, topoisomerase II-, and vascular endothelial growth factor) were significant when evaluated using the <b>marginal</b> homogeneity <b>test.</b> Clustering and classification analysis based on these same 8 markers readily separated differentiated and anaplastic thyroid tumors {{with a high degree}} of accuracy. Conclusion :The markers we observed to change during thyroid tumor progression may not only show promise as molecular diagnostic or prognostic tools but also warrant further study as potential targets for treatment of disease...|$|R
40|$|We {{study the}} {{feasibility}} of level expansion and test the quartic vertex of closed string field theory by checking the flatness of the potential in <b>marginal</b> directions. The <b>tests,</b> which work out correctly, require the cancellation of two contributions: one from an infinite-level computation with the cubic vertex and the other from a finite-level computation with the quartic vertex. The numerical result...|$|R
40|$|International audienceThis paper {{proposes a}} semi-parametric test of {{independence}} (or serial independence) between marginal vectors {{each of which}} is normally distributed but without assuming the joint normality of these <b>marginal</b> vectors. The <b>test</b> statistic is a Cramér­von Mises functional of a process defined from the empirical characteristic function. This process is defined similarly as the process of Ghoudi et al. [J. Multivariate Anal. 79 (2001) 191] built from the empirical distribution function and used to test for independence between univariate <b>marginal</b> variables. The <b>test</b> statistic can be represented as a V-statistic. It is consistent to detect any form of dependence. The weak convergence of the process is derived. The asymptotic distribution of the Cramér­von Mises functionals is approximated by the Cornish­Fisher expansion using a recursive formula for cumulants and inversion of the characteristic function with numerical evaluation of the eigenvalues. The test statistic is finally compared with Wilks statistic for testing the parametric hypothesis of independence in the one-way MANOVA model with random effects...|$|R
40|$|Epistasis {{could be}} an {{important}} source of risk for disease. How interacting loci might be discovered is an open question for genome-wide association studies (GWAS). Most researchers limit their statistical analyses to testing individual pairwise interactions (i. e., <b>marginal</b> <b>tests</b> for association). A more effective means of identifying important predictors is to fit models that include many predictors simultaneously (i. e., higher-dimensional models). We explore a procedure called screen and clean (SC) for identifying liability loci, including interactions, by using the lasso procedure, which is a model selection tool for high-dimensional regression. We approach the problem by using a varying dictionary consisting of terms to include in the model. In the first step the lasso dictionary includes only main effects. The most promising single-nucleotide polymorphisms (SNPs) are identified using a screening procedure. Next the lasso dictionary is adjusted to include these main effects and the corresponding interaction terms. Again, promising terms are identified using lasso screening. Then significant terms are identified through the cleaning process. Implementation of SC for GWAS requires algorithms to explore the complex model space induced by the many SNPs genotyped and their interactions. We propose and explore a set of algorithms and find that SC successfully controls Type I error while yielding good power to identify risk loci and their interactions. When the method is applied to data obtained from the Wellcome Trust Case Control Consortium study of Type 1 Diabetes it uncovers evidence supporting interaction within the HLA class II region as well as within Chromosome 12 q 24...|$|R
