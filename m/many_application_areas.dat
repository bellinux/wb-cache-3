814|10000|Public
2500|$|Combinatorics is {{well known}} for the breadth of the {{problems}} it tackles. Combinatorial problems arise in many areas of pure mathematics, notably in algebra, probability theory, topology, and geometry, as well as in its <b>many</b> <b>application</b> <b>areas.</b> Many combinatorial questions have historically been considered in isolation, giving an ad hoc solution to a problem arising in some mathematical context. In the later twentieth century, however, powerful and general theoretical methods were developed, making combinatorics into an independent branch of mathematics in its own right. One of the oldest and most accessible parts of combinatorics is graph theory, which by itself has numerous natural connections to other areas. [...] Combinatorics is used frequently in computer science to obtain formulas and estimates in the analysis of algorithms.|$|E
5000|$|Improved testability: <b>Many</b> <b>{{application}}</b> <b>areas</b> can be reconfigured {{to improve}} {{testing of the}} application in isolation.|$|E
50|$|PDE {{surfaces}} can be utilised in <b>many</b> <b>application</b> <b>areas.</b> These include computer-aided design, interactive design, parametric design, computer animation, computer-aided {{physical analysis}} and design optimisation.|$|E
50|$|These {{considerations}} occur {{frequently in}} practice and so integer linear programming {{can be used in}} <b>many</b> <b>applications</b> <b>areas,</b> some of which are briefly described below.|$|R
50|$|There {{are over}} 150 {{available}} jEdit plug-ins for <b>many</b> different <b>application</b> <b>areas.</b>|$|R
40|$|Structured, spatial-temporal data {{arises in}} <b>many</b> <b>applications</b> <b>areas</b> such as transportation, sensor {{networks}} or mobile services. Peer to peer networks are the natural {{choice for the}} distributed architecture required by these applications. However, a closer analysis of the available distributed hash table (DHT) based approaches shows their inefficiency since the data structure gets lost and the short liveness of the data leads to a high signalling traffic. In this work we propose a novel storage network based on an overlay of Space-based Computing Containers for storing, accessing and manipulating dynamic data. ...|$|R
50|$|The {{shape memory}} alloy {{is used in the}} {{production}} of a variety of devices (valves, proportional valves, actuators, release systems, mini-actuators). The use of SMA devices in the industrial field goes across the board of <b>many</b> <b>application</b> <b>areas</b> such as domotics, the white goods industry, the automotive business and consumer electronics.|$|E
50|$|Solenoid valves are {{the most}} {{frequently}} used control elements in fluidics. Their tasks are to shut off, release, dose, distribute or mix fluids. They are found in <b>many</b> <b>application</b> <b>areas.</b> Solenoids offer fast and safe switching, high reliability, long service life, good medium compatibility of the materials used, low control power and compact design.|$|E
5000|$|A {{region of}} {{interest}} (often abbreviated ROI), are samples within an data set identified for a particular purpose. The concept of a ROI is commonly used in <b>many</b> <b>application</b> <b>areas.</b> For example, in medical imaging, the boundaries of a tumor may be defined on an image or in a volume, {{for the purpose of}} measuring its size. The endocardial border may be defined on an image, perhaps during different phases of the cardiac cycle, for example end-systole and end-diastole, for the purpose of assessing cardiac function. In geographical information systems (GIS), a ROI can be taken literally as a polygonal selection from a 2D map. In computer vision and optical character recognition, the ROI defines the borders of an object under consideration. In many applications, symbolic (textual) labels are added to a ROI, to describe its content in a compact manner. Within a ROI may lie individual points of interest (POIs).|$|E
30|$|The interval-valued {{analysis}} and interval differential equations are specific cases of set-valued {{analysis and}} set differential equations, respectively [1 – 3]. Interval analysis is introduced {{as an attempt}} to handle interval uncertainty, while interval differential equations are natural models for describing dynamic systems under uncertainty, and this approach is useful in <b>many</b> <b>applications</b> <b>areas,</b> such as physics and engineering [4, 5]. As in classical real analysis, the importance of the derivative of an interval-valued function in the study of interval differential equations is well known. On the other hand, the inversions of addition and multiplication are fundamental in interval arithmetic, interval analysis, and the concept of interval differentiability.|$|R
40|$|It is {{well known}} that the HEPWM {{technique}} can provide highest quality output waveforms at low switching frequencies in comparison to other PWM techniques. Many HEPWM schemes have been proposed, including several types which allows for offline and online calculation of the HEPWM switching angles in <b>many</b> <b>application</b> <b>area.</b> However, the development of HEPWM involves transcendental equations that contain trigonometric terms is difficult to solve. The purpose of this project is to provide a comprehensive review on HEPWM schemes that have been proposed including several types which allows for offline and online calculation of the HEPWM switching angels and the methods involved for solving the HEPWM equations...|$|R
40|$|Abstract—Knowledge-based systems (KBS) {{are being}} used in <b>many</b> <b>applications</b> <b>areas</b> where their {{failures}} can be costly because of the losses in services, property, or even life. To ensure their reliability and dependability, it is therefore important that these systems are verified and validated before they are deployed. This paper provides perspectives on issues and problems that impact the verification and validation (V&V) of KBS. Some of the reasons V&V of KBS is difficult are presented. The paper also {{provides an overview of}} different techniques and tools that have been developed for performing V&V activities. Finally, some of the research issues that are relevant for future work in this field are discussed...|$|R
50|$|ISO/TC 37 looks upon a {{long history}} of {{terminology}} unification activities. In the past, terminology experts - even more so experts of terminology theory and methodology - had to struggle for wide recognition. Today their expertise is sought in <b>many</b> <b>application</b> <b>areas,</b> especially in various fields of standardization. The emerging multilingual information society and knowledge society will depend on reliable digital content. Terminology is indispensable here. This is because terminology plays a crucial role wherever and whenever specialized information and knowledge is being prepared (e.g. in research and development), used (e.g. in specialized texts), recorded and processed (e.g. in data banks), passed on (via training and teaching), implemented (e.g. in technology and knowledge transfer), or translated and interpreted. In the age of globalization the need for methodology standards concerning multilingual digital content is increasing - ISO/TC 37 has developed over the years the expertise for methodology standards for science and technology related content in textual form.|$|E
50|$|Parallel multidimensional {{digital signal}} {{processing}} (mD-DSP) {{is defined as the}} application of parallel programming and multiprocessing to {{digital signal processing}} techniques to process digital signals that have more than a single dimension. The use of mD-DSP is fundamental to <b>many</b> <b>application</b> <b>areas</b> such as digital image and video processing, medical imaging, geophysical signal analysis, sonar, radar, lidar, array processing, computer vision, computational photography, and augmented and virtual reality. However, as the number of dimensions of a signal increases the computational complexity to operate on the signal increases rapidly. This relationship between the number of dimensions and the amount of complexity, related to both time and space, as studied in the field of algorithm analysis, is analogues to the concept of the curse of dimensionality. This large complexity generally results in an extremely long execution run-time of a given mD-DSP application rendering its usage to become impractical for many applications; especially for real-time applications. This long run-time is the primary motivation of applying parallel algorithmic techniques to mD-DSP problems.|$|E
5000|$|Association rule {{learning}} is a rule-based machine learning method for discovering interesting relations between variables in large databases. It is intended to identify strong rules discovered in databases using some measures of interestingness. [...] Based {{on the concept of}} strong rules, Rakesh Agrawal, Tomasz Imieliński and Arun Swami [...] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets. For example, the rule [...] found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as, e.g., promotional pricing or product placements. In addition to the above example from market basket analysis association rules are employed today in <b>many</b> <b>application</b> <b>areas</b> including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.|$|E
40|$|Using a recently-developed {{boundary}} element {{approach for}} electrical impedance tomography {{the identification of}} boundary shapes between materials of contrasting conductivity is considered. The examples considered are motivated {{by the desire to}} locate damages in filter and catalyst beds in industrial processes, but they are also applicable in <b>many</b> <b>applications</b> <b>areas</b> where the unknown location of a boundary is sought. The approach to reconstruction of the boundary location is statistical and is based upon Markov chain Monte Carlo techniques. The degree of accuracy and reliability of the reconstructed estimates is quantified through credible intervals. The results demonstrate that the proposed methods are well suited for shape estimation from electrical impedance tomography data...|$|R
50|$|Steam boilers {{are used}} where steam and hot steam is needed. Hence, steam boilers {{are used as}} {{generators}} to produce electricity in the energy business. Besides <b>many</b> different <b>application</b> <b>areas</b> in the industry for example in heating systems or for cement production, steam boilers are used in agriculture as well for soil steaming.|$|R
40|$|The eXtensible Markup Language (XML) is well {{accepted}} in <b>many</b> different <b>application</b> <b>areas.</b> As a consequence, {{there is an}} increasing need for persistently storing XML documents. As soon as <b>many</b> users and <b>applications</b> work concurrently on the same collection of XML documents [...] - i. e. an XML base [...] - isolating accesses and modifications of different transactions becomes an important issue. We discuss si...|$|R
40|$|The multi-comparand {{associative}} search paradigm {{is shown to}} be efficient in processing complex search problems from <b>many</b> <b>application</b> <b>areas</b> including computational geometry, graph theory, and list/matrix computations. In this paper the first FPGA implementation of a small multi-comparand multi-search associative processor is reported...|$|E
30|$|Reversible computation (Perumalla 2013) {{has gained}} {{more and more}} {{attention}} in <b>many</b> <b>application</b> <b>areas,</b> such as the modeling of biochemical systems, program debugging and testing, and also quantum computing. For the excellent properties reversible computing has, it will be exploited in many computing devices in the future.|$|E
40|$|In {{recent decades}} {{parallel}} and distributed {{systems have been}} extensively used in <b>many</b> <b>application</b> <b>areas,</b> {{and there has been}} signi cant e ort in developing formal methodologies for the speci cation and analysis of such systems � unfortunately not always completely satisfactorily. The presence of concurrency...|$|E
40|$|The {{circular}} traffic problem, {{also known}} as the Travelling Salesman Problem (TSP) belongs to a group called distribution problems, {{which is one of the}} significant group of linear programming. These tasks can be used in <b>many</b> <b>applications</b> <b>areas</b> such as production planning, logistic or travelling. This thesis deals with the application of TSP or its modification to find the optimal route among selected Vietnamese destinations. The aim is to find the best circuit among 20 places out of 37 considering the cost and time. The first chapter concentrates on the general theory of linear programming including the description of economical and mathematical models of the selected distribution problems. The main part of this thesis focuses on The Travelling Salesman Problem itself and its practical applicatio...|$|R
50|$|Hamiltonian {{coloring}} {{is a type}} of graph coloring. Hamiltonian coloring uses {{a concept}} called detour distance between two vertices of the graph. It has <b>many</b> <b>applications</b> in different <b>areas</b> of science and technology.|$|R
5000|$|Besides the <b>many</b> {{specific}} <b>applications,</b> one <b>area</b> {{of research}} is methods for the accurate and efficient solution of multiscale modeling problems. The primary areas of mathematical and algorithmic development include: ...|$|R
40|$|We {{address a}} {{generalization}} of graphs, the directed hypergraphs, {{and show that}} they are a powerful tool in modelling and solving several relevant problems in <b>many</b> <b>application</b> <b>areas.</b> Such application areas include Linear Production Problems, Flexible Manufacturing Systems, Propositional Logic, Relational Databases, and Public Transportation Systems...|$|E
30|$|Discretization of the {{fractional}} Fourier transform (FrFT) {{is vital}} in <b>many</b> <b>application</b> <b>areas</b> including signal and image processing, filtering, sampling, and time-frequency analysis [1 – 3]. As FrFT {{is related to}} the Wigner distribution [1], it is a powerful tool for time-frequency analysis, for example, chirp rate estimation [4].|$|E
40|$|Multiresolution data {{arise when}} an object or a {{phenomenon}} is described at several levels of detail Multiresolution data is prevalent in <b>many</b> <b>application</b> <b>areas</b> F Examples include biology, computer vision Faster growth of multiresolution data {{is expected in}} future Over the years, data accumulates in multiple resolutions becaus...|$|E
50|$|A {{distributed}} {{algorithm is}} an algorithm designed {{to run on}} computer hardware constructed from interconnected processors. Distributed algorithms are used in <b>many</b> varied <b>application</b> <b>areas</b> of distributed computing, such as telecommunications, scientific computing, distributed information processing, and real-time process control. Standard problems solved by distributed algorithms include leader election, consensus, distributed search, spanning tree generation, mutual exclusion, and resource allocation.|$|R
40|$|This {{articles}} {{provides a}} review of recent advances in modeling spatio-temporal data. In an attempt to unify the modeling strategies we describe the primary spatio-temporal data types. We then discuss general models for point reference data only. Spatial-temporal modeling has largely been developed through applications in environmental, geostatistics, hydrology and meteorology. We review current methods for <b>many</b> such <b>application</b> <b>areas...</b>|$|R
40|$|The {{field of}} time series data mining has seen an {{explosion}} of interest in recent years. This interest has flowed over into <b>many</b> <b>applications</b> <b>areas,</b> including fiber manufacturing systems. The volume of time series data generated by a fiber monitoring system can be huge. This limits the applicability of data mining algorithms to this problem domain. A widely used solution {{is to reduce the}} data size through feature extraction. Four of the mostly commonly used feature extraction techniques are Fourier transforms, Wavelets, Piecewise Aggregate Approximation, and Piecewise Linear Approximation (PLA). In this paper, we first empirically demonstrate that PLA techniques produce the highest quality features for this problem domain. We then introduce a novel PLA algorithm that is shown to produce higher quality features than any other currently available techniques. 1...|$|R
40|$|Multi-modal {{models of}} {{physical}} objects {{are important in}} <b>many</b> <b>application</b> <b>areas,</b> but constructing such models has been di#cult. ACME, the UBC Active Measurement facility, is a robotic facility we have developed for constructing such models. We describe the construction of multi-modal models, including models of shape, contact sounds, and surface roughness...|$|E
40|$|In <b>many</b> <b>application</b> <b>areas</b> {{involving}} the mathematical modeling of convection, diusion, and reaction processes, diusion can be small (compared to the convection {{and the reaction}} coe-cients), degenerate, or even identically equal to zero in subregions of the computational domain. This multi-scale behavior between convection and diusion creates various challenges in th...|$|E
40|$|Abstract. We {{show that}} in <b>many</b> <b>application</b> <b>areas</b> {{including}} soft constraints reasonable requirements of scale-invariance lead to polynomial (tensor-based) formulas for combining degrees (of certainty, of preference, etc.) Partial orders naturally appear in <b>many</b> <b>application</b> <b>areas.</b> One of the main objectives of science and engineering is to help people select decisions which are the most beneficial to them. To make these decisions, – we must know people’s preferences, – we must have the information about different events – possible consequences of different decisions, and – since information is never absolutely accurate and precise, we must also have information about the degree of certainty. All these types of information naturally lead to partial orders: – For preferences, a < b means that b is preferable to a. This relation is used in decision theory; see, e. g., [1]...|$|E
40|$|Wireless sensor nodes (WSNs) are {{employed}} today in <b>many</b> different <b>application</b> <b>areas,</b> ranging from health and lifestyle to automotive, smart building, predictive maintenance (e. g., of machines and infrastructure), and active RFID tags. Currently these devices have limited lifetimes, however, since they require significant operating power. The typical power requirements of some current portable devices, including a body sensor network, {{are shown in}} Figure 1...|$|R
40|$|Hollow glass micro-spheres, {{first used}} to make fibre optic sensors for high {{hydrostatic}} pressure, have been interrogated using a high-precision CCD spectrometer, to give far better precision than earlier. It is found that these simple, low-cost micro-sensors have excellent sensitivity to both static and dynamic pressure, and {{have the advantage of}} being hermetically sealed. <b>Many</b> other <b>application</b> <b>areas</b> are foreseen for these low-cost sensors...|$|R
40|$|Saddle-point systems {{arise in}} <b>many</b> <b>applications</b> <b>areas,</b> {{in fact in}} any {{situation}} where an extremum principle arises with constraints. The Stokes problem describing slow viscous flow of an incompressible fluid {{is a classic example}} coming from partial differential equations and in the area of Optimization such problems are ubiquitous. In this manuscript we show how new approaches for the solution of saddle-point systems arising in Optimization can be derived from the Bramble-Pasciak Conjugate Gradient approach widely used in PDEs and more recent generalizations thereof. In particular we derive a class of new solution methods based on the use of Preconditioned Conjugate Gradients in non-standard inner products and demonstrate how these can be understood through more standard machinery. We show connections to Constraint Preconditioning and give the results of numerical computations on a number of standard Optimization test examples. ...|$|R
