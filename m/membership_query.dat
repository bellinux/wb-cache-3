72|560|Public
5000|$|Type : Indicates {{the message}} type as follows: <b>Membership</b> <b>Query</b> (0x11), Membership Report (IGMPv1: 0x12, IGMPv2: 0x16, IGMPv3: 0x22), Leave Group (0x17) ...|$|E
5000|$|The {{teaching}} {{dimension of}} a finite concept class {{can be used}} to give a lower and an upper bound on the <b>membership</b> <b>query</b> cost of the concept class.|$|E
5000|$|Max Resp Time : Specifies {{the time}} limit for the {{corresponding}} report. The field has {{a resolution of}} 100 milliseconds, the value is taken directly. This field is meaningful only in <b>Membership</b> <b>Query</b> (0x11); in other messages it is set to 0 and ignored by the receiver.|$|E
40|$|We {{consider}} {{the problem of}} proper learning a Boolean Halfspace with integer weights { 0, 1, [...] .,t} from <b>membership</b> <b>queries</b> only. The best known algorithm for this problem is an adaptive algorithm that asks n^O(t^ 5) <b>membership</b> <b>queries</b> where the best lower bound {{for the number of}} <b>membership</b> <b>queries</b> is n^t [Learning Threshold Functions with Small Weights Using <b>Membership</b> <b>Queries.</b> COLT 1999] In this paper we close this gap and give an adaptive proper learning algorithm with two rounds that asks n^O(t) <b>membership</b> <b>queries.</b> We also give a non-adaptive proper learning algorithm that asks n^O(t^ 3) <b>membership</b> <b>queries...</b>|$|R
40|$|We {{study the}} {{learning}} models defined in [D. Angluin, M. Krikis, R. H. Sloan, G. Turán, Malicious omissions and errors in an-swering to <b>membership</b> <b>queries,</b> Machine Learning 28 (2 – 3) (1997) 211 – 255]: Learning with equivalence and limited <b>membership</b> <b>queries</b> and learning with equivalence and malicious <b>membership</b> <b>queries.</b> We show {{that if a}} class of concepts that is closed under projection is learnable in polynomial time using equivalence and (standard) <b>membership</b> <b>queries</b> then it is learnable in polynomial time in the above models. This closes the open problems in [D. Angluin, M. Krikis, R. H. Sloan, G. Turán, Malicious omissions and errors in answering to <b>membership</b> <b>queries,</b> Machin...|$|R
40|$|Abstract. We {{consider}} {{a model of}} learning Boolean functions from quantum <b>membership</b> <b>queries.</b> This model was studied in [26], where it was shown that any class of Boolean functions which is information-theoretically learnable from polynomially many quantum <b>membership</b> <b>queries</b> is also information-theoretically learnable from polynomially many classical <b>membership</b> <b>queries.</b> In this paper we establish a strong computational separation between quantum and classical learning. We prove that if any cryptographic one-way function exists, {{then there is a}} class of Boolean functions which is polynomial-time learnable from quantum <b>membership</b> <b>queries</b> but not polynomial-time learnable from classical <b>membership</b> <b>queries.</b> A novel consequence of our result is a quantum algorithm that breaks a general cryptographic construction which is secure in the classical setting. ...|$|R
5000|$|The naive {{solution}} to the problem is as follows: [...] Initialize a counter, , to zero, [...] Initialize an efficient dictionary data structure, , such as hash table or search tree in which insertion and membership can be performed quickly. [...] For each element , a <b>membership</b> <b>query</b> is issued. [...] If [...] is not a member of [...] (...) Add [...] to [...] Increase [...] by one, [...] Otherwise (...) do nothing. Output [...]|$|E
40|$|Abstract — Bloom filter is a space-efficient {{randomized}} {{data structure}} for group <b>membership</b> <b>query.</b> It {{is widely used}} in networking applications which involve the packet header/content inspection. To provide fast <b>membership</b> <b>query</b> operation, this data structure resides in the main memory in most of its applications. Each <b>membership</b> <b>query</b> consists hashing {{for a set of}} memory addresses and memory accesses at these locations. In this paper, we propose a new design of Bloom filter in which every two memory addresses are squeezed into one I/O block of the main memory. With the burst-type data I/O capability in the contemporary DRAM design, the total number of memory I/O’s involved in the <b>membership</b> <b>query</b> is reduced by half. Therefore, the average query delay can be reduced significantly. The cost of using this new design is a negligible increment of false positive rate as shown by both analysis and simulation. I...|$|E
40|$|Consider {{the problem}} of <b>membership</b> <b>query</b> for a given {{partially}} ordered set. We devise a greedy algorithm which can produce near-optimal search strategies. Rigorous analysis has been given, which shows our algorithm can have fewer comparisons than the best known solution by at least a factor of 0. 27 under random graph model. Experimental results have also been given, which suggest {{the advantage of the}} algorithm under other models. KEY WORDS algorithms and computation theories, <b>membership</b> <b>query,</b> partial order, greedy algorithm...|$|E
40|$|We {{consider}} exact {{learning of}} concepts using {{two types of}} query: extended equivalence <b>queries,</b> and malicious <b>membership</b> <b>queries,</b> that is, <b>membership</b> <b>queries</b> that are permitted to make errors on some arbitrarily chosen set of examples of a bounded cardinality. We present a randomized algorithm to learn ¯-DNF formulas using these queries. The expected running time of the algorithm is polynomial {{in the number of}} variables and the maximum number of strings on which the membership oracle is allowed to make errors. 1 Introduction We continue the investigation begun by Angluin and Krikis [2] concerning the effects of errors in the answers to <b>membership</b> <b>queries</b> in the model of equivalence <b>queries</b> and malicious <b>membership</b> <b>queries.</b> We are interested in the question of whether polynomial-time learnability of a concept class using equivalence <b>queries</b> and (errorfree) <b>membership</b> <b>queries</b> implies polynomial-time learnability in the error model of equivalence <b>queries</b> and malicious <b>membership</b> <b>queries,</b> [...] ...|$|R
40|$|AbstractWe {{study the}} {{learning}} models defined in [D. Angluin, M. Krikis, R. H. Sloan, G. Turán, Malicious omissions and errors in answering to <b>membership</b> <b>queries,</b> Machine Learning 28 (2 – 3) (1997) 211 – 255]: Learning with equivalence and limited <b>membership</b> <b>queries</b> and learning with equivalence and malicious <b>membership</b> <b>queries.</b> We show {{that if a}} class of concepts that is closed under projection is learnable in polynomial time using equivalence and (standard) <b>membership</b> <b>queries</b> then it is learnable in polynomial time in the above models. This closes the open problems in [D. Angluin, M. Krikis, R. H. Sloan, G. Turán, Malicious omissions and errors in answering to <b>membership</b> <b>queries,</b> Machine Learning 28 (2 – 3) (1997) 211 – 255]. Our algorithm can also handle errors in the equivalence queries...|$|R
40|$|We {{study the}} learnability of Threshold {{functions}} with bounded weights using <b>membership</b> <b>queries</b> only. We {{show that the}} class Ct of Threshold functions with positive integer weights that are less or equal ∗ This research was done in a discussion seminar that was opened in the spring 1997 at the research center of Ibillin Elias College. to t is learnable with n O(t 5) <b>membership</b> <b>queries.</b> We also provide a lower bound of Ω(n t) {{for the number of}} <b>membership</b> <b>queries</b> required to learn this class. We also show that learning the class with weights from {− 1, 0, 1 } requires at least Ω(2 n) <b>membership</b> <b>queries.</b> 2...|$|R
40|$|In this paper, we {{continue}} our on-line learning approach [5] towards building an intelligent WWW search engine. We establish a connection between on-line learning theory and search engine construction based on our <b>Membership</b> <b>Query,</b> Target Concept, and Ranking Assumptions. With applications of Winnow [13] and virtual-variable [15] methods we show that when d discretized attributes {{with a total of}} S different values are used to index web documents, any collection of documents represented by a disjunction of k relevant attributes can be exactly identified with at most k log 2 S membership queries, or at most 1 : 885 k log 2 S k Γ k equivalence queries. We also show {{that it is possible to}} slightly improve the <b>membership</b> <b>query</b> bounds with randomization. In our COLT SEARCH project, we have been building an experimental search engine. So far, we have collected more than 3. 9 millions urls, indexed 843, 398 documents with 343 keywords, and implemented the <b>membership</b> <b>query</b> algorithms. Further [...] ...|$|E
40|$|This chapter {{discusses}} the false rates of Bloom filters in a distributed environment. A Bloom filter (BF) is a space-efficient data structure to support probabilistic <b>membership</b> <b>query.</b> In distributed systems, a Bloom filter {{is often used}} to summarize local services or objects and this Bloom filter is replicated to remote hosts. This allows remote hosts to perform fast <b>membership</b> <b>query</b> without contacting the original host. However, when the services or objects are changed, the remote Bloom replica may become stale. This chapter analyzes the impact of staleness on the false positive and false negative for membership queries on a Bloom filter replica. An efficient update control mechanism is then proposed based on the analytical results to minimize the updating overhead. This chapter validates the analytical models and the update control mechanism through simulation experiments...|$|E
40|$|We {{present a}} <b>membership</b> <b>query</b> (i. e. black box interpolation) {{algorithm}} for exactly identifying {{the class of}} read-once formulas over the basis of boolean threshold functions. We also present a catalogue of generic transformations {{that can be used}} to convert an algorithm in one learning model into an algorithm in a different model...|$|E
40|$|We {{study the}} learnability of {{monotone}} term decision lists {{in the exact}} model of equivalence and <b>membership</b> <b>queries.</b> We show that, for any constant k> 0, k-term monotone decision lists are exactly and properly learnable with n^O(k) <b>membership</b> <b>queries</b> in O(n^(k^ 3)) time. We also show n^Omega(k) <b>membership</b> <b>queries</b> are necessary for exact learning. In contrast, both k-term monotone decision lists (k> 1) and general monotone decision lists are not learnable with equivalence queries alone. Postprint (published version...|$|R
40|$|We {{study the}} {{learning}} models defined in [AKST 97]: Learning with equivalence and limited <b>membership</b> <b>queries</b> and learning with equivalence and malicious <b>membership</b> <b>queries.</b> We show {{that if a}} class of concepts that is closed under projection is learnable in polynomial time using equivalence and (standard) <b>membership</b> <b>queries</b> then it is learnable in polynomial time in the above models. This closes the open problems in [AKST 97]. Our algorithm can also handle errors in the equivalence queries. ...|$|R
40|$|Let F be {{a set of}} boolean functions. We {{present an}} {{algorithm}} for learning F_∨ := {∨_f∈ S f | S ⊆ F} from <b>membership</b> <b>queries.</b> Our algorithm asks at most |F| · OPT(F_∨) <b>membership</b> <b>queries</b> where OPT(F_∨) is the minimum worst case number of <b>membership</b> <b>queries</b> for learning F_∨. When F {{is a set of}} halfspaces over a constant dimension space or a set of variable inequalities, our algorithm runs in polynomial time. The problem we address has practical importance in the field of program synthesis, where the goal is to synthesize a program that meets some requirements. Program synthesis has become popular especially in settings aiming to help end users. In such settings, the requirements are not provided upfront and the synthesizer can only learn them by posing <b>membership</b> <b>queries</b> to the end user. Our work enables such synthesizers to learn the exact requirements while bounding the number of <b>membership</b> <b>queries...</b>|$|R
40|$|We {{consider}} {{a model of}} learning Boolean functions from quantum membership queries. This model is a natural generalization of the classical <b>membership</b> <b>query</b> learning model to the quantum domain and {{is closely related to}} the well studied topic of quantum property testing for black-box Boolean functions. The quantum <b>membership</b> <b>query</b> learning model was studied in [27], where it was shown that any class of Boolean functions which is information-theoretically learnable from polynomially many quantum membership queries is also information-theoretically learnable from polynomially many classical membership queries. In contrast to this information-theoretic equivalence between quantum and classical learning, this paper establishes a strong computational separation between quantum and classical learning. We prove that if any cryptographic one-way function exists, then there exists a concept class of Boolean functions which is polynomial-time learnable from quantum membership queries bu [...] ...|$|E
30|$|There {{are three}} main active {{learning}} scenarios, comprising <b>membership</b> <b>query</b> synthesis, stream-based selective sampling and pool-based sampling [59]. Popular active learning approaches {{can be found}} in [61]. They have been studied extensively in the field of machine learning and applied to many data processing problems such as image classification and biological DNA identification [61, 62].|$|E
40|$|We {{consider}} {{the problem of}} attribute-efficient learning in query and mistake-bound models. Attribute-efficient algorithms make a number of queries or mistakes that is polynomial {{in the number of}} relevant variables in the target function, but only sublinear in the number of irrelevant variables. We consider a variant of the <b>membership</b> <b>query</b> model in which the learning algorithm is given as input the number of relevant variables of the target function. We show that in this model, any projection and embedding closed class of functions (including parity) that can be learned in polynomial time can be learned attribute-efficiently in polynomial time. We show that this does not hold in the randomized <b>membership</b> <b>query</b> model. In the mistakebound model, we {{consider the}} problem of learning attribute-efficiently using hypotheses that are formulas of small depth. Our results extend the work of Blum et al. [4] and Bshouty et al. [7]...|$|E
40|$|AbstractWe {{investigate}} cryptographic {{limitations on}} the power of <b>membership</b> <b>queries</b> to help with concept learning. We extend the notion of prediction-preserving reductions to prediction with <b>membership</b> <b>queries.</b> We exhibit a number of reductions and show several prediction problems to be complete for different complexity classes. We show that assuming the intractability of (1) quadratic residues module a composite, (2) inverting RSA encryption, or (3) factoring Blum integers, there is no polynomial time prediction algorithm with <b>membership</b> <b>queries</b> for Boolean formulas, constant depth threshold circuits, 3 μ-Boolean formulas, finite unions or intersections of DFAs, 2 -way DFAs, NFAs, or CFGs. Also, we show that if there exist one-way functions that cannot be inverted by polynomial-sized circuits, then CNF or DNF formulas and convex polytopes intersected with the Boolean hypercube are either polynomial time predictable without <b>membership</b> <b>queries,</b> or they are not polynomial time predictable even with membership queries; so, in effect, <b>membership</b> <b>queries</b> will not help with predicting CNF or DNF formulas...|$|R
40|$|We {{consider}} the exact learnability of subclasses of Boolean formulas from <b>membership</b> <b>queries</b> alone. We show how to combine known learning algorithms that use <b>membership</b> and equivalence <b>queries</b> to obtain new learning results only with memberships. In particular we show the exact learnability of read-k monotone formulas, Sat-k O(log n) -CDNF, and O(sqrtlog n) -size CDNF from <b>membership</b> <b>queries</b> only. Postprint (Published version...|$|R
30|$|A simple {{bloom filter}} {{supports}} insertions and <b>membership</b> <b>queries.</b> During an insertion, the bits that are indexed by the hash functions {{are set to}} 1. During <b>membership</b> <b>queries,</b> the <b>membership</b> of an element in the bloom filter is confirmed {{if all of the}} bits indexed by all of the hash functions are 1.|$|R
40|$|We {{introduce}} {{a new model of}} <b>membership</b> <b>query</b> (MQ) learning, where the learning algorithm is restricted to query points that are close to random examples drawn from the underlying distribution. The learning model is intermediate between the PAC model (Valiant, 1984) and the PAC+MQ model (where the queries are allowed to be arbitrary points). <b>Membership</b> <b>query</b> algorithms are not popular among machine learning practitioners. Apart from the obvious difficulty of adaptively querying labelers, it has also been observed that querying unnatural points leads to increased noise from human labelers (Lang and Baum, 1992). This motivates our study of learning algorithms that make queries that are close to examples generated from the data distribution. We restrict our attention to functions defined on the n-dimensional Boolean hypercube and say that a <b>membership</b> <b>query</b> is local if its Hamming distance from some example in the (random) training data is at most O((n)). We show the following results in this model: (i) The class of sparse polynomials (with coefficients in R) over { 0, 1 }^n is polynomial time learnable under a large class of locally smooth distributions using O((n)) -local queries. This class also includes the class of O((n)) -depth decision trees. (ii) The class of polynomial-sized decision trees is polynomial time learnable under product distributions using O((n)) -local queries. (iii) The class of polynomial size DNF formulas is learnable under the uniform distribution using O((n)) -local queries in time n^O(((n))). (iv) In addition we prove a number of results relating the proposed model to the traditional PAC model and the PAC+MQ model...|$|E
40|$|The Kushilevitz-Mansour (KM) {{algorithm}} is an algorithm that finds all the "large" Fourier coe#cients of a Boolean function. It {{is the main}} tool for learning decision trees and DNF expressions in the PAC model {{with respect to the}} uniform distribution. The algorithm requires access to the <b>membership</b> <b>query</b> (MQ) oracle. The access is often unavailable in learning applications and thus the KM algorithm cannot be used...|$|E
40|$|This work {{presents}} a machine-checked tree automata library for Standard-ML, OCaml and Haskell. The algorithms are efficient by using appropriate data structures like RB-trees. The available algorithms for non-deterministic automata include <b>membership</b> <b>query,</b> reduction, intersection, union, and emptiness check with computation of a witness for non-emptiness. The executable algorithms {{are derived from}} less-concrete, non-executable algorithms using data-refinement techniques. Moreover, this work contains a formalization {{of the class of}} treeregula...|$|E
40|$|We {{study the}} {{properties}} of the agnostic learning framework of Haussler (1992) and Kearns, Schapire, and Sellie (1994). In particular, we address the question: is there any situation in which <b>membership</b> <b>queries</b> are useful in agnostic learning? Our results show that the answer is negative for distribution-independent agnostic learning and positive for agnostic learning with respect to a specific marginal distribution. Namely, we give a simple proof that any concept class learnable agnostically by a distribution-independent algorithm with access to <b>membership</b> <b>queries</b> is also learnable agnostically without <b>membership</b> <b>queries.</b> This resolves an open problem posed by Kearns et al. (1994). For agnostic learning with respect to the uniform distribution over { 0, 1 } n we show a concept class that is learnable with <b>membership</b> <b>queries</b> but computationally hard to learn from random examples alone (assuming that one-way functions exist) ...|$|R
40|$|We {{consider}} the exact learnability of subclasses of Boolean formulas from <b>membership</b> <b>queries</b> alone. We show how to combine known learning algorithms that use <b>membership</b> and equivalence <b>queries</b> to obtain new learning results only with memberships. In particular we show the exact learnability of read-k monotone CDNF formulas, Sat- k O(log n) -CDNF, and O(p log n) -size CDNF from <b>membership</b> <b>queries</b> only. 1 Introduction Learning DNF formulas {{has been one}} of the most attractive and tantalizing problems since the seminal paper of Valiant [Val 84]. Although many results in the literature give evidence that the problem is hard even if we are allow to use <b>membership</b> <b>queries</b> [AK 91, AHP 92], it has been recently proved by Jackson [Jac 94] that using <b>membership</b> <b>queries,</b> DNF are PAC learnable in polynomial time under the uniform distribution. Here we concentrate in a more restricted framework. While Jackson's algorithm is a PAC learning algorithm, we wish to have exact identification of the target [...] ...|$|R
2500|$|In active learning, {{a learner}} can make <b>membership</b> <b>queries</b> {{to the target}} concept c, asking for its value c(x) on inputs x chosen by the learner. The learner then has to {{reconstruct}} the exact target concept, with high probability. In the model of quantum exact learning, the learner can make <b>membership</b> <b>queries</b> in quantum superposition. If {{the complexity of the}} learner is measured by the number of <b>membership</b> <b>queries</b> it makes, then quantum exact learners can be polynomially more efficient than classical learners for some concept classes, but not more. If complexity is measured by the amount of time ...|$|R
40|$|We {{present a}} <b>membership</b> <b>query</b> (i. e. black box interpolation) {{algorithm}} for exactly identifying {{the class of}} read-once formulas over the basis of boolean threshold functions. We also present a catalogue of generic transformations {{that can be used}} to convert an algorithm in one learning model into an algorithm in a different model. 1 Introduction In one of the simplest models of learning, the learner must exactly identify an unknown target function by asking membership queries. A <b>membership</b> <b>query</b> asks for the output of the function on an element of its domain. The query is answered by an infallible, honest oracle. This learning model is equivalent to standard black box interpolation where one substitutes inputs into a black box oracle computing a function from some class, and uses the observed outputs to deduce what the hidden function must be. This research was supported in part by the NSERC of Canada. y Supported by ONR grant N 00014 - 85 -K- 0445 and NSF grant NSF-CCR- 89 - 02500. The r [...] ...|$|E
40|$|AbstractWe {{consider}} the problem ofattribute-efficientlearning in query and mistake-bound models. Attribute-efficient algorithms make {{a number of}} queries or mistakes that is polynomial {{in the number of}} relevant variables in the target function, but only sublinear in the number of irrelevant variables. We consider a variant of the <b>membership</b> <b>query</b> model in which the learning algorithm is given as input the number of relevant variables of the target function. We show that in this model, any projection and embedding closed class of functions (including parity) that can be learned in polynomial time can be learned attribute-efficiently in polynomial time. We show that this does not hold in the randomized <b>membership</b> <b>query</b> model. In the mistake-bound model, we {{consider the}} problem of learning attribute-efficiently using hypotheses that are formulas of small depth. Our results extend the work of A. Blum, L. Hellerstein, and N. Littlestone (J. Comput. System Sci. 50 (1995), 32 – 40) and N. Bshouty, R. Cleve, S. Kannan, and C. Tamon (in “Proceedings, 7 th Annu. ACM Workshop on Comput. Learning Theory,” pp. 130 – 139, ACM Press, New York, 1994) ...|$|E
40|$|External dynamic hashing {{has been}} used in {{traditional}} database systems as a fast method to answer membership queries. Given a dynamic set S of objects, a <b>membership</b> <b>query</b> asks whether an object with identity k is in the most current S. This paper addresses the more general problem of Temporal Hashing. In this setting changes to the dynamic set are timestamped and the <b>membership</b> <b>query</b> has a temporal predicate, as in: "find whether object with identity k was in the set S at time t". We present an efficient solution to the Temporal Hashing problem. Our solution, also termed partially persistent hashing, behaves as if a separate, ephemeral (i. e., non-temporal) dynamic hashing scheme is available on every state assumed by set S over time. However if the buckets of these hashing schemes were to be stored for each time of interest, the space would become prohibitively large (quadratic on the total number of changes in set S's evolution); instead, our method uses linear space. We compare [...] ...|$|E
40|$|It {{is known}} that the class of {{deterministic}} finite automata is polynomial time learnable by using <b>membership</b> and equivalence <b>queries.</b> We investigate the query complexity of learning deterministic finite automata, i. e., the number of <b>membership</b> and equivalence <b>queries</b> made {{during the process of}} learning. We extend a known lower bound on <b>membership</b> <b>queries</b> to the case of randomized learning algorithms, and prove lower bounds on the number of alternations between <b>membership</b> and equivalence <b>queries.</b> We also show that a trade-off exists, allowing us {{to reduce the number of}} equivalence queries at the price of increasing the number of <b>membership</b> <b>queries...</b>|$|R
40|$|We {{consider}} a weak version of pseudorandom function generators {{and show that}} their existence {{is equivalent to the}} non-learnability of Boolean circuits in Valiant's pac-learning model with <b>membership</b> <b>queries</b> on the uniform distribution. Furthermore, we show that this equivalence holds still for the case of non-adaptive <b>membership</b> <b>queries</b> and for any (non-trivial) p-samplable distribution...|$|R
40|$|AbstractThe {{plausibility}} {{of computing}} {{the answers to}} many <b>membership</b> <b>queries</b> to a hard set with few queries {{is the subject of}} the theory of terseness. In this paper, we develop companion theories-both complexity-theoretic and recursion-theoretic-of characteristic vector terseness. These theories ask whether the answers to many <b>membership</b> <b>queries</b> to a hard set can be checked with fewer queries...|$|R
