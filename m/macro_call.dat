13|147|Public
50|$|The {{format of}} the <b>Macro</b> <b>call</b> {{depended}} upon the system it was used upon.|$|E
50|$|In {{computer}} science, syntactic closures are an {{implementation strategy}} for a hygienic macro system. The actual arguments to a <b>macro</b> <b>call</b> are {{closed in the}} current environment, such that they cannot inadvertently reference bindings introduced by the macro itself.|$|E
5000|$|When CICS {{was first}} released, it only {{supported}} application transaction programs written in IBM 360 Assembler. COBOL and PL/I support were added years later. Because {{of the initial}} assembler orientation, requests for CICS services were made using assembler language macros. For example, the request to read a record from a file were made by a <b>macro</b> <b>call</b> to the [...] "File Control Program" [...] of CICS might look like this: ...|$|E
5000|$|Writing <b>macros</b> <b>calling</b> R {{to perform}} {{calculations}} without exposing R {{to the user}} ...|$|R
50|$|For MVT (either TYPE=MVT or TYPE=M65MP) with TSO, the TSOGEN macro {{plays the}} same role as GENERATE. Either macros {{analyzes}} the options specified on the previous <b>macro</b> <b>calls</b> and punches the Stage 2 job stream.|$|R
50|$|Another popular pastime was player vs player sparring. This {{later became}} {{corrupted}} by cheating, {{as well as}} version compatibility issues, which later versions tried to address with little success. The most popular of these cheating programs was a <b>macro</b> <b>called</b> VitaminF.|$|R
40|$|Creating dynamic, {{data driven}} {{programs}} {{is a very}} powerful tool. Often we can use the metadata or the project data itself to help write our programs. This paper will introduce some of the concepts related to writing SAS ® programs which will generate pieces of SAS code in a data driven manner. Parts of the SAS language used in this discussion include the following: 1. <b>macro</b> <b>call</b> routines (call symput and call execute) 2. PROC SQ...|$|E
40|$|When writing {{computer}} programs, certain patterns arise {{over and}} over again. For example, programs must often loop through the elements of arrays, increment or decrement the values of variables, and perform multi-way conditionals based on numeric or character values. Programming language designers typically acknowledge this fact by including special-purpose syntactic constructs that handle the most common patterns. C, for instance, provides multiple looping constructs, multiple conditional constructs, and multiple constructs for incrementing or otherwise updating {{the value of a}} variable [9]. Some patterns are less common but can occur frequently in a certain class of programs or perhaps just within a single program. These patterns might not even be anticipated by a language’s designers, who in any case would typically choose not to incorporate syntactic constructs to handle such patterns in the language core. Yet, recognizing that such patterns do arise and that specialpurpose syntactic constructs can make programs both simpler and easier to read, language designers sometimes include a mechanism for syntactic abstraction, such as C’s preprocessor macros or Common Lisp [11] macros. When such facilities are not present or are inadequate for a specific purpose, an external tool, like the m 4 [8] macro expander, might be brought to bear. Syntactic abstraction facilities differ in several significant ways. C’s preprocessor macros are essentially token-based, allowing the replacement of a <b>macro</b> <b>call</b> with a sequence of tokens with text from the <b>macro</b> <b>call</b> substituted for the macro’s formal parameters, if any. Lisp macros are expression-based, allowing the replacement of a single expression with another expression, computed in Lisp itself and based on the subforms of the <b>macro</b> <b>call,</b> if any. In both cases, identifiers appearing within a macro-call subform are scoped where they appear in the output, rather than where they appear in the input, possibly leading to unintended capture of a variable reference by a variable binding. For example, consider the simple transformation of Scheme’s or form [7] into let and if below. (Readers unfamiliar with Scheme might want to read ∗ This document appeared as a chapter of Beautiful Code: Leading Programmers Explain How They Think, edited by Andy Oram and Greg Wilson and published by O’Reilly an...|$|E
40|$|This is a macro which {{facilitates}} remote {{execution of}} WinBUGS from within SAS. The macro pre-processes data for WinBUGS, writes the WinBUGS batch-script, executes this script and reads in output {{statistics from the}} WinBUGS log-file back into SAS native format. The user specifies the input and output file names and directory path {{as well as the}} statistics to be monitored in WinBUGS. The code works best for a model that has already been set up and checked for convergence diagnostics within WinBUGS. An obvious extension of the use of this macro is for running simulations where the input and output files all have the same name but all that differs between simulation iterations is the input dataset. The functionality and syntax of the <b>macro</b> <b>call</b> are described in this paper and illustrated using a simple linear regression model. ...|$|E
5000|$|This text {{creates a}} new <b>macro</b> <b>called</b> [...] that can be called simply by typing [...] into the command prompt, or from other macros or programs. SINCURVE uses two local variables, x and angle, {{as well as a}} global variable, OFFSET.|$|R
40|$|This {{presentation}} {{illustrates a}} method for creating a multiple comparison test for proportions in a 2 x C cross tabulation or contingency table using the FREQ procedure and a SAS <b>macro</b> <b>called</b> compprop. This test is analogous to a Tukey-type multiple comparison test as used with one-way analysis of variance...|$|R
40|$|The {{preprocessor}} {{incorporated into}} the C language {{is often used to}} substitute in-line code for function <b>calls</b> using preprocessor <b>macros.</b> However, the semantics of <b>macro</b> <b>calls</b> are different to those for function calls {{and there are a number}} of common pitfalls. This paper examines the most common errors and presents a number of algorithms whereby the compiler can detect these errors at compile-time. The algorithms vary in complexity from a simple analysis of lexical tokens in the preprocessor to examination of the parse tree within the parser. Most of the algorithms have been implemented in a prototype C <b>macro</b> checker <b>called</b> Check. 1...|$|R
40|$|Measures {{of effect}} size are {{recommended}} to communicate {{information on the}} strength of relationships. Such information supplements the reject/fail-to-reject decision obtained in statistical hypothesis testing. Because sample effect sizes are subject to sampling error, as is any sample statistic, computing confidence intervals for these statistics is a useful strategy to represent the magnitude of uncertainty about the corresponding population effect sizes. This paper provides a SAS macro that uses bootstrapping to compute confidence intervals for an effect size associated with mediation analysis models. Using SAS/IML, the macro produces point and interval estimates of an R-squared effect size that represents the proportion of variance accounted for by the mediated effect. This paper provides the macro programming language, as well {{as an example of the}} <b>macro</b> <b>call</b> and output. Finally, the results from a simulation study investigating the accuracy and precision of the estimates are presented...|$|E
40|$|We {{identify}} {{two types}} of domain-specific features in macro expansion systems: with the expansion-time values of domain-specific attributes the user can control conditional expansion; domain-specific actions are performed by the system, and we divide them into expansion-integrated and conversion-integrated ones. The domain of our implemented prototype system is machine-level code generation, but we also formulate a model intended to capture domain-specific macro expansion in various domains. An important property of the model is that the expansion result is independent of the <b>macro</b> <b>call</b> expansion order. 1 Introduction T E X by Knuth [18] is surely {{one of the most}} successful domain-specific languages. The T E X typesetting system is capable of transforming a manuscript prepared in T E X format into pages of finest typographic quality. For example, T E X autonomously positions the line and page breaks by applying sophisticated built-in algorithms. The T E X vocabulary includes 300 primit [...] ...|$|E
40|$|During {{the last}} year we built several {{solutions}} for opening our ET++ applications for internal and external scripting. The most annoying part to be coded manually was the code stubs that translate a string based request into the invocation of a member function. For this reason we built an ET++ specific solution that provides dispatchable member functions in an inexpensive, non-intrusive way. Our solution consists of {{an extension of the}} macro generated ET++ run time meta information. To make a member function dispatchable, a developer has to write one <b>macro</b> <b>call.</b> This generates a member function meta object providing information about arguments and a function that serves to invoke the respective member function. These two generated parts work {{in the context of the}} dynamic invocation framework, which embodies an architecture that can be customized for varying interfacing needs. 1. Introduction Our team has been developing interactive standalone applications based on the ET++ applicati [...] ...|$|E
5000|$|One little-known usage {{pattern of}} the C {{preprocessor}} is known as X-Macros. An X-Macro is a header file. Commonly these use the extension [...] ".def" [...] instead of the traditional [...] ".h". This file contains a list of similar <b>macro</b> <b>calls,</b> which {{can be referred to}} as [...] "component macros". The include file is then referenced repeatedly.|$|R
50|$|Inside a Page, Layout or Snippet, Radiant {{offers a}} special <b>macro</b> language, <b>called</b> Radius, that uses XML-like tags.|$|R
40|$|Developing {{a process}} for {{standardized}} reports in terms of Tables, Figures and Listings (TFLs) generations for a clinical study report by developing SAS ® macro-based either reporting tool or template SAS programs is an ongoing focus {{of the health care}} and life science industry. We have developed SAS macros and template SAS programs (<b>macro</b> <b>calls)</b> based on our Biometrics Standard TFLs shells for safety analysis like Adverse Events (AE), LABs...|$|R
40|$|The SURVEYLOGISTIC {{procedure}} in SAS ® 9 {{provides a way}} to perform logistic regression with survey data. However, some options frequently used with the LOGISTIC procedure, such as stepwise and score model selection, {{were not included in}} PROC SURVEYLOGISTIC. One such option is SELECTION=SCORE BEST=n, which is used to identify the best subsets of covariates, allowing the user to select the number of models displayed for each model size with the highest score chi-square statistics. Two methods are described here for recreating this procedure option in PROC SURVEYLOGISTIC. The first method employs macros that run PROC SURVEYLOGISTIC once for each combination of covariates; for example, there are 10, 660 possible combinations of 3 covariates from a candidate set of 41 variables, resulting in 10, 660 runs of PROC SURVEYLOGISTIC. The <b>macro</b> <b>call</b> is nested within multiple DO loops. ODS is used to output the statistic of interest. The second method uses data step programming to generate a data set that repeats the observations for each combination of covariates. PROC SURVEYLOGISTIC is executed only once using a by command to test each combination of covariates separately. Although some important options are missing from PROC SURVEYLOGISTIC, careful programming can recreate the desired results...|$|E
40|$|Abstract—The {{widely used}} C {{preprocessor}} (CPP) {{is generally considered}} a source of difficulty for understanding and maintaining C/C++ programs. The main reason for this difficulty is CPP’s purely lexical semantics, i. e., its treatment of both input and output as token streams. This can easily lead to errors {{that are difficult to}} diagnose, and {{it has been estimated that}} up to 20 % of all macros are erroneous. To reduce such errors, more restrictive, replacement languages for CPP have been proposed to limit expanded macros to be valid C syntactic units. However, there is no practical tool that can effectively validate CPP macros in legacy applications. In this paper, we introduce a novel, general characterization of inconsistent macro usage as a strong indicator of macro errors. Our key insight is that all applications of the same macro should behave similarly. In particular, we map each <b>macro</b> <b>call</b> c in a source file f to c’s normalized syntactic constructs within the abstract syntax tree (AST) for f’s preprocessed source, and use syntactic similarity as the basis for comparing macro calls of the same macro definition. Utilizing this characterization, we have developed an efficient algorithm to statically validate macro usage in C/C++ programs. We have implemented the algorithm; evaluation results show that our tool is effective in detecting common macro-related errors and reports few false positives, making it a practical tool for validating macro usage. Keywords-preprossing, macro errors, inconsistencies I...|$|E
40|$|The {{widely used}} C {{preprocessor}} (CPP) {{is generally considered}} a source of difficulty for understanding and maintaining C/C++ programs. The main reason for this difficulty is CPP’s purely lexical semantics, i. e., its treatment of both input and output as token streams. This can easily lead to errors {{that are difficult to}} diagnose, and {{it has been estimated that}} up to 20 % of all macros are erroneous. To reduce such errors, more restrictive, replacement languages for CPP have been proposed to limit expanded macros to be valid C syntactic units. However, there is no practical tool that can effectively validate CPP macros in legacy applications. In this paper, we introduce a novel, general characterization of inconsistent macro usage as a strong indicator of macro errors. Our key insight is that all applications of the same macro should behave similarly. In particular, we map each <b>macro</b> <b>call</b> c in a source file f to c’s normalized syntactic constructs within the abstract syntax tree (AST) for f’s preprocessed source, and use syntactic similarity as the basis for comparing macro calls of the same macro definition. Utilizing this characterization, we have developed an efficient algorithm to statically validate macro usage in C/C++ programs. We have implemented the algorithm; evaluation results show that our tool is effective in detecting common macro-related errors and reports few false positives, making it a practical tool for validating macro usage...|$|E
50|$|Keyboard macros {{and mouse}} macros allow short {{sequences}} of keystrokes and mouse actions to transform into other, usually more time-consuming, sequences of keystrokes and mouse actions. In this way, frequently used or repetitive sequences of keystrokes and mouse movements can be automated. Separate programs for creating these <b>macros</b> are <b>called</b> <b>macro</b> recorders.|$|R
5000|$|In {{the early}} 1970s, Ray Tomlinson updated an {{existing}} utility called SNDMSG {{so that it}} could copy messages (as files) over the network. Lawrence Roberts, the project manager for the ARPANET development, took the idea of READMAIL, which dumped all [...] "recent" [...] messages onto the user's terminal, and wrote a programme for TENEX in TECO <b>macros</b> <b>called</b> RD, which permitted access to individual messages. Barry Wessler then updated RD and called it NRD.|$|R
50|$|ML/I accepts input in {{completely}} free form, treating data as {{a stream of}} bytes rather than a series of lines or records. It does not require any particular flagging of <b>macro</b> <b>calls,</b> which makes it particularly useful for processing arbitrary text. Replacements of text can be simple (e.g. PIG is {{to be replaced by}} DOG) or complex (e.g. replace the item between the third and fourth commas after the last full stop, by the contents of some counter).|$|R
40|$|We {{present a}} macro, %CYARROW, {{that makes it}} easy to draw arrows using SAS ® /GRAPH’s {{superior}} Annotate facility. %CYARROW is specifically designed to be used in conjunction with %ANNOMAC macros, a set of SAS macros that provides a shortcut when creating an Annotate dataset. %CYARROW is an alternative to the undocumented (and “broken”) %ARROW macro. In addition to honoring the five standard options for the DRAW Annotate function (COLOR, HSYS, LINE, SIZE, and WHEN), %CYARROW offers sophisticated arrow shape options that control the length and the angle of the arrow tip and its aspect ratio. ANNOTATE DATA SET AND ANNOTATE MACROS The Annotate facility is a part of SAS/GRAPH. It is most commonly used to enhance graphics output by adding text and other graphic elements to them. It also creates advanced, custom graphics output from scratch in conjunction with PROC GANNO. In order to use the Annotate facility, one creates a dataset (an Annotate dataset) with specific variables and values. The Annotate dataset then is fed into a graphics procedure. The procedure, in turn, processes each observation of the Annotate dataset as an instruction to the facility. A good introduction to the Annotate facility is the, excellent, short volume by Carpenter(1999 a). Since the bulk of work in using Annotate facility lies in creating the Annotate dataset, SAS kindly provides a set of macros, %ANNOMAC, that significantly reduces the amount of work. As Rorie and Duncan(2003) demonstrate (also see Carpenter(1999 b)), a single %LINE() Annotate <b>macro</b> <b>call</b> can replace: (1) creating two observations; (2) assigning the function variable values (MOVE, for the first observation; and DRAW for the second); (3) assigning x and y coordinates for the starting and ending points of a line; and (4) assigning color, line type, and thickness. The %ANNOMAC includes %BAR to create a fillable rectangle, %LINE to draw a line, %SLICE to draw a pie slice, and %LABEL to write text at the specified location, to name a few. Our installation of SAS Release 9. 1. 2 includes the source code file for the %ANNOMAC macros (in the “SAS 9. 1 /core/sasmacro ” directory). To our delight, the source code includes an undocumented macro called %ARROW...|$|E
40|$|Under the {{direction}} of DR. PETER CALINGAERT.) ML/I is a general purpose macro language which provides for the user specification of the argument delimiters of a macro, where each macro may have several possible patterns of delimiters. Other language features include nested and recursive <b>macro</b> <b>calls</b> and definitions, macro-time assignment and conditional statements, an extensive macrotime environment, the specification of a possibly variable number of delimiters for each macro, and a method of defining multi-atom macro names and delimiters...|$|R
50|$|PMView reads {{and writes}} and {{converts}} between more than 40 image file formats, shows {{the images on}} the screen, single and in slide shows, rotates or mirrors them, changes sizes and color depth, crops parts out of the images, and provides global editing of the image, all this individually on the image displayed on the screen, by prerecorded <b>macros</b> <b>called</b> batch scripts {{on a range of}} images, or directly in the File Open Container. And it can, of course, also print the images.|$|R
40|$|Patient-reported outcome (PRO) studies {{often require}} {{correlation}} analyses using multiple variable types. Producing tables that contain Pearson, polychoric, and polyserial correlations for ordinal and categorical variables is challenging in Base SAS®. This paper introduces a SAS <b>macro</b> <b>called</b> %PROCORR that routes variables {{to the appropriate}} correlation computation. The macro also identifies the appropriate output statistics {{for each type of}} correlation and creates a report-ready table. The analyses and output discussed were created with Base SAS Version 9. 2 software and apply to analysts with macro experience...|$|R
40|$|How to keep interim {{datasets}} or formats {{generated in}} macro programs from unexpectedly overwriting work data sets or work formats that are {{outside of the}} <b>macro</b> <b>calls</b> is a topic sometimes being overlooked. It can create confusions and sometimes lead to misleading results. This is an important macro design issue when developing public use or utility macro applications. This paper introduces an efficient technique that can be utilized to avoid conflicts between local macro data sets or formats and non-macro data sets or formats...|$|R
40|$|The SAS system V. 8 {{implements}} the computation of {{unweighted and weighted}} kappa statistics as {{an option}} in the FREQ procedure. A major limitation of this implementation is that the kappa statistic can only be evaluated {{when the number of}} raters is limited to 2. Extensions to the case of multiple raters due to Fleiss (1971) have not been implemented in the SAS system. A SAS <b>macro</b> <b>called</b> MAGREE. SAS, that can handle the case of multiple raters is available at the SAS Institute’s web site (check it a...|$|R
40|$|The FAST {{compiler}} is a backend for compilers of lazy functional languages. There are {{two versions}} of the compiler: one that takes a rather simple lazy functional language as input and a second that accepts a language similar to Miranda. On output the compiler produces a set of <b>macro</b> <b>calls</b> that are normally turned into a C program by one of the code generators that have been developed for FAST. Such a C program must be compiled by a C compiler and linked with the appropriate runtime library to...|$|R
5000|$|The {{software}} was originally titled [...] "Supercomp-20". It was renamed 20/20, and {{was available for}} AT&T Unix, DEC VAX, the IBM RS/6000, and IBM-compatible PCs. It was the first spreadsheet with integrated database and graphics support available for Unix. In 1989, a version was released with real-time data updating. 20/20 also had <b>macros</b> (<b>called</b> [...] "command files" [...] in the documentation), and a goal-seeking facility, which allowed the user to choose a desired value for a result cell, and vary an input cell automatically until the desired result was achieved.|$|R
50|$|In 2007, Sigma {{released}} a HSM {{version of the}} 18-50mm 2.8 EX DC <b>Macro,</b> <b>called</b> the 18-50mm 2.8 EX DC Macro HSM. This lens is available for Nikon F-mount only. The lens has the same optical formula as the non-HSM lens, but is 0.5 mm shorter, and 85 g (18.9 oz.) heavier. The lens has a closer minimum focus distance of 20 cm, {{but because of the}} larger Nikon DX sensor size, the magnification rating is still 1:3. Also because of larger sensor size, the stated angle of view is 76.5º - 31.7º, though theses angles are still obtainable on the non-HSM version.|$|R
5000|$|Throughout the rabbit's lifetime, the {{photographer}} continued to document his journeys through natural and not-so-natural environments {{as well as}} take hundreds of pictures of the rabbit balancing objects. Oolong has been noticed by the media, including the New York Times, {{and has become a}} widespread Internet meme. One of Oolong's photographs was used as an image <b>macro</b> <b>called</b> [...] "Bunny Wafflehead" [...] which featured Oolong balancing a dorayaki on his head. Another photograph shows Oolong with a pancake on his head with the caption [...] "I have no idea what you're talking about... so here's a bunny with a pancake on its head." ...|$|R
50|$|The {{format of}} a <b>macro</b> (subroutine) <b>call</b> may be {{illustrated}} by the following example. Macro A in this example adds the two parameters passed to it from the main program, and returns the sum {{on the top of}} the stack.|$|R
40|$|This paper {{presents}} {{results of}} an investigation <b>macro</b> <b>called</b> “Marketing in public libraries in Colombia. ” The aim of research within which frames this paper proposed as: “Identifying {{the current status of}} the strategic planning of marketing information services in public libraries in Colombia”, whose ultimate purpose was given to allow, from This diagnostic tool to build these units of information to positively impact the communities and meet the new requirements of a society in constant transformation. This article takes time for public libraries of the municipalities in Colombia. The quantitative research, collect a general and descriptive way, how the public libraries provide planned or intuitive elements, tools and variables inherent to the marketing of services...|$|R
