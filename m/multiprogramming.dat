455|363|Public
25|$|Among other things, a <b>multiprogramming</b> {{operating}} system kernel must {{be responsible for}} managing all system memory which is currently in use by programs. This ensures that a program does not interfere with memory already in use by another program. Since programs time share, each program must have independent access to memory.|$|E
25|$|In 1964, the IBM System/360 {{was a line}} of six {{computers}} each {{having the}} same instruction set architecture. The Model 30 was the smallest and least expensive. Customers could upgrade and retain the same application software. Each System/360 model featured <b>multiprogramming.</b> With operating system support, multiple programs could be in memory at once. When one was waiting for input/output, another could compute. Each model also could emulate other computers. Customers could upgrade to the System/360 and retain their IBM 7094 or IBM 1401 application software.|$|E
25|$|Gelenbe {{has contributed}} {{pioneering}} research concerning {{the performance of}} <b>multiprogramming</b> computer systems, virtual memory management, data base reliability optimisation, distributed systems and network protocols. He formed, led, and trained the team that designed the commercial QNAP Computer and Network Performance Modeling Tool. He introduced the Flexsim Object Oriented approach for the simulation in manufacturing systems. He carried {{out some of the}} first work on adaptive control of computer systems, and published seminal papers on the performance optimisation of computer network protocols and on the use of diffusion approximations for network performance. He developed new product form queueing networks with negative customers and triggers known as G-networks. He also introduced a new spiked stochastic neural network model known as the random neural network, developed its mathematical solution and learning algorithms, and applied it to both engineering and biological problems. His inventions include the design of the first random access fibre-optics local area network, a patented admission control technique for ATM networks, a neural network based anomaly detector for brain magnetic resonance scans, and the cognitive packet network routing protocol to offer quality of service to users.|$|E
5000|$|The Pay {{television}} {{companies must}} to {{order in the}} referred form the broadcast signals of stations that have not obtained authorization to <b>multiprogram,</b> As well as <b>multiprogrammed</b> broadcast signals with a larger audience, regardless of the secondary number with which they count.|$|R
50|$|In Japan <b>Multiprogram</b> {{has been}} {{successful}} with the launch of ISDB-T there.|$|R
40|$|Assessing the {{performance}} of <b>multiprogram</b> workloads running on multithreaded hardware is difficult because it involves a balance between single-program performance and overall system performance. This article argues for developing <b>multiprogram</b> performance metrics in a top-down fashion starting from system-level objectives. The authors propose two performance metrics: average normalized turnaround time. A user-oriented metric, and system throughput, a system-oriented metric...|$|R
2500|$|In 1969, the RC 4000 <b>Multiprogramming</b> System {{introduced}} the system design philosophy {{of a small}} nucleus [...] "upon which operating systems for different purposes could be built in an orderly manner", what would be called the microkernel approach.|$|E
5000|$|Real-Time <b>Multiprogramming</b> Operating System (RTMOS) was {{a process}} control {{operating}} system {{developed in the}} 1960s by General Electric that supported both real-time computing and <b>multiprogramming.</b> [...] <b>Multiprogramming</b> operating systems are now considered obsolete, having been replaced by multitasking.|$|E
5000|$|RC 4000 Software: <b>Multiprogramming</b> System (Complete), Regnecentralen, Copenhagen, Denmark (1969) ...|$|E
5000|$|... #Caption: The <b>Multiprogram</b> Research Facility (foreground right) at the Oak Ridge National Laboratory ...|$|R
40|$|Weighted speedup is {{nowadays}} {{the most}} commonly used <b>multiprogram</b> workload performance metric. Weighted speedup is a weighted-IPC metric, i. e., the <b>multiprogram</b> IPC of each program is first weighted with its isolated IPC. Recently, Michaud questions the validity of weighted-IPC metrics by arguing that they are inconsistent and that weighted speedup favors unfairness [4]. Instead, he advocates using the arithmetic or harmonic mean of the raw IPC values of the programs in the <b>multiprogram</b> workload. We show that weighted-IPC metrics are not inconsistent, and that weighted speedup is fair in giving equal importance to each program. We argue that, in contrast to raw-IPC metrics, weighted-IPC metrics have a system-level meaning, and that raw-IPC metrics are affected by the inherent behavior of the programs. We also show that the choice of a metric may adversely affect the conclusions from an experiment. We suggest to use two weighted-IPC metrics-system throughput (STP) and average normalized turnaround time (ANTT) -for evaluating <b>multiprogram</b> workload performance, and to avoid raw-IPC metrics...|$|R
50|$|<b>Multiprogram</b> control allowed up to 8 {{programs}} to be sharing the machine, {{each with its}} own set of 32 special registers.|$|R
5000|$|Applications {{could create}} sub-tasks, which allowed <b>multiprogramming</b> within the one job.|$|E
5000|$|Testing a <b>multiprogramming</b> system, Software—Practice and Experience 3, 2 (April-June), 145-150 ...|$|E
5000|$|Structured <b>multiprogramming,</b> Communications of the ACM 15, 7 (July 1972), 574-578 ...|$|E
40|$|Abstract. In {{this paper}} we {{reformulate}} the thread scheduling problem on <b>multiprogrammed</b> SMPs. Scheduling algorithms usually attempt to maximize performance of memory intensive applications by optimally exploiting the cache hierarchy. We present experimental results indicating that- {{contrary to the}} common belief- the extent of performance loss of memory-intensive, <b>multiprogrammed</b> workloads is disproportionate to the deterioration of cache performance caused by interference between threads. In previous work [1] we found that memory bandwidth saturation is often the actual bottleneck that determines the performance of <b>multiprogrammed</b> workloads. Therefore, we present and evaluate two realistic scheduling policies which treat memory bandwidth as a firstclass resource. Their design methodology is general enough and {{can be applied to}} introduce bus bandwidth-awareness to conventional scheduling policies. Experimental results substantiate the advantages of our approach. ...|$|R
40|$|Almost all new consumer-grade {{processors}} {{are capable}} of executing multiple programs simultaneously. The analysis of <b>multiprogrammed</b> workloads for multicore and SMT processors is challenging and time-consuming {{because there are many}} possible combinations of benchmarks to execute and each combination may exhibit several different interesting behaviors. Missing particular combinations of program behaviors could hide performance problems with designs. It is thus of utmost importance to have a representative <b>multiprogrammed</b> workload when evaluating multithreaded processor designs. This paper presents a methodology that uses phase analysis, principal components analysis (PCA) and cluster analysis (CA) applied to microarchitectureindependent program characteristics in order to find important program interactions in <b>multiprogrammed</b> workloads. The end result is a small set of co-phases with associated weights that are representative for a <b>multiprogrammed</b> workload across multithreaded processor architectures. Applying our methodology to the SPEC CPU 2000 benchmark suite yields 50 distinct combinations for two-context multithreaded processor simulation that researchers and architects can use for simulation. Each combination is simulated for 50 million instructions, giving a total of 2. 5 billion instructions to be simulated for the SPEC CPU 2000 benchmark suite. The performance prediction error with these representative combinations is under 2. 5 % of the real workload for absolute throughput prediction and {{can be used to make}} relative throughput comparisons across processor architectures. ...|$|R
50|$|This {{innovative}} {{feature of}} the ISDB-T standard allows a consumer to watch three different programs at once, or in a sports match, {{it is possible to}} watch the game {{from the point of view}} of different cameras. The Brazilian Ministry of Communication prevented commercial broadcast companies from using this feature; only public DTV channels are allowed to use it. This decision was taken because <b>Multiprogram</b> could allow unauthorized use of the TV broadcast band. To start with, the Ministry of Communication informed it was being created required legal support to allow the use of such feature, but later decided that the feature will be blocked until new studies are performed. Rede Globo (one of the main Brazilian TV broadcasters) and ABRA (Association of Broadcasting Companies) are pushing the Ministry to keep the <b>Multiprogram</b> feature blocked because it will impact the current TV business model, reducing revenues from advertising. However, once users see the benefit of the <b>Multiprogram</b> feature, some organizations are asking the Ministry of Communication to allow its use by all broadcasters. Some broadcasters, using a different business model from that used by Rede Globo, are asking the Federal Superior Court to decide if the <b>Multiprogram</b> blockage is legal.|$|R
5000|$|PCP {{for early}} users {{and for those}} without the {{resources}} for <b>multiprogramming.</b>|$|E
50|$|The {{term was}} popularized with the {{introduction}} of OS/360 (announced 1964), which featured <b>Multiprogramming</b> with a Fixed number of Tasks (MFT) and <b>Multiprogramming</b> with a Variable number of Tasks (MVT). In this case tasks were identified with light-weight processes, a job consisted of a number of tasks, and, later, tasks could have sub-tasks (in modern terminology, child processes).|$|E
5000|$|THE <b>multiprogramming</b> {{system for}} the Electrologica X8 (software based virtual memory without {{hardware}} support) ...|$|E
25|$|The Pakistan Institute of Nuclear Science and Technology (also {{known as}} PINSTECH), is a <b>multiprogram</b> science and {{technology}} national research institute managed for the Ministry of Science by the Pakistan Atomic Energy Commission (PAEC).|$|R
40|$|Most multiprocessors are <b>multiprogrammed</b> {{to achieve}} {{acceptable}} response time. Unfortunately, inopportune preemption may significantly degrade {{the performance of}} synchronized parallel applications. To address this problem, researchers have developed two principal strategies for concurrent, atomic update of shared data structures: (1) preemption-safe locking and (2) non-blocking (lock-free) algorithms. Preemption-safe locking requires kernel support. Non-blocking algorithms generally require a universal atomic primitive, and are widely regarded as inefficient. We present {{a comparison of the}} two alternative strategies, focusing on four simple but important concurrent data structures— stacks, FIFO queues, priority queues and counters—in microbenchmarks and real applications on a 12 -processor SGI Challenge multiprocessor. Our results indicate that data-structurespecific non-blocking algorithms, which exist for stacks, FIFO queues and counters, can work extremely well: not only do they outperform preemption-safe lock-based algorithms on <b>multiprogrammed</b> machines, they also outperform ordinary locks on dedicated machines. At the same time, since general-purpose nonblocking techniques do not yet appear to be practical, preemptionsafe locks remain the preferred alternative for complex data structures: they outperform conventional locks by significant margins on <b>multiprogrammed</b> systems. ...|$|R
40|$|This paper studies compile-time and runtime {{techniques}} for enhancing performance portability of MPI code running on <b>multiprogrammed</b> shared memory machines. The proposed techniques allow MPI nodes {{to be executed}} safely and efficiently as threads. Compile-time transformation eliminates global and static variables in C code using node-specific data. The runtime support includes an efficient and provablycorrect communication protocol that uses lock-free data structure and takes advantage of address space sharing among threads. The experiments on SGI Origin 2000 show that our MPI prototype called TMPI using the proposed techniques is competitive with SGI's native MPI implementation in a dedicated environment, {{and that it has}} significant performance advantages in a <b>multiprogrammed</b> environment...|$|R
5000|$|RC 4000 Software: <b>Multiprogramming</b> System, Part I General Description, Regnecentralen, Copenhagen, Denmark (1969) 13-52 ...|$|E
50|$|A <b>multiprogramming</b> or {{multitasking}} OS is {{a system}} executing many processes concurrently. <b>Multiprogramming</b> requires that the processor be allocated to each process {{for a period of}} time and de-allocated at an appropriate moment. If the processor is de-allocated during the execution of a process, it must be done in such a way that it can be restarted later as easily as possible.|$|E
5000|$|The {{nucleus of}} a <b>multiprogramming</b> system, Communications of the ACM 13, 4 (April 1970), 238-242 ...|$|E
40|$|This paper {{describes}} the derivation {{of a program}} for the propagation of information over a network, with acknowledgement (feedback) when the computation is complete. The derivation is {{carried out in the}} theory of Owicki and Gries. The paper therefore illustrates the use of this theory for the derivation, as opposed merely to the verification, of distributed <b>multiprograms.</b> Notable is that the derivation, while calculational in style, is carried out with a minimum of formal machinery, e. g., there is no temporal logic. The derivation also serves as a concrete illustration of program reuse. A theory that is based on a shared variable model of communication is shown to manage the design of distributed <b>multiprograms</b> quite well...|$|R
40|$|We {{provide a}} work-stealing {{scheduling}} method for nested fork/join parallelism that is mathematically proven to self- adapt <b>multiprogrammed</b> applications resource allocation {{to the current}} workloads’ individual needs while it takes avail- able resources into account. The scheduling method both scales up the allocated resources when needed and down, when possible. The theoretical model has been implemented in the Bar- relﬁsh distributed multikernel operating system and demon- strated to function on a simulated x 86 64 multicore plat- form. The work presented here is the ﬁrst step towards a com- plete framework for the system-wide scheduling and load balancing of <b>multiprogrammed</b> many-core systems, assum- ing a variety of workload types and guaranteeing at least av- erage execution for each running program. QC 20130109 </p...|$|R
40|$|We {{consider}} {{the problem of}} mapping tasks to processor nodes at run-time in <b>multiprogrammed</b> multicomputer systems (i. e. message passing MIMD-systems). Besides load balancing, {{the goal is to}} place intensively communicating tasks close together to minimize communication delays. Since the placement has to be done at run-time by migrating tasks, migration cost are also considered. Our decentralized approach is inspired by a physical analogy: Tasks are considered as particles acted upon by forces. Each aspect of the allocation goal is modeled by a dedicated force. Migration activities cease, when a stable situation with balanced forces is reached. Simulations for <b>multiprogrammed</b> hypercube and 2 D-grid topologies confirmed the usefulness and suggests superiority of this more general approach to other decentralized algorithms for the environment considered...|$|R
5000|$|PCP (Primary Control Program), {{which was}} a very early version of OS/360 that didn't support <b>multiprogramming.</b>|$|E
5000|$|In <b>multiprogramming</b> systems, {{the running}} task keeps running until it {{performs}} {{an operation that}} requires waiting for an external event (e.g. reading from a disk or tape, receiving a message from a network, reading from a terminal or other human input device) or until the computer's scheduler forcibly swaps the running task out of the CPU. <b>Multiprogramming</b> systems are designed to maximize CPU usage.|$|E
50|$|<b>Multi{{programming}}</b> systems (Production programmers) - Used {{for programming}} devices in high volumes by Electronics manufacturers and programming centers.|$|E
40|$|Statistical {{simulation}} {{is driven}} by a stream of randomly generated instructions, based on statistics collected during a single detailed simulation. This method can give accurate performance estimates within minutes, allowing a large design space to be simulated quickly. Prior work has applied this technique to superscalar processors. We evaluate the extension of statistical simulation to Symmetric Multiprocessing (SMP) systems. Key program parameters are identified, and program statistics are collected during detailed simulations for both <b>multiprogrammed</b> workloads (SpecInt) and parallel scientific workload (Splash- 2). The accuracy of statistical simulation is evaluated {{at different levels of}} model detail, and it is shown that for <b>multiprogrammed</b> workloads a 10 % average error can be achieved, and for parallel benchmark programs 15 % average error can be achieved...|$|R
40|$|We {{investigate}} proactive {{dynamic load}} balancing on multicore systems, in which threads are continually migrated {{to reduce the}} impact of processor/thread mismatches to enhance {{the flexibility of the}} SPMD-style programming model, and enable SPMD applications to run efficiently in <b>multiprogrammed</b> environments. We present Juggle, a practical decentralized, user-space implementation of a proactive load balancer that emphasizes portability and usability. Juggle shows performance improvements of up to 80 % over static balancing for UPC, OpenMP, and pthreads benchmarks. We analyze the impact of Juggle on parallel applications and derive lower bounds and approximations for thread completion times. We show that results from Juggle closely match theoretical predictions across a variety of architectures, including NUMA and hyper-threaded systems. We also show that Juggle is effective in <b>multiprogrammed</b> environments with unpredictable interference from unrelated external applications...|$|R
40|$|Abstract. Clusters and grids have {{increasingly}} become standard platforms for high performance computing as they provide extremely high execution rates with great cost effectiveness. Such systems {{are designed to}} support concurrent execution of multiple jobs. It calls for <b>multiprogrammed</b> scheduling of the different jobs for effective system utilization and for keeping average response times low. Although {{a significant amount of}} work has been done in scheduling parallel jobs on multiprocessor systems, the problem of scheduling parallel tasks of an individual job on a <b>multiprogrammed</b> parallel system has not been given enough attention so far. In this paper, we present a dynamic scheduling technique for scheduling iterations of a DOALL loop (of a single application) to achieve load balance between a given set of processors. Experimental results show the effectiveness of our approach. ...|$|R
