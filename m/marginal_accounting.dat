2|63|Public
40|$|While most {{analyses}} of economic impacts {{of population growth}} have been equivocal, this article describes a new perspective from which the effects are strongly negative. The economies and diseconomies of population size are largely circumstantial and empirically inconsistent, but those of growth rate are intrinsic and consistent. These impacts are not apparent on income and per capita GDP, but on costs. The article estimates these costs using the logic of calculus rather than <b>marginal</b> <b>accounting.</b> Specifically, the cost of maintaining per capita capacity of durable assets, including infrastructure, equipment and skilled personnel, is increased by population growth by a factor proportional to the working lifespan of the asset class...|$|E
40|$|The {{comparative}} {{production potential}} among annual cropping systems grown as bioenergy feedstock in the Eastern Cornbelt of the US Midwest is generally unknown. Two field experiments {{were conducted to}} evaluate the compositional attributes, agronomic and economic efficiencies, and environmental impacts of sorghum (Sorghum bicolor M.) and maize (Zea mays L.) {{as they relate to}} bioethanol production and nitrogen (N). A 3 site-year fertilizer rate study (0, 67, 135 and 202 kg N ha- 1) comparing five distinct sorghum hybrids/lines and a maize hybrid, was conducted to evaluate yields, carbohydrate pools, and associated theoretical ethanol (EtOH) yields. Post-harvest, dried stover was analyzed for carbohydrate partitioning and theoretical EtOH yield was calculated using conversion and efficiency factors for sugars as proposed by the National Renewable Energy Lab’s state of technology report. Simple <b>marginal</b> <b>accounting</b> was conducted to determine the economic EtOH responses to incremental investments for N fertilizer by the hybrids/lines. A related study of system N balance, specifically focused on N removal in harvested tissue and N loss to subsurface drainage water, was conducted at Purdue University’s Water Quality Field Station. The study compared continuous residue removal systems of sorghum and maize to grain-only maize-based systems, two of which included a soybean rotation. In the N rate study, sorghums had total aboveground biomass and EtOH yields that were either similar to, or higher than maize. The photoperiod sensitive sorghum had the highest biomass and EtOH yields, (30 Mg ha 1 dry wt. and over 12, 000 L EtOH ha- 1). The lowest yielding sorghum hybrid/line was the commercial grain sorghum hybrid, which produced biomass and total EtOH yields (20 Mg ha- 1 dry wt. and 7, 000 L EtOH ha 1) similar to maize. The concentrations and contents of total non-structural carbohydrates (TNCs) and total fibers (TFs) varied markedly among hybrids/lines. The concentration of TFs were negatively correlated to TNCs (r=- 0. 8). A higher content of EtOH convertible carbohydrates (TFs plus TNCs) was associated with a higher pool of non-convertible extractives. Biomass yield was the main driver for EtOH yields, as the theoretical equations that were used suggests only minor differences in conversion efficiencies and rates among the different carbohydrate pools. The lowest N rate of 67 kg N ha- 1 had the highest incremental increase in biomass yield for all sorghums. Consistent with this, the economic analyses also exhibited that this N rate (67 kg N ha- 1) had the largest marginal gain. When no N fertilizer was applied, the highest yielding sorghum hybrids/lines still had EtOH returns from stover as high as 6000 ha- 1, compared to the grain hybrids which had 3 ̆c 2000 ha - 1 at 0 N. The N balance study revealed that the bioenergy residue removed systems exported the highest quantities of N in the plant tissue and maintained average biomass yields (13 - 14 Mg ha- 1) over the 5 years, with no evidence of decreased productivity due to residue removal. Also no negative impact on subsurface drainage water quality was identified with these bioenergy systems. The grain-only rotated systems had higher nitrate (NO 3 -N) concentrations in the subsurface drainage water than the residue removed systems. Results suggest that the biological N fixation occurring in the soybean contributed to a general trend of higher cumulative NO 3 -N loads in subsurface drainage water from the rotated systems compared to the continuous systems. From environmental, agronomic and economic viewpoints, our collective results demonstrate that all hybrids/lines assessed in this study could be more produced as biomass feedstock for cellulosic EtOH production in the Eastern Cornbelt of the US, Midwest. They could be more efficiently produced with lower N rates, and sorghum tended to perform better than maize at lower N, energy and economic inputs than maize. ...|$|E
40|$|The present paper {{analyses}} {{the dependence}} structure between WTI and Brent crude oil spot log-returns using modern copula techniques. In {{a first step}} we apply several single equation models to the <b>marginals</b> to <b>account</b> for autocorrelation and volatility clustering. Second, to select both copulas and tail copulas characterising the joint dynamics between the time series we implement and evaluate newly introduced bootstrap-based goodness-of-fit tests. Based on each approach, a comprehensive backtesting is performed by simulating and comparing the risk measures Value-at-Risk and Expected Shortfall with historical values...|$|R
50|$|Grenzplankostenrechnung is a German costing methodology, {{developed}} in the late 1940s and 1960s, {{designed to provide a}} consistent and accurate application of how managerial costs are calculated and assigned to a product or service. The term Grenzplankostenrechnung, often referred to as GPK, has best been translated as either <b>marginal</b> planned cost <b>accounting</b> or flexible analytic cost planning and accounting.|$|R
40|$|Abstract—Likelihood based-learning of {{graphical}} models faces {{challenges of}} computational-complexity and robustness to model error. This paper studies methods that fit parameters directly to maximize {{a measure of}} the accuracy of predicted <b>marginals,</b> taking into <b>account</b> both model and inference approximations at training time. Experiments on imaging problems suggest marginalization-based learning performs better than likelihood-based approximations on difficult problems where the model being fit is approximate in nature...|$|R
30|$|In {{addition}} to the seasonal variation, streamflows at different locations also exhibit significant spatial correlation, even though most flow stations belong to different rivers or tributaries. Spatial correlation of streamflows arose {{from the fact that}} the amounts of rainfalls falling within the tributaries of individual flow stations are correlated. Therefore, a complete characterization of streamflows at different locations must take into <b>account</b> <b>marginal</b> distributions of streamflows at individual stations and their temporal and spatial correlations.|$|R
40|$|Likelihood based-learning of {{graphical}} models faces {{challenges of}} computational-complexity and robustness to model mis-specification. This paper studies methods that fit parameters directly to maximize {{a measure of}} the accuracy of predicted <b>marginals,</b> taking into <b>account</b> both model and inference approximations at training time. Experiments on imaging problems suggest marginalization-based learning performs better than likelihood-based approximations on difficult problems where the model being fit is approximate in nature. Comment: To Appear, IEEE Transactions on Pattern Analysis and Machine Intelligenc...|$|R
40|$|We {{model the}} times of the gold {{medalist}} swimmers in the Olympic Games. As the data represent an extreme value we use methods from extreme value theory. Features of the recorded variables lead to the inclusion of mixed parametric and nonparametric modeling for the marginal nonstationarity, constraints on <b>marginal</b> parameters to <b>account</b> for stochastic ordering between times from different events, and bivariate modeling to capture dependence across winning event times. Our analysis provides greater insight into the progression of winning times...|$|R
40|$|The {{limitation}} on obtaining precise outcomes of measurements performed on two non-commuting observables of a particle as {{set by the}} uncertainty principle in its entropic form, can be reduced {{in the presence of}} quantum memory. We derive a new entropic uncertainty relation based on fine- graining, which leads to an ultimate limit on the precision achievable in measurements performed on two incompatible observables in the presence of quantum memory. We show that our derived uncertainty relation tightens the lower bound set by entropic uncertainty for members of the class of two-qubit states with maximally mixed <b>marginals,</b> while <b>accounting</b> for the recent experimental results using maximally entangled pure states and mixed Bell-diagonal states. An implication of our uncertainty relation on the security of quantum key generation protocols is pointed out. Comment: Latex, 5 pages, one encapsulated figure, accepted for publication in Physical Review Letter...|$|R
5000|$|All {{petroleum}} {{production and}} exploration is taken {{under the auspices}} of joint ventures between foreign multi-national corporations and the Nigerian federal government. This joint venture manifests itself as the Nigerian National Petroleum Corporation, a nationalised state corporation. All companies operating in Nigeria obey government operational rules and naming conventions (companies operating in Nigeria must legally be sub-entities of the main corporation, often incorporating [...] "Nigeria" [...] into its name). Joint ventures account for approximately 95% of all crude oil output, while local independent companies operating in <b>marginal</b> fields <b>account</b> for the remaining 5%. Additionally, the Nigerian constitution states that all minerals, oil, and gas legally belong to the federal government. Six companies are operating in Nigeria and are listed with their countries of origin (most of the following is extracted from a 1999 Human Rights Watch report): ...|$|R
40|$|The {{goal of the}} {{research}} is to generate profitable logistics and commercial strategies for customers. The methodology is a top-down procedure based in financial statements with higher detail (by channel, by product or by client), process mapping and activity-based-cost. The methodology has three phases and 12 steps to segment profitable, <b>marginal</b> and non-profitable <b>accounts</b> to define strategies to decrease costs or to increase profitability in emerging markets. A set of tools is proposed to prioritize customers' attention and to develop logistics/commercial strategies according to their potential growth...|$|R
40|$|Genetic {{variation}} in the pistachio late blight fungus, Alternaria alternata, was investigated by {{restriction fragment length polymorphism}} (RFLP) in the rDNA region. Southern hybridization of EcoRI, HindIII, and XbaI digested fungal DNA with a RNA probe derived from Alt 1, an rDNA clone isolated from a genomic library of the Japanese pear pathotype of A. alternata, revealed 34 different rDNA haplotypes among 56 isolates collected from four central valley locations in California. Analysis of molecular variation revealed a significant amount of genetic diversity within populations (85 – 8 %), with only <b>marginal</b> variation <b>accounting</b> for differentiation among populations (14 – 2 %, U ST fl 0 – 142). All isolates examined were highly pathogenic. The identity of the four geographic populations sampled was not evident in both cluster and principal component analyses, probably indicating either the selectively neutral nature of rDNA variation or prevalence of widespread gene flow among populations combined with uniform host-selection...|$|R
40|$|We use the QCD sum rule {{approach}} {{to calculate the}} splitting between vector and pseudoscalar mesons containing one light and one heavy quark, and the kinetic energy of the heavy quark. Our result for the splitting induced by the chromomagnetic interaction agrees to the experimental data on charm and beauty mesons. For the matrix element of the kinetic energy operator, we obtain the value K=-(0. 60 ± 0. 10) GeV^ 2. Comment: 33 ps., PS figures included, requires REVTEX. 3 and psfig, TUM-T 31 - 42 / 93 /R (additional contribution to kinetic energy taken into <b>account,</b> <b>marginal</b> changes in the results...|$|R
40|$|Fractional Brownian Motion (FBM) {{has emerged}} as a {{powerful}} traffic model, able to fit the long-term correlations of actual network traffic flows with a limited number of parameters. An open research issue is the fast generation of FBM sample paths to be used in network simulations, which might require a large number of samples in case rare events are involved. In this paper we analyse the statistical behaviour of the well-known Random Midpoint Displacement algorithm, an approximate generation algorithm whose complexity is linear with the simulation length, taking into <b>account</b> <b>marginal</b> distribution as well as correlation structure...|$|R
40|$|We study a single-item, multi-period, {{stochastic}} perishable inventory problem {{under both}} backlogging and lost-sales circumstances, {{with and without}} an order capacity constraint in each period. We first model the problem as a dynamic program and then develop two heuristics namely, Dual-Balancing (DB) and Look-Ahead (LA) policies, to approximate the optimal inventory level {{at the beginning of}} each period. To characterize the holding and backlog cost functions under the proposed polices, we introduce a truncated marginal holding cost for the <b>marginal</b> cost <b>accounting</b> scheme. Our numerical examples demonstrate that both DB and LA policies have a possible worst-case performance guarantee of two in perishable inventory systems under different assumptions, and the LA policy significantly outperforms the DB policy in most situations. We also analyze the target inventory level in each period (the inventory level {{at the beginning of each}} period) under different policies. We observe that the target inventory level under the LA policy is not larger than the optimal one in each period in systems without an order capacity constraint...|$|R
40|$|The {{relevance}} of imperfect competition for models of economic fluctuations has received increased attention from researchers in both macroeconomics and industrial organization. The authors outline a new methodology for estimating industry markups of price over marginal cost {{and the influence}} of market structure on cyclical movements in total factor productivity. Measures of industry concentration, import competition, and unionization are important for explaining markups in some industry groups. Much of the estimated markup of price over <b>marginal</b> cost is <b>accounted</b> for by noncapital fixed costs. Finally, the authors show that their estimated margins fluctuate substantially over the cycle. In particular, markups are countercyclical, especially in concentrated durable-goods industries. Copyright 1988 by MIT Press. ...|$|R
40|$|This article {{presents}} a new simple econometric {{framework for the}} estimation of individual firms' markup over their <b>marginal</b> cost, taking <b>account</b> of firm heterogeneity, demand-driven cyclical price changes, and the limited availability of firm-level information. The framework is applied to study markup of Japanese firms in manufacturing and wholesale/retail trade for 1994 [...] 2002. The results indicate that, on average, the Japanese markets become more competitive in the 1990 s than before even in non-manufacturing industries. We also find sizable heterogeneity and non-negligible pro-cyclicality in the markup of the Japanese firms. Copyright 2009 The Author 2009. Published by Oxford University Press on behalf of Associazione ICC. All rights reserved., Oxford University Press. ...|$|R
25|$|Olives are not {{native to}} the Americas. Spanish colonists brought the olive to the New World, where its {{cultivation}} prospered in present-day Peru and Chile. The first seedlings from Spain were planted in Lima by Antonio de Rivera in 1560. Olive tree cultivation quickly spread along the valleys of South America's dry Pacific coast where the climate {{was similar to the}} Mediterranean. Spanish missionaries established the tree in the 18th century in California. It was first cultivated at Mission San Diego de Alcalá in 1769 or later around 1795. Orchards were started at other missions, but in 1838, an inspection found only two olive orchards in California. Cultivation for oil gradually became a highly successful commercial venture from the 1860s onward. In Japan, the first successful planting of olive trees happened in 1908 on Shodo Island, which became the cradle of olive cultivation. An estimated 865 million olive trees are in the world today (as of 2005), {{and the vast majority of}} these are found in Mediterranean countries, with traditionally <b>marginal</b> areas <b>accounting</b> for no more than 25% of olive-planted area and 10% of oil production.|$|R
50|$|The {{cropping}} {{pattern in the}} district reveals that food crops like jowar, maize, bajra and wheat among cereals, red gram, Bengal gram and green gram among pulses are major crops cultivated in the district. The major oilseed crops are sunflower, groundnut and safflower. Horticulture crops like grapes, pomegranate, ber, guave sapota, lime are also grown. A recent trend shows {{that there is a}} low shift towards fruit crops like Pomegranate and grapes of the total area of 8,610 square kilometres. Covered during 2002-03 cereals occupy about 55.2% by oilseeds 24.5% pulse 15.6% and other commercial crops like cotton and sugarcane about 4.8%. There is a slight shift towards commercial crops like cotton and sugarcane over last 2 years. The land holding pattern in the district indicates that small and <b>marginal</b> farmers <b>account</b> for 4% of total land holdings and 0.6% of the total land, semi-medium for 27.5% with 10.1% of total land while 68% of the holdings are above 20,000 m², accounting for 89.3% of land. Many small scale industries are working in the district however no large scale industry {{can be found in the}} district.|$|R
40|$|Americans {{now work}} 50 {{percent more than}} do the Germans, French, and Italians. This {{was not the case}} in the early 1970 s when the Western Europeans worked more than Americans. In this paper, I examine the role of taxes in {{accounting}} for the differences in labor supply across time and across countries, in particular, the effective marginal tax rate on labor income. The population of countries considered is that of the G- 7 countries, which are major advanced industrial countries. The surprising finding is that this <b>marginal</b> tax rate <b>accounts</b> for the predominance of the differences at points in time and the large change in relative labor supply over time {{with the exception of the}} Italian labor supply in the early 1970 s...|$|R
40|$|This study {{examines}} Japan’s inflation between 1973 and 2005 using empirical esti-mates {{of the new}} Keynesian Phillips curve. Although a few other studies look at Japan’s inflation in this context, none presents results for the baseline model with robustness tests. The results yield three important conclusions. First, the baseline new Keynesian Phillips curve predicts that a 1 percent change in real <b>marginal</b> cost <b>accounts</b> {{for as much as}} a 0. 424 percent change in inflation. This new curve also tends to match the path of Japan’s actual inflation more closely than the Phillips curve in recent years. In addition, it predicts that Japanese firms change prices every two to four quarters. This rate of price adjustment implies they engage in flexible price setting. Second, in a nested specification, forward-looking price-setting behavior dominates backward-looking behavior. Third, structural breaks in the parameters occurred during the land and asset price bubble of the late 1980 s and near the time of the Asian financial crisis in 1997. Subsample estimates of the new Keynesian Phillips curve show that Japan’s price rigidity tended to increase after the break points. This tendency is consistent with the notion that Japanese firms found it difficult to further reduce real marginal cost as Japan’s economic slowdown became more entrenched...|$|R
40|$|Localization {{performance}} in wireless networks has been traditionally benchmarked using the Cramer-Rao lower bound (CRLB), given a fixed geometry of anchor nodes and a target. However, by endowing {{the target and}} anchor locations with distributions, this paper recasts this traditional, scalar benchmark as a random variable. The goal of this work is to derive an analytical expression for the distribution of this now random CRLB, {{in the context of}} Time-of-Arrival-based positioning. To derive this distribution, this work first analyzes how the CRLB is affected by the order statistics of the angles between consecutive participating anchors (i. e., internodal angles). This analysis reveals an intimate connection between the second largest internodal angle and the CRLB, which leads to an accurate approximation of the CRLB. Using this approximation, a closed-form expression for the distribution of the CRLB, conditioned on the number of participating anchors, is obtained. Next, this conditioning is eliminated to derive an analytical expression for the marginal CRLB distribution. Since this <b>marginal</b> distribution <b>accounts</b> for all target and anchor positions, across all numbers of participating anchors, it therefore statistically characterizes localization error throughout an entire wireless network. This paper concludes with a comprehensive analysis of this new network-wide-CRLB paradigm. Comment: Submitted to IEEE Transactions on Wireless Communication...|$|R
40|$|Diversification {{of small}} farms is often {{suggested}} {{as a means}} for rapid rural development in India. Small and <b>marginal</b> holdings <b>account</b> for about three-fourth of the total operational holdings in the country, operating over one-fourth of the total area. Majority of small and marginal farmers cultivate mainly low value, subsistence crops. In the absence of adequate farm and non-farm employment opportunities, they are also forced to live below poverty line. The situation is likely to worsen because of the growing pressure of population on land and the limited scope of increasing additional production through subsistence farming. Hence arises the need for commercialisation and diversification of small farms within and outside agriculture and their proper integration with local and global markets. This is intended not only to liberate the small and marginal farmers from the poverty trap, but also to meet the country's growing demands for fruits, vegetables, milk and milk products, meat, fish, eggs etc. which generally show rising trends with increasing levels of per-capita income in the economy. However, the moot question today is how do we achieve the goal of diversification of small farms by overcoming various technological, infrastructural, institutional and policy constraints. The present paper intends to analyse the problems and prospects of diversification of smal...|$|R
40|$|We {{consider}} two classical stochastic {{inventory control}} models, the periodic-review stochastic inventory control {{problem and the}} stochastic lot-sizing problem. The goal is to coordinate a sequence of orders of a single commodity, aiming to supply stochastic demands over a discrete, finite horizon with minimum expected overall ordering, holding and backlogging costs. In this paper, we address the important problem of finding computationally efficient and provably good inventory control policies for these models {{in the presence of}} correlated and non-stationary (time-dependent) stochastic demands. This problem arises in many domains and has many practical applications in supply chain management. Our approach is based on a new <b>marginal</b> cost <b>accounting</b> scheme for stochastic inventory control models combined with novel cost-balancing techniques. Specifically, in each period, we balance the expected cost of over ordering (i. e, costs incurred by excess inventory) against the expected cost of under ordering (i. e., costs incurred by not satisfying demand on time). This leads to what we believe to be the first computationally efficient policies with constant worst-case performance guarantees for a general class of important stochastic inventory models. That is, there exists a constant C such that, for any instance of the problem, the expected cost of the policy is at most C times the expected cost of a...|$|R
30|$|We use Porter’s (1980) generic {{strategies}} to categorize firms {{according to their}} competitive advantages. The generic strategies are the basis on which a firm may seek to achieve a lasting position in its environment. Porter (1980, 1996) develops a conceptual typology of three generic competitive strategies along the dimensions of strategic scope and strategic strength. In this paper, {{we focus on the}} supply-side dimension and look at the strengths and core competitive advantages of a firm. The strategy of differentiation aims at creating unique products or services which attract brand loyalty and price inelasticity. This strategy must be backed up with costly activities such as product design, marketing expenditures and especially, extensive research. Meanwhile, the strategy of cost leadership aims to build market share via aggressive pricing to maximize economies of scale, which requires tight cost controls. It involves the “construction of efficient-scale facilities, rigorous pursuit of cost reductions from experience, tight cost and overhead control, avoidance of <b>marginal</b> customer <b>accounts,</b> and cost minimization in areas like R&D, service, sales force, advertising, and so on” (Porter 1980). Due to resource restrictions, firms cannot deploy both strategies simultaneously. In his analysis of capital goods producers, Hambrick and Mason (1984) finds only clusters for one single strategic position. His argument is consistent with Porter’s (1980) view that firms avoid a “stuck in the middle” position.|$|R
40|$|In {{this talk}} I discuss the neo-liberal mandate to engage in, and {{maintain}} ‘moderate’ and ‘healthy’ levels {{of physical activity}} with reference to two studies – one focusing on people with type 2 diabetes (Peel et al., 2010); the other examining discourse about dementia onset and prevention (Peel, 2014). Physical activity is particularly important for people with type 2 diabetes, as evidence suggests that any reduction in sedentary time is good for metabolic health. Similarly, increased levels of physical activity are deemed important to ameliorate risk of developing dementia. I examine how, for people with diabetes, the discussion and salience of physical activity is <b>marginal</b> in <b>accounts</b> of self-management. Aside from walking, physical activities tended to attenuate over time. Dog walking significantly featured in these data and I explore three central themes: 1) incidental walking; 2) incremental physical activity gains; and 3) augmenting physical activity maintenance. Recent media reporting about dementia (e. g., ‘Why walking nine miles a week could save you from dementia’ (The Guardian)) foregrounds lifestyle and health behaviour modifications to ‘stave off’ the condition – and walking {{is part of that}} landscape. Taken together, I suggest that the ascendance of ‘healthist’ individualised mandates to ‘control’ health and chronic illness through sustaining appropriate levels of physical activity should be understood as fundamentally relational. Moreover, this relationality can include dogs as well as family, friends and wider support networks...|$|R
2500|$|In most systems the {{algorithm}} used is a [...] "DC" [...] model {{rather than an}} [...] "AC" [...] model, so constraints and redispatch resulting from thermal limits are identified/predicted, but constraints and redispatch resulting from reactive power deficiencies are not. Some systems take <b>marginal</b> losses into <b>account.</b> The prices in the real-time market {{are determined by the}} LMP algorithm described above, balancing supply from available units. This process is carried out for each 5-minute, half-hour or hour (depending on the market) interval at each node on the transmission grid. The hypothetical redispatch calculation that determines the LMP must respect security constraints and the redispatch calculation must leave sufficient margin to maintain system stability {{in the event of an}} unplanned outage anywhere on the system. This results in a spot market with [...] "bid-based, security-constrained, economic dispatch with nodal prices".|$|R
40|$|We use {{structural}} estimation {{techniques to}} analyse labour supply effects {{of changes in}} economic incentives for individuals who have just finished vocational rehabilitation in Norway. The complicated and sometimes non-convex budget sets for this group of <b>marginal</b> workers are <b>accounted</b> for. We also focus on the limitation in the choice sets this group faces. Parametric bootstrap and simulation techniques are applied to construct confidence intervals for the predicted impacts {{of changes in the}} economic environment. The results show that there is a small to moderate effect of changes in economic incentives on the chance of vocational rehabilitation bringing individuals back to employment. We also find that individual health status and local labour market conditions are the most important factors affecting the transition from rehabilitation to work. Copyright 2008 The Author. Journal compilation 2008 CEIS, Fondazione Giacomo Brodolini and Blackwell Publishing Ltd. ...|$|R
40|$|Nested {{simulation}} algorithms {{are used}} in several scientific investigations such as climate, statistical me-chanics, and financial and actuarial risk management. Recently, these methods have also {{been used in the}} context of Bayesian computations and are referred to as Nested Sampling. In several of these problems, the inner level computation typically involves simulating events with very small probability, leading to rare event importance sampling methods. The quality of the resulting estimates depend on the allocation of computational resources between inner and outer level simulations. We introduce a novel adaptive rare event simulation algorithm that allocates the computational resources by taking in to <b>account</b> <b>marginal</b> changes in the rare event probabilities. We establish the consistency and efficiency of our algorithm and theoretically and numerically compare our results with the non-adaptive methods. We illustrate the proposed methods with several examples. ...|$|R
40|$|Americans {{now work}} 50 {{percent more than}} do the Germans, French, and Italians. This {{was not the case}} in the early 1970 s when the Western Europeans worked more than Americans. In this paper, I examine the role of taxes in {{accounting}} for the differences in labor supply across time and across countries, in particular, the effect of the marginal tax rate on labor income. The population of countries considered is that of the G- 7 countries, which are the major advanced industrial countries. The surprising finding is that this <b>marginal</b> tax rate <b>accounts</b> for the predominance of the differences at points in time and the large change in relative labor supply over time {{with the exception of the}} Italian labor supply in the early 1970 s. This finding has important implications for policy, in particular for making social security programs solvent. ...|$|R
40|$|In this work, {{we propose}} a Hidden Markov Model for Internet traffic sources at packet level, jointly {{analyzing}} Inter Packet Time and Packet Size. We give an analytical basis and the mathematical details regarding the model, and we test {{the flexibility of}} the proposed modeling approach with real traffic traces related to common Internet services with strong differences in terms of both applications/users and protocol behavior: SMTP, HTTP, a network game, and an instant messaging platform. The presented experimental analysis shows that, even maintaining a simple structure, the model is able to achieve good results in terms of estimation of statistical parameters and synthetic series generation, taking into <b>account</b> <b>marginal</b> distributions, mutual, and temporal dependencies. Moreover we show how, by exploiting such temporal dependencies, the model is able to perform short-term prediction by observing traffic from real sources...|$|R
40|$|We {{study the}} link between tax {{progressivity}} and top income shares. Using variation from large-scale Western tax reforms in the 1980 s and 1990 s and the novel synthetic control method, we find large and lasting boosting impacts on top income shares from the progressivity reductions. Effects are largest in the very top groups while earners in {{the bottom half of}} the top decile were almost unaffected by the reforms. Cuts in top <b>marginal</b> tax rates <b>account</b> for most of this outcome whereas reduced overall progressivity contributed less. Searching for mechanisms, real income responses as measured by growth in aggregate GDP per capita, registered patents and tax revenues were unaffected by the reforms. By contrast, tax avoidance behavior related to the management of capital incomes in the very income top appears to lie behind the observed effects...|$|R
5000|$|In most systems the {{algorithm}} used is a [...] "DC" [...] model {{rather than an}} [...] "AC" [...] model, so constraints and redispatch resulting from thermal limits are identified/predicted, but constraints and redispatch resulting from reactive power deficiencies are not. Some systems take <b>marginal</b> losses into <b>account.</b> The prices in the real-time market {{are determined by the}} LMP algorithm described above, balancing supply from available units. This process is carried out for each 5-minute, half-hour or hour (depending on the market) interval at each node on the transmission grid. The hypothetical redispatch calculation that determines the LMP must respect security constraints and the redispatch calculation must leave sufficient margin to maintain system stability {{in the event of an}} unplanned outage anywhere on the system. This results in a spot market with [...] "bid-based, security-constrained, economic dispatch with nodal prices".|$|R
40|$|We {{examine whether}} two {{commonly}} used indicators of bank fragility, the subordinated debt spread and KMV’s distance to default, yield signals {{in line with}} supervisors’ interests. We argue that supervisors would prefer indicators that are strictly increasing in earnings, and decreasing in leverage and earnings volatility. Using standard option pricing, we show that the two indicators do indeed satisfy these properties if the firm is still solvent. We also summarise the results from a test of these properties {{in a sample of}} EU banks during the 1990 s. The results suggest that the distance to default signals bank fragility earlier than the subordinated debt spread. Also, the spread is affected by the implicit safety net of the bank. Finally, the results suggest that the indicators may add <b>marginal</b> value to <b>accounting</b> information through a reduction in Type II (“false positive”) errors. Banking; Bank fragility; Market indicators; Market discipline; Bankruptcy predictors...|$|R
5000|$|Grenzplankostenrechnung (GPK) is a German costing methodology, {{developed}} in the late 1940s and 1950s, {{designed to provide a}} consistent and accurate application of how managerial costs are calculated and assigned to a product or service. The term Grenzplankostenrechnung, often referred to as GPK, has been translated as either <b>Marginal</b> Planned Cost <b>Accounting</b> or Flexible Analytic Cost Planning and Accounting. The GPK methodology has become the standard for cost accounting in Germany [...] as a [...] "result of the modern, strong controlling culture in German corporations". German firms that use GPK methodology include Deutsche Telekom, Daimler AG, Porsche AG, Deutsche Bank, and Deutsche Post (German Post Office). These companies have integrated their costing information systems based on ERP (Enterprise Resource Planning) software (e.g., SAP) and they tend to reside in industries with highly complex processes. However, GPK is not exclusive to highly complex organizations; GPK is also applied to less complex businesses.|$|R
40|$|Most {{works on}} Augustus or the Augustan age have {{focussed}} {{attention on the}} formation of the principate, its development, and the ultimate honour of being named Pater Patriae in 2 BC. After 2 BC, Augustus as a person becomes <b>marginal</b> in most <b>accounts</b> which focus on the deaths of Gaius and Lucius and the increasing centrality of Tiberius – or the succession. Yet Augustus would live as Princeps for longer than the reigns of most of the Julio Claudian emperors and their successors, including those of Caligula, Claudius, Nero, Vespasian, Titus and Domitian. When closely examined, this final decade of Augustus’ life can be seen as more autocratic than the previous decades of the principate. Our paper evaluates how the ageing of Augustus affected the running of the principate, or the restored res publica, and considers more seriously the role of Augustus in the final decade of his long life. [Taken from introduction]Peer-reviewedPost-prin...|$|R
