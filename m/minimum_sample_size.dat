373|10000|Public
25|$|The {{intersection}} of the column and row is the <b>minimum</b> <b>sample</b> <b>size</b> required.|$|E
25|$|There are, however, some {{potential}} drawbacks to using stratified sampling. First, identifying strata and implementing {{such an approach}} can increase the cost and complexity of sample selection, as well as leading to increased complexity of population estimates. Second, when examining multiple criteria, stratifying variables {{may be related to}} some, but not to others, further complicating the design, and potentially reducing the utility of the strata. Finally, in some cases (such as designs with a large number of strata, or those with a specified <b>minimum</b> <b>sample</b> <b>size</b> per group), stratified sampling can potentially require a larger sample than would other methods (although in most cases, the required sample size would be no larger than would be required for simple random sampling).|$|E
2500|$|The most {{frequently}} occurring Y-DNA haplogroup among modern Filipinos is Haplogroup O3-M122, which is found with high frequency in populations from East Asia, Southeast Asia, and Polynesia. In particular, {{the type of}} O3-M122 that is found frequently in Filipinos, O-P201(xM7, M134), is also found frequently in other Austronesian populations, especially the Batak Toba from Sumatra and the Polynesians. Haplogroup O1a-M119 (labeled as [...] "Haplogroup H" [...] in this study) is also commonly found among Filipinos and is shared with other Austronesian-speaking populations, especially those in Taiwan, western Indonesia, and Madagascar. After the 16th century, the colonial period saw the influx of genetic influence from other populations. This {{is evidenced by the}} presence of the Y-DNA Haplogroup R1b which is present among the population of the Philippines. However, DNA studies vary. A year 2001 study conducted by Stanford University Asia-Pacific Research Center stated that 3.6% of the Philippine population had European Y-DNA. However, only 28 individuals from the isolated rural island of Palawan were genotyped for this study, a sample size far below the <b>minimum</b> <b>sample</b> <b>size</b> needed to account for credible test results in a population of over 100 million individuals. According to another genetic study done by the University of California (San Francisco), they discovered that Filipinos possess moderate amounts of European genetic ancestry. Also, according to a massive DNA study conducted by the National Geographic's, [...] "The Genographic Project", based on genetic testings of 80,000 Filipino people by the National Geographic in 2008–2009, they found out that the average Filipino's genes are around 53% Southeast Asian and had varying Oceanian, East Asian, Southern European, South Asian and Native American percentages. Most of these statistical samples however came from Mindanao and Palawan; areas that were least affected by Spanish colonization. Which means that people coming from North and some Visayan cities that are traditionally hispanic outpost might have more. The Stanford study says that 3.6% (that is 1 out of 28) have shown to have European PATERNAL markers. That is, the Y chromosome passed by the males to their male offsprings/descendants (aka unbroken male lineage). The European ancestry was actually more of a side note as the study was geared towards [...] "interbreeding" [...] between Homo erectus and homo sapiens. The Kaiser (UCSF) study was more generalized. It says that [...] "self-reported Filipinos showed continuous European genetic ancestry". Points to consider: Stanford only studied Y chromosomes. Kaiser most likely used the newer autosomal DNA testing.|$|E
40|$|<b>Minimum</b> <b>sample</b> <b>sizes</b> are {{recommended}} for conducting {{exploratory factor analysis}} on dichotomous data. A Monte Carlo simulation was conducted, varying the level of communalities, number of factors, variable-to-factor ratio and dichotomization threshold. <b>Sample</b> <b>sizes</b> were identified based on congruence between rotated population and sample factor loadings...|$|R
5000|$|PowerUp! {{provides}} convenient excel-based {{functions to}} determine minimum detectable effect <b>size</b> and <b>minimum</b> required <b>sample</b> <b>size</b> for various experimental and quasi-experimental designs.|$|R
40|$|In mastery {{testing the}} raw {{agreement}} index and the kappa index may be estimated via one test administration when the test scores follow beta-binomial distributions. This paper reports formulae, tables, {{and a computer}} program which facil-itate the computation of the standard errors of the estimates. Illustrative applications are provided {{in the form of}} confi-dence intervals, hypothesis testing, and <b>minimum</b> <b>sample</b> <b>sizes</b> in reliability studies for mastery tests...|$|R
5000|$|The {{intersection}} of the column and row is the <b>minimum</b> <b>sample</b> <b>size</b> required.|$|E
50|$|Plans for {{training}} of personnel were developed, as were plans for external quality assessment. The <b>minimum</b> <b>sample</b> <b>size</b> in each pilot project country was 200 individuals between 25 and 64 years of age. The pilot survey project succeeded at standardizing HES measurements across populations despite participant countries having differing cultural settings, economic statuses, infrastructures and levels of previous experience conducting an HES.|$|E
50|$|A {{variety of}} {{research}} {{study by the}} University of the Philippines, genetic chromosome were found in Filipinos which are shared by people {{from different parts of}} East Asia, and Southeast Asia. The predominant genotype detected was SC, the Southeast Asian genotype. However, only about 50 urine samples were collected for the study, far below the <b>minimum</b> <b>sample</b> <b>size</b> needed to account for credible test results.|$|E
40|$|An {{acceptance}} sampling plan for Gompertz distribution under a truncated life test is developed. For different acceptance numbers, consumer’s confidence levels {{and values of}} the ratio of the experimental time to the specified mean lifetime, the <b>minimum</b> <b>sample</b> <b>sizes</b> required to ensure the specified mean lifetime are obtained. The operating characteristic function values and the associated producer’s risks are also presented. An example is provided to illustrate the {{acceptance sampling}} plan...|$|R
40|$|The {{two-phase}} design {{consists of}} an initial (Phase One) study with known disease status and inexpensive covariate information. Within this initial study one selects a subsample on which to collect detailed covariate data. Two-phase studies {{have been shown to}} be efficient compared to standard case-control designs. However, potential problems arise if one cannot assure <b>minimum</b> <b>sample</b> <b>sizes</b> in the rarest categories or if recontact of subjects is difficult...|$|R
40|$|Background: Progressive brain atrophy in {{multiple}} sclerosis (MS) may reflect neuroaxonal and myelin loss and MRI measures of brain tissue loss {{are used as}} outcome measures in MS treatment trials. This study investigated <b>sample</b> <b>sizes</b> required to demonstrate reduction of brain atrophy using three outcome measures in a parallel group, placebo-controlled trial for secondary progressive MS (SPMS). Methods: Data were taken from a cohort of 43 patients with SPMS who had been followed up with 6 -monthly T 1 -weighted MRI for up to 3 years within the placebo arm of a therapeutic trial. Central cerebral volumes (CCVs) were measured using a semiautomated segmentation approach, and brain volume normalized for skull size (NBV) was measured using automated segmentation (SIENAX). Change in CCV and NBV was measured by subtraction of baseline from serial CCV and SIENAX images; in addition, percentage brain volume change relative to baseline was measured directly using a registration-based method (SIENA). <b>Sample</b> <b>sizes</b> for given treatment effects and power were calculated for standard analyses using parameters estimated from the sample. Results: For a 2 -year trial duration, <b>minimum</b> <b>sample</b> <b>sizes</b> per arm required to detect a 50 % treatment effect at 80 % power were 32 for SIENA, 69 for CCV, and 273 for SIENAX. Two-year <b>minimum</b> <b>sample</b> <b>sizes</b> were smaller than 1 -year by 71 % for SIENAX, 55 % for CCV, and 44 % for SIENA. Conclusion: SIENA and central cerebral volume are feasible outcome measures for inclusion in placebo-controlled trials in secondary progressive multiple sclerosis. Neurology (R) 2009; 72 : 595 - 60...|$|R
50|$|TQIP {{utilizes}} {{a retrospective}} cohort of trauma patients in designated and ACS-verified Level I and II {{hospitals in the}} United States and Canada. There is no <b>minimum</b> <b>sample</b> <b>size</b> requirement for a trauma center {{to participate in the}} program. , over 200 participating Level I and II trauma centers that vary in type (public, private teaching university, teaching community, etc.) and region participate in TQIP.|$|E
5000|$|An {{advantage}} of cultural consensus is {{the availability of}} necessary sample size information and that necessary sample sizes {{do not need to}} be very large. Sample size determination in a consensus analysis is similar to other types of analyses; namely, that when variability is low, power is high and small samples will suffice. Here, variability is the agreement (competence) among subjects. For the formal model, sample size can be estimated from the level of agreement (e.g., assuming a low average competence level of [...]50), the proportion of items to be correctly classified (assuming a high level, [...]95), and high confidence (.999) a <b>minimum</b> <b>sample</b> <b>size</b> of 29 (per subgroup) is necessary.1,5 For higher levels of competence and lower levels of accuracy and confidence, smaller samples sizes are necessary. Similarly, sample size can be estimated with reliability theory and the Spearman-Brown prophecy formula (applied to people instead of items). For a relatively low level of agreement (an average correlation of [...]25 between people, comparable to an average competence of [...]50) and a high degree of desired validity (.95 correlation between the estimated answers and the true answers), a study would require a <b>minimum</b> <b>sample</b> <b>size</b> of 30 subjects.|$|E
50|$|Power {{analysis}} {{can be used}} to calculate the <b>minimum</b> <b>sample</b> <b>size</b> required so that one can be reasonably likely to detect an effect of a given size. For example: “how many times do I need to toss a coin to conclude it is rigged?” Power {{analysis can}} also be used to calculate the minimum effect size that is likely to be detected in a study using a given sample size. In addition, the concept of power is used to make comparisons between different statistical testing procedures: for example, between a parametric and a nonparametric test of the same hypothesis.|$|E
30|$|All {{analyses}} with HM {{concentration in}} moss {{were based on}} a reasonably large <b>sample</b> <b>size</b> of at least 3274 (As) out of 3965 (Zn) <b>sample</b> points. The <b>minimum</b> <b>sample</b> <b>sizes</b> for elements and ELCE 40 classes were calculated and presented by Schröder et al. [28, 29]. As the number of moss sampling sites was very low (>[*] 10 in the classes D_ 16, D_ 21, L_ 2, M_ 5, and M_ 6), the correlations for these classes are not considered reliable and are not described below. However, these four classes altogether represent only 2.3 % (=[*] 69, 600  km 2) of the sampled area in the countries participating in the EMS (=[*] 3, 083, 500  km 2).|$|R
40|$|Methods are {{presented}} for calculating <b>minimum</b> <b>sample</b> <b>sizes</b> necessary to obtain precise estimates of fungal spore dimensions. Using previously published spore-length data sets for Peronospora species, we demonstrate that 41 — 71 spores {{need to be}} measured to estimate the mean length with a reasonable level of statistical precision and resolution. This is further progressed with examples for calculating the minimum number of spore lengths to measure when matching an undetermined specimen to a known species. Although applied only to spore-length data, all described methods {{can be applied to}} any morphometric data that satisfy certain statistical assumptions. <br /...|$|R
40|$|This paper {{considers}} {{the problem of}} an acceptance sampling plan for a truncated life test when the lifetime follows the generalized Rayleigh distribution. For different acceptance numbers, confidence levels, {{and values of the}} ratio of the fixed experiment time to the specified mean life, the <b>minimum</b> <b>sample</b> <b>sizes</b> necessary to ensure the specified mean life are found. The operating characteristic values of the sampling plans and producer's risk are discussed. Some tables are presented {{and the use of the}} tables is illustrated by a numerical example. Consumer's risk, generalized Rayleigh distribution, operating characteristic curve, producer's risk, truncated life tests,...|$|R
50|$|There are, however, some {{potential}} drawbacks to using stratified sampling. First, identifying strata and implementing {{such an approach}} can increase the cost and complexity of sample selection, as well as leading to increased complexity of population estimates. Second, when examining multiple criteria, stratifying variables {{may be related to}} some, but not to others, further complicating the design, and potentially reducing the utility of the strata. Finally, in some cases (such as designs with a large number of strata, or those with a specified <b>minimum</b> <b>sample</b> <b>size</b> per group), stratified sampling can potentially require a larger sample than would other methods (although in most cases, the required sample size would be no larger than would be required for simple random sampling.|$|E
5000|$|In 2014 ATVOD {{published}} {{the results of}} research carried out in December 2013, tracking the actions of 45,000 UK internet users {{under the age of}} 18. Of those sampled, 10% of under-18s, 6% of under-16s, and 3% of under-12s who used the Internet during that month accessed an adult internet service at some point. [...] The definition of an adult website in the survey was broad, including the sex toy and lingerie retailer Ann Summers. Concerns were raised about the small sample size associated with users aged under 12. Nielsen Netview, the marketing agency that carried out the survey, commented that: [...] "The sample size for 6-11 year-olds on the panel is very low. Figures for this age range are still reported, but they are always issued with a 'health warning' as being potentially too unstable to accurately project audience size." [...] ATVOD confirmed that: [...] "Sample sizes for the youngest children (6 - 11) are relatively small and figures for this age group should be treated with caution as they may exhibit large changes month to month... These demographics do not meet <b>minimum</b> <b>sample</b> <b>size</b> standards." ...|$|E
50|$|These {{indigenous}} {{elements in}} the Filipino's genetic makeup serve as clues to the patterns of migration throughout Philippine prehistory. After the 16th century, of course, the colonial period saw the influx of genetic influence from Europeans. During the above-mentioned study conducted by Stanford University Asia-Pacific Research Center, it was stated that 3.6% of the Philippine population has varying degrees of European ancestry from Spanish, and American colonization. However, only 28 individuals from the Philippines were genotyped for this study, again a sample size far below the <b>minimum</b> <b>sample</b> <b>size</b> needed to account for credible test results in a population of over 90 million individuals. However, the Stanford study is conflicted by {{the findings of the}} open-source Y-DNA bank of the company, Applied Biosystems, which found out that most Philippine Y-DNA haplogroups were found to be O3 and O2, which comes from East Asia, Southeast Asia and Polynesia but also concluded that those that carry the percentage of Spanish Y-DNA haplogroups, were higher at around 13.33% of the population (haplogroup R1b). Compared to the 28 individuals used by Stanford which they sampled from the rural areas of isolated Palawan island, the Y-DNA bank had analyzed 105 Filipino individuals from all across the country.|$|E
40|$|For {{analysing}} element {{input into}} ecosystems and associated risks due to atmospheric deposition, element concentrations in moss provide complementary and time-integrated data at high spatial resolution every 5 years since 1990. The paper reviews (1) <b>minimum</b> <b>sample</b> <b>sizes</b> needed for reliable, statistical estimation of mean values at four different spatial scales (European and national level {{as well as}} landscape-specific level covering Europe and single countries); (2) trends of heavy metal (HM) and nitrogen (N) concentrations in moss in Europe (1990 – 2010); (3) correlations between concentrations of HM in moss and soil specimens collected across Norway (1990 – 2010); and (4) canopy drip-induced site-specific variation of N concentration in moss sampled in seven European countries (1990 – 2013). While the <b>minimum</b> <b>sample</b> <b>sizes</b> on the European and national level were achieved without exception, for some ecological land classes and elements, the coverage with sampling sites should be improved. The decline in emission and subsequent atmospheric deposition of HM across Europe has resulted in decreasing HM concentrations in moss between 1990 and 2010. In contrast, hardly any changes were observed for N in moss between 2005, when N was included into the survey for the first time, and 2010. In Norway, both, the moss and the soil survey data sets, were correlated, indicating a decrease of HM concentrations in moss and soil. At the site level, the average N deposition inside of forests was almost three {{times higher than the}} average N deposition outside of forests...|$|R
40|$|Stomach content {{analysis}} {{is a traditional}} methodology in food web studies, however, studies using this technique hardly ever justify sampling protocol or assess sufficient number of samples to characterize diet. We evaluate a well established sampling protocol in a temperate continental shelf sea (Southern Bay of Biscay) by analyzing 10 years of stomach analysis of the demersal predator Chelidonichthys cuculus. Our sampling had {{the coverage of the}} IBTS survey in the area, and consisted on 10 stomachs of the predator whenever present in the catch. <b>Minimum</b> <b>sampling</b> <b>size</b> was annually estimated by adjusting an asymptotic model to the prey accumulation curve. Our sampling identified annually 92. 5 - 99. 7 % of the prey pool, suggesting that up to 3 species remained unidentified depending on the year, however the number of stomach samples necessary to reach this precision in the diet varied between 96 and 338 predators. While these annual samples characterize satisfactorily the species diet and largely exceeds the number of samples that would optimize the sampling strategy, it might still lack the statistical power to perform some of the most common analyses in trophic ecology, incurring in type I error in statistical analysis. We use a set of environmental variables including geographical data and sediment characteristics to explore the relation between the <b>minimum</b> <b>sampling</b> <b>size</b> to characterize C. cuculus diet and that necessary to analyse geographical patterns in its diet...|$|R
40|$|This paper {{shows how}} machine {{learning}} classifier techniques {{can be used}} to help determine the minimum amount of data required in physical geographic models. Two case studies are considered that report the use of machine learning classifiers to obtain <b>minimum</b> <b>sample</b> <b>sizes</b> for ground-based data surveys in environmental domains. One such learning algorithm, the inductive learning program C 4. 5 was used to verify that a high performance classifier, better than 95 % classification accuracy on unseen data, can be constructed using 235 sample points in the case-study area. We compare this result to the magnitude of <b>sample</b> <b>sizes</b> required for similar classification performance using back-propagation neural networks and instance-based learning. We examine the reasons and implications for these variations with reference to the domain. 1 Introductio...|$|R
40|$|Proactive {{preliminary}} <b>minimum</b> <b>sample</b> <b>size</b> determination can {{be useful}} for the early planning stages of a latent variable modeling study to set a realistic scope, long before the model and population are finalized. This study examined existing methods and proposed a new method for proactive preliminary <b>minimum</b> <b>sample</b> <b>size</b> determination...|$|E
40|$|Hypergeometric Attribute Sampling System Based on Risk and Fraction Defective (HYPERSAMP) {{computer}} program demonstrates attribute sampling system developed to determine <b>minimum</b> <b>sample</b> <b>size</b> required for any preselected value for consumer's risk and fraction of nonconforming units. Used {{in place of}} MIL-STD- 105 E sampling plans when <b>minimum</b> <b>sample</b> <b>size</b> desirable, such as when tests are destructive or expensive. Written for IBM PC-compatible computers...|$|E
30|$|The online “sample size calculator” formula {{determined}} {{the size of}} our sample at 577 households as the <b>minimum</b> <b>sample</b> <b>size</b> to ensure 95  % confidence and 4  % precision levels. The second step was to distribute the total sample size proportionally among selected villages using, as suggested by the theory, a 50 - 50 weighting between the population and the number of households in each village. We considered five as a <b>minimum</b> <b>sample</b> <b>size</b> from each village. Accordingly, in cases where the <b>minimum</b> <b>sample</b> <b>size</b> determined is below five, it was increased to five for which the total sample size became 608. Finally, we used a simple random sampling procedure to select respective numbers of households from each village (Abdelali-Martini and Hamza 2014).|$|E
30|$|Study {{enrollment}} {{was restricted}} by funding. However, we projected that such resource restrictions would still allow for sufficient enrollment {{to yield a}} <b>minimum</b> effective <b>sample</b> <b>size</b> that would be sufficient for primary outcome analyses, even after factoring in an anticipated drop-out rate of 10 % per group (see <b>sample</b> <b>size</b> justification below) [4, 5, 37].|$|R
40|$|An {{important}} aspect of tropical medicine is analysis of geographic aspects of risk of disease transmission, which for lack of detailed public health data must often be reduced {{to an understanding of}} the distributions of critical species such as vectors and reservoirs. We examine the applicability of a new technique, ecological niche modeling, to the challenge of understanding distributions of such species based on municipalities in the state of São Paulo in which a group of 5 Lutzomyia sandfly species have been recorded. The technique, when tested based on independent occurrence data, yielded highly significant predictions of species' distributions; <b>minimum</b> <b>sample</b> <b>sizes</b> for effective predictions were around 40 municipalities...|$|R
40|$|Hayter (J. Amer. Statist. Assoc. 85 (1990)) {{proposed}} a one-sided studentized range test (OSRT) for testing {{the null hypothesis}} H 0 : ? 1 = … = ?k against the simple ordered alternative Ha: ? 1 ? … ? ?k in a one-way layout. The size and power of this test, however, are quite difficult to calculate. The method suggested in Hayter (J. Amer. Statist. Assoc. 85 (1990)) for critical point computation works only for small k. The method introduced in this paper works for much larger k, and also works for the power calculation. Some tables of critical points and <b>minimum</b> <b>sample</b> <b>sizes</b> satisfying certain power requirements are provided...|$|R
40|$|This paper {{examines}} the <b>minimum</b> <b>sample</b> <b>size</b> required {{by each of}} six sampling techniques for estimating annual passenger miles traveled to meet the Federal Transit Administration’s 95 % confidence and 10 % precision levels for the National Transit Database. It first describes these sampling techniques in non-technical terms and hypothesizes how {{they are expected to}} compare in their minimum sample sizes. It then determines the <b>minimum</b> <b>sample</b> <b>size</b> for 83 actual sample datasets that cover 6 modes and 65 transit agencies. Finally, it summarizes the results in <b>minimum</b> <b>sample</b> <b>size</b> to compare the relative efficiency of these sampling techniques. The potential for improved efficiency from using these sampling techniques is great, but the exact degree of improvement depends highly on individual agencies, modes, and services...|$|E
40|$|In this paper, {{we develop}} {{acceptance}} sampling plan when the lifetime experiment is truncated at a pre-assigned time. The <b>minimum</b> <b>sample</b> <b>size</b> required {{to ensure a}} specified median life of the experimental unit is provided when the lifetimes of the units follow generalized Weibull distribution which exhibits both monotone and non-monotone failure rates. The operating characteristic values of the sampling plans {{as well as the}} producer’s risk are also presented. One data analysis is provided for illustrative purpose. Acceptance sampling, Failure rates, Generalized Weibull distribution, Life test, Type I censoring, <b>Minimum</b> <b>sample</b> <b>size,</b> Producer’s risk...|$|E
3000|$|Study design: {{randomized}} and non-randomized controlled clinical trials, prospective cohort studies, {{and case}} series (with a <b>minimum</b> <b>sample</b> <b>size</b> of 20 patients) with minimum follow-up periods of 6  months [...]...|$|E
30|$|Statistical {{population}} {{of this research}} comprises all 5017 olive growers of Roudbar County, while <b>sample</b> <b>size</b> consists of 209 respondents (Bartlett et al. 2001). To achieve the <b>minimum</b> required <b>sample</b> <b>size</b> in this study, a sample of 240 people was considered. Finally, 210 questionnaires were returned from 240 questionnaires distributed (questionnaire return rate was 87.5 %).|$|R
40|$|The primary {{objective}} {{of this study was}} to find the smallest <b>sample</b> <b>size</b> for which equating based on a random groups design could be expected to result in less overall equating error than had no equating been conducted. Mean, linear, and equipercentile equating methods were considered. Some of the analyses presented in this paper assumed that the test scores were normally distributed. Other analyses were not based on this assumption. Real test data were used to check whether the theoretical methods provide reasonably accurate results for use in estimating <b>sample</b> <b>size</b> requirements. The science subtest of the ACT assessment provided the basic data for investigating the standard errors of equating and the <b>minimum</b> <b>sample</b> <b>sizes</b> needed to obtain less equating error than the identity equating. In general, as the <b>sample</b> <b>size</b> increased, the magnitude of the standard errors decreased for both forms of the test considered. In linear equating, the standard error becomes less as the raw score value approaches the mean score. I...|$|R
40|$|AbstractThe {{computational}} cost of many computer codes is {{a burden}} that obliges users {{to use the}} same set of simulations to perform uncertainty and sensitivity analysis. Correlation ratios are a simple and straightforward tool to estimate first order sensitivity indices. Nevertheless, they demand the use of debiasing factors and of appropriate partitions of the support of each input parameter to deliver optimal estimates. The way to estimate these indices depends in fact on the actual values to be estimated. This work contains an exhaustive study developed for providing a set of guidelines about the optimal way to deliver such estimates, which involves the <b>minimum</b> <b>sample</b> <b>sizes</b> needed, the selection of the partition and the use of appropriate debiasing factors...|$|R
