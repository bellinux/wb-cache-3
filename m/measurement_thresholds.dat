10|686|Public
40|$|The rainbow schlieren {{apparatus}} is simpler, cheaper, {{and more}} easily built to large scale than the interferometer. The accuracies {{of the two}} instruments are similar but only if refraction is properly accounted for in interferometry. The <b>measurement</b> <b>thresholds</b> of both instruments are similar. The rainbow schlieren device provides more detailed information because the detection threshold of the rainbow schlieren is {{an order of magnitude}} better than that of the interferometer...|$|E
40|$|Abstract: Measurements {{validation}} is {{a critical}} feature in monitoring systems required by most industry applications to achieve higher level reliability. This paper presents {{the use of the}} <b>measurement</b> <b>thresholds</b> generated from the propagation of parametric uncertainty using fuzzy logic to validate the sensor measurements of an induction motor drive by means of fuzzy techniques. If measurements fail the validation check, they are replaced by reconstructed data to maintain the operation. Reconstruction is performed with fuzzy logic, which also supports the evaluation of the thresholds. The algorithms proposed here have been implemented and tested both in simulation and in real time experiments on a field oriented controlled induction machine...|$|E
40|$|Analyses of {{simulated}} {{and operational}} ERTS images have provided initial estimates of resolution, ground resolution, detectability thresholds {{and other measures}} of image quality of interest to earth scientists and cartographers. Based on these values, including an approximate ground resolution of 250 meters for both RBV and MSS systems, the ERTS- 1 images appear suited to the production and/or revision of planimetric and photo maps of 1 : 500, 000 scale and smaller for which map accuracy standards are compatible with the imaged detail. Thematic mapping, although less constrained by map accuracy standards, will be influenced by <b>measurement</b> <b>thresholds</b> and errors which {{have yet to be}} accurately determined for ERTS images. This study also indicates the desirability of establishing a quantitative relationship between image quality values and map products which will permit both engineers and cartographers/earth scientists to contribute to the design requirements of future satellite imaging systems...|$|E
30|$|To {{solve the}} problem of finding the optimal channel {{selection}} strategy, based on the combination of both passive and active <b>measurement</b> <b>threshold</b> criteria, we also need to consider the adaptive nature of the OTT CoD application traffic, which makes it harder to determine optimal thresholds.|$|R
40|$|This study {{proposes a}} {{performance}} {{analysis of the}} measurements mechanism applicable to the terminal controlled cell reselection algorithm in a mobile cellular communication system. The cell reselection mechanism decides on which cell, a user equipment (UE) is camped on, when {{it is in the}} idle mode. The analysis demonstrates the impact of the neighbour cells <b>measurement</b> <b>threshold</b> setting during the reselection on the serving cell pilot channel quality and a measurement effort in the UE, in terms of the time spent measuring neighbour cells. The authors demonstrate that there is a trade-off between the cell reselection performance, in terms of the signal quality during the mobility and the battery life in the mobile terminal with different system configurations. Furthermore, a novel approach and enhanced load based <b>measurement</b> <b>threshold</b> configuration scheme is proposed, in order to improve this trade-off and also the overall system performance and the user experience. Performance analysis results are given in different scenarios to demonstrate the efficacy of the proposed scheme...|$|R
50|$|An infraparticle is an {{electrically}} {{charged particle}} {{and its surrounding}} cloud of soft photonsâ€”of which there are infinite number, {{by virtue of the}} infrared divergence of quantum electrodynamics. That is, it is a dressed particle rather than a bare particle. Whenever electric charges accelerate they emit Bremsstrahlung radiation, whereby an infinite number of the virtual soft photons become real particles. However, only a finite number of these photons are detectable, the remainder falling below the <b>measurement</b> <b>threshold.</b>|$|R
40|$|A {{statistical}} {{framework for}} climatological Z-R parameter estimation is developed and simulation experiments are {{conducted to examine}} sampling properties of the estimators. Both parametric and nonparametric models are considered. For parametric models, it is shown that Z-R parameters can be estimated by maximum likelihood, a procedure with optimal large sample properties. A general nonparametric framework for climatological Z-R estimation is also developed. Nonparametric procedures are attractive because of their flexibility in dealing with certain types of measurement errors common to radar data. Simulation experiments show that even under favorable assumptions on error characteristics of radar and raingages, large datasets are required to obtain accurate Z-R parameter estimates. Another important conclusion is that estimation results are generally quite sensitive to radar and raingage <b>measurement</b> <b>thresholds.</b> For fixed sample size, the simulation results {{can be used to}} provide quantitative assessments of the accuracy of Z-R model parameter estimates. These results are particularly useful for error analysis of precipitation products that are derived using climatological Z-R relations. One example is the large-area rainfall estimates derived using the height-area rainfall threshold (HART) technique...|$|E
40|$|Abstract The {{effect of}} undersampling on {{estimating}} {{the size of}} extreme natural hazards from historical data is examined. Tests using synthetic catalogs indicate that the tail of an empirical size distribution sampled from a pure Pareto probability distribution can range from having one-to-several unusually large events to appearing depleted, relative to the parent distribution. Both of these effects are artifacts caused by limited catalog length. It {{is more difficult to}} diagnose the artificially depleted empirical distributions, since one expects that a pure Pareto distribution is physically limited in some way. Using maximum-like-lihood methods and the method of moments, we estimate the power-law exponent and the corner size parameter of tapered Pareto distributions for several natural hazard examples: tsunamis, floods, and earthquakes. Each of these examples has varying catalog lengths and <b>measurement</b> <b>thresholds,</b> relative to the largest event sizes. In many cases where there are only several orders of magnitude between the measurement threshold and the largest events, joint two-parameter estimation techniques are necessary to account for estimation dependence between the power-law scaling exponent and the corner size parameter. Results indicate that whereas the corner size parameter of a tapered Pareto distribution ca...|$|E
40|$|Today {{pipeline}} inspection {{through the}} use of in-line inspection tools is a standard procedure. These inspection tools collect highly precise data regarding the geometry of flaws and defects in the pipe wall. In turn this data is used for fitness-for-purpose investigations, the final goal of the operator being an understanding of the true state of integrity for a given pipeline. Different physical principles are applied during the non destructive testing of pipelines, each with its own set of advantages and disadvantages. Choosing the most suitable non destructive testing technology and therefore in line inspection tool for a given inspection task requires an understanding of these different techniques and their system specific <b>measurement</b> <b>thresholds,</b> accuracies and resolutions. This paper will provide an overview of the most widely used in-line inspection technologies of today, with a special focus on the use of ultrasound technology for the detection and sizing of metal loss, quantitative wall thickness measurement and crack inspection. Case examples will be used to illustrate the information that these tools can provide and the influence of accuracy, resolution and confidence levels on integrity assessment and fitness-for-purpose procedures. The paper will also discuss current trends in the industry: the development and application of specialize...|$|E
30|$|The {{residual}} strain analysis using DIC method {{was found to}} be suitable for the non-contact evaluation of the damage in the cell layers beneath the finished surface, although there was limitation of positioning the ROI and <b>measurement</b> <b>threshold.</b> It was confirmed that the subsurface damages may occur depending on the cutting condition employed. The mechanism for occurrence of the machining defects, which is deeply related to the subsurface damage, could be further clarified by analyzing the {{residual strain}} beneath the finished surface using the DIC method.|$|R
40|$|This paper {{presents}} a novel mechanism which increases mobile terminal battery performance. It supports a cell reselection algorithm which decides on which cell, user equipment (UE) is camped on when in idle mode (there is no active radio {{connection with a}} mobile network). Study is based on real 3 G UTRA network measurements. Authors propose a technique to reduce UE current consumption in idle mode based on dynamic Sintrasearch neighbour cell <b>measurements</b> <b>threshold</b> optimization. System analysis covers both UTRA and E-UTRA - Long Term Evolution (LTE) technology...|$|R
40|$|Risk {{assessment}} of pesticides {{can be a}} statistically difficult problem because pesticides occur only occasionally, but they may occur on multiple components in the diet. A Bayesian statistical model is presented which incorporates multivariate modelling of food consumption and modelling of pesticide measurements which are for a large part below a <b>measurement</b> <b>threshold.</b> It is shown that Bayesian modelling is feasible for {{a limited number of}} food components, and that in a data-rich situation the model compares well with an empirical Monte Carlo modellin...|$|R
40|$|Ecological {{indicators}} are used extensively as tools to manage environmental resources. In the oceans, indicators of plankton {{can be measured}} {{using a variety of}} observing systems including: mooring stations, ships, autonomous floats and ocean colour remote sensing. Given the broad range of temporal and spatial sampling resolutions of these different observing systems, as well as discrepancies in measurements obtained from different sensors, the estimation and interpretation of plankton indicators can present significant challenges. To provide support to the assessment {{of the state of the}} marine ecosystem, we propose a suite of plankton indicators and subsequently classify them in an ecological framework that characterizes key attributes of the ecosystem. We present two case studies dealing with plankton indicators of biomass, size structure and phenology, estimated using the most spatially extensive and longest in situ and remote-sensing observations. Discussion of these studies illustrates how some of the challenges in estimating and interpreting plankton indicators may be addressed by using for example relative <b>measurement</b> <b>thresholds,</b> interpolation procedures and delineation of biogeochemical provinces. We demonstrate that one of the benefits attained, when analyzing a suite of plankton indicators classified in an ecological framework, is the elucidation of non-trivial changes in composition, structure and functioning of the marine ecosystem...|$|E
3000|$|The {{core part}} of the DVNS is the Services Registry. This is a {{database}} where all the known/registered WSI Enablers and the VSN services, which are known to this VSN service provider, are listed and described. In addition to the service name, ID, and description, the Service Registry has knowledge of the WSI Enabler(s) that offer the services, their gateways, etc., and in particular knows which Gateway(s) is/are responsible for each service. The VSN services may be composed from several [...] "more elementary" [...] services (hereafter called [...] "abstract services") according, for example, to some pre-defined composition rule. Abstract services are described {{through a number of}} inputs, outputs, and parameters. An example of such a service is one that passively collects measurements of sensing capabilities in a selection of areas. For this service, the parameters may correspond to the set of desired sensing capabilities and areas of interest, the type of the data aggregation function (minimum, maximum, average, etc), the QoS requirements (e.g., tolerated time for a response, accepted percentage of estimated error), the type of reporting pattern (periodic or one-shot) and associated <b>measurement</b> <b>thresholds,</b> and the unit of measurement. The input in this service is the sensor observations and the outputs can be the raw and processed sensor data, as well as the history of the sensor data.|$|E
40|$|After {{selection}} of the 13 biodiversity variables (Sect. 2. 3) based on their importance and feasibility for assessment by NFIs, responses were solicited from participating countries regarding {{the degree to which}} the variables are now assessed. Two conclusions were evident: (1) most countries currently assess most of the variables, but (2) consensus is lacking on assessment methods and necessary field crew expertise, suggesting that harmonization would require emphasis on field operations. For each of the seven essential features into which the 13 variables were grouped, more detailed assessments were conducted. For forest categories, the conclusion was that the only major difference in classification systems used by European NFIs was whether potential or actual vegetation was used to define classes. Thus, the prospects for harmonization of forest categories are considered excellent. For forest structure, the prospects depend on the variable. For tree species, the prospects are excellent because the variable is assessed in the same manner by all NFIs. For dbh and height, considerable variability in measurementthresholds were found, but otherwise the harmonization prospects are good. For social position, definitions of classes varied, but harmonized estimates of proportions for dominant, intermediate, and suppressed classes are considered possible. Prospects for harmonized estimates of layers are consideraly poorer because of different definitions, thresholds and the uncertainty associated with visual assessment methods. Harmonized estimation of forest age is impeded by the increasing proportion of uneven-aged stands for which age is often not assessed, different definitions, and different assessment methods. However, agreement on dominant age as a reference definition would greatly increase the prospects. Deadwood is becoming an increasingly popular indicator of sustainable forest management. Unfortunately, considerable variability was found in deadwood definitions, components (e. g., stumps, limbs), sampling methods, and <b>measurement</b> <b>thresholds.</b> Thus, harmonized deadwood estimation will require development of bridges. Harmonization of regeneration estimates faces challenges due to differences in assessment approaches such as presence/absence versus coverage and all species versus dominant species. Harmonized estimation may be restricte to change in regeneration success. Harmonized estimation for ground vegetation also faces serious challenges due to differences in the components assessed (e. g., small trees, shrubs, herbs, bryophytes, lichens), difference in height thresholds, and differences in categories for which ground vegetation is reported. Forest naturalness integrates many of the other essential feature. However, many countries do not assess naturalness, and among those that do, assessment variables, methods, and reporting classes vary considerably. For harmonized assessment using NFI variables, the hemeroby approach, which emphasizes indications of human influence, is extremely sensitive to plot size. Harmonization using the ecosystem processes approach requires a common dbh threshold and similar plot sizes. The overall conclusion is that harmonization will be considerably easier for some essential features than for others. The factors leading to difficulties often are related to different definitions, different reporting classes, different <b>measurement</b> <b>thresholds,</b> and different features of sampling protocols such as plot sizes and configurations. Nevertheless, construction of reference definitions and bridges greatly facilitate harmonization for all essential features as is illustrated in Chap. 5...|$|E
30|$|The PW {{measurement}} {{can also}} be {{defined in terms of}} the number of pixels above a certain high threshold: if more pixels are above that threshold, a larger reaction is needed from the controller. However, this kind of measurement does not reveal the distribution of pixels and can lead to instabilities and challenges for smooth control. Particularly, if pixels are close to the <b>measurement</b> <b>threshold,</b> they can easily switch their position from one side of the threshold to the other. In one case, we would measure a significant number of bright pixels and in the other case much less or even none. From the previous discussion, it is clear that a better solution is required to solve such difficult cases. This solution is a histogram-based measurement.|$|R
40|$|The paper evaluates {{how well}} three {{different}} parametric shapes, ellipsoids, rectangles, and parallelograms, serve as models of three-dimentional detection contours. The {{constraints of the}} procedures for deriving the best-fitting shapes on inferences about the theoretical visual detection mechanisms are described. Results of two statistical tests show that only the parallelogram fits the data with more precision than the variance in repeated <b>threshold</b> <b>measurements,</b> and thus provides a slightly better fit {{than the other two}} shapes. Nevertheless it does not serve as a better guide than the ellipsoidal model for interpolating from the <b>measurements</b> to <b>thresholds</b> in novel color directions...|$|R
40|$|Wide-band {{ultrasound}} transducers, {{based on}} ferroelectric polymer technology, {{were used for}} the measurement of distances in unstructured environments. Piezo-polymer based sonar was mounted aboard mobile robot to emulate the function of bio-sonar, according to strategies observed in the flight of bats. A complete electronic system was designed and assembled, with reduced dimensions, weight, and power consumption, boasting easy assembly onto small mobile devices. Different techniques for distance <b>measurement</b> (<b>threshold</b> method and cross-correlation function together with a denoising method based on wavelet transform) are discussed and compared with results reported in literature, emphasizing the advantages of the polymer transducer in terms of versatility, efficiency, and work modalities. The Web Publishing Tool implemented the remote control features in LabVIEW to manage and modify the signal parameters during testing and acquire data. ...|$|R
40|$|Ambulatory blood {{pressure}} (BP) monitoring is the reference standard for out-of-clinic BP <b>measurement.</b> <b>Thresholds</b> for identifying ambulatory hypertension (daytime systolic BP [SBP]/diastolic BP [DBP] â‰¥ 135 / 85 mm[*]Hg, 24 -hour SBP/DBP â‰¥ 130 / 80 mm[*]Hg, and nighttime SBP/DBP â‰¥ 120 / 70 mm[*]Hg) have been derived from European, Asian, and South American populations. We determined BP thresholds for ambulatory hypertension in a US population-based sample of African American adults. We analyzed {{data from the}} Jackson Heart Study, a population-based cohort study comprised exclusively of African American adults (n= 5306). Analyses were restricted to 1016 participants who completed ambulatory BP monitoring at baseline in 2000 to 2004. Mean SBP and DBP levels were calculated for daytime (10 : 00 am- 8 : 00 pm), 24 -hour (all available readings), and nighttime (midnight- 6 : 00 am) periods, separately. Daytime, 24 -hour, and nighttime BP thresholds for ambulatory hypertension were identified using regression- and outcome-derived approaches. The composite of a cardiovascular disease or an all-cause mortality event {{was used in the}} outcome-derived approach. For this latter approach, BP thresholds were identified only for SBP because clinic DBP was not associated with the outcome. Analyses were stratified by antihypertensive medication use. Among participants not taking antihypertensive medication, the regression-derived thresholds for daytime, 24 -hour, and nighttime SBP/DBP corresponding to clinic SBP/DBP of 140 / 90 mm[*]Hg were 134 / 85 mm[*]Hg, 130 / 81 mm[*]Hg, and 123 / 73 mm[*]Hg, respectively. The outcome-derived thresholds for daytime, 24 -hour, and nighttime SBP corresponding to a clinic SBP â‰¥ 140 mm[*]Hg were 138 mm[*]Hg, 134 mm[*]Hg, and 129 mm[*]Hg, respectively. Among participants taking antihypertensive medication, the regression-derived thresholds for daytime, 24 -hour, and nighttime SBP/DBP corresponding to clinic SBP/DBP of 140 / 90 mm[*]Hg were 135 / 85 mm[*]Hg, 133 / 82 mm[*]Hg, and 128 / 76 mm[*]Hg, respectively. The corresponding outcome-derived thresholds for daytime, 24 -hour, and nighttime SBP were 140 mm[*]Hg, 137 mm[*]Hg, and 133 mm[*]Hg, respectively, among those taking antihypertensive medication. On the basis of the outcome-derived approach for SBP and regression-derived approach for DBP, the following definitions for daytime, 24 -hour, and nighttime hypertension corresponding to clinic SBP/DBP â‰¥ 140 / 90 mm[*]Hg are proposed for African American adults: daytime SBP/DBP â‰¥ 140 / 85 mm[*]Hg, 24 -hour SBP/DBP â‰¥ 135 / 80 mm[*]Hg, and nighttime SBP/DBP â‰¥ 130 / 75 mm[*]Hg, respectivel...|$|E
40|$|The authors {{demonstrate}} Brownian-noise-limited {{operation of}} an optomechanical oscillator, wherein mechanical oscillations of a silica optical microcavity are sustained {{by means of}} radiation pressure. Using phase noise <b>measurement</b> above <b>threshold,</b> {{it has been shown}} that the short-term linewidth of mechanical oscillations is fundamentally broadened, limited by thermal equipartition of energy...|$|R
40|$|One of {{the useful}} {{features}} of muon colliders is the naturally narrow spread in beam energies. <b>Measurements</b> of <b>threshold</b> cross sections then become a prime candidate for precision measurements of particle masses, widths, and couplings {{as well as}} determining particle spin. We describe the potential for measuring cross sections near threshold in supersymmetric theories...|$|R
30|$|<b>Threshold</b> <b>measurements</b> were {{performed}} for both kidneys and spleen using 42, 50, 60 and 70 {{percent of the}} maximum in the organ as limit. The 42 Â % threshold has previously showed to most closely resemble the true volume [24], and the higher thresholds were chosen to see what impact a higher threshold {{would have on the}} quantification. The <b>threshold</b> <b>measurements</b> {{were performed}} using the VOI tool in NEDPAS Software Tools [25] Version Built 26042009 written by R. Boellaard, VU University Medical Center, Amsterdam, The Netherlands.|$|R
40|$|<b>Measurements</b> of <b>threshold</b> {{contrast}} {{required for}} various resolution tasks at various background light levels are reported. The predictions {{of a simple}} statistical model based on photon-noise limited detection are compared with the empirical observations. Correspondence is encouraging provided care is taken {{to account for the}} variation of all important parameters such as spatial and temporal integration, pupil area, etc...|$|R
5000|$|There {{have been}} several {{theories}} {{about the nature of}} this object, but currently no theory entirely fits the observed data. It has been suggested that the object could be an unusual [...] "micro quasar", having very high radio luminosity yet low X-ray luminosity, and being fairly stable, it could be an analogue of the low X-ray luminosity galactic microquasar SS 433. However, all known microquasars produce large quantities of X-rays, whereas the object's X-ray flux is below the <b>measurement</b> <b>threshold.</b> The object is located at several arcseconds from the center of M82 which makes it unlikely to be associated with a supermassive black hole. It has an apparent superluminal motion of four times the speed of light relative to the galaxy center. Apparent superluminal motion is consistent with relativistic jets in massive black holes and does not indicate that the source itself is moving above lightspeed.|$|R
50|$|Electrogustometry is the <b>measurement</b> {{of taste}} <b>threshold</b> by passing {{controlled}} anodal current through the tongue. When current {{passes through the}} tongue a unique and distinct metallic taste is perceived.|$|R
50|$|In 1978, he {{obtained}} his degree in Medicine and Surgery at the University of Ferrara. His doctoral thesis concerned the <b>measurement</b> of anaerobic <b>threshold</b> {{in the sport}} of running.|$|R
40|$|Absolute cross {{sections}} for electron impact ionization, dissociative excitation (DE) and dissociative ionization of N- 2 (+) ions are {{measured in the}} energy range from threshold to 2500 eV. The animated crossed electron-ion beam method has been employed. The individual contributions of ionization products (N- 2 (2 +)) and dissociation fragments (N+), which have both identical mass-to-charge ratio and average velocity, are deduced from the analysis of product velocity distributions. Particular {{attention was paid to}} determining the transmission efficiency for dissociation fragments, since their collection was incomplete during the <b>measurements.</b> <b>Threshold</b> energies and kinetic energy released to dissociation fragments are measured. The role of states contributing to different reactions is discussed. For DE, the present results are found to be much smaller than the results of Peterson et al (1998). For ionization (single and dissociative), a satisfactory agreement with their result is obtained {{as well as with the}} prediction of Kim et al (2000) obtained in the binary-encounter Bethe approximation...|$|R
40|$|Abstractâ€”In this paper, a {{parametric}} electromagnetic {{radiated emission}} {{model has been}} explored. Several mathematical improvements with respect to its extraction and computational performance have been deployed. The model, represented {{with an array of}} radiating electric dipoles, predicts the electromagnetic emission of components and systems. Core-level changes have been made in order to extract the model parameters: the dipole positions, their orientations and currents, and the effective relative permittivity from near-field <b>measurements.</b> <b>Thresholding</b> and windowing techniques are used to detect and optimize dipole positions, directly from the field data. A fast and memory efficient two-level optimization algorithm based on the Levenberg-Marquardt non-linear least squares technique is implemented for parametric extraction. All the constraints of the previous model have been overcome and the system is validated for mono-substrate and multisubstrate devices from measurements and/or simulations, with promising results. A tremendous improvement in modeling capability and performance has been obtained when compared with that of its erstwhile counterpart. 1...|$|R
50|$|Psychophysics also {{refers to}} a general class of methods {{that can be applied}} to study a perceptual system. Modern {{applications}} rely heavily on <b>threshold</b> <b>measurement,</b> ideal observer analysis, and signal detection theory.|$|R
40|$|The paper {{reviews the}} {{contributions}} of Ernst Mach to vestibular research. His experiments, mainly psychophysical in nature, included <b>measurements</b> of <b>threshold</b> and investigation of the vestibular-visual interaction. Among his conclusions are that the adequate stimulus for the semicircular canals must be pressure, and that the sustained endolymph flow theory of Breuer (1874) and Crum Brown (1874) is erroneous. Excerpts are given of Mach's publications on vestibular functions. ...|$|R
40|$|A {{finite element}} model of cardiac {{conduction}} was used to simulate two experimental protocols: 1) fibrillation <b>threshold</b> <b>measurements</b> and 2) clinical electrophysiologic (EP) testing procedures. The model consisted of a cylindrical lattice whose properties were determined by four parameters: element length, conduction velocity, mean refractory period, and standard deviation of refractory periods. Different stimulation patterns were applied to the lattice under a given set of lattice parameter values and {{the response of the}} model was observed through a simulated electrocardiogram. The studies confirm that the model can account for observations made in experimental fibrillation <b>threshold</b> <b>measurements</b> and in clinical EP testing protocols...|$|R
40|$|An {{exercise}} test {{delivers a}} large number of measurements that are valuable in risk prediction, in detecting coronary artery disease, and in describing the functional exercise response of a patient. However, it is difficult to have comprehensive knowledge of all <b>measurements</b> and their <b>thresholds.</b> The Exercise Test Interpretation (XTI) program compares exercise <b>measurements</b> against established <b>thresholds</b> and provides statements and reasoning texts, as well as explanations of the statements when thresholds are exceeded. A concise, clear, and accurate overview of an exercise test is provided. For validation, the FINCAVAS database (Tampere University, Finland) containing mortality, angiographic, and other clinical data has been used...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedTransient cavitation produced by pulsed ultrasound in the MHz range has been investigated. First, a theoretical background which develops bubble motion {{in general and}} focuses specifically on transient cavitation is presented. Second, {{the development of an}} apparatus which is designed specifically for studying this type of cavitation is discussed. Third, the use of the apparatus to make <b>measurements</b> of cavitation <b>thresholds</b> at various frequencies, pulse durations, and pulse repetition rates is discussed. Finally, results of the cavitation <b>threshold</b> <b>measurements</b> are interpreted using theories developed earlier. [URL] Commander, United States NavyLieutenant, United States Nav...|$|R
3000|$|The second {{reference}} database was for Ingrowth (INGROW). Ingrowth, defined as trees growing across the minimum DBH <b>measurement</b> <b>threshold</b> of 10.0 Â cm, was summarized at the plot-level for each measurement interval and the ingrowth trees were extracted. As {{for the individual}} tree growth {{reference database}}, several stand-level variables were compiled and boosted regression was used to screen variables important for predicting number of ingrowth trees per ha per year (ANINGR). Basal area per ha (BAPHA), net basal area growth per ha per year (AGBA), basal area mortality per ha per year (MortBA), and BA for balsam fir (Abies balsamea (L.)Â Mill. [...]), black spruce (Picea mariana (Mill.) B.S.P.), red spruce (Picea rubens (Sarg.)), white pine (Pinus strobus L.), red maple (Acer rubrum L.), sugar maple (Acer saccharum Marsh.), aspen (Populus spp.), white birch (Betula papyrifera Marsh.), and yellow birch (Betula alleghaniensis Britt.) were identified as important predictors by the boosted regressions. In addition to these basal area measurements, stand density index (SDI), quadratic mean diameter (Dq), maximum DBH, and maximum HT were selected as importantÂ stand-level variables.|$|R
40|$|Multiple {{assessments}} of ambient odor {{were made by}} trained individuals around a swine finishing operation in eastern Nebraska. Assessor responses were analyzed to determine relationships between field odor measurements/ ratings and ratings of annoyance potential, and to identify candidate <b>measurement</b> <b>threshold</b> values for causing annoyance. The likelihood of annoyance increased as odors became more offensive, intense, and concentrated, with r 2 values of 0. 89, 0. 81, and 0. 64, respectively. Candidate thresholds were sought to delineate both â€œany degree of stated annoyance 2 Ì† 2 and 2 Ì† 2 consequential annoyance, 2 Ì† 2 defined as likely causing a change in behavior or activity level and instilling some memory of the odor event. Candidate thresholds for any stated annoyance and consequential annoyance, respectively, were: 1 and 2 for intensity (on a 0 - 5 scale); 2 and 7 dilutions to threshold for odor concentration (as measured using a mask scentometer); and - 1 and - 2 for Hedonic tone (on a + 4 to - 4 scale) ...|$|R
40|$|The aim of {{the paper}} was to {{establish}} the structure of growing stocks, current volume increment, (commercial) value of growing stocks and current (commercial) value increment by different social collectives in highquality beech stands. In order to do so, beech stands from 18 site units were analysed, with analyses of five plots measuring 30 x 30 m carried out on each site unit. For all trees above the <b>measurement</b> <b>threshold,</b> the stem analyses were performed. The stem quality was estimated by quarters. On this basis, the volume, current decade volume increment, value and current decade value increment of stands were established. More than 90 % of volume and even aslightly higher share of value go to the trees from the stand canopy. The collective of 100 the thickest trees per hectare covers {{about half of the}} stands volume or stands value. The percentage of sliced veneer quality is extremely low (3 %), while the percentage of peeled veneer quality is five times higher. The highest values are achieved by stands from mountainous beech sites...|$|R
