4|21|Public
40|$|The program theory used {{to obtain}} the {{software}} package, <b>MAIL</b> <b>LOG,</b> developed for the Scout Project Automatic Data System, SPADS, is described. The program is written in FORTRAN for the PRIME 300 computer system. The <b>MAIL</b> <b>LOG</b> data base consists of three main subfiles: (1) incoming and outgoing mail correspondence; (2) design information releases and reports; and (3) drawings and engineering orders. All subroutine descriptions, flowcharts, and <b>MAIL</b> <b>LOG</b> outputs are given and the data base design is described...|$|E
40|$|The {{operating}} {{instructions for the}} software package, <b>MAIL</b> <b>LOG,</b> developed for the Scout Project Automatic Data System, SPADS, are provided. The program is written in FORTRAN for the PRIME 300 computer system. The <b>MAIL</b> <b>LOG</b> program has the following four modes of operation: (1) INPUT - putting new records into the data base (2) REVISE - changing or modifying existing records in the data base (3) SEARCH - finding special records existing in the data base (4) ARCHIVE - store or put away existing records in the data base. The output includes special printouts of records in the data base and results from the INPUT and SEARCH modes. The <b>MAIL</b> <b>LOG</b> data base consists of three main subfiles: Incoming and outgoing mail correspondence; Design Information Releases and Releases and Reports; and Drawings and Engineering orders...|$|E
40|$|The summary and {{specifications}} {{to obtain}} the software package, <b>MAIL</b> <b>LOG,</b> developed for the Scout Project Automatic Data System, SPADS are provided. The <b>MAIL</b> <b>LOG</b> program has four modes of operation: (1) input - putting new records into the data base; (2) revise - changing or modifying existing records in the data base; (3) search - finding special records existing in the data base; and (4) archive - store or put away existing records in the data base. The output includes special printouts of records in the data base and results from the input and search modes...|$|E
5000|$|A spammer can direct an {{open proxy}} {{to connect to}} a mail server, and send spam through it. The <b>mail</b> server <b>logs</b> a {{connection}} from the proxy—not the spammer's own computer. This provides an even greater degree of concealment for the spammer than an open relay, since most relays log the client address in the headers of messages they pass. Open proxies have also been used to conceal the sources of attacks against other services besides mail, such as Web sites or IRC servers. As spam from proxies and other [...] "spammable" [...] resources grew, DNSBL operators started listing their IP addresses, as well as open relays.|$|R
50|$|Flock 2.5 {{integrated}} {{social networking}} and media services including MySpace, Facebook, YouTube, Twitter, Flickr, Blogger, Gmail, Yahoo! <b>Mail,</b> etc. When <b>logging</b> {{into any of}} the supported social services, Flock could track updates from friends: profiles, uploaded photos, and more. Flock's latest 2.5 version added Twitter Search functionality, multi-casting of status updates to multiple services, and the introduction of instant messaging via Facebook Chat in the browser.|$|R
50|$|Numerous {{other points}} of {{historical}} interest exist on or nearby the Clam River, including the old Arbuckle House and Logging Dam. This house {{served as a}} stopping place for travelers along the old Stillwater to La Pointe <b>Mail</b> Road. Several <b>logging</b> dams are also known to have existed along the river, demonstrating the river’s significance as a channel of commerce during the logging era.|$|R
40|$|Information {{relevant}} to the <b>MAIL</b> <b>LOG</b> program theory is documented. The L-files for mail correspondence, design information release/report, and the drawing/engineering order are given. In addition, sources for miscellaneous external routines and special support routines are documented along with a glossary of terms...|$|E
40|$|Abstract There are {{numerous}} imperative digital text based proofs, {{some of which}} are SMS (Short Message Services), messages, <b>mails,</b> chat <b>logs,</b> etc. The person who researches a case is fundamentally overflowed with information and he needs to invest all his profitable examination time, examining through the loud indexed lists and experiencing unimportant query items. Hence a system is initiated using digital textual data mining standards for configuration and execution, which enhances IIR (Intelligent Information Retrieval) viability in digital forensics. The framework analyzes the input corpus data with domain specific keywords after which search and ranking of the SMSs, based on the weight of the keywords of forensic interest iscomputed. This software is developed as a proof of concept with data mining and weighted search concepts. *Author for correspondenc...|$|R
50|$|TSAPI, {{short for}} Telephony Server Application Programming Interface, was a {{computer}} telephony integration standard developed and promoted by Novell and AT&T. It consisted {{of a number of}} call control commands for switching calls, voice <b>mail</b> and call <b>logging</b> using NetWare servers. Unlike the competing TAPI from Microsoft/Intel, TSAPI was a server-based system that did not expect client-side equipment to handle call switching. This was important to AT&T, who sold large telephone switches that TSAPI was intended to work with.|$|R
40|$|This {{bachelor}} {{thesis is}} interested in integration of security systems into intelligent home networking. For showing the network’s functionality, a demonstration panel with Tecomat programmable logic controller is used. This thesis deals with usage of programmable logic controllers as central units for home security systems. Library with three function blocks for simplification of the module’s configuration, work with user passwords, <b>mail</b> sending and <b>logging</b> function is an output of this thesis. A virtual interface for simplifying the configuration of this security system is have also been created...|$|R
500|$|On August 4, a new {{and larger}} US {{contingent}} was deployed to Guatemala. In order to remain covert, this group identified itself to Armas as the [...] "Social Research Group", composed of businessmen and experts from universities. It consisted of eight CIA officers, three men from the State Department, and one from the US Information Agency. It was led by an officer working under the pseudonym [...] "Francis T. Mylkes," [...] and also included David Atlee Phillips, who was fluent in Spanish and {{had been part of}} the PBSUCCESS team. The group presented itself as unaffiliated with the US government in order to avoid nationalist backlash and to maintain plausible deniability. The new PBHistory group worked directly with the new Guatemalan Comité training its 25 agents and using them to procure documents; the training involved [...] "screening, classifying, indexing, and carding of the confiscated documents [...] the rudiments of <b>mail</b> control, <b>logging,</b> abstracting, and cryptic reference." ...|$|R
40|$|We discuss {{several issues}} {{regarding}} {{the organization of}} economic laboratory experiments such as subject pool, recruitment, scheduling, and show how we solved them {{with the help of}} the Online Recruitment System for Economic Experiments (ORSEE) version 2. 0. With this integrated software experimenters have a free, convenient, and very powerful tool to organize their experiments and sessions in a standardized way. Key features are: PHP/MySQL application, multiple language/ laboratory/ subject pool/ experimenters/ experiment types/ experiment classes support, attribute query selection, random recruitment, experiment calendar, automated reputation system, automated invitation and rule based reminder mailing, subjects manage their own account, overview about registration state, user rights management, pdf output and <b>mailing,</b> complete <b>logging</b> and statistics, and customizable layout. In version 2. 0 the software has been completely reprogrammed in PHP. Several new features have been added. A test system has been installed in order to visually support the reader while reading the manual (www. orsee. org). experiments, recruitment, subject pool management, methodology...|$|R
5000|$|On 4 August, a new {{and larger}} US {{contingent}} was deployed to Guatemala. In order to remain covert, this group identified itself to Armas as the [...] "Social Research Group", composed of businessmen and experts from universities. It consisted of eight CIA officers, three men from the State Department, and one from the US Information Agency. It was led by an officer working under the pseudonym [...] "Francis T. Mylkes," [...] and also included David Atlee Phillips, who was fluent in Spanish and {{had been part of}} the PBSUCCESS team. The group presented itself as unaffiliated with the US government in order to avoid nationalist backlash and to maintain plausible deniability. The new PBHISTORY group worked directly with the new Guatemalan Comité training its 25 agents and using them to procure documents; the training involved [...] "screening, classifying, indexing, and carding of the confiscated documents and the rudiments of <b>mail</b> control, <b>logging,</b> abstracting, and cryptic reference." ...|$|R
40|$|Professional loggers are {{key players}} in the {{management}} of the region’s forest resource. They {{are an integral part of}} a multi-billion dollar wood products industry. In addition, they shape the structure, composition, health, and future development of the forest resource and help various forest owners meet their myriad objectives. Through a comprehensive, random <b>mail</b> survey of <b>logging</b> firms in Wisconsin and Michigan’s Upper Peninsula, we offer ACKNOWLEDGMENTS the first-ever study of this critical link between the forests and the wood products industry. The following Funding for this study was provided in key findings relate to the business environment, timbe...|$|R
40|$|This paper explores how the FSM is {{attempting}} to revolutionalize software development practices by advocating that all software be free for access, study, modification, and (re) distribution. The FSM also admonishes the use of non-free software as immoral because it prevents its users from learning (about programming, etc.) and 4 prevents developers and users from helping their fellow man (Stallman, 2002; Williams, 2002). In this paper, we show how {{the ideology of the}} FSM influences software development work practices in F/OSS communities and how an occupational community (Trice and Beyer, 1993; Van Maanen and Barley, 1984) of F/OSS developers has emerged as part of this movement. In previous papers, we presented the results of a qualitative study of the methods and social processes used in GNUenterprise (GNUe), a free software development community with the goal of developing a free resource planning system (Elliott and Scacchi, 2003 a; b). We showed how they jointly build community and a web of software system artifacts via instant message (IM) streams using internet relay chat (IRC), text-based records of IRC <b>logs,</b> <b>mailing</b> lists, and summary digests (Kling and Scacchi, 1982; Scacchi, 2002 a; b). We captured the beliefs, values, and norms of the GNUe virtual organizational culture by using a grounded theory approach and by utilizing an organizational culture perspective (Martin, 2002; Schein, 1992; Trice and Beyer, 1993). In this paper, we show how beliefs and values of the FSM are manifested in the norms of GNUe software development practices informal self-management, immediate acceptance of fellow contributors, and open disclosure of all documentation and work transcripts (IRC <b>logs,</b> <b>mailing</b> list archives, summary digests). In addition [...] ...|$|R
30|$|Software {{repositories}} can be {{a valuable}} source of information since they contain (or may allow to extract) information about the technical and social perspectives of a software project, such as sources of developer communications (Genc-Nayebi & Abran, 2016). Mining Software Repositories (MSR) area focuses on uncovering useful information about software by extracting and analyzing data from different software repositories (Ahmed, 2008). The unstructured data in software repositories have also pushed the Software Engineering research community to mine and analyze useful knowledge present in such repositories, i.e. different versioning systems (e.g. Git), archived communications (e.g. <b>mailing</b> lists), chat <b>logs,</b> online forums (e.g. Q&A repositories), mobile app stores (e.g. user reviews on Google Play) and online video-sharing websites (e.g. programming tutorials shared on YouTube) (Ahmad et al., 2018).|$|R
40|$|The {{proliferation}} of open source projects raises {{a number of}} vital economic, social, and software engineering questions that are subject of intense research. Based on experience analyzing numerous open source and commercial projects we propose a set of tools to support extraction and validation of software project data. Such tools would streamline empirical investigation of open source projects and {{make it possible to}} test existing and new theories about the nature of open source projects. Our software includes tools to extract and summarize information from <b>mailing</b> lists, CVS <b>logs,</b> ChangeLog files, and defect tracing databases. More importantly, it cross-links records from various data sources and identifies all contributors for a software change. We illustrate some of the capabilities by analyzing data from Ximian Evolution project. 1...|$|R
40|$|One of {{the most}} {{annoying}} problems on the Internet is spam. To fight spam, many approaches have been proposed over the years. Most of these approaches involve scanning the entire contents of e-mail messages {{in an attempt to}} detect suspicious keywords and patterns. Although such approaches are relatively effective, they also show some disadvantages. Therefore an interesting question is whether {{it would be possible to}} effectively detect spam without analyzing the entire contents of e-mail messages. The contribution of this paper is to present an alternative spam detection approach, which relies solely on analyzing the origin (IP address) of e-mail messages, as well as possible links within the e-mail messages to websites (URIs). Compared to analyzing suspicious keywords and patterns, detection and analysis of URIs is relatively simple. The IP addresses and URIs are compared to various kinds of blacklists; a hit increases the probability of the message being spam. Although the idea of using blacklists is well known, the novel idea proposed within this paper is to introduce the concept of ‘bad neighborhoods’. To validate our approach, a prototype has been developed and tested on our university’s mail server. The outcome was compared to SpamAssassin and <b>mail</b> server <b>log</b> files. The result of that comparison was that our prototype showed remarkably good detection capabilities (comparable to SpamAssassin), but puts only a small load on the mail server...|$|R
40|$|Unsolicited bulk email (spam) {{is used by}} cybercriminals to lure users into scams and {{to spread}} malware infections. Most of these {{unwanted}} messages are sent by spam botnets, which are networks of compromised machines {{under the control of}} a single (malicious) entity. Often, these botnets are rented out to particular groups to carry out spam campaigns, in which similar mail messages are sent to a large group of Internet users in a short amount of time. Tracking the bot-infected hosts that participate in spam campaigns, and attributing these hosts to spam botnets that are active on the Internet, are challenging but important tasks. In particular, this information can improve blacklist-based spam defenses and guide botnet mitigation efforts. In this paper, we present a novel technique to support the identification and tracking of bots that send spam. Our technique takes as input an initial set of IP addresses that are known to be associated with spam bots, and learns their spamming behavior. This initial set is then “magnified ” by analyzing large-scale <b>mail</b> delivery <b>logs</b> to identify other hosts on the Internet whose behavior is similar to the behavior previously modeled. We implemented our technique in a tool, called BOTMAGNIFIER, and applied it to several data streams related to the delivery of email traffic. Our results show {{that it is possible to}} identify and track a substantial number of spam bots by using our magnification technique. We also perform attribution of the identified spam hosts and track the evolution and activity of well-known spamming botnets over time. Moreover, we show that our results can help to improve state-of-the-art spam blacklists. ...|$|R
40|$|While we {{continue}} to see rise in the adoption of agile methods for software development, {{there has been a}} call to study the appropriateness of agile methods in open-source and other emerging contexts. This paper examines Scrum methodology adopted by a large, globally distributed team which builds an open-source electronic medical records platform called OpenMRS. The research uses a mixed method approach, by doing quantitative analysis of source-code, issue tracker as well as community activity (IRC <b>logs,</b> <b>Mailing</b> lists, wiki) in pre and post Scrum adoption, covering a period of 4 years. Later we conducted semi-structured interviews with core developers and followed it up with group discussions to discuss the analysis of the quantitative data and get their views on our findings. Since the project is "domain heavy", contributors (developers and implementers) need to have certain health informatics understanding before making significant contributions. This puts knowledge-sharing and "bus factor" as critical points of management for the community. The paper presents ideas about a tailored Scrum methodology that might better suited for open-source communities to improve knowledge-sharing and community participation, instead of just agilit...|$|R
40|$|Media {{information}} management {{should be considered}} from all professional perspectives through virtual communities of users (VCU) made up of researchers, technical experts, critics, information and media professionals, students, etc. Although a new virtual community of {{information management}} has already been set up, {{in the opinion of}} the authors it is too broad to allow for sufficient attention to different areas of specialisation. The present article presents the case of an existing virtual community of users of audio-visual information, covering both cinematography and TV. This VCU is characterised by multimedia contents, interactivity, and the integration of distinctive work areas, such as a documentation service, web <b>log,</b> <b>mail</b> list,forum, users’ contributions, and periodic chats. Two streaming servers are being used to produce and broadcast multimedia content: one located at RedIRIS [the Spanish National Research Network] and the other at the Computer Centre of the Univ. Complutense de Madrid (UCM). The VCU has its origins in a broader framework, proposed by the Library and Information Science Department of the UCM, whose aim is to establish a Spanish and Iberoamerican multimedia information management network...|$|R
40|$|Graduation date: 2013 Free {{and open}} source {{software}} (FOSS) projects primarily rely on the efforts of volunteer contributors from around the world. For this reason, recruiting and retaining contributor {{is vital to the}} sustainability and growth of FOSS projects. This notion became the jumping-off point for this three-part investigation into the cultural structure and social dynamics of the FOSS community. In Chapter 2, we analyzed mailing list discussions initiated by newcomers to a FOSS project and found that receiving timely and supportive responses was positively correlated to newcomers' future participation. In Chapter 3, we examined <b>mailing</b> list subscription <b>logs,</b> and found a disproportional attrition rate among women along every step of the FOSS joining process, further documentation of a well-known lack of gender diversity in FOSS. Finally, in Chapter 4, we examined the current demographic composition of the FOSS community, and the lack of diversity in a more general sense, as well as the mechanisms that perpetuate this situation. We present two theoretical frameworks [...] group faultlines theory and critical systems thinking, that can help explain this current homogeneity, as well as guide future research...|$|R
30|$|It is {{important}} to note that ISO 25010 can serve as standard for OSS only in terms of product quality and quality in use. It does not address unique characteristics of OSS such as the community. A key distinguishing feature of OSS is that it is built and maintained by a community (Haaland et al. 2010). The quality of this community also determines the quality of the OSS (Samoladas et al. 2008). From the literature, community related quality characteristics include (Soto and Ciolkowski 2009): maintenance capacity, sustainability, and process maturity. Maintenance capacity refers to the number of contributors to an OSS project and the amount of time they are willing and able to contribute to the development effort as observed from versioning <b>logs,</b> <b>mailing</b> lists, discussion forums and bug report systems. Furthermore, sustainability refers to the ability of the community to grow in terms of new contributors and to regenerate by attracting and engaging new members to take the place of those leaving the community. In addition, process maturity refers to the adoption and use of standard practices in the development process such as submission and review of changes, peer review of changes, provision of a test suite, and planned releases.|$|R
40|$|It is {{frequently}} suggested that work {{groups that have}} computer technology to support activities such as text editing, data manipulation, and communication develop systematically different structures and working processes from groups that rely on more conventional technologies such as memos, phone calls, and meetings. However, cross-sectional or retrospective research designs do not allow this hypothesis to be tested with much power. This field experiment created two task forces, each composed equally of recently retired employees and employees still at work but eligible to retire. They were given the identical tasks of preparing reports for their company on retirement planning issues, but they {{were randomly assigned to}} different technology conditions. One group had full conventional office support; the other had, in addition, networked microcomputers with electronic mail and routine office software. Structured interviews were conducted four times during the year-long project; in addition, electronic <b>mail</b> activity was <b>logged</b> in the on-line group. Although both groups produced effective reports, the two differed significantly in the kind of work they produced, the group structures that emerged, and evaluations of their own performance. Although the standard group was largely dominated by the employees through the extensive reliance on informal meetings, the electronic technology used by the other task force allowed the retirees to exercise primary leverage. We conclude that use of computer support for cooperative work results in both quantitative and qualitative changes but that effective participation in such electronically supported groups requires significant invest...|$|R
40|$|More {{and more}} {{communities}} use internet based services and infrastructure for communication and collaboration. All these activities leave digital traces {{that are of}} interest for research as real world data sources that can be processed automatically or semi-automatically. Since productive online communities (such as open source developer teams) tend to support the establishment of ties between actors who work on or communicate about the same or similar objects, social network analysis is a frequently used research methodology in this field. A typical application of Social Network Analysis (SNA) techniques is the detection of cohesive subgroups of actors (also called “community detection”. We were particularly interested in such methods that allow {{for the detection of}} overlapping clusters, which is the case with the Clique Percolation Method (CPM) and Link Community detection (LC). We have used these two methods to analyze data from some open source developer communities (<b>mailing</b> lists and <b>log</b> files) and have compared the results for varied time windows of measurement. The influence of the time span of data capturing/aggregation can be compared to photography: A certain minimal window size is needed to get a clear image with enough “light” (i. e. dense enough interaction data), whereas for very long time spans the image will be blurred because subgroup membership will indeed change during the time span (corresponding to a moving target). In this sense, our target parameter is “resolution” of subgroup structures. We have identified several indicators for good resolution. In general, this value will vary for different types of communities with different communication frequency and behavior. Following our findings, an explicit analysis and comparison of the influence of time window for different communities may be used to better adjust analysis techniques for the communities at hand...|$|R

