1|8915|Public
30|$|<b>Multiple</b> <b>image</b> <b>display</b> with {{on-the-fly}} rough {{registration of}} any image whose {{coordinate reference system}} is understood by Orfeo ToolBox, which include both ground projected and sensor geometry images.|$|E
40|$|Various {{examples}} are provided for generalized internal multiple imaging (GIMI). In one example, among others, {{a method includes}} generating a higher order internal <b>multiple</b> <b>image</b> using a background Green's function and rendering the higher order internal <b>multiple</b> <b>image</b> for presentation. In another example, a system includes a computing device and a generalized internal multiple imaging (GIMI) application executable in the computing device. The GIMI application includes logic that generates a higher order internal <b>multiple</b> <b>image</b> using a background Green's function and logic that renders the higher order internal <b>multiple</b> <b>image</b> for <b>display</b> on a display device. In another example, a {{non-transitory computer readable medium}} has a program executable by processing circuitry that generates a higher order internal <b>multiple</b> <b>image</b> using a background Green's function and renders the higher order internal <b>multiple</b> <b>image</b> for <b>display</b> on a display device...|$|R
40|$|The {{display is}} the last {{component}} in a chain of activity from image acquisition, compression, coding transmission and reproduction of 3 -D images through to the display itself. There are various schemes for 3 -D display taxonomy; the basic categories adopted for this paper are: holography where the image is produced by wavefront reconstruction, volumetric where the image is produced within a volume of space and <b>multiple</b> <b>image</b> <b>displays</b> where two or more images are seen across the viewing field. In an ideal world a stereoscopic <b>display</b> would produce <b>images</b> in real time that exhibit all {{the characteristics of the}} original scene. This would require the wavefront to be reproduced accurately, but currently this can only be achieved using holographic techniques. Volumetric displays provide both vertical and horizontal parallax so that several viewers can see 3 -D images that exhibit no accommodation/convergence rivalry. <b>Multiple</b> <b>image</b> <b>displays</b> fall within three fundamental types: holoform in which a large number of views give smooth motion parallax and hence a hologram-like appearance, multiview where a series of discrete views are presented across viewing field and binocular where only two views are presented in regions that may occupy fixed positions or follow viewers' eye positions by employing head tracking. Holography enables 3 -D scenes to be encoded into an interference pattern, however, this places constraints on the display resolution necessary to reconstruct a scene. Although holography may ultimately offer the solution for 3 DTV, the problem of capturing naturally lit scenes will first have to be solved and holography is unlikely to provide a short-term solution due to limitations in current enabling technologies. Liquid crystal, digital micromirror, optically addressed liquid crystal and acoustooptic spatial light modulators (SLMs) have been employed as suitable spatial light modulation devices in holography. Liquid crystal SLMs are generally favored owing to the c- - ommercial availability of high fill factor, high resolution addressable devices. Volumetric displays provide both vertical and horizontal parallax and several viewers are able to see a 3 -D image that exhibits no accommodation/convergence rivalry. However, the principal disadvantages of these <b>displays</b> are: the <b>images</b> are generally transparent, the hardware tends to be complex and non-Lambertian intensity distribution cannot be <b>displayed.</b> <b>Multiple</b> <b>image</b> <b>displays</b> take many forms and it is likely that {{one or more of these}} will provide the solution(s) for the first generation of 3 DTV displays...|$|R
40|$|Abstract—The {{display is}} the last {{component}} in a chain of activity from image acquisition, compression, coding transmission and reproduction of 3 -D images through to the display itself. There are various schemes for 3 -D display taxonomy; the basic categories adopted for this paper are: holography where the image is produced by wavefront reconstruction, volumetric where the image is produced within a volume of space and <b>multiple</b> <b>image</b> <b>displays</b> where two or more images are seen across the viewing field. In an ideal world a stereoscopic <b>display</b> would produce <b>images</b> in real time that exhibit all {{the characteristics of the}} original scene. This would require the wavefront to be reproduced accurately, but currently this can only be achieved using holographic techniques. Volumetric displays provide both vertical and horizontal parallax so that several viewers can see 3 -D images that exhibit no accommodation/convergence rivalry. Multiple imag...|$|R
40|$|If a {{refreshed}} {{light emitting}} diode (LED) display is moved relative to the observer with such severity that the display cannot be fixated, <b>multiple</b> <b>images</b> of the <b>display</b> may appear. To determine the threshold refresh rate of this perceptual phenomenon, subjects evaluated the relative multiple imaging ofnine LED refresh rates while under whole body vibration...|$|R
40|$|Abstract Image preview is a {{convenient}} way to browse large or <b>multiple</b> <b>images</b> on small <b>displays.</b> However, current signal-level image resampling algorithms may remove many features {{of interest in}} the preview image. In this paper, we propose perceptual image preview which retains more perceptual features such that users can inspect features of interest by viewing the preview image only and without zooming in. This technology has two components, structure enhancement and perceptual feature visualization. Structure enhancement enhances the image structure while suppressing subtle details using a gradient modulation method, thus making the succedent perceptual features more apparent. For perceptual feature visualization, features of interest detected in the picture is visualized on the structure enhanced preview image. We demonstrate with two examples of most commonly used image quality features, image blur and noise. The effectiveness of the proposed method is validated by experimental results...|$|R
40|$|<b>Images</b> <b>displayed</b> by {{projection}} {{systems can}} experience geometric distortions. These distortions can {{be compensated for}} by electronic correction, also called image warping. When the image that will be displayed is composed of several input sources, the different image layers have to be corrected independently {{from each other in}} order to achieve optimal image quality. A VLSI architecture for independent electronic correction of <b>multiple</b> <b>image</b> layers is proposed...|$|R
30|$|Hiperwall {{is a high}} performance, high {{resolution}} visualization system. Hiperwall’s visualization system software architecture applies parallel processing techniques to overcome the performance limitations typically associated with the <b>display</b> of large <b>multiple</b> <b>images</b> on <b>multiple</b> <b>display</b> devices (flat-panel tiles) simultaneously. Hiperwall is a collaborative visualization platform {{that is designed to}} visualize enormous data sets and allows viewers to see the details, while retaining the context of the surrounding data. This allows a group of scientists/researchers/students to collaborate and share detailed information. The Hiperwall system allows the user to display a wide variety of high-resolution 2 D and 3 D images, animations, movies, and time-varying data in real time all at once on multiple display-tiles that can be configured according {{to the needs of the}} user. Users can project a single image across the entire display area or many different images simultaneously. Hiperwall’s middleware even allows researchers in geographically diverse locations to collaborate on Big Science Experiments that generate Big Data.|$|R
40|$|Currently, many {{low cost}} {{computers}} can only simultaneously display {{a palette of}} 256 colors. However, this palette is usually selectable from a very large gamut of available colors. For many applications, this limited palette size imposes a significant constraint on the achievable image quality. In this paper, we propose a method for designing an optimized universal color palette for use with halftoning methods such as error di#usion. The advantage of a universal color palette {{is that it is}} fixed and therefore allows <b>multiple</b> <b>images</b> to be <b>displayed</b> simultaneously. In order to design the palette, we employ a new vector quantization method known as sequential scalar quantization (SSQ) to allocate the colors in a visually uniform color space. The SSQ method achieves near optimal allocation, but may be e#ciently implemented using a series of look up tables. When used with error di#usion, SSQ adds little computational overhead, and may be used to minimize the visual error in an opponent colo [...] ...|$|R
30|$|The 8 display node PCs in {{the rack}} (labeled as DN A 1 through DN D 2) {{as shown in}} Fig. 3.F. 1 are {{connected}} to the Hiperwall display-tiles (one display node for each display tile). Each display node consists of a display device that is driven by a PC (mini-tower or rack-mount) running the Hiperwall software. The Hiperwall software runs as an application operating on a standard PC connected via a standard 1 Gbps network switch. Hiperwall’s tiled display system software architecture applies parallel processing techniques to overcome the performance limitations typically associated with the <b>display</b> of large <b>multiple</b> <b>images</b> on <b>multiple</b> <b>display</b> devices (flat-panel tiles) at once. A display node software receives content over a 1 Gbps network switch from a sender or a streamer node and projects it on the display wall tile via a HDMI cable. All display-node computers work in parallel, thus giving flexibility and scalability while also allowing the user to place contents on one or more multiple display-tiles all at once.|$|R
40|$|We {{address the}} problem of {{rendering}} a scene in one location and displaying it in another, remote, location, where the remote user controls the viewpoint. Network latency makes it impossible to accept a new viewpoint, render the complete scene, and return the generated image to the user fast enough to provide immersion. Our render server constructs images and depth maps ("depth images") and sends them over the network to a remote client. The client warps and composites several depth images to form the <b>image</b> <b>displayed</b> to the user. Using <b>multiple</b> <b>images</b> greatly reduces the visual artifacts produced by image warping. The client runs entirely in software and <b>displays</b> <b>images</b> at 6 frames per second...|$|R
3000|$|... (t) be {{a set of}} <b>images</b> <b>displayed</b> to {{the user}} at each {{iteration}} t and L be the number of <b>images</b> <b>displayed,</b> such that |I [...]...|$|R
40|$|There is {{provided}} a supplementary visual display system (10, 200) {{for use in}} conjunction with a display device (40) including an <b>image</b> <b>display</b> region (50) for presenting images to a viewer (15). The system (10, 200) comprises: (a) one or more illumination sources (100 a, 100 b, 110, 120) which at least partially peripherally surround the <b>image</b> <b>display</b> region (50) and/or project illumination radiated therefrom so as to illuminate a region visually appearing to the viewer (15) to at least partially peripherally surround the <b>image</b> <b>display</b> region (50);; (b) monitoring components for monitoring audio program content and/or intensity and/or color and/or depth information in the entire <b>image</b> <b>display</b> region (50) or in one or more sub-regions (300, 310, 320, 330) of the <b>image</b> <b>display</b> region (50) when images are presented thereon and generating corresponding image and/or audio indicative signals: and (c) controlling components (500) for controlling light radiation emitted in use from the one or more illumination sources (100 a, 100 b, 110, 120) in response to {{at least one of the}} image and/or audio indicative signals so as to provide at least a partial spatial extension of the <b>image</b> <b>display</b> region (50) ...|$|R
5000|$|Digital <b>Image</b> <b>Display,</b> Algorithms and Implementation, by Gheorghe Berbecel ...|$|R
5000|$|Toggle between viewing {{websites}} with {{or without}} <b>images</b> <b>displayed</b> ...|$|R
40|$|XvicImage is a {{high-performance}} XWindows (Motif-compliant) user interface widget for <b>displaying</b> <b>images.</b> It handles {{all aspects of}} low-level <b>image</b> <b>display.</b> The fully Motif-compliant <b>image</b> <b>display</b> widget handles the following tasks: (1) <b>Image</b> <b>display,</b> including dithering as needed (2) Zoom (3) Pan (4) Stretch (contrast enhancement, via lookup table) (5) Display of single-band or color data (6) Display of non-byte data (ints, floats) (7) Pseudocolor display (8) Full overlay support (drawing graphics on image) (9) Mouse-based panning (10) Cursor handling, shaping, and planting (disconnecting cursor from mouse) (11) Support for all user interaction events (passed to application) (12) Background loading and <b>display</b> of <b>images</b> (doesn't freeze the GUI) (13) Tiling of images...|$|R
40|$|The {{bidirectional}} microdisplay approach combines organic {{light-emitting diode}} (OLED) <b>image</b> <b>display</b> and silicon complementary metal-oxide-semiconductor image sensing {{in a single}} chip. Its application in smart glasses might enable gaze-controlled interaction. This is to present a new bidirectional OLED microdisplay featuring super video graphics array resolution for both <b>image</b> <b>display</b> and acquisition...|$|R
30|$|These {{results suggest}} that {{providing}} face averages to people that are searching for faces in crowds, for example security and police personnel, may result in better search accuracy. However, because face averages require <b>multiple</b> <b>images</b> to construct them, {{it may be more}} beneficial to give <b>multiple</b> <b>images</b> to officers in the field. Indeed, there may be additional benefits of providing <b>multiple</b> <b>images</b> for face search, as recent work has found that exposure to within-face variability presented across <b>multiple</b> <b>images</b> benefits face matching accuracy (Bindemann & Sandford, 2011; Etchells et al., 2017; Menon et al., 2015 a, 2015 b; White et al., 2014). In the next experiment, we simulate exposure to variability by providing a search template consisting of <b>multiple</b> <b>images</b> of the target to determine whether this also improves search performance.|$|R
5000|$|... #Caption: An <b>image</b> <b>displayed</b> on {{a medical}} image sharing {{platform}} ...|$|R
5000|$|... #Caption: [...] <b>Image</b> <b>Displaying</b> the Serotonin Nerve Pathways in the Brain ...|$|R
5000|$|... #Caption: This <b>image</b> <b>displays</b> the {{login page}} of Daylight Linux Version 2 ...|$|R
50|$|<b>Multiple</b> <b>image</b> super-resolution.|$|R
5000|$|Flicker-free <b>image</b> <b>displaying</b> {{components}} with optimized {{double buffering}} via advanced MicroTiles based repaint optimizer ...|$|R
30|$|The {{amount of}} {{irradiance}} scattering and haze {{depends on the}} unknown scene depth, which makes haze removal complicated. Most haze removal methods require <b>multiple</b> <b>images</b> or additional prior information. The methods in [1, 2] remove haze using <b>multiple</b> <b>images</b> under different degrees of polarization. In [3 – 5], the haze-free image is obtained from <b>multiple</b> <b>images</b> with different weather conditions. By inputting depth prior information or 3 D models, the methods in [6, 7] can also restore haze-free images.|$|R
30|$|Visual {{cryptography}} (VC) is an {{encryption technique}} for hiding a secret image in distributed and shared images (referred to as shares). VC schemes are employed to encrypt <b>multiple</b> <b>images</b> as meaningless, noisy patterns or meaningful <b>images.</b> However, decrypting <b>multiple</b> secret <b>images</b> using a unique share is difficult with traditional VC. We propose {{an approach to}} hide <b>multiple</b> <b>images</b> in meaningful shares. We can decrypt <b>multiple</b> <b>images</b> simultaneously using a common share, which we refer to as a magic sheet. The magic sheet decrypts <b>multiple</b> secret <b>images</b> depending on a given share. The shares are printed on transparencies, and decryption is performed by physically superimposing the transparencies. We evaluate the proposed method using binary, grayscale, and color images.|$|R
25|$|These <b>images</b> <b>display</b> {{frequencies}} of self-reported European American ancestries {{as of the}} 2000 U.S. Census.|$|R
5000|$|Image {{resource}} for website and large <b>image</b> <b>displays</b> with Creative Advertising students photographing for Santos ...|$|R
30|$|In Experiment 3, we {{have found}} that search {{templates}} elicited from <b>multiple</b> <b>images</b> lead to faster and more accurate search than those from face averages. These results extend the findings of studies of unfamiliar face matching (White et al., 2014), where <b>multiple</b> <b>images</b> have been shown to lead to more accurate matching performance than face averages. Although face averages contain the invariant features of a face, it appears that the variance information contained in <b>multiple</b> <b>images</b> produces more robust templates for visual search.|$|R
5000|$|... #Caption: St. Jerome <b>image</b> <b>displayed</b> at {{the main}} altar of the church during his feast day.|$|R
5000|$|... #Caption: [...] InSAR <b>image</b> <b>displaying</b> {{the ground}} {{deformation}} after {{the eruption of}} Calbuco volcano in Chile.|$|R
50|$|The optronic {{equipment}} {{is composed of}} mission interface overshell integrating the optronics, head camera (EBCMOS light intensification technology), <b>image</b> <b>display</b> units (OLED technology) allowing data and icons transmitted on the bus system to be <b>displayed,</b> <b>images</b> and video coming from the weapon or the head camera. The <b>image</b> <b>display</b> unit is fixed to the helmet: its screen can be brought into line with infantryman's eye. When not in use, it can be folded away {{so as not to}} hinder the soldier.|$|R
50|$|Cerebral polyopia is {{most often}} {{associated}} with occipital or temporal lobe lesions, as well as occipital lobe epilepsy. This condition is relatively uncommon, thus further research regarding its causes and mechanism has not been performed. Polyopia can be experienced as partial second or <b>multiple</b> <b>images</b> to either side (or in any eccentricity) of an object at fixation. Polyopia occurs when both eyes are open, or when one eye is open, during fixation on a stimulus. Known cases of polyopia provide evidence that, {{in relation to the}} stimulus at fixation, <b>multiple</b> <b>images</b> can appear at a constant distance in any direction; gaps in portions of an object at fixation can exist; <b>multiple</b> <b>images</b> can be overlayed vertically, horizontally, or diagonally on top of the stimulus; and the <b>multiple</b> <b>images</b> can appear different sizes, alignments, and complexities. The complexity of the stimulus does not appear to affect the clarity of the <b>multiple</b> <b>images.</b> The physical distance of the stimulus from the patient (near or far) also does not seem to affect the presence of multiple images.7 However, if the stimulus is swung or moved, <b>multiple</b> <b>images</b> of that object can either be extinguished or transformed into different objects, depending on the severity of the condition.|$|R
5000|$|... #Caption: When The Land Belonged to God, replica <b>image</b> <b>displayed</b> {{for many}} years in the Montana Senate ...|$|R
40|$|Aim: To {{compare the}} use of film-based periapical radiographs and digital {{panoramic}} <b>images</b> <b>displayed</b> on monitor and glossy paper {{in the assessment of}} the periapical status of the teeth. Methodology: A total of 86 subjects were examined. All participants underwent a full-mouth radiographic survey (14 periapical radiographs) and a digital panoramic radiography. The periapical status of all appraised teeth was assessed. Results: Periapical radiographs allowed the assessment of the periapical status of a significantly higher percentage of teeth (87. 4 %) Digital radiography had a significantly reduced potential to allow assessment of the periapical status (p< 0. 01). Only 58. 0 % and 34. 3 % of teeth could be appraised using digital panoramic <b>images</b> <b>displayed</b> on monitor and glossy paper respectively (p< 0. 01). The total percentage of teeth with periapical pathosis was four-fold higher when assessed with digital panoramic <b>images</b> <b>displayed</b> on glossy paper compared with periapical radiographs (p< 0. 01). Conclusions: Periapical radiographs allowed the assessment of a significantly higher percentage of teeth when comparing to digital radiography, which had a significantly lower potency in the assessment of periapical status of the teeth. Digital panoramic <b>images</b> <b>displayed</b> on a monitor resulted in a significantly higher percentage of appraised teeth compared to digital <b>images</b> <b>displayed</b> on glossy paper. Apical periodontitis was scored more often on paper than on screen, and more often on screen than in periapical radiographs...|$|R
5000|$|... #Caption: This <b>image</b> <b>displays</b> a dense cloud {{pattern and}} arcing band of convection, {{indicating}} a young, developing cyclone.|$|R
50|$|Ability to {{simultaneously}} zoom and pan <b>multiple</b> <b>images.</b>|$|R
