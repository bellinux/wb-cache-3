0|10000|Public
40|$|National audienceThe aim of {{this article}} is to create a unique medical record {{structure}} from the <b>metabase</b> <b>of</b> any medical record. The work proposes the design of transformation algorithms which consists in translating the legacy relational database (RDB) into a unique medical record structure by analysing the correlation between the legacy RDB keys and the classification of the relations into four types : base relation, dependent relation, inheritance relation and composite relation...|$|R
5000|$|IIS 6.0 Metabase Auditing: Allowing the {{tracking}} <b>of</b> <b>metabase</b> edits.|$|R
40|$|A {{system and}} method for {{creating}} a database <b>of</b> metadata (<b>metabase)</b> <b>of</b> a variety of digital media content, including TV and radio content delivered on Internet. This semantic-based method captures and enhances domain or subject specific metadata of digital media content, including the specific meaning and intended use of original content. To support semantics, a WorldModel is provided that includes specific domain knowledge, ontologies {{as well as a}} set of rules relevant to the original content. The metabase may also be dynamic in that it may track changes to the any variety of accessible content, including live and archival TV and radio programming...|$|R
50|$|MetaBase is a user-contributed {{database}} of biological databases, listing all the biological databases currently {{available on the}} internet. The initial release <b>of</b> <b>MetaBase</b> was derived entirely from {{the content of the}} Nucleic Acids Research (NAR) 2007 Database Issue. MetaBase is a wiki, using the MediaWiki software as well as the Semantic MediaWiki extension.|$|R
5000|$|Prior to IIS 7, Microsoft's Internet Information Services stores its {{information}} in an internal database called the MetaBase. The metabase is an inheritable, hierarchical database {{that allows for}} configuration of HTTP/HTTPS, FTP, SMTP, and NNTP at the server, the site, or the folder or file level. Different versions of IIS use different formats; prior to IIS version 6 this was always a proprietary format, whereas with 6.0 and later the data is stored in XML files. The <b>metabase</b> consists <b>of</b> two files, MetaBase.xml and MBSchema.xml, stored in the [...] directory. The metabase periodically gets backed up to the [...] subdirectory.|$|R
40|$|Abstract. Our {{research}} and development activities in digital libraries raised relevant features in supporting Web information integration. Underlain by an in house multi-agent based architecture, the main achievements {{so far have been}} prototyped as services: (a) various semantic interoperability niches, by the use of inter-ontological relationships built onto iscapes (a means of specifying information requests using embedded context sensitive information); (b) integrated access to information, by automating <b>metabase</b> (a database <b>of</b> metadata) creation; (c) a framework for creating iscapes and metadata modeling; and (d) information processing, by query planning and cost modeling of Web sources. A real-world application scenario illustrates how geographical and environmental Web-based information systems can benefit from appropriating these facilities...|$|R
40|$|In {{this paper}} we propose a new {{technique}} for processing the non state scales quantification questions. The method, AWMK (answering with metabase and knowledge base), handles heterogeneous information from a large data source which is scattered into several tabulated files. AWMK makes use of our new concept, namely, metabase. A metabase is a "rich" indexed file to facilitate the retrieval of information from the knowledge base and tabulated files. The architecture AWMK makes use <b>of</b> <b>metabase,</b> knowledge base system, database, decoder, encoder, lexicon and accommodator. The system that incorporates different components of AWMK is described in detail. As a result of this investigation, AWMK is applied to a real-world problem, the interpretation of laser-material experiments, this without using a database management system...|$|R
30|$|For {{modeling}} IS, we generalize {{the concept}} <b>of</b> <b>data</b> models. <b>Data</b> models consist <b>of</b> collections (<b>of</b> <b>data)</b> {{so that each}} collection has gotten a name. The collections are set <b>of</b> <b>data</b> or multi-set (bag) <b>of</b> <b>data</b> <b>of</b> <b>data</b> types with well-defined properties and structure; the most typical representation <b>of</b> <b>data</b> model is either relational data model or object-relational data model. The instances <b>of</b> <b>data</b> types make up finite subsets of potential dataset.|$|R
40|$|Problems <b>of</b> <b>data</b> {{processing}} {{from the}} different sources are analyzed. The formal model of date space and operations on it are described. It is shown that algebraic systems <b>of</b> <b>data</b> space and data warehouses are subclasses of algebraic system <b>of</b> ?<b>data</b> space? class. The features <b>of</b> <b>data</b> integration from different sources are determined. The scheme <b>of</b> <b>data</b> integration and means <b>of</b> <b>data</b> exchange is developed. ???????????????? ???????? ????????? ?????? ? ????????? ??????????. ????????? ?????????? ?????? ???????????? ?????? ? ??????? ???????? ??? ???. ????????, ??? ?????????????? ??????? ???? ?????? ? ????????? ?????? ???????? ??????????? ?????????????? ??????? ?????? ????????????? ???????. ?????????? ??????????? ?????????? ?????? ? ?????? ??????????. ??????????? ????? ?????????? ?????? ? ??????? ?????? ???????...|$|R
50|$|According to the Inmon school <b>of</b> <b>data</b> warehousing, {{tradeoffs}} inherent {{with data}} marts include limited scalability, duplication <b>of</b> <b>data,</b> data inconsistency with other silos of information, and inability to leverage enterprise sources <b>of</b> <b>data.</b>|$|R
30|$|TB and AM: design <b>of</b> the study, <b>data</b> acquisition, {{analysis}} and interpretation <b>of</b> <b>data,</b> drafting <b>of</b> manuscript. AB and DB: <b>data</b> acquisition, analysis <b>of</b> <b>data,</b> and drafting <b>of</b> manuscript. FBB: statistical analysis, analysis <b>of</b> <b>data</b> and critical revision. DA: interpretation <b>of</b> <b>data,</b> drafting <b>of</b> manuscript. All authors read and approved the final manuscript.|$|R
5000|$|Data field - Some {{documentation}} {{recommends a}} maximum of 32 bytes <b>of</b> <b>data</b> (64 hex characters) in this field. [...] The minimum amount <b>of</b> <b>data</b> for S0/S1/S2/S3 records is zero. The maximum amount <b>of</b> <b>data</b> varies {{depending on the size}} of the address field. Since the Byte Count field can't be higher than 255 (0xFF), then the maximum number <b>of</b> bytes <b>of</b> <b>data</b> is calculated by 255 minus (1 byte for checksum field) minus (number of bytes in the address field). S0/S1 records support up to 252 bytes <b>of</b> <b>data.</b> S2 record supports up to 251 bytes <b>of</b> <b>data.</b> S3 record supports up to 250 bytes <b>of</b> <b>data.</b>|$|R
30|$|Enterprise Control Language was {{specifically}} designed for manipulation of large amounts <b>of</b> <b>data.</b> It enables implementation <b>of</b> <b>data</b> intensive applications with complex data-flows and huge volumes <b>of</b> <b>data.</b>|$|R
30|$|KS {{treated the}} patient, {{performed}} the acquisition and analysis <b>of</b> <b>data,</b> {{and wrote the}} manuscript. YA, TH, TO, and NU treated the patient and performed the acquisition <b>of</b> <b>data.</b> NA, HI, and SN performed the preoperative examination and analysis <b>of</b> <b>data.</b> KN performed the histological examination and analysis <b>of</b> <b>data.</b> JF performed the operation, analysis <b>of</b> <b>data,</b> and total organization of writing the manuscript. All authors read and approved the final manuscript.|$|R
5000|$|Identification <b>of</b> <b>data</b> {{relationships}} as part <b>of</b> <b>data</b> lineage analysis ...|$|R
40|$|Large {{gradient}} seebeck coefficient measurement {{computer program}} gathers many channels <b>of</b> <b>data,</b> performs analysis, and plots each set <b>of</b> <b>data</b> simutaneously. User can modify code to alter number <b>of</b> channels <b>of</b> <b>data</b> collected and sampling rate and equations that process data. Written in HP Basic. Program also adaptable to other types <b>of</b> <b>data...</b>|$|R
3000|$|The number <b>of</b> <b>data</b> {{forwarded}} in a node affects {{its energy}} consumption. The more data forwarded by a given node, the greater its energy consumption. Therefore, {{in order to}} increase the network lifetime, it is necessary to reduce the maximum amount <b>of</b> <b>data</b> forwarded by the nodes in the network. The amount <b>of</b> <b>data</b> forwarded by the node is usually composed of two parts: the amount <b>of</b> <b>data</b> generated by itself and the amount <b>of</b> <b>data</b> generated by other nodes. Therefore, reducing the amount <b>of</b> <b>data</b> generated by itself and the amount <b>of</b> <b>data</b> sent by other nodes can reduce the maximum energy consumption. The set of all nodes in the network is defined as S[*]=[*]{ 1,[*] 2,[*]⋯,[*]N}, the network lifetime is denoted by l, and the amount <b>of</b> <b>data</b> forwarded by each node is Di. We have [...]...|$|R
40|$|The {{present study}} was {{conducted}} to search 200 million digits of π and 1 million digits of e for some pieces of numerically expressed information on ruminant agriculture. The results obtained were as follows. Pieces of numerically expressed information that were found in digits of π were as follows: (1) a string <b>of</b> <b>data</b> on weather condition, (2) a string <b>of</b> <b>data</b> on forage production related to growth days, (3) a string <b>of</b> <b>data</b> on correlation analysis between digestibility and lignin content of forages, (4) a string <b>of</b> <b>data</b> on digestibility improvement by ammonia treatment, (5) a string <b>of</b> <b>data</b> on silage fermentation characteristics of forages, (6) a string <b>of</b> <b>data</b> on forage protein degradation in the rumen, (7) a string <b>of</b> <b>data</b> on basic growth analysis of ruminants, (8) a string <b>of</b> <b>data</b> on economic aspects of ruminant agriculture, (9) a string <b>of</b> <b>data</b> on complementary bases related to DNA structure, (10) a string <b>of</b> <b>data</b> on bases for primers related to the detection study on rumen microbes. Pieces of numerically expressed information that were found in digits of e were as follows: (11) a string <b>of</b> <b>data</b> on bases encoding amino acids. It was suggested that some pieces of numerically expressed information on ruminant agriculture were found in digits ofπ and e...|$|R
5000|$|... a {{description}} of the category or categories <b>of</b> <b>data</b> subject and <b>of</b> the <b>data</b> or categories <b>of</b> <b>data</b> relating to them; ...|$|R
40|$|In {{the paper}} the authors discuss a rather new field <b>of</b> quality <b>of</b> <b>data.</b> The {{introductory}} chapters discusses {{decision making and}} importance <b>of</b> <b>data</b> in the process. Further, definitions <b>of</b> quality and <b>data</b> related to the quality <b>of</b> <b>data</b> are considered and proposed. As a general discussion <b>of</b> quality <b>of</b> <b>data</b> is rather difficult, the quality <b>of</b> register <b>data</b> is discussed further, proposing a definition and an approach to be adopted to at least estimate quality <b>of</b> <b>data.</b> Based on that, {{an example of a}} method of estimate of the quality <b>of</b> <b>data</b> <b>of</b> the Slovenian Business Register is shown. The final part of the paper contains a discussion and recommendations about a possible future approach to this issue. CES/SEM. 46 /WP. ...|$|R
50|$|The book {{therefore}} carefully introduces {{more and}} more complex kinds <b>of</b> <b>data,</b> which sets it apart from every other introductory programming book. It starts from atomic forms <b>of</b> <b>data</b> and then progresses to compound forms <b>of</b> <b>data,</b> including data that can be arbitrarily large. For each kind <b>of</b> <b>data</b> definition, the book explains how to organize the program in principle, thus enabling a programmer who encounters a new form <b>of</b> <b>data</b> to still construct a program systematically.|$|R
40|$|The {{particularities}} <b>of</b> <b>data</b> storing in multilevel data storages under ?big data? {{conditions are}} considered. For multilevel data storages the task <b>of</b> <b>data</b> blocks optimal allocation with {{taking in consideration}} technical characteristics of individual storage levels is formulated. Three models for different variants <b>of</b> <b>data</b> storage types, user requests and expenditures minimization policies are proposed. Methods of solving these problems were proposed. The variant of genetic algorithm to determine the optimal allocation <b>of</b> <b>data</b> blocks onto different levels <b>of</b> <b>data</b> storage is developed...|$|R
5000|$|A {{data model}} {{explicitly}} determines the structure <b>of</b> <b>data.</b> Typical applications <b>of</b> <b>data</b> models include database models, design of information systems, and enabling exchange <b>of</b> <b>data.</b> Usually data models are specified in a data modeling language.3 ...|$|R
40|$|Privacy {{preserving}} {{data mining}} techniques are introduced {{with the aim}} of extract the relevant knowledge from the large amount <b>of</b> <b>data</b> while protecting the sensible information at the same time. The success <b>of</b> <b>data</b> mining relies on the availability <b>of</b> high quality <b>data.</b> To ensure quality <b>of</b> <b>data</b> mining, effective information sharing between organizations becomes a vital requirement in today’s society. Privacy preserving data mining deals with hiding an individual’s sensitive identity without sacrificing the usability <b>of</b> <b>data.</b> Whenever we are concerning with data mining, Security is measure issue while extracting data. Privacy Preserving Data Mining concerns with the security <b>of</b> <b>data</b> and provide the data on demand as well as amount <b>of</b> <b>data</b> that is required...|$|R
40|$|Practitioners and {{researchers}} in the domain <b>of</b> <b>data</b> warehousing are primarily focussing on technical aspects <b>of</b> <b>data</b> warehouse systems. Organizational issues are often neglected although several studies about critical success factors <b>of</b> <b>data</b> warehouse projects emphasize their importance. Thus, {{the aim of this}} paper is to provide deeper insights in organizational issues <b>of</b> <b>data</b> warehousing. The paper focuses on structural aspects <b>of</b> <b>data</b> warehouse organizations by presenting results of an exploratory survey conducted in 2003. The study shows a trend towards organizational challenges, problems in the structural dimension <b>of</b> <b>data</b> warehouse organizations and what kind <b>of</b> documentation about <b>data</b> warehouse departments exists. The findings of the study are discussed and implications for research and practice are highlighted...|$|R
5000|$|... 4 <b>of</b> the 12 <b>data</b> zones {{making up}} Govanhill {{are within the}} bottom 15% <b>of</b> <b>data</b> zones in Scotland. One <b>of</b> these <b>data</b> zones {{occupies}} the bottom 5% <b>of</b> <b>data</b> zones in Scotland ...|$|R
3000|$|... where P is the {{precision}} of the numerical representation, and N {{is defined as the}} number <b>of</b> <b>data</b> transmitted. Since {{the precision}} is usually constant, the amount <b>of</b> <b>data</b> transmitted could be derived {{in terms of the number}} <b>of</b> <b>data</b> transmitted. The numbers <b>of</b> <b>data</b> <b>of</b> the belief and the target motion model for the prediction process are n [...]...|$|R
40|$|Abstract. 3 -ary {{vector data}} {{definition}} was researched. 3 -ary vector data definition was expanded. Data items were defined by 4 -ary vector in dataspace. Correlation <b>of</b> <b>data</b> for object {{was defined by}} weight. A library dataspace model was designed. Weights <b>of</b> <b>data</b> were verified by using articles in library. The result proves weight <b>of</b> <b>data</b> can measure the correlation <b>of</b> <b>data...</b>|$|R
40|$|In {{this paper}} {{we present a}} survey <b>of</b> <b>data</b> {{versioning}} techniques. A version <b>of</b> a <b>data</b> object corresponds to a particular snapshot of the object's state. Versioning <b>of</b> <b>data</b> objects is an effective mechanism for tolerating failures, errors and intrusions, {{as well as for}} analysis <b>of</b> <b>data</b> modification history. As the per-byte disk storage cost drops precipitously and the relative financial penalty <b>of</b> <b>data</b> loss increases substantially in recent years, application <b>of</b> <b>data</b> versioning techniques has evolved from user-level source code/document control and enterprise backup tools, to single-assignment file systems and storage servers. There are three [...] ...|$|R
50|$|Several {{standards}} {{exist for}} the secure removal <b>of</b> <b>data</b> and the elimination <b>of</b> <b>data</b> remanence.|$|R
40|$|The {{existing}} {{surface roughness}} standards comprise only two dimensions. However, the real roughness {{of the surface}} is 3 D (three-dimensional). Roughness parameters of the 3 D surface are also important in analyzing the mechanics of contact surfaces. Problems of mechanics of contact surfaces are related to accuracy of 3 D surface roughness characteristic. One {{of the most important}} factors for 3 D characteristics determination is the number <b>of</b> <b>data</b> points per* mdy axes. With number <b>of</b> <b>data</b> points we understand its number in cut-off length. Number <b>of</b> <b>data</b> points have substantial influence on the accuracy of measurement results, measuring time and size <b>of</b> output <b>data</b> file (especially along they-axis direction, where number <b>of</b> <b>data</b> points are number of parallel profiles). Number <b>of</b> <b>data</b> points must be optimal. Small number <b>of</b> <b>data</b> points lead to incorrect results and increase distribution amplitude, but too large number <b>of</b> <b>data</b> points do not enlarge range of fundamental information, but substantially increase measuring time. Therefore, we must find optimal number <b>of</b> <b>data</b> points per each surface processing method...|$|R
50|$|In addition, after {{separation}} <b>of</b> <b>data</b> and metadata, {{data and}} metadata can be processed independently in different hosts without occupying bandwidth <b>of</b> <b>data</b> channel, which {{can improve the}} concurrency <b>of</b> <b>data</b> and metadata to further enhance file system performance.|$|R
25|$|The EnKF version {{described}} here involves randomization <b>of</b> <b>data.</b> For filters without randomization <b>of</b> <b>data,</b> see.|$|R
5000|$|Data Context: Facilitates {{discovery}} <b>of</b> <b>data</b> {{through an}} approach to the categorization <b>of</b> <b>data</b> according to taxonomies. Additionally, enables the definition <b>of</b> authoritative <b>data</b> assets within a COI.|$|R
40|$|A {{method of}} {{representing}} a group <b>of</b> <b>data</b> items comprises, {{for each of}} a plurality <b>of</b> <b>data</b> items in the group, determining the similarity between said data item and each of a plurality <b>of</b> other <b>data</b> items in the group, assigning a rank to each pair {{on the basis of}} similarity, wherein the ranked similarity values for each of said plurality <b>of</b> <b>data</b> items are associated to reflect the overall relative similarities <b>of</b> <b>data</b> items in the group...|$|R
30|$|Data set feature {{processing}} scheme includes feature collection, feature {{conversion and}} reservation. The filter feature <b>of</b> <b>data</b> set would be pre-fetched. The classification characteristics <b>of</b> <b>data</b> set {{could be obtained}} based on the classification accuracy <b>of</b> <b>data</b> set. According to the characteristics <b>of</b> the <b>data</b> set, the crowd filter would select the appropriate crowd incentive strategy. Based on the complexity characteristics <b>of</b> the <b>data</b> set classification, {{the transformation of the}} subset <b>of</b> the <b>data</b> set would be completed.|$|R
