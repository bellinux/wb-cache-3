3|23|Public
40|$|Deteriorated {{equipment}} has {{a significant}} impact on the product quality and maintenance policies. In this paper, we present a decision-making architecture to determine maintenance and product dispatching policies based on condition-monitoring information and the relationship between machine degradation and associated product quality. We use a Markov decision process for the long-term decision making and integer programming for the short-term decision making with a multi-product, <b>multi-station</b> <b>system.</b> We demonstrate the advantage of the proposed approach by comparing the proposed policy with traditional decision-making approaches. Furthermore, we illustrate the improvement of the proposed policy over the current usage-based maintenance policy with a semiconductor manufacturing process application. close...|$|E
40|$|The {{projected}} emittance (2 D) and {{the intrinsic}} emittance (4 D) reconstruction method {{by using the}} beam size measurements at different locations is analyzed in order to study analytically the conditions of solvability of the systems of equations involved in this process. Some conditions are deduced and discussed, and general guidelines about {{the locations of the}} measurement stations have been obtained to avoid unphysical results. The special case of the multi-Optical Transition Radiation system (m-OTR), made of four measurement stations, in the Extraction Line (EXT) of Accelerator Test Facility 2 (ATF 2) has been simulated in much detail and compared with measurements. Finally a feasibility study of a <b>multi-station</b> <b>system</b> for fast transverse beam size measurement, emittance reconstruction and coupling correction in the Ring to Main Linac (RTML) of International Linear Collider (ILC) Diagnostic sections of the RTML has been discussed in detail...|$|E
40|$|This paper {{considers}} {{the problem of}} evaluating and benchmarking process design configuration in a multi-station assembly process. We focus on the unique challenges brought by the <b>multi-station</b> <b>system,</b> namely, (1) a system level model to characterize the variation propagation in the entire process, and (2) the necessity to describe the system response to variation inputs at both global (system level) and local (station level and single fixture level) scales. State space representation is employed to recursively describe the propagation of variation in such a multi-station process, incorporating process design information such as fixture locating layout at individual stations and station-to-station locating layout change. Following the sensitivity analysis in control theory, a group of hierarchical sensitivity indices is defined and {{expressed in terms of}} the system matrices in the state space model, which are determined by the given process design configuration. Implication of these indices with respect to variation control is discussed and a three-step procedure of applying the sensitivity indices for selecting a better design and prioritizing the critical station/fixture is presented. We illustrate the proposed method using the group of sensitivity indices in design evaluation of the assembly process of a SUV (Sport Utility Vehicle) side panel...|$|E
40|$|Today’s {{automotive}} industries require quick ramp-up {{in order}} to shorten the time to market and fulfill greater demand for product variety. Since, dimensional tolerance problems {{are one of the}} main causes for delay during ramp-up in multi-station assembly systems; hence, rapid diagnosis of faults contributing to dimensional errors is of significant concern. This paper presents an agent-based simulation model (ABSM) which integrates model-based and data-based diagnostics for fault diagnosis and correction in multi-station assembly processes. The fault causing variation sources, their effects on dimensional accuracy, diagnosis from sensors data and corrective actions in <b>multi-station</b> assembly <b>systems</b> are simulated using proposed ABSM. A case study has been considered to illustrate the ABSM methodology for fault diagnosis in <b>multi-station</b> assembly <b>systems...</b>|$|R
40|$|Abstract. For the <b>multi-station</b> {{positioning}} <b>system</b> in {{the field}} of underwater acoustics engineering, different geometric layout means different location precision. The location precision of the system was analyzed. The location precisions of several typical distributions were simulated, and the optimal form of distribution was provided. The rhombus distribution and the “Y ” distribution are two optimal distributions...|$|R
50|$|Experiments are {{conducted}} with research radars, {{such as those}} of the European Incoherent Scatter Scientific Association (EISCAT) with transmitters in Tromsø and on Svalbard. These are used for example to study the processes which cause the aurora. The three-dimensional structure of the aurora is studied with ALIS (Auroral Large Imaging <b>System),</b> a <b>multi-station</b> imaging <b>system</b> which uses tomographic reconstruction techniques, artificial intelligence and advanced IT.|$|R
40|$|Abstract. This paper {{explores the}} {{inspection}} allocation problem with considering production line balance {{at the same}} time for <b>multi-station</b> assembly <b>systems.</b> A mathematical model is developed in order to find the minimal total cost. When the number of parts increases, the time spent increases dramatically with the enumerative method. Therefore, an approach to genetic algorithm is developed and it takes much less time with near-optimal solutions...|$|R
40|$|For a single-server <b>multi-station</b> polling <b>system,</b> {{we focus}} on the {{generating}} function and Laplace–Stieltjes transform of the time-stationary joint queue length and workload distributions, respectively, under no further assumptions on the service discipline. We express these quantities as expressions involving the generating functions of the joint queue length distribution at visit beginnings and visit completions at the various stations. The latter is known for a broad variety of cases. Finally, we identify a workload decomposition result. Keywords: Polling system; Queue length; Steady-state distributio...|$|R
40|$|In <b>multi-station</b> {{assembly}} <b>systems,</b> {{common for}} mass-customization manufacturing strategies, the product being assembled {{is held in}} a fixture attached to a pallet, and the pallet is conveyed between workstations. In high-precision assembly systems, variation {{in the position of}} the pallet {{is one of the largest}} sources of variation within the error budget, reducing quality and yields. Conventional approaches to locating pallets use pins and bushings, and a method for predicting their repeatability is presented. This paper also presents an exact constraint approach using a split-groove kinematic coupling, which reduces variation in pallet location by an order of magnitude. © 2003 Elsevier Inc. All rights reserved...|$|R
30|$|Auroral {{tomography}} observations {{have been}} carried out in March, 1995, as a joint international campaign between Sweden and Japan. Three unmanned Swedish ALIS stations (Kiruna, Merasjärvi, Tjautjas) and two Japanese JICCD sites (Abisko, Nikkaluokta), geographically separated by about 50 km at higher latitudes, were operated to capture multi-station monochromatic tomography images at 557.7 nm wavelength using CCD cameras. All cameras were pointing to one of the predetermined directions to secure a common field of view. Several images of auroral arcs, mostly for the core region right above Kiruna, have synchronously been taken by the <b>multi-station</b> imaging <b>system.</b> Tomographic inversion analysis for four-point images was carried out using the algebraic reconstruction technique. Reconstructions of a curved arc and of a double arc system suggest promising application of this technique to the retrieval of three-dimensional auroral luminosity.|$|R
40|$|Recent {{research}} {{efforts have been}} aimed toward deriving mathematical models to relate manufacturing sources of variation with part quality variations in <b>multi-station</b> machining <b>systems</b> in order to integrate design and manufacturing knowledge. Such integration would {{make it possible to}} create a large number of applications to improve product and process design and manufacturing in areas such as fault diagnosis, best placement of inspection stations, process planning, dimensional control and process-oriented tolerancing. However, nowadays there are still important limitations on the development of these models and even some of their potential applications have still not been studied in detail. The comprehensive research work described in this dissertation contributes to overcome some of the current limitations in this field. The dissertation is divided into three parts. The first part presents a comprehensive literature review of machining sources of error that produce macro and/or micro-geometrical variations on machined surfaces, and the 3 D manufacturing variation models (the Stream of Variation model – SoV – and the Model of the Manufactured Part – MoMP) applied in the literature to analyze the propagation of those variations in multi-station machining processes. The second part of the dissertation highlights the current limitation of the SoV model through an experimental study where fixture- and machining-induced variations are analyzed. To overcome this limitation, the extension of the SoV model is formulated by modeling and adding machining-induced variations. The third part of the dissertation presents some potential applications of the SoV model and its extended version for part quality improvement. The first application shows how to apply the SoV model together with sensor-based fixtures when there are CNC machine-tools in the <b>multi-station</b> machining <b>system</b> in order to modify the cutting-tool path and partially compensate the expected part quality error. The second developed application deals with the evaluation and improvement of manufacturing process plans by integrating the SoV model and historical shop-floor quality data. Finally, the third application shows the use of the extended SoV model for the improvement of process-oriented tolerancing in multi-station machining processes...|$|R
40|$|In this paper, the SVA-FEA (Statistical Variation Analysis & Finite Element Analysis) {{method to}} do tolerance/variation {{analysis}} of multi-station assemblies of compliant parts is presented. Based {{mainly on the}} 'unit displacement' and 'sensitivity matrix' method, the proposed method allows {{for the use of}} statistical variation data in the fixturing and fastening points to predict the final shape variation of <b>multi-station</b> assembly <b>systems.</b> 'Linear' contacts between compliant parts is also included to model in more real fashion the spring-back effect between mating parts. So what happens {{at the end of the}} assembly process may be predicted. This evaluation enables users to analyze different assembly configurations in the early design phase. The implementation of the proposed method has provided a new Matlab-based variation analysis tool. For each assembly station only two FEA runs are required. No Monte Carlo simulation is needed. Finally, two case studies are presented and discussed...|$|R
40|$|Large-scale {{automated}} assembly {{systems are}} widely used in automotive, aerospace and consumer electronics industries to obtain high quality products in less time. However, one disadvantage of these automated systems {{is that they are}} composed of too many working parameters. Since {{it is not possible to}} monitor all these parameters during the assembly process, an undetected error may propagate and result in a more critical detected error. In this paper, a unique way of detecting and diagnosing these types of failures by using Virtual Factories is discussed. A Virtual Factory was developed by building and linking several software modules to predict and diagnose propagated errors. A <b>multi-station</b> assembly <b>system</b> was modeled and a previously discussed ÔÔoff-line prediction and recoveryÕÕ method was applied. The obtained results showed that this method is capable of predicting propagated errors, which are too complex to solve for a human expert...|$|R
40|$|Products made of {{compliant}} sheet metals {{are widely}} used in automotive, aerospace, appliance and electronics industries. One {{of the most important}} challenges for the assembly process with compliant parts is dimensional quality, which affects product functionality and performance. This paper develops a methodology to evaluate the dimensional variation propagation in a <b>multi-station</b> compliant assembly <b>system</b> based on linear mechanics and a state space representation. Three sources of variation: part variation, fixture variation and welding gun variation are analyzed. The proposed method is illustrated through a case study on an automotive body assembly process. �DOI: 10. 1115 / 1. 1631574 �...|$|R
40|$|The main {{challenges}} in tolerance synthesis for complex assembly design currently are: (i) {{to produce a}} simplified deterministic model that is able to formulate general statistic models in complex assembly problems; (ii) to lower the high computation intensity required in optimization studies when the process capability (yield) model is used for key product characteristics. In this paper, tolerance synthesis for complex assemblies {{is defined as a}} probabilistic optimization problem which allows the modeling of assemblies with a general multivariate statistical model and complex tolerance regions. An approach is developed for yield surrogate model generation based on an assembly model in <b>multi-station</b> manufacturing <b>systems,</b> computer experiments, multivariate distribution transformation and regression analysis. Therefore, efficient gradient-based approaches can be applied to avoid the intensive computation in direct optimization. Industrial case studies are presented to illustrate and validate the proposed methodology and compared with the existing tolerance synthesis methods. [Supplementary materials are available for this article. Go to the publisher's online edition of IIE Transactions for the following free supplemental resource: Appendix]...|$|R
40|$|Localization of {{a moving}} target in a dual-frequency radars system has now gained {{considerable}} attention. The noncoherent localization approach based on a least squares (LS) estimator has been addressed in the literature. Compared with the LS method, a novel localization method based on a two-step weighted least squares estimator is proposed to increase positioning accuracy for a <b>multi-station</b> dual-frequency radars <b>system</b> in this paper. The effects of signal noise ratio {{and the number of}} samples on the performance of range estimation are also analyzed in the paper. Furthermore, both the theoretical variance and Cramer–Rao lower bound (CRLB) are derived. The simulation results verified the proposed method...|$|R
40|$|Automated {{assembly}} systems often {{stop their}} operation {{due to the}} unexpected failures occurred during their assembly process. Since these large-scale systems are composed of many parameters, it is dif®cult to anticipate all possible types of errors with their likelihood of occurrence. Several systems were developed in the literature, focussing on on-line diagnosing and recovery of the assembly process in an intelligent manner based on the predicted error scenarios. However, these systems do not cover all of the possible errors and they are de®cient {{in dealing with the}} unexpected error situations. The proposed approach uses Monte Carlo simulation of the assembly process with the 3 -D model of the assembly line to predict the possible errors in an off-line manner. After that, these predicted errors are diagnosed and recovered using Bayesian reasoning and genetic algorithms. Several case studies are performed on single-station and <b>multi-station</b> assembly <b>systems</b> and the results are discussed. It is expected that with this new approach, errors can be diagnosed and recovered accurately and costly downtimes of robotic assembly systems will be reduced. Keywords: Off-line programming, genetic algorithms, robotic assembly systems, virtual factories, error diagnosis and recovery 1...|$|R
40|$|After a {{successful}} demonstration of a non-intercepting beam profile monitor for the H- beams at the 750 KeV and the 200 MeV LINAC at Brookhaven National Laboratory, the SNS project approved using a Nd:YAG laser {{rather than the}} traditional carbon wire for transverse profile monitors in the SNS super-conducting LINAC. Experiments have also been performed on SNS 2. 5 MeV medium energy beam transport line at LBNL. The design and {{the implementation of a}} <b>multi-station</b> profile monitoring <b>system</b> using a single laser will be presented. The laser beam is scanned across the H- beam to photo-neutralize narrow slices. The liberated electrons are collected to provide a measurement of the transverse beam profile. The prototype system has been tested; the measurement and performance results will be presented...|$|R
40|$|In <b>multi-station</b> {{manufacturing}} <b>systems,</b> {{the quality}} of final products is significantly affected by both product design as well as process variables. Historically, however, tolerance research has primarily focused on allocating tolerances based on the product design characteristics of each component. Currently, there are no analytical approaches to optimally allocate tolerances to integrate product and process variables in multi-station manufacturing processes at minimum costs. The concept of process-oriented tolerancing expands the current tolerancing practices, which bound errors related to product variables, to explicitly include process variables. The resulting methodology extends the concept of “part interchangeability” into “process interchangeability,” which is critical due to increasing requirements related to the selection of suppliers and benchmarking. The proposed methodology {{is based on the}} development and integration of three models: (i) the tolerance-variation relation; (ii) variation propagation; and (iii) process degradation. The tolerance-variation model is based on a pin-hole fixture mechanism in multi-station assembly processes. The variation propagation model utilizes a state space representation but uses a station index instead of a time index. Dynamic process effects such as tool wear are also incorporated into the framework of process-oriented tolerancing, which provides the capability to design tolerances for the whole life-cycle of a production system. The tolerances of process variables are optimally allocated through solving a nonlinear constrained optimization problem. An industry case study is used to illustrate the proposed approach...|$|R
40|$|The {{formation}} of new atmospheric particles involves an initial step forming stable clusters {{less than a}} nanometre in size (similar to 10 nm). Although at times, the same species can be responsible for both processes, {{it is thought that}} more generally each step comprises differing chemical contributors. Here, we present a novel analysis of measurements from a unique <b>multi-station</b> ground-based observing <b>system</b> which reveals new insights into continental-scale patterns associated with new particle formation. Statistical cluster analysis of this unique 2 -year multi-station dataset comprising size distribution and chemical composition reveals that across Europe, there are different major seasonal trends depending on geographical location, concomitant with diversity in nucleating species while it seems that the growth phase is dominated by organic aerosol formation. The diversity and seasonality of these events requires an advanced observing system to elucidate the key processes and species driving particle formation, along with detecting continental scale changes in aerosol formation into the future...|$|R
40|$|The {{complexity}} of the oral environment, and ethical problems associated with studies of oral diseases in humans inevitably directed the attention to development of laboratory models, that simulate the human oral microcosm. These developments {{and in particular the}} in vitro 'artificial mouth' systems have progressed from simple and basic apparatus devised by Magitot and Miller at the end of 19 th century to the currently available, highly sophisticated, computer-controlled, <b>multi-station</b> artificial mouth <b>systems.</b> These advances have metamorphosed from the early studies devised primarily to investigate factors affecting the carious process to the present designs that evaluate growth, pathogenicity, metabolism and mineralization of dental plaque under highly controlled conditions. The modern 'artificial mouth systems' can evaluate microbial interactions in simulated dental plaque and similar biofilms and monitor their physical, chemical, biological and molecular features to a very high degree of accuracy. We review and trace here the historical aspects and developments leading to the currently available artificial mouth systems and discuss their contribution to the study of oral flora, especially related to many variants of dental caries. © 2003 Elsevier Science Ltd. All rights reserved. link_to_subscribed_fulltex...|$|R
40|$|A simple {{technique}} {{to estimate the}} distance of the lightning strikes d with a single VLF electromagnetic wave receiver at a single station is described. The technique is based on the recording of oscillatory waveforms of the electric fields of sferics. Even though the process of estimating d using the waveform is a rather classical one, a novel and simple procedure for finding d is proposed in this paper. The procedure adopted provides two independent estimates of {{the distance of the}} stroke. The accuracy of measurements has been improved by employing high speed (333 ns sampling rate) signal processing techniques. GPS time is used as the reference time, which enables us to compare the calculated distances of the lightning strikes, by both methods, with those calculated from the data obtained by the World-Wide Lightning Location Network (WWLLN), which uses a multi-station technique. The estimated distances of the lightning strikes (77), whose times correlated, ranged from ~ 3000 &ndash; 16 250 km. When dd compared with those calculated with the <b>multi-station</b> lightning location <b>system</b> is ~ 4. 7 %, while for all the strokes it was ~ 8. 8 %. One of the lightnings which was recorded by WWLLN, whose field pattern was recorded and the spectrogram of the sferic was also recorded at the site, is analyzed in detail. The deviations in d calculated from the field pattern and from the arrival time of the sferic were 3. 2 % and 1. 5 %, respectively, compared to d calculated from the WWLLN location. FFT analysis of the waveform showed that only a narrow band of frequencies is received at the site, which is confirmed by the intensity of the corresponding sferic in the spectrogram...|$|R
40|$|Recent {{activity}} on Mt Etna {{was characterized by}} 25 lava fountains occurred on Mt Etna in 2011 and the ﬁrst semester of 2012. In summer 2012 volcanic activity in a milder form was noticed within the Bocca Nuova crater, before it came to an essential halt in August 2012. Together with previous unrests (e. g., in 2007 - 08) these events offer rich material for testing automatic data processing and alert issue {{in the context of}} volcano monitoring. Our presentation focuses on the seismic background radiation – volcanic tremor – which has {{a key role in the}} surveillance of Mt Etna. From 2006 on a <b>multi-station</b> alert <b>system</b> exploiting STA/LTA ratios, has been established in the INGV operative centre of Catania. Besides, also the frequency content has been found to change correspondingly to the type of volcanic activity, and can thus be exploited for warning purposes. We apply Self Organizing Maps and Fuzzy Clustering which offer an efﬁcient way to visualize signal characteristics and its development with time. These techniques allow to identify early stages of eruptive events and automatically ﬂag a critical status before this becomes evident in conventional monitoring techniques. Changes of tremor characteristics are related to the position of the source of the signal. Given the dense seismic network we can base the location of the sources on distribution of the amplitudes across the network. The locations proved to be extremely useful for warning throughout both a ﬂank eruption in 2008 as well as the 2011 lava fountains. During all these episodes a clear migration of tremor sources towards the eruptive centres was revealed in advance. The location of the sources completes the picture of an imminent volcanic unrest and corroborates early warnings ﬂagged by the changes of signal characteristics. Automatic real time data processing poses high demands on computational efﬁciency, robustness of the methods and stability of data acquisition. The amplitude based multi-station approach is not sensitive to the failure of single stations and therefore offers a good stability. On the other hand, the single station approach, exploiting unsupervised classiﬁcation techniques, limits logistic efforts, as only one or few key stations are necessary. A common characteristics of both strategies is their robustness to disturbances (undesired transients like earthquakes, noise, short gaps in the continuous data ﬂow). False alarms were not encountered so far. A critical issue it the reliability of data storage and access. Therefore, a speciﬁc hardware cluster architecture has been proposed for failover protection, including a Storage Area Network system. We present concepts of the software architectures which allow easy data access following predeﬁned user policies. We also envisage the integration of seismic data and those originating from other scientiﬁc ﬁelds (e. g., volcano imagery, geochemistry, deformation, gravity, magneto-telluric). This will facilitate cross-checking of evidences encountered from the single data streams, in particular allow their immediate veriﬁcation with respect to ground truth...|$|R
40|$|Eighteen {{paroxysmal}} episodes {{occurred on}} Mt Etna in 2011, and provided rich material for testing automatic procedures of data processing and alert {{systems in the}} context of volcano monitoring. The 2011 episodes represent a typical picture of activity of Mt Etna: in 2000 and 2001, before the 2001 flank eruption, more than one hundred lava fountains were encountered. Other major lava fountains occurred before the flank eruptions of 2002 / 03 and 2008. All these fountains, which are powerful but usually short lived phenomena, originated from the South-East Crater area and caused the formation of thick ash clouds, followed by the fallout of material with severe problems for the infrastructure of the metropolitan area of Catania. We focus on the seismic background radiation – volcanic tremor – which {{plays a key role in}} the surveillance of Mt Etna. Since 2006 a <b>multi-station</b> alert <b>system</b> has been established in the INGV operative centre of Catania exploiting STA/LTA ratios. Besides, it has been demonstrated that also the spectral characteristics of the signal changes correspondingly to the type of volcanic activity. The simultaneous application of Self Organizing Maps and Fuzzy Clustering offers an efficient way to visualize signal characteristics and its development with time, allowing to identify early stages of eruptive events and automatically flag a critical status before this becomes evident in conventional monitoring techniques. Changes of tremor characteristics are related to the position of the source of the signal. The location of the sources exploits the distribution of the amplitudes across the seismic network. The locations were extremely useful for warning throughout both a flank eruption in 2008 as well as the 2011 lava fountains, during which a clear migration of tremor sources towards the eruptive centres could be noticed in advance. The location of the sources completes the picture of an imminent volcanic unrest and corroborates early warnings flagged by the changes of signal characteristics. On-line data processing requires computational efficiency, robustness of the methods and reliability of data acquisition. The amplitude based multi-station approach offers a reasonable stability as it is not sensitive to the failure of single stations. The single station approach, based on our unsupervised classification techniques, is cost-effective with respect to logistic efforts, as only one or few key stations are necessary. Both systems have proven to be robust with respect to disturbances (undesired transients like earthquakes, noise, short gaps in the continuous data flow), and false alarms were not encountered so far. Another critical aspect is the reliability of data storage and access. A hardware cluster architecture has been proposed for failover protection, including a Storage Area Network system. We outline concepts of the software architectures which allow easy data access following predefined user policies. We envisage the integration of seismic data and those originating from other scientific fields (such as volcano imagery, geochemistry, deformation, gravity, magneto-telluric), in order to facilitate cross-checking of the findings encountered from the single data streams, in particular allowing their immediate verification with respect to ground truth...|$|R

