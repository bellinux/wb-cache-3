0|34|Public
40|$|The {{computation}} of {{the direct}} dynamics problem (forward dynamics) {{plays a major role}} in the real-time computer modelling and simulation of robot manipulators. The efficient and computationally inexpensive solution of this problem facilitates the design of real-time robot simulators. In addition, it allows for a better understanding of the key elements affecting robot operations. This work proposes to solve this problem by employing parallel and distributed processing techniques. First, a parallel implementation of a simplified Lagrange-Euler formulation is used to solve for the dynamics. Second, a resulting system of linear equations is solved using Gaussian-Elimination with simple row interchange. Both algorithms are distributed over a <b>multiple-instruction,</b> <b>multiple-data</b> <b>stream</b> (MIMD) computer architecture...|$|R
40|$|Introduction The Real World Computing (RWC) Project aims at {{developing}} "flexible information processing" {{technologies for}} real world applications. Main research areas are optical computing, theoretical basis, novel functions, and massively parallel computing. A series of massively parallel computers are {{planned to be}} developed to serve {{as part of the}} infrastructure of the project. The first in the series, RWC- 1, is now under development [4]. RWC- 1 is based on the "RICA architecture" in which computation and communication is closely coupled. The close coupling enables efficient fine-grain parallel computation, which is desirable in flexible computational tasks. <b>Multiple-instruction,</b> <b>multiple-data</b> <b>stream</b> (MIMD) type parallel computers [...] - RWC- 1 is one such [...] - allow more flexible computation than single-instruction, single-data stream (SIMD) type parallel computers, since constituent processors does not run in a lock-step manner but and asynchronously and freely. The price one h...|$|R
40|$|Experiments were {{conducted}} at NASA Ames Research Center to define multi-tasking software requirements for <b>multiple-instruction,</b> <b>multiple-data</b> <b>stream</b> (MIMD) computer architectures. The {{focus was on}} specifying solutions for algorithms {{in the field of}} computational fluid dynamics (CFD). The program objectives were to allow researchers to produce usable parallel application software as soon as possible after acquiring MIMD computer equipment, to provide researchers with an easy-to-learn and easy-to-use parallel software language which could be implemented on several different MIMD machines, and to enable researchers to list preferred design specifications for future MIMD computer architectures. Analysis of CFD algorithms indicated that extensions of an existing programming language, adaptable to new computer architectures, provided the best solution to meeting program objectives. The CoFORTRAN Language was written in response to these objectives and to provide researchers a means to experiment with parallel software solutions to CFD algorithms on machines with parallel architectures...|$|R
40|$|Sequence {{comparison}} with a ne gap costs {{is a problem}} that is readily parallelizable on simple singleinstruction, <b>multiple-data</b> <b>stream</b> (SIMD) parallel processors using only constant space per processing element. Unfortunately, the twin problem of sequence alignment, nding the optimal characterby-character correspondence between two sequences, is more complicated. While the innovative O(n 2) time and O(n) -space serial algorithm has been parallelized for <b>multiple-instruction,</b> <b>multiple-data</b> <b>stream</b> (MIMD) computers with only a communication-time slowdown, typically O(log n), it is not suitable for hardware-e cient SIMD parallel processors with only local communication. This paper proposes several methods of computing sequence alignments with limited memory per processing element. The algorithms are also well-suited to serial implementation. The simpler algorithms feature, for an arbitrary integer L, a factor of L slowdown in exchange for reducing space requirements from O(n) toO (Lp n) per processing element. Using this result, we describe an O(n log n) parallel time algorithm that requires O(log n) space per processing element onO(n) SIMD processing elements with only a mesh or linear interconnection network...|$|R
40|$|Advanced control {{strategies}} {{require the}} inclusion of the dynamical model of the robot arm in the control law. However, the dynamics consist of a highly coupled and non-linear set of equations. Thus, this complexity has always presented a major obstacle in real-time dynamic control applications. The computationally efficient solution of this problem will lead to a better comprehension of the key factors affecting robot operations. This work describes a solution of this problem by employing a parallel processing approach. The dynamics are computed by using a semi-customised Newton-Euler formulation. The algorithm is distributed over a highly-coupled <b>multiple-instruction</b> <b>multiple-data</b> <b>stream</b> (MIMD) computer architecture. The computer system is constructed from general purpose (VLSI) building blocks called (TRANSPUTER. The cost-effectiveness and speed of the scheme is demonstrated by a case study (PUMA 560 robot arm). The communication issues between the different processors are discussed. Speed-up results are included to show the superiority and advantages of the parallel approach...|$|R
40|$|A message-passing {{version of}} the PAGOSA shock-wave physics code has been {{developed}} at Sandia National Laboratories for <b>multiple-instruction,</b> <b>multiple-data</b> <b>stream</b> (MIMD) computers. PAGOSA is an explicit, Eulerian code for modeling the three-dimensional, high-speed hydrodynamic flow of fluids and the dynamic deformation of solids under high rates of strain. It was originally developed at Los Alamos National Laboratory for the single-instruction, multiple-data (SIMD) Connection Machine parallel computers. The performance of Sandia`s message-passing version of PAGOSA has been measured on two MIMD machines, the nCUBE 2 and the Intel Paragon XP/S. No special {{efforts were made to}} optimize the code for either machine. The measured scaled speedup (computational time for a single computational node divided by the computational time per node for fixed computational load) and grind time (computational time per cell per time step) show that the MIMD PAGOSA code scales linearly with the number of computational nodes used on a variety of problems, including the simulation of shaped-charge jets perforating an oil well casing. Scaled parallel efficiencies for MIMD PAGOSA are greater than 0. 70 when the available memory per node is filled (or nearly filled) on hundreds to a thousand or more computational nodes on these two machines, indicating that the code scales very well. Thus good parallel performance can be achieved for complex and realistic applications when they are first implemented on MIMD parallel computers...|$|R
40|$|Includes bibliographical {{references}} (pages [60]- 62). A new multi-path {{acoustic echo}} canceller for teleconferencing {{is presented in}} this thesis. This echo canceller contains digitized versions of multiple echo paths in its memory for all the microphones in the teleconferencing system. The echo paths were obtained by echo path modelling. The simulation for echo cancellation shows that the canceller has improved echo cancellation performance compared with a conventional single-path model echo canceller. The improvement is quite noticeable when active microphone switching occurs. A new adaptation technique is incorporated in this echo canceller which takes specific microphone related echo paths into account. The echo canceller demonstrates a highly parallel pipelined multi-processor architecture. The <b>multiple-instruction</b> <b>multiple-data</b> <b>stream</b> (MIMD) structure is utilized for implementing the echo cancellation system. The real-time acoustic echo cancellation application is computationally intensive. The intrinsic parallelism of a specific adaptive algorithm was exploited in this custom multiple microprocessor architecture. The design objective {{was to provide a}} system platform for efficient resource utilization and adaptive algorithm execution. The system consists of five high speed floating-point digital signal processors (DSP). One master processor handles system control, program downloads, data transfers, microphone selection and scalar adaptive filter computations. The other four slave processors execute filtering and adaptive algorithm computations in parallel. The interprocessor communication scheme accommodates large adaptive filters by permitting the addition of more slave processors. The system achieves excellent speedup rates when implementing FIR and DLMS algorithms for real-time acoustic echo cancellation applications. The system speedup with four SPMs varies from 2. 756 to 3. 967 when implementing a FIR filter with DLMS algorithm while the order of the filter increases from 32 to 2048. This indicates that the highest computational speedup can be achieved when DLMS algorithm is selected with high filter order. M. S. (Master of Science...|$|R
50|$|In multiprocessing, the {{processors}} {{can be used}} {{to execute}} a single sequence of instructions in multiple contexts (single-instruction, multiple-data or SIMD, often used in vector processing), multiple sequences of instructions in a single context (multiple-instruction, single-data or MISD, used for redundancy in fail-safe systems and sometimes applied to describe pipelined processors or hyper-threading), or multiple sequences of instructions in multiple contexts (<b>multiple-instruction,</b> <b>multiple-data</b> or MIMD).|$|R
40|$|Optical {{implementation}} of general binary cellular automata including regular and hybrid cellular automata is proposed, {{which is based}} on optical neighborhood logic operations. All of 256 local rules of elementary cellular automata can be performed all optically by simply programming the structure of decoding mask. The optical processor can carry <b>multiple-instruction</b> <b>multiple-data</b> processing, so it is flexible to be used for the design of optical computing systems. The simulated experiments are given. Finally, optical {{implementation of}} 2 -D cellular automata is discussed...|$|R
40|$|We generalize {{the first}} author's {{adaptive}} numerical scheme for scalar first order conservation laws to systems of equations. The resulting numerical methods generate highly non-uniform, time-dependent grids, and hence {{are difficult to}} execute efficiently on vector computers such as the Cray or Cyber 205. In contrast, we show that these algorithms may be executed in parallel on alternate computer architectures. We describe a parallel implementation of the algorithm on the Denelcor HEP, a <b>multiple-instruction,</b> <b>multiple-data</b> (MIMD) shared memory parallel computer...|$|R
40|$|The {{simulation}} of the computational plasticity on a complex structure remains a formidable computational task, especially when a highly nonlinear, complex material model was used. It {{appears that the}} computational requirements for a such problem can only be satisfied by massively parallel architectures. In order to effectively harness the tremendous computational power provided by such architectures, {{it is imperative to}} investigate and to study the algorithmic and implementation issues pertaining to dynamic load balancing for computational plasticity on a highly parallel, distributed-memory, <b>multiple-instruction,</b> <b>multiple-data</b> computers. This paper will measure the effectiveness of the algorithms developed in handling the dynamic load balancing...|$|R
40|$|This paper {{examines}} {{the problem of}} dealing with the integration of a two-dimensional Schrödinger equation using a sector-diabatic coupled-channel approach when the coupling matrix is too large to fit into the memory of individual nodes of a <b>multiple-instruction,</b> <b>multiple-data</b> (MIMD) parallel machine. For this case, the distribution of blocks of the coupling matrix among the different nodes and the use of a pipeline model are investigated. To measure performances and to compare them with those measured for a previously optimized task farm model, the pipeline model was implemented on a hypercube and its structure optimized. Benchmarks were performed for di-mensions of the coupling matrix manageable by both task farm and pipeline models. ...|$|R
40|$|This paper {{presents}} a procedure for computing the aeroelasticity of wing-body configurations on <b>multiple-instruction,</b> <b>multiple-data</b> (MIMD) parallel computers. In this procedure, fluids are modeled using Euler equations discretized by a finite difference method, and structures are modeled using finite element equations. The procedure is designed {{in such a}} way that each discipline can be developed and maintained independently by using a domain decomposition approach. A parallel integration scheme is used to compute aeroelastic responses by solving the coupled fluid and structural equations concurrently while keeping modularity of each discipline. The present procedure is validated by computing the aeroelastic response of a wing and comparing with experiment. Aeroelastic computations are illustrated for a High Speed Civil Transport type wing-body configuration...|$|R
40|$|A multi-scale {{hardware}} and software architecture implementing the EMMS (energy-minimization multis-cale) paradigm is proven {{to be effective in}} the simulation of a two-dimensional gas solid suspension. General purpose CPUs are employed for macro-scale control and optimization, and many integrated cores (MICs) operating in <b>multiple-instruction</b> <b>multiple-data</b> mode are used for a molecular dynamics simulation of the solid particles at the meso-scale. Many cores operating in single-instruction multiple-data mode, such as general purpose graphics processing units (GPGPUs), are employed for direct numerical simulation of the fluid flow at the micro-scale using the lattice Boltzmann method. This architecture is also expected to be efficient for the multi-scale simulation of other complex systems. (C) 2013 Chinese Society of Particuology and Institute of Process Engineering, Chinese Academy of Sciences. Published by Elsevier B. V. All rights reserved. A multi-scale {{hardware and}} software architecture implementing the EMMS (energy-minimization multis-cale) paradigm is proven to be effective in the simulation of a two-dimensional gas solid suspension. General purpose CPUs are employed for macro-scale control and optimization, and many integrated cores (MICs) operating in <b>multiple-instruction</b> <b>multiple-data</b> mode are used for a molecular dynamics simulation of the solid particles at the meso-scale. Many cores operating in single-instruction multiple-data mode, such as general purpose graphics processing units (GPGPUs), are employed for direct numerical simulation of the fluid flow at the micro-scale using the lattice Boltzmann method. This architecture is also expected to be efficient for the multi-scale simulation of other complex systems. (C) 2013 Chinese Society of Particuology and Institute of Process Engineering, Chinese Academy of Sciences. Published by Elsevier B. V. All rights reserved...|$|R
40|$|Encouraged by {{continuous}} {{advances in}} FPGA technologies, we explore high-performance Multi-Processor-on-a-Programmable-Chip (MPoPC) reconfigurable architectures. This paper proposes a methodology for assigning resources at run time and scheduling large-scale floating-point, data-parallel applications on our mixed-mode HERA MPoPC. HERA stands for HEterogeneous Reconfigurable Architecture. An application {{is represented by}} a novel mixed-mode task flow graph {{which is scheduled to}} run under a variety of independent or cooperating parallel computing modes: SIMD (Single-Instruction, Multiple-Data), Multiple-SIMD and MIMD (<b>Multiple-Instruction,</b> <b>Multiple-Data).</b> The reconfigurable logic is customized at static time and reconfigured at run time to match application characteristics. An in-house developed parallel power flow analysis code by Newton s method is employed to verify the methodology and evaluate the performance. This application is of utmost importance to any power grid. 1...|$|R
40|$|A {{procedure}} for computing the aeroelasticity of wings on parallel <b>multiple-instruction,</b> <b>multiple-data</b> (MIMD) computers is presented. In this procedure, fluids are modeled using Euler equations, and structures are modeled using modal or finite element equations. The procedure is designed {{in such a}} way that each discipline can be developed and maintained independently by using a domain decomposition approach. In the present parallel procedure, each computational domain is scalable. A parallel integration scheme is used to compute aeroelastic responses by solving fluid and structural equations concurrently. The computational efficiency issues of parallel integration of both fluid and structural equations are investigated in detail. This approach, which reduces the total computational time by a factor of almost 2, is demonstrated for a typical aeroelastic wing by using various numbers of processors on the Intel iPSC/ 860...|$|R
40|$|With {{the advent}} of readily {{available}} <b>Multiple-Instruction,</b> <b>Multiple-Data</b> (MIMD) machines, calculations are being performed which, until recently, were impractical. Physical scientific calculations such as weather forecasting, shock propagation, fluid migration and aerodynamics calculations are being performed at higher fidelity and over larger problem spaces. These types of calculations are often performed by mapping physical space onto a two dimensional grid. When using a MIMD computer, each processor is responsible for performing calculations {{for a portion of}} the grid. To obtain optimal performance on a MIMD computer, the computational load for each processor must be nearly equal and the communication between processors must be minimized. Unfortunately, balancing load and simultaneously reducing communication is difficult. Many modern scientific grid calculations exacerbate the problem because grid points are dynamically created and deleted during the calculation. If a calculation i [...] ...|$|R
40|$|Abstract-Chip {{multiprocessing}} {{has demonstrated}} to be a promising approach in microprocessor design. With ever increasing concerns for energy consumption, performanceenergy trade-offs are often necessary, {{especially in the}} design of real-time embedded systems. This paper presents our performance and energy study on an in-house developed FPGAbased mixed-mode chip multiprocessor, where the SIMD (Single-Instruction, <b>Multiple-Data),</b> MIMD (<b>Multiple-Instruction,</b> <b>Multiple-Data)</b> and M-SIMD (Multiple-SIMD) computing modes can exist simultaneously in one system. We propose performance-energy trade-off techniques based on the observation that SIMD and MIMD task executions involve substantially different amounts of computation and communication, which result in different time and energy behavior and provide us with opportunities to realize various performance-energy objectives. Generalized matrix-matrix multiplication (MMM) is employed as an example to illustrate our analysis. Experimental results on a Xilinx Virtex II XC 2 V 6000 - 5 FPGA demonstrate the effectiveness of the proposed approach. I...|$|R
40|$|This paper {{describes}} {{a tool for}} the development of distributed applications. The target execution environment is a network of heterogenous general-purpose workstations. This tool (called HERMES) mainly handles the message transport layer and does not deal with aspects more directly related to parallel computing, such as the topology of communicating processes or load balancing among processors. A coarse-grained concurrence is supported and the resulting parallel architecture is based on the <b>multiple-instructions</b> <b>multiple-data</b> paradigm. This system is mainly characterized by its ability of handling special messages (alarm and urgent) that are guaranteed immediate processing by the receiving process. Messages are always asynchronous, in that they are immediately delivered to destination, without any temporary buffering by the communication system (i. e. asynchronously with respect to the program execution). The system is still under development but a preliminary version, restricted to pro [...] ...|$|R
40|$|Scientific {{visualization}} {{is playing}} {{an increasingly important}} role in the analysis and interpretation of massively parallel CFD simulations due to the enormous volume of data that can be generated on these machines. In this paper we will describe the development of a visualization technique based on a parallel analogue to the Marching Cubes algorithm. The algorithm has been developed for <b>Multiple-Instruction,</b> <b>Multiple-Data</b> (MIMD) massively parallel computers and is designed {{to take advantage of the}} heterogeneous programming capabilities of the MIMD architecture. We examine several different configurations and conclude that for producing animations the best one, in terms of both frame generation time and disk usage, is to run the two applications heterogeneously and send the resulting geometry description directly to a workstation for rendering, thereby totally eliminating the use of files from the animation process. INTRODUCTION Massively parallel supercomputers offer scientists and [...] ...|$|R
40|$|In {{this paper}} I {{describe}} and extend a new DNA computing paradigm introduced in Blumberg [4] for building massively parallel {{machines in the}} DNA-computing models described by Adelman [1, 2], Cai et. al. [5], and Liu et. al. [8]. Employing only DNA operations which have been reported as successfully performed, I present an implementation of a Connection Machine [7], a SIMD (single-instruction multiple-data) parallel computer as an illustration of how to apply this approach to building computers in this domain (and as an implicit demonstration of PRAM equivalence). This is followed {{with a description of}} how to implement a MIMD (<b>multiple-instruction</b> <b>multiple-data)</b> parallel machine. The implementations described herein differ most from existing models in that they employ explicit communication between processing elements (and hence strands of DNA). Keywords: DNA Computing, Parallel Computation, Parallel Architecture c fl Massachusetts Institute of Technology, 1996. CONTENTS i Con [...] ...|$|R
40|$|Abstract- Even though {{state-of-the-art}} FPGAs present {{new opportunities}} in exploring low-cost high-performance architectures for floating-point scientific applications, they also pose serious challenges. Multiprocessors-on-a-Programmable-Chip (MPoPCs), which integrate both softwareprogrammability and hardware-reconfigurability, provide substantial flexibility {{that can result}} in programming ease and high performance. This paper presents an application-oriented system design methodology for HERA (HEterogeneous Reconfigurable Architecture), an in-house developed MPoPC that targets applications involving large matrices. HERA is a mixed computing-mode multiprocessor supporting simultaneous execution in SIMD (Single-Instruction, <b>Multiple-Data),</b> MIMD (<b>Multiple-Instruction,</b> <b>Multiple-Data),</b> and multiple-SIMD for chosen groups of processors. Given an application with specific energy-performance objectives, our design methodology aims to customize HERA to match the diverse computation and communication characteristics of tasks in the application. Appropriate analysis of the application guides system synthesis that employs a parameterized hardware component library (PHCL) of function units with predictable performance and power dissipation. Extensive experimental results for parallel power-flow analysis are presented to demonstrate the effectiveness of our design methodology. Keywords: FPGA, Multiprocessor-on-a-Programmable Chip, design methodology, floating-point unit, mixedmode parallel processing. ...|$|R
40|$|The high price, long {{design and}} {{development}} cycles, programming difficulty and {{high maintenance cost}} of supercomputers limit their range of potential applications. Recent advances in Field-Programmable Gate Arrays (FPGAs) have made feasible the development of highperformance and programmable parallel systems on a programmable chip (PSOPC). PSOPC’s yield highperformance at low cost for many parallel applications. We present in this paper the design and implementation of our HERA (HEterogeneous Reconfigurable Architecture) machine that employs FPGAs to allow the simultaneous execution {{of a variety of}} parallel processing modes, including SIMD (Single-Instruction, <b>Multiple-Data),</b> MIMD (<b>Multiple-Instruction,</b> <b>Multiple-Data)</b> and M-SIMD (Multiple-SIMD). The processing element is centered on a single-precision IEEE 754 floating-point unit (FPU) and employs a 7 -stage pipeline. To demonstrate the robustness and viability of our approach, we propose a data partitioning scheme and employ mixedmode scheduling for Cannon’s matrix-matrix multiplication algorithm with matrices of arbitrary size and shape. Performance results on our 64 -PE machine that employs a dual-FPGA system are better than the optimized performance on a dual-Xeon PC...|$|R
40|$|Modem design {{requirements}} for an aircraft push current technologies {{used in the}} design process to their limit or sometimes require more advanced technologies to meet the requirement. New {{design requirements}} always demand to improve the operational performance. Accurate prediction of aerodynamic coefficients is essential to improve the performance. For example, {{in the design of}} an advanced subsonic civil transport, since the fluid flow at transonic regime shows strong nonlinearities, high fidelity equations, such as the Euler or Navier-Stokes equations predict flow characteristics more accurately than the linear aerodynamics, which are widely used in the current design process However, high fidelity flow equations are computationally expensive and require an order of magnitude longer time to obtain aerodynamic coefficients required in the design. Parallel computing is one possibility to cut down the computational turn-around time in using high fidelity equations so that high fidelity equations would be incorporated into the design process. By doing so, high fidelity equations would be used in the routine design process. This work will demonstrate the feasibility of using high fidelity flow equations in a design process by computing aerodynamic influence coefficients of a wing-body-empennage configuration on a <b>multiple-instruction,</b> <b>multiple-data</b> parallel computer...|$|R
40|$|Recent {{advances}} in multi-million-gate platform FPGAs {{have made it}} possible to design and implement complex parallel systems on a programmable chip (PSOPCs) that also incorporate hardware floating-point units (FPUs). These options take advantage of resource reconfiguration. In contrast to the majority of the FPGA community that still employs reconfigurable logic to develop algorithm-specific circuitry, our FPGA-based mixed-mode reconfigurable computing machine can implement simultaneously a variety of parallel execution modes and is also user programmable. Our HERA (HEterogeneous Reconfigurable Architecture) machine can implement the SIMD (Single-Instruction, <b>Multiple-Data),</b> MIMD (<b>Multiple-Instruction,</b> <b>Multiple-Data)</b> and M-SIMD (Multiple-SIMD) execution modes. Each processing element (PE) is centered on a single-precision IEEE 754 FPU with tightly-coupled local memory, and supports dynamic switching between SIMD and MIMD at runtime. Mixed-mode parallelism has the potential to best match the characteristics of all subtasks in applications, thus resulting in sustained high performance. We evaluate HERA s performance by two common computation-intensive testbenches: matrix-matrix multiplication (MMM) and LU factorization of sparse Doubly-Bordered-Block-Diagonal (DBBD) matrices. Experimental results with electrical power network matrices show that the mixed-mode scheduling for LU factorization can result in speedups of about 19 % and 15. 5 % compared to the SIMD and MIMD implementations, respectively...|$|R
40|$|INTRODUCTION The SPMD (Single-Program <b>Multiple-Data</b> <b>Stream)</b> {{model has}} been widely adopted as the base of {{parallel}}izing compilers and parallel programming languages for scientific programs [1]. This model will work well not only for shared memory machines but also for distributed memory multicomputers, provided that; data are allocated appropriately by the programmer and/or the compiler itself, the compiler distributes parallel computations to processors so that interprocessor communication costs are minimized, and codes for communication are inserted, only when necessary, at the point adequate for minimizing communication latency. 314 Chapter 13 forall i / 1 to N do begin a[i] / b[index [i]]; end; (a) Loop with indexed right-hand side forall i / 1 to<F 24. 6...|$|R
40|$|Abstract — Recovering {{the symbols}} in a multiple-input multiple-output (MIMO) {{receiver}} is a computationally-intensive process. The layered space-time (LST) algorithms provide a reasonable tradeoff between complexity and performance. Com-mercial digital signal processors (DSPs) {{have become a}} key component in many high-volume products such as cellular tele-phones. As an alternative to power-hungry DSPs, we propose to use a moderately-parallel single-instruction <b>stream,</b> <b>multiple-data</b> <b>stream</b> (SIMD) co-processor architecture, called DSP-RAM, to implement an LST MIMO receiver that offers high performance with relatively low power consumption. For a typical indoor wireless environment, a 100 -MHz DSP-RAM can potentially provide more than 10 times greater decoding throughput at the receiver of a (4, 4) MIMO system compared to a conventional 720 -MHz DSP. The DSP-RAM processor has been coded in a hardware description language (HDL) and synthesized for both available field-programmable gate arrays (FPGAs) and for a 0. 18 −µm CMOS standard cell implementation. Index Terms — Layered space-time decoding, MIMO receiver, processor-in-memory, parallel processing. I...|$|R
40|$|Motion {{estimation}} is {{a temporal}} image compression technique where an n x n block of pixels {{in the current}} frame of a video sequence is represented by a motion vector {{with respect to the}} best matched block in a search area of the previous frame, and the DCT coefficients of the estimated error terms. In this paper, a fast technique for motion estimation is proposed and later mapped onto the SIMD structure of the Computational*RAM (C*RAM). C*RAM is a conventional computer DRAM (or SRAM) with built-in logic circuitry at the sense-amplifier {{to take advantage of the}} high on-chip memory bandwidth and massively parallel SIMD (Single-Instruction <b>stream,</b> <b>Multiple-Data</b> <b>stream)</b> operations. The proposed technique, first, attempts to reduce the n-bit grayscale frames into 1 -bit binary frames using morphological filters, and to search for motions of the extracted features on the binary frames. While the reduction procedure requires a small percentage of computation using the full grayscale, the searc [...] ...|$|R
40|$|Motion {{estimation}} is {{a temporal}} image compression technique, where an n x n block of pixels {{in the current}} frame of a video sequence is represented by a motion vector {{with respect to the}} best matched block in a search area of the previous frame, and the DCT coefficients of the displaced block differences. In this paper, a low complexity technique for motion estimation is proposed. The proposed technique, first, reduces the n-bit grayscale frames into 1 -bit binary frames using morphological filters, and determines the displacement of the edge features of the adjacent frames. While reduction in bit-depth requires a small percentage of computation using the full pixel resolution, the search procedure is performed by simple XOR logic operations and 1 -b distortion accumulations on the entire search area. Compared to other low complexity techniques, the proposed technique yields better frame reconstruction, operates using simpler arithmetic/logic operations, and possesses a higher degree of parallelism when implemented on a 2 -D Single-Instruction <b>stream,</b> <b>Multiple-Data</b> <b>stream</b> (SIMD) architecture. Key words: motion estimation, morphological image processing, SIMD architecture, parallel processing. 1...|$|R
40|$|For {{innovative}} portable products, Systems on Chips (SoCs) containing several processors, {{memories and}} specialised modules are obviously required. Performances but also low-power are main {{issues in the}} design of such SoCs. Are these low-power SoCs only constructed with low-power processors, memories and logic blocks? If the latter are unavoidable, many other issues are quite important for low-power SoCs, such as the way to synchronise the communications between processors as well as test procedures, online testing, software design and development tools. This paper is a general framework for the design of low-power SoCs, starting from the system level to the architecture level, assuming that the SoC is mainly based on the re-use of low-power processors, memories and logic peripherals. SoCs with many processors, co-processors, memories and peripherals cannot be synchronised with a single master clock, due to larger and larger wire delays in deep submicron technologies. Several clocking schemes have been proposed, such as GALS (Globally Asynchronous Locally Synchronous) but also full asynchronous architectures. This paper will present {{the advantages and disadvantages of}} these SoC clocking strategies as well as the impacts on low power. For embedded SoCs containing several processors, one has to write several pieces of software for each processor starting typically from a high-level specification using the C/C++ language. In order to tackle this problem, we propose to first transform the original specification by means of a systematic script of platform-independent source code transformations. That is illustrated by applying global loop transformation techniques to identify asynchronous partitions exhibiting little communication and high locality of access characteristics. In a second stage, we explore <b>multiple-instruction</b> <b>multiple-data</b> (MIMD) mapping onto a given (partly) predefined platform using advanced space-time analysis techniques to maintain low data transfer rates while achieving high system throughput. At the SoC level, accurate cost feedback including high-level power estimation is required. From this essential information, energy trade-offs between application sub-modules can for example be used to refine the solution further. In the case of mapping onto programmable cores with a shared memory hierarchy, a final refinement consists in reorganising the data layout for efficient cache utilisation...|$|R
40|$|In this thesis, {{image and}} video {{processing}} algorithms, especially the compression algorithms, are first studied {{in their natural}} formats to appreciate the needs for real-time operations and hence, parallel computing. The computational intense, memory-bound problems are next approached from two directions: algorithmic and architectural. Algorithmic approach tends to systematically analyze the flow independence and data independence of a program, while architectural approach tends to gain speed-up by resource multiplicity and time sharing. The majority of image and video processing algorithms are inherently data-parallel in nature. The vectorization of these algorithms requires consistent practices, and new challenge in parallel programming seems endless. The data-parallel nature of image/video processing algorithms map well onto the Single-Instruction <b>stream,</b> <b>Multiple-Data</b> <b>stream</b> (SIMD) of an increasingly popular Memory-Embedded Array Processor classified as the Intelligent RAMS, specifically, the Computational*RAM (C*RAM). C*RAM is a SIMD-memory hybrid where the processing elements are pitch-matched to memory columns of a conventional computer RAM at the sense-amplifiers {{to take advantage of}} the inherently high memory bandwidth, and the emulation of the massively parallel processors. Throughout the thesis, speed-ups from 1 to 3 orders of magnitude are obtained. Memory-bound algorithms such as Motion Estimation, and Mean-Absolute-Error for Nearest Neighbor Distortion Computation are among the most efficient implementations. At its best, this thesis will, definitely, put forward the promising research direction which involves fast and efficient in-memory parallel computing for visual communications...|$|R
40|$|The end of chip {{frequency}} scaling capacity, due heat dissipation limitations, made manufacturers {{search for an}} alternative to sustain the processing capacity growth. The chosen solution was to increase the hardware parallelism, by packing multiple independent processors in a single chip, in a <b>Multiple-Instruction</b> <b>Multiple-Data</b> (MIMD) fashion, each with special instructions to operate over a vector of data, in a Single-Instruction Multiple-Data (SIMD) manner. Such paradigm change, brought to software developer the convoluted task of producing efficient and scalable applications. Programming languages and associated tools evolved to aid such task for new developed applications. But automated optimizations capable of coping with such a new complex hardware, from legacy, single threaded applications, is still lacking. To apply code transformations, either developers or compilers, require to assert that, by doing so, they are not changing the expected comportment of the application producing unexpected results. But syntactically poor codes, such as use of pointer parameters with multiple possible indirections, complex loop structures, or incomplete codes, make very hard to extract application behavior solely from the source code in {{what is called a}} static analyses. To cope with the lack of information extracted from the source code, many tools and research has been done in, how to use dynamic analyses, that does application profiling based on run-time information, to fill the missing information. The combination of static and dynamic information to characterize an application are called hybrid analyses. This works advocates for the use of hybrid analyses to be able to optimizations on loops, regions where most of computations are done. It proposes a framework capable of statically applying some complex loop transformations, that previously would be considered unsafe, by assuring their safe use during run-time with a lightweight test. The proposed framework uses application execution profiling to help the static loop optimizer to: 1) identify and classify program hot-spots, so as to focus only on regions vital for the execution time; 2) guide the optimizer in understanding the overall loop behavior, so as to reduce the valid loop transformations search space; 3) using instruction's memory access functions, it statically builds a lightweight run-time test that determine, based on the program parameters values, if a given optimization is safe to be used or not. It's applicability is shown by performing complex loop transformations into a variety of loops, obtained from applications of different fields, and demonstrating that the run-time overhead is insignificant compared to the loop execution time or gained performance, {{in the vast majority of}} cases. L'auteur n'a pas fourni de résumé en françai...|$|R
40|$|This thesis explores a new {{approach}} to building data-parallel accelerators that is based on simplifying the instruction set, microarchitecture, and programming methodology for a vector-thread architecture. The thesis begins by categorizing regular and irregular data-level parallelism (DLP), before presenting several architectural design patterns for data-parallel accelerators including the <b>multiple-instruction</b> <b>multiple-data</b> (MIMD) pattern, the vector single-instruction multiple-data (vector-SIMD) pattern, the single-instruction multiple-thread (SIMT) pattern, and the vector-thread (VT) pattern. Our recently proposed VT pattern includes many control threads that each manage their own array of microthreads. The control thread uses vector memory instructions to efficiently move data and vector fetch instructions to broadcast scalar instructions to all microthreads. These vector mechanisms are complemented by the ability for each microthread to direct its own control flow. In this thesis, I introduce various techniques for building simplified instances of the VT pattern. I propose unifying the VT control-thread and microthread scalar instruction sets to simplify the microarchitecture and programming methodology. I propose a new single-lane VT microarchitecture based on minimal changes to the vector-SIMD pattern. (cont.) Single-lane cores are simpler to implement than multi-lane cores and can achieve similar energy efficiency. This new microarchitecture uses control processor embedding to mitigate the area overhead of single-lane cores, and uses vector fragments to more efficiently handle both regular and irregular DLP as compared to previous VT architectures. I also propose an explicitly data-parallel VT programming methodology that is based on a slightly modified scalar compiler. This methodology is easier to use than assembly programming, yet simpler to implement than an automatically vectorizing compiler. To evaluate these ideas, we have begun implementing the Maven data-parallel accelerator. This thesis compares a simplified Maven VT core to MIMD, vector-SIMD, and SIMT cores. We have implemented these cores with an ASIC methodology, and I use the resulting gate-level models to evaluate the area, performance, and energy of several compiled microbenchmarks. This work is the first detailed quantitative comparison of the VT pattern to other patterns. My results suggest that future data-parallel accelerators based on simplified VT architectures should be able to combine the energy efficiency of vector-SIMD accelerators with the flexibility of MIMD accelerators. by Christopher Francis Batten. Thesis (Ph. D.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2010. This electronic version was submitted by the student author. The certified thesis is available in the Institute Archives and Special Collections. Cataloged from student submitted PDF version of thesis. Includes bibliographical references (p. 165 - 170) ...|$|R

