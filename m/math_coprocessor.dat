87|13|Public
25|$|A floating-point unit (FPU, colloquially a <b>math</b> <b>coprocessor)</b> {{is a part}} of a {{computer}} system specially designed to carry out operations on floating-point numbers.|$|E
25|$|In {{particular}} hardware abstraction {{does not}} involve abstracting the instruction set, which generally falls under the wider concept of portability. Abstracting the instruction set, when necessary (such as for handling the several revisions to the x86 instruction set, or emulating a missing <b>math</b> <b>coprocessor),</b> is performed by the kernel, or via hardware virtualization.|$|E
25|$|In 1992, Wang marketed a PC-compatible {{based on}} the Intel 80386SX processor, which they called the Alliance 750CD. It was clocked at 25MHz and had a socket for an 80387 <b>math</b> <b>coprocessor.</b> It came with 2 {{megabytes}} of installed RAM, and was expandable to 16 megabytes using SIMM memory cards (a Wang invention that became an industry standard). It had a 1.44 megabyte floppy disk drive, an internal 80 megabyte hard disk, and a CD-ROM drive. Five expansion slots were built-in. It came with MS-DOS and Windows 3.1 operating systems.|$|E
5000|$|Release 2 brought add-in support, better memory {{management}} and expanded memory support, supported x87 <b>math</b> <b>coprocessors,</b> and introduced {{support for the}} Lotus International Character Set (LICS). Introduced in September 1985. The Japanese version Lotus 1-2-3 Release 2J for NEC PC-98 computers was released on 1986-09-05.|$|R
50|$|Companies {{that have}} {{designed}} or manufactured floating point units {{compatible with the}} Intel 8087 or later models include AMD (287, 387, 486DX, 5x86, K5, K6, K7, K8), Chips and Technologies (the Super <b>MATH</b> <b>coprocessors),</b> Cyrix (the FasMath, Cx87SLC, Cx87DLC, etc., 6x86, Cyrix MII), Fujitsu (early Pentium Mobile etc.), Harris Semiconductor (manufactured 80387 and 486DX processors), IBM (various 387 and 486 designs), IDT (the WinChip, C3, C7, Nano, etc.), IIT (the 2C87, 3C87, etc.), LC Technology (the Green <b>MATH</b> <b>coprocessors),</b> National Semiconductor (the Geode GX1, Geode GXm, etc.), NexGen (the Nx587), Rise Technology (the mP6), ST Microelectronics (manufactured 486DX, 5x86, etc.), Texas Instruments (manufactured 486DX processors etc.), Transmeta (the TM5600 and TM5800), ULSI (the Math·Co coprocessors), VIA (the C3, C7, and Nano, etc.), and Xtend (the 83S87SX-25 and other coprocessors).|$|R
2500|$|The Motorola 6888x <b>math</b> <b>co{{processors}}</b> and the Motorola 68040 and 68060 processors {{support this}} same 64-bit significand extended precision type (similar to the Intel format although padded to a 96-bit format with 16 unused bits inserted between the exponent and significand fields). [...] The follow-on Coldfire processors {{do not support}} this 96-bit extended precision format.|$|R
2500|$|The x86 {{extended}} precision {{format is}} an 80-bit format first {{implemented in the}} Intel 8087 <b>math</b> <b>coprocessor</b> and is supported by all processors {{that are based on}} the x86 design which incorporate a floating-point unit (FPU). [...] This 80-bit format uses one bit for the sign of the significand, 15 bits for the exponent field (i.e. the same range as the 128-bit quadruple precision IEEE 754 format) and 64 bits for the significand. The exponent field is biased by 16383, meaning that 16383 has to be subtracted from the value in the exponent field to compute the actual power of 2. [...] An exponent field value of 32767 (all fifteen bits 1) is reserved so as to enable the representation of special states such as infinity and Not a Number. [...] If the exponent field is zero, the value is a denormal number and the exponent of 2 is −16382.|$|E
2500|$|The IA32, x86-64, and Itanium {{processors}} {{support an}} 80-bit [...] "double extended" [...] extended precision format with a 64-bit significand. [...] The Intel 8087 <b>math</b> <b>coprocessor</b> {{was the first}} x86 device which supported floating point arithmetic in hardware. [...] It was designed to support a 32-bit [...] "single precision" [...] format and a 64-bit [...] "double precision" [...] format for encoding and interchanging floating point numbers. [...] The temporary real (extended) format was designed not to store data at higher precision as such, but rather primarily {{to allow for the}} computation of double results more reliably and accurately by minimising overflow and roundoff-errors in intermediate calculations: for example, many floating point algorithms (e.g. exponentiation) suffer from significant precision loss when computed using the most direct implementations. [...] To mitigate such issues the internal registers in the 8087 were designed to hold intermediate results in an 80-bit [...] "extended precision" [...] format. [...] The 8087 automatically converts numbers to this format when loading floating point registers from memory and also converts results back to the more conventional formats when storing the registers back into memory. To enable intermediate subexpressions results to be saved in extended precision scratch variables and continued across programming language statements, and otherwise interrupted calculations to resume where they were interrupted, it provides instructions which transfer values between these internal registers and memory without performing any conversion, which therefore enables access to the extended format for calculations- also reviving the issue of the accuracy of functions of such numbers, but at a higher precision.|$|E
50|$|A <b>math</b> <b>coprocessor</b> (80x87).|$|E
50|$|Cyrix Corporation was a {{microprocessor}} developer that {{was founded in}} 1988 in Richardson, Texas, as a specialist supplier of <b>math</b> <b>coprocessors</b> for 286 and 386 microprocessors. The company was founded by Tom Brightman and Jerry Rogers. Cyrix founder, President and CEO Jerry Rogers, aggressively recruited engineers and pushed them, eventually assembling a small but efficient design team of 30 people.|$|R
5000|$|Its {{name comes}} from the words fractal and integer, since the first {{versions}} of it computed fractals by using only integer arithmetic (also known as fixed-point arithmetic), which led to much faster rendering on x86 computers without <b>math</b> <b>coprocessors.</b> Since then, floating-point arithmetic and [...] "arbitrary-precision" [...] modes have been added, the latter of which emulates an arbitrarily large mantissa in RAM. The arbitrary-precision mode is slow even on modern computers.|$|R
50|$|Because IBM didn't {{use it in}} IBM PC design, it did {{not become}} well known; later I/O-coprocessors did not keep the x89 {{designation}} the way <b>math</b> <b>coprocessors</b> kept the x87 designation. It {{was used in the}} Apricot PC and the Intel Multibus iSBC-215 Hard disk drive controller. It was also used in the Altos 586 multi-user computer. Intel themselves used the 8089 in their reference designs (which they also commercialized) as System 86.|$|R
5000|$|... {{optional}} 8087 <b>math</b> <b>coprocessor</b> board plugged {{directly into}} CPU board ...|$|E
5000|$|U80613: FPU (equiv. to Intel 80287 {{floating}} point <b>math</b> <b>coprocessor)</b> ...|$|E
5000|$|... 68881 - Motorola 68881, a <b>math</b> <b>coprocessor</b> used in with 68020 and 68030 ...|$|E
50|$|Weitek {{started in}} 1981, when several Intel {{engineers}} left {{to form their}} own company. Weitek developed <b>math</b> <b>coprocessors</b> for several systems, including those based on the Motorola 68000 family, the 1064, and for Intel-based i286 systems, the 1067. Intel's own FPU design for the i386 fell far behind in development, and Weitek delivered the 1167 for them. Later upgrades to this design led to the 2167, 3167 and 4167. Weitek would later deliver similar FPUs for the MIPS architecture, known as the XL line. Weitek FPUs had several differences compared to x87 offerings, lacking extended double precision but having a register-file rather than a stack-based model.|$|R
40|$|In this paper, “Universal Multiplication Equation”- a new {{multiplication}} {{equation is}} proposed. This is called universal {{because of its}} wide application on all types of numbers. This works fine without any assumptions, no matter whatever the numbers are. It has evolved after continuous study on numbers; how the answers were generated, when different types of numbers underwent multiplication. Using the same equation, it has been proved why zero multiplied by any number is zero and why negative multiplied by negative is positive. This equation can be further used for fast mental calculations and calculations in competitive exams very efficiently. This can be also used {{in the field of}} <b>math</b> <b>coprocessors</b> in computers. Algorithms can be developed using this equation for faster multiplications in multiplier (FPGA’s), reducing the processing time and power consumption hence increases the efficiency...|$|R
40|$|In {{this paper}} new {{multiplier}} and square architecture is proposed based on algorithm of ancient Indian Vedic Mathematics, for low power and high speed applications. It {{is based on}} generating all partial products and their sums in one step. The design implementation is described in both at gate level and high level RTL code (behavioural level) using Verilog Hardware Description Language. The design code is tested using Veriwell Simulator. The code is synthesized in Synopys FPGA Express using: Xilinx, Family: Spartan Svq 300, Speed Grade:- 6. The present paper relates {{to the field of}} <b>math</b> <b>coprocessors</b> in computers and more specifically to improvement in speed and power over multiplication and square algorithm implemented in coprocessors. In FPGA implementation it has been found that the proposed Vedic multiplier and square are faster than array multiplier and Booth multiplier...|$|R
5000|$|Intel 80486DX2 66 MHz or a {{compatible}} CPU with a <b>math</b> <b>coprocessor</b> (Pentium processor recommended) ...|$|E
5000|$|... 387 = 32 &times; 43, also {{shorthand}} for the Intel 80387, <b>math</b> <b>coprocessor</b> chip to the 386.|$|E
50|$|Aftermarket vendors also {{released}} {{modifications to}} upgrade mainboard memory and permit installation of an Intel 8087 <b>math</b> <b>coprocessor.</b>|$|E
40|$|Abstract — In this paper, {{shortest}} {{method to}} solve calculations of number ending with five have been presented. Many facts {{related to the}} calculation are proposed through which the entire calculation gets reduced {{to the level of}} an eye blink. There are many methods in Vedic Mathematics to multiply any two numbers. They are time consuming since they are not specifically meant for numbers ending with five. This describes the method to find the cube of a number ending with five accurately and very fast. It even describes the shortest method to solve the multiplication of two numbers ending with five. By using these formulas, calculations involving two numbers ending with five can be easily solved. This method can be also used in the field of <b>math</b> <b>coprocessors</b> in computer. This algorithm is tested in matlab(2012 a version). This method can be implemented on vlsi chip for faster multiplication...|$|R
50|$|The 16-bit Intel x86 {{processors}} up to {{and including}} the 80386 do not include floating-point units (FPUs). Intel introduced the 8087, 80187, 80287 and 80387 <b>math</b> <b>coprocessors</b> to add hardware floating-point and transcendental function capabilities to the 8086 through 80386 CPUs. The 8087 works with the 8086/8088 and 80186/80188, the 80187 works with the 80186 but not the 80188, the 80287 works with the 80286 and the 80387 works with the 80386. The combination of an x86 CPU and an x87 coprocessor forms a single multi-chip microprocessor; the two chips are programmed as a unit using a single integrated instruction set. The 8087 and 80187 coprocessors are connected in parallel with the data and address buses of their parent processor and directly execute instructions intended for them. The 80287 and 80387 coprocessors are interfaced to the CPU through I/O ports in the CPU's address space, this is transparent to the program, which does not need to know about or access these I/O ports directly; the program accesses the coprocessor and its registers through normal instruction opcodes.|$|R
40|$|This paper {{discusses}} about "Array of Array" multiplier {{which is}} a derivative of Braun Array Multiplier. Braun array are much suitable for VLSI implementation because of its less space complexity though it shows larger time complexity, {{on the other hand}} tree multipliers have time complexity of O(log n) but are less suitable for VLSI implementation since, being less regular; they require larger total routing length, which leads to performance degradation; simply put, they show higher space complexity. The main advantage of "Array of Array" multipliers is its inherent ability to reduce both time and space complexity [7] [8] with intermediate relative performance [7]. In this paper a 16 × 16 unsigned 'Array of Array' multiplier circuit is designed with hierarchical structuring, it has been optimized using Vedic Multiplication Sutra (Algorithm) "Urdhva Triyagbhyam" [1][6] and Karatsuba-Ofman algorithm[2]. The proposed algorithm is useful for <b>math</b> <b>coprocessors</b> in the field of computers. Algorithm is implemented on SPARTAN- 3 E FPGA (Field Programmable Gate Array). The proposed multiplier implementation shows large reduction in average power dissipation and in time delay as compared to Booth encoded radix- 4 multiplier...|$|R
50|$|Starting in 1983 {{the company}} {{followed}} Microway, {{the company that}} a year earlier provided the software needed by scientists and engineers to modify the IBM-PC Fortran compiler {{so that it could}} transparently employ Intel 8087s. The 80-bit Intel 8087 <b>math</b> <b>coprocessor</b> ran a factor of 50 faster than the 8/16-bit 8088 CPU that the IBM-PC software came with. However, in 1982 the speed up in floating point intensive applications was only a factor of 10 as the initial software developed by Microway and Hauppauge continued to call floating point libraries to do computations instead of placing inline x87 instructions inline with the 8088's instructions that allowed the 8088 to drive the 8087 directly. By 1984 inline compilers made their way into the market providing increased speed ups. Hauppauge provided similar software products in competition with Microway that they bundled with math coprocessors and remained in the Intel <b>math</b> <b>coprocessor</b> business until 1993 when the Intel Pentium came out with a built in <b>math</b> <b>coprocessor.</b> However like other companies that entered the <b>math</b> <b>coprocessor</b> business, Hauppauge produced other products that contributed to a field that is today called HPC - High Performance Computing.|$|E
50|$|A floating-point unit (FPU, colloquially a <b>math</b> <b>coprocessor)</b> {{is a part}} of a {{computer}} system specially designed to carry out operations on floating-point numbers.|$|E
5000|$|... 82C836 - Single Chip 386sx AT (SCATsx) - Compatible with PC/AT (bus), {{supported}} all {{the features}} of SCAT, added support for the i386SX processor and i387SX <b>math</b> <b>coprocessor.</b>|$|E
50|$|A later {{revision}} of the original Tandy 1000 model was the Tandy 1000A. This revision fixed bugs, scanned expansion cards for bootable ROMs, and added a socket for a <b>math</b> <b>coprocessor.</b>|$|E
5000|$|The <b>math</b> <b>coprocessor</b> {{business}} rapidly increased {{starting in}} 1994 with software products that accelerated applications like Lotus 123. At {{the same time}} the advent of the 80286 based IBM-AT with its 80287 <b>math</b> <b>coprocessor</b> provided new opportunities for companies that had grown up selling 8087s and supporting software. This included products like Hauppage's [...] "287 Fast/5," [...] a product that took advantage of the 80287's design that used an asynchronous clock to drive its FPU at 5 MHz instead of the 4 MHz clocking provided by IBM, making it possible for the 80287s that came with the AT to be overclocked to 12 MHz.|$|E
50|$|Microcontrollers {{traditionally}} do {{not have}} a <b>math</b> <b>coprocessor,</b> so floating point arithmetic is performed by software. However, some recent designs do include an FPU and DSP optimized features. An example would be Microchip's PIC32 MIPS based line.|$|E
50|$|Without a coprocessor, the 386 {{normally}} performs floating-point arithmetic through (slow) software routines, implemented at runtime {{through a}} software exception-handler. When a <b>math</b> <b>coprocessor</b> is paired with the 386, the coprocessor performs the {{floating point arithmetic}} in hardware, returning results much faster than an (emulating) software library call.|$|E
50|$|The 486DLC can be {{described}} as a 386DX with the 486 instruction set and 1 KB of on-board L1 cache added. Because it used the 386DX bus (unlike its 16-bit cousin, the 486SLC) it was a fully 32-bit chip. Like the 386 and 486SX, it had no on-board <b>math</b> <b>coprocessor,</b> but unlike the 486SX, it could make use of an Intel 387DX or compatible numeric coprocessor. A few 486SX motherboards also provided i387 sockets, but this feature was a very much a rarity. Due to the smaller L1 cache, the 486DLC could not compete on a clock-for-clock basis with the 486SX, but a 33 MHz 486DLC could keep pace with a 25 MHz 486SX, cost less, and offered the ability to upgrade further with the addition of an inexpensive <b>math</b> <b>coprocessor.</b>|$|E
50|$|The 80287 (i287) is the <b>math</b> <b>coprocessor</b> for the Intel 80286 {{series of}} microprocessors. Intel's models {{included}} variants with specified upper frequency limits ranging from 6 up to 12 MHz. Later followed the i80287XL with 387 microarchitecture and the i80287XLT, a special version intended for laptops, {{as well as}} other variants.|$|E
5000|$|In later Nx586's, a x87 <b>math</b> <b>coprocessor</b> was {{included}} on-chip. Using IBM's multichip module (MCM) technology, NexGen combined the 586 and 587 {{die in a}} single package. The new device, which used the same pinout as its predecessor, was marketed as the Nx586-PF100 to distinguish it from the FPU-less Nx586-P100.|$|E
50|$|In {{particular}} hardware abstraction {{does not}} involve abstracting the instruction set, which generally falls under the wider concept of portability. Abstracting the instruction set, when necessary (such as for handling the several revisions to the x86 instruction set, or emulating a missing <b>math</b> <b>coprocessor),</b> is performed by the kernel, or via hardware virtualization.|$|E
50|$|The 8086/8088 {{could be}} {{connected}} to a mathematical coprocessor to add hardware/microcode-based floating-point performance. The Intel 8087 was the standard <b>math</b> <b>coprocessor</b> for the 8086 and 8088, operating on 80-bit numbers. Manufacturers like Cyrix (8087-compatible) and Weitek (not 8087-compatible) eventually came up with high-performance floating-point coprocessors that competed with the 8087, {{as well as with}} the subsequent, higher-performing Intel 80387.|$|E
