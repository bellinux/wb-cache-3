13|10000|Public
50|$|The {{description}} of the audio-visual content is not a superficial task and {{it is essential for}} the effective use of this type of archives. The standardization system that deals with audio-visual descriptors is the MPEG-7 (<b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group</b> - 7).|$|E
40|$|The {{emerging}} {{digital audio}} and video compression technology brings both an opportunity and a new challenge to IC design. The pervasive application of compression technology to consumer electronics will require high volume, low cost IC's and fast time to market of the prototypes and production units. At the same time, the algorithms used in the compression technology result in complex VLSI IC's. The conflicting challenges of algorithm complexity, low cost, and fast time to market {{have an impact on}} device architecture and design methodology. The work presented in this paper is about the design of a dedicated, high precision, <b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group</b> (MPEG) audio decoder...|$|E
30|$|Multi-view video coding (MVC) is a video coding {{standard}} that reduces {{a large amount}} of MVV data. It was developed by the Joint Video Team (JVT), an organization jointly created by the Video Coding Expert Group and the <b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group</b> (MPEG) [5]. In general, the computational complexity of a video codec for MVV proportionally increases with the number of views. However, the complexity of MVC is far beyond the independent encoding of each view because of the exhaustive search for inter-view prediction, a key technique in MVC, and it leads to excessive power consumption and works as an obstacle for practical use. Therefore, it is necessary to decrease the computational complexity of MVC.|$|E
50|$|Beginning in {{the late}} 1980s, a {{standardization}} body called the <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> (MPEG) developed generic standards for coding of both audio and video. Subband coding resides {{at the heart of}} the popular MP3 format (more properly known as MPEG-1 Audio Layer III), for example.|$|R
5000|$|He was {{a member}} of the MPEG (<b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group)</b> and was {{involved}} in creation of the audio specifications for the MPEG standard, commonly known as MP3. He is a named inventor on 6 US Patents that were developed in the creation of the Rhapsody music streaming service. 8,738,7898,131,8657,792,7877,099,8487,020,637 6,611,813 ...|$|R
50|$|The first {{digital video}} coding {{standard}} was H.120, created by ITU in 1984. H.120 was not usable in practice, as its performance was too poor. Its 1988 successor, ITU's H.261, {{was the first}} practical video coding standard. MPEG-1, designed by the <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group,</b> followed in 1991, and MPEG-2/H.262 in 1994.|$|R
40|$|There are {{a number}} of {{different}} video compression standards. Most of them are variations of the work of two different committees. The International Telephony Union’s Specialist Group on Coding for Visual Telephony and the International Standards Organization’s <b>motion</b> <b>picture</b> <b>expert</b> <b>group,</b> known as MPEG. The most popular standards are the ISO’s MPEG- 2 and the ITU’s H. 261. MPEG- 2 has been chosen to simulate video application. We study link utilization, WAN clouds, and message sources for compressed data and uncompressed data. The study includes Video application [...] The bandwidth used for simulation runs depends on the type of application under study. The bandwidth is divided into five percentages, 50 %, 60 %, 70 %, 80 %, and 90 % (traffic intensity) for the purpose of study...|$|E
40|$|Abstract—After the {{profound}} success of defining H. 264 /AVC video coding standard in 2002, ITU-T Video Coding Experts Group (VCEG) started a Next-generation Video Coding (NGVC) project. The original target {{is to achieve}} 50 % bit rate re-duction {{at about the same}} video quality. In the past a few years, researchers have been very actively searching for new or improved technologies that can achieve this goal. After several years ’ struggle, in January 2010, the ISO/IEC <b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group</b> (MPEG) and VCEG jointly issued a call-for-proposal for the “High Efficiency Video Coding (HEVC) ”. At the April VCEG/MPEG meeting, 27 proposals were evaluated and the results seem to be promising. Consequently, a “new” video standard may be defined in two years. We will present a limited and maybe biased view on this subject. I...|$|E
40|$|This paper {{gives an}} {{overview}} of shape dissimilarity measure properties, such as metric and robustness properties, and of retrieval performance measures. Fifteen shape similarity measures are shortly described and compared. Since an objective comparison of their qualities seems to be impossible, experimental comparison is needed. The <b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group</b> (MPEG), a working group of ISO/IEC has defined the MPGE- 7 standard for description and search of audio and visual content. A region based and a contour based shape similarity method {{are part of the}} standard. The data set created by the MPEG- 7 committee for evaluation of shape similarity measures offers an excellent possibility for objective experimental comparison of the existing approaches evaluated based on the retrieval rate. Their retrieval results on the MPEG- 7 Core Experiment Core Experiment Shape- 1 test set as reported in the literature and obtained by a reimplementation are compared and discussed. To compare the performance of similarity measures, we built the framework SIDESTEP [...] Shape-based Image Delivery Statistics Evaluation Project, [URL]...|$|E
3000|$|... rtPS: rtPS is {{designed}} to support real-time service flows with variable-size packets generated at periodic intervals (i.e., variable bit rate--VBR), such as <b>Motion</b> <b>Pictures</b> <b>Experts</b> <b>Group</b> (MPEG) video. Based on a polling mechanism to request bandwidth periodically, this service can guarantee QoS such as the minimum data rate and maximum latency for VBR real-time applications.|$|R
40|$|This paper {{describes}} an algorithm for frequency scanning of DCT coefficients {{which has been}} submitted to MPEG (<b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group)</b> {{in contrast to the}} well-known block scanning technique. With respect to coding of the scanned coefficients, an entropy coding method, Modified Universal Variable Length Coding (MUVLC), is employed. In the test model (TM) system of MPEG the coding efficiency of MUVLC and the MPEG VLC was compared. The results showed that the MUVLC technique gives higher coding efficiency and more flexibility in a broadcast environment...|$|R
40|$|Abstract. This paper {{introduces}} an {{implementation and}} structure of a video codec (coder-decoder) using Vector Quantization (VQ) in the program Matlab. It also aims on the VQ weak and strong features and it describes an ex-periment with turning the advantages into concrete profit in video data compression. We would like to aim also on usage in video – MPEG 4 (<b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group)</b> standard – or in compressing the scientific (high resolu-tion) images. In conclusion we are comparing our ap-proach with other image compression methods with objec-tive and subjective criteria of image quality perception...|$|R
40|$|Abstract-Networked {{real time}} video {{applications}} in a wireless and mobile environment {{bring a new}} level of collaboration and communication to the future battlefield. Providing video services with certain deterministic guarantees in a resource limited and error prone wireless network is a challenge. The inefficiency of bandwidtb utilization and degradation of Quality of Service (QoS) are the issues have to be considered. To solve these problems this paper proposes a “QoS aware Selective Repeat Automatic Repeat Request (QSR-ARQ) ” scheme. This scheme not only utilizes the layer properties of <b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group</b> (MPEG) compressed video frames and their QoS requirements to increase bandwidth efficiency, but aLso considers tbe timing boundaries of different data sections in the video frames to achieve high receiving quality. A priority-based scheduler is also proposed. This scheduler is used in conjunction with the QSR-ARQ to achieve low delay and high throughput without sacrificing video quality. A computer simulation was used to compare the performance of the proposed protocol with a conventional SR-ARQ. Au asymmetric implementation is also considered for both sender and receiver with different complexity requirements. The potential military application is that combat soldiers may use this scheme to receive real time video information...|$|E
40|$|Video is the {{sequence}} of images played with respect to time. The successive images are highly correlated with each other. Video compression algorithms take the advantage of this fact. Only the residual information is transmitted using the technique called as block based motion estimation and motion compensation [2]. MPEG 1 (<b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group),</b> MPEG 2, MPEG 4, H. 261, H. 263, H. 264 are the ancestors of H. 265. Work on the emerging “Advanced Video Coding” (AVC) standard now known as ITU-T(International Telecommunication Union) Recommendation H. 264 and as ISO 14496 (International Organization For Standards) (MPEG- 4) Part 10 has dominated the video coding standardization community. The work has been stimulating, intense, dynamic, and all-consuming {{for those of us}} most deeply involved in its design. The time has arrived to see what has been accomplished. The new H. 264 /AVC & Enhanced version H. 265 standard is designed to provide a technical solution, the H. 265 is the latest video compression technique in which 50 % of bit rate is saved more than H. 264 and broad range of applications, including broadcast over cable, satellite, cable modem, and terrestrial. It finds the applications in interactive or serial storage on optical and magnetic storage devices, DVDs (Digital Video Disk). Conventional services over Ethernet, LAN (Local Area Network), wireless and mobile network and mobile...|$|E
40|$|In this paper, {{we propose}} a fuzzy logic-based control scheme for {{real-time}} <b>motion</b> <b>picture</b> <b>expert</b> <b>group</b> (MPEG) video to avoid long delay or excessive loss at the user-network interface (UNI) in an {{asynchronous transfer mode}} (ATM) network. The system consists of a shaper whose role is to smooth the MPEG output traffic to reduce the burstiness of the video stream. The input and output rates of the shaper buffer are controlled by two fuzzy logic-based controllers. To avoid a long: delay at the shaper, the first controller aims to tune the output rate of the shaper in the video frame time scale {{based on the number}} of available transmission credits at the UNI and the occupancy of the shaper's buffer. Based on the average occupancy of the shaper's buffer and its variance, the second controller tunes the input rate to the shaper over a much larger time scale by applying a closed-loop MPEG encoding scheme. With this approach, the traffic enters the network at an almost constant bit rate (CBR) (with a very small variation) allowing simple network management functions such as admission control and bandwidth allocation, while guaranteeing a relatively constant video quality since the encoding rate is changed only in critical periods when the shaper buffer "threatens" to overflow. The performance of the proposed scheme is evaluated through numerical tests on real video sequences...|$|E
40|$|This memo {{provides}} {{information for the}} Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2003). All Rights Reserved. This document describes a Uniform Resource Name (URN) namespace for the <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> (MPEG) for naming persistent resources {{as part of the}} MPEG standards. Example resources include technical documents and specifications, eXtensible Markup Language (XML) Schemas, classification schemes, XML Document Type Definitions (DTDs), namespaces, style sheets, media assets, and other types o...|$|R
40|$|The {{extraction}} of motion and shape information of three-dimensional objects from their two-dimensional projections {{is a task}} that emerges in Various applications such as computer vision, biomedical engineering, and video coding and mining especially after the recent guidelines of the <b>Motion</b> <b>Pictures</b> <b>Expert</b> <b>Group</b> regarding MPEG- 4 and MPEG- 7 standards. Present work establishes a novel approach for extracting the motion and shape parameters of a rigid three-dimensional object {{on the basis of}} its orthographic projections and the associated motion field. Experimental results have been included to verify the theoretical analysis...|$|R
50|$|The {{company has}} been {{established}} in the video delivery domain since the late 1980s when the <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> (MPEG) was created with the purpose of deriving a standard for the coding of moving pictures and audio. As a video headend division of the French electronics Thomson group, now known as Technicolor SA, the company developed and manufactured MPEG-2 and MPEG-4/AVC video encoding and networking equipment based on advanced compression algorithms. Since 2011, the division has become an independent private held company with a financial structure backed by the public/private Venture Capital, FCDE.|$|R
40|$|Includes bibliographical {{references}} (p. 47 - 49). With {{the rapid}} growth of wireless multimedia services, the demand for video transmission over wireless channels has been increasingly exponentially. This has led to the design of error resiliency schemes for obtaining better codecs. The perceptual video quality is influenced not only by the compression artifacts, but also by the channel errors. Hence, a video codec needs to accommodate contradictory requirements: coding efficiency and robustness to data loss, along with other limitations such as memory, bandwidth, real time coding and complexity. In this thesis, we have studied the comparative performance of two prominent open source H. 264 AVC video codecs - Joint Model (JM) and Fast Forward <b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group</b> (FFMPEG). We have studied various features of these codecs, such as macroblock tree rate control, multi-pass encoding, and psychovisual optimization model (it includes the parameters like adaptive quantization, psy-RD and psy-trellis). Observations based on the PSNR values and rate-control have been used to analyze the objective video quality for error-free and corrupted bitstreams generated by both codecs. In addition, we have analyzed the creation of different priorities based on cumulative mean squared error (CMSE) values for dividing the I, P and B video frames into four priorities. These studies helped us in understanding which codec can be more robust against channel errors or losses and how we can improve their performance...|$|E
30|$|In WiMAX {{networks}} (IEEE 802.16 e, to be precise) of {{the five}} QoS classes, {{three of them are}} used for real time traffic which are the Unsolicited Grant Services (UGS), Real Time Polling Service (rtPS) and Extended Real Time Polling Service (ertPS). The other two classes used are the non-real time traffic which consist of the Non Real Time Polling Service (nrtPS) and the Best Effort Service (BE) [15]. The UGS class provides a fixed periodic traffic flow with a Constant Bit Rate (CBR) real-time traffic without any form of QoS guarantees. An example of this includes the Voice over Internet Protocol (VoIP) without silence suppression [2, 12, 14 – 17]. The rtPS class supports real time traffic flow that generates Variable Bit Rate (VBR) with QoS guarantees in a periodical manner. An example of such traffic are the <b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group</b> (MPEG), video conferencing and streaming [2, 12, 14 – 17]. The nrtPS class is for non-real time VBR traffic with no QoS guarantees (i.e. delay). However, it can provide guarantees in terms of high throughput. The File Transfer Protocol (FTP) application belongs to this class [2, 12, 14 – 17]. The BE class has no QoS guarantees and neither guarantees delay nor throughput. This class generates variable sized packet application such as the Hypertext Transport Protocol (HTTP) and the electronic mail (email) [4, 15, 17]. As mentioned earlier the ertPS class in the 802.16 e has been created with the objective of exploiting the advantages of UGS and rtPS class [2]. As opposed to the UGS class, this class is designed to support VoIP traffic with silence suppression and the traffic flow generates variable sized packets. These packets are coupled with QoS guarantees and space which are generated in a periodical manner [2, 12, 14 – 17].|$|E
40|$|Abstract. This paper {{proposes a}} novel {{fault-tolerant}} disk subsystem named Zoned-RAID (Z-RAID). Z-RAID improves {{the performance of}} traditional RAID system by utilizing the zoning property of modern disks which provides multiple zones with different data transfer rates in a disk. This study proposes to optimize data transfer rate of RAID system by constraining placement of data blocks in multi-zone disks. We apply Z-RAID for multimedia database servers such as video servers that require a high data transfer rate as well as fault tolerance. Our analytical and experimental results demonstrate the superiority of ZRAID to conventional RAID. Z-RAID provides a higher effective data transfer rate in normal mode with no disadvantage. In {{the presence of a}} disk failure, Z-RAID still performs as well as RAID. 1 Introduction Recent years have witnessed the proliferation of multimedia databases, especiallyhandling streaming media types such as digital audio and video, with the wide acceptance of the public and the industry. These media have become a part ofeveryday life including not only electronic consumer products but also online streaming media services on the Internet. Due to 1) successful standards forcompression and file formats, such as MPEG (<b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group),</b> 2) increased network capacity for local area networks (LAN) and the Internet, and 3) advanced streaming protocols (e. g., Real Time Streaming Protocol, RTSP), more and more multimedia database applications, combined with the Internet,are providing streaming media services such as remote viewing of video clips. Streaming media (SM) have two main characteristics. First, SM data mustbe displayed at a pre-specified rate. Any deviation from this real-time requirement may result in undesirable artifacts, disruptions, and jitters, collectivelytermed hiccups. Second, SM objects are large in size. For example, the size of a two-hour MPEG- 2 encoded digital movie requiring 4 Mb/s for its display i...|$|E
40|$|AbstractÐThe {{extraction}} of motion and shape information of three-dimensional objects from their two-dimensional projections {{is a task}} that emerges in various applications such as computer vision, biomedical engineering, and video coding and mining especially after the recent guidelines of the <b>Motion</b> <b>Pictures</b> <b>Expert</b> <b>Group</b> regarding MPEG- 4 and MPEG- 7 standards. Present work establishes a novel approach for extracting the motion and shape parameters of a rigid threedimensional object {{on the basis of}} its orthographic projections and the associated motion field. Experimental results have been included to verify the theoretical analysis. Index TermsÐ 3 D motion, 3 D structure, structure from motion, orthography. ...|$|R
40|$|Abstract—Wireless {{channels}} {{are characterized by}} high time-varying bit-error rates (BERs). To cope with this problem, several adaptive forward-error-correction (AFEC) schemes have been proposed in the literature. They work locally at the wireless link, adding a variable amount of redundancy to the transmitted data {{in order to maintain}} the packet error rate below an acceptable level. However, when such schemes are utilized, the bandwidth offered to the applications changes when channel conditions change. In this paper, the effects of these bandwidth variations are investigated in the case of real-time <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> (MPEG) video transmission. The MPEG encoder is controlled in order to adapt its emission rate to the current bandwidth offered by the wireless link. To this end, the encoding quality is diminished by the source rate controller when the transmission rate has to be decreased due to an increase in the channel BER, whereas it is improved when the transmission rate can be increased due to a decrease in the channel BER. A Markov-based model, denoted as SBBP/SBBP/ 1 /K, has been introduced to model the scenario being considered. The analytical framework allows evaluation of the performance of the system and can be used to optimize the design of a video transmission system for wireless channels, providing the instruments to derive the tradeoff between information corruption in the wireless channel and MPEG video encoding quality. Index Terms—Forward error correction (FEC), <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> (MPEG), quality of service (QoS), switched batch Bernoulli process (SBBP), wireless channels. I...|$|R
40|$|Fast Forward <b>Motion</b> <b>Pictures</b> <b>Expert</b> <b>Group</b> (FFmpeg) is a well-known, high performance, cross {{platform}} open source library for recording, streaming, and playback of {{video and audio}} in various formats, namely, <b>Motion</b> <b>Pictures</b> <b>Expert</b> <b>Group</b> (MPEG), H. 264, Audio Video Interleave (AVI), {{just to name a}} few. With FFmpeg current licensing options, it is also suitable for both open source and commercial software development. FFmpeg contains over 100 open source codecs for video encoding and decoding. Given the complexities of MPEG standards, FFmpeg still lacks a framework for (1) seeking to a particular image frame in a video, which is needed for accurate annotation at the frame level for applications in fields such as medical domain, digital communications and commercial video broadcasting and (2) motion vectors extraction for analysis of motion patterns in video content. Most importantly, FFmpeg code base is not well documented, which has raised a significant difficulty for developing an extension. As our contributions, we extended FFmpeg code base to include new APIs and libraries support accurate frame-level seek, motion vector extraction, and MPEG- 2 video encoding/decoding. We documented FFmpeg MPEG- 2 codec to facilitate future software development. We evaluated the performance of our implementation against a high-performance third-party commercial software development kit on videos captured from television broadcasts and from endoscopy procedures. To evaluate the usability of our libraries, we integrated them with some commercial applications. In the following sections, we will discuss our software architecture, important implementation details, performance evaluation results, and lessons learned...|$|R
40|$|Two new technologies, the FASTexpedition and Remote FAST, {{have been}} {{developed}} that provide remote, 3 D (three dimensional), high resolution, dynamic, interactive viewing of scientific data. The FASTexpedition permits one to access scientific data from the World Wide Web, take guided expeditions through the data, and continue with self controlled expeditions through the data. Remote FAST permits collaborators at remote sites to simultaneously view an analysis of scientific data being controlled {{by one of the}} collaborators. Control can be transferred between sites. These technologies are now being used for remote collaboration in joint university, industry, and NASA projects. Also, NASA Ames Research Center has initiated a project to make scientific data and guided expeditions through the data available as FASTexpeditions on the World Wide Web for educational purposes. Previously, remote visualization of dynamic data was done using video format (transmitting pixel information) such as video conferencing or MPEG (<b>Motion</b> <b>Picture</b> <b>Expert</b> <b>Group)</b> movies on the Internet. The concept for this new technology is to send the raw data (e. g., grids, vectors, and scalars) along with viewing scripts over the Internet and have the pixels generated by a visualization tool running on the viewers local workstation. The visualization tool that is currently used is FAST (Flow Analysis Software Toolkit). The advantages of this new technology over using video format are: (1) The visual is much higher in resolution (1280 x 1024 pixels with 24 bits of color) than typical video format transmitted over the network. (2) The form of the visualization can be controlled interactively (because the viewer is interactively controlling the visualization tool running on his workstation). (3) A rich variety of guided expeditions through the data can be included easily. (4) A capability is provided for other sites to see a visual analysis of one site as the analysis is interactively performed. Control of the analysis can be passed from site to site. (5) The scenes can be viewed in 3 D using stereo vision. (6) The network bandwidth for the visualization using this new technology is much smaller than when using video format. (The measured peak bandwidth used was 1 Kbit/sec whereas the measured bandwidth for a small video picture was 500 Kbits/sec.) This talk will illustrate the use of these new technologies and present a proposal for using these technologies to improve science education...|$|E
40|$|As {{known as}} MP 3 {{and it is}} a {{standard}} for audio compression that makes any music file smaller with little or no loss of sound quality. MP 3 is part of MPEG, an acronym for <b>Motion</b> <b>Pictures</b> <b>Expert</b> <b>Group,</b> a family of standards for displaying video and audio using loss compression. Compression scheme used to transfer audio files via the Internet and store in portable players and digital audio servers. The MP 3 player is the well-used device nowadays and apart of the users are the athletes. There are several large companies such like Sony Corporation, Philips, Panasonic, Aiwa and Apple produced their own design and brand new MP 3 players...|$|R
40|$|The paper {{describes}} a subband coding algorithm {{which has been}} submitted to MPEG (<b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group)</b> for subjective testing during the Kurihama meeting in November 1991. It presents {{the current state of}} the authors' investigations, most of which have been carried out in the framework of the collaboration of the European projects VADIS and COST 211. The main idea is to achieve a simple but robust coding scheme which is flexible enough to handle future requirements, such as TV and HDTV compatibilities. The field merged frames are coded in 16 subbands. Motion compensated prediction of the frames reduces the temporal redundancy. The results obtained show that subband coding is a competitive alternative to other coding methods...|$|R
40|$|Status of this Memo This {{document}} specifies an Internet standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "Internet Official Protocol Standards " (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2003). All Rights Reserved. The <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> (MPEG) Committee (ISO/IEC JTC 1 /SC 29 WG 11) is a working group in ISO that produced the MPEG- 4 standard. MPEG defines tools to compress content such as audio-visual information into elementary streams. This specification defines a simple, but generic RTP payload format for transport of any nonmultiplexed MPEG- 4 elementary stream...|$|R
40|$|Abstract—This paper {{investigates the}} {{application}} of multicode spread-spectrum code-division multiple-access (SS-CDMA) tech-niques to three-dimensional (3 -D) stereoscopic video transmission over wireless asynchronous transfer mode (ATM) networks. Three-dimensional visual communications, made {{through the use of}} stereoscopic images, are able to achieve total display realism. Such services allow users to share the virtual reality (VR) world without any geographical restrictions. In order to create a 3 -D system with two images (left and right) that should be transmitted over a bandlimited mobile channel simultaneously, a cost-effective <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> (MPEG) -based wavelet multires-olution coding with a joint motion and disparity compensation is developed to reduce a large amount of information contained in the images to meet the low-transmission rate limitation of mobile channels. However, the rapidly variable bit rate (VBR) charac...|$|R
40|$|This paper {{evaluates the}} {{performance}} capabilities of configurable mechanisms and protocols, {{to be exploited}} by the multimedia quality-of service (QoS) management activities. The evaluation method is simulation based on the protocol formal specification, avoiding to build a special model dedicated to performance evaluation, and using the same formal specification as written for validation {{and implementation of the}} protocol. Therefore predictions on the performance, can be done in the early stage of the protocol development. A case study is considered – <b>Motion</b> <b>Pictures</b> <b>Expert</b> <b>Group</b> (MPEG) video compression mechanism and Xpress Transport Protocol (XTP 4. 0). It is shown, with simulation results and examples, that the MPEG and the XTP rate control mechanism performance models gives QoS estimations, good enough to realize efficient multimedia QoS and resource management based on configurable mechanism and protocols, like MPEG video and XTP. I...|$|R
40|$|Current video {{transmission}} and distribution systems at CERN {{use a variety of}} analogue techniques which are several decades old. It will soon be necessary to replace this obsolete equipment, and the opportunity therefore exists to rationalize the diverse systems now in place. New standards for digital {{transmission and distribution}} are now emerging. This paper gives an overview of these new standards and of the underlying technology common to many of them. The paper reviews Digital Video Broadcasting (DVB), the <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> specifications (MPEG 1, MPEG 2, MPEG 4, and MPEG 7), videoconferencing standards (H. 261 etc.), and packet video systems, together with predictions of the penetration of these standards into the consumer market. The digital transport mechanisms now available (IP, SDH, ATM) are also reviewed, and the implication of widespread adoption of these systems on {{video transmission}} and distribution is analysed...|$|R
40|$|The {{requirement}} of continuous retrieval, {{and the presence}} of multiple media streams whose display must proceed in a mutually synchronized manner are the distinguishing features that are unique to digital multimedia. In the emerging international multimedia encoding standard MPEG, continuity and synchronization are handled at different layers of the multimedia stream. We discuss how they are specified and propose techniques for their implementation within a distributed multimedia environment. ii 1 1 Introduction Multimedia services, in which stored media objects are retrieved on demand by end users, are rapidly emerging to be offered on digital communication networks. There are two distinguishing requirements of media playback: intra-media continuity and inter-media synchronization [6]. In the emerging international multimedia encoding standard MPEG (<b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group),</b> continuity and synchronization are handled at different layers of the multimedia stream. In this paper, [...] ...|$|R
40|$|The <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> (MPEG) - 1 audio {{compression}} algorithm is an International Organization for Standardization (ISO) standard for high fidelity {{audio compression}}. MPEG- 1 provides three layers, with increasing {{degree of complexity}} of implementation and quality of compression. Layer I uses a 32 sub-band filter bank for decomposing the input signal into sub-sampled spectral components, for subsequent quantization and coding using rules of psychoacoustics. The filter bank is not a perfect reconstruction system. Layer III refines the spectral resolution of the Layer I by further processing its output using Modified Discrete Cosine Transform. This hybrid system suffers from several defects. In this paper, we rectify these problems using a unified filter bank that has temporal resolution and frequency selectivity identical to the hybrid system. In addition, it provides Perfect Reconstruction. A feasible design example is also presented...|$|R
40|$|We {{present a}} {{real-time}} MPEG (<b>Motion</b> <b>Pictures</b> <b>Expert</b> <b>Group)</b> software decoder that uses message-passing libraries such as MPL, p 4, and MPI. The parallel MPEG decoder currently {{runs on the}} IBM SP system but can be easily ported to other parallel machines. This paper discusses our parallel MPEG decoding algorithm {{as well as the}} parallel programming environment under which it uses. Several technical issues are discussed, including balancing of decoding speed, memory limitation, I/O capacities, and optimization of MPEG decoding components. This project shows that a real-time portable software MPEG decoder is feasible in a general-purpose parallel machine. Keywords: Image processing, high-performance computing, video compression, real-time system, message-passing library. 1 Introduction Video compression is a crucial technique in coping with large amounts of digitized video data. MPEG is an industrial standard of video and associated audio compression for digital media storage and transmiss [...] ...|$|R
40|$|Teleradiology allows {{contemporaneous}} {{interpretation of}} imaging exams performed at {{some distance from}} the interpreting radiologist. The transmitted images are usually static. However, there is benefit to real-time review of full-motion ultrasound (US) exams as they are performed. Telesonography is transmission of full-motion sonographic data to a remote site. We hypothesize that US exams, read after having been compressed utilizing <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> version 4 (MPEG- 4) compression scheme, transmitted over the Internet as streaming multimedia, decompressed, and displayed, are equivalent in diagnostic accuracy to reading the examinations locally. MPEG- 4 uses variable compression on each image frame to achieve a constant output bit rate. With less compression, the bit rate rises, and the only way the encoder can contain bit rate within the set bandwidth is by lowering frame rate or reducing image quality. We review the relevant technologies and industry standard components that will enable low-cost telesonography...|$|R
40|$|This {{tutorial}} {{covers the}} theory behind MPEG/audio compression. This algorithm {{was developed by the}} <b>Motion</b> <b>Picture</b> <b>Experts</b> <b>Group</b> (MPEG), as an International Organization for Standardization (ISO) standard for the high fidelity compression of digital audio. The MPEG/audio compression standard is one part of a multiple part standard that addresses the compression of video (11172 - 2), the compression of audio (11172 - 3), and the synchronization of the audio, video, and related data streams (11172 - 1) to an aggregate bit rate of about 1. 5 Mbits/sec. The MPEG/audio standard also can be used for audio-only applications to compress high fidelity audio data at much lower bit rates. While the MPEG/audio compression algorithm is lossy, often it can provide "transparent", perceptually lossless, compression even with compression factors of 6 -to- 1 or more. The algorithm works by exploiting the perceptual properties of the human auditory system. This paper also will cover the basics of psychoacoustic mo [...] ...|$|R
