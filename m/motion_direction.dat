912|1001|Public
50|$|We {{can also}} use prior {{constraints}} on the camera motion. By analyzing different images of the same point can obtain {{a line in the}} direction of motion. The intersection of several lines is the point at infinity in the <b>motion</b> <b>direction,</b> and one constraint on the affine structure.|$|E
50|$|The <b>motion</b> <b>direction</b> of a contour is ambiguous, {{because the}} motion {{component}} {{parallel to the}} line cannot be inferred based on the visual input. This means {{that a variety of}} contours of different orientations moving at different speeds can cause identical responses in a motion sensitive neuron in the visual system.|$|E
50|$|Each MAFOR {{broadcast}} {{is followed by}} a brief technical synopsis of the current weather map in plain language. The synopsis gives the location of the centers of significant high and low pressure areas, and their forecast <b>motion</b> (<b>direction</b> and speed). Reference is occasionally made to marked wind shift lines, giving the anticipated time at which the wind shift will occur at key points.|$|E
40|$|When human {{subjects}} discriminate <b>motion</b> <b>directions</b> of two visual stimuli, their discrimination improves with practice. This improved performance {{has been found}} to be specific to the practiced directions and does not transfer to new <b>motion</b> <b>directions.</b> Indeed, such stimulus-specific learning has become a trademark finding in almost all perceptual learning studies and has been used to infer the loci of learning in the brain. For example, learning in motion discrimination has been inferred to occur in the visual area MT (medial temporal cortex) of primates, where neurons are selectively tuned to <b>motion</b> <b>directions.</b> However, such <b>motion</b> discrimination task is extremely difficult, as is typical of most perceptual learning tasks. When the difficulty is moderately reduced, learning transfers to new <b>motion</b> <b>directions.</b> This result challenges the idea of using simple visual stimuli to infer the locus of learning in low-level visual processes and suggests that higher-level processing is essential even in “simple” perceptual learning tasks...|$|R
40|$|SummaryFunctional neuroimaging has {{successfully}} identified brain areas that show greater responses to visual motion [1 – 3] and adapted responses to repeated <b>motion</b> <b>directions</b> [4 – 6]. However, such {{methods have been}} thought to lack the sensitivity and spatial resolution to isolate direction-selective responses to individual motion stimuli. Here, we used {{functional magnetic resonance imaging}} (fMRI) and pattern classification methods [7 – 10] to show that ensemble activity patterns in human visual cortex contain robust direction-selective information, from which it is possible to decode seen and attended <b>motion</b> <b>directions.</b> Ensemble activity in areas V 1 –V 4 and MT+/V 5 allowed us to decode which of eight possible <b>motion</b> <b>directions</b> the subject was viewing on individual stimulus blocks. Moreover, ensemble activity evoked by single <b>motion</b> <b>directions</b> could effectively predict which of two overlapping <b>motion</b> <b>directions</b> was the focus of the subject's attention and presumably dominant in perception. Our results indicate that feature-based attention can bias direction-selective population activity in multiple visual areas, including MT+/V 5 and early visual areas (V 1 –V 4), consistent with gain-modulation models of feature-based attention and theories of early attentional selection. Our approach for measuring ensemble direction selectivity may provide new opportunities to investigate relationships between attentional selection, conscious perception, and direction-selective responses in the human brain...|$|R
40|$|Functional neuroimaging has {{successfully}} identified brain areas that show greater responses to visual motion [1 – 3] and adapted responses to repeated <b>motion</b> <b>directions</b> [4 – 6]. However, such {{methods have been}} thought to lack the sensitivity and spatial resolution to isolate direction-selective responses to individual motion stimuli. Here, we used {{functional magnetic resonance imaging}} (fMRI) and pattern classification methods [7 – 10] to show that ensemble activity patterns in human visual cortex contain robust direction-selective information, from which it is possible to decode seen and attended <b>motion</b> <b>directions.</b> Ensemble activity in areas V 1 –V 4 and MT+/V 5 allowed us to decode which of eight possible <b>motion</b> <b>directions</b> the subject was viewing on individual stimulus blocks. Moreover, ensemble activity evoked by single <b>motion</b> <b>directions</b> could effectively predict which of two overlapping <b>motion</b> <b>directions</b> was the focus of the subject’s attention and presumably dominant in perception. Our results indicate that feature-based attention can bias direction-selective population activity in multiple visual areas, including MT+/V 5 and early visual areas (V 1 –V 4), consistent with gain-modulation models of feature-based attention and theories of early attentional selection. Our approach for measuring ensemble direction selectivity may provide new opportunities to investigate relationships between attentional selection, conscious perception, and direction-selective responses in the human brain. Results In this study, we investigated whether ensemble activity patterns in the human visual cortex contain sufficiently reliable direction-selective information to decode see...|$|R
50|$|Locomotives of {{this series}} were built with two types of gearbox: first 1P154 had one speed range (factory designation: Ls150), {{and the other a}} quadruple gearbox 1P154/2 with two speed ranges (factory designation: 2Ls150). Accordingly, the former had a maximal speed of 25.7 km/h, and the letter was capable of 45.8 km/h.Gearbox {{steering}} is of mechanical-hydraulic type, while fuel dosing and <b>motion</b> <b>direction</b> change is mechanical.|$|E
50|$|The {{ability of}} a subject to detect {{coherent}} motion is commonly tested using motion coherence discrimination tasks. For these tasks, dynamic random-dot patterns (also called random dot kinematograms) are used that consist in 'signal' dots moving {{in one direction and}} 'noise' dots moving in random directions. The sensitivity to motion coherence is assessed by measuring the ratio of 'signal' to 'noise' dots required to determine the coherent <b>motion</b> <b>direction.</b> The required ratio is called the motion coherence threshold.|$|E
50|$|McKenzie and Morgan {{determined}} {{that there were}} 16 types of triple junction theoretically possible, though several of these are speculative and have not necessarily been seen on earth. These junctions were classified firstly by the types of plate boundaries meeting - for example RRR, TTR, RRT, FFT etc. - and secondly by the relative motion directions of the plates involved. Some configurations such as RRR can only have one set of relative motions whereas TTT junctions may be classified into TTT(a) and TTT(b). These differences in <b>motion</b> <b>direction</b> affect the stability criteria.|$|E
40|$|This paper {{proposes a}} method for reconstructing {{qualitative}} positions of multiple vision sensors from qualitative information observed by the vision sensors, i. e., <b>motion</b> <b>directions</b> of moving objects. In order to directly acquire the qualitative positions of points, the method proposed in this paper iterates the following steps: 1) observing <b>motion</b> <b>directions</b> (left or right) of moving objects with the vision sensors, 2) classifying the vision sensors into ######### ########## ##### based on the <b>motion</b> <b>directions,</b> 3) acquiring ##### ##### ###########, and 4) propagating the constraints. Compared with the previous methods, which reconstruct the environment structure from quantitative measurements and acquire qualitative representations by abstracting it, this paper focuses on how to acquire qualitative positions of landmarks from low-level, simple, and reliable information (that is, qualitative). The method has been evaluated with simulations and also verified with observation error...|$|R
30|$|Individual {{observations}} must be {{put together}} into a coherent picture that provides information about relevant global parameters such as density distribution, <b>motion</b> <b>directions,</b> turbulence etc.|$|R
5000|$|These {{detectors}} detect different <b>motion</b> <b>directions</b> and are modeled from neurons in monkey V1/2 {{and area}} MTThe {{output of the}} local motion detectors are the following: ...|$|R
50|$|Rivers: River symbol {{meanings}} {{deal with}} <b>motion,</b> <b>direction,</b> {{and the flow}} of our thoughts {{as well as our}} lives. When the river in the ace of wands Tarot card flows into our psychic vision it is a message that we must consider the direction we are taking in our lives. Specifically, since the ace of wands deals with passion and energy, we may want to consider where our actions are taking us. Take the time to reassess your goals and be confident you are heading in the life direction you desire.|$|E
5000|$|Its most {{distinguishing}} feature {{was that the}} cab and firebox were {{at the front of}} the locomotive instead of the traditional rear. This was done essentially by running a 2-8-8-4 machine backwards with myriad modifications. The engineer and fireman swapped sides and faced away from the firebox. The tender was moved to behind the [...] "new" [...] locomotive back to improve forward vision. The smoke box end coupling was strengthened. The power reverse lever (Johnson Bar) and the steam throttle <b>motion</b> <b>direction</b> was reversed. The drive wheel axles are reversed, end for end without rekeying the return [...] "fly" [...] cranks, to reverse the expansion link timing on both sides.|$|E
50|$|The third theory {{contends that}} there is greater {{interference}} of object-based attention when any flanking distractors (e.g., visual scene crowding or noise) are present. Particularly, if these distractors {{belong to the same}} object or object-group as that being attended (noise similar), as opposed to coming from different objects (noise dissimilar) — irrespective of the distinguishing characteristics of the objects themselves (e.g., colour, <b>motion</b> <b>direction,</b> shape, orientation). An influencing element is that an object-like representation can engage attention even when it is not the intended target of a visual search. Therefore, an important consideration is that the perceptual resemblance between distractors and a target object influences the efficiency of visual search; increases in similarity among the distractors, increases search efficiency. Similarly, visual search efficiency increases the less similar the target is to the distractors.|$|E
40|$|When {{multiple}} <b>motion</b> <b>directions</b> {{are presented}} simultaneously {{within the same}} region of the visual field human observers see motion transparency. This perceptual phenomenon requires from the visual system to separate different motion signal distributions, which are characterised by distinct means that correspond to the different dot directions and variances that {{are determined by the}} signal and processing noise. Averaging of local motion signals can be employed to reduce noise components, but such pooling could at the same time lead to the averaging of different directional signal components, arising from spatially adjacent dots moving in different directions, which would reduce the visibility of transparent directions. To study the theoretical limitations of encoding transparent motion by a biologically plausible motion detector network, the distributions of <b>motion</b> <b>directions</b> signalled by a motion detector model (2 DMD) were analysed here for Random Dot Kinematograms (RDKs). In sparse dot RDKs with two randomly interleaved <b>motion</b> <b>directions,</b> the angular separation that still allows us to separate two directions is limited by the internal noise in the system. Under the present conditions direction differences down to 30 deg could be separated. Correspondingly, in a transparent motion stimulus containing multiple <b>motion</b> <b>directions,</b> more than eight directions could be separated. When this computational analysis is compared to some published psychophysical data, it appears that the experimental results do not reach the predicted limits. Whereas the computer simulations demonstrate that even an unsophisticated motion detector network would be appropriate to represent a considerable number of <b>motion</b> <b>directions</b> simultaneously within the same region, human observers usually are restricted to seeing not {{more than two or three}} directions under comparable conditions. This raises the question why human observers do not make full use of information that could be easily extracted from the representation of motion signals at the early stages of the visual system...|$|R
40|$|Abstract. Taking the wavelet {{decomposed}} approximate {{image as}} the main research object, a direction estimation method for moving object was proposed in this paper. Firstly, the approximate image for {{the frame of the}} video was obtained via wavelet decomposition; and furthermore, the motion estimation on the approximate image was achieved to obtain the motion vectors. Finally, the motion vectors were described as polar coordinate form to compute the number of motion vectors in specified angles and the information entropy of the <b>motion</b> <b>directions.</b> The experiment results show that the proposed method can remove the effect of noise and the results of direction estimation are consistent with the actual <b>motion</b> <b>directions...</b>|$|R
40|$|AbstractAdaptation was {{studied in}} a {{paradigm}} {{in which the}} adapting stimulus was a variably biased version of a bistable apparent motion stimulus, a motion quartet, and the post-adaptation test stimulus was a “neutral” motion quartet. Either horizontal or vertical motion was perceived, never {{both at the same}} time. When only one of these was perceived during the entire adaptation phase of a trial, and the perceived motion was highly stable, adaptation effects were greater for the perceived than the unperceived <b>motion</b> <b>directions</b> (i. e., adaptation was selective to the perceived motion). However, when the perceived motion during adaptation was relatively unstable (i. e., when the perceived motion was more likely to spontaneously change directions), similar levels of adaptation were obtained for perceived as well as unperceived, but possible <b>motion</b> <b>directions.</b> Thus, adaptation occurs prior to the determination of which of the competing <b>motion</b> <b>directions</b> will be perceived. The relationship between the stability of the adapting percept and the selectivity of adaptation is explained in terms of differences in the activation of mutually inhibitory horizontal and vertical motion detectors. Copyright © 1996 Elsevier Science Ltd...|$|R
5000|$|A popular {{explanation}} for the different reaction times of feature and conjunction searches is the feature integration theory (FIT), introduced by Treisman and Gelade in 1980. This theory proposes that certain visual features are registered early, automatically, and are coded rapidly in parallel across the visual field using preattentive processes.Experiments show that these features include luminance, colour, orientation, <b>motion</b> <b>direction,</b> and velocity, {{as well as some}} simple aspects of form. For example, a red X can be quickly found among any number of black Xs and Os because the red X has the discriminative feature of colour and will [...] "pop out." [...] In contrast, this theory also suggests that in order to integrate two or more visual features belonging to the same object, a later process involving integration of information from different brain areas is needed and is coded serially using focal attention. For example, when locating an orange square among blue squares and orange triangles, neither the colour feature [...] "orange" [...] nor the shape feature [...] "square" [...] is sufficient to locate the search target. Instead, one must integrate information of both colour and shape to locate the target.|$|E
50|$|The {{rocks of}} the Western belt {{comprise}} dominantly sedimentary rocks including greywacke and mudstone that have undergone deformation. In {{the southern part}} of the Western Belt the rocks have undergone folding as the main type of deformation. The Western Belt is generally separated from the Central Belt by the Melones fault zone which also distinguishes between the metamorphic rocks of the Western and Central Belts of the Sierra Nevada Mountains. The Western Belt rocks are interpreted to be a part of the Slate Creek terrane, which was accreted onto the western margin of North America at approximately 150 Ma. The age of these rocks was dated using potassium-argon dating (K-Ar). At the western foothills of the Sierra Nevada Mountains there are numerous dikes that have intruded the rocks that range in age from 148-155 Ma. These dikes are proposed to have been formed when the North American plate underwent a change in <b>motion</b> <b>direction</b> so that subduction was no longer occurring in a northeast direction but in the southeast direction. The shear sense along the dikes is a sinistral shear sense which indicates later southeast subduction of the oceanic plate.|$|E
40|$|AbstractMotion {{direction}} {{learning is}} known to be specific to the trained direction. However, in this study we used our recently developed TPE (training-plus-exposure) method to demonstrate that <b>motion</b> <b>direction</b> learning can transfer to an opposite direction. Specifically, we first replicated the strict direction specificity of <b>motion</b> <b>direction</b> learning with a group of moving dots. However, when the participants were exposed to the opposite direction in an irrelevant dot number discrimination task, either simultaneously with <b>motion</b> <b>direction</b> training or at a later time, but not in a reversed order, <b>motion</b> <b>direction</b> learning transferred to the opposite direction significantly and sometimes completely. These results suggest that <b>motion</b> <b>direction</b> learning may be a high-level process in which the brain learns the potentially transferrable rules of reweighting the <b>motion</b> <b>direction</b> inputs. However, we speculate that high-level learning may not functionally connect to sensory neurons that are tuned to other directions but are not stimulated during training, which leads to direction specificity. It is the stimulus exposure in TPE training that connects high-level learning to the exposed opposite direction to enable learning transfer...|$|E
40|$|The paper {{deals with}} the problem of motion {{planning}} of anthropomorphic mechanical hands avoiding collisions. The proposed approach tries to mimic the real human hand motions, but reducing the dimension of the search space in order to obtain results as a compromise between motion optimality and planning complexity (time) by means of the concept of principal <b>motion</b> <b>directions.</b> Basically, the work includes the following phases: capturing the human hand workspace using a sensorized glove and mapping it to the mechanical hand workspace, reducing the space dimension by looking for the most relevant principal <b>motion</b> <b>directions,</b> and planning the hand movements using a sampling-based roadmap planner. The approach has been implemented for a four finger anthropomorphic mechanical hand, and some examples are included to illustrate its validity. Postprint (published version...|$|R
40|$|It {{has been}} shown that humans cannot {{perceive}} more than three directions from a multidirectional motion stimulus. However, it remains unknown whether adapting to such imperceptible <b>motion</b> <b>directions</b> could generate <b>motion</b> aftereffects (MAEs). A series of psychophysical experiments were conducted to address this issue. Using a display consisting of randomly oriented Gabors, we replicated previous findings that observers were unable to perceive the global directions embedded in a five-direction motion pattern. However, adapting to this multidirectional pattern induced both static and dynamic MAEs, despite the fact that observers were unaware of any global <b>motion</b> <b>directions</b> during adaptation. Furthermore, by comparing the strengths of the dynamic MAEs induced at different levels of motion processing, we found that spatial integration of local illusory signals per se was sufficient to produce a significant global MAE. These psychophysical results show that the generation of a directional global MAE does not require conscious perception of the global motion during adaptation...|$|R
40|$|Trabajo presentado al ICRA 2009 celebrado en Kobe (Japón) del 12 al 17 de mayo. The paper {{deals with}} the problem of motion {{planning}} of anthropomorphic mechanical hands avoiding collisions. The proposed approach tries to mimic the real human hand motions, but reducing the dimension of the search space in order to obtain results as a compromise between motion optimality and planning complexity (time) by means of the concept of principal <b>motion</b> <b>directions.</b> Basically, the work includes the following phases: capturing the human hand workspace using a sensorized glove and mapping it to the mechanical hand workspace, reducing the space dimension by looking for the most relevant principal <b>motion</b> <b>directions,</b> and planning the hand movements using a sampling-based roadmap planner. The approach has been implemented for a four finger anthropomorphic mechanical hand, and some examples are included to illustrate its validity. This work was partially supported by the CICYT projects DPI 2007 - 63665 and DPI 2008 - 02448. Peer Reviewe...|$|R
40|$|International audienceIt {{is widely}} {{accepted}} that V 1 surround suppression mechanism {{plays a role}} in the end-stopping property of neurons in the primary visual cortex. But, what is not known is the extent of this mechanism to explain the <b>motion</b> <b>direction</b> perceived in MT neurons, and neither, the spatio-temporal content of the V 1 suppressive surrounds that maximizes the end-stopping property. Here we model different V 1 suppressive surrounds in order to maximize their end-stopping property and to characterize their spatio-temporal response. The output of these end-stopping V 1 neurons converge into a population of modeled MT neurons with different <b>motion</b> <b>direction</b> selectivity. We also evaluate the effect of the V 1 surround suppression mechanism in the <b>motion</b> <b>direction</b> seen by the population of MT neurons, how this <b>motion</b> <b>direction</b> depends on the V 1 end-stopping property, and how this <b>motion</b> <b>direction</b> fits psychophysical experiments regarding motion perception, such as, barberpoles, plaids type I, plaids type II and unikinetic plaids...|$|E
40|$|Recent {{research}} {{addresses the}} question whether motion information of multiple objects contributes to maintaining a selection of objects across a period of motion. Here, we investigate whether target and/or distractor motion information is used during attentive tracking. We asked participants to track four objects and changed either the <b>motion</b> <b>direction</b> of targets, the <b>motion</b> <b>direction</b> of distractors, neither, or both during a brief flash {{in the middle of}} a tracking interval. We observed that a single direction change of targets is sufficient to impair tracking performance. In contrast, changing the <b>motion</b> <b>direction</b> of distractors had no effect on performance. This indicates that target- but not distractor motion information is evaluated during tracking...|$|E
30|$|Local motion {{events were}} reduced {{in the final}} {{coherent}} <b>motion</b> <b>direction</b> discrimination experiment as noise was programmed as random position noise. The seal continued {{to work with a}} performance comparable to the previous coherent <b>motion</b> <b>direction</b> discrimination experiment with random direction noise which might indicate that local motion events had not played a crucial role during at least the coherent <b>motion</b> <b>direction</b> discrimination experiment using random direction noise. In our opinion, there was no other possibility than to solve the respective task by the analysis of the global motion of the display, thus by integrating information from a large field of view in this final experiment. It needs to be mentioned that coherent <b>motion</b> <b>direction</b> thresholds might even be lower in harbor seals since training was not continued and thus the seal might have not reached its best threshold performance under the respective experimental conditions. Furthermore, dot density was very low. Therefore, performance thus could potentially increase with a higher dot density, an effect that had been documented in phase 2 of the coherent motion detection experiment.|$|E
40|$|The {{visual system}} can detect {{coherent}} {{motion in the}} midst of motion noise. This is accomplished with motion-sensitive channels, each of which is tuned to a limited range of <b>motion</b> <b>directions.</b> Our aim was to show how a single channel is affected by motions both within and outside its tuning range. We used a psychophysical reverse-correlation procedure. An array of dots moved coherently with a new, randomly chosen, direction every 14 or 28 ms. Human subjects pressed a key whenever they saw upwards movement. The results were analyzed by finding two <b>motion</b> <b>directions</b> before each key-press: the first preceded the key-press by the reaction time, and the second preceded the first by a variable interval. There were two main findings. First, the subject was significantly more likely to press the key when the vector average of the two motions was in the target direction. This effect was short-lived: it was only seen for inter-stimulus intervals of several tens of milliseconds. Second, motion detection was reduced when the target direction was preceded by a <b>motion</b> of similar <b>direction</b> 100 – 200 ms earlier. The results support the idea that a motion-sensitive channel sums sub-optimal inputs, and is suppressed by similar motion in the long term...|$|R
40|$|The {{reported}} alignment {{between the}} projected spin-axes and proper <b>motion</b> <b>directions</b> of pulsars is revisited {{in the light}} of new data from Jodrell Bank and Effelsberg. The present investigation uses 54 pulsars, the largest to date sample of pulsars with proper-motion and absolute polarisation, to study this effect. Our study has found strong evidence for pulsar spin-velocity alignment, excluding that those two vectors are completely uncorrelated, with > 99...|$|R
40|$|AbstractWhen {{observers}} {{adapt to}} a transparent-motion stimulus, the resulting motion aftereffect (MAE) is typically in the direction opposite to the vector average of the component directions. It has been proposed {{that the reason for}} this is that it is the adaptation state at the local-level (i. e. of the local-motion-pooling units) that determines the nature of the MAE (Vidnyanszky et al. Trends in Cognitive Sciences, 6 (4), 157 – 161). The adapting stimuli used in these experiments typically consisted of random-dot kinematograms, with each dot being able to move over the entire viewing aperture. Here we used spatially-localised global-plaid stimuli which enabled us, over the course of adaptation, to present either one of both <b>motion</b> <b>directions</b> at each local region. A unidirectional MAE was perceived when two <b>motion</b> <b>directions</b> were presented at each location and a transparent MAE was perceived when a single direction was presented. These results support the notion that it is the adaptation state at the local-motion-pooling level that determines the nature of the MAE to transparent motion stimuli...|$|R
40|$|The {{present study}} {{examined}} {{the degree to which}} the perception of change in <b>motion</b> <b>direction</b> is delayed, compared with that in color, depending on the motion velocity, by using detection and prediction tasks. In Experiment 1, stimulus patterns abruptly reversed color and changed their direction of motion synchronously,and observers were asked to respond when they perceived the reversal of a particular attribute. The detection times for changes in color were 60 - 70 ms shorter than those for changes in <b>motion</b> <b>direction</b> of the same patterns. Further, the detection times decreased with the velocity of pattern motion, except for the stationary pattern. In Experiment 2,after the color and <b>motion</b> <b>direction</b> of the test patterns changed synchronously and then disappeared, observers were asked to predict the temporal period of one change cycle. The predicted times for the change in color were shorter than those for the change in <b>motion</b> <b>direction.</b> The predicted times increased with the velocity of pattern motion. The relationship between the influences of velocity and perceptual asynchrony are discussed...|$|E
40|$|To {{perceive}} multiple overlapping {{surfaces in}} the same location of the visual field (transparency), the visual system must determine which surface elements belong together, and should be integrated, and which should be kept apart. Spatial relations between surfaces, such as depth order, must also be determined. This paper details two experiments examining the interaction of <b>motion</b> <b>direction</b> and disparity cues on the perception of depth order and surface segmentation in transparency. In Experiment 1, participants were presented with random-dot stereograms, where transparent planes were defined by differences in <b>motion</b> <b>direction</b> and disparity. Participants reported the direction of motion of the front surface. Results revealed marked effects of <b>motion</b> <b>direction</b> on perceived depth order. These biases interact with disparity in an additive manner, suggesting that the visual system integrates <b>motion</b> <b>direction</b> with other available cues to surface segmentation. This possibility was tested further in Experiment 2. Participants were presented with two intervals; one containing motion and disparity defined transparent planes, the other containing a volume of moving dots. Inter-plane disparity was varied to find thresholds for the correct identification of the transparent interval. Thresholds depended on motion direction: thresholds were lower when disparities and directions in the transparency interval matched participants’ preferred depth order, compared to conditions where disparity and direction were in conflict. These results suggest that <b>motion</b> <b>direction</b> influences the judgement of depth order even {{in the presence of}} other visual cues, and that the assignment of depth order may {{play an important role in}} segmentation...|$|E
40|$|Abstract: Recently, {{evidence}} has emerged for a radial orientation bias in early visual cortex. These results predict that in early visual cortex a tangential bias should be present for <b>motion</b> <b>direction.</b> We tested this prediction {{in a human}} imaging study, using a translating random dot pattern that slowly rotated its <b>motion</b> <b>direction</b> 360 in cycles of 54 s. In addition, polar angle and eccentricity mapping were performed. This allowed the measurement of the BOLD response across the visual representations of the different retinotopic areas. We found that, in V 1, V 2, and V 3, BOLD responses were consistently enhanced for centrifugal and centripetal motion, relative to tangential motion. The relative magnitude of the centrifugal and centripetal response biases changed with visual eccentricity. We found no <b>motion</b> <b>direction</b> biases in MTþ. These results {{are in line with}} previously observed anisotropies in motion sensitivity across the visual field. However, the observation of radial motion biases in early visual cortex is surprising considering the evidence for a radial orientation bias. An additional experiment was performed to resolve this apparent conflict in results. The additional experiment revealed that the observed <b>motion</b> <b>direction</b> biases most likely originate from anisotropies in long rang...|$|E
40|$|We {{predict a}} fast domain wall (DW) motion induced by a thermal {{gradient}} across a nanoscopic ferromagnetic stripe of MnBi. The driving mechanism is an exchange torque fueled by magnon accumulation at the DWs. Depending on {{the thickness of}} the sample, both hot-to-cold and cold-to-hot DW <b>motion</b> <b>directions</b> are possible. The finding unveils an energy efficient way to manipulate DWs as an essential element in magnetic information processing such as racetrack memory...|$|R
40|$|A {{model for}} {{self-organization}} of the coordinate transformations required for spatial reaching is presented. During a motor babbling phase, a mapping from spatial coordinate <b>directions</b> to joint <b>motion</b> <b>directions</b> is learned. After learning, {{the model is}} able to produce straight-line spatial velocity trajectories with characteristic bell-shaped spatial velocity profiles, as observed in human reaches. Simulation results are presented for transverse plane reaching using a two degree-of-freedom arm. Office of Naval Research (N 00014 - 92 -J- 1309...|$|R
50|$|Detection and {{discrimination}} of motion {{can be improved}} by training with long-term results. Participants trained to detect the movements of dots on a screen in only one direction become particularly good at detecting small movements in the directions around that {{in which they have}} been trained. This improvement was still present 10 weeks later. However perceptual learning is highly specific. For example, the participants show no improvement when tested around other <b>motion</b> <b>directions,</b> or for other sorts of stimuli.|$|R
