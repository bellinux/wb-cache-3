0|10000|Public
50|$|Though {{wholesalers}} buy {{primarily from}} manufacturers and sell mostly to retailers, industrial users and other wholesalers, they also perform <b>many</b> <b>value</b> added <b>functions.</b> The wholesaler, an intermediary, is used based on principles of specialization and {{division of labor}} as well as contractual efficiency.|$|R
50|$|<b>Many</b> complex <b>valued</b> <b>functions</b> with an attractor at {{the origin}} define a fractal when {{this aspect of}} their orbits' {{behavior}} is categorized. Some of the orbits are attracted to the origin; some are periodic; some are attracted to other attractors, including possibly an attractor at infinity.|$|R
40|$|In {{this paper}} an {{evolutionary}} technique for synthesizing Multi-Valued Logic (MVL) functions using Neural Network Deployment Algorithm (NNDA) is presented. The algorithm {{is combined with}} back-propagation learning capability and neural MVL operators. This research article is done to observe the anomalistic characteristics of MVL neural operators and their role in synthesis. The advantages of NNDA-MVL algorithm is demonstrated with realization of synthesized <b>many</b> <b>valued</b> <b>functions</b> with lesser MVL operators. The characteristic feature set consists of MVL gate count, network link count, network propagation delay and accuracy achieved in training. In brief, this paper depicts an effort of reduced network size for synthesized MVL functions. Trained MVL operators improve the basic architecture by reducing MIN gate and interlink connection by 52. 94...|$|R
40|$|In {{reinforcement}} learning, {{the goal}} is to seek rewards and avoid punishments. A simple scalar captures the value of a state or of taking an action, where expected future rewards increase and punishments decrease this quantity. Naturally an agent should learn to predict this quantity to take beneficial actions, and <b>many</b> <b>value</b> <b>function</b> approximators exist for this purpose. In the present work, however, we show how <b>value</b> <b>function</b> approximators can cause confusion between predictors of an outcome of one valence (e. g., a signal of reward) and the inhibitor of the opposite valence (e. g., a signal canceling expectation of punishment). We show this to be a problem for both linear and non-linear <b>value</b> <b>function</b> approximators, especially when the amount of data (or experience) is limited. We propose and evaluate a simple resolution: to instead predict reward and punishment values separately, and rectify and add them to get the value needed for decision making. We evaluate several function approximators in this slightly different <b>value</b> <b>function</b> approximation architecture and show that this approach is able to circumvent the confusion and thereby achieve lower value-prediction errors. Comment: 14 pages, 3 figures, 23 references, Workshop paper in ICLR 2014 (updated based on reviewer comments...|$|R
40|$|<b>Many</b> complex <b>valued</b> <b>functions</b> we {{encounter}} are entire functions. In order to classify such functions, maximum modulus function is introduced {{to measure the}} growth of an entire function. Naturally, minimum modulus function is also being defined and studied. In fact, the maximum and minimum moduli funcitons are closely related in some cases. The classical Wiman's theorem gives us an affirmative answer for all the entire functions of order strictly less than one. How about the meromorphic functions? What are {{the relationships between the}} maximum and minimm moduli of a meromorphic function? We will provide some partial answers in this thesis...|$|R
40|$|In packet switches, packets queue at switch {{inputs and}} contend for outputs. The {{contention}} arbitration policy directly affects switch performance. The best policy {{depends on the}} current state of the switch and current traffic patterns. This problem is hard because the state space, possible transitions, and set of actions all grow exponentially with the size of the switch. We present a reinforcement learning formulation of the problem that decomposes the <b>value</b> <b>function</b> into <b>many</b> small independent <b>value</b> <b>functions</b> and enables an efficient action selection. ...|$|R
40|$|AbstractWe {{study the}} {{integration}} and approximation problems for monotone or convex bounded functions {{that depend on}} d variables, where d can be arbitrarily large. We consider the worst case error for algorithms that use finitely <b>many</b> <b>function</b> <b>values.</b> We prove that these problems suffer from the curse of dimensionality. That is, one needs exponentially <b>many</b> (in d) <b>function</b> <b>values</b> to achieve an error ε...|$|R
40|$|We {{study the}} average case {{complexity}} of approximating functions or their integrals over R^d. Approximations (quadratures) are constructed based on finitely <b>many</b> <b>function</b> <b>values.</b> We consider these {{problems in a}} weighted sense, and we focus on how the complexity depends on the prior distribution and the weight. For the approximation problem, the proofs are constructive. For integration, general upper bounds are obtained by using Monte Carlo arguments...|$|R
40|$|AbstractWe {{define the}} number field analog of the zeta {{function}} of d-complex variables studied by Zagier in (First European Congress of Mathematics, vol. II (Paris, 1992), Progress in Mathematics, vol. 120, Birkhauser, Basel, 1994, pp. 497 – 512). We prove that {{in certain cases}} this function has a meromorphic continuation to Cd, and we identify the linear subvarieties comprising its singularities. We use our approach to meromorphic continuation to prove that there exist infinitely <b>many</b> <b>values</b> of these <b>functions</b> at regular points in their extended domains which can be expressed as a rational linear combination of values of the Dedekind zeta function...|$|R
40|$|We show that, {{associated}} with any complex root of unity ω, there exists a particularly simple 4 d-TQFT model M_ω defined on the cobordism category of Delta complexes. For an oriented closed 4 -manifold X of Euler characteristic χ(X), it is conjectured that the quantity N^ 3 χ(X) / 2 M_ω(X), where N is the order of ω, takes only finitely <b>many</b> <b>values</b> as a <b>function</b> of ω. In particular, it is equal to 1 for S^ 4, (3 +(- 1) ^N) / 2 for S^ 2 × S^ 2, and N^- 1 / 2 ∑_k= 1 ^Nω^k^ 2 for C P^ 2. Comment: 7 page...|$|R
40|$|The use of {{strategic}} alliances is growing as acquisitions and mergers often under-perform expectations. This research {{looks at the}} literature on strategic alliances to {{gain an understanding of}} the rationale for strategic alliances, organizational propensity to enter into strategic alliances and their effect on sustainable competitive advantage. The methodology is qualitative, based on twelve case studies of organizations, with five out-performing the industry and five under-performing. The cases are structured around the value chain and modified grounded theory is used to analyze the data and to gain {{a deeper understanding of the}} phenomenon. A wider range of reasons for entering alliances is substantiated and the theory concerning organizational propensity to enter into strategic alliances is supported. Strategic alliances are being used to perform <b>many</b> <b>value</b> chain <b>functions</b> as organizations are lacking in both capabilities and resources. These are being accessed by using strategic alliances in the search for differentiation, sustainable competitive advantage and superior performance...|$|R
2500|$|We {{are taking}} a sum of finitely <b>many</b> <b>function</b> <b>values</b> of , multiplied with the {{differences}} of two subsequent approximation points. We can easily see that the approximation is still too large. Using more steps produces a closer approximation, but will always be too high and will never be exact. Alternatively, replacing these subintervals by ones with the left end height of each piece, we will get an approximation that is too low: for example, with twelve such subintervals we will get an approximate value for the area of 0.6203.|$|R
40|$|Holomorphic {{functions}} are amazing because their values in an ever so small disk {{in the complex}} plane completely determine the <b>function</b> <b>values</b> at arbitrary points in their maximum possible domain. The process of extending such a function beyond its initial domain is called analytic continuation. We attempt to make this theoretic result tractable by computers. In the present article, we first prove that any algorithm for analytic continuation can generally not depend on finitely <b>many</b> <b>function</b> <b>values</b> only, without closer inspection of the function itself. We then derive a computable local bound on the step size between sampling points which yields an algorithm for analytic continuation of complex plane algebraic curves. Finally, we provide a numerical example demonstrating its practical use. 1...|$|R
40|$|Wetlands are {{resources}} {{of paramount importance}} with <b>many</b> <b>values</b> and <b>functions.</b> However, with the economy development and the population growth, wetlands have undergone great changes. This study investigated the land-cover and landscape pattern dynamics of Guide wetlands in the periods 1977 - 2006. Four Landsat images were used to locate and quantify the changes. The study revealed the area of wetlands previewed a downward trend during the past 30 years, whereas the area of cultivated land increased all the time. From 1997 to 2000, the wetland landscape pattern became more fragile and less connective. The landscape types converted to each other dramatically. During 2000 to 2006, both dominant and contagion indices on the whole area were enhanced. Its driving forces were analyzed according to socioeconomic development and climatic information. Remote sensing (RS) and Geographic information system (GIS) technologies {{have proved to be}} useful tools for assisting decision-makers to locate and quantify changes in land resources, and hence to identify appropriate solutions for sustainable management of wetlands. * Corresponding author. This is useful to know for communication with the appropriate person in cases with more than one author. 1...|$|R
40|$|AbstractThis is a {{follow-up}} paper of “Liberating the dimension for function approximation”, where we studied approximation of infinitely variate functions by algorithms that use linear information consisting of finitely many linear functionals. In this paper, we study similar approximation problems, however, now the algorithms can only use standard information consisting of finitely <b>many</b> <b>function</b> <b>values.</b> We {{assume that the}} cost of one <b>function</b> <b>value</b> depends on the number of active variables. We focus on polynomial tractability, and occasionally also study weak tractability. We present non-constructive and constructive results. Non-constructive results are based on known relations between linear and standard information for finitely variate functions, whereas constructive results are based on Smolyak’s construction generalized to the case of infinitely variate functions. Surprisingly, for many cases, the results for standard information are roughly the same as for linear information...|$|R
40|$|The {{class of}} {{generalized}} pattern search (GPS) algorithms for mixed variable optimization is extended to problems with stochastic objective functions. Because random {{noise in the}} objective function {{makes it more difficult}} to compare trial points and ascertain which points are truly better than others, replications are needed to generate sufficient statistical power to draw conclusions. Rather than comparing pairs of points, the approach taken here augments pattern search with a ranking and selection (R&S) procedure, which allows for comparing <b>many</b> <b>function</b> <b>values</b> simultaneously. Asymptotic convergence for the algorithm is established, numerical issues are discussed, and performance of the algorithm is studied on a set of test problems. Pattern search algorithms Mixed variable programming Nonlinear programming Simulation Ranking and selection...|$|R
5000|$|Classical measure {{theory is}} {{fundamentally}} non-constructive, since the classical definition of Lebesgue measure does not describe {{any way to}} compute the measure of a set or the integral of a function. In fact, if one thinks of a function just as a rule that [...] "inputs a real number and outputs a real number" [...] then there cannot be any algorithm to compute the integral of a function, since any algorithm would {{only be able to}} call finitely <b>many</b> <b>values</b> of the <b>function</b> at a time, and finitely <b>many</b> <b>values</b> are not enough to compute the integral to any nontrivial accuracy. The solution to this conundrum, carried out first in Bishop's 1967 book, is to consider only functions that are written as the pointwise limit of continuous functions (with known modulus of continuity), with information about the rate of convergence. An advantage of constructivizing measure theory is that if one can prove that a set is constructively of full measure, then there is an algorithm for finding a point in that set (again see Bishop's book). For example, this approach can be used to construct a real number that is normal to every base.|$|R
40|$|Abstract. This article {{studies the}} problem of {{approximating}} functions belonging to a Hilbert space Hd with an isotropic or anisotropic Gaussian reproducing kernel, d∑ Kd(x,t) = exp − γ 2 ℓ (xℓ −tℓ) 2 for all x,t ∈ R d. ℓ= 1 The isotropic case corresponds to using the same shape parameters for all coordinates, namely γℓ = γ> 0 for all ℓ, whereas the anisotropic case corresponds to varying shape parameters γℓ. We are especially interested in moderate to large d. We consider two classes of algorithms: (1) using finitely many arbitrary linear functionals, (2) using only finitely <b>many</b> <b>function</b> <b>values.</b> The pertinent error criterion is the worst case of such an algorithm over the unit ball in Hd, with the error for a single function given by the L 2 norm also with a Gaussian weight...|$|R
40|$|In {{the second}} half of the nineteenth century in New South Wales the {{introduction}} and spread of mass schooling added a significant workload to the lives of most children. The ideal of modern schooling placed children in a classroom, morning and afternoon, five days a week, for most weeks of the year. In effect the schoolroom became a kind of workplace, albeit unpaid. Schoolwork became a given for nearly all children, whatever their household's societal position. Socio-economic status, race and gender affected and mediated a child's experience of schooling, but they did not remove children from the school experience. The school system functioned to reproduce and impart values considered important by the respectable and powerful in society. The mass schooling program established remains in place today. Consolidated and extended, it nevertheless retains and continues <b>many</b> original <b>values</b> and <b>functions,</b> and still prescribes experience and containment for children. children, schooling, New South Wales...|$|R
40|$|AbstractVariants of the {{brightness}} {{function of a}} convex body K in Rn are investigated. The Lambertian lightness function LK(v,w) gives the total reflected light resulting from illumination by a light source at infinity in the direction w that is visible when looking in the direction v. The partial brightness function RK(v,w) gives {{the area of the}} projection orthogonal to v of the portion of the surface of K that is both illuminated by a light source from the direction w and visible when looking in the direction v. A class of functions called lightness functions is introduced that includes LK and RK as special cases. Much of the theory of {{the brightness}} function—uniqueness, stability, and the existence and properties of convex bodies of maximal and minimal volume with finitely <b>many</b> <b>function</b> <b>values</b> equal to those of a given convex body—is extended to lightness functions...|$|R
40|$|The Cumulative Prospect Theory (CPT) uses {{piecewise}} <b>value</b> <b>functions</b> {{instead of}} consumer utility and provides alternative assumptions for investment behaviour approximated by power <b>value</b> <b>function.</b> In this study, our aim {{to find a}} generalized <b>value</b> <b>function</b> {{that will make the}} <b>value</b> <b>function</b> introduced by Kahneman-Tversky (1992) a special case. This functional form of the <b>value</b> <b>function</b> determine the appropriate parameter of the <b>values</b> <b>function.</b> We believe that if one can approximate the original CPT <b>value</b> <b>function</b> by other types of functions, the optimization problem and the many other implications can be compared to choose the best model depending on the focus of the problems. This, eventually, could result in improving the theory in both theoretical and empirical points of views. utility theory; prospect theory; expected utility; portfolio optimization,...|$|R
40|$|Consider a given <b>value</b> <b>function</b> on {{states of}} a Markov {{decision}} problem, as {{might result from}} applying a reinforcement learning algorithm. Unless this <b>value</b> <b>function</b> equals the corresponding optimal <b>value</b> <b>function,</b> at some states {{there will be a}} discrepancy, which is natural to call the Bellman residual, between what the <b>value</b> <b>function</b> specifies at that state and what is obtained by a one-step lookahead along the seemingly best action at that state using the given <b>value</b> <b>function</b> to evaluate all succeeding states. This paper derives a tight bound on how far from optimal the discounted return for a greedy policy based on the given <b>value</b> <b>function</b> will be {{as a function of the}} maximum norm magnitude of this Bellman residual. A corresponding result is also obtained for <b>value</b> <b>functions</b> defined on state-action pairs, as are used in Q-learning. One significant application of these results is to problems where a function approximator is used to learn a <b>value</b> <b>function,</b> with training of the approxi [...] ...|$|R
3000|$|... ∗, which {{replicates}} a <b>value</b> <b>function</b> {{equal to}} the optimal <b>value</b> <b>function</b> such that V(t,x,y)=J(t,x,y,π [...]...|$|R
50|$|Loosely speaking, Bellman error points {{towards the}} optimal <b>value</b> <b>function.</b> The {{sequence}} of BEBF form a basis space which is orthogonal {{to the real}} <b>value</b> <b>function</b> space; thus with sufficient number of BEBFs, any <b>value</b> <b>function</b> can be represented exactly.|$|R
5000|$|If [...] is such {{a complex}} <b>valued</b> <b>function,</b> it may be {{decomposed}} aswhere [...] and [...] are real-valued functions. In other words, {{the study of the}} complex <b>valued</b> <b>functions</b> reduces easily {{to the study of the}} pairs of real <b>valued</b> <b>functions.</b>|$|R
40|$|We {{study in}} this paper the first-order {{behavior}} of <b>value</b> <b>functions</b> in parametric dynamic programming with linear constraints and nonconvex cost functions. By establishing an abstract result on the Frechet subdifferential of <b>value</b> <b>functions</b> of parametric mathematical programming problems, some new formulas on the Frechet subdifferential of <b>value</b> <b>functions</b> in parametric dynamic programming are obtained. Dynamic programming <b>Value</b> <b>functions</b> Frechet normal cones Frechet subgradients The Frechet subdifferential...|$|R
40|$|The {{problem of}} {{estimating}} the <b>value</b> <b>function</b> underlying a Markovian reward process is considered. As {{it is well}} known, the <b>value</b> <b>function</b> underlying a Markovian reward process satisfied a linear fixed point equation. One approach to learning the <b>value</b> <b>function</b> from finite data {{is to find a}} good approximation to the <b>value</b> <b>function</b> in a given (linear) subspace of the space of <b>value</b> <b>functions.</b> We review {{some of the issues that}} arise when following this approach, as well as some results that characterize the finite-sample performance of some of the algorithms...|$|R
40|$|With every real <b>valued</b> <b>function,</b> {{of a real}} argument, can be {{associated}} a matrix function mapping a linear space of symmetric matrices into itself. In this paper we study directional differentiability properties of such matrix functions associated with directionally differentiable real <b>valued</b> <b>functions.</b> In particular, we show that matrix <b>valued</b> <b>functions</b> inherit semismooth properties of the corresponding real <b>valued</b> <b>functions.</b> Key words: matrix function, eigenvalues and eigenvectors, directional derivatives, semismooth mapping...|$|R
40|$|We {{study the}} fuzzy Henstock and the fuzzy McShane {{integrals}} for fuzzy-number <b>valued</b> <b>functions.</b> The {{main purpose of}} this paper is to establish the following decomposition theorem: a fuzzy-number <b>valued</b> <b>function</b> is fuzzy Henstock integrable if and only if it can be represented as a sum of a fuzzy McShane integrable fuzzy-number <b>valued</b> <b>function</b> and of a fuzzy Henstock integrable fuzzy number <b>valued</b> <b>function</b> generated by a Henstock integrable function...|$|R
40|$|The <b>value</b> <b>function</b> {{of complex}} fuzzy is {{widespread}} in fuzzy control; discussions of complex fuzzy <b>value</b> <b>function</b> integral properties have important {{theoretical and practical}} significance. In this paper, firstly, the concept and the operation rules of fuzzy number and the expression of complex fuzzy value functionf~~(x) =(f~ 1 (x),f~ 2 (x)) are introduced, and the Riemann integral definition of the complex fuzzy <b>value</b> <b>function</b> f~~(x) =(f~ 1 (x),f~ 2 (x)) is given under the new order relation of meaning. Based on the definition of r-cut set is given, the <b>value</b> <b>function</b> of complex fuzzy is turned to interval <b>valued</b> <b>function</b> using r-cut set, then complex fuzzy <b>value</b> <b>function</b> integral expression is given with extension principle. In addition, the properties of integral fuzzy-valued function are discussed, and interval additivity, inequality sex and linearity on the real coefficient and complex coefficient of the complex fuzzy <b>value</b> <b>function</b> integral are obtained...|$|R
40|$|The <b>value</b> <b>{{function}}</b> of a mixed-integer linear program (MILP) is {{a function}} that returns the optimal solution <b>value</b> as a <b>function</b> of the right-hand side. In this paper, we analyze {{the structure of the}} <b>value</b> <b>function</b> of a MILP with a single constraint. We show that the <b>value</b> <b>function</b> is uniquely determined by a finite number of break points and at most two slopes. We derive conditions for the <b>value</b> <b>function</b> to be continuous and analyze its behavior where it is discontinuous. We also propose a method for systematically extending the <b>value</b> <b>function</b> from a neighborhood of the origin to the entire real line using the technique of maximal subadditive extension...|$|R
40|$|<b>Value</b> <b>function</b> {{iteration}} {{is one of}} {{the standard}} tools for the solution of the Ramsey model. We compare six different ways of <b>value</b> <b>function</b> iteration with regard to speed and precision. We find that <b>value</b> <b>function</b> iteration with cubic spline interpolation between grid points dominates the other methods in most cases. For the initialization of the <b>value</b> <b>function</b> over a fine grid, modified policy function iteration over a coarse grid and subsequent linear interpolation between the grid points provides a very efficient way to reduce computational time. <b>value</b> <b>function</b> iteration, policy function iteration, Howard’s algorithm, acceleration, cubic interpolation, stochastic Ramsey model...|$|R
40|$|In this paper, we {{introduce}} a novel method for {{the discovery of}} <b>value</b> <b>functions</b> for Markov decision processes (MDPs). This method, which we call <b>value</b> <b>function</b> discovery (VFD), is based on ideas from the evolutionary algorithm field. VFDs key feature is that it discovers descriptions of <b>value</b> <b>functions</b> that are algebraic in nature. This feature is unique, because the descriptions include the model parameters of the MDP. The algebraic expression of the <b>value</b> <b>function</b> discovered by VFD {{can be used in}} several scenarios, e. g., conversion to a policy (with one-step policy improvement) or control of systems with time-varying parameters. The work in this paper is a first step toward exploring potential usage scenarios of discovered <b>value</b> <b>functions.</b> We give a detailed description of VFD and illustrate its application on an example MDP. For this MDP, we let VFD discover an algebraic description of a <b>value</b> <b>function</b> that closely resembles the optimal <b>value</b> <b>function.</b> The discovered <b>value</b> <b>function</b> is then used to obtain a policy, which we compare numerically to the optimal policy of the MDP. The resulting policy shows near-optimal performance {{on a wide range of}} model parameters. Finally, we identify and discuss future application scenarios of discovered <b>value</b> <b>functions...</b>|$|R
40|$|The {{piecewise}} power <b>value</b> <b>function</b> {{proposed by}} Kahneman and Tversky {{is inconsistent with}} both theoretical and experimental work. We propose the expo-power function {{as an alternative to}} the power function and examine its ability to explain choices in Allais experiments. Cumulative prospect theory Expo-power <b>value</b> <b>function</b> Exponential <b>value</b> <b>function...</b>|$|R
40|$|A {{representation}} changer is {{a function}} that converts a concrete representation of an abstract value into a different concrete representation of that <b>value.</b> <b>Many</b> useful <b>functions</b> can be recognised as representation changers; examples include compilers, and arithmetic functions such as addition and multiplication. Functions that can be specified as the right inverse of other functions are special cases of representation changers. In recent years, a number of authors have used a relational calculus to derive representation changers from their specifications. In this paper we show that the generality of relations is not essential, and representation changers can be derived within the more basic setting of functional programming. We illustrate our point by deriving a carry-save adder and a base-converter, two functions which have previously been derived relationally. 1 Introduction In the calculational approach to programming {{the aim is to}} derive programs from their specifications by a p [...] ...|$|R
40|$|We {{establish}} {{the existence of}} a solution to the optimality equation for discounted finite Markov decision processes by means of Birkhoff's fixed point theorem. The proof yields the well-known linear programming formulation for the optimal <b>value</b> <b>function</b> while its dual characterizes the optimal <b>value</b> <b>function</b> as the maximum over all <b>value</b> <b>functions...</b>|$|R
