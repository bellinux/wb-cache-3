319|0|Public
25|$|Peripherals {{released}} for the PlayStation include memory cards, the PlayStation Mouse, the PlayStation Analog Joystick, the PlayStation Link Cable, the Multiplayer Adapter (a four-player multitap), the Memory Drive (a {{disk drive}} for 3.5 inch floppy disks), the GunCon (a light gun), and the Glasstron (a <b>monoscopic</b> head-mounted display).|$|E
2500|$|A second {{approach}} in gesture detecting using appearance-based models uses image sequences as gesture templates. Parameters for this method are either the images themselves, or certain features derived from these. Most of the time, only one ( [...] <b>monoscopic)</b> or two ( [...] stereoscopic [...] ) views are used.|$|E
50|$|The output {{signals from}} the LGN {{determine}} the spatial dimensions of the stereoscopic and <b>monoscopic</b> portions of the horopter of the visual system.|$|E
5000|$|A second {{approach}} in gesture detecting using appearance-based models uses image sequences as gesture templates. Parameters for this method are either the images themselves, or certain features derived from these. Most of the time, only one ( [...] <b>monoscopic)</b> or two ( [...] stereoscopic [...] ) views are used.|$|E
50|$|Peripherals {{released}} for the PlayStation include memory cards, the PlayStation Mouse, the PlayStation Analog Joystick, the PlayStation Link Cable, the Multiplayer Adapter (a four-player multitap), the Memory Drive (a {{disk drive}} for 3.5 inch floppy disks), the GunCon (a light gun), and the Glasstron (a <b>monoscopic</b> head-mounted display).|$|E
5000|$|Obtaining {{satellite}} images {{is also an}} expensive endeavor. High resolution stereo images (0.5 m resolution) cost around €11,000. Image satellites include Quikbird, Ikonos. High resolution <b>monoscopic</b> images cost around €5,500. Somewhat lower resolution images (e.g. from the CORONA satellite; with a 2 m resolution) cost around €1.000 per 2 images. Note that Google Earth images are too low in resolution to make an accurate 3D model.|$|E
5000|$|A single camera {{can also}} be used if the subject remains {{perfectly}} still (such as an object in a museum display). Two exposures are required. The camera can be moved on a sliding bar for offset, or with practice, the photographer can simply shift the camera while holding it straight and level. This method of taking stereo photos is sometimes referred to as the [...] "Cha-Cha" [...] or [...] "Rock and Roll" [...] method. [...] It is also sometimes referred to as the [...] "astronaut shuffle" [...] because it was used to take stereo pictures {{on the surface of the}} moon using normal <b>monoscopic</b> equipment.|$|E
50|$|Most {{360-degree}} {{video is}} <b>monoscopic</b> (2D), {{meaning that it}} {{is viewed as a}} one (360x180 equirectangular) image directed to both eyes. Stereoscopic video (3D) is viewed as two distinct (360x180 equirectangular) images directed individually to each eye. 360-degree videos are typically viewed via personal computers, mobile devices such as smartphones, or dedicated head-mounted displays. When viewed on PCs, the mouse is typically used to pan around the video by clicking and dragging. On smartphones, internal sensors such as the gyroscope are used to pan the video based on the orientation of the device. Taking advantage of this behavior, devices such as Google Cardboard viewers and the Samsung Gear VR serve as stereoscope-style headset enclosures that a smartphone can be inserted into, for viewing this content in a virtual reality format. They emulate the operation of a dedicated head-mounted display, but utilizing the display of the phone itself and internal lenses, rather than containing dedicated screens of their own.|$|E
40|$|Gaze {{perception}} {{has received}} considerable research attention {{due to its}} importance in social interaction. The majority of recent studies have utilized <b>monoscopic</b> pictorial gaze stimuli. However, a <b>monoscopic</b> direct gaze differs from a live or stereoscopic gaze. In the <b>monoscopic</b> condition, both eyes of the observer receive a direct gaze, whereas in live and stereoscopic conditions, only one eye receives a direct gaze. In the present study, we examined {{the implications of the}} difference between <b>monoscopic</b> and stereoscopic direct gaze. Moreover, because research has shown that stereoscopy affects the emotions elicited by facial expressions, and facial expressions affect the range of directions where an observer perceives mutual gaze- the cone of gaze-we studied the interaction effect of stereoscopy and facial expressions on gaze perception. Forty observers viewed stereoscopic images wherein one eye of the observer received a direct gaze while the other eye received a horizontally averted gaze at five different angles corresponding to five interaxial distances between the cameras in stimulus acquisition. In addition to <b>monoscopic</b> and stereoscopic conditions, the stimuli included neutral, angry, and happy facial expressions. The observers judged the gaze direction and mutual gaze of four lookers. Our results show that the mean of the directions received by the left and right eyes approximated the perceived gaze direction in the stereoscopic semidirect gaze condition. The probability of perceiving mutual gaze in the stereoscopic condition was substantially lower compared with <b>monoscopic</b> direct gaze. Furthermore, stereoscopic semidirect gaze significantly widened the cone of gaze for happy facial expressions. Peer reviewe...|$|E
40|$|Error {{concealment}} for stereoscopic images receives {{little attention}} in research of image processing. While many {{methods have been}} proposed for monocular images, this paper considers a concealment strategy for block loss in stereoscopic image pairs, utilizing the information of the associated image to fulfill the higher quality demand. We present a hybrid approach, combining a 2 D projective transformation and a <b>monoscopic</b> error concealment technique. Pixel values from the associated stereo image are warped to their corresponding positions in the lost block. To reduce discontinuities at the block borders, a <b>monoscopic</b> error concealment algorithm with low-pass properties is integrated. The stereoscopic depth perception is much less affected in our approach than using only <b>monoscopic</b> error concealment techniques...|$|E
40|$|Optimal {{presentation}} of three-dimensional {{information on a}} two-dimensional display screen requires careful design of the projection to the display surface. <b>Monoscopic</b> perspective projection alone is usually not sufficient to represent three-dimensional spatial information. It can, however, be improved by the adjustment of perspective parameters and by geometric visual enhancements such as reference lines and a background grid. Stereoscopic display is another method of providing three-dimensional information to the human operator. Two experiments are performed with three-axis manual tracking tasks. The first experiment investigates the effects of perspective parameters on tracking performance. The second experiment investigates the effects of visual enhancements for both <b>monoscopic</b> and stereoscopic displays. Results indicate that, although stereoscopic displays do generally permit superior tracking performance, <b>monoscopic</b> displays can allow equivalent performance when they are defined with optimal perspective parameters and provided with adequate visual enhancements...|$|E
40|$|This study {{investigated}} transfer-of-training for a pick-and-place task in <b>monoscopic,</b> stereoscopic, and real-world environments. Ten training trials {{were given to}} 30 subjects in the three environments (10 subjects each). The averages of task completion time in the stereoscopic and real-world environments were less {{than those in the}} <b>monoscopic</b> environment. In a post-training real-world trial, there were no differences due to the training environment (including another group of 10 subjects who received no training). Subjects, who had training in the stereoscopic or real-world environments, were more accurate in the placement of cans at near targets than those who received <b>monoscopic</b> or no training. Thus training in a virtual stereoscopic environment was beneficial in terms of task accuracy. The effectiveness of virtual environments may continue to improve as advances in computer hardware enable higher resolution presentations and reduce system lags...|$|E
40|$|The {{present study}} {{investigated}} the ability to interactively locate points in a three dimensional computer environment using a six degree of freedom input device. Four different visual feedback modes were tested: fixed viewpoint <b>monoscopic</b> perspective, fixed viewpoint stereoscopic perspective, head-tracked <b>monoscopic</b> perspective and head-tracked stereoscopic perspective. Targets were located at plus and minus 10 cm along the X, Y or Z axes, from a fixed starting location. Data about the time {{to complete the task}} and positioning accuracy (error) are gathered for each trial. In addition, subjective feedback regarding the apparatus, visual mode and task difficulty was solicited from subjects. The results indicate that stereoscopic performance is superior to <b>monoscopic</b> performance and that asymmetries exist both across and within axes. Head tracking had no appreciable effect upon performance. Subjective feedback regarding performance is usually consistent with objective measures, but some in [...] ...|$|E
40|$|International audienceWe discuss touch-based {{navigation}} of 3 D visualizations in {{a combined}} <b>monoscopic</b> and stereoscopic viewing environment. We identify {{a set of}} interaction modes, and a workflow that helps users transition between these modes to improve their interaction experience. In our discussion we analyze, in particular, the control-display space mapping between the different reference frames of the stereoscopic and <b>monoscopic</b> displays. We show how this mapping supports interactive data exploration, but may also lead to conflicts between the stereoscopic and <b>monoscopic</b> views due to users' movement in space; we resolve these problems through synchronization. To support our discussion, we present results from an exploratory observational evaluation with domain experts in fluid mechanics and structural biology. These experts explored domain-specific datasets using variations {{of a system that}} embodies the interaction modes and workflows; we report on their interactions and qualitative feedback on the system and its workflow...|$|E
40|$|We {{describe}} a new low-level scheme to achieve high definition 3 D-stereoscopy within the bandwidth of the <b>monoscopic</b> HDTV infrastructure. Our method uses a studio quality <b>monoscopic</b> high resolution color camera {{to generate a}} transmitted "main stream" view, and a flanking 3 D-stereoscopic pair of low cost, low resolution monochrome camera "outriggers" to generate a depth map of the scene. The depth map is deeply compressed and transmitted as a low bandwidth "auxiliary stream". The two streams are recombined at the receiver to generate a 3 D-stereoscopic pair of high resolution color views {{from the perspectives of}} the original outriggers. Alternatively, views from two arbitrary perspectives between (and, to a limited extent, beyond) the low resolution <b>monoscopic</b> camera positions can be synthesized to accommodate individual viewer preferences. We describe our algorithms, and the design and outcome of initial experiments. The experiments begin with three NTSC color images, degrade the outer p [...] ...|$|E
40|$|Aims: To compare <b>monoscopic</b> and {{stereoscopic}} {{assessment of}} the optic disc using novel software for the digital stereoscopic analysis of optic disc stereopairs. Methods: Software was developed for the stereoscopic display of digital optic disc images using an interlaced display method. Neuroretinal rim width was determined at 10 degree intervals around the optic disc using a custom (stereoscopic) cursor whose depth was adjusted to that of Elschnigâ€™s rim. Measurements were taken, first viewing the disc monoscopically and at a separate sitting, stereoscopically. Results: Measurements were made in 35 eyes from 35 patients (1260 estimates for each observer) using three observers. The mean cup to disc ratio (CDR) ranged from 0. 57 to 0. 66 (SD 0. 13 â€“ 0. 14) for <b>monoscopic</b> viewing compared with 0. 64 to 0. 69 (SD 0. 12 â€“ 0. 14) for stereoscopic viewing. Stereoscopic assessments gave higher CDRs in temporal, superior, nasal, and inferior aspects of the optic disc (p< 0. 001, Mann-Whitney U test). Agreement between observers in estimating CDR was high for <b>monoscopic</b> assessment (intraclass correlation coefficient 0. 74 (CI 0. 72 to 0. 76) increasing to 0. 80 (0. 78 to 0. 82) for stereoscopic assessment. Conclusion: Digital stereoscopic optic disc assessment provides lower estimates of neuroretinal rim width {{and higher levels of}} interobserver agreement compared with <b>monoscopic</b> assessments...|$|E
40|$|A {{teleoperation}} simulator {{has been}} constructed with vector display system, joysticks, and a simulated cylindrical manipulator, {{in order to}} quantitatively evaluate various display conditions. The first of two experiments thus conducted investigated the effects of perspective parameter variations on human operators' pick-and-place performance, using a <b>monoscopic</b> perspective display. The second experiment involved visual enhancements of the <b>monoscopic</b> perspective display, by adding a grid and reference lines, by comparison with visual enhancements of a stereoscopic display; results indicate that stereoscopy generally permits superior pick-and-place performance, but that monoscopy nevertheless allows equivalent performance when defined with appropriate perspective parameter values and adequate visual enhancements...|$|E
40|$|In {{this paper}} we {{investigate}} how different conditions aiding perception {{in an online}} Virtual Reality application affect depth perception. The VR was developed for parents experiencing feeding difficulties with their infants. The role of effective use of stereoscopic viewing, head tracking and animation is examined. In a complete block designed experiment {{subjects were asked to}} determine the positions of the spoon in the 3 D environment. Task was done under different conditions: the animation of the baby model was either on or off and four different viewing modes were used: <b>monoscopic</b> or stereoscopic viewing with or without head tracking. The use of head tracking improved the position perception when <b>monoscopic</b> vision without any animation applied. However, adding head tracking to stereo vision did not improve the position perception. The use of animation positively affected the judgment of depth perception under the <b>monoscopic</b> vision and makes it comparable with the performance under the head tracking mode. The outcome of this study provides insight into how to create more interactive scene and enhance depth-related visual tasks by exploiting dynamic scene changes...|$|E
40|$|Abstract—We discuss touch-based {{navigation}} of 3 D visualizations in {{a combined}} <b>monoscopic</b> and stereoscopic viewing environment. We identify {{a set of}} interaction modes, and a workflow that helps users transition between these modes to improve their interaction experience. In our discussion we analyze, in particular, the control-display space mapping between the different reference frames of the stereoscopic and <b>monoscopic</b> displays. We show how this mapping supports interactive data exploration, but may also lead to conflicts between the stereoscopic and <b>monoscopic</b> views due to users ’ movement in space; we resolve these problems through synchronization. To support our discussion, we present results from an exploratory observational evaluation with domain experts in fluid mechanics and structural biology. These experts explored domain-specific datasets using variations {{of a system that}} embodies the interaction modes and workflows; we report on their interactions and qualitative feedback on the system and its workflow. Index Terms—Visualization of 3 D data, human-computer interaction, expert interaction, direct-touch input, mobile displays, stereoscopic environments, VR, AR, conceptual model of interaction, interaction reference frame mapping, observational study. F...|$|E
40|$|WO 200209446 A UPAB: 20020711 NOVELTY - The {{structured}} panel (2) has {{an arrangement}} for connecting the panel {{to the flat}} screen (1) and an arrangement for adjusting the panel. The arrangement for connecting the panel to the screen is a device with an arrangement (3) for holding the panel and for connecting it movably and/or reversibly to the flat screen or for moving the panel away from the screen. USE - For <b>monoscopic</b> and stereoscopic image presentation on flat screens. ADVANTAGE - Enables selective <b>monoscopic</b> or stereoscopic presentation without spectacles for portable and flat image monitors and suitable projection systems with flat projection screens and is simple to use...|$|E
40|$|This paper {{presents}} concepts, {{methods and}} experi-mental results for estimating {{the scale of}} a trajec-tory that is established by <b>monoscopic</b> Visual Odom-etry algorithms for use in autonomous driving. While <b>monoscopic</b> Visual Odometry has been widely inves-tigated, one of its key issues restrains its broad ap-pliance: the scale drift. To tackle it, we leverage scene inherent information about the ground plane and external sensors such as a single-row low-cost laser scanner to estimate the scale in real-time. A vision-based calibration method for the registration of a laser scanner and a camera is introduced. The scale corrected trajectory from Visual Odometry is combined with a cyclist tracking to form an Advance...|$|E
30|$|The {{stereoscopic}} {{images have}} clear differences compared with <b>monoscopic</b> image {{in terms of}} the coexistence of both {{the left and the right}} images. That characteristic is related to several constraints that have to be followed during the forgery process.|$|E
3000|$|Many {{resampling}} {{detection methods}} have been proposed in the past. Even though there are various ways to expose the resampling process, most techniques commonly use the relation between pixels. Studies related to resampling detection method using <b>monoscopic</b> image is as follows: [...]...|$|E
40|$|Streaming media {{applications}} often {{suffer from}} packet losses in wired or wireless IP links. In {{order to get}} reasonable degree of quality in case of packet losses, {{it is necessary to}} have error concealment tools at the decoder. Even though several research has been done on <b>monoscopic</b> video, very few studies are found in the literature for stereoscopic error concealment. In this paper we propose novel full frame loss concealment algorithms for stereoscopic sequences. The proposed methods use redundancy and disparity between the two views and motion information between the previously decoded frames to estimate the lost frame. The results show that, the proposed algorithms outperform the <b>monoscopic</b> methods when they are applied to the same view as they are simulcast coded. 1...|$|E
40|$|We {{propose a}} method for {{real-time}} photorealistic stereo rendering of the natural phenomenon of fire. Applications {{include the use of}} virtual reality in fire fighting, military training, and entertainment. Rendering fire in real-time presents a challenge because of the transparency and non-static fluid-like behavior of fire. It is well known that, in general, methods that are effective for <b>monoscopic</b> rendering are not necessarily easily extended to stereo rendering because <b>monoscopic</b> methods often do not provide the depth information necessary to produce the parallax required for binocular disparity in stereoscopic rendering. We investigate the existing techniques used for <b>monoscopic</b> rendering of fire and discuss their suitability for extension to real-time stereo rendering. Methods include the use of precomputed textures, dynamic generation of textures, and rendering models resulting from the approximation of solutions of fluid dynamics equations through the use of ray-tracing algorithms. We have found that in order to attain real-time frame rates, our method based on billboarding is effective. Slicing is used to simulate depth. Texture mapping or 2 D images are mapped onto polygons and alpha blending is used to treat transparency. We can use video recordings or prerendered high-quality images of fire as textures to attain photorealistic stereo...|$|E
40|$|Fire. (Under the {{direction}} of Dr. David McAllister.) We propose a method for real-time photorealistic stereo rendering of the natural phenomenon of fire. Applications {{include the use of}} virtual reality in fire fighting, military training, and entertainment. Rendering fire in real-time presents a challenge because of the transparency and non-static fluid-like behavior of fire. It is well known that, in general, methods that are effective for <b>monoscopic</b> rendering are not necessarily easily extended to stereo rendering because <b>monoscopic</b> methods often do not provide the depth information necessary to produce the parallax required for binocular disparity in stereoscopic rendering. We investigate the existing techniques used for <b>monoscopic</b> rendering of fire and discuss their suitability for extension to real-time stereo rendering. Methods include the use of precomputed textures, dynamic generation of textures, and rendering models resulting from the approximation of solutions of fluid dynamics equations through the use of ray-tracing algorithms. We have found that in order to attain real-time frame rates, our method based on billboarding is effective. Slicing is used to simulate depth. Texture mapping or 2 D images are mapped onto polygons and alpha blending is used to treat transparency. We can use video recordings or pre-rendered high-quality images of fire as textures to attain photorealistic stereo...|$|E
40|$|Depth-image-based {{rendering}} (DIBR) is {{a method}} to represent a stereoscopic content. The DIBR consists of a <b>monoscopic</b> center view and an associated per-pixel depth map. Using these two components and given depth condition from a user, the DIBR renders left and right views. The advantages of DIBR are numerous. The user can choose not only the <b>monoscopic</b> or stereoscopic view selectively, but also the depth condition what he prefers when he watches a stereoscopic content. However, {{in the view of}} copyright protection, since not only the center view but also each left or right view {{can be used as a}} <b>monoscopic</b> content when they are illegally distributed, the watermark signal which is embedded in the center view must have an ability to protect the respective three views. In this study, we solve this problem by exploiting the horizontal noise mean shifting (HNMS) technique. We exploit the fact that the objects in the view are shifted only to horizontal way when the center view renders to the left and right views. Using this fact, the proposed stereoscopic watermarking scheme moves the mean of horizontal noise histogram which is invariant to horizontal shifting, and we achieve good performance as shown in the experimental results...|$|E
30|$|One of {{the most}} {{challenging}} objectives of the HESS project is to detect particles which energy are below 50 [*]GeV. In this energy range, it is not conceivable to use all telescopes (since the smallest ones cannot trigger), and only the fifth telescope may be used in a <b>monoscopic</b> mode.|$|E
40|$|Due to the {{inherent}} postural constraints from a microscope, surgeons who perform minimally invasive surgeries may {{be exposed to}} prolonged static postures. As 3 D displays become more economically viable, {{their role in the}} healthcare industry may become more prominent. The purpose of this pilot-study is to assess the effect of stereoscopic displays on postural constraint, perceived effort, and performance during simulated microsurgery tasks. Ten subjects with no surgical experience performed microsurgical skills tests using four visualization methods: 2 D flat panel display, 3 D flat panel display, <b>monoscopic</b> microscope, and stereoscopic microscope. Body posture was measured via motion tracking equipment and task performance was captured through video analysis. Subjective data was gathered on posture, perceived effort, and equipment usability. Significant differences were found between all displays for each measured joint angle; however, all posture deviations can be classified as neutral. Participants were unable to perceive posture differences between the visualization methods. Task completion times were fastest for the <b>monoscopic</b> microscope; however, the differences were not significant. Total errors were significantly greater for the <b>monoscopic</b> microscope than the flat panel displays. Perceived effort ratings were not significantly different among visualization methods. This study demonstrates that 2 D and 3 D flat panel visualization methods may provide an alternative to microscopes during surgery; however, hardware improvements are needed before this technology is viable in the healthcare industry...|$|E
30|$|Also, {{the need}} for {{protection}} of the multi-view content is big. Since the device for generating multi-view content {{have a number of}} lens and the processor have high performance, the price for generating multi-view content is more expensive than the <b>monoscopic</b> one. Nevertheless, forgery protection technology for multi-view content has rarely been developed.|$|E
40|$|Teleoperation work {{involving}} {{remotely operated}} vehicles, remote sensor platforms, and remote manipulators is described. The implementation of head slaved <b>monoscopic</b> and stereoscopic camera platforms, binaural microphone and pinnae systems, and image and audio processing with integrated virtual reality is discussed. The most recent medium for long distance communication is cellular mobile phone technology...|$|E
40|$|Abstract—In this paper, {{we propose}} a {{learning}} based approach to estimating pixel disparities from the motion information extracted out of input <b>monoscopic</b> video sequences. We represent each video frame with superpixels, and extract the motion features from the superpixels and the frame boundary. These motion features {{account for the}} motion pattern of the superpixel as well as camera motion. In the learning phase, given a pair of stereoscopic video sequences, we employ a state-of-the-art stereo matching method to compute the disparity map of each frame as ground truth. Then a multi-label SVM is trained from the estimated disparities and the corresponding motion features. In the testing phase, we use the learned SVM to predict the disparity for each superpixel in a <b>monoscopic</b> video sequence. Experiment {{results show that the}} proposed method achieves low error rate in disparity estimation. I...|$|E
40|$|Stereoscopic display {{technologies}} have seen wide spread application in entertainment and gaming contexts through {{their ability to}} intensify the perception of depth. However, their potential for enhancing the development and application of spatial knowledge within a 3 D space is not as certain. Existing research suggests that stereoscopic displays can contribute both positively and negatively {{to the process of}} spatial cognition within 3 D virtual environments. In order to explore this issue, a study comparing experience with binocular parallax stereoscopic displays to standard <b>monoscopic</b> displays was undertaken using a 3 D virtual environment that required users to complete tasks using spatial cues. Findings suggested that spatial experience with binocular parallax stereoscopic displays and standard <b>monoscopic</b> displays was comparable in terms of effectiveness, though the experience was subjective and many participants found that binocular parallax stereoscopy created a strong emotional response...|$|E
40|$|Hong Kong {{is one of}} the world's mountainous {{international}} cities, and landslides are {{a constant}} threat to human life and property. Monitoring landslides in Hong Kong is important and this is always done by field surveying. However, although conventional survey techniques provide accurate landslide information, they are limited to small areas and physical contact with the slope may be dangerous. Remote sensing techniques can provide an alternative for collecting information about landslide causes and occurrences, and they may assist in the prediction of future landslide occurrences. This article demonstrates the use of <b>monoscopic</b> and stereoscopic aerial photographs, along with satellite images from the IKONOS very high resolution (VHR) sensor for detailed landslide hazard assessment over Hong Kong. For <b>monoscopic</b> aerial photographs, a fusion technique for generating pseudo true colour images from false colour aerial photographs was demonstrated. The pseudo true colour image is useful for better visual analysis in the photogrammetric model. For <b>monoscopic</b> IKONOS image, a set of image fusion techniques was applied in order to improve landslide interpretation, and the results were examined visually and statistically. The Pan-sharpening method among all the image fusion techniques has been demonstrated to have superior performance for identifying both landslide trails and crowns. Stereoscopic viewing using a stereoscopic pair of aerial photographs and stereoscopic IKONOS images was employed for more detailed landslide investigation such as landscape positional relationships (e. g. streams and ridges). Digital elevation models (DEM) were generated from aerial photographs and IKONOS stereoscopic images, and they were compared with digital contour data with 2 m contour interval. The DEMs generated from digital photogrammetric model and IKONOS stereoscopic images are consistently more accurate than an existing DEM, and are sensitive to micro-scale terrain features. The Hong Kong Civil Engineering Department may use the derived <b>monoscopic</b> fused images, stereoscopic images, DEM and anaglyph as objective measures for a detailed landslide study within Hong Kong. Department of Land Surveying and Geo-Informatic...|$|E
40|$|H. E. S. S is {{an array}} of {{atmospheric}} Cherenkov telescopes dedicated to GeV-TeV gamma-ray astronomy. The original array has been in operation {{since the beginning of}} 2004. It is composed of four 12 -meter diameter telescopes. The installation of a fifth 28 -meter diameter telescope is being completed. This telescope will operate both in stereoscopic mode and in <b>monoscopic</b> mode i. e. without a coincident detection on the smaller telescopes. A second-level trigger system is needed to supress spurious triggers of the 28 -meter telescope when operated in <b>monoscopic</b> mode. This paper gives the motivation and principle of the second-level trigger. The principle of operation is illustrated by an example algorithm. The hardware implementation of the second level trigger system of H. E. S. S. phase 2 is described and its expected performances are then evaluated. Comment: accepted for publication in Astroparticle Physic...|$|E
40|$|This paper {{presents}} {{a method of}} converting a 2 D still photo containing the head 2 ̆ 6 shoulders of a human (e. g. a passport photo) to pseudo- 3 D, so that the depth can be perceived via stereopsis. This technology {{has the potential to}} be included in self-serve photo booths and, also as an added accessory (i. e. software package) for digital still cameras and scanners. The basis of the algorithm is to exploit the ability of the human visual system in combining <b>monoscopic</b> and stereoscopic cues for depth perception. Common facial features are extracted from the 2 D photograph, in order to create a parametric depth map that conforms to the available <b>monoscopic</b> depth cues. The original 2 D photograph and the created depth map are used to generate left and right views for stereoscopic viewing. The algorithm is implemented in software, and promising results are obtained...|$|E
