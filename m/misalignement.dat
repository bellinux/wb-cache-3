20|10|Public
40|$|After {{a summary}} of the motivations for searching flavour violating decays and {{electric}} dipole moments in the leptonic sector, I briefly sketch the present status of the limits on lepton-slepton <b>misalignement</b> and discuss the potentialities of the planned experimental improvements. Candidates for theories beyond the Standard Model have to satisfy all these experimental constraints; I will discuss in particular how the supersymmetric SM extended with the see-saw faces the flavour problem. ...|$|E
40|$|Abstract—The {{performance}} of an ultra-wideband (UWB) Rake receiver over a sparse multipath channel with an ex-ponential power delay profile is investigated {{in the presence}} of path delay estimation errors. An exact expression of the bit error probability accounting for both tap <b>misalignement</b> and missing-path errors is obtained. Also obtained are an approximate simpler expression and upper/lower bounds. The exact expression is compared with simulations and is shown to be in good agreement. Index Terms—UWB, imperfect channel estimate, path delay estimation, Rake receiver design I...|$|E
40|$|Abstract γ+jet events {{provide a}} tomographic {{measurement}} of the medium formed in heavy ion collisions at LHC energies. Tagging events with a well identified high pT direct photon and measuring the correlation distribution of hadrons emitted oppositely to the photon, allows us to determine, with a good approximation, both the jet fragmentation function and the back-to-back azimuthal <b>misalignement</b> of the direct photon and the jet. Comparing these two observables measured in pp collisions with the ones measured in AA collisions will reveal the modifications of the jet structure induced by the medium formed in AA collisions and consequently will infer the medium properties...|$|E
40|$|The Zgoubi {{integrator}} [1] is a {{good and}} universal tool for particle tracking as well as spin tracking [2], and takes into account all machine realistic aspects, like real fields, non-linearities, fringing fields or <b>misalignements.</b> It is used for simulations of the SuperB storage ring. We present the Zgoubi implementation and the methods carried out to es-timate the Invariant Spin Field (ISF) evolution of SuperB, on some simple case for validation, and we investigate for some specific polarization behavior...|$|R
40|$|Minimization of {{the beam}} losses in a multi-MW H{sup -} linac such as ProjectX to a level below 1 W/m is a {{challenging}} task. The impact of different mechanism of beam stripping, including stripping in electric and magnetic fields, residual gas, blackbody radiation and intra-beam stripping, is analyzed. Other sources of beam losses are <b>misalignements</b> of beamline elements and errors in RF fields and phases. We present in this paper requirements for dynamic errors and correction schemes to keep beam losses under control...|$|R
40|$|This paper {{develops}} a NATREX (NATural Real EXchange rate) model for two large economies, the Eurozone and the United States, which are fully specified {{and allowed to}} interact. The theoretical framework, grounded on dynamic disequilibrium modelling approach in continuous time, provides the basis for empirical estimation. The model is estimated in its structural form as a simultaneous nonlinear differential equations system for the 1975 - 2003 period. The estimated parameters are then used to derive the simulated Euro/USD NATREX series in- and out-of-sample that offers the benchmark against which the <b>misalignements</b> of the actual real exchange rate are measured. NATREX Equilibrium exchange rate Euro/USD Structural approach Continuous time econometrics Misalignment...|$|R
40|$|International audienceRecently, we have {{witnessed}} a growing need to volve business poeple {{in the early stages}} of Entreprise Information Systems developmment. The MAP methodology apperars to be a good candidate for involving business poeple in the early modelling of business application, reducing the risk of business-IT systems <b>misalignement.</b> fUrthermore, in the context of Model Driven Enginieering, such a methodology perfectly fits in the upper CIM level. in this paper we revisit the MAP to propose a formal approach capable of prociding solid basis to it, necessary when developing automatic tools aimed at supporting tha modeling activity and the verification of the production map diagram...|$|E
40|$|First imaging {{results are}} {{obtained}} {{with a new}} CCD mosaic prototype (3 K x 3 k, 15 µm pixels). The CCDs are aligned using an etched socket alignment technique. Three different measurements of the alignment are made using star images, test pattern images, and microscope analysis. The CCDs have an angular <b>misalignement</b> of less than 30 ppm. The composite device is flat to within ± 3 µm, with rows/columns oriented to within 20 ppm. The use of an existing technology with built in precision reduces many of the difficulties and expenses typically encountered with mosaic detector construction. A new camera being built for the UBC liquid mirror telescope is also described. ...|$|E
40|$|At the Linear Collider {{mismatches}} {{between the}} two beams will result in an intense beamstrahlung. We have studied how this beamstrahlung would evolve {{as a function of}} the offset {{between the two}} beams and we suggest ways of monitoring it. 1 Beamstrahlung at the Linear Collider. At the Linear Collider the colliding beams will have a vertical size of less than a few nanometers. With such a small size any <b>misalignement</b> of the final focus magnets will lead to an offset between the two beams at the interaction point (IP). As the magnetic field in each bunch will be of the order of kilo-Teslas, the <b>misalignement</b> of the two beams will make that each beam will travel accross the strong magnetic dipole created by the other and thus produce an intense synchrotron radiation called, in this case, beamstrahlung [1]. We have used CAIN [2] to evaluate the intensity of the beamstrahlung {{as a function of the}} offset between the two beams. The beam parameters used are those of the JLC as described [3] but our conclusions are valid for any linear collider operationg around 500 GeV and would be similar at an energy of 1 TeV. In this study we have neglected the coherent beamstrahlung (CB) as the energy of the CB photons is well below the energies discussed below. The figure 1 shows the beamstrahlung spot 200 meters away from the IP for different vertical offset between the two beams. As one can see there is a clear dependance of the beamstrahlung pattern with the beam offset...|$|E
40|$|The Planetary Fourier Spectrometer (PFS) {{on board}} the Mars- 94 missionis an {{infrared}} spectrometer optimised for studies of the Martian atmosphere. Moreover the measurements of the instrument will provide also information about the surface composition and the surface- atmosphere interactions. The spectrometer consists of a Dual Rotational Reflector Interferometer (RRI) covering two spectral ranges 220 - 1670 cm- 1 (6 - 45 m) and 2080 - 8000 cm- 1 (1. 25 - 4. 5 m) the long wavelength channel (LWC) and the short wavelength channel (SWC) respectively. In the RRI two pairs of retroreflectors, which are connected by a L-shaped arms with an axle, are driven in parralel on a circular path. Patial <b>misalignements</b> due to tolerance effects of real optical and mechanical elements {{are taken into account}} in an estimation of the spectral responsivity in comparison with the ratiation of the Martian surface and atmosphere...|$|R
40|$|The goal of {{this thesis}} is the {{preparation}} of the Higgs boson search in its diphoton decay at LHC with the ATLAS detector. The issues that have been studied deal with the Higgs to two photons vertex reconstruction, with the electromagnetic calorimeter and the inner detector, and the diphoton invariant mass resolution. Different simulations of the ATLAS detector and the effects of additional material and of detector <b>misalignements</b> have been studied. Issues concerning the statistical significance calculation have also been discussed and the discovery potential has been evaluated. A part if this thesis is done with CSC data, that use the most recent detector simulation and new reconstruction methods. Every step of the signal and background treatment has been discussed. We finally evaluate that with an integrated luminosity of 10 fb- 1 {{we will be able to}} see a Higgs to two photons signal with a statistical significance of 3 sigma...|$|R
40|$|The {{measurement}} of the Rossiter-MacLaughlin effect in transiting planetary systems has revealed a significant population of hot giant planets orbiting outside the equatorial plane of their parent star. In an attempt to improve our understanding of these spin-orbit <b>misalignements,</b> and discriminate between various scenarios, we propose to determine whether debris disks are located within the equatorial plane of their star using infrared spectro-interferometry. To validate our approch, we have chosen the bright star Fomalhaut and measured the orientation of its rotationnally-distorted stellar photosphere using micro-arcsecond precision VLTI/AMBER spectro-astrometry within the Br-gamma line. The derived poition angle is in perfect agreement with the position angle of the cold debris disk imaged in the visible and sub-millimeter domains. We discuss {{the implications of this}} result on our understanding of the dust grain properties in the Fomalhaut disk, and how this study can be extended to other debris disk systems...|$|R
40|$|An {{increase}} in disc height, segmental lordosis or sagittal <b>misalignement</b> after total disc replacement (TDR) {{may lead to}} higher contact forces or capsule tensile forces in the facet joints of the segment L 5 /S 1. Therefore we investigated the correlation of these anatomical parameters to the clinical outcome of patients with TDR. 40 Patients suffering from degenerative disc disease or initial osteochondrosis at L 5 /S 1 were threated with TDR. In follow-up examinations radiographic analysis and clinical scores were examined. In radiographs the difference in disc heigt, segmental lordosis and sagittal vertebral <b>misalignement</b> to the preoperative state was measured. Clinical scores included ODI and VAS for overall, back, and leg pain. Depending on the clinical outcome patients {{divided into two groups}} (ODI 25 % group F) for correlation analysis to the radiographic parameters. We could examine 34 patients at a mean follow-up of 59. 5 month. 24 patients were assigned to group N, 10 patients to group F. However both groups had significant decrease of overall pain, back pain and ODI. In the correlation analysis patients with a larger disc height, increased lordosis, and posterior translation of the L 5 vertebra presented higher clinical scores. Comparing of these groups also showed significant differences of these parameters. We conclude that conditions with higher facet joint capsule tensile forces are a reason for clinical failure of TDR at L 5 /S 1. This failure can be eliminated by avoiding iatrogenic posterior translation and segmental overdistraction with consecutive hyperlordosis...|$|E
40|$|The paper {{investigates the}} {{reaction}} of the Federal Reserve to developments in the stock market. The issue is analyzed by first constructing an Index of Stock Price <b>Misalignement</b> in which the fundamental value of the stocks is computed {{on the basis of the}} discounted cash flow approach and by then including this index, among the regressors, into a forward looking Taylor rule. In accordance with the descriptive evidence, based mainly on the analysis of the FOMC meetings and public statements, our findings show that the Fed tends to lower the Fed funds rate when stock prices fall below their fundamental value, while there is no evidence of monetary stringency during episodes of exuberance in the stock market. ...|$|E
40|$|This paper {{presents}} the results of functional tests carried out on the first 7 em slit FEEP emitter prototype designed and manufactured at Centrospazio. While FEEP emitters have traditionally been fed with cesium, this thruster used rubidium as a propellant. The investigations carried out include electrical parameters measurement and ion beam profile recording. The use of Rb resulted in immediate, good wetting of the emitter blades and in very good ion emission, while emitter <b>misalignement</b> caused a portion of the usefullenght of the thruster not to operate, showing how sensitive this thruster is to small changes in its delicate geometrical arrangement. Nevertheless, maximum estimated thrust was as high as 1. 2 mN and beam divergence was within the expected values...|$|E
40|$|The {{target for}} beam energy {{calibration}} at LEP 200 is to achive a relative accuracy of approximatively 10 - 4 for energies above the W pair production threshold. A variety of calibration {{methods have been}} used for that purpose, one of them being based on a spectrometer magnet. The spectrometer is using six dedicated high resolution BPMs to measure the beam energy through the deflection angle around a dedicated and calibrated dipole magnet. To obtain the average beam energy, local deviations at the spectrometer due to the energy sawtoothing must be taken into account. The local energy shift depends on the energy loss in each arc {{as well as on the}} details of the RF voltage distribution. Local phase errors and longitudinal <b>misalignements</b> affect the local energy and must be taken into account. This note describes a method to determine some overall RF parameters for each interaction point of LEP to improve the accuracy of the local energy prediction. It is based on a MAD model of the RF system which is calibrated by dedicated experiments...|$|R
40|$|It is a firm {{prediction}} of the concordance Cold Dark Matter (CDM) cosmological model that galaxy clusters {{live at the}} intersection of large-scale structure filaments. The thread-like structure of this "cosmic web" has been traced by galaxy redshift surveys for decades. More recently the Warm-Hot Intergalactic Medium (WHIM) residing in low redshift filaments has been observed in emission and absorption. However, a reliable direct detection of the underlying Dark Matter skeleton, which should contain {{more than half of all}} matter, remained elusive, as earlier candidates for such detections were either falsified or suffered from low signal-to-noise ratios and unphysical <b>misalignements</b> of dark and luminous matter. Here we report the detection of a dark matter filament connecting the two main components of the Abell 222 / 223 supercluster system from its weak gravitational lensing signal, both in a non-parametric mass reconstruction and in parametric model fits. This filament is coincident with an overdensity of galaxies and diffuse, soft X-ray emission and contributes mass comparable to that of an additional galaxy cluster to the total mass of the supercluster. Combined with X-ray observations, we place an upper limit of 0. 09 on the hot gas fraction, the mass of X-ray emitting gas divided by the total mass, in the filament. Comment: Nature, in pres...|$|R
40|$|In this talk, I will {{describe}} two recent studies {{carried out with}} infrared interferometry to characterise the planetary system around Fomalhaut, and its debris disk in particular. In the first study, we aimed to determine whether the debris disk is located within the equatorial plane of the stellar photosphere, in an attempt to improve our understanding of spin-orbit <b>misalignements</b> in planetary systems in general. We measured the orientation of the rotationnally-distorted stellar photosphere using micro-arcsecond precision VLTI/AMBER spectro-astrometry within the Br-gamma line. The derived poition angle is in perfect agreement with the position angle of the cold debris disk measured in visible and sub-millimeter images. We discuss the implications of this result on our understanding of the dust grain properties in the Fomalhaut disk. In the second study, we aimed at characterising the dust content of the innermost part of the debris disk. We used archival high-precision K-band visibility measurements with VLTI/VINCI and obtained N-band nulling observations with the Keck Interferometer Nuller. We report a significant excess emission at K band, and a marginal excess emission at N band, that we attempt to reproduce with a 2 D debris disk model. A comprehensive Bayesian analysis of the main disk parameters is performed to derive most-probable values. Our analysis points towards a very compact ring of hot dust close to the sublimation radius as the origin of the reported excess emission...|$|R
30|$|Since the {{presence}} of collateral has a direct reducing impact on FTDCVA/DVA, this formula may {{give the impression that}} collateralization achieves a reduction in counterparty risk at no cost to either the bank or the clients. However, in our incomplete market setup, the value CR of counterparty risk {{from the point of view}} of the bank as a whole ignores the <b>misalignement</b> of interest between the shareholders and the creditors of a bank. Propositions 4.1 (i) and (ii) give explicit decompositions of the shareholder valuation CA of counterparty risk and of the wealth transfer CL triggered from the shareholders to the creditors by the impossibility for the bank to hedge its own jump-to-default exposure (see Albanese and Crépey (2017, Sections 2.1 and 3.4)). Accounting for the further impossibility for the bank to replicate counterparty default losses, not only these contra-liabilities (CL), but also cost of capital (KVA), are material to shareholders and need to be reflected in entry prices on top of CR (cf. (1)).|$|E
40|$|International audienceWe {{show that}} the {{canonical}} single frequency sarcomeric SHG intensity pattern (SHG-IP) of control muscles is converted to double frequency sarcomeric SHG-IP in preserved mdx mouse gastrocnemius muscles {{in the vicinity of}} necrotic fibers. These double frequency sarcomeric SHG-IPs are often spatially correlated to double frequency sarcomeric two-photon excitation fluorescence (TPEF) emitted from Z-line and I-bands and to one centered spot SHG angular intensity pattern (SHG-AIP) suggesting that these patterns are signature of myofibrillar <b>misalignement.</b> This latter is confirmed with transmission electron microscopy (TEM). Moreover, a good spatial correlation between SHG signature of myofibrillar misalignment and triad reduction is established. Theoretical simulation of sarcomeric SHG-IP is used to demonstrate the correlation between change of SHG-IP and -AIP and myofibrillar misalignment. The extreme sensitivity of SHG microscopy to reveal the submicrometric organization of A-band thick filaments is highlighted. This report is a first step toward future studies aimed at establishing live SHG signature of myofibrillar misalignment involving excitation contraction defects due to muscle damage and disease...|$|E
40|$|Through Silicon Vias (TSVs) are {{critical}} elements in three dimensional integrated circuits (3 -D ICs) and {{are susceptible to}} undergo defects at different stages: during their own fabrication, the bonding stage or during their life time. Typical defects are microvoids, underfilling, <b>misalignement,</b> pinholes in the oxide or misalignments during bonding {{in such a way}} that resistive opens become a frequent failure mechanism affecting TSVs. Although there is considerable research effort dedicated to improve TSVs testing, no much attention has been paid to weak defects, especially to weak open defects (resistive opens) causing small delays. In this work, a testing strategy is proposed to detect small delay defects by means of a post-bond oscillation test. Variations in the Duty Cycle of transmitted signals after unbalanced logic gates are shown to detect weak open defects in TSVs. HSPICE simulations including process parameter variations show the effectiveness of the method in the detection of weak open defects above 1 kO. Postprint (published version...|$|E
40|$|The ATLAS Level- 1 Muon Barrel Trigger {{is one of}} {{the main}} {{elements}} of the first stage of event selection of the ATLAS experiment at the Large Hadron Collider. The challenge of the Level- 1 system is a reduction of the event rate from a collision rate of 40 MHz by a factor 10 ^ 3, using simple algorithms that can be executed with a latency of the order of 1 mus. The input stage of the Level- 1 Muon consists of an array of processors receiving the full granularity of data from a dedicated detector (Resistive Plate Chambers in the Barrel). of the different time-of-flights and cables and optical fiber lenghts, signals have to be adjusted in time in order to be correctly aligned before being processed. We present the analysis te chnics developed to allow for a study of time <b>misalignements</b> both among the RPC trigger sectors and globally with the LHC clock. These studies collect and integrate several informations, such as tri gger times from the ATLAS Central Trigger Processor, both from the RPC and external triggers (e. g. the Inner Detector); and offline reconstructed muon tracks, that provide us with the ability to per form topology-based study of the trigger timing by knowing the muon trajectory. These techniques have been tested using a large statistics sample of cosmic muon events in combined runs with the rest of the ATLAS detector; and are expected to provide a fast and detailed mapping of the status of the timing c alibration with the early LHC beam data...|$|R
40|$|We present multi-frequency, multi-epoch radio imaging of {{the complex}} radio source B 2151 + 174 {{in the core of}} the cluster, Abell 2390 (z~ 0. 23). From new and {{literature}} data we conclude that the FRII-powerful radio source is the combination of a compact, core-dominated `medium-symmetric object' (MSO) with a more extended, steeper spectrum mini-halo. B 2151 + 174 is unusual in a number of important aspects: i) {{it is one of the}} most compact and flat spectrum sources in a cluster core known; ii) it shows a complex, compact twin-jet structure in a north-south orientation; iii) the orientation of the jets is 45 deg misaligned with apparent structure (ionization cones and dust disk) of the host galaxy on larger scales. Since the twin-jet of the MSO has its northern half with an apparent `twist', it might be that precession of the central supermassive black hole explains this <b>misalignement.</b> B 2151 + 174 may be an example of the early stage (10 ^ 3 - 10 ^ 4 yrs duration) of a `bubble' being blown into the ICM where the plasma has yet to expand. Comment: 10 pages, 5 figures, 3 tables, accepted by MNRA...|$|E
40|$|Several {{recent studies}} have {{suggested}} that circumstellar disks in young stellar binaries may be driven into <b>misalignement</b> with their host stars due to secular gravitational interactions between the star, disk and the binary companion. The disk in such systems is twisted/warped due to the gravitational torques from the oblate central star and the external companion. We calculate the disk warp profile, taking into account of bending wave propagation and viscosity in the disk. We show that for typical protostellar disk parameters, the disk warp is small, thereby justifying the "flat-disk" approximation adopted in previous theoretical studies. However, the viscous dissipation associated with the small disk warp/twist tends to drive the disk toward alignment with the binary or the central star. We calculate the relevant timescales for the alignment. We find the alignment is effective for sufficiently cold disks with strong external torques, and is ineffective for the majority of star-disk-binary systems. Viscous warp driven alignment may be necessary to account for the observed spin-orbit alignment in multi-planet systems if these systems are accompanied by an inclined binary companion. Comment: 11 pages, 9 figures, 4 tables, submitted to MNRA...|$|E
40|$|Service {{failure and}} {{recovery}} is a well-established area of services research. Research {{has shown that}} service recovery is critically important from a managerial perspective in terms of maintaining customer relationships. Yet few firms excel at handling service failures. There is {{a growing number of}} managers who claim that customers tend to be dissatisfied with their service recovery effort. Their employees cannot improve service processes when they experience recovery situations and their companies still does not learn from service failure. Michel et al (2007) attribute the service recovery ineffectiveness to the competing interests for managing employees, customers and processes. We agree with their contention that to address these criticisms, complaint management must first acknowledge and then find new approaches to achieve consistency and to correct the <b>misalignement</b> of interests that can exist between the actions of the organisation and the needs of its customers and employees. We believe that search in the customer knowledge management literature represent one effective means to enhance a firm ability to implement a cohesive service recovery strategy. Key words: complaint management, customer knowledge management, service-dominant logic Problem and context The academic research on marke...|$|E
40|$|The paper {{presents}} {{a magnetic field}} gradientmeter meant to detect the very small size ferromagnetic inclusions. The detection of the magnetic field gradient is useful in certain applications permitting to eliminate some disturbing factors and to localize the local inhomogeneities of the magnetic field or certain close field sources. The gradientmeter makes use of two identical magnetic transducers of fluxgate type, connected in opposition, such that the output signal is proportional with the difference of the field from every transducer. The error sources are presented {{as well as the}} solutions to reduce them. The main error source in gradient measurement is the difference of sensitivities and the transducers <b>misalignement.</b> The two components of the local magnetic field – the longitudinal and transversal ones – determine the appearance of some error signals. The longitudinal component of the magnetic field applied to the transducer produces a measuring error proportional with its size. The measuring error proportional to the field component normal to the measuring direction can be eliminated by an accurate sensors alignment. The block diagram and the operation principle of the gradientmeter are described. The experimental results reveal the possibility to use this method for the detection of small size ferromagnetic inclusions...|$|E
40|$|A {{direct method}} for {{estimating}} the rotational motion between two image frames is developed. The algorithm {{does not require}} knowledge of image correspondences, optical flow or scene structure and only assumes approximate knowledge of the translational motion. Spatial and temporal intensity gradients are avoided, resulting in an algorithm that is noise resistant. Moreover, the algorithm does not assume a particular projection model and is valid for both orthographic and perspective models. It {{is based on a}} statistical measure of epipolar misalignment. Specifically, that (1) the intensity histograms of corresponding epipolar lines are invariant (ignoring occlusions) and, more importantly, that (2) the histograms of "almost corresponding" epipolar lines are similar. This latter property {{is a function of the}} spatial correlation present in the image and it is empirically demonstrated to be well behaved over a large class of scenes. These epipolar properties of histograms, i. e. that the difference between two histograms is a minimum when the two epipolar lines truly correspond and (approximately) increases monotonically with the degree of <b>misalignement</b> between two "epipolar" lines, allows the rotational motion to be estimated in a straightforward manner as a 3 -dimensional "epipolar search". Experimental results are presented on the SRI JISCT stereo database to empirically support the epipolar properties of intensity histograms. The calibrated NASA helicopter flight sequence is then analyzed to quantify the accuracy with wich the rotations can be estimated. Experimental results indicate that very precise rotational estimates can be achieved...|$|E
40|$|We {{revisit the}} mass {{properties}} of the lensing cluster of galaxies MS 2137 - 23 and assess the mutual agreement between cluster mass estimates based on lensing, X-rays and stellar dynamics. We perform a thorough elliptical lens modelling using arcs in the range 20 <R< 100 kpc and weak lensing (100 <R< 1000 kpc). We confirm that the dark matter distribution is consistent with an NFW profile with high concentration c= 11. 7 ± 0. 6. We further analyse the stellar kinematics data of Sand etal(2004) with a detailed modelling of the los velocity distribution of stars in the cD galaxy and quantify the small bias due to non-Gaussianity of the LOSVD. After correction, the NFW lens model is still unable to properly fit kinematical data and is twice as massive as suggested by X-rays (Allen etal 2001). The discrepancy between projected and tridimensional mass estimates is studied by assuming prolate (triaxial) halos with the major axis oriented toward the line-of-sight. This model well explains the high concentration and the <b>misalignement</b> of 13 deg between stellar and dark matter components. We then calculate the systematic and statistical uncertainties in the relative normalization between cylindric M(< R) and spherical M(< r) mass estimates for triaxial halos. These uncertainties prevent any attempt to couple 2 D and 3 D constraints without a complete tridimensional analysis. Such asphericity/projection effects should be a major concern for comparisons between lensing and X-rays/dynamics mass estimates. Comment: Final accepted version in A&A with Improved discussion and figures. Full resolution pdf version at ftp://ftp. iap. fr/pub/from_users/gavazzi/MS 2137 _triax. pd...|$|E
40|$|Abstract. We {{revisit the}} mass {{properties}} of the lensing cluster of galaxies MS 2137 - 23 and assess the mutual agreement between cluster mass estimates based on strong/weak lensing, X-rays and stellar dynamics. We perform a thorough elliptical lens modelling using arcs and their counter-images in the range 20 � R � 100 kpc and weak lensing (100 � R � 1000 kpc). We confirm that the dark matter distribution is well consistent with an NFW profile with high concentration c ∼ 11. 7 ± 0. 6. We further analyse the stellar kinematics data of Sand et al. (2004) with a detailed modelling of the line-of-sight velocity distribution of stars in the cD galaxy and quantify the small bias due to non-Gaussianity of the LOSVD. After correction, the NFW lens model is unable to properly fit kinematical data and is a factor of ∼ 2 more massive than suggested by X-rays analysis (Allen et al. 2001). The discrepancy between projected (lensing) and tridimensional (X-rays,dynamics) mass estimates is studied by assuming prolate (triaxial) halos with the major axis oriented toward the line-of-sight. This model well explains the high concentration and the <b>misalignement</b> between stellar and dark matter components (∆ψ ∼ 13 ◦). We then calculate the systematic and statistical uncertainties in the relative normalization between the cylindric M 2 (< r) and spherical M 3 (< r) mass estimates for triaxial halos. These uncertainties prevent any attempt to couple 2 D and 3 D constraints without undertaking a complete tridimensional analysis. Such asphericity/projection effects should be a major concern for comparisons between lensing and X-rays/dynamics mass estimates...|$|E
40|$|International audienceTHE BALANCED SCORECARD AS A NORMALIZED STRATEGY COMMUNICATION TOOL : A RESEARCH STUDY SHOWING HOW TEXTUAL ANALYSIS CAN REVEAL ORGANIZATIONAL ISSUES The {{balanced}} scorecard is quite recent as a management control tool. Its main {{idea is to}} add some new dimensions to previous systems mainly focussed on financial issues. Kaplan and Norton (1992) have suggested {{to add to the}} financial perspective, a customer perspective (the different value propositions), an internal processes one (how value is created), and finally a organizational learning one (role of intangible assets). However, this performance measure approach has been gradually transformed in a communication tool, in order to explain the pursued strategy to all members of the organization. Finally, after a huge number of consulting interventions, Kaplan and Norton have been able to propose a standardized structure, with the main and most usual areas of concerns of managers. Hence, they have delivered a norm of management, with its own structure, set of hypothesis and causal relationships, organizational objectives, and in particular the shareholder value creation. Two questions can then be raised, adopting such an approach. Firtsly, one can wonder if such a tool is structured as agents think and behave. Secondly, using the {{balanced scorecard}}, another question remain whether strategic alignement promises can really be reached. These questions are explored using the firm-as-text theory (Cooren and Taylor, 1997). This framework allows to conceptualize organizations as not only producing texts but also being structured by these produced texts. Our case study shows, how using a textual analysis software and lexical approach, one can reveal some misconceptions in the balanced scorecard and some other organizational issues. Overview of the textual analysis method ALCESTE in French is an acronym used for a textual analysis software which means Analysis of Coocurrent Lexemes in a Set of Textual Fragments. First applied and developed by a statistician and sociologist, Max Reinert (1993), this software has become increasingly popular in social sciences. Very briefly, the algorithm used is a cluster analysis statistical technique able to identify cooccurrent terms within short texts segments. The clustering tree also indicate how each cluster is close from one another. It also possible to tag texts, and hence test correlations between such tags and each cluster. Field Research and Case Study Our field of research is a public administration, in charge of a middle size French town. The epismogic position is an action-research from an interpretative perspective. We have helped this organization in designing and adapting its own balanced scorecard. This teamwork has been achieved with five top managers, in a context where the mayor of the town and the top director of administration were recently arrived. This approach is also known in literature as "top-down" with a system of cascading scorecards. This means that the middle management composed of twenty directors have only been solicited in a second step. Under this information system architecture, the balanced scorecards of departments are gathered in order to elaborate the central and main scorecard, useful for the top director of administration and the mayor. As can be seen, four specific have been selected. The first one is defined as "resources". The second one is about "organizational learning". The third on is classical, and centered on "internal processes". Finally, the fourth one is specific to a public administration, and retains the external, political perspective. The official strategy pursued by themayor is to transform the town in a better generous, ecological and sharing space. Research design and empirical results Each director has received an electronic document in order to feel what was his or her view and interpretation of each strategic objective. We have gathered all answers in one common file, where each answer was related to ist origin (department), and place in the scorecard (perspective, orientation, objective). These results can be interpreted in several ways. First of all, it must be mentioned that not all directors have answered and participated to this experiment. Their behavior can be explained by their reluctance to the balanced scorecard project, and their resistance to change. Another result is the number of fragments of texts clustered. The obtained rate is relatively low, not exceeding 53 %. This means that directors have in general quite different ways of thinking and interpreting similar strategic objectives. For some specific objectives, there is also almost no answer, showing that directors are unable to put words and actions behind. It is also interesting to understand, through cluster 5, that the sharing objective (*obj_shar) is in fact associated to the internal processes perspective (*per_proc). Another significant example is about the buildings and equipments optimization objective. It has been a priori classified as a process. It can be clearly shown that this objective is textually and cognitively connected to the resources perspective (cluster 4). The last result we would like to stress is the significant absence of the words "sustainable" or "sustainability". It is all the more astonishing that these concepts are {{at the core of the}} oragnizational strategy, as defined by the mayor. In fact directors do not want their local power and influence to be questioned by the Agenda 21 new imperatives. They also try to resist, and conceptualize their missions and objectives outside this transversal and collective strategic project. We have also added to our initial corpus a strategic text published by the political team and the town mayor. Using the same ALCESTE methodlogy, it can be clearly demonstrated that we have within the same organization two very different strategic projects. On one side, there is the political project, related to the town perspective in the balanced scorecard. On the other side, there is the administrative way of thinking with objectives related to other perspectives. This means that the administration still has to integrate in its strategic way of thinking the projects and the political objectives. As it has been developed in this brief abstract, a textual analysis can provide a great support in understanding the gap between the defined structure of the balanced scorecard and people organisational thinking. The absence of the word "sustainability" is a proof of a major strategic <b>misalignement.</b> The gap between the political discourse and the administration language can also be highlighted. In that sense, espoused theories, as shown in figure 1, are not those that are in use, as shown in our results (Argyris and Schön, 2002). Asking top executives to have a textual production can also reveal their internal strategies, will to cooperate, and lack of understanding of certain kinds of objectives. The ALCESTE statistical ratio of text's units related to clusters is also a way of measuring the group cohesion and strategic alignement. La mise en place d'un balanced scorecard dans une mairie nous fournit l'occasion de montrer les écarts de représentation entre le maire, l'équipe de direction et les responsables de services. Le cycle texte-conversation révèle des effets de résistance par rapport à la thématique du développement durable inscrite dans le projet politique...|$|E

