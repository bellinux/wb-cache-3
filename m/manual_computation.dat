47|29|Public
25|$|Local {{standards}} usually {{define the}} educational methods and content {{included in the}} elementary level of instruction. In the United States and Canada, controversial subjects include the amount of calculator usage compared to <b>manual</b> <b>computation</b> and the broader debate between traditional mathematics and reform mathematics.|$|E
50|$|Usable: The Sample UHID {{is capable}} of {{implementation}} {{in a variety of}} technologies such as scanners, bar code readers, etc. The 28 digit identifier will present difficulty for <b>manual</b> <b>computation</b> and transcription. It may be a time-consuming process and subject to human errors.|$|E
50|$|Local {{standards}} usually {{define the}} educational methods and content {{included in the}} elementary level of instruction. In the United States and Canada, controversial subjects include the amount of calculator usage compared to <b>manual</b> <b>computation</b> and the broader debate between traditional mathematics and reform mathematics.|$|E
40|$|One of {{the issues}} in {{statistics}} education today involves {{the extent to which}} <b>manual</b> <b>computations</b> should be incorporated into the elementary statistics curriculum. Students should be required to work with data and carry out some <b>manual</b> <b>computations</b> because such activities speed and enhance the learning process, reinforce the concepts and techniques introduced, provide an environment of constructive participation and personal discovery, and improve quantitative skills. A discussion of student populations, of the nature of hand computations, and of different types of data and their role in the learning process is given...|$|R
5000|$|A {{computer}} algebra system (CAS) is any mathematical software {{with the}} ability to manipulate mathematical expressions in a way similar to the traditional <b>manual</b> <b>computations</b> of mathematicians and scientists. The development of the computer algebra systems {{in the second half of}} the 20th century is part of the discipline of [...] "computer algebra" [...] or [...] "symbolic computation", which has spurred work in algorithms over mathematical objects such as polynomials.|$|R
40|$|Space position-fixing {{techniques}} {{have been investigated}} by collecting data on the observable phenomena of space flight {{that could be used}} to solve the problem of autonomous navigation by the use of optical data and <b>manual</b> <b>computations</b> to calculate the position of a spacecraft. After completion of the developmental and test phases, the product of the experiment would be a manual-optical technique of orbital space navigation that could be used as a backup to onboard and ground-based spacecraft-navigation systems...|$|R
50|$|The Casio FX-7000G is a {{calculator}} which is widely known {{as being the}} world's first graphing calculator available to the public. It {{was introduced to the}} public and later manufactured between 1985 and c. 1988. Notable features are its ability to graph functions, and that it is programmable. The calculator offers 82 scientific functions and is capable of <b>manual</b> <b>computation</b> for basic arithmetic problems.|$|E
50|$|Sometimes, strings {{need to be}} {{embedded}} {{inside a}} text file that is both human-readable and intended for consumption by a machine. This is needed in, for example, source code of programming languages, or in configuration files. In this case, the NUL character doesn't work well as a terminator since it is normally invisible (non-printable) and is difficult to input via a keyboard. Storing the string length would also be inconvenient as <b>manual</b> <b>computation</b> and tracking of the length is tedious and error-prone.|$|E
50|$|Columbia University Astronomy Professor Wallace Eckert was {{examining}} the process {{used by the}} Navy to produce Air Almanacs. Deciding that the <b>manual</b> <b>computation</b> techniques used were too slow and error prone, he recommended automating the process with existing punched card based unit record equipment. One of the hardest problems was getting a high-quality printout of the tables. Initially IBM 405 accounting machines with special modifications were used, but he wanted something better. In 1941 Eckert developed a specification for a card-driven composing typewriter and asked IBM to design and build it.|$|E
40|$|AbstractWe use {{the notion}} of Borel {{generators}} to give alternative methods for computing standard invariants, such as associated primes, Hilbert series, and Betti numbers, of Borel ideals. Because there are generally few Borel generators relative to ordinary generators, this enables one to do <b>manual</b> <b>computations</b> much more easily. Moreover, this perspective allows us to find new connections to combinatorics involving Catalan numbers and their generalizations. We conclude with a surprising result relating the Betti numbers of certain principal Borel ideals {{to the number of}} pointed pseudo-triangulations of particular planar point sets...|$|R
40|$|Experiments at the Arc Jet Tunnel at Ames Research Center have typical {{run times}} of 5 - 10 sec {{during which the}} test model is {{subjected}} to an environment simulating reentry into Jupiter. Previous real-time determination of mass flow required off-line <b>manual</b> <b>computations</b> from taped or strip chart data. The present paper describes a computer which provides personnel with real-time computations of mass flow. Using an 8 -bit microprocessor and standard TTL interface circuitry, the unit interrogates temperature and pressure instruments with other parameters to compute mass flow...|$|R
40|$|We use {{the notion}} of Borel {{generators}} to give alternative methods for computing standard invariants, such as associated primes, Hilbert series, and Betti numbers, of Borel ideals. Because there are generally few Borel generators relative to ordinary generators, this enables one to do <b>manual</b> <b>computations</b> much more easily. Moreover, this perspective allows us to find new connections to combinatorics involving Catalan numbers and their generalizations. We conclude with a surprising result relating the Betti numbers of certain principal Borel ideals {{to the number of}} pointed pseudo-triangulations of particular planar point sets. Comment: 23 pages, 2 figures; very minor changes in v 2. To appear in J. Algebr...|$|R
5000|$|The {{advent of}} {{electronic}} computers slowly changed what the all-female computations group did. The women {{were trained to}} program in FORTRAN, the primary computer language developed for scientific applications. Male engineers largely didn't {{want to do the}} programming themselves in the 1960s. It was still considered [...] "women's work," [...] not part of an engineer's job description. [...] Through her career, Finley provided both <b>manual</b> <b>computation</b> work and FORTRAN programs as part of JPL's missions to the Moon, Mars, Venus, Mercury, Jupiter, Saturn, Uranus and Neptune, in the Ranger, Mariner, Pioneer, Viking, and Voyager programs.|$|E
50|$|Venturer {{had only}} eight torpedoes {{as opposed to}} the 22 carried by U-864. After three hours Launders decided to make a {{prediction}} of U-864s zig-zag, and released a spread of his torpedoes into its predicted course. This <b>manual</b> <b>computation</b> of a firing solution against a three-dimensionally manoeuvring target was the first occasion on which techniques were used and became the basis of modern computer-based torpedo targeting systems. Prior to this attack, no target had been sunk by torpedo where the firing ship had to consider the target's position in three-dimensional terms, where the depth of the target was variable and not a fixed value. The computation thus differs fundamentally from those performed by analogue torpedo fire-control computers which regarded the target in strictly 2D terms with a constant depth determined by the target's draught.|$|E
5000|$|... on notation: In this article, {{we follow}} the {{convention}} from differential geometry in which multivectors and multicovectors are written with lower and upper indices, respectively. Since differential forms are multicovector fields, upper indices are employed to index them. [...] The opposite rule applies to the components of multivectors and multicovectors, which instead are written with upper and lower indices, respectively. For instance, we represent the standard coordinates of vector [...] as , so that [...] {{in terms of the}} standard basis [...] In addition, superscripts appearing in the denominator of an expression (as in [...] ) are treated as lower indices in this convention. When indices are applied and interpreted in this manner, the number of upper indices minus the number of lower indices in each term of an expression is conserved, both within the sum and across an equal sign, a feature that serves as a useful mnemonic device and helps pinpoint errors made during <b>manual</b> <b>computation.</b>|$|E
40|$|Using Excel or {{any form}} of {{spreadsheet}} for project scheduling is a convenient approach. The approach is dynamic compared to traditionally <b>manual</b> <b>computations.</b> It is also less complicated and mechanistic and rather straightforward compared to advanced programming languages. This paper intends to investigate numerous implementations of spreadsheet modeling ever worked and resulted for generalized critical path method. The approaches produced have significantly contributed to the advancements {{of teaching and learning}} and computerized applications in management science and industrial engineering. The approaches are comprehensively discussed, the advantages of respective approaches are thoroughly reviewed, their limitations are carefully addressed, and significant findings from the approaches presented are evidently derived. Key words: Critical path method; Spreadsheet modeling; Project scheduling; Operations research; Management science; Quantitative method; Industrial engineering</p...|$|R
40|$|In this study, the Truckload Delivery with Backhaul Scheduling Problem (TDBSP) is {{formulated}} and an Ant Colony Optimization methodology {{developed for}} a related problem, the Vehicle Routing Problem with Backhaul and Time Windows (VRPBTW), is adapted for its solution. The TDBSP {{differs from the}} VRPBTW in that shipments are in units of truckloads, multiple time windows in multiple days are available for delivery to customers, limited space for servicing customers is available and multiple visits to each customer may be required. The problem is motivated by a real-world application arising at a leading cement producer in Thailand. Experts at the cement production plant assign vehicles to cement customers and lignite mines based on <b>manual</b> <b>computations</b> and experience. This study provides mathematical and computational frameworks for modeling and solving this real-world application...|$|R
50|$|Scholars {{have been}} able to {{identify}} only two works as authored by Haridatta. One of them, titled Grahacaranibandhana, is the basic <b>manual</b> of <b>computations</b> of the Parahita system of astronomy. This was unearthed by K.V. Sarma and was published in 1954. The other work titled Mahamarganibandhana is no longer extant.|$|R
30|$|The cell {{formation}} {{problem is}} considered as NP-hard (nondeterministic polynomial hard) combinatorial optimization problem due to solution complexity (Bayram and Sahin 2016; Rodriguez Leon et al. 2013). Due to solution complexity, <b>manual</b> <b>computation</b> to obtain solutions may produce erroneous results.|$|E
40|$|A new Rank Order Cluster Algorithm is {{discussed}} {{which provides a}} simple, effective and efficient analytical technique {{for the formation of}} machine-component groupings. The method is specifically developed for computer application although it is possible for it to be used for <b>manual</b> <b>computation,</b> if required, particularly for smaller problems. ...|$|E
40|$|Touch zones defined {{simply by}} touching, while editing done automatically. Development of touch-screen {{interactive}} computing system, tedious task. Interactive Editor for Definition of Touch-Sensitive Zones computer program increases efficiency of human/machine communications by enabling user to define each zone interactively, minimizing redundancy in programming and eliminating need for <b>manual</b> <b>computation</b> of boundaries of touch areas. Information produced during editing process written to data file, to which access gained when needed by application program...|$|E
40|$|The revised {{second edition}} of the “Soil Sampling Protocol to Certify the Changes of Organic Carbon Stock in Mineral Soils of European Union” updates the Manual {{published}} in 2005. The revision {{is based on the}} practical testing in the field. Following numerous comments of the users the revised manual is illustrated by examples of the application of the <b>manual</b> and <b>computation</b> routine. JRC. H. 7 -Land management and natural hazard...|$|R
40|$|AbstractWe study an old {{mathematical}} model, developed {{before the}} computer era, for analyzing {{the strength of}} a stiffened shell roof. The specific problem considered is a textbook example presented in K.  Girkmann: Flächentragwerke, 3 rd edition, 1954. Here the roof consists of a spherical dome and a stiffening ring of rectangular cross section attached {{to the edge of the}} dome. The problem is to compute the resultant force and moment acting at the junction of the dome and the ring. We approach the old model for solving the problem in two different ways. First we carry out a historical study, where we look for possible improvements of the old model while limiting ourselves to <b>manual</b> <b>computations</b> only. We find a variant of the model which, despite being about as simple as the original one, is considerably more accurate in comparison with recent numerical solutions based on FEM and axisymmetric 3 D elastic formulation of the problem. The second approach in our study is to carry out an a posteriori error analysis of our refined old model. The analysis is based on variational methods and on the Hypercircle theorem of the linear theory of elasticity. The error analysis confirms, and largely also explains, the observed–rather high–accuracy of the refined old mathematical model...|$|R
40|$|In {{the first}} phase of this study, a data-base {{containing}} clinical and laboratory findings of 704 patients with systemic lupus erythematosus (SLE), originating from 29 centres and 14 countries, was used to assess the validity of 4 common indices of disease activity, SLAM, BILAG, SLEDAI and SIS. The physician's judgement of activity was assumed as the unique reference criterion (gold standard). Computer programmes were developed to calculate automatically the 4 activity indices; this computation appeared to correspond with <b>manual</b> <b>computations</b> in a sample of 60 appropriately selected cases. All 4 indices were closely correlated with each other (r in the range of 0. 716 to 0. 872), and with the physician's score (r in the range of 0. 620 to 0. 719). In {{the second phase of the}} study the activity index developed in part I (ECLAM) was prospectively validated, and its performance compared to that of the other scales, both as a single state index and as a transition index (i. e., its ability to assess disease activity at a single point in time and to detect variations in consecutive readings). A computer-assisted clinical chart was prepared for this purpose. This chart allowed us to calculate automatically all the indices. Two consecutive observation times (time 0, and time 1 three months later) were included in the study protocol. Data on 75 patients from 19 centres were collected, and each patient was observed twice. All the computed indices were closely correlated, both at time 0 (r ranging from 0. 725 to 0. 884), and at time 1 (r ranging from 0. 607 to 0. 833) ...|$|R
40|$|We {{report a}} {{methodology}} for computing functional vascular density within a rodent dorsal window chamber model based on long-exposure laser speckle imaging (LSI). This technique {{relies on the}} presence of flow to create detailed vasculature maps. Employing this contrast mechanism is not possible using conventional imaging methods. Additionally, a freeware algorithm for computing functional vascular density (FVD) from images acquired using long-exposure LSI is also described to facilitate ease in adopting this method. We demonstrate that together these tools can be used to compute FVD nearly twelve times faster than <b>manual</b> <b>computation,</b> yet with comparable accuracy...|$|E
40|$|A {{model is}} {{described}} that predicts hospital census and computes, for each day, {{the number of}} elective admissions that will maximize the census over the short run, subject to constraints on the probability of overflow. Where a computer is available the model provides detailed predictions of census in units as small as 10 beds; used with <b>manual</b> <b>computation</b> the model allows production of tables of the recommended numbers of elective admissions to the hospital as a whole. The model has been tested in five hospitals and {{is part of the}} admissions system in two of them; implementation is described, and the results obtained are discussed...|$|E
40|$|Computer-aided {{learning}} of structural behaviour {{can be very}} effective and motivating. Students are able to analyse structures in far less time than by traditional methods and address problems of much greater complexity. They do so without the burden of <b>manual</b> <b>computation.</b>   Computer programs exist that are well suited for this purpose, {{two of which are}} described. They offer a broad range of design capabilities, and are easy to master because of their intuitive and graphically oriented approach.   A number of examples are given to illustrate the potential of computer-aided learning as a complement to traditional methods either in the classroom or in coursework. ...|$|E
50|$|Technical {{fire control}} has been {{performed}} in various places, but mostly in firing batteries. However, in the 1930s, the French moved it to battalion level and combined {{it with some}} tactical fire control. This was copied by the US. Nevertheless, most armies seemed to have retained it within firing batteries, and some duplicated the technical fire control teams in a battery to give operational resilience and tactical flexibility. Computers {{reduced the number of}} men needed and enabled decentralisation of technical fire control to autonomous sub-battery fire units, such as platoons, troops, or sections, although some armies had sometimes done this with their <b>manual</b> methods. <b>Computation</b> on the gun or launcher, integrated with their laying system, is also possible. MLRS led the way in this.|$|R
40|$|Introduction The National Hospital Discharge Survey is {{a primary}} data source for {{epidemiology}} research in the United States. To ensure that estimates are reliable, confidence intervals need to be calculated. The original survey data source is not available to the public, and the usual statistical methods are unsuitable for calculating confidence intervals. Instead, calculating confidence intervals requires using the statistical methods and relative standard errors that the U. S. National Center for Health Statistics has provided. However, the relative standard error parameters differ by hospital, patient category, and group. They also change yearly with sampling and are expressed differently before and during or after 1988. Consequently, <b>manual</b> <b>computations</b> of confidence intervals with multiple groups, diseases, and years are inefficient and prone to error. We developed a SAS program to compute confidence intervals for National Hospital Discharge Survey data from 1979 through 2000, newborns excluded. Methods We transposed 22 tables of relative standard error parameters (one for each year) into two new parameter tables that maintain the sampling designs before 1988 and during and after 1988 but are similar in overall structure. We unified all values to make each set of relative standard error parameters unique. We developed a program, COMPURSE, to search for relative standard error parameters for inputted estimates and to calculate confidence intervals. We set up an interface program for users to enter data, time period, confidence interval level, and output location; to read the relative standard error parameter tables; and to run the COMPURSE program. Results For different sets of National Hospital Discharge Survey data, COMPURSE efficiently and correctly retrieved relevant relative standard error parameters for estimates and accurately calculated relative standard errors, standard errors, and confidence intervals for annual estimates, multiple-year summaries, and average annual estimates. Conclusion The program COMPURSE helps users analyze National Hospital Discharge Survey data efficiently...|$|R
30|$|Statistical {{tables are}} an {{essential}} component of scientific papers and reports in biomedical and agricultural sciences. Measurements in these tables are summarized as mean[*]±[*]SEM for each treatment group. Results from pairwise-comparison tests are often included using letter displays, in which treatment means that are not significantly different, are followed by a common letter. However, the traditional <b>manual</b> processes for <b>computation</b> and presentation of statistically significant outcomes in MS Word tables using a letter-based algorithm are tedious and prone to errors.|$|R
40|$|Abstract. In {{order to}} discard some {{disadvantages}} of traditional astronomical navigation positioning, such as <b>manual</b> <b>computation</b> and time-consuming, we design a special calculator for locating ship's position, {{which not only}} make astronomical navigation positioning calculation quickly and operate instrument simply, but also convenient to carry. The system based on the theory of sun shift line positioning principle use the 32 -bit microcontrollers based on ARM Cortex-M 3 kernel as the core controller. In this paper, we give hardware design and software process of the system. Through actual test, {{the results of the}} testing value and actual value can tally well. Its calculation process only needs a few seconds, also could greatly improve the real-time and accuracy of positioning...|$|E
40|$|The {{main object}} {{of this study}} is to compute the {{structural}} fire resistance for several steel members under different loading conditions. This is done in chapter 4 using two advanced calculation models. Chapter 1 contains prescriptions according to European codes, needed for this research. In Chapter 2 the notion of structural fire resistance is explained and also information about the types of fire protection materials used in this research is given. In Chapter 3 a short presentation of the properties of the structural steel was made. A validation of the results is made within chapter 4 and 5 by comparing values provided by the two applications and also by means of <b>manual</b> <b>computation</b> according to the code. Rezumat...|$|E
40|$|Left Ventricle (LV) Ejection Fraction (EF) is a {{fundamental}} parameter for heart function assessment. Being based on border tracing, however, <b>manual</b> <b>computation</b> of EF is time-consuming and extremely prone to inter-and intraobserver variability. In this paper we present an automatic method for EF computation which provides results in agreement with those provided by expert observers. The segmentation strategy consists of two stages: first, the region of interest is identified by means of mimetic criteria; then, the identified region is used for initialization of an active contour based on a variational formulation of level set methods, which provides accurate segmentation of the LV cavity. Volume calculation is then performed according to the conventional Simpson's rule and, finally, the EF is computed...|$|E
40|$|Casinos are {{hospitality}} {{operations in}} which a gaming experience is offered to guests in addition to general hospitality services. To create stable, high-quality guest services while generating satisfactory guest experiences, casinos rely significantly on the skills of their front-line employees. The initial training before employees begin {{to work in a}} live-gaming casino environment is crucial. It gives them the basic knowledge to be able to perform their tasks proficiently and deliver the required guest-service standards to all patrons during live gaming sessions. Table games dealers are the primary front-line employees in a table game operation, they receive majority of their training before becoming employed by any casino. Table games dealer (TGD) training schools curricula mostly focus on the game rules and procedures and on a general understanding of the table games operation from the dealer’s perspective. During their training period, TGDs learn the rules and procedures of each table game, e. g., black jack, craps, roulette—they will deal later. They also have the opportunity to develop their <b>manual</b> skills, <b>computation</b> techniques, and shortcuts and learn the procedures related to table game protection...|$|R
40|$|Abstract Complete and {{accurate}} annotation {{of the mouse}} genome {{is critical to the}} advancement of research con-ducted on this important model organism. The National Center for Biotechnology Information (NCBI) develops and maintains many useful resources to assist the mouse research community. In particular, the reference sequence (RefSeq) database provides high-quality annotation of multiple mouse genome assemblies using a combinatorial approach that leverages <b>computation,</b> <b>manual</b> curation, and collaboration. Implementation of this conservative and rigorous approach, which focuses on representation of only full-length and non-redundant data, produces high-quality annotation products. RefSeq records explicitly link sequences to current knowledge in a timely manner, updating public records regularly and rapidly in response t...|$|R
40|$|Includes bibliographical {{references}} (pages [109]- 111) Snow and ice-covered roads cause inconvenience to the public, reduce vehicle mobility, {{and increase}} the potential for accidents. The regions which experience snow and ice storms require special attention to keep the roads safe for driving and reduce damage to property and personal loss. Any improvement made in the planning o f snow removal can save money to tax payers and the local government. In this research, a generic framework is proposed for the dynamic planning o f the snow removal process. The framework contains a heuristic, a continuous simulation model, and an interface for integrating these two. The framework accommodates both salt spraying and snow plowing operations o f the snow removal process. The framework also considers changes in the snow-fall rate and dynamically determines new routing plans for the snow removal trucks to follow, whenever changes in the snow-fall rate require a new routing plan. The heuristic developed for the framework treats snow removal routes as an undirected, hierarchical network and determines the routing plans for the snow removal trucks. The developed heuristic {{has been found to}} give a better solution compared to an existing heuristic, when the subnetwork induced by each hierarchy level is disconnected. The heuristic has also been modified to obtain a lower bound for the Hierarchical Postman Problem applied to the snow removal process. The heuristic has been implemented in Turbo C and validated using thirty-one sample networks. The simulation model developed for the framework is a continuous one, and it considers the changes in the snow-fall rate for dynamically planning the snow removal / process. When executed, the simulation model obtains a routing plan by calling the developed heuristic and simulates the salt spraying and snow plowing operations. When the snow-fall rate changes, the simulation model dynamically revises the snow removal process by calling the heuristic and obtaining a new plan. The simulation model has been implemented using the simulation language SIMAN and has been interfaced with the heuristic using WATCOM C/C++. The implemented framework has been validated using an actual snow removal problem from the city of DeKalb, Illinois. The simulation results have been found to compare favorably with <b>manual</b> <b>computations,</b> thus validating the framework. The details o f the framework, including the developed heuristic and the continuous simulation model, are discussed in this thesis. M. S. (Master of Science...|$|R
