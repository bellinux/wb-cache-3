285|874|Public
25|$|Seizing {{an entry}} from a pre-allocated array is faster than using dynamic memory {{allocation}} for each node, since dynamic memory allocation typically requires {{a search for}} a free <b>memory</b> <b>block</b> of the desired size.|$|E
25|$|Stuxnet {{installs}} malware into <b>memory</b> <b>block</b> DB890 of the PLC {{that monitors}} the Profibus messaging bus of the system. When certain criteria are met, it periodically modifies the frequency to 1,410Hz {{and then to}} 2Hz and then to 1,064Hz, and thus affects {{the operation of the}} connected motors by changing their rotational speed. It also installs a rootkit – the first such documented case on this platform – that hides the malware on the system and masks the changes in rotational speed from monitoring systems.|$|E
25|$|On many systems, a program's {{virtual address}} may refer to data {{which is not}} {{currently}} in memory. The layer of indirection provided by virtual addressing allows the operating system to use other data stores, like a hard drive, to store what would otherwise have to remain in main memory (RAM). As a result, operating systems can allow programs to use more memory than the system has physically available. When a program needs data which is not currently in RAM, the CPU signals to the kernel that this has happened, and the kernel responds by writing the contents of an inactive <b>memory</b> <b>block</b> to disk (if necessary) {{and replacing it with}} the data requested by the program. The program can then be resumed from the point where it was stopped. This scheme is generally known as demand paging.|$|E
50|$|To avoid fragmentation, µC/OS-II allows {{applications}} to obtain fixed-sized <b>memory</b> <b>blocks</b> from a partition {{made of a}} contiguous memory area. All <b>memory</b> <b>blocks</b> are the same size, and the partition contains an integral number of blocks. Allocation and deallocation of these <b>memory</b> <b>blocks</b> is done in constant time and is a deterministic system.|$|R
50|$|Upper <b>memory</b> <b>blocks</b> can {{be created}} by mapping {{extended}} memory into the upper memory area when running in virtual x86 mode. This is similar to how expanded memory can be emulated using extended memory so this method of providing upper <b>memory</b> <b>blocks</b> is usually provided by the expanded memory manager (for example EMM386). Ironically the application programming interface for managing the upper <b>memory</b> <b>blocks</b> is specified in the eXtended Memory Specification.|$|R
40|$|Abstract—Cache locking is an {{effective}} technique to improve timing predictability in real-time systems. In static cache locking, the locked <b>memory</b> <b>blocks</b> remain unchanged throughout the program execution. Thus static locking may not be effective for large programs where multiple <b>memory</b> <b>blocks</b> are competing for few cache lines available for locking. In comparison, dynamic cache locking overcomes cache space limitation through time-multiplexing of locked <b>memory</b> <b>blocks.</b> Prior dynamic locking technique partitions the program into regions and takes indepen-dent locking decisions for each region. We propose a flexible loop-based dynamic cache locking approach. We not only select the <b>memory</b> <b>blocks</b> to be locked but also the locking points (e. g., loop level). We judiciously allow <b>memory</b> <b>blocks</b> from the same loop to be locked at different program points for WCET improvement. We design a constraint-based approach that incorporates a global view {{to decide on the}} number of locking slots at each loop entry point and then select the <b>memory</b> <b>blocks</b> to be locked for each loop. Experimental evaluation shows that our dynamic cache locking approach achieves substantial improvement of WCET compared to prior techniques. I...|$|R
25|$|The {{method used}} to read NANDflash memory can cause nearby cells in the same <b>memory</b> <b>block</b> to change over time (become programmed). This is known as read disturb. The {{threshold}} number of reads is generally {{in the hundreds of}} thousands of reads between intervening erase operations. If reading continually from one cell, that cell will not fail but rather one of the surrounding cells on a subsequent read. To avoid the read disturb problem the flash controller will typically count the total number of reads to a block since the last erase. When the count exceeds a target limit, the affected block is copied over to a new block, erased, then released to the block pool. The original block is as good as new after the erase. If the flash controller does not intervene in time, however, a read disturb error will occur with possible data loss if the errors are too numerous to correct with an error-correcting code.|$|E
2500|$|First, in {{the mapping}} of virtual memory addresses, instead of needing an MMU, the MCP systems are descriptor-based. [...] Each {{allocated}} <b>memory</b> <b>block</b> {{is given a}} master descriptor with {{the properties of the}} block (i.e., the size, address, and whether present in memory). [...] When a request is made to access the block for reading or writing, the hardware checks its presence via the presence bit (pbit) in the descriptor.|$|E
2500|$|In {{the first}} stage, the {{existing}} system would be moved {{on top of a}} new kernel-based OS with built-in support for multitasking and protected memory. The existing libraries, like QuickDraw, would take too long to be rewritten for the new system and would not be converted to be reentrant. Instead, a single paravirtualized operating system, the [...] "Blue Box", keeps applications and older code like QuickDraw in a single <b>memory</b> <b>block</b> so they continue to run as they had in the past. The Blue Box operating system itself runs in a separate memory space, so crashing applications or extensions within Blue Box can not crash the entire machine.|$|E
5000|$|<b>Memory</b> <b>Blocks</b> {{have evolved}} to become {{individually}} hand crafted plaster tiles, measuring 6" [...] × 8" [...] × 1" [...] and finished to a porcelain-like quality, cracked to create an aged look and feel. [...] Some <b>memory</b> <b>blocks</b> are embellished with silver and gold leafing done by hand.|$|R
5000|$|... <b>memory</b> <b>blocks</b> {{including}} {{a selection of}} ROM, RAM, EEPROM and flash memory ...|$|R
5000|$|Memory {{allocation}} {{services for}} dynamic allocation and freeing of fixed-size or variable-size <b>memory</b> <b>blocks.</b>|$|R
5000|$|The handle can {{for example}} be {{implemented}} with an [...] The module can interpret the handle internally by dividing it into pool index, <b>memory</b> <b>block</b> index and a version. The pool and <b>memory</b> <b>block</b> index allow fast {{access to the}} corresponding block with the handle, while the version, which is incremented at each new allocation, allows detection of handles whose <b>memory</b> <b>block</b> is already freed (caused by handles retained too long).|$|E
50|$|Free the {{formerly}} allocated <b>memory</b> <b>block.</b>|$|E
50|$|In {{this format}} the {{directory}} is decentralised and distributed among the caches that share a <b>memory</b> <b>block.</b> Different caches that share a <b>memory</b> <b>block</b> {{are arranged in}} the form of a binary tree. The cache that accesses a <b>memory</b> <b>block</b> first is the root node. Each <b>memory</b> <b>block</b> has the root node information (HEAD) and Sharing counter field (SC). The SC field has the number of caches that share the block. Each cache entry has pointers to the next sharing caches known as L-CHD and R-CHD. A condition for this directory is that the binary tree should be number balanced, i.e the number of nodes in the left sub tree must be equal to or one greater than the number of nodes in the right subtree. All the subtrees should also be number balanced.|$|E
40|$|Laboratory {{methods for}} {{studying}} <b>memory</b> <b>blocking</b> and recovery include directed forgetting, retrieval-induced forgetting, and retrieval bias or <b>memory</b> <b>blocking</b> procedures. These methods primarily use word lists. For example, striking, reversible forgetting effects {{have been reported}} for both emotional (e. g., expletives) and non-emotional (e. g., tools) categorized lists of words. The present study examined forgetting and recovery of richer, more episodic materials. Participants studied a series of brief narrative passages varying in emotional intensity, such as a vignette involving torture or child abuse (emotional) vs. vignettes about cycling or insects (non-emotional). Free recall of the 1 -word titles of the vignettes (e. g., Torture, Cyclist) showed a strong <b>memory</b> <b>blocking</b> effect, and cues from the stories on a subsequent cued recall test reversed the effect. In a second experiment, vignette-related pictures inserted into an incidental picture naming task triggered some recovery of initially forgotten vignettes, as shown on a post-test. Both emotional and non-emotional stories were susceptible to this reversible <b>memory</b> <b>blocking</b> effect...|$|R
40|$|We {{investigate}} {{the power and}} energy implications of using embedded FPGA <b>memory</b> <b>blocks</b> to implement logic. Previous {{studies have shown that}} this technique provides extremely dense implementations of some types of logic circuits, however, these previous studies did not evaluate the impact on power. In this paper, we measure the effects on power and energy as a function of three architectural parameters: the number of available <b>memory</b> <b>blocks,</b> the size of the <b>memory</b> <b>blocks,</b> and the flexibility of the <b>memory</b> <b>blocks.</b> We show that although embedded memories provide area efficient implementations of many circuits, this technique results in additional power consumption. We also show that blocks containing smaller-memory arrays are more power efficient than those containing large arrays, but for most array sizes, the <b>memory</b> <b>blocks</b> should be as flexible as possible. Finally, we show that by combining physical arrays into larger logical memories, and mapping logic {{in such a way that}} some physical arrays can be disabled on each access, can reduce the power consumption penalty. The results were obtained from place and routed circuits using standard experimental physical design tools and a detailed power model. Several results were also verified through current measurements on a 0. 13 [*] μm CMOS FPGA...|$|R
50|$|Dickens {{began making}} <b>Memory</b> <b>Blocks</b> {{while he was}} working in Vancouver during the early 1990s in a studio on Hastings Street.|$|R
5000|$|<b>Memory</b> <b>Block</b> English Heritage, Liverpool Community Arts Projects (Liverpool 2004) ...|$|E
5000|$|The tag bits {{derived from}} the <b>memory</b> <b>block</b> address are {{compared}} with the tag bits associated with the set. If the tag matches, {{then there is a}} cache hit and the cache block is returned to the processor. Else there is a cache miss and the <b>memory</b> <b>block</b> is fetched from the lower memory(main memory, disk).|$|E
50|$|QEMM {{supports}} {{moving and}} reallocating extended <b>memory</b> <b>block,</b> Virtual DMA Services (VDS) specification.|$|E
50|$|BlueMax was {{a special}} version {{designed}} for the IBM PS/2 with ROM compression {{to get the most}} of the Upper <b>Memory</b> <b>Blocks.</b>|$|R
5000|$|For complex microprocessors, {{floating}} point units and cache <b>memory</b> <b>blocks</b> are turned off when idle. This method is called dynamic power management ...|$|R
50|$|A {{physically}} indexed CPU cache {{is designed}} such that addresses in adjacent physical <b>memory</b> <b>blocks</b> take different positions ("cache lines") in the cache, {{but this is}} not the case when it comes to virtual memory; when virtually adjacent but not physically adjacent <b>memory</b> <b>blocks</b> are allocated, they could potentially both take the same position in the cache. Coloring is a technique implemented in memory management software, which solves this problem by selecting pages that do not contend with neighbor pages.|$|R
5000|$|... with no {{temporary}} vectors {{needed and}} only one pass through each <b>memory</b> <b>block.</b>|$|E
5000|$|The {{eviction}} of <b>memory</b> <b>block</b> {{from the}} cache is {{decided by the}} replacement policy.|$|E
50|$|There {{are three}} {{different}} policies available for placement of a <b>memory</b> <b>block</b> in the cache.|$|E
40|$|Abstract [...] The <b>memory</b> <b>blocks</b> {{testing is}} a {{separate}} testing procedure followed in VLSI testing. The <b>memory</b> <b>blocks</b> testing involve writing a specific bit sequences in the memory locations and reading them again. This type of test is called March test. A particular March test consists of a sequence of writes followed by reads with increasing or decreasing address. There are several test circuits available for testing the memory chips. However no test setup is developed so far for testing the <b>memory</b> <b>blocks</b> inside the FPGA. The BRAMs of FPGA are designed to work at much higher frequency than the FPGA core logic. Hence testing the BRAMs at higher speed is essential. The conventional memory test circuits cannot be used for this purpose. Hence the proposed work develops a memory testing tool based on March tests for FPGA based BRAM...|$|R
40|$|Coarse-grain {{reconfigurable}} arrays often rely on an imperative {{programming approach}} including a read/write mechanism for memory access. In this paper, we present an architecture {{composed of a}} configurable array of computing cores and <b>memory</b> <b>blocks</b> in which both the execution mechanism and configuration principle of the computing cores and the behaviour of the <b>memory</b> <b>blocks</b> are based on streaming and dataflow principles. We illustrate our ideas {{with the implementation of}} a long finite impulse response (FIR) filter where memory tiles are used to store intermediate results...|$|R
40|$|The {{trend in}} new {{state-of-the-art}} FPGAs {{is to have}} large amounts of on-chip embedded <b>memory</b> <b>blocks.</b> These <b>memory</b> <b>blocks</b> are used to hold the input/output data for various applications. Existing register binding techniques in high-level synthesis aim at minimizing the storage requirements of circuits by sharing variables among registers and thus minimizing the required number of registers for a specific design. In this paper, a new technique is proposed that makes use of the existing embedded <b>memory</b> <b>blocks</b> and maps variables to these <b>blocks.</b> The proposed <b>memory</b> binding approach gives considerable performance increase over the existing register binding techniques. The memory binding technique resulted in up to 57 % savings in the total chip area (number of logic cells/elements occupied on the FPGA) over the old register binding techniques for a small resource bag and up to 6 % savings for a large resource bag. N/...|$|R
5000|$|The set is {{determined}} by the index bits derived from the address of the <b>memory</b> <b>block.</b>|$|E
50|$|Streaming {{computations}} can be efficiently accommodated using software pipelining of <b>memory</b> <b>block</b> transfers using a multi-buffering strategy.|$|E
5000|$|Static memory {{management}} supports thread suspend/resume when it allocates/frees a <b>memory</b> <b>block</b> and thread-safe dynamic heap management; ...|$|E
5000|$|C++ can {{allocate}} arbitrary <b>blocks</b> of <b>memory.</b> Java only allocates memory via object instantiation. Arbitrary <b>memory</b> <b>blocks</b> may {{be allocated}} in Java as {{an array of}} bytes.|$|R
5000|$|The home environment, as {{described}} in a 1987 issue of Soviet magazine Technical Aesthetics (Техническая эстетика in Russian), would be composed of [...] "spherical speakers, a detachable monitor, headphones, a handheld remote control with a removable display, a diskette drive, a processor with three <b>memory</b> <b>blocks</b> and more". The modules were designed to be used collectively, or individually by family members, {{and the number of}} <b>memory</b> <b>blocks</b> was supposed to be possibly increased endlessly according {{to the needs of the}} household so different family members could activate different programs simultaneously.|$|R
5000|$|Zoe's {{life after}} {{her return to}} her own time is not further {{explored}} in the series. In the spin-off short story [...] "The Tip of the Mind" [...] by Peter Anghelides, it is revealed that although her intellect allows her to resist the <b>memory</b> <b>blocks</b> by the Time Lords, she is unable to access the memories of her time with the Doctor consciously. This causes her strange dreams, and makes her work suffer. An encounter with the Third Doctor makes the <b>memory</b> <b>blocks</b> permanent, but she ultimately never reaches her full potential.|$|R
