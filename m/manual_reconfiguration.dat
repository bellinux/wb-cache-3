23|4|Public
50|$|Corrective {{actions for}} {{redundant}} items includes <b>manual</b> <b>reconfiguration</b> when automatic fault bypass is not available, which depends upon maintenance coverage.|$|E
5000|$|Administrative overhead: Static routes must be {{configured}} on each router in the network(s). This configuration {{can take}} a long time if there are many routers. It also means that reconfiguration can be slow and inefficient. Dynamic routing on the other hand automatically propagates routing changes, reducing the need for <b>manual</b> <b>reconfiguration.</b>|$|E
50|$|QStar {{announced}} on 19th July 2012, QStar Unveils Industry’s First Software-Based LTFS Volume-Spanning and File-Spanning Capability for Tape Libraries. With {{the use of}} QStar’s LTFS volume-spanning technology, all media within the tape library {{can be seen as}} one or more ever-growing network share(s). New LTFS media is automatically added to the set as the previous media becomes full. This approach eliminates the constant stopping and <b>manual</b> <b>reconfiguration</b> required by standard LTFS methodologies as a tape reaches capacity.|$|E
40|$|Our {{vision is}} that mobile {{computational}} devices should behave always {{appropriate for the}} situation the user is currently in. The device will become a generic tool accompanying the user in all its situations of his everyday life and it will embrace the complete scale of electronic functionality. We will use mobile devices equally for communication as for payment, as keys, as entertainment gadgets, navigation tools, and capable of providing arbitrary specific features. Compared to personal computers we think there is something very special about mobile devices {{with regard to their}} generic usability. On the one hand, mobile devices demand automatic adaptivity, because its user is always on the move and does not have time for <b>manual</b> <b>reconfigurations</b> when he suddenly finds himself in a situation where he requires additional functionality. On the other hand, mobile devices are increasingly capable of perceiving their current use context. I. e. they can perceive context data as light, noise, temperature, time, user, location, and co-located devices etc. Context-Sensitive Intelligenc...|$|R
40|$|An {{increasing}} {{amount of}} Web services are being implemented using process management tools and languages (BPML, BPEL, etc.). The main advantage of processes is that designers can express complex business conversations {{at a high}} level of abstraction, even reusing standardized business protocols. The downside is that the infrastructure behind the Web service becomes more complex. This is particularly critical for Web services that may be subjected to high variability in demand and suffer from unpredictable peaks of heavy load. In this paper we present a flexible architecture for process execution that has been designed to support autonomic scalability. The system runs on a cluster of computers and reacts to workload variations by altering its configuration in order to optimally use the available resources. Such changes happen automatically and without any human intervention. This feature completely removes the need for the <b>manual</b> monitoring and <b>reconfiguration</b> of the system, which in practice is a difficult and time-consuming operation. In the paper we describe the architecture of the system and present an extensive performance evaluation of its autonomic capabilities. ...|$|R
40|$|Multi-display environments (MDEs) of {{all kinds}} are used a lot nowadays. A wide variety of devices helps to build a common display space. TVs, monitors, {{projected}} surfaces, phones, tablets, everything that {{has the ability to}} display visual information can be incorporated in multi-display environments. While the main research emphasis so far has been on interaction techniques and user experience within different MDEs, some research topics are dealing with static and dynamic display reconfiguration. In fact, several studies already work with MDEs that are capable of display reconfiguration on-the-fly. Different frameworks can perform splitting, streaming and rendering of visual data on large-scale displays with the ability of dynamic display reconfiguration to calibrate multiple-projectors or to combine different heterogeneous displays into one display wall dynamically. However, all of these frameworks require different approaches for display reconfiguration. Our goal is to create a model for display reconfiguration which will be abstract, transparent, will work in real-time, and will be easily deployable in any MDE. In this work we present an extension to a software framework called Display as a Service (DaaS). This extension is represented as a model for real-time display reconfiguration using DaaS. The DaaS framework allows for generic and transparent management of pixel-transport assuming only a network connection, providing a simple high-level implementation for pixel-producing and pixel-displaying applications. The main limitation of this approach is a certain delay between pixel generation and display. However, the video encoding and network transport are subject of improvements which will solve the problem in the future. As a proof of concept, we demonstrate three usage scenarios: <b>manual</b> dynamic display <b>reconfiguration,</b> automatic display calibration, and real-time display tracking. We also present a new algorithm for precise display calibration using markers and a handheld camera. The calibration results are evaluated using different tracking libraries. The additional precise calibration part for our proposed algorithm makes the calibration accuracy several times better compared to a naive approach...|$|R
40|$|The ever-growing {{complexity}} of today’s computing systems renders <b>manual</b> <b>reconfiguration</b> infeasible. Instead, systems {{must be able}} to adapt themselves to changes in their environment. Thus adaptivity becomes a key feature of a system. However, so far no general metric for the comparison of systems according to their adaptivity has been established. In this paper we identify the two dimensions of adaptivity, review a number of approaches and then seek to define a sufficiently generic metric. I...|$|E
40|$|The {{advent of}} {{inexpensive}} computers has spurred interest in distributed architectures, {{in which a}} cluster of low-cost computers can achieve performance on the same scale as expensive super-computers. The goal of research in distributed systems {{is to take a}} highly decomposable problem solution, and put that solution into a framework that allows the system {{to take full advantage of}} the solution's decomposability. An architecture that allows additional processors to be taken advantage of with little or no <b>manual</b> <b>reconfiguration</b> would be ideal...|$|E
40|$|Abstract—Future {{manufacturing}} {{systems have}} to be more adaptable to be able to compete in fast changing markets and address specific customer demands. To increase adaptability of production systems, the software and communication infrastruc-tures {{have to be}} adaptable as well. Current communication paradigms tightly couple manufacturing systems to communi-cation infrastructures. Changes in the manufacturing system require <b>manual</b> <b>reconfiguration</b> of software and communication infrastructure. In this paper we define the requirements for future adaptable manufacturing systems. They have to be loosely coupled, dynamic, adaptable, and capable of plug & play. We also propose a data-centric approach to make communication systems more adaptable. Using a simplified industrial setup, we show that the approach is feasible for manufacturing systems and increases the adaptability. I...|$|E
40|$|The Orion {{spacecraft}} {{will replace}} the space shuttle and {{will be the first}} human spacecraft since the Apollo program to leave low earth orbit. This vehicle will serve as the cornerstone of a complete space transportation system with a myriad of mission requirements necessitating rendezvous to multiple vehicles in earth orbit, around the moon and eventually beyond. These goals will require a complex and robust vehicle that is, significantly different from both the space shuttle and the command module of the Apollo program. Historically, orbit operations have been accomplished with heavy reliance on ground support and <b>manual</b> crew <b>reconfiguration</b> and monitoring. One major difference with Orion is that automation will be incorporated as a key element of the man-vehicle system. The automated system will consist of software devoted to transitioning between events based on a master timeline. This effectively adds a layer of high level sequencing that moves control of the vehicle from one phase to the next. This type of automated control is not entirely new to spacecraft since the shuttle uses a version of this during ascent and entry operations. During shuttle orbit operations however many of the software modes and hardware switches must be manually configured through the use of printed procedures and instructions voiced from the ground. The goal of the automation scheme on Orion is to extend high level automation to all flight phases. The move towards automation represents a large shift from current space shuttle operations, and so these new systems will be adopted gradually via various safeguards. These include features such as authority-to-proceed, manual down modes, and functional inhibits. This paper describes the contrast between the manual and ground approach of the space shuttle and the proposed automation of the Orion vehicle. I will introduce typical orbit operations that are common to all rendezvous missions and go on to describe the current Orion automation architecture and contrast it with shuttle rendezvous techniques and circumstances. The shuttle rendezvous profile is timed to take approximately 3 days from orbit insertion to docking at the International Space Station (ISS). This process can be divided into 3 phases: far-field, mid-field and proximity operations. The far-field stage is characterized as the most quiescent phase. The spacecraft is usually too far to navigate using relative sensors and uses the Inertial Measurement Units (IMU s) to numerically solve for its position. The maneuvers are infrequent, roughly twice per day, and are larger than other burns in the profile. The shuttle uses this opportunity to take extensive ground based radar updates and keep high fidelity orbit states on the ground. This state is then periodically uplinked to the shuttle computers. The targeting solutions for burn maneuvers are also computed on the ground and uplinked. During the burn the crew is responsible for setting the shuttle attitude and configuring the propulsion system for ignition. Again this entire process is manually driven by both crew and ground activity. The only automatic processes that occur are associated with the real-time execution of the burn. The Orion automated functionality will seek to relieve the workload of both the crew and ground during this phas...|$|R
40|$|In this ever-changing {{business}} environment, {{business processes}} {{are constantly being}} customized to reflect the up-to-date organizational structure and business objectives. Furthermore, technological updates and innovation also affect the way business is carried out. A workplace application provides an interactive electronic working environment that integrates software applications to assist users in performing their daily work more efficiently. It is challenging to maintain workplace applications as it often involves laborintensive <b>manual</b> <b>reconfiguration</b> to adapt workplace applications to the changes to business processes. In this paper, we propose a workplace design framework that automatically analyzes business processes and generates workplace applications. Furthermore, it permits workplace reconfiguration at run time, which minimizes the interruption to users ’ work and simplifies deployment of business process changes to workplace applications. A prototype workplace application is designed and developed to demonstrate {{the effectiveness of the}} proposed framework. ...|$|E
40|$|Abstract. Admission control aims to {{compensate}} for the inability of slow-changing network configurations to react rapidly enough to load fluctuations. Even though many admission control approaches exist, most of them suffer from {{the fact that they are}} based on some very rigid assumptions about the per-flow and aggregate underlying traffic models, requiring <b>manual</b> <b>reconfiguration</b> of their parameters in a “trial and error ” fashion when these original assump-tions stop being valid. In this paper we present a fuzzy reinforcement learning admission control approach based on the increasingly popular Pre-Congestion Notification framework that requires no a priori knowledge about traffic flow characteristics, traffic models and flow dynamics. By means of simulations we show that the scheme can perform well under a variety of traffic and load con-ditions and adapt its behavior accordingly without requiring any overly compli-cated operations and with no need for manual and frequent reconfigurations...|$|E
40|$|Abstract. As {{the vision}} of {{ubiquitous}} computing becomes reality smart devices are embedded into our surroundings and domestic appliances providing services transparently. The nature of such smart computing environments is open and dynamic; therefore the use of predefined security associations between all of the participating devices is particularly difficult. Our proposal, called ÆTHER, defines a security management architecture designed specifically to address access control {{and the establishment of}} associations in smart environments. Attribute authority sets and access control policy entries are embedded into pervasive devices defining initial trust relationships. Members of the attribute authority sets are trusted to issue credentials for the corresponding attributes that can then be used to gain access to services provided by smart devices. We allow these sets to grow dynamically without requiring <b>manual</b> <b>reconfiguration</b> facilitating decentralized administration, which is required in volatile pervasive environments, and attribute mapping to allow roaming among smart authority domains. ...|$|E
30|$|This paper {{proposes a}} scheme to extend {{component}} models such that all component interfaces provide a compact semantic description of the functionality that they offer. This scheme facilitates <b>manual</b> <b>reconfiguration</b> by allowing the developer to reason {{at the level of}} functionally equivalent services, rather than unique interfaces, and supports autonomic reconfiguration through runtime compatibility testing of interface pairs. We have implemented this scheme for the Loosely Coupled Component Infrastructure (LooCI) component model [4]. Our evaluation shows that this scheme imposes minimal computational and memory overhead, while reducing the development complexity and bandwidth requirements of reconfiguration actions. In relation to our previous work [4, 10, 11], this paper offers the following unique contributions: (i) a complete description of the semantic type system of LooCI, (ii) a large-scale analytic evaluation and (iii) performance figures that quantify the overhead of semantics for two representative classes of WSN devices: AVR Raven [12] and Sun SPOT [15].|$|E
40|$|International audienceComputing and {{networking}} technologies are becoming ever more pervasive {{in order to}} support their users' increasingly dynamic lifestyles. These technologies aim to increase the networks' awareness of their users' requirements. At the same time, they strive {{to reduce the amount of}} <b>manual</b> <b>reconfiguration</b> and explicit interaction between the users and the network resources. The main problem is the extreme difficulty in reconfiguring the network's resources at runtime and in adapting the network's behaviour automatically according to the changes happening in the surroundings. To address these issues, we investigated the use of the emerging semantic Web technologies, policies, and context information. We also developed an ontology-based reasoning machinery to address the problem of automated adaptability. In this paper, we provide an analysis of the ontologies we developed and the reasoning machinery required increasing the network's awareness of its context. We report on the experiments we conducted to evaluate the techniques we are proposing...|$|E
40|$|Part 2 : Autonomic and Distributed Network ManagementInternational audienceAdmission control aims to {{compensate}} for the inability of slow-changing network configurations to react rapidly enough to load fluctuations. Even though many admission control approaches exist, most of them suffer from {{the fact that they are}} based on some very rigid assumptions about the per-flow and aggregate underlying traffic models, requiring <b>manual</b> <b>reconfiguration</b> of their parameters in a “trial and error” fashion when these original assumptions stop being valid. In this paper we present a fuzzy reinforcement learning admission control approach based on the increasingly popular Pre-Congestion Notification framework that requires no a priori knowledge about traffic flow characteristics, traffic models and flow dynamics. By means of simulations we show that the scheme can perform well under a variety of traffic and load conditions and adapt its behavior accordingly without requiring any overly complicated operations and with no need for manual and frequent reconfigurations...|$|E
40|$|Computing and {{networking}} technologies are becoming ever more pervasive {{in order to}} support their users ’ increasingly dynamic lifestyles. These technologies aim to increase the networks ’ awareness of their users ’ requirements. At the same time, they strive {{to reduce the amount of}} <b>manual</b> <b>reconfiguration</b> and explicit interaction between the users and the network resources. The main problem is the extreme difficulty in reconfiguring the network’s resources at runtime and in adapting the network’s behaviour automatically according to the changes happening in the surroundings. To address these issues, we investigated the use of the emerging semantic web technologies, policies, and context information. We also developed an ontology-based reasoning machinery to address the problem of automated adaptability. In this paper, we provide an analysis of the ontologies we developed and the reasoning machinery required to increase the network’s awareness of its context. We report on the experiments we conducted to evaluate the techniques we are proposing...|$|E
40|$|In {{this paper}} we present {{the design and}} {{evaluate}} the performance of an autonomic workflow execution engine. Although there exist many distributed workflow engines, in practice, it remains a difficult problem to deploy such systems in an optimal configuration. Furthermore, when facing an unpredictable workload with high variability, <b>manual</b> <b>reconfiguration</b> is not an option. Thanks to its autonomic controller, the engine features self-configuration, self-tuning and self-healing properties. The engine runs on a cluster of computers using a tuple space to coordinate its various components. Its autonomic controller monitors its performance and responds to workload variations by altering the configuration. In case failures occur, the controller can recover the workflow execution state from persistent storage and migrate it to a different node of the cluster. Such interventions are carried out without any human supervision. As part {{of the results of}} our performance evaluation, we compare different autonomic control strategies and discuss how they can automatically tune the system...|$|E
40|$|In {{this ever}} {{changing}} business environment, business processes {{are constantly being}} customized to reflect the up-to-date organizational structure and business objectives. Technology updates and innovation also affect the way business is carried out. A workplace application provides an interactive electronic working environment that integrates software applications to assist users in performing their daily work more efficiently. Managing and maintaining workplace applications within an organization is a challenging job, since it often involves labor intensive <b>manual</b> <b>reconfiguration</b> to adapt the workplace to the changes in business processes. In this paper, we propose a dynamic reconfigurable workplace framework that supports {{the changing nature of}} the business domain. This framework updates the workplace at run time, minimizes the interruption to users ’ work, and simplifies the evolution of a business application. The effectiveness of the framework is studied by examining changes to several business processes and the ability of the framework to update the corresponding workplaces...|$|E
40|$|Abstract — In {{order for}} Grids to become relied upon for {{critical}} infrastructure and reliable scientific computing, Grid-wide management must be automated {{so that it}} is possible in quickly and comprehensively respond to or anticipate specific environmental changes and requirements. That is, due to the disjoint administration of Grids which results in high communication requirements as well as large numbers of skilled administrators, <b>manual</b> <b>reconfiguration</b> of large portions of a Grid in such situations is not a viable solution. We have developed an architecture that allows changes to the grid configuration to be automated in response to operator input or sensors placed throughout the Grid. Additionally, our architecture allows the resource owner to specify who is allowed to alter the configuration of his resource and what types of reconfigurations are allowed. This permits the automation of reconfiguration while retaining owner control of the individual resources. Our experiments show that this architecture can be used to reconfigure a representative GT 4 -based development grid in order to enforce maximum latency limits on a Virtual Organization’s jobs by dynamically controlling job priorities Grid-wide. I...|$|E
40|$|Abstract—Evaluating user {{interfaces}} with virtual user models {{is a means}} for rapid prototyping. Setting up a simulation environment for virtual user models often requires high effort due to the heterogeneous simulation tools. Furthermore, the frequent reconfigurations of the simulation due to the rapid changes of the user interface prototypes impose a high amount of workload upon the user. In particular, the <b>manual</b> <b>reconfiguration</b> of the com-munication between the simulation components is very complex and error prone. Small changes to the user interface often result in changes in the communication of several components. Our solution is the automatic generation of the communication data description for all simulation components. This paper presents the implemented solution and illustrates it with two scenarios from the maritime domain. These scenarios deal with collision avoidance strategies and new concepts for route exchanges between ships and vessel traffic service centres. The automated generation process facilitates handling the emerging changes, which are required in the complex simulation configurations. The evaluation of how well this supports the rapid prototyping process in these scenarios is not addressed in this paper, but is the topic of ongoing research. Keywords–rapid prototyping; virtual user models; co-simulation; user interface evaluation. I...|$|E
40|$|Abstract: Tone mapping {{algorithms}} {{are used}} to adapt captured wide dynamic range (WDR) scenes to the limited dynamic range of available display devices. Although there are several tone mapping algorithms available, most of them require manual tuning of their rendering parameters. In addition, the high complexities {{of some of these}} algorithms make it difficult to implement efficient real-time hardware systems. In this work, a real-time hardware implementation of an exponent-based tone mapping algorithm is presented. The algorithm performs a mixture of both global and local compression on colored WDR images. An automatic parameter selector has been proposed for the tone mapping algorithm in order to achieve good tone-mapped images without <b>manual</b> <b>reconfiguration</b> of the algorithm for each WDR image. Both algorithms are described in Verilog and synthesized for a field programmable gate array (FPGA). The hardware architecture employs a combination of parallelism and system pipelining, so as to achieve a high performance in power consumption, hardware resources usage and processing speed. Results show that the hardware architecture produces images of good visual quality that can be compared to software-based tone mapping algorithms. High peak signal-to-noise ratio (PSNR) an...|$|E
40|$|Due {{to their}} {{constrained}} nature, {{wireless sensor networks}} (WSNs) are often optimised for a specific application domain, for example by designing a custom medium access control protocol. However, when several WSNs are located {{in close proximity to}} one another, the performance of the individual networks can be negatively affected as a result of unexpected protocol interactions. The performance impact of this 'protocol interference' depends on the exact set of protocols and (network) services used. This paper therefore proposes an optimisation approach that uses self-learning techniques to automatically learn the optimal combination of services and/or protocols in each individual network. We introduce tools capable of discovering this optimal set of services and protocols for any given set of co-located heterogeneous sensor networks. These tools eliminate the need for <b>manual</b> <b>reconfiguration</b> while only requiring minimal a priori knowledge about the network. A continuous re-evaluation of the decision process provides resilience to volatile networking conditions in case of highly dynamic environments. The methodology is experimentally evaluated in a large scale testbed using both single- and multihop scenarios, showing a clear decrease in end-to-end delay and an increase in reliability of almost 25 %...|$|E
40|$|Virtual private {{networks}} (VPN) offer {{services for}} secure data exchange over public networks and are steadily gaining importance for commercial organizations, private individuals {{as well as}} governments and military administrations. However, growing VPN sizes and a dynamic behavior of VPN gateways and clients, e. g., for mobility reasons or perhaps reactions due to denial-of-service (DoS) attacks, make a manual configuration of large, dynamic VPN complicated and expensive. First, the administrative overhead is subject to a quadratic growth {{with the number of}} VPN devices, if each VPN device shall be able to communicate with every other VPN device. This will not only lead to higher expenses, but also to more errors introduced by human failure. Second, the robustness of the VPN is not as high as it could be, e. g., in case of partial failures of the transport network some VPN devices could redirect traffic for other devices that cannot reach each other directly anymore. Even though IPsec could support such a resilient behavior by utilizing nested security associations, <b>manual</b> <b>reconfiguration</b> prohibits a timely reaction. Third, manually configured security associations cannot be adopted with sufficient flexibility to support mobile VPNs appropriately. It is impossible to configure security associations between tw...|$|E
40|$|Tone mapping {{algorithms}} {{are used}} to adapt captured wide dynamic range (WDR) scenes to the limited dynamic range of available display devices. Although there are several tone mapping algorithms available, most of them require manual tuning of their rendering parameters. In addition, the high complexities {{of some of these}} algorithms make it difficult to implement efficient real-time hardware systems. In this work, a real-time hardware implementation of an exponent-based tone mapping algorithm is presented. The algorithm performs a mixture of both global and local compression on colored WDR images. An automatic parameter selector has been proposed for the tone mapping algorithm in order to achieve good tone-mapped images without <b>manual</b> <b>reconfiguration</b> of the algorithm for each WDR image. Both algorithms are described in Verilog and synthesized for a field programmable gate array (FPGA). The hardware architecture employs a combination of parallelism and system pipelining, so as to achieve a high performance in power consumption, hardware resources usage and processing speed. Results show that the hardware architecture produces images of good visual quality that can be compared to software-based tone mapping algorithms. High peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) scores were obtained when the results were compared with output images obtained from software simulations using MATLAB...|$|E
40|$|The {{proliferation}} of servers on the Internet {{has led to}} the emergence of server load balance as an important service in cloud aiming to optimize resource usage, maximize throughput and minimize the response time. Server load balance is the process and technology that distributes incoming requests among several servers in order tominimize the response time and maximize the utilization of servers. The existing schemes of the load balance (dynamic or static) do not consider the service types as well as the size of the request. Besides, these schemes are implemented either in dedicated hardware devices called load-balancer or built intothe Operating System (OS) such as Linux Virtual Server (LVS). It is difficult to customize the built-in LB scheme during runtime. Additionally, load balancer experiences problems due to the same scheme being used for different type of services. In the cloud, most Service Providers (SP) host various kinds of services that require different load balancing schemes. This requires theinstallation of additional load-balancers for each service or a <b>manual</b> <b>reconfiguration</b> of the device to handle the new services. Such operation is time-consuming and expensive(Marc Koerner & Kao, 2012). To address aforementioned problems, we proposed a service based load balance (SBLB) mechanism using Software-Defined Networks (SDN). The SDN controller is leveraged to provide online flow classification. The proposed mechanism is evaluated using benchmarking experiments and validated using a statisticalmodel. We investigate the impact of the different type of requests (compute and data) on SBLB mechanism in homogeneous and heterogeneous environments. The results demonstrate that SBLB can provide faster response time, higher throughput as compared to the other load balance solutions. For example, SBLB mechanism can reduce the average response time (ART) up to 5...|$|E
40|$|The {{inability}} to seamlessly disseminate data securely over a high-integrity, wireless broadband network {{has been identified}} as a primary technical barrier to providing an order-of-magnitude increase in aviation capacity and safety. Secure, autonomous communications to and from aircraft will enable advanced, automated, data-intensive air traffic management concepts, increase National Air Space (NAS) capacity, and potentially reduce the overall cost of air travel operations. For the first time ever, secure, mobile, network technology was designed, developed, and demonstrated with state-ofthe- art protocols and applications by a diverse, cooperative Government-industry team led by the NASA Glenn Research Center. This revolutionary technology solution will make fundamentally new airplane system capabilities possible by enabling secure, seamless network connections from platforms in motion (e. g., cars, ships, aircraft, and satellites) to existing terrestrial systems without the need for <b>manual</b> <b>reconfiguration.</b> Called Mobile Router, the new technology autonomously connects and configures networks as they traverse from one operating theater to another. The Mobile Router demonstration aboard the Neah Bay, a U. S. Coast Guard vessel stationed in Cleveland, Ohio, accomplished secure, seamless interoperability of mobile network systems across multiple domains without manual system reconfiguration. The Neah Bay was chosen because of its low cost and communications mission similarity to low-Earth-orbiting satellite platforms. This technology was successfully advanced from technology readiness level (TRL) 2 (concept and/or application formation) to TRL 6 (system model or prototype demonstration in a relevant environment). The secure, seamless interoperability offered by the Mobile Router and encryption device will enable several new, vehicle-specific and systemwide technologies to perform such things as remote, autonomous aircraft performance monitoring and early detection and mitigation of potential equipment malfunctions. As an additional benefit, team advancements were incorporated into open standards, ensuring technology transfer. Low-cost, commercial products incorporating the new technology are already available. Furthermore, these products are fully interoperable with legacy network technology equipment currently being used throughout the world...|$|E

