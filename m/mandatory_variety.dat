1|5|Public
40|$|Value for Cultivation and Use (VCU), the <b>mandatory</b> <b>variety</b> testing {{system for}} {{agricultural}} crops in the European Union (EU), {{has been used}} as a policy instrument by favouring the release of variety types that enable socially desirable developments, such as reducing fungicide use. With this paper, we aim to assess whether VCU can be used to enhance the availability of varieties suitable to organic farming. Therefore, we analyse data of an organic spring wheat VCU project that was conducted between 2001 and 2004 at three locations in the Netherlands. Varieties selected through organic VCU were clearly more suitable for organic production than those registered through the conventional procedure. However, new varieties could not match the baking quality of the organic standard variety. We conclude that enhancing the number of suitable varieties for the organic sector requires adapting both conventional breeding programmes as well as the VCU system...|$|E
50|$|Vehicle {{impoundment}} is an option, or is <b>mandatory,</b> for a <b>variety</b> of offences, {{among them}} exceeding a posted speed limit {{by at least}} 50 km/h and drink-driving.|$|R
40|$|We study optimal {{disclosure}} of variety by a multi-product firm with random costs. In our model {{there are two}} varieties that are horizontally differentiated and differ in overall quality, but buyers cannot distinguish between them without labels. The equilibrium prices for labeled varieties are increasing functions of the absolute value of the cost differential and do not reveal which variety is cheaper to produce. Nondisclosure is most common when there is moderate uncertainty about the relative input cost, not too much idiosyncrasy in consumer valuations, and not too much difference in quality across <b>varieties.</b> Although <b>mandatory</b> {{disclosure of}} <b>variety</b> benefits consumers, it decreases expected welfare when relative input cost variability is large and quality asymmetry is small. The cheaper variety tends to be oversupplied (undersupplied) when disclosure is voluntary (mandatory). Competition among multi-product firms that source inputs in the same upstream market may not lead to more disclosure. "information, product differentiation, Labeling, quality disclosure,...|$|R
40|$|BACKGROUND: With the {{emergence}} of the tumor microenvironment as an essential ingredient of cancer malignancy, therapies targeting the host compartment of tumors have begun to be designed and applied in the clinic. CONTENT: The malignant features of cancer cells cannot be manifested without an important interplay between cancer cells and their local environment. The tumor infiltrate composed of immune cells, angiogenic vascular cells, lymphatic endothelial cells, and cancer-associated fibroblastic cells contributes actively to cancer progression. The ability to change these surroundings is an important property by which tumor cells are able to acquire some of the hallmark functions necessary for tumor growth and metastatic dissemination. Thus in the clinical setting the targeting of the tumor microenvironment to encapsulate or destroy cancer cells in their local environment has become <b>mandatory.</b> The <b>variety</b> of stromal cells, the complexity of the molecular components of the tumor stroma, and the similarity with normal tissue present huge challenges for therapies targeting the tumor microenvironment. These issues and their interplay are addressed in this review. After a decade of intensive clinical trials targeting cellular components of the tumor microenvironment, more recent investigations have shed light on the important role in cancer progression played by the noncellular stromal compartment composed of the extracellular matrix. SUMMARY: A better understanding of how the tumor environment affects cancer progression should provide new targets for the isolation and destruction of cancer cells via interference with the complex crosstalk established between cancer cells, host cells, and their surrounding extracellular matrix. Peer reviewe...|$|R
40|$|This is {{the report}} of a study based on a Melbourne Secondary School looking at the use of laptop {{computers}} made by the staff in their teaching. Questionnaires were the instrument used to find {{a measure of the}} level of penetration and overall acceptance of laptop computers and computer technology by the Teaching Staff. The questionnaire was administered in 1997 and again in 1999. This study looks, with regard to the use of laptop computers by staff, at aspects of the teaching curriculum, administrative tasks and teaching at the classroom level over the two-year period 1997 to 1999. The questionnaire used is a `census' of all staff teaching at Years 9 - 12 where the laptop program is <b>mandatory</b> in a <b>variety</b> of study areas. The finding of this report is that the program at Goodlands Grammar has, {{at least in the short}} term, created a teaching environment that is still working within the traditional curriculum, using computers to achieve traditional outcomes. The computer has not, as yet, become integrated into the classroom program; rather it remains a complicated overlay to the existing curriculum. Restricted Access: University of Melbourne Staff and Students Onl...|$|R
40|$|Astrophysics {{is in need}} of a broad {{variety of}} nuclear data. This {{concerns}} static ground state properties, characteristics of excited nuclei, spontaneous decay properties, or interactions of nuclei with (mainly) nucleons, α-particles or photons. A strong theoretical activity complementing laboratory efforts is also <b>mandatory.</b> A large <b>variety</b> of highly 'exotic' laboratory-unreachable nuclei are indeed involved in the astrophysics modelling. Even when laboratory-studied nuclei are considered, theory has very often to be called for. Mastering the huge volume of nuclear information and making it available in an accurate and usable form for incorporation into astrophysics models is clearly of pivotal importance. The recognition of this necessity has been the driving motivation for the construction of the Brussels library (BRUSLIB) of computed data of astrophysics relevance. It provides an extended information in tabular form on masses, nuclear level densities and partition functions, fission barriers, and thermonuclear reaction rates. In addition of the unprecedented broadness of its scope, BRUSLIB has the unique and most important feature of relying to the largest possible extent on global and coherent microscopic nuclear models. The models of this sort that we have developed to predict the basic properties of the nuclei and of their interactions are briefly reviewed. The content of the BRUSLIB library that relies on these models is described, as well as a user-friendly nuclear network generator (NETGEN) complementing BRUSLIB. Finally, an application of BRUSLIB and NETGEN to the p-process nucleosynthesis during He detonation in sub-Chandrasekhar CO white dwarfs is proposed. © 2005 Elsevier B. V. All rights reserved. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R

