682|1199|Public
25|$|The early programmers had to {{make use}} of {{techniques}} frowned upon today— especially altering the code. As there was no index register until much later, the only way of accessing an array was to alter which <b>memory</b> <b>location</b> a particular instruction was referencing.|$|E
25|$|As device {{management}} {{is a very}} OS-specific topic, these drivers are handled differently by each kind of kernel design, but in every case, the kernel has to provide the I/O to allow drivers to physically access their devices through some port or <b>memory</b> <b>location.</b> Very important decisions {{have to be made}} when designing the device management system, as in some designs accesses may involve context switches, making the operation very CPU-intensive and easily causing a significant performance overhead.|$|E
25|$|The little-endian {{system has}} the {{property}} {{that the same}} value can be read from memory at different lengths without using different addresses (even when alignment restrictions are imposed). For example, a 32-bit <b>memory</b> <b>location</b> with content 4A 00 00 00 can be read at the same address as either 8-bit (value = 4A), 16-bit (004A), 24-bit (00004A), or 32-bit (0000004A), all of which retain the same numeric value. Although this little-endian property is rarely used directly by high-level programmers, it is often employed by code optimizers {{as well as by}} assembly language programmers.|$|E
50|$|Some {{operations}} used specific <b>memory</b> <b>locations</b> (those locations {{were not}} reserved {{and could be}} used for other purposes). Read a card stored the 80 columns of data from a card into <b>memory</b> <b>locations</b> 001-080. Index registers 1, 2 and 3 were in <b>memory</b> <b>locations</b> 087-089, 092-094 and 097-099 respectively. Punch a card punched the contents of <b>memory</b> <b>locations</b> 101-180 into a card. Write a line printed the contents of <b>memory</b> <b>locations</b> 201-332.|$|R
50|$|In this case, with A2 {{always being}} zero, {{the first four}} <b>memory</b> <b>locations</b> are {{duplicated}} and appear again as the second four. <b>Memory</b> <b>locations</b> 4 through 7 have become inaccessible.|$|R
50|$|Note {{that the}} way memory is {{addressed}} {{has no effect on}} the access time for <b>memory</b> <b>locations</b> which are already cached, having an impact only on <b>memory</b> <b>locations</b> which need to be retrieved from DRAM.|$|R
25|$|The {{relatively}} small number of processors in early systems, allowed them to easily use a shared memory architecture, which allows processors to access a common pool of memory. In the early days a common approach was the use of uniform memory access (UMA), in which access time to a <b>memory</b> <b>location</b> was similar between processors. The use of non-uniform memory access (NUMA) allowed a processor to access its own local memory faster than other memory locations, while cache-only memory architectures (COMA) allowed for the local memory of each processor to be used as cache, thus requiring coordination as memory values changed.|$|E
25|$|Intel Corporation saw {{the massive}} {{potential}} of the invention and introduced the first commercial NOR type flash chip in 1988. NOR-based flash has long erase and write times, but provides full address and data buses, allowing random access to any <b>memory</b> <b>location.</b> This makes it a suitable replacement for older read-only memory (ROM) chips, which are used to store program code that rarely needs to be updated, such as a computer's BIOS or the firmware of set-top boxes. Its endurance may be from as little as 100 erase cycles for an on-chip flash memory, to a more typical 10,000 or 100,000 erase cycles, up to 1,000,000 erase cycles. NOR-based flash was the basis of early flash-based removable media; CompactFlash was originally based on it, though later cards moved to less expensive NANDflash.|$|E
2500|$|On a little-endian system, the bytes {{are written}} {{from left to}} right in {{increasing}} significance, starting with the one's byte: 0Dh at +0, 0Ch at +1, 0Bh at +2, 0Ah at +3. Writing a 32-bit binary value to a <b>memory</b> <b>location</b> on a little-endian system and outputting the <b>memory</b> <b>location</b> (with growing addresses {{from left to right}}) shows that the order is reversed (byte-swapped) compared to usual big-endian notation. This is the way a hexdump is displayed: because the dumping program is unable to know what kind of data it is dumping, the only orientation it can observe is monotonically increasing addresses. The human reader, however, who knows {{that he or she is}} reading a hexdump of a little-endian system and who knows what kind of data he or she is reading, reads the byte sequence 0Dh,0Ch,0Bh,0Ah as the 32-bit binary value 168496141, or 0x0a0b0c0d in hexadecimal notation. (Of course, this is not the same as the number 0D0C0B0Ah = 0x0d0c0b0a = 218893066.) ...|$|E
50|$|DCAS is {{sometimes}} {{confused with the}} double-width compare-and-swap (DWCAS) implemented by instructions such as x86 CMPXCHG16B. DCAS, as discussed here, handles two discontiguous <b>memory</b> <b>locations,</b> typically of pointer size, whereas DWCAS handles two adjacent pointer-sized <b>memory</b> <b>locations.</b>|$|R
30|$|The third {{implemented}} distributed RPA {{with local}} network, uses 2 M/K FIFOs for each processor element, plus (K- 2)M/ 2 K <b>memory</b> <b>locations</b> {{as the local}} net memory in each processor elements. Totally each processor elements requires a total of (M/ 2 +M/K) <b>location</b> <b>memory</b> to store the particles. The overall required memory is (M+KM/ 2). In the comparison, the architecture presented in [6] needs M <b>memory</b> <b>locations</b> for each processor elements (M/K inside the processor elements plus (K- 1)M/K <b>memory</b> <b>locations</b> at the CU). Thus, the total <b>memory</b> <b>locations</b> required in [6] design is MK. Thus, our implementation has a resource reduction advantage of M(K - 2)/ 2 {{in addition to a}} speed advantage without compromising the SIRF performance.|$|R
50|$|Three {{reserved}} <b>memory</b> <b>locations</b> {{were used}} as address indexing 'registers'. The third index register was dedicated to pointing at the current procedure's stack frame on the call/return stack. Other reserved <b>memory</b> <b>locations</b> controlled operand sizes when that size was not constant.|$|R
2500|$|Hardware {{designers}} later developed EEPROMs {{with the}} erasure region broken up into smaller [...] "fields" [...] {{that could be}} erased individually without affecting the others. Altering {{the contents of a}} particular <b>memory</b> <b>location</b> involved copying the entire field into an off-chip buffer memory, erasing the field, modifying the data as required in the buffer, and re-writing it into the same field. This required considerable computer support, and PC-based EEPROM flash memory systems often carried their own dedicated microprocessor system. Flash drives are more or less a miniaturized version of this.|$|E
2500|$|In {{computer}} programming, {{the symbol}} [...] "?" [...] {{has a special}} meaning in many programming languages. In C-descended languages, [...] "?" [...] {{is part of the}} [...] operator, which is used to evaluate simple boolean conditions. In C# 2.0, the [...] "?" [...] modifier is used to handle nullable data types and [...] "??" [...] is the null coalescing operator. In the POSIX syntax for regular expressions, such as the one used in Perl and Python, ? stands for [...] "zero or one instance of the previous subexpression", i.e. an optional element. In certain implementations of the BASIC programming language, the [...] "?" [...] character may be used as a shorthand for the [...] "print" [...] function; in others (notably the BBC BASIC family), [...] "?" [...] is used to address a single-byte <b>memory</b> <b>location.</b> In OCaml, the question mark precedes the label for an optional parameter. In Scheme, as a convention, symbol names ending in ? are used for predicates such as odd?, null?, and eq?. Similarly, in Ruby, method names ending in ? are used for predicates. In Swift, a type followed by [...] "?" [...] denotes an option type; [...] "?" [...] is also used in [...] "optional chaining", where if an option value is nil, it ignores the following operations.|$|E
2500|$|Users {{prepared}} {{their programs}} by punching them (in assembler) onto a paper tape. They soon became good at {{being able to}} hold the paper tape {{up to the light}} and read back the codes. When a program was ready it was hung on a length of line strung up near the paper tape reader. The machine operators, who were present during the day, selected the next tape from the line and loaded it into EDSAC. This is of course well known today as job queues. If it printed something then the tape and the printout were returned to the user, otherwise they were informed at which <b>memory</b> <b>location</b> it had stopped. Debuggers were some time away, but a CRT screen could be set to display the contents of a particular piece of memory. This was used to see if a number was converging, for example. A loudspeaker was connected to the accumulator's sign bit; experienced users knew healthy and unhealthy sounds of programs, particularly programs 'hung' in a loop. [...] After office hours certain [...] "Authorised Users" [...] were allowed to run the machine for themselves, which went on late into the night until a valve blew – which usually happened according to one such user.|$|E
5000|$|When {{performing}} alias {{analysis for}} code, every load and store to memory {{needs to be}} labeled with its class. We then have the useful property, given <b>memory</b> <b>locations</b> [...] and [...] with [...] alias classes, that if [...] then [...] may-alias , and if [...] then the <b>memory</b> <b>locations</b> will not alias.|$|R
5000|$|Gather support, {{enabling}} vector {{elements to}} be loaded from non-contiguous <b>memory</b> <b>locations</b> ...|$|R
5000|$|Saving data on {{multiple}} <b>memory</b> <b>locations</b> will guarantee the safekeeping of the acts.|$|R
50|$|In a Reverse Subtract and Skip if Borrow (RSSB) instruction, the {{accumulator}} is {{subtracted from}} the <b>memory</b> <b>location</b> {{and the next}} instruction is skipped {{if there was a}} borrow (<b>memory</b> <b>location</b> was smaller than the accumulator). The result is stored in both the accumulator and the <b>memory</b> <b>location.</b> The program counter is mapped to <b>memory</b> <b>location</b> 0. The accumulator is mapped to <b>memory</b> <b>location</b> 1.|$|E
5000|$|The {{contents}} of <b>memory</b> <b>location</b> {{are added to}} Accumulator A. The {{contents of}} the <b>memory</b> <b>location</b> remain unchanged.|$|E
5000|$|WNTY: Write Numeric TYpewriter: each <b>memory</b> <b>location</b> {{contained}} a 6-bit {{character in the}} range of 000000 to 001001; with this instruction, each <b>memory</b> <b>location</b> was rendered as one of the characters [...] "0" [...] through [...] "9".|$|E
40|$|By {{studying}} {{the behavior of}} programs in the SPECint 95 suite we observed that six out of eight programs exhibit {{a new kind of}} value locality, the frequent value locality, according to which a few values appear very frequently in <b>memory</b> <b>locations</b> and are therefore involved in a large fraction of memory accesses. In these six programs ten distinct values occupy over 50 % of all <b>memory</b> <b>locations</b> and on an average account for nearly 50 % of all memory accesses during program execution. This observation holds for smaller blocks of consecutive <b>memory</b> <b>locations</b> and the set of frequent values remains quite stable over the execution of the program...|$|R
5000|$|... #Caption: An {{illustration}} {{of different ways}} in which <b>memory</b> <b>locations</b> can be cached by particular cache locations ...|$|R
5000|$|Matrices are storied in {{consecutive}} <b>memory</b> <b>locations</b> in {{the order}} determined by varying the rightmost subscript first.|$|R
50|$|Whether or not CPU 2 {{was trying}} to access the <b>memory</b> <b>location,</b> the DPRAM now {{performs}} CPU 1's test. If the test succeeds, the DPRAM sets <b>memory</b> <b>location</b> A to the value specified by CPU 1. If the test fails, the DPRAM copies the value back from the special register to <b>memory</b> <b>location</b> A. Either operation wipes out the special flag value. If CPU 2 now issues a test-and-set, it will succeed.|$|E
50|$|Operands {{in memory}} were {{accessed}} serially, one <b>memory</b> <b>location</b> at a time, and the 1401 could {{read or write}} one <b>memory</b> <b>location</b> within its basic cycle time of 11.5 microseconds.All instruction timings were cited in multiples of this cycle time.|$|E
5000|$|CPU 1 {{issues a}} test-and-set {{instruction}} {{to write to}} [...] "memory location A". The DPRAM does not immediately store the value in <b>memory</b> <b>location</b> A, but instead simultaneously moves the current value to a special register, while setting the contents of <b>memory</b> <b>location</b> A to a special [...] "flag value". If at this point, CPU 2 issues a test-and-set to <b>memory</b> <b>location</b> A, the DPRAM detects the special flag value, and as in Variation 1, issues a BUSY interrupt.|$|E
40|$|AbstractLower bounds for the ‘cycle {{detection}} problem’ {{were recently}} investigated by Fich (1981, 1983). She showed that Floyd's algorithm was optimal among those algorithms which have M = 2 <b>memory</b> <b>locations</b> and which make {{a finite number}} of ‘jumps’. A lower bound for the case where M > 2 was also presented, but the question of whether having more than two <b>memory</b> <b>locations</b> could actually yield a better algorithm was left open. In this report, we show that it cannot. A lower bound was also presented by Fich (1981, 1983) for algorithms which have two <b>memory</b> <b>locations</b> and which make {{a finite number of}} ‘back advances’. We show here that the same lower bound holds even if the restriction on back advances is dropped...|$|R
5000|$|A {{number of}} {{important}} registers, {{such as those of}} the GTIA and POKEY chips, appear at different <b>memory</b> <b>locations.</b>|$|R
5000|$|Sensitive {{register}} instructions: read {{or change}} sensitive registers or <b>memory</b> <b>locations</b> {{such as a}} clock register or interrupt registers: ...|$|R
50|$|A Change Sequence Mode (CSM) {{instruction}} stored {{the next}} instruction address in a <b>memory</b> <b>location</b> and loaded the instruction counter from another <b>memory</b> <b>location.</b> This provided a simple switch between threads within a program, {{similar to the}} sequence/cosequence behaviour of the Honeywell 800 series.|$|E
50|$|The COMX Printer card allowed {{connection}} of parallel and serial printers. Depending on {{what type of}} printer was connected the firmware ROM was selected either with the parallel firmware between <b>memory</b> <b>location</b> @C000-@CFFF and the serial firmware between <b>memory</b> <b>location</b> @D000-@DFFF or the other way around.|$|E
5000|$|A variant is also {{possible}} with two operands and an internal accumulator, where the accumulator is subtracted from the <b>memory</b> <b>location</b> specified by the first operand. The result is stored in both the accumulator and the <b>memory</b> <b>location,</b> and the second operand specifies the branch address: ...|$|E
40|$|Say that a {{parallel}} algorithm that uses p processors and N (>p) shared <b>memory</b> <b>locations</b> is given. The problem of simulating this algorithm by p processors and only p shared <b>memory</b> <b>locations</b> without increasing the running time {{by more than}} a constant factor is considered. A solution for a family of such parallel algorithms is given. The solution utilizes the idea of dynamically changing locations of the addresses of the algorithm throughout the simulation...|$|R
5000|$|Out-of-bounds Memory Access: This occurs by {{accessing}} the <b>memory</b> <b>locations,</b> outside the allocated space. An attacker can rewrite or erase {{all the important}} data stored in those <b>memory</b> <b>locations.</b> Whenever there arises such a case, an error must be generated at the compile time, and zero must be returned at run-time, not letting the program override the memory. A project WebCL Validator, was initiated by the Khronos Group (developers) on handling this vulnerability.|$|R
50|$|Every {{thread in}} CUDA is {{associated}} with a particular index so that in can calculate and access <b>memory</b> <b>locations</b> in an array.|$|R
