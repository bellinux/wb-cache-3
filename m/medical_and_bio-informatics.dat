1|10000|Public
5000|$|Association for <b>Medical</b> <b>and</b> <b>Bio-Informatics,</b> Singapore (AMBIS) ...|$|E
40|$|Distributed {{computing}} {{based on}} the Master-Worker and PULL interaction model is applicable {{to a number of}} applications in high energy physics, <b>medical</b> physics <b>and</b> <b>bio-informatics.</b> We demonstrate a realistic medical physics use-case of a dosimetric system for brachytherapy using distributed Grid resources. We present the efficient techniques for running parallel jobs in a case of the BLAST, a gene sequencing application, {{as well as for the}} Monte Carlo simulation based on Geant 4. We present a strategy for improving the runtime performance and robustness of the jobs as well as for the minimization of the development time needed to migrate the applications to a distributed environment...|$|R
5000|$|Faculty of Computer Science, with B.Sc.degree {{programs}} in Computer Science, Artificial Intelligence, <b>and</b> <b>Bio-Informatics,</b> <b>and</b> a Diploma program in Telecommunication Engineering.|$|R
40|$|Probabilistic models aim {{to explain}} human {{cognition}} {{by appealing to}} the principles of probability theory and statistics, which dictate how an agent should act rationally in situations that involve uncertainty. While probability theory was originally developed as a means of analyzing games of chance, it was quickly realized that probabilities could be used to analyze rational actions {{in a wide range of}} contexts (e. g., Bayes, 1763 / 1958; Laplace, 1795 / 1951). Probabilistic models have come to be used in many disciplines, and are currently the method of choice for an enormous range of applications, including artificial systems for <b>medical</b> inference, <b>bio-informatics,</b> <b>and</b> computer vision. Applying probabilistic models to human cognition thus provides the opportunity to draw upon work in computer science, engineering, mathematics, and statistics, often producing quite surprising connections. There are two challenges involved in developing probabilistic models of cognition. The first challenge is specifying a suitable model. This requires considering the computational problem faced by an agent, the knowledge available to that agent, and the appropriate way to represent that knowledge. The second challenge is evaluating mode...|$|R
40|$|This {{dissertation}} {{describes an}} interdisciplinary research project that spans computer-vision, imaging of biological nanoparticles via cryogenic {{transmission electron microscopy}} (cryo-tem), <b>and</b> <b>bio-informatics</b> / proteomics. This research introduces a new method for reconstructing individual biological particles imaged via cryo-tem with typical accuracies of 88...|$|R
40|$|This article {{examines}} property relations in biotechnology {{by looking at}} open source in the sub-disciplines of genomics <b>and</b> <b>bio-informatics</b> within the context established interpretations of common property in international man-dates on genetic resources. It is argued {{that the role of}} genomics in biotech...|$|R
50|$|Within the six institutes {{the various}} {{scientific}} departments cover all agricultural disciplines except veterinary sciences. In {{addition to the}} Institutes the ARO maintains a computer unit, Genomics <b>and</b> <b>Bio-informatics</b> section, technology transfer (engaged in business related activities), international activities, youth activity units and a library.|$|R
30|$|Yoon Sang Kim He {{obtained}} B.S., M.S., and Ph.D. {{degrees in}} Electrical Engineering from Sungkyunkwan University, Seoul, Korea, in 1993, 1995, 1999, respectively. Currently, he {{is a full}} professor at the School of Computer and Science Engineering, Korea University of Technology Education (KOREATECH), Cheonan, Korea. His research areas include Virtual simulation, Power-IT technology, <b>and</b> <b>Bio-informatics.</b>|$|R
5000|$|By {{conducting}} differential {{gene expression}} <b>and</b> <b>bio-informatics</b> analyses on the tumor reversion cellular models, they identified more than 200 genes {{involved in the}} process of tumor reversion, and specifically TCTP (Translationally Controlled Tumor Protein / Translationally Controlled Tumour Protein [...] ). This work led to potential drugs preventing, and managing cancer by inhibiting the expression of the gene tpt1/TCTP.|$|R
50|$|Meta{{computing}}, as a computing of computing, includes: {{the organization}} of large computer networks, choice of the design criteria (for example: peer-to-peer or centralized solution) and metacomputing software (middleware, metaprogramming) development where, in the specific domains, the concept metacomputing {{is used as a}} description of software meta-layers which are networked platforms for the development of user-oriented calculations, for example for computational physics <b>and</b> <b>bio-informatics.</b>|$|R
40|$|Abstract- Due to {{the revolutionary}} change in data mining <b>and</b> <b>bio-informatics,</b> {{it is very}} useful to use data mining {{techniques}} to evaluate and analyze bio-medical data. In this paper we purpose a frame work for intelligent data mining system for bio databases especially for diabetic patients depending on their medical test reports. The bio-databases are framed based on the various characteristics involved within th...|$|R
50|$|Yves De Koninck {{comes from}} a large family of intellectuals and scholars. He {{is the son of}} the philosopher Thomas De Koninck, and nephew of Joseph De Koninck, Professor Emeritus at the Brain and Mind Research Institute of the University of Ottawa. He has two brothers: Paul De Koninck is Professor of Biochemistry, Microbiology <b>and</b> <b>Bio-Informatics</b> at Université Laval and a neuroscientist, and Marc De Koninck, a social worker and {{community}} organizer.|$|R
50|$|Christos Faloutsos (Χρήστος Φαλούτσος) is a Greek {{computer}} scientist {{and a professor}} at Carnegie Mellon University. He has received the Presidential Young Investigator Award by the National Science Foundation (1989), 22 best paper awards, and several teaching awards. He has served {{as a member of the}} executive committee of SIGKDD. He has published over 300 refereed articles, one monograph, and holds five patents. His research interests include data mining for streams and networks, fractals, indexing for multimedia <b>and</b> <b>bio-informatics</b> data bases, <b>and</b> performance.|$|R
40|$|Copyright It is not {{permitted}} to download or to forward/distribute the text or part of it {{without the consent of}} the author(s) and/or copyright holder(s), other than for strictly personal, individual use. UvA-DARE is a service provided by the library of the University of Amsterdam ([URL] Jakub T. Mościcki is a researcher and software engineer at CERN, Geneva, Switzerland. He obtained the MSc in Computer Science from the AGH University of Science and Technology in Kraków, Poland. He is a lead developer of the Ganga project and creator of the DIANE framework, which are used to support very large LHC user communities as well as users of multidisciplinary applications in theoretical physics, <b>medical</b> <b>and</b> radiation studies, <b>bio-informatics,</b> drug design, telecommunications. His research interests focus on scheduling and management of distributed and parallel applications, large-scale computing infrastructures such as grids, and various forms of High Throughput and High Performance Computing. Thousands of scientific users witness every day inherent instabilities and bottlenecks of large-scale task processing systems: lost or incomplete jobs and hard-to-predict completion times. They are struggling to resubmit failed jobs and get consistent results. And it is always difficult to catch up with latest deployed software environments or system configurations. In addition, the users have often more than one system to deal with: they continue to use locally available computing power (a desktop PC, a nearby computing center, a small cluster next door) while exploiting global resources such as grids. On top of this, grids use a large variety of middleware stacks, which are customized in different ways by user communities. Quality of Service and usability are the two keywords probably most frequently echoed in the corridors of many "grid-enabled " research labs...|$|R
40|$|Ontologies {{have become}} the {{knowledge}} representation medium of choice in recent years {{for a range of}} computer science specialities including the Semantic Web, Agents, <b>and</b> <b>Bio-informatics.</b> There has {{been a great deal of}} research and development in this area combined with hype and reaction. This special issue is concerned with the limitations of ontologies and how these can be addressed, together with a consideration of how we can circumvent or go beyond these constraints. The introduction places the discussion in context and presents the papers included in this issue...|$|R
40|$|There {{has long}} been {{interest}} and demand {{for the development of}} a vaccine to prevent infections caused by the Gram-positive organism group A streptococcus. Despite numerous efforts utilizing advanced approaches such as genomics, proteomics <b>and</b> <b>bio-informatics,</b> there is currently no vaccine. Here we review various strategies employed to achieve this goal. We also discuss the approach that we have pursued, a non-host reactive, conformationally constrained minimal B cell epitope from within the C-repeat region of M-protein, and the potential limitations in moving forward. Office of the Snr Dep Vice Chancellor, Institute for GlycomicsNo Full Tex...|$|R
50|$|The faculty offers three-year Bachelor of Science (BS), two-year Master of Science (MS) and {{a three-year}} Ph.D. degree programmes. There {{are two main}} areas of study programmes. One is the mathematical-physical-chemical subject group, which {{includes}} mathematics, computer science, actuarial science, mathematical economy, statistics, physics, astronomy, geophysics, meteorology, biophysics, chemistry, environmental chemistry, food science, biochemistry and nano-science. The other is the natural history-geography group, which includes biology, physical education, sports science, geology, geography, geo-informatics, geology-geophysics <b>and</b> <b>bio-informatics.</b> The University was co-founder of the Euroleague for Life Sciences (ELLS) which was established in 2001.|$|R
40|$|Systems {{providing}} assistance {{during a}} biopsy or an autopsy {{can be found}} in various <b>medical</b> centers <b>and</b> hospitals, today. Traditionally, CT(computed tomography) and MRI(magnetic resonance imaging) scans are used to produce detailed 3 D models and offer support during this procedures. Unfortunately, the high doses of radiation which are involved during a CT scan make the procedure less favorable for a continuous operation. At the Erasmus MC the departments of Pathology, Radiology <b>and</b> <b>Bio-informatics</b> are working on a prototype for guiding biopsies in a MIA procedure using a tracking camera. For this prototype, an existing piece of software for rendering and manipulating data from CT and MRI scans, V-Scope, developed at the Erasmus MC has been extended to provide the needed functionality for this. In this report, we describe the design, implementation and testing of this prototype as a project for our bachelor thesis. Furthermore, we provide recommendations for further enhancements of the prototype. Technische InformaticaComputer ScienceElectrical Engineering, Mathematics and Computer Scienc...|$|R
5000|$|Other than these, {{courses are}} also taught in <b>bio-informatics</b> <b>and</b> hardware.copa ...|$|R
50|$|Geneticists, Diagnosticians, Researchers <b>and</b> <b>Bio-informatics</b> {{scientists}} {{came together}} in June 2006 at the Human Variome Project Meeting, organized by Professor Cotton’s team, and agreed {{take on the task}} of organising data collection and unifying the systems of data access and storage. This initiative builds on substantial pilot work and achievements of the Human Genome Variation Society. The authority of those initiating this project is evidenced by the fact that major international bodies were present. These included WHO, OECD, European Commission, UNESCO, March of Dimes (US), Centers for Disease Control and Prevention (US), Google, representatives of two dozen international genetics bodies, numerous genetics journals, 20 countries and Australian State and Federal Governments.|$|R
40|$|Abstract. In silico protein-ligand docking is a {{basic problem}} in pharma-ceutics <b>and</b> <b>bio-informatics</b> research. One {{of the very few}} protein-ligand docking {{software}} with available source is the Autodock 3. 05 of the Scripps Research Institute. Autodock 3. 05 uses a Lamarckian genetic algorithm for global optimization with a Solis-Wets local search strategy. In this work we evaluate the convergence speed and the deviation properties of the solution produced by Autodock with diverse parameter settings. We conclude that the docking energies found by the genetic algorithm have uncomfortably large deviations. We also suggest a method for consider-ably decreasing the deviation while the number of evaluations will not be increased. ...|$|R
40|$|Fisher kernels {{provide a}} {{commonly}} used vectorial representation of structured objects. The paper presents {{a technique that}} exploits label information to improve the object representation of Fisher kernels by employing ideas from metric learning. In particular, the new technique trains a generative model {{in such a way}} that the distance between the log-likelihood gradients induced by two objects with the same label is as small as possible, and the distance between the gradients induced by two objects with different labels is as large as possible. We illustrate the strong performance of classifiers trained on the resulting object representations on problems in handwriting recognition, speech recognition, facial expression analysis, <b>and</b> <b>bio-informatics.</b> 1...|$|R
40|$|The {{main goal}} of the seminar Decision Procedures in Soft, Hard and Bio-ware was to bring {{together}} renowned as well as young aspiring researchers from two groups. The first group formed by researchers who develop both theory and efficient implementations of decision procedures. The second group comprising of researchers from application areas such as program analysis and testing, crypto-analysis, hardware verification, industrial planning <b>and</b> scheduling, <b>and</b> <b>bio-informatics,</b> who have worked with, and contributed to, high quality decision procedures. The purpose of the seminar was to heighten awareness between tool and theory developers for decision procedures with the array of applications found in software, hardware and biological systems analysis...|$|R
5000|$|Biotechnology: bio-medical engineering, bio-pharmaceuticals, genomics, {{breeding}} <b>and</b> pest management, <b>bio-informatics,</b> crop science <b>and</b> bio-pesticides and bio-products.|$|R
40|$|Hidden Markov {{models are}} {{well-known}} in analysis of random processes, which exhibit temporal or spatial structure {{and have been}} successfully applied {{to a wide variety}} of applications such as but not limited to speech recognition, musical scores, handwriting, <b>and</b> <b>bio-informatics.</b> We present a novel algorithm for estimating the parameters of a hidden Markov model through the application of a non-negative matrix factorization to the joint probability distribution of observations from two consecutive time steps. We start with the discrete observation model and extend the results to the continuous observation model through a non-parametric approach of kernel density estimation. For both the cases, we present results on a toy example and compare the performance with the Baum-Welch algorithm. 1...|$|R
40|$|Over {{the past}} few years, data mining {{has grown from a}} {{relatively}} unknown discipline into a widespread billion dollar business. Being first only adopted in the retail and banking sectors, we can nowadays observe a proliferation of the application domains, like for instance in e-commerce, terrorism prevention, RFID, software engineering, pharmaceutics, <b>and</b> <b>bio-informatics.</b> In this presentation, we cover some of these recent application domains and explain how data mining can contribute towards an increased efficiency in these fields. In the second part, we present some new data mining techniques that are expected to make a rapid transition into business environments. Techniques that will be discussed are, amongst others, support vector machines (SVMs), Bayesian network classifiers, bagging and boosting, and multirelational data mining...|$|R
40|$|Recent {{advances}} in biomedical technology have facilitated global analysis of cellular proteins and are termed as “proteomics”. Proteomics {{has become the}} key area of research in biomedicine and microbiology which uses meticulous and sophisticated techniques including two-dimensional acrylamid gel electrophoresis, mass spectrometry <b>and</b> <b>bio-informatic</b> databases. Proteomics is rapidly growing into post-genomic era in biomedical investigations. Its base lies on structural, physical, functional and other bio-characteristics of proteins and its application provides great opportunity to clarify the action of various pathogenetic agents. It will identify new diagnostic methods, new diagnostic markers of disease, new therapeutic agents, as well as protein candidates for vaccines. Application of this phenomenon expands from basic research, to clinical applications such as drug development, control of infectious diseases, cancer, neuropathology and cardiovascular diseases...|$|R
40|$|Sequencing and {{analysing}} of the Arabidopsis thaliana genome, {{the first}} plant kingdom genome to be unraveled, will always remain a scientific landmark. International initiatives to sequence rice, {{the most important}} cereal in Asia, are underway. However as functional information piles up in Arabidopsis and rice, researchers working in other crops will benefit from this new knowledge {{and apply it to}} their studied plants or crop species. The increasing role of public databases of model organisms <b>and</b> <b>bio-informatics</b> in data mining, presents a new opportunity as well as a challenge to researchers to develop more focused molecular tools for gene discovery and deployment. The work presented in here describes how such an approach has benefited sorghum, a rainfed semi-arid troprical cereal...|$|R
40|$|A Hidden Markov model (HMM) is a {{statistical}} Markov {{model in which}} the system being modeled {{is assumed to be}} a Markov process with unobserved (hidden) states. HMM is an extremely flexible tool and has been successfully applied {{to a wide variety of}} stochastic modeling tasks. One of the first applications of HMM is speech recognition. Later they came to be known for their applicability in handwriting recognition, part-of-speech tagging <b>and</b> <b>bio-informatics.</b> In this thesis, we will explain the mathematics involved in HMMs and how to efficiently perform HMM computations using dynamic programming (DP) which makes it easy to implement HMM. We will also address the practical issues associated with the use of HMM like numerical scaling of conditional probabilities to model long sequences and smoothing of poor probability estimates caused by sparse training data...|$|R
40|$|Clustering {{techniques}} have more importance in data mining {{especially when the}} data size is very large. It is widely used in the fields including pattern recognition system, machine learning algorithms, analysis of images, information retrieval <b>and</b> <b>bio-informatics.</b> Different clustering algorithms are available such as Expectation Maximization (EM), Cobweb, FarthestFirst, OPTICS, SimpleKMeans etc. SimpleKMeans clustering is a simple clustering algorithm. It partitions n data tuples into k groups such that each entity in the cluster has nearest mean. This paper is about {{the implementation of the}} clustering techniques using WEKA interface. This paper includes a detailed analysis of various clustering techniques with the different standard online data sets. Analysis is based on the multiple dimensions which include time to build the model, number of attributes, number of iterations, number of clusters and error rate...|$|R
40|$|Abstract—Many {{real world}} {{learning}} {{problems can be}} recast as multi-task learning problems which utilize correlations among different tasks to obtain better generalization per-formance than learning each task individually. The feature selection problem in multi-task setting has many applications in fields of computer vision, text classification <b>and</b> <b>bio-informatics.</b> Generally, it can be realized by solving a L- 1 -infinity regu-larized optimization problem. And the solution automatically yields the joint sparsity among different tasks. However, due to the nonsmooth nature of the L- 1 -infinity norm, there lacks an efficient training algorithm for solving such problem with general convex loss functions. In this paper, we propose an accelerated gradient method based on an “optimal ” first order black-box method named after Nesterov and provide the con-vergence rate for smooth convex loss functions. For nonsmoot...|$|R
40|$|Abstract—The {{increasing}} {{amount of}} data collected {{in the fields of}} physics <b>and</b> <b>bio-informatics</b> allows researchers to build realistic, and therefore accurate, models/simulations and gain a deeper understanding of complex systems. This analysis is often at the cost of greatly increased processing requirements. Cloud computing, which provides on demand resources, can offset increased analysis requirements. While beneficial to researchers, adaption of clouds has been slow due to network and performance uncertainties. We compare the performance of cloud computers to clusters to make clear the advantages and limitations of clouds. Focus has been put on understanding how virtualization and the underlying network effects performance of High Performance Computing (HPC) applications. Collected results indicate that performance comparable to high performance clusters is achievable on cloud computers {{depending on the type of}} application run...|$|R
30|$|The {{management}} of Ventilator Associated Pneumonia (VAP) presents many difficulties {{because of the}} heterogeneity of the disease; the way the immunocompromised host and the aggressive ICU environment interact is only partially discovered, the available biomarkers for diagnosis are not sufficient to ensure prompt differentiation between sick patients and patients at risk, the microbiological cultures require invasive techniques and time consuming methods. A translational medicine <b>and</b> <b>bio-informatics</b> approach can enable {{the identification of the}} main players of pathology, which may represent novel therapeutic targets or biomarker candidates. Analysis of proteome i.e. allows to individuate proteins that act as biomarkers, for patient-centered research strategies. Similarly, the genomic approach has proved useful to individuate those patients who are prone to develop VAP, and, in the future, we could be able to immunomodulate their responses to save them from nosocomial infections.|$|R
40|$|We {{describe}} an empirical investigation into layout criteria {{that can help}} with the comprehension of Euler diagrams. Euler diagrams are used to represent set inclusion in applications such as teaching set theory, database querying, software engineering, filing system organisation <b>and</b> <b>bio-informatics.</b> Research in automatically laying out Euler diagrams for use with these applications is at an early stage, and our work attempts to aid this research by informing layout designers {{about the importance of}} various Euler diagram aesthetic criteria. The three criteria under investigation were: contour jaggedness, zone area inequality and edge closeness. Subjects were asked to interpret diagrams with different combinations of levels for each of the criteria. Results for this investigation indicate that, within the parameters of the study, all three criteria are important for understanding Euler diagrams and we have a preliminary indication of the ordering of their importance...|$|R
40|$|Abstract. In {{the last}} decade, {{the notion of}} metric embeddings with small {{distortion}} has received wide attention in the literature, with applications in combinatorial optimization, discrete mathematics, <b>and</b> <b>bio-informatics.</b> The notion of embedding is, given two metric spaces on {{the same number of}} points, to find a bijection that minimizes maximum Lipschitz and bi-Lipschitz constants. One reason for the popularity of the notion is that algorithms designed for one metric space can be applied to a different one, given an embedding with small distortion. The better distortion, the better the effectiveness of the original algorithm applied to a new metric space. The goal recently studied by Kenyon et al. [2004] is to consider all possible embeddings between two finite metric spaces and to find the best possible one; that is, consider a single objective function over the space of all possible embeddings that minimizes the distortion. In this article we continu...|$|R
40|$|Background Doxorubicin {{has been}} shown to inhibit {{proliferation}} of cancer cells through proteolytic acti-vation of CREB 3 L 1 (cAMP response element binding protein 3 -like 1), a transcription factor synthesized as a membrane-bound precursor. Upon doxorubicin treatment, CREB 3 L 1 is cleaved so that the N-terminal domain of the protein can reach the nucleus where it acti-vates transcription of genes that inhibit cell proliferation. These results suggest that the level of CREB 3 L 1 in cancer cells may determine their sensitivity to doxorubicin. Methods Mice transplanted with 6 lines of renal cell carcinoma (RCC) were injected with doxorubicin to observe the effect of the chemotherapy on tumor growth. Immunohistochemistry <b>and</b> <b>bio-informatics</b> analyses were performed to compare CREB 3 L 1 levels in types of cancer known to respond to doxorubicin versus those resistant to doxorubicin. Results Higher levels of CREB 3 L 1 protein are correlated with increased doxorubicin sensitivity o...|$|R
