4|16|Public
40|$|An Autonomous Visual Plankton Recorder (AVPR) {{was used}} to record colour in situ images of {{plankton}} and other marine particulates at several oligotrophic stations around the world, including a northern hemisphere subtropical open ocean, a northern hemisphere subtropical marginal sea, a southern hemisphere tropical marginal sea, and a polar open ocean. Quantitative analyses and comparisons of particle concentrations, sizes and vertical profiles were possible after identification of optimal image enhancement settings and employment of a specially- developed <b>macro</b> <b>routine</b> in the off-the-shelf image analysis software Image Pro Plus. Such baseline data is invaluable for assessing the effects of surface or near-surface waste water or tailings disposal during deep-sea mining operations in oligotrophic areas. Marine particulate profiles, their relationships to oceanographic parameters and water mass structure, and the resolution-dependent limitations of the system are introduced and discussed...|$|E
40|$|Now-a-days, metal to plastic micro-welding is {{of great}} {{interest}} {{in the field of}} biomedical and electronics applications. Laser transmission welding (LTW) has emerged as the most suitable technique for such applications. In this paper, a three-dimensional finite element (FE) thermal model is developed to simulate the laser transmission welding process for joining polyvinylidene fluoride to titanium using a distributed moving heat flux. The objectives of this study are to predict the transient temperature field as well as the weld dimensions. All the major physical phenomena associated with the LTW process, such as, heat radiation, thermal conduction and convection heat losses are taken into account in the model development. The simulation algorithm is programmed as a <b>macro</b> <b>routine</b> within the ANSYS® finite element code. The developed model derives its main advantage from its applicability in parametric studies {{of a wide range of}} laser transmission metal to plastic welding problems of different geometrical, material and joint type, requiring only the basic thermo-physical material properties, the geometric details and the laser process parameters as input...|$|E
40|$|The {{present study}} {{evaluated}} {{the influence of}} the cement film thickness on the push-out bond strength of glass fiber posts in the cervical, medium, and apical thirds of root canal spaces. Thirty roots were randomly divided into three groups, according to the fiber post system’s drills: (G 1) # 2; (G 2) # 3; (G 3) # 4. The posts were cemented using a self-adhesive cement, and a small amount of powdered Rhodamine B was used as a stain. Images of both sides of each slice were obtained before and after the push-out test. To determine the cement thickness, a <b>macro</b> <b>routine</b> was developed using the software KS 400. The data were analyzed statistically using Kruskal-Wallis and Dunn’s test. G 2 (14. 62 ± 5. 15 [*]MPa) showed statistically higher bond strength values than G 1 (10. 04 ± 5. 13 [*]MPa) and G 3 (7. 68 ± 6. 14 [*]MPa). All groups presented higher bond strength values in the apical third. The bur diameter significantly influenced the results of the shear bond strength for the push-out test. The slight increase in the cement thickness allowed an increase in the values of shear bond strength when compared to very thin or very thick cement films...|$|E
50|$|The {{programming}} interface <b>macros</b> and <b>routines</b> are collectively called DAM: {{direct access}} methods.|$|R
40|$|A {{program that}} is a job may define {{parameters}} for and call other programs which are routines. SAS R○ routines and subroutines may be implemented as %includes or <b>macros.</b> <b>Routines</b> call other routines and subroutines. When testing or debugging multilevel %includes, {{it is difficult to}} determine which parameter in which routine or subroutine produced an error or warning message in the log. This paper discusses options used for testing, provides a new option, shows subroutine control using session constants, and illustrates two macros to show parameters and calling sequence of routines. Expected audience is intermediate to advanced programmer...|$|R
5000|$|Basic Assembler {{versions}} {{were available}} for CPS, TPS, and DPS including Input/Output Control System (IOCS) <b>macros</b> and processing <b>routines.</b>|$|R
40|$|Finite {{elements}} {{simulations of}} indentation loads {{caused by an}} ice sheet on a rigid conical offshore structure were carried out using the ANSYS structural commercial code (www. ansys. com). A square level ice sheet (20. 0 m x 20. 0 m) pushing a 10 m waterline diameter water cone was considered as the engineering application. The interactions between the structure and the ice sheet were modeled using a nonlinear 3 -D contact element formulation. The mechanical behaviour of ice (constitutive model for ice) is elastic, while its failure was modeled using a multi surface failure criterion. The latter includes {{the effects of the}} strain (loading) rate, temperature, salinity and porosity on the magnitude of ice strength. During the simulations, failed elements (i. e. elements that satisfy the stress conditions of failure criterion) were taken out from the initial geometry of the ice sheet. Therefore, the process and sequence for breaking ice pieced from the original ice sheet were modeled. This was achieved via developing and ANSYS <b>macro</b> (<b>routine)</b> for element death numerical technique. The validation of the numerical model is presented. The validation was achieved by comparing the computed ice loads from the numerical simulations with full-scale ice load measurements obtained form the Kemi-I test cone (M 44 tt 4 nen et al., 1996). In addition to the validation, the results of sensitivity and parametric analyses are presented and discussed. Conclusions and recommendations are provided. Peer reviewed: YesNRC publication: Ye...|$|E
40|$|The {{operation}} target, {{of digital}} school building plans recording, {{in the area}} of the Education Secretary of Buenos Aires City, is to survey, organize and create the connectivity into a single database, for a great number of graphic and non graphic documents. The information stocked in vellum, paper, and blueprints, on different scales and formats, has been collected, classified and checked. A skillful cad operator staff, in a prolific environment generated by codes, rules and helped by several particular tools which include <b>macros,</b> <b>routines</b> and libraries, is doing the production of drawings. All the documents and their parent information, from any kind of source, establish the core of an important database. The new information scope has the flexibility and accessibility required for a permanent data updating and extension...|$|R
40|$|We present {{documentation}} {{for running}} the GenBounds software, new SAS programs for generating the implicit edits from a given set of explicit ratio edits. We have developed two separate programs: one written in SAS/IML and one written in SAS/OR. The first {{program is designed}} for production processing {{and the second is}} designed for edit development. Both programs are submitted using the same <b>macro</b> driver <b>routine,</b> %Implied, and are available from ESMPD and SRD...|$|R
5000|$|The list of {{available}} Processing resources lists the available (built-in and user-supplied) <b>macros,</b> batch processing <b>routines</b> and scripts. PhotoShop-compatible plugins {{will appear in}} this list, ready for use, if their [...]8BF files {{have been placed in}} the PhotoPerfect directory.|$|R
40|$|Creating dynamic, {{data driven}} {{programs}} {{is a very}} powerful tool. Often we can use the metadata or the project data itself to help write our programs. This paper will introduce some of the concepts related to writing SAS ® programs which will generate pieces of SAS code in a data driven manner. Parts of the SAS language used in this discussion include the following: 1. <b>macro</b> call <b>routines</b> (call symput and call execute) 2. PROC SQ...|$|R
40|$|Joy et al. (2012) {{utilized}} a new element mapping {{routine that}} was developed to locate specific phases in complex crystalline or brecciated rocks. Several simple computer <b>routines</b> (<b>macros)</b> were developed to manage the data and project {{it in a way}} that is useful. Because these routines can be used to process data for other studies, we are making the...|$|R
40|$|In {{a series}} of joint papers, Teppo Felin and Nicolai J. Foss {{recently}} launched a microfoundations project {{in the field of}} strategic management. Felin and Foss observe that extant explanations in strategic management are predominantly collectivist or <b>macro.</b> <b>Routines</b> and organizational capabilities, which are supposed to be properties of firms, loom large in the field of strategic management. Routines figure as explanantia in explanations of firm behavior and firm performance, for example. Felin and Foss plead for a replacement of such macro-explanations by micro-explanations (viz. explanations in terms of individual action and interaction). Such a replacement is needed, Felin and Foss argue, because macro-explanations are necessarily incomplete: they miss out on crucial links in the causal chain that connect macro phenomena with each other. I argue that this argument is flawed. It is based on a doubtful if not outright incorrect understanding and use of Coleman’s diagram. In a sense to be explained below, only if Coleman’s diagram is squared it can accurately account for the relations between individual action and interaction, routines and firm behavior and firm performance. Once Coleman’s diagram is squared, one can see why and how macro-explanations need not miss out on any link in the causal chains that connect macro phenomena. Micro-analyses are still needed, not to highlight and specify causal links that macro-explanations miss out on, but to check whether the many properties that are ascribed to routines in macro-explanations of firm behavior are warranted...|$|R
40|$|We present {{documentation}} {{for running}} the GenBounds software which are new SAS ® programs for generating the implicit edits from a given set of explicit ratio edits. We have developed two separate programs: one written in SAS/IML ® and one written in SAS/OR®. The first {{program is designed}} for production processing {{and the second is}} designed for edit development. A SAS %Window ® interface has been developed which relieves the user of having to remember to set some 45 + macro variables and keyword parameters. This software package includes the following SAS programs: • RatioBndWin [...] - the %Window interface. • ResBnd_IW [...] - calculates explicit edits. • BndAnalysiswx [...] - plots explicit and implicit edits. • GenBndsIML [...] - calculates implicit edits using SAS/IML. • GenBndsOR [...] - calculates implicit edits using SAS/OR. • IndAvgWX [...] - recalculates industry averages. The main focus of this paper and presentation is the calculation of the implied edits. Both programs are submitted using the same <b>macro</b> driver <b>routine,</b> %Implied...|$|R
40|$|The Flexible Spacecraft Dynamics and Control program (FSD) was {{developed}} {{to aid in the}} simulation of a large class of flexible and rigid spacecraft. FSD is extremely versatile and can be used in attitude dynamics and control analysis as well as in-orbit support of deployment and control of spacecraft. FSD has been used to analyze the in-orbit attitude performance and antenna deployment of the RAE and IMP class satellites, and the HAWKEYE, SCATHA, EXOS-B, and Dynamics Explorer flight programs. FSD is applicable to inertially-oriented spinning, earth oriented, or gravity gradient stabilized spacecraft. The spacecraft flexibility is treated in a continuous manner (instead of finite element) by employing a series of shape functions for the flexible elements. Torsion, bending, and three flexible modes can be simulated for every flexible element. FSD can handle up to ten tubular elements in an arbitrary orientation. FSD is appropriate for studies involving the active control of pointed instruments, with options for digital PID (proportional, integral, derivative) error feedback controllers and control actuators such as thrusters and momentum wheels. The input to FSD is in four parts: 1) Orbit Construction FSD calculates a Keplerian orbit with environmental effects such as drag, magnetic torque, solar pressure, thermal effects, and thruster adjustments; or the user can supply a GTDS format orbit tape for a particular satellite/time-span; 2) Control words - for options such as gravity gradient effects, control torques, and integration ranges; 3) Mathematical descriptions of spacecraft, appendages, and control systems- including element geometry, properties, attitudes, libration damping, tip mass inertia, thermal expansion, magnetic tracking, and gimbal simulation options; and 4) Desired state variables to output, i. e., geometries, bending moments, fast Fourier transform plots, gimbal rotation, filter vectors, etc. All FSD input is of free format, namelist construction. FSD is written in FORTRAN 77, PASCAL, and MACRO assembler for batch execution and has been implemented on a DEC VAX series computer operating under VMS. The PASCAL and <b>MACRO</b> <b>routines</b> (in addition to the FORTRAN program) are supplied as both source and object code, so the PASCAL compiler is not required for implementation. This program was last updated in 1985...|$|R
40|$|Research in {{healthcare}} often involves identified data. These datasets contain protected health information (PHI) {{that has to}} be removed to meet use and disclosure requirements for research under HIPAA. There are varying databases in which patient information is stored. These can be multiple datasets on the same patients or different patients that need to be combined for analysis. When combining multiple datasets for further analysis, it becomes a challenge in aligning these datasets, and at the same time, protecting PHI. This paper highlights the importance of examining the format of each dataset, and discusses steps to prepare the datasets before removing the PHI. Subsequently, we introduce, in progressively complex methods, combinations of SAS ® functions, such as DO-LOOPs, SEED, RANUNI, NODUPKEY, EOF (end of file) functions, to replace the PPI with research appropriate identifiers, specifically variables embedded in medical records and administrative datasets. At the end of this paper, a <b>MACRO</b> LOOP <b>routine</b> with ARRAY, CALL VNAME, CALL SYMPUT, PROC APPEND that encompasses all these functions is presented to combine all six datasets for further analysis...|$|R
40|$|Abstract—This paper {{presents}} an on-going research {{work on the}} implementation of feature-based machining via macro programming. Repetitive machining features such as holes, slots, pockets etc can readily be encapsulated in macros. Each macro consists of methods on how to machine the shape {{as defined by the}} feature. The macro programming technique comprises of a main program and subprograms. The main program allows user to select several subprograms that contain features and define their important parameters. With <b>macros,</b> complex machining <b>routines</b> can be implemented easily and no post processor is required. A case study on machining of a part that comprised of planar face, hole and pocket features using the macro programming technique was carried out. It is envisaged that the macro programming technique can be extended to other feature-based machining fields such as the newly developed STEP-NC domain. Keywords—Feature-based machining, CNC, Macro, STEP-NC. I...|$|R
40|$|Allogeneic {{bone marrow}} {{transplantation}} (BMT) is an established therapy for patients {{with a variety of}} haematological malignancies. Patients undergoing BMT often suffer from severe infections that can be partly explained by humoral immune deficiency. We have evaluated the molecular and serological basis for impaired humoral immunity among patients treated with BMT. Reconstitution of B-cell repertoires was followed from before to three years after transplantation by analysis of immunoglobulin (Ig) genes at DNA and RNA levels as well as by measurement of circulating antibodies in patients' sera. Four patients were analysed for Ig heavy chain variable (VH) gene usage. The diagnosis leading to transplantation was acute lymphoblastic leukaemia of pre-B type, lymphoma (K 1 +) and chronic myeloid leukaemia (two patients). Peripheral blood mononuclear cells were isolated from donated marrow and patients' venous blood. Nucleic acids were isolated and amplified with primers specific for various VH genes using PCR. Thereafter we analysed amplified fragments by nucleotide sequencing or hybridisation with oligonucleotide probes specific for individual B-cell clones. We detected a restricted usage of VH 6 and VH 3 Ig gene rearrangements among BMT patients compared to healthy controls. Complementarity determining regions (CDRs) 3 were characteristic of an adult type of rearrangement considering N-nucleotide additions and length. Furthermore, individual B-cell clones appeared to dominate the repertoire at different time points after transplantation. To evaluate the effect of the restricted VH gene usage on functional Ig repertoires, analysis of patient sera was performed. Sera from 44 patients, the majority receiving treatment for various haematological malignancies, were analysed with a quantitative immunoblot technique. This method is based on the Western-blot technique and allowed a global analysis of Ig specificities towards protein extracts prepared from human liver, muscle and skin tissue and from cultured Staphylococcus epidermidis. Quantification of reactive antibodies in each serum was conducted with densitometry. To analyse the immunoreactivity profiles and perform multivariate statistical treatment of the data dedicated computer software and <b>macro</b> <b>routines</b> were used. The results demonstrate that 60 % of treated patients have severely reduced diversity in their IgM repertoire compared to healthy controls during and after the first year post-BMT. The IgG repertoire, however, is not affected and patients demonstrate a similar diversity of IgG antibodies as healthy controls. It is possible that the reduced diversity in the IgM repertoire, as well as the oligoclonal nature of VH 6 and VH 3 rearrangements among patients treated with BMT, contribute to the impaired humoral immunity characteristic of this patient group. The reduced diversity of the Ig repertoire might result in a decrease of the individual's capability to recognise and respond to certain bacterial or viral antigens. However, we demonstrate a more diverse IgM and IgG repertoire among BMT patients receiving marrow from a matched unrelated donor (MUD) than from a sibling donor. Patients receiving marrow from MUD suffer more infections than do patients receiving sibling marrow. From this it follows that a polyclonal repertoire might be secondary to immune activation by pathogens or minor antigen mismatches, and it might be that an oligoclonal repertoire, rather than contributing to sensitivity to infections, is a sign of lack of infections...|$|R
40|$|PROC FCMP {{allows a}} SAS ® {{programmer}} {{the opportunity to}} create user-defined functions in SAS. Prior to the availability of FCMP in SAS 9, SAS <b>macros</b> or linked <b>routines</b> were often used to achieve a similar – but less elegant – effect. This paper examines the advantages of FCMP over the earlier alternatives and why it is therefore so valuable to the programmer. BACKGROUND What is FCMP? FCMP is an acronym for Function Compiler. What does FCMP do? “The SAS Function Compiler (FCMP) procedure enables you to create, test, and store SAS functions, CALL routines, and subroutines before you use them in other SAS procedures or DATA steps. ” (Source: SAS Institute Inc. 2012. Base SAS ® 9. 3 Procedures Guide.) PROC FCMP is the procedure used to invoke the SAS Function Compiler. It puts the power to create user-defined functions, which behave the same way native SAS functions do, {{into the hands of}} the programmer. PROC FCMP was introduced for limited procedures with SAS 9 and became available to the DATA step with 9. 2. What is a function? In the mathematical sense, a function is a transformation from a set of one or more values to a singular result, by means of some calculation. While we think of the inputs to a function a...|$|R
40|$|The {{objective}} {{of this study was}} to create and evaluate a <b>routine</b> (<b>macro)</b> using Image-Pro Plus 4. 5 software (Media Cybernetics, Silver Spring, USA) for automatic counting of labeled nuclei by proliferating cell nuclear antigen (PCNA) immunohistochemistry. A total of 154 digital color images were obtained from eleven sections of reticular oral lichen planus stained by PCNA immunohistochemistry. Mean density (gray-level), red density, green density, blue density, area, minor axis, perimeter rate and roundness were parameters used for PCNA labeled nuclei discrimination, followed by their outlined presentation and counting in each image by the macro. Mean density and area thresholds were automatically defined based, respectively, on mean density and mean area of PCNA labeled nuclei in the assessed image. The reference method consisted in visual counting of manually outlined labeled nuclei. Statistical analysis of macro results versus reference countings showed a very significant correlation (r s = 0. 964, p < 0. 001) for general results and a high level (89. 8 ± 3. 8 %) of correctly counted labeled nuclei. We conclude that the main parameters associated with a high correlation between macro and reference results were mean density (gray-level) and area thresholds based on image profiles; and that Image-Pro Plus 4. 5 using a routine with automatic definition of mean density and area thresholds can be considered a valid alternative to visual counting of PCNA labeled nuclei...|$|R

