24|63|Public
5000|$|... and [...] are {{resolved}} at compile time, {{and thus are}} much faster than [...] and [...] variables which are dynamic entities accessed {{by means of a}} runtime Symbol table. For this same reason, [...] and [...] variables are [...] exposed to the Macro compiler, and any <b>macro</b> <b>code</b> which attempts to reference them will generate a runtime error.|$|E
5000|$|In {{order to}} make cross-compilation {{possible}} for Scheme code, CHICKEN imposes a model of separate compilation: A compiled module consists of two shared libraries. One library contains the actual code which will be used at runtime (compiled for the target platform), {{and the other is}} an [...] "import module", which will be used to load the code which runs at compile-time (on the host platform), such as procedural <b>macro</b> <b>code.</b>|$|E
50|$|PowerPoint 2000 {{and later}} {{versions}} introduced macro security {{to help protect}} computers from malicious code within a PowerPoint presentation. This led to disabling all VBA or <b>macro</b> <b>code</b> by default, causing presentations containing codes unable to run properly, unless the viewer adjusted their macro security settings to the Low setting. Security Warning in PowerPoint 2007 alerts the user of macros in a presentation {{as soon as it}} is opened, giving the option to run the presentation with or without the macros enabled.|$|E
50|$|Common Lisp is {{extensible}} through standard {{features such}} as Lisp <b>macros</b> (<b>code</b> transformations) and reader macros (input parsers for characters).|$|R
40|$|Data {{security}} {{is an important}} issue in data exchange, especially in cyber world. Because so many threads that threaten the data itself. When Office document exchange in STIKOM, its encrypt is made when it's sent use RSA (Rivest-Shamin-Adleman) algorithm. User can download encrypted document from web application then to decrypt the document using desktop application. After that injecting the <b>macros</b> <b>code</b> are using Visual Basic Application (VBA). So, the office document which has injected with <b>macros</b> <b>code</b> only can be open when it's connected to an XML Web Service...|$|R
5000|$|A {{preprocessor}} performs <b>macro</b> definition, source <b>code</b> file inclusion, and conditional compilation.|$|R
50|$|These flaws are {{completely}} different from the previous ones : the main problem in VBA-type macros is the viruses. Macro viruses are relatively recent, the first one named Concept, has been created in June 1995.The main reason {{of that is that}} the high-level languages used to write <b>macro</b> <b>code</b> are powerful and easy to use, considerably increasing the pool of potential virus writers, and the documents containing the macros can be disseminated rapidly and widely by E-mail.So they can be spread quickly and be very destructive.|$|E
50|$|LOCAL, STATIC, and GLOBAL are {{resolved}} at compile time, {{and thus are}} much faster than PRIVATE and PUBLIC variables which are dynamic entities accessed {{by means of a}} runtime Symbol table. For this same reason, LOCAL, STATIC and GLOBAL variables are not exposed to the Macro compiler, and any <b>macro</b> <b>code</b> which attempts to reference them will generate a runtime error. Due to the dynamic nature of PRIVATE and PUBLIC variables, they can be created and destroyed at runtime, can be accessed and modified by means of runtime macros, and can be accessed and modified by Codeblocks created on the fly.|$|E
40|$|Oftentimes in {{epidemiological}} research, we {{deal with}} case-control studies in which the exposures have more than two levels (i. e., {{we are looking at}} an exposure by outcome table that is rx 2). However, the CMH option in PROC FREQ will compute the estimates of risk for only 2 x 2 tables, and not for the more general rx 2 tables. Datasets are created for each comparison against the referent exposure group, and PROC FREQs are run on these individual datasets. The PROC FREQ then is re-run for the entire rx 2 table to obtain the estimate of the overall linear association. This can become quite a tedious undertaking very quickly. In this paper, we present <b>macro</b> <b>code</b> that automates the creation of the separate datasets and the subsequent PROC FREQs, and summarizes the cell counts and statistics of interest in an easily interpretable table for the client. It is aimed at a moderate skill level; it uses <b>macro</b> <b>code,</b> PROC FREQ, and PROC TABULATE; and, though currently it is written to execute in PC SAS TM, the code is not specific to an operating system...|$|E
50|$|Support include <b>macro,</b> custom shader <b>code</b> block, dynamic {{definition}} in shader compiling.|$|R
40|$|The SAS ® Macro Language is a {{powerful}} tool for extending the capabilities of the SAS System. This hands-on workshop presents numerous tips and tricks related to the construction of effective macros through the demonstration of a collection of proven <b>Macro</b> Language <b>coding</b> techniques. Attendees learn how to process statements containing macros; replace text strings with macro variables; generate SAS code using macros; manipulate macro variable values with macro functions; handle global and local variables; construct arithmetic and logical expressions; interface the macro language with the DATA step and SQL procedure; store and reuse macros; troubleshoot and debug macros; and develop efficient and portable <b>macro</b> language <b>code...</b>|$|R
5000|$|Lisp, {{a family}} of {{languages}} written in trees, with <b>macros</b> to manipulate <b>code</b> trees ...|$|R
30|$|Two tools {{can be used}} {{in order}} to program the Bi-i Vision System, i.e., the {{analogic}} <b>macro</b> <b>code</b> (AMC) and the software development kit (SDK). In particular, by using the AMC language, the Bi-i Vision System can be programmed for simple analogic routines [9], whereas the SDK is used to design more complex algorithms (see Appendix). Referring to the image processing library (IPL), note that the so-called TACE_IPL is a library developed within the SDK. It contains useful functions for morphological and grey-scale processing in the ACE 16 k chip (see Appendix). Additionally, the Bi-i V 2 includes an InstantVision™ library [9].|$|E
40|$|This paper studies some'of the {{problems}} involved in attaining machine independence for a code generator, {{similar to the}} language independence and the token independence attained by automatic parsing and automatic lexical systems. In particular, the paper examines the logic involved in two areas of code generation: computation and data reference. It presents models embodying the logic of each area and demonstrates how the models can be filled out by descriptive information about a particular machine. The paper also describes how the models {{can be incorporated into}} a descriptive <b>macro</b> <b>code</b> generating s_vstem (DMACS) to be u [...] sed as a tool by a language implementer in creating a machine independent code generator, which can be made machine-directed by a suitable description of a particu- lar machine...|$|E
40|$|Most of us {{are engaged}} in {{providing}} data to information consumers {{at least some of}} the time, and by far the most often requested format is the Microsoft Excel workbook. As the capabilities of Excel have expanded, so have the requests for more and more sophisticated output, and the search for ways to generate this output with the least amount of human effort as possible. One of the SAS ® tools that I have recently started using to great effect is the ODS ExcelXP tagset. By harnessing some of the vast capabilities available within this tagset, in concert with the judicious application of <b>macro</b> <b>code</b> and Dynamic Data Exchange (DDE), I am now able to deliver nicely formatted, multisheet native Excel workbooks for any number of subsets of my data as might be desired...|$|E
50|$|Midnight Commander's {{features}} include {{the ability to}} view the contents of RPM package files, to work with common archive formats {{as if they were}} simply another directory, and to function as an FTP or FISH client. Midnight Commander also includes an editor called mcedit, which can be executed as a standalone program or from Midnight Commander using the F4 key. mcedit's {{features include}} syntax highlighting for many languages, <b>macros,</b> <b>code</b> snippets, simple integration with external tools, automatic indentation, mouse support, a clipboard and the ability to work in both ASCII and hex modes. Users also have the option to replace mcedit with the editor of their choice (Options Menu>Configuration>Don't Use Internal Edit).|$|R
50|$|GWD Text Editor is a {{text editor}} and IDE for Microsoft Windows. It {{does not have}} an update since 2003.Features include {{configurable}} syntax highlighting, ANSI C compatible macro language, projects (IDE for Borland C++ and Java), plug-ins, clip library, FTP client, keystroke <b>macros,</b> <b>code</b> completion and API assistance for C/C++, Java and JavaScript, ScriptWizard, PlugInWizard, autosave and crash recovery, column/block editing mode, bookmarks, numbered lines, autocorrect, spell checker for 12 languages, customizable toolbar, print preview, line drawing, sorting, text formatting, drag and drop support, a remappable keyboard (with QEDIT, MS Word and WordStard keyboard emulations), support for DOS/Windows, UNIX, and Macintosh text file formats, the ability to edit unlimited file sizes, ability to capture compiler outputs and more.|$|R
50|$|Lisp {{uses this}} to {{implement}} a very powerful macro system. Like other macro languages such as C, a <b>macro</b> returns <b>code</b> that can then be compiled. However, unlike C macros, the macros are Lisp functions and so can exploit the full power of Lisp.|$|R
40|$|Abstract. We {{present the}} design of a meta-programming system {{embedded}} into Nemerle 1, a new functional language for the. NET platform. The system enables compile-time operations – generation, transformation and automated analysis of programs by means of hygienic code quotation, syntax extensions, operating on the code like on any other datatype (e. g. listing, adding or changing members of class definition), performing partial typing of a program syntax tree (compiler internal typing procedures are executed by a <b>macro</b> <b>code)</b> and interoperability with the compilation process. All these operations can be fully parametrized with any external data (like a database, a file or a web page). Our system is a convenient tool for Aspects Oriented Programming with the ability to operate on datatypes, traverse the program code and perform various algorithmic operations on its content. ...|$|E
40|$|Survival {{analysis}} {{is a popular}} method in medical research. Preliminary analysis and visualization of survival curves are important to make adequate assumptions about the statistical model. This paper shows various approaches that produce Kaplan–Meier curves from PROC LIFETEST or from the baseline statement in PROC PHREG. We developed <b>macro</b> <b>code</b> to plot survival curves with confidence intervals for selected points by strata. The number of subgroups in strata and corresponding SAS graph options are calculated and assigned by design. The paper also presents macro for adjusted survival curves. Powerful tool that performs multivariate {{analysis is}} a PROC PHREG. We analyzed data with time dependent variables and repeated measurements. Two types of data structures were considered: “horizontal ” with a unique observation per ID and multiple time-points, and “vertical ” with multiple observations per ID. The paper demonstrates macros with nested Cox proportional hazard models for both types of these data structure...|$|E
40|$|The Decision Support Systems {{web site}} {{promises}} to deliver information on demand. How {{do you do}} that? More specifically, how do you meet the requests of many users who span {{all levels of the}} organization and need different levels of data? How do you optimize the user experience that is dialing over a 28. 8 modem? “Ask DSS”, partially modeled after “Ask Jeeves ” is one such application. All users choose from a prearranged set of questions. Each question has several pull-down boxes to let users tailor it for their particular inquiry. We term this a &quot;predefined where clause with variable values. &quot; It’s easily maintained because each question has its own SAS program called from the SAS/IntrNet ® broker. <b>Macro</b> <b>code</b> manages the dynamic decision making of which user and what data, and JavaScript within the web page manages the questions submitted and the necessary parameters to pass...|$|E
50|$|<b>Macro</b> Recorded <b>code</b> {{may not be}} {{compatible}} between Excel versions. Some code that is used in Excel 2010 {{can not be used}} in Excel 2003. Making a Macro that changes the cell colors and making changes to other aspects of cells may not be backward compatible.|$|R
50|$|Intelledox Infiniti was {{developed}} to address the market requirement for software specifically designed {{to assist with the}} construction of repetitive documents (document automation/ECM). Intelledox allows non-technical users to implement common Microsoft Word skills, to create reusable document components in a central repository, without the requirement of <b>macros</b> or <b>coding.</b>|$|R
5000|$|The [...] {{statement}} {{is used to}} reference data. This statement links a program's internal description of a dataset to the data on external devices: disks, tapes, cards, printers, etc. The DD may provide information such as a device type (e.g. '181','2400-5','TAPE'), a volume serial number for tapes or disks, and {{the description of the}} data file, called the [...] subparameter after the Data Control Block (DCB) in the program used to identify the file. Information describing the file can come from three sources: The DD card information, the dataset label information for an existing file stored on tape or disk, and the DCB <b>macro</b> <b>coded</b> in the program. When the file is opened this data is merged, with the DD information taking precedence over the label information, and the DCB information taking precedence over both. The updated description is then written back to the dataset label. This can lead to unintended consequences if incorrect DCB information is provided.|$|R
40|$|Macro {{programming}} {{is one of}} the most powerful and flexible techniques in the SAS system. Macro programs can be used to automate repetitive tasks and for conditional execution of program statements. For some, however, the syntax of <b>macro</b> <b>code</b> may sometimes be confusing and hard to follow. But most macro tasks can be accomplished with the use of a CALL EXECUTE routine within a DATA step. The argument to the Call execute routine is a text string or variable containing a text string. The Call execute resolves this argument and executes it after the end of the calling DATA step. The text string argument can be coded to execute another DATA step or to run a PROC or both. In fact, you can use the CALL EXECUTE routine within a DATA step to write a complete SAS program that can perform a variety of tasks, under the control of the calling DATA step...|$|E
40|$|In {{order to}} support the {{statistical}} analysis of clinical data, we utilized the DDE facility in SAS software to retrieve clinical study data from a Microsoft Access database. Although the DDE facility is documented, it took {{quite a bit of}} experimentation to successfully execute. Our programming environment included Windows for Workgroups 3. 11, SAS 6. 10, and Microsoft Access 2. 0. Our Microsoft Access database was available to many users on a local area network and DDE allowed us to access the most current data. In this paper, we use our programs to provide examples to review the DDE syntax using the filename statement and explain how the DDE triplet maps to our Microsoft Access database. Our example reads in entire Access tables, but we describe how to set limits. Our examples use SAS <b>macro</b> <b>code</b> so accessing current data from the database could be easily repeated in any calling program. Our paper highlights the fine points and pitfalls of this useful technique...|$|E
40|$|Background Misclassification bias {{is present}} in most studies, yet {{uncertainty}} about its magnitude or direction is rarely quantified. Methods The authors present a method for probabilistic sensitivity analysis to quantify likely effects of misclassification of a dichotomous outcome, exposure or covariate. This method involves reconstructing the data {{that would have been}} observed had the misclassified variable been correctly classified, given the sensitivity and specificity of classification. The accompanying SAS macro implements the method and allows users to specify ranges of sensitivity and specificity of misclassification parameters to yield simulation intervals that incorporate both systematic and random error. Results The authors illustrate the method and the accompanying SAS <b>macro</b> <b>code</b> by applying it to a study of the relation between occupational resin exposure and lung-cancer deaths. The authors compare the results using this method with the conventional result, which accounts for random error only, and with the original sensitivity analysis results. Conclusion By accounting for plausible degrees of misclassification, investigators can present study results in a way that incorporates uncertainty about the bias due to misclassification, and so avoid misleadingly precise-looking results...|$|E
50|$|While {{a typical}} {{installation}} of LaTeX, together with TeX binaries takes from 50 to 300 MB, Lout is about 1 MB. This is mainly due to fewer packages and tools, but {{might also be}} attributed to a C implementation instead of <b>macro</b> language source <b>code.</b>|$|R
50|$|StructuralEquality, Memoize, json, {{and with}} are <b>macros</b> which {{generate}} <b>code</b> in compile time. Though {{some of them}} (StructuralEquality, Memoize) can look like C# attributes, during compiling, they will be examined by the compiler and transformed to appropriate code using logic predefined by their macros.|$|R
40|$|This {{information}} {{is provided by}} SAS as a service to its users. The text, <b>macros,</b> and <b>code</b> are provided “as is. ” There are no warranties, expressed or implied, as to merchantability or fitness for a particular purpose regarding {{the accuracy of the}} materials or code contained herein. SAS r ○, SAS/AF r ○, SAS/ETS r ○, SAS/GRAPH r ○, SAS/IML r ○, SAS/QC r ○, and SAS/STAT r ○ are trademarks or registered trademarks of SAS in the USA and other countries. r ○ indicates USA registration. Marketing Researc...|$|R
40|$|Macro {{programming}} {{is generally considered}} an advanced topic. But, while macros certainly can be challenging, {{it is also true}} that the basic concepts are not difficult to learn. This paper is designed for people who know the basics of SAS programming, but know nothing about SAS macro programming. We explain how the macro processor works, and how to use macros and macro variables. Using these techniques you can create flexible, reusable code that can save you time and effort. WHY USE MACROS? Because <b>macro</b> <b>code</b> takes longer to write and debug than standard SAS code, you generally won’t use macros in programs that will be run only a few times. But if you find yourself writing similar code over and over again, then macros may make your job easier. Macros can help in several ways. First, with macros you can make one small change in your program and have SAS echo that change throughout your program. Second, macros can allow you to write a piece of code and use it over and over again in the same program or in different programs. Third, you can make your programs data driven, letting SAS decide what to do based on actual data values. THE MACRO PROCESSO...|$|E
40|$|The {{macrofunction}} in Computer Aided Manufacturing (CAM) {{systems is}} executed {{based on the}} macrocode which is transformed {{by a series of}} operations input by the user. By the use of this function, operations which should be performed by the user can be simplified. Therefore, if the transformation from mechanical drawings to NC code can be changed directly into macrocode, NC machining can be achieved easily. In our study, a function for transforming macrocode from data of a CAD drawing to CAM data is developed. However, drawing data of a CAD system (CAD drawing) does not always coincide with drawing data of a CAM system (CAM drawing), because in a CAM system, restricted conditions, such as machining conditions, must be considered. Consequently, drawing data must be represented by a structure and function which include information about restricted conditions. Thus, the concept of the relationship between "master and servant" for expressing structure and function in an object model definitely is specifically incorporated. As a result, even in the case where structure and function are changed, the knowledge base can be consistently maintained. This paper describes representation of knowledge in the knowledge base and a method for generating a <b>macro</b> <b>code</b> using this knowledge base...|$|E
40|$|Selected {{methods of}} {{mortality}} analysis focused on adults {{and the oldest}} age-groups Abstract Questions about human life span, longevity and mortality in general are natural to almost everyone. This Doctoral Thesis deals with one central question - whether some limit of human life span or of its improvements exists. It is rather a methodological work, therefore its aim is to introduce not only relevant theories but above all the methods usable in the mortality analysis focused on adults or the oldest-old. At the beginning the most important theories and opinions of scientist dealing with mortality are introduced. In {{the first half of}} the analytical part mainly the traditional and basic approaches are included. The theme of life tables is opened by an analysis of its construction in the Czech Republic, together with its possible modifications. As a result the independent <b>macro</b> <b>code</b> for the SAS software is attached in the electronic Appendix. This macro enables to calculate the unknown parameters of selected mortality laws by the method of weighted non-linear least squares and to produce the smoothed and extrapolated values of mortality rates. Using the individual life durations, life tables according to education attainment were constructed (also attached in the electronic Appendix). In the second half of the [...] ...|$|E
50|$|The {{language}} was based around {{the idea of}} programming with macros. A user will define a <b>macro</b> (a <b>code</b> word that can be defined by the user to invoke {{a specific set of}} instructions to perform a routine within the program) to execute a set of instructions, usually in either machine or assembly language, and use the macro in the program. In this way, a user need only define a routine once and then when that particular operation, or string is required, the user can substitute is with the macro name.|$|R
5000|$|In {{contrast}} to user interface libraries like GTK+, Qt, and wxWidgets, FLTK uses a more lightweight design and restricts itself to GUI functionality. Because of this, {{the library is}} very small (the FLTK [...] "Hello World" [...] program is around 100 KiB), and is usually statically linked. It also avoids complex <b>macros,</b> separate <b>code</b> preprocessors, and use of some advanced C++ features: templates, exceptions, and run-time type information (RTTI) or, for FLTK 1.x, namespaces. Combined with the modest size of the package, this makes it relatively easy to learn for new users.|$|R
5000|$|The macro Language {{automated}} {{a lot of}} {{this process}} and the ProTERM user could <b>code</b> <b>macros</b> to log in and perform unix functions in Bash_(Unix_shell) or Bourne_shell making this a very powerful terminal emulator, capable of manipulating mainframes and [...] "hacking" [...] {{into the heart of the}} internet at low and high levels.|$|R
