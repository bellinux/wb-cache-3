33|4|Public
50|$|Bio-Hyperpliance is a {{scalable}} <b>multi-modal</b> <b>biometrics</b> recognition {{system that}} leverages distributed node balancing for 1:N identification of large databases.|$|E
50|$|Hybrid Biometrics is a <b>multi-modal</b> <b>biometrics</b> {{system that}} {{supports}} fingerprint, finger vein, palm vein, and iris recognition {{from a single}} server.|$|E
40|$|The {{topic of}} <b>multi-modal</b> <b>biometrics</b> has {{attracted}} {{strong interest in}} recent years. This paper categorizes approaches to <b>multi-modal</b> <b>biometrics</b> based on the biometric source, the type of sensing used, {{and the depth of}} collaborative interaction in the processing. This paper also attempts to identify some of the challenges and issues that confront research in multimodal biometrics. 1...|$|E
40|$|Abstract. 2 D {{intensity}} {{images and}} 3 D shape models are both useful for face recognition, but in different ways. While algorithms {{have long been}} developed using 2 D or 3 D data, recently has seen work on combining both into <b>multi-modal</b> face <b>biometrics</b> to achieve higher performance. However, the fusion of the two modalities has mostly been at the decision level, based on scores obtained from independent 2 D and 3 D matchers. In this paper, we propose a systematic framework for fusing 2 D and 3 D face recognition at both feature and decision levels, by exploring synergies of the two modalities at these levels. The novelties are the following. First, we propose to use Local Binary Pattern (LBP) features to represent 3 D faces and present a sta-tistical learning procedure for feature selection and classifier learning. This leads to a matching engine for 3 D face recognition. Second, we propose a statistical learning approach for fusing 2 D and 3 D based face recognition at both feature and decision levels. Experiments show that the fusion at both levels yields signif-icantly better performance than fusion at the decision level. ...|$|R
40|$|The {{contribution}} {{of this paper}} is to compare paradigms coming from the classes of parametric, and non-parametric techniques to solve the decision fusion problem encountered in the design of a multi-modal biometrical identity verification system. The multi-modal identity verification system under consideration is built of d modalities in parallel, each one delivering as output a scalar number, called score, stating how well the claimed identity is verified. A decision fusion module receiving as input the d scores has to take a binary decision: accept or reject the claimed identity. We have solved this fusion problem using parametric and non-parametric classifiers. The performances of all these fusion modules have been evaluated and compared with other approaches on a multi-modal database, containing both vocal and visual biometric modalities. Keywords: <b>Multi-modal</b> identity verification, <b>biometrics,</b> decision fusion. 1 Introduction The automatic verification 1 of a person is more and [...] ...|$|R
40|$|Zero-interaction {{authentication}} (ZIA) {{refers to}} a form of user-transparent login mechanism using which a terminal (e. g., a desktop computer) can be unlocked by the mere proximity of an authentication token (e. g., a smartphone). Given its appealing usability, ZIA has already been deployed in many real-world applications. However, ZIA contains one major security weakness - unauthorized physical access to the token, e. g., during lunch-time or upon theft, allows the attacker to have unfettered access to the terminal. In this paper, we address this gaping vulnerability with ZIA systems by (un) locking the authentication token with the user's walking pattern as she approaches the terminal to access it. Since a user's walking or gait pattern is believed to be unique, only that user (no imposter) would be able to unlock the token {{to gain access to the}} terminal in a ZIA session. While walking-based biometrics schemes have been studied in prior literature for other application settings, our main novelty lies in the careful use of: (1) multiple sensors available on the current breed of devices (e. g., accelerometer, gyroscope and magnetometer), and (2) multiple devices carried by the user (in particular, an "in-pocket" smartphone and a "wrist-worn" smartwatch), that all capture unique facets of user's walking pattern. Our contributions are three-fold. First, we introduce, design and implement WUZIA ("Walk-Unlock ZIA"), a <b>multi-modal</b> walking <b>biometrics</b> approach tailored to enhance the security of ZIA systems (still with zero interaction). Second, we demonstrate that WUZIA offers a high degree of detection accuracy, based on multi-sensor and multi-device fusion. Third, we show that WUZIA can resist active attacks that attempt to mimic a user's walking pattern, especially when multiple devices are used. Comment: 20 pages, 4 figures, under submissio...|$|R
40|$|The {{topic of}} <b>multi-modal</b> <b>biometrics</b> has {{attracted}} {{great interest in}} recent years. This talk will categorize different approaches to <b>multi-modal</b> <b>biometrics</b> based on the biometric sources, the type(s) of sensing used, {{and the depth of}} collaborative interaction in the processing. By “biometric source ” we mean the property of the person that is used for identification, such as fingerprint, voice, face appearance or iris texture. By type of sensing we mean different sensor modalities, such as 2 D, 3 D, or infra-red. By collaboration we mean {{the degree to which the}} processing of one biometric is influenced by the results of processing other biometrics. One commo...|$|E
30|$|Quality {{measures}} play {{an important}} role in score-level fusion systems and have been used to improve recognition accuracy [18, 24, 25]. In the majority of these approaches, the appropriate quality measures are calculated independently for each modality; this is a natural approach because each modality sample is captured using an individual and independent sensor, and the sensor’s properties are a major factor in determining the sample quality. For example, in <b>multi-modal</b> <b>biometrics</b> with face and fingerprint modalities, face and fingerprint samples are captured using a digital camera and a fingerprint scanner, respectively, and thus the fingerprint scanner never affects the quality of the face modality. In contrast, a single sensor-based system captures multiple modality samples using a single common sensor, and the qualities of multiple modalities are therefore affected by the same sensor property. For example, face and gait images captured simultaneously using a single camera [26] are both affected by the same sensor property (e.g., the SR of the sensor affects both the face and the gait samples, and it also affects the matching scores as a result). In general, correlation of matching scores that originate from different modalities are not so high in multiple sensor-based <b>multi-modal</b> <b>biometrics,</b> but this is not true for single sensor-based <b>multi-modal</b> <b>biometrics,</b> because the same sensor property affects the sample qualities of multiple modalities, and these qualities then affect the matching scores.|$|E
40|$|Biometrics based {{individual}} identification is observed {{as an effective}} technique for automatically knowing, with a high confidence a person’s identity. Multi-modal biometric systems consolidate the evidence accessible by multiple biometric sources and normally better recognition performance associate to system based on a single biometric modality. Multi biometric systems are used to overcome this issue by providing multiple pieces of indication of the same identity. This system provides effective fusion structure that combines {{information provided by the}} multiple field experts based on decision-level and score-level fusion method, thereby increasing the efficiency which is not conceivable in uni-modal system. <b>Multi-modal</b> <b>biometrics</b> can be attained through a fusion of two or more images, where the subsequent fused image will be more protected. This paper discusses various fusion techniques, architecture of multi-modal biometric authentication and working of biometric fusion i. e. Iris and Fingerprint recognition that are used in <b>multi-modal</b> <b>biometrics...</b>|$|E
40|$|Multi-biometrics has {{recently}} {{emerged as a}} mean of more robust and effcient personal verification and identification. Exploiting information from multiple sources at various levels i. e., feature, score, rank or decision, the false acceptance and rejection rates can be considerably reduced. Among all, feature level fusion is relatively an understudied problem. This paper addresses the feature level fusion for multi-modal and multi-unit sources of information. For multi-modal fusion the face and iris biometric traits are considered, while the multi-unit fusion is applied to merge {{the data from the}} left and right iris images. The proposed approach computes the SIFT features from both biometric sources, either multi- modal or multi-unit. For each source, the extracted SIFT features are selected via spatial sampling. Then these selected features are finally concatenated together into a single feature super-vector using serial fusion. This concatenated feature vector is used to perform classification. Experimental results from face and iris standard biometric databases are presented. The reported results clearly show the performance improvements in classification obtained by applying feature level fusion for both <b>multi-modal</b> and multi-unit <b>biometrics</b> in comparison to uni-modal classification and score level fusion...|$|R
40|$|The {{objective}} of this work is to explore approaches to create unique identities by the de-duplication process using <b>multi-modal</b> <b>biometrics.</b> Various government sectors in the world provide different services and welfare schemes for the beneffit {{of the people in}} the society using an identity number. A unique identity (UID) number assigned for every person would obviate the need for a person to produce multiple documentary proofs of his/her identity for availing any government/private services. In the process of creating unique identity of a person, there is a possibility of duplicate identities as the same person might want to get multiple identities in order to get extra beneffits from the Government. These duplicate identities can be eliminated by the de-duplication process using <b>multi-modal</b> <b>biometrics,</b> namely, iris, ngerprint, face and signature. De-duplication is the process of removing instances of multiple enrollments of the same person using the person's biometric data. As the number of people enrolledinto the biometric system runs into billions, the time complexity increases in the de duplication process. In this thesis, three different case studies are presented to address the performance issues of de-duplication process in order to create unique identity of a person...|$|E
30|$|A {{benchmark}} database {{is constructed}} and {{is composed of}} gait, head, and height biometric scores, including three types of qualities (SR, TR, and view) drawn from a publicly available database: the OU-ISIR Gait Database, Large Population Dataset [27]. Additionally, our database contains {{a very large number}} of scores because of the large numbers of subjects and qualities that are included, with totals of 3, 908, 128 genuine scores and 7, 468, 432, 608 imposter scores, and thus will serve as a benchmark for score-level fusion approaches for the <b>multi-modal</b> <b>biometrics</b> research community.|$|E
40|$|Multiple {{classifier}} {{systems have}} been originally proposed for supervised classification tasks, and few works have dealt with semi-supervised multiple classifiers. However, there are important pattern recognition applications, such as multi-sensor remote sensing and <b>multi-modal</b> <b>biometrics,</b> which demand semi-supervised multiple classifier systems able to exploit both labelled and unlabelled data. In this paper, the use, in multiple classifier systems, of two well known semi-supervised learning methods, namely, co-training and self-training, is investigated by experiments. Reported results on benchmarking data sets show that co-training and self-training allow exploiting unlabelled data in different types of multiple classifiers systems...|$|E
40|$|Humans {{should be}} able to think of {{computers}} as extensions of their body, as craftsmen do with their tools. Current security models, however, are too unlike those used in human minds [...] -for example, computers authenticate users by challenging them to repeat a secret rather than by continually observing the many subtle cues offered by their appearance and behavior. We propose three lines of research that can be combined to produce cognitive security on computers and other personal devices: imprinting and continuously deployed <b>multi-modal</b> <b>biometrics,</b> self-protection through virtualization and trusted computing, and adjustably autonomous security...|$|E
30|$|Single sensor-based <b>multi-modal</b> <b>biometrics</b> is a {{promising}} approach that offers simple system construction, low cost, and wide applicability to real situations such as CCTV footage-based criminal investigations. In <b>multi-modal</b> <b>biometrics,</b> fusion at the score-level {{is a popular}} and promising approach, and data qualities that affect the matching score of each modality are often incorporated as a quality-dependent score-level fusion framework. This paper presents a very large-scale single sensor-based multi-quality multi-modal biometric score database called MultiQ Score Database version 2 to advance the research into evaluation, comparison, and benchmarking of score-level fusion approaches using both quality-independent and quality-dependent protocols. We extracted gait, head, and height modalities from the OU-ISIR Gait Database and introduce spatial resolution (SR), temporal resolution (TR) and view as quality measures that significantly affect biometric system performance. We considered seven and 10 scaling factors for SR and TR, respectively, with four view variations. We then constructed a database comprising approximately 4 million genuine and 7.5 billion imposter score databases. To evaluate this database, we set two different protocols, and provided a set recognition accuracy for state-of-the-art approaches using protocols for both quality-independent and quality-dependent schemes. This database and the evaluation results will be beneficial for score-level fusion research. Additionally, we provide {{detailed analysis of the}} recognition accuracies associated with gait, head, and height modalities in different spatial/temporal resolutions and views. These analyses may be useful in criminal investigation research.|$|E
40|$|<b>Multi-modal</b> <b>biometrics</b> has {{numerous}} {{advantages over}} unimodal biometric systems. Decision level fusion {{is the most}} popular fusion strategy in multimodal biometric systems. Recent research has shown promising performance of hand based biometrics, i. e. palmprint and hand geometry over other biometric modalities. However, the improvement in performance is constrained by the lack of optimal sensor points and fusion strategy. In this paper, we have implemented a particle swarm based optimization technique for selecting optimal parameters through decision level fusion of two modalities: palmprint and hand geometry. The experimental evaluation on a database of 100 users confirms the utility of the decision level fusion using particle swarm optimization...|$|E
40|$|This paper {{proposes a}} novel human {{recognition}} method in video, which combines human face and gait traits using a dynamic <b>multi-modal</b> <b>biometrics</b> fusion scheme. The Fisherface approach is adopted to extract face features, while for gait features, Locality Preserving Projection (LPP) {{is used to}} achieve low-dimensional manifold embedding of the temporal silhouette data derived from image sequences. Face and gait features are fused dynamically at feature level based on a distance-driven fusion method. Encouraging experimental results are achieved on the video sequences containing 20 people, which show that dynamically fused features produce a more discriminating power than any individual biometric as well as integrated features built on common static fusion schemes. <br /...|$|E
30|$|Multiple algorithms: While we {{considered}} multiple scores that {{were derived from}} <b>multi-modal</b> <b>biometrics</b> and provided a single matcher for each modality in this work, {{it is also possible}} to introduce multiple scores that are derived from multiple matchers, as per the existing biometric score database NIST-Multimodal [37], which contains scores that are derived from multiple face matchers. From a quality-dependent score-level fusion viewpoint, it is particularly interesting to introduce matchers with different sensitivities into the quality measures that were used in this paper (i.e., SR and TR). For example, gait feature representations that are encoded with more temporal and/or motion information (e.g., [67, 68] may be sensitive to TR variations (i.e., yielding higher accuracies for higher TRs), while those that are encoded with more static (shape) information (e.g., [69]) may be insensitive to the TR.|$|E
40|$|Information Fusion of <b>multi-modal</b> <b>Biometrics</b> has {{attracted}} much attention in recent years. However, this paper focuses on the information fusion in single modals, that is, the face Biometric. Two different representation methods, gray level intensity and Gabor feature, are exploited for fusion. We study the fusion problem in face recognition at both the face representation level and the confidence level. At the representation level, both the PCA feature fusion and the LDA feature fusion are considered, while at the confidence level, the sum rule and the product rule are investigated. We show through experiments on FERET face database and our own face database that appropriate information fusion can improve the performance of face recognition and verification. This suggests that gray level intensity and Gabor feature compensate for each other, based on the feasible fusion. 1...|$|E
40|$|Biometrics is {{physical}} or behavior characteristics {{that can be}} used for human identification. We propose the ear as a biometric and investigate it with both 2 D and 3 D data. The ICP-based algorithm also demonstrates good scalability with size of dataset. These results are encouraging in that they suggest a strong potential for 3 D ear shape as a biometric. Multi-biometric 2 D and 3 D ear recognition are also explored. The proposed automatic ear detection method will integrate with the current system, and the performance will be evaluated with the original one. The investigation of ear recognition under less controlled conditions will focus on the robustness and variability of ear biometrics. <b>Multi-modal</b> <b>biometrics</b> using 3 D ear images will be explored, and the performance will be compared to existing biometrics experimental results...|$|E
40|$|Ear {{recognition}} is a promising biometric measure, {{especially with the}} growing interest in <b>multi-modal</b> <b>biometrics.</b> Histogram of Oriented Gradients (HOG) has been effectively and efficiently used solving the problems of object detection and recognition, especially when illumination variations are present. This work presents a robust approach for ear recognition using multi-scale dense HOG features as a descriptor of 2 D ear images. The multi-scale features assure to capture the different and complicated structures of ear images. Dimensionality reduction was performed to avoid feature redundancy and provide a more efficient recognition process while being prone to over-fitting. Finally, a test was performed on a large and realistic database {{and the results were}} compared to {{the state of the art}} ear recognition approaches tested on the same dataset and under the same test procedure...|$|E
40|$|Researchers have {{suggested}} that the ear may have advantages over the face for biometric recogni-tion. Our previous experiments with ear and face recognition using the standard principal compo-nent analysis approach showed lower recognition performance using ear images. We report results of similar experiments on larger data sets that are more rigorously controlled for relative quality of face and ear images. We find that recognition performance is not significantly different between the face and the ear; for example, 69. 3 % versus 72. 7 %, respectively, in one experiment. We also find that multi-modal recognition using both the ear and face results in statistically significant improvement over either individual biometric; for example, 90. 9 % in the analogous experiment. Index terms- biometrics, face recognition, ear recognition, <b>multi-modal</b> <b>biometrics,</b> principal component analysis, appearance-based recognition. 1 1...|$|E
30|$|Quality {{measures}} {{can be used}} at various stages in the recognition pipeline to improve the recognition accuracy. During the enrollment phase, a quality measure is used as the criterion for sample recapture [48]. In the preprocessing phase, both quality-dependent feature enhancement and quality-dependent target region selection are considered [46]. In the matching phase, different matching algorithms are {{used to calculate the}} scores for uni-modal and <b>multi-modal</b> <b>biometrics.</b> In this phase, classifier or distance metrics are selected adaptively depending on the sample quality [49]. Another direction is to directly stack the quality measures into a score vector, i.e., Q-stack vector and to treat it as a feature vector for classification [50, 51]. Moreover, in [52, 53], biometric samples are classified into clusters based on the sample quality, and score normalization or fusion are done in a cluster-dependent way.|$|E
40|$|Authentication is {{required}} in stored database systems so that only authorized users can access the data and related cloud infrastructures. This paper proposes an `authentication technique using multi-factor and multi-dimensional authentication system with multi-level security. The proposed technique {{is likely to be}} more robust as the probability of breaking the password is extremely low. This framework uses a multi-modal biometric approach and SMS to enforce additional security measures with the conventional Login/password system. The robustness of the technique is demonstrated mathematically using a statistical analysis. This work presents the authentication system using the consumer authentication architecture diagrams, activity diagrams, data flow diagrams, sequence diagrams, and algorithms. Categories and Subject Descriptors Multi-factor biometric password generation and authentication. Additional Key Words and Phrases Multi-dimensional, multi-level security systems, multiple privilege levels, multi-factor passwords, <b>multi-modal</b> <b>biometrics,</b> cloud computing, big data intelligence, security and privacy. 1...|$|E
40|$|Biometrics {{represent}} a promising approach for reliable and secure user authentication. However, {{they have not}} yet been widely adopted in embedded systems, particularly in resource-constrained devices such as cell phones and personal digital assistants (PDAs). In this paper, we investigate the challenges involved in using face-based biometrics for authenticating a user to an embedded system. To enable high authentication accuracy, we consider robust face verifiers based on principal component analysis/linear discriminant analysis (PCA-LDA) algorithms and Bayesian classifiers, and their combined use (<b>multi-modal</b> <b>biometrics).</b> Since embedded systems are severely constrained in their processing capabilities, algorithms that provide sufficient accuracy tend to be computationally expensive, leading to unacceptable authentication times. On the other hand, achieving acceptable performance often comes at the cost of degradation in the quality of results. Our work aims at developing embedded processing architectures tha...|$|E
40|$|Abstract – Ensemble methods {{provide a}} principled frame-work for {{building}} high performance classifiers and repre-senting {{many types of}} data. As a result, these methods can be useful for making inferences in many domains such as classification and <b>multi-modal</b> <b>biometrics.</b> We introduce a novel ensemble method for combining multiple representa-tions (or views). The method is a multiple view general-ization of AdaBoost. Similar to AdaBoost, base classifiers are independently built from each representation. Unlike AdaBoost, however, all data types share the same sampling distribution as the view whose weighted training error is the smallest among all the views. As a result, the most con-sistent data type dominates over time, thereby significantly reducing sensitivity to noise. In addition, our proposal is provably better than AdaBoost trained on any single type of data. The proposed method {{is applied to the}} problems of facial and gender prediction based on biometric traits as well as of protein classification. Experimental results show that our method outperforms several competing techniques including kernel-based data fusion...|$|E
40|$|In {{traditional}} research, {{data fusion}} {{is referred to}} as multi-sensor data fusion. The theory is that data from multiple sources can be combined to provide more accurate, reliable and meaningful information than that provided by a single data source. Applications in this field of study were originally in the military domain; more recently, investigations for its application in various civilian domains (eg: computer security) have been undertaken. Multi-sensor data fusion as applied to biometric authentication is termed <b>multi-modal</b> <b>biometrics.</b> The objective {{of this study was to}} apply feature level fusion of fingerprint feature and keystroke dynamics data for authentication purposes, utilizing Artificial Neural Networks (ANNs) as a classifier. Data fusion was performed adopting the cooperative paradigm, a less researched approach. This approach necessitates feature subset selection to utilize the most discriminatory data from each source. Experimental results returned a false acceptance rate (FAR) of 0. 0 and a worst case false rejection rate (FRR) of 0. 0006, which were comparable to—and in some cases, slightly better than—other research using the cooperative paradigm...|$|E
40|$|Abstract — Biometrics {{identification}} {{methods have}} proved to be very efficient, more natural and easy for users than traditional methods of human identification. Biometrics methods truly identify humans, not keys and cards they posses or passwords they should remember. Ear on the other hand, has a more uniform distribution of color, so almost all information is conserved when converting the original image into gray scales. We propose the ear as a biometric and investigate it with both 2 D and 3 D data. The ICP-based algorithm also demonstrates good scalability with size of dataset. These results are encouraging in that they suggest a strong potential for 3 D ear shape as a biometric. Multi-biometric 2 D and 3 D ear recognition are also explored. The proposed automatic ear detection method will integrate with the current system, and the performance will be evaluated with the original one. The investigation of ear recognition under less controlled conditions will focus on the robustness and variability of ear biometrics. <b>Multi-modal</b> <b>biometrics</b> using 3 D ear images will be explored, and the performance will be compared to existing biometrics experimental results...|$|E
40|$|Abstract—Palmprints are {{emerging}} as a new entity in <b>multi-modal</b> <b>biometrics</b> for human identification and verification. Mul-tispectral palmprint images captured in the visible and infrared spectrum not only contain the wrinkles and ridge structure of a palm, but also the underlying pattern of veins; making them a highly discriminating biometric identifier. In this paper, we propose a feature encoding scheme for robust and highly accurate representation and matching of multispectral palmprints. To facilitate compact storage of the feature, we design a binary hash table structure that allows for efficient matching in large databases. Comprehensive experiments for both identification and verification scenarios are performed on two public datasets – one captured with a contact-based sensor (PolyU dataset), {{and the other with}} a contact-free sensor (CASIA dataset). Recognition results in various experimental setups show that the proposed method consistently outperforms existing state-of-the-art methods. Error rates achieved by our method (0. 003 % on PolyU and 0. 2 % on CASIA) are the lowest reported in literature on both dataset and clearly indicate the viability of palmprint as a reliable and promising biometric. All source codes are publicly available. Index Terms—Palmprint, Multispectral, Hashing, Contourlet. I...|$|E
40|$|The use of {{personal}} identity verification systems with <b>multi-modal</b> <b>biometrics</b> {{has been proposed}} {{in order to increase}} the performance and robustness against environmental variations and fraudulent attacks. Usually multi-modal fusion of biometrics is performed in parallel at the score-level by combining the individual matching scores. This parallel strategy exhibits some drawbacks: (i) all available biometrics are necessary to perform fusion, thus the verification time depends on the slowest system; (ii) some users could be easily recognizable using a certain biometric instead of another one and (iii) the system invasiveness increases. A system characterized by the serial combination of multiple biometrics can be a good trade-off between verification time, performance and acceptability. However, these systems have been poorly investigated, and no support for designing the processing chain has been given so far. In this paper, we propose a novel serial scheme and a simple mathematical model able to predict the performance of two serially combined matchers as function of the selected processing chain. Our model helps the designer in finding the processing chain allowing a trade-off, in particular, between performance and matching time. Experiments carried out on well-known benchmark data sets made up of face and fingerprint images support the usefulness of the proposed methodology and compare it with standard parallel fusion...|$|E
40|$|This paper {{addresses}} {{the problem of}} combining multi-modal kernels in situations in which object correspondence information is unavailable between modalities, for instance, where missing feature values exist, or when using proprietary databases in <b>multi-modal</b> <b>biometrics.</b> The method thus seeks to recover inter-modality kernel information so as to enable classifiers to be built within a composite embedding space. This is achieved through a principled group-wise identification of objects within differing modal kernel matrices in order to form a composite kernel matrix that retains the full freedom of linear kernel combination existing in multiple kernel learning. The underlying principle {{is derived from the}} notion of tomographic reconstruction, which has been applied successfully in conventional pattern recognition. In setting out this method, we aim to improve upon object-correspondence insensitive methods, such as kernel matrix combination via the Cartesian product of object sets to which the method defaults in the case of no discovered pairwise object identifications. We benchmark the method against the augmented kernel method, an order-insensitive approach derived from the direct sum of constituent kernel matrices, and also against straightforward additive kernel combination where the correspondence information is given a priori. We find that the proposed method gives rise to substantial performance improvements...|$|E
40|$|Palmprints are {{emerging}} as a new entity in <b>multi-modal</b> <b>biometrics</b> for human identification and verification. Multispectral palmprint images captured in the visible and infrared spectrum not only contain the wrinkles and ridge structure of a palm, but also the underlying pattern of veins; making them a highly discriminating biometric identifier. In this paper, we propose a feature encoding scheme for robust and highly accurate representation and matching of multispectral palmprints. To facilitate compact storage of the feature, we design a binary hash table structure that allows for efficient matching in large databases. Comprehensive experiments for both identification and verification scenarios are performed on two public datasets [...] one captured with a contact-based sensor (PolyU dataset), {{and the other with}} a contact-free sensor (CASIA dataset). Recognition results in various experimental setups show that the proposed method consistently outperforms existing state-of-the-art methods. Error rates achieved by our method (0. 003 % on PolyU and 0. 2 % on CASIA) are the lowest reported in literature on both dataset and clearly indicate the viability of palmprint as a reliable and promising biometric. All source codes are publicly available. Comment: Preliminary version of this manuscript was published in ICCV 2011. Z. Khan A. Mian and Y. Hu, "Contour Code: Robust and Efficient Multispectral Palmprint Encoding for Human Recognition", International Conference on Computer Vision, 2011. MATLAB Code available: [URL]...|$|E
40|$|Palmprints {{have been}} widely studied for {{biometric}} recognition for many years. Traditionally, a white light source is used for illumination. Recently, multispectral imaging has drawn attention because of its high recognition accuracy. Multispectral palmprint systems can provide more discriminant information under different illuminations in a short time, thus they can achieve better recognition accuracy. Previously, multispectral palmprint images were taken {{as a kind of}} <b>multi-modal</b> <b>biometrics,</b> and the fusion scheme on the image level or matching score level was used. However, some spectral information will be lost during image level or matching score level fusion. In this study, we propose a new method for multispectral images based on a quaternion model which could fully utilize the multispectral information. Firstly, multispectral palmprint images captured under red, green, blue and near-infrared (NIR) illuminations were represented by a quaternion matrix, then principal component analysis (PCA) and discrete wavelet transform (DWT) were applied respectively on the matrix to extract palmprint features. After that, Euclidean distance was used to measure the dissimilarity between different features. Finally, the sum of two distances and the nearest neighborhood classifier were employed for recognition decision. Experimental results showed that using the quaternion matrix can achieve a higher recognition rate. Given 3000 test samples from 500 palms, the recognition rate can be as high as 98. 83 %...|$|E
40|$|Human {{identity}} {{is a prerequisite}} for trust assurance and assessment, which is essential for effective human-machine interaction in trusted autonomous systems. Unlike conventional authentication methods which do not require users to re-authenticate themselves for sustained access, continuous authentication affirms human identity in real-time, therefore is a solution for continued access monitoring in trusted autonomous systems. Robust continuous authentication needs robust multi-modal data sources. In this paper, we design a <b>multi-modal</b> <b>biometrics</b> system that continuously verifies the presence of a logged-in user. Two types of biometric data are used, face images and Electroencephalography (EEG) signals. Information from individual modalities is fused at matching score level. For face modality, matching scores are calculated by distances between eigenface coefficients. While for EEG signals, an event-related potential (ERP) modality is established by a simple ERP elicitation protocol and calculation of cross-correlation similarities. Scores from the two modalities are normalized and fused using three schemes, namely the sum-score, max-score and min-score scheme. The experiments reveal that individual variations found in the ERPs are detectable and can be used for continuous authentication. This is an interesting finding which indicates that the ERP biometrics are feasible for user authentication and worthy of further research. Results also show that combining ERP biometric with face biometric using sum-score scheme outperforms each modality in isolation. This piece of finding indicates the potential of integrating ERP into multimodal authentication systems...|$|E
40|$|Biometric {{data can}} be used as input for PKI key pair generation. The concept of not saving the private key is very appealing, but the {{implementation}} of such a system shouldn’t be rushed because it might prove less secure then current PKI infrastructure. One biometric characteristic can be easily spoofed, so it was believed that <b>multi-modal</b> <b>biometrics</b> would offer more security, because spoofing two or more biometrics would be very hard. This notion, of increased security of multi-modal biometric systems, was disproved for authentication and matching, studies showing that not only multi-modal biometric systems are not more secure, but they introduce additional vulnerabilities. This paper is a study on the implications of spoofing biometric data for retrieving the derived key. We demonstrate that spoofed biometrics can yield the same key, which in turn will lead an attacker to obtain the private key. A practical implementation is proposed using fingerprint and iris as biometrics and the fuzzy extractor for biometric key extraction. Our experiments show what happens when the biometric data is spoofed for both uni-modal systems and multi-modal. In case of multi-modal system tests were performed when spoofing one biometric or both. We provide detailed analysis of every scenario in regard to successful tests and overall key entropy. Our paper defines a biometric PKI scenario and an in depth security analysis for it. The analysis {{can be viewed as a}} blueprint for implementations of future similar systems, because it highlights the main security vulnerabilities for bioPKI. The analysis is not constrained to the biometric part of the system, but covers CA security, sensor security, communication interception, RSA encryption vulnerabilities regarding key entropy, and much more...|$|E
40|$|This PhD {{research}} project developed and evaluated innovative approaches to computer system user authentication, using biometric characteristics. It involved experiments {{with a significant}} number of participants and development of new approaches to biometric data representation and analysis. The initial authentication procedure, that we all perform when we log onto a computer system, is considered to be the first line of protection for computer systems. The password is the most common verification token used in initial authentication procedures. Unfortunately, passwords are subject to numerous attack vectors (loss, theft, guessing or cracking), and as a result unauthorised persons may gain access to the verification token and be incorrectly authenticated. This has led to password-based authentication procedures being responsible for a large proportion of computer network security breaches. In recent years, the use of biometrics has been increasingly researched as an alternative to passwords in the initial authentication procedure. Biometrics concerns the physical traits and behavioural characteristics that make each individual unique. Biometric authentication involves the use of biometric technologies in authentication systems, with the aim to provide accurate verification (based on biometric characteristics). Research has demonstrated that uni-modal biometric authentication (that is, authentication based on a single biometric characteristic) makes it difficult for an impostor to impersonate a legitimate user. More recent research is finding that multi-modal biometric authentication (that is, authentication based on the combination of multiple biometric characteristics) can make it even more difficult for an impostor to impersonate a legitimate user. Thus <b>multi-modal</b> <b>biometrics</b> claims improved accuracy and robustness. <b>Multi-modal</b> <b>biometrics</b> requires consideration of various aspects of data integration, known to the field of data fusion. Multi-modal biometric research has, until recently, focused on the fusion of data (from multiple sources) at the decision level or the confidence score level. It has been proposed that fusion of data at the feature level will produce more accurate and reliable verification. However, fusion of data at the feature level is a more difficult task than fusion at the other two levels. For decision level fusion, 'accept' or 'reject' results from the different data sources are fused. For confidence score level fusion, confidence scores (typically in the continuous interval [0, 1]) from the different data sources are fused. That is, for the aforementioned levels, the data from the multiple sources are of the same nature. Feature level fusion combines feature vectors, where the data from the different sources are most likely to consist of different units of measurement. Data fusion literature formally specifies that data may be combined according to three paradigms: competitive, complementary, and cooperative. Competitive data fusion assesses data from all available sources, and bases classification upon the 'best' source. Complementary data fusion combines all available data from all sources, and bases classification upon this combined data. Cooperative data fusion involves the selection of the best features of each individual data source, and then combines the selected features prior to classification. The objectives of the current study were to investigate the use of two individual biometric characteristics (keystroke dynamics and fingerprint recognition). For keystroke dynamics, feature selection was employed to reduce the variability associated with data from this characteristic. For fingerprint recognition, a new method was developed to represent fingerprint features. This was done to assist classification by Artificial Neural Networks, and to meet the requirement to facilitate fusion with the keystroke dynamics data at the feature level. Whilst feature level data fusion was the primary objective, investigation of the two individual characteristics was conducted to enable comparison of results with the data fusion results. For the data fusion investigation, the complementary and cooperative paradigms were adopted, with the cooperative approach involving four stages. The feature selection method chosen to filter keystroke dynamics data was based on normality statistics, and returned results comparable to many other research efforts. The fingerprint feature representation method developed for this experiment demonstrated an innovative and effective technique, which could be applicable in a uni-modal or a multi-modal context. As the new fingerprint representation method resulted in a standard length feature vector for each fingerprint, data alignment and subsequent feature level data fusion was efficiently and practicably facilitated. The experiment recruited 90 participants to provide typing and fingerprint samples. Of these, 140 keystroke dynamics samples and 140 fingerprint samples (from each participant) were utilised for the first two phases of the experiment. Phase three of the experiment involved the fusion of the samples from the first two phases, and thus there were 140 combined samples. These quantities provided 100 samples for false negative testing and 10, 500 samples for false positive testing (for each participant for each phase of the experiment). These figures are similar or better than virtually all previous research studies in this field. The results of the three phases of the experiment were calculated as the two performance variables, the false rejection rate (FRR) -measuring the false negatives-and the false acceptance rate (FAR) -measuring the false positives. The keystroke dynamics investigation returned an average FAR of 0. 02766095 and an average FRR of 0. 0862, which were• at least comparable with other research in the field. The fingerprint recognition investigation returned an average FAR of 0. 0 and an average FRR of 0. 0022, which were as good as (or better than) other research in the field. The feature level data fusion adopting the complementary approach returned an average FAR of 0. 0 and an average FRR of 0. 0004. Feature level data fusion adopting the cooperative approach returned respective average FAR and FRR results of 0. 00000381 and 0. 0004 for stage 1, 0. 0 and 0. 0006 for stage 2, 0. 0 and 0. 001 for stage 3, and 0. 0 and 0. 001 for stage 4. The research demonstrated that uni-modal biometric authentication systems provide an accurate alternative to traditional password-based authentication methods. Additionally, the keystroke dynamics investigation demonstrated that filtering 'noisy' data from raw data improved accuracy for this biometric characteristic (though other filtering methods than that used in this research may improve accuracy further). Also, the newly developed fingerprint representation method demonstrated excellent results, and indicated that its use for future research (in representing two dimensional data for classification by Artificial Neural Networks) could be advantageous. The data fusion investigation demonstrated that multi-modal biometric authentication systems provide additional accuracy improvement (as well as a perceived robustness) compared to uni-modal biometric authentication systems. Feature level data fusion demonstrated improved accuracy compared with confidence score level and decision level data fusion methods. The new fingerprint representation method (which provided an innovative technique for representing data from any two dimensional data source) facilitated feature level data fusion with keystroke dynamic data, and the results validate the importance of using feature rich data...|$|E
