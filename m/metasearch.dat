346|21|Public
50|$|Lagisatu.com is {{a travel}} <b>metasearch</b> engine {{focusing}} on hotels. In April 2013, Lagisatu.com integrated MuslimStars, {{which makes it}} the world’s first hotel <b>metasearch</b> engine catering for Muslim travelers.|$|E
5000|$|They {{will both}} {{cooperate}} and provide complete access to interface for the <b>metasearch</b> engine, including private {{access to the}} index database, and will inform the <b>metasearch</b> engine of any changes made upon the index database; ...|$|E
50|$|Blucora's InfoSpace {{business}} provides <b>metasearch</b> and private-label Internet search {{services for}} consumers and online search and monetization solutions {{to a network}} of more than 100 partners worldwide. InfoSpace's main <b>metasearch</b> site is Dogpile; its other brands are WebCrawler, and MetaCrawler.|$|E
40|$|Distributed {{information}} retrieval has pressing scalability concerns {{due to the}} growing number of independent sources of on-line data and the emerging applications. A promising solution to distributed retrieval is <b>metasearching,</b> which dispatches a user’s query to multiple sources and gathers the results into a single result set. An important component of <b>metasearching</b> is selecting the set of information sources most likely to provide relevant documents. Recent research has focused on how to obtain statistics for the selection task. In this paper we discuss different information source selection approaches and their applicability for resource-constrained sensor network applications. 1...|$|R
40|$|In principle, federated or <b>metasearching</b> does {{allow one}} to do {{one-stop}} shopping to find search results. In MetaLib, for instance, once you see the list of relevant databases, you can designate up to eight databases - the ones likeliest to give you relevant results - for simultaneous searching. (Compare that with the {{dozens and dozens of}} databases which Dialog's One-Search allows...|$|R
40|$|I. Introduction ??? Definitions ??? Landscape of <b>metasearching</b> in {{academic}} libraries II. Description of the Implementation at CSU Northridge III. Literature Review IV. Results of student assessment V. Results of librarian assessment VI. Conclusion - including impact of portal/federated searching technology on information literacy {{programs as well}} as the future of resource. Presented at 2005 LITA (Library and Information Technology Association) National Forum, San Jose, CA, October 1, 2005...|$|R
50|$|<b>Metasearch</b> {{engines are}} {{not capable of}} {{decoding}} query forms or able to fully translate query syntax. The number of links generated by <b>metasearch</b> engines are limited, and therefore do not provide the user with the complete results of a query.The majority of <b>metasearch</b> engines do not provide over ten linked files from a single search engine, and generally do not interact with larger search engines for results. Sponsored webpages are prioritised and are normally displayed first.|$|E
50|$|PolyCola is a <b>metasearch</b> engine. A <b>metasearch</b> {{engine is}} a tool which lets you submit a word or phrase in the search box. Then it sends your search {{concurrently}} to other individual search engines which then sends it to its own databases. Within couple of seconds, you receive the result from several search engines. A <b>metasearch</b> engine only sends your search terms to databases of individual search engines; {{it does not have}} its own database of web pages.|$|E
50|$|A <b>metasearch</b> engine {{accepts a}} single search {{request from the}} user. This search request is then passed on to another search engine’s {{database}}. A <b>metasearch</b> engine does not create a database of webpages but generates a virtual database to integrate data from multiple sources.|$|E
40|$|Cooperative Curation Symposium and Workshop, Wednesday, August 8 -Thursday, August 9, 2012 in the Clough Commons, Georgia Tech Library. This two-day {{symposium}} and workshop {{hosted by}} the GALILEO Knowledge Repository project at the Georgia Institute of Technology, includes a one-day symposium featuring case studies from four institutions relating their approaches to cooperative scholarly communication initiatives and a one-day workshop featuring concurrent technology and program management sessions on topics including governance, <b>metasearching,</b> repository hosting, digitization, outreach, among others...|$|R
40|$|With over 800 million pages {{covering}} {{most areas}} of human endeavor, the World Wide Web is {{fertile ground for}} information retrieval. Numerous search technologies have been applied to Web searches, and the dominant search method {{has yet to be}} identified. This chapter provides an overview of existing Web search technologies and classifies them into six categories: (i) hyperlink exploration, (ii) information retrieval, (iii) <b>metasearches,</b> (iv) SQL approaches, (v) content-based multimedia searches, and (vi) others. A comparative study of some major commercial and experimental search services is presented, and some future research directions for Web searches are suggested...|$|R
40|$|This paper {{analyzes}} {{the results of}} transaction logs at California State University, Los Angeles (CSULA) and studies the effects of implementing a Web-based OPAC along with interface changes. The authors find that user success in subject searching remains problematic. A major increase {{in the frequency of}} searches that would have been more successful in resources other than the library catalog is noted over the time period 2000 - 2002. The authors attribute this increase to the prevalence of Web search engines and suggest that <b>metasearching,</b> relevance-ranked results, and relevance feedback ("more like this") are now expected in user searching and should be integrated into online catalogs as search options...|$|R
50|$|However, <b>Metasearch</b> {{also has}} issues. Scores of {{websites}} stored on search engines are all different: this can draw in irrelevant documents. Other {{problems such as}} spamming also significantly reduce {{the accuracy of the}} search. The process of fusion aims to tackle this issue and improve the engineering of a <b>metasearch</b> engine.|$|E
5000|$|<b>Metasearch</b> {{engines are}} so named as they conduct {{searches}} across multiple independent search engines. <b>Metasearch</b> engines often {{make use of}} [...] "screen scraping" [...] to get live availability of flights. Screen scraping {{is a way of}} crawling through the airline websites, getting content from those sites by extracting data from the same HTML feed used by consumers for browsing (rather than using a Semantic Web or database feed designed to be machine-readable). <b>Metasearch</b> engines usually process incoming data to eliminate duplicate entries, but may not expose [...] "advanced search" [...] options in the underlying databases (because not all databases support the same options).|$|E
50|$|Jobster is an {{employment}} website, a <b>metasearch</b> engine for job listings.|$|E
40|$|Presented at the Cooperative Curation Symposium and Workshop, Thursday, August 9, 2012 in the Clough Commons {{classroom}} 102, Georgia Tech Library. Cooperative Curation Workshop: Georgia’s Approach to Statewide Repository Services - Technology Track: <b>Metasearching</b> - Breakout Session 4. Patrick Etienne is a Digital Library Developer and Larry Hansard is the Technology & Systems Librarian at Georgia Tech Library. Keith Gilbertson is a Digital Technologies Development Librarian at Virginia Tech. Customizing the GKR interface, {{creating a}} new home page, creating new help and about pages, changing communities to disciplines, adding the institution index, modifying the advanced search types, modifying the simple item record view, adding icons to the browse by results and PubMed Central open access import...|$|R
40|$|We {{study the}} problem of {{aggregating}} partial rankings. This problem is motivated by applications such as <b>metasearching</b> and information retrieval, search engine spam fighting, e-commerce, learning from experts, analysis of population preference sampling, committee decision making and more. We improve recent constant factor approximation algorithms for aggregation of full rankings and generalize them to partial rankings. Our algorithms improved constant factor approximation with respect to all metrics discussed in Fagin et al’s recent important work on comparing partial rankings. We {{pay special attention to}} two important types of partial rankings: the well-known top-m lists and the more general p-ratings which we define. We provide first evidence for hardness of aggregating them for constant m, p...|$|R
40|$|There are {{hundreds}} of algorithms within data mining. Some of them are used to transform data, some to build classifiers, others for prediction, etc. Nobody knows well all these algorithms and nobody can know all the arcana of their behavior in all possible applications. How {{to find the best}} combination of transformation and final machine which solves given problem? The solution is to use configurable and efficient meta-learning to solve data mining problems. Below, a general and flexible meta-learning system is presented. It can be used to solve different problems with computational intelligence, basing on learning from data. The main ideas of our meta-learning algorithms lie in complexity controlled loop, searching for most adequate models and in using special functional specification of search spaces (the meta-learning spaces) combined with flexible way of defining the goal of <b>metasearching...</b>|$|R
50|$|A <b>metasearch</b> engine (or aggregator) is {{a search}} tool that uses another search engine's data to {{produce their own}} results from the Internet. <b>Metasearch</b> engines take input from a user and {{simultaneously}} send out queries to third party search engines for results. Sufficient data is gathered, formatted by their ranks and presented to the users.|$|E
50|$|HotBot is a <b>metasearch</b> {{engine for}} {{information}} on the world wide web.|$|E
50|$|In June 2015, the United Kingdom website was {{launched}} as a <b>metasearch</b> engine.|$|E
40|$|This paper {{describes}} the language modeling script constructed for the Spring 2000 Information Retrieval seminar. The script builds on Callan's[1] work of automatically generating language models for text databases by creating language models for internet search engines. An {{overview of the}} work, principles and observed properties of language models, the language modeling script (LAMB) and its shortcomings are described. 1 Introduction The Spring 2000 Information Retrieval (IR) seminar has focused on IR concepts in general as well as distributed information retrieval. One of the major topics of the seminar focused on efficient and effective <b>metasearching.</b> If collection selection is employed in distributed searching, a proxy form of the sub-collections is needed to represent the real collection at query time. We refer to this proxy form as a language model of the collection. The interest {{of this paper is}} on how to efficiently and automatically create a language model that accurately [...] ...|$|R
40|$|The {{implementation}} of Metalib in UOC's Library was centred {{in the end}} user. For the adaptation of Metalib to the users' needs and search behaviour, we carried out three tests: - One with students, conducted by a consulting company; - A second one with teachers, {{carried out by the}} Library; - The third, with teachers and staff, also was carried out by the Library, after having made some changes resulting from the first and second test. The tests, made with the software Morae, underlined a number of difficulties to understand the concepts related to <b>metasearching.</b> The tests also showed difficulties in navigating and in managing the search results. All the information gathered was used to improve the navigation through the interface. The presentation tells about the tests’ methodology, the conclusions reached with this experience, and the decisions finally taken by the Library to improve the Metalib interface...|$|R
40|$|We {{introduce}} a general {{and in a}} certain sense time-optimal way of solving one problem after another, efficiently searching the space of programs that compute solution candidates, including those programs that organize and manage and adapt and reuse earlier acquired knowledge. The Optimal Ordered Problem Solver (OOPS) draws inspiration from Levin's Universal Search designed for single problems and universal Turing machines. It spends part of the total search time for a new problem on testing programs that exploit previous solution-computing programs in computable ways. If the new problem can be solved faster by copy-editing/invoking previous code than by solving the new problem from scratch, then OOPS will find this out. If not, then at least the previous solutions will not cause much harm. We {{introduce a}}n efficient, recursive, backtracking-based way of implementing OOPS on realistic computers with limited storage. Experiments illustrate how OOPS can greatly profit from metalearning or <b>metasearching,</b> that is, searching for faster search procedures...|$|R
5000|$|Indexed data (documents, weblogs, images, videos, {{shopping}} articles, jobs ...) used by <b>metasearch</b> engines ...|$|E
50|$|HotelsCombined is a hotel <b>metasearch</b> engine {{founded in}} 2005, with {{headquarters}} in Sydney, Australia.|$|E
50|$|Search.creativecommons.org - a <b>Metasearch</b> {{engine for}} finding Creative Commons content on other search engines.|$|E
40|$|An ever {{increasing}} amount of valuable information {{is stored in}} Web databases, "hidden" behind search interfaces. To save the user's effort in manually exploring each database, metasearchers automatically select the most relevant databases to a user's query [2, 5, 16, 21, 27, 18]. In this paper, {{we focus on the}} first of the two technical challenges of <b>metasearching,</b> namely database selection. Past research uses a pre-collected summary of each database to estimate its "relevancy" to the query, and in many cases make incorrect database selection. In this paper, we propose two techniques: probabilistic relevancy modelling and adaptive probing. First, we model the relevancy of each database to a given query as a probabilistic distribution, derived by sampling that database. Using the probabilistic model, the user can explicitly specify a desired level of certainty for database selection. The adaptive probing technique decides which and how many databases to contact in order to satisfy the user's requirement. Our experiments on real Hidden-Web databases indicate that our approach significantly improves the accuracy of database selection at the cost of a small number of database probing...|$|R
40|$|Many {{valuable}} text databases {{on the web}} have non-crawlable contents {{that are}} “hidden” behind search interfaces. Metasearchers are helpful tools for searching over multiple such “hidden-web” text databases at once through a unified query interface. An important step in the <b>metasearching</b> process is database selection, or determining which databases are the most relevant for a given user query. The state-ofthe-art database selection techniques rely on statistical summaries of the database contents, generally including the database vocabulary and the associated word frequencies. Unfortunately, hidden-web text databases typically do not export such summaries, so previous research has developed algorithms for constructing approximate content summaries from document samples extracted from the databases via querying. We present a novel “focused probing” sampling algorithm that detects the topics covered in a database and adaptively extracts documents that {{are representative of the}} topic coverage of the database. Our algorithm is the first that constructs content summaries that include the frequencies of the words in the database. Unfortunately, Zipf’s law practically guarantees that, for any relatively large database, content summaries built from moderately sized document samples will fail to cover many lowfrequency words; in turn, incomplete content summaries might negatively affect the database selectio...|$|R
40|$|To {{make good}} decisions, {{businesses}} try to gather good intelligence information. Yet managing and processing {{a large amount}} of unstructured information and data {{stand in the way of}} greater business knowledge. An effective business intelligence tool must be able to access quality information from a variety of sources in a variety of forms, and it must support people as they search for and analyze that information. The EBizPort system was designed to address information needs for the business/IT community. EBizPort’s collection-building process is designed to acquire credible, timely, and relevant information. The user interface provides access to collected and <b>metasearched</b> resources using innovative tools for summarization, categorization, and visualization. The effectiveness, efficiency, usability, and information quality of the EBizPort system were measured. EBizPort significantly outperformed Brint, a business search portal, in search effectiveness, information quality, user satisfaction, and usability. Users particularly liked EBizPort’s clean and user-friendly interface. Results from our evaluation study suggest that the visualization function added value to the search and analysis process, that the generalizable collection-building technique can be useful for domain-specific information searching on the Web, and that the search interface was important for Web search and browse support...|$|R
5000|$|Since every {{search engine}} {{is unique and}} has {{different}} algorithms for generating ranked data, duplicates will therefore also be generated. To remove duplicates,a <b>metasearch</b> engine processes this data and applies its own algorithm. A revised list is produced as an output for the user. When a <b>metasearch</b> engine contacts other search engines, these search engines will respond in three ways: ...|$|E
5000|$|There {{are also}} other online {{vacation}} rental sites {{that specialize in}} <b>metasearch</b> or resort residences.|$|E
50|$|ProntoHotel {{is a free}} hotel travel <b>metasearch</b> engine {{founded in}} 2007 with {{headquarters}} in Rome, Italy.|$|E
40|$|SDARTS is a {{protocol}} and toolkit designed to facilitate <b>metasearching.</b> SDARTS combines two complementary existing protocols, SDLIP and STARTS, {{to define a}} uniform interface that collections should support for searching and exporting metasearch-related metadata. SDARTS also includes a toolkit with wrappers that are easily customized to make both local and remote document collections SDARTScompliant. This paper describes two significant {{ways in which we}} have extended the SDARTS toolkit. First, we have added a tool that automatically builds rich content summaries for remote web collections by probing the collections with appropriate queries. These content summaries can then be used by a metasearcher to select over which collections to evaluate a given query. Second, we have enhanced the SDARTS toolkit so that all SDARTS-compliant collections export their metadata under the emerging Open Archives Initiative (OAI) protocol. Conversely, the SDARTS toolkit now also allows all OAI-compliant collections to be made SDARTS-compliant with minimal e#ort. As a result, we implemented a bridge between SDARTS and OAI, which will facilitate easy interoperability among a potentially large number of collections. The SDARTS toolkit, with all related documentation and source code, is publicly available at [URL]...|$|R
40|$|Many {{valuable}} text databases {{on the web}} have noncrawlable contents {{that are}} “hidden ” behind search interfaces. Metasearchers are helpful tools for searching over multiple such “hidden-web” text databases at once through a unified query interface. An important step in the <b>metasearching</b> process is database selection, or determining which databases are the most relevant for a given user query. The state-of-the-art database selection techniques rely on statistical summaries of the database contents, generally including the database vocabulary and associated word frequencies. Unfortunately, hidden-web text databases typically do not export such summaries, so previous re-search has developed algorithms for constructing approximate content summaries from document samples extracted from the databases via querying. We present a novel “focused-probing ” sampling algorithm that detects the topics covered in a database and adaptively extracts documents that {{are representative of the}} topic coverage of the database. Our algorithm is the first to construct content summaries that include the frequencies of the words in the database. Unfortunately, Zipf ’s law practically guarantees that for any relatively large database, content summaries built from moderately sized document samples will fail to cover many low-frequency words; in turn, incom-plete content summaries might negatively affect the database selection process, especially for shor...|$|R
40|$|Nelli {{is a new}} way to use the library. It organises and {{retrieves}} {{information as}} well as providing tailored services. The Nelli information retrieval portal can be used to manage all the information materials necessary in research, teaching and studying. It is an interface through which researchers, students and the public can access libraries’ acquired data resources. Minister of Education Tuula Haatainen will open the national Nelli information retrieval portal for the use of Finnish universities’ customers on 15 September 2004. Public libraries, polytechnics, as well as special schools and research institutes {{will be able to use}} Nelli later. Nelli belongs to everyone. The University of Helsinki, the National Library of Finland, working jointly with Finnish universities, is responsible for the start-up of the Nelli information retrieval portal. Powered by ExLibrix’s MetaLib and SFX software, Nelli’s services can be tailored locally; each university can configure Nelli services to meet its customers’ needs. Nelli is a tool for researchers that provides: high quality content and information retrieval services from a single source, <b>metasearches</b> enabling the simultaneous searching of several databases with a single command, linking services, management of customer identification and user rights, tailoring of interfaces, customer-specific settings. The combination of the Virtual University and the Nelli information retrieval portal exploits electronic services to enhance the effectiveness of the learning environment...|$|R
