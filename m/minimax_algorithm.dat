119|79|Public
25|$|Since the <b>minimax</b> <b>algorithm</b> and its {{variants}} {{are inherently}} depth-first, a strategy such as iterative deepening is usually {{used in conjunction}} with alpha–beta so that a reasonably good move can be returned even if the algorithm is interrupted before it has finished execution. Another advantage of using iterative deepening is that searches at shallower depths give move-ordering hints, as well as shallow alpha and beta estimates, that both can help produce cutoffs for higher depth searches much earlier than would otherwise be possible.|$|E
25|$|Given {{the rules}} of any two-person game with {{a finite number of}} positions, one can always trivially {{construct}} a <b>minimax</b> <b>algorithm</b> that would exhaustively traverse the game tree. However, since for many non-trivial games such an algorithm would require an infeasible amount of time to generate a move in a given position, a game is not considered to be solved weakly or strongly unless the algorithm can be run by existing hardware in a reasonable time. Many algorithms rely on a huge pre-generated database, and are effectively nothing more.|$|E
25|$|Alpha–beta pruning is {{a search}} {{algorithm}} {{that seeks to}} decrease the number of nodes that are evaluated by the <b>minimax</b> <b>algorithm</b> in its search tree. It is an adversarial search algorithm used commonly for machine playing of two-player games (Tic-tac-toe, Chess, Go, etc.). It stops completely evaluating a move when at least one possibility {{has been found that}} proves the move to be worse than a previously examined move. Such moves need not be evaluated further. When applied to a standard minimax tree, it returns the same move as minimax would, but prunes away branches that cannot possibly influence the final decision.|$|E
50|$|One popular <b>minimax</b> {{approximation}} <b>algorithm</b> is the Remez algorithm.|$|R
40|$|We study {{algorithms}} {{for online}} linear optimization in Hilbert spaces, {{focusing on the}} case where the player is unconstrained. We develop a novel characterization of a large class of <b>minimax</b> <b>algorithms,</b> recovering, and even improving, several previous results as immediate corollaries. Moreover, using our tools, we develop an algorithm that provides a regret bound ofO...|$|R
50|$|Several <b>minimax</b> {{approximation}} <b>algorithms</b> are available, {{the most}} common being the Remez algorithm.|$|R
50|$|The {{pseudocode}} for {{the depth}} limited <b>minimax</b> <b>algorithm</b> is given below.|$|E
50|$|The {{design of}} Blondie24 {{is based on}} a <b>minimax</b> <b>algorithm</b> of the {{checkers}} game tree in which the evaluation function is a deep learning convolutional artificial neural network. The neural net receives as input a vector representation of the checkerboard positions and returns a single value which is passed on to the <b>minimax</b> <b>algorithm.</b>|$|E
50|$|In {{combinatorial}} game theory, {{there is}} a <b>minimax</b> <b>algorithm</b> for game solutions.|$|E
50|$|The {{result is}} called the {{polynomial}} of best approximation or the <b>minimax</b> approximation <b>algorithm.</b>|$|R
40|$|Abstract-Two {{iterative}} <b>minimax</b> <b>algorithms</b> {{are presented}} with associ-ated convergence theorems. Both algorithms consists of iterative proce-dures based on a sequence of finite parameter sets; in general these finite parameter sets are subsets of an infinite parameter space. To show their applicabilities, several commonly used examples are presented. It is also shown that minimax problems with or without finite parameter sets can be solved by these two algorithms numerically to any assigned degree of accuracy. I...|$|R
50|$|The {{particular}} polynomial used {{to approximate}} a trig function is generated {{ahead of time}} using some approximation of a <b>minimax</b> approximation <b>algorithm.</b>|$|R
50|$|A naïve <b>minimax</b> <b>algorithm</b> may be trivially {{modified}} to additionally return an entire Principal Variation {{along with a}} minimax score.|$|E
5000|$|The expectiminimax {{algorithm}} is {{a variant of}} the <b>minimax</b> <b>algorithm</b> and was first proposed by Donald Michie in 1966.Its pseudocode is given below.|$|E
50|$|In every zero-sum game, {{the value}} of the game is {{achieved}} by the <b>minimax</b> <b>algorithm</b> (player 1 tries to maximize the profit, and player 2 tries to minimize the cost).|$|E
50|$|A <b>minimax</b> {{approximation}} <b>algorithm</b> (or L∞ approximation or uniform approximation) is {{a method}} to find an approximation of a mathematical function that minimizes maximum error.|$|R
40|$|In the {{theoretical}} {{part of this}} paper, we introduce a simplified proof technique for error bounds and convergence of a variation of E. Kansa’s well-known unsymmetric meshless collocation method. For a numerical implementation of the convergent variation, a previously proposed greedy technique is coupled with linear optimization. This algorithm allows a fully adaptive on-the-fly data-dependent meshless selection of test and trial spaces. The new method satisfies the assumptions of the background theory, and numerical experiments demonstrate its stability. Kansa’s method, convergence, error bounds, linear optimization, <b>minimax</b> <b>algorithms...</b>|$|R
40|$|Optimization models {{related with}} routing, {{bandwidth}} utilization and power consumption are {{developed in the}} wireless mesh computing environment using the operations research techniques such as maximal flow model, transshipment model and <b>minimax</b> optimizing <b>algorithm.</b> The Path creation algorithm is used to find the multiple paths from source to destination. A multi-stage optimization model is developed by combining the multi-path optimization model, optimization model in capacity utilization and energy optimization model and <b>minimax</b> optimizing <b>algorithm.</b> The input to the multi-stage optimization model is a network with many source and destination. The optimal solution obtained from this model is a minimum energy consuming path from source to destination along with the maximum data rate over each link. The performance is evaluated by comparing the data rate values of superimposed <b>algorithm</b> and <b>minimax</b> optimizing <b>algorithm.</b> The main advantage of this model is the reduction of traffic congestion in the network...|$|R
5000|$|Type A {{programs}} {{would use a}} [...] "brute force" [...] approach, examining every possible position for a fixed number of moves using the <b>minimax</b> <b>algorithm.</b> Shannon believed this would be impractical for two reasons.|$|E
50|$|Algorithm {{optimizations}} for minimax {{are also}} equally applicable for Negamax. Alpha-beta pruning can decrease {{the number of}} nodes the negamax algorithm evaluates in a search tree {{in a manner similar}} with its use with the <b>minimax</b> <b>algorithm.</b>|$|E
50|$|Best Node Search is a minimax search algorithm, {{developed}} in 2011. Experiments with random trees {{show it to}} be the most efficient <b>minimax</b> <b>algorithm.</b> This algorithm does tell which move leads to minmax, but does not tell the evaluation of minimax.|$|E
40|$|Abstract—Optimization models {{related with}} routing, {{bandwidth}} utilization and power consumption are {{developed in the}} wireless mesh computing environment using the operations research techniques such as maximal flow model, transshipment model and <b>minimax</b> optimizing <b>algorithm.</b> The Path creation algorithm is used to find the multiple paths from source to destination. A multi-stage optimization model is developed by combining the multi-path optimization model, optimization model in capacity utilization and energy optimization model and <b>minimax</b> optimizing <b>algorithm.</b> The input to the multi-stage optimization model is a network with many source and destination. The optimal solution obtained from this model is a minimum energy consuming path from source to destination along with the maximum data rate over each link. The performance is evaluated by comparing the data rate values of superimposed <b>algorithm</b> and <b>minimax</b> optimizing <b>algorithm.</b> The main advantage of this model is the reduction of traffic congestion in the network. Keywords-optimization; breakthrough; transportation; aximization; superimposed; transshipment. I...|$|R
40|$|We {{investigate}} algorithms {{for playing}} multi-agent visibilitybased pursuit-evasion games. A team of pursuers attempts to maintain visibility {{contact with an}} evader who actively avoids tracking. We aim for applicability of the algorithms in real-world scenarios; hence, we impose hard constraints on the run-time of the algorithms and we evaluate them in a simulation model based on a real-world urban area. We compare Monte-Carlo tree search (MCTS) and iterative deepening <b>minimax</b> <b>algorithms</b> running on the informationset tree of the imperfect-information game. The experimental results demonstrate that both methods create comparable good strategies for the pursuer, while the later performs better in creating the evader’s strategy...|$|R
40|$|Of {{the many}} <b>minimax</b> <b>algorithms,</b> SSS* {{consistently}} searches the smallest game trees. Its {{success can be}} attributed to the accumulation and use of information acquired while traversing the tree, allowing a best first search strategy. The main disadvantage of SSS* is its excessive storage requirements. This paper describes a class of search algorithms which, though based on the popular alpha-beta algorithm, also acquire and use information to guide their search. They retain their directional nature yet are as good as SSS*, even while searching random trees. Further, while some of these new algorithms also require substantial storage, they are more flexible and can be programmed to use only the space available, at the cost of some degradation in performance...|$|R
50|$|The {{performance}} of the naïve <b>minimax</b> <b>algorithm</b> may be improved dramatically, without affecting the result, {{by the use of}} alpha-beta pruning.Other heuristic pruning methods can also be used, but not all of them are guaranteed to give the same result as the un-pruned search.|$|E
50|$|In {{competitive}} two-player games, {{the killer}} heuristic {{is a technique}} for improving the efficiency of alpha-beta pruning, which in turn improves {{the efficiency of the}} <b>minimax</b> <b>algorithm.</b> This algorithm has an exponential search time to find the optimal next move, so general methods for speeding it up are very useful.|$|E
5000|$|There {{are many}} ways to {{deliberately}} introduce poor decision-making in search algorithms. Take the <b>minimax</b> <b>algorithm</b> for example. The <b>minimax</b> <b>algorithm</b> is an adversarial search algorithm that is popularly used in games that require more than one player to compete against each other. The main purpose in this algorithm is to choose a move that maximizes your chance of winning and avoid moves that maximizes the chance of your opponent winning. An algorithm like this would be extremely beneficial to the computer as computers are able to search thousands of moves ahead. To [...] "dumb down" [...] this algorithm to allow for different difficulty levels, heuristic functions have to be tweaked. Normally, huge points are given in winning states. Tweaking the heuristic by reducing such big payoffs would reduce the chance of the algorithm in choosing the winning state.|$|E
40|$|In this paper, {{we propose}} a novel {{implementation}} of a minimax decision rule for continuous density hidden Markov-model-based robust speech recognition. By combining {{the idea of the}} minimax decision rule with a normal Viterbi search, we derive a recursive <b>minimax</b> search <b>algorithm,</b> where the <b>minimax</b> decision rule is repetitively applied to determine the partial paths during the search procedure. Because of the intrinsic nature of a recursive search, the proposed method can be easily extended to perform continuous speech recognition. Experimental results on Japanese isolated digits and TIDIGITS, where the mismatch between training and testing conditions is caused by additive white Gaussian noise, show the viability and efficiency of the proposed <b>minimax</b> search <b>algorithm.</b> published_or_final_versio...|$|R
40|$|Abstract—In this paper, {{we propose}} a novel {{implementation}} of a minimax decision rule for continuous density hidden Markov-model-based robust speech recognition. By combining {{the idea of the}} minimax decision rule with a normal Viterbi search, we de-rive a recursive <b>minimax</b> search <b>algorithm,</b> where the <b>minimax</b> de-cision rule is repetitively applied to determine the partial paths during the search procedure. Because of its intrinsic nature of a recursive search, the proposed method can be easily extended to perform continuous speech recognition. Experimental results on Japanese isolated digits and TIDIGITS, where the mismatch be-tween training and testing conditions is caused by additive white Gaussian noise, show the viability and efficiency of the proposed <b>minimax</b> search <b>algorithm.</b> Index Terms—Minimax rule, plug-in-MAP rule, robust decision rule, robust speech recognition. I...|$|R
40|$|Abstract In the {{theoretical}} {{part of this}} paper, we introduce a simplified proof technique for error bounds and convergence of a variation of E. Kansa's well-known unsymmetric meshless collocation method. For a numerical implementation of the convergent variation, a previously proposed greedy technique is coupled with linear optimization. This algorithm allows a fully adaptive on-the-fly data-dependent meshless selection of test and trial spaces. The new method satisfies the assumptions of the background theory, and numerical experiments demonstrate its stability. Kansa's method, convergence, error bounds, linear optimization, <b>minimax</b> <b>algorithms</b> 1 Introduction A general framework for solving PDE problems in strong or weak form by kernel- based meshless methods was outlined in [13]. It writes the PDE problem as uncountably many simultaneous scalar equation...|$|R
50|$|MTD(f), is a minimax search algorithm, {{developed}} in 1994 by Aske Plaat, Jonathan Schaeffer, Wim Pijls, and Arie de Bruin. Experiments with tournament-quality chess, checkers, and Othello programs {{show it to}} be the most efficient <b>minimax</b> <b>algorithm.</b> The name MTD(f) is an abbreviation for MTD(n,f) (Memory-enhanced Test Driver with node n and value f). It is an alternative to the alpha-beta pruning algorithm.|$|E
5000|$|A simple {{version of}} the <b>minimax</b> <b>algorithm,</b> stated below, deals with games such as tic-tac-toe, where each player can win, lose, or draw.If player A can win in one move, his best move is that winning move.If player B knows that one move {{will lead to the}} {{situation}} where player A can win in one move, while another move will lead to the situation where player A can, at best, draw, then player B's best move is the one leading to a draw.Late in the game, it's easy to see what the [...] "best" [...] move is.The <b>Minimax</b> <b>algorithm</b> helps find the best move, by working backwards {{from the end of the}} game. At each step it assumes that player A is trying to maximize the chances of A winning, while on the next turn player B is trying to minimize the chances of A winning (i.e., to maximize B's own chances of winning).|$|E
50|$|Since the <b>minimax</b> <b>algorithm</b> and its {{variants}} {{are inherently}} depth-first, a strategy such as iterative deepening is usually {{used in conjunction}} with alpha-beta so that a reasonably good move can be returned even if the algorithm is interrupted before it has finished execution. Another advantage of using iterative deepening is that searches at shallower depths give move-ordering hints, as well as shallow alpha and beta estimates, that both can help produce cutoffs for higher depth searches much earlier than would otherwise be possible.|$|E
40|$|<b>Minimax</b> <b>algorithms</b> {{for failure}} {{detection}} and identification for redundant noncolinear arrays of single-degree-of-freedom gyros and accelerometers are described. These algorithms are optimum {{in the sense}} that detection occurs as soon as it is no longer possible to account for the instrument outputs as the outputs of good instruments operating within their noise tolerances, and identification occurs as soon as it is true that only a particular instrument failure could account for the actual instrument outputs within the noise tolerance of good instruments. An estimation algorithm is described which minimizes the maximum possible estimation error magnitude for the given set of instrument outputs. Monte Carlo simulation results are presented for the application of the algorithms to an inertial reference unit consisting of six gyros and six accelerometers in two alternate configurations...|$|R
40|$|Lots of {{traditional}} games, {{but now the}} game is becoming obsolete. Many games were replaced with the modern game technology products. Modern games are becoming more practical {{because it did not}} require the terrain and many friends. Quite alone in front of the screen was a person may engage in an exciting game. One of the efforts to preserve and disseminate traditional games one of which is macan-macanan is to adapt the game into a computer game. This study aims to apply artificial intelligence using <b>minimax</b> <b>algorithms</b> and programming language ActionScript 3 in the game with a macan-macanan research methods are prototyping. The design used in this study is an artificial intelligence approach for representing the state, science, human computer interaction for designing the user experience, as well as the UML for object-based design. Results from this study is that {{in order to determine the}} value of the evaluation <b>algorithm</b> <b>minimax</b> for the end node / terminal state in the game macan-macanan, required the calculation of the total step is valid for each piece, as well as to pawn macan, necessary calculations springboard to a higher value and the weight difference the appropriate type of pawns...|$|R
40|$|In this paper, we {{introduce}} {{an efficient}} replanning algorithm for nondeterministic domains, namely {{what we believe}} to be the first incremental heuristic <b>minimax</b> search <b>algorithm.</b> We apply it to the dynamic discretization of continuous domains, resulting in an efficient implementation of the parti-game reinforcement-learning algorithm for control in high-dimensional domains. ...|$|R
