10000|10000|Public
5|$|Albert A. Bühlmann {{published}} Decompression–Decompression sickness in 1984. Bühlmann {{recognized the}} problems associated with altitude diving, and proposed a <b>method</b> <b>that</b> calculated maximum nitrogen loading in the tissues at a particular ambient pressure by modifying Haldane's allowable supersaturation ratios to increase linearly with depth.|$|E
5|$|Since August 31, 2010, {{third-party}} Twitter applications {{have been}} required to use OAuth, an authentication <b>method</b> <b>that</b> does not require users to enter their password into the authenticating application. This was done to increase security and improve the user experience.|$|E
5|$|Snow is an {{important}} consideration for loads on structures. To address these, European countries employ Eurocode 1: Actions on structures - Part 1-3: General actions - Snow loads. In North America, ASCE Minimum Design Loads for Buildings and Other Structures gives guidance on snow loads. Both standards employ <b>method</b> <b>that</b> translate maximum expected ground snow loads onto design loads for roofs.|$|E
50|$|Space mapping {{optimization}} {{belongs to}} the class of surrogate-based optimization <b>methods,</b> <b>that</b> is to say, optimization <b>methods</b> <b>that</b> rely on a surrogate model.|$|R
50|$|Traits both {{provide a}} set of <b>methods</b> <b>that</b> {{implement}} behaviour to a class, and require that the class implements {{a set of}} <b>methods</b> <b>that</b> parameterize the provided behaviour.|$|R
5000|$|A {{class has}} zero or more method {{modifiers}}. These modifiers {{can apply to}} its own <b>methods,</b> <b>methods</b> <b>that</b> are inherited from its ancestors or <b>methods</b> <b>that</b> are provided by roles.|$|R
5|$|The {{possibility}} also {{exists to}} apply newer {{techniques such as}} optically stimulated luminescence (OSL) testing to attempt to date any bricks, pottery, or other fired materials found in situ in the structure, a <b>method</b> <b>that</b> was successfully used {{in the identification of}} a suspected Roman road near Bayston Hill in Shropshire.|$|E
5|$|Al-Aqsa's dome {{is one of}} the few domes to be {{built in}} front of the mihrab during the Umayyad and Abbasid periods, the others being the Umayyad Mosque in Damascus (715) and the Great Mosque of Sousse (850). The {{interior}} of the dome is painted with 14th-century-era decorations. During the 1969 burning, the paintings were assumed to be irreparably lost, but were completely reconstructed using the trateggio technique, a <b>method</b> <b>that</b> uses fine vertical lines to distinguish reconstructed areas from original ones.|$|E
5|$|Another <b>method</b> <b>that</b> {{has been}} used to {{establish}} the date of eruption is tree-ring dating. Tree-ring data has shown that a large event interfering with normal tree growth in North America occurred during 1629–1628 (±65 years)BCE. Evidence of a climatic event around 1628BCE has been found in studies of growth depression of European oaks in Ireland and of Scotch pines in Sweden. Bristlecone pine frost rings also indicate a date of 1627BCE, supporting the late 1600sBCE dating. Procedural changes in how ice cores are interpreted would bring that data more in line with the dendrochronological numbers.|$|E
50|$|Reversal {{symmetry}} is {{a voting}} system criterion which requires that if candidate A is the unique winner, and each voter's individual preferences are inverted, then A {{must not be}} elected. <b>Methods</b> <b>that</b> satisfy reversal symmetry include Borda count, the Kemeny-Young method, and the Schulze <b>method.</b> <b>Methods</b> <b>that</b> fail include Bucklin voting, instant-runoff voting and Condorcet <b>methods</b> <b>that</b> fail the Condorcet loser criterion such as Minimax.|$|R
30|$|Learning from {{imbalanced}} data is {{a challenging}} task. Current methods to combat imbalanced data include data-level <b>methods</b> <b>that</b> modify {{the distribution of}} the data through either under sampling (removing majority instances) or over sampling (adding minority instances) and algorithm-level <b>methods</b> <b>that</b> tune existing learning algorithms to mitigate the bias towards the majority instances. Furthermore, hybrid <b>methods</b> <b>that</b> combine the approaches in the data-level and algorithm-level approaches are also used (Krawczyk 2016).|$|R
40|$|Constraints are a {{valuable}} tool for managing information across multiple databases, {{as well as for}} general purposes of assuring data integrity. However, efficient implementation of constraint checking is difficult. In this paper we explore techniques for assuring constraint satisfaction without performing a complete evaluation of the constraints. We consider <b>methods</b> <b>that</b> use only constraint definitions, <b>methods</b> <b>that</b> use constraints and updates, and <b>methods</b> <b>that</b> use constraints, updates, and "local" data...|$|R
5|$|Another <b>method</b> <b>that</b> {{is widely}} used in these {{analyses}} is mass spectrometry. Here, accurate measurement {{of the mass of}} the unmodified native enzyme and the inactivated enzyme gives the increase in mass caused by reaction with the inhibitor and shows the stoichiometry of the reaction. This is usually done using a MALDI-TOF mass spectrometer. In a complementary technique, peptide mass fingerprinting involves digestion of the native and modified protein with a protease such as trypsin. This will produce a set of peptides that can be analysed using a mass spectrometer. The peptide that changes in mass after reaction with the inhibitor will be the one that contains the site of modification.|$|E
5|$|Because of the {{resampled}} convolution <b>method</b> <b>that</b> {{they describe}} for computing a numerical approximation of the curve-shortening flow, they call their method the resampled curvature scale space. They observe that this scale space is invariant under Euclidean transformations of the given shape, and assert that it uniquely determines {{the shape and}} is robust against small variations in the shape. They compare it experimentally against several related alternative definitions of a scale space for shapes, and find that the resampled curvature scale space is less computationally intensive, more robust against nonuniform noise, and less strongly influenced by small-scale shape differences.|$|E
5|$|Carter and Frank Spotnitz wrote major {{parts of}} the script in Hawaii over Christmas 1996. They used the same <b>method</b> <b>that</b> they had used when writing episodes and {{sketching}} out scenes for the series on 3x5 index cards. By the time the Christmas break had ended, the whole narrative for the film had been written. Upon his return from Hawaii, Carter looked for spare time to write the script. He returned to Hawaii and in ten days wrote {{about half of the}} 124-page screenplay for the film.|$|E
30|$|These works can be {{classified}} into two types: <b>methods</b> <b>that</b> uses a single LRF and measures a person’s legs [23 – 27] and <b>methods</b> <b>that</b> combines measurements from multiple sensors, including multiple LRFs [28 – 30].|$|R
30|$|In Section 3, we {{analyze the}} BG <b>methods</b> <b>that</b> {{operate on the}} sole visible optical (standard video) sensor channel, individuating groups of <b>methods</b> <b>that</b> employ a single monocular camera, and {{approaches}} where multiple cameras are utilized.|$|R
40|$|We {{study the}} {{behavior}} of the ball measure of non-compactness under several interpolation methods. First we deal with <b>methods</b> <b>that</b> interpolate couples of spaces, and then we proceed to extend the results to <b>methods</b> <b>that</b> interpolate finite families of spaces. We will need an approximation hypothesis on the target family of spaces. We study {{the behavior of}} the ball measure of non-compactness under several interpolation methods. First we deal with <b>methods</b> <b>that</b> interpolate couples of spaces, and then we proceed to extend the results to <b>methods</b> <b>that</b> interpolate finite families of spaces. We will need an approximation hypothesis on the target family of spaces...|$|R
5|$|DX arrays {{have been}} made to form hollow {{nanotubes}} 4–20nm in diameter, essentially two-dimensional lattices which curve back upon themselves. These DNA nanotubes are somewhat similar in size and shape to carbon nanotubes, and while they lack the electrical conductance of carbon nanotubes, DNA nanotubes are more easily modified and connected to other structures. One of many schemes for constructing DNA nanotubes uses a lattice of curved DX tiles that curls around itself and closes into a tube. In an alternative <b>method</b> <b>that</b> allows the circumference to be specified in a simple, modular fashion using single-stranded tiles, the rigidity of the tube is an emergent property.|$|E
5|$|During the 1993 {{run for the}} {{national}} title, Smith used a <b>method</b> <b>that</b> was introduced to him {{at a conference in}} Switzerland. At the conference, Smith was presented a tape by a lecturer who used doctored images to achieve his goal of losing weight. The photos showed the lecturer what he would look like if he were thinner as motivation to reach his weight-loss goals. Smith took a picture of the scoreboard from the 1982 Championship, modified it to read 1993 and erased the name Georgetown, leaving that space blank. He proceeded to place copies of the doctored photo in all of the players' lockers.|$|E
5|$|Inexpensive {{powdered}} S.luteus fruit {{bodies are}} sometimes {{added to the}} more expensive B.edulis mushroom soup powder, a fraudulent practice {{that is difficult to}} detect with microscopy because the tissues are no longer intact. This adulteration can be determined chemically, however, by testing for increased levels of the sugar alcohols arabitol and mannitol. The practice can also be determined with a DNA-based <b>method</b> <b>that</b> is sensitive enough to detect the addition of 1–2% of S.luteus to B.edulis powder.|$|E
50|$|Before {{looking at}} the {{specific}} <b>methods,</b> <b>that</b> is, specific functions , there are some general concepts related to the <b>methods</b> <b>that</b> need to be explained. Which triangulation method is chosen for a particular problem depends to some extent on these characteristics.|$|R
40|$|This paper {{presents}} a literature review on <b>methods</b> <b>that</b> {{have been used}} {{in the last two decades}} to predict Stock Market Indexes. Methods studied range from those enabling to grab the linear characteristics present in the stock market indexes, going through those that focus on non-linear features and finally hybrid <b>methods</b> <b>that</b> are more robust, since they capture linear and non-linear features. In addition, this research includes <b>methods</b> <b>that</b> use macroeconomic variables to predict indexes from different stock exchanges around the world...|$|R
40|$|This chapter {{highlights}} the potential {{and variety of}} qualitative <b>methods</b> <b>that</b> {{can be applied to}} counselling and psychotherapy outcome research. The chapter’s main focus is on outlining the various forms of qualitative data collection <b>methods</b> <b>that</b> are available to researchers. This is followed by an overview of the various qualitative analysis <b>methods</b> <b>that</b> can be utilised for interpreting the data. Finally, the limitations of qualitative outcome research are discussed, including a number of approaches to evaluating the credibility of such research...|$|R
5|$|Instead of {{blurring}} and thresholding, {{this method}} can alternatively {{be described as}} applying a median filter with Gaussian weights to each pixel. It is possible to use kernels other than the heat kernel, or to adaptively refine the grid so that it has high resolution near the curve but does not waste time and memory on pixels far from the curve that do {{not contribute to the}} outcome. Instead of using only the two values in the pixelated image, a version of this <b>method</b> <b>that</b> uses an image whose pixel values represent the signed distance to the curve can achieve subpixel accuracy and require lower resolution.|$|E
5|$|Kepler-11 and its planets were {{discovered}} by NASA's Kepler Mission, a mission tasked with discovering planets in transit around their stars. The transit <b>method</b> <b>that</b> Kepler uses involves detecting dips in brightness in stars. These dips in brightness {{can be interpreted}} as planets whose orbits move in front of their stars from the perspective of Earth. Kepler-11 is the first discovered exoplanetary system with more than three transiting planets.|$|E
5|$|Palatography {{involves}} {{the painting of}} a colored substance onto the tongue which is then transferred onto the palate during articulation. A picture is then taken of the palate to record the location of contact and, if another palatogram is to be taken, the mouth is washed out and the tongue repainted. A particularly low cost <b>method</b> <b>that</b> is often used in fieldwork, {{it can be difficult}} to collect large amounts of data.|$|E
40|$|This paper {{presents}} {{a set of}} preliminary experiments which show that identifying translationese is possible with machine learning <b>methods</b> <b>that</b> work at character level, more precisely <b>methods</b> <b>that</b> use string kernels. But caution is necessary because string kernels very easily can introduce confounding factors. ...|$|R
50|$|This chapter lists {{procedures}} {{that may be}} omitted and under what circumstances. Tools and <b>methods</b> <b>that</b> can be excluded in cultivation and processing under abnormal conditions. Tea utensils and brewing <b>methods</b> <b>that</b> can be simplified or improvised under various outdoor and unusual habitat environments.|$|R
5000|$|An Abstract Class is a {{class that}} is incomplete, {{or to be}} {{considered}} incomplete.Normal classes may have abstract <b>methods,</b> <b>that</b> is, <b>methods</b> <b>that</b> are declared but not yet implemented, {{only if they are}} abstract classes.A class C has abstract methods if any of the following is true: ...|$|R
5|$|Rapid {{diagnosis}} and treatment are important {{in the care of}} TBI; if the injury is not diagnosed shortly after the injury, the risk of complications is higher. Bronchoscopy is the most effective method to diagnose, locate, and determine the severity of TBI, and it is usually the only <b>method</b> <b>that</b> allows a definitive diagnosis. Diagnosis with a flexible bronchoscope, which allows the injury to be visualized directly, is the fastest and most reliable technique. In people with TBI, bronchoscopy may reveal that the airway is torn, or that the airways are blocked by blood, or that a bronchus has collapsed, obscuring more distal (lower) bronchi from view.|$|E
5|$|Rhodes started {{teaching}} piano {{when he was}} 19. He dropped out of studying at the University of Southern California in 1929 to support his family through the Great Depression by full-time teaching. As a teacher, he designed a <b>method</b> <b>that</b> combined classical and jazz music, which became popular across the United States, and resulted in an hour-long nationally syndicated radio show. Rhodes continued to teach the piano through his lifetime, and the piano method continues to be taught today by {{a team led by}} Joseph Brandsetter.|$|E
5|$|The Bundled Measures Policy authorizes {{different}} factions {{within the}} state to collaborate on mitigation projects. This policy takes a more of a community-based approach by adding several groups {{for the purpose of}} multiple perspectives and inventive approaches. The Bundled Measures Policy is one <b>method</b> <b>that</b> generates co-benefits for both parties. In example, if a partaking business were to add cool roofs, there will be a reduction in greenhouse gases which is beneficial for the environment as well as the need for excess energy which is beneficial for the business.|$|E
50|$|There {{are several}} <b>methods</b> <b>that</b> can be used.|$|R
40|$|For {{classification}} {{problems with}} ordinal attributes very often the class attribute should increase with each {{or some of}} the explaining attributes. These are called classification problems with monotonicity constraints. Classical decision tree algorithms such as CART or C 4. 5 generally do not produce monotone trees, even if the dataset is completely monotone. This paper surveys the <b>methods</b> <b>that</b> have so far been proposed for generating decision trees that satisfy monotonicity constraints. A distinction is made between <b>methods</b> <b>that</b> work only for monotone datasets and <b>methods</b> <b>that</b> work for monotone and non-monotone datasets alike...|$|R
40|$|This paper {{provides}} an updated overview, {{intended to be}} of practical value to analysts, of <b>methods</b> <b>that</b> {{can be applied to}} minimize or control the build-up of near-surface electrical charge during electron-induced Auger electron spectroscopy (AES). Although well-developed methods can be highly effective, dealing with insulating or ungrounded samples for which high spatial resolution is needed remains a challenge. Examples of the application of methods involving low-energy ion sources and sample thinning using a focused ion beam that can allow high-resolution measurements on a variety of samples are highlighted. The physical bases of newer and traditional methods are simply described along with strengths and limitations of the methods. Summary tables indicate <b>methods</b> <b>that</b> can be applied to most AES spectrometers, <b>methods</b> <b>that</b> require special instrumental capabilities and <b>methods</b> <b>that</b> require special sample preparation or mounting...|$|R
