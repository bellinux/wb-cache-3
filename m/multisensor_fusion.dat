149|211|Public
40|$|<b>Multisensor</b> <b>fusion</b> and {{consensus}} filtering are two fascinating {{subjects in the}} research of sensor networks. In this survey, we will cover both classic results and recent advances developed in these two topics. First, we recall some important results {{in the development of}} <b>multisensor</b> <b>fusion</b> technology. Particularly, we pay great attention to the fusion with unknown correlations, which ubiquitously exist in most of distributed filtering problems. Next, we give a systematic review on several widely used consensus filtering approaches. Furthermore, some latest progress on <b>multisensor</b> <b>fusion</b> {{and consensus}} filtering is also presented. Finally, conclusions are drawn and several potential future research directions are outlined...|$|E
40|$|International audienceThis paper {{presents}} a multisensor and multitarget tracking architecture with objects eclipses. The architecture {{is composed of}} two sub-systems : a multitarget tracking for each sensor and a multitarget and <b>multisensor</b> <b>fusion</b> center. The multitarget tracking uses the Dempster-Shafer theory with proposed distributions of masses, that are functions of the distance between perceived objects and known objects, the sensor reliability and the perception uncertainty. The <b>multisensor</b> <b>fusion</b> {{is based on the}} Covariance Intersection algorithm...|$|E
40|$|Real-time {{condition}} monitoring and fault diagnosis for complex machine {{is a fairly}} problem. This paper presents a new general framework for <b>multisensor</b> <b>fusion</b> based on a distributed detection. Parallel processing and distributed <b>multisensor</b> <b>fusion,</b> as rapidly emerging and promising technologies, provides powerful tools for solving this difficult problem. The distribution and parallelism of proposing and confirming of hypotheses in condition and diagnostic is proposed. A combination serial and parallel configuration of n sensors for decision fusion is analyzed. Unlike a parallel fusion scheme which fuses data only when it receives all information from all sensors, this configuration does not require data from all sensors before fusion. This fusion process stops when the given level of confidence is reached. It shows the result for a real-time parallel distributed complex machine condition monitor and fault diagnostic system. Keywords: Distributed detection <b>Multisensor</b> <b>fusion</b> Fault Di [...] ...|$|E
40|$|Abstract: <b>Multisensor</b> image <b>fusion</b> is {{a process}} of {{combining}} or amalgamating information from multiple sensors. It has been applied {{to a wide variety of}} fields such as navigation, military surveillance, remote sensing, medical diagnosis, industrial process control and measurement, intelligent robot, and law enforcement. In this paper, the basic concept, advantage, general structure, methods, applications, and performance evaluation of <b>multisensor</b> image <b>fusion</b> are presented...|$|R
40|$|This paper {{deals with}} the {{solution}} to the problem of <b>multisensor</b> data <b>fusion</b> for a single target scenario as detected by an airborne track-while-scan radar. The details of a neural network implementation, various training algorithms based on standard backpropagation, and the results of training and testing the neural network are presented. The promising capabilities of RPROP algorithm for <b>multisensor</b> data <b>fusion</b> for various parameters are shown in comparison to other adaptive technique...|$|R
40|$|Next {{generation}} cyberspace {{intrusion detection}} systems will fuse data from heterogeneous distributed network sensors to create cyberspace situational awareness. This paper provides a few first steps toward developing the engineering requirements using {{the art and}} science of <b>multisensor</b> data <b>fusion</b> as the underlying model. Current generation internet-based intrusion detection systems and basic <b>multisensor</b> data <b>fusion</b> constructs are summarized. The TCP/IP model is used to develop framework sensor and database models. The SNMP ASN. 1 MIB construct is recommended for the representation of context-dependent threa...|$|R
40|$|International audienceThis article {{presents}} a <b>multisensor</b> <b>fusion</b> strategy for a novel road-matching method designed to support real-time navigational features within advanced driver assistance systems. In road navigation, context, integrity, reliability and accuracy are essential qualities for road-matching methods. Particularly, managing multihypotheses {{is a useful}} strategy to treat ambiguous situations in the road-matching task. In this study, <b>multisensor</b> <b>fusion</b> and multimodal estimation are realized using a hybrid Bayesian network. To manage multihypothesis, multimodal estimation is proposed. Experimental results, using data from antilock braking system sensors, a {{differential global positioning system}} receiver, and an accurate digital roadmap illustrate the performance of the proposed approach, especially in ambiguous situations...|$|E
40|$|Bayesian-filter {{techniques}} {{provide a}} powerful statistical tool to help manage measurement uncertainty and perform <b>multisensor</b> <b>fusion</b> and identity estimation. The authors survey Bayes filter implementations and show their application to real-world location-estimation tasks common in pervasive computing...|$|E
40|$|In this paper, a <b>multisensor</b> <b>fusion</b> fault {{tolerant}} control system with fault detection and identification via set separation is presented. The fault detection and identification unit verifies that for each sensorâ€“estimator combination, the estimation tracking errors lie inside pre-computed sets and discards faulty sensors when their associated estimation tracking errors leave the sets. An active {{fault tolerant}} controller is obtained, where the remaining healthy estimates are combined using a technique {{based on the}} optimal fusion criterion in the linear minimum-variance sense. The fused estimates are then used to implement a state feedback tracking controller. We ensure closed-loop stability and performance under the occurrence of abrupt sensor faults. Experimental validation, illustrating the <b>multisensor</b> <b>fusion</b> fault tolerant control strategy is included...|$|E
40|$|This paper {{presents}} an integrated model aimed at obtaining robust and reliable results in decision level <b>multisensor</b> data <b>fusion</b> applications. The proposed model {{is based on}} the connection of Dempster-Shafer evidence theory and an extreme learning machine. It includes three main improvement aspects: a mass constructing algorithm to build reasonable basic belief assignments (BBAs); an evidence synthesis method to get a comprehensive BBA for an information source from several mass functions or experts; and a new way to make high-precision decisions based on an extreme learning machine (ELM). Compared to some universal classification methods, the proposed one can be directly applied in <b>multisensor</b> data <b>fusion</b> applications, but not only for conventional classifications. Experimental results demonstrate that the proposed model is able to yield robust and reliable results in <b>multisensor</b> data <b>fusion</b> problems. In addition, this paper also draws some meaningful conclusions, which have significant implications for future studies...|$|R
40|$|This paper {{presents}} {{the theory and}} formalism of fuzzy causal probabilistic networks (FCPN) and show their current and potential applications in <b>multisensor</b> data <b>fusion.</b> A fuzzy causal probabilistic network (FCPN) is a directed acyclic graph representing the joint probability distributions {{of a set of}} fuzzy random variables describing a problem domain. FCPNs extend causal probabilistic networks (CPN), also called Bayesian networks, belief networks, or influence diagrams, by associating each discrete variable with a fuzzifier and a defuzzifier, if required. A fuzzifier converts a crisp variable to a fuzzy discrete variable while a defuzzifier does the inverse. FCPNs provide a high-level generic architecture for fusing data incoming from multiple sensors. The paper also provides an overview on the field of <b>multisensor</b> data <b>fusion.</b> Airborne early warning and control using multiple sensors is studied to showcase the theory of FCPNs and their applications for <b>multisensor</b> data <b>fusion.</b> Key [...] ...|$|R
40|$|Abstract- The art {{and science}} of <b>multisensor</b> data <b>fusion</b> is the {{emerging}} foundation {{for the development of}} next generation network-centric decision support systems, including critical infrastructure protection. These challenging technical objectives require the cooperative signal processing of a federation of critical infrastructures. Publish-subscribe architectures provide process-to-process messaging infrastructures that enable a communications framework for the distribution and delivery of information between sensor fusion processes. In this paper we discuss high level service-oriented architectural issues for critical infrastructure <b>multisensor</b> data <b>fusion</b> including event notification services, wide-area network topology, and the publish-subscribe subscription language...|$|R
40|$|AbstractPath {{following}} is difficult when the observation rate is low. Multiple model estimators incorporating <b>multisensor</b> <b>fusion</b> have proven useful in this application. This paper shows {{the advantage of}} a recently developed multiple model algorithm. Performance comparisons with some current algorithms are presented...|$|E
40|$|<b>Multisensor</b> <b>fusion</b> is {{becoming}} increasingly important in intelligent computer vision systems. In this paper we present the generalized fuzzy integral with respect to an S-decomposable measure {{as a tool for}} fusing information from multiple sensors in an object recognition problem. Results from an experiment with automatic target recognition imagery are provided...|$|E
40|$|This {{paper is}} devoted to the control problem of a robot {{manipulator}} for a class of constrained motions in an unknown environment. To accomplish a task in the presence of uncertainties, we propose a new guidance and control strategy based on <b>multisensor</b> <b>fusion.</b> Three different sensors-robot joint encoders, a wrist force-torque sensor and a vision system-are utilized for our task. First of all, a sensor-based hybrid position/force control scheme is proposed for an unknown contact surface. Secondly, a new <b>multisensor</b> <b>fusion</b> scheme is utilized to handle an uncalibrated workcell, wherein the surface on which there is a path to be followed by a robot is assumed to be unknown but visible by the vision system and the precise position and orientation of camera(s) with respect to the base frame of the robot is also assumed to be unknown. Our work is related with areas such as visual servoing, <b>multisensor</b> <b>fusion</b> and robot control for constrained motion. The main features of the proposed approach are: (i) multi-sensor fusion is used both for two disparate sensors (i. e. force-torque and visual sensors) and for complementary observed data rather than redundant ones as in traditional way; (ii) visual servoing is realized on the tangent space of the unknown surface; (iii) calibration of the camera with respect to the robot is not needed. Link_to_subscribed_fulltex...|$|E
40|$|Data {{provided}} by sensors is always subjected to {{some level of}} uncertainty and inconsistency. <b>Multisensor</b> data <b>fusion</b> algorithms reduce the uncertainty by combining data from several sources. However, if these several sources provide inconsistent data, catastrophic fusion may occur where the performance of <b>multisensor</b> data <b>fusion</b> is {{significantly lower than the}} performance of each of the individual sensor. This paper presents an approach to <b>multisensor</b> data <b>fusion</b> in order to decrease data uncertainty with ability to identify and handle inconsistency. The proposed approach relies on combining a modified Bayesian fusion algorithm with Kalman filtering. Three different approaches, namely, prefiltering, postfiltering and pre-postfiltering are described based on how filtering is applied to the sensor data, to the fused data or both. A case study to find the position of a mobile robot by estimating its x and y coordinates using four sensors is presented. The simulations show that combining fusion with filtering helps in handling the problem of uncertainty and inconsistency of the data...|$|R
40|$|The {{paradigm}} of <b>multisensor</b> data <b>fusion</b> has been {{evolved from a}} centralized architecture to a decentralized or distributed architecture along with the advancement in sensor and communication technologies. These days, distributed state estimation and data fusion has been widely explored in diverse fields of engineering and control due to its superior performance over the centralized one in terms of flexibility, robustness to failure and cost effectiveness in infrastructure and communication. However, distributed <b>multisensor</b> data <b>fusion</b> is not without technical challenges to overcome: namely, dealing with cross-correlation and inconsistency among state estimates and sensor data. In this paper, we review the key theories and methodologies of distributed <b>multisensor</b> data <b>fusion</b> available to date with a specific focus on handling unknown correlation and data inconsistency. We aim at providing readers with a unifying view out of individual theories and methodologies by presenting a formal analysis of their implications. Finally, several directions of future research are highlighted...|$|R
40|$|The <b>multisensor</b> {{information}} <b>fusion</b> is a {{key issue}} for multisensor system. One of its difficulties lies in the switching {{of the state of}} sensor clusters. That is, which direction should the sensor information been fused into at a given moment? An algorithm of <b>multisensor</b> information <b>fusion</b> based on rough set and neural network was proposed in this paper. Firstly, the typical clustering distributions of 54 sensors within one day were regarded as sample space. The rough set was used for access of knowledge to make the decision table of the "data - fusion distribution". Next, the redundant properties and samples of information in one month were removed using the method of knowledge reduction of rough set. Then, the neural network was applied for clustering and analyzing to form the distribution rules of <b>multisensor</b> information <b>fusion.</b> Finally, the rough neural fusion algorithm, the neural quotient space fusion algorithm and word computing fusion algorithm are simulated and analyzed. The results show that the model and algorithm proposed in the paper are efficient in classification and rapid in sensor clustering distribution decide. </p...|$|R
40|$|This paper {{describes}} {{the integration of}} a primary radarsensor within the <b>multisensor</b> <b>fusion</b> an Advanced-Surface Movement Guidance and Control System (A-SMGCS). All values for a traffic situation report are derived purely from range measurements. Fundamental aspects {{to be considered for}} the integration within the sensor data fusion are discussed and results from field tests are presented...|$|E
40|$|This paper {{presents}} a <b>multisensor</b> <b>fusion</b> framework for video activities recognition based on statistical reasoning and D-S evidence theory. Precisely, the framework consists in {{the combination of}} the events â€™ uncertainty computation with the trained database and the fusion method based on the conflict management of evidences. Our framework aims to build <b>Multisensor</b> <b>fusion</b> architecture for event recognition by combining sensors, dealing with conflicting recognition, and improving their performance. According to a complex eventâ€™s hierarchy, Primitive state is chosen as our target event in the framework. A RGB camera and a RGB-D camera are used to recognise a personâ€™s basic activities in the scene. The main convenience of the proposed framework is that it firstly allows adding easily more possible events into the system with a complete structure for handling uncertainty. And secondly, the inference of Dempster-Shafer theory resembles human perception and fits for uncertainty and conflict management with incomplete information. The cross-validation of real-world data (10 persons) is carried out using the proposed framework, and the evaluation shows promising results that the fusion approach has an average sensitivity of 93. 31 % and an average precision of 86. 7 %. These results are better than the ones when only one camera is used, encouraging further research focusing on the combination of more sensors with more events, as well as the optimization of the parameters in the framework for improvements. KEY WORDS object recognition and motion, architecture and implementation, <b>Multisensor</b> <b>fusion,</b> event recognition, Evidence theor...|$|E
40|$|This paper {{describes}} {{the application of}} statistical estimation and <b>multisensor</b> <b>fusion</b> techniques to the detection, classication and localisation of targets with unattended ground sensors (UGS). Data have been collected for personnel and vehicles moving near a seismic sensor, and processed to allow two features to be obtained. An EM algorithm is used to estimate parameters of a Gaussian mixture model representing the signal data, resulting in improved detection and classication compared to the sensor's built-in algorithm. A design is given for <b>multisensor</b> <b>fusion</b> {{of a set of}} UGS sensors, in which multiple detections by a single sensor are used to estimate the closest distance of the target to the sensor, based on an assumption about the target speed, and these estimates are associated to a set of predened trajectories which the target is assumed to follow. A multiple hypothesis scheme is used to update the probabilities of the trajectories as the target moves past the sensors through [...] ...|$|E
50|$|In {{computer}} vision, <b>Multisensor</b> Image <b>fusion</b> is {{the process}} of combining relevant information from two or more images into a single image. The resulting image will be more informative than any of the input images.|$|R
40|$|Abstract â€“ Artificial neural {{networks}} (ANNs), support vector machines (SVMs) and naive Bayes classifiers (NBCs) are common tools for <b>multisensor</b> data <b>fusion</b> applications. In this paper ANN, SVM and NBC {{are applied to}} embed-ded realtime feature fusion and compared to different algo-rithms concerning classification execution {{time as well as}} classification rate. These algorithms are implemented on our three-layered <b>multisensor</b> data <b>fusion</b> architecture and applied to traffic monitoring where we are focusing on fus-ing data originating from distributed acoustic, image and laser sensors for vehicle classification and tracking. The evaluation of the algorithms is performed on our em-bedded platform and has shown promising results concern-ing realtime classification execution time and classification rate...|$|R
40|$|Contents Acknowledgments ix 1 Introduction 1 2 Intrusion Detection Systems 5 2. 1 Information Security........................ 5 2. 2 Intrusion Detection and its Problems............... 7 2. 3 Cooperating IDSs.......................... 10 2. 3. 1 Interoperability....................... 10 2. 3. 2 Intelligent Attack Analysis and Data Fusion...... 11 2. 4 Evaluation and Thesis Goal.................... 15 2. 5 Summary............................... 16 3 <b>Multisensor</b> Data <b>Fusion</b> 19 3. 1 History of <b>Multisensor</b> Data <b>Fusion................</b> 19 3. 2 The JDL Functional Data Fusion Process Model........ 20 3. 3 Antony's Biologically Motivated Fusion Process Model..... 24 3. 4 Data Fusion Architectures..................... 26 3. 5 Development of a Data Fusion System.............. 29 v vi CONTENTS 3. 6 Sum...|$|R
40|$|The present conference {{discusses}} {{topics in}} {{the fusion of}} active and passive sensors, object estimation and verification, three-dimensional representation and knowledge integration, three-dimensional perception from multisensor data, the representation of uncertainty in <b>multisensor</b> <b>fusion,</b> and sensor calibration and registration. Also discussed are the areas of multisensor target detection and classification, multisensor processing architectures, knowledge structures and spatial reasoning, sensory interfaces to telerobotic systems, and navigation with spatial data bases...|$|E
40|$|With the {{evolution}} of computer and fusion algorithms, data fusion systems have been applied to many areas, both in civilian and military fields. In the past, in the <b>multisensor</b> <b>fusion</b> community, the research goal has been primarily focused on establishing a computational approach for fusion processing and algorithms. However, {{it will be very}} useful to be able to characterize the relationship between sensed information inputs available to the fusion system and the quality of fused information output. This will not only help us understand the fusion system performance but also provide high level performance bounds given sensor mix and quality for system control such as sensor resource allocation and estimate information requirements. This paper presents a fusion performance model (FPM) for a general <b>multisensor</b> <b>fusion</b> system. The model includes both kinematics and classification component and focuses on the two performance measures: positional error and classification error. The performance model is based on the Bayesian theory and a combination of simulation and analytical approaches. Simulation results that validate the analytical performance predictions are also included...|$|E
40|$|Abstract. Pyroelectric {{infrared}} (PIR) sensors {{can detect}} {{the presence of}} human without the need to carry any device, which are widely used for human presence detection in home/office automation systems {{in order to improve}} energy efficiency. However, PIR detection is based on the movement of occupants. For occupancy detection, PIR sensors have inherent limitation when occupants remain relatively still. <b>Multisensor</b> <b>fusion</b> technology takes advantage of redundant, complementary, or more timely information from different modal sensors, which is considered an effective approach for solving the uncertainty and unreliability problems of sensing. In this paper, we proposed a simple multimodal sensor fusion algorithm, which is very suitable to be manipulated by the sensor nodes of wireless sensor networks. The inference algorithm was evaluated for the sensor detection accuracy and compared to the <b>multisensor</b> <b>fusion</b> using dynamic Bayesian networks. The experimental results showed that a detection accuracy of 97 % in room occupancy can be achieved. The accuracy of occupancy detection is very close to that of the dynamic Bayesian networks...|$|E
40|$|<b>Multisensor</b> data <b>fusion</b> has {{attracted}} {{a lot of research}} in recent years. It has been widely used in many applications especially military applications for target tracking and identification. In this paper, we will handle the <b>multisensor</b> data <b>fusion</b> problem for systems suffering from the possibility of missing measurements. We present the optimal recursive fusion filter for measurements obtained from two sensors subject to random intermittent measurements. The noise covariance in the observation process is allowed to be singular which requires the use of generalized inverse. Illustration example shows the effectiveness of the proposed filter in the measurements loss case compared to the available optimal linear fusion methods. <br /...|$|R
40|$|Abstract:- In {{this paper}} {{we examine the}} {{comparative}} use {{of different types of}} wavelets for Quickbird <b>multisensor</b> image <b>fusion,</b> for the purposes of high-resolution urban mapping. Based on the Discrete Wavelet Transform, several types of standard wavelets were implemented and evaluated. The best wavelet fusion results were combined with the IHS image fusion method using two types of colour composites. The IHS image fusion method was also implemented. The crossbred wavelet and IHS transform provides the most accurate colour representation of the spectral information of the initial bands, improving also their spatial resolution. Based on the results of the evaluation, a high-resolution fusion-based map of Heraclion, Crete was produced. Key-Words:- <b>Multisensor</b> image <b>fusion,</b> High resolution mapping, Wavelets, IHS transform 1...|$|R
40|$|Rosana G. Moreira, Editor-in-Chief; Texas A&M UniversityThis is a {{paper from}} International Commission of Agricultural Engineering (CIGR, Commission Internationale du Genie Rural) E-Journal Volume 9 (2007) : <b>Multisensor</b> Data <b>Fusion</b> Implementation for a Sensor Based Fertilizer Application System. Manuscript ATOE 07 010. Vol. IX. July, 2007...|$|R
40|$|This paper {{presents}} <b>multisensor</b> <b>fusion</b> {{techniques for}} {{the acquisition of}} the profile of surfaces with minimum error using low cost sensors ultrasonic sensors. These surfaces are composed by areas with different depths, corners and specular surfaces. To minimize the constraints of sonar sensors, it was developed dedicated software and hardware, {{as well as an}} empirical model was obtained from real data. This model is based in two proposed concepts: Points of Constant Depth (PCD) and Areas of Constant Depth (ACD). Having this sonar model in mind, four <b>multisensor</b> <b>fusion</b> techniques are used separately to validate the PCDs and decide the ACDs: average and variance, fuzzy controller and heuristic method based in rules. In this work a PUMA 560 manipulator was equipped with a CCD video camera and four ultrasonic sensors on the wrist, to acquire data for internally representation of the geometry of the partâ€™s surface, exploiting the mobility of the robot. The CCD camera view defines the working area while the ultrasonic sensors enable the acquisition of the surface profile...|$|E
40|$|This thesis proposes {{an entropy}} based Markov chain (EMC) fusion {{technique}} and demon-strates its applications in <b>multisensor</b> <b>fusion.</b> <b>Multisensor</b> <b>fusion</b> {{is a science}} in studying the methods for combining multiple sensory observations into a consensus output such that classification and estimation accuracy can be improved by reducing the measurement uncertainty. The consensus output can be either (a) one of the possible classes for the classification problem, or (b) a random variable for the parameter estimation problem. In recent years, {{a great deal of}} interests in <b>multisensor</b> <b>fusion</b> has been aroused in the fields of robotics, computer vision, remote sensing and medical imaging because of the general belief that multiple observations can help lower the uncertainty level, which can hardly be achieved by any individual observation. Therefore, a number of context dependent <b>multisensor</b> <b>fusion</b> techniques have been proposed recently. The most widely used measure of uncertainty, which is expressed in terms of the probabilistic function, is Shannon's entropy. It was originally employed in the measurement of randomness which in turn can be interpreted as the measurement of uncertainty. Self-emropy and conditional entropy, which measure how uncertain a sensor is about its own observation and joint observations respectively, are adopted. Markov chain has been used as an observation combination process because of two major reasons: (a) the consensus output is a linear combination of the weighted local observations which greatly simplifies the observation combination process; and (b) the weight is the transition probability assigned by one sensor to another sensor and can be intuitively related to the single observation distribution and the joint observation distribution between two sensors. Higher order distributions are not necessary. Because of these reasons, the Markov chain is employed. Experiments have been done to implement the entropy based Markov chain (EMC) fusion technique. The results show that the proposed approach can reduce the measurement uncertainty by aggregating multiple observations. The major benefits of this approach are as follows: (a) single observation distributions and joint observation distributions between any two sensors, which represent the interrelations between the sensory observations and the consensus output, can be represented in polynomial form, (b) the consensus output is the linear combination of the weighted observations, in which weights can be computed in polynomial time and (c) EMC is robust because it suppresses the noisy observation with high uncertainty level to minimize the contribution of the noisy and unreliable observations in the combination process...|$|E
30|$|Although all {{approaches}} {{already mentioned}} use {{the hypothesis of}} Gaussian additive noise for mathematical convenience, in practice, remote sensing imagery noise shows non-Gaussian characteristics [84]. In some applications, such as astronomical image restoration, Poisson noise is usually used, or a shaping filter [85] {{may be used in}} order to transform non-Gaussian noise into Gaussian. Recently, Niu et al.[84] proposed the use of a mixture of Gaussian (MoG) noise for <b>multisensor</b> <b>fusion</b> problems.|$|E
40|$|Abstract: A {{difficulty}} of <b>multisensor</b> data <b>fusion</b> {{lies in the}} switching {{of the state of}} sensor clusters. That is, which direction should the sensor data been fused into at a given moment? In this paper, firstly, the rough set was used for access of knowledge. The typical clustering distributions of 54 sensors within one day were regarded as sample space for the decision-making table of the "data-fusion distribution". Next, based on the method of knowledge reduction using rough set, the redundant properties and samples of data in one month were removed. Then, the ART 2 network was applied for clustering and analyzing, and the distribution rules of <b>multisensor</b> data <b>fusion</b> are formed. The experiment results show that the model is efficient in classification and rapid in sensor clustering distribution decide. 1...|$|R
40|$|The <b>multisensor</b> {{information}} <b>fusion</b> {{technology is}} adopted for real time measuring the four parameters which are connected {{closely with the}} weld nugget size (welding current, electrode displacement, dynamic resistance, welding time), thus much more original information is obtained. In this way, the difficulty caused by measuring indirectly weld nugget size can be decreased in spot welding quality control, and the stability of spot welding quality can be improved. According to this method, two-dimensional fuzzy controllers are designed with the information fusion result as input and the thyristor control signal as output. The spot welding experimental {{results indicate that the}} spot welding quality intelligent control method based on <b>multisensor</b> information <b>fusion</b> technology can compensate the influence caused by variable factors in welding process and ensure the stability of welding quality. link_to_subscribed_fulltex...|$|R
40|$|The {{number of}} {{perception}} sensors on automated vehicles increases {{due to the}} increasing number of advanced driver assistance system functions and their increasing complexity. Furthermore, fail-safe systems require redundancy, thereby increasing the number of sensors even further. A one-size-fits-all <b>multisensor</b> data <b>fusion</b> architecture is not realistic due to the enormous diversity in vehicles, sensors and applications. As an alternative, this work presents a methodology {{that can be used to}} effectively come up with an implementation to build a consistent model of a vehicleâ€™s surroundings. The methodology is accompanied by a software architecture. This combination minimizes the effort required to update the <b>multisensor</b> data <b>fusion</b> system whenever sensors or applications are added or replaced. A series of real-world experiments involving different sensors and algorithms demonstrates the methodology and the software architecture...|$|R
