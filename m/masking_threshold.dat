120|228|Public
5000|$|The MPEG audio {{encoding}} process leverages the <b>masking</b> <b>threshold.</b> In this process, {{there is}} a block called [...] "Psychoacoustic model". This is communicated with the band filter and the quantify block. The psychoacoustic model analyzes the samples sent to it by the filter band, computing the <b>masking</b> <b>threshold</b> in each frequency band using a Fast Fourier transform. The number of points used depends upon the MPEG layer. Using these thresholds, the signal-to-mask ratio is determined {{and sent to the}} quantifier. The quantifier assigns more or less bits in each block based upon the SMR. The block with the highest SMR will encode with the maximum number of bits.|$|E
50|$|It is {{uncommon}} {{to work with}} only one tone. Most sounds are composed of multiple tones. There can be many possible maskers at the same frequency. In this situation, {{it would be necessary}} to compute the global <b>masking</b> <b>threshold</b> using a high resolution Fast Fourier transform via 512 or 1024 points to determine the frequencies that comprise the sound. Because there are bandwidths that humans are not able to hear, it is necessary to know the signal level, masker type, and the frequency band before computing the individual thresholds. To avoid having the <b>masking</b> <b>threshold</b> under the threshold in quiet, one adds the last one to the computation of partial thresholds. This allows computation of the signal-to-mask ratio (SMR).|$|E
5000|$|The <b>masking</b> <b>threshold</b> is {{the sound}} {{pressure}} level of a sound {{needed to make the}} sound audible in the presence of another noise called a [...] "masker". This threshold depends upon the frequency, the type of masker, and the kind of sound being masked. The effect is strongest between two sounds close in frequency.|$|E
40|$|A {{psychoacoustic model}} which approximates the <b>masked</b> <b>threshold</b> evoked by complex sounds is presented. It {{features}} nonlinear superposition of masking components {{in order to}} generate <b>masked</b> <b>thresholds</b> which closely match known psychoacoustic data. First results obtained with the psychoacoustic model for controlling the quantizers of the ISO MPEG Layer 3 coder are discussed. 1 Introduction Significant improvements of high quality audio bit rate reduction have been achieved by considering {{the properties of the}} human auditory perception. This is generally realized by the introduction of a psychoacoustic model which generates the <b>masked</b> <b>threshold</b> evoked by a sound signal and which controls the quantizers of a coding system. The <b>masked</b> <b>threshold</b> for quantization errors is defined as the maximum level of quantization noise which is just non audible {{in the presence of a}} masking sound. Therefore, the quantization noise will only become audible if the level exceeds the <b>masked</b> <b>threshold.</b> Bit rate [...] ...|$|R
40|$|This paper {{examines}} how <b>masked</b> <b>thresholds</b> {{depend on the}} masker bandwidth and center frequency when the masker has a smaller bandwidth than the signal. The signal bandwidth was equal to the equivalent rectangular bandwidth of the auditory filter and the masker bandwidth was 0. 1, 0. 35, or 0. 6 times the signal bandwidth. The masker and signal were centered at the same frequency of 257, 697, 1538, 3142, or 6930 Hz. <b>Masked</b> <b>thresholds</b> were estimated using a two-interval two-alternative forced-choice paradigm and a three-down one-up adaptive staircase method. <b>Masked</b> <b>thresholds</b> increased with increasing masker bandwidth and were lowest for medium center frequencies...|$|R
5000|$|The {{input signal}} is {{decomposed}} into subsampled spectral components. For each sample an {{estimation of the}} actual <b>masked</b> <b>threshold</b> is derived using rules known from psychoacoustics. This is the perceptual model of the encoding system. The spectral components are quantized and coded keeping the quantization noise below the <b>masked</b> <b>threshold.</b> Finally is formed the bitstream.|$|R
5000|$|... #Caption: The {{spectrum}} of a 1 kHz tone. A sound {{will not be}} heard if it is under the threshold in quiet.This limit changes around the masker frequency, {{making it more difficult}} to hear a nearby tone. The slope of the <b>masking</b> <b>threshold</b> is steeper toward lower frequencies than toward higher frequencies, which means it is easier to mask with higher frequency tones.|$|E
50|$|Layer II's 1024 point FFT doesn't entirely {{cover all}} samples, and would omit several entire MP3 sub-bands, where {{quantization}} factors must be determined. MP3 instead uses two passes of FFT analysis for spectral estimation, {{to calculate the}} global and individual masking thresholds. This allows it to cover all 1152 samples. Of the two, it utilizes the global <b>masking</b> <b>threshold</b> level from the more critical pass, with the most difficult audio.|$|E
50|$|The {{utility of}} SBC {{is perhaps best}} {{illustrated}} with a specific example. When used for audio compression, SBC exploits auditory masking in the human auditory system. Human ears are normally sensitive {{to a wide range}} of frequencies, but when a sufficiently loud signal is present at one frequency, the ear will not hear weaker signals at nearby frequencies. We say that the louder signal masks the softer ones. The louder signal is called the masker, and the point at which masking occurs is known as the <b>masking</b> <b>threshold.</b>|$|E
40|$|The maske {{threshold}} of short (≤ 40 ms) probe tone or a short one-third octave probe noise appears to increase if {{the frequency of}} a tonal masker is swept. Frequency sweeps were exponential (octaves/s) and unidirectional. Probe sounds were presented in the time center of the masker at the center frequency of the masker. The sweep speed, S, {{appeared to be an}} important parameter; masker duration was much less important. For 10 -ms tonal probes, in-phase with the masker in their common time center, 100 -ms maskers, and upward sweeps, increase of the <b>masked</b> <b>threshold</b> appeared to be maximal at a sweep speed of 30 oct/s and the <b>masked</b> <b>threshold</b> was 21 dB higher than the <b>masked</b> <b>threshold</b> found for the stationary masker (S = 0 oct/s). Above 30 oct/s the <b>masked</b> <b>threshold</b> decreased. For downward sweeps masking was maximal at S = 20 oct/s and the threshold was 15 dB higher. Sweeping upward the increase in masking was 12 dB for both noise probes and tonal probes with phase differing by 90 ° from the masker in their common time center. The results are inconsistent with current models of masking: sweeping the frequency the <b>masked</b> <b>threshold</b> increases whereas the energy within the critical band at the probe frequency decreases...|$|R
50|$|Similar to {{simultaneous}} masking, temporal masking {{reveals the}} frequency analysis {{performed by the}} auditory system; forward <b>masking</b> <b>thresholds</b> for complex harmonic tones (e.g., a sawtooth probe with a fundamental frequency of 500 Hz) exhibit threshold peaks (i.e., high masking levels) for frequency bands centered on the first several harmonics. In fact, auditory bandwidths measured from forward <b>masking</b> <b>thresholds</b> are narrower and more accurate than those measured using simultaneous masking.|$|R
3000|$|For amplitude-based masking, a soft mask {{according}} to (14) and (16) was used. Thus, {{there are two}} parameters, the <b>mask</b> <b>threshold</b> [...]...|$|R
50|$|The {{psychoacoustic model}} is applied using a 1024-point Fast Fourier Transform (FFT). Of the 1152 samples per frame, 64 samples {{at the top}} and bottom of the {{frequency}} range are ignored for this analysis. They are presumably not significant enough to change the result. The psychoacoustic model uses an empirically determined masking model to determine which sub-bands contribute more to the <b>masking</b> <b>threshold,</b> and how much quantization noise each can contain without being perceived. Any sounds below the absolute threshold of hearing (ATH) are completely discarded. The available bits are then assigned to each sub-band accordingly.|$|E
50|$|To enable {{higher quality}} compression, one may use subband coding. First, a digital filter bank divides the input signal {{spectrum}} into some number (e.g., 32) of subbands. The psychoacoustic model {{looks at the}} energy {{in each of these}} subbands, {{as well as in the}} original signal, and computes masking thresholds using psychoacoustic information. Each of the subband samples is quantized and encoded so as to keep the quantization noise below the dynamically computed <b>masking</b> <b>threshold.</b> The final step is to format all these quantized samples into groups of data called frames, to facilitate eventual playback by a decoder.|$|E
3000|$|... {{denotes the}} <b>masking</b> <b>threshold</b> density of {{original}} signals which is computed in each scale factor band. The modified PE and the <b>masking</b> <b>threshold</b> are utilized for the quantization and encoding process [16].|$|E
5000|$|... {{is there}} an {{auditory}} event? Is a certain sound noticeable? => Determination of perception thresholds like hearing <b>threshold,</b> auditory <b>masking</b> <b>thresholds</b> etc.|$|R
5000|$|Psychoacoustic tuning curves can be {{measured}} using the notched-noise method. This form of measurement can take {{a considerable amount of}} time and can take around 30 minutes to find each <b>masked</b> <b>threshold.</b> [...] In the notched-noise method the subject is presented with a notched noise as the masker and a sinusoid (pure tone) as the signal. Notched noise is used as a masker to prevent the subject hearing beats that occur if a sinusoidal masker is used. [...] The notched noise is noise with a notch around the frequency of the signal the subject is trying to detect, and contains noise within a certain bandwidth. The bandwidth of the noise changes and the <b>masked</b> <b>thresholds</b> for the sinusoid are measured. The <b>masked</b> <b>thresholds</b> are calculated through simultaneous masking when the signal is played to the subject {{at the same time as}} the masker and not after.|$|R
40|$|In {{listening}} {{experiments that}} assess spatial hearing (e. g. localization) {{in the presence}} of background noise it is important to ensure audibility of the target stimulus. Target audibility could be easily controlled using knowledge about the <b>masked</b> <b>thresholds</b> in the respective paradigm. However, if a large number of acoustic conditions as well as target sounds are considered, individual psychoacoutic threshold measurements are not feasible and alternative methods need to be applied. In this study a binaural auditory model is applied to predict <b>masked</b> <b>thresholds</b> for wide-band non-stationary stimuli. This model closely follows the approach of Hant and Alwan (Speech Communication, 2003, Vol. 40, pp. 291 - 313). In the first stage of the model an auditory front-end generates an internal representation of the stimuli in both ears. The auditory front-end includes head-related transfer functions auditory bandpass filtering, squaring, temporal integration, logarithmic compression and additive internal noise. In the second stage, a decision device combines d 0 information across time, frequency and ears and provides an estimate of the <b>masked</b> <b>threshold.</b> Three different methods of combining information across ears were compared: A better-ear approach, a cross-ear glimpsing approach and an approach using binaural integration. The model was verified using psychoacoustic <b>masked</b> <b>threshold</b> data of a detection paradigm that considered a target word presented from 15 different locations in a reverberant multi-talker background. The model predictions were in very good agreement with the measured <b>masked</b> <b>thresholds.</b> It is concluded that this model is suitable to control audibility of a target stimulus in a complex reverberant environment. Moreover, the model was used to systematically analyze the effect of head-shadow, signal spectrum, auditory sensitivity and room reverberation on target audibility. 8 page(s...|$|R
40|$|A {{constrained}} Kalman filtering algorithm {{based on}} auditory <b>masking</b> <b>threshold</b> is proposed for enhancing speech degraded by colored noise. The auditory <b>masking</b> <b>threshold</b> {{is used as}} a constraint to obtain a Kalman gain, which minimizes the estimate error variance under the constraint that the error power is smaller than the <b>masking</b> <b>threshold.</b> From the characteristics of the correlation vector, the power spectrum density and the <b>masking</b> <b>threshold,</b> a nonlinear constrained optimization problem is formed to calculate the Kalman gain. Simulation results show that the algorithm can improve subjective PESQ scores over both classic algorithms and recently published algorithms...|$|E
3000|$|... [*]ms {{sub-band}} signal) {{is above}} the <b>masking</b> <b>threshold,</b> no bit-rate reduction is applied. If the temporal mask mean {{is above the}} noise mean, then the amount of bits needed to encode that sub-band FDLP residual signal is reduced {{in such a way}} that the noise level becomes similar to the <b>masking</b> <b>threshold.</b>|$|E
40|$|Many {{existing}} audio coders use {{a critically}} sampled discrete wavelet transform (DWT) for the decomposition of audio signals. While the aliasing {{present in the}} wavelet coefficients is cancelled in the decoder, these coders normally perform calculation of the simultaneous <b>masking</b> <b>threshold</b> directly on these aliased coefficients. This paper uses over-sampling in the wavelet packet decomposition {{in order to provide}} alias-free coefficients for accurate simultaneous <b>masking</b> <b>threshold</b> calculation. The proposed technique is compared with <b>masking</b> <b>threshold</b> calculation based upon the FFT and critically-sampled wavelet coefficients, and the results show that a bit rate saving of up to 16 kbit/s can be achieved using over-sampling...|$|E
40|$|The aim of {{the current}} study was to {{investigate}} the effects of pulse rate on spectral acuity in cochlear implant patients using a masking paradigm. High rates of electrical simulation may limit speech perception due to channel interactions between electrodes. Spectral acuity was measured with three different stimulation rates using a masking paradigm. The masking stimuli were presented at 300, 900, and 1800 pulses per second (pps/ch) on electrode 12. The probe stimulus was presented on electrodes 11, 12 and 13 at 900 pps/ch. It was hypothesized that the higher stimulation rates would show an increase in <b>masked</b> <b>thresholds.</b> The results of this experiment were that the two higher rates of stimulation have significantly higher <b>masked</b> <b>thresholds</b> than the lowest rate. There {{was no significant difference between}} the <b>masked</b> <b>thresholds</b> for the three electrodes measured at each rate. It was concluded that channel interactions occur due to increased rate of stimulation but this may not influence spectral acuity as much as temporal acuity. 1...|$|R
50|$|The unmasked {{threshold}} is the quietest {{level of}} the signal which can be perceived without a masking signal present. The <b>masked</b> <b>threshold</b> is the quietest {{level of the}} signal perceived when combined with a specific masking noise. The amount of masking {{is the difference between}} the <b>masked</b> and unmasked <b>thresholds.</b>|$|R
3000|$|These <b>masking</b> <b>thresholds</b> {{are then}} {{utilized}} in quantizing the sub-band FDLP residual signals. The {{number of bits}} required for representing the sub-band FDLP residuals is reduced in accordance with TM thresholds compared to the WB-FDLP codec without TM. Since the sub-band signal {{is the product of}} its FDLP envelope and residual (carrier), the <b>masking</b> <b>thresholds</b> for the residual signal are obtained by subtracting the dB SPL of the envelope from that of the sub-band signal. First, we estimate the quantization noise present in the WB-FDLP codec without TM. If the mean of the quantization noise (in [...]...|$|R
30|$|A {{sparsification}} {{was first}} proposed in [26], which principle {{is to set}} to zero {{a part of the}} source time-frequency (TF) coefficients found by a Gabor transform, without audible distortion. For this purpose, a simple simultaneous masking model was proposed, indicating, for each frequency bin, the <b>masking</b> <b>threshold</b> resulting from the other frequency components (which is quite different from a <b>masking</b> <b>threshold</b> computed for coding or watermarking purpose, i.e., for noise addition). Each frequency component falling below this <b>masking</b> <b>threshold</b> shifted by some decibels (typically - 6.6 dB), called ‘irrelevance function’, is simply removed. According to the experimental results presented in [26], this method allows to remove around 36 % of the Gabor coefficients, for sources sampled at 16 kHz.|$|E
3000|$|To {{estimate}} the <b>masking</b> <b>threshold</b> at each sample index, we compute a short-term dB SPL {{so that the}} signal is divided into [...]...|$|E
3000|$|... where ⌊[*]·[*]⌋ {{represents}} the floor function. As {{for the third}} criterion, the signal power variation shall not exceed the auditory <b>masking</b> <b>threshold</b> η.|$|E
3000|$|... [*]ms) {{may differ}} from real audio signal {{encoding}} conditions. Therefore, the actual <b>masking</b> <b>thresholds</b> are much below the thresholds obtained from the linear masking model. To obtain the actual thresholds, informal listening experiments were conducted to determine the correction factors [36].|$|R
40|$|Auditory {{localization}} {{research needs}} to be performed in more realistic testing environments to better capture the real-world abilities of listeners and their hearing devices. However, there are significant challenges involved in controlling the audibility of relevant target signals in realistic environments. To understand the important aspects influencing target detection in more complex environments, a reverberant room with a multi-talker background was simulated and presented to the listener in a loudspeaker-based virtual sound environment. <b>Masked</b> <b>thresholds</b> of a short speech stimulus were measured adaptively for multiple target source locations in this scenario. It was found that both distance and azimuth of the target source have a strong influence on the <b>masked</b> <b>threshold.</b> Subsequently, a functional model was applied to analyze the factors influencing target detectability. The model is comprised of an auditory front-end that generates an internal representation of the stimuli in both ears, followed by a decision device combining d' information across time, frequency and both ears. The model predictions of the <b>masked</b> <b>thresholds</b> were overall in very good agreement with the experimental results. An analysis of the model processes showed that head shadow effects, signal spectrum, and reverberation have a strong impact on target audibility in the given scenario. 11 page(s...|$|R
40|$|Series: Progress in Brain ResearchPublisher’s {{permission}} requested and denied. Studies of {{the temporal}} course of masking using pulsatile electrical stimulation provide a sensitive new technique for the investigation of central pattern recognition. The <b>masked</b> <b>threshold</b> for a single-pulse probe was studied for several different maskers {{as a function of}} the time between the probe and the start of the masker. These experiments showed the gradual development of a temporal pattern in the <b>masked</b> <b>thresholds</b> as the number of pulses in the masker was increased. For a 210 msec masker with pulses at 10 msec intervals, both backward and forward <b>masking</b> <b>thresholds</b> showed a well-defined peak at times 10 msec before and after the masker. Probe pulses presented at these times were probably perceived to be part of the masker pattern and therefore were not easily identified as probe pulses. This conclusion was confirmed by using a masker with pulses at 20 msec intervals. Only backward masking was tested, and the results showed a peak approximately 20 msec before the start of the masker, fitting in with the temporal pattern of the masker. Restricted Access: This resource is not available from the Digital Repository for copyright reasons. This is a citation and abstract only record...|$|R
40|$|This paper uses {{a method}} of {{incorporating}} simultaneous masking into the calculation of a linear predictive filter (SMLPC) as the front end to a 2 kbps waveform interpolation (WI) speech coder. A modification to the <b>masking</b> <b>threshold</b> calculation used in SMLPC is proposed. This modification improves the performance of SMLPC in noise like sections by placing greater emphasis on strongly voiced speech. MOS test results reveal that the modified SMLPC improved the perceptual quality of the WI coder. The improvement is significant for female speakers whilst the quality for male speech is virtually unchanged. This result conflicts with previous results reported for SMLPC where only male speech was improved. The change is attributed to the modification of the <b>masking</b> <b>threshold</b> and confirms that adapting the <b>masking</b> <b>threshold</b> according to the pitch of the speech will allow SMLPC to remove more perceptually important information from all input speech than standard LPC...|$|E
30|$|The <b>masking</b> <b>threshold</b> {{obtained}} through the above procedure is designated as η(n), {{which represents the}} noise power level not detectable by human ears in the n th band.|$|E
40|$|In {{this work}} we {{consider}} adaptive bit allocation for percep-tual coding of narrowband audio signals at low rates (down to 8 kb/s). Two different strategies {{are used to}} shape the audible noise spectrum. In one approach, the quantiza-tion noise spectrum is shaped in parallel with the <b>masking</b> <b>threshold</b> curve. This way the noise is equally audible in different frequency bands. The other approach generates a flat noise spectrum above the <b>masking</b> <b>threshold.</b> The noise power is not equally distributed over the frequency range, hence it is audible to various extents at different frequencies. ...|$|E
30|$|A secure transmorphing {{algorithm}} involves four inputs: {{the original}} image, the processed image, a <b>mask</b> <b>threshold,</b> and a secret key. The original and processed {{images can be}} in any format but are assumed {{to have the same}} pixel resolution. The output transmorphed image and the reconstructed image are all in JPEG format.|$|R
40|$|This paper {{presents}} a locally-adaptive perceptual quantization scheme for visual data compression. The {{strategy is to}} exploit human visual masking properties by deriving <b>masking</b> <b>thresholds</b> in a locally-adaptive fashion based on a sub-band decomposition. The derived <b>masking</b> <b>thresholds</b> are used in controlling the quantization stage by adapting the quantizer reconstruction levels to the local amount of masking present {{at the level of}} each sub-band transform coefficient. Compared to the existing non locally-adaptive perceptual quantization methods, the new locally-adaptive algorithm exhibit superior performance and does not require additional side information. This is accomplished by estimating the amount of available masking from the already quantized data and linear prediction of the coefficient under consideration. By virtue of the local adaptation, the proposed quantization scheme is able to remove a large amount of perceptually redundant information. Since the algorithm does not requi [...] ...|$|R
40|$|This article {{reviews the}} {{evolution}} of a series of models of loudness developed in Cambridge, UK. The first model, applicable to stationary sounds, was based on modifications of the model developed by Zwicker, including the introduction of a filter to allow for the effects of transfer of sound through the outer and middle ear prior to the calculation of an excitation pattern, and changes {{in the way that the}} excitation pattern was calculated. Later, modifications were introduced to the assumed middle-ear transfer function and to the way that specific loudness was calculated from excitation level. These modifications led to a finite calculated loudness at absolute threshold, which made it possible to predict accurately the absolute thresholds of broadband and narrowband sounds, based on the assumption that the absolute threshold corresponds to a fixed small loudness. The model was also modified to give predictions of partial loudness—the loudness of one sound in the presence of another. This allowed predictions of <b>masked</b> <b>thresholds</b> based on the assumption that the <b>masked</b> <b>threshold</b> corresponds to a fixed small partial loudness. Versions of the model for time-varying sounds were developed, which allowed prediction of the <b>masked</b> <b>threshold</b> of any sound in a background of any other sound. More recent extensions incorporate binaural processing to account for the summation of loudness across ears. In parallel, versions of the model for predicting loudness for hearing-impaired ears have been developed and have been applied to the development of methods for fitting multichannel compression hearing aids...|$|R
