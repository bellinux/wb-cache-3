31|0|Public
50|$|For the {{hypertext}} object, the THINK C text {{object was}} modified to allow <b>multifont</b> capability, {{and to allow}} anchors to be encoded in the styles.|$|E
50|$|Having seen Mosaic late in 1993 {{and been}} captivated by its potential, Peter Brooks {{set out in}} April 1994 to create a fully graphic, <b>multifont</b> web browser for home PC users.|$|E
50|$|Adaptive Recognition - {{a method}} {{based on a}} {{combination}} of two types of printed character recognition algorithms: <b>multifont</b> and omnifont. The system generates an internal font for each input document based on well printed characters using a dynamic adjustment (adaptation) to the specific input symbols. Thus, the method combines the omnitude and the technological efficiency of the omnifont approach with the high font recognition accuracy that dramatically improves the recognition rate.|$|E
50|$|The Lively Kernel {{includes}} its own <b>multifont</b> {{text editor}} written in JavaScript. It includes support for centering, justification and similar rudimentary text composition abilities. Working in Lively thus has {{much the same}} feel as working in a web page design program, except that the on-the-fly text layout is not being done in an offline composition program, {{but it is the}} built-in dynamic behavior of text in the Lively Kernel.|$|E
5000|$|Version 4.0 {{included}} a fully functional word processor - Q&A Write - {{that could be}} launched from Q&A or used as a stand-alone application. Q&A Write featured a 100,000 word spell check, a 660,000 word thesaurus, a dictionary, formatting options such as page layout, columnar formatting, automatic page numbering and headers, as well as support for the addition of graphics. Additionally, it offered <b>multifont</b> printing support {{and the ability to}} hot-link elements of a Lotus 1-2-3 document, Symphony spreadsheet or Lotus PIC graphs, to Q&A Write documents. Macros could be stored in an ASCII text file created with a text editor, Q&A Write or by recording keys; the Macro Menu could be accessed from many locations by pressing Shift-F2.|$|E
5000|$|In 1989, CERN was {{the largest}} {{internet}} node in Europe, and Berners-Lee saw an opportunity to join hypertext with the internet: [...] "I just {{had to take the}} hypertext idea and connect it to the Transmission Control Protocol and domain name system ideas and—ta-da!—the World Wide Web ... Creating the web was really an act of desperation, because the situation without it was very difficult when I was working at CERN later. Most of the technology involved in the web, like the hypertext, like the internet, <b>multifont</b> text objects, had all been designed already. I just had to put them together. It was a step of generalising, going to a higher level of abstraction, thinking about all the documentation systems out there as being possibly part of a larger imaginary documentation system." ...|$|E
50|$|In 1994 and 1995, the {{majority}} of home PC users {{who were interested in}} accessing the World Wide Web had to do so using terminal-based software. These users usually had dial-up shell accounts with their employers' Unix machines or with commercial UNIX ISPs (e.g. Netcom). They would run a terminal emulator program on their PCs, temporarily turning the machines into black screen terminals, dial into the Unix server, and then run text-based internet software such as pine and elm for e-mail, gopher for file retrieval, and lynx or www for a text-based browsing experience of the new World Wide Web. While this text-based browsing was fine while web pages were text-only, Mosaic changed the browser and web-page landscape in 1993 by displaying and therefore encouraging graphical, multimedia and <b>multifont</b> web pages. It also pioneered the point-and-click navigation for web browsing that had been a standard for prior hypertext applications, like Windows Help.|$|E
40|$|Research on <b>multifont,</b> {{automatic}} character-recognition machines {{has been}} in prog-ress for ten years. With more than 3000 type fonts in common use (including 300 type-writer fonts) there is enormous variability in the representation of any character. One approach to the <b>multifont</b> problem is to augment the recognition algorithms with a con...|$|E
40|$|This paper {{introduces}} a <b>multifont</b> classification scheme to help recognition of <b>multifont</b> and multisize characters. It uses typographical attributes such as ascenders, descenders and serifs {{obtained from a}} word image. The attributes are used as an input to a neural network classifier to produce the mul-tifont classification results. It can classify 7 commonly used fonts for all point sizes from 7 to 18. The approach devel-oped in this scheme can handle {{a wide range of}} image quality even with severely touching characters. The detection of the font can improve the character segmentation as well as the character recognition because the identification of the font provides information on the structure and the typographical design of characters. Therefore, this <b>multifont</b> classification algorithm can be used in maintaining good recognition rates of a machine printed OCR system regardless of fonts and sizes. Experiments have shown font classification accura-cies reach high performance levels of about 95 percent even with severely touching characters. The technique developed for the selected 7 fonts in this paper can be applied to any other fonts...|$|E
40|$|This paper {{describes}} the general {{structure of a}} full automated document analysis system for printed documents. The system {{is based on a}} character preclassification stage which reduces the number of patterns to recognize and introduces a new contextual processing. This specific approach for <b>multifont</b> printed documents reading is based on pattern character redundancies. With the study of prototype pattern instead of characters, we can extract reliable contextual information on the entire text. This statistical information is used to check hypotheses given by the <b>multifont</b> recognition stage. We shall describe the system organization and particularly the preclassification stage, then we shall give some results on recent documents...|$|E
40|$|A word {{recognition}} {{algorithm is}} proposed that integrates character recognition with word shape analysis. The algorithm consists {{of a set of}} serial filters and parallel classifiers, and the decisions are combined to generate a consensus ranking of the input lexicon. Experimental results with <b>multifont</b> machine-printed word images are discussed. ...|$|E
40|$|Abstract. A new {{segmentation}} algorithm for <b>multifont</b> Farsi/Arabic texts {{based on}} conditional labeling of {{up and down}} contours was presented in [1]. A preprocessing technique was used to adjust the local base line for each subword. Adaptive base line, up and down contours and their curvatures were used to improve the segmentation results. The algorithm segments 97 % of 22236 characters in 18 fonts correctly. However, finding {{the best way to}} receive high performance in the <b>multifont</b> case is challengeable. Different characteristics of each font are the reason. Here we propose an idea to consider some extra classes in the recognition stage. The extra classes will be some parts of characters or the combination of 2 or more characters causing most of errors in segmentation stage. These extra classes will be determined statistically. We have used a learn document of 4820 characters for 4 fonts. Segmentation result improves from 96. 7 % to 99. 64 %...|$|E
40|$|Neural {{networks}} are very often {{applied to the}} pattern recognition problem. In 1990 D. Specht introduced a special class of Probabilistic Neural Networks which were unnoticed in the computational practice due to their extremely large computer memory requirement. In this note we present and discuss results of experiments assessing the usability of Probabilistic Neural Networks to the <b>multifont</b> recognition problem for large size of the training set...|$|E
40|$|A {{key problem}} faced by {{classifiers}} is coping with styles not {{represented in the}} training set. We present an application of hierarchical Bayesian methods {{to the problem of}} recognizing degraded printed characters in a variety of fonts. The proposed method works by using training data of various styles and classes to compute prior distributions on the parameters for the class conditional distributions. For classification, the parameters for the actual class conditional distributions are fitted using an EM algorithm. The advantage of hierarchical Bayesian methods is motivated with a theoretical example. Severalfold increases in classification performance relative to style-oblivious and style-conscious are demonstrated on a <b>multifont</b> OCR task...|$|E
40|$|Abstract: A {{computational}} {{model for the}} recognition of <b>multifont</b> machine-printed word images of highly variable quality is given. The model integrates three word-recognition algorithms, each of which utilizes a different form of shape and context information. The approaches are character-recognition-based, segmentation-based, and word-shape-analysis based. The model overcomes limitations of previous solutions that focus on isolated characters. In an experiment using a lexicon of 33, 850 words and a test set of 1, 671 highly variable word images, the algorithm achieved a correct rate of 89 % at the top choice and 95 % in the top ten choices. Key Words: character recognition, word recognition, pattern recognition, multiple classifiers, decision combi~' nation...|$|E
40|$|In this paper, {{we propose}} a {{multistage}} restoration method {{in order to}} obtain a high-quality binary character pattern from a character image taken by digital camera. First, the character image is expanded and blurred before being converted into the binary character pattern. Multiple thresholds based on Otsu's Method are applied when binarization is performed. Next, the binary character pattern is modified by a system using ridge and ravine points. Then, line width of the character is normalized using thinning. In experiments, <b>multifont</b> characters were used for evaluating the restoration method and recognition accuracy was improved by approximately 5 % from 86 % to 91 %...|$|E
40|$|The {{recognition}} of Arabic characters {{is still a}} major challenge to overcome. In this paper, we propose a new approach {{in the field of}} {{recognition of}} <b>multifont</b> isolated Arabic characters. It is based on the semi-cursive nature of Arabic characters and consists in as-similating them to a small number of checkpoints equipped with their derivatives. The choice of this approach is motivated by the interesting properties of Bézier curves that allow drawing paramet-ric curves from a limited number of dots equipped with their tan-gents. The results achieved are very interesting and relate to char-acter recognition derived from a large number of fonts (23 fonts). 1...|$|E
40|$|A new {{integrated}} OCR {{system is}} presented. It allows recognition of printed uppercase and lowercase alphanumerics at a reading speed of 100 characters per second. The algorithm consists of following steps: edge detection, line-thinning, pattern segmentation, filtering, curvature calculations and final decision. The first two steps are simultaneously performed {{by means of}} a custom-designed LSI circuit. Its output signal is a sequence of vectors describing the contour of the skeletonized character. This information is fed to a microprocessor which performs the other steps. The system is designed as a low-cost equipment suitable for hand-carried OCR applications where well-formed characters are to be read. The use of a shape extraction recognition method leads conceptually to <b>multifont</b> possibilities. Anglai...|$|E
40|$|Text {{extraction}} from a web {{image is}} important for web indexing because the text can contain a key information of the web. This paper presents a method to detect a text with various orientation and <b>multifont</b> sizes in a web image. The proposed method consists of three steps; 1) color reduction of low resolution web image by a spatial merging algorithm, 2) extraction of character candidates by finding connected components corresponding to strokes, and 3) detection of texts in an arbitrary direction by filtering and combining character candidates based on a potential field. This method allows to detect text orientation and scale invariantly. Experiments with 200 web images are performed to verify {{the validity of the}} proposed method. ...|$|E
40|$|International audienceOptical Character Recognition (OCR) is {{the process}} of {{translating}} images of text into a comprehensible machine format. Generally, an OCR system is composed of binariza-tion, segmentation and recognition stages. Given an extracted binary character, the recognition stage ensures its description and decides its corresponding ASCII code. In this paper, we propose a new OCR system that aims to high speed, Multiscale and <b>Multifont</b> character recognition. Our proposal is based essentially on robust description using a new Unified Character Descriptor (UCD). In addition, a character type-face and font-size recognition is performed to choose the adequate template for faster matching process. Obtained OCR Accuracy of our proposed System is 1. 5 x higher then that reached by Tesseract on the LRDE dataset...|$|E
40|$|A {{method for}} {{computer}} recognition of plane figures is described. For each figure, its integral projection along a certain direction is defined. This is obtained by intersecting the figure {{with a set}} of lines parallel to the chosen direction and considering the lengths of the connected segments of the intersections {{as a function of the}} location of the lines. Discontinuities in the integral projections reveal in general the existence of strokes along the corresponding directions and this way a figure can be decomposed into certain basic strokes. The information whether certain strokes appear or not in a given figure and their relative position can be used for the classification of the figure. This method was implemented and tested on <b>multifont</b> lower-case typewritten letters. Recognition rates around 98 % were achieved on the testing sets...|$|E
40|$|Optical Characters Recognition (OCR) {{has been}} an active subject of {{research}} {{since the early days}} of computers. Despite the age of the subject, it remains one of the most challenging and exciting areas of research in computer science. In recent years it has grown into a mature discipline, producing a huge body of work. Arabic character recognition has been one of the last major languages to receive attention. This is due, in part, to the cursive nature of the task since even printed Arabic characters are in cursive form. This paper describes the performance of combining Hough transform and Hidden Markov Models in a <b>multifont</b> Arabic OCR system. Experimental tests have been carried out on a set of 85. 000 samples of characters corresponding to 5 different fonts from the most commonly used in Arabic writing. Some promising experimental results are reported. </p...|$|E
40|$|A {{multi-level}} <b>multifont</b> {{character recognition}} is presented. The system proceeds by first delimiting {{the context of}} the characters. As a way or enhancing system performance, typographical information is extracted and used for font identification before actual character recognition is performed. This has the advantage of sure character identification as well as text reproduction in original form. The font identification is based on decision trees where the characters are automatically arranged differently in confusion classes according to the physical characteristics of fonts. The character recognizers are built around the first and second order hidden Markov models (HMM) as well as Euclidean distance measures. The HMMs use the Viterbi and the Extended Viterbi algorithms to which enhancements were made. Also present is a majority-vote system that polls the other systems for "advice" before deciding on the identity of a character. Among other things, this last system is shown to give bett [...] ...|$|E
40|$|Abstract: This paper reports an {{investigation}} of some methods for isolating, or segmenting, characters during the reading of machineprinted text by optical character recognition systems. Two new segmentation algorithms using feature extraction techniques are presented; both are intended {{for use in the}} recognition of machine-printed lines of lo-, 11 - and 12 -pitch serif-type <b>multifont</b> characters. One of the methods, called quasi-topological segmentation, bases the decision to “section ” a character on a combination of featureextraction and character-width measurements. The other method, topological segmentation, involves feature extraction alone. The algorithms have been tested with an evaluation method that is independent of any particular recognition system. Test results are based on application of the algorithm to upper-case alphanumeric characters gathered from print sources that represent the existing world of machine printing. The topological approach demonstrated better performance on the test data than did the quasitopological approach...|$|E
40|$|Abstract: A {{series of}} {{techniques}} {{is being developed}} to postprocess noisy, <b>multifont,</b> nonformatted OCR data on a word basis to 1) determine if a field is alphabetic or numeric; 2) verify that an alphabetic word is legitimate; 3) fetch from a dictionary a set of potential entries using a garbled word as a key; and 4) error-correct the garbled word by selecting the most likely dictionary word. Four algorithms were developed using a technique called vector processing (representing alphabetic words as numeric vectors) and also by applying Bayes maximum likelihood solutions to correct the OCR output. The result was {{the development of a}} software simulator which processed sequential fields generated by the Advanced Optical Character Reader (in use by the U. S. Postal Service in New York City), performed the four functions indicated above, and selected the correct alphabetic word from a dictionary of 62000 entries. 1...|$|E
40|$|In {{this paper}} a robust <b>multifont</b> {{character}} recognition system for degraded documents such as photocopy or fax is described. The system {{is based on}} Hidden Markov Models (HMMs) using discrete and hybrid modeling techniques, where the latter makes use of an information theory-based neural network. The presented recognition results refer to the SEDAL-database of English documents using no dictionary. It is also demonstrated that the usage of a language model, that consists of character n-grams yields significantly better recognition results. Our resulting system clearly outperforms commercial systems and leads to further error rate reductions compared to previous results reached on this database. 1. Introduction During the last years, Hidden Markov Models (HMMs, see [7]) have been used not only for speech recognition but also for on- and off-line handwriting recognition (for example [2, 8]). However, the greatest advantage of HMMtechnologies, the possibility of segmentation-free recognit [...] ...|$|E
40|$|A~s~Qc~-A {{method for}} the {{recognition}} of <b>multifont</b> printed characters is proposed, giving emphasis to the identification of structural descriptions of character shapes using prototypes. Noise and shape variations are modeled as series of transformations from groups of features in the data to features in each prototype. Thus, the method manages systematically the relative distortion between a candidate shape and its prototype, accomplishing robustness to noise with less than two prototypes per class, on average. Our method uses a flexible matching between components and a flexible grouping of the individual components to be matched. A number of shape transformations are defined, including filling of gaps, so that the method handles broken characters. Also, {{a measure of the}} amount of distortion that these transformations cause is given. Classification of character shapes is defined as a minimization problem among the possible transformations that map an input shape into prototypical shapes. Some tests with hand-printed numerals confirmed the method’s high robustness level. Zndex Terms-Shape distance, graph matching, relative neighborhood graph, broken character recognition, subgraph homeomorphism. I...|$|E
40|$|International audienceA {{multi-level}} <b>multifont</b> {{character recognition}} is presented. The system proceeds by first delimiting {{the context of}} the characters. As a way of enhancing system performance, typographical information is extracted and used for font identification before actual character recognition is performed. This has the advantage of sure character identification as well as text reproduction in its original form. The font identification is based on decision trees where the characters are automatically arranged differently in confusion classes according to the physical characteristics of fonts. The character recognizers are built around the first and second order hidden Markov models (HMM) as well as Euclidean distance measures. The HMMs use the Viterbi and the Extended Viterbi algorithms to which enhancements were made. Also present is a majority-vote system that polls the other systems for advice before deciding on the identity of a character. Among other things, this last system is shown to give better results than each of the other systems applied individually. The system finally uses combinations of stochastic and dictionary verification methods for word recognition and error-correction...|$|E
40|$|Unlike {{classification}} of documents with plain background and high resolution, {{classification of}} historical document, namely Indus script written on stone, wall, and palm leaves is challenging because of sources on which script is written and various handwriting, which causes noise, distortions, background variations, multisized text, and <b>multifont.</b> In this paper, we propose an integrated method that has two-stage algorithms to classify Indus and English from the South Indian documents. The first stage uses morphological operations and thinning on Canny of the input image {{to study the}} straightness and cursiveness of thinned components to classify the Indus document from the South Indian and English. The second stage proposes region growing and thinning to study the straightness and cursiveness of the thinned edges to classify the English from the South Indian documents. We select 100 documents for each script in total 600 documents to evaluate {{the performance of the}} method. The comparative study with existing method shows that the proposed method outperforms the existing method in terms of classification rate...|$|E
40|$|Using ODA for Translating Multimedia Information The {{purpose of}} this RFC is to inform implementors of {{multimedia}} systems about our experiences using ISO 8613 : Office Document Architecture (ODA). Because ODA is being proposed as an encoding format for use in multimedia mail and file exchange, implementors wishing to use ODA in an open systems environment may profit from our experiences. This memo provides information for the Internet community. It does not specify any standard. Distribution of this memo is unlimited. 2. Overview ODA is a recently approved ISO (8613) and CCITT (T. 410) standard for representing documents containing <b>multifont</b> text, raster images and geometric graphics. This encoding has been specified {{for use in a}} number of related standards, such as X. 400. However, ODA is a very abstract standard, defining entities such as "composite logical object classes " and not common entities, such as "paragraphs". Therefore, effective use of ODA as an interchange medium requires the definition of a document application profile (dap) that defines some common entities and a map between ODA entities defined in the dap and entities used in the interchanged systems...|$|E
40|$|Many text {{recognition}} systems recognize text imagery at {{the character}} level and assemble {{words from the}} recognized characters. An alternative approach is to recognize text imagery at the word level, without analyzing individual characters. This approach avoids the problem of individual character segmentation, and can overcome local errors in character recognition. A word-level recognition system for machine-printed Arabic text has been implemented. Arabic is a script language, and is therefore difficult to segment at the character level. Character segmentation has been avoided by recognizing text imagery of complete words. The Arabic recognition system computes a vector of image-morphological features on a query word image. This vector is matched against a precomputed database of vectors from a lexicon of Arabic words. Vectors from the database with the highest match score are returned as hypotheses for the unknown image. Several feature vectors may be stored for each word in the database. Database feature vectors generated using multiple fonts and noise models allow the system to be tuned to its input stream. Used in conjunction with database pruning techniques, this Arabic recognition system has obtained promising word recognition rates on low-quality <b>multifont</b> text imagery. Keywords: optical character recognition, Arabic text recognition, mathematical morphology, feature matching 1...|$|E

