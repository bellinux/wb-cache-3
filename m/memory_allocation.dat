1227|197|Public
5|$|In C++ {{computer}} programming, allocators are {{an important}} component of the C++ Standard Library. The standard library provides several data structures, such as list and set, commonly referred to as containers. A common trait among these containers is their ability to change size during the execution of the program. To achieve this, some form of dynamic <b>memory</b> <b>allocation</b> is usually required. Allocators handle all the requests for allocation and deallocation of memory for a given container. The C++ Standard Library provides general-purpose allocators that are used by default, however, custom allocators may also be supplied by the programmer.|$|E
25|$|Seizing {{an entry}} from a pre-allocated array is faster than using dynamic <b>memory</b> <b>allocation</b> for each node, since dynamic <b>memory</b> <b>allocation</b> {{typically}} requires {{a search for}} a free memory block of the desired size.|$|E
25|$|You want to {{separate}} <b>memory</b> <b>allocation</b> from construction e.g. in implementing a std::vector<> (see std::vector<>::reserve).|$|E
50|$|Allocations local to {{the current}} stack frame cannot {{be in the same}} alias class as any {{previous}} allocation from another stack frame. This is the case because new <b>memory</b> <b>allocations</b> must be disjoint from all other <b>memory</b> <b>allocations.</b>|$|R
5000|$|... mtrace (...) /* Starts the {{recording}} of <b>memory</b> <b>allocations</b> and releases */ ...|$|R
5000|$|No data {{pre-processing}} needed, no {{loading time}} and no <b>memory</b> <b>allocations</b> in system <b>memory.</b>|$|R
25|$|The RISC OS kernel is single-tasking (the {{cooperative}} multi-tasking {{is provided}} by the WindowManager module) and controls handling of interrupts, DMA services, <b>memory</b> <b>allocation</b> and the video display.|$|E
25|$|For these reasons, this {{approach}} is mainly used for languages that do not support dynamic <b>memory</b> <b>allocation.</b> These disadvantages are also mitigated if the maximum size of the list is known {{at the time the}} array is created.|$|E
25|$|A {{team led}} by Sheena Josselyn in the Silva Lab {{discovered}} that there are molecular and cellular mechanisms that regulate which neurons in a circuit encode a given memory (neuronal <b>memory</b> <b>allocation).</b> They found that the transcription factor CREB modulates the probability that individual amygdala neurons become involved in storing a specific emotional memory: higher levels of CREB increase this probability while lower levels of CREB have the opposite effect. Later, Yu Zhou and colleagues in the Silva lab discovered that CREB modulates <b>memory</b> <b>allocation</b> by regulating neuronal excitability. These studies suggested that the mechanisms that consolidate one memory, for a limited period of time, {{may be involved in}} determining the allocation of the next memory, so that the two memories are associated or linked.|$|E
50|$|Version 0.98.2 {{employs a}} minor patch to correct malloc <b>memory</b> <b>allocations</b> and {{multiple}} threads issues, mainly on Ubuntu 11.10 operating systems. This 2011 gtk-gnutella version was also {{dedicated to the}} memory of Dennis Ritchie, 1941-2011.|$|R
5000|$|Parasoft Insure++ is runtime memory {{analysis}} and error detection tool. Its Inuse component provides a graphical view of <b>memory</b> <b>allocations</b> over time, with specific visibility into overall heap usage, block allocations, possible outstanding leaks, etc.|$|R
2500|$|Version 0.98.2 {{employs a}} minor patch to correct malloc <b>memory</b> <b>allocations</b> and {{multiple}} threads issues, mainly on Ubuntu 11.10 operating systems. [...] This 2011 gtk-gnutella version was also {{dedicated to the}} memory of Dennis Ritchie, 1941-2011.|$|R
25|$|For {{hardware}} {{functions such as}} {{input and}} output and <b>memory</b> <b>allocation,</b> the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and frequently makes system calls to an OS function or is interrupted by it. Operating systems are found on many devices that contain a computer from cellular phones and video game consoles to web servers and supercomputers.|$|E
25|$|Assembly {{language}} is still taught in most computer science and electronic engineering programs. Although few programmers today regularly work with assembly {{language as a}} tool, the underlying concepts remain very important. Such fundamental topics as binary arithmetic, <b>memory</b> <b>allocation,</b> stack processing, character set encoding, interrupt processing, and compiler design {{would be hard to}} study in detail without a grasp of how a computer operates at the hardware level. Since a computer's behavior is fundamentally defined by its instruction set, the logical way to learn such concepts is to study an assembly language. Most modern computers have similar instruction sets. Therefore, studying a single assembly {{language is}} sufficient to learn: I) the basic concepts; II) to recognize situations where the use of assembly language might be appropriate; and III) to see how efficient executable code can be created from high-level languages. This is analogous to children needing to learn the basic arithmetic operations (e.g., long division), although calculators are widely used for all except the most trivial calculations.|$|E
25|$|In 2016 Denise Cai in Alcino Silva's laboratory, led {{a team of}} {{scientists}} at UCLA and UCSD that discovered that mechanisms of <b>memory</b> <b>allocation</b> can be used to link memories across time. They showed that one memory triggers the activation of CREB and subsequent enhancements in excitability in a subset of neurons of a neuronetwork, so that a subsequent memory, even many hours later, can be directed or allocated to some of the same neurons that encoded the first memory. Later on, recall of the first memory triggers the activation of those neurons and therefore the reactivation and retrieval of the second memory. These results represent the first molecular, cellular and circuit mechanism underlying the linking of memories across time. These authors also showed that memory linking mechanisms are affected in the aging brain, and that manipulating excitability in a subset of neurons reverses these deficits. Impairments in CREB and neuronal excitability in aging likely underlie these abnormalities in memory linking. It is possible that problems with memory linking may underlie well-known source memory problems (source amnesia) associated with aging.|$|E
50|$|Performance Analyzer is {{available}} {{as part of}} Oracle Developer Studio. It has visualization capabilities, can read out hardware performance counters, thread synchronization, <b>memory</b> <b>allocations</b> and I/O, and specifically supports Java, OpenMP, MPI, and the Solaris kernel.|$|R
50|$|The {{handlers}} log all <b>memory</b> <b>allocations</b> and frees to a file {{defined by}} the environment variable MALLOC_TRACE (if the variable is unset, describes an invalid filename, or describes a filename the user does not have permissions to, the handlers are not installed).|$|R
500|$|The C++11 {{standard}} has {{enhanced the}} allocator interface to allow [...] "scoped" [...] allocators, so that containers with [...] "nested" [...] <b>memory</b> <b>allocations,</b> such as vector of strings or {{a map of}} lists of sets of user-defined types, can ensure that all memory is sourced from the container's allocator.|$|R
500|$|The 2011 {{revision}} of the C++ Standard removed the weasel words requiring that allocators of a given type always compare equal and use normal pointers. [...] These changes make stateful allocators much more useful and allow allocators to manage out-of-process shared memory. The current purpose of allocators {{is to give the}} programmer control over <b>memory</b> <b>allocation</b> within containers, rather than to adapt the address model of the underlying hardware. [...] In fact, the revised standard eliminated the ability of allocators to represent extensions to the C++ address model, formally (and deliberately) eliminating their original purpose.|$|E
2500|$|Visual Studio Team System Profiler (VSTS Profiler) {{is a tool}} {{to analyze}} the {{performance}} of [...]NET projects that analyzes the space and time complexity of the program. It analyzes the code and prepares a report that includes CPU sampling, instrumentation, [...]NET <b>memory</b> <b>allocation</b> and resource contention.|$|E
2500|$|In 1983, [...] "C with Classes" [...] {{was renamed}} to [...] "C++" [...] (++ being the {{increment}} operator in C), adding new features that included virtual functions, function name and operator overloading, references, constants, type-safe free-store <b>memory</b> <b>allocation</b> (new/delete), improved type checking, and BCPL style single-line comments with two forward slashes (//). [...] Furthermore, it included {{the development of}} a standalone compiler for C++, Cfront.|$|E
40|$|Region-based memory {{management}} {{can be used}} to control dynamic <b>memory</b> <b>allocations</b> and deallocations safely and efficiently. Existing (direct-style) region systems that statically guarantee region safety [...] -no dereferencing of dangling pointers [...] -are based on refinements of Tofte and Talpin's seminal work on region inference for managing heap memory in stacks of regions...|$|R
50|$|Libcwd {{keeps an}} {{internal}} administration of <b>memory</b> <b>allocations.</b> This {{allows one to}} do things like memory leak checking, printing out an overview of allocated memory (in a very powerful way, allowing one to filter on about anything: regular expressions for library names, function names (demangled or not) and/or time intervals during which allocations were made).|$|R
3000|$|However, {{showing how}} {{memories}} are a critical reference for project activities is functional in a creative perspective {{to produce a}} tool that is constant an [...] "expansion" [...] of personal memory. This could be further extendable with time, and elements of the architect’s history and education would be always visible and available, instead of being given up by limited availability of <b>memory</b> <b>allocations.</b>|$|R
2500|$|SCO's {{first public}} {{disclosure}} {{of what they}} claim is infringing code was at SCO Forum in August 2003. [...] The first, known as the Berkeley Packet Filter, was distributed under the BSD License and is freely usable by anyone. [...] The second example was related to <b>memory</b> <b>allocation</b> functions, also released under the BSD License. It {{is no longer in}} the Linux code base.|$|E
2500|$|Placement new {{can also}} be used as a simple {{debugging}} tool, to enable programs to print the filename and line number of the source code where a <b>memory</b> <b>allocation</b> has failed. This does not require the inclusion of the Standard C++ library header <new>, but does require the inclusion of a header that declares four placement functions and a macro replacement for the new keyword that is used in new expressions. For example, such a header would contain: ...|$|E
2500|$|The {{original}} Sun 1 was a single-board computer {{built around}} the Motorola 68000 microprocessor and introduced in 1982. It included the original Sun 1 memory management unit that provided address translation, memory protection, memory sharing and <b>memory</b> <b>allocation</b> for multiple processes running on the CPU. [...] All access of the CPU to private on-board RAM, external Multibus memory, on-board I/O and the Multibus I/O ran through the MMU, where they were translated and protected in uniform fashion. The MMU was implemented in hardware on the CPU board.|$|E
40|$|We {{develop and}} examine job {{migration}} policies by considering effective usage of global memory {{in addition to}} CPU load sharing in distributed systems. When a node is identified for lacking sufficient memory space to serve jobs, one or more jobs of the node will be migrated to remote nodes with low <b>memory</b> <b>allocations.</b> If the <b>memory</b> space is sufficiently large, the jobs will be scheduled by a CPU-based load sharing policy. Following the principle of sharing both CPU and memory resources, we present several load sharing alternatives. Our objective {{is to reduce the}} number of page faults caused by unbalanced <b>memory</b> <b>allocations</b> for jobs among distributed nodes, so that overall performance of a distributed system can be significantly improved. We have conducted trace-driven simulations to compare CPUbased load sharing policies with our policies. We show that our load sharing policies not only improve performance of memorybound jobs, but also maintain the same load sharing quality as the CPU-ba [...] ...|$|R
40|$|Today web browsers {{are used}} {{more and more}} as {{application}} runtime environment in addition to their use and origins as document viewers. At the same time web application’s architecture is undergoing changes. For instance functionality is being moved from the backend into the client, following the so-called Thick client architecture. Currently it is quite easy to create client side web applications that do not manage their <b>memory</b> <b>allocations.</b> There has not been large focus in client side application’s memory usage for various reasons. However, currently client side web applications are widely being built and some of these applications are expected to be run for extended periods. Longevity of the application requires application’s succesful memory management. From the performance point of view it is also beneficial that the application manages its memory succesfully. The client-side behaviour of the application is developed with JavaScript, which has automatically managed <b>memory</b> <b>allocations.</b> However, like all abstractions, automatically managed memory is a leaky abstraction to an undecidable problem. In this thesis we aim at finding out what it takes to create client side applications that succesfully manage their <b>memory</b> <b>allocations.</b> We will {{take a look at the}} tools available for investigating memory issues during application development. We also developed a memory diagnostics module, in order to be able to diagnose application instance’s memory usage during its use. The diagnostics module developed during this thesis was used succesfully to monitor application’s memory usage over time. With the use of the data provided by the diagnostics module, we were able to identify memory issues from our demo application. However, currently the Web platform does not enable the creation of cross-browser standard relying solution for diagnosing web application’s memory usage...|$|R
50|$|Dr. Memory is an {{open-source}} memory debugging tool {{built on}} DynamoRIO and released under an LGPL license. Dr. <b>Memory</b> monitors <b>memory</b> <b>allocations</b> and <b>memory</b> accesses using shadow memory. It detects memory-related programming errors such as accesses of uninitialized memory, accesses to freed memory, heap overflow and underflow, and memory leaks. Its feature set {{is similar to}} that of the Valgrind-based Memcheck tool, though it operates on Windows as well as Linux and is twice as fast as Memcheck.|$|R
2500|$|In the C++ {{programming}} language, placement syntax allows programmers to explicitly {{specify the}} memory management of individual objects— i.e. their [...] "placement" [...] in memory. Normally, when an object is created dynamically, an allocation function is invoked {{in such a}} way that it will both allocate memory for the object, and initialize the object within the newly allocated memory. The placement syntax allows the programmer to supply additional arguments to the allocation function. A common use is to supply a pointer to a suitable region of storage where the object can be initialized, thus separating <b>memory</b> <b>allocation</b> from object construction.|$|E
2500|$|A buffer {{overflow}} {{occurring in the}} heap data area {{is referred to as}} a heap overflow and is exploitable in a manner different from that of stack-based overflows. [...] Memory on the heap is dynamically allocated by the application at run-time and typically contains program data. [...] Exploitation is performed by corrupting this data in specific ways to cause the application to overwrite internal structures such as linked list pointers. [...] The canonical heap overflow technique overwrites dynamic <b>memory</b> <b>allocation</b> linkage (such as malloc meta data) and uses the resulting pointer exchange to overwrite a program function pointer.|$|E
2500|$|All <b>memory</b> <b>allocation</b> is {{therefore}} completely automatic (one {{of the features}} of modern systems) {{and there is no way}} to allocate blocks other than this mechanism. [...] There are no such calls as malloc or dealloc, since memory blocks are also automatically discarded. [...] The scheme is also lazy, since a block will not be allocated until it is actually referenced. [...] When memory is nearly full, the MCP examines the working set, trying compaction (since the system is segmented, not paged), deallocating read-only segments (such as code-segments which can be restored from their original copy) and, as a last resort, rolling dirty data segments out to disk.|$|E
50|$|ActiveCheck {{performs}} a less intrusive analysis and monitors all calls by the {{application to the}} C Runtime Library, Windows API and calls to COM objects. By monitoring <b>memory</b> <b>allocations</b> and releases, it can detect memory leaks and overruns. Monitoring API and COM calls enables ActiveCheck to check parameters, returns and exceptions and report exceptions when they occur. Thread deadlocks can also be detected by monitoring of the synchronization objects and calls giving actual and potential deadlock detection.|$|R
40|$|This {{dissertation}} proposes generalized {{techniques to}} support software performance analysis using system execution traces {{in the absence}} of software development artifacts such as source code. The proposed techniques do not require modifications to the source code, or to the software binaries, for the purpose of software analysis (non-intrusive). The proposed techniques are also not tightly coupled to the architecture specific details of the system being analyzed. This dissertation extends the current techniques of using system execution traces to evaluate software performance properties, such as response times, service times. The dissertation also proposes a novel technique to auto-construct a dataflow model from the system execution trace, which will be useful in evaluating software performance properties. Finally, it showcases how we can use execution traces in a novel technique to detect Excessive Dynamic <b>Memory</b> <b>Allocations</b> software performance anti-pattern. This is the first attempt, according to the author 2 ̆ 7 s best knowledge, of a technique to detect automatically the excessive dynamic <b>memory</b> <b>allocations</b> anti-pattern. The contributions from this dissertation will ease the laborious process of software performance analysis and provide a foundation for helping software developers quickly locate the causes for negative performance results via execution traces. ...|$|R
40|$|Strict {{control over}} the {{scheduling}} and execution of processor resources is essential for many fixed-priority real-time applications. To facilitate this common requirement, the Real-Time CORBA (RT-CORBA) specification defines standard middleware features that support end-to-end predictability for operations in such applications. One {{of the most important}} features in RT-CORBA is thread pools, which allow application developers and end-users to configure and control processor resources. This paper provides two contributions to the evaluation of techniques for improving the quality of implementation of RTCORBA thread pools. First, we describe the key patterns underlying common strategies for implementing RT-CORBA thread pools. Second, we evaluate each thread pool strategy in terms of its consequences on (1) feature support, such as request buffering and thread borrowing, (2) scalability in terms of endpoints and event demultiplexers required, (3) efficiency in terms of data movement, context switches, <b>memory</b> <b>allocations,</b> and synchronizations required, (4) optimizations in terms of stack and thread specific storage <b>memory</b> <b>allocations,</b> and (5) bounded and unbounded priority inversion incurred in each implementation. This paper also provides results that illustrate empirically how different thread pool implementation strategies perform in different ORB configurations. ...|$|R
