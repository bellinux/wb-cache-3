0|967|Public
40|$|We {{propose a}} proof {{representation}} format for human-oriented proofs at the assertion level with underspecification. This work aims at providing a possible solution to challenging phenomena {{worked out in}} empirical studies in the DIALOG project at Saarland University. A particular challenge in this project is {{to bridge the gap}} between the human-oriented proof representation format with under-specification used in the proof manager of the tutorial dialogue system and the calculus- and <b>machine-oriented</b> <b>representation</b> format of the domain reasoner...|$|R
40|$|Compilability is a {{fundamental}} property of knowledge <b>representation</b> <b>formalisms</b> which captures how succinctly information can be expressed. Although many results concerning compilability have been obtained, they are all &quot;worst-case &quot; results. We develop a theory of average-case compilability which allows for the formal comparison and classification of knowledge <b>representation</b> <b>formalisms</b> &quot;on average. &quot;...|$|R
5000|$|Make {{recommendations}} {{on the development}} and use of Health information Standards for data interchange and <b>representation</b> <b>formalisms.</b>|$|R
5000|$|One of the {{fundamental}} design goals of the <b>representation</b> <b>formalisms</b> developed in SRL is to abstract away from concrete entities and to represent instead general principles that are intended to be universally applicable. Since there are countless ways in which such principles can be represented, many <b>representation</b> <b>formalisms</b> have been proposed in recent years. In the following, {{some of the more}} common ones are listed in alphabetical order: ...|$|R
40|$|Abstract. Sowa’s Conceptual Graphs and Formal Concept Analysis {{have been}} {{combined}} into another knowledge <b>representation</b> <b>formalism</b> named Concept Graphs. In this paper, we compare Simple Conceptual Graphs with Simple Concept Graphs, by successively studying their dif-ferent syntaxes, semantics, and entailment calculus. We show that these graphs are almost identical mathematical objects, have equivalent se-mantics, and similar inference mechanisms. We highlight the respective benefits {{of these two}} graph-based knowledge <b>representation</b> <b>formalisms,</b> and propose to unify them. ...|$|R
40|$|Information {{extraction}} from semi-structured documents requires to find n-ary queries {{in trees}} that define appropriate sets of n-tuples of nodes. We propose new <b>representation</b> <b>formalisms</b> for n-ary queries by tree automata that we prove to capture MSO. We then investigate n-ary queries by unambiguous tree automata which are relevant for query induction in multi-slot information extraction. We {{show that this}} <b>representation</b> <b>formalism</b> captures the class of n-ary queries that are finite unions of Cartesian closed queries, a property we prove decidable...|$|R
40|$|In {{this paper}} we present an underspecified logic, i. e. a pair {{consisting}} of a proper underspecified semantic <b>representation</b> <b>formalism</b> and a deductive component that directly operates on these structures. We show how the main features of this formalism can be imported into other existing underspecified semantic <b>representation</b> <b>formalisms.</b> We also show that deduction rules may be imported there along the same lines. The set of importable rules will of course depend on the completeness properties of the particular formalisms. ...|$|R
40|$|We {{develop a}} {{methodology}} for comparing knowledge <b>representation</b> <b>formalisms</b> {{in terms of}} their "representational succinctness, " that is, their ability to express knowledge situations relatively efficiently. We use this framework for comparing many important formalisms for knowledge base representation: propositional logic, default logic, circumscription, and model preference defaults; and, at a lower level, Horn formulas, characteristic models, decision trees, disjunctive normal form, and conjunctive normal form. We also show that adding new variables improves the effective expressibility of certain knowledge <b>representation</b> <b>formalisms.</b> ...|$|R
40|$|Shells and {{high-level}} {{programming language}} environments {{suffer from a}} number of shortcomings as knowledge engineering tools. We conclude that a variety of knowledge <b>representation</b> <b>formalisms</b> and a variety of controls regimes are needed. In addition guidelines should be provided about when to choose which knowledge <b>representation</b> <b>formalism</b> and which control regime. The guidelines should be based on properties of the task and the domain of the expert system. In order to arrive at these guidelines we first critically review some of the classifications of expert systems in the literature. We then give our own list of criteria. We test this list applying our criteria to a number of existing expert systems. As a caveat, we have not yet made a systematic attempt at correlating the criteria and different knowledge <b>representations</b> <b>formalisms</b> and control regimes, although we make some preliminary remarks throughout the paper...|$|R
25|$|Examples of {{knowledge}} <b>representation</b> <b>formalisms</b> include semantic nets, systems architecture, frames, rules, and ontologies. Examples of automated reasoning engines include inference engines, theorem provers, and classifiers.|$|R
40|$|Abstract. In {{this paper}} {{we present a}} {{framework}} for automated learning within mathematical reasoning systems. In particular, this framework enables proof planning systems to automatically learn new proof methods from well chosen examples of proofs which use a similar reasoning pattern to prove related theorems. Our framework consists of a <b>representation</b> <b>formalism</b> for methods and a machine learning technique which can learn methods using this <b>representation</b> <b>formalism.</b> We present the implementation of this framework within theÅMEGA proof planning system, and some experiments we ran on this implementation to evaluate the validity of our approach. ...|$|R
40|$|In this paper, {{we present}} a novel {{approach}} for information integration usable in many different web and network environments. The knowledge <b>representation</b> <b>formalism</b> of Description Logic Programs (DLPs) {{is well known in}} the Semantic Web community as a qualified Information Integration language. This is due to its property of being the intersection between the established knowledge <b>representation</b> <b>formalisms</b> of Description Logics and Logic Programming. In this paper, we take the DLPs a step further and extend them with probabilities. Furthermore, we suggest a framework for Information Integration by using these so-calle...|$|R
40|$|In {{this paper}} {{we present a}} {{framework}} for automated learning within mathematical reasoning systems. In particular, this framework enables proof planning systems to automatically learn new proof methods from well chosen examples of proofs which use a similar reasoning pattern to prove related theorems. Our framework consists of a <b>representation</b> <b>formalism</b> for methods and a machine learning technique which can learn methods using this <b>representation</b> <b>formalism.</b> We present the implementation of this framework within the mega proof planning system, and some experiments we ran on this implementation to evaluate the validity of our approach...|$|R
40|$|This paper {{describes}} Livingstone, an implemented kernel for a model-based reactive self-con guring autonomous system. It {{presents a}} formal characterization of Livingstone's <b>representation</b> <b>formalism,</b> and reports on our {{experience with the}} implementation {{in a variety of}} domains. Livingstone provides a reactive system that performs signi cant deduction in the sense/response loop by drawing on our past experience at building fast propositional con ict-based algorithms for model-based diagnosis, and by framing a model-based con guration manager as a propositional feedback controller that generates focused, optimal responses. Livingstone's <b>representation</b> <b>formalism</b> achieves broad coverage of hybrid hardware/softwar...|$|R
40|$|Modelling {{knowledge}} and data in CAD/CAM applications is complex because different goals and contexts {{have to be}} taken into account. This complexity makes particular demands upon <b>representation</b> <b>formalisms.</b> Today many modelling tools are based on record structures. By analyzing the requirements for a product model of a portal structure in steel, this paper shows that in many situations record structures are not well suited as a <b>representation</b> <b>formalism</b> for storing {{knowledge and}} data in CAD/CAM applications. This is illustrated by performing a knowledge-level analysis of the knowledge and data generated in the design and manufacturing process of a portal structure in steel...|$|R
40|$|This paper {{describes}} Livingstone, an implemented kernel for a self-reconfiguring autonomous system, that is reactive {{and uses}} component-based declarative models. The paper presents a formal {{characterization of the}} <b>representation</b> <b>formalism</b> used in Livingstone, and reports on our experience with the implementation {{in a variety of}} domains. Livingstone's <b>representation</b> <b>formalism</b> achieves broad coverage of hybrid software/hardware systems by coupling the concurrent transition system models underlying concurrent reactive languages with the discrete qualitative representations developed in model-based reasoning. We achieve a reactive system that performs significant deductions in the sense/response loop by drawing on our past experience at building fast propositional conflictbase...|$|R
5000|$|Many {{fundamental}} logical formalisms {{are essential}} to section I.2 on artificial intelligence, for example modal logic and default logic in Knowledge <b>representation</b> <b>formalisms</b> and methods, Horn clauses in logic programming, and description logic.|$|R
40|$|In this thesis, two {{requirements}} on Underspecified <b>Representation</b> <b>Formalisms</b> are investi-gated {{in detail in}} the context of underspecification of scope. The requirement on partial disambiguation, stating that partially disambiguated ambiguities need to be represented, does not carry much content unless it has become clear, exactly what those ambiguities are. In line with König and Reyle (1999), I argue that all theoretically possible patterns of ambiguity, i. e. subsets of readings, can occur in natural language and that therefore an underspecified <b>representation</b> <b>formalism</b> can only be regarded as expressively com-plete, if it provides representations for all of these subsets. This discussion is couched in a general formal setting, which facilitates clean definitions and allows for the derivation of formally precise results. With those formal definitions at hand, various underspeci-fied <b>representation</b> <b>formalisms</b> are evaluated. As it turns out, none of the investigated formalisms is expressively complete, which answers a corresponding question raised in (König and Reyle, 1999). These incompleteness results allow for a straightforward com-parison of the discussed approaches with respect to expressive power, which forms th...|$|R
40|$|The <b>{{representation}}</b> <b>formalism</b> {{as well as}} {{the representation}} language is of great importance for the success of machine learning. The <b>representation</b> <b>formalism</b> should be expressive, efficient, useful, and applicable. First-order logic needs to be restricted in order to be efficient for inductive and deductive reasoning. In the field of knowledge <b>representation</b> term subsumption <b>formalisms</b> have been developed which are efficient and expressive. In this paper, a learning algorithm, KLUSTER, is described which represents concept definitions in this formalism. KLUSTER enhances the representation language if this is necessary for the discrimination of concepts. Hence, KLUSTER is a constructive induction program. KLUSTER builds the most specific generalization and a most general discrimination in polynomial time. It embeds these concept learning problems into the overall task of learning a hierarchy of concepts...|$|R
40|$|Complex {{tasks that}} are being {{performed}} in trade and industry such as diagnosis, engineering and planning, increasingly require rapid and easy access to large amounts of complicated knowledge. To cope with these demands on trade and industry, advanced automated support for managing knowledge seems to be needed. Knowledge based systems are claimed to match these needs. However, {{to deal with the}} vast volume and complexity of knowledge through knowledge based systems, preconditions at three computer systems levels should be fulfilled. At the first level, called the knowledge level, the development of knowledge based systems requires a well-elaborated theory of the nature of knowledge that helps to get a clear and consistent definition of knowledge. By providing guidelines for selecting and developing methodologies and for organising the mathematical functions underlying knowledge <b>representation</b> <b>formalisms,</b> such a definition significantly advances the process of knowledge engineering. Here, we present the theory of functional object-types as a theory of the nature of knowledge. At the second level, called the symbol level, the <b>representation</b> <b>formalisms</b> used must be compatible with the chosen theory of the nature of knowledge. The <b>representation</b> <b>formalisms</b> also have to be interpretable as propositions representing knowledge, so that their knowledge level import can be assessed. Furthermore, knowledge <b>representation</b> <b>formalisms</b> have to play a causal role in the intelligent behaviour of the knowledge based system. At the third level, called the systems level, a knowledge based system should be equipped with facilities that enable an effective management of the <b>representation</b> <b>formalisms</b> used. Yet other system facilities are needed to allow the knowledge base to communicate with existing computer systems used in the daily practice of trade and industry, for instance Database Management Systems, Geographical Information Systems and Computer Aided Design Systems. It should be taken into account that these systems may run in different networks and on different operating systems. A real-world knowledge based system that operates in the field of soil contamination exemplifies the development of an advanced and operational knowledge-based system that complies with the preconditions at each computer systems level...|$|R
40|$|The {{focus of}} this paper is schema {{transformation}} during the development of an information system. We describe a framework for conversion and transformation of conceptual (semantic) data models and their internal (<b>machine-oriented)</b> <b>representations.</b> This framework allows us to `walk' through the solution space of candidate internal representations for a given conceptual data model. This walk may be randomized or performance-driven, where storage requirements and average response times are combined in a multiobjective fitness function. Furthermore, a wide variety of control parameters may be embedded, such as preferences for database table size, absence of data redundancy or absence of optional database fields. Basic experimental results produced by a prototype converter/transformer are presented, including deviations from the standard Optimal Normal Form for databases. Keywords: data schema transformation, database design, performance engineering. 1 Introduction 1. 1 Background In this [...] ...|$|R
40|$|As modern Automated Deduction systems {{rely heavily}} {{on the use of}} a <b>machine-oriented</b> <b>representation</b> of a given problem, {{together}} with sophisticated redundancy-avoiding techniques, a major task in convincing human users of the correctness of automatically generated proofs is the intelligible representation of these proofs. In this paper, we propose the use of the cut-rule in the human-oriented presentation of computer-generated proofs. The intelligent application of cuts enables the integration of essential lemmata and therefore shortens and structures proof presentation. We show that many translation techniques in Automated Deduction, such as antiprenexing and some forms of normal form translations, can be described as cuts and are indeed part of the deductive solution of a problem. Furthermore, we demonstrate the connection between symmetric simplification, quantorial extension principles and the application of the cut-rule. 1 Introduction Most of today's Automated Ded [...] ...|$|R
40|$|This paper {{presents}} a document analysis system which {{is capable of}} extracting the semantics of specific text portions of structured documents. The main component {{of the system is}} the knowledge representation scheme- called hsco, Frame Representation of Structured Documents. It allows the definition of knowledge about document components as well as knowledge about analysis algorithms in a uniform, simple, but powerful <b>representation</b> <b>formalism.</b> The specific inference algorithm of Fresco is presented which combines the two different knowledge sources- the document model and the algorithmic model. The flexibility of the <b>representation</b> <b>formalism</b> Fresco and the properties of the inference algorithm are shown in two different applications, in interpreting amount fields on cheques and in analysing business letters. ...|$|R
40|$|This paper uses Bayesian {{modeling}} {{techniques to}} analyze a data set {{extracted from the}} British General HousehoM survey. The models used are Bayesian networks, which provide a compact and easy to interpret knowledge <b>representation</b> <b>formalism.</b> An issue considered {{is the need for}} automated Bayesian modeling...|$|R
40|$|Abstract. Agent {{programming}} for robots requires {{different levels of}} abstraction and a <b>representation</b> <b>formalism</b> {{able to cope with}} several sources of complexity (e. g. parallel execution, partial observability, exogenous events, etc.). Reinforcement Learning (RL) has proved promising in improving the performance, adaptability and robustness of plans although it still does not easily scale to the domains of common robotic applications. We propose to combine Petri Net Plans, an extremely expressive plan <b>representation</b> <b>formalism,</b> with Reinforcement Learning over a stochastic process derived directly from such a plan specifically to reduce the search space and improve the performance of complex behaviors. We show how to model and learn the behavior of the agent in the context of Keepaway Soccer (a widely accepted benchmark for RL) and th...|$|R
40|$|ABSTRACT: The {{qualification}} {{problem may}} be the most fundamental difficulty in formalizing common sense knowledge in general, and in formalizing knowledge about action in particular. This position paper argues that the qualification problem is intrinsicallycomputational as opposed to representational. This does not imply that explicit, formal, knowledge has no role in the production of commonsensical behaviour, but it does imply that the qualification problem cannot be solved using currently available <b>representation</b> <b>formalisms.</b> For a future <b>representation</b> <b>formalism</b> to help in solving the qualification problem, it will be vital for it to possess a context mechanism. Artificial intelligence research has a history of wishful thinking. In the 1950 s the hope was that the right heuristic search algorithms, if only they could be found, would suffice to explai...|$|R
40|$|Enabling Subject Matter Experts (SMEs) to {{formulate}} knowledge without {{the intervention of}} Knowledge Engineers (KEs) requires providing SMEs with methods and tools that abstract the underlying knowledge representation, allowing SMEs {{to focus on the}} modeling activities. However, automatically bridging the gap between SME-authored models and their internal representation is not an easy task, {{especially in the case of}} complex knowledge types like processes, where aspects like frame management, data, and control flow need to be addressed. In this paper, we present a process <b>representation</b> <b>formalism</b> and method for automatically grounding SME-authored process models in the form of process diagrams into a particular representation language, supporting process representation and reasoning. Categories and Subject Descriptors I. 2. 4 Knowledge <b>Representation</b> <b>Formalisms</b> and Methods...|$|R
40|$|We {{describe}} a new sentence realization framework for text-to-text applications. This framework uses IDL-expressions as a <b>representation</b> <b>formalism,</b> and a generation mechanism based on algorithms for intersecting IDL-expressions with probabilistic language models. We present both {{theoretical and empirical}} results concerning the correctness and efficiency of these algorithms...|$|R
40|$|It is {{well known}} that many {{artificial}} intelligence applications need to represent and reason with knowledge that is not fully certain. This has motivated the study of many knowledge <b>representation</b> <b>formalisms</b> that can effectively han-dle uncertainty, and in particular probabilistic description logics (DLs) [7 – 9]...|$|R
40|$|Description logics (DLs) [1] are {{a family}} of {{knowledge}} <b>representation</b> <b>formalisms</b> that underpin OWL 2 [2]—an ontology language used in advanced information systems with many practical applications. Answering conjunctive queries (CQs) over ontologyenriched data sets is a core reasoning service in such systems, so the computationa...|$|R
40|$|Description Logics {{have been}} {{successfully}} used as knowledge <b>representation</b> <b>formalisms</b> {{in a wide range}} of application domains. Expressive Description Logics (M) can be defined as extensions of the well-known concept language ALC, allowing for number restrictions on complex role expressions built with constructors M #, #}...|$|R
40|$|Description Logics (DLs) are {{a family}} of {{knowledge}} <b>representation</b> <b>formalisms</b> used to represent and reason about an application’s domain elements. They are applicable in the semantic web as they {{provide the basis for}} the Web Ontology Language (OWL). Decision procedures for expressive DLs enabling both nominals and QCRs wer...|$|R
40|$|In {{this short}} paper, the basic ideas behind a {{project on the}} {{application}} of Knowledge <b>Representation</b> <b>formalisms</b> and technologies for Conceptual Modelling and Query Management are presented. It is argued that good Conceptual Modelling is required to support powerful information access through Intelligent Navigation,a fundamental task in Digital Libraries...|$|R
40|$|This paper {{presents}} {{a brief summary}} of the eight workshop on Linked Data on the Web. The LDOW 2013 workshop is held {{in conjunction with the}} World Wide Web conference 2013. The focus is on data publishing, integration and consumption using RDF and other semantic <b>representation</b> <b>formalisms</b> and technologies...|$|R
40|$|XML is the {{underlying}} <b>representation</b> <b>formalism</b> of much web-data. Thus to reason about web-data essentially {{boils down to}} reasoning about data in XML format. In this course the students learn about the main languages for querying XML data: XPath and XQuery. The course contains both theoretical work and practical examples...|$|R
40|$|Abstract. In {{the field}} of non-monotonic logics, the lexicographic closure is {{acknowledged}} as a a powerful and logically well-characterized approach; {{we are going to}} see that such a construction can be applied in {{the field of}} Description Logics, an important knowledge <b>representation</b> <b>formalism,</b> and we shall provide a simple decision procedure. ...|$|R
