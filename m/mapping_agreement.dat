6|166|Public
30|$|The results {{indicate}} that the level of disagreement between wildfire perimeter mapping methods was significant, and that the level of error in manual mapping significantly increased in areas of higher TR. This is consistent with the hypothesis that manual mapping errors {{can be attributed to the}} difficulties in mapping associated with rougher terrain. Since area burned was not significantly correlated to <b>mapping</b> <b>agreement</b> or error, the size of the fire did not alter the level of accuracy in mapping the fire perimeter.|$|E
30|$|Areas {{of greater}} terrain {{roughness}} were prone to increased manual mapping error {{on the side}} of commission. There are at least two explanations for this. First, much of the area falsely classified as burned consists of small island polygons. As described in the introduction, unburned islands within a burned area are almost always included in manually mapped fire perimeters, since it is unsafe to map these locations during or even immediately following a fire, and more efficient to simply include them in the burned area. This is visually consistent with the imagery and the published fire perimeters for this study; there are several cases where a published perimeter skirts the base of a slope or canyon instead of following the fingers of burned area that lay on ridges or in canyons. Since errors of omission were not significantly correlated to TR, the weaker significant correlation between TR and overall <b>mapping</b> <b>agreement</b> can be attributed primarily to over-mapping in the areas of higher TR.|$|E
40|$|Monitoring the sealing-over of {{the soil}} surface by {{impermeable}} material in urban environments is of great interest as a key indicator of sustainable land use. Many studies have attempted to automatically classify surface impermeability by using satellite or aerial imagery. Air photo interpretation (API) {{has been used as}} a method to verify their accuracy. However, independent accuracy assessments of API have not been widely reported. The aims of this research are, firstly, to investigate independent accuracy assessments of API. Secondly, to determine whether object-based image analysis could replace manual interpretation for the detection of sealed soil and vegetated surfaces at the residential garden plot level. Four study areas, representing the industrial, commercial and residential parts of Cambridge, UK, were manually digitised and classified by API. The same areas were automatically segmented and manually classified with the use of eCognition software, Definiens Professional 5. The two methods were compared and the average overall <b>mapping</b> <b>agreement</b> was estimated to be 92 %. The disagreement was qualitatively analysed and the advantages and disadvantages of each method were discussed. The very high agreement between the two methods in conjunction with the benefits of the automated method led to the conclusion that automated segmentation using eCognition has a considerable potential to replace the manual boundary delineation when true-colour aerial photography is used. 1...|$|E
5000|$|The {{international}} community considers all Israeli {{settlements in the}} West Bank illegal under international law, which the Israeli government disputes. However unauthorized outposts are also illegal under Israeli law. According to the 2003 road <b>map</b> <b>agreement,</b> settlements and outposts erected after March 2001 are to be dismantled.|$|R
50|$|The <b>Mapping</b> Services <b>Agreement</b> {{contract}} expired on 31 March 2012 and {{was replaced}} by the Data Co-operation Agreement.|$|R
50|$|In May 2005 local {{authorities}} in the UK signed an <b>agreement</b> (<b>Mapping</b> Services <b>Agreement)</b> with suppliers of geographic data, which included Ordnance Survey and the managers of the NLPG. This solved the issues surrounding ownership of address data and contained many restrictions {{on the use of}} LLPGs by {{local authorities}} as well as compulsions upn local authorities to maintain their LLPGs.|$|R
40|$|In Brazil, soybean {{plantations}} overcome 25 million hectares, and Mato Grosso State {{accounts for}} 27 % of this area, so that earlier information about soybean mapping and acreage {{is very important}} for traders and farmers as well as for supporting studies that require up-to-dated land mappings over crop seasons. In this paper we assessed the Crop Enhanced Index-Preview Estimate (CEI-PE) methodology which intends to provide three soybean mapping and acreage up to 45 days prior to the original CEI. We produce soybean maps over 11 crop seasons (2000 / 2001 to 2010 / 2011) using MODIS images of the Enhanced Vegetation Index (EVI). CEI in Mato Grosso uses EVI images in two key periods during soybean crop season, the first (MinEVI) is composed from Day of Year (DOY) 161 to 224 (off-season). The second (MaxEVI) is composed using EVI Images acquired during soybean peak canopy development. To provide CEI-PE we computed EVI images over three different periods, from DOY 321 to 48, 32 and 16, called MaxEVI- 49, - 33 and - 17, respectively. Then, we compared soybean acreage and <b>mapping</b> <b>agreement</b> between CEI-PE and the original CEI. The CEI-PE decreased mapping accuracy from CEI- 49 to - 33 and to - 17, with average spatial agreement of 91. 6, 82. 8 and 73. 9 %, respectively. On acreage estimation, CEI-PE showed average difference around 2. 8, 3. 6 and - 7. 8 %, for CE- 49, - 33 and - 17, respectively. Moreover, soybean acreage was generally overestimated in CEI- 49 and - 33 and underestimation in CEI- 17 compared to the original CEI. Pages: 356 - 36...|$|E
40|$|One the {{key feature}} behind Linked Data {{is the use}} of vocabularies that allow {{datasets}} to share a common language to describe similar concepts and relationships and resolve ambiguities between them. The development of vocabularies is often driven by a consensus process among datasets implementers, in which the criterion of interoperability is considered to be sufficient. This can lead to misrepresentation of real-world entities in Linked Data vocabularies entities. Such drawbacks can be fixed by the use of a formal methodology for modelling Linked Data vocabularies entities and identifying ontological distinctions. One proven example is the OntoClean methodology for curing taxonomies. In this work, it is presented a software tool that implements the PURO approach to ontological distinction modelling. PURO models vocabularies as Ontological Foreground Models (OFM), and the structure of ontological distinctions as Ontological Background Models (OBM), constructed using meta-properties attached to vocabulary entities, in a process known as vocabulary annotation. The software tool, named Background Annotation plugin, written in Java and integrated in the Protégé ontology editor, enables a user to graphically annotate vocabulary entities through an annotation workflow, that implements, among other things, persistency of annotations and their retrieval. Two kinds of workflows are supported: generic and dataset-specific, in order to differentiate a vocabulary usage, in terms of a PURO OBM, with respect to a given Linked Data dataset. The workflow is enhanced by the use of dataset statistical indicators retrieved through the Sindice service, for a sample of chosen datasets, such as the number of entities present in a dataset, and the relative frequency of vocabulary entities in that dataset. A further enhancement is provided by dataset summaries that offer an overview of the most common entity-property paths found in a dataset. Foreseen utilisation of the Background Annotation plugin include: 1) the checking of <b>mapping</b> <b>agreement</b> between different datasets, as produced by the R 2 R framework and 2) annotation of dependent resources in Concise Boundaries Descriptions of entities, used in data sampling from Linked Data datasets for data mining purposes...|$|E
40|$|Evan N Wong, 1 David A Mackey, 1 William H Morgan, 1, 2 Fred Kuanfu Chen 1, 2 1 Centre for Ophthalmology and Visual Science, (Lions Eye Institute), The University of Western Australia, Perth, WA, Australia; 2 Department of Ophthalmology, Royal Perth Hospital, Perth, WA, Australia Purpose: To {{investigate}} the intersession test–retest variability (TRV) of topography- and threshold-based parameters {{derived from the}} Nidek MP- 1. Design: Prospective observational study. Methods: Sixteen participants with and without central scotoma underwent microperimetry in one eye over three sessions at 1 -month intervals in a single institution. We calculated 95 % coefficient of repeatability (CR) {{for the number of}} normal-suspect (NS) loci, relative scotoma (RS) and dense scotoma (DS), median macular sensitivity (MS), mean sensitivity of responding loci (RLS), perilesional loci (PLS), and extralesional loci (ELS). Topographical agreement score of mapping NS and DS loci (TASNS and TASDS) were also calculated for each patient. Results: Mean (range) age was 50 (21 – 86) years. The CR (95 % confidence intervals) for NS, RS, and DS were 9. 9 (6. 5 – 13. 3), 9. 5 (6. 2 – 12. 7), and 3. 0 (1. 1 – 4. 1) respectively. CR (95 % CIs) for median MS, mean RLS, PLS, and ELS were 3. 4 (2. 3 – 4. 5), 1. 6 (1. 1 – 2. 2), 1. 8 (0. 9 – 2. 6), and 2. 8 (1. 5 – 4. 0) dB. We found significant change in thresholds between Test 1, and Tests 2 and 3 (both P= 0. 03), but not between Tests 2 and 3 (P= 0. 8). Medians (range) TASNS and TASDS were 74 % (39 %– 100 %) and 77 % (0 %– 97 %), respectively, between Tests 2 and 3. Conclusion: We recommend the use of four DS loci (upper limit of CR) as the limit of TRV for assessing change. There was large interindividual variability in NS or DS <b>mapping</b> <b>agreement.</b> We recommend discarding the first microperimetry test and caution the use of a change in spatial distribution to determine disease progression. Keywords: test–retest variability, TASNS, TASDS, Nidek MP-...|$|E
5000|$|Grease pencils {{were used}} on the Sykes-Picot <b>Agreement</b> <b>map</b> in 1916 ...|$|R
5000|$|... #Caption: Sykes Picot <b>Agreement</b> <b>Map,</b> an {{enclosure}} in Paul Cambon's {{letter to}} Sir Edward Grey, 9 May 1916 ...|$|R
40|$|SUSTAIN {{wishes to}} {{acknowledge}} its appreciation {{to all the}} individuals, institutions and companies who helped to design, implement and evaluate {{the results of the}} MAP study. Our particular thanks and appreciation is extended to USAID Officers Dr. Tom Marchione (USAID/BHR/PPE), the technical officer for the <b>MAP</b> cooperative <b>agreement,</b> Dr. Sam Kahn (USAID/G/PHN/HN) and to the industry expert...|$|R
50|$|The <b>Mapping</b> Services <b>Agreement</b> (MSA) is a {{licensing}} contract between local {{authorities in the}} United Kingdom and suppliers of geographic data. Most of its contents are covered by commercial in confidence requirements. The general outcome of the MSA, however, is the supply of geographic data to local authorities and the defining of licensing issues regarding address data.|$|R
40|$|Localization is a {{critical}} issue in mobile robotics. If a robot does not know where it is, it cannot effectively plan movements, locate objects, or reach goals. In this paper, we describe probabilistic self-localization techniques for mobile robots {{that are based on}} the principle of maximum-likelihood estimation. The basic method is to compare a map generated at the current robot position with a previously generated map of the environment in order to probabilistically maximize the <b>agreement</b> between the <b>maps.</b> This method is able to operate in both indoor and outdoor environments using either discrete features or an occupancy grid to represent the world map. The map may be generated using any method to detect features in the robot's surroundings, including vision, sonar, and laser range-finder. We perform an efficient global search of the pose space that guarantees that the best position is found according to the probabilistic <b>map</b> <b>agreement</b> measure in a discretized pose space. In additio [...] ...|$|R
30|$|The line {{profiles}} {{across the}} reconstructed phase <b>maps</b> show good <b>agreement</b> {{between the three}} different reconstruction results for fine details, but they also highlight the large differences at low spatial frequencies.|$|R
40|$|Two {{approaches}} to the microscopical derivation of the interacting boson model are examined and compared. The first one is the well-known Otsuka-Arima-Iachello method as extended to a multishell case by using the generalized seniority scheme or exact calculations in the seniority equal to 0 and 2 space. The second one is a procedure based on the similarity transformed Dyson <b>mapping.</b> Close <b>agreement</b> between the two approaches is found...|$|R
50|$|On September 7, 2004, the National Highway Authority (Dirección Nacional de Vialidad) and Provincial Highway Authority (Administración de Vialidad Provincial) {{signed an}} {{agreement}} exchanging Provincial Route 62 between Tecka and Pampa de Agnia (paved between 1974 and 1976) for National Route 25 (unpaved) between Pampa de Agnia and National Route 40 (marked in green on the <b>map).</b> This <b>agreement</b> was ratified by Provincial Law 5486 promulgated on May 31, 2006.|$|R
50|$|In May 2005 the <b>Mapping</b> Services <b>Agreement</b> (MSA) {{was signed}} with local authorities. This {{was part of}} a long drawn out process of {{procurement}} for mapping data and included management of the NSG and the NLPG. The outcome of agreement involved the loss of the custodianship by OS of the NSG which was awarded to the data management company Intelligent Addressing Ltd who were already managers of the NLPG.|$|R
40|$|United States Agency for International Development iACKNOWLEDGEMENTS SUSTAIN {{wishes to}} {{acknowledge}} its appreciation {{to all the}} individuals, institutions and companies who helped to design, implement and evaluate {{the results of the}} MAP study. Our particular thanks and appreciation is extended to USAID Officers Dr. Tom Marchione (USAID/BHR/PPE), the technical officer for the <b>MAP</b> cooperative <b>agreement,</b> Dr. Sam Kahn (USAID/G/PHN/HN) and to the industry experts and other specialists who contributed invaluable volunteer expertise and guidance to this study...|$|R
40|$|We {{present a}} novel {{approach}} for the derivation of the X-ray temperature function for galaxy clusters, {{which is based on}} the statistics of Gaussian random fields applied to the cosmic gravitational potential. It invokes only locally defined quantities so that no reference to the cluster's mass is made. To relate linear and non-linear potential and to take into account only structures that have collapsed, we include either spherical- or ellipsoidal-collapse dynamics and compare both resulting models to temperature functions derived from a numerical simulation. Since deviations from the theoretical prediction are found in the simulation for high redshifts, we develop an analytic model to include the effects of mergers in our formalism. We jointly determine the cosmological parameters Omega_m 0 and sigma_ 8 from two different cluster samples for different temperature definitions and find good agreement with constraints from WMAP 5. Introducing theoretically a refined detection definition based on the upcrossing criterion, we reformulate our analytic approach for 2 D and use it to predict the number density of spurious detections caused by large-scale structure and shot noise in filtered weak-lensing convergence <b>maps.</b> <b>Agreement</b> with a numerical simulation is found at the expected level...|$|R
40|$|Two {{modified}} mapping {{tables that}} convert Abbreviated Injury Scale (AIS) 98 codes to AIS 2008 codes have been separately developed by Palmer et al. (P-map) and Tohira et al. (T-map). We aimed {{to determine which}} map gives the most accurate code conversion. We computed the intraclass correlation coefficients for the Injury Severity Score (ISS), the New ISS (NISS) and the Maximum AIS (MAIS) of six body regions using the mapped AIS 2008 codes and the manually determined AIS 2008 codes (gold standard). We also applied post-hoc severity adjustment to the mapped AIS 2008 codes. The ISS and NISS based on the two <b>maps</b> showed substantial <b>agreement</b> with the gold standard. The chest region MAIS of the P-map and the extremities region MAIS of both <b>maps</b> demonstrated moderate <b>agreement</b> with the gold standard, while the MAISs of the other regions displayed substantial agreement. The post-hoc severity adjustment for the P-map significantly improved the agreement for the chest region MAIS. The injury severity scores based on the two <b>maps</b> displayed similar <b>agreement</b> with the gold standard. The post-hoc severity adjustment provided by the P-map might be better at adjusting for severity levels than that provided by the T-map...|$|R
40|$|Abstract. The paper {{presents}} application on {{digital image}} correlation (DIC) and microindentation for investigation of plastic flow under Brinell ball indenter applied on steel specimen made of two screwed together parts. Specimens {{in two different}} material state (a) as delivered (b) annealed were investigated. This approach enables internal surface to act as the external one and to be examined by mentioned methods. Results obtained by application of DIC on scanning electron microscope (SEM) images are compared to microhardness <b>maps</b> and <b>agreement</b> is demonstrated...|$|R
40|$|Abstract—Localization is a {{critical}} issue in mobile robotics. If a robot does not know where it is, it cannot effectively plan movements, locate objects, or reach goals. In this paper, we describe probabilistic self-localization techniques for mobile robots {{that are based on}} the principle of maximum-likelihood estimation. The basic method is to compare a map generated at the current robot position with a previously generated map of the environment in order to probabilistically maximize the <b>agreement</b> between the <b>maps.</b> This method is able to operate in both indoor and outdoor environments using either discrete features or an occupancy grid to represent the world map. The map may be generated using any method to detect features in the robot’s surroundings, including vision, sonar, and laser range-finder. We perform an efficient global search of the pose space that guarantees that the best position is found according to the probabilistic <b>map</b> <b>agreement</b> measure in a discretized pose space. In addition, subpixel localization and uncertainty estimation are performed by fitting the likelihood function with a parameterized surface. We describe the application of these techniques in several experiments, including experimental localization results for the Sojourner Mars rover. Index Terms—Maximum-likelihood estimation, mobile robotics, self-localization, uncertainty estimation. I...|$|R
40|$|We {{present a}} {{scanning}} antenna probe that provides 35 nm optical hotspots with a 16 -fold excitation enhancement. A resonant optical antenna, tuned to {{operation in the}} visible, is carved into the aluminum-coated scanning probe. The antenna resonances, field localization, excitation, and polarization response are probed in the near-field by scanning over single fluorescent nanobeads. At the same time, the distance-dependent coupling of the emission to the antenna mode is <b>mapped.</b> Good <b>agreement</b> with theory is obtained. The presented scanning antenna approach is useful for both nanoscale plasmonic mode imaging and (bio) imagin...|$|R
40|$|We {{present a}} semiclassical {{prediction}} of regular- to- chaotic tunneling in systems with a mixed phase space, including {{the effect of}} a nonlinear resonance chain. We identify complex paths for direct and resonance- assisted tunneling in the phase space of an integrable approximation with one nonlinear resonance chain. We evaluate the resonance- assisted contribution analytically and give a prediction based on just a few properties of the classical phase space. For the standard <b>map</b> excellent <b>agreement</b> with numerically determined tunneling rates is observed. The results should similarly apply to ionization rates and quality factors...|$|R
40|$|Documents {{housed in}} Folder 21 of President Kelly Thompson 2 ̆ 7 s Subject/Correspondence File {{regarding}} urban renewal in Jonesville. Includes correspondence, project budgets, planning <b>map</b> and <b>agreements.</b> Agreement between Bowling Green Urban Renewal 2 ̆ 6 Community Development Agency 2 ̆ 6 WKU, 4 / 16 / 1965 Bates, Georgia Downing, Dero Kentucky. Dept. of Finance Jonesville Lawson, Owen Milliken 2 ̆ 6 Milliken Resolution That the Commission Council Amend the Jonesville Urban Renewal Loan 2 ̆ 6 Grant Contract to Include an Additional 25, 000. 00 Non Cash Credit, nd Taylor, J. H. Thompson, Kelly Urban Renewal 2 ̆ 6 Community Development Agenc...|$|R
40|$|We {{show that}} Steady-state Ab initio Laser Theory (SALT) {{can be applied}} to find the {{stationary}} multimode lasing properties of an N-level laser. This is achieved by mapping the N-level rate equations to an effective two-level model of the type solved by the SALT algorithm. This <b>mapping</b> yields excellent <b>agreement</b> with more computationally demanding N-level time domain solutions for the steady state...|$|R
40|$|As {{wildfires}} {{becomes an}} increasingly important issue affecting our nation’s landscapes, fire managers must quickly assess possible adverse fire effects to efficiently allocate resources for rehabilitation or remediation. While burn severity maps derived from satellite imagery can provide a landscape view of relative fire impacts, fire effects simulation models can also provide spatial fire severity estimates along with the biotic context in which to interpret severity. In this project, we evaluated two methods of mapping burn severity for four wildfires in western Montana using 64 plots as field reference: 1) an image-based burn severity mapping approach using the Differenced Normalized Burn Ratio (ΔNBR), and 2) a fire effects simulation approach using the FIREHARM model. We compared the ability of these two approaches to estimate field-measured fire effects {{and found that the}} image-based approach was moderately correlated to percent tree mortality (r = 0. 53) but had no relationship with percent fuel consumption (r = - 0. 04). The FIREHARM model was moderately correlated with percent fuel consumption (0. 33) and weakly correlated with percent tree mortality (r = 0. 18). Burn severity maps produced by the two approaches were quite variable with <b>map</b> <b>agreement</b> ranging from 33. 5 % and 64. 8 % for the four sampled wildfires. Both approaches had the same overall map accuracies when compared to a sampled composite burn index (57. 8 %). Though there are limitations to both approaches, we believe these techniques could be used synergistically to improve burn severity mapping capabilities of land managers, enabling them to meet rehabilitation objectives quickly and effectively...|$|R
40|$|Land-use and land-cover {{changes are}} driving {{unprecedented}} changes in ecosystems and environmental processes at different scales. This study {{was aimed at}} identifying the potential land-use drivers in the Jedeb catchment of the Abbay basin by combining statistical analysis, field investigation and remote sensing. To do so, a land-use change model was calibrated and evaluated using the SITE (SImulation of Terrestrial Environment) modelling framework. SITE is cellular automata based multi-criteria decision analysis framework for simulating land-use conversion based on socio-economic and environmental factors. Past land-use trajectories (1986 – 2009) were evaluated using a reference Landsat-derived <b>map</b> (<b>agreement</b> of 84 %). Results show that major land-use change drivers {{in the study area}} were population, slope, livestock and distances from various infrastructures (roads, markets and water). It was also found that farmers seem to increasingly prefer plantations of trees such as Eucalyptus by replacing croplands perhaps mainly due to declining crop yield, soil fertility and climate variability. Potential future trajectory of land-use change was also predicted under a business-as-usual scenario (2009 – 2025). Results show that agricultural land will continue to expand from 69. 5 % in 2009 to 77. 5 % in 2025 in the catchment albeit at a declining rate when compared with the period from 1986 to 2009. Plantation forest will also increase at a much higher rate, mainly at the expense of natural vegetation, agricultural land and grasslands. This study provides critical information to land-use planners and policy makers for a more effective and proactive management in this highland catchment...|$|R
40|$|In generic Hamiltonian systems tori {{of regular}} motion are {{dynamically}} separated from regions of chaotic motion in phase space. Quantum mechanically these phase-space regions are coupled by dynamical tunneling. We introduce a semiclassical approach based on complex paths for {{the prediction of}} dynamical tunneling rates from regular tori to the chaotic region. This approach is demonstrated for the standard <b>map</b> giving excellent <b>agreement</b> with numerically determined tunneling rates. Comment: 5 pages, 4 figure...|$|R
40|$|A {{rule-based}} classification {{model was}} developed to derive land-cover information from a large set of hyper-temporal, multi-spectral satellite imagery encompassing the state of Arizona. The model uses Advanced Very High Resolution Radiometer (AVHRR) imagery and the 30 -minute digital elevation model (DEM) from the EROS Data Center (EDC) Conterminous U. S. AVHRR Biweekly Composites. Sixty one images from 1990, 1991 and 1992 were analyzed using the Brown & Lowe (1973) Natural Vegetative Communities of Arizona map to identify temporal patterns of Normalized Difference Vegetation Index (NDVI) and thermal measurements for 13 land-cover classes. Fifteen characteristic layers were created to represent the spectral, thermal and temporal properties of the data set. These layers were inputs for the rule-based classification model. The model was run on three years of data, creating three single year land-cover maps. The modeling effort showed that NDVI, thermal and DEM characteristics are useful for discerning land-cover classes. The single year land-cover maps showed that the rule-based model could not detect land-cover change between years. The single year maps were combined to create a summary land-cover map. This map differs from the Brown and Lowe map in the shape, proportional size and spatial distribution of land-cover polygons. The rule-based model can discern more land-cover classes than spectral cluster classification. Ground observations and an aerial video {{was used to assess}} map accuracy. The same proportion of agreement was observed between the ground observations, the Brown and Lowe map, and the summary land-cover <b>map.</b> <b>Agreement</b> was higher between video and the summary map than between video and the Brown and Lowe map. With further refinements to the input data set, classification model rules and field accuracy assessment, higher levels of agreement can be expected. Overall results show that rule-based classification of hyper-temporal, multi-spectral satellite imagery is a desirable method for mapping global land-cover...|$|R
40|$|ABSTRACT: Electron {{tomography}} {{in combination}} with electron energy-loss spectroscopy (EELS) experiments and simulations was used to unravel the interplay between structure and plasmonic properties of a silver nanocuboid dimer. The precise 3 D geometry of the particles fabricated by means of electron beam lithography was reconstructed through electron tomography, and the full three-dimensional information {{was used as an}} input for simulations of energy-loss spectra and plasmon resonance <b>maps.</b> Excellent <b>agreement</b> between experiment and theory was found throughout, bringing the comparison between EELS imaging and simulations to a quantitative and correlative level. In addition, interface mode patterns, normally masked by the projection nature of a transmission microscopy investigation, could be unambiguously identified through tomographic reconstruction. This work overcomes the need for geometrical assumptions or symmetry restrictions of the sample in simulations and paves the way for detailed investigations of realistic and complex plasmonic nanostructures...|$|R
40|$|Abstract. To date, most identity-based key {{agreement}} protocols {{are based}} on a single PKG (Private Key Generator) environment. In 2002, Chen and Kudla proposed an identity-based key agreement protocol for a multiple PKG environment, where each PKG shares identical system parameters but possesses a distinct master key. However, it is more realistic to assume that each PKG uses different system parameters. In this paper, we propose a new two party key agreement protocol between users belonging to different PKGs that do not share system parameters. We also extend this protocol to a tripartite key agreement protocol. Our two party protocol requires the same amount of pairing computation as Smart’s protocol for a single PKG environment and provides PKG forward secrecy. We show that the proposed key agreement protocols satisfy every security requirements of key agreement protocols. Keywords: ID-based cryptosystem, bilinear <b>map,</b> key <b>agreement</b> protocol, multiple PKG. ...|$|R
2500|$|Documents {{from the}} 1920s and 1930s {{indicate}} that some local inhabitants regarded themselves {{as part of}} Lebanon, but after the French mandate ended in 1946 the land was administered by Syria, and represented as such on maps of the time, including 1949 Armistice <b>Agreement</b> <b>maps</b> and Syrian and Lebanese military maps. [...] Shebaa Farms were then occupied by Israel in the 1967 Six-Day War. According to BBC, Syria agrees with Lebanon that Shebaa farms [...] is part of Lebanon. Syria accepts the Lebanese claim but refuses any binding demarcation.|$|R
40|$|The European Council's Maastricht <b>Agreement</b> <b>maps</b> out {{a precise}} route to {{monetary}} {{union and the}} eventual introduction of a common currency. My discussion begins {{with a look at}} the general arguments for and against monetary union. I shall then discuss the proposed constitution of the European Central Bank and whether it is likely to be conducive to monetary stability, together with some of the problems posed by the transition to the new regime. Finally, I will turn to the issue of rules for the conduct of fiscal policy and the question of "fiscal federalism. "...|$|R
5000|$|Documents {{from the}} 1920s and 1930s {{indicate}} that some local inhabitants regarded themselves {{as part of}} Lebanon, but after the French mandate ended in 1946 the land was administered by Syria, and represented as such on maps of the time, including 1949 Armistice <b>Agreement</b> <b>maps</b> and Syrian and Lebanese military maps. [...] Shebaa Farms were then occupied by Israel in the 1967 Six-Day War. According to BBC, Syria agrees with Lebanon that Shebaa farms is part of Lebanon. Syria accepts the Lebanese claim but refuses any binding demarcation.|$|R
