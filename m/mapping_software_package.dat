3|10000|Public
50|$|Dick Banks, a Colorado School of Mines graduate, and Joe Sukkar, Ph.D, began a {{partnership}} in 1969 {{with the development}} of a contour <b>mapping</b> <b>software</b> <b>package</b> based on Triangulation (topology). Triangulation is more rigorous than gridded contour map software because the original data points are always honored, and not estimated as in Grid map software.|$|E
40|$|Abstract. Complex {{reasoning}} and argumentation {{are central to}} legal practice. Software-supported argument mapping {{may be able to}} help lawyers reason and argue more effectively. This article describes Rationale™, a generic argument <b>mapping</b> <b>software</b> <b>package,</b> and reviews some evidence that using it can help improve reasoning, i. e., make people smarter. It then explores three different explanations for this potential benefit: usability, complementation, and semi-formality. First, argument mapping software can be more usable for reasoning activities than traditional methods because it can inherit the wisdom gained through decades of research and experience into usability; can exploit a wider range of representational resources; and is designed specifically to support reasoning activities. Second, such software works by complementing {{the strengths and weaknesses of}} our natural or inbuilt cognitive capacities. Third, it helps shift {{reasoning and}} argumentation into a semi-formal mode, a kind of “swee...|$|E
40|$|OBJECTIVE: To perform voxel-wise {{assessments}} of regional brain atrophy state and rate {{in subjects with}} relapsing-remitting (RR) multiple sclerosis (MS). BACKGROUND: Recently, attention has focused on defining the tissue compartments and regions within which brain atrophy occurs. These regional measures of brain volume changes may help to better define {{the nature of the}} pathology underlying MS. In this context, specific regional measures of grey matter (GM) volume changes can be obtained by using the voxel-based morphometry (VBM) approach. METHODS: Fifty-nine subjects with RR MS underwent conventional MRI at baseline and after a mean follow-up period of 3 years. Cross-sectionally, two VBM analyses (SPM-VBM, based on the Statistical Parametric <b>Mapping</b> <b>software</b> <b>package,</b> and FSL-VBM, based on the FMRIB Software Library tools) were performed to assess cortical GM volumes in RR MS patients compared to 25 age- and sex-matched normal controls (NC). Longitudinally, FSL-VBM and the regional extension of the SIENA method (SIENAr) were both used to assess regional brain atrophy rate in the RR MS patients and its relationship with increases in T(2) -weighted white matter (WM) lesion volume over the follow-up period. RESULTS: Widespread decrease in cortical GM volume was found in the RR MS patients compared to NC. Both SPM-VBM and FSL-VBM showed similar involvement of cortical regions (frontal, temporal, parietal, occipital lobes and insula), with a close correlation between the numbers of significant voxels obtained with the two different procedures (r= 0. 73, p< 0. 001). After 3 -year follow-up, both FSL-VBM and SIENAr showed a further significant reduction in GM volume in the lateral frontal and parietal cortices, bilaterally. Regional volume changes also appeared significantly pronounced in correspondence to the increase in T(2) -weighted WM lesion volume over the follow-up period. CONCLUSIONS: By using different methodologies, we showed similar widespread tissue loss in the cerebral cortex of patients with RR MS. This brain tissue loss further progresses over time, particularly in the fronto-parietal cortex and seems to be partially dependent upon the increase of lesion load...|$|E
50|$|The main {{practical}} {{challenge in}} the LAMP approach was {{finding a way to}} enable students to engage in extensive deliberate practice of reasoning skills. To confront this, van Gelder and his colleague Andy Bulka developed the argument <b>mapping</b> <b>software</b> <b>packages</b> Reason!Able (2000) and Rationale (2006).|$|R
5000|$|As {{with other}} mind <b>mapping</b> <b>software</b> <b>packages,</b> FreeMind allows {{the user to}} edit a {{hierarchical}} set of ideas around a central concept. The non-linear approach assists in brainstorming new outlines and projects as ideas are added around the mind map. [...] As a Java application, FreeMind is portable across multiple platforms and retains the same user interface, causing some amount of variation from the common interface on each platform. Mac users may notice the most difference from their traditional user interface, but a MacWorld reviewer says the software's features should still appeal to the segment of users who accept function over form.|$|R
40|$|Heterozygous {{chromosome}} rearrangements such as recip-rocal translocations {{are most}} accurately displayed as two-dimensional linkage maps. Standard linkage <b>mapping</b> <b>software</b> <b>packages,</b> such as MapMaker, generate only one-dimensional maps and so reciprocal translocations appear as clusters of markers, {{even though they}} originate from two nonhomolo-gous chromosomes. To more accurately map these regions, researchers have developed statistical methods that use the variance in map distance to distinguish among the four segments (two translocation, two interstitial) of the translo-cation. In this study, we describe modifications {{to one of these}} protocols, that proposed by Livingstone et al. (2000). We also introduce QuadMap, a new software application for dissect-ing heterozygous translocation-affected linkage maps...|$|R
40|$|Abstract: Defined in {{the early}} 1990 s for use with gridded {{satellite}} passive microwave data, the Equal-Area Scalable Earth Grid (EASE-Grid) was quickly adopted and used for distribution {{of a variety of}} satellite and in situ data sets. Conceptually easy to understand, EASE-Grid suffers from limitations that make it impossible to format in the widely popular GeoTIFF convention without reprojection. Importing EASE-Grid data into standard <b>mapping</b> <b>software</b> <b>packages</b> is nontrivial and error-prone. This article defines a standard for an improved EASE-Grid 2. 0 definition, addressing how the changes rectify issues with the original grid definition. Data distributed using the EASE-Grid 2. 0 standard will be easier for users to import into standard <b>software</b> <b>packages</b> and will minimize common reprojection errors that users had encountered with the original EASE-Grid definition...|$|R
40|$|Due to {{the fact}} that {{morphology}} and perinatal growth of the piglet brain is similar to humans, use of the piglet as a translational animal model for neurodevelopmental studies is increasing. Magnetic resonance imaging (MRI) can be a powerful tool to study neurodevelopment in piglets, but many of the MRI resources have been produced for adult humans. Here, we present an average in vivo MRI-based atlas specific for the 4 -week-old piglet. In addition, we have developed probabilistic tissue classification maps. These tools can be used with brain <b>mapping</b> <b>software</b> <b>packages</b> (e. g. SPM and FSL) to aid in voxel-based morphometry and image analysis techniques. The atlas enables efficient study of neurodevelopment in a highly tractable translational animal with brain growth and development similar to humans...|$|R
40|$|QTLNetworkR is an R {{package that}} aims to provide a {{user-friendly}} and platform-independent tool to visualize quantitative trait loci (QTL) mapping results. The graphical functions of the QTLNetworkR are based upon lattice and grid packages, and the graphical user interface (GUI) of the QTLNetworkR is built upon RGtk 2 and gWidgetsRGtk 2 packages. Six functions {{are designed to help}} visualize marker interval, putative QTL, QTL-by-environment interactions, marker interval interactions, epistasis, and the predicted genetic architecture of complex traits. It is especially helpful in profiling results for multiple traits at multiple environments. The current version of QTLNetworkR is able to accept QTL mapping results from QTLNetwork, and it is ready for possible extensions to import results from some other QTL <b>mapping</b> <b>software</b> <b>packages.</b> In addition, we presented a QTL mapping result in rice (Oryza sativa) as an example to describe the features of QTLNetworkR...|$|R
50|$|Another common atlas for {{the human}} brain is the Montreal Neurological Institute and Hospital (MNI) {{coordinate}} system, which is the template used for SPM and the International Consortium for Brain <b>Mapping.</b> Most neuroimaging <b>software</b> <b>packages</b> are able to convert from Talairach to MNI coordinates.|$|R
40|$|Botanical gardens, as {{stewards}} of living plant collections, {{are given the}} duty of managing the data concerning their collection. These data are both historical and geographical. Since the 1950 s, people have been working to manage their geographic data using a system of computer modeling. This system has evolved into what is now commonly known as a Geographic Information System (GIs). This study looks at the database and <b>mapping</b> <b>software</b> system combinations currently in use at botanical institutions. A compiled list of forty-nine named institutions shows the reader what combinations are in current use. This study is written for institutions that already have a computerized database in place, and are seeking information on choosing a computerized mapping system. A discussion {{of the history of}} Computer Aided Drafting (CAD), Geographic Information System (GIS) and computer mapping in general, educates and prepares the reader to become familiar with particular <b>software</b> <b>packages.</b> A literature and history review provides the reader with resources for more information on database systems if they do not currently have one implemented in their institution. Plant mapping professionals rank a series of 20 questions on the importance of computerized <b>mapping</b> <b>software</b> to the institutional needs. The three most commonly utilized <b>mapping</b> <b>software</b> <b>packages</b> were then evaluated on a point-by- point basis to determine which software options most completely fulfills the garden users' stated desires. One software choice was found to be the most flexible for the garden users' stated desires...|$|R
50|$|Mapping eQTLs is done using {{standard}} QTL mapping {{methods that}} test {{the linkage between}} variation in expression and genetic polymorphisms. The only considerable difference is that eQTL studies can involve a million or more expression microtraits. Standard gene <b>mapping</b> <b>software</b> <b>packages</b> can be used, although it is often faster to use custom code such as QTL Reaper or the web-based eQTL mapping system GeneNetwork. GeneNetwork hosts many large eQTL mapping data sets and provide access to fast algorithms to map single loci and epistatic interactions. As is true in all QTL mapping studies, the final steps in defining DNA variants that cause variation in traits are usually difficult and require {{a second round of}} experimentation. This is especially the case for trans eQTLs that do not benefit from the strong prior probability that relevant variants are in the immediate vicinity of the parent gene. Statistical, graphical, and bioinformatic methods are used to evaluate positional candidate genes and entire systems of interactions.|$|R
30|$|Data {{for this}} study come from Japan Meteorological Agency (JMA), Kyushu University, and Kagoshima University as well as National Research Institute for Earth Science and Disaster Resilience (NIED). We also {{acknowledge}} {{that all of the}} maps were created using the GMT (Generic <b>Mapping</b> Tools) <b>software</b> <b>package.</b> We {{would like to thank the}} anonymous reviewers for their helpful and constructive comments that greatly contributed to improving the letter. We would also like to thank the Editor, Takuya Nishimura, for their generous comments and support during the review process.|$|R
5000|$|GeoJSON is {{supported}} by numerous <b>mapping</b> and GIS <b>software</b> <b>packages,</b> including OpenLayers, Leaflet, MapServer, Geoforge software, GeoServer, GeoDjango, PointPlot, [...] GDAL, Safe Software FME, and CartoDB. It is also possible to use GeoJSON with PostGIS and Mapnik, both of which handle the format via the GDAL OGR conversion library. Bing Maps, Yahoo! and Google also support GeoJSON in their API services.|$|R
40|$|China {{still use}} sketch maps as control devices that {{guarantees}} consistency {{and accuracy of}} population counting in previous census. Although the rapid advancement of geospatial technologies provides many possible solutions of digital census mapping, existing researches do not answer which solution is suitable to China. Subject to many constraints originated from characteristics of China, a practical solution of census mapping based on remote sensing imagery and auxiliary geographic information was proposed and proved to be feasible through evaluation analysis and a three-stage pilot study. Imagery with 2. 5 meters and higher resolution, innovative workflow of census areas delineation, easy-to-use census <b>mapping</b> <b>software</b> <b>packages</b> and training organization all together provide the all-around supports for the 2010 rounded census (the 6 th census) mapping activities. A digital census geographic framework detailed {{at the level of}} enumeration area was established in the 2010 rounded census which fills in the gaps in the field of modern geospatial census in China. The spatially referenced digital census database, especially the detailed census units, is of great value in successive census, sampling survey and many other census-related fields. Future work including quality evaluation of census areas, census mapping solution in the Tibet Autonomous Region are also discussed...|$|R
40|$|We have {{developed}} an integrated physical <b>mapping</b> computer <b>software</b> <b>package</b> (IMP), originally designed to support the physical mapping of human chromosome 13 and expanded to support several gene-identification projects based on the positional candidate approach. IMP displays map data {{in a form that}} provides useful guidelines to the end users. An integrated map with high resolution and confidence is constructed from different types of mapping data, including hybridization experiments, STS-based PCR assays, genetic linkage mapping, cDNA localization, and FISH data. The map is also designed to provide suggestions for specific experiments that are required to obtain maps with even higher resolution and confidence. To this end, the optimization employs multiple constraints that take into account already established STS “scaffold ” <b>maps.</b> This <b>software</b> thus serves as an important general tool kit for physical mapping, sequencing, and gene-hunting projects. © 1999 Academic Pres...|$|R
40|$|Initiative {{project has}} uniquely {{combined}} recently developed tools {{to produce and}} publish on the Internet near-real-time maps of forecast or imminent flooding. The tools used by the project include powerful desktop computers, Light Detection and Ranging (LIDAR) topographic data, a robust two-dimensional (2 -D) flow model, GIS, and Internet <b>map</b> server <b>software.</b> The pilot study selected a 23 -kilometer reach of the Snoqualmie River east of Seattle, Washington, that is between Snoqualmie Falls and Carnation, Washington. The study developed a 2 -D model based on LIDAR topographic data. GIS tools were used to process elevation data for the flow model and to process model generated flow information into maps. An Internet <b>map</b> server <b>software</b> <b>package</b> was used to post the flow maps to the Internet. The pilot study demonstrates the feasibility of combining these tools with National Weather Service flow forecasts to produce storm-specific areal flood information maps that are served near-real-time (in a matter of hours, depending on {{the duration of the}} forecast hydrograph) on a flexible and user-friendly Internet Web page...|$|R
30|$|We thank T. Yoshida, T. Kubota, T. Shiina, and R. Takagi at Tohoku University and E. Tani at Kyoto University for {{fruitful}} discussions. The {{comments from}} the Lead Guest Editor Y. Iio and two anonymous reviewers are very helpful in revising the manuscript. We used the unified earthquake catalog of the Japan Meteorological Agency (JMA) and the F-net focal mechanism catalog of the National Research Institute for Earth Science and Disaster Resilience. We also used a seamless digital geological map of Japan compiled by the Geological Survey of Japan at the National Institute of Advanced Industrial Science and Technology. The figures in this paper were prepared using the Generic <b>Mapping</b> Tools (GMT) <b>software</b> <b>package</b> (Wessel and Smith 1998).|$|R
50|$|Concurrently, Carl Reed did an {{inventory}} of existing public domain and commercial GIS technology. Approximately 70 different <b>mapping</b> and GIS <b>software</b> <b>packages</b> were identified. Of these, 54 had enough documentation and basic required functionality to warrant further analysis in terms of matching GIS functionality against user requirements. This document is a valuable historical document as it has information and details of systems long extinct and forgotten. The evaluation resulted in the determination that no existing GIS capability provided even {{a fraction of the}} functional capability required to meet user needs. Therefore, {{the decision was made to}} design and program a new interactive GIS application that used existing publicly available software whenever possible.|$|R
40|$|AbstractThe MEG/EEG inverse {{problem is}} ill-posed, giving {{different}} source reconstructions {{depending on the}} initial assumption sets. Parametric Empirical Bayes allows one to implement most popular MEG/EEG inversion schemes (Minimum Norm, LORETA, etc.) within the same generic Bayesian framework. It also provides a cost-function {{in terms of the}} variational Free energy—an approximation to the marginal likelihood or evidence of the solution. In this manuscript, we revisit the algorithm for MEG/EEG source reconstruction with a view to providing a didactic and practical guide. The aim is to promote and help standardise the development and consolidation of other schemes within the same framework. We describe the implementation in the Statistical Parametric <b>Mapping</b> (SPM) <b>software</b> <b>package,</b> carefully explaining each of its stages {{with the help of a}} simple simulated data example. We focus on the Multiple Sparse Priors (MSP) model, which we compare with the well-known Minimum Norm and LORETA models, using the negative variational Free energy for model comparison. The manuscript is accompanied by Matlab scripts to allow the reader to test and explore the underlying algorithm...|$|R
40|$|Semi-automated object {{extraction}} {{has been}} established as a standard procedure for the efficient generation of 3 D city models. Apart from aerial imagery, satellite imagery and laserscanner data {{turned out to be}} an additional source to create virtual city models. CyberCity-Modeler (CC-Modeler™) as a tool for the generation and optimisation of 3 D city and plant models has been used in a range of projects with different requirements. Therefore modules have been developed and integrated to the main <b>software</b> <b>package</b> to improve functionality. CC-Modeler ™ consists of four modules: CC-Modeler for topological structuring, CC-Edit for improving geometry, CC-Mapping for integration of wall texture and CC-Digit for integration of digitised data from <b>maps.</b> Concerning the <b>software</b> <b>package</b> CC-Modeler™, some functions as geometrical regularisation of buildings, editing functions for topology adjustment, modeling of overhanging roofs, adding attributes to objects, mapping from texture libraries, generation of corridors etc. are explained in this paper. Additionally, the use of satellite and laserscanner data for the efficient generation of 3 D city models as an alternative or supplement to aerial images is discussed and the progress in real-time visualisation of 3 D city models is presented. ...|$|R
40|$|This study covers tourism {{destinations}} {{which include}} beach, Museums, Parks and resorts, hotels, restaurants, clubs, bars, cinemas and fitness centres, {{as well as}} complementing tourism destination Services which includes police post, clinics and hospital in Victoria Island Lagos and how the utilisation of GIS technology can be use to improved tourism management. Also to model accessibility to these points of interest mentioned above using Geographic information system analytical tools and functions. Geographic coordinates of the location of all bars, clubs, restaurants, cinema, fitness centre, hospital, clinic, police post and various tourists destination have been picked with their corresponding attributes to build a database using Arc <b>Map</b> 9. 3 <b>software</b> <b>package</b> Geo database. Analyses to aid decision for management and future planning was carried out using the spatial statistical tools in the GIS application used for this study. The analysis included central Feature analysis which was used to model area central to Tourism Facilities, Tourism services and Tourisms Destinations in Victoria Island...|$|R
40|$|Creating {{a visual}} {{representation}} of {{data can be}} very useful way to demonstrate patterns that are not readily apparent in a table. Carnegie Mellon University’s Institutional Research office uses SAS <b>mapping</b> <b>software</b> to display data in a user-friendly way. SAS 9. 3 now allows anyone to make maps using the base <b>software</b> <b>package.</b> This poster shows the reader how to output Institutional Research data using the SAS GMAP procedure. Examples include maps displaying enrollment, alumni, and study abroad data...|$|R
50|$|The {{mind mapping}} {{technology}} of visual thinking {{was invented by}} Tony Buzan in the 1960s.Along with the traditional practice of hand-drawn mind maps there is a range of special mind <b>mapping</b> <b>software,</b> which is commonly used to create mind maps for purposes of business, project management and knowledge management.The first version of ConceptDraw MINDMAP was released in 2001. Since 2008 {{it has been a}} part of the ConceptDraw Office <b>software</b> <b>package</b> for Windows and macOS platform.|$|R
5000|$|A {{number of}} <b>software</b> <b>packages</b> use the SWMM5 engine, {{including}} many commercial <b>software</b> <b>packages.</b> Some of these <b>software</b> <b>packages</b> include: ...|$|R
50|$|There {{are many}} <b>software</b> <b>packages</b> {{available}} to merge text and images into VDP print files. Some are stand-alone <b>software</b> <b>packages,</b> however {{most of the}} advanced VDP <b>software</b> <b>packages</b> are actually plug-in modules for one or more publishing <b>software</b> <b>packages</b> such as Adobe Creative Suite.|$|R
5000|$|<b>Software</b> <b>packaging</b> formats {{are used}} to create <b>software</b> <b>packages</b> that may be self-installing files.|$|R
5000|$|With {{extraction}} lossy data conversion, <b>software</b> <b>packages</b> take content stored by {{a different}} <b>software</b> <b>package</b> and extract out the content to the desired format. This may allow data to be extracted in a format not recognized by the original <b>software</b> <b>package.</b>|$|R
40|$|Numerous <b>software</b> <b>packages</b> {{are being}} used and updated {{regularly}} on most computer systems. Installing all these <b>software</b> <b>packages</b> is a formidable task because each one has a different procedure for compiling or for placing the files required at run time. The LUDE (Logithèque Universitaire Distribuée et Extensible) software library is an organization for installing <b>software</b> <b>packages,</b> a set of tools to install and uninstall <b>software</b> <b>packages</b> and browse their documentation, {{and a number of}} FTP servers offering over 100 pre-installed freely redistributable <b>software</b> <b>packages.</b> It offers functionality and flexibility not available i...|$|R
40|$|This paper {{presents}} an integrated rule-based and case-based reasoning approach for evaluation and {{selection of the}} <b>software</b> <b>packages.</b> Rule-based reasoning is used to (i) store knowledge about the software evaluation criteria (ii) guide user to capture user needs of the <b>software</b> <b>package.</b> Case-based reasoning is used to (i) determine the fit between candidate <b>software</b> <b>packages</b> and user needs of the <b>software</b> <b>package</b> (ii) rank the candidate <b>software</b> <b>packages</b> according to their score. We have implemented this approach and performed usability test to verify functionality, efficiency and convenience of this approach...|$|R
40|$|Teachers using {{traditional}} lecture method {{find it difficult}} to communicate the concept of chemical bonding to students; and students {{find it difficult to}} learn the concept. The trend in the 21 st century learning is the use of computer and <b>software</b> <b>packages</b> to facilitate teaching-learning process. This study set out to develop and validate a <b>software</b> <b>package</b> for teaching chemical bonding in secondary schools. The study produced chemical bonding instructional <b>software</b> <b>package</b> (CBISP), adopting the procedure suggested in FTCESP-model for teacher-made computer educational <b>software</b> <b>package.</b> It also produced an instrument for validation of the <b>software</b> <b>package.</b> The internal consistency (α) of the Chemical Bonding Instructional <b>Software</b> <b>Package</b> (CBISP) has a value of 0. 781, obtained by Kendall's Coefficient of Concordance method used in determining it. The author asserts that the procedure adopted in the development and validation of the CBISP is a veritable way of ensuring sustainable supply of relevant <b>software</b> <b>packages</b> in the school system...|$|R
40|$|Publication of {{this article}} was funded by the Stellenbosch University Open Access Fund. The {{original}} publication is available at [URL] factors exist that may contribute to the unsuccessful completion of application <b>software</b> <b>package</b> implementation projects. The most significant contributor to application <b>software</b> <b>package</b> project failure lies in the misalignment of the organisation’s business processes with the functionality of the application <b>software</b> <b>package.</b> While various IT control frameworks that may assist in the implementation of application <b>software</b> <b>packages</b> are available, the question arises why industry still reports that the success rate of application <b>software</b> <b>package</b> implementation projects remains low. The {{purpose of this study was}} to examine the extent to which the Projects in Controlled Environment (PRINCE 2) framework assists in the alignment of the organisation’s business processes with the functionality provided by the application <b>software</b> <b>package</b> implemented. This study investigated whether PRINCE 2 addresses all the reasons for project failure. It identifies the shortcomings and weaknesses in PRINCE 2 which may contribute to the misalignment between the business processes of the organisation and the functionality of the application <b>software</b> <b>package</b> implemented. The study recommends how these weaknesses identified in PRINCE 2 can be addressed. By taking these recommendations into account when using PRINCE 2 to implement application <b>software</b> <b>packages,</b> proper alignment between the organisation’s business processes and the functionality of the application <b>software</b> <b>package</b> may be achieved. This results in a more successful application <b>software</b> <b>package</b> implementation. Stellenbosch UniversityPublishers' versio...|$|R
40|$|Software defect {{prediction}} {{is the process}} of locating defective modules in software. Software quality may be a field of study and apply that describes the fascinating attributes of <b>software</b> <b>package</b> product. The performance should be excellent with none defects. Software quality metrics are a set of <b>software</b> <b>package</b> metrics that target the standard aspects of the product, process, and project. The <b>software</b> <b>package</b> {{defect prediction}} model helps in early detection of defects and contributes to their economical removal and manufacturing a top quality <b>software</b> <b>package</b> supported many metrics. The most objective of paper is to assist developers determine defects supported existing <b>software</b> <b>package</b> metrics victimization data mining techniques and thereby improve the <b>software</b> <b>package</b> quality. In this paper, role of various classification techniques in software defect prediction process are analyzed...|$|R
40|$|An {{application}} <b>software</b> <b>package</b> implementation is {{a complex}} endeavour, and as such it requires the proper understanding, evaluation and redefining of the current business processes {{to ensure that the}} implementation delivers on the objectives set {{at the start of the}} project. Numerous factors exist that may contribute to the unsuccessful implementation of application <b>software</b> <b>packages.</b> However, the most significant contributor to the failure of an application <b>software</b> <b>package</b> implementation lies in the misalignment of the organisation’s business processes with the functionality of the application <b>software</b> <b>package.</b> Misalignment is attributed to a gap that exists between the business processes of an organisation and what functionality the application <b>software</b> <b>package</b> has to offer to translate the business processes of an organisation into digital form when implementing and configuring an application <b>software</b> <b>package.</b> This gap is commonly referred to as the information technology (IT) gap. This study proposes to define and discuss the IT gap. Furthermore this study will make recommendations for aligning the business processes with the functionality of the application <b>software</b> <b>package</b> (addressing the IT gap). The end result of adopting these recommendations will be more successful application <b>software</b> <b>package</b> implementations...|$|R
25|$|One of the {{elements}} of the package will be the <b>software</b> <b>package.</b> The <b>software</b> <b>package</b> is a package in itself, because it consists of the different software components that together form the product. In contrast with the overall <b>package,</b> the <b>software</b> <b>package</b> is always a technical package in which all the files needed are combined in order to run the software product. Another concept of the <b>software</b> <b>package</b> is the version. This keeps track of the modifications made to the software product. By relating it to the <b>software</b> <b>package</b> the vendor and the customer are able {{to keep track of the}} functionality and properties of the product the customer is using.|$|R
40|$|Abstract — A {{number of}} groups have {{reported}} on the occurrence of intra-operative brain shift during deep brain stimulation (DBS) surgery. This {{has a number of}} implications for the procedure including an increased chance of intra-cranial bleeding and complications due to the need for more exploratory electrodes to account for the brain shift. It has been reported that the amount of pneumocephalus or air invasion into the cranial cavity due to the opening of the dura correlates with intra-operative brain shift. Therefore, pre-operatively predicting the amount of pneumocephalus expected during surgery is of interest toward accounting for brain shift. In this study, we used 64 DBS patients who received bilateral electrode implantations and had a post-operative CT scan acquired immediately after surgery (CT-PI). For each patient, the volumes of the pneumocephalus, left ventricle, right ventricle, white matter, grey matter, and cerebral spinal fluid were calculated. The pneumocephalus was calculated from the CT-PI utilizing a region growing technique that was initialized with an atlas-based image registration method. A multi-atlas based image segmentation method was used to segment out the ventricles of each patient. The Statistical Parametric <b>Mapping</b> (SPM) <b>software</b> <b>package</b> was utilized to calculate the volumes of the cerebral spinal fluid (CSF), white matter and grey matter. A Pearson’s coefficient of 0. 4877 (p = 0. 0078) was found with a multi-linear regression between the volume of the pneumocephalus and the left ventricle, right ventricle, third ventricle, CSF and white matter. This information may help the surgical team to account for brain shift during the planning stage and may be useful, in addition to other information, to prospectively predict brain shift. Index Terms—deep brain stimulation, brain shift, pneumocephalus, computer assisted surgery I...|$|R
