43|233|Public
5|$|Stackless Python is a {{significant}} fork of CPython that implements microthreads; it does not use the C <b>memory</b> <b>stack,</b> thus allowing massively concurrent programs. PyPy also has a stackless version.|$|E
2500|$|There are {{two modes}} of accepting. The pushdown {{automaton}} either accepts by final state, which means after reading its input the automaton reaches an accepting state (in [...] ), or it accepts by empty stack (...) , which means after reading its input the automaton empties its stack. The first acceptance mode uses the internal memory (state), the second the external <b>memory</b> (<b>stack).</b>|$|E
5000|$|Tandem Computers T/16. Like HP 3000, {{except that}} compilers, not microcode, {{controlled}} when the register stack spilled to the <b>memory</b> <b>stack</b> or was refilled from the <b>memory</b> <b>stack.</b>|$|E
25|$|Vertical NAND (V-NAND) <b>memory</b> <b>stacks</b> <b>memory</b> cells {{vertically}} {{and uses}} a charge trap flash architecture. The vertical layers allow larger areal bit densities without requiring smaller individual cells.|$|R
5000|$|Hybrid <b>Memory</b> Cube <b>stacked</b> <b>memory</b> {{standard}} from Micron (2011) ...|$|R
50|$|Nvidia has {{announced}} that the Pascal GP100 GPU will feature four High Bandwidth <b>Memory</b> <b>stacks,</b> allowing a total of 16 GB HBM2 on the highest-end models, 16 nm technology, Unified Memory and NVLink.|$|R
50|$|Stackless Python is a {{significant}} fork of CPython that implements microthreads; it does not use the C <b>memory</b> <b>stack,</b> thus allowing massively concurrent programs. PyPy also has a stackless version.|$|E
5000|$|MU5 and ICL 2900 Series. Hybrid stack and {{accumulator}} machines. The {{accumulator register}} buffered the memory stack's top data value. Variants of load and store opcodes controlled when that register was spilled to the <b>memory</b> <b>stack</b> or reloaded from there.|$|E
50|$|If the {{hardwired}} stack {{machine has}} N registers to cache the topmost <b>memory</b> <b>stack</b> words, then all spills and refills are avoided {{in this example}} and there is only 1 data cache cycle, {{the same as for}} a register or accumulator machine.|$|E
50|$|All models {{other than}} the model 1 consist of two <b>memory</b> <b>stacks.</b> Addressing for the stacks is interleaved, so the first 64-bit word is in one stack, the second in the other stack, and so forth. This {{improved}} performance when doing sequential access.|$|R
40|$|Silicon {{interposer}} {{technology is}} promising for large-scale in-tegration of memory within a processor package. While past work on vertical, 3 D-stacked <b>memory</b> allows a <b>stack</b> of mem-ory {{to be placed}} directly {{on top of a}} processor, the total amount of memory that could be integrated is limited {{by the size of the}} processor die. With silicon interposers, mul-tiple <b>memory</b> <b>stacks</b> can be integrated inside the processor package, thereby increasing both the capacity and the band-width provided by the 3 D memory. However, the full po-tential of all of this integrated memory may be squandered if the in-package interconnect architecture cannot keep up with the data rates provided by the multiple <b>memory</b> <b>stacks.</b> This position paper describes key issues in providing the in-terconnect support for aggressive interposer-based memory integration, and argues for additional research efforts to ad-dress these challenges to enable integrated memory to deliver its full value. CCS Concepts •Hardware → Dynamic memory; 3 D integrated cir-cuits; Package-level interconnect...|$|R
40|$|Time-shared {{interface}} speeds {{data processing}} in distributed computer network. Two-level high-speed scanning approach routes information to buffer, portion {{of which is}} reserved for series of "first-in, first-out" <b>memory</b> <b>stacks.</b> Buffer address structure and memory are protected from noise or failed components by error correcting code. System is applicable to any computer or processing language...|$|R
5000|$|Some simple stack {{machines}} or stack interpreters use no top-of-stack hardware registers. Those minimal implementations {{are always}} slower than standard register machines. A typical expression like X+1 compiles to 'Load X; Load 1; Add'. This does implicit writes and reads of the <b>memory</b> <b>stack</b> which weren't needed: ...|$|E
50|$|A {{machine with}} an {{expression}} stack can get by with just two registers that are visible to a programmer: The top-of-stack address and the next-instruction address. The minimal hardware implementation has far fewer bits of flipflops or registers. Faster designs can simply buffer the topmost N stack cells into registers to reduce <b>memory</b> <b>stack</b> cycles.|$|E
50|$|The T/16 {{instruction}} set changed several features from the HP 3000 design. The T/16 supported paged virtual memory from the beginning. The HP 3000 series did not add paging until the PA-RISC generation, 10 years later (although MPE V {{it had a}} form of paging via the APL firmware, in 1978). Tandem added support for 32-bit addressing in its second machine; HP 3000 lacked this until its PA-RISC generation. Paging and long addresses was critical for supporting complex system software and large applications. The T/16 treated its top-of-stack registers in a novel way; the compiler, not the microcode, was responsible for deciding when full registers were spilled to the <b>memory</b> <b>stack</b> and when empty registers were re-filled from the <b>memory</b> <b>stack.</b> On the HP 3000, this decision took extra microcode cycles in every instruction. The HP 3000 supported COBOL with several instructions for calculating directly on arbitrary-length BCD (binary-coded decimal) strings of digits. The T/16 simplified this to single instructions for converting between BCD strings and 64-bit binary integers.|$|E
40|$|Abstract — The {{performance}} of most digital systems today {{is limited by}} the interconnect latency between logic and memory, rather than by the {{performance of}} logic or memory itself. Threedimensional (3 -D) integration using through-silicon-vias (TSVs) may provide a solution to overcome the scaling limitations by <b>stacking</b> multiple <b>memory</b> dies on top of a many-core die. In this paper, we propose a Mesh-of-Trees (MoT) network to support high-throughput and low-latency communication between processing cores and 3 -D stacked multi-banked shared L 2 data memory. Compared to conventional MoT network [5] that is straightforwardly adapted to 3 -D integration, the experimental results show that the proposed network significantly improves the number of operations per second. We also investigate the architecture parameters of 3 -D <b>memory</b> <b>stacking</b> (e. g., number of tiers to be stacked, TSV sharing, etc.) that affect the interconnection network as well as the system performance and fabrication cost, which permits to explore trade-offs among different 3 -D <b>memory</b> <b>stacking</b> architectures. I...|$|R
5000|$|Memory {{checking}} includes memory leaks, dangling pointers, uninitialized variables, use of invalid memory references, mismatched memory, allocation and deallocation, <b>stack</b> <b>memory</b> checks, and <b>stack</b> trace with controllable {{stack trace}} depth ...|$|R
5000|$|... #Caption: Typical logic plus <b>memory</b> PoP <b>stack,</b> {{common to}} mobile phone SoCs or {{baseband}} modems from 2005 onward ...|$|R
5000|$|It {{also has}} small code, saving on <b>memory.</b> <b>Stack</b> machine {{instructions}} {{do not need}} to contain register IDs, so the ZPU's code is smaller than other RISC CPUs, said to need only about 80% of the space of ARM Holdings Thumb2. [...] For example, the signed immediate helps the ZPU store a 32-bit value in at most 5 bytes of instruction space, and as little as one. Most RISC CPUs require at least eight bytes.|$|E
5000|$|Computations of the pushdown {{automaton}} are {{sequences of}} steps. The computation {{starts in the}} initial state [...] with the initial stack symbol [...] on the stack, and a string [...] on the input tape, thus with initial description [...] There are two modes of accepting. The pushdown automaton either accepts by final state, which means after reading its input the automaton reaches an accepting state (in [...] ), or it accepts by empty stack (...) , which means after reading its input the automaton empties its stack. The first acceptance mode uses the internal memory (state), the second the external <b>memory</b> (<b>stack).</b>|$|E
5000|$|The {{transputer}} {{instruction set}} comprised 8-bit instructions divided into opcode and operand nibbles. The [...] "upper" [...] nibble contained the 16 possible primary instruction codes, {{making it one}} of the very few commercialized minimal instruction set computers. The [...] "lower" [...] nibble contained the single immediate constant operand, commonly used as an offset relative to the Workspace (<b>memory</b> <b>stack)</b> pointer. Two prefix instructions allowed construction of larger constants by prepending their lower nibbles to the operands of following instructions. Additional instructions were supported via the Operate (Opr) instruction code, which decoded the constant operand as an extended zero-operand opcode, providing for almost endless and easy instruction set expansion as newer implementations of the transputer were introduced.|$|E
40|$|We propose scale-free Identifier Network(sfIN), a {{novel model}} for event {{identification}} in documents. In general, sfIN first encodes a document into multi-scale <b>memory</b> <b>stacks,</b> then extracts special events via conducting multi-scale actions, {{which can be}} considered as a special type of sequence labelling. The design of large scale actions makes it more efficient processing a long document. The whole model is trained with both supervised learning and reinforcement learning. Comment: 8 pages, 8 figure...|$|R
5000|$|Bandwidth: 3D {{integration}} allows {{large numbers}} of vertical vias between the layers. This allows construction of wide bandwidth buses between functional blocks in different layers. A typical example would be a processor+memory 3D stack, with the cache <b>memory</b> <b>stacked</b> {{on top of the}} processor. This arrangement allows a bus much wider than the typical 128 or 256 bits between the cache and processor. Wide buses in turn alleviate the memory wall problem.|$|R
3000|$|... /W-structured (device S 2) {{resistive}} switching <b>memory</b> <b>stacks</b> were fabricated. A small via size of 150 [*]×[*] 150  nm 2 was {{etched into}} the SiO 2 on W bottom electrode (BE), {{which was about}} 100  nm in thickness. Standard photolithography and dry etching processes were used to open the via holes for the RRAM devices. The photoresist (PR) was coated and opened on active and top electrode (TE) regions for lift-off process. Then, a high-κ Ta 2 O 5 film with a thickness ([...] [...]...|$|R
50|$|The MultiMediaCard (MMC) is {{a memory}} card {{standard}} used for solid-state storage. Unveiled in 1997 by SanDisk and Siemens AG, {{it is based}} on a surface contact low pin-count serial interface using a single <b>memory</b> <b>stack</b> substrate assembly, and is therefore much smaller than earlier systems based on high pin-count parallel interfaces using traditional surface mount assembly such as CompactFlash. Both products were initially introduced using SanDisk NOR-based Flash technology. MMC {{is about the size of}} a postage stamp: 24 mm × 32 mm × 1.4 mm. MMC originally used a 1-bit serial interface, but newer versions of the specification allow transfers of 4 or 8 bits at a time. MMC can be used in many devices that can use Secure Digital (SD) cards.|$|E
50|$|To {{include all}} this {{functionality}} {{on a single}} chip, the transputer's core logic was simpler than most CPUs. While some have called it a RISC due to its rather sparse nature (and because that was a desirable marketing buzzword at the time), it was heavily microcoded, had a limited register set, and complex memory-to-memory instructions, all of which place it firmly in the CISC camp. Unlike register-heavy load-store RISC CPUs, the transputer had only three data registers, which behaved as a stack. In addition a Workspace Pointer pointed to a conventional <b>memory</b> <b>stack,</b> easily accessible via the Load Local and Store Local instructions. This allowed for very fast context switching by simply changing the workspace pointer to the memory used by another process (a technique used {{in a number of}} contemporary designs, such as the TMS9900). The three register stack contents were not preserved past certain instructions, like Jump, when the transputer could do a context switch.|$|E
50|$|The index registers, IX and IY, were {{intended}} as flexible 16 bit pointers, enhancing {{the ability to}} manipulate <b>memory,</b> <b>stack</b> frames and data structures. Officially, they were treated as 16-bit only. In reality, they were implemented {{as a pair of}} 8-bit registers, in the same fashion as the HL register, which is accessible either as 16 bits or separately as the High and Low registers. Even the binary opcodes (machine language) were identical, but preceded by a new opcode prefix. Zilog published the opcodes and related mnemonics for the intended functions, but did not document the fact that every opcode that allowed manipulation of the H and L registers was equally valid for the 8 bit portions of the IX and IY registers. As an example, the opcode 26h followed by an immediate byte value (LD H,n) will load that value into the H register. Preceding this two-byte instruction with the IX register's opcode prefix, DD, would instead result in the most significant 8 bits of the IX register being loaded with that same value. A notable exception to this would be instructions similar to LD H,(IX+d) which make use of both the HL and IX or IY registers in the same instruction; in this case the DD prefix is only applied to the (IX+d) portion of the instruction.|$|E
40|$|The {{emerging}} three-dimensional (3 D) chip architectures, {{with their}} intrinsic capability {{of reducing the}} wire length, promise attractive solutions to reduce the delay of interconnects in future microprocessors. 3 D <b>memory</b> <b>stacking</b> enables much higher memory bandwidth for future chip-multiprocessor design, mitigating the ""memory wall"" problem. In addition, heterogenous integration enabled by 3 D technology can also result in innovative designs for future microprocessors. This book first provides a brief introduction to this emerging technology, and then presents a variety of approaches to desig...|$|R
40|$|The {{notion of}} {{reversible}} computing is attracting interest {{because of its}} applications in diverse fields, in particular the study of programming abstractions for fault tolerant systems. Reversible CCS (RCCS), proposed by Danos and Krivine, enacts reversibility by means of <b>memory</b> <b>stacks.</b> Ulidowski and Phillips proposed a general method to reverse a process calculus given in a particular SOS format, by exploiting {{the idea of making}} all the operators of a calculus static. CCSK is then derived from CCS with this method. In this paper we show that RCCS is at least as expressive as CCSK...|$|R
40|$|Linguists {{have often}} argued that {{recursion}} produces linguistic complexity. However, recursion itself preexisting {{processes such as}} lexical insertion, lexical combination, <b>memory</b> <b>stacks,</b> and methods of interpretation. In the brain, recursion is an emergent property {{of a set of}} adaptations that involve at least six processing systems. Linguistic complexity arises from the interplay of all six of these systems. The complexity of this neuronal support means that the full complexity of human language could not have arisen fortuitously at some single moment in evolution. However, there is evidence that some pieces of the six systems supporting complexity have developed more recently than others...|$|R
5000|$|Besides {{recovering}} {{well from}} failed parts, the T/16 was also designed to detect as {{many kinds of}} intermittent failures as possible, as soon as possible. This prompt detection is called [...] "fail fast". The point was to find and isolate corrupted data before it was permanently written into databases and other disk files. In the T/16, error detection was by some added custom circuits that added little cost to the total design; no major parts were duplicated just to get error detection.The T/16 CPU was a proprietary design. It was greatly influenced by the HP 3000 minicomputer. They were both microprogrammed, 16-bit, stack-based machines with segmented, 16-bit virtual addressing. Both were intended to be programmed exclusively in high-level languages, with no use of assembler. Both were initially implemented via standard low-density TTL chips, each holding a 4-bit slice of the 16-bit ALU. Both had {{a small number of}} top-of-stack, 16-bit data registers plus some extra address registers for accessing the <b>memory</b> <b>stack.</b> Both used Huffman encoding of operand address offsets, to fit a large variety of address modes and offset sizes into the 16-bit instruction format with very good code density. Both relied heavily on pools of indirect addresses to overcome the short instruction format. Both supported larger 32- and 64-bit operands via multiple ALU cycles, and memory-to-memory string operations. Both used [...] "big-endian" [...] addressing of long versus short memory operands. These features had all been inspired by Burroughs B5500-B6800 mainframe stack machines.|$|E
3000|$|Improvement in the {{resistive}} switching and self-compliance {{behaviors of}} a forming-free resistive <b>memory</b> <b>stack</b> of Ir/TaO [...]...|$|E
3000|$|In this study, self-compliance-limited and low-voltage-operated {{resistive}} switching behaviors {{with improved}} switching cycle uniformity {{in a simple}} resistive <b>memory</b> <b>stack</b> of Ir/TaO [...]...|$|E
50|$|The PXA26x family (code-named Dalhart) {{consists}} of the PXA260 and PXA261-PXA263. The PXA260 is a stand-alone processor clocked at the same frequency as the PXA25x, but features a TPBGA package which is about 53% smaller than the PXA25x's PBGA package. The PXA261-PXA263 {{are the same as}} the PXA260 but have Intel StrataFlash <b>memory</b> <b>stacked</b> on top of the processor in the same package; 16 MB of 16-bit memory in the PXA261, 32 MB of 16-bit memory in the PXA262 and 32 MB of 32-bit memory in the PXA263. The PXA26x family was released in March 2003.|$|R
50|$|The Teraflops Research Chip (also called Polaris) is a {{research}} manycore processor, containing 80 cores developed by Intel Corporation's Tera-Scale Computing Research Program. The processor was officially announced February 11, 2007 and shown working at the 2007 International Solid-State Circuits Conference. Features of the processor include dual floating point engines, sleeping-core technology, self-correction, fixed-function cores, and three-dimensional <b>memory</b> <b>stacking.</b> The purpose of the chip is to explore the possibilities of Tera-Scale architecture (the process of creating processors with more than four cores) and to experiment with various forms of networking and communication within {{the next generation of}} processors.|$|R
5000|$|... {{transferring}} multiple registers {{to or from}} <b>memory</b> (especially the <b>stack)</b> at once ...|$|R
