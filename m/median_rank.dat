41|114|Public
50|$|A {{statistical}} method used for analyzing {{the tendency of}} an individual to produce value-increasing aspects before value-decreasing is the standardized <b>median</b> <b>rank</b> difference (SMRD). This statistic is calculated as the 2(MRi - MRd)/n where MRd {{is defined as the}} <b>median</b> <b>rank</b> of value decreasing statements in a participant’s sequence, MRi is the <b>median</b> <b>rank</b> of value increasing statements, and n is the total number of aspects. SMRD can be between 1 (all value-increasing statements were listed before value-decreasing) to −1 (all value-decreasing statements were listed before value-increasing). In the endowment effect research discussed above, SMRD was higher (.62) for sellers than for buyers (.26).|$|E
50|$|An {{estimator}} for {{the slope}} with approximately <b>median</b> <b>rank,</b> {{having the same}} breakdown point as the Theil-Sen estimator, may be maintained in the data stream model (in which the sample points are processed one by one by an algorithm {{that does not have}} enough persistent storage to represent the entire data set) using an algorithm based on ε-nets.|$|E
50|$|The International Baccalaureate {{is offered}} as an {{international}} / global alternative to the NSW Higher School Certificate. It has been offered at MLC School since 2001 and is chosen by 30% of MLC School's graduates.MLC School’s 2010 IB Diploma results included four perfect scores, converting to the maximum Australian Tertiary Admissions Rank (ATAR) of 99.95. The School's IB Diploma <b>median</b> <b>rank</b> was 98.80.The combined 2010 HSC and IB Diploma scores also resulted in 55% of candidates receiving an ATAR of 90.00 or above, with 14 candidates scoring 99.00 or above.|$|E
50|$|Additionally, DesignIntelligence's ten-year <b>median</b> <b>ranking</b> also ranks {{the program}} 5th.|$|R
5000|$|Conversely, DesignIntelligence's ten-year <b>median</b> <b>ranking</b> {{places the}} program 3rd.*(T) denotes tie ...|$|R
50|$|Additionally, DesignIntelligence's ten-year <b>median</b> <b>ranking</b> also ranks {{the program}} 2nd, tied with Yale University.|$|R
40|$|OBJECTIVES: This study {{determined}} the flexural strength of one hipped and eight presintered zirconia and evaluated the results using different estimation methods of Weibull statistics. MATERIALS AND METHODS: Presintered zirconia specimens were prepared in white state and sintered according to each manufacturer's instructions. One hipped zirconia acted as the control group. The specimens were loaded in a Universal Testing Machine (ISO 6872, 2008). Data were analysed using "normal" (Levene test, one-way ANOVA, Scheffé test) and "Weibull distribution" estimated by either Least Squares (LS) (mean (Excel) and <b>median</b> <b>rank</b> (MINITAB)), Maximum Likelihood (ML) (MINITAB) or ML (MINITAB) with a correction of BS EN 843 - 5 (2006) (MLC) (alpha= 0. 05). RESULTS: According to normal (σ) and Weibull distribution (s), three-point flexural strength (MPa) of the hipped zirconia (σ= 1643 (1507; 1782), s(LS mean rank) : 1772, s(LS <b>median</b> <b>rank)</b> : 1751 (1619; 1894), s(ML) : 1733 (1645; 1826) and s(MLC) : (1625; 1848) showed significantly higher results compared {{to all other}} presintered zirconia groups (p< 0. 001). The lowest mean and characteristic strength was observed with GC (σ= 817 (803; 953), s(LS mean rank) : 935, s(LS <b>median</b> <b>rank)</b> : 935 (868; 1007), s(ML) : 932 (875; 994) and s(MLC) : (862; 1009)). The highest Weibull modulus estimated by LS for mean and <b>median</b> <b>rank</b> was observed with LZ (8. 9 and 9. 8 (7. 5; 12. 9), respectively) and the lowest with ZE (5. 1 and 5 (3; 8. 2), respectively). According to ML and MLC estimation, the control group showed the highest (10. 1 (6. 6; 15. 6), 9. 2 (5. 8; 14. 2), respectively), and CZ the lowest (5. 6 (3. 8; 8. 2), 5. 0 (3. 2; 7. 8), respectively) Weibull modulus. No differences in estimates of standard deviations of the normal distribution and the estimates of Weibull moduli for different estimation methods were found between all tested groups. CONCLUSIONS: Flexural strength of the tested hipped zirconia was {{higher than those of}} presintered ones according to both normal and Weibull distribution. LS (<b>median</b> <b>rank)</b> and ML estimates can be compared by a global test and by means of 95...|$|E
40|$|The typical {{experimental}} {{procedure for}} testing {{stress corrosion cracking}} initiation involves an interval-censored reliability test. Based on these test results, the parameters of a Weibull distribution, which is a widely accepted crack initiation model, can be estimated using maximum likelihood estimation or <b>median</b> <b>rank</b> regression. However, {{it is difficult to}} determine the appropriate number of test specimens and censoring intervals required to obtain sufficiently accurate Weibull estimators. In this study, we compare maximum likelihood estimation and <b>median</b> <b>rank</b> regression using a Monte Carlo simulation to examine the effects of the total number of specimens, test duration, censoring interval, and shape parameters of the true Weibull distribution on the estimator uncertainty. Finally, we provide the quantitative uncertainties of both Weibull estimators, compare them with the true Weibull parameters, and suggest proper experimental conditions for developing a probabilistic crack initiation model through crack initiation tests...|$|E
40|$|Objectives: Trial {{registries}} {{can be used}} {{to measure}} reporting biases and support systematic reviews but 45 % of registrations do not provide a link to the article reporting on the trial. We evaluated the use of document similarity methods to identify unreported links between ClinicalTrials. gov and PubMed. Study Design and Setting: We extracted terms and concepts from a dataset of 72, 469 ClinicalTrials. gov registrations and 276, 307 PubMed articles, and tested methods for ranking articles across 16, 005 reported links and 90 manually-identified unreported links. Performance was measured by the <b>median</b> <b>rank</b> of matching articles, and the proportion of unreported links that could be found by screening ranked candidate articles in order. Results: The best performing concept-based representation produced a <b>median</b> <b>rank</b> of 3 (IQR 1 - 21) for reported links and 3 (IQR 1 - 19) for the manually-identified unreported links, and term-based representations produced a <b>median</b> <b>rank</b> of 2 (1 - 20) for reported links and 2 (IQR 1 - 12) in unreported links. The matching article was ranked first for 40 % of registrations, and screening 50 candidate articles per registration identified 86 % of the unreported links. Conclusions: Leveraging the growth in the corpus of reported links between ClinicalTrials. gov and PubMed, we found that document similarity methods can assist in the identification of unreported links between trial registrations and corresponding articles. Comment: 8 pages, 3 figure...|$|E
40|$|In this paper, {{an attempt}} {{is made to}} develop Quality Control Charts for {{monitoring}} the process mean based on Double Ranked Set Sampling (DRSS) rather than the traditional Simple Random Sampling (SRS). Considering a normal population and several shift values, {{the performance of the}} Average Run Length (ARL) of these new charts was compared with the control charts based on Ranked Set Sampling (RSS) and SRS with the same number of observations. It is shown that the new charts {{do a better job of}} detecting changes in process mean compared with SRS and RSS. Average run length, double <b>median</b> <b>ranked</b> set sampling, lower central limit, <b>median</b> double <b>ranked</b> set sampling, <b>median</b> <b>ranked</b> set sampling, ranked set sampling and upper central limit,...|$|R
30|$|Finally, a final ranking is {{obtained}} by separating, by {{the relation of}} outranking S 2, the all equally placed of the <b>median</b> <b>ranking</b> V. For more details you can see [26].|$|R
40|$|In {{this article}} a new single {{sampling}} plan based on ranked data scheme is proposed. Two main requirements are considered for the new plan: the lifetime of the test units is assumed to follow the generalized exponential distribution; and the data are selected by using the <b>median</b> <b>ranked</b> set sampling scheme from a large lot. The distribution function characterization under the <b>median</b> <b>ranked</b> set sampling scheme is derived assuming that the set size is known; the minimum number of set cycle and consequently the minimum sample size necessary to ensure the specified average life are obtained and the operating characteristic values of the ranked sampling plans {{as well as the}} producer’s risk are presented. An illustrative examples based on the results obtained are given...|$|R
40|$|The {{paper is}} {{concerned}} with transformer Weibull lifetime modelling which is recognised as essential for effective asset management within electric utilities. Two popular and widely adopted methods, maximum likelihood estimation and <b>median</b> <b>rank</b> regression, are discussed and compared for their properties in estimating transformer lifetime data. To greatly mimic the field collected transformer lifetime data, Monte-Carlo simulations are conducted to generate multiple sets of transformer lifetime data with the censoring rate being set at 90 % and sample size chosen as ranging from 60 to 1000. Weibull parameters are estimated for each sample set with both methods. Performance of each estimation method is then evaluated {{with respect to their}} corresponding relative difference between median value and the true value (RD) as well as the relative root mean square error (RRMSE) obtained for each sample size. It is found that the maximum likelihood method is superior to the <b>median</b> <b>rank</b> regression method {{due to the fact that}} it always provides smaller RD as well as RRMSE and is hence recommended to be used for transformer Weibull lifetimemodelling...|$|E
40|$|Clinical trial {{registries}} {{can be used}} {{to monitor}} the production of trial evidence and signal when systematic reviews become out of date. However, this use has been limited to date due to the extensive manual review required to search for and screen relevant trial registrations. Our aim was to evaluate a new method that could partially automate the identification of trial registrations that may be relevant for systematic review updates. We identified 179 systematic reviews of drug interventions for type 2 diabetes, which included 537 clinical trials that had registrations in ClinicalTrials. gov. We tested a matrix factorisation approach that uses a shared latent space to learn how to rank relevant trial registrations for each systematic review, comparing the performance to document similarity to rank relevant trial registrations. The two approaches were tested on a holdout set of the newest trials from the set of type 2 diabetes systematic reviews and an unseen set of 141 clinical trial registrations from 17 updated systematic reviews published in the Cochrane Database of Systematic Reviews. The matrix factorisation approach outperformed the document similarity approach with a <b>median</b> <b>rank</b> of 59 and recall@ 100 of 60. 9 %, compared to a <b>median</b> <b>rank</b> of 138 and recall@ 100 of 42. 8 % in the document similarity baseline. In the second set of systematic reviews and their updates, the highest performing approach used document similarity and gave a <b>median</b> <b>rank</b> of 67 (recall@ 100 of 62. 9 %). The proposed method was useful for ranking trial registrations to reduce the manual workload associated with finding relevant trials for systematic review updates. The results suggest that the approach could be used as part of a semi-automated pipeline for monitoring potentially new evidence for inclusion in a review update. Comment: Submitted to the Journal of Biomedical Informatic...|$|E
40|$|Abstract—Recently, {{there have}} been several {{attempts}} to propose definitions and algorithms for ranking queries on probabilistic data. However, these lack many intuitive properties of a top-k over deterministic data. We define several fundamental properties, including exact-k, containment, unique-rank, value-invariance, and stability, which are satisfied by ranking queries on certain data. We argue these properties should also be carefully studied in defining ranking queries in probabilistic data, and fulfilled by definition for ranking uncertain data for most applications. We propose an intuitive new ranking definition based on the observation that the ranks of a tuple across all possible worlds represent a well-founded rank distribution. We studied the ranking definitions based on the expectation, the median and other statistics of this rank distribution for a tuple and derived the expected rank, <b>median</b> <b>rank</b> and quantile rank correspondingly. We are able to prove that the expected rank, <b>median</b> <b>rank</b> and quantile rank satisfy all these properties for a ranking query. We provide efficient solutions to compute such rankings across the major models of uncertain data, such as attribute-level and tuple-level uncertainty. Finally, a comprehensive experimental study confirms the effectiveness of our approach...|$|E
40|$|The ranked set {{sampling}} (RSS) method {{as suggested}} by McIntyre (1952) may be modified {{to come up with}} new sampling methods that can be made more efficient than the usual RSS method. Two such modifications, namely extreme and <b>median</b> <b>ranked</b> set sampling methods, are considered in this study. These two methods are generally easier to use in the field and less prone to problems resulting from errors in ranking. Two regression-type estimators based on extreme ranked set sampling (ERSS) and <b>median</b> <b>ranked</b> set sampling (MRSS) for estimating the population mean of the variable of interest are considered in this study and compared with the regression-type estimators based on RSS suggested by Yu & Lam (1997). It turned out that when the variable of interest and the concomitant variable jointly followed a bivariate normal distribution, the regression-type estimator of the population mean based on ERSS dominates all other estimators considered. ...|$|R
50|$|Bucklin {{voting is}} {{a class of}} voting methods {{that can be used}} for {{single-member}} and multi-member districts. It is named after its original promoter, the Georgist politician James W. Bucklin of Grand Junction, Colorado, and is also known as the Grand Junction system. As in Majority Judgment, the Bucklin winner will be one of the candidates with the highest <b>median</b> <b>ranking</b> or rating.|$|R
40|$|We modify RSS {{to come up}} {{with new}} {{sampling}} method, namely, Multistage <b>Median</b> <b>Ranked</b> Set Sampling (MMRSS). The MMRSS was suggested for estimating the population median and to increase the efficiency of the estimator for specific value of the sample size. The MMRSS was compared to the Simple Random Sampling (SRS), Ranked Set Sampling (RSS) and <b>Median</b> <b>Ranked</b> Set Sampling (MRSS) methods. It is found that MMRSS gives an unbiased estimate of the population median of symmetric distributions and it is more efficient than SRS, RSS and MRSS based on the same number of measured units. Also, {{it was found that the}} efficiency of MMRSS increases in r (r is the number of stage) for specific value of the sample size. For asymmetric distributions considered in this study, MMRSS has a small bias, close to zero as r increases, especially with odd sample size. A set of real data was used to illustrate the method...|$|R
40|$|This paper {{describes}} {{the design and}} implementation of the slot filling system prepared by Stanford’s natural language processing group for the 2010 Knowledge Base Population (KBP) track at the Text Analysis Conference (TAC). Our system relies on a simple distant supervision approach using mainly resources furnished by the track organizers: we used slot examples from the provided knowledge base, which we mapped to documents from several corpora, i. e., those distributed by the organizers, Wikipedia, and web snippets. Our implementation attained the <b>median</b> <b>rank</b> among all participating systems. ...|$|E
40|$|The Weibull {{distribution}} is frequently used in reliability applications. Many different methods of estimating the parameters and important {{functions of the}} parameters (e. g. quantiles and failure probabilities) have been suggested. Maximum likelihood and <b>median</b> <b>rank</b> regression methods are most commonly used today. Largely because of conflicting results from different {{studies that have been}} conducted to investigate the properties of these estimators, there are sharp differences of opinion on which method should be used. The {{purpose of this paper is}} to report on the results of our simulation study, to provide insight into the differences between the competing methods, and to resolve the differences among the previous studie...|$|E
40|$|The Weibull distribution, {{an extreme}} value distribution, is {{frequently}} used to model survival, reliability, wind speed, and other data. One {{reason for this}} is its flexibility; it can mimic various distributions like the exponential or normal. The two-parameter Weibull has a shape (γ) and scale (β) parameter. Parameter estimation has been an ongoing search to find efficient, unbiased, and minimal variance estimators. Through data analysis and simulation studies, the following three methods of estimation will be discussed and compared: maximum likelihood estimation (MLE), method of moments estimation (MME), and <b>median</b> <b>rank</b> regression (MRR). The analysis of wind speed data from the TW Daniels Experimental Forest are used for this study to test the performance and flexibility of the Weibull distribution...|$|E
40|$|Different {{cumulative}} sum (CUSUM) control charts {{for the sample}} mean based on ranked set sampling (RSS) data and <b>median</b> <b>ranked</b> set sampling (MRSS) data are developed and compared to the usual CUSUM based on simple random sampling (SRS) data using computer simulation. All the charts based on ranked set sampling data are shown to have smaller average run length (ARL) than the classical CUSUM charts based on SRS if the process starts {{to get out of}} control, and have approximately the same ARL if the process is in control. Real data using the RSS and MRSS are used to illustrate the new developed methods and construct the corresponding control charts. These charts are compared to usual SRS chart, {{it turns out that the}} newly developed charts are more efficient i. e. having smaller ARL In this study we are assuming the underling distribution is normal. KEYWORDS Average run length; <b>median</b> <b>ranked</b> set sampling; ranked set sampling and simple random sampling. 1...|$|R
40|$|Image {{segmentation}} of retinal {{blood vessels}} {{is a process}} that can help to predict and diagnose cardiovascular related diseases, such as hypertension and diabetes, which are known to affect the retinal blood vessels' appearance. This work proposes an unsupervised method for the segmentation of retinal vessels images using a combined matched filter, Frangi's filter and Gabor Wavelet filter to enhance the images. The combination of these three filters in order to improve the segmentation is the main motivation of this work. We investigate two approaches to perform the filter combination: weighted mean and <b>median</b> <b>ranking.</b> Segmentation methods are tested after the vessel enhancement. Enhanced images with <b>median</b> <b>ranking</b> are segmented using a simple threshold criterion. Two segmentation procedures are applied when considering enhanced retinal images using the weighted mean approach. The first method is based on deformable models and the second uses fuzzy C-means for the image segmentation. The procedure is evaluated using two public image databases, Drive and Stare. The experimental results demonstrate that the proposed methods perform well for vessel segmentation in comparison with state-of-the-art methods...|$|R
40|$|The {{method of}} maximum {{likelihood}} estimation based on <b>Median</b> <b>Ranked</b> Set Sampling (MRSS) {{was used to}} estimate the shape and scale parameters of the Exponentiated Exponential Distribution (EED). They were compared with the conventional estimators. The relative efficiency was used for comparison. The amount of information (in Fisher 2 ̆ 7 s sense) available from the MRSS about {{the parameters of the}} EED were be evaluated. Confidence intervals for the parameters were constructed using MRSS...|$|R
40|$|The {{three-spined stickleback}} (Gasterosteus aculeatus L., {{hereafter}} 'stickleback') {{is a common}} mesopredatory fish in marine, coastal and freshwater areas. In {{large parts of the}} Baltic Sea, stickleback densities have increased > 10 -fold during the last decades, and it {{is now one of the}} dominating fish species both in terms of biomass and effects on lower trophic levels. Still, relatively little is known about its diet-knowledge which is essential to understand the increasing role sticklebacks play in the ecosystem. Fish diet analyses typically rely on visual identification of stomach contents, a labour-intensive method that is made difficult by prey digestion and requires expert taxonomic knowledge. However, advances in DNA-based metabarcoding methods promise a simultaneous identification of most prey items, even from semi-digested tissue. Here, we studied the diet of stickleback from the western Baltic Sea coast using both DNA metabarcoding and visual analysis of stomach contents. Using the cytochrome oxidase (CO 1) marker we identified 120 prey taxa in the diet, belonging to 15 phyla, 83 genera and 84 species. Compared to previous studies, this is an unusually high prey diversity. Chironomids, cladocerans and harpacticoids were dominating prey items. Large sticklebacks were found to feed more on benthic prey, such as amphipods, gastropods and isopods. DNA metabarcoding gave much higher taxonomic resolution (<b>median</b> <b>rank</b> genus) than visual analysis (<b>median</b> <b>rank</b> order), and many taxa identified using barcoding could not have been identified visually. However, a few taxa identified by visual inspection were not revealed by barcoding. In summary, our results suggest that the three-spined stickleback feeds on a wide variety of both pelagic and benthic organisms, indicating that the strong increase in stickleback populations may affect many parts of the Baltic Sea coastal ecosystem...|$|E
30|$|A rank fit linear {{regression}} of the form: z = a − b.r + u {{can be estimated}} via least squares with u is a random term; r is the log of the rank of a company {{in terms of its}} reported impact, y, of big data on profit, and we note z = log (1  + y) = y (when y is small). The estimated line produces the following results: z =  7.4  −  4.2 *r, or a power law exponent of 1 +(1 / 4.2) =  1.3 (with R-square of 98  %, and both coefficients statistically significant at 5  %). At rank one, the regression leads to 7.4  % impact (versus 20  % reported); at the <b>median</b> <b>rank,</b> r =  40, the regression leads an impact of roughly 0.7  %, while at last rank r =  80, the impact is − 0.6  % (versus − 2.5  % reported).|$|E
40|$|Abstract. This {{research}} {{analyzed the}} results of flexural strength of dense and porous mullite ceramic prepared from kaolin clay by using two-parameter Weibull probability distribution with different estimates. Chemical and physical characterizations of the clay were conducted using XRF, XRD and FESEM. The samples were tested using three point bending tests. The different estimates used in analyzing the results include mean rank, <b>median</b> <b>rank,</b> modified Kaplan Meier and Kaplan Meier. Among the estimates, Kaplan Meier was found to give the best fit with the highest correlation coefficient (R 2) value. The porous ceramic had the higher value of Weibull modulus {{in comparison to the}} dense ceramic, while the characteristic strength (scale parameter) of the dense ceramic was higher than that of the porous ceramic. The micrograph of the porous ceramic showed a relatively balanced distribution of rounded pores, which is associated with the higher Weibull modulus in the porous ceramic...|$|E
40|$|In this paper, some test {{procedures}} for scale parameters of exponential and rectangular distributions involving the <b>median</b> <b>ranked</b> set sampling (MRSS) method are discussed. The necessary tables for the critical regions for the suggested tests are supplied. The power {{functions of the}} tests are compared with the power functions of the same tests suggested by Abu-Dayyeh and Muttlak (1996) using ranked set sampling (RSS) data. It is seen that the {{test procedures}} using the MRSS data have greater power than those using the RSS data when the sample is drawn from an exponential distribution...|$|R
40|$|Stratified double <b>median</b> <b>ranked</b> set {{sampling}} (SDMRSS) {{method is}} suggested for estimating the population mean. The SDMRSS is {{compared with the}} simple random sampling (SRS), stratified simple random sampling (SSRS), and stratified ranked set sampling (SRSS). It is shown that SDMRSS estimator is an unbiased of the population mean and more efficient than SRS, SSRS, and SRSS. Also, by SDMRSS, we can increase the efficiency of mean estimator for specific value of the sample size. SDMRSS is applied on real life examples, {{and the results of}} the example agreed the theoretical results...|$|R
40|$|This paper {{investigates the}} problem of {{combining}} ordinal preferences, expressed as priority vectors, to form a consensus. An axiomatic structure relating {{to the concept of}} distance between rankings is developed, uniqueness of the distance measure is proven and its form derived. Adopting the <b>median</b> <b>ranking</b> as a form of consensus, it is shown that this ranking can be determined, in the case of complete rankings, by solving a certain assignment problem. The results are compared and contrasted to earlier work due to Arrow, Kendall, Kemeny and Snell, and Bogart. games/group decisions: voting/committees, utility/preference: theory, decision analysis...|$|R
40|$|Abstract—In this paper, {{we propose}} a new feature {{evaluation}} method {{that forms the}} basis for feature ranking and selection. The method starts by generating a number of feature subsets in a random fashion and evaluates features based on the de-rived subsets. It then proceeds {{in a number of}} stages. In each stage, it inputs the features whose ranks in the previous stage were above the <b>median</b> <b>rank</b> and re-evaluates those features in the same fashion {{as it did in the}} first stage. When the number of features is high, the method has a computational advantage over recursive feature elimination (RFE), a state-of-art method that ranks features by identifying the least valuable feature in each stage. It also achieves better results than RFE in terms of classification accuracy and some other measures introduced in this paper, especially when the size of the training data is small or the number of irrelevant features is large...|$|E
40|$|The rule {{used by the}} United States Figure Skating Association and the International Skating Union, {{hereafter}} the ISU Rule, {{to aggregate}} individual rankings of the skaters by the judges into a final ranking, is an interesting example of a social welfare function. This rule is examined thoroughly in this paper {{from the perspective of}} the modern theory of social choice. The ISU Rule is based on four different criteria, the first being median ranks of the skaters. Although the <b>median</b> <b>rank</b> criterion is a majority principle, it is completely at odd with another majority principle introduced in this paper and called the Extended Condorcet Criterion. It may be translated as follows: If a competitor is ranked consistently ahead of another competitor by an absolute majority of judges, he should be ahead in the final ranking. Consistency here refers to the absence of a cycle in the majority relation involving these two skaters. There are actually many cycles in the data of four Olympic [...] ...|$|E
40|$|Abstract — Uncertain {{data are}} {{inherent}} in many applications such as environmental surveillance and quantitative economics research. As an important problem in many applications, KNN query has been extensively investigated in the literature. In this paper, we study the problem of processing rank based KNN query against uncertain data. Besides applying the expected rank semantic to compute KNN, we also introduce the <b>median</b> <b>rank</b> which is less sensitive to the outliers. We show both ranking methods satisfy nice top-k properties such as exactk, containment, unique ranking, value invariance, stability and fairfulness. For given query q, IO and CPU efficient algorithms are proposed in the paper to compute KNN based on expected (median) ranks of the uncertain objects. To tackle the correlations of the uncertain objects and high IO cost caused by large number of instances of the uncertain objects, randomized algorithms are proposed to approximately compute KNN with theoretical guarantees. Comprehensive experiments are conducted on both real and synthetic data to demonstrate the efficiency of our techniques. I...|$|E
30|$|The {{characteristics}} of the data led us to use the non-parametric Sign Test (Whitley and Ball 2002). This test evaluates if the median, for a given set of values (in our case, for each practice) is higher than a fixed value. We used the fixed value of 3.5, since the overall median was approximately 3. Note that the fixed value {{is higher than the}} overall median, so the Sign Test would allow us to identify each practice whose <b>median</b> <b>ranking</b> was closer to 4 (i.e. mostly ranked as mandatory), since more than 50 % of subjects would have been ranked those practices with maximum level of importance.|$|R
40|$|Abstract: In this paper, {{percentile}} double ranked set sampling (PDRSS) {{method is}} suggested for estimating the population mean. The PDRSS method is {{compared with the}} simple random sampling (SRS), ranked set sampling (RSS), <b>median</b> <b>ranked</b> set sampling (MRSS) and the extreme ranked set sampling (ERSS) methods. When the underlying distribution is symmetric, {{it turns out that}} PDRSS produce unbiased estimators of the population mean and it is more efficient than SRS, RSS, MRSS and ERSS based on the same sample size. For asymmetric distribution considered in this study, it is shown that PDRSS has a small bias and it is more efficient than RSS, MRSS and ERSS for most cases considered in this study...|$|R
40|$|This {{article is}} devoted to the problem of {{predicting}} the value taken by a random permutation Σ, describing the preferences of an individual over a set of numbered items { 1, [...] ., n} say, based on the observation of an input/explanatory r. v. X e. g. characteristics of the individual), when error is measured by the Kendall τ distance. In the probabilistic formulation of the 'Learning to Order' problem we propose, which extends the framework for statistical Kemeny ranking aggregation developped in CKS 17, this boils down to recovering conditional Kemeny medians of Σ given X from i. i. d. training examples (X_ 1, Σ_ 1), [...] ., (X_N, Σ_N). For this reason, this statistical learning problem is referred to as <b>ranking</b> <b>median</b> regression here. Our contribution is twofold. We first propose a probabilistic theory of <b>ranking</b> <b>median</b> regression: the set of optimal elements is characterized, the performance of empirical risk minimizers is investigated in this context and situations where fast learning rates can be achieved are also exhibited. Next we introduce the concept of local consensus/median, in order to derive efficient methods for <b>ranking</b> <b>median</b> regression. The major advantage of this local learning approach lies in its close connection with the widely studied Kemeny aggregation problem. From an algorithmic perspective, this permits to build predictive rules for <b>ranking</b> <b>median</b> regression by implementing efficient techniques for (approximate) Kemeny median computations at a local level in a tractable manner. In particular, versions of k-nearest neighbor and tree-based methods, tailored to <b>ranking</b> <b>median</b> regression, are investigated. Accuracy of piecewise constant <b>ranking</b> <b>median</b> regression rules is studied under a specific smoothness assumption for Σ's conditional distribution given X...|$|R
