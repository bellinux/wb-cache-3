0|642|Public
40|$|So far the {{discussion}} of high performance computing has concentrated on {{increasing the amount of}} processing power in a system, either through parallelism, which seeks {{to increase the number of}} instructions that can be executed in a time period, or through pipelining, which improves the instruction throughput. Another, equally important, aspect of high performance computing is the organization of the memory system. No matter how fast one makes the processing unit, if the memory cannot keep up and provide instructions and data at a sufficient rate there will be no improvement in performance. The main problem that needs to be overcome in <b>matching</b> <b>memory</b> response to processor speed is the <b>memory</b> <b>cycle</b> time, defined in section 2. 2 to be the time between two successive <b>memory</b> operations. Processor <b>cycle</b> times are typically much shorter than <b>memory</b> <b>cycle</b> times. When a processor initiates a memor...|$|R
50|$|Instructions took 8 <b>memory</b> <b>cycles</b> (160 μs) {{to fetch}} and a {{variable}} number of <b>memory</b> <b>cycles</b> to execute. Indirect addressing added 4 <b>memory</b> <b>cycles</b> (80 μs) for {{each level of}} indirection.|$|R
50|$|The fetch/execute {{mechanism}} {{was completely}} redesigned, optimizing {{the timing and}} allowing partial fetches when the P or Q fields were not needed. Instructions took either 1, 4, or 6 <b>Memory</b> <b>cycles</b> (10 µs, 40 µs, or 60 µs) to fetch and a variable number of <b>memory</b> <b>cycles</b> to execute. Indirect addressing added 3 <b>memory</b> <b>cycles</b> (30 µs) for each level of indirection. Indexed addressing added 5 <b>memory</b> <b>cycles</b> (50 µs) for each level of indexing. Indirect and indexed addressing could be combined at any level of indirection or indexing.|$|R
25|$|This {{standard}} supports standard <b>memory</b> <b>cycles</b> with {{lengths of}} 1 byte to 4 kilobytes of data, short <b>memory</b> <b>cycles</b> with lengths of 1, 2, or 4 bytes that have much less overhead compared to standard <b>memory</b> <b>cycles,</b> and I/O cycles with lengths of 1, 2, or 4 bytes of data which are low overhead as well. This significantly reduces overhead {{compared to the}} LPC bus, where all cycles except for the 128-byte firmware hub read cycle spends more than one-half {{of all of the}} bus's throughput and time in overhead. The standard <b>memory</b> <b>cycle</b> allows a length of anywhere from 1 byte to 4 kilobytes in order to allow its larger overhead to be amortised over a large transaction. eSPI slaves are allowed to initiate bus master versions of all of the <b>memory</b> <b>cycles.</b> Bus master I/O cycles, which were introduced by the LPC bus specification, and ISA-style DMA including the 32-bit variant introduced by the LPC bus specification, are not present in eSPI. Therefore, bus master <b>memory</b> <b>cycles</b> are the only allowed DMA in this standard.|$|R
5000|$|Magnetic core memory: 32 KB {{capacity}} (<b>memory</b> <b>cycle</b> time of 2 microseconds); ...|$|R
50|$|The {{access time}} plus {{the time to}} rewrite is the <b>memory</b> <b>cycle</b> time.|$|R
5000|$|... memory unit: 4096 12-bit {{words of}} core memory (access time 2.5 microseconds, <b>memory</b> <b>cycle</b> time 16 microseconds) ...|$|R
5000|$|The entire {{core memory}} {{was in the}} IBM 1625 <b>memory</b> unit. <b>Memory</b> <b>cycle</b> time was halved {{compared}} to the Model I's (internal or 1623 memory unit), to 10 µs (i.e., the cycle speed was raised to 100 kHz) by using faster cores. A Memory Address Register Storage (MARS) core memory read, clear, or write operation took 1.5 µs and each write operation was automatically (but not necessarily immediately) preceded by a read or clear operation of the same [...] "register(s)" [...] during the 10 µs <b>memory</b> <b>cycle.</b>|$|R
50|$|To {{obtain the}} operand's address an {{indirect}} indexed instruction required three <b>memory</b> <b>cycles</b> (the index register being in memory) while the direct access instruction required only one.|$|R
50|$|A memory arbiter is {{a device}} {{used in a}} shared memory system to decide, for each <b>memory</b> <b>cycle,</b> which CPU {{will be allowed to}} access that shared memory.|$|R
50|$|Memory {{capacity}} for the 70/55 ranged from 65,536 bytes of core memory to 524,288 bytes. The <b>memory</b> <b>cycle</b> time was 0.84 microseconds to access four bytes of information.|$|R
50|$|Core <b>memory</b> <b>cycle</b> {{times were}} 20 microseconds for the Model I, 10 microseconds for the Model II (about a {{thousand}} times slower than typical computer main memory in 2006).|$|R
5000|$|When [...] is {{asserted}} {{during a}} valid <b>memory</b> <b>cycle,</b> that is, when the processor has asserted the [...] and/or [...] status outputs, the following {{sequence of events}} will occur: ...|$|R
40|$|As {{a nearly}} global language, English as a Foreign Language (EFL) {{programs}} {{are essential for}} people wishing to learn English. Researchers have noted that extensive reading is {{an effective way to}} improve a person's command of English. Choosing suitable articles in accordance with a learner's needs, interests and ability using an e-learning system requires precise learner profiles. This paper proposes a personalized English article recommending system, which uses accumulated learner profiles to choose appropriate English articles for a learner. It employs fuzzy inference mechanisms, <b>memory</b> <b>cycle</b> updates, learner preferences and analytic hierarchy process (AHP) to help learners improve their English ability in an extensive reading environment. By using fuzzy inferences and personal <b>memory</b> <b>cycle</b> updates, it is possible to find an article best suited for both a learner’s ability and her/his need to review vocabulary. After reading an article, a test is immediately provided to enhance a learner’s memory for the words newly learned in the article. The responses of tests can be used to explicitly update <b>memory</b> <b>cycles</b> of the newly-learned vocabulary. In addition, this paper proposes a methodology that also implicitly modifies <b>memory</b> <b>cycles</b> of words that were learned before. By intensively reading articles recommended through the proposed approach, learners comprehend new words quickly and review words that they knew implicitly as well, thereby efficiently improving their vocabulary volume...|$|R
50|$|Memory {{capacities}} for the 70/25 {{ranged from}} a minimum of 16,384 bytes {{to a maximum of}} 65,536 bytes. The <b>memory</b> <b>cycle</b> time was 1.5 microseconds to access one 8 bit byte.|$|R
50|$|Memory {{capacity}} for the 70/45 {{ranged from a}} minimum of 16,384 bytes to 262,144 bytes. The <b>memory</b> <b>cycle</b> time was 1.44 microseconds to access two bytes (one half word) of information.|$|R
50|$|Two memory {{configurations}} for the 70/15 were available: either 4,096 bytes or 8,192 bytes of core <b>memory.</b> The <b>memory</b> <b>cycle</b> {{time for}} a 70/15 was 2 microseconds per byte of information.|$|R
50|$|In the 160 and 160-A, the <b>memory</b> <b>cycle</b> {{time was}} 6.4 microseconds. An add took two cycles. The average {{instruction}} took 15 microseconds, for a processing rate of 67,000 instructions per second.|$|R
50|$|Processor {{performance}} and frequency has grown rapidly {{over the past}} three decades. Post mid-1980's it has grown by 52% annually largely driven by organisational and architectural ideas. 64-bit Intel Xeon processor (2004) can clock at 3.6 GHz thus having a cycle time of 0.27 ns. <b>Memory</b> <b>cycle</b> time however has not grown at this fast rate. This has resulted in processor cycle times being currently much faster than <b>memory</b> <b>cycle</b> times, and the trend has been for this gap to increase over time. The problem of increasing memory latency, relative to processor speed, has been dealt with by adding high speed cache memory.|$|R
5000|$|The 550 and 560 {{supported}} 16 K to 256 K 32-bit words (64 KB to 1 MB) [...] Main <b>memory</b> <b>cycle</b> {{time was}} 645 ns. Virtual memory and memory protection were standard features.|$|R
50|$|The 128-word {{thin-film}} memory general register stack (16 each arithmetic, index, and repeat {{with a few}} in common) had a 300-nanosecond access time with a complete cycle time of 600 nanoseconds. Six <b>cycles</b> of thin-film <b>memory</b> per core <b>memory</b> <b>cycle</b> and fast adder circuitry permitted memory address indexing within the current instruction core <b>memory</b> <b>cycle</b> and also modification of the index value (the signed upper 18 bits {{were added to the}} lower 18 bits) in the specified index register (16 were available). The 16 input/output (I/O) channels also used {{thin-film memory}} locations for direct to memory I/O memory location registers. Programs could not be executed from unused thin-film memory locations.|$|R
5000|$|The first 20,000 decimal digits of Magnetic-core memory were {{internal}} to the CPU itself (which {{reduced the}} floor space {{requirements of the}} basic system). Expansion to either 40,000 or 60,000 decimal digits required the addition of an IBM 1623 Memory unit. The <b>memory</b> <b>cycle</b> time was 20μs ( [...] that is, the memory speed was 50kHz = 1/20th of a MHz). A Memory Address Register Storage (MARS) Core memory read, clear, or write operation took 2 μs and each write operation was automatically (but not necessarily immediately) preceded by a read or clear operation of the same [...] "register(s)" [...] during the 20 μs <b>memory</b> <b>cycle.</b>|$|R
50|$|Super I/O {{devices and}} audio devices {{are allowed to}} accept I/O cycles, accept ISA-style {{third-party}} DMA cycles, and generate bus master <b>cycles.</b> Generic-application <b>memory</b> devices like nonvolatile BIOS memory and LPC flash devices are allowed to accept <b>memory</b> <b>cycles.</b> Firmware hubs are allowed to accept firmware <b>memory</b> <b>cycles.</b> Embedded controllers are allowed to accept I/O cycles and generate bus master cycles. Some ISA cycles that were deemed not useful to these classes were removed. They include host-initiated two-byte <b>memory</b> <b>cycles</b> and host-initiated two-byte I/O cycles. These removed transfer types could be initiated by the host on ISA buses but not on LPC buses. The host would have to simulate two-byte cycles by splitting them up into two one-byte cycles. The ISA bus has a similar concept because the original 8-bit ISA bus required 16-bit cycles to be split up. Therefore, the 16-bit ISA bus automatically split 16-bit cycles into 8-bit cycles {{for the benefit of}} 8-bit ISA peripherals unless the ISA device being targeted by a 16-bit <b>memory</b> or I/O <b>cycle</b> asserted a signal that told the bus that it could accept the requested 16-bit transfer without assistance from an ISA cycle splitter. ISA-style bus mastering has been replaced in the LPC bus with a bus mastering protocol that does not rely on the ISA-style DMA controllers at all. This was done in order to remove ISA's limit on what type of bus master cycles a device is allowed to initiate on which DMA channel. The ISA-style bus cycles that were inherited by LPC from ISA are one-byte host-initiated I/O bus <b>cycles,</b> one-byte host-initiated <b>memory</b> <b>cycles,</b> and one- or two-byte host-initiated ISA-style DMA cycles.|$|R
50|$|The UNIVAC 418 was a transistorized, 18-bit word {{core memory}} machine made by Sperry Univac. The name came from its 4-microsecond <b>memory</b> <b>cycle</b> time and 18-bit word. The {{assembly}} language for {{this class of}} computers was TRIM III and ART418.|$|R
50|$|The 7090 uses a 36-bit word length, with {{an address}} space of 32,768 words (15-bit addresses). It {{operates}} {{with a basic}} <b>memory</b> <b>cycle</b> of 2.18 μs, using the IBM 7302 Core Storage core memory technology from the IBM 7030 (Stretch) project.|$|R
40|$|Abstract-Many {{architecture}} {{features are}} available for improving {{the performance of a}} cache-based system. These hardware techniques include cache memories, processor stalling characteristics, <b>memory</b> <b>cycle</b> time, the external data bus width of a processor, and pipelined memory system, etc. Each of these techniques affects the cost, design, and performance of a system. We present a powerful approach to assess the performance trade-offs of these architecture techniques based on the equivalence of mean memory delay time. For the same perf'ormance point, we demonstrate how each of these features can be traded off and report the ranking of the achievable performance of using them. index Terms-Bus width, cache hit ratio, <b>memory</b> <b>cycle</b> time, performance trade-off, pipelined memory, read-bypassing write buffer. ...|$|R
50|$|Even in {{very simple}} systems, {{at various times}} the data bus {{is driven by the}} program memory, by RAM, and by I/O devices.To prevent bus {{contention}} on the data bus, at any one instant only one device drives the data bus.In very simple systems, only the data bus is required to be a bidirectional bus.In very simple systems, the memory address register always drives the address bus, the control unit always drives the control bus,and an address decoder selects which particular device is allowed to drive the data bus during this bus cycle.In very simple systems, every instruction cycle starts with a READ <b>memory</b> <b>cycle</b> where program <b>memory</b> drives the instruction onto the data bus while the instruction register latches that instruction from the data bus.Some instructions continue with a WRITE <b>memory</b> <b>cycle</b> where the <b>memory</b> data register drives data onto the data bus into the chosen RAM or I/O device.Other instructions continue with another READ <b>memory</b> <b>cycle</b> where the chosen RAM, program memory, or I/O device drives data onto the data bus while the memory data register latches that data from the data bus.|$|R
40|$|Abstract The growing {{difference}} between processor and main <b>memory</b> <b>cycle</b> time necessitates {{the use of}} more aggressive techniques to reduce or hide main memory access latency. Prefetching data into higher speed memories is one such technique. However, speculative prefetching can significantly increase memory traffic...|$|R
25|$|The AGC {{transferred}} data to {{and from}} memory through the G register in a process called the <b>memory</b> <b>cycle.</b> The <b>memory</b> <b>cycle</b> took 12 timing pulses (11.72μs). The cycle began at timing pulse 1 (TP1) when the AGC loaded the memory address to be fetched into the S register. The memory hardware retrieved the data word from memory at the address specified by the S register. Words from erasable memory were deposited into the G register by timing pulse 6 (TP6); words from fixed memory were available by timing pulse 7. The retrieved memory word was then available in the G register for AGC access during timing pulses 7 through 10. After timing pulse 10, the data in the G register was written back to memory.|$|R
40|$|As the {{decrease}} in processor cycle time continues to outpace {{the decrease}} in <b>memory</b> <b>cycle</b> time, even moderately sized on-chip caches may require several cycles of access time in the near future. This means that time is lost, even on a cache hit, if independent instructions cannot be scheduled after a read from memory. A novel hardware device is proposed that keeps track {{of the history of}} load instructions and predicts their targets before they are computed by the instruction pipeline. This allows the saving of several processor cycles. The storage required to implement such a device is quite large, but as the latency required to read from the first level cache grows, a moderate performance improvement is seen. Hardware Support for Hiding Cache Latency January 13, 1995 2 1. 0 Introduction As processor speeds increase to higher and higher levels, the need for a fast memory system becomes more pronounced. In the past, a small, fast first-level cache was adequate to <b>match</b> the <b>memory</b> spe [...] ...|$|R
50|$|If a TLB hit takes 1 clock cycle, a miss takes 30 clock cycles, and {{the miss}} rate is 1%, the {{effective}} <b>memory</b> <b>cycle</b> rate is {{an average of}} 1 × 0.99 + (1 + 30) × 0.01 = 1.30 (1.30 clock <b>cycles</b> per <b>memory</b> access).|$|R
50|$|Memory {{locations}} 1 through 63 {{were used}} as index registers. One hundred and ten instructions were in the instruction set. The CPU included integral block I/O and interrupt facilities. Multiply time was 51-63 microseconds, and divide time was 72-84 microseconds. Basic <b>memory</b> <b>cycle</b> time was 6 microseconds.|$|R
50|$|Instructions {{are fairly}} simple. Most are register-to-register or register-immediate {{instructions}} which execute {{in a single}} <b>memory</b> <b>cycle.</b> There are eight storage reference instructions which require two or three storage cycles to complete. The only shift capability is to shift right one or to add a register to itself.|$|R
40|$|Hardware-assisted garbage {{collection}} {{makes use of}} dedicated circuits located within a special expansion memory module to enhance the response time and throughput of {{garbage collection}} operations. This paper provides detailed descriptions of the <b>memory</b> <b>cycles</b> required to implement each of the primitive garbage collection operations provided by the hardware-assisted garbage collection module. 17 November 1992 Department of Computer Science Iowa State University 226 AtanasoffHall Ames, Iowa 50011 - 1040 *This work {{was supported by the}} National Science Foundation under Grant MIP- 9010412. <b>Memory</b> <b>Cycle</b> Accountings for HardwareAssisted Real-Time Garbage Collection * Kelvin Nilsen 1. Background Acomplete description of the hardware-assisted garbage-collection architecture and algorithm is provided in references [1 - 3]. The overall system architecture is illustrated below: The garbage-collected memory module plays the role of traditional expansion memory within a standard bus-orie [...] ...|$|R
50|$|Fast storage was 1024 40-bit {{words of}} {{magnetic}} core <b>memory</b> (<b>cycle</b> time 5µs), directly addressable as 1024 full or 2048 half-words. This was complemented by an additional 8192 words of backing store on magnetic drum (3000 rpm). A full word stored 40-bit numbers in two's-complement form, or two 20-bit instructions.|$|R
50|$|The CPU had a CPU and <b>memory</b> <b>cycle</b> time of 480 ns. Main {{memory was}} {{composed}} of MOSFET monolithic integrated circuits. The Model 115 came standard with 65,536 (64 KB) of memory, but it could optionally be ordered with up to 196,608 (192 KB). The system had a CRT operator console.|$|R
