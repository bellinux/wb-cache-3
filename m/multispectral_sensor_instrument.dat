1|1053|Public
40|$|The use {{of digital}} soil mapping, {{with the help}} of spectroscopic data, {{provides}} a non-destructive and cost-efficient alternative to soil property laboratory measurements. Visible, near-infrared and short wave infrared (VNIR/ SWIR, 400 - 2500 nm) hyperspectral imaging {{is one of the most}} promising tools for topsoil property mapping. The aim of this study was to test the sensitivity of soil property prediction results to coarsening image spectral resolution. This may offer an analysis of the potential of forthcoming hyperspectral satellite sensors, e. g., HYPerspectral X IMagery (HYPXIM) or Environmental Mapping and Analysis Program (EnMAP), and existing multispectral sensors, e. g., SENTINEL- 2 <b>Multispectral</b> <b>Sensor</b> <b>Instrument</b> (MSI) or LANDSAT- 8 Operational Land Imager (OLI), for soil properties mapping. This study used VNIR/SWIR hyperspectral airborne data acquired by the AISA-DUAL sensor (initial spectral and spatial resolutions of approximately 5 nm and 5 m, respectively) over a 300 km(2) Mediterranean rural region. Ten spectral configurations were built and divided in the following two groups: i) six spectral configurations corresponding to simulated sensors with regular spectral resolution from 5 nm to 200 nm (i. e., the Full Width at Half Maximum (FWHM) remains constant throughout the considered spectral domain; this includes the simulation of the forthcoming HYPXIM and EnMAP hyperspectral satellites) and ii) four spectral configurations corresponding to existing multispectral sensors with irregular spectral resolution (i. e., the FWHM differs from spectral sampling interval; Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER), SENTINEL- 2 MSI, LANDSAT- 7 Enhanced Thematic Mapper (ETM +) and LANDSAT- 8 OLI). The soil property studied in this paper is the clay content, defined as the percentage of granulometric fraction finer than 2 mu m by weight of the soil, which will be estimated using the partial least squares regression method. Our results showed that i) spectral configurations with regular spectral resolutions from 5 to 100 nm provided similar and good clay content prediction performances (R-val(2) > 0. 7 and RPIQ > 3) and allowed clay mapping with correct short-scale variations, ii) the spectral configuration with a regular spectral resolution of 200 nm provided unsatisfactory clay content prediction performance (R-val(2) similar or equal to 0. 01 and RPIQ similar or equal to 1. 65) and iii) the ASTER sensor was the only existing multispectral sensor that provided both correct performance of clay content estimation (R-val(2) similar or equal to 0. 8 and RPIQ similar or equal to 3. 72) and correct clay mapping. Therefore, clay mapping by the ASTER multispectral data should be pursued while awaiting the launch of forthcoming hyperspectral satellite sensors (e. g., HYPXIM and EnMAP), which will be good candidates for future large clay mapping campaigns over bare soils...|$|E
40|$|International audienceRecent {{simulations}} of <b>multispectral</b> <b>sensors</b> {{are based on}} a simple Gaussian model, which includes filters transmittance and substrate absorption. In this paper we want to make the distinction between these two layers. We discuss the balance of energy by channel in <b>multispectral</b> solid state <b>sensors</b> and propose an updated simple Gaussian model to simulate <b>multispectral</b> <b>sensors.</b> Results are based on simulation of typical sensor configurations...|$|R
5000|$|... 5. 2005- stealth technology, <b>multispectral</b> <b>sensors,</b> {{networked}} : F-22, F-35, PAK FA, Chengdu J-20 ...|$|R
40|$|Approved {{for public}} release, {{distribution}} unlimitedThe Worldview- 2 satellite, scheduled for launch in 2009, {{will have a}} <b>multispectral</b> <b>sensor</b> with several additional spectral bands not available on current <b>multispectral</b> <b>sensors.</b> This research investigates {{the use of the}} additional yellow spectral band to derive bathymetry. A hyperspectral image acquired from the AVIRIS sensor was used as a substitute image for the Worldview- 2 <b>multispectral</b> <b>sensor.</b> The image was processed using the Stumpf et al. (2003) "ratio method" to determine bathymetry in a section of Kaneohe Bay, Hawaii. Depths acquired using the green/blue, yellow/green and yellow/blue ratios were compared to ground truth bathymetry derived from a digital nautical chart. The results indicate that using the Stumpf et al. (2003) algorithm with yellow/green and yellow/blue ratios improves the accuracy of derived depths compared to depths derived using the green/blue ratio, especially in shallow waters. US Navy (USN) author...|$|R
40|$|A <b>multispectral</b> optical <b>sensor</b> {{collects}} data {{at select}} wavebands or channels. An {{example is the}} Sea-viewing Wide-Field-of-view Sensor (SeaWiFS) ocean color satellite, which measures eight wavebands between 402 and 885 nm (20 - 40 nm bandwidth with peaks centered around 412, 443, 490, 510, 555, 670, 765, and 865 nm). Optical oceanographers have been using <b>multispectral</b> <b>sensors</b> since the 1980 s with great success...|$|R
40|$|Within this paper, a {{methodology}} for the cross- calibration of <b>multispectral</b> <b>sensors</b> based on spaceborne hyperspectral, and its practical implementation for a consistent re-processing of 30 + years of NOAA AVHRR data are shown. For the development, a large variety of HYPERION images including typical surface spectral signatures for Western, Central, South and Eastern Europe, Scandinavia, {{as well as}} Northern Africa are used, also covering different seasonal and phenological conditions. This extensive database of hyperspectral imagery is then used to simulate the spectral responses of various <b>multispectral</b> <b>sensors.</b> Extending the approach from STEVEN et al. [1, 2], statistically robust models are developed in order to derive intercalibration factors for the specific sensor spectral responses. By applying these factors, differences caused by the spectral response functions of <b>multispectral</b> <b>sensors</b> can be reduced resulting in an increased consistency in multi- sensoral time series. This finding underpins the need for spaceborne imaging spectrometers such as HYPERION, the upcoming EnMAP and HISUI, and dedicated missions such as the proposed TRUTHS, {{which can be used}} as a direct reference for spectral and radiometric cross-calibration...|$|R
30|$|For the analysis, we will {{consider}} the case of a camera based on N=[3, 5, 8, 12] bands. We chose a three-band sensor to represent the typical color case, five bands are chosen for <b>multispectral</b> color <b>sensors</b> or colorimeters [44]. The eight bands are selected for comparison with an existing filter realization [3, 7]. Twelve bands are chosen, as they are expected to provide the best spectral reconstruction used in <b>multispectral</b> <b>sensors</b> [43, 45].|$|R
40|$|System {{promises}} {{capability of}} rapidly processing {{large amounts of}} data generated by currently available and planned <b>multispectral</b> <b>sensors,</b> such as those utilized on aircraft and spacecraft. Techniques developed for system, greatly decrease operator time required for signature extraction from multispectral data base...|$|R
40|$|After {{almost three}} decades of {{successful}} data acquisition using <b>multispectral</b> <b>sensors</b> the first space based hyperspectral sensors were launched in 2000 on the NASA EO- 1 satellite. However, airborne hyperspectral sensors such as AVIRIS, among others, have been generating useful data for many years. Th...|$|R
5000|$|Ball Aerospace built WorldView-2. It was {{launched}} on October 8, 2009. DigitalGlobe partnered with Boeing commercial launch services to deliver WorldView-2 into a sun-synchronous orbit. The satellite includes a panchromatic sensor with a 46 cm maximum resolution and a <b>multispectral</b> <b>sensor</b> of 184 cm ...|$|R
40|$|Band {{selection}} {{is essential in}} the design of <b>multispectral</b> <b>sensor</b> systems. This paper describes the TNO hyperspectral band selection tool HYBASE. It calculates the optimum band positions given the number of bands and the width of the spectral bands. HYBASE is used to assess the minimum number of spectral bands that is required to get the best targetbackground contrast. The band selection algorithm is described along with a description of the graphical user interface. HYBASE is tested on a representative dataset. The test results shed new light on the optimum band selection. HYBASE is developed for the Royal Netherlands Army to investigate the benefit brought by hyper- or <b>multispectral</b> <b>sensors</b> in comparison to present day broad band sensors. HYBASE is tested in European field trials...|$|R
40|$|The {{use of a}} solar-diffuser {{panel is}} a {{desirable}} approach to the on-board absolute radiometric calibration of satellite <b>multispectral</b> <b>sensors</b> used for earth observation in the solar reflective spectral range. It provides a full aperture, full field, end-to-end calibration {{near the top of}} the sensor's dynamic range and across its entire spectral response range. A serious drawback is that the panel's reflectance, and the response of any simple detector used to monitor its reflectance may change with time. This paper briefly reviews some preflight and on-board methods for absolute calibration and introduces the ratioing-radiometer concept in which the radiance of the panel is ratioed with respect to the solar irradiance at the time the <b>multispectral</b> <b>sensor</b> is viewing the panel in its calibration mode...|$|R
40|$|Hyperspectral imaging {{has become}} a fast growing {{technique}} in remote sensing image processing due to recent advances of hyperspectral imaging technology. It makes use {{of as many as}} hundreds of contiguous spectral bands to expand the capability of <b>multispectral</b> <b>sensors</b> that use tens of discrete spectral bands. As a result...|$|R
40|$|Hyperspectral sensors acquire {{hundreds}} {{to thousands}} of channels which provide more spectral information (Du et al., 2004) than the <b>multispectral</b> <b>sensors,</b> for instance. The high spectral resolution of hyperspectral data helps in discovering minor differences in narrow-band reflectance caused by various vegetation types and characteristics thereof, which are not detectable with multispetral dat...|$|R
5000|$|Lockheed Martin AN/AAQ-39 Gunship <b>Multispectral</b> <b>Sensor</b> System (GMS2) - EO/IR {{fire control}} system {{consists}} of mid-wave infrared (MWIR) FLIR, two Image-Intensified Television (I2TV) cameras (CCD-TV), laser target designator/rangefinder with eyesafe mode (1064 and 1570 nm dual mode laser emitter), and near-infrared (NIR) laser pointer/marker (860 nm laser emitter) (mounted under {{the nose of}} port landing gear sponson) ...|$|R
40|$|International audienceThanks to some {{technical}} progress in interferencefilter design based on different technologies, we can finally successfully implement {{the concept of}} <b>multispectral</b> filter array-based <b>sensors.</b> This article provides the relevant state-of-the-art for multispectral imaging systems and presents {{the characteristics of the}} elements of our <b>multispectral</b> <b>sensor</b> as a case study. The spectral characteristics are based on two different spatial arrangementsthat distribute eight different bandpass filters in the visible and near-infrared area of the spectrum. We demonstrate that the system is viable and evaluate its performance through sensor spectral simulation...|$|R
40|$|Airborne {{multispectral}} and hyperspectral {{remote sensing}} {{is a powerful}} tool for environmental monitoring applications. In this paper we describe a new system (ASPIS) composed by a 4 -CCD spectral sensor, a thermal IR camera and a laser altimeter that is mounted on a flexible Sky-Arrow airplane. A test application of the <b>multispectral</b> <b>sensor</b> to estimate durum wheat quality is also presented...|$|R
40|$|In {{this paper}} we use {{different}} co-occurrence texture measures to extract information on different building densities inside a town structure from ASAR images. Our method {{is applied to}} single channel and polarimetric ASAR data individually and jointly. We also analyze data coming from the Envisat- 1 <b>Multispectral</b> <b>sensor</b> MERIS to analyze the relevance of such data for urban areas characterization. 1...|$|R
40|$|International audienceThis paper studies a new Bayesian {{algorithm}} for fusing hyperspectral and multispectral images. The observed {{images are}} related to the high spatial resolution hyperspectral image to be recovered through physical degradations, e. g., spatial and spectral blurring and/or sub-sampling defined by the sensor characteristics. In this work, we assume that the spectral response of the <b>multispectral</b> <b>sensor</b> is unknown as it may not be available in practical applications. The resulting fusion problem is formulated within a Bayesian estimation framework, which is very convenient to model the uncertainty regarding the <b>multispectral</b> <b>sensor</b> characteristics and the scene to be estimated. The high spatial resolution hyperspectral image is then inferred from its posterior distribution. More precisely, to compute the Bayesian estimators associated with this posterior, a Markov chain Monte Carlo algorithm is proposed to generate samples asymptotically distributed according to the distribution of interest. Simulation results demonstrate the efficiency of the proposed fusion method when compared with several state-of-the-art fusion techniques...|$|R
40|$|Abstract: Combining {{multiple}} proximal sensors {{within a}} {{wireless sensor network}} (WSN) enhances our capacity to monitor vegetation, compared to using a single sensor or non-networked setup. Data from sensors with different spatial and temporal characteristics can provide complementary information. For example, point-based <b>sensors</b> such as <b>multispectral</b> <b>sensors</b> which monitor at high temporal frequency but, at a single point, can be complemented by array-based sensors such as digital cameras which have greater spatial resolution but may only gather data at infrequent intervals. In this article we describe the successful deployment of a prototype system for using multiple proximal <b>sensors</b> (<b>multispectral</b> <b>sensors</b> and digital cameras) for monitoring pastures. We show {{that there are many}} technical issues involved in such a deployment, and we share insights relevant for other researchers who may consider using WSNs for an operational deployment for pasture monitoring under often difficult environmental conditions. Although the sensors andJ. Sens. Actuator Netw. 2013, 2 389 infrastructure are important, we found that other issues arise and that an end-to-en...|$|R
40|$|This paper studies a new Bayesian {{algorithm}} for fusing hyperspectral and multispectral images. The observed {{images are}} related to the high spatial resolution hyperspectral image to be recovered through physical degradations, e. g., spatial and spectral blurring and/or sub-sampling defined by the sensor characteristics. In this work, we assume that the spectral response of the <b>multispectral</b> <b>sensor</b> is unknown as it may not be available in practical applications. The resulting fusion problem is formulated within a Bayesian estimation framework, which is very convenient to model the uncertainty regarding the <b>multispectral</b> <b>sensor</b> characteristics and the scene to be estimated. The high spatial resolution hyperspectral image is then inferred from its posterior distribution. More precisely, to compute the Bayesian estimators associated with this posterior, a Markov chain Monte Carlo algorithm is proposed to generate samples asymptotically distributed according to the distribution of interest. Simulation results demonstrate the efficiency of the proposed fusion method when compared with several state-of-the-art fusion techniques...|$|R
40|$|The aim of {{this study}} is to assess the {{suitability}} of four spaceborne <b>multispectral</b> <b>sensors</b> (Spot 5 HRG, Landsat 5 TM, Landsat 7 ETM+, and IKONOS) for inter-tidal sediment characterization, in comparison to a hyperspectral image of 4 m x 4 m spatial resolution and 116 spectral bands. Four sediment properties were considered: organic matter content, moisture content, chlorophyll a content, and mud content. The utilized data were a hyperspectral image and its accompanying field data. The methodology included spectral and spatial resampling of this image to the properties of the spaceborne <b>multispectral</b> <b>sensors.</b> Then, these resampled data were analyzed by means of unsupervised classification. The results showed that spaceborne multispectral data have the potential for sediment characterization. Yet, compared to the hyperspectral image, the characterization of the different properties generally decreased. The results showed the spectral suitability of Landsat sensors to characterize all properties and the spectral and spatial suitability of all sensors to characterize chlorophyll a content...|$|R
40|$|The oceans are {{monitored}} since decades using <b>multispectral</b> <b>sensors</b> on satellite, {{but very}} little {{information is available}} {{for the majority of}} inland waters since they are too small for ocean colour satellites, optically too complex for most <b>multispectral</b> <b>sensors</b> and too numerous (around 120 million lakes > 15 m) for traditional sampling. Since inland waters cover less than 4 % of Earth's surface, their importance for global processes has long been overlooked, but new data indicate that they may be more important than the oceans in some aspects, e. g. they bury twice as much carbon from the atmosphere by sedimentation. A number of hyperspectral space sensors will be launched in the next years whose resolution of 30 m is suited to monitor water quality of nearly 90 % of the lake areas. I present the principles of the models that are used to analyse hyperspectral data over water and discuss the potential and challenges of hyperspectral imaging for optically complex water types...|$|R
5000|$|CD6 - Centre for <b>Sensors,</b> <b>Instruments</b> and Systems Development ...|$|R
40|$|Large scale water {{resource}} investigations and effective pollution surveillance program require {{the development of}} additional instrumentation and techniques to supplement existing methods of data acquisition. As a result, interest is growing {{in the concept of}} remote sensing. Described in this paper is the <b>multispectral</b> <b>sensor</b> concept and its application in {{water resource}} studies. KEY WORDS: remote sensing; water pollution surveillance; industrial wastes; water pollution control; instrumentatio...|$|R
40|$|Modern CMOS {{processes}} {{allow the}} fabrication of structured metal layers with spectral and polarization selective properties for visible light. Using such "optical nanostructures", <b>multispectral</b> <b>sensors</b> and polarization sensors {{as well as}} enhanced image sensors can be manufactured in a cost-effective way. The research on optical nanostructures is accelerated by Finite Difference Time Domain simulation and by automated layout generation. The experimental results demonstrate the feasibility of color and polarization filters...|$|R
5000|$|Multispectral imaging {{deals with}} several images at {{discrete}} and somewhat narrow bands. Being [...] "discrete and somewhat narrow" [...] is what distinguishes multispectral imaging in the visible wavelength from color photography. A <b>multispectral</b> <b>sensor</b> may have many bands covering the spectrum from the {{visible to the}} longwave infrared. Multispectral images do not produce the [...] "spectrum" [...] of an object. Landsat {{is an excellent example}} of multispectral imaging.|$|R
40|$|Usual {{image fusion}} methods inject {{features}} {{from a high}} spatial resolution panchromatic sensor into every low spatial resolution multispectral band trying to preserve spectral signatures and improve spatial resolution {{to that of the}} panchromatic sensor. The objective is to obtain the image that would be observed by a sensor with the same spectral response (i. e., spectral sensitivity and quantum efficiency) as the <b>multispectral</b> <b>sensors</b> and the spatial resolution of the panchromatic sensor. But in these methods, features from electromagnetic spectrum regions not covered by <b>multispectral</b> <b>sensors</b> are injected into them, and physical spectral responses of the sensors are not considered during this process. This produces some undesirable effects, such as resolution overinjection images and slightly modified spectral signatures in some features. The authors present a technique which takes into account the physical electromagnetic spectrum responses of sensors during the fusion process, which produces images closer to the image obtained by the ideal sensor than those obtained by usual wavelet-based image fusion methods. This technique is used to define a new wavelet-based image fusion method...|$|R
40|$|There is an {{increasing}} demand for future airborne reconnaissance systems to obtain aerial images for tactical or peacekeeping operations. Especially Unmanned Aerial Vehicles (UAVs) equipped with <b>multispectral</b> <b>sensor</b> systems and with real time jam resistant data transmission capabilities are ofhigh interest. An airborne experimental platform has been developed as testbed to investigate different concepts of reconnaissance systems before their application in UAVs. It {{is based on a}} Dornier DO 228 aircraft, which is used as flying platform. Great care has been taken to achieve the possibility to test different kinds of <b>multispectral</b> <b>sensors.</b> Hence basically it is capable to be equipped with an infrared sensor head, high resolution aerial cameras of the whole optical spectrum and radar systems. The onboard equipment further includes systems for digital image processing, compression, coding, and storage. The data are RF transmitted to the ground station using technologies with high jam resistance. The images, after merging with enhanced vision components, are delivered to the observer who has an uplink data channel available to control flight and imaging parameters...|$|R
40|$|This paper proposes an {{unsupervised}} clustering algorithm for multispectral images, which automatically {{determines the}} number of statistically distinct clusters in the image. It uses the multivariate student-t distribution as a more flexible un-derlying statistical model, with the Gaussian as only a special case. The algorithm shows better data modeling flexibility than the Gaussian case. Excellent and reproducible clustering results are observed for both simulated data and real data from Worldview- 2 <b>multispectral</b> <b>sensor...</b>|$|R
40|$|The {{solid-state}} array spectroradiometer (SAS) {{developed at}} JSC for remote sensing applications is a <b>multispectral</b> <b>sensor</b> {{which has no}} moving parts, is virtually maintenance-free, and {{has the ability to}} provide data which requires a minimum of processing. The instrument is based on the 42 x 342 element charge injection device (CID) detector. This system allows the combination of spectral scanning and across-track spatial scanning along with its associated digitization electronics into a single detector...|$|R
40|$|Adaptive data {{processing}} procedures {{are applied to}} the problem of classifying objects in a scene scanned by <b>multispectral</b> <b>sensor.</b> These procedures show a performance improvement over standard nonadaptive techniques. Some sources of error in classification are identified and those correctable by adaptive processing are discussed. Experiments in adaptation of signature means by decision-directed methods are described. Some of these methods assume correlation between the trajectories of different signature means; for others this assumption is not made...|$|R
40|$|In {{this work}} is {{presented}} a study of some aspects concerning {{the evaluation of the}} forest inventory of the territory of the Modena (Italy) district using remote sensing data. The considered sensors are the ETM+ (Landsat 7) and the <b>multispectral</b> <b>sensor</b> on board of the IKONOS- 2 satellite. In particular, some considerations about the pre-elaboration methods of the data and {{about the quality of the}} classification retrieved using the images acquired by the two sensors are presented...|$|R
40|$|The {{solution}} of matrix equations {{is essential to}} carrying out a large variety of control algorithms and to reducing certain types of data such as the output of a <b>multispectral</b> <b>sensor</b> array. Optical techniques and, in particular, integrated-optical circuits (IOC's) can provide compact, low-power devices for performing the mitrix multiplications necessary for the {{solution of}} these problems. A specific IOC for performing vector-matrix multiplication and several approaches {{to the design of}} IOC's for matrix-matrix multiplication will be discussed...|$|R
40|$|Liquid water {{stored on}} the surface of ice sheets and glaciers impacts surface mass balance, ice dynamics, and heat transport. Multispectral remote sensing can be used to detect supraglacial lakes and {{estimate}} their depth and area. In this study, we use in situ spectral and bathymetric data to assess lake depth retrieval using the recently launched Landsat 8 Operational Land Imager (OLI). We also extend our analysis to other <b>multispectral</b> <b>sensors</b> to evaluate their performance with similar methods. Digital elevation models derived from WorldView stereo imagery (pre-lake filling and post-drainage) are used to validate spectrally derived depths, combined with a lake edge determination from imagery. The optimal supraglacial lake depth retrieval is a physically based single-band model applied to two OLI bands independently (red and panchromatic) that are then averaged together. When OLI- and WorldView-derived depths are differenced, they yield a mean and standard deviation of 0. 0  ±  1. 6  m. This method is then applied to OLI data for the Sermeq Kujalleq (Jakobshavn Isbræ) region of Greenland to study the spatial and intra-seasonal variability of supraglacial lakes during summer 2014. We also give coefficients for estimating supraglacial lake depth using a similar method with other <b>multispectral</b> <b>sensors...</b>|$|R
50|$|The MQ-8B {{is being}} {{modified}} to permit rapid swap out of payload configurations. The current sensor configuration of a day/night turret with a laser target designator will remain an option. Alternate sensor payloads in consideration include a TSAR with Moving Target Indicator (MTI) capability, a <b>multispectral</b> <b>sensor,</b> a SIGINT module, the Target Acquisition Minefield Detection System (ASTAMIDS), and the Tactical Common Data Link (TCDL). The Army wanted the Fire Scout {{to operate as}} an element of an integrated ground sensor network as well.|$|R
