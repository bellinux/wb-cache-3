213|10000|Public
50|$|Likewise in {{numerical}} {{experiments and}} <b>modelling</b> <b>uncertainty</b> analysis draws upon {{a number of}} techniques for determining the reliability of model predictions, accounting for various sources of uncertainty in model input and design. A related field is sensitivity analysis.|$|E
5000|$|Fuzzy {{logic and}} {{probability}} address {{different forms of}} uncertainty. While both fuzzy logic and probability theory can represent degrees of certain kinds of subjective belief, fuzzy set theory uses the concept of fuzzy set membership, i.e., how much an observation is within a vaguely defined set, and probability theory uses the concept of subjective probability, i.e., likelihood of some event or condition. The concept of fuzzy sets {{was developed in the}} mid-twentieth century at Berkeley [...] {{as a response to the}} lacking of probability theory for jointly <b>modelling</b> <b>uncertainty</b> and vagueness.|$|E
40|$|In this note, we {{stress the}} {{relevance}} of developing tools for <b>modelling</b> <b>uncertainty</b> in information management and decision aiding, conceived as previous stages for decision making. We discuss the general framework of <b>modelling</b> <b>uncertainty</b> in decision making problems and briefly introduce the specific models we have selected to illustrate these ideas, as developed by researchers...|$|E
40|$|In {{this note}} a one-state, one-control {{variable}} quadratic linear problem with robust control and discount factor is developed {{to examine the}} optimal response of the first-period control to changes in future <b>model</b> <b>uncertainty.</b> A change in future <b>model</b> <b>uncertainty</b> {{has an effect on}} the optimal first-period control response going {{in the same direction as}} the one caused by an equal size change in current <b>model</b> <b>uncertainty.</b> However, both analytical and numerical results show that such effect is much lower than the one derived from a change in current <b>model</b> <b>uncertainty.</b> Moreover, such effect is even much lower as the change in <b>model</b> <b>uncertainty</b> moves farther away into the future. Finally, the infinite horizon result confirms the reinforcing nature of the effects on the optimal first-period control response of current and future changes in <b>model</b> <b>uncertainty.</b> Copyright Kluwer Academic Publishers 2004 macroeconomic policy, <b>model</b> <b>uncertainty,</b> optimal control, robustness,...|$|R
40|$|As any {{model is}} only an {{abstraction}} of the real world, <b>model</b> <b>uncertainty</b> always exists. The magnitude of <b>model</b> <b>uncertainty</b> is important for geotechnical decision making. If <b>model</b> <b>uncertainty</b> is not considered, the geotechnical predictions and hence the decisions based on the geotechnical predictions might be biased. In this study, a framework for characterizing geotechnical <b>model</b> <b>uncertainty</b> using observation data is proposed. The framework {{is based on the}} concept of multivariable Bayesian updating, in which the statistics of <b>model</b> <b>uncertainty</b> are updated using observed performance data. Uncertainties in both input parameters and observed data can be considered in the proposed framework. To bypass complex computational works involved in the proposed framework, a practical approximate solution is presented. The proposed framework is illustrated by characterizing the <b>model</b> <b>uncertainty</b> of four limit equilibrium methods for slope stability analysis using quality centrifuge test data. Parametric study in the illustrative example shows that both quality and quantity of the performance data could affect the determination of the <b>model</b> <b>uncertainty,</b> and that such effects can be systematically quantified with the proposed method...|$|R
40|$|Abstract — <b>Model</b> <b>uncertainty</b> {{limits the}} {{utilization}} of Model Predictive Controllers (MPC) to minimize building energy consumption. We propose a new Robust Model Predictive Control (RMPC) structure to make a building controller robust to <b>model</b> <b>uncertainty.</b> The results from RMPC are compared with those from a nominal MPC and a common building Rule Based Control (RBC). The results are then used to develop a methodology for selecting a controller type (i. e. RMPC, MPC, and RBC) {{as a function of}} building <b>model</b> <b>uncertainty.</b> RMPC is found to be the desirable controller for the cases with an intermediate level (30 %- 67 %) of <b>model</b> <b>uncertainty,</b> while MPC is preferred for the cases with a low level (0 - 30 %) of <b>model</b> <b>uncertainty.</b> A common RBC is found to outperform MPC or RMPC if the <b>model</b> <b>uncertainty</b> goes beyond a certain threshold (e. g. 67 %). I...|$|R
40|$|A {{thruster}} {{fault tolerant}} control (FTC) method is developed for underwater {{vehicles in the}} presence of <b>modelling</b> <b>uncertainty,</b> external disturbance and unknown thruster fault. The developed method incorporates the sliding mode algorithm and backstepping scheme to improve its robustness to <b>modelling</b> <b>uncertainty</b> and external disturbance. In order to be independent of the fault detection and diagnosis (FDD) unit, thruster fault is treated {{as a part of the}} general uncertainty along with the <b>modelling</b> <b>uncertainty</b> and external disturbance, and radial basis function neural network (RBFNN) is adopted to approximate the general uncertainty. According to the Lyapunov theory, control law and adaptive law of RBFNN are derived to ensure the tracking errors asymptotically converge to zero. Trajectory tracking simulations of underwater vehicle subject to <b>modelling</b> <b>uncertainty,</b> ocean currents, tether force and thruster faults are carried out to demonstrate the effectiveness and feasibility of the proposed method...|$|E
40|$|Nonlinear {{finite element}} {{analyses}} (NLFEA) allow for simulation {{of the expected}} real nonlinear structural behaviour of reinforced concrete structures. NLFEA in structural safety assessment does however introduce potentially significant uncertainties to the design procedure due to complex numerical modelling, which requires comprehension, and management by suitable safety formats. The <b>modelling</b> <b>uncertainty</b> comprises the uncertainties introduced by the solution strategy, the finite element analysis (FEA) software and the user to the design procedure. Solution strategy {{is used as a}} collective term for the finite element model and the analysis procedure. In this master s thesis, a structural safety assessment of a reinforced concrete structural wall is performed, with emphasis on assessing and evaluating the <b>modelling</b> <b>uncertainty.</b> The nonlinear FEA software DIANA, version 9. 6, is used for all the finite element analyses, and a previously experimental test study of structural walls is used as reference case. Validation of a solution strategy based on recommendations by the Dutch guidelines (DG) for use on structural walls is focused on, since validated guidelines for NLFEA may help minimize the <b>modelling</b> <b>uncertainty</b> and improve the efficiency of the design method. The actual <b>modelling</b> <b>uncertainty</b> is estimated by a statistical approach to multiple structural walls, and relevant global safety formats are applied in the safety assessment, and evaluated with emphasis on the incorporated value of the <b>modelling</b> <b>uncertainty</b> and the impact on the design capacity. The design capacity is also assessed by an analytical method of strut-and-tie modelling. Deficiencies and sources of <b>modelling</b> <b>uncertainty</b> are highlighted in the discussions. The results should be relevant for further studies on this subject and possibly also for later users of NLFEA in assessment of concrete structures for a safer and more efficient use. The estimated <b>modelling</b> <b>uncertainty</b> of a mean ratio of experimental to predicted strength θm= 1. 21 and a coefficient of variation of the modelling Vθ= 6. 6 % reflects the observed similar behaviour of multiple walls, though at low applied load levels compared to the experimental tests. The constitutive modelling indicates to be the main contributor to the systematic underestimation of the load capacity. The evaluated safety formats provide design capacities greater than by the analytical method, where the safety format by Schlune et. al and ECOV provide the highest design capacity. Significant values of the <b>modelling</b> <b>uncertainty</b> are observed in this study. Until the observed limitations in DG and the FEA software DIANA have been addressed, the selected solution strategy should not be considered as validated for use on structural walls in general, based only on this study. Prescribed, low values of the <b>modelling</b> <b>uncertainty</b> and no correction of bias in the model in the safety formats may be improper for many problems. The difficulty of handling bias, and the <b>modelling</b> <b>uncertainty</b> s dependency on a selected solution strategy and FEA software, is clarified during this evaluation. Model validation and a conscious inclusion of the <b>modelling</b> <b>uncertainty</b> into the safety formats is confirmed as essential for a reliable and profitable use of NLFEA in structural safety assessment...|$|E
40|$|Non-linear {{finite element}} {{analyses}} (NLFEA) of reinforced concrete structures have gained much {{attention in the}} structural engineering community during the last decade, and the practising engineer is now equipped with an advanced tool {{that can be used}} in the design process. The three main objectives of the present work has been i) to develop a solution strategy for NLFEA applicable during design of large reinforced concrete structures, ii) to quantify the <b>modelling</b> <b>uncertainty</b> obtained with the solution strategy, and iii) to quantify the variability of the compressive strength of concrete. These are central ingredients in the semi-probabilistic safety formats for NLFEA introduced in the literature. A solution strategy comprises all the choices that need to be made in order to perform a NLFEA, and the <b>modelling</b> <b>uncertainty</b> indicates how well the analysis outcomes compare to the real physical behaviour. A three dimensional material model for concrete was adapted and implemented in a finite element software. The material model required only one material parameter, the uniaxial compressive strength. The complete solution strategy is discussed in detail in the appended papers. A refinement of the solution strategy is only justified if the resulting <b>modelling</b> <b>uncertainty</b> is reduced, if necessary knowledge about the basic variables can be obtained, and if in the end it can be shown to produce results that provide a better basis for decision making. The <b>modelling</b> <b>uncertainty</b> was quantified by comparing NLFEA predictions to experimental outcomes, resulting in a bias of 1. 10 and a coefficient of variation of 0. 11. All the uncertainties that are not explicitly considered in the NLFEA will implicitly contribute to the estimated <b>modelling</b> <b>uncertainty,</b> and a pure <b>modelling</b> <b>uncertainty</b> is thus not straightforward to obtain. This is unfortunate, since the <b>modelling</b> <b>uncertainty</b> will carry a large part of the uncertainties in the problem. However, it can be useful, since the analyst later does not need to consider the uncertainties that were not considered during quantification of the <b>modelling</b> <b>uncertainty.</b> A hierarchical model for the variability of material properties was formulated for the study of the compressive strength of ready-mixed concrete. By combining Bayesian inference and maximum likelihood estimators, the contributions from the different hierarchical levels were quantified. The method was demonstrated on more than 14000 compressive strength recordings from the Norwegian market. The results indicate that the designer should specify strength classes that better utilize the strength potential of the durability class. A closer collaboration between the designer, contractor and the producer is expected to result in improved concrete specifications. In addition to summarizing the main findings of the work, this thesis contains a part describing the background and the context of the work...|$|E
40|$|Abstract. In {{this note}} a one-state, one-control {{variable}} quadratic linear problem with robust control and discount factor is developed {{to examine the}} optimal response of the first-period control to changes in future <b>model</b> <b>uncertainty.</b> A change in future <b>model</b> <b>uncertainty</b> {{has an effect on}} the optimal first-period control response going {{in the same direction as}} the one caused by an equal size change in current <b>model</b> <b>uncertainty.</b> However, both analytical and numerical results show that such effect is much lower than the one derived from a change in current <b>model</b> <b>uncertainty.</b> Moreover, such effect is even much lower as the change in <b>model</b> <b>uncertainty</b> moves farther away into the future. Finally, the infinite horizon result confirms the reinforcing nature of the effects on the optimal first-period control response of current and future changes in <b>model</b> <b>uncertainty.</b> Key words: optimal control; model uncertainty; robustness; macroeconomic policy 1...|$|R
40|$|Knowledge about model error or <b>model</b> <b>uncertainty</b> is {{essential}} for liquefaction analysis. <b>Model</b> <b>uncertainty</b> characterization is generally not easy due {{to the presence of}} a large number of uncertain model input parameters. The Bayesian network is a versatile tool for analyzing problems involving a large number of uncertain variables. In this paper, a Bayesian network is developed to determine the <b>model</b> <b>uncertainty</b> of liquefaction evaluation models considering the parameter uncertainties. An approximate variable elimination algorithm is suggested to reduce the computational work in <b>model</b> <b>uncertainty</b> characterization. A weighted likelihood function is used to consider the sampling bias in the calibration database. The <b>model</b> <b>uncertainty</b> of a liquefaction model is studied to illustrate the proposed method. It is found that the model is on average biased towards the conservative side. Ignoring the <b>model</b> <b>uncertainty</b> is a convenient assumption, but it may result in either overestimation or underestimation of the reliability index...|$|R
40|$|<b>Model</b> <b>uncertainty</b> hampers {{consensus}} on the key determinants of economic growth. Some recent cross-country cross-sectional analyses have employed Bayesian Model Averaging to tackle the issue of <b>model</b> <b>uncertainty.</b> This paper extends that approach to panel data models with country-specific fixed effects in order to simultaneously address <b>model</b> <b>uncertainty</b> and endogeneity issues. The empirical findings suggest that in a panel setting the most robust growth determinants are the price of investment goods, distance to major world cities, and political rights. Growth determinants, <b>model</b> <b>uncertainty,</b> bayesian <b>model</b> averaging, dynamic panel estimation...|$|R
40|$|Concrete is {{the most}} widely used {{construction}} material in the world. To obtain effective new constructions and to use existing concrete structures in an optimal way, accurate structural models are needed. This requires that good approximations of important model parameters be available and that the nonlinear material response of concrete can be accounted for. However, uncertain model parameters can significantly influence the structural response modelled which leads to high <b>modelling</b> <b>uncertainty.</b> To estimate uncertain parameters a methodology is proposed and applied to the new Svinesund Bridge to improve the initial finite element model through finite element model updating using on-site measurements. To account for the nonlinear material response, it is also necessary to have a safety format suited to nonlinear analysis. However, the available safety formats for nonlinear analysis have been questioned and the need to quantify the <b>modelling</b> <b>uncertainty</b> of nonlinear analysis has been highlighted, Carlsson et al. (2008). Therefore, the <b>modelling</b> <b>uncertainty</b> of nonlinear analysis was quantified based on available data. It was found that the uncertainty varies significantly depending on the failure mode obtained and that this uncertainty was often the factor that governed the safety evaluation. Based on this observation, a new safety format is proposed which allows the <b>modelling</b> <b>uncertainty</b> be explicitly accounted for. To facilitate realistic modelling the mean in situ material parameters are used in the nonlinear analysis; the reliability is assured by a, so called, resistance safety factor. Apart from the <b>modelling</b> <b>uncertainty,</b> the resistance safety factor depends on the material and geometrical uncertainty. It was found that the material variability can be estimated by using a sensitivity study, which involves two to three additional nonlinear analyses with reduced material strengths. Applying the safety format to short columns loaded by a normal force and to beam sections loaded in bending, shear, and the combination of bending and shear, led to a reliability level that was in good agreement with the target reliability. Other safety formats for nonlinear analysis, according to EN 1992 - 2, CEN (2005), and Model Code 2010, fib (2010 a), fib (2010 b), were found to underestimate the <b>modelling</b> <b>uncertainty</b> of difficult-to-model failure modes, leading to a reliability level below the target reliability. To study the consequences of assuring the safety on the structural level by an inequality of forces, as proposed in Model Code 2010, four safety formats were applied to a concrete portal frame bridge. It was shown that an inequality of forces on the structural level does not necessarily lead to the intended reliability level, unless the deformation capacity used is reliably available...|$|E
40|$|In this paper, an observer-based fault {{estimation}} (FE) {{method is}} presented {{for a class}} of nonlinear networked control systems (NCSs) with Markov transfer delays. First, the nonlinear NCSs are modelled by nonlinear discrete Takagi- Sugeno (T-S) fuzzy model with <b>modelling</b> <b>uncertainty.</b> Under some geometric conditions, the proposed nonlinear T-S model can be transformed into two subsystems {{with one of them}} having backstepping form. Then, the discrete nonlinear observer is designed to provide the estimation of unmeasurable state and the <b>modelling</b> <b>uncertainty,</b> which is used to construct a fault estimation algorithm. Finally, an example is included to show the efficiency of the proposed method. Index Terms-Nonlinear networked control systems, Takagi- Sugeno fuzzy model, fault estimation, observer. Zehui Mao, Bin Jiang, Peng Shi, and Vincent Cocquempo...|$|E
40|$|We {{present a}} deep {{learning}} framework for probabilistic pixel-wise semantic segmentation, which we term Bayesian SegNet. Semantic segmentation {{is an important}} tool for visual scene understanding and a meaningful measure of uncertainty is essential for decision making. Our contribution is a practical system which is able to predict pixel-wise class labels {{with a measure of}} model uncertainty. We achieve this by Monte Carlo sampling with dropout at test time to generate a posterior distribution of pixel class labels. In addition, we show that <b>modelling</b> <b>uncertainty</b> improves segmentation performance by 2 - 3 % across a number of state of the art architectures such as SegNet, FCN and Dilation Network, with no additional parametrisation. We also observe a significant improvement in performance for smaller datasets where <b>modelling</b> <b>uncertainty</b> is more effective. We benchmark Bayesian SegNet on the indoor SUN Scene Understanding and outdoor CamVid driving scenes datasets...|$|E
40|$|There are {{two types}} of {{uncertainty}} that could affect the credibility of a geotechnical analysis, i. e., <b>uncertainty</b> in <b>model</b> input parameters, and uncertainty associated with the prediction model. This research provides theories, solutions, and application examples on <b>model</b> <b>uncertainty</b> characterization utilizing observed performance data from similar geotechnical systems when model input parameters are uncertain and when observed performance cab be subjected to measurement error. This research starts with a literature review on <b>model</b> <b>uncertainty</b> characterization and computational techniques for implementing Bayesian methods. A Bayesian framework is then proposed to identify geotechnical <b>model</b> <b>uncertainty</b> considering both <b>uncertainty</b> in <b>model</b> input parameters and observation uncertainty. In the proposed framework, the <b>model</b> <b>uncertainty</b> parameters are <b>modeled</b> as random variables, and their distributions are updated simultaneously with uncertain model input parameters and uncertain system performance using the observed performance data. To facilitate professional application, a simplified Bayesian formulation involves less computational work is also suggested to characterize <b>model</b> <b>uncertainty</b> approximately. Three methods are developed for <b>model</b> <b>uncertainty</b> characterization, i. e., (1) a maximum posterior density method in the simplified Bayesian framework, (2) a grid calculation method in the simplified Bayesian framework, and (3) Markov chain Monte Carlo (MCMC) simulation in the original Bayesian framework. Among the three methods, MCMC simulation in the original Bayesian framework is most accurate as it depends on fewer assumptions. The maximum posterior density method is less accurate than the grid calculation method as it is not only based on the approximate formulation but also based on the large sample approximation, whereas the grid calculation method only depends on the approximate formulation. The advantage of the maximum posterior density method resides in its ease of implementation. The three methods are of various degrees of theoretical stringency and application convenience. Three application examples are used to thoroughly illustrate these methods for <b>model</b> <b>uncertainty</b> characterization utilizing different types of observed data, and to demonstrate how <b>model</b> <b>uncertainty</b> characterization can help the current geotechnical practice. Particularly, in the first example the <b>model</b> <b>uncertainty</b> of limit equilibrium methods is characterized using point observed data. It is found the knowledge on <b>model</b> <b>uncertainty</b> is crucial for a site-specific back analysis of slope failure. If such knowledge is poor, most observed information would be allocated to update the <b>model</b> <b>uncertainty</b> parameters rather than model input parameters. When there is good knowledge on <b>model</b> <b>uncertainty,</b> most information would be allocated to update the site-specific model input parameters. In such a case, <b>model</b> <b>uncertainty</b> parameters will not be updated much even when they are incorporated in the updating process. Nevertheless, the back analysis of slope failure can be implemented in a simpler manner by excluding the <b>model</b> <b>uncertainty</b> parameters from the updating process. Based on this idea, two easy-to-apply procedures for back analysis of multiple slope stability parameters are suggested. The second example shows the prediction of pile capacity is dominated by <b>model</b> <b>uncertainty.</b> How to treat those piles that were not loaded to failure in pile load tests has important effect on <b>model</b> <b>uncertainty</b> characterization. To incorporate the <b>model</b> <b>uncertainty</b> in daily design, partial factors are developed based on the characterized <b>model</b> <b>uncertainty</b> using a two stage procedure, i. e., (1) calculating the partial factors based on reliability analysis, and (2) adjusting these partial factors to be in compliance with partial factors for loads specified in the structural design codes. After the partial factors are obtained, regression analyses are further conducted to reveal the relationship between the partial factors and the uncertainty structure in the design. In the third example, the <b>model</b> <b>uncertainty</b> of a liquefaction model is evaluated using fully censored data. In particular, how to consider the bias in the database is addressed. This example also illustrates the conceptual difference between reliability analyses with and without considering <b>model</b> <b>uncertainty.</b> If the <b>model</b> <b>uncertainty</b> is not considered, a single limit state surface is drawn to separate the failure region from the safe region in the space of design parameters. If <b>model</b> <b>uncertainty</b> is considered, multiple limit state surfaces with varying probabilities are drawn. If <b>model</b> <b>uncertainty</b> is neglected, the results from the reliability analysis would be over-confident...|$|R
40|$|This paper investigates {{whether the}} <b>model</b> <b>uncertainty</b> of {{reinforced}} recycled aggregate concrete (RAC) beams subjected to bending {{differs from that}} of reinforced natural aggregate concrete (NAC) beams. An introductory remark concerning the importance of the codification of RAC structural design is made and notions concerning <b>model</b> <b>uncertainties</b> and their role on structural codification are given. Afterwards, the criteria used in the construction of a database of RAC and NAC beams are referred before presenting the key findings of an analysis on the <b>model</b> <b>uncertainty</b> of the cracking, yielding and ultimate moments of beams subjected to four-point bending tests. The analytical moments were calculated following Eurocode 2 provisions. Probabilistic <b>models</b> for <b>model</b> <b>uncertainties</b> are proposed. Negligible differences in the <b>model</b> <b>uncertainty</b> of NAC and RAC beams are reported...|$|R
40|$|<b>Model</b> <b>uncertainty,</b> in {{the context}} of {{derivative}} pricing, can be defined as the uncertainty on the value of a contingent claim resulting from the lack of precise knowledge of the pricing model to be used for its valuation. We introduce here a quantitative framework for defining <b>model</b> <b>uncertainty</b> in option pricing models. After discussing some properties which a quantitative measure of <b>model</b> <b>uncertainty</b> should verify in order to be useful and relevant {{in the context}} of risk measurement and management, we propose a method for measuring <b>model</b> <b>uncertainty</b> which verifies these properties and yields numbers which are comparable to other risk measures and compatible with observations of market prices of a set of benchmark derivatives. We illustrate the difference between <b>model</b> <b>uncertainty</b> and the more common notion of "market risk" through examples. Finally, we illustrate the connection between our proposed measure of <b>model</b> <b>uncertainty</b> and the recent literature on coherent and convex risk measures. decision under ambiguity; uncertainty; option pricing; risk measures; mathematical finance...|$|R
40|$|This paper {{introduces}} {{the concept of}} Temporal Hierarchies for time series forecasting. A temporal hierarchy can be constructed for any time series by means of non-overlapping temporal aggregation. Predictions constructed at all aggregation levels are combined with the proposed framework to result in temporally reconciled, accurate and robust forecasts. The implied combination mitigates <b>modelling</b> <b>uncertainty,</b> while the reconciled nature of the forecasts results in a unified prediction that supports aligned decisions at different planning horizons: from short-term operational up to long-term strategic planning. The proposed methodology is independent of forecasting models. It can embed high level managerial forecasts that incorporate complex and unstructured information with lower level statistical forecasts. Our results show that forecasting with temporal hierarchies increases accuracy over conventional forecasting, particularly under increased <b>modelling</b> <b>uncertainty.</b> We discuss organisational implications of the temporally reconciled forecasts using {{a case study of}} Accident & Emergency departments...|$|E
40|$|The main {{objectives}} {{of this work}} focus, firstly, on {{a review of the}} current existent methodologies to estimate air quality <b>modelling</b> <b>uncertainty,</b> and, secondly, in the preparation of guidelines for <b>modelling</b> <b>uncertainty</b> estimation, which can be used by local and regional authorities responsible for air quality management. From the application exercise, it was concluded {{that it is possible to}} define a subset of statistical parameters able to reproduce the general uncertainties estimation. Concerning the quality indicators defined by EU directives, the results show that the legislated uncertainty estimation measures are ambiguous and inadequate in several aspects, mainly in what concerns the error measures for hourly and daily indicators based on the highest observed concentration. A relative error at the percentile correspondent to the allowed number of exceedances of the limit value was suggested and tested, showing that is a more robust and appropriate parameter for model performance evaluation...|$|E
40|$|Abstract—In {{this paper}} we present CASTRO, a new {{approach}} for achieving robust planned trajectories for nonlinear systems {{in the presence of}} <b>modelling</b> <b>uncertainty.</b> With CASTRO,wesimultaneouslyoptimizetrajectoriesformultiple copiesofthesamesystemmodel,eachusingdifferentestimates for the system parameters. The systems are constrained to usethesamepolicy. Withanappropriatesamplingofsystem parameters in the optimization problem, the trajectory will be robust when run on the real system, compared to a trajectoryoptimizedwithjustonemodel. Wepresentresults onasimulateddouble-linkpendulumswing-upproblem. I...|$|E
40|$|<b>Modeling</b> <b>uncertainty</b> {{can have}} a {{significant}} impact on the assessed risk of earthquake-induced damage and collapse in a building obtained through the performance-based earthquake engineering framework. This paper quantifies the effect of <b>modeling</b> <b>uncertainty</b> on performance-based risk assessments, accounting for differences in software platforms, solution algorithm, element-types, and model parameter calculation or selection, using results of the 7 -story reinforced concrete (RC) building blind prediction contest (2006) at University of California at San Diego (UCSD). The blind prediction test data provide a unique opportunity to quantify the influence of <b>modeling</b> <b>uncertainty</b> on structural response predictions. In this study, the bias and variability of predicted drift in the contest submissions are taken to represent <b>modeling</b> <b>uncertainty.</b> The <b>modeling</b> <b>uncertainty</b> quantified from the UCSD test submissions is combined with uncertainty due to record-to-record variability and a set of fragility curves are computed for different drift levels. The final fragility curves account for modeling and ground motion uncertainty. Results are compared with the results with no <b>modeling</b> <b>uncertainty.</b> The key contribution of this study is to investigate the uncertainty embedded in the response due to combination of ground motion and <b>modeling</b> <b>uncertainty...</b>|$|R
40|$|We use Bayesian model {{averaging}} {{to analyze}} the sample evidence on return predictability {{in the presence of}} <b>model</b> <b>uncertainty.</b> The analysis reveals in-sample and out-of-sample predictability, and shows that the out-of-sample performance of the Bayesian approach is superior to that of model selection criteria. We find that term and market premia are robust predictors. Moreover, small-cap value stocks appear more predictable than large-cap growth stocks. We also investigate the implications of <b>model</b> <b>uncertainty</b> from investment management perspectives. We show that <b>model</b> <b>uncertainty</b> is more important than estimation risk, and investors who discard <b>model</b> <b>uncertainty</b> face large utility losses...|$|R
40|$|We study asset pricing when agents face <b>model</b> <b>uncertainty</b> and empirically {{demonstrate}} that <b>model</b> <b>uncertainty</b> matters for asset pricing. We measure {{the amount of}} <b>model</b> <b>uncertainty</b> in the economy with the disagreement of professional forecasters, attributing different weights to each professional forecaster. The weighting scheme is estimated via a method that is inspired by recent work on MIDAS regressions. We run regressions representing the typical risk-return trade-off, where risk is represented by conditional volatility and augment these regressions {{with a measure of}} <b>model</b> <b>uncertainty.</b> We nd stronger empirical evidence for a model uncertainty-return trade-off than for the traditional risk-return trade-off...|$|R
40|$|For {{realistic}} modelling of {{reinforced concrete}} structures, non-linear models are often inevitable, {{which raises the}} question of an appropriate safety format for non-linear analysis. This paper gives an overview of available safety formats and discusses their advantages and disadvantages. An analysis of available round robin tests and modelling competitions shows that current safety formats do not properly account for the <b>modelling</b> <b>uncertainty</b> of non-linear analysis. Based on this observation a new safety format was proposed which allows one to explicitly account for the <b>modelling</b> <b>uncertainty.</b> To avoid any interaction of the modelled response with the safety format, the mean in situ material parameters should be used in the non-linear analysis and a resistance safety factor is used to assure the intended reliability level. The application of the new safety format to beam sections loaded in bending showed that it offers a reliability level that is in good agreement with the target reliability...|$|E
40|$|The studies {{performed}} in the doctoral dissertation focused on estimation of the seismic response {{of some of the}} most typical reinforced concrete (RC) building structures, i. e. frame structures, cantilever wall structures and dual structures composed of frames and cantilever walls. The seismic response of structures was calculated by taking into account record-to-record variability (randomness) and <b>modelling</b> <b>uncertainty.</b> The spectral acceleration at the period of the equivalent SDOF model Sa (T*) was used as the intensity measure. Default dispersion measures were proposed for the considered structures, based on extensive numerical studies of a portfolio of archetypal structural systems, which have contributed to the development of the practice-oriented risk assessment methodology based on the N 2 method and predetermined dispersion measures. The identification of the structural parameters that influence the values of dispersion measures was also made, and their values were given. In addition, a simplified procedure for seismic response assessment with consideration of uncertainty was proposed. The development of the proposed procedure relied on the determination of the so-called probabilistic single degree of freedom model (probabilistic SDOF model), which allows approximate simulation of <b>modelling</b> <b>uncertainty.</b> The major advantage of the proposed procedure is that both seismic response assessment and simulation of <b>modelling</b> <b>uncertainty</b> are performed at the level of the probabilistic SDOF model. Such an approach allows significant reduction of computational time in comparison to some existing procedures. The results of the proposed procedure were validated by the employment of more accurate procedures. It was shown that the proposed procedure allows a considerable reduction of computational efforts, but still provides comparable accuracy as some existing procedures...|$|E
40|$|In {{order to}} make {{non-linear}} finite element analyses applicable during assessments of the ultimate load capacity or the structural reliability of large reinforced concrete structures, there is need for an efficient solution strategy with a low <b>modelling</b> <b>uncertainty.</b> A solution strategy comprises choices regarding force equilibrium, kinematic compatibility and constitutive relations. This contribution demonstrates four important steps {{in the process of}} developing a proper solution strategy: (1) definition, (2) verification by numerical experiments, (3) validation by benchmark analyses and (4) demonstration of applicability. A complete solution strategy is presented in detail, including a fully triaxial material model for concrete, which was adapted to facilitate its implementation in a standard finite-element software. Insignificant sensitivity to finite element discretisation, load step size, iteration method and convergence tolerance were found by numerical experiments. A low <b>modelling</b> <b>uncertainty,</b> denoted by the ratio of experimental to predicted capacity, was found by comparing the results from a range of experiments to results from non-linear finite element predictions. The applicability to large reinforced concrete structures is demonstrated by an analysis of an offshore concrete shell structure. </p...|$|E
40|$|International audienceThe problem {{concerns}} {{the identification of}} {{a model of the}} external loads applied to tubes bundles through the knowledge of dynamical responses. The computational model is simplified implying a loss of accuracy and of predictability due to <b>model</b> <b>uncertainties</b> induced by the simplification introduced. A probabilistic <b>model</b> of <b>model</b> <b>uncertainties</b> is implemented in the mean computational model using the nonparametric probabilistic approach for system-parameter <b>uncertainties</b> and <b>model</b> <b>uncertainties.</b> In addition, a probabilistic model for the stochastic loads is constructed to take into account <b>model</b> <b>uncertainties</b> in the probabilistic model of the stochastic loads. The nonlinear stochastic dynamical system, submited to the uncertain stochastic loads, is used to identify the probability <b>model</b> of its <b>uncertainties...</b>|$|R
40|$|<b>Model</b> <b>uncertainty</b> is a {{significant}} challenge to more widespread use of model predictive controllers (MPC) for optimizing building energy consumption. This paper presents two methodologies to handle modeluncertainty for building MPC. First, we propose a modeling framework for online estimation of states andunknown parameters leading to a parameter-adaptive building (PAB) model. Second, we propose a robustmodel predictive control (RMPC) formulation to make a building controller robust to <b>model</b> <b>uncertainties.</b> The results from these two approaches are compared with those from a nominal MPC and a commonbuilding rule based control (RBC). The results are then used to develop a methodology for selecting acontroller type (i. e. RMPC, MPC, or RBC) {{as a function of}} building <b>model</b> <b>uncertainty.</b> RMPC is found to bethe superior controller for the cases with an intermediate level of <b>model</b> <b>uncertainty</b> (30 – 67 %), while thenominal MPC is preferred for the cases with a low level of <b>model</b> <b>uncertainty</b> (0 – 30 %). Further, a commonRBC outperforms MPC or RMPC if the <b>model</b> <b>uncertainty</b> goes beyond a certain threshold (e. g. 67 %) ...|$|R
40|$|Reinterpreting most of {{the market}} price of risk as a price of <b>model</b> <b>uncertainty</b> eradicates a link between asset prices and {{measures}} of the welfare costs of aggregate fluctuations that was proposed by Hansen et al. (1999), Tallarini (2000), and Alvarez and Jermann (2004). Prices of <b>model</b> <b>uncertainty</b> contain information {{about the benefits of}} removing <b>model</b> <b>uncertainty,</b> not the consumption fluctuations that Lucas (1987, 2003) studied. A max-min expected utility theory lets us reinterpret Tallarini’s riskaversion parameter as measuring a representative consumer’s doubts about the model specification. We use model detection instead of risk-aversion experiments to calibrate that parameter. Plausible values of detection error probabilities give prices of <b>model</b> <b>uncertainty</b> that approach the Hansen and Jagannathan (1991) bounds. Fixed detection error probabilities give rise to virtually identical asset prices as well as virtually identical costs of <b>model</b> <b>uncertainty</b> for Tallarini’s two models of consumption growth. Key words: Risk aversion, model misspecification, robustness, market price of risk, equity premium puzzle, risk-free rate puzzle, detection error probability, costs of <b>model</b> <b>uncertainty...</b>|$|R
40|$|Response surface {{methodology}} (RSM) {{relies on}} the design of experiments and empirical modelling techniques to find the optimum of a process when the underlying fundamental mechanism of the process is largely unknown. This paper proposes an iterative RSM framework, where Gaussian process (GP) regression models are applied for the approximation of the response surface. GP regression is flexible and capable of modelling complex functions, as opposed to the restrictive form of the polynomial models that are used in traditional RSM. As a result, GP models generally attain high accuracy of approximating the response surface, and thus provide great chance of identifying the optimum. In addition, GP is capable of providing both prediction mean and variance, the latter being a measure of the <b>modelling</b> <b>uncertainty.</b> Therefore, this uncertainty can be accounted for within the optimization problem, and thus the process optimal conditions are robust against the <b>modelling</b> <b>uncertainty.</b> The developed method is successfully applied to the optimization of trans-stilbene conversion in the epoxidation of trans-stilbene over cobalt ion-exchanged faujasite zeolites (Co 2 +–NaX) catalysts using molecular oxyg...|$|E
40|$|Abstract: This paper {{considers}} the fault detection of networked control systems (NCS). First the NCS model is derived and {{transformed into a}} framework of linear time invariant (LTI) system with <b>modelling</b> <b>uncertainty</b> caused by the stochastic change in the system parameter due to the network induced delay and data loss. A residual evaluation technique, which combines the norm-based and statistic schemes, is applied. A simulation study for the proposed approach is given...|$|E
40|$|Ductility is an {{important}} limit state {{for the design of}} reinforced concrete beams. Its implementation varies considerably between design codes. This is investigated using reliability-based assessment with ductility defined by strain ratio. The <b>modelling</b> <b>uncertainty</b> for the ductility limit state typically is much greater than that for structural strength limit state. This is reflected in the corresponding reliability indices of limit state defined for ductility. Some of these could be considered unacceptably low...|$|E
40|$|We study {{orders of}} risk and <b>model</b> <b>uncertainty</b> aversion in the smooth {{ambiguity}} model proposed by Klibano, Marinacci, and Mukerji [4]. We consider a quadratic approximation of their model and we show that both risk and <b>model</b> <b>uncertainty</b> attitudes have at most a second order effect. Specifically, the order depends on {{the properties of the}} support of the decision maker's limit prior, which we fully characterize. We find that <b>model</b> <b>uncertainty</b> attitudes have a second order effect unless the support is a singleton, that is, unless <b>model</b> <b>uncertainty</b> fades away in the limit. Special attention is given to the binomial state spaces often used in mathematical finance. ...|$|R
40|$|AbstractModel {{uncertainty}} {{is a significant}} challenge to more widespread use of model predictive controllers (MPC) for optimizing building energy consumption. This paper presents two methodologies to handle <b>model</b> <b>uncertainty</b> for building MPC. First, we propose a modeling framework for online estimation of states and unknown parameters leading to a parameter-adaptive building (PAB) model. Second, we propose a robust model predictive control (RMPC) formulation to make a building controller robust to <b>model</b> <b>uncertainties.</b> The results from these two approaches are compared with those from a nominal MPC and a common building rule based control (RBC). The results are then used to develop a methodology for selecting a controller type (i. e. RMPC, MPC, or RBC) {{as a function of}} building <b>model</b> <b>uncertainty.</b> RMPC is found to be the superior controller for the cases with an intermediate level of <b>model</b> <b>uncertainty</b> (30 – 67 %), while the nominal MPC is preferred for the cases with a low level of <b>model</b> <b>uncertainty</b> (0 – 30 %). Further, a common RBC outperforms MPC or RMPC if the <b>model</b> <b>uncertainty</b> goes beyond a certain threshold (e. g. 67 %) ...|$|R
40|$|We {{introduce}} heterogeneity into {{a monetary}} policy committee by allowing the degree of <b>model</b> <b>uncertainty</b> to differ across members. It is shown that in this framework the stage at which members reach consensus matters. An aggregation protocol under which members only average policy deemed optimal from each member’s point of view leads to more volatility compared to an alternative protocol in which members agree on a common worst-case scenario from which optimal policy is then derived. The reason is that inflation, output and the interest rate are convex functions of each member’s idiosyncratic degree of <b>model</b> <b>uncertainty.</b> If the degree of <b>model</b> <b>uncertainty</b> becomes more heterogenous, inflation volatility falls due to more vigorous stabilization policy. The degree of heterogeneity across members is therefore an important determinant of macroeconomic volatility. Interestingly, the implications for the committee design under a min-max approach to <b>model</b> <b>uncertainty</b> are identical to those derived from a Bayesian approach. Robustness, <b>Model</b> <b>Uncertainty,</b> Monetary Policy Committee, Optimal Monetary Policy...|$|R
