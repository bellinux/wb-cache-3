784|2557|Public
25|$|Unilateral {{activation}} of the amygdala due to fearful stimuli may also produce unilateral {{activation of}} other regions. The right <b>middle</b> <b>temporal</b> <b>gyrus,</b> right brainstem, left hippocampus, right cerebellum, right fuisform gyrus, and left lingual gyrus were also activated during fearful stimuli. Activation of multiple brain regions both indicates that emotions are processed {{in many parts of}} the brain and that emotions are complex.|$|E
25|$|Along {{with the}} ventral pathway being {{important}} for visual processing, {{it is also}} important for processing auditory information. During processing, when sound waves enter the ear, this information is transduced into an unanalyzed auditory object. The subcortical auditory pathway then relays the information to the auditory cortex in the dorsal superior temporal gyrus (dSTG). In the dSTG, it is then divided into its constituent phones. These phones are then recognized into phonetic words in the superior temporal sulcus (STS). The information first enters the ventral stream at the posterior <b>middle</b> <b>temporal</b> <b>gyrus</b> and the posterior inferior temporal sulcus p(MTG+ITS). Here the auditory words are converted into semantic words. These words are then converted into a semantic phrase by the first combinatorial net at the anterior portion of the middle temporal lobe and then converted into a syntactic noun phrase at the second combinatorial net. This second combinatorial net is location in the anterior inferior temporal gyrus.|$|E
25|$|In {{the early}} years, {{they were more}} {{interested}} in the acoustics of speech. For instance, they were looking at the differences between /ba/ or /da/, but now research has been directed to the response in the brain from the stimuli. In recent years, there has been a model developed {{to create a sense of}} how speech perception works; this model is known as the Dual Stream Model. This model has drastically changed from how psychologists look at perception. The first section of the Dual Stream Model is the ventral pathway. This pathway incorporates <b>middle</b> <b>temporal</b> <b>gyrus,</b> inferior temporal sulcus and perhaps the inferior temporal gyrus. The ventral pathway shows phonological representations to the lexical or conceptual representations, which is the meaning of the words. The second section of the Dual Stream Model is the dorsal pathway. This pathway includes the sylvian parietotemporal, inferior frontal gyrus, anterior insula, and premotor cortex. Its primary function is to take the sensory or phonological stimuli and transfer it into an articulatory-motor representation (formation of speech).|$|E
40|$|Background: Loss of gray matter {{has been}} {{previously}} found in early-onset schizophrenic patients. However, there are no consistent findings between studies due to different methods used to measure grey matter volume/density and influences of confounding factors. Methods: The volume of gray matter (GM) was measured in 29 first episode early-onset schizophrenia (EOS) and 34 well-matched healthy controls by using voxel-based morphometry (VBM). Psychotic symptoms were assessed using the Positive and Negative Syndrome Scale (PANSS). The correlations between the GM volume and PANSS scores, age of psychosis onset, duration of psychosis, and chlorpromazine (CPZ) equivalent value were investigated. Results: Relative to healthy subjects, the patients with first episode EOS showed significantly lower GM volume in the left <b>middle</b> and superior <b>temporal</b> <b>gyrus.</b> The loss of GM volume negatively correlated with PANSS-positive symptoms (p = 0. 002), but not with PANSS-negative symptoms, PANSS-general psychopathology, and PANSS-total score. No significant correlation was found between GM volume and age of psychosis onset, duration of psychosis, and CPZ equivalent value. Conclusion: Patients with first episode EOS have evidence of reduced GM in the left <b>middle</b> and superior <b>temporal</b> <b>gyrus.</b> Structural abnormalities in the left <b>middle</b> and superior <b>temporal</b> <b>gyrus</b> {{may contribute to the}} pathophysiology of schizophrenia...|$|R
40|$|Single and {{multiple}} unit neuronal activity was recorded from the cortex of the lateral temporal lobe in conscious humans during open brain surgery {{for the treatment}} of epilepsy. Recordings were obtained from the right and left superior, <b>middle</b> and inferior <b>temporal</b> <b>gyrus</b> of 34 patients (41 recording sites). Recordings were restricted to regions to be resected during subsequent surgery. This excluded recordings from language areas proper. Neuronal responses to words and sentences presented over a loudspeaker and during free conversation were recorded. No significant differences between the right and left hemisphere were obvious. All neurons in the superior <b>temporal</b> <b>gyrus</b> responded to various aspects of spoken language with temporally well defined activation/inhibition patterns, but not or only little to non-linguistic noises or tones. Excitatory responses were typically short or prolonged (up to several hundred ms) bursts of discharges at rates above 20 /sec, reaching peak rates of 50 – 100 /s. Such responses could be specifically related to certain combinations of consonants suggesting a function in categorization, they could depend on word length, could differentiate between polysyllabic and compound words of the same length or could be unspecifically related to language as such. No formant specific responses were found, but the prolonged excitations across syllables suggest that consonant/vowel combinations may play a role for some activation patterns. Responses of some neurons (or neuronal populations) depended on the attention paid to the words and sentences, or the task connected with them (repeat words, speech addressed to the patient demanding something). Neurons in the <b>middle</b> and inferior <b>temporal</b> <b>gyrus</b> were only little affected by listening to single words or sentences, but some were unspecifically activated by words or while listening to sentences. Excitatory responses varied within a limited range of discharge rates usually below 5 – 10 /s. Phonetic distortion of spoken language could reduce responses in superior <b>temporal</b> <b>gyrus</b> neurons, but also the slight changes in discharge rate of <b>middle</b> <b>temporal</b> neurons could be absent during distorted and uncomprehensible speech sounds. We conclude that superior <b>temporal</b> <b>gyrus</b> neuron responses reflect some general phonetic but not semantic aspects of spoken language. <b>Middle</b> and inferior <b>temporal</b> <b>gyrus</b> neurons do not signal phonetic aspects of language, but may be involved in understanding language under certain conditions...|$|R
40|$|Gender {{specific}} {{differences in}} cognitive functions {{have been widely}} discussed. Considering social cognition such as emotion perception conveyed by non-verbal cues, generally a female advantage is assumed. In the present study, however, we revealed a cross-gender interaction with increasing responses {{to the voice of}} opposite sex in male and female subjects. This effect was confined to erotic tone of speech in behavioural data and haemodynamic responses within voice sensitive brain areas (right <b>middle</b> superior <b>temporal</b> <b>gyrus).</b> The observed response pattern, thus, indicates a particular sensitivity to emotional voices that have a high behavioural relevance for the listener...|$|R
500|$|... "Bart the General" [...] and Seinfelds [...] "The Tape" [...] {{were used}} in a Dartmouth College {{experiment}} to study brain activity in relation to humorous moments in television shows. The results were published in a 2004 issue of the academic journal Neurolmage. The researchers noted, [...] "During moments of humor detection, significant [...] activation was noted in the left posterior <b>middle</b> <b>temporal</b> <b>gyrus</b> ... and left inferior frontal gyrus".|$|E
50|$|Another {{study using}} fMRI {{showed that the}} parts of the brain {{responding}} to puns and semantic-based jokes which participants found amusing were different. In response to puns, the left posterior <b>middle</b> <b>temporal</b> <b>gyrus</b> and the left inferior frontal gyrus were activated. When listening to semantic jokes, the left posterior <b>middle</b> <b>temporal</b> <b>gyrus</b> was again activated, and so were the left posterior inferior temporal gyrus, the right posterior <b>middle</b> <b>temporal</b> <b>gyrus,</b> and the cerebellum. Interestingly, brain activity in the medial ventral prefrontal cortex was associated with ratings of funniness which the participants gave after the brain scan and initial humor response. This response may be stemming from the mood or emotional change which occurs after hearing humor.|$|E
5000|$|... #Caption: Lateral {{surface of}} left {{cerebral}} hemisphere, {{viewed from the}} side. (<b>Middle</b> <b>temporal</b> <b>gyrus</b> shown in orange.) ...|$|E
40|$|Three {{areas of}} the left {{hemisphere}} play different roles in sentence comprehension. An area of posterior <b>middle</b> and superior <b>temporal</b> <b>gyrus</b> shows activation correlated with the structural complexity of a sentence, suggesting that this area supports processing of sentence structure. The lateral anterior <b>temporal</b> <b>gyrus</b> is more activated bilaterally by all sentence conditions than by word lists; thus {{the function of the}} area probably does not directly support processing of structure but rather processing of words specific to a sentence context. Left inferior frontal cortex also shows activation related to sentence complexity but is also more activated in word list processing than in simple sentences; this region may thus support a form of verbal working memory which maintains sentence structural information as well as lexical items. ...|$|R
40|$|This {{dissertation}} examines what {{network in}} the human brain {{is involved in the}} perception of prosody and whether activity within this network is modulated by the personality trait alexithymia. The first four chapters of this dissertation reveal that a bihemispheric network consisting of Heschl’s <b>gyrus,</b> the <b>middle</b> superior <b>temporal</b> <b>gyrus,</b> the posterior superior <b>temporal</b> <b>gyrus</b> and the pars opercularis of the inferior frontal gyrus is involved in the perception of emotional prosody. Furthermore, relative right hemispheric specialization for emotional prosody perception can be demonstrated but no hemispheric specialization can be found for linguistic prosody perception. Moreover, hemispheric specialization for emotional prosody perception seems to be driven by hemispheric specialization for non-prosody-specific acoustic dimensions of the speech signal, and not for abstract emotional processing. Additionally, automaticity of processing can be demonstrated for emotional prosody, particularly for anger, but not for emotional music. Last, alexithymia can indeed be demonstrated to modulate activity within the emotional prosody perception network, particularly at relatively early components of the emotional prosody perception pathway. This dissertation is of interest to neurolinguists, (neuro-) phoneticians, psychologists, cognitive neuroscientists, comparative biologists and neurologists specialized in aphasi...|$|R
40|$|The {{current study}} {{explored}} how listeners map the variable acoustic input onto a common sound structure representation while {{being able to}} retain phonetic detail to distinguish among the identity of talkers. An adaptation paradigm was utilized to examine areas which showed an equal neural response (equal release from adaptation) to phonetic change when spoken by the same speaker and when spoken by two different speakers, and insensitivity (failure to show release from adaptation) when the same phonetic input was spoken by a different speaker. Neural areas which showed speaker invariance were located in the anterior portion of the <b>middle</b> superior <b>temporal</b> <b>gyrus</b> bilaterally. These findings provide support for the view that speaker normalization processes allow for the translation of a variable speech input to a common abstract sound structure. That this process appears to occur early in the processing stream, recruiting temporal structures, suggests that this mapping takes place prelexically, before sound structure input is mapped on to lexical representations...|$|R
50|$|<b>Middle</b> <b>temporal</b> <b>gyrus</b> is a gyrus in {{the brain}} on the Temporal lobe. It is located between the {{superior}} temporal gyrus and inferior temporal gyrus.|$|E
5000|$|The second, {{the angular}} gyrus, arches over the {{posterior}} {{end of the}} superior temporal sulcus, behind which it is continuous with the <b>middle</b> <b>temporal</b> <b>gyrus.</b>|$|E
50|$|The {{superior}} temporal sulcus is the sulcus {{separating the}} superior temporal gyrus from the <b>middle</b> <b>temporal</b> <b>gyrus</b> in the temporal lobe of the brain. The superior temporal sulcus {{is the first}} sulcus inferior to the lateral fissure.|$|E
40|$|Individuals with {{developmental}} prosopagnosia exhibit severe and lasting difficulties in recognizing faces despite {{the absence of}} apparent brain abnormalities. We used voxel-based morphometry to investigate whether developmental prosopagnosics show subtle neuroanatomical differences from controls. An analysis based on segmentation of T 1 -weighted images from 17 developmental prosopagnosics and 18 matched controls revealed that they had reduced grey matter volume in the right anterior inferior temporal lobe and in the superior <b>temporal</b> sulcus/middle <b>temporal</b> <b>gyrus</b> bilaterally. In addition, a voxel-based morphometry analysis based on the segmentation of magnetization transfer parameter maps showed that developmental prosopagnosics also had reduced grey matter volume in the right middle fusiform gyrus and the inferior <b>temporal</b> <b>gyrus.</b> Multiple regression analyses relating three distinct behavioural component scores, derived from a principal component analysis, to grey matter volume revealed an association between a component related to facial identity and grey matter volume in the left superior <b>temporal</b> sulcus/middle <b>temporal</b> <b>gyrus</b> plus the right <b>middle</b> fusiform gyrus/inferior <b>temporal</b> <b>gyrus.</b> Grey matter volume in the lateral occipital cortex was associated with component scores related to object recognition tasks. Our results demonstrate that developmental prosopagnosics have reduced grey matter volume in several regions known to respond selectively to faces and provide new evidence that integrity of these areas relates to face recognition ability...|$|R
40|$|Controversies exist {{concerning}} {{factors that}} contribute to the occurrence of epileptic seizures after stroke. Therefore, we studied prospectively the occurrence of seizures in 322 patients with a first-ever CT-confirmed symptomatic territorial brain infarct involving the cortex. We also studied potential risk factors for seizures, and gave special attention to cortical infarct location. Fifty-four patients developed post-stroke seizures. We distinguished between early- and late-onset seizures, occurring within two weeks following stroke-onset, or later than two weeks, respectively. We found that patients of 65 years or older with a cardioembolic brain infarct involving the <b>middle</b> <b>temporal</b> or post-central <b>gyrus,</b> had an almost eight times increased risk of early-onset seizures, whereas patients with a large brain infarct involving the supramarginal or superior <b>temporal</b> <b>gyrus,</b> had a five times increased risk of late-onset seizures. We conclude that risk factors and epileptogenic cortical areas for post brain infarct seizures can be identified, which however, differ between early- and late-onset seizures. These two seizure types may also differ in terms of seizure mechanism. Our findings may influence the decision on prophylactic treatment with antiepileptic drugs in stroke patients...|$|R
30|$|GM atrophy {{was greater}} than {{hypometabolism}} in the temporal lobes (left and right <b>middle</b> <b>temporal</b> poles, left hippocampus and left parahippocampus as well as left inferior <b>temporal</b> <b>gyrus).</b> This was also true in the left calcarine (Table  2).|$|R
50|$|BA38 is a {{subdivision}} of the cytoarchitecturally defined temporal region of cerebral cortex. It is located {{primarily in the}} most rostral portions of the superior temporal gyrus and the <b>middle</b> <b>temporal</b> <b>gyrus.</b> Cytoarchitecturally it is bounded caudally by the inferior temporal area 20, the middle temporal area 21, the superior temporal area 22 and the ectorhinal area 36 (Brodmann-1909).|$|E
50|$|During speech comprehension, activations {{are focused}} {{in and around}} Wernicke's area. A large body of {{evidence}} supports a role for the posterior superior temporal gyrus in acoustic-phonetic aspects of speech processing, whereas more ventral sites such as the posterior <b>middle</b> <b>temporal</b> <b>gyrus</b> (pMTG) are thought to play a higher linguistic role linking the auditory word form to broadly distributed semantic knowledge.|$|E
50|$|Its exact {{function}} is unknown, {{but it has}} been connected with processes as different as contemplating distance, recognition of known faces, and accessing word meaning while reading.Some studies indicate that lesions of the posterior region of the <b>middle</b> <b>temporal</b> <b>gyrus,</b> in the left cerebral hemisphere, may result in alexia and agraphia for kanji characters (characters of Chinese origin used in Japanese writing).|$|E
40|$|Previous {{research}} suggests that the human left planum temporale (PT) {{plays an important role in}} language. To test this hypothesis, functional MRI (fMRI) data were collected from 12 normal right-handed subjects during passive and active listening to words and tone sequences. Several left hemisphere areas, including the superior <b>temporal</b> sulcus, <b>middle</b> <b>temporal</b> gyms, angular <b>gyrus</b> and lateral frontal lobe showed stronger activation during the word conditions. This was not true of the PT, which responded equally to tones and words during passive listening and more strongly to tones during active listening. The PT is likely to be involved in early auditory processing, while specifically linguistic functions are mediated by multimodal association areas distributed elsewhere in the left hemisphere...|$|R
40|$|Although {{the neural}} {{basis for the}} {{perception}} of vocal emotions has been described extensively, the neural basis {{for the expression of}} vocal emotions is almost unknown. Here, we asked participants both to repeat and to express high-arousing angry vocalizations to command (i. e., evoked expressions). First, repeated expressions elicited activity in the left <b>middle</b> superior <b>temporal</b> <b>gyrus</b> (STG), pointing to a short auditory memory trace for the repetition of vocal expressions. Evoked expressions activated the left hippocampus, suggesting the retrieval of long-term stored scripts. Secondly, angry compared with neutral expressions elicited activity in the inferior frontal cortex IFC and the dorsal basal ganglia (BG), specifically during evoked expressions. Angry expressions also activated the amygdala and anterior cingulate cortex (ACC), and the latter correlated with pupil size as an indicator of bodily arousal during emotional output behavior. Though uncorrelated, both ACC activity and pupil diameter were also increased during repetition trials indicating increased control demands during the more constraint production type of precisely repeating prosodic intonations. Finally, different acoustic measures of angry expressions were associated with activity in the left STG, bilateral inferior frontal gyrus, and dorsal B...|$|R
40|$|Speech {{contains}} prosodic cues such as pauses {{between different}} phrases of a sentence. These intonational phrase boundaries (IPBs) elicit a specific component in ERP-studies, the so-called closure-positive-shift (CPS). The {{aim of the}} present fMRI study is to identify the neural correlates of this prosody-related component in sentences containing segmental and prosodic information (natural speech) and hummed sentences only containing prosodic information. Sentences with two IPBs both in normal and hummed speech activated the <b>middle</b> superior <b>temporal</b> <b>gyrus,</b> the Rolandic operculum and the gyrus of Heschl more strongly than sentences with one IPB. The results from a region of interest (ROI) analysis of auditory cortex and auditory association areas suggest that the posterior Rolandic operculum, in particular, supports the processing of prosodic information. A comparison of natural speech and hummed sentences revealed a number of left-hemispheric areas within the temporal lobe {{as well as in}} the frontal and parietal lobe that were activated more strongly for natural speech than for hummed sentences. These areas constitute the neural network for the processing of natural speech. The finding that no area was activated more strongly for hummed sentences compared to natural speech suggests that prosody is an integrated part of natural speech. ...|$|R
50|$|Unilateral {{activation}} of the amygdala due to fearful stimuli may also produce unilateral {{activation of}} other regions. The right <b>middle</b> <b>temporal</b> <b>gyrus,</b> right brainstem, left hippocampus, right cerebellum, right fuisform gyrus, and left lingual gyrus were also activated during fearful stimuli. Activation of multiple brain regions both indicates that emotions are processed {{in many parts of}} the brain and that emotions are complex.|$|E
50|$|This area is {{also known}} as middle {{temporal}} area 21. It is a subdivision of the cytoarchitecturally defined temporal region of cerebral cortex. In the human it corresponds approximately to the <b>middle</b> <b>temporal</b> <b>gyrus.</b> It is bounded rostrally by the temporopolar area 38 (H), ventrally by the inferior temporal area 20, caudally by the occipitotemporal area 37 (H), and dorsally by the superior temporal area 22 (Brodmann-1909).|$|E
5000|$|... "Bart the General" [...] and Seinfelds [...] "The Tape" [...] {{were used}} in a Dartmouth College {{experiment}} to study brain activity in relation to humorous moments in television shows. The results were published in a 2004 issue of the academic journal Neurolmage. The researchers noted, [...] "During moments of humor detection, significant brain activation was noted in the left posterior <b>middle</b> <b>temporal</b> <b>gyrus</b> ... and left inferior frontal gyrus".|$|E
40|$|We {{examined}} the spatiotemporal dynamics of word processing by recording the electrocorticogram (ECoG) from the lateral frontotemporal cortex of neurosurgical patients chronically implanted with subdural electrode grids. Subjects {{engaged in a}} target detection task where proper names served as infrequent targets embedded in a stream of task-irrelevant verbs and nonwords. Verbs described actions related to the hand (e. g, throw) or mouth (e. g., blow), while unintelligible nonwords were sounds which matched the verbs in duration, intensity, temporal modulation, and power spectrum. Complex oscillatory dynamics were observed in the delta, theta, alpha, beta, low, and high gamma (HG) bands in response to presentation of all stimulus types. HG activity (80 – 200 [*]Hz) in the ECoG tracked the spatiotemporal dynamics of word processing and identified a network of cortical structures involved in early word processing. HG {{was used to determine}} the relative onset, peak, and offset times of local cortical activation during word processing. Listening to verbs compared to nonwords sequentially activates first the posterior superior <b>temporal</b> <b>gyrus</b> (post-STG), then the <b>middle</b> superior <b>temporal</b> <b>gyrus</b> (mid-STG), followed by the superior temporal sulcus (STS). We also observed strong phase-locking between pairs of electrodes in the theta band, with weaker phase-locking occurring in the delta, alpha, and beta frequency ranges. These results provide details on the first few hundred milliseconds of the spatiotemporal evolution of cortical activity during word processing and provide evidence consistent with the hypothesis that an oscillatory hierarchy coordinates the flow of information between distinct cortical regions during goal-directed behavior...|$|R
40|$|Background: Vestibular {{migraine}} affects 1 % of {{the general}} population, and 30 %– 50 % of all migraine patients describe occasionally associated vertigo or dizziness. We aimed to identify brain regions altered in vestibular migraine in order to evaluate the connection between migraine and the vestibular system. Methods: Seventeen patients with definite vestibular migraine were compared to 17 controls using magnetic resonance imaging-based voxel-based morphometry. Results: We found grey matter (GM) volume reduction in the superior, inferior and <b>middle</b> (MT/V 5) <b>temporal</b> <b>gyrus</b> {{as well as in}} the mid. cingulate, dorsolateral prefontal, insula, parietal and occipital cortex. A negative correlation of disease duration and GM volume was observed in areas associated with pain and vestibular processing. Moreover, there was a negative correlation between headache severity and prefrontal cortex volume. Conclusion: Alterations identified in vestibular migraine resemble those previously described for migraine, but also extend to areas involved in multisensory vestibular control and central vestibular compensation possibly representing the pathoanatomic connection between migraine and the vestibular system...|$|R
40|$|Patients with {{schizophrenia}} have semantic processing disturbances {{leading to}} expressive language deficits (formal thought disorder). The underlying pathology has {{been related to}} alterations in the semantic network and its neural correlates. Moreover, crossmodal processing, {{an important aspect of}} communication, is impaired in schizophrenia. Here we investigated specific processing abnormalities in patients with schizophrenia with regard to modality and semantic distance in a semantic priming paradigm. Fourteen patients with schizophrenia and fourteen demographically matched controls made visual lexical decisions on successively presented word-pairs (SOA = 350 ms) with direct or indirect relations, unrelated word-pairs, and pseudoword-target stimuli during fMRI measurement. Stimuli were presented in a unimodal (visual) or crossmodal (auditory-visual) fashion. On the neural level, the effect of semantic relation indicated differences (patients > controls) within the right angular gyrus and precuneus. The effect of modality revealed differences (controls > patients) within the left superior frontal, <b>middle</b> <b>temporal,</b> inferior occipital, right angular gyri, and anterior cingulate cortex. Semantic distance (direct vs. indirect) induced distinct activations within the left <b>middle</b> <b>temporal,</b> fusiform <b>gyrus,</b> right precuneus, and thalamus with patients showing fewer differences between direct and indirect word-pairs. The results highlight aberrant priming-related brain responses in patients with schizophrenia. Enhanced activation for patients possibly reflects deficits in semantic processes that might be caused by a delayed and enhanced spread of activation within the semantic network. Modality-specific decreases of activation in patients might be related to impaired perceptual integration. Those deficits could induce and increase the prominent symptoms of schizophrenia like impaired speech processing...|$|R
50|$|The primary {{auditory}} cortex {{is surrounded}} by secondary auditory cortex, and interconnects with it. These secondary areas interconnect with further processing areas in the superior temporal gyrus, in the dorsal bank of the superior temporal sulcus, and in the frontal lobe. In humans, connections of these regions with the <b>middle</b> <b>temporal</b> <b>gyrus</b> are probably important for speech perception. The frontotemporal system underlying auditory perception allows us to distinguish sounds as speech, music, or noise.|$|E
5000|$|The {{temporal}} lobe {{is unique to}} primates. In humans, the IT cortex {{is more complex than}} their relative primate counterparts. The human inferior temporal cortex consists of the inferior temporal gyrus, the <b>middle</b> <b>temporal</b> <b>gyrus,</b> and the fusiform gyrus. When looking at the brain laterally - that is from the side and looking at the surface of the {{temporal lobe}} - the inferior temporal gyrus is along the bottom portion of the temporal lobe, and is separated from the <b>middle</b> <b>temporal</b> <b>gyrus</b> located directly above by the inferior temporal sulcus. Additionally, some processing of the visual field that corresponds to the ventral stream of visual processing occurs in the lower portion of the superior temporal gyrus closest to the superior temporal sulcus. The medial and ventral view of the brain - meaning looking at the medial surface from below the brain, facing upwards - reveals that the inferior temporal gyrus is separated from the fusiform gyrus by the occipital-temporal sulcus. This human inferior temporal cortex is much more complex than that of other primates: non-human primates have an inferior temporal cortex that is not divided into unique regions such as humans' inferior temporal gyrus, fusiform gyrus, or <b>middle</b> <b>temporal</b> <b>gyrus.</b> [...] This region of the brain corresponds to the inferior temporal cortex and is responsible for visual object recognition and receives processed visual information. The inferior temporal cortex in primates has specific regions dedicated to processing different visual stimuli processed and organized by the different layers of the striate cortex and extra-striate cortex. The information from the V1 -V5 regions of the geniculate and tectopulvinar pathways are radiated to the IT cortex via the ventral stream: visual information specifically related to the color and form of the visual stimuli. Through comparative research between primates - humans and non-human primates - results indicate that the IT cortex plays a significant role in visual shape processing. This is supported by functional magnetic resonance imaging (fMRI) data collected by researchers comparing this neurological process between humans and macaques.|$|E
50|$|The {{inferior}} temporal gyrus {{is placed}} below the <b>middle</b> <b>temporal</b> <b>gyrus,</b> and is connected behind with the inferior occipital gyrus; it also extends around the infero-lateral border {{on to the}} inferior surface of the temporal lobe, where it {{is limited by the}} inferior sulcus. This region is one of the higher levels of the ventral stream of visual processing, associated with the representation of complex object features, such as global shape. It may also be involved in face perception, and in the recognition of numbers.|$|E
50|$|The amygdala, {{fusiform}} gyrus, insula, {{and superior}} and <b>middle</b> <b>temporal</b> regions {{have been identified}} as areas in the brain that play a role in visual emotional cues. It was found that there was greater activation in the bilateral anterior superior <b>temporal</b> <b>gyrus</b> and bilateral fusiform gyrus when it came to emotional stimuli. The amygdala has been connected with the automatic evaluation of threat, facial valence information, and trustworthiness of faces.|$|R
50|$|This area is {{also known}} as {{inferior}} temporal area 20, and it refers to a subdivision of the cytoarchitecturally defined temporal region of cerebral cortex. In the human it corresponds approximately to the inferior <b>temporal</b> <b>gyrus.</b> Cytoarchitecturally it is bounded medially by the ectorhinal area 36 (H), laterally by the <b>middle</b> <b>temporal</b> area 21, rostrally by the temporopolar area 38 (H) and caudally by the occipitotemporal area 37 (H) (Brodmann-1909).|$|R
40|$|Arithmetic {{development}} {{is characterized by}} strategy shifts between procedural strategy use and fact retrieval. The current study {{is the first to}} explicitly investigate children’s neural activation {{associated with the use of}} these different strategies. Participants were 26 typically developing 4 th graders (9 - to 10 -year-olds), who, in a behavioral session, were asked to verbally report on a trial-by-trial basis how they had solved 100 subtraction and multiplication items. These items were subsequently presented during functional magnetic resonance imaging (fMRI). An event-related design allowed us to analyze the brain responses during retrieval and procedural trials, based on the children’s verbal reports. During procedural strategy use, and more specifically for the decomposition of operands strategy, activation increases were observed in the inferior and superior parietal lobes (intraparietal sulci), inferior to superior frontal gyri, bilateral areas in the occipital lobe, and insular cortex. For retrieval, in comparison to procedural strategy use, we observed increased activity in the bilateral angular and supramarginal gyri, left <b>middle</b> to inferior <b>temporal</b> <b>gyrus,</b> right superior <b>temporal</b> <b>gyrus,</b> and superior medial frontal gyrus. No neural differences were found between the two operations under study. These results are the first in children to provide direct evidence for alternate neural activation when different arithmetic strategies are used and further unravel that previously found effects of operation on brain activity reflect differences in arithmetic strategy use. status: accepte...|$|R
