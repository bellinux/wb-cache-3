2086|263|Public
50|$|Advanced <b>motion</b> <b>compensation</b> such as {{overlapped}} <b>motion</b> <b>compensation</b> and coding {{of motion}} vectors for 8x8 blocks, could be used.|$|E
50|$|Due to {{the extra}} {{decoding}} CPU cost of global <b>motion</b> <b>compensation,</b> most hardware players {{do not support}} global <b>motion</b> <b>compensation.</b>|$|E
50|$|Other {{features}} are DXVA support for Hardware <b>Motion</b> <b>Compensation,</b> iDCT, DCT and color space conversion. Support for Hardware <b>Motion</b> <b>Compensation,</b> iDCT, DCT and color space conversion is also listed.|$|E
40|$|Conventional ground {{moving target}} imaging {{algorithms}} mainly {{focus on the}} range cell migration correction and the motion parameter estimation of the moving target. However, in real Synthetic Aperture Radar (SAR) data processing, non-ideal <b>motion</b> error <b>compensation</b> is also a critical process, which focuses and has serious impacts on the imaging quality of moving targets. Non-ideal motion error can not be compensated by either the stationary SAR <b>motion</b> error <b>compensation</b> algorithms or the autofocus techniques. In this paper, two sorts of non-ideal motion errors that affect the Doppler centroid of the moving target is analyzed, and a novel non-ideal <b>motion</b> error <b>compensation</b> algorithm is proposed based on the Inertial Navigation System (INS) data and the range walk trajectory. Simulated and real data processing results are provided to demonstrate {{the effectiveness of the}} proposed algorithm...|$|R
5000|$|Programmable <b>motion</b> interrupts, {{temperature}} <b>compensation,</b> gain, offset, bandwidth ...|$|R
50|$|INSAT-3D is a meteorological, {{data relay}} and {{satellite}} aided {{search and rescue}} satellite developed by the Indian Space Research Organisation and was launched successfully on 26 July 2013 using an Ariane 5 ECA launch vehicle from French Guiana. The satellite has many new technology elements like star sensor, micro stepping Solar Array Drive Assembly (SADA) to reduce the spacecraft disturbances and Bus Management Unit (BMU) for control and telecom and telemetry function. It also incorporates new features of bi-annual rotation and Image and Mirror <b>motion</b> <b>compensations</b> for improved performance of the meteorological payloads.|$|R
5000|$|May contain {{image data}} and/or motion vector displacements. Older {{standards}} allow {{only a single}} global <b>motion</b> <b>compensation</b> vector for the entire frame or a single <b>motion</b> <b>compensation</b> vector per macroblock.|$|E
50|$|Block <b>motion</b> <b>compensation</b> divides up {{the current}} frame into {{non-overlapping}} blocks, and the <b>motion</b> <b>compensation</b> vector tells where those blocks come from(a common misconception {{is that the}} previous frame is divided up into non-overlapping blocks, and the <b>motion</b> <b>compensation</b> vectors tell where those blocks move to).The source blocks typically overlap in the source frame.Some video compression algorithms assemble the current frame out of pieces of several different previously-transmitted frames.|$|E
5000|$|Quarter-pixel {{precision}} for <b>motion</b> <b>compensation,</b> enabling precise {{description of}} the displacements of moving areas. For chroma the resolution is typically halved both vertically and horizontally (see 4:2:0) therefore the <b>motion</b> <b>compensation</b> of chroma uses one-eighth chroma pixel grid units.|$|E
40|$|The MPEG {{video data}} {{includes}} {{three types of}} frames, that is: I-frame, P-frame and B-frame. However, the I-frame records the main information of video data, the P-frame and the B-frame are just regarded as <b>motion</b> <b>compensations</b> of the I-frame. This paper presents the approach which analyzes the MPEG video stream in the compressed domain, and find out the key frame of MPEG video stream by extracting the I-frame. Experiments indicated that this method can be automatically realized in the compressed MPEG video and it will {{lay the foundation for}} the video processing in the future...|$|R
40|$|Abstract. Taking the {{eccentricity}} error of workpiece’s axis as an example, the real cutting pathes on the spiral bevel gear’s tooth {{surface and the}} normal errors were obtained according to each machining position. By decoupling error <b>compensation</b> <b>motions,</b> the <b>compensation</b> values of three translational and two rotational axes were obtained. After compensating, the tooth form errors were reduced largely. This compensation method {{is closer to the}} fact of gear grinding and the compensation effect is better than the method of adjusting machine setting parameters...|$|R
30|$|Control strategies, {{including}} <b>motion</b> scaling, gravity <b>compensation</b> and tremor canceling, {{are applied}} in the robotic system to achieve the precise control.|$|R
5000|$|XvMCContext {{describes}} {{the state of}} the <b>motion</b> <b>compensation</b> pipeline. An individual XvMCContext can be created for use with a single port, surface type, <b>motion</b> <b>compensation</b> type, width and height combination. For example, a context might be created for a particular port that does MPEG-2 <b>motion</b> <b>compensation</b> on 720 x 480 4:2:0 surfaces. Once the context is created, referencing it implies the port, surface type, size and the <b>motion</b> <b>compensation</b> type. Contexts may be [...] "direct" [...] or [...] "indirect". For indirect contexts the X display server renders all video using the data passed to it by the client. For direct contexts the client libraries render the video with little or no interaction with the X display server.|$|E
50|$|Hardware <b>motion</b> <b>compensation</b> for DVD playback.|$|E
5000|$|... #Subtitle level 3: <b>Motion</b> <b>compensation</b> block {{boundary}} artifacts ...|$|E
40|$|The shift-variant {{property}} of the discrete wavelet transform (DWT) makes the <b>motion</b> estimation and <b>compensation</b> ine$cient in the wavelet domain. In order to overcome the shift-variant {{property of}} the DWT, a low-band-shift (LBS) method has been developed. Using the LBS method in the wavelet domain, two <b>motion</b> estimation and <b>compensation</b> schemes are developed and evaluated. One scheme is the <b>motion</b> estimation and <b>compensation</b> using the LBS method with wavelet-block basis {{and the other is}} with band-by-band basis. Both schemes using the LBS method have superior performances to the conventional motion estimation methods in spatial domain or wavelet domain with respect to peak-noise-to-signal ratio (PSNR). The experiment results showthat the proposed schemes have PSNR improvements of above 1. 0 dB to the full-search method in spatial domain. � 2001 Elsevier Science B. V. All rights reserved...|$|R
30|$|In this section, {{we present}} a 3 D-DWT based encoder with low {{complexity}} and good R/D performance. As our main concern is fast encoding process, no R/D optimization, <b>motion</b> estimation/motion <b>compensation</b> (ME/MC) or bit-plane processing is applied. This encoder is based on both the 3 D-DWT transform and lower-trees (3 D-LTW).|$|R
30|$|In {{interframe}} coding, <b>motion</b> estimation and <b>compensation</b> {{have become}} powerful techniques {{to eliminate the}} temporal redundancy due to high correlation between consecutive frames [1].|$|R
5000|$|X-Video <b>Motion</b> <b>Compensation</b> (XvMC) API for Linux/UNIX operating-system.|$|E
50|$|Individual slices {{still have}} to be {{continuous}} horizontal regions of macroblocks, but with FMO's slice groups, <b>motion</b> <b>compensation</b> can take place within any contiguous macroblocks through the entire group; effectively, each slice group is treated as one or more contiguous shaped slices for the purposes of <b>motion</b> <b>compensation.</b>|$|E
50|$|Rendering {{is done by}} {{presenting}} the library with a target XvMCSurface and up to two reference XvMCSurfaces for the <b>motion</b> <b>compensation,</b> a buffer of 8x8 blocks and a command buffer which describes {{how to use the}} 8x8 blocks along with <b>motion</b> <b>compensation</b> vectors to construct the data in the target XvMCSurface. When the pipeline starts at the iDCT level, Xv will perform the IDCT on the blocks before performing the <b>motion</b> <b>compensation.</b> A function is provided to copy/overlay a portion of the XvMCSurface to a drawable with arbitrary scaling.|$|E
40|$|The {{bibliography}} contains citations {{concerning the}} design, development, testing, {{and evaluation of}} bistatic and multistatic radar used in surveillance and countermeasure technology. Citations discuss radar cross sections, target recognition and characteristics, ghost recognition, <b>motion</b> image <b>compensation,</b> and wavelet analysis. Stealth aircraft design, stealth target tracking, synthetic aperture radar, and space applications are examined...|$|R
40|$|Abstract—The {{discrete}} {{wavelet transform}} (DWT) has several advantages of multiresolution analysis and subband decomposition, {{which has been}} successfully used in image processing. However, the shift-variant property is intrinsic due to the decimation process of the wavelet transform, and it makes the wavelet-domain <b>motion</b> estimation and <b>compensation</b> inefficient. To overcome the shift-variant property, a low-band-shift method is proposed and a <b>motion</b> estimation and <b>compensation</b> method in the wavelet domain is presented. The proposed method has a superior performance to the conventional motion estimation methods {{in terms of the}} mean absolute difference (MAD) as well as the subjective quality. The proposed method can be a model method for the motion estimation in wavelet domain just like the full-search block matching in spatial domain. Index Terms—Block matching, discrete wavelet transform (DWT), low-band-shift, <b>motion</b> estimation and <b>compensation,</b> wavelet block. I...|$|R
40|$|The paper {{considers}} {{a method for}} accuracy improvement of automatic control systems with break-up control laws. The method presupposes asymmetrizing of a structure or parameters of a non-linear regulator proportionally to destabilizing effects. Some variants of such asymmetrizing with usage of so-called ‘quick’ automatic oscillatory <b>motions</b> for <b>compensation</b> of slow errow components are given in the paper. </span...|$|R
5000|$|Hardware Acceleration (<b>Motion</b> <b>Compensation</b> and iDCT) for DVD Playback.|$|E
5000|$|... iDCT transformations & <b>motion</b> <b>compensation</b> support (DVD {{playback}} acceleration) ...|$|E
5000|$|RAGE Mobility 128, M3, M4 (RAGE 128Pro-based) (<b>Motion</b> <b>Compensation,</b> IDCT) ...|$|E
40|$|The {{effects of}} strong motion errors in wide-beam, azimuth {{synthetic}} aperture radar (SAR) processing are analysed and discussed, using simulated data, as well as data collected by the airborne experimental SAR system of the Deutsches Zentrum für Luft- und Raumfahrt e. V. (DLR) (E-SAR). A new sub-aperture approach for residual <b>motion</b> error <b>compensation</b> in wide-beam azimuth processing is proposed...|$|R
40|$|Dynamic Singularities {{are shown}} for {{free-floating}} space manipulator systems where the spacecraft moves {{in response to}} manipulator <b>motions</b> without <b>compensation</b> from its attitude control system. At a dynamic singularity the manipulator is unable to move its end-effector in some inertial direction; thus dynamic singularities {{must be considered in}} the design, planning, and control of free-floating space manipulator systems. The existenc...|$|R
40|$|In {{this paper}} we show {{a way to}} create stable full body motion for a {{humanoid}} robot without defining all joint trajectories in advance. The full body motion is split in a task and <b>compensation</b> <b>motion.</b> The task motion can be generated in advance, while the <b>compensation</b> <b>motion</b> is obtained during execution of the task. We show that the <b>compensation</b> <b>motion</b> {{can be obtained by}} making use of the linear relation between the joint velocities and the linear momentum of the complete robot. A setpoint for the linear momentum is generated by making use of the error between the current Capture Point and the desired Capture Point location. We have implemented the control algorithm in simulation as well on a real humanoid robot. We were able to create stable full body motion for a bending forward task. It turns out that the control algorithm to create stable full body motion is insensitive for model errors in the internal model of the robot. BMDBMechEMechanical, Maritime and Materials Engineerin...|$|R
5000|$|RAGE Mobility C, EC, L, M2, (RAGE Pro-based) (<b>Motion</b> <b>Compensation)</b> ...|$|E
5000|$|RAGE Mobility P, M, M1 (RAGE Pro-based) (<b>Motion</b> <b>Compensation,</b> IDCT) ...|$|E
5000|$|... #Subtitle level 2: Video formats {{that support}} quarter-pixel <b>motion</b> <b>compensation</b> ...|$|E
30|$|The fast coding/decoding {{process and}} the {{avoiding}} {{of the use of}} <b>motion</b> estimation/motion <b>compensation</b> algorithms, makes the 3 D-LTW encoder a good candidate for applications where the coding/decoding delay are critical for proper operation or for applications where a frame must be reconstructed as soon as possible. 3 D-DWT based encoders could be an intermediate solution between pure Intra encoders and complex Inter encoders.|$|R
30|$|In this section, {{we present}} a 3 D-DWT-based encoder with low {{complexity}} and good R/D performance. As our main concern is fast encoding process, no R/D optimization, <b>motion</b> estimation/motion <b>compensation</b> (ME/MC) or bitplane processing is applied. This encoder is based on both 3 D-DWT and run-length encoding (3 D-GOP-RL), and {{it is able to}} compress an ITU-D 1 (576 p 30) video sequence at 40 frames per second.|$|R
40|$|Despite {{being the}} prefered {{approach}} for still-image compression {{for nearly a}} decade, wavelet-based coding for video {{has been slow to}} emerge, due primarily {{to the fact that the}} shift variance of the discrete wavelet transform hinders <b>motion</b> estimation and <b>compensation</b> crucial to modern video coders. Recently it has been recognized that a redundant, or overcomplete, wavelet transform is shift invariant and thus permits motion prediction in the wavelet domain. In this dissertation, other uses for the redundancy of overcomplete wavelet transforms in video coding are explored. First, it is demonstrated that the redundant-wavelet domain facilitates the placement of an irregular triangular mesh to video images, thereby exploiting transform redundancy to implement geometries for <b>motion</b> estimation and <b>compensation</b> more general than the traditional block structure widely employed. As the second contribution of this dissertation, a new form of multihypothesis prediction, redundant wavelet multihypothesis, is presented. This new approach to <b>motion</b> estimation and <b>compensation</b> produces <b>motion</b> predictions that are diverse in transform phase to increase prediction accuracy. Finally, it is demonstrate...|$|R
