53|3|Public
5000|$|Alan Bundy, University of Edinburgh, <b>meta-level</b> <b>reasoning</b> for guiding {{inductive}} proof, proof {{planning and}} recipient of 2007 IJCAI Award for Research Excellence, Herbrand Award, and 2003 Donald E. Walker Distinguished Service Award.|$|E
50|$|Alan Richard Bundy, CBE, FRS, FREng, FRSE, FBCS, FAAAI, FECCAI, FAISB, is a {{professor}} at the School of Informatics at the University of Edinburgh, known for his contributions to automated reasoning, especially to proof-planning, the use of <b>meta-level</b> <b>reasoning</b> to guide proof search.|$|E
5000|$|After {{studying}} {{mathematics and}} computer science in Amsterdam, Van Harmelen moved to the Department of AI of the University of Edinburgh, where he was awarded a PhD in 1989 for his research on <b>meta-level</b> <b>reasoning.</b> While in Edinburgh, he [...] "co-developed a logic-based toolkit for expert systems, and worked with Alan Bundy on proof planning for inductive theorem proving".|$|E
40|$|This {{manifesto}} {{proposes a}} simple model of metareasoning that constitutes a general framework to organize {{research on this}} topic. The claim is that metareasoning, like the action-perception cycle of reasoning, is composed of the introspective monitoring of reasoning and the subsequent <b>meta-level</b> control of <b>reasoning.</b> This model holds for single agent and multiagent systems and is broad enough to include models of self. We offer the model as a short conversation piece to which the community can compare and contrast individual theories...|$|R
40|$|We suggest why, {{and show}} how, to {{represent}} defeasible reasoning about prioritization-type precedence. We define Defeasible Axiomatized Policy (DAP) circumscription: {{it is the}} first formalism to express defeasible prioritization. DAP circumscription can represent one or more (generally, a finite reflective tower) of <b>meta-levels</b> of such <b>reasoning,</b> without resorting to a more powerful logical language. We argue for the usefulness, and analyze the expressive significance, of this representational generalization. We show that it can often be achieved with only a modest increase in the mathematical complexity of inference: DAP circumscription often reduces to a series of prioritized predicate circumscriptions, for which inference procedures are currently available. DAP circumscription also offers an improved approach to pointwise prioritization and circumscription, even in the basic, monotonic case of reasoning about prioritization. We observe that unsatisfiability and representational awkw [...] ...|$|R
40|$|AbstractThe {{abstract}} {{nature of}} Dung's seminal theory of argumentation accounts for its widespread application {{as a general}} framework for various species of non-monotonic reasoning, and, more generally, reasoning {{in the presence of}} conflict. A Dung argumentation framework is instantiated by arguments and a binary conflict based attack relation, defined by some underlying logical theory. The justified arguments under different extensional semantics are then evaluated, and the claims of these arguments define the inferences of the underlying theory. To determine a unique set of justified arguments often requires a preference relation on arguments to determine the success of attacks between arguments. However, preference information is often itself defeasible, conflicting and so subject to argumentation. Hence, in this paper we extend Dung's theory to accommodate arguments that claim preferences between other arguments, thus incorporating <b>meta-level</b> argumentation based <b>reasoning</b> about preferences in the object level. We then define and study application of the full range of Dung's extensional semantics to the extended framework, and study special classes of the extended framework. The extended theory preserves the abstract nature of Dung's approach, thus aiming at a general framework for non-monotonic formalisms that accommodate defeasible reasoning about as well as with preference information. We illustrate by formalising argument based logic programming with defeasible priorities in the extended theory...|$|R
40|$|We {{describe}} a system called Tileworld, {{which consists of}} a simulated robot agent and a simulated environment which is both dynamic and unpredictable. Both the agent and the environment are highly parameterized, enabling one to control certain characteristics of each. We can thus experimentally investigate the behavior of var-ious <b>meta-level</b> <b>reasoning</b> strategies by tuning {{the parameters of the}} agent, and can assess the success of alternative strategies in dierent environments by tuning the en-vironmental parameters. Our hypothesis is that the appropriateness of a particular <b>meta-level</b> <b>reasoning</b> strategy will depend in large part upon the characteristics of the environment in which the agent incorporating that strategy is situated. We describe our initial experiments using Tileworld, in which we have been evaluating a version of the <b>meta-level</b> <b>reasoning</b> strategy proposed in earlier work by one of the authors [5]...|$|E
40|$|Abstract. In agent systems, <b>meta-level</b> <b>reasoning</b> is {{commonly}} used in enforcing rationality {{in the choice of}} goals and actions performed by an agent, ensuring that an agent behaves as effectively and efficiently as possible. Through metareasoning an agent is able to explicitly consider goals before committing to them, and consider courses of action before executing plans. In this paper, we argue that although seldom considered, a flexible <b>meta-level</b> <b>reasoning</b> component is a valuable addition to any agent architecture. We describe such a component for use in BDI architectures, underpinned by a model of motivation and a motivationbased description language, and demonstrate its effectiveness empirically. ...|$|E
40|$|Abstract {{without regard}} to the amount of time it is taking or the changes {{meanwhile}} going on, is not likely to make ra. tional decisions. We describe a system called Tileworld, which con-sists of a simulated robot agent and a simulated environment which is both dynamic and unpre-dictable. Both the agent and the environment are highly parameterized, enabling one to control certain characteristics of each. We can thus ex-perimentally investigate the behavior of various <b>meta-level</b> <b>reasoning</b> strategies by tuning the pa-rameters of the agent, and can assess the success of alternative strategies in different environments by tuning the environmental parameters. Our hy-pothesis is that the appropriateness of a pa. rticu 1 a. r <b>meta-level</b> <b>reasoning</b> strategy will depend in large pa,rt upon the characteristics of the environment in which the agent incorporating that strategy is situated. We describe our initial experiments us-ing Tileworld, in which we have been evaluating a version of the <b>meta-level</b> <b>reasoning</b> strategy pro-posed in earlier work by one of the authors [Brat-man e 2 al., 19 SS]. One solution that has been proposed eliminates ex-plicit execution-time reasoning by compiling into the agent all decisions a. bout what to do in particular situations [Agre and Chapman, 1987, Brooks, 1987, Ka. elbling, 198 S]. This is an interesting endeavor, but its ultimate feasibility for complex domains remains an open question...|$|E
40|$|In {{this paper}} we show how a formal {{semantics}} {{can be given}} to reasoning processes in meta-level architectures that reason about (object level) knowledge states and changes of them. Especially the {{attention is focused on}} the upward and downward reflections in these architectures. Temporalized epistemic logic is used to specify <b>meta-level</b> <b>reasoning</b> processes and the outcomes of these. ...|$|E
40|$|In {{this paper}} we {{summarise}} our progress towards building a self-aware agent {{based on the}} definition of explicit selfawareness. An explicit self-aware agent is characterised by 1) being based on an extensive and human-like knowledge base, 2) being transparent both in its behaviour and in how the knowledge is represented and used, and 3) being able to communicate in natural language and directly display awareness through its dialogues. We first review the requirements posed by explicit self-awareness on the knowledge representation and reasoning system and then describe how these have been realized in the {{new version of the}} EPILOG system. We argue that <b>meta-level</b> <b>reasoning</b> is very important to achieve self-awareness but that it doesn’t need to be on an entirely different level from object-level reasoning. In fact, in our agent <b>meta-level</b> <b>reasoning</b> and object-level reasoning cooperate seamlessly to answer each question posed to it...|$|E
40|$|Deliberative agents {{operating}} in open environments must make complex real-time decisions on scheduling and coor-dination of domain activities. These {{decisions are made}} in the context of limited resources and uncertainty about the outcomes of activities. We describe a reinforcement learn-ing based approach for efficient <b>meta-level</b> <b>reasoning.</b> Em-pirical results showing the effectiveness of meta-level rea-soning in a complex domain are provided. 1...|$|E
40|$|Abstract. The {{reflection}} theorem {{has been}} proved using Isabelle/ZF. This theorem cannot be expressed in ZF, and its proof requires reasoning at the meta-level. There is a particularly elegant proof that reduces the <b>meta-level</b> <b>reasoning</b> to a single induction over formulas. Each case of the induction {{has been proved}} with Isabelle/ZF, whose built-in tools can prove specific instances of the reflection theorem upon demand. ...|$|E
40|$|In {{this article}} we show how formal {{semantics}} can be given to reasoning processes in meta-level architectures that reason about (object level) knowledge states and effects changes may have on them. Especially, {{attention is focused on}} the upward and downward reflections in these architectures. Temporalized epistemic logic is used to specify <b>meta-level</b> <b>reasoning</b> processes and the outcomes of these. © 2003 Wiley Periodicals, Inc...|$|E
40|$|Meta-level {{architectures}} for {{dynamic control}} of reasoning processes are quite powerful. In the literature many applications in reasoning systems modelling complex tasks are described, {{usually in a}} procedural manner. In this paper we present a declarative framework based on temporal (partial) logic that enables one to describe the dynamics of reasoning behaviour by temporal models. Using these models the semantics of the behaviour of the whole (<b>meta-level)</b> <b>reasoning</b> system can be described {{by a set of}} (intended) temporal models...|$|E
40|$|This {{paper is}} {{concerned}} with developing a reflective architecture for formalizing and reasoning about entities {{that occur in the}} process of software development, such as specifications, theorems, programs, and proofs. The starting point is a syntactic extension of the type theory ECC. An encoding of this object calculus within itself comprises the meta-level, and reflection principles are provided for switching between di#erent levels. These reflection principles are used to mix object- and <b>meta-level</b> <b>reasoning,</b> to generate "standard" units by executing meta-operators, and to apply formal tactics that allow for abstraction from the base logic...|$|E
40|$|AbstractKnowledge-based proof {{planning}} {{is a new}} paradigm in automated theorem proving (ATP) which swings the motivational pendulum back to its AI origins in that it employs and further develops many AI principles and techniques such as hierarchical planning, knowledge representation in frames and control-rules, constraint solving, tactical and <b>meta-level</b> <b>reasoning.</b> It differs from traditional search-based techniques in ATP not least with respect to its level of abstraction: the proof of a theorem is planned at an abstract level and an outline of the proof is found. This outline, i. e., the abstract proof plan, can be recursively expanded and it will thus construct a proof within a logical calculus. The plan operators represent mathematical techniques familiar to a working mathematician. While the knowledge of a domain is specific to the mathematical field, the representational techniques and reasoning procedures are general-purpose. The general-purpose planner makes use of this mathematical domain knowledge and of the guidance provided by declaratively represented control-rules which correspond to mathematical intuition about how to prove a theorem in a particular situation. These rules {{provide a basis for}} <b>meta-level</b> <b>reasoning</b> and goal-directed behaviour. We demonstrate our approach for the mathematical domain of limit theorems, which was proposed as a challenge to automated theorem proving by the late Woody Bledsoe. Using the proof planner of the Ωmega system we were able to solve all the well known challenge theorems including those that cannot be solved by any of the existing traditional systems...|$|E
40|$|We use {{the phrase}} “joined-up ” here with a double meaning: to convey two aspects of {{scientific}} discovery which we believe are essential, yet under-researched with respect to automating scientific discovery processes. Firstly, from an Artificial Intelligence perspective, the majority of approaches to using AI techniques involve a disjointed sequential application of different problem solving methods, with the user providing the glue in various ways. These include routine logistical aspects such as the pre-processing of data and knowledge, translating outputs into input, choosing parameter settings for running AI methods, etc. More importantly, however, the user performs various aspects of <b>meta-level</b> <b>reasoning,</b> including asking the most pertinent questions, determining what i...|$|E
40|$|Abstract. We {{argue that}} Lakatos ’ {{work on the}} history and {{philosophy}} of mathematics is of key relevance to machine creativity as it suggests ways in which to explore and transform concept spaces, rerepresent knowledge and change evaluation criteria. We describe approaches to implementing methods which Lakatos identifies, including our own approach, which extends Colton’s HR and has enabled us to automatically generate mathematical conjectures, concepts and examples which were previously impossible in HR- including Goldbach’s conjecture. The methods are of general importance {{as they can be}} applied to many domains- we describe their theoretical application to game plans, two-dimensional geometry, moral philosophy, philosophy of mind, political argument and <b>meta-level</b> <b>reasoning.</b> ...|$|E
40|$|Abstract. A recent {{extension}} to Dung’s argumentation framework allows for argu-ments to express preferences between other arguments. Value based argumentation can be formalised in this extended framework, enabling meta-level argumentation about {{the values that}} arguments promote, and the orderings on these values. In this paper, we show how extended frameworks integrating <b>meta-level</b> <b>reasoning</b> about values can be rewritten as Dung frameworks, and show a soundness and complete-ness result {{with respect to the}} rewrites. We then describe how value orderings can emerge, or be ‘formed’, as a result of dialogue games based on the rewritten frame-works, and illustrate the advantages of this approach over existing dialogue games for value based argumentation frameworks. 1...|$|E
40|$|By {{employing}} hybrid dynamical systems-oriented {{techniques for}} reasoning about dynamical systems, {{it is possible}} to for-malize some typically informal meta-intelligence about real-time intelligence of embodied agents. Furthermore, this meta-reasoning could be straightforwardly implemented in an embodied agent, forming a basis for meta-intelligent plan-ning or deeper logical reflection. This paper concretely illus-trates the underlying concepts, discussing a specific dynam-ical system for navigation intelligence, a specific system for <b>meta-level</b> <b>reasoning,</b> and a hypothetical case of their integra-tion in an embodied agent. The paper also suggests that the fundamental ideas generalize to other, similarly expressed in-telligence models, and that some high-level meta-reasoning over dynamical intelligence could thus be straightforwardly reduced to meta-reasoning over logical representations...|$|E
40|$|We {{argue that}} Lakatos' {{work on the}} history and {{philosophy}} of mathematics is of key relevance to machine creativity as it suggests ways in which to explore and transform concept spaces, rerepresent knowledge and change evaluation criteria. We describe approaches to implementing methods which Lakatos identifies, including our own approach, which extends Colton's HR and has enabled us to automatically generate mathematical conjectures, concepts and examples which were previously impossible in HR - including Goldbach 's conjecture. The methods are of general importance {{as they can be}} applied to many domains - we describe their theoretical application to game plans, two-dimensional geometry, moral philosophy, philosophy of mind, political argument and <b>meta-level</b> <b>reasoning...</b>|$|E
40|$|Qualitative {{probabilistic}} networks (QPNs) [13] are {{an abstraction}} of in uence diagrams and Bayesian belief networks replacing numerical relations by qualitative in uences and synergies. To reason in a QPN is to nd the e ect of decision or new evidence on a variable {{of interest in}} terms of the sign of the change in belief (increase or decrease). We review our work on qualitative belief propagation, a computationally e cient reasoning scheme based on local sign propagation in QPNs. Qualitative belief propagation, unlike the existing graph-reduction algorithm, preserves the network structure and determines the e ect of evidence on all nodes in the network. We show how this supports <b>meta-level</b> <b>reasoning</b> about the model and automatic generation of intuitive explanations of probabilistic reasoning. ...|$|E
40|$|Intentional agent {{systems are}} {{increasingly}} being used {{in a wide range}} of complex applications. Capabilities has recently been introduced into one of these systems as a software engineering mechanism to support modularity and reusability while still allowing <b>meta-level</b> <b>reasoning.</b> This paper presents a formalisation of capabilities within the framework of beliefs, goals and intentions and indicates how capabilities can affect agent reasoning about its intentions. We define a style of agent commitment which we refer to as a self-aware agent which allows an agent to modify its goals and intentions as its capabilities change. We also indicate which aspects of the specification of a BDI interpreter are affected by the introduction of capabilities and give some indications of additional reasoning which could be incorporated into an agent system on the basis of both the theoretical analysis and the existing implementation...|$|E
40|$|Bayesian network (BN) {{inference}} {{has long}} {{been seen as a}} very important and hard problem in AI. Both exact and approximate BN inference are NP-hard [Co 90, Sh 94]. To date researchers have developed many different kinds of exact and approximate BN inference algorithms. Each of these has different properties and works better for different classes of inference problems. Given a BN inference problem instance, it is usually hard but important to decide in advance which algorithm among a set of choices is the most appropriate. This problem is known as the algorithm selection problem [Ri 76]. The goal of this research is to design and implement a <b>meta-level</b> <b>reasoning</b> system that acts as a “BN inference expert ” and is able to quickly select the most appropriate algorithm for any given Bayesian network inference problem, and then predict the run time performance...|$|E
40|$|The {{verification}} of CCS programs {{has often been}} characterised as an expensive, time-consuming, and error-prone task, where computer assistance {{is thought to be}} essential. Yet, existing theorem proving based frameworks, for the {{verification of}} programs using CCS, are no much use because their poor level of automation. In this paper, we propose the use of proof plans as the chief mechanism for the automation of CCS program verification. We present a collection of proof plan methods that guide a proof plan formation for the verification of deterministic, and divergence-free CCS programs. The <b>meta-level</b> <b>reasoning</b> embedded in these methods takes full advantage of the operational interpretation of processes while outputting plan steps to the appropriate object-level representation. Keywords: Proof planning, process algebras, CCS, automatic program verification. 1 Introduction The specification and verification of communicating systems has often been characterised as an expensive, time-co [...] ...|$|E
40|$|There is a {{need for}} agent systems that can scale to realworld applications, yet retain the clean {{semantic}} underpinning of more formal agent frameworks. We describe the SRI Procedural Agent Realization Kit (SPARK), a new BDI agent framework that combines these two qualities. In contrast to most practical agent frameworks, SPARK has a clear, well-defined formal semantics that is intended to support reasoning techniques such as procedure validation, automated synthesis, and procedure repair. SPARK also provides a variety of capabilities such as introspection and <b>meta-level</b> <b>reasoning</b> to enable more sophisticated methods for agent control, and advisability techniques that support user directability. On the practical side, SPARK has several design constructs that support the development of large-scale agent applications. SPARK is currently being used as the agent infrastructure for a personal assistant system for a manager in an office environment. 1...|$|E
40|$|We use {{the phrase}} “joined-up ” here with a double mean-ing: to convey two aspects of {{scientific}} discovery which we believe are essential, yet under-researched with respect to automating scientific discovery processes. Firstly, from an Artificial Intelligence perspective, the majority of ap-proaches to using AI techniques involve a disjointed se-quential application of different problem solving methods, with the user providing the glue in various ways. These in-clude routine logistical aspects such as the pre-processing of data and knowledge, translating outputs into input, choos-ing parameter settings for running AI methods, etc. More importantly, however, the user performs various aspects of <b>meta-level</b> <b>reasoning,</b> including asking the most pertinent questions, determining what it means if a process terminates with success and identifying – and investigating – anoma-lies. This approach tends to lead to auto-assisted discov-eries where the user knows what they are looking for, but not what it looks like, rather than the deeper discoveries of examples/concepts/hypotheses/explanations that the user didn’t even know {{he or she was}} looking for. While AI meth-ods promise the discovery of such surprising and novel sci-entific artefacts, they rarely deliver on this promise, as their application is too regimented within the problem solving paradigm of AI. We therefore advocate (and actively pursue) investigations into how to build systems which combine reasoning activi-ties {{in such a way that}} the whole is more than a sum of the parts. While automating the logistical aspects mentioned above is tiresome but straightforward, we believe that au-tomating the <b>meta-level</b> <b>reasoning</b> skills employed by the users of AI tools for discovery tasks is a fascinating prob-lem. To this end, we have looked at various ad-hoc combina-tions for discovery tasks in pure mathematics (e. g., (Colton & Pease 2005), (Charnley, Colton, & Miguel 2006), with a summary in (Colton & Muggleton 2006)), but more recently we have started to investigate the value of more generic ap-proaches based on proof-planning from automated theorem proving (Sorge et al. 2007), and global workspace architec...|$|E
40|$|We use {{an example}} to compare the Boyer-Moore Theorem Prover and the Nuprl Proof Development System. The {{respective}} machine verifications of a version of Ramsey's theorem illustrate {{similarities and differences between}} the two systems. The proofs are compared using both quantitative and non-quantitative measures, and we examine difficulties in making such comparisons. 1 Introduction Over the last 25 years, a large number of logics and systems have been devised for machine verified mathematical development. These systems vary significantly in many important ways, including: underlying philosophy, object-level logic, support for <b>meta-level</b> <b>reasoning,</b> support for automated proof construction, and user interface. A summary of some of these systems, along with a number of interesting comments about issues (such as differences in logics, proof power, theory construction, and styles of user interaction), may be found in Lindsay's article [14]. The Kemmerer study [13] compares the use of four [...] ...|$|E
40|$|Qualitative Probabilistic Networks (QPNs) are an {{abstraction}} of Bayesian belief networks replacing numerical relations by qualitative influences and synergies [Wellman, 1990 b]. To reason in a QPN {{is to find}} the effect of new evidence on each node in terms of the sign of the change in belief (increase or decrease). We introduce a polynomial time algorithm for reasoning in QPNs, based on local sign propagation. It extends our previous scheme from singly connected to general multiply connected networks. Unlike existing graph-reduction algorithms, it preserves the network structure and determines the effect of evidence on all nodes in the network. This aids <b>meta-level</b> <b>reasoning</b> about the model and automatic generation of intuitive explanations of probabilistic reasoning. Introduction A formal representation should not use more specificity than needed to support the reasoning required of it. The appropriate degree of specificity or numerical precision will vary depending on what kind o [...] ...|$|E
40|$|Humans have {{different}} problem solving strategies {{at their disposal}} and they can flexibly employ several strategies when solving a complex problem, whereas previous theorem proving and planning systems typically employ a single strategy or a hard coded combination of a few strategies. We introduce multi-strategy proof planning that allows for combining a number of strategies and for switching flexibly between strategies in a proof planning process. Thereby proof planning becomes more robust since {{it does not necessarily}} fail if one problem solving mechanism fails. Rather it can reason about preference of strategies and about failures. Moreover, our strategies provide a means for structuring the vast amount of knowledge such that the planner can cope with the otherwise overwhelming knowledge in mathematics. 1 Introduction The choice of an appropriate problem solving strategy is a crucial human skill and is typically guided by some <b>meta-level</b> <b>reasoning.</b> Trained mathematicia [...] ...|$|E
40|$|Conceptual Structures (CS) Theory is a logic-based {{knowledge}} representation formalism. To show that conceptual graphs {{have the power}} of first-order logic, {{it is necessary to}} have a mapping between both formalisms. A proof system, i. e. axioms and inference rules, for conceptual graphs is also useful. It must be sound (no false statement is derived from a true one) and complete (all possible tautologies can be derived from the axioms). This paper shows that Sowa's original definition of the mapping is incomplete, incorrect, inconsistent, and unintuitive, and the proof system is incomplete too. To overcome these problems a new translation algorithm is given and a complete proof system is presented. Furthermore, the framework is extended for higher-order types. Key phrases: logical foundations of Conceptual Structures; OE operator; inference rules; logical axioms; higher-order types; <b>meta-level</b> <b>reasoning.</b> 1 Introduction The logical foundation of CS Theory, as presented in [ [...] ...|$|E
40|$|Constraint {{propagation}} algorithms vary in {{the strength}} of propagation they apply. This paper investigates a simple configuration for adaptive propagation [...] the process of varying {{the strength of}} propagation to reflect the dynamics of search. We focus on two propagation methods, Arc Consistency (AC) and Forward Checking (FC). AC-based algorithms apply a stronger form of propagation than FC-based algorithms; they invest greater computational effort to detect inconsistent values earlier. The relative payoff of maintaining AC during search as against FC may vary for different constraints and for different intermediate search states. We present a scheme for Adaptive Arc Propagation (AAP) that allows the flexible {{combination of the two}} methods. <b>Meta-level</b> <b>reasoning</b> and heuristics are used to dynamically distribute propagation effort between the two. One instance of AAP, Anti-Functional Reduction (AFR), is described in detail here. AFR achieves precisely the same propagation as a pure AC [...] ...|$|E
40|$|In dynamic environments, optimal {{deliberation}} in the decision-theoretic {{sense is}} impossible. Instead, {{it is sometimes}} necessary to trade potential decision quality for decision timeliness. One approach to achieving this trade-off is to endow intelligent agents with meta-level strategies that provide them guidance about when to reason [...] - and what to reason about [...] -and when to act instead. In this paper, we describe our investigations of a particular <b>meta-level</b> <b>reasoning</b> strategy, filtering, in which an agent commits to the goals it has already adopted, and then tends to filter from consideration new options that would conflict with the successful completion of existing goals [Bratman et al. 1988]. To investigate the utility of filtering, we {{conducted a series of}} experiments using the Tileworld testbed [Pollack and Ringuette 1990]. Previous experiments [Kinny and Georgeff 1991] provided preliminary evidence of the feasibility of filtering; our results generalize and refine those earlier [...] ...|$|E
40|$|I {{present a}} method for {{reasoning}} about spatial relationships {{on the basis of}} entailments in propositional logic. Formalisms for representing topological and other spatial information (e. g. [2] [10] [11]) have generally employed the 1 st-order predicate calculus. Whilst this language is much more expressive than 0 -order (propositional) calculi it is correspondingly harder to reason with. Hence, by encoding spatial relationships in a propositional representation automated reasoning becomes more effective. I specify representations in both classical and intuitionistic propositional logic, which [...] - together with well-defined <b>meta-level</b> <b>reasoning</b> algorithms [...] - provide for efficient reasoning about a large class of spatial relations. 1 INTRODUCTION This work has developed out of research done by Randell, Cui and Cohn (henceforth RCC) on formalising spatial and temporal concepts used in describing physical situations [11]. A set of classical 1 st-order logic axioms has been formulated in whi [...] ...|$|E
40|$|Logic embeddings {{provide an}} elegant means to formalize {{sophisticated}} non-classical logics in classical higher-order logic (HOL, Church’s simple type theory [11]). In previous work (cf. [4] and the references therein) the embeddings ap-proach {{has been successfully}} applied to automate object-level and <b>meta-level</b> <b>reasoning</b> {{for a range of}} logics and logic combinations with off-the-shelf HOL theorem provers. This also includes quantified modal logics (QML) [7] and quan-tified conditional logics (QCL) [3]. For many of the embedded logics few or none automated theorem provers did exist before. HOL is exploited in this approach to encode the semantics of the logics to be embedded, for example, Kripke seman-tics for QMLs [12] or selection function semantics for QCLs [23]. The embeddings approach is related to labelled deductive systems [15], which employ meta-level (world-) labeling techniques for the modeling and implementation of non-classical proof systems. In our embeddings approach such labels are instead encoded in the HOL logic. In recent work [6, 5] we have applied the embeddings approach to verif...|$|E
