64|10000|Public
40|$|AbstractThis paper {{concerns}} the reverse 2 -median problem on {{trees and the}} reverse 1 -median problem on graphs that contain exactly one cycle. It is shown that both <b>models</b> <b>under</b> <b>investigation</b> can be transformed to an equivalent reverse 2 -median problem on a path. For this new problem an O(nlogn) algorithm is proposed, where n {{is the number of}} vertices of the path. It is also shown that there exists an integral solution if the input data are integral...|$|E
40|$|Hybrid Monte Carlo (HMC) {{has been}} {{successfully}} applied to molecular simulation problems since its introduction in the late 1980 s. Its use in Bayesian computation, however, is relatively recent and rare (Neal 1996). In this article, we investigate statistical models in which HMC shows an edge over the more standard Monte Carlo techniques such as the Metropolis algorithm and the Gibbs sampler. The <b>models</b> <b>under</b> <b>investigation</b> include the indirect observation model, nonlinear state-space model and non-linear random-effects model. We also propose two methods, the multi-point method and parallel tempering, for improving HMC’s efficiency...|$|E
40|$|The {{article focuses}} on {{the current state of}} {{research}} in simultaneous interpreting (SI), comparing cognitive pragmatic models with cognitive linguistic approaches. The author offers an objective list of {{the advantages and disadvantages of}} the cognitive linguistic approach and other models currently used in SI. The aim of the article is not to present a one-sidedly positive assessment of the cognitive linguistic approach, but instead to arrive at a balanced evaluation of the individual approaches and the possibilities offered by the <b>models</b> <b>under</b> <b>investigation.</b> The author also points out further approaches that could be characterized as covertly cognitive...|$|E
40|$|BACKGROUND: Patient {{safety and}} adverse events {{in primary care}} are {{receiving}} increasing attention from policy makers, professional bodies and researchers. Various taxonomic models {{have been developed to}} specify the factors that predispose to adverse events in hospital settings. These are assumed to have general applicability across different healthcare settings. However, they have never been applied to home health care. AIMS: This study helps define the value of one such model in a domiciliary setting. The principal {{purpose of the study was}} to understand the circumstances in which the involvement of local authority-funded home carers as well as NHS-funded district nurses in medication-related activities for older people living at home in the UK might jeopardise patient safety. METHOD: The study was undertaken in two contrasting sites. One was in London and the other in the Midlands. District nurses and home carers were purposively selected to take part in semi-structured interviews. The data were used to construct a taxonomic model that specified the factors that predispose older people to adverse events when medication-related responsibilities are transferred from district nursing to home care services. RESULTS: The new taxonomy was compared to the taxonomic <b>model</b> <b>under</b> <b>investigation.</b> Dissonance existed within a number of categories. CONCLUSIONS: The <b>model</b> <b>under</b> <b>investigation</b> was found to be too narrow for application in domiciliary settings. The challenges that exist in home health care are often very different from those that exist in hospital settings, from which the <b>model</b> <b>under</b> <b>investigation</b> was derived. The root causes of accidents are most likely to be identified by models empirically derived from, and tailored to fit, the particular circumstances in which they are to be applied...|$|R
40|$|The spin- 1 / 2 Ising-Heisenberg {{model on}} {{diamond-like}} decorated Bethe lattices is exactly solved {{with the help}} of decoration-iteration transformation and exact recursion relations. It is shown that the <b>model</b> <b>under</b> <b>investigation</b> exhibits reentrant phase transitions whenever a sufficiently high coordination number of the underlying Bethe lattice is considered. Comment: 6 pages, 3 figures, presented at 14 th Czech and Slovak Conference on Magnetism 6. - 9. July 2010, Kosice, Slovaki...|$|R
40|$|Abstract. A filter/guidance {{simulation}} toolbox {{based on}} Matlab software was designed. Built under {{the principle of}} “define once and use many times”, the propose toolbox successfully separate the estimation algorithms, the guidance law, and the math <b>model</b> <b>under</b> <b>investigation</b> into three different yet related parts, which drastically reduced the burden of repeatedly designing the same filters and guidance law for different simulation models. Typical example from both simulation cases and real field test data proved the correctness and effectiveness of the proposed toolbox...|$|R
40|$|The present {{review is}} {{intended}} to encompass the applications of symmetry based approaches for solving non-Newtonian fluid flow problems in various physical situations. Works which deal with the fundamental science of non-Newtonian fluids that are analyzed using the Lie group method and conditional symmetries are reviewed. We provide the mathematical modelling, the symmetries deduced, and the solutions obtained for all the models considered. This survey includes, as far as possible, all the articles published until 2015. Only papers published by a process of peer review in archival journals are reviewed and are grouped together according to the specific non-Newtonian <b>models</b> <b>under</b> <b>investigation...</b>|$|E
40|$|Key {{words and}} phrases. Efficient estimation, {{generalized}} linear models, measurement-error models, structural models. SUMMARY Efficient {{estimation of the}} regression parameters in a structural generalized linear measurement-error model is studied. Using the efficient scores derived in Stefanski and Carroll (1987), the existence of asymptotically efficient estimators is established by employing a one-step construction {{similar to that used}} by Bickel (1982). The construction assumes the l' availability of an n~-consistent estimator which is argued to exist quite generally for the <b>models</b> <b>under</b> <b>investigation.</b> 1. INTRODUCTION. For a generalized linear model in canonical form, the conditional density of the response variable Y given the pxl-dimensional covariate U • u can be written a...|$|E
40|$|Abstract. In {{this paper}} {{we report on}} a study of {{implicit}} feedback models for unobtrusively tracking the information needs of searchers. Such models use relevance information gathered from searcher interaction and can be a potential substitute for explicit relevance feedback. We introduce a variety of implicit feedback models designed to enhance an Information Retrieval (IR) system’s representation of searchers ’ information needs. To benchmark their performance we use a simulation-centric evaluation methodology that measures how well each model learns relevance and improves search effectiveness. The results show that a heuristic-based binary voting model and one based on Jeffrey’s rule of conditioning [5] outperform the other <b>models</b> <b>under</b> <b>investigation.</b> ...|$|E
40|$|Integration {{of large}} amounts of {{experimental}} data and previous knowledge is recognized as {{the next step in}} enhancing biological pathway discovery. Here, data integration for quantitative regulatory network <b>modelling</b> is <b>under</b> <b>investigation,</b> using evolutionary computation and high-performance computing...|$|R
30|$|In this note, we {{extended}} dimensionally {{a numerical}} technique to approximate {{the solution of}} the well-known Burgers-Huxley equation, using a finite-difference perspective. The method is an exact technique that requires one to solve a cubic polynomial at each temporal step and each spatial node via the Cardano formulas. The method is an exact technique which preserves positivity, boundedness and monotonicity, resembling thus the features of many classical solutions of the <b>model</b> <b>under</b> <b>investigation.</b> Finally, we also established that the method is convergent of first order in time and second order in space.|$|R
40|$|We {{present a}} simple {{model in which}} a brane with {{anisotropic}} metric is embedded in an AdS bulk. We discuss the localization of the massless mode and the amplification of both the massless and the massive modes on the branes, paying {{particular attention to the}} normalization of the perturbed action and to the evaluation of the effective coupling constant that controls the amplitude of the spectrum. In the <b>model</b> <b>under</b> <b>investigation</b> there is no mass gap between massless and massive modes, and the massive modes can be amplified, with mass-dependent amplitudes...|$|R
40|$|Experimentation is {{ubiquitous}} {{in the field}} of psychology and fundamental to the advancement of its science, and {{one of the biggest challenges}} for researchers is designing experiments that can conclusively discriminate the theoretical hypotheses or <b>models</b> <b>under</b> <b>investigation.</b> The recognition of this challenge has led to the development of sophisticated statistical methods that aid in the design of experiments and that are within the reach of everyday experimental scientists. This tutorial paper introduces the reader to an implementable experimentation methodology, dubbed Adaptive Design Optimization, that can help scientists to conduct “smart ” experiments that are maximally informative and highly efficient, which in turn should accelerate scientific discovery in psychology and beyond. ...|$|E
40|$|In {{this paper}} {{we report on}} a study of {{implicit}} feedback models for unobtrusively tracking the information needs of searchers. Such models use relevance information gathered from searcher interaction and can be a potential substitute for explicit relevance feedback. We introduce a variety of implicit feedback models designed to enhance an Information Retrieval (IR) system's representation of searchers' information needs. To benchmark their performance we use a simulation-centric evaluation methodology that measures how well each model learns relevance and improves search effectiveness. The results show that a heuristic-based binary voting model and one based on Jeffrey 's rule of conditioning [5] outperform the other <b>models</b> <b>under</b> <b>investigation...</b>|$|E
40|$|The {{main purpose}} of the study was to verify if helical flow, widely {{observed}} in several vessels, might be a signature of the blood dynamics of vein graft anastomosis. We investigated the existence of a relationship between helical flow structures and vascular wall indexes of atherogenesis in aortocoronary bypass models with different geometric features. In particular, we checked for the existence of a relationship between the degree of helical motion and the magnitude of oscillating shear stress in conventional hand-sewn proximal anastomosis. The study is based on the numerical evaluation of four bypass geometries that are attached to a simplified computer representation of the ascending aorta with different angulations relative to aortic outflow. The finite volume technique was used to simulate realistic graft fluid dynamics, including aortic compliance and proper aortic and graft flow rates. A quantitative method was applied to evaluate the level of helicity in the flow field associated with the four bypass <b>models</b> <b>under</b> <b>investigation.</b> A linear inverse relationship (R=- 0. 97) was found between the oscillating shear index and the helical flow index for the <b>models</b> <b>under</b> <b>investigation.</b> The results obtained support the hypothesis that an arrangement of the flow field in helical patterns may elicit damping in wall shear stress temporal gradients at the proximal graft. Accordingly, helical flow might play a significant role in preventing plaque deposition or in tuning the mechanotransduction pathways of cells. Therefore, results confirm that helical flow constitutes an important flow signature in vessels, and its strength as a fluid dynamic index (for instance in combination with magnetic resonance imaging flow visualization techniques) for risk stratification, in the activation of both mechanical and biological pathways leading to fibrointimal hyperplasia...|$|E
40|$|We {{consider}} cosmological {{dynamics in}} the theory of gravity with the scalar field possessing a nonminimal kinetic coupling to gravity, κ G_μνϕ^μϕ^ν, and the power-law potential V(ϕ) =V_ 0 ϕ^N. Using the dynamical system method, we analyze all possible asymptotical regimes of the <b>model</b> <b>under</b> <b>investigation</b> and show that for sloping potentials with 0 2. Using a numerical analysis, we also construct exact cosmological solutions and find initial conditions leading to the initial kinetic coupling inflation followed either by a "graceful" oscillatory exit or by the secondary inflation. Comment: 10 pages, 6 figures, submitted to PR...|$|R
40|$|In {{this paper}} a {{rigorous}} {{proof of the}} mean field limit for a pedestrian flow model in two dimensions is given by using a probabilistic method. The <b>model</b> <b>under</b> <b>investigation</b> is an interacting particle system coupled to the eikonal equation on the microscopic scale. For stochastic initial data, it is proved that {{the solution of the}} $N$-particle pedestrian flow system with properly chosen cut-off converges in the probability sense to the solution of the characteristics of the non-cut-off Vlasov equation. Furthermore, the result on propagation of chaos is also deduced in terms of bounded Lipschitz distance...|$|R
40|$|The {{majority}} of multicell-decoding cellular models preserve a fundamental assumption which has initially appeared in Wyner’s model, namely the collocation of User Terminals (UTs). Although this assumption produces more tractable mathematical models, {{it is unrealistic}} w. r. t. current practical cellular systems. In this paper, we alleviate this assumption by assuming uniformly distributed UTs. The <b>model</b> <b>under</b> <b>investigation</b> is the uplink channel of a planar cellular array {{in the presence of}} power-law path loss and flat fading. In this context, we employ a free probability approach to evaluate the effect of UT distribution on the optimal sum-rate capacity of a variable-density cellular system...|$|R
40|$|In {{this paper}} we {{consider}} model averaging for quantile regressions (QR) when all <b>models</b> <b>under</b> <b>investigation</b> are potentially misspecified {{and the number}} of parameters is diverging with the sample size. To allow for the dependence between the error terms and regressors in the QR models, we propose a jackknife model averaging (JMA) estimator which selects the weights by minimizing a leave-one-out cross-validation criterion function and demonstrate its asymptotic optimality in terms of minimizing the out-of-sample final prediction error. We conduct simulations to demonstrate the finite-sample performance of our estimator and compare it with other model selection and averaging methods. We apply our JMA method to forecast quantiles of excess stock returns and wages. (C) 2015 Elsevier B. V. All rights reserved...|$|E
40|$|This study aims {{to examine}} the {{construct}} validity and {{factor structure of the}} Rosenberg self-esteem scale (RSES) using a sample (n= 312) of Polish prisoners incarcerated in Nowogard High Security Prison. The number of confirmatory factor analysis (CFA) <b>models</b> <b>under</b> <b>investigation</b> was limited to two by virtue of employing a much stricter and more rigorously sound methodological procedure in which item errors were prevented from correlating, as suggested by Brown. Confirmatory factor analyses indicated that the two-factor (positive and negative self-esteem) model provided a better fit for the RSES items than did the one-factor model. The results provide some initial support for the two-dimensional model that could possibly be measuring substantively separate factors within a prison sample, thus calling into question the one-factor solution of the RSES...|$|E
40|$|Non-profit {{organizations}} {{represent an}} important institutional avenue for delivering social services in contemporary Australia. Moreover, a voluminous theoretical literature {{exists on the}} voluntary sector in advanced countries. However, relatively little effort has thus far been expended on the empirical assessment of the main models of non-profit organizational behaviour. Using 2003 survey data drawn from selected NSW non-profit social service providers, this paper seeks to replicate Lester Salamon’s (1992) seminal American empirical investigation of stylized versions of demand-side theories, supply-side theories, organizational theories, and Salamon’s (1987) own model of voluntary sector failure. In common with Salamon’s (1992) earlier findings, our {{results suggest that the}} theory of voluntary sector failure possesses the greatest explanatory power of the four main <b>models</b> <b>under</b> <b>investigation.</b> Key Words: non-profit organizations; social service delivery; voluntary sector models...|$|E
40|$|This paper {{presents}} a statistical test allowing the analyst {{to determine if}} a given time series is statistically incompatible with being modeled as a linear or log-linear process. Since the commonly used models for financial time series of interest to insurance professionals are linear or log-linear, this paper allows the analyst to verify the linearity of the <b>model</b> <b>under</b> <b>investigation,</b> or else points to the necessity of non-linear modeling. We also show how to test for time series Gaussianity using the same type of statistical test statistic. These results are applied to several financial data sets relevant to the financial operations of insurance companies...|$|R
40|$|The large-sample {{properties}} of likelihood-based statistical inference <b>under</b> mixture <b>models</b> have received much attention from statisticians. Although {{the consistency of}} the nonparametric MLE is regarded as a standard conclusion, many researchers ignore the precise conditions required on the mixture model. An incorrect claim of consistency can lead to false conclusions even if the mixture <b>model</b> <b>under</b> <b>investigation</b> seems well behaved. Under a finite normal mixture model, for instance, {{the consistency of the}} plain MLE is often erroneously assumed in spite of recent research breakthroughs. This paper streamlines the consistency results for the nonparametric MLE in general, and in particular for the penalized MLE under finite normal mixture models...|$|R
40|$|We {{present a}} simple {{model in which}} a brane with {{anisotropic}} metric is embedded in an AdS bulk. We discuss the localization of the massless mode and the amplification of both the massless and the massive modes on the branes, paying {{particular attention to the}} normalization of the perturbed action and to the evaluation of the effective coupling constant that controls the amplitude of the spectrum. In the <b>model</b> <b>under</b> <b>investigation</b> there is no mass gap between massless and massive modes, and the massive modes can be amplified, with mass-dependent amplitudes. Comment: 7 pages, talk given at the 4 th QG 05 meeting, Cala Gonone (Sardinia, Italy), Sept. 12 - 16, 200...|$|R
40|$|Purpose – This study aims {{to examine}} the {{construct}} validity and {{factor structure of the}} Rosenberg self-esteem scale (RSES) using a sample (n= 312) of Polish prisoners incarcerated in Nowogard High Security Prison. Design/methodology/approach – The number of confirmatory factor analysis (CFA) <b>models</b> <b>under</b> <b>investigation</b> was limited to two by virtue of employing a much stricter and more rigorously sound methodological procedure in which item errors were prevented from correlating, as suggested by Brown. Findings – Confirmatory factor analyses indicated that the two-factor (positive and negative self-esteem) model provided a better fit for the RSES items than did the one-factor model. Originality/value – The results provide some initial support for the two-dimensional model that could possibly be measuring substantively separate factors within a prison sample, thus calling into question the one-factor solution of the RSES...|$|E
40|$|In this work, {{we study}} the target {{detection}} and tracking problem in mobile sensor networks, where the performance metrics of interest are {{probability of detection}} and tracking coverage, when the target can be stationary or mobile and its duration is finite. We propose a physical coverage-based mobility model, where the mobile sensor nodes move such that the overlap between the covered areas by different mobile nodes is small. It is shown that for stationary target scenario the proposed mobility model can achieve a desired detection probability with a significantly lower number of mobile nodes especially when the detection requirements are highly stringent. Similarly, when the target is mobile the coverage-based mobility model produces a consistently higher detection probability compared to other <b>models</b> <b>under</b> <b>investigation.</b> Comment: 7 pages, 12 figures, appeared in INFOCOM 201...|$|E
40|$|In an inflationary regime {{driven by}} a free massive {{inflaton}} we consider a class of observers which sees an inhomogeneous and isotropic Universe and derive within a genuinely gauge invariant approach the backreaction effects due to long wavelength scalar fluctuations on the associated effective Hubble factor and equation of state. We find that, for such so-called isotropic observers, contrary to what happens for the observables defined by free-falling observers, there is an effect to leading order in the slow-roll parameter {{in the direction of}} slowing down the measured rate of expansion and of having an effective equation of state less de Sitter like. From a general point of view the isotropic observers result has to be considered complementary to other cases (observers) in helping to characterize the physical properties of the <b>models</b> <b>under</b> <b>investigation.</b> ...|$|E
40|$|This chapter {{discusses}} {{two important}} aspects of the structure-determination process that are related to the accuracy and reliability of the <b>model</b> <b>under</b> <b>investigation.</b> Quality control is defined as the analysis of an intermediate model to identify aspects of it that are unusual in some sense and that could therefore be due to errors in the model building or refinement process. Any such errors need to be fixed, if at all possible, prior to analysis and publication of the model. Validation is the process of assessing the reliability of the final model (or certain aspects of it, e. g., the active site residues) that is about to be analysed, published, deposited and possibly used in follow-up studies. 1...|$|R
40|$|We study cosmological {{solutions}} in R + β R^N-gravity for an isotropic Universe filled with ordinary matter with {{the equation of}} state parameter γ. Using the Bogolyubov-Krylov-Mitropol'skii averaging method we find asymptotic oscillatory {{solutions in}} terms of new functions, which have been specially introduced by us for this problem and appeared as a natural generalization of the usual sine and cosine. It is shown that the late-time behaviour of the Universe in the <b>model</b> <b>under</b> <b>investigation</b> {{is determined by the}} sign of the difference γ-γ_crit where γ_crit= 2 N/(3 N- 2). If γ 2. Some important differences between N= 2 and N> 2 cases are discussed. Comment: 23 + 10 pages, 7 figures, published versio...|$|R
40|$|We {{consider}} a discrete-time gated vacation system. The available buffer space {{is divided into}} two subsequent queues separated by a gate and new customers arrive either before or after this gate. Whenever all customers after the gate are served, the server takes a vacation. After each vacation, the gate opens which causes all waiting customers to move to the buffer space after the gate. The <b>model</b> <b>under</b> <b>investigation</b> allows to capture performance of a. o. the exhaustive and the gated queueing systems with multiple or single vacations. Using a probability generating functions approach, we obtain expressions for performance measures such as moments of system contents at various epochs in equilibrium and of customer delay. We conclude with a numerical example. Key words: Discrete-time queue, vacation, interruption...|$|R
30|$|Bifurcation {{diagrams}} {{that correspond}} to layers of the unfolding of the deg. TB singularity {{have been identified in}} different models, for example the Bazykin predator-prey model [33, 36] or several neuron models (see Kirst et al. [31] and references therein). Other authors realized that the bifurcation diagrams identified in the <b>models</b> <b>under</b> <b>investigation</b> were deformations of this unfolding [37]. Studying the partial unfolding of the codim- 4 doubly degenrate TB singularity can help to understand some of these deformations. For example, the bifurcation diagram for the Morris–Lecar model produced by Govaerts et al. [37], which appears also in a model for a compression system [38], can be located in the stage (E) in Fig.  15. The presence of the other stages in the right ordering would be indicative for a codim- 4 doubly degenerate TB singularity in the model.|$|E
40|$|This is {{a review}} paper {{concerned}} with the global consistency of the quantum dynamics of non-commutative systems. Our point of departure is the theory of constrained systems, since it provides a unified description of the classical and quantum dynamics for the <b>models</b> <b>under</b> <b>investigation.</b> We then elaborate on recently reported results {{concerned with the}} sufficient conditions {{for the existence of}} the Born series and unitarity and turn, afterwards, into analyzing the functional quantization of non-commutative systems. The compatibility between the operator and the functional approaches is established in full generality. The intricacies arising in connection with the explicit computation of path integrals, for the systems under scrutiny, is illustrated by presenting the detailed calculation of the Feynman kernel for the non-commutative two dimensional harmonic oscillator. Comment: 19 pages, title changed, version to be published in Brazilian Journal of Physic...|$|E
40|$|In {{this paper}} we {{consider}} the problem of frequentist model averaging for quantile regression (QR) when all the <b>models</b> <b>under</b> <b>investigation</b> are potentially misspecified {{and the number of}} parameters in some or all models is diverging with the sample size To allow for the dependence between the error terms and the regressors in the QR models, we propose a jackknife model averaging (JMA) estimator which selects the weights by minimizing a leave-one-out cross-validation criterion function and demonstrate that the jackknife selected weight vector is asymptotically optimal in terms of minimizing the out-of-sample final prediction error among the given set of weight vectors. We conduct Monte Carlo simulations to demonstrate the finite-sample performance of the proposed JMA QR estimator and compare it with other model selection and averaging methods. We find that in terms of out-of-sample forecasting, the JMA QR estimator can achieve significant efficiency gain...|$|E
40|$|The mixed spin- 1 / 2 and spin- 3 / 2 Ising {{model on}} the union jack lattice is solved by {{establishing}} a mapping correspondence with the eight-vertex model. It is shown that the <b>model</b> <b>under</b> <b>investigation</b> becomes exactly soluble as a free-fermion eight-vertex model when the parameter of uniaxial single-ion anisotropy tends to infinity. Under this restriction, the critical points are characterized by critical exponents from the standard Ising universality class. In a certain subspace of interaction parameters, which corresponds to a coexistence surface between two ordered phases, the model becomes exactly soluble as a symmetric zero-field eight-vertex model. This surface is bounded by a line of bicritical points having interaction-dependent critical exponents that satisfy a weak universality hypothesis. Comment: 8 pages, 8 figure...|$|R
30|$|A {{scratchpad memory}} for JOP is {{implemented}} and the {{integration into the}} programming <b>model</b> is <b>under</b> <b>investigation.</b> We will add a small fully associative data cache to JOP. This cache will {{also serve as a}} buffer for a real-time transactional memory for the JOP CMP system. We will investigate whether a standard cache for static data is a practical solution for Java.|$|R
40|$|GCMAC) {{has been}} the {{starting}} point for studying the Shannon-theoretic limits of cellular systems. In 1994, a simple infinite GCMAC was initially introduced by Wyner and was subsequently extended by researchers to incorporate flat fading environments and power-law path loss models. However, Wyner-like models, preserve a fundamental assumption, namely the symmetry of User Terminals (UTs). In this paper, we investigate the effect of this assumption on the sum-rate capacity limits, by examining the case of distributed and thus asymmetric UTs. The <b>model</b> <b>under</b> <b>investigation</b> is a GCMAC over a linear cellular array in the presence of power-law path loss and flat fading. In this context, we study the effect of UT distribution for cell-centre and cell-edge UTs and we show that its effect is considerable only in the case of low cell density...|$|R
