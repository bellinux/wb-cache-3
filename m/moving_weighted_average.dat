8|10000|Public
30|$|To verify {{whether the}} Kalman-based {{smoothing}} algorithm for ranging data improved the location accuracy and enhanced robustness, partial ranging {{data of the}} indoor position (3.39, 5.40) and outdoor position (3.00, 4.00) were investigated: The ranging data {{were divided into two}} test groups (those smoothed via Kalman method before being calculated by cooperative localization, and those obtained directly via cooperative localization) while two other groups of location results were smoothed by <b>moving</b> <b>weighted</b> <b>average</b> method. The absolute location error among the groups was compared as shown in Figs.  12 and 13.|$|E
30|$|Chan, Taylor, {{extended}} Kalman filter (EKF), and {{particle filter}} (PF), et al., are frequently-used algorithms in TDOA location. The positioning precision of Chan algorithm decreases significantly in NLOS environment. Taylor algorithm can obtain accurate computation when initial estimated situation approximates the actual location, otherwise, {{it is difficult}} for the algorithms to ensure the convergence. But PF algorithm performs on poor instantaneity. The proposed algorithm has high accuracy and performs well in real-time tracking. A novel, CSS-based location system including a TDOA ranging method is presented in this paper. A location engine was designed as a series of location algorithms and smoothing algorithms, and a Kalman filter algorithm and <b>moving</b> <b>weighted</b> <b>average</b> technique were respectively applied to smooth the TDOA range measurements and location results.|$|E
40|$|Advances in {{monitoring}} technology {{have resulted in}} the collection of a vast amount of data that exceeds the simultaneous surveillance capabilities of ex-pert clinicians in the clinical environment. To facilitate the clinical decision-making process, this thesis solves two fundamental problems in physiological monitoring: signal estimation and trend-pattern recognition. The general approach is to transform changes in different trend features to nonzero shifts by calculating the model-based forecast residuals and then to apply a statistical test or Bayesian approach on the residuals to detect changes. The EWMA-Cusum method describes a signal as the exponentially <b>moving</b> <b>weighted</b> <b>average</b> (EWMA) of historical data. This method is simple, robust, and applicable to most variables. The method based on the Dynamic Linear Model (refereed to as Adaptive-DLMmethod) describes a signal using the linear growth model combined with an EWMA model. An adaptive Kalman filter is used to estimate the second-order characteristics and adjus...|$|E
50|$|<b>Weighted</b> <b>moving</b> <b>average</b> (WMA).|$|R
5000|$|... #Caption: 3-day Rising {{moving average}} on a 5-day close-price <b>weighted</b> <b>moving</b> <b>average</b> ...|$|R
40|$|To date, {{numerous}} {{extensions of}} the exponentially <b>weighted</b> <b>moving</b> <b>average,</b> EWMA charts have been made. A new robust EWMA chart for the process mean is proposed. It enables easier detection of outliers and increase sensitivity {{to other forms of}} out-of-control situation when outliers are present. Key words: Exponentially <b>weighted</b> <b>moving</b> <b>average</b> (EWMA), cumulative sum (CUSUM), Shewhart...|$|R
40|$|Current {{synthetic}} {{chemical systems}} lack {{the ability to}} self-modify and learn to solve desired tasks. In this paper we introduce a new parallel model of a chemical delay line, which stores past concentrations over time with minimal latency. To enable temporal processing, we integrate the delay line with our previously proposed analog chemical perceptron. We show that we can successfully train our new memory-enabled chemical learner on four non-trivial temporal tasks: the linear <b>moving</b> <b>weighted</b> <b>average,</b> the moving maximum, and two variants of the Nonlinear AutoRegressive Moving Average (NARMA). Our implementation is based on chemical reaction networks and follows mass-action and Michaelis-Menten kinetics. We show that despite a simple design and limited resources, a single chemical perceptron extended with memory of variable size achieves 93 - 99 % accuracy on the above tasks. Our results present an important step toward actual biochemical systems that can learn and adapt. Such systems have applications in biomedical diagnosis and smart drug delivery...|$|E
30|$|Location based {{services}} (LBS) {{provided by}} {{wireless sensor networks}} have garnered {{a great deal of}} attention from researchers and developers in recent years. Chirp spread spectrum (CSS) signaling formatting with time difference of arrival (TDOA) ranging technology is an effective LBS technique in regards to positioning accuracy, cost, and power consumption. The design and implementation of the location engine and location management based on TDOA location algorithms were the focus of this study; as the core of the system, the location engine was designed as a series of location algorithms and smoothing algorithms. To enhance the location accuracy, a Kalman filter algorithm and <b>moving</b> <b>weighted</b> <b>average</b> technique were respectively applied to smooth the TDOA range measurements and location results, which are calculated by the cooperation of a Kalman TDOA algorithm and a Taylor TDOA algorithm. The location management server, the information center of the system, was designed with Data Server and Mclient. To evaluate the performance of the location algorithms and the stability of the system software, we used a Nanotron nanoLOC Development Kit 3.0 to conduct indoor and outdoor location experiments. The results indicated that the location system runs stably with high accuracy at absolute error below 0.6  m.|$|E
40|$|Effective {{distribution}} using collaborative fulfillment networks requires coordination {{among the}} multiple participating firms {{at different stages}} of the supply chain. Acting independently, supply chain partners fail to weigh the cost burden they impose on upstream suppliers when their replenishment order quantities vary from period to period. This paper explores a new approach to coordinate multiple stages in the supply chain by controlling, through appropriate downstream inventory management, the demand variability that is propagated to upstream stages. We propose and analyze a coordinated inventory replenishment policy that uses "order smoothing" to reduce order-size variability and thus reduce overall system costs, including both inventory and transportation costs. We characterize the optimal parameter values for smoothing alternatives (such as exponential smoothing and <b>moving</b> <b>weighted</b> <b>average</b> policies), assess their economic benefits, and develop insights regarding supply chain contexts that might benefit most significantly from reducing the variability of orders to upstream stages. Using the distribution network for specialty brand appliances as an illustrative example, we demonstrate the potential cost savings that order-smoothing strategies can yield compared to the uncoordinated case when individual firms separately minimize their costs. The magnitude of savings depends on several factors, including the variability in consumer demand, level of product variety, and degree of inventory aggregation in the distribution system. Based on our analytical results, we develop a framework to assess cost reduction opportunities through variability control for different supply chain scenarios. supply chain coordination, inventory control, variability reduction, distribution systems, collaborative fulfillment, order smoothing...|$|E
5000|$|... sumix compute <b>weighted</b> <b>moving</b> <b>average</b> (trace MIX) on a {{panel of}} seismic data ...|$|R
40|$|Technical {{analysis}} rely on {{assumption that}} analysis of past market performance provides possibility for proper stock price forecasting, in particular by identification of {{buy and sell}} signals. The article describe main moving average models: simple <b>moving</b> <b>average,</b> <b>weighted</b> <b>moving</b> <b>average</b> and exponential moving average and manner of theirs usage while constructing investment strategy on financial market. The article outlines possibilities and limitations of moving averages usage in investment practice. In addition empirical verification of moving averages is provided for selected polish shares forming index WIG 20...|$|R
3000|$|... denote an {{exponentially}} <b>weighted</b> <b>moving</b> <b>average</b> of RTT and the deviation, respectively. The initial {{values of}} [...]...|$|R
40|$|Title from PDF {{of title}} page (University of Missouri [...] Columbia, viewed on September 3, 2013). The entire thesis text is {{included}} in the research. pdf file; the official abstract appears in the short. pdf file; a non-technical public abstract appears in the public. pdf file. Dissertation advisor: Dr. Min YangIncludes bibliographical references. Vita. Ph. D. University of Missouri [...] Columbia 2013. Dissertations, Academic [...] University of Missouri [...] Columbia [...] Statistics. "May, 2013 "[ACCESS RESTRICTED TO THE UNIVERSITY OF MISSOURI AT AUTHOR'S REQUEST. ] There are many areas where optimal designs are applied to, for example, {{the development of a new}} drug, where a conventional dose- finding study involves learning about the dose-response curve in order to bring forward right doses of drug to late-stage development. The first part of this dissertation focus on three pharmacodynamics sigmoid Emax models, we derive the corresponding simple formats of the adaptive optimal designs regardless of the optimality criteria or parameters of interest. An algorithm for deriving a specific adaptive optimal design is developed. A simulation study comparing the adaptive optimal designs and the uniform designs is also performed. The second part of this dissertation focuses on the statistical process control, we proposed an adaptive approach for the multivariate CUSUM statistical process control chart for signaling a range of location shifts. This method is based on the multivariate CUSUM control chart proposed by Pignatiello and Runger in 1990. We used the exponentially <b>moving</b> <b>weighted</b> <b>average</b> (EMWA) statistic to estimate the current process mean shift and change the reference value adaptively in each run. By specifying the minimal magnitude of the mean shift through the non-centrality parameter, our proposed control chart can achieve an overall good performance for detecting a range of shifts rather than a single value...|$|E
40|$|Multitemporal SAR {{images have}} been {{increasingly}} {{used for the}} detection of different types of environmental changes. The detection of urban changes using SAR images is complicated due to the complex mixture of the urban environment and the special characteristics of SAR images, for example, the existence of speckle. This thesis investigates urban change detection using multitemporal SAR images with the following specific objectives: (1) to investigate unsupervised change detection, (2) to investigate effective methods for reduction of the speckle effect in change detection, (3) to investigate spatio-contextual change detection, (4) to investigate object-based unsupervised change detection, and (5) to investigate a new technique for object-based change image generation. Beijing and Shanghai, the largest cities in China, were selected as study areas. Multitemporal SAR images acquired by ERS- 2 SAR and ENVISAT ASAR sensors were used for pixel-based change detection. For the object-based approaches, TerraSAR-X images were used. In Paper I, the unsupervised detection of urban change was investigated using the Kittler-Illingworth algorithm. A modified ratio operator that combines positive and negative changes was used to construct the change image. Four density function models were tested and compared. Among them, the log-normal and Nakagami ratio models achieved the best results. Despite the good performance of the algorithm, the obtained results suffer from the loss of fine geometric detail in general. This was a consequence of the use of local adaptive filters for speckle suppression. Paper II addresses this problem using the nonlocal means (NLM) denoising algorithm for speckle suppression and detail preservation. In this algorithm, denoising was achieved through a <b>moving</b> <b>weighted</b> <b>average.</b> The weights are a function of the similarity of small image patches defined around each pixel in the image. To decrease the computational complexity, principle component analysis (PCA) was used to reduce the dimensionality of the neighbourhood feature vectors. Simple methods to estimate the number of significant PCA components to be retained for weights computation and the required noise variance were proposed. The experimental results showed that the NLM algorithm successfully suppressed speckle effects, while preserving fine geometric detail in the scene. The analysis also indicates that filtering the change image instead of the individual SAR images was effective in terms {{of the quality of the}} results and the time needed to carry out the computation. The Markov random field (MRF) change detection algorithm showed limited capacity to simultaneously maintain fine geometric detail in urban areas and combat the effect of speckle. To overcome this problem, Paper III utilizes the NLM theory to define a nonlocal constraint on pixels class-labels. The iterated conditional mode (ICM) scheme for the optimization of the MRF criterion function is extended to include a new step that maximizes the nonlocal probability model. Compared with the traditional MRF algorithm, the experimental results showed that the proposed algorithm was superior in preserving fine structural detail, effective in reducing the effect of speckle, less sensitive to the value of the contextual parameter, and less affected by the quality of the initial change map. Paper IV investigates object-based unsupervised change detection using very high resolution TerraSAR-X images over urban areas. Three algorithms, i. e., Kittler-Illingworth, Otsu, and outlier detection, were tested and compared. The multitemporal images were segmented using multidate segmentation strategy. The analysis reveals that the three algorithms achieved similar accuracies. The achieved accuracies were very close to the maximum possible, given the modified ratio image as an input. This maximum, however, was not very high. This was attributed, partially, to the low capacity of the modified ratio image to accentuate the difference between changed and unchanged areas. Consequently, Paper V proposes a new object-based change image generation technique. The strong intensity variations associated with high resolution and speckle effects render object mean intensity unreliable feature. The modified ratio image is, therefore, less efficient in emphasizing the contrast between the classes. An alternative representation of the change data was proposed. To measure the intensity of change at the object in isolation of disturbances caused by strong intensity variations and speckle effects, two techniques based on the Fourier transform and the Wavelet transform of the change signal were developed. Qualitative and quantitative analyses of the result show that improved change detection accuracies can be obtained by classifying the proposed change variables.   QC 20150529 </p...|$|E
5000|$|That is, this discrete-time {{implementation}} of a simple RC low-pass filter is the exponentially <b>weighted</b> <b>moving</b> <b>average</b> ...|$|R
40|$|A new {{control chart}} {{procedure}} is given {{for which the}} Shewhart -chart, the cumulative sum chart, and the exponentially <b>weighted</b> <b>moving</b> <b>average</b> chart are special cases. The run length properties for a one-sided generalized control chart are analyzed using an integral equation approach. A comparison of the average run lengths of various new control chart procedures is given. Shewhart -chart exponentially <b>weighted</b> <b>moving</b> <b>average</b> chart cumulative sum chart...|$|R
50|$|Variations of this {{calculation}} typically involve {{using different}} types of moving averages, such as an exponential <b>moving</b> <b>average,</b> a <b>weighted</b> <b>moving</b> <b>average</b> or an adaptive moving average.|$|R
40|$|Abstract. When the {{production}} run {{is short and}} process parameters change frequently, {{it is difficult to}} monitor the process using traditional control charts. In such a case, the coefficient of variation (CV) is very useful for monitoring the process variability. The CV control chart, however, is not sensitive at small shifts in the magnitude of CV. This study suggest the CV-GWMA(generally <b>weighted</b> <b>moving</b> <b>average)</b> control chart, combining the GWMA technique, which shows better performance than the EWMA(exponentially <b>weighted</b> <b>moving</b> <b>average)</b> or DEWMA(double exponentially <b>weighted</b> <b>moving</b> <b>average)</b> technique in detecting small shifts of the process. Through a performance evaluation, the proposed control chart showed more excellent performance than the existing CV-EWMA control chart or the CV-DEWMA control chart in detecting small shifts in CV...|$|R
40|$|Investments {{in foreign}} {{exchange}} (forex) promise lucrative profits, thus inviting {{a lot of}} attention for researcher sand traders to create a system or indicator in trading. All indicators or system is reliable and has proven hat can bring profit for traders. Basically all indicator are reliable and tested which able to bring some profit to traders. Ironically there are many trader fail to gain the profit and became bankrupt. It because they has no well money management and good mentality in trading. Therefore in this study is focused on technical analysis by using <b>weighted</b> <b>moving</b> <b>average</b> which will be implemented on the mobile device so that it can give predictions on the price of the EURO-USD currency pair. The results is the <b>weighted</b> <b>moving</b> <b>average</b> was not quite accurate in determining the price of a currency especially during sideways price but it so accurate when they have strong price trend or large-scale. <b>weighted</b> <b>moving</b> <b>average</b> becomes really easy to apply when using 2 or more <b>weighted</b> <b>moving</b> <b>average</b> and able to give facility in analyzing movement of currency with the counterpart of EURO-USD by means of mobile medium...|$|R
40|$|Article is {{forecasting}} {{comparative analysis}} of number of guess room occupancy at Karlita International Hotel, Tegal, Central Java using 11 forecasting methods: linear regression, <b>moving</b> <b>average,</b> <b>weighted</b> <b>moving</b> <b>average,</b> exponential smoothing, exponential smoothing with trend, naïve method, trend analysis, additive decomposition – CMA, additive decomposition – average all, multiplicative decomposition – CMA, multiplicative decomposition – average All. Article used 17 data from January 2012 to Mei 2013, and results after using those 11 methods were the smallest MAD is 101. 69 and the smallest MSE is 15, 163. 95. From additive decomposition – average all method, data showed guess room occupancy forecast at Karlita International Hotel for June 2013 is 960 guess...|$|R
50|$|The {{average in}} the graph below is a {{smoothed}} 14-day <b>weighted</b> <b>moving</b> <b>average,</b> using only the most recent poll conducted by any given pollster within that range.|$|R
5000|$|A {{slightly}} more intricate method for smoothing a raw time series {xt} is to calculate a <b>weighted</b> <b>moving</b> <b>average</b> by first choosing {{a set of}} weighting factors ...|$|R
5000|$|The {{average in}} the graph below is a {{smoothed}} 14-day <b>weighted</b> <b>moving</b> <b>average,</b> using only the most recent poll conducted by any given pollster within that range.|$|R
40|$|A multivariate {{synthetic}} exponentially <b>weighted</b> <b>moving</b> <b>average</b> (MSEWMA) {{control chart}} {{is presented in}} this study. The MSEWMA control chart consists of a multivariate exponentially <b>weighted</b> <b>moving</b> <b>average</b> (MEWMA) control chart and a conforming run length control chart. The average run length of the MSEWMA control chart is obtained using a Markov chain approach. From the numerical comparisons, it is shown that the MSEWMA control chart is more efficient than the multivariate synthetic T 2 control chart and the MEWMA control chart for detecting shifts in the process mean vector...|$|R
40|$|Control charts {{are used}} to monitor process {{characteristics}} and to detect changes in process levels. In many situations the deterioration of a process results in process levels that drift monotonically over time. In this paper we use two well-known order-restricted tests to construct new control charts. Simulations {{are used to}} compare the new control charts to the exponentially <b>weighted</b> <b>moving</b> <b>average</b> chart. The comparisons show that the performance of the new control charts {{is similar to that of}} the EWMA chart. Average run length Control charts Exponentially <b>weighted</b> <b>moving</b> <b>average</b> Order-restricted tests...|$|R
40|$|This paper {{proposes a}} hybrid multivariate {{exponentially}} <b>weighted</b> <b>moving</b> <b>average</b> (EWMA) estimator of the variance-covariance matrix of returns. The proposed estimator employs a range-based EWMA specification {{to estimate the}} conditional variances of returns, and a standard return-based EWMA specification to estimate the correlation between each pair of returns. The hybrid EWMA estimator offers an improvement over the standard EWMA estimator, both statistically and economically. Moreover, the hybrid EWMA estimator is less sensitive to the choice of decay factor. Conditional variance-covariance matrix of returns Exponentially <b>weighted</b> <b>moving</b> <b>average</b> (EWMA) Intraday range...|$|R
40|$|An {{automatic}} {{surveillance system}} to detect {{changes in the}} incidences of microorganisms diagnosed {{in the department of}} clinical microbiology has been developed. The program is incorporated into the laboratory computer system and gives a weekly list of microorganisms whose isolation rates compared with those of a previous period exceed a chosen limit. The system uses time series analysis with <b>moving</b> <b>weighted</b> <b>averages,</b> and the detection limit is based on the distribution of the residuals. Output from the system included information about potential outbreaks of gastroenteritis, nosocomial infection with Corynebacterium jeikeium, and a seasonal epidemic of respiratory syncytial virus. The system also listed organisms not commonly isolated in the laboratory and detected incorrect reports. We conclude that continuous surveillance of laboratory data with time series analysis is a valuable tool for epidemiologic surveillance and quality control. Large quantities of data may be screened...|$|R
40|$|This study {{extends the}} {{generally}} <b>weighted</b> <b>moving</b> <b>average</b> (GWMA) control chart by imitating the double exponentially <b>weighted</b> <b>moving</b> <b>average</b> (DEWMA) technique. The proposed chart {{is called the}} double generally <b>weighted</b> <b>moving</b> <b>average</b> (DGWMA) control chart. Simulation is employed to evaluate the average run length characteristics of the GWMA, DEWMA and DGWMA control charts. An extensive comparison of these control charts reveals that the DGWMA control chart with time-varying control limits is more sensitive than the GWMA and the DEWMA control charts for detecting medium shifts in the mean of a process when the shifts are between 0. 5 and 1. 5 standard deviations. Additionally, the GWMA control chart performs better when the mean shifts are below the 0. 5 standard deviation, and the DEWMA control performs better when the mean shifts are above the 1. 5 standard deviation. The design of the DGWMA control chart is also discussed. GWMA control chart, DGWMA control chart, DEWMA control chart, average run length, time-varying control limits,...|$|R
50|$|Although {{designed}} for monthly use, a daily calculation {{over the same}} period can be made, converting the periods to 294-day and 231-day rate of changes, and a 210-day <b>weighted</b> <b>moving</b> <b>average.</b>|$|R
3000|$|... {{and apply}} the EWMA (exponentially <b>weighted</b> <b>moving</b> <b>average)</b> with α[*]=[*] 0.075 as a LP-Filter to prevent the abrupt burst of the measurement. Though {{it is enough to}} predict the length of [...]...|$|R
50|$|Digital {{elevation}} models, triangulated irregular networks, edge-finding algorithms, Thiessen polygons, Fourier analysis, (<b>weighted)</b> <b>moving</b> <b>averages,</b> inverse distance weighting, kriging, spline, and trend {{surface analysis}} are all mathematical methods to produce interpolative data.|$|R
40|$|New {{methods to}} {{forecast}} volatility are usually compared to simple methods like <b>weighted</b> <b>moving</b> <b>averages</b> or GARCH (1, 1) models. In this paper, we provide new benchmark methods {{which are more}} accurate but still very simple. In an empirical study of daily returns on major world indices, our new methods clearly outperformed the conventional methods. The superiority of our methods appears to be quite universal as it {{is not confined to}} certain markets or certain time periods. GARCH models, weighted medians, exponentially <b>weighted</b> <b>moving</b> <b>averages,</b> EWMA, averaging across windows, squared forecasting errors, absolute forecasting errors, volatility forecasting,...|$|R
40|$|This paper {{examines}} {{the accuracy of}} forecasts produced by mechanical forecasting techniques and three groups of analysts. The nine mechanical forecasting techniques are variations of exponentially <b>weighted</b> <b>moving</b> <b>averages,</b> naive models, simple moving averages, and regressions. One-, two- and three-year forecasts are used to evaluate these techniques. The mechanical techniques exhibit statistically significant differences {{in their ability to}} forecast earnings per share, with the exponentially <b>weighted</b> <b>moving</b> <b>averages</b> producing the best forecasts. One-year forecasts produced by the best of the mechanical forecasting techniques were compared to the corresponding analysts' projections. No statistically significant difference could be discerned. ...|$|R
40|$|This paper {{deals with}} {{effective}} forecasting methods for typically lumpy demand for aircraft spare parts, and analyzes {{the behavior of}} forecasting techniques when dealing with lumpy demand. Twenty forecasting techniques are considered and tested and historical data from Alitalia are used to analyze and compare their performance. The results demonstrate that item lumpiness is the dominant parameter and show that demand forecasting for lumpy items is a complex problem; results from previous studies are not very accurate. The best approaches {{are found to be}} <b>weighted</b> <b>moving</b> <b>averages,</b> the Croston method, and exponentially <b>weighted</b> <b>moving</b> <b>average</b> models...|$|R
40|$|This study applies equally <b>weighted</b> <b>moving</b> <b>average</b> (SMA), {{exponential}} <b>weighted</b> <b>moving</b> <b>average</b> (EWMA), Bias-Corrected EWMA and quantile regression {{approach to}} improve Bias-Corrected EWMA model to estimate portfolio downside risk. Using historical daily return data of twelve stock prices and four international portfolios, we test {{the performance of}} this modified approach {{to see if it}} can improve the precise forecasting capability of downside risk. The empirical results, derived from the Kupiec (1995) tests, show that the proposed method indeed offers substantial improvements on capturing dynamic return distributions. Moreover, the proposed quantile regression approach proves superior to ES prediction models relative to the other methods...|$|R
3000|$|... {{expresses the}} <b>weighted</b> <b>moving</b> <b>average</b> {{prediction}} where X̂_n + 1 ^k denotes the predicted {{value for the}} n+ 1 -th step based on past L historical data of the k-th channel; α [...]...|$|R
