15|3363|Public
25|$|Perhaps {{the first}} major change was the advent of music {{sequencer}} technology. Prior to its introduction all synchronisation was achieved by adding SMPTE time code to analogue tape. This acted as a reference point so that individual tracks could be easily synchronised. With the advent of MIDI hardware, devices {{could be used to}} synchronise any MIDI device and eventually <b>MIDI</b> <b>Time</b> <b>Code</b> or MTC became an alternative method of synchronising studio activity. Continuing development in this area has led to computer-controlled sequencing.|$|E
5000|$|... syncable via <b>MIDI</b> <b>Time</b> <b>Code,</b> MIDI Clock, FSK24, SMPTE, 1/4 note click.|$|E
50|$|The network elects a System Timing Master (STM) {{which is}} the source of {{synchronization}} on for all devices. Timecode formats includes MaGIC timecode and <b>MIDI</b> <b>Time</b> <b>Code.</b>|$|E
30|$|The output H is then {{converted}} to a binary (note on/off) by applying a threshold to it. To evaluate H, the note on/off information of each original chorale is extracted from the MIDI file. This forms a ground truth for each chorale. In this process, the <b>MIDI</b> <b>time</b> is retimed to linearly map {{with the number of}} frames in H.|$|R
40|$|Abstract – IRIG <b>time</b> <b>codes</b> {{are used}} for time {{synchronization}} for industrial equipments as all types of IRIG <b>time</b> <b>codes</b> are accepted as international standard. IRIG-B {{is one of the}} available IRIG <b>time</b> <b>codes</b> which is widely accepted as time synchronization protocol. This paper highlights the brief description of various <b>time</b> <b>codes</b> of IRIG standard and mentions the methods used for generation of IRIG-B <b>time</b> <b>code</b> format...|$|R
40|$|A {{high quality}} <b>time</b> <b>code</b> and word clock {{synchronization}} {{is essential to}} prevent audio drop outs and flutters in sound studios. A bad adjustment of <b>time</b> <b>code</b> generators respectively word clock synchronizers requires extensive error checks in synchronization networks. For this reason, a new measurement method is presented which enables sound engineers to measure longitudinal <b>time</b> <b>code</b> jitter and to check <b>time</b> <b>code</b> / word clock synchronization. Annoying audible artifacts in sound studios {{can be traced back}} on measured <b>time</b> <b>code</b> jitter and on loss of synchronization of the used <b>time</b> <b>code</b> / word clock synchronizer. With this method a <b>time</b> <b>code</b> jitter measurement accuracy of +/- 20 microsecond can be achieved. Entnommen aus TEMA</a...|$|R
50|$|Digital Sky - An {{architectural}} {{feature on}} level 13 where computerised images are projected onto {{the ceiling of}} the mall. The lighting was originally designed and programmed by Jason Saunders of Photonic-Motion in Melbourne Australia, in sequence with video on a Wholehog 2 PC running <b>midi</b> <b>time</b> <b>code.</b>|$|E
50|$|The <b>MIDI</b> <b>time</b> <b>code</b> is 32 bits long, {{of which}} 24 are used, while 8 bits are unused and always zero. Because the {{full-time}} code messages {{requires that the}} most significant bits of each byte are zero (valid MIDI data bytes), there are really only 28 available bits and 4 spare bits.|$|E
50|$|<b>MIDI</b> <b>time</b> <b>code</b> (MTC) embeds {{the same}} timing {{information}} as standard SMPTE timecode {{as a series}} of small 'quarter-frame' MIDI messages. There is no provision for the user bits in the standard <b>MIDI</b> <b>time</b> <b>code</b> messages, and SysEx messages are used to carry this information instead. The quarter-frame messages are transmitted in a sequence of eight messages, thus a complete timecode value is specified every two frames. If the MIDI data stream is running close to capacity, the MTC data may arrive a little behind schedule which has the effect of introducing a small amount of jitter. In order to avoid this it is ideal to use a completely separate MIDI port for MTC data. Larger full-frame messages, which encapsulate a frame worth of timecode in a single message, are used to locate to a time while timecode is not running.|$|E
40|$|WO 2004105034 A UPAB: 20050124 NOVELTY - To {{synchronize}} {{sound and}} film, a detection unit (10) registers the <b>time</b> <b>codes</b> for each separate {{image in the}} film sequence. A <b>time</b> <b>code</b> generator (12) gives a sequence of synthesis <b>time</b> <b>codes</b> from a starting value, provided by a decoder (14) which processes the detected <b>time</b> <b>codes.</b> The detected and synthesis <b>time</b> <b>codes</b> are compared (16) to establish any phase deviations which require a manipulation (20) of the synthesis <b>time</b> <b>codes.</b> The synthesis <b>time</b> <b>codes</b> are fed to an audio processing unit (24), to allocate the sampled audio signal values to each image from detected synthesis <b>time</b> <b>codes,</b> under <b>time</b> control. USE - The technique is for the synchronization of sound with separate images in cinema and video films, using wave field synthesis. ADVANTAGE - The synchronized sound {{can be used with}} loudspeaker arrays comprising numbers of loudspeakers to give a variety of structured and synchronized sounds with the film...|$|R
50|$|In telecommunication, <b>time</b> <b>code</b> {{ambiguity}} is {{the shortest}} interval between successive repetitions of the same <b>time</b> <b>code</b> value.|$|R
5000|$|Visible <b>time</b> <b>code,</b> a.k.a. {{burnt-in}} timecode and BITC (pronounced [...] "bit-see") - {{the numbers}} are burnt into the video image so that humans can easily read the <b>time</b> <b>code.</b> Videotapes that are duplicated with these <b>time</b> <b>code</b> numbers [...] "burnt-in" [...] to the video are known as window dubs.|$|R
5000|$|ADAT {{machines}} {{could be}} controlled externally with the Alesis LRC (Little Remote Control), which could {{be attached to the}} ADAT with a 1/4" [...] tip/sleeve plug, and featured the transport controls and most commonly used functions. Alternatively the BRC (Big Remote Control) could be used, which included many more features which the stand-alone ADAT did not have, such as song naming, more locate points and <b>MIDI</b> <b>Time</b> <b>Code</b> synchronisation.|$|E
50|$|Perhaps {{the first}} major change was the advent of music {{sequencer}} technology. Prior to its introduction all synchronisation was achieved by adding SMPTE time code to analogue tape. This acted as a reference point so that individual tracks could be easily synchronised. With the advent of MIDI hardware, devices {{could be used to}} synchronise any MIDI device and eventually <b>MIDI</b> <b>Time</b> <b>Code</b> or MTC became an alternative method of synchronising studio activity. Continuing development in this area has led to computer-controlled sequencing.|$|E
50|$|A {{sequencer}} {{can drive}} a MIDI system with its internal clock, {{but when a}} system contains multiple sequencers, they must synchronize to a common clock. <b>MIDI</b> <b>Time</b> <b>Code</b> (MTC), developed by Digidesign, implements SysEx messages {{that have been developed}} specifically for timing purposes, and is able to translate to and from the SMPTE time code standard. MIDI Clock is based on tempo, but SMPTE time code is based on frames per second, and is independent of tempo. MTC, like SMPTE code, includes position information, and can adjust itself if a timing pulse is lost. MIDI interfaces such as Mark of the Unicorn's MIDI Timepiece can convert SMPTE code to MTC.|$|E
50|$|Because {{a single}} <b>time</b> <b>code</b> {{is made up}} of 40 {{consecutive}} bits, read errors can cause a timecode to be unreadable even if a single bit is misread. A bit that has become unreadable due to a scratch can make an entire 40 bit long <b>time</b> <b>code</b> permanently unreadable. Dust can have a similar effect on the <b>time</b> <b>code.</b> The <b>time</b> <b>code</b> implements very little error checking, an attribute strong {{in a number of other}} vinyl control systems.|$|R
50|$|However, {{sometimes}} editors will (confusingly) use {{the letter}} B to designate <b>time</b> <b>code</b> breaks {{on a video}} tape. If there is broken <b>time</b> <b>code</b> on a video tape, {{there will be two}} (or more) instances of a particular <b>time</b> <b>code</b> on the video tape. When re-capturing, it can be ambiguous as to which timecode is the right one. The letter B may indicate that the right <b>time</b> <b>code</b> is from the second set of timecode on the video tape.|$|R
50|$|When {{the phase}} {{modulation}} <b>time</b> <b>code</b> was added in late 2012, this station identification was eliminated; the <b>time</b> <b>code</b> itself serves as station identification.|$|R
50|$|Lightpipe was {{designed}} for use with the Alesis ADATs, and although extremely versatile, {{there are a few}} limitations. For straightforward digital audio transfer, the receiving device can synchronize to the lightpipe's embedded clock signal, achieving a 1:1 digital copy. For transport control, additional synchronization is needed between devices. (For example, using two ADAT machines {{at the same time to}} achieve 16-channel throughput would require better transport control; otherwise, the two ADAT machines would be very unlikely to play in sync.) Nine pin D connectors are used to transfer transport information. The Alesis ADAT HD24 also offers <b>MIDI</b> <b>Time</b> <b>Code</b> for synchronization with MIDI-enabled devices.|$|E
50|$|The Mark III system {{followed}} in 2000. The Mark III included {{a variety of}} underlying technical improvements to the record and playback system. An especially noteworthy improvement was its ability to play back performances at very low volume levels. Additional user features included recording and playback of synchronous audio tracks, playback of specially encoded CD-ROM disks from a built-in CD player, and the SmartKey system that provided a play-along feature in which the user is prompted to press silently wiggling keys. The Mark III also introduced support for video-sync recording and playback based on the generation and reception of <b>MIDI</b> <b>Time</b> <b>Code.</b> Another upgrade known as the DCD1 was available that could provide early Disklavier owners with a CD drive for reading Cd's like the Mk III.|$|E
5000|$|Channel Voice {{messages}} transmit real-time {{performance data}} over a single channel. Examples include [...] "note-on" [...] messages which contain a MIDI note number that specifies the note's pitch, a velocity value that indicates how forcefully the note was played, {{and the channel}} number; [...] "note-off" [...] messages that end a note; program change messages that change a device's patch; and control changes that allow adjustment of an instrument's parameters. Channel Mode messages include the Omni/mono/poly mode on and off messages, as well as messages to reset all controllers to their default state or to send [...] "note-off" [...] messages for all notes. System messages do not include channel numbers, and are received by every device in the MIDI chain. <b>MIDI</b> <b>time</b> <b>code</b> {{is an example of}} a System Common message. System Real-Time messages provide for synchronization, and include MIDI clock and Active Sensing.|$|E
50|$|The phase-modulated <b>time</b> <b>code</b> {{has been}} {{completely}} updated and {{is not related to}} the amplitude-modulated <b>time</b> <b>code.</b> The only connection is that it is also transmitted in 60-second frames, and the amplitude-modulated markers (when only 20% of the second is transmitted at full strength) are not used for essential <b>time</b> <b>code</b> information.|$|R
40|$|Abstract — {{the paper}} deals with {{development}} of <b>time</b> <b>code</b> generator and translator using microcontroller based user interface. TCG/T {{is used in}} order to provide time stamping and event synchronization in satellite stations. TCG (<b>Time</b> <b>Code</b> Generator) is a precision timing system that generates a GPS (Global positioning system) Synchronized serial <b>time</b> <b>code</b> with DS 1307 -RTC (Real time Clock) where the process takes place and gives a serial time output using the IRIG-A (Inter Range Instrumentation Group) <b>time</b> <b>code.</b> TCT (<b>Time</b> <b>Code</b> Translator) is capable of accepting the control signals from TCG and translate the serial time to parallel time using a CPLD (Complex Programmable Logic Device). TCG/T can be programmed to even translate and provide parallel <b>time</b> <b>code</b> to front end hardware for time stamping the satellite raw data ingested by real time data acquisition systems up to microsecond level...|$|R
50|$|As {{with most}} longwave <b>time</b> <b>code</b> stations, the JJY signal is amplitude-modulated to send one bit per second, {{transmitting}} a complete <b>time</b> <b>code</b> every minute.|$|R
5000|$|In 1992 (NeXT 3.0 release), the Music Kit was un-bundled {{from the}} NeXT {{software}} {{and was released}} as a copyrighted open source package to the Stanford Center for Computer Research in Music and Acoustics (CCRMA), where Julius O. Smith was a professor. Stanford University hired David A. Jaffe {{as a consultant to}} continue to develop the Music Kit. Among the additions at that time were support for the Airel QuintProcessor, a five-DSP board for the NeXTcube, support for audio directly via the DSP56001 serial port (which was brought out {{to the back of the}} NeXT cube), and support for NextSTEP and the use of DSP processing using the Turtle Beach DSP56001 card. A set of eight Motorola evaluation boards were combined into a chassis for the prototype [...] "Frankenstein" [...] platform, used by the Sondius program of the Stanford Office of Technology Licensing to develop physical models of musical instruments. In addition, Jaffe was hired by a third party to add <b>MIDI</b> <b>time</b> <b>code</b> support to the Music Kit. (The Sondius group was later spun off into an independent company, Staccato Systems, Inc., with funding from Yamaha and Stanford University. Staccato Systems, Inc. was acquired by Analog Devices in 2000.) ...|$|E
40|$|Multiple {{loudspeakers}} can be configured {{to create}} a three-dimensional virtual sound space that allows a sound to be placed at any point within the virtual sound space. The accurate placement {{of the position of}} a sound {{plays an important role in}} virtual-reality applications and allows composers to realise compositions that exploit sonic spatialization. Software that represents and controls sound placement within a virtual sound space typically uses expensive commercial or dedicated audio hardware to mix and route audio signals. This paper discusses the perception of sound spaces, the acoustical properties of spatial sound, and describes a Java-based virtual sound environment. A teaching laboratory equipped with multimedia workstations provides the required hardware. A single master workstation controls the mixing and routing of audio by controlling the loudspeakers on multiple slave workstations. The master machine controls the slave loudspeakers using the networking capabilities of Java. Synchronization between the workstations is achieved using <b>MIDI</b> <b>Time</b> <b>Code...</b>|$|E
50|$|WWVB transmits data at one bit per second, taking 60 {{seconds to}} send the current time of day and date within a century. There are two {{independent}} <b>time</b> <b>codes</b> used for this purpose: an amplitude-modulated <b>time</b> <b>code,</b> {{which has been in}} use with minor changes since 1962, and a phase-modulated <b>time</b> <b>code</b> added in late 2012.|$|R
5000|$|Between 31 and 39 seconds {{past the}} minute inclusive, the once-per-second tones {{are reduced to}} 10-millisecond [...] "ticks" [...] while a digital <b>time</b> <b>code</b> is transmitted. The digital <b>time</b> <b>code</b> is {{formatted}} so that a Bell 103-compatible 300-baud modem can decode it, and CHU {{is the only time}} signal station that uses this format for its <b>time</b> <b>code</b> transmissions.|$|R
40|$|A {{computer}} oriented <b>time</b> <b>code</b> {{designed for}} users with various time resolution requirements is presented. It is {{intended as a}} <b>time</b> <b>code</b> for spacecraft and ground applications where direct code compatibility with automatic data processing equipment is of primary consideration. The principal features of this <b>time</b> <b>code</b> are: byte oriented format, selectable resolution options (from seconds to nanoseconds); and long ambiguity period. The <b>time</b> <b>code</b> {{is compatible with the}} new data handling and management concepts such as the NASA End-to-End Data System and the Telemetry Data Packetization format...|$|R
50|$|A <b>time</b> <b>code</b> {{was added}} to WWVB on July 1, 1965. This made it {{possible}} for clocks to be designed that could receive the signal, decode it, and then automatically synchronize themselves. The <b>time</b> <b>code</b> format has changed only slightly since 1965; it sends a decimal <b>time</b> <b>code,</b> using four binary bits to send each digit in binary-coded decimal (BCD).|$|R
50|$|Although the {{transmitters}} {{are active}} 24 hours a day, each transmits the <b>time</b> <b>code</b> one hour per day. Beginning {{on the hour}} is 25 minutes of 25.0 kHz, including morse code station identification and <b>time</b> <b>code.</b> This is followed by 5-minute intervals of 25.1, 25.5, 23.0 and 20.5 kHz. No <b>time</b> <b>code</b> is sent during {{the last quarter of}} an hour.|$|R
50|$|For example, in a <b>time</b> <b>code</b> {{in which}} year-of-century (the '72' in 10/04/72) {{is the most}} slowly {{changing}} field, the <b>time</b> <b>code</b> ambiguity would be 100 years; it is ambiguous whether this value refers to a date in 1872, 1972 or some other century. For a digital clock in which hours and minutes up {{to a maximum of}} 11:59 are displayed, the <b>time</b> <b>code</b> ambiguity would be 12 hours.|$|R
50|$|Jam sync {{refers to}} the {{practice}} of applying a phase hit to a system to bring it in synchronization with another. The term originates from the use of this technique to replace defective <b>time</b> <b>code</b> on a video tape recording by replacing it with a new <b>time</b> <b>code</b> sequence, which may be an extension of a previous good <b>time</b> <b>code</b> sequence on an earlier part of the source material.|$|R
5000|$|The {{manufacturer}} ID of [...] {{indicates a}} real-time universal message, the channel of [...] indicates it {{is a global}} broadcast. The following ID of [...] identifies this is a <b>time</b> <b>code</b> type message, and the second [...] indicates it is a full-time code message. The 4 bytes of <b>time</b> <b>code</b> follow. Although <b>MIDI</b> is generally little-endian, the 4 <b>time</b> <b>code</b> bytes follow in big-endian order, followed by a [...] "end of exclusive" [...] byte.|$|R
5000|$|... #Subtitle level 2: <b>MIDI</b> Universal Real <b>Time</b> SysEx Message Format ...|$|R
40|$|International Telemetering Conference Proceedings / October 30 -November 02, 1989 / Town & Country Hotel & Convention Center, San Diego, CaliforniaComputer based data {{acquisition}} and signal processing systems have evolved from computers developed for more generic applications. As {{a result of}} less technical origins, current computer systems have Real Time Clocks (RTC’s) that are relatively inaccurate and {{which can not be}} automatically synchronized to external time standards. The imbedded bus level <b>time</b> <b>code</b> processor modules described in this article in conjunction with Universal Time Coordinate (UTC) standard time receivers and standard InterRange Instrumentation Group <b>time</b> <b>code</b> signals provide a substitute source of time data, a source that overcomes the limitations of conventional Real Time Clock devices. To illustrate system synchronization with the use of bus level <b>time</b> <b>code</b> processors, a hypothetical multi-location, multi-processor {{data acquisition}} system is described which uses: 1 > Global Positioning Satellite receivers to acquire UTC time, 2 > InterRange Instrumentation Group (IRIG) <b>time</b> <b>code</b> as the local time distribution technique, and 3 > bus level <b>time</b> <b>code</b> modules to extract time data from the IRIG <b>time</b> <b>code.</b> Each of these three elements (receivers, <b>time</b> <b>code</b> signal, bus level module) has various selection possibilities with an associated impact on system time accuracy. It is shown that, with selection care, 1 microsecond absolute time accuracy for each processor can be obtained and 1 millisecond accuracy is routinely available...|$|R
