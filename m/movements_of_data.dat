8|10000|Public
40|$|Wireless: {{technology}} that permits the active transfer of information involving emanation of energy between separated points without physical connection. (Wolfowitz 2004) Mobile digital communications connect movements {{of people to}} <b>movements</b> <b>of</b> <b>data.</b> Wi-Fi, a 'wireless technology ' in U. S. Assistant Secretary of Defence Wolfowitz's terms, connects people and data in a quite complicated cultural-technological mix. In certain contexts, it dispenses with the wires that connect computers and the Internet. But this mundane innovation in new media infrastructure seen in many domestic, commercial and organisational settings, {{can be interpreted as}} significant in different ways: [T]he real value of a satellite television broadcast, a WiFi connection to a laptop, or a mobile phone call from your car to your mother isn’t the absence of dangling wires. Mobility, portability, ubiquity, and affordability are all enhanced when signals pass through the air rather than through strands of copper or optical fiber. (Werbach 2003) This chapter argues that the values of 'mobility, portability, ubiquity and affordability ' involve a mutual contextualisation of movements and images of movement. Put more baldly, the plethora of figurations, practices, commodifications, pricing-models, gadgets and modifications associated with Wi-Fi can be seen as an image of movement as well as an infrastructure that re-positions people in 2 relation to <b>movements</b> <b>of</b> <b>data.</b> The analytical problem confronting evaluations of heavily-imagined mobile technologies is how to hold together images of movement and movement itself...|$|E
40|$|A {{programming}} notation {{is introduced}} {{that can be}} used for protecting secrecy and integrity of data in global computing applications. The approach is based on the explicit annotations of data and network nodes. Data are tagged with information about the allowed movements, network nodes are tagged with information about the nodes that can send data and spawn processes to them. The annotations are used to confine <b>movements</b> <b>of</b> <b>data</b> and processes. The approach is illustrated by applying it to three paradigmatic calculi for global computing, namely cKlaim (a calculus at the basis of cKlaim), (a distributed version of the [pi]-calculus) and Mobile Ambients Calculus. For all of these formalisms, it is shown that their semantics guarantees that computations proceed only while respecting confinement constraints. Namely, it is proven that, after successful static type checking, data can reside at and cross only authorised nodes. "Local" formulations of this property where only relevant subnets type check are also presented. Finally, the theory is tested by using it to model secure behaviours of a UNIX-like multiuser system...|$|E
40|$|Load {{balancing}} is {{a critical}} issue for the efficient operation of peer-to-peer networks. We give new protocols for several scenarios, whose provable performance guarantees are within a constant factor of optimal. First, we give an improved version of consistent hashing, a scheme used for item to node assignments in the Chord system. In its original form, it required every network node to operate O(log n) virtual nodes to achieve a balanced load, causing a corresponding increase in space and bandwidth usage. Our protocol eliminates the necessity of virtual nodes while maintaining a balanced load. Improving on related protocols, our scheme allows for the deletion of nodes and admits a simpler analysis, since the assignments do {{not depend on the}} history of the network. We then analyze a simple protocol for load sharing by <b>movements</b> <b>of</b> <b>data</b> from higher loaded to lower loaded nodes. This protocol can be extended to preserve the ordering of data items. As an application, we use the last protocol to give an efficient implementation of a distributed data structure for range searches on ordered data...|$|E
30|$|Scalable Workload-Driven Partitioning:In this partitioning, we {{analyze the}} {{transaction}} logs, and monitor the data access pattern, {{that is the}} <b>movement</b> <b>of</b> <b>data</b> periodically. The partitions are formed, based on this <b>movement</b> <b>of</b> <b>data.</b>|$|R
50|$|Flow: <b>Movement</b> <b>of</b> <b>data</b> or {{material}} in the process.|$|R
50|$|Supports {{automated}} storage tiering, {{known as}} Dynamic Tiering, to automate the <b>movement</b> <b>of</b> <b>data</b> between tiers to optimize performance.|$|R
40|$|International audienceReading {{and writing}} data {{efficiently}} from storage system {{is necessary for}} most scientific simulations to achieve good performance at scale. Many software solutions {{have been developed to}} decrease the I/O bottleneck. One well-known strategy, in the context of collective I/O operations, is the two-phase I/O scheme. This strategy consists of selecting a subset of processes to aggregate contiguous pieces of data before performing reads/writes. In this paper, we present TAPIOCA, an MPI-based library implementing an efficient topology-aware two-phase I/O algorithm. We show how TAPIOCA can take advantage of double-buffering and one-sided communication to reduce as much as possible the idle time during data aggregation. We also introduce our cost model leading to a topology-aware aggregator placement optimizing the <b>movements</b> <b>of</b> <b>data.</b> We validate our approach at large scale on two leadership-class supercomputers: Mira (IBM BG/Q) and Theta (Cray XC 40). We present the results obtained with TAPIOCA on a micro-benchmark and the I/O kernel of a large-scale simulation. On both architectures, we show a substantial improvement of I/O performance compared with the default MPI I/O implementation. On BG/Q+GPFS, for instance, our algorithm leads to a performance improvement by a factor of twelve while on the Cray XC 40 system associated with a Lustre filesystem, we achieve an improvement of four...|$|E
40|$|As geo-realistic {{rendering}} of land surfaces is becoming commonplace in {{geographical information systems}} (GIS), games and online Earth visualization platforms, {{a new type of}} k Nearest Neighbor (kNN) queries, “surface ” k Nearest Neighbor (skNN) queries, has emerged and been investigated recently, which extends the traditional kNN queries to a constrained third dimension (i. e., land surface). All existing techniques, however, assume a static environment, limiting their utility in emerging applications (e. g., Location-based Services) where objects move. In this paper, for the first time, we propose two exact methods that can continuously answer skNN queries in a highly dynamic environment which allows for arbitrary <b>movements</b> <b>of</b> <b>data</b> objects. The first method, inspired by the existing techniques in monitoring kNN in road networks [7] maintains an analogous counterpart of the Dijkstra Expansion Tree on land surface, called Surface Expansion Tree (SE-Tree). However, we show the concept of expansion tree for land surface does not work as SEtree suffers from intrinsic defects: it is fat and short, and hence does not improve the query efficiency. Therefore, we propose a superior approach that partitions SE-Tree into hierarchical chunks of pre-computed surface distances, called Angular Surface Index Tree (ASI-Tree). Unlike SE-tree, ASI-Tree is a well balanced thin and tall tree. With ASI-Tree, we can continuously monitor skNN queries efficiently with low CPU and I/O overheads by both speeding up the surface shortest path computations and localizing the searches. We experimentally verify the applicability and evaluate the efficiency of the proposed methods with both real world and synthetic data sets. ASI-Tree consistently and significantly outperforms SE-Tree in all cases. 1...|$|E
40|$|DNA {{sequence}} {{data are}} currently {{viewed as a}} ‘bedrock’ or ‘backbone’ of modern biological science. This article traces DNA sequence data produced by so-called ‘next generation sequencing’ (NGS) platforms as it moves into a biological data infrastructure called the Sequence Read Archive (SRA). Since 2007, the SRA has been the leading repository for NGS-produced nucleotide (DNA and RNA) sequences. The way sequence data move into the SRA, we suggest, is symptomatic of a decisive shift towards post-archival genomics. This term refers to the increasing importance of the logistics rather than the biology of sequence data. In the SRA, logistical concerns with the bulk movements of sequence data somewhat supplant the emphasis in previous genomic and biological databases on contextualising particular sequences and cross-linking between different forms of biological data. At the same time, post-archival logistics do not necessarily flatten genomic research into global genomic homogeneity. Rather, the SRA provides evidence of an increasingly polymorphous flow of sequence data deriving from an expansion and diversification of sequencing techniques and instruments. The patterns of movement of data {{in and around the}} SRA suggest that sequence data are proliferating in various overlapping and sometimes disparate forms. By mapping differences in content across the SRA, by tracking patterns of absence or ‘missingness’ in metadata, and by following how changes in file formats highlight uncertainties in the definitions of seemingly obvious DNA-related artefacts such as a sequencer ‘run’, we highlight the growing lability of nucleotide sequence data. The <b>movements</b> <b>of</b> <b>data</b> in the SRA attest to a decisive mutation in sequences from biological bedrock to an increasingly expandable material whose epistemic and technological value remains open to reinvention...|$|E
5000|$|The S/370-XA architecture, first {{available}} in early 1983 on the 3081 and 3083 processors, provided {{a number of}} major enhancements, including: expansion of the address space from 24-bits to 31-bits; facilitating <b>movement</b> <b>of</b> <b>data</b> between two address spaces; and a complete redesign of the I/O architecture. The cross-memory services capability which facilitated <b>movement</b> <b>of</b> <b>data</b> between address spaces was actually available just prior to S/370-XA architecture on the 3031, 3032 and 3033 processors.|$|R
40|$|Corporate and {{government}} organizations dependence on computers and networks for storage and <b>movement</b> <b>of</b> <b>data</b> raises significant security issues. Two <b>of</b> these are <b>movement</b> <b>of</b> <b>data</b> across security domains (cross-domain) and computer reuse. The cross-domain transfer problem {{must address the}} contents of the file space as well as the contents of slack and free space. Three options are presented and discussed. One is selected as most practical and more fully discussed. Since this option involves the use of forensics software [...] . Copyright SANS Institut...|$|R
50|$|The primary {{component}} of an IBM MQ installation is the Queue Manager. The queue manager handles storage, timing issues, triggering, {{and all other}} functions {{not directly related to}} actual <b>movement</b> <b>of</b> <b>data.</b>|$|R
40|$|This thesis {{examines}} {{the issue of}} political versus economic incentives to default, {{with regard to the}} present Greece debt crisis. It is hypothesized that when a country has strong political incentives to not default on its debt it will choose not to do so, despite such a course being advantageous according to economic rationale. To assess this issue, a sovereign default model is calibrated to match the economy of Greece. The model mimics the core movements of the data quite well, with exception of spreads and debt-to-output-ratio, and it predicts a default for Greece every 312. 5 years. The sensitivity analysis illuminates a high sensitivity to the assumption of a highly patient borrower, resulting in low spreads and a low debt-to-output ratio. Since the early thirties no Western European country has defaulted on its debt. It has been regarded as a rather remote phenomenon occurring in distant developing countries, or in socialist/post-socialist republics. 1 This track record has however been challenged {{in the aftermath of the}} financial crisis erupting in 2007, starting with socialisation of several banks in various countries. The most extreme example of a bank bailout had been in Iceland, which has been subject to speculations as to whether or not the country will default on at least parts of its debt. Iceland has been followed by a debt crisis in several EMU countries, most notably Greece, Spain and Portugal. The economic crisis, and potential implications for EMU countries, has spilled over from being a purely economic matter to also encompass a political crisis. Despite several bailouts from the other member countries and the IMF, the Greek crisis still lingers on. The need for a Greek haircut and political reforms within the EU, in order to avoid a Greek default, seems to become even more urgent by the day. 2 One might thus ask whether or not Greece should already have defaulted on her debt, instead of continuing to service it and implement austerity packages rendering social unrest. There must certainly be some important incentives that make a default an implausible outcome. That constitutes the basis for this thesis, to test whether or not Greece indeed should have defaulted and, if so, what other credible motives it had for not doing so could be. The nature of sovereign debt differs greatly from common commercial debt, as it is not enforceable. As pointed out by Obstfeldt and Rogoff (1996), a sovereign default is more related to a sovereign’s willingness rather than ability to service its debts. There might be several situations where a government might be able, but not willing, for many reasons, to service their debts. Consistent with the theory that it is a question of will rather than ability, one could argue that harsh political implications associated with a default might deter such actions. Such logic might particularly apply to the case of Greece, as it is a minor country in the EU/EMU. Whilst one cannot be explicitly certain about the nature of political consequences, the mere existence of a worst-case scenario could work as a strong incentive to avoid default. 3 However, one must first lay the foundation as to whether it is in the economic interest of the government to default. For this purpose the model presented in Arellano (2008) is calibrated to match the Greek business cycle, and used to assess whether or not it would have been beneficial for Greece to default on its debt. Assuming that the Greek sovereign places a high valuation of future consumption, the results indicate that the government exposed to these conditions would find it profitable to indeed default prior to Q 12011 only in 10 % of the cases. Under this assumption the model is adequately able to mimic the core <b>movements</b> <b>of</b> <b>data,</b> except for underestimating spreads and debt holdings. A sensitivity analysis reveals that the whether or not default would have been a more economically plausible route depends mostly on how future consumption is valued compared to present day consumption. The thesis is structured as follows: at first the earlier research on sovereign default incentives and the founding hypothesis is outlined. Thereafter the sovereign debt model of Arellano (2008) is described accompanied by a non-technical summary at the end. In addition this section includes the European integration theory that constitutes the basic political rationale. Potential issues with underlying theory and model application are scrutinized in section III, entitled Methodology. Subsequently the data movement, the empirical results from the simulations and the sensitivity analysis is shown. The thesis ends with some concluding remarks...|$|E
5000|$|... #Caption: The {{shadow table}} {{has the same}} {{structure}} as the original table, but different data. The red arrow shows the <b>movement</b> <b>of</b> <b>data</b> to the shadow table and the green, shows the opposite.|$|R
40|$|The {{protection}} of individuals regarding the processing <b>of</b> personal <b>data</b> and free <b>movement</b> <b>of</b> such <b>data</b> represents {{a growing concern}} of the States, {{but also of the}} EU bodies. At the level of EU Member States, the issue of protecting the individuals regarding the processing <b>of</b> personal <b>data</b> and free <b>movement</b> <b>of</b> such <b>data</b> poses no particular problems. Internationally and especially between the member states of the European Union, the existing regulatory framework no longer responds to theses needs such as: online activities, digital economy, internet banking, etc., being increasingly obvious the tendency of fragmentation <b>of</b> the <b>movement</b> <b>of</b> personal <b>data...</b>|$|R
50|$|In telecommunications, {{node-to-node}} {{data transfer}} is the <b>movement</b> <b>of</b> <b>data</b> from one node {{of a network}} to the next. In the OSI model it is handled by the lowest two layers, the data link layer and the physical layer.|$|R
30|$|Hence, in iiHadoop we {{implement}} a locality-aware task scheduler which schedules {{the map and}} reduce tasks on the nodes that hold all or most <b>of</b> their input <b>data.</b> This scheduling policy is efficient because it prevents the unnecessary <b>movement</b> <b>of</b> <b>data</b> and reduces the network communication overhead.|$|R
50|$|Check {{that the}} <b>movement</b> <b>of</b> {{inventory}} <b>data</b> among processing steps is correct.|$|R
5000|$|... {{provides}} fully synchronous <b>movement</b> <b>of</b> GPR <b>data</b> between CPU and slave logic ...|$|R
5000|$|In April 2016, WANdisco {{announced}} that IBM {{had signed a}} deal to OEM WANdisco Fusion. [...] The deal allows IBM to rebrand Fusion as [...] "IBM Big Replicate" [...] and {{plays an important role}} in IBMs Big Data and Cloud Computing strategy including <b>movement</b> <b>of</b> <b>data</b> between on-premises software and Cloud ...|$|R
40|$|In this paper, {{we discuss}} the {{development}} and piloting of a new methodology for illuminating the socio-material con- stitution <b>of</b> <b>data</b> objects and flows as data move between different sites <b>of</b> practice. The <b>data</b> journeys approach contributes {{to the development of}} critical, qualitative methodologies that can address the geographic and temporal scale of emerging knowledge infrastructures, and capture the ‘life of data’ from their initial generation through to re-use in different contexts. We discuss the theoretical development <b>of</b> the <b>data</b> journeys methodology and the application of the approach on a project examining meteorological data on their journey from initial production through to being re- used in climate science and financial markets. We then discuss three key conceptual findings from this project about: (1) the socio-material constitution <b>of</b> digital <b>data</b> objects, (2) ‘friction’ in the <b>movement</b> <b>of</b> <b>data</b> through space and time and (3) the mutability <b>of</b> digital <b>data</b> as a material property that contributes to driving the <b>movement</b> <b>of</b> <b>data</b> between different sites of practice...|$|R
40|$|Part 2 : Regular PapersInternational audienceInformation sharing {{is a vital}} {{element of}} a {{successful}} business. However, technological, organisational and human challenges obstruct the effective <b>movement</b> <b>of</b> <b>data.</b> In this paper, we analyse a collection of case studies from healthcare describing failing information systems developments. A set of 32 failing factors were extracted showing that data movement, either between systems, people or organisations, is a key indicator of IT failure. From this examination, we derived anti-patterns for data movement in which some key differences between the source and target location <b>of</b> the <b>movement</b> caused high costs to the developments. Finally, we propose data journey modelling as a lightweight technique that captures the <b>movement</b> <b>of</b> <b>data</b> through complex networks of people and systems, {{with the aim of}} improve go/no-go decision making for new IT developments, based on the anti-patterns we have identified...|$|R
50|$|In contrast, {{dataflow}} programming {{emphasizes the}} <b>movement</b> <b>of</b> <b>data</b> and models programs {{as a series}} of connections. Explicitly defined inputs and outputs connect operations, which function like black boxes. An operation runs as soon as all of its inputs become valid. Thus, dataflow languages are inherently parallel and can work well in large, decentralized systems.|$|R
30|$|As most of VLs, Pipeline Pilot uses idea {{of drawing}} boxes and {{connecting}} them by arrows (pipes). It allows simulations’ development in an interactive way and checking the syntax {{of a model}} on the fly. Pipeline Pilot implements the idea of dataflow programming, emphasizing the <b>movement</b> <b>of</b> <b>data</b> throw pipes. This approach allows users to automate parallelization effectively.|$|R
50|$|An {{expense and}} cost {{recovery}} system (ECRS) is a specialized subset of “Extract - Transform - Load” (ETL) {{functioning as a}} powerful and flexible set of applications, including programs, scripts and databases designed to improve the cash flow of businesses and organizations by automating the <b>movement</b> <b>of</b> <b>data</b> between cost recovery systems, electronic billing from vendors, and accounting systems.|$|R
40|$|Modern {{high speed}} networks, such as ATM, {{can provide the}} {{bandwidth}} and the QoS guarantees to demanding real-time multimedia applications. However, overall performance of a networked multimedia application will greatly depend on the in-host data movement. Analyzing the characteristics and requirements of those applications, we came to several conclusions about {{the operation of the}} multimedia devices' drivers. We applied these conclusions in the design and implementation of a device driver for a multimedia teleconferencing system, based on IBM RS/ 6000 servers, running the AIX 3. 2 operating system. Tracing the complete in-host data path, we found that though our device driver minimized the <b>movement</b> <b>of</b> <b>data</b> between the teleconferencing card and user main memory, the UDP/IP stack proved to be a cause of delay in the <b>movement</b> <b>of</b> <b>data</b> between user main memory and the network interface. (Also cross-referenced as UMIACS-TR- 96 - 18...|$|R
40|$|Most {{scientific}} data analysis computations consume voluminous data distributed across multiple geographic locations. Moving this data to computational resources {{is a standard}} practice in such data analyses. Several factors preclude this <b>movement</b> <b>of</b> <b>data</b> to computational resources; these factors include the sheer volume <b>of</b> the <b>data,</b> the availability <b>of</b> network bandwidth, and the policies governing the <b>movement</b> <b>of</b> <b>data</b> that {{have been put in}} place by the institutions and individuals that own the data in question. To cope with such a scenario, an increasingly appealing choice is to move computations to the data. This is made possible by the fact that increasingly powerful commodity machines make it reasonable to assume that powerful compute capabilities will be available in close network proximity to the data. In this paper, we present an architecture for distributed data analysis, which relies on the notion of moving computations to data. For an important class of scientific applications this approach is especially well-suited...|$|R
50|$|Health {{information}} exchanges (HIEs): multi-stakeholder entities that enable the <b>movement</b> <b>of</b> health-related <b>data</b> within state, regional or non-jurisdictional participant groups.|$|R
5000|$|Controls the <b>movement</b> <b>of</b> {{application}} <b>data</b> {{from one}} set of staging libraries to the next (known as Promote in SCLM) ...|$|R
5000|$|Directive 95/46/EC on the {{protection}} of individuals {{with regard to the}} processing <b>of</b> personal <b>data</b> and on the free <b>movement</b> <b>of</b> such <b>data.</b> EU Directive 1995.|$|R
50|$|Communication-Avoiding Algorithms {{minimize}} <b>movement</b> <b>of</b> <b>data</b> {{within a}} memory hierarchy for improving its running-time and energy consumption. These minimize {{the total of}} two costs (in terms of time and energy): arithmetic and communication. Communication, in this context refers to moving data, either between levels of memory or between multiple processors over a network. It is much more expensive than arithmetic.|$|R
40|$|New {{concepts}} of magnetic memory devices are exploiting the <b>movement</b> <b>of</b> <b>data</b> bits by current induced domain wall motion. This concept {{has been widely}} explored with rectangular nanowires (NWs) or stripes both theoretically and experimentally [1]. In the case of cylindrical NWs not much {{progress has been made}} on the experimental side, despite its promising advantages like the absence of Walker breakdown [2]...|$|R
40|$|This book is for {{executives}} and practitioners tasked with the <b>movement</b> <b>of</b> <b>data</b> from old systems {{to a new}} repository. It uses {{a series of steps}} guaranteed to get the reader from an empty new system to one that is working and backed by the user population. Using this proven methodology will vastly increase the chances of a successful migration...|$|R
40|$|OceanStore is {{a utility}} {{infrastructure}} designedto span {{the globe and}} provide continuous access to persistent information. Since this infrastructure is comprised <b>of</b> untrusted servers, <b>data</b> is protected through redundancy and cryptographic techniques. To improve performance, data is allowedtobe cached anywhere, anytime. Finally, monitoring of usage patterns allows adaptation to regional outages and denial of service attacks; monitoring also enhances performancethrough pro-active <b>movement</b> <b>of</b> <b>data.</b> A prototype implementation is currently under development...|$|R
30|$|The {{transfer}} <b>of</b> <b>data</b> {{is managed}} as per the tier migration model, i.e. the Host (OS) initiates {{a process to}} transfer the I/O requests belonging to non-bulky or SSD favorable staging queues via the network through peer-to-peer data transfer protocol to the Host (OS)-of targeted SSD. Storage virtualization provides additional features for <b>movement</b> <b>of</b> <b>data</b> between tiers and machines via efficient inter-connect technologies such as RDMA (Remote Direct Memory Access), Infiniband, RCoE (RDMA over converged Ethernet), etc. [35].|$|R
5000|$|The Electronic Privacy Directive {{has been}} drafted {{specifically}} {{to address the}} requirements of new digital technologies and ease the advance of electronic communications services. The Directive complements the Data Protection Directive and applies to all matters which are not specifically covered by that Directive. In particular, {{the subject of the}} Directive is the “right to privacy in the electronic communication sector” and free <b>movement</b> <b>of</b> <b>data,</b> communication equipment and services.|$|R
