5262|468|Public
25|$|Sub-domains of {{computer}} vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, <b>motion</b> <b>estimation,</b> and image restoration.|$|E
25|$|What {{distinguished}} {{computer vision}} from the prevalent field of {{digital image processing}} {{at that time was}} a desire to extract three-dimensional structure from images with the goal of achieving full scene understanding. Studies in the 1970s formed the early foundations for many of the computer vision algorithms that exist today, including extraction of edges from images, labeling of lines, non-polyhedral and polyhedral modeling, representation of objects as interconnections of smaller structures, optical flow, and <b>motion</b> <b>estimation.</b>|$|E
2500|$|Several tasks {{relate to}} <b>motion</b> <b>estimation</b> where an image {{sequence}} is processed {{to produce an}} estimate of the velocity either at each points in the image or in the 3D scene, or even of the camera that produces the images [...] Examples of such tasks are: ...|$|E
40|$|Controlled dynamic processes. their <b>motions</b> and <b>estimation</b> of <b>motions</b> are {{investigated}} {{in the paper}} aiming at the widening of a stabilizing management class and a class of stabilized dynamic processes. The obtaining of <b>motion</b> <b>estimations</b> is also {{the aim of the}} paper. As a result the stabilizability crierion for an autonomous controlled dynamic process has been obtained. <b>Motion</b> <b>estimations</b> for bilinear, composite, exponential stabilized dynamic processes have been obtained. An algorithm for the time estimation of the stabilization of a non-linear dynamic process has been suggested. Stabilizing managements for bilinear and composite dynamic processes have been constructed. All results are the new results and make it possible to use computers for the obtaining of quantitative estimations of dynamic non-linear controlled processes. The paper results may find their field of application in mechanics of controlled motion, dynamics of a movable composition of railway transportAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|This paper {{proposes a}} novel <b>motion</b> field <b>estimation</b> method {{based on a}} 3 D light {{detection}} and ranging (LiDAR) sensor for motion sensing for intelligent driverless vehicles and active collision avoidance systems. Unlike multiple target tracking methods, which estimate the motion state of detected targets, such as cars and pedestrians, <b>motion</b> field <b>estimation</b> regards the whole scene as a motion field in which each little element has its own motion state. Compared to multiple target tracking, segmentation errors and data association errors have much less significance in <b>motion</b> field <b>estimation,</b> making it more accurate and robust. This paper presents an intact 3 D LiDAR-based <b>motion</b> field <b>estimation</b> method, including pre-processing, a theoretical framework for the <b>motion</b> field <b>estimation</b> problem and practical solutions. The 3 D LiDAR measurements are first projected to small-scale polar grids, and then, after data association and Kalman filtering, the motion state of every moving grid is estimated. To reduce computing time, a fast data association algorithm is proposed. Furthermore, considering the spatial correlation of motion among neighboring grids, a novel spatial-smoothing algorithm is also presented to optimize the motion field. The experimental results using several data sets captured in different cities indicate that the proposed <b>motion</b> field <b>estimation</b> is able to run in real-time and performs robustly and effectively...|$|R
40|$|In this paper, {{we develop}} a new {{algorithm}} for <b>motion</b> parame-ter <b>estimation</b> of moving targets in a multistatic passive radar. Existing methods for <b>motion</b> parameter <b>estimation</b> rely on the estimated Doppler signatures of the observed signals corre-sponding to each transmitter. These techniques may fail for weak signals where the individual Doppler signature cannot be properly estimated. The focus {{of this paper is}} on <b>motion</b> parameter <b>estimation</b> from weak signals observed using mul-tiple illuminators. Utilizing the sparsity of the motion param-eters, the proposed technique obtains robust motion parame-ter estimates through the fusion of the data corresponding to all available illuminators, achieving signal enhancement and multistatic diversity. To reduce the computational cost, the acceleration and velocity parameters are decoupled and se-quentially estimated. Index Terms — multistatic passive radar, target tracking, <b>motion</b> parameter <b>estimation,</b> compressive sensing 1...|$|R
50|$|<b>Motion</b> <b>estimation</b> based video {{compression}} helps in saving bits by sending encoded difference images which have inherently less entropy {{as opposed to}} sending a fully coded frame. However the most computationally expensive and resource extensive operation in the entire compression process is <b>motion</b> <b>estimation.</b> Hence, fast and computationally inexpensive algorithms for <b>motion</b> <b>estimation</b> {{is a need for}} {{video compression}}.|$|E
5000|$|... and in {{particular}} {{regarding the use of}} quarter pixel-precision <b>motion</b> <b>estimation.</b> Adding the extra precision to the motion of a block during <b>motion</b> <b>estimation</b> might increase quality, but in some cases that extra quality isn't worth the extra bits necessary to encode the motion vector to a higher precision.|$|E
5000|$|... #Subtitle level 4: Watson-Ahumada {{model for}} <b>motion</b> <b>estimation</b> in humans ...|$|E
50|$|The SVP-UX and SVP-WX {{integrated}} Trident's first-generation <b>motion</b> compensation/motion <b>estimation</b> technology.|$|R
40|$|SAR {{coherence}} can {{be exploited}} for applications of repeated surveys like digital elevation map generation, improvement of ground range resolution, measurement of small {{changes of the}} terrain. Results of the Bonn experiment are presented. The main goal of the experiment was the validation of differential interferometry technique for small terrain <b>motions</b> <b>estimation.</b> However, many other interesting results, {{a few of them}} not yet interpreted, have been obtained...|$|R
40|$|Abstract — Method for object <b>motion</b> {{characteristic}} <b>estimation</b> {{based on}} wavelet Multi-Resolution Analysis: MRA is proposed. With moving pictures, the motion characteristics, direction of translation, roll/pitch/yaw rotations {{can be estimated}} by MRA with an appropriate support length of the base function of wavelet. Through simulation study, method for determination of the appropriate support length of Daubechies base function is clarified. Also {{it is found that}} the proposed method for object <b>motion</b> characteristics <b>estimation</b> is validated...|$|R
5000|$|Multi‑frame <b>motion</b> <b>estimation</b> (up to 16 {{reference}} frames or 32 reference fields) ...|$|E
50|$|Applying {{the motion}} vectors to an image to {{synthesize}} the transformation {{to the next}} image is called motion compensation. As a way of exploiting temporal redundancy, <b>motion</b> <b>estimation</b> and compensation are key parts of video compression. Almost all video coding standards use block-based <b>motion</b> <b>estimation</b> and compensation such as the MPEG series including the most recent HEVC.|$|E
50|$|Video {{encoding}} software {{products such}} as Xvid, 3ivx, and DivX Pro Codec, which are based upon the MPEG-4 specification, use <b>motion</b> <b>estimation</b> algorithms to significantly improve video compression. The default level of resolution for <b>motion</b> <b>estimation</b> for most MPEG-4 ASP implementations is half a pixel, although quarter pixel is specified under the standard. H.264 decoders always support quarter-pixel motion. Quarter-pixel resolution can {{improve the quality of}} the video prediction signal as compared to half-pixel resolution, although the improvement may not always be enough to offset the increased bit cost of the quarter-pixel-precision motion vector; additional techniques such as rate-distortion optimization, which takes both quality and bit cost into account, are used to significantly improve the effectiveness of quarter-pel <b>motion</b> <b>estimation.</b>|$|E
40|$|GPU（Graphic Processing Unit）是一种市场上很容易获得的低成本、高性能处理器，拥有高度并行性和可编程性的GPU已经广泛应用于各种通用计算领域。本论文利用GPU来实现结构光三维视觉测量和电子稳像系统中的运动矢量估计。结构光三维视觉测量技术因其非接触、动态响应快、精度高等优点被广泛应用于各种表面检测领域。采用结构光视觉对其进行缺陷检测需要占用大量的计算资源，往往难以满足实时检测的要求。电子稳像技术是通过数字图像处理技术对序列图像进行运动估计，进而进行运动补偿来消除图像帧间的诸如抖动、旋转等非正常偏移的一种技术，其中的关键技术是全局运动矢量估计。在整个电子稳像系统中，运动矢量估计需要非常大的计算量，消耗大量的计算资源，几乎占用了整个电子稳像系统大部分的计算时间，因此提高运动矢量估计的计算效率成了提高电子稳像系统实时性的关键。本文首先对基于结构光视觉的钢轨表面缺陷检测作了深入研究，提出了一种结构光中心的快速提取算法——Steger算法的改进算法，并将该算法在GPU中实现。对于钢轨表面缺陷深度和宽度的计算，本文则提出了一种基于形态学的计算方法，并在静态情况下对钢轨表面缺陷检测进行实验，实验结果显示，GPU对于结构光中心的快速提取具有非常好的效果。同时，本文对于运动矢量估计算法进行研究，其中以块匹配算法及其改进算法作为重点研究对象，对于块匹配算法的一种改进算法——GEA算法（Global Elimination Algorithm），进行并行化处理，并利用GPU实现该算法。针对具有平移和小的旋转抖动的航拍视频进行实验，实验结果表明，GPU对于运动矢量估计具有非常好的加速效果，能够满足运动矢量估计的实时处理。GPU (Graphic Processing Unit) {{is a kind}} of {{low cost}} and high {{performance}} processor that is easy to get from market, and GPU with high parallelism and programmability has been widely used in all kinds of general-purpose computing field. In this paper, GPU is used to implement structured light 3 d vision measurement and <b>motion</b> vector <b>estimation.</b> Structured light 3 d vision measuring technique has been widely used in various surface defects detection field because of its advantages of non-contact, fast dynamic response and high precision. Defects inspection using structure light vision takes up a lot of computing resources, and {{it is often difficult to}} meet the requirement of real-time detection. Electronic image stabilization is a technology that uses the digital image processing technology to estimate the motion vectors on image sequences and then compensate them to remove the non-normal movement such as image jitter and rotation, and the key technology is the global <b>motion</b> vector <b>estimation.</b> Throughout the electronic image stabilization system, <b>motion</b> vector <b>estimation</b> requires a very large amount of calculation, consumes large amounts of computing resources, and almost occupies most of the computational time of the whole electronic image stabilization system. Thus improving the computing efficiency of <b>motion</b> vector <b>estimation</b> is the key to real-time electronic image stabilization system. Firstly, in this paper，an intensive study is made on rail surface defects detection based on structure light vision, a fast algorithm of structure light center extraction [...] the improved algorithm of Steger algorithm, is put forward and its parallel algorithm is realized in GPU. For the calculation of the depth and width of the rail surface defects, a calculation method based on morphology is put forward in this paper. Under the static condition, the experiment of rail surface defects detection is made, and the result shows that GPU has a very good effect in extracting structured light center. At the same time, this paper studies <b>motion</b> vector <b>estimation</b> algorithm, with block matching algorithm and its improved algorithm the key research object. As an improved algorithm, GEA algorithm (Global Elimination Algorithm) is paralleled processed and is implemented using GPU. Aerial video with translation and small jitter is used in the experiment, and the result shows that GPU has very good speedup for <b>motion</b> vector <b>estimation,</b> and can meet the real-time processing of <b>motion</b> vector <b>estimation...</b>|$|R
30|$|To {{find the}} {{displacement}} of objects within a scene captured by single camera, we use the <b>motion</b> vector <b>estimation</b> procedure of the H. 264 standard. Since H. 264 <b>motion</b> vector <b>estimation</b> is block-based (i.e., it measures {{the displacement of}} a block and not a point or object), we propose correction steps that reevaluate and refine the estimated motion vectors in order to calculate the motion vectors for the objects within the scene. Then the resulting object motion vectors are transformed to depth information. The following subsections elaborate on different steps of our proposed scheme.|$|R
40|$|International audienceMotion {{is one of}} {{the main}} {{characteristics}} that describe the semantic information of videos. In this work, a global video descriptor based on orientation tensors is proposed. This descriptor is obtained by combining polynomial coefficients calculated for each image in a video. The coefficients are found through the projection of the optical flow on Legendre polyno- mials, reducing the dimension of per frame <b>motion</b> <b>estimations.</b> The sequence of coefficients are then combined using orientation tensors. The global tensor descriptor created is evaluated by a classification of the KTH video database with a SVM classifier...|$|R
50|$|Moving objects {{within a}} frame are not {{sufficiently}} represented by global motion compensation.Thus, local <b>motion</b> <b>estimation</b> is also needed.|$|E
5000|$|The {{position}} of the scientist in <b>motion</b> <b>estimation</b> Haidamaks provoked a rebuke T. Shevchenko in his poem [...] "Cold Yar.|$|E
50|$|Sub-domains of {{computer}} vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, <b>motion</b> <b>estimation,</b> and image restoration.|$|E
40|$|This paper {{proposes a}} VLSI {{architecture}} for VGA 30 fps video segmentation with affine <b>motion</b> model <b>estimation.</b> The adopted algorithm is formulated as a contextual statistical labeling problem exploiting multiscale Markov random field (MRF) models. The algorithm optimization for VLSI implementation {{is characterized by}} image division method, ICM labeling limited to region boundary, and omission of <b>motion</b> models <b>estimation</b> for new regions. The optimization reduces the computational costs by 82 %, the amount of memory by 95 %, {{and the amount of}} data traffic by 99 % without accuracy degradation. The VLSI architecture is characterized by pipeline processing of the divided images, concurrent <b>motion</b> models <b>estimation</b> for multiple regions, and a common processing element of update and detection labeling. The architecture enables VGA 30 fps video segmentation with 167 MHz frequency. The estimated core area using 0. 18 μm technology is 30 mm 2. This processor is applicable to the video recognition applications such as vehicle safety, robot, and surveillance systems under the restriction of energy consumption...|$|R
30|$|After {{conducting}} an initial study of motion smoothing methods, {{it has been}} experimentally checked that the low-pass filter has a high performance as algorithm for <b>motion</b> intention <b>estimation,</b> eliminating undesired movements.|$|R
30|$|They {{corresponds}} to a phenomenon present in previous video stabilization techniques, but not still reported. Independently of which approach is used, video stabilization process depends on a phase of <b>motion</b> intention <b>estimation.</b> The phantom movements are generated during {{the elimination of the}} high-frequency movements due to the <b>motion</b> intention <b>estimation</b> which reduces the frequency of the movements and the previous motion intention estimators which are not able to detect or correct these troubles. Our proposal eliminates this phantom movements using a combination of a low-pass filter, as a motion intention estimator, with the control action. However, this method slightly decreases the ITF value.|$|R
50|$|Retroactively obtaining camera {{movement}} {{data from}} the captured footage is known as match moving or camera tracking. It {{is a form of}} <b>motion</b> <b>estimation.</b>|$|E
50|$|<b>Motion</b> <b>estimation</b> {{and video}} {{compression}} have {{developed as a}} major aspect of optical flow research. While the optical flow field is superficially similar to a dense motion field derived from the techniques of <b>motion</b> <b>estimation,</b> optical flow {{is the study of}} not only the determination of the optical flow field itself, but also of its use in estimating the three-dimensional nature and structure of the scene, as well as the 3D motion of objects and the observer relative to the scene, most of them using the Image Jacobian.|$|E
50|$|<b>Motion</b> <b>estimation</b> is {{the process}} of {{determining}} motion vectors that describe the transformation from one 2D image to another; usually from adjacent frames in a video sequence. The motion vectors may relate to the whole image (global <b>motion</b> <b>estimation)</b> or specific parts, such as rectangular blocks, arbitrary shaped patches or even per pixel. The motion vectors may be represented by a translational model or many other models that can approximate the motion of a real video camera, such as rotation and translation in all three dimensions and zoom.|$|E
40|$|The {{technique}} of <b>motion</b> vector <b>estimation</b> can remove the information of temporal redundancy {{to reduce the}} bit rate for video coding. Due to the great computation required in <b>motion</b> vector <b>estimation,</b> many simplified search algorithms have been proposed. In particular, one-bit transform scheme can significantly reduce the search complexity. This paper proposes a dynamic threshold scheme to form the binary images with respective to each macro-block images. Motion vectors are calculated {{through a series of}} Boolean operations, such as “XOR”, “AND”, and/or “OR”. The experimental results show that better improvement on the coding quality can be achieved. 1...|$|R
30|$|However, {{projection}} of real-world moving objects onto a 2 D imaging plane will not always result in pure translational objects motion. Rotation, zoom [5], and other nonrigid motions are also pervasive in videos. Researches on higher-order motion models such as affine [6, 7], bilinear [8], quadratic [9], perspective [10], and elastic [11] ones are conducted. These higher-order motion models aim to include nontranslational motions so that MCP prediction accuracy {{can be increased}} {{at the expense of}} additional motion vectors or parameters. However, these methods require <b>motion</b> parameter <b>estimations.</b> A commonly used method for <b>motion</b> parameter <b>estimation</b> is Gauss-Newton minimization algorithm in which motion parameters are iteratively updated until a minimum is found for the cost function [12]. <b>Motion</b> parameter <b>estimation</b> is in general of very high computational complexity. Moreover, subpixel reconstruction is required for these higher-order motion models because the transformed positions may not be a sampling point of the image. Interpolation is required to obtain the intensity values of these positions. This further increases the computational complexity. As a result, higher-order motion models are seldom used in practical coding applications.|$|R
40|$|In {{wideband}} radar systems, {{the performance}} of <b>motion</b> parameters <b>estimation</b> can significantly affect {{the performance of}} object detection {{and the quality of}} inverse synthetic aperture radar (ISAR) imaging. Although the traditional <b>motion</b> parameters <b>estimation</b> methods can reduce the range migration (RM) and Doppler frequency migration (DFM) effects in ISAR imaging, the computational complexity is high. In this paper, we propose a new fast non-parameter-searching method for <b>motion</b> parameters <b>estimation</b> based on the cross-correlation of adjacent echoes (CCAE) for wideband LFM signals. A cross-correlation operation is carried out for two adjacent echo signals, then the motion parameters can be calculated by estimating the frequency of the correlation result. The proposed CCAE method can be applied directly to the stretching system, which is commonly adopted in wideband radar systems. Simulation results demonstrate that the new method can achieve better estimation performances, with much lower computational cost, compared with existing methods. The experimental results on real radar datasets are also evaluated to verify the effectiveness and superiority of the proposed method compared to the state-of-the-art existing methods...|$|R
50|$|The sum of {{absolute}} differences {{may be used}} for a variety of purposes, such as object recognition, the generation of disparity maps for stereo images, and <b>motion</b> <b>estimation</b> for video compression.|$|E
50|$|An encoder {{will use}} various {{algorithms}} such as <b>motion</b> <b>estimation</b> {{to construct a}} frame that describes the differences. This allows a decoder to use the reference frame plus the differences to construct the desired frame.|$|E
5000|$|... #Caption: Motion vectors {{that result}} from a {{movement}} into the -plane of the image, combined with a lateral movement to the lower-right. This is a visualization of the <b>motion</b> <b>estimation</b> performed in order to compress an MPEG movie.|$|E
40|$|International audienceDense point {{matching}} {{and tracking}} in image sequences {{is an open}} issue with implications in several domains, from content analysis to video editing. We observe that for long term dense point matching, some regions of the image are better matched by concatenation of consecutive motion vectors, while for others a direct long term matching is preferred. We propose a method to optimally estimate the correspondence of a point w. r. t. a reference image from a set of input <b>motion</b> <b>estimations</b> over different temporal intervals. Results on texture insertion by point tracking {{in the context of}} video editing are presented and compared with a state-of-the-art approach...|$|R
40|$|This {{paper is}} devoted {{to the study of the}} problem of {{exponential}} asymptotic stability of the rotational motion of a gyrostat using servo-control moments which are applied to the internal rotors. The servo-control moments which impose the rotational motion are obtained. The stabilizing servo-control moments are obtained from the conditions to ensure exponential asymptotic stability of the desired <b>motion.</b> <b>Estimations</b> of the phase coordinations as exponential functions are presented. The method based on a choice of the structural form of the servo-control moments such that the equations of motion reduce to a system of differential equations with exponential asymptotic stability of an special solution...|$|R
40|$|Abstract—Traditional {{optical flow}} {{algorithms}} rely on consecutive short-exposed images. In this work, we {{make use of}} an additional long-exposed image for <b>motion</b> field <b>estimation.</b> Long-exposed images integrate motion information directly in form of motion-blur. With this additional information more robust and accurate motion fields can be estimated. In addition the moment of occlusion can be determined. Considering the basic signal-theoretical problem in <b>motion</b> field <b>estimation,</b> we exploit the fact that long-exposed images integrate motion information to prevent temporal aliasing. A suitable image formation model relates the long-exposed image to preceding and succeeding short-exposed images in terms of dense 2 D motion and per-pixel occlusion/disocclusion timings. Based on our image formation model, we describe a practical variational algorithm to estimate the motion field not only for visible image regions but also for regions getting occluded. Results for synthetic as well as real-world scenes demonstrate {{the validity of the}} approach. Index Terms—Motion field <b>estimation,</b> <b>motion</b> blur, optical flow, occlusion, computational video...|$|R
