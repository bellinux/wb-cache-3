4|10000|Public
5000|$|FAR 27.404(h) - Unauthorized <b>marking</b> <b>of</b> <b>data</b> - {{discusses}} the marking provisions of FAR clause 52.227-14 ...|$|E
40|$|In a company, one {{can take}} {{advantage}} of semantic technologies for online sales and advertising of products or services. Objects for semantic descriptions of business effects are already declared on the web and suffice for such purpose. On the other hand, describing specific characteristics of the business effects generally requires developing our own ontology. Afterwards, this ontology can be used by any application on the web for querying our semantically described cases. The first part describes the Semantic Web development. It starts with a vision of the web founder, Tim Berners-Lee, about web linked data, and continues to search a way to present web contents to computers in a simpler manner. This part also describes approaches to assigning the meaning to the data, and issues which arise in developing semantic technologies. Semantic Web works on the already existing web technologies, and changes the web into a database. Web ontologies, resource description framework and intelligent agents are presented as its complete unit. The final chapter begins with a description of the company and its website. It captures the benefits brought by the use of the semantics. Technological approaches to the semantic <b>marking</b> <b>of</b> <b>data</b> on the website address Microformats, RDFa and Microdata. We encounter the issue of semantics input via the CMS. Wines are the target groups of objects for semantic description. Their specific characteristics confirm choosing RDFa technology. Further research leads to the development of wine domain ontology and displays its potential use on the website...|$|E
40|$|Since 1975 {{bar codes}} on {{products}} at the retail counter {{have been accepted}} as the standard for entering product identity for price determination. Since {{the beginning of the}} 21 st century, the Data Matrix symbol has become accepted as the bar code format that is marked directly on a part, assembly or product that is durable enough to identify that item for its lifetime. NASA began the studies for direct part marking Data Matrix symbols on parts during the Return to Flight activities after the Challenger Accident. Over the 20 year period that has elapsed since Challenger, a mountain of studies, analyses and focused problem solutions developed by and for NASA have brought about world changing results. NASA Technical Standard 6002 and NASA Handbook 6003 for Direct Part Marking Data Matrix Symbols on Aerospace Parts have formed the basis for most other standards on part marking internationally. NASA and its commercial partners have developed numerous products and methods that addressed the difficulties of collecting part identification in aerospace operations. These products enabled the <b>marking</b> <b>of</b> <b>Data</b> Matrix symbols in virtually every situation and the reading of symbols at great distances, severe angles, under paint and in the dark without a light. Even unmarkable delicate parts now have a process to apply a chemical mixture called NanocodesTM that can be converted to a Data Matrix. The accompanying intellectual property is protected by 10 patents, several of which are licensed. Direct marking Data Matrix on NASA parts virtually eliminates data entry errors and the number of parts that go through their life cycle unmarked, two major threats to sound configuration management and flight safety. NASA is said to only have people and stuff with information connecting them. Data Matrix {{is one of the most}} significant improvements since Challenger to the safety and reliability of that connection. This presentation highlights the accomplishments of NASA in its efforts to develop technologies for automatic identification, its efforts to implement them and its vision on their role in space...|$|E
25|$|Some CPUs {{support a}} feature called NX ("No eXecute") or XD ("eXecute Disabled") bit, which in {{conjunction}} with software, {{can be used to}} <b>mark</b> pages <b>of</b> <b>data</b> (such as those containing the stack and the heap) as readable and writable but not executable.|$|R
40|$|NOVELTY - The method {{involves}} diverting {{the print}} data generated {{to carry out}} the printing process, which contains at least the document data and control data, within the data processing system to an operating system level that is inaccessible to the user via a marking component in which the marking process is conducted. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: an arrangement for automatic <b>marking</b> <b>of</b> printouts from <b>data</b> processing system and a data processing system. USE - For automatic <b>marking</b> <b>of</b> printouts from <b>data</b> processing system. ADVANTAGE - Enables very reliable automatic <b>marking</b> <b>of</b> all printouts, using which the user can locate printouts without great effort...|$|R
40|$|With the {{increasing}} use of internet for communication, the major concern of these days is, the security <b>of</b> <b>data</b> being communicated over it. Steganography is the art and science of invisible communication. It hides secret information in other information, thus hiding the existence of the communicated information. In this paper we have discussed a technique of hiding text messages in the images using image steganography. The technique uses matching <b>of</b> secret <b>data</b> with pixel values of cover image as base concept. The LSBs of matched pixels are changed to <b>mark</b> presence <b>of</b> <b>data</b> inside that pixel. For making selection <b>of</b> channels for <b>marking</b> presence <b>of</b> <b>data,</b> a pseudo random number generator is used, which adds another layer of security to the technique and makes the extraction <b>of</b> secret <b>data</b> very difficult for the intruders. The results show that technique provides more security against visual and statistical attacks and attempts to provide more data hiding capacity by using more bits per pixel...|$|R
40|$|Graduation date: 2004 Certain {{applications}} {{have recently}} appeared in industry where a traditional bar code printed on a label {{will not survive}} because the item to be tracked has {{to be exposed to}} harsh environments. Laser direct-part marking is a manufacturing process used to create permanent marks on a substrate that could help to alleviate this problem. In this research, a 532 nm laser was utilized to create a direct-part marked Data Matrix symbol onto carbon steel substrates with different carbon content. The quality of the laser marked Data Matrix symbol was then evaluated according to the criteria outlined in the ISO/IEC 16022 bar code technology specification for Data Matrix. Several experiments were conducted to explore the effects that different parameters have {{on the quality of the}} laser direct-part marked symbols. First, an experiment was conducted to investigate the effect of two different laser tool path patterns. In later experiments, parameters such as type of carbon steel, percent of laser tool path overlap, profile speed, average power and frequency were found to have significant effects on the quality of laser direct-part marked Data Matrix symbols. The analysis of the results indicated that contrast and print growth were the critical standard performance measures that limited laser direct-part marked Data Matrix symbols from achieving a higher final grade. No significant effects were found with respect to other standard performance measures (i. e., encode, axial uniformity, and unused error correction). Next, the experimental data collected for contrast and print growth was utilized as training, validation and testing data sets in the modeling of artificial neural networks for the laser direct-part marking process. Two performance measures (i. e., mean squared error and correlation coefficient) were employed to assess the performance of the artificial neural network models. Single-output artificial neural network models corresponding to a specific performance measure were found to have good learning and predicting capabilities. The single-output artificial neural network models were compared to equivalent multiple linear regression models for validation purposes. The prediction capability of the single-output artificial neural network models with respect to laser direct-part <b>marking</b> <b>of</b> <b>Data</b> Matrix symbols on carbon steel substrates was superior to that of the multiple linear regression models...|$|E
50|$|Credit Benchmark was {{established}} in 2012 by <b>Mark</b> Faulkner, founder <b>of</b> <b>Data</b> Explorers {{and the author of}} the Guide to Securities Lending Markets, and Donal Smith, formerly CEO <b>of</b> <b>Data</b> Explorers which sold to Markit in 2012.|$|R
5000|$|The first {{protection}} of floppy disks consisted {{of changing the}} address marks, bit slip marks, <b>data</b> <b>marks,</b> or end <b>of</b> <b>data</b> <b>marks</b> for each sector. For example, Apple’s standard sector markings were: ...|$|R
5000|$|The {{process which}} is {{handling}} mail messages runs with reduced privilegesunder a dedicated user ID. Optionally it can run chroot-ed.Risks of buffer overflows and memory allocation bugs is largelyavoided by implementing all protocol handling and mail processingin Perl, which handles dynamic memory management transparently.Care is taken that content of processed messages does not inadvertentlypropagate to the system. Perl provides an additional security safety netwith its <b>marking</b> <b>of</b> tainted <b>data</b> origination fromthe wild, and Amavis {{is careful to}} put this Perl feature to good useby avoiding automatic untainting <b>of</b> <b>data</b> (use re [...] "taint") and onlyuntainting it explicitly at strategic points, late in the data flow.|$|R
50|$|Dirty bits {{can also}} be used in Incremental {{computing}} by <b>marking</b> segments <b>of</b> <b>data</b> that need to be processed or have yet to be processed. This technique can be used with delayed computing to avoid unnecessary processing of objects or states that have not changed. When the model is updated (usually by multiple sources), only the segments that need to be reprocessed will be marked dirty. Afterwards, an algorithm will scan the model for dirty segments and process them, marking them as clean. This ensures the unchanged segments are not recalculated and saves processor time.|$|R
40|$|Abstract. In this paper, we {{describe}} the SomeWhere semantic peerto-peer data management system that promotes a ”small is beautiful” vision of the Semantic Web based on simple personalized ontologies (e. g., taxonomies of classes) but which are distributed at a large scale. In this vision of the Semantic Web, no user imposes to others his own ontology. Logical mappings between ontologies make possible {{the creation of a}} web of people in which personalized semantic <b>marking</b> up <b>of</b> <b>data</b> cohabits nicely with a collaborative exchange <b>of</b> <b>data.</b> In this view, the Web is a huge peer-to-peer data management system based on simple distributed ontologies and mappings. ...|$|R
30|$|Although {{events in}} the Himalayas have an {{influence}} far beyond the mountains, the region is data poor, {{and there is a}} <b>marked</b> lack <b>of</b> <b>data</b> and information especially for the high mountain areas (Eriksson et al. [2009]; Nepal [2012]). There are few detailed measurements of glacial ice, and the extremely poor accessibility and sparse population mean that the density of hydrometeorological stations of any sort is very low and far from being representative in a region characterized by high spatial variability of precipitation and temperature. This further compounds the problems of understanding the upstream-downstream linkages within the river basins.|$|R
40|$|In this paper, we {{describe}} the SomeWhere semantic peerto-peer data management system and report experiments showing that it already scales up to a thousand of peers. SomeWhere promotes a ”small is beautiful ” vision of the Semantic Web based on simple personalized ontologies (e. g., taxonomies of classes) but which are distributed at a large scale. In this vision of the Semantic Web, no user imposes to others his own ontology. Logical mappings between ontologies make possible {{the creation of a}} web of people in which personalized semantic <b>marking</b> up <b>of</b> <b>data</b> cohabits nicely with a collaborative exchange <b>of</b> <b>data.</b> In this view, the Web is a huge peer-to-peer data management system based on simple distributed ontologies and mappings...|$|R
30|$|Argos allows {{recording}} multiple car parameters (such as speed), driver variables (such as {{the point}} of gaze), and environmental parameters (some of which are obtained by means of real-time signal processing, such as the distance to lateral road <b>marks).</b> All <b>of</b> these <b>data</b> {{can be used to}} replay driving sessions in the laboratory and to extract data associated with different driving session segments.|$|R
40|$|AbstractIn {{this paper}} we present the {{application}} of a modified iterative Fourier transform algorithm in combination with a closed loop feedback control using a CCD camera in order to improve the diffraction efficiency and uniformity of two-dimensional intensity distributions generated using a spatial light modulator (SLM). The impact of these improvements is demonstrated for nanosecond laser <b>marking</b> <b>of</b> a two-dimensional <b>data</b> matrix on a thin metal film utilising the dynamic nature of the SLM...|$|R
40|$|In {{this paper}} it is {{noted that the}} way in which spatial {{information}} systems are used varies with the spatial level of the planning systems which use them. In West Germany very few systems with high spatial resolution are found at federal level, whereas at lower levels the areal coverage is smaller. Meanwhile the spheres of competence of planning, and the number of information systems, are growing. Specific obstacles to the development of spatial information systems involve the use of computers, problems of confidentiality, and problems <b>of</b> <b>data</b> exchange. In this paper the reasons for the <b>marked</b> lack <b>of</b> <b>data</b> with spatial detail in the fields of energy and ecology are discussed, and the relationships between missing data and bottlenecks in political action are pointed out. ...|$|R
40|$|This paper {{exemplifies the}} {{determinants}} of business success revealed by business owners, who started their businesses from abrasion and faced various impediments to achieve ultimate success in their respective fields. The key {{purpose of the study}} was to investigate the core factors that brought them to the <b>mark</b> <b>of</b> ultimate success. <b>Data</b> was collected through recorded interviews based on self-constructed questions. Throughout, the research was conducted on practical echelon. Each of the business personalities considered faith on all mighty GOD as the foremos...|$|R
30|$|The content {{addressable}} memory (CAM) is {{the core}} of the CAM FSM. At the beginning of the CAM FSM working, the CAM is initialized firstly. With two stage pipelines, the data formed by accumulating the byte which is received by the CAM FSM are used to match the special tags (64 bits) set in the traffic generator. Through the above matching, the matching <b>mark</b> <b>of</b> the <b>data</b> frame and its valid mark are recorded. For one thing, the total data frame transmission time can be achieved by clock cycles, which is used in Equation  6. For another thing, using the valid mark can help us to avoid invalid statistics about clock cycles when the tag in the data frames is missing.|$|R
40|$|Abstract—Database and {{database}} {{systems have}} been used widely in almost, all life activities. Sometimes missed data items are discovered as missed or null values in the database tables. The presented paper proposes a design for a supervised learning system to estimate missed values found in the university database. The values <b>of</b> estimated <b>data</b> items or data it items used in estimation are numeric and not computed. The system performs data classification based on Case-Based Reasoning (CBR) to estimate loosed <b>marks</b> <b>of</b> students. A <b>data</b> set is used in training the system {{under the supervision of}} an expert. After training the system to classify and estimate null values under expert supervision, it starts classification and estimation <b>of</b> null <b>data</b> by itself. Keywords—DataBase(DB);Data mining; Case-Based Reasoning (CBR); Classification;Null Values; Supervised Learning I...|$|R
40|$|Multiple {{researchers}} have proposed cyclic query plans for evaluating iterative queries over streams or rapidly changing input. The Declarative Networking community uses cyclic plans to evaluate Datalog programs that track reachability and other graph traversals on networks. Cyclic query plans can also evaluate pattern-matching and other queries based on event sequences. An issue with cyclic queries over dynamic inputs is knowing when the query result has progressed {{to a certain}} point in the input, since the number <b>of</b> iterations is <b>data</b> dependent. One option is a ―strictly staged ‖ computation, where the query plan quiesces between inputs. This option introduces significant latency, and may also ―underload ‖ inter-operator buffers. An alternative is to settle for soft guarantees, such as ―eventual consistency‖. Such imprecision can make it difficult, for example, to know when to purge state from stateful operators. We propose a third option in which cyclic queries run continuously, but detect progress ―on the fly ‖ by means of a Flying Fixed-Point (FFP) operator. FFP sits on the cyclic loop and circulates speculative predictions on forward progress, which it then validates. FFP is always able to track progress for a class of queries we term strongly convergent. A key advantage of FFP is that it works with existing algebra operators, thereby inheriting their capabilities, such as windowing and dealing with out-oforder input. Also, for stream systems that explicitly model inputevent lifetimes, we know exactly which values are in the query result at each point in time. A key implementation decision is the method for speculating. Using the high-water <b>mark</b> <b>of</b> <b>data</b> events minimizes the number of speculative punctuations. Probing operators on the cyclic loop to determine their external progress circulates many more speculative messages, but tracks actual output progress more closely. We show how a hybrid approach limits predictions while coming close the progress-tracking ability of Probing. 1...|$|R
40|$|The amount <b>of</b> <b>data</b> in the CMS inner tracker {{system at}} the LHC {{interaction}} rate is so large that it cannot be read out at each bunch crossing. A pipeline memory is then needed to store the data at the front [...] end level until a Level 1 Trigger accept signal marks the interesting data which will then be read out. Due to the random arrival of triggers with a maximum average rate of 100 kHz a queue may develop in the pipeline which in the end can become full and cause errors. Some triggers must then be vetoed. In the present version of the chip {{to be used in}} the Tracker read [...] out, the APV 6, the memory (storage, <b>marking</b> <b>of</b> interesting <b>data,</b> read [...] out and clearing) is governed by a very complex embedded logic: precise predictions concerning the inefficiency due to vetoing the triggers can be done only by means of computer simulation. This document is mainly intended to give an extensive description of the logic and to present the results obtained by running an updated version of the [...] ...|$|R
40|$|This {{study was}} {{designed}} to compare the variations in velocity, stride length, time of support, and time of non-support in the run. The subjects included 2 boys of normal intelligence, 2 EMR boys, and 2 TMR boys ranging in age from 126 months to 138 months. Subjects were filmed, through the use of cinematography, at 100 frames per second. The following frames were selected for analysis: foot-strike, mid-support (at the point when the tibias perpendicular to the foot), heel rise, and toe off. These frames were traced onto graph paper and joints were <b>marked.</b> Treatment <b>of</b> <b>data</b> comprised descriptive statistics, utilizing the AAPHER Youth Fitness norms for normal populations and retarded populations as a standard of comparison. Analysis <b>of</b> <b>data</b> produced a significant relationship between IQ and running velocity, stride length, and time of support. The lower the IQ the slower the average velocity of the run, The slower the average velocity the shorter the stride length and the greater the time of support. There seemed to be no significant correlation between IQ and time of non-support...|$|R
40|$|KEEP) <b>marks</b> {{a decade}} <b>of</b> <b>data</b> {{collection}} {{as a part}} of its multicenter screening program for volunteer participants at risk of chronic kidney disease (CKD). During the years, KEEP has yielded important inferences regarding CKD epidemiologic characteristics and risk factors, 1, 2 and related comorbid conditions, including hypertension, metabolic syndrome, diabetes, bone and mineral disorder, anemia, and heart disease, have been characterized and reported. 3 - 11 This supplement to the American Journal of Kidney Diseases highlights 4 articles: (1) a 10 th anniversary summary of KEEP milestones; (2) a comparison of CKD among elderly KEEP participants, th...|$|R
5000|$|The {{acceleration}} of the Mk. II can be gauged from the data on an information board at the Bristol Aeroplane Company Museum at Kemble Airfield, Kemble, Gloucestershire, where a complete Bloodhound can be seen. The <b>Mark</b> <b>of</b> Bloodhound this <b>data</b> refers to is not given but is presumably the Mark II since the top speed of the Mk. I is Mach 2.2:"By the time the missile has just cleared the launcher it is doing 400 mph. By the time the missile is 25 feet from the launcher it has reached {{the speed of sound}} (around 720 mph). Three seconds after launch, as the four boost rockets fall away, it has reached Mach 2.5 which is roughly 1,800 mph" ...|$|R
40|$|We {{will present}} {{the current state of}} ongoing work on a simple to use, quality result {{algorithm}} for visualization <b>of</b> <b>marked</b> cells <b>of</b> the model organism. In this work, we try to find a method based on volume rendering to visualize <b>marked</b> parts <b>of</b> input <b>data</b> composed by a set of confocal deconvolution microscope images {{in such a way that}} these marked parts can be higlighted and visualized. We have tried different techniques for dealing with the visualization speed and with the quality of the rendered images and propose best methods for realizing the work goals. In the last case, the quality of the rendered image is sufficient for imagination of position <b>of</b> the <b>marked</b> parts. We demonstrate results on different biological data sets, such as plant cells or model organism Caenorhabditis Elegans marked by GFP process...|$|R
40|$|Today, cabled {{seafloor}} observatories {{are installed}} at many {{sites around the}} globe, gathering different types of sensors in the marine environment where a Global Positioning System (GPS) signal is not accessible. Accurate time <b>marking</b> <b>of</b> ocean sensor <b>data</b> is highly important in many marine applications. This paper presents a smart GPS emulator based on the IEEE– 1588 Precision Time Protocol (PTP). The device was designed and implemented {{to be able to}} provide accurate timing data (trigger + time code) to any ocean sensor as a broadband seismometer. In this case, accurate location and magnitude of a detected earthquake are dependent on the accuracy <b>of</b> the <b>data</b> time <b>marks.</b> The performance <b>of</b> time synchronization is tested, using a commercial broadband seismometer, and the results are presented. These tests are based on a comparison of the synchronization trigger between master and slave clocks as well as the analysis <b>of</b> the <b>data</b> acquired by the seismometer. The work presented here leads to an improved performance of the ocean-bottom seismometers as well as tsunami warning systems. Peer ReviewedPostprint (published version...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThis thesis explores and identifies trends in officer separation within the Navy Explosive Ordnance Disposal (EOD) officer community. It blends analyses {{of a survey}} conducted on active duty EOD officers with interviews of former EOD officers to better understand why the community struggles to meet manning requirements at the eight-to ten-year <b>mark.</b> Analysis <b>of</b> the <b>data</b> indicates that family stability, leadership, military bureaucracy, and limited operational time each are factors in the community's retention problem. Of those, this thesis proposes that leadership focus on a factor it can influence— operational time. In particular, it proposes that longer tours and extending operational time for junior officers may mitigate officer separation. Lieutenant, United States Nav...|$|R
40|$|Abstract: The {{military}} {{organization is}} dependent on timely access to up-to-date, relevant and trustworthy information in order to conduct its business. Access to information {{is controlled by the}} user’s security clearance and the classification or protective <b>marking</b> <b>of</b> the <b>data.</b> Whilst it is necessary to preserve data confidentiality and integrity, controls have resulted in strict separation between different levels of security. This regime not only constrains the type and level of information sharing that can be achieved, more critically the speed at which access may be realized is impeded. The military is moving towards Network Enabled Capability (NEC) where the emphasis is on resource sharing within national contingents and on a coalition basis, facilitated by the Network. Future capability is predicated on the core attribute of agility. NEC is expected to enable the dynamic formation of communities of interest and the rapid reorganisation of resources as required by military commanders. This paper tests the assertion that the ability to express, verify and implement flexible security policy is essential to achieve the agility required. The assertion is tested through the practical application of a suitable security policy framework to a small but representative case study, the results of which will be of interest to system architects and decision makers alike. Keywords: NEC, Dynamic, Security, Policy. 1...|$|R
40|$|In {{the context}} of Differentiated Services (DiffServ), we {{investigate}} the effect <b>of</b> acknowledgment <b>marking</b> on the throughput of TCP connections. We carry out experiments on a testbed offering three classes of service (Premium, Assured and Best-Effort), and different levels of congestion on the data and acknowledgment path. We apply a full factorial statistical design and deduce that marking TCP data packets is not sufficient and that acknowledgment marking on the reverse path is a necessary condition to efficiently match targeted performance in DiffServ. We find that the optimal marking strategy depends {{on the level of}} congestion on the reverse path. In the practical case where Internet Service Providers cannot obtain such information in order to mark acknowledgment packets, we show that the strategy leading to optimal overall performance is to copy the <b>mark</b> <b>of</b> the respective <b>data</b> packet, provided that the affected service class is appropriately provisioned...|$|R
40|$|Cells {{in culture}} undergo replicative senescence. In this study, we {{analyzed}} functional, genetic and epigenetic sequels of long-term culture in human mesenchymal stem cells (MSC). Already within early passages the fibroblastoid colonyforming unit (CFU-f) frequency and the differentiation potential of MSC declined significantly. Relevant chromosomal aberrations were not detected by karyotyping and SNP-microarrays. Subsequently, we have compared DNA-methylation profiles with the Infinium HumanMethylation 27 Bead Array and the profiles differed markedly in MSC derived from adipose tissue and bone marrow. Notably, all MSC revealed highly consistent senescence-associated modifications at specific CpG sites. These DNA-methylation changes correlated with histone <b>marks</b> <b>of</b> previously published <b>data</b> sets, such as trimethylation of H 3 K 9, H 3 K 27 and EZH 2 targets. Taken together, culture expansion of MSC has profound functional implications - these are hardly reflected by genomic instability {{but they are}} associated with highly reproducible DNA-methylation changes which correlate with repressive histone marks. Therefore replicative senescence seems to be epigenetically controlled...|$|R
40|$|D URING {{the hundred}} years that mongolism has been {{recognized}} as a medical entity, many studies of the disease have been made. The epidemiology of this condition has re-ceived considerable attention and much empha-sis {{has been placed on}} the anthropometric, physical, and mental characteristics of the mongoloid. There is, however, a <b>marked</b> lack <b>of</b> <b>data</b> concerning the metabolism of mongo-bids and those which exist, for the most part, do not show mongoloids to be particularly abnormal in their metabolic patterns. The present study {{is the result of the}} corn-mon observations that as mongoloids age, their skins become rough, dry, and exzematous. Fissures of the lips and corners of the mouth are also frequently seen. These types of lesions are also found in individuals deficient in the B vi tamins. This study is an attempt to determine whether the metabolism of vitamins by mongol-oids is abnormal. METHODS The subjects used in these experiments were either mongoloids or mentally deficient pa-tients without other obviously abnormal char-acteristics. During these studies the subjects ate their usual diets in the dining rooms of the Wrentham State School. Iii the first two studies all food served was weighed and the nutrient intakes calculated from tables of foo...|$|R
40|$|The {{cardiovascular}} {{effects of}} nitrous oxide were studied in thirteen dogs. Nitrous oxide depressed the myocardial contractile {{force in the}} deg as measured with the Brodie-Walton gauge. Cardiac output, central venous pressure, arterial blood pressure, and heart rate were not significantly changed. Sympathetic nervous responses were neither inhibited nor continuously stimulated by this agent. The effect of nitrous oxide on {{the efficiency of the}} heart is discussed. Nitrous oxide was introduced as an anaesthetic agent over one hundred years ago. Despite its wide use, there is a <b>marked</b> paucity <b>of</b> <b>data</b> re-garding its effects on the cardiovascular system (Hamilton, 1963). This is especially true with regard to the effects of this agent on the intact, innervated cardiovascular system. This project was carried out to study the effects of nitrous oxide on myocardial function and haemodynamic parameters. Haemodynamic measurements in-cluded arterial blood pressure, central venous pressure and cardiac output. Measurements of myocardial function included maximum isometric systolic tension, rate of tension development with systole, rate of relaxation and heart rate. A Brodie-Walton strain gauge was used to measure isometric tension so that our data could be com-pared with those of others who have studied the effects of various anaesthetic agents using thi...|$|R
40|$|Food labels play an {{important}} role in well-being of consumers. As a part <b>of</b> it, date <b>marking</b> is a valid guide to shelf life of a food. The present study was done in 2010, in Smart Food Center, Wollongong; New South Wales, Australia to determine if the residents are familiar with date <b>marking</b> <b>of</b> food products. <b>Data</b> was accumulated by either interview guide or questionnaire method. Basic unselected samples of 200 shoppers were interviewed. Awareness of consumers about the method <b>of</b> date <b>marking</b> <b>of</b> food products, the frequency of purchasing spoiled or stale products, particularity about dates marked on food products before buying them, observation <b>of</b> the date <b>marked</b> on perishable and semi perishable food items, and satisfaction of consumers with the freshness and date <b>marking</b> <b>of</b> products were mainly studied. Out of 200 consumers who were interviewed, 112 (56 %) supported date marking services. 128 (64 %) consumers were well informed of the date making system. Most of the people in this group were between 35 to 44 years of age. 75 % of respondents were women. The range of family income was between AUS$ 30000 - 750000 per months. There was no association between degree of knowledge <b>of</b> date <b>marking</b> and sex and educational level of consumers who purchased spoiled food products. Among consumers who purchased spoiled food items, a significant number were informed <b>of</b> date <b>marking</b> systems and used it when making purchases. Date marking has been observed by both male and female and was not related to their academic degrees...|$|R
50|$|The high-water <b>mark</b> <b>of</b> cov-lite loans {{came in the}} 2007 {{acquisition}} by Kohlberg Kravis Roberts, a US {{private equity}} firm, {{by way of a}} record $16bn cov-lite loan for its buy-out <b>of</b> First <b>Data.</b>|$|R
40|$|Abstract: The {{conventional}} <b>marking</b> {{and identification}} <b>of</b> animals {{can be done}} in several different ways. With the application of modern informatics and electronics solutions, it is possible to substitute conventional ways with the different types <b>of</b> the electronic <b>marking</b> and identification. All types of electronic identification for transferring data are using the technology of the radio frequency (RFDI). With application <b>of</b> electronic <b>marking,</b> it is possible to achieve a great number of advantages of which the most important are the high precision <b>of</b> reading the <b>data,</b> individual supervision for every animal, automatic input <b>of</b> <b>data,</b> processing and keeping the information as a permanent actualization <b>of</b> <b>data</b> base. It is necessary to remove all existing defects and in future to work on the improvement of existing types <b>of</b> the electronic <b>marking</b> <b>of</b> animals...|$|R
