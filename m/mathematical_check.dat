3|59|Public
40|$|Abstract. This paper {{wishes to}} foster {{communication}} between mathematicians and physicists working in mirror symmetry and orbifold Gromov-Witten theory. We provide a reader friendly {{review of the}} physics computation in [ABK 06] that predicts Gromov-Witten invariants of [C 3 /Z 3] in arbitrary genus, and of the mathematical framework for expressing these invariants as Hodge integrals. Using geometric properties of the Hodge classes, we compute the unpointed invariants for g = 2, 3, thus providing the first high genus <b>mathematical</b> <b>check</b> of the physics predictions...|$|E
40|$|Accurate presurgical {{planning}} is imperative for successful cranial surgery. This article introduces a simulation program {{developed in a}} computer-aided design environment. The neurocranium is introduced as a mathematical surface, since {{this is the part}} on which the actual operation will be performed. The viscerocranium, which serves as reference, is visualized using small triangular surfaces. The development of the program commenced with a classification of the different surgical techniques mentioned in the literature into six basic actions. The use of mathematically described surfaces has the advantage that the program can simulate actions which change the shape of a surface and perform an on-line estimation of the fracture risk during bending. Three-point bending tests were carried out to provide the necessary data to perform the <b>mathematical</b> <b>check,</b> as these data are not available in the literature. A database with reference distances was introduced to guide the surgeon to obtain the best possible results. During one clinical trial, the computer was taken into the operating room so that the surgical plan developed with the simulation program could be applied to the actual operation. Comp Aid Surg 4 : 117 - 128 (1999). © 1999 Wiley-Liss, Inc. status: publishe...|$|E
40|$|N. G. de Bruijn {{was one of}} {{the pioneers}} to explore the idea of using a {{computer}} to formally <b>check</b> <b>mathematical</b> proofs. The Automath project, that started in 1967 and ran until 1980, was the first in developing computer programs to actually <b>check</b> <b>mathematical</b> proofs. But Automath is more than that: it is a language for doing mathematics and it has philosophical implications for the way we look at logic and th...|$|R
30|$|MRAK {{formulated}} the optimization problems, {{designed the}} proposed solutions, performed numerical simulations, and prepared the initial draft {{as well as}} the revision. K-KW managed funding for the research, modified solution pattern, verified <b>mathematical</b> derivations, <b>checked</b> and analyzed the simulation results, and improved the writeup. Both authors read and approved the final manuscript.|$|R
5000|$|Coq - Which {{allows the}} {{expression}} of <b>mathematical</b> assertions, mechanically <b>checks</b> proofs of these assertions, helps to find formal proofs, and extracts a certified program from the constructive proof of its formal specification.|$|R
2500|$|Gerald Jay Sussman and Jack Wisdom, [...] (MIT Press, 2001). Begins {{with the}} {{principle}} of least action, uses modern <b>mathematical</b> notation, and <b>checks</b> the clarity and consistency of procedures by programming them in computer language.|$|R
5000|$|Gerald Jay Sussman and Jack Wisdom, Structure and Interpretation of Classical Mechanics (MIT Press, 2001). Begins {{with the}} {{principle}} of least action, uses modern <b>mathematical</b> notation, and <b>checks</b> the clarity and consistency of procedures by programming them in computer language.|$|R
40|$|The {{method of}} {{increase}} of uniformity of galvanic coating {{owing to the}} addition of nano-carbon material "Taunit" into electrolyte is offered. For search of optimum nano-carbon concentration in electrolyte the mathematical model considering influence of nano-carbon concentration on polarization is formed. Adequacy of <b>mathematical</b> model is <b>checked</b> up on the experimental data received by authors on the laboratory device...|$|R
40|$|The {{implementation}} of the algorithms used in the flight program to approximate elementary functions and <b>mathematical</b> procedures was <b>checked.</b> This was done by verifying that at least one, and in most cases, more than one function computed {{through the use of}} the algorithms was calculated properly. The following algorithms were checked: sine-cosine, arctangent, natural logarithm, square root, inverse square root, as well as the vector dot and cross products...|$|R
50|$|In {{computer}} science, Coq is {{an interactive}} theorem prover. It allows {{the expression of}} <b>mathematical</b> assertions, mechanically <b>checks</b> proofs of these assertions, helps to find formal proofs, and extracts a certified program from the constructive proof of its formal specification. Coq works within {{the theory of the}} calculus of inductive constructions, a derivative of the calculus of constructions. Coq is not an automated theorem prover but includes automatic theorem proving tactics and various decision procedures.|$|R
25|$|The factor-label method {{can also}} be used on any <b>mathematical</b> {{equation}} to <b>check</b> whether or not the dimensional units on the left hand side of the equation are the same as the dimensional units on the right hand side of the equation. Having the same units on both sides of an equation does not ensure that the equation is correct, but having different units on the two sides (when expressed in terms of base units) of an equation implies that the equation is wrong.|$|R
40|$|The {{publication}} presents {{results from}} {{a study of the}} total microflora in urogenic soils in Sofia. The influence of four major factors on the total microflora size is analyzed: depth of sampling, humidity and soil temperature, content of lead. A regression and correlation analysis was carried out, whereby the statistical significance of the coefficients in the <b>mathematical</b> model was <b>checked</b> {{in the case of a}} one-factor model and a model with all the factors. The behavior of the model has been investigated in a variety of data samples and an optimal option has been selected...|$|R
50|$|The factor-label method {{can also}} be used on any <b>mathematical</b> {{equation}} to <b>check</b> whether or not the dimensional units on the left hand side of the equation are the same as the dimensional units on the right hand side of the equation. Having the same units on both sides of an equation does not ensure that the equation is correct, but having different units on the two sides (when expressed in terms of base units) of an equation does allow one to conclude that the equation is wrong.|$|R
40|$|This {{research}} {{was aimed at}} identifying actions that can be performed to help students overcome the difficulties in solving one step word problems. The research used descriptive qualitative approach. The type of {{research was}} participant action research. In this research, it was found out that by using approaches such as translation, simulation, making picture, dialogue, group activity, planting concept of addition and substraction using one-time saving and borowing technigues, rereading the original story of the word problems, <b>checking</b> <b>mathematical</b> sentences that had been made, and recomputing, students can solve the one-step word problems well {{in terms of its}} solving step...|$|R
40|$|The Theorema project aims at {{integrating}} computation and deduction in {{a system}} that can be used by the working scientist for building and <b>checking</b> <b>mathematical</b> models, including the design and verification of new algorithms. Currently, the system uses the rewrite engine of the computer algebra system Mathematica for building and combining a number of automatic/interactive provers (high-order predicate-logic, induction for lists/tuples and natural numbers, etc.) in natural deduction style and in natural language presentation. These provers can be used for defining and proving properties of mathematical models and algorithms, while a specially provided "computing engine" can execute directly the logical description of these algorithms...|$|R
40|$|Results are {{presented}} {{of an investigation}} into the subsynchronous resonance (SSR) behavior of the 1, 072 MVA nuclear powered turbo-generators to be installed at Koeberg Power Station. A mathematical model describing the dynamics of the shaft system, the synchronous generator and the transmission network is presented. An eigenvalue analysis of a linearized model and the Fourier transformation of some of the time domain waveforms provide insight into the physical mechanism of SSR. The <b>mathematical</b> model is <b>checked</b> by measurements on a laboratory micro-alternator and transmission line simulator system. The results show that unless precautionary steps are taken, unstable subsynchronous oscillations could occur at Koeberg...|$|R
40|$|International audienceThe aim of {{this paper}} is to derive and analyse {{diffusion}} models for semiconductor spintronics. We begin by presenting and studying the so called "spinor" Boltzmann equation. Starting then from a rescaled version of linear Boltzmann equation with different spin-flip and non spin-flip collision operators, different continuum (drift-diffusion) models are derived. By comparing the strength of the spin-orbit scattering with the scaled mean free paths, we explain how some models existing in the literature (like the two-component models) can be obtained from the spinor Boltzmann equation. A new spin-vector drift-diffusion model keeping spin relaxation and spin precession effects due to the spin-orbit coupling in semiconductor structures is derived and some of its <b>mathematical</b> properties are <b>checked...</b>|$|R
40|$|Abstract. Cristian Calude et al. in [5] have {{recently}} introduced {{the idea of}} measuring the degree of difficulty of a mathematical problem (even those still given as conjectures) by {{the length of a}} program to verify or refute the statement. The method to evaluate and compare problems, in some objective way, will be discussed in this note. For the practitioner, wishing to apply this method using a standard universal register machine language, we provide (for the first time) some “small ” core subroutines or library for dealing with array data structures. These can be used to ease the development of full programs to <b>check</b> <b>mathematical</b> problems that require more than a predetermined finite number of variables. ...|$|R
40|$|In {{this work}} the {{observability}} of an Inertial Navigation System (INS) during In-Flight Alignment (IFA) is investigated. A systematic {{approach to the}} observability analysis of a piece-wise constant system is presented and its use is justified mathematically. As a tool for the investigation a Stepped Observability Matrix (SOM) is constructed and a corresponding Stepped Space is defined. The INS error model is transformed into the Stepped Space during a specially chosen IFA trajectory and a full observability is carried out. The results of the <b>mathematical</b> analysis are <b>checked</b> against the results of covariance simulation and a full agreement is found between the two. Finally, the practical implications of this analysis are outlined...|$|R
40|$|This work {{investigates the}} {{quantifier}} elimination problem in real closed fields {{with respect to}} the application in description logics. The motivation for the investigation in this topic is mainly based on the demand for an extension of a description logic system to support a default concrete domain for non-linear multivariate equations and inequations. In this report we provide a literature overview that summarizes main <b>mathematical</b> tools for <b>checking</b> whether a set of non-linear multivariate (in-) equations is satisfiable (quantifier elimination problem). In addition, the report describes the interface to a prototype implementation for complex numbers (rather than the reals) provided a description logic system. We also shortly describe how initial application examples are handled with the prototype implementation...|$|R
40|$|The mass {{transfer}} of solute from a dilute gaseous mixture during bubble formation {{at the tip}} of a submerged nozzle in the presence of an instantaneous chemical reaction on the liquid side is simulated via a two-parameter model. This mechanistic model is developed from the general mass balance of solute by introducing a number of physically reasonable assumptions coupled with carefully <b>checked</b> <b>mathematical</b> approximations. Using data reported elsewhere, parameter estimates are found and a statistical analysis of their significance is presented. Experimental evidence is predicted much better than via other theoretical models. The analysis reported is useful for the preliminary design of industrial sparging vessels because most of the solute removal occurs during bubble growth...|$|R
50|$|Even if Metamath is {{used for}} <b>mathematical</b> proof <b>checking,</b> its {{algorithm}} is so general we can extend the field of its usage. In fact Metamath could be used with every sort of formal system: the checking of a computer program could be considered (even if Metamath's low level would make it difficult); it could possibly even be a syntactic checker for a natural language (same remark). Because Metamath has a very generic concept of what a proof is (namely a tree of formulas connected by inference rules) and no specific logic {{is embedded in the}} software, Metamath can be used with species of logic as different as Hilbert-style logics or sequents-based logics or even with lambda calculus. In contrast, it is largely incompatible with logical systems which use other things rather than formulas and inference rules. The original natural deduction system (due to Gerhard Gentzen), which uses an extra stack, {{is an example of a}} system that cannot be implemented with Metamath. In the case of natural deduction however it is possible to append the stack to the formulas (transforming the natural deduction formulas into a sort of sequent) so that Metamath's requirements are met.|$|R
40|$|We {{present results}} {{concerning}} {{the characterization of}} selected silica-based materials from a molecular modeling approach, together with some physical and <b>mathematical</b> tests to <b>check</b> {{the reliability of the}} obtained results. The experimental adsorption data is used in combination with Monte Carlo simulations and a regularization procedure in order to propose a reliable Pore Size Distribution (PSD). Individual adsorption isotherms are obtained by Monte Carlo simulations performed in the Grand Canonical ensemble. The methodology is applied to M 41 S materials, chosen due to their well defined pore geometry and pore size distribution, obtainable from alternative procedures. Our results are in excellent agreement with previous published results, demonstrating the reliability of this methodology for the characterization of other materials, with less well-defined structural properties...|$|R
40|$|Automatic <b>mathematical</b> {{solution}} assessment <b>checks</b> the equivalence {{of mathematical}} expressions in the user answer and standard solution. It is a challenging problem as the semantics o f mathematical expressions are highly symbolic and equivalent mathematical expressions {{can be expressed}} in different forms. In this paper, we propose an effective Probabilistic Equivalence Verification (PEV) approach for automatic mathematical solution assessment. The proposed PEV approach is a randomized method based on the probabilistic numerical equivalence testing of two mathematical expressions. It can avoid false negative errors completely while guaranteeing a small probability of false positive errors to occur. The performance results {{have shown that the}} proposed PEV approach has outperformed other popular techniques in Computer Algebra Systems such as Maple and Mathematica...|$|R
40|$|The paper {{analyzes}} {{an operation}} of the standard three-impulse automatic control system (ACS) for steam generator water supply. <b>Mathematical</b> model for <b>checking</b> its operational ability on load relief has been developed in the paper and this model {{makes it possible to}} determine maximum deviations of water level without execution of actual tests and any corrections in the plants for starting-up of technological protection  systems in accordance with water level in the drum.   The paper reveals reasons of static regulation errors while solving problems of internal and external distortions caused by expenditure of over-heated steam in the standard automatic control system. An actual significance of modernization pertaining to automatic control system for steam generator water supply has been substantiated in the paper...|$|R
40|$|The paper {{describes}} a format for presenting proofs called structured calculational proof. The format resembles calculational proof, {{a style of}} reasoning popular among computer scientists, but extended with structuring facilities. A prototype tool has been developed which allows readers to interactively browse proofs presented in this format via the world wide web. The ability to browse a proof increases its readability, and hence its value as a proof. Computers {{have been used for}} some time to both construct and <b>check</b> <b>mathematical</b> proofs, but using them to enhance the readability of proofs is a relatively novel application. This paper was originally presented at the symposium on Logic, Mathematics and the Computer The reference is as follows: Jim Grundy. A browsable format for proof presentation. In Christo e...|$|R
40|$|ProofCheck is {{a system}} for writing and <b>checking</b> <b>mathematical</b> proofs. Theorems and proofs are {{contained}} in a plain TEX or L ATEX document. Parsing and proof checking are accomplished through Python programs which read the source file. A general explanation of the use {{and structure of the}} system and programs is provided and a sample proof is shown in detail. The work done by the authors has been based on standard sentence logic, a non-standard predicate logic and set theory with proper classes. Theorems and proofs based on other foundations may be checked if external data files are modified. Four such data files and their possible modifications are described. In addition, {{the extent to which the}} formal language can be shaped to accommodate an author’s preferences is discussed. ...|$|R
40|$|Abstract. We {{describe}} a framework with which first order theorem provers {{can be used}} for checking formal proofs. The main aim of the framework is to take as much advantage as possible from the strength of first order theorem provers in the formalization of realistic formal proofs. In order to obtain this, we restricted the use of higher order constructs to a minimum. In particular, we refrained from * notation in formulas and from currying. The first order prover can be freely chosen. All communication with the theorem prover uses TPTP syntax. The system is intended for teaching, for <b>checking</b> <b>mathematical</b> proofs or correctness proofs of algorithms and also for improving the effectiveness of theorem provers. In its current set up, the system is not intended for building large libraries of checked mathematics...|$|R
40|$|In {{the last}} years the {{polyphase}} IIR structures proved themselves very attractive for very high performance filters that can be designed using very few coefficients. This combined with their little sensitivity to coefficient quantization in comparison to standard FIR and IIR structures makes them very applicable for very fast filtering when implemented in fixed point arithmetic. However, although the mathematical description is very simple, there exist {{a number of ways}} to implement such filters. In this paper we take all these different implementation structures and analyze the rounding noise originating fiom the limited arithmetic wordlength of the <b>mathematical</b> operators and <b>check</b> the intemal data growth within the structure. These analysis need to be done to ensure that the performance of the implementation would match the performance of the theoretical design...|$|R
40|$|The Proofchecker is a heuristically {{oriented}} {{computer program}} for <b>checking</b> <b>mathematical</b> proofs, with the checking of textbook proofs as its ultimate goal. It constructs, from each proof step given to it, a corresponding sequence of formal steps, if possible. It records {{the current state}} of the proof in the form of what it is sufficient to prove. There are two logical rules of inference: modus powers and insertion (if it is sufficient to prove B, and A is the theorem, then it is sufficient to prove A implies B). The permissible formal steps include these rules of inference as well as provision for handling definitions, lemmas, calculations, and reversion to previous states. As of now, most of the formalisms are programmed and partially debugged, but the heuristic aspects have yet to be programmed...|$|R
5000|$|There are methods {{by which}} to check for {{outliers}} in the discipline of statistics and statistical analysis. As is the basic idea of descriptive statistics, when encountering an outlier, we have to explain this value by further analysis of the cause or origin of the outlier. In cases of extreme observations, which are not an infrequent occurrence, the typical values must be analyzed. In the case of quartiles, the Interquartile Range (IQR) {{may be used to}} characterize the data when there may be extremities that skew the data; the interquartile range is a relatively robust statistic (also sometimes called [...] "resistance") compared to the range and standard deviation. There is also a <b>mathematical</b> method to <b>check</b> for outliers and determining [...] "fences", upper and lower limits from which to check for outliers.|$|R
40|$|ProofCheck is {{a system}} for writing and <b>checking</b> <b>mathematical</b> proofs. Theorems and proofs are {{contained}} in a plain TEX or L ATEX document. Parsing and proof checking are accomplished through Python programs which read the source file. Although {{the use of these}} programs has never been restricted to any particular logic or mathematical language, the work required to actually implement an author’s choices in these matters, especially in the logic, and to make the necessary modifications of the supporting files have been sufficiently laborious as to pose an obstacle to the use of ProofCheck. This paper describes updates to the system whose purpose is to alleviate these labors to the extent possible so as to facilitate the use of ProofCheck in a logical and linguistic setting of the author’s choice. 1 What is ProofCheck? ProofCheck is a Python package, available a...|$|R
40|$|Computer {{systems are}} used for {{controlling}} physical processes in many safety-critical applications. These systems are embedded into the larger system of the application and are interfaced with their physical environment using input hardware (sensors, analog-to-digital converters) and output hardware (digital to analog converters, actuators). A challenging task in designing such sys-tems is finding {{the right combination of}} input hardware, output hardware, and software such that their integration produces systems that satisfy their requirements. In this thesis we propose a <b>mathematical</b> basis for <b>checking,</b> without the need for developing and verifying a detailed implementation, if acceptable soft-ware exists given the chosen hardware interfaces. The requirements framework we use is the relational four-variable model proposed by Parnas and Madey. This model helps to clarify the behaviour of, and the boundaries between, the system’s physical environment, hardware interfaces, and software, which ar...|$|R
40|$|Abstract. The aim of {{this paper}} is to derive and analyse {{diffusion}} models for semiconductor spintronics. We begin by presenting and studying the so called ”spinor ” Boltzmann equation. Starting then from a rescaled version of linear Boltzmann equation with different spin-flip and non spin-flip collision operators, different continuum (drift-diffusion) models are derived. By comparing the strength of the spin-orbit scattering with the scaled mean free paths, we explain how some models existing in the literature (like the two-component models) can be obtained from the spinor Boltzmann equation. A new spin-vector drift-diffusion model keeping spin relaxation and spin precession effects due to the spin-orbit coupling in semiconductor structures is derived and some of its <b>mathematical</b> properties are <b>checked.</b> Key words. Spinor Boltzmann equation, spin-orbit coupling, spin-flip interactions, diffusion limit, decoherence limit, two-component drift-diffusion model, spin-vector drift-diffusion model. Subject classifications. hal- 00624338, version 1 - 17 Sep 2011 1. Introduction. Th...|$|R
40|$|Problem statement: Membrane {{computing}} formalism {{has provided}} better modeling capabilities for biological systems {{in comparison to}} conventional <b>mathematical</b> models. Model <b>checking</b> {{could be used to}} reason about the biological system in detail and with precision by verifying formally whether membrane computing model meets the properties of the system. Approach: This study was carried to investigate the preservation of properties of two biological systems that had been modeled and simulated in membrane computing by a method of model checking using PRISM. The two biological systems were prey-predator population and signal processing in the legend-receptor networks of protein TGF-ß. Results: The model checking of membrane computing model of the biological systems with five different properties showed that the properties of the biological systems could be preserved in the membrane computing model. Conclusion: Membrane computing model not only provides a better approach in representing and simulating a biological system but also able to sustain the basic properties of the system...|$|R
40|$|Polyphase IIR {{structures}} {{have recently}} proven themselves very attractive for very high performance filters {{that can be}} designed using very few coefficients. This, combined with their low sensitivity to coefficient quantization in comparison to standard FIR and IIR structures, makes them very applicable for very fast filtering when implemented in fixed-point arithmetic. However, although the mathematical description is very simple, there exist {{a number of ways}} to implement such filters. In this paper, we take four of these different implementation structures, analyze the rounding noise originating from the limited arithmetic wordlength of the <b>mathematical</b> operators, and <b>check</b> the internal data growth within the structure. These analyses need to be done to ensure that the performance of the implementation matches the performance of the theoretical design. The theoretical approach that we present has been proven by the results of the fixed-point simulation done in Simulink and verified by an equivalent bit-true implementation in VHDL...|$|R
