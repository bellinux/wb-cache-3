59|9398|Public
50|$|TAAS is an {{emerging}} chip technology to meet ever growing demand to run multiple heterogeneous high computation-complex systems {{with only one}} piece of silicon real estate by re-use of the same transistors through reconfigurations. The processor also shares the same transistors to run different system tasks in form of software, but due to its fixed and limited hardware resources such as execution units (EXE units) and memory access ports (load and store units), processor-like architecture is not suitable for running high computation-complex systems such as broadband wireless PHY signal processing or deep neural networks machine learning algorithms. GPU offers <b>massive</b> <b>parallel</b> <b>computing</b> capability by its many-core architecture. However the power consumption of GPU for memory access is far exceeding that of computation. GPU architecture is medium in performance as compared to ASIC and very high in power consumption.|$|E
30|$|Hence, we {{employ a}} three-layered, {{hierarchical}} master/slaves method to approximate such a tradeoff. To address <b>massive</b> <b>parallel</b> <b>computing,</b> {{based on the}} above paradigm, tasks are dynamically scheduled to achieve a fine scalability.|$|E
40|$|In {{this paper}} we motivate {{the use of}} a {{declarative}} programming style and the use of <b>massive</b> <b>parallel</b> <b>computing</b> systems to model control strategies in concurrent systems. The simplified formulation of system components and their interaction permits to generate a rapid prototype of the system. Based on this prototype, a first simulation of the modeled strategies and the system is done on a <b>massive</b> <b>parallel</b> <b>computing</b> system. Using parallel hardware the massive parallelism of real systems can be naturally matched to an execution model. To allow a sophisticated modeling and rapid prototyping we use strategies based on fuzzy logic and present a prototype of a fuzzy library for the concurrent programming language PCN [4]. We demonstrate the modeling strengths of our approach by describing aspects of a 'real world problem', a color sorting assembly buffer used in car production. Keywords: PCN, Modeling, Transputer, Flexible Manufacturing Systems, Algorithmic Skeletons, Fuzzy 1 Introduction T [...] ...|$|E
30|$|Equipment layer: It is {{the lowest}} level of the whole system. The system is a {{high-performance}} computing platform based on GPU, where GPU is responsible for <b>massive</b> data high-performance <b>parallel</b> <b>computing,</b> and CPU is responsible for process control of program execution.|$|R
40|$|Abstract. Generally {{working in}} severe conditions, {{mechanical}} equipments {{are subjected to}} progressive deterioration of their state. The mechanical failures {{account for more than}} 60 % of breakdowns of the system. Therefore, the identification of impending mechanical fault is very important to prevent the system from illness running. It generally requires high performance computer to complete the traditional <b>parallel</b> <b>computing,</b> while the <b>parallel</b> FFT algorithm based on Hadoop MapReduce programming model can be realized in the low-end machines. Combining with Cloud Computing and equipment fault diagnosis technology, it can realize the <b>massive</b> data <b>parallel</b> <b>computing</b> and distributed storage. The result of experiment shows that it would provide a good solution and technical support for mechanical equipment on-line monitoring and real-time fault diagnosis...|$|R
40|$|Asynchronous {{nonlinear}} fractal operators {{were considered}} {{in order to}} implement fractal applications by <b>massive</b> <b>parallel</b> asynchronous <b>computing</b> system as recurrent neural networks. Assuming the convergence of the synchronous fractal operator to an element ~ f which is an approximation of the original image f, it is proved that any asynchronous deterministic realization of local fractal operators is convergent to ~ f and the stochastic realization converges to ~ f with probability one. Beside compression, applications of such stochastic fractal operators for object recognition and image association are described. This new approach {{to the concept of}} associative memory, exhibits correct associative recalls for highly noised images and also for images with small 3 D distortions (on Olivietti face database it results in 100 % rate of face recognition) ...|$|R
30|$|A three-layered master/slave {{hierarchical}} dynamic scheduling {{method is}} presented for <b>massive</b> <b>parallel</b> <b>computing</b> of CA. We have also demonstrated {{the potential for}} processing N − X CA by a large scale method. The variance in the processing time of CA is a concern and is handled by adopting the layered dynamic task scheduling. The {{results show that the}} synchronization cost with the proposed method is limited within groups while achieving overall workload balancing.|$|E
30|$|This paper adopts {{parallel}} computing techniques to help speed up large CA. In the master/slave architecture, the I/O workload is minimal and is handled with the master reading the data, and then broadcasting to the slaves. It {{focuses on the}} challenges of workload scheduling, workload balance, and limiting the communication cost of CA computation. Our contribution is to address this large-scale <b>massive</b> <b>parallel</b> <b>computing</b> problem of CA, apply the hierarchical task scheduling, which efficiently limits the synchronization penalty along with the dynamic task scheduling strategy, and introduce the method to N −  2 large-scale contingency analysis with robust scalability.|$|E
40|$|The central {{detectors}} of the ALICE experiment at LHC {{will produce}} a data size of up to 75 MB/event at an event rate less than approximately equals 200 Hz resulting in a data rate of similar to 15 GB/s. Online processing of the data is {{necessary in order to}} select interesting (sub) events ("High Level Trigger"), or to compress data efficiently by modeling techniques. Processing this data requires a <b>massive</b> <b>parallel</b> <b>computing</b> system (High Level Trigger System). The system will consist of a farm of clustered SMP-nodes based on off- the-shelf PCs connected with a high bandwidth low latency network...|$|E
40|$|The General Purpose {{computing}} on Graphics Processing Units (GPGPUs) techniques {{represent a}} significantly different <b>parallel</b> <b>computing</b> scheme than the MapReduce/Hadoop based {{ones that are}} currently adopted by mainstream Big Data systems. The <b>massive</b> data <b>parallel</b> <b>computing</b> power provided by inexpensive commodity GPUs makes large-scale spatial data processing on GPUs and GPU-accelerated clusters attractive from both a research and practical perspective. In this article, we report our work on data parallel designs of spatial indexing, spatial joins and several other spatial operations, such as polygon rasterization, polygon decomposition and point interpolation. The data parallel designs are further scaled out to distributed computing nodes by integrating single-node GPU implementations with High-Performance Computing (HPC) toolset and the new generation in-memory Big Data systems such as Cloudera Impala. In addition to introducing GPGPU computing background and outlining data parallel designs for spatial operations, references to individual works are provided as a summary chart for interested readers to follow more details on designs, implementations and performance evaluations...|$|R
50|$|In-database {{processing}} is one {{of several}} technologies focused on improving data warehousing performance. Others include <b>parallel</b> <b>computing,</b> shared everything architectures, shared nothing architectures and <b>massive</b> <b>parallel</b> processing. It is an important step towards improving predictive analytics capabilities.|$|R
40|$|In the 1990 s the Beowulf project {{smoothed}} to way for massively paral-lel computing as {{access to}} <b>parallel</b> <b>computing</b> power became affordable for research {{institutions and the}} industry. But the <b>massive</b> breakthrough of <b>parallel</b> <b>computing</b> has still not occurred. This is because two things were missing: low cost parallel computers and simple to use parallel programming models. However, {{with the introduction of}} multicore processors for main-stream computers and implicit parallel programming models like OpenMP a fundamental change of the way developers design and build their software applications is taken place—a change towards <b>parallel</b> <b>computing.</b> This thesis gives an overview of the field of high performance computing with a special focus on <b>parallel</b> <b>computing</b> in connection with the R environ-ment for statistical computing and graphics. Furthermore, an introduction to <b>parallel</b> <b>computing</b> using various extensions to R is given. The major contribution of this thesis is the package called paRc, which contains an interface to OpenMP and provides a benchmark environment to compare various parallel programming models like MPI or PVM with each other as well as with highly optimized (BLAS) libraries. The dot product matrix multiplication was chosen as the benchmark task as it is a prime example in <b>parallel</b> <b>computing.</b> Eventually a case study in computational finance is presented in this thesis. It deals with the pricing of derivatives (European call options) using parallel Monte Carlo simulation...|$|R
40|$|The High Level Trigger (HLT) of the ALICE {{experiment}} requires <b>massive</b> <b>parallel</b> <b>computing.</b> One of {{the main}} tasks of the HLT system is two-dimensional cluster finding on raw data of the Time Projection Chamber (TPC), which is the main data source of ALICE. To {{reduce the number of}} computing nodes needed in the HLT farm, FPGAs, which are an intrinsic part of the system, will be utilized for this task. VHDL code implementing the Fast Cluster Finder algorithm, has been written, a testbed for functional verification of the code has been developed, and the code has been synthesize...|$|E
40|$|Abstract — This paper {{presents}} a webcam-based spherical coordinate conversion system using OpenCL <b>massive</b> <b>parallel</b> <b>computing</b> for panorama video image stitching. With multi-core architecture and its high-bandwidth data transmission rate of memory accesses, modern programmable GPU {{makes it possible}} to process multiple video images in parallel for real-time interaction. To get a panorama view of 360 degrees, we use OpenCL to stitch multiple webcam video images into a panorama image and texture mapped it to a spherical object to compose a virtual reality immersive environment. The experimental results show that when we use NVIDIA 9600 GT to process eight 640 × 480 images, OpenCL can achieve ninety times speedups...|$|E
40|$|Abstract—A strip domain {{decomposition}} parallel algorithm for fast direct Poisson solver is presented on a 3 D Cartesian staggered grid. The parallel algorithm follows {{the principles of}} sequential algorithm for fast direct Poisson solver. Both Dirichlet and Neumann boundary conditions are addressed. Several test cases are likewise {{addressed in order to}} shed light on accuracy and efficiency in the strip domain parallelization algorithm. Actually the current implementation shows a very high efficiency when dealing with a 9 large grid mesh up to 3. 6 × 10 under massive parallel approach, which explicitly demonstrates that the proposed algorithm is ready for <b>massive</b> <b>parallel</b> <b>computing.</b> Keywords—Strip-decomposition, parallelization, fast direct poisson solver. I...|$|E
40|$|Direct {{numerical}} simulation (DNS) for gas-solid flow is implemented on a multi-scale supercomputing system, Mole- 8. 5, featuring <b>massive</b> <b>parallel</b> GPU-CPU hybrid <b>computing,</b> {{for which the}} lattice Boltzmann method (LBM) is deployed together with the immersed moving boundary (IMB) method and discrete element method (DEM). A two-dimensional suspension with about 1, 166, 400 75 -micron solid particles distributed {{in an area of}} 11. 5 cm x 46 cm, and a three-dimensional suspension with 129, 024 solid particles in a domain of 0. 384 cm x 1. 512 cm x 0. 384 cm are fully-resolved below particle scale and distinct multi-scale heterogeneity are observed. Almost 20 -fold speedup is achieved on one Nvidia C 2050 GPU over one core of Intel E 5520 CPU in double precision, and nearly ideal scalability is maintained when using up to 672 GPUs. The simulations demonstrate that LB-IMB-DEM modeling with <b>parallel</b> GPU <b>computing</b> may suggest a promising approach for exploring the fundamental mechanisms and constitutive laws of complex gas-solid flow, which are, so far, poorly understood in both experiments and theoretical studies. Comment: 12 pages, 7 figures; submitted to Chemical Engineering Scienc...|$|R
40|$|Introduction The {{emerging}} {{generation of}} supercomputers will {{be suitable for}} <b>massive</b> <b>parallel</b> applications. To orchestrate the communication needed to coordinate concurrent tasks, we are currently developing a new coordination language [1] called CoLa. Specifically CoLa is aimed to provide a high programming abstraction level for massively <b>parallel</b> <b>computing,</b> especially for applications {{in the field of}} distributed artificial intelligence. CoLa is embedded in classical programming languages and combines both declarative as well as imperative semantic properties in its definition. CoLa incorporates a high level identification concept, defining communication objects as correspondents [2], a postal mail delivery model for efficient and transparent message passing [3][4] and new communication and synchronization mechanisms. Programming Model CoLa is based on the concept of correspondents, a...|$|R
40|$|The paper {{presents}} {{an overview of}} <b>parallel</b> <b>computing</b> in computational fluid dynamics. A taxonomy of <b>parallel</b> <b>computing</b> architectures and programming paradigms is described. Issues in <b>parallel</b> <b>computing</b> are discussed including domain decomposition and load balancing, performance, scalability, benchmarks and portability. Examples of experience with <b>parallel</b> <b>computing</b> in the aerospace industry is described. 1 Overview This paper is intended for researchers in Computational Fluid Dynamics (CFD) {{who do not have}} experience in <b>parallel</b> <b>computing.</b> It provides a description of <b>parallel</b> <b>computing</b> hardware architecture, software paradigms, the principal issues in utilizing <b>parallel</b> <b>computing</b> for CFD, and examples of use of <b>parallel</b> <b>computing</b> in the aerospace industry. <b>Parallel</b> <b>computing,</b> particularly in computational fluid dynamics, is a broad field of research and development. The software and hardware technology is developing at an extraordinary pace. The reader is directed to the numerous jou [...] ...|$|R
40|$|General purpose {{graphical}} processing {{units were}} proven to be useful for accelerating computationally intensive algorithms. Their capability to perform <b>massive</b> <b>parallel</b> <b>computing</b> significantly improve performance of many algorithms. This thesis focuses on using graphical processors (GPUs) to accelerate algorithms based on adversarial search. We investigate {{whether or not the}} adversarial algorithms are suitable for single instruction multiple data (SIMD) type of parallelism, which GPU provides. Therefore, parallel versions of selected algorithms accelerated by GPU were implemented and compared with the algorithms running on CPU. Obtained results show significant speed improvement and proof the applicability of GPU technology in the domain of adversarial search algorithms...|$|E
40|$|The {{development}} of multicore architectures supporting parallel data processing {{has led to}} a paradigm shift, which affects communication systems significantly. This article provides a scalable parallel approach of an iterative LDPC decoder, presented in a tutorial-based style. It is suitable for decoding any irregular LDPC code without the limitation of the maximum node degree, and it includes a parallel calculation of the syndrome. This is the main difference from algorithms presented so far. The proposed approach can be implemented in applications supporting <b>massive</b> <b>parallel</b> <b>computing,</b> such as GPU or FPGA devices. The implementation of the LDPC decoder with the use the OpenCL and CUDA frameworks is discussed and the performance evaluation is given {{at the end of this}} contribution...|$|E
40|$|The {{ability to}} handle large scale graph data is crucial to an {{increasing}} number of applications. Much work has been dedicated to supporting basic graph operations such as subgraph matching, reachability, regular expression matching, etc. In many cases, graph indices are employed to speed up query processing. Typically, most indices require either super-linear indexing time or super-linear indexing space. Unfortunately, for very large graphs, super-linear approaches are almost always infeasible. In this paper, we study the problem of subgraph matching on billion-node graphs. We present a novel algorithm that supports efficient subgraph matching for graphs deployed on a distributed memory store. Instead of relying on super-linear indices, we use efficient graph exploration and <b>massive</b> <b>parallel</b> <b>computing</b> for query processing. Our experimental results demonstrate the feasibility of performing subgraph matching on web-scale graph data. 1...|$|E
40|$|Abstract. <b>Parallel</b> <b>computing</b> {{has become}} an {{important}} subject {{in the field of}} computer science and has proven to be critical when researching high performance solutions. The evolution of computer architectures (multi-core and many-core) towards a higher number of cores can only confirm that parallelism is the method of choice for speeding up an algorithm. In the last decade, the graphics processing unit, or GPU, has gained an important place in the field of high performance computing (HPC) because of its low cost and <b>massive</b> <b>parallel</b> processing power. Super-computing has become, for the first time, available to anyone at the price of a desktop computer. In this paper, we survey the concept of <b>parallel</b> <b>computing</b> and especially GPU <b>computing.</b> Achieving efficient <b>parallel</b> algorithms for the GPU is not a trivial task, there are several technical restrictions that must be satisfied in order to achieve the expected performance. Some of these limitations are consequences of the underlying architecture of the GPU and the theoretical models behind it. Our goal is to present a set of theoretical and techni-cal concepts that are often required to understand the GPU and its massive parallelism model. In particular, we show how this new technology can help the field of compu...|$|R
40|$|The paper {{analyze the}} {{characteristic}} of <b>Parallel</b> <b>Computing</b> Model of BSP and NOWs, Explore on <b>Parallel</b> <b>Computing</b> Model of BSP in the NOWs fit Environment. Indicate: some algorithm that designed rationalization <b>parallel</b> <b>computing,</b> acquire an approximately linear accelerated. With the <b>parallel</b> <b>computing</b> algorithm {{base on the}} NOWs of linear programming normal improve on simplex method obtain had best result to validate the conclusion...|$|R
40|$|For {{many years}} the Graphics Processing Unit (GPU) of common {{desktops}} was just used to accelerate {{certain parts of}} the graphics pipeline. After developers had access to the native instruction set and memory of the <b>massive</b> <b>parallel</b> computational elements of GPUs a lot has changed. GPUs became powerful and programmable. Nowadays two SDKs are most used for GPU programming: CUDA and OpenCL. CUDA is the most adopted general purpose <b>parallel</b> <b>computing</b> architecture for GPUs but is restricted to Nvidia graphic cards only. In contrast, OpenCL is a new royalityfree framework for parallel programming intended to be portable across different hardware manufacturers or even different platforms. In this paper, we evaluate both solutions considering a typical parallel algorithm: Ray Tracing. We show our performance results and experiences on developing both implementations that could be easily adapted to solve other problems...|$|R
40|$|With the {{proposal}} of medium to high average current accelerator facilities {{the demand for}} cavities with extremely low Higher Order Mode (HOM) impedances is increasing. Modern numerical tools are still under development to more thoroughly predict impedances that need {{to take into account}} complex absorbing boundaries and lossy materials. With the usually large problem size it is preferable to utilize <b>massive</b> <b>parallel</b> <b>computing</b> when applicable and available. Apart from such computational issues, we have developed methods using available computer resources to enhance the information that can be extracted from a cavities? wakefield computed in time domain. In particular this is helpful for a careful assessment of the extracted RF power and the mitigation of potential beam break-up or emittance diluting effects, a figure of merit for the cavity performance. The method is described as well as an example of its implementation...|$|E
40|$|Motivated by {{the growing}} {{interest}} in today's <b>massive</b> <b>parallel</b> <b>computing</b> capabilities we analyze a queueing network with many servers in parallel to which jobs arrive a according to a Poisson process. Each job, upon arrival, is split into several pieces which are randomly routed to specific servers in the network, without centralized information {{about the status of}} the servers' individual queues. The main feature of this system is that the different pieces of a job must initiate their service in a synchronized fashion. Moreover, the system operates in a FCFS basis. The synchronization and service discipline create blocking and idleness among the servers, which is compensated by the fast service time attained through the parallelization of the work. We analyze the stationary waiting time distribution of jobs under a many servers limit and provide exact tail asymptotics; these asymptotics generalize the celebrated Cramér-Lundberg approximation for the single-server queue...|$|E
40|$|AbstractWe discuss {{molecular}} dynamics (MD) simulations of high-energy radiation damage in materials relevant for encapsulation of nuclear waste and materials {{to be used}} in fusion reactors, including several important oxides and iron. We study various stages of evolution and relaxation of 100 – 200 keV collision cascades, and identify reversible elastic and irreversible inelastic structural changes. The elastic expansion of the lattice around the cascade is explained in terms of anharmonicity of interatomic interactions. The remaining irreversible structural change is related to resistance to amorphization by radiation damage. This resistance is quantified by the number of remaining defect atoms in the damaged structure. We discuss how MD simulations can predict experimental resistance to amorphization, including the important case of highly resistant materials. Finally, we discuss our current work to simulate radiation damage of MeV energies and system sizes of the order of billion atoms using <b>massive</b> <b>parallel</b> <b>computing</b> facilities...|$|E
40|$|This paper {{presents}} {{a method for}} embedding arbitrary communication topologies into heterogeneous crossbar interconnection networks. Our methods extends and improves the method presented in [1] {{which is based on}} mathematical programming. It supports not only homogeneous but also heterogeneous networks with different interfaces. It has been applied to a crossbar network of parallel signal processor system consisting of 256 modules. It is shown that the optimization of the embedding algorithm leads to a considerable enhancement of the performance. Keywords: Configuration, embedding, <b>parallel</b> <b>computing,</b> heterogeneous networks. 1 INTRODUCTION The time to compute large scale applications on <b>massive</b> <b>parallel</b> computers depends crucially on the communication overhead caused by the data exchange between processors [2]. Thus a good match between the data dependencies defined by the application and the topology of the processor interconnection network is essential for an effective parallel proce [...] ...|$|R
40|$|In {{this paper}} a survey on current trends in <b>parallel</b> <b>computing</b> {{has been studied}} that depicts all the aspects of <b>parallel</b> <b>computing</b> system. A large {{computational}} problem {{that can not be}} solved by a single CPU can be divided into a chunk of small enough subtasks which are processed simultaneously by a parallel computer. The parallel computer consists of <b>parallel</b> <b>computing</b> hardware, <b>parallel</b> <b>computing</b> model, software support for parallel programming. Parallel performance measurement parameters and parallel benchmarks are used to measure the performance of a <b>parallel</b> <b>computing</b> system. The hardware and the software are specially designed for parallel algorithm and programming. This paper explores all the aspects of <b>parallel</b> <b>computing</b> and its usefulness...|$|R
5000|$|<b>Parallel</b> {{processing}} (including <b>massive</b> <b>parallel</b> {{processing and}} MPPAs) ...|$|R
40|$|This paper {{presents}} a texture synthesis algorithm {{that was designed}} for the tile-less generation of large images of arbitrary size from small sample images. The synthesised texture shows features that are visually similar to the sample over a wide frequency range. The development of the algorithm aimed at achieving high quality results for a large range of natural textures, incorporation of the original samples in the synthesis product, ease of use and good texturing speed even with input sample data two magnitudes larger than used by previous techniques. Like other algorithms we utilise an implicit texture model by copying arbitrary shaped texture patches from the sample to the destination over a multi-scale image pyramid. Our method combines the advantages of different previous techniques with respect to quality. A mixture of exhaustive searching, <b>massive</b> <b>parallel</b> <b>computing</b> and the well-known LBG-algorithm ensures a good balance between texturing quality and speed...|$|E
40|$|Molecular {{computing}} {{is potentially}} {{one of the}} most powerful tools for the development of <b>massive</b> <b>parallel</b> <b>computing</b> protocols. In the present paper, a first example of the use of PNA:PNA interactions in molecular computing is described. A series of short PNA sequences have been designed with a four base stretch coding for variables and solutions. Hybridization of the components in different combinations was tested both in solution and in a microarray format. A series of PNA representing the solutions were spotted on a microarray surface in order to simulate the hardware. A series of PNA representing the variables, labeled with TAMRA, were used to interrogate the device enabling to solve non-deterministic logic operations. The system was shown to be able to solve a two-variable equation with a high signal to noise ratio. This paper intends to provide a proof of principle that PNA, on account of their stability and specificity of binding, are most suitable for constructing organic-type computers...|$|E
40|$|Introduction Nowadays, {{high-order}} compact finite difference schemes {{are often}} used to build the codes for DNS or LES of nonhomogeneous or anisotropic turbulence. For problems with large meshes, <b>massive</b> <b>parallel</b> <b>computing</b> offers an attractive mean to reduce the elapse times or even to run the codes and obtain results. Therefore, a difficult task to yield scalable numerical solvers {{appears to be the}} construction of efficient parallel preconditioners based on domain decomposition (DDM) and multigrid (MG) techniques for the Krylov subspace iterative methods. So far, the main objective of this work is to obtain asymptotically optimal multi-domain and multi-level preconditioners for them, i. e. with convergence rates independent of the mesh size # or the number of unknowns, {{of the size of the}} local subdomains # or the number of processors of the computer, and of the number of levels in the multigrid process, e. g. [1, 11]. Let us recall that it is generally not possible to reach when domai...|$|E
40|$|The {{network of}} {{workstations}} (NOW) we consider for <b>parallel</b> <b>computing</b> is heterogeneous and nondedicated (time-sharing), where computing power varies among the workstations, and multiple jobs may {{interact with each}} other in execution. We address three performance issues in this paper. First, we examine the effects of heterogeneity on co-scheduling and local scheduling policies for <b>parallel</b> <b>computing.</b> Through experimentation and quantitative comparisons, we discuss features and requirements of scheduling policies on heterogeneous NOW. Second, the heterogeneity and nondedication of NOW introduce new performance factors into <b>parallel</b> <b>computing,</b> which make traditional performance metrics for <b>parallel</b> <b>computing</b> under homogeneous platforms not suitable. We conducted a collection of experimental measurements to show the performance impact to <b>parallel</b> <b>computing.</b> Finally, using network latencies we experimentally evaluate the <b>parallel</b> <b>computing</b> scalability on NOW. Our objective of this study is t [...] ...|$|R
5000|$|Teradata: The DWH of Teradata was {{the first}} <b>massive</b> <b>parallel</b> database.|$|R
40|$|Abstract. <b>Parallel</b> <b>computing</b> is in <b>parallel</b> {{computer}} system for parallel {{processing of data}} and information, often {{also known as the}} high performance computing or super computing. The content of <b>parallel</b> <b>computing</b> were introduced, the realization of <b>parallel</b> <b>computing</b> and MPI <b>parallel</b> programming under Linux environment were described. The parallel algorithm based on divide and conquer method to solve rectangle placemen problem was designed and implemented with two processors. Finally, Through the performance testing and comparison, we verified the efficiency of <b>parallel</b> <b>computing...</b>|$|R
