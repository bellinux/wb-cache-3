37|11|Public
5|$|Ongoing {{problems}} with avionics systems were {{addressed in the}} Jolly Well program, completed in 1964, which improved components of the AN/ASQ-38 bombing navigational computer and the terrain computer. The MADREC (<b>Malfunction</b> <b>Detection</b> and Recording) upgrade fitted to most aircraft by 1965 could detect failures in avionics and weapons computer systems, and was essential in monitoring the Hound Dog missiles. The electronic countermeasures capability of the B-52 was expanded with Rivet Rambler (1971) and Rivet Ace (1973).|$|E
25|$|The C-5 {{features}} a <b>Malfunction</b> <b>Detection</b> Analysis and Recording (MADAR) system to identify errors throughout the aircraft.|$|E
5000|$|A Gemini <b>Malfunction</b> <b>Detection</b> System was {{installed}} {{to inform the}} crew of the rocket's status, and improve response in an emergency.|$|E
30|$|In {{connected}} AVs, {{an additional}} major threat is the injection of fake messages that could trigger inappropriate reactions. Additionally, the authentication {{that protects the}} system from external attackers and misbehavior detection is required to detect internal and unintentional attacks. The deployment of <b>malfunctioning</b> <b>detection</b> systems requires not only a software update of the on-board unit (OBU) but also {{a major change in}} the current standardized security architecture such as the European Telecommunications Standards Institute (ETSI) or the American National Standards Institute’s (ANSI) reference architecture. The OBU stores the content of all messages (new point of interest, obstacles, construction sites, etc.) in a so-called Local Dynamic Map (LDM in Europe) or Geographic Information System (GIS in the United States). Based on such a local representation of the real world, misbehavior detection, in-network data aggregation and more general decisions are made. Poisoning this database will affect the overall cooperative system. Here, again, the mitigation technique is a <b>malfunctioning</b> <b>detection</b> system, which performs plausibility checks before storing data into the map database.|$|R
40|$|Abstract- Autoregressive {{modelling}} {{of noise}} data {{is widely used}} for system identification, surveillance, <b>malfunctioning</b> <b>detection</b> and diagnosis. Several methods are available to estimate an autoregressive model. Usually, the so-called Yule-Walker method is employed. The various estimation methods generally yield comparable parameter estimates. In some special cases however, involving nearly periodic signals, the Yule-Walker approach may lead to incorrect parameter estimates. Burg’s method offers the best alternative to Yule-Walker. In this paper a theoretical explanation of this phenomenon is given, while the 1994 IAEA Benchmark test {{is presented as a}} practical example of Yule-Walker yielding poor parameter estimates. I...|$|R
40|$|Wireless sensor {{networks}} {{are often used}} to monitor physical and environmental conditions in various regions where human access is limited. Due to limited resources and deployment in hostile environment, they are vulnerable to faults and malicious attacks. The sensor nodes affected or compromised can send erroneous data or misleading reports to base station. Hence identifying malicious and faulty nodes in an accurate and timely manner is important to provide reliable functioning of the networks. In this paper, we present a malicious and <b>malfunctioning</b> node <b>detection</b> scheme using dual-weighted trust evaluation in a hierarchical sensor network. Malicious nodes are effectively detected {{in the presence of}} natural faults and noise without sacrificing fault-free nodes. Simulation results show that the proposed scheme outperforms some existing schemes in terms of mis-detection rate and event detection accuracy, while maintaining comparable performance in malicious node detection rate and false alarm rate...|$|R
50|$|Gemini 2 {{had been}} {{scheduled}} for launch on December 9, 1964. On that date, the countdown reached zero and the first stage engines were ignited. The launch vehicle's <b>Malfunction</b> <b>Detection</b> System detected technical problems due {{to a loss of}} hydraulic pressure and shut down the engines about one second after ignition.|$|E
50|$|Ongoing {{problems}} with avionics systems were {{addressed in the}} Jolly Well program, completed in 1964, which improved components of the AN/ASQ-38 bombing navigational computer and the terrain computer. The MADREC (<b>Malfunction</b> <b>Detection</b> and Recording) upgrade fitted to most aircraft by 1965 could detect failures in avionics and weapons computer systems, and was essential in monitoring the Hound Dog missiles. The electronic countermeasures capability of the B-52 was expanded with Rivet Rambler (1971) and Rivet Ace (1973).|$|E
40|$|DAC, {{a generic}} and {{automatic}} Data center Address Configuration system. With an automatically generated blueprint {{that defines the}} connections of servers and switches labeled by logical Ids, e. g., IP addresses, DAC first learns the physical topology labeled by device IDs, e. g., MAC addresses. Then, {{at the core of}} DAC is its device-tological ID mapping and <b>malfunction</b> <b>detection.</b> DAC makes an innovation in abstracting the device-to-logical ID mapping to the graph isomorphism problem and solves it with low time complexity by leveraging the attributes of data center network topologies. Its <b>malfunction</b> <b>detection</b> scheme detects errors such as device and link failures and mis-wirings, including the most difficult case where mis-wirings do not cause any node degree change. We have evaluated DAC via simulation, implementation, and experiments...|$|E
30|$|In {{order to}} clarify this capability, {{consider}} a disturbance which {{occurs in a}} power system. It is {{important for us to}} be discovered immediately to take accurate actions. Power systems make use of distance relays in transmission lines to detect this condition. A distance relay is a device that measures the apparent impedance as an index of distance from the relay location. The power swing is a consequence of a severe disturbance like line fault, loss of generator unit and switching heavy load and creates large fluctuations (just like dynamic phasor condition) of active and reactive power between two areas of a power system. Power swing affects the distance relay behavior and causes its <b>malfunction.</b> Fast <b>detection</b> of power swing is interested in distance protection of transmission lines. Several methods have been proposed to solve this problem till now [24 – 29]. However the detection based on first and second derivatives of dynamic phasor can be a novel method and makes this aim accessible.|$|R
40|$|Thesis (M. Ing. (Computer and Electronical Engineering)) [...] North-West University, Potchefstroom Campus, 2005. Heating, {{ventilating}} and {{air conditioning}} (HVAC) systems consume 43 % of the energy used by buildings. This percentage grows when the HVAC system operates with <b>malfunctions.</b> Fault <b>detection</b> and diagnosis (FDD) methods are developed to reduce abnormal events and down-times and to promote energy saving use of equipment. Most FDD methodologies for HVAC systems {{found in the literature}} revolve around first principle models and mathematical models. This dissertation describes a FDD solution based on process history data and artificial neural network (ANN) models. ANN models, of HVAC components, are built from fault-free operation data. Faulty data are then used with the ANN models to build various residuals and statistical residual transformations. From these residuals, unique residual patterns are assigned to discern between a variety of malfunctions. This FDD strategy is, firstly, applied to a static pressure control loop and secondly, applied to the overall power consumption of an HVAC system. In both studies, the FDD system successfully detected and classified unwanted anomalies - some deviating as little as 5 % from normal operational standards. Finally, the FDD system is rated according to a common set of criteria reviewed in the literature study. This criterion shows the FDD strategy to be robust and adaptable, with low modelling and computational requirements. Master...|$|R
40|$|The {{determination}} of abnormal behavior at process industries gains increasing interest as strict regulations and highly competitive operation conditions are regularly applied at the process systems. A synergetic approach in exploring {{the behavior of}} industrial processes is proposed, targeting at the discovery of patterns and implement fault <b>detection</b> (<b>malfunction)</b> diagnosis. The patterns are based on highly correlated time series. The concept {{is based on the}} fact that if independent time series are combined based on rules, we can extract scenarios of functional and non-functional situations so as to monitor hazardous procedures occurring in workplaces. The selected methods combine and apply actions on historically stored, experimental data from a chemical pilot plant, located at CERTH/CPERI. The implementation of the clustering and classification methods showed promising results of determining with great accuracy (97 %) the potential abnormal situations...|$|R
40|$|Developments in {{communications}} systems, computer systems, and power distribution {{systems for the}} space shuttle are described. The use of high speed delta modulation for bit rate compression in the transmission of television signals is discussed. Simultaneous Multiprocessor Organization, an approach to computer organization, is presented. Methods of computer simulation and automatic <b>malfunction</b> <b>detection</b> for the shuttle power distribution system are also described...|$|E
40|$|In this project, {{the authors}} {{investigated}} the dynamics {{and reliability of}} a brake control system using a test bench which is a Lincoln Town Car brake system. The objectives of the project are to: 1) experimentally characterize the brake system; 2) obtain good nonlinear models of the brake system; 3) perform reliability analysis of the brake control system; and, 4) develop algorithms for brake <b>malfunction</b> <b>detection</b> and brake reliability enhancement. By using the brake test bench, the dynamic characteristics of the brake-actuator system are studied experimentally. Based on the experimental results, two models are obtained {{for the first time}} - one for the whole brake-actuator system, the other for the hydraulic actuator. Efficient controllers are then designed to cancel the nonlinearities in the brake system. Through extensive experiments, algorithms for the <b>malfunction</b> <b>detection</b> have been developed. Additionally, the feasibility of the brake control system to Advanced Vehicle Control Systems (AVCS) applications has been investigated. Automobile driving [...] Braking [...] Automation, Automobile driving [...] Braking [...] Mathematical models, Automobiles [...] Automatic control...|$|E
30|$|The {{paper has}} a {{technical}} contribution by implementing the scientific theory of distributed parameter systems with the linear and non-linear estimation techniques for a practical application using intelligent wireless sensor networks. This approach {{may be seen}} as a new technology based on specific estimation algorithms, using the sensor network as a “distributed” sensor place in the field of the distributed parameter systems, with application in the development of methods for monitoring, fault detection and diagnosis, and sensor <b>malfunction</b> <b>detection.</b>|$|E
40|$|Slow-flow venous {{pressure}} for detection of arterviovenous graft <b>malfunction.</b> BackgroundEarly <b>detection</b> with elective intervention of malfunctioning arteriovenous (AV) grafts improves access viability. Herein, we evaluated outlet {{venous pressure}} (OP), normalized by mean arterial blood pressure (MABP), at varying blood flow (Qb) {{rates in the}} detection of venous outlet stenosis. MethodsThis single-center, observational study included stable dialysis patients with polytetrafluoroethylene (PTFE) AV grafts. Phase I involved {{the determination of the}} optimal Qb (0, 50, 250, or 400 mL/min) and threshold OP/MABP. Sixty-one patients were followed up for 6 months. The primary end point was graft thrombosis. Phase II assessed serial slow-flow pressure (SFpr = OP/MABP at Qb of 50 mL/min) in a larger sample size (N = 152). The primary end point was graft thrombosis. Phase III implemented the use of SFpr monitoring in the detection and correction of outlet lesion(s). ResultsIn phase I, 21 patients developed graft thrombosis. The most significant difference in pressure between the functioning and thrombosed grafts was at Qb of 0 mL/min and SFpr. The threshold of OP/MABP at Qb 0 (> 0. 53) and SFpr (> 0. 6) were predictive of graft thrombosis. In phase II, 37 of 42 patients with graft thrombosis had SFpr> 0. 6 (sensitivity 88. 1 %; specificity 97. 2 %; positive and negative predictive values were 90. 2 % and 95. 5 %, respectively). In phase III, 13 patients with SFpr> 0. 6 had outlet lesions on angiography. ConclusionSerial SFpr used in conjunction with angiography and angioplasty provides a strategy for reducing the incidence of thrombosis. This technique has comparable sensitivity and specificity to other existing methods. This technique is both time-efficient and cost-effective...|$|R
40|$|Free-electron lasers (FELs) {{opened a}} new window on imaging the motion of atoms and molecules. At SLAC, FEL {{experiments}} are performed at LCLS using 120 Hz pulses with 10 ^ 12 to 10 ^ 13 photons in 10 fs (billions of times brighter than at the most powerful synchrotrons). Concurrently, users and staff operate under high pressure due to flexible and often rapidly changing setups and low tolerance for system <b>malfunction.</b> This extreme <b>detection</b> environment raises unique challenges, from obvious to surprising, and leads to treating detectors as consumables. We discuss in detail the detector damage mechanisms observed in 7 years of operation at LCLS, together with the corresponding damage mitigation strategies and their effectiveness. Main types of damage mechanisms already identified include: (1) x-ray radiation damage (from "catastrophic" to "classical"), (2) direct and indirect damage caused by optical lasers, (3) sample induced damage, (4) vacuum related damage, (5) high-pressure environment. In total, 19 damage mechanisms have been identified. We also present general strategies for reducing damage risk or minimizing the impact of detector damage on the science program. These include availability of replacement parts and skilled operators and also careful planning, incident investigation resulting in updated designs, procedures and operator training. Comment: 10 pages, 6 figures, 2 table...|$|R
40|$|Regrettably, {{buildings}} {{often do}} not perform as expected or wanted by the users. Especially with regard to indoor environment, dissatisfaction is occurring frequently. Based on an investigation of two office building projects, an analysis of causes for the mismatch between user requirements/expectations {{and the performance of}} buildings and systems has been made. The investigation consisted of an analysis of the development of building and systems, based on documents and contracts, an interview of the building manager, an occupant questionnaire, measurements, calculations and interviews with stakeholders. The early design stage (pre-design) and the handing over of the building are found to be critical for the performance of the building (including systems) with regard to indoor environment. Due to assuming a fixed user pattern of the building the chosen concept for the building and systems often is not able to cope with changes during the use of the building. It is proposed to exchange this traditional approach for a ‘strategic’ design concept, wherein flexibility of the design is the main goal. In the handing over phase, there is not sufficient monitoring of the functioning of the HVAC system, resulting in insufficient tuning of the system and late reaction on <b>malfunctioning.</b> Automatic fault <b>detection</b> and diagnosis using a Building Management System could {{play an important role in}} the monitoring of the HVAC system...|$|R
40|$|Data center {{networks}} encode locality and topology {{information into}} their server and switch addresses for performance and routing purposes. For this reason, the traditional address configuration protocols such as DHCP require {{a huge amount}} of manual input, leaving them error-prone. In this paper, we present DAC, a generic and automatic Data center Address Configuration system. With an automatically generated blueprint that defines the connections of servers and switches labeled by logical IDs, e. g., IP addresses, DAC first learns the physical topology labeled by device IDs, e. g., MAC addresses. Then, at the core of DAC is its device-to-logical ID mapping and <b>malfunction</b> <b>detection.</b> DAC makes an innovation in abstracting the device-to-logical ID mapping to the graph isomorphism problem and solves it with low time complexity by leveraging the attributes of data center network topologies. Its <b>malfunction</b> <b>detection</b> scheme detects errors such as device and link failures and miswirings, including the most difficult case where miswirings do not cause any node degree change. We have evaluated DAC via simulation, implementation, and experiments. Our simulation results show that DAC can accurately find all the hardest-to-detect malfunctions and can autoconfigure a large data center with 3. 8 million devices in 46 s. In our implementation, we successfully autoconfigure a small 64 -server BCube network within 300 ms and show that DAC is a viable solution for data center autoconfiguration...|$|E
40|$|Abstract. A traffic {{performance}} measurement system, PeMS, currently {{functions as a}} statewide repository for traffic data gathered by thousands of automatic sensors. It has integrated data collection, processing and communications infrastructure with data storage and analytical tools. In this paper, we discuss statistical issues that have emerged as we attempt to process a data stream of 2 GB per day of wildly varying quality. In particular, we focus on detecting sensor malfunction, imputation of missing or bad data, estimation of velocity and forecasting of travel times on freeway networks. Key words and phrases: ATIS, freeway loop data, speed estimation, <b>malfunction</b> <b>detection.</b> 1...|$|E
40|$|Abstract—Data center {{networks}} encode locality and topology {{information into}} their server and switch addresses for performance and routing purposes. For this reason, the traditional address configuration protocols such as DHCP require {{huge amount of}} manual input, leaving them error-prone. In this paper, we present DAC, a generic and automatic Data center Address Configuration system. With an automatically generated blueprint which defines the connections of servers and switches labeled by logical IDs, e. g., IP addresses, DAC first learns the physical topology labeled by device IDs, e. g., MAC addresses. Then {{at the core of}} DAC is its device-to-logical ID mapping and <b>malfunction</b> <b>detection.</b> DAC makes an innovation in abstracting the device-to-logical ID mapping to the graph isomorphism problem, and solves it with low time-complexity by leveraging the attributes of data center network topologies. Its <b>malfunction</b> <b>detection</b> scheme detects errors such as device and link failures and miswirings, including the most difficult case where miswirings do not cause any node degree change. We have evaluated DAC via simulation, implementation and experiments. Our simulation results show that DAC can accurately find all the hardest-to-detect malfunctions and can autoconfigure a large data center with 3. 8 million devices in 46 seconds. In our implementation, we successfully autoconfigure a small 64 -server BCube network within 300 milliseconds and show that DAC is a viable solution for data center autoconfiguration. Index Terms—Data center networks, Address configuration, Graph isomorphis...|$|E
40|$|Thesis (Master's) [...] University of Washington, 2014 The {{focus of}} the work {{contained}} in this thesis is missing data treatments in traffic loop detector datasets. This work is motivated {{by the need to}} improve data quality and coverage for performance reporting and system management decisions. Missing data, whether due to hardware <b>malfunction</b> or error <b>detection</b> and removal, is a critical concern in loop detector data quality control in Washington State and elsewhere, and can quickly become the controlling factor in overall data quality as the rate of missingness increases. First, the various causal factors and resulting patterns of missingness in loop detector datasets are discussed with respect to the assumptions underlying common missing data treatments. Next, two multiple imputation methodologies are introduced for loop detector data, which have seen use in a number of fields but have not yet been applied to traffic data. These methods are {{able to take advantage of}} the various spatial correlation structures present in volume and speed data, and can produce reliable imputation even under high rates of missingness and missing entire days and months. The proposed imputation algorithms are demonstrated in different locations, time periods, and missing data patterns, and are shown to be capable of reliably representing the statistical properties of the true data. Aggregation levels, model structure, and limitations of the proposed methods are discussed, and some guidelines for implementation are presented. The proposed algorithms are designed to be incorporated into a comprehensive quality control process for traffic data, to be implemented as part of the STAR Lab DRIVE Net data analysis, visualization, and dissemination platform...|$|R
40|$|Anomaly {{detection}} methods {{are used in}} a wide variety of fields to extract important information (e. g. credit card fraud, presence of tumours or sensor <b>malfunctions).</b> Current anomaly <b>detection</b> methods are data- or application specific; a general anomaly detection method would be a useful tool in many situations. In this thesis a general method based on statistics is developed and evaluated. The method includes well-known statistical tools as well as a novel algorithm (sensor profiling) which is introduced in this thesis. The general method makes use of correlations found in complex sensor systems, which consists of several sensor signals. The method is evaluated using real sensor data provided by Volvo Car Corporation. The sensor profiling can be used to find clusters of data with similar probability distributions. It is used to automatically determine the sensor performance across different external conditions. Evaluating the anomaly detection method on a data set with known anomalies in one sensor signal results in 94 % of anomalies detected at 6 % false detection rate. Evaluating the method on additional sensor signals was not done. The sensor profiling revealed conditions where the sensor signal behaves qualitatively and quantitatively different. It is able to do this in data where other commonly used methods, such as regression analysis, fail to extract any information. Sensor profiling may have additional applications beyond anomaly detection as it is able to extract information when other methods can not. To conclude, this thesis presents a seemingly natural method and tool chain to automatically detect anomalies in any sensor data that can be represented as a time series. The performance of this method is still to be proven on a large set of general sensor data, but it shows promise, mainly for sensor systems consisting of several sensor signals...|$|R
40|$|Abstract: When {{operating}} a control loop, the correct {{function of the}} controller depends on data usually acquired from a sensor. A problem may occur when the output information from the sensor is biased. Then <b>malfunction</b> <b>detection</b> of the sensor used for measuring the controlled variable can become a very important task. It is sometimes difficult to detect changes in {{the properties of the}} sensors, because they are not apparent from the control loop behaviour. Although biased sensor output information does not lead to a failure of the control function, we are faced with the problem that, although the control loop seems to be working properly, the consequences of a “small ” malfunction (sensor discredibility) can be substantial and expensive. It is easy to imagine, e. g. a combustion ratio control where deviations from an optimal ratio value have no principal influence on the operation of the device, but late discovery of an increase in harmful emissions may be very costly. Sensor redundancy may not be an acceptable solution if it requires expensive measuring equipment. This paper describes experiments on software sensor discredibility detection as a way that replaces usual hardware redundancy and saves the costs of additional measurements. It also shows the possibility of improving a controlled system by avoiding hidden impreciseness in the control loop operation. The used tools are methods of computational intelligence that are adapted and evaluated in an example application of a level control in a two-tank cascade. Keyords: <b>malfunction</b> <b>detection,</b> evolutionary algorithm, simulated annealing algorithm, software redundanc...|$|E
40|$|A <b>malfunction</b> <b>detection</b> {{system for}} {{detecting}} malfunctions in electrical signal processing circuits is disclosed. Malfunctions of {{a hearing aid}} {{in the form of}} frequency distortion and/or inadequate amplification by the hearing aid amplifier, as well as weakening of the hearing aid power supply are detectable. A test signal is generated and a timed switching circuit periodically applies the test signal to the input of the hearing aid amplifier in place of the input signal from the microphone. The resulting amplifier output is compared with the input test signal used as a reference signal. The hearing aid battery voltage is also periodically compared to a reference voltage. Deviations from the references beyond preset limits cause a warning system to operate...|$|E
40|$|With the {{continuous}} {{development of the}} wireless devices technology, securing wireless sensor networks {{became more and more}} a significant but also a difficult task. In this paper we present our research for a robust and intelligent algorithm dedicated to the discovery of malfunctioning or attacked sensor nodes. Our strategy is focused on neural network predictors based on past and present values obtained from neighboring nodes. Limited resources in terms of computational power, energy, memory and bandwidth impose heavy constraints on functionality of an effective <b>malfunction</b> <b>detection</b> system. For this reason we consider that our algorithm is designed and suitable for execution on the base station level and, by this, it is appropriate even for large-scale sensor networks...|$|E
40|$|The safing and failure-detection expert (SAFE) is a {{prototype}} for a <b>malfunction</b> <b>detection,</b> diagnosis, and safing {{system for the}} atmospheric revitalization subsystem (ARS) in the Space Shuttle orbiter. SAFE, whose knowledge was extracted from expert-provided heuristics and documented procedures, automatically manages all phases of failure handling: detection, diagnosis, testing procedures, and recovery instructions. The SAFE architecture allows it to handle correctly sensor failures and multiple malfunctions. Since SAFE is highly interactive, it {{was used as a}} test bed for the evaluation of various advanced human-computer interface (HCI) techniques. The use of such expert systems in the next generation of space vehicles would increase their reliability and autonomy to levels not achievable before...|$|E
40|$|Hearing aids often develop {{malfunctions}} {{that are}} not detected by the wearer. This is particularly true when the wearers are school-age children. Studies of selected groups showed that from 30 to more than 50 percent of school children were not getting adequate benefit from their hearing aids because of unrecognized malfunctions, usually low or dead batteries. This can be serious because hearing impairment retards a child's educational progress. NASA technology incorporated in the Hearing Aid <b>Malfunction</b> <b>Detection</b> Unit (HAMDU), the device pictured, is expected to provide an effective countermeasure to the childrens' hearing aid problem. A patent license has been awarded to a minority-owned firm, Hopkins International Company, a subsidiary of H. H. Aerospace Design Co., Inc., Elmford, New York. The company plans early commercial availability of its version of the device...|$|E
40|$|Data center {{networks}} encode locality and topology {{information into}} their server and switch addresses for performance and routing purposes. For this reason, the traditional address configuration protocols such as DHCP require {{huge amount of}} manual input, leaving them error-prone. In this paper, we present DAC, a generic and automatic Data center Address Configuration system. With an automatically generated blueprint which defines the connections of servers and switches labeled by logical IDs, e. g., IP addresses, DAC first learns the physical topology labeled by device IDs, e. g., MAC addresses. Then {{at the core of}} DAC is its device-to-logical ID mapping and <b>malfunction</b> <b>detection.</b> DAC makes an innovation in abstracting the device-to-logical ID mapping to the graph isomorphism problem, and solves it with low time-complexity by leveraging the attributes of data center networ...|$|E
40|$|The Gemini-Titan 1 (GT- 1) {{space vehicle}} was {{comprised}} of the Gemini spacecraft and the Gemini launch vehicle. The Gemini launch vehicle is a two-stage modified Titan II ICBM. The major modifications are {{the addition of a}} <b>malfunction</b> <b>detection</b> system and a secondary flight controls system. The Gemini spacecraft, designed to carry a crew of two men on earth orbital and rendezvous missions, was unmanned for the flight reported herein (GT- 1). There were no complete Gemini flight systems on board; however, the C-band transponder and telemetry transmitters were Gemini flight subsystems. Dummy equipment, having a mass and moment of inertia equal to flight system equipment, was installed in the spacecraft. The Spacecraft was instrumented to obtain data on spacecraft heating, structural loading, vibration, sound pressure levels, and temperature and pressure during the launch phase...|$|E
40|$|This paper {{describes}} a novel binary classification method named LASCUS {{that can be}} applied to uneven datasets and sensitive problems such as <b>malfunction</b> <b>detection.</b> Such method aims at filling the gap left by traditional algorithms which have difficulties when coping with unbalanced datasets and are not able to satisfactorily recognize unfrequent patterns. The proposed method is based on the use of a self organizing map (SOM) and of a fuzzy inference system (FIS). The SOM creates a set of clusters to be associated either to frequent or unfrequent situations while the FIS determines such association on the basis of data distribution. The method has been tested on the widely used benchmarking Wisconsin breast cancer database and on two industrial applications. The obtained results, which are discussed in the paper, are encouraging and in line with expectations...|$|E
40|$|Abstract—Signals and {{datasets}} {{that arise}} in physical and engineering applications, as well as social, genetics, biomolecular, and many other domains, are becoming increasingly larger and more complex. In contrast to traditional time and image signals, data in these domains are supported by arbitrary graphs. Signal processing on graphs extends concepts and techniques from traditional signal processing to data indexed by generic graphs. This paper studies the concepts of low and high frequencies on graphs, and low-, high-, and band-pass graph filters. In traditional signal processing, there concepts are easily defined because of a natural frequency ordering that has a physical interpretation. For signals residing on graphs, in general, there is no obvious frequency ordering. We propose a definition of total variation for graph signals that naturally leads to a frequency ordering on graphs and defines low-, high-, and band-pass graph signals and filters. We study the design of graph filters with specified frequency response, and illustrate our approach with applications to sensor <b>malfunction</b> <b>detection</b> and data classification...|$|E
40|$|This article {{presents}} an automatic <b>malfunction</b> <b>detection</b> framework {{based on data}} mining approach to analysis of network event sequences. The considered environment is Long Term Evolution (LTE) for Universal Mobile Telecommunication System (UMTS) with sleeping cell caused by random access channel failure. Sleeping cell problem means unavailability of network service without triggered alarm. The proposed detection framework uses N-gram analysis for identification of abnormal behavior in sequences of network events. These events are collected with Minimization of Drive Tests (MDT) functionality standardized in LTE. Further processing applies dimensionality reduction, anomaly detection with k-nearest neighbor, cross-validation, post-processing techniques and efficiency evaluation. Different anomaly detection approaches proposed in this paper are compared against each other with both classic data mining metrics, such as F-score and receiver operating characteristic curves, and a newly proposed heuristic approach. Achieved results demonstrate that the suggested method {{can be used in}} modern performance monitoring systems for reliable, timely and automatic detection of random access channel sleeping cells. Comment: 26 page...|$|E
40|$|The {{accurate}} {{detection of}} high-frequency transient fault currents in overhead transmission lines {{is the basis}} of <b>malfunction</b> <b>detection</b> and diagnosis. This paper proposes a novel differential winding printed circuit board (PCB) Rogowski coil for the detection of transient fault currents in overhead transmission lines. The interference mechanism of the sensor surrounding the overhead transmission line is analyzed and the guideline for the interference elimination is obtained, and then a differential winding printed circuit board (PCB) Rogowski coil is proposed, where the branch and return line of the PCB coil were designed to be strictly symmetrical by using a joining structure of two semi-rings and collinear twisted pair differential windings in each semi-ring. A serial test is conducted, including the frequency response, linearity, and anti-interference performance as well as a comparison with commercial sensors. Results show that a PCB Rogowski coil has good linearity and resistance to various external magnetic field interferences, thus enabling it to be widely applied in fault-current-collecting devices...|$|E
40|$|Signals and {{datasets}} {{that arise}} in physical and engineering applications, as well as social, genetics, biomolecular, and many other domains, are becoming increasingly larger and more complex. In contrast to traditional time and image signals, data in these domains are supported by arbitrary graphs. Signal processing on graphs extends concepts and techniques from traditional signal processing to data indexed by generic graphs. This paper studies the concepts of low and high frequencies on graphs, and low-, high-, and band-pass graph filters. In traditional signal processing, there concepts are easily defined because of a natural frequency ordering that has a physical interpretation. For signals residing on graphs, in general, there is no obvious frequency ordering. We propose a definition of total variation for graph signals that naturally leads to a frequency ordering on graphs and defines low-, high-, and band-pass graph signals and filters. We study the design of graph filters with specified frequency response, and illustrate our approach with applications to sensor <b>malfunction</b> <b>detection</b> and data classification...|$|E
40|$|Abstract. The faults of {{the marine}} {{mechanicals}} happens suddenly usually cause to loss hugely. So it’s necessary to monitor and analyze {{the condition of the}} machine machines. Now, more and more tools have been applied to the marine mechanicals ’ condition monitoring and fault diagnoses. The spectral analysis technique has been widely used to detect the contents of abrasive metal in the lubricating oil. To mine the spectral data better, a method was put forward, which can be used to build the healthy record and reveal the important information about the operated conditions of the equipment. In the method, the similar information of the principal component in oil was obtained in the stable abrasion of the different friction pairs of equipment. The composition of mechanical and electrical equipment was also gained. The healthy record was created preliminarily according to all the information. In the <b>malfunction</b> <b>detection</b> of the equipment, cooperated with the data of the threshold of oil, the analysis results of spectra can be compared with the healthy record. So, the abnormal abrasion can be judged accurately...|$|E
