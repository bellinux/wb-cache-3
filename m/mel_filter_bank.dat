16|4382|Public
30|$|<b>Mel</b> <b>filter</b> <b>bank</b> {{processing}} The {{range of}} frequencies in the FFT spectrum obtained is very broad. Since {{it is difficult}} to follow a linear scale in case of speech signals, Mel-scale is used for the filtering process. The <b>Mel</b> <b>filter</b> <b>bank</b> consists of a set of overlapping triangular filters applied to compute the weighted sum of filter components approximating the output to a Mel scale. The center frequencies of the Mel-filters are linearly spaced and the band width is fixed on the Mel scale [9].|$|E
40|$|AbstractSpeaker {{identification}} system identifies the person by his/her speech sample. Speaker Identification (SI) system should posses a robust feature extraction unit {{and a good}} classifier. Mel frequency cepstral coefficient (MFCC) is very old feature extraction scheme, which has been regarded as standard set of feature vectors for speaker identification. The <b>mel</b> <b>filter</b> <b>bank</b> used in MFCC method, captures the speaker information more effectively in lower frequencies than higher frequencies. Hence high frequency region characteristics are lost. This problem is solved in the proposed method. The speech signal comprises both voiced and unvoiced segments. The voiced segment includes high energy, low frequency components and unvoiced segment includes low energy, high frequency components. In proposed method, the speech sample is divided into voiced and unvoiced segments. The voiced speech segment is filtered using <b>mel</b> <b>filter</b> <b>bank</b> to generate MFCC from lower frequencies of speech signal and unvoiced speech segment is filtered using inverted <b>mel</b> <b>filter</b> <b>bank</b> to generate IMFCC from higher frequencies of speech signal...|$|E
40|$|An {{important}} {{topic in}} Automatic Speech Recognition (ASR) {{is to reduce}} the effect of noise to achieve a better recognition performance in noisy environments. For noise robust ASR different methods exist and this paper investigates the possibilities of improving and combining existing methods. The existing methods considered are Quantile Based Noise Estimation (QBNE) [1] and Post-Processing (PP) [2]. As an improvement of QBNE, we introduce Adaptive QBNE (AQBNE), which makes the noise estimation algorithm adaptive. Furthermore the feature extraction has been improved, by replacing the standard <b>mel</b> <b>filter</b> <b>bank</b> with a Speech Band Emphasizing filter bank (SBE), which improves the resolution in the speech band. The existing and proposed methods have been tested on the SpeechDat-Car database separately and in various combinations, to reveal how well they combine. SBE generally combined well with all methods, improving recognition performance considerably in all tests. Especially AQBNE with SBE showed an improvement of 27. 98 % compared to an improvement of 14. 99 % for QBNE with <b>mel</b> <b>filter</b> <b>bank.</b> AQBNE with SBE achieved remarkable results under highly mismatched training and test conditions with an 80. 39 % improvement, compared to a 21. 04 % improvement for QBNE with <b>mel</b> <b>filter</b> <b>bank.</b> A combination of QBNE and PP showed no improvement, compared to QBNE without PP. I...|$|E
30|$|The input {{features}} for these individual acoustic models are as described above, namely 128 -dimensional multilingual bottleneck features and 40 -dimensional <b>Mel</b> <b>filter</b> <b>banks</b> with delta and delta-delta derivatives. The target labels are also as mentioned above. All parameters are randomly initialized. The training algorithm {{is the same}} as that for baseline LSTM. We use an initial learning rate of 0.00005 and the momentum of 0.9.|$|R
30|$|<b>Filter</b> <b>banks</b> are {{parameterized}} in {{the frequency}} domain with the frequency center cn, bandwidth sn, gain αn, shape g, and frequency scale p. The result wn is a continuous function defined {{in the frequency}} domain. When p is a linear function, <b>filter</b> <b>banks</b> are uniformly distributed in the frequency domain. However, {{there is a strong}} desire to analyze audio signals similar to human ears, which means a non-linear function named auditory <b>filter</b> <b>banks</b> [18 – 20]. Based on psychoacoustics experiments, three non-linear mappings between the frequency and perceptual domain are commonly used, including the Bark scale [21], ERB scale [22], and Mel scale [23]. The parameters αn, cn, and sn in Eq. 1 represent the frequency properties of wn, which simulate the frequency selectivity in human ears. In [16], g is selected as a gaussian function because of its smoothness and tractability, correspondingly, the <b>Mel</b> <b>filter</b> <b>banks</b> use triangular <b>filters</b> [17]. When g is totally independent and not limited to any specific shape, wn for each filter can be parameterized as a fully connected mapping from all frequency bins to a value.|$|R
40|$|In {{this paper}} we {{investigate}} {{the use of}} noise-robust features characterizing the speech excitation signal as complementary features to the usually considered vocal tract based features for Automatic Speech Recognition (ASR). The proposed Excitation-based Features (EBF) are tested in a state-of-the-art Deep Neural Network (DNN) based hybrid acoustic model for speech recognition. The suggested excitation features ex-pand the set of periodicity features previously considered for ASR, expecting that these features help in a better dis-crimination of the broad phonetic classes (e. g., fricatives, nasal, vowels, etc.). Our experiments on the AMI meeting transcription system showed that the proposed EBF yield a relative word error rate reduction of about 5 % when com-bined with conventional PLP features. Further experiments led on Aurora 4 confirmed the robustness of the EBF to both additive and convolutive noises, with a relative improvement of 4. 3 % obtained by combinining them with <b>mel</b> <b>filter</b> <b>banks.</b> Index Terms — neural networks, automatic speech recog-nition, speech excitation signal 1...|$|R
40|$|The {{sensitivity}} of human ear {{is dependent on}} frequency which is nonlinearly resolved across the audio spectrum. Now to improve the recognition performance in a similar non linear approach requires a front -end design, suggested by empirical evidences. A popular alternative to linear prediction based analysis is therefore filter bank analysis since this provides a much more straightforward route to obtain the desired non-linear frequency resolution. <b>MEL</b> <b>filter</b> <b>bank</b> and BARK filter bank are two popular filter bank analysis techniques. This paper presents FPGA based implementation of <b>MEL</b> <b>filter</b> <b>bank</b> and BARK filter bank with different bandwidths and different signal spectrum ranges. The designs have been implemented using VHDL, simulated and verified using Xilinx 11. 1. For each filter bank, the basic building block is implemented in Spartan 3 E. A comparative study among these two mentioned filter banks is also done in this paper. Comment: 16 pages, 20 figures, 6 tables; International Journal of Artificial Intelligence & Applications (IJAIA), Vol. 3, No. 3, May 201...|$|E
40|$|We {{present a}} {{framework}} to apply Volterra series to analyze multi-layered perceptrons trained {{to estimate the}} posterior probabilities of phonemes in automatic speech recognition. The identified Volterra kernels reveal the spectro-temporal patterns that are learned by the trained system for each phoneme. To demonstrate the applicability of Volterra series, we analyze a multilayered perceptron trained us-ing <b>Mel</b> <b>filter</b> <b>bank</b> energy features and analyze its first order Volterra kernels. Index Terms — Volterra series, multilayered perceptrons, speech recognitio...|$|E
40|$|Processing of {{the speech}} signal in the {{autocorrelation}} domain {{in the context of}} robust feature extraction is based on the following two properties: 1) pole preserving property (the poles of a given (original) signal are preserved in its autocorrelation function), and 2) noise separation property (the autocorrelation function of a noise signal is confined to lower lags, while the speech signal contribution is spread over all the lags in the autocorrelation function, thus providing a way to eliminate noise by discarding lower-lag autocorrelation coefficients). In this paper, we use these properties to derive robust features for automatic speech recognition. We compute the magnitude spectrum of the one-sided higher-lag autocorrelation sequence, process it through a <b>Mel</b> <b>filter</b> <b>bank</b> and parameterise it in terms of Mel Frequency Cepstral Coefficients (MFCCs). Since the proposed method combines autocorrelation domain processing with <b>Mel</b> <b>filter</b> <b>bank</b> analysis, we call the resulting MFCCs, Autocorrelation Mel Frequency Cepstral Coefficients (AMFCCs). Recognition experiments are conducted on the Aurora II database and it is found that the AMFCC representation performs as well as the MFCC representation in clean conditions and provides more robust performance in the presence of background noise. Griffith Sciences, Griffith School of EngineeringNo Full Tex...|$|E
40|$|Although <b>Mel</b> scale <b>filter</b> <b>bank</b> spacing is used {{extensively}} in Automatic Speech Recognition (ASR), {{it will be}} shown in this paper that it provides little benefit over other perceptually motivated frequency warping scales. An MFCC like feature based on the Bark scale is shown to yield similar performance in speech recognition experiments as MFCC. The performance of MFCC and BFCC features are also compared to Uniform Frequency Cepstral Coefficients (UFCC) where it is shown that neither the Mel or Bark scale provide significant advantage over a Uniform scale if training and test conditions are matched...|$|R
40|$|A {{mismatch}} between the training {{data and the}} test condition of an automatic speech recognition system usually deteriorates the recognition performance. Quantile based histogram equalization can increase the system's robustness by approximating the cumulative density function of the current signal and then reducing an eventual mismatch based on this estimate. In a first step each output of the <b>mel</b> scaled <b>filter</b> <b>bank</b> can be transformed independent from the others. This paper will describe an improved version of the algorithm that combines neighboring filter channels. On several databases recorded in real car environment the recognition error rates could be significantly reduced with this new approach...|$|R
40|$|We review briefly the the {{performance}} of auditory processing front ends for an automatic speech recognizer (ASR) in adverse environment. At low SNR, the improvement of auditory model front ends can up to 20 % for speech degraded by white noise and 4 % for real world noise. They are particularly insensitive to broadband spectral distortion. 1. INTRODUCTION The auditory model front ends have been applied widely in speech technology. However, it is still arguable whether an auditory model front end improves {{the performance}} of ASR with undegraded speech. Some experimental results show that auditory model front ends are either compatible to or not perform {{as well as a}} <b>mel</b> scale <b>filter</b> <b>bank</b> (MFB) or short time Fourier transform (STFT) front ends with undegraded speech [2, 6]. On the other hand, some results support that the auditory model front ends help to improve {{the performance of}} ASR and the improvement ranges from 1 % to 5 % [4, 5]. Under the adverse environment, the results are more c [...] ...|$|R
40|$|Abstract—Mel Frequency Cepstral Coefficients (MFCCs) are {{the most}} popularly used speech {{features}} in most speech and speaker recognition applications. In this work, we propose a modified <b>Mel</b> <b>filter</b> <b>bank</b> to extract MFCCs from subsampled speech. We also propose a stronger metric which effectively captures the correlation between MFCCs of original speech and MFCC of resampled speech. It is found that the proposed method of filter bank construction performs distinguishably well and gives recognition performance on resampled speech close to recognition accuracies on original speech. I...|$|E
40|$|Mel Frequency Cepstral Coefficients (MFCCs) are {{the most}} popularly used speech {{features}} in most speech and speaker recognition applications. In this work, we propose a modified <b>Mel</b> <b>filter</b> <b>bank</b> to extract MFCCs from subsampled speech. We also propose a stronger metric which effectively captures the correlation between MFCCs of original speech and MFCC of resampled speech. It is found that the proposed method of filter bank construction performs distinguishably well and gives recognition performance on resampled speech close to recognition accuracies on original speech. Comment: arXiv admin note: substantial text overlap with arXiv: 1410. 690...|$|E
40|$|In large MP 3 databases, {{files are}} {{typically}} generated with different parameter settings, i. e., bit rate and sampling rates. This {{is of concern}} for MIR applications, as encoding difference can potentially confound meta-data estimation and similarity evaluation. In this paper we will discuss the influence of MP 3 coding for the Mel frequency cepstral coeficients (MFCCs). The main {{result is that the}} widely used subset of the MFCCs is robust at bit rates equal or higher than 128 kbits/s, for the implementations we have investigated. However, for lower bit rates, e. g., 64 kbits/s, the implementation of the <b>Mel</b> <b>filter</b> <b>bank</b> becomes an issue...|$|E
40|$|This paper {{focuses on}} a robust feature {{extraction}} algorithm for automatic classification of pathological and normal voices in noisy environments. The proposed algorithm is based on human auditory processing and the nonlinear Teager-Kaiser energy operator. The robust features which labeled Teager Energy Cepstrum Coefficients (TECCs) are computed in three steps. Firstly, each speech signal frame is passed through a Gammatone or <b>Mel</b> scale triangular <b>filter</b> <b>bank.</b> Then, the absolute value of the Teager energy operator of the short-time spectrum is calculated. Finally, the discrete cosine transform of the log-filtered Teager Energy spectrum is applied. This feature is proposed to identify the pathological voices using a developed neural system of multilayer perceptron (MLP). We evaluate the developed method using mixed voice database composed of recorded voice samples from normophonic or dysphonic speakers. In order to show the robustness of the proposed feature in detection of pathological voices at different White Gaussian noise levels, we compare its performance with results for clean environments. The experimental results show that TECCs computed from Gammatone <b>filter</b> <b>bank</b> are more robust in noisy environments than other extracted features, while their performance is practically similar to clean environments...|$|R
40|$|License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. This paper {{focuses on a}} robust feature extraction algorithm for automatic classification of pathological and normal voices in noisy environments. The proposed algorithm is based on human auditory processing and the nonlinear Teager-Kaiser energy operator. The robust features which labeled Teager Energy Cepstrum Coefficients (TECCs) are computed in three steps. Firstly, each speech signal frame is passed through a Gammatone or <b>Mel</b> scale triangular <b>filter</b> <b>bank.</b> Then, the absolute value of the Teager energy operator of the short-time spectrum is calculated. Finally, the discrete cosine transform of the log-filtered Teager Energy spectrum is applied. This feature is proposed to identify the pathological voices using a developed neural system of multilayer perceptron (MLP). We evaluate the developed method using mixed voice database composed of recorded voice samples from normophonic or dysphonic speakers. In order to show the robustness of the proposed feature in detection of pathological voices at different White Gaussian noise levels, we compare its performance with results for clean environments. The experimental results show that TECCs computed from Gammatone <b>filter</b> <b>bank</b> are more robust in noisy environments than other extracted features, while their performance is practically similar to clean environments. 1...|$|R
40|$|Noise robust speech {{recognition}} {{has become an}} important area of research in recent years. The fact that human listeners can recognize speech {{in the presence of}} strong noise inspires researchers to imitate some aspects of human auditory perception in automatic {{speech recognition}}. This has led to sub-band based speech recognition in which the full-band speech is split into several sub-bands and where each sub-band is processed separately. The resulting multi-band features can be combined in various ways for carrying out speech recognition task. Reported results have shown the superiority of this technique for speech recognition in strong noise conditions. In this paper, we will briefly review the multi-band feature extraction. We will then propose a block discrete cosine transform (BDCT) with its kernel transformation matrix being derived from the decomposition of the kernel of the discrete cosine transform (DCT). We show that the BDCT approximates the DCT in keeping information in decorrelating a sequence. When the BDCT is applied to the <b>mel</b> frequency <b>filter</b> <b>bank</b> energies (FBEs) to replace the DCT to convert them to cepstral coefficients, a new kind of MFCCs is yielded. We call these new features Block discrete cosine transform based MFCCs (BMFCCs) and show that a sub-band processing idea is implicit in the BMFCCs since the BDCT automatically divides the mel frequency FBEs into two sub-bands. We will report various speech recognition results using the BMFCCs as well as the comparison with the multi-band MFCCs and fullband MFCCs to elaborate the properties of the BMFCCs. 1...|$|R
40|$|In concatenative text-to-speech (TTS) {{synthesis}} systems unit selection aims {{to reduce}} the number of concatenation points in the synthesized speech and make concatenation joins as smooth as possible. This research considers synthesis of completely new utterances from non-uniform units, whereby the most appropriate units, according to acoustic and phonetic criteria, are selected from a myriad of similar speech database candidates. A Viterbi-style algorithm dynamically selects the most suitable database units from a large speech database by considering concatenation and target costs. Concatenation costs are derived from <b>mel</b> <b>filter</b> <b>bank</b> amplitudes, whereas target costs are considered in terms of the phonemic and phonetic properties of required units. Within subjects and between subjects ANOVA [9] evaluation of listeners' scores showed that the TTS system with this method of unit selection was preferred in 52 % of test sentences...|$|E
40|$|Mel Frequency Cepstral Coefficients (MFCCs) are {{the most}} popularly used speech {{features}} in most speech and speaker recognition applications. In this paper, we study the effect of resampling a speech signal on these speech features. We first derive {{a relationship between the}} MFCC param- eters of the resampled speech and the MFCC parameters of the original speech. We propose six methods of calculating the MFCC parameters of downsampled speech by transforming the <b>Mel</b> <b>filter</b> <b>bank</b> used to com- pute MFCC of the original speech. We then experimentally compute the MFCC parameters of the down sampled speech using the proposed meth- ods and compute the Pearson coefficient between the MFCC parameters of the downsampled speech and that of the original speech to identify the most effective choice of Mel-filter band that enables the computed MFCC of the resampled speech to be {{as close as possible to}} the original speech sample MFCC...|$|E
40|$|It has {{recently}} been shown that normalisation of vocal tract length can significantly increase recognition accuracy in speaker independent automatic speech recognition systems. An inherent difficulty with this technique is in automatically estimating the normalisation parameter from a new speaker's speech and previous techniques have typically relied on an exhaustive search to estimate this parameter. In this paper, we present a method of normalising utterances by a linear warping of the <b>mel</b> <b>filter</b> <b>bank</b> channels in which in which the normalisation parameter is estimated by fitting formant estimates to a probabilistic model. This method is fast, computitionally inexpensive and requires only {{a limited amount of}} data for estimation. It generates normalisations which are close to those which would be found by an exhaustive search. The normalisation is applied to a phoneme recognition task using the TIMIT database and results show a useful improvement over an un-normalised speaker independent system...|$|E
40|$|This paper {{describes}} {{an approach to}} normalize the noise level of a speech signal at the outputs of the <b>Mel</b> scaled <b>filter</b> [...] <b>bank</b> used in MFCC [...] feature extraction. An adaptive normalizing function that distinguishes between speech and silence parts of the signal is used to normalize the noise level, without altering the speech parts of the signal. This technique is combined with an adaptation of the reference vectors, depending on the average norm of the incoming feature vectors. On a database with training data recorded in office environment and testing data recorded in driving cars, the word error rate could be reduced from 35. 5 % to 14. 7 % for the city traffic testing set and from 78. 0 % to 24. 1 % for the highway testing set. 1. INTRODUCTION Noise level normalization (NLN) {{is based on the}} observance, that a combination spectral subtraction (SS) and signal [...] to [...] noise [...] ratio normalization (SNRN) gives better recognition results when the subtraction and normalization are only applied to the [...] ...|$|R
40|$|Oversampled <b>filter</b> <b>banks</b> are {{currently}} being proposed for robust transmission applications. In this paper, we completely characterize multidimensional doubly finite-impulse-response (FIR) <b>filter</b> <b>banks,</b> that is, oversampled <b>filter</b> <b>banks</b> whose dual is FIR. Then, we consider the problem of extending perfect reconstruction critically sampled multidimensional <b>filter</b> <b>banks</b> {{in order to obtain}} doubly FIR (DFIR) <b>filter</b> <b>banks.</b> As a result, very simple criteria for constructing DFIR <b>filter</b> <b>banks</b> as extensions of orthogonal <b>filter</b> <b>banks</b> are obtained. This paper also analyzes the problem of constructing totally FIR <b>filter</b> <b>banks,</b> i. e., DFIR <b>filter</b> <b>banks</b> that remain DFIR even when some channels are removed. It is shown that any totally FIR <b>filter</b> <b>bank</b> can be implemented as the cascade of a critically sampled DFIR <b>filter</b> <b>bank</b> whose number of channels is equal to the subsampling factor, a redundant finite-dimensional transform, and a suitable set of delay...|$|R
30|$|The former {{frequency}} <b>filter</b> <b>banks</b> {{are somehow}} interrelated with the long-term <b>filter</b> <b>banks.</b> Combining {{the idea of}} {{these two types of}} <b>filter</b> <b>banks,</b> future work will be an investigation on two-dimensional <b>filter</b> <b>banks.</b>|$|R
40|$|Since {{emotional}} speech can {{be regarded}} as a variation on neutral (non-emotional) speech, it is expected that a robust neu-tral speech model can be useful in contrasting different emo-tions expressed in speech. This study explores this idea by cre-ating acoustic models trained with spectral features, using the emotionally-neutral TIMIT corpus. The performance is tested with two emotional speech databases: one recorded with a mi-crophone (acted), and another recorded from a telephone ap-plication (spontaneous). It is found that accuracy up to 78 % and 65 % can be achieved in the binary and category emotion discriminations, respectively. Raw <b>Mel</b> <b>Filter</b> <b>Bank</b> (MFB) out-put was found to perform better than conventional MFCC, with both broad-band and telephone-band speech. These results sug-gest that well-trained neutral acoustic models can be effectively used as a front-end for emotion recognition, and once trained with MFB, it may reasonably work well regardless of the chan-nel characteristics...|$|E
40|$|Objective {{speech quality}} {{assessment}} is a challenging task {{which aims to}} emulate human judgment in the complex and time consuming task of subjective assessment. It is difficult to perform {{in line with the}} human perception due the complex and nonlinear nature of the human auditory system. The challenge lies in representing speech signals using appropriate features and subsequently mapping these features into a quality score. This paper proposes a nonintrusive metric for the quality assessment of noise-suppressed speech. The originality of the proposed approach lies primarily in the use of <b>Mel</b> <b>filter</b> <b>bank</b> energies (FBEs) as features and the use of support vector regression (SVR) for feature mapping. We utilize the sensitivity of FBEs to noise in order to obtain an effective representation of speech towards quality assessment. In addition, the use of SVR exploits the advantages of kernels which allow the regression algorithm to learn complex data patterns via nonlinear transformation for an effective and generalized mapping of features into the quality score. Extensive experiments conducted using two third party databases with different noise-suppressed speech signals show the effectiveness of the proposed approach...|$|E
40|$|In this paper, {{a feature}} {{extraction}} method that is robust to additive background noise is proposed for automatic speech recognition. Since the background noise corrupts the autocorrelation coefficients {{of the speech}} signal mostly at the lower-time lags, while the higher-lag autocorrelation coefficients are least affected, this method discards the lower-lag autocorrelation coefficients and uses only the higher-lag autocorrelation coefficients for spectral estimation. The magnitude spectrum of the windowed higher-lag autocorrelation sequence is used here as {{an estimate of the}} power spectrum of the speech signal. This power spectral estimate is processed further (like the well-known Mel frequency cepstral coefficient (MFCC) procedure) by the <b>Mel</b> <b>filter</b> <b>bank,</b> log operation and the discrete cosine transform to get the cepstral coefficients. These cepstral coefficients are referred to as the autocorrelation Mel frequency cepstral coefficients (AMFCCs). We evaluate the speech recognition performance of the AMFCC features on the Aurora and the resource management databases and show that they perform as well as the MFCC features for clean speech and their recognition performance is better than the MFCC features for noisy speech. Finally, we show that the AMFCC features perform better than the features derived from the robust linear prediction-based methods for noisy speech. Griffith Sciences, Griffith School of EngineeringNo Full Tex...|$|E
40|$|This article {{considers}} <b>filter</b> <b>banks</b> for subband coding {{of discrete}} time electrocardiogram (ECG) signals. Two parallel FIR <b>filter</b> <b>banks</b> are optimized and {{compared with a}} classic tree-structured <b>filter</b> <b>bank.</b> The new <b>filter</b> <b>banks</b> give a decrease in signal distortion from 0. 6 to 0. 8 % PRD compared to the reference <b>filter</b> <b>bank...</b>|$|R
40|$|An {{algorithm}} is {{developed for the}} design of complex-valued linear-phase paraunitary <b>filter</b> <b>banks.</b> The designed <b>filter</b> <b>banks</b> have, {{for the first time in}} the design of sub-band <b>filter</b> <b>banks,</b> complex-valued <b>filter</b> responses. The difference between a real-valued and complex-valued linear-phase paraunitary <b>filter</b> <b>bank</b> is that conjugate-centro-symmetric matrices are employed. <b>Filter</b> <b>banks</b> with 8 and 16 channels were presented to validate the algorithm. link_to_subscribed_fulltex...|$|R
50|$|Oversampled <b>filter</b> <b>banks</b> are multirate <b>filter</b> <b>banks</b> {{where the}} number of output samples at the {{analysis}} stage is larger than {{the number of}} input samples. It is proposed for robust applications. One particular class of oversampled <b>filter</b> <b>banks</b> is nonsubsampled <b>filter</b> <b>banks</b> without downsampling or upsampling. The perfect reconstruction condition for an oversampled <b>filter</b> <b>bank</b> can be stated as a matrix inverse problem in the polyphase domain.|$|R
30|$|For {{the design}} of filter bank, the ARCTIC {{database}} is used. The input speech signal sampled at 16 kHz is pre-processed in various stages, such as pre-emphasis, framing, and windowing. The 8 -kHz bandwidth speech frame is decomposed up to four levels by wavelet packet decomposition. This partitions the frequency axis into 16 bands each of 500 -Hz band width. The different frequency bands with the speaker-specific features are further decomposed to get finer resolution than the Mel filter bank[24, 25]. The lower frequency range 0 to 1 kHz captures the fundamental frequency which has maximum energy with most speaker-specific information. Therefore, the lower two bands 0 to 0.5 kHz and 0.5 to 1 kHz is decomposed up to the seventh level. It splits the band of 0 to 1 kHz into 16 sub-bands 62.5 Hz each, which is finer than corresponding bandwidth of Mel filter bank[24]. In addition, the frequency band of 1 to 3 kHz contains the speaker-specific information about {{the first and second}} harmonics of the fundamental frequency[23]. This frequency band carries less speaker-specific information compared to previous lower sub-bands. Therefore, the band of 1 to 2 kHz is decomposed up to six levels and 2 - to 3 -kHz band is decomposed up to five levels. This gives 12 sub-bands with finer frequency resolution than the Mel sub-bands. The frequency band of 4 to 5 kHz related to the invariant part of the vocal tract gives information about the piriform fossa. It holds features suitable for speaker identity. However, the resolution of this frequency range is coarser in Mel filter bank[12]. Therefore, this band is further decomposed up to fifth level. The frequency bands 3 to 4 kHz and 5 to 8 kHz do not require further decomposition as these bands already have a fine frequency resolution than the corresponding bands of <b>Mel</b> <b>filter</b> <b>bank.</b> The significant band decomposition is continued till the substantial energy of the corresponding bands is achieved.|$|E
40|$|A new <b>filter</b> <b>bank</b> {{approach}} for speaker recognition front-end is proposed. The conventional mel-scaled <b>filter</b> <b>bank</b> is {{replaced with a}} speaker-discriminative <b>filter</b> <b>bank.</b> <b>Filter</b> <b>bank</b> is selected from a library in adaptive basis, based on the broad phoneme class of the input frame. Each phoneme class is associated with its own <b>filter</b> <b>bank.</b> Each <b>filter</b> <b>bank</b> is designed {{in a way that}} emphasizes discriminative subbands that are characteristic for that phoneme. Experiments on TIMIT corpus show that the proposed method outperforms traditional MFCC features...|$|R
40|$|The {{theory and}} design of optimal uniform {{orthonormal}} <b>filter</b> <b>banks</b> has been investigated for a long time. It has been proven that the theoretic coding gain of a uniform paraunitary analysis/synthesis <b>filter</b> <b>bank</b> system is maximized {{if and only if}} the <b>filter</b> <b>bank</b> is designed as a principal component <b>filter</b> <b>bank.</b> In this paper, optimal orthonomal wavelet <b>filter</b> <b>banks</b> that can be regarded as a special case of nonuniform orthonomal <b>filter</b> <b>banks</b> are investigated. A major result presented in this paper is that the wavelet <b>filter</b> <b>banks</b> designed with minimum mean- squared error criterion results in maximizing theoretical coding gain in an energy compaction sense. 1...|$|R
40|$|Unitary and nonunitary <b>filter</b> <b>banks</b> with uniform {{frequency}} separation have been extensively {{studied in the}} past. Improvement in coding gain has been achieved when allowing for nonunitary <b>filter</b> <b>banks</b> in image coders. Subjective improvements {{can be achieved by}} employing nonuniform <b>filter</b> <b>banks.</b> The paper presents a method to construct nonuniform nonunitary perfect reconstruction <b>filter</b> <b>banks.</b> A polyphase matrix representation of nonuniform parallel <b>filter</b> <b>banks</b> is given for octave band splitting. In this case, results show that the parallel <b>filter</b> <b>banks</b> tend to become the tree-structured <b>filter</b> <b>banks.</b> It is further shown that the perfect reconstruction property can be met only by examining each stage of the treestructured system in a polyphase matrix representation. Finally, frequency responses are presented when the <b>filter</b> <b>banks</b> are optimized for coding gain. 1. INTRODUCTION Unitary and nonunitary <b>filter</b> <b>banks</b> [1, 2, 3] with uniform {{frequency separation}} are widely employed in subband [...] ...|$|R
40|$|Wavelet {{transforms}} {{provide a}} new technique for time-scale analysis of non-stationary signals. Wavelet analysis uses orthonormal bases in which computations can be done efficiently with multirate systems known as <b>filter</b> <b>banks.</b> This thesis develops a comprehensive set of tools for (multidimensional) multirate signal analysis and uses them to investigate two multirate systems: <b>filter</b> <b>banks</b> and transmultiplexers. Several results in <b>filter</b> <b>bank</b> theory are obtained: a new parameterization of unitary <b>filter</b> <b>banks,</b> a theory of modulated <b>filter</b> <b>banks,</b> a theory of <b>filter</b> <b>banks</b> with symmetry restrictions, reduction of the multidimensional rational sampling rate <b>filter</b> <b>bank</b> problem to the uniform sampling rate <b>filter</b> <b>bank</b> problem, solution to the completion problem for <b>filter</b> <b>banks</b> (by reducing it to the (YJBK) parameterization problem in control theory) etc. Perfect reconstruction <b>filter</b> <b>banks</b> are shown to give structured decompostions of separable Hilbert spaces. <b>Filter</b> <b>banks</b> are used to construct several classes of wavelet bases: multiplicity M wavelet tight frames and frames, regular multiplicity M orthonormal bases, modulated wavelet tight frames etc. The thesis describes the design of optimal wavelets for signal representation and the wavelet sampling theorem. Application of wavelets in signal interpolation and in the approximation of linear-translation invariant operators is investigated...|$|R
40|$|AbstractWe {{first show}} that by {{combining}} monodimensional <b>filter</b> <b>banks</b> one can obtain nonseparable <b>filter</b> <b>banks.</b> We then give necessary conditions for these <b>filter</b> <b>banks</b> to generate orthonormal and regular wavelets. Finally, we establish {{that some of}} these <b>filter</b> <b>banks</b> lead to arbitrarily smooth, nonseparable, orthonormal, compactly supported wavelet bases...|$|R
