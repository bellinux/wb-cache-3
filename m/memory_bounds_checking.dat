0|1543|Public
40|$|Part 7 : Software Security and PrivacyInternational audienceUnsafe {{memory accesses}} in {{programs}} written using popular programming languages like C and C++ {{have been among}} the leading causes of software vulnerability. Memory safety checkers, such as Softbound, enforce memory spatial safety by checking if accesses to array elements are within the corresponding array <b>bounds.</b> However, such <b>checks</b> often result in high execution time overhead due to the cost of executing the instructions associated with the <b>bound</b> <b>checks.</b> To mitigate this problem, techniques to eliminate redundant <b>bound</b> <b>checks</b> are needed. In this paper, we propose a novel framework, SIMBER, to eliminate redundant <b>memory</b> <b>bound</b> <b>checks</b> via statistical inference. In contrast to the existing techniques that primarily rely on static code analysis, our solution leverages a simple, model-based inference to identify redundant <b>bound</b> <b>checks</b> based on runtime statistics from past program executions. We construct a knowledge base containing sufficient conditions using variables inside functions, which are then applied adaptively to avoid future redundant checks at a function-level granularity. Our experimental results on real-world applications show that SIMBER achieves zero false positives. Also, our approach reduces the performance overhead by up to 86. 94 % over Softbound, and incurs a modest 1. 7 % code size increase on average to circumvent the redundant <b>bound</b> <b>checks</b> inserted by Softbound...|$|R
50|$|Except {{the extreme}} case with , all the {{security}} vulnerabilities {{can be avoided}} by introducing auxiliary code to perform <b>memory</b> management, <b>bounds</b> <b>checking,</b> input checking, etc. This is often done {{in the form of}} wrappers that make standard library functions safer and easier to use. This dates back to as early as The Practice of Programming book by B. Kernighan and R. Pike where the authors commonly use wrappers that print error messages and quit the program if an error occurs.|$|R
40|$|WWW home page:[URL] Abstract. Reconfigurable {{processors}} pose unique {{problems for}} program safety {{because of their}} use of computational approaches {{that are difficult to}} integrate into traditional program analyses. The combination of proof-carrying code for verification of standard processor machine code and model-checking for array configurations is explored. This combination extends proof-carrying code to provide a context for model checking, but uses standard model checking technology. This approach is shown to be useful in verifying safety properties including the synchronization of memory access by the reconfigurable array and <b>memory</b> access <b>bounds</b> <b>checking.</b> ...|$|R
50|$|In {{computer}} science, a smart pointer is {{an abstract}} data type that simulates a pointer while providing added features, such as automatic <b>memory</b> management or <b>bounds</b> <b>checking.</b> Such features are intended to reduce bugs caused by the misuse of pointers, while retaining efficiency. Smart pointers typically {{keep track of the}} memory they point to, and may also be used to manage other resources, such as network connections and file handles. Smart pointers originated in the programming language C++.|$|R
40|$|Introduction One of {{the most}} widely {{recognized}} inadequacies of C is its low-level treatment of arrays. Arrays are not first-class objects in C; an array name in an expression almost always decays into a pointer to the underlying type. This is unfortunate, especially since an increasing number of high-performance computers are optimized for calculations involving arrays of numbers. On such machines, double[] may be regarded as an intrinsic data type comparable to double or int and quite distinct from double*. This weakness of C is acknowledged in the ARM [4], where it is suggested that the inadequacies of the C array can be overcome in C++ by wrapping it in a class that supplies dynamic <b>memory</b> management, <b>bounds</b> <b>checking,</b> operator syntax, and other useful features. Such "smart arrays" can in fact supply the same functionality as the first-class arrays found in other high-level, general-purpose programming langua...|$|R
40|$|Baggy <b>Bounds</b> <b>Checking</b> is a backward-compatible {{defense against}} out-of-bounds errors. It is {{reported}} as being {{faster than any}} previous <b>bounds</b> <b>checking</b> tool. However, it enforces allocation bounds instead of object bounds and thus cannot detect memory errors that are in padding areas. In this paper, we present BBAC: a technique that extends Baggy <b>Bounds</b> <b>Checking</b> to enforce accurate <b>bounds</b> <b>checking.</b> The key insight behind our approach is to store the object size {{at the end of}} the padding area, making it efficient to lookup object bounds meta-data at runtime. We show experimentally that BBAC can detect more memory errors than Baggy <b>Bounds</b> <b>Checking.</b> Our experiments also show that BBAC only adds an additional 4. 39 % performance overhead over the original Baggy <b>Bounds</b> <b>Checking</b> technique for the Olden benchmarks and 2 x overhead at most on the real-world applications we tested. © 2012 IEEE. Baggy <b>Bounds</b> <b>Checking</b> is a backward-compatible defense against out-of-bounds errors. It is reported as being faster than any previous <b>bounds</b> <b>checking</b> tool. However, it enforces allocation bounds instead of object bounds and thus cannot detect memory errors that are in padding areas. In this paper, we present BBAC: a technique that extends Baggy <b>Bounds</b> <b>Checking</b> to enforce accurate <b>bounds</b> <b>checking.</b> The key insight behind our approach is to store the object size {{at the end of the}} padding area, making it efficient to lookup object bounds meta-data at runtime. We show experimentally that BBAC can detect more memory errors than Baggy <b>Bounds</b> <b>Checking.</b> Our experiments also show that BBAC only adds an additional 4. 39 % performance overhead over the original Baggy <b>Bounds</b> <b>Checking</b> technique for the Olden benchmarks and 2 x overhead at most on the real-world applications we tested. © 2012 IEEE...|$|R
40|$|We {{analyze the}} {{performance}} of different <b>bounds</b> <b>checking</b> implementations. Specifically, we examine using the x 86 bound instruction to reduce the run-time overhead. We also propose a compiler optimization that prunes the <b>bounds</b> <b>checks</b> that are not necessary to guarantee security. The optimization {{is based on the}} observation that buffer overflow attacks are launched through external inputs. Therefore, it is sufficient to <b>bounds</b> <b>check</b> only the accesses to those data structures that can possibly hold the external inputs. Also, it is sufficient to <b>bounds</b> <b>check</b> only the <b>memory</b> writes. The proposed optimizations reduce the number of required <b>bounds</b> <b>checks</b> as well as the amount of meta-data that need to be maintained to perform those checks. ...|$|R
50|$|Because {{performing}} <b>bounds</b> <b>checking</b> during every usage is time-consuming, it is {{not always}} done. Bounds-checking elimination is a compiler optimization technique that eliminates unneeded <b>bounds</b> <b>checking.</b>|$|R
40|$|Buffer {{overflows}} {{affect a}} large installed base of C code. This technical note describes {{the criteria for}} deploying a compiler-based memory safety checking tool and the performance {{that can be achieved}} with two such tools whose source code is freely available. The note then describes a modification to the LLVM compiler to enable hoisting <b>bounds</b> <b>checks</b> from loops and functions. This proof-of-concept prototype has been used to demonstrate how these optimizations can be performed reliably on <b>bounds</b> <b>checks</b> to improve their performance. However, the performance of bounds propagation is the dominant cost, and the overall runtime cost for <b>bounds</b> <b>checking</b> for C remains expensive, even after these optimizations are applied. Nevertheless, optimized <b>bounds</b> <b>checks</b> are adequate for non-performance-critical applications, and improvements in processor technology may allow optimized <b>bounds</b> <b>checking</b> to be used with performance-critical applications...|$|R
5000|$|... string-manipulation routines, {{including}} [...] and , {{for lack}} of <b>bounds</b> <b>checking</b> and possible buffer overflows if the <b>bounds</b> aren't <b>checked</b> manually; ...|$|R
40|$|The {{ability to}} check memory {{references}} against their associated array/buffer bounds helps programmers to detect programming errors involving address overruns {{early on and}} thus avoid many difficult bugs down the line. This paper proposes a novel approach called Cash to the array <b>bound</b> <b>checking</b> problem that exploits the segmentation feature in the virtual memory hardware of the X 86 architecture. The Cash approach allocates a separate segment to each static array or dynamically allocated buffer, and generates the instructions for array references {{in such a way}} that the segment limit check in X 86 ’s virtual memory protection mechanism performs the necessary array <b>bound</b> <b>checking</b> for free. In those cases that hardware <b>bound</b> <b>checking</b> is not possible, it falls back to software <b>bound</b> <b>checking.</b> As a result, Cash does not need to pay per-reference software checking overhead in most cases. However, the Cash approach incurs a fixed set-up overhead for each use of an array, which may involve multiple array references. The existence of this overhead requires compiler writers to judiciously apply the proposed technique to minimize the performance cost of array <b>bound</b> <b>checking.</b> This paper presents the detailed design and implementation of the Cash compiler, and a comprehensive evaluation of various performance tradeoffs associated with the proposed array <b>bound</b> <b>checking</b> technique. For the set of complicated network applications we tested, including Apache, Sendmail, Bind, etc., the latency penalty of Cash’s <b>bound</b> <b>checking</b> mechanism is between 2. 5 % to 9. 8 % when compared with the baseline case that does not perform any <b>bound</b> <b>checking.</b> ...|$|R
40|$|Buffer {{overflow}} attacks {{cause serious}} security problems. Array & pointer <b>bound</b> <b>checking</b> {{is one of}} the most effective approaches for defending against buffer overflow attacks when source code is available. However; original array & pointer <b>bound</b> <b>checking</b> causes too much overhead since it is designed to catch memory errors and it puts too many checks. In this paper, we propose an efficient array & pointer <b>bound</b> <b>checking</b> strategy to defend against buffer overflow attacks. In our strategy, only the bounds of write operations are checked. We discuss the optimization strategy via hardware/software and conduct experiments. The experimental results show that our strategy can greatly reduce the overhead of array & pointer <b>bound</b> <b>checking.</b> Our conclusion is that based on our strategy, array & pointer <b>bound</b> <b>checking</b> can be a practical solution for defending systems against buffer overflow attacks with tolerable overhead. Department of ComputingRefereed conference pape...|$|R
40|$|Abstract—Providing spatial {{safety of}} memory accesses {{has been one}} of the main {{concerns}} for the security of programs written in C/C++. Most of the existing approaches to handling spatial memory errors either fail to solve the runtime overhead issues or cannot provide the complete solution for memory protection. Moreover, none of the previous work considers multithread workloads running in multiprocessor systems. In this paper, we attempt to provide an architectural support for fast and efficient <b>bounds</b> <b>checking</b> for multithread workloads in chip-multiprocessor (CMP) environments. Bounds information sharing and smart tagging help to perform <b>bounds</b> <b>checking</b> more effectively utilizing the characteristics of a pointer. Also, the BCache architecture allows fast access to the bounds information. Simulation results show that the proposed scheme reduces the average miss latency of bounds information by 49 % as well as reducing µPC of memory operations by 29 % on average compared to the previous hardware scheme. Keywords-architecture; chip-multiprocessor; security; <b>memory</b> attacks; <b>bounds</b> checking; I...|$|R
5000|$|The Java {{language}} requires specific {{behavior in}} the case of an out-of-bounds array access, which generally requires <b>bounds</b> <b>checking</b> of array accesses. This eliminates a possible source of instability but usually at the cost of slowing execution. In some cases, especially since Java 7, compiler analysis can prove a <b>bounds</b> <b>check</b> unneeded and eliminate it. C++ has no required behavior for out-of-bounds access of native arrays, thus requiring no <b>bounds</b> <b>checking</b> for native arrays. C++ standard library collections like std::vector, however, offer optional <b>bounds</b> <b>checking.</b> In summary, Java arrays are [...] "usually safe; slightly constrained; often have overhead" [...] while C++ native arrays [...] "have optional overhead; are slightly unconstrained; are possibly unsafe." ...|$|R
40|$|Interest {{in using}} Java for {{high-performance}} parallel computing {{has increased in}} recent years. One obstacle that has inhibited Java from widespread acceptance {{in the scientific community}} is the language requirement that all array accesses must be checked to ensure they are within bounds. In practice, array <b>bounds</b> <b>checking</b> in scientific applications may increase execution time by more than a factor of 2. Previous research has explored optimizations to statically eliminate <b>bounds</b> <b>checks,</b> but the dynamic nature of many scientific codes makes this difficult or impossible. Our approach is instead to create a new Java implementation that does not generate explicit <b>bounds</b> <b>checks.</b> It instead places arrays inside of Index Confinement Regions (ICRs), which are large, isolated, mostly unmapped virtual memory regions. Any array reference outside of its bounds will cause a protection violation; this provides implicit <b>bounds</b> <b>checking.</b> Our results show that our new Java implementation reduces the overhead of <b>bounds</b> <b>checking</b> from an average of 63 % to an average of 9 % on our benchmarks...|$|R
50|$|<b>Bounds</b> <b>checking</b> is a compiler-based {{technique}} that adds run-time bounds information for each allocated block of memory, and checks all pointers against those at run-time. For C and C++, <b>bounds</b> <b>checking</b> {{can be performed}} at pointer calculation time or at dereference time.|$|R
40|$|Abstract. The {{ability to}} check memory {{references}} against their associated array/buffer bounds helps programmers to detect programming errors involving address overruns {{early on and}} thus avoid many difficult bugs down the line. This paper proposes a novel approach called Boud to the array <b>bounds</b> <b>checking</b> problem that exploits the debug register hardware in modern CPUs. Boud allocates a debug register to monitor accesses to an array or buffer within a loop so that accesses stepping outside the array’s or buffer’s bound will trigger a breakpoint exeption. Because the number of debug registers is typically small, in cases when hardware <b>bounds</b> <b>checking</b> is not possible, Boud falls back to software <b>bounds</b> <b>checking.</b> Although Boud can effectively eliminate perarray-reference software checking overhead in most cases, it still incurs a fixed set-up overhead for each use of an array within a loop. This paper presents the detailed design {{and implementation of the}} Boud compiler, and a comprehensive evaluation of various performance tradeoffs associated with the proposed array <b>bounds</b> <b>checking</b> technique. For the set of real-world network applications we tested, including Apache, Sendmail, Bind, etc., the latency penalty of Boud’s <b>bounds</b> <b>checking</b> mechanism is between 2. 2 % to 8. 8 %, respectively, when compared with the vanilla GCC compiler, which does not perform any <b>bounds</b> <b>checking.</b> ...|$|R
40|$|Compiler {{optimization}} {{technology has}} been steadily advancing as more sophisticated processors hit the market. For high end embedded processors, today’s most advanced compilers take advantage of both CPU specific and application specific information to optimize code intelligently for optimal result. This paper discusses one such sophisticated optimization technique which combines array <b>bound</b> <b>check</b> optimization together with redundancy elimination combined with folding. The array <b>bound</b> <b>check</b> optimization described in this paper reduces the run time overhead by eliminating unnecessary <b>bound</b> <b>checks.</b> The results and comparisons demonstrate number of advantages of this method over the existing methods...|$|R
40|$|To {{guarantee}} execution, Java {{and other}} strongly typed languages require <b>bounds</b> <b>checking</b> of array accesses. Because <b>bounds</b> <b>checks</b> may raise exceptions, they block code motion of instructions with side effects, thus preventing many useful code optimizations, such as partial redundancy elimination or instruction scheduling of memory operations. Furthermore, {{because it is}} not expressible at level, the elimination of <b>bounds</b> <b>checks</b> can only be performed at run time, after the program is loaded. Using existing powerful bounds-check optimizers at run time is not feasible, however, because they are too heavyweight for the dynamic compilation setting. ABCD is a light-weight algorithm for elimination of &ray Checks on Demand. Its design emphasizes simplicity and efficiency. In essence, ABCD works by adding a few edges to the SSA value graph and performing a simple traversal of the graph. Despite its simplicity, ABCD is surprisingly powerful. On our benchmarks, ABCD removes on average 45 % of dynamic <b>bound</b> <b>check</b> instructions, sometimes achieving near-ideal optimization. The efficiency of ABCD stems from two factors. First, ABCD works on a representation. As a result, it requires on average fewer than 10 simple analysis steps per <b>bounds</b> <b>check.</b> Second, ABCD is demand-driven. It can be applied to a set of frequently executed (hot) <b>bounds</b> <b>checks,</b> which makes it suitable for the dynamic-compilation setting, in which compile-time cost is constrained but hot statements are known...|$|R
5000|$|... "Fat" [...] {{pointers}} support pointer arithmetic with run-time <b>bounds</b> <b>checking</b> ...|$|R
2500|$|Assembly and C/C++ {{are popular}} {{programming}} languages that {{are vulnerable to}} buffer overflow, {{in part because they}} allow direct access to memory and are not strongly typed. C provides no built-in protection against accessing or overwriting data in any part of memory; more specifically, it does not check that data written to a buffer is within the boundaries of that buffer. The standard C++ libraries provide many ways of safely buffering data, and C++'s Standard Template Library (STL) provides containers that can optionally perform <b>bounds</b> <b>checking</b> if the programmer explicitly calls for checks while accessing data. For example, a vector's member function at (...) performs a <b>bounds</b> <b>check</b> and throws an out_of_range exception if the <b>bounds</b> <b>check</b> fails. However, C++ behaves just like C if the <b>bounds</b> <b>check</b> is not explicitly called. Techniques to avoid buffer overflows also exist for C.|$|R
40|$|Abstract. We {{present a}} {{high-level}} approach to array <b>bound</b> <b>check</b> op-timization that is neither hampered by recursive functions, nor disabled {{by the presence}} of partially redundant checks. Our approach combines a forward analysis to infer precise contextual constraint at designated pro-gram points, and a backward method for deriving a safety pre-condition for each <b>bound</b> <b>check.</b> Both analyses are formulated {{with the help of a}} practical constraint solver based on Presburger formulae; resulting in an accurate and fully automatable optimization. The derived pre-conditions are also used to guide <b>bound</b> <b>check</b> specialization, for the purpose of elim-inating partially redundant checks. ...|$|R
5000|$|Pointer {{manipulation}} of buffers that {{may interfere with}} later <b>bounds</b> <b>checking,</b> e.g.: ...|$|R
40|$|<b>Bound</b> <b>checks</b> are {{introduced}} in {{programs for the}} run-time detection of array bound violations. Compiletime optimizations are employed to reduce the execution time overhead due to <b>bound</b> <b>checks.</b> The optimizations reduce the program execution time through elimination of checks and propagation of checks out of loops. An execution of the optimized program terminates with an array bound violation {{if and only if}} the same outcome would have resulted during the execution of the program containing all array <b>bound</b> <b>checks.</b> However, {{the point at which the}} array bound violation occurs may not be the same. Experimental results indicate that the number of <b>bound</b> <b>checks</b> performed during the execution of a program is greatly reduced using these techniques. Categories and Subject Descriptors: D. 2. 5 [Software Engineering]: Testing and Debugging-error handling and recovery; D. 3. 4 [Programming Languages]: Processors-optimization, compilers. General Terms: Languages, Reliability Additional Key Words and Phrase [...] ...|$|R
40|$|ABSTRACTArray <b>bound</b> <b>checking</b> is {{critical}} for code safety and debugging but users {{are not ready to}} trade much execution time forit. A considerable research work has been carried out during the past 25 years but experimental results are scarce. Com-mercial implementations are limited to intraprocedural array <b>bound</b> <b>checking</b> and are not really fulfilling user expectationsfor compilation and execution times. Instead of designing a new specific algorithm, we imple-mented two algorithms representative of the main published approaches by re-using static analysis techniques available inPIPS, an interprocedural parallelizer. The first algorithm is based on redundant <b>bound</b> <b>checking</b> elimination. The secondone is based on insertion of unavoidable tests. Results with the SPEC CFP 95 benchmarks show that com-mercial products could easily be improved using automatic analysis techniques and that user expectations can be ful-filled for most benchmarks. However, additional techniques should be used to obtain excellent results for all benchmarks. Our approach to optimize <b>bound</b> <b>checking</b> can also be ap-plied to other imperative languages such as Fortran, Pascal, Java when used for scientific applications. Keywordsarray reference, array <b>bound</b> <b>checking,</b> range checking, subscript out of range, bound violation, program verification. 1 INTRODUCTIONArray <b>bound</b> <b>checking</b> refers to determining whether all array references are within their declared range in all of theiruses in a program. These array <b>bound</b> <b>checks</b> may be analyzed intraprocedurally or interprocedurally, depending onthe need for accuracy. Such checking is desirable for any program, regardless of the language it is written in, sincebound violations are among the most common programming errors. Subscripting arrays beyond their declared sizes may result in unexpected results, security holes or failures. For the safetyof execution, some languages such as Java require that a program only be allowed to access elements of an array that arepart of the defined extent of the array...|$|R
50|$|The new egalitarian {{approach}} is to rely on <b>memory</b> <b>bound</b> functions. As stated before, a <b>memory</b> <b>bound</b> function is a function whose computation time {{is dominated by the}} time spent accessing <b>memory.</b> A <b>memory</b> <b>bound</b> function accesses locations in a large region of memory in an unpredictable way, {{in such a way that}} using caches are not effective. In recent years, the speed of CPU has grown drastically, but there has been comparatively small progress in developing faster main memory. Since the ratios of memory latencies of machines built in the last five years is typically no greater than two, and almost always less than four, the <b>memory</b> <b>bound</b> function will be egalitarian to most systems for the foreseeable future.|$|R
40|$|Array <b>bound</b> <b>checking</b> is {{critical}} for code safety and debugging but users {{are not ready to}} trade much execution time for it. A considerable research work has been carried out during the past 25 years but experimental results are scarce. Commercial implementations are limited to intraprocedural array <b>bound</b> <b>checking</b> and are not really fulfilling user expectations for compilation and execution times...|$|R
50|$|Bounds-checking elimination: Many languages, {{for example}} Java, enforce <b>bounds</b> <b>checking</b> of all array accesses. This is a severe {{performance}} bottleneck on certain {{applications such as}} scientific code. Bounds-checking elimination allows the compiler to safely remove <b>bounds</b> <b>checking</b> in many situations where it can determine that the index must fall within valid bounds, for example {{if it is a}} simple loop variable.|$|R
5000|$|Many {{programming}} languages, such as C, never perform automatic <b>bounds</b> <b>checking</b> {{to raise}} speed. However, this leaves many off-by-one errors and buffer overflows uncaught. Many programmers believe these languages sacrifice {{too much for}} rapid execution. In his 1980 Turing Award lecture, C. A. R. Hoare described his experience {{in the design of}} ALGOL 60, a language that included <b>bounds</b> <b>checking,</b> saying: ...|$|R
40|$|We {{present a}} type-based {{approach}} to eliminating array <b>bound</b> <b>checking</b> and list tag checking by conservatively extending Standard ML with a restricted form of dependent types. This enables the programmer to capture more invariants through types while type-checking remains decidable {{in theory and}} can still be performed efficiently in practice. We illustrate our approach through concrete examples and present the result of our preliminary experiments which support support the feasibility and effectiveness of our approach. 1 Introduction The absence of run-time array <b>bound</b> <b>checks</b> is an infamous source of fatal errors for programs in languages such as C. Nonetheless, compilers offer the option to omit array <b>bound</b> <b>checks,</b> since they can {{turn out to be}} expensive in practice (Chow 1983; Gupta 1994). In statically typed languages such as ML, one would like to provide strong guarantees about the safety of all operations, so array <b>bound</b> <b>checks</b> cannot be omitted in general. The same is true for Ja [...] ...|$|R
40|$|We {{present an}} {{extension}} of field analysis (see [4]) called related field analysis which is a general technique for proving relationships between two or more fields of an object. We demonstrate the feasibility and applicability of related field analysis by applying it {{to the problem of}} removing array <b>bounds</b> <b>checks.</b> For array <b>bounds</b> <b>check</b> removal, we define a pair of related fields to be an integer field and an array field for which the integer field has a known relationship to the length of the array. This related field information can then be used to remove array <b>bounds</b> <b>checks</b> from accesses to the array field. Our results show that related field analysis can remove an average of 50 % of the dynamic array <b>bounds</b> <b>checks</b> {{on a wide range of}} applications. We describe the implementation of related field analysis in the Swift optimizing compiler for Java, as well as the optimizations that exploit the results of related field analysis. ...|$|R
40|$|Attacks that exploit out-of-bounds {{errors in}} C and C++ {{programs}} are still prevalent despite {{many years of}} research on <b>bounds</b> <b>checking.</b> Previous backwards compatible <b>bounds</b> <b>checking</b> techniques, which {{can be applied to}} unmodified C and C++ programs, maintain a data structure with the bounds for each allocated object and perform lookups in this data structure to check if pointers remain within bounds. This data structure can grow large and the lookups are expensive. In this paper we present a backwards compatible <b>bounds</b> <b>checking</b> technique that substantially reduces performance overhead. The key insight is to constrain the sizes of allocated memory regions and their alignment to enable efficient bounds lookups and hence efficient <b>bounds</b> <b>checks</b> at runtime. Our technique has low overhead in practice—only 8 % throughput decrease for Apache— and is more than two times faster than the fastest previous technique and about five times faster—using less memory—than recording object bounds using a splay tree. ...|$|R
40|$|Several {{programming}} languages {{guarantee that}} array subscripts are checked {{to ensure they}} are {{within the bounds of}} the array. While this guarantee improves the correctness and security of arraybased code, it adds overhead to array references. This has been an obstacle to using higher-level languages, such as Java, for high-performance parallel computing, where the language specification requires that all array accesses must be checked to ensure they are within bounds. This is because, in practice, array-bounds checking in scientific applications may increase execution time by more than a factor of 2. Previous research has explored optimizations to statically eliminate <b>bounds</b> <b>checks,</b> but the dynamic nature of many scientific codes makes this difficult or impossible. Our approach is, instead, to create a compiler and operating system infrastructure that does not generate explicit <b>bounds</b> <b>checks.</b> It instead places arrays inside of Index Confinement Regions (ICRs), which are large, isolated, mostly unmapped virtual memory regions. Any array reference outside of its bounds will cause a protection violation; this provides implicit <b>bounds</b> <b>checking.</b> Our results show that when applying this infrastructure to high-performance computing programs written in Java, the overhead of <b>bounds</b> <b>checking</b> relative to a program with no <b>bounds</b> <b>checks</b> is reduced from an average of 63 % to an average of 9 %...|$|R
40|$|Optimization of array <b>bound</b> <b>checking</b> at compile-time is {{performed}} {{in order to}} reduce the overhead of the run-time checking. There are many researches in this field but the results seem not very highly appreciated, even with the commercial compilers. This paper describes two techniques for array <b>bound</b> <b>checking</b> implemented in our research compiler PIPS. It also gives experimental results together with the comparison of different approaches...|$|R
40|$|We present L 0, {{a purely}} {{functional}} programing language supporting nested regular data parallelism and targeting massively parallel SIMD hardware such as modern graphics processing units (GPUs). L 0 incorporates the following novel features: • A type system for in-place modification and aliasing of arrays and array slices that ensures referential transparency, {{which in turn}} supports equational reasoning. • An assertion language for expressing <b>bounds</b> <b>checks</b> on dynamically allocated arrays, which can often be checked statically to eliminate dynamic <b>bounds</b> <b>checks.</b> • Compiler optimisations for hoisting <b>bounds</b> <b>checks</b> out of inner loops and performing loop fusion based on structural transformations. We show that: • The type system is simpler than existing linear and unique typin...|$|R
5000|$|... #Subtitle level 2: <b>Memory</b> <b>bound</b> {{functions}} and <b>memory</b> functions ...|$|R
