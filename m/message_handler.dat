34|38|Public
50|$|<b>Message</b> <b>handler</b> updated and new Coach Corner features: Un-sell/un-buy, remove ach. skills.|$|E
50|$|A <b>message</b> <b>handler</b> will, in general, process {{messages}} {{from more than}} one sender. This means its state can change for reasons unrelated to the behavior of a single sender or client process. This is in contrast to the typical behavior of an object upon which methods are being invoked: the latter is expected to remain in the same state between method invocations. In other words, the <b>message</b> <b>handler</b> behaves analogously to a volatile object.|$|E
50|$|On August 17, 2016, WNG575 {{and other}} NWS Gray {{stations}} transitioned {{to the new}} Broadcast <b>Message</b> <b>Handler</b> (BMH) control system, giving the station a new voice along with significant internal upgrades.|$|E
40|$|To be able {{to benefit}} from the low latencies offered by recent user-level {{communication}} architectures, messageprocessing overhead must be minimized. This requirement has resulted in the development of messagehandling models that trade expressiveness for performance. We describe three models of increasing expressiveness. The least expressive model, the active messages model, disallows all blocking in <b>message</b> <b>handlers.</b> This complicates programming if messages arrive asynchronously and <b>message</b> <b>handlers</b> need to synchronize with other threads. The second model, the singlethreaded upcall model, allows blocking in some cases. It is thus more expressive than active messages, but not as expressive as the last model, popup threads, which puts no restrictions on <b>message</b> <b>handlers.</b> We have implemented all three models on the same user-level communication architecture. The implementation carefully integrates thread management and message-handling. Using this integrated system, the performance of the [...] ...|$|R
50|$|Delphi {{uses the}} Pascal-based {{programming}} language called Object Pascal introduced by Borland, and compiles Delphi source code into native x86 code. It includes VCL, support for COM independent interfaces with reference counted class implementations, {{and support for}} many third-party components. Interface implementations can be delegated to fields or properties of classes. <b>Message</b> <b>handlers</b> are implemented by tagging a method of a class with the integer constant of the message to handle.|$|R
40|$|The {{first year}} of the PrKAda project is recounted. The primary goal was to develop a system for {{delivering}} Artificial Intelligence applications developed in the ProKappa system in a pure-Ada environment. The following areas are discussed: the ProKappa core and ProTalk programming language; the current status of the implementation; the limitations and restrictions of the current system; and the development of Ada-language <b>message</b> <b>handlers</b> in the ProKappa environment...|$|R
5000|$|The NWS Weather Forecast Office in Greenville, South Carolina, simply used {{a message}} informing NWR {{listeners}} to [...] "stand by for important weather information" [...] when a weather warning was issued. However, {{this seems to}} have been hard-coded into the system and tests of the SAME device serving the Greenville-Spartanburg area were also prefaced with this message. This has since disappeared upon implementation of the Broadcast <b>Message</b> <b>Handler.</b> Forecast offices in Seattle, Washington, Las Vegas, Nevada, Jackson, Kentucky and Charleston, West Virginia have a similar feature; none of these offices have yet to switch over to the Broadcast <b>Message</b> <b>Handler</b> , so this 'stand by' message can still be heard on stations originating from these offices.|$|E
50|$|Some NWS Weather Forecast Offices, {{such as the}} Spokane, Washington WFO, use a short {{script for}} the main SAME test, and send out a 1050 Hz tone for the main test message. This test set up is {{retained}} with the Broadcast <b>Message</b> <b>Handler,</b> that was installed on 10 May 2016.|$|E
5000|$|In January 2016, six sites {{across the}} nation were {{selected}} to begin testing a new system known as the Broadcast <b>Message</b> <b>Handler</b> (BMH), which features a new voice replacing all other voices. These six test sites include offices at Greenville-Spartanburg, South Carolina; Brownsville, Texas; Omaha, Nebraska; Portland, Oregon; Anchorage, Alaska; and Tiyan, Guam. A gradual nationwide implementation of the Broadcast <b>Message</b> <b>Handler</b> system began in April 2016, and lasted {{through the end of}} 2016. The name of the new voice being used on NWR is [...] "Paul" [...] (its classification from new voice partner NeoSpeech). Many stations have dubbed him [...] "Paul II" [...] or [...] "Paul Jr" [...] to avoid confusion with [...] "Perfect Paul". This has also happened on NWS offices with Spanish programming; Javier was replaced with a female voice named [...] "Violetta" [...] (another voice from NeoSpeech).|$|E
40|$|Abstract For some applications, message-oriented {{systems have}} a {{performance}} advantage over process-oriented systems. However, message-oriented {{systems can be}} more difficult to debug, due to their unpredictable control flow. Our project allows programmers to debug a message-oriented system using the more intuitive control flow of a process-oriented system. We have developed an algorithm, threadsim, that maps sequences of <b>messages</b> and <b>handler</b> functions in a message oriented system onto a simulated process tree in real time with constant amortized overhead per message. Using this algorithm, we have created an extension to gdb that can simulate threads on any single-process event-driven system. We prove that our algorithm will work for similar systems that run an arbitrary number of <b>message</b> <b>handlers</b> in parallel. 1 Introduction and Motivation 1. ...|$|R
40|$|NICAM is a {{communication}} layer for SMP PC clusters connected via Myrinet, {{designed to reduce}} overhead and latency by directly utilizing a micro-processor equipped on the network interface. It adopts remote memory operations to reduce much of the overhead found in message passing. NICAM employs an Active Messages framework for flexibility in programming on the network interface, and this flexibility will compensate for the large latency resulting from the relatively slow micro-processor. Running <b>message</b> <b>handlers</b> directly on the network interface reduces the overhead by freeing the main processors {{from the work of}} polling incoming <b>messages.</b> The <b>handlers</b> also make synchronizations faster by avoiding the costly interactions between the main processors and the network interface. In addition, this implementation can completely hide latency of barriers in data-parallel programs, because handlers running in the background of the main processors allow reposition of barriers to any place where [...] ...|$|R
40|$|A {{coherent}} global {{address space}} in a distributed system en-ables shared memory programming in a much larger scale than a single multicore or a single SMP. Without dedicated hardware support at this scale, the solution is a software dis-tributed shared memory (DSM) system. However, traditional approaches to coherence (centralized via “active ” home-node directories) and critical-section execution (distributed across nodes and cores) are inherently unfit for such a scenario. Instead, {{it is crucial to}} make decisions locally and avoid the long latencies imposed by both network and software <b>message</b> <b>handlers.</b> Likewise, synchronization is fast if it rarely involves communication with distant nodes (or even other sockets). To minimize the amount of long-latency com-munication required in both coherence and critical section execution, we propose a DSM system with a novel coherence protocol, and a novel hierarchical queue delegation lock-ing approach. More specifically, we propose an approach, suitable for data-race-free (DRF) programs, based on self-invalidation, self-downgrade, and passive data classification directories that require no <b>message</b> <b>handlers,</b> thereby incur-ring no extra latency. For fast synchronization we extend Queue Delegation Locking to execute critical sections in large batches on a single core before passing execution along to other cores, sockets, or nodes, in that hierarchical order. The result is a software DSM system called Argo which local-izes as many decisions as possible and allows high parallel performance with little overhead on synchronization when compared to prior DSM implementations. 1...|$|R
50|$|SystmConnect is TPP’s {{suite of}} {{products}} designed {{to join up}} care across healthcare communities. Serving as both a <b>message</b> <b>handler</b> and a data repository, SystmConnect allows a complete, unified view of patient records in real time, even in areas with a mixed economy of IT systems. This helps to ensure patients receive consistent, timely and appropriate care.|$|E
5000|$|In the Oberon {{operating}} system {{both of these}} techniques are used for dynamic dispatch. The first one is used for a known set of methods; the second is used for any new methods declared in the extension module. For example, if the extension module Rectangles were to implement a new Rotate (...) procedure, within the Figures module {{it could only be}} called via a <b>message</b> <b>handler.</b>|$|E
50|$|Oberon {{supports}} {{extension of}} record types {{for the construction}} of abstractions and heterogeneous structures. In contrast to the later dialects—Oberon-2 and Active Oberon—the original Oberon doesn't have a dispatch mechanism as a language feature but rather as programming technique or design pattern. This gives great flexibility in the OOP world. In the Oberon operating system two programming techniques have been used in conjunction for the dispatch call: Method suite and <b>Message</b> <b>handler.</b>|$|E
40|$|We {{describe}} a new architecture that improves message-passing performance, both for device I/O and for interprocessor communication. Our architecture integrates an SMT processor with a userlevel network interface that can directly schedule threads on the processor. By allowing the network interface to directly initiate message handling code at user level, {{most of the}} OS-related overhead for handling interrupts and dispatching to user code is eliminated. By using an SMT processor, most of the latency of executing <b>message</b> <b>handlers</b> can be hidden. This paper presents measurements that show that the OS overheads for message-passing are significant, and briefly describes our architecture and the simulation environment that we are building to evaluate it...|$|R
40|$|The {{variety of}} {{communications}} employed by CGFs requires a flexible communications infrastructure {{that can be}} readily modified for new applications, new communication devices, and even user preferences. Understanding the variety of CGF communications has led us to re-design the communications infrastructure of TacAir-Soar, a realtime aircraft CGF. The design consists of four major components: consistent communications knowledge, a language for communication events, a message transport infrastructure, and <b>message</b> <b>handlers</b> for communication devices. This paper describes the motivations for these new components, focusing especially on the software engineering approaches that provide a more modular, extensible, and maintainable framework for CGF communications. We also discuss {{the costs of the}} new solution and some ideas for reuse in the CGF community...|$|R
40|$|Communications co-processors (CCPs) {{have become}} commonplace in modern MPPs and {{networks}} of workstations. These co-processors provide dedicated hardware support for fast communication. In this paper we study how {{to exploit the}} capabilities of CCPs for executing user level <b>message</b> <b>handlers.</b> We show, {{in the context of}} Active Messages and Split-C, that we can move message handling code to the co-processor thus freeing the main processor for computational work. We address the important issues that arise, such as synchronization, and the limited computational power and flexibility of CCPs. We have implemented co-processor versions of both Active Messages and Split-C. These implementations, developed on the Meiko CS- 2, provide us with an excellent experimental platform to evaluate the benefits of a communications co-processor architecture. ...|$|R
5000|$|It {{supports}} the basic control structures of procedural languages: repeat for/while/until, if/then/else, {{as well as}} function and message [...] "handler" [...] calls (a handler is a subroutine, a <b>message</b> <b>handler</b> is a procedure). Data types are transparent to the user, conversion happens transparently in the background between strings and numbers. There are no classes or data structures in the traditional sense; their place was taken by special string literals, or rather [...] "lists" [...] of [...] "items" [...] delimited by commas (in later versions the [...] "itemDelimiter" [...] property allowed choosing an arbitrary character).|$|E
5000|$|... module demo; /* This {{behavior}} simply sends two print(...) {{messages to}} the standardOutput actor.*/behavior HelloWorld { /* The act(...) <b>message</b> <b>handler</b> is invoked by stand-alone theaters automatically and is used to bootstrap salsa programs. */ void act( [...] String argv [...] ) { standardOutput<-print( [...] "Hello" [...] ) @ standardOutput<-print( [...] "World!" [...] ); } /* Notice that the above code is different from standardOutput<-print( [...] "Hello" [...] ); standardOutput<-print( [...] "World!" [...] ); the code above uses a continuation {{to insure that the}} world message is sent after the hello message completes processing. */} ...|$|E
50|$|FOX {{offers a}} {{transparent}} bi-directional messaging system. Each widget sends its message {{to a certain}} target. Each message is composed by a selector that identifies its kind and an id that is unique and provided by the widget's enumeration. The advantage is that each widget can call a target widget's method in a transparent manner, even if the method does not exist. Vice versa, {{in the implementation of}} the individual <b>message</b> <b>handler,</b> since the sender is known, the target can also dispatch a message to the sender. This is a particularly important feature in component oriented software, where components may be written by different people, or even different organizations.|$|E
40|$|Application-specific safe <b>message</b> <b>handlers</b> (ASHs) are {{designed}} to provide applications with hardware-level network performance. ASHs are user-written code fragments that safely and efficiently execute in the kernel in response to message arrival. ASHs can direct message transfers (thereby eliminating copies) and send messages (thereby reducing send-response latency). In addition, the ASH system provides support for dynamic integrated layer processing (thereby eliminating duplicate message traversals) and dynamic protocol composition (thereby supporting modularity). ASHs provide this high degree of flexibility while still providing network performance as good as, or (if they exploit application-specific knowledge) even better than, hard-wired in-kernel implementations. A combination of user-level microbenchmarks and end-to-end system measurements using TCP demonstrate {{the benefits of the}} ASH system. 1 Introduction Applications' complexity and ambition scale with increases in processin [...] ...|$|R
40|$|Powerful non-strict {{parallel}} languages require fast dynamic scheduling. This thesis explores how {{the need}} for multithreaded execution can be addressed as a compilation problem, to achieve switching rates approaching what hardware mechanisms might provide. Compiler-controlled multithreading is examined through compilation of a lenient parallel language, ID 90, for a threaded abstract machine, TAM. A key feature of TAM is that synchronization is explicit and occurs only {{at the start of}} a thread, so that a simple cost model can be applied. A scheduling hierarchy allows the compiler to schedule logically related threads closely together in time and to use registers across threads. Remote communication is via message sends and split-phase memory accesses. Messages and memory replies are received by compiler-generated <b>message</b> <b>handlers</b> which rapidly integrate these events with thread scheduling. To compile ID 90 for TAM, we employ a new parallel intermediate form, dualgraphs, with [...] ...|$|R
40|$|Google’s Android OS {{provides}} a lightweight IPC mechanism called Binder, which enables {{the development of}} feature-rich apps that seamlessly integrate services and data of other apps. Whenever apps can act both as service consumers and service providers, {{it is inevitable that}} the IPC mechanism provides message receivers with message provenance information to establish trust. However, the Android OS currently fails in providing sufficient provenance information, which has led to a number of attacks. We present an extension to the Android IPC mechanism, called Scippa, that establishes IPC call-chains across appli-cation processes. Scippa provides provenance information required to effectively prevent recent attacks such as confused deputy attacks. Our solution constitutes a system-centric ap-proach that extends the Binder kernel module and Android’s <b>message</b> <b>handlers.</b> Scippa integrates seamlessly into the sys-tem architecture and our evaluation shows a performance overhead of only 2. 23 % on Android OS v 4. 2. 2. 1...|$|R
50|$|On December 1, 2014, Indrajeet Bhuyan and Saurav Kar, both 17 years old, {{demonstrated}} the WhatsApp <b>Message</b> <b>Handler</b> Vulnerability, which allows anyone to remotely crash WhatsApp just {{by sending a}} specially crafted message of 2kb in size. To escape the problem, the user who receives the specially crafted message has to delete his/her whole conversation and start a fresh chat, because opening the message keeps on crashing WhatsApp unless the chat is deleted completely. In early 2015, after WhatsApp launched a web client {{that can be used}} from the browser, Bhuyan also found that it had two security issues that compromised user privacy: the WhatsApp Photo Privacy Bug and the WhatsApp Web Photo Sync Bug.|$|E
30|$|The {{positioning}} procedure {{works as}} follows: when {{a moving target}} (typically a person carrying a device) enters a room and wants to know its location, it first broadcasts a room granularity request to nearby anchors. Then the <b>message</b> <b>handler</b> forwards the upcoming replies to the room separation module. After several rounds of estimation, the result analyzer deems that the user is in a certain room and changes the requirement to cube granularity. The <b>message</b> <b>handler</b> begins to send requests of cube granularity and forwards the replies to cube determination module. When the target leaves the room, the result analyzer senses that the results are no longer correct, causing the requirement to switch back to room granularity.|$|E
40|$|We {{propose the}} flying object that adapts {{itself to the}} {{environment}} {{by means of the}} dynamic behavior change mechanism. The flying object is user-defined, first-class and abstract entity. Such properties provide independency and transparency. The flying object model establishes a unique decomposition of the flying object. In this model, the flying object consists of four objects: the delegator that encapsulates the implementation, the <b>message</b> <b>handler</b> that interprets the messages, the event handler that provides adaptation strategies and the context object that holds a state beyond the adaptation. The ability of accommodation, the openness, is one of great contributions of this model because many functions such as object migration, load balancing, distributed transaction management, the communication protocols and even adaptation strategies can be introduced by the <b>message</b> <b>handler</b> and the event handler as a plug-in module. Furthermore, a source code translation technique is introduced for automatic decomposition of the flying object as a replacement for the virtual machine customizations or low-level programming. The delegator and the context object are instantiated from the same translated class to minimize maintenance costs of classes {{as a result of an}} automatic translation. Therefore, the system organized by the flying object is best suited for the open distributed environment...|$|E
40|$|Device Interface (ADI). The ADI {{provides}} a fairly high-level abstraction of a communication device {{that should be}} realized by the underlying low-level communication library like Nexus. The Nexus implementation of ADI establishes a full connection among the communication links used in the MPICH program and the ADI functions are realized as RSR <b>message</b> <b>handlers.</b> The implementation of ADI on different machines may apply different protocols for transferring data. 6. 1. 2 Resource management Globus has a hierarchical resource management concept which is built on three major components:. The Resource Specification Language (RSL). A hierarchical broker architecture. Globus Resource Allocation Managers (GRAMs) The RSL is used to specify the resource requirements of a particular application. It contains expressions like:. "Run a distributed simulation with 100 K entities". "Perform a parameter study with 10 K separate trials". "Create a shared virtual space with participants X, Y and [...] ...|$|R
40|$|Varieties of Message-Oriented Middleware (MOM) {{platforms}} {{are available}} each {{with their own}} propriety functionality to solve specific messaging challenges. At present, {{it is not possible}} to mix and match these propriety features into a customized MOM solution. A number of patterns have been identified that allow a software systems implementation to be more flexible and extensible. This work investigates the use of one such pattern, the POSA Interceptor pattern, in the construction of a MOM framework that is easily customised and extended in a structured way. This framework, Chameleon, is designed to support the use of interceptors (<b>message</b> <b>handlers)</b> with a MOM platform to facilitate dynamic changes to the behaviour of the deployed platform. The framework also allows for interceptors to be used on both the client-side and serverside, permitting advance functionality to be deployed to the client, and for co-operation between client-side and server-side interceptors...|$|R
40|$|Tcl#Tk is an {{attractive}} language {{for the design of}} intelligent agents because it allows the quick construction of prototypes and user interfaces; new scripts can easily be bound at runtime to respond to events; and execution state is encapsulated by the interpreter, which helps in agent migration. However, a system of intelligent agents must share a common language for communicating requests and knowledge. Wehaveintegrated KQML #Knowledge Query Manipulation Language#, one such standard language, into Tcl#Tk. The resulting system, called TKQML, provides several bene#ts to those building intelligent agent systems. First, TKQML allows easy integration of existing tools which have Tcl#Tk interfaces with an agent system by using Tcl to move information between KQML and the application. Second, TKQML is an excellent language with which to build agents, allowing on-the-#y speci#- cation of <b>message</b> <b>handlers</b> and construction of graphical interfaces. This paper describes the impl [...] ...|$|R
40|$|The {{results of}} efforts to apply {{powerful}} Ada constructs to the formatted message handling process are described. The goal of these efforts was to extend the state-of-technology in message handling {{while at the same}} time producing production-quality, reusable code. The first effort was initiated in September, 1984 and delivered in April, 1985. That product, the Generic Message Handling Facility, met initial goals, was reused, and is available in the Ada Repository on ARPANET. However, it became apparent during its development that the initial approach to building a <b>message</b> <b>handler</b> template was not optimal. As a result of this initial effort, several alternate approaches were identified, and research is now on-going to identify an improved product. The ultimate goal is to be able to instantly build a message handling system for any message format given a specification of that message format. The problem lies in how to specify the message format, and one that is done, how to use that information to build the <b>message</b> <b>handler.</b> Message handling systems and message types are described. The initial efforts, its results and its shortcomings are detailed. The approach now being taken to build a system which will be significantly easier to implement, and once implemented, easier to use, is described. Finally, conclusions are offered...|$|E
30|$|The goal of {{the camera}} {{controller}} on camera sensors is to adjust the camera sensor status according to the received control message. It {{is worth noting that}} a number of uncertain factors (e.g., variable service response time and unstable bandwidth) mislead the <b>message</b> <b>handler,</b> resulting in making suboptimal or even inaccurate event coverage. It is not hard to imagine that the control messages from cloudlets and clouds are not synchronous in this environment. One important problem is how to analyze and deal with different control messages from cloudlets and clouds.|$|E
40|$|Abstract. This paper {{shows how}} {{parallelism}} has been integrated into SCOOP, a C++ class library for solving optimisation problems. After {{a description of}} the modeling and the optimisation parts of SCOOP, two new classes that permit parallel optimisation are presented: a class whose only purpose is to handle messages and a class for managing optimiser and <b>message</b> <b>handler</b> objects. Two of the most interesting aspects of SCOOP, modularity and generality, are preserved by clearly separating problem representation, solution techniques and parallelisation scheme. This allows the user to easily model a problem and construct a parallel optimiser for solving it by combining existing SCOOP classes. ...|$|E
40|$|Recent {{networks}} and network interfaces promise remarkable communication performance {{with very little}} overhead, but current software structures impose substantial overhead that prevents applications from achieving the benefits of these new architectures. We propose a new software structure that eliminates much of the overhead while preserving the ease of programming of current systems. Our architecture relies on the compiler {{to bridge the gap}} between high-level application programs and low-level communication primitives. The compiler incorporates application code into <b>message</b> <b>handlers</b> using a new runtime mechanism called optimistic active messages. This work was supported in part by the Advanced Research Projects Agency under contracts N 00014 - 91 J - 1698 and DABT 63 - 93 -C- 008, by the National Science Foundation under contract MIP- 9012773, by an NSF Presidential Young Investigator Award, by IBM, AT&T, and Digital Equipment Corp., by Project Scout under ARPA contract MDA 972 - 92 -J- 1032, by a [...] ...|$|R
40|$|Active {{messages}} {{have proven}} to be an effective approach for certain communication problems in high performance computing. Many MPI implementations, as well as runtimes for Partitioned Global Address Space languages, use active messages in their low-level transport layers. However, most active message frameworks have low-level programming interfaces that require significant programming effort to use directly in applications and that also prevent optimization opportunities. In this paper we present AM++, a new user-level library for active messages based on generic programming techniques. Our library allows <b>message</b> <b>handlers</b> to be run in an explicit loop that can be optimized and vectorized by the compiler and that can also be executed in parallel on multicore architectures. Runtime optimizations, such as message combining and filtering, are also provided by the library, removing the need to implement that functionality at the application level. Evaluation of AM++ with distributed-memory graph algorithms shows the usability benefits provided by these library features, as well as their performance advantages...|$|R
40|$|In current Java implementations, Remote Method Invocation is slow. On a Pentium Pro/Myrinet cluster, for example, a null RMI takes 1228 µs using Sun's JDK 1. 1. 4. This paper {{describes}} Manta, a Java {{system designed}} to support efficient communication. On the same Myrinet cluster, Manta achieves a null RMI latency of 35 µs. Manta {{is based on a}} native Java compiler. It achieves high communication performance mainly through the following techniques: removal of copying in the network sub system, compiler-generation of specialized marshaling code, and Optimistic Active Messages, a technique that avoids thread creation in <b>message</b> <b>handlers</b> for small methods. Our work shows that techniques from other high performance RPC based systems also work in Java, making RMI, originally designed for distributed programming, a viable mechanism for parallel programming as well. 1 Introduction There is a growing interest in using Java for high-performance parallel applications (see, for example, the Java Gran [...] ...|$|R
