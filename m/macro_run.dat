1|46|Public
40|$|The %MktOrth autocall macro lists {{some of the}} 100 % {{orthogonal}} main-effects {{plans that}} the %MktEx macro can generate. See page 106 {{for an example of}} using this macro in the design chapter. Also see the following pages for examples of using this macro in the discrete choice chapter: 342 and 660. Additional examples appear throughout this chapter. Mostly, you use this macro indirectly; it is called by the %MktEx macro. However, you can directly call the %MktOrth macro to see what orthogonal designs are available and decide which ones to use. The following step requests all the designs in the catalog with 100 or fewer runs and two-level through six-level factors (with no higher-level factors.) %mktorth(maxn= 100, maxlev= 6) The macro creates data sets and displays no output except the following notes: NOTE: The data set WORK. MKTDESLEV has 347 observations and 9 variables. NOTE: The data set WORK. MKTDESCAT has 347 observations and 3 variables. This next step generates the entire catalog of 119, 852 designs ∗ including over 62, 000 designs in 512 runs that are not generated by default: %mktorth(maxlev= 144, options= 512) This step might take on the order of several minutes to run. This next step generates the catalog of approximately 57 thousand designs including designs with up to 144 -level factors: %mktorth(maxlev= 144) This step might take on the order of several minutes to run. Unless you really want to see all of the designs, you can make the %MktOrth <b>macro</b> <b>run</b> much faster by specifying smaller values for range= or maxn = (which control the number of runs) and maxlev = (which controls the maximum number of factor levels and the number of variables in the MKTDESLEV data set) than the defaults (range=n le 1000, maxn= 1000, maxlev= 50). The maximum number of levels you can specify is 144. The following step lists the first few and the last few designs in the catalog: proc print data=mktdeslev(where=(n le 12 or n ge 972)); var design reference; id n; by n; run; Elsewhere in this chapter, the size of the orthogonal array catalog is reported to be 117, 556. The discrepancy is due to the 2296 designs that are explicitly in the catalog and have more than 513 runs. Most are constructed from the parent array 24 8 in 576 runs (which is useful for making Latin Square designs). The rest are constructed from Hadamar...|$|E
5000|$|In Minitab, the Royal Society of Chemistry {{has created}} a <b>macro</b> to <b>run</b> kernel density {{estimation}} based on their Analytical Methods Committee Technical Brief 4.|$|R
5000|$|Configurable list of <b>macros</b> {{commands}} to <b>run</b> locally or send to connected client.|$|R
5000|$|A {{complete}} [...] "Hello, world!" [...] {{program in}} PDP-11 <b>macro</b> assembler, to <b>run</b> under RT-11: ...|$|R
25|$|Allows an undo unit {{to contain}} other undo units. In essence {{this allows the}} undo unit {{to act as an}} undo stack, {{grouping}} undo units together. For example, if a <b>macro</b> is <b>run,</b> all undo-able actions performed by the macro may be grouped together in one undo unit.|$|R
5000|$|Simple collector: a small notepad-like utility, used {{to collect}} text from web pages. Scripts and <b>macros</b> can be <b>run</b> in the current web page ...|$|R
50|$|Development on Wordfast version 1 (then called simply Wordfast) {{was begun}} in 1999 in Paris, France, by Yves Champollion. It {{was made up}} of a set of <b>macros</b> that <b>ran</b> inside of Microsoft Word, version 97 or higher. At that time, other {{translation}} memory programs also worked inside Microsoft Word, for example Trados.|$|R
5000|$|ChemStation has {{a command}} line {{interpreter}} and can <b>run</b> <b>macros.</b> Those macros are files grouping {{a set of}} commands. These files possess a [...]mac extension.|$|R
5000|$|The 3790 {{failed to}} achieve the success IBM intended, due to several issues. [...] It had a complex {{programming}} language, The 3790 Macro Assembler, and the customers {{found it difficult to}} deploy applications on it. The <b>Macro</b> Assembler <b>ran</b> only on an IBM mainframe and then the compiled and linked object was moved to the 3790 for testing.|$|R
5000|$|Here, [...] "m" [...] {{denotes the}} [...] "Macro" [...] key. It {{generally}} produces a [...] "\"; although, applications receive a different keycode and can therefore instead use the key to, for example, <b>run</b> <b>macros.</b>|$|R
5000|$|Zgrass {{included}} three priorities (called levels) that allowed <b>macros</b> to be <b>run</b> normally, or in [...] "foreground" [...] or [...] "background" [...] levels. This added a simple form of multitasking which was tremendously useful in an animation-oriented language. Game authors could place joystick-reading routines in a <b>macro</b> set to <b>run</b> in the background, {{and then the}} joystick would be read automatically whenever the current drawing macro completed. Functions placed in the foreground ran before either, and was often used for timers and other [...] "low latency" [...] needs. Zgrass included a [...] function that would call macros on a timed basis, making the implementation of timers very easy.|$|R
5000|$|On {{versions}} {{that require}} Ctrl + [...] "Program Macro" [...] at start the programming session, you still use [...] "Program Macro" [...] to end programming session. If the last 2 keystrokes are ctrl + [...] "Program Macro" [...] the ctrl stroke {{becomes part of}} the macro. When this <b>macro</b> is <b>run</b> [...] "ctrl" [...] key is stuck on preventing other macros running until another ctrl key press to clear the keyboard state.|$|R
50|$|The troff {{typesetting}} system includes sets of commands called <b>macros</b> {{that are}} <b>run</b> before starting {{to process the}} document. These macros include setting up page headers and footers, defining new commands, and generally influencing how the output will be formatted.|$|R
40|$|The current {{implementation}} of the Fan Chart displays equal tail probability bands and do {{not take into account}} that the variable of interest may be subject to data revision. In this note I propose the use of Highest Probability Density, HPD, bands and include flexibility to display the risks related to data revision. Click here to obtain a Visual Basic for Excel routine. Please save the the as FanChartGdpGrowth. xls and enable <b>Macros</b> to <b>run</b> the program. ...|$|R
50|$|Wordfast Classic {{is a set}} of <b>macros</b> that <b>run</b> in Microsoft Word 97 {{or higher}} on any platform. More recent {{versions}} support features only available on higher versions of Microsoft Word, but generally still runs on Word 97. A document translated in Wordfast Classic is temporarily turned into a bilingual document (contains both source text and translation, in delimited segments), turning into its final form by being cleaned up. This workflow is similar to the old Trados 5, WordFisher and Logoport.|$|R
50|$|Later HP {{financial}} calculators {{are many}} times as fast with more functions, but none have been as successful. The HP-12C's programing mode is very intuitive and works like a macro operation on a computer. Basically, the keys one would press in the calculating mode {{to arrive at a}} solution are entered in the programing mode along with logical operators (if, and, etc.) if applicable to the solution. After the programing is complete, the <b>macro</b> will <b>run</b> in the computation mode to save the user steps and improve accuracy. There are 99 lines of programmable memory on the HP-12C.|$|R
40|$|Every SAS ® macro {{developer}} {{from time}} to time has spent countless hours writing, testing and perfecting code {{so that it can be}} used over and over by different users on different platforms. There are certain situations where one needs to enhance the speed of the processing of SAS code, such as in a production environment or if there is a need to process large volumes of data. A SAS Stored Macro Facility consists of a library of SAS macros which are already compiled, that are available to users or processes at any time. These pre-compiled <b>macros</b> <b>run</b> immediately when called and do not use valuable CPU time while waiting for compilation. Some examples of where a stored macro facility would be useful are in production environments, where jobs may be scheduled to run on a certain day of the day, week, or month. Another would be a standard report which is being used for an FDA submission and needs to be in an exact format. Creating a stored macro facility can be a beneficial tool for a developer or end-user and it is fairly easy to set up on any platform. There are also options to store the source code along with the compiled macro. This paper will give a brief introduction to the SAS Stored Macro Facility and explain how to set it up and use it to its full potential. The Basic...|$|R
50|$|In {{computing}} terminology, a {{macro virus}} is {{a virus that}} is written in a macro language: a programming language which is embedded inside a software application (e.g., word processors and spreadsheet applications). Some applications, such as Microsoft Office, Excel, Power point allow macro programs to be embedded in documents such that the <b>macros</b> are <b>run</b> automatically when the document is opened, and this provides a distinct mechanism by which malicious computer instructions can spread. This is one reason it can be dangerous to open unexpected attachments in e-mails. Many antivirus programs can detect macro viruses, however the macro virus' behavior can still be difficult to detect.|$|R
40|$|The Kansas Geological Survey (KGS) {{developed}} a semi-analytical solution for slug tests that incorporates {{the effects of}} partial penetration, anisotropy, {{and the presence of}} variable conductivity well skins. The solution can simulate either confined or unconfined conditions. The original model, written in FORTRAN, has a text-based interface with rigid input requirements and limited output options. We recreated the main routine for the KGS model as a Visual Basic <b>macro</b> that <b>runs</b> in most versions of Microsoft Excel and built a simple-to-use Excel spreadsheet interface that automatically displays the graphical results of the test. A comparison of the output from the original FORTRAN code to that of the new Excel spreadsheet version for three cases produced identical results...|$|R
40|$|Johansen (1972) {{explains}} how a short <b>run</b> <b>macro</b> production function {{can be derived}} {{on the basis of}} a distribution of micro production units with respect to fixed input coefficients. The present note points out that the composite mean regression, introduced by Frisch (1929), can be useful in analysing some of the production models in Johansen (1972). The focus is on complementary, alternative and marginally independent production factors at the macro level in a production mode...|$|R
40|$|It is {{very common}} to run a group of SAS {{programs}} together in batch mode. For example, often we run {{a large number of}} individual SAS programs to generate listings and tables for a clinical trial. These programs are submitted to run together in a batch job. There are different ways to create the batch program. For instance, a shell script for a UNIX system can be created to do it on the server side (SUGI 145 - 31), or a. BAT file for Windows OS can fulfill this task on a specific PC (SUGI 105 - 27). In this article, we present another approach. We use a simple macro to create the SAS batch program in the Windows environment {{that can be used for}} batch-submit later in either operating system. This <b>macro</b> can <b>run</b> on any PC which has the SAS system installed...|$|R
40|$|SWASH (Surface WAter Scenarios Help) assists {{the user}} in calculating {{pesticide}} exposure {{concentration in the}} EU FOCUS surface water scenarios. It {{is part of the}} exposure calculation procedure, being part of the obligatory evaluation procedure to place an active substance on List 1 according to EU Directive 91 / 414 /EEC. SWASH encompasses: (i) FOCUS Drift Calculator, calculating pesticide entries through spray drift deposition, (ii) PRZM- 3, calculating pesticide entries through run-off, (iii) MACRO, calculating pesticide entries through drainage and (iv) TOXSWA, calculating the behaviour of pesticides in small surface waters. It is linked to SPIN, a pesticide properties tool, and prepares input for the PRZM, MACRO and TOXSWA models. Via the SWASH shell the user can enter the shells of the other models to perform the PRZM or <b>MACRO</b> model <b>runs</b> needed to assess the fate of the substance in he FOCUS water body systems using TOXSWA...|$|R
40|$|Leif Johansens short <b>run</b> <b>macro</b> {{production}} function {{is used to}} explore the conditions for a productivity slowdown to take place simultaneously with an accelerated technical change in production. A capacity distribution such that the supply curve is concave at the extensive margin considerably {{increases the likelihood of}} a reverse relation. Changes in price expectations may further reinforce this mechanism. Increasing costs of transferring labour to new investment is the key mechanism behind the results. The mechanism emphasizes the decisive role of past investmellt. and future price expectations in shaping the relation between technical change and productivity growth...|$|R
40|$|Motivated by four-dimensional {{superstring}} models, {{we consider}} the possibility of treating the Yukawa couplings of the Minimal Supersymmetric Standard Model (MSSM) as dynamical variables of the effective theory at the electroweak scale. Assuming bottom-tau unification, we concentrate {{on the top and}} bottom Yukawa couplings, and find that minimizing the effective potential drives them close to an effective infrared fixed line. Requiring an acceptable bottom-top mass ratio leads in principle to an additional constraint on the MSSM parameter space. As a by-product, we give new approximate analytical solutions of the renormalization group equations for the MSSM parameters. Comment: 18 pages, 4 effective figures, plain LATEX (no special <b>macros,</b> to be <b>run</b> twice...|$|R
40|$|This paper {{explores the}} {{relation}} between the quality of financial institution and asset bubbles. In this paper, we will show that bubbles can improve the macro performance even if the quality of financial in- stitution is very poor and the financial market does not work well. In this sense, the high quality of financial institution and bubbles are substitutes. We will explore, however, that they are not perfect substi- tutes. Bubbles may burst. If bubbles burst, the economic performance must go down if the quality of financial institution is low. Hence, we will show that not relaying on bubbles, but improving the quality of financial institution is important for long <b>run</b> <b>macro</b> performance. ...|$|R
40|$|The REsource ALlocation Model (REALM) {{has been}} used for {{modelling}} most Victorian water supply systems and a number of systems in other states in Australia. It is maintained by the Victorian Department of Sustainability and Environment and Victoria University. Recent development of REALM has been undertaken to add additional capabilities to the package. It is now possible to use sub-equations to set variable capacity carriers, simulate carryover of unused allocation and simulate crop demand using the PRIDE model within each demand node. Other enhancements include the ability to <b>run</b> <b>macros</b> to automate tasks, view target curves and more. This paper describes the development and application of the enhancements included in REALM version 6. 0...|$|R
40|$|The {{user-friendly}} shell SWASH, {{acronym for}} Surface WAter Scenarios Help, assists the user in calculating pesticide exposure {{concentrations in the}} EU FOCUS surface water scenarios. It {{is part of the}} exposure calculation procedure developed by the FOCUS Surface Water Scenarios Working Group, which {{has become part of the}} obligatory evaluation procedure to place an active substance on List 1 according to EU Directive 91 / 414 /EEC. SWASH encompasses four separate tools and models: (i) FOCUS Drift Calculator, calculating pesticide entries through spray drift deposition, (ii) PRZM- 3, calculating pesticide entries through run-off, (iii) MACRO, calculating pesticide entries through drainage and (iv) TOXSWA, calculating the behaviour of pesticides in small surface waters. It maintains a central pesticide properties database, prepares input for the PRZM, MACRO and TOXSWA models and then guides the user in performing the FOCUS Surface Water runs in a consistent and user-friendly way. Via the SWASH shell the user can enter the shells of the other models to perform the PRZM or <b>MACRO</b> model <b>runs</b> needed to assess the fate of the substance in the FOCUS water body systems using TOXSW...|$|R
40|$|The SURVEYLOGISTIC {{procedure}} in SAS ® 9 {{provides a way}} to perform logistic regression with survey data. However, some options frequently used with the LOGISTIC procedure, such as stepwise and score model selection, {{were not included in}} PROC SURVEYLOGISTIC. One such option is SELECTION=SCORE BEST=n, which is used to identify the best subsets of covariates, allowing the user to select the number of models displayed for each model size with the highest score chi-square statistics. Two methods are described here for recreating this procedure option in PROC SURVEYLOGISTIC. The first method employs <b>macros</b> that <b>run</b> PROC SURVEYLOGISTIC once for each combination of covariates; for example, there are 10, 660 possible combinations of 3 covariates from a candidate set of 41 variables, resulting in 10, 660 runs of PROC SURVEYLOGISTIC. The macro call is nested within multiple DO loops. ODS is used to output the statistic of interest. The second method uses data step programming to generate a data set that repeats the observations for each combination of covariates. PROC SURVEYLOGISTIC is executed only once using a by command to test each combination of covariates separately. Although some important options are missing from PROC SURVEYLOGISTIC, careful programming can recreate the desired results...|$|R
40|$|When {{public health}} {{officials}} requested operations research models to help county health departments across the United States create plans for dispensing medications and vaccines, we developed capacity planning and queueing network models. We then faced the challenge of distributing these models {{to a set of}} persons who have unknown experience with operations research techniques and no resources for acquiring and learning new software. We decided to use spreadsheets, which eliminated the most significant obstacles. To allow users to evaluate a wide variety of plans, we created software that <b>runs</b> <b>macros</b> to generate spreadsheet models based on user input. Public health emergency preparedness planners can download the software from our web site. Developing spreadsheets for this type of application is very different from end-user modeling and typical spreadsheet applications...|$|R
40|$|When your {{variables}} of interest are distributed on a circle (e. g., angles, times of day, dates) linear statistics often cannot be used properly. The major problem with circular variables is that values which are far apart on a linear scale can be very close together in reality. Take for example an angle of 10 degree. On a linear scale, it is 340 degrees from a second angle of 350 degrees. The true distance between the two angles, however, is only 20 degrees. This causes problems when using traditional statistical tests. Commercial software packages often do not provide tools for circular statistics, making circular statistical analyses often hard and lengthy to perform. Because I was interested in orientation issues of great tit (Parus major) nestlings (Kölliker & Richner, 2004) I became interested in circular statistics and wrote a few SAS-macros covering some basic needs when doing statistics with circular variables. The macros {{are based on the}} highly recommendable textbooks on circular statistics by Batschelet (1981) and Fisher (1993). Please consult these texts for understanding the background of circular statistics. Circular statistics macros: You find the collection of the SAS-macros in a single Text-file (“circular_stats. sas”) downloadable on www. evolution. unibas. ch/koelliker/misc. htm). You need access to SAS {{to be able to use}} the <b>macros.</b> To <b>run</b> the <b>macros,</b> download the file and run it in SAS using the “...|$|R
40|$|During the {{development}} and maintenance (life-cycle) process of SAS ® macros, especially while they are already used for production purposes, {{it is very much}} recommended to keep a history of changes, additions and bug fixes along with the macro version number. Archiving of the production SAS program code should include the applied macro version or at least the applied macro version number. That way the code can be used for reproduction purposes. Newer versions of a macro should be as much as possible backwards compatible. Then a newer version may replace an older version when running reproduction SAS programs. In case a current macro version is not fully backwards compatible it should not be used for reproduction purposes with code that used to call the older macro version. Instead the older macro version has to be used. A version control system within the macro code is presented which allows the user to specify which (compatible) version of a particular macro is to be used. If the current macro version is known not to be compatible with an older, specified version it refuses to run, generates an appropriate message and stops. The user then should take care for replacing it by the appropriate older macro version. Alternative solutions that don’t stop the code from running and that allow forcing of a specific version of a <b>macro</b> to <b>run,</b> are being presented...|$|R
40|$|This report {{describes}} a methodology for generating {{descriptive statistics for}} soils above different parent materials in the British Geological Survey’s (BGS) Humber-Trent Atlas region. There {{is a need to}} compile this type of statistics both for (i) public enquiries and (ii) populating domains on the new Parent Material Map under development at BGS. Instructions are given to link G-BASE soil data downloaded from the corporate Geochemistry Database, linking it spatially to v 0. 1 of the Parent Material Map within ArcMAP v 9. 1 and downloading the combined data into an Access database. A <b>macro</b> is <b>run</b> within Access to generate the required descriptive statistics that include maximum and minimum values, the range of data, arithmetic mean and standard deviations and geometric mean and standard deviation. For demonstration purposes, descriptive statistics are presented for the parent material classification used in the BGS Rock Classification Scheme (RCS). Further statistics were generated for parent materials split into the different geological ages of the RCS. This will produce more appropriate statistics for the Parent Material Map. After completion of this report an updated version of the macro used to generate the descriptive statistics was created. This was too late {{to be used in the}} majority of work. However, in Appendix 4, a small additional example has been added using the improved macro that includes the facility to generate percentile values...|$|R
40|$|We {{construct}} N= 1 supergravity models {{where the}} gauge symmetry and supersymmetry are both spontaneously broken, with naturally vanishing classical vacuum energy and unsuppressed Goldstino components along gauge non-singlet directions. We discuss some physically interesting situations where such a mechanism {{could play a}} role, and identify the breaking of a grand-unified gauge group as the most likely possibility. We show that, even when the gravitino mass is {{much smaller than the}} scale m_X of gauge symmetry breaking, important features can be missed if we first naively integrate out the degrees of freedom of mass O (m_X), in the limit of unbroken supersymmetry, and then describe the super-Higgs effect in the resulting effective theory. We also comment on possible connections with extended supergravities and realistic four-dimensional string constructions. Comment: 14 A 4 pages, no figures, plain LATEX (no special <b>macros,</b> to be <b>run</b> twice...|$|R
40|$|CINA is a {{software}} which uses LOTUS 1 - 2 - 3 commands and <b>macros</b> and it <b>runs</b> on an IBM PC. It contains an extensive database of three sections. Section 1 includes {{a list of}} several models of commercialized infusion devices. Section 2 presents the available IV packagings {{for a list of}} IV drugs. Section 3 contains the record of IV standard infusion regimens for each drug. Any other new infusion device, drug, or standard infusion regimen can be added or modified. The software verifies the compatibility of the prescribed infusion device according to the available drug packaging contained in the database. Moreover, it converts the infusion steps into the flow-rate units of the selected infusion device according to the patient's weight and the chosen drug concentration. Finally, the software allows the storage of all the information on a disk file or outputting on a printer. © 1991 Kluwer Academic Publishers. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|During {{the last}} year we built several {{solutions}} for opening our ET++ applications for internal and external scripting. The most annoying part to be coded manually was the code stubs that translate a string based request into the invocation of a member function. For this reason we built an ET++ specific solution that provides dispatchable member functions in an inexpensive, non-intrusive way. Our solution consists of {{an extension of the}} <b>macro</b> generated ET++ <b>run</b> time meta information. To make a member function dispatchable, a developer has to write one macro call. This generates a member function meta object providing information about arguments and a function that serves to invoke the respective member function. These two generated parts work {{in the context of the}} dynamic invocation framework, which embodies an architecture that can be customized for varying interfacing needs. 1. Introduction Our team has been developing interactive standalone applications based on the ET++ applicati [...] ...|$|R
40|$|The Freeman-Tukey double-arcsine {{transformation}} {{is used to}} transform binomial or Poisson data so that they correspond with probabilities under the standard normal. This permits use of the normal distribution for significance testing on proportions. Tukey’s HSD and other “post hoc ” multiple comparison tests have traditionally been used to test differences among groups of means. The double-arcsine transformation allows {{for the use of}} these to test differences among proportions in 2 xc contingency tables. This paper presents a Base SAS ® <b>macro</b> that will <b>run</b> Tukey’s HSD, LSD, Bonferroni, Dunn-Sidak and Scheffé tests on groups of proportions having a 2 xc structure. Simulation testing showed that each of these tests produced more conservative results and protected family-wise error rates much closer to alpha risk than pairwise χ 2 tests of association on the same proportions. The macro permits inputs as a 2 xc counts table or as proportions and their associated sample sizes...|$|R
