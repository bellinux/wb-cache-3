98|129|Public
50|$|The related causal <b>Markov</b> <b>condition</b> {{is that a}} {{phenomenon}} is independent of its noneffects, given its direct causes. In {{the event that the}} structure of a Bayesian network accurately depicts causality, the two conditions are equivalent. However, a network may accurately embody the <b>Markov</b> <b>condition</b> without depicting causality, in which case it should not be assumed to embody the causal <b>Markov</b> <b>condition.</b>|$|E
5000|$|... is a {{completely}} positive trace-preserving map, and [...] a C*-algebra of bounded operators. The pair must obey the quantum <b>Markov</b> <b>condition,</b> that ...|$|E
50|$|The <b>Markov</b> <b>condition</b> (sometimes called Markov assumption) for a Bayesian network {{states that}} any node in a Bayesian network is conditionally {{independent}} of its nondescendents, given its parents.|$|E
40|$|This paper {{investigates the}} {{condition}} for duality between the achievable rate {{regions of the}} indirect distributive source coding problem and the broadcast channel. It has been shown previously that crucial {{to the existence of}} duality are two simultaneous <b>Markov</b> <b>conditions</b> that the joint distribution must satisfy. In this paper, we illustrate that the <b>Markov</b> <b>conditions</b> are satisfied if and only if distributive coding achieves the same sum rate as centralized coding under the same joint distribution. Thus, duality is closely related to the value of cooperation. Duality exists if and only if cooperation does not help. Several classes of channels in which duality exists are illustrated as examples. They include a generalization of a previous result on Gaussian multi-terminal source coding and a novel discrete memoryless broadcast channel for which Marton’s achievable rate region is optimal at the sum rate point. ...|$|R
40|$|Abstract—The {{recovery}} theorem require <b>Markov</b> <b>conditions</b> between transitional states, but {{data shows}} that the path, partic-ularly the position with respect to recent minimum matters for states, significantly enough for equal movement p between a price p and pp depend severely on whether the latter price is above the recent minimum. Figure 1. The forward kernel at S 2 depends on the path. Implied vol at S 2 via S 1 b is much lower than implied vol at S 2 via S 1 a...|$|R
40|$|Abstract—We {{study the}} three-user multi-antenna Gaussian multiple-access channel (MAC) where {{prior to the}} {{transmission}} over the MAC the transmitters can {{communicate with each other}} over noise-free broadcast pipes of given capacities. We present the capacity region of this channel. Additionally, we also study the three-user multi-antenna Gaussian MAC with common messages and present its capacity region. The main step in deriving these two capacity results consists in proving that Gaussian distributions maximize certain mutual information expressions under multiple Markov constraints. Towards this end, a tool previously used in [3], [6], [7] is extended to the vector case and to multiple <b>Markov</b> <b>conditions.</b> I...|$|R
40|$|This paper {{analyzes}} independence concepts for sets {{of probability}} measures associated with directed acyclic graphs. The paper shows that epistemic {{independence and the}} standard <b>Markov</b> <b>condition</b> violate desirable separation properties. The adoption of a contraction condition leads to d-separation but still fails to guarantee a belief separation property. To overcome this unsatisfactory situation, a strong <b>Markov</b> <b>condition</b> is proposed, based on epistemic independence. The main {{result is that the}} strong <b>Markov</b> <b>condition</b> leads to strong independence and does enforce separation properties; this result implies that (1) separation properties of Bayesian networks do extend to epistemic independence and sets of probability measures, and (2) strong independence has a clear justi- cation based on epistemic independence and the strong <b>Markov</b> <b>condition.</b> ...|$|E
40|$|It is {{well known}} that, in {{directed}} Markov fields, the pairwise <b>Markov</b> <b>condition</b> does not imply the global <b>Markov</b> <b>condition,</b> unless the distribution is strictly positive. We introduce a stronger version of the pairwise condition which requires that every nonadjacent pair be independent conditional on every set that separates the pair in the graph. We show that this stronger condition {{is equivalent to the}} global <b>Markov</b> <b>condition</b> (for all probability distributions.) We generalize this result to abstract dependency models, and show that a weaker condition holds for compositional graphoids. ...|$|E
40|$|The {{development}} of causal modelling since the 1950 s {{has been accompanied}} by a number of controversies, the most striking of which concerns the <b>Markov</b> <b>condition.</b> Reichenbach's conjunctive forks did satisfy the <b>Markov</b> <b>condition,</b> while Salmon's interactive forks did not. Subsequently some experts in the field have argued that adequate causal models should always satisfy the <b>Markov</b> <b>condition,</b> while others have claimed that non-Markovian causal models are needed in some cases. This paper argues for the second position by considering the multi-causal forks, which are widespread in contemporary medicine (Section 2). A non-Markovian causal model for such forks is introduced and shown to be mathematically tractable (Sections 6, 7, and 8). The paper also gives a general discussion of the controversy about the <b>Markov</b> <b>condition</b> (Section 1), and of the related controversy about probabilistic causality (Sections 3, 4, and 5...|$|E
40|$|Abstract. This paper studies: (i) {{the long}} time {{behaviour}} of the empirical distribution {{of age and}} normalised position of an age dependent critical branching <b>Markov</b> process <b>conditioned</b> on non-extinction; and (ii) the super-process limit of a sequence of age dependent critical branching Brownian motions. 1...|$|R
40|$|Abstract—Aspects of the duality {{between the}} {{information}}-em-bedding {{problem and the}} Wyner–Ziv problem of source coding with side information at the decoder are developed and used to es-tablish a spectrum new results on these and related problems, with implications {{for a number of}} important applications. The single-letter characterization of the information-embedding problem is developed and related to the corresponding characterization of the Wyner–Ziv problem, both of which correspond to optimization of a common mutual information difference. Dual variables and dual <b>Markov</b> <b>conditions</b> are identified, along with the dual role of noise and distortion in the two problems. For a Gaussian context with quadratic distortion metric, a geometric interpretation of the duality is developed. From such insights, we develop a capacity-achieving information-embedding system based on nested lattices. We show the resulting encoder–de...|$|R
40|$|AbstractFrobenius {{published}} two proofs of a theorem {{which characterizes}} irreducible and fully indecomposable matrices in an algebraic manner. It is {{shown that the}} second proof, which depends on the Frobenius-König theorem, yields a stronger form of the result than the first. Some curious features in Frobenius's last paper are examined; these include his criticisms of a result due to D. König and the latter's application of graph theory to matrices. A condition on matrices formulated by Markov is examined in detail {{to show that it}} may coincide with Frobenius's concept of irreducibility, and several theorems on stochastic matrices of Perron-Frobenius type proved by Marcov are exhibited. In a research part of the paper, a theorem is proved which characterizes irreducible matrices and which contains Frobenius's theorem and was motivated by <b>Markov's</b> <b>condition...</b>|$|R
40|$|In {{deterministic}} causal chains {{the relations}} „A causes B ’ and „B causes C ’ imply that „A causes C’. However, {{this is not}} necessarily the case for probabilistic causal relationships: A may probabilistically cause B, and B may probabilistically cause C, but A does not probabilistically cause C, but rather ¬C. The normal transitive inference is only valid when the <b>Markov</b> <b>condition</b> holds, a key feature of the Bayes net formalism. However, it has been objected that the Markov assumption does not need to hold in the real world. In our studies we examined how people reason about causal chains that do not obey the <b>Markov</b> <b>condition.</b> Three experiments involving causal reasoning within causal chains provide evidence that transitive reasoning seems to hold psychologically, even when it is objectively not valid. Whereas related research has shown that learners assume the <b>Markov</b> <b>condition</b> in causal chains in the absence of contradictory data, we here demonstrate the use of this assumption for situations in which participants were directly confronted with evidence contradicting the <b>Markov</b> <b>condition.</b> The results suggest a causal transitivity heuristic resulting from chaining individual causal links into mental causal models that obey the <b>Markov</b> <b>condition...</b>|$|E
3000|$|..., which {{satisfies}} the <b>Markov</b> <b>condition</b> as already described, constitutes the developed integrated BN.|$|E
40|$|This essay {{explains}} what the Causal <b>Markov</b> <b>Condition</b> says and defends the condition {{from the many}} criticisms that have been launched against it. Although we are skeptical {{about some of the}} applications of the Causal <b>Markov</b> <b>Condition,</b> we argue that it is implicit in the view that causes can be used to manipulate their effects and that it cannot be surrendered without surrendering this view of causation...|$|E
40|$|State space {{truncation}} {{is frequently}} demanded for practical computations of large or infinite <b>Markov</b> chains. <b>Conditions</b> are given which guarantee an error bound or rate of convergence. Concrete truncations and explicit error bounds are obtained for two non-product form queueing applications: an overflow model and a Candem queue with blocking...|$|R
40|$|Consider a 3 -state {{system with}} one {{absorbing}} state, such as Healthy, Sick, and Dead. If the system satisfies the 1 -step <b>Markov</b> <b>conditions,</b> {{the prevalence of}} the Healthy state will converge to a value that is independent of the initial distribution. This equilibrium prevalence and its variance are known under the assumption of time homogeneity, and provided reasonable estimates in the time non-homogeneous systems studied. Here, we derived the equilibrium prevalence for a system with more than three states. Under time homogeneity, the equilibrium prevalence distribution was shown to be an eigenvector of a partition of the matrix of transition probabilities. The eigenvector worked well for time non-homogeneous examples as well. We developed a test for whether the available sample was at equilibrium, {{and used it to}} explore whether there was selection bias in the baseline distribution of a large longitudinal cohort sample...|$|R
40|$|This paper {{provides}} a simulated moments estimator (SME) of {{the parameters of}} dynamic models {{in which the state}} vector follows a time-homogeneous <b>Markov</b> process. <b>Conditions</b> are provided for both weak and strong consistency as well as asymptotic normality. Various tradeoff's among the regularity conditions underlying the large sample properties of the SME are discussed {{in the context of an}} asset pricing model. ...|$|R
30|$|Now, {{we suggest}} a {{characterization}} {{based on the}} augmented backwards vector. This result also shows the independence from the time direction of the <b>Markov</b> <b>condition.</b>|$|E
40|$|The aim of {{the paper}} is to relate Bell's notion of local {{causality}} to the Causal <b>Markov</b> <b>Condition.</b> To this end, first a framework, called local physical theory, will be introduced integrating spatiotemporal and probabilistic entities and the notions of local causality and Markovity will be defined. Then, illustrated in a simple stochastic model, it will be shown how a discrete local physical theory transforms into a Bayesian network and how the Causal <b>Markov</b> <b>Condition</b> arises as a special case of Bell's local causality and Markovity...|$|E
40|$|The present text {{comments}} on Steel 2005, {{in which the}} author claims to extend from the deterministic to the general case, the result according to which the causal <b>Markov</b> <b>condition</b> is satisfied by systems with jointly independent exogenous variables. I show that Steel's claim cannot be accepted unless one is prepared to abandon standard causal modeling terminology. Correlatively, I argue that the most fruitful aspect of Steel 2005 consists in a realist conception of error terms, and I show how this conception sheds {{new light on the}} relationship between determinism and the causal <b>Markov</b> <b>condition...</b>|$|E
40|$|Frobenius {{published}} two proofs of a theorem {{which characterizes}} irreducible and fully indecomposable matrices in an algebraic manner. It is {{shown that the}} second proof, which depends on the Frobenius-Konig theorem, yields a stronger form of the result than the first. Some curious features in Frobenius’s last paper are examined; these include his criticisms of a result due to D. K&rig and the latter’s application of graph theory to matrices. A condition on matrices formulated by Markov is examined in detail {{to show that it}} may coincide with Frobenius’s concept of irreducibility, and several theorems on stochastic matrices of Perron-Frobenius type proved by Markov are exhibited. In a research part of the paper, a theorem is proved which characterizes irreducible matrices and which contains Frobenius’s theorem and was motivated by <b>Markov’s</b> <b>condition.</b> 0. Introduction and Motivution This article combines detailed examination of parts of classical and influential papers by G. F. Frobenius (1849 - 1917), A. A. Marko...|$|R
40|$|We {{consider}} the parallel computation of the stationary probability distribution vector of ergodic Markov chains with large state spaces by preconditioned Krylov subspace methods. The parallel preconditioner is obtained as an explicit approximation, in factorized form, {{of a particular}} generalized inverse of the infinitesimal generator of the <b>Markov</b> process. <b>Conditions</b> that guarantee {{the existence of the}} preconditioner are given, and the results of a parallel implementation are presented...|$|R
40|$|We {{consider}} a financial market {{driven by a}} continuous time homogeneous <b>Markov</b> chain. <b>Conditions</b> for absence of arbitrage and for completeness are spelled out, non-arbitrage pricing of derivatives is discussed, and details are worked out for some cases. Closed form expressions are obtained for interest rate derivatives. Computations typically amount to solving a set of first order partial differential equations. An excursion into risk minimization in the incomplete case illustrates the matrix techniques that are instrumental in the model...|$|R
40|$|Nancy Cartwright's {{comments}} ([2002]) expose some {{gaps and}} {{difficulties in the}} argument for the causal <b>Markov</b> <b>condition</b> in our essay ‘Independence, Invariance and the Causal Markov Condition’ ([1999]), and we are grateful {{for the opportunity to}} reformulate our position. In particular, Cartwright disagrees vigorously with many of the theses we advance about the connection between causation and manipulation. Although we are not persuaded by some of her criticisms, we shall confine ourselves to showing how our central argument can be reconstructed and to casting doubt on Cartwright's claim that the causal <b>Markov</b> <b>condition</b> typically fails when there are indeterministic by-products...|$|E
40|$|The present text {{comments}} {{on a paper}} by Daniel Steel, in which the author claims to extent from the deterministic to the general case the result according to which the causal <b>Markov</b> <b>condition</b> is satisfied by systems with jointly independent exogenous variables. I show that Steel's claim cannot be accepted unless one is prepared to abandon standard causal modeling terminology. Correlatively, I argue that the most fruitful aspect of Steel's paper consists in a realist conception of error terms and I show how this conception sheds {{new light on the}} relationship between determinism and the causal <b>Markov</b> <b>condition...</b>|$|E
40|$|AbstractThe <b>Markov</b> <b>condition</b> {{describes}} the conditional independence relations {{present in a}} causal model that are consequent to its graphical structure, whereas the faithfulness assumption presumes {{that there are no}} other independencies in the model. Cartwright argues that causal inference methods have limited applicability because the <b>Markov</b> <b>condition</b> cannot always be applied to domains, and gives an example of its incorrect application. Cartwright also argues that both humans and Nature, fairly commonly, design objects that violate the faithfulness assumption. Because both arguments suggest that data {{is not likely to be}} ideal, we suggest that problems of the theory be separated from problems of the data. As regards the <b>Markov</b> <b>condition,</b> conflicted intuitions about conditional independence relationships in certain complex domains can be explained in terms of measurement and of proxy selection. As regards faithfulness, we show that violations of this assumption do not affect the predictive powers of causal models. More generally, the criticisms of causal models, taken constructively, reveal the subtlety of the ideal, while clarifying the source of problems in data...|$|E
40|$|Abstract — Safety-critical {{control systems}} use fault {{tolerant}} interconnections of components {{to minimize the}} effect of randomly triggered faults. The system availability process indicates {{whether or not the}} interconnection is operating correctly at each time instant. It is a 2 -state process that results from the transformation of the stochastic processes characterizing the availability processes of the interconnected components. To analyze closed-loop systems controlled by these fault tolerant interconnected components, it is important to determine the characteristics of the system availability process. When the availability processes of the interconnected components are independent homogeneous Markov chains, the statistical nature of the system availability process is characterized. In particular, it is shown that the system availability process is not necessarily Markov, but has a well-defined one-step transition probability matrix that approaches a constant stochastic matrix at steady-state. Since it is simpler to analyze switched closed-loop systems when the switching process is <b>Markov,</b> <b>conditions</b> for the system availability process to be a Markov chain for all initial distributions are determined. A sufficient stability condition is given when the system availability process is a non-homogeneous Markov chain for a class of initial distributions. I...|$|R
40|$|Service {{delivery}} systems influence outcomes of personal social services. To understand and redesign {{delivery systems}} new conceptual and analytic tools are needed. The notion of delivery systems {{as a set}} of statuses through which clients move permits construction of transition matrixes to display caseload dynamics. In this study, analysis of such matrixes for a large child care system reveals patterns of movement not otherwise seen. It is concluded from inspection of tables and from testing for <b>Markov</b> <b>conditions</b> that the system is not changing despite administrative interventions. Probabilities of movement among statuses appear to be functions of the system and not determined by the history of the particular child. These findings suggest that the fate of children in placement is determined more by system dynamics than by client or professional considerations. This study shows that modeling of service delivery {{as a set of}} transition probabilities is a useful tool for evaluation of social systems. /) elivery systems for health and personal social services haveL attracted more attention as they have grown and their effects on clients have begun to be appreciated. The locus of service is the interaction between the client and the professional; but this interactio...|$|R
40|$|AbstractNecessary {{conditions}} are given for a symmetric α-stable (SαS) process, 1 < α < 2, to be <b>Markov.</b> These <b>conditions</b> are then applied to find Markov or weakly Markov processes within certain important classes of SαS processes: time changed Lévy motion, scale mixed Gaussian processes, moving averages and harmonizable processes. Two stationary SαS Markov processes are introduced, {{the right and}} the left SαS Ornstein-Uhlenbeck processes. Some of the results are in sharp contrast to the Gaussian case α = 2...|$|R
30|$|The causal <b>Markov</b> <b>condition</b> holds (i.e., each {{variable}} {{is independent of}} its nondescendants in the DAG conditioning on its parents), and in addition, the error term in X_i is independent from the parents of X_i.|$|E
40|$|This paper {{explores the}} {{relationship}} between a manipulability conception of causation and the causal <b>Markov</b> <b>condition</b> (CM). We argue that violations of CM also violate widely shared expectations—implicit in the manipulability conception—having to do with the absence of spontaneous correlations. They also violate expectations concerning the connection between independence or dependence relationships in the presence and absence of interventions. 1. Introduction. The causal <b>Markov</b> <b>condition</b> (CM) relates probability distributions to the causal structures that generate them. Given the direct causal relationships among the variables in some set V and an associated probability distribution P over V, CM says that conditional on its parents (its direct causes in V) every variable is independent of every other variable...|$|E
40|$|Previous {{research}} has {{cast doubt on}} whether the <b>Markov</b> <b>condition</b> is a default assumption of human causal reasoning—as causal Bayes net approaches suggest. Human subjects often seem to violate the <b>Markov</b> <b>condition</b> in common-cause reasoning tasks. While this might be treated as evidence that humans are inefficient causal reasoners, we propose that the underlying human intuitions reflect abstract causal knowledge that is sensitive to {{a great deal of}} contextual information— knowledge of the “causal background”. In this paper, we introduce a hierarchical Bayesian model of causal background knowledge which explains Markov violations and makes additional, more fine-grained predictions on the basis of causally relevant category membership. We confirm these predictions using an experimental paradigm which extends that used in previous studies of “Markov violation. ...|$|E
40|$|AbstractOn compact sets {{preserving}} <b>Markov's</b> inequality, Bernstein-type <b>conditions</b> for {{a continuous}} function {{to be of}} class Ck are discussed. Also, relationships between the distribution of zeros of polynomials of best uniform or Lp approximation to a given function and its differential properties are established...|$|R
40|$|We {{consider}} {{the problem of}} simulation-based estimation of performance measures for a <b>Markov</b> chain <b>conditioned</b> on a rare event. The conditional law depends on the solution of a multiplicative Poisson equation. An adaptive scheme for learning the latter is proposed and analyzed. An example motivated by a well known problem in communication networks is given. Applications of the basic scheme to other related domains such as importance sampling for rare event simulation and the solution of a class of eigenvalue problems are also sketched...|$|R
40|$|We {{study the}} problem of long-run average cost control of <b>Markov</b> chains <b>conditioned</b> on a rare event. In a related recent work, a {{simulation}} based algorithm for estimating performance measures associated with a <b>Markov</b> chain <b>conditioned</b> on a rare event has been developed. We extend ideas from this work and develop an adaptive algorithm for obtaining, online, optimal control policies conditioned on a rare event. Our algorithm uses three timescales or step-size schedules. On the slowest timescale, a gradient search algorithm for policy updates {{that is based on}} one-simulation simultaneous perturbation stochastic approximation (SPSA) type estimates is used. Deterministic perturbation sequences obtained from appropriate normalized Hadamard matrices are used here. The fast timescale recursions compute the conditional transition probabilities of an associated chain by obtaining solutions to the multiplicative Poisson equation (for a given policy estimate). Further, the risk parameter associated with the value function for a given policy estimate is updated on a timescale that lies in between the two scales above. We briefly sketch the convergence analysis of our algorithm and present a numerical application in the setting of routing multiple flows in communication networks. Key Words: Markov decision processes, optimal control conditioned on a rare event, simulation based algorithms, SPSA with deterministic perturbations, reinforcement learning. ...|$|R
