1096|2101|Public
25|$|In ALGOL 68S(S) from Carnegie Mellon University {{the power}} of {{parallel}} processing was improved by adding an orthogonal extension, eventing. Any variable declaration containing keyword event made assignments to this variable eligible for parallel evaluation, i.e. the right hand side {{was made into a}} procedure which was moved to one of the processors of the C.mmp <b>multiprocessor</b> <b>system.</b> Accesses to such variables were delayed after termination of the assignment.|$|E
25|$|The Alpha 21164 or EV5 became {{available}} in 1995 at processor frequencies {{of up to}} 333MHz. In July 1996 the line was speed bumped to 500MHz, in March 1998 to 666MHz. Also in 1998 the Alpha 21264 (EV6) was released at 450MHz, eventually reaching (in 2001 with the 21264C/EV68CB) 1.25GHz. In 2003, the Alpha 21364 or EV7 Marvel was launched, essentially an EV68 core with four 1.6 GB/s inter-processor communication links for improved <b>multiprocessor</b> <b>system</b> performance, running at 1 or 1.15GHz.|$|E
500|$|In 1969, company Honeywell {{introduced}} its first Multics system, a symmetric <b>multiprocessor</b> <b>system</b> capable of {{running up to}} eight processors in parallel. C.mmp, a 1970s multi-processor project at Carnegie Mellon University, {{was among the first}} multiprocessors with more than a few processors. The first bus-connected multiprocessor with snooping caches was the Synapse N+1 in 1984." ...|$|E
40|$|Simulated {{annealing}} {{has proven}} to be a good technique for solving hard combinatorial optimization problems. Some attempts at speeding up annealing algorithms have been based on shared memory <b>multiprocessor</b> <b>systems.</b> Also parallelizations for certain problems on distributed memory <b>multiprocessor</b> <b>systems</b> are known...|$|R
40|$|AbstractMultiprocessor {{systems have}} been widely used for the {{execution}} of parallel applications. Task scheduling is crucial for the right operation of <b>multiprocessor</b> <b>systems,</b> where the aim is shortening the length of schedules. Fault tolerance is becoming a necessary attribute in <b>multiprocessor</b> <b>systems</b> as the number of processing elements is getting larger. This paper presents a fault tolerant scheduling algorithm for task graph applications in <b>multiprocessor</b> <b>systems.</b> The algorithm is an extension of a previously proposed algorithm with a reduced communications scheme. Simulation results show the efficiency of the proposed algorithm despite its simplicity...|$|R
5000|$|ThreadWeaver - {{library to}} use <b>multiprocessor</b> <b>systems</b> more {{effectively}} ...|$|R
500|$|One of {{the main}} motivations for {{studying}} book embedding cited by [...] involves an application in VLSI design, to the organization of fault-tolerant multiprocessors. In the DIOGENES system developed by these authors, the CPUs of a <b>multiprocessor</b> <b>system</b> are arranged into a logical sequence corresponding to the spine of a book (although this sequence {{may not necessarily be}} placed along a line in the physical layout of this system). Communication links connecting these processors are grouped into [...] "bundles" [...] which correspond to the pages of a book and act like stacks: connecting one of the processors to {{the start of a new}} communications link pushes all the previous links upward in the bundle, and connecting another processor to the end of a communication link connects it to the one at the bottom of the bundle and pops all the other ones down. Because of this stack behavior, a single bundle can handle a set of communications links that form the edges of a single page in a book embedding. [...] By organizing the links in this way, a wide variety of different network topologies can be implemented, regardless of which processors have become faulty, as long as enough non-faulty processors remain to implement the network. [...] The network topologies that can be implemented by this system are exactly the ones that have book thickness at most equal to the number of bundles that have been made available.|$|E
2500|$|... /ONECPU [...] Equivalent {{to using}} /NUMPROC=1. Causes Windows {{to use only}} one CPU on a <b>multiprocessor</b> <b>system.</b>|$|E
2500|$|... /NUMPROC=nnn [...] Sets {{the number}} of {{processors}} that Windows will run at startup. With this switch, the user can force a <b>multiprocessor</b> <b>system</b> to use only the quantity of processors (number) that you specify. Useful for troubleshooting performance problems and defective CPUs.|$|E
25|$|Native {{operating}} system support for PPM on <b>multiprocessor</b> <b>systems,</b> including systems using processors with multiple logical threads, multiple cores, or multiple physical sockets.|$|R
5000|$|... spinlocks, which prevent, in <b>multiprocessor</b> <b>systems,</b> spinlocking-thread {{from being}} preempted; ...|$|R
40|$|Abstract â€” Multiprocessor designs {{have become}} popular in {{embedded}} domains for achieving {{the power and}} performance requirements. In this paper, we present principles and techniques for design and implementation of RTOS for embedded <b>multiprocessor</b> <b>systems.</b> We also present a system-level design toolkit for rapid design and evaluation of embedded <b>multiprocessor</b> <b>systems.</b> I...|$|R
5000|$|C.mmp - <b>Multiprocessor</b> <b>system</b> from Carnegie Mellon University.|$|E
50|$|In a <b>multiprocessor</b> <b>system,</b> coprocessors {{could not}} be shared between CPUs. To avoid {{problems}} with returns from coprocessor, bus error, and address error exceptions, it was generally necessary in a <b>multiprocessor</b> <b>system</b> for all CPUs {{to be the same}} model, and for all FPUs to be the same model as well.|$|E
5000|$|... /ONECPU [...] - [...] Equivalent {{to using}} /NUMPROC=1. Causes Windows {{to use only}} one CPU on a <b>multiprocessor</b> <b>system.</b>|$|E
5000|$|... = various {{secondary}} effects, such as queuing {{effects in}} <b>multiprocessor</b> <b>systems</b> ...|$|R
40|$|SOPC Builder Altera ??? ???????? ????????????????? ??????. ???????? ??????????? ?? ??????????? ??????????????? ?? ?????????????? ???????????? ?????? NIOS II Altera, ???? ??????????? ??? ??????????????????? ????????? ??????????? ???????. General {{information}} of {{the methodology of}} <b>multiprocessor</b> <b>systems</b> on chip based on FPGA are provided. The features of a standard design flow facilities SOPC Builder Altera to develop <b>multiprocessor</b> <b>systems</b> are considered. Modeling and research of programmable multiprocessor cores NIOS II Altera, which is designed for high-performance control functions are completed...|$|R
40|$|During {{the recent}} years, {{computer}} performance has increased dramatically. To measure {{the performance of}} computers, benchmarks are ideal tools. Benchmarks exist in many areas and point to different applications. For instance, in a normal PC, benchmarks {{can be used to}} test the performance of the whole system which includes the CPU, graphic card, memory <b>system,</b> etc. For <b>multiprocessor</b> <b>systems,</b> there also exist open source benchmark programs. In our project, we gathered information about some open benchmark programs and investigated their applicability for evaluating embedded <b>multiprocessor</b> <b>systems</b> intended for radar signal processing. During our investigation, parallel cluster <b>systems</b> and embedded <b>multiprocessor</b> <b>systems</b> were studied. Two benchmark programs, HPL and NAS Parallel Benchmark were identified as particularly relevant for the application field. The benchmark testing was done on a parallel cluster system which has an architecture that is similar to the architecture of embedded <b>multiprocessor</b> <b>systems,</b> used for radar signal processing...|$|R
5000|$|Multiprocessor (Symmetric <b>multiprocessor</b> <b>system)</b> {{links to}} connect other POWER9 {{processors}} {{in on the}} same motherboard, or in other closely attached enclosures.|$|E
5000|$|Inter-processor {{interrupt}} (IPI): {{a special}} case of interrupt that is generated by one processor to interrupt another processor in a <b>multiprocessor</b> <b>system.</b>|$|E
5000|$|Loop {{over the}} data, placing each {{element in the}} {{appropriate}} bucket. (This may mean: send it to a processor, in a <b>multiprocessor</b> <b>system.)</b> ...|$|E
50|$|Of course, <b>multiprocessor</b> <b>systems</b> add {{their own}} complications, {{which are not}} {{addressed}} here.|$|R
40|$|With {{more and}} more {{multiprocessor}} computers coming to the market and applications, system reliability is becoming a key issue of the <b>multiprocessor</b> <b>systems.</b> As there is an inherent characteristic of redundancy existing in the <b>multiprocessor</b> <b>systems,</b> the way to raise {{the reliability of the}} systems is turned to software strategy rather than m hardware redundancy. Aiming at realizing fault tolerance and making better utilization of system resources, this paper presents a fault tolerant strategy to raise the reliability for the <b>multiprocessor</b> <b>systems,</b> which utilizes a common class of operating system algorithm referred to as Self-Scheduling (SS). Simulation results have been analyzed to show the feasibility of the proposed fault tolerant policy...|$|R
40|$|Computer architects have {{realized}} that interconnection bandwidth has become a critical limitation {{to the development of}} high-performance <b>multiprocessor</b> <b>systems.</b> Major reason is that the progress of processor performance has increasingly outpaced that of the interconnection networks, thereby limiting the usefulness of <b>multiprocessor</b> <b>systems.</b> This work presents a comprehensive study and the development of optoelectronicbased network routers. Optoelectronic technology can potentially provide ample bandwidth required by <b>multiprocessor</b> <b>systems</b> {{but at the same time}} can raise some critical issues that are discussed here such as on-chip wiring and chip packaging. We also propose new architectural techniques suitable for the development of optoelectronic- based network routers to increase the network bandwidth utilization...|$|R
5000|$|In a <b>multi{{processor}}</b> <b>system</b> running Microsoft Windows, {{a processor}} may interrupt another processor {{for the following}} reasons, {{in addition to the}} ones listed above: ...|$|E
5000|$|Method and {{apparatus}} for shared cache coherency for a chip multiprocessor or <b>multiprocessor</b> <b>system</b> Method and apparatus for {{floating point}} operations and format conversion operations ...|$|E
50|$|Sindhu's {{earlier work}} {{subsequently}} influenced the architecture, design, {{and development of}} Sun Microsystems' first high-performance <b>multiprocessor</b> <b>system</b> family, which included systems such as the SS1000 and SC2000.|$|E
40|$|The large {{potential}} of <b>multiprocessor</b> <b>systems</b> is frequently not fully realized {{by the way}} that they are supported by the system services. It is often the case that certain synchronization methods, such as lockbased ones, may limit the parallelism. But it is possible to share data without using locks, by employing wait/lock-free (a. k. a. non-blocking) synchronization, which offers guarantees for time-dependability and fault-tolerance. It is significant to see the impact of wait/lock-free synchronization design in key services and data structures for <b>multiprocessor</b> <b>systems,</b> such as the memory allocation service. Efficient, scalable memory allocators for multithreaded applications in <b>multiprocessor</b> <b>systems</b> is a significant goal of recent research projects. In this paper we propose [...] ...|$|R
5000|$|SWAP: Technology {{that can}} reflash the BIOS of <b>multiprocessor</b> <b>systems</b> that run FreeBSD, Linux, Solaris, or Windows.|$|R
40|$|This paper {{considers}} {{questions of}} an effective use of <b>multiprocessor</b> computing <b>system</b> to implement a parallel algorithm solving the multiphase gas dynamics problem. A technique is offered to parallelize the two-dimensional explicit differential scheme to implement it on <b>multiprocessor</b> <b>systems</b> with distributed memory (MIMD architecture) ...|$|R
5000|$|In a <b>multiprocessor</b> <b>system,</b> {{consider}} {{that more than}} one processor has cached a copy of the memory location X. The following conditions are necessary to achieve cache coherence: ...|$|E
50|$|CPU {{shielding}} is {{a practice}} where on a <b>multiprocessor</b> <b>system</b> or on a CPU with multiple cores, real-time tasks can run on one CPU or core while non-real-time tasks run on another.|$|E
5000|$|An inter-processor {{interrupt}} (IPI) {{is a special}} type of interrupt by which one processor may interrupt another processor in a <b>multiprocessor</b> <b>system</b> if the interrupting processor requires action from the other processor. Actions that might be requested include: ...|$|E
40|$|The role of {{workstations}} {{in future}} systems {{has been a}} hotly debated topic. Some believe the workstation is useful primarily as a terminal and that the computing {{of the future will}} be done on large <b>multiprocessor</b> <b>systems.</b> Others believe that workstations will be the processors of those <b>multiprocessor</b> <b>systems.</b> Still others believe that the role of the workstation will be between the two extremes, providing simple processing capabilities such as editing for the local user...|$|R
5000|$|At the {{opposite}} extreme {{is a truly}} random memory access pattern. A few <b>multiprocessor</b> <b>systems</b> are specialised to deal with these.|$|R
40|$|Fault {{diagnosis}} {{is important to}} the design and maintenance of large <b>multiprocessor</b> <b>systems.</b> PMC model is the most famous diagnosis model in the system level diagnosis of <b>multiprocessor</b> <b>systems.</b> Under the PMC model, only node faults are allowed. But in real circumstances, link faults may occur. So based on the PMC model, we propose in this paper a diagnosis model called the generalized PMC(GPMC) model to adapt to the real circumstances. The foundation of GPMC model has been established. And to measure the fault diagnosis capability of <b>multiprocessor</b> <b>systems</b> under the GPMC model, the fault diagnosis capability measuring parameters: $h$-edge restricted diagnosability and $h$-vertex restricted edge diagnosability have been introduced. As an application, the $h$-edge restricted diagnosability and $h$-vertex restricted edge diagnosability of hypercubes are explored. Comment: 5 pages no figure...|$|R
