4|30|Public
40|$|Many {{macro-economic}} forecasts and forecast updates, such {{as those}} from the IMF and OECD, typically involve both a model component, which is replicable, as well as intuition (namely, expert knowledge possessed by a forecaster), which is non-replicable.. Learning from previous mistakes can affect both the replicable component of a model as well as intuition. If learning, and hence forecast updates, are progressive, forecast updates should generally become more accurate as the actual value is approached. Otherwise, learning and forecast updates would be neutral. The paper proposes a methodology to test whether <b>macro-economic</b> <b>forecast</b> updates are progressive, where the interaction between model and intuition is explicitly taken into account. The data set for the empirical analysis is for Taiwan, where we have three decades of quarterly data available of forecasts and their updates of two economic fundamentals, namely the inflation rate and real GDP growth rate. The empirical {{results suggest that the}} forecast updates for Taiwan are progressive, and that progress can be explained predominantly by improved intuition. Macro-economic forecasts, econometric models, intuition, learning, progressive forecast updates, forecast errors. ...|$|E
40|$|The {{macroeconomic}} {{determinants of}} banking sector distresses in the Nordic countries, Belgium, Ger-many, Greece, Spain and the UK are analysed using an econometric model estimated on panel data from partly the early 1980 s to 2002. The dependent variable is {{the ratio of}} banks’ loan losses to lending. In ad-dition to the lagged dependent variable, the explanatory variables include a surprise change in incomes and real interest rates, both variables as a separate cross-product term with lagged aggregate indebtedness. The underlying macroeconomic account that this paper puts forward is that loan losses are basically gen-erated by strong adverse aggregate shocks under high exposure of banks to such shocks. The underlying innovations to income and real interest rates are constructed using published <b>macro-economic</b> <b>forecast</b> for these variables. According to the results, high customer indebtedness combined with adverse macroeco-nomic surprise shocks to income and real interest rates contributed to the distress in banking sector. Loan losses also display strong autoregressive behaviour which might indicate a feedback effect from loan losses back to macroeconomic level in deep recessions. The results {{can be used in}} macro stress-testing the banking sector. financial fragility; shock; loan loss; banking crisis...|$|E
40|$|The {{purpose of}} this {{document}} is to describe {{the features of the}} Agriculture and Agri-Food Canada (AAFC) Medium Term Outlook for Canadian Agriculture (previously entitled Medium Term Policy Baseline) covering the period 2007 to 2017. The outlook is an attempt to outline a plausible future of the international and domestic agri-food sectors. It serves as a benchmark for discussion and scenario analysis. The outlook makes specific assumptions and outlines their implications. Since it assumes that policies remain unchanged from existing legislation, the outlook is not a forecast of future events. The medium term assumptions used and published by the OECD/FAO in the Agricultural Outlook 2007 - 2016 are by in large maintained in the AAFC's international agricultural markets outlook but updated to reflect short term price forecasts produced and released by USDA in October 2007. The world prices generated by this process combined with the <b>macro-economic</b> <b>forecast</b> for Canada published by the Conference Board in September 2007 are the key inputs used to produce the Canadian agricultural markets outlook. The key sectors covered are grains, oilseeds and products, special crops, bio-fuels, beef/cattle, pork/hogs, milk and dairy products, chicken, turkey and eggsOutlook, agriculture, cereals, oilseeds, bio-fuels, livestock, red meats, milk, dairy products, chicken, turkey, eggs, Agribusiness, Agricultural and Food Policy, International Relations/Trade, Livestock Production/Industries,...|$|E
40|$|We develop {{projections}} of China's likely meat {{trade in the}} year 2010 using a general equilibrium model in conjunction with forecasts of productivity growth rates and <b>macro-economic</b> <b>forecasts.</b> Interestingly, <b>macro-economic</b> uncertainty {{appears to be more}} important in driving China's net trade position in meats than is sector-specific supply uncertainty. International Relations/Trade,...|$|R
40|$|The Belgian Federal Planning Bureau (BFPB) is {{a public}} agency under the {{authority}} of the Prime Minister and the Minister of Economic Affairs. The BFPB has a legal status that gives it an autonomy and intellectual independence within the Belgian Federal public sector. BFPB’activities are primarily focused on <b>macro-economic</b> <b>forecasting,</b> analysing and assessing policies in the economic, social and environmental fields...|$|R
40|$|We will be devoting to {{fundamentals}} of nonlinear dynamics, model equation derivation, classical methods for solving nonlinear oscillations, and modern nonlinearity identification techniques that {{are employed in}} solids mechanics, fluid dynamics, meteorology, even <b>macro-economic</b> <b>forecasting.</b> During {{the first half of}} the course, a series of formal lectures will be given. This will be followed by common and individualized reading assignments, and by student presentations that summarize each topical areas. Term project(s) will then cap the course. Instructor...|$|R
40|$|THB present {{paper will}} {{describe}} {{some aspects of}} research carried out at the Research Department of the Bank of Israel since 1958 in connection with forecasting and the programming of Israel's development. Work of this kind had already been carried out in Israel at an earlier stage 1 and present research has greatly benefited from it. I shall, however, confine myself to the more recent, though short, experience with which I feel more familiar. Being more of a survey the description will of necessity be rather sketchy and brief, but I shall try {{to refer to the}} relevant sources for additional material, in case of interest. The present phase in the field of analysis and programming of development had its origins in discussions in the Ministry of Finance and the Bank of Israel towards the end of 1957. It was felt at the time that although {{there was a great deal}} of Govern-ment intervention in many fields of economic activity (such as large-scale promotion of and participation in development projects, export promotion through subsidies and allowances, licensing of imports, and other broad fiscal and monetary measures), and although there seemed to prevail some broad agreement as to the basic aims and needs of this economy (such as the absorption into full employment of large-scale immigra-tion and the gradual closing of a considerable import gap), there had been little in the way of integration of individual sector plans and policy measures into one consistent whole. Need was felt for a long-term <b>macro-economic</b> <b>forecast</b> or plan which could be translated into annual 'National Budgets'. The latter were intended to form the background to the various Government budgets (the Regular, Development, and Foreign Currency Budgets) submitted to Parliament towards the beginning of the ' Among thc planning projects in the past the ones of widest scope were, notably, carricd our by Dr. A. L. Gaarhon, first in the Jewish Agency [I] andafte...|$|E
40|$|This study {{examines}} {{the ability of}} economists to forecast ten major economic series. The {{data for this study}} were provided by J. A. Livingston of the Philadelphia Inquirer, who since 1947 has collected forecasts for the upcoming 6 and 12 months. The results reveal that, in general, for the period from 1947 through 1978, the economists in Livingston's sample did not produce efficient forecasts and were not able to outperform simple statistical models. It should be noted, however, that a substantial and consistent improvement in forecasting performance by economists in Livingston's sample did occur over this same period. These results contain important information for managers who use <b>macro-economic</b> consensus <b>forecasts.</b> consensus <b>forecasts,</b> <b>macro-economic</b> variables, efficient <b>forecasts,</b> forecast errors...|$|R
40|$|Apart from {{input-output}} studies, {{little effort}} {{appears to have}} been made to construct general-purpose macro-economic models of the Irish economy. A paper by Brendan Walsh is one exception. (See his "Econometric Macro-Model Building in the Irish Context", ESRI Quarterly Economic Commentary, June 1970.) The present study is an attempt to move some small distance in filling the significant gap which still remains in the macro-economic analysis of the economy. Apart from their possible academic interest, models of the kind developed here should be of interest to Government as guides in the formation of budgetary policy. The model constructed in this paper may also be of interest to banks and large industrial firms concerned with <b>macro-economic</b> <b>forecasting</b> as a basis for their own short-run planning...|$|R
40|$|This paper {{presents}} {{an evaluation of}} the forecasts of WIFO, the Institute for Advanced Studies (IHS) and the OECD for the Austrian economy for three key macro-economic variables for the period 1983 - 1999. As to the projections of growth and inflation in terms of accuracy no significant differences have emerged between the three institutions, while the prospects for unemployment are more precisely assessed by the two domestic institutes. Compared with previous studies, forecasting errors exhibit a slight downward trend. The forecasts by WIFO, IHS and the OECD are largely unbiased and efficient, and – {{with the exception of the}} unemployment rate forecast by the OECD – clearly superior to "naïve" forecasting strategies. Evaluation of <b>Macro-economic</b> <b>Forecasts</b> for Austria in the 1980 s and 1990 s...|$|R
40|$|This paper {{argues that}} {{probability}} forecasts convey {{information on the}} uncertainties that surround <b>macro-economic</b> <b>forecasts</b> in a manner which is straightforward and which is preferable to other alternatives, {{including the use of}} confidence intervals. Probability forecasts relating to UK output growth and inflation, obtained using a small macro- econometric model, are presented. We discuss in detail the probability that inflation will fall within the Bank of England’s target range and that recession will be avoided, both as separate single events and jointly. The probability forecasts are also used to provide insights on the interrelatedness of output growth and inflation outcomes at different horizons. Probability Forecasting; Long Run Structural VARs; Macroeconomic Modelling, Probability Forecasts of Inflation; Interest Rates and Output Growth...|$|R
40|$|This paper {{argues that}} {{probability}} forecasts convey {{information on the}} uncertainties that surround <b>macro-economic</b> <b>forecasts</b> in a straightforward manner which is preferable to other alternatives, {{including the use of}} confidence intervals. Point and probability forecasts obtained using a small macro-econometric model, are presented and evaluated using recursive forecasts generated from the model over the period 1999 q 1 - 2000 q 1. Out of sample probability forecasts of inflation and output growth are also provided over the period 2001 q 2 - 2003 q 1, and their implications discussed in relation to the Bank of England's inflation target and the need to avoid recessions, both as separate events and jointly. It is also shown how the probability forecasts can be used to provide insights on the inter-relationship of output growth and inflation at different horizons. ...|$|R
40|$|Do {{accurate}} {{predictions of}} macro-economic {{variables such as}} industrial production or consumer price inflation allow expert forecasters to sepa-rate stock market winners from losers? I study this question for the G- 7 countries with data between 1969 and 2003. In general, the answer is yes, but the profitability of global macro-economic arbitrage varies greatly through time. High-precision forecasts capture approximately 10 % of the cross-sectional variation in one- and three-year stock index returns. The investment value of <b>macro-economic</b> <b>forecasts</b> The concept of global macro-economic arbitrage {{first appeared in the}} minds of topnotch investment strategists and hedge fund managers like Paul Tudor Jones or Julian Robertson. These pioneers and many others af-terward spent much of their careers developing a refined understanding of the global economy, and of the links between vital macro-economic indicators. Macro traders formulate recurring forecasts of the gross domes...|$|R
40|$|The Vector AutoRegressive Moving Average (VARMA) {{model is}} {{fundamental}} {{to the study of}} multivariate time series. However, estimation becomes challenging in even relatively low-dimensional VARMA models. With growing interest in the simultaneous modeling of large numbers of marginal time series, many authors have abandoned the VARMA model in favor of the Vector AutoRegressive (VAR) model, which is seen as a simpler alternative, both in theory and practice, in this high-dimensional context. However, even very simple VARMA models can be very complicated to represent using only VAR modeling. In this paper, we develop a new approach to VARMA identification and propose a two-phase method for estimation. Our identification and estimation strategies are linked in their use of sparsity-inducing convex regularizers, which favor VARMA models that have {{only a small number of}} nonzero parameters. We establish sufficient conditions for consistency of sparse infinite-order VAR estimates in high dimensions, a key ingredient for our two-phase sparse VARMA estimation strategy. The proposed framework has good estimation and forecast accuracy under numerous simulation settings. We illustrate the forecast performance of the sparse VARMA models for several application domains, including <b>macro-economic</b> <b>forecasting,</b> demand forecasting, and volatility forecasting. The proposed sparse VARMA estimator gives parsimonious forecast models that lead to important gains in relative forecast accuracy...|$|R
40|$|Since 1993 the Centre of Policy Studies {{has been}} using the MONASH model to produce year-by-year {{forecasts}} for the Australian economy, typically with forecast horizons of about ten years. MONASH is a large dynamic applied general equilibrium model. The MONASH forecasting system takes as inputs <b>macro-economic</b> <b>forecasts</b> from Syntec Economic Services, forecasts for the agricultural and mining sectors from the Australian Bureau of Agricultural and Resource Economics, forecasts for international tourism from the Bureau of Tourism Research, and scenarios on technical change from extrapolations of recent historical experience. The MONASH model then produces consistent forecasts for 112 industries, 56 regions and 282 occupations. The occupational forecasts give projections of the demand for the ASCO unit groups {{in each of the}} six Australian States. These forecasts provide a background for assessing the skills likely to be required in the Australian workforce in the next decade. In this paper we report a selection of our most recent (as at February 1995) forecasts for occupations, and explain how they relate to the macroeconomic and industrial dimensions of the overall forecasts. ...|$|R
40|$|<b>Macro-economic</b> <b>forecasts</b> {{typically}} involve both a model component, {{which is}} replicable, {{as well as}} intuition, which is non-replicable. Intuition is expert knowledge possessed by a forecaster. If forecast updates are progressive, forecast updates should become more accurate, on average, as the actual value is approached. Otherwise, forecast updates would be neutral. The paper proposes a methodology to test whether forecast updates are progressive and whether econometric models are useful in updating forecasts. The data set for the empirical analysis are for Taiwan, where we have three decades of quarterly data available of forecasts and updates of the inflation rate and real GDP growth rate. The actual series for both the inflation rate and the real GDP growth rate are always released by the government one quarter {{after the release of}} the revised forecast, and the actual values are not revised after they have been released. Our empirical results suggest that the forecast updates for Taiwan are progressive, and can be explained predominantly by intuition. Additionally, the one-, two- and three-quarter forecast errors are predictable using publicly available information for both the inflation rate and real GDP growth rate, which suggests that the forecasts can be improved. ...|$|R
40|$|B. De Finetti's "Fundamental Theorem of Probability" is reformulated as a computable linear {{programming}} problem. The theorem is substantially extended, and {{shown to have}} fundamental implications for the {{theory and practice of}} statistics. It supports an operational meaning for the partial assertion of prevision via asserted bounds. The theorem is expanded to apply to general quantities; to allow bounds and orderings on previsions as input to the programming problem; and to yield bounds, even on conditional previsions, as output. Consequences include the ultimate strengthening of any probability inequality based on linear constraints, such as the Bienayme-P. L. Chebyshev inequality and an inequality related to Kolmogorov's inequality, but based only on the judgment of a sequence of quantities as e:-ethangeable. Included in the wide variety of potential applications are the safety assessment of complex engineering systems, the analysis of agricultural production statistics, and a synthesis of su) jective judgments in <b>macro-economic</b> <b>forecasting.</b> Prevision is explicitly recognized as a completion of the notion of logical assertion, introduced by Frege. (Author/SLD) *****,:?*v*************************************************************** * Reproductions supplied by EDRS are the best that can be made * * from the original document. ...|$|R
40|$|Since the {{pioneering}} work on leading indicators by Mitchell and Bums ([19381 1961) and their collaborators at the NBER, {{the prediction of}} business-cycle turning points {{has been one of}} the core problems of business-cycle anal-ysis. This paper describes one approach to forecasting the future state of the business cycle or, more simply, to predicting recessions. The paper has three objectives. The first is to provide the mathematical details of this approach to forecasting recessions. The second is to evaluate the empirical performance of the resulting recession probability forecasts. This evaluation focuses on the sharp economic downturn in the fall of 1990, which provided an opportunity to examine the performance of a range of leading economic indicators under the unusual conditions of a broadly weak economy facing the prospect of oil supply disruptions and war in the Persian Gulf. The third objective is to draw some general conclusions about the use of leading indicators for <b>macro-economic</b> <b>forecasting.</b> The methodology for estimating the probability that the economy will be in a recession at a future date is described in section 2. 1. Rather than trying to forecast turning points (see, e. g., Kling 1987; Hymans 1973; Neftci 1982...|$|R
50|$|Development {{planning}} centre: Established in 1994 {{with the}} financial support {{in the form of}} an endowment, from the Planning Commission, the unit endeavours to develop <b>macro-economic</b> models for <b>forecasting</b> the changes to assist the Government of India in policy making. The unit has collaboration arrangement with the Central Planning Bureau of Netherlands and Erasmus University.|$|R
40|$|A {{question}} which is prior to any analysis of co-movements in economic time series {{is the extent}} to which the series contain genuine information rather than noise. In this paper, I describe a methodology for distinguishing between signal and noise, and illustrate its application both with respect to the degree of convergence in European business cycles (the co-movements between real GDP growth in the various countries) and to understanding the poor practical record of <b>macro-economic</b> <b>forecasts</b> (the comovements between variables within economies). By way of illustration, the degree of synchronisation of the business cycles may be quantified by calculation of the correlation matrix of the matrix of observations formed from the time series of GDP growth for each economy. However due to the finite size of the number of variables (which corresponds to the number of economies) and the number of observations (which is the number of observations of GDP) then a reliable determination of the correlation matrix may prove to be problematic. The structure of the correlation matrix may be dominated by noise rather than by true information. In order to assess the degree to which an empirical correlation matrix is noise dominated we can compare the eigenspectra properties of the empirical matrix with the theoretical eigenspectra properties of a random matrix. Undertaking this analysis will identify those eigenstates of the empirical matrix who contain genuine information content. The remaining eigenstates will be noise dominated and hence unstable over time. 1...|$|R
40|$|A small {{econometric model}} has been {{programmed}} in a Lotus 1 - 2 - 3 spreadsheet for student use. Sample-period-simulation performance, policy multipliers, and applica-tions for forecasting and policy making are demonstrated. Keywords: econometric model, forecasting, policy simulation, multipliers. Econometric models have become the standard method for <b>macro-economic</b> <b>forecasting</b> and policy analysis. According to Paul Samuel-son, even economists accustomed to simpler, more intuitive models &dquo;stand {{on the shoulders of}} the giants&dquo; who use models, by subscrib-ing to econometric forecasting services or by comparing their work with that of the modelers. Applied econometric models have become very large, some with iooo or more equations, explaining highly disaggregated elements of the economy. Disaggregation is useful to provide forecasts for detailed elements of the economy that may relate closely to particular kinds of business. It may help to evaluate the impact of specific policy alternatives. But the structure of a large complicated model is difficult to disentangle and understand, and, perhaps surprisingly, disaggregation seems to be of little help in improving the forecasting effectiveness of models. For pedagogical purposes, large systems, like the Wharton model, are impractical for classroom use. A small structural model is sufficient to bring out the essentials of the economy and to demonstrate how models are used. Structure of the Penn Mini Macromodel Our minimum econometric model of the United States economy’ includes only five behavioral equations and three identities. These are summarized in Table i and explained briefly here...|$|R
40|$|This {{working paper}} desc NIME model. The specifica from the {{following}} assump there exists a representativ the entire enterprise secto by hiring production facto to the final users. Second, t labour, capital, and imp household sector supplies wage rate with the enterp of unemployment and the the production factors are section we make the addi towards equilibrium occu looking behaviour and “ru ends with the presentatio demand, factor prices and country blocks of the NIMEribes the enterprise sector of the tion of the enterprise sector starts tions. First, for each country block e agent capturing the behaviour of r. This agent maximizes its profits rs, and selling goods and services he available production factors are orts. Third, a utility maximizing labour and bargains over the real rise sector. Fourth, the natural rate steady state productivity growth of exogenous. Fifth, in the empirical tional assumption that adjustment rs sluggishly because of backward le of thumb ” behaviour. The paper n of estimation results for factor output prices for the four main model. Federal Planning Bureau The Belgian Federal Planning Bureau (BFPB) is a public agency {{under the authority of}} the Prime Minister and the Minister of Economic Affairs. The BFPB has a legal sta-tus that gives it an autonomy and intellectual independence within the Belgian Federal public sector. The BFPB’s activities are primarily focused on <b>macro-economic</b> <b>forecasting,</b> analysing and assessing policies in the economic, social and environmental fields...|$|R
40|$|The {{purpose of}} this {{document}} is to describe {{the features of the}} MTO covering the period 2010 to 2020. The MTO is a plausible future for the international and domestic agri-food sectors based on current policies in Canada and other countries as of Fall 2010. It serves as a benchmark for discussion and scenario analysis. The outlook makes specific assumptions and outlines their implications. Since it assumes that policies remain unchanged from existing legislation, the outlook is not a forecast of future events. In particular there are no assumptions made regarding the outcome of the Doha round of trade negotiations. It also assumes no impact from climate change and from policy to mitigate climate change nor significant animal disease outbreaks or unusual climatic conditions over the period of the outlook. The starting point of the MTO is world agricultural commodities price projection based on the OECD/FAO Agricultural Outlook for 2009 / 2019 adjusted with more recent information. The Canadian <b>macro-economic</b> <b>forecasts</b> are from the Conference Board of Canada outlook published in September 2010. In addition, short-term price forecasts have been updated using United States Department of Agriculture (USDA) projections released in October 2010. For example, droughts in some southern hemisphere countries and China as well as the foot and mouth outbreak in South Korea have not been taken into account. Outlook, Agriculture, Cereals, Oilseeds, Bio-fuels, Livestock, Red meats, Milk, Dairy products, Chicken, Turkey, Eggs, Agribusiness, Agricultural and Food Policy, International Relations/Trade, Livestock Production/Industries,...|$|R
40|$|The {{purpose of}} this {{document}} is to describe {{the features of the}} Agriculture and Agri-Food Canada (AAFC) Medium Term Outlook for Canadian Agriculture covering the period 2009 to 2019. The outlook is an attempt to outline a plausible future of the international and domestic agri-food sectors. It serves as a benchmark for discussion and scenario analysis. The outlook makes specific assumptions and outlines their implications. Since it assumes that policies remain unchanged from existing legislation, the outlook is not a forecast of future events. In particular there are no assumptions made regarding the outcome of the Doha round of trade negotiations. It also assumes no impact from climate change and from policy to mitigate climate change nor significant animal disease outbreaks or unusual climatic conditions over the period of the outlook. The starting point of the international baseline is the so-called lower GDP slow recovery medium term scenario published in the OECD/FAO Agricultural Outlook 2009 - 2018. This scenario was updated in the short term using <b>macro-economic</b> <b>forecasts</b> released by the OECD in September 2009 and by the World Bank in June 2009. Exchange rates were updated to reflect the information released at the end of 2008 and in the first 6 months of 2009. The agricultural outlook was updated to reflect short term price forecasts produced and released by the U. S. Department of Agriculture (USDA) in October 2009. outlook, agriculture, cereals, oilseeds, bio-fuels, livestock, red meats, milk, dairy products, chicken, turkey, eggs, Agribusiness, Agricultural and Food Policy, International Relations/Trade, Livestock Production/Industries,...|$|R
40|$|Recent {{works in}} the econometric {{literature}} consider the problem of efficiently summarising a large set of variables and using this summary {{for a variety of}} purposes, including forecasts (Stock and Watson, 2002; Forni et al., 2005; Giannone et al., 2008; for a wide review, see Eklund and Kapetanios, 2008). Factor analysis combined with linear modelling has usually been the main tool used for this task. This paper presents a new statistical approach to <b>forecasting</b> <b>macro-economic</b> aggregates, based on the Random Forests technique, originally developed as a learning classification tool (Breiman, 2001). This technique can handle {{a very large number of}} input variables without overfitting and is known to enjoy good prediction properties and to be robust to noise. While the Random Forests algorithm is usually applied in medical research and biological studies, it is largely unknown in economics. This paper investigates the potential of applying this promising technique to modelling and <b>forecasting</b> <b>macro-economic</b> aggregates using large datasets of survey variables, in the same vein as Biau et al. (2007). A specific application for short-term GDP forecasting in the euro area is shown using th...|$|R
40|$|This paper {{presents}} an empirical strategy that bridges {{the gap between}} event studies and <b>macro-economic</b> <b>forecasts</b> based on common-factor models. Event studies examine the response of finan-cial variables to a market-sensitive “surprise ” component using a narrow event window. The authors argue that these features—narrow event window and surprise component—can be easily embedded in common-factor models that study the real-time impact of macroeconomic announcements on key policy variables such as inflation or gross domestic product growth. Demonstrative applications are provided for Swiss inflation that show that (i) the communication of monetary policy announce-ments generates an asymmetric response for inflation forecasts, (ii) the pass-through effect of import price releases on inflation forecasts is weak, and (iii) macroeconomic releases of real and nominal variables generate nonsynchronized effects for inflation forecasts. (JEL E 37, E 52, E 58) Federal Reserve Bank of St. Louis Review, September/October 2009, 91 (5, Part 2), pp. 507 - 18. weekly updates enhance the forecast accuracy for monthly Swiss inflation. These studies argue that sequentially updating the forecast on incom-ing macroeconomic information is informative for analysts monitoring nominal and real activity. A drawback of diffusion indices {{is that they are}} statistical models without economic structure. A naive method of uncovering the driving forces behind forecasts from common-factor models compares the forecasting performance between included and excluded variable blocks in the panel. Forni et al. (2001) use this method to show that financial variables are important for inflation forecasts. Analogous to the naive method, the impact of macroeconomic announcements on indices can be interpreted using an event study framework. The “impact effect ” is defined as the difference between the forecast conditional on A n attractive feature of diffusion indicesis their ability to embed timely infor-mation from macroeconomic releases. Studies using common-factor proce-dures by Forni et al. (2000) and Stock and Watson (2002) show that updated forecasts have lower forecast errors because additional observations from macroeconomic releases are included in...|$|R
40|$|Modelling French economy : DMS INSEE. Service des Programmes <b>Macro-economic</b> <b>forecasts</b> {{used during}} the {{preparation}} of the VIIIth (1981 - 1985) french Plan were built {{with the help of a}} dynamic macro-econometric model. This model, called DMS (Dynamique Multi Sectoriel), has been developed from 1974 to 1976 at thé INSEE (Service des Programmes). The most direct approach to DMS consists in a survey of its main equations. Three important features appears then : the role of time-lags for dynamic properties of the projections; a complete description for eleven sectors, including price determination; in each of the three manufacturing industries a clay-clay vintage model implies a sort of memory for thé economy on médium term outlook. However a model cannot be summarized by the list of its equations. It involves many kinds of relationships between institutional sectors and simulates regulation procedures like in the real economy. According to DMS, most of these relationships relies on the twin-aspects of capital, both physical and financial matter of économie behaviour. Key desequilibrium-indicators are bound to these aspects : the degree of utilization of capacity and the profit rate; they order regulation processes, especially the moves of prices and investment from year to year. How sophisticated the model maybe, it remains a very rough figure compared with economic reality. Econometric methods are based on statistical data analyses, refering to years ago; are they really able to underly projections in the future ? Business fixed investment funitions of DMS model depends on profit rates, especially in the non-industrial sectors, how far can it be expected that accelarator effects have nowadays a greater influence ? DMS includes no monetary and financial sector; what sort of discrepanciesmay result from external hypothesis on irïterest rates and external exchange rates ? The DMS-team of economist had to answer those basic questions 1 in each working parties designed to prépare the VIIIth Plan. Part of the answer s are given in the paper, waiting for new improvement in statistical and economic research or analysis. de L'INSEE Service des Programmes. Une représentation de l'économie française : le modèle DMS. In: Revue économique, volume 31, n° 5, 1980. pp. 930 - 981...|$|R
40|$|After brief {{remarks on}} the history of {{modeling}} and inference techniques in economics and econometrics, attention is focused on the emergence of economic science in the 20 th century. First, the broad objectives of science and the Pearson-Jeffreys' "unity of science" principle will be reviewed. Second, key Bayesian and non-Bayesian practical scientific inference and decision methods will be compared using applied examples from economics, econometrics and business. Third, issues and controversies on how to model the behavior of economic units and systems will be reviewed and the structural econometric modeling, time series analysis (SEMTSA) approach will be described and illustrated using a <b>macro-economic</b> modeling and <b>forecasting</b> problem involving analyses of data for 18 industrialized countries over the years since the 1950 s. Point and turning point forecasting results will be summarized. Last, a few remarks will be made about the future of scientific inference and modeling techniques in economics and econometrics. ...|$|R
40|$|F. Bouton & H. Erkel-Rousse:Sectoral {{business}} surveys {{as an aid}} to short-term macroeconomic forecasting: The services contribution. Sectoral business surveys {{as an aid to}} short-term macroeconomic forecasting: {{the services}} contribution * by François Bouton and Hélène Erkel-Rousse (Insee, France) Abstract: On the basis of French data, we show that the short-term business survey in services delivers a specific piece of information with respect to the equivalent survey for industry, making it possible to improve short-term <b>macro-economic</b> analysis and <b>forecasting</b> of the GDP growth rate. This specific contribution may be due to a lower sensitivity of service sectors to international trade and inventory movements. We present and discuss GDP forecasts at a one or two-quarter horizon based on miscellaneous univariate as well as multivariate VAR models encompassing data relating to both industry and services. We then suggest that the short-term business survey in services can help one dating the turning points of economic activity. Finally, we show that static common factors are very robust with respect to the imperfect synchrony of their constituent balances. This result constitutes an ex post justification of the intensive use of this kind of synthetic indicators in the paper...|$|R
40|$|This paper {{presents}} {{an analysis of}} forecasting errors of the Economic Policy Department's forecasts for Malta. Based on this analysis an approach for carrying out a risk assessment of macroeconomic forecast is proposed. In particular, this paper contains: 1. {{an evaluation of the}} Economic Policy Department's macroeconomic forecast errors since 2004, 2. a comparison of Economic Policy Department's forecasting performance with that of the European Commission and the Central Bank of Malta, 3. an assessment of Malta's forecast performance compared with that of other European economies, 4. an evaluation of possible biases in the forecast, and finally, 5. a methodology for the illustration of forecast uncertainty and the balance of risk surrounding our forecast through the use of Fan Charts. The publication is in line with the requirements of Council Directive 2011 / 85 /EU of the European Union on the requirements for budgetary frameworks of the Member States. As from 2014, the Directive binds Member States to guide their <b>macro-economic</b> and budgetary <b>forecasts</b> by the performance of past forecasts and endeavour to take into account relevant risk scenarios. The risk assessment developed in this paper follows the methodology suggested by Selim Elekdag and Prakash Kannan (2009) in their seminal IMF working Paper and will become a regular feature of the Economic Policy Department's published macroeconomic forecasts. N/...|$|R
40|$|M. Com. (Econometrics) The {{main purpose}} of this study is the {{combining}} of forecasts with special reference to major macroeconomic series of South Africa. The study is based on econometric principles and makes use of three <b>macro-economic</b> variables, <b>forecasted</b> with four forecasting techniques. The macroeconomic variables which have been selected are the consumer price index, consumer expenditure on durable and semi-durable products and real M 3 money supply. Forecasts of these variables have been generated by applying the Box-Jenkins ARIMA technique, Holt's two parameter exponential smoothing, the regression approach and mUltiplicative decomposition. Subsequently, the results of each individual forecast are combined in order to determine if forecasting errors can be minimized. Traditionally, forecasting involves the identification and application of the best forecasting model. However, in the search for this unique model, it often happens that some important independent information contained in one of the other models, is discarded. To prevent this from happening, researchers have investigated the idea of combining forecasts. A number of researchers used the results from different techniques as inputs into the combination of forecasts. In spite of the differences in their conclusions, three basic principles have been identified in the combination of forecasts, namely: i The considered forecasts should represent the widest range of forecasting techniques possible. Inferior forecasts should be identified. Predictable errors should be modelled and incorporated into a new forecast series. Finally, a method of combining the selected forecasts needs to be chosen. The best way of selecting a m ethod is probably by experimenting to find the best fit over the historical data. Having generated individual forecasts, these are combined by considering the specifications of the three combination methods. The first combination method is the combination of forecasts via weighted averages. The use of weighted averages to combine forecasts allows consideration of the relative accuracy of the individual methods and of the covariances of forecast errors among the methods. Secondly, the combination of exponential smoothing and Box-Jenkins is considered. Past errors of each of the original forecasts are used to determine the weights to attach to the two original forecasts in forming the combined forecasts. Finally, the regression approach is used to combine individual forecasts. Granger en Ramanathan (1984) have shown that weights can be obtained by regressing actual values of the variables of interest on the individual forecasts, without including a constant and with the restriction that weights add up to one. The performance of combination relative to the individual forecasts have been tested, given that the efficiency criterion is the minimization of the mean square errors. The results of both the individual and the combined forecasting methods are acceptable. Although some of the methods prove to be more accurate than others, the conclusion can be made that reliable forecasts are generated by individual and combined forecasting methods. It is up to the researcher to decide whether he wants to use an individual or combined method since the difference, if any, in the root mean square percentage errors (RMSPE) are insignificantly small...|$|R
40|$|The {{concept of}} Circular Economy is much {{discussed}} among experts and in sustainably advanced business contexts {{such as the}} 2017 Sustainability Summit in London. Several multinational companies have already joined networks to accelerate the transition into futureproofed business practices. Startups, long-established companies and scientific research are devising groundbreaking solutions to work towards this new business imperative. At its core, the Circular Economy aims at replacing the traditional, linear way of extraction, production, consumption and disposal with a circular model, where waste is considered as a precious resource for new applications. However, it seems that in the Swiss business environment the concept is rather unknown or ignored, {{even though it is}} highly relevant considering the current and <b>forecasted</b> <b>macro-economic</b> and environmental developments. “Adapt or die” {{is one of the more}} recent statements in the light of environmental pollution, the tightening of resource availability together with population growth and increasing consumption on a global level. Therefore, this Bachelor’s thesis aims to analyze the present status of and to provide guidance for the Swiss fashion retail industry. By means of a multiple-case, embedded case study design, two Swiss fashion retailers are studied within their respective ecosystems. The two units of study were selected to approach a certain degree of external analytic validity, which is the reason why a large multinational and a smaller player with Swiss tradition were chosen. Qualitative and quantitative sources of primary and secondary data are adduced, whereas solely qualitative methods are applied. The assessments are then made inductively on the basis of the business model Recovery & Recycling. It is as such one of five Accenture-devised possibilities for enterprises to embark on a circular future. It was found that successfully employing the Recovery & Recycling business model embraces decoupling in two different ways: decoupling from potentially harmful resources, the environmental perspective and, decoupling from increasingly scarce resources, the economic perspective. The Swiss fashion industry turned out to be rather advanced within the environmental perspective, yet there is room for improvement when it comes to closing the material loop from an economic perspective. Smaller players with limited means are well advised to draw on the many instruments or methods already available and to imitate larger, more advanced players. Finally, some advancements depend on breakthroughs in recycling technology and material sciences. Nevertheless, much can already be improved by efficient design of products and processes in a way that facilitates reuse and recycling...|$|R

