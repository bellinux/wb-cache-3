0|98|Public
5000|$|... {{grab handle}} - a pivoted, rigidly-mounted, or {{suspended}} handle often <b>mounted</b> above <b>eye</b> level of standing passengers ...|$|R
30|$|All stimuli {{were created}} using MATLAB {{software}} (MathWorks, Natick, MA, USA) and displayed using Experiment Builder (SR Research, Ottawa, ON, Canada) on a Mac mini (Apple, Cupertino, CA, USA) with an 18 -inch ViewSonic CRT monitor (1024 × 768 pixels, 85 Hz; ViewSonic, Walnut, CA, USA). Eye movements were recorded by an EyeLink 1000 Tower <b>Mount</b> <b>eye</b> tracker (1000 -Hz sampling rate; SR Research). Participants were seated approximately 81 cm from the display.|$|R
5000|$|Happily Ever After (2008), With <b>Mount</b> Sims, Hungry <b>Eye</b> Records ...|$|R
5000|$|AOSLO {{represents}} an advantageous alternative to retinal dissection {{for a variety}} of reasons. Analysis of cone packing density before AOSLO was only possible on <b>mounted</b> <b>eyes</b> from eye donor banks. [...] As this method could not measure changes to cones in living eyes, it could not be used to track retinal changes over time or eye movements. With the use of living subjects, AOSLO allows for these measurements as well as easier control of age and other confounding factors while maintaining similar anatomical results for cone packing density. [...] Future clinical implications for AOSLO are also possible.|$|R
40|$|There {{is a large}} {{evidence-base}} {{suggesting the}} role of attentional bias in addictive behaviours. However, {{there has been no}} evidence to date of any research in the field of alcohol addiction that investigates if traditionally used laboratory-based measures of attentional bias correspond to more naturalistic methods in real-world settings. A non-clinical sample of 43 students aged 18 - 30 were recruited from the University of Liverpool. Participants completed two measures of attentional bias; a fixed eye tracker measure utilising the visual probe task in a standard laboratory set-up, and a head <b>mounted</b> <b>eye</b> tracker within a more naturalistic setting. Attentional bias was measured by participants fixation duration to alcohol compared with non-alcohol/neutral stimuli. Participant’s drinking habits were also measured using the Time Line Follow Back and the Alcohol Use Disorders Identification Test. A measure of craving and measures of mood were also administered. Correlation analyses were conducted on 34 complete data sets. No significant correlations were found between the two measures of attentional bias. Some significant correlations were found, however, between drinking-related variables, craving and the fixed eye tracker attentional bias measure supporting previous findings within the literature. Additional analyses were conducted to explore the relationship between mood, attentional bias measures and drinking-related variables. The results of this study are discussed in detail in relation to the theoretical and clinical implications and future research is suggested. Keywords: attentional bias, alcohol, naturalistic setting, fixed <b>eye</b> tracker, head <b>mounted</b> <b>eye</b> tracker, visual probe task, cravin...|$|R
5000|$|Rapid <b>Eye</b> <b>Mount</b> telescope, a larger, {{somewhat}} slower companion telescope also {{located at}} La Silla.|$|R
50|$|This {{article is}} about <b>eyes</b> <b>mounted</b> on stalks. For the instinctive {{tendency}} to track prey, see eye-stalking.|$|R
50|$|The {{head has}} stereo cameras in a swivel <b>mounting</b> where <b>eyes</b> would be {{located on a}} human and {{microphones}} on the side. It also has lines of red LEDs representing mouth and eyebrows mounted behind the face panel for making facial expressions.|$|R
40|$|The {{object of}} this paper is to develop an emotion {{recognition}} system that analysis the motion trajectory of the eye and gives the response on appraisal emotion. The emotion recognition solution is based on the data gathering using head <b>mounted</b> <b>eye</b> tracking device. The participants of experimental investigation were provided with a visual stimulus (PowerPoint slides) and the emotional feedback was determined by the combination of eye tracking device and emotion recognition software. The stimulus was divided in four groups by the emotion that should be triggered in the human, i. e., neutral, disgust, exhilaration and excited. Some initial experiments and the data on the recognition accuracy of the emotion from eye motion trajectory are provided along with the description of implemented algorithms...|$|R
40|$|Abstract — The {{object of}} this paper is to develop an emotion {{recognition}} system that analysis the motion trajectory of the eye and gives the response on appraisal emotion. The emotion recognition solution is based on the data gathering using head <b>mounted</b> <b>eye</b> tracking device. The participants of experimental investigation were provided with a visual stimulus (PowerPoint slides) and the emotional feedback was determined by the combination of eye tracking device and emotion recognition software. The stimulus was divided in four groups by the emotion that should be triggered in the human, i. e., neutral, disgust, exhilaration and excited. Some initial experiments and the data on the recognition accuracy of the emotion from eye motion trajectory are provided along with the description of implemented algorithms. Keywords—Emotional status; eye tracking; human computer interaction; virtual human I...|$|R
5000|$|Honor - When a Power Stone is {{discovered}} on <b>Mount</b> Arashikage, Snake <b>Eyes</b> competes with Storm Shadow {{to get to}} it. Meanwhile, Jinx and Kamakura fight the Dreadnoks.|$|R
30|$|As the {{underpinning}} technology, VR {{has been}} defined as a 3 D computer-generated alternative environment to be immersed in, for navigating around and interacting with (Briggs 1996), or as a component of communication taking place in a ‘synthetic’ space, which embeds human as its integral part (Regenbrecht and Donath 1997). The definitions of VR systems usually includes a computer capable of real-time animation, controlled by a set of wired gloves and a position tracker, and using a head-mounted stereoscopic display as visual output. For instance, Regenbrecht and Donath (1997) defined the tangible components of VR as a congruent set of hardware and software, with actors within a three-dimensional or multi-dimensional input/output space, where actors can interact with other autonomous objects, in real time. VR has also been defined as a simulated world, which comprises of some computer-generated images conceived via head <b>mounted</b> <b>eye</b> goggles and wired clothing – thereby enabling the end users to interact in a realistic three-dimensional situation (Yoh 2001).|$|R
40|$|Most {{people believe}} that the slower we read the better we comprehend. However, a lot of novel rapid reading {{techniques}} and methods were developed to increase the reading speed without diminishing the comprehension. In this research an empirical study was performed to investigate {{if there is a}} difference in speed reading between male and female. The initial hypothesis in this research was the assumptions that there is NO difference between male and female in reading speed. Ten undergraduate and graduate students participated in achieving this experiment; five females and five males using head <b>mounted</b> <b>eye</b> trackers ASL 6000 series. The experiment results showed that there is a difference in speed reading between males and females. Females spend longer time between consecutive segments than males and they spend longer time on each segment than males in the reading process. Females might have taken long time to focus and concentrate on understating the topic while males might have read fast without guarantee to comprehend. These results help psychology and computer science researchers to develop adaptive reading materials and devices...|$|R
40|$|Fig. 1 : We {{accurately}} estimate 3 D gaze positions {{by combining}} digital manufacturing, marker tracking and monocular eye tracking. With a simple calibration procedure we attain an angular accuracy of 0. 8 ◦. Abstract — Many applications in visualization benefit from accurate knowledge of {{where a person}} is looking at. We present a system for accurately tracking gaze positions on a three dimensional object using a monocular head <b>mounted</b> <b>eye</b> tracker. We accomplish this by 1) using digital manufacturing to create stimuli with accurately known geometry, 2) embedding fiducial markers directly into the manufactured objects to reliably estimate the rigid transformation of the object, and, 3) using a perspective model to relate pupil positions to 3 D locations. This combination enables the efficient and accurate computation of gaze position on an object from measured pupil positions. We validate the accuracy of our system experimentally, achieving an angular resolution of 0. 8 ◦ and a 1. 5 % depth error using a simple calibration procedure with 11 points. Index Terms—eye tracking, calibration, accuracy...|$|R
50|$|On 17 August 2012, India {{received}} the first Embraer 145 Airborne Early Warning and Control Aircraft, built with Indian technology. It is claimed {{as a major}} breakthrough in <b>mounting</b> an electronic <b>eye</b> in the sky for India.|$|R
40|$|Gaze {{tracking}} is {{a promising}} research area with application that goes from advanced human machine interaction systems, to human attention processes studying, modeling and use in cognitive vision fields. In this {{paper we propose}} a novel approach for the calibration and use of a head <b>mounted</b> dual <b>eye</b> gaze tracker. Key aspects are a robust pupil tracking algorithm based on prediction from infrared LED purkinje image position, and a new gaze localization method based on trifocal geometry considerations...|$|R
40|$|In this work, a {{new head}} <b>mounted</b> <b>eye</b> {{tracking}} system is presented. Based on computer vision techniques, the system integrates eye images and head movement, in real time, performing a robust gaze point tracking. Nystagmus movements due to vestibulo-ocular reflex are monitored and integrated. The system proposed {{here is a}} strongly improved version of a previous platform called HATCAM, which was robust against changes of illumination conditions. The new version, called HAT-Move, is equipped with accurate inertial motion unit to detect the head movement enabling eye gaze even in dynamical conditions. HAT-Move performance is investigated {{in a group of}} healthy subjects in both static and dynamic conditions, i. e. when head is kept still or free to move. Evaluation was performed in terms of amplitude of the angular error between the real coordinates of the fixed points and those computed by the system in two experimental setups, specifically, in laboratory settings and in a 3 D virtual reality (VR) scenario. The achieved results showed that HAT-Move is able to achieve eye gaze angular error of about 1 degree along both horizontal and vertical directions...|$|R
40|$|PURPOSE. The {{purpose of}} this study was to {{identify}} ways to improve qualitative and quantitative assessments of retinal vessels and neovascularization (NV). METHODS. At postnatal day (P) 17, mice with oxygen-induced ischemic retinopathy were injected intravitreously with one of a variety of FITC-labeled or unlabeled antibodies and humanely killed 12 hours later. Retinas were flat <b>mounted</b> (retinas from <b>eyes</b> injected with labeled antibodies) or incubated with secondary antibody and then flat <b>mounted</b> (retinas from <b>eyes</b> injected with unlabeled antibodies). RESULTS. Retinas from eyes injected with labeled anti-platelet endothelial cell adhesion molecule 1 (PECAM 1) showed good resolution of the fine structure of retinal NV, including filopodia at the tips of sprouts. New vessels originated from superficial retinal vessels, something that is widely recognized, bu...|$|R
40|$|This paper {{reports a}} novel stereo-vision-method (binocular system-geometrical mapped (BS-GM)) to {{estimate}} the depth coordinates of the eye gaze point in a controlled 3 D space of vision. The method outcomes were compared in both 2 D and 3 D visual targets with both mono- and stereovision algorithms in order to estimate accuracy of results. More specifically, we compared BS-GM with a monocular method and with two stereo-vision methodologies which were different in order to the mapping functions. All of the methods were implemented in the same head <b>mounted</b> <b>eye</b> tracking system able to acquire both eyes. In 2 D visual space (i. e. plane of vision) we compared BS-GM with a monocular method, a binocular system-linear mapped (BS-LM) and a binocular system-quadratic mapped (BS-QM). In the 3 D space estimation all of the binocular systems were compared each other. Thirteen enrolled subjects observed 31 targets of known coordinates in a controlled environment. Results achieved on 2 D comparison showed no statistical significant difference among the four methods, while the comparison on 3 D space of vision showed that BS-GM method achieved a significant better accuracy than BS-LM and BS-QM method. Specifically, BS-GM showed and average percentage error obit of 3. 47 %...|$|R
2500|$|The Rapid <b>Eye</b> <b>Mount</b> {{telescope}} {{is a small}} rapid-reaction automatic telescope with a primary [...] mirror. The telescope, in an altazimuth mount, began operation in October 2002. The {{primary purpose of the}} {{telescope is}} to follow the afterglow of the GRBs detected by the Swift Gamma-Ray Burst Mission satellite.|$|R
50|$|Images can be {{stabilized}} mechanically with optics <b>mounted</b> on the <b>eye</b> itself, or {{the image}} can be continually updated on a display {{to counteract the}} effects of eye movements. None of these methods allows perfect image stabilization leaving open {{the question of whether}} perfectly stabilized images disappear completely.|$|R
5000|$|Salamanders are {{generally}} similar to an oven without a front door, with the heating elements at the top. They are more compact; typically {{only half the}} height and depth of a conventional oven. They are often wall <b>mounted</b> at <b>eye</b> level, enabling easy access and close control of the cooking process. Many salamanders can be fitted with a cast iron [...] "branding" [...] plate {{which is used to}} make grill marks on the surface of meat. Some grills can also be fitted with a rotisserie accessory for roasting meats.|$|R
5000|$|The Rapid <b>Eye</b> <b>Mount</b> {{telescope}} (REM) {{is a small}} rapid-reaction automatic telescope with {{a primary}} 60 cm mirror. The telescope, in an altazimuth mount, began operation in October 2002. The {{primary purpose of the}} telescope is to follow the afterglow of the GRBs detected by the Swift Gamma-Ray Burst Mission satellite.|$|R
6000|$|Her speech seemed {{suddenly}} to be frozen by {{the spectacle of}} dread which, I knew, from the tenor I saw <b>mounting</b> in her <b>eyes,</b> must be on her inner vision. To my astonishment, Lon was affected by her words and manner. His face showed desperate, for all his voice sounded hearty and genial, as he said— ...|$|R
40|$|Study Objectives: To date, {{cognitive}} probe paradigms {{have been}} used in different guises to obtain reaction time measurements suggestive of an attention bias towards sleep in insomnia. This study adopts a methodology which is novel to sleep research to obtain a continual record of where the eyes—and therefore attention—are being allocated with regard to sleep and neutral stimuli. Design: A head <b>mounted</b> <b>eye</b> tracker (Eyelink II,SR Research, Ontario, Canada) was used to monitor eye movements in respect to two words presented on a computer screen, with one word being a sleep positive, sleep negative, or neutral word above or below a second distracter pseudoword. Probability and reaction times were the outcome measures. Participants: Sleep group classification was determined by screening interview and PSQI (&# 62; 8 = insomnia, &# 60; 3 = good sleeper) score. Measurements and Results: Those individuals with insomnia took longer to fixate on the target word and remained fixated for less time than the good sleep controls. Word saliency had an effect with longer first fixations on positive and negative sleep words in both sleep groups, with largest effect sizes seen with the insomnia group. Conclusions: This overall delay in those with insomnia with regard to vigilance and maintaining attention on the target words moves away from previous attention bias work showing a bias towards sleep, particularly negative, stimuli but is suggestive of a neurocognitive deficit in line with recent research. </p...|$|R
6000|$|It {{was during}} this deplorable state of affairs that a {{stranger}} entered the city one day. He was surprised at seeing so many prisons, and approaching the window in one of them, behind the bars of which he saw a very respectable-looking citizen, he asked what all this meant. The citizen informed him how matters stood, and then, with tears <b>mounting</b> to his <b>eyes,</b> he added: ...|$|R
5000|$|Several popular {{automatic}} scoring {{systems have}} five pin versions. On most string type pinsetters, automatic scoring equipment is connected {{directly to the}} pinsetter circuitry. Scoring cameras {{can be used on}} both types of pinsetting installations. Most systems mount the camera mounted between lanes as in tenpin; however the ProScore system—when installed on free-fall—reads scores using a set of five electronic <b>eyes</b> <b>mounted</b> above the pindeck.|$|R
40|$|Abstract. Collaborative control {{architectures}} assist human {{users in}} performing tasks, without undermining their capabilities or curtailing the natural {{development of their}} skills. In this study, we evaluate our collaborative control architecture by investigating the visual attention patterns of robotic wheelchair users. Our initial hypothesis stated that the user would require less visual attention for driving, whilst they are being assisted by the collaborative system, thus allowing them to concentrate on higher level cognitive tasks, such as planning. However, our analysis of eye gaze patterns—as recorded by a head <b>mounted</b> <b>eye</b> tracking system—supports the opposite conclusion: that patterns of saccadic activation increase and become more chaotic under the assisted mode. Our findings highlight the necessity for techniques that assist the user in forming an appropriate mental model of the collaborative control architecture. ronmental exploration, or planning future manoeuvres. We also expect the driver to fixate on objects of interest, which may help to strengthen our intent-prediction system. We do not treat eye gaze as an active input device, in which the user tries to control the wheelchair by moving their head and/or eyes, as was demonstrated in [9]. Instead, we aim {{to use it as}} a passive device, to non-intrusively increase the user state vector (the knowledge we possess about the user at each time step). In this exploratory study, we observe the characteristics of the user’s eye movements, whilst performing typical manoeuvres, such as driving around offices and passing through narrow doorways. The observations are made over one independent variable, which can take one of two states: provide adaptive assistance, or provide no assistance. ...|$|R
40|$|This paper {{describes}} {{a system for}} tracking the Line of Primary Gaze (LoPG) of subjects as they view a large projection screen. LoPG is monitored using a magnetic head tracker and a tracking algorithm. LoPG tracking can also be combined with a head <b>mounted</b> <b>eye</b> tracker to enable gaze tracking. The algorithm presented uses a polynomial function to correct for distortion in magnetic tracker readings, a geometric model for computing LoPG from corrected tracker measurements, and a method for finding intersection of the LoPG with a screen. Calibration techniques for the above methods are presented. Results of two experiments validating the algorithm and calibration methods are also reported. Experiments showed an improvement in accuracy of LoPG tracking provided by {{each of the two}} presented calibration steps yielding errors in primary gaze-point measurements of less than two degrees over a wide range of head positions. AUTHOR'S NOTE This work {{was supported in part by}} National Institutes of Health Grant EY 12890. Commercial eye tracker manufacturers, such as SR Research (Osgoode, ON Canada), ISCAN (Burlington, MA) and Applied Science Laboratories (ASL: Bedford, MA), market systems for monitoring point of regard on a display surface (combining head and eye tracking), but the manufacturers of these systems provide the devices as black-box tools. This makes it difficult for researchers to modify these trackers for special applications such as the large display and wide range of head movement needed for our walking simulator (Figure 1). This simulator takes the form of a projected virtual environment where a subject views computer generated images projected onto a large screen (Southard, 1995). Access to the algorithms and intermediate variables computed within the commercial gaze [...] ...|$|R
40|$|The aim of {{the current}} study was twofold: (1) to {{validate}} the use of action sport cameras for quantifying focus of visual attention in sailing and (2) to apply this method to examine whether an external focus of attention is associated with better performance in upwind sailing. To test the validity of this novel quantification method, we first calculated the agreement between gaze location measures and head orientation measures in 13 sailors sailing upwind during training regattas using a head <b>mounted</b> <b>eye</b> tracker. The results confirmed that for measuring visual focus of attention in upwind sailing, the agreement for the two measures was high (intraclass correlation coefficient (ICC) = 0. 97) and the 95 % limits of agreement were acceptable (between − 8. 0 % and 14. 6 %). In a next step, we quantified the focus of visual attention in sailing upwind as fast as possible by means of an action sport camera. We captured sailing performance, operationalised as boat speed {{in the direction of the}} wind, and environmental conditions using a GPS, compass and wind meter. Four trials, each lasting 1 min, were analysed for 15 sailors each, resulting in a total of 30 upwind speed trials on port tack and 30 upwind speed trials on starboard tack. The results revealed that in sailing-within constantly changing environments-the focus of attention is not a significant predictor for better upwind sailing performances. This implicates that neither external nor internal foci of attention was per se correlated with better performances. Rather, relatively large interindividual differences seem to indicate that different visual attention strategies can lead to similar performance outcomes...|$|R
40|$|The Rapid <b>Eye</b> <b>Mount</b> (REM) is a 60 [*]cm robotic {{telescope}} {{located at}} La Silla, Chile. Its Observing Software (REMOS) is constituted {{by a set}} of distributed intercommunicating processes organized around a central manager. Together they grant the system safety, automatically schedule and perform observations with two simultaneous cameras of user-defined targets, and drive fast reaction to satellite alerts. Subsequent data reduction is left to pipelines managed by each camera...|$|R
25|$|The midband {{region of}} its eye {{is made up}} of six rows of {{specialised}} ommatidia—a cluster of photoreceptor cells. Four rows carry up to 16 different photoreceptor pigments: 12 for colour sensitivity, others for colour filtering. The vision of the mantis shrimp can perceive both polarised light and multispectral images. Their <b>eyes</b> (<b>mounted</b> on mobile stalks and capable of moving independently of each other) are similarly variably coloured and are considered to be the most complex eyes in the animal kingdom.|$|R
50|$|The Rapid <b>Eye</b> <b>Mount</b> {{telescope}} (REM) is a fully automatic, 60 cm aperture telescope {{located at}} ESO's La Silla Observatory at 2,400 metres altitude {{on the edge}} of the Atacama Desert in Chile. The telescope's aim is to catch the afterglows of gamma-ray bursts (GRBs). REM is triggered by a signal from a high-energy satellite such as Swift and rapidly points to the detected location in the sky. It is operated for the Italian National Institute for Astrophysics since 2002.|$|R
50|$|The midband {{region of}} its eye {{is made up}} of six rows of {{specialised}} ommatidia—a cluster of photoreceptor cells. Four rows carry up to 16 different photoreceptor pigments: 12 for colour sensitivity, others for colour filtering. The vision of the mantis shrimp can perceive both polarised light and multispectral images. Their <b>eyes</b> (<b>mounted</b> on mobile stalks and capable of moving independently of each other) are similarly variably coloured and are considered to be the most complex eyes in the animal kingdom.|$|R
40|$|Part 6 : Robotic Systems - IIInternational audienceFor {{a natural}} interaction, people {{immersed}} within a virtual environment (like a CAVE system) use multimodal input devices (i. e. pointing devices, haptic devices, 3 D mouse, infrared markers and so on). In {{the case of}} physically impaired people who are limited in their ability of moving their hands, {{it is necessary to}} use other special input devices {{in order to be able}} to perform a natural interaction. For the inference of their preference or interests regarding the surrounding environment, it is possible to take in consideration the movements of their eyes or head. Based on the analysis of eye movements, an assistive high level eye tracking interface can be designed to find the intentions of the users. A natural interaction can also be performed at some extent using head movements. This work is a compared study regarding the promptness of selection between two interaction interfaces, one based on head tracking and the other based on eye tracking. Several experiments have been conducted in order to obtain a selection speed ratio during the process of selecting virtual objects. This parameter is useful in the evaluation of promptness or ergonomics of a certain selection method, provided that eyes focus almost instantly on the objects of interest, long before a selection is completed with any other kind of interaction device (i. e. mouse, pointing wand, infrared markers). For the tests, the tracking of eyes and head movements has been performed with a high speed and highly accurate head <b>mounted</b> <b>eye</b> tracker and a 6 DoF magnetic sensor attached to the head. Direction of gaze is considered with respect to the orientation of head, thus users are free to turn around or move freely during the experiments. The interaction interface based on eye tracking allows the users to make selections just by gazing at objects, while the head tracking method forces the users to turn their heads towards the objects they want to be selected...|$|R
40|$|Copyright 2010 Society of Photo-Optical Instrumentation Engineers. One {{print or}} {{electronic}} copy {{may be made}} for personal use only. Systematic electronic or print reproduction and distribution, duplication of any material in this paper for a fee or for commercial purposes, or modification {{of the content of}} the paper are prohibited. This paper can also be found at: [URL] mammography is gradually being introduced across all breast screening centres in the UK during 2010. This provides increased training opportunities using lower resolution, lower cost and more widely available devices, in addition to the clinical digital mammography workstations. This study examined how experienced breast screening personnel performed when they examined sets of difficult DICOM two-view screening cases in three conditions: on GE digital mammography workstations, on a standard LCD monitor (using a DICOM viewer) and an iPhone (running Osirix software). In each condition they either viewed the full images unaided or were permitted to use the post-processing manipulations of pan, zoom and window level/width adjustments. For each case they had to report the feature type, rate their confidence on the presence of abnormality, classify the case and specify case density. Their visual search behaviour was recorded throughout using a head <b>mounted</b> <b>eye</b> tracker. Additionally aspects of their real life screening performance and performance on a national self assessment scheme were examined. Data indicate that screening experience {{plays a major role in}} doing well on the self assessment scheme. Task performance was best on the clinical workstation. However, the data also suggest that a DICOM viewer that runs on a PC or laptop with a standard LCD display allows viewing digital images in full resolution support impressive cancer detection performance. The iPhone is not ideal for examining full images due to the amount of scrolling and zooming required. Overall, the results indicate that low cost devices could be used to provide additional tailored training as long as device resolution and HCI aspects are carefully considered...|$|R
