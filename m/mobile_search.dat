244|410|Public
25|$|<b>Mobile</b> <b>search</b> is {{important}} for the usability of mobile content for the same reasons as internet search engines became important to the usability of internet content. Early internet content was largely provided by portals such as Netscape. As the depth of available content grew, portals were unable to provide total coverage. As a result, Internet web search engines such as Google and AltaVista proved popular as a way of allowing users to find the increasingly specialist content they were looking for. In an international journal article, 'Exploring the logic of mobile search', Westlund, Gómez-Barroso, Compañó, and Feijóo(2011) outline a thorough review of research on <b>mobile</b> <b>search</b> usage, and also present an in-depth study of user patterns. They conclude that <b>mobile</b> <b>search</b> has started to change mobile media consumption patterns radically. They also emphasize that future developments of <b>mobile</b> <b>search</b> must be sensitive to the mobile logic.|$|E
25|$|Within {{the broad}} {{umbrella}} of <b>mobile</b> <b>search</b> (the ability to browse for mobile specific content), {{there are a}} range of services. Given the relative immaturity of the market, {{not all of these}} can be expected to become the industry standards.|$|E
25|$|<b>Mobile</b> <b>search</b> is an {{evolving}} branch of information retrieval services that {{is centered on}} the convergence of mobile platforms and mobile phones, or {{that it can be}} used to tell information about something and other mobile devices. Web search engine ability in a mobile form allows users to find mobile content on websites which are available to mobile devices on mobile networks. As this happens mobile content shows a media shift toward mobile multimedia. Simply put, <b>mobile</b> <b>search</b> is not just a spatial shift of PC web search to mobile equipment, but is witnessing more of treelike branching into specialized segments of mobile broadband and mobile content, both of which show a fast-paced evolution.|$|E
50|$|In April 2011, Magicbricks {{introduced}} the mobile website with features like <b>mobile</b> <b>searches</b> for property, agent, builder and price trends.|$|R
50|$|<b>Mobile</b> local <b>search</b> {{is usually}} based on {{organized}} directories accessed through specialized search tools, {{rather than the}} web, although <b>mobile</b> local <b>search</b> often provides links to mobile (WAP) web sites. It is also an application of a location-based service.|$|R
25|$|Howcast has {{developed}} free, native {{applications for the}} iPhone, iPad, and Android-powered phones to allow <b>mobile</b> <b>searching</b> and viewing of Howcast videos. The Howcast for iPhone application launched in November 2008 and received more than 500,000 downloads by May 2009.|$|R
25|$|Texperts was a UK-based <b>mobile</b> <b>search</b> service. In December 2008, Texperts {{was bought}} by the United States-based Knowledge Generation Bureau, {{operator}} of the 118 118 services, a directory services company which had also entered the SMS Any question market. The company was later renamed KGBAnswers.|$|E
25|$|There {{will be a}} {{distinctly}} different flavor to this season’s search for the ivory-billed woodpecker. Seven members of the Cornell Lab of Ornithology’s <b>mobile</b> <b>search</b> team will plunge {{into some of the}} most forbidding wilderness in southwestern Florida. …The work begins in Florida in early January and continues through mid-March. …In mid-March the Cornell Lab of Ornithology team will join the South Carolina search along the Congaree, PeeDee, and Santee Rivers.|$|E
2500|$|... "Competition for the US <b>mobile</b> <b>search</b> market {{promises}} to be fierce, thanks to the large US online ad market and strong pushes by portals. By 2019, mobile ad spending will rise to $65.87 billion, or 72.2% of total digital ad spend", according to a leading market research firm; eMarketer. Depending on a researcher's particular bias toward telecom, Web or technology factors, the published forecasts for global <b>mobile</b> <b>search</b> vary from $1.5 billion by 2011 (from Informa Telecoms & Media) to over $11 billion by 2008 (according to Piper Jaffray).|$|E
5000|$|Pixable, {{provision}} of <b>mobile</b> photo <b>search</b> and aggregation services ...|$|R
5000|$|Tomasz Imieliński - Databases, Data Mining. <b>Mobile</b> Computing, <b>Search</b> engine {{technology}} ...|$|R
30|$|The {{proliferation}} of mobile devices is producing {{a new wave}} of <b>mobile</b> visual <b>search</b> applications that enable users to sense their surroundings with smart phones. As the particular challenges of <b>mobile</b> visual <b>search,</b> achieving high recognition bitrate becomes the consistent target of existed related works. In this paper, we explore to holistically exploit the deep learning-based hashing methods for more robust and instant <b>mobile</b> visual <b>search.</b> Firstly, we present a comprehensive survey of the existed deep learning based hashing methods, which showcases their remarkable power of automatic learning highly robust and compact binary code representation for visual search. Furthermore, in order to implement the deep learning hashing on computation and memory constrained mobile device, we investigate the deep learning optimization works to accelerate the computation and reduce the model size. Finally, we demonstrate a case study of deep learning hashing based <b>mobile</b> visual <b>search</b> system. The evaluations show that the proposed system can significantly improve 70 % accuracy in MAP than traditional methods, and only needs less than one second computation time on the ordinary mobile phone. Finally, with the comprehensive study, we discuss the open issues and future research directions of deep learning hashing for <b>mobile</b> visual <b>search.</b>|$|R
2500|$|Most major {{search engines}} have {{implemented}} a mobile optimized version {{of their products}} that take into consideration bandwidth and form factor limitations of the mobile platform. [...] For example, Google has launched a mobile-friendly version of their search engine. The algorithms for <b>mobile</b> <b>search</b> engine results {{are thought to be}} evolving and aspects such as location and predictive searching will become increasingly important. Google just released its latest 160 page Full Search Quality Raters Guide with a new emphasis on Mobile and Usefulness.|$|E
2500|$|A new {{category}} of <b>mobile</b> <b>search</b> tool that is emerging {{is one in}} which a pre-selected set of possible search content is downloaded in advance by a mobile user and then allows for a final internet search step. [...] An example of such search tools is the Worldport Navigator for the iPhone, which provides users with a push-button experience of selecting from thousands of human-screened and categorized Web selections in three or four seconds, without the need for text entry, search, result review, or page-scrolling.|$|E
5000|$|Overall <b>Mobile</b> <b>Search</b> Company of the Year, <b>Mobile</b> <b>Search</b> Awards, September 2008 ...|$|E
40|$|We {{present a}} {{low bit rate}} {{vocabulary}} coding scheme {{in the context of}} <b>mobile</b> landmark <b>search.</b> Our scheme exploits lo-cation cues to boost a compact subset of visual vocabulary, which is discriminative for visual search and incurs low bit rate query for efficient upstream wireless transmission. To validate the coding scheme, we have developed <b>mobile</b> land-mark <b>search</b> prototype systems within typical areas includ...|$|R
50|$|Swagbucks has {{released}} mobile apps on both Google Play and the App Store {{that allow the}} user to check their SB balances, perform <b>mobile</b> <b>searches,</b> answer the daily poll, complete special offers, and redeem SB for a selection of popular gift cards for major retailers, including Amazon, Walmart, Target and others. These apps are currently only available in the U.S.|$|R
30|$|Location {{recognition}} (i.e., logical localization) {{is one of}} {{the most}} important applications for <b>mobile</b> visual <b>search.</b> Different from the physical localization which gives the location of users or devices, the location recognition is to localize the objects captured by the mobile devices. For example, when the traveller takes a photo of one building in the city, the location recognition can instantly recognize and tag the photos with the name and location of building [76]. Although GPS embedded with mobile device can easily give the user/device location, how to localize the building from crowd buildings is a great challenge. In the past, <b>mobile</b> visual <b>search</b> was a main method to solve this problem. Given the images of the captured objects, the system will search the similar images which have location labels in the dataset to determine its location. Different from the existed <b>mobile</b> visual <b>search</b> scheme described in section 2, we try to use the deep learning hashing to solve the challenges of <b>mobile</b> visual <b>search.</b>|$|R
50|$|Some mobile {{carriers}} {{offer free}} or cheaper rate plans {{in exchange for}} SMS or other mobile ads. However, mobile TV and <b>mobile</b> <b>search</b> may override this privacy concern, {{as soon as they}} are implemented on a full-blown basis. In a naive way to override privacy concern, however, a user’s prior consent needs to be obtained through membership to join or user account to set up. Both mobile TV and <b>mobile</b> <b>search</b> may supersede the way of getting users’ prior consent through membership or user account because users are free to choose mobile TV channels or <b>mobile</b> <b>search</b> services on a voluntary basis.|$|E
50|$|AskMeNow Inc. was an American public corporation, {{specializing in}} <b>mobile</b> <b>search</b> and mobile advertising. The Irvine, California based company officially {{launched}} in November 2005 and ceased operations in late 2008. AskMeNow's primary offering was a consumer <b>mobile</b> <b>search</b> product which utilized proprietary technology {{to offer a}} natural language based interaction and dynamic content provision platform.|$|E
50|$|<b>Mobile</b> <b>search</b> is {{important}} for the usability of mobile content for the same reasons as internet search engines became important to the usability of internet content. Early internet content was largely provided by portals such as Netscape. As the depth of available content grew, portals were unable to provide total coverage. As a result, Internet web search engines such as Google and AltaVista proved popular as a way of allowing users to find the increasingly specialist content they were looking for. In an international journal article, 'Exploring the logic of mobile search', Westlund, Gómez-Barroso, Compañó, and Feijóo(2011) outline a thorough review of research on <b>mobile</b> <b>search</b> usage, and also present an in-depth study of user patterns. They conclude that <b>mobile</b> <b>search</b> has started to change mobile media consumption patterns radically. They also emphasize that future developments of <b>mobile</b> <b>search</b> must be sensitive to the mobile logic.|$|E
5000|$|Location-aware <b>mobile</b> {{real-estate}} <b>search</b> website {{specifically for}} mobile phones that detects the users' location using GPS ...|$|R
30|$|As {{introduce}} in Section 1.1, due to {{the complex}} capture conditions, the query image is naturally noisy with varying visual qualities, such as flashing, occupy, rotation, blur, affine transformation, etc. Therefore, except the three hash code constraints in the learning process, how to handle these specific noisy in the <b>mobile</b> visual <b>search</b> is another big challenge for the deep learning hashing-based <b>mobile</b> visual <b>search.</b>|$|R
30|$|In this paper, we {{comprehensively}} {{survey the}} exited deep learning hashing technologies {{to demonstrate the}} necessity and sufficiency of deep learning hashing based <b>mobile</b> visual <b>search.</b> To achieve it, we analyze three different kinds of deep learning hashing methods in detail, and compare their performance on the CIFAR- 10 dataset. Moreover, to efficiently implement the networks, we also discuss the deep learning optimization on mobile devices. Most important, according to our knowledge, we give {{one of the first}} attempts to design a deep learning hashing-based <b>mobile</b> visual <b>search</b> system for location recognition to evaluate our conclusions. Finally, after sufficient investigation, we give the emerging topics of deep learning hashing based <b>mobile</b> visual <b>search</b> in the future.|$|R
50|$|The only {{real-time}} {{solution that}} provides 100% attribution from every {{phone call from}} <b>mobile</b> <b>search.</b>|$|E
50|$|On July 31, 2012, Baidu {{announced}} they would {{team up with}} Sina to provide <b>mobile</b> <b>search</b> results.|$|E
5000|$|In August 2016, Google {{announced}} {{two major}} changes {{related to its}} <b>mobile</b> <b>search</b> results. The first, removing the [...] "mobile-friendly" [...] label that highlighted pages were easy to read on mobile from its <b>mobile</b> <b>search</b> results page. The second, on January 10, 2017, the company will start punishing mobile pages that show intrusive interstitials when a user first opens a page and they will rank lower in its search results.|$|E
40|$|We survey popular {{data sets}} used in {{computer}} vision literature {{and point out}} their limitations for <b>mobile</b> visual <b>search</b> applications. To overcome many of the limitations, we propose the Stanford <b>Mobile</b> Visual <b>Search</b> data set. The data set contains camera-phone images of products, CDs, books, outdoor landmarks, business cards, text documents, museum paintings and video clips. The data set has several key characteristics lacking in existing data sets: rigid objects, widely varying lighting conditions, perspective distortion, foreground and background clutter, realistic ground-truth reference data, and query data collected from heterogeneous low and high-end camera phones. We hope that the data set will help push research forward {{in the field of}} <b>mobile</b> visual <b>search.</b> Categories andSubjectDescriptor...|$|R
40|$|The {{advent of}} smart phones has {{provided}} an excellent platform for <b>mobile</b> visual <b>search.</b> Most of previous <b>mobile</b> visual <b>search</b> systems adopt {{the framework of}} ”bag of words”,in which words indicate quantized codes of visual features. In this work, we propose a novel <b>mobile</b> visual <b>search</b> system based on ”bag of hash bits”. Using new ideas for hash bit selection, multi-hash table generation, and hamming-distance soft scoring, we overcome the problem of bit inefficiency affecting the traditional hashing approaches, and achieve promising accuracy outperforming state of the art. The framework is also general in that general feature type {{can be used for}} generating the hash bits. Demos and experiments over a large scale product image set demonstrate the effectiveness of our approach...|$|R
50|$|In May 2007, Monster {{launched}} its first (NA and EU) Mobile services offering <b>Mobile</b> job <b>search</b> and career advice.|$|R
50|$|The <b>mobile</b> <b>search</b> {{provides}} {{secure access}} to all relevant company information via mobile devices such as a tablet or smartphone.|$|E
5000|$|Though {{there are}} various ways of {{classifying}} or naming the categories of {{the different types of}} user intent, overall they seem to follow the same clusters. In general and up until the rise and explosion of <b>mobile</b> <b>search,</b> there are and were three very broad categories: informational, transactional, and navigational. However over time and with the rise of <b>mobile</b> <b>search,</b> other categories have appeared or categories have segmented into more specific categorization.|$|E
50|$|In February 2016 Relcy added a {{messaging}} system to its <b>mobile</b> <b>search</b> engine and announced {{the launch of}} an Android app.|$|E
40|$|Cataloged from PDF {{version of}} thesis. Includes bibliographical {{references}} (leaves 70 - 75). Thesis (M. S.) : Bilkent University, Department of Computer Engineering, İhsan Doğramacı Bilkent University, 2015. As availability of internet access on mobile devices develops year after year, users {{have been able}} to make use of <b>mobile</b> internet and <b>search</b> services while on the go. Location information on these devices has enabled mobile users to utilize local search applications for discovering places and activities around them. Although <b>mobile</b> local <b>search</b> is a kind of search activity, it is inherently di erent than general web <b>search.</b> <b>Mobile</b> local <b>search</b> focuses on local businesses and points of interest, instead of web pages as in general web search. Moreover, users' context has a signi cant e ect on their decision process. In previous studies, ranking signals and user context have been investigated on a small set of features. We extend ranking signals and user context in <b>mobile</b> local <b>search</b> with using data of location-based social networks. We developed a <b>mobile</b> local <b>search</b> application, Gezinio, and collected a data set of local search queries. Gezinio helps users to issue local queries and see various kinds of social information about local businesses around them. We built ranking models and investigated how social features a ect decision process of users. We show that social features in uence users' click decisions and they can be utilized by ranking models to improve the local search experience. Additionally, we propose di erent social features for di erent query categories. by Basri Kahveci. M. S...|$|R
30|$|As {{introduced}} in Section 1.1, <b>mobile</b> visual <b>search</b> is seriously {{disturbed by the}} noise of captured images or videos, such as flashing, occupy, rotation, blur, affine transformation, and so on. How to design robust features for more accurate search is still a great challenge. However, the existed deep learning hashing methods for desktop images search mainly focus on how to mine the discriminative features for images having a similar labels, which neglect these invariance properties. Therefore, in the future, the deep learning hashing method designed for <b>mobile</b> visual <b>search</b> must handle these specific noise {{in the learning process}} to further improve the accuracy, such as add the transformation invariance in the loss function and so on. In addition, large scale <b>mobile</b> visual <b>search</b> dataset is also needed to learn effective features.|$|R
30|$|Recently, as {{the basic}} {{function}} for numerous mobile applications, <b>mobile</b> visual <b>search</b> attracts massive researchers’ attention [41]. As described in Section 1.1, the existed <b>mobile</b> visual <b>search</b> works mostly focused on how to achieve high recognition bitrate [8], which could be classified into four categories according to their transferred query types: transfer scaled-down or compressed images [9, 42, 43], transfer moderate features [10 – 12], transfer compressed features [13, 14, 44, 45], and transfer feature signature produced by hashing [15, 16, 46 – 48].|$|R
