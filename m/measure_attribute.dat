12|1278|Public
50|$|From a {{conceptual}} point of view, performance-based budgeting systems are a sub-set {{of what are}} known as 'outcomes systems'. Outcomes systems are any systems designed to identify, prioritize, <b>measure,</b> <b>attribute</b> and/or hold parties to account for outcomes. The technical principles for developing and implementing sound performance-based budgeting systems as a type of outcomes system are described in outcomes theory.|$|E
5000|$|It is easy {{to trace}} the {{influence}} of Hutcheson's ethical theories on the systems of Hume and Adam Smith. The prominence given by these writers {{to the analysis of}} moral action and moral approbation with the attempt to discriminate the respective provinces of the reason and the emotions in these processes, is undoubtedly due to the influence of Hutcheson. To a study of the writings of Shaftesbury and Hutcheson we might, probably, in large <b>measure,</b> <b>attribute</b> the unequivocal adoption of the utilitarian standard by Hume, and, if this be the case, the name of Hutcheson connects itself, through Hume, with the names of Priestley, Paley and Bentham. Butler's Sermons appeared in 1726, the year after the publication of Hutcheson's two first essays, and there are parallels between the [...] "conscience" [...] of the one writer and the [...] "moral sense" [...] of the other.|$|E
40|$|This paper {{discusses}} {{several factors}} influencing {{the evaluation of}} the degree of interestingness of rules discovered by a data mining algorithm. The main goals of this paper are: (1) drawing attention to several factors related to rule interestingness that have been somewhat neglected in the literature; (2) showing some ways of modifying rule interestingness measures to take these factors into account; (3) introducing a new criterion to <b>measure</b> <b>attribute</b> surprisingness, as a factor influencing the interestingness of discovered rules. Keywords: data mining, rule interestingness, rule surprisingness...|$|E
50|$|There are {{two main}} ways to improve performance: {{improving}} the <b>measured</b> <b>attribute</b> by using the performance platform more effectively, or by improving the <b>measured</b> <b>attribute</b> by modifying the performance platform, which in turn allows a given level of use {{to be more effective}} in producing the desired output.|$|R
40|$|ABSTRACT Data Warehousing and OLAP {{applications}} typically {{view data}} as having multiple logical dimensions (e. g., product, location) with natural hierarchies defined on each dimension. OLAP queries usually involve hierarchical selections {{on some of}} the dimensions, and often aggregate <b>measure</b> <b>attributes</b> (e. g., sales, volume). Accurately estimating the distribution of <b>measure</b> <b>attributes,</b> under hierarchical selections, is important in a variety of scenarios, including approximate query evaluation and cost-based optimization of queries...|$|R
40|$|Data Warehousing and OLAP {{applications}} typically {{view data}} as having multiple logical dimensions (e. g., product, location) with natural hierarchies de ned on each dimension. OLAP queries usually involve hierarchical selections {{on some of}} the dimensions, and often aggregate <b>measure</b> <b>attributes</b> (e. g., sales, volume). Accurately estimating the distribution of <b>measure</b> <b>attributes,</b> under hierarchical selections, is important in a variety of scenarios, including approximate query evaluation and cost-based optimization of queries. In this paper, we propose fast (near linear time) algorithms for the problem of approximating the distribution of <b>measure</b> <b>attributes</b> with hierarchies de ned on them, using histograms. Our algorithms are based on dynamic programming and a novel notion of sparse intervals that we introduce, and are the rst practical algorithms for this problem. They effectively trade space for construction time without compromising histogram accuracy. We complement our analytical contributions with an experimental evaluation using real data sets, demonstrating the superiority of our approach...|$|R
40|$|In {{this thesis}} we present SIRUM: {{a system for}} Scalable Informative RUle Mining from multi-dimensional data. Informative rules have {{recently}} been studied in several contexts, including data summarization, data cube exploration and data quality. The objective is to produce a concise set of rules (patterns) over {{the values of the}} dimension attributes that provide the most information about the distribution of a numeric <b>measure</b> <b>attribute.</b> SIRUM optimizes this task for big, wide and distributed datasets. We implemented SIRUM in Spark and observed significant performance improvements on real data due to our optimizations...|$|E
40|$|OLAP queries (i. e. group-by or cube-by queries with aggregation) {{have proven}} to be {{valuable}} for data analysis and exploration. Many decision support applications need very complex OLAP queries, requiring a fine degree of control over both the group definition and the aggregates that are computed. For example, suppose that the user has access to a data cube whose <b>measure</b> <b>attribute</b> is Sum(Sales). Then the user might wish to compute the sum of sales in New York and the sum of sales in California for those data cube entries in which Sum(Sales) ? $ 1, 000, 000...|$|E
40|$|Abstract—In {{order to}} {{minimize}} vulnerabilities and achieve target level security, quantification of security is necessary. Unfortunately, quantitative estimation of security in design phase is largely missing. Given the need and significance of such a mechanism, an effort has {{been made by the}} authors of the paper to deduce a methodology to find out the impact of Inheritance on vulnerability propagation in object oriented design (OOD). An algorithm to <b>measure</b> <b>Attribute</b> Vulnerability Ratio (AVR) of an OOD is developed. The proposed approach is implemented using a case study of Automated Teller Machine (ATM) to illustrate the applicability of the approach...|$|E
40|$|One of {{the most}} {{striking}} and challenging phenomena in the Social Sciences is the unreliability of its measurements: <b>Measuring</b> the same <b>attribute</b> twice often yields two different results. If the same measurement instrument is applied twice such a difference may sometimes be due to a change in the <b>measured</b> <b>attribute</b> itself. Sometimes thes...|$|R
5000|$|<b>Measured</b> <b>attributes</b> - {{assessments}} {{vary with}} regard to the specific personality <b>attributes</b> <b>measured.</b> Some assessments focus on an individual's interests, and perhaps aptitude, while others focus on skills or values. More robust assessments use key development indicators (KDIs) that define measurements for specific types of careers and match individual career aspirations with the needs of companies.|$|R
50|$|Physical {{properties}} map is a maps {{of various}} <b>measured</b> <b>attributes</b> of the extraterrestrial surface, such as albedo (see albedo, in this section), thermal anomalies (e.g., {{the distribution of}} hotspots on the Earth-facing hemisphere of the Moon), and polarimetric measurements.|$|R
30|$|Tarjan’s {{algorithm}} {{does not}} have parameters to be adjusted. The parameters of the GAs and MOEAs were adjusted following our previous works[11, 12], where an empirical parameter tuning was done[32]. To configure the algorithms of approach SBA, besides the parameters related to the evolution process, it was also necessary to set the weights of the measures: attribute and operation coupling to compose the aggregated fitness function. We evaluated three combinations of weights. To verify the empirical influence of each measure in the stub construction we used a configuration to minimize only the attribute coupling (identified here as the configuration GA with attributes (GAA)). In this configuration, {{the weight of the}} measure operation coupling was set to zero. The other configuration minimizes only the operation coupling (identified here as the configuration GA with Operations (GAO)). In this configuration, the weight of the <b>measure</b> <b>attribute</b> coupling was set to zero. In the third configuration (configuration GA), equal importance was given to both measures.|$|E
40|$|This paper {{introduces}} a new method for measuring attribute utilities in multiattribute utility theory. The novelty of our method {{lies in the}} use of anchor levels, i. e. levels of attributes the value of which is not affected by other attributes. It is shown that, no matter how complex the interactions between attributes are, we can meaningfully define and <b>measure</b> <b>attribute</b> utilities if we can construct anchor levels for those attributes. When applied to time preferences, the method measures temporal utility in the presence of intertemporal dependencies. An application to medical decision making is described, where the (dis) utility of side-effects of radiotherapy, an important factor in the treatment decision, can now be measured. KEY WORDS: Utility Measurement, Multiattribute Utility, Time Preference, QALY 2 1. INTRODUCTION This paper is the final part of a trilogy on utility measurement. The three papers introduce a new method for defining and measuring utilities of decision criteria [...] ...|$|E
40|$|We {{identify}} a broad class of aggregate queries, called MPF queries, {{inspired by the}} literature on marginalizing product functions. MPF queries operate on �functional relations,� where a <b>measure</b> <b>attribute</b> is functionally determined by the other relation attributes. An MPF query is an aggregate query over a stylized join of several functional relations. In the motivating literature on probabilistic inference, this join corresponds to taking the product of several probability distributions, and the grouping step corresponds to marginalization. Thus, MPF queries represent probabilistic inference in a relational setting. While they {{play a central role}} in probabilistic inference, and our work complements recent work that provides a framework for probabilistic inference in a database setting, we present MPF queries in a general form where arbitrary functions other than probability distributions are handled. We demonstrate the value of MPF queries for decision support applications through a number of illustrative examples. We exploit the relationship to probabilistic inference in query evaluation by combining database optimization techniques for aggregate queries with traditional algorithms from the probabilistic inference literature, such as Variable Elimination and Belief Propagation. We consider how to optimize individual queries, combining features from Variable Elimination and Chaudhuri and Shim�s algorithm for optimizing Group By queries. We also present an algorithm to find a cache of materialized views in order to efficiently evaluate a workload of MPF queries, combining Belief Propagation, Junction Trees, and database-style Group By optimizations. These results are especially interesting and timely because of the growing interest in managing data with uncertainty using probabilistic frameworks...|$|E
50|$|First {{thing to}} do is select a group of some subject (for forestry: trees). Then measure several easily <b>measured</b> <b>attributes</b> such as DBH, height, species, etc. Graph the results and perform a {{regression}} analysis and transform some of the variables until a correct regression is found.|$|R
40|$|One of {{problems}} that has dogged the science of astronomy from it inception is that of determining how far away objects are. Astronomers have devised a range of tools to convert from things we can measure into distances. One of the most easily <b>measured</b> <b>attributes</b> of an object is its brightness. The differenc...|$|R
40|$|Nick Koudas AT&T Labs [...] Research koudas@research. att. com S. Muthukrishnan AT&T Labs [...] Research muthu@research. att. com Divesh Srivastava AT&T Labs [...] Research divesh@research. att. com 1 Introduction Now {{there is}} {{tremendous}} interest in data warehousing and OLAP applications. OLAP applications typically view data as having multiple logical dimensions (e. g., product, location) with natural hierarchies defined on each dimension, {{and analyze the}} behavior of various <b>measure</b> <b>attributes</b> (e. g., sales, volume) {{in terms of the}} dimensions. OLAP queries typically involve hierarchical selections on some of the dimensions (e. g., product is classified under the jeans product category, or location is in the north-east region), often aggregating <b>measure</b> <b>attributes</b> (see, e. g., [6]). Cost-based query optimization of such OLAP queries needs good estimates of the selectivity of hierarchical selections. Histograms capture attribute value distribution statistics in a space-efficient fashion. They hav [...] ...|$|R
40|$|Format {{choice is}} {{recognized}} as a cognitive process. Like any other purchasing decision format choice also is an information processing behavior. A store is chosen based on the confidence that the customer has regarding the store; {{about the nature and}} quality of product and service he will receive. In Indian scenario formats {{have been found to be}} influencing the choice of store as well as orientation of the shoppers (Sinha and Uniyal, 2005). This study seeks to analyze the various factors influencing decision making process of customers in choosing a store format. A full-profile* procedure was used for the Conjoint Analysis in this study. The exploratory study brought out five different formats that existed in the food and grocery sector. With this it also identified combinations of the seven parameters have given rise to some generic retail formats. It also helped identifying the important factor set which affects consumer format choice decisions. The findings also provide details useful for retailers in designing an efficient retail package to offer their customers. * Full-profile conjoint analysis has been a popular approach to <b>measure</b> <b>attribute</b> utilities. In the full-profile conjoint task, different product descriptions (or even different actual products) are developed and presented to the respondent for acceptability or preference evaluations. Each product profile is designed as part of a fractional factorial experimental design that evenly matches the occurrence of each attribute with all other attributes. By controlling the attribute pairings, the researcher can estimate the respondent’s utility for each level of each attribute tested. ...|$|E
40|$|Attribute Kano {{characteristics}} {{are useful in}} product design to prioritize development efforts. However, attribute Kano characteristics have not been discussed and applied to product optimization when using Just-About-Right (JAR) scales. Product optimizations without identifying attributes Kano characteristics can be misleading. The two objectives in this research were: 1. Determine attribute Kano categories using a modified classic Kano classification methodology. 2. Propose a method to <b>measure</b> <b>attribute</b> performance and identify attribute Kano characteristics to direct product optimization. Two methodologies of attribute Kano classification were investigated. In experiment one, a modified classic Kano methodology was employed to determine attribute Kano categories through an online survey. Orange juice users (n= 1072) participated in the survey. Seven orange juice attributes were evaluated. In experiment two, orange juice users (n= 100) tested three commercial orange juices. The same attributes used in part one were investigated. Attribute Kano characteristics were investigated using the performance scale and partial least squares regressions. In experiment one, the results show consumers classified orange color as an indifferent attribute, and other attributes, i. e., orange flavor, sweetness, sourness, pulpiness, thickness and freshness, as attractive attributes. The determination on thickness seems weak since consumer responses in the categories of attractive and indifferent are relatively equal, reflecting the potential consumer segmentation. The decision on freshness is firm because {{there are more than}} 75 % consumer responses in the attractive category. Relatively high consumer responses in the questionable category of sourness and pulpiness indicate low efficiency of this research method. In experiment two, the results show that orange color was an indifferent attribute and the others, i. e., orange flavor, sweetness, sourness, pulpiness, thickness and freshness were identified as one-dimensional attributes. In Minute Maid Original, orange flavor, sweetness, thickness and freshness were not strong enough, and sourness was too strong. For Simple Orange Original, sourness was too strong and orange flavor, pulpiness, thickness and freshness were not enough. No defect was found with Tropicana Pure Premium. By integrating Kano characteristics, modification of these attributes can be prioritized...|$|E
40|$|Sustainable {{development}} in global food markets is hindered by {{the discrepancy between}} positive consumer attitudes towards sustainable development or sustainability {{and the lack of}} corresponding sustainable consumption by a majority of consumers. Apparently for many (light user) consumers the ‘importance’ of ‘sustainability’ has a meaning that is not directly translated into purchases. The cognitive and motivational perceptual structures of sustainability among light users of sustainable products are empirically compared to the Brundlandt definition (needs of future generations) and the Triple-P-Baseline (people, planet, prosperity) definition of sustainability. Results show that light users cognitively can distinguish between the social and temporal dimensions of the Brundlandt definition, as well as the people, planet and prosperity dimensions of the Triple-P definition of sustainability. In the motivational structure of light users of sustainable products, all attributes that do not offer direct and personal benefits are collapsed into a single dimension. This single dimension explains purchases more parsimoniously than a more complex structure, and is itself explained by a set of psychographic predictors that appears to be related to identity. Perceived relevance and determinance are two distinct constructs, underlying the overall concept of attribute importance. Attribute relevance is commonly measured by self-reported importance in a Likert type scale. In order to <b>measure</b> <b>attribute</b> determinance a survey based measure is developed. In an empirical survey (N= 1543) determinance of sustainability related product attributes is measured through a set of forced choice items and contrasted to self-reported relevance of those attributes. In line with expectations, a priori determinance predicts sustainable food choice more efficiently than perceived relevance. Determinance of sustainability related product attributes can be predicted by future temporal orientation, independently of relevance of these attributes. These results support an interpretation of the attitude to behaviour gap in terms of construal level theory, and this theory allows for testable hypotheses on low construal motivators that should induce light users to purchase sustainable products. Sustainable consumption is viewed as a dilemma between choices for immediate (low construal) benefits and choices that avoid long-term collective (high construal) harm. Identity theory suggests that self-confirmation could be a driving motive behind the performance of norm-congruent sustainable behaviour. Through identity people may acquire the intrinsic motivation to carry out pro-environmental behaviour. This view is tested in two empirical studies in The Netherlands. The first study shows that sustainable identity predicts sustainable preference, and that the effect of identity on preference is partly mediated by self-confirmation motives. The second study confirms that sustainable identity influences the determinance of sustainable attributes, and through this determinance has an impact on sustainable product choice. This effect is partly mediated by stated relevance of these attributes. Sustainable certification signals positive sustainable quality of a product, but fail to create massive demand for such products. Based on regulatory focus theory and prospect theory it is argued that negative signalling of low sustainable quality would have a stronger effect on the adoption of sustainable products than the current positive signalling of high sustainable quality. The effects of positive vs. negative signalling of high vs. low sustainable quality on attitude and preference formation are tested in three experimental studies. Results show (1) that negative labelling has a larger effect on attitude and preference than positive labelling, (2) that the effect of labelling is enhanced by regulatory fit, and (3) that the effect of labelling is mediated by personal norms, whereas any additional direct effect of environmental concern on preference formation is negligible. Overall the present thesis suggests that the attitude to behaviour gap in sustainable consumption can be explained as a conflict between high construal motives for the abstract and distant goals of sustainable development and the low construal motives that drive daily consumption. Activating low construal motives for sustainable consumption, be it intrinsic motives to affirm a sustainable self-concept or loss aversion motives, increases sustainable consumer behaviour. Applying these insights to marketing decision making opens a new line of research into the individual, corporate, and institutional drivers that may contribute to the sustainable development of global food markets...|$|E
5000|$|... <b>measuring</b> {{multiple}} <b>attributes</b> (sexual attraction, {{sexual orientation}} identity and sexual behaviour) separately ...|$|R
50|$|As a consequence, {{the system}} behaves as a {{classical}} statistical ensemble {{of the different}} elements {{rather than as a}} single coherent quantum superposition of them. From the perspective of each ensemble member's measuring device, the system appears to have irreversibly collapsed onto a state with a precise value for the <b>measured</b> <b>attributes,</b> relative to that element.|$|R
40|$|In {{psychological}} measurement, two {{interpretations of}} measurement {{systems have been}} developed: the reflective interpretation, in which the <b>measured</b> <b>attribute</b> is conceptualized as the common cause of the observables, and the formative interpretation, in which the <b>measured</b> <b>attribute</b> {{is seen as the}} common effect of the observables. We advocate a third interpretation, in which attributes are conceptualized as systems of causally coupled (observable) variables. In such a view, a construct like ’depression’ is not seen as a latent variable that underlies symptoms like ’lack of sleep’ or ’fatigue’, and neither as a composite constructed out of these symptoms, but as a system of causal relations between the symptoms themselves (e. g., lack of sleep / fatigue, etc.). We discuss methodological strategies to investigate such systems as well as theoretical consequences that bear on the question in which sense such a construct could be interpreted as real...|$|R
40|$|Recently, {{structured}} data {{is getting more}} and more important in database applications, such as molecular biology, image retrieval or XML document retrieval. Attributed graphs are a natural model for the {{structured data}} in those applications. For the clustering and classification of such structured data, a similarity <b>measure</b> for <b>attributed</b> graphs is necessary. All known similarity <b>measures</b> for <b>attributed</b> graphs are either limited to a special type of graph or computationally extremely complex, i. e. NP-complete, and are, therefore, unsuitable for data mining in large databases. In this paper, we present a new similarity <b>measure</b> for <b>attributed</b> graphs, called matching distance. We demonstrate, how the matching distance can be used for e#cient similarity search in attributed graphs. Furthermore, we propose a filter-refinement architecture and an accompanying set of filter methods {{to reduce the number of}} necessary distance calculations during similarity search. Our experiments show that the matching distance is a meaningful similarity <b>measure</b> for <b>attributed</b> graphs and that it enables e#cient clustering of structured data...|$|R
30|$|Science {{identity}} is psychometrically {{distinct from the}} other science attitudinal <b>measures</b> often <b>attributed</b> to identity.|$|R
50|$|The {{study of}} {{allometry}} {{is extremely important}} in dealing with measurements and data analysis {{in the practice of}} forestry. Allometry studies the relative size of organs or parts of organisms. Tree allometry narrows the definition to applications involving measurements of the growth or size of trees. Allometric relationships are often estimating difficult tree measurement, such as volume, from an easily <b>measured</b> <b>attribute</b> such as diameter at breast height (DBH).|$|R
50|$|While {{reliability}} {{does not}} imply validity, reliability does place a limit on the overall validity of a test. A test that is not perfectly reliable cannot be perfectly valid, either {{as a means of}} <b>measuring</b> <b>attributes</b> of a person or as a means of predicting scores on a criterion. While a reliable test may provide useful valid information, a test that is not reliable cannot possibly be valid.|$|R
30|$|The {{simulation}} {{which is}} implemented in C++ works on static traffic sets generated using randomized multiple CT requests with uniform distribution. The performance of RDM TELIC is measured {{on the basis}} of randomized traffic sets as mentioned above on multiple domain, i.e., single path (SP), multipath (MP), several paths and irregular several paths (ISP), fish, and duck. The <b>measured</b> <b>attributes</b> are allocation, rejection, and pre-emption of CT 1 and CT 2 traffic.|$|R
50|$|Development {{of tools}} and {{technologies}} to <b>measure</b> quality <b>attributes</b> of fruit pre-harvest, reducing harvest losses and labour costs while maximising yield.|$|R
40|$|This paper {{explores the}} {{attributes}} of quality in recorded clinical encounter data, examines issues in <b>measuring</b> these <b>attributes,</b> and describes a method for <b>measuring</b> two <b>attributes,</b> completeness and correctness. The method is defined {{in the context of}} computer-based records and is demonstrated in a pilot study. Videotaped physician-patient encounters and an empiric process of determining a gold standard for content are used. The methodology was found to be feasible. Problems encountered during the pilot study can be remedied...|$|R
5000|$|... #Caption: In July 1950 {{the first}} Bumper rocket is {{launched}} from Cape Canaveral, Florida. The Bumper was a two-stage rocket {{consisting of a}} Post-War V-2 topped by a WAC Corporal rocket. It could reach then-record altitudes of almost 400 km. Launched by General Electric Company, this Bumper was used primarily for testing rocket systems and for research on the upper atmosphere. They carried small payloads {{that allowed them to}} <b>measure</b> <b>attributes</b> including air temperature and cosmic ray impacts.|$|R
5000|$|Stability {{requires}} that fingerprints {{remain the same}} over time. However, by definition browser configuration preferences are not tamper proof. For example, if one <b>measured</b> <b>attribute</b> is whether the browser has cookies on or off, then a simple change of that setting is sufficient to change the fingerprint. One remedy {{is to reduce the}} number of parameters collected to only those that are very unlikely to change; however, this is likely to reduce diversity, as fewer parameters are being measured.|$|R
40|$|Pu 300 has {{particular}} {{application in}} the Arms Control Transparency arena, where very sensitive material {{is often the}} subject of tests and measurements. In Arms Control Transparency projects, we attempt to <b>measure</b> <b>attributes</b> of material removed from a nuclear weapon without revealing sensitive information about the material. The <b>measured</b> <b>attribute</b> can either be reported directly or compared against a threshold value. The set of <b>attributes</b> that are <b>measured</b> {{can be used as}} a fingerprint for the material. One such attribute for plutonium is material age. Age, in this sense, is defined as the amount of time that has passed since americium separation. The Pu 300 system consists of a coaxial HPGe detector and a Canberra Inspector multichannel analyzer. The Inspector allows the high resolution spectral information to be limited by adjusting upper and lower level discriminators so only the information between 330 keV and 350 keV is collected. The fits of the peaks in the gamma-ray spectrum are fed into a physics code to give an age of the material measured. The physics code is based on the buildup of {sup 241 }Am from the decay of {sup 241 }Pu...|$|R
40|$|Variation in wheat kernel {{hardness}} {{is influenced}} by several factors including genetic expression and environmental conditions. However, these factors explain {{only a portion of}} the observed variation. Thus, there are unknown contributors to this important physical property. The following experi-ments investigated growing locations between farms and within the spike as a source of variation. Four commercial varieties of Hard Red Winter (HRW) wheat were chosen for evaluation; Jagger, Jagalene, Overley, and 2137. In total, 374 wheat spikes were collected from three farms participating in the Kansas State University Research and Extension- 2007 Crop Performance Tests (KSCPT). For analyses, each kernel was removed and cataloged by spikelet and floret position. A total of 10, 240 kernels were uniquely identified by variety, farm, plot, spike, spikelet and floret position. Using the single kernel characterization system (SKCS), kernels were crushed to determine the hardness, diameter, weight, and moisture content. The variability of each <b>measured</b> <b>attribute</b> was greatest between spikes of a given variety. <b>Measured</b> <b>attributes</b> exist in gradients along the spike, with the top and bottom portions being most variable. This research broadens our knowledge of wheat kernel variation, and results from this experiment may contribute to improved methods fo...|$|R
40|$|An {{improved}} attribute recognition {{method is}} reviewed and discussed {{to evaluate the}} risk of water inrush in karst tunnels. Due to the complex geology and hydrogeology, the methodology discusses the uncertainties related to the evaluation index and <b>attribute</b> <b>measure.</b> The uncertainties can be described by probability distributions. The values of evaluation index and <b>attribute</b> <b>measure</b> were employed through random numbers generated by Monte Carlo simulations and an <b>attribute</b> <b>measure</b> belt was chosen instead of the linearity <b>attribute</b> <b>measure</b> function. Considering the uncertainties of evaluation index and <b>attribute</b> <b>measure,</b> the probability distributions of four risk grades are calculated using random numbers generated by Monte Carlo simulation. According to the probability distribution, the risk level can be analyzed under different confidence coefficients. The method improvement is more accurate and feasible compared with the results derived from the attribute recognition model. Finally, the improved attribute recognition method was applied and verified in Longmenshan tunnel in China...|$|R
