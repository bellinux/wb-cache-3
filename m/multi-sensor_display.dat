1|2|Public
30|$|For unknown task environments, {{presenting}} all {{the information}} to the operator gives them the opportunity to decide what is useful given the task. However, a <b>multi-sensor</b> <b>display</b> may be beneficial only when each single sensor provides unique useful information to contribute to correct decision-making. System designers should not eliminate the potential for using display methods that provide {{all the information}} while minimizing the operator’s invested attentional resources.|$|E
40|$|Multispectral imagery {{can supply}} an {{observer}} with different components of information to, in combination, lead to critical decisions. Human observers can be presented with two fusion techniques: 1) cognitive fusion presents the two sensor images within 5 degrees of visual angle and 2) algorithmic fusion aims to enhance image quality by combining relevant information from two individual sensor images into one composite image. Researchers have used {{methods such as}} comparing performance across different algorithms or comparing algorithmic fusion to a single-sensor image. However, cognitive fusion is a technique that provides all of the sensor information and, if utilized efficiently, may yield better performance than algorithmic fusion. I used a cognitive framework, systems factorial technology (Townsend 2 ̆ 6 Nowaza, 1995) to test specific underlying mechanisms of information processing across both fusion techniques in two discrimination tasks. The results of my Experiments demonstrate that the efficiency of processing sensor information is just as good for cognitive fusion as algorithmic fusion across both discrimination tasks. Future research with <b>multi-sensor</b> <b>displays</b> should not disregard the potential benefits that displaying all of the available information may have over the algorithmic interpretations of important information...|$|R
40|$|We {{have gained}} {{important}} insights from prior {{studies that have}} suggested relationships between lightning and storm growth, decay, convective rain flux, vertical distribution of storm mass and echo volume in the region, and storm energetics. A study was initiated in the Summer of 1996 to determine how total (in-cloud plus ground) lightning observations might provide added knowledge to the forecaster in the determination and identification of severe thunderstorms and weather hazards in real-time. The Melbourne Weather Office was selected as a primary site to conduct this study because Melbourne is the only site {{in the world with}} continuous and open access to total lightning (LDAR) data and a Doppler (WSR- 88 D) radar. A Lightning Imaging Sensor Data Applications Demonstration (LISDAD) system was integrated into the forecaster's workstation during the Summer 1996 to allow the forecaster to interact in real-time with the <b>multi-sensor</b> data being <b>displayed.</b> LISDAD currently ingests LDAR data, the cloud-to-ground National Lightning Detection Network (NLDN) data, and the Melbourne radar data in f real-time. The interactive features provide the duty forecaster the ability to perform quick diagnostics on storm cells of interest. Upon selection of a storm cell, a pop-up box appears displaying the time-history of various storm parameters (e. g., maximum radar reflectivity, height of maximum reflectivity, echo-top height, NLDN and LDAR lightning flash rates, storm-based vertically integrated liquid water content). This product is archived to aid on detailed post-analysis...|$|R

