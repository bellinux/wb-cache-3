11|543|Public
5000|$|Suppose an LSM is {{implemented}} via [...] B-trees, {{each of which}} has a capacity that is [...] larger than its predecessor.The <b>merge</b> <b>time</b> depends on three facts: The sorted order of keys in an -item B-tree can be produced in [...] IOs; Two sorted lists of [...] and [...] items can be merged into a sorted list in [...] IOs; and a B-tree of a sorted list of [...] items can be built in [...] IOs. When a tree overflows, it is merged into a tree whose size is [...] larger, therefore a level that holds [...] items requires [...] IOs to merge. An item may be merged once per level, giving a total time of , which matches the Fractal Tree index.|$|E
50|$|Time Inc. and Warner Communications were {{planning}} to <b>merge.</b> <b>Time</b> {{wanted to get into}} TV more with its HBO channel, and wanted Warner Communications’s help. Then Paramount made an offer to all the shareholders of $200 per share (up from an initial $175). Time shares had been trading at $120. Time had a range of defenses, including a staggered board, making it hard to meet, with a 50-day notice period for any motions, and a poison pill plan with a 15% trigger. But with the Paramount threat, they went further. It {{was going to be a}} stock for stock merger, and instead they changed it into a leveraged purchase transaction. The NYSE required that shareholder approval be given for transfers above 20% of shares. So this change in the structure of the transaction meant that shareholders would not be given a say.|$|E
50|$|For the Fibonacci heap, the find-minimum {{operation}} takes constant (O(1)) amortized time. The insert {{and decrease}} key operations also work in constant amortized time. Deleting an element (most {{often used in}} the special case of deleting the minimum element) works in O(log n) amortized time, where n {{is the size of}} the heap. This means that starting from an empty data structure, any sequence of a insert and decrease key operations and b delete operations would take O(a + b log n) worst case time, where n is the maximum heap size. In a binary or binomial heap such a sequence of operations would take O((a + b) log n) time. A Fibonacci heap is thus better than a binary or binomial heap when b is smaller than a by a non-constant factor. It is also possible to merge two Fibonacci heaps in constant amortized time, improving on the logarithmic <b>merge</b> <b>time</b> of a binomial heap, and improving on binary heaps which cannot handle merges efficiently.|$|E
5000|$|There {{are several}} other heaps which support faster <b>merge</b> <b>times.</b> For instance, Fibonacci heaps can be <b>merged</b> in [...] <b>time.</b> Since binary heaps require [...] <b>time</b> to <b>merge,</b> shadow merge remains efficient.|$|R
2500|$|In 1989, when Time, Inc. and Warner Communications <b>merged,</b> <b>Time</b> {{became part}} of Time Warner, along with Warner Bros[...]|$|R
40|$|Abstract We use {{controlled}} N-body simulation {{to investigate}} the dynamical pro-cesses (dynamical friction, tidal truncation, etc.) involved in the merging of small satellites into bigger halos. We confirm the validity of some analytic formulae pro-posed earlier based on simple arguments. For rigid satellites represented by softened point masses, the <b>merging</b> <b>time</b> scale depends on both the orbital shape and con-centration of the satellite. The dependence on orbital ellipticity is roughly a power law, as suggested by Lacey & Cole, and the dependence on satellite concentration {{is similar to that}} proposed by White. When merging satellites are represented by non-rigid objects, Tidal effects must be considered. We found that material beyond the tidal radius are stripped off. The decrease in the satellite mass might mean an increase in the <b>merging</b> <b>time</b> scale, but in fact, the <b>merging</b> <b>time</b> is decreased, because the stripped-off material carries away a proportionately larger amount of of orbital energy and angular momentum...|$|R
40|$|Abstract—In {{the first}} phase of sorting a large file, sorted sequences, called runs, are generated. In the second phase, the runs are merged into a sorted file. The <b>merge</b> <b>time</b> can be much greater than the runs-generation time. Generating longer runs and thus fewer runs in {{the first phase}} may greatly reduce the <b>merge</b> <b>time.</b> In this paper, we present a {{parallel}} algorithm that can utilize the broadcast capability of the IBM SP 2 to generate long runs. The new algorithm has been implemented in C and PVMe. Experimental results show that our algorithm generates longer runs than two earlier algorithms, and is more desirable...|$|E
40|$|UCIMerge is a {{framework}} in STATA to standardize {{the merging of}} international comparative datasets. This project creates conventions and a library of functions so that it becomes easier and faster to <b>merge</b> <b>time</b> series datasets, incorporate updates, make sure observations are consistent across years, conserve N and encourage reproducible research...|$|E
40|$|We {{show that}} the decay of a soliton into {{vortices}} provides a mechanism for measuring the initial phase difference between two merging Bose-Einstein condensates. At very low temperatures, the mechanism is resonant, operating only when the clouds start in anti-phase. But at higher temperatures, phase fluctuations trigger vortex production {{over a wide range}} of initial relative phase, as observed in recent experiments at MIT. Choosing the <b>merge</b> <b>time</b> to maximize the number of vortices created makes the interferometer highly sensitive to spatially varying phase patterns and hence atomic movement. Comment: 5 pages, 5 figure...|$|E
40|$|Two-dimensional particle-in-cell {{simulation}} in a cylindrical geometry {{shows that}} the vortex formation and merging of a magnetically confined pure electron column are controllable with rotating-wall electric fields. With an optimized frequency, the vortex <b>merging</b> <b>time</b> can be extended longer than that without rotating fields. close 5...|$|R
40|$|We {{study the}} degree to which non-radiative gas {{dynamics}} affects the merger histories of haloes along with subsequent predictions from a semi-analytic model (SAM) of galaxy formation. To this aim, we use a sample of dark matter only and non-radiative SPH simulations of four massive clusters. The presence of gas-dynamical processes (e. g. ram-pressure from the hot ICM) makes haloes more fragile in the runs which include gas. This results in a 25 per cent decrease in the total number of subhaloes at z = 0. The impact on the galaxy population predicted by SAMs is complicated by the presence of "orphan" galaxies, i. e. galaxies whose parent substructures are reduced below the resolution limit of the simulation. In the model employed in our study, these galaxies survive for a residual <b>merging</b> <b>time</b> that is computed using a variation of the Chandrasekhar formula. Due to ram-pressure stripping, haloes in gas simulations tend to be less massive than their counterparts in the dark matter simulations. The resulting <b>merging</b> <b>times</b> for satellite galaxies are then longer in these simulations. On the other hand, the presence of gas influences the orbits of haloes making them on average more circular and therefore reducing the estimated <b>merging</b> <b>times</b> with respect to the dark matter only simulation. This effect is particularly significant for the most massive satellites and is (at least in part) responsible for the fact that brightest cluster galaxies in runs with gas have stellar masses which are about 25 per cent larger than those obtained from dark matter only simulations. Our results show that gas-dynamics has only a marginal impact on the statistical properties of the galaxy population, but that its impact on the orbits and <b>merging</b> <b>times</b> of haloes strongly influences the assembly of the most massive galaxies. Comment: 13 pages, 12 figures, to appear in MNRA...|$|R
30|$|Monthly mean {{data from}} 43 ground {{stations}} {{located in the}} northern hemisphere and equipped with Dobson spectrophotometers {{were used for the}} comparison with the individual satellite instruments and the new SNNs <b>merged</b> <b>time</b> series. The monthly means from each ground station were compared with the corresponding monthly means from the 1 ° × 1 °gridded satellite data.|$|R
40|$|The {{elapsed time}} for {{external}} mergesort is nor-mally dominated by I/O time. This paper {{is focused on}} reducing I/O time during the merge phase. Three new buffering and read-ahead strategies are proposed, called equal buffering, extended forecasting and clustering. They exploit the fact that virtually all mod-ern disks perform caching and sequential read-ahead. The latter two also collect information during run formation (the last key of each run block) which is then used to preplan read-ing. For random input data, extended fore-casting and clustering were found to reduce <b>merge</b> <b>time</b> by 30 % compared with traditional double buffering. Clustering exploits any tem-poral skew in input runs to further {{reduce the number of}} seeks...|$|E
30|$|For SSSP and {{connected}} components, {{the behavior of}} iiHadoop in different stages {{is similar to that}} for PageRank algorithm; therefore, the performance improvement is also the same. The data loading time is affected by the size of data. These algorithms need less time to load data compared to PageRank since the size of their datasets is less than that of PageRank as shown in Table 1. For k-means, the shuffle and reduce stages cannot benefit from the above improvements since the implementation of k-means needs to shuffle the static data in each iteration which increases the shuffle time as Hadoop. In addition, the total re-computation in incremental k-means increases the <b>merge</b> <b>time</b> in reduce stage and as a result leads to a large increase in the runtime of the reduce phase.|$|E
40|$|Abstract. Merge sort {{is useful}} in sorting {{a great number of}} data pro-gressively, {{especially}} when they can be partitioned and easily collected to a few processors. Merge sort can be parallelized, however, conventional algorithms using distributed memory computers have poor performance due to the successive reduction of the number of participating processors by a half, up to one in the last merging stage. This paper presents load-balanced parallel merge sort where all proces-sors do the merging throughout the computation. Data are evenly dis-tributed to all processors, and every processor is forced to work in all merging phases. An analysis shows the upper bound of the speedup of the <b>merge</b> <b>time</b> as (P − 1) / logP where P is the number of processors. We have reached a speedup of 8. 2 (upper bound is 10. 5) on 32 -processor Cray T 3 E in sorting of 4 M 32 -bit integers. ...|$|E
40|$|Time series {{data capture}} crop growth {{dynamics}} and {{are some of}} the most effective data sources for crop mapping. However, a drawback of precise crop classification at medium resolution (30 m) using multi-temporal data is that some images at crucial time periods are absent from a single sensor. In this research, a medium-resolution, 15 -day time series was obtained by merging Landsat- 5 TM and HJ- 1 CCD data (with similar radiometric performances in multi-spectral bands). Subsequently, optimal temporal windows for accurate crop mapping were evaluated using an extension of the Jeffries–Matusita (JM) distance from the <b>merged</b> <b>time</b> series. A support vector machine (SVM) was then used to compare the classification accuracy of the optimal temporal windows and the entire time series. In addition, different training sample sizes (10 % to 90 % of the entire training sample in 10 % increments; five repetitions for each sample size) were used to investigate the stability of optimal temporal windows. The results showed that time series in optimal temporal windows can achieve high classification accuracies. The optimal temporal windows were robust when the training sample size was sufficiently large. However, they were not stable when the sample size was too small (i. e., less than 300) and may shift in different agro-ecosystems, because of different classes. In addition, <b>merged</b> <b>time</b> series had higher temporal resolution and were more likely to comprise the optimal temporal periods than time series from single-sensor data. Therefore, the use of <b>merged</b> <b>time</b> series increased the possibility of precise crop classification...|$|R
5000|$|Castle Rock Entertainment - {{purchased}} in 1993 by Turner Broadcasting System; TBS <b>merged</b> with <b>Time</b> Warner in 1996 ...|$|R
5000|$|AOL was a Time Warner spin-off; this {{effectively}} was a demerger, as AOL {{had previously}} <b>merged</b> into <b>Time</b> Warner.|$|R
40|$|The Viterbi-Algorithm (VA) is {{a common}} {{application}} of dynamic programming. Since it contains a nonlinear feedback loop (ACS-feedback, ACS: add-compare-select), this loop is the bottleneck in high data rate implementations. In this paper we show that asymptotically the ACS-feedback no longer has to be processed recursively, i. e. there is no feedback, resulting in negligible performance loss. This can be exploited to derive purely feedforward architectures for Viterbi decoding, such that a modular cascadable implementation results. By designing one cascadable module, any speedup can be achieved simply by adding modules to the implementation. It is shown that optimization criteria, e. g. minimum latency or maximum hardware efficiency, are met by very different architectures. be seen that they merge into a unique path, the optimum one. The survivor depth D is then defined as that depth {{in which it is}} highly probable that all paths <b>merge</b> (<b>time</b> k-D). In a practical implementation of the VA, called Viterbi decoder (VD), this allows the decoded transition to be given out with latency D. The computation of the best path to each node of the trellis is achieved through dynamic programming by calculating a path metric yi,k for each state Si at every time instant k according to the "ACS-recursion" v s. : yi,k+l = ma. ximum (,. ̇ y,k + 'j,k) V j+i which for the simple example Fig. 1 leads to 1...|$|E
40|$|Concepts of Markov chains mixing, {{the study}} of the {{convergence}} to stationarity, emerged three decades ago. Studying times to convergence of Markov chains is crucial as it ties to many other mathematical areas, such as Markov Chain Monte Carlo, a method of sampling from a given probability distribution. The purpose of this thesis is to study the long term behavior of time-inhomogeneous Markov chains. We analyze under what conditions they converge, in what sense they converge and what the rate of convergence should be. A Markov chain is a random process with the memoryless property: the next state only depends on the current state, and not on the sequence of events that preceded it. Time-inhomogeneous Markov chains refer to chains with different transition probability matrices at each step. What makes them interesting is that they don't necessarily have stationary distributions. Instead of comparing the chain to the stationary distribution, we look at the distance between two distributions started at different initial states. We refer to the time until the two distributions get sufficiently close as <b>merge</b> <b>time.</b> As a foundation for our simulations and proofs, we first show the convergence theorem for time-inhomogeneous Markov chains with a sufficient assumption. We then study the various ways of perturbing the random walk on the n-cycle, by forcing the random walker to move in a certain direction with higher probability if it is at a particular site. Changing perturbations at every step results in different one-step transition kernels throughout the chain, therefore making the chain time-inhomogeneous. We then compare the merge times, {{as a function of the}} number of states n, to those of the unperturbed time-homogeneous simple random walk on the n-cycle. One of the perturbations represents the case in which the random walker has a varying probability of staying put at a particular site at every step. Simulations show that the merge times for this perturbed chain is almost identical to those of the unperturbed chains. We are able to show this result by proving an explicit bound on the hitting times. Honors Thesis, Duke University Mathematics Departmen...|$|E
5000|$|TBS <b>merged</b> with <b>Time</b> Warner in 1996. From October 2006, MGM Television began distributing New Line's {{films and}} {{television}} series.|$|R
50|$|Bombay Courier was Bombay's first English {{newspaper}} to be printed in 1777 by Rustomji Kashaspathi.It was later <b>merged</b> with <b>Times</b> of India in 1861.|$|R
5000|$|Time Warner, 1989-present (Warner <b>merged</b> with <b>Time</b> Inc.; from 2000 to 2003, {{the parent}} company was known as AOL Time Warner, {{following}} merger with AOL) ...|$|R
5000|$|New Line Cinema - {{purchased}} in 1994 by Turner Broadcasting System; TBS <b>merged</b> with <b>Time</b> Warner in 1996; New Line merged with Warner Bros. in 2008 ...|$|R
50|$|Again in 1970 {{the school}} <b>merged,</b> this <b>time</b> with Crozer Theological Seminary, the Baptist school from Upland, Pennsylvania where the Rev. Dr. Martin Luther King, Jr. studied.|$|R
50|$|Adolph Ochs became {{proprietor}} {{and editor}} of the Times in 1901. In the following year he purchased the Philadelphia Public Ledger and <b>merged</b> the <b>Times</b> into his new acquisition.|$|R
5000|$|In 1994, PBS {{moved to}} {{distribution}} through Turner Home Entertainment. In 1997, when Turner Home Entertainment's parent company <b>merged</b> with <b>Time</b> Warner, distribution was through Warner Home Video until 2004.|$|R
5000|$|Kenkoro is an {{amalgamation}} of {{a number}} of different unions that have <b>merged</b> over <b>time.</b> They include the [...] (Tetsudō Honbu), which was formerly the National Railway Locomotive Engineers' Union (Zendoro).|$|R
5000|$|The Selznick International Pictures library (excluding Gone {{with the}} Wind, which was {{acquired}} by Metro-Goldwyn-Mayer in 1944, and eventually by Turner Entertainment Co. in 1986; Turner <b>merged</b> with <b>Time</b> Warner in 1996) ...|$|R
5000|$|Boomj is {{a social}} {{networking}} site targeted at those born between 1946 and 1965, {{commonly referred to as}} [...] "Baby Boomers". In 2007, BOOMj <b>merged</b> with <b>Time</b> Lending California, a real estate company.|$|R
40|$|International audienceCurrent quality source-adaptive {{schemes for}} {{multicast}} multilayered video rely on merging capabilities at special nodes {{in the network}} {{as a means of}} combining feedback from the whole set of receivers. These strategies reduce network load and avoid feedback implosion at the source. In this paper, we examine how to provide optimal feedback for such schemes. The optimal feedback is achieved when state information from the whole set of receivers is represented in every incoming feedback packet at the source. We show that the choice of a suitable <b>merging</b> <b>time</b> window in the intermediate nodes coupled with a periodical transmission of feedback packets by the receivers leads to near-optimal feedback...|$|R
40|$|Multi-year {{time series}} from data loggers in five cinder cones on the Mauna Kea summit plateau, Hawaii, {{collected}} 2012 - 2016. Variables measured are ground temperature, air temperature, and humidity. Study sites are Puu Wekiu, Puu Hau Kea, Puu Waiau, Puu Pohaku, and Puu Makanaka. The reduced data are <b>merged</b> <b>time</b> series without time gaps and corrected for known issues. The raw data are downloads from HOBO data loggers. It is recommended {{to use the}} reduced data instead of the raw data. A list of data loggers with time periods and sensor depths is provided in loggers_summary_mk. csv. For further information and file formats, see README. TXT. For context, see references...|$|R
50|$|Double Elimination Tribal Council: For {{the third}} {{consecutive}} season, this twist had returned, which occurred just before the <b>merge.</b> This <b>time,</b> the winning tribe would join the losing tribe in voting off another castaway from the latter tribe.|$|R
50|$|Many of the {{specific}} functions of today's DEC began as tasks carried out by individual commissions or agencies created for those specific purposes. These smaller entities <b>merged</b> over <b>time</b> to create today's department, which was officially created in 1970.|$|R
50|$|Baol was ethnically a Wolof kingdom, but it {{included}} communities of Serer-Safen and other Serer groups. The {{social and political}} systems were basically {{the same as those}} of Cayor. In fact, the kingdoms <b>merged</b> from <b>time</b> to time for mutual defense.|$|R
50|$|A {{cascading}} discontinuity set {{is a term}} {{related to}} Wild Cards and applied in foresight and risk management areas. It attempts to define a series of smaller, seemingly disconnected events that <b>merge</b> over <b>time</b> leading to a Wild Card-like result.|$|R
