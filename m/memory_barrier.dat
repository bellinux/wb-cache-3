39|71|Public
25|$|All editions (except Starter edition) are {{currently}} available in both 32-bit and 64-bit versions. The biggest {{advantage of the}} 64-bit version is breaking the 4gigabyte <b>memory</b> <b>barrier,</b> which 32-bit computers cannot fully access.|$|E
5000|$|... #Subtitle level 3: Compile-time <b>memory</b> <b>barrier</b> {{implementation}} ...|$|E
5000|$|Some compilers support builtins that emit {{hardware}} <b>memory</b> <b>barrier</b> instructions: ...|$|E
5000|$|... #Subtitle level 4: Compiler {{support for}} {{hardware}} <b>memory</b> <b>barriers</b> ...|$|R
5000|$|Weak {{consistency}} (reads {{and writes}} are arbitrarily reordered, {{limited only by}} explicit <b>memory</b> <b>barriers)</b> ...|$|R
5000|$|Multithreaded {{programs}} usually use synchronization primitives {{provided by}} a high-level programming environment, such as Java and [...]NET Framework, or an application programming interface (API) such as POSIX Threads or Windows API. Synchronization Primitives such as mutexes and semaphores are provided to synchronize access to resources from parallel threads of execution. These primitives are usually implemented with the <b>memory</b> <b>barriers</b> required to provide the expected memory visibility semantics. In such environments explicit use of <b>memory</b> <b>barriers</b> is not generally necessary.|$|R
5000|$|... a single-reader single-writer {{ring buffer}} FIFO, {{with a size}} which evenly divides the {{overflow}} {{of one of the}} available unsigned integer types, can unconditionally be implemented safely using only a <b>memory</b> <b>barrier</b> ...|$|E
50|$|All editions (except Starter edition) are {{currently}} available in both 32-bit and 64-bit versions. The biggest {{advantage of the}} 64-bit version is breaking the 4 gigabyte <b>memory</b> <b>barrier,</b> which 32-bit computers cannot fully access.|$|E
5000|$|On later {{implementations}} of the x86 architecture, spin_unlock {{can safely}} use an unlocked MOV {{instead of the}} slower locked XCHG. This is due to subtle memory ordering rules which support this, even though MOV is not a full <b>memory</b> <b>barrier.</b> However, some processors (some Cyrix processors, some revisions of the Intel Pentium Pro (due to bugs), and earlier Pentium and i486 SMP systems) will do the wrong thing and data protected by the lock could be corrupted. On most non-x86 architectures, explicit <b>memory</b> <b>barrier</b> or atomic instructions (as in the example) must be used. On some systems, such as IA-64, there are special [...] "unlock" [...] instructions which provide the needed memory ordering.|$|E
40|$|Abstractâ€”This report {{explores the}} way LLVM generates the <b>memory</b> <b>barriers</b> {{needed to support}} the C 11 /C++ 11 atomics for ARM. I measure the {{influence}} of <b>memory</b> <b>barriers</b> on performance, and I show {{that in some cases}} LLVM generates too many barriers. By leaving these barriers out, performance increases significantly. I introduce two LLVM passes, which will remove these extra barriers, improving performance in my test by 40 %. I believe one of these passes is ready to be upstreamed to LLVM, while the other will need more testing...|$|R
50|$|<b>Memory</b> <b>barriers</b> are {{typically}} used when implementing low-level machine code that operates on memory shared by multiple devices. Such code includes synchronization primitives and lock-free data structures on multiprocessor systems, and device drivers that communicate with computer hardware.|$|R
50|$|The {{hardware}} level requires atomic operations such as Test-and-set, Fetch-and-add, Compare-and-swap, or Load-Link/Store-Conditional, {{together with}} <b>memory</b> <b>barriers.</b> Portable operating systems cannot simply block interrupts to implement synchronization, since hardware that lacks actual concurrent execution such as hyper-threading or multi-processing is now extremely rare.|$|R
5000|$|Some architectures, {{including}} the ubiquitous x86/x64, provide several <b>memory</b> <b>barrier</b> instructions including an instruction sometimes called [...] "full fence". A full fence ensures that all load and store operations {{prior to the}} fence will have been committed prior to any loads and stores issued following the fence. Other architectures, such as the Itanium, provide separate [...] "acquire" [...] and [...] "release" [...] memory barriers which address the visibility of read-after-write operations {{from the point of}} view of a reader (sink) or writer (source) respectively. Some architectures provide separate memory barriers to control ordering between different combinations of system memory and I/O memory. When more than one <b>memory</b> <b>barrier</b> instruction is available it is important to consider that the cost of different instructions may vary considerably.|$|E
5000|$|A write {{barrier in}} a garbage {{collector}} is {{a fragment of}} code emitted by the compiler immediately before every store operation to ensure that (e.g.) generational invariants are maintained. A write barrier in a memory system, {{also known as a}} <b>memory</b> <b>barrier,</b> is a hardware-specific compiler intrinsic that ensures that all preceding memory operations [...] "happen before" [...] all subsequent ones.|$|E
5000|$|... rcu_assign_pointer (...) : The updater {{uses this}} {{function}} to assign a new value to an RCU-protected pointer, {{in order to}} safely communicate the change in value from the updater to the reader. This function returns the new value, and also executes any <b>memory</b> <b>barrier</b> instructions required for a given CPU architecture. Perhaps more importantly, it serves to document which pointers are protected by RCU.|$|E
50|$|For high-performance, {{low-level}} work, communicating between threads {{is sometimes}} needed without the overhead of mutexes. This is done using atomic operations on memory locations. These can optionally specify the minimum memory visibility constraints needed for an operation. Explicit <b>memory</b> <b>barriers</b> {{may also be}} used for this purpose.|$|R
40|$|The {{semantics}} of Java multithreading dictates {{all possible}} behaviors that a multithreaded Java program can exhibit on any platform. This {{is called the}} Java Memory Model (JMM) and describes the allowed reorderings among the memory operations in a thread. However, multiprocessor platforms traditionally have memory consistency models of their own. In this paper, we study {{the interaction between the}} JMM and the multiprocessor memory consistency models. In particular, <b>memory</b> <b>barriers</b> may have to be inserted to ensure that the multiprocessor execution of a multithreaded Java program respects the JMM. We study the impact of these additional <b>memory</b> <b>barriers</b> on program performance. Our experimental results indicate that the performance gain achieved by relaxed hardware memory consistency models far exceeds the performance degradation due to the introduction of JMM. 1...|$|R
5000|$|Dependent loads can be reordered (this {{is unique}} for Alpha). If the {{processor}} fetches a pointer to some data after this reordering, {{it might not}} fetch the data itself but use stale data which it has already cached and not yet invalidated. Allowing this relaxation makes cache hardware simpler and faster but leads to the requirement of <b>memory</b> <b>barriers</b> for readers and writers.|$|R
50|$|A <b>memory</b> <b>barrier,</b> {{also known}} as a membar, memory fence or fence {{instruction}}, is a type of barrier instruction that causes a central processing unit (CPU) or compiler to enforce an ordering constraint on memory operations issued before and after the barrier instruction. This typically means that operations issued prior to the barrier are guaranteed to be performed before operations issued after the barrier.|$|E
50|$|Generally, {{there are}} <b>memory</b> <b>barrier</b> {{operations}} available on platforms (which are exposed in C++11) {{that should be}} preferred instead of volatile as they allow the compiler to perform better optimization and more importantly they guarantee correct behaviour in multi-threaded scenarios; neither the C specification (before C11) nor the C++ specification (before C++11) specifies a multi-threaded memory model, so volatile may not behave deterministically across OSes/compilers/CPUs).|$|E
50|$|Memory {{barriers}} are low-level primitives {{and part of}} an architecture's memory model, which, like instruction sets, vary considerably between architectures, {{so it is not}} appropriate to generalize about <b>memory</b> <b>barrier</b> behavior. The conventional wisdom is that using memory barriers correctly requires careful study of the architecture manuals for the hardware being programmed. That said, the following paragraph offers a glimpse of some memory barriers which exist in contemporary products.|$|E
40|$|So what possessed CPU {{designers}} to {{cause them to}} inflict <b>memory</b> <b>barriers</b> on poor unsuspecting SMP software designers? In short, because reordering memory references allows much better performance, and so <b>memory</b> <b>barriers</b> are needed to force ordering in things like synchronization primitives whose correct operation depends on ordered memory references. Getting a more detailed {{answer to this question}} requires a good understanding of how CPU caches work, and especially what is required to make caches really work well. The following sections: 1. present the structure of a cache, 2. describe how cache-coherency protocols ensure that CPUs agree on the value of each location in memory, and, finally, 3. outline how store buffers and invalidate queues help caches and cache-coherency protocols achieve high performance. We will see that <b>memory</b> <b>barriers</b> are a necessary evil that is required to enable good performance and scalability, an evil that {{stems from the fact that}} CPUs are orders of magnitude faster than are both the interconnects between them and the memory they are attempting to access. 1 Cache Structure Modern CPUs are much faster than are modern memory systems. A 2006 CPU might be capable of executing ten instructions per nanosecond, but will require many tens of nanoseconds to fetch a data item from main memory. This disparity in speed â€” more than two orders of magnitude â€” has resulted in the multimegabyte caches found on modern CPUs. These caches are associated with the CPUs as shown in Figure 1, and can typically be accessed in a few cycles. ...|$|R
50|$|Each API or {{programming}} environment in principle {{has its own}} high-level memory model that defines its memory visibility semantics. Although programmers do not usually need to use <b>memory</b> <b>barriers</b> in such high level environments, {{it is important to}} understand their memory visibility semantics, to the extent possible. Such understanding is not necessarily easy to achieve because memory visibility semantics are not always consistently specified or documented.|$|R
50|$|Houses {{similar to}} Claire's own, these houses are located {{throughout}} Morganville. They {{are connected to}} each other through Ada, Myrnin's invention that keeps up <b>memory</b> <b>barriers</b> in town (later replaced by Frank collins, Shane's father). Amelie often makes her appearances in these houses in the early novels. Houses {{referred to in the}} novels include the Glass house, the Day house, and Claire's parents house.|$|R
50|$|Memory-mapped I/O is {{the cause}} of memory {{barriers}} in older generations of computers, which are unrelated to <b>memory</b> <b>barrier</b> instructions. The 640 KB barrier is due to the IBM PC placing the Upper Memory Area in the 640-1024 KB range within its 20-bit memory addressing. The 3 GB barrier and PCI hole are manifestations of this with 32-bit memory addressing; with 64-bit memory addressing these are usually no longer problems on newer architectures.|$|E
50|$|The 2 GB limit {{refers to}} a {{physical}} <b>memory</b> <b>barrier</b> for a process running on a 32-bit operating system, which can only use a maximum of 2 GB of memory. The problem mainly affects 32-bit versions of operating systems like Microsoft Windows and Linux, although some variants of the latter can overcome this barrier. It {{is also found in}} servers like FTP servers or embedded systems like Xbox. The use of Physical Address Extension (PAE) can help overcome this barrier.|$|E
50|$|<b>Memory</b> <b>barrier</b> {{instructions}} address reordering effects only at {{the hardware}} level. Compilers may also reorder instructions {{as part of the}} program optimization process. Although the effects on parallel program behavior can be similar in both cases, in general it is necessary to take separate measures to inhibit compiler reordering optimizations for data that may be shared by multiple threads of execution. Note that such measures are usually necessary only for data which is not protected by synchronization primitives such as those discussed in the prior section.|$|E
50|$|As a result, <b>memory</b> <b>barriers</b> are required. A store barrier will flush {{the store}} buffer, {{ensuring}} all writes {{have been applied}} to that CPU's cache. A read barrier will flush the invalidation queue, thus ensuring that all writes by other CPUs become visible to the flushing CPU. Furthermore, memory management units do not scan the store buffer, causing similar problems. This effect is already visible in single threaded processors.|$|R
50|$|On {{most modern}} uniprocessors memory {{operations}} are not executed {{in the order}} specified by the program code. In single threaded programs all operations {{appear to have been}} executed in the order specified, with all out-of-order execution hidden to the programmer - however in multi-threaded environments (or when interfacing with other hardware via memory buses) this can lead to problems. To avoid problems <b>memory</b> <b>barriers</b> can be used in these cases.|$|R
50|$|<b>Memory</b> <b>barriers</b> are {{necessary}} because most modern CPUs employ performance optimizations {{that can result}} in out-of-order execution. This reordering of memory operations (loads and stores) normally goes unnoticed within a single thread of execution, but can cause unpredictable behaviour in concurrent programs and device drivers unless carefully controlled. The exact nature of an ordering constraint is hardware dependent and defined by the architecture's memory ordering model. Some architectures provide multiple barriers for enforcing different ordering constraints.|$|R
50|$|Since the caches {{intermediate}} accesses {{to memory}} addresses, data written to different addresses may reach the peripherals' memory or registers {{out of the}} program order, i.e. if software writes data to an address and then writes data to another address, the cache write buffer does not guarantee that the data will reach the peripherals in that order. It {{is the responsibility of the}} software to include <b>memory</b> <b>barrier</b> instructions after the first write, to ensure that the cache buffer is drained before the second write is executed.|$|E
50|$|Most modern CPUs reorder {{memory accesses}} to improve {{execution}} efficiency (see memory ordering for types of reordering allowed). Such processors invariably give {{some way to}} force ordering in a stream of memory accesses, typically through a <b>memory</b> <b>barrier</b> instruction. Implementation of Peterson's and related algorithms on processors which reorder memory accesses generally requires use of such operations to work correctly to keep sequential operations from happening in an incorrect order. Note that reordering of memory accesses can happen even on processors that don't reorder instructions (such as the PowerPC processor in the Xbox 360).|$|E
50|$|A thread {{block is}} a {{programming}} abstraction {{that represents a}} group of threads that can be executing serially or in parallel. For better process and data mapping, threads are grouped into thread blocks. The number of threads varies with available shared memory. 'The number of threads in a thread block is also limited by the architecture {{to a total of}} 512 threads per block.' The threads in the same thread block run on the same stream processor. Threads in the same block can communicate with each other via shared <b>memory,</b> <b>barrier</b> synchronization or other synchronization primitives such as atomic operations.|$|E
40|$|Background: Rapid {{evolutions}} in {{sequencing technology}} force read mappers into flexible adaptation to longer reads, changing error models, <b>memory</b> <b>barriers</b> and novel applications. Results: ALFALFA achieves a high performance in accurately mapping long single-end and paired-end reads to gigabase-scale reference genomes, while remaining competitive for mapping shorter reads. Its seed-and-extend workflow is underpinned by fast retrieval of super-maximal exact matches from an enhanced sparse suffix array, with flexible parameter tuning to balance performance, memory footprint and accuracy. Conclusions: ALFALFA is open source and available a...|$|R
40|$|This {{document}} describes several reference-counting disciplines {{used in the}} Linux kernel, {{and concludes}} by summarizing the memory-barrier, atomicinstruction, and compiler-control required by each. This material is adapted from a tutorial document, so the alert reader may notice a few departures from the typical standards-document style. These disciplines show ample precedent for specifying that a given variable should have atomic response to normal loads and stores, and for the ability to separately specify atomic operations, <b>memory</b> <b>barriers,</b> and disabling of compiler optimizations in uses of variables. ...|$|R
50|$|Modern {{programming}} languages like Java therefore {{implement a}} memory model. The memory model specifies synchronization barriers that are established via special, well-defined synchronization operations such as acquiring a lock by entering a synchronized block or method. The memory model stipulates that {{changes to the}} values of shared variables only need to be made visible to other threads when such a synchronization barrier is reached. Moreover, the entire notion of a race condition is defined over the order of operations with respect to these <b>memory</b> <b>barriers.</b>|$|R
