28|192|Public
5000|$|... dmesg (display message or driver message) is {{a command}} on most Unix-like {{operating}} systems that prints the <b>message</b> <b>buffer</b> of the kernel. The output of this command typically contains the messages {{produced by the}} device drivers.|$|E
50|$|The CANpie API {{supports}} {{the concept of}} hardware message buffers (mailboxes) with a total limit of 255 buffers. A <b>message</b> <b>buffer</b> has a unique direction (receive or transmit). As an option {{it is possible to}} connect a FIFO with arbitrary size to a <b>message</b> <b>buffer</b> for both transfer directions. The total number of CAN channels is limited to 255, the API provides a method to gather information about the features of each CAN hardware channel. This is especially important for an application designer who wants to write the code only once. The CAN frame time-stamping (specified by CiA 603, CAN Frame time-stamping - Requirements for network time management) is supported with a resolution of 1 nano-second.|$|E
5000|$|When a {{buffered}} channel {{has been}} filled to its capacity (sending is [...] "capacity" [...] number of outputs ahead of receiving inputs), the default {{behavior of the}} channel is to become synchronous, and the sender will block on the next sending. Observe {{that there is no}} common <b>message</b> <b>buffer</b> shared between channels. Increasing complexity, as compared to using a channel as unidirectional and point to point, it is possible to share channels between multiple receivers or multiple senders, and to merge independent data-streams into a single shared channel. From this follows that a single channel may also be used for bidirectional communication.|$|E
50|$|SMS-COMMAND {{may be used}} {{to query}} for a <b>message</b> <b>buffered</b> in the SMSC, to modify its {{parameters}} or to delete it.|$|R
5000|$|For short {{messages}} (fewer than 256 bytes) the kernel copies the <b>message</b> <b>buffers</b> between processes, {{from the}} address {{space of the}} sending process to the system address space, {{and from there to}} the receiving process' address space.|$|R
40|$|Racial inequalities in the {{education}} system are {{an issue that has}} yet to be adequately addressed. Given how discriminatory experiences adversely impact African American students, it is important to understand how their educational attitudes are impacted and ways that students can be protected from these harmful experiences. The study aims to answer six research questions: 1) How does racial discrimination predict African American college students’ value placed in education? 2) How does racial discrimination predict African American college students’ expectations for success? 3) How do preparation for bias messages predict the value they place in education? 4) How do preparation for bias messages predict African American college students’ expectations for success? 5) Do preparation for bias <b>messages</b> <b>buffer</b> the effect of racial discrimination on value placed in education? 6) Do preparation for bias <b>messages</b> <b>buffer</b> the effect of racial discrimination on expectations for success...|$|R
5000|$|The Chatterbox {{is similar}} to an IRC channel. It is also nicknamed the catbox. It appears as a panel {{on the right side}} of the page that logged-in users can use to read conversations and {{participate}} in them. The site's administrators used to have the ability to [...] "borg" [...] - prevent from using the Chatterbox or message system - those users whose behavior violated the unwritten standards of politeness and decorum. This was done through a bot called EDB (short for [...] "Everything Death Borg"), which announced when it had [...] "swallowed" [...] a user. This silencing lasted for five minutes, though persistent trolls were silenced for a longer period - sometimes permanently. , the EDB was no longer much used, only making mostly token appearances for humorous effect. Noders who consistently cause trouble (usually by trolling) can be silenced permanently and can be forbidden from noding altogether, though this is rarely done. This would be initiated by a chanops, (A staff member with a + by his or her username that monitors potential abuse [...] ). There is also a utility called 'chatterlight', which provides the chatlog / <b>message</b> <b>buffer</b> with a larger portion of the screen.|$|E
40|$|Determination {{of message}} {{stability}} {{is important for}} multicast group communication systems, both for assuring applications that messages have been delivered and also for <b>message</b> <b>buffer</b> management. We present a protocol for determining message stability that uses a single scalar timestamp to acknowledge messages from many sources. The protocol avoids the linear growth in the acknowledgment size that occurs with vector acknowledgment protocols. Compared to other protocols, the protocol consumes significantly less network bandwidth, and its latency to the determination of message stability is only slightly larger. Synchronized physical clocks are shown to yield lower latency than logical clocks. We also present a simple connection establishment and group membership protocol for use {{in conjunction with the}} message stability protocol. Key words: <b>Message</b> <b>buffer</b> mangagement, group communication, message stability, timestamp acknowledgment 1 Introduction Message stability is an important conc [...] ...|$|E
40|$|The {{throughput}} {{performance of}} a TDMA channel with finite buffer capacity for transmitting data messages is considered. Each station has limited <b>message</b> <b>buffer</b> capacity and has Poisson message arrivals. Message arrivals will be blocked if the buffers are congested. Using the embedded Markov chain model, the solution procedure for the limiting system-size probabilities is presented in a recursive fashion. Numerical examples are given to demonstrate the tradeoffs between the blocking probabilities and the buffer sizing strategy...|$|E
5000|$|... {{support for}} {{buffered}} operation modes where <b>messages</b> are <b>buffered</b> locally if the receiver {{is not ready}} ...|$|R
40|$|International audienceCompatibility is {{a crucial}} problem that is {{encountered}} while constructing new software by reusing and composing existing components. A set of software components is called compatible if their composition preserves certain properties, such as deadlock freedom. However, checking compatibility for systems communicating asynchronously is an undecidable problem, and asynchronous communication is a common interaction mechanism used in building software systems. A typical approach in analyzing such systems is to bound the state space. In this paper, we take a different approach and do not impose any bounds {{on the number of}} participants or the sizes of the <b>message</b> <b>buffers.</b> Instead, we present a sufficient condition for checking compatibility of a set of asynchronously communicating components. Our approach relies on the synchronizability property which identifies systems for which interaction behavior remains the same when asynchronous communication is replaced with synchronous communication. Using the synchronizability property, we can check the compatibility of systems with unbounded <b>message</b> <b>buffers</b> by analyzing only a finite part of their behavior. We have implemented a prototype tool to automate our approach and we have applied it to many examples...|$|R
3000|$|Non-durability The Follower {{responses}} the Leader immediately when {{it receives}} the log <b>message</b> and <b>buffers</b> the log record in memory.|$|R
40|$|We propose an {{efficient}} buffer management method for Cachet [7], called BCachet. Cachet is an adaptive cache coherence protocol {{based on a}} mechanism-oriented memory model called Commit-Reconcile & Fences (CRF) [1]. Although Cachet is theoretically proved to be sound and live, a direct implementation of Cachet is not feasible because it requires too expensive hardware. We greatly reduced the hardware cost for buffer management in BCachet without chang-ing the memory model and the adaptive nature of Cachet. Hardware cost for the incoming <b>message</b> <b>buffer</b> of the memory site is greatly reduced from PxN FIFOs to two FIFOs in BCachet where P {{is the number of}} sites and N is the number of address lines in a memory unit. We also reduced the minimum size of suspended <b>message</b> <b>buffer</b> per memory site from (log 2 P+V) xPxrqma, to log 2 P where V {{is the size of a}} memory block in terms of bits and rqma is the maximum number of request messages per cache. BCachet has three architectural merits. First, BCachet separates buffer management units for deadlock avoidance and those units for livelock avoidance so that a designer ha...|$|E
40|$|We {{describe}} a scalable incomplete boundedness {{test for the}} communication buffers in UML RT models. UML RT is {{a variant of the}} UML modeling language, tailored to describing asynchronous concurrent embedded systems. We reduce UML RT models to systems of communicating finite state machines (CFSMs). We propose a series of further abstractions that leaves us with a system of linear inequalities. Those represent the message sending and receiving effect that the control flow cycles of every process have on the overall <b>message</b> <b>buffer.</b> The test tries to establish the existence of a linear combination of the effect vectors so that at least one message can occur an unbounded number of times. We discuss the complexity of this test and present experimental results using the IBOC system that we are implementing. Scalability of the test is in part {{due to the fact that}} it is polynomial for the type of sparse control flow graphs that are derived from UML RT models. Also, the analysis is local, i. e., it avoids the combinatorial state space explosion due to concurrency of the models. We also present a method to derive upper bound estimates for the maximal occupancy of each individual <b>message</b> <b>buffer.</b> While we focus on the analysis of UML RT models, the analysis can directly be applied to any type of CFSM models...|$|E
40|$|The author {{discusses}} the {{close relationship between}} data and operations and suggests that a compiler {{should be able to}} check that data structures are accessed by meaningful procedures only. This idea leads to the introduction of shared classes—a programming notation for the monitor concept. The notation is illustrated by a <b>message</b> <b>buffer</b> for concurrent processes. We will discuss the close relationship between data and operations and use it to define a very important form of resource protection. If we consider variables of primitive types such as integer and boolean,it is quite possible that values of different types will be represented by identical bit strings at the machine level. For example both the boolean value true and the integer value 1 might be represented by the bit string 000 [...] . 001 in single machine words. So data of different types are distinguished not only by the representation of their values, but also by the operations associated with the types. An integer, for example, is a datum subject only to arithmetic operations, comparisons, and assignments involving other data subject to the same restrictions. Now consider structured types. Take for example a variable that represents a <b>message</b> <b>buffer</b> which contains a sequences of messages sent, but not yet received. A static picture of process communication can be defined b...|$|E
40|$|In modern cluster systems, {{message passing}} {{functionality}} is often offloaded {{to the network}} interface card for efficiency reasons. However, this limits the amount of memory available for <b>message</b> <b>buffers.</b> Unfortunately, buffer insufficiency can cause an otherwise correct program to deadlock, or at least slow down. Hence, given a program trace from an execution in an unrestricted environment, determining the minimum number of buffers needed for a safe execution is an important problem. We present three [...] ...|$|R
40|$|This paper {{described}} {{improvements to}} the abstract interprocess communication features added to VHDL {{as part of the}} SUAVE language design. Channel type declarations are extended to allow specification of bounded <b>message</b> <b>buffers.</b> This allows the designer to choose between asynchronous or synchronous message passing semantics. The latter makes models more amenable to formal verification based on state-space exploration. The language is also extended to allow specification of timeout intervals in select statements. This change makes the language more widely applicable, including for description of telecommunication protocols...|$|R
40|$|The {{main focus}} {{of this paper is}} to define the {{operational}} semantics for the message passing strategy called Asynchronous Message Passing System (AMPS) used in the distributed programming language, LIPS (Language for Implementing Parallel/distributed Systems). AMPS is a point-to-point message passing system that does not use any <b>message</b> <b>buffers.</b> It is based on simple architecture and interfaces. In order to adequately provide implementation information for the message passing strategy, we have defined the operational semantics and the codes needed for the abstract machine of LIPS...|$|R
40|$|Keywords—Wireless sensor networks, medium access pro-tocol, energy efficiency, time {{division}} multiple access. Abstract—In this paper {{we present a}} novel TDMA-based medium access control (MAC) protocol for wireless sensor networks. Unlike conventional MAC protocols which func-tion independently of the application, we introduce an Adap-tive, Information-centric and Lightweight MAC(AI-LMAC) protocol that adapts its operation depending on the require-ments of the application. We also present a completely lo-calised data management framework that helps capture in-formation about traffic patterns in the network. This infor-mation is subsequently used by AI-LMAC to modify its op-eration accordingly. We present preliminary results showing how the MAC protocol efficiently manages the issues of fair-ness, latency and <b>message</b> <b>buffer</b> management. I...|$|E
40|$|Performance {{analysis}} of the ABySS genome sequence assembler (ABYSS-P) executing on the K computer with up to 8192 compute nodes is described which identified issues that limited scalability to less than 1024 compute nodes and required prohibitive <b>message</b> <b>buffer</b> memory with 16384 or more compute nodes. The open-source Scalasca toolset was employed to analyse executions, revealing the impact of massive amounts of MPI point-to-point communication used particularly for master/worker process coordination, and inefficient parallel file operations that manifest as waiting time at later MPI collective synchronisations and communications. Initial remediation via use of collective communication operations and alternate strategies for parallel file handling show large performance and scalability improvements, with partial executions validated on the full 82, 944 compute nodes of the K computer...|$|E
40|$|In Promela, {{communication}} buffers {{are defined}} with a fixed length, and buffer overflows {{can be handled}} in two different ways: block the send statement or lose the message. Both solutions change the semantics of the system, compared to one with unbounded channels. The question arises, if such buffer overflows can ever occur in a given system and what buffer lengths are sufficient to avoid them. We describe a scalable incomplete boundedness test for the communication buffers in Promela models, {{which is based on}} overapproximation and static analysis. We first reduce Promela models to systems of communicating finite state machines (CFSMs) and then apply further abstractions that leave us with a system of linear inequalities. Those represent the message sending and receiving effect that the control flow cycles of every process have on any <b>message</b> <b>buffer.</b> The test tries to establish the existence of a linear combination of the effect vectors so that at least one message can occur an unbounded number of times. If no such linear combination exists then the system is bounded. We discuss the complexity of this test and present experimental results using our implementation in the IBOC system. Scalability of the test is in part {{due to the fact that}} it is polynomial for the type of sparse control flow graphs derived from Promela models. Also, the analysis is local, i. e., it avoids the combinatorial state space explosion due to concurrency of the models. We also present a method to derive upper bound estimates for the maximal occupancy of each individual <b>message</b> <b>buffer.</b> Previously, we have applied this approach to UML RT models, while in this paper we focus on the additional problems specific to Promela code: determining the potential message types of any chan [...] ...|$|E
40|$|A {{method for}} {{communicating}} data between peripheral devices and an embedded processor that includes receiving, at a data buffer {{unit of the}} embedded processor, the data from a peripheral device. The method also includes copying data from the data buffer unit into the bridge buffer of the embedded processor as a bridge <b>buffer</b> <b>message.</b> Additionally, the method includes creating, after storing the data as a bridge <b>buffer</b> <b>message,</b> a peripheral device message comprising the bridge <b>buffer</b> <b>message,</b> and sending the peripheral device message to a thread message queue of a subscriber...|$|R
40|$|Several Java {{bindings}} of the Message Passing Interface standard, MPI, {{have been}} developed recently. <b>Message</b> <b>buffers</b> have usually been restricted to arrays with elements of primitive type. We discuss use of the Java object serialization model for marshalling general communication data in MPI. This approach is compared with a Java transcription of the standard MPI derived datatype mechanism. We describe an implementation of the mpiJava interface to MPI incorporating automatic object serialization. Benchmark {{results show that the}} current JDK implementation of serialization is (not unexpectedly) probably not fast enough for high performance applications. Means of solving this problem are discussed...|$|R
40|$|This paper {{presents}} a deadlock-free routeing algorithm for multiprocessor interconnection networks based on store-and-forward (S/F) communication. The adaptive {{nature of the}} method proposed encourages using light traffic paths. Furthermore it has the properties of avoiding blocked communication (deadlock), reducing communication delay time between source and destination, using efficiently <b>message</b> <b>buffers</b> as network resources {{and being able to}} control communication traffic flow from each processor of the network. The routeing algorithm has been implemented on a 64 -node transputer network (T-Rack) configured as a number of well known topologies to evaluate the behaviour of the algorithm and some performance figures have been derived...|$|R
40|$|Mechanisms for {{managing}} message buffers in Time Warp parallel simulations executing on cache-coherent shared-memory multiprocessors are studied. Two simple buffer management strategies called the sender pool and receiver pool mechanisms are examined {{with respect to}} their efficiency, and in particular, their interaction with multiprocessor cache-coherence protocols. Measurements of implementations on a Kendall Square Research KSR- 2 machine using both synthetic workloads and benchmark applications demonstrate that sender pools offer significant performance advantages over receiver pools. However, it is also observed that both schemes, especially the sender pool mechanism, are prone to severe performance degradations due to poor locality of reference in large simulations using substantial amounts of <b>message</b> <b>buffer</b> memory. A third strategy called the partitioned buffer pool approach is proposed that exploits the advantages of sender pools, but exhibits much better locality. Measurements of [...] ...|$|E
40|$|This paper {{presents}} {{the design and}} evaluation of the M-cache, a small, fast and intelligent memory for handling messages at the processing nodes of multicomputer systems. The M-cache is neither a conventional cache nor a <b>message</b> <b>buffer,</b> though it has some characteristics of both. It provides hardware support for the message search operation often performed in message-directed programming, a programming style inherent {{to the implementation of}} object-oriented paradigms on distributed computing systems. It also provides a mechanism for bandwidth matching between the interconnection network and local memory of a node. Through simulation experiments, we have studied the execution of concurrent algorithms on systems with and without M-caches to obtain relative speedup measures. The results show that a modest investment in silicon is sufficient to effect over an order of magnitude reduction in message-retrieval time. Such hardware support is needed to make the cost-effective implementation of [...] ...|$|E
40|$|Real time {{systems are}} {{characterized}} by high speed processing and throughput as well as asynchronous event processing requirements. These requirements give rise to particular implementations of parallel or pipeline multitasking structures, of intertask or interprocess communications mechanisms, and finally of <b>message</b> (<b>buffer)</b> routing or switching mechanisms. These mechanisms or structures, along with the data structue, describe the essential character of the system. These common structural elements and mechanisms are identified, their implementation {{in the form of}} routines, tasks or macros - in other words, tools are formalized. The tools developed support or make available the following: reentrant task creation, generalized message routing techniques, generalized task structures/task families, standardized intertask communications mechanisms, and pipeline and parallel processing architectures in a multitasking environment. Tools development raise some interesting prospects in the areas of software instrumentation and software portability. These issues are discussed following the description of the tools themselves...|$|E
50|$|Insertions, deletions and updates are {{inserted}} as <b>message</b> into <b>buffers</b> {{that make}} their way towards the leaves. The messaging infrastructure can be exploited to implement {{a variety of other}} operations, some of which are discussed below.|$|R
40|$|Abstract. This paper {{proposes a}} {{mechanism}} for simulating limited communication bandwidth and processing power available to an agent in multi-agent simulations. Although there exist dedicated tools able to simulate computer networks, most multi-agent platforms lack support {{for this kind of}} resource allocation. We target such multi-agent platforms and offer an easy method to implement the missing functionality by the agent designer. The introduced method assigns two additional <b>message</b> <b>buffers</b> to each agent, which are used to (i) limit the number of messages an agent is able to send in one simulation round, and (ii) limit the number of messages an agent is able to process in one simulation round. ...|$|R
40|$|Abstract. Analysis of {{worst-case}} message transmission {{times in}} CAN networks is usually performed assuming {{the availability of}} an infinite length priority queue of <b>message</b> <b>buffers</b> at the network adapter with zero access time. In reality, adapters provide {{a finite number of}} <b>buffers</b> for <b>message</b> transmission. This paper shows how to account for the availability of a limited number of buffers at the adapter and how to model the impossibility of performing preemption once a message has been copied into the adapter buffer and it is awaiting transmission. A new worst-case bound for message transmission is provided and evaluated with respect to the SAE benchmark. 1...|$|R
40|$|Generating good {{communication}} code is {{an important}} issue for all compilers targeting parallel or distributed systems. However, different compilers for the same parallel system usually implement the communication generation routines (e. g., <b>message</b> <b>buffer</b> packing) independently and from scratch. As a result, these compilers either pursue a simple approach (calling a standard runtime library), which does not do justice to the capabilities of the system, or they incur high development costs. This paper describes a way to separate the communication issues from other compilation aspects (e. g., determining the distribution of data and computation). This organization places the responsibility for communication issues with the communication backend, and this backend can be shared by different compilers. It produces code that is customized for each communication step, based on the exact data distribution and the characteristics of the target parallel system. This approach has several advantage [...] ...|$|E
40|$|Mobile IP {{is used to}} {{keep track}} of {{location}} information and make the data available to the mobile devices anytime, anywhere. Mobile IP has been widely accepted but lacks in providing seamless handoff. We have proposed a framework for wireless network that uses a flexible and adaptive mailbox-based scheme. In this scheme a mailbox associated with each mobile node while allowing de coupling between them. The FIFO <b>message</b> <b>buffer</b> of mailbox used to store incoming messages destined to a mobile node. Mailbox can be detached from its owner node {{in the sense that the}} mailbox can reside at a location different from the current location of the owner node. During handoff, mailbox of mobile node can itself decide whether it has to move from current mobility agent (home agent or foreign agent) to new mobility agent. A pull technique, MPUL (Message Pull) adopted to implement the message delivery from mailbox to its owner node. The performance tradeoff for various mobility conditions are evaluated using analytical model...|$|E
40|$|My {{research}} {{interest is}} broadly focused towards solving {{problems in the}} domain of large scale decentralized (communication) systems. Specifically, I am interested in structural and func-tional analysis of complex systems as well as designing distributed algorithms. In principle, I am curious about any complex system, with a special attention to the following- mobile ad hoc networks, wireless sensor networks, internet of things and computer networks. However, I am also interested in the computational social science as well as computational biology. Research Overview My PhD thesis is on understanding the dynamics of information dissemination in large scale decentralized systems through structural and functional analysis. The five specific problems addressed in this direction are- (1) Maximization of coverage of information dissemination in unstructured networks under constraint (2) Mathematical analysis {{of the structure of the}} projection of alphabetic bipartite networks (3) Structural analysis of intergroup networks (4) Analysis of information dissemination in <b>message</b> <b>buffer</b> augmented delay tolerant networks and (5) Analysis of spreading dynamics through indirect communication. A brief overview of each of the problems is provided in the following...|$|E
30|$|When a node meets another node, {{it sends}} the highest {{priority}} <b>messages</b> in the <b>buffer</b> during the contact.|$|R
40|$|An {{interesting}} {{feature of}} some recent parallel computers {{is the fact}} that the underlying transport mechanism behind the currently dominating message passing interfaces is based on a global address space model. By accessing this global address space directly most of the inherent delays for administering <b>message</b> <b>buffers</b> and queues can be avoided. Using this interface we have implemented a user level distributed shared memory layer using the virtual memory protection mechanisms of the operating system. The synchronisation required for maintaining the coherency of the memory is addressed by implementing a distributed shared lock which exploits the remote atomic store operations provided by the Meiko CS- 2. This allows an asynchronous style of pogramming where the load is dynamically distributed over the nodes of a parallel partition...|$|R
40|$|DTM, dynamic {{synchronous}} transfer mode, is a {{new time}} division multiplexing technique for fiber networks currently being developed and implemented at the Royal Institute of Technology in Stockholm, Sweden. This paper describes the hardware and software aspects of the design of an SBus host interface to the DTM network for a Sun SPARCstation. The interface {{is based on a}} dual port memory residing on the interface card and accesible over the SBus from the host CPU. The host operating system allocates <b>message</b> <b>buffers</b> directly in this memory. The interface has hardware support for segmenting and reassembling packets to and from the data units of the DTM. The software part of the interface manages the shared memory and the virtual circuits provided by the DTM network. ...|$|R
