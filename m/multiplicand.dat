177|25|Public
5|$|The machine's most {{significant}} innovation {{is generally considered}} to be its incorporation of index registers, commonplace on modern computers. The SSEM had included two registers, implemented as Williams tubes: the accumulator (A) and the program counter (C). As A and C had already been assigned, the tube holding the two index registers, originally known as B-lines, was given the name B. The contents of the registers could be used to modify program instructions, allowing convenient iteration through an array of numbers stored in memory. The Mark 1 also had a fourth tube, (M), to hold the <b>multiplicand</b> and multiplier for a multiplication operation.|$|E
25|$|Suppose for {{simplicity}} {{that the}} <b>multiplicand</b> has three digits. The first digit is the hundreds-digit, the middle digit is the tens-digit, and the last, rightmost, digit is the ones-digit. The multiplier {{only has a}} ones-digit. The ones-digits of the <b>multiplicand</b> and multiplier form a column: the ones-column.|$|E
25|$|Thus the {{designation}} of multiplier and <b>multiplicand</b> {{does not affect the}} result of the multiplication.|$|E
5000|$|The FOIL rule {{cannot be}} {{directly}} applied to expanding products {{with more than}} two <b>multiplicands,</b> or <b>multiplicands</b> with more than two summands. However, applying the associative law and recursive foiling allows one to expand such products. For instance,Alternate methods based on distributing forgo {{the use of the}} FOIL rule, but may be easier to remember and apply. For example, ...|$|R
50|$|A set {{consists}} of 10 rods corresponding to digits 0 to 9. The rod 0, {{although it may}} look unnecessary, is needed for multipliers or <b>multiplicands</b> having 0 in them.|$|R
25|$|Subtract {{the partial}} product {{resulting}} from the MSB (pseudo sign bit) instead of adding it like the other partial products. This method requires the <b>multiplicand's</b> sign bit to be extended by one position, being preserved during the shift right actions.|$|R
25|$|If the <b>multiplicand</b> has a hundreds-digit, {{find the}} product of the {{multiplier}} and the hundreds-digit of the <b>multiplicand,</b> and to this product add the carry digit if there is one. Then write the resulting sum of the hundreds-column under the line, also in the hundreds column. If the sum has two digits then write down the last digit of the sum in the hundreds-column and write the carry digit to its left: on the thousands-column.|$|E
25|$|When two {{numbers are}} multiplied {{together}}, {{the result is}} called a product. The two numbers being multiplied together are called factors, with <b>multiplicand</b> and multiplier also used.|$|E
25|$|Multiplication is {{the second}} basic {{operation}} of arithmetic. Multiplication also combines two numbers into a single number, the product. The two original numbers are called the multiplier and the <b>multiplicand,</b> sometimes both simply called factors.|$|E
40|$|Reducing power {{consumption}} prolongs battery life and increases integration. In digital CMOS designs, switching activity is closely {{connected with the}} total {{power consumption}}. Switching activity on programmable processors implementing linear filters, fast Fourier transforms, and other signal processing operations {{is dominated by the}} hardware multiplier. In this paper, we employ wordlength reduction of <b>multiplicands</b> to reduce switching activity in hardware multipliers using truncation and signed right shift methods. For 32 bit × 32 bit Wallace and Radix- 4 modified Booth multipliers, truncation by 16 bits achieves a 4 : 1 and 2 : 1 reduction, respectively, in switching activity, whereas signed right shift gives little or no reduction. The key contribution of this paper is the reduction of power consumption by altering <b>multiplicands</b> in software without any hardware modifications. 1...|$|R
40|$|In this {{supplementary}} document, we {{revisit the}} issue of non-bounding “majorants”. In Section 3. 2. 2 of the paper, we incor-rectly stated that negative <b>multiplicands,</b> which may arise with non-bounding majorants, prevent convergence of the residual ratio tracking estimator in Equation (5). It {{turns out that the}} estimator re-mains unbiased even with negative <b>multiplicands.</b> In the following, we use the recently presented integral formulation of null-collision algorithms [Galtier et al. 2013] to reason about the convergence of our (residual) ratio tracking with non-bounding “majorants”. The original delta tracking requires a bounding majorant. If this is violated, the “probabilities ” (defined w. r. t. the majorant) of col-liding with a real particle or a fictitious particle become greater than 1 or negative, respectively. 1 Fortunately, the choice of these probabilities is not constrained; they can be set to arbitrary values provided that these still represent valid probabilities and the relativ...|$|R
50|$|As an example, let's {{consider}} the multiplication of 58 with 213. After writing the <b>multiplicands</b> on the sides, consider each cell, {{beginning with the}} top left cell. In this case, the column digit is 5 and the row digit is 2. Write their product, 10, in the cell, with the digit 1 above the diagonal and the digit 0 below the diagonal (see picture for Step 1).|$|R
25|$|Then {{comes the}} tens-column. The tens-column so far {{contains}} only one digit: the tens-digit of the <b>multiplicand</b> (though it might contain a carry digit under the line). Find {{the product of}} the multiplier and the tens-digits of the <b>multiplicand.</b> Then, if there is a carry digit (superscripted, under the line and in the tens-column), add it to this product. If the resulting sum is less than ten then write it in the tens-column under the line. If the sum has two digits then write its last digit in the tens-column under the line, and carry its first digit over to the next column: in this case the hundreds column.|$|E
25|$|Next, the tens-column. The tens-digit of the <b>multiplicand</b> is 2, the {{multiplier}} is 3, {{and three}} times two is six. Add the carry-digit, 2, to the product, 6, to obtain 8. Eight has only one digit: no carry-digit, so write in the tens-column under the line. You can erase the two now.|$|E
25|$|Consider a {{multiplication}} {{where one}} of the factors has multiple digits, whereas the other factor has only one digit. Write down the multi-digit factor, then write the single-digit factor under the last digit of the multi-digit factor. Draw a horizontal line under the single-digit factor. Henceforth, the multi-digit factor will be called the <b>multiplicand,</b> and the single-digit factor will be called the multiplier.|$|E
50|$|Older {{multiplier}} architectures {{employed a}} shifter and accumulator to sum each partial product, often one partial product per cycle, trading off speed for die area. Modern multiplier architectures use the Baugh - Wooley algorithm, Wallace trees, or Dadda multipliers {{to add the}} partial products together in a single cycle. The performance of the Wallace tree implementation is sometimes improved by modified Booth encoding {{one of the two}} <b>multiplicands,</b> which reduces the number of partial products that must be summed.|$|R
50|$|It follows that, for {{sufficiently}} large n, Karatsuba's algorithm {{will perform}} fewer shifts and single-digit additions than longhand multiplication, {{even though its}} basic step uses more additions and shifts than the straightforward formula. For small values of n, however, the extra shift and add operations may make it run slower than the longhand method. The point of positive return depends on the computer platform and context. As a rule of thumb, Karatsuba is usually faster when the <b>multiplicands</b> are longer than 320-640 bits.|$|R
40|$|In this {{investigation}} {{we have developed}} a block cipher called modern advanced Hill cipher including a pair of involutory matrices as <b>multiplicands,</b> and involving a set of functions such as Mix(), Substitute() and Permute(). In addition to these functions, we have a pair of transformations, namely, modular arithmetic addition and XORoperation. All these functions and transformations are introduced in each round of the iteration process. The cryptanalysis carried out in this analysis clearly indicates that this cipher {{is a very strong}} one and it cannot be broken by any cryptanalytic attack...|$|R
25|$|If the <b>multiplicand</b> {{does not}} have a hundreds-digit then if there is no carry digit then the {{multiplication}} algorithm has finished. If there is a carry digit (carried over from the tens-column) then write it in the hundreds-column under the line, and the algorithm is finished. When the algorithm finishes, the number under the line is the product of the two numbers.|$|E
2500|$|Say {{one wants}} to find {{the product of the}} numbers 3 and 729. Write the single-digit {{multiplier}} under the multi-digit <b>multiplicand,</b> with the multiplier under the ones-digit of the <b>multiplicand,</b> like so: ...|$|E
2500|$|The {{multiplication}} {{of whole}} numbers may be thought as a repeated addition; that is, the multiplication of two numbers {{is equivalent to}} adding as many copies of one of them, the <b>multiplicand,</b> as {{the value of the}} other one, the multiplier. Normally, the multiplier is written first and <b>multiplicand</b> second, (though this can vary by language.) ...|$|E
40|$|In this {{investigation}} {{we have developed}} a procedure for the encryption of an image by applying modern advanced Hill Cipher including a pair of involutory matrices as <b>multiplicands</b> {{and a set of}} functions. Firstly we have obtained an encrypted image of a gray level image. Then this analysis is extended to an RGB color image. Here {{it is interesting to note}} that the encrypted image of the gray level image and the encrypted image of the color image do not have any resemblance with their corresponding original images. This fact ensures security of images in an effective manner. ...|$|R
40|$|This thesis {{presents}} a new architecture for a parallel multiplier. For large words, both multiplication time and area required are large when conventional methods are used. In this thesis, an architecture is discussed to multiply large words {{by means of}} overlapped multi-bit scanning. This technique can be applied, without {{significant change in the}} conventional architecture, to achieve great improvement in overall performance. New multiplier architectures with a minimum time area product can be detected using the method discussed for a CSA tree. An efficient technique is presented to generate negative multiples of <b>multiplicands</b> required in most o...|$|R
50|$|With a yupana {{as the one}} {{designed}} by Poma de Ayala {{can not be represented}} every <b>multiplicands,</b> but it is necessary to extend the yupana vertically (adding rows) to represent numbers whose sum of digits exceeds 5. The same thing goes for the multipliers: to represent all the numbers is necessary to extend the number of columns. It should be emphasized that this interpretation, apart the supposed error calculation (or representation by the designer), {{is the only one that}} identifies in the yupana of Poma de Ayala a mathematical and consistent message (multiplication) and not a series of random numbers as in other interpretations.|$|R
2500|$|The {{numbers to}} be multiplied are {{generally}} called the [...] "factors". The number to be multiplied {{is called the}} [...] "multiplicand", {{while the number of}} times the <b>multiplicand</b> is to be multiplied comes from the [...] "multiplier". Usually the multiplier is placed first and the <b>multiplicand</b> is placed second, however sometimes the first factor is the <b>multiplicand</b> and the second the multiplier. Additionally, there are some sources in which the term [...] "multiplicand" [...] is regarded as a synonym for [...] "factor". In algebra, a number that is the multiplier of a variable or expression (e.g., the 3 in 3xy2) is called a coefficient.|$|E
2500|$|No digits of the <b>multiplicand</b> {{have been}} left unmultiplied, so the {{algorithm}} finishes, and ...|$|E
2500|$|Next, the hundreds-column. The hundreds-digit of the <b>multiplicand</b> is 7, {{while the}} {{multiplier}} is 3. The product of 3 and 7 is 21, {{and there is}} no previous carry-digit (carried over from the tens-column). The product 21 has two digits: write its last digit in the hundreds-column under the line, then carry its first digit over to the thousands-column. Since the <b>multiplicand</b> has no thousands-digit, then write this carry-digit in the thousands-column under the line (not superscripted): ...|$|E
5000|$|The {{method for}} general {{multiplication}} {{is a method}} to achieve multiplications [...] with low space complexity, i.e. as few temporary results as possible {{to be kept in}} memory.This is achieved by noting that the final digit is completely determined by multiplying the last digit of the <b>multiplicands.</b> This is held as a temporary result. To find the next to last digit, we need everything that influences this digit: The temporary result, the last digit of [...] times the next-to-last digit of , as well as the next-to-last digit of [...] times the last digit of [...] This calculation is performed, and we have a temporary result that is correct in the final two digits.|$|R
40|$|Abstract—For the {{improvement}} of the Phase-Mode parallel multiplier, we propose to use a Booth encoder as a substitute of an AND array. Booth’s algorithm is often used for generations of partial products. The scale of the encoder does not matter for defining its operation frequency because the Phase-Mode Booth encoder is a pipelined structure. We suggest that the encoder is used as a serial encoder {{to reduce the number of}} Josephson junctions (JJ). There are two methods for applying the Booth encoder to the current structure. The first method is shifting <b>multiplicands.</b> The second method is shifting partial products and complementary signals. The total JJ’s in both methods are less than the AND array in large scale. The Phase-Mode Booth encoder with 2. 5 kA/cm 2 Nb/AlOx/Nb junctions can operate over 30 GHz according to the numerical simulations...|$|R
40|$|We present {{methods to}} {{generate}} systematically the hard-est test cases for multiplication, division, and square root subject to directed rounding, essentially extending previous work on number-theoretic floating-point testing to rounding modes other than to-nearest. The algorithms focus upon the rounding {{boundaries of the}} modes truncate, to-minus-infinity, and to-infinity, and programs based on them require little beyond exact arithmetic in the working precision to create billions of edge cases. We will show {{that the amount of}} work required to calculate trial <b>multiplicands</b> pays off in the form of free extra tests due to an interconnection among the operations considered herein. Although these tests do not replace proofs of correctness, they can be used to gain a high degree of confidence that the accuracy requirements as mandated by IEEE Standard 754 have been satisfied. Index terms: arithmetic testing, IEEE Standard 754, rounding functions, Hensel lifting, hyperSPAR...|$|R
2500|$|First part. Start {{with the}} ones-column. The <b>multiplicand</b> is 789 and the ones-multiplier is 5. Perform the {{multiplication}} {{in a row}} under the line: ...|$|E
2500|$|Then the tens-column. The <b>multiplicand</b> is 789 and the tens-multiplier is 4. Perform the {{multiplication}} in the tens-row, {{under the}} previous subproduct in the ones-row, but shifted one column to the left: ...|$|E
2500|$|Next, the hundreds-column. The <b>multiplicand</b> is {{once again}} 789, and the hundreds-multiplier is 3. Perform the {{multiplication}} in the hundreds-row, under the previous subproduct in the tens-row, but shifted one (more) column to the left. Then draw a horizontal line under the hundreds-row: ...|$|E
40|$|In {{this paper}} we will {{classify}} all the minimal quadratic algorithms for computing one bilinear form and for computing the coefficients of (S = 0 n x i l i) (S = 0 n y i l i) where n q where q - 2 {{is the number}} of elements of the field. Key Words : Polynomial multiplication, quadratic algorithms, finite fields, linear recurring sequences, Hankel matrices. 1. INTRODUCTION In infinite fields it is possible to compute the coefficients of the product of two polynomials of degree n in 2 n + 1 non-scalar multiplications. It is known that each algorithm for computing the above product in 2 n + 1 non-scalar multiplications must evaluate the <b>multiplicands</b> at minimum 2 n distinct points, multiply the samples, and interpolate the results. However in finite fields this method fails, if 2 n exceeds the number of field elements. In this paper we classify all the minimal quadratic algorithms for computing one bilinear form and for computing the product of two polynomials of degree n when [...] ...|$|R
40|$|Abstract — We {{introduce}} a technique for establishing and amplifying gaps between parameters of network coding and index coding problems. The technique uses linear programs to establish separations between combinatorial and coding-theoretic parameters and applies hypergraph lexicographic products to amplify these separations. This entails combining the dual solutions of the lexicographic <b>multiplicands</b> and proving {{that this is}} a valid dual solution of the product. Our result is general enough to apply to a large family of linear programs. This blend of linear programs and lexicographic products gives a recipe for constructing hard instances in which the gap between combinatorial or coding-theoretic parameters is polynomially large. We find polynomial gaps in cases in which the largest previously known gaps were only small constant factors or entirely unknown. Most notably, we show a polynomial separation between linear and non-linear network coding rates. This involves exploiting a connection between matroids and index coding to establish a previously unknown separation between linear and nonlinear index coding rates. We also construct index coding problems with a polynomial gap between the broadcast rate and the trivial lower bound for which no gap was previously known. 1...|$|R
40|$|Fundamental and {{the core}} of all the Digital Signal Processors (DSPs) are its {{multipliers}} and speed of the DSPs is mainly determined by the speed of its multipliers. Multiplication is the most fundamental operation with intensive arithmetic computations. Two important parameters associated with multiplication algorithms performed in DSP applications are latency and throughput. Latency is the “real delay of computing a function”. Throughput {{is a measure of}} “how many computations can be performed in a given period of time”. The execution time of most DSP algorithms is dependent on its multipliers, and hence need for high speed multiplier arises. Urdhva tiryakbhyam sutra performs faster for small inputs and Nikhilam sutra for larger inputs. Here a novel Integrated Vedic multiplier architecture, which by itself selects the appropriate multiplication sutra based on the inputs, is proposed. So depending on inputs, whichever sutra is faster, that sutra is selected by the proposed integrated Vedic multiplier architecture. In the simulation results, {{it can be seen that}} Urdhva performs faster for small inputs, but Nikhilam performs better for large inputs (more than twice as much for 64 bit <b>multiplicands)</b> ...|$|R
