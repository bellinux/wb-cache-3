0|427|Public
40|$|Publicado em "Proceedings of the World Congress on Engineering 2014, vol. 1. ISBN 978 - 988 - 19252 - 7 - 5 "The work {{presented}} here compares {{the performance of}} indoor positioning systems suitable for low power wireless sensor networks. Map <b>matching,</b> approximate <b>positioning</b> (<b>weighted</b> centroid) and exact positioning algorithms (least squares) were tested and compared in a small predefined indoor environment. We found that, for our test scenario, weighted centroid algorithms provided the best results. Least squares proved to be completely unreliable when using distances obtained by a propagation model. Major improvements in the positioning error were found when body influence {{was removed from the}} test scenario. Fundação para a Ciência e a Tecnologia (FCT...|$|R
40|$|This work {{compares the}} {{performance}} of indoor positioning systems suitable for low power wireless sensor networks. The research goal is to study positioning techniques that are compatible with real-time positioning in wireless sensor networks, having low-power and low complexity as requirements. Map <b>matching,</b> approximate <b>positioning</b> (<b>weighted</b> centroid) and exact positioning algorithms (least squares) were tested and compared in a small predefined indoor environment. We found that, for our test scenario, weighted centroid algorithms provide better results than map matching. Least squares proved to be completely unreliable when using distances obtained by the one-slope propagation model. Major improvements in the positioning error were found when body influence {{was removed from the}} test scenario. The results show that the positioning error can be improved if the body effect in received signal strength is accounted for in the algorithms. Helder D. Silva is supported by the Portuguese Foundation for Science and Technology under the grant SFRBD/ 78018 / 2011. info:eu-repo/semantics/publishedVersio...|$|R
40|$|A {{long-range}} (96 h â 120 h) <b>weighted</b> <b>position</b> consensus for {{tropical cyclone}} tracks is evaluated for 24 western North Pacific storms in 2006. The first <b>weighted</b> <b>position</b> technique simply weights the 96 -h, 108 -h, and 120 -h dynamical model positions inversely to their distances from the 60 -h, 66 -h, and 72 -h consensus <b>positions.</b> The second <b>weighted</b> consensus technique {{uses the same}} weighting factors but {{is applied to the}} forecast motion vectors to assess 96 h â 120 h track errors. The <b>weighted</b> <b>position</b> consensus yields modest reductions in error relative to an unweighted position consensus at 96 h â 120 h and produces smoother track forecasts. <b>Weighted</b> <b>position</b> consensus errors are reduced when the COAMPS model and the Air Force Weather Agency MM 5 model are removed from the unweighted consensus used to form the weighting factors. Including the Japan and ECMWF model tracks also improves the <b>weighted</b> <b>position</b> consensus performance. The weighted motion vector consensus achieves dramatic improvements over an unweighted position consensus (9. 9 % at 96 h and 5. 6 % at 120 h). Most of the improvement over an unweighted position consensus is from using a motion vector consensus rather than a position consensus since large improvements are also achieved with an unweighted motion vector consensus. US Air Force (USAF) author...|$|R
50|$|Therefore, tournament NRR can {{alternatively}} {{be thought}} of as the weighted average of the run rates scored in each <b>match</b> (<b>weighted</b> by the lengths of the innings batted compared to the other innings batted), minus the weighted average of the run rates conceded in each <b>match</b> (<b>weighted</b> by the lengths of the innings bowled compared to the other innings bowled). Each time another match is played, the weights of the previous innings reduce, and so the contributions of the previous innings to overall NRR reduce.|$|R
2500|$|If {{the mass}} {{distribution}} is continuous with the density ρ(r) within a solid Q, then the integral of the <b>weighted</b> <b>position</b> coordinates {{of the points}} in this volume relative {{to the center of}} mass R over the volume V is zero, that is ...|$|R
50|$|The NRR in {{a single}} game is the average runs per over that a team scores, minus the average runs per over that is scored against them. The NRR in a tournament is the average runs per over that a team scores across the whole tournament, minus the average runs per over that is scored against them across the whole tournament. This {{is the same as}} the {{weighted}} average of the run rates scored in each <b>match</b> (<b>weighted</b> by the lengths of the innings batted compared to the other innings batted), minus the weighted average of the run rates conceded in each <b>match</b> (<b>weighted</b> by the lengths of the innings bowled compared to the other innings bowled). This is not usually the same as the total or average of the NRRs from the individual matches in the tournament.|$|R
2500|$|In physics, {{the center}} of mass of a {{distribution}} of mass in space is the unique point where the <b>weighted</b> relative <b>position</b> of the distributed mass sums to zero, or the point where if a force is applied it moves {{in the direction of}} the force without rotating. The distribution of mass is balanced around {{the center of}} mass and the average of the <b>weighted</b> <b>position</b> coordinates of the distributed mass defines its coordinates. [...] Calculations in mechanics are often simplified when formulated with respect to the center of mass.|$|R
5000|$|The date of {{the match}} - more recent <b>matches</b> are <b>weighted</b> more heavily ...|$|R
25|$|The {{center of}} mass is the unique point {{at the center of}} a {{distribution}} of mass in space that has the property that the <b>weighted</b> <b>position</b> vectors relative to this point sum to zero. In analogy to statistics, the {{center of mass}} is the mean location of a distribution of mass in space.|$|R
50|$|If {{the mass}} {{distribution}} is continuous with the density ρ(r) within a solid Q, then the integral of the <b>weighted</b> <b>position</b> coordinates {{of the points}} in this volume relative {{to the center of}} mass R over the volume V is zero, that isSolve this equation for the coordinates R to obtainwhere M is the total mass in the volume.|$|R
5000|$|... 4. Verify that {{covariates}} are balanced across {{treatment and}} comparison {{groups in the}} <b>matched</b> or <b>weighted</b> sample ...|$|R
50|$|The Bashforth screens {{were made}} with several threads and series {{connected}} switches. A projectile passing through a screen would break one or more threads, the broken thread caused a switch to momentarily (about 20 ms) interrupt a current as the switch arm moved from its <b>weighted</b> <b>position</b> to its unweighted position, and the momentary interruption would be recorded on a paper chart.|$|R
30|$|In this section, we {{show that}} the {{algorithm}} from [19] can be easily generalized to find a <b>weighted</b> k-clique <b>matching</b> (for any k≥ 2) that is at most a factor k off from the maximum. Before we provide pseudo-code for this algorithm, we first present a sequential algorithm by Preis [22] that computes a 1 / 2 -approximation of the <b>weighted</b> <b>matching.</b> A high-level explanation of this algorithm will help us gain intuition about how the self-stabilizing algorithms for <b>weighted</b> <b>matching</b> and <b>weighted</b> k-clique <b>matching</b> work.|$|R
40|$|The <b>weighted</b> <b>matching</b> {{problem is}} to find a <b>matching</b> in a <b>weighted</b> graph that has maximum weight. The fastest known {{algorithm}} for this problem has running time O(nm + n 2 log n). Many real world problems require graphs of such large size that this running time is too costly. We present a linear time approximation algorithm for the <b>weighted</b> <b>matching</b> problem with a performance ratio of 2 3 performance ratio of 1 / 2...|$|R
40|$|Approximation {{algorithms}} {{have so far}} mainly {{been studied}} for problems that are not known to have polynomial time algorithms for solving them exactly. Here we propose an approximation algorithm for the <b>weighted</b> <b>matching</b> problem in graphs which can be solved in polynomial time. The <b>weighted</b> <b>matching</b> problem {{is to find a}} matching in an edge weighted graph that has maximum weight. The first polynomial time algorithm for this problem was given by Edmonds in 1965. The fastest known algorithm for the <b>weighted</b> <b>matching</b> problem has a running time of O(nm+n 2 log n). Many real world problems require graphs of such large size that this running time is too costly. Therefore there is considerable need for faster approximation algorithms for the <b>weighted</b> <b>matching</b> problem. We present a linear time approximation algorithm for the <b>weighted</b> <b>matching</b> problem with a performance ratio arbitrarily close to 2 /...|$|R
50|$|The {{assignment}} problem {{seeks to}} find a <b>matching</b> in a <b>weighted</b> bipartite graph that has maximum weight. Maximum weighted matchings {{do not have to}} be stable, but in some applications a maximum <b>weighted</b> <b>matching</b> is better than a stable one.|$|R
40|$|A new {{approximation}} algorithm {{for maximum}} <b>weighted</b> <b>matching</b> in general edge-weighted graphs is presented. It calculates a matching {{with an edge}} weight of at least 1 / 2 of the edge weight of a maximum <b>weighted</b> <b>matching.</b> Its time complexity is O(|E|), with |E| being the number of edges in the graph. This improves over the previously known 1 / 2 -approximation algorithms for maximum <b>weighted</b> <b>matching</b> which require O(|E| log(|V|)) steps, where |V| {{is the number of}} vertices...|$|R
40|$|Wattenhofer [WW 04] derive a {{complicated}} distributed algorithm to compute a <b>weighted</b> <b>matching</b> of an arbitrary weighted graph, {{that is at}} most a factor 5 away from the maximum <b>weighted</b> <b>matching</b> of that graph. We show that {{a variant of the}} obvious sequential greedy algorithm [Pre 99], that computes a <b>weighted</b> <b>matching</b> at most a factor 2 away from the maximum, is easily distributed. This yields the best known distributed approximation algorithm for this problem so far...|$|R
40|$|In {{this paper}} we study the {{generalized}} version of <b>weighted</b> <b>matching</b> in bipartite networks. Consider a <b>weighted</b> <b>matching</b> in a bipartite network {{in which the}} nodes derive value from the split of the matching edge assigned to them if they are matched. The value a node derives from the split depends both on the split {{as well as the}} partner the node is matched to. We assume that the value of a split to the node is continuous and strictly increasing in the part of the split assigned to the node. A stable <b>weighted</b> <b>matching</b> is a matching and splits on the edges in the matching such that no two adjacent nodes in the network can split the edge between them so that both of them can derive a higher value than in the matching. We extend the <b>weighted</b> <b>matching</b> problem to this general case and study the existence of a stable <b>weighted</b> <b>matching.</b> We also present an algorithm that converges to a stable <b>weighted</b> <b>matching.</b> The algorithm generalizes the Hungarian algorithm for bipartite matching. Faster algorithms can be made when there is more structure on the value functions...|$|R
40|$|We {{introduce}} {{and study}} online versions of <b>weighted</b> <b>matching</b> problems in metric spaces. We present a simple 2 k Γ 1 competitive algorithm for online minimum <b>weighted</b> bipartite <b>matching</b> where 2 k {{is the number}} of nodes. We show that this competitiveness is optimal. For online maximum matching, we prove that the greedy algorithm achieves an optimal competitive factor of 3. In contrast, we prove that the greedy algorithm performs exponentially poorly for online minimum matching. Key words. online algorithm, <b>matching,</b> <b>weighted</b> <b>matching,</b> competitiveness AMS(MOS) subject classifications. 68 P 05, 68 Q 25, 68 R 10, 68 R 05 1 Introduction The assignment problem, finding a bipartite matching of minimum weight, is one of the archetypical problems in algorithmic graph theory and in combinatorial optimization [2, 10]. We introduce a natural online version of this problem, which we call online min-matching. Let G be a complete bipartite graph with one bipartition designated as the server vertices, an [...] ...|$|R
40|$|Abstract. In this paper, {{we study}} {{distributed}} algorithms to compute a <b>weighted</b> <b>matching</b> that have constant (or at least sub-logarithmic) running {{time and that}} achieve approximation ratio 2 + ɛ or better. In fact we present two such synchronous algorithms, that work on arbitrary weighted trees. The first algorithm is a randomised distributed algorithm that computes a <b>weighted</b> <b>matching</b> of an arbitrary weighted tree, that approximates the maximum <b>weighted</b> <b>matching</b> by a factor 2 + ɛ. The running time is O(1). The second algorithm is deterministic, and approximates the maximum <b>weighted</b> <b>matching</b> by a factor 2 + ɛ, but has running time O(log ∗ |V |). Our algorithms {{can also be used}} to compute maximum unweighted matchings on regular and almost regular graphs within a constant approximation. ...|$|R
50|$|In physics, {{the center}} of mass of a {{distribution}} of mass in space is the unique point where the <b>weighted</b> relative <b>position</b> of the distributed mass sums to zero, or the point where if a force is applied it moves {{in the direction of}} the force without rotating. The distribution of mass is balanced around {{the center of}} mass and the average of the <b>weighted</b> <b>position</b> coordinates of the distributed mass defines its coordinates. Calculations in mechanics are often simplified when formulated with respect to the center of mass.It is a hypothetical point where entire mass of an object may be assumed to be concentrated to visualise its motion.In other words, the center of mass is the particle equivalent of a given object for application of Newton's laws of motion.|$|R
40|$|Abstract. Greedy graph {{matching}} {{provides us}} with a fast way to coarsen a graph during graph partitioning. Direct algorithms on the CPU which perform such greedy matchings are simple and fast, but offer few handholds for parallelisation. To remedy this, we introduce a fine-grained shared-memory parallel algorithm for maximal greedy matching, together with an implementation on the GPU, which is faster (speedups up to 6. 8 for random matching and 5. 6 for <b>weighted</b> <b>matching)</b> than the serial CPU algorithms and produces matchings of similar (random <b>matching)</b> or better (<b>weighted</b> <b>matching)</b> quality. ...|$|R
40|$|The maximum <b>weighted</b> <b>{{matching}}</b> {{problem is}} to find a maximum matching in a given graph such that the sum of weights of edges in it is maximum. In this paper, the concept of maximum random fuzzy <b>weighted</b> <b>matching</b> is proposed firstly, and then the maximum random fuzzy <b>weighted</b> <b>matching</b> problem is formulated as expected value model, chance-constrained programming and dependent-chance programming according to various decision criteria. Furthermore, a hybrid genetic algorithm is designed to solve the proposed random fuzzy programming models and finally a corresponding numerical example is presented...|$|R
40|$|This paper {{provides}} a framework for web implementation of the different matching algorithms for two way kidney paired donation (KPD). The first accept <b>match,</b> <b>weighted</b> Edmond‟s algorithm and optimized matching algorithm are {{used to test the}} matching process in KPD. The results of matching algorithms are obtained in terms of number of matches (transplants) that can be made between incompatible patient donor pairs. Also, currently in India, only cadaver transplant program (CTP) and live related donations are legally acceptable. Hence, this study indicates that the number of patients on waiting list can be enormously decreased, if KPD is legalized in India. ...|$|R
25|$|The {{location}} {{of the interaction between}} the gamma ray and the crystal can be determined by processing the voltage signals from the photomultipliers; in simple terms, the location can be found by weighting the position of each photomultiplier tube by the strength of its signal, and then calculating a mean <b>position</b> from the <b>weighted</b> <b>positions.</b> The total sum of the voltages from each photomultiplier, measured by a pulse height analyzer is proportional to the energy of the gamma ray interaction, thus allowing discrimination between different isotopes or between scattered and direct photons.|$|R
40|$|Abstract. Approximation {{algorithms}} {{have so far}} mainly {{been studied}} for problems that are not known to have polynomial time algorithms for solving them exactly. Here we propose an approximation algorithm for the <b>weighted</b> <b>matching</b> problem in graphs which can be solved in polynomial time. The <b>weighted</b> <b>matching</b> problem {{is to find a}} matching in an edge weighted graph that has maximum weight. The first polynomial time algorithm for this problem was given by Edmonds in 1965. The fastest known algorithm for the <b>weighted</b> <b>matching</b> problem has a running time of O(nm+n 2 log n). Many real world problems require graphs of such large size that this running time is too costly. Therefore there is considerable need for faster approximation algorithms for the <b>weighted</b> <b>matching</b> problem. We present a linear time approximation algorithm for the <b>weighted</b> <b>matching</b> problem with a performance ratio arbitrarily close to 2 1. This improves the previously best performance ratio of. Our 3 2 algorithm is not only of theoretical interest but because it is easy to implement and the constants involved are quite small it is also useful in practice...|$|R
40|$|In {{this paper}} we {{introduce}} the incremental assignment problem. In this problem, {{a new pair}} of vertices and their incident edges are added to a weighted bipartite graph whose maximum <b>weighted</b> <b>matching</b> is already known, and the maximum <b>weighted</b> <b>matching</b> of the extended graph is sought. We propose an O(|V | 2) algorithm for the problem...|$|R
40|$|AbstractIn many pattern {{matching}} applications the text has some properties attached to its various parts. Pattern Matching with Properties (Property Matching, for short), involves a string matching between the pattern and the text, and {{the requirement that}} the text part satisfies some property. Some immediate examples come from molecular biology where {{it has long been}} a practice to consider special areas in the genome by their structures. It is straightforward to do sequential matching in a text with properties. However, indexing in a text with properties becomes difficult if we desire the time to be output dependent. We present an algorithm for indexing a text with properties in O(nlog|Σ|+nloglogn) time for preprocessing and O(|P|log|Σ|+toccπ) per query, where n is the length of the text, P is the sought pattern, Σ is the alphabet, and toccπ is the number of occurrences of the pattern that satisfy some property π. As a practical use of Property Matching we show how to solve <b>Weighted</b> <b>Matching</b> problems using techniques from Property <b>Matching.</b> <b>Weighted</b> sequences have recently been introduced as a tool to handle a set of sequences that are not identical but have many local similarities. The weighted sequence is a “statistical image” of this set, where we are given the probability of every symbol’s occurrence at every text location. <b>Weighted</b> <b>matching</b> problems are {{pattern matching}} problems where the given text is weighted. We present a reduction from <b>Weighted</b> <b>Matching</b> to Property Matching that allows off-the-shelf solutions to numerous <b>weighted</b> <b>matching</b> problems including indexing, swapped matching, parameterized matching, approximate matching, and many more. Assuming that one seeks the occurrence of pattern P with probability ϵ in weighted text T of length n, we reduce the problem to a property matching problem of pattern P in text T′ of length O(n(1 ϵ) 2 log 1 ϵ) ...|$|R
40|$|Abstract. The node {{localization}} algorithms {{based on}} distance measurement are mainly studied in this paper. A stepwise <b>weighted</b> <b>positioning</b> algorithm based on distance measurement is designed {{on the basis}} of analyzing several typical positioning algorithms,static nodes positioning under natural environment is achieved. On this basis,with STMS 32 selected as a core chip in the paper,the basic system circuit and peripheral interface circuit of node device is designed,and then using the development software BeeKit and CodeWarrior for node software design,localization algorithm is testedthrough experiment. After analyzing the results,the algorithm is mostly influenced by the RSSI ranging error,the coarse positioning of node can be achieved...|$|R
40|$|In this paper, an {{algorithm}} {{for construction}} of multiple sets of two dimensional (2 D) or matrix unipolar (optical) orthogonal codes has been proposed. Representations of these 2 D codes in difference of positions representation (DoPR) have also been discussed along-with conventional <b>weighted</b> <b>positions</b> representation (WPR) of the code. This paper also proposes less complex methods for calculation of auto-correlation as well as cross-correlation constraints within set of matrix codes. The multiple sets of matrix codes provide flexibility for selection of optical orthogonal codes set in wavelength-hopping time-spreading (WHTS) optical {{code division multiple access}} (CDMA) system...|$|R
50|$|The Herfindahl {{index is}} also a widely used metrics for {{economic}} concentration. In portfolio theory, the Herfindahl index {{is related to the}} effective number of positions held in a portfolio. As above, this number is Neff = 1/H, where H is computed as the sum of the squares of the proportion of market value invested in each security. A low H-index implies a very diversified portfolio: as an example, a portfolio with H = 0.02 is equivalent to a portfolio with Neff=50 equally <b>weighted</b> <b>positions.</b> The H-index {{has been shown to be}} one of the most efficient measures of portfolio diversification.|$|R
40|$|We {{consider}} {{the problem of}} estimating {{the weight of a}} maximum <b>weighted</b> <b>matching</b> of a <b>weighted</b> graph G(V,E) whose edges are revealed in a streaming fashion. We develop a reduction from the maximum <b>weighted</b> <b>matching</b> problem to the maximum cardinality matching problem that only doubles the approximation factor of a streaming algorithm developed for the maximum cardinality matching problem. Our results hold for the insertion-only and the dynamic (i. e, insertion and deletion) edge-arrival streaming models. The previous best-known reduction is due to Bury and Schwiegelshohn (ESA 2015) who develop an algorithm whose approximation guarantee scales by a polynomial factor. As an application, we obtain improved estimators for weighted planar graphs and, more generally, for weighted bounded-arboricity graphs, by feeding into our reduction the recent estimators due to Esfandiari et al. (SODA 2015) and to Chitnis et al. (SODA 2016). In particular, we obtain a (48 +ϵ) -approximation estimator for the weight of a maximum <b>weighted</b> <b>matching</b> in planar graphs...|$|R
30|$|This paper focusses on the {{positioning}} {{part of the}} proposed joint communication and positioning system. Most positioning methods suffer from a bias introduced by multipath propagation. Multipath mitigation is, thus, an important issue. The proposed channel parameter estimator performs multipath mitigation in two ways: First, the maximum-likelihood estimator is able to take all relevant multipath components into account {{in order to minimize}} the modeling error. Second, soft information can be obtained for the parameter estimates. Soft information corresponds to the variance of an estimate and is a measure of reliability. This information can be exploited by a <b>weighted</b> <b>positioning</b> algorithm in order to improve the accuracy of the position estimate.|$|R
40|$|Abstract In many pattern {{matching}} applications the text has some properties attached to various of its parts. Pattern Matching with Properties (Property Matching, for short), involves a string matching between the pattern and the text, and {{the requirement that}} the text part satisfies some property. Some immediate ex-amples come from molecular biology where {{it has long been}} a practice to consider special areas in the genome by their structure. It is straightforward to do sequential matching in a text with properties. However, indexing in a text with properties becomes difficult if we desire the time to be output dependent. We present an algorithm forindexing a text with properties in O(n log jΣ j + n log log n) time for preprocessing and O(jP j log jΣ j + toccss) per query, where n is the length of the text, P is the sought pattern, Σ is the alphabet, and toccss isthe number of occurrences of the pattern that satisfy some property ss. As a practical use of Property Matching we show how to solve <b>Weighted</b> <b>Matching</b> problems using techniques from Property <b>Matching.</b> <b>Weighted</b> sequences have been recently introduced as a tool to handlea set of sequences that are not identical but have many local similarities. The weighted sequence is a &quot;statistical image &quot; of this set, where we are given the probability of every symbol's occurrence at every textlocation. <b>Weighted</b> <b>matching</b> problems are {{pattern matching}} problems where the given text is weighted. We present a reduction from <b>Weighted</b> <b>Matching</b> to Property Matching that allows off-the-shelf so-lutions to numerous <b>weighted</b> <b>matching</b> problems including indexing, swapped matching, parameterized matching, approximate matching, and many more. Assuming that one seeks the occurrence of pattern Pwith probability ffl in weighted text T of length n, we reduce the problem to a property matching problemof pattern P in text T 0 of length O(n (1 ffl) 2 log 1 ffl). 1 Introduction The original classic string matching problem of seeking all occurrences of a length m pattern string P ina lengt...|$|R
40|$|The ILM {{web server}} {{provides}} a web interface to two algorithms, iterated loop <b>matching</b> and maximum <b>weighted</b> <b>matching,</b> for efficiently predicting RNA secondary structures with pseudoknots. The algorithms can utilize either thermodynamic or comparative information or both, {{and thus can}} work on both aligned and individual sequences. Predicted secondary structures are presented in several formats compatible {{with a variety of}} existing visualization tools. The service can be accessed a...|$|R
