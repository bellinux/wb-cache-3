93|10000|Public
2500|$|On 24 April 2013, Australian Federal Police arrested 24-year-old Matthew Flannery of Point Clare, who boasted on Facebook [...] "I’m {{the leader}} of LulzSec". Flannery, who went by the {{username}} Aush0k, was arrested for the alleged hacking of the Narrabri Shire Council website on which homepage sexually explicit text and an image were left. On 27 August 2014, Flannery entered guilty pleas to five charges of making unauthorised <b>modification</b> <b>of</b> <b>data</b> to cause impairment, and dishonestly obtaining the Commonwealth Bank details of a woman. Flannery, who said the reference to LulzSec was a joke, lost his job of computer technician in a security company. On 16 October 2014, {{he was sentenced to}} 15 months of house arrest which continues until mid-April 2016, alongside a 12 months good behaviour bond.|$|E
50|$|Dynamic data {{authentication}} (DDA) provides protection against <b>modification</b> <b>of</b> <b>data</b> and cloning.|$|E
50|$|At core Mediation {{involves}} {{data transfer}} between various systems {{with or without}} <b>modification</b> <b>of</b> <b>data</b> starting from Network elements to OSS/BSS systems.|$|E
30|$|Tampering Unauthorized <b>modification</b> <b>of</b> {{information}} <b>data</b> exchanged.|$|R
5000|$|... {{to possess}} {{sophisticated}} input dialogs for creation and <b>modification</b> <b>of</b> model <b>data</b> ...|$|R
5000|$|Data Stream Controller multiplexes {{individual}} data streams as {{a single}} persistent connection, and it centralizes control of the creation and <b>modification</b> <b>of</b> groups <b>of</b> <b>data</b> channels at the server level.|$|R
50|$|Any {{circumstance}} {{or event}} {{with the potential}} to adversely impact an IS through unauthorized access, destruction, disclosure, <b>modification</b> <b>of</b> <b>data,</b> and/or denial of service.|$|E
50|$|A {{presentation}} at BlackHat USA 2010 {{revealed that a}} number of large public websites had left Memcached open to inspection, analysis, retrieval, and <b>modification</b> <b>of</b> <b>data.</b>|$|E
50|$|Static data {{authentication}} (SDA) ensures data {{read from the}} card has been signed by the card issuer. This prevents <b>modification</b> <b>of</b> <b>data,</b> but does not prevent cloning.|$|E
30|$|Besides {{evaluating}} queries efficiently, many deployment scenarios {{also require}} the <b>modification</b> <b>of</b> outsourced <b>data.</b> While some proposed CPI approaches {{assume that the}} data is outsourced once without being modified at a future point in time, other approaches allow changes {{to be made to}} the outsourced data without harming its confidentiality. <b>Modifications</b> <b>of</b> the <b>data</b> may constitute insertions, updates or deletions of records.|$|R
5000|$|Rules for use and <b>modification</b> <b>of</b> the <b>data,</b> which {{derive from}} the dynamic {{characteristics}} of the objects themselves—called the functional model ...|$|R
40|$|Ontology-based Data Access (OBDA) {{is gaining}} {{importance}} both scientifically and practically. However, {{little attention has}} been paid so far to the problem of updating OBDA systems. This is an essential issue if {{we want to be able}} to cope with <b>modifications</b> <b>of</b> <b>data</b> both at the ontology and at the source level, while maintaining the independence <b>of</b> the <b>data</b> sources. In this paper, we propose mechanisms to properly handle updates in this context. We show that updating data both at the ontology and source level is first-order rewritable. We also provide a practical implementation of such updating mechanisms based on non-recursive Datalog. Peer ReviewedPostprint (author's final draft...|$|R
50|$|Firstly, {{as there}} is no authentication, an {{attacker}} can edit a message and recompute the CRC without the substitution being detected. When stored alongside the data, CRCs and cryptographic hash functions by themselves do not protect against intentional <b>modification</b> <b>of</b> <b>data.</b> Any application that requires protection against such attacks must use cryptographic authentication mechanisms, such as message authentication codes or digital signatures (which are commonly based on cryptographic hash functions).|$|E
50|$|Integrity {{refers to}} being correct or {{consistent}} with the intended state of information. Any unauthorized <b>modification</b> <b>of</b> <b>data,</b> whether deliberate or accidental, is a breach of data integrity. For example, data stored on disk {{are expected to be}} stable - they are not supposed to be changed at random by problems with a disk controller. Similarly, application programs are supposed to record information correctly and not introduce deviations from the intended values.|$|E
5000|$|On 24 April 2013, Australian Federal Police arrested 24-year-old Matthew Flannery of Point Clare, who boasted on Facebook [...] "I’m {{the leader}} of LulzSec". Flannery, who went by the {{username}} Aush0k, was arrested for the alleged hacking of the Narrabri Shire Council website on which homepage sexually explicit text and an image were left. On 27 August 2014, Flannery entered guilty pleas to five charges of making unauthorised <b>modification</b> <b>of</b> <b>data</b> to cause impairment, and dishonestly obtaining the Commonwealth Bank details of a woman. Flannery, who said the reference to LulzSec was a joke, lost his job of computer technician in a security company. On 16 October 2014, {{he was sentenced to}} 15 months of house arrest which continues until mid-April 2016, alongside a 12 months good behaviour bond.|$|E
40|$|Abstract. Web <b>of</b> <b>Data</b> formats such as linked data, RDFa and microformats are {{read-only}} technologies. The issue <b>of</b> updating Web <b>data</b> {{directly from}} an RDF-based environment {{has so far}} gained limited attention. We present a preliminary report on the idea <b>of</b> “pushing back” <b>modifications</b> <b>of</b> RDF <b>data</b> to the original source, focusing on the specific case where data resides behind site-specific Web APIs. ...|$|R
40|$|Abstract. Workflow {{management}} systems (WfMSs) frequently use data {{to coordinate the}} execution of workflow instances. A WfMS evaluates conditions defined on data to make the control flow decisions i. e. selecting the next activity or deciding on an actor. However, data- within and outside of a running workflow instance- may change dynamically. <b>Modifications</b> <b>of</b> <b>data</b> needed for past control flow decisions may invalidate these decisions. We analyze the desired synchronization policies, and propose a mechanism called data guard to selectively guarantee that significant changes in data are recognized and handled by the data management system to ensure correctness of workflow execution in face of asynchronous updates. ...|$|R
50|$|In {{addition}} to creation, deletion, <b>modification</b> <b>of</b> user identity <b>data</b> either assisted or self-service,Identity Management controls ancillary entity data {{for use by}} applications, such as contact information or location.|$|R
50|$|A blitter is a circuit, {{sometimes}} as a coprocessor or a logic block on a microprocessor, {{dedicated to the}} rapid movement and <b>modification</b> <b>of</b> <b>data</b> within a computer's memory. A blitter can copy large quantities of data from one memory area to another relatively quickly, and in parallel with the CPU, while freeing up the CPU's more complex capabilities for other operations. A typical use for a blitter is the movement of a bitmap, such as windows and fonts in a graphical user interface or images and backgrounds in a 2D computer game. The name comes from the bit blit operation of the 1973 Xerox Alto, which stands for bit-block transfer. A blit operation {{is more than a}} memory copy, because it can involve data that's not byte aligned (hence the bit in bit blit), handling transparent pixels (pixels which should not overwrite the destination data), and various ways of combining the source and destination data.|$|E
30|$|Any {{circumstance}} {{or event}} {{with the potential}} to adversely affect a system through unauthorised access, destruction, disclosure, or <b>modification</b> <b>of</b> <b>data,</b> or denial of service.|$|E
30|$|Using {{advanced}} {{analysis of}} disaggregated data allows for <b>modification</b> <b>of</b> <b>data</b> {{as has been}} done for Fig. 3. Although the accident types did not match perfectly, the Swedish types could be modified into their Finnish equivalent.|$|E
50|$|Data {{warehouse}} automation {{can provide}} advantages like source data exploration, warehouse data models, ETL generation, test automation, metadata management, managed deployment, scheduling, change impact analysis and easier maintenance and <b>modification</b> <b>of</b> the <b>data</b> warehouse.More {{important than the}} technical features of DWA tools, however, {{is the ability to}} deliver projects faster and with less resources.|$|R
5000|$|Procedural {{languages}} allow {{developers to}} extend the database with custom subroutines (functions), often called stored procedures. These functions {{can be used to}} build triggers (functions invoked upon <b>modification</b> <b>of</b> certain <b>data)</b> and custom aggregate functions. Procedural languages can also be invoked without defining a function, using the [...] "DO" [...] command at SQL level.|$|R
40|$|The paper {{describes}} a problems of automatic conversion of Metafont fonts into the PostScript Type 1 font format. Several methods of conversion are observed. A short description of Paradissa Fonts Collection is presented which contains Computer Modern fonts (conventionally used in (LA) TEX) in the ATM compatible PostScript Type 1 format. The {{use of the}} collection and the problems related to it are discussed. 1 Introduction. Intensive informatization of human activities invokes rapid <b>modifications</b> <b>of</b> methods <b>of</b> <b>data</b> production, processing and use. This requires the adaptation <b>of</b> collected <b>data</b> arrays to efficient modern techniques of information processing...|$|R
30|$|Tampering with data: Data {{tampering}} {{involves the}} malicious <b>modification</b> <b>of</b> <b>data.</b> Examples include unauthorized changes made to persistent data, {{such as that}} held in a database, and the alteration of data as it flows between two computers over an open network, such as the Internet.|$|E
3000|$|... 5) Monitoring and {{auditing}} Security monitoring {{is gathering}} and investigating network events {{to catch the}} intrusions. Audit means recording user activities of the healthcare system in chronological order, such as maintaining a log of every access to and <b>modification</b> <b>of</b> <b>data.</b> These are two optional security metrics to measure and {{ensure the safety of}} a healthcare system [38].|$|E
40|$|<b>Modification</b> <b>of</b> <b>data</b> for IPA Criterion A list, {{exclusion}} of some taxa from the 1997 IUCN Red List of Threatened Plants (WALTER & GILLETT, 1998), inclusion of others, {{as well as}} upgrading and degrading of the threat category in some cases are proposed. Small alternations concern additions and corrections to the species distribution mainly for Slovakia...|$|E
40|$|Abstract: To enable {{analyses}} and decision support over historic, forecast, and es-timated data, efficient querying and <b>modification</b> <b>of</b> probabilistic <b>data</b> {{is an important}} aspect. In earlier work, we proposed a data model and operators for the analysis and the <b>modification</b> <b>of</b> uncertain <b>data</b> in support <b>of</b> what-if scenario analysis. Naturally, and as discussed broadly in previous research, the representation <b>of</b> uncertain <b>data</b> intro-duces additional complexity to queries over such data. When targeting the interactive creation and evaluation of scenarios, we {{must be aware of}} the run-time performance of the provided functionalities in order to better estimate response times and reveal potentials for optimizations to users. The present paper builds on our previous work, addressing both a comprehensive evaluation of the complexity of selected operators as well as an experimental validation. Specifically, we investigate effects of varying operator parameterizations and the underlying data characteristics. We provide exam-ples {{in the context of a}} simple analysis process and discuss our findings and possible optimizations. ...|$|R
50|$|To sum up, if the {{attacker}} {{is able to}} set the IV {{that will be used}} for MAC verification, he can perform arbitrary <b>modification</b> <b>of</b> the first <b>data</b> block without invalidating the MAC.|$|R
40|$|The ATLAS Distributed Data Management system {{requires}} {{accounting of}} its contents at the metadata layer. This presents a hard problem due to the large scale {{of the system and}} the high rate <b>of</b> concurrent <b>modifications</b> <b>of</b> <b>data.</b> The system must efficiently account more than 90 PB of disk and tape that store upwards of 2. 5 billion files across 900 storage systems globally. In this work a generic accounting system is presented, which is able to scale to the requirements of ATLAS. The design and architecture is presented based on Hadoop Pig and HBase. A strong emphasis is placed on the necessary design choices such that the underlying data models are generally applicable to many kinds of accounting, reporting and monitoring...|$|R
40|$|The {{demand for}} {{multi-user}} applications has grown significantly with the explosive {{expansion of the}} Internet. Concurrent access and <b>modification</b> <b>of</b> <b>data</b> has become the norm, and thus, database systems handle concurrent execution of queries of many different types. Often, the interaction of these queries among themselves can impact {{the performance of the}} system significantly. However, standard methods of query optimizatio...|$|E
40|$|This paper compares five {{definitions}} of data integrity, and shows {{how they can}} be ordered in an increasingly restrictive sequence. The most general of these, due to Courtney and Ware [6], is based on the concept of expectation of data quality: data has integrity to the extent that its quality meets, or exceeds, the quality requirements that users expect of it. This definition incorporates liveness requirements, whereas the others only address safety requirements. The second and third definitions are both based on the ability to modify data. One of these, due to Sandhu and Jajodia [16], defines the scope of integrity to be safeguards against the improper <b>modification</b> <b>of</b> <b>data.</b> The other narrows the scope further to safeguards against the unauthorized <b>modification</b> <b>of</b> <b>data.</b> This latter definition has been popular in recent security criteria [4, 10]. The fourth definition discussed here is Biba's concept of integrity as one-directional information flow in a lattice [2]. We argue that Biba's [...] ...|$|E
40|$|This {{thesis is}} {{concerned}} with giving both {{an overview of the}} application of hash functions in cryptography and a presentation of today's standard cryptographic hash functions. Cryptographic hash functions are a valuable tool in cryptography. They are applied in many areas of information security to provide protection of the authenticity of messages; data integrity verification which prevents <b>modification</b> <b>of</b> <b>data</b> from going undetected, time stamping and digital signature scheme...|$|E
5000|$|Creating an {{immutable}} class used {{to require}} two steps: first, creating accessors (either automatically or manually) that prevent <b>modification</b> <b>of</b> object attributes, and secondly, preventing direct <b>modification</b> <b>of</b> the instance <b>data</b> <b>of</b> instances of that class (this was usually {{stored in a}} hash reference, and could be locked with Hash::Util's lock_hash function): ...|$|R
5000|$|XTS mode is {{susceptible}} to data manipulation and tampering, and applications must employ measures to detect <b>modifications</b> <b>of</b> <b>data</b> if manipulation and tampering is a concern: [...] "...since there are no authentication tags then any ciphertext (original or modified by attacker) will be decrypted as some plaintext {{and there is no}} built-in mechanism to detect alterations. The best that can be done is to ensure that any alteration of the ciphertext will completely randomize the plaintext, and rely on the application that uses this transform to include sufficient redundancy in its plaintext to detect and discard such random plaintexts." [...] This would require maintaining checksums for all data and metadata on disk, as done in ZFS or Btrfs. However, in commonly used file-systems such as ext4 and NTFS only metadata is protected against tampering, while the detection <b>of</b> <b>data</b> tampering is non existent.|$|R
40|$|The {{amount of}} {{information}} available on the Web grows at an incredible high rate. Systems and procedures devised {{to extract these data}} from Web sources already exist, and different approaches and techniques have been investigated during the last years. On the one hand, reliable solutions should provide robust algorithms <b>of</b> Web <b>data</b> mining which could automatically face possible malfunctioning or failures. On the other, in literature {{there is a lack of}} solutions about the maintenance of these systems. Procedures that extract Web data may be strictly interconnected with the structure <b>of</b> the <b>data</b> source itself; thus, malfunctioning or acquisition <b>of</b> corrupted <b>data</b> could be caused, for example, by structural <b>modifications</b> <b>of</b> <b>data</b> sources brought by their owners. Nowadays, verification <b>of</b> <b>data</b> integrity and maintenance are mostly manually managed, in order to ensure that these systems work correctly and reliably. In this paper we propose a novel approach to create procedures able to extract data from Web sources [...] the so called Web wrappers [...] which can face possible malfunctioning caused by <b>modifications</b> <b>of</b> the structure <b>of</b> the <b>data</b> source, and can automatically repair themselves. ...|$|R
