568|98|Public
25|$|C++ Accelerated <b>Massive</b> <b>Parallelism</b> (C++ AMP) is {{a library}} that accelerates {{execution}} of C++ code by exploiting the data-parallel hardware on GPUs.|$|E
2500|$|At {{the age of}} 18, Plateau {{had wanted}} to become a medical doctor, but her father advised against it. After {{studying}} at the École Normale Supérieure and , Brigitte Plateau submitted in 1980 a postgraduate thesis (DEA) in computer science at the University of Paris XI and in 1984, a state computer thesis. She obtained a (fr) at the Centre national de la recherche scientifique (CNRS), then taught as a visiting scholar at the University of Maryland in the United States. In 1988, she was appointed full professor by Grenoble Polytechnic Institute, assigned to Ensimag and to the laboratory of Computer Engineering. In 1999, she created the IT and distribution Laboratory (Grenoble INP-UJF-CNRS) that she headed until 2004. In January 2007 Plateau created the Grenoble Informatics Laboratory associated with the French Institute for Research in Computer Science and Automation (INRIA). [...] As of 2014, Plateau was in charge of 500 computer scientists at the laboratory. Her research work is on the performance of computer systems, in particular distributed and parallel systems. She is studying queueing models, distributed algorithms and massively parallel computers (by simulation and observation). She is an expert in high speed calculations using <b>massive</b> <b>parallelism.</b>|$|E
50|$|These {{properties}} together allow <b>massive</b> <b>parallelism.</b>|$|E
40|$|Recent {{emerging}} many-core-on-a-chip architectures present <b>massive</b> on-chip <b>parallelism</b> through hardware {{support for}} multithreading. In {{order to achieve}} fast development of parallel applications that exploit this <b>massive</b> intrachip <b>parallelism</b> to achieve highly sustainable performance, suitable programming models are needed. OpenMP, the industry de facto standard for writing parallel programs on shared memory systems, could become a reasonable candidate...|$|R
40|$|A massively {{parallel}} processor proves {{to be a powerful}} tool for manipulating large Poisson series. Assuming the series to be sparse, as in most problems of non-linear dynamics, they map into the computer one term per processor. The parallel processor then executes the basic operations in the free algebra of Poisson series over the field of real or rational numbers. We describe a prototype Poisson series processor currently running on the Connection Machine. Timing the calculation of various expansions in the two-body problem demonstrates <b>massive</b> <b>parallelism's</b> potential for tackling the enormous symbolic calculations customary in non-linear dynamics...|$|R
40|$|Abstract. Recent {{emerging}} many-core-on-a-chip architectures present <b>massive</b> on-chip <b>parallelism</b> through hardware {{support for}} multithreading. In {{order to achieve}} fast development of parallel applications that exploit this <b>massive</b> intrachip <b>parallelism</b> to achieve highly sustainable performance, suitable programming models are needed. OpenMP, the industry de facto standard for writing parallel programs on shared memory systems, could become a reasonable candidate. To increase {{our understanding of the}} behavior and performance characteristics of OpenMP programs on many-core-on-a-chip architectures, this paper presents a performance study of basic OpenMP language constructs on the IBM Cyclops- 64 architecture, which consists of 160 hardware thread units in a single chip. Compared with previous work on conventional SMP systems [1], the overhead of OpenMP language constructs on C 64 many-core architecture is at least one order of magnitude lower. ...|$|R
5000|$|... {{advanced}} graphics processing {{units for}} exploiting <b>massive</b> <b>parallelism</b> in geospatial computing; ...|$|E
50|$|The {{other problem}} is {{difficulty}} in parallelism. Since {{the nature of}} Coordinate Descent is to cycle through the directions and minimize the objective function with respect to each coordinate direction, Coordinate Descent is not an obvious candidate for <b>massive</b> <b>parallelism.</b> Recent research works have shown that <b>massive</b> <b>parallelism</b> is applicable to Coordinate Descent by relaxing the change of the objective function with respect to each coordinate direction.|$|E
50|$|C++ Accelerated <b>Massive</b> <b>Parallelism</b> (C++ AMP) is {{a library}} that accelerates {{execution}} of C++ code by exploiting the data-parallel hardware on GPUs.|$|E
40|$|AbstractWe present {{transformation}} {{rules to}} parallelize divide-and-conquer (DC) algorithms over powerlists. These rules convert the parallel control structure of DC into a sequential control flow, thereby making the implicit <b>massive</b> data <b>parallelism</b> in a DC scheme explicit. The results given here are illustrated by many examples including Fast Fourier Transform and Batcher's bitonic sort...|$|R
40|$|Accelerating {{processors}} {{can often}} be more cost and energy effective {{for a wide range}} of data-parallel computing problems than general-purpose processors. For graphics processor units (GPUs), this is particularly the case when program development is aided by environments, such as NVIDIA’s Compute Unified Device Architecture (CUDA), which dramatically reduces the gap between domainspecific architectures and general-purpose programming. Nonetheless, general-purpose GPU (GPGPU) programming remains subject to several restrictions. Most significantly, the separation of host (CPU) and accelerator (GPU) address spaces requires explicit management of GPU memory resources, especially for <b>massive</b> data <b>parallelism</b> that well exceeds the memory capacity of GPUs. One solution to this problem is to transfer data between GPU and host memories frequently. In this work, we investigate another approach. We run massively data-parallel applications on GPU clusters. We further propose a programming model for <b>massive</b> data <b>parallelism</b> with data dependencies for this scenario. Experience from micro benchmarks and real-world applications shows that our model provides not only ease of programming but also significant performance gains. ...|$|R
40|$|Multithreaded {{architectures}} {{have the}} potential of tolerating large memory and functional unit latencies and increase resource utilization. The Blue Gene/Cyclops architecture, being developed at the IBM T. J. Watson Research Center, is one such systems that offers <b>massive</b> intra-chip <b>parallelism.</b> Although the BG/C architecture was initially designed to execute specific applications, {{we believe that it}} can be effectively used on a broad range of parallel numerical applications...|$|R
50|$|Like most companies, Fujitsu {{turned to}} <b>massive</b> <b>parallelism</b> for future machines, and the VP2000 family {{were not on}} the market for very long. Nevertheless, over 100 were sold, and in July 1993, there were 180 installed.|$|E
50|$|C++ Accelerated <b>Massive</b> <b>Parallelism</b> (C++ AMP) is {{a native}} {{programming}} model that contains elements that span the C++ programming language and its runtime library. It provides {{an easy way to}} write programs that compile and execute on data-parallel hardware, such as graphics cards (GPUs).|$|E
50|$|The MPPA's <b>massive</b> <b>parallelism</b> and its {{distributed}} memory MIMD architecture distinguishes it from multicore and manycore architectures, which have fewer processors and an SMP or other shared memory architecture, mainly intended for general-purpose computing. It's also distinguished from GPGPUs with SIMD architectures, used for HPC applications.|$|E
40|$|ABSTRACT: Satisfiability (SAT) is a {{computationally}} expensive algorithm {{central to}} many CAD and test applications. In this paper, we present {{the architecture of}} a new SAT solver using reconfigurable logic. Our main contributions include new forms of <b>massive</b> fine-grain <b>parallelism</b> and structured design techniques based on iterative logic arrays that reduce compilation times from hours to a few minutes. Our architecture is easily scalable. Our results show several orders of magnitude speed-up compared with a state-of-the-art software implementation, and with a prior SAT solver using reconfigurable hardware. 1...|$|R
40|$|We are now {{entering}} the multi-core era, many multi-core chips are designed and manufactured by various vendors, such as Intel, AMD and Sun etc. IBM Cyclops- 64 (C 64) is a multi-core archi-tecture that provides <b>massive</b> on-chip <b>parallelism,</b> <b>massive</b> on-chip bandwidth, and multiple level memory hierarchy. This type of multi-core architecture presents big challenges to application devel-opers and system software designers {{on how to}} exploit the thread level parallelism(TLP) provided by the multi-core chips. While a lot of researchers believe that multi-core architecture will become the mainstream in the future, {{there are only a}} few studies about the application development on those advanced architec-tures have been reported. The emerging multi-core architectures not only unveil opportunities of massive on-chip paral-lelism through hardware support, but also present great challenges to application developers and system software designers. In this paper, we report our experience of optimizing the Fast Fourier Transform (FFT) on the IBM Cyclops- 64 (C 64) architecture, a novel multi-core architecture con-sisting of 160 threads, an explicit memory hierarchy, and an on-chip interconnection network...|$|R
40|$|Neural Networks (NNs), {{which are}} able to learn {{nonlinear}} behaviors from a limited set of measurement data, can provide efficient modeling solutions for many virtual reality applications. Due to their continuous memory behavior, NNs {{are able to}} provide instantaneously an estimation of the output value for input values that {{were not part of}} the initial training set. Hardware NNs consisting of a collection of simple neuron circuits provide the <b>massive</b> computational <b>parallelism</b> allowing for higher speed realtime models. A virtual prototyping environment for Electronic Design Automation (EDA) and a NN model for the 3 D electromagnetic field are discussed in a representative case study. 1...|$|R
50|$|MapD {{develops}} a {{database management system}} product and a visualization layer. The MapD database is designed for GPU environments and takes advantage of both the memory bandwidth and the <b>massive</b> <b>parallelism</b> available on that hardware. By tuning the database for these hardware capabilities, MapD can execute queries at 100x the speed of traditional CPU databases.|$|E
50|$|Clearly, the {{organizing}} {{principle of the}} brain is parallelism. It's using <b>massive</b> <b>parallelism.</b> The information is in the connection between {{a lot of very}} simple parallel units working together. So if we built a computer that was more along that system of organization, it would likely {{be able to do the}} same kinds of things the brain does.|$|E
50|$|Iterative {{reconstruction}} {{refers to}} iterative algorithms used to reconstruct 2D and 3D images in certain imaging techniques.For example, in computed tomography an image must be reconstructed from projections of an object. Here, iterative reconstruction techniques are usually abetter, but computationally more expensive {{alternative to the}} common filtered back projection (FBP) method, which directly calculates the image ina single reconstruction step. In recent research works, scientists have shown that extremely fast computations and <b>massive</b> <b>parallelism</b> is possible for iterative reconstruction, which makes iterative reconstruction practical for commercialization.|$|E
30|$|Even with a {{high-end}} computer, {{the result is}} not satisfactory in terms of speed. Candidate systems using this algorithm require a faster response. To address this and other problems associated with a conventional PC, such as size or power consumption, we propose three implementations on three specific image-processing devices: a Vision Chip, a custom architecture on FPGA and a MPPA. From {{the characteristics of the}} algorithm, it is extracted that (by its nature) an MP-SIMD architecture matches better. We also test the capabilities of the reconfigurable hardware on FPGAs, which increasingly provides more features. Finally, using the MPPA, we check whether exploiting the task parallelism instead of its <b>massive</b> data <b>parallelism</b> also provides good results.|$|R
40|$|We review {{our work}} done to {{optimize}} the staggered conjugate gradient (CG) algorithm in the MILC code for use with the Intel Knights Landing (KNL) architecture. KNL is the second gener- ation Intel Xeon Phi processor. It is capable of <b>massive</b> thread <b>parallelism,</b> data parallelism, and high on-board memory bandwidth and is being adopted in supercomputing centers for scientific research. The CG solver consumes the majority of time in production running, so we have spent most of our effort on it. We compare performance of an MPI+OpenMP baseline version of the MILC code with a version incorporating the QPhiX staggered CG solver, for both one-node and multi-node runs. Comment: 8 pages, 4 figure...|$|R
40|$|International audience—The main {{challenges}} in smart camera networks {{come from the}} limited capacity of network communications. Indeed, wireless protocols such as the IEEE 802. 15. 4 protocol target low data rate, low power consumption and low cost wireless networking in order to fit the requirements of sensor networks. Since nodes {{more and more often}} integrate image sensors, network bandwidth has become a strong limiting factor in application deployment. This means that data must be processed at the node level before being sent on the network. In this context, FPGA-based platforms, supporting <b>massive</b> data <b>parallelism,</b> offer large opportunities for on-board processing. We present in this paper our FPGA-based smart camera platform, called DreamCam, which is able to autonomously exchange processed information on an Ethernet network...|$|R
50|$|Vector {{processors}} (for example modern graphics {{processing unit}} (GPUs) and Xeon Phi) use <b>massive</b> <b>parallelism</b> to achieve high throughput whilst working around memory latency (reducing the need for prefetching). Many read operations are issued in parallel, for subsequent invocations of a compute kernel; calculations may be put on hold awaiting future data, whilst the execution units are devoted to working on data from past requests data that has already turned up. This is easier for programmers to leverage {{in conjunction with the}} appropriate programming models (compute kernels), but harder to apply to general purpose programming.|$|E
50|$|TeraChem is {{the first}} {{computational}} chemistry software program written completely from scratch {{to benefit from the}} new streaming processors such as graphics processing units (GPUs). The computational algorithms have been completely redesigned to exploit <b>massive</b> <b>parallelism</b> of CUDA-enabled Nvidia GPUs. The original development started at the University of Illinois at Urbana-Champaign.Due to the great potential of the developed technology, this GPU-accelerated software was subsequently commercialized. Now it is distributed by PetaChem, LLC, located in the Silicon Valley. The software package is under active development and new features are released often.|$|E
50|$|The {{organisation}} {{and complexity}} of all living beings {{is based on a}} coding system functioning with four key components of the DNA-molecule. Because of this, the DNA is very suited as a medium for data processing. According to different calculations a DNA-computer with one liter of fluid containing six grams of DNA could potentially have a memory capacity of 3072 exabytes. The theoretical maximum data transfer speed would also be enormous due to the <b>massive</b> <b>parallelism</b> of the calculations. Therefore, about 1000 petaFLOPS could be reached, while today's most powerful computers do not go above a few dozen (99 petaFLOPS being the current record).|$|E
40|$|The MOVE {{project of}} the Department of Electrical Engineering of the TU Delft aims at {{designing}} and building high-performance processors {{by means of a}} new class of architectures called transporttriggered architectures. Transport-triggered architectures comprise a new class of architectures that are programmed by specifying data-transports instead of operations; they are particulary suited for application specific purposes. In order to exploit the power of these architectures new code scheduling techniques are required. 1 Introduction This document gives a short overview of the MOVE project at the Delft University of Technology. The MOVE project concerns the automation of application-specific processor system design providing optimal cost-performance tradeoffs. The project is based on three tenets: RISC, instruction-level <b>parallelism,</b> and <b>massive</b> message-passing <b>parallelism.</b> RISC principles tell us to carefully quantify cost and performance of extra hardware functionality, taking also [...] ...|$|R
40|$|With {{the current}} {{advances}} in bone imaging and progress in numerical techniques, the micro structural Finite Element analysis (FEM) of human bone for stiffness and strength assessment for individual fracture risk prediction, with a <b>massive</b> potential for <b>parallelism</b> as become a signi?cant candidate for {{investigation in the}} current multicore processors. This master thesis work focuses on investigating the credibility of Finite Element analysis of the human bone structure on the IBM Cell processor. Microelectronics & Computer EngineeringElectrical Engineering, Mathematics and Computer Scienc...|$|R
40|$|Abstract—The flux state {{quantum bit}} (qubit) is {{promising}} for a solid state implementation of scalable quantum computing. The simplest flux state qubit {{consists of an}} rf SQUID with two fluxoid states, which can be readout with a dc SQUID—the most sensitive magnetic flux detector. Efficient readout with less back-action is desirable for quantum computing. In this work, we report mea-surements of the switching flux and switching current distribu-tions of under damped dc SQUIDs. The data show that single shot readout of flux qubit with very high efficiency (99 %) can be re-alized using underdamped hysteretic dc SQUIDs. Index Terms—dc SQUID, qubit, readout. QUANTUM computing has drawn significant interestbecause of its <b>massive</b> intrinsic <b>parallelism.</b> In principle, any system that is able to store and coherently process information in a Hilbert space {{can be used to}} implement quantum computing. Recently, quantum logic operations hav...|$|R
5000|$|At {{the first}} C.E.C. Workshop, in Brussels in November 1991, {{bioelectronics}} {{was defined as}} 'the use of biological materials and biological architectures for information processing systems and new devices'. Bioelectronics, specifically bio-molecular electronics, were described as 'the {{research and development of}} bio-inspired (i.e. self-assembly) inorganic and organic materials and of bio-inspired (i.e. <b>massive</b> <b>parallelism)</b> hardware architectures for the implementation of new information processing systems, sensors and actuators, and for molecular manufacturing down to the atomic scale'.The National Institute of Standards and Technology (NIST), an agency of the U.S. Department of Commerce, defined bioelectronics in a 2009 report as [...] "the discipline resulting from the convergence of biology and electronics".|$|E
50|$|The <b>massive</b> <b>parallelism</b> {{of neural}} {{networks}} allows redundant populations of neurons {{to mediate the}} same or similar percepts. Nonetheless, {{it is assumed that}} every subjective state will have associated neural correlates, which can be manipulated to artificially inhibit or induce the subject's experience of that conscious state. The growing ability of neuroscientists to manipulate neurons using methods from molecular biology in combination with optical tools was achieved by the development of behavioral and organic models that are amenable to large-scale genomic analysis and manipulation. Non-human analysis such as this, in combination with imaging of the human brain, have contributed to a robust and increasingly predictive theoretical framework.|$|E
50|$|Interaction nets are a {{graphical}} model of computation devised by Yves Lafont in 1990 as a generalisation of the proof structures of linear logic. An interaction net system is specified {{by a set}} of agent types and a set of interaction rules. Interaction nets are an inherently distributed model of computation in the sense that computations can take place simultaneously in many parts of an interaction net, and no synchronisation is needed. The latter is guaranteed by the strong confluence property of reduction in this model of computation. Thus interaction nets provide a natural language for <b>massive</b> <b>parallelism.</b> Interaction nets {{are at the heart of}} many implementations of the lambda calculus, such as efficient closed reduction and optimal, in Lévy's sense, Lambdascope.|$|E
40|$|Current {{artificial}} {{neural network}} (ANN) algorithms require extensive computational resources. However, they exhibit <b>massive</b> fine-grained <b>parallelism</b> and require only moderate arithmetic precision. These properties make possible custom VLSI implementations for high performance, low cost systems. This paper describes one such system, a special purpose digital VLSI architecture to implement neural network training in a speech recognition application. The network algorithm {{has a number of}} atypical features. These include: shared weights, sparse activation, binary inputs, and a serial training input stream. The architecture illustrates a number of design techniques to exploit these algorithmspecific features. The result is a highly pipelined system which sustains a learning rate of one pattern per clock cycle. At a clock rate of 20 MHz each "neuron" site performs 200 million connection updates per second. Multiple such neurons can be integrated onto a modestly sized VLSI die. International [...] ...|$|R
40|$|Image coding systems {{currently}} undergoing standardisation {{within the}} ISO and CCITT are {{the final outcome}} of a process of incremental improvements to classical hybrid (transform-predictive) algorithms. The task of VLSI architecture synthesis for these complete systems is made somewhat awkward due to the unstructured, irregular and non-modular nature of these algorithms. An ad hoc methodology for pruning the architectural search space, directed by the goal of minimizing the overall internal memory, leads to a strongly control-flow solution, using a pipeline scheme that is more efficient than the original signal-flow graph. A generic image coding processor using a parallel programmable architecture is another solution. It may be inferred that second generation image coding techniques should be designed with <b>massive</b> fine-grain <b>parallelism</b> in view, {{if they are to}} take advantage of the full potential of dedicated VLSI implementations...|$|R
40|$|International audienceLow density {{parity check}} (LDPC) {{decoding}} process {{is known as}} compute intensive. This kind of digital communication applications was recently implemented onto graphic processing unit (GPU) devices for LDPC code performance estimation and/or for real-time measurements. Overall previous studies about LDPC decoding on GPU {{were based on the}} implementation of the flooding-based decoding algorithm that provides <b>massive</b> computation <b>parallelism.</b> More efficient layered schedules were proposed in literature because decoder iteration can be split into sublayer iterations. These schedules seem to badly fit onto GPU devices due to restricted computation parallelism and complex memory access patterns. However, the layered schedules enable the decoding convergence to speed up by two. In this letter, we show that: 1) layered schedule can be efficiently implemented onto a GPU device; and 2) this approach [...] implemented onto a low-cost GPU device [...] provides higher throughputs with identical correction performances (BER) compared to previously published results...|$|R
