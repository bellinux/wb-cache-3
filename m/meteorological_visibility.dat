32|10|Public
50|$|In meteorology, {{visibility}} is {{a measure}} of the distance at which an object or light can be clearly discerned. It is reported within surface weather observations and METAR code either in meters or statute miles, depending upon the country. Visibility affects all forms of traffic: roads, sailing and aviation. <b>Meteorological</b> <b>visibility</b> refers to transparency of air: in dark, <b>meteorological</b> <b>visibility</b> is still the same as in daylight for the same air.|$|E
50|$|With good visibility, pilots can {{determine}} the aircraft attitude by utilising visual cues from outside the aircraft, most significantly the horizon. Without such external visual cues, pilots must use an internal source of the attitude information, which is usually provided by gyroscopically-driven instruments such as the attitude indicator ("artificial horizon"). The availability of a good horizon cue is controlled by <b>meteorological</b> <b>visibility,</b> hence minimum visibility limits feature in the VMC minima. Visibility {{is also important to}} avoid terrain.|$|E
40|$|Fog is a {{challenging}} problem for road safety. To estimate the fog density and estimate the <b>meteorological</b> <b>visibility</b> distance, some attempts using an in-vehicle cameras are being developed. To complete {{the notion of}} <b>meteorological</b> <b>visibility,</b> we propose to estimate {{the distance to the}} most distant visible object belonging to the road surface. We call this distance the mobilized visibility distance, which may be compared with the mobilizable visibility distance which is defined as being the greatest distance at which a potential object on the road surface would be visible. In this paper, the relationships between these distances and the <b>meteorological</b> <b>visibility</b> distance are established. To illustrate our proposal, our methods to estimate the <b>meteorological</b> <b>visibility</b> distance and the mobilized visibility distance are presented and samples of results are given...|$|E
25|$|Originally {{scheduled}} for 5 ½ hours, the test flight was shortened {{to three hours}} with the pilots wanting to complete the flight under visual <b>meteorological</b> conditions while <b>visibility</b> and cloud ceiling were low.|$|R
50|$|The runway of Kaunas Airport is 3,250m {{long and}} 45m wide, and is {{categorized}} with a 4E ICAO reference code. This enables to handle aircraft {{with up to}} 45m wing span WRONG? and 14m main gear wheel span, which includes planes {{the size of a}} Boeing 747 or Antonov An-124. The runway is oriented along the dominant direction of western winds; it is also equipped with CAT II ILS equipment which allows Kaunas Airport to receive aircraft with minimum <b>visibility</b> <b>meteorological</b> conditions.|$|R
5000|$|On December 15, 2009, Boeing {{conducted}} the 787-8 maiden flight from Paine Field in Everett, Washington, at 10:27 am PST and landed {{three hours later}} at 1:33 p.m. at Seattle's Boeing Field, after reaching [...] and [...]Originally scheduled for 5 ½ hours, the test flight was shortened to three hours with the pilots wanting to complete the flight under visual <b>meteorological</b> conditions while <b>visibility</b> and cloud ceiling were low.The 6,800h, six-aircraft ground and flight test programme was scheduled in {{eight and a half}} months, the fastest certification campaign for a new Boeing commercial design.|$|R
40|$|Abstract. The <b>meteorological</b> <b>visibility</b> {{estimation}} is {{an important}} task, for example, in road traffic control and aviation safety, but its reliable automation is difficult. The conventional light scattering measurements are limited into a small space and the extrapolated values are often erro-neous. The current <b>meteorological</b> <b>visibility</b> estimates relying on a single camera work only with data captured in day light. We propose a new method based on feature vectors that are projections of the scene im-ages with lighting normalization. The proposed method was combined with the high dynamic range imaging to improve night time image qual-ity. Visibility classification accuracy (F 1) of 85. 5 % was achieved for data containing both day and night images. The {{results show that the}} ap-proach can compete with commercial visibility measurement devices. ...|$|E
40|$|In {{the light}} of the {{measurement}} data in real atmosphere, the attenuation proper-ties of near infrared radiation of GaAs LED propagating through fog are discussed Comparisons of the attenuation coefficient with the simultaneously observed <b>meteorological</b> <b>visibility</b> show that there is a close relationship between them. This oonolusion is proved by the theoretical calculation. I...|$|E
40|$|Dual {{base line}} AVRA (AVRA MK II) {{system is a}} tramsmissometer system for {{measuring}} the runway visual range (RVR) and <b>Meteorological</b> <b>visibility</b> (MV) satisfying the visibility range requirements for all categories of aircraft landing operations (Cat II, Cat IIIa and Cat IIIb). This document describes the software for this system. Flowcharts designed for this system are also included...|$|E
40|$|A recent {{field trial}} in the Northern German {{littoral}} area of the Baltic Sea yielded a dataset of <b>visibility,</b> <b>meteorological</b> parameters, aerosol size distributions, as well as transmission over a horizontal path of 1344 m. The experimental results are compared to simulations using the MODTRAN (moderate resolution atmospheric transmission) model, that was run with the rural and Navy Aerosol Model, (NAM) in various configurations. Best results were obtained when MODTRAN was tuned with the measured visibility values. When NAM was used without visibility tuning, MODTRAN tended to overestimate the transmission in low-visibility conditions, which was attributed {{to the presence of}} a non-maritime aerosol fraction. © 2015 SPIE...|$|R
40|$|Thunderstorms {{are always}} {{dangerous}} weather phenomena for flight safety and, irrespective of their nature, {{they have a}} negative impact on all aviation activities. Thunderstorm clouds can generate severe and rapid changes of various <b>meteorological</b> elements (<b>visibility,</b> cloudiness and cloud lower base, wind), sometimes to such a great extent that landing may become impossible. Thunderstorms are serious weather hazards in aviation and may produce great damage and even casualties. One such unfortunate aviation event took place in the vicinity of the Bucharest-Otopeni Aerodrome, on 30. 06. 2009, when a military aircraft, which was operating a training flight in the responsibility area of the Bucharest - Otopeni military aerodrome, was struck by lightning at local hour 18 : 20. The present study actually makes an inventory of the extremely hazardous flying conditions, by thoroughly analyzing the relevant weather reports and data, as well as visual and synoptic messages from that very day. All these materials showed that the airdrome of destination was under the influence of an anti-cyclonic ridge, which accounted for the very poor meteorological conditions. On such severe weather, although the crew members tried to avoid the Cumulonimbus clouds in which a severe thunderstorm was developing, the flight was put in danger since the aircraft was struck by lightning, which simply blurred out the radar system and, therefore, landmarks orientation became almost impossible, thus creating false perceptions to the pilots trying hard to stabilize the plane. ...|$|R
40|$|AbstractIn this paper, how to {{integrate}} Sentry™ Visibility sensor with Campbell Scientific CR 1000 series data loggers is described. The CR 1000 {{is the product}} of Campbell Scientific, which provides precision measurement capabilities in a rugged, battery-operated package. It consists of a measurement and control module and a wiring panel. Standard operating range is - 25 °C to+ 50 °C and it is widely used to get data. SVS 1 Sentry™ Visibility Sensor measures atmospheric <b>visibility</b> (<b>meteorological</b> optical range) by determining the amount of light scattered by particles (smoke, dust, haze, fog, rain, and snow) in the air that pass through the optical sample volume. The detailed integration steps between the data logger CR 1000 and SVS 1 Sentry™ Visibility Sensor is given. The steps include: 1) establish communication with SVS 1 Sentry Visibility sensor via RS- 232 port of PC: 2) write down the instrument communication parameter settings. 3) make necessary electrical and data line connections to data logger. 4) program the data logger to acquire data from Sentry™ Visibility Sensor. Practice proves that the acquisition method is feasible...|$|R
40|$|The {{purpose of}} this study was to {{determine}} if the utilizatioii offilters would improve target identiJcatioii performance on a television display. Inpiglit video tape was obtained of convoys of vehicular targets under different <b>meteorological</b> <b>visibility</b> conditions while using two types offilters and a no-filter cotiditioir on the television camera. The video tape was used in the laboratory for dynamic presentations on a rele-vision display. Analysis of variance revealed with five miles visibility no reliable difference Lt target identification slant ranges between filters 15 atid 29, but reliable differences between filter 15 arid no filter, arid between fiIter 29 and no filter. With seven miles <b>meteorological</b> <b>visibility</b> reliuble differences in target identification performance were found between all combinations of the conditions investigated. Maximum mean improvements in performance were as follows: witlifive miles visibility filter 15 increased target identification range 2600 feet farther than the no-filter condition. With seven miles visibility filter 29 increased target identification range 3685 feet feet farther than the no-filter condition...|$|E
40|$|In this paper, we briefly {{present the}} LCPC and INRETS {{work on the}} {{modeling}} {{of the effects of}} fog on road vision. Thereafter, we show how we exploit these various effects to build estimators of the visibility distance. Thus, we present our measurement technique of the <b>meteorological</b> <b>visibility</b> distance exploiting the effect of atmospheric veil. This method consists of a dynamic implementation of a model of light propagation in the atmosphere, which represents th...|$|E
40|$|Fog {{is often}} {{considered}} as a mere nuisance rather than a hazard. However, reduced <b>meteorological</b> <b>visibility</b> conditions cause accidents and transportation delays, with substantial ﬁnancial consequences. The visibility loss results from minute airborne droplets which scatter light, causing drastic alterations {{in the image of}} the environment perceived by vision systems, both human and artiﬁcial. Modeling the visual effects of dense fog makes it possible to simulate foggy conditions, in order to design and test countermeasures for improved safety and mobility. First, we introduce basic notions about the nature of fog and we brieﬂy review the microphysical models which usually serve to describe its droplet size distribution. Second, we explain how light interacts with fog droplets, and we present the optical descriptors which describe scattering and extinction phenomena. Third, we analyze how contrast is impaired by these phenomena {{in the image of the}} environment perceived by a vision system, and we propose and discuss a semi-analytic model of the visual effects of fog. Finally, we show applications of this model to the monitoring of the <b>meteorological</b> <b>visibility</b> through use of charge-coupled device cameras operating in the visible light range...|$|E
40|$|District 10 of the California Department of Transportation (Caltrans) {{encompasses}} an area {{of seasonal}} fog and dust-related visibility problems {{that have been the}} cause of numerous multi-car traffic collisions, many fatal. In 1990, motivated by the expansion of State Route 120 (SR 120) connecting Interstate Highway 5 (I- 5) and State Route 99 (SR 99), Caltrans proposed a sophisticated multi-sensor automated warning system as a means for reducing incidents in this high-traffic area. This proposal, and the significant development effort that followed, culminated in the implementation of Phase 1 of the Caltrans Automated Warning System, or “CAWS”, which entered service in November 1996. The system includes 36 traffic speed monitoring sites, 9 complete remote <b>meteorological</b> stations including <b>visibility</b> detectors, and nine changeable message signs for warning drivers. The system is controlled by a network of three computers in the District 10 Transportation Management Center (TMC), running specialized software developed by Caltrans Operations. This system is believed {{to be one of the}} most advanced of its kind in the world...|$|R
40|$|Abstract. In {{order to}} improve the safety of driving under {{different}} <b>visibility</b> <b>meteorological</b> conditions on the expressway, this paper analyses the composition and operation principle of the expressway lane departure warning and navigation system based on machine vision. And an effective lane mark identification algorithm suiting for different visibility situations is proposed. Firstly the image contrast between the expressway lane and its background is increased by using histogram equalization technology, improving detecting range of lanes and accuracy. Secondly the edges in the lane directions are detected by utilizing specific Sobel operator. In order to suit for different visibility situations and improve detecting efficiency, the method of maximum classes square error is applied to threshold segmentation. Finally, lane is abstracted according to expressway lane features after image Hough transform. Based on lanes identification, this paper designs a navigation algorithm of driving direction. This algorithm performs driving direction navigation decisions according to two characteristic parameters which are deviation angle and deviation distance. The experimental {{results indicate that the}} developed system exhibits good detection performances in recognition reliability and navigation decision. It has proved that this system has high accuracy, large detection range and high practicability...|$|R
40|$|An aviator may control an {{aircraft}} by viewing {{the world through}} the windscreen (visual flight) or with information from the cockpit instruments (instrument flight), depending upon <b>visibility,</b> <b>meteorological</b> conditions, and the competence of the pilot. It seems intuitively obvious that instrument flight should be far more challenging than visual flight. However, since the same pilot controls the same aircraft through the same air using the same stick-and-rudder input devices, the only difference is the way the same information is presented. Consequently, instrument flight is harder than visual flight only {{because of the way the}} instruments display the information. Each instrument displays one flight parameter and it is up to the pilot to convert the numeric value of the displayed parameter into useful information. We think that it is possible to use modern display technologies and computational capabilities to make instrument flight safer, easier, and more efficient, possibly even beyond that of visual flight. The challenge is design of the instruments. Using emerging principles of knowledge engineering derived from such areas as human-centered computing, cognitive task analysis, and ecological display design, we are designing a suite of aircraft cockpit instruments to enhance instrument flight performance. Our presentation will describe our approach, methodology, instrumentation, and some experimental results. We have used commercially available, off-the-shelf desk-top flight simulators for which we have developed precise flight performance measures that may have broad application for training and performance testing...|$|R
40|$|Abstract—An {{atmospheric}} visibility measurement system capable of quantifying {{the most common}} operating range of onboard exteroceptive sensors is a key parameter {{in the creation of}} driving assistance systems. This information is then utilized to adapt sensor operations and processing or to alert the driver that his onboard assistance system is momentarily inoperative. Moreover, a system capable of either detecting the presence of fog or estimating visibility distances constitutes in itself a driving assistance. In this paper, the authors present a technique to estimate the mobilized visibility distance through a use of onboard charge-coupled device cameras. The latter represents the distance to the most distant object on the road surface having a contrast above 5 %. This definition is very close to the definition of the <b>meteorological</b> <b>visibility</b> distance proposed by the International Commission on Illumination. The method combines the computations of local contrasts above 5 % and of a depth map of the vehicle environment using stereovision within 60 ms on a current-day computer. In this paper, both methods are described separately. Then, their combination is detailed. The method is operative night and day in every kind of meteorological condition and is evaluated; thanks to video sequences under sunny weather and foggy weather. Index Terms—Charge coupled devices camera, contrast impairment, driving assistance, fog, <b>meteorological</b> <b>visibility,</b> stereovision. I...|$|E
40|$|SUMMARY An {{atmospheric}} visibility measurement system capable of quantifying {{the most common}} operating range of onboard exteroceptive sensors is a key parameter {{in the creation of}} driving assistance systems. This information is then utilized to adapt sensor operations and processing or to alert the driver that the onboard assistance system is momentarily inoperative. Moreover, a system capable of either detecting the presence of fog or estimating visibility distances constitutes in itself a driving aid. In this paper, we rst present a review of di erent optical sensors likely to measure the visibility distance. We then present our stereovision based technique to estimate what we call the "mobilized visibility distance". This is the distance to the most distant object on the road surface having a contrast above 5 %. In fact, this de nition is very close to the de nition of the <b>meteorological</b> <b>visibility</b> distance proposed by the International Commission on Illumination (CIE). The method combines the computation of both a depth map of the vehicle environment using the "v-disparity " approach and of local contrasts above 5 %. Both methods are described separately. Then, their combination is detailed. A qualitative evaluation is done using di erent video sequences. Finally, a static quantitative evaluation is also performed thanks to reference targets installed on a dedicated test site. key words: <b>meteorological</b> <b>visibility,</b> fog, contrast, stereovision, sensor, driving assistance, intelligent transportation systems...|$|E
40|$|In this paper, {{we propose}} {{a new way}} to {{estimate}} fog extinction at night using a classification of fog depending on the forward scattering. We show that a characterization of fog based on the atmospheric extinction parameter only is not sufficient. This method works in dense fogs (<b>meteorological</b> <b>visibility</b> distances < 400 m) with a single image and three known light sources. The method is validated on synthetic images generated with a semi Monte-Carlo ray tracing software dedicated to fog simulation. We drove this study in simulated environment in order to help us designing a test site located outdoor. ...|$|E
40|$|A record-breaking {{dust storm}} {{originating}} from desert regions in northern Syria and Iraq {{occurred over the}} eastern Mediterranean in September 2015. In this contribution {{of a series of}} two articles (part 1, observations; part 2, atmospheric modeling), we provide a comprehensive overview of the aerosol conditions during this extreme dust outbreak in the Cyprus region. These observations are based on satellite observations (MODIS, moderate resolution imaging spectroradiometer) of aerosol optical thickness (AOT) and Ångström exponent, surface particle mass (PM 10) concentrations measured at four sites in Cyprus, visibility observations at three airports in southern Cyprus and corresponding conversion products (particle extinction coefficient, dust mass concentrations), EARLINET (European Aerosol Research Lidar Network) lidar observations of dust vertical layering over Limassol, particle optical properties (backscatter, extinction, lidar ratio, linear depolarization ratio), and derived profiles of dust mass concentrations. Maximum 550  nm AOT exceeded values of 5. 0, according to MODIS, and the mass loads were correspondingly >[*]  10  g m − 2 over Larnaca and Limassol during the passage of an extremely dense dust front on 8  September 2015. Hourly mean PM 10 values were close to 8000  µg m − 3 and the observed <b>meteorological</b> optical range (<b>visibility)</b> was reduced to 300 – 750  m at Larnaca and Limassol. The visibility observations suggest peak values of the near-surface total suspended particle (TSP) extinction coefficients of 6000  Mm − 1 and thus TSP mass concentrations of 10   000  µg m − 3. The Raman polarization lidar observations mainly indicated a double layer structure of the dust plumes (reaching to about 4  km height), pointing to at least two different dust source regions. Dust particle extinction coefficients (532  nm) already exceeded 1000  Mm − 1 and the mass concentrations reached 2000  µg m − 3 in the elevated dust layers on 7  September, more than 12  h before the peak dust front on 8  September reached the Limassol lidar station around local noon. Typical Middle Eastern dust lidar ratios around 40  sr were observed in the dense dust plumes. The particle depolarization ratio decreased from around 0. 3 in the lofted dense dust layers to 0. 2 {{at the end of the}} dust period (11  September), indicating an increasing impact of anthropogenic haze...|$|R
40|$|The {{connectivity}} {{and presence}} of free space optics (FSO) systems dependent on weather conditions especially in unusual haze have been studied. The attenuation and visibility have been analyzed using different formulas and {{compared with the}} experimental study. In an unusual haze condition, the attenuation of signal follows the same pattern as obtained from the theoretical analysis. Attenuation due to scattering, which has been expressed {{as a function of}} the link distance, wavelength and <b>meteorological</b> <b>visibility,</b> has been calculated from the visibility data collected at Senai airport in Malaysia. Maximum attenuation about 20 dB/km has been observed due to the unusual haze in Malaysia...|$|E
40|$|PM 2. 5 {{has been}} given special concern in recent years when the air quality {{monitoring}} station started recording. However, long-term PM 2. 5 concentration dynamic analysis cannot be taken with the limited observations. We therefore estimated the PM 2. 5 concentration using <b>meteorological</b> <b>visibility</b> data in Beijing. We found that 71 +/- 17 % of PM 10 were PM 2. 5, which contributed to visibility impairment (y = 332. 26 e(- 0. 232 x); R- 2 = 0. 75, P < 0. 05). We then reconstructed a time series of annual PM 2. 5 from 1973 to 2013, and examined its relationship with urbanization by indicators of population, gross domestic production (GDP), energy consumption, and number of vehicles. Concluded that 1) Meteorological conditions were not the major cause of PM 2. 5 increase from 1973 to 2013; 2) With population and GDP growth, PM 2. 5 increased significantly (R- 2 = 0. 5917, P < 0. 05; R- 2 = 0. 5426, P < 0. 05); 3) Intensive human activity could change air quality in a short period, as observed changes in the correlations of PM 2. 5 concentration with energy consumption and number of vehicles before and after 2004, respectively. The success of this research provides an easy way in reconstructing long-term PM 2. 5 concentration with limited PM 2. 5 observation and <b>meteorological</b> <b>visibility,</b> and insight the impact of urbanization on air quality...|$|E
40|$|Abstract. Estimating the {{atmospheric}} or <b>meteorological</b> <b>visibility</b> distance {{is very important}} for air and ground transport safety, as well as for air quality. However, there is no holistic approach to tackle the problem by camera. Most existing methods are data-driven approaches which perform a linear regression between the contrast in the scene and the visual range estimated by means of reference additional sensors. In this paper, we propose a probabilistic model-based approach which takes into account the distribution of contrasts in the scene. It is robust to illumination variations in the scene by taking into account the Lambertian surfaces. To evaluate our model, meteorological ground truth data were collected, showing very promising results. This works opens new perspectives in the computer vision community dealing with environmental issues. ...|$|E
40|$|A new {{innovative}} fog production device {{has been}} developed in close cooperation with partners of a European project called “FOG” funded by the EU. It is {{set up in the}} fog chamber of the road and bridges laboratory at Clermont-Ferrand. Most of the activities of this laboratory are dedicated to road safety but the facility is open to any other activity, such as environmental research. The recent developments consist in setting up a controllable device able to produce stable visibility levels and homogeneous fog, representative of various types of natural water droplet distribution. The fog characteristics were determined and compared to natural fog. Results are presented for a selection of conditions including stabilized visibility levels for dense fog, less than 50 metres <b>meteorological</b> <b>visibility</b> and two kinds of droplet distribution. Peer reviewe...|$|E
40|$|Abstract. The {{availability}} of atmosphere laser communication systems in dependence on weather conditions and on atmosphere laser link parameters, such as transmitted optical power, beam divergence, or link path distance, is discussed. A number of phenomena in the atmosphere, such as fog, can affect beam attenuation. In this work, {{the analysis and}} simulation of the empirical models (like Kruse, Vasseur, etc) indicate that the predicted attenuation of those models is similar and the main attenuation factor of 532 nm laser propagation in atmosphere is aerosol particle. Attenuation caused by fog, which can be expressed {{as a function of}} the link distance, wavelength, and <b>meteorological</b> <b>visibility,</b> is calculated from visibility data collected at several locations in Guilin. Statistical evaluation of the attenuation caused by fog and the power link margin calculated from atmosphere laser communication link parameters are used for calculating the link availability...|$|E
40|$|This {{dissertation}} {{deals with}} the problematic of the free space optical link availability determination. For the presumption of the free space optical link unavailability {{we have to know}} statistical distribution of the atmospheric attenuations. In this work is also presented the measurement of these atmospheric attenuations with the specially designed optical link. Measurement is using switching of the two separate transmitters with wavelengths of 830 nm and 1550 nm. Presented statistic distribution let us determine the suitability of the link in the chosen locality during its design. Comparison of our measurement with other models like model based on the <b>meteorological</b> <b>visibility</b> is also presented. The last part of this work is focused on the preconditions for the hi-speed network bit error rate determination. Sample of the bit error rate measurement obtained by our designed bit error rate tester is attached...|$|E
40|$|There {{are some}} {{deficiencies}} in the traditional daytime visibility calculation method using CCD digital camera: visibility observation value is accurate while using the artificial objects but expensive; nonzero internal reflection coefficient of the target lead to inaccurate visibility observation results when using natural objects as the target. A new daytime visibility algorithm based on color CCD digital camera is proposed in this paper: we use the color images obtained by the CCD digital camera, then estimate transmission of color digital image by using the knowledge of dark channel prior, and obtain the atmospheric attenuation coefficient form transmission to calculating visibility value. The experimental data show that the max-error of the proposed algorithm is less than 20 % which conform to the error provisions of WMO on the <b>meteorological</b> <b>visibility</b> instrument, and simple operation, without artificial target, low cost...|$|E
40|$|In camera-based Advance Driver Assistance System (ADAS) such as {{traffic sign}} recognition, some failure may be {{inferred}} by adverse meteorological conditions, in particular under foggy weather. This paper investigates {{the effects of}} reduced visibility from fog in an ADAS operating range, more specifically a traffic sign detection algorithm. For this purpose, we produced a database of synthetic images containing road signs with and without fog, that {{is intended to be}} shared with the scientific community. The database enables a study of the effects of reduced visibility from fog on a gradient-based geometrical model of traffic signs. After analysing the tolerance of the algorithm to additive noise and blurring, its performance is measured under increasing level of fog. Its operating range is measured with regard to the fog density: we discuss the way the distance required to detect a sign increases with the <b>meteorological</b> <b>visibility</b> distance and its impact on safety...|$|E
40|$|Atmospheric {{visibility}} is {{an important}} input for road and air transportation safety, {{as well as a}} good proxy to estimate the air quality. A model-driven approach is presented to monitor the <b>meteorological</b> <b>visibility</b> distance through use of ordinary outdoor cameras. Unlike in previous data-driven approaches, a physics-based model is proposed which describes the mapping function between the contrast in the image and the atmospheric visibility. The model is non-linear, which allows encompassing a large spectrum of applications. The model assumes a continuous distribution of objects with respect to the distance in the scene and is estimated by a novel process. It is more robust to illumination variations by selecting the Lambertian surfaces in the scene. To evaluate the relevance of the approach, a publicly available database is used. When the model is fitted to short range data, the proposed method is shown to be effective and to improve on existing methods. In particular, it allows envisioning an easier deployment of these camera-based techniques on multiple observation sites...|$|E
40|$|Abstract—In the {{framework}} of the French Research Action for Secure Driving (ARCOS) Project, we developed a system that uses in-vehicle charge-coupled device (CCD) cameras, aiming to estimate the visibility distance in adverse weather conditions, particularly fog situations. The topic of this paper is the validation of the system. First, we present Koschmieder’s model of apparent luminance of objects observed against the background sky on the horizon and deal with the definitions of the different visibility distances we use in our measurement framework, as well as the links that bind them. Then, we describe the two specific onboard techniques we designed to estimate the visibility distance. In the third section, we present a dedicated site and how we use it to validate the previous techniques. Finally, we give the results of a quantitative validation of our onboard techniques, using actual pictures of the validation site in foggy weather. Index Terms—Driving assistance, experimental validation, fog, intelligent transportation systems, <b>meteorological</b> <b>visibility.</b> I...|$|E
40|$|We propose an {{analytical}} model for backscattered luminance in fog and derive an expression for the visibility signal-to-noise ratio {{as a function}} of <b>meteorological</b> <b>visibility</b> distance. The model uses single scattering processes. It is based on the Mie theory and the geometry of the optical device (emitter and receiver). In particular, we present an overlap function and take the phase function of fog into account. The results of the backscattered luminance obtained with our analytical model are compared to simulations made using the Monte Carlo method based on multiple scattering processes. An excellent agreement is found in that the discrepancy between the results is smaller than the Monte Carlo standard uncertainties. If we take no account of the geometry of the optical device, the results of the model-estimated backscattered luminance differ from the simulations by a factor 20. We also conclude that the signal-to-noise ratio computed with the Monte Carlo method and our analytical model is in good agreement with experimental results since the mean difference between the calculations and experimental measurements is smaller than the experimental uncertainty...|$|E
40|$|An {{atmospheric}} visibility measurement system capable of quantifying {{the most common}} operating range of onboard exteroceptive sensors is a key parameter {{in the creation of}} driving assistance systems. This information is then utilized to adapt sensor operations and processing or to alert the driver that the onboard assistance system is momentarily inoperative. Moreover, a system capable of either detecting the presence of fog or estimating visibility distances constitutes in itself a driving aid. In this paper, we present a technique to estimate the mobilized visibility distance through use of onboard CCD cameras. This distance represents the distance to the most distant object on the road surface having a contrast above 5 %. This definition is very close to the definition of the <b>meteorological</b> <b>visibility</b> distance proposed by the International Commission on Illumination (CIE). Our method combines the computations of a depth map of the vehicle environment using stereovision and of local contrasts above 5 %. In this paper, both methods are described separately. Then, their combination is detailed. Our method is operative in every kind of meteorological conditions and is evaluated thanks to video sequences under sunny weather and foggy weather. ...|$|E
40|$|The {{date of receipt}} and {{acceptance}} will be inserted by the editor Abstract In this article, we will present a technique for measuring visibility distances under foggy weather conditions using a camera mounted onboard a moving vehicle. Our research has focused in particular {{on the problem of}} detecting daytime fog and estimating visibility distances; thanks to these efforts, an original method has been developed, tested and patented. The approach consists of dynamically implementing Koschmieder’s Law. Our method enables comput-ing the <b>meteorological</b> <b>visibility</b> distance, a measure defined by the International Commission on Illumi-nation (CIE) as the distance beyond which a black object of an appropriate dimension is perceived with a contrast of less than 5 %. Our proposed solution is an original one, featuring the advantage of utilizing a single camera and ne-cessitating the presence of just the road and sky in the scene. As opposed to other methods that require the explicit extraction of the road, this method offers fewer constraints by virtue of being applicable with no more than the extraction of a homogeneous surface containing a portion of the road and sky within the image. This image preprocessing also serves to identify the level of compatibility of the processed image with the set of Koschmieder’s model hypotheses...|$|E
40|$|Highly {{integrated}} and increasingly complex video-based driver assistance systems are rapidly developing nowadays. Following the trend towards autonomous driving, {{they have to}} operate not only under advantageous but also under adverse conditions. This includes sight impairments caused by atmospheric aerosols such as fog or smog. It {{is an important part}} of environmental understanding to thoroughly analyze the optical properties of these aerosols. The aim of this thesis is to develop models and algorithms in order to estimate <b>meteorological</b> <b>visibility</b> in homogeneous daytime fog. The models for light transport through fog are carefully derived from the theory of radiative transfer. In addition to Koschmieder's well-established model for horizontal vision, a recursively-defined sequence of higher-order models is introduced which yields arbitrarily good approximations to the solutions of the radiative boundary problem. Based on the radiative transfer models, visibility estimation algorithms are proposed which are applicable to data captured by a driver assistance front camera. For any one of these algorithms, the recording of luminances from objects observed at distinct distances is required. This data can be acquired from moving objects being tracked as well as from depth-extended homogeneous objects such as the road. The resulting algorithms supplement each other with respect to different road traffic scenarios and environmental conditions. All given algorithms are extensively discussed and optimized regarding their run-time performance in order to make them applicable for real-time purposes. The analysis shows that the proposed algorithms are a useful addition to modern driver assistance cameras...|$|E
