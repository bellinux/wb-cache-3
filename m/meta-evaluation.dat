126|9|Public
5000|$|Finally, this {{approach}} is suitable for <b>meta-evaluation</b> and may be combined with other approaches which are participatory or expertise- oriented.|$|E
50|$|Before Lisp had macros, it had {{so-called}} FEXPRs, function-like operators whose inputs {{were not}} the values computed by the arguments but rather the syntactic forms of the arguments, and whose output were values {{to be used in}} the computation. In other words, FEXPRs were implemented at the same level as EVAL, and provided a window into the <b>meta-evaluation</b> layer. This was generally found to be a difficult model to reason about effectively.|$|E
5000|$|In the {{critical}} early weeks following the tsunami, American Red Cross-trained volunteers in {{psychological first aid}} developed programs in Maldives, Sri Lanka, Indonesia and India. These psychosocial programs initiated by the American Red Cross team planned to provide service to the {{children and their families}} in communities and schools. Five years later psychosocial support services have been provided to more than 733,700 people). Dr. Prewitt Diaz served as the Global Psychosocial Support technical advisor since 2005. He developed the response strategy for the 2005 tsunami, and led a team of specialist in Indonesia, India, Maldives, and Sri Lanka. The project lasted five years, a <b>meta-evaluation</b> reports that “the PSP project was adapted to the local culture in each country. The impact was the large number of ordinary people, especially women, got involved in a project that brought hope, taught them new skills, and increased their feeling of self-efficacy. In the five-year duration the PSP program served 733,700 and trained over 29,000 PSP technicians ...|$|E
40|$|Lonely {{adolescents}} {{report that}} they have poor social skills, but it is unknown whether {{this is due to}} an accurate perception of a social skills deficit, or a biased negative perception. This is an important distinction, as actual social skills deficits require different treatments than biased negative perceptions. In this study, we compared self-reported social skills evaluations with peer-reported social skills and <b>meta-evaluations</b> of social skills (i. e., adolescents' perceptions of how they believe their classmates evaluate them). Based on the social skills view, we expected negative relations between loneliness and these three forms of social skills evaluations. Based on the bias view, we expected lonely adolescents to have more negative self- and <b>meta-evaluations</b> compared to peer-evaluations of social skills. Participants were 1342 adolescents (48. 64 % male, M (age) = 13. 95, SD =. 54). All classmates rated each other in a round-robin design to obtain peer-evaluations. Self- and <b>meta-evaluations</b> were obtained using self-reports. Data were analyzed using polynomial regression analyses and response surface modeling. The results indicated that, when self-, peer- and <b>meta-evaluations</b> were similar, a greater sense of loneliness was related to poorer social skills. Loneliness was also related to larger discrepancies between self- and peer-evaluations of loneliness, but not related to the direction of these discrepancies. Thus, for some lonely adolescents, loneliness may be related to an actual social skills deficit, whereas for others a biased negative perception of one's own social skills or a mismatch with the environment may be related to their loneliness. This implies that different mechanisms may underlie loneliness, which has implications for interventions...|$|R
50|$|Research methodologies {{utilized}} by Rusch have included secondary {{analysis of the}} outcomes reported by the federally mandated Longitudinal Study of Youth in Transition, matched-pairs analysis {{of the effectiveness of}} a high school education, qualitative analysis of model programs, and <b>meta-evaluations</b> of model program outcomes. Several of Rusch’s publications identified new methods of inquiry, including meta-analysis using repeated measures, withdrawal designs for use with intra-subject experimental designs, and new conceptual frameworks to better understand cost-benefit analysis of model programs.|$|R
40|$|Purpose – To {{highlight}} {{the challenges and}} identify options to improve school health evaluations. Design/methodology/approach – This editorial draws on recent international and national <b>meta-evaluations</b> and {{the experiences of the}} author. Findings – A simple set of questions is needed for discussion between those commissioning evaluations and those conducting them to make school health evaluations more effective and relevant to stakeholders. Originality/value – The paper identifies important steps which need to be considered in undertaking evaluations of school health interventions. <br /...|$|R
40|$|In {{this paper}} we draw on impact {{assessment}} {{work of the}} Australian Centre for International Agricultural Research (ACIAR) to present an example of <b>meta-evaluation</b> – an evaluation of evaluations – in an agricultural research, development and extension setting. We explore quality issues relating to evaluation studies {{in the context of}} government institutions. Program evaluation standards (PES) are divided into categories of utility, feasibility, propriety and accuracy to provide a framework for the <b>meta-evaluation.</b> The PES are presented as a universal measure of evaluation study quality. The intent of using them here is to judge the adequacy of PES as a universal quality measure or <b>meta-evaluation</b> base and to extract useful insights from ACIAR program evaluation activities when developing a <b>meta-evaluation</b> model for the Limpopo Department of Agriculture (LDA). Our <b>meta-evaluation</b> is undertaken of 63 impact assessment reports. First, the literature guiding the conduct of a <b>meta-evaluation</b> is reviewed. Second, an assessment (the <b>meta-evaluation)</b> of the evaluation studies is carried out for 19 sampled reports from a population of relevant reports fitting the dimension of the analysis, and results are presented and discussed. Also, lessons learned are presented, using the framework provided by the <b>meta-evaluation</b> criteria. Third, taking into account the lessons learned, implications are drawn for a proposed systematic <b>meta-evaluation</b> of the LDA. Finally, we conclude that all the PES cannot be equally emphasized in a <b>meta-evaluation</b> model. At ACIAR, 70 % of the standards were at least partially addressed. Therefore, we succeeded in using the PES in judging the ACIAR evaluation quality. As such, they can be an important base when developing an evaluation model but should be applied in a contextualized manner. <b>Meta-evaluation,</b> Evaluation Quality, Program Evaluation Standards, Evaluation Model, Australian Centre for International Agricultural Research, Limpopo Department of Agriculture (South Africa), International Development,...|$|E
40|$|Abstract: It {{has become}} a {{standard}} in major high-stakes evaluations to commission an independent review {{to determine whether the}} evaluation meets generally accepted standards of quality. This is called a <b>meta-evaluation.</b> Given the historic importance of the Evaluation of the Paris Declaration, the Management Group commissioned a <b>meta-evaluation</b> of the evaluation. The <b>meta-evaluation</b> concluded that the findings, conclusions, and rec-ommendations presented in the Paris Declaration Evaluation adhered closely and rigorously to the evaluation evidence col-lected and synthesized. The <b>meta-evaluation</b> included an as-sessment of the evaluation’s strengths, weaknesses, and lessons. This article describes how the <b>meta-evaluation</b> was designed and implemented, the data collected, and the conclusions reached. Résumé: Il est devenu courant, dans les évaluations comportant des en-jeux majeurs, de commander un audit indépendant chargé d...|$|E
40|$|<b>Meta-evaluation</b> {{can be seen}} as {{a quality}} control measure of {{policies}} or programs. For that purpose, a formal methodology is used when assessing the quality of an evaluation work. The presented <b>meta-evaluation</b> is based on an adapted version of the evaluation standards used by DEGEVAL (German evaluation society). The well-balanced design of the DEGEVAL standards makes them widely applicable and useful also for conducting meta-evaluations. This paper presents the results of a <b>meta-evaluation</b> undertaken on the evaluation of the German Federal Organic Farming Scheme. Concerning most sections the quality of the underlying study is excellent...|$|E
40|$|During {{the last}} decade, {{increasingly}} more {{public and private}} actors, in both developed or developing countries, have supported initiatives 1 : 1 in education (a computer for each student). This initiatives represent a qualitative leap from the prior educative experiences with the {{information and communication technologies}} (TIC), because each child has access to a personal device, normally portable, mini laptops or mobile devices. The document tries to systematize the most outstanding evidence about such initiatives from the official web sites, program valuations and academic <b>meta-evaluations.</b> Includes information about the expectations of these policies, the designs of the programs and the challenges for an effective implementation of the model 1 : 1. Due to the limited evidence available, the document emphasizes some doubts, without response,about effectiveness-cost and educational impacts that these programs have in education...|$|R
40|$|We {{present a}} novel {{approach}} for efficiently evaluating the performance of retrieval models and introduce two evalua-tion metrics: Distributional Overlap (DO), which com-pares the clustering of scores of relevant and non-relevant documents, and Histogram Slope Analysis (HSA), which examines the log of the empirical distributions of relevant and non-relevant documents. Unlike rank evaluation met-rics such as mean average precision (MAP) and normalized discounted cumulative gain (NDCG), DO and HSA only re-quire calculating model scores of queries and a fixed sample of relevant and non-relevant documents rather than scoring the entire collection, even implicitly {{by means of an}} inverted index. In experimental <b>meta-evaluations,</b> we find that HSA achieves high correlation with MAP and NDCG on a mono-lingual and a cross-language document similarity task; on four ad-hoc web retrieval tasks; and on an analysis of ten TREC tasks from the past ten years. In addition, when evaluating latent Dirichlet allocation (LDA) models on doc-ument similarity tasks, HSA achieves better correlation with MAP and NCDG than perplexity, an intrinsic metric widely used with topic models...|$|R
40|$|We {{present the}} first {{evaluation}} of the utility of automatic evaluation metrics on surface realizations of Penn Treebank data. Using outputs of the OpenCCG and XLE realizers, along with ranked WordNet synonym substitutions, we collected a corpus of generated surface realizations. These outputs were then rated and post-edited by human annotators. We evaluated the realizations using seven automatic metrics, and analyzed correlations obtained between the human judgments and the automatic scores. In contrast to previous NLG <b>meta-evaluations,</b> we find {{that several of the}} metrics correlate moderately well with human judgments of both adequacy and fluency, with the TER family performing best overall. We also find that all of the metrics correctly predict {{more than half of the}} significant systemlevel differences, though none are correct in all cases. We conclude with a discussion of the implications for the utility of such metrics in evaluating generation in the presence of variation. A further result of our research is a corpus of post-edited realizations, which will be made available to the research community. ...|$|R
40|$|Recent {{studies suggest}} that <b>meta-evaluation</b> can be {{valuable}} in developing new approaches to evaluation, building evaluation capacities, and enhancing organizational learning. These new extensions {{of the concept of}} <b>meta-evaluation</b> are significant, given the growing emphasis on improving the quality and effectiveness of evaluation practices in the South Asian region. Following a review of the literature, this paper presents a case study of the use of concurrent <b>meta-evaluation</b> in the four-year project Assessing Communication for Social Change which developed and trialled a participatory impact assessment methodology in collaboration with a development communication Non-government organization (NGO) in Nepal. Key objectives of the <b>meta-evaluation</b> included to: continuously develop, adapt and improve the impact assessment methodology, Monitoring and Evaluation (M&E) systems and process and other project activities; identify impacts of the project; and build capacities in critical reflection and review. Our analysis indicates that this <b>meta-evaluation</b> was essential to understanding various constraints related to the organizational context that affected the success of the project and the development of improved M&E systems and capacities within the NG...|$|E
40|$|A Data Fusion Framework For <b>Meta-Evaluation</b> of Intelligent Transportation System Effectiveness William M. Evanco JO 90 March 1996 Washington Project No. : Contract No. : Sponsor: 0495 18 B 40 A DTFH 61 - 95 -C- 00040 Federal Highway Administration This study {{presents}} {{a framework for}} the <b>meta-evaluation</b> of Intelligent Transportation System effectiveness. The framework is based on data fusion approaches that adjust for data biases and violations of other standard statistical assumptions. Operational test characteristics that have a bearing on <b>meta-evaluation</b> methodology are identified {{in the context of}} the experimental paradigm. Data fusion approaches are presented for various types of measures of effectiveness and techniques for handling biases of various kinds are developed. Keywords: <b>meta-evaluation,</b> operational tests, data fusion THIS INFORMAL PAPER PRESENTS TENTATIVE INFORMATION FOR LIMITED DISTRIBUTION MCF 1900 05 / 92 TABLE OF CONTENTS SECTION PAGE 1 Introduction l-l 1. 1 Purpose o [...] ...|$|E
40|$|ALNAP {{developed}} this Quality Proforma in 2000 / 2001 {{as a way}} of assessing humanitarian evaluation reports drawing on current thinking and good practice in the evaluation of humanitarian action. 1 The overall aim of the Quality Proforma is {{to improve the quality of}} humanitarian evaluation practice. It does this by: 1. Providing an assessment tool for ALNAP’s annual <b>meta-evaluation</b> of humanitarian evaluation reports as part of its Review of Humanitarian Action 2 series. The <b>meta-evaluation</b> seeks to identify trends in the quality of humanitarian evaluations, identifying both good and weak practices. 3 2. Providing a checklist for evaluation managers and evaluators. The Quality Proforma has undergone refinements during its application in four ALNAP Reviews between 2001 and 2003 / 4, in order to strengthen consistency in interpretation and usage and reflect developments in current thinking in the evaluation of humanitarian action. This version of the Proforma has undergone a process of simplification and reordering for the Review of Humanitarian Action in 2004 in order to make it more accessible. 3. <b>Meta-evaluation</b> process Each evaluation report included in ALNAP’s <b>meta-evaluation</b> is rated against the Quality Proforma b...|$|E
30|$|Distance higher {{education}} is another important modality used to increase coverage since it ensures that quality requirements are not inferior {{to those of the}} equivalent face-to-face education. Early distance education models were focused on content. Printed or audiovisual materials were made available to students who had sporadic interactions with tutors and counselors in centralized learning centers distributed in the regions targeted. In this modality, pedagogical and technological factors designed for this purpose {{are at the center of}} innovations (Galvis, 1982). The digital technologies allow for the creation and operation of a virtual (online) campus which promotes synchronous and asynchronous interaction with the available resources between all sides of the educational process (Galvis & Pedraza, 2013). This provides the opportunity for learners to receive support, which is predominately virtual, in learning centers. It is worth noting that quality in this modality is also regulated by standards and procedures provided by accreditation entities, allowing for characterization and differentiation of what is offered in this modality and between the organizations (Tanweer & Qadri, 2016). <b>Meta-evaluations</b> on the use of this modality (Means, Toyama, Murphy, Bakia, & Jones, 2010) have helped to overcome resistance or skepticism about its use in HEIs. These evaluations state that HEIs do not only seek to expand coverage, but to improve educational quality; online education can make learning more flexible, and thus more effective.|$|R
40|$|Sustainability {{indicator}} {{programs in}} developing countries are the poor cousin of ecological indicator research. While {{an enormous number of}} indicators for the monitoring of sustainable development exists, few <b>meta-evaluations</b> on these measurements have been conducted {{in developing countries}}. Yet, researchers developing new programs face the question: how shall we design our monitoring instrument to respond to the local challenges. By presenting a qualitative meta-performance evaluation of seven sustainability indicator programs on the municipal level in developing countries of Asia, we identify crucial success factors in this contribution. The research draws on 41 expert interviews in Indonesia, Thailand, China, and India, as well as on program-related documents. In the presented case studies, local contexts are intended to be diverse: obtained results should map success factors in different settings. A context-related list of good-practice factors is derived from the interview material via a Qualitative Content Analysis and assessed against the data. We identify crucial strengths and weaknesses of sustainability indicator programs in six dimensions and link the success factors to their contexts. The results include innovative approaches to indicator types, data collection and data quality control, and a correlation between the anchoring of programs in approved development plans and long-term implementation. The results can provide valuable guidance to users of existing sustainability indicator programs and planners of new programs...|$|R
40|$|This thesis {{presents}} {{an exploration of}} the operationalization of empowerment outcomes in research on transformative participatory evaluations, focusing on the context of international development evaluation. Covering a 15 year period from 1999 and 2014, through the examination of the empirical research literature, the study explores: 1) how empowerment outcomes are measured, 2) {{the extent to which these}} outcomes demonstrate empowerment principles, and 3) which factors and conditions appear to enable or detract from the attainment of these outcomes. I found that the current state of the empirical research on transformative participatory evaluation to be largely comprised of reflective case narratives that rely solely on scarcely documented qualitative methods. In general, transformative outcomes do tend to mirror empowerment principles such as ownership, inclusion, democracy, and social justice. Finally, I found that various factors and conditions are critical to the reported attainment of transformative outcomes, particularly in relation to the local program context, for example, reforms in local and international governments that support increased local control over resources and governance, organizational structures and priorities that are congruent with empowerment objectives, and previous experience with empowerment processes. I also highlighted deficiencies in the current empirical research and call on the evaluation community to improve research on transformative approaches to participatory evaluation by suggesting critical areas for practice and writing. These include strengthening research designs and the use of <b>meta-evaluations,</b> further defining and clarifying key terms, and providing rich detail to facilitate further learning in this area...|$|R
40|$|The {{need for}} greater {{understanding}} of assessment practices and models highlights a deficit of an up-to-date <b>meta-evaluation</b> model, whilst articulating with new phases in Information Society (IS) development. This paper aims to discuss the <b>meta-evaluation</b> model and frameworks that were created to explain the relations between IS transitions {{and the development of}} library performance evaluation models in Portugal (1970 – 2013). The research is based on a qualitative methodology supported by a combination of literature review with the construction and application of conceptual models and frameworks. The <b>meta-evaluation</b> model of the impact of transitions on library performance evaluation provides an adequate representation and explanation of relationships between IS transitions and library performance evaluation models. The CLPET (Categorizing Library Performance Evaluation Typologies) Matrix, as well as the relational framework that was developed proved to be useful analytical tools. This paper highlights the current transition of performance models into a more holistic performance management, clarifying that diverse uses and components of performance are strongly linked to IS dynamics. It will also enable readers to discuss the impact of <b>meta-evaluation</b> models as a strong instrument to support the challenges of visions, strategies and best practices shifted over time...|$|E
40|$|The {{general purpose}} of this study was to present a model of <b>meta-evaluation</b> applied to the {{performance}} audit of the Brazilian Court of Audit. This consisted of meta-evaluating its procedures such as criteria, standards, validity, trustworthiness and its results. Auditing, evaluation and <b>meta-evaluation</b> were also conceptualized. The theoretical approach used was based on qualitative methods and their procedures: synthesis of analysis content, deductive grouping criteria from Joint Committee criteria and Qualitative Synthesis Studies. <b>Meta-evaluation</b> was defined as evaluation from other evaluation considering its aspects: methodology; subject selection, purpose, criteria and results analysis. Ten audits of government performance were analyzed. The results showed weakness of methods and techniques used to evaluate the program context and criteria related to applying audit methods and techniques. To conclude, other difficulties of the audit process were demonstrated and there are also suggestions on how to improve it...|$|E
40|$|Includes abstract. Includes bibliographical references. This study investigates a naturalistic {{evaluation}} model’s {{ability to}} assess the outcomes and impact of development interventions in a rigorous manner. The study was undertaken {{by means of a}} <b>meta-evaluation</b> of five evaluation projects conducted by a socio-economic development consultancy situated in Cape Town. This <b>meta-evaluation</b> process was based upon four evaluation quality or ‘trustworthiness’ criteria proposed by Guba and Lincoln (1989); namely, credibility, transferability, dependability and confirmability. These four criteria were conceptualised, operationalised and applied to the evaluation projects under review...|$|E
40|$|In this paper, {{we report}} on the results of a {{full-size}} evaluation campaign of various MT systems. This campaign is novel compared to the classical DARPA/NIST MT evaluation campaigns in the sense that French is the target language, and that it includes an experiment of <b>meta-evaluation</b> of various metrics claiming to better predict different attributes of translation quality. We first describe the campaign, its context, its protocol and the data we used. Then we summarise the results obtained by the participating systems and discuss the <b>meta-evaluation</b> of the metrics used...|$|E
40|$|As part of {{a larger}} {{research}} project about right-wing extremism and its causes and countermeasures, this article assesses the quality of existing evaluation studies in Switzerland, Germany, the US and other countries in order to synthesize their results. It presents the results of a <b>meta-evaluation</b> of measures against right-wing extremism in areas including education and social work. The <b>meta-evaluation</b> follows the professional evaluation standards of the Swiss Evaluation Society (SEVAL Standards). Analysis of the quality of selected evaluation studies in the field of measures against right-wing extremism allows for an assessment of the value of their results. The <b>meta-evaluation</b> covers 12 evaluation reports, enabling a description of the current practice of evaluation of measures taken against right-wing extremism in selected countries. The article also presents evidence about the usefulness of the SEVAL Standards in an applied setting. Thus the article provides background information on both evaluation of measures against right-wing extremism and the applicability of evaluation standards...|$|E
40|$|This {{research}} {{project has been}} designed to provide a national mapping and <b>meta-evaluation</b> of the key features of &# 8220;safe at home&# 8221; programs that enhance safety and prevent homelessness for women and their children who have experienced domestic and family violence. The project was undertaken in two phases. The first phase involved the preparation of a state of knowledge paper providing a comprehensive review of the literature and a national mapping of current &# 8220;safe at home&# 8221; programs by jurisdiction, including details of legislation underpinning &# 8220;safe at home&# 8221; programs in each jurisdiction. In the second phase, the authors undertook a <b>meta-evaluation</b> of select evidence about Australian &# 8220;safe at home&# 8221; programs and practices. This report presents the results of the <b>meta-evaluation.</b> It concludes with recommendations for future &# 8220;safe at home&# 8221; evaluations, as well as key considerations for &# 8220;safe at home&# 8221; responses in terms of core program elements, contexts and circumstances...|$|E
40|$|The {{validation}} of biclustering algorithms remains a challenging task, {{even though a}} number of measures have been proposed for {{evaluating the quality of}} these algorithms. Although no criterion is universally accepted as the overall best, a number of <b>meta-evaluation</b> conditions to be satisfied by biclustering algorithms have been enunciated. In this work, we present MOCICE-BCubed F$_ 1 $, a new external measure for evaluating biclusterings, in the scenario where gold standard annotations are available for both the object clusters and the associated feature subspaces. Our proposal relies on the so-called micro-objects transformation and satisfies the most comprehensive set of <b>meta-evaluation</b> conditions so far enunciated for biclusterings. Additionally, the proposed measure adequately handles the occurrence of overlapping in both the object and feature spaces. Moreover, when used for evaluating traditional clusterings, which are viewed as a particular case of biclustering, the proposed measure also satisfies the most comprehensive set of <b>meta-evaluation</b> conditions so far enunciated for this task...|$|E
40|$|Based on {{the impact}} of {{learning}} assessment on educational processes, the idea of assessing learning evaluations to turn evaluation into a tool for change in education becomes relevant (Ravela, 2009). This article intends to communicate the methodological design to apply a <b>meta–evaluation</b> on two subjects, English for Special Purposes and Basic Mathematics, which belong to the Accounting studies at Universidad Nacional del Litoral. The investigative objective is to evaluate the learning evaluations, i. e. <b>meta–evaluation,</b> in the above mentioned subjects to reach two goals. On the one hand, identify the reinforcement or changes necessary to improve the quality of the evaluation processes so that they become evaluation as learning, evaluation for learning and evaluation of learning. On the other hand, determine the epistemological, didactic, cultural and technological conditions adequate to promote the improvement of teaching and learning in those subjects. The complete methodological design has the characteristics of an illuminative evaluation (Parlett and Hamilton, 1972), which assumes a research line oriented to discovery and application (Arnal et ál., 1992). The <b>meta–evaluation</b> design presented here can become an institutional strategy for academic decision–making that envisages the continuous construction of a culture of self–reflection on learning quality...|$|E
40|$|The {{new policy}} {{strategy}} of ‘gender mainstreaming ’ poses particular {{challenges for the}} evaluation of public gender-equality policies. To elaborate on this issue, a first step is to analyse the evaluation of those public gender-equality policies that have formally adopted the gender mainstreaming strategy. In this article, results are summarized from a <b>meta-evaluation</b> of 11 evaluation processes of gender-equality plans implemented between 1995 and 1999, both at regional and national levels in Spain. This <b>meta-evaluation</b> focused on analysing the evaluation processes rather than the outcomes of those evaluations. First, the different types of evaluation carried out in the 11 studies are discussed. Second, some contextual factors are identified as influencing elements in the evaluations. Third, some conclusions and lessons learnt are presented, using the framework provided by the <b>meta-evaluation</b> criteria previously established. Finally, taking into account those lessons, a discussion of the evaluation of gender mainstreaming is presented, elaborating on the ways in which gender mainstreaming strategies and gender perspective can be evaluated and which should be used to conduct useful evaluations...|$|E
40|$|The Brazilian Ministry of Social Development and Fight against Hunger (MDS) {{regularly}} {{promotes the}} evaluation of its social programs, such as those developed in the Reference Centers for Social Assistance (CRAS). Such evaluations make use of a web system that supports the collection and processing of information {{as well as the}} dissemination of its results to local, regional and central government officials through the so-called CRAS Census. A <b>meta-evaluation</b> of the CRAS 2008 Census was carried out based on criteria specified by the Joint Committee (1994), from which we elicited requirements that enabled improvements of the web system. The article reports new requirements elicited from the <b>meta-evaluation</b> of the CRAS 2008 Census, held in the period 2009 - 2010. The approach of <b>meta-evaluation</b> as an alternative source of requirements elicitation took into consideration results from evaluations of social programs in order to identify system problems without the usual need of intense interaction with users. This approach revealed opportunities for improvements in the evaluation process that led to the elicitation of requirements for the computerized system. Some of the elicited features were incorporated into the Census 2010 and others may be incorporated in future censuses...|$|E
40|$|The {{evaluation}} of the Paris Declaration (PD) {{is one of the}} most important and challenging evaluative undertakings of the past decade in the aid sector. The PD evaluation commissioned by the OECD/DAC Evaluation Network consists of a set of independent crosscountry and donor evaluations which were carried out in two phases. The scope and importance of this evaluation makes it a particularly suitable subject for a <b>meta-evaluation.</b> Our '{{evaluation of}} the evaluation’ complements the official <b>meta-evaluation</b> of the synthesis report in that it assesses all country evaluation reports available in English (15 out of 21 reports) using the OECD/DAC Evaluation Quality Standards. Two research questions are central in our undertaking: Is the quality of the country evaluation reports good enough to be included in the synthesis report? Do the reports properly comply with the evaluation framework to permit comparison of evaluation across countries? The findings of the <b>meta-evaluation</b> demonstrate that comparability of country evaluation reports is satisfactory. The quality of evidence, however, is questionable, due to various limitations and constraints that plagued several country evaluations. Therefore, the inclusion of some of the country reports in the evaluation synthesis report is questionable. ...|$|E
40|$|This paper {{presents}} a new methodology for <b>meta-evaluation</b> that {{makes use of}} fuzzy sets and fuzzy logic. It is composed of a data collection instrument and of a hierarchical fuzzy inference system. The advantages of the proposed methodology are: (i) the instrument, which allows intermediate answers; (ii) the inference process ability to adapt to specific needs; and (iii) transparency, {{through the use of}} linguistic rules that facilitate both the understanding and the discussion of the whole process. The rules are based on guidelines established by the Joint Committee on Standards for Educational Evaluation (1994) and also represent the view of experts. The system can provide support to evaluators that may lack experience in <b>meta-evaluation.</b> A case study is presented as a validation of the proposed methodology...|$|E
40|$|This {{field study}} {{discusses}} curriculum evaluation in technical and further education in Australia and the Australian Capital Territory. The {{study has been}} developed to include {{a case study of}} evaluation undertaken at the Bruce College of Technical and Further Education. The case study forms an integra 1 part of the field study and provides the focus for discussion of evaluation standards developed by Stufflebeam and others (joint Committee, 1981) for evaluation and <b>meta-evaluation.</b> The standards suggested by the Joint Committee (1981) were applied to the case study to examine the value of the case study itself as a form of a <b>meta-evaluation,</b> together with the advantages and limitations of the standards themselves. Following this analysis a modified list of standards has been prepared for application in the TAFE sector...|$|E
40|$|A <b>meta-evaluation</b> is an {{assessment}} of evaluation prac-tices. Meta-evaluations include assessments of validity and usefulness {{of two or more}} studies focused on the same issues. This article describes specific recommendations on how to achieve effective performance audits of government tourism-marketing departments and programs, as well as how to achieve effective tourism-marketing programs...|$|E
40|$|Of aCf fresH fOOd vOuCHer PrOgraMMes Many {{people have}} contributed to the {{development}} of the <b>Meta-Evaluation</b> of ACF’s Fresh Food Voucher Programmes, and their inputs were received with much appreciation, though it is impossible to name them all. Thanks to all staff and country programme members who have contributed with discussions and ideas...|$|E
40|$|<b>Meta-evaluation</b> is {{a process}} which symbolically evaluates an actor and checks {{to see whether the}} actor {{fulfills}} its contract (specification). A formalism for writing contracts for actors with side-effects is presented. <b>Meta-evaluation</b> of actors with side-effects is carried out by using situational tags which denotes a situation (local state of an actor systems at the moment of the transmissions of messages). And also it is illustrated how the situational tags are used for providing the termination of the activation of actors. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for the laboratory's artificial intelligence research is provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N 00014 - 70 -A- 0362 - 0004. MIT Artificial Intelligence Laborator...|$|E
40|$|This poster {{investigates the}} use of {{theoretical}} benchmarks to describe the matching functions of XML retrieval systems and the properties of specificity and exhaustivity in XML retrieval. Theoretical benchmarks concern the formal representation of qualitative properties of IR models. To this end, a Situation Theory framework for the <b>meta-evaluation</b> of XML retrieval is presented...|$|E
40|$|This paper {{outlines}} {{our use of}} participatory {{action research}} (PAR), <b>meta-evaluation,</b> {{information and communication technologies}} (ICTs) and online collaboration tools to collaboratively plan, manage and evaluate the research project: Assessing Communication for Social Change: A New Agenda in Impact Assessment (ACSC). The main aim of this project is to develop, test and rigorously evaluate a participatory approach t...|$|E
