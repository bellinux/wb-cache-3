16|40|Public
50|$|The Plessey System 250 was {{the first}} {{operational}} computer system to implement capability-based addressing, and the first sold commercially. It {{was designed as a}} real-time controller for computerized telephone switching systems. It had a <b>multiprocessing</b> <b>architecture.</b>|$|E
50|$|In October 2014, Intaver {{released}} version 6 {{that included}} a new project portfolio risk management client/server applicationRiskyProject Enterprise to the existing RiskyProject Professional and Lite. RiskyProject 6 also implemented <b>multiprocessing</b> <b>architecture,</b> which significantly improved performance of Monte Carlo simulations.|$|E
40|$|A <b>multiprocessing</b> <b>architecture</b> for {{performing}} real time {{monitoring and analysis}} using knowledge-based problem solving techniques is discussed. To handle asynchronous inputs and perform in real time, the system consists of three or more separate processes which run concurrently on one or more processors and communicate via a message passing scheme. The Data Management Process gathers, compresses, scales and sends the incoming telemetry data to other tasks. The Inference Process consists of a proprietary high performance inference engine that runs at 1000 rules per second using telemetry data to perform real time analysis on the state and health of the Space Telescope. The <b>multiprocessing</b> <b>architecture</b> has been interfaced to a simulator {{and is able to}} process the incoming telemetry in real time...|$|E
40|$|<b>Multiprocessing</b> <b>architectures</b> provide {{hardware}} for executing multiple tasks simultaneously via {{techniques such}} as simultaneous multithreading and symmetric multiprocessing. The problem addressed by this paper is that even when tasks that are executing concurrently do not communicate, they may interfere by affecting each otherâ€™s timing. For cyberphysical system applications, such interference can nullify many of the advantages offered by parallel hardware. In this paper, we argue for temporal semantics in layers of abstraction in computing. This {{will enable us to}} achieve temporal isolation on <b>multiprocessing</b> <b>architectures.</b> We discuss techniques at the microarchitecture level, in the memory hierarchy, in on-chip communication, and in the instruction-set architecture that can provide temporal semantics and control over timing. Categories and Subject Descriptor...|$|R
5000|$|Spector {{received}} his Bachelor of Arts degree in Applied Mathematics from Harvard University, and his PhD {{in computer science}} from Stanford University in 1981. His research explored communication architectures for building multiprocessors out of network-linked computers and included measurements of remote procedure call operations on experimental Ethernet. [...] His dissertation was titled <b>Multiprocessing</b> <b>Architectures</b> for Local Computer Networks, and his advisor was Forest Baskett III.|$|R
40|$|In the {{embedded}} world, symmetric <b>multiprocessing</b> <b>architectures</b> {{are currently}} most popular, however more embedded hardware platforms {{are being developed}} with asymmetric multiprocessor architectures. These may enable higher performance and provide cleaner separation of subsystems. Telecom applications are typically designed applying a planar architecture pattern. The goal of our experiments is to compare the performance and cross-plane influence in dualcore symmetric and asymmetric multiprocessing environments. Next to a pronounced performance difference, a crossinfluence between the different planes has been verified. status: publishe...|$|R
40|$|The work is {{concerned}} with the software and hardware for automatization of intelligent activities. The aim is to create the working station with <b>multiprocessing</b> <b>architecture,</b> its base software and applications software for the editing-publishing system of publication preparation. The architecture of the multiprocessing system with parallel combined operation of the different-type processors has been developed. It shall operate in the multiprogram modification regime {{of a large number of}} the interacting processors in several user's interests on base of the realizing conceptual model of "working mixture" of single program part modification by the virtual and real processors. The working station with many-bus and open <b>multiprocessing</b> <b>architecture</b> and its base software and applied system of the editing-publishing polygraphic products preparation on the professional level has been created. The pilot series of MRAMOR working stations for 40 working places has been manufacturedAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|E
40|$|Abstract: We {{consider}} some technical problems dealing with numerical implementation of explicit methods for computers with <b>multiprocessing</b> <b>architecture.</b> We give few examples written in Fortran {{and using the}} MPI library. We also consider problems of processes blocking, increasing of productivity (including processes balancing) and debugging. We believe that these tricks and fragments of the code will be useful for numerical implementation of parallel programs for various problems. Note: Publication language:russia...|$|E
40|$|In this paper, three {{parallel}} polygon {{scan conversion}} algorithms have been proposed, and their performance when executed on a shared bus architecture has been compared. It {{has been shown}} that the parallel algorithm that does not use edge coherence performs better than those that use edge coherence. Further, a <b>multiprocessing</b> <b>architecture</b> has been proposed to execute the parallel polygon scan conversion algorithms more efficiently than a single shared bus architecture...|$|E
50|$|Cellular {{multiprocessing}} is a <b>multiprocessing</b> computing <b>architecture</b> designed initially for Intel {{central processing}} units from Unisys, a worldwide information technology consulting services and solutions company.|$|R
5000|$|A uniprocessor {{system is}} defined as a {{computer}} system that has a single central processing unit that is used to execute computer tasks. As more and more modern software is able to make use of <b>multiprocessing</b> <b>architectures,</b> such as SMP and MPP, the term uniprocessor is therefore used to distinguish the class of computers where all processing tasks share a single CPU. Most desktop computers are now shipped with multiprocessing architectures.A type of architecture that is based on a single computing unit. All operations ( [...] additions, multiplications, etc. [...] ) are done sequentially on the unit.|$|R
40|$|Current {{embedded}} {{applications are}} migrating from sin-gle processor-based systems to intensive data communi-cation requiring multiprocessing. The performance de-manded by these applications requires {{the use of}} hetero-geneous <b>multiprocessing</b> <b>architectures</b> in a single chip (MPSoCs) endowed with complex communication infra-structures, such as Networks on Chip or NoCs. NoC pa-rameter choices, such as network dimensioning, topology, routing algorithm, and buffer sizing then become essen-tial aspects for optimizing the implementation of such complex systems. This paper presents NoC models that allow evaluating communication architectures through the variation of parameters during MPSoC design. Appli-cability of the concepts is demonstrated through two het-erogeneous MPSoC case studies: an MJPEG decoder and an H. 264 encoder. ...|$|R
40|$|Vendor-provided softcore {{processors}} often support advanced {{features such}} as caching that work well in uniprocessor or uncoupled multiprocessor architectures. However, {{it is a challenge}} to implement Symmetric Multiprocessor on a Programmable Chip (SMPoPC) systems using such processors. This paper presents an implementation of a tightly-coupled, cache-coherent symmetric <b>multiprocessing</b> <b>architecture</b> using a vendor-provided softcore processor. Experimental results show that this implementation can be achieved without invasive changes to the vendor-provided softcore processor and without degradation of the performance of the memory system...|$|E
40|$|Submitted {{on behalf}} of EDAA ([URL] audienceVendor-provided softcore {{processors}} often support advanced features such as caching that work well in uniprocessor or uncoupled multiprocessor architectures. However, {{it is a challenge}} to implement Symmetric Multiprocessor on a Programmable Chip (SMPoPC) systems using such processors. This paper presents an implementation of a tightly-coupled, cache-coherent symmetric <b>multiprocessing</b> <b>architecture</b> using a vendor-provided softcore processor. Experimental results show that this implementation can be achieved without invasive changes to the vendor-provided softcore processor and without degradation of the performance of the memory system...|$|E
40|$|Over {{the past}} quarter century, {{integrated}} microelectronics and its associated support technologies have matured from use in advanced research laboratories and internal corporate developments to mainstream, off-the-shelf technologies in broad industrial use. However, with the rapid increase in both performance and density, integrated electronics continues to push the limits of design and CAD technologies. This trend will continue over the next decade, with specific emphasis on high-level synthesis techniques, new packing technologies where many chips will be integrated on a single silicon 'PCB', high-performance <b>multiprocessing</b> <b>architecture,</b> and new approaches to design verification. In this presentation, future directions in these and other areas will be presented, {{in the context of}} existing CAD vendor and ASIC technology options...|$|E
40|$|ISBN: 978 - 0 - 7695 - 3180 - 9 International audienceCurrent {{embedded}} {{applications are}} migrating from single processorÂ¬based systems to intensive data communication requiring multiprocessing. The performance demanded by these applications requires {{the use of}} heterogeneous <b>multiprocessing</b> <b>architectures</b> in a single chip (MPSoCs) endowed with complex communication infrastructures, such as Networks on Chip or NoCs. NoC parameter choices, such as network dimensioning, topology, routing algorithm, and buffer sizing then become essential aspects for optimizing the implementation of such complex systems. This paper presents NoC models that allow evaluating communication architectures through the variation of parameters during MPSoC design. Applicability of the concepts is demonstrated through two heterogeneous MPSoC case studies: an MJPEG decoder and an H. 264 encoder...|$|R
40|$|This paper {{examines}} simultaneous multithreading, {{a technique}} permitting several independent threads to issue instructions to a superscalar 's multiple functional units {{in a single}} cycle. We present several models of simultaneous multithreading and compare them with alternative organizations: a wide superscalar, a fine-grain multithreaded processor, and single-chip, multiple-issue <b>multiprocessing</b> <b>architectures.</b> Our results show that both (single-threaded) superscalar and fine-grain multithreaded architectures are limited {{in their ability to}} utilize the resources of a wide-issue processor. Simultaneous multithreading has the potential to achieve 4 times the throughput of a superscalar, and double that of fine-grain multithreading. We evaluate several cache configurations made possible by this type of organization and evaluate tradeoffs between them. We also show that simultaneous multithreading is an attractive alternative to single-chip multiprocessor...|$|R
40|$|The {{design of}} {{concurrent}} data structures is greatly {{facilitated by the}} availability of synchronization operations that atomically modify k arbitrary locations, such as k-read-modify-write (krmw). Aiming to increase concurrency in order to exploit the parallelism offered by todayâ€™s multi-core and <b>multiprocessing</b> <b>architectures,</b> we propose a highly-concurrent nonblocking software implementation of krmw, which induces only constant space complexity overhead. Our algorithm ensures that two operations delay each other {{only if they are}} within distance O(k) in the conflict graph, dynamically induced by the operationsâ€™ data items. The algorithm uses double compare-and-swap (dcas). When dcas is not supported by the architecture, the algorithm of Attiya and Dagan [3] can be used to replace dcas with (unary) cas, with only a slight increase in the interference among operations...|$|R
40|$|Typical telecom {{applications}} apply a planar architecture pattern {{based on}} the processing requirements of each subsystem. In a symmetric multiprocessing environment all applications share the same hardware resources. However, currently embedded hardware platforms are being designed with asymmetric multiprocessor architectures to improve separation and increase performance of noninterfering tasks. These asymmetric multiprocessor architectures allow different planes to be separated and assign dedicated hardware for each responsibility. While planes are logically separated, some hardware is still shared and creates cross-plane influence effects which will impact {{the performance of the}} system. The aim of this report is to evaluate, in an embedded environment, the performance of a typical symmetric <b>multiprocessing</b> <b>architecture</b> compared to its asymmetric multiprocessing variant, applied on a telecom application...|$|E
40|$|Integrated {{multi-core}} processors with on-chip application acceleration {{have established}} {{themselves as the}} most efficient method of powering next-generation networking platforms. New {{research has been conducted}} for addressing the issues of multi-core supported network and system security. This paper put forward an asymmetrical <b>multiprocessing</b> <b>architecture</b> multi-core supported anomaly intrusion detection system. The key idea is to use an independent core to run the intrusion detection system to monitor the host system. The detection method is based on the Hebb rule and uses libpcap to grab the network transmission packages. In the experiments, we use VMware which is configured to run the Ubuntu to simulate the IDS core. The results show that when the intrusion threshold is 0. 3 - 0. 5 the system performs best...|$|E
40|$|Rapid {{progress}} {{in the area of}} Field-Programmable Gate Arrays (FPGAs) has led to the availability of softcore processors that are simple to use, and can enable the development of a fully working system in minutes. This has lead to the enormous popularity of System-On-Programmable-Chip (SOPC) computing platforms. These softcore processors, while relatively simple compared to their leading-edge hardcore counterparts, are often designed with a number of advanced performance-enhancing features, such as instruction and data caches. Moreover, they are designed to be used in a uniprocessor or uncoupled multiprocessor architecture, and not in a tightly-coupled <b>multiprocessing</b> <b>architecture.</b> As a result, traditional cache-coherency protocols are not suitable for use with such systems. This thesis describes a system for enforcing cache coherency on symmetric multiprocessing (SMP) systems using softcore processors. A hybrid protocol that incorporates hardware and software to enforce cache coherency is presented...|$|E
5000|$|One common {{variety of}} single board {{computer}} uses standardized computer form factors intended {{for use in a}} backplane enclosure. Some of these types are CompactPCI, PXI, VMEbus, VXI, and PICMG. SBCs have been built around various internal processing structures including the Intel <b>architecture,</b> <b>multiprocessing</b> <b>architectures,</b> and lower power processing systems like RISC and SPARC. In the Intel PC world, the intelligence and interface/control circuitry is placed on a plug-in board that is then inserted into a passive (or active) backplane. The end result is similar to having a system built with a motherboard, except that the backplane determines the slot configuration. Backplanes are available with a mix of slots (ISA, PCI, PCIX, PCI-Express, etc.), usually totaling 20 or fewer, meaning it will fit in a 19" [...] rackmount enclosure (17" [...] wide chassis).|$|R
40|$|Researchers {{have been}} {{actively}} pursuing load balancing schemes for parallel searches {{in an attempt}} to achieve linear or near linear speedups. Most of the approaches have used message based distributed models. Although, they have been successfully ported to shared-memory systems, their designs and approaches are counter intuitive and cumbersome for symmetric <b>multiprocessing</b> <b>architectures.</b> Here, we present an asynchronous load balancing scheme that is a natural programming model for symmetric multiprocessor machines. We test the scheme on two classic problems using different search strategies and find it effective in obtaining linear or near linear speedups. Keywords: load balancing, threads, parallelism. 1. INTRODUCTION Parallel searches have proven to be very beneficial for the Artificial Intelligence and Operations Research communities [1][2][3]. Large combinatorial problems, which otherwise are impractical for a single processor, can be solved by exploiting the parallelism of m [...] ...|$|R
5000|$|Symmetric multiprocessingLike Windows, RTX {{is based}} on a {{symmetric}} <b>multiprocessing</b> (SMP) <b>architecture.</b> Depending on the real-time needs, users can choose the number of processors to dedicate to RTX to run real-time processes. RTX can use up to 31 dedicated processors; RTX64 can use up to 63. Users can then scale real-time applications between the RTX dedicated processors.|$|R
30|$|This article {{presents}} an efficient {{implementation of the}} EKF-SLAM algorithm on a multi-processor architecture. The approach {{is based on an}} algorithm implementation adequate to a defined architecture. The aim is to optimize the implementation of the SLAM algorithm on a low-cost and heterogeneous architecture implementing an SIMD coprocessor (NEON) and a DSP core. The hardware includes several low-cost sensors. As[17], we chose to use a low-cost camera (exteroceptive sensor) and odometers (proprioceptive sensors). Following[12], we efficiently tune the parameters of the SLAM algorithm. We improve on previous works by proposing an adequate implementation of the EKF-SLAM algorithm on a <b>multiprocessing</b> <b>architecture</b> (ARM processor, SIMD NEON coprocessor, DSP core). The specifications related to the NEON coprocessor and the DSP core improve the processing time and the system performance. Results aim to demonstrate that an optimized implementation of the algorithm, resulting from an evaluation methodology, can help to design embedded systems implementing low-cost multiprocessor architecture operating under real-time constraints.|$|E
40|$|I hereby {{declare that}} I am the sole {{author of this}} thesis. This is a true copy of the thesis, {{including}} any required final revisions, as accepted by my examiners. I understand that my thesis may be made electronically available to the public. ii Rapid progress {{in the area of}} Field-Programmable Gate Arrays (FPGAs) has led to the availabil-ity of softcore processors that are simple to use, and can enable the development of a fully work-ing system in minutes. This has lead to the enormous popularity of System-On-Programmable-Chip (SOPC) computing platforms. These softcore processors, while relatively simple com-pared to their leading-edge hardcore counterparts, are often designed with a number of advanced performance-enhancing features, such as instruction and data caches. Moreover, they are de-signed to be used in a uniprocessor or uncoupled multiprocessor architecture, and not in a tightly-coupled <b>multiprocessing</b> <b>architecture.</b> As a result, traditional cache-coherency protocols are not suitable for use with such systems. This thesis describes a system for enforcing cache coherency on symmetric multiprocessing (SMP) systems using softcore processors. A hybrid protocol that incorporates hardware and software to enforce cache coherency is presented. ii...|$|E
40|$|This paper {{describes}} a generalized parallelization methodology for mapping video coding algorithms onto a <b>multiprocessing</b> <b>architecture,</b> through systematic task decomposition, scheduling and performance analysis. It exploits data parallelism {{inherent in the}} coding process and performs task scheduling base on task data size and access locality with the aim to hide as much communication overhead as possible. Utilizing Petri-nets and task graphs for representation and analysis, the method enables parallel video frame capturing, buffering and encoding without extra communication overhead. The theoretical speedup analysis indicates that this method offers excellent communication hiding, resulting in system efficiency well above 90 %. A H. 261 video encoder has been implemented on a TMS 32 OC 8 O system using this method, and its performance was measured. The theoretical and measured performances are similar in that the measured speedup of the H. 261 is 3. 67 and 3. 76 on four PP for QCIF and 352 x 240 video, respectively. They correspond to frame rates of 30. 7 frame per second (fps) and 9. 25 fps, and system efficiency of 91. 8 % and 94 % respectively. As it is, this method is particularly efficient for platforms with small number of parallel processors...|$|E
40|$|Nested Monte Carlo is a {{computationally}} expensive exercise. The main contributions {{we present}} {{in this thesis}} are the formulation of efficient algorithms to perform nested Monte Carlo for the estimation of Value-at-Risk and Expected-Tail-Loss. The algorithms are designed {{to take advantage of}} <b>multiprocessing</b> computer <b>architecture</b> by performing computational tasks in parallel. Through numerical experiments we show that our algorithms can improve efficiency in the sense of reducing mean-squared error...|$|R
40|$|Because clock {{frequency}} has hardly advanced in recent years, major chip manufacturers are shifting their focus from improving {{the speed of}} individual processors to increasing parallel-processing capabilities. Multicore technology refers to a processor {{with more than one}} engine, allowing for greater efficiency because the processor workload is essentially shared. With multicore and <b>multiprocessing</b> <b>architectures</b> becoming common, itâ€™s imperative to devise effective software tools for managing the difficulty of concurrent programming. At the same time, applications must be designed to exploit parallelism and avoid the perils of sequential execution. To utilize the architectureâ€™s capabilities, itâ€™s critical to allow many operations to make progress concurrently and to complete without interference. Multiword synchronization A good example of the challenge in obtaining high throughput is multiword synchronization operations, such as k-compare-and-swap (kCAS). Such operations allow reading the contents of several memory locations, comparing them with specified values, and if they all match, updating the locationsâ€”all in one atomic operation. Multiword synchronization facilitates the design and implementation of concurrent data structures, making this process more effective and easier than when using onl...|$|R
40|$|Since its inception, the {{blackboard}} paradigm {{has been viewed}} as particularly appropriate for parallel and distributed hardware architectures. Yet, the paradigmâ€™s multiprocessing potential remains largely untapped. The availability of multiprocessing hardware and languages in conjunction with tools for building blackboard applications is sparking renewed interest in <b>multiprocessing</b> blackboard <b>architectures.</b> <b>Multiprocessing</b> can be introduced {{at a number of}} levels in {{the blackboard}} architecture, from low-level parallel coding techniques to concurrent execution of knowledge sources and control components. This chapter details the issues associated with these multiprocessing levels and presents three high-level design alternatives for parallel and distributed blackboard architectures. Each design is appropriate for a particular architectural and application environment, and we discuss the selection criteria for each design and issues associated with its implementation. The three designs are being implemented as extensions to the Generic Blackboard Development System (GBB). ...|$|R
40|$|International Telemetering Conference Proceedings / October 26 - 29, 1992 / Town and Country Hotel and Convention Center, San Diego, CaliforniaEquipment {{for data}} {{collection}} and recording has widespread use {{in a variety of}} engineering applications. This paper deals with the use of multiprocessor-based architectures in digital data acquisition systems, emphasizing advantages in terms of flexibility and overall system throughput, and the characteristics of the embedded operating system. An overview of the basic architecture of typical data acquisition systems is first presented, followed by a description of a <b>multiprocessing</b> <b>architecture</b> for data acquisition in real-time environments where multiple sampling rates are employed to monitor analog and digital data from different sources. Software and hardware techniques are covered, including the multiplexing of analog signals, digital signal processing, use of masking techniques in the processing of serial data streams, and the use of multi-point buses for communications with peripheral devices. The characteristics of a real-time multi-tasking operating system are analysed. This is the core of the software in any data acquisition system which must meet real-time constraints. In turn, the core of the operating system is the real-time kernel. Emphasis is put into the organization of the kernel, covering issues such as kernel primitives, service calls, interrupt service routines, process scheduling, memory management, and communications and synchronization between processes...|$|E
30|$|Each {{processing}} element at {{each step}} of the algorithm thus accesses from memory its p input operands and writes into memory those of its output operands. The algorithm, while providing an arbitrary, generalised, level of parallelism up to the ultimate massive parallelism, produces optimal <b>multiprocessing</b> machine <b>architecture</b> minimizing addressing, the number of memory partitions as well as the number of required shuffles. Meanwhile it produces virtually wired-in pipelined architecture and properly ordered output.|$|R
50|$|NUMA {{architectures}} logically {{follow in}} scaling from symmetric <b>multiprocessing</b> (SMP) <b>architectures.</b> They were developed commercially during the 1990s by Burroughs (later Unisys), Convex Computer (later Hewlett-Packard), Honeywell Information Systems Italy (HISI) (later Groupe Bull), Silicon Graphics (later Silicon Graphics International), Sequent Computer Systems (later IBM), Data General (later EMC), and Digital (later Compaq, then HP, now HPE). Techniques developed by these companies later {{featured in a}} variety of Unix-like operating systems, and to an extent in Windows NT.|$|R
40|$|The Earth Observing System (EOS), {{part of a}} {{cohesive}} national effort to study global change, will deploy a constellation of remote sensing spacecraft over a 15 year period. Science data from the EOS spacecraft will be processed and made available to a large community of earth scientists via NASA institutional facilities. A number of these spacecraft are also providing an additional interface to broadcast data directly to users. Direct broadcast of real-time science data from overhead spacecraft has valuable applications including validation of field measurements, planning science campaigns, and science and engineering education. The success and usefulness of EOS direct broadcast depends largely on the end-user cost of receiving the data. To extend this capability to the largest possible user base, the cost of receiving ground stations must be as low as possible. To achieve this goal, NASA Goddard Space Flight Center is developing a prototype low-cost transportable ground station for EOS direct broadcast data based on Very Large Scale Integration (VLSI) components and pipelined, <b>multiprocessing</b> <b>architectures.</b> The targeted reproduction cost of this system is less than $ 200 K. This paper describes a prototype ground station and its constituent components...|$|R
50|$|Snarf is a {{term used}} by {{computer}} programmers meaning to grab a large document, file or any data, and use it without the author's (owner) permission. In the UNIX community the term means the acquisition of a file or set of files across a network. It also refers to using command line tools to transfer files through the HTTP, gopher, finger and FTP protocols without user interaction, and to a method of achieving cache coherence in a <b>multiprocessing</b> computer <b>architecture</b> through observation of writes to cached data.|$|R
40|$|The {{growing demand}} for high {{processing}} power in various scientific and engineering applications has made <b>multiprocessing</b> <b>architectures</b> increasingly popular. These multiprocessing systems consist of processing elements or nodes which are connected together by interconnection networks in various topologies. One of the design methodologies used for parallel machines has fed {{to the development of}} distributed memory message-passing concurrent computers, commonly known as multicomputers. They consist of many processing nodes that interact by sending messages (containing both data and synchronization information) over a communication link, between nodes. Thus, efficient communication in multicomputers is one of the important research areas in parallel computing today, and it depends on the underlying scheme for routing. For this reason it is essential to know which routing techniques are suitable and practical. Although an extremely wide number of routing algorithms have been proposed and implemented in hardware and software, it is difficult for the designer of a multicomputer to choose the best routing algorithm given a particular architectural configuration. In an attempt to overcome this difficulty, we present a survey and comparison of wormhole routing techniques in mesh interconnection networks. The mesh topology is important because of its scalability. Moreover, it has already been implemented in many commercial multicomputer...|$|R
