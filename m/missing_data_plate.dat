0|10000|Public
3000|$|... {{represent}} <b>missing</b> <b>data.</b> Finally, let ϕ be the scalar or vector‐valued parameter {{describing the}} process that generates the <b>missing</b> <b>data.</b> The underlying mechanism that generates <b>missing</b> <b>data</b> can be considered either ignorable or non‐ignorable. An ignorable <b>missing</b> <b>data</b> mechanism {{is one in which}} inferences are not affected by {{the process that}} generated the <b>missing</b> <b>data.</b>|$|R
40|$|Introduction. <b>Missing</b> <b>data</b> is {{a common}} problem in {{research}} and can produce severely misleading analyses, including biased estimates of statistical parameters, and erroneous conclusions. In its 1999 report, the APA Task Force on Statistical Inference encouraged authors to report complications such as <b>missing</b> <b>data</b> and discouraged the use of traditional <b>missing</b> <b>data</b> methods, such as listwise and pairwise deletion. While many advances in the statistical treatment of <b>missing</b> <b>data</b> have been made, {{it remains to be}} seen whether these procedures are applied in practice. In their study examining <b>missing</b> <b>data</b> reporting practices of studies published in 1999 and 2003, Peugh and Enders found that <b>missing</b> <b>data</b> was rarely acknowledged and, when it was addressed, out-of-date statistical methods were used in response. ^ Purpose. The purpose of this dissertation is to (a) provide an overview of the causes, assumptions, misconceptions, and statistical remedies regarding <b>missing</b> <b>data</b> in applied research; (b) replicate partially, extend, and expand the Peugh and Enders findings; (c) identify the ways in which <b>missing</b> <b>data</b> are addressed; and (d) assess current reporting practices. ^ Sample. Data from 1, 106 studies were collected from the 24 educational and applied psychological journals published in 2007. ^ Methods. Data were collected on a number of points including the amount of <b>missing</b> <b>data,</b> the <b>missing</b> <b>data</b> method used, the study design, the cause of <b>missing</b> <b>data,</b> the type of <b>missing</b> <b>data,</b> the underlying nature of the <b>missing</b> <b>data,</b> the <b>missing</b> <b>data</b> mechanism, and whether or not a power analysis was performed. ^ Findings. Compared to the Peugh and Enders findings, the current sample of studies published in 2007 showed improvements in the assessment and treatment of <b>missing</b> <b>data.</b> More studies explicitly acknowledged <b>missing</b> <b>data,</b> modern <b>missing</b> <b>data</b> methods were employed more often, more studies discussed <b>missing</b> <b>data</b> in detail, and the underlying nature of the <b>missing</b> <b>data</b> was examined more often. However, the way in which many studies reported the amount, type, and cause of <b>missing</b> <b>data</b> was often inaccurate and/or unclear. This dissertation gives a statistical and narrative description of results and provides recommendations for improvement. ...|$|R
5000|$|In statistics, ignorability is {{a feature}} of an {{experiment}} design whereby the {{method of data collection}} (and the nature of <b>missing</b> <b>data)</b> do not depend on the <b>missing</b> <b>data.</b> A <b>missing</b> <b>data</b> mechanism such as a treatment assignment or survey sampling strategy is [...] "ignorable" [...] if the <b>missing</b> <b>data</b> matrix, which indicates which variables are observed or missing, is independent of the <b>missing</b> <b>data</b> conditional on the observed data.|$|R
40|$|This paper {{outlines}} an algorithm {{to improve}} the robustness of <b>missing</b> <b>data</b> treatment to pathological motion (PM). PM can cause misdiagnosis of clean image <b>data</b> as <b>missing</b> <b>data.</b> The proposed algorithm uses a probabilistic framework to jointly detect PM and <b>missing</b> <b>data</b> by exploiting more temporal information than is typically used for <b>missing</b> <b>data</b> detection and by exploiting the local smoothness assumption of motion fields. The results of the framework are compared to an equivalent <b>missing</b> <b>data</b> detector without PM detection and the framework is shown to prevent the misdiagnosis of <b>missing</b> <b>data</b> due to P...|$|R
40|$|<b>Missing</b> <b>data</b> are a {{major problem}} in the {{behavioral}} neurosciences, particularly when data collection is costly. Often researchers exclude cases with <b>missing</b> <b>data,</b> which can result in biased estimates and reduced power. Trying to avoid the deletion of a case because of a <b>missing</b> <b>data</b> point can be conducted, but implementing a naïve <b>missing</b> <b>data</b> method can result in distorted estimates and incorrect conclusions. New approaches for handling <b>missing</b> <b>data</b> have been developed but these techniques are not typically included in undergraduate research methods texts. The topic of <b>missing</b> <b>data</b> techniques would be useful for teaching research methods and for helping students with their research projects. This paper aimed to illustrate that estimating <b>missing</b> <b>data</b> is often more efficacious than complete case analysis, otherwise know...|$|R
40|$|Background: The {{objectives}} of this systematic review are {{to examine how}} researchers report <b>missing</b> <b>data</b> in questionnaires and to {{provide an overview of}} current methods for dealing with <b>missing</b> <b>data.</b> Methods: We included 262 studies published in 2010 in 3 leading epidemiologic journals. Information was extracted on how <b>missing</b> <b>data</b> were reported, types of missing, and methods for dealing with <b>missing</b> <b>data.</b> Results: Seventy-eight percent of the studies lacked clear information about the measurement instruments. <b>Missing</b> <b>data</b> in multi-item instruments were not handled differently from other <b>missing</b> <b>data.</b> Complete-case analysis was most frequently reported (81 % of the studies), and the selectivity of <b>missing</b> <b>data</b> was seldom examined. Conclusions: Although there are specific methods for handling <b>missing</b> <b>data</b> in item scores and in total scores of multi-item instruments, these are seldom applied. Researchers mainly use complete-case analysis for both types of missing, which may seriously bias the study results...|$|R
40|$|The {{purpose of}} this study was to investigate, within the context of a two-predictor {{multiple}} regression analysis with systematically <b>missing</b> <b>data,</b> the effectiveness of eight <b>missing</b> <b>data</b> treatments on the sample estimate of R 2 and each standardized regression coefficient. Furthermore, the study investigated whether sample size, proportion of systematically <b>missing</b> <b>data</b> above the mean of the regressor, and the percentage of <b>missing</b> <b>data</b> affected the effectiveness of the eight <b>missing</b> <b>data</b> treatments. One thousand samples of size 50, 100, and 200 were generated per data set. The percentages of <b>missing</b> <b>data</b> were 0 %, 10 %, 20 %, 30 %, 40 %, 50 %, and 60 %, occurring either on one regressor or across both regressors. The proportions of <b>missing</b> <b>data</b> that were above the mean value of the regressors were 0. 60, 0. 70, 0. 80, or 0. 90. The data were analyzed by computing effect sizes obtained from the <b>missing</b> <b>data</b> treatment conditions relative to the complete sample condition (i. e., 0 % <b>missing</b> <b>data).</b> The results suggest that the stochastic multiple regression imputation technique was the most effective treatment of the <b>missing</b> <b>data.</b> Listwise and pairwise deletion approaches were less effective than stochastic multiple regression imputation but were superior to the other techniques examined. mpirical investigations frequently have <b>missing</b> <b>data</b> on one or more variables. Researchers have long recognized that <b>missing</b> <b>data</b> within a study may be detrimental to any subsequent data analyses, interpretations, and conclusions. Unfortunately, researchers...|$|R
40|$|Abstract Background <b>Missing</b> <b>data</b> due to {{attrition}} are {{rampant in}} substance abuse clinical trials. However, <b>missing</b> <b>data</b> are often {{ignored in the}} presentation of substance abuse clinical trials. This paper demonstrates <b>missing</b> <b>data</b> methods which {{may be used for}} hypothesis testing. Methods Methods involving stratifying and weighting individuals based on <b>missing</b> <b>data</b> pattern are shown to produce tests that are robust to <b>missing</b> <b>data</b> mechanisms in terms of Type I error and power. In this article, we describe several methods of combining data that may be used for testing hypotheses of the treatment effect. Furthermore, illustrations of each test's Type I error and power under different <b>missing</b> <b>data</b> percentages and mechanisms are quantified using a Monte-Carlo simulation study. Results Type I error rates were similar for each method, while powers depended on <b>missing</b> <b>data</b> assumptions. Specifically, power was greatest for the weighted, compared to un-weighted methods, especially for greater <b>missing</b> <b>data</b> percentages. Conclusion Results of this study as well as extant literature demonstrate the need for standards of design and analysis specific to substance abuse clinical trials. Given the known substantial attrition rates and concern for the <b>missing</b> <b>data</b> mechanism in substance abuse clinical trials, investigators need to incorporate <b>missing</b> <b>data</b> methods a priori. That is, <b>missing</b> <b>data</b> methods should be specified {{at the outset of the}} study and not after the data have been collected. </p...|$|R
40|$|<b>Missing</b> <b>data</b> is a {{widespread}} problem that can affect {{the ability to use}} data to construct effective prediction systems. We investigate a common machine learning technique that can tolerate missing values, namely C 4. 5, to predict cost using six real world software project databases. We analyze the predictive performance after using the k-NN <b>missing</b> <b>data</b> imputation technique to see if it is better to tolerate <b>missing</b> <b>data</b> or to try to impute missing values and then apply the C 4. 5 algorithm. For the investigation, we simulated 3 missingness mechanisms, 3 <b>missing</b> <b>data</b> patterns, and 5 <b>missing</b> <b>data</b> percentages. We found that the k-NN imputation can improve the prediction accuracy of C 4. 5. At the same time, both C 4. 5 and k-NN are little affected by the missingness mechanism, but that the <b>missing</b> <b>data</b> pattern and the <b>missing</b> <b>data</b> percentage have a strong negative impact upon prediction (or imputation) accuracy particularly if the <b>missing</b> <b>data</b> percentage exceed...|$|R
40|$|BACKGROUND:: The {{objectives}} of this systematic review are {{to examine how}} researchers report <b>missing</b> <b>data</b> in questionnaires and to {{provide an overview of}} current methods for dealing with <b>missing</b> <b>data.</b> METHODS:: We included 262 studies published in 2010 in 3 leading epidemiologic journals. Information was extracted on how <b>missing</b> <b>data</b> were reported, types of missing, and methods for dealing with <b>missing</b> <b>data.</b> RESULTS:: Seventy-eight percent of the studies lacked clear information about the measurement instruments. <b>Missing</b> <b>data</b> in multi-item instruments were not handled differently from other <b>missing</b> <b>data.</b> Complete-case analysis was most frequently reported (81 % of the studies), and the selectivity of <b>missing</b> <b>data</b> was seldom examined. CONCLUSIONS:: Although there are specific methods for handling <b>missing</b> <b>data</b> in item scores and in total scores of multi-item instruments, these are seldom applied. Researchers mainly use complete-case analysis for both types of missing, which may seriously bias the study results. © 2012 by Lippincott Williams & Wilkins...|$|R
40|$|The {{impact of}} <b>missing</b> <b>data</b> on {{quantitative}} {{research has been}} a great concern to methodologists and educational researchers alike. An examination of the quantitative studies published in Theory and Research in Social Education (TRSE) for the past 20 years reveals that, in studies where <b>missing</b> <b>data</b> were reported and care was taken to treat <b>missing</b> <b>data,</b> all used either listwise or pairwise deletion methods. Yet the recent APA Task Force on Statistical Inference warned against the use of these methods for dealing with <b>missing</b> <b>data.</b> Newer and more principled methods take into account conditions under which <b>missing</b> <b>data</b> occurred. These methods have been implemented into statistical software (e. g., SPSS and SAS); thus, they are accessible to social studies researchers. In this paper, we promote the use of two of these principled statistical methods for treating <b>missing</b> <b>data.</b> Both methods are illustrated with a real-world data set, and the results are interpreted within the framework of assumptions made about <b>missing</b> <b>data.</b> Implications for social studies researchers include the choice of principled rather than ad hoc <b>missing</b> <b>data</b> methods in quantitative research; the need to specify explicit <b>missing</b> <b>data</b> methods used when writing reports; and incorporation of appropriate <b>missing</b> <b>data</b> methods in standards used by journal referees and editors in judging manuscripts for publication...|$|R
40|$|To {{obtain a}} better {{understanding}} of the pharmacokinetic and/or pharmacodynamic characteristics of an investigated treatment, clinical data is often analysed with nonlinear mixed effects modelling. The developed models can be used to design future clinical trials or to guide individualised drug treatment. <b>Missing</b> <b>data</b> is a frequently encountered problem in analyses of clinical data, and to not venture the predictability of the developed model, it is of great importance that the method chosen to handle the <b>missing</b> <b>data</b> is adequate for its purpose. The overall aim of this thesis was to develop methods for handling <b>missing</b> <b>data</b> in the context of nonlinear mixed effects models and to compare strategies for handling <b>missing</b> <b>data</b> in order to provide guidance for efficient handling and consequences of inappropriate handling of <b>missing</b> <b>data.</b> In accordance with <b>missing</b> <b>data</b> theory, all <b>missing</b> <b>data</b> can be divided into three categories; missing completely at random (MCAR), missing at random (MAR) and missing not at random (MNAR). When data are MCAR, the underlying <b>missing</b> <b>data</b> mechanism does not depend on any observed or unobserved data; when data are MAR, the underlying <b>missing</b> <b>data</b> mechanism depends on observed data but not on unobserved data; when data are MNAR, the underlying <b>missing</b> <b>data</b> mechanism depends on the unobserved data itself. Strategies and methods for handling <b>missing</b> observation <b>data</b> and <b>missing</b> covariate <b>data</b> were evaluated. These evaluations showed that the most frequently used estimation algorithm in nonlinear mixed effects modelling (first-order conditional estimation), resulted in biased parameter estimates independent on <b>missing</b> <b>data</b> mechanism. However, expectation maximization (EM) algorithms (e. g. importance sampling) resulted in unbiased and precise parameter estimates as long as data were MCAR or MAR. When the observation data are MNAR, a proper method for handling the <b>missing</b> <b>data</b> has to be applied to obtain unbiased and precise parameter estimates, independent on estimation algorithm. The evaluation of different methods for handling <b>missing</b> covariate <b>data</b> showed that a correctly implemented multiple imputations method and full maximum likelihood modelling methods resulted in unbiased and precise parameter estimates when covariate data were MCAR or MAR. When the covariate data were MNAR, the only method resulting in unbiased and precise parameter estimates was a full maximum likelihood modelling method where an extra parameter was estimated, correcting for the unknown <b>missing</b> <b>data</b> mechanism's dependence on the <b>missing</b> <b>data.</b> This thesis presents new insight to the dynamics of <b>missing</b> <b>data</b> in nonlinear mixed effects modelling. Strategies for handling different types of <b>missing</b> <b>data</b> have been developed and compared in order to provide guidance for efficient handling and consequences of inappropriate handling of <b>missing</b> <b>data...</b>|$|R
30|$|Comparisons of CBT and PPT {{administered}} assessments {{may also}} be impacted by <b>missing</b> <b>data.</b> Our use of Hierarchical Multiple Imputations (HMI) mitigates the impacts of <b>missing</b> <b>data,</b> but studies that use listwise deletion to address <b>missing</b> <b>data</b> may have different results. The skewing of participation rates by student course grade demonstrates that the <b>data</b> are not <b>missing</b> completely at random and that <b>missing</b> <b>data</b> are therefore non-ignorable.|$|R
40|$|Many {{researchers}} {{face the}} problem of <b>missing</b> <b>data</b> in longitudinal research. Especially, high risk samples are characterized by <b>missing</b> <b>data</b> which can complicate analyses and the interpretation of results. In the current study, {{our aim was to}} find the most optimal and best method to deal with the <b>missing</b> <b>data</b> in a specific study with many <b>missing</b> <b>data</b> on the outcome variable. Therefore, different techniques to handle <b>missing</b> <b>data</b> were evaluated, and a solution to efficiently handle substantial amounts of <b>missing</b> <b>data</b> was provided. A simulation study was conducted to determine the most optimal method to deal with the <b>missing</b> <b>data.</b> Results revealed that multiple imputation (MI) using predictive mean matching was the most optimal method with respect to lowest bias and the smallest confidence interval (CI) while maintaining power. Listwise deletion and last observation carried backward also scored acceptable with respect to bias; however, CIs were much larger and sample size almost halved using these methods. Longitudinal research in high risk samples could benefit from using MI in future research to handle <b>missing</b> <b>data.</b> The paper ends with a checklist for handling <b>missing</b> <b>data...</b>|$|R
40|$|Alma B Pedersen, 1 Ellen M Mikkelsen, 1 Deirdre Cronin-Fenton, 1 Nickolaj R Kristensen, 1 Tra My Pham, 2 Lars Pedersen, 1 Irene Petersen 1, 2 1 Department of Clinical Epidemiology, Aarhus University Hospital, Aarhus N, Denmark; 2 Department of Primary Care and Population Health, University College London, London, UK Abstract: <b>Missing</b> <b>data</b> are {{ubiquitous}} in clinical epidemiological research. Individuals with <b>missing</b> <b>data</b> {{may differ from}} those with no <b>missing</b> <b>data</b> {{in terms of the}} outcome of interest and prognosis in general. <b>Missing</b> <b>data</b> are often categorized into the following three types: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR). In clinical epidemiological research, <b>missing</b> <b>data</b> are seldom MCAR. <b>Missing</b> <b>data</b> can constitute considerable challenges in the analyses and interpretation of results and can potentially weaken the validity of results and conclusions. A number of methods have been developed for dealing with <b>missing</b> <b>data.</b> These include complete-case analyses, missing indicator method, single value imputation, and sensitivity analyses incorporating worst-case and best-case scenarios. If applied under the MCAR assumption, some of these methods can provide unbiased but often less precise estimates. Multiple imputation is an alternative method to deal with <b>missing</b> <b>data,</b> which accounts for the uncertainty associated with <b>missing</b> <b>data.</b> Multiple imputation is implemented in most statistical software under the MAR assumption and provides unbiased and valid estimates of associations based on information from the available data. The method affects not only the coefficient estimates for variables with <b>missing</b> <b>data</b> but also the estimates for other variables with no <b>missing</b> <b>data.</b> Keywords: <b>missing</b> <b>data,</b> observational study, multiple imputation, MAR, MCAR, MNA...|$|R
40|$|This {{class will}} review {{statistical}} analysis for complete data {{and provide an}} introduction to the models and methods for the dataset with missing values. The course has a significant component of statistical computations dealing with <b>missing</b> <b>data.</b> It is intended for those who already have some experience with standard statistical methods for complete data and want to extend them to handle the <b>missing</b> <b>data</b> in practice. Course Objectives: After the completion of this course, the students are expected to 1. Understand the <b>missing</b> <b>data</b> mechanism, the underlying assumptions and identify different patterns of <b>missing</b> <b>data</b> 2. Understand the difference in statistical analysis between <b>missing</b> <b>data</b> problem and complete data problem (including weighted methods) 3. Be able to perform simple <b>missing</b> <b>data</b> analysis with single imputation; comprehend its weakness 4. Be able to implement likelihood-based analysis with ignorable missing response; implement EM algorithm with some statistical package 5. Understand the principle of Bayesian analysis with missing data; implement multiple imputation with some statistical package 6. Understand <b>missing</b> <b>data</b> models in contingency tables 7. Have a basic understanding of the recent development of statistical methods to deal with non-ignorable <b>missing</b> <b>data</b> 8. Be able to implement and interpret statistical methods for <b>missing</b> <b>data</b> in a practical scenario. Required Texts: Statistical Analysis with <b>Missing</b> <b>Data,</b> Little and Rubin, 2 nd edition, Wiley...|$|R
3000|$|Incomplete data: The way of data {{collection}} and storage could result in <b>missing</b> <b>data,</b> but the above algorithms require complete quantitative data. Although there are algorithms for processing <b>missing</b> <b>data,</b> which assume that the <b>missing</b> <b>data</b> is negligible, {{it is difficult to}} calculate CPT by the algorithms in the case of incomplete data, especially with excessively <b>missing</b> <b>data.</b> So how to calculate the CPT of qualitative and missing-data indicators objectively? [...]...|$|R
40|$|<b>Missing</b> <b>data</b> {{often occur}} in {{agriculture}} and animal husbandry experiment. The <b>missing</b> <b>data</b> in experimental design makes {{the information that}} we get less complete. In this research, the <b>missing</b> <b>data</b> was estimated with Yates method and Expectation Maximization (EM) algorithm. The basic concept of the Yates method is to minimize sum square error (JKG), meanwhile the basic concept of the EM algorithm is to maximize the likelihood function. This research applied Balanced Lattice Design with 9 treatments, 4 replications and 3 group of each repetition. <b>Missing</b> <b>data</b> estimation results showed that the Yates method was better used for two of <b>missing</b> <b>data</b> in the position on a treatment, a column and random, meanwhile the EM algorithm was better used to estimate one of <b>missing</b> <b>data</b> and two of <b>missing</b> <b>data</b> in the position of a group and a replication. The comparison of the result JKG of ANOVA showed that JKG of incomplete data larger than JKG of incomplete data that has been added with estimator of data. This suggest  thatwe need to estimate the <b>missing</b> <b>data.</b> </em...|$|R
5000|$|... 3. MLM can Handle <b>Missing</b> Data: <b>Missing</b> <b>data</b> is {{permitted}} in MLM without causing additional complications. With RM-ANOVA, subject’s data must be excluded {{if they are}} <b>missing</b> a single <b>data</b> point. <b>Missing</b> <b>data</b> and attempts to resolve <b>missing</b> <b>data</b> (i.e. using the subject’s mean for non-missing data) can raise additional problems in RM-ANOVA.|$|R
40|$|Abstract. The Naive Bayesian {{classifier}} is {{the least}} sensitive to <b>missing</b> <b>data</b> in the methods of <b>data</b> mining. However, <b>missing</b> <b>data</b> still affects {{the accuracy of the}} classifiers before the dataset which contains <b>missing</b> <b>data</b> used to train in the classifier. We can fill up the <b>missing</b> <b>data</b> to gain a full dataset. This paper introduces a random patch algorithm based on Markov Transition probability. This algorithm can fill up the dataset which contains <b>missing</b> <b>data</b> to a full one. Using the full dataset to classification can increase the accuracy of the classifier. We perform experiments to prove the algorithm effectiveness...|$|R
40|$|The {{effect of}} a number of factors, such as the choice of {{analytical}} method, the handling method for <b>missing</b> <b>data,</b> sample size, and proportion of <b>missing</b> <b>data,</b> were examined to evaluate the effect of <b>missing</b> <b>data</b> treatment on accuracy of estimation. A methodological approach involving simulated data was adopted. One outcome of the statistical analyses undertaken in this study is the formulation of easy-to-implement guidelines for educational researchers that allows one to choose one of the following factors when all others are given: sample size, proportion of <b>missing</b> <b>data</b> in the sample, method of analysis, and <b>missing</b> <b>data</b> handling method...|$|R
40|$|Analysis of Covariance (ANCOVA) {{is mostly}} {{used in the}} {{analysis}} of research or experimental design. ANCOVA is the combination between regression analysis and Analysis of Variance (ANOVA). ANCOVA were used because there are some concomitant variable, which is variable that difficult to control by the researchers but an impact on observed the response variable. The purpose from concomitant variable is reduces variability in the experiment. If there is <b>missing</b> <b>data</b> on Randomized Complete Block Design (RCBD) the first must be done estimating the <b>missing</b> <b>data</b> before ANCOVA done. ANCOVA on RCBD with complete <b>data</b> or <b>missing</b> <b>data</b> isn 2 ̆ 7 t much different, if there are <b>missing</b> <b>data,</b> the degrees of freedom is reduced by the total amount of <b>missing</b> <b>data</b> and the sum of square treatment reduced by the value of the bias. Application of tensile strength of the glue experiment to the case ANCOVA on RCBD with one <b>missing</b> <b>data</b> show no effect of treatment and group by the tensile strength of the glue. For Fe toxicity experiment with two <b>missing</b> <b>data</b> are found only treatment effect to Fe texicity. Based on value from the coefficient of variance for one <b>missing</b> <b>data</b> and two <b>missing</b> <b>data</b> showed that ANCOVA is more appropriately used than ANOVA...|$|R
40|$|<b>Missing</b> <b>data</b> {{arise in}} almost all {{scientific}} disciplines. In many cases, <b>missing</b> <b>data</b> in an analysis is treated in a casual and ad-hoc manner, leading to invalid inferences and erroneous conclusions. This book summarizes knowledge regarding the theory of estimation for semiparametric models with <b>missing</b> <b>data...</b>|$|R
40|$|Abstract. When {{handling}} <b>missing</b> <b>data,</b> {{a researcher}} {{should be aware}} of the mechanism underly-ing the missingness. In the presence of non-randomly <b>missing</b> <b>data,</b> a model of the <b>missing</b> <b>data</b> mechanism should be included in the analyses to prevent the analyses based on the data from becoming biased. Modeling the <b>missing</b> <b>data</b> mechanism, however, is a difficult task. One way in which knowledge about the <b>missing</b> <b>data</b> mechanism may be obtained is by collecting additional data from non-respondents. In this paper the method of re-approaching respondents who did not answer all questions of a questionnaire is described. New answers were obtained from a sample of these non-respondents and the reason(s) for skipping questions was (were) probed for. The additional data resulted in a larger sample and was used to investigate the differences between respondents and non-respondents, whereas probing for the causes of missingness resulted in more knowledge about the nature of the <b>missing</b> <b>data</b> patterns. Key words: <b>missing</b> <b>data,</b> follow-up, cause of missingness, scale data. 1...|$|R
40|$|<b>Missing</b> <b>data</b> is {{unavoidable}} in sensor networks due to sensor faults, communication malfunctioning and malicious attacks. There {{is a very}} little insight in <b>missing</b> <b>data</b> causes and statistical and pattern properties of <b>missing</b> <b>data</b> in collected data streams. To address this problem, we utilize interactingparticle model {{that takes into account}} both patterns of <b>missing</b> <b>data</b> at individual sensor data streams as well as the correlation between occurrence of <b>missing</b> <b>data</b> at other sensor data streams. The model can be used in algorithms and protocols for energy efficient data collection and other tasks in presence of <b>missing</b> <b>data.</b> We use statistical intersensor models for predicting the readings of different sensors. As a driver application, we address the problem of energy efficient sensing by adaptively coordinating the sleep schedules of sensor nodes while we guarantee that values of nodes in the sleep mode can be recovered from the awake nodes within a user's specified error bound and probability of <b>missing</b> <b>data</b> at awake nodes is less than a given threshold. The sleeping coordination is addressed by creating the maximal number of subgroups of disjoint nodes, each of whose data is sufficient to recover the data of the entire network in presence of <b>missing</b> <b>data.</b> On simulated and actually collected data for temperature and humidity sensors in Intel Berkeley Lab, we show that by using sleeping coordination that considers <b>missing</b> <b>data,</b> we reduce the typical 40 % <b>missing</b> <b>data</b> rate of traditional sleeping techniques to less than 7 %. 1...|$|R
3000|$|... is {{considered}} to be a latent construct, θ is an inherently unobserved (i.e., <b>missing)</b> variable. <b>Missing</b> <b>data</b> in the individual response pattern (the 0 / 1 answers of persons to test items) constitute the second type, and <b>missing</b> <b>data</b> in background information constitute the third type of <b>missing</b> <b>data.</b>|$|R
40|$|Multiple {{imputation}} {{can handle}} <b>missing</b> <b>data</b> and disclosure limitation simultaneously. First, {{fill in the}} <b>missing</b> <b>data</b> to generate m completed datasets, then replace confidential values in each completed dataset with r imputations. I investigate how to select m and r. Confidentiality Disclosure <b>Missing</b> <b>data</b> Multiple imputation Synthetic data...|$|R
40|$|In the {{framework}} of <b>missing</b> <b>data</b> imputation, Rubin formalized three types of <b>missing</b> <b>data</b> mechanisms upon deﬁnition of a <b>missing</b> <b>data</b> indicator matrix pointing out the missing-ness in the data matrix, assigning it a random variable with a conditional probability distribution given the data matrix depending on unknown parameters. Within Rubin’s paradigm, <b>missing</b> <b>data</b> imputation {{can be understood as}} a model selection problem, such as to estimate the performance of different models in order to choose the best one which generate sample data. This paper formalizes a new <b>missing</b> <b>data</b> imputation paradigm. Within statistical learning paradigm, <b>missing</b> <b>data</b> imputation can be understood as a model assessment problem, whatever is the probability model underlying sample data the goal is to minimize its prediction error (generalization error) on new data...|$|R
30|$|In {{this paper}} two {{spectral}} methods for data imputation, originating from the discrete sampling theorem, {{are introduced to}} air quality time series with <b>missing</b> <b>data.</b> The methods are thoroughly evaluated {{with respect to the}} common practice and {{the state of the art}} <b>missing</b> <b>data</b> recovery methods. The evaluation of the methods here is much more comprehensive than previous studies, as it uses much longer air quality time series with no <b>missing</b> <b>data,</b> under significantly larger number <b>missing</b> <b>data</b> scenarios.|$|R
40|$|When {{analyzing}} {{data from}} environmental surveys, the researcher {{must address the}} issue of how to handle <b>missing</b> <b>data.</b> Methods proposed to solve the <b>missing</b> <b>data</b> problem in estimation procedures should consider the type of <b>missing</b> <b>data,</b> the sampling design used to collect the data, and the availability of auxiliary variables correlated with the process of interest. In this paper, we consider different approaches to handling <b>missing</b> <b>data</b> and study their properties when applied to environmental data. 1...|$|R
40|$|<b>Missing</b> <b>data</b> {{occur in}} {{virtually}} every study. The present paper reviews some of the various strategies for addressing the <b>missing</b> <b>data</b> problem. The paper also provides instructional detail on two accessible ways of estimating <b>missing</b> <b>data,</b> both using SPSS for Windows: (a) substitution of missing values with the variable mean of non-missing scores; and (b) replacement of missing values with estimates derived from regression. Nine tables and five appendices provide details of the analyses and outputs. <b>Missing</b> <b>Data...</b>|$|R
40|$|Autoencoder {{neural network}} is {{implemented}} {{to estimate the}} <b>missing</b> <b>data.</b> Genetic algorithm is implemented for network optimization and estimating the <b>missing</b> <b>data.</b> <b>Missing</b> <b>data</b> is treated as Missing At Random mechanism by implementing maximum likelihood algorithm. The network performance is determined by calculating the mean square error of the network prediction. The network is further optimized by implementing Decision Forest. The impact of <b>missing</b> <b>data</b> is then investigated and decision forrests are found to improve the results...|$|R
40|$|<b>Missing</b> <b>data</b> in scales {{can occur}} at the item score level or total score level. However, a lot of studies have only {{researched}} the performance of <b>missing</b> <b>data</b> methods applied to the item level. This study investigates whether the <b>missing</b> <b>data</b> problem in scales should be solved on the item score level or total score level and, more importantly, which <b>missing</b> <b>data</b> method {{could be used to}} most efficiently handle the <b>missing</b> <b>data</b> problem at that level. First different methods to handle <b>missing</b> <b>data</b> are discussed. I argue that deletion methods and single imputation methods should be avoided and consider multiple imputation and maximum likelihood estimation as proper methods. I propose that multiple imputation applied to the scale items should be used to handle <b>missing</b> <b>data</b> in scales. Second, I research the performance of two approaches of multiple imputation applied to the items. I compare passive imputation to best predictor imputation, an approach where an incomplete item is imputed by its best (i. e. highest correlated) predictors. Best predictors imputation is found to be more efficient than passive imputation when handling <b>missing</b> <b>data</b> in scales in the simulated data...|$|R
40|$|<b>Missing</b> <b>data</b> are {{prevalent}} {{in nearly all}} areas of research. It is of utmost importance that appropriate methods are used to obtain statistically valid inferences {{in the presence of}} <b>missing</b> <b>data.</b> Multiple imputation relies on the creation of multiple sets of plausible values for the <b>missing</b> <b>data.</b> We provide background on <b>missing</b> <b>data</b> and its consequences, and describe the fundamental concepts underlying multiple imputation. We then describe a flexible implementation of multiple imputation, called multiple imputation by chained equations, that allows the analyst to specify a separate conditional regression for each variable with <b>missing</b> <b>data.</b> We conclude with an overview of software options for multiple imputation by chained equations...|$|R
40|$|<b>Missing</b> <b>data</b> is {{a common}} issue in {{research}} that, if improperly handled, can lead to inaccurate conclusions about populations. A variety of statistical techniques are available to treat <b>missing</b> <b>data.</b> Some of these are simple while others are conceptually and mathematically complex. The {{purpose of this paper}} is to provide the novice researcher with an introductory conceptual overview of the issue of <b>missing</b> <b>data.</b> The authors discuss patterns of <b>missing</b> <b>data,</b> common missing-data handling techniques, and issues associated with <b>missing</b> <b>data.</b> Techniques discussed include listwise deletion, pairwise deletion, case mean substitution, sample mean substitution, group mean substitution, regression imputation, and estimation maximization. © McGill University School of Nursing...|$|R
40|$|AbstractThis paper {{presents}} a decomposition for the posterior {{distribution of the}} covarianee matrix of normal models under a family of prior distributions when <b>missing</b> <b>data</b> are ignorable and monotone. This decomposition {{is an extension of}} Bartlett′s decomposition of the Wishart distribution to monotone <b>missing</b> <b>data.</b> It is not only theoretically interesting but also practically useful. First, with monotone <b>missing</b> <b>data,</b> it allows more efficient drawing of parameters from the posterior distribution than the factorized likelihood approach. Furthermore, with nonmonotone <b>missing</b> <b>data,</b> it allows for a very efficient monotone date augmentation algorithm and thereby multiple imputation or the <b>missing</b> <b>data</b> needed to create a monotone pattern...|$|R
