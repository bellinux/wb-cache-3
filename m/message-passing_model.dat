105|96|Public
5000|$|Both Prim’s {{algorithm}} and Kruskal’s algorithm require {{processes to}} know {{the state of the}} whole graph, which is very difficult to discover in the <b>message-passing</b> <b>model.</b>|$|E
50|$|Due {{to these}} difficulties, new {{techniques}} were needed for distributed MST algorithms in the <b>message-passing</b> <b>model.</b> Some bear similarities to Borůvka's algorithm for the classical MST problem.|$|E
50|$|The GHS {{algorithm}} of Gallager, Humblet and Spira {{is one of}} {{the best-known}} algorithms in distributed computing theory. This algorithm can construct the MST in asynchronous <b>Message-passing</b> <b>model.</b>|$|E
50|$|Today, {{the most}} {{commonly}} used programming languages that have specific constructs for concurrency are Java and C#. Both of these languages fundamentally use a shared-memory concurrency model, with locking provided by monitors (although <b>message-passing</b> <b>models</b> can and have been implemented on top of the underlying shared-memory model). Of the languages that use a <b>message-passing</b> concurrency <b>model,</b> Erlang is probably the most widely used in industry at present.|$|R
50|$|Whereas <b>message-passing</b> <b>models</b> require tightly-coupled {{processes}} sending {{messages to}} each other in some sequence or protocol, Linda processes are decoupled from other processes, communicating only through the tuplespace; a process need have no notion of other processes except for the kinds of tuples consumed or produced (data coupling).|$|R
40|$|This paper {{deals with}} the problem of {{broadcasting}} in minimum time in the telephone and <b>message-passing</b> <b>models.</b> Approximation algorithms are developed for arbitrary graphs, as well as for several restricted graph classes. In particular, an O(p n) -additive approximation algorithm is given for broadcasting in general graphs, and an O(log log n= log n) (multiplicative) ratio approximation is given for broadcasting in the open path model. This also results in an algorithm for broadcasting on random graphs (in the telephone and <b>message-passing</b> <b>models),</b> that yields an O(log log n= log n) approximation with high probability. In addition, the paper presents a broadcast algorithm for graph families with small separators (such as chordal, k-outerplanar, bounded-face planar and series-parallel graphs), with approximation ratio proportional to the separator size times log n. Finally, an efficient approximation algorithm is presented for the class of graphs representable as trees of c [...] ...|$|R
50|$|Termite Scheme is {{a variant}} of Scheme {{implemented}} on top of Gambit-C. Termite is intended for distributed computing, it offers a simple and powerful <b>message-passing</b> <b>model</b> of concurrency, inspired by that of Erlang.|$|E
5000|$|Two {{commonly}} used algorithms for the classical {{minimum spanning tree}} problem are Prim’s algorithm and Kruskal’s algorithm. However, {{it is difficult to}} apply these two algorithms in the distributed <b>message-passing</b> <b>model.</b> The main challenges are: ...|$|E
50|$|The <b>message-passing</b> <b>model</b> {{is one of}} {{the most}} {{commonly}} used models in distributed computing. In this model, each process is modeled as a node of a graph. The communication channel between two processes is an edge of the graph.|$|E
40|$|Abstract. This paper {{deals with}} the problem of {{broadcasting}} in minimum time in the tele-phone and <b>message-passing</b> <b>models.</b> Approximation algorithms are developed for arbitrary graphs as well as for several restricted graph classes. In particular, an O(vfvT) -additive approximation algorithm is given for broadcasting in general graphs, and an O(log n / log log n) (multiplicative) ratio approximation is given for broadcasting in the open-path model. This also results in an algorithm for broadcasting on random graphs (in the telephone and <b>message-passing</b> <b>models)</b> that yields an O(log n / log log n) approximation with high probability. In addition, the paper presents a broadcast algorithm for graph families with small separators (such as chordal, k-outerplanar, bounded-face planar, and series-parallel graphs), with approximation ratio proportional to the separator size times log n. Finally, an efficient approximation algorithm is presented for the class of graphs representable as trees of cliques. Key words, broadcast, approximation AMS subject classifications. 05 C 85, 68 Q 25, 90 C 27, 90 B 3...|$|R
40|$|We {{present a}} unified, axiomatic {{approach}} to proving lower bounds for the k-set agreement problem in both synchronous and asynchronous <b>message-passing</b> <b>models.</b> The proof involves constructing {{the set of}} reachable states, proving that these states are highly connected, and then appealing to a well-known topological result that high connectivity implies that set agreement is impossible. We construct the set of reachable states in an iterative fashion using a round operator that we define, and our proof of connectivity is an inductive proof based on this iterative construction and simple properties of the round operator. ...|$|R
40|$|PGAS {{programming}} languages such as Chapel, Coar-ray Fortran, Habanero-C, UPC and X 10 [3 – 6, 8] sup-port high-level {{and highly}} productive programming models for large-scale parallelism. Unlike <b>message-passing</b> <b>models</b> such as MPI, which introduce non-trivial complexity due to message passing semantics, PGAS languages simplify distributed parallel program-ming by introducing higher level parallel language con-structs that include operations on global / distributed arrays, distributed task parallelism, directed synchro-nization and mutual exclusion. Past studies on program analysis and optimizations for PGAS programming languages have been spe-cific to different languages, i. e. either built on spe...|$|R
50|$|The Actor model might usefully be {{described}} as a specialised kind of process-oriented system in which the <b>message-passing</b> <b>model</b> is restricted to the simple fixed case of one infinite input queue per process (i.e. actor), to which any other process can send messages.|$|E
50|$|Thus the <b>message-passing</b> <b>model</b> in Smalltalk-72 {{was closely}} tied to a {{particular}} machine model and programming-language syntax that did not lend itself to concurrency. Also, although the system was bootstrapped on itself, the language constructs were not formally defined as objects that respond to Eval messages (see discussion below). This led some {{to believe that a}} new mathematical model of concurrent computation based on message passing should be simpler than Smalltalk-72.|$|E
50|$|In a <b>message-passing</b> <b>model,</b> {{parallel}} processes exchange data through passing {{messages to}} one another. These communications can be asynchronous, where a message {{can be sent}} before the receiver is ready, or synchronous, where the receiver must be ready. The Communicating sequential processes (CSP) formalisation of message passing uses synchronous communication channels to connect processes, and led to important languages such as Occam, Limbo and Go. In contrast, the actor model uses asynchronous message passing and has been employed {{in the design of}} languages such as D, Scala and SALSA.|$|E
40|$|AbstractWe {{present a}} unified, axiomatic {{approach}} to proving lower bounds for the k-set agreement problem in both synchronous and asynchronous <b>message-passing</b> <b>models.</b> The proof involves constructing {{the set of}} reachable states, proving that these states are highly connected, and then appealing to a well-known topological result that high connectivity implies that set agreement is impossible. We construct the set of reachable states in an iterative fashion using a round operator that we define, and our proof of connectivity is an inductive proof based on this iterative construction and simple properties of the round operator...|$|R
40|$|Abstract—X 10 {{is a new}} {{object-oriented}} PGAS (Partitioned Global Address Space) {{programming language}} with support for distributed asynchronous dynamic parallelism that goes beyond past SPMD <b>message-passing</b> <b>models</b> such as MPI and SPMD PGAS models such as UPC and Co-Array Fortran. The concurrency constructs in X 10 {{make it possible to}} ex-press complex computation and communication structures with higher productivity than other distributed-memory program-ming models. However, this productivity often comes at the cost of high performance overhead when the language is used in its full generality. This paper introduces high-level compiler optimizations and transformations to reduce communication and synchronization overheads in distributed-memory implementations of X 10 pro-grams. Specifically, we focus on locality optimizations suc...|$|R
40|$|We {{argue that}} OS-provided data {{coherence}} on non-cache-coherent NUMA multiprocessors (machines with a single, global physical address space), can perform substantially better than distributed shared memory emulations on message-passing hardware, {{and almost as}} well as fully cache-coherent multiprocessors. 1 Introduction As a means of expressing parallel algorithms, shared memory programming models are widely believed to be easier to use than <b>message-passing</b> <b>models.</b> Small-scale, bus-based shared-memory multiprocessors are now ubiquitous, and several large-scale cache-coherent multiprocessors have been designed in recent years. Unfortunately, large machines are substantially more difficult to build than small ones, because snooping does not scale. It appears likely that large-scale cache coherence will have high per-processor costs (relative to workstations and small-scale multiprocessors) for the foreseeable future. Many researchers have therefore undertaken to harness the parallel proce [...] ...|$|R
40|$|This paper {{presents}} an algorithm for performing on-the-fly race detection for parallel message-passing programs. The algorithm reads {{a trace of}} the communication events in a message-passing parallel program and either finds a specific race condition or reports that the traced program is race-free. It supports a rich <b>message-passing</b> <b>model,</b> including blocking and nonblocking sends and receives, synchronous and asynchronous sends, receive selectivity by source and/or tag value, and arbitrary amounts of system buffering of messages. It runs in polynomial time and is very efficient for most types of executions. A key feature of the race detection algorithm is its use of several new types of logical clocks for determining ordering relations. It is likely that these logical clocks will also be useful in other settings. 1 Introduction Many commercial parallel computers support a <b>message-passing</b> <b>model</b> in which processes communicate solely by issuing matching send and receive commands. If a si [...] ...|$|E
40|$|Micha/l Ha'n'ckowiak Dept of Math and CS Adam Mickiewicz University Pozna'n, Poland Micha/l Karo'nski Dept of Math and CS Adam Mickiewicz University Pozna'n, Poland & Dept of Math and CS Emory University Atlanta, Georgia, USA Alessandro Panconesi Dept of CS University of Bologna Bologna, Italy Abstract We {{show that}} maximal {{matchings}} can be computed deterministically in O(log 4 n) rounds in the synchronous, <b>message-passing</b> <b>model</b> of computation. This improves {{on an earlier}} result by three log-factors. 1 Introduction In this paper we show that maximal matchings (MM's) can be computed deterministically in O(log 4 n) rounds in the synchronous, <b>message-passing</b> <b>model</b> of computation. This improves substantially on an earlier result by the present authors, which shows that MM's can be computed in O(log 7 n) many rounds [9]. This rather substantial improvement in asymptotics is based on several new algorithmic ideas that, we hope, might prove useful in other conte [...] ...|$|E
40|$|Abstract. This paper {{presents}} a schematic algorithm for distributed systems. This schematic algorithm uses a &quot;black-box &quot; procedure for communication, {{the output of}} which must meet two requirements: a global-order requirement and a deadlock-free requirement. This algorithm is valid in any distributed system model that can provide such a communication procedure that complies with these requirements. Two such models exist in an asynchronous fail-stop environment: one in the shared-memory model {{and one in the}} <b>message-passing</b> <b>model.</b> The implementation of the block-box procedure in these models enables us to translate existing algorithms between the two models whenever these algorithms are based on the schematic algorithm. We demonstrate this idea in two ways. First, we present a randomized algorithm for the consensus problem in the <b>message-passing</b> <b>model</b> based on the algorithm of Aspnes and Herlihy [AH] in the shared-memory model. This solution is the fastest known randomized algorithm that solves the consensus problem against a strong fail-stop adversary with one-half resiliency. Second...|$|E
40|$|We take a signi cant {{step toward}} unifying the synchronous, semi-synchronous, and {{asynchronous}} <b>message-passing</b> <b>models</b> of distributed computation. The key idea {{is the concept}} of a pseudosphere, anew combinatorial structure in which each process from a set of processes is independently assigned a value from a set of values. Pseudospheres have anumber of nice combinatorial properties, but their principal interest lies in the observation that the behavior of protocols in the three models can be characterized as simple unions of pseudospheres, where the exact structure of these unions is determined by the timing properties of the model. We use this pseudosphere construction to derive new and remarkably succinct proofs of bounds on consensus and k-set agreement in the asynchronous and synchronous models, as well as the rst lower bound on wait-free k-set agreement in the semi-synchronous model. ...|$|R
40|$|The Bulk Synchronous Parallel (BSP) {{programming}} {{model is}} attractive for par-allel programs that proceed in “phases”: it is simpler to program than more general <b>message-passing</b> <b>models</b> such as MPI, and facilitates performance forecasting. While restricting overlap {{of communication and}} computation, it lends itself to efficient com-munication through aggregation and scheduling, thereby preventing unnecessary end-point contention. InfiniBand is a standard high-speed, low-latency interconnect for clusters. This paper explores the possibility of efficient BSP implementation on com-puter clusters. We present an architecture and prototype implementation of BSP in an InfiniBand-connected PC-based cluster, utilizing the unique capabilities of InfiniBand for efficient implementation of key BSP functions such as barrier synchronization. This enables demanding applications to achieve good speedups. Our commodity BSP-IB cluster forms a well-balanced parallel machine, outperforming custom multiprocessor BSP machines (e. g., IBM SP and Origin 2000) in every respect. ...|$|R
40|$|A {{fundamental}} {{issue in the}} use of message-passing systems is the creation of repeatable and portable programs. Repeatable program behavior is critical for debugging message-passing programs, while portability is essential for efficient software development. This paper makes two main contributions. First, it defines a set of program executions (called safe executions) that are guaranteed to be repeatable and portable. Safe program executions are defined for applications that utilize both blocking and nonblocking send and receive primitives, synchronous and asynchronous sends, and receives that select on the basis of source and/or tag values. To the best of our knowledge, {{this is the first time}} that conditions for repeatable and portable executions have been created for such rich <b>message-passing</b> <b>models.</b> Second, this paper gives precise characterizations of safe executions. The safety of an execution is shown to depend on the message-ordering properties of the underlying communication sys [...] ...|$|R
40|$|In {{a multiparty}} <b>message-passing</b> <b>model</b> of communication, there are k players. Each player has a private input, and they {{communicate}} by sending messages {{to one another}} over private channels. While this model has been used extensively in distributed computing and in multiparty computation, lower bounds on communication complexity in this model and related models have been somewhat scarce. In recent work phillips 12,woodruff 12,woodruff 13, strong lower bounds of the form Ω(n · k) were obtained for several functions in the message-passing model; however, a lower bound on the classical Set Disjointness problem remained elusive. In this paper, we prove tight lower bounds of the form Ω(n · k) for the Set Disjointness problem in the message passing model. Our bounds are obtained by developing information complexity tools in the <b>message-passing</b> <b>model,</b> and then proving an information complexity lower bound for Set Disjointness. As a corollary, we show a tight lower bound for the task allocation problem DruckerKuhnOshman via a reduction from Set Disjointness...|$|E
40|$|We {{revisit the}} problem of {{detecting}} the termination of a distributed application in an asynchronous <b>message-passing</b> <b>model</b> with crash-recovery failures and failure detectors. We derive a suitable definition of termination detection in this model but show that this definition is impossible to implement {{unless you have a}} failure detector which can predict the future. We subsequently weaken the problem and strengthen the failure model to allow solvability...|$|E
40|$|A {{radio network}} is a {{synchronous}} network of processors that communicate by transmitting messages to their neighbors. A processor receives {{a message in}} a given step {{if and only if}} it is silent then and precisely one of its neighbors transmits. This stringent rule poses serious difficulties in performing even the simplest tasks. This is true even under the overly optimistic assumptions of centralized coordination and complete knowledge of the network topology. We look at the question of simulating two of the standard message-passing models on a radio network. In the general <b>message-passing</b> <b>model,</b> a processor may send each of its outgoing neighbors a possibly different message in each round. In the uniform <b>message-passing</b> <b>model,</b> in each round a processor must send an identical message to all its outgoing neighbors. Both message-passing models can easily simulate the radio model with no overhead. In the other direction, we propose and study a primitive called the single-round simulation (SRS), enabling the simulation of a single round of an algorithm designed for the standard message models. We give lower bounds for th...|$|E
40|$|Current message-passing {{parallel}} computers provide {{send and receive}} primitives {{with a wide variety}} of blocking, synchronization, selectivity and ordering properties. Unfortunately, the interactions between the different properties of the send and receive primitives can be extremely complex, and as a result, the precise semantics of these primitives are not well understood. In this paper we present formal <b>models</b> for <b>message-passing</b> systems that provide both synchronous and asynchronous sends, both blocking and nonblocking sends and receives, and a variety of ordering properties. In addition, the receive primitives are very general in that they can specify the desired source and/or tag value of a message. Our models apply to all message-passing programs, including ones with errors, and they apply to {{parallel computers}} with arbitrary amounts of buffering. To the best of our knowledge, this is the first time that such rich <b>message-passing</b> <b>models</b> have been defined formally. In addition to p [...] ...|$|R
40|$|The long {{foreseen}} goal {{of parallel}} programming models is to scale parallel code without significant programming effort. Irregular parallel applications are a particularly challenging application domain for parallel programming models, since they require domain specific data distribution and load balancing algorithms. From a performance perspective, shared-memory models still {{fall short of}} scaling as well as <b>message-passing</b> <b>models</b> in irregular applications, although they require less coding effort. We present a simple runtime methodology for scaling irregular applications parallelized with the standard OpenMP interface. We claim that our parallelization methodology requires the minimum amount of effort from the programmer and prove experimentally that {{it is able to}} scale two highly irregular codes as well as MPI, with an order of magnitude less programming effort. This is probably the first time such a result is obtained from OpenMP, more so, by keeping the OpenMP API intact. 1...|$|R
40|$|Given the {{complexity}} of high-performance parallel programs, developers often must rely on performance analysis tools to help them improve {{the performance of their}} applications. While many tools support analysis of message-passing programs, tool support is limited for applications written in programming models that present a partitioned global address space (PGAS) to the programmer such as UPC and SHMEM. Existing tools that support <b>message-passing</b> <b>models</b> are difficult to extend to support PGAS models due to differences between the two paradigms and the techniques used in their imple-mentations. In this paper, we present our work on Parallel PerformanceWizard (PPW), a performance analysis system for PGAS and MPI application analysis. We discuss new concepts, namely the generic-operation-type abstraction and GASP-enabled data collection, developed to facilitate support for multiple programming models and then give an overview of PPW’s automatic analysis and visualization capabilities. Finally, to show the usefulness of our system, we present results on PPW’s overhead, storage requirements and scalability before demonstrating its effectiveness via application case studies...|$|R
40|$|Abstract—Most Ad Hoc {{networks}} use diffusion to commu-nicate. This {{approach requires}} many messages and may cause network saturation. To optimize these communications, one solution consists in structuring networks into clusters. In this paper, {{we present a}} new self-stabilizing asynchronous distributed algorithm based on <b>message-passing</b> <b>model.</b> We compare the proposed algorithm {{with one of the}} best existing solutions based on <b>message-passing</b> <b>model.</b> Our approach does not require any initialization and builds non-overlapping k-hops clusters. It is based only on information from neighboring nodes with periodic messages exchange. Starting from an arbitrary configuration, the network converges to a stable state after a finite number of steps. A legal configuration is reached after at most n+ 2 transitions and uses at most n ∗ log(2 n+ k + 3) memory space, where n is the number of network nodes. Using the OMNeT++ simulator, we performed an evaluation of the proposed algorithm to notably show that we use fewer messages and stabilizing time is better. Keywords-ad hoc networks; clustering; distributed algorithms;self-stabilizing; OMNeT++ simulator I...|$|E
40|$|AbstractA slowly-growing {{number of}} {{computer}} {{scientists have found}} that ideas from topology {{can be used to}} analyze and understand problems in distributed computing. In this paper, we review one approach we have used in the past to write a succinct proof of the lower bound for the number of rounds needed to solve the k-set agreement problem in a synchronous, <b>message-passing</b> <b>model</b> of computation. The central idea in this approach is a simple combinatorial structure we call apseudosphere in which each process from a set of processes is independently assigned a value from a set of values. Pseudospheres have a number of nice combinatorial properties, but their principal interest lies in the observation that the global states that arise in the synchronous, <b>message-passing</b> <b>model</b> can be viewed as simple unions of pseudospheres, and the fact that topological properties of unions of pseudospheres are so easy to prove. We choose this work to review because it is a simple example of how we model distributed systems with topology, and because it is the basis of on-going work to simplify the proof of this result...|$|E
40|$|In {{this paper}} {{we present a}} self-stabilizing quorum-based {{distributed}} mutual exclusion algorithm. Our algorithm is designed for an asynchronous <b>message-passing</b> <b>model.</b> The algorithm scales well since it has constant synchronization delay and its message complexity {{is proportional to the}} square root of the number of processes in the system. The algorithm tolerates message loss. The algorithm places few assumptions on timeouts needed for its implementation. All this allows for a ready implementation of the algorithm on practical distributed architectures...|$|E
40|$|We {{consider}} the communication complexity of finding an approximate maximum matching in a graph in a multi-party <b>message-passing</b> communication <b>model.</b> The maximum matching problem {{is one of}} the most fundamental graph combinatorial problems, with a variety of applications. The input to the problem is a graph G that has n vertices and the set of edges partitioned over k sites, and an approximation ratio parameter α. The output is required to be a matching in G that has to be reported by one of the sites, whose size is at least factor α of the size of a maximum matching in G. We show that the communication complexity of this problem is Ω(α^ 2 k n) information bits. This bound is shown to be tight up to a n factor, by constructing an algorithm, establishing its correctness, and an upper bound on the communication cost. The lower bound also applies to other graph combinatorial problems in the <b>message-passing</b> communication <b>model,</b> including max-flow and graph sparsification...|$|R
40|$|We present Cloud Haskell, {{a domain}} {{specific}} language for developing programs for a distributed-memory computing environment. Implemented as a shallow embedding in Haskell, {{it provides a}} <b>message-passing</b> communication <b>model,</b> inspired by Erlang, without introducing incompatibility with Haskell 2 ̆ 7 s established sharedmemory concurrency. A key contribution is a method for serializing function closures for transmission across the network. Cloud Haskell has been implemented; we present example code and some preliminary performance measurements...|$|R
40|$|In {{a system}} with limited-scope failure detectors, there are q {{clusters}} of processes such that some correct process in each cluster is never suspected by any process in that cluster. The failure detector class Sx,q satisfies this property all the time, while ⋄Sx,q satisfies it eventually. This paper gives the first tight bounds for the k-set agreement task in asynchronous <b>message-passing</b> <b>models</b> augmented with failure detectors from either the Sx,q or ⋄Sx,q classes. For Sx,q, we show that any k-set agreement protocol that tolerates f failures must satisfy f<k+ x − q, wherexisthe combined size of the k largest clusters. This result establishes {{for the first time}} that the protocol of Mostéfaoui and Raynal for the Sx = Sx, 1 failure detector is optimal. For ⋄Sx,q, we show that any k-set agreement protocol that tolerates f failures must satisfy f<min (n+ 1,k+ x − q). We give a novel protocol 2 that matches our lower bound, disproving a conjecture of Mostéfaoui and Raynal for the ⋄Sx = ⋄Sx, 1 failure detector. Our lower bounds exploit techniques borrowed from Combinatorial Topology, demonstrating {{for the first time that}} this approach is applicable to models that encompass failure detectors. ...|$|R
