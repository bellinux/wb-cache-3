303|35|Public
25|$|A set A of {{vertices}} in a graph {{is said to}} be {{a module}} if every vertex in A has the same set of neighbours outside of A. Any graph has a uniquely recursive decomposition into modules, its <b>modular</b> <b>decomposition,</b> which can be constructed from the graph in linear time; <b>modular</b> <b>decomposition</b> algorithms have applications in other graph algorithms including the recognition of comparability graphs.|$|E
25|$|Cographs may be {{recognized}} in linear time, and a cotree representation constructed, using <b>modular</b> <b>decomposition,</b> partition refinement, LexBFS , or split decomposition. Once a cotree representation has been constructed, many familiar graph problems may be solved via simple bottom-up calculations on the cotrees.|$|E
50|$|<b>Modular</b> <b>decomposition</b> {{can be used}} {{to compute}} a power graph by using the strong modules of the modular decomposition.Modules in <b>modular</b> <b>decomposition</b> are groups of nodes in a graph thathave {{identical}} neighbors. A Strong Module is a module that does not overlap with another module. However, in complex networks strong modules are more the exception than the rule. Therefore, the power graphs obtained through <b>modular</b> <b>decomposition</b> are far from minimality.The main difference between <b>modular</b> <b>decomposition</b> and power graph analysis is the emphasis of power graph analysis in decomposing graphs not only using modules of nodes but also modules of edges (cliques, bicliques). Indeed, power graph analysis {{can be seen as a}} loss-less simultaneous clustering of both nodes and edges.|$|E
40|$|Usually, {{mathematical}} objects have highly parallel interpretations. In this paper, {{we consider}} them as sequential constructors of other objects. In particular, we prove that every reflexive directed graph {{can be interpreted}} as a program that builds another and is itself builded by another. That leads to some optimal memory computations, codings similar to <b>modular</b> <b>decompositions</b> and other strange dynamical phenomenons. Comment: 11 page...|$|R
40|$|Kernelization algorithms, {{usually a}} {{preprocessing}} step before other more traditional algorithms, are very special {{in the sense}} that they return (reduced) instances, instead of final results. This characteristic excludes the freedom of applying a kernelization algorithm for the weighted version of a problem to its unweighted instances. Thus with only very few special cases, kernelization algorithms have to be studied separately for weigthed and unweighted versions of a single problem. feedback arc set on tournament is currently a very popular problem in recent research of parameterized, as well as approximation computation, and its wide applications in many areas make it appear in all top conferences. The theory of graph <b>modular</b> <b>decompositions</b> is a general approach in the study of graph structures, which only had its surfaces touched in previous work on kernelization algorithms of feedback arc set on tournament. In this paper, we study further properties of graph <b>modular</b> <b>decompositions</b> and apply them to obtain the first linear kernel for the unweighted feedback arc set on tournament problem, which only admits linear kernel in its weighted version, while quadratic kernel for the unweighted. Comment: further improvement under progres...|$|R
40|$|B. Courcelle 1;? and J. A. Makowsky 2; 3;?? 1 LaBRI Universite Bordeaux- 1, Talence, France e{mail: courcell@labri. u-bordeaux. fr 2 Department of Computer Science Technion{Israel Institute of Technology, Haifa, Israel e{mail: janos@cs. technion. ac. il 3 Department of Mathematics Swiss Federal Institute of Technology 8092 Zurich, Switzerland Abstract. Tree-like {{structures}} are usually dened by construction from small structures or, equivalently, by "decompositions" as in treedecompositions or <b>modular</b> <b>decompositions,</b> or alternatively by transductions from trees. All {{of these approaches}} lead to parametrized classes of structures for which many classical problems become parametrically tractable. We study the interrelationships between these approaches. The main novelty {{of this paper is}} to enrich the set of operations dening clique-width with a new operation that fuses in one stroke all vertices having a designated label. Adding this fuse operation to the operations [...] ...|$|R
5000|$|... #Caption: An O(n) {{representation}} of the <b>modular</b> <b>decomposition</b> ...|$|E
5000|$|... #Caption: A graph, its {{quotient}} where [...] "bags" [...] of vertices of {{the graph}} {{correspond to the}} children of the root of the <b>modular</b> <b>decomposition</b> tree, and its full <b>modular</b> <b>decomposition</b> tree: series nodes are labeled [...] "s", parallel nodes [...] "//" [...] and prime nodes [...] "p".|$|E
5000|$|<b>Modular</b> <b>decomposition</b> of {{directed}} graphs {{can be done}} in linear time [...]|$|E
40|$|A text {{is a word}} {{together}} with an (additional) linear ordering. Each text has a generic tree representation, called its shape. We consider texts in a logical and an algebraic framework, and we prove that the classes of monadic second order definable and of recognizable text languages coincide. In particular we demonstrate that {{the construction of the}} shape of a text can be formalized in terms of our monadic second-order logic. We briefly consider right-linear grammars for texts. Introduction The theory of 2 -structures, introduced in [7], studies <b>modular</b> <b>decompositions</b> of graph-like structures. In this framework texts appear as representations for a certain subclass of 2 -structures, see [8]. A text is in essence a word extended with an (additional) linear ordering of its positions. In previous work grammars generating context-free text languages were studied [10]. The question addressed in this paper is: which text languages constitute the class of "regular" text languages? We give a [...] ...|$|R
40|$|It {{is known}} {{that a number of}} natural graph {{problems}} which are FPT parameterized by treewidth become W-hard when parameterized by clique-width. It is therefore desirable to find a different structural graph parameter which is as general as possible, covers dense graphs but does not incur such a heavy algorithmic penalty. The main contribution {{of this paper is to}} consider a parameter called modular-width, defined using the well-known notion of <b>modular</b> <b>decompositions.</b> Using a combination of ILPs and dynamic programming we manage to design FPT algorithms for Coloring and Partitioning into paths (and hence Hamiltonian path and Hamiltonian cycle), which are W-hard for both clique-width and its recently introduced restriction, shrub-depth. We thus argue that modular-width occupies a sweet spot as a graph parameter, generalizing several simpler notions on dense graphs but still evading the "price of generality" paid by clique-width. Comment: to appear in IPEC 2013. arXiv admin note: text overlap with arXiv: 1304. 5479 by other author...|$|R
40|$|We {{consider}} {{the problem of}} determining the optimal sequence of tests for {{the discovery of a}} faulty component, where there is a random cost associated with testing a component. Our work is motivated by applications in telecommunications networks, e. g., location and isolation of faults (or intruders) in IP networks. A novel feature in our approach is that a risk-sensitive performance criterion is used in order to rank different competing schedules. Risk-sensitivity is incorporated through the use of an exponential utility function, and hence optimal schedules attain a trade-off between minimal expected costs and, e. g., a low variance about the achievable expected costs. We characterize optimal schedules both when the testing sequence is not subject to precedence constraints, and when it is subject to such constraints, given by an arbitrary partial order. For the case with precedence constraints, we show that our models can be analyzed via <b>modular</b> <b>decompositions,</b> as studied by Monma and Sidney...|$|R
5000|$|<b>Modular</b> <b>decomposition,</b> for {{a proper}} {{generalization}} of connected components on undirected graphs ...|$|E
50|$|Cographs are the graphs {{that only}} have {{parallel}} or series nodes in their <b>modular</b> <b>decomposition</b> tree.|$|E
50|$|A set A of {{vertices}} in a graph {{is said to}} be {{a module}} if every vertex in A has the same set of neighbours outside of A. Any graph has a uniquely recursive decomposition into modules, its <b>modular</b> <b>decomposition,</b> which can be constructed from the graph in linear time; <b>modular</b> <b>decomposition</b> algorithms have applications in other graph algorithms including the recognition of comparability graphs.|$|E
40|$|International audienceOnce {{the set of}} finite graphs is {{equipped}} with an algebra structure (arising from the definition of operations that generalize the concatenation of words), one can define {{the notion of a}} recognizable set of graphs in terms of finite congruences. Applications to the construction of efficient algorithms and to the theory of context-free sets of graphs follow naturally. The class of recognizable sets depends on the signature of graph operations. We consider three signatures related respectively to Hyperedge Replacement (HR) context-free graph grammars, to Vertex Replacement (VR) context-free graph grammars, and to <b>modular</b> <b>decompositions</b> of graphs. We compare the corresponding classes of recognizable sets. We show that they are robust in the sense that many variants of each signature (where in particular operations are defined by quantifier-free formulas, a quite flexible framework) yield the same notions of recognizability. We prove that for graphs without large complete bipartite subgraphs, HR-recognizability and VR-recognizability coincide. The same combinatorial condition equates HR-context-free and VR-context-free sets of graphs. Inasmuch as possible, results are formulated in the more general framework of relational structures...|$|R
40|$|Biochemical {{reaction}} networks typically {{consist of}} a complicated structure with many interacting species and components. Techniques {{for the analysis of}} such complex systems commonly use decompositions into simpler subsystems. These <b>decompositions</b> are often <b>modular,</b> representing the state vector as a concatenation of component vectors. Without transformation, <b>modular</b> <b>decompositions</b> may lead to system parameters directly influencing the dynamics of many subsystems at once. When parameters are the control inputs, this complicates analysis and design. This paper investigates an alternative decomposition, termed layering, which partitions parameters between layers. This allows for hierarchical analysis, where the steady state response of the integrated system to the perturbation of a parameter is calculated in stages. The first stage is to calculate the local response of the steady state of a layer, considered in isolation from other layers; the second is to calculate the perturbed layer's effect on the others when connected back into the full system. This analysis results in a strategy for detecting the layered structure of a biochemical network based on preserving cycles of mass flow within layers. Additionally, by expressing how the local response propagates through the system we uncover the paths by which the direct control of a certain layer may indirectly control others, giving insights into how to exploit their dependencies. © 2014 American Automatic Control Council...|$|R
40|$|Variational data {{assimilation}} estimates {{key control}} parameters of a numerical model {{to minimize the}} misfit between model and actual observations. YAO is a code generator based on a <b>modular</b> graph <b>decomposition</b> of the model; it is particularly suited to generating adjoint codes, which {{is the basis for}} variational assimilation experiments. We present an algorithm that checks the consistency of the calculations defined by the user. We then present how the modular graph structure enables an automatic and efficient parallelization of the generated code on shared memory architectures avoiding data race conditions. We demonstrate our approach on actual geophysical applications...|$|R
5000|$|As a base case, if G {{only has}} one vertex, its <b>modular</b> <b>decomposition</b> {{is a single}} tree node.|$|E
5000|$|In (Gallai, 1967), Gallai {{defined the}} <b>modular</b> <b>decomposition</b> recursively on a graph with vertex set V, as follows: ...|$|E
50|$|There are {{variants}} of <b>modular</b> <b>decomposition</b> for undirected graphs and directed graphs. For each undirected graph, this decomposition is unique.|$|E
40|$|Abstract—We {{introduce}} {{a way to}} program adaptive reactive systems, using behavioral, scenario-based programming. Extending the semantics of live sequence charts with reinforcements allows the programmer not only to specify what the system should do or must not do, but also what it should try to do, in an intuitive and incremental way. By integrating scenario-based programs with reinforcement learning methods, the program can adapt to the environment, and try to achieve the desired goals. Visualization methods and <b>modular</b> learning <b>decompositions,</b> based on the unique structure of the program, are suggested, and result in an efficient development process and a fast learning rate. Keywords-scenario-based programming; adaptive systems; reinforcement learning; behavior-based; LSC; BPJ I...|$|R
40|$|Cluster-based {{descriptions}} of biological networks have received much attention {{in recent years}} fostered by accumulated evidence {{of the existence of}} meaningful correlations between topological network clusters and biological functional modules. Several well-performing clustering algorithms exist to infer topological network partitions. However, due to respective technical idiosyncrasies they might produce dissimilar <b>modular</b> <b>decompositions</b> of a given network. In this contribution, we aimed to analyze how alternative modular descriptions could condition the outcome of follow-up network biology analysis. We considered a human protein interaction network and two paradigmatic cluster recognition algorithms, namely: the Clauset-Newman-Moore and the infomap procedures. We analyzed at what extent both methodologies yielded different results in terms of granularity and biological congruency. In addition, taking into account Guimera cartographic role characterization of network nodes, we explored how the adoption of a given clustering methodology impinged on the ability to highlight relevant network meso-scale connectivity patterns. As a case study we considered a set of aging related proteins, and showed that only the high-resolution modular description provided by infomap, could unveil statistically significant associations between them and inter-intra modular cartographic features. Besides reporting novel biological insights that could be gained from the discovered associations, our contribution warns against possible technical concerns that might affect the tools used to mine for interaction patterns in network biology studies. In particular our results suggested that sub-optimal partitions from the strict point of view of their modularity levels might still be worth being analyzed when meso-scale features were to be explored in connection with external source of biological knowledge. Comment: (v 2 35 pages, 11 figures, including Sup Mat...|$|R
40|$|Movement {{generation}} has been hypothesized {{to rely on}} a modular organization of muscle activity. Crucial to this hypothesis is the ability to perform reliably a variety of motor tasks by recruiting a limited set of modules and combining them in a task-dependent manner. Thus far, existing algorithms that extract putative modules of muscle activations, such as Nonnegative Matrix Factorization (NMF), identify <b>modular</b> <b>decompositions</b> that maximize the reconstruction of the recorded EMG data. Typically, the functional role of the decompositions, i. e. task accomplishment, is only assessed a posteriori. However, as motor actions are defined in task space, we suggest that motor modules should be computed in task space too. In this study, we propose a new module extraction algorithm, named DsNM 3 F, that uses task information during the module identification process. DsNM 3 F extends our previous space-by-time decomposition method (the so-called sNM 3 F algorithm, which could assess task performance only after having computed modules) to identify modules gauging between two complementary objectives: reconstruction of the original data and reliable discrimination of the performed tasks. We show that DsNM 3 F recovers the task dependence of module activations more accurately than sNM 3 F. We also apply it to electromyographic signals recorded during performance of a variety of arm pointing tasks and identify spatial and temporal modules of muscle activity that are highly consistent with previous studies. DsNM 3 F achieves perfect task categorization without significant loss in data approximation when task information is available and generalizes as well as sNM 3 F when applied to new data. These findings suggest that the space-by-time decomposition of muscle activity finds robust task-discriminating modular representations of muscle activity and that the insertion of task discrimination objectives is useful for describing the task modulation of module recruitment...|$|R
5000|$|With a {{small number}} of simple exceptions, every graph with a nontrivial <b>modular</b> <b>decomposition</b> also has a skew {{partition}} [...]|$|E
5000|$|... #Caption: The <b>modular</b> <b>decomposition,</b> {{augmented}} with a quotient on {{the children}} of each internal node, gives a complete representation of G.|$|E
50|$|For {{recognizing}} distance-hereditary graphs and circle graphs, {{a further}} generalization of <b>modular</b> <b>decomposition,</b> called the split decomposition, is especially useful (Spinrad, 2003).|$|E
40|$|<b>Modular</b> problem <b>decomposition</b> {{is often}} {{employed}} {{to cope with}} complex real-world problems. An intelligent decomposition can efficiently lead to compact and general solutions but is, in most cases, the result of laborious domain analysis and engineering. Little {{has been done to}} automatically discover natural decompositions of complex problems while simultaneously solving the subproblems; usually, a decomposition architecture must be specified in advance. This paper presents the Evolutionary Speciation Genetic Programming (ESGP) framework which evolves a problem decomposition as an ensemble of species whose members collectively solve the problem. Problem decomposition emerges as a result of speciation and specialization within each species. Speciation is facilitated by the symbiotic representation of individuals. Cooperation among species emerges through coevolution. We present experiments on complex, multi-regime function approximation problems to demonstrate and analyze the basic concep [...] ...|$|R
40|$|International audienceWe {{introduces}} the umodules, a generalisation {{of the notion}} of graph module. The theory we develop captures among others undirected graphs, tournaments, digraphs, and $ 2 -$structures. We show that, under some axioms, a unique decomposition tree exists for umodules. Polynomial-time algorithms are provided for: non-trivial umodule test, maximal umodule computation, and decomposition tree computation when the tree exists. Our results unify many known <b>decomposition</b> like <b>modular</b> and bi-join <b>decomposition</b> of graphs, and a new decomposition of tournaments...|$|R
40|$|Many {{physical}} systems {{today are}} modeled by interacting continuous and discrete event systems. Such hybrid systems contain both continuous and discrete states {{that influence the}} dynamic behavior. There has been an increasing interest in these types of systems during the last decade, mostly due to the growing use of computers in the control of physical plants {{but also as a}} result of the hybrid nature of physical processes. Hybrid system models, suitable for describing the essential dynamics of a fairly large class of physical systems in control engineering applications, are proposed in this thesis. The continuous dynamics is described by differential equations whose evolution depends on continuous states and inputs as well as discrete states. The discrete dynamics is modeled by discrete event systems dependent on discrete and continuous states and inputs. It is shown that hybrid systems can be constructed by <b>modular</b> <b>decompositions.</b> A closed-loop hybrid system structure consisting of an open-loop hybrid plant and a hybrid controller, suitable for the description of control engineering systems, is proposed. Stability is one of the most important properties of dynamic systems. A large portion of this thesis is focused on conditions ensuring stability of hybrid systems. The stability results are extensions of Lyapunov theory where the existence of an abstract energy function satisfying certain properties verifies stability. It is shown how the search for such functions can be formulated as linear matrix inequality (LMI) problems, where solutions can be found by computerized methods. Stability robustness dealing with the possibility to guarantee stability despite the presence of model uncertainties is also treated. A large number of examples illustrating different approaches is given. There are many controller structures in the industry consisting of local controllers and the design task is to decide the appropriate switching among these. A related problem occurs in the case of having discrete actuators in continuous processes. The design part of this thesis addresses the problem of how to switch between different continuous vector fields guaranteeing stability of the closed-loop system...|$|R
5000|$|<b>Modular</b> <b>decomposition</b> {{is a good}} {{tool for}} solving the maximum weight {{independent}} set problem; the linear time algorithm on cographs is the basic example for that. Another important tool are clique separators as described by Tarjan.|$|E
50|$|The first {{polynomial}} algorithm {{to compute}} the <b>modular</b> <b>decomposition</b> tree of a graph was published in 1972 (James, Stanton & Cowan 1972) and now linear algorithms are available (McConnell & Spinrad 1999, Tedder et al. 2007, Cournier & Habib 1994).|$|E
50|$|Cographs may be {{recognized}} in linear time, and a cotree representation constructed, using <b>modular</b> <b>decomposition,</b> partition refinement, LexBFS , or split decomposition. Once a cotree representation has been constructed, many familiar graph problems may be solved via simple bottom-up calculations on the cotrees.|$|E
40|$|BACKGROUND: Cluster-based {{descriptions}} of biological networks have received much attention {{in recent years}} fostered by accumulated evidence {{of the existence of}} meaningful correlations between topological network clusters and biological functional modules. Several well-performing clustering algorithms exist to infer topological network partitions. However, due to respective technical idiosyncrasies they might produce dissimilar <b>modular</b> <b>decompositions</b> of a given network. In this contribution, we aimed to analyze how alternative modular descriptions could condition the outcome of follow-up network biology analysis. METHODOLOGY:/nWe considered a human protein interaction network and two paradigmatic cluster recognition algorithms, namely: the Clauset-Newman-Moore and the infomap procedures. We analyzed to what extent both methodologies yielded different results in terms of granularity and biological congruency. In addition, taking into account Guimera's cartographic role characterization of network nodes, we explored how the adoption of a given clustering methodology impinged on the ability to highlight relevant network meso-scale connectivity patterns. RESULTS: As a case study we considered a set of aging related proteins and showed that only the high-resolution modular description provided by infomap, could unveil statistically significant associations between them and inter/intra modular cartographic features. Besides reporting novel biological insights that could be gained from the discovered associations, our contribution warns against possible technical concerns that might affect the tools used to mine for interaction patterns in network biology studies. In particular our results suggested that sub-optimal partitions from the strict point of view of their modularity levels might still be worth being analyzed when meso-scale features were to be explored in connection with external source of biological knowledge. : CONICET (grant PIP 0087), UBACyT (grant 20020110200314), ISCIII-FEDER (PI 13 / 00082 and CP 10 / 00524), IMI JU (grant agreements n° [115002] (eTOX) and n° [115191] (Open PHACTS) ], resources of which are composed of financial contribution from the EU's FP 7 (FP 7 / 2007 – 2013) and EFPIA companies’ in kind contribution...|$|R
40|$|Program {{synthesis}} is {{a discipline}} {{aimed at the}} automatic construction of executable programs from declarative specifications that describe the behavior of such programs. When a concurrent program is specified for synthesis, a programmer may indicate that certain program units can be executed concurrently as asynchronous processes. This document describes {{a new approach to}} the automatic synthesis of inter-process communication code for concurrent programs. The long range objective of this work is the definitions of tools and techniques for the production of reliable software systems. ^ Our approach is aimed at enhancing the practicality of program synthesis techniques. First, we define a model in which a concurrent program consists of a set of asynchronous processes that interact with each other by accessing and modifying a set of shared resources. In particular, a program may contain multiple sets of potentially distributed resources. Second, we define a specification language that emphasizes a clear separation of the safety and liveness properties in a program specification. Temporal logic is used to define formally the semantics of program specifications. In addition, our specification language allows for a <b>modular</b> <b>decompositions</b> of program specifications into program units. Third, we define an approach to synthesis that is automatable. ^ Our approach to synthesis is based on the following paradigm. First, a program specification is written in a declarative language based on temporal logic. Second, the specification is analyzed in an effort to prove that the target program satisfies crucial concurrency properties, such as absence of deadlock and freedom of starvation. Third, if the concurrency properties of the specification are established successfully, then Ada code is generated. ^ Our approach broadens significantly the class of programs that can be generated automatically with respect to previous approaches. Programs can be synthesized that contain multiple sets of shared resources. In particular, we have successfully applied this approach to the specification and synthesis of a number of traditional examples for concurrency. These examples cover a variety of features that are typical of concurrent programs, such as mutual exclusion, possibility of deadlock, bounded length queues and interrupts. ...|$|R
30|$|The {{concept of}} {{modularity}} {{can be applied}} not only to complex product system design, but also to business system interpretation and design. However, the amount of literature on modular organization is much less than that on product modularity. Based upon a case study on Haier’s reengineered business-process system after the “market-chain” reform, this paper examines the course of its process decomposition to form a prototype of modular organization, and further analyzes {{the evolution of the}} three key factors in the design rules, which make the independent modules interact with others to form a complex system. The study shows that a system will gain strategic flexibility when more business units in service supplying and product manufacturing are treated as modules of the firm. Meanwhile, a system will become more complex when the number and variety of modules increase, which in turn induces the evolution in the process of the <b>modular</b> organization’s <b>decomposition</b> and integration.|$|R
