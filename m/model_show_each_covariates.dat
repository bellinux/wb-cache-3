0|10000|Public
50|$|Fate {{prediction}} using fugacity <b>modeling</b> has <b>shown</b> that fatty alcohols with chain {{lengths of}} C10 and greater in water partition into sediment. Lengths C14 and above are predicted {{to stay in}} the air upon release. <b>Modeling</b> <b>shows</b> that <b>each</b> type of fatty alcohol will respond independently upon environmental release.|$|R
30|$|P-values for <b>each</b> <b>covariate</b> in <b>each</b> final {{model are}} presented, {{together}} with odds ratios and 95 % confidence intervals for <b>each</b> <b>covariate</b> category versus an appropriate reference group.|$|R
40|$|We analyze {{competition}} in emerging markets between firms {{in developing and}} developed countries {{from the viewpoint of}} the boundaries of the firm. Although indigenous firms generally face a disadvantage in technology compared with foreign firms, they have an advantage in marketing as local firms. Moreover, they have opportunities to leave weaker fields to independent specialized firms and use lower wages. On the other hand, foreign firms also have their own advantages and disadvantages for growth. Therefore, entry conditions for indigenous firms can vary greatly depending on the situation. We classify these conditions into eight cases by developing a <b>model</b> and <b>showing</b> <b>each</b> boundary choice for indigenous firms...|$|R
40|$|This article {{presents}} a cognitive modelling approach for criminal behaviour, which {{is illustrated by}} a case study for the behaviour of three types of violent criminals as known from literature within the area of Criminology. The <b>model</b> can <b>show</b> <b>each</b> of their behaviours, depending on the characteristics set and inputs in terms of stimuli from the environment. Based on literature in Criminology about motivations and opportunities and their underlying factors, it is shown by a formal mapping how the model {{can be related to}} a biological grounding. This formal mapping covers ontology elements for states and dynamic properties for processes, and thus shows how the cognitive model can be biologically grounded...|$|R
40|$|Low-fat {{ground beef}} (LFGB) {{is a new}} product {{designed}} to be as palatable as beef products that contain {{significantly higher levels of}} fat. A hedonic <b>model</b> <b>shows</b> that <b>each</b> unitary increase in the leanness of ground beef products carries a price premium of $. 0206 /lb. If LFGB garners a 10 % share of the ground beef market, the retail price of all ground beef products will increase by $. 01 /lb. and consumption will increase by 39. 75 million lbs. The price of commercial cows will increase by $. 56 /cwt. Price quantity, and welfare measures are magnified as the market share captured by LFGB increases. Agribusiness,...|$|R
40|$|ABSTRACT: The authors {{present a}} generic model of trust for {{electronic}} commerce consist-ing of two basic components, party trust and control trust, {{based on the}} concept that trust in a transaction with another party combines trust in the other party and trust in the control mechanisms that ensure the successful performance of the transaction. This generic trust model {{can be used in}} designing trust-related value-added services in e-commerce. To illustrate its design use, two e-commerce activities that require trust are compared: elec-tronic payment and cross-border electronic trade. The <b>model</b> <b>shows</b> that <b>each</b> of these activities requires a different type of trust, created by completely different services...|$|R
40|$|This paper {{describes}} a theory-driven evaluation model {{that is used}} in evaluating four pilots in which an infrastructure for lifelong competence development, which is currently being developed, is validated. The model makes visible the separate implementation steps that connect the envisaged infrastructure {{at the very beginning}} to the actual learning outcomes at the end. The <b>model</b> <b>shows</b> how <b>each</b> implementation step can lead to differences, that may influence the ultimate outcomes. We first show the characteristics of the model, and how they are derived from existing evaluation literature. Secondly, we <b>show</b> how the <b>model</b> is used in the several stages of evaluation, including its use to test the program theory...|$|R
40|$|The authors {{present a}} generic model of trust for {{electronic}} commerce {{consisting of two}} basic components, party trust and control trust, based on the concept that trust in a transaction with another party combines trust in the other parry and trust in the control mechanisms that ensure the successful performance of the transaction. This generic trust model con be used in designing trust-related value-added services in e-commerce. To illustrate its design use, two e-commerce activities that require trust are compared: electronic payment and cross-border electronic trade. The <b>model</b> <b>shows</b> that <b>each</b> of these activities requires {{a different type of}} trust, created by completely different services...|$|R
30|$|Nevertheless, we further {{calculated}} several robustness {{checks and}} alternately ran a FEM and a pooled OLS regression with standard errors clustered {{at the firm}} level. Additionally, we varied the model by taking the single CEOs as sources of unobserved heterogeneity. None of the robustness <b>models</b> <b>showed</b> drastic deviations. <b>Each</b> <b>model</b> used cluster-robust standard errors for the calculation of significance to avoid bias due to cluster building or serial correlation.|$|R
40|$|This paper {{presents}} the performance {{evaluation of a}} CMB (Chandy-Misra-Bryant) protocol {{from the perspective of}} execution time. The performance of each logical process in simulation is measured. Our evaluation shows that logical processes can have different behaviors and different protocols can be used simultaneously in simulations. While some logical processes may perform well using conservative protocols, others can use optimistic protocols because otherwise most of the time these processes would be blocked unnecessarily. In order to analyze the behavior of the simulations some models were simulated using a CMB implementation called ParSMPLX. These <b>models</b> <b>showed</b> that <b>each</b> logical process of a simulation has a different behavior that makes it more suitable for a specific protocol, increasing the performance. ...|$|R
40|$|Abstract — UN/CEFACT’s {{modeling}} methodology (UMM) is a UML {{profile for}} modeling global B 2 B choreographies. The current UMM version comprises three main views for describing a computation independent model from a neutral perspective. Currently, the UMM version is missing a platform independent <b>model</b> <b>showing</b> how <b>each</b> partner has {{to realize the}} message exchanges to support the agreed choreography. In this paper we derive such a platform independent model from a UMM business transaction- a key artifact of the computation independent model. The resulting model {{is based on a}} state machine describing the local view of a participating business partner. This state machine unambiguously defines how a business partner has to react on incoming messages and on message expected but not received. I...|$|R
40|$|In {{this paper}} {{we aim at}} nding {{similarities}} among the coefficients from a multivariate regression. Using a quantile regression coefficients modeling, the effect of <b>each</b> <b>covariate,</b> given a response (also multivariate) is a curve in the multidimensional space of the percentiles. Collecting all the curves, describing the effects of <b>each</b> <b>covariate</b> on <b>each</b> response variable, we could be able to assess if only one or more covariates have same effects on different responses...|$|R
40|$|Treatment by {{covariate}} interactions can {{be explored}} in reviews using interaction analyses (e. g., subgroup analysis). Such analyses can {{provide information on}} how the covariate modifies the treatment effect and is an important methodological approach for personalising medicine. Guidance exists regarding how to apply such analyses but {{little is known about}} whether authors follow the guidance. Using published recommendations, we developed criteria to assess how well interaction analyses were designed, applied, interpreted, and reported. The Cochrane Database of Systematic Reviews was searched (8 th August 2013). We applied the criteria to the most recently published review, with an accessible protocol, for each Cochrane Review Group. We excluded review updates, diagnostic test accuracy reviews, withdrawn reviews, and overviews of reviews. Data were summarised regarding reviews, <b>covariates,</b> and analyses. <b>Each</b> of the 52 included reviews planned or did interaction analyses; 51 reviews (98 %) planned analyses and 33 reviews (63 %) applied analyses. The type of analysis planned and the type subsequently applied (e. g., sensitivity or subgroup analysis) was discrepant in 24 reviews (46 %). No review reported how or why <b>each</b> <b>covariate</b> had been chosen; 22 reviews (42 %) did state <b>each</b> <b>covariate</b> a priori in the protocol but no review identified <b>each</b> post-hoc <b>covariate</b> as such. Eleven reviews (21 %) mentioned five covariates or less. One review reported planning to use a method to detect interactions (i. e., interaction test) for each covariate; another review reported applying the method for <b>each</b> <b>covariate.</b> Regarding interpretation, only one review reported whether an interaction was detected for <b>each</b> <b>covariate</b> and no review discussed the importance, or plausibility, of the results, or the possibility of confounding for <b>each</b> <b>covariate.</b> Interaction analyses in Cochrane Reviews can be substantially improved. The proposed criteria can be used to help guide the reporting and conduct of analyses...|$|R
40|$|We {{tested the}} {{internal}} reliability and predictive validity {{of a new}} 4 -item Short Social Dominance Orientation (SSDO) scale among adults in 20 countries, using 15 languages (N = 2, 130). Low scores indicate preferring group inclusion and equality to dominance. As expected, cross-nationally, the lower people were on SSDO, the more they endorsed more women in leadership positions, protecting minorities, and aid to the poor. Multilevel moderation <b>models</b> <b>showed</b> that <b>each</b> effect was stronger in nations where a relevant kind of group power differentiation was more salient. Distributions of SSDO were positively skewed, despite use of an extended response scale; results show rejecting group hierarchy is normative. The short scale is effective. Challenges regarding translations, use of short scales, and intersections between individual and collective levels in social dominance theory are discussed. © The Author(s) 2013...|$|R
40|$|Application of {{recombinant}} DNA {{technology and}} electrophysiology {{to the study}} of amiloride-sensitive Na+ channels has resulted in an enormous increase in the understanding of the structure–function relationships of these channels. Moreover, this knowledge has permitted the elucidation of the physiological roles of these ion channels in cellular processes as diverse as transepithelial salt and water movement, taste perception, volume regulation, nociception, neuronal function, mechanosensation, and even defaecation. Although members of this ever-growing superfamily of ion channels (the Deg/ENaC superfamily) share little amino acid identity, they are all organized similarly, namely, two short N- and C-termini, two short membrane-spanning segments, and a very large extracellular loop domain. In this brief Topical Review, we discuss the structural features of each domain of this Deg/ENaC superfamily and, using ENaC as a <b>model,</b> <b>show</b> how <b>each</b> domain relates to overall channel function...|$|R
40|$|ArticleWe {{tested the}} {{internal}} reliability and predictive validity {{of a new}} 4 -item Short Social Dominance Orientation (SSDO) scale among adults in 20 countries, using 15 languages (N = 2, 130). Low scores indicate preferring group inclusion and equality to dominance. As expected, cross-nationally, the lower people were on SSDO, the more they endorsed more women in leadership positions, protecting minorities, and aid to the poor. Multilevel moderation <b>models</b> <b>showed</b> that <b>each</b> effect was stronger in nations where a relevant kind of group power differentiation was more salient. Distributions of SSDO were positively skewed, despite use of an extended response scale; results show rejecting group hierarchy is normative. The short scale is effective. Challenges regarding translations, use of short scales, and intersections between individual and collective levels in social dominance theory are discussed. University of Connecticut Research FoundationNational Science Foundation Graduate Research Fellowshi...|$|R
40|$|We {{analyzed}} the vertical wind profile measured at six experimental tower sites in dense {{forest in the}} Amazon Basin and examined how well two simple models can reproduce these observations. In general, the vertical wind profile below the canopy is strongly affected by the forest structure. From the forest floor to 0. 65 h (where h = 35 [*]m is the average height of the forest canopy for sites considered), the wind profile is approximately constant with height with speeds less than 1 [*]ms− 1. Above 0. 65 to 2. 25 h, the wind speed increases with height. Testing these data with the Yi and Souza <b>models</b> <b>showed</b> that <b>each</b> was able to reproduce satisfactorily the vertical wind profile for different experimental sites in the Amazon. Using the Souza Model, {{it was possible to}} use fewer input variables necessary to simulate the profile...|$|R
40|$|Will serious future {{climate change}} be avoided through {{strengthened}} intergenerational altruism? This paper first shows that normatively attractive outcomes {{will be implemented}} in a model with only private assets if each generation has sufficient non-paternalistic altruism for its immediate descendants. This conclusion is radically changed in a setting where the private asset leads to negative atmospheric externalities, and where efficient development requires that only a public asset is accumulated. In fact, the <b>model</b> <b>shows</b> that, if <b>each</b> dynasty {{is trying to get}} ahead in a world threatened by climate change by increasing its intergenerational altruism, then long-term wellbeing will be seriously undermined...|$|R
40|$|This paper {{explores the}} {{interaction}} between long memory and aggregation. Results are derived which link the (possibly fractional) orders of integration of the aggregate series {{with those of the}} underlying series when the aggregation is either cross-sectional or temporal (in discrete or continuous time). These results provide empirically testable hypotheses that are examined using six U. K. macroeconomic series. A semiparametric method is found to be broadly consistent with the implications of the theory but fully parametric ARFIMA <b>models</b> <b>show</b> considerable variation. <b>Each</b> series appears to be integrated of an order of between one and one-and-a-half...|$|R
40|$|When {{financial}} markets are global, {{the impacts of}} national banking regulations extend beyond national borders. While lax regulatory enforcement improves the profitability of home banks, it also increases loan supply, which in turn reduces the global interest rate spreads. In a two-country <b>model</b> we <b>show</b> that <b>each</b> regulator 2 ̆ 7 s enforcement choice {{is affected by the}} relative size of the national financial market. An authority regulating a smaller market has a smaller impact on global interest rates and therefore a stronger incentive to relax regulatory enforcement...|$|R
40|$|The {{benefits}} of using notch, slot and multiple circular perforations in plate fin heat sinks (PFHSs), are investigated numerically, using a conjugate heat transfer <b>model.</b> Comparisons <b>show</b> that <b>each</b> type of perforation can provide significantly reduced pressure drops over PFHSs but that fins with slot perforations {{provide the most}} effective design in terms of heat transfer and pressure drop. The practical {{benefits of}} each type of perforated fin for micro-electronics cooling is also explored and their capabilities of achieving low processor temperatures for reduced mechanical power consumption are quantified...|$|R
30|$|We {{suppose the}} {{influence}} coefficient of <b>each</b> <b>covariate</b> could be 0, 1 or 2. When influence coefficient is lager, this factor has more effect on human reliability, and human errors {{are more likely}} to occur. γ is the weight value of <b>each</b> <b>covariate.</b> Since available data is limited, we cannot obtain the weight value through fitting process by far. In this paper, the weight value of covariate is obtained via analytic hierarchy process (AHP) [24]. Through expert assessment, the five covariates are compared in pairs with respect to their relative importance to human error probability. Then their value weight could be calculated.|$|R
40|$|In the {{framework}} of Generalized Additive Models (GAM) an automatic data-driven procedure is introduced for assigning an appropriate smoother to <b>each</b> <b>covariate</b> and for defining an ordering entrance for the covariates in the model. The resulting Smoothing Score algorithm aims to improve model indentifiability. It uses the bagging procedure in order to select the smoothers to be assigned to <b>each</b> <b>covariate</b> and a new scoring measure able to rank the candidate smoothers {{with respect to their}} bagged predictive accuracy. The adequacy of this scoring measure is evaluated on artificial data. A comparison between the smoothing score algorithm and the standard GAM is made using real data concerning a classification task...|$|R
500|$|In the {{perspective}} of quantum mechanics, helium is the second simplest atom to model, following the hydrogen atom. Helium is composed of two electrons in atomic orbitals surrounding a nucleus containing two protons and (usually) two neutrons. As in Newtonian mechanics, no system that consists {{of more than two}} particles can be solved with an exact analytical mathematical approach (see 3-body problem) and helium is no exception. Thus, numerical mathematical methods are required, even to solve the system of one nucleus and two electrons. Such computational chemistry methods have been used to create a quantum mechanical picture of helium electron binding which is accurate to within < 2% of the correct value, in a few computational steps. Such <b>models</b> <b>show</b> that <b>each</b> electron in helium partly screens the nucleus from the other, so that the effective nuclear charge Z which each electron sees, is about 1.69 units, not the 2 charges of a classic [...] "bare" [...] helium nucleus.|$|R
40|$|Background - Students’ {{engagement}} in dishonest behaviours is problematic and may influence future professional practice. Aims - To consider the antecedents predicting {{engagement in}} academic dishonesty. Methods - A total of 433 pharmacy and medical {{students participated in}} a survey measuring engagement in academic dishonesty, self deception, justification, and acceptability. Hierarchical linear regression and path analysis methods were conducted. Results – Engagement in academic dishonesty was predicted by later years of study, justification, responses to a case scenario and notions of acceptability (R 2 = 34 %). An appropriately fitted path <b>model</b> <b>showed</b> that <b>each</b> explanatory variable correlated with engagement in academic dishonesty separately rather than being mediated by notions of acceptability. Conclusion - It is likely that students are establishing different ethical frames of references when engaging in dishonest behaviours such as rational self-interest or Machiavellianism. The prevention of academic dishonesty and its intervention needs to consider individualised, group-based and institutional processes...|$|R
40|$|We {{are taking}} an {{information}} theoretic {{approach to the}} question of the best way to harmonise melodies. Is it best to add the bass first, as has been traditionally the case? We describe software which uses statistical machine learning techniques to learn how to harmonise from a corpus of existing music. The software is able to perform the harmonisation task in various different ways. A performance comparison using the information theoretic measure cross-entropy is able to show that, indeed, the bass first approach appears to be best. We then use this overall strategy to investigate the performance of specialist models for the prediction of different musical attributes (such as pitch and note length) compared with single models which predict all attributes. We find that the use of specialist models affords a definite performance advantage. Final comparisons with a simpler <b>model</b> <b>show</b> that <b>each</b> has its pros and cons. Some harmonisations are presented which have been generated by some of the better performing models...|$|R
40|$|This study {{presents}} the specification, estimation and historical simulation of a multisectoral bilateral trade model for 120 commodity categories and fourteen countries and two regions covering {{the rest of}} the world. The <b>model</b> <b>shows,</b> for <b>each</b> trade flow, the country of origin, the country of destination, and the commodity traded. The primary purpose of the study is to enable the making of long-range annual forecasts of bilateral trade flows within the Inforum international multisectoral modeling system. 1 Besides their own intrinsic interest, the detailed bilateral trade flows ensure rigorous accounting consistency in the trade forecasts and also permit examination of specific changes in international competitive relations. The analysis uses time-series regressions on annual OECD and UN data of international trade by commodity of origin and destination for the 1974 - 91 period. 2. Overview of the Model The bilateral trade model differentiates 120 categories of commodity trade (Table 1), and distinguishes fourteen countries and two regions covering {{the rest of the}} world. The countrie...|$|R
5000|$|In the {{perspective}} of quantum mechanics, helium is the second simplest atom to model, following the hydrogen atom. Helium is composed of two electrons in atomic orbitals surrounding a nucleus containing two protons and (usually) two neutrons. As in Newtonian mechanics, no system that consists {{of more than two}} particles can be solved with an exact analytical mathematical approach (see 3-body problem) and helium is no exception. Thus, numerical mathematical methods are required, even to solve the system of one nucleus and two electrons. Such computational chemistry methods have been used to create a quantum mechanical picture of helium electron binding which is accurate to within < 2% of the correct value, in a few computational steps. Such <b>models</b> <b>show</b> that <b>each</b> electron in helium partly screens the nucleus from the other, so that the effective nuclear charge Z which each electron sees, is about 1.69 units, not the 2 charges of a classic [...] "bare" [...] helium nucleus.|$|R
40|$|AbstractWe {{analyze the}} joint venture type airport-airline {{vertical}} relationship under double moral hazard, where both make efforts but neither can see the other's efforts. With continuous-time stochastic dynamic programming <b>model,</b> we <b>show,</b> by <b>each</b> party's de-centralized utility maximizations, they can agree on the optimal contract, which is linear function of the final state, slope being the product of their productivity difference and diffusion rate index, when optimal effort costs are negligible and risk averse parameters both asymptotically approach zero. If productivities are same, or diffusion rate is unity, the optimal linear sharing rule do {{not depend on the}} final state...|$|R
30|$|The figures used to {{calculate}} the percentages are the number of dimensions of the organization code that correspond to the respective dimension of the external reality. We repeated the simulations 80 times for each of the 80 periods involved, as in the original E-E model [7]. Then we recorded the results. The percentage shows the average result across the simulations. In the scenarios involving the garbage can model, each of these simulations contain 50 choice arenas within each period. For each of these, 80 repetitions are performed. In this table, the results across the two <b>models</b> are <b>shown</b> for <b>each</b> of three adaptation levels.|$|R
40|$|This paper {{examines}} two {{proposals to}} correct the risk-taking incentives embedded in the current deposit insurance system and to provide protection to the deposit insurance fund. the first would require banks to issue subordinated debt, and the second would require bank stockholders to post surety bonds. We use the cash-flow version of the Capital Asset Pricing <b>Model</b> to <b>show</b> how <b>each</b> proposal would affect the values and rates of return on uninsured deposits and equity. We then indicate the impact that each proposal {{would have on the}} values of the Federal Deposit insurance Corporation claim and on the bank, emphasizing the role of deposit insurance pricing. Deposit insurance; Bank capital...|$|R
40|$|Recent neuropsychological {{evidence}} {{suggest that}} {{a key role in}} linking perceptions and intentions is played by sense of presence. Despite this phenomenon having been studied primarily in the field of virtual reality (conceived as the illusion of being in the virtual space), recent research highlighted that it is a fundamental feature of everyday experience. Specifically, the function of presence as a cognitive process is to locate the Self in a physical space or situation, based on the perceived possibility to act in it; so, the variations in sense of presence allow one to continuously adapt his own action to the external environment. Indeed intentions, as the cognitive antecedents of action, are not static representations of the desired outcomes, but dynamic processes able to adjust their own representational content according to the opportunities/restrictions emerging in the environment. Focusing on the peculiar context of action mediated by interactive technologies, we here propose a theoretical <b>model</b> <b>showing</b> how <b>each</b> level of an intentional hierarchy (future-directed; present directed; and motor intentions) can "interlock" with environmental affordances in order to promote a continuous stream of action and activity...|$|R
40|$|Background Treatment by {{covariate}} interactions can {{be explored}} in reviews using interaction analyses (e. g., subgroup analysis). Such analyses can {{provide information on}} how the covariate modifies the treatment effect and is an important methodological approach for personalising medicine. Guidance exists regarding how to apply such analyses but {{little is known about}} whether authors follow the guidance. Methods Using published recommendations, we developed criteria to assess how well interaction analyses were designed, applied, interpreted, and reported. The Cochrane Database of Systematic Reviews was searched (8 th August 2013). We applied the criteria to the most recently published review, with an accessible protocol, for each Cochrane Review Group. We excluded review updates, diagnostic test accuracy reviews, withdrawn reviews, and overviews of reviews. Data were summarised regarding reviews, covariates, and analyses. Results Each of the 52 included reviews planned or did interaction analyses; 51 reviews (98 %) planned analyses and 33 reviews (63 %) applied analyses. The type of analysis planned and the type subsequently applied (e. g., sensitivity or subgroup analysis) was discrepant in 24 reviews (46 %). No review reported how or why <b>each</b> <b>covariate</b> had been chosen; 22 re-views (42 %) did state <b>each</b> <b>covariate</b> a priori in the protocol but no review identified <b>each</b> post-hoc <b>covariate</b> as such. Eleven reviews (21 %) mentioned five covariates or less. One review reported planning to use a method to detect interactions (i. e., interaction test) for each covariate; another review reported applying the method for <b>each</b> <b>covariate.</b> Regarding interpretation, only one review reported whether an interaction was detected for eac...|$|R
40|$|Given a {{treatment}} variable, a stratifying factor, and covariates, xbalance calculates standardized differences (biases) along <b>each</b> <b>covariate,</b> {{with and without}} the stratification. Also, tests for conditional independence of the treatment variable and the covariates within strata. Provides both stratified and unstratified analysis. This package requires installation of the -rsource- package (q. v.) standardized differences, biases, stratification...|$|R
40|$|Abstract. Knowledge {{diffusion}} is {{a complex}} process. Knowledge is intangible and therefore {{is not easy to}} capitalize within an organization, or share between a set of individuals. The aim {{of this paper is to}} study the impact of two different structures of communication on both processes of knowledge transfer and individual learning, in the context of a community of practice. We will specifically compare two types of communication structures (through face-toface interactions and through a forum) by using agent-based <b>models.</b> Results <b>show</b> that <b>each</b> structure has a different impact on individual learning and knowledge transfer. Though, communication through face-to-face interactions seems to make individuals learn slower than on a web forum. Conclusions are widely discussed...|$|R
40|$|In {{this paper}} we study a general version of re-gression where <b>each</b> <b>covariate</b> {{itself is a}} func-tional data such as {{distributions}} or functions. In real applications, however, typically {{we do not have}} direct access to such data; instead only some noisy estimates of the true co-variate functions/distributions are available to us. For example, when <b>each</b> <b>covariate</b> is a distribution, then we {{might not be able to}} directly observe these distributions, but it can be assumed that i. i. d. sample sets from these distributions are available. In this pa-per we present a general framework and a k-NN based estimator for this regression prob-lem. We prove consistency of the estimator and derive its convergence rates. We further show that the proposed estimator can adapt to the local intrinsic dimension in our case and provide a simple approach for choosing k. Finally, we illustrate the applicability of our framework with numerical experiments. ...|$|R
