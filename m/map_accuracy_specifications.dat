0|1347|Public
40|$|It is very {{different}} from spaceborne InSAR and airborne InSAR because satellite orbit is relatively more higher, the distance between satellite subsatellite point and mapping area may be from hundreds to thousands of kilometers. Height measure based on spaceborne InSAR must eliminate the influence of earth’s curvature, otherwise its error may be higher. But how much is the influence of height measure from earth’s curvature to <b>mapping</b> <b>accuracy</b> in spaceborne InSAR? we have not read relative reports. In this paper, that is analyzed in detail, and the conclusions are drawn: Height measure based on spaceborne InSAR must eliminate the influence of earth’s curvature and its precision is much higher in that way. The error from earth spheroid is well-regulated, and may be corrected. According to the height <b>accuracy</b> <b>specifications,</b> in a definite range, the earth’s surface can be taken as flat in some area. 1...|$|R
40|$|There is {{a growing}} demand for high-accuracy {{elevation}} data collected by airborne or terrestrial mobile lidar systems in utility corridor surveys. Large-scale projects demand more stringent accuracy of lidar data under strongly variable survey conditions challenging lidar signal detection capability with extremely wide signal dynamic range. While <b>accuracy</b> <b>specifications</b> are provided by the lidar system manufacturers, translating these specifications to real-world achievable accuracy and evaluating it against existing <b>mapping</b> <b>accuracy</b> standards is a challenge left to the end user. In this paper we present a new cost-effective approach for evaluating lidar data accuracy for linear target detection. The practical application {{of this approach is}} demonstrated by assessing accuracy of the lidar data collected in airborne power line surveys. The demonstrated approach could be modified and applied for accuracy analysis of the geo-referenced lidar data collected by either airborne or mobile terrestrial lidar system for various corridor mapping applications. 1...|$|R
50|$|The bearing <b>accuracy</b> <b>specification</b> for all VOR beacons {{is defined}} in the International Civil Aviation Organisation Convention on International Civil Aviation Annex 10, Volume 1.|$|R
40|$|Graduation date: 1985 In {{this paper}} "map complexity" {{refers to the}} {{inherent}} intricacy of a mapped geographic pattern. Map complexity and sample size are two variables shown to influence the accuracy of interpolated dasymetric maps. An automated experiment was designed to investigate the precise relationship among map complexity, sample size, and the <b>accuracy</b> of dasymetric <b>maps</b> interpolated using Thiessen polygons. The results of the experiment were evaluated through regression analysis. A positive curvilinear relationship between sample size and <b>map</b> <b>accuracy,</b> and an inverse linear relationship between map complexity and <b>map</b> <b>accuracy</b> were observed. <b>Map</b> complexity was the more important variable influencing <b>map</b> <b>accuracy</b> and interaction between the two independent variables was indicated. A logistic shaped curve is presented summarizing the theoretical relationship between sample size, map complexity, and dasymetric <b>map</b> <b>accuracy...</b>|$|R
40|$|There {{are large}} {{individual}} differences {{in the ability to}} create an accurate mental representation (i. e., a cognitive map) of a novel environment, yet the factors underlying cognitive <b>map</b> <b>accuracy</b> remain unclear. Given the roles that landmarks and cognitive <b>map</b> <b>accuracy</b> play in successful navigation, the current study examined whether differences in the landmarks that individuals look at while navigating are related to differences in cognitive <b>map</b> <b>accuracy.</b> Participants completed a battery of spatial tests: some that assessed spatial skills prior to a navigation task, and others that tested memory for the environment following exploration of a virtual world. Results indicated that individuals with inaccurate maps had weak perspective-taking abilities, struggled to create shortcuts, and remembered fewer landmarks despite having looked at target buildings and objects in the environment for the same duration as individuals with accurate cognitive maps. These findings suggest that memory capabilities underlie differences in cognitive <b>map</b> <b>accuracy...</b>|$|R
40|$|Land cover maps {{of forests}} within an {{urban and rural}} {{environment}} derived from high spatial resolution multispectral data (QuickBird) and medium spatial resolution multispectral data (Landsat ETM+ and SPOJ 4) were compared to ascertain whether increased spatial resolution increases <b>map</b> <b>accuracy</b> of forests and whether <b>map</b> <b>accuracy</b> varies across land cover classification schemes. It is commonly assumed that increased spatial resolution would probably increase land cover <b>map</b> <b>accuracy</b> regardless of land cover classification methodology. This study assessed whether that assumption is correct within a rural and an urban environment. <b>Map</b> <b>accuracy</b> for modified National Land Cover Data (NLCD) 2001 Level II, Level I, and Unique (a modified NLCD 2001 Level II and Level I combination) shows that 30 -m Landsat ETM-H data had the highest overall <b>map</b> <b>accuracy</b> for rural, urban, and combined rural/urban land cover maps. Analysis of user 2 ̆ 7 s and producer 2 ̆ 7 s accuracies shows that Landsat FTM-f data had higher levels of producer 2 ̆ 7 s accuracy of 3 ̆e 90. 0 °/o for the coniferous cover type for modified NLCD 2001 Level II and Unique, excluding one instance for which SPOT 4 had a user 2 ̆ 7 s accuracy of 98. 5...|$|R
3000|$|... accuracy: the {{difference}} between an intended final dimension and the actual dimension as determined by a physical measurement of the part in addition to those for linear dimensions, there are <b>accuracy</b> <b>specifications</b> for such features as hole sizes and flatness [...]...|$|R
40|$|Land-cover is an {{important}} parameter in analyzing the state and dynamics of natural and anthropogenic terrestrial ecosystems. Land-cover classes related to semi-arid savannas currently exhibit among the greatest uncertainties in available global land cover datasets. This study focuses on the Kalahari in northeastern Namibia and compares the effects of different composite lengths and observation periods with class-wise <b>mapping</b> <b>accuracies</b> derived from multi-temporal MODIS time series classifications to better understand and overcome quality gaps in mapping semi-arid land-cover types. We further assess the effects of precipitation patterns on <b>mapping</b> <b>accuracy</b> using Tropical Rainfall Measuring Mission (TRMM) observation data. Botanical field samples, translated into the UN Land Cover Classification System (LCCS), were used for training and validation. Different sets of composites (16 -day to three-monthly) were generated from MODIS (MOD 13 Q 1) data covering the sample period from 2004 to 2007. Land-cover classifications were performed cumulatively based on annual and inter-annual feature sets {{with the use of}} random forests. Woody vegetation proved to be more stable in terms of omission and commission errors compared to herbaceous vegetation types. Generally, <b>mapping</b> <b>accuracy</b> increases with increasing length of the observation period. Analyses of variance (ANOVA) verified that inter-annual classifications significantly improved class-wise <b>mapping</b> <b>accuracies,</b> and confirmed that monthly composites achieved the best accuracy scores for both annual and inter-annual classifications. Correlation analyses using piecewise linear models affirmed positive correlations between cumulative <b>mapping</b> <b>accuracy</b> and rainfall and indicated an influence of seasonality and environmental cues on the <b>mapping</b> <b>accuracies.</b> The consideration of the inter-seasonal variability of vegetation activity and phenology cycling in the classification process further increases the overall classification performance of savanna classes in large-area land-cover datasets. Implications for global monitoring frameworks are discussed based on a conceptual model of the relationship between observation period and accurac...|$|R
40|$|Abstract. In {{the paper}} two methods for data {{structure}} analysis and visualisation are presented: the simultaneous nonlinear mapping (Sammon, 1969) and the sequential one (Montvilas, 1995). These two methods were compared according ability {{to map the}} data on the plane, <b>mapping</b> <b>accuracy</b> and a <b>mapping</b> time. It was showed that the sequential nonlinear mapping has some bigger total mapping error but needs considerable less calculation time {{than that of the}} simultaneous one. Examples are given. Key words:simultaneous nonlinear mapping, sequential nonlinear <b>mapping,</b> <b>accuracy,</b> comparison. 1...|$|R
30|$|The {{evaluation}} of classification accuracies followed that outlined in several standard texts {{on the subject}} (e.g., [72 – 75]). Statistical estimation of classification accuracy {{has been a long}} studied and established subject that has a vast literature. However, most theoretical considerations for sample sizes and other factors for the assessment of <b>map</b> <b>accuracy</b> were developed and verified on low-to-moderate dimensionality data (e.g., Landsat TM, MSS, SPOT HRV) and allowing relatively large errors. With hyperspectral data, the <b>map</b> <b>accuracy</b> is expected to increase; therefore, the sample size required for rigorous assessment of the accuracy within a meaningful error limit and confidence level may become prohibitively large. The works cited above, and others in the literature, offer recommendations for accuracy assessments. According to the formula derived from binomial distribution [72], the number of test samples needed for <b>map</b> <b>accuracy</b> assessment is ntest[*]=[*]x 2 [*]×[*]p[*]×[*](1 [*]−[*]p)[*]/[*]E 2, where E is the allowed maximum error in the accuracy assessment, x defines the confidence level (confidence level corresponding to x ‘sigma’), and p is the desired <b>map</b> <b>accuracy.</b> As an example, for assessment of the classification at the 95 % confidence level within 4 % error, this requires at least 2, 700 test samples for the 23 classes in this study.|$|R
40|$|Statistical {{procedure}} to evaluate <b>map</b> <b>accuracy</b> {{is required to}} answer the user's doubt regarding reliability of maps. Statistical procedure involve sampling, design and determining <b>accuracy</b> of <b>map</b> and categories. Calculation of statistics on a aerial extent of land-use categories and reliable sample size are shown. Sample selection is done by stratified systematic unaligned sampling technique. The lower limit of one-tailed confidence interval is determine the entire <b>map</b> <b>accuracy.</b> The confidence interval is used to define {{the upper and lower}} limits of accuracy of the categories. The importance [...] ...|$|R
40|$|Assessing the {{accuracy}} of land cover maps is often prohibitively expensive {{because of the difficulty}} of collecting a statistically valid probability sample from the clas-sified map. Even when post-classification sampling is undertaken, cost and acces-sibility constraints may result in imprecise estimates of <b>map</b> <b>accuracy.</b> If the <b>map</b> is constructed via supervised classification, then the training sample provides a po-tential alternative source of data for accuracy assessment. Yet unless the training sample is collected by probability sampling, the estimates are, at best, of uncertain quality, and may be substantially biased. In this article, a new approach to <b>map</b> <b>accuracy</b> assessment based on maximum posterior probability estimators is dis-cussed. These estimators may be used to reduce bias and increase precision when the training sample is collected without benefit of probability sampling, and also to increase precision of estimates obtained from post-classification sampling. A calibrated maximum posterior probability estimate of <b>map</b> <b>accuracy</b> is computed by first estimating the probability that each map unit has been correctly classi...|$|R
40|$|The {{objective}} {{of this study is}} to evaluate the <b>mapping</b> <b>accuracy</b> of the MSG-SEVIRI operational snow cover product over Austria. The SEVIRI instrument is aboard the geostationary Meteosat Second Generation (MSG) satellite. The snow cover product provides 32 images per day, with a relatively low spatial resolution of 5 km over Austria. The <b>mapping</b> <b>accuracy</b> is examined at 178 stations with daily snow depth observations and compared with the daily MODIS-combined (Terra + Aqua) snow cover product for the period April 2008 –June 2012. The results show that the 15 min temporal sampling allows a significant reduction of clouds in the snow cover product. The mean annual cloud coverage is less than 30 % in Austria, as compared to 52 % for the combined MODIS product. The <b>mapping</b> <b>accuracy</b> for cloud-free days is 89 % as compared to 94 % for MODIS. The largest mapping errors are found in regions with large topographical variability. The errors are noticeably larger at stations with elevations that differ greatly from those of the mean MSG-SEVIRI pixel elevations. The median of <b>mapping</b> <b>accuracy</b> for stations with absolute elevation difference less than 50 m and more than 500 m is 98. 9 and 78. 2 %, respectively. A comparison between the MSG-SEVIRI and MODIS products indicates an 83 % overall agreement. The largest disagreements are found in Alpine valleys and flatland areas in the spring and winter months, respectively...|$|R
40|$|In {{this paper}} {{a method for}} the {{evaluation}} of static robustness towards random variations in cellular neural network (CNN) templates is proposed. From this evaluation, circuit <b>accuracy</b> <b>specifications</b> for a VLSI implementation are derived which allow the designer to optimize the performance. Moreover, from this evaluation method, guidelines for robust template designs are derived and parametric testing templates are developed. status: publishe...|$|R
40|$|The {{purpose of}} this {{research}} is to develop design and accuracy criteria for large-scale topographic surveys. The large-scale topographic survey is a ‘sparse surface model’ consisting of sampling prescription, surface modeling algorithm, and partitioned terrain complexity. Predictable survey outcomes can be achieved by partitioning the site into unitary land forms such that the amplitude of resident terrain microform is less than one-half the <b>accuracy</b> <b>specification.</b> A paraboloid of revolution can be used to model unitary land form. The limiting radius of surface curvature and the <b>accuracy</b> <b>specification</b> can be used to compute a sampling interval. Where the resident microform, without regard to its distribution, is less than one-half the <b>accuracy</b> <b>specification,</b> sampling prescriptions based on curvature provide predictable sampling outcomes. The sampling in such cases is accomplished on the trend surface without regard to the distribution of the microform amplitude. Where the amplitude of resident microform is greater than one-half of the desired <b>accuracy</b> <b>specification,</b> composite sampling is the result. Predictable sampling outcomes cannot be achieved in such cases, however the better results are achieved within the one-quarter mean wavelength where the microform can be shown to be periodic. Such sampling takes place {{on the surface of the}} microform without regard to curvature on the underlying trend surface. ^ The Draft National Standard for Spatial Data Accuracy (NSSDA) vertical accuracy statistic has a high probability of failure on unitary land forms because of the lack of a measure of central tendency. The error distribution on a unitary land form needs a measure of central tendency to locate the center of mass of the error residuals. ^ Unsymmetrical error distributions that occur with sparse data sets produce inflated confidence intervals because variance is a second-degree function. This fact can be mitigated by the use of the median and average deviation to locate and describe the mass of the error residuals. These smaller intervals will encompass from 87 to 91 % of error residuals. The residuals in the tails can be reported with a count and magnitude range. This provides much more information about the large-scale topographic survey to the engineer than a single statistic. ...|$|R
40|$|Abstract: Habitat mapping can be {{accomplished}} using many techniques and types of data. There are pros and cons for each technique and dataset, therefore, {{the goal of this}} project was to investigate the capabilities of new satellite sensor technology and to assess <b>map</b> <b>accuracy</b> for a variety of image classification techniques based on hundreds of field-work sites. The study area was Masonboro Island, an undeveloped area in coastal North Carolina, USA. Using the best map results, a habitat change assessment was conducted between 2002 and 2010. WorldView- 2, QuickBird, and IKONOS satellite sensors were tested using unsupervised and supervised methods using a variety of spectral band combinations. Light Detection and Ranging (LiDAR) elevation and texture data pan-sharpening, and spatial filtering were also tested. In total, 200 maps were generated and results indicated that WorldView- 2 was consistently more accurate than QuickBird and IKONOS. Supervised maps were more accurate than unsupervised in 80 % of the maps. Pan-sharpening the images did not consistently improve <b>map</b> <b>accuracy</b> but using a majority filter generally increased <b>map</b> <b>accuracy.</b> During the relatively short eight-year period, 20 % of the coastal study area changed with intertidal marsh experiencing the most change. Smaller habitat classe...|$|R
40|$|This paper {{compares the}} {{predictive}} performance of different geostatistical kriging algorithms for intertidal surface sediment facies mapping using grain size data. Indicator kriging, which maps facies types from conditional probabilities of predefined facies types, is first considered. In the second approach, grain size fractions are first predicted using cokriging and the facies types are then mapped. As grain size fractions are compositional data, their characteristics {{should be considered}} during spatial prediction. For efficient prediction of compositional data, additive log-ratio transformation is applied before cokriging analysis. The predictive performance of cokriging of the transformed variables is {{compared with that of}} cokriging of raw fractions in terms of both prediction errors of fractions and facies <b>mapping</b> <b>accuracy.</b> From a case study of the Baramarae tidal flat, Korea, the mapping method based on cokriging of log-ratio transformation of fractions outperformed the one based on cokriging of untransformed fractions in the prediction of fractions and produced the best facies <b>mapping</b> <b>accuracy.</b> Indicator kriging that could not account for the variation of fractions within each facies type showed the worst <b>mapping</b> <b>accuracy.</b> These case study results indicate that the proper processing of grain size fractions as compositional data is important for reliable facies mapping...|$|R
40|$|International audienceIn the {{framework}} of hydrodynamic modelling, topography is classically obtained by an inter-polation of punctual field elevation surveys. A methodology, based on block conditional simu-lations, is presented to enhance <b>mapping</b> <b>accuracy,</b> using contour lines extracted from floodedareas in remote sensing data...|$|R
40|$|Many cartographers {{have been}} {{concerned}} with the difficult problem of concili ating <b>map</b> <b>accuracy</b> and legibility in portraying spatial distributions. Geographic distributions are seldom simple enough to be readily perceived and understood. For the sake of cartographic communication, {{a certain amount of}} generalization is usuall...|$|R
40|$|Although {{numerous}} algorithms {{exist for}} genome alignment using Next Generation Sequencing tags, assembly of colour coded reads remains a challenge. We present a novel pairwise sequence aligner algorithm derived from Smith-Waterman method. Original {{feature of the}} algorithm is that it translates the reference sequence into colour code and performs the alignment in colour space. While operating on this base it can prevent most read error-derived assembly errors. Based on dynamic programming it gives the optimal alignment in colour space. Further, validation on empirical dataset with capillary sequencing proved high <b>mapping</b> <b>accuracy.</b> We can also conclude that the novel algorithm provides performance comparable with the currently available solutions. The algorithm can be implemented into any reference assembly software thereby improving <b>mapping</b> <b>accuracy</b> while maintaining high speed mapping...|$|R
40|$|Introduction, The U. S. Naval Observatory (USNO), f rom {{the very}} f i rs t day o f i t s {{establishment}} i n 1830 as a chronometer rat ing office, to the present, has been {{deeply involved in}} the specialized field o f Precise Time and Time Interval (PTTI). During this period o f one and one ha l f centuries, the <b>accuracy</b> <b>specification</b> tha t defines Precise Time and Tim...|$|R
40|$|Abstract. In an {{ordinary}} process of measurement it’s {{possible that the}} environmental changes of temperature induce errors of measurement which exceeds the <b>accuracy</b> <b>specifications</b> of load cells. The paper describes {{the effects of the}} environmental temperature on one type of high accuracy load cells, it indicates the degree of correlation between the variations of temperature and the mass readings of the cells, and furthermore it figures out the mathematical model of its behavior...|$|R
50|$|In 1977 NGL began {{development}} {{of its first}} in-house designed aircraft data recorder, a sealed maintenance recorder for the McDonnell Douglas (now Boeing) F/A-18 Hornet A/B. A data recorder that had to meet unprecedented environmental and <b>accuracy</b> <b>specifications</b> and was Normalair’s first order for US defence equipment. The F/A-18 unit placed Normalair {{at the forefront of}} aircraft recorder technology and a dedicated electronics division was set up at Clarence Street, near to the former Huish football ground.|$|R
25|$|Geologic Quadrangle (GQ) Map: Detailed {{geologic}} maps depicting {{areas of}} special {{importance to the}} solution of geologic problems. May portray bedrock or surficial units, or both. May include brief texts, structure sections, and columnar sections. 71/2- or 15-minute quadrangles printed in multicolor on topographic bases that meet National <b>Map</b> <b>Accuracy</b> standards.|$|R
40|$|Abstract—Spatial error {{analysis}} and estimation {{is an important}} task pertaining to geospatial imaging and mapping that can enable the user to establish the accuracy of information obtained from georeferenced images. Spatial {{error analysis}} techniques allow the user to quantify and understand spatial uncertainty and discrepancies in data. The objective of this work {{is to develop a}} set of software tools that may be used to analyze and estimate the spatial inaccuracies and quantify findings using industry standard terms for georeferenced image data <b>accuracy</b> <b>specifications.</b> <b>Accuracy</b> Analyst is a software tool {{that can be used to}} analyze the horizontal accuracies pertaining to the spatial coordinates surveyed for certain well-defined ground control locations and the locations of those photo-identifiable points extracted from georeferenced orthorectified image dat...|$|R
40|$|A linkage disequilibrium-based {{method for}} fine mapping {{quantitative}} trait loci (QTL) {{has been described}} that uses similarity between individuals' marker haplotypes to determine if QTL alleles are identical by descent (IBD) to model covariances among individuals' QTL alleles for a mixed linear model. <b>Mapping</b> <b>accuracy</b> with this method {{was found to be}} sensitive to the number of linked markers that was included in the haplotype when fitting the model at a putative position of the QTL. The objective of this study was to determine the optimal haplotype structure for this IBD-based method for fine mapping a QTL in a previously identified QTL region. Haplotypes consisting of 1, 2, 4, 6, or all 10 available markers were fit as a “sliding window” across the QTL region under ideal and nonideal simulated population conditions. It was found that using haplotypes of 4 or 6 markers as a sliding “window” resulted in the greatest <b>mapping</b> <b>accuracy</b> under nearly all conditions, although the true IBD state at a putative QTL position was most accurately predicted by IBD probabilities obtained using all markers. Using 4 or 6 markers resulted in greater discrimination of IBD probabilities between positions while maintaining sufficient accuracy of IBD probabilities to detect the QTL. Fitting IBD probabilities on the basis of a single marker resulted in the worst <b>mapping</b> <b>accuracy</b> under all conditions because it resulted in poor accuracy of IBD probabilities. In conclusion, for fine mapping using IBD methods, marker information must be used in a manner that results in sensitivity of IBD probabilities to the putative position of the QTL while maintaining sufficient accuracy of IBD probabilities to detect the QTL. Contrary to expectation, use of haplotypes of 4 – 6 markers to derive IBD probabilities, rather than all available markers, best fits these criteria. Thus for populations similar to those simulated here, optimal <b>mapping</b> <b>accuracy</b> for this IBD-based fine-mapping method is obtained with a haplotype structure including a subset of all available markers...|$|R
30|$|Accuracy {{design is}} an {{important}} tool for predicting and control the error when design a machine, which has wide application in designing the machine tool, robot and coordinate measuring machine [4]. Generally, accuracy design of a machine tool can predict the whole accuracy by synthesizing the influence of each error sources so as to judge if the design meets the required <b>accuracy</b> <b>specifications.</b> Therefore, reasonable <b>accuracy</b> design is beneficial for minimizing the risk and cost, and the optimal decision and selection in the machine tool design.|$|R
40|$|Elevation data {{produced}} by NASA’s Shuttle Radar Topography Mission (SRTM) {{is currently the}} most detailed publicly available, free-of-cost, near-global digital elevation model (DEM). While generally very successful in collecting complete and accurate elevation data, the mission C-band Radar had limitations over specific landscapes, including sand deserts. This paper {{presents the results of}} a validation study using data from ground surveys in the Libyan Sahara. It tests (a) the accuracy of finished Level 2 SRTM DEM data; and (b) the performance of an interpolation procedure that is routinely applied to fill SRTM data voids on a global scale. The results show that SRTM data consistently meets its own <b>accuracy</b> <b>specifications,</b> with a root mean square error (RMSE) of 1. 3 to 5. 2 m. Interpolated void-filled data achieved lower accuracy, with RMSE of approximately 7 m for an area of smaller dunes, and RMSE of 14 m within an extensive field of strongly undulating dunes with heights of more than 100 m, meaning that the <b>accuracy</b> <b>specification</b> of SRTM data in this area is not met. It is concluded that void-filling by interpolation in areas of extensive dune fields does not reproduce the representative topography of such a landscape, and spatially higher resolved elevation data is needed to achieve this via interpolation...|$|R
25|$|<b>Map</b> <b>accuracy</b> {{refers to}} the work of the {{surveyor}} (field-worker) and relates not so much to the positional accuracy of the survey but rather to its utility for the competitor. Map quality {{refers to the}} quality of the artwork. Many national bodies have a competition in which awards are made to cartographers after assessment by a national panel.|$|R
40|$|Analyses of {{simulated}} {{and operational}} ERTS images have provided initial estimates of resolution, ground resolution, detectability thresholds {{and other measures}} of image quality of interest to earth scientists and cartographers. Based on these values, including an approximate ground resolution of 250 meters for both RBV and MSS systems, the ERTS- 1 images appear suited to the production and/or revision of planimetric and photo maps of 1 : 500, 000 scale and smaller for which <b>map</b> <b>accuracy</b> standards are compatible with the imaged detail. Thematic mapping, although less constrained by <b>map</b> <b>accuracy</b> standards, will be influenced by measurement thresholds and errors which {{have yet to be}} accurately determined for ERTS images. This study also indicates the desirability of establishing a quantitative relationship between image quality values and map products which will permit both engineers and cartographers/earth scientists to contribute to the design requirements of future satellite imaging systems...|$|R
40|$|Abstract 1 Example-based super-resolution recovers missing high {{frequencies}} in a magnified image by learning the correspondence between co-occurrence examples at two different resolution levels. As high-resolution examples usually contain more details and are of higher dimensionality {{in comparison with}} low-resolution ones, the mapping from low-resolution to high-resolution is an ill-posed problem. Rather than imposing more complicated mapping constraints, we propose to improve the <b>mapping</b> <b>accuracy</b> by enhancing low-resolution examples in terms of mapped features, e. g., derivatives and primitives. A feature enhancement method is presented {{through a combination of}} interpolation with prefiltering and non-blind sparse prior deblurring. By enhancing low-resolution examples, unique feature information carried by high-resolution examples is decreased. This regularization reduces the intrinsic dimensionality disparity between two different resolution examples and thus improves the feature <b>mapping</b> <b>accuracy.</b> Experiments demonstrate our super-resolution scheme with feature enhancement produces high quality results both perceptually and quantitatively. 1...|$|R
40|$|In {{this study}} we present a Micro Aerial Vehicle (MAV) {{equipped}} with precise position and attitude sensors that together with a pre-calibrated camera enables accurate corridor mapping. The design of the platform is based on widely available model components to which we integrate an open-source autopilot, customized mass-market camera and navigation sensors. We adapt the concepts of system calibration from larger mapping platforms to MAV and evaluate them practically for their achievable accuracy. We present case studies for accurate mapping without ground control points: first for a block configuration, later for a narrow corridor. We evaluate the <b>mapping</b> <b>accuracy</b> with respect to checkpoints and digital terrain model. We show that while {{it is possible to}} achieve pixel (3 - 5 cm) <b>mapping</b> <b>accuracy</b> in both cases, precise aerial position control is sufficient for block configuration, the precise position and attitude control is required for corridor mapping...|$|R
40|$|Numerous {{global and}} {{regional}} validation studies examined MODIS snow <b>mapping</b> <b>accuracy</b> {{by using measurements}} at climate stations, which are mainly at grassy sites. MODIS accuracy in alpine and forested regions is, however, still not well understood. The main objective {{of this study is}} to evaluate MODIS (MOD 10 A 1 and MYD 10 A 1) snow cover products in a small experimental catchment by using extensive snow course measurements at open and forest sites. The MODIS accuracy is tested in the Jalovecky creek catchment (Northern Slovakia) in the period 2000 – 2011. The results show that the combined Terra and Aqua images enables snow mapping to an overall accuracy of 91. 5 %. The accuracy at forested, open and mixed land uses at the Červenec sites is 92. 7 %, 98. 3 % and 81. 8 %, respectively. The use of a 2 -day temporal filter enables a significant reduction in the number of days with cloud coverage and an increase in overall snow <b>mapping</b> <b>accuracy.</b> In total, the 2 -day temporal filter decreases the number of cloudy days from 61 % to 26 % and increases the snow <b>mapping</b> <b>accuracy</b> to 94 %. The results indicate three possible factors leading to misclassification of snow as land: patchy snow cover, limited MODIS geolocation <b>accuracy</b> and <b>mapping</b> algorithm errors. Out of a total of 27 misclassification cases, patchy snow cover, geolocation issues and mapping errors occur in 12, 12 and 3 cases, respectively...|$|R
40|$|Habitat mapping can be {{accomplished}} using many techniques and types of data. There are pros and cons for each technique and dataset, therefore, {{the goal of this}} project was to investigate the capabilities of new satellite sensor technology and to assess <b>map</b> <b>accuracy</b> for a variety of image classification techniques based on hundreds of field-work sites. The study area was Masonboro Island, an undeveloped area in coastal North Carolina, USA. Using the best map results, a habitat change assessment was conducted between 2002 and 2010. WorldView- 2, QuickBird, and IKONOS satellite sensors were tested using unsupervised and supervised methods using a variety of spectral band combinations. Light Detection and Ranging (LiDAR) elevation and texture data pan-sharpening, and spatial filtering were also tested. In total, 200 maps were generated and results indicated that WorldView- 2 was consistently more accurate than QuickBird and IKONOS. Supervised maps were more accurate than unsupervised in 80 % of the maps. Pan-sharpening the images did not consistently improve <b>map</b> <b>accuracy</b> but using a majority filter generally increased <b>map</b> <b>accuracy.</b> During the relatively short eight-year period, 20 % of the coastal study area changed with intertidal marsh experiencing the most change. Smaller habitat classes changed substantially as well. For example, 84 % of upland scrub-shrub experienced change. These results document the dynamic nature of coastal habitats, validate the use of the relatively new Worldview- 2 sensor, and may be used to guide future coastal habitat mapping...|$|R
40|$|Forests are {{the major}} source of {{biodiversity}} and provide natural sources of wood, fodder, gums, resins, and medicines. Forests encounter damage by nature and human factors, which needs to be monitored for all tree species, whether invasion or intentional damage. This study focuses on the classification of an open tall stand coastal surrounding site for the mapping and classification of tree species and ground features using airborne imagery. So, improving the classification and <b>mapping</b> <b>accuracy</b> of forest in surrounding coastal regions is essential for the restoration and management decisions. The first objective of this thesis is to use segmented Principal Component (PC) images to classify the ground features including different tree species and to improve the classification results. More specific goals include (a) Use of hyperspectral images to map and classify the forest region using a segmented PC image, (b) Investigating the gain in <b>mapping</b> <b>accuracy</b> with segmented PC image as opposed to hyperspectral imagery alone. The second objective is to assess and investigate the fusion of airborne hyperspectral imagery and LiDAR derived Canopy Height Model for classification and assessing the results. These objectives aim at investigating the gain in <b>mapping</b> <b>accuracy</b> with fusion image as opposed to hyperspectral imagery alone. Thus, overall this study assesses the differences in classification outputs using a data fusion technique, segmented PC image and individual hyperspectral images, which differ in accuracy, in Mediterranean forest. MLC based supervised image classification method provided better accuracy (96. 3...|$|R
40|$|This paper {{presents}} an integrative hierarchical stepwise sampling (IHS) method and two case studies {{to compare it}} with stratified random sampling (SRS) and conditioned Latin hypercube sampling (cLHS). The first comparison between IHS and SRS was conducted for mapping sand content of two soil layers in a study area in Anhui Province, China. Two sample sets of the same sample size were collected in the field based on IHS and SRS. The second case study is a simulation study, where we compared IHS and cLHS for mapping soil series in the Raffelson watershed in Wisconsin (USA). The study used an accurate and detailed soil series map produced previously as a proxy of the real soil distribution. Virtual samples with nine sample sizes designed by IHS and cLHS were collected on the soil map. For both case studies, an individual predictive soil mapping method was employed and independent validation samples were {{used to evaluate the}} <b>mapping</b> <b>accuracies.</b> Results indicate that IHS generally performs better than SRS for capturing distributions of the environmental variables. It obtained higher <b>mapping</b> <b>accuracies</b> than SRS at different sample sizes. On the other hand, cLHS appears to provide a better representation for distributions of the environmental variables than IHS, but the <b>mapping</b> <b>accuracies</b> with IHS are higher than those with cLHS at nearly all sample sizes. Finally, both case studies showed that IHS provides valuable information on representativeness of the samples...|$|R
