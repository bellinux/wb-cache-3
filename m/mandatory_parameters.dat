12|30|Public
5000|$|Parameter type = 2 : This {{parameter}} {{indicates that}} the sender received an INIT or INIT ACK chunk with missing <b>mandatory</b> <b>parameters.</b>|$|E
50|$|The {{appropriate}} Russian law N 102 ФЕДЕРАЛЬНЫЙ ЗАКОН ОБ ИПОТЕКЕ called Federal Mortgage Law {{was passed}} on 16.07.1998. This law regulates mortgage lending issues including definition and <b>mandatory</b> <b>parameters</b> of Russian Mortgage Certificate.|$|E
50|$|Note {{that the}} first 3 <b>mandatory</b> <b>parameters</b> (v=, s= and o=), even though they seem to contain {{displayable}} text, are {{not intended to be}} displayed to users and translated. The fields present in their values are considered in the protocol as opaque strings, they are used as identifiers, just like paths in an URL or filenames in a file system: the SDP standard indicates that they must be all non empty and should be UTF-8 encoded.|$|E
5000|$|Parameter type = 7 : This <b>parameter</b> {{identifies}} a <b>mandatory</b> <b>parameter</b> in an INIT or INIT ACK chunk has {{an invalid}} value.|$|R
5000|$|SMPP 5.0 just {{specifies}} that message_id is a <b>mandatory</b> <b>parameter</b> of {{the type}} C-Octet string of the submit_sm_resp message. According to the section 3.1.1 NULL Settings, ″A NULL string ″″ is encoded as 0x00″. The length of the PDU is at least 17 octets.|$|R
5000|$|... the <b>mandatory</b> {{technical}} <b>parameters</b> to {{be observed}} by radio stations, especially transmitters; ...|$|R
5000|$|Modern day FDRs receive inputs via {{specific}} data frames from the Flight Data Acquisition Units (FDAU). They record significant flight parameters, including {{the control and}} actuator positions, engine information and time of day. There are 88 parameters required as a minimum under current US federal regulations (only 29 were required until 2002), but some systems monitor many more variables. Generally each parameter is recorded a few times per second, though some units store [...] "bursts" [...] of data {{at a much higher}} frequency if the data begin to change quickly. Most FDRs record approximately 17-25 hours of data in a continuous loop. It is required by regulations that an FDR verification check (readout) is performed annually in order to verify that all <b>mandatory</b> <b>parameters</b> are recorded.|$|E
40|$|This version {{documents}} {{new features}} {{found in the}} BMC Bioinformatics paper (in particular code chunk annotation, although it is simplified {{as compared to the}} paper) and removes many <b>mandatory</b> <b>parameters</b> such as item tags and description. This implies that "stash" could become deprecated in future releases...|$|E
30|$|BASR {{serves to}} help users {{understand}} the required SRPreConditions and SRParameters for service operations. It also assists in relevant operation preparations during the operation process. Basically, as a user selects certain cloud service/CSI/PSSA and SRParameter(s), BASR can actively examine all available operations for unsatisfied operation conditions and parameters. Then, relevant information regarding how to fulfil such conditions or/and obtain the <b>mandatory</b> <b>parameter(s)</b> is produced {{to assist the}} user for further actions.|$|E
5000|$|The Mandatory fixed part, when present, {{contains}} the <b>mandatory,</b> fixed-length <b>parameters</b> {{associated with the}} message type.|$|R
5000|$|An ISUP message {{contains}} a fixed header containing the {{circuit identification code}} and the ISUP message type, followed by a <b>mandatory</b> fixed-length <b>parameter</b> part, a <b>mandatory</b> variable-length <b>parameter</b> part, and an optional parameter part that are dependent {{on the type of}} message being sent. ISUP messages can be sent using the services of the Message Transfer Part, or, less often, the Signalling Connection Control Part. These messages are transmitted in various stages of call setup and release. The most common messages are: ...|$|R
2500|$|Any new {{expression}} {{that uses the}} placement syntax is a placement new expression, and any operator new or operator delete function that takes more than the <b>mandatory</b> first <b>parameter</b> ( [...] and , respectively) is a placement new or placement delete function.|$|R
40|$|Precise {{knowledge}} of dielectric {{properties of materials}} is required to implement the material in devices and circuits. At microwave frequencies complex permittivity (dielectric constant and loss tangent) are the two <b>mandatory</b> <b>parameters</b> prior to any design. We have identified Lithium Fluoride as a potential candidate, {{which can be used}} in conjunction with superconducting and non-superconducting parts of several microwave communication devices. Even though dielectric constant of LiF is known at room temperature there is no data presented at cryogenic temperatures. In this paper we have reported the dielectric constant and loss tangent of LiF as a function of temperature (19 - 295 K) and at a frequency of 8 GHz...|$|E
40|$|In {{the past}} decade, the {{research}} of pulsating variable stars has taken a giant leap forward thanks to the photometric measurements provided by space missions like Most, CoRoT, Kepler/K 2, and Brite. These missions have provided quasi uninterrupted photometric time-series with an ultra-high quality and a total length that is not achievable from Earth. However, many of the success stories {{could not have been}} told without ground-based spectroscopic follow-up observations. Indeed, spectroscopy has some important assets as it can provide (more) accurate information about stellar parameters (like the effective temperature, surface gravity, metallicity, and abundances that are <b>mandatory</b> <b>parameters</b> for an in-depth asteroseismic study), the radial velocity (that is important for the detection of binaries and for the confirmation of cluster membership, if applicable), and the projected rotational velocity (that allows the study of the effects of rotation on pulsations). Fortunately, several large spectroscopic surveys are (becoming) available {{that can be used for}} these purposes. For some of these surveys, sub-projects have been initiated with the specific goal to complement space-based photometry. In this review, several spectroscopic surveys are introduced and compared with each other. We show that a large amount of spectroscopic data is (becoming) available for a large variety of objects...|$|E
40|$|Demonstrating that a waste form {{produced}} by a given immobilization process is chemically and physically durable as well as compliant with disposal facility acceptance criteria {{is critical to the}} success of a waste treatment program, and must be pursued in conjunction with the maturation of the waste processing technology. Testing of waste forms produced using differing scales of processing units and classes of feeds (simulants versus actual waste) is the crux of the waste form qualification process. Testing is typically focused on leachability of constituents of concern (COCs), as well as chemical and physical durability of the waste form. A principal challenge regarding testing immobilized low-activity waste (ILAW) forms is the absence of a standard test suite or set of <b>mandatory</b> <b>parameters</b> against which waste forms may be tested, compared, and qualified for acceptance in existing and proposed nuclear waste disposal sites at Hanford and across the Department of Energy (DOE) complex. A coherent and widely applicable compliance strategy to support characterization and disposal of new waste forms is essential to enhance and accelerate the remediation of DOE tank waste. This paper provides a background summary of important entities, regulations, and considerations for nuclear waste form qualification and disposal. Against this backdrop, this paper describes a strategy for meeting and demonstrating compliance with disposal requirements emphasizing the River Protection Project (RPP) Integrated Disposal Facility (IDF) at the Hanford Site and the fluidized bed steam reforming (FBSR) mineralized low-activity waste (LAW) product stream...|$|E
40|$|In {{order to}} promote the use of sea-sate related {{parameters}} and in particular to introduce new warning criteria for rogues waves and dangerous sea-states within GMDSS, WP 8 main tasks consisted in to propose updates of WMO regulations and to interact with some end users to define specific products {{with the aid of}} physical, statistical and deterministic wave models. To find the appropriate parameters and related thresholds, a specific database issued from ECMWF was prepared for WP 5 to find correlations with ship accidents. Major updates of MMMS (Manual of Marine Meteorological Services, including sea-state as a <b>mandatory</b> <b>parameter</b> in MSI (Marine Safety Information) and dangerous sea-state/rogue waves and as a potential criterion for warning, has been agreed b...|$|R
40|$|This release {{marks the}} early access phase for YANK 1. 0. We intend {{for this to}} be a formal release for users to test YANK and its {{functionality}} while we refactor the underlying Python API. In this release: YAML Syntax Structure Frozen. YANK YAML Version 1. 0. All YAML scripts from this version will be compatible with future versions until YAML 2. 0 New features may appear in the time meantime, but scripts will be forwards compatible. Initial support for OpenMM XML systems and PDB files Support for separate solvent configurations for the two phases when defined from amber/gromacs/openmm files clearance in YAML no <b>mandatory</b> <b>parameter</b> of explicit solvent, but only when molecule setup goes through pipeline Boresch Orientational Restraints fully implemented and documented. Long range anisotropic dispersion correction improved to work on both ends of thermodynamic cycle leg Documentation updated with better algorithms and theory sections. Full walkthroughs of yank-examples added to online documentation Various other documentation improvements Support for upcoming OpenMM 7. 1 Release and features (still works with 7. 0. 1) YANK now on MIT License Many bugfixe...|$|R
40|$|It is {{objective}} to {{show the}} feasibility of volumetric velocity-encoded MRI (3 D-TPM) to derive velocity based motion quantification parameters. Background About 30 % of patients treated with cardiac resynchronization therapy (CRT) do not benefit from the procedure. The introduction of quantitative parameters for selection of patients appears <b>mandatory.</b> However, <b>parameters</b> based on 2 D imaging techniques may be less reproducible caused by rapid changes of the motion pattern along the cardiac axis. Methods 12 volunteers (26 ± 7 years) and 2 patients (46, DCM/ 29, LBBB) were investigated at a 3 T whole body MR scanner (Achieva, Philips) with a 32 channel cardiac coil. ...|$|R
40|$|Data {{representations}} in low dimensions such as {{results from}} unsupervised dimensionality reduction methods are often visually interpreted to find clusters of observations. To identify clusters the result must be appreciably clustered. This property of a result {{may be called}} "clusteredness". When judged visually, the appreciation of clusteredness is highly subjective. In this paper we suggest an objective way to assess clusteredness in data representations. We provide a definition of clusteredness that captures important aspects of a clustered appearance. We characterize these aspects and define the extremes rigorously. For this characterization of clusteredness we suggest an index to assess the degree of clusteredness, coined the OPTICS Cordillera. It makes only weak assumptions and is a property of the result, invariant for different partitionings or cluster assignments. We provide bounds and a normalization for the index, and prove that it represents the aspects of clusteredness. Our index is parsimonious with respect to <b>mandatory</b> <b>parameters</b> but also exible by allowing optional parameters to be tuned. The index {{can be used as}} a descriptive goodness-of-clusteredness statistic or to compare different results. For illustration we use a data set of handwritten digits which are very differently represented in two dimensions by various popular dimensionality reduction results. Empirically, observers had a hard time to visually judge the clusteredness in these representations but our index provides a clear and easy characterisation of the clusteredness of each result. (authors' abstract) Series: Discussion Paper Series / Center for Empirical Research Method...|$|E
40|$|The {{plastoquinone}} (Q(B)) binding niche of the Photosystem II (PSII) D 1 {{protein is}} the subject of intense research due to its capability to bind also anthropogenic pollutants. In this work, the Chlamydomonas reinhardtii D 1 primary structure was used as a template to computationally design novel peptides enabling the binding of the herbicide atrazine. Three biomimetic molecules, containing the Q(B) -binding site in a loop shaped by two alpha-helices, were reconstituted by automated protein synthesis, and their structural and functional features deeply analysed by biophysical techniques. Standing out among the others, the biomimetic mutant peptide, D 1 pepMut, showed high ability to mimic the D 1 protein in binding both Q(B) and atrazine. Circular dichroism spectra suggested a typical properly-folded alpha-helical structure, while isothermal titration calorimetry (ITC) provided a complete thermodynamic characterization of the molecular interaction. Atrazine binds to the D 1 pepMut with a high affinity (K-d = 2. 84 mu M), and a favourable enthalpic contribution (Delta H = - 11. 9 kcal mol(- 1)) driving the interaction. Fluorescence spectroscopy assays, in parallel to ITC data, provided hyperbolic titration curves indicating the occurrence of a single atrazine binding site. The binding resulted in structural stabilisation of the D 1 pepMut molecule, as suggested by atrazine-induced cooperative profiles for the fold-unfold transition. The interaction dynamics and the structural stability of the peptides in response to the ligand were particularly considered as <b>mandatory</b> <b>parameters</b> for biosensor/biochip development. These studies paved the way to the set-up of an array of synthetic mutant peptides {{with a wide range of}} affinity towards different classes of target analytes, for the development of optical nanosensing platforms for herbicide detection...|$|E
40|$|Purpose On 2009 the European Union (EU) Member States {{agreed to}} require origin {{labeling}} for virgin and {{extra virgin olive}} oils (EC Regulation 182 / 2009) to defend consumers need about true characteristics and origin. This Regulation, together with the well established laws regarding denominations and protected indications of origin (PDO PGI and TSG), {{has led to a}} new olive oil market where geographic origin labels are a big market competitive advantage. The extra virgin olive oil is also susceptible to several kind of adulterations, involving its blending with oils of scarce quality or of different botanical variety. In this context, quality markers of extra virgin olive oil have been identified and whose determination has become mandatory for its marketing. The purpose of the present work is to highlight the possible differences in mandatory chemical parameters and antioxidant properties among oil samples of different geographical origin. Both commercial and artisanal samples were analyzed and compared.  Design/methodology/approach. Fifty-five samples of extra virgin olive oil of known origin were analyzed for peroxide number, ΔK, free acidity percentage, total polyphenols and antioxidant capacity (by DPPH test). The results were then processed by multivariate statistical techniques such as ANOVA, Principal Component Analysis and Linea Discriminant Analysis.  Findings. All the <b>mandatory</b> <b>parameters</b> for all the samples analyzed were in the range of the legal limits, indicating an overall quality. Moreover, the samples were clearly discriminated according to their geographical origin. Further differentiation has been achieved for samples produced industrially or in artisanal way.  Originality/value The present work explores the possibility of using mandatory oil quality chemical parameters, besides their original purpose, also to differentiate their geographical and production origin. The parameters were determined by simple and well-established analytical methods, applicable in every average laboratory for routine quality analysis...|$|E
30|$|OCSO is an {{approach}} designed for service users {{to work with}} real-world cloud services to ensure efficient utilization of the provisioned service resources. OCSO system is rule-based, and once the <b>mandatory</b> service optimization <b>parameters</b> are completed, it would function fully automatically. As it detects inefficient service resource usage due to the workload changes, it reacts to add/remove certain resources by launching appropriate scaling up/down or in/out actions dynamically.|$|R
40|$|Cartridge Serial Number {{parameter}} {{increased in}} length from 10 bytes to 32 bytes. • Media Length parameter format changed from ASCII to binary and reduced from 4 to 2 bytes. • Parameter Format Version parameter added to Drive Mandatory section to for upwards compatibility. • Load Count added to Drive <b>Mandatory</b> section. • <b>Parameter</b> sections increased in length (and renumbered) to allow greater flexibility. • Timestamp appended added to Date Last Written parameter. • “Media Vendor Unique ” MAM section added...|$|R
40|$|The {{design of}} harbours, {{as with any}} other system design, must be an {{optimization}} process. In this study, a global examination of the different constraints in coastal engineering was performed and an optimization problem was defined. The problem has multiple objectives, and the criteria to be minimized are the structure cost and wave height disturbance inside a harbour. As concluded in this survey, the constraints are predefined <b>parameters,</b> <b>mandatory</b> constraints or optional constraints. All of these constraints are categorized into four categories: environmental, fluid mechanical, structural and manoeuvring...|$|R
30|$|Finally, the Open Geospacial Consortium (OGC), Inc. {{has been}} {{developing}} different standards {{in the area of}} geospatial data. One of the standards developed by the OGC is the sensor observation service (SOS) that deals with the specifications of data observation from different sensors in different, possibly geographically scattered, sensor networks [14]. The standard specifies that a GetObservation request may have several <b>mandatory</b> and optional <b>parameters.</b> One of the optional parameters is featureOfInterest, which is similar to our observation type. However, this approach is more focused for geographical observations and is a subset of a bigger framework, which significantly differs from the IETF recommendation.|$|R
50|$|Intermittent Mandatory Ventilation (IMV) {{refers to}} any mode of {{mechanical}} ventilation where a regular series of breaths are scheduled but the ventilator senses patient effort and reschedules mandatory breaths {{based on the}} calculated need of the patient. Similar to continuous <b>mandatory</b> ventilation in <b>parameters</b> set for the patients pressures and volumes but distinct {{in its ability to}} support a patient by either supporting their own effort or providing support when patient effort is not sensed. IMV is frequently paired with additional strategies to improve weaning from ventilator support or to improve cardiovascular stability in patients who may need full life support.|$|R
50|$|It {{had been}} part of his family {{tradition}} to enroll in the competition-examination to gain a position in the mandarin. In 1831, Cao Ba Quat entered the Thi Huong examinations, which was held in Hanoi. Initially he was ranked second among the prosperous candidates, but after his exam was reviewed by the Court, it was declared that he had failed due to violating examination rules. There was a <b>mandatory</b> stylistic and <b>parameters</b> that were to be followed by the candidates and it has been speculated that Cao Ba Quat was unable to follow the four forms of writing known as Chan, Thao, Trien, Le.|$|R
40|$|Objectives:To {{compare the}} value of ankle and toe {{pressures}} as regards the diagnosis of critical ischaemia, its prognosis, {{and the need for}} vascular surgery. Design:University hospital-based retrospective study. Materials and methods:Fifty-seven patients (23 women and 34 men) with gangrene or rest pain had a haemodynamic evaluation combining ankle systolic pressure, toe pressure and cutaneous oximetry (tcPO 2) with long-term follow-up (until death, for 44 %). Results:After 2 years of follow-up, actuarial rates were 49 and 79 % for survival and limb salvage, respectively. Ankle and toe pressures gave rise to different subsets of patients, p< 0. 001, mainly because of the existence of a group of patients with very distal foot arterial disease. Low ankle pressure was linked to the risk of major amputation. Low toe pressure was linked to a great need for vascular surgery. Diabetes increased the risk of minor amputation. Conclusions:The concept of critical ischaemia remains clinically relevant. Haemodynamic quantitative data strengthen this concept, but ankle and toe pressures are not interchangeable parameters. For these reasons, toe pressures should be changed from a recommended to a <b>mandatory</b> haemodynamic <b>parameter</b> in the definition of critical ischaemia...|$|R
40|$|This {{presentation}} {{addresses the}} use of Base SAS to write XML code to automate bulk file loading into Documentum, a document management system (DMS). Documentum with FirstDoc ® manages document attributes and has features such as check-in, check-out, version control, ownership, and access control. Even when using the bulk loading utility of Documentum with FirstDoc, the user must manually enter ample document metadata which can be monotonous and time consuming. Automating repetitive manual tasks are best handled with programming languages like SAS to eliminate tedious tasks. Benefits to the business include substantial timesaving and error reduction. Documentum with FirstDoc allows {{the use of}} XML control files to bulk load document objects. Base SAS can effectively be used to generate code in other languages like XML, especially when the other language has a consistent structure. This presentation will describe XML syntax requirements, outline the XML structure, and show the required document attributes to be processed via SAS code. Step by step instructions and example SAS code show how to control the <b>mandatory</b> keyword <b>parameters</b> and loop control in order to read a desired directory of objects. Concluding remarks will discuss implementation considerations and {{the advantages and disadvantages}} of this technique...|$|R
40|$|Abstract. The {{author of}} this paper aims to {{highlight}} the basic design of a flexible manufacturing cell with parallel organization destined for the assembly of tires on AAV carcasses shafts, operation performed by a TRTR serial-modular industrial robot. The paper describes, in detail: the direct and inverse geometric modeling of the mechanical structure, the direct kinematic modeling of the industrial robot under study, by calculating and illustrating, by means of time development graphs, the column vectors of the generalized coordinates {{as well as the}} prehension device characteristic point trajectory that define, at a given moment, its position, orientation and movement within the flexible manufacturing cell proposed for implementation. The final part of the paper presents, based on several functional <b>parameters</b> <b>mandatory</b> for the building of the FMC, the calculus of economic indicators necessary for the optimum functioning of the cell as well as for determining the value of the robot included in its activity and of the overall flexible manufacturing system...|$|R
40|$|Assessment of {{reproductive}} toxicity is an animal-, time- and cost-consuming process. In order to refine, replace and reduce animal testing, {{the use of}} in-silico, in-vitro and alternative in-vivo strategies is tested for their value to predict adverse reproductive outcomes. Due {{to the complexity of}} the reproductive cycle, encompassing maturation of gametes, mating, implantation of the conceptus, intra-uterine survival and maturation as well as postnatal development, no alternative testing strategies so far are able to cover all aspects of fertility. One approach should therefore be the use of existing animal study data, especially from repeated dose studies, to analyse indicators for reproductive toxicity. The current versions of OECD Guideline requirements for repeated dose toxicity include structural changes in reproductive organ tissues (mainly testes, epididymides, prostate, seminal vesicles and ovaries and uterus). Based on this information repeated dose toxicity studies are useful for selection of substances for further reproductive toxicity testing, for appropriate dose selection and for selection to incorporate additional parameters, e. g. for endocrine testing, into reproductive toxicity studies. In addition repeated dose studies can have a predictive value for detecting certain impairments {{of reproductive}} function. These conclusions have been extended by analysing animal studies from the Fraunhofer ITEM databases RepDose for repeated dose toxicity and FeDTex for reproductive toxicity. Further, based on the analysis of FeDTex, and in view of the development of AOP (adverse outcome pathway) -based approaches it should be considered to enhance the list of <b>mandatory</b> study <b>parameters</b> in repeated dose studies by hormone and sperm parameters and oestrus cyclicity in order to increase the predictivity for reproductive toxicity...|$|R
40|$|Abstract—Spot segmentation—the second {{essential}} {{stage of}} cDNA microarray image analysis—constitutes a challenging process. At present, several up-to-date spot-segmentation techniques or software programs—proposed in the literature—are often characterized as “automatic. ” On the contrary, {{they are in}} effect not fully automatic since they require human intervention in order to specify <b>mandatory</b> input <b>parameters</b> or to correct their results. Human intervention, however, can inevitably modify the actual results of the cDNA microarray experiment and lead to erroneous biological conclusions. Therefore, {{the development of an}} automated spot-segmentation process becomes of exceptional interest. In this paper, an original and fully automatic approach to accurately segmenting the spots in a cDNA microarray image is presented. In order for the segmentation to be accomplished, each real spot of the cDNA microarray image is represented in a three-dimensional (3 -D) space by a 3 -D spot model. Each 3 -D spot model is determined via an optimization problem, which is solved by using a genetic algorithm. The segmentation of real spots is conducted by drawing the contours of their 3 -D spot models. The proposed method has been compared with various published and established techniques, using several synthetic and real cDNA microarray images that contain thousands of spots. The outcome has shown that the proposed method outperforms prevalent existing techniques. It is also noise resistant and yields excellent results even under adverse conditions such as the appearance of spots of various sizes and shapes. Index Terms—cDNA microarrays, genetic algorithm, image analysis, spot segmentation, 3 -D spot modeling...|$|R
40|$|The RF {{system of}} the ThomX storage ring {{consists}} in a 500 MHz single cell copper cavity of the ELETTRA type, powered with a 50 kW CW solid state amplifier, and the associated Low Level RF feedback and control loops. The low operating energy of 50 – 70 MeV makes the impedances of the cavity higher order modes (HOMs) particularly critical for the beam stability. Their parasitic effects on the beam can be cured by HOM frequency shifting techniques, based on a fine temperature tuning and a dedicated plunger. A typical cavity temperature stability of ± 0. 05 °C within a range from 35 up to 80 °C {{can be achieved by}} a precise control of its water cooling temperature. On the other hand, the tuning of the cavity fundamental mode is achieved by changing its axial length by means of a mechanical tuner. In order to insure a fine control of the HOM frequencies, a good knowledge of their characteristics is <b>mandatory.</b> The main <b>parameters</b> of the fundamental and of the HOMs up to 4 GHz have been calculated using the HFSS and CST MWS codes. Preliminary measurements results have been obtained and show a good agreement with the simulations...|$|R
40|$|The balloon-borne {{experiment}} Cosmic Ray Energetics And Mass (CREAM) investigates {{very high}} energy (10 e 10 to 10 e 15 eV) cosmic rays over the elemental range from protons to iron. This energy range offers promising prospects for answering fundamental questions related with the source, acceleration mechanism and propagation {{conditions of the}} cosmic-ray flux. This should also help constraining the astrophysical <b>parameters</b> <b>mandatory</b> to search for dark-matter signals in the GeV range. The first CREAM flight was launched from the McMurdo Station, Antarctica, aboard a NASA research balloon on December 16, 2004. Floating for nearly 42 days at altitudes between 36 and 39 km, CREAM collected over 4 x 10 e 7 events. CREAM-II was launched on December 16, 2005 and flew for 28 days. The preliminary analysis already show some very interesting results emerging from this set of data. The CREAM III flight is scheduled to fly next winter 2007 with, among others instrumental improvements, a Cherenkov imager (RICH) detector, providing individual separation of nuclear cosmic-ray elements through {{the whole range of}} interest, in account of its excellent charge resolution over this range. This upgrade should improve significantly the instrument performances, especially in the high mass range of the detected particles...|$|R
30|$|One-dimensional basin {{model is}} {{generated}} using the PetroMod software (version 9.0) {{to analyze the}} burial and thermal maturity histories for the Taratu Formation. All <b>parameters</b> <b>mandatory</b> for basin modeling are prepared for the well under study, including name of formations as detected in the well, formation age (Ma), formation thickness (m), measured borehole temperature (celsius), and measured vitrinite reflectance (% Ro). This research uses a constant heat flow of a constant heat flow of 60  mW/m 2 (Godfrey et al. 2001) and a kinetic model introduced by Pepper and Corvi (1995). This model suggests that the central parameter that controls expulsion of hydrocarbon is the hydrogen index of the formation and applies five organofacies in characterizing a source rock. This study applies the kinetic model type III DE for the source rock of study because this model type is suitable for terrigenous, non-marine, and waxy source rock, such as the Taratu Formation. In this study, kinetic model type III DE is applied for the source rock of study as the Taratu Formation. A water depth of 123.4  m beneath sea level is another boundary condition in 1 -D modeling. Petroleum system elements that each formation represents together with other relevant geochemical parameters belonging to the studied source rock such as TOC and HI are also useful.|$|R
40|$|WEPFI 005 - Work is {{supported}} by the French "Agence Nationale de la Recherche" as part of the program "investing in the future" under reference ANR- 10 -EQPX- 51, and also by grants from Region Ile-de-France. International audienceThe RF system of the ThomX* storage ring will consist in a 500 MHz single cell copper cavity of the ELETTRA type, powered with a 50 kW CW solid state amplifier, and the associated Low Level RF feedback and control loops. The low operating energy of 50 - 100 MeV makes the impedances of the cavity higher order modes (HOMs) particularly critical for the beam stability. Their parasitic effects on the beam can be cured byHOMfrequency shifting techniques, based on a fine temperature tuning and a dedicated plunger. A typical cavity temperature stability of ± 0. 05 oC within a range from 35 up to 80 oC can be achieved by a precise control of its water cooling temperature. On the other hand, the tuning of the cavity fundamental mode is achieved by changing its axial length by means of a mechanical tuner. In order to insure a fine control of the HOM frequencies, a good knowledge of their characteristics is <b>mandatory.</b> The main <b>parameters</b> of the fundamental and of the HOMs up to 4 GHz have been calculated using the HFSS and CST MWS codes. Preliminary measurements results have been obtained and show a good agreement with the simulations...|$|R
