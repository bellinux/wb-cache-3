3|57|Public
40|$|Joint Collaborative Team on 3 D Video Coding Extensions of ITU-T SG 16 WP 3 and ISO/IEC JTC 1 /SC 29 /WG 11, JCT 3 V-E 0126, 5 th Meeting: Vienna, AU, July 27 - Aug. 2, 2013. This {{proposal}} {{is a result}} of harmonization of techniques in JCT 3 V-D 0178 and JCT 3 V-D 0109. In JCT 3 V-D 0178, up to two candidates may be inserted into a <b>merge</b> <b>candidate</b> list, wherein a candidate is derived by left/right shifting of the disparity vector to identify a candidate in a block of the reference view, if that candidate is unavailable, a disparity motion vector from the spatial neighboring blocks or the disparity vector is left/right shifted to create the candidate. In JCT 3 V-D 0109, a candidate is purely derived by a shift considering the width and height of the current PU. In this joint contribution, it is proposed to add only one additional candidate in the <b>merge</b> <b>candidate</b> list. The additional candidate is firstly generated by shifting the disparity vector by considering the size of the current PU and utilizing the motion information of an identified block in the reference view, as it is done in JCT 3 V-D 0109. Furthermore, similar to JCT 3 V-D 0178, if the block doesn't provide an available candidate, the candidate is derived by shifting horizontally a disparity motion vector. Compared to the current HTM design, the proposed method achieves a compression efficiency gain of 0. 2 % in terms of BD rate for both BVSP on and off cases, respectively...|$|E
40|$|Joint Collaborative Team on 3 D Video Coding Extensions of ITU-T SG 16 WP 3 and ISO/IEC JTC 1 /SC 29 /WG 11, JCT 3 V-D 0178, 4 th Meeting: Incheon, KR, 20 - 26 Apr. 2013. When inter-view motion {{prediction}} is enabled, the current HTM {{design of the}} <b>merge</b> <b>candidate</b> list may include an inter-view predicted motion candidate before all the spatial merging candidates. In addition, the disparity vector may also be converted to a disparity motion vector and it is inserted into the list following the above-right spatial candidate. As a harmonized follow-up proposal of JCT 3 V-C 0045 and JCT 3 V-C 0148, it is proposed to add two more candidates. Each candidate is derived with a horizontally shifted disparity vector being used for inter-view motion prediction and if it doesn't provide an available candidate, then it is derived from a horizontally shifted spatial neighbouring candidate, if it contains a disparity motion vector. Compared to the current HTM design, the proposed method achieves compression efficiency gain of 0. 2 % in terms of BD rate for both BVSP on and off cases...|$|E
30|$|Since {{the depth}} map and its {{associated}} texture video are both projections of the same scenery from the same viewpoint {{at the same time}} instant, the motion characteristics (i.e., block partitioning and corresponding motion vectors) of the depth map {{and its associated}} texture video are typically similar. Therefore, a new coding mode motion parameter inheritance (MPI) [4, 17], where the data that are already transmitted for the texture video picture can be reused for efficient encoding of the depth map, has been introduced in the 3 D-HEVC encoder. This achieves the highest coding efficiency but requires a very high computational complexity. Since the motion vectors of the texture video have quarter-sample accuracy, whereas for the depth map only full-sample accuracy is used, in the inheritance process, the motion vectors are quantized to their nearest full-sample position. In addition, the inherited reference picture shall be the one with the same picture order count (POC) and viewpoint as the reference picture of the co-located block in the texture video picture. If there is no reference picture in the reference lists that satisfies this condition, such a candidate is treated as invalid and it is not inserted to the <b>merge</b> <b>candidate</b> list. However, the coding information correlations between the depth map and texture video are not fully studied. The coding information includes the reference picture, prediction mode, and motion vector.|$|E
30|$|In general, {{there will}} be {{multiple}} pairs of identifiable quantization bins that can be <b>merged.</b> Often, all <b>candidate</b> identifiable pairs cannot be merged simultaneously; that is, after a pair has been <b>merged,</b> other <b>candidate</b> pairs may become nonidentifiable. In what follows, we propose algorithms to determine in a sequential manner which pairs should be merged.|$|R
3000|$|B| 2)) are {{required}} for determining the occupancy {{of each and every}} data point while <b>merging</b> these <b>candidate</b> clusters where, |D [...]...|$|R
40|$|A {{segmentation}} {{method for}} color images {{is presented in}} this work. A morphological unsupervised 2 D multiband histogram clustering provides an initial coarse segmntation of the image. Region information is then used and a novel technique is introduced to simplify the Region Adjacency Graph by <b>merging</b> <b>candidate</b> regions until the stabilization of a segmentation criterion. Merged regions are refined by a color watershed. The whole method requires the definition of only one single parameter which acts {{as a kind of}} multiscale parameter...|$|R
40|$|A hybrid {{segmentation}} {{method for}} color images {{is presented in}} this work. It combines 2 D histogram clustering to produce segmentation maps fused together providing an initial unsupervised clustering of the dominant colors of the image. Region information is then used and a novel technique is introduced to simplify the Region Adjacency Graph by <b>merging</b> <b>candidate</b> regions until the stabilization of a "good" segmentation criterion. Merged regions are refined by a color watershed using local and global properties of the image. The robustness of the method is experimentally verified and the color space influence is studied...|$|R
40|$|We use the {{polyhedral}} process network (PPN) {{model of}} com-putation to program embedded Multi-Processor Systems on Chip (MPSoCs) platforms. If a designer wants {{to reduce the}} number of processes in a network due to resource constraints, for example, then the process merging transformation can be used to achieve this. We present a compile-time approach to evaluate the system throughput of PPNs in order to select a <b>merging</b> <b>candidate</b> which gives a system throughput as close as possible to the original PPN. We show results for two experiments on the ESPAM platform prototyped on a Xilinx Virtex 2 Pro FPGA. I...|$|R
40|$|An hybrid {{segmentation}} {{method for}} color images {{is presented in}} this work. It combines 2 D histogram clustering to produce segmentation maps fused together providing an initial unsupervised clustering of the dominant colors of the image. Region information is then used and a novel technique is introduced to simplify the Region Adjacency Graph by <b>merging</b> <b>candidate</b> regions until the stabilization of a "good" segmentation criterion. Merged regions are refined by a color watershed using local and global properties of the image. The robustness of the method is experimentally verified and the color space influence is studied...|$|R
40|$|Abstract. The EM {{algorithm}} for Gaussian mixture models {{often gets}} caught in local maxima {{of the likelihood}} which involve having too many Gaussians {{in one part of}} the space and too few in another, widely separated part of the space. We present a new EM algorithm which performs split and merge operations on the Gaussians to escape from these configurations. This algorithm uses two novel criteria for efficiently selecting the split and <b>merge</b> <b>candidates.</b> Experimental results on synthetic and real data show the effectiveness of using the split and merge operations to improve the likelihood of both the training data and of held-out test data. 1...|$|R
30|$|In {{micro-blog}} corpus, {{the next}} steps for filtering network words are to calculate IF-IDF values of each candidate word, and then sort them, set a threshold value, and finally <b>merge</b> the <b>candidate</b> words higher than the threshold into micro-blog network sentiment word set.|$|R
40|$|The main {{motivation}} {{of this paper}} is to devise a way to select the best answers collected from multiple web sources. Depending on questions, we need to combine multiple QA modules. To this end, we analyze real-life questions for their characteristics and classify them into different domains and genres. In the proposed distributed QA framework, local optimal answers are selected by several specialized sub-QAs. For fining global optimal answers, <b>merged</b> <b>candidates</b> are re-ranked by adjusting confidence weights based on the question analysis. We adopt the idea of the margin separation of SVM classification algorithm to adjust confidence weights calculated by own ranking methods in sub-QAs. We also prove the effects of the proposed re-ranking algorithm based on a series of experiments. </p...|$|R
40|$|Nowadays, the {{existing}} blind source separation (BSS) algorithms in rotating machinery fault diagnosis can hardly {{meet the demand}} of fast response, high stability, and low complexity simultaneously. Therefore, this paper proposes a spectrum correction based BSS algorithm. Through the incorporation of FFT, spectrum correction, a screen procedure (consisting of frequency <b>merging,</b> <b>candidate</b> pattern selection, and single-source-component recognition), modified k-means based source number estimation, and mixing matrix estimation, the proposed BSS algorithm can accurately achieve harmonics sensing on field rotating machinery faults in case of short-sampled observations. Both numerical simulation and practical experiment verify the proposed BSS algorithm’s superiority in the recovery quality, stability to insufficient samples, and efficiency over {{the existing}} ICA-based methods. Besides rotating machinery fault diagnosis, the proposed BSS algorithm also possesses a vast potential in other harmonics-related application fields...|$|R
40|$|We {{examine the}} {{competitive}} {{effects of a}} passive partial ownership (PPO) when it serves as an instrument for the acquirer firm to learn the merger synergies with the target firm in advance. The realization of a synergy is uncertain ex ante, so that a direct merger exhibits a downside risk {{not only for the}} <b>merging</b> <b>candidates</b> but also for consumers. We show that minority shareholdings can reduce this downside risk as they allow for a sequential takeover where the acquirer takes an initial minority share, becomes an insider, and learns the merger synergy. We show how this feature of PPOs affects a firm's takeover strategy and the decision problem of the antitrust authority. We derive implications for a merger control approach to PPO acquisitions, where we examine a forward looking price test and a safeharbor rule...|$|R
40|$|Rough {{set theory}} {{is used to}} represent, analyze, and {{manipulate}} knowledge in information or decision tables. To remove superfluous attributes without changing the original knowledge, reduction is must in rough set. This paper introduces the pseudo decision table to replace the original table and two algorithms, RGonCRS and SRGonCRS, based on the current rules size, CRS, are presented to generate all reducts which ensure the lower approximation for each instance in {{the table with a}} minimal number of attributes. RGonCRS finds reducts by <b>merging</b> <b>candidate</b> attributes and SRGonCRS is a scalable version of RGonCRS which generates reducts for very large tables. Propositions and proofs are presented in this paper. Empirical tests are shown for RGonCRS using simulated information tables and UCI benchmark datasets and a preliminary test is generated for SRGonCRS. Results are compared to the well-known rough set software – Rough Se...|$|R
40|$|We {{present a}} split and merge EM (SMEM) {{algorithm}} {{to overcome the}} local maxima problem in parameter estimation of finite mixture models. In the case of mixture models, local maxima often involve having too many components of a mixture model {{in one part of}} the space and too few in another, widely separated part of the space. To escape from such configurations we repeatedly perform simultaneous split and merge operations using a new criterion for efficiently selecting the split and <b>merge</b> <b>candidates.</b> We apply the proposed algorithm to the training of Gaussian mixtures and mixtures of factor analyzers using synthetic and real data and show the effectiveness of using the split and merge operations to improve the likelihood of both the training data and of held-out test data. We also show the practical usefulness of the proposed algorithm by applying it to image compression and pattern recognition problems...|$|R
40|$|We {{present and}} {{evaluate}} two variants of an algorithm for simultaneously segmenting and modeling a mixed-density unstructured 3 D point cloud by ellipsoidal (Gaussian) region growing. The base algorithm merges initial ellipsoids into larger ellipsoidal segments {{with a minimum}} spanning tree algorithm. The variants differ only in the merge criterion used—a threshold on a generalised distance measure defined on the <b>merge</b> <b>candidates.</b> The first variant (shape-distance) considers the relative shape, orientation and position of the ellipsoids, and can grow regions across missing or sparse data, whilst the second (density-distance) attempts to maintain a good fit to the data by setting a minimum sample density threshold on the merged ellipsoid. Adjusting the threshold in each case changes the quality and degree of segmentation achieved. The threshold parameter is tuned by minimising Akaike’s Information Criterion (AIC) {{with respect to the}} threshold value. Experiments show that thresholds selected in this way lead to low complexity models and are stable across different environments. The shape-distance measure segments large-scale structures more readily than the density-distance measure, but leads to higher AIC scores, and higher model complexity. ...|$|R
40|$|Industrial {{applications}} of mo del-driven engineering to de- velop large and complex systems {{resulted in an}} increasing demand for collab oration features. However, use cases such as mo del di�erencing and merging {{have turned out to}} b e a di�cult challenge, due to (i) the graph- like nature of mo dels, and (ii) the complexity of certain op erations (e. g. hierarchy refactoring) that are common to day. In the pap er, we present a novel search-based automated mo del merge approach where rule-based design space exploration is used to search the space of solution candi- dates that represent con�ict-free merged mo dels. Our metho d also allows engineers to easily incorp orate domain-sp eci�c knowledge into the merge pro cess to provide b etter solutions. The merge pro cess automatically cal- culates multiple <b>merge</b> <b>candidates</b> to b e presented to domain exp erts for �nal selection. Furthermore, we prop ose to adopt a generic synthetic b enchmark to carry out an initial scalability assessment for mo del merge with large mo dels and large change sets...|$|R
40|$|Many {{statistical}} {{learning problems}} in NLP call for local model search methods. But accuracy tends to suffer with current techniques, which often explore either too narrowly or too broadly: hill-climbers can {{get stuck in}} local optima, whereas samplers may be inefficient. We propose to arrange individual local optimizers into organized networks. Our building blocks are operators of two types: (i) transform, which suggests new places to search, via non-random restarts from already-found local optima; and (ii) join, which <b>merges</b> <b>candidate</b> solutions to find better optima. Experiments on grammar induction show that pursuing different transforms (e. g., discarding parts of a learned model or ignoring portions of training data) results in improvements. Groups of locally-optimal solutions can be further perturbed jointly, by constructing mixtures. Using these tools, we designed several modular dependency grammar induction networks of increasing complexity. Our complete system achieves 48. 6 % accuracy (directed dependency macro-average over all 19 languages in the 2006 / 7 CoNLL data) — more than 5 % higher than the previous state-of-the-art. ...|$|R
5000|$|Bottom-up {{algorithms}} {{take the}} [...] "opposite" [...] approach to top-down methods, first assuming {{that there is}} a step in between every sample in the digital signal, and then successively merging steps based on some criteria tested for every <b>candidate</b> <b>merge.</b>|$|R
3000|$|For s-sparse signal recovery, we {{consider}} the CoSaMP algorithm presented in Algorithm 2.1 of[20], which is described in Algorithm 1 of this paper. At each iteration, it forms a signal proxy f and identifies a potential candidate Ω of the signal support by locating the largest 2 s components of the proxy. The algorithm then <b>merges</b> the <b>candidate</b> Ω with the one from the previous iteration, {{to create a new}} support set T. To estimate the target signal [...]...|$|R
40|$|A uni ed multigrid {{solution}} {{technique is}} presented for solving the Euler and Reynoldsaveraged Navier-Stokes equations on unstructured meshes using mixed elements consisting of triangles and quadrilaterals in two dimensions, and of hexahedra, pyramids, prisms and tetrahedra in three dimensions. While {{the use of}} mixed elements {{is by no means}} a novel idea, the contribution of the paper lies in the formulation of a complete solution technique which can handle structured grids, block structured grids, and unstructured grids of tetrahedra or mixed elements without any modi cation. This is achieved by discretizing the full Navier-Stokes equations on tetrahedral elements, and the thin layer version of these equations on other types of elements, while using a single edge-based data-structure to construct the discretization over all element types. An agglomeration multigrid algorithm, which naturally handles meshes of any types of elements, is employed to accelerate convergence. An automatic algorithm which reduces the complexity of a given triangular or tetrahedral mesh by <b>merging</b> <b>candidate</b> triangular or tetrahedral elements into quadrilateral or prismatic elements is also described. The gains in computational e ciency a orded by the use of non-simplicial meshes over fully tetrahedral meshes are demonstrated through several examples...|$|R
40|$|Abstract Major {{challenges}} of clustering geo-referenced data include identifying arbitrarily shaped clusters, properly utilizing spatial information, coping with diverse extrinsic characteristics of clusters and supporting region discovery tasks. The goal of region discovery {{is to identify}} interesting regions in geo-referenced datasets based on a domain expert’s notion of interestingness. Almost all agglomerative clustering algorithms only focus on the first challenge. The goal of the proposed work is to develop agglomerative clustering frameworks that deal with all four challenges. In particular, we propose a generic agglomerative clustering framework for geo-referenced datasets (GAC-GEO) generalizing agglomerative clustering by allowing for three plug-in components. GAC-GEO agglomerates neighboring clusters maximizing a plug-in fitness function that capture the notion of interestingness of clusters. It enhances typical agglomerative clustering algorithms in two ways: fitness functions support task-specific clustering, whereas generic neighboring relationships {{increase the number of}} <b>merging</b> <b>candidates.</b> We also demonstrate that existing agglomerative clustering algorithms can be considered as specific cases of GAC-GEO. We evaluate the proposed framework on an artificial dataset and two real world applications involving region discovery. The experimental results show that GAC-GEO is capable of identifying arbitrarily shaped hotspots for different data mining tasks...|$|R
40|$|This paper {{describes}} the approaches and {{results of our}} sys-tem for the NTCIR- 10 INTENT task. We present some methods for Subtopic Mining subtask and Document Rank-ing subtask. In the Subtopic Mining subtask, we employ a voting method to rank candidate subtopics and semantic re-source HowNet was used to <b>merge</b> those <b>candidate</b> subtopics which may impact diversity. In the Document Ranking Sub-task, we also employ a voting method based on the mined subtopics. In the Chinese subtopic mining, our best val-ues of I...|$|R
40|$|This {{paper is}} the first part in our series on the {{influence}} of tidal interactions and minor mergers on the radial and vertical disk structure of spiral galaxies. We report on the sample selection, our observations, and data reduction. Surface photometry of the optical and near infrared data of a sample of 110 highly-inclined/edge-on disk galaxies are presented. This sample consists of two subsamples of 61 non-interacting galaxies (control sample) and of 49 interacting galaxies/minor <b>merging</b> <b>candidates.</b> Additionally, 41 of these galaxies were observed in the near infrared. We show that the distribution of morphological types of both subsamples is almost indistinguishable, covering the range between 0 <= T <= 9. An improved, 3 -dimensional disk modelling- and fitting procedure is described in order to analyze and to compare the disk structure of our sample galaxies by using characteristic parameters. We find that the vertical brightness profiles of galactic disks respond very sensitive even to small deviations from the perfect edge-on orientation. Hence, projection effects of slightly inclined disks may cause substantial changes {{in the value of the}} disk scale height and must therefore be considered in the subsequent study. Comment: LaTeX, 36 pages, 5 figures, complete series of papers incl. all figures of higher quality is available at [URL]...|$|R
40|$|HLT 1994 : Workshop on Human Language Technology, March 8 - 11, 1994, Plainsboro, New Jerey, USA. This paper {{describes}} an accurate and efficient algorithm for very-large-vocabulary continuous speech recognition {{based on an}} HMM-LR algorithm. The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models. To reduce the search space without pruning the correct candidate, we use forward and backward trellis likelihoods, an adjusting window for choosing only the probable part of the trellis for each predicted phoneme, and an algorithm for <b>merging</b> <b>candidates</b> that have the same allophonic phoneme sequences and the same context-free grammar states. <b>Candidates</b> are also <b>merged</b> at the meaning level. This algorithm is applied to a telephone directory assistance system that recognizes spontaneous speech containing the names and addresses of more than 70, 000 subscribers (vocabulary size is about 80, 000). The experimental {{results show that the}} system performs well in spite of the large perplexity. This algorithm was also applied to a multi-modal telephone directory assistance system, and the system was evaluated from the human-interface point of view. To cope with the problem of background noise, an HMM composition technique which combines a noise-source HMM and a clean phoneme HMM into a noise-added phoneme HMM was investigated and incorporated into the system...|$|R
40|$|In this work, we {{investigate}} how to automatically reassign the man-ually annotated labels at the image-level to those contextually de-rived semantic regions. First, we propose a bi-layer sparse coding formulation for uncovering how an image or semantic region can be robustly reconstructed from the over-segmented image patches {{of an image}} set. We then harness it for the automatic label to re-gion assignment of the entire image set. The solution to bi-layer sparse coding is achieved by convex ℓ 1 -norm minimization. The underlying philosophy of bi-layer sparse coding is that an image or semantic region can be sparsely reconstructed via the atomic image patches belonging to the images with common labels, while the ro-bustness in label propagation requires that these selected atomic patches come from very few images. Each layer of sparse cod-ing produces the image label assignment to those selected atomic patches and <b>merged</b> <b>candidate</b> regions based on the shared image labels. The results from all bi-layer sparse codings over all can-didate regions are then fused to obtain the entire label to region assignments. Besides, the presenting bi-layer sparse coding frame-work can be naturally applied to perform image annotation on new test images. Extensive experiments on three public image datasets clearly demonstrate the effectiveness of our proposed framework in both label to region assignment and image annotation tasks...|$|R
40|$|Abstract—In this paper, {{we propose}} a {{parallel}} design of Viterbi decoder for Software-Defined Radio (SDR). Our method implements a divide-and-conquer approach by tiling decoding sequences, performing independent speculated Viterbi decoding, and <b>merging</b> partial <b>candidate</b> paths {{into the final}} path. For each independent Viterbi decoding, the best path is selected by calculating Hamming distances trellis-by-trellis in parallel. Our method shows up to 14. 6 x speedup on an NVIDIA 8800 GTX over a sequential C implementation on a 2. 4 GHz Intel Core 2 CPU. Also, compared with existing GPU-based implementation in [3], our method outperforms up to 2. 5 x...|$|R
40|$|The {{demand for}} the MBA program is {{considered}} high in Malaysia and to select the suitable MBA candidate that can excel in his performance encouraged {{me to do this}} research. The MBA program is different from other postgraduate program in the sense that it’s <b>candidates</b> <b>merge</b> from different backgrounds with different learning styles and this might make them differ in their academic performance...|$|R
40|$|Received date; {{accepted}} date We {{present a}} combined X-ray and optical analysis of three bimodal galaxy clusters selected as <b>merging</b> <b>candidates</b> at z ∼ 0. 1. These targets {{are part of}} MUSIC (MUlti–Wavelength Sample of Interacting Clusters), which is a general project designed to study the physics of merging clusters by means of multi-wavelength observations. Observations include spectro-imaging with XMM-Newton EPIC camera, multi-object spectroscopy (260 new redshifts), and wide-field imaging at the ESO 3. 6 m and 2. 2 m telescopes. We build a global picture of these clusters using X-ray luminosity and temperature maps together with galaxy density and velocity distributions. Idealized numerical simulations were used to constrain the merging scenario for each system. We show that A 2933 is very likely an equal-mass advanced pre-merger ∼ 200 Myr before the core collapse, while A 2440 and A 2384 are post-merger systems (∼ 450 Myr and ∼ 1. 5 Gyr after core collapse, respectively). In the case of A 2384, we detect a spectacular filament of galaxies and gas spreading over more than 1 h− 1 Mpc, which we infer to have been stripped during the previous collision. The analysis of the MUSIC sample allows us to outline some general properties of merging clusters: a strong luminosity segregation of galaxies in recent post-mergers; the existence of preferential axes –corresponding to the merging directions – along which the BCGs and structures on various scales are aligned; the concomitance, in most major merger cases, of secondary merging or accretion events, with groups infalling onto th...|$|R
40|$|In {{this paper}} an {{information}} theoretic approach is provided for resolving border ambiguity under partial occlusion. The proposed framework allows structural interpretation of images {{prior to the}} application of domain specific knowledge. The central idea behind MDL based figure-ground grouping is <b>merging</b> those place-token <b>candidates</b> whose composed description length (whole) is better than sum of their individual description lengths (parts). The computational theory is illustrated by application to blocks-world images. ...|$|R
30|$|In {{the second}} phase, we refine the {{previous}} segmentation by <b>merging</b> adjacent <b>candidate</b> segments that share similar structures. This phrase is required because a paragraph is sometimes over-segmented into several candidate segments {{in the first}} phase due to the difference in height of the two lines on the boundary. We address this issue by considering features about the whole segment, e.g., font-size approximated by the average height of lines, when finding two segments that should be merged. Algorithm  2 shows the detailed process of the second phase. At the fourth line in this algorithm, two candidate segments are considered similar if (1) they share the same alignment, (2) they have similar font-size, or (3) the space between them is less than a threshold.|$|R
40|$|Freeway merging in {{congested}} {{traffic is}} a significant challenge toward fully automated driving. Merging vehicles need to decide not only how to merge into a spot, but also where to merge. We present a method for the freeway merging based on multi-policy decision making with a reinforcement learning method called passive actor-critic (pAC), which learns with less knowledge {{of the system and}} without active exploration. The method selects a <b>merging</b> spot <b>candidate</b> by using the state value learned with pAC. We evaluate our method using real traffic data. Our experiments show that pAC achieves 92 % success rate to merge into a freeway, which is comparable to human decision making. Comment: 6 pages, 5 figures. ICML Workshop on Machine Learning for Autonomous Vehicle...|$|R
40|$|We {{present a}} {{combined}} X-ray and optical analysis of three bimodal galaxy clusters selected as <b>merging</b> <b>candidates</b> at z ~ 0. 1. These targets {{are part of}} MUSIC (MUlti [...] Wavelength Sample of Interacting Clusters), which is a general project designed to study the physics of merging clusters by means of multi-wavelength observations. Observations include spectro-imaging with XMM-Newton EPIC camera, multi-object spectroscopy (260 new redshifts), and wide-field imaging at the ESO 3. 6 m and 2. 2 m telescopes. We build a global picture of these clusters using X-ray luminosity and temperature maps together with galaxy density and velocity distributions. Idealized numerical simulations were used to constrain the merging scenario for each system. We show that A 2933 is very likely an equal-mass advanced pre-merger ~ 200 Myr before the core collapse, while A 2440 and A 2384 are post-merger systems ~ 450 Myr and ~ 1. 5 Gyr after core collapse, respectively). In the case of A 2384, we detect a spectacular filament of galaxies and gas spreading over more than 1 h^{- 1 } Mpc, which we infer to have been stripped during the previous collision. The analysis of the MUSIC sample allows us to outline some general properties of merging clusters: a strong luminosity segregation of galaxies in recent post-mergers; the existence of preferential axes [...] corresponding to the merging directions [...] along which the BCGs and structures on various scales are aligned; the concomitance, in most major merger cases, of secondary merging or accretion events, with groups infalling onto the main cluster, {{and in some cases}} the evidence of previous merging episodes in one of the main components. These results are in good agreement with the hierarchical scenario of structure formation, in which clusters are expected to form by successive merging events, and matter is accreted along large [...] scale filaments...|$|R
40|$|Abstract—Due to the {{prevalence}} of “We-Media”, everybody quickly publishes and receives information in various forms anywhere and anytime through the Internet. The rich cross-media information carried by the multi-modal data in multiple media has a wide audience, deeply reflects the social realities and brings about much greater social impact than any single media information. Therefore, automatically detecting topics from cross-media is of great benefit for the organizations (i. e., advertising agencies, governments) that care about the social opinions. How-ever, cross-media topic detection is challenging from following aspects: 1) the multi-modal data from different media often involve distinct characteristics; 2) topics are presented in an arbitrary manner among the noisy web data. In this paper, we propose a multi-modality fusion framework and a topic recovery approach to effectively detect topics from cross-media data. The multi-modality fusion framework flexibly incorporates the heterogeneous multi-modal data into a Multi-Modality Graph (MMG), which takes full advantage from the rich cross-media information to effectively detect topic candidates. The topic recovery (TR) approach solidly improves the entirety and purity of detected topics by: 1) <b>merging</b> the topic <b>candidates</b> that are highly relevant themes of the same real topic; 2) filtering out the less-relevant noise data in the <b>merged</b> topic <b>candidates.</b> Extensive experiments on both single-media and cross-media data sets demonstrate the promising flexibility and effectiveness of our method in detecting topics from cross media. Index Terms—We-media, topic detection, cross-media, multi-modality, fusion, topic recover...|$|R
40|$|We {{have several}} {{different}} commercial Web search engines that are available. It is ex-pected {{that the combination}} of the results from different Web search engines has some impact on the accuracy of question-answering (QA) for Web documents, be-cause the search results are not identical and the combination increases the variety of information source. However, as far as we know, there are no studies on the ef-fect of combining different Web search en-gines on QA. In this paper, we examined the effect of the combination on QA. We investi-gated three different methods to combine search results from different search en-gines in the process of QA. The first one is a conventional method that straightfor-wardly merges search results from differ-ent search engines, then, feeds the unified search result into one QA engine. On the other hand, the second one and third one are our proposal methods that feed each search result from individual search en-gine to a QA engine separately, then <b>merge</b> the answer <b>candidates.</b> The experimental result showed that the methods that <b>merge</b> the answer <b>candidates</b> after QA are more effective than the method that merges the search results before QA. ...|$|R
