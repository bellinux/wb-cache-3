2|14|Public
40|$|AbstractWe {{introduce}} the new families (k,r) -RBC of languages accepted in quasi-realtime by one-way counter automata having k blind counters, of {{which at least}} r are reversal-bounded. It is proved, that these families form a strict and linear hierarchy of semi-AFLs within the the family BLIND=M∩(C− 1) of blind multicounter languages with generator C− 1 ={w∈{a− 1,b− 1 }*∣w−a− 1 =w−b− 1 }. This thereby combines the families BLIND and RBC from [13] to one strict hierarchy and generalizes and sharpens Greibachs results. The strict inclusions between the k-counter families (k,r) -RBC are proved using linear algebra techniques. We also study the language theoretic <b>monadic</b> <b>operation</b> twist [18, 20], {{in connection with the}} semi-AFLs of languages accepted by multicounter and multipushdown acceptors, all restricted to reversal-bounded behavior. It is verified, that the family (k,r) -RBC is twist-closed if and only if r= 0, in which case (k, 0) -RBC=M(C−k), C−k being the k-fold shuffle of disjoint copies of C− 1. We characterize the family M∩(PAL) of languages accepted in quasi-realtime by non-deterministic one-way reversal-bounded multipushdown acceptors as the least twist-closed trio Mtwist(PAL) generated by the set of palindromes PAL={w∈{a,b}*∣w=wrev}...|$|E
40|$|Our goal is {{to present}} a completed, {{semantic}} formalization of the Jeeves privacy language evaluation engine, based on the original Jeeves constraint semantics defined by Yang et al at POPL 12, but sufficiently strong to support a first complete implementation thereof. Specifically, we present and implement a syntactically and semantically completed concrete syntax for Jeeves that meets the example criteria given in the paper. We also present and implement the associated translation to J, but here formulated by a completed and decompositional operational semantic formulation. Finally, we present an enhanced and decompositional, non-substitutional operational semantic formulation {{and implementation of the}} J evaluation engine (the dynamic semantics) with privacy constraints. In particular, we show how implementing the constraints can be defined as a monad, and evaluation can be defined as <b>monadic</b> <b>operation</b> on the constraint environment. The implementations are all completed in Haskell, utilizing its almost one-to-one capability to transparently reflect the underlying semantic reasoning when formalized this way. In practice, we have applied the "literate" program facility of Haskell to this report, a feature that enables the source LATEX to also serve as the source code for the implementation (skipping the report-parts as comment regions). The implementation is published as a github project...|$|E
5000|$|The four {{different}} <b>monadic</b> <b>operations</b> {{result from the}} different binary values for the coefficients. Identity operation requires f(1) = 1 and f(0) = 0, and negation occurs if f(1) = 0 and f(0) = 1. For the 16 dyadic operators, the Boolean polynomials are of the form: ...|$|R
40|$|Abstract. Stream-based {{programming}} {{has been}} around for a long time, but it is typically restricted to static data-flow networks. By introducing first-class streams that implement the monad interface, we can describe arbitrary dynamic networks in an elegant and consistent way using only two extra primitives besides the <b>monadic</b> <b>operations.</b> This paper presents an efficient stream implementation and demonstrates the compositionality of the constructs by mapping them to functions over natural numbers. ...|$|R
40|$|We {{describe}} {{how to perform}} monadic computations over recursive data structures with fine grained control over the evaluation strategy. This solves the issue that {{the definition of a}} recursive monadic function already determines the evaluation strategy due to the necessary sequencing of the <b>monadic</b> <b>operations.</b> We show that compositional data types already provide the structure needed in order to delay monadic computations at any point of the computation. ...|$|R
50|$|There are {{instructions}} to push, calculate, and pop values {{on top of}} this stack; <b>monadic</b> <b>operations</b> (FSQRT, FPTAN etc.) then implicitly address the topmost ST(0) while dyadic operations (FADD, FMUL, FCOM, etc.) implicitly address ST(0) and ST(1). The non-strict stack-model also allows dyadic operations to use ST(0) together with a direct memory operand or with an explicitly specified stack-register, ST(x), in a role similar to a traditional accumulator (a combined destination and left operand). This can also be reversed on an instruction-by-instruction basis with ST(0) as the unmodified operand and ST(x) as the destination. Furthermore, the contents in ST(0) can be exchanged with another stack register using an instruction called FXCH ST(x).|$|R
50|$|Vector {{logic is}} an {{algebraic}} model of elementary logic based on matrix algebra. Vector logic {{assumes that the}} truth values map on vectors, and that the <b>monadic</b> and dyadic <b>operations</b> are executed by matrix operators.|$|R
40|$|Vector {{logic is}} a matrix-vector {{representation}} of the logical calculus inspired in neural network models. In this algebraic formalism, the truth values map on orthonormal Q-dimensional vectors, the <b>monadic</b> <b>operations</b> are represented by square matrices, and the dyadic operations produce rectangular matrices that act on the Kronecker product of the vector truth values. In this formalism, the theorems and tautologies of classical logic are demonstrated using the rules of matrix algebra. In the present work, we analyze a three-valued vector logic that adds to the “yes ” and “no ” vectors, a third “uncertain ” vector that represents the truth value corresponding to undecidable propositions. Fuzziness is produced both via linear combinations of “yes ” and “no ” vectors, and by the supplementary dimension of the logical vector subspace. We describe the basic matrix operators, and we show that for this three-valued vector logic, the modalities “possibility ” and “necessity ” are simple square matrices instead of infinite recursive processes. Finally, we explore the application of this formalism to represent the complex valued operator NOT, and the usefulness of vector logic to understand the powers and limitations of some reversible logical computations. ...|$|R
40|$|It is a {{classical}} result of Mortimer that L², first-order logic with two variables, is decidable for satisfiability. We show that going beyond L² by adding {{any one of}} the following leads to an undecidable logic: ffl very weak forms of recursion, viz. (i) transitive closure <b>operations</b> (ii) (restricted) <b>monadic</b> fixed-point <b>operations</b> ffl weak access to cardinalities, through the Hartig (or equicardinality) quantifier ffl a choice construct known as Hilbert's "-operator. In fact all these extensions of L² prove to be undecidable both for satisfiability, and for satisfiability in finite models. Moreover most of them are hard for Σ 1 1, the first level of the analytical hierachy, and thus have a much higher degree of undecidability than first-order logic...|$|R
2500|$|Early IBM APL interpreters for IBM 360 and IBM 370 {{hardware}} implemented {{their own}} multi-user management instead {{of relying on}} the host services, thus they were timesharing systems in their own right. First introduced in 1966, the APL\360 system was a multi-user interpreter. The ability to programmatically communicate with the operating system for information and setting interpreter system variables was done through special privileged [...] "I-beam" [...] functions, using both <b>monadic</b> and dyadic <b>operations.</b>|$|R
40|$|We {{describe}} a technique for embedding interpreters in statically-typed functional programs, by which (higher-order) {{values in the}} interpreting language may be embedded in the interpreted language and values from the interpreted language may be projected back into the interpreting one. The idea is introduced with SML code for the command-line interface to a tactical theorem prover applet and then extended to languages with recursive types and applied to elementary meta-programming. We then show how the method combines with Filinski's continuation-based <b>monadic</b> reflection <b>operations</b> to define an `extensional' version of the call-by-value monadic translation and hence to allow values to be mapped bidirectionally between the levels of an interpreter for a functional language parameterized by an arbitrary monad. Finally, we show how SML functions may be embedded into, and projected from, an interpreter for an asynchronous pi-calculus via an `extensional' variant of a standard translation from lambda into pi...|$|R
40|$|Drawing {{together}} {{two lines of}} research (that done in type-safe region-based memory management and that done in monadic encapsuation of effects), we give a type-preserving translation from {{a variation of the}} region calculus of Tofte and Talpin into an extension of System F augmented with <b>monadic</b> types and <b>operations.</b> Our source language is a novel region calculus, dubbed the Single Effect Calculus, in which sets of effects are specified by a single region representing an upper bound on the set. Our target language is F RGN, which provides an encapsulation operator whose parametric type ensures that regions (and values allocated therein) are neither accessible nor visible outside the appropriate scope. ...|$|R
40|$|The term UniMath refers both to {{a formal}} system for {{mathematics}}, {{as well as}} a computer-checked library of mathematics formalized in that system. The UniMath system is a core dependent type theory, augmented by the univalence axiom. The system is kept as small as possible in order to ease verification of it - in particular, general inductive types {{are not part of the}} system. In this work, we partially remedy the lack of inductive types by constructing some datatypes and their associated induction principles from other type constructors. This involves a formalization of a category-theoretic result on the construction of initial algebras, {{as well as a}} mechanism to conveniently use the datatypes obtained. We also connect this construction to a previous formalization of substitution for languages with variable binding. Altogether, we construct a framework that allows us to concisely specify, via a simple notion of binding signature, a language with variable binding. From such a specification we obtain the datatype of terms of that language, equipped with a certified <b>monadic</b> substitution <b>operation</b> and a suitable recursion scheme. Using this we formalize the untyped lambda calculus and the raw syntax of Martin-Löf type theory. Comment: 30 page...|$|R
40|$|Abstract: Almost {{ten years}} ago, Ralf Hinze {{has written a}} {{functional}} pearl on how to derive backtracking functionality for the purely functional programming language Haskell. In these notes, we show how {{to arrive at the}} efficient, two-continuation based backtracking monad derived by Hinze starting from an intuitive inefficient implementation that we subsequently refine using well known program transformations. It turns out that the technique can be used to build monads for non-determinism from modular, independent parts which gives rise to various new implementations. Specifically, we show how the presented approach can be applied to obtain new implementations of breadth-first search and iterative deepening depth-first search. We present a new method to implement monads for non-determinism in Haskell. With our approach, their implementation is split into two independent parts: one is identical for every implementation, the other captures the essence of the employed search strategy. The part that is identical for every implementation includes the <b>monadic</b> bind <b>operation,</b> which {{does not have to be}} reimplemented for every non-determinism monad. Programmers only need to define notions of failure and choice and can wrap these definitions in a parametrised type to obtain a monad for non-determinism. As the implementation of monadic bind is usually the most involved part in the implementation of non-determinism monads, our approach gives rise to simpler implementations of search strategies that required a more complex implementation before. For example, difference lists are a natural choice to represent non-deterministic computations efficiently but do not give rise to a natural implementation of monadic bind. We show that wrapping the type for difference lists in a continuation monad results in the well-known twocontinuation-based backtracking monad derived by Hinze in his influential pearl [Hin 00]. Wrapping different base types—which both lack a natural implementation of monadic bind—we obtain novel implementations of breadth-first search and iterative deepening depth-first search. Our main contribution is the method used to obtain these strategies from modular parts, not the simplified implementation of established search strategies...|$|R
40|$|This thesis {{presents}} a {{critical analysis of}} normalisation by evaluation as a technique for speeding up compilation of typed functional programming languages. Our investigation focuses on the SML. NET compiler and its typed intermediate language MIL. We implement and measure the performance of normalisation by evaluation for MIL {{across a range of}} benchmarks. Taking a different approach, we also implement and measure the performance of a graph-based shrinking reductions algorithm for SML. NET. MIL is based on Moggi’s computational metalanguage. As a stepping stone to normalisation by evaluation, we investigate strong normalisation of the computational metalanguage by introducing an extension of Girard-Tait reducibility. Inspired by previous work on local state and parametric polymorphism, we define reducibility for continuations and more generally reducibility for frame stacks. First we prove strong normalistion for the computational metalanguage. Then we extend that proof to include features of MIL such as sums and exceptions. Taking an incremental approach, we construct a collection of increasingly sophisticated normalisation by evaluation algorithms, culminating in a range of normalisation algorithms for MIL. Congruence rules and alpha-rules are captured by a compositional parameterised semantics. Defunctionalisation is used to eliminate eta-rules. Normalisation by evaluation for the computational metalanguage is introduced using a monadic semantics. Variants in which the monadic effects are made explicit, using either state or control operators, are also considered. Previous implementations of normalisation by evaluation with sums have relied on continuation-passing-syle or control operators. We present a new algorithm which instead uses a single reference cell and a zipper structure. This suggests a possible alternative way of implementing Filinski’s <b>monadic</b> reflection <b>operations.</b> In order to obtain benchmark results without having to take into account all of the features of MIL, we implement two different techniques for eliding language constructs. The first is not semantics-preserving, but is effective for assessing the efficiency of normalisation by evaluation algorithms. The second is semantics-preserving, but less flexible. In common with many intermediate languages, but unlike the computational metalanguage, MIL requires all non-atomic values to be named. We use either control operators or state to ensure each non-atomic value is named. We assess our normalisation by evaluation algorithms by comparing them with a spectrum of progressively more optimised, rewriting-based normalisation algorithms. The SML. NET front-end is used to generate MIL code from ML programs, including the SML. NET compiler itself. Each algorithm is then applied to the generated MIL code. Normalisation by evaluation always performs faster than the most naıve algorithms— often by orders of magnitude. Some of the algorithms are slightly faster than normalisation by evaluation. Closer inspection reveals that these algorithms are in fact defunctionalised versions of normalisation by evaluation algorithms. Our normalisation by evaluation algorithms perform unrestricted inlining of functions. Unrestricted inlining can lead to a super-exponential blow-up in the size of target code with respect to the source. Furthermore, the worst-case complexity of compilation with unrestricted inlining is non-elementary {{in the size of the}} source code. SML. NET alleviates both problems by using a restricted form of normalisation based on Appel and Jim’s shrinking reductions. The original algorithm is quadratic in the worst case. Using a graph-based representation for terms we implement a compositional linear algorithm. This speeds up the time taken to perform shrinking reductions by up to a factor of fourteen, which leads to an improvement of up to forty percent in total compile time. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R

