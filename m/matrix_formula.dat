62|363|Public
2500|$|... is an {{immediate}} {{consequence of the}} <b>matrix</b> <b>formula</b> (found by considering the determinants of the matrices {{on the left and}} right sides of the <b>matrix</b> <b>formula).</b>|$|E
2500|$|These {{last two}} identities provide {{a way to}} compute Fibonacci numbers recursively in [...] {{arithmetic}} operations and in time , where [...] {{is the time for}} the multiplication of two numbers of n digits. This matches the time for computing the nth Fibonacci number from the closed-form <b>matrix</b> <b>formula,</b> but with fewer redundant steps if one avoids recomputing an already computed Fibonacci number (recursion with memoization).|$|E
50|$|Many identities can {{be derived}} or proven from these definitions; for {{instance}} an identity analogous to Cassini's identity for Fibonacci numbers,is an immediate consequence of the <b>matrix</b> <b>formula</b> (found by considering the determinants of the matrices {{on the left and}} right sides of the <b>matrix</b> <b>formula).</b>|$|E
30|$|Some useful <b>matrix</b> <b>formulae</b> are {{recalled}} in Appendix 1.|$|R
40|$|Contractions of Lie algebras are {{combined}} with the classical matrix method of Gel’fand to obtain <b>matrix</b> <b>formulae</b> for the Casimir operators of inhomogeneous Lie algebras. The method is presented for the inhomogeneous pseudounitary Lie algebras Iu(p, q). This procedure is extended to contractions of Iu(p, q) isomorphic to an extension by a derivation of the inhomogeneous special pseudo-unitary Lie algebras Isu(p − 1, q), providing an additional analytical method to obtain their invariants. Further, <b>matrix</b> <b>formulae</b> for the invariants of other inhomogeneous Lie algebras are presented...|$|R
40|$|Abstract. Contractions of Lie algebras are {{combined}} with the classical matrix method of Gel’fand to obtain <b>matrix</b> <b>formulae</b> for the Casimir operators of inhomogeneous Lie algebras. The method is presented for the inhomogeneous pseudounitary Lie algebras Iu(p, q). This procedure is extended to contractions of Iu(p, q) isomorphic to an extension by a derivation of the inhomogeneous special pseudo-unitary Lie algebras Isu(p − 1, q), providing an additional analytical method to obtain their invariants. Further, <b>matrix</b> <b>formulae</b> for the invariants of other inhomogeneous Lie algebras are presented. PACS numbers: 02. 20 Sv 2 1...|$|R
5000|$|It is {{possible}} to calculate the optimal rotation [...] based on the <b>matrix</b> <b>formula</b> ...|$|E
50|$|Multi-access keys may {{be printed}} in various way (tabular, <b>matrix,</b> <b>formula</b> style, etc.) but are more {{commonly}} used as computer-aided, interactive keys.|$|E
5000|$|... {{where the}} wavevector k is {{measured}} from the Dirac points (the zero of energy is chosen here {{to coincide with}} the Dirac points). The equation uses a pseudospin <b>matrix</b> <b>formula</b> that describes two sublattices of the honeycomb lattice.|$|E
40|$|AbstractCombining Fourier series {{expansion}} with recursive <b>matrix</b> <b>formulas,</b> new reliable algorithms {{to compute the}} periodic, non-negative, definite stabilizing solutions of the periodic Riccati and Lyapunov matrix differential equations are proposed in this paper. First, periodic coefficients are expanded in terms of Fourier series to solve the time-varying periodic Riccati differential equation, and the state transition matrix of the associated Hamiltonian system is evaluated precisely with sine and cosine series. By introducing the Riccati transformation method, recursive <b>matrix</b> <b>formulas</b> are derived to solve the periodic Riccati differential equation, which is composed of four blocks of the state transition matrix. Second, two numerical sub-methods for solving Lyapunov differential equations with time-varying periodic coefficients are proposed, both based on Fourier {{series expansion}} and the recursive <b>matrix</b> <b>formulas.</b> The former algorithm is a dimension expanding method, and the latter one uses the solutions of the homogeneous periodic Riccati differential equations. Finally, the efficiency and reliability of the proposed algorithms are demonstrated by four numerical examples...|$|R
40|$|This paper {{concerns}} cluster algebras with principal coefficients A(S,M) {{associated to}} bordered surfaces (S,M), {{and is a}} companion to a concurrent work of the authors with Schiffler [MSW 2]. Given any (generalized) arc or loop in the surface [...] with or without self-intersections [...] we associate an element of (the fraction field of) A(S,M), using products of elements of PSL_ 2 (R). We give a direct proof that our <b>matrix</b> <b>formulas</b> for arcs and loops agree with the combinatorial formulas for arcs and loops in terms of matchings, which were given in [MSW, MSW 2]. Finally, we use our <b>matrix</b> <b>formulas</b> to prove skein relations for the cluster algebra elements associated to arcs and loops. Our <b>matrix</b> <b>formulas</b> and skein relations generalize prior work of Fock and Goncharov [FG 1, FG 2, FG 3], {{who worked in the}} coefficient-free case. The results of this paper will be used in [MSW 2] in order to show that certain collections of arcs and loops comprise a vector-space basis for A(S,M). Comment: 35 pages, lots of picture...|$|R
40|$|This article surveys {{efficient}} methods {{based on}} the sparse resultant for computing all isolated solutions of an arbitrary system of n polynomials in n unknowns. In particular, we construct <b>matrix</b> <b>formulae</b> which yield nontrivial multiples of the resultant thus reducing root-finding to the eigendecomposition of a square matrix...|$|R
50|$|In linear algebra, a Block LU {{decomposition}} is {{a matrix}} decomposition of a block matrix into a lower block triangular matrix L and an upper block triangular matrix U. This decomposition {{is used in}} numerical analysis to reduce {{the complexity of the}} block <b>matrix</b> <b>formula.</b>|$|E
5000|$|These {{last two}} identities provide {{a way to}} compute Fibonacci numbers recursively in [...] {{arithmetic}} operations and in time , where [...] {{is the time for}} the multiplication of two numbers of n digits. This matches the time for computing the nth Fibonacci number from the closed-form <b>matrix</b> <b>formula,</b> but with fewer redundant steps if one avoids recomputing an already computed Fibonacci number (recursion with memoization).|$|E
5000|$|After modifications, the {{decomposition}} satisfies [...] is analytic and invertible on {{the lower}} half plane. To extend analyticity to the upper half plane we need this key observation: Given a rational matrix [...] who is analytic in the lower half plane and nonsingular in the lower half plane, we have [...] is analytic and nonsingular in the lower half plane. The analyticity follows from the adjugate <b>matrix</b> <b>formula</b> (since both the entries of [...] and [...] are analytic {{on the lower}} half plane). The nonsingularity follows from which can only have zeroes at places where [...] had poles. The determinant of a rational polynomial matrix can only have poles where its entries have poles, so [...] has no poles in the lower half plane.|$|E
40|$|For an {{arbitrary}} subset A of the finite state space 5 of a Markov chain the so–called embedded matrix PA is introduced. By {{use of these}} <b>matrices</b> <b>formulas</b> expressing all kinds of probabilities can be written down almost automatically, and calculated very easily on a computer. Also derivations can be given very systematically...|$|R
40|$|Standard life {{contingency}} formulas are {{shown to have}} matrix analogues. The derivation of these multidimensional forms permits simple solution to multiple contingency problems, including moves {{in and out of}} employment, insurance, marriage, sickness, and retirement. Awkward and inaccurate approximations now commonly used can thus be replaced by <b>matrix</b> <b>formulas</b> readily manipulated by computer...|$|R
5000|$|... where [...] are {{matrices}} {{with elements}} Eij, xij, [...] respectively. If all elements in these matrices would be commutative then clearly [...] The Capelli identity shows that despite noncommutativity {{there exists a}} [...] "quantization" [...] of the formula above. The only price for the noncommutativity is a small correction: [...] on the left hand side. For generic noncommutative <b>matrices</b> <b>formulas</b> like ...|$|R
3000|$|... [...]) is the Kronecker’s delta {{function}} from Equation 6. The {{left side of}} the Equation 7 is a summation series that iterates through an edge list and increments for each pair of the same class. The right side of Equation 7 is the <b>matrix</b> <b>formula</b> which iterates through an adjacency matrix and increments the same way. The one-half fraction from the <b>matrix</b> <b>formula</b> is there to remove the double counting of pairs.|$|E
40|$|The {{literature}} of formula allocation has several central themes which the <b>matrix</b> <b>formula</b> described here addresses. Most important, formulas have almost uni-versally {{failed to provide}} a mechanism to distribute funds for serials as well as books. The <b>matrix</b> <b>formula</b> allocates funds for monographs and serials based on disciplinary needs and publishing patterns. It also provides a method for determining the variables which best represent institutional goals, normalizing them and explicitly determining the percent of funds allocated by the individual variable. These features are great advantages in dealing fairly with the difficult problems of allocating scarce resources. Finally, the article discusses the appro-priate limits formulas may have as allocation tools. bout ten years ago a colleague responded {{to one of my}} en-thusiastic discussions of what I will call the <b>matrix</b> <b>formula</b> with a comment that "all formulas are t...|$|E
40|$|We {{prove the}} {{determinant}} connectivity <b>matrix</b> <b>formula.</b> Mathematically, the proof introduces novel techniques {{based on an}} algebraic approach and connectivity properties. Although {{this is the second}} part of a previous paper and has its original motivation there, the paper is self contained and the result is interesting in itself...|$|E
40|$|Abstract. This paper {{introduces}} {{a method to}} generate efficient vectorized implementations of small stride permutations using only vector load and vector shuffle instructions. These permutations are crucial for highperformance numerical kernels including the fast Fourier transform. Our generator takes as input only the specification of the target platform’s SIMD vector ISA and the desired permutation. The basic idea underlying our generator is to model vector instructions as matrices and sequences of vector instructions as <b>matrix</b> <b>formulas</b> using the Kronecker product formalism. We design a rewriting system and a search mechanism that applies matrix identities to generate those <b>matrix</b> <b>formulas</b> that have vector structure and minimize a cost measure that we define. The formula is then translated into the actual vector program for the specified permutation. For three important classes of permutations, we show that our method yields a solution with the minimal number of vector shuffles. Inserting into a fast Fourier transform yields a significant speedup. ...|$|R
40|$|A projection-based {{solution}} to the symplectic group state labeling problem is presented. The approach yields a nonorthogonal Gel'fand–Tsetlin basis for the irreducible representations of Sp(2 n). A method for evaluating the corresponding overlap coefficients is discussed. The action of the Sp(2 n) generators, in the basis obtained, is determined and some <b>matrix</b> element <b>formulas</b> are derived. The results obtained are comparable to the <b>matrix</b> element <b>formulas</b> for O(n) and U(n) ...|$|R
40|$|We derive <b>matrix</b> <b>formulae</b> {{in closed}} {{form for the}} {{unconditional}} third and fourth moments of a broad class of vector autoregressive time series with regime switching. First and second moments are well-known. New measures of multivariate skewness and kurtosis are introduced and basic properties are investigated. The knowledge of series level, variation, co-movements, skewness and kurtosis are useful to support model interpretation in real data application. Numerical examples complete the paper...|$|R
40|$|In {{this paper}} a {{possible}} application is presented {{of a general}} rank- 1 <b>matrix</b> <b>formula</b> to the eigenvalue sensitivity evaluation which reduces the sensitivity expressions to elegant, very fast and recursive formulas with substantial savings in computer resources. The rank- 1 <b>matrix</b> <b>formula</b> allows for re-arranging terms in multi-product forms involving vectors and matrices. The formula is applicable to rank- 1 matrices of special structures which may constitute derivatives of the system state matrix with respect to parameters of interest. In such cases, {{the use of the}} rank- 1 formula yields exact non-approximate solutions which are identical to those obtained by other conventional formulas. The applicability of the rank- 1 formula is believed to cover a wide variety of practical engineering systems pertaining to sound and vibration. © 1997 Academic Press Limited...|$|E
40|$|We give {{a general}} <b>matrix</b> <b>formula</b> for {{computing}} the bias {{of the exact}} unconditional maximum likelihood estimate in ARMA models, with known and unknown mean, up to order 1 /n, where n is {{the length of the}} series. Some illustrative examples are presented. ARMA model bias correction maximum likelihood estimate...|$|E
40|$|In this work, {{we study}} {{a version of}} the general {{question}} of how well a Haar-distributed orthogonal matrix can be approximated by a random Gaussian matrix. Here, we consider a Gaussian random <b>matrix</b> (<b>Formula</b> presented.) of order n and apply to it the Gram–Schmidt orthonormalization procedure by columns to obtain a Haar-distributed orthogonal <b>matrix</b> (<b>Formula</b> presented.). If (Formula presented.) denotes the vector formed by the first m-coordinates of the ith row of (Formula presented.) and (Formula presented.), our main result shows that the Euclidean norm of (Formula presented.) converges exponentially fast to (Formula presented.), up to negligible terms. To show the extent of this result, we use it to study the convergence of the supremum norm (Formula presented.) and we find a coupling that improves by a factor (Formula presented.) the recently proved best known upper bound on (Formula presented.). Our main result also has applications in Quantum Information Theory...|$|E
5000|$|With these solved for (by {{using the}} Cramer 2×2 <b>matrix</b> inverse <b>formula),</b> the new forward and {{backward}} vectors are: ...|$|R
40|$|A {{rigorous}} asymptotic {{theory for}} Pearson residuals in generalized linear models {{is not yet}} available. We give <b>matrix</b> <b>formulae</b> of order n- 1, where n is the sample size, {{for the first two}} moments of these residuals. The formulae are applicable to many regression models in common use. We suggest adjusted Pearson residuals in these models with approximately zero mean and unit variance. Exponential family Generalized linear model Link function Log-linear model Pearson residual...|$|R
40|$|We {{present a}} source-to-source {{compiler}} that processes <b>matrix</b> <b>formulae</b> {{in the form}} of Kronecker product factorizations. The Kronecker product notation allows for simple expressions of algorithms such as Walsh-Hadamard, Haar, Slant, Hartley, and FFTs as well as transpositions and wavelet transforms. The compiler is based on a set of term rewriting rules that translate high level matrix descriptions into parallel and sequential loops and assignment statements. We provide back-end translators for FORTRAN, FORTRAN- 90, C and Matlab. ...|$|R
40|$|This paper {{presents}} a general rank- 1 <b>matrix</b> <b>formula</b> {{which allows for}} proper rearrangement of individual terms in multiproduct forms involving vectors and matrices. A far-reaching application of the new <b>matrix</b> <b>formula</b> to eigenvalue sensitivity evaluation {{is presented in the}} paper. Such an application reduces the sensitivity expressions to elegant, very fast and recursive forms with substantial savings in computer resources. The formula is applicable to rank- 1 matrices of special structures which may constitute derivatives of the system state matrix, which is widely used in control system applications, with respect to various parameters of interest. In such cases, the use of the rank- 1 formula yields exact non-approximate solutions which are identical to those obtained by other conventional formulas. The applicability of the rank- 1 formula is believed to cover a wide variety of practical engineering systems pertaining to control and stability. © 1998 John Wiley & Sons, Ltd...|$|E
40|$|This paper {{introduces}} a visual framework in computational environment for displaying multi-region, multi-sector classical models, associated with authors such Isard, Chenery, Moses, Leontief, Riefler and Tiebout. Based on {{the quantity and}} nature of trade data of each model, different conditions are imposed upon the matrix of trade coefficients (Formula presented.) which result in various matrix partitioning schemes. <b>Matrix</b> (<b>Formula</b> presented.) illustrates the interactions among interregional and intersectoral economic activities and is considered a key component in input-output modeling. Using MATHEMATICA as software tool we introduce a method to construct and present <b>matrix</b> (<b>Formula</b> presented.) both graphically, with static and dynamic images, and analytically. The output produced enables understanding and/or teaching theoretical trade hypotheses. Furthermore, our computational approach produces random, structured matrices of trade coefficients, which makes possible infinite computer experiments with interregional input-output models of any size, without typing in input. The computer codes are fully presented and can be reproduced {{as they are in}} computational-based research practice and education. © 2014 Springer Science+Business Media New York...|$|E
40|$|AbstractWe give {{a general}} <b>matrix</b> <b>formula</b> for {{computing}} the second-order skewness of maximum likelihood estimators. The formula was firstly {{presented in a}} tensorial version by Bowman and Shenton (1998). Our matrix formulation has numerical advantages, since it requires only simple operations on matrices and vectors. We apply the second-order skewness formula to a normal model with a generalized parametrization and to an ARMA model...|$|E
40|$|Many {{applications}} that involve inference {{and learning in}} signal processing, communication and artificial intelligence can be cast into a graph framework. Factor graphs are a type of network that can be studied and solved by propagating belief messages with the sum/product algorithm. In this paper we provide explicit <b>matrix</b> <b>formulas</b> for inference and learning in finite alphabet Forney-style factor graphs, with the precise intent of allowing rapid prototyping of arbitrary topologies in standard software like MATLAB...|$|R
40|$|In this paper, we give {{a general}} {{recursive}} formula for E(∏i Tr{(WΣ- 1) mi}), where W~Wp(∑; n) denotes a real Wishart <b>matrix.</b> <b>Formulas</b> for xed n; p {{are presented as}} well as asymptotic versions when n/p→c, when n,p→∞ i. e., when the so called Kolmogorov condition holds. Finally, we show application of the asymptotic moment relation when deriving moments for the Marchenko-Pastur distribution (free Poisson law). A numerical illustration using implementation of the main result is also performed...|$|R
40|$|This paper {{provides}} general <b>matrix</b> <b>formulas</b> for computing {{the score}} function, the (expected and observed) Fisher {{information and the}} ∆ matrices (required {{for the assessment of}} local influence) for a quite general model which includes the one proposed by Russo et al. (2009). Additionally, we also present an expression for the generalized leverage. The matrix formulation has a considerable advantage, since although the complexity of the postulated model, all general formulas are compact, clear and have nice forms...|$|R
