166|4944|Public
50|$|Single and <b>multithread</b> modes: if a {{computer}} supports multi-threading, video creation process is performed faster in <b>multithread</b> mode, {{especially on a}} multi-core system.|$|E
50|$|Support <b>Multithread</b> applications.|$|E
5000|$|Valgrind runs {{programs}} on a virtual processor and can detect memory errors (e.g., misuse of malloc and free) and race conditions in <b>multithread</b> programs.|$|E
5000|$|Interleaved multithreading: Interleaved {{issue of}} {{multiple}} instructions from different threads, {{also referred to}} as temporal <b>multithreading.</b> It can be further divided into fine-grained <b>multithreading</b> or coarse-grained <b>multithreading</b> depending on the frequency of interleaved issues. Fine-grained multithreading—such as in a barrel processor—issues instructions for different threads after every cycle, while coarse-grained <b>multithreading</b> only switches to issue instructions from another thread when the current executing thread causes some long latency events (like page fault etc.). Coarse-grain <b>multithreading</b> is more common for less context switch between threads. For example, Intel's Montecito processor uses coarse-grained <b>multithreading,</b> while Sun's UltraSPARC T1 uses fine-grained <b>multithreading.</b> For those processors that have only one pipeline per core, interleaved <b>multithreading</b> is the only possible way, because it can issue at most one instruction per cycle.|$|R
5000|$|Simultaneous <b>multithreading,</b> another {{implementation}} of hardware <b>multithreading</b> ...|$|R
50|$|Temporal <b>multithreading</b> {{is one of}} the {{two main}} forms of <b>multithreading</b> that can be {{implemented}} on computer processor hardware, the other being simultaneous <b>multithreading.</b> The distinguishing difference between the two forms is the maximum number of concurrent threads that can execute in any given pipeline stage in a given cycle. In temporal <b>multithreading</b> the number is one, while in simultaneous <b>multithreading</b> the number is greater than one. Some authors use the term super-threading synonymously.|$|R
5000|$|Concurrent testing: run {{tests in}} {{arbitrarily}} big thread pools with various policies available (all methods {{in their own}} thread, one thread per test class, etc.), and test whether the code is <b>multithread</b> safe.|$|E
50|$|In a <b>multithread</b> environment, insert, delete and query are {{mutually}} exclusive. However, instead of locking the whole data structure, a sub-range of bins may be locked. Detailed performance analysis {{should be done}} to justify the overhead.|$|E
50|$|All are bundled with a {{graphical}} debugger and {{an integrated}} development environment. Single thread and parallel <b>multithread</b> support {{is controlled by}} the user and includes five optimization levels, OpenMP and other advanced software engineering, and Speed Math levels 0 through 9.|$|E
40|$|This paper {{examines}} simultaneous <b>multithreading,</b> {{a technique}} permitting several independent threads to issue instructions to a superscalar 's multiple functional units {{in a single}} cycle. We present several models of simultaneous <b>multithreading</b> and compare them with alternative organizations: a wide superscalar, a fine-grain <b>multithreaded</b> processor, and single-chip, multiple-issue multiprocessing architectures. Our results show that both (single-threaded) superscalar and fine-grain <b>multithreaded</b> architectures are limited {{in their ability to}} utilize the resources of a wide-issue processor. Simultaneous <b>multithreading</b> has the potential to achieve 4 times the throughput of a superscalar, and double that of fine-grain <b>multithreading.</b> We evaluate several cache configurations made possible by this type of organization and evaluate tradeoffs between them. We also show that simultaneous <b>multithreading</b> is an attractive alternative to single-chip multiprocessor...|$|R
40|$|Modern {{programming}} {{languages and}} operating systems provide software mechanisms {{to support the}} execution of <b>multithreaded</b> applications. These <b>multithreaded</b> applications are executed, commonly, on high speed superscalar processors that in general do not provide special support to manage multiple contexts. In this paper the effect that <b>multithreading</b> has {{on the performance of}} modern superscalar processors is studied. A simulation environment, designed specifically, to trace the execution of <b>multithreaded</b> programs is described. Simulation results that show the dynamic behavior of software <b>multithreading</b> {{and its impact on the}} performance of a superscalar processor are presented. 1 Introduction <b>Multithreading</b> is being used extensively as a software technique to improve the performance and response time of client-server applications. Additionally, modern programming languages like Java [Flanagan, 1997] have included support for <b>multithreading</b> as part of the language. In appl [...] ...|$|R
50|$|<b>Multithreading</b> - <b>Multithreading</b> is {{supported}} {{on top of}} pthreads. Scheme-level API conforms to SRFI-18.|$|R
50|$|As {{embedded}} file systems typically require low memory usage, Fusion is compact. The memory is also fully dynamic, not a read only ROM-style file system. According to the vendor's web site, it is <b>multithread</b> capable and FAT12/FAT16/FAT32 compatible. It also features wear leveling, post error correction and data compression.|$|E
5000|$|ARM has an {{extensive}} processor core debug architecture (CoreSight) {{that started with}} EmbeddedICE (a debug facility available on most ARM cores), and now includes many additional components such as an ETM (Embedded Trace Macrocell), with a high speed trace port, supporting multi-core and <b>multithread</b> tracing. Note that tracing is non-invasive; systems {{do not need to}} stop operating to be traced. (However, trace data is too voluminous to use JTAG as more than a trace control channel.) ...|$|E
50|$|In {{contrast}} to MVC, PAC {{is used as}} a hierarchical structure of agents, each consisting of a triad of presentation, abstraction and control parts. The agents (or triads) communicate with each other only through the control part of each triad. It also differs from MVC in that within each triad, it completely insulates the presentation (view in MVC) and the abstraction (model in MVC). This provides the option to separately <b>multithread</b> the model and view which can give the user experience of very short program start times, as the user interface (presentation) can be shown before the abstraction has fully initialized.|$|E
5000|$|... {{coarse-grained}} <b>multithreaded</b> processor IP {{core and}} later the first fine-grained <b>multithreaded</b> processor IP core ...|$|R
40|$|In {{this paper}} we propose a synergy of {{processing}} on parallel processor arrays (systolic or SIMD) and <b>multithreading,</b> termed <b>multithreaded</b> systolic computation. The <b>multithreaded</b> systolic computation principle is demonstrated on a programmable systolic array executing a set of linear algebra algorithms. We demonstrate that <b>multithreaded</b> systolic computation can provide throughput improvements that asymptotically approach the number of simultaneously executable threads...|$|R
50|$|Intel Itanium Montecito used {{coarse-grained}} <b>multithreading</b> and Tukwila and newer use 2-way SMT (with Dual-domain <b>multithreading).</b>|$|R
5000|$|Apple has {{then decided}} {{to create their own}} protocol, {{imposing}} all parameters related to synchronization like the sampling frequency. This session protocol is called [...] "AppleMIDI" [...] in Wireshark software. Session management with AppleMIDI protocol requires two UDP ports, the first one is called [...] "Control Port", the second one is called [...] "Data Port". When used within a <b>multithread</b> implementation, only the Data port requires a [...] "real-time" [...] thread, the other port can be controlled by a normal priority thread. These two ports must be located at two consecutive location (n / n+1), the first one can be any of the 65536 possible ports.|$|E
5000|$|Bidule uses a modular {{structure}} {{based on a}} patch cord metaphor much like AudioMulch, Reaktor, Pure Data, and Max/MSP. Individual modules are called bidules (the Plogue web site states that the word [...] "Bidule" [...] is French for [...] "thingy" [...] or [...] "gadget"). A set of bidules and connections is called a layout, and sub-patches called groups can be built within layouts and saved for use elsewhere. The program features real time audio, MIDI, Open Sound Control (OSC), and spectral processing. With other audio DAW software ReWire, Bidule can run as a ReWire mixer or device. Bidule can run standalone or as a VST, VSTi or AU plugin, and can host the same. ASIO/CoreAudio is supported for low latency audio. Bidule can use <b>multithread</b> processing, {{and there is a}} beta build for discrete processing. Parameters can be linked to MIDI or OSC input or to other module parameters. Over one hundred modules and groups come with the software, including modules that can perform high-level math on signals.|$|E
40|$|<b>Multithread</b> {{programming}} is widely adopted in novel embedded system applications {{due to its}} high perfor-mance and flexibility. This article addresses compiler optimization for reducing the power consumption of <b>multithread</b> programs. A traditional compiler employs energy management techniques that analyze compo-nent usage in control-flow graphs {{with a focus on}} single-thread programs. In this environment the leakage power can be controlled by inserting on and off instructions based on component usage information generated by flow equations. However, these methods cannot be directly extended to a <b>multithread</b> environment due to concurrent execution issues. This article presents a <b>multithread</b> power-gating framework composed of <b>multithread</b> power-gating anal-ysis (MTPGA) and predicated power-gating (PPG) energy management mechanisms for reducing the leakage power when executing <b>multithread</b> programs on simultaneous multithreading (SMT) machines. Our mul-tithread programming model is based on hierarchical bulk-synchronous parallel (BSP) models. Based on a <b>multithread</b> component analysis with dataflow equations, our MTPGA framework estimates the energy usage of <b>multithread</b> programs and inserts PPG operations as power controls for energy management. We performed experiments by incorporating our power optimization framework into SUIF compiler tools and by simulating the energy consumption with a post-estimated SMT simulator based on Wattch toolkits. Th...|$|E
5000|$|Classic. 4K, M14K, 24K, 34K, 74K, 1004K (multicore and <b>multithreaded)</b> and 1074K (superscalar and <b>multithreaded)</b> families.|$|R
40|$|In {{this paper}} we propose a synergy of {{processing}} on parallel processor arrays (systolic or SIMD) and <b>multithreading</b> named <b>multithreaded</b> systolic computation. <b>Multithreaded</b> systolic computation enables simultaneous execution of independent algorithm data sets, or even different algorithms, on systolic array level...|$|R
40|$|Abstract — Nowadays, <b>multithreaded</b> {{architectures}} {{are becoming}} more and more popular. In fact, many processor vendors have already shipped processors with <b>multithreaded</b> features. Regardless of this push on <b>multithreaded</b> processors, still today there is not a clear procedure that defines how to measure the behavior of a <b>multithreaded</b> processor. This paper presents FAME, a new evaluation methodology aimed to fairly measure the performance of <b>multithreaded</b> processors. FAME can be used in conjunction with any of the metrics proposed for <b>multithreaded</b> processors like IPC throughput, weighted speedup, etc. The idea behind FAME is to reexecute all threads in a <b>multithreaded</b> workload until all of them are fairly represented in the final measurements taken from the workload. Then these measurements will be combined with the corresponding metric to obtain a final value that quantifies the performance of the processor under consideration. I...|$|R
40|$|The main aim of {{this study}} is to promote the {{efficiency}} of a control system using a <b>multithread</b> digital control design. In this system, the management of a computer`s input and output information is handled appropriately by the program language. The <b>multithread</b> digital control design is used in the robotic arm`s tracking system. The advantage of this <b>multithread</b> digital control design is to activate each procedure running simultaneously when the transient overload of the information`s input and output in the control system occurs. Therefore, the time run in the <b>multithread</b> system will be shorter than that run in a traditional single thread system in which each procedure is lined up for running. In this study, case studies of <b>multithread</b> application used in image tracking and robot control are introduced. The results reveal that the speed of the tracking system can be improved by using the <b>multithread</b> technique under an immediate procedure plan...|$|E
40|$|Abstract. The web data {{collection}} {{is the process}} of collecting the semi-structured, large-scale and redundant data which include web content, web structure and web usage in the web by the crawler and it is often used for the information extraction, information retrieval, search engine and web data mining. In this paper, the web {{data collection}} principle is introduced and some related topics are discussed such as page download, coding problem, updated strategy, static and dynamic page. The <b>multithread</b> technology is described and <b>multithread</b> mode for the web data collection is proposed. The web data collection with <b>multithread</b> can get better resource utilization, better average response time and better performance...|$|E
40|$|Nowadays, <b>multithread</b> {{architectures}} for PCs (multi-core CPUs and GPUs), {{and game}} consoles (as Microsoft Xbox 360 and Sony Playstation 3) is a trend. Hence, single thread games loops {{will not get}} the best performance on such architectures. For this reason, <b>multithread</b> game loops that take advantage of such architectures are gaining importance. There {{are a lot of}} <b>multithread</b> game loops {{that can be used in}} order to achieve better performance in a game, but they can not be adapted for different architectures. This paper presents a new architecture for game loops that can detect and ana-lyze the user hardware and adapts itself to a specific game loop that can achieve the best performance for that hardware...|$|E
40|$|Thesis (Ph. D.) [...] University of Washington, 1996 This {{dissertation}} examines simultaneous <b>multithreading,</b> {{a technique}} permitting several independent threads to issue instructions to a superscalar processor's functional units {{in a single}} cycle. Simultaneous <b>multithreading</b> significantly increases processor utilization {{in the face of}} both long instruction latencies and limited available parallelism per thread. This research presents several models of simultaneous <b>multithreading</b> and compares them with alternative organizations: a wide superscalar, a fine-grain <b>multithreaded</b> processor, and single-chip, multiple-issue multiprocessing architectures. The results show that both (single-threaded) superscalar and fine-grain <b>multithreaded</b> architectures are limited in their ability to utilize the resources of a wide-issue super-scalar processor. Simultaneous <b>multithreading</b> has the potential to achieve 4 times the throughput of a superscalar, and double that of fine-grain <b>multithreading.</b> Simultaneous <b>multithreading</b> is also an attractive alternative to single-chip multiprocessors; simultaneous <b>multithreaded</b> processors with a variety of organizations outperform corresponding conventional multiprocessors with similar execution resources. This dissertation also shows that the throughput gains from simultaneous <b>multithreading</b> can be achieved without extensive changes to a conventional wide-issue superscalar, either in hardware structures or sizes. An architecture for simultaneous <b>multithreading</b> is presented that achieves three goals: (1) it minimizes the architectural impact on a conventional superscalar design, (2) it has minimal performance impact on a single thread executing alone, and (3) it achieves significant throughput gains when running multiple threads. Our simultaneous <b>multithreading</b> architecture achieves a throughput of 5. 4 instructions per cycle, a 2. 5 -fold improvement over an unmodified superscalar with similar hardware resources. This speedup is enhanced by an advantage of <b>multithreading</b> previously unexploited in other architectures: the ability to favor for fetch and issue those threads which will use the processor most efficiently each cycle, thereby providing the "best" instructions to the processor. An analytic response-time model shows that the benefits of simultaneous <b>multithreading</b> in a multiprogrammed environment are not limited to increased throughput. Those throughput increases lead to significant reductions in queueing time for runnable processes, leading to response-time improvements that in many cases are significantly greater than the throughput improvements themselves...|$|R
40|$|Abstract — Interleaved <b>multithreading</b> is a {{technique}} in which the processor starts executing a different task when the current thread is stalled. However, whereas different forms of hardware <b>multithreading</b> have been extensively evaluated in superscalar processors, an evaluation of <b>multithreading</b> techniques in a VLIW architecture is frequently missing. The objective {{of this paper is}} to determine an efficient method of implementing interleaved hardware <b>multithreading</b> in the TriMedia and evaluate the performance. The TriMedia is a multimedia VLIW processor designed by Philips semiconductors. Currently, <b>multithreading</b> is not implemented in the TriMedia. First, the details of the used interleaved <b>multithreading</b> method are given. After that, the architectural changes that are made in to cycle-accurate simulator of the TriMedia are described. Then, the various test result are presented. Finally we discuss the conclusions that can be drawn from the simulation results. Index Terms — Interleaved <b>multithreading,</b> VLIW processor, TriMedia I...|$|R
5000|$|Portable <b>multithreading</b> code (in C/C++ {{and other}} languages, one {{typically}} has to call platform-specific primitives {{in order to}} get <b>multithreading).</b>|$|R
40|$|Abstract—The web data {{collection}} {{is the process}} of collecting the semi-structured, large-scale and redundant data which include web content, web structure and web usage in the web by the crawler and it is often used for the information extraction, information retrieval, search engine and web data mining. In this paper, the web {{data collection}} principle is introduced and some related topics are discussed such as page download, coding problem, updated strategy, static and dynamic page. The <b>multithread</b> technology is described and <b>multithread</b> mode for the web data collection is proposed. The web data collection with <b>multithread</b> can get better resource utilization, better average response time and better performance. Keywords-web page; data collection;multithread I...|$|E
40|$|The {{continuously}} {{increased demand}} for paralleling multitask in domains such as grid computing and cloud computing has significantly promoted research on concurrent mechanism and concurrent programming. The Java programming language supports <b>multithread</b> mechanism for developing paralleling programs, however, {{it is difficult to}} apply Java concurrent primitives to specific problems. Thus, for the development of high reliable and qualitative Java concurrent programs, this paper analyses Java <b>multithread</b> mechanism and it’s realization, studies the concurrent mechanism based on Java synchronization and interactive communication mechanism, compares the concurrent structure based on operating system and based on Java <b>multithread,</b> sums up some concurrent programming rules and strategies to prevent deadlock. A frame instance based on entire synchronization is presented, which can help to develop concurrent programs quickly.  </p...|$|E
40|$|This paper {{presents}} a simulator of a <b>multithread</b> processor, which is developed, {{with a minimum}} architectural impact, on a conventional RISC platform. The <b>multithread</b> processor supports a mixture of controland data-flow model of execution with hardware primitives for scheduling and synchronization. The simulator permits, by changing the processor parameters such as the cache size, the number of contexts {{and the number of}} resources, to design, debug, test and evaluate the performance of multithreaded programs with a minimum efforts. The results achieved indicate that the <b>multithread</b> simulator exhibits high performance by switching between ready contexts and hence overlapping the computation with memory accesses to reduce the processor idle time. 1 INTRODUCTION The mismatch between the processor and memory speeds {{has become one of the}} greatest problems in designing the future processor generation. This difference is made worse by the fact that, in general, the execution of one instructi [...] ...|$|E
40|$|JCilk {{extends the}} serial {{subset of the}} Java {{language}} by importing the fork-join primitives spawn and sync from the Cilk <b>multithreaded</b> language, thereby providing call-return semantics for <b>multithreaded</b> subcomputations. In addition, JCilk transparently integrates Java’s exception handling with <b>multithreading</b> by extending the semantics of Java’s tr...|$|R
40|$|Keywords: garbage collection, microcontroller, Java microprocessor, real-time, <b>multithreading</b> We {{envision}} the upcoming of microcontrollers and systems-on-a-chip {{that are based}} on <b>multithreaded</b> processor kernels due to the fast context switching ability of hardware <b>multithreading.</b> Moreover we envision an extensive market for Java-based applications in embedded real-time systems...|$|R
40|$|Explicit {{hardware}} {{support for}} <b>multithreaded</b> software, {{either in the}} form of shared-memory chip multiprocessors or hardware <b>multithreaded</b> architectures, is becoming increasingly common. As such support becomes available, application developers are expected to exploit these developments by employing <b>multithreaded</b> programming. But although threads simplify the program’s conceptual design, they also increase programming complexity. In writing sharedmemory <b>multithreaded</b> applications, programmers must ensure that threads interact correctly, and this requires care and expertise. Errors in accessing shared-data object...|$|R
