54|172|Public
5000|$|In March 2006, Temasek also {{invested}} some US$400 {{million in}} the E.Sun Financial Holding Company, the holding company of Taiwan's E.Sun Commercial Bank, and acquired a 9.95% Stake in i-Logistics, a Japanese logistics firm with core capabilities in international and <b>multi-modal</b> <b>distribution</b> services.|$|E
50|$|Alberta's International Region is an {{economic}} region effectively {{within the boundaries of}} Leduc County, including the City of Leduc. It is a major industrial hub located 20 kilometres south of Edmonton, Alberta’s capital city. Home to the largest developed energy services industrial park in Canada, three of the world’s top five oil services multinationals operate facilities within the region.  The strategic location provides one of the most comprehensive and efficient <b>multi-modal</b> <b>distribution</b> systems in North America. Key sectors in the region include transportation and logistics, advanced manufacturing, energy services, and agri-foods processing.|$|E
3000|$|SPR {{the bulk}} number {{concentration}} of each aerosol type {{obtained from the}} SPRINTARS simulation, and f the weight factor required to normalize the <b>multi-modal</b> <b>distribution.</b> The variables n [...]...|$|E
5000|$|Distributions of [...] "the scores" [...] (calculated as {{the best}} {{frequency}} minus the worst frequency) for all items which allow the researcher to observe the empirical distribution of estimated utilities. This produces information on how realistic the results from traditional analysis methods assuming standard continuous distributions are likely to be. Consumers tend to form distinct groups with often very different preferences, giving rise to <b>multi-modal</b> <b>distributions.</b>|$|R
40|$|A {{generalized}} probe sequence {{typical of}} trapped ion experiments using shelving is studied. Detection efficiency is analyzed for finite shelved state lifetimes and using <b>multi-modal</b> count <b>distributions.</b> <b>Multi-modal</b> <b>distributions</b> are {{more appropriate for}} measurements that use {{a small number of}} ions than the simple Poisson counting statistics usually considered and have a larger variance that may be significant in determining uncertainties and in making weighted fits. Optimal probe times and the resulting state detection efficiency and sensitivity are determined for arbitrary cooling rates, initial states and shelved state lifetimes, in terms of a probe coherence time τp. A universal optimal probe time of tp 0. 43 τp is shown to give an almost optimal probe sensitivity for most systems...|$|R
50|$|Generally, the trickiest {{part of this}} {{algorithm}} is finding the bounds of the horizontal slice, which involves inverting the function describing the distribution being sampled from. This is especially problematic for <b>multi-modal</b> <b>distributions,</b> where the slice may consist of multiple discontiguous parts. It is often possible to use a form of rejection sampling to overcome this, where we sample from a larger slice that is known to include the desired slice in question, and then discard points outside of the desired slice.|$|R
40|$|A {{generalised}} {{framework for}} Metropolis-Hastings admits many algorithms as specialisations {{and allows for}} synthesis of multiple methods to create a parallel algorithm, with no tuning required, to efficiently draw uncorrelated samples, from the posterior density in Bayesian systems identification, at lower computational cost in comparison with conventional samplers. Two automatic annealing schemes demonstrate complementary robustness in detecting <b>multi-modal</b> <b>distribution...</b>|$|E
40|$|There is no {{qualitative}} dependent {{model that}} can simultaneously account for data sets {{in which the}} variable of interest has both a <b>multi-modal</b> <b>distribution</b> and is potentially ordered. Such a multimodal distribution {{may be the result}} of individuals being captive to particular choices. Such a case arises when there is digit preferencing (particular numbers, such as 0, 5 and 101 are often favored in many survey-based data sets). This paper introduces a new discrete choice model, the Digit Ordered Extreme Value (DOGEV), that does account for both ordering and digit preferencing in the data, and applies it to an Australian Inflationary Expectations data set. Open Acces...|$|E
40|$|We {{present a}} new {{state-based}} prediction algorithm for time series. Given time series {{produced by a}} process composed of different underlying states, the algorithm predicts future time series values based on past time series values for each state. Unlike many algorithms, this algorithm predicts a <b>multi-modal</b> <b>distribution</b> over future values. This prediction forms the basis for labelling part of a time series with the underlying state that created it given some labelled examples. The algorithm is robust {{to a wide variety}} of possible types of changes in signals including changes in mean, amplitude, amount of noise, and period. We show results demonstrating that the algorithm successfully segments signals for a wide variety of example possible signal changes...|$|E
40|$|A Markov-chain Monte Carlo {{sampling}} algorithm samples a {{new point}} around the latest sample {{due to the}} Markov property, which prevents it from sampling from <b>multi-modal</b> <b>distributions</b> since the corresponding chain often fails to search entire support of the target distribution. In this paper, to overcome this problem, mode switching scheme {{is applied to the}} conventional MCMC algorithms. The algorithm separates the reducible Markov chain into several mu-tually exclusive classes and use mode switching scheme to increase mixing rate. Simulation results are given to illus-trate the algorithm with promising results...|$|R
40|$|We {{develop a}} finite-dimensional {{approximation}} of the Frobenius-Perron operator using the finite volume method {{applied to the}} continuity equation {{for the evolution of}} probability. A Courant-Friedrichs-Lewy condition ensures that the approximation satisfies the Markov property, while existing convergence theory for the finite volume method guarantees convergence of the discrete operator to the continuous operator as mesh size tends to zero. Properties of the approximation are demonstrated in a computed example of sequential inference for the state of a low-dimensional mechanical system when observations give rise to <b>multi-modal</b> <b>distributions.</b> Comment: 15 pages, 2 figure...|$|R
5000|$|The {{particle}} filter {{could be considered}} as a generalisation of the UKF. It makes no assumptions about the distributions of the errors in the filter and neither does it require the equations to be linear. Instead it generates a large number of random potential states ("particles") and then propagates this [...] "cloud of particles" [...] through the equations, resulting in a different distribution of particles at the output. The resulting distribution of particles can then be used to calculate a mean or variance, or whatever other statistical measure is required. The resulting statistics are used to generate the random sample of particles for the next iteration. The {{particle filter}} is notable in its ability to handle <b>multi-modal</b> <b>distributions</b> (i.e. distributions where the PDF has more than one peak). However, it is computationally very intensive and is currently unsuitable for most real-world, real-time applications.|$|R
40|$|Abstract- This paper {{describes}} {{a method for}} tracking the for the towel, are used. In [4] a single Extended Particle filter hands/arms of a person performing hand washing. A hand washing (XPF) is used to track multiple and dynamic objects in complex quality assessment system needs {{to know if the}} hands are joined environments where a <b>multi-modal</b> <b>distribution</b> represents the or separated, if they are under water, if they are in contact with. lthe towel or the tap, {{and it has to be}} robust to different lighting conditions, occlusions, reflections and changes in color on the steel In our approach a skin color segmentation process is applied. surface. In the proposed system hands/arms are extracted by using The hands/arms are modeled by using an area based ellipse skin color segmentation. An area based ellipse model is used for fitting method. A single <b>multi-modal</b> <b>distribution</b> is then used in representing each hand/arm. A Particle filter (PF) in combination [...] . with a k-means based clustering technique is used for tracking odrt est the positio an orientao no fbothands/arms. both hands/arms. A supervision algorithm measures the number of That is not the case of the KF which needs two different filters for objects being tracked and the quality of the tracking itself. Finally each one of the hands. The results obtained by PF are analyzed the PF performance is discussed and compared with the standard and compared with those given by KF estimator. Kalman filter (KF) estimator. The remainder of the paper is organized as follows: Section KeVwords- Hand washing, Kalman filter, Particle filter, Skin 1 I provides a description of the hands/arms segmentation process detection, Tracking. and the proposed model. PF is described in Section III. Th...|$|E
40|$|In this {{contribution}} {{we present}} a novel constrained clustering method, Constrained clustering with a complex cluster structure (C 4 s), which incorporates equivalence constraints, both positive and negative, as the background information. C 4 s is capable of discovering groups of arbitrary structure, e. g. with <b>multi-modal</b> <b>distribution,</b> since at the initial stage the equivalence classes of elements generated by the positive constraints are split into smaller parts. This provides {{a detailed description of}} elements, which are in positive equivalence relation. In order to enable an automatic detection of the number of groups, the cross-entropy clustering is applied for each partitioning process. Experiments show that the proposed method achieves significantly better results than previous constrained clustering approaches. The advantage of our algorithm increases when we are focusing on finding partitions with complex structure of clusters...|$|E
40|$|Severe {{financial}} turbulences {{are driven}} by high impact and low probability events that are the characteristic hallmarks of systemic financial stress. These unlikely adverse events arise from the extreme tail of a probability distribution and are therefore very poorly captured by traditional econometric models that rely on the assumption of normality. In order {{to address the problem}} of extreme tail events, we adopt a mixture vector autoregressive (MVAR) model framework that allows for a <b>multi-modal</b> <b>distribution</b> of the residuals. A comparison between the respective results of a VAR and MVAR approach suggests that the mixture of distributions allows for a better assessment of the effect that adverse shocks have on counterparty credit risk, the real economy and banks 2 ̆ 019 capital requirements. Consequently, we argue that the MVAR provides a more accurate assessment of risk since it captures the fat tail events often observed in time series of default probabilities...|$|E
40|$|Cost {{data that}} arise in the {{evaluation}} of health care technologies usually exhibit highly skew, heavy-tailed and, possibly, <b>multi-modal</b> <b>distributions.</b> Distribution-free methods for analysing these data, such as the bootstrap, or those based on the asymptotic normality of sample means, may often lead to inefficient or misleading inferences. On the other hand, parametric models that fit the data (or a transformation of the data) equally well can produce very different answers. We consider a Bayesian approach, and model cost data with a distribution composed of a piecewise constant density up to an unknown endpoint, and a generalised Pareto distribution for the remaining tail...|$|R
5000|$|This {{requires}} computation of {{the conditional}} probabilities [...] The multiple atlas orbit model randomizes over the denumerable set of atlases [...] The model on {{images in the}} orbit {{take the form of}} a <b>multi-modal</b> mixture <b>distribution</b> ...|$|R
40|$|Abstract. We {{present an}} {{algorithm}} to generate samples from probability distributions {{on the space}} of curves. We view a traditional curve evolution energy functional as a negative log probability distribution and sample from it using a Markov chain Monte Carlo (MCMC) algorithm. We define a proposal distribution by generating smooth perturbations to the normal of the curve and show how to compute the transition probabilities {{to ensure that the}} samples come from the posterior distribution. We demonstrate some advantages of sampling methods such as robustness to local minima, better characterization of <b>multi-modal</b> <b>distributions,</b> access to some measures of estimation error, and ability to easily incorporate constraints on the curve. ...|$|R
40|$|Acrylic acid {{copolymers}} {{are potential}} carriers for drug delivery. The surface, surface rugosity and the absolute {{dimension of the}} particles are parameters that determine the binding of drugs or detergents, diffusion phenomena at the surface {{and the distribution of}} the carrier within the human body. The particle-size distribution and surface rugosity of the particles have been investigated by small-angle X-ray scattering and dynamic light scattering. Direct Fourier transform as well as a new strategy for the indirect maximum-entropy method MAXENTare used for data evaluation. Scattering equivalence of a pure <b>multi-modal</b> <b>distribution</b> of hard spheres (five populations) and a mixed multimodal-surface-fractal model (four popula-tions) was found. Model calculations and dynamic light-scattering experiments gave evidence of the multimodal particle-size distribution combined with the fractal sur-face of the carrier. The main moiety consists of particles 90 nm in diameter which are surface fractals in the 10 nm region. 1...|$|E
40|$|Colorization is an {{ambiguous}} problem, with multiple viable colorizations {{for a single}} grey-level image. However, previous methods only produce the single most probable colorization. Our goal is to model the diversity intrinsic {{to the problem of}} colorization and produce multiple colorizations that display long-scale spatial co-ordination. We learn a low dimensional embedding of color fields using a variational autoencoder (VAE). We construct loss terms for the VAE decoder that avoid blurry outputs and take into account the uneven distribution of pixel colors. Finally, we build a conditional model for the <b>multi-modal</b> <b>distribution</b> between grey-level image and the color field embeddings. Samples from this conditional model result in diverse colorization. We demonstrate that our method obtains better diverse colorizations than a standard conditional variational autoencoder (CVAE) model, as well as a recently proposed conditional generative adversarial network (cGAN). Comment: This revision to appear in CVPR 1...|$|E
40|$|We {{present a}} novel {{discriminant}} analysis learning method which is applicable to non-linear data structures. The method {{can deal with}} pattern classification problems which have a <b>multi-modal</b> <b>distribution</b> for each class and samples of other classes may be closer to a class {{than those of the}} class itself. Conventional linear discriminant analysis (LDA) and LDA mixture model can not solve this linearly non-separable problem. Several local linear transformations are considered to yield locally transformed classes that maximize the between-class covariance and minimize the within-class covariance. The method invloves a novel gradient based algorithm for finding the optimal set of local linear bases. It does not have a local-maxima problem and stably converges to the global maximum point. The method is computationally efficienct as compared to the previous non-linear discriminant analysis based on the kernel approach. The method does not suffer from an overfitting problem by virtue of the linear base structure of the solution. The classification results are given for both simulated data and real face data. ...|$|E
40|$|In this {{contribution}} I present {{my current}} {{work in a}} new generation of evolutionary synthesis models that compute the multiwavelength energy distribution (from gamma-rays to radio) as well as the associated dispersion for young stellar systems. I will also show some statistical effects that may appear in the analysis of surveys, like bimodal or <b>multi-modal</b> <b>distributions</b> and bias when color indices computed by the codes are compared with observations. Such new generation of synthesis models may be useful for the analysis of the data expected from GTC. Comment: 2 pages, 2 figures. Contribution to "Science with the GTC", Granada 8 - 6 Feb (2002...|$|R
40|$|We {{consider}} {{the problem of}} assessing new and existing technologies for their cost-effectiveness in the case where data on both costs and efficacy are available from a clinical trial, and we address it {{by means of the}} cost-effectiveness acceptability curve in the simple case where efficacy is measured as a binary outcome. We consider a Bayesian approach, and in recognising that cost data usually exhibit highly skew, heavy-tailed and, possibly <b>multi-modal</b> <b>distributions,</b> we introduce a model for costs composed of a piecewise constant density up to an unknown endpoint, and a generalised Pareto distribution for the remaining tail. Healthcare cost data, cost-effectiveness analysis, mixture models, semiparametric modelling. ...|$|R
40|$|We {{develop a}} {{detailed}} approach {{to study how}} mobility impacts the performance of reactive MANET routing protocols. In particular we examine how the statistics of path durations including PDFs vary with the parameters such as the mobility model, relative speed, number of hops, and radio range. We find that at low speeds, certain mobility models may induce <b>multi-modal</b> <b>distributions</b> that reflect {{the characteristics of the}} spatial map, mobility constraints and the communicating traffic pattern. However, our study suggests that at moderate and high velocities the exponential distribution with appropriate parameterizations is a good approximation of the path duration distribution for a range of mobility models...|$|R
40|$|We {{describe}} {{a new form}} of representation of image velocities, which does not rely on vector fields. For each local spatio-temporal region of the input image, we desire a function over the space of velocities describing the presence of a given velocity in that region. This function may be interpreted as a probability distribution over velocity, although {{it is not necessary to}} do so. A primary advantage of this representation is that it is capable of representing more than one velocity at a given image location. A <b>multi-modal</b> <b>distribution</b> indicates the presence of multiple motions. Such situations occur frequently in natural scenes near occlusion boundaries, and in situations of transparency. We develop an example of this type of representation through a series of modifications of current differential approaches to motion estimation. We define an angular version of the standard gradient constraint equation, and then extend this to represent multiple motions. The derivation is first done [...] ...|$|E
40|$|One {{element of}} the supply of {{international}} transport services {{as part of a}} logistics supply chain is the use of transport documents which exchange and record information and embodies legal significance. Historically, many of these documents developed along modal lines and are paper-based but modern logistics practices and international trade often require <b>multi-modal</b> <b>distribution</b> channels and the greater use of information technology with a possible shift to electronic documents. This paper examines whether, {{in the light of the}} evolving operational and legal environment and from an industry perspective, a more flexible approach to carriage documentation could emerge. The paper, based on a qualitative study, comprises five sections. Following the introduction, the research methodology is outlined. Section 3 discusses documents of carriage and legal issues while Section 4 presents the findings from the study. The final section offers some conclusions and suggests that, despite various changes which are moving in the right direction, legacy and uncertainty render various parties reluctant to take advantage of the changing legal framework...|$|E
40|$|In {{this work}} we derive a novel {{framework}} rendering measured distributions into approximated distributions of their mean. This {{is achieved by}} exploiting constraints imposed by the Gauss-Markov theorem from estimation theory, being valid for mono-modal Gaussian distributions. It formulates {{the relation between the}} variance of measured samples and the so-called standard error, being the standard deviation of their mean. However, multi-modal distributions are present in numerous image processing scenarios, e. g. local gray value or color distributions at object edges, or orientation or displacement distributions at occlusion boundaries in motion estimation or stereo. Our method not only aims at estimating the modes of these distributions together with their standard error, but at describing the whole <b>multi-modal</b> <b>distribution.</b> We utilize the method of channel representation, a kind of soft histogram also known as population codes, to represent distributions in a non-parametric, generic fashion. Here we apply the proposed scheme to general mono- and multimodal Gaussian distributions to illustrate its effectiveness and compliance with the Gauss-Markov theorem...|$|E
40|$|In this study, {{we aim to}} {{estimate}} the unknown <b>multi-modal</b> measurement noise <b>distribution</b> of nonlinear state space models. The unknown noise distribution is modeled as a mixture of exponential family of distributions. We use the Expectation-Maximization (EM) method in order to jointly estimate the unknown parameters {{as well as the}} states. The online version of the EM algorithm is implemented by using particle filtering techniques. The resulting algorithm is a noise adaptive particle filter which is applicable to many sensor models having <b>multi-modal</b> noise <b>distributions</b> with unknown parameters...|$|R
40|$|Abstract — Probabilistic {{approaches}} are extensively used to solve high-dimensionality problems {{in many different}} fields. The particle filter is a prominent approach {{in the field of}} Robotics, due to its adaptability to non-linear models with <b>multi-modal</b> <b>distributions.</b> Nonetheless, its result is strongly dependent on the quality and the number of samples required to cover the space of possible solutions. In contrast, interval analysis deals with high-dimensionality problems by reducing the space enclosing the actual solution. Notwithstanding, it cannot precise where in the resulting subspace the actual solution is. We devised a strategy that combines the best of both worlds. Our approach is illustrated by solving the global localization problem for underwater robots. I...|$|R
40|$|This paper {{considers}} {{the problem of}} estimating linear dynamic system models when the observations are corrupted by random disturbances with nonstandard distributions. The paper is particularly motivated by applications where sensor imperfections involve significant contribution of outliers or wrap-around issues resulting in <b>multi-modal</b> <b>distributions</b> such as commonly encountered in robotics applications. As will be illustrated, these nonstandard measurement errors can dramatically compromise the effectiveness of standard estimation methods, while a computational Bayesian approach developed here is demonstrated to be equally effective as standard methods in standard measurement noise scenarios, but dramatically more effective in nonstandard measurement noise distribution scenarios. Comment: 16 pages, 4 figures. Submitted for review to the 18 th IFAC Symposium on System Identification (SYSID...|$|R
40|$|In {{analyzing}} {{data from}} experiments on periodically stimulated neurons, the interspike interval histogram shows a <b>multi-modal</b> <b>distribution</b> and under certain conditions, stochastic resonance. We discuss a simple integrate and fire {{model of a}} single neuron which is capable of describing these two features. As input for the neuron we use a periodic signal combined with poisson noise, this gives results that resemble data from experiments. 1 Introduction There {{has been a great}} number of experiments in the past involving measurements on single neurons in the presence of some external stimulus. In the special case of a periodic and excitatory stimulus a typical phenomenon is observed: the neuron of interest tends to fire with the same period as the period of the stimulus it receives. We call this the coherent signal. It depends on the strength of the stimulus whether a spike occurs every cycle or not. In the latter case we observe multi-modality in interspike interval histograms (isihs) : p [...] ...|$|E
40|$|This paper {{presents}} a three-objective distribution planner {{to tackle the}} tactical optimization of fresh food distribution networks considering operating cost, carbon footprint and delivery time goals. The developed expert system overcomes the widely adopted methodologies mainly focused on the cost minimization only. These three independent goals are jointly included in a unique tool, called Food Distribution Planner, to support the tactical planning of <b>multi-modal</b> <b>distribution</b> networks of perishable produces. This expert system implements a three-objective linear programming model, considering the typical food distribution constraints, i. e. the food quality dependence on the delivery time, the geographically distributed market demand and the farmer production capacities. This paper further applies the proposed system to a real case study dealing with the distribution of {{fresh fruits and vegetables}} from a set of Italian producers to several European retailers. The most effective distribution network is studied best balancing the economic, environmental and delivery time objective functions. Such a tactical network planning leads to 9. 6...|$|E
40|$|Transportation {{industry}} is a fairly large industry in today's globalised world, and has significant effect too. Each and every big or small {{industry is}} bound to use the transportation facilities or logistics. The main problems in this logistics operation are optimising the cost, time, distance travelled, back orders and surpluses. In most of the studies, {{one or two of}} the aspects mentioned above has been taken into consideration and solved accordingly. Again in a lot of studies, it was assumed that the demand structure, inventory structure, structure of cluster formation and structure of route formation are of deterministic nature. This study is reviewing the previous attempts to solve different aspects of distribution problems, and simultaneously proposing alternative way of attempts. evolutionary algorithms, transportation facilities, multi-objective distribution, multi-product distribution, <b>multi-modal</b> <b>distribution,</b> costs, time optimisation, distance travelled, back orders, surpluses, demand structure, inventories, cluster formation, route formation, routes, deterministic attributes, logistics management, economics, globalisation,...|$|E
40|$|Abstract — We {{describe}} a filter-based model of orientation processing in {{primary visual cortex}} (V 1) and demonstrate that novelty in cortical “pinwheel ” space {{can be used as}} a measure of perceptual salience. In the model, novelty is computed as the negative log likelihood of a pinwheel’s activity relative to the population response. The population response is modeled using a mixture of Gaussians, enabling the representation of complex, <b>multi-modal</b> <b>distributions.</b> Hidden variables that are inferred in the mixture model can be viewed as grouping or “binding ” pinwheels which have similar responses within the distribution space. Results are shown for several stimuli that illustrate well-known contextual effects related to perceptual salience, as well as results for a natural image...|$|R
40|$|Point {{processes}} are becoming {{very popular in}} modeling asynchronous sequential data due to their sound mathematical foundation and strength in modeling a variety of real-world phenomena. Currently, they are often characterized via intensity function which limits model's expressiveness due to unrealistic assumptions on its parametric form used in practice. Furthermore, they are learned via maximum likelihood approach which is prone to failure in <b>multi-modal</b> <b>distributions</b> of sequences. In this paper, we propose an intensity-free approach for point processes modeling that transforms nuisance processes to a target one. Furthermore, we train the model using a likelihood-free leveraging Wasserstein distance between point processes. Experiments on various synthetic and real-world data substantiate {{the superiority of the}} proposed point process model over conventional ones...|$|R
40|$|Many {{techniques}} are currently used for motion estimation. In the block-based approaches {{the most common}} procedure applied is the block-matching based on various algorithms. To refine the motion estimates resulting from the full search or any coarse search algorithm, one can find few applications of Kalman filtering, mainly in the intraframe scheme. The Kalman filtering technique applicability for block-based motion estimation is rather limited due to discontinuities in the dynamic behaviour of the motion vectors. Therefore, we propose an application {{of the concept of}} the filtering by approximated densities (FAD). The FAD, originally introduced to alleviate limitations due to conventional Kalman modelling, is applied to interframe block-motion estimation. This application uses a simple form of FAD involving statistical characteristics of <b>multi-modal</b> <b>distributions</b> up to second order...|$|R
