22|0|Public
50|$|<b>Monosemy</b> is {{the absence}} of {{semantic}} ambiguity in language, i.e. only having one meaning per word. The majority of natural human languages are polysemous, i.e. having more than one meaning per word. The artificial language Lojban and its predecessor Loglan represent attempts at creating monosemous languages. <b>Monosemy</b> is important for translation and semantic computing.|$|E
40|$|This paper {{addresses}} {{vector space}} models of prepositions, a notoriously ambiguous word class. We propose a rank-based distance measure {{to explore the}} vector-spatial properties of the ambiguous objects, focusing on two research tasks: (i) to distinguish polysemous from monosemous prepositions in vector space; and (ii) to determine salient vector-space features for a classification of preposition senses. The rank-based measure predicts the polysemy vs. <b>monosemy</b> of prepositions with a precision of up to 88 %, and suggests preposition-subcategorised nouns as more salient preposition features than preposition-subcategorising verbs...|$|E
40|$|This chapter {{proposes a}} {{conception}} of lexical meaning as use-potential, in contrast to prevailing atomistic and reificational views. The issues are illustrated on the example of spatial expressions, pre-eminently prepositions. It is argued that the dichotomy between polysemy and semantic generality is a false one, with expressions occupying points on a continuum from full homonymy to full <b>monosemy,</b> and with typical cases of polysemy falling in between. The notion of use-potential is explored in connectionist models of spatial categorization. Some possible objections to the use-potential approach are also addressed...|$|E
40|$|In this paper, {{the problem}} of disambiguating a target word for Polish is {{approached}} by searching for related words with known meaning. These relatives are used to build a training corpus from unannotated text. This technique is improved by proposing new rich sources of replacements that substitute the traditional requirement of <b>monosemy</b> with heuristics based on wordnet relations. The naïve Bayesian classifier has been modified to account for an unknown distribution of senses. A corpus of 600 million web documents (594 billion tokens), gathered by the NEKST search engine allows us to assess the relationship between training set size and disambiguation accuracy. The classifier is evaluated using both a wordnet baseline and a corpus with 17, 314 manually annotated occurrences of 54 ambiguous words...|$|E
40|$|This chapter {{addresses}} {{the dynamics of}} terms and meaning in specialised communication {{by means of a}} semantic investigation into the domain of machining and metalworking terminology. The double quantitative analysis consists of the identification and quantification of specialised vocabulary as well as the quantification of the semantic analysis by means of a <b>monosemy</b> measure. This approach involves a statistical analysis in order to come to linguistic conclusions. Accordingly, the study aims to question the univocity ideal in a quantitative way. It focuses on the methodology and shows that an interdisciplinary approach can yield valuable results. The study is completed by a small analysis on an English test corpus from the same domain in order to explore the semantic differences between (culturally different) corpora. status: publishe...|$|E
40|$|Workers in many job {{categories}} tend {{to develop}} technical languages, which are restricted subjects of natural language. A better {{knowledge of these}} retrictions provides guidelines {{for the design of}} the restricted languages of interactive systems. Accordingly, a technical language used by air-traffic controllers in their communications with pilots was studied. A method of analysis is presented that allows the schemata underlying each category of messages to be identified. This schematic knowledge was implemented in programs, which assume that the goal-oriented aspect of technical languages (and particularly the restricted domain of discourse) limits the processes and the data necessary {{in order to understand the}} messages (<b>monosemy,</b> limited vocabulary, evocation of the schemata by some command words, absence of syntax). The programs can interpret, and translate into sequences of action, the messages emitted by the controllers...|$|E
40|$|The {{industry}} of cross-border waste-shipment is growing considerably in the EU economy. As a result, {{there is an}} increasing need of specialized translations in this field. With the aim of designing a translation-oriented glossary to help professional translators, the terminology extracted from an ad-hoc multilingual corpus has been analyzed to identify terminological variation. The results provided by this analysis prove that terminological variation is found on multiple levels, thus challenging Wüster's principle of <b>monosemy.</b> Following the traditional definition of term as relationship between concept and denomination, this paper proposes {{a model for the}} description of terminological variation explained through examples taken from the previously examined terminology. Here, concept and denomination are seen as two components that are subject to variation. Conceptual variation includes polysemy and homonymy, while denominational variation includes synonymy, i. e. diastratic, graphic and geographic variants, as well as complex term reduction. These variations {{do not appear to be}} completely independent from one another, as denominational variation inevitably implies at least a slight conceptual shift...|$|E
40|$|This {{thesis is}} an {{examination}} of polysemy {{and its effects on}} second language learners, revealing it as a greater concern than it is normally accorded in pedagogical research. Arguing against a reliance on the dictionary to determine the number of senses a given word has, it begins with a thorough exploration of the concept, both from diachronic and synchronic perspectives, by contrasting it with the related concepts of homonymy and <b>monosemy.</b> A monosemic stance is argued for, which does not deny the existence of polysemy but argues for a framework in which contextual variations of a word are not considered discrete meanings. The British National Corpus is consulted for data demonstrating that instances of a word that may appear as discrete units of meanings actually form a single, unified usage. With <b>monosemy</b> redistributed to account for more than it normally does, and with polysemy relegated solely to semantics (factoring out syntax, pragmatics, etc.), polysemy becomes a considerably less sloppy concept, revealing that, at a top-down level, there are essentially only two varieties. The first of these is 'lexical metaphor,' {{in which there is a}} clear literalmetaphoric divide between uses, and the second is 'vicariant polysemy' in which senses are discrete but not synchronically explainable by metaphor. Using Hoey's notion of lexical priming, the factored-out elements of syntax, collocation, etc. are returned to, but strictly as effects of the semantic process of sense generation that should not be mistaken for the cause, though they frequently are. The second part of this thesis moves from the theoretical to the applied, reviewing the sparse literature on the subject. Techniques for raising awareness of the issue among students are discussed as are dictionary skills relevant to polysemy and homonymy. Attention is then turned toward homonymy, examining the problem it poses to word lists and providing the beginning of a solution by revealing which words on the General Service List are homonymic and giving the relative frequency of each meaning. A technique to assist learners in acquiring additional meanings of homonyms is examined, as is a technique for guessing new or novel meanings of polysemes in context...|$|E
40|$|This {{dissertation}} studies lexically-specic (irregular) polysemy, using a {{case study}} of the English verb see as the major example. Clearly, words such as see have dierent meanings in dierent contexts, but how can we distinguish dierent senses from mere dierent uses (modulations) of the same sense? What are the semantic and paradigmatic relations among the senses? Answers to these questions were sought through a series of psycholinguistic experiments, formal analysis in terms of Frame Semantics (Fillmore 1976; Fillmore 1982; Fillmore & Atkins 1992) and other cognitive linguistic theories, and analysis of entries in monolingual and bilingual dictionaries. The results show that speakers can reliably distinguish many senses of see, that the English pattern of senses is partially shared across languages, and that frame semantics is a good way of representing the relations among senses. First, the relation of semantics to world knowledge and categorization is discussed, and Frame Semantics, homonymy, polysemy, and <b>monosemy,</b> traditional tests for polysemy, and other types of linguistic evidence are dened. Then, the semantics and syntax of see are outlined and detailed frame represen...|$|E
40|$|This paper {{argues that}} the text-type “patent” is eminently {{suitable}} for teaching specialized translation at MA level. Translating a patent is a challenge at two levels, given that its technical content is expressed {{by means of a}} textual and linguistic framework which in fact is of a legal nature. Consequently, the translation process confronts the translator with no easy task because it must necessarily involve a different approach at the theoretical and practical levels, accounting for the morphosyntactic, lexical and textual peculiarities of both the technical and legal components. Nevertheless a number of features – such as rigid layout rules, recurrent syntactic and lexical structures and a marked tendency towards redundancy and <b>monosemy</b> – counterbalance the aforesaid complexity. That of patents is therefore a somewhat unique text type, which is particularly suitable for specialized translation classes at MA level for at least two reasons. Firstly, students are forced to adopt different translation strategies to cope with the patent’s both technical and legal features. Secondly, translating a patent involves an extensive use of CAT tools. This makes such a text type particularly suitable for introducing students to professional translation, which is the ultimate goal of our teaching activity...|$|E
40|$|The {{study of}} {{polysemy}} is of fundamental importance for any semantic study of language. Nerlich & Clarke (2003 : 349) Ever since {{the notion of}} polysemy was proposed more than 100 years ago by Bréal (1897), it has been puzzling researchers from many disciplines: linguists, lexicographers, psycholinguists, psychologists, computer scientists, AI researchers, … Much of the problems polysemy poses to analysts is that tackling it requires an understanding of several other notions {{to which it is}} related: ambiguity, homonymy, <b>monosemy,</b> vagueness, prototypicality and similarity of meaning, and others. While space does not permit a full-fledged discussion of any one of these notions, to set the stage I will provide what are coarse but at least fairly uncontroversial characterizations of these notions: ambiguity: the fact that 2 + interpretations of a word are discrete and antagonistic as in e. g., the adjective light: in order for I am wearing a light coat and so does my friend to be felicitous, light has to mean the same – 'not dark ' or 'not heavy ' – in both conjuncts; homonymy: a form of ambiguity where 2 + unrelated meanings are associated with th...|$|E
40|$|A border {{discipline}} {{in search of}} an autonomous status within language sciences, Terminology today remains deprived of a conceptual tool and a discourse based on objective methods of description. In reality, judging from the abundance of recent publications, Terminology theories are disparate and eclectic. Pessimists refer to a decline if not an outright identity crisis. They are not entirely wrong. What is needed is a state of the art. Those willing to pursue the course of the terminological thought soon notice the conflicts, the barriers, and the gaps. Nonetheless, real progress has been made, such as taking phraseology and the complete text into consideration, and putting into perspective sociolinguistic and cognitive aspects. A quick retrospective glance reminds us how researchers, even from early 1970, began benefitting from the interlinguistic approach (in the sense of differential linguistics) to detach themselves from axioms of the Terminology of Wusterian obedience and to demonstrate that terminologies were not as radically distant from the general language as some presumed, that they constituted complex polysystems that present, in a dialectical relation, both motivation and convention, <b>monosemy</b> and polysemy, analogies and anomalies, and synonymical concurrences. Since this is the time for assessments and perspectives, we will venture to reflect on the three levels of practice, praxeology and fundamental research. SCOPUS: re. jinfo:eu-repo/semantics/publishe...|$|E
40|$|This paper {{presents}} the results of a study of terminological units and discourse formulas which constitute the lexical basis of the discourse of the English law enforcement system. Due to the current expanding cooperation of Russian law enforcement units with their foreign partners the area addressed is of great interest to those involved in teaching foreign languages for specific purposes at law faculties and schools, yet has not received an adequate treatment to this point. The article reveals an interdisciplinary character of the law enforcement terminology, which accounts for numerous transterms used in it. The study identifies the reasons for the integration of the law enforcement terminology with other terminological systems and also names the main sources of transterms. Other highly productive methods of concept nomination in the area include syntactic and morphosyntactic term formation. This enriches the law enforcement terminology with multicomponent terms and their abbreviated and elliptical variants. The analysis of discourse formulas suggests syntactic heterogeneity of these structures, their stylistic neutrality, <b>monosemy</b> and semantic transparency. This layer of the law enforcement discourse is also characterized by information compression by means of abbreviations and digital encoding. The results of the research can be applied in English textbook and translation dictionary designing...|$|E
40|$|This chapter {{makes use}} of wine reviews for the {{investigation}} of how experiences of sensory perceptions of VISION, SMELL, TASTE and TOUCH are described. In {{spite of all the}} great challenges involved in describing perceptions, professional wine reviewers are expected {{to be able to give}} an understandable account of their experiences. The reviews are explored with focus on the different types of descriptors and the ways their meanings are construed. It gives an account of the use of both property expressions, such as soft, sharp, sweet and dry and object descriptors, such as blueberry, apple and honey. It pays particular attention to the apparent cross-sensory use of descriptors, such as white aromas and soft smell, arguing that the ontological cross-over of sensory modalities are to be considered as symptoms of ‘synesthesia’ in the wine-tasting practice and <b>monosemy</b> at the conceptual level. In contrast to the standard view of the meanings of words for sensory perceptions, the contention is that it is not the case that, for instance, sharp in sharp smell primarily evokes a notion of touch; rather the sensory experiences are strongly interrelated in cogni-tion. When instantiated in, say SMELL, soft spans the closely related sense domains, and the lexical syncretism is taken to be grounded in the workings of human sensory cognition...|$|E
40|$|The present article {{reports on}} an {{investigation}} of one child's acquisition of the multiple senses of the preposition with from 2; 0 – 4; 0. Two competing claims regarding children's early representation and subsequent acquisition of with were investigated. The “multiple meanings” hypothesis predicts that children form individual form-meaning pairings for with as separate lexical entries. The “monosemy approach” (McKercher 2001) claims that children apply a unitary meaning by abstracting core features early in acquisition. The child's (“Brian”) speech and his input were coded according to eight distinguishable senses of with. The results showed that Brian first acquired the senses that were most frequent in the input (accompaniment, attribute, and instrument). Less common senses took much longer to emerge. A {{detailed analysis of the}} input showed that a variety of clues are available that potentially enable the child to distinguish among high frequency senses. The acquisition data suggested that the child initially applied a restricted one-to-one form-meaning mapping for with, which is argued to reflect the spatial properties of the preposition. On the basis of these results it is argued that neither the <b>monosemy</b> nor the multiple meanings approach can fully explain the data, but that the results are best explained by a combination of word learning principles and children's ability to categorize the contextual properties of each sense's use in the ambient language...|$|E
40|$|Slang is one {{of those}} things that {{everybody}} can recognize and nobody can define. " Paul Roberts (Andersson –Trudgil 1990 : 69) Over the years, in my work I have constantly highlighted the terminological heterogeneity in the field of European social dialects. Many of the terms that belong to national traditions and cultures are used in conjunction with international scientific ones (Armianov: 2004). And yet, the linguistic features that make terms out of ordinary words are rather clear and we can put forward the following characteristics: 1. the single meaning (the <b>monosemy)</b> of the term; 2. its semantic precision; 3. its stylistic neutrality. It is surprising that as soon as one starts discussing slang, argot or jargon the linguistic and cultural polysemy of these terms immediately brings a very complex and diverse picture to mind. This complexity and this diversity exist in all the countries of Europe and in the United States and they are quite difficult to overcome because of numerous extralinguistic factors. Because of this sociocultural opposition and the heterogeneity of the sociolectal terminological apparatus it is important to bring some order to this chaos. In the current context, I will attempt to paint a picture in which the European social dialects will be defined and analysed according to their pure linguistic and social characteristics. The final goal is to elaborate a clear structure, and a common terminological scale for European sociolects where each slang, jargon or argot can find its place...|$|E
40|$|Polysemy seems {{nowadays}} {{to be one}} of pet {{topics for}} linguists of various theo-retical persuasions. Structural linguists have noticed that the phenomenon of multiplicity of meanings, traditionally called polysemy, is relatively common and present in all natural languages. Although the phenomenon is easy to recog-nize—one expression is related with several meanings—its precise characteriza-tion is fraught with difficulties. It is, on the one hand, difficult to distinguish from homonymy, while, on the other, the boundary between polysemy and <b>monosemy</b> is not discrete, either. These serious problems resulted in a gradual loss of interest in the matter, particularly during the domination of the transfor-mational-generative paradigm. The editors of the volume under review complain in their introduction about “denigration of polysemy, ” pointing out that, for ex-ample, “the renewed interest in the issues of human communication (a good deal of which depends on language production and understanding) left the problem of polysemy untouched ” and that “such a landmark linguistics publication as Jackendoff's Foundations of Language allots polysemy some meagre four pages ” (p. 9). There is, however, no denying that polysemy comes into the focus of linguis-tic research as late as in the end of the 20 th century, and that this is coupled with the rise of cognitive linguistics. In addition to studying fundamental conceptual questions relating to polysemy that were inherited from traditional approaches, the cognitive linguistic research starts focussing on polysemy as a problem of categorization {{as well as on the}} motivation for linking various meanings, chiefly meanings of lexical units linked by metaphor and metonymy (cf. Geeraert...|$|E
40|$|In {{this paper}} I {{argue that the}} lexeme time {{constitutes}} a lexical category of distinct senses instantiated in semantic memory. The array of distinct senses constitutes a motivated semantic network organised {{with respect to a}} central sense termed the SANCTIONING SENSE. The senses associated with time are derived by virtue of the interaction between the Sanctioning Sense, conceptual processing and structuring, and context. Hence, semantic representations, cognitive mechanisms, and situated language use are appealed to in accounting for the polysemy associated with time. The model adduced is termed PRINCIPLED POLYSEMY. The conclusion which emerges, in keeping with recent studies in lexical semantics, most notably Lakoff (1987), Pustejovsky (1995), Tyler & Evans (2003) and Evans (2004), is that the lexicon is not an arbitrary repository of unrelated lexemes; rather, the lexicon exhibits a significant degree of systematicity, and productivity. In order to adduce what constitutes a dis-tinct sense, I introduce three criteria: (1) a meaning criterion, (2) a concept elaboration criterion and (3) a grammatical criterion. A further claim is that the lexicon exhibits significant redundancy. This position is at odds with SINGLE-MEANING APPROACHES to polysemy, which posit highly underspecified lexical META-ENTRIES, such as the gener-ative approach of Pustejovsky (1995) or the <b>monosemy</b> position of Ruhl (1989). That is, I propose that lexical items constitute highly granular categories of senses, which are encoded in semantic memory (=the lexicon). This necessitates a set of criteria for determining what counts as a distinct sense without deriving a proliferation of un-warranted senses, a criticism which has been levelled at some studies of word-meaning in cognitive linguistics (e. g. Lakoff 1987) ...|$|E
40|$|International audienceThe {{following}} are the main issues addressed in research on modality: (i) {{what is the difference}} between root and epistemic modality? (ii) what meanings exactly do modals have? and (iii) are these meanings part of the semantics of the modal expression (polysemy) or are these meanings pragmatically derived interpretations of a single meaning (<b>monosemy)</b> ? In this paper, I argue that the difficulty to answer these questions results from the misconception that they all are directly related to the modal expressions themselves. I will show that a better understanding can be arrived at by combining insights from Construction Grammar (CxG) and Relevance Theory (RT). More specifically, I argue that two different constructions (i. e. form-meaning pairs) are involved in English: a (modal) verb and a more schematic MODAL construction (MCx) in which the verb occurs, each with its respective form and function. I will also explain the interaction between the two constructions, and show how the (modal) verb inherits part of its meaning from the MCx. In addition, building on the Relevance theoretic distinction between conceptual and procedural meaning, I argue that the (modal) verb encodes conceptual meaning whilst the MCx encodes procedural meaning. It then becomes clear that the contribution of the two constructions to the modal sentence varies and therefore that the answer to the questions raised above will be different depending on the type of meaning that is at stake. The distinction argued for seems, therefore, rather necessary. Furthermore, the advantage of this approach is that it can also explain the use of modal expressions other than modal verbs (e. g. nouns: permission, risk; adjectives: vital, acceptable; adverbs: probably, maybe), and account for both the formal and functional diachronic development of modal expressions in English...|$|E
40|$|Sources of {{inspiration}} help designers {{to define the}} context of their designs and reflect on the emotional impact of their new products. By observing and interpreting sources {{of inspiration}}, designers form vocabularies of terms, pallets of colors, or mood boards with images, which express their feelings, inspire their creativity and help them communicate design concepts. These ideas are the motivation behind the EU-funded project TRENDS, which aimed at developing a software tool that supports the inspirational stage of design by providing designers of concept cars with various sources of inspiration. This paper concentrates on OntoTag, the semantic-based image retrieval algorithm developed within the TRENDS project, and its evaluation. OntoTag uses concepts from a general-purpose lexical ontology called OntoRo, and semantic adjectives from a domain-specific ontology for designers called CTA, to index the images in the TRENDS database in a way which provides designers with a degree of serendipity and stimulates their creativity. The semantic-based algorithm involves the following four steps: (i) creating a collection of documents and images retrieved from the web, (ii) for each document, identifying the most frequently used keywords and phrases in the text around the image, (iii) identifying the most powerful concepts represented in each document, and (iv) ranking the concepts identified and linking them to the images in the collection. OntoTag differs significantly from earlier approaches as it does not rely on machine learning and the availability of tagged corpuses. Its main innovation is {{in the use of the}} words' <b>monosemy</b> and polysemy as a measure of their probability to belong to a certain concept. The proposed approach is illustrated with examples based on the software tool developed for the needs of two of the industrial collaborators involved in the TRENDS project...|$|E
40|$|The paper {{discusses}} asyndetic sentences, compound sentences {{without a}} conjunction between the clauses. Slavic scholars pay considerable {{attention to these}} sentences. They predominantly consider asyndetic sentences {{to be a model}} of compound sentences, apart from the model of compound conjunctional sentences, and plead that they should be described separately. Asyndetic sentences in contemporary Serbian have not been studied sufficiently. There are few specific papers dedicated to asyndetic sentences, and one can say that there are virtually no papers giving them an in-depth treatment. Therefore, we are so far left without a full insight into how widespread that compound sentence model is in contemporary Serbian and in what variants it occurs, not to mention our even lesser knowledge of its distribution in certain functional styles. This paper describes one type of asyndetic sentences in the contemporary Standard Serbian language. It includes such sentences that have a word or a phrase functioning as the verifier of the semantic relation between the clauses of asyndetic sentences. The paper demonstrates that such sentences take up a sizeable portion of the asyndetic sentence corpus, and {{that a large number of}} concretisers occur functioning as the verifiers of different meanings which are established between the clauses. The concretisers, similarly to conjunctions in syndetic sentences, serve the purpose of reducing the typical polysemy of asyndetic sentences to <b>monosemy</b> by assigning a monosemic relation between the clauses while foregrounding one of the possible meanings, and suppressing the others. The paper indicates that coordinate asyndetic sentences express a number of different semantic relations between the clauses. Some of them are expressed in complex sentences, some in compound sentences, and there are also those that can be expressed in both types of conjunctional sentences. The paper presents examples of sentences which have in their second clauses concretisers with conclusive, exclusive, temporal, adversative, causal, concessive, manner, spatial, gradational, respective and explanatory meanings. An array of subtypes occur within some of the types, depending on what semantic relation between the clauses is assigned by the concretisers. Finally, it is woth noting that this paper has more consistently solved the problem of exclusive and conclusive clauses as well. It is not well founded to place them among compound sentences because those sentences have their own conjunctions, whereas these are without conjunctions; it is also not well founded to classify them within some types of compound sentences because some of their classes stand out on account of characteristical conjunctions. Conclusive and exclusive clauses, as the paper demonstrates, are two types of asyndetic sentences with concretisers, the kind better represented in Serbian and which, in their entirety, are a model of asyndetic sentences. [Projekat Ministarstva nauke Republike Srbije, br. 178021 : Opis i standardizacija savremenog srpskog jezika...|$|E
40|$|Traditionally, the exegetical {{works of}} the later Latin Fathers {{have tended to be}} {{described}} and compared in terms of where they fit into the polarity between a literal or historical reading of Scripture on the one hand, and a spiritual or allegorical approach on the other. For {{a large part of the}} Twentieth Century, the tendency to understand patristic exegesis within the framework of the senses of Scripture was heavily preponderant among scholars, thanks in some measure to the influence of Henri de Lubac and others as well as existing patterns of reading the Fathers. More recently, scholarly interests have diversified, and patristic exegesis has been explored using a wider range of categories. However, concepts such as literalism and allegory still hold pride of place within the field as a whole, even if their preponderance has been substantially lessened in some respects over the past thirty years. Most reference and introductory-level works continue to be dominated by the same old framework, as are many major studies. The majority of monographs that would not go quite this far still give the senses of Scripture in some form or another a substantial place in their analysis. This thesis does not wish to deny that the relationship between the literal and spiritual senses should continue to occupy an important place in future scholarship  after all, this relationship is a substantial part of most patristic authors own, often explicit, conceptualisation of their exegetical work, as is well-attested. What it does seek to do is to question through a case-study whether the senses of Scripture ought to occupy quite the same central place that they do on the grounds of their usefulness to modern scholars in distinguishing between different exegetical styles. It argues that on questions of where particular authors sit on the literal-allegorical spectrum, the framework of the senses is not particularly helpful in the case of the later Latin Fathers because they all tend to be placed in roughly the same place: fundamentally literal, but with significant allegorical tendencies. This thesis therefore argues that what is needed are some additional categories within which the exegetical {{works of the}}se Fathers can be analysed, distinguished, and discussed. Through an examination of how four major Latin exegetes, Augustine, Jerome, Ambrose and Hilary, deal with the crucifixion and resurrection narratives at the ends of the Gospels, several such additional categories are developed. The most important of these is the lens focus of the interpreter: is he primarily focussed on philological details in the text, events and other realities described by (behind) the text, authorial perspectives before the text, or something else? Other useful points of comparison which emerge from this case-study include the extent to which each exegete tends towards polysemy (multiple interpretations of the same text) or <b>monosemy,</b> how ordered or otherwise the interpreter is in moving through his text, how free-ranging he is in his choice of comments on the biblical sentence at hand, whether he is inclined to focus on Scriptural prophecy-fulfilment relationships, and how interested he is in practically applying what he has gleaned from his reading to his audience. The thesis concludes that scholarship on the exegesis of the later Latin Fathers would significantly benefit if the senses of Scripture received a little less attention than they have in the past, relative to other factors such as those identified through this case study. Its chief limitation is that its observations and recommendations may not fit as closely to works on other parts of the Bible as they do to the Gospels...|$|E

