134|0|Public
5000|$|Enhanced Digital TV profile (EDTV) - {{includes}} the Structure, Layout, Media, Context, MediaContentAnchor, CompositeNodeInterface, PropertyAnchor, SwitchInterface, Descriptor, Linking, CausalConnectorFunctionality, ConnectorBase, TestRule, TestRuleUse, ContentControl, DescriptorControl, Timing, Import, EntityReuse, ExtendedEntityReuse, KeyNavigation, Animation, TransitionBase, Transition and <b>Metainformation</b> modules ...|$|E
50|$|Of all the {{versions}} of XHTML, XHTML Basic 1.0 provides the fewest features. With XHTML 1.1, {{it is one}} of the two first implementations of modular XHTML. In addition to the Core Modules (Structure, Text, Hypertext, and List), it implements the following abstract modules: Base, Basic Forms, Basic Tables, Image, Link, <b>Metainformation,</b> Object, Style Sheet, and Target.|$|E
50|$|Base16 or hex (not to be {{confused}} with Intel HEX and the like) is one of the simplest binary-to-text encodings, which stores each byte as a pair of hexadecimal digits. Many variations of such format are possible, for example either uppercase (A-F) or lowercase (a-f) letters may be used for digits greater than 9; spaces, line breaks or other separators may be added between digit groups of different lengths; header and/or footer with <b>metainformation</b> may be added.|$|E
5000|$|The overall {{objective}} of a data steward is data quality, {{in regard to}} the key/critical data elements existing within a specific enterprise operating structure, of the elements in their respective domains. This includes capturing/documenting (<b>meta)information</b> for their elements (such as: definitions, related rules/governance, physical manifestation, related data models, etc. With most of these properties being specific to an attribute/concept relationship), identifying owners/custodians/various responsibilities, relations insight pertaining to attribute quality, aiding with project requirement data facilitation and documentation of capture rules.|$|E
5000|$|The first lines contain <b>metainformation</b> such as {{the name}} of the chant, the {{appropriate}} place in the liturgy of the mass or the Liturgy of the Hours, the original source or the copyright of the score. Sung text and notes are not, as in Lilypond syntax, separated, but the notes are written in parentheses right after the corresponding syllable. A short overview of the syntax is provided by a cheat sheet. If both the TeX and the gabc file are in the same directory, one has just to compile the tex-file with [...]|$|E
50|$|Scientific {{data are}} {{archived}} with related <b>metainformation</b> in a relational database (Sybase) through an editorial system. Data are in Open Access and are distributed through web services in standard formats on the Internet through various search engines and portals. Data set descriptions (metadata) are {{conform to the}} ISO 19115 standard and are served in various further formats (e.g. Directory Interchange Format, Dublin Core). They include a bibliographic citation and are persistently identified using Digital Object Identifiers (DOI). Identifier provision and long-term availability of data sets via library catalogs is ensured through a cooperation with the German National Library of Science and Technology (TIB). Retrieval of data sets is provided through a full text search engine (based on Apache Lucene / panFMP). For efficient data compilations a data warehouse is operated. Data descriptions are available through various protocols (OAI-PMH, Web Catalog Service).|$|E
40|$|The {{following}} {{paper is}} a short explanation and overview {{of the work of}} the team together with Mr. Wolke, Mr. Yermashov and Mr. Rasenack presented at the same conference. We do not prefer source code as the basic definition of an application. Instead we use the ASLT as the basic view. For a first understanding, this is source code parsed into a tree form and stored permanent. Changes on the application definition during development normally take place in the ASLT. Two converters, java 2 aslt and aslt 2 java produce the ASLT or the source code. A tree is a much simpler form to do automatic code insertion into an existing application. There are further views into the application. They can be used as input. They are synchronized with the ASLT basic view. The tree form can support a special form of “comments” called <b>metainformation.</b> This <b>metainformation</b> can be attached to each node forming a node of its own. So <b>metainformation</b> can be attached to a <b>metainformation</b> node producing nested <b>metainformation.</b> The concept is supported by tools to access the ASLT, for example to insert a node, to remove it, to change its contents, to validate the type or to evaluate the <b>metainformation</b> and process it, maybe during design time, may be during runtime. These tools are called <b>metainformation</b> processing tools (MIPTs) ...|$|E
40|$|The {{objective}} of this thesis is to explore <b>metainformation</b> usage {{in order to achieve}} higher effectivity in pathfinding in the city, to choose the most suitable maps and methods for path search. Afterwards these functions are implemented to make a functional navigation system, which can use expanded <b>metainformation</b> contained in the chosen maps...|$|E
40|$|Abstract: In general, <b>metainformation</b> {{plays an}} {{important}} role in knowledge management for finding information. However, adding <b>metainformation</b> usually takes additional time. We work on WildDocs, a spatial-based knowledge management system. One of its main tasks is providing implicit <b>metainformation</b> that was added automatically during the structuring process without requiring a high cognitive load. This is supported by a detailed and less abstract structure model as well as by real world-based simulation of behavior. In this paper, we focus on emerging rotation, fixed sized documents, and binding mechanisms. We conclude that spatial structure techniques that consider physical limits and emerging structures may add important <b>metainformation</b> without significantly increased cognitive load on the user. We further point to our current and future implementation and the development of a special input device that supports efficient navigation on WildDocs’s space...|$|E
40|$|The state {{environmental}} information system LUIS BB, recently {{developed by the}} {{ministry for the environment}} of the federal state of Brandenburg/Germany, provides simple and efficient access to environmental information by a particular concept of service. This paper addresses the question of <b>metainformation</b> in a document-based approach, which was particularly fitted to the LUIS philosophy. The introduction of a document layer as carrier and mediator of <b>metainformation</b> provides an appropriate interface to the LUIS service implementations as well as to business processes and workflow systems. The corresponding environmental document definition language interconnects <b>metainformation</b> of the service provision with that of service usage on different abstraction levels...|$|E
40|$|Computer systems {{should provide}} what you want, {{when you want}} it (the WYWWYWI Principle, {{pronounced}} "why why why"), but they frequently do not. Our research encourages a new philosophy of design based on the WYWWYWI principle, and the tools for authors to provide this easily. Comprehensive <b>metainformation</b> embodies the WYWWYWI principle. <b>Metainformation</b> includes the structural relationships, content-based relationships, user-declared link-based relationships, and metadata around an element of interest. Combined, the <b>metainformation</b> {{goes a long way}} towards establishing the full semantics for (the meaning of and context around) a system's elements. We take a three-pronged approach to providing <b>metainformation</b> on a grand scale. First, we provide a systematic methodology for systems analysts to determine the relationships around elements of interest in their information domains [...] -Relationship Analysis. Relationship Analysis will result in a comprehensive set of a domain's structural relationships. Second, we provide a <b>Metainformation</b> Engine, which automatically generates sets of structural and content-based relationships around elements of interest as links, as well as metadata within static and virtual documents. Third, we provide an infrastructure for widespread link-based services within both static and virtual documents. This approach provides the inspiration as well as a sound foundation for a ubiquitous embracing of the WYWWYWI principle in the everyday systems people use, both on the Web and beyond...|$|E
3000|$|RootServer It manages all servers <b>metainformation</b> in an OceanBase cluster, {{as well as}} {{data storage}} location.|$|E
40|$|Information, {{as well as}} its qualifiers, or <b>metainformation,</b> {{forms the}} basis of human decisionmaking. Modeling human {{reasoning}} therefore requires the development of representations of both information and meta-information. However, while existing models and modeling approaches may include computational technologies that support meta-information analysis, they generally neglect its role in human reasoning. Herein, we describe the application of Bayesian Belief Networks to model how humans calculate, aggregate, and reason about <b>metainformation</b> when making decisions. 1...|$|E
40|$|The Digital Library Integration Infrastructure (DLII) {{provides}} a systematic lightweight approach for integrating digital library collections and services. Digital library systems generally require minimal or no changes to their code. Users see a totally integrated environment. They use their digital library system just as before. But in addition, they see extra link anchors. Selecting one generates {{a list of}} links to relevant <b>metainformation</b> (structural, content-based and knowledge-sharing relationships, and metadata). DLII generates {{the vast majority of}} supplemental link anchors and <b>metainformation</b> links automatically through the use of relationship rules. This paper presents the concept of <b>metainformation,</b> describes the DLII infrastructure and architecture, and explains how systems can integrate into the infrastructure. This research’s primary contribution is providing a relatively straightforward, sustainable infrastructure for integrating digital library collections and services...|$|E
40|$|The {{widespread}} use of the Internet {{as a source of}} information and pastime requires a reliable mechanism for filtering. Classification of Web pages {{is one of the most}} difficult stages of filtering. It should be borne in mind: html-structure, content and communication with other resources through hyperlinks. Particular attention should be paid to <b>metainformation,</b> that should reflect the basic keywords and a brief summary of Web pages. Classification of Web pages based on the <b>metainformation</b> is considered to be difficult because of the absence of clear boundaries between the communities of web documents. In this situation, it is necessary to use neural network classifiers...|$|E
40|$|The {{interdisciplinary}} {{interaction of}} bibliography with sociology, history, pedagogics, information science, and cultural studies is considered {{based on the}} information approach. Bibliography is shown to act as an indicator of social development {{as a part of the}} <b>metainformation</b> "layer" of society. © 2012 Allerton Press, Inc...|$|E
40|$|A dataset of <b>metainformation</b> of {{benign and}} malware Android samples {{used in the}} paper Martín, A., Calleja, A., Menéndez, H. D., Tapiador, J., & Camacho, D. (2016, December). ADROIT: Android malware {{detection}} using meta-information. In Computational Intelligence (SSCI), 2016 IEEE Symposium Series on (pp. 1 - 8). IEEE...|$|E
40|$|Approaches {{to dealing}} with <b>metainformation</b> in library {{digitisation}} projects are considered with respect to characteristics of defined elements. Some applications within projects being undertaken in Australia are described with reference to existing standards for resource description and vocabulary control, {{and the role of}} these within online cataloguing systems, and network interfaces...|$|E
40|$|We are {{concerned}} with the automatic semantic interpretation of legal modificatory provisions. We propose a novel approach which pairs deep syntactic parsing and a fine-grained taxonomy of legal modifications. Although still in a developmental stage, the implemented system can be used to annotate with <b>metainformation</b> modificatory provisions of NormaInRete documents...|$|E
40|$|The {{contribution}} introduces an adaptable {{process model}} {{to meet the}} special requirements of the coordination of planning activities in AEC (Architecture, Engineering, Construction). The process model {{is based on the}} concept of Coloured Petri-Nets and uses <b>metainformation</b> to characterize process-relevant information and to enable process-control based on the actual results of the planning. ...|$|E
40|$|Purpose of this diploma {{thesis is}} {{to design a}} data {{structure}} of The National Metadata Catalogue. This concept must allow an integration of outputs from other public administration <b>metainformation</b> systems. If this purpose is met, users can search for required data sources at one place. This design {{is based on the}} most important metadata standards, especially on standard ČSN ISO 19115 – Geographical information – metadata. A considerable attention is dedicated to definition of the term „metadata“ and to the practical examples of the metadata use. An important part of the thesis is also the analysis of the actual situation of public administration <b>metainformation</b> systems. Most important systems (MIS MŽP, MIDAS and SMS) are described in detail. Conclusion of the thesis is dedicated to the designing of The National Metadata Catalogue data structure according to the forementioned objectives...|$|E
40|$|Citation {{of legal}} {{authorities}} {{are an important}} part of legal documents. They can be used for improving the usability of legal databases and hypermedia-systems by working up the references into hyperlinks and by extracting <b>metainformation</b> about the content of the legal text. CITEXPERT is an expertsystem for automatically recognizing references to statutes in a legal text and for generating <b>metainformation</b> about and/or inserting hyperlinks into the legal text. In this system pattern recognition using regular expressions is used for searching for legal references. The regcognized patterns are analysed by rules depending on the different types of references. For assigning the found patterns to the legal rules referred to, a thesaurus of the names of statutes and commonly used short forms and terms of referring was built up. CITEXPERT is used for working up decisions of the Austrian Supreme Courts for legal databases. 1...|$|E
40|$|Presented {{research}} {{is intended for}} ontological identification of relevant specifications for semantic context integration of heterogeneous semistructured sources. <b>Metainformation</b> model is defined which includes uniform features for ontology, thesaurus and classifier modeling. Special technique for integration and mapping of different ontologies in this model is defined. The method for identification of specification element correlations in different contexts is considered...|$|E
40|$|To {{provide for}} {{interoperability}} of heterogeneous information objects it {{is required to}} establish a global, uniform view of the underlying digital collections and services. An information model is needed which is able to express uniformly the structure and semantics of heterogeneous data collections {{as well as the}} available services. Usually the mediator's layer is introduced to provide the users with the <b>metainformation</b> uniformly characterizing content of the underlying collections and with the canonical information model applied for definition of such <b>metainformation</b> and for querying integrated world of digital collections. The paper focuses on the canonical model intended for homogeneous representation of various semistructured and hybrid data models that have been developed recently with orientation on the data contained in Web sites. The paper provides a short overview of several representative semistructured and hybrid data models. The canonical information model (based on the SY [...] ...|$|E
40|$|The model MOVE 4 calculates {{the chance}} of {{occurrence}} of over 900 Dutch plant species for abiotic soil conditions and physical geographical region. In this report we describe how the model can be run (technical documentation). This includes <b>metainformation</b> of the model, borders applications of the model in projects etc. This document is produced {{within the framework of}} the quality status (i. e. quality assurance) of the model MOVE...|$|E
40|$|Gogol is a {{rule-based}} computer Go program. It uses a lot {{of reliable}} tactical rules. Tactical rules are rules about simple goals such as connecting and making an eye. Gogol uses a simplified game theory to represent the degree of achievement of the goals. The automatic acquisition of tactical rules follows a three step process: Pattern generation, Game evaluation, Generalisation. Gogol has <b>metainformation</b> about the correct use of the rules in global Go positions...|$|E
40|$|Mirrors are meta-level {{entities}} {{introduced to}} decouple reflection from the base-level system. Current mirror-based systems focus on functional decomposition of reflection. In this paper we advocate that mirrors should also address structural decomposition. Mirrors {{should not only}} be the entry points of reflective behavior but also be the storage entities of <b>metainformation.</b> This decomposition can help resolve issues in terms of resource constraints (e. g. embedded systems and robotics) or security. Indeed, structural decomposition enables discarding meta-information. 1...|$|E
40|$|EEA’s {{role as a}} Reference Centre for {{environmental}} information in Europe {{has been identified as}} one of the main priorities in the EEA’s Work Programme. This paper provides background information about the principle of public access to environmental information and details the EEA’s work towards launching the Reference Centre on Internet later this year. Main emphasis is placed on the importance of proper use of <b>metainformation</b> for organising the content of Web based environmental information services. ...|$|E
30|$|The CardSpace {{framework}} {{is based on}} the identification process we experience in the real world using physical identification cards. Within the CardSpace framework, an identity provider issues a user with a virtual card called InfoCard, which is an XML file containing (relatively) nonsensitive <b>metainformation</b> about the user. Subsequently, a user can use one of its InfoCards to help identify itself to any service provider who trusts the identity provider that issued the selected InfoCard. InfoCards can also be self-issued by the users themselves.|$|E
40|$|Abstract. We {{describe}} FCART software system, {{a universal}} integrated environment for knowledge and data engineers {{with a set}} of research tools based on Formal Concept Analysis. The system is intended for knowledge discovery from big dynamic data collections, including text collections. FCART allows the user to load structured and unstructured data (texts and various <b>metainformation)</b> from heterogeneous data sources, build data snapshots, compose queries, generate and visualize concept lattices, clusters, attribute dependencies, and other useful analytical artifacts. Full preprocessing scenario is considered...|$|E
40|$|The intermediator {{framework}} {{is required to}} support heterogeneous subject mediators interoperability in diverse world of mediation platforms that {{can be observed in}} distributed digital libraries and other areas. The intermediator framework based on the "local as view" mediation approach is introduced. The paper focuses on a protocol supporting registration of a mediator information (source) at another mediator. It is proposed to use a subset of OAI protocol to support such registration exchanging <b>metainformation</b> uniformly represented in the canonical model of the intermediator framework...|$|E
40|$|People {{have become}} used to paper as an {{information}} carrier {{over thousands of}} years. Paper is usually easy to handle and has been adopted {{as a metaphor for}} information structures in computer applications. This article gives a brief overview of our analysis on real world bindings. We further compare those to some metaphor-based spatial structure applications. We conclude that the high abstract implementation level in spatial structure applications takes away additional <b>metainformation</b> that may be useful for the user to find information quicker. Categories and Subject Descriptor...|$|E
40|$|This paper {{discusses}} {{the use of}} genre theory for analysing information content of structured documents and mixed media training material. We describe an analysis phase of an ongoing research aimed at information reuse from Operation and Maintenance (O&M) manuals in training, consisting of spoken, multimedia and textual content. The content of training was given the form of templates. We used them successfully for locating reusable information contents available from O&M manuals and other information sources. These templates can {{also serve as a}} basis for designing XML document type definitions (DTD's) for training content, or as draft versions of XSLT templates for defining reuse transformations from source to target documentation. While defining and hardening genres of training, we collected <b>metainformation</b> and knowledge the trainers possessed. We then formalised this as another set of genres for training. Based on our findings we suggest that genre theory can be used as 1) a framework for defining content within genres, 2) for revealing <b>metainformation</b> needed for enacting genres and 3) for locating reusable information contents from structured source documents. We also observed potential problems for reuse in scheduling of production processes and a need for demonstrating a single point of access to all training knowledge and material available...|$|E
40|$|A {{traditional}} approach to reasoning about the trustworthiness of a transaction {{is to determine}} the trustworthiness of the specific agent involved, based on its past behavior. As a departure from such traditional trust models, we propose a transaction centered trust model (MetaTrust) where an agent uses its previous transactions to assess the trustworthiness of a potential transaction based on associated <b>metainformation,</b> which is capable of distinguishing successful transactions from unsuccessful ones. This meta information is harnessed using a machine learning algorithm (namely, discriminant analysis) to extract relationships between the potential transaction and previous transactions...|$|E
40|$|In {{the last}} years, a GEneral Multilingual Environmental Thesaurus (GEMET) {{in all the}} {{languages}} of the EU-member states has been developed within the working program of the "European Topic Centre for Catalogue of Data Sources & Thesaurus " (ETC/CDS), European Environment Agency, (EEA). GEMET is meant to support indexing of metadata within the CDS system. At the same time, an environmental Thesaurus based on the Umwelt Thesaurus (UBA-Umweltbundesamt, Berlin) was produced in co-operation between Germany and Austria for their common <b>metainformation</b> system "Environmental Data Catalogue" (Umweltdatenkatalog, UDK). Austrian UDK a...|$|E
40|$|The {{workflow}} in data archiving {{is explained}} by using the information system PANGAEA© as an example. PANGAEA is an information system, operated as Open Access library for georeferenced data from basic research on earth and environment. Scientific primary data are archived with related <b>metainformation</b> and are distributed via webservices and accessible through various clients. An introduction is given on how to find data, how to compile larger data collections and finaly how to use visualization software to present those data. The required technology in the background is briefly explained (relational database, data warehouse, backup) ...|$|E
