4|10000|Public
40|$|Abstract. Selective laser melting (SLM) is {{a modern}} method for {{producing}} objects with complex shape and fine structures in one working cycle from metal powders. Combination of the advanced technology of SLM with unique properties of Ti 6 Al 4 V alloy allows creating complex 3 D objects for medicine or aerospace industry. Since properties of SLM parts depend on the geometrical characteristics of tracks and their cohesion, optical monitoring is actually used to for control the process. Temperature gradient determines the microstructure and mechanical properties of the SLM part, so studies about temperature fields are primarily important. On-line monitoring during laser scanning of Ti 6 Al 4 V alloy and formation of a single track in real-time with high-speed IR camera was studied. Numerical simulation allowed estimation the temperature distribution during processing. Conclusion regarding control system based on the online <b>monitoring</b> <b>of</b> <b>deviations</b> of the signal from IR camera during the SLM process was done...|$|E
40|$|This paper {{describes}} on-going {{research into}} strategic planning practices within British construction companies. The study {{focuses on the}} internal activities that contractors undertake to establish their corporate strategies. Previous studies of construction strategic planning have generally focused on either the analysis of industries trends, or corporate strategies as viewed from outside the construction organisation. The results of a preliminary survey and an extensive literature search have revealed that most construction contractors take an informal approach to planning in the long-term. A more systematic and formalised approach for undertaking such a planning exercise should bring about unity of purpose in the strategies, and also ensure improved <b>monitoring</b> <b>of</b> <b>deviations</b> and appropriate early actions. The research method combines both the primary methods of case studies, interviews and questionnaire surveys, with the secondary methods of academic and industry literary reviews; together with the analysis of specific corporate records to elicit information on the activities, participants and issues addressed in formulating strategic plans. An initial simple case study provides the background to the more robust interview surveys...|$|E
40|$|It is {{observed}} that general explicit guidance schemes exhibit numerical instability {{close to the}} injection point. This difficulty is normally attributed to the demand for exact injection which, in turn, calls for finite corrections to be enforced {{in a relatively short}} time. The deviations in vehicle state which need corrective maneuvers are caused by the off-nominal operating conditions. Hence, the onset of terminal instability depends on the type of off-nominal conditions encountered. The proposed separate terminal guidance scheme overcomes the above difficulty by minimizing a quadratic penalty on injection errors rather than demanding an exact injection. There is also a special requirement in the terminal phase for the faster guidance computations. The faster guidance computations facilitate a more frequent guidance update enabling an accurate terminal thrust cutoff. The objective of faster computations is realized in the terminal guidance scheme by employing realistic assumptions that are accurate enough for a short terminal trajectory. It {{is observed}} from simulations that one of the guidance parameters (P) related to the thrust steering angular rates can indicate the onset of terminal instability due to different off-nominal operating conditions. Therefore, the terminal guidance scheme can be dynamically invoked based on <b>monitoring</b> <b>of</b> <b>deviations</b> in the lone parameter P...|$|E
40|$|This article briefly {{describes}} the premises {{for the application}} of the standard direct cost calculation method in industry, the standard single cost calculation method, the stages of standard cost calculation per product and the calculation methods of standards per product. It also briefly underlines the possibilities of cost calculation and <b>monitoring</b> <b>of</b> <b>deviation</b> <b>of</b> the costs of raw materials and other materials as compared to the pre-established standard costs. Calculation method, standard direct cost method, accounting organisation, calculation <b>of</b> <b>deviation...</b>|$|R
30|$|The {{review of}} the {{relevant}} studies indicates that Phase-I variability <b>monitoring</b> <b>of</b> profiles in multistage processes involving the cascade property has not been investigated yet. As the performance <b>of</b> a profile <b>monitoring</b> scheme is highly dependent on the standard <b>deviation</b> <b>of</b> the error term in a regression model being used, this paper focuses on Phase-I <b>monitoring</b> <b>of</b> the standard <b>deviation</b> <b>of</b> a simple linear regression profile in a multistage process with cascade property. To this aim, based on Du and Zhang (2016) who discussed the joint <b>monitoring</b> <b>of</b> input and output of systems using autoregressive disturbances of arbitrary orders, a two-stage process is first modeled in this paper by an autoregressive model of order one, i.e., AR(1). Then, the shifts are applied on the standard <b>deviation</b> <b>of</b> a simple linear profile. Similar to Atashgar et al. (2014), three methods in Phase-I profile monitoring including the T 2 control chart proposed by Stover and Brill (1998), the T 2 scheme of Kang and Albin (2000), and the T 2 chart of Williams et al. (2007) are employed to investigate {{the effect of the}} cascade property. Eventually a new control chart based on the U statistic is proposed for Phase-I <b>monitoring</b> <b>of</b> the standard <b>deviation</b> in multistage processes. This statistic {{has been shown to be}} very effective to remove the effect of the cascade property (Kalaei et al. 2016).|$|R
40|$|Abstract—In the {{long-term}} evolution of software systems, various maintenance {{activities such as}} functionality extension, bug fixing, refactoring may positively or negatively {{affect the quality of}} design and implementation. The trend of quality degradation caused by negative affections may accumulate and cause serious difficulties for future maintenance of the software if they were not addressed properly in time. In this paper, we propose an approach for monitoring the degradation trends of software design in evolution and providing useful feedbacks for evolution decisions. The approach {{is based on the assumption}} that the deviations between different modularity views and their trends in evolution can be used to monitor the degradation trends of design. Currently, our approach considers three modularity views, namely package view, structural cluster view and semantic cluster view. Package view denotes the package structure reflecting the desired modularity view; Structural cluster view and semantic cluster view are the modularity views extracted from implementation by software clustering based on formal information and non-formal information, respectively. Then based on the three modularity views extracted from each version, our approach calculates the similarity between different views as the measurement <b>of</b> modularity <b>deviations,</b> and analyzes the deviation trends over a series of versions. We conduct an empirical study on three open-source systems, which confirms that continuous <b>monitoring</b> <b>of</b> <b>deviation</b> trends <b>of</b> modularity views can provide useful feedbacks for future evolution decisions. Keywords- evolution analysis, software quality evolution, software modulairty, software clustering, maintenance history I...|$|R
40|$|In {{this article}} we examine the {{state-of-the-art}} research related to digital media in education and evaluate the information concerning {{a new generation of}} students that are community-minded and technologically savvy, highlighting the innovative technology behind the new interaction and communication processes, and assessing the challenges for Open and Distance Learning (ODL). Where traditional distance education is based on the completion of carefully graded assignments and tests, today games, simulations and virtual environments may become safe platforms for trial and error experimentation. With games the chance of failure is high, but the cost is low and the lessons are learned immediately and with greater emotional impact. However, these conditions may become more difficult to address when the volume of users increases from small to medium, large or extra-large. Dealing effectively with tens or even hundreds of thousands of students in absentia requires following very sound organizational principles and good technical implementation, systematic <b>monitoring</b> <b>of</b> <b>deviations</b> from established norms, regular audition of users ' comments and criticisms, careful analysis of final results. In this emerging scenario, involving digital media, games and simulations, ODL systems must have means of establishing rich connections with each member of the universe of users. In this sense we propose using a virtual space with multiple places, in ways that use the Internet, social applications, games and mobile devices to involve students in pedagogical activities...|$|E
40|$|In this paper, {{we present}} the {{on-going}} {{work of the}} iNeighbour TV research project that aims to promote health care and social interaction among senior citizens, their relatives and caregivers. The TV set was the device chosen to mediate all the action, since it is a friendly device and one with which the elderly are used to interact. A study, conducted among the project’s target audience (TA), using a participatory design approach is addressed in the paper. Its purpose was to better characterize this type of users; identify relevant features; and evaluate usability and user interface requirements targeted to television (in an IPTV infrastructure). The analysis of the study results, which ensured the revision of the project’s features, is also presented along with a comprehensive description of the validated features. Some of these include: automatic user recognition system, medication reminder, <b>monitoring</b> system (<b>of</b> <b>deviations</b> from daily patterns), caregiver support, events planning, audio calls {{and a set of}} tools to promote community service. PTDC/CCI-COM/ 100824 / 200...|$|R
40|$|Reactor noise analysis, {{based upon}} the <b>monitoring</b> <b>of</b> the <b>deviations</b> <b>of</b> {{typically}} the neutron flux from its mean value, has for objectives a) the early detection of anomalies before they have any inadvertent effect on plant safety and availability and b) the determination of dynamical core parameters. Because noise analysis is a non-intrusive technique, {{it can be used}} on-line while the reactor is running at nominal full power conditions. One of the challenges of noise diagnostics is nevertheless to be able to recover from very few neutron detector signals the nature and characteristics of the driving perturbation, localize it, and classify the severity of the anomaly. This requires competences in many areas, such as reactor physics and dynamics, reactor modelling, stochastic processes, signal analysis, and measurement techniques. This paper represents an attempt to pay a tribute to Dr. Pázsit’s seminal work on power reactor noise at the occasion of the special session organized in his honor at M&C 2017. Emphasis will be put on the development of innovative methods that resulted in industrial demonstrations at commercial nuclear power stations. The subjects covered hereafter are: the <b>monitoring</b> <b>of</b> control rod vibrations, the characterization and localization of anomalies, the diagnostics of BWR instabilities and the diagnostics of core barrel vibrations...|$|R
40|$|OBJECTIVES This study {{sought to}} report {{long-term}} changes of cardiac autonomic control by continuous, device-based <b>monitoring</b> <b>of</b> the standard <b>deviation</b> <b>of</b> the averages of intrinsic intervals in the 288 five-min segments of a day (SDANN) and of heart rate (HR) profile in heart failure (HF) patients treated with cardiac resynchronization therapy (CRT). BACKGROUND Data on long-term changes of time-domain parameters of heart rate variability (HRV) and of HR in highly symptomatic HF patients treated with CRT are lacking. METHODS Stored data were retrieved for 113 HF patients (New York Heart Association functional class III to TV, left ventricular ejection fraction 120 ms) receiving a CRT device capable of continuous assessment of HRV and HR profile. RESULTS The CRT induced a reduction of minimum HR (from 63 +/- 9 beats/min to 58 +/- 7 beats/min, p 0...|$|R
40|$|International audienceDamage {{detection}} consists <b>of</b> <b>monitoring</b> the <b>deviations</b> <b>of</b> {{a current}} system from its reference state, characterized by some nominal property repeatable for every healthy state. Preferably, the damage detection is performed directly on vibration data, hereby avoiding modal {{identification of the}} structure. The practical aspect of using only the output measurements cause difficulties because of variations in ambient excitation due to variability in the environmental conditions, like sea, wind, and temperature. In this paper, a new Mahalanobis distance-based damage detection method is studied and compared to the well-known subspace-based damage detection algorithm {{in the context of}} two large case studies. Both methods are implemented in the modal analysis and structural health monitoring software ARTeMIS, in which the joint features of the methods are concluded in a control chart in an attempt to enhance the resolution of the damage detection. The damage indicators from both methods are evaluated based on the ambient vibration signals from numerical simulations on a novel offshore support structure and experimental example of a full scale bridge. The results reveal that the performance of the two damage detection methods is similar, hereby implying merit of the new Mahalanobis distance-based approach, as it is less computational complex. The fusion of the damage indicators in the control chart provides the most accurate view on the progressively damaged systems...|$|R
40|$|Although {{techniques}} for the short-term control of end-tidal gases exist, {{the lack of}} a satisfactory technique for longer-term control of the end-tidal gases has limited protracted physiological experiments of this nature. We have constructed a chamber in which subjects can be comfortable for many hours while having their end-tidal gas composition monitored and controlled. The system for controlling the end-tidal gas composition is based on a principle described by Swanson and Bellville (J. Appl. Physiol. 39 : 377 - 385, 1975) in which end-tidal PO 2 (PETO 2) and PCO 2 (PETCO 2) are <b>monitored</b> and <b>deviations</b> <b>of</b> the actual PETO 2 and PETCO 2 (PETCO 2) are <b>monitored</b> and <b>deviations</b> <b>of</b> the actual PETO 2 and PETCO 2 from the desired values are corrected by a feedback mechanism that adjusts the inspired gas composition accordingly. End-tidal and inspired gas tensions are measured via a nasal catheter connected to a mass spectrometer. A computer averages the end-tidal and inspired gas tensions and, at 5 -min intervals, adjusts the gas composition inside the chamber. During 8 h of isocapnic hypoxia, the system held the 5 -min average value for PETO 2 within 2 Torr of the desired value (55 Torr) and the value for PETCO 2 within 0. 35 Torr of the desired value (the resting value for each subject) in four subjects...|$|R
40|$|Damage {{detection}} consists <b>of</b> <b>monitoring</b> the <b>deviations</b> <b>of</b> {{a current}} system from its reference state, characterized by some nominal property repeatable for every healthy state. Preferably, the damage detection is performed directly on vibration data, hereby avoiding modal {{identification of the}} structure. The practical aspect of using only the output measurements cause difficulties because of variations in ambient excitation due to variability in the environmental conditions, like sea, wind, and temperature. In this paper, a new Mahalanobis distance-based damage detection method is studied and compared to the well-known subspace-based damage detection algorithm {{in the context of}} two large case studies. Both methods are implemented in the modal analysis and structural health monitoring software ARTeMIS, in which the joint features of the methods are concluded in a control chart in an attempt to enhance the resolution of the damage detection. The damage indicators from both methods are evaluated based on the ambient vibration signals from numerical simulations on a novel offshore support structure and experimental example of a full scale bridge. The results reveal that the performance of the two damage detection methods is similar, hereby implying merit of the new Mahalanobis distance-based approach, as it is less computational complex. The fusion of the damage indicators in the control chart provides the most accurate view on the progressively damaged systems...|$|R
40|$|One {{possible}} {{approach for}} {{the determination of}} new maintenance inspection schedules in the case <b>of</b> operational load <b>monitoring</b> is presented. Emphasis is laid on fatigue critical structural items. The method {{is based on the}} assumption that required safetyfactors may be reduced, if the actual load history is known from individual monitoring. As an example the method has been applied to an existing widebody aircrafi type. Key words: operational load monitoring, maintenance NOTATION range factor, indicating the influence of the range of flights on the damage required safety factor with respect to fatigue life required safety factor in the case of individual operational load monitoring required safety factor without individual oper-ational load <b>monitoring</b> standard <b>deviation</b> <b>of</b> load spectra standard <b>deviation</b> <b>of</b> S-N data total probability of failure probability of failure from S-N data...|$|R
40|$|ObjectivesThis study {{sought to}} report {{long-term}} changes of cardiac autonomic control by continuous, device-based <b>monitoring</b> <b>of</b> the standard <b>deviation</b> <b>of</b> the averages of intrinsic intervals in the 288 five-min segments of a day (SDANN) and of heart rate (HR) profile in heart failure (HF) patients treated with cardiac resynchronization therapy (CRT). BackgroundData on long-term changes of time-domain parameters of heart rate variability (HRV) and of HR in highly symptomatic HF patients treated with CRT are lacking. MethodsStored data were retrieved for 113 HF patients (New York Heart Association functional class III to IV, left ventricular ejection fraction ≤ 35 %, QRS > 120 ms) receiving a CRT device capable of continuous assessment of HRV and HR profile. ResultsThe CRT induced a reduction of minimum HR (from 63 ± 9 beats/min to 58 ± 7 beats/min, p 0 %) four weeks after CRT initiation. ConclusionsCardiac resynchronization therapy is able to significantly modify the sympathetic-parasympathetic interaction to the heart, as defined by HR profile and HRV. Lack of HRV improvement four weeks after CRT identifies patients at higher risk for major cardiovascular events...|$|R
40|$|It is {{demonstrated}} experimentally {{that through the}} use of feedback control, it is possible to stabilize the no-motion (conductive) state of a fluid layer confined in a circular cylinder heated from below and cooled from above (the Rayleigh-Bénard problem), thereby postponing the transition from a no-motion state to cellular convection. The control system utilizes multiple sensors and actuators. The actuators consist of individually controlled heaters microfabricated on a silicon wafer which forms the bottom of the test cell. The sensors are diodes installed at the fluid 2 ̆ 7 s midheight. The sensors <b>monitor</b> the <b>deviation</b> <b>of</b> the fluid temperatures from preset, desired values and direct the actuators to act {{in such a way as}} to eliminate these deviations...|$|R
40|$|In this paper, a {{strategy}} is proposed for alternative computations {{of the residual}} vectors in Krylov subspace methods, which improves the agreement of the computed residuals and the true residuals {{to the level of}} O(u) #A##x#. Building on earlier ideas on residual replacement and on insights in the finite precision behavior of the Krylov subspace methods, computable error bounds are derived for iterations that involve occasionally replacing the computed residuals by the true residuals, and they are used to <b>monitor</b> the <b>deviation</b> <b>of</b> the two residuals and hence to select residual replacement steps, so that the recurrence relations for the computed residuals, which control the convergence of the method, are perturbed within safe bounds. Numerical examples are presented to demonstrate the e#ectiveness of this new residual replacement scheme...|$|R
40|$|Novelty {{detection}} is {{the identification}} <b>of</b> <b>deviations</b> from a training set. It {{is suitable for}} <b>monitoring</b> the health <b>of</b> mechanical systems where it usually {{is impossible to know}} every potential fault. In this paper, two novelty detectors are presented. The first detector which integrates One-Class Support Vector Machine (OCSVM) with an incremental clustering algorithm is designed for health <b>monitoring</b> <b>of</b> the turbopump, while the second one which is trained on sensor fault samples is designed to recognize faults from sensors and faults actually from the turbopump. Analysis results showed that these two detectors are both sensitive and efficient for the health <b>monitoring</b> <b>of</b> the turbopump...|$|R
40|$|Integrating {{multiple}} fuzzy {{expert systems}} under restricting requirements Integrace mnohonásobných fuzzy expertních systémů za omezujících podmínek S. ALY, I. VRANA Czech University of Agriculture, Prague, Czech Republic Abstract: The multiple, different and specific expertises are often needed in making YES-or-NO (YES/NO) decisions for treating {{a variety of}} business, economic, and agricultural decision problems. This {{is due to the}} nature of such problems in which decisions are influenced by multiple factors, and accordingly multiple corresponding expertises are required. Fuzzy expert systems (FESs) are widely used to model expertise due to its capability to model real world values which are not always exact, but frequently vague, or uncertain. In addition, they are able to incorporate qualitative factors. The problem of integrating multiple fuzzy expert systems involves several independent and autonomous fuzzy expert systems arranged synergistically to suit a varying problem context. Every expert system participates in judging the problem based on a predefined match between problem context and the required specific expertises. In this research, multiple FESs are integrated through combining their crisp numerical outputs, which reflect the degree of bias to the Yes/No subjective answers. The reasons for independency can be related to maintainability, decision responsibility, analyzability, knowledge cohesion and modularity, context flexibility, sensitivity of aggregate knowledge, decision consistency, etc. This article presents simple algorithms to integrate multiple parallel FES under specific requirements: preserving the extreme crisp output values, providing for null or non-participating expertises, and considering decision-related expert systems, which are true requirements of a currently held project. The presented results provides a theoretical framework, which can bring advantage to decision making is many disciplines, as e. g. new product launching decision, food quality tracking, <b>monitoring</b> <b>of</b> suspicious <b>deviation</b> <b>of</b> the business processes from the standard performance, tax and customs declaration issues, control and logistic of food chains/networks, etc...|$|R
40|$|In a job-shop environment, {{achieving}} a schedule {{that is on}} target is difficult due to the dynamism of factors affecting the system. In this paper the Shewart's Individuals control chart is applied to a scheduling process {{for the purpose of}} measuring schedule performance. The charts are applied to <b>monitor</b> the <b>deviations</b> <b>of</b> actual from scheduled process times for jobs on a process machine. Data transformation operations are used to counter the negative effects of non-normal data. The proposed methodology enables a scheduler study the variations between scheduled and actual outcomes, seek ways of eliminating these variations and check if process improvements have been effective. SPC charts have not been used to measure schedule performance in a job shop setting, so this paper uniquely contributes to research within the field. schedule performance measurement; SPC; statistical process control; control charts; job shop scheduling; data transformation...|$|R
40|$|The {{feasibility}} of controlling flow patterns of Rayleigh–Bénard convection in a fluid layer confined {{in a circular}} cylinder heated from below and cooled from above (the Rayleigh-Bénard problem) is investigated numerically. It is demonstrated that, {{through the use of}} feedback control, it is possible to stabilize the no-motion (conductive) state, thereby postponing the transition from a no-motion state to cellular convection. The control system utilizes multiple sensors and actuators. The actuators consist of individually controlled heaters positioned on the bottom surface of the cylinder. The sensors are installed at the fluid 2 ̆ 7 s midheight. The sensors <b>monitor</b> the <b>deviation</b> <b>of</b> the fluid 2 ̆ 7 s temperatures from preset desired values and direct the actuators to act in such a way so as to eliminate these deviations. The numerical predictions are critically compared with experimental observations...|$|R
40|$|This work explores how {{extended}} {{modeling of}} sensors and robot motion {{can be used}} to improve Markov localization by <b>monitoring</b> <b>deviations</b> <b>of</b> actual measurements from expected sensor readings. By comparing target and actual motions of robot joints, proprioception is achieved yielding a quality measure for the current odometry. a quality measure for odometry that helps differentiate periods of unhindered motion from periods where robot motion was impaired for whatever reason. By negative information we denote the absence of an expected sensor reading. Negative information is seldom used in localization because it yields less information than positive information (i. e. sensing a landmark) and a sensor often fails to detect a landmark, even if it falls within its sensing range. We address these difficulties by carefully modeling the sensor to avoid false negatives. In real world experiments, we are able to demonstrate that a robot is able to localize in positions where without the use of negative information it could not. ...|$|R
40|$|Abstract: Sensor {{system of}} the belt {{conveyor}} is designed, then corrective and alarm command is given. According to the signal <b>of</b> real-time <b>monitoring,</b> belt <b>deviation</b> state is determined, and roller axis position is adjusted {{in order to achieve}} the purpose <b>of</b> <b>deviation</b> – adjusting. Based on dynamic <b>monitoring</b> <b>of</b> the belt conveyor, corrective devices are constructed, and hydraulic servo system model is designed by Matlab software in this paper, then the stability of the system is analyzed...|$|R
40|$|This paper {{discusses}} {{design of}} a suhue control monitoring system in stirred tank heater system that has an important function in industrial processes. <b>Monitoring</b> <b>of</b> suhue control system in stirred tank heater is designed using Supervisory Control and Data Acquisition (SCADA) that control function of industrial processes. While the actuator to be controlled is the position of burner openings, so that the heat can be adjusted to meet a predetermined set-point. The suhue controller that is also used as a Remote Terminal Unit (RTU) is Programmable Logic Controller (PLC). The testing result showed on SCADA system was quite good, where the average percentage <b>of</b> <b>deviation</b> for testing <b>of</b> set-point data was 0. 76687 %, and the percentage <b>of</b> <b>deviation</b> for testing <b>of</b> suhue data was 0. 082 %...|$|R
40|$|This paper {{presents}} a unique method <b>of</b> <b>monitoring</b> the effectiveness <b>of</b> {{the planning process}} {{as well as the}} execution of mine plans. The method primarily determines the degree <b>of</b> <b>deviation</b> from the original mine plans by comparing actual mined areas to initially planned mining areas. The performance of mining operations is also measured by comparing actual and planned tonnages for a particular period. Once the degree <b>of</b> <b>deviation</b> from mine plans has been established the cause/s <b>of</b> the <b>deviation</b> can be determined through a simple fault tree analysis. Accurate identification of the reasons <b>of</b> <b>deviation</b> can aid the mine in selecting possible methods to correct the deviation. It is, however, {{beyond the scope of this}} paper to discuss the methods employed in correcting such deviations, as each mining operation will have unique causes <b>of</b> plan <b>deviation</b> and methods <b>of</b> remedying them. <b>Deviations</b> from the plan greatly affect the yields obtainable, which in turn affects the life of mine, thus having negative economic and financial implications. Accordingly, this paper {{presents a}} project management method which aims to reduce risk by improving planning systems to ensure optimum overall extraction of coal reserves...|$|R
40|$|Many Web based {{learning}} experiences fail due to bad or absent support. LMSs (learning management systems) must incorporate mechanisms for real time <b>monitoring</b> <b>of</b> {{the involvement of}} each participant in a course, allowing the detection <b>of</b> <b>deviations</b> to the scheduled activities, enabling the correction <b>of</b> these <b>deviations</b> (Ramos et al., 2001). The principal standardization projects in the area do not cover this type of aspects. Those projects are mainly focused on contents and their delivery to the learners participating in the courses. This article describes a proposal of a reference model and functionalities towards a specification of a layer for real-time management of user interactions with SCORM (sharable content object reference model) compliant LMSs...|$|R
40|$|Quality of {{machined}} {{products is}} often {{related to the}} shapes of surfaces that are constrained by geometric tolerances. In this case, statistical quality monitoring {{should be used to}} quickly detect unwanted deviations from the nominal pattern. The majority of the literature has focused on statistical profile monitoring, while there is little research on surface monitoring. This paper faces the challenging task of moving from profile to surface monitoring. To this aim, different parametric approaches and control-charting procedures are presented and compared with reference to a real case study dealing with cylindrical surfaces obtained by lathe turning. In particular, a novel method presented in this paper consists of modeling the manufactured surface via Gaussian processes models and <b>monitoring</b> the <b>deviations</b> <b>of</b> the actual surface from the target pattern estimated in phase I. Regardless of the specific case study in this paper, the proposed approach is general and can be extended to deal with different kinds of surfaces or profiles...|$|R
40|$|The VLT {{data flow}} {{operations}} of XSHOOTER covers {{the generation of}} flux calibrated science spectra. A new component to maintain and overview this process is the <b>monitoring</b> <b>of</b> the spectral response function. We describe the of the XSHOOTER flat field spectrum and response function in terms <b>of</b> <b>deviation</b> from reference calibrations. the new scheme {{the stability of the}} response function and the impact of operational constraints like the frequent exchange of flat lamps is now monitored. This demonstrates the benefit for the quality assurance of the science spectra. ...|$|R
40|$|International audienceThe work {{presented}} in this paper concerns the <b>monitoring</b> <b>of</b> software processes using a fuzzy logic based approach. The proposed monitoring for software processes focuses on the detection <b>of</b> <b>deviations</b> with respect to given models. The level <b>of</b> <b>deviation</b> is computed for different aspects of the process like progress, cost, structure (order between activities), etc. The proposed approach is implemented by the OMEGA environment (OMEGA stands for On-line Monitoring Environment: General and Adaptable). The environment provides a language for defining monitoring models. Such models are executed by the environment's engine. Fuzzy sets theory is used in the representation of the information handled by monitoring systems, and possibility theory in the reasoning upon it. Fuzzy logic offers significant advantages over other approaches due to its ability to naturally represent uncertain and imprecise information. It equally provides a good framework for approximate reasoning. The use <b>of</b> the proposed <b>monitoring</b> environment is illustrated {{in the context of the}} Unified Software Development Process...|$|R
40|$|The study {{deals with}} linear methods of {{summation}} of Fourier series. The work {{is aimed at}} deriving asymptotic equalities <b>of</b> <b>deviations</b> <b>of</b> linear mean Fourier series on generalized Gelder classes. Asymptotic equalities <b>of</b> <b>deviations</b> <b>of</b> linear mean Fourier series on generalized Gelder classes are received. Asymptotic equalities <b>of</b> <b>deviations</b> <b>of</b> Abel-Poisson operators on generalized Gelder classes are receivedAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|Abstract. A {{monitoring}} system is developed to visualize and {{to control the}} process of Selective Laser Melting (SLM) of metallic powder. The system is integrated with industrial PHENIX PM- 100 machine. Visualization is carried out using LED illumination and CCD-camera; a home developed pyrometer is applied for <b>monitoring</b> <b>of</b> thermal phenomena in the zone <b>of</b> laser impact. <b>Deviation</b> <b>of</b> temperature from its optimal value is chosen as a criterion for the express method of quality control...|$|R
40|$|The study {{deals with}} the problem of {{investigation}} of the behaviour of upper bounds <b>of</b> <b>deviations</b> <b>of</b> polynomials caused by the linear methods from continuous periodical functions. The work is aimed at obtaining asymptotic equalities for upper bounds <b>of</b> <b>deviations</b> <b>of</b> linear mean Fourier series by classes of continuous (psi, beta) -differential functions. Asymptotic equalities are received for <b>deviations</b> <b>of</b> linear mean Fourier series from the functions of classes of continuous periodical (psi, beta) -differential functions. Asymptotic behaviour of upper bounds <b>of</b> <b>deviations</b> <b>of</b> the Favar sums from the functions of classes of continuous periodical (psi, beta) -differential functions is studiedAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|The article {{offers a}} complex of key {{instruments}} of management of operation activity of a small business trade enterprise, including: 1) budgeting of operation activity; 2) its accounting by norms and deviations from them; 3) <b>monitoring</b> <b>of</b> operational activity of an enterprise, which envisages analysis <b>of</b> revealed <b>deviations.</b> The article shows {{the most efficient way}} of realisation and practical use of the presented concept – application of the “standard-cost” scheme within the framework of which the following tasks are solved: 1) budgeting of income from operational activity; 2) establishment of standards of costs; 3) accumulation of data on factual income and expenditures; 4) analysis <b>of</b> <b>deviations</b> and reporting; and 5) introduction of necessary amendments. The article also offers an imitation model of analysis of dynamics of trade processes, which allows detection of key spheres of management of operation activity of a small trade enterprise and principles of carrying out an efficient and well thought over financial policy...|$|R
40|$|Inaccuracies, or deviations, in the {{measurements}} <b>of</b> <b>monitored</b> variables in a control system are {{facts of life}} that control software must accommodate [...] -the software {{is expected to continue}} functioning correctly {{in the face of an}} expected range <b>of</b> <b>deviations</b> in the inputs. Deviation analysis can be used to determine how a software specification will behave in the face <b>of</b> such <b>deviations</b> in data from the environment. The idea is to describe the correct values of an environmental quantity, along with a range <b>of</b> potential <b>deviations,</b> and then determine the effects on the outputs of the system. The analyst can then check whether the behavior of the software is acceptable with respect to these deviations. In thi...|$|R
40|$|Problem Multinational {{companies}} play {{a significant}} role in the globalized economy. In this context, the trade-off between standardization and localization of practices and strategies is an issue that meaningfully influences the success of such companies abroad. This particularly applies to the field of human resource development (HRD). Purpose The purpose of this study was to explore the processes of a HRD measure of an internationally operating cooperation and how it was translated in the local context. Based on Kirkpatrick’s (1994) training evaluation model the effectiveness of the implementation was also elucidated. Methodology A qualitative research design was chosen for this explanatory study to investigate one single case. Thus, 28 semi-structured interviews were conducted with various stakeholders and themes were generated though a deductive analysis. Results The study exemplified that contextual circumstances, individual ideas, and goals of multiple stakeholders affected the transfer of the standardized training program. A deficiency in communication and <b>monitoring</b> facilitated <b>deviations</b> <b>of</b> the original training targets. The results were coherent with the translation theory and supported its utilization in future research. The findings can likely offer valuable recommendations for effective standardized training programs...|$|R
40|$|Post-translational {{modifications}} of proteins expand {{the diversity of}} the proteome by several orders of magnitude and {{have a profound effect on}} several biological processes. Their detection by experimental methods is not free of limitations such as the amount of sample needed or the use of destructive procedures to obtain the sample. Certainly, new approaches are needed and, therefore, we explore here the feasibility of using 13 C chemical shifts of different nuclei to detect methylation, acetylation and glycosylation of protein residues by <b>monitoring</b> the <b>deviation</b> <b>of</b> the 13 C chemical shifts from the expected (mean) experimental value of the non-modified residue. As a proof-of-concept, we used 13 C chemical shifts, computed at the DFT-level of theory, to test this hypothesis. Moreover, as a validation test of this approach, we compare our theoretical computations of the 13 Cε chemical-shift values against existing experimental data, obtained from NMR spectroscopy, for methylated and acetylated lysine residues with good agreement within ∼ 1 ppm. Then, further use of this approach to select the most suitable 13 C-nucleus, with which to determine other modifications commonly seen, such as methylation of arginine and glycosylation of serine, asparagine and threonine, shows encouraging results...|$|R
