33|90|Public
500|$|Wainwright {{observed}} {{while driving}} {{in his car}} that [...] "it [...] be funny to redo this as a song cycle". Soon afterwards, he took the idea to New York-based theatrical producer Jared Geller (who would later co-produce the tribute concert with David Foster), hoping to turn a dream into a reality. Geller initially thought the idea was [...] "insane", but he and Wainwright continued discussing options. Eventually, Geller agreed {{to assist with the}} production and the two found space in Wainwright's schedule to book Carnegie Hall a year in advance. Once the venue was booked, staging elements such as lighting, <b>microphone</b> <b>location</b> and amplification were discussed. Stephen Oremus signed on as the conductor of the 36-piece orchestra and Phil Ramone took charge of the recording. Rehearsals began in April 2006, and while {{it would have been easier}} to practice in rehearsal rooms, large theaters such as the Lynch at the John Jay College of Criminal Justice and the Museum of Jewish Heritage were utilized because [...] "Rufus wanted a feel for performing this material on a stage". As a result of financial restrictions, full orchestra rehearsals took place only two days before the show and the day of each performance (practice with smaller groups of instruments began a few months before the concerts).|$|E
50|$|Devices {{equipped}} with various sensors have become ubiquitous. Most smartphones can sense ambient light, noise (through the <b>microphone),</b> <b>location</b> (through the GPS), movement (through the accelerometer), and more. These sensors can collect {{vast quantities of}} data that are useful {{in a variety of}} ways. For example, GPS and accelerometer data can be used to locate potholes in cities, and microphones can be used with GPS to map noise pollution.|$|E
5000|$|Wainwright {{observed}} {{while driving}} {{in his car}} that [...] "it would be funny to redo this as a song cycle". Soon afterwards, he took the idea to New York-based theatrical producer Jared Geller (who would later co-produce the tribute concert with David Foster), hoping to turn a dream into a reality. Geller initially thought the idea was [...] "insane", but he and Wainwright continued discussing options. Eventually, Geller agreed {{to assist with the}} production and the two found space in Wainwright's schedule to book Carnegie Hall a year in advance. Once the venue was booked, staging elements such as lighting, <b>microphone</b> <b>location</b> and amplification were discussed. Stephen Oremus signed on as the conductor of the 36-piece orchestra and Phil Ramone took charge of the recording. Rehearsals began in April 2006, and while {{it would have been easier}} to practice in rehearsal rooms, large theaters such as the Lynch at the John Jay College of Criminal Justice and the Museum of Jewish Heritage were utilized because [...] "Rufus wanted a feel for performing this material on a stage". As a result of financial restrictions, full orchestra rehearsals took place only two days before the show and the day of each performance (practice with smaller groups of instruments began a few months before the concerts).|$|E
40|$|Two {{impedance}} eduction {{methods are}} explored {{for use with}} data acquired in the NASA Langley Grazing Flow Impedance Tube. The first is an indirect method based on the convected Helmholtz equation, {{and the second is}} a direct method based on the Kumaresan and Tufts algorithm. Synthesized no-flow data, with random jitter to represent measurement error, are used to evaluate a number of possible <b>microphone</b> <b>locations.</b> Statistical approaches are used to evaluate the suitability of each set of <b>microphone</b> <b>locations.</b> Given the computational resources required, small sample statistics are employed for the indirect method. Since the direct method is much less computationally intensive, a Monte Carlo approach is employed to gather its statistics. A comparison of results achieved with full and reduced sets of <b>microphone</b> <b>locations</b> is used to determine which sets of <b>microphone</b> <b>locations</b> are acceptable. For the indirect method, each array that includes microphones in all three regions (upstream and downstream hard wall sections, and liner test section) provides acceptable results, even when as few as eight microphones are employed. The best arrays employ microphones well away from the leading and trailing edges of the liner. The direct method is constrained to use microphones opposite the liner. Although a number of arrays are acceptable, the optimum set employs 14 microphones positioned well away from the leading and trailing edges of the liner. The selected sets of <b>microphone</b> <b>locations</b> are also evaluated with data measured for ceramic tubular and perforate-over-honeycomb liners at three flow conditions (Mach 0. 0, 0. 3, and 0. 5). They compare favorably with results attained using all 53 <b>microphone</b> <b>locations.</b> Although different optimum <b>microphone</b> <b>locations</b> are selected for the two impedance eduction methods, there is significant overlap. Thus, the union of these two microphone arrays is preferred, as it supports usage of both methods. This array contains 3 microphones in the upstream hard wall section, 14 microphones opposite the liner, and 3 microphones in the downstream hard wall section...|$|R
30|$|Source {{separation}} is being actively studied for signal processing. Some methods use {{the source and}} <b>microphone</b> <b>locations.</b> Delay-and-sum beamforming and null beamforming are methods that emphasize or suppress the signal from a specific direction. These methods can be implemented with less computational complexity. HARK uses geometric higher-order decorrelation-based source separation (GHDSS) [9]. GHDSS separates mixed signals by using a higher-order decorrelation between the sound source signals and geometric constraints derived from the positional relationships among the microphones. The weak point of these methods is that they require the source and <b>microphone</b> <b>locations.</b> This prior information cannot easily be obtained in advance.|$|R
40|$|Broadband {{microphone}} arrays play {{an important}} role for noise reduction in various applications, such as voice interface equipment or hands-free telephony. For most cases, it is essential to design the beamformer so that certain spatial and frequency features can be extracted and the rest being attenuated. For the method to be data-independent, a physical signal propagation model can be deployed and the optimization problem can be posed. In this paper, this design problem is studied. Robust minimax designs are considered. We will study the sensitivity of the designs towards uncertainties in the parameters, including speaker positions and <b>microphone</b> <b>locations.</b> We found that the optimal design is not very sensitive to speaker position perturbations, but is affected significantly if <b>microphone</b> <b>locations</b> are indeed erroneous. © 2011 IEEE. link_to_subscribed_fulltex...|$|R
40|$|A {{computer}} user's manual {{describing the}} operation and the essential features of the <b>microphone</b> <b>location</b> program is presented. The <b>Microphone</b> <b>Location</b> Program determines microphone locations that ensure accurate and stable results from the equation system used to calculate modal structures. As part of the computational procedure for the <b>Microphone</b> <b>Location</b> Program, a first-order measure of {{the stability of the}} equation system was indicated by a matrix 'conditioning' number...|$|E
40|$|Two {{computer}} programs help analyst meet low-noise limits on turbofan engines. <b>Microphone</b> <b>Location</b> Program computes optimum locations in turbofan duct for placement of microphones. After tests in first program are run, acoustic phase, amplitude, and pressure {{are used as}} inputs in Modal Calculation Program...|$|E
30|$|In this paper, we have {{presented}} a diversity technique that combines the processed signals of several separate microphones. The aim of our approach was noise robustness for in-car hands-free applications, because single channel noise suppression methods {{are sensitive to}} the <b>microphone</b> <b>location</b> and in particular to the distance between speaker and microphone.|$|E
40|$|In this paper, {{the design}} of {{distributed}} broadband beamforming system is studied. In the configuration, we assume that each microphone is equipped with wireless communications capability. Once their mutual distance information is collected, localization techniques {{can be used to}} estimate the <b>microphone</b> <b>locations.</b> A broadband beamformer can then be designed such that the error between the actual response and the desired response is minimized. However, due to variations in the estimated <b>microphone</b> <b>locations,</b> robust design with uncertainties must be considered. This problem is formulated as a minimax optimization problem, which is then transformed into a semi-definite programming problem so that interior point algorithms can be applied. We illustrate the proposed method by several designs and show that the algorithm is robust and efficient. © 2012 ICIC International. link_to_subscribed_fulltex...|$|R
30|$|Two {{acoustical}} phenomena {{associated with}} gunfire will be exploited {{to determine the}} shooter's position: the muzzle blast and the shock wave. The principle is to detect and time stamp the phenomena as they reach microphones distributed over an area, and let the shooter's position be estimated by, in a sense, the most likely point, considering the <b>microphone</b> <b>locations</b> and detection times.|$|R
40|$|The {{infrasonic}} signatures {{generated by}} the main blade slap rate of a helicoper were used {{in an effort to}} detect infrasound generated by clear air turbulence. The artificially produced infrasound and the response of the data acquisition system used are analyzed. Flight procedures used by the pilot are described and the helicopter flight information is tabulated. Graphs show the relative frequency amplitudes obtained at various <b>microphone</b> <b>locations...</b>|$|R
40|$|A {{computer}} user's manual {{describing the}} operation and the essential features of the Modal Calculation Program is presented. The modal Calculation Program calculates the amplitude and phase of modal structures by means of acoustic pressure measurements obtained from microphones placed at selected locations within the fan inlet duct. In addition, the Modal Calculation Program also calculates the first-order errors in the modal coefficients that are due to tolerances in <b>microphone</b> <b>location</b> coordinates and inaccuracies in the acoustic pressure measurements...|$|E
40|$|The {{purpose of}} this study is to obtain a basic data on layout of the trawlers’bridge equipment. The task {{activities}} of bridge workers involved in the navigation and fishing operation were analyzed by link analysis methods. The results are as follows. It was found that the movement pattern and frequency of bridge workers are different accordance with the bridge work (navigation, casting net, towing net and hauling net). The central workstation of movement of the bridge workers was a radar workstation, a steering workstation and a trawl winch workstation in the bridge work. But the radar did not show up as the center of movement during the hauling net. Workstations related deeply to the central workstations of the movement on the bridge were as below. Radar workstation was related to a GPS plotter, a <b>microphone</b> <b>location</b> for external communication with VHF and MF/HF equipment and a steering in the case of the navigation, the steering, the GPS plotter and the net monitor in the case of the fishing operation. Steering workstation was related deeply to the GPS plotter, the radar in the case of the navigation, a speed controller, the GPS plotter, a fish finder, the net monitor and the <b>microphone</b> <b>location</b> i...|$|E
40|$|In this paper, {{we present}} a {{microphone}} array beamforming approach to blind speech separation. Unlike previous beamforming approaches, our system does not require a-priori knowledge of the microphone placement and speaker location, making the system directly comparable other blind source separation methods which require no prior knowledge of recording conditions. <b>Microphone</b> <b>location</b> is automatically estimated using an assumed noise field model, and speaker locations are estimated using cross correlation based methods. The system is evaluated on the data provided for the PASCAL Speech Separation Challenge 2 (SSC 2), achieving a word error rate of 58 % on the evaluation set...|$|E
40|$|The {{purpose of}} this pilot study was to record, characterize, and {{quantify}} road maintenance activity in Mexican spotted owl (Strix occidentalis lucida) habitat to gauge potential sound level exposure for owls during road maintenance activities. We measured sound levels from three different types of road maintenance equipment (rock crusherlloader, dozerlroller, and grader), from seven distances (30, 60, 120, 180, 240, 320, and 400 m), in two different habitat types (forested and meadow sites) on the Lincoln National Forest, New Mexico, on 22 - 23 October 2002 to determine how sound varied over distance, habitat type, topography, and stimulus type. Sound levels increased as the distance between road maintenance activity and <b>microphone</b> <b>locations</b> decreased, regardless of stimulus type or habitat type. Concomitantly, the amount of sound energy within the middle frequency range decreased substantially with increasing stimulus distance from <b>microphone</b> <b>locations.</b> The frequency range over which owls can potentially hear road maintenance events decreased with increasing stimulus distance. Sound recordings of road maintenance equipment were louder at tree microphones than at base microphones, regardless of stimulus distance, stimulus type, and site location...|$|R
40|$|Features {{required}} to produce test section acoustic properties which allow the acoustic signature of propulsion systems to be measured are discussed for NASA's Altitude Wind Tunnel. A combination of both analytical and experimental methods are used to identify and reduce background noises as well as critiquing wind tunnel design in terms of acoustic requirements. Acoustic capabilities of the wind tunnel, key personnel, and drawings of <b>microphone</b> <b>locations</b> are presented in viewgraph format...|$|R
40|$|This is the author’s {{version of}} a work that was {{accepted}} for publication in the journal, Applied Acoustics. Changes resulting from the publishing process, such as peer review, editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may {{have been made to}} this work since it was submitted for publication. A definitive version was subsequently published at: [URL] it is possible to determine the effect over a wide frequency range of different aperture devices on the sound field in a duct, the contribution from the individual higher-order modes must be established. Two approaches to decompose the sound field may be taken which are either to use a large number of <b>microphone</b> <b>locations</b> to reconstruct the sound field, or to use a hybrid method involving a reduced set of <b>microphone</b> <b>locations</b> and a model of the sound field in the system. Modelling the higher-order modes in a duct is itself a numerically intensive procedure if fully coupled calculations are required. It is possible to simplify the process for modelling the sound field by using uncoupled calculations for the higher order modes. Results are presented for such a hybrid approach, combining a limited number of <b>microphone</b> <b>locations</b> with an uncoupled model, to establish the sound field in a circular duct. Both point source and plane wave sources are considered and direct measurement of the sound field is compared to the reconstructed field for a normalised wave number range up to 7. Results show acceptable agreement between the hybrid approach and direct measurement with the greatest errors occurring around cut-on of the axially anti-symmetric modes. Thus, it is demonstrated that a hybrid approach may be applied to ducts with simple sources and that the approach can be used to deconstruct the in-duct sound field into the individual higher-order mode contribution...|$|R
30|$|Additionally, a {{distributed}} sensing algorithm, {{running on}} the geolocation database, combines data coming from the sensor nodes (energy detection vs. position) to detect the presence of PMSE devices and provide an estimative of its location. The algorithm {{is based on a}} logical OR operation to combine information from each sensor. If one or more sensors detect an active wireless microphone, the geolocation database engine computes an estimate of the wireless <b>microphone</b> <b>location</b> through triangulation and creates an exclusion area around it; furthermore, the corresponding DVB-T channel is removed from the list of available channels for that area [22], until the next sensing campaign does not detect WM activity.|$|E
40|$|Measurement of the {{acoustical}} insulation of building facades requires simultaneous measurement of sound pressure levels indoors and outdoors, {{but there is}} still some question as to the best location for the outdoor microphone. This paper reports the differences between sound pressure levels at 2 m from a facade and at its surface, for a series of measurements at 33 different houses. The mean results compare well with a modified line source model, and suggest that a 3 dB correction between measurement locations is appropriate on average, except at low frequencies. The variation in the results, from house to house, suggests that establishing a single preferred outdoor <b>microphone</b> <b>location</b> is desirable. Peer reviewed: YesNRC publication: Ye...|$|E
40|$|Aerodynamic {{noise from}} the rod wake-airfoil {{interactions}} at M= 0. 2 and Re_D= 46, 000 is computed by solving the linearized perturbed compressible equations (LPCE), with the acoustic source and hydrodynamic flow variables computed from the incompressible LES. A 2 D LPCE calculation is conducted at zero spanwise wave-number (k_z= 0) with an assumption of statistical homogeneity in the spanwise direction. Then, a 2 D Kirchhoff method is used to extrapolate the sound field at the acoustic far-field boundary (40 D) up to the <b>microphone</b> <b>location</b> (185 D away from the airfoil chord center). Finally, a power spectrum density (PSD) for actual span (30 D) is predicted by Oberais correction method for 3 D spectral acoustic pressure and spanwise coherence function for the wall pressure. The computational results for flow and acoustics are critically validated with the experimental data measured at the Ecole Centrale de Lyon...|$|E
40|$|Results for the {{vibration}} measured at five locations on the fuselage structure during static operations are presented. The analysis {{was concerned with}} the magnitude of {{the vibration}} and the relative phase between different locations, the frequency response (inertance) functions between the exterior pressure field and the vibration, and the coherent output power functions at interior <b>microphone</b> <b>locations</b> based on sidewall vibration. Fuselage skin panels near the plane of rotation of the propeller accept propeller noise excitation more efficiently than they do exhaust noise...|$|R
40|$|We {{describe}} a new method for sound analysis using a spherical microphone array {{without the use}} of quadrature over the sphere. Quadrature based solutions are very sensitive to the placement of microphones on the sphere, needing measurements to be made at exactly the quadrature positions. We propose to use fitting with band-limited radial basis functions (RBFs) rather than quadrature. Our approach results in frequency independent beamformer weights for flexibly placed <b>microphone</b> <b>locations.</b> Results are demonstrated using both synthetic and real spherical array data. 1...|$|R
30|$|The sound {{activity}} represents {{whether or}} not sound is active in each time frame. This sound activity estimation enables sound detection. The system estimates the source activities of K source signals and separates the D mixed signals captured by the microphones into K sources without prior information, such as <b>locations,</b> <b>microphone</b> <b>locations,</b> and impulse responses between sound sources and microphones. The first assumption means that this system deals with a determined or over-determined problem. The second assumption means that the mixing process from the sources to the microphones is unchanged.|$|R
40|$|We {{address the}} problem of <b>microphone</b> <b>location</b> {{calibration}} where the sensor positions have a sparse spatial approximation on a discretized grid. We characterize the microphone signals as a sparse vector represented over a codebook of multi-channel signals where the support of the representation encodes the microphone locations. The codebook is constructed of multi-channel signals obtained by inverse filtering the acoustic channel and projecting the signals onto a array manifold matrix of the hypothesized geometries. This framework requires that the position of a speaker or the track of its movement to be known without any further assumption about the source signal. The sparse position encoding vector is approximated by model-based sparse recovery algorithm exploiting the block-dependency structure underlying the broadband speech spectrum. The experiments conducted on real data recordings demonstrate the effectiveness of the proposed approach and the importance of the joint sparsity models in multi-channel speech processing tasks...|$|E
40|$|Results are {{presented}} for an analytical {{study of the}} accuracy and limitations of a technique that permits the mathematical extrapolation of near-field noise data to far-field conditions. The effects of the following variables on predictive accuracy of the far-field pressure were examined: (1) number of near-field microphones; (2) length of source distribution; (3) complexity of near-field and far-field distributions; (4) source-to-microphone distance; and (5) uncertainties in microphone data and imprecision in {{the location of the}} near-field microphones. It is shown that the most important parameters describing predictive accuracy are the number of microphones, the ratio of source length to acoustic wavelength (L/lambda), and the error in location of near-field microphones. For maximum <b>microphone</b> <b>location</b> errors of plus or minus 1 cm, only an accuracy of plus or minus 2. 5 dB can be attained with approximately 40 microphones for the highest L/lambda of 10...|$|E
30|$|Our earlier {{proposed}} system, {{presented in}} [15], {{is similar to}} the Dolphin system [2], except that it adopts trilateration instead of multilateration and audible sound instead of an ultrasound signal. The system deploys four tweeters and aims to locate a microphone. Two methods have been proposed. The first method uses four combinations of three of the four measured distances to generate four estimates of the <b>microphone</b> <b>location.</b> The resulting position is the center point of the four estimates. The second method uses the three most reliable distances for the computation of the microphone position. In [15], the first method was adopted and the system gives accuracy of 2 cm with 99 % precision. Inspired from [15], a novel acoustic localization system was presented in [16]. The system is a receiver localization system that uses CDMA operation. It differs from the system described in [15] in that it uses the fingerprinting technique instead of lateration. It deploys three tweeters and computes the microphone position through nonparametric kernel regression.|$|E
40|$|In {{this paper}} {{we present a}} {{methodology}} for the self-calibration of microphone arrays using Times Of Ar-rival of acoustic signals produced by acoustic sources. Geometric constraints are derived from the measure-ments of the Times Of Arrival. <b>Microphone</b> <b>locations</b> are then found by combining the geometric constraints. When multiple arrays {{are present in the}} acoustic scene, in many applications the knowledge of their mutual po-sitions is required. If a priori information about the ge-ometry of the array is given, the same framework can be easily adapted to infer the mutual positions of the ar-rays. Some experimental results and simulations prove the accuracy of the current work. 1...|$|R
40|$|An {{investigation}} has been conducted, {{with the objective}} of creating a database of inputs that can be used with noise prediction software, to evaluate noise of aircraft taxing movements and community noise exposure levels. The acoustic consultant can use these data with any of the software packages, to simulate taxing, by moving point source. ISO 3744 Standard is used, to estimate sound power levels emitted by a noise source and helps in describing a procedure based on sound pressure level measurements in a free field over a reflecting surface. The main steps that are involved in the procedure, include a measurement surface grid needs to be defined, to envelope the noise source and linear averaged third octave band spectra needs to be measured for all <b>microphone</b> <b>locations...</b>|$|R
25|$|A {{direct field}} is {{generated}} by audio drivers arranged to encircle the test article. Two different control schemes {{can be used to}} perform a direct field test. One method, known as single-input-single-output or SISO, uses a single drive signal to all acoustic drivers with multiple control microphones averaged to produce the control measurement. This method will produce a set of correlated plane waves that may combine to produce large magnitude variations creating local fluctuations on the test article surface. Magnitude variations as much as +/−12dB can be experienced. The second method, known as MIMO, uses multiple independent drive signals to control multiple independent <b>microphone</b> <b>locations.</b> This method produces a more uncorrelated field that is much more uniform than the SISO field. Magnitude variations in the range of +/-3dB are typical when using MIMO control.|$|R
40|$|Abstract — In {{this paper}} design of quiet zones in {{broadband}} diffuse fields has been present {{by using the}} method of acoustic pressure minimization over various spaces and frequencies. The technique is squared acoustic pressure minimization. The theory and simulations of pressure minimization over space and frequency using two-channel and three-channel systems are presented. The work {{presented in this paper}} is {{the second part of the}} study and we focus on diffuse primary fields with two and three secondary sources. The first part of the study concerned with a plane wave primary field only. A constrained minimization of pressure is also introduced in this paper, to control pressure at various spaces and frequencies. The results show that a good attenuation is achieved at the <b>microphone</b> <b>location</b> or desired range over space and frequency using a two-channel system. However, a better performance could be achieved using a three-channel system. Index Terms—active control system, broad-band diffuse fields, acoustic pressure, diffuse primary fields, constrained minimization. I...|$|E
40|$|When a {{microphone}} array {{is mounted on}} a mobile aerial platform, such as an unmanned aerial vehicle (UAV), most existing beamforming methods cannot be used to adequately identify continuous and impulsive ground. Here, numerical simulation results and laboratory experiments are presented that validate a proposed time-frequency beamforming method based on the Multiple Signal Classification (MUSIC) algorithm to detect these acoustic sources from a mobile aerial platform. In the numerical simulations three parameters were varied to test the proposed algorithm?s location estimation performance: 1) the acoustic excitation types; 2) the moving receiver?s simulated flight conditions; and 3) the number of acoustic sources. Also, a distance and angle error analysis was done to quantify the proposed algorithm?s source location estimation accuracy when considering microphone positioning uncertainty. For experimental validation, three laboratory experiments were conducted. Source location estimations were done for: a 600 Hz sine source, a banded white noise source between 700 - 800 Hz, and a composite source combined simultaneously with both the sine and banded white noise sources. The proposed algorithm accurately estimates the simulated monopole?s location coordinates no matter the excitation type or simulated trajectory. When considering simultaneously-excited, multiple monopoles at high altitudes, e. g. 50 m, the proposed algorithm had no error when estimating the source?s locations. Finally, a distance and angle error analysis exposed how relatively small <b>microphone</b> <b>location</b> error, e. g. 1 cm maximum error, can propagate into large averaged distance error of about 10 m in the far-field for all monopole excitation types. For all simulations, however, the averaged absolute angle error remained small, e. g. less than 4 degrees, even when considering a 5 cm maximum <b>microphone</b> <b>location</b> error. For the laboratory experiments, the sine source had averaged distance and absolute angle errors of 0. 9 m and 14. 07 degrees from the source?s true location, respectively. Similarly, the banded white noise source?s averaged distance and absolute angle errors were 1. 9 m and 47. 14 degrees; and lastly, the averaged distance and absolute angle errors of 0. 78 m and 8. 14 degrees resulted when both the sources were simultaneously excited...|$|E
40|$|DOI: 10. 3397 / 1 / 376207 To {{accurately}} characterise {{the noise}} {{measured in the}} vicinity of wind farms, outdoor microphones must be adequately protected from the wind. A standard 90 mm windshield is appropriate for measurements in light winds; however, as the wind speed increases, wind-induced pressure fluctuations contribute to the measured sound pressure level, leading to erroneous data. Three alternative secondary windshields have been developed and tested in an outdoor environment and evaluated for their ability to allow low frequency noise and infrasound measurements to be obtained in the presence of wind. Performance evaluation is facilitated through analysis of high resolution spectra as well as analysis of the coherence between microphones with different windshields under various meteorological conditions. This enables a distinction to be made between noise originating from sources such as a wind farm and wind-induced noise. The effect of the <b>microphone</b> <b>location</b> with respect to the ground surface has also been investigated for frequencies up to 100 Hz. Kristy Hansen, Branko Zajamšek and Colin Hanse...|$|E
40|$|A {{study was}} {{conducted}} to determine the applicability of using small-scale powered helicopter models operating in nonanechoic wind tunnels to predict the sound pressure levels of full-scale rotor harmonic noise components. The investigation included noise generation due to high-tip-speed effects, tandem-rotor blade/vortex interactions, single rotors operating on test towers, and the interaction between main rotor vortices and tail rotors. In all cases {{it was found that the}} pressure time history waveforms characteristic of different noise-generating mechanisms were properly reproduced by the models. Corrections for <b>microphone</b> <b>locations,</b> acoustical reverberation, and tunnel wind velocity were developed. Application of these corrections to the model data were found to yield satisfactory correlation with full-scale sound pressure levels except for the isolated single rotor, where highly transient data, both model and full-scale, recluded good agreement of absolute values...|$|R
40|$|We {{propose a}} novel {{algorithm}} to design an optimum array geometry for source localization inside an enclosure. We assume a square-law decay propagation {{model for the}} sound acquisition so that the additive noise on the measured source-microphone distances {{is proportional to the}} distances regardless of the noise distribution. We formulate the source localization as an instance of the “Generalized Trust Region Subproblem ” (GTRS) whose solution gives the location of the source. We show that by suitable selection of the <b>microphone</b> <b>locations,</b> one can tremendously decrease the noise-sensitivity of the resulting solution. In particular, by minimizing the noise-sensitivity of the source location in terms of sensor positions, we find the optimal noise-robust array geometry for the enclosure. Simulation results are provided to show the efficiency of the proposed algorithm. Index Terms – Robust microphone placement, Source localization, Generalized Trust Region Subproblem (GTRS). 1...|$|R
40|$|ICASSP 2008 : IEEE International Conference on Acoustics, Speech, and Signal Processing, March 30 - April 4, 2008, Las Vegas, Nevada, USA. We {{propose a}} robust and fast dereverberation {{technique}} for real-time speech recognition application. First, we effectively identify the late reflection {{components of the}} room impulse response. We use this information together {{with the concept of}} spectral subtraction (SS) to remove the late reflection components of the reverberant signal. In the absence of the clean speech in actual scenario, approximation is carried out in estimating the late reflection where the estimation error is corrected through multi-band SS. The multi-band coefficients are optimized during offline training and used in the actual online dereverberation. The proposed method performs better and faster than the relevant approach using multi-LPC and reverberant matched model. Moreover the proposed method is robust to speaker and <b>microphone</b> <b>locations...</b>|$|R
