10|692|Public
40|$|In this paper, {{we present}} a GLRT-based {{adaptive}} detection algorithm for extended targets with improved rejection capabilities of mismatched signals. We assume that a set of secondary data is available and that noise returns in primary and secondary data share the same statistical characterization. To increase the selectivity of the detector, similarly to the ABORT formulation, we modify the hypothesis testing problem at hand introducing fictitious signals under the null hypothesis. Such unwanted signals {{are supposed to be}} orthogonal to the nominal steering vector in the whitened observation space. The performance assessment, carried out by Monte Carlo simulation, shows that the proposed dectector ensures better rejection capabilities of mismatched signals than existing ones, at the price of a certain loss in terms of detection of <b>matched</b> <b>signals...</b>|$|E
40|$|Chalcogenide glasses such as arseic sulfide(As 2 S 3) have {{attracted}} attention for {{applications such as}} all-optical switching in high speed communication. This is due to their high non-linear refractive-index. Z-scan and the Degenerate four wave mixing (DFWM) techniques {{can be used to}} measure the non-linear refractive index n 2 and the two photon absorption coefficient β. A simaltanous closed-aperture and open-aperture Z-scan experimental set up was used to obtain the experimental results. The results were then fitted into a theoretical formula. Values of n 2 = 3 × 10 - 17 m 2 /W and β= 0. 29 cm/GW have been obtained. DFWM measurements were made on arsenic sulfide films. A Box-cars forward geometry was used in these measurements. Experimental results based on non-phase <b>matched</b> <b>signals</b> were again fitted into a theoretical formula and a value of n 2 = 3. 9 × 10 - 17 m 2 /W was obtained...|$|E
40|$|International audienceWe {{consider}} the classical radar problem of detecting a target in Gaussian noise with unknown covariance matrix. In {{contrast to the}} usual assumption of deterministic target amplitudes, we assume here that the latter are drawn from a Gaussian distribution. The generalized likelihood ratio test (GLRT) is derived based on multiple primary data {{and a set of}} secondary data containing noise only. The new GLRT is shown to be the product of Kelly's GLRT and a corrective, data dependent term. We also investigate two-step approaches where the GLRT for a known disturbance covariance matrix is first derived. In order to come up with detectors that provide a good tradeoff between detection of <b>matched</b> <b>signals</b> and rejection of mismatched signals, we also investigate the two-step GLRT when a fictitious signal is included in the null hypothesis. The constant false alarm rate properties of the detectors are analyzed. Numerical simulations are presented, which show that for small sample sizes the newly-proposed GLRT can outperform Kelly's GLRT and, in addition, that detectors including a fictitious signal are very powerful, at least for low-to-intermediate clutter to noise ratio values...|$|E
40|$|Neural IR models, such as DRMM and PACRR, have {{achieved}} strong results by successfully capturing relevance <b>matching</b> <b>signals.</b> We {{argue that the}} context of these <b>matching</b> <b>signals</b> is also important. Intuitively, when extracting, modeling, and combining <b>matching</b> <b>signals,</b> one would like to consider the surrounding text (local context) {{as well as other}} signals from the same document that can contribute to the overall relevance score. In this work, we highlight three potential shortcomings caused by not considering context information and propose three neural ingredients to address them: a disambiguation component, cascade k-max pooling, and a shuffling combination layer. Incorporating these components into the PACRR model yields Co-PACRR, a novel context-aware neural IR model. Extensive comparisons with established models on Trec Web Track data confirm that the proposed model can achieve superior search results. In addition, an ablation analysis is conducted to gain insights into the impact of and interactions between different components. We release our code to enable future comparisons. Comment: To appear in WSDM 201...|$|R
50|$|This <b>match</b> <b>signalled</b> the {{reversal}} of {{a long period of}} decline for Villa. Ten years later they were champions of England and the following year they had become the champions of Europe.|$|R
50|$|Recognition memory, a {{subcategory}} of declarative memory, is {{the ability}} to recognize previously encountered events, objects, or people. When the previously experienced event is reexperienced, this environmental content is matched to stored memory representations, eliciting <b>matching</b> <b>signals.</b>|$|R
40|$|A Matlab {{simulation}} {{was developed}} to help visualise and investigate electromagnetic tunnelling through particular non-dissipative and dissipative barriers within a waveguide. The theory behind the simulation {{is based on a}} transmission line model that accurately predicts experimental results and is shown to be equivalent to previous numerical and quantum tunnelling models. A few useful speeds referring to electromagnetic waves have been defined and utilised to calculate die speeds at which different incident time signals penetrate electromagnetic barriers. Due to bandwidth restrictions, the created incident time signals had wavepacket properties. The importance of resampling an oscillating signal at the appropriate frequency to avoid aliasing has been recognised. The definition and creation of <b>matched</b> <b>signals</b> that can penetrate long barriers yet remain a single pulse have been investigated. Such signals will have no practical application since the attenuation will deem the transmitted signals immeasurable. However, the speeds through these larger barrier lengths will have a smaller uncertainty since the time delays are longer. Most of the signal distortion depends only on the barrier interfaces rather than the barrier length. Penetration through dissipative barriers gives speeds below the vacuum speed of light for all barrier lengths investigated. Faster than light speeds are however predicted for penetration through non-dissipative barriers greater than about 4 cm...|$|E
40|$|International audienceMagnetic field {{measurements}} {{from the four}} Cluster spacecraft from the mid- and high-altitude cusp are presented. Cluster underwent two encounters with the mid-altitude cusp during its commissioning phase (24 August 2000). Evidence for field-aligned currents (FACs) {{was seen in the}} data from all three operating spacecraft from northern and southern cusps. The extent of the FACs was of the order of 1 R E in the X -direction, and at least 300 km in the Y -direction. However, fine-scale field structures with scales of the order of the spacecraft separation (300 km) were observed within the FACs. In the northern crossing, two of the spacecraft appeared to lie along the same magnetic field line, and observed very well <b>matched</b> <b>signals.</b> However, the third spacecraft showed evidence for structuring transverse to the field on scales of a few hundred km. A crossing of the high-altitude cusp from 13 February 2001 is presented. It is revealed to be a highly dynamic structure with the boundaries moving with velocities ranging from a few km/s to tens of km/s, and having structure on timescales ranging from less than one minute up to several minutes. The cusp proper is associated with the presence of a very disordered magnetic field, which is entirely different from the magnetosheath turbulence...|$|E
40|$|Magnetic field {{measurements}} {{from the four}} Cluster spacecraft from the mid- and high-altitude cusp are presented. Cluster underwent two encounters with the mid-altitude cusp during its commissioning phase (24 August 2000). Evidence for field-aligned currents (FACs) {{was seen in the}} data from all three operating spacecraft from northern and southern cusps. The extent of the FACs was of the order of 1 RE in the X-direction, and at least 300 km in the Y-direction. However, fine-scale field structures with scales of the order of the spacecraft separation (300 km) were observed within the FACs. In the northern crossing, two of the spacecraft appeared to lie along the same magnetic field line, and observed very well <b>matched</b> <b>signals.</b> However, the third spacecraft showed evidence for structuring transverse to the field on scales of a few hundred km. A crossing of the high-altitude cusp from 13 February 2001 is presented. It is revealed to be a highly dynamic structure with the boundaries moving with velocities ranging from a few km/s to tens of km/s, and having structure on timescales ranging from less than one minute up to several minutes. The cusp proper is associated with the presence of a very disordered magnetic field, which is entirely different from the magnetosheath turbulence. Key words. Magnetospheric physics (current systems; magnetopause, cusp, and boundary layers) – Space plasma physics (discontinuities...|$|E
40|$|International audienceThis paper {{proposes a}} vibration-induced micro-Doppler {{estimation}} method for oscillating targets in {{synthetic aperture radar}} (SAR) images using azimuth time-frequency tracking and a <b>matched</b> <b>signal</b> transform. The approach involves an azimuth defocusing of the SAR image in order to access the phase history. The tracking in azimuth is based on local polynomial phase modeling using as estimator for the polynomial coefficients the high-order ambiguity function. The vibration frequency is obtained from the spectrum of the tracked instantaneous frequency law, while the oscillation amplitude is estimated using a <b>matched</b> <b>signal</b> transform. The procedure is tested by simulations and on real SAR images acquired by the TerraSAR-X satellite over the Puylaurent water-dam in France...|$|R
40|$|ABSTRACT: Raising {{the level}} of {{abstraction}} for synthetic biology design requires solving several challenging problems, including mapping abstract designs to DNA sequences. In this paper we present the first formalism and algorithms to address this problem. The key steps of this transformation are feature <b>matching,</b> <b>signal</b> <b>matching,</b> and part matching. Feature matching ensures that the mapping satisfies the regulatory relationships in the abstract design. <b>Signal</b> <b>matching</b> ensures that the expression levels of functional units are compatible. Finally, part matching finds a DNA part sequence that can implement the design. Our software tool MatchMaker implements these three steps...|$|R
40|$|Abstract—We {{propose a}} time–frequency (TF) {{technique}} designed to <b>match</b> <b>signals</b> with multiple and different characteristics for successful analysis and classification. The method uses a modified <b>matching</b> pursuit <b>signal</b> decomposition incorporating signal-matched dictionaries. For analysis, {{it uses a}} combination of TF representations chosen adaptively to provide a concentrated representation for each selected signal component. Thus, it exhibits maximum concentration while reducing cross terms for the difficult analysis case of multicomponent signals of dissimilar linear and nonlinear TF structures. For classification, this technique may provide the instantaneous frequency of signal components as well as estimates of their relevant parameters. Index Terms—Classification, matching pursuit, time–frequency. I...|$|R
40|$|The {{derivation}} {{of structural}} {{characteristics of a}} compound of unknown structure from its spectral data is a central procedure for modern structure elucidation. Computer searching in spectral libraries of fully-assigned 13 C NMR spectra of substructures or full structures {{is an essential part}} of structure elucidation and has been widely applied because this type of spectra reflects the nature of the skeletal backbone of an organic compound, information not as readily available by other spectroscopic techniques [1]. In this paper we describe an extensive test of a previously developed method for interpretive search in spectral libraries of fully-assigned 13 C NMR spectra [2]. The method is implemented into a Windows-based user-friendly program, called Infer C NMR. The program input consists of the 13 C NMR spectrum of the unknown compound (chemical shift and multiplicity of each signal) and molecular formula. The search algorithm retrieves a list of connected substructures from the reference compounds in such a way that only atoms with <b>matched</b> <b>signals</b> are included into the inferred substructures. The substructures are explicitly defined in terms of atom type, hydrogen multiplicity, and bond type. They are presented embedded into the reference structures and are sorted according to their reliability (estimation of their correctness, usually called accuracy). This accuracy is calculated by a multivariate function that was obtained in advance by comprehensive statistics. The parameters that restrict the search algorithm are the tolerance of signal matching (Tol) in ppm and the minimum number of carbon atoms in the inferred (retrieved) substructures (m. n. c.); the latter is set to six for this study...|$|E
40|$|Thesis (MScEng (Mechanical and Mechatronic Engineering)) [...] University of Stellenbosch, 2009. Percussion is a {{centuries old}} bedside {{diagnostic}} technique {{that is used}} to diagnose various conditions of the thorax and abdomen, among these, abnormalities of the liver. The physician taps the patient’s skin in the area of interest to determine the qualities or presence of the underlying tissue or organ, by listening to the generated sound. The research contained in this thesis views percussion as a system identification method which uses an impulse response to identify the underlying system. A design employing an electromagnetic actuator as input pulse generator and accelerometer as impulse response recorder was motivated and built. Tests were performed on volunteers and the recorded signals were analysed to find methods of identifying the presence of the liver from these signals. The analyses <b>matched</b> <b>signals</b> to models or simply extracted signal features and matched these model parameters or signal features to the presence of the liver. Matching was done using statistical pattern recognition methods and the true presence of the liver was established using MR images. Features extracted from test data could not be matched to the presence of the liver with sufficient confidence which led to the conclusion that either the test, apparatus or analysis was flawed. The lack of success compelled a further test on a mock-up of the problem – a silicone model with an anomaly representing the organ under test. Results from these tests showed that signals should be measured further from the actuator and the approach followed during this test could lead to the successful location of the anomaly and discrimination between subtle differences in the consistency thereof. It is concluded that further research should aim to first validate percussion as performed by the physician and increase complexity in a phased manner, validating results and apparatus at each step. The approach followed was perhaps too bold in light of the lack of fundamental understanding of percussion and the underlying mechanisms...|$|E
30|$|However, the above-cited {{detectors}} {{have been}} designed without {{taking into account the}} possible presence of signal mismatch, and they behave quite differently in this situation. A mismatched signal may arise due to several reasons, for example, imperfect array calibration, spatial multipath, pointing errors, etc. Since it is difficult to find a decision scheme capable of successfully detecting slightly mismatched mainlobe targets and effectively rejecting sidelobe targets simultaneously, it becomes important to achieve a good tradeoff between a high sensitivity of mainlobe targets and perfect rejection of sidelobe targets. In order to meet this goal, several strategies have been exploited. One solution is to design a two-stage detector, which is formed by cascading two detectors: the first-stage detector, usually with perfect sensitivity properties, judges if there is enough received energy entering into the receivers; the second-stage detector, usually with perfect selectivity properties, makes the decision {{as to whether or not}} the received signal is to be considered as the signal of interest (SOI). One declares the presence of a target only when the received signal survives both detection thresholds. This is the principle underlying the adaptive sidelobe blanker (ASB) and its improved versions[4 – 7]. Another solution is to modify the hypothesis test problem by adding a fictitious signal under the null hypothesis; this fictitious signal is assumed to be orthogonal to the presumed signal steering vector. When there is no target in the presumed direction but one in another direction, e.g., a sidelobe target, the detector will incline towards the null hypothesis, which is the desired result. This is the rationale of the adaptive beamformer orthogonal rejection test (ABORT)[8] and whitened ABORT (W-ABORT)[9]. A third solution is to design a tunable detector. For example, in[10], a tunable detector is proposed, which consists of a blend of Kelly’s GLRT and AMF through a so-called sensitivity parameter. This parameter controls the degree to which sidelobe targets are rejected. This approach is also used in[11, 12], where different tunable detectors are devised through similar sensitivity parameters. A fourth solution is to assume that a noise-like interferer exists in the cell under test (CUT) but not present in the training data. More precisely, the GLRT in this setting is proposed in[13], which is found to be the ACE, while the Rao test is proposed in[14], with the name—double-normalized AMF (DN-AMF). It is shown that the ACE has excellent sidelobe signals rejection capabilities, at the price of a certain loss in terms of detection of <b>matched</b> <b>signals.</b> Compared to its natural competitor, the DN-AMF provides both enhanced sidelobe targets rejection capabilities and high-detection performance of mainlobe targets.|$|E
40|$|We take it {{for granted}} that objects {{continue}} to exist after being occluded. This knowledge - known as object permanence - is present even in childhood, but its neural basis is not fully understood. Here, we show that monkey inferior temporal (IT) neurons carry potential signals of object permanence even in animals that received no explicit behavioral training. We compared two conditions with identical visual stimulation: the same object emerged from behind an occluder as expected following its occlusion, or unexpectedly after occlusion of a different object. Some neurons produced a larger (surprise) signal when the object emerged unexpectedly, whereas other neurons produced a larger (<b>match)</b> <b>signal</b> when the object reappeared as expected. Neurons carrying <b>match</b> <b>signals</b> also reinstated selective delay period activity just before the object emerged. Thus, signals related to object permanence are present in IT neurons and may arise through an interplay of memory and match computations...|$|R
5000|$|Timekeepers {{were given}} responsibility, rather than referees, for {{controlling}} time in <b>matches.</b> They <b>signalled</b> using a hooter siren system.|$|R
40|$|Incoming {{events that}} match or {{mismatch}} stored representations {{are thought to}} influence {{the ability of the}} hippocampus to switch between memory encoding and retrieval modes. Electrophysiological work has dissociated <b>match</b> and mismatch <b>signals</b> in the monkey perirhinal cortex, where <b>match</b> <b>signals</b> were selective for matches to goal states, whereas mismatch signals were not modulated by intention (Miller and Desimone, 1994). To investigate whether the theoretically important relational <b>match</b> and mismatch <b>signals</b> in the hippocampus are modulated by goal states, we fully crossed whether a probe stimulus relationally matched or mismatched a previously perceived image or goal state. Subjects performed two working memory tasks in which they either responded “yes ” to probes that were identical to the previous sample scene or, after performing a relational manipulation of the scene, responded “yes ” only to a probe that was identical to this perceptually novel image. Using functional magnetic resonance imaging, we found evidence for relational match enhancements bilaterally in the hippocampus that were selective for matches between the probe stimulus and goal state, but were not modulated by whether that goal was perceptually novel. Moreover, we found evidence for a complementary hippocampal mismatch enhancement that was triggered by stimuli containing salient perceptual manipulations. Our results provided evidence for parallel memory signatures in the hippocampus: a controlled <b>match</b> <b>signal</b> that can detect matches to internally generated goal states and an automatic mismatch signal that can identify unpredicted perceptual novelty. Key words: hippocampus; medial temporal lobes; match enhancement; mismatch enhancement; goal states; relational memor...|$|R
3000|$|... {{represented}} by regular, structured Tanner graphs. These graphs {{are constructed using}} Latin squares defined over a multiplicative group of a Galois ring, rather than a finite field. Our approach yields codes {{for a wide range}} of code rates and more importantly, codes whose minimum pseudocodeword weights equal their minimum Hamming distances. Simulation studies show that these structured codes, when transmitted using <b>matched</b> <b>signal</b> sets over an additive-white-Gaussian-noise channel, can outperform their random counterparts of similar length and rate.|$|R
40|$|Adaptation {{method for}} matched {{processing}} of an acoustic {{signal to the}} transmission environment characteristics is offered. The method is based on additional averaging of signal parameters on frequency. The method is applicable in the conditions of moderately dispersible environment when changes of some parameters of a signal in narrow frequency bands can be neglected. Based on the specified method the algorithm for <b>matched</b> <b>signal</b> processing, which is invariant to intensity parameters of modal components of a signal is proposed. ????????? ????? ????????? ????????????? ????????? ????????????? ??????? ? ??????????????? ????? ????????, ?????????? ?? ?????????????? ?????????? ?????????? ??????? ?? ???????. ????? ???????? ? ???????? ???????? ?????????? ????, ????? ??????????? ????????? ?????????? ??????? ? ???????? ???????????? ????? ????????? ????? ????? ??????????. ?? ?????? ?????????? ?????? ??????? ???????? ????????????? ?????????, ???????????? ? ?????????? ????????????? ??????? ????????? ???????...|$|R
40|$|Eurocode 8 {{allows the}} use of real records as an input for {{nonlinear}} dynamic analysis; nevertheless, {{it has been found}} hardly applicable by practitioners. This is related to both the difficulty in rationally relating the ground motions to the hazard at the site and the required selection criteria, which may favor {{the use of}} various types of spectral <b>matching</b> <b>signals</b> rather than real records. To overcome, at least the latter problem, a specific software, namely REXEL, freely available a...|$|R
5000|$|For example, {{to obtain}} the highest {{signal-to-noise}} ratio for a signal with [...] set to <b>match</b> the <b>signal's</b> , the optimal flip angle is 68°.|$|R
3000|$|... [...]) to be {{analyzed}} in the frequency domain so that its representation <b>matches</b> the <b>signal</b> model used in the system. Then, the preprocessed signal, [...]...|$|R
40|$|We {{address the}} problem of {{boundary}} handling in correlationbased template matching by proposing a probabilistic model of the detection process. Whilst our approach bears similarities to those taken in deriving results in <b>matched</b> and subspace <b>signal</b> detection, it offers a new interpretation: that a dual correlator architecture provides a systematic way of handling general uncertainty, and, more specifically, the boundaries of data in signals. We also provide an extended model to deal more effectively with amplitude variations of target with respect to template. These improvements have immediate applications not only in classical <b>matched</b> <b>signal</b> detection, but also for template matching by correlation in digital image analysis and computer vision, where partial target occlusion at image boundaries remains a significant problem. 1...|$|R
50|$|On {{the next}} Raw, Clay {{completed}} his heel turn by abandoning Tensai {{to lose their}} tag match and attacking Tensai after the <b>match,</b> <b>signalling</b> the end of Tons of Funk, as the Funkadactyls also allied themselves with Woods and R-Truth. Despite this, Clay found no immediate success, as {{he went on to}} lose to Tensai, Woods and Truth in singles matches. Clay would compete in the André the Giant Memorial Battle Royal at WrestleMania XXX, but failed to win as he was eliminated by The Great Khali.|$|R
25|$|Feedback is used {{to better}} <b>match</b> <b>signal</b> sources to their loads. For example, a direct {{connection}} of a voltage source to a resistive load may result in signal loss due to voltage division, but interjecting a negative feedback amplifier can increase the apparent load seen by the source, and reduce the apparent driver impedance seen by the load, avoiding signal attenuation by voltage division. This advantage is not restricted to voltage amplifiers, but analogous improvements in matching can be arranged for current amplifiers, transconductance amplifiers and transresistance amplifiers.|$|R
40|$|Abstract This paper {{presents}} {{a new class}} of low-density parity-check (LDPC) codes over represented by regular, structured Tanner graphs. These graphs are constructed using Latin squares defined over a multiplicative group of a Galois ring, rather than a finite field. Our approach yields codes {{for a wide range of}} code rates and more importantly, codes whose minimum pseudocodeword weights equal their minimum Hamming distances. Simulation studies show that these structured codes, when transmitted using <b>matched</b> <b>signal</b> sets over an additive-white-Gaussian-noise channel, can outperform their random counterparts of similar length and rate. </p...|$|R
3000|$|The paper {{entitled}} [...] "Hardware {{implementation of}} a spline-based genetic algorithm for embedded stereo vision sensor providing real-time visual guidance to the visually impaired" [...] by Dah-Jye Lee et al. develops an embedded stereo vision sensor for visual guidance for people with visual impairment. One-dimensional (1 D) spline-based genetic algorithm is applied to <b>matching</b> <b>signals</b> and generating a dense disparity map, from which 3 D information is extracted. The 1 D spline-based genetic algorithm can be executed in parallel and implemented into an FPGA to become a compact system.|$|R
40|$|This paper {{presents}} {{a new class}} of low-density parity-check (LDPC) codes over Ã¢Â„Â¤ 2 a represented by regular, structured Tanner graphs. These graphs are constructed using Latin squares defined over a multiplicative group of a Galois ring, rather than a finite field. Our approach yields codes {{for a wide range of}} code rates and more importantly, codes whose minimum pseudocodeword weights equal their minimum Hamming distances. Simulation studies show that these structured codes, when transmitted using <b>matched</b> <b>signal</b> sets over an additive-white-Gaussian-noise channel, can outperform their random counterparts of similar length and rate...|$|R
40|$|We {{investigate}} the matching of the continuous gravitational wave in an all sky search {{in reference to}} the Earth based laser interferometric detectors. We consider the source location as the parameters of the signal manifold and templates corresponding to different source locations. For fixed source frequency f_o, under the transformation θ_T →π - θ_T; 0 <θ_T <π, we found that the <b>matching</b> of the <b>signals</b> is almost same for arbitrary observation time T_obs and ϕ (celestial longitude), where θ_T are the templates in θ (celestial colatitude) space. Though insignificant, we observed variation in the <b>matching</b> of <b>signals</b> for different θ, detector positions and orientations. However, this insignificant mismatch scales with f_o. Consequently, <b>matching</b> of the <b>signals</b> fall with f_o. In ϕ space, under the transformations ϕ_T →π - ϕ_T; 0 <ϕ_T <π and ϕ_T → 3 π - ϕ_T; π<ϕ_T < 2 π, we found that the <b>matching</b> of the <b>signals</b> fall with T_obs, f_o, θ and ϕ, where ϕ_T are the templates in ϕ space...|$|R
40|$|In {{situations}} where {{the presence of a}} signal is to be detected in several noisy channels, often one channel will have higher signal-to-noise ratio (SNR) than the others. When the SNR on one channel is sufficiently high that the signal can be extracted from that channel, {{it may be possible to}} use the extracted signal to aid in detecting the presence of the signal on the other channels. In this paper, the matching pursuit time-frequency method with <b>matched</b> <b>signal</b> dictionaries is used to extract a chirp signal from a noisy channel. The extracted signal is used in one channel of a generalized coherence (GC) detector with the goal of detecting the presence of the signal on other, even noisier, channels. This approach is compared via simulation to a GC detector that does not pre-process the highest SNR channel to extract the signal. Detector performance is shown to be significantly enhanced by <b>matching</b> pursuit <b>signal</b> extraction prior to coherence estimation...|$|R
50|$|The {{matching}} {{of active}} and passive fibers can be optimized in several ways. The easiest method for <b>matching</b> the <b>signal</b> carrying light {{is to have}} identical NA and core diameters for each fiber. This however {{does not account for}} all the refractive index profile features. Matching of the MFD is also a method used to create <b>matched</b> <b>signal</b> carrying fibers. It has been shown that matching all of these components provides the best set of fibers to build high power amplifiers and lasers. Essentially, the MFD is modeled and the resulting target NA and core diameter are developed. The core-rod is made and before being drawn into fiber its core diameter and NA are checked. Based on the refractive index measurements, the final core/clad ratio is determined and adjusted to the target MFD. This approach accounts for details of the refractive index profile which can be measured easily and with high accuracy on the preform, before it is drawn into fiber.|$|R
40|$|Abstract Background Gas chromatography-mass {{spectrometry}} (GC-MS) is {{a robust}} {{platform for the}} profiling of certain classes of small molecules in biological samples. When multiple samples are profiled, including replicates of the same sample and/or different sample states, one needs to account for retention time drifts between experiments. This can be achieved either by the alignment of chromatographic profiles prior to peak detection, or by <b>matching</b> <b>signal</b> peaks {{after they have been}} extracted from chromatogram data matrices. Automated retention time correction is particularly important in non-targeted profiling studies. Results A new approach for <b>matching</b> <b>signal</b> peaks based on dynamic programming is presented. The proposed approach relies on both peak retention times and mass spectra. The alignment of more than two peak lists involves three steps: (1) all possible pairs of peak lists are aligned, and similarity of each pair of peak lists is estimated; (2) the guide tree is built based on the similarity between the peak lists; (3) peak lists are progressively aligned starting with the two most similar peak lists, following the guide tree until all peak lists are exhausted. When two or more experiments are performed on different sample states and each consisting of multiple replicates, peak lists within each set of replicate experiments are aligned first (within-state alignment), and subsequently the resulting alignments are aligned themselves (between-state alignment). When more than two sets of replicate experiments are present, the between-state alignment also employs the guide tree. We demonstrate the usefulness of this approach on GC-MS metabolic profiling experiments acquired on wild-type and mutant Leishmania mexicana parasites. Conclusion We propose a progressive method to <b>match</b> <b>signal</b> peaks across multiple GC-MS experiments based on dynamic programming. A sensitive peak similarity function is proposed to balance peak retention time and peak mass spectra similarities. This approach can produce the optimal alignment between an arbitrary number of peak lists, and models explicitly within-state and between-state peak alignment. The accuracy of the proposed method was close to the accuracy of manually-curated peak matching, which required tens of man-hours for the analyzed data sets. The proposed approach may offer significant advantages for processing of high-throughput metabolomics data, especially when large numbers of experimental replicates and multiple sample states are analyzed. </p...|$|R
40|$|The Statnamic {{method is}} an {{increasingly}} popular technique {{to carry out}} loading tests on cast in-situ piles. The method bas {{proved to be a}} cost-effective alternative to a static loading test. As-sociated to Unloading Point Method (UPM) and to automatie <b>signal</b> <b>matching,</b> the Statnamic testing technique provides an estimation of the static load-settlement curve of foundation piles. For long piles with wave numbers (Nw) less than 12, however, the method becomes less accu-rate because of stress wave phenomena (concrete piles longer than 35 m or steel piles longer than 40 m). In these cases, the <b>signal</b> <b>matching</b> stress wave method can be used to estimate the static load-settlement curve. The TNO Stress-Wave method is a convenient way to carry out automatic <b>matching</b> on Statnamic <b>signals.</b> The use of TNO Stress-Wave method and of auto-matic <b>signal</b> <b>matching</b> for a Statnamic prediction is investigated in this paper. A case study is introduced and the results of a <b>signal</b> <b>matching</b> are presented. Further, the case study is mod-elled in TNO Stress-Wave and the results of the model are compared to the results of the field Statnamic test...|$|R
40|$|High density {{oligonucleotide}} arrays (DNA chips) {{have been}} used in two color mutational analysis of the 3. 43 kb exon 11 of the hereditary breast and ovarian cancer gene BRCA 1. Two color analysis allows competitive hybridization between a reference standard and an unknown sample, improving the performance of the assay. Fluorescein and phycoerythrin dyes werepreviously used due to their compatibility with a single line 488 nm excitation source. Here we show that an alternative dye combination, containing the energy transfer dye system phycoerythrin*cy 5 along with phycoerythrin, provides more evenly <b>matched</b> <b>signal</b> intensities and decreased spectral overlap between the two fluorophores, while maintaining compatibility with a 488 nm excitation source...|$|R
40|$|Single shot imaging {{capability}} for OH radical distributions in various atmospheric pressure methane flames upon excitation with a tunable frequency-quadrupled Nd[*]:[*]YAG laser is demonstrated. The laser wavelength can be tuned with an intra-cavity etalon to produce laser-induced fluorescence (LIF) signals from OH via absorption in the OH A–X (2, 0) P 1 (10) line. Simultaneous single-shot imaging of the burnt and unburnt zones in laminar nonpremixed, premixed and turbulent flames is presented. The unburnt areas are visualized with LIF of acetone that is seeded to the methane fuel. Acetone levels {{are set to}} <b>match</b> <b>signal</b> intensities {{to that of the}} OH signals to allow imaging on a single intensified CCD camera...|$|R
