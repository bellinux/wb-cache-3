5|10000|Public
40|$|<b>Minimization</b> <b>of</b> <b>drive</b> <b>test</b> (MDT) has {{recently}} been standardized by 3 GPP as a key self organizing network (SON) feature. MDT allows coverage to be estimated at the base station (BS) using user equipment (UE) measurement reports with the objective to {{eliminate the need for}} drive tests. However, most MDT based coverage estimation methods recently proposed in literature assume that UE position is known at the BS with 100 % accuracy, an assumption that does not hold in reality. In this paper we develop an analytical model that allows the quantification of error in MDT based autonomous coverage estimation (ACE) as a function of error in UE as well as BS positioning. Our model also allows characterization of error in ACE as function of standard deviation of shadowing...|$|E
30|$|Instead of cell-level {{performance}} indicators, other classic solutions may rely {{on direct}} reporting {{produced by the}} UEs, such as drive tests, UE app monitoring, or analysis of the control plane messages. In order to overcome limitations of drive tests (classically performed by field engineers with especial terminals), recent standardization work has established mechanisms for <b>minimization</b> <b>of</b> <b>drive</b> <b>test</b> (MDT). In MDT, measurements automatically gathered from common terminals are used for network monitoring. In this way, the work presented in [6] {{is based on the}} use of MDT information for sleeping cell detection. However, MDT is typically applied in outdoor environments where the terminals’ reports are combined with geographical information obtained from satellite or cellular-based localization (e.g., based on observed time difference of arrival (OTDoA)). Thus, those systems have very low performance indoors {{due to the lack of}} satellite coverage and the short distance between cells.|$|E
40|$|Automatic {{detection}} of cells {{which are in}} outage {{has been identified as}} one of the key use cases for Self Organizing Networks (SON) for emerging and future generations of cellular systems. A special case of cell outage, referred to as Sleeping Cell (SC) remains particularly challenging to detect in state of the art SON because in this case cell goes into outage or may perform poorly without triggering an alarm for Operation and Maintenance (O&M) entity. Consequently, no SON compensation function can be launched unless SC situation is detected via drive tests or through complaints registered by the affected customers. In this paper, we present a novel solution to address this problem that makes use of <b>minimization</b> <b>of</b> <b>drive</b> <b>test</b> (MDT) measurements recently standardized by 3 GPP and NGMN. To overcome the processing complexity challenge, the MDT measurements are projected to a low-dimensional space using multidimensional scaling method. Then we apply state of the art k-nearest neighbor and local outlier factor based anomaly detection models together with pre-processed MDT measurements to profile the network behaviour and to detect SC. Our numerical results show that our proposed solution can automate the SC detection process with 93 accuracy...|$|E
40|$|The concept <b>of</b> <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT) {{has been}} de-veloped in Third Generation Partnership Project (3 GPP) specifi-cations standard. With MDT, Mobile Network Operators (MNOs) were enabled to {{remotely}} collect measurements indicating the network Quality of Service (QoS), as experienced by their users, correlated with actual location information. This results in wider application of use cases that allows network monitor-ing and optimization, {{without the need}} for conventional <b>drive</b> <b>tests.</b> To facilitate access to distributed geospatial data through a set of policies, common rules, and standards that would im-prove interoperability, this paper, proposes an open architec-ture, in compliance with the Open Geospatial Consortium (OGC) web services and the MDT architectures, enabling the automa-tion of the MDT use cases and real-time service management...|$|R
30|$|Here {{we respond}} to the missing point of hotspot {{location}} by proposing a dynamic clustering algorithm based on Global Positioning System (GPS) coordinate location. We suppose that the BS benefits from <b>minimization</b> <b>of</b> <b>drive</b> <b>tests</b> (MDT) [27] which collects network quality information like UE coordinates, i.e., MDT geo-localize the UEs. Detailed location information provided by MDT reports, allows the operator to associate a set of MDT measurements with a physical location. The UEs are requested by the BS to acquire location information for a configured MDT session [28]. The knowledge of the UEs coordinates is hence available at the BS {{and can be used}} in order to find the hotspots. The BS will apply an algorithm based on the well known K-means that outputs or create clusters of UEs. Then, after some optimizations, we succeed on transforming the clusters into hotspots.|$|R
40|$|Wireless Local Area Network (WLAN) {{positioning}} {{has become}} a popular localization system due to its low-cost installation and widespread availability of WLAN access points. Traditional grid-based radio frequency (RF) fingerprinting (GRFF) suffers from two drawbacks. First it requires costly and non-efficient data collection and updating procedure; secondly the method goes through time-consuming data pre-processing before it outputs user position. This paper proposes Cluster-based RF Fingerprinting (CRFF) to overcome these limitations by using modified <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> data which can be autonomously collected by cellular operators from their subscribers. The effect of environmental changes and device variation on positioning accuracy has been carried out. Experimental results show that even under these variations CRFF can improve positioning accuracy by 15. 46 and 22. 30 % in 95 percentile of positioning error as {{compared to that of}} GRFF and K-nearest neighbour methods respectively...|$|R
40|$|In this paper, {{we address}} the {{challenge}} of autonomous cell outage detection (COD) in Self-Organizing Networks (SON). COD is a pre-requisite to trigger fully automated self-healing recovery actions following cell outages or network failures. A special case of cell outage, referred to as Sleeping Cell (SC) remains particularly challenging to detect in state-of-the-art SON, since it triggers no alarms for Operation and Maintenance (O&M) entity. Consequently, no SON compensation function can be launched unless site visits or drive tests are performed, or complaints are received by affected customers. To address this issue, we present and evaluates a COD framework, {{which is based on}} <b>minimization</b> <b>of</b> <b>drive</b> <b>test</b> (MDT) reports, a functionality recently specified in third generation partnership project (3 GPP) Release 10, for LTE Networks. Our proposed framework aims to detect cell outages in an autonomous fashion by first pre-processing the MDT measurements using multidimensional scaling method and further employing it together with machine learning algorithms to detect and localize anomalous network behaviour. We validate and demonstrate the effectiveness of our proposed solution using the data obtained from simulating the network under various operational settings...|$|E
40|$|To be able {{to provide}} {{uninterrupted}} high quality of experience to the subscribers, operators must ensure high reliability of their networks while aiming for zero downtime. With the growing complexity of the networks, there exists unprecedented challenges in network optimization and planning, especially activities such as cell outage detection (COD) and mitigation that are labour-intensive and costly. In this paper, we address the challenge of autonomous COD and cell outage compensation in self-organising networks (SON). COD is a pre-requisite to trigger fully automated self-healing recovery actions following cell outages or network failures. A special case of cell outage, referred to as sleeping cell, remains particularly challenging to detect in state-of-the-art SON, because it triggers no alarms for operation and maintenance entity. Consequently, no SON compensation function can be launched unless site visits or drive tests are performed, or complaints are received by affected customers. To address this issue, our COD solution leverages <b>minimization</b> <b>of</b> <b>drive</b> <b>test</b> functionality, recently specified in third generation partnership project Release 10 for LTE networks, in conjunction with state-of-the art machine learning methods. Subsequently, the proposed cell outage compensation mechanism utilises fuzzy-based reinforcement learning mechanism to fill the coverage gap and improve the quality of service, for the users in the identified outage zone, by reconfiguring the antenna and power parameters of the neighbouring cells. The simulation results show that the proposed framework can detect cell outage situations in an autonomous fashion and also compensate for the detected outage in a reliable manner...|$|E
40|$|In this paper, {{we present}} a layered Radio Environment Map (REM) {{architecture}} along with its applications to the Self-Organizing Network (SON) functionalities of heterogeneous LTE radio-access networks comprising macrocells and femtocells. In this architecture, the functional blocks re-appear with different spatial and temporal granularity at different architectural layers. Although REM {{is one of the}} key promising technologies to enable future cognitive radio networks, it can be already applied to provide limited cognitive capabilities to today’s commercial networks too. We explain why, and show how, this architecture can support today's LTE SON functions like Automatic Neighbor Relation (ANR) and <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT), and also allows the smooth introduction of new Radio Access Technologies (RATs) through refarming. We also demonstrate some of the quantitative benefits adopting REM technologies can bring using the MDT as an example...|$|R
40|$|Abstract—The {{existence}} of coverage holes in cellular networks {{is a common}} problem for mobile operators. Traditionally, the cellular coverage is computed using sophisticated planning tools, and then optimized through <b>drive</b> <b>tests.</b> With the <b>drive</b> <b>tests</b> information, the operators detect the poorly covered areas and take actions to eliminate them. The introduction of self-organized or “cognitive ” techniques, would allow the operators to maxi-mize the network’s information obtained through <b>drive</b> <b>tests</b> or reported by the mobile users. In this paper we propose the use of spatial Bayesian geo-statistics to build a Radio Environment Map (REM) for real coverage hole detection purposes. Results show {{that the number of}} pixels forming the coverage holes, as well as the probability of detecting them, can be significantly increased with the use of REMs, compared to the case where only network measurements are used. Keywords—Coverage hole detection, <b>minimization</b> <b>of</b> <b>drive</b> <b>tests,</b> spatial information exploitation, REM...|$|R
40|$|This paper aims to find {{patterns}} of knowledge from physical layer data coming from Heterogeneous Long Term Evolution (LTE) networks. We discuss how the collected data is employed {{in such a}} manner that improves <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT) functionality in LTE networks. In particular we aim to predict Quality of Service (QoS) expressed in terms of throughput of the User Datagram Protocol (UDP) traffic flow. We propose regression models to estimate QoS, by extrapolating information independently of the user’s physical location. In particular our approach allows to estimate the QoS in any location, based on measurements collected at anytime in the past, or anywhere in the network. This will allow to significantly reduce costs of future network deployments, even in complex and heterogeneous scenarios, such as those foreseen in stadiums, events, etc. We identify three feasible regression models, and we compare results in terms of prediction accuracy...|$|R
40|$|International audience—Technology {{evolutions}} {{make possible}} {{the use of}} Geo-Localized Measurements (GLM) for performance and quality of service optimization thanks to the <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Testing</b> (MDT) feature. Exploiting GLM in radio resource management is a key challenge in future networks. The Forecast Scheduling (FS) concept that uses GLM in the scheduling process has been recently introduced. It exploits long term time and spatial diversity of vehicular users {{in order to improve}} user throughputs and quality of service. In a previous paper we have formulated the FS as a convex optimization problem namely the maximization of an α−fair utility function of the cumulated downlink data rates of the users along their trajectories. This paper proposes an extension for the FS model to take into account different types of random events such as arrival and departure of users and uncertainties in the mobile trajectories. Simulation results illustrate the significant performance gain achieved by the FS algorithms in the presence of random events. ...|$|R
40|$|In {{this paper}} we propose a novel {{optimization}} algorithm for grid-based RF fingerprinting to improve user equipment (UE) positioning accuracy. For this purpose we have used Multi-objective Genetic Algorithm (MOGA) which enables autonomous calibration of gridcell layout (GCL) for better UE positioning as compared to that of the conventional fingerprinting approach. Performance evaluations were carried out using two different training data-sets consisting <b>of</b> <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Testing</b> measurements obtained from a dynamic system simulation in a heterogeneous LTE small cell environment. The robustness of the proposed method has been tested analyzing positioning results from two different areas of interest. Optimization of GCL is performed in two ways: (1) array-wise calibration of the grid-cell units using non-overlapping GCL and (2) creating an overlapping GCL to cover of whole simulation area with different rectangular grid-cell units. Simulation results show that if sufficient amount of training data is available then the proposed method can improve positioning accuracy of 56. 74 % over the conventional gridbased RF fingerprinting...|$|R
40|$|This article {{presents}} an automatic malfunction detection framework {{based on data}} mining approach to analysis of network event sequences. The considered environment is Long Term Evolution (LTE) for Universal Mobile Telecommunication System (UMTS) with sleeping cell caused by random access channel failure. Sleeping cell problem means unavailability of network service without triggered alarm. The proposed detection framework uses N-gram analysis for identification of abnormal behavior in sequences of network events. These events are collected with <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT) functionality standardized in LTE. Further processing applies dimensionality reduction, anomaly detection with k-nearest neighbor, cross-validation, post-processing techniques and efficiency evaluation. Different anomaly detection approaches proposed in this paper are compared against each other with both classic data mining metrics, such as F-score and receiver operating characteristic curves, and a newly proposed heuristic approach. Achieved results demonstrate that the suggested method {{can be used in}} modern performance monitoring systems for reliable, timely and automatic detection of random access channel sleeping cells. Comment: 26 page...|$|R
40|$|The {{configuration}} {{and maintenance}} of constantly evolving mobile cellular networks are {{getting more and more}} complex and hence expensive. Self-Organizing Networks (SON) concept is an umbrella term for the set of automated solutions for network operations proposed by 3 rd Generation Partnership Project (3 GPP) group. Automated cell outage detection is one of the components of SON functionality. In early studies our research group developed data-driven approach for the detection of malfunctioning cells. In this paper we investigate the performance of the proposed solution {{as a function of the}} density of active users and the size of observation interval. The evaluation is conducted in Long Term Evolution (LTE) /LTE-Advanced (LTE-A) system level simulator. The analyzed data is the collection <b>of</b> <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Testing</b> (MDT) reports, which is basically user-level statistics. Our approach is able to detect cells experiencing random access failures, but the performance depends on the amount of available data...|$|R
30|$|The {{increasing}} {{complexity of}} network {{infrastructure and services}} has also led operators {{to be interested in}} managing performance at the user level, instead of the cell- or network level, with the aim of maintaining their competitiveness levels. Today’s solutions based on per-cell performance counters are insufficient to perform adequate root-cause analysis. For this reason, the standardization bodies have proposed the use of user-centric indicators and call traces to support the optimization and troubleshooting processes [9]. With the <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT) described in [10], the collection of traffic measurements can be done in an autonomous manner. In other words, each device that is active in the network reports measurements and signaling messages (i.e., call events) to the base station. Unlike traditional <b>drive</b> <b>tests,</b> MDT avoids the use of expensive measurement equipment and it does not require human effort. The information provided by call traces and MDT is not aggregated and reflects the performance at the user level. However, operators can process this information and use it to identify problems with greater accuracy at higher levels (e.g., the cell level).|$|R
40|$|International audienceIn future networks, Radio Resource Management (RRM) {{could benefit}} from Geo-Localized Measurements (GLM) thanks to the <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Testing</b> (MDT) feature {{introduced}} in Long Term Evolution (LTE). Such measurements can be processed by the network and be used to optimize its performance. The {{purpose of this paper}} a is to use GLM to significantly improve scheduling. We introduce the concept of forecast scheduler for users in high mobility that exploit GLM. It is assumed that a Radio Environment Map (REM) can provide interpolated Signal to Interference plus Noise Ratio (SINR) values along the user trajectories. The diversity in the mean SINR values of the users during a time interval of several seconds allows to achieve a significant performance gain. The forecast scheduling is formulated as a convex optimization problem namely the maximization of an α−fair utility function of the cumulated rates of the users along their trajectories. Numerical results for thee different mobility scenarios illustrate the important performance gain achievable by the forecast scheduler. Index Terms—Forecast scheduler, alfa-fair, high mobility, Minimizing <b>Drive</b> <b>Tests,</b> MDT, Radio Environment Maps, REM, geo-localized measurement...|$|R
40|$|The Sleeping Cell {{problem is}} a {{particular}} type of cell degradation in Long-Term Evolution (LTE) networks. In practice such cell outage leads to the lack of network service and sometimes it can be revealed only after multiple user complains by an operator. In this study a cell becomes sleeping because of a Random Access Channel (RACH) failure, which may happen due to software or hardware problems. For the detection of malfunctioning cells, we introduce a data mining based framework. In its core is the analysis of event sequences reported by a User Equipment (UE) to a serving Base Station (BS). The crucial element of the developed framework is an anomaly detection algorithm. We compare performances of distance, centroid distance and probabilistic based methods, using Receiver Operating Characteristic (ROC) and Precision-Recall curves. Moreover, the theoretical comparison of the methods’ computational efficiencies is provided. The sleeping cell detection framework is verified by means of a dynamic LTE system simulator, using <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Testing</b> (MDT) functionality. It is shown that the sleeping cell can be pinpointed...|$|R
40|$|A data-mining {{framework}} for analyzing a cellular network <b>drive</b> <b>testing</b> database {{is described in}} this paper. The presented method is designed to detect sleeping base stations, network outage, and change of the dominance areas in a cognitive and self-organizing manner. The essence of the method is to find similarities between periodical network measurements and previously known outage data. For this purpose, diffusion maps dimensionality reduction and nearest neighbor data classification methods are utilized. The method is cognitive because it requires training data for the outage detection. In addition, the method is autonomous because it uses <b>minimization</b> <b>of</b> <b>drive</b> <b>testing</b> (MDT) functionality to gather the training and testing data. Motivation of classifying MDT measurement reports to periodical, handover, and outage categories is to detect areas where periodical reports start to become similar to the outage samples. Moreover, these areas are associated with estimated dominance areas to detected sleeping base stations. In the studied verification case, measurement classification results in an increase {{of the amount of}} samples which can be used for detection of performance degradations, and consequently, makes the outage detection faster and more reliable...|$|R
40|$|Location based {{applications}} and services have become popular in many wireless communication devices. This thesis study presents a performance evaluation of Radio Frequency (RF) fingerprinting framework in heterogeneous Long Term Evolution (LTE) and Wireless Local Area Networks (WLAN) using <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Testing</b> (MDT) measurements which allow automated construction of extensive RF fingerprint training databases. Utilization of MDT data could create additional opportunities for service provider and application developers. Typical RF fingerprint consist of radio measurements from multiple LTE transceiver stations and WLAN access points. Regardless environmental conditions, received signal strength indicator pattern for difference reference points, set a fingerprint of radio {{conditions for the}} specific location. Based on RF fingerprinting framework for positioning by using MDT measurements specified in LTE release 10, performance of locating user equipment was studied by signal strength mean value algorithm using grid based method at outdoor environment. To find out the optimal grid size, three different grid size were used. Source of positioning error and effects have been extensively investigated. Cumulative distribution function {{has been used to}} express the result. This study suggests that, MDT based RF fingerprint locationing system can provide a good basis for the network based proximity detection...|$|R
30|$|Detection and {{assessment}} of coverage holes are both related to fault detection and diagnosis within self-healing [10] and coverage optimization [11]. Traditionally, coverage holes have been detected through <b>drive</b> <b>tests,</b> which are characterized by being time consuming and expensive. For this reason, particular attention is being given to automatically detect coverage holes through the already standardized mobile traces [12] and <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> feature [13 – 16], which allows operators to automatically store both the user measurements and the signaling messages. Some existing studies propose different methods to detect coverage holes. An approach to improve {{the accuracy of the}} coverage hole prediction based on a spatial Bayesian framework is presented in [17]. In addition, another technique to detect real coverage holes by means of radio environment maps is provided in [18]. However, according to [19], an LTE coverage hole has a different impact on the network depending on whether it is covered by an underlying radio access technology (uRAT) or not, so the way of compensating or optimizing them will be different. Since LTE networks are continually growing, not only the detection of coverage holes, but also the quantification of their impact would be helpful to determine how it should be improved.|$|R
40|$|In {{the coming}} years, {{planning}} future mobile networks will be infinitely {{more complex than}} nowadays. Future networks are expected to present multiple Network Management (NM) challenges to operators, such as managing network complexity in terms of densification of scenarios, heterogeneous nodes, applications, Radio Access Technologies (RAT), among others. In this context, the exploitation of past information gathered by the network is highly relevant when planning future deployments. In this paper we present a network planning tool based on Machine Learning (ML). In particular, we propose an approach which allows to predict Quality of Service (QoS) offered to end-users, based on data collected by the <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT) function. As a QoS indicator, we focus on Physical Resource Block (PRB) per Megabit (Mb) in an arbitrary point of the network. Minimizing this metric allows serving users with the same QoS by consuming less resources, and therefore, being more cost-effective. The proposed network planning tool considers a Genetic Algorithm (GA), which tries to reach the operator targets. The network parameters we desire to optimise are set as the input to the algorithm. Then, we predict the QoS of the network by means of ML techniques. By integrating these techniques in a network planning tool, operators {{would be able to}} find the most appropriate deployment layout, by minimizing the resources (i. e., the cost) they need to deploy to offer a given QoS in a newly planned deployment...|$|R
40|$|Planning {{of current}} and future mobile {{networks}} is becoming increasingly complex due to the heterogeneity of deployments, which feature not only macrocells, but also an underlying layer of small cells whose deployment is not fully {{under the control of}} the operator. In this paper, we focus on selecting the most appropriate Quality of Service (QoS) prediction techniques for assisting network operators in planning future dense deployments. We propose to use machine learning as a tool to extract the relevant information from the huge amount of data generated in current 4 G and future 5 G networks during normal operation, which is then used to appropriately plan networks. In particular, we focus on radio measurements to develop correlative statistical models with the purpose of improving QoS-based network planning. In this direction, we combine multiple learners by building ensemble methods and use them to do regression in a reduced space rather than in the original one. We then compare the QoS prediction accuracy of various approaches that take as input the 3 GPP <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT) measurements collected throughout a heterogeneous network and analyse their trade-offs. We also explain how the collected data is processed and used to predict QoS expressed in terms of Physical Resource Block (PRB) / Megabit (MB) transmitted. This metric was selected because of the interest it may have for operators in planning, since it relates lower layer resources with their impact in terms of QoS up in the protocol stack, hence closer to the end-user...|$|R
40|$|This {{dissertation}} {{is devoted}} to development and validation of advanced per- formance monitoring system for existing and future cellular mobile networks. Knowledge mining techniques are employed for analysis of user speciﬁc logs, collected with <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT) functionality. Ever increas- ing quality requirements, expansion of the mobile networks and their extend- ing heterogeneity, call for effective automatic means of performance monitoring. Nowadays, network operation is mostly controlled manually through aggregated key performance indicators and statistical proﬁles. These methods are {{are not able to}} fully address the dynamism and complexity of modern mobile networks. Self-organizing networks introduce automation to the most important network functions, but the opportunity of processing large arrays of user reported perfor- mance data is underutilized. Advanced performance monitoring system developed in the presented re- search considers both numerical and sequential properties of the MDT data for detection of faults. Network malfunctions analyzed in this study are sleeping cells in either physical or medium access layer. A full data mining cycle is em- ployed for identiﬁcation of problematic regions in the network. Pre-processing with statistical normalization and sliding window methods, both linear and non- linear transformation and dimensionality reduction algorithms, together with clustering and classiﬁcation methods are used in the discussed research. Sev- eral post-processing and detection quality evaluation methods are proposed and applied. The developed system is capable of fast and accurate detection of non- trivial network dysfunctions and is suitable for future mobile networks, even in combination with cognitive self-healing. As a result, operation of modern mo- bile networks would become more robust, increasing quality of service and user experience...|$|R
30|$|Similarly to the {{previously}} described industrial approaches, in this work, {{we focus on}} the application of ML to improve SON functionalities by providing a more accurate estimates of the key performance indicators (KPIs) {{as a function of the}} network configuration. The KPIs are mainly important for operators to detect changes in the provided quality of service (QoS) and QoE, for example, in order to reconfigure the network in response to a detected degradation in QoS. The estimation of the KPIs based on a limited network measurements is one of the main requirements <b>of</b> the <b>minimization</b> <b>of</b> <b>drive</b> <b>tests</b> (MDT) functionality and represents a key element for the realization of the big data empowered SON approach introduced in [13]. In this work, we apply learning-based LTE KPI estimation approach to the specific use case of LTE small cell frequency and bandwidth assignment. We investigate the potential of LTE’s frequency assignment flexibility [14] in small cell deployments, i.e., exploiting the possibility of assigning different combinations of carrier frequency and system bandwidth to each small cell in the network in order to achieve performance improvements. Currently, most LTE small cell deployments rely on same-frequency operation with the reuse factor of one, whose main objective is to maximize the spectral efficiency. However, the spectrum reuse factor is subject to a trade-off between spectral efficiency and interference mitigation. Since interference may become a critical issue in unplanned dense small cell deployments, reconsidering spectrum reuse factors in this kind of deployments may be necessary. Moreover, the same-frequency operation is not expected to be the standard practice in the future, since additional spectrum will be available at higher frequencies, e.g., 3.5 GHz [15]. Thus, for the future network deployments, it will be more relevant to consider band-separated local area access operating on higher-frequency bands, with the overlaid macro layer operating on lower cellular bands.|$|R
40|$|The recent advancements in {{cellular}} mobile technology and smart phone usage have opened opportunities for researchers and commercial companies to develop ubiquitous low cost localization systems. Radio frequency (RF) fingerprinting {{is a popular}} positioning technique which uses radio signal strength (RSS) values from already existing infrastructures to provide satisfactory user positioning accuracy in indoor and densely built outdoor urban areas where Global Navigation Satellite System (GNSS) signal is poor and hard to reach. However a major requirement for the RF fingerprinting to maintain good localization accuracy is the collection and updating of large training database. The <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT) functionality proposed by 3 GPP LTE Release 10 & 11 has enabled cellular operators to autonomously gather and update necessary amount of RF fingerprint samples by utilizing their subscriber user equipments (UEs). The main objective of this thesis is to propose a framework for RF fingerprint positioning (RFFP) of outdoor UEs using MDT data and to further improve its performance capability to provide better localization. In the first part only LTE base-station (BS) RSS values were used to improve grid-based RF fingerprint positioning (G-RFFP) by using novel approaches: using overlapped grid-cell layouts (GCL), weighting based grid-cell unit selection and Artificial Intelligence based G-RFFP method. In the second part real measurement RSS values from LTE BS and WLAN access points (APs) were utilized and a generic measurement method referred to as GMDT was proposed to correlate WLAN RSS to LTE RSS measurements and its significance to RFFP was studied using a partial fingerprint matching technique. To remove the computational cost associated with training data preprocessing a new cluster-based RF fingerprint positioning (C-RFFP) method was proposed. This thesis provides {{a good source of}} information and novel techniques for cellular operators to build a low cost RF fingerprint positioning system which can deliver acceptable results in emergency user localizatio...|$|R
40|$|With {{the advent}} of Long-Term Evolution (LTE) {{networks}} {{and the spread of}} a highly varied range of services, mobile operators are increasingly aware of the need to strengthen their maintenance and operational tasks in order to ensure a quality and positive user experience. Furthermore, the co- existence of multiple Radio Access Technologies (RAT), the increase in the traffic demand and the need to provide a great variety of services are steering the cellular network toward a new scenario where management tasks are becoming increasingly complex. As a result, mobile operators are focusing their efforts to deal with the maintenance of their networks without increasing either operational expenditures (OPEX) or capital expenditures (CAPEX). In this context, it is becoming necessary to effectively automate the management tasks through the concept of the Self-Organizing Networks (SON). In particular, SON functions cover three different areas: Self-Configuration, Self-Optimization and Self- Healing. Self-Configuration automates the deployment of new network elements and their parameter configuration. Self-Optimization is in charge of modifying the configuration of the parameters in order to enhance user experience. Finally, Self-Healing aims reduce the impact that failures and services degradation have on the end-user. To that end, Self-Healing (SH) systems monitor the network elements through several alarms, measurements and indicators in order to detect outage and degraded cells, then, diagnose the cause of their problem and, finally, execute the compensation or recovery actions. Even though mobile networks are become more prone to failures due to their huge increase in complexity, the automation of the troubleshooting tasks through the SH functionality has not been fully realized. Traditionally, both the research and the development of SON networks have been related to Self-Configuration and Self-Optimization. This has been mainly due to the challenges that need to be faced when SH systems are studied and implemented. This is especially relevant in the case of fault diagnosis. However, mobile operators are paying increasingly more attention to self-healing systems, which entails creating options to face those challenges that allow the development of SH functions. On the one hand, currently, the diagnosis continues to be manually done since it requires considerable hard-earned experience {{in order to be able}} to effectively identify the fault cause. In particular, troubleshooting experts thoroughly analyze the performance of the degraded network elements by means of measurements and indicators in order to identify the cause of the detected anomalies and symptoms. Therefore, automating the diagnosis tasks means knowing what specific performance indicators have to be analyzed and how to map the identified symptoms with the associate fault cause. This knowledge is acquired over time and it is characterized by being operator-specific based on their policies and network features. Furthermore, troubleshooting experts typically solve the failures in a network without either documenting the troubleshooting process or recording the analyzed indicators along with the label of the identified fault cause. In addition, because there is no specific regulation on documentation, the few documented faults are neither properly defined nor described in a standard way (e. g. the same fault cause may be appointed with different labels), making it even more difficult to automate the extraction of the expert knowledge. As a result, this a lack of documentation and lack of historical reported faults makes automation of diagnosis process more challenging. On the other hand, when the exact root cause cannot be remotely identified through the statistical information gathered at cell level, <b>drive</b> <b>test</b> are scheduled for further information. These <b>drive</b> <b>tests</b> aim to monitor mobile network performance by using vehicles to personally measure the radio interface quality along a predefined route. In particular, the troubleshooting experts use specialized test equipment in order to manually collect user-level measurements. Consequently, <b>drive</b> <b>test</b> entail a hefty expense for mobile operators, since it involves considerable investment in time and costly resources (such as personal, vehicles and complex test equipment). In this context, the Third Generation Partnership Project (3 GPP) has standardized the automatic collection of field measurements (e. g. signaling messages, radio measurements and location information) through the mobile traces features and its extended functionality, the <b>Minimization</b> <b>of</b> <b>Drive</b> <b>Tests</b> (MDT). In particular, those features allow to automatically monitor the network performance in detail, reaching areas that cannot be covered by <b>drive</b> <b>testing</b> (e. g. indoor or private zones). Thus, mobile traces are regarded as an important enabler for SON since they avoid operators to rely on those expensive <b>drive</b> <b>tests</b> while, at the same time, provide greater details than the traditional cell-level indicators. As a result, enhancing the SH functionalities through the mobile traces increases the potential cost savings and the granularity of the analysis. Hence, in this thesis, several solutions are proposed to overcome the limitations that prevent the development of SH with special emphasis on the diagnosis phase. To that end, the lack of historical labeled databases has been addressed in two main ways. First, unsupervised techniques have been used to automatically design diagnosis system from real data without requiring either documentation or historical reports about fault cases. Second, a group of significant faults have been modeled and implemented in a dynamic system level simulator in order to generate an artificial labeled database, which is extremely important in evaluating and comparing the proposed solutions with the state-of- the-art algorithm. Then, the diagnosis of those faults that cannot be identified through the statistical performance indicators gathered at cell level is automated by the analysis of the mobile traces avoiding the costly <b>drive</b> <b>test.</b> In particular, in this thesis, the mobile traces have been used to automatically identify the cause of each unexpected user disconnection, to geo-localize RF problems that affect the cell performance and to identify the impact of a fault depending on the availability of legacy systems (e. g. Third Generation, 3 G). Finally, the proposed techniques have been validated using real and simulated LTE data by analyzing its performance and comparing it with reference mechanisms...|$|R
40|$|<b>Drive</b> <b>test</b> is one <b>of</b> {{the first}} steps {{in the process of}} network {{optimization}} that aims to collect data measurements in less optimal areas. <b>Drive</b> <b>test</b> requires many tools such as laptop with TEMS software installed, mobile phone, data cable, GPS and usually a car. This study aims to design android applications {{that can be used to}} do <b>drive</b> <b>test</b> with idle mode method without requiring many tools and the results <b>of</b> <b>drive</b> <b>test</b> data analysis can be used for network optimization in less optimal areas. The result of data analysis <b>of</b> <b>drive</b> <b>test</b> application named SignalTrack shows that RSCP value on Jl. Prof. M. Yamin is still bad because the spot ratio is very good, which is only 55. 74 % while usually each provider targets 95 % threshold. The comparison <b>of</b> <b>drive</b> <b>test</b> application by using NEMO software if being seen from the drawing and table result is similar, and for the level of accuracy of SignalTrack is also not much different from NEMO...|$|R
30|$|The {{serving cell}} {{occupied}} by the present <b>drive</b> <b>test</b> terminal's traffic can be located from <b>test</b> data <b>of</b> <b>drive</b> <b>test</b> which having problems of Rx-Quality Sub, which means the serving cell having problems.|$|R
50|$|Free Radio (network) have {{recorded}} a number <b>of</b> <b>drive</b> <b>tests</b> for Vauxhall Motors at Hednesford Raceway {{and are also}} an official partner of the venue, advertising each of the events held there.|$|R
40|$|This paper {{focuses on}} the {{analysis}} of a large volume <b>of</b> <b>drive</b> <b>test</b> data and the identification of adverse trends or aberrant behavior of a mobile handset under <b>test</b> by means <b>of</b> <b>drive</b> <b>test</b> data visualization. The first target application was to identify poor mobility decisions that are made by the handsets in calls. The goal was to compare a set of behaviors from a baseline unit (one accepted to generally operate well). We {{were able to identify}} a particular call that was exhibiting a different path (talking to a different cell than expected or taking longer to move to a new cell). In this paper we develop a mobility tool that evaluates the handset’s performance by means of mapping the handoffs on the Google Maps. The mapping of the handoffs by means of the Google Maps were very powerful in identifying the above mentioned mobility patterns. Keywords: Mobility Patterns, Hand-offs, Drive Test, Mobile phones. 1...|$|R
40|$|In {{this present}} era, the {{development}} of mobile technology runs very fast along with the human’s needed to obtain information that the higher and infinite. Technology of Wideband Code Division Multiple Access is an access technology that was developed as a standard of third-generation (3 G) mobile telephone technology. Technology of WCDMA use chip rate of 3. 84 Mbps that allows customers to obtain the use of high speeds data transfer for each user. With these technologies {{are expected to be}} obtained of good quality also for voice services. Measuring the quality of calls for service WCDMA system can be done by looking at some network Quality of Service parameters. Low QoS value is caused by some disturbance that occurred on the network, one that is drop call. Analysis of the drop call can be done through observation of statistical data. In addition, to find out the actual situation of liver location drop call can be made through the analysis <b>of</b> <b>drive</b> <b>test</b> data. Process <b>of</b> voice services analysis is done by making the simulation program using Matlab 7. 8. The simulation consists of three main parts: analysis of statistical data drop call, analysis of drop call data simulation, and analysis <b>of</b> <b>drive</b> <b>test</b> data simulation. Several parameters used in the process of drop call data analysis, among others, drop call is caused missing neighbor, soft handover, IRAT / hard handover, congestion, out of synchronization, other factors, and establish the call. For the simulation <b>of</b> <b>drive</b> <b>test</b> data, the parameters used, among others, and then BLER (Block Error Rate), RSSI (Received Signal Strength Indicator), CPICH RSCP (Common Pilot Channel Received Signal Code Power), CPICH Ec / No (Common Pilot Channel Ec / No), SQI (Speech Quality Index), and TxPo (Transmitter Power). The results show a base station will require optimization if the value of Speech Drop Rate exceeds 2...|$|R
40|$|Abstract — Even though mobile radio systems deliver {{more and}} more {{performance}} data {{there is always a}} need to measure the performance of the network in the field. These measurements can either be part of the deploying new network sites inorder to meet coverage, capacity and quality requirements, optimization of the network, benchmarking of performance, trouble shooting, or to verify the performance after an upgrade or reconfiguration of the network. These measurements are performed through Drive Test and RF survey. <b>Drive</b> <b>testing</b> is principally applied in both the planning and optimization stage of network development. The paper focuses on the procedure <b>of</b> <b>drive</b> <b>test</b> and its importance in network planning...|$|R
40|$|This paper {{presents}} {{a number of}} Self-Organising Network (SON) based methods using a 3 GPP Minimisation <b>of</b> <b>Drive</b> <b>Testing</b> (MDT) approach or similar and the analysis of these geo-located UE measurements to maximise traffic offload onto lamppost mounted 3 G/WCDMA microcells. Simulations have been performed for a real 3 G/WCDMA microcell deployment in a busy area of central London and {{the results suggest that}} for the network studied a traffic increase on the microcell layer of up to 175 % is achievable through the novel SON methods presented...|$|R
40|$|Code Division Multiple Access (CDMA) is a {{modulation}} technique and multiple access techniques based on directsequence spread spectrum signal transmission where the bandwidth occupied spectrum exceeds the minimum {{required in the}} spread spectrum technique. Development and use of CDMA techniques in multiple access wireless communications based on the consideration of the increasing needs of today's mobile communications. Channel capacity of cellular systems that have been applied so far from having limitations. CDMA 2000 1 x is CDMA system with two kinds of channels. It is supplemental channel and fundamental channel. Fundamental channel for 9. 6 kbps used for voice calls, while the Supplemental channels are used when making a call high-speed data packet at least twice {{the speed of the}} fundamental channel, and maximum reach 153. 6 Kbps. <b>Drive</b> <b>test</b> is important and useful steps to obtain performance values of the mobile phone. <b>Drive</b> <b>test</b> device that is used TEMS which {{can be used as a}} <b>drive</b> <b>test</b> device CDMA network. Log files <b>of</b> TEMS <b>drive</b> <b>test</b> results must be exported use Actix Software to file (. tab), which in turn can be used in the analysis of call quality using CDMA 2000 1 x main aid software Map Info. Analyzing the data and discussion <b>of</b> <b>drive</b> <b>test</b> on the Map Info is on every spot of the quality of the main parameters that are less good. Spot is a part of the overall area <b>of</b> the <b>drive</b> <b>test</b> route done. The main parameters are FFER (Forward FER), RSSI (Receive signal strength Interference), Ec / Io, TxGA, and Tx Power. Results of analysis showed that <b>drive</b> <b>test</b> route <b>of</b> this final project, almost in good call condition. However, there are many spot not in ideal conditions. Spot 1 suffer reverse channel interference. Then in spot 2 and spot 3 also occurs forward channel interference [...] The unideal main parameters value caused by interference and incomplete handoff. It’s can be overcome with decrease TxPower level. Keywords: CDMA 2000 1 x, Call Analysis, Drive Test, TEMS, Map Info, FFER, RSSI, Ec / Io, TxGA, Tx Power...|$|R
30|$|The {{following}} figures provide {{statistical data}} concerning the <b>test</b> <b>drives.</b> The <b>test</b> protocol consisted of ten questions: name of the operator, name of the attendant, number of passengers, test route (short or long), test purpose, test audience, weather conditions, road conditions, problems during the drive and applied solutions to the problem. During the test period from April 24 th to November 22 th a total <b>of</b> 240 <b>test</b> <b>drives</b> were conducted, <b>of</b> which 102 were on the long route and 138 on the short route. The <b>test</b> <b>drives</b> covered a distance of almost 341  km. During these <b>test</b> <b>drives</b> 874 persons were transported. The majority <b>of</b> <b>test</b> <b>drives</b> (70 %) were conducted in sunny and dry or slight cloudy conditions. For almost 28 % <b>of</b> the <b>test</b> <b>drives</b> it was cloudy respectively very cloudy and rainy. 0.7 % <b>of</b> the <b>test</b> <b>drives</b> took place during snowfall. However, <b>test</b> <b>drives</b> and a few rides in heavy rain had to be stopped because of weather conditions. The majority <b>of</b> the <b>test</b> <b>drives</b> (45 %) was conducted for demonstration purposes for an external audience. These demonstration drives were held either for company delegations, representatives from road or transport authorities, for the press or for private persons. 38 % <b>of</b> the <b>drives</b> were used for operator training, <b>test</b> <b>drives</b> for data collection or <b>test</b> <b>drives</b> without external passengers immediately after the commissioning of the self-driving shuttle. Almost 18 % of the trips were conducted for technical tests. Here, for example, optimizations were made on the route guidance, the software was updated, brake tests were made, or the functionality and/or range of the sensors were tested.|$|R
