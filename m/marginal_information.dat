80|101|Public
50|$|The {{document}} (digital or paper) representing an orthophotomosaic {{with additional}} <b>marginal</b> <b>information</b> like a title, north arrow, scale bar and cartographical information is called an orthophotomap or image map. Often these maps show additional point, line or polygon layers (like a traditional map) {{on top of}} the orthophotomosaic. A similar document, mostly used for disaster relief, is called a spatiomap.|$|E
50|$|High {{profitability}} of the bulk trade {{resulted in the}} possibility of large savings, and the reservoir of savings looking for profitable investment eventually resulted in a lowering of interest rates as a primary effect, and of the development of sophisticated financial markets as a secondary effect. Such financial markets also profited from the phenomenon of decreasing <b>marginal</b> <b>information</b> cost; this soon helped make Amsterdam an important financial center also.|$|E
5000|$|In {{statistical}} mechanics, Loschmidt's paradox may {{be expressed}} in terms of mutual information. Loschmidt noted that it must be impossible to determine a physical law which lacks time reversal symmetry (e.g. the second law of thermodynamics) only from physical laws which have this symmetry. He pointed out that the H-theorem of Boltzmann made the assumption that the velocities of particles in a gas were permanently uncorrelated, which removed the time symmetry inherent in the H-theorem. It can be shown that if a system is described by a probability density in phase space, then Liouville's theorem implies that the joint information (negative of the joint entropy) of the distribution remains constant in time. The joint information is equal to the mutual information plus the sum of all the <b>marginal</b> <b>information</b> (negative of the marginal entropies) for each particle coordinate. Boltzmann's assumption amounts to ignoring the mutual information in the calculation of entropy, which yields the thermodynamic entropy (divided by Boltzmann's constant).|$|E
40|$|This paper {{deals with}} {{transportation}} polytopes in the probability simplex (that is, sets of categorical bivariate probability distributions with prescribed <b>marginals).</b> <b>Information</b> projections between such polytopes are studied, and a sufficient condition is described under which these mappings are homeomorphisms. Comment: 6 pages, 1 figure. v 2 : A remark concerning Frechet-Hoeffding bounds is adde...|$|R
40|$|This paper {{characterizes the}} set of {{equilibrium}} networks in the two-way flow model of network formation with small decay, and this for all increasing benefit functions of the players. We show {{that as long as}} the population is large enough, this set contains large- as well as small-diameter networks. For all benefit functions, the periphery-sponsored star is the most stable. When the <b>marginal</b> benefits of <b>information</b> are constant, all non-star networks are equally stable. With increasing <b>marginal</b> benefits of <b>information,</b> small-diameter networks in general tend to be more stable. However, with decreasing <b>marginal</b> benefits of <b>information,</b> large-diameter networks tend to be the most robust along with the periphery-sponsored sta...|$|R
40|$|We give {{analytical}} bounds on the Value-at-Risk and on convex risk {{measures for}} {{a portfolio of}} random variables with fixed marginal distributions under an additional positive dependence structure. We show that assuming positive dependence information in our model leads to reduced dependence uncertainty spreads compared to the case where only <b>marginals</b> <b>information</b> is known. In more detail, we show that in our model the assumption of a positive dependence structure improves the best-possible lower estimate of a risk measure, while leaving unchanged its worst-possible upper risk bounds. In a similar way, we derive for convex risk measures that the assumption of a negative dependence structure leads to improved upper bounds for the risk while it does not help to increase the lower risk bounds in an essential way. As a result we find that additional assumptions on the dependence structure may result in essentially improved risk bounds...|$|R
50|$|The entrepôt {{performed}} an additional function, a derivative of its primary market-function: the physical proximity of merchants promoted {{the exchange of}} information about market forces, prices, and developments in the factors underlying supply and demand. This not only lowered the cost of information-gathering but even led to decreasing <b>marginal</b> <b>information</b> costs. Other things being equal, this externality would lower the total marginal cost of goods trading through the entrepôt. It is a well-known economic fact that in circumstances of decreasing marginal costs, economies of scale occur, which can give an advantage to early entrants that permits them to outgrow their competitors, sometimes even leading to a natural monopoly. This may explain why {{in the field of}} entrepôts certain markets (Antwerp, Amsterdam) gained a dominant position for some time, while others (London, Hamburg) were left behind and only came into their own when the special circumstances favoring the others came to an end. In the case of Amsterdam those circumstances changed when the technological possibilities of direct trade improved, obviating the intermediating function of the entrepôt.|$|E
40|$|Census reports can be {{interpreted}} as providing nearly exact knowledge of moments of the marginal distribution of economic variables. This information can be combined with cross-sectional or panel samples to improve accuracy of estimation. In this paper, the authors show how to do this efficiently. They show that the gains from use of <b>marginal</b> <b>information</b> can be substantial. The authors also discuss how to test the compatibility of sample and <b>marginal</b> <b>information.</b> Copyright 1994 by The Review of Economic Studies Limited. ...|$|E
40|$|This paper {{develops}} {{a model of}} information collection about publicly traded firms in an economy. The supply noise is modeled as the variability of liquidity-motivated trading in the shares of the firm. The paper theoretically examines the influence of various firm characteristics {{on the amount of}} information collected about a firm and on the <b>marginal</b> <b>information</b> content of announcements made by it. Empirical work focuses on the <b>marginal</b> <b>information</b> content of quarterly earnings announcements made by firms. The empirical results are generally consistent with the model's predictions...|$|E
40|$|International audienceThis paper {{deals with}} the {{existence}} of a nonconcavity in the value of information, as was first explained by Radner and Stiglitz [A nonconcavity in the value of information, in: M. Boyer, R. E. Kihlstrom (Eds.), Bayesian Models in Economic Theory, Elsevier Science Publishers, Amsterdam, 1984, pp. 33 - 52 (Chapter 3) ]. After defining infinitesimal information distance variationIIDV, we find that IIDV = 0 is sufficient for a zero <b>marginal</b> value of <b>information</b> at the null. This is a condition only on the information structure and in particular is independent of the decision maker's preferences. This condition is tight: when IIDV > 0, there exists a payoff function for which the <b>marginal</b> value of <b>information</b> at the null is positive under general assumptions. © 2007...|$|R
40|$|We {{propose a}} copula density {{estimator}} that can include <b>information</b> on bivariate <b>marginals</b> when the <b>information</b> is available. We use B-splines for copula density approximation and include <b>information</b> on bivariate <b>marginals</b> via a penalty term. Our estimator satisfies the constraints for a copula density. Under mild conditions, the proposed estimator is consistent...|$|R
40|$|This paper {{introduces}} a general model of matching that includes evolving public Bayesian reputations and stochastic production. Despite productive complementarity, assortative matching robustly fails for high discount factors, unlike in Becker (1973). This failure holds around the highest (lowest) reputation agents for "high skill" ("low skill") technologies. We find that matches of likes eventually dissolve. In another life-cycle finding, young workers are paid {{less than their}} marginal product, and old workers more. Also, wages rise with tenure but need not reflect <b>marginal</b> products: <b>information</b> rents produce non-monotone and discontinuous wage profiles. Copyright © 2009 The Review of Economic Studies Limited. ...|$|R
40|$|Our {{purpose is}} to study the visual memory (VM) of natural complex scenes in {{function}} of subjects’ expertise. 15 subjects were divided into 3 groups according to their level of driving expertise (novices, 5 years of experience) {{and were asked to}} memorize road images (divided into 3 levels of complexity). After each image presentation (5 second presentation), subjects were asked to answer 6 questions, 3 about central information for driving and 3 about marginal items (not relevant for driving) and to estimate their self-confidence. Our results showed an effect of detail type, subjects’ expertise and stimulus complexity: performance was significantly better for central items than for <b>marginal</b> <b>information,</b> for less complex images than for more complex images and with experts (level 2 and 3) than novices (level 1). We observed no interaction between these 3 variables (detail type, image complexity and subjects’ expertise). This finding suggests difference between central and <b>marginal</b> <b>information</b> in VM performance is stable independently of the image complexity and subjects’ expertise. It generalizes results from our previous study with experts in art history and from Melcher’s study (2006) that showed difference between central and <b>marginal</b> <b>information</b> was stable independently of stimulus presentation duration. Peer reviewe...|$|E
40|$|Many {{existing}} spectral clustering algorithms share {{a conventional}} graph partitioning criterion: normalized cuts (NC). However, {{one problem with}} NC is that it poorly captures the graph’s local <b>marginal</b> <b>information</b> which {{is very important to}} graph-based clustering. In this paper, we present a discriminant analysis based graph partitioning criterion (DAC), which is designed to effectively capture the graph’s local <b>marginal</b> <b>information</b> characterized by the intra-class compactness and the inter-class separability. DAC preserves the intrinsic topological structures of the similarity graph on data points by constructing a k-nearest neighboring subgraph for each data point. Consequently, the clustering results generated by the DAC-based clustering algorithm (DACA) are robust to the outlier disturbance. Theoretic analysis and experimental evaluations demonstrate the promise and effectiveness of DACA. ...|$|E
30|$|It {{should be}} noted that – for privacy reasons – there is no public {{database}} on migrant entrepreneurship in the Netherlands. All information has to be collected through carefully designed interview schemes. This is a rather painstaking process, regarding not only the interview itself, but also the preparation time required to identify an entrepreneur who is willing to participate. This leads necessarily to small samples (in our case, 83). However, for a benchmark analysis this is a reasonable number. An important test criterion for the size of the sample is whether the <b>marginal</b> <b>information</b> gain from the last interviewees is declining to zero (the ‘zero <b>marginal</b> <b>information</b> gain stopping rule’). Statistical representativeness is then becoming less problematic in this type of field research (see for a justification and details, Yin 1984).|$|E
40|$|The <b>marginal</b> {{forecast}} <b>information</b> {{contained in}} deferred futures prices is evaluated using the direct test of Vuchelen and Gutierrez. In particular, the informational role of deferred futures contracts in live cattle and hogs is assessed from the two- to twelve-month horizons. The {{results indicate that}} unique information is contained in live cattle futures prices out through the ten-month horizon, while hog futures prices add incremental information at all tested horizons. Practitioners using futures-based forecasting methods are well-served by deferred hog futures prices; however, live cattle futures listed beyond the 10 month horizon are not adding incremental information. forecast information, forecast evaluation, livestock futures,...|$|R
30|$|Our second {{algorithm}} derives {{the seed}} set from pre-computed seed set of constituent topics, {{which is based}} on Observation  2. Moreover, it uses <b>marginal</b> influence <b>information</b> pre-computed to help select seeds from different seed sets. Our idea is partially motivated from Observation  1, especially the observation on Arnetminer dataset, which shows that in some cases the network could be well separated among different topics. Intuitively, if nodes are separable among different topics, and each node v is only pertinent to one topic i, the marginal influence of v would not change much whether it is for a mixed item or the pure topic i. The following lemma makes this intuition precise for the extreme case of fully separable networks.|$|R
40|$|The sub-optimal "meliorating" {{behavior}} {{studied by}} Herrnstein shows that all known animal species match average and not <b>marginal</b> payoffs. When <b>information</b> processing is costly, Herrnstein’s matching {{and a similar}} simplifying "paradox" discovered by Allais may be efficient for agents averse {{to the risk of}} making errors. Such simplification is likely to be an evolutionarily stable strategy. Differential aversion to errors can lead to different estimates, even without differences in estimating ability. ...|$|R
40|$|<b>Marginal</b> <b>information</b> is {{of great}} {{importance}} for classification. This paper presents a new nonparametric linear discriminant analysis method named Push-Pull marginal discriminant analysis (PPMDA), which takes full advantage of <b>marginal</b> <b>information.</b> For two-class cases, {{the idea of this}} method is to determine projected directions such that the marginal samples of one class are pushed away from the between-class marginal samples as far as possible and simultaneously pulled to the within-class samples as close as possible. This idea can be extended for multi-class cases and give rise to the PPMDA algorithm for feature extraction of multi-class problems. The proposed method is evaluated using the CENPARMI handwritten numeral database, the Extended Yale face database B and the ORL database. Experimental results show the effectiveness of the proposed method and its advantage after performance over the state-of-the-art feature extraction methods. Department of Computin...|$|E
40|$|At head of title: Danmark. "AMS C 521, C 531, C 541. "Photolithograph {{reproduction}} of sheets partly covering Greenland, {{originally published in}} Copenhagen in 1936 - 1938. Elevations shown by contours at 50 meter intervals. <b>Marginal</b> <b>information</b> in Danish and English. Some sheets have imprint or series note. Three index maps on separate sheets, 24 x 36 cm...|$|E
30|$|As can be {{seen from}} the figure, the images (c) and (d) have {{different}} degrees of blur, such as the <b>marginal</b> <b>information</b> of the runways and the outline of the aircraft is not clear, compared to (c) and (d), the image (e) is clearer as far as the visual effect is concerned. For example, the image (e) contours of aircraft and distant details such as trees and buildings look more clearly.|$|E
40|$|Information {{technology}} (IT) is {{an important}} aspect of the electronic supply chain management (SCM). Advances in information technology, particularly in the Internet, enables companies to share information within and inter-organizations. The Internet and its three important types of networks: Intranet, Extranet, and Web allow organization to transfer digital data instantly and with high fidelity at nearly zero <b>marginal</b> cost. <b>Information</b> sharing is a vital aspect of coordination amongst parties in a supply chain. Information sharing can increase supply chain efficiency by reducing inventories and smoothing production. In Addition, e-commerce can enhance selling online and help better understand customers. E-SCM efficiency is highly important as today’s competition is no longer between companies, but between supply chains. This paper examined how IT- th...|$|R
40|$|International audienceThis paper {{describes}} how eight undergraduate students majoring in economics and business studies reasoned about marginal change (marginal cost, marginal revenue, and marginal profit) {{in the process}} of deciding how they would advise the management team of an airline about an economic decision involving the addition of another jet plane. To elicit students' understanding of marginal change in an economic context, pairs of students were engaged in a task-based interview. Nearly all of the students were able to reason correctly about marginal change within the immediate context of the task, while four of the students also did so beyond the context presented in the task. Only one student considered the <b>marginal</b> change <b>information</b> in the task as a rate of change...|$|R
40|$|In {{this paper}} we fit {{stochastic}} frontier production functions to data for Chinese farms grouped {{into each of}} four regions—North, Northeast, East, and Southwest—over 1995 - 1999. These frontier production functions are shown to have statistically different structures, and the <b>marginal</b> product <b>information</b> shows overuse of chemical inputs in the East and capital services in the North. Labor also has a low marginal product. Next, we use the data and the production parameters to create technical efficiency scores {{for each of the}} farms and then standardize them. Standardized technical efficiency is shown to have the same structure across regions and {{to be related to the}} age of the farmer, land fragmentation, and the village migration rate, controlling for year dummies and village or regional fixed effects...|$|R
40|$|Recently (Beh, 2008, JSPI) {{presented}} an index {{that helps to}} identify how likely two dichotomous categorical variables may be associated given only the aggregate (or <b>marginal)</b> <b>information.</b> Such an index {{was referred to as}} the aggregate association index. This paper will further consider some of the issues concerned with that index. These include variations of the original index as well as adaptations for quantifying the possibility that there exists a statistically significant positive or negative association between the two dichotomous variables...|$|E
40|$|While linear time-series models, {{technical}} analysis, {{and momentum}} models all extract information from past market data, they each interpret data differently. We test the informative role of three representative models {{and examine the}} trading performance of a combined forecasting model at the individual stock level. Our results indicate that these models all contain <b>marginal</b> <b>information</b> and complement each other. The combined trading model captures higher upward trending returns and provides the same downward trending returns compared with the buy-and-hold strategy...|$|E
40|$|A new {{detection}} criterion {{based on}} {{the change in the}} <b>marginal</b> <b>information</b> redundancy is presented. By establishing a link with information theory we are able to give an intuitive interpretation of our criterion. The usefulness of the new criterion is demonstrated for a case study of human movement initiation detection from force and torque signals in activity of daily living tasks. Using the new criterion, we achieve a performance that is more in agreement with expert decisions compared with traditional thresholding techniques and the advanced wavelet-based detector and energy detectors. status: publishe...|$|E
40|$|Using {{strictly}} defined {{criteria of}} significant arrhythmias, long term electrocardiographic recording has been evaluated for confirmation of arrhythmias {{as the cause}} of cerebral symptoms in 81 patients with suspected Adams-Stokes syndrome. Extension of long term electrocardiographic recording for more than 24 hours gives <b>marginal</b> additional <b>information</b> at a high cost. Among 43 patients monitored until symptoms appeared, non cardiogenic causes were confirmed in 20 of 22 patients because the recording showed normal rhythm during symptoms. Fifteen of 21 patients with a significant arrhythmia during an asymptomatic 24 hour recording later had the same arrhythmia during symptoms. Of 38 patients who failed to develop symptoms, 21 had a significant arrhythmia detectable within 24 hours and 23 when 48 hours of recording were analysed...|$|R
40|$|The <b>marginal</b> cost <b>information</b> {{needed to}} {{implement}} traditional inventory models {{is not likely}} to be available in practice. The most important inventory management issues in practive involve aggregate objectives and constraints while the richest theoretical models deal with single item management. To help resolve these problems, the authors propose that inventory decisions be conceived as policy tradeoffs on a three dimensional response surface showing the optimal relationships among aggregate customer service, workload, and investment. We show that any optimal management decision must result in a point located on the surface. Computational results show that the methodology suggested can make improvements in management policy in four inventories that total more than 78, 000 line items. inventory/production: parametric analysis, inventory/production: stochastic models, military: logistics...|$|R
40|$|Test {{selection}} in psychological assessment is guided, both explicitly and implicitly, by how informative tests are {{with regard to}} a trait of interest. Most existing formulations of test information are sensitive to subpopulation variation, {{with the result that}} test information will vary from sample to sample. Recently, measures of test information have been developed that quantify the potential informativeness of the test. These indices are defined by the properties of the test, as distinct from the properties of the sample or examinee. As of yet, however, measures of potential information have been developed only for unidimensional tests. In practice, psychological tests are often multidimensional. Furthermore, multidimensional tests are often used to estimate one specific trait among many. This study develops measures of potential test information for multidimensional tests, as well as measures of <b>marginal</b> potential test <b>information</b> [...] -test information with regard to one trait within a multidimensional test. In Study 1, the performance of the metrics was tested in data simulated from unidimensional, first-order multidimensional, second-order, and bifactor models. In Study 2, measures of marginal and multidimensional potential test information are applied to a set of neuropsychological data collected as part of Rush University 2 ̆ 7 s Memory and Aging Project. In simulated data, marginal and multidimensional potential test information were sensitive to the changing dimensionality of the test. In observed neuropsychological data, five traits were identified. Verbal abilities were most closely correlated with probable dementia. Both indices of <b>marginal</b> potential test <b>information</b> identify the Mini Mental Status Exam as the best measure of that trait. More broadly, greater <b>marginal</b> potential test <b>information</b> calculated with regard to verbal abilities was associated with greater criterion validity. These measures allow for the direct comparison of two multidimensional tests that assess the same trait, facilitating test selection and improving the precision and validity of psychological assessment...|$|R
40|$|Abstract. It is {{well known}} that in linear programming, the optimal values of the dual {{variables}} can be interpreted as shadow prices (marginal values) of the right-hand side coefficients. However, this is true only under nondegeneracy assumptions. Since real problems are often degenerate, the output from conventional LP software regarding such <b>marginal</b> <b>information</b> can be misleading. This paper surveys and generalizes known results in this topic and demonstrates how true shadow prices can be computed with or without modification to existing software. Key words: linear programming, shadow prices, optimization software. 1...|$|E
40|$|The aim of {{the thesis}} is to {{determine}} whether schoolchildren at primary school can distinguish essential and <b>marginal</b> <b>information</b> in different types of text communications. The work deals with what relevant information pupils seek with difficulty and on the contrary, which of them they find easily. There are information about different peformances of girls and boys in this area. The work contains also comparing the results among schools and pupils with different classification. There {{is an effort to}} find out the type of the text communication, in which pupils look for substantial information easily...|$|E
40|$|This paper {{addresses}} {{the question of}} whether nominal Eurocurrency interest rates provide significant information about expected inflation. To test this question two sets of inflation forecasts for the U. S. and five European countries were generated: 1) from time series of past inflation rates; 2) by forecasting real rates from time series of past real rates and subtracting these forecasts from nominal rates. The accuracy of the two sets of inflation forecasts was compared. The results indicate that nominal Eurocurrency rates provide valuable <b>marginal</b> <b>information</b> about expected inflation for the U. S. and U. K., but not for the other European countries. ...|$|E
40|$|Recently {{there has}} been a surge in econometric and {{epidemiologic}} works focusing on estimating average treatment effects under various sets of assumptions. Estimation of average treatment effects in observational studies often requires adjustment for differences in pretreatment variables. Rosenbaum and Rubin have proposed the propensity score method for estimating the average treatment effect by adjusting pretreatment variables. In this paper, the empirical likelihood method is used to estimate average treatment effects on the treated under the difference-in-differences framework. The advantage of this approach is that the common <b>marginal</b> covariate <b>information</b> can be incorporated naturally to enhance the estimation of average treatment effects. Compared with other approaches in the literature, the method proposed can provide more efficient estimation. A simulation study and a real economic data analysis are presented. Copyright (c) 2008 The Authors. ...|$|R
40|$|This paper {{shows how}} a Metropolis-Hastings {{algorithm}} with efficient jump {{can be constructed}} for the estimation of multiple threshold time series of the U. S. short term interest rates. The results show that interest rates are persistent in a lower regime and exhibit weak mean reversion in the upper regime. For model selection and specification several techniques are used such as <b>marginal</b> likelihood and <b>information</b> criteria, as well as estimation with and without truncation restrictions imposed on thresholds. ...|$|R
40|$|The {{theory of}} optimal {{taxation}} {{has shown that}} bunching can be optimal under certain circumstances so that low-skilled agents are not offered any work incentives. Optimal bunching balances the marginal costs of voluntary unemployment and the <b>marginal</b> reduction in <b>information</b> rents for high-skilled workers. This paper demonstrates how the optimal scheme will change if the budget is cut. It shows that a tighter budget constraint {{will lead to more}} voluntary unemployment and less work incentives. Copyright Blackwell Publishing, Inc. 2002. ...|$|R
