22|25|Public
5000|$|During the 1980s {{the term}} [...] "WIMP", {{which stands for}} window, icon, <b>menu,</b> <b>pointer,</b> was coined at PARC.|$|E
40|$|Abstract: Pen-Based user {{interface}} {{is a primary}} Post-WIMP (window icon <b>menu</b> <b>pointer)</b> interface, and it provides natural interactions for users. However, the current toolkits for constructing pen-based {{user interface}} are built for single-user tasks, which can not support collaborative work well. This paper analyzes the features of pen-based interaction and collaboration environment. Furthermore, the design and implementation of a toolkit, CoPen Toolkit, which can support the development of collaborative pen-based user interfaces are discussed. CoPen Toolkit offers flexible architecture and extended components, which can support ink-based data, event processing, networked collaboration, etc. Based on CoPen Toolkit, several typical prototypes have been built, and {{the results show that}} it can support construction and fast-prototyping of collaborative pen-based user interfaces. Key words: collaborative pen-based interaction; user interface; toolkit 摘 要: 笔式用户界面是一种重要 的 Post-WIMP(window icon <b>menu</b> <b>pointer)</b> 界面,它给用户提供了自然的交互...|$|E
40|$|This paper {{describes}} {{an attempt to}} enhance a windows based (WIMP - Windows Icon <b>Menu</b> <b>Pointer)</b> environment. The goal is to establish whether user interaction on the common desktop PC can be augmented by adding new modalities to the WIMP interface, thus bridging the gap between todays interaction patterns and future interfaces comprising e. g. advanced conversational capabilities, VR technology, etc...|$|E
5000|$|In computing, a {{windowing}} system (or window system) is software that manages separately {{different parts of}} display screens. It {{is a type of}} graphical user interface (GUI) which implements the WIMP (windows, icons, <b>menus,</b> <b>pointer)</b> paradigm for a user interface.|$|R
25|$|A {{series of}} {{elements}} conforming a visual language {{have evolved to}} represent information stored in computers. This {{makes it easier for}} people with few computer skills to work with and use computer software. The most common combination of such elements in GUIs is the windows, icons, <b>menus,</b> <b>pointer</b> (WIMP) paradigm, especially in personal computers.|$|R
25|$|Since the {{commands}} available in command line interfaces can be many, complex operations {{can be performed}} using a short sequence of words and symbols. This allows greater efficiency and productivity once many commands are learned, but reaching this level takes some time because the command words may not be easily discoverable or mnemonic. Also, using the command line can become slow and error-prone when users must enter long commands comprising many parameters or several different filenames at once. However, windows, icons, <b>menus,</b> <b>pointer</b> (WIMP) interfaces present users with many widgets that represent and can trigger some of the system's available commands.|$|R
40|$|We {{introduce}} a multiplatform C++ framework for managing application windows respectively displayed content. The framework provides an API for handling display devices, representation and presentation of displayed content, managing input events and other actions. Furthermore, objects are extended with semantic context which defines their functional properties. Semantics allows more accurate classification of entities, choosing more accurate reactions for incomming signals. The framework provides platform, {{which does not}} strictly rely on classical WIMP (windows, icons, <b>menu,</b> <b>pointer)</b> paradigm and gives ability to develop solutions non-conventional way (e. g. zoomable UI, tangible UI) ...|$|E
40|$|This study compares a {{traditional}} 3 D WIMP (Window Icon <b>Menu</b> <b>Pointer)</b> modeller to {{a prototype of}} a novel system with a 6 DOF haptic feedback device, stereovision and a co-located display, both in quantitative and qualitative terms. The novel system was conceived to overcome limitations of traditional interaction techniques and devices when dealing with three-dimensions. Experimental results confirm the fundamental role of spatial input for 3 D modelling and the significant contribution of haptics and stereovision to qualitative and quantitative performance. A review of relevant research and motivations for the study is presented along {{with a discussion of}} main outcomes...|$|E
40|$|Screenshots, {{known for}} years as {{capturing}} Graphical User Interface by means of print screen button or capturing software, is not only beneficial for creating user guide or user manual document, but also for reverse engineering process. This paper presents {{a new way of}} capturing the data appear on a screen by creating the ontology of its interface. Data capturing based on the interaction style of interface or windowing system, known as WIMP (Window Icon <b>Menu</b> <b>Pointer).</b> The Ontology model used as template, called as WIMP-UI. OWL is used as ontology language, Portégé as editor tools, and Pellet reasoner for reasoning...|$|E
40|$|With the {{introduction}} of new modes to control user interfaces like speech, gesture and multi-touch Post-WIMP interfaces increasingly substitute classical WIMP (windows, icons, <b>menus,</b> <b>pointer)</b> user interfaces. In this paper, we describe a toolchain of three connected tools to design and monitor custom Post-WIMP interactors using model-based user interface design (MBUID) methods. We use state charts and mappings as the basic modeling technique. Different to other MBUID approaches our models are get created to specify the behavior of existing widgets. These models are then used to attach further control modes and connect interactors using mappings. We explain the toolchain by an interactive music sheet web application that can be controlled by head movements to turn the sheets...|$|R
40|$|VR {{systems are}} well {{accepted}} in the product development process today. However this technology {{does not have a}} broad penetration and high number of installations in comparison to desktop systems, due to the high investments in VR technology especially hardware. On the user interface side many VR systems took over ideas from traditional WIMP interfaces (windows, icons, <b>menus,</b> <b>pointers)</b> without maintaining a smooth transition for the users from desktop environments to immersive environments and vice versa. In addition a great bunch of multi modal interaction techniques have been developed to render VR interaction more intuitively. This paper discusses various user interface concepts of VR systems and their use along the product development process. We give examples for solutions and projects developed in collaboration with different companies, such as BMW, Italdesign, FIAT, Airbus...|$|R
25|$|Electronic paper {{technologies}} {{have a very}} low refresh rate compared to other low-power display technologies, such as LCD. This prevents producers from implementing sophisticated interactive applications (using fast-moving <b>menus,</b> mouse <b>pointers</b> or scrolling) like those common on standard mobile devices. An example of this limit is that a document cannot be smoothly zoomed without either extreme blurring during the transition or a very slow zoom.|$|R
40|$|Abstract: We have {{developed}} a browsing tool for visualizing information about the lunar surface that uses map-based AR (augmented reality) in which virtual objects are superimposed on an actual map, resulting in a tangible user interface. In particular, our browsing tool enables a user {{to learn about the}} exploration conducted during the Apollo 17 mission by using a map of the lunar surface with geographically embedded information. We conducted a preliminary experiment to investigate the practicality of this interface compared to a WIMP (window, icon, <b>menu,</b> <b>pointer)</b> interface. The results showed that the AR interface is suitable for learning about the lunar surface and that it is probably better for children than the WIMP interface...|$|E
40|$|One of {{the most}} {{complicated}} tasks when working with three-dimensional virtual worlds is the navigation process. Usually, this process {{requires the use of}} buttons and key-sequences and the development of interaction metaphors which frequently makes the interaction process artificial and inefficient. In these environments, very simple tasks, like look upward and downward can became extremely complicated. To overcome these obstacles, this work presents an interaction model for three-dimensional virtual worlds, based on the interpretation of the natural gestures of a real user while he/she is walking in a real world. This model {{is an example of a}} non-WIMP(Window, Icon, <b>Menu,</b> <b>Pointer)</b> interface. To test this model we created a device named virtual-bike. With this device, the user can navigate through the virtual environment exactly as if he were riding a real bike. KEYWORDS: virtual reality, non-WIMP(Windows, Icon...|$|E
40|$|Abstract—Geometric Modeling is {{a widely}} studied area in {{computer}} graphics and methods for constructing 3 D models with intuitive interfaces are a topic that has been attracting the interest of many researches. In contrast to the complicated interfaces of modeling softwares, created using the WIMP paradigm (Window, Icon, <b>Menu,</b> <b>Pointer),</b> several studies have shown applications with interfaces based on gestures, which are simpler and more natural. In this scenario, the area of Sketch-Based Interfaces and Modeling (SBIM) emerged. Sketch is a very efficient tool to convey the essence of an object with few strokes, because humans have the ability of inferring 3 D models from 2 D drawings. However, associating a sketch to a 3 D model is not a computationally trivial task. In this paper we present a conceptualization of the area, highlighting opportunities, challenges and trends in SBIM...|$|E
40|$|VR {{systems are}} {{nowadays}} established in many areas. However, even in environments where VR is widely accepted, users spend the bigger {{part of their}} time working at classic desktops with WIMP (windows, icons, <b>menus,</b> <b>pointers)</b> interfaces. When switching to a VR-Setup the user usually also switches to a different application and thus needs time to familiarize with the software. For this reason we introduce a concept of HCI {{that is based on}} 3 D widgets (hybrid objects) that are designed {{in such a way that}} with no or only slight modification 2 D interaction is also possible. Thus, the same application can be used in 2 D as well as in 3 D. Furthermore, we introduce the Hybrid Desktop, a 2 D/ 3 D desktop VR configuration that is optimal for the hybrid objects concept. Finally, we describe a user test to show that skills learned on a application running on a desktop computer can be transferred to the same application running on VR hardware due to the consistent user interface...|$|R
50|$|Another notable feature was the {{combined}} use {{of both a}} command-line interface and graphical user interface. AmigaDOS was the disk operating system and command line portion of the OS and Workbench the native graphical windowing, icons, <b>menu</b> and <b>pointer</b> environment for file management and launching applications. Notably, AmigaDOS allowed long filenames (up to 107 characters) with whitespace and did not require filename extensions. The windowing system and user interface engine which handles all input events is called Intuition.|$|R
40|$|Research Interests The goal of my {{research}} is to improve everyday graphical user interfaces, multimodal interfaces, and other human-computer interaction techniques that encourage people to use computers as well as improving efficiency in performing individual operations. My current research interests focus on common WIMP (windows, icons, <b>menus,</b> and <b>pointers)</b> widgets. I believe that traditional WIMP interfaces can be improved by exploiting extra spatial information, e. g., mouse position and movement, which have been paid little attention so far...|$|R
40|$|Abstract. Here {{we present}} a {{companion}} study to work previously detailed in “ 3 D Modelling is not for WIMPs ” (Scali, S., Wright, M., Shillito, A. M., 2003). In that study we showed {{that the use of}} a 3 D haptic environment in combination with stereovision provided a marked improvement in the ability to complete a 3 D task when compared to traditional WIMP (Window, Icon, <b>Menu,</b> <b>Pointer)</b> interfaces. Using the same haptic equipment we examined how the new environment affected the number of stylus/mouse clicks performed during a 3 D object alignment task. The results showed that when using haptics there was a highly significant {{decrease in the number of}} clicks required to perform the alignment task when compared to a WIMP interface. In conjunction with our previous work this shows that using a haptic system drastically increases the overall system usability, and decreases the users perceived task load. ...|$|E
40|$|Part 1 : Long and Short Papers (Continued) International audienceEmploying post-WIMP {{interfaces}}, i. e. {{user interfaces}} {{going beyond the}} traditional WIMP (Windows, Icons, <b>Menu,</b> <b>Pointer)</b> paradigm, often implies a more complex authoring process for applications. We present a novel authoring method and a corresponding tool that aims to enable developers {{to cope with the}} added level of complexity. Regarding the development as a process conducted on different layers, we introduce a specific layer for post-WIMP in addition to layers addressing implementation or traditional GUI elements. We discuss the concept of cross layer authoring that supports different author groups in the collaborative creation of post-WIMP applications permitting them working independently on their respective layer and contributing their specific skills. The concept comprises interactive visualization techniques that highlight connections between code, GUI and post-WIMP functionality. It allows for graphical inspection while transitioning smoothly between layers. A cross layer authoring tool has been implemented and was well received by UI developers during evaluation...|$|E
40|$|Abstract. Employing post-WIMP {{interfaces}}, i. e. {{user interfaces}} {{going beyond the}} traditional WIMP (Windows, Icons, <b>Menu,</b> <b>Pointer)</b> paradigm, often implies a more complex authoring process for applications. We present a novel authoring method and a corresponding tool that aims to enable developers {{to cope with the}} added level of complexity. Regarding the development as a process conducted on different layers, we introduce a specific layer for post-WIMP in addition to layers addressing implementation or traditional GUI elements. We discuss the concept of cross layer authoring that supports different author groups in the collaborative creation of post-WIMP applications permitting them working independently on their respective layer and contributing their specific skills. The concept comprises interactive visualization techniques that highlight connections between code, GUI and post-WIMP functionality. It allows for graphical inspection while transitioning smoothly between layers. A cross layer authoring tool has been implemented and was well received by UI developers during evaluation...|$|E
40|$|In {{the last}} few years, the {{consumer}} device landscape has been significantly transformed by the rapid proliferation of smartphones and tablets, whose sales are fast overtaking that of traditional PCs. The highly user-friendly multitouch interfaces combined with ever more efficient electronics {{have made it possible}} to perform an increasingly wide range of activities on those mobile devices. One category of tasks, for which the desktop PC with mouse and keyboard remains the platform of choice, however, is office work. In particular, productivity document engineering tasks are still more likely to be carried out on a regular computer and with software, whose interfaces are based on the time-honoured "windows, icons, <b>menus,</b> <b>pointer</b> " (WIMP) paradigm. With the recent emergence of larger touch-based devices such as wall screens and digital tabletops (which overcome the limitations of mobile devices in terms of available screen real estate) as well as the resurgence of the stylus as an additional input instrument, the vocabulary of interactions at the disposal of interface designers has vastly broadened. Hybrid pen and touch input is a very new and promising interaction model that practitioners have begun to tap, but it has yet to be applied in office applications and document-centri...|$|R
50|$|Although {{the term}} has fallen into disuse, some {{use it as}} an {{approximate}} synonym for graphical user interface (GUI). Any interface that uses graphics can be called a GUI, and WIMP systems derive from such systems. However, while all WIMP systems use graphics as a key element (the icon and pointer elements), and therefore are GUIs, the reverse is not true. Some GUIs are not based in windows, icons, <b>menus,</b> and <b>pointers.</b> For example, most mobile phones represent actions as icons, and some might have menus, but very few include a pointer or run programs in a window.|$|R
40|$|In 2007 Microsoft {{changed the}} {{graphical}} user interface of MS Office, and {{moved away from the}} long -established drop down menu approach to a ribbon {{graphical user interface}}. There have been mixed reactions to Microsoft's ribbon interface. Ericson (2006) mentioned that even the experienced user might have difficulty adopting the interface, and Dostal (2010) concluded that the biggest issue with the Ribbon User Interface is to get accustomed to a redesigned user interface. Reaction to this change was negative among our new and current students. For years the students had tried to memorise how to apply the right commands in Microsoft Office applications by selecting the correct items from the dropdown menus of the WIMP (windows, icons, <b>menus,</b> <b>pointer)</b> interface, and now that they were confronted with the new interface their confusion had begun to slow their progress down. The major effect in transition from the traditional WIMP interface to the Ribbon interface had created a difficulty for most students who had their original training with the older versions of MS Office software, as they were not able to locate the commands that they had learnt with the earlier versions of the MS Office in the new Ribbon interfaced version. The shrinking nature of the ribbon that would hide some commands on the ribbon when the resolution of the screen changes was also confusing for those students as they could not quickly locate the command they were looking for because the Ribbon had compacted them to save space. For both new students and also more experienced ones, the approach to learning the Ribbon Interface seemed to be difficult {{due to the fact that}} they had to memorise the hierarchy of tab names, group names and then the commands. This led us to enhance our current teaching methods to try to deal with this change...|$|R
40|$|This thesis {{examines}} and invesTgates the subsTtuTon of {{the mouse}} for a more natural means of human computer interacTon, ranging from manipulaTng WIMP‐based applicaTons to developing post‐WIMP interfaces and exploring their usefulness. The WIMP (Window, Icon, <b>Menu,</b> <b>Pointer)</b> interface has been the standard paradigm for the personal compuTng era. Their use is opTmized for the keyboard and mouse input device pair, tools that have remained fundamentally stagnant with regard to innovaTon for decades[1]. Accomplished through the construcTon of a touchscreen with variable levels of contact detecTon, targeted demo applicaTons not only show the effecTveness of such an input apparatus but introduce the potenTal for previously unexplored levels of interacTon. The use of direct‐contact manipulaTon provides a more natural interacTon than is achieved by the mouse, avoiding the need to abstract crucial concepts such as 'selecTng', 'dragging', or 'resizing'. The introducTon of vision driven touch‐sensiTvity allows {{for the use of}} physical objects to denote disTnct meanings, providing a means to create associaTons between physical and digital acTons. Building upon this concept...|$|E
40|$|A large set of pathologies {{can make}} it {{impossible}} for several users to use an OS (Operating System) or a software. In fact, most User Interface (UI) are developed around WIMP (Windows Icon <b>Menu</b> <b>Pointer)</b> interfaces while Post-WIMP interfaces are not yet widely used. While consoles designers have started to include this paradigm in their products and have a long history on ergonomic studies, most of these approaches are not exploited to give the opportunity to disabled people to use a computer or a game console. In this paper, we present the first step towards a multimodal interaction approach for designing therapeutic games. This approach is conceived to work in conjunction with a game for all design. This means that not only the game has to be usable by regular user and disabled people but also that the conceived game has to be fun for both targets. In this paper we present a first set of interview we conducted with four therapists. These interviews allowed us to present a first solution to use several devices {{in order to deal with}} different pathologies (i. e. a multimodal approach) that we applied to a cross platform game...|$|E
40|$|Most of today's Graphical User Interfaces (GUI) and toolkits {{are based}} on serial, discrete, token based, {{paradigms}} that seem to acceptably implement traditional WIMP (Window, Icon, <b>Menu,</b> <b>Pointer)</b> interfaces. These tools however, are not suited for "next generation" interaction techniques such as Virtual Reality (VR). These interaction techniques rely upon asynchronous, parallel, and continuous user/computer interaction. This work proposes a specification paradigm, DLoVe, which provides a framework of techniques and abstractions that directly addresses these issues. In addition, DLoVe also provides a mechanism for executing programs designed for a single machine to be executed in a distributed environment, where updates on DLoVe variables are processed in parallel. DLoVe's framework also provides the abstractions for writing multi-user VR programs or transforming existing single-user programs into multi-user ones. Moreover, DLoVe addresses issues of performance and maintainability, providing mechanisms, drivers, and utilities that allow run time tuning and network management to be specified in a simple manner. This thesis describes in detail the proposed system, evaluates it, and provides examples and analysis of several applications developed within DLoVe's paradigm, and provides a guide on how applications can be implemented in this framework...|$|E
40|$|This web-based {{exhibition}} was curated by the Crafts Council as the launch {{project for the}} organisation’s ‘On-View’ feature platform where it remains permanently featured., This exhibition comprehensively documents a research-through-practice investigation which has established several entirely new ‘work-flow’ processes for designing with digitally-recorded three-dimensional drawings used as the input for creating physical artefacts. The concept employs a digitising arm to record spatial sketches developed into artefacts by combinations of digital fabrication technologies and hand skills., The research extends {{the knowledge of the}} practical and artistic application of post-WIMP (windows, icons, <b>menus,</b> <b>pointer)</b> interface systems within design practices, particularly in the applied arts sector. It also explores ways in which gestural expression can be captured digitally and translated into physical artefacts by new tools of digital fabrication., The new design processes developed during this investigation have been tested extensively through the creation of a series of glass and ceramic bowls. The research was structured with a clear aim and a set of objectives, however other elements of the research were also guided by discoveries during creative explorations organised as cycles of reflective practice. The whole investigation has been rigorously documented and widely disseminated., A portfolio of evidence includes a conference paper delivered at Physicality 2009 (HCI 2009, Churchill College Cambridge) and conference presentations: ‘Icograda’ (World Design Congress, Beijing), the Estonian Triennial of Applied Arts and ‘The Big Smoke’ (Auckland, New Zealand)., Pieces created during this investigation have been exhibited at numerous national and international venues: The Wills Lane Gallery (St. Ives), Galerie Handwerk (Munich, Germany), ‘Know How’ (Tallinn, Estonian), ‘DRAW,’ (Royal College of Art, London) and ‘Lab Craft,’ (London Design Festival, then touring 9 UK venues with 50 k+ cumulative visitors) ...|$|R
40|$|We {{propose a}} novel Human Computer Interaction (HCI) {{paradigm}} for volume visualization in projection-based immersive virtual environments (VEs). This paradigm is intuitive, highly efficient and allows accurate {{control over the}} virtual objects. A fine control mode for direct manipulation is proposed to address the low accuracy problem of virtual object manipulation in VEs. An agent object interaction method is proposed to provide more flexibility in manipulating the volume objects. A two-handed scaling method is proposed to conveniently scale the volume object along one, two, or three axes. Finally, a ghost object paradigm is proposed to address the motion constraint problem for virtual objects. An implementation using a 3 -state tracked glove setup as the input interface is discussed. How basic functionality for volume visualization can be transferred from the 2 D WIMP (Window, Icon, <b>Menu,</b> and <b>Pointer)</b> interface to a 3 D VR interface is also systematically discussed...|$|R
40|$|We {{present the}} design and {{evaluation}} of Graphically Enhanced Keyboard Accelerators (GEKA), a user interface interaction method allowing commands within a graphical application to be quickly and easily invoked through the keyboard. The high-level goal of this work is to make interactive desktop computing more pleasant and productive for experienced computer users. GEKA {{is designed to provide}} complete coverage of the command set, to require low visual demand, and to support ease of learning and remembering, a low error rate, and high speed. This thesis describes GEKA's design and two related user studies. A formative study with 10 participants explored how our target users currently work with Window, Icon, <b>Menu</b> and <b>Pointer</b> (WIMP) interfaces. The results of the study suggest that advanced computer users prefer to execute commands with the keyboard. However, they are often unable to do so in current applications because shortcuts are not available for all commands or are unknown. This indicates a desire among advanced users for a GEKA-lik...|$|R
40|$|An {{existing}} {{application software}} perhaps has no requirements document or requirements document {{does not represent}} the application. The situation creates a problem in application software maintenance or reengineering. Thus, requirements document should be reconstructed from the existing application software. Effort on reconstructing a requirements document from the existing application software is similar to requirements document construction for a new application software, needs requirements elicitation. Requirements elicitation can be done using an ontology model that captures end-to-end interaction between users and system. Using the ontology model does not need software documentation and source code at all, the only one is the existing application software itself. In this case, the existing application software should be executed and then observed its behavior in term of end-to-end interaction on each starting point in which the interface identified. This set of interaction flows {{is known as a}} Use Case Realization (UCR) in Requirements Management with Use Case (RMUC) approach. The appropriate ontology model provides an ease to understand the software requirements semantic meaning. The model consists of two models includes, WIMP-UI (Window Icon <b>Menu</b> <b>Pointer</b> – User Interface) and USI (User- Interaction) ontology models...|$|E
40|$|Traditional user {{interfaces}} in modeling {{have followed the}} WIMP (Window, Icon, <b>Menu,</b> <b>Pointer)</b> paradigm. While functional and powerful, {{they can also be}} cumbersome and daunting to a novice user; creating a complex model requires much expertise and effort. A recent trend is toward more accessible and natural interfaces, which has lead to sketch-based interfaces for modeling (SBIM). The goal is to allow hand-drawn sketches {{to be used in the}} modeling process, from rough model creation through to fine detail construction. Mapping 2 D sketches to a 3 D modeling operation is a difficult and ambiguous task, so our categorization is based on how an SBIM application chooses to interpret a sketch, of which there are three primary methods: to create a 3 D model, to add details to an existing model, or to deform and manipulate a model. In this STAR, we present a taxonomy of sketchbased interfaces focused on geometric modeling applications. The canonical and recent works are presented and classified, including techniques for sketch acquisition, filtering, and interpretation. The report also includes a discussion of important challenges and open problems for researchers to tackle in the coming years. 1...|$|E
40|$|User {{interfaces}} {{have traditionally}} followed the WIMP (window, icon, <b>menu,</b> <b>pointer)</b> paradigm. Though functional and powerful, {{they are usually}} cumbersome for a novice user to design a complex model, requiring considerable expertise and effort. This paper presents a system for designing geometric models and image deformation with sketching curves, {{with the use of}} Green coordinates. In 3 D modeling, the user first creates a 3 D model by using a sketching interface, where a given 2 D curve is interpreted as the projection of the 3 D curve. The user can add, remove, and deform these control curves easily, as if working with a 2 D line drawing. For a given set of curves, the system automatically identifies the topology and face embedding by applying graph rotation system. Green coordinates are then used to deform the generated models with detail-preserving property. Also, we have developed a sketch-based image-editing interface to deform image regions using Green coordinates. Hardware-assisted schemes are provided for both control shape deformation and the subsequent surface optimization, the experimental results demonstrate that 3 D/ 2 D deformations can be achieved in realtime. © 2011 Springer Science+Business Media, LLC...|$|E
40|$|We have {{implemented}} an infinite resolution multimedia sketchpad {{as a base}} for exploring a stream-of-consciousness model of computation where information creating, sharing and retrieval becomes so intuitive that the interface becomes invisible. Motivation to pursue this came from work on Pad [4], which {{can be thought of as}} a kind of traditional sketchpad or windows environment in the sense that it is a general-purpose substrate for visualizing two dimensional graphics and text. But Pad also supports the radical notion of being infinite in extent and resolution. We implemented Pad to explore smooth zooming for navigation and to serve as a platform for multimedia authoring and information visualization. The ability to work with very large datasets has been a primary design consideration in the development of Pad. INTRODUCTION The motivation for our work on multiscale interfaces is to move beyond windows, icons, <b>menus,</b> and <b>pointers</b> to explore interfaces that more effectively support [...] ...|$|R
40|$|With the {{availability}} of affordable large-scale monitors and powerful projector hardware, an increasing variety of display configurations {{can be found in}} our everyday environments, such as office spaces and meeting rooms. These emerging display environments combine conventional monitors and projected displays of different size, resolution, and orientation into a common interaction space. However, the commonly used WIMP (windows, icons, <b>menus,</b> and <b>pointers)</b> user interface metaphor is still based on a single pointer operating multiple overlapping windows on a single, rectangular screen. This simple concept cannot easily capture the complexity of heterogeneous display settings. As a result, the user cannot facilitate the full potential of emerging display environments using these interfaces. The focus of this thesis is to push the boundaries of conventional WIMP interfaces to enhance information management in emerging display environments. Existing and functional interfaces are extended to incorporate knowledge from two layers: the physical environment and the content of the individual windows. The thesis first addresses the technical infrastructure to construct spatially aware multi-display environments and irregular displays. Based on this infrastructure, novel WIMP interaction and information presentatio...|$|R
40|$|We {{present a}} menu {{interface}} designed primarily for headworn displays {{that have a}} small field-of-view. To support interaction with a hierarchical menu, we logically divide an absolute positioning device into finger-operated strip segments, which we use as one-dimensional scrolling devices. Our menu system is intended to make user interaction faster by not requiring constant visual feedback. This is preferable for interaction in which the visual user interface elements occupy {{only a small portion}} of the eye's entire field-of-view and in which navigating in <b>menus</b> with a <b>pointer</b> would be awkward and time-consuming. With our approach, it is even possible for the user to use peripheral vision for interaction, since there is no need to precisely position a small pointer on the screen. Thus, the user can maintain eye contact with others or keep his or her focus of attention on the environment while using a wearable device...|$|R
