8|49|Public
50|$|In 2011, Traditional Series models' were {{improved}} {{by means of}} a new DTAR pickup system, which allows blending between an internal <b>microphone</b> <b>element</b> and an under-saddle transducer. Previous DTAR configurations only included an under-saddle transducer. Also, hard shell case material has been upgraded to a high-end, faux alligator skin material with crushed velvet interior padding.|$|E
5000|$|The most {{commonly}} available contact <b>microphone</b> <b>element</b> {{is made of}} a thin piezoelectric ceramic round glued to a thin brass or alloy metal disc. This center disc is positively charged while the brass disc is negatively charged. If the silver disc is cracked or scorched, the piezo will no longer function at full sensitivity.|$|E
5000|$|Although S.G. Brown's Type G Telephone Relay (using a {{magnetic}} [...] "earphone" [...] mechanism driving a carbon <b>microphone</b> <b>element)</b> {{was able to}} give power amplification and had been in use as early as 1914, it was a purely mechanical device with limited frequency range and fidelity. It was suited only to a limited range of audio frequencies - essentially voice frequencies.|$|E
40|$|It {{has been}} shown {{recently}} that, using two (or more) microphones and a forward-difference approximation, it is possible estimate the pressure at a remote observer location {{rather than at the}} actual microphone locations. These “virtual-microphones ” have been successfully used in active noise control systems to minimise the pressure at a location remote from the microphones. However, the virtual microphones have not been without their problems. Determining the open loop weights for the <b>microphone</b> <b>elements</b> is not always a trivial task. In practice the implementation of virtual microphone arrays has additional difficulties. The virtual sensors have shown that they are sensitive to phase and magnitude mismatches between <b>microphone</b> <b>elements,</b> so it is essential that well matched elements are used. This paper explores the use of the LMS algorithm to derive the optimal weights for the <b>microphone</b> <b>elements.</b> It will be seen that this optimal approach improves the quality of the pressure estimate at the desired remote location compared to the traditional open loop approach. It completely compensates for amplitude mismatches and spatial errors, and the method even addresses phases mismatches to some extent...|$|R
50|$|In 1982 Heil Sound {{introduced}} their HC Series elements, {{specifically the}} HC-4 and HC-5, which allowed the non-DSP transmitters {{of the time}} to produce different sounding audio by changing <b>microphone</b> <b>elements.</b> The most recent is the HC-6, which is used in many of their current microphone models.|$|R
40|$|Copyright © 2005 Acoustical Society of AmericaThis paper {{builds on}} earlier {{work by the}} same authors to derive {{expressions}} for the time-averaged acoustic energy density in the frequency domain using the auto- and cross-spectral densities of multiple <b>microphone</b> <b>elements.</b> Expressions for the most common three-dimensional geometric arrangements are derived. Simplified expressions for use with two channel spectrum analysers are also presented. Ben S. Cazzolato and Justin Gha...|$|R
50|$|Phantom {{power is}} {{sometimes}} used by workers in avionics {{to describe the}} DC bias voltage used to power aviation microphones, which use a lower voltage than professional audio microphones. Phantom power used {{in this context is}} 8 to 16 volts DC in series with a 470 ohm (nominal) resistor as specified in RTCA Inc. standard DO-214. These microphones evolved from the carbon microphones used {{in the early days of}} aviation and the telephone which relied on a DC bias voltage across the carbon <b>microphone</b> <b>element.</b>|$|E
50|$|A pop filter or pop shield is a noise {{protection}} filter for microphones, typically {{used in a}} recording studio. It serves to reduce or eliminate 'popping' sounds caused by the mechanical impact of fast moving air on the microphone during recorded speech and singing. It also keeps moisture off the microphone which can cause mold growth. Additionally, a pop filter can protect against the accumulation of saliva on the <b>microphone</b> <b>element.</b> Salts in human saliva are corrosive and thus use of a pop filter may improve {{the life of the}} microphone.|$|E
40|$|A special {{array system}} has been {{designed}} to examine noise source distributions over a helicopter rotor model. The particular measurement environment is for a rotor operating in the open jet of an anechoic wind tunnel. An out-of-flow directional <b>microphone</b> <b>element</b> array is used with a directivity pattern whose major directional lobe projects on the rotor disk. If significant contributions from extraneous tunnel noise sources {{in the direction of the}} side lobes are excluded, the dominant output from the array would be that noise emitted from the projected area on the rotor disk. The design incorporates an array element signal blending features which serves to control the spatial resolution of the size of the directional lobes. (Without blending, the resolution and side lobe size are very strong functions of frequency, which severely limits the array's usefulness) ...|$|E
50|$|Electret {{materials}} {{have been known}} since the 1920s and were proposed as condenser <b>microphone</b> <b>elements</b> several times, but they were considered impractical until the foil electret type was invented at Bell Laboratories in 1961 by James West and Gerhard Sessler, using a thin metallized Teflon foil.This became the most common type, used in many applications from high-quality recording and lavalier use to built-in microphones in small sound recording devices and telephones.|$|R
5|$|In the game, Neku Sakuraba and {{his allies}} are forced to {{participate}} in a game that will determine their fate. The battle system uses many of the unique features of the Nintendo DS, including combat that takes place on both screens, and attacks performed by certain motions on the touchscreen or by shouting into the <b>microphone.</b> <b>Elements</b> of Japanese youth culture, such as fashion, food, and cell phones, are key aspects of the missions.|$|R
50|$|Electret <b>microphone</b> <b>elements</b> {{typically}} {{include a}} junction field-effect transistor as an impedance converter to drive other electronics {{within a few}} meters of the microphone. The operating current of this JFET is typically 0.1 to 0.5 mA and {{is often referred to}} as bias, which is different from the phantom power interface which supplies 48 volts to operate the backplate of a traditional condenser microphone. Electret microphone bias is sometimes supplied on a separate conductor.|$|R
40|$|Automatic speech {{recognition}} {{has become a}} standard feature on many consumer electronics and automotive products, and {{the accuracy of the}} decoded speech has improved dramatically over time. Often, designers of these products achieve accuracy by employing microphone arrays and beamforming algorithms to reduce interference. However, beamforming microphone arrays are too large for small form factor products such as smart watches. Yet these small form factor products, which have precious little space for tactile user input (i. e. knobs, buttons and touch screens), would benefit immensely from a user interface based on reliably accurate automatic {{speech recognition}}. This thesis proposes a solution for interference mitigation that employs blind source separation with a compact array of commercially available unidirectional microphone elements. Such an array provides adequate spatial diversity to enable blind source separation and would easily fit in a smart watch or similar small form factor product. The solution is characterized using publicly available speech audio clips recorded for the purpose of testing automatic speech recognition algorithms. The proposal is modelled in different interference environments and the efficacy of the solution is evaluated. Factors affecting the performance of the solution are identified and their influence quantified. An expectation is presented for the quality of separation as well as the resulting improvement in word error rate that can be achieved from decoding the separated speech estimate versus the mixture obtained from a single unidirectional <b>microphone</b> <b>element.</b> Finally, directions for future work are proposed, which have the potential to improve the performance of the solution thereby making it a commercially viable product...|$|E
40|$|This {{dissertation}} {{studies the}} audio localization {{component of a}} touchless interactive display located in the CSE building at UC San Diego. The display has been named The Automatic Cameraman (TAC) and consists of four large television displays, a PTZ camera, and a microphone array. In this work, we propose a simple {{solution to the problem}} of accurately pointing the PTZ camera at speaking humans who are interacting with TAC. The focus of this dissertation will be on a novel audio localization and tracking algorithm based on what we call the coordinate- free approach. Previous approaches to localization assume a precise known geometry for the microphone array. This is expressed through a coordinate system for the room with an exact position for each <b>microphone</b> <b>element.</b> As a result, arrays are typically built so that microphone positions can be known easily e. g. as linear or planar with fixed spacing. The coordinate-free method we propose requires no such knowledge of such a coordinate system allowing for an ad-hoc placement of microphones. Our coordinate-free localization algorithm employs a statistical approach by learning a mapping from observed time-delays between microphone pairs directly to a pan and tilt directive for the PTZ-camera. In addition, we explicitly utilize the fact that the training set of time-delay vectors lie on a low-dimensional structure, namely a three-dimensional structure governed by the sound source's true spatial location. We explore various regressor models with special attention to those that are known to exploit this intrinsic low dimensionality. We follow this with a study of a particle filtering based tracker of the time-delays between microphones. Our tracker employs a novel approach to the particle filtering problem based on online learning. It introduces a new, practically useful, particle resampling scheme. It is also more robust to model misspecification than traditional particle filters. In the final part of the dissertation, we examine a MEMS digital microphone based array that we recently implemented on an FPGA. We explore how this digital array will alleviate many of the technical deficiencies of the current analog array in TA...|$|E
50|$|In the game, Neku Sakuraba and {{his allies}} are forced to {{participate}} in a game that will determine their fate. The battle system uses many of the unique features of the Nintendo DS, including combat that takes place on both screens, and attacks performed by certain motions on the touchscreen or by shouting into the <b>microphone.</b> <b>Elements</b> of Japanese youth culture, such as fashion, food, and cell phones, are key aspects of the missions.|$|R
25|$|An {{electret}} microphone {{is a type}} of condenser microphone, which eliminates the need for a power supply by using a permanently charged material. Electret materials have been known since the 1920s, and were proposed as condenser <b>microphone</b> <b>elements</b> several times, but were considered impractical until the foil electret type was invented at Bell Laboratories in 1962 by Jim West, using a thin metallized Teflon foil. This became the most common type, used in many applications from high-quality recording and lavalier use to built-in microphones in small sound recording devices and telephones.|$|R
30|$|Let us {{assume that}} the reverberant signal impinges on a {{unidirectional}} microphone array, rather than a single omnidirectional microphone. Such an array can be composed of several directional <b>microphone</b> <b>elements</b> or alternately by applying beamforming techniques with a few closely spaced omnidirectional microphones [19, 20]. The overall source-to-microphone response {{can be described as}} a convolution of the RIR (2) with the response of the corresponding directional microphone. The acoustic response of a directional microphone (or beamformer) is time-invariant and is defined only by the frequency and angle of the arriving signal.|$|R
5000|$|Phantom power {{supplies}} are often built into mixing consoles, microphone preamplifiers and similar equipment. In addition to powering the circuitry of a microphone, traditional condenser microphones also use phantom power for polarizing the <b>microphone's</b> transducer <b>element.</b>|$|R
50|$|Although, until recently, less precise {{than the}} more {{traditional}} mechanomyography, it is considerably easier to set up. The signal is measured using condenser <b>microphone</b> <b>elements,</b> piezoelectric sensors, accelerometers, {{or a combination of}} sensors attached to the skin. Hydrophones have also been used to measure muscles immersed in water. Improvements in microphones and contact transducers (piezoelectric devices), as well as recording systems, has meant that they have become available in a size and of a quality that enables them to be applied to a normal daily setting outside the clinic and the laboratory setting. These new possibilities provide a clinical tool for the assessment of patients with musculoskeletal complaints during daily activities, or assessment of athletes in terms of efficiency in use of muscles.|$|R
40|$|An integrated, modular {{real-time}} {{microphone array}} {{system has been}} implemented to detect, track and extract speech from {{a person in a}} realistic office environment. Multimodal integration, whereby audio and visual information are used together to detect and track the speaker, is examined to determine comparative advantages over unimodal processing. An extensive quantitative comparison is also performed on a number of system variables (linear/compound arrays, interpolation, audio/visual tracking, etc) to determine the system configuration that represents the best compromise between performance, robustness, and complexity. Given a fixed number of <b>microphone</b> <b>elements</b> the compound array, with a broader frequency response but a coarser spatial resolution, has been determined to have a slight performance advantage in the currently implemented system over the linear array...|$|R
40|$|EUROSPEECH 1997 : the 5 th European Conference on Speech Communication and Technology, September 22 - 25, 1997, Rhodes, Greece. One {{of the key}} {{technologies}} for natural man-machine interface is hands-free speech recognition. The performance of hands-free distant- talking speech recognition will be seriously degraded by noise and reverberation in real environments. A microphone array is applied to solve the problem. When applying a microphone array to speech recognition, parameters such as number of <b>microphone</b> <b>elements</b> and their spacing interval affect the performance. In order to optimize these parameters, a measure which reflects recognition performance is needed. In this paper, we investigate a measure of a microphone array design for speech recognition through experiments using various kinds of a microphone array design...|$|R
5000|$|The primary {{difficulty}} {{inherent in}} {{this approach is that}} high-frequency localisation and clarity relies on the diaphragms approaching true coincidence. By stacking the capsules vertically, perfect coincidence for horizontal sources is obtained. However, sound from above or below will theoretically suffer from subtle comb filtering effects in the highest frequencies. In most instances this is not a limitation as sound sources far from the horizontal plane are typically from room reverberation. In addition, stacked figure-8 <b>microphone</b> <b>elements</b> have a deep null in the direction of their stacking axis such that the primary transducer in those directions is the central omnidirectional microphone. In practice this can produce less localisation error than either of the alternatives (tetrahedral arrays with processing, or a fourth microphone for the Z axis.) ...|$|R
40|$|ICASSP 2006 : IEEE International Conference on Acoustics, Speech, and Signal Processing, May 14 - 19, 2006, Toulouse, France. In {{this paper}} we {{introduce}} a new double-talk free spoken dialogue interface combining sound field control and a source separation technique based on independent component analysis (ICA). First, sound field control provides silent zones on the <b>microphone</b> <b>elements</b> and prevents the response sound from being observed. In the second step, we propose a novel semi-blind source separation algorithm to suppress the error caused by fluctuation of the room transfer function. By using a direct input of response sound signal to ICA, a source separation problem {{can be converted to}} a supervised learning problem. Since the problem becomes easier, the proposed method showed higher performances than the method using blind source separatio...|$|R
25|$|In 2007, <b>microphones</b> {{employing}} ribbon <b>elements</b> made {{of strong}} nanomaterials became available, offering {{orders of magnitude}} improvement in signal purity and output level.|$|R
30|$|The least-square (LS) {{technique}} is used [6] {{to estimate the}} beamformer filters that will achieve the desired beam pattern according to a desired direction response. To accomplish this beamformers estimation, we need to calculate the steering vectors which represent the phase delays of a plane wave evaluated at the <b>microphone</b> array <b>elements.</b>|$|R
40|$|The {{concept of}} {{augmented}} reality audio characterizes techniques where a real sound environment is extended with virtual auditory environments and communications scenarios. A framework is introduced for mobile augmented reality audio (MARA) {{based on a}} specific headset configuration where binaural <b>microphone</b> <b>elements</b> are integrated into stereo earphones. When microphone signals are routed directly to the earphones, a user is exposed to a pseudoacoustic representation of the real environment. Virtual sound events are then mixed with microphone signals to produce a hybrid, an augmented reality audio representation, for the user. An overview of related technology, literature, and application scenarios is provided. Listening test results with a prototype system show that the proposed system has interesting properties. For example, in some cases listeners found {{it very difficult to}} determine which sound sources in an augmented reality audio representation are real and which are virtual...|$|R
40|$|In {{beamformer}} design, {{the microphone}} locations are often fixed {{and only the}} filter coefficients are varied {{in order to improve}} on the noise reduction performance. However, the positions of the <b>microphone</b> <b>elements</b> {{play an important role in}} the overall performance and should be optimized at the same time. However, this nonlinear optimization problem is non-convex and local search techniques might not yield the best result. This problem is addressed in this paper. A hybrid descent method is proposed which consists of a genetic algorithm together with a gradient-based method. The gradient-based method can help to locate the optimal solution rapidly around the start point, while the genetic algorithm is used to jump out from local minima. This hybrid method has the descent property and can help us to find the optimal placement for better beamformer design. Numerical examples are provided to demonstrate the effectiveness of the method. Department of Applied Mathematic...|$|R
40|$|In {{beamformer}} design, {{the microphone}} array configuration is often prescribed and the filter coefficients are varied {{in order to}} improve on the noise reduction performance. However, the positions of the <b>microphone</b> <b>elements</b> {{play an important role in}} the overall performance and should be optimized at the same time. This problem is addressed in this paper. In order to understand the performance improvement through location movements, we first look at the design with an infinite filter length, which gives the performance limit for finite filter length designs. When the filter length is finite, both the filter coefficients and the placement of the microphone array are decision variables. In both situations, the problems can be formulated as constrained optimization problems. As the filter length increases, we show that the performance converges quickly to the limit. For illustration, two numerical examples are solved. Comparing with several popular configurations, we show that the performance of the optimized configuration improves significantly. © 2011 IEEE. link_to_subscribed_fulltex...|$|R
5000|$|Most {{external}} microphone {{designs are}} of either omnidirectional or noise-canceling type. Noise-canceling microphone headsets use a bi-directional <b>microphone</b> as <b>elements.</b> A bi-directional <b>microphone's</b> receptive field has two angles only. Its receptive field {{is limited to}} only the front and the direct opposite back of the microphone. This create an [...] "8" [...] shape field, and this design is the best method for picking up sound only from a close proximity of the user, while not picking up most surrounding noeous noise.|$|R
50|$|Around 2002, {{relatively}} inexpensive ($80 - $200) Chinese-manufactured ribbon microphones {{inspired by the}} RCA-44 and older Russian Oktava ribbon microphones became available. In 2007, <b>microphones</b> employing ribbon <b>elements</b> made of strong nanomaterials became available, offering orders of magnitude improvement in signal purity and output level.|$|R
25|$|The {{traditional}} {{telephone network}} (PSTN) is generally limited to narrowband audio by the intrinsic {{nature of its}} transmission technology, TDM (time-division multiplexing), and by the analogue-to-digital converters used {{at the edge of}} the network, as well as the speakers, <b>microphones</b> and other <b>elements</b> in the endpoints themselves.|$|R
5000|$|The {{orchestra}} eschews digital sampling (music), instead favoring analog Electroacoustic {{music and}} Acousmatic sound techniques {{and the use}} of contact <b>microphones,</b> when creating <b>elements</b> of its music. Its eclectic sound has not gone unnoticed, RPM Orchestra currently holds distinction as the [...] "Oddest Band in Phoenix".|$|R
5000|$|Typically, {{an array}} {{is made up}} of {{omnidirectional}} microphones, directional microphones, or a mix of omnidirectional and directional microphones distributed about the perimeter of a space, linked to a computer that records and interprets the results into a coherent form. Arrays may also be formed using numbers of very closely spaced microphones. Given a fixed physical relationship in space between the different individual <b>microphone</b> transducer array <b>elements,</b> simultaneous DSP (digital signal processor) processing of the signals from each of the individual <b>microphone</b> array <b>elements</b> can create one or more [...] "virtual" [...] microphones. Different algorithms permit the creation of virtual microphones with extremely complex virtual polar patterns and even the possibility to steer the individual lobes of the virtual microphones patterns so as to home-in-on, or to reject, particular sources of sound. The application of these algorithms can produce varying levels of accuracy when calculating source level and location, and as such, care should be taken when deciding how the individual lobes of the virtual microphones are derived.|$|R
40|$|Acoustic sensor {{networks}} (ASN) {{are widely}} used to monitor water leaks in the power generating systems. Since the ASN are used in harsh climatic conditions the failures of <b>microphone</b> <b>elements</b> of ASN are inevitable. That's why the failure detection of ASN elements {{is a problem of}} current interest. Two techniques of operational monitoring ASN are developed. Both of them are based on the placement of the test sound source within a network. The signal processing for ASN sensors had to detect the failed element. Techniques are based time difference of arrival (TDOA) estimating at the each pair of ASN elements. TDOA estimates as argmaximum of cross-correlation function (CCF) for signals on each microphone sensors pair. The M-sequence phase-shift keyed signal is applied as a test acoustic signal to ensure high accuracy of the CCF maximum estimation at low signal/noise ratio (SNR). The first technique is based on the isolation principle for TDOA sum at three points. It require to locate the test sound source in the far field. This is not always possible due to technological reasons. For the second proposed technique test sound source can be located near the ASN. It is based on a system of hyperbolic equations solving {{for each of the four}} elements of the ASN. Both techniques has been tested in the computer imitation experiment. It was found that for the SNR to – 5 dB both techniques show unmistakable indicators of control quality. The second method requires significantly more time control...|$|R
40|$|A {{fiber optic}} microphone, {{based on the}} {{principle}} of the fiber optic lever, features small size, extended bandwidth, and capability to operate at high temperatures. These are requirements for measurements in hypersonic flow. This paper describes the principles of operation of fiber optic sensors, a discussion of the design of a fiber optic <b>microphone,</b> the functional <b>elements</b> and packaging techniques of the optoelectronic circuitry, and the calibration techniques used {{in the development of the}} high temperature fiber optic microphone...|$|R
40|$|Recent {{commercialisation}} of seedless watermelon varieties {{relies on}} the guarantee of a high quality product. Several internal defects may deteriorate greatly this fruit: (a) creases and/or large voids in the flesh, (b) overripeness and (c) bruises due to impact. The objective {{of this research was}} to develop a feasible non-destructive procedure for detecting these defects in individual fruits, based on acoustic impulse response. A device consisting of a <b>microphone,</b> structural <b>elements</b> and a mechanical impact generator was designed and tested. Good and defective seedless watermelons were tested with the acoustic device. Spectral parameters were examined as potential non-destructive predictors of internal disorders. Waveband magnitude parameters, obtained by summing the magnitude of the spectrum between two frequencies in a specified band width (always including between 40 and 500 Hz), were the acoustic parameters showing the best ability to detect internal disorders...|$|R
