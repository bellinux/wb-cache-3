507|1117|Public
5000|$|... 1. For every {{discrete}} <b>memoryless</b> <b>channel,</b> {{the channel}} capacity ...|$|E
5000|$|Binary {{symmetric}} channel (BSC), {{a discrete}} <b>memoryless</b> <b>channel</b> {{with a certain}} bit error probability ...|$|E
5000|$|Note {{that if the}} {{probability}} of error on a discrete <b>memoryless</b> <b>channel</b> [...] is strictly less than one half, then minimum distance decoding is equivalent to maximum likelihood decoding, since if ...|$|E
40|$|This paper {{investigates the}} first- and second-order maximum {{achievable}} rates of codes with/without cost constraints for mixed channels whose channel law {{is characterized by}} a general mixture of (at most) uncountably many stationary and <b>memoryless</b> discrete <b>channels.</b> These channels are referred to as mixed <b>memoryless</b> <b>channels</b> with general mixture and include the class of mixed <b>memoryless</b> <b>channels</b> of finitely or countably <b>memoryless</b> <b>channels</b> as a special case. For mixed <b>memoryless</b> <b>channels</b> with general mixture, the first-order coding theorem which gives a formula for the ε-capacity is established, and then a direct part of the second-order coding theorem is provided. A subclass of mixed <b>memoryless</b> <b>channels</b> whose component channels can be ordered according to their capacity is introduced, and the first- and second-order coding theorems are established. It is shown that the established formulas reduce to several known formulas for restricted scenarios. Comment: 29 pages; submitted to IEEE Trans. on Information Theory, Jan. 2015. A conference version of this paper is presented at ISIT 201...|$|R
30|$|We first {{consider}} the <b>memoryless</b> <b>channels.</b>|$|R
5000|$|... #Subtitle level 3: Achievability for {{discrete}} <b>memoryless</b> <b>channels</b> ...|$|R
50|$|In 1956, Claude Shannon {{introduced}} the discrete <b>memoryless</b> <b>channel</b> with noiseless feedback. In 1961, Alfréd Rényi {{introduced the}} Bar-Kochba game (also known as Twenty questions), with a given percentage of wrong answers, and calculated the {{minimum number of}} randomly chosen questions to determine the answer.|$|E
50|$|Shannon's theorem is an {{important}} theorem in forward error correction, and describes the maximum information rate at which reliable communication is possible over a channel that has a certain error probability or signal-to-noise ratio (SNR). This strict upper limit is {{expressed in terms of}} the channel capacity. More specifically, the theorem says that there exist codes such that with increasing encoding length the probability of error on a discrete <b>memoryless</b> <b>channel</b> can be made arbitrarily small, provided that the code rate is smaller than the channel capacity. The code rate is defined as the fraction k/n of k source symbols and n encoded symbols.|$|E
3000|$|The upper bounds {{follow from}} Theorem 7. For the lower bound, we prefix a <b>memoryless</b> <b>channel</b> with inputs [...]...|$|E
5000|$|... #Subtitle level 2: Channel coding theorem for non-stationary <b>memoryless</b> <b>channels</b> ...|$|R
40|$|It {{is shown}} that the encoding/decoding problem for any asynchronous-user {{discrete}} <b>memoryless</b> multiple-access <b>channel</b> {{can be reduced to}} corresponding problems for at most 2 M - 1 single-user discrete <b>memoryless</b> <b>channels.</b> This result, which extends a similar result for Gaussian channels, reduces the seemingly hard task of finding good multiple-access codes to the much better understood task of finding good codes for single-user channels. As a by-product, some interesting properties of the capacity region of-user asynchronous discrete <b>memoryless</b> <b>channels</b> are derived...|$|R
2500|$|The {{channel coding}} theorem for {{discrete}} time non-stationary <b>memoryless</b> <b>channels</b> {{can be found}} here: noisy channel coding theorem ...|$|R
3000|$|To {{obtain the}} discrete-input continuous-output <b>memoryless</b> <b>channel</b> (DCMC) {{capacity}} associated with 8 PSK of 2 bits/channel use, the AWGN channel needs a minimum E [...]...|$|E
40|$|Abstract — We {{consider}} a two-dimensional {{version of the}} classical maximum-likelihood sequence detection problem for a binary antipodal signal that is corrupted by linear intersymbol interference (ISI) and then passed through a <b>memoryless</b> <b>channel.</b> For one-dimensional signals, this detection problem is well-known to be efficiently solved using the Viterbi algorithm. We show that the two-dimensional version is, in general, intractable, {{in the sense that}} a decision formulation of the problem is NP–complete for a certain fixed two-dimensional ISI and <b>memoryless</b> <b>channel</b> with errors and erasures. I...|$|E
40|$|In this tutorial, {{the design}} {{procedure}} of nearcapacity channel code design invoking non-binary EXtrinsic Information Transfer (EXIT) charts {{is illustrated by}} using design examples of Irregular Concatenated Coding Arrangements (ICCAs) relying on Irregular Convolutional Codes (IrCCs). More specifically, in order to benchmark the near-capacity design examples, both the capacity and the Outage Probability (OP) of the Continuous-input Continuous-output <b>Memoryless</b> <b>Channel</b> (CCMC), of the Discrete-input Continuous-output <b>Memoryless</b> <b>Channel</b> (DCMC) {{as well as of}} the Differential Discreteinput Continuous-output <b>Memoryless</b> <b>Channel</b> (D-DCMC) are characterised. Furthermore, the EXIT-chart aided near-capacity design principles are illustrated by detailing the design process of three characteristic prototype schemes, which represent the family of coherent and non-coherent detection based systems as well as Multi-Input Multi-Output (MIMO) systems, respectively. Moreover, the beneficial application of the EXIT-chart based design principle is also demonstrated in the context of cooperative systems using a specific distributed MIMO prototype schem...|$|E
40|$|It {{is shown}} that the encoding/decoding problem for any {{asynchronous}} M-user <b>memoryless</b> multiple-access <b>channel</b> {{can be reduced to}} corresponding problems for at most 2 M- 1 single-user <b>memoryless</b> <b>channels.</b> This is done via a method called time-splitting multiple-access which is closely related to a recently developed method called rate-splitting multiple access. It is also related to multilevel coding. The practical interest for time-splitting multiple access is that it reduces the seemingly hard task of finding good multiple-access codes and implementable decoders for such codes to the much better understood task of finding codes and decoders for single-user channels. As a by-product, some interesting properties of the capacity region of M-user asynchronous discrete <b>memoryless</b> <b>channels</b> are derived...|$|R
40|$|For any channel with a convex {{constraint}} set and finite Augustin capacity, {{existence of a}} unique Augustin center and associated Erven-Harremoes bound are established. Augustin-Legendre capacity, center, and radius are introduced and proved to be equal to the corresponding Renyi-Gallager entities. Sphere packing bounds with polynomial prefactors are derived for codes on two families of channels: (possibly non-stationary) <b>memoryless</b> <b>channels</b> with multiple additive cost constraints and stationary <b>memoryless</b> <b>channels</b> with convex constraints on the empirical distribution of the input codewords. Comment: Accepted to ISIT 201...|$|R
40|$|Abstract — Fixed length block codes on {{discrete}} <b>memoryless</b> <b>channels</b> with feedback {{are considered}} for errors and erasures decoding. Upper and lower bounds are derived for the error exponent {{in terms of}} the rate and the erasure exponents. In addition the converse result of Burnashev for variable length block codes is extended to include list decoding. Early results about the use of feedback on discrete <b>memoryless</b> <b>channels</b> (DMCs) in terms conventional performance criteria were negative. Not only the capacity was not increasing with feedback, as Shannon showed in [9], but also the erro...|$|R
40|$|Polar codes under {{successive}} cancellation decoding {{proposed by}} Arıkan provably achieve the symmetric capacity {{of any given}} binary-input discrete <b>memoryless</b> <b>channel.</b> The successive cancellation list decoder for polar codes was described by Tal and Vardy as a generalization of the successive cancellation decoder of Arıkan. The performance of the successive cancellation list decoder is encouraging in practice. In this paper, we formalize the successive cancellation list decoder in our notation and prove that polar codes under successive cancellation list decoding achieve the symmetric capacity of any given binary-input discrete <b>memoryless</b> <b>channel</b> in theory as well. We also formalize the polar codes with CRC precoding of Tal and Vardy. In fact, we propose a family of more general codes, namely, precoded polar codes and prove that precoded polar codes under successive cancellation list decoding can achieve the symmetric capacity of any given binary-input discrete <b>memoryless</b> <b>channel</b> under some conditions. Comment: 11 pages, no figure...|$|E
40|$|An {{iterative}} method of computing {{the capacity of}} a discrete <b>memoryless</b> <b>channel,</b> whose channel matrix has m row vectors and is of rank t, has been proposed independently by Arimoto (1972) and Blahut (1972). The amount of computation involved depends upon {{the size of the}} channel matrix used. It is shown that it is sufficient to use a set of t linearly independent row vectors as channel matrix in the computation of the capacity of a discrete <b>memoryless</b> <b>channel.</b> For the case m > t, a criterion for selecting a set of t linearly independent row vectors as channel matrix is presented...|$|E
40|$|We {{study the}} {{degraded}} multi-receiver wiretap channel with public and confidential messages. In this channel, {{there is a}} transmitter that wishes to communicate with two legitimate users {{in the presence of}} an external eavesdropper. The legitimate users and the eavesdropper satisfy a certain degradation order. In this paper, we study this channel model for the scenario where the transmitter sends a pair of public and confidential messages to each legitimate user. While there are no secrecy constraints on the public messages, confidential messages need to be transmitted in perfect secrecy. First, we obtain an inner bound for the capacity region of the discrete <b>memoryless</b> <b>channel</b> by using an achievable scheme that uses superposition coding and binning. Next, we obtain an outer bound for the capacity region of the degraded discrete <b>memoryless</b> <b>channel.</b> We show that this outer bound partially matches the inner bound. Consequently, we provide a partial characterization of the capacity region of the degraded discrete <b>memoryless</b> <b>channel.</b> Finally, we consider the degraded Gaussian multi-input multi-output (MIMO) wiretap channel with public and confidential messages. We show that, to evaluate both the inner and outer bounds for the Gaussian MIMO case, considering only jointly Gaussian auxiliary random variables and channel input is sufficient. Since the inner and outer bounds provided earlier for the degraded discrete <b>memoryless</b> <b>channel</b> partially match, these sufficiency results provide a partial characterization of the capacity region of the degraded Gaussian MIMO channel...|$|E
40|$|Abstract—This paper {{shows the}} strong {{converse}} and the dispersion of <b>memoryless</b> <b>channels</b> with cost constraints. The analysis {{is based on}} a new non-asymptotic converse bound expressed in terms of the distribution of a random variable termed the b-tilted information density, which plays a role {{similar to that of the}} information density in channel coding without cost constraints. We also analyze the fundamental limits of lossy joint-sourcechannel coding over channels with cost constraints. Index Terms—Converse, finite blocklength regime, channels with cost constraints, joint source-channel coding, strong converse, dispersion, <b>memoryless</b> sources, <b>memoryless</b> <b>channels,</b> Shannon theory. I...|$|R
40|$|We {{describe}} certain extremalities for Gallager’s E 0 function evaluated {{under the}} uniform input distribution for binary input discrete <b>memoryless</b> <b>channels.</b> The results characterize the extremality of the E 0 (ρ) curves of the binary erasure channel and the binary symmetric channel {{among all the}} E 0 (ρ) curves that can be generated by the class of binary discrete <b>memoryless</b> <b>channels</b> whose E 0 (ρ) curves pass through a given point (ρ 0, e 0), for some ρ 0 > − 1. Index Terms Channel reliability function, random coding exponent, extremal channels. I...|$|R
40|$|We {{describe}} certain extremalities for Gallager's E_ 0 function evaluated {{under the}} uniform input distribution for binary input discrete <b>memoryless</b> <b>channels.</b> The results characterize the extremality of the E_ 0 (ρ) curves of the binary erasure channel and the binary symmetric channel {{among all the}} E_ 0 (ρ) curves that can be generated by the class of binary discrete <b>memoryless</b> <b>channels</b> whose E_ 0 (ρ) curves pass through a given point (ρ_ 0, e_ 0), for some ρ_ 0 > - 1. Comment: 39 pages, submitted to IEEE Transactions on Information Theor...|$|R
40|$|Typical {{performance}} of low-density parity-check (LDPC) codes over a general binary-input output-symmetric <b>memoryless</b> <b>channel</b> is investigated using methods of statistical mechanics. The binary-input additive-white-Gaussian-noise channel and the binary-input Laplace channel are considered as specific channel noise models...|$|E
3000|$|Let W:X→Y denote {{a general}} {{symmetric}} binary input <b>memoryless</b> <b>channel</b> (B-DMC) and W_N:X^N→Y^N denote a vector channel. If channels are independent but not identical, then W_N(y_ 1 ^N|x_ 1 ^N)=∏ _i= 1 ^NW_(i)(y_i|x_i) where W_(i): X_i→Y_i, such that their transition probabilities p [...]...|$|E
30|$|The polar codes {{previously}} {{introduced in}} [1] are a coding scheme that achieves the symmetric capacity of any discrete <b>memoryless</b> <b>channel</b> (DMC) by exploiting channel polarization phenomena. The block error rate converges to zero as the code length N goes to infinity.|$|E
40|$|Abstract—Inner {{and outer}} bounds are derived on the optimal {{performance}} of fixed-length block codes on discrete <b>memoryless</b> <b>channels</b> with feedback and errors-and-erasures decoding. First, an inner bound is derived using a two-phase encoding scheme with communication and control phases {{together with the}} optimal decoding rule for the given encoding scheme, among decoding rules that can be represented in terms of pairwise comparisons between the messages. Then, an outer bound is derived using a generalization of the straight-line bound to errors-and-erasures decoders and the optimal error-exponent tradeoff of a feedback encoder with two messages. In addition, {{upper and lower bounds}} are derived, for the optimal erasure exponent of error-free block codes in terms of the rate. Finally, a proof is provided {{for the fact that the}} optimal tradeoff between error exponents of a two-message code does not improve with feedback on discrete <b>memoryless</b> <b>channels</b> (DMCs). Index Terms—Decision feedback, discrete <b>memoryless</b> <b>channels</b> (DMCs), error exponent, errors-and-erasures decoding, feedback, feedback encoding schemes, soft decoding, two-phase encoding schemes, variable-length coding. I...|$|R
40|$|Channel polarization, {{originally}} {{proposed for}} binary-input channels, is generalized to arbitrary discrete <b>memoryless</b> <b>channels.</b> Specifically, it is shown {{that when the}} input alphabet size is a prime number, a similar construction to that for the binary case leads to polarization. This method can be extended to channels of composite input alphabet sizes by decomposing such channels into a set of channels with prime input alphabet sizes. It is also shown that all discrete <b>memoryless</b> <b>channels</b> can be polarized by randomized constructions. The introduction of randomness {{does not change the}} order of complexity of polar code construction, encoding, and decoding. A previous result on the error probability behavior of polar codes is also extended to the case of arbitrary discrete <b>memoryless</b> <b>channels.</b> The generalization of polarization to channels with arbitrary finite input alphabet sizes leads to polar-coding methods for approaching the true (as opposed to symmetric) channel capacity of arbitrary channels with discrete or continuous input alphabets. © 2009 IEEE...|$|R
25|$|The AEP for non-stationary discrete-time {{independent}} process {{leads us}} to (among other results) source coding theorem for non-stationary source (with independent output symbols) and channel coding theorem for non-stationary <b>memoryless</b> <b>channels.</b>|$|R
40|$|In Information Theory we know {{two types}} of channel models for communication: the {{probabilistic}} description of transmission of letters and the combinatorial description based on counting erroneous transmission of letters. The standard probabilistic channel {{is that of a}} discrete <b>memoryless</b> <b>channel,</b> abbreviate...|$|E
40|$|This paper extends linear-complexity {{concatenated}} coding schemes to fountain communication over the discrete-time <b>memoryless</b> <b>channel.</b> Achievable fountain error exponents for one-level and multi-level concatenated fountain codes are derived. It is {{also shown that}} {{concatenated coding}} schemes possess interesting properties in several multi-user fountain communication scenarios...|$|E
3000|$|... where K is the Rician {{factor in}} terms of dB. We assume that the {{demodulator}} operates over one symbol interval, which yields a discrete <b>memoryless</b> <b>channel.</b> At the receiver, the corrupted MLTC-CPFSK signals are processed by the demodulator and MAP decoder to extract the information sequence.|$|E
3000|$|..., {{is assumed}} to be known. We will further {{restrict}} our discussion to the case of <b>memoryless</b> <b>channels,</b> where each transmission {{is assumed to}} occur independently according to the channel transition probability.|$|R
50|$|The AEP for non-stationary discrete-time {{independent}} process {{leads us}} to (among other results) source coding theorem for non-stationary source (with independent output symbols) and channel coding theorem for non-stationary <b>memoryless</b> <b>channels.</b>|$|R
40|$|We {{obtain a}} maximizer for the quantum mutual {{information}} for classical information sent over the quantum qubit amplitude damping channel. This {{is achieved by}} limiting the ensemble of input states to antipodal states, in the calculation of the product-state capacity for the channel, the resulting maximizing ensemble consisting of just two non-orthogonal states. We also consider the product-state capacity of a convex combination of two <b>memoryless</b> <b>channels</b> and demonstrate in particular {{that it is in}} general not given by the minimum of the capacities of the respective <b>memoryless</b> <b>channels.</b> Comment: Published in IJQI (2008). One figure adde...|$|R
