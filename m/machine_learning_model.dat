410|10000|Public
5000|$|Removal of multi-collinearity {{improves}} {{the performance of}} the <b>machine</b> <b>learning</b> <b>model.</b>|$|E
5000|$|Graphcore is a {{semiconductor}} {{company that}} develops accelerators for AI and Machine Learning. It aims {{to make a}} massively parallel Intelligent Processing Unit (IPU) that holds the complete <b>machine</b> <b>learning</b> <b>model</b> inside the processor.|$|E
50|$|A {{decision}} stump is a <b>machine</b> <b>learning</b> <b>model</b> {{consisting of}} a one-level decision tree. That is, it is a decision tree with one internal node (the root) which is immediately connected to the terminal nodes (its leaves). A decision stump makes a prediction based {{on the value of}} just a single input feature. Sometimes they are also called 1-rules.|$|E
50|$|Interactive {{explanations}} of results from (sometimes) complex <b>machine</b> <b>learning</b> <b>models</b> and techniques.|$|R
40|$|Abstract. We {{examine the}} interplay of {{optimization}} and <b>machine</b> <b>learning.</b> Great {{progress has been made}} in <b>machine</b> <b>learning</b> by cleverly reducing <b>machine</b> <b>learning</b> problems to convex optimization problems with one or more hyper-parameters. The availability of powerful convexprogramming theory and algorithms has enabled a flood of new research in <b>machine</b> <b>learning</b> <b>models</b> and methods. But many of the steps necessary for successful <b>machine</b> <b>learning</b> <b>models</b> fall outside of the convex <b>machine</b> <b>learning</b> paradigm. Thus we now propose framing <b>machine</b> <b>learning</b> problems as Stackelberg games. The resulting bilevel optimization problem allows for efficient systematic search of large numbers of hyper-parameters. We discuss recent progress in solving these bilevel problems and the many interesting optimization challenges that remain. Finally, we investigate the intriguing possibility of novel <b>machine</b> <b>learning</b> <b>models</b> enabled by bilevel programming. ...|$|R
5000|$|R: {{produces}} PMML for neural {{nets and}} other <b>machine</b> <b>learning</b> <b>models</b> via the package pmml.|$|R
50|$|The {{same kind}} of <b>machine</b> <b>learning</b> <b>model</b> could require {{different}} constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, {{and have to be}} tuned so that the model can best solve the machine learning problem. Usually a metric is chosen to measure the algorithm's performance on an independent data set and hyperparameters that maximize this measure are adopted. Often cross-validation is used to estimate this generalization performance.|$|E
5000|$|Hierarchical {{temporal}} {{memory is}} an online <b>machine</b> <b>learning</b> <b>model</b> developed by Jeff Hawkins and Dileep George of Numenta, Inc. that models {{some of the}} structural and algorithmic properties of the neocortex. HTM is a biomimetic model based on the memory-prediction theory of brain function described by Jeff Hawkins in his book On Intelligence. HTM is a method for discovering and inferring the high-level causes of observed input patterns and sequences, thus building an increasingly complex model of the world.|$|E
50|$|Some other {{researchers}} have suggested that learning in DDM tasks {{can be explained by}} a connectionist theory or connectionism. The connections between units, whose strength or weighing depend upon previous experience. Thus, the output of a given unit depends upon the output of the previous unit weighted by the strength of the connection. As an example, Gibson et al. has shown that a connectionist neural network <b>machine</b> <b>learning</b> <b>model</b> does a good job to explain human behavior in the Berry and Broadbent’s Sugar Production Factory task.|$|E
40|$|This paper {{introduces}} the Encog library for Java and C#, a scalable, adaptable, multiplatform <b>machine</b> <b>learning</b> framework that was 1 st released in 2008. Encog allows {{a variety of}} <b>machine</b> <b>learning</b> <b>models</b> {{to be applied to}} datasets using regression, classification, and clustering. Various supported <b>machine</b> <b>learning</b> <b>models</b> can be used interchangeably with minimal recoding. Encog uses efficient multithreaded code to reduce training time by exploiting modern multicore processors. The current version of Encog can be downloaded from [URL]...|$|R
50|$|SINGA's {{software}} stack {{includes three}} major components, namely, core, IO and model. The following figure illustrates these components {{together with the}} hardware. The core component provides memory management and tensor operations; IO has classes for reading (and writing) data from (to) disk and network; The model component provides data structures and algorithms for <b>machine</b> <b>learning</b> <b>models,</b> e.g., layers for neural network models, optimizers/initializer/metric/loss for general <b>machine</b> <b>learning</b> <b>models.</b>|$|R
40|$|<b>Machine</b> <b>learning</b> <b>models</b> are {{vulnerable}} to adversarial examples formed by applying small carefully chosen perturbations to inputs that cause unexpected classification errors. In this paper, we perform experiments on various adversarial example generation approaches with multiple deep convolutional neural networks including Residual Networks, the best performing models on ImageNet Large-Scale Visual Recognition Challenge 2015. We compare the adversarial example generation techniques {{with respect to the}} quality of the produced images, and measure the robustness of the tested <b>machine</b> <b>learning</b> <b>models</b> to adversarial examples. Finally, we conduct large-scale experiments on cross-model adversarial portability. We find that adversarial examples are mostly transferable across similar network topologies, and we demonstrate that better <b>machine</b> <b>learning</b> <b>models</b> are less vulnerable to adversarial examples. Comment: Accepted for publication at ICMLA 201...|$|R
50|$|Protein {{secondary}} structure prediction is a {{main focus of}} this subfield as the further protein foldings (tertiary and quartenary structures) are determined based on the {{secondary structure}}. Solving the true structure of a protein is an incredibly expensive and time-intensive process, furthering the need for systems that can accurately predict {{the structure of a}} protein by analyzing the amino acid sequence directly. Prior to machine learning, researchers needed to conduct this prediction manually. This trend began in 1951 when Pauling and Corey released their work on predicting the hydrogen bond configurations of a protein from a polypeptide chain. Today, through the use of automatic feature learning, the best machine learning techniques are able to achieve an accuracy of 82-84%. The current state-of-the-art in secondary structure prediction uses a system called DeepCNF (Deep Convolutional Neural Fields) which relies on the <b>machine</b> <b>learning</b> <b>model</b> of artificial neural networks to achieve an accuracy of approximately 84% when tasked to classify the amino acids of a protein sequence into one of three structural classes (helix, sheet, or coil). The theoretical limit for three-state protein secondary structure is 88-90%.|$|E
50|$|Bayesian {{optimization}} is {{a methodology}} {{for the global}} optimization of noisy black-box functions. Applied to hyperparameter optimization, Bayesian optimization consists of developing a statistical model of the function from hyperparameter values to the objective evaluated on a validation set. Intuitively, the methodology assumes {{that there is some}} smooth but noisy function that acts as a mapping from hyperparameters to the objective. In Bayesian optimization, one aims to gather observations in such a manner as to evaluate the <b>machine</b> <b>learning</b> <b>model</b> the least number of times while revealing as much information as possible about this function and, in particular, the location of the optimum. Bayesian optimization relies on assuming a very general prior over functions which when combined with observed hyperparameter values and corresponding outputs yields a distribution over functions. The methodology proceeds by iteratively picking hyperparameters to observe (experiments to run) in a manner that trades off exploration (hyperparameters for which the outcome is most uncertain) and exploitation (hyperparameters which are expected to have a good outcome). In practice, Bayesian optimization has been shown to obtain better results in fewer experiments than grid search and random search, due to the ability to reason about the quality of experiments before they are run.|$|E
5000|$|Under {{the third}} direction, {{researchers}} propose to use text mining and sentiment analysis algorithms to extract information about investors’ mood from social networks, media platforms, blogs, newspaper articles, and other relevant sources of textual data (sometimes referred as news analytics). A thread of publications (Barber & Odean (2008), Dougal et al. (2012), and Ahern & Sosyura (2015)) report a significant influence of financial articles and sensational news on behavior of stock prices. It {{is also not}} surprising, that such popular sources of news as Wall Street Journal, New York Times or Financial Times have a profound influence on the market. The strength of the impact can vary between different columnists even inside a particular journal (Dougal et al. (2012)). Tetlock (2007) suggests a successful measure of investors’ mood by counting the amount of [...] "negative" [...] words in a popular Wall Street Journal column [...] "Abreast of the market". Zhang et al. (2011) and Bollen et al. (2011) report Twitter to be an extremely important source of sentiment data, which helps to predict stock prices and volatility. The usual way to analyze {{the influence of the}} data from micro-blogging platforms on behavior of stock prices is to construct special mood tracking indexes. The easiest way would be to count the number of [...] "positive" [...] and [...] "negative" [...] words in each relevant tweet and construct a combined indicator based on this data. Nasseri et al. (2014) reports the predictive power of StockTwits (Twitter-like platform specialized on exchanging trading-related opinions) data with respect to behavior of stock prices. An alternative, but more demanding, way is to engage human experts to annotate a large number of tweets with the expected stock moves, and then construct a <b>machine</b> <b>learning</b> <b>model</b> for prediction. The application of the event study methodology to Twitter mood shows significant correlation to cumulative abnormal returns (Sprenger et al. (2014), Ranco et al. (2015), Gabrovšek et al. (2017) [...] ). Karabulut (2013) reports Facebook to be a good source of information about investors’ mood. Overall, most popular social networks, finance-related media platforms, magazines, and journals can be a valuable source of sentiment data, summarized in Peterson (2016). However, important to notice that it is relatively more difficult to collect such type of data (in most cases a researcher needs a special software). In addition, analysis of such data can also require deep machine learning and data mining knowledge (Hotho et al. (2005)).|$|E
5000|$|High-performance and {{parallel}} data transfer to statistical {{tools such as}} built-in <b>machine</b> <b>learning</b> algorithms based on R, {{and the ability to}} store <b>machine</b> <b>learning</b> <b>models,</b> and use them for in-database scoring.|$|R
30|$|All hairpins were {{filtered}} for sequence similarity as in Yousef et al. [31] before training <b>machine</b> <b>learning</b> <b>models</b> {{using the}} Usearch tool [47].|$|R
40|$|In {{the past}} years, mass {{univariate}} statistical analyses of neuroimaging data have been complemented {{by the use}} of multivariate pattern analyses, especially based on <b>machine</b> <b>learning</b> <b>models.</b> While these allow an increased sensitivity for the detection of spatially distributed e ffects compared to univariate techniques, they lack an established and accessible software framework. Here we introduce the Recognition for Neuroimaging Toolbox" (PRoNTo), an open-source, cross-platform and MATLAB-based software comprising many necessary functionalities for <b>machine</b> <b>learning</b> <b>modelling</b> of neuroimaging data. Peer reviewe...|$|R
30|$|A <b>machine</b> <b>learning</b> <b>model</b> was {{constructed}} {{and used to}} classify both weakly positive and negative samples, significantly enhancing specificity and sensitivity.|$|E
3000|$|... and {{combining}} these using a <b>machine</b> <b>learning</b> <b>model.</b> Some {{machine learning}} techniques {{that have been}} used in the past are artifical neural networks (ANN), linear discriminant analysis (LDA) classifiers, and binary decision trees.|$|E
40|$|The {{benefits}} of cardiac surgery are sometimes {{difficult to predict}} and the decision to operate on a given individual is complex. Machine Learning and Decision Curve Analysis (DCA) are recent methods developed to create and evaluate prediction models. We conducted a retrospective cohort study using a prospective collected database from December 2005 to December 2012, from a cardiac surgical center at University Hospital. The different models of prediction of mortality in-hospital after elective cardiac surgery, including EuroSCORE II, a logistic regression model and a <b>machine</b> <b>learning</b> <b>model,</b> were compared by ROC and DCA. Of the 6, 520 patients having elective cardiac surgery with cardiopulmonary bypass, 6. 3 % died. Mean age was 63. 4 years old (standard deviation 14. 4), and mean EuroSCORE II was 3. 7 (4. 8) %. The area under ROC curve (IC 95 %) for the <b>machine</b> <b>learning</b> <b>model</b> (0. 795 (0. 755 - 0. 834)) {{was significantly higher than}} EuroSCORE II or the logistic regression model (respectively, 0. 737 (0. 691 - 0. 783) and 0. 742 (0. 698 - 0. 785), p < 0. 0001). Decision Curve Analysis showed that the <b>machine</b> <b>learning</b> <b>model,</b> in this monocentric study, has a greater benefit whatever the probability threshold. According to ROC and DCA, <b>machine</b> <b>learning</b> <b>model</b> is more accurate in predicting mortality after elective cardiac surgery than EuroSCORE II. These results confirm the use of machine learning methods in the field of medical prediction...|$|E
30|$|These {{features}} are {{then used to}} build supervised <b>machine</b> <b>learning</b> <b>models</b> to differentiate between benign and malicious P 2 P traffic. More details will follow in the next section.|$|R
40|$|BACKGROUND: As {{more and}} more {{researchers}} are turning to big data for new opportunities of biomedical discoveries, <b>machine</b> <b>learning</b> <b>models,</b> as the backbone of big data analysis, are mentioned more often in biomedical journals. However, owing to the inherent complexity of <b>machine</b> <b>learning</b> methods, they are prone to misuse. Because of the flexibility in specifying <b>machine</b> <b>learning</b> <b>models,</b> the results are often insufficiently reported in research articles, hindering reliable assessment of model validity and consistent interpretation of model outputs. OBJECTIVE: To attain a set of guidelines {{on the use of}} <b>machine</b> <b>learning</b> predictive <b>models</b> within clinical settings to make sure the models are correctly applied and sufficiently reported so that true discoveries can be distinguished from random coincidence. METHODS: A multidisciplinary panel of <b>machine</b> <b>learning</b> experts, clinicians, and traditional statisticians were interviewed, using an iterative process in accordance with the Delphi method. RESULTS: The process produced a set of guidelines that consists of (1) a list of reporting items to be included in a research article and (2) a set of practical sequential steps for developing predictive models. CONCLUSIONS: A set of guidelines was generated to enable correct application of <b>machine</b> <b>learning</b> <b>models</b> and consistent reporting of model specifications and results in biomedical research. We believe that such guidelines will accelerate the adoption of big data analysis, particularly with <b>machine</b> <b>learning</b> methods, in the biomedical research community...|$|R
40|$|A~machine {{learning}} framework is developed to estimate ocean-wave conditions. By supervised training of <b>machine</b> <b>learning</b> <b>models</b> on {{many thousands of}} iterations of a physics-based wave model, accurate representations of significant wave heights and period {{can be used to}} predict ocean conditions. A model of Monterey Bay was used as the example test site; it was forced by measured wave conditions, ocean-current nowcasts, and reported winds. These input data along with model outputs of spatially variable wave heights and characteristic period were aggregated into supervised learning training and test data sets, which were supplied to <b>machine</b> <b>learning</b> <b>models.</b> These <b>machine</b> <b>learning</b> <b>models</b> replicated wave heights with a root-mean-squared error of 9 cm and correctly identify over 90 % of the characteristic periods for the test-data sets. Impressively, transforming model inputs to outputs through matrix operations requires only a fraction (< 1 / 1, 000) of the computation time compared to forecasting with the physics-based model. Comment: submitted to Journal of Coastal Engineerin...|$|R
40|$|This thesis {{presents}} a <b>machine</b> <b>learning</b> <b>model</b> capable of extracting discrete classes out of continuous valued input features. This is done using a neurally inspired novel competitive classifier (CC) which feeds the discrete classifications {{forward to a}} supervised <b>machine</b> <b>learning</b> <b>model.</b> The supervised learning model uses the discrete classifications and perhaps other information available to solve a problem. The supervised learner then generates feedback to guide the CC into potentially more useful classifications of the continuous valued input features. Two supervised learning models are combined with the CC creating ASOCS-AFE and ID 3 AFE. Both models are simulated {{and the results are}} analyzed. Based on these results, several areas of future research are proposed...|$|E
40|$|Predictive {{models are}} often used for {{real-time}} decision making. However, typical machine learning techniques ignore feature evaluation cost, and focus solely on {{the accuracy of the}} machine learning models obtained utilizing all the features available. We develop algorithms and indexes to support cost-sensitive prediction, i. e., making decisions using machine learning models taking feature evaluation cost into account. Given an item and a online computation cost (i. e., time) budget, we present two approaches to return an appropriately chosen <b>machine</b> <b>learning</b> <b>model</b> that will run within the specified time on the given item. The first approach returns the optimal <b>machine</b> <b>learning</b> <b>model,</b> i. e., one with the highest accuracy, that runs within the specified time, but requires significant up-front precomputation time. The second approach returns a possibly sub- optimal <b>machine</b> <b>learning</b> <b>model,</b> but requires little up-front precomputation time. We study these two algorithms in detail and characterize the scenarios (using real and synthetic data) in which each performs well. Unlike prior work that focuses on a narrow domain or a specific algorithm, our techniques are very general: they apply to any cost-sensitive prediction scenario on any machine learning algorithm...|$|E
40|$|The constaints of {{time and}} memory will reduce the {{learning}} performance of Support Vector Machine (SVM) when {{it is used to}} solve the large number of samples. In order to solve this problem, a novel algorithm called Granular Support Vector Machine based on Mixed Kernel Function (GSVM-MKF) is proposed. Firstly, the granular method is propsed and then the judgment and extraction methods of support vector particles are given. On the above basis, we propose a new granular support vector <b>machine</b> <b>learning</b> <b>model.</b> Secondly, in order to further improve the performance of the granular support vector <b>machine</b> <b>learning</b> <b>model,</b> a mixed kernel function which effectively uses the global kernel function having the good generalization ability and the local kernel function having good learning ability is proposed. Finally, the theoretical analysis and experimental results show the effectiveness of the method. The constaints {{of time and}} memory will reduce the learning performance of Support Vector Machine (SVM) when it is used to solve the large number of samples. In order to solve this problem, a novel algorithm called Granular Support Vector Machine based on Mixed Kernel Function (GSVM-MKF) is proposed. Firstly, the granular method is propsed and then the judgment and extraction methods of support vector particles are given. On the above basis, we propose a new granular support vector <b>machine</b> <b>learning</b> <b>model.</b> Secondly, in order to further improve the performance of the granular support vector <b>machine</b> <b>learning</b> <b>model,</b> a mixed kernel function which effectively uses the global kernel function having the good generalization ability and the local kernel function having good learning ability is proposed. Finally, the theoretical analysis and experimental results show the effectiveness of the method...|$|E
5000|$|Binding sites {{also exist}} on {{antibodies}} as specifically coded regions that bind antigens {{based upon their}} structure. Several supervised <b>Machine</b> <b>learning</b> <b>models</b> and applications were suggested to identify the binding sites.|$|R
50|$|Data {{collected}} for training <b>machine</b> <b>learning</b> <b>models</b> usually is lacking a comprehensive set of {{working conditions and}} health states/fault modes, which may cause false positives and false negatives in online implementation of AI systems.|$|R
30|$|<b>Machine</b> <b>learning</b> (ML), the {{de facto}} {{approach}} to achieve artificial intelligence, provides a convenient way for AI practitioners to rapidly implant intelligence to machines, {{with the help of}} labeled data, and without needing to make clear the logics and theory behind data. All in a sudden, the convenient approach was acquired by professionals in nearly every fields. People continually collect data from their users, train <b>machine</b> <b>learning</b> <b>models</b> using the collected data and pack the trained models to their products to provide better service to their users. The intelligent service, in turn, attracts more users and usages, and simultaneously provides more data to refine the <b>machine</b> <b>learning</b> <b>models,</b> resulting in a virtuous circle that absorbing users and practitioners.|$|R
40|$|Being a bank, bunq {{deals with}} {{transaction}} fraud {{on a regular}} basis. All transactions that are handled by bunq are monitored for these cases of fraud by a transaction monitoring system. When this system flags a transaction as being possibly fraudulent, a bunq employee has to manually check this transaction. The problem with the current system is that it proves to be time consuming and labor intensive. This {{is caused by the}} fact that there are a lot of transactions which are falsely flagged as possibly fraudulent, these transactions are called false positives. This resulted in a demand for a system which reduced the number of false positives and thereby the time needed to manually check the flagged transactions. To fulfill this demand, bunq has been working on creating a <b>machine</b> <b>learning</b> <b>model</b> which classifies transactions as fraudulent or legitamte. This <b>machine</b> <b>learning</b> <b>model</b> has shown promising results during test runs on historical data. However, it was not yet production ready, because it was very slow and there existed no connection with the existing bunq back-end. During the project, a new transaction monitoring system was designed and implemented. The new system uses a combination of a bunq-made <b>machine</b> <b>learning</b> <b>model</b> and a set of pre-defined rules to flag a transaction as possibly fraudulent or not. The final system implementation consists out of 5 different components: (1) an incoming transaction system, responsible for noticing new transactions and segregating those over different workers so that they can be classified in parallel, (2) an information gathering system, which efficiently gathers large sets of needed information for the classification, (3) a <b>machine</b> <b>learning</b> <b>model</b> server, which enables fast communication with altering machine learning models, (4) a set of pre-defined rules, which check transactions for indicators of fraud and (5) a Grafana dashboard which monitors the performance and statistics of the <b>machine</b> <b>learning</b> <b>model,</b> the pre-defined rules and our system. The system is fully tested by unit and integration tests. Furthermore, new machine learning models and pre-defined rules can be easily adopted. All the above mentioned components are implemented and fully working. The final implementation is focused on integrating the system in the currently existing bunq back-end, because the system will actually be used in production...|$|E
30|$|A {{complete}} covariate {{shift process}} {{is divided into}} two stages: reweighting importance of training data, and training a weighted <b>machine</b> <b>learning</b> <b>model</b> for prediction on the test dataset. In the first stage, we reweight the importance of training instances by estimating the ratio P_te(x_tr)/P_tr(x_tr).|$|E
40|$|In this paper, {{we propose}} a semi-supervised {{learning}} of acoustic driven phrase breaks and its usefulness for text-to-speech systems. In this work, we derive {{a set of}} initial hypothesis of phrase breaks in a speech signal using pause as an acoustic cue. As these initial estimates are obtained based on knowledge of speech production and speech signal processing, one could treat the hypothesized phrase break regions as labeled data. Features such as duration, F 0 and energy are extracted from these labeled regions and a <b>machine</b> <b>learning</b> <b>model</b> is trained to perform the classification of these acoustic features as belonging to the class of a phrase break or not a phrase break. We then attempt to bootstrap the <b>machine</b> <b>learning</b> <b>model</b> using unlabeled data (i. e., {{the rest of the}} data). Index Terms: speech synthesis, acoustic driven phrasing, semisupervised 1...|$|E
40|$|In {{order to}} achieve {{state-of-the-art}} performance, modern <b>machine</b> <b>learning</b> techniques require careful data pre-processing and hyperparameter tuning. Moreover, given the ever increasing number of <b>machine</b> <b>learning</b> <b>models</b> being developed, model selection is becoming increasingly important. Automating the selection and tuning of <b>machine</b> <b>learning</b> pipelines consisting of data pre-processing methods and <b>machine</b> <b>learning</b> <b>models,</b> has long {{been one of the}} goals of the <b>machine</b> <b>learning</b> community. In this paper, we tackle this meta-learning task by combining ideas from collaborative filtering and Bayesian optimization. Using probabilistic matrix factorization techniques and acquisition functions from Bayesian optimization, we exploit experiments performed in hundreds of different datasets to guide the exploration of the space of possible pipelines. In our experiments, we show that our approach quickly identifies high-performing pipelines across a wide range of datasets, significantly outperforming the current state-of-the-art...|$|R
40|$|More {{and more}} data are {{becoming}} part of people 2 ̆ 7 s lives. With the popularization of technologies like sensors, and the Internet of Things, data gathering is becoming possible and accessible for users. With these data in hand, users {{should be able to}} extract insights from them, and they want results as soon as possible. Average users have little or no experience in data analytics and <b>machine</b> <b>learning</b> and are not great observers who can collect enough data to build their own <b>machine</b> <b>learning</b> <b>models.</b> With large quantities of similar data being generated around the world and many <b>machine</b> <b>learning</b> <b>models</b> being used, {{it should be possible to}} use additional data and existing models to create accurate <b>machine</b> <b>learning</b> <b>models</b> for these users. This thesis proposes Agora, a Web-based marketplace where users can share their data and <b>machine</b> <b>learning</b> <b>models</b> with other users with small datasets and little experience. This thesis includes an overview of all the components that make up Agora, as well as details of two of its main components: Hephaestus and Sibyl. Hephaestus is a domain adaptation method for multi-feature regression models with seasonal adjustment, which can improve predictions for small datasets using information from additional datasets. Hephaestus works in the pre- and post- processing phases, making it possible to work with any standard <b>machine</b> <b>learning</b> algorithm. As a case study, we built predictive models using the proposed method to predict school energy consumption with only one month of data, improving accuracy to the same level as if 12 months of data were being used. Sibyl is a flexible, scalable and non-blocking <b>machine</b> <b>learning</b> as a service, which facilitates the creation of multiple predictive models and running them at the same time. As a case study, we implemented Sibyl equipped with three <b>machine</b> <b>learning</b> algorithms to show the flexibility of adding new algorithms. We also executed three models at the same time to demonstrate that they can run without interference from another model. The results obtained in this research demonstrates the concept of Agora. Users can share the same platform to provide or consume knowledge and create multiple concurrent <b>machine</b> <b>learning</b> <b>models...</b>|$|R
30|$|Based on {{the above}} dataset, we build multiclass {{classifiers}} for the nine industry sectors. In the following, we will first describe how we generate the features and then introduce the <b>machine</b> <b>learning</b> <b>models</b> we used.|$|R
