15|41|Public
50|$|The AN/USQ-17 or Naval Tactical Data System (NTDS) {{computer}} {{referred to}} in Sperry Rand documents as the Univac M-460, was Seymour Cray's last design for UNIVAC. UNIVAC later released a commercial version, the UNIVAC 490 and that system was later upgraded to a <b>multiprocessor</b> <b>configuration</b> as the 494.|$|E
50|$|The WCC is {{the main}} {{computer}} within the Patriot system. It is a 24-bit parallel militarized computer with fixed and floating point capability. It is organized in a <b>multiprocessor</b> <b>configuration</b> that operates at a maximum clock rate of 6 megahertz. This computer controls the operator interface, calculates missile intercept algorithms, and provides limited fault diagnostics. Compared to modern personal computers, it has somewhat limited processing power, {{although it has been}} upgraded several times during Patriot's service life.|$|E
50|$|After {{initialization}} UMMPS {{is entirely}} interrupt driven. The interrupts {{may be due}} to supervisor (SVC) or monitor (MC) call instructions issued by job programs to request services, page fault interrupts for virtual memory pages that are not in real memory when referenced by a job program, program interrupts caused by abnormal conditions in job programs, timer interrupts on behalf of job programs or used internally within the supervisor, interrupts from the input/output subsystem, machine check interrupts, external (operator initiated) interrupts, and interrupts from other processors in a <b>multiprocessor</b> <b>configuration.</b>|$|E
50|$|ND {{also sold}} <b>multiprocessor</b> <b>configurations,</b> naming them ND-580/n and an ND-590n, where n {{represented}} {{the number of}} CPUs in a given configuration, 2, 3, or 4.|$|R
40|$|Abstract—This {{correspondence}} {{introduces the}} class of partially-connected multiple-bus <b>multiprocessor</b> <b>configurations</b> called band-connected partial crossbars. An analytical derivation of the effective memory bandwidth of band-connected partial crossbars, based on a simple model of such systems, is also presented. Index Terms—Band-connected partial crossbar, effective memory bandwidth, multibus, multiple-bus, multiprocessor. I...|$|R
40|$|The {{integration}} of vector computers into <b>multiprocessor</b> <b>configurations</b> allows {{the use of}} multiple high-speed processors in parallel for one program. There are two aspects which are considered to be important for an efficient use of <b>multiprocessor</b> <b>configurations.</b> First, the flexibility, speed and user friendliness of the available synchronization and communication primitives, and second, the user problems in detecting data dependencies and in translating programs correctly into the parallel form required by the system. This paper is intended to give an overview of our experiences in multitasking using up to four CPUs of a CRAY X-MP/ 48. The results gained by macrotasking and microtasking will be compared for program kernels and real-life application programs. Special attention is paid to the difficulties of using more than two CPUs in parallel...|$|R
5000|$|The 1107 {{and early}} 1108 {{machines}} {{were aimed at}} the Engineering/Scientific computing community, {{so much so that}} the 1100 Series User Group was named the UNIVAC Scientific Exchange, or USE. The operating systems were batch oriented, with FORTRAN and (to a much lesser extent) ALGOL being the most commonly used languages. As the market for commercial computing became more mature, these operating systems were no longer able to meet the growing demand for business computing, where applications were commonly written in COBOL. UNIVAC responded to this change in the market with the 1108A multiprocessor system and with the EXEC 8 operating system. Where engineering and scientific programs could often be [...] "compute bound" [...] (i.e. - utilizing the entire CPU and core memory), business applications, typically written in COBOL, were almost always [...] "I/O bound" [...] (i.e. - waiting for I/O operations to complete). Instrumentation of the EXEC 8 operating system showed that, in a 1108A <b>multiprocessor</b> <b>configuration,</b> the CPU(s) were often in the [...] "idle loop" [...] as much as 50% of the time (see note below). Since CPU performance was not an issue in these applications, it made commercial sense to create a lower-priced, lower-performance system to address the rapidly growing commercial business market.|$|E
40|$|Modern {{digital image}} {{processing}} hardware makes possible quantitative analysis of microscope images at high speed. This paper describes an application to automatic screening for cervical cancer. The system uses twelve MC 6809 microprocessors arranged in a pipeline <b>multiprocessor</b> <b>configuration.</b> Each processor executes {{one part of the}} algorithm on each cell image as it passes through the pipeline. Each processor communicates with its upstream and downstream neighbors via shared two-port memory. Thus no time is devoted to input-output operations as such. This configuration is expected to be at least ten times faster than previous systems...|$|E
40|$|Design space {{exploration}} of multiprocessors on chip requires both automatic performance analysis tech-niques and efficient multiprocessors configuration per-formance evaluation. Prohibitive simulation time of single <b>multiprocessor</b> <b>configuration</b> makes large design {{space exploration}} impossible without massive use of computing resources and still implementation {{issues are not}} tackled. This paper proposes a new perfor-mance evaluation methodology for multiprocessors on chip which conduct a multiobjective design space ex-ploration through emulation. The proposed approach is validated on a 4 way multiprocessor on chip design space exploration where a 6 order of magnitude im-provement have been achieved over cycle accurate sim-ulation. 1...|$|E
50|$|In {{centralized}} control, all {{control equipment}} is replaced a central processing unit. It {{must be able}} to process 10 to 100 calls per second, depending on the load to the system. <b>Multiprocessor</b> <b>configurations</b> are commonplace and may operate in various modes, such as in load-sharing configuration, in synchronous duplex-mode, or one processor may be in stand-by mode.|$|R
50|$|All job {{programs}} run in S/360 problem state, may {{run with}} virtual addressing enabled or disabled, and {{may or may}} not be reentrant (more than one instance of the job program {{may or may not}} be allowed to execute). With <b>multiprocessor</b> <b>configurations</b> a single job will only execute on a single processor at a time, but the supervisor may assign a job to different processors at different times.|$|R
40|$|Abstract: As {{a general}} rule, most {{performance}} analysts are confident in fundamental relationships like one plus one equals two. Unfortunately, this time proven relationship is a gross over {{estimation of the}} actual capacity delivered by a dual or <b>multiprocessor</b> <b>configurations.</b> In this paper, we will present a simple conceptual model of multiprocessor performance and provide a generalized first order result for evaluating the capabilities of alternative multiprocessor designs. ...|$|R
40|$|The BlueGene/L {{supercomputer}} {{has been}} designed {{with a focus on}} power/performance efficiency to achieve high application performance under the thermal constraints of common data centers. To achieve this goal, emphasis was put on system solutions to engineer a power-efficient system. To exploit thread level parallelism, the BlueGene/L system can scale to 64 racks with a total of 65536 computer nodes consisting of a single compute ASIC integrating all system functions with two industry-standard PowerPC microprocessor cores in a chip <b>multiprocessor</b> <b>configuration.</b> Each PowerPC processor exploits data-level parallelism with a highperformance SIMD floating point unit. To support good application scaling [...] ...|$|E
40|$|This thesis {{describes}} the detailed {{design of a}} distributed operating system for a real-time, microcomputer based multiprocessor system. Process structuring and segmented address spaces comprise the central concepts around which this system is built. The system particularly supports applications where processing is partitioned into a set of multiple processes. One such area is that of digital signal processing for which this system has been specifically developed. The operating system is hierarchically structured to logically distribute its functions in each process. This and loop-free properties of the design allow for the physical distribution of system code and data amongst the microcomputers. In a <b>multiprocessor</b> <b>configuration,</b> this physical distribution minimizes system bus contention and lays the foundation for dynamic reconfiguration. (Author) [URL]...|$|E
40|$|Banking {{operations}} {{often require}} complex facilities for their data processing. This application required a <b>multiprocessor</b> <b>configuration</b> {{controlled by a}} single job step running continuously for many hours a day. Discussed are the special access methods and recovery procedures designed for this environment. The paper also describes a particularly eficient sorting technique evolved for handling large volumes of paper documents. Design features of a real-time check-clearing system by J. A. Banham and P. McClelland The transactions involved in {{the operations of the}} banking in-dustry often require the use of data processing facilities {{in a manner that is}} different from that of other industries. A large volume of documents must be processed. Many data entries are made, and the data must be processed quickly to provide a short turnaround time. The check-clearing operation is typical of th...|$|E
30|$|Following {{the design}} flow, {{a number of}} <b>multiprocessor</b> <b>configurations</b> can be created and {{programmed}} easily using our CubeGen framework. In this section, we will evaluate {{the performance of a}} novel FPGA implementation of the recognition approach-based task parallelism. The pipeline design described above was simulated and implemented targeting Xilinx FPGA. Furthermore, we present a number of experiments in which we show the FPGA synthesis results and the execution times of the image processing algorithm.|$|R
50|$|Early {{editions of}} MVS (mid-1970s) {{were among the}} first of the IBM OS series to support <b>multiprocessor</b> <b>configurations,</b> though the M65MP variant of OS/360 running on 360 Models 65 and 67 had {{provided}} limited multiprocessor support. The 360 Model 67 had also hosted the multiprocessor capable TSS/360, MTS and CP-67 operating systems. Because multiprocessing systems can execute instructions simultaneously, they offer greater processing power than single-processing system. As a result, MVS was able to address the business problems brought on by the need to process large amounts of data.|$|R
50|$|The {{criteria}} of a real-time {{can be classified}} as hard, firm or soft. The scheduler set the algorithms for executing tasks according to a specified order. There are multiple mathematical models to represent a scheduling System, most implementations of real-time scheduling algorithm are modeled {{for the implementation of}} uniprocessors or <b>multiprocessors</b> <b>configurations.</b> The more challenging scheduling algorithm is found in multiprocessors, it is not always feasible to implement a uniprocessor scheduling algorithm in a multiprocessor. The algorithms used in scheduling analysis “can be classified as pre-emptive or non-pre-emptive".|$|R
40|$|This paper {{presents}} the performance {{evaluation of a}} new technique for radiosity computation which aims at exploiting efficiently the different levels of a memory hierarchy of both sequential and parallel computers. Such ability is essential when dealing with complex environments having several millions of polygons. The principle of our technique is to split the initial environment into several sub-environments and compute the radiosity within each sub-environment. Exchange of energy between sub-environments is performed by means of virtual interfaces and visibility masks. The size of sub-environments can be adapted in order {{to fit into a}} cache or a local memory. We performed several experiments using an SGI Origin 2000 to show the effectiveness of our solution. It improves both the sequential and parallel execution of a progressive radiosity algorithm. Our technique decreases the execution time on one processor of an SGI Origin 2000 by a factor of more than 5 and leads to a very good efficiency for complex environments (1 million of polygons) on a <b>multiprocessor</b> <b>configuration...</b>|$|E
40|$|As {{microprocessors}} scale {{rapidly in}} frequency, {{the design of}} fast and efficient interconnects becomes extremely important for low latency data access and high performance. Furthermore, in a <b>multiprocessor</b> <b>configuration,</b> {{the width of the}} shared interconnect can pose a significant hurdle in terms of design complexity, cost, and achievable interconnect frequency. In this paper, we evaluate a technique for reducing the interconnect width by exploiting the spatial and temporal locality in communication transfers (addresses & data). The width reduction implies a number of other advantages including higher operating frequency, reduced pin-count, lower chip & board cost, etc. We evaluate the effectiveness of the proposed scheme by performing trace-driven simulations for two well-known commercial server workloads (SPECweb 99 and TPC-C). We also study the sensitivity of the compression hit ratio with respect to the number of bits compressed, size of the encoding/decoding table used and the replacement policy. The results indicate that the proposed technique has a potential to reduce address bus width in most cases and data bus widths in some cases while maintaining equal or better performance than in the uncompressed case...|$|E
40|$|Bioinformatics {{is among}} the most active {{research}} areas in computer science. In this study, we investigate a suite of workloads in bioinformatics on two multiprocessor systems with different configurations, and examine the effects of the configurations on the performance of the workloads. Our result indicates that the configurations of the multiprocessor systems have significant impact on the performance and scalability of the workloads. For example, a number of workloads have significantly higher scalability on one of the systems, but poorer absolute performance than on the other system. However, traditional scalability failed to capture the impacts of the system configurations on the workloads. We present insights on what kinds of workloads will run faster on which systems and propose new metrics to capture the impacts of multiple processor configurations on the workloads. These findings not only provide an easy way to compare results running on different systems, but also enable re-configuration of the underlying systems to run specific workloads efficiently. We also show how processor mapping and loop spreading may help map the workoads to the underlining <b>multiprocessor</b> <b>configuration</b> and achieve consistent scalability for these workloads. ...|$|E
40|$|A {{real-time}} multiprocessor {{programming language}} (RTMPL) {{has been developed}} to provide for high-order programming of real-time simulations on systems of distributed computers. RTMPL is a structured, engineering-oriented language. The RTMPL utility supports a variety of <b>multiprocessor</b> <b>configurations</b> and types by generating assembly language programs according to user-specified targeting information. Many programming functions are assumed by the utility (e. g., data transfer and scaling) to reduce the programming chore. This manual describes RTMPL from a user's viewpoint. Source generation, applications, utility operation, and utility output are detailed. An example simulation is generated to illustrate many RTMPL features...|$|R
40|$|The use of <b>multiprocessor</b> <b>configurations</b> over uniprocessor {{is rapidly}} {{increasing}} to exploit parallelism instead of frequency scaling for better compute capacity. The multiprocessor architectures being developed {{will have a}} major impact on existing software. Current languages provide facilities for concurrent and distributed programming, but are prone to races and non-determinism. SHIM, a deterministic concurrent language, guarantees the behavior of its programs are independent of the scheduling of concurrent operations. The language currently supports atomic arrays only, i. e., parts of arrays cannot be sent to concurrent processes for evaluation (and edition). In this report, we propose a way to add non-atomic arrays to SHIM and describe the semantics that should be considered while allowing concurrent processes to edit parts of the same array...|$|R
40|$|Previous work on {{scheduling}} dynamic competitive jobs {{is focused}} on <b>multiprocessors</b> <b>configurations.</b> This paper presents a new distributed dynamic scheduling scheme for sporadic real-time jobs with arbitrary precedence relations on arbitrary wide networks. A job is modeled by a Directed Acyclic Graph (DAG). Jobs arrive on any site {{at any time and}} compete for the computational resources of the network. The scheduling algorithm developed in this paper is based upon a new concept of Computing Spheres in order to determine a good neighborhood of sites that may cooperate for the execution of a job if it cannot be guaranteed locally. The salient feature of this new concept is that it allows the algorithm to be performed on arbitrary wide networks since it uses a limited number of sites and communication links. 1...|$|R
40|$|The {{complexity}} of future control systems will require {{large amounts of}} processing power in each individual subsystem. This {{can be achieved by}} using a higher performance processor or by using multiple processors within a single system. Multiple processors on a single bus may saturate the bus so as to reduce the expected performance gain. In order to determine an empirical limit for the number of processors that a VME bus can support, experiments were conducted to find the point at which VME system output was not increased by the addition of more processors. This paper details the results of those tests. Goals of the Test In order to generate some facts ’ about the performance of VME in a <b>multiprocessor</b> <b>configuration,</b> a simple set of tests were conducted. The goals of these tests were to: l Determine the incremental system performance improvement {{as a function of the}} number of CPUs * Determine how much effect different arbitration schemes have on system performance l Determine the system performance at various bus utilization levels Test Hardware Confipuratiorr The test setup hardware was assembled from available components. These are not high performance parts but are representative of the hardware that is used to build embedded systems at Fermilab. The test hardware consisted of: 1 VME Crate with power suppl...|$|E
30|$|These issues {{increase}} {{the demand for}} providing a framework that is able to automatically generate a suitable <b>multiprocessor</b> <b>configuration</b> according to the real-time requirements and the features of a given image processing application. More precisely, {{our goal is to}} develop rapid prototyping tools for image processing applications, using parallel homogeneous architecture, as will be described in the next section. In response to that, we have proposed a new MPSoC approach [1] that aims at raising the abstraction level of the specifications for both software and hardware providing the necessary tools supporting the design from the specification down to the embedded implementation. In addition, our methodology proposes a complete generic architecture from which code can be generated automatically. Furthermore, our new design methodology is able to support parallelization of complete image processing applications using multiple instruction multiple data processors (MIMD). From a sequential application, the proposed graphic programming environment (CubeGen) leads us to generate MPSoC system implementation on an FPGA with the parallelized application implemented onto it only in few hours. To this end, we build a programming environment dedicated to the fast prototyping of embedded vision applications based on parallel algorithmic skeletons. Due to computationally intensive nature of processing algorithms, the corresponding software code for each processing node is also generated automatically using specific skeleton and its associated communication functions that facilitate the conversion from sequential algorithm to a parallel C code. These tools represent an important step towards simplification of application implementation in FPGA platform. Another important advantage is that the proposed FPGA design flow offers great potentials for quickly making several experiments with different MPSoCs and exploring configuration choices during the design process. Therefore, the development time for applications running on these architectures is easier and faster than for hand-designed architecture. Evidently, the use of such approach makes it possible to adjust the architecture by refining of the material architecture where it is needed to efficiently meet the requirements of a given application. This often implies that the software has to be developed {{at the same time the}} hardware architecture is refined to provide a design with enough calculation capacity and flexibility.|$|E
40|$|Graduation date: 1975 This paper {{investigates the}} benefit of various {{parallel}} processing architectures for a Command and Control system for the Royal Thai Air Force. Parallel processing {{has been shown to}} be useful for air defense and air traffic control applications. Its advantages are examined within the constraint imposed by the available resources of a developing nation. Several alternative types of architecture including array parallel processing, pipeline processing, associative processing, multiprocessing, and computer network are examined and summarized. The consideration criteria are based on cost, performance, reliability and flexibility. A system architecture based on a generalized <b>multiprocessor</b> <b>configuration</b> is proposed. This system has a second level of parallelism within each processor by providing a number of independent functional logical and arithmetic units in the processing unit. It is modular in design and hence economical, adaptable, and expandable. Therefore, the basic system cost will be within the financial constraints. To obtain the optimum designed configuration and to find the limitations of the proposed model, the necessary system parameters such as processing units (P), memory modules (M), memory cycle time, rate of memory reference, are introduced. The memory conflicts (queue statistics) average utilization of a memory module (facility statistics), and other statistics parameters are measured by simulation. The relative system cost is evaluated and the system efficiency curve is plotted against the corresponding memory module utilization to determine the optimum operating configuration. To illustrate command and control execution, a typical program which solves N simultaneous non-linear equations in N unknowns by the Newton-Raphson iterative procedure is selected as an example. The algorithm of Ramamoothy and Gonzalez is applied for recognizing the parallel processable tasks of the selected FORTRAN program as the system compiler and recognizer. The connectivity matrices corresponding to the analyzed program are illustrated and the parallel processable task tables are constructed. As an example of second level parallel processing, the necessary PU instructions are proposed and their corresponding execution time are defined. A number of FORTRAN statements related to the selected program are assumed to be executed by one of the processing units (PU) in the system. A set of machine instructions equivalent to those FORTRAN statements are derived and a long hand simulation performed. The time of both concurrent execution and sequential execution are computer and compared. A number of intermediate ratios of concurrent execution time to the corresponding sequential execution time for the simulated program are computed and plotted as a function of the number of executed machine instructions...|$|E
40|$|Rapport de Recherche LIPN n° 2006 - 01 Previous work on {{scheduling}} dynamic competitive jobs {{is focused}} on <b>multiprocessors</b> <b>configurations.</b> This paper presents a new distributed dynamic scheduling scheme for sporadic real-time jobs with arbitrary precedence relations on arbitrary wide networks. A job is modeled by a Directed Acyclic Graph (DAG). Jobs arrive on any site {{at any time and}} compete for the computational resources of the network. The scheduling algorithm developed in this paper is based upon a new concept of Computing Spheres in order to determine a good neighborhood of sites that may cooperate for the execution of a job if it cannot be guaranteed locally. The salient feature of this new concept is that it allows the algorithm to be performed on arbitrary wide networks since it uses a limited number of sites and communication links...|$|R
40|$|An {{innovative}} cache accessing scheme {{based on}} high MRU (most recently used) hit ratio [1] is proposed {{for the design of}} a one-cycle cache in a CMOS implementation of System/ 370. It is shown that with this scheme the cache ac-cess time is reduced by 30 ~ 35 % and the performance is within 4 % of a true one-cycle cache. This cache scheme is proposed to be used in a VLSI System/ 370, which is organ-ized to achieve high performance by taking advantage of the performance and integration level of an advanced CMOS technology with half-micron channel ength [2]. Decisions on the system partition are based on technology limitations, performance considerations and future extendability. Design decisions on various aspects of the cache organization are based on trace simulations for both UP (uniprocessor) and MP (<b>multiprocessor)</b> <b>configurations...</b>|$|R
40|$|Enlarged color {{photograph}} of the Intel® 8086 microprocessor. Chalk the 8086 design up to Intel’s competitive paranoia. ”Because {{of the success of}} Zilog’s 8 -bit processor, we were sure they were cooking up some super processors for 16 bits and beyond,” recalls Peter Stohl, lead engineer on 8086. “We knew we had to beat them to the punch. We were scared and moving fast. ” At the time, Intel wanted to retain backward compatibility with the large installed base of 8 -bit code while providing a much greater address space—a full 1 MB—and faster clock speeds of up to 5 MHz. In spite of difficult circumstances and tools rudimentary by today’s standards, after only two years the 8086 team had produced working silicon. The new processor shipped in 1978 and incorporated many innovative features—it could even run in <b>multiprocessor</b> <b>configurations...</b>|$|R
40|$|This paper extends earlier {{research}} on hash-join algorithms to a multiprocessor architecture. Implementations {{of a number}} of centralized join algorithms are described and measured. Evaluation of these algorithms served to verify earlier analytical results. In addition, they demonstrate that bit vector filtering provides dramatic improvement in the performance of all algorithms including the sort merge join algorithm. <b>Multiprocessor</b> <b>configurations</b> of the centralized Grace and Hybrid hash-join algorithms are also presented. Both algorithms are shown to provide linear increases in throughput with corresponding increases in processor and disk resources. 1. Introduction After the publication of the classic join algorithm paper in 1977 by Blasgen and Eswaran [BLAS 77], the topic was virtually abandoned as a research area. Everybody "knew" that a nested-loops algorithm provided acceptable performance on small relations or large relations when a suitable index existed and that sort-merge was [...] ...|$|R
40|$|This paper {{presents}} a quantitative comparison {{of a collection}} of DSP multiprocessor list scheduling heuristics which consider inter-processor communication delays. The following aspects have been addressed: (1) performance in terms of the total execution time (makespan), (2) sensitivity of heuristics in terms of the characteristics of acyclic precedence graphs, including graph size and graph parallelism, (3) sensitivity of heuristics to the number of processors, and (4) compile time efficiency. In addition, the effectiveness of list scheduling performance enhancement techniques is examined. The main contributions of this paper are: ffl Contrary to the belief of some previous authors, our study indicates that no single published list scheduling heuristic consistently produces the best schedules under all possible program structures and DSP <b>multiprocessor</b> <b>configurations.</b> We believe this fact is very important to designers of DSP multiprocessor scheduling heuristics. ffl Based on such o [...] ...|$|R
40|$|The {{interconnection}} {{network is}} the single most important element of a multiprocessor. Choosing the best interconnection scheme for a given sized multiprocessor is no easy task. This paper presents a two phase analysis to assist in the design of multiprocessor interconnection networks. The two phases of the analysis are analytical, and simulation. The analytical phase introduces a new metric called the network bandwidth requirement, or nbr. This is an estimate for the interconnecting network link speed required for a multiprocessor of a given size. The nbr result is used in the simulation phase of the analysis. Various <b>multiprocessor</b> <b>configurations</b> are simulated using stochastic activity networks to verify the results of the analytical phase. The nbr is shown to be an excellent estimate for the interconnection network link speed required in a multiprocessor. The simulation may also be used to analyze various multiprocessor characteristics...|$|R
40|$|As VLSI {{advances}} towards {{billions of}} fast transistors on a chip (Gigascale Integration, or GSI), {{it is becoming}} clear that interconnect issues will dominate. Conventional uniprocessor architectures, developed {{in an era when}} interconnect was largely ignored, may be incompatible with this technology. This paper presents a quantitative exploration of architectural alternatives for gigascale technology. It evaluates a set of candidate architectures in 100 nm technology that span a spectrum of uniprocessor and <b>multiprocessor</b> <b>configurations.</b> Results show that a system composed of eight six-way superscalar processors provides the best performance over a wide range of applications. Designs that include large complex uniprocessors are limited by wire delay, and fall short of parallel systems when even a small amount of explicit parallelism is available (greater than 10 % of the workload). Similarly, highly parallel designs with many small processors are restricted due to limited parallelism. The [...] ...|$|R
40|$|This {{dissertation}} {{studies the}} design of single bus, shared memory multiprocessors. The purpose of the studies is to find optimum points in the design space for different memory system components that include private caches, shared bus and main memory. Two different methodologies are used based on the operating environment of a multiprocessor. For a multiprocessor operating in the throughput-oriented environment, Customized Mean Value Analysis (CMVA) models are developed to evaluate {{the performance of the}} multiprocessor. The accuracy of the models are validated by comparing their results to those generated by actual trace-driven simulation over several thousand <b>multiprocessor</b> <b>configurations.</b> The comparison results show that the CMVA models can be as accurate as trace driven simulation in predicting the multiprocessor throughput and bus utilization. The validated models are then used to evaluate design choices that include cache size, cache block size, cache set-associativity, bus switch [...] ...|$|R
40|$|To realize high performance, {{embedded}} {{applications are}} deployed on multiprocessor platforms tailored for an application domain. However, when a suitable platform is not available, only few application niches can justify the increasing costs of an IC product design. An {{alternative is to}} design the multiprocessor on an FPGA. This retains the programmability advantage, while obviating the risks in producing silicon. This also opens FPGAs {{to the world of}} software designers. In this paper, we demonstrate the feasibility of FPGA-based multiprocessors for high performance applications. We deploy IPv 4 packet forwarding on a multiprocessor on the Xilinx Virtex-II Pro FPGA. The design achieves a 1. 8 Gbps throughput and loses only 2. 6 X in performance (normalized to area) compared to an implementation on the Intel IXP- 2800 network processor. We also develop a design space exploration framework using Integer Linear Programming to explore <b>multiprocessor</b> <b>configurations</b> for an application. Using this framework, we achieve a more efficient multiprocessor design surpassing the performance of our hand-tuned solution for packet forwarding. 1...|$|R
