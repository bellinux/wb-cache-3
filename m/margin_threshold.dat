2|59|Public
40|$|Abstract. We {{reconsider the}} {{stochastic}} (sub) gradient {{approach to the}} unconstrained primal L 1 -SVM optimization. We observe that if the learning rate is inversely proportional {{to the number of}} steps, i. e., the number of times any training pattern is presented to the algorithm, the update rule may be transformed into the one of the classical perceptron with margin in which the <b>margin</b> <b>threshold</b> increases linearly with the number of steps. Moreover, if we cycle repeatedly through the possibly randomly permuted training set the dual variables defined naturally via the expansion of the weight vector as a linear combination of the patterns on which margin errors were made are shown to obey {{at the end of each}} complete cycle automatically the box constraints arising in dual optimization. This renders the dual Lagrangian a running lower bound on the primal objective tending to it at the optimum and makes available an upper bound on the relative accuracy achieved which provides a meaningful stopping criterion. In addition, we propose a mechanism of presenting the same pattern repeatedly to the algorithm which maintains the above properties. Finally, we give experimental evidence that algorithms constructed along these lines exhibit a considerably improved performance. ...|$|E
40|$|We {{reconsider the}} {{stochastic}} (sub) gradient {{approach to the}} unconstrained primal L 1 -SVM optimization. We observe that if the learning rate is inversely proportional {{to the number of}} steps, i. e., the number of times any training pattern is presented to the algorithm, the update rule may be transformed into the one of the classical perceptron with margin in which the <b>margin</b> <b>threshold</b> increases linearly with the number of steps. Moreover, if we cycle repeatedly through the possibly randomly permuted training set the dual variables defined naturally via the expansion of the weight vector as a linear combination of the patterns on which margin errors were made are shown to obey {{at the end of each}} complete cycle automatically the box constraints arising in dual optimization. This renders the dual Lagrangian a running lower bound on the primal objective tending to it at the optimum and makes available an upper bound on the relative accuracy achieved which provides a meaningful stopping criterion. In addition, we propose a mechanism of presenting the same pattern repeatedly to the algorithm which maintains the above properties. Finally, we give experimental evidence that algorithms constructed along these lines exhibit a considerably improved performance. Comment: In v 2 the numerical results are obtained using the latest release 1. 7 of Cygwin and the g++ compiler version 4. 5. 3. We also consider in the experiments the algorithms SvmSgd and SGD-QN. A slightly shorter version of this paper appeared in ECML/PKDD 201...|$|E
30|$|Thirty-two 18 F-FDG PET-CT scans were acquired. The third PET-CT scan {{of patient}} 10 {{could not be}} {{performed}} due to scheduling difficulties. For patient 1, in scan 3 {{it was not possible}} to draw a VOIauto, since the tumor showed an almost complete metabolic response at this treatment stage and it did not meet the <b>margin</b> <b>thresholds</b> to complete the VOIauto. Since it was possible to define the other three types of VOIs, this scan was included in the analyses and a value of zero was given to the metabolic parameters for the VOIauto. The median time between the HILP and scan 2 was 21 [18 – 21] days, whereas the time between the end of EBRT and scan 3 was 3 (1 – 3) days.|$|R
3000|$|In this {{experiment}} hackers {{were allowed to}} see the users' reference latency vector along with their own pressure template, a GUI window was fixed with two indicator lights [...] "one for latency and one for pressure" [...] that flashes green when either latency or pressure is within the acceptance <b>margin.</b> TSE <b>threshold</b> [...]...|$|R
30|$|The MP device {{provides}} real-time intraoperative {{assessment of}} microscopic lumpectomy margins. Published reports {{on use of}} the device have so far been in the settings of clinical studies. In this retrospective case review, we provided the first report on routine use of the device in the USA. The device integrated very well with the workflow in the operating room, taking no more than 5  minutes to use. There were no adverse events associated with device use. Adjunctive use of the device significantly decreases, when compared to corresponding historical series, by 62 % the rate of patients who required re-excision procedures. The <b>margin</b> <b>thresholds</b> for returning a patient {{to the operating room}} were not standardized between surgeons. Still, this relative reduction was similar irrespective of the nominal rates per surgeon. With use of the device, the rate of re-excision procedures was 9.7 %.|$|R
40|$|Abstract: We {{consider}} multi-wavelet thresholding {{method for}} nonparametric estimation. An adaptive procedure {{based on a}} convex combination of weighted term-by-term thresholded wavelet estimators is proposed. By considering the density estimation framework, we prove that it is optimal in the minimax sense over Besov balls under the L 2 risk, without any extra logarithm term. Key words and phrases: aggregation, oracle inequalities, <b>margin,</b> wavelets, <b>threshold</b> estimators, density estimatio...|$|R
30|$|In {{search of}} a uniform and {{reproducible}} way to calculate changes in metabolic tumor activity in these upfront highly heterogeneous tumors, the use of four different VOI delineation techniques was studied. The VOIman (defined as reference VOI) is the only delineation technique in which the entire tumor is encompassed independently {{of the amount of}} necrosis present in the tumor. Therefore, the VOIman delineation technique seems to be most reliable when used for calculating the metabolic tumor activity. However, the VOIman delineation technique is time-consuming, making it unfit for implementation into daily practice. A high correlation, acceptable level of agreement, and comparable ranking was found between the VOIman and the VOIgrad+ delineation techniques. The differences in ranking between the four VOI delineation techniques are best explained by the high amount of necrosis present in these tumors, as tumor necrosis did not meet the <b>margin</b> <b>thresholds</b> of the VOIauto and VOIgrad. To obtain the VOIgrad+, the necrosis was manually included, and therefore, the ranking of patients was comparable to the ranking according to the VOIman.|$|R
40|$|In {{this paper}} we discuss the issue of {{computation}} of the bilateral credit valuation adjustment (CVA) under rating triggers, and in presence of ratings-linked margin agree-ments. Specifically, we consider collateralized OTC contracts, that are subject to rating triggers, between two parties – an investor and a counterparty. Moreover, we model the margin process as a functional of the credit ratings of the counterparty and the investor. We employ a Markovian approach for modeling of the rating transitions of the two parties to the contract. In this framework, we derive the representation for bilateral CVA. We also introduce a new component in the decomposition of the coun-terparty risky price: namely the rating valuation adjustment (RVA) that accounts for the rating triggers. We give two examples of dynamic collateralization schemes where the <b>margin</b> <b>thresholds</b> {{are linked to the}} credit ratings of the parties. We account for the rehypothecation risk in the presence of independent amounts. Our results are il-lustrated via computation of various counterparty risk adjustments for a CDS contract and for an IRS contract...|$|R
40|$|In {{familiarize}} thresholds {{literary criticism}} {{deals with the}} text as building his entrances and goings out that form the framework ocean, concept of threshold known in the Arab-Islamic culture in the French Western culture, namely the text equivalent of the original text is known only by and through him, and I knew study (platforms) by Jeanette study him in his quest for poetic and I ate before him and he Attoerha talking about scripts {{and their impact on}} the literary text production Almtaagliat, and afternoon term (the title) in the Arab and Western literature is not as one of the platforms only, but is parallel to the term (thresholds) and (platforms), which in its entirety is linked to a correlation entirely by stating and crossing it, and I have numerous job sites or platforms for the purposes of Taanah and descriptive and suggestive and erotic, and I have studied the surrounding text Altoleva in the context of applied studies in the book of miracle signs and found the most important Maver (the author's name, title, start-up, <b>margins)</b> <b>threshold.</b> ...|$|R
40|$|We give a new {{algorithm}} {{for learning}} intersections of halfspaces with a margin, i. e. {{under the assumption}} that no example lies too close to any separating hyperplane. Our algorithm combines random projection techniques for dimensionality reduction, polynomial threshold function constructions, and kernel methods. The algorithm is fast and simple. It learns a broader class of functions and achieves an exponential runtime improvement compared with previous work on learning intersections of halfspaces with a margin. Key words: computational learning theory, intersections of halfspaces, <b>margin,</b> polynomial <b>threshold</b> function, random projection, kernel Perceptron. ∗ Corresponding author...|$|R
40|$|An {{algorithm}} {{for learning}} fast multiclass object detection cascades is introduced. It produces multi-resolution (MRes) cascades, whose early stages are binary target vs. non-target detectors that eliminate false positives, late stages multiclass clas-sifiers that finely discriminate target classes, and middle stages have intermediate numbers of classes, determined in a data-driven manner. This MRes structure is achieved {{with a new}} structurally biased boosting algorithm (SBBoost). SBBost extends previous multiclass boosting approaches, whose boosting mechanisms are shown to implement two complementary data-driven biases: 1) the standard bias towards examples difficult to classify, and 2) a bias towards difficult classes. It is shown that structural biases can be implemented by generalizing this class-based bias, so as to encourage the desired MRes structure. This is accomplished through a generalized definition of multiclass margin, which includes a set of bias pa-rameters. SBBoost is a boosting algorithm for maximization of this margin. It can also be interpreted as standard multiclass boosting algorithm augmented with <b>margin</b> <b>thresholds</b> or a cost-sensitive boosting algorithm with costs defined by the bias parameters. A stage adaptive bias policy is then introduced to determine bias parameters in a data driven manner. This is shown to produce MRes cascades that have high detection rate and are computationally efficient. Experiments on multiclass object detection show improved performance over previous solutions. ...|$|R
40|$|In {{this paper}} we {{describe}} an orbit design aide tool, called Telecom Orbit Analysis and Simulation Tool(TOAST). Although {{it can be}} used for studying and selecting orbits for any planet, we solely concentrate on its use for Mars. By specifying the six orbital elements for an orbit, a time frame of interest, a horizon mask angle, and some telecom parameters such as the transmitting power, frequency, antenna gains, antenna losses, link <b>margin,</b> received <b>threshold</b> powers for the rates, etc. this tool enables the user to view the animation of the orbit in two and three-dimensional different telecom metrics at any point on the Mars, namely the global planetary map...|$|R
40|$|We {{demonstrate}} polarization-independent simultaneous all-optical phase-preserving amplitude regeneration and wavelength {{conversion of}} NRZ {{differential phase shift}} keying (DPSK) data by four-wave mixing (FWM) in a semiconductor optical amplifier (SOA). The dependence upon polarization state of the signals is eliminated by using a co-polarized dual-pump architecture. Investigation on the regenerative capability vs. pumps detuning shows significant BER <b>threshold</b> <b>margin</b> improvement over 6 nm conversion range...|$|R
3000|$|... can {{be carried}} out by a band manager that mediates between the primary and {{secondary}} users [33]. The channel magnitude of the downlink path (PBS to SU) in not equal to the reverse channel magnitude (SU to PBS) if FDD is used. However, this downlink channel magnitude {{can be used as a}} rough estimate of the uplink channel magnitude. In this case it will be necessary to add some <b>margin</b> on the <b>threshold</b> [...]...|$|R
40|$|We {{studied the}} {{degradation}} of poly-Si CMOS inverters under high frequency operation. Increased low noise <b>margin</b> and logic <b>threshold</b> voltage, decreased high noise margin and gain were observed. Based on a previous drain current model of thin-film transistors (TFTs), voltage transfer characteristic of inverter is well described. Large degradation was observed in p-TFT instead of n-TFT after 10 ks operation. Dynamic negative bias temperature instability {{is considered to be}} the degradation mechanism leading to the inverter's degradation. © 2011 IEEE...|$|R
40|$|The NOAA 8 SARSAT system {{performance}} was tested at 121. 5 / 243 MHz to measure detection probability, detection threshold, location accuracy, ambiguity resolution, and multiple access capacity. Detection probability exceeds 0. 95 {{for a single}} satellite pass. Detection <b>threshold</b> <b>margin</b> varies from 2 dB (243 MHz, incoherent) to 20 dB (121. 5, coherent). Position location error is 20 km 68 % of the time. Ambiguity is resolved 75 % of the time. The system can locate 10 separate test signals...|$|R
40|$|Abstract: This study {{analyzes}} the geographic spread of commercial Internet Service Providers (ISPs), the leading suppliers of Internet access. The geographic spread of ISPs {{is a key}} consideration in U. S. policy for universal access. We examine the Fall of 1998, a time of minimal government subsidy, when inexpensive access was synonymous with a local telephone call to an ISP. Population size and location in a metropolitan statistical area were {{the single most important}} determinants of entry, but their effects on national, regional and local firms differed, especially on the <b>margin.</b> The <b>thresholds</b> for entry were remarkably low for local firms. Universal service in less densely-populated areas was largely a function of investment decisions by ISPs with local focus. There was little trace of the early imprint of government subsidies for Internet access at major U. S. universities...|$|R
40|$|This study {{analyzes}} the geographic spread of commercial Internet Service Providers (ISPs), the leading suppliers of Internet access. The geographic spread of ISPs {{is a key}} consideration in U. S. policy for universal access. We examine the Fall of 1998, a time of minimal government subsidy, when inexpensive access was synonymous with a local telephone call to an ISP. Population size and location in a metropolitan statistical area were {{the single most important}} determinants of entry, but their effects on national, regional and local firms differed, especially on the <b>margin.</b> The <b>thresholds</b> for entry were remarkably low for local firms. Universal service in less densely-populated areas was largely a function of investment decisions by ISPs with local focus. There was little trace of the early imprint of government subsidies for Internet access at major U. S. universities. Internet; Universal service; Geographic diffusion; Telecommunications...|$|R
40|$|Janet G Bauer, 1 Sue S Spackman, 2 Robert Fritz, 2 Amanjyot K Bains, 3 Jeanette Jetton-Rangel 3 1 Advanced Education Services, 2 Division of General Dentistry, 3 Center of Dental Research, Loma Linda University School of Dentistry, Loma Linda, CA, USA Introduction: Best {{estimates}} of intervention outcomes are used when uncertainties {{in decision making}} are evidenced. Best estimates are often, out of necessity, from a context of less than quality evidence or needing more evidence to provide accuracy. Purpose: The {{purpose of this article}} is to understand the best estimate behavior, so that clinicians and patients may have confidence in its quantification and validation. Methods: To discover best estimates and quantify uncertainty, critical appraisals of the literature, gray literature and its resources, or both are accomplished. Best {{estimates of}} pairwise comparisons are calculated using meta-analytic methods; multiple comparisons use network meta-analysis. Manufacturers provide margins of performance of proprietary material(s). Lower <b>margin</b> performance <b>thresholds</b> or requirements (functional failure) of materials are determined by a distribution of tests to quantify performance or clinical competency. The same is done for the high <b>margin</b> performance <b>thresholds</b> (estimated true value of success) and clinician-derived critical values (material failure to function clinically). This quantification of margins and uncertainties assists clinicians in determining if reported best estimates are progressing toward true value as new knowledge is reported. Analysis: The best estimate of outcomes focuses on evidence-centered care. In stochastic environments, we are not able to observe all events in all situations to know without uncertainty the best estimates of predictable outcomes. Point-in-time analyses of best estimates using quantification of margins and uncertainties do this. Conclusion: While study design and methodology are variables known to validate the quality of evidence from which best estimates are acquired, missing are tolerance margins, or upper and lower performance requirements and clinician critical values, within which best estimates behave and are validated. Understanding the best estimate behavior toward true value may provide clinicians and patients confidence in decision making under uncertainty. Keywords: metric, outcomes, quantification of margins and uncertainties, true value, performance margin...|$|R
40|$|A {{compact device}} with a {{two-level}} transfer function (TF) implemented with two semiconductor optical amplifier (SOA) -based stages is proposed and characterized. Each stage exploits nonlinear polarization rotation and self-phase modulation. The obtained improved TF with very flat {{top and bottom}} levels makes the scheme suitable for working as a reshaper in all-optical regeneration. The effectiveness of the device is verified in regenerating both nonreturn-to-zero (NRZ) and return-to-zero (RZ) data signals up to 40 Gb/s. Bit error rate measurements demonstrate increased <b>threshold</b> <b>margin</b> and extinction ratio improvement...|$|R
40|$|Abstract—The {{conventional}} flip-flop core is {{generalized to}} mul-tistability in full static CMOS without compromising the standard binary CMOS {{features such as}} ratioless device sizing, negligible static power consumption, and wide noise margins. The proposed multiple-level cell is built with eight devices for three-level opera-tion and necessitates four more devices for each additional level. It can be arranged with a proper address scheme {{to function as a}} RAM cell, D-latch, or synaptic memory. Experimental work veri-fies four-level operation with 3 -V supply. Simulations indicate the possibility of six-level storage in 5 -V operation. The cell retains noise <b>margins</b> one <b>threshold</b> voltage wide even at such high-level operation. This is made possible by exploiting the dynamic hys-teresis associated with the transfer characteristic of an inverter op-erating with very low rail-to-rail voltage. Index Terms—CMOS memory integrated circuits, flip-flops, hysteresis, multivalued logic circuits, network hardware, random access memories. I...|$|R
40|$|This thesis {{provides}} a comparative textual, aesthetic, and thematic analysis of self-representation in {{a selection of}} films and installations produced in France by three film-makers whose backgrounds and approach to the subject varies: the installation artist, Sophie Calle, the experimental film-maker, Vincent Dieutre, and the documentary film-maker, Marianne Otero. It examines ways in which their films and installations are characterised by certain recurring themes and aesthetic strategies despite their apparent differences. The first chapter contrasts the traditions of literary and pictorial selfrepresentation (autobiography, diary, self-portrait, and essay) with the blurring of such distinct categories in cinema and the visual arts. In the following chapters, a comparative analysis between the three artists points to a recurring representation of a questioning, split, and scattered Self. As a result, a sense of constant in-between-ness emerges, and the protagonists’ systematic spatial dislocations are not merely geographic and physical but also temporal and mental. The aesthetic constructions aptly reflect their interrogation about {{their place in the}} world in that the cinematic balance between motion and stillness aptly underscores the fundamental paradox of simultaneous permanence and change, which characterises identity. The abstraction associated with figurations of loss and absence contrasts with a sense of nowness, which is reinforced by the prominence of the body on screen, which harks back to more concrete issues and calls for a reflection on theories of affect, the Figural, sensation. Most importantly, the bodies’ physicality draws attention to the plasticity of the medium, {{and the fact that the}} body on screen is also that of the artist is especially effective. Self-representation is a mise en abyme par excellence and cannot be envisaged outside the film-makers’ aesthetic reflection upon their practice for their modes of self-representation rely heavily on the specificity of the medium used. Finally, it draws on recurrent patterns, which simultaneously reflect the rituals of self-representation and the cinematic process: passage, repetition, and transformation, through figures of intermediality, re-enactment, or intertextuality. Yet, equally important are figurations of the place and limits of the Self in relation to the outer space of the Other; hence the significance of <b>margins,</b> <b>thresholds,</b> liminality, in which the question of gender is also central...|$|R
60|$|Beside {{the city}} where Media dwelt, there were few other {{clusters}} of habitations in Odo. The higher classes living, here and there, in separate households; but not as eremites. Some buried themselves in the cool, quivering bosoms of the groves. Others, fancying a marine vicinity, dwelt hard by the beach in little cages of bamboo; whence of mornings they sallied out with jocund cries, and went plunging into the refreshing bath, whose frothy <b>margin</b> was the <b>threshold</b> of their dwellings. Others still, like birds, built their nests among the sylvan nooks of the elevated interior; whence all below, and hazy green, lay steeped in languor the island's throbbing heart.|$|R
40|$|In {{this article}} we {{describe}} how reimbursement cost-effectiveness thresholds, per unit of health benefit, whether set explicitly or observed implicitly via historical reimbursement decisions, serve as a signal to firms about the commercial viability of their R&D projects (including candidate products for in-licensing). Traditional finance methods for R&D project valuations, such as net present value analyses (NPV), incorporate information from these payer reimbursement signals to help determine which R&D projects should be continued and which projects should be terminated (in {{the case of the}} latter because they yield an NPV < 0). Because the influence these signals have for firm R&D investment decisions is so significant, we argue it is important that reimbursement thresholds reflect the economic value of the unit of health benefit being considered for reimbursement. Thresholds set too low (below the economic value of the health benefit) will result in R&D investment levels that too low relative to the economic value of R&D (on the <b>margin).</b> Similarly, <b>thresholds</b> set too high (above the economic value of the health benefit) will result in inefficiently high levels of R&D spending. The U. S. in particular...|$|R
40|$|We {{consider}} a game between two capacity providers that compete for customers through a broker {{who works on}} commissions and sells to both loyal and non-loyal customers. The capacity providers compete by selecting commission <b>margins</b> and sales <b>thresholds</b> at which commissions on all sales increase. We show that in equilibrium, contracts require positive sales thresholds. The threshold requirement can be best described as a mechanism for one provider to profit {{at the expense of}} the other. For exogenous commission margins, we show that it is the provider with the lower margin who benefits from thresholds {{at the expense of the}} broker. However, the gains for the lower margin provider can be a mirage in full equilibrium, where commission margins are endogenous...|$|R
40|$|Abstract Background When {{comparing}} active treatments, a non-inferiority (or one-sided equivalence) {{study design}} is often used. This design requires {{the definition of}} a non-inferiority <b>margin,</b> the <b>threshold</b> value of clinical relevance. In recent studies, a non-inferiority margin of 15 mm has been used for the change in endometriosis-associated pelvic pain (EAPP) on a visual analog scale (VAS). However, this value was derived from other chronic painful conditions and its validation in EAPP was lacking. Methods Data were analyzed from two placebo-controlled studies of active treatments in endometriosis, including 281 patients with laparoscopically-confirmed endometriosis and moderate-to-severe EAPP. Patients recorded EAPP on a VAS at baseline and the end of treatment. Patients also assessed their satisfaction with treatment on a modified Clinical Global Impression scale. Changes in VAS score were compared with patients' self-assessments to derive an empirically validated non-inferiority margin. This anchor-based value was compared to a non-inferiority margin derived using the conventional half standard deviation rule for minimal clinically important difference (MCID) in patient-reported outcomes. Results Anchor-based and distribution-based MCIDs were- 7. 8 mm and- 8. 6 mm, respectively. Conclusions An empirically validated non-inferiority margin of 10 mm for EAPP measured on a VAS is appropriate to compare treatments in endometriosis. </p...|$|R
40|$|Intraoperative {{assessment}} of surgical margins {{is critical to}} ensuring residual tumor does not remain in a patient. Previously, we developed a fluorescence structured illumination microscope (SIM) system with a single-shot field of view (FOV) of 2. 1 × 1. 6 mm (3. 4 mm 2) and sub-cellular resolution (4. 4 μm). The goal {{of this study was}} to test the utility of this technology for the detection of residual disease in a genetically engineered mouse model of sarcoma. Primary soft tissue sarcomas were generated in the hindlimb and after the tumor was surgically removed, the relevant margin was stained with acridine orange (AO), a vital stain that brightly stains cell nuclei and fibrous tissues. The tissues were imaged with the SIM system with the primary goal of visualizing fluorescent features from tumor nuclei. Given the heterogeneity of the background tissue (presence of adipose tissue and muscle), an algorithm known as maximally stable extremal regions (MSER) was optimized and applied to the images to specifically segment nuclear features. A logistic regression model was used to classify a tissue site as positive or negative by calculating area fraction and shape of the segmented features that were present and the resulting receiver operator curve (ROC) was generated by varying the probability threshold. Based on the ROC curves, the model was able to classify tumor and normal tissue with 77 % sensitivity and 81 % specificity (Youden's index). For an unbiased measure of the model performance, it was applied to a separate validation dataset that resulted in 73 % sensitivity and 80 % specificity. When this approach was applied to representative whole margins, for a tumor probability threshold of 50 %, only 1. 2 % of all regions from the negative <b>margin</b> exceeded this <b>threshold,</b> while over 14. 8 % of all regions from the positive <b>margin</b> exceeded this <b>threshold...</b>|$|R
40|$|We {{report on}} the {{influence}} of different types of radiation on the nitride read-only memories (NROM). The memory cells were irradiated by light ions (Boron), X-rays and c-rays. Memory transistor parameters, such as threshold voltage and subthreshold drain leakage were studied {{as a function of the}} accumulated radiation dose and compared to the as-programmed (-erased) devices parameters. Their time evolution was registered in the range from few hours up to 5 months after the irradiation. The NROM cells showed good radiation robustness up to high accumulated doses. Sufficient program <b>margin</b> (difference of <b>threshold</b> voltage in the programmed state and the read-out voltage level) remained after c or X irradiation for absorbed doses exceeding 50 krad(Si) and 100 krad(Si), respectively. For Boron irradiation, the programmed devices remained stable up to the fluence of 1011 ions/cm 2 (equivalent to 1 Mrad(Si) of TID toleranc...|$|R
40|$|We {{investigate}} and experimentally demonstrate a simple method for phase-preserving amplitude regeneration of constant envelope phase-coded signals. This scheme exploits nonlinear interaction between noisy data and a continuous wave beam {{at a different}} wavelength in a saturated semiconductor optical amplifier (SOA). We show that proper balancing of the input signals' power allows us to exploit the amplitude limiting effect of SOA saturated gain without introducing significant excess phase noise due to suppression of the α-factor in the amplifier. In a 10 -Gb/s nonreturn-to-zero differential phase-shift-keying experiment, both four-wave-mixing (FWM) and pass-through signals are remarkably improved with respect to input data in terms of Q-factor and bit error ratio <b>threshold</b> <b>margin,</b> demonstrating wavelength preserving and wavelength converting regeneration. In particular, the FWM signal exhibits better regenerative performance over {{a broader range of}} degraded input data and for lower input overall power levels...|$|R
5000|$|QMU has the {{potential}} to support improved decision-making for programs that must rely heavily on modeling and simulation. Modeling and simulation results are being used more often during the acquisition, development, design, and testing of complex engineering systems. [...] One of the major challenges of developing simulations is to know how much fidelity should be built into each element of the model. The pursuit of higher fidelity can significantly increase development time and total cost of the simulation development effort. QMU provides a formal method for describing the required fidelity relative to the design <b>threshold</b> <b>margins</b> for key performance variables. This information {{can also be used to}} prioritize areas of future investment for the simulation. Analysis of the various M/U ratios for the key performance variables can help identify model components that are in need of fidelity upgrades to order to increase simulation effectiveness.|$|R
40|$|A {{review of}} recent {{work on the}} effect of threshold-voltage {{instability}} on the reliability of SiC power MOSFETs is presented. Significant increases in the instability of the ID-VGS characteristics due to ON-state current stressing are similar in nature to increases caused by high-temperature bias stressing. Devices stressed by elevated temperature alone exhibited very little instability compared with devices stressed with both temperature and applied bias. These results, along with other results in the literature, suggest that this increase in threshold voltage instability at elevated temperature is due to the activation of additional near-interfacial gate oxide traps related to an O-vacancy defect known as an E′ center. It is important to develop improved processing methods to decrease the number of precursor oxide defect sites, since an increased negative shift can give rise to increased leakage current in the OFF-state and potential device failure if proper precautions are not met to provide an adequate <b>margin</b> for the <b>threshold</b> voltage...|$|R
40|$|The aim of {{this study}} is {{introducing}} an online intelligent method for bidding negotiations in e-marketing. The growth and popularity of internet, increases using of modern techniques to help costumers and sellers in choosing best product and achieve higher benefit. Recommender systems as useful mean have memorable role in permanency customer loyalty. In traditional trade, customer and seller negotiate face to face. But now in online trade, it has changed to negotiation through internet and recommender systems. As a result, paying attention to preferences of both customer and seller in online structure is needed. In this study, we propose a method for making a recommender system for both seller and customer such that the satisfaction level of both be more than a <b>threshold</b> <b>margin.</b> First the needs and preferences of seller and customer are determined and then through the proposed algorithm successive suggestions are made until achieving a point that both sides of the business feel satisfaction...|$|R
40|$|We propose two transductive bounds on {{the risk}} of {{majority}} votes that are estimated over partially labeled training sets. The first one involves the margin distribution of the classifier and a risk bound on its associate Gibbs classifier. The bound is tight when so is the Gibbs’s bound and when the errors of the majority vote classifier is concentrated on a zone of low margin. In semi-supervised learning, considering the margin {{as an indicator of}} confidence constitutes the working hypothesis of algorithms which search the decision boundary on low density regions. Following this assumption, we propose to bound the error probability of the voted classifier on the examples for whose margins are above a fixed threshold. As an application, we propose a self-learning algorithm which iteratively assigns pseudo-labels to the set of unlabeled training examples that have their <b>margin</b> above a <b>threshold</b> obtained from this bound. Empirical results on different datasets show the effectiveness of our approach compared to the same algorithm and the TSVM in which the threshold is fixed manually. ...|$|R
40|$|International audienceIn {{this paper}} we present two transductive bounds on {{the risk of}} the {{majority}} vote estimated over partially labeled training sets. Our first bound is tight when the additional unlabeled training data are used in the cases where the voted classifier makes its errors on low margin observations and where the errors of the associated Gibbs classifier can accurately be estimated. In semi-supervised learning, considering the margin as an indicator of confidence constitutes the working hypothesis of algorithms which search the decision boundary on low density regions. In this case, we propose a second bound on the joint probability that the voted classifier makes an error over an example having its margin over a fixed threshold. As an application we are interested on self-learning algorithms which assign iteratively pseudo-labels to unlabeled training examples having <b>margin</b> above a <b>threshold</b> obtained from this bound. Empirical results on different datasets show the effectiveness of our approach compared to the same algorithm and the TSVM in which the threshold is fixed manually...|$|R
40|$|We {{consider}} a two-stage decision problem, {{in which an}} online retailer first makes optimal decisions on his profit <b>margin</b> and free-shipping <b>threshold,</b> and then determines his inventory level. We start by developing the retailer’s expected profit function. Then, we use publicly-available statistics to find the best-fitting distribution for consumers’ purchase amounts and the best-fitting function for conversion rate (i. e., probability that an arriving visitor places an online order with the retailer). We show that: (i) a reduction of the profit margin does not significantly affect the standard deviation of consumers’ order sizes (purchase amounts) but increases the average order size; whereas, (ii) variations in a positive finite free-shipping threshold affect both the average value and the standard deviation of the order sizes. We then use Arena to simulate the online retailing system and OptQuest to find the retailer’s optimal decisions and maximum profit. Next, we perform a sensitivity analysis to {{examine the impact of}} the ratio of the unit holding and salvage cost to the unit shipping cost on the retailer’s optimal decisions. We also draw some important managerial insights...|$|R
40|$|Corneal touch {{threshold}} (CTT) {{was investigated}} by aesthesiometry {{in patients with}} keratoconusq with and without contact lens wear. Using a matching control group it was established that CTT was significantly higher for the central corneal position in keratoconus. No difference inCTT was found in four peripheral corneal positions in keratoconic and normal corneas. Central CTT correlated inversely with central corneal curvature and central corneal thickness. Central corneal curvature was the most significant single factor to correlate with central CTT and indicates that CTT increases (sensitivity reduces) as the cornea steepens. Corneal surface irregularityq as measured by mire image distortion, correlated positively with central CTT as did corneal scarring. Central CTT did not show a relationship with duration of the disease nor the visibility of the corneal nerve fibres. Lid <b>margin</b> touch <b>thresholds</b> (LTT) were investigated for the central position on the lower and upper eyelid margins. No statistical {{differences were found between}} keratoconic and normal eyes nor between upper and lower eyelid margins. The magnitude of LTT was in the order of that established for the peripheral corneal CTT. Innervation of the human corneal stroma and epithelium was investigated by light and electron microscopy in the central and mid-peripheral positions. All nerve bundles were located in the anterior two thirds of the. corneas. In keratoconic corneas mid-peripheral stromal nerve bundles were disorganised and irregular taking up the shape of the adjacent collagen lamellae. Nerve bundles had a regular oval appearance in the control corneas. In both groups Schwann cell cytoplasm was sparse and of varying degree of electron density; axon varicosities were not uncommon and axon content with respect to organelles were similar. The axon density showed large variation in keratoconic: specimens and averaged more than threefold that of control specimens for stromal and epithelial nerves. The control corneas showed a greater proportion of large diameter stromal axons than in keratoconic corneas. This result was reversed for epithelial axons. The results are discussed with respect to the disease process and influence on tactile sensitivity...|$|R
