14|212|Public
50|$|By 2006 CCD <b>matrix</b> <b>camera</b> {{backs of}} 39 megapixels were available. using the Kodak CCD and 33-megapixel Dalsa CCD in the Sinar 75 {{and in the}} Leaf Aptus 75 (6726×5040 pixels, with 7.2-micrometre-wide pixels). By 2008 several camera {{manufactures}} were developing larger camera backs based on the Kodak 50-megapixel CCD. Scanning backs are a narrower niche, used only for the highest-quality images with large-format cameras. Sinar continued their development of the step and repeat system of extending the CCD capabilities (macroscanning) with the arTec camera which creates a panoramic image with stitching technology.|$|E
50|$|Since it is {{much easier}} to {{manufacture}} a high-quality linear CCD array with only thousands of pixels than a CCD matrix with millions, very high resolution linear CCD camera backs were available much earlier than their CCD matrix counterparts. For example, you could buy an (albeit expensive) camera back with over 7,000 pixel horizontal resolution in the mid-1990s. However, , it is still difficult to buy a comparable CCD <b>matrix</b> <b>camera</b> of the same resolution. Rotating line cameras, with about 10,000 color pixels in its sensor line, are able, , to capture about 120,000 lines during one full 360 degree rotation, thereby creating a single digital image of 1,200 Megapixels.|$|E
40|$|Abstract—Visual {{inspection}} using cameras is {{used here}} for testing the lateral surface of cylindrical products. The inspection {{can be carried}} out according to available resources by: line scan camera system, <b>matrix</b> <b>camera</b> with conical mirror system and <b>matrix</b> <b>camera</b> with multi flat mirrors system. The research is aimed to use the previous systems for testing the objects surface and making comparison between the mentioned systems. This requires suitable setting of each system to perform experiments and getting images, includes: setting of camera, light, object and mirrors. The image of each system has a different view from each other and it is quite difficult to make directly comparison between them. For this reason, the images should have the same view for its lateral surface, so called the developed view. The image of the line scan camera is used as a reference for the developed view and the images coming from <b>matrix</b> <b>camera</b> with conical mirror and multi flat mirrors are manipulated using image processing in MATLAB program to find the developed view of lateral surface of the inspected object. The developed view of the images from the previous systems is compared in terms of their resolution and accuracy, for the same tested object, in order to choose which system is suitable for the inspection task...|$|E
2500|$|In {{computer}} vision a <b>camera</b> <b>matrix</b> or (<b>camera)</b> projection <b>matrix</b> is a [...] matrix which describes the mapping of a pinhole camera from 3D {{points in the}} world to 2D points in an image.|$|R
5000|$|In {{the actual}} {{rendering}} step, the world <b>matrix</b> * <b>camera</b> <b>matrix</b> * projection matrix is calculated {{and then finally}} applied to every single point. Thus, the points of all objects are transferred directly to the screen coordinate system (at least almost, the value range of the axes are still -1..1 for the visible range, see section [...] "Window-Viewport-Transformation").|$|R
25|$|This {{implies that}} the camera center (in its {{homogeneous}} representation) lies in the null space of the <b>camera</b> <b>matrix,</b> provided that it is represented in terms of 3D coordinates relative to the same coordinate system as the <b>camera</b> <b>matrix</b> refers to.|$|R
40|$|Panoramic {{images and}} {{panoramic}} cameras (or sensors) are of increasing importance for various applications in computer vision, computer graphics, visualization, and robotics. Various panoramic image capturing sensors {{have been developed}} for different purposes. But many of the sensing devices do not support stereo visualization. This paper reviews a methodology for stereo panorama acquisition using a widely available digital <b>matrix</b> <b>camera.</b> We also propose a method for camera calibration. The calibration process of such an image acquisition system is essential to ensure a high quality of stereo visualization...|$|E
40|$|An {{uncooled}} micromolometer <b>matrix</b> <b>camera</b> {{has been}} developed for IR and THz high-speed imaging. The 120 x 160 matrix consists of resistive vanadium oxide elements on a silicon nitride bridge. The element size is 46 x 46 micron at the array period of 51 micron. We describe device fabrication process and matrix operational characteristics. Application of the camera in quasi-optical systems with Novosibirsk terahertz free electron laser as a radiation source is described. Recording rate up to 90 frames per second has been achieved...|$|E
40|$|The {{invention}} {{relates to}} a process and a device for the interferometric detection of the shape and/or change in shape of objects under test. The object under test arranged in the measuring arm of an interferometer is illuminated simultaneously {{by the light of}} two laser beam sources, and the measuring and reference light bundle (M 1, R 1) generated {{by the light of the}} first laser beam source (2, 21) and interfering with each other is separated spatially from the measuring and reference light bundle (M 2, R 2) generated by the light of the second laser beam source (3, 22) interfering with each other, and the measuring and reference wave fronts (M 1, R 1) generated by the light of the first laser beam source (2, 21) interfering with each other is observed by a first <b>matrix</b> <b>camera</b> and the measuring and reference wave fronts (M 2, R 2) generated by the light having a different wavelength and generated by the second laser beam source (3, 22) is observed by a second <b>matrix</b> <b>camera</b> (14, 33) and the mea suring data of the two observed intensity distributions are detected at the same clock and further processed with the aid of a computer...|$|E
50|$|Camera resectioning is {{the process}} of {{estimating}} the parameters of a pinhole camera model approximating the camera that produced a given photograph or video. Usually, the pinhole camera parameters are represented in a 3 &times; 4 <b>matrix</b> called the <b>camera</b> <b>matrix.</b>|$|R
50|$|This {{implies that}} the camera center (in its {{homogeneous}} representation) lies in the null space of the <b>camera</b> <b>matrix,</b> provided that it is represented in terms of 3D coordinates relative to the same coordinate system as the <b>camera</b> <b>matrix</b> refers to.|$|R
2500|$|Since the <b>camera</b> <b>matrix</b> [...] is {{involved}} in the mapping between elements of two projective spaces, it too can be regarded as a projective element. This means that it has only 11 degrees of freedom since any multiplication by a non-zero scalar results in an equivalent <b>camera</b> <b>matrix.</b>|$|R
40|$|A {{stroboscopic}} surface thermal lensing (SSTL) {{system for}} the fast detection of thermal-induced defects in large-scaled optical coating films was constructed. The SSTL signal was generated {{by a set of}} double-modulators and captured by a high speed <b>matrix</b> <b>camera,</b> respectively. The spot size of both pump laser and probe laser expanded for larger detection area was finished in a single step. Based on the STL technique, both the mapping of amplitude and the phase of SSTL signal on the whole area of the coatings can be achieved simultaneously...|$|E
40|$|The {{high quality}} {{digitalisation}} of warped documents {{is still a}} big problem for most scanner technologies. The presented work is a contribution to develop a new technique handling this problem. Basic principle of the proposed method is a special kind of light section, that works with a comparatively very broad stripe lighting by using one additional <b>matrix</b> <b>camera.</b> We can reconstruct the 3 d-surface of the document by simple capturing an image sequence of the stripe lighting of a common book scanner during the scanning process. Based on a surface model we transform the warped document in a plane. Result is the two-dimensional output being a nearly distortion-free digital copy of the original warped document...|$|E
40|$|Coherent-optical Fourier {{transformation}} of video {{images can be}} very powerful; a set-up will be described. The modulation of the coherent beam occurs in a spatial light modulator where the liquid crystal display image of the object is projected onto an optically addressed spatial light modulator that uses bismuth silicium oxide for photoconduction and a twisted nematic liquid crystal as a birefringent layer. Edge enhancing of the image can occur; in addition, {{it appears that the}} Fourier spectrum of an edge is asymmetric due to local phase variations. The set-up was applied to recognize objects at different positions. A charge-coupled device <b>matrix</b> <b>camera</b> detects the Fourier plane, in the personal computer the pixels are summed up to ring-wedge-segments and processed for pattern recognition...|$|E
30|$|After {{determining}} world coordinates, {{the camera}} is registered to obtain the <b>camera</b> <b>matrix,</b> namely focal length of camera, optical center, and radial distortion parameters of image. Therefore, camera labeling is required. In the work, {{the camera is}} labeled by Yang and Patras [31] to obtain the <b>camera</b> <b>matrix.</b>|$|R
5000|$|Since the <b>camera</b> <b>matrix</b> [...] is {{involved}} in the mapping between elements of two projective spaces, it too can be regarded as a projective element. This means that it has only 11 degrees of freedom since any multiplication by a non-zero scalar results in an equivalent <b>camera</b> <b>matrix.</b>|$|R
5000|$|... #Subtitle level 2: Normalized <b>camera</b> <b>matrix</b> and {{normalized}} {{image coordinates}} ...|$|R
40|$|The method employs three laser sources (1 - 3) of {{different}} wavelengths coupled into a common fibre (4), {{from the end}} of which a conical wave enters the glass block (5) of a triangulation interferometer. A beam splitting layer (6) sends symmetrical partial beams through a collimator (9) on to the surface (10) under examination. Precisely one zero-order fringe per wavelength is imaged (11) on a holographic diffraction grating (12) associated with a lens (13) and CCD <b>matrix</b> <b>camera</b> (14). The measurement plane through in-phase points is represented by a stationary electromagnetic field and optically conjugated. USE/ADVANTAGE - On finely machined metallic surfaces such as toothed wheels or turbine blades. Highly improved precision is achievable with better lateral resolution over wider range...|$|E
40|$|The {{apparatus}} has a base {{on which}} the spectacle frame is fixed {{by means of a}} holder (13). The contour of the frame in the x-y plane is detected by means of a non-contact optoelectronic scanner. The resulting measurement data together with further measurement data in the z direction are fed to an analysis circuit for calculation of the curves of the frame, esp. the facing. A first scanner (2) is formed as a <b>matrix</b> <b>camera</b> (3) to determine the frame component contours in the x-y plane. A one dimensional triangulation measurement sensor is provided as a second scanner (5). One or more curves are formed spaced from the detected contours, and are stored in a memory. A mirror arrangement (7) is associated with the triangulation sensor (6). The mirror arrangement (7) reflects the measurement beam of the triangulation sensor to the frame components. The curves are used to scan and generate profiles of the frame components in the z direction by moving the triangulation sensor and the associated mirror arrangement along the curves. ADVANTAGE - Provides simple and efficient arrangement to provide precise three dimensional detection of shape of frame...|$|E
40|$|Tire {{inspection}} {{is presently}} done by {{workers who have}} as their main problems, besides identifying the defects, the time available for defect identification and the inherent costs. Companies can become more sustainable by adopting automated methods to perform such type of processes, such as artificial vision, with advantages both in the processing time and in the incurred costs. This paper addresses {{the development of an}} artificial vision system that aims to be an asset in the field of tyre inspection, having as main characteristics its execution speed and its reliability. The conjugation of these criteria is a prerequisite for this system {{to be able to be}} integrated in inspection machines. The paper focusses on the study of three image processing methods to be used in the identification of marks (red dots) on tires. In this work was used the free Open Computer Vision artificial vision library to process the images acquired by a Basler <b>matrix</b> <b>camera.</b> Two different techniques, namely Background Subtraction and Hough Transform, were tested to implement the solution. After developing the artificial vision inspection application, tests were made to measure the performance of both methods and the results were promising: processing time was low and, simultaneous, the achieved accuracy is high...|$|E
25|$|The <b>camera</b> <b>matrix</b> derived {{here may}} appear trivial {{in the sense}} that it {{contains}} very few non-zero elements. This depends to a large extent on the particular coordinate systems which have been chosen for the 3D and 2D points. In practice, however, other forms of <b>camera</b> <b>matrices</b> are common, as will be shown below.|$|R
2500|$|Consequently, the <b>camera</b> <b>matrix</b> which relates {{points in}} the {{coordinate}} system (X1',X2',X3') to image coordinates is ...|$|R
25|$|This type of <b>camera</b> <b>matrix</b> is {{referred}} to as a normalized <b>camera</b> <b>matrix,</b> it assumes focal length = 1 and that image coordinates are measured in a coordinate system where the origin is located at the intersection between axis X3 and the image plane and has the same units as the 3D coordinate system. The resulting image coordinates are referred to as normalized image coordinates.|$|R
40|$|The digital {{airborne}} multisensor and multiresolution {{system for}} {{collection of information}} (images) about mine suspected area was created, within European commission project Airborne Minefield Area Reduction (ARC, EC IST- 2000 - 25300, [URL] {{to gain a better}} perspective in mine suspected areas (MSP) in the Republic of Croatia. The system consists of a <b>matrix</b> <b>camera</b> (visible and near infrared range of electromagnetic spectrum, 0. 4 - 1. 1 µm), thermal (thermal range of electromagnetic spectrum, 8 - 14 µm) and a hyperspectral linear scanner. Because of a specific purpose and seeking object on the scene, the flights for collecting the images took place at heights from 130 m to 900 m above the ground. The result of a small relative flight height and large MSPs was a large number of images which cover MSPs. Therefore, the need for merging images in largest parts, for a better perspective in whole MSPs and the interaction of detected object influences on the scene appeared. The mentioned system did not dispose of the module for automatic mosaicking and geocoding, so mosaicking and after that geocoding were done manually. This process made the classification of the scene (better distinguishing of objects on the scene) and fusion of multispectral and multiresolution images after that possible. Classification and image fusion can be even done by manually mosaicking and geocoding. This article demonstrated this claim. </p...|$|E
40|$|DE 19849793 C UPAB: 20000426 NOVELTY - An {{imaging device}} {{produces}} a 3 D {{representation of the}} surface, measuring curvature. Electronic smoothing eliminates irregularities. Differencing techniques and area comparisons establish irregularity exceeding set limits. DETAILED DESCRIPTION - Preferred Features: The data extraction and smoothing unit includes a band pass filter. The lower frequency is selected to suppress curvature, the upper frequency is selected to smooth higher frequencies, without removing the irregularity of interest. A development includes two low pass filters and a subtracter. A non-linear filter is used for smoothing. Pixel artifacts are excluded (aliasing); singularities are excluded. The unit making comparative judgments is a two-dimensional median filter avoiding suppression of regions exceeding the predetermined area limit. Practical implementation includes a laser (13) and cylindrical lens (12) producing a flat beam (11) to light the surface. A <b>matrix</b> <b>camera</b> (14) measures the diffusely-reflected flat beam. Bulges, or neckings of the sidewalls are registered, rejecting hash from tread edges and shoulders. A controller relates camera framing frequency and tire speed, to obtain a given resolution. USE - To detect e. g. bulges and depressions in tire sidewalls, for quality inspection and control. ADVANTAGE - The method eliminates noise by filtering, which arises from {{the edges of the}} tread, whilst leaving lower-frequency bulge- or depression information intact. It removes its own noise, in the form of image aliasing and also ignores inevitable minor irregularities and roughness...|$|E
2500|$|The <b>camera</b> <b>matrix</b> derived above can be {{simplified}} {{even further}} {{if we assume}} that f = 1: ...|$|R
5000|$|IRMA <b>MATRIX</b> - TOF <b>camera,</b> {{used for}} {{automatic}} passenger counting on mobile and stationary applications by iris-GmbH ...|$|R
2500|$|Again, {{the null}} {{space of the}} {{normalized}} <b>camera</b> <b>matrix,</b> [...] described above, is spanned by the 4-dimensional vector ...|$|R
2500|$|The <b>camera</b> <b>matrix</b> [...] derived in the {{previous}} section has a null space which is spanned by the vector ...|$|R
2500|$|Finally, {{also the}} 3D {{coordinates}} {{are expressed in}} a homogeneous representation [...] {{and this is how}} the <b>camera</b> <b>matrix</b> appears: ...|$|R
40|$|Abstract-A {{method for}} {{calibrating}} single scanline CCD cameras {{is described in}} this paper. We show that the more classical 2 -D camera calibration techniques are necessary but not suflicient for solving for the 1 -D camera calibration problem. We propose a model for single scanline cameras, and we provide a two-step procedure for estimating its parameters. We also show how the extrinsic camera parameters can be determined geometrically without making explicit the intrinsic camera parameters. The accuracy of the calibration method is analyzed through an application example. Index Terms-Camera calibration, cross-ratio, intrinsic and extrinsic camera parameters, linear least squares estimation, perspective projection, single scanline CCD cameras. I. INTR~DUCTION In many applications of computer vision, 1 -D (single scanline) cameras may replace 2 -D (<b>matrix)</b> <b>cameras.</b> Inspection of parts, fo...|$|R
30|$|The {{calibration}} process used in {{stereo vision}} {{is the same}} when a checkerboard {{is used as a}} reference to the points in the world coordinate and image processing is used to find the points in the image coordinate. The calibration process is first done on each camera separately to find the projection <b>camera</b> <b>matrix</b> for each <b>camera,</b> and then, these matrices are used to calculate the essential matrix to find the external geometry parameters between the cameras.|$|R
2500|$|Assuming {{also that}} the <b>camera</b> <b>matrix</b> is given by , the mapping from the {{coordinates}} in the (X1',X2',X3') system to homogeneous image coordinates becomes ...|$|R
2500|$|... where [...] is the <b>camera</b> <b>matrix</b> and the [...] sign {{implies that}} {{the left and right}} hand sides are equal up to a non-zero scalar multiplication.|$|R
40|$|This work {{presents}} a consideration about the cinematographic syncretic text. Using The Matrix Trilogy as an example, this work shows {{the existence of}} a cinema syntax that is based on the way that Hollywood makes films. This syntax can be understood as one strategy of enunciation which is organized from camera and edition resources, whose mission is to manage the way that the public must feel and react, evidencing or devaluating certain narrative aspects. Keywords: <b>Matrix.</b> Syncretism. <b>Camera.</b> Edition. Cinema. Este trabalho apresenta uma reflexão sobre o texto sincrético cinematográfico. Procura mostrar, a partir de exemplos da Trilogia Matrix, a existência de uma sintaxe do cinema padrão Hollywood, que pode ser entendida como uma estratégia de enunciação organizada a partir dos recursos de câmera e de edição, cuja missão é administrar como o público deve sentir e reagir, evidenciando ou desvalorizando certos aspectos da narrativa. Palavras-chave: <b>Matrix.</b> Sincretismo. <b>Câmera.</b> Edição. Cinema...|$|R
