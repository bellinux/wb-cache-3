292|108|Public
5|$|In {{order to}} run safely on {{multiprocessor}} machines, access to shared resources (like files, data structures) must be serialized so that threads or processes do {{not attempt to}} modify the same resource at the same time. In order to prevent multiple threads from accessing or modifying a shared resource simultaneously, DragonFly employs critical sections, and serializing tokens to prevent concurrent access. While both Linux and FreeBSD 5 employ fine-grained <b>mutex</b> models to achieve higher performance on multiprocessor systems, DragonFly does not. Until recently, DragonFly also employed spls, but these were replaced with critical sections.|$|E
25|$|One case {{of early}} {{criticism}} against Exception handling {{was dealing with}} resource leaks or state inconsistence, such as escaping a section locked by a <b>mutex,</b> or one temporarily holding a file open. This have largely been solved by RAII and the dispose pattern, {{which had to be}} specifically invented to solve the issue, but have proven to be useful in other contexts.|$|E
25|$|The {{academic}} {{study of}} concurrent computing {{started in the}} 1960s, with Dijkstra (1965) credited with being the first paper in this field, identifying and solving the mutual exclusion problem. He {{was also one of}} the early pioneers of the research on principles of distributed computing. His foundational work on concurrency, semaphores, mutual exclusion (<b>mutex),</b> deadlock (deadly embrace), finding shortest paths in graphs, fault-tolerance, self-stabilization, among many other contributions comprises many of the pillars upon which the field of distributed computing is built. Shortly before his death in 2002, he received the ACM PODC Influential-Paper Award in distributed computing for his work on self-stabilization of program computation. This annual award was renamed the Dijkstra Prize (Edsger W. Dijkstra Prize in Distributed Computing) the following year, in his honor.|$|E
5000|$|... dispatchers, which {{act like}} <b>mutexes,</b> semaphores, events, and timers.|$|R
50|$|The {{following}} table {{summarizes the}} properties of tokens and <b>mutexes.</b>|$|R
5000|$|... {{adaptive}} <b>mutexes,</b> binary semaphores {{that are}} implemented differently {{depending upon the}} conditions; ...|$|R
25|$|In 1968 Dijkstra {{published}} his seminal paper 'Cooperating sequential processes', a 70-page essay that originated {{the field of}} concurrent programming. He discussed in it the notion of mutual exclusion (<b>mutex)</b> and the criteria a satisfactory solution should satisfy. He also redressed the historical perspective left out of his 1965 paper by including the first known correct solution to the mutual exclusion problem, for two processes, due to Theodorus Dekker. Dijkstra subsequently generalized Dekker's solution to n processes. Further, he proposed the first synchronisation mechanism for concurrent processes, the semaphore with its two operations, P and V. He also identified the 'deadlock problem' (called there 'the problem of the deadly embrace') and proposed an elegant 'Banker's algorithm' that prevents deadlock. The deadlock detection and prevention became perennial research problems {{in the field of}} concurrent programming.|$|E
500|$|Serializing tokens {{are used}} to prevent {{concurrent}} accesses from other CPUs and may be held simultaneously by multiple threads, ensuring that only one of those threads is running at any given time. Blocked or sleeping threads therefore do not prevent other threads from accessing the shared resource unlike a thread that is holding a <b>mutex.</b> Among other things, the use of serializing tokens prevents many of the situations {{that could result in}} deadlocks and priority inversions when using mutexes, as well as greatly simplifying the design and implementation of a many-step procedure that would require a resource to be shared among multiple threads. The serializing token code is evolving into something quite similar to the [...] "Read-copy-update" [...] feature now available in Linux. Unlike Linux's current RCU implementation, DragonFly's is being implemented such that only processors competing for the same token are affected rather than all processors in the computer.|$|E
2500|$|LMDB employs multiversion {{concurrency}} control (MVCC) and allows multiple threads within multiple processes to coordinate simultaneous {{access to a}} database. Readers scale linearly by design. [...] While write transactions are globally serialized via a <b>mutex,</b> read-only transactions operate in parallel, including {{in the presence of}} a write transaction, and are entirely wait free except for the first read-only transaction on a thread. Each thread reading from a database gains ownership of an element in a shared memory array, which it may update to indicate when it is within a transaction. Writers scan the array to determine the oldest database version the transaction must preserve, without requiring direct synchronization with active readers.|$|E
5000|$|Modula-3â€”modern {{member of}} Algol family with {{extensive}} support for threads, <b>mutexes,</b> condition variables ...|$|R
5000|$|System locks (including latches, <b>mutexes</b> and {{internal}} locks) protect internal database structures like data files.|$|R
50|$|Readers-writer locks {{are usually}} {{constructed}} {{on top of}} <b>mutexes</b> and condition variables, or on top of semaphores.|$|R
5000|$|... int pthread_mutex_init(pthread_mutex_t * <b>mutex</b> , pthread_mutexattr_t * attr);int pthread_mutex_destroy (pthread_mutex_t * mutex);int pthread_mutex_lock (pthread_mutex_t * <b>mutex</b> [...] );int pthread_mutex_unlock (pthread_mutex_t * <b>mutex</b> [...] ); ...|$|E
50|$|In {{computer}} science, the reentrant <b>mutex</b> (recursive <b>mutex,</b> recursive lock) is {{particular type}} of mutual exclusion (<b>mutex)</b> device that may be locked multiple times by the same process/thread, without causing a deadlock.|$|E
5000|$|A <b>mutex</b> is {{essentially}} the same thing as a binary semaphore and sometimes uses the same basic implementation. The differences between them are in how they are used. While a binary semaphore may be used as a <b>mutex,</b> a <b>mutex</b> is a more specific use-case, in that only the thread that locked the <b>mutex</b> is supposed to unlock it. This constraint makes it possible to implement some additional features in mutexes: ...|$|E
5000|$|... {{items for}} synchronisation: <b>mutexes</b> and {{counting}} semaphores, used for thread synchtonization, signalling from ISR to a thread and guarding shared resources, ...|$|R
5000|$|Implementing <b>mutexes</b> and {{condition}} variables requires {{some kind of}} synchronization primitive provided by hardware support that provides atomicity. Locks {{and condition}} variables are higher-level abstractions over these synchronization primitives. On a uniprocessor, disabling and enabling interrupts {{is a way to}} implement monitors by preventing context switches during the critical sections of the locks and condition variables, but this is not enough on a multiprocessor. On a multiprocessor, usually special atomic read-modify-write instructions on the memory such as test-and-set, compare-and-swap, etc. are used, depending on what the ISA provides. These usually require deferring to spin-locking for the internal lock state itself, but this locking is very brief. Depending on the implementation, the atomic read-modify-write instructions may lock the bus from other cores' accesses and/or prevent re-ordering of instructions in the CPU. Here is an example pseudocode implementation of parts of a threading system and <b>mutexes</b> and Mesa-style condition variables, using test-and-set and a first-come, first-served policy. This glosses over most of how a threading system works, but shows the parts relevant to <b>mutexes</b> and condition variables: ...|$|R
5|$|DragonFly {{switched}} to multiprocessor safe slab allocator, which requires neither <b>mutexes</b> nor blocking operations for memory assignment tasks. It was eventually ported into standard C library in the userland, where it replaced FreeBSD's malloc implementation.|$|R
5000|$|Alternately, if {{the thread}} holding the <b>mutex</b> is deleted (perhaps {{due to an}} {{unrecoverable}} error), the <b>mutex</b> can be automatically released.|$|E
5000|$|While {{any attempt}} to perform the [...] "lock" [...] {{operation}} on an ordinary <b>mutex</b> (lock) would either fail or block when the <b>mutex</b> is already locked, on a recursive <b>mutex</b> this operation will succeed {{if and only if}} the locking thread is the one that already holds the lock. Typically, a recursive <b>mutex</b> tracks the number of times it has been locked, and requires equally many unlock operations to be performed before other threads may lock it.|$|E
50|$|With {{priority}} ceilings, {{the shared}} <b>mutex</b> process (that runs {{the operating system}} code) has a characteristic (high) priority of its own, which is assigned to the task locking the <b>mutex.</b> This works well, provided the other high priority task(s) that tries to access the <b>mutex</b> {{does not have a}} priority higher than the ceiling priority.|$|E
5000|$|Recursive <b>mutexes</b> {{solve the}} problem of non-reentrancy with regular mutexes: if a {{function}} that takes a lock and executes a callback is itself called by the callback, deadlock ensues. In pseudocode, that is the following situation: ...|$|R
5000|$|For {{synchronization}} between threads, appropriate <b>mutexes</b> ( [...] , , etc.) {{and condition}} variables ( [...] and [...] ) {{are added to}} the library. These are accessible via Resource Acquisition Is Initialization (RAII) locks ( [...] and [...] ) and locking algorithms for easy use.|$|R
5000|$|In computing, a futex (short for [...] "fast userspace mutex") is a kernel {{system call}} that programmers {{can use to}} {{implement}} basic locking, or as a building block for higher-level locking abstractions such as semaphores and POSIX <b>mutexes</b> or condition variables.|$|R
5000|$|Notice {{that the}} order in which {{different}} semaphores are incremented or decremented is essential: changing the order might result in a deadlock. It is important to note here that though <b>mutex</b> seems to work as a semaphore with value of 1 (binary semaphore), but there is difference in the fact that <b>mutex</b> has ownership concept. Ownership means that <b>mutex</b> can only be [...] "incremented" [...] back (set to 1) by the same process that [...] "decremented" [...] it (set to 0), and all others tasks wait until <b>mutex</b> is available for decrement (effectively meaning that resource is available), which ensures mutual exclusivity and avoids deadlock. Thus using mutexes improperly can stall many processes when exclusive access is not required, but <b>mutex</b> is used instead of semaphore.|$|E
5000|$|... var m : <b>Mutex</b> // A non-recursive <b>mutex,</b> {{initially}} unlocked. [...] function lock_and_call(i : Integer) m.lock (...) callback(i) m.unlock (...) [...] function callback(i : Integer) if i > 0 lock_and_call(i - 1) ...|$|E
5000|$|Since {{only the}} thread that locked the <b>mutex</b> is {{supposed}} to unlock it, a <b>mutex</b> may store the id of thread that locked it and verify the same thread unlocks it.|$|E
40|$|Many {{planning}} domains {{require a}} richer notion {{of time in}} which actions can overlap and have di erent durations. The key to fast performance in classical planners (e. g., Graphplan, ipp, and Blackbox) has been {{the use of a}} disjunctive representation with powerful mutual exclusion reasoning. This paper presents tgp, a new algorithm for temporal planning. tgp operates by incrementally expanding a compact planning graph representation that handles actions of di ering duration. The key to tgp performance is tight mutual exclusion reasoning which is based on an expressive language for bounding <b>mutexes</b> and includes <b>mutexes</b> between actions and propositions. Our experiments demonstrate that mutual exclusion reasoning remains valuable in a rich temporal setting. ...|$|R
5000|$|... (N.B.: <b>Mutexes</b> {{themselves}} {{can also be}} spin-locks which involve busy-waiting {{in order to get}} the lock, but in order to solve this problem of wasted CPU resources, we assume that queueLock is not a spin-lock and properly uses a blocking lock queue itself.) ...|$|R
25|$|The kernel and {{scheduling}} is distributed across the SPEs. Tasks are synchronized using <b>mutexes</b> or semaphores as {{in a conventional}} operating system. Ready-to-run tasks wait in a queue for an SPE to execute them. The SPEs use shared memory for all tasks in this configuration.|$|R
5000|$|Mutexes {{may provide}} {{priority}} inversion safety. If the <b>mutex</b> knows who locked it and {{is supposed to}} unlock it, {{it is possible to}} promote the priority of that thread whenever a higher-priority task starts waiting on the <b>mutex.</b>|$|E
5000|$|Note that, in this example, the {{thread-safe}} stack is internally {{providing a}} <b>mutex,</b> which, {{as in the}} earlier producer/consumer example, is shared by both condition variables, which are checking different conditions on the same concurrent data. The {{only difference is that}} the producer/consumer example assumed a regular non-thread-safe queue and was using a standalone <b>mutex</b> and condition variables, without these details of the monitor abstracted away as is the case here. In this example, when the [...] "wait" [...] operation is called, it must somehow be supplied with the thread-safe stack's <b>mutex,</b> such as if the [...] "wait" [...] operation is an integrated part of the [...] "monitor class". Aside from this kind of abstracted functionality, when a [...] "raw" [...] monitor is used, it will always have to include a <b>mutex</b> and a condition variable, with a unique <b>mutex</b> for each condition variable.|$|E
50|$|The RAII {{design is}} often used for {{controlling}} <b>mutex</b> locks in multi-threaded applications. In that use, the object releases the lock when destroyed. Without RAII in this scenario the potential for deadlock would be high and the logic to lock the <b>mutex</b> would be far from the logic to unlock it. With RAII, the code that locks the <b>mutex</b> essentially includes the logic that the lock will be released when execution leaves {{the scope of the}} RAII object.|$|E
50|$|For high-performance, {{low-level}} work, communicating between threads {{is sometimes}} needed without the overhead of <b>mutexes.</b> This is done using atomic operations on memory locations. These can optionally specify the minimum memory visibility constraints needed for an operation. Explicit memory barriers {{may also be}} used for this purpose.|$|R
50|$|Issues such as {{deadlock}} and priority inversion can be {{very difficult}} to avoid, and require coordination at many levels of the kernel. Because locking with tokens does not deadlock and acquired tokens need not be atomic when later operations block, it allow much simpler code than <b>mutexes.</b>|$|R
5000|$|FreeRTOS {{provides}} {{methods for}} multiple threads or tasks, <b>mutexes,</b> semaphores and software timers. A tick-less mode is provided for low power applications. Thread priorities are supported. FreeRTOS applications can be completely statically allocated. Alternatively RTOS objects can be dynamically allocated with five schemes of memory allocation provided: ...|$|R
