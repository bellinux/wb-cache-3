13|7|Public
5000|$|Whereas in [...] "pure math," [...] the {{gradient}} of a scalar function {{expressed by}} the <b>math</b> <b>notation</b> grad(f) may not have physical units associated with it; in drilling engineering the pore pressure gradient is usually expressed in API-type International Association of Drilling Contractors (IADC) physical units of measurement, namely [...] "psi per foot." [...] In the well-known formula ...|$|E
5000|$|Consider the {{expression}} [...] If the operator [...] has left associativity, this expression would {{be interpreted as}} [...] If the operator has right associativity, {{the expression}} would be interpreted as [...] If the operator is non-associative, the expression might be a syntax error, or it might have some special meaning. Some mathematical operators have inherent associativity. For example, subtraction and division, as used in conventional <b>math</b> <b>notation,</b> are inherently left-associative. Addition and multiplication, by contrast, are both left and right associative. (e.g. [...] ).|$|E
50|$|Paracomp was a Macintosh {{programming}} company {{known for}} their 3D software, Swivel 3D and ModelShop and FilmMaker. FilmMaker was known for its packaging which was a 16mm film reel tin which was used to contain the software and manuals. Paracomp was also {{the publisher of the}} computer algebra system Milo, which - as the first program on Macintosh - allowed to perform symbolic computation using standard <b>math</b> <b>notation.</b> Paracomp was acquired by MacroMind in 1991 to briefly form MacroMind-Paracomp, before adding Authorware in 1992 and becoming Macromedia.|$|E
40|$|By {{means of}} {{functional}} integrations spectral properties of semi-relativistic Pauli-Fierz Hamiltonians in quantum electrodynamics is considered. Two self-adjoint extensions of a semi-relativistic Pauli-Fierz Hamiltonian are defined. An essential self-adjointness, a spatial decay of bound states, a Gaussian {{domination of the}} ground state {{and the existence of}} a measure associated with the ground state are shown. Comment: To be published in Adv in <b>Math.</b> Confused <b>notations</b> are revise...|$|R
40|$|General Instruction: This is an {{individual}} project but you are allowed to discuss in groups on all the {{issues related to the}} project. The final write up must be in your own words. Start to work on your project as early as possible. Purposes: 1. Apply the sparse representation method to the face recognition problem. 2. The IHT algorithm for sparse recovery. 3. Comparison of the performance of the different techniques by using Matlab. 4. Get familiar with some of the well- known data sets. Project Description: Part I: State clearly the method of sparse representation using L 1 minimization and explain how {{it can be used to}} solve the face recognition problem (using <b>math</b> <b>notations,</b> not just sentences). Part II: State clearly the method of iterative hard thresholding (IHT) for sparse recovery and give an algorithm for solving the face recognition problem through sparse representation via IHT. Part III: Implement the IHT algorithm in Part II using the image data set used in Project III. Report on the accuracy (in terms of the percentage of correct recognition when you repeat with a set of different testing images) ...|$|R
40|$|This paper {{describes}} and summarizes {{experiences of}} Masaryk University team MIRMU with the mathematical search performed for the NTCIR pilot Math Task. Our {{approach is the}} similarity search based on enhanced full text search utilizing attested state-of-the-art techniques and implementations. The variability of used Math Indexer and Searcher (MIaS) system {{in terms of the}} <b>math</b> query <b>notation</b> was tested by submitting multiple runs with four query notations provided. The analysis of the evaluation results shows that the system performs best using TeX queries that are translated to combined Presentation-Content MathML...|$|R
5000|$|Casio used to {{call this}} Natural Display or Natural {{textbook}} display, but now uses Natural-VPAM.SHARP calls this WriteView on its scientific calculators and on its graphing calculators it just uses the term Equation Editor. HP calls this Textbook display setting [...] {{which can be used}} in both RPN and Algebraic mode in both Stack and in Equation Writer application.Mathematica calls this Semantic-Faithful Typesetting. Mathcad calls this standard <b>math</b> <b>notation.</b> Maple has a Math Equation Editor but does not have a special name for this input method. Texas Instruments calls this MathPrint.|$|E
5000|$|As of 2013, {{with the}} {{majority}} of English-speaking ICEB member-countries having officially adopted UEB, there remain barriers to implementation and deployment. Besides ICEB member-nations, there are also many other countries with blind citizens that teach and use English: India, Hong Kong/China, Pakistan, the Philippines, and so on. Many of these countries use non-UEB <b>math</b> <b>notation,</b> for English-speaking countries specifically, versions of the Nemeth Code were widespread by 1990 (in the United States, Western Samoa, Canada including Quebec, New Zealand, Israel, Greece, India, Pakistan, Sri Lanka, Thailand, Malaysia, Indonesia, Cambodia, Vietnam, and Lebanon) in contrast to the similar-to-UEB-but-not-identical Taylor notation in 1990 (used by the UK, Ireland, Australia, Nigeria, Hong Kong, Jordan, Kenya, Sierra Leone, Singapore, and Zimbabwe). [...] Some countries in the Middle East used both Nemeth and Taylor math-notations as of 1990, i.e. Iran and Saudi Arabia. As of 2013, it is unclear whether the English-using blind populations of various ICEB and non-ICEB nations will move to adopt the UEB, and if so, at what rate.|$|E
40|$|The polysymplectic $(n+ 1) $-form is {{introduced}} as an analogue of the symplectic {{form for the}} De Donder-Weyl polymomentum Hamiltonian formulation of field theory. The corresponding Poisson brackets on differential forms are constructed. The analogues of the Poisson algebra are shown to be generalized (non-commutative and higher-order) Gerstenhaber algebras defined in the text. Comment: 6 pages, LaTeX. Talk at Gropu 21, Goslar (Germany) 1996. Typos in <b>math</b> <b>notation</b> fixed, refs updated, minor style improvement...|$|E
40|$|This paper {{describes}} and summarizes {{experience of}} Masaryk University Math Information Retrieval team (MIRMU) with the mathematical search developed and performed for the NTCIR- 11 Math- 2 Task. Our {{approach is the}} similarity search based on canonicalized MathML and second gener-ation of scalable full text search engine Math Indexer and Searcher (MIaS) with attested state-of-the-art information retrieval techniques like query expansion. The capability of MIaS system in terms of <b>math</b> query <b>notation,</b> normal-ization and combining math with textual query tokens was deployed by submitting multiple runs with four query no-tations provided, and with results merged from multiple queries. The analysis of the evaluation results shows that the system performs best using TEX queries that are translated and canonicalized to Content MathML, where MIaS ranked as # 1 for all metrics returning very relevant results...|$|R
40|$|Lower-level college math courses usually {{avoid using}} formalism, in both {{definitions}} and proofs. Later, when students have mastered definitions and proofs written largely in English, {{they may be}} shown how informal reasoning could be formalized, but the impression is left that such formalization would not be worth the effort. The design of proofs is also not taught. Students see proofs and {{may be asked to}} develop a few themselves, but {{there is little or no}} discussion of principles or strategies for designing proofs. Few are happy with the results of these courses. Generally, students' reasoning abilities are poor, even after several math courses. Many students still fear <b>math</b> and <b>notation,</b> and the development of proofs remains a mystery to most. In short, students are not being equipped with the tools needed to employ mathematics in solving new problems. We believe that this statee of affairs can be improved. This article describes our approach...|$|R
40|$|Document {{classification}} {{is widely}} applied in many scientific areas and academic environments, using NLP techniques and term extraction algorithms like CValue, TfIdf, TermEx, GlossEx, Weirdness {{and the others}} like. Nevertheless, they mainly have weaknesses in extracting most important terms when input text has not been rectified grammatically, or even has non-alphabetic methodical and <b>math</b> or chemical <b>notations,</b> and cross-domain inference of terms and phrases. In this paper, we propose a novel Text-Categorization and Term-Extraction method based on human-expert choice of classified categories. Papers are the training phase substances of the proposed algorithm. They have been already la-beled with some scientific pre-defined field specific categories, by a human expert, especially one with high experi-ences and researches and surveys in the field. Our approach thereafter extracts (concept) terms of the labeled papers o...|$|R
40|$|We work in {{the space}} C n of n × 1 column vectors with the inner product (x, y) =x † y. A † denotes the {{transpose}} conjugate of A. We mix <b>math</b> <b>notation</b> and bra(c) ket notation like English and pidgin. Postulate 1. An isolated quantum system “is described by ” a unit vector in Cn. A unit vector ψ in Cn is called a state. Aqubit is a unit vector in C 2. A linear combination of states is called a superposition. Postulate 2. The evolution of an isolated system is described by a continuous 1 -parameter group of unitary operators. That means we have unitary matrices U(t) such that U(0) = I U(t 1 + t 2) =U(t 1) U(t 2) ψ(t) =U(t) ψ(0) Example. The Schrödinger equation i...|$|E
40|$|We {{describe}} a symbol classification technique for identifying the expected locations of neighboring symbols in mathematical expressions. We use the seven symbol layout classes of the DRACULAE <b>math</b> <b>notation</b> parser (Zanibbi, Blostein, and Cordy, 2002) to represent expected locations for neighboring symbols: Ascender, Descender, Centered, Open Bracket, Non-Script, Variable Range (e. g. integrals) and Square Root. A new feature based on shape contexts (Belongie et al., 2002) named layout context {{is used to}} describe the arrangement of neighboring symbol bounding boxes relative to a reference symbol, and the nearest neighbor rule is used for classification. 1917 mathematical symbols from the University of Washington III document database are used in our experiments. Using a leave-one-out estimate, our best classification rate reaches nearly 80 %. In our experiments, we find that the size of the symbol neighborhood, and number and arrangement of key points representing a symbol affect performance significantly...|$|E
40|$|Abstract Document {{recognition}} and retrieval technolo-gies complement one another, providing improved ac-cess to increasingly large document collections. While {{recognition and}} retrieval of textual information is fairly mature, with wide-spread availability of Optical Char-acter Recognition (OCR) and text-based search engines, recognition and retrieval of graphics such as images, fig-ures, tables, diagrams, and mathematical expressions are in comparatively {{early stages of}} research. This pa-per surveys {{the state of the}} art in recognition and re-trieval of mathematical expressions, organized around four key problems in math retrieval (query construc-tion, normalization, indexing, and relevance feedback), and four key problems in math recognition (detecting expressions, detecting and classifying symbols, analyz-ing symbol layout, and constructing a representation of meaning). Of special interest is the machine learn-ing problem of jointly optimizing the component algo-rithms in a math recognition system, and developing effective indexing, retrieval and relevance feedback al-gorithms for math retrieval. Another important open problem is developing user interfaces that seamlessly integrate recognition and retrieval. Activity in these important research areas is increasing, in part because <b>math</b> <b>notation</b> provides an excellent domain for study-ing problems common to many document and graphics recognition and retrieval applications, and also because mature applications will likely provide substantial ben-efits for education, research, and mathematical literacy...|$|E
40|$|Document {{classification}} {{is widely}} applied in many scientific areas and academic environments, using NLP techniques and term extraction algorithms like CValue, TfIdf, TermEx, GlossEx, Weirdness {{and the others}} like. Nevertheless, they mainly have weaknesses in extracting most important terms when input text has not been rectified grammatically, or even has non-alphabetic methodical and <b>math</b> or chemical <b>notations,</b> and cross-domain inference of terms and phrases. In this paper, we propose a novel Text-Categorization and Term-Extraction method based on human-expert choice of classified categories. Papers are the training phase substances of the proposed algorithm. They have been already labeled with some scientific pre-defined field specific categories, by a human expert, especially one with high experiences and researches and surveys in the field. Our approach thereafter extracts (concept) terms of the labeled papers of each category and assigns all to the category. Categorization of test papers is then applied based on their extracted terms and further comparing with each category’s terms. Besides, our approach will produce semantic enabled outputs that are useful for many goals such as knowledge bases and data sets complement of the Linked Data cloud and for semantic querying of them by some languages such as SparQL. Besides, further finding classified papers’ gained topic or class will be easy by using URIs contained in the ontological outputs. The experimental results, comparing LPTC with five well-known term extraction algorithms by measuring precision and recall, show that categorization effectiveness can be achieved using our approach. In other words, the method LPTC is significantly superior to CValue, TfIdf, TermEx, GlossEx and Weirdness in the target study. As well, we conclude that higher number of papers for training, even higher precision we have...|$|R
40|$|Abstract. Spreadsheets are {{well-known}} to be frequently-used but error-prone communication devices. They {{are useful}} {{since they are}} active (e. g., automatic computation), provide a cognitive notation system drawing on visualizing val-ues, meanings and relations {{at the same time}} (enabled by labeled, color-coded grids), and provide easy-to-use domain-specific operations (e. g., computational functions). The latter, in particular, is enabled by the text-style formula format in spreadsheets, in which variables are replaced by cell references. For simply-structured formulae this works very well. To keep the formulae simple, computa-tions are modularized into subformulae and as such distributed over and beyond the spreadsheet. This makes the provenance (tree) of spreadsheet values difficult to understand – a probable cause for the high error rate in spreadsheets. To explore and navigate the subformulae involved in the computation of a cell value we present the subformula explorer “FEncy”, a tree-based, explorative in-terface: Whenever a user clicks on a cell its formula becomes the root of a cell-dependency graph. Each child node displays the formula of a cell (or range) ref-erence used in the parent formula either in the original text-style or potentially in <b>math</b> <b>notation.</b> Moreover, each node represents a direct link to the respective cell (or range), {{so that it can be}} used for formula navigation as well. ...|$|E
40|$|Cengel and Cimbala's Fluid Mechanics Fundamentals and Applications, {{communicates}} {{directly with}} tomorrow's engineers {{in a simple}} yet precise manner. The text covers the basic principles and equations of fluid mechanics {{in the context of}} numerous and diverse real-world engineering examples. The text helps students develop an intuitive understanding of fluid mechanics by emphasizing the physics, using figures, numerous photographs and visual aids to reinforce the physics. The highly visual approach enhances the learning of Fluid mechanics by students. This text distinguishes itself from others by the way the material is presented - in a progressive order from simple to more difficult, building each chapter upon foundations laid down in previous chapters. In this way, even the traditionally challenging aspects of fluid mechanics can be learned effectively. McGraw-Hill is also proud to offer ConnectPlus powered by Maple with the third edition of Cengel/Cimbabla, Fluid Mechanics. This innovative and powerful new system that helps your students learn more easily and gives you the ability to customize your homework problems and assign them simply and easily to your students. Problems are graded automatically, and the results are recorded immediately. Natural <b>Math</b> <b>Notation</b> allows for answer entry in many different forms, and the system allows for easy customization and authoring of exercises by the instructor...|$|E
40|$|Document {{recognition}} and retrieval technologies complement one another, providing improved access to increasingly large document collections. While {{recognition and}} retrieval of textual information is fairly mature, with wide-spread availability of Optical Character Recognition (OCR) and text-based search engines, recognition and retrieval of graphics such as images, figures, tables, diagrams, and mathematical expressions are in comparatively {{early stages of}} research. This paper surveys {{the state of the}} art in recognition and retrieval of mathematical expressions, organized around four key problems in math retrieval (query construction, normalization, indexing, and relevance feedback), and four key problems in math recognition (detecting expressions, detecting and classifying symbols, analyzing symbol layout, and constructing a representation of meaning). Of special interest is the machine learning problem of jointly optimizing the component algorithms in a math recognition system, and developing effective indexing, retrieval and relevance feedback algorithms for math retrieval. Another important open problem is developing user interfaces that seamlessly integrate recognition and retrieval. Activity in these important research areas is increasing, in part because <b>math</b> <b>notation</b> provides an excellent domain for studying problems common to many document and graphics recognition and retrieval applications, and also because mature applications will likely provide substantial benefits for education, research, and mathematical literacy...|$|E
40|$|In an old joke, two noblemen vie to {{name the}} bigger number. The first, after ruminating for hours, triumphantly announces ”Eighty-three! ” The second, mightily impressed, replies ”You win. ” A biggest number contest is clearly {{pointless}} when the contestants take turns. But what if the contestants write down their numbers simultaneously, neither aware of the other’s? To introduce a talk on ”Big Numbers, ” I invite two audience volunteers to try exactly this. I tell them the rules: You have fifteen seconds. Using standard <b>math</b> <b>notation,</b> English words, or both, name a single whole number–not an infinity–on a blank index card. Be precise enough for any reasonable modern mathematician to determine exactly what number you’ve named, by consulting only your card and, if necessary, the published literature. So contestants can’t say ”the number of sand grains in the Sahara, ” because sand drifts {{in and out of}} the Sahara regularly. Nor can they say ”my opponent’s number plus one, ” or ”the biggest number anyone’s ever thought of plus one”–again, these are ill-defined, given what our reasonable mathematician has available. Within the rules, the contestant who names the bigger number wins. Are you ready? Get set. Go. The contest’s results are never quite what I’d hope. Once, a seventh-grade boy filled his card with a string of successive 9 ’s. Like many other big-number tyros, he sought to maximize his number by stuffing a 9 into every place value. Had he chosen easy-to-write 1 ’s rather than curvaceous 9 ’s, his number could have been millions of times bigger. He still would been decimated, though, by the girl he was up against, who wrote a string of 9 ’s followed by the superscript 999. Aha! An exponential: a number multiplied by itself 999 times. Noticing this innovation, I declared the girl’s victory without bothering to count the 9 ’s on the cards. And yet the girl’s number could have been much bigger still, had she stacked the mighty exponential more than once. Take 999, for example. This behemoth, equal to 9387, 420, 489, has 369, 693, 100 digits. By comparison, the number of elementary particles in the observable universe has a meager 85 digits, give or take. Three 9 ’s, when stacked exponentially, already lift us incomprehensibly ∗ Revised by Florian Mayer 1 beyond all the matter we can observe–by a factor of about 10369, 693, 015. And we’ve said nothing of 9 99...|$|E

