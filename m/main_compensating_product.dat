0|59|Public
40|$|Using {{forward current}} {{injection}} with densities {{in the range}} 15 - 30 A/cm(2) we can effectively eliminate the radiation-induced boron-oxygen complex, which is the <b>main</b> <b>compensating</b> center in irradiated Si solar cells. It was found that for a given forward current density the elimination rate is decreasing with increasing irradiation dose. Additionally, some evidences have been obtained on the negative-U properties of the radiation-induced boron-oxygen complex...|$|R
40|$|We {{study the}} {{influence}} of <b>main</b> <b>compensating</b> defects: As antisites and Mn interstitials, known to occur in GaMnAs ferromagnetic semiconductor, on its structural properties. Our experimental results {{show that there is}} a balance between Mn interstitial and As antisite defects, leading to the reduced density of one type of defect upon increased density of another defect. The significant differences in the lattice parameters of GaMnAs with the different balance between these two types of defects were observed. The annealing induced reduction of GaMnAs lattice constant is inhibited in the samples with large density of As antisites. Comment: 17 pages, 4 figure...|$|R
40|$|The Method of Imprecision (MoI) is {{a formal}} theory for the {{manipulation}} of preliminary design information that represents preferences among design alternatives with the mathematics of fuzzy sets. Using the MoI, different design tradeoff strategies can be applied. To date, two aggregation functions {{have been developed for}} the MoI, one representing a compensating strategy and one a non-compensating strategy. Other research on aggregation functions on fuzzy sets has focused on two classes of functions that are not suitable for engineering design. The general restrictions on designappropriate aggregation functions are discussed, and a family of functions ranging from the non-compensating min to the <b>compensating</b> <b>product</b> of powers is presented. An application to preliminary engineering design is given...|$|R
40|$|MBE-grown Sn- and Mg-doped {{epitaxial}} In 2 O 3 thin-film samples {{with varying}} doping concentrations have been measured using positron Doppler spectroscopy and {{compared to a}} bulk crystal reference. Samples were subjected to oxygen or vacuum annealing and the effect on vacancy type defects was studied. Results indicate that after oxygen annealing the samples are dominated by cation vacancies, the concentration of which changes {{with the amount of}} doping. In highly Sn-doped In 2 O 3, however, these vacancies are not the <b>main</b> <b>compensating</b> acceptor. Vacuum annealing increases the size of vacancies in all samples, possibly by clustering them with oxygen vacancies. Peer reviewe...|$|R
5000|$|Lemon {{laws are}} American state laws {{that provide a}} remedy for purchasers of cars and other {{consumer}} goods in order to <b>compensate</b> for <b>products</b> that repeatedly fail to meet standards of quality and performance. Although there may be defective products of all sorts ranging from small electrical appliances to huge pieces of machinery, the term [...] "lemon" [...] is most often used to describe defective motor vehicles such as automobiles, trucks, SUVs, and motorcycles.|$|R
50|$|Independence: MFOs {{typically}} do not sell (traditional products {{that a family}} might typically encounter from a brokerage firm) and generally are not <b>compensated</b> for the <b>products</b> utilized by clients. MFOs usually follow a “service delivery model” holding themselves out as an objective provider of advice that places the interests of their clients first.|$|R
40|$|AbstractThis paper {{introduces}} the novel concept of fixture capability measure to determine fixture layout {{for the best}} assembly process yield by optimizing position of locators and reference clamps to <b>compensate</b> stochastic <b>product</b> variations and part deformation. This allows {{reducing the risk of}} product failures caused by product and process variation. The method is based on three main steps: (i) physics-based modelling of parts and fixtures, (ii) stochastic polynomial chaos expansion to calculate fixture capability, and (iii) fixture capability optimisation using surrogate modelling. The methodology is demonstrated and validated using the results of an aerospace wing sub-assembly joined by riveting technique...|$|R
50|$|He was Pelayo's <b>main</b> escalater player, <b>compensating</b> for {{his small}} size and weak left {{hand with a}} perfect {{placement}} on the court. Fans said that the vaqueta ball went to {{him as if he}} had a magnet, while his corner placements prevented the ball from reaching his opponents.|$|R
40|$|The {{quality of}} roll formed {{products}} {{is known to}} be highly dependent on the process design. In addition, unavoidable variations of material properties during mass production can have a significant deteriorating effect on the product quality. This study focuses on the question how to <b>compensate</b> for <b>product</b> defects while simultaneously minimizing the sensitivity for variation of material properties. This is achieved by using robust optimization techniques to determine the optimal process settings of adjustable tools in the final roll forming stand. The work covers both numerical analyses as well as experiments. Initial roll forming experiments of an Advanced High Strength Steel (AHSS) V-section profile showed a significant amount of longitudinal bow and springback in the final product. Finite Element (FE) simulations are subsequently performed to determine the relationship between adjustable process settings and uncontrollable variation of incoming material properties with respect to the product defects. The computationally expensive non-linear FE simulations are subsequently replaced by the best performing metamodel chosen from of a family of metamodels. Using these metamodels, the optimal robust process settings for the adjustable stand are determined and the effect on product quality analyzed. The results show that the effect of scattering material properties on the dimensional quality of the roll formed product is significant. Moreover, it is shown that the adjustment of the tooling in the final roll stand leads to a significantly improved <b>product</b> quality by <b>compensating</b> for <b>product</b> defects and minimizing the deteriorating effects of scattering variables...|$|R
5000|$|The party {{seeks to}} {{represent}} farmers and workers in Myanmar, and their <b>main</b> goals include <b>compensating</b> {{those who have}} lost land to the government, providing new equipment and technical upgrades to farmers, and redistributing corporate and government owned land to [...] "those farmers who are actually working on the land." ...|$|R
40|$|A single sheet tester having closed {{magnetic}} path (a closed type of SST) {{has a problem}} that measurement accuracy of magnetostriction is considerably affected by electromagnetic force between specimen and yoke. Therefore, an open type has been developed. In order to get uniform flux distribution in a sufficiently large region, a compensating magnetizing winding is installed, and a method of waveform control is investigated, in which applied voltages to <b>main</b> and <b>compensating</b> windings are adjusted individually. The effectiveness of the newly developed open type is demonstrated by measuring magnetostrictions of thin amorphous sheet as well as highly grain-oriented silicon steel sheet </p...|$|R
40|$|Ascending aortic {{aneurysm}} is a connective tissue disorder. Even though multiple novel gene mutations have been identified, risk profiling and diagnosis before rupture still represent a challenge. There are studies demonstrating shorter telomere lengths {{in the blood}} leukocytes of abdominal {{aortic aneurysm}} patients. The {{aim of this study}} was to measure whether relative telomere lengths are changed in the blood leukocytes of ascending aortic aneurysm patients. We also studied the expression of telomerase in aortic tissue samples of ascending aortic aneurysms. Relative lengths of leukocyte telomeres were determined from blood samples of patients with ascending aortic aneurysms and compared with healthy controls. Telomerase expression, both at the level of mRNA and protein, was quantified from the aortic tissue samples. Mean relative telomere length was significantly longer in ascending aortic aneurysm blood samples compared with controls (T/S ratio 0. 87 vs. 0. 61, p< 0. 001). Expressions of telomerase mRNA and protein were elevated in the aortic aneurysm samples (p< 0. 05 and p< 0. 01). Our study reveals a significant difference in the mean length of blood leukocyte telomeres in ascending aortic aneurysm and controls. Furthermore, expression of telomerase, the <b>main</b> <b>compensating</b> factor for telomere loss, is elevated at both the mRNA and protein level in the samples of aneurysmal aorta. Further studies will be needed to confirm if this change in telomere length can serve as a tool for assessing the risk of ascending aortic aneurysm...|$|R
40|$|Frameshift {{mutations}} {{are generally}} considered to be deleterious and of little importance for the evolution of novel gene functions. However, by screening an exhaustive set of vertebrate gene families, we found that, when a second transcript encoding the original gene <b>product</b> <b>compensates</b> for this mutation, frameshift mutations can be retained for millions of years and enable new gene functions to be acquired. status: publishe...|$|R
40|$|We {{propose a}} new {{instruction}} (FPADDRE) that computes the round-off error in floating-point addition. We explain how this instruction benefits high-precision arithmetic operations in applications where double precision is not sufficient. Performance estimates on Intel Haswell, Intel Skylake, and AMD Steamroller processors, {{as well as}} Intel Knights Corner co-processor, demonstrate that such an instruction would improve the latency of double-double addition by up to 55 % and increase double-double addition throughput by up to 103 %, with smaller, but non-negligible benefits for double-double multiplication. The new instruction delivers up to 2 x speedups on three benchmarks that use high-precision floating-point arithmetic: double-double matrix-matrix multiplication, <b>compensated</b> dot <b>product,</b> and polynomial evaluation via the compensated Horner scheme...|$|R
40|$|ABSTRACT. We {{present the}} {{seasonal}} {{cycle of the}} Antarctic surface energy balance (SEB) using 4 years (1998 – 2001) of automatic weather station (AWS) data. The four AWSs are situated on an ice shelf, in the coastal and inland katabatic wind zone and the interior plateau of Dronning Maud Land. To calculate surface temperature we use a SEB closure assumption for a surface skin layer. Modelled and observed surface have a root-mean-square difference of 1. 8 K at the plateau AWS (corresponding to an uncertainty in the SEB of 5 Wm– 2) and < 1 K (3 Wm– 2) at the other sites. The effect of wind-speed sensor freezing on the calculated SEB is discussed. At all sites the annual mean net radiation is negative and the near-surface air is on average stably stratified. Differences in the seasonal cycle of the SEB are mainly caused by the different wind climates at the AWS sites. In the katabatic wind zone, a combination of clear skies and strong winds forces a large wintertime turbulent transport of sensible heat towards the surface, which in turn enhances the longwave radiative heat loss. On the coastal ice shelf and on the plateau, strong winds are associated with overcast conditions, limiting the radiative heat loss and sensible heat exchange. During the short Antarctic summer, the net radiation becomes slightly positive at all sites. Away from the cold interior, the <b>main</b> <b>compensating</b> heat loss at the surface is sublimation. In the interior, summer temperatures are too low to allow significant sublimation to occur; here, surface heat loss is mainly due to convection. 1...|$|R
5000|$|In economics, {{compensating}} variation (CV) is {{a measure}} of utility change introduced by John Hicks (1939). 'Compensating variation' refers to the amount of additional money an agent would need to reach her initial utility after a change in prices, a change in product quality, or the introduction of new <b>products.</b> <b>Compensating</b> variation can be used to find the effect of a price change on an agent's net welfare. CV reflects new prices and the old utility level. It is often written using an expenditure function, e(p,u): ...|$|R
50|$|In 1978, Seiko {{released}} the Twin Quartz watch {{to address the}} impact of temperature on {{the frequency of the}} quartz crystal oscillator, which put a limitation on the accuracy of quartz watch. Seiko put a second crystal in the watch that's linked with a processor that detects the change in temperature and signals the <b>main</b> oscillator to <b>compensate.</b> The result was a huge improve in the watch’s accuracy from 5 seconds per month to 5 seconds per year.|$|R
3000|$|... {{meets the}} carbon {{emission}} target. In this case, export of carbon-intensive <b>products</b> <b>compensates</b> the domestic carbon emission reduction. Thus, one can observe that the accounting policy on “producer based” could cause “carbon import” and that, on the contrary, carbon control on “trade-adjusted” or “demand-based” emission accounting may cause larger “carbon export” effects which can harm the global carbon emission control target. It {{should be noted}} that the above two “leakage” patterns disappear when carbon emission target is agreed by all countries. Third, the outcome of partial participation seems small. These findings suggest how the carbon control measures should be implemented.|$|R
40|$|Enterovirus 71 {{is one of}} {{the major}} causative agents of hand, foot and mouth disease in {{children}} under six years of age. No vaccine or antiviral therapy is currently available. In this work, we found that the number of B cells was reduced in enterovirus 71 -infected mice. Deferoxamine, a marine microbial natural <b>product,</b> <b>compensated</b> for the decreased levels of B cells caused by enterovirus 71 infection. The neutralizing antibody titer was also improved after deferoxamine treatment. Furthermore, deferoxamine relieved symptoms and reduced mortality and muscle damage caused by enterovirus 71 infection. This work suggested that deferoxamine has the potential for further development as a B cell-immunomodulator against enterovirus 71...|$|R
40|$|Requirement of NO {{presence}} in feed is one barrier of anammox {{process for the}} application since NO is not a frequent composition in most wastewaters. In this study, anodic oxidation of NH to NO was realized in a single-chamber bioelectrochemical system with an anodic potential of - 0. 5 V. The NO <b>product</b> <b>compensated</b> its lack in the feed to accelerate the anammox. As a result, the anammox efficiency increased by at least 29. 2 %. When the potential was removed, the nitrogen removal in these two reactors had no significant differences. The SEM images and FISH analysis suggested that the abundance of anammox bacteria was obviously higher in R 2...|$|R
40|$|This paper {{estimates}} the effective market-access granted under NAFTA in textiles and apparel by combining two approaches. First, we estimate {{the effect of}} tariff preferences and rules of origin on the border prices of Mexican final goods exported to the US and of US intermediates exported to Mexico. We find that {{one third of the}} estimated rise in the border price of Mexican apparel <b>products</b> <b>compensates</b> for the cost of complying with NAFTA’s rules of origin. We also find that the price of US intermediates exported to Mexico is raised significantly by the presence of rules of origin downstream. Second, simulations from a structural model inspired by our econometric estimates, suggest little market-access improvement for Mexican exporters...|$|R
30|$|This paper {{presents}} a textline detection method for degraded historical documents. Our method follows a conventional two-step procedure that the binarization is first performed {{and then the}} textlines are extracted from the binary image. In order to address the challenges in historical documents such as document degradation, structure noise, and skews, we develop new methods for the binarization and textline extraction. First, we improve the performance of binarization by detecting the non-text regions and processing only text regions. We also improve the textline detection method by extracting <b>main</b> textblock and <b>compensating</b> the skew angle and writing style. Experimental {{results show that the}} proposed method yields the state-of-the-art performance for several datasets.|$|R
30|$|In {{order to}} briefly {{illustrate}} the compensation {{capability of the}} proposed control method in a multi-bus microgrid, a comparison for three different scenarios is presented below. In detail, for the first scenario, the multi-bus microgrid only has one UPQC installed at the <b>main</b> bus to <b>compensate</b> harmonics. For the second scenario, additional APFs are installed at all sub-bus to compensate the current harmonics raised by the local nonlinear loads. For the third scenario, the distributed converters could perform as the active power filters to compensate the current harmonics by using the proposed method in this paper, while eliminating the APF installed at each sub-bus.|$|R
40|$|In {{the work}} we present new laser {{measuring}} system for precise calibrations of length measuring transducers. This gauge is called nano-comparator because {{the resolution of the}} positioning of the measuring probe is in order of nanometers. The gauge works fully self-controlled and it is equipped by control software which is able to calibrate wide area of transducers. We put <b>main</b> stress to <b>compensating</b> of thermal dilatation of the gauge body and to eliminating of imperfection of linear guide ways which are used for positioning of the testing probe of the gauge. The work presents the first records of scale calibration of an incremental transducer...|$|R
40|$|This paper {{estimates}} the effective market access granted under NAFTA in textiles and apparel by combining two approaches. First, we estimate {{the effect of}} tariff preferences and rules of origin on the border prices of Mexican final goods exported to the US and of US intermediates exported to Mexico. We find that {{one third of the}} estimated rise in the border price of Mexican apparel <b>products</b> <b>compensates</b> for the cost of complying with NAFTA’s rules of origin. We also find that the price of US intermediates exported to Mexico is raised significantly by the presence of rules of origin downstream. Second, simulations from a structural model inspired by our econometric estimates, suggest little market access improvement for Mexican exporters. NAFTA; regional integration; rules of origin...|$|R
40|$|With female heterogamety, {{the primary}} sex ratio is {{determined}} at the first meiotic division shortly before ovulation, in birds. Up to now, {{there is no evidence}} of any physiological mechanism leading to hatching sex ratio deviations. The primary follicles in prophase I are already supplied with considerable amounts of yolk and chromosomal segregation distortion appears to be highly constrained by the mechanism of meiotic division. Also, genetic interests of gametes strongly oppose any maternal attempt at control of the sex ratio. Hence, sex ratio manipulation by preferential ovulation of Z- or W-ova is argued to be implausible. More probably, to avoid any further loss of investment, sex ratio adjustment should take place early after ovulation and fertilisation via sex-specific termination of embryonic development before initiation of egg shell formation. I suggest that the widely reported influence of the position within the egg laying sequence on offspring sex could potentially serve as an explanation for a wide range of sex ratio effects found in birds. The sequence effect, in turn, might be caused by changes in concentrations of yolk testosterone over the laying sequence. This effect could be sex-specific if non-dosage <b>compensated</b> gene <b>products</b> of Z-chromosomes counteracted any adverse effects on embryonic survival of deviating testosterone levels...|$|R
40|$|The Marco Legal Estable {{provides}} us with {{a rare opportunity to}} study a system of multi-output reimbursements applied to the distribution of electricity in Spain over an extensive period of time: 1988 – 1997. To do so, an analysis structure is proposed based on a Bennet-type indicator (1920), which allows us to identify the variations in the revenues associated with the activity of electricity distribution, for each of the companies and each one of the outputs. The Law recognized, regulated and <b>compensated</b> four <b>products</b> differently. This indicator is broken down into a quantity effect and a reimbursement effect. The quantity effect evaluates the impact on revenues of the variations in demand for each of the outputs, and the reimbursement effect the modifications in revenues due to the changes in the remuneration per product, which are based on standard costs. Modern production theory is used to explain the quantity indicator by means of a productivity and activity effect. Lastly, the productivity indicator is broken down into operating efficiency, allocative efficiency and technical change. To do so, a sequential-type technology is defined whose information begins in 1952. Mathematical programming techniques are used to resolve the proposed economic decomposition. electricity distribution regulation, Marco Legal Estable, electricity distribution revenues, Bennet indicator. ...|$|R
40|$|Interferometers are {{normally}} operated in environment-controlled optical laboratories because vibrations will induce errors in measurement results. In order {{to extend the}} application of interferometry to shop floor inspection, two methods are adapted: one method is to introduce a reference interferometer and vibration compensation system to the <b>main</b> interferometer, to <b>compensate</b> for the environmental disturbance; and the other method is to realize the data sample in just one image shot. Each method has its own applications. With the advances of these technologies, the use of interferometry as a highly accurate and fast measurement method will become more common in shop floor measurements and inspections. Keywords: online/in-process measurement, surface measurement, environmental disturbance, vibration compensation, reference interferometer, common pat...|$|R
40|$|Subsurface drip {{distribution}} {{is an important}} on-site wastewater treatment technique which is widely used with various soil types and restricted site conditions. It can distribute pretreated wastewater uniformly into soil. Some recent field applications showed low application uniformities, which was reflected in overloading of the field near the supply manifold while low emitter discharge rates occurred {{at the end of}} lateral. Designers are seeking appropriate operation pressures and drip zone configurations to improve system application uniformity. This research was conducted to test some popular wastewater drip products in both lab and field-scale experiments. The first goal {{of this study was to}} evaluate the performance of five subsurface drip products under eight operational pressures ranging from 0 to 310 kPa (45 psi). After evaluation of each group of 60 emitters, results showed that Netafim Bioline pressure compensating (PC) emitters exhibited a uniformity coefficient (UC) of 95 % with a coefficient of variance (Cv) of 4. 9 %. The average UC of Geoflow Wasteflow products is 94. 4 % and Cv value is 6. 8 %. Flow rate and pressure relationships (Q-H curves) were developed for each drip emitter tested. By analyzing low and normal operational pressure ranges, Q-H curves were fitted to the data and resulted in R 2 values ranging from 1. 000 to 0. 414. Geoflow pressure <b>compensating</b> <b>products</b> possess the features of non-pressure compensating emitters under low pressure head. Netafim PC products are characterized as pressure compensating over the full range of operational pressures and emit water with nominal uniformity during low pressure range. To evaluate drip zone configurations with respect to distribution uniformity, a field-scale experiment was set up and three drip tubing products were tested in different dosing and operation schemes. Three factors of wastewater drip system design were tested. System operation pressure (138 kPa/ 20 psi and 276 kPa/ 40 psi); different pressure control components (pressure regulator/recirculation valve) and schemes (continuous flushing/intermittent flushing); and supply line length (7. 6 m/ 25 ft, 15. 2 m/ 50 ft, and 30. 4 m/ 100 ft) were evaluated to compare their influence on water application uniformity. It was concluded that, for Geoflow PC and NPC products, among all three factors, system operational pressure has the greatest effect on drip system application uniformity; supply line length has the least influence. For Netafim PC tubing, pressure control scheme has the greatest effect on drip system application uniformity; supply line length has the least influence. The optimal combination of the three factors could save more than 10 minutes of dosing time to meet the required dosing application uniformity. An engineering computation example on system fill time was presented and compared to experimental results to demonstrate the possible gap between typical design processes and real field application...|$|R
40|$|Sphingolipids {{comprise}} a large, widespread family of complex eucaryotic-membrane constituents of poorly defined function. The yeast Saccharomyces cerevisiae is particularly suited for studies of sphingolipid function {{because it contains}} {{a small number of}} sphingolipids and is amenable to molecular genetic analysis. Moreover, it is the only eucaryote in which mutants blocked in sphingolipid biosynthesis have been isolated. Beginning with a nonreverting sphingolipid-defective strain that requires the addition of the long-chain-base component of sphingolipids to the culture medium for growth, we isolated two strains carrying secondary, suppressor mutations that permit survival in the absence of exogenous long-chain base. Remarkably, the suppressor strains made little if any sphingolipid. A study of how the suppressor gene <b>products</b> <b>compensate</b> for the lack of sphingolipids may reveal the function(s) of these membrane lipids in yeast cells...|$|R
50|$|The mosque is on a {{very high}} platform. The Baitul Mukarram Mosque’s {{building}} is eight storied and 99 feet high from the ground level. According to the original plan, the main entrance of the mosque was {{to be on the}} eastern side. The 'shaan' on the east is 29,000 square feet with ablution space on its south and north sides. Ablution or Wu’du Place cached an important part when the Baitul Mukarram was begun. The absence of a dome on the <b>main</b> building is <b>compensated</b> by the two superficial domed entrance porticoes, one on the south, and the other on the north. The height of these porticoes consists of three rabbit's foot shaped arches, the middle of which is bigger than the rest.|$|R
40|$|The {{objective}} {{of this research is}} to begin exploring the welfare effects of new food product introductions and to determine whether such effects vary depending on the income classification of the customer base to which the products are introduced. In other words, when new products are introduced to both high- and low-income markets, is there a significant difference in estimated welfare effects that can be attributed to differences in consumer-base income levels? In an application involving new bottled juice introductions, we do, in fact, find notable differences in welfare effects accruing to different income-class cohorts. Our results provide important evidence of the need for an even greater understanding of new product welfare effects and how these effects vary across population groups and certain new <b>product</b> claims. <b>compensating</b> variation, differentiated <b>products,</b> distance metrics, new product valuation, retailing, Consumer/Household Economics,...|$|R
40|$|One of {{the main}} {{problems}} for the deep-drawing process is springback. Generally, the deep-drawing tools are directly derived from {{the shape of the}} product. However, when the press is opened after forming, the product will spring back due to internal stresses. In order to produce a geometrically accurate product, the geometry of the tools is compensated. The goal of this project is to develop an algorithm to perform this task automatically, with the use of FE deep-drawing simulations. In this report the two main compensation algorithms are discussed that are mentioned in literature. Springback compensation is always the last step in the process planning of a deep drawn product. It is not always needed, in some cases the product can be made to fit the assembly by simply pushing it back into the right shape. To make the right decision, springback has to be measured and evaluated properly, which can be hard for complex shaped products. Today, manual springback compensation is applied, based on the measurements on prototype products. This is a time consuming process for which a lot of experience is needed. The use of FE simulations can speed up this process, but to fully use the detailed results of such a simulation, a compensation algorithm has to be used. The first algorithm is called the smooth displacement adjustment (SDA) method. The method is based on a direct comparison of the desired shape and the shape after springback. The idea is to compensate springback by reversing the springback deformation field and applying this to the product geometry. The method can also be applied iteratively by using the shape deviation field between the springback (actual) geometry and the reference (desired) geometry. A smoothing/extrapolation function has been added, so the new toolset can be derived directly from this <b>compensated</b> <b>product</b> geometry. The method has been tested on a real industrial part, a trunk-lid inner frame that has been adopted as a benchmark part for the NUMISHEET 2005 conference. The method was very successful, after compensation the mean shape deviation was lowered by 70 %. However, some large shape deviation was still present in the product flanges, showing that there is still room for improvement. The second algorithm is called the springforward (SF) method. The principle of the SF method is to compensate springback with the internal stresses that cause it, instead of applying direct geometric optimization, such as the DA method. The method was applied to an academic process, the plastic bending of a strip. It is explained that with the current definition of the algorithm, iterative application is not useful. This problem is solved by adding a push-back stage, so the compensation is linked to the desired geometry again. However, the actual calculation of the compensated geometry suffers from large principal and numerical problems, as was demonstrated using a simple industrial product. ...|$|R
40|$|ABSTRACT- The minimum {{absolute}} temperatures {{from the}} Cotnari vineyard fell below the endurance {{limit of the}} varieties during the winter 2005 / 2006, until- 26 oC (on 19 February, 2006) and they affected the main buds at a proportion of 76. 7 % {{in the case of}} Fetească albă variety, and 74. 1 % in the case of Francuşă variety. The loss of the <b>main</b> buds was <b>compensated</b> by the fructification cutting, the viability and fertility of the secondary buds, so that the calculated production potential could reach 9693 kg/hectare in the case of Grasă de Cotnari variety, 14348 kg/hectare in the case of Fetească albă variety, 17684 kg/hectare in the case of Tamâioasa romanească variety and 12363 kg/hectare in the case of Fracuşă variety. Key words: negative temperatures, bud viability, production potential...|$|R
40|$|A sensor’s {{model for}} {{resolver}} manufacturers is developed. This model <b>compensates</b> deviations in <b>product</b> characteristics {{due to the}} variability of the assembly process, through computed corrections on the production’s controllable variables - winding parameters. The model follows a two-step strategy. On a first step a traditional transformer’s model computes the resolver’s nominal physical parameters: electric and magnetic resistances and leakage impedances of primary and secondary windings. On a second step a linear model computes the increments on the controllable variables to compensate small deviations in design assumptions, due to the variability of the manufacturing processes. In this model the in-plant controllable variables are adjusted (number of windings and wire diameters). The incremental model develops a set of correction tools that allows the resolver manufacturer to change some controllable variables in order to correct assembled resolvers that without any action would be scrap to the production line...|$|R
40|$|Computer-generated {{hologram}} (CGH) is {{an effective}} way to compensate wavefront aberration in null test of aspheric surfaces and freeform surfaces. Our strategies of CGH design for 600 mm diameter SiC primary mirror surface figure testing are presented, and an experiment demonstrating the compensation test results of CGH is reported. We design a CGH including two sections on the same substrate in order to align the CGH to the incident wavefront: <b>main</b> section for <b>compensating</b> wavefront in null test, alignment section for adjusting the relative position between CGH and interferometer. In order to isolate different orders of diffraction, we used power carrier to make different orders of diffraction come to focus at different position along the axis to avoid ghost reflections. We measured the 600 mm diameter SiC primary mirror using this CGH, and the surface test result is 0. 033 lambda rms. </p...|$|R
