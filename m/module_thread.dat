3|23|Public
2500|$|A major error, {{caught by}} Fuller himself, {{involved}} a misapplication of his Synergetics Constant in Synergetics 1, {{which led to}} the mistaken belief he had discovered a radius 1 sphere of 5 tetravolumes. He provided a correction in Synergetics 2 in the form of his T <b>module</b> <b>thread.</b> (986.206 - 986.212) ...|$|E
40|$|These {{controllers}} include smooth pursuit visual tracking, inverse kinematic reaching, {{and operation}} space {{control of the}} arm [77]. This layer also provides TCP/IP interprocess communication among the Linux cluster’s 1 Gb LAN. We use the Yarp software package developed by Metta and Fitzpatrick [91]. We implemented a custom python-Yarp interface, allowing us to dynamically define and transmit data structures between processes at rates up to 100 hz. Additionally, two FireWire framegrabbers provide synchronized image pairs to the cluster. Finally, all image and sensory data are timestamped using the hardware clock from the CANbus PCI card. This ensures synchronization of the data up to the transmit time of the 1 Gb LAN. 4. 7. 4 Behavior Layer The behavior layer implements the robot’s visual processing, learning, and task behaviors. These algorithms are run within our behavior-based architecture named Slate. 4. 8 Slate: A Behavior Based Architecture We have developed a behavior based architecture named Slate. What is meant by a robot architecture? According to Mataric [90], An architecture provides a principled way of organizing a control system. However, {{in addition to providing}} structure, it imposes constraints on the way the control problem can be solved. Following Mataric, Arkin [4] notes the common aspects of behavior-based architectures: • emphasis on the importance of coupling sensing and action tightly • avoidance of representational symbolic knowledge • decomposition into contextually meaningful units Roboticists have developed many flavors of behavior based architectures. We refer to Arkin for a review [4]. Loosely stated, Slate is a lightweight architecture for organizing perception and control. It is implemented as a programming abstraction in Python that allows one to easily define many small computational threads. These threads can run at parameterized 66 slate arbitrator thread threa s d fs slate <b>module</b> <b>thread</b> thread slate thread s a s proprioception yarp communication slate scheduler process module threa...|$|E
50|$|RScheme {{implements}} all of R4RS except transcript-on and transcript-off, {{and all of}} R5RS except define-syntax. In addition, RScheme has {{a reflective}} object system, many operating system services, <b>modules,</b> <b>threads,</b> and other systems programming features, including the ability to integrate with and compile to C code.|$|R
5000|$|In {{versions}} 0.8.x, {{the separate}} <b>Threading</b> <b>module</b> provides full multithreading to scripts, while starting from version 0.9.x the [...] "Threading" [...] module is integrated {{in the standard}} <b>modules</b> and <b>threading</b> support is provided directly inside the main engine. The multithreading model is agent oriented, and data across threads must be explicitly shared through several possible sharing mechanisms. Each thread runs a different virtual machine, which runs separately from any operation happening in the others (as i.e. garbage collection). This allows for efficient parallel processing and zero contention outside {{the control of the}} script developer.|$|R
5000|$|In Python version 2.4 or later, {{local class}} in <b>threading</b> <b>module</b> {{can be used}} to create thread-local storage.import threadingmydata = threading.local (...) mydata.x = 1 ...|$|R
50|$|AMD Bulldozer {{microarchitecture}} FlexFPU and Shared L2 cache are multithreaded but integer cores in <b>module</b> {{are single}} <b>threaded,</b> {{so it is}} only a partial SMT implementation.|$|R
40|$|The {{aim of this}} Mini-Project, {{based at}} the University of Manchester, was to produce {{guidance}} for Engineering schools in designing <b>modules</b> or <b>threads</b> to embed sustainable development within the curriculum. The project undertook a modified ‘Delphi’ study to bring convergence of the views of experts {{from a range of}} engineering disciplines on sustainable development in the engineering curriculu...|$|R
5000|$|Note {{that without}} precautions, this {{approach}} can be detected by the target process due to the DLL_THREAD_ATTACH notifications sent to every loaded <b>module</b> as a <b>thread</b> starts.|$|R
40|$|In this article, a denotational {{definition}} of synchronous subset of SystemC is proposed. The subset treated includes <b>modules,</b> processes, <b>threads,</b> wait statement, ports and signals. We propose formal model for System C delta delay. Also, we give a complete semantic definition for the language's two-phase scheduler. The proposed semantic can constitute {{a base for}} validating the equivalence of synchronous HDL subsets...|$|R
40|$|Oberon [WiGu 89] is a modular, {{single-threaded}} {{operating system}} for single-user operation of stand-alone workstations. It {{is used in}} daily {{work as well as}} in programming courses. As a stand-alone system, most Oberon implementations lack network support. This report describes two modules, which extend Oberon with concurrency and network capabilities. <b>Module</b> <b>Threads</b> implements the abstraction of threads, as well as mechanisms for thread synchronisation. Threads are scheduled preemptively and are useful to run network servers in the background. Module Network offers an abstract way to access networks. It is an abstraction corresponding to the transport layer of the OSI model [Tan 89]. Network offers multiple logical hosts on one physical site and channels for communications between hosts. Actual network protocols have to be supplied in other modules. Channels can be extended and adapted to the needs of clients and servers. Contents 1 Introduction 2 Threads 2. 1 Basic characteristics 2. 2 Pro [...] ...|$|R
40|$|In current architectures, page {{tables are}} the {{fundamental}} mechanism that allows contemporary OSs to isolate user processes, binding each thread {{to a specific}} page table. A thread cannot therefore directly call another process's function or access its data; instead, the OS kernel provides data communication primitives and mediates process synchronization through inter-process communication (IPC) channels, which impede system performance. Alternatively, the recently proposed CODOMs architecture provides memory protection across software <b>modules.</b> <b>Threads</b> can cross <b>module</b> protection boundaries inside the same process using simple procedure calls, while preserving memory isolation. We present dIPC (for "direct IPC"), an OS extension that repurposes and extends the CODOMs architecture to allow threads to cross process boundaries. It maps processes into a shared address space, and eliminates the OS kernel from the critical path of inter-process communication. dIPC is 64. 12 × faster than local remote procedure calls (RPCs), and 8. 87 × faster than IPC in the L 4 microkernel. We show that applying dIPC to a multi-tier OLTP web server improves performance by up to 5. 12 × (2. 13 × on average), and reaches over 94...|$|R
50|$|The modular {{architecture}} consists of multithreaded shared L2 cache and FlexFPU, which uses simultaneous multithreading. Each physical integer core, two per <b>module,</b> is single <b>threaded,</b> {{in contrast with}} Intel's Hyperthreading, where two virtual simultaneous threads share the resources of a single physical core.|$|R
30|$|The plug-in linux_pslist {{extracts}} a list {{of running}} processes. The resulting entries of our measurements differed between the dump file (230 entries) and the cold boot analysis (225 entries) by solely five more threads. This comes from the LiME kernel <b>module</b> creating these <b>threads</b> during the acquisition process. The analysis with the BMA took 24.23 s, whereas the LiME dump analysis took 3.54 s.|$|R
40|$|Rapid {{reconstruction}} of multidimensional image {{is crucial for}} enabling real-time 3 D fluorescence imaging. This becomes a key factor for imaging rapidly occurring events in the cellular environment. To facilitate real-time imaging, we have developed a graphics processing unit (GPU) based real-time maximum a-posteriori (MAP) image reconstruction system. The parallel processing capability of GPU device that consists {{of a large number}} of tiny processing cores and the adaptability of image reconstruction algorithm to parallel processing (that employ multiple independent computing <b>modules</b> called <b>threads)</b> results in high temporal resolution. Moreover, the proposed quadratic potential based MAP algorithm effectively deconvolves the images as well as suppresses the noise. The multi-node multi-threaded GPU and the Compute Unified Device Architecture (CUDA) efficiently execute the iterative image reconstruction algorithm that is ≈ 200 -fold faster (for large dataset) when compared to existing CPU based systems...|$|R
40|$|We {{present a}} new visual {{paradigm}} for Visualization Systems, inspired by stack-based programming. Most current implementations of Visualization systems {{are based on}} directional graphs. However directional graphs as a visual representation of execution, though initially quite intuitive, quickly grow cumbersome and difficult to follow under complex examples. Our system presents the user with a simple and compact methodology of visually stacking actions directly on top of data objects {{as a way of}} creating filter scripts. We explore and address extensions to the basic paradigm to allow for: multiple data input or data output objects to and from execution action <b>modules,</b> execution <b>thread</b> jumps and loops, encapsulation, and overall execution control. We exploit the dynamic nature of current computer graphic interfaces by utilizing features such as drag-and-drop, color emphasis and object animation to indicate action, looping, message/parameter passing; to furnish an overall better understanding of the resulting laid out execution scripts...|$|R
40|$|Although platform-independent runtime {{systems for}} {{parallel}} programming languages are desirable, {{the need for}} low-level optimizations usually precludes their existence. This is because most optimizations involve some combination of low-level communication and low-level threading, the product of which is almost always platform-dependent. We propose {{a solution to the}} threading half of this dilemma by using a thread package, that allows fine-grain control over the behavior of the threads while still providing performance comparable to hand-tuned, machine-dependent thread packages. This makes it possible to construct platform-independent <b>thread</b> <b>modules</b> for parallel runtime systems and, more importantly, to optimize them. ...|$|R
40|$|A three-channel data {{acquisition}} system was developed for the NASA Multi-Frequency Radar (MFR) system. The system {{is based on a}} commercial-off-the-shelf (COTS) industrial PC (personal computer) and two dual-channel 14 -bit digital receiver cards. The decimated complex envelope representations of the three radar signals are passed to the host PC via the PCI bus, and then processed in parallel by multiple cores of the PC CPU (central processing unit). The innovation is this parallelization of the radar data processing using multiple cores of a standard COTS multi-core CPU. The data processing portion of the {{data acquisition}} software was built using autonomous program <b>modules</b> or <b>threads,</b> which can run simultaneously on different cores. A master program module calculates the optimal number of processing threads, launches them, and continually supplies each with data. The benefit of this new parallel software architecture is that COTS PCs can be used to implement increasingly complex processing algorithms on an increasing number of radar range gates and data rates. As new PCs become available with higher numbers of CPU cores, the software will automatically utilize the additional computational capacity...|$|R
40|$|Our goal is {{to develop}} a flexible, customizable, and {{practical}} multi-core testbed based on an Intel desktop computer that can be utilized to assist the theoretical research on power/thermal aware resource management in design of computer systems. By integrating different <b>modules,</b> i. e. <b>thread</b> mapping/scheduling, processor/core frequency and voltage variation, temperature/power measurement, and run-time performance collection, into a systematic and unified framework, our testbed can bridge the gap between the theoretical study and practical implementation. The effectiveness for our system was validated using appropriately selected benchmarks. The importance of this research is that it complements the current theoretical research by validating the theoretical results in practical scenarios, which are closer to that in the real world. In addition, by studying the discrepancies of results of theoretical study and their applications in real world, the research also aids in identifying new research problems and directions...|$|R
40|$|Abstract. Following the scenario-based {{approach}} to programming which centered around live sequence charts (LSCs), we propose a general {{approach to}} software development in Java. A program {{will consist of}} <b>modules</b> called behavior <b>threads</b> (b-threads), each of which independently describes a scenario that may cross object boundaries. We identify a protocol and a coordination mechanism that allow such behavioral programming. Essentially, runs of programs are sequences of events that result from three kinds of b-thread actions: requesting that events be considered for triggering, waiting for triggered events, and blocking events requested by other b-threads. The coordination mechanism synchronizes and interlaces b-threads execution yielding composite, integrated system behavior. The protocol idioms and the coordination mechanism of b-threads are implemented as a Java library called BPJ. Throughout the exposition we illustrate benefits of the approach and discuss the merits of behavioral programming as a broad, implementation-independent paradigm. ...|$|R
40|$|Modern malware like Stuxnet {{is complex}} and {{exploits}} multiple vulnerabilites in not only the user level processes but also the OS kernel to compromise a system. A main trait of such exploits is manipulation of control flow. There is a pressing need to diagnose such exploits. Existing solutions that monitor control flow either have large overhead or high false positives and false negatives, hence making their deployment impractical. In this paper, we present Total-CFI, an efficient and practical tool built on a software emulator, capable of exploit detection by enforcing system-wide Control Flow Integrity (CFI). Total-CFI performs punctual guest OS view reconstruction to identify key guest kernel semantics like processes, code <b>modules</b> and <b>threads.</b> It incorporates a novel thread stack identification algorithm that identifies the stack boundaries for different threads in the system. Furthermore, Total-CFI enforces a CFI policy- a combination of whitelist based and shadow call stack based approaches to monitor indirect control flows and detect exploits. We provide a proof-of-concept implementation of Total-CFI on DECAF, built on top of Qemu. We tested 25 commonly used programs and 7 recent real world exploits on Windows OS and found 0 false positives and 0 false negatives respectively. The boot time overhead {{was found to be}} no more than 64. 1 % and the average memory overhead was found to be 7. 46 KB per loaded module, making it feasible for hardware integration...|$|R
40|$|Purpose. Reference data in {{technical}} literature about such characteristics as stiffness and elasticity of rail threads at torsion are rather contradictory. This {{is due to}} the absence of correct analytical solution of this task and because of complexity of experimental studies of this problem under combined action of vertical and horizontal lateral forces. The article presents the new method of solving the task of calculation the real values of stiffness and elasticity <b>modules</b> of rail <b>thread</b> when torsion under combined action of vertical and horizontal lateral forces. Methodology. The complex method of solving the problem was used in the paper. It includes the theoretical part and the results of the experiment. Using the experiment the characteristics of horizontal lateral stiffness of the rail threads of the head and bottom at different constructions of the modern rail fastenings was measured. The second task of determination of the real values of elasticity and stiffness modulus of the rail thread when torsion was solved by the theoretical methods. Findings. New values of stiffness characteristics and elasticity <b>module</b> of rail <b>thread</b> when torsion for the modern rail constrictions Р 65, UIC 60, Р 50 and the rail fastenings of the types КПП, КБ, ДО, under combined action of vertical and horizontal forces and torsion were obtained. Originality. For the first time in domestic research it was carried out the experimental and theoretical solution of the task for determination of the real values of the stiffness and elasticity modulus of rail thread when torsion under combined action of vertical and horizontal forces of the wheel loadings. The solution is represented in the functional dependence on the correlation of vertical and horizontal forces; acting together. The solution is carried out for the modern designs of the rails of domestic standard P 65, P 50, P 43 and international standard UIC 60. Practical value. The obtained results make it possible to carry out calculations of the real acting strains and deformations in the rails of different types under the joint action of vertical and horizontal forces for railway track on concrete and wooden sleepers with different designs of rigid and elastic rail fastenings КБ, КПП, Д 0 with higher accuracy as compared to the current calculation methodology...|$|R
40|$|Abstract. In {{behavioral}} programming, {{a program}} consists of separate <b>modules</b> called behavior <b>threads,</b> each representing {{a part of}} the system’s allowed, necessary or forbidden behavior. An execution of the program is a series of synchronizations between these threads, where at each synchronization point an event is selected to be carried out. As a result, the execution speed is dictated by the slowest thread. We propose an eager execution mechanism for such programs, which builds upon the realization that it is often possible to predict the outcome of a synchronization point even without waiting for slower threads to synchronize. This allows faster threads to continue running uninterrupted, whereas slower ones catch up at a later time. Consequently, eager execution brings about increased system performance, better support for the modular design of programs, and the ability to distribute programs across several machines. It also allows to apply behavioral programming to a variety of problems that were previously outside its scope. We illustrate the method by concrete examples, implemented in a behavioral programming framework in C++...|$|R
40|$|Traditionally, HEP {{experiments}} {{exploit the}} multiple cores in a CPU by having each core process one event. However, future PC designs {{are expected to}} use CPUs which {{double the number of}} processing cores {{at the same rate as}} the cost of memory falls by a factor of two. This effectively means the amount of memory per processing core will remain constant. This is a major challenge for LHC processing frameworks since the LHC is expected to deliver more complex events (e. g. greater pileup events) in the coming years while the LHC experiment's frameworks are already memory constrained. Therefore in the not so distant future we may need to be able to efficiently use multiple cores to process one event. In this presentation we will discuss a design for an HEP processing framework which can allow very fine grained parallelization within one event as well as supporting processing multiple events simultaneously while minimizing the memory footprint of the job. The design is built around the libdispatch framework created by Apple Inc. (a port for Linux is available) whose central concept is the use of task queues. This design also accommodates the reality that not all code will be thread safe and therefore allows one to easily mark modules or sub parts of <b>modules</b> as being <b>thread</b> unsafe. In addition, the design efficiently handles the requirement that events in one run must all be processed before starting to process events from a different run. After explaining the design we will provide measurements from simulating different processing scenarios where the processing times used for the simulation are drawn from processing times measured from actual CMS event processing...|$|R
40|$|Nuclear {{magnetic}} resonance (NMR) spectroscopy technique is becoming exceedingly significant {{due to its}} capability of studying protein structures in solution. However, NMR protein structure determination has remained a laborious and costly process until now, even {{with the help of}} currently available computer programs. After the NMR spectra are collected, the main road blocks to the fully automated NMR protein structure determination are peak picking from noisy spectra, resonance assignment from imperfect peak lists, and structure calculation from incomplete assignment and ambiguous nuclear Overhauser enhancements (NOE) constraints. The goal of this dissertation is to propose error-tolerant and highly-efficient methods that work well on real and noisy data sets of NMR protein structure determination and the closely related protein structure prediction problems. One major contribution of this dissertation is to propose a fully automated NMR protein structure determination system, AMR, with emphasis on the parts that I contributed. AMR only requires an input set with six NMR spectra. We develop a novel peak picking method, PICKY, to solve the crucial but tricky peak picking problem. PICKY consists of a noise level estimation step, a component forming step, a singular value decomposition-based initial peak picking step, and a peak refinement step. The first systematic study on peak picking problem is conducted to test the performance of PICKY. An integer linear programming (ILP) -based resonance assignment method, IPASS, is then developed to handle the imperfect peak lists generated by PICKY. IPASS contains an error-tolerant spin system forming method and an ILP-based assignment method. The assignment generated by IPASS is fed into the structure calculation step, FALCON-NMR. FALCON-NMR has a <b>threading</b> <b>module,</b> an ab initio module, an all-atom refinement module, and an NOE constraints-based decoy selection module. The entire system, AMR, is successfully tested on four out of five real proteins with practical NMR spectra, and generates 1. 25 A, 1. 49 A, 0. 67 A, and 0. 88 A to the native reference structures, respectively. Another contribution of this dissertation is to propose novel ideas and methods to solve three protein structure prediction problems which are closely related to NMR protein structure determination. We develop a novel consensus contact prediction method, which is able to eliminate server correlations, to solve the protein inter-residue contact prediction problem. We also propose an ultra-fast side chain packing method, which only uses local backbone information, to solve the protein side chain packing problem. Finally, two complementary local quality assessment methods are proposed to solve the local quality prediction problem for comparative modeling-based protein structure prediction methods...|$|R

