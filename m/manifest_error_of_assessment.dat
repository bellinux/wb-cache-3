0|10000|Public
5000|$|On February 9, 2011 [...] Boris Boillon is {{appointed}} ambassador of France in Tunis {{instead of}} Pierre Ménat {{that the costs}} <b>of</b> <b>errors</b> <b>of</b> <b>assessment</b> by the French foreign policy at the Tunisian revolution.|$|R
40|$|Parties on {{the losing}} side in {{international}} arbitration have long argued that an <b>error</b> <b>of</b> law is a defence to the enforcement of foreign awards. Citing article V(2) (b) of the New York Convention, such parties have argued that a <b>manifest</b> <b>error</b> <b>of</b> law {{is a violation of}} public policy. While national courts have generally paid little heed to this line of argument, this article seeks to raise the possibility that there may yet be the exceedingly rare instance in which a court should preclude enforcing an award marred by a hideous <b>error</b> <b>of</b> law. Limited review of an arbitrator 2 ̆ 7 s application of the law in international arbitrations should exist where enforcing the award would be contrary to the forum 2 ̆ 7 s most basic notions of justice. By way of case law, natural justice and general principles of arbitral law, this article argues that if indeed such egregious awards arise, they should be denied enforcement under the Convention...|$|R
2500|$|The court {{declared}} her innocent on 7 July 1456 by annulling her sentence. They {{declared that}} Joan had been tried {{as a result}} of 'false articles of accusation'. Those articles and Cauchon's sentence were to be torn out of a copy of the proceedings and burnt by the public executioner at Rouen. The Archbishop of Rheims read out the appellate court's verdict: [...] "In consideration of the request of the d'Arc family against the Bishop of Beauvais, the promoter of criminal proceedings, and the inquisitor of Rouen... in consideration of the facts.... We, in session of our court and having God only before our eyes, say, pronounce, decree and declare that the said trial and sentence (of condemnation) being tainted with fraud (dolus malus), calumny, iniquity and contradiction, and <b>manifest</b> <b>errors</b> <b>of</b> fact and of law... to have been and to be null, invalid, worthless, without effect and annihilated... We proclaim that Joan did not contract any taint of infamy and that she shall be and is washed clean of such".|$|R
40|$|RUSSELL SCOTT, by {{and through}} Agent Russell-Emanuel :Scott, Appellant, {{petitions}} the Utah Court Of Appeals to rehear the Memorandum Decision of April 22, 2004 pursuant Utah Rules of Appellate Procedure, Rule 35 and in accord Utah R. App. P., Rule 10 (a) (3) for rehearing and reviewing said decision which is subject for rehearing/review {{on the basis}} <b>of</b> <b>manifest</b> <b>error(s)</b> in want <b>of</b> subject matter jurisdiction...|$|R
40|$|This study {{examines}} {{the limits of}} global corruption indicators based on experts' perceptions. It draws on a wave of original surveys conducted in eight African countries that combined two types of approaches. The first approach covers a sample of over 35, 000 people and uses experience-based questions to measure petty bureaucratic corruption. The second (Mirror Survey) reports 350 experts' opinions. A comparison of these two sources paints a clear picture <b>of</b> the experts' <b>errors</b> <b>of</b> <b>assessment.</b> We also find evidence for ideological biases, with experts tending to rank countries {{based on their own}} political preferences, and the existence of an erroneous implicit cultural model of "how Africa works"...|$|R
5000|$|During the {{demolition}} of Florence H., it was erroneously assumed that the explosive, submerged for more than 13 years, was not reactive. On 8 December 1930, {{as a result of}} a demolition charge, the payload inside the ship also exploded. The Artiglio, positioned by a fatal <b>error</b> <b>of</b> <b>assessment</b> at an insufficient distance, was destroyed by the explosion and sank in the Bay of Biscay between Belle Île and Houat, Morbihan, France. Twelve crew members died in the accident, including divers Alberto Gianni, Aristide Franceschi, and Alberto Bargellini, all from Viareggio, and the ship's commander, Captain Bertolotto di Camogli. [...] The survivors were rescued by the Rostro.|$|R
40|$|Summary This study {{examines}} {{the limits of}} global corruption indicators based on experts' perceptions. It draws on a wave of original surveys conducted in eight African countries that combined two types of approaches. The first approach covers a sample of over 35, 000  people and uses experience-based questions to measure petty bureaucratic corruption. The second (Mirror Survey) reports 350  experts' opinions. A comparison of these two sources paints a clear picture <b>of</b> the experts' <b>errors</b> <b>of</b> <b>assessment.</b> We also find evidence for ideological biases, with experts tending to rank countries {{based on their own}} political preferences, and the existence of an erroneous implicit cultural model of "how Africa works". corruption governance perception sub-Saharan Africa expert surveys household surveys...|$|R
40|$|A {{compromise}} {{is the final}} decision adopted by mediating between two or more opposite proposals. A compromise can be achieved in various ways, and all ways have been tried in Tunisia {{over the last few}} years, starting from 2011, when the Arab world entered a cycle of generalized revolution. A {{compromise is}} historic when in a society the trade-off is decided by a number of influential political actors and comports with the major political and social guidelines or even fits into a historical context in rapid evolution (marked by sudden and massive changes). It is therefore a fundamental choice of orientation which cannot be considered ordinary administration. A profusion <b>of</b> approximations, <b>errors</b> <b>of</b> <b>assessment,</b> and "clichés" have been circulating about the revolution, particularly about the one that took place in Tunisia. In an effort to clear away these misunderstandings, this essay offers some observations on the conditions that bring about a revolution...|$|R
40|$|Summary: It {{is argued}} that {{subsidiarity}} should be interpreted, {{in accordance with the}} principle of effectiveness, as requiring that the Community should only act where the objectives of the proposed action can only be achieved at Community level. Subsidiarity has not so far been an effective brake on action by the European institutions, and the Court’s scrutiny of Community acts for compliance with subsidiarity has been undemanding. The Constitution Treaty seeks to confi rm and strengthen application of subsidiarity. Monitoring by national parliaments, and in particular the possibility for one third to object to a proposal on subsidiarity grounds, thus “showing a yellow card,” could lead to improved compliance with subsidiarity by the lawmaking institutions; and the “yellow card” procedure could change the dynamics of judicial enforcement of subsidiarity. Where national parliaments “raised a yellow card,” but the Commission maintained its draft, one possibility (which the present writer would advocate) would be that in any subsequent judicial proceedings the Court of Justice would require the Commission to demonstrate that the national parliaments had made a <b>manifest</b> <b>error</b> <b>of</b> appraisal in objecting to the draft act on subsidiarity grounds. Giving teeth to subsidiarity by entrusting national parliaments with responsibility for monitoring its application, and reinforcing that responsibility with an appropriate judicial response from the Court of Justice, could enhance the sense of “ownership” of the European project at national level. Although it appears unlikely that the Constitution Treaty will come into force, that fact need not prevent the introduction by other means of subsidiarity monitoring by national parliaments, and the adoption by the Court of Justice of the approach indicated...|$|R
30|$|The {{demand for}} {{automated}} assessment and certification systems has grown {{due to the}} fact that it would be extremely complex and hard to assess the huge amount of candidates manually by humans. This demand is confirmed by both employability and institutional needs. This situation drives the design <b>of</b> automated <b>assessment</b> systems in order to decrease both cost and time <b>of</b> manual <b>assessment</b> processes. Furthermore, automated assessment and certification systems are expected to avoid subjectivity and <b>errors</b> <b>of</b> human <b>assessment.</b> Indeed, a panoply of systems and tools have been designed and implemented in order to automatically assess IT skills. The next section provides a detailed review of those developments.|$|R
40|$|Rectifications of {{multispectral}} scanner and thematic mapper data sets for full and subscene areas, analyses <b>of</b> planimetric <b>errors,</b> <b>assessments</b> <b>of</b> {{the number and}} distribution of ground control points required to minimize errors, and factors contributing to error residual are examined. Other investigations include the generation of three dimensional terrain models {{and the effects of}} spatial resolution on digital classification accuracies...|$|R
40|$|We {{analyze the}} Lattice Boltzmann method for the {{simulation}} of fluctuating hydrodynamics by Adhikari et al. [Europhys. Lett. 71, 473 (2005) ] {{and find that}} it shows excellent agreement with theory even for small wavelengths {{as long as a}} stationary system is considered. This is in contrast to other finite difference and older lattice Boltzmann implementations that show convergence only in the limit of large wavelengths. In particular cross correlators vanish to less than 0. 5 %. For larger mean velocities, however, Galilean invariance violations <b>manifest</b> themselves through <b>errors</b> <b>of</b> a magnitude {{similar to those of the}} earlier implementations. Comment: 8 pages, 9 figures, DSFD 200...|$|R
40|$|In Italy the Iridaceae show high {{biodiversity}} and {{consist of a}} fair number of genera and species. Some of these are well distributed in the regions, others show a punctiform distribution and are found only in some regions, while the remainder are endemic to Italy. The distribution of some species is reported repeatedly in the literature with certainty, while that of other less easily identifiable taxa (with diagnostic characters barely discernible, and/or the presence of polymorphism and polyploidy in populations), in fact, shows an <b>error</b> <b>of</b> <b>assessment</b> regarding their true areas of distribution. In particular, a thorough and methodical comparative study (analysis of observations in the field and of biosystematics) is important and more likely to promote the solution of taxonomic-nomenclatural problems. Such an approach will not only discourage the proliferation of species names, but also emphasise the real separation of those closely related yet distinct taxa and allow the recognition of synonymy, especially in taxa {{with a high level of}} criticality, as in Crocus vernus (L.) Hill, Iris sicula Tod., I. lutescens Lam., I. x germanica L., etc. As a result, all of this contributes towards a better understanding of their real status and encourages experts to take appropriate protective measures, according to the Strategic Plan for the Protection of Biodiversity, 2011 - 2020...|$|R
40|$|Abstract- Low-height vegetation, {{common in}} {{semiarid}} regions, {{is difficult to}} characterize with airborne LiDAR (light detection and ranging) due to the similarities, in time and space, of the point returns of vegetation and ground. Other complications may occur due to the lowheight vegetation structural characteristics {{and the effects of}} terrain slope. This research is focused on modeling methods and <b>error</b> <b>assessment</b> <b>of</b> low-height vegetation in varying terrain. Several methods to best determine vegetation height and 2 -d crown area are developed using both the LiDAR point cloud and rasters derived from the point cloud. These methods are tested on varying sloped terrain. <b>Error</b> <b>assessments</b> <b>of</b> bare earth terrain models in low-height vegetation cover types and slopes are also performed. Recommendations for modeling low-height vegetation and/or filtering lowheight vegetation from terrain models will be presented, along with open-source algorithms...|$|R
40|$|What is the {{precision}} needed for measures of albedo? • The IPCC, section 2. 5. 3. 1. 3 provides <b>error</b> <b>assessments</b> <b>of</b> albedo measurements for croplands • Both models demonstrate a high sensitivity to very {{small changes in}} albedo • Albedo changes between 0. 03 - 0. 05 seem significant 3 Albedo models using potential natura...|$|R
40|$|Abstract: All {{digital data}} contain error {{and many are}} uncertain. Digital models of {{elevation}} surfaces consist of files containing large numbers of measurements representing {{the height of the}} surface of the earth, and therefore a proportion of those measurements are very likely to be subject to some level <b>of</b> <b>error</b> and uncertainty. The collection and handling of such data and their associated uncertainties has been a subject of considerable research, which has focused largely upon the description of the effects of interpolation and resolution uncertainties, as well as modelling the occurrence <b>of</b> <b>errors.</b> However, digital models of elevation derived from new technologies employing active methods of laser and radar ranging are becoming more widespread, and past research will need to be re-evaluated in the near future to accommodate such new data products. In this paper we review the source and nature <b>of</b> <b>errors</b> in digital models of elevation, and in the derivatives of such models. We examine the correction <b>of</b> <b>errors</b> and <b>assessment</b> <b>of</b> fitness for use, and finally we identify some priorities for future research...|$|R
40|$|Like all {{experimentally}} determined {{physical and}} chemical properties, pH measurements {{are affected by the}} limited precision and accuracy of the measurement procedures. Fundamental studies of pH standards, based on measurement of the potential of an electrochemical cell without transference, known as the Harned cell, containing a platinum-hydrogen electrode and a silver-silver chloride reference electrode, indicate that vapour condensation phenomena on potentiometric cell walls not immersed in the thermostatic bath are a major source <b>of</b> <b>error</b> in <b>assessment</b> <b>of</b> pH values. In this work a study was conducted on phthalate buffer, 0. 05 mol kg(- 1) supercript stop KHPhth, and results are reported for the effect of this phenomenon on the assignment of pH values and on their corresponding uncertainties. Identification and quantification of this effect constitute an original contribution to improvement of the primary method of pH measurement and, therefore, more rigorous pH (PS) values...|$|R
40|$|With the {{development}} of mobile phone platforms and systems using numerical methods, it opens wide opportunities building a trustworthy engineering construction projects. Exploring models of real structures requires major computing resources costs, so {{it is important to}} find quick quality solutions. However, most of the engineering design area facing challenges where currect solution is not known. For this chalanges are using approximate methods of calculation, which finding the most appropriate solution. For several decades, the prevailing numerical methods, using engineering design computing technologies is the finite element method. This approach dealing with one of the difficulties, which affects the calculation results in an implicit dependence on the selected finite element mesh. Although this area is examined for decades, but the finite element generation mesh {{is one of the most}} widely investigated area. Designing the model of the construction, is important to obtain reliable calculation results, calculation errors in assessing the specific case of the calculation. Qualitative evaluation of finite element solutions, can be used finite element strategies. This method is an iterative process managed solution from pre-defined tolerances and the various definitions <b>of</b> <b>errors</b> <b>of</b> <b>assessment</b> procedures. Using finite element strategies can be qualitatively assess the results obtained, which are sufficiently accurate models describing the structure in question, at different external influences. Using finite element strategies and their application at issue, mechanical construction models are popular in computational mechanics and mechanical engineering challenges, extending the possibilities of numerical experiments...|$|R
40|$|Abstract. Traditionally, {{the classes}} in {{thematic}} maps {{have been treated}} as crisp sets, using classical set theory. In this formulation, map classes {{are assumed to be}} mutually exclusive and exhaustive. This approach limits the ability of thematic maps to represent the continuum of variation found in most landscapes. Substitution of fuzzy sets allows more � exibility for treatment of map classes in the areas <b>of</b> accuracy <b>assessment</b> and area estimation. Accuracy assessment methods based on fuzzy sets allow consideration of the magnitude <b>of</b> <b>errors</b> and <b>assessment</b> <b>of</b> the frequency of ambiguity in map classes. An example <b>of</b> an accuracy <b>assessment</b> from a vegetation map of the Plumas National Forest illustrates the implementation of these methods. Area estimation based on fuzzy sets and using accuracy assessment data allows estimation of the area of classes as a function of levels of class membership. The fuzzy area estimation methods are an extension of previous methods presented by Card (1982). One interesting result is that the sum of the areas of the classes in a map need not be unity. This approach allows a wider range of queries within a GIS. 1...|$|R
6000|$|Neither {{were the}} monks of Ely in jesting humor, {{when they came}} to count up the price of their own baseness. They had (as was in that day the cant of all cowardly English churchmen, {{as well as of the}} more crafty Normans) [...] "obeyed the apostolic injunction, to submit to the powers that be, because they are ordained," [...] &c. But they found the hand of the powers that be a very heavy one. Forty knights were billeted on them at free {{quarters}} with all their men. Every morning the butler had to distribute to them food and pay in the great hall; and in vain were their complaints of bad faith. William meanwhile, who loved money as well as he [...] "loved the tall deer," [...] had had 1,000 (another says 700) marks of them as the price of their church's safety, for the payment whereof, if one authority is to be trusted, they sold [...] "all the furniture of gold and silver, crosses, altars, coffers, covers, chalices, platters, ewers, urnets, basons, cups, and saucers." [...] Nay, the idols themselves were not spared, [...] "for," [...] beside that, [...] "they sold a goodly image of our Lady with her little Son, in a throne wrought with marvellous workmanship, which Elsegus the abbot had made. Likewise, they stripped many images of holy virgins of much furniture of gold and silver." [...] [Footnote: These details are from a story found in the Isle of Ely, published by Dr. Giles. It seems a late composition,-- probably of the sixteenth century,--and has <b>manifest</b> <b>errors</b> <b>of</b> fact; but valeat quantum.] So that poor St. Etheldreda had no finery in which to appear on festivals, and went in russet for many years after. The which money (according to another [Footnote: Stow's [...] "Annals."]) they took, as they had promised, to Picot the Viscount at Cambridge. He weighed the money; and finding it an ounce short, accused them of cheating the King, and sentenced them to pay 300 marks more. After which the royal commissioners came, plundered the abbey of all that was left, and took away likewise [...] "a great mass of gold and silver found in Wentworth, wherewith the brethren meant to repair the altar vessels"; and also a [...] "notable cope which Archbishop Stigand gave, which the church hath wanted to this day." ...|$|R
40|$|An attempt {{has been}} made to {{substantiate}} the behavioral features of the economic choice of an economic entity {{in the context of the}} decision-making environment transformation, and also to study their influence on the forming subjective preferences. At the same time, the behavioral paradigm is identified as a basic theoretical construct, which makes it possible to identify the main irrationalizing factors. Based on the study of the conceptual provisions of the behavioral paradigm, it was concluded that the preferences of the economic entity in the process of implementing the economic choice are formed under the influence of motivational and cognitive predictors, which limit the rationality of the economic entity. Deviating from rational criteria towards irrational, the economic entity shapes its preferences on the basis of economic and non-economic criteria, systematically making mistakes in the context of the influence of cognitive distortions manifested in decision-making under modern conditions. Based on the findings, the author constructs a model of economic choice, taking into account behavioral predictors. Among the most important cognitive distortions are herd instinct, professional deformation, "curse of knowledge", bias toward information retrieval, <b>error</b> <b>of</b> substantiation <b>of</b> <b>assessment,</b> bias <b>of</b> confirmation, neglect of formalized methods of cognition, conservatism, preferences of personified trust and heuristics of asymmetric perception...|$|R
40|$|The aim of {{this thesis}} is to {{initiate}} the reader into the business process modelling and error analysis when creating them. In the beginning, the work deals with the theory of business processes reengineering, methodologies, standards, CASE tools and subsequently with modeling itself. The contribution of this thesis lies in the <b>error</b> <b>assessment</b> <b>of</b> process diagrams and diagrams related to them based on the type division with possible consequences <b>of</b> <b>errors</b> and techniques how to avoid them {{with the use of}} methodologies or CASE tools...|$|R
5000|$|A {{judgment}} clearly {{displays a}} mistake {{made by the}} judge or a <b>manifest</b> <b>error.</b>|$|R
30|$|This {{study used}} a {{specially}} designed accuracy assessment phantom (Koivukangas 2012) to assess the accuracy of a commercial surgical navigator, the StealthStation S 7 (Medtronic Inc., Louisville, CO, USA). The navigator enabled the interchangeable use of both OTS and EMTS. The phantom consisted of three separate levels attached with screws to form the total reference volume. On each level a total <b>of</b> 49 accuracy <b>assessment</b> points were machined with 20 mm displacement between the beveled holes. This gave a specific region of surgical interest (ROSI) volume of 120 x 120 x 100 mm. The phantom was industrially verified at Oulu PMC using the Mitutoyo Strato 9166 (Mitutoyo, Japan) accuracy sensing device. The displacement <b>error</b> <b>of</b> the accuracy <b>assessment</b> points {{was found to be}} +/− 0.015 mm.|$|R
40|$|Remote sensing derived {{data are}} {{increasingly}} being utilized as a data source in geographic information systems (GIS). Remote sensing and GIS error associated with the data acquisition, processing. analysis, conversion, and final product presentation can {{have a significant impact}} on the confidence of decisions made using the data. This paper attempts to identify potential sources <b>of</b> <b>error</b> at each data integration process step, assess potential impacts <b>of</b> <b>error</b> propagation on the decision making process, and recommend priority error quantification research topics. There is an immediate need for the development and standardization <b>of</b> <b>error</b> <b>assessment</b> procedures and reporting conventions. Suggested error quantification research topic priorities include the development of more cost-effective remote sensing accuracy <b>assessment</b> procedures, development <b>of</b> field verification data collection guidelines, procedures for vector-to-raster and raster-to-vector conversions, <b>assessment</b> <b>of</b> scaling issue [...] ...|$|R
40|$|Techniques {{being applied}} {{to test the}} {{sensitivity}} of the physical characteristics of clouds, as determined by remote sensing, to the spatial resolution of the scans are described. The sensitivity is being evaluated with an <b>error</b> <b>assessment</b> <b>of</b> data from the AVHRR instrument on Nimbus- 7. A spatial coherence analysis is being applied to AVHRR data for a 250 sq km region in the Pacific off the Mexican coast. Errors in the derived cloud cover and radiances from which cloud-free regions and cloud-covered regions are being estimated on the basis of radiance values in pixel-sized areas...|$|R
40|$|This study {{investigated}} interrater reliability and measurement <b>error</b> <b>of</b> the Melbourne <b>Assessment</b> <b>of</b> Unilateral Upper Limb Function (Melbourne Assessment) and the Quality of Upper Extremity Skills Test (QUEST), and assessed {{the relationship between}} both scales in 21 children (15 females, six males; mean age 6 y 4 mo [SD 1 y 3 mo], range 5 - 8 y) with hemiplegic CP. Two raters scored the videotapes <b>of</b> the <b>assessments</b> independently in a randomized order. According to the House Classification, three participants were classified as level 1, one participant as level 3, eight as level 4, three as level 5, one participant as level 6, and five as level 7. The Melbourne Assessment and the QUEST showed high interrater reliability (intraclass correlation 0. 97 for Melbourne Assessment; 0. 96 for QUEST total score; 0. 96 for QUEST hemiplegic side). The standard <b>error</b> <b>of</b> measurement and the smallest detectable difference was 3. 2 % and 8. 9 % for the Melbourne Assessment and 5. 0 % and 13. 8 % for the QUEST score on the hemiplegic side. Correlation analysis indicated that different dimensions of upper limb function are addressed in both scales. status: publishe...|$|R
40|$|Large scale studies {{frequently}} use complex sampling procedures, disproportionate sampling weights, {{and adjustment}} techniques {{to account for}} potential bias due to nonresponses {{and to ensure that}} results from the sample can be generalized to a larger population. Survey researchers are concerned about measurement error and the use of weights in developing models. Consequently, multiple weighting factors are used and these weighting factors are manifested as a final survey (composite) weight available for analysis. We developed a method to incorporate an external weighting factor like this for analyses <b>of</b> measurement <b>errors</b> in the theory of generalizability to provide researchers with a tool to evaluate the measurement <b>error</b> components <b>of</b> survey quality and undesirable <b>error</b> components <b>of</b> large-scale <b>assessment</b> programs such as national and stat...|$|R
5000|$|... "In 1812, Petru Maior (...) {{wrote his}} The History of the Romanian Beginnings in Dacia. In his {{tendency}} {{to prove that}} we Romanians are un-corrupted descendants of the Romans, Maior maintains, in the fourth paragraph, that Dacians were entirely exterminated by the Romans, and there was thus no mixing of these two peoples. In order to prove such an unnatural hypothesis, our historian relies on a dubious passage in Eutropius and a passage in Julian, to which he gives an interpretation that no sane mind could admit, and thus begins the demonstration of our Romance identity through history - with a falsification of history. (...) that which surprises and saddens concerning these creations is not their error itself, since this can be explained and at times justified through {{the circumstances of the}} period, but rather the <b>error</b> <b>of</b> our <b>assessment</b> <b>of</b> them nowadays, the haughtiness and self-satisfaction with which they are defended by the Romanian intelligentsia as if true acts of science, the blindness that provides for a failure to see that building a Romanian national awareness cannot rely on a basis that would enclose a lie." ...|$|R
40|$|Accurate {{measurement}} of pressure differences across a diseased heart valve involves either laborious planimetry or elaborate digital computing facilities. An analogue device is described, simple and inexpensive to construct, which {{derives from the}} recorder input of two pressure signals the time (seconds/minute) of valve opening and the mean pressure difference during this time. Measurements may be repeated over long periods. The importance of using pressure differences as compared with peak or end diastolic gradients is noted; serious <b>errors</b> in <b>assessment</b> <b>of</b> valvular disease may otherwise occur...|$|R
40|$|Background: To {{investigate}} {{the relationship between}} the change in the <b>manifest</b> refractive <b>error</b> (ΔM), the change in apical corneal power (ΔACP) and initial corneal asphericity (Q) in overnight orthokeratology (ortho-K). Methods: One hundred and twenty-eight clinical records of children undergoing ortho-K from a university optometry clinic were reviewed. The refractive and topographical data at baseline and at two-week visit of 58 patients who fulfilled the inclusion criteria were retrieved and analysed. Results: Significant differences (p < 0. 001) between the change in <b>manifest</b> refractive <b>error</b> and changes in the apical corneal power or the maximum change in corneal power (ΔMCP) within the treatment zone were found. Linear regression analysis was used to describe the change in <b>manifest</b> refractive <b>error</b> and the change in apical corneal power, and the change in <b>manifest</b> refractive <b>error</b> and the maximum change in corneal power, with the equations: ΔM = 0. 91 ΔACP + 0. 57 (r = 0. 78, p < 0. 001) and ΔM = 0. 93 ΔMCP + 0. 01 (r = 0. 79, p < 0. 001) respectively. On average, the change in apical corneal power underestimated the change in <b>manifest</b> refractive <b>error</b> by 0. 34 ± 0. 57 D; whereas on average, the maximum change in corneal power overestimated the change in <b>manifest</b> refractive <b>error</b> by 0. 23 ± 0. 57 D (paired-t-tests, p < 0. 001). A low but significant correlation between initial corneal asphericity and the change in <b>manifest</b> refractive <b>error</b> (Spearman r = - 0. 33, p = 0. 01) was observed. Conclusions: The change in apical corneal power underestimates the change in <b>manifest</b> refractive <b>error</b> in ortho-K, whereas the maximum change in corneal power overestimates this parameter. Compared with retinoscopy and autorefraction, the change in apical corneal power is still useful for estimation of the change in <b>manifest</b> refractive <b>error.</b> Although the maximum change in corneal power appears to give a closer estimation of the change in <b>manifest</b> refractive <b>error</b> than the change in apical corneal power, there is no advantage in the use of maximum corneal power (manually located) instead of apical corneal power (a default given by the topographer) to estimate the change in <b>manifest</b> refractive <b>error,</b> as there is {{no significant difference in the}} estimations by either parameter. Initial corneal asphericity measured by the Medmont E 300 corneal topographer has limited usage in predicting the change in <b>manifest</b> refractive <b>error</b> in overnight ortho-K. School of Optometr...|$|R
40|$|This {{technical}} note (TN) {{focuses on the}} <b>assessment</b> <b>of</b> the atmospheric effects and their compensation in SAR interferometry and especially in persistent scatterer interferometry (PSI). Different strategies to reduce atmospheric effects exist for mountainous areas. In principle, the topographically-correlated atmospheric phase can be estimated • directly from the data, • from global coarse grid GPS zenith path delay data and • from numerical weather prediction models (NWP). These methods are compared and the related assessment is described in this {{technical note}}. The output is a recommendation how to implement the atmosphere mitigation in mountainous areas and an <b>error</b> propagation <b>assessment</b> <b>of</b> the NWP method...|$|R
40|$|The goal of {{this study}} was to test the {{hypothesis}} that reintroduction of Continuous Performance Improvement (CPI) methodology, a lean approach to management at Seattle Children’s (Hospital, Research Institute, Foundation), would facilitate engagement of vivarium employees in the development and sustainment of a daily management system and a work-in-process board. Such engagement was implemented through reintroduction of aspects of the Toyota Production System. Iterations of a Work-In-Process Board were generated using Shewhart’s Plan-Do-Check-Act process improvement cycle. Specific attention was given to the importance of detecting and preventing <b>errors</b> through <b>assessment</b> <b>of</b> th...|$|R
5000|$|Arbitration {{awards are}} non-justiciable. Distinguish from an [...] "expert determination" [...] where the expert determines {{a matter of}} fact (which is ordinarily not subject to any form of appeal at all, except in cases of obvious bias or <b>manifest</b> <b>error</b> or bad faith).|$|R
40|$|Background: Recent high-precision {{measurements}} of alpha-induced reaction data below the Coulomb barrier {{have pointed out}} questions of the alpha-particle optical-model potential (OMP) which are yet open within various mass ranges. Purpose: The applicability of a previous optical potential and eventual uncertainties and/or systematic <b>errors</b> <b>of</b> the OMP <b>assessment</b> at low energies can be further considered on this basis. Method: Nuclear model parameters based on the analysis of recent independent data, particularly gamma-ray strength functions, have been involved within statistical model calculation of the (alpha,x) reaction cross sections. Results: The above-mentioned potential provides a consistent description of the recent alpha-induced reaction data with no empirical rescaling factors of the and/or nucleon widths. Conclusions: A suitable <b>assessment</b> <b>of</b> alpha-particle optical potential below the Coulomb barrier should involve the statistical-model parameters beyond this potential {{on the basis of}} a former analysis of independent data. Comment: 12 pages, 8 figures. Updated citations. Minor correctio...|$|R
40|$|This paper {{deals with}} the study of {{preparations}} based on medicinal plants used in traditional Chinese medicine for treatment and prevention {{of a wide range}} of diseases. The purpose of this research was evaluation of the capabilities of a multisensor system for instrumental <b>assessment</b> <b>of</b> the samples bitterness. 33 samples of medicinal plants were evaluated by tasters according to bitterness intensity from 0 to 6. Methodology of the analysis was developed and repeated measurements of the samples were performed by multisensor system. Tasters’ assessments were used as reference data while multisensor system calibrating. A regression model built according to these data displayed good correlation of the system response with bitterness perceived by people. The parameters of the regression model give the possibility for concluding that the multisensor system is capable to predict the bitterness of the medicinal plants preparations with average precision equal to ± 1 of the reference bitterness scale. Relative <b>error</b> <b>of</b> bitterness determination is 14 %, which is a good result for such type <b>of</b> measurements (typical <b>error</b> <b>of</b> the taster’s <b>assessment</b> is, as a rule, in the range of 15 - 30 %) ...|$|R
