35|369|Public
5000|$|Example call: push EAX pass some {{register}} result push byteEBP+20 pass some <b>memory</b> <b>variable</b> (FASM/TASM syntax) push 3 pass some constant call calc {{the returned}} result {{is now in}} EAXTypical callee structure: (some or all (except ret) of the instructions below may be optimized away in simple procedures)calc: push EBP save old frame pointer mov EBP,ESP get new frame pointer sub ESP,localsize reserve place for locals [...] [...] perform calculations, leave result in EAX [...] mov ESP,EBP free space for locals pop EBP restore old frame pointer ret paramsize free parameter space and return ...|$|E
3000|$|We {{could have}} similar {{problems}} when transmitting {{data to the}} network. The native libraries to handle the transmission of data only use one RAM <b>memory</b> <b>variable</b> to hold the packet until it is accepted by the transceiver and saved into its transmission buffer. If the processor requests to transmit several packets (for example, the calculated z [...]...|$|E
40|$|We {{examine the}} {{importance}} of problem formulation for the solution of large-scale optimization problems on high-performance architectures. We use limited <b>memory</b> <b>variable</b> metric methods to illustrate performance issues. We show that the performance of these algorithms is drastically affected by application implementation. Model applications are drawn from the MINPACK- 2 test problem collection, with numerical results from a super-scalar architecture (IBM RS 6000 / 370), a vector architecture (CRAY- 2), and a massively parallel architecture (Intel DELTA). Key words. optimization, large-scale, limited <b>memory,</b> <b>variable</b> metric, performance evaluation, vector architecture, parallel architecture. AMS subject classifications. 65 Y 05, 65 Y 20, 65 K 05, 65 K 10, 90 C 06, 90 C 30 1. Introduction. Our aim is to explore performance issues associated with the solution of large-scale optimization problems on high-performance architectures. The solution of these problems, where the number of variables ranges betwe [...] ...|$|E
30|$|We {{adopted the}} first-order Crank–Nicolson method to {{calculate}} the time integration of the constitutive equation, Eq. (5), and the auxiliary equation for the <b>memory</b> <b>variables,</b> Eq. (6). This enables us to solve the original implicit scheme equations explicitly. The discretized formula {{can be found in}} Maeda et al. (2013).|$|R
40|$|Group versus {{individual}} {{verbal and}} visuospatial memory outcome following epilepsy surgery was evaluated by a non-parametric method in 25 left and 29 right temporal lobectomy patients. Twenty-five controls were assessed twice. Analyses of change at an individual level evaluated by this statistical approach based on paired-ranks {{were compared to}} results with a method based on distances (Reliable Change). The left temporal lobectomy group deteriorated in the two verbal <b>memory</b> <b>variables</b> (p < 0. 01 and 0. 05). High levels of individual changes unexplained by group patterns were disclosed in the three <b>memory</b> <b>variables</b> analyzed in the patients. Significant individual change, although less pronounced, also occurred in the controls. Group versus individual outcome was adequately distinguished by the non-parametric method. To properly analyze memory change after epilepsy surgery, evaluation at group and individual level ought to combined...|$|R
5000|$|Deallocate {{the space}} of <b>memory</b> a <b>variables</b> data may take up, and ...|$|R
30|$|In the prototype, {{we use a}} four-level radix tree to {{save all}} {{recorded}} memory values. The radix tree is indexed by the <b>memory</b> <b>variable</b> address, which is passed as a parameter in the DTrace primitive calls. We plan to leverage Intel processor features like Intel MPX (Oleksenko et al. 2017) {{to speed up the}} radix tree search and update operations.|$|E
30|$|The main {{contribution}} {{of this paper}} are: (a) the equation with hereditary <b>memory,</b> <b>variable</b> density, and external force term is representative; (b) the detailed construction process of the energy functional is given by an integration method; (c) we give a detailed proof of the existence for the solution; (d) the proof of the exponential decay result is simplified by introducing only one auxiliary functional; (e) the polynomial decay result is established.|$|E
40|$|Typically, {{practical}} optimization problems involve nonsmooth {{functions of}} {{hundreds or thousands}} of variables. As a rule, the variables in such problems are restricted to certain meaningful intervals. In this paper, we propose an efficient adaptive limited memory bundle method for large-scale nonsmooth, possibly nonconvex, bound constrained optimization. The method combines the nonsmooth variable metric bundle method and the smooth limited <b>memory</b> <b>variable</b> metric method, while the constraint handling is based on the projected gradient method and the dual subspace minimization. The preliminary numerical experiments to be presented confirm the usability of the method...|$|E
40|$|Abstract—This article {{examines}} whether purely decentral-ized controllers {{can be designed}} to stabilize networks of double-integrator agents with general observation topologies and iden-tical non-minimum-phase internal dynamics. A new control architecture is proposed, that permits stabilization of such non-minimum-phase double-integrator networks. This design provides an alternative to solutions that require information exchange (of controller <b>memory</b> <b>variables)</b> between agents. I...|$|R
40|$|In this paper, {{we present}} a {{class-based}} <b>variable</b> <b>memory</b> length Markov model and its learning algorithm. This {{is an extension of}} a <b>variable</b> <b>memory</b> length Markov model. Our model is based on a class-based probabilistic suffix tree, whose nodes have an automatically acquired wordclass relation. We experimentally compared our new model with a word-based bi-gram model, a word-based tri-gram model, a class-based bi-gram model, and a word-based <b>variable</b> <b>memory</b> length Markov model. The results show that a class-based <b>variable</b> <b>memory</b> length Markov model outperforms the other models in perplexity and model size. 1...|$|R
40|$|International audienceThis paper {{deals with}} the {{numerical}} modeling of transient mechanical waves in linear viscoelastic solids. Dissipation mechanisms are described using the generalized Zener model. No time convolutions are required thanks {{to the introduction of}} <b>memory</b> <b>variables</b> that satisfy local-in-time differential equations. By appropriately choosing the relaxation parameters, it is possible to accurately describe a large range of materials, such as solids with constant quality factors. The evolution equations satisfied by the velocity, the stress, and the <b>memory</b> <b>variables</b> are written {{in the form of a}} first-order system of PDEs with a source term. This system is solved by splitting it into two parts: the propagative part is discretized explicitly, using a fourth-order ADER scheme on a Cartesian grid, and the diffusive part is then solved exactly. Jump conditions along the interfaces are discretized by applying an immersed interface method. Numerical experiments of wave propagation in viscoelastic and fluid media show the efficiency of this numerical modeling for dealing with challenging problems, such as multiple scattering configurations...|$|R
40|$|Many {{practical}} optimization problems involve nonsmooth (that is, {{not necessarily}} differentiable) functions of {{hundreds or thousands}} of variables with various constraints. In this paper, we describe a new efficient adaptive limited memory interior point bundle method for large, possible nonconvex, nonsmooth inequality constrained optimization. The method is a hybrid of the nonsmooth variable metric bundle method and the smooth limited <b>memory</b> <b>variable</b> metric method, and the constraint handling is based on the primal-dual feasible direction interior point approach. The preliminary numerical experiments to be presented confirm the effectiveness of the method...|$|E
30|$|In this paper, we {{consider}} the Dirichlet boundary value problem of nonlinear evolution equation with hereditary <b>memory,</b> <b>variable</b> density, and external force term. We prove {{the existence of a}} global solution by means of the Galerkin method, establish the exponential stability by using only one auxiliary functional (this method is simpler than that in [1]), and also show the polynomial stability under suitable conditions. Under suitable hypotheses on the external force term function f and integral kernel function μ with γ≥ 0 in the model, we can further consider the local existence and blowup phenomenon of the solution.|$|E
30|$|In OpenSWPC, we {{implemented}} a frequency-independent attenuation model by adopting the GZB. The assumption of frequency-independent attenuation is valid in the low-frequency regime below ∼ 1  Hz, {{at least to}} a first-order approximation (e.g., Aki and Richards 2002). However, at frequencies above about 1  Hz, attenuation appears to follow a power-law frequency dependence (e.g., Carcolé and Sato 2010; Phillips et al. 2014). Incorporation of such different frequency-dependent attenuation properties for high frequencies can also be modeled by applying the <b>memory</b> <b>variable</b> approach (Withers et al. 2015). Such implementation of more realistic attenuation characteristics to OpenSWPC is a prospect for future development.|$|E
40|$|Some methodologies {{developped}} by {{practitioners to}} model damping phenomena for distributed parameter systems will be listed and revisited. We {{will try to}} put them in the framework of port-Hamiltonian systems, either linear or non-linear, either finite or infinite-dimensional. The most significant distinction occurs between static and dynamic damping models: for the latter, a particular attention will be paid to the notion of <b>memory</b> <b>variables,</b> such as those defined in mechanical engineering...|$|R
40|$|We {{discuss the}} {{properties}} of the dynamics of purely memristive circuits using a recently derived consistent equation for the internal <b>memory</b> <b>variables</b> of the involved memristors. In particular, we show that the number of independent memory states in a memristive circuit is constrained by the circuit conservation laws, and that the dynamics preserves these symmetries by means of a projection on the physical subspace. Moreover, we discuss other symmetries of the dynamics under various transformations of the internal memory, and study the linearized and strongly non-linear regimes of the dynamics. In the strongly non-linear regime, we derive a conservation law for the internal <b>memory</b> <b>variables.</b> We also provide a condition on the reality of the eigenvalues of Lyapunov matrices describing the linearized dynamics close to a fixed point. We show that the eigenvalues ca be imaginary only for mixtures of passive and active components. Our last result concerns the weak non-linear regime. We show that the internal memory dynamics can be interpreted as a constrained gradient descent, and provide the functional being minimized. This latter result provides another direct connection between memristors and learning. Comment: 19 pages, 2 figures; more typos corrected, proof of fixed point corrected, presentation improve...|$|R
5000|$|The {{stochastic}} chain [...] is, then, a chain with <b>memory</b> of <b>variable</b> length, taking {{values in}} [...] and {{compatible with the}} probabilistic context tree , where ...|$|R
40|$|By rearranging {{terms in}} the {{viscoelastic}} wave equations for the standard linear solid, new composite memory variables are defined. Instead of having one <b>memory</b> <b>variable</b> for compressional relaxation and {{one for each of}} the six independent components of quasi-shear stress relaxation, as in the standard relaxation mechan-ism formulation, the new grouping contains only one for each displacement response component. Thus, only two (rather than three) memory variables are required for 2 -D computations, and only three (rather than seven) a re required for 3 -D computations. The amount of computation is not changed as the new formulation is equivalent to the standard one, but there is a significant saving in computer memory. Key words: memory variables, synthetic seismograms, viscoelasticity...|$|E
40|$|International audienceWe {{propose a}} {{construction}} of fatigue laws from cohesive forces {{models in the}} case of a crack submitted to a mode I cyclic loading. Taking the cumulated opening as the <b>memory</b> <b>variable</b> and the surface energy density associated with Dugdale's model, we explicitly construct the fatigue law which gives the crack growth rate by cycle d'/dN in terms of the stress intensity factor KI. In particular, we recover a Paris law with an exponent 4, i. e., d'/dN = CKI 4, when KI is small, the coefficient C being explicitly expressed in terms of the material parameters. Furthermore, the law can be applied in the full range of values of KI and can be extended to non simple cycles...|$|E
40|$|ABSTRACT. This {{study was}} {{designed}} ' to examine relationships be. tweei three-viriables of analysis/i 0 egiation skill in visual,perception and the tendency to retain differentiated memories of sequential visual images {{in a sample of}} 206 university underqraduated [...] Correlation techniques and factor. analysis-were used to analyze-relationships between the perceptual variables and the' <b>memory</b> <b>variable.</b> While some relationships betwOen perceptual skill and memory were found which were statiqticallyfsignificant, variations in neither individual perceptual skills nor in factors, whith ey formed in combination were found to account for a sufficient portion of variance in visual memory functioning to be of practical importance. Leveling/sharpening in visual memory appeired to be largely independent of the specific perceptual skills measliredc in this study. (Author) -y e A. o...|$|E
40|$|We {{present an}} {{expressive}} agent design language for reinforcement learning {{that allows the}} user to constrain the policies considered by the learning process. The language includes standard features such as parameterized subroutines, temporary interrupts, aborts, and <b>memory</b> <b>variables,</b> but also allows for unspecified choices in the agent program. For learning that which isn't specified, we present provably convergent learning algorithms. We demonstrate by example that agent programs written in the language are concise as well as modular. This facilitates state abstraction and the transferability of learned skills. ...|$|R
5000|$|A {{stochastic}} chain with <b>memory</b> of <b>variable</b> {{length is}} a stochastic chain , taking values in a finite alphabet , and {{characterized by a}} probabilistic context tree , so that ...|$|R
30|$|This PML method {{solves the}} {{auxiliary}} differential equations {{in addition to}} the equations of motion and the constitutive equations in the absorbing zone with complex and frequency-shifted absorbing functions. Typically 10 – 20 grids are used for the thickness of the PML zone surrounding the model; this can be defined in the input parameters. To avoid large computational loads when solving the auxiliary equations of the PML, we assumed that the material in the PML zone was perfectly elastic and did not calculate the <b>memory</b> <b>variables</b> (Eq. 6), for the anelasticity.|$|R
40|$|Recognition of {{biological}} motion probably needs {{the integration of}} form and motion information. For recognition and categorisation of complex static shapes, recognition performance can be significantly increased by optimisation of the extracted mid-level form features. Several algorithms for the learning of optimised mid-level features from image data have been proposed. It {{seems likely that the}} visual recognition of complex movements is also based on optimised features. Exploiting a new physiologically inspired algorithm and classical unsupervised learning methods, we have tried to determine mid-level motion features that are maximally useful for the recognition of body movements from image sequences. We optimised mid-level neural detectors in a hierarchical model for the recognition of human actions (Giese and Poggio, 2003 Nature Reviews Neuroscience 4 179 - 192) by unsupervised learning. Learning is based on a memory trace learning rule: Each detector is associated with a <b>memory</b> <b>variable</b> that increases when the detector is activated during correct classifications, and that decreases otherwise. Detectors whose <b>memory</b> <b>variable</b> falls below a critical threshold 'die', and are eliminated from the model. In addition, we tested a classical principal-components approach. The model is trained with movies showing different human actions, from which optic flow fields are computed. The tested learning algorithms extract mid-level motion features that lead to a substantial improvement of the recognition performance. For the special case of walking, many of the extracted motion features are characterised by horizontal opponent motion. This result is consistent with psychophysical data showing that opponent horizontal motion is a dominant mid-level feature that accounts for high recognition rates, even for strongly impoverished stimuli (Casile and Giese, 2005 Journal of Vision 5 348 - 360). As for the categorisation of static shapes, recognition performance for human actions is improved by choosing optimised mid-level features. The learned features might predict receptive field properties of complex motion-selective neurons (eg in area KO/V 3 B) ...|$|E
40|$|Memory access {{errors are}} {{a major source of}} bugs in {{programs}} written in C. The errors are difficult to find and can lead to runtime failures or even security compromises. Languages such as Java are free from such errors because of their strong type-checking mechanisms. We propose a method to achieve many of the memory safety features in these type-safe languages without changing the C language or rewriting source code. Our approach is based on the safety rule that a <b>memory</b> <b>variable</b> should only be updated by the small set of instructions intended by the programmer. Any deviation from the safety rule is considered a violation. The proposed method is implemented using static program slicing techniques and runtime memory access monitoring. Our method can be used for detecting memory corruption attacks, identifying bugs during software development, and diagnosing memory-related failures post-mortem...|$|E
40|$|Five {{experiments}} {{related to}} anaphor resolution to a classic <b>memory</b> <b>variable,</b> namely, interference created by multiple uses {{of a given}} object-concept, and by spatial distance of the referent from the reader's focus of attention. Participants memorized a diagram of a building with rooms containing objects, and then read narratives describing characters' activities there. Reading was self-paced word by word. Accessibility was measured by readers' time to understand anaphoric sentences containing a definite noun phrase referring to an object in its room. Spatial distance between the object and the current focus of attention increased reading times for names of the object, the room, and sentence wrap-up. Multiple examples of a target-object increased its reading time only if they were scattered across different rooms. An associative model of memory retrieval during text comprehension was used to interpret the complex pattern of results...|$|E
40|$|A Newmark-diffusive {{scheme is}} {{presented}} for the time-domain solution of dynamic systems containing fractional derivatives. This scheme combines a classical Newmark time-integration method used to solve second-order mechanical systems (obtained for example after finite element discretization), with a diffusive representation {{based on the}} transformation of the fractional operator into a diagonal system of linear differential equations, which can be seen as internal <b>memory</b> <b>variables.</b> The focus is given on the algorithm implementation into a finite element framework, the strategies for choosing diffusive parameters, and applications to beam structures with a fractional Zener model...|$|R
5000|$|Given {{the sample}} {{produced}} by a chain with <b>memory</b> of <b>variable</b> length, {{we start with the}} maximum tree whose branches are all the candidates to contexts to the sample; ...|$|R
40|$|Though {{there has}} been an {{abundance}} of experimental research in false memory phenomena over the last several decades, there is a surprising dearth of studies that examine whether or not people who are susceptible to false memories in certain conditions are also susceptible to false memories under other conditions. The dissertation research presented here addresses this issue. In one large study, subjects participated in three well-established false memory paradigms (a misinformation task, the Deese-Roediger-McDermott (DRM) list learning paradigm, and an imagination inflation exercise) as well as completed several individual difference measures. Results indicate that there are some small, positive, significant correlations between false <b>memory</b> <b>variables</b> in all three inter-paradigm comparisons. Moreover, while a handful of individual difference variables were correlated with some false <b>memory</b> <b>variables</b> in the DRM and imagination inflation paradigms, not one of them predicted false memories in the misinformation paradigm. Furthermore, only the Anomalous/Paranormal Experience Subscale of the Anomalous Events Inventory was correlated with both DRM and imagination inflated false memories. It seems likely that due to procedural dissimilarities, the variation in the proposed theoretical explanations, and the differing qualities of the false memories that each paradigm produces, there is no false memory "trait. " In other words, no one type of person seems especially prone, or especially resilient, to the ubiquity of memory distortion...|$|R
40|$|UnrestrictedLatent Change Score {{models are}} used to examine {{training}} effects in a randomized clinical trial on memory training (see McArdle & Prindle, 2008). Data are taken from the Memory and Control groups of ACTIVE (Jobe, Smith, Ball, et al., 2001). First, we examined mean differences in SEMs and find training effects within the trained domain (memory) and transfer to everyday problem solving present for both groups. Second, pre-post test latent change score models find mean training effects for the <b>memory</b> <b>variable</b> with less transfer of training. Third, we use two common factor models to test measurement. Standard likelihood ratio testing suggests invariant loadings do not fit the Near factor but fit the Far factor. Fourth, a latent change score model with common factors did not offer any new information over previous models. Implications and ideas for future analyses are presented in the discussion section...|$|E
3000|$|Let us {{remark that}} {{each time a}} letter S[i] is read, only the letter S'[i] is saved in a <b>memory</b> <b>variable</b> which is always changed in each step, and each time reading a letter, the {{automaton}} A'_P takes only one state transition, not the same KMP one, therefore {{the speed of the}} whole matching process is faster than the KMP one, in case we do not care of extracting operations but only matching operations. In the comparative results between our algorithm with the KMP one, to obtain the runtime of matching phase for our method, we need to save S'[1] [...]... S'[n] in a string buffer first and then calculate the runtime of the whole matching process. The experimental results show that the runtime {{is the same as the}} runtime of the BM algorithm, and they run faster than the KMP one with the ratio of about 1  /  7 in speed.|$|E
40|$|The {{paper is}} {{concerned}} with the mathematical modelling and computational simulation of hysteretic behaviour typically exhibited by shape memory alloys in the pseudoelastic temperature range, as observed by I. Muller and his co-workers in experimental tests for CuZnAl monocrystals. The point of departure is the one-dimensional thermomechanical model due to I. Muller and due to V. I. Levitas. The internal hysteresis loops are described by means of a discrete <b>memory</b> <b>variable</b> which can be handled by a monotone path rule. Existence and uniqueness of solutions is shown in the presence of hardening. We investigate the limit of vanishing hardening and vanishing material inhomogenuity and show that the limit depends on their relative size within the limit procedure. The analytical and numerical results show that under small hardening the phase transformation process is very sensitive to any inhomogenuities which may be present (e. g. geometric ones) or are developed in the two-phase system in the [...] ...|$|E
40|$|Thirty {{children}} from 2 classes {{of a special}} school for learning disabilities which were comparable to each other {{with respect to the}} relevant variables participated in an experiment on the memory strategy of categorizing. Based on the results of a pretest both classes were split into two groups of equal size and performance and assigned subsequently to two different treatment groups. One of these groups received a training to reason inductively, the other one an attentional training. At the end of this first training phase Catell’s CFT 20 intelligence test was conducted for both groups. After that both groups received an instruction of how to use the memory strategy of categorizing or clustering. At the end of this second phase the reasoning training group scored higher in the <b>memory</b> <b>variables</b> (i. e. „number of reproduced items” and „degree of categorical organisation”). This difference of performance showed up in a third CFT test after six months {{as well as in the}} <b>memory</b> <b>variables</b> without any training, except for a single refreshing lesson. The additional analysis for the second post test in individual cases shows that students who have received the mental training („Denktraining für Jugendliche, Klauer, 1993) have 4 to 5 -fold higher chance of successfully solving the commemorative tasks than students who were coached with the attention training...|$|R
40|$|This paper {{examines}} how {{to design a}} low-cost and algorithm-based approach that recovers random multiple bit – errors in an application's data-words on memory during the execution time of an application. This is a low cost and an effective software technique in order to detect and recover an application’s sensitive data elements using an affordably lower redundancy in both time and space. This is a practical approach towards gaining fault tolerance and dependable computing through recovery or corrections of multiple bit-errors in <b>memory</b> <b>variables</b> as well. Key Words: Data–word error detection and recovery, fault tolerance, transient bit errors. 1...|$|R
40|$|This {{quasi-experimental}} study investigates neuropsychological functioning {{differences between}} 63 active duty {{soldiers who were}} placed into three groups (MTBI, PTSD, control) to provide better information for differentiating PTSD and MTBI. The ANAM and MicroCog were utilized to measure psychomotor speed, memory, and attention. Participants with PTSD performed worse on most measures of psychomotor speed and attention, and endorsed more symptoms of depression and anxiety when compared to MTBI and control participants. Further, attention {{appears to be the}} best cognitive domain for differentiating PTSD from MTBI, whereas <b>memory</b> <b>variables</b> did not differentiate these groups. Clinical and research implications of these findings are discussed...|$|R
