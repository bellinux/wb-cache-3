1|18|Public
40|$|Abstract Background Zonocerus variegatus (Linnaeus, 1758) (Orthoptera: Pyrgomorphidae) {{is known}} as an {{agricultural}} pest in West and Central Africa. However, its importance in the agricultural production system in Cameroon has not been investigated. The study assesses farmers' perception {{on the importance of}} Z. variegatus in the agricultural production systems of the humid forest zone of Southern Cameroon. Methods Research was carried out in 5 villages of each of three Agro-Ecological, Cultural and Demographic Blocks (AECD-Blocks) of the Forest <b>Margin</b> <b>Benchmark</b> Area (FMBA). In each village, a semi-structured survey was used; male and female groups of farmers were interviewed separately. Results Z. variegatus is present throughout the humid forest zone of Southern Cameroon, where it is ranked as the third most economically important insect pest of agriculture. In the farmers' opinion, Z. variegatus is a polyphagous insect with little impact on young perennial crops. The length of the pre-farming fallow does not affect Z. variegatus pest pressure in the following crops. The increased impact of the grasshopper observed today in the fields, compared to what existed 10 years ago is as a result of deforestation and increase in surface of herbaceous fallow. The damage caused by Z. variegatu s is higher in fields adjacent to C. odorata and herbaceous fallows than in those adjacent to forests and shrubby fallows. The fight against this grasshopper is often done through physical methods carried out by hand, for human consumption. The farmers highlight low usage of the chemical methods and a total absence of biological and ecological methods. Conclusion Farmers' perception have contributed to understanding the status of Z. variegatus in the humid forest zone of Southern Cameroon. The results are in general similar to those obtained in other countries. </p...|$|E
5000|$|August 1991: Sybase goes {{public at}} a split {{adjusted}} price of $4.40. Sybase SQL server 4.0, and later 4.8 (the first smp server) and 4.9.1, all outperformed competitors by significant <b>margins</b> in standard <b>benchmarks.</b>|$|R
40|$|The {{well-known}} MinOver {{algorithm is}} a simple modification of the perceptron algorithm and provides the maximum margin classifier without a bias in linearly separable two class classification problems. DoubleMinOver as a slight modification of MinOver is introduced, which now includes a bias. It is shown how this simple and iterative procedure can be extended to SoftDoubleMinOver for classification with soft <b>margins.</b> On <b>benchmarks</b> the extremely simple SoftDoubleMinOver algorithm achieves the same classification performance with the same computational effort as sophisticated Support-Vector-Machine software...|$|R
40|$|In the Congo Basin, {{smallholder}} farmers practice slash-and-burn shifting cultivation. Yet, deliberate burning might {{no longer}} be sustainable under reduced fallow scenarios. We synthesized data from the Forest <b>Margins</b> <b>Benchmark</b> Area (FMBA), comprising 1. 54  million hectares (ha), in southern Cameroon and assessed the impact of fire exclusion on yield, labor inputs, soil fertility, ecosystem carbon stocks, and fallow recovery indicators in two common field types (plantain and maize) under both current and reduced fallow scenarios. While we could not distinguish between impacts of standard farmer burning practice and fire exclusion treatments for the current fallow scenario, we concluded that fire exclusion would lead to higher yields, higher ecosystem carbon stocks as well as potentially faster fallow recovery under the reduced fallow scenario. While its implementation would increase labor requirements, we estimated increased revenues of 421 and 388  US$ ha− 1 for plantain and maize, respectively. Applied to the FMBA, and assuming a 6 -year reduced fallow scenario, fire exclusion in plantain fields would potentially retain 240, 464  Mg more ecosystem carbon, comprising topsoil carbon plus tree biomass carbon, than standard farmer practice. Results demonstrate a potential “win–win scenario” where yield benefits, albeit modest, and conservation benefits can be obtained simultaneously. This could {{be considered as a}} transitional phase towards higher input use and thus higher yielding systems...|$|R
40|$|The African {{root and}} tuber scale (ARTS) Stictococcus vayssierei Richard is a {{subterranean}} insect originally infesting several native plant {{species in the}} forest zones of Central Africa. With help of the native ant Anoplolepis tenella Santchi, ARTS has recently emerged as a major constraint to cassava production. We conducted an experiment in 18 farmer fields in two villages in the Forest <b>Margins</b> <b>Benchmark</b> Area of Cameroon {{to test the hypothesis}} that removal from fallows of known host-plant residues prior to field establishment will reduce subsequent ARTS infestation on cassava. Two 20 m x 20 m plots ('treated' and control) were established in each of 18 fields. Both plots were prepared and subsequently managed by the farmer according to field practices prevalent in the area. In the 'treated' plot, however, all host-plant residues were removed thoroughly prior to cassava planting. Densities of ARTS and its associated ant were determined on a sample of ten plants in each plot at three, six and nine months after planting (MAP). Overall average ARTS density per plant was not significantly different between treated and control plots. However, variation in ARTS densities between fields within a village was high, and in several fields ARTS densities were significantly higher in one plot compared with the other. ARTS densities were higher in control than in treated plots in 4 out of 18 fields, while higher scale densities occurred in treated compared with control plots in one field. ARTS densities did not differ between plots in the remaining 13 fields. These results indicated that removal of host-plant residues before planting as it was practiced in this study cannot significantly reduce ARTS infestations on cassava. Explanations and recommendations are provided for further testing of the impact of pre-planting host-plant residue removal on ARTS infestations in cassava fields in Central Africa. International Fund for Agricultural DevelopmentAustrian Ministry of Foreign AffairsPeer Revie...|$|R
40|$|The {{purpose of}} a margin {{requirement}} is to protect a clearinghouse from members' defaults resulting from big losses due to adverse movement of futures prices. To decide on how much a margin is required, a clearinghouse may refer to a <b>benchmark</b> <b>margin</b> defined as a constant multiple of the forecasted volatility. However, a <b>benchmark</b> <b>margin</b> only advises on a desirable margin level. It gives no advice on whether a clearinghouse should alter existing required margin. This paper proposes a margin scheme that can advise on when to change the required margin and if a change is recommended, to what level it should be changed. The proposed margin scheme can be devised so that the coverage probability and change frequency are controlled at target levels deemed appropriate by the clearinghouse. The proposed margin scheme needs a volatility forecast as input. This paper shows that among {{a large number of}} volatility forecasts, implied volatility gives the best results. This confirms a conjecture that implied volatility may have more information content than other volatility forecasts as far as margin setting is concerned. © 2010 Elsevier B. V. All rights reserved. link_to_subscribed_fulltex...|$|R
40|$|Cepstral {{features}} {{have been}} widely used in audio applications. Domain knowledge has {{played an important role in}} designing different types of cepstral features proposed in the literature. In this paper, we present a novel approach for learning optimized cepstral features directly from audio data to better discriminate between different categories of signals in classification tasks. We employ multi-layer feedforward neural networks to model the cepstral feature extraction process. The network weights are initialized to replicate a reference cepstral feature like the mel frequency cepstral coefficient. We then propose a embedded approach that integrates feature learning with the training of a support vector machine (SVM) classifier. A single optimization problem is formulated where the feature and classifier variables are optimized simultaneously so as to refine the initial features and minimize the classification risk. Experimental results have demonstrated the effectiveness of the proposed feature learning approach, outperforming competing methods by a large <b>margin</b> on <b>benchmark</b> data. ...|$|R
40|$|Abstract — This paper {{proposes a}} novel {{technique}} for representing system security constraints that properly include voltage stability limits {{in the operation}} of competitive electricity markets. The market clearing algorithm is modeled as a voltage stability constrained Optimal Power Flow (OPF) problem, while the distance to the closest critical power flow solution is represented by means of a loading parameter and evaluated using a Continuation Power Flow (CPF) technique. Sensitivities obtained at the OPF step are used to estimate power directions for the CPF method, while the CPF analysis provides the loading parameter {{to be used in the}} OPF problem based on an N- 1 contingency criterion. The OPF and the CPF steps are repeated until the maximum loading parameter is found, thus providing optimal solutions considering both proper market conditions and security <b>margins.</b> Two <b>benchmark</b> systems with both supply and demand bidding are used to illustrate and test the proposed technique. Index Terms — Electric energy markets, security, optimal power flow, continuation power flow, sensitivity analysis, voltage stability. I...|$|R
40|$|In this paper, {{we present}} a face {{detector}} based on Cascade Deformable Part Models (CDPM) [1]. Our model is learnt from partially labelled images using Latent Support Vector Machines (LSVM). Recently Zhu et al. [2] proposed a Tree StructureModel for multi-view face detection trained with facial landmark labels, which resulted on a complex and suboptimal system for face detection. Instead, we adopt CDPMs enhanced with a data-mining procedure to enrich models during the LSVM training. Furthermore, a post-optimization procedure is derived to improve {{the performance of the}} CDPMs. Experimental results show that the proposed model can deal with highly expressive and partially occluded faces while outperforming the state-of-the-art face detectors by a large <b>margin</b> on challenging <b>benchmarks</b> such as the FDDB [3] and the AFLW [4] databases...|$|R
40|$|Real‐time {{estimates}} of potential output {{are used for}} the calculation of the cyclically adjusted budget balance, {{one of the main}} indicators in the assessment of the fiscal performance of EU member states. The estimation of potential output involves a decomposition of actual output into a cyclical and a structural component based on arbitrary assumptions about the statistical properties of the two unobserved components. With a very high degree of smoothing, variations in GDP are mostly taken to be temporary, as are the ensuing changes in the budget deficit. Conversely, with a low degree of smoothing, variations in GDP are mostly taken to be permanent, leading to different policy conclusions. Our paper examines whether and how different potential output estimates would have supported different decisions in the EU budgetary surveillance in terms of both timing and substance. The results show that only a very high degree of smoothing of potential output would significantly reduce the reliability of the surveillance indicators. We conclude that a higher degree of smoothing compared with current practice would not be harmful for EU fiscal surveillance, while it could contribute to more cautious policies by signalling larger and longer periods of economic ‘good times’. potential output, cyclical adjustment, EU budgetary surveillance, Stability and Growth Pact, Excessive Deficit Procedure, safety <b>margin,</b> minimum <b>benchmark,</b> fiscal surveillance indicators,...|$|R
40|$|This paper {{presents}} a novel {{framework in which}} image cosegmentation and colocalization are cast into a single optimization problem that integrates information from low level appearance cues with that of high level localization cues in a very weakly supervised manner. In contrast to multi-task learning paradigm that learns similar tasks using a shared representation, the proposed framework leverages two representations at different levels and simultaneously discriminates between foreground and background at the bounding box and superpixel level using discriminative clustering. We show empirically that constraining the two problems at different scales enables the transfer of semantic localization cues to improve cosegmentation output whereas local appearance based segmentation cues help colocalization. The unified framework outperforms strong baseline approaches, of learning the two problems separately, by a large <b>margin</b> on four <b>benchmark</b> datasets. Furthermore, it obtains competitive results compared {{to the state of}} the art for cosegmentation on two benchmark datasets and second best result for colocalization on Pascal VOC 2007. Comment: 8 pages, Under Revie...|$|R
40|$|Training a deep {{architecture}} using {{a ranking}} loss has become {{standard for the}} person re-identification task. Increasingly, these deep architectures include additional components that leverage part detections, attribute predictions, pose estimators and other auxiliary information, in order to more effectively localize and align discriminative image regions. In this paper we adopt a different approach and carefully design each component of a simple deep architecture and, critically, the strategy for training it effectively for person re-identification. We extensively evaluate each design choice, leading {{to a list of}} good practices for person re-identification. By following these practices, our approach outperforms the state of the art, including more complex methods with auxiliary components, by large <b>margins</b> on four <b>benchmark</b> datasets. We also provide a qualitative analysis of our trained representation which indicates that, while compact, it is able to capture information from localized and discriminative regions, in a manner akin to an implicit attention mechanism...|$|R
40|$|Matching local {{geometric}} {{features on}} real-world depth images is a challenging task {{due to the}} noisy, low-resolution, and incomplete nature of 3 D scan data. These difficulties limit the performance of current state-of-art methods, which are typically based on histograms over geometric properties. In this paper, we present 3 DMatch, a data-driven model that learns a local volumetric patch descriptor for establishing correspondences between partial 3 D data. To amass training data for our model, we propose a self-supervised feature learning method that leverages the millions of correspondence labels found in existing RGB-D reconstructions. Experiments show that our descriptor is not only able to match local geometry in new scenes for reconstruction, but also generalize to different tasks and spatial scales (e. g. instance-level object model alignment for the Amazon Picking Challenge, and mesh surface correspondence). Results show that 3 DMatch consistently outperforms other state-of-the-art approaches by a significant <b>margin.</b> Code, data, <b>benchmarks,</b> and pre-trained models are available online at [URL] To appear at the Conference on Computer Vision and Pattern Recognition (CVPR) 2017. Project webpage: [URL]...|$|R
40|$|Abstract—The goal of semi-supervised {{learning}} (SSL) methods is {{to reduce}} the amount of labeled training data required by learning from both labeled and unlabeled instances. Macskassy and Provost [1] proposed the weighted-vote relational neighbor classifier (wvRN) as a simple yet effective baseline for semi-supervised learning on network data. It is similar to many recent graph-based SSL methods (e. g., [2], [3]) and is shown to be essentially the same as the Gaussian-field classifier proposed by Zhu et al. [4] and proves to be very effective on some benchmark network datasets. We describe another simple and intuitive semi-supervised learning method based on random graph walk that outperforms wvRN by a large <b>margin</b> on several <b>benchmark</b> datasets when very few labels are available. Additionally, we show that using authoritative instances as training seeds — instances that arguably cost much less to label — dramatically reduces the amount of labeled data required to achieve the same classification accuracy. For some existing state-of-the-art semi-supervised learning methods the labeled data needed is reduced by a factor of 50. I...|$|R
40|$|The {{problem of}} {{predicting}} {{the location of}} users on large social networks like Twitter has emerged from real-life applications such as social unrest detection and online marketing. Twitter user geolocation is a difficult and active research topic with a vast literature. Most of the proposed methods follow either a content-based or a network-based approach. The former exploits user-generated content while the latter utilizes the connection or interaction between Twitter users. In this paper, we introduce a novel method combining the strength of both approaches. Concretely, we propose a multi-entry neural network architecture named MENET leveraging the advances in deep learning and multiview learning. The generalizability of MENET enables the integration of multiple data representations. In the context of Twitter user geolocation, we realize MENET with textual, network, and metadata features. Considering the natural distribution of Twitter users across the concerned geographical area, we subdivide {{the surface of the}} earth into multi-scale cells and train MENET with the labels of the cells. We show that our method outperforms the state of the art by a large <b>margin</b> on three <b>benchmark</b> datasets. Comment: Submitted to the IEEE Transactions on Big Dat...|$|R
40|$|The {{international}} OECD/NRC BWR Full-size Fine-Mesh Bundle Tests (BFBT) benchmark, {{based on}} the NUPEC database, encourages advancement in sub-channel analysis of two-phase flow in rod bundles, which has great relevance {{with regard to the}} nuclear reactor safety <b>margin</b> evaluation. This <b>benchmark</b> specification is being designed so that it can systematically assess and compare the participants’ numerical models for the prediction of detailed sub-channel void distributions and critical powers to full-scale experimental data on a prototypical BWR rod bundle. Currently the numerical modelling of sub-channel void distribution has no theoretical approach that can be applied {{to a wide range of}} geometrical and operating conditions. In the past decade, experimental and computational technologies have tremendously improved the study of the two-phase flow structure. Over the next decade, it can be expected that mechanistic approaches will be more widely applied to the complicated two-phase fluid phenomena inside fuel bundles. The development of truly mechanistic models for critical power prediction is currently underway. These models must include processes such as void distribution, droplet deposition, liquid film entrainment and spacer grid behaviour. The benchmark specification requires participants to explain their modelling correlations between the measured critical power and the two-phase flow dominant processes. ...|$|R
40|$|The goal of semi-supervised {{learning}} methods is {{to reduce}} the amount of labeled training data required by learning from both labeled and unlabeled instances. We make contribution towards this goal along several dimensions. Macskassy and Provost [13] proposed the weighted-vote relational neighbor classifier (wvRN) as a simple yet solid baseline for semi-supervised learning on network data. It is shown to be essentially the same as the Gaussian-field classifier proposed by Zhu et al. [22] and proves to be very effective on many benchmark network datasets. We describe another simple and intuitive semisupervised learning method based on random graph walk that outperforms wvRN by a large <b>margin</b> on several <b>benchmark</b> datasets when very few labels are available. Secondly, we show that using authoritative instances as training seeds — instances that arguably cost much less to label — dramatically reduces the amount of labeled data required to achieve the same classification accuracy. For some existing state-of-the-art semi-supervised learning methods the labeled data needed is reduced by a factor of 50. Third, we offer insights as to why learning methods based on random graph walk are able to more fully exploit the unlabeled data than previous methods. Based on the above observations, we strongly recommend the proposed method as a strong baseline for future research on semi-supervised classification of network data...|$|R
40|$|We {{present a}} multi-view face {{detector}} based on Cascade Deformable Part Models (CDPM). Over the last decade, {{there have been}} several attempts to extend the well-established Viola&Jones face detector algorithm {{to solve the problem of}} multi-view face detection. Recently a tree structure model for multi-view face detection was proposed. This method is primarily designed for facial landmark detection and consequently a face detection is provided. However, the effort to model inner facial structures by using a detailed facial landmark labelling resulted on a complex and suboptimal system for face detection. Instead, we adopt CDPMs, where the models are learned from partially labelled images using Latent Support Vector Machines (LSVM). Furthermore, LSVM is enhanced with data-mining and bootstrapping procedures to enrich models during the training. Furthermore, a post-optimization procedure is derived to improve the performance. This semi-supervised methodology allows us to build models based on weakly labelled data while incrementally learning latent positive and negative samples. Our results show that the proposed model can deal with highly expressive and partially occluded faces while outperforming the state-of-the-art face detectors by a large <b>margin</b> on challenging <b>benchmarks</b> such as the Face Detection Data Set and Benchmark (FDDB) [1] and the Annotated Facial Landmarks in the Wild (AFLW) [2] databases. In addition, we validate the accuracy of our models under large head pose variation and facial occlusions in the Head Pose Image Database (HPID) [3] and Caltech Occluded Faces in the Wild (COFW) datasets [4], respectively. We also outline the suitability of our models to support facial landmark detection algorithms...|$|R
40|$|This paper {{presents}} {{socio-economic analysis}} of the Desert <b>Margins</b> Programme (DMP) <b>benchmark</b> sites in Kajiado and Makueni Districts in Southern rangelands, Marsabit District (Kalacha, Kargi, Korr and Ngurunit) and Turkana District (Turkwel ecosystem). DMP is addressing land degradation and loss of biodiversity in marginal areas. It focuses research and development activities on people (livelihoods, food security, leadership, culture, indigenous knowledge system, level of modern knowledge/training, poverty); environment (vegetation trends, land degradation, biodiversity, land use systems) and natural resources management (NRM) policies. During characterisation of benchmark sites, stratified random sampling was used to sample 180 respondents. Data was collected by questionnaire and analysed using the Statistical Package for Social Scientists (SPSS). The livelihoods approach was used to describe, explore and predict interactions between livelihood assets, natural resources management strategies, policies, institutions and processes, livelihood strategies and livelihood outcomes. The sample of 97 male and 83 female respondents from 157 male-headed and 23 female-headed households, revealed fair gender parity. Results indicated age and gender as important demographic characteristics in decision-making structures and resource-ownership regimes. The main occupations were crop and livestock production, which were perceived to pose challenges to maintaining environmental integrity. Other livelihood strategies included pottery, basketry, carvings, sale of firewood and charcoal, sale of medicinal plant extracts and bee keeping. Constraints to marketing crops and livestock were noted. To secure and sustain current livelihood assets (human, financial, social, natural and physical) of the people, this paper recommends facilitation of relevant policies, institutions and processes, transfer of relevant knowledge and enhanced marketing opportunitie...|$|R

