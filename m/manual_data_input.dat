15|10000|Public
50|$|REACT {{incorporates}} a secure communication link between LCC and Higher Authority (SACCS) to receive and configuration and targeting data without {{any need for}} <b>manual</b> <b>data</b> <b>input.</b>|$|E
5000|$|The latter feature, {{although}} not externally apparent, {{was perhaps the}} most pioneering of the design; a leap forward from the rudimentary action information system of the [...] "Counties" [...] and its heavy reliance on <b>manual</b> <b>data</b> <b>input.</b>|$|E
50|$|Bristol saw {{a number}} of new systems {{introduced}} into the Navy, including the Sea Dart anti-aircraft and Ikara anti-submarine missile systems and was the first Royal Navy ship to carry the 4.5 inch (113 mm) Mk 8 gun. Another addition to the fleet was the new advanced Action Data Automated Weapons System Mk.2 (ADAWS-2), a computer system designed to coordinate the ship's weapons and sensors. ADAWS-2 was a large advance on the rudimentary action information system of its predecessor the s, which was heavily reliant on <b>manual</b> <b>data</b> <b>input.</b>|$|E
40|$|November 1986. ""Turner-Fairbank Highway Research Center. ""A Traffic Engineer's Guide. "Prepared by K. G. Courage, C. E. Wallace, D. P. Reaves (Transportation Research Center, University of Florida). Cover title. Includes bibliographical references. User's <b>manual</b> [...] <b>Data</b> <b>input</b> {{processors}} (AAP forms) [...] <b>Data</b> <b>input</b> processor (AAP DIM) [...] Microcomputer version (PC-AAP). User's manual. Sponsored by U. S. Federal Highway Administration, Office of Research and Development. Mode of access: Internet...|$|R
40|$|Abstract. Coal {{consumption}} characteristics {{data provided}} by on-line monitoring system are crucial for Energy-saving generation dispatching. Therefore contrastive tests are required for checking {{the accuracy of the}} coal consumption on-line monitoring system. In the paper, factors affecting coal consumption characteristics data were analyzed, methods and contents of the contrastive tests were also achieved. By comparing three test conditions with the base condition, computing program, measuring points, <b>manual</b> <b>inputting</b> <b>data</b> and other influencing factors were checked. This tests could provide accurate coal consumption characteristics data. This study has been applied successfully in many plant units, and the formation of local standard in Guizhou Province, China...|$|R
40|$|The proper {{presentation}} {{and management of}} information in America's largest and busiest (Level V) air traffic control towers calls for an in-depth understanding of many different human-computer considerations: user interface design for graphical, radar, and text; <b>manual</b> and automated <b>data</b> <b>input</b> hardware; information/display output technology; reconfigurable workstations; workload assessment; and many other related subjects. This paper discusses these subjects {{in the context of}} the Surface Development and Test Facility (SDTF) currently under construction at NASA's Ames Research Center, a full scale, multi-manned, air traffic control simulator which will provide the "look and feel" of an actual airport tower cab. Special emphasis will be given to the human-computer interfaces required for the different kinds of information displayed at the various controller and supervisory positions and to the computer-aided design (CAD) and other analytic, computer-based tools used to develop the facility...|$|R
50|$|An optical virtual {{keyboard}} {{was invented}} and patented by IBM engineers in 1992. It optically detects and analyses human hand and finger motions and interprets them as operations on a physically non-existent input device like a surface with painted or projected keys. In that way it can emulate unlimited types of manually operated input devices (such as a mouse, keyboard, and other devices). Mechanical input units {{can be replaced}} by such virtual devices, potentially optimized for a specific application and for the user's physiology, maintaining speed, simplicity and unambiguity of <b>manual</b> <b>data</b> <b>input.</b>|$|E
50|$|Range and {{direction}} correction system provides better accuracy {{with respect to}} its predecessors. The Morava can launch single rocket, partial ripple or full salvo, which can cover an area of 32 hectares.The LRSVM is equipped with fully automatic targeting control systems. The launch vehicle is fitted with an Inertial Navigation System (INS), GPS unit and absolute encoders for automatic positioning. Vehicle has ballistic computer with automatic or <b>manual</b> <b>data</b> <b>input</b> and firing elements computation. Rockets are launched directly form the cab or remotely form the vehicle. The LRSVM can fire single rockets or full salvo. A crew of three prepares this artillery system for firing within 45 seconds. It leaves firing position within 30 seconds.|$|E
50|$|The Rooikat 105 is {{designed}} for high mobility day and night combat operations. Passive image intensifiers and thermal imaging equipment for night driving, navigation and weapon deployment permit round-the-clock combat operations. The Rooikat 105 {{is equipped with a}} GT7 105mm anti-tank gun. The gun fires the full range of Nato full-pressure 105mm ammunition including generation I, II and III rounds. The gun, fitted with a 51-caliber thermal sleeve encased barrel, fires six rounds a minute. There are two 7.62mm machine guns, one co-axial to the main armament and one at the commander's position, for general purpose ground and air defence. The vehicle is equipped with two banks of 81mm smoke grenade launchers, mounted in a forward firing position {{on each side of the}} turret. The system is electrically operated. The smoke grenades form a dense protective smoke screen, which can be sustained using an exhaust smoke generator. The digital fire control system takes data from a suite of sensors and provides an automatic fire control solution. Automatic data input includes target range from a laser rangefinder, target speed and direction derived from tracking the target, crosswind speed, weapon tilt and the characteristics of the weapon. <b>Manual</b> <b>data</b> <b>input</b> includes ammunition type and environmental data. The fire control system allows the Rooikat to engage enemy targets while on the move across rough terrain. The time between laser ranging the target and firing is approximately two seconds. Three variations of fire directing systems are offered. The most complex system incorporates a primary stabilised gunner's sight, automatic computation and implementation of ballistic offset of the weapon, electro-mechanical gun control, stabilised main weapon, gunner's sight with day / night channel slaved to the main weapon and an independent panoramic commander's sight.|$|E
40|$|A {{simulation}} {{program for}} the flow of data through the Data Management System of Spacelab and Space Shuttle was presented. The science, engineering, command and guidance, navigation and control data were included. The programming language used was General Purpose Simulation System V (OS). The science and engineering data flow was modeled from its origin at the experiments and subsystems to transmission from Space Shuttle. Command data flow was modeled {{from the point of}} reception onboard and from the CDMS Control Panel to the experiments and subsystems. The GN&C data flow model handled data between the General Purpose Computer and the experiments and subsystems. Mission 18 was the particular flight chosen for simulation. The general structure of the program is presented, followed by a user's <b>manual.</b> <b>Input</b> <b>data</b> required to make runs are discussed followed by identification of the output statistics. The appendices contain a detailed model configuration, program listing and results...|$|R
40|$|This is a reportSafetyNet {{work package}} 5 (WP 5), in the {{creation}} of two in-depth European accident databases, has produced a comprehensive database glossary to help inform both those directly involved in the work package and those who will use the final data and analysis results. The final version of the glossary can be regarded as a repository of information generated during the completion of the task and as such combines to provide a ‘Manual’ for the data collection and data use within the work package and externally. Information contained within the glossary extends from the early development stages of the task to the final review, a duration of approximately 4. 5 years. The complete glossary has been designed to provide all the information relevant for a thorough understanding of the SafetyNet WP 5 task. This information {{can be used in a}} number of ways as the complete document combines to produce a <b>manual</b> for <b>data</b> <b>input</b> (also referred to as ‘coding’), data analysis and the understanding of any analysis by external parties The SafetyNet WP 5 glossary provides information in 6 key areas, all of which build into a complete picture of the WP 5 project as a whole, the 6 key areas in turn provide information on glossary use, data Limitations and restrictions, the data variables, accident classification system (GDV), SafetyNet accident causation system (SNACS) and Database usage The glossary is intended to be used as complete reference material covering all of the aspects listed in the previous paragraph. As such the glossary should be used as a guide to understanding the task and any analysis derived from the WP 5 data. The glossary however, is not a specific tool for conducting full analysis as only illustrative details of data limitation and restrictions are included. These will be discussed in more detail and should be fully understood before work is undertaken as misuse could lead to misinterpretation of any results...|$|R
40|$|A {{collection}} of Scientific and Technical Reports (CSTR) 13; list is a bibliography of new reports. It is an announcement {{to be made}} by an Information Centre or Library as and when new reports are received and acquired by it. Information Centre for Aeronautics (ICA) at National Aeronautical Laboratory, Bangalore produces such a CSTR on monthly basis, announcing thereby its new acquisition of reports. This CSTR list is widely circulated to the users of NAL Library. After generating the above list, the same data is deposited and stored permanently in a report database for the purpose of information retrieval. 13; 13; In this document, the input formats, standardisation of <b>input</b> of <b>data,</b> rules and guidelines pertaining to <b>inputting</b> of <b>data</b> of reports are discussed in detail. For <b>inputting</b> of <b>data,</b> UDS 2000 Off-line key to floppy Data entry system has been used. The database of reports is stored and maintained on Sperry Univac 1171 /H 1 Computer System at the Computer Centre, NAL, Bangalore. This document serves as a <b>manual</b> for <b>inputting</b> <b>data</b> of reports. 13; 13...|$|R
40|$|Tower crane {{layout design}} and {{planning}} within construction {{site is a}} common construction technical issue, and {{is regarded as a}} complex combinatorial problem. Previous research focused on utilising either mathematical methods or visualisation tools to find an optimal tower crane layout plan. Both these two approaches require large amounts of <b>manual</b> <b>data</b> <b>input</b> by the layout planners, which is time-consuming and not very practical in industry. The {{purpose of this paper is}} to develop an integrated approach which combines Building Information Modelling (BIM) and Firefly Algorithm (FA) to automatically generate an optimal tower crane layout plan. Firstly, BIM is utilised to provide inputs for the mathematical model. Then the FA is used to determine the optimal locations of tower cranes and supply points. Finally, the optimal tower crane layout scheme will be visualised and evaluated through BIM-based simulation. A practical case is selected to demonstrate the proposed approach. The final result is promising and demonstrates the practical value of this approach...|$|E
30|$|In {{order to}} address all these {{challenges}} we developed a generic, ontology-centered research infrastructure. The main principle is the following: By modeling the actual research domain {{in the form of}} a domain ontology (Step 1 of the process), the domain-experts build the base for all subsequent steps. The whole research infrastructure derives its structure and behavior from the central domain ontology—at run-time. Changes to the ontology have immediate effects on the whole system, which consists of three main modules. Firstly, a management tool, which allows the user to model and maintain the domain ontology, but also process and analyze the research data. The other two components are an ontology-derived electronic data interface based upon and open-source ETL (Extract-Transform-Load) suite, and an ontology-derived web interface for <b>manual</b> <b>data</b> <b>input</b> and processing. Wherever possible the elaborate structural meta-information is used to actively support the user in data handling, processing and analyzing. The system always appears to the user as if it was especially tailored for his domain. For further information in more detail on the infrastructure itself, the reader is kindly referred to [29, 30, 31].|$|E
40|$|Applications {{for self}} {{tracking}} that collect, analyze, or publish personal and medical data {{are getting more}} popular. This includes either a broad variety of medical and healthcare apps {{in the fields of}} telemedicine, remote care, treatment, or interaction with patients, and a huge increasing number of self tracking apps that aims to acquire data form from people’s daily life. The Quantified Self movement goes far beyond collecting or generating medical data. It aims in gathering data of all kinds of activities, habits, or relations that could help to understand and improve one’s behavior, health, or well-being. Both, health apps as well as Quantified Self apps use either just the smartphone as data source (e. g., questionnaires, <b>manual</b> <b>data</b> <b>input,</b> smartphone sensors) or external devices and sensors such as ‘classical’ medical devices (e. g,. blood pressure meters) or wearable devices (e. g., wristbands or eye glasses). The data can be used to get insights into the medical condition or one’s personal life and behavior. This talk will provide an overview of the various data sources and data formats that are relevant for self tracking as well as strategies and examples for analyzing that data with Python...|$|E
2500|$|Thursday 18 October from midday for <b>Manual</b> <b>data</b> entry centres ...|$|R
50|$|This method can {{automate}} {{data processing}} by using pre-defined templates and configurations. A template in this case, {{would be a}} map of the document, detailing where the data fields are located within the form or document. As compared to the <b>manual</b> <b>data</b> entry process, automatic form input systems are more preferable, since they help reduce the problems faced during <b>manual</b> <b>data</b> processing.|$|R
40|$|Metadata is {{important}} for the interpretation of scientific data, quality assessment and long term usability of data sets. The sharing of spectral data collections among research groups is uncommon {{and one of the reasons}} for this is the missing standardisation of the sampling process. Appropriate metadata serves the purpose of detailing the sampling procedure and the surrounding conditions during data capture, thus providing necessary information for data sharing. Reliable data retrieval requires the organised storage of spectral and metadata. To this means RSL developed the SPECCHIO system which is based on a relational database and provides <b>data</b> <b>input,</b> query and output mechanisms that strive to minimize the <b>manual</b> <b>data</b> capture. SPECCHIO serves as a non-redundant repository and source for spectral signatures which can be retrieved by metadata queries. The system will be used in the level 2 / 3 processing of the APEX (Airborne Prism Experiment) product generation to support the classification of natural and manmade materials and landcovers...|$|R
40|$|Construction {{site layout}} {{planning}} (CSLP) {{is recognized as}} a crucial component of construction management. The objective of CSLP {{is to determine the}} best arrangement of temporary facilities on a construction site, which would minimize the transportation distance of site personnel and equipment. It could be achieved by creating dynamic layout models that allow layout planners to cater the changing requirements of the site. However, these models are project specific and require large amount of <b>manual</b> <b>data</b> <b>input</b> by the layout planner. Besides being tedious, this approach is not practical either, since any changes to the design or construction plans would have to be manually updated into the models, resulting in unnecessary work by the layout planner. In this study, we propose an automated framework to create dynamic site layout models leveraging the BIM technology. Using the information in BIM models and construction schedules, a dynamic layout model can be automatically created for facility layout optimization. Furthermore, the actual travel distances among facilities instead of Euclidean distances are considered in our framework when performing the facility layout optimization. A&z. ast; algorithm and genetic algorithm heuristic method are used. The proposed approach and framework could reflect the actual site situation and facilitate the facility layout planning on construction sites. A case example is presented in this paper to demonstrate the framework and compare its results with those using Euclidean distances...|$|E
40|$|This is {{a conference}} paper [© IEEE]. It is also {{available}} from: [URL] Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must {{be obtained from the}} IEEE. In order to design and implement the information systems and modules that could comprise an “industrial strong” knowledge-based tool, links to shop floor systems containing real-time production data and PCA customer information (e. g. bill of materials (BOM), CAD drawings) are required. Details of the issues of implementing the tool in an industrial organisation and the integration of various data sources (e. g. “in-house” developed systems, enterprise resource planning systems, ad-hoc developed databases, machine data and CAD data) are presented in this paper. The application of the CLOVES system in an industrial setup highlights the difficulties in integrating information from design as CAD data and shows how these setbacks could be overcome if the electronics industry were to adopt a common CAD assembly information exchange platform. Hence, this paper concludes that existing automation tool manufacturers should focus exclusively on developing generic connections by adopting industry standards that can facilitate the deployment of “plug and play” tools. This standardisation could in turn help software developers, to provide the electronics industry with more integrated systems that communicate better among loosely coupled information systems and avoid depending on extensive time consuming <b>manual</b> <b>data</b> <b>input...</b>|$|E
40|$|The use of robots and {{automation}} {{levels in}} the industrial sector is expected to grow, and {{is driven by the}} on-going need for lower costs and enhanced productivity. The manufacturing industry continues to seek ways of realizing enhanced production, and the programming of articulated production robots has been identified as a major area for improvement. However, realizing this automation level increase requires capable programming and control technologies. Many industries employ offline-programming which operates within a manually controlled and specific work environment. This is especially true within the high-volume automotive industry, particularly in high-speed assembly and component handling. For small-batch manufacturing and small to medium-sized enterprises, online programming continues to play an important role, but the complexity of programming remains a major obstacle for automation using industrial robots. Scenarios that rely on <b>manual</b> <b>data</b> <b>input</b> based on real world obstructions require that entire production systems cease for significant time periods while data is being manipulated, leading to financial losses. The application of simulation tools generate discrete portions of the total robot trajectories, while requiring manual inputs to link paths associated with different activities. Human input is also required to correct inaccuracies and errors resulting from unknowns and falsehoods in the environment. This study developed a new supported online robot programming approach, which is implemented as a robot control program. By applying online and offline programming in addition to appropriate manual robot control techniques, disadvantages such as manual pre-processing times and production downtimes have been either reduced or completely eliminated. The industrial requirements were evaluated considering modern manufacturing aspects. A cell-based Voronoi generation algorithm within a probabilistic world model has been introduced, together with a trajectory planner and an appropriate human machine interface. The robot programs so achieved are comparable to manually programmed robot programs and the results for a Mitsubishi RV- 2 AJ five-axis industrial robot are presented. Automated workspace analysis techniques and trajectory smoothing are used to accomplish this. The new robot control program considers the working production environment as a single and complete workspace. Non-productive time is required, but unlike previously reported approaches, this is achieved automatically and in a timely manner. As such, the actual cell-learning time is minimal. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|A new hand- or finger-mounted <b>data</b> <b>input</b> {{device is}} pre-sented, using {{traditional}} touch-typing skills as method of (al-phabetic) character input thus providing an ultra-portable solution for “quiet ” <b>data</b> <b>input</b> into portable computer sys-tems. The presented keyboard independent touch-typing de-vice (KITTY) offers high <b>data</b> <b>input</b> rates and a virtually zero learning curve for new users. ...|$|R
25|$|Process {{activities}} are knowledge and collaborative activities that result due to organizational context such as errors/rework, <b>manual</b> <b>data</b> transformation, stress, politics, etc.|$|R
5000|$|A {{write to}} this {{register}} will reset bits 5 through 7 of SKSTAT which are latches to 1. The latches flag keyboard overrun, Serial <b>data</b> <b>input</b> overrun, and Serial <b>data</b> <b>input</b> frame error.|$|R
40|$|Purpose: To {{investigate}} {{the possibility of}} application of knowledge-based expert systems to facilitate the task of techno-economical feasibility analysis of utilization of special purpose machines for high quantity production tasks. Also, to study the possibility of assisting special purpose machine designers in applying knowledge-based expert systems in the design task {{in order to reduce}} required machine design time, improve machine design efficiency, and eliminate possible human errors. Design/methodology/approach: Development of a knowledge-based expert system has been proposed to help decide where to utilize special purpose machines to accomplish the production task. The knowledge-based expert system consists of a rule-base which contains qualitative human knowledge and expertise in the form of if-then rules; and a database which contains qualitative information of machining operations, and characteristics of standardized special purpose machine components. Findings: A case study has been presented where an analysis has been {{made on the basis of}} techno-economical considerations for a typical part with three machining operations to be produced in large quantities. It has been concluded that for the given production task, special purpose machines would result in a significant 59 % reduction of costs compared to CNC machines, and 95. 5 % compared to traditional machines. The proposed methodology also reduces the time and effort needed for decision making on utilization of special purpose machines and determination of machine layout. In addition, it minimizes the level of expertise required to perform these functions and eliminates possible human errors. Research limitations/implications: The current system focuses on drilling and drilling-related operations which cover about 60 % of all machining operations. More work is needed to cover other machining operations including milling. Also the KBES developed currently works on a standalone basis. Work is in progress to integrate it with a 3 D CAD modelling system. Upon completion the information could be directly extracted from the CAD system, eliminating the need for <b>manual</b> <b>data</b> <b>input</b> by the user. Originality/value: In spite of a large number of publications on machine tool design in the literature, publications on special purpose machines are very limited. The method of techno-economical analysis presented here for utilization of special purpose machines in comparison with other production alternatives is of great value to manufacturing engineers and specialists. Also the methodology presented for machine design and implementation is highly valued by machine tool designers and manufacturers...|$|E
40|$|This thesis mainly {{focuses on}} the study and {{application}} of the integration of Computer numerical control (CNC) machining and on-machine cutting tool measurement. According to the industry survey, in current aerospace industry, the usage of off-line tool setters {{is one of the}} most prevailing ways for cutting tools measurement. The following up manual tool data input is required so that the CNC machine will know the tool dimension and finish the assigned machining tasks. Off-line tool setters are often of high accuracy and the measurement results are reliable. However, due to its off-line characteristic, after the tool is used, its current dimension status cannot be known or updated. Thus the quality of the upcoming machined parts cannot be guaranteed. Moreover, the involvement of operators’ <b>manual</b> <b>data</b> <b>input</b> in the traditional method inevitably introduces human error to machining from time to time. To improve the process of part machining and eventually achieve produced parts that are within tolerance, a new approach is proposed in this thesis on the integration of machining and on-line tool measurement. The idea is to perform tool measurement without unloading the tool from the CNC machine, and update the tool dimension data in the machine control before the tool is used to machine the part. The key to this approach is the employment of a laser tool setter, an optoelectronic device that has the ability to communicate with the CNC control. Analysis on kinematics of this new type of device is conducted and its method of communication with CNC machine control is described. Special software on CNC machine control level must be utilized to achieve the objective of on-machine measurement. Custom macros features of FANUC controls is used to suit the needs of parametric programming. The discussions on custom macros feature are carried out in this thesis. With the measurement method established, measurement uncertainty of the system will be discussed in depth. Considering the special attributes of the laser tool setter, the tool geometry and the machine control, an optimized measurement strategy is studied and proposed. Finally, experiments are carried out to verify the accuracy and repeatability of the measurement system. Application on rejecting out-of-tolerance tool being used in machining is also discussed. The result of applications shows the measurement system is suitable for industry use. ...|$|E
50|$|VBT is a {{possible}} way to avoid {{much of the time}} and cost of <b>manual</b> <b>data</b> mapping using traditional extract, transform, load technologies.|$|R
50|$|<b>Input</b> <b>data</b> is {{classified}} into two categories: relative <b>input</b> <b>data</b> and absolute <b>input</b> <b>data.</b>|$|R
5000|$|Data: widgets for <b>data</b> <b>input,</b> <b>data</b> filtering, sampling, imputation, feature {{manipulation}} and feature selection ...|$|R
5000|$|Direct {{integration}} with accounting system: Can the expense data flow {{directly into the}} accounting system, coded appropriately, {{without the need for}} any <b>manual</b> <b>data</b> entry? ...|$|R
40|$|Current {{field data}} {{collection}} methods for many of today’s scientific and other observer/monitor type applications are still entrenched in the “clipboard age”, requiring <b>manual</b> <b>data</b> transcription to a database management system at some (often much) later date, and only allows for visualisation and analysis of recently captured field data “back in the lab”. This chapter is targeted at progressing today’s pen & paper methodology into the spatially enabled mobile computing age of realtime multi-media <b>data</b> <b>input,</b> integration, visualisation, and analysis simultaneously both {{in the field and}} the lab. The system described is customized to the specific needs of the Canadian Great Lakes Laboratory for Fisheries and Aquatic Sciences Fish Habitat Management Group requirements for fish species at risk assessment, but is ready for adaptation to other environmental agency applications (e. g. forestry, health-pesticide monitoring, agriculture, etc.). The chapter is ideally suited to all agencies responsible for collecting field data of any type that have not yet moved to a state-of-the-art mobile and wireless data collection, visualisation, and analysis work methodolog...|$|R
40|$|Survey {{process in}} the field needs {{surveyor}} to writedown data manually on a paper. <b>Manual</b> <b>data</b> recording process will later be repeated to save it in the computer for a digital data. This process increases the possibility to have an error in the <b>data</b> <b>input</b> step from a handwritten data. Furthermore, {{there is a need}} to turn the survey data into a processed data for a decision making purpose by the survey administrator. Android is chosen as the mobile device platform in this thesis, because it is the most used platform in smartphones. Also, it answers the need of a surveyor in the field to easily carry the survey data. Server application uses Node. js framework to minimalize data process between platforms. There are two applications as the result, which are administrator web application and surveyor Android-based application. Web application is for creating, viewing, changing, deleting, and processing question and survey result data. Android-based application is to be used by specific surveyor in the field for answering many kinds of question types that is created in the web application...|$|R
40|$|Cosmedic {{is a field}} {{services}} and beauty products {{are included in the}} category of beauty treatments in Semarang are quite large and many devotees. During the data collection of customers / consumers care still use <b>manual</b> <b>data</b> collection that is filling the registration form and stored in the customer ledger. As for consulting services to customers in physician care. The results of the consultation treatment still use <b>manual</b> <b>data</b> collection were recorded in books care consultations by physicians. Warehouse section is still the drug data collection process also still use <b>manual</b> <b>data</b> collection so that the difficulty of making a report item, the difficulty of knowing the number of goods. Thus the beauty clinic is in desperate need of a computerized system in processing customer transactions in this Cosmedic. authors take the title with the theme as shown below Management Information Systems Nursing Care Beauty In Cosmedic Semaran...|$|R
50|$|Automated and <b>manual</b> <b>data</b> {{cleaning}} {{is commonly}} performed in migration to improve data quality, eliminate redundant or obsolete information, and match {{the requirements of}} the new system.|$|R
50|$|Many {{applications}} {{can reduce}} {{a major portion}} of <b>manual</b> <b>data</b> entry by populating data fields based upon the entered ISBN using MARC standards technology via the Internet.|$|R
5000|$|All {{these data}} collection, analysis, and {{visualization}} tasks are highly automated in modern software. In the past, however, these tasks required <b>manual</b> <b>data</b> recording and processing [...]|$|R
