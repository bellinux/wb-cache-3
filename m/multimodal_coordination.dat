8|3|Public
5000|$|... #Subtitle level 3: National Road Transport & <b>Multimodal</b> <b>Coordination</b> Authority ...|$|E
50|$|Creation of National Road Transport & <b>Multimodal</b> <b>Coordination</b> Authority for {{improving}} quality of road transportation, focus on developing integrated transport systems & multi-modal hubs and feeder system and last mile connectivity for people friendly mobility.|$|E
40|$|Abstract—By {{the onset}} of reaching, young infants are already able {{to keep track of}} the {{position}} of their hand by using visual feedback from the target and proprioceptive feedback from the arm. How is this <b>multimodal</b> <b>coordination</b> achieved? We propose that infants learn to coordinate vision and proprioception by using tactile feedback from the target. In order to evaluate this hypothesis, we employ an evolutionary-based learning algorithm as a proxy for trial-and-error sensorimotor development in young infants. A series of simulation studies illustrate how touch: 1) helps coordinate vision and proprioception; 2) facilitates an efficient reaching strategy; and 3) promotes intermodal recalibration when the coordination is perturbed. We present two developmental predictions generated by the model and discuss the relative importance of visual and tactile feedback while learning to reach. Index Terms—Computational model, <b>multimodal</b> <b>coordination,</b> sensorimotor development, trial-and-error learning...|$|E
40|$|Multimodal {{dialogue}} systems allow {{users to}} input information in multiple modalities. These systems can handle simultaneous or sequential composite <b>multimodal</b> input. Different <b>coordination</b> schemes require such systems to capture, collect and integrate user input in different modalities, and then {{respond to a}} joint interpretation. We performed a study to understand the variability of input in multimodal dialogue systems and to evaluate methods to perform the collection of input information. An enhancement {{in the form of}} incorporation of a dynamic time window to a multimodal input fusion module was proposed in the study. We found that the enhanced module provides superior temporal characteristics and robustness when compared to previous methods. ...|$|R
40|$|Abstract. Previous {{studies have}} {{argued for the}} use of gaze-assisted {{pointing}} techniques (MAGIC) in improving human-computer interaction. Here, we present experimental findings that were drawn from human performance of two tasks on a wall-sized display. Our results show that a crude adoption of MAGIC across a range of complex tasks does not increase pointing performance. More importantly, a detailed analysis of user behavior revealed several issues that were previously ignored (such as, interference of corrective saccades, increased decision time due to variability of precision, errors due to eye-hand asynchrony, and interference with search behavior) which should influence the development of gaze-assisted technology. Keywords: Eye-Tracking, Eye-Hand <b>Coordination,</b> <b>Multimodal.</b> ...|$|R
40|$|IJCAI- 99 in Stockholm. 2. The first {{workshop}} {{was aimed}} at studying the need for knowledge and reasoning in dialogue systems from theoretical and practical perspectives. Besides the innovative aspect of research, an emphasis was also laid {{on the importance of}} implemented dialogue systems as test-beds for evaluating the usefulness of theories and ideas, and on improvements in practical system abilities supporting a more natural and efficient interaction. The second workshop had a concentration on <b>multimodal</b> interfaces: the <b>coordination</b> and integration of multimodal inputs {{and the ways in which}} multimodal inputs reinforce and complement each other, and the role of dialogue in multimodal interaction. It took place at IJCAI- 2001 in Seattle. 3 The third workshop focused on the role and use of ontologies to develop flexible, adaptive, user-friendly and enjoyable multi-modal dialogue systems. It was held at IJCAI- 2003 in Acapulco 4. The fourth workshop had a focus on adaptivity in dialogue systems including research in three main areas: dialogue management, adaptive discourse planning, and automatic learning of dialogue policies. The fourth workshop was held at IJCAI- 2005 in Edinburgh. 5 The fifth workshop was held a...|$|R
40|$|Abstract [...] By {{the onset}} of reaching, young infants are already able {{to keep track of}} the {{position}} of their han by using visual feedback from the target and proprioceptive feedback from the arm. How is this <b>multimodal</b> <b>coordination</b> achieved? We propose that infants learn to coordinate vision and proprioception by using tactile feedback from the target. In order to evaluate this hypothesis, we employ an evolutionarybased learning algorithm as a proxy for trial-and-error sensorimotor development in young infants. A series of simulation studies illustrate how touch (1) help coordinate vision and proprioception, (2) facilitates a efficient reaching strategy, and (3) promotes intermodal recalibration when the coordination is perturbed. We present two developmental predictions generated by the model, and discuss the relative importance of visual and tactile feedback while learning to reach. Index terms [...] computational model, sensorimotor development, trial-and-error learning, <b>multimodal</b> <b>coordination</b> I...|$|E
40|$|The {{organization}} of time-varying linguistic behavior, while controlled, is not precisely timed. This claim is supported empirically, {{but it is}} also motivated theoretically by an idea that will be fleshed out in the talk; namely, language behavior necessitates a neuro-cognitive displacement from the fine-grained spatial and temporal instantiation of language. This obviates the need for the precise synchronization that can be observed in that other peculiarly human activity – music. Index Terms: concurrency, synchrony, <b>multimodal</b> <b>coordination,</b> instantaneous correspondence algorithm, language, musi...|$|E
40|$|This {{proposal}} {{is focused on}} the exhibition design interpreted as a complex process task of exhibition development strategies for a cultural event: a process where the most specialized component is implemented only in relation to a “humanistic sensitivity” that includes different levels of practices and processes. The exhibition design project moves between the spatial conformation control of the environment and the definition of the exhibition instruments: to get it, implements an intense coordination of multiple disciplines related to each other and often complementary. As claimed in this proposal the exhibition design is a discipline made up of <b>multimodal</b> <b>coordination</b> practices of their own forms of expression: a “culture project convergent”. To support this definition will be compared a few case studies of italian projects, analyzed through interviews with the designers and curators, to highlight the problems and the final results of a round trip between “humanities” and a project aims to make possible different modes of narrative and vision...|$|E
40|$|Across the nation, {{there are}} {{opportunities}} to improve coordination among transportation modal agencies, including aviation, transit, ports, highway, rail, pedestrian, and bicycle modes. Virginia’s statewide multimodal transportation planning effort VTrans 2025 addresses <b>multimodal</b> <b>coordination</b> of transportation {{investments in the}} state. Virginia’s Secretary of Transportation submitted a final report of the VTrans 2025 effort to the Virginia General Assembly in November 2004. The {{purpose of this study}} was to demonstrate an analytical methodology that could aid efforts such as this to coordinate and prioritize multimodal investments. The methodology developed can help decision makers to identify and prioritize proposed multimodal investment networks (MINs). These are large-scale coordinated investments in transportation projects across modes. The body of this report describes relevant literature and provides an overview of the developed methodology: (1) prioritization of the MINs, and (2) statistical comparison of modal plans. The analytical methodology developed will be of interest to multimodal transportation planning efforts across the nation, particularly where there is a need for systematic evidence-based approaches to coordinating the efforts of modal transportation agencies. Most data in the report are presented solely for purposes of demonstrating the methodology...|$|E
40|$|This {{dissertation}} documents three experiments {{investigating the}} potential effect of fractal fluctuations in exploratory {{behaviors in the}} change of perceptual judgments. Specifically, Experiment 1 dealt strictly with haptic perception and tests participants 2 ̆ 7 ability to judge geometrical properties of unseen wielded objects. It introduced a four-block structure in which the first and fourth blocks are a pretest and posttest, respectively, and the middle two blocks are used for training by visual feedback following each judgment. Results of Experiment 1 suggested that the fractality of fluctuations in manual wielding predicts accuracy in judging the object 2 ̆ 7 s geometric properties. With the same task and four-block structure, Experiment 2 sought to establish that the fractality of fluctuations in head sway predicts use of visual feedback to improve these judgments. Experiment 2 also investigated the relationship between fractality in head sway and fractality in manual wielding to determine how fluctuations at the head, incident to visual feedback, might influence fluctuations at the hand. Results suggested that fractal fluctuations in head sway predict the use of optical information and promote later fractal fluctuations at the hand during visual feedback. Departing from haptic perception, Experiment 3 tested visual judgments of the same objects as in Experiments 1 and 2, over four blocks but without any feedback. Experiment 3 sought to replicate effects for fractality of fluctuations in head sway and {{to determine whether or}} not the relationship between head and hand fractalities found in Experiment 2 was relevant to the coordination of the visual and the haptic perceptual subsystems. Results suggested that fractal fluctuations in head sway predicted the use of optical information during tasks without manual wielding but did not influence later fractal fluctuations at the hand. Taken together, the results of these experiments suggest that the fractality of exploratory behaviors optimizes use of available information for perception and provides a substrate for the <b>multimodal</b> <b>coordination</b> of perceptual subsystems during perceptual learning. ...|$|E

