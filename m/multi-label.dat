1535|135|Public
25|$|Yakhnenko, O., and Honavar, V. (2011). Multi-Instance <b>Multi-Label</b> Learning for Image Classification with Large Vocabularies. In: Proceedings of the British Machine Vision Conference.|$|E
500|$|In July 2016, {{the album}} was {{certified}} gold by the RIAA, and has sold 211,000 copies in the United States. In May 2015, Billboard revealed Lovato {{was in the process}} of starting an [...] "artist-centric" [...] new record label, Safehouse Records, of which she will be co-owner. The label will be a partnership between her, Nick Jonas, and Lovato's manager Phil McIntyre, and will form part of a new collaborative arrangement with record label Island. Confident was released through the new venture deal. This will be Lovato's second <b>multi-label</b> venture of her career; she was formerly part of Jonas Records, a UMG/Hollywood/Jonas Brothers partnership, which is now defunct.|$|E
50|$|There are {{two main}} methods for {{tackling}} the <b>multi-label</b> classification problem: problem transformation methods and algorithm adaptation methods. Problem transformation methods transform the <b>multi-label</b> problem into a set of binary classification problems, which can then be handled using single-class classifiers. Algorithm adaptation methods adapt the algorithms to directly perform <b>multi-label</b> classification. In other words, {{rather than trying to}} convert the problem to a simpler problem, they try to address the problem in its full form.|$|E
40|$|Linear {{discriminant}} analysis (LDA) {{is one of}} the most popular dimension reduction meth-ods, but it is originally focused on a single-labeled problem. In this paper, we derive the formulation for applying LDA for a <b>multi-labeled</b> problem. We also propose a generalized LDA algorithm which is effective in a high dimensional <b>multi-labeled</b> problem. Experi-mental results demonstrate that by considering <b>multi-labeled</b> structure, LDA can achieve computational efficiency and also improve classification performances...|$|R
40|$|Abstract. Nowadays {{data mining}} {{algorithms}} are successfully applying {{to analyze the}} real data in our life to provide useful suggestion. Since some available real data is multi-valued and <b>multi-labeled,</b> researchers have focused their attention on developing approaches to mine multi-valued and <b>multi-labeled</b> data in recent years. Unfortunately, there are no algorithms can discretize multi-valued and <b>multi-labeled</b> data to improve the performance of data mining. In this paper, we proposed a novel approach to solve this problem. Our approach {{is based on a}} statistical-based discretization metric and the simulated annealing search algorithm. Experimental results show that our approach can effectively improve the performance of the-state-of-art multi-valued and <b>multi-labeled</b> classification algorithm...|$|R
40|$|Recently, <b>multi-labeled</b> {{trees have}} been used to help unravel the {{evolutionary}} origins of polyploid species. A <b>multi-labeled</b> tree is the same as a phylogenetic tree except that more than one leaf may be labeled by a single species, so that the leaf set of a <b>multi-labeled</b> tree can be regarded as a multiset. In contrast to phylogenetic trees, which can be efficiently encoded in terms of certain bipartitions of their leaf sets, we show that it is NP-hard to decide whether a collection of bipartitions of a multiset can be represented by a <b>multi-labeled</b> tree. Even so, we also show {{that it is possible to}} generalize to <b>multi-labeled</b> trees a well-known condition that characterizes when a collection of bipartitions encodes a phylogenetic tree. Using this generalization, we obtain a fixed-parameter algorithm for the above decision problem in terms of a parameter associated to the given multiset...|$|R
5000|$|In machine learning, <b>multi-label</b> {{classification}} and the {{strongly related}} problem of multi-output classification are variants of the classification problem where multiple labels may {{be assigned to}} each instance. <b>Multi-label</b> classification is a generalization of multiclass classification, which is the single-label problem of categorizing instances into precisely {{one of more than}} two classes; in the <b>multi-label</b> problem there is no constraint on how many of the classes the instance can be assigned to.|$|E
5000|$|Multiclass {{classification}}, Multicriteria classification, <b>Multi-label</b> classification ...|$|E
5000|$|... #Subtitle level 2: Adapted {{algorithms}} for <b>multi-label</b> classification ...|$|E
40|$|Abstract: Schema {{matching}} is {{the task}} of finding semantic correspondences between elements of two schemas, which {{plays a key role}} in many database applications. In this paper, we cast the schema matching problem (SMP) into a <b>multi-labeled</b> graph matching problem. First, we propose an internal schema model: <b>multi-labeled</b> graph model, and transform schemas into <b>multi-labeled</b> graphs. Therefore, SMP reduce to a labeled graph matching, which is a classic combinatorial problem. Secondly, we study a generic graph similarity measure based on Contrast Model, and propose a versatile optimization function to compare two <b>multi-labeled</b> graphs. Then, we can design the optimization algorithm to solve the <b>multi-labeled</b> graph matching problem. Based on the matching result obtained by greedy matching, we implement a fast hybrid search algorithm to find the feasible matching results. Finally, we use several schemas to test the hybrid search algorithm. The experimental results confirm that the algorithm model and the hybrid algorithm are effective...|$|R
50|$|The scikit-learn Python package {{implements}} some <b>multi-labels</b> algorithms and metrics.|$|R
40|$|Abstract. In {{this paper}} we present methods of {{enhancing}} existing discriminative classifiers for <b>multi-labeled</b> predictions. Discriminative methods like support vector machines perform {{very well for}} uni-labeled text classification tasks. <b>Multi-labeled</b> classification is a harder task subject to relatively less attention. In the <b>multi-labeled</b> setting, classes are often {{related to each other}} or part of a is-a hierarchy. We present a new technique for combining text features and features indicating relationships between classes, which can be used with any discriminative algorithm. We also present two enhancements to the margin of SVMs for building better models in the presence of overlapping classes. We present results of experiments on real world text benchmark datasets. Our new methods beat accuracy of existing methods with statistically significant improvements. ...|$|R
5000|$|Peek-A-Boo (<b>multi-label</b> {{compilation}} covering '69 through '89) (Rhino) 1990 ...|$|E
5000|$|Collective <b>Multi-Label</b> Classification, Nadia Ghamrawi and Andrew McCallum. CIKM’05, Bremen, Germany.|$|E
5000|$|... k-nearest neighbors: the ML-kNN {{algorithm}} {{extends the}} k-NN classifier to <b>multi-label</b> data.|$|E
40|$|In {{the online}} {{dictionary}} matching problem {{the goal is}} to preprocess a set of patterns D={P_ 1, [...] .,P_d} over alphabet Sigma, so that given an online text (one character at a time) we report all of the occurrences of patterns that are a suffix of the current text before the following character arrives. We introduce a succinct Aho-Corasick like data structure for the online dictionary matching problem. Our solution uses a new succinct representation for <b>multi-labeled</b> trees, in which each node has a set of labels from a universe of size lambda. We consider lowest labeled ancestor (LLA) queries on <b>multi-labeled</b> trees, where given a node and a label we return the lowest proper ancestor of the node that has the queried label. In this paper we introduce a succinct representation of <b>multi-labeled</b> trees for lambda=omega(1) that support LLA queries in O(log(log(lambda))) time. Using this representation of <b>multi-labeled</b> trees, we introduce a succinct data structure for the online dictionary matching problem when sigma=omega(1). In this solution the worst case cost per character is O(log(log(sigma)) + occ) time, where occ is the size of the current output. Moreover, the amortized cost per character is O(1 +occ) time...|$|R
40|$|We {{present a}} novel method to address <b>multi-labeled</b> protein {{subcellular}} localization prediction in Gram-negative bacteria using support vector machines (SVM) as classifiers. For a given protein sequence {{that may have}} more than one label, features are extracted from amino acid composition and molecular function related terms in Gene Ontology (GO) as input to SVM. We apply one-against-others SVM to proteins of Gram-negative bacteria in a 5 -fold cross-validation. The results of the <b>multi-labeled</b> predictions are evaluated based on two criteria: class number an...|$|R
40|$|We propose {{probabilistic}} generative models, called parametric mixture models (PMMs), for multiclass, <b>multi-labeled</b> text categorization problem. Conventionally, {{the binary}} classification {{approach has been}} employed, in which whether or not text belongs to a category is judged by the binary classifier for every category. In contrast, our approach can simultaneously detect multiple categories of text using PMMs. We derive efficient learning and prediction algorithms for PMMs. We also empirically show that our method could significantly outperform the conventional binary methods when applied to <b>multi-labeled</b> text categorization using real World Wide Web pages. ...|$|R
5000|$|... boosting: AdaBoost.MH and AdaBoost.MR are {{extended}} {{versions of}} AdaBoost for <b>multi-label</b> data.|$|E
50|$|A list of {{commonly}} used <b>multi-label</b> data-sets {{is available at}} the Mulan website.|$|E
5000|$|The {{extent to}} which a dataset is <b>multi-label</b> can be {{captured}} in two statistics: ...|$|E
40|$|This paper {{presents}} {{a method for}} constructing consistent non-manifold meshes of <b>multi-labeled</b> volu- metric datasets. This approach is di erent to traditional surface reconstruction algorithms which often only support extracting 2 -manifold surfaces based on a binary voxel classi cation. However, in some { especially medical { applications, <b>multi-labeled</b> datasets, where up to eight di erently labeled voxels can be adjacent, are subject to visualization resulting in non-manifold meshes. In addition to an e cient surface reconstruction method, a constrained geometric lter is developed which {{can be applied to}} these non-manifold meshes without producing ridges at mesh junctions...|$|R
40|$|We {{describe}} a nonparametric topic model for labeled data. The model uses a mix-ture of random measures (MRM) {{as a base}} distribution of the Dirichlet process (DP) of the HDP framework, so {{we call it the}} DP-MRM. To model labeled data, we define a DP distributed random measure for each la-bel, and the resulting model generates an unbounded number of topics for each label. We apply DP-MRM on single-labeled and <b>multi-labeled</b> corpora of documents and com-pare the performance on label prediction with MedLDA, LDA-SVM, and Labeled-LDA. We further enhance the model by incorporating ddCRP and modeling <b>multi-labeled</b> images for image segmentation and object labeling, comparing the performance with nCuts and rddCRP. 1...|$|R
40|$|We {{describe}} a vector quantizer (VQ) with memory for auto-matic speech recognition (ASR) {{and compare the}} recognition performance results to those obtained with traditional mem-oryless VQ for ASR. Standard VQ for ASR quantizes the speech data independently of any past information. We in-troduce memory in a probabilistic framework for quantiza-tion state modeling. This is accomplished {{in the form of}} an ergodic hidden Markov model (HMM) in which the state oc-cupied by the HMM represents the quantization label. We evaluate this approach in the context of video-only isolated digit ASR and implement both single stream (single labeling) and multi-stream (<b>multi-labeling)</b> systems. For single stream recognition, our approach increases the recognition rate from 62. 67 % to 66. 95 %. When using <b>multi-labeling,</b> our proposed vector quantizer with memory consistently outperforms the memoryless vector quantizer...|$|R
5000|$|... neural networks: BP-MLL is an {{adaptation}} of the popular back-propagation algorithm for <b>multi-label</b> learning.|$|E
5000|$|Zhang S., Neagu D. and Bălescu C., ”Refinement of Clustering Solutions Using a <b>Multi-Label</b> ...|$|E
50|$|This {{compilation}} is {{the first}} <b>multi-label</b> anthology of Clark's career, issued by the Australian label Raven Records.|$|E
40|$|Text {{categorisation}} is challenging, due to {{the complex}} structure with heterogeneous, changing topics in documents. The performance of text categorisation relies {{on the quality of}} samples, effectiveness of document features, and the topic coverage of categories, depending on the employing strategies; supervised or unsupervised; single labelled or <b>multi-labelled.</b> Attempting to deal with these reliability issues in text categorisation, we propose an unsupervised <b>multi-labelled</b> text categorisation approach that maps the local knowledge in documents to global knowledge in a world ontology to optimise categorisation result. The conceptual framework of the approach consists of three modules; pattern mining for feature extraction; feature-subject mapping for categorisation; concept generalisation for optimised categorisation. The approach has been promisingly evaluated by compared with typical text categorisation methods, based on the ground truth encoded by human experts. ...|$|R
40|$|We {{describe}} a new fast algorithm for <b>multi-labelling</b> problems. In general, a <b>multi-labelling</b> problem is NP-hard. Widely used algorithms like α-expansion can reach a suboptimal {{result in a}} time linear {{in the number of}} the labels. In this paper, we propose an algorithm which can obtain results of comparable quality polynomially faster. We use the Divide and Conquer paradigm to separate the complexities induced by the label set and the variable set, and deal with each of them respectively. Such a mechanism improves the solution speed without depleting the memory resource, hence it is particularly valuable for applications where the variable set and the label set are both huge. Another merit of the proposed method is that the trade-off between quality and time efficiency can be varied through using different parameters. The advantage of our method is validated by experiments...|$|R
40|$|International audienceThis paper {{describes}} a new Ant Colony Optimization (ACO) algorithm for solving Graph Matching Problems, {{the goal of}} which is to find the best matching between vertices of <b>multi-labeled</b> graphs. This new ACO algorithm is experimentally compared with greedy and reactive tabu approaches on subgraph isomorphism problems and on multivalent graph matching problems...|$|R
50|$|Java {{implementations}} of <b>multi-label</b> algorithms {{are available}} in the Mulan and Meka software packages, both based on Weka.|$|E
5000|$|Some {{classification}} algorithms/models {{have been}} adaptated to the <b>multi-label</b> task, without requiring problem transformations. Examples of these include: ...|$|E
50|$|Multiclass {{classification}} {{should not}} be confused with <b>multi-label</b> classification, where multiple labels are to be predicted for each instance.|$|E
40|$|We {{prove that}} Nakhleh's latest dissimilarity measure for phylogenetic {{networks}} is a metric on the classes of tree-child phylogenetic networks, of semi-binary time consistent tree-sibling phylogenetic networks, and of <b>multi-labeled</b> phylogenetic trees. We also {{prove that it}} distinguishes phylogenetic networks with different reduced versions. In this way, it becomes the dissimilarity measure for phylogenetic networks with the strongest separation power available so far. Comment: 15 page...|$|R
40|$|<b>Multi-labeled</b> corpora, {{where each}} {{document}} is tagged {{with a set}} of labels, are ubiq-uitous. When the number of unique labels in the dataset is large, there are naturally some dependencies among the labels. In this paper, we propose TREELAD—a hierarchical topic model to capture these label dependencies using a tree-structured topic hierarchy. We apply TREELAD on a real-world dataset and show some promising empirical results. ...|$|R
40|$|We {{address the}} problem of <b>multi-labelled</b> text {{classification}} using word-sequence kernels. However, rather than applying them with Support Vector Machine as in previous work, we chose a classifier based on Gaussian Processes. This is a probabilistic non-parametric method that retains a sound probabilistic semantics while overcoming the limitations of parametric methods. We present the empirical evaluation of our approach on the standard Reuters- 21578 datasets. ...|$|R
