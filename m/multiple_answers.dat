158|389|Public
25|$|J. P. Guilford drew a {{distinction}} between convergent and divergent production (commonly renamed convergent and divergent thinking). Convergent thinking involves aiming for a single, correct solution to a problem, whereas divergent thinking involves creative generation of <b>multiple</b> <b>answers</b> to a set problem. Divergent thinking is sometimes used as a synonym for creativity in psychology literature. Other researchers have occasionally used the terms flexible thinking or fluid intelligence, which are roughly similar to (but not synonymous with) creativity.|$|E
2500|$|The same {{survey showed}} that AA {{received}} 32% of its membership from other members, another 32% from treatment facilities, 30% were self-motivated to attend AA, 12% of its membership from court–ordered attendance, and only 1% of AA members decided to join based on information obtained from the Internet. [...] People taking the survey were allowed to select <b>multiple</b> <b>answers</b> for what motivated them to join AA.|$|E
50|$|Assembly {{members could}} {{distribute}} votes among <b>multiple</b> <b>answers</b> to the multiple-choice questions except question 2.|$|E
30|$|The ESGE Central office sent 3422 members a {{structured}} electronic questionnaire with <b>multiple</b> <b>answer</b> choices for each question. After 3  months, the answers were classified {{with a unique}} number in the EXCEL spread sheet. Statistical analysis was done using the SPSS v. 18.|$|R
40|$|Abstract. Number {{of correct}} answers and time {{spent by the}} {{students}} enrolled at Faculty of Materials Science and Engineering from Technical University of Cluj-Napoca and attending at Materials Chemistry discipline <b>answering</b> to a <b>multiple</b> choice <b>multiple</b> <b>answer</b> online evaluation system were analyzed. The analysis shown that the evaluation characteristics it follow a lifetime distribution...|$|R
5000|$|Polls {{and surveys}} - the {{presenter}} shows questions with <b>multiple</b> choice <b>answers</b> ...|$|R
5000|$|... #Subtitle level 3: Languages {{spoken at}} work, at school and/or {{at home on}} 1 February 2011 (<b>multiple</b> <b>answers</b> possible) ...|$|E
50|$|Viewers call up to win cash prizes {{by playing}} on the word tower. Viewers must find <b>multiple</b> <b>answers</b> (e.g. films 'a').|$|E
50|$|Types of {{questions}} include interrogative (regular) questions, <b>multiple</b> <b>answers,</b> situations, chapter and verse references, quoting a Bible verse or finishing a verse.|$|E
40|$|The JAVELIN system {{evaluated}} at TREC 2003 is {{an integrated}} architecture for open-domain question answering. JAVELIN employs a modular approach that addresses individual {{aspects of the}} QA task in an abstract manner. The System implements a planner that controls the execution and information flow, {{as well as a}} <b>multiple</b> <b>answer</b> seeking strategies used differently {{depending on the type of}} question...|$|R
40|$|This {{research}} {{is aimed at}} describing: 1) students’ difficulties in <b>answering</b> <b>multiple</b> choice questions in narrative text, and 2) Why do the students have difficulty in <b>answering</b> <b>multiple</b> choice questions of narrative text. In this {{research is}} descriptive research as an approach to collect and analyze the data. The object {{of this research is}} students’ difficulties in <b>answering</b> <b>multiple</b> choice questions at eight grades of SMP Muhammadiyah Karangrayung in 2012 / 2013 academic year. The method of collecting data conducted by doing: observation, interview, and document analysis. The results of this research show that student’ difficulties in <b>answering</b> <b>multiple</b> choice questions, and why do the students have difficulty in <b>answering</b> <b>multiple</b> choice questions in narrative text. The result of students’ difficulties in <b>answering</b> <b>multiple</b> choice questions are as follows: 1) main idea, 2) meaning of word or vocabulary, and 3) generic structure. The reason why the students have difficulty in <b>answering</b> <b>multiple</b> choice questions in narrative text are as follows: 1) less interest in following the lesson, 2) the lack of vocabulary, 3) the limitation of time, 4) length of paragraph, 5) and too many choices which are similar to each other in multiple choice questions...|$|R
30|$|In this case, a user is {{requested}} to select {{all the places}} that he/she visited during a specific day along with the time window (e.g., What are the places that you visited on May 8 th and what time did you arrive there?), (see Type ‐ 3 Question in Fig. 3). As before, the list may contain <b>multiple</b> correct <b>answers</b> along with <b>multiple</b> incorrect <b>answers.</b>|$|R
5000|$|Without the DNS Client service running: If the [...] "hosts" [...] file {{contains}} multiple lines denoting <b>multiple</b> <b>answers</b> {{for a given}} lookup, {{only the}} first answer found will be returned.|$|E
5000|$|With the DNS Client service running: If the [...] "hosts" [...] file {{contains}} multiple lines denoting <b>multiple</b> <b>answers</b> {{for a given}} lookup, all of {{the answers}} in the cache will be returned.|$|E
5000|$|Notice {{that the}} total is higher than 100% because of <b>multiple</b> <b>answers.</b> It {{is easy to see}} that the results of this {{research}} are widely incompatible with the claims made by embassies and commercial associations: ...|$|E
5000|$|Polls {{and surveys}} (allows the {{presenter}} to conduct questions with <b>multiple</b> choice <b>answers</b> {{directed to the}} audience) ...|$|R
50|$|Trending Life Questions - Also {{played with}} celebrity guests, guests are asked life {{questions}} with <b>multiple</b> choice <b>answers.</b>|$|R
30|$|In this case, a user is {{requested}} to select {{all the places}} that he/she visited during a specific day along with the order of visits (e.g., What are the places that you visited on May 8 th and in what order?), see Type ‐ 2 Question in Fig. 3. As in Type ‐ 1, the list may contain <b>multiple</b> correct <b>answers</b> along with <b>multiple</b> incorrect <b>answers</b> (i.e., distracters).|$|R
50|$|A TempO {{course has}} timed {{controls}} only. The competitors are ranked {{according to their}} time taken, which is {{the time needed to}} answer all controls and 30 seconds penalty for each incorrect answer, including blank and <b>multiple</b> <b>answers.</b>|$|E
5000|$|Beer Run: Don or Mayleen {{give the}} {{contestant}} a question. There are <b>multiple</b> <b>answers</b> to that question. They {{have to give}} Don or Mayleen as many answers as they can in 30 seconds. Each correct answer is worth $10.|$|E
50|$|The main {{game has}} 8 rounds. Each round has one or <b>multiple</b> <b>answers,</b> to be {{selected}} {{from a list of}} choices. To clear the round and win the money, the team must select all correct choices, otherwise they lose and leave with nothing.|$|E
50|$|Note: The above {{composite}} score cut points reflect the pre-2011 grading formula which deducted 0.25 points for every incorrect <b>multiple</b> choice <b>answer.</b>|$|R
50|$|Pardo's online {{multimedia}} game, {{originally developed}} at the National Film Board {{in the summer of}} 1968, was centered on children playing in teams watching film loops - and based on their personal visual processing, making up questions (and <b>multiple</b> <b>answer</b> choices) to stump other players, who although watching the same imagery, naturally watched them from their personal perspective, history and emotional experience. Exposure to the fact that everyone saw the same visual information differently was a critically important learning process for the children.|$|R
50|$|BMAT is a 2-hour, pen-and-paper test, which {{consists}} of three sections. The first two sections are both <b>multiple</b> choice/short <b>answer</b> and the third section is a writing task.|$|R
5000|$|Just One More: Given a {{question}} with <b>multiple</b> <b>answers,</b> the contestants bid {{back and forth}} as to how many they could name. The high bidder won control; if he/she gave an incorrect answer, the opponent could steal the money with one correct response.|$|E
5000|$|In another investigation, Tandem {{partners}} in Bolzano and Merano {{who had been}} learning {{for more than one}} year together, and can be seen accordingly as experts, were questioned about their experiences in order to infer criteria for ‘good’ Tandems. The results showed (in order of frequency, <b>multiple</b> <b>answers</b> possible): ...|$|E
50|$|The {{visual arts}} allow {{students}} to learn varied techniques such as drawing, page layout, oil painting, screenprinting, Photoshop, metals and jewelry, and also promote such twenty-first century skills such as Lion Taming, making good judgments about qualitative relationships, seeing multiple perspectives and <b>multiple</b> <b>answers,</b> and addressing complex forms of problem solving.|$|E
30|$|Questions {{that are}} {{generated}} based on recent battery charging events ask a user to identify: (1) {{the time when}} the device was plugged into a power source (i.e., charger) within the last 24 h and (2) the mode of charging (e.g., AC charger, USB) (see Fig. 1 f). As in the physical activity question, this type of question can have <b>multiple</b> correct <b>answers</b> as well (i.e., a device may be charged multiple times during a day). In case of <b>multiple</b> correct <b>answers,</b> a user needs to pick only one of them.|$|R
40|$|Abstract. Esfinge is {{a general}} domain Portuguese {{question}} answering system which uses the information available on the Web as an additional resource when searching for answers. Other external resources and tools used are a broad coverage parser, a morphological analyser, a named entity recognizer and a Web-based database of word co-occurrences. In this fourth participation in CLEF, {{in addition to the}} new challenges posed by the organization (topics and anaphors in questions and the use of Wikipedia to search and support answers), we experimented with a multiple question and <b>multiple</b> <b>answer</b> approach in QA...|$|R
40|$|In {{this paper}} we analyze two {{question}} answering tasks : the TREC- 8 question answering task {{and a set}} of reading comprehension exams. First, we show that Q/A systems perform better when there are <b>multiple</b> <b>answer</b> opportunities per question. Next, we analyze common approaches to two subproblems: term overlap for answer sentence identification, and answer typing for short answer extraction. We present general tools for analyzing the strengths and limitations of techniques for these subproblems. Our results quantify the limitations of both term overlap and answer typing to distinguish between competing answer candidates. ...|$|R
50|$|Programs are checked {{either by}} {{comparison}} to a known correct answer or by running a dedicated judging code, unique to each problem. This is increasingly necessary when {{there may be}} <b>multiple</b> <b>answers</b> in more complex problems. By using a computer, the marking is consistent, fair and can measure efficiency in real time, in comparison to human judging.|$|E
50|$|This time, the {{champion}} {{did not have}} a choice of categories to start the round. Instead, a predetermined category was played and {{the champion}} was asked one question in that category. The question could, and often did, feature <b>multiple</b> <b>answers</b> and the champion had to answer all parts of the question correctly in order to win the money.|$|E
50|$|The teams each try to {{make one}} perfect hive out of one super hive (basically a {{slightly}} larger hive) out of answers. Humour {{is made out of}} the fact that the two hives are called the A-hive and the B-hive. They must find <b>multiple</b> <b>answers</b> on a single question. Every answer found is worth a point; a perfect hive is worth ten.|$|E
50|$|Trivia Quiz: Once an episode, Kasem {{would lead}} into a {{commercial}} with a music question with three <b>multiple</b> choice <b>answers.</b> After the commercial played, {{he would give}} the answer.|$|R
50|$|He {{returned}} at {{the next}} two events of Pride, submitting Juan Mott via rear naked choke and drawing with Takada Dojo understudy and fellow underdog Daijiro Matsui. However, his biggest victory came at Pride 4, where Shoji faced another unbeaten Brazilian jiu-jitsu exponent, Wallid Ismail. The Brazilian was aggressive and held Akira mounted for the first round, with Shoji reversing him every time. At the second round, however, the Japanese got the upper hand over a tired Ismail and landed <b>multiple</b> <b>answered</b> punches, which prompted the referee to stop the match for a win for Shoji.|$|R
50|$|Quiz Show is a two-player arcade game by Atari, Inc, {{originally}} {{released in}} 1976. A computerized {{version of a}} quiz show, the game presents <b>multiple</b> choice <b>answers</b> to questions {{from a range of}} categories.|$|R
