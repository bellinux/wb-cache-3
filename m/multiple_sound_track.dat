0|2669|Public
50|$|The {{motivation}} of using {{this method is}} that based on previous research. This method is used for <b>multiple</b> <b>sound</b> source <b>tracking</b> and localizing despite soundtracking and localization only apply for a single sound source.|$|R
5000|$|The Telecinema was {{the first}} cinema in the world {{specially}} designed and built to show both films and television. [...] It created {{a heightened sense of}} realism by special effects that involved the audience more closely in what was shown. Among the techniques employed were a borderless screen and film with <b>multiple</b> <b>sound</b> <b>tracks</b> whose <b>sound</b> was reproduced through a series of loudspeakers behind the screen and in the auditorium. [...] J.D. Ralph and R.J. Spottiswoode were responsible for the presentation and programme, which comprised a feature film, fourteen documentaries, four experimental films and four 'stereoscopic' (3-D) films.|$|R
40|$|This paper {{presents}} a real-time auditory and visual tracking of multiple objects for humanoid under real-world environments. Real-time processing {{is crucial for}} sensorimotor tasks in tracking, and multiple-object tracking is crucial for real-world applications. <b>Multiple</b> <b>sound</b> source <b>tracking</b> needs perception of a mixture of sounds and cancellation of motor noises caused by body movements...|$|R
40|$|Abstract — Real-time {{and robust}} <b>sound</b> source <b>tracking</b> is an {{important}} function for a robot operating in a daily environment, because the robot should recognize where a sound event such as speech, music and other environmental sounds originate from. This paper addresses real-time <b>sound</b> source <b>tracking</b> by realtime integration of an in-room microphone array (IRMA) and a robot-embedded microphone array (REMA). The IRMA system consists of 64 ch microphones attached to the walls. It localizes <b>multiple</b> <b>sound</b> sources based on weighted delay-and-sum beamforming on a 2 D plane. The REMA system localizes <b>multiple</b> <b>sound</b> sources in azimuth using eight microphones attached to a robot’s head on a rotational table. The localization results are integrated to <b>track</b> <b>multiple</b> <b>sound</b> sources by using a particle filter in real-time. The experimental results show that particle filter based integration improved accuracy and robustness in <b>multiple</b> <b>sound</b> source <b>tracking</b> even when the robot’s head was in rotation. I...|$|R
40|$|<b>Sound</b> source <b>tracking</b> is an {{important}} function for a robot operating in a daily environment, because the robot should recognize where a sound event such as speech, music and other environmental sounds originates from. This paper addresses <b>sound</b> source <b>tracking</b> by integrating a room and a robot microphone array. The room microphone array consists of 64 microphones attached to the walls. It provides 2 D (x-y) sound source localization based on a weighted delay-and-sum beamforming method. The robot microphone array consists of eight microphones installed on a robot head, and localizes <b>multiple</b> <b>sound</b> sources in azimuth. The localization results are integrated to <b>track</b> <b>sound</b> sources by using a particle filter for <b>multiple</b> <b>sound</b> sources. The experimental results show that particle filter based integration reduces localization errors and provides accurate and robust 2 D <b>sound</b> source <b>tracking.</b> 1...|$|R
40|$|In {{the area}} of audio {{recording}} and reproduction, mixing is {{the process by which}} <b>multiple</b> <b>sound</b> sources (of either a recorded or synthetic origin) are combined, over one or more channels. However, when <b>sound</b> <b>tracks</b> are combined, mix engineers have to take care to preserve quality, as <b>multiple</b> <b>sounds</b> may occur at once. The more masking that occurs during mixing, the worse the audible sound quality. For this research project, I have chosen two methods to help improve audibility of sounds in the final mix. The first is elevation filtering. Elevation filtering is based on the theories of IID, ITD and pinna effect. I decided to design an elevation difference filter, which includes the elevation data. If we utilize such an elevation filter for a <b>sound</b> <b>track,</b> the perceived source position will change and allow it to be distinguished from other sounds. Another method is creating a 180 degree phase shift (out of phase) situation to reduce the level of masking. This technique is based on the theory of the binaural release of masking. Given that an out of phase situation can decrease masking, I have designed a Max/MSP patch which can create an ‘out of phase’ situation for two ears in any azimuth position. Finally, these two methods will be tested to see if the difference in sound quality is audible or not. A musical composition will also be created, utilizing these two technologies, which will constitute the musical outcome of my research...|$|R
40|$|The {{ever-increasing}} {{complexity of}} new electronic systems designs, {{combined with the}} need for very high performance and low power consumption have driven technology development, methodologies and design flows, including the widespread use of reconfigurable FPGA technologies in systems design. The in-system reconfigurability of FPGAs offers the possibility of reconfiguring the device for different functionality without halting the application. Adding this functionality requires special design flows. This thesis first explores the use of different FPGA reconfigurable design flows, using a sample design, which includes a sensor and wireless transmitter along with the FPGA. Two reconfigurable flows were investigated, Dynamic Partial Reconfiguration (DPR) and Multi- Boot (MB). These flows were also used in FPGA implementations of algorithms for the localization and <b>tracking</b> of <b>sound</b> sources. It is shown that the less-studied Multi-Boot flow has some unexpected advantages over the better-known DPR technique. Applications based on sound source localization and tracking require specific algorithms, which can adapt themselves to disturbing noise or the mobility of the target. This work proposes a novel hybrid algorithm with the ability to adapt its search spectrum according to the target movement. This property allows a good balance between required power processing and real-time response, especially when implemented on a FPGA. Moreover, the algorithm fits quite well on a Dynamic Partial Reconfiguration (DPR) or Multi-Boot (MB) strategy. The approach combines the Generalized Cross Correlation (GCC) and the Delay and Sum Beamforming (DSB) algorithms in such a manner that reductions of more than 80 % in DSB computation can be obtained while preserving precision and improving real-time capabilities. The novel algorithm is also applied to a number of application topics such as speaker recognition and <b>multiple</b> <b>sound</b> source <b>tracking</b> that use different localization and beamforming techniques. The performance of the author’s hybrid algorithm in these applications is studied and it is shown to retain its advantages in these cases...|$|R
50|$|Traditionally, split edits {{have been}} {{described}} as overlapping the sound, {{not to be confused with}} overlapping dialogue, where the latter involves laying one <b>sound</b> <b>track</b> over another <b>sound</b> <b>track.</b>|$|R
5000|$|The {{original}} Jimmy Page soundtrack {{was released}} in 2012 as Lucifer Rising and Other <b>Sound</b> <b>Tracks.</b> Further music was issued {{as part of his}} <b>Sound</b> <b>Tracks</b> box set. Page explained of the latter: ...|$|R
50|$|The {{soundtrack of}} the game was {{compiled}} into an album named Thermonuclear Deity Hisoutensoku ~ Touhou Hisoutensoku ORIGINAL <b>SOUND</b> <b>TRACK</b> (核熱造神ヒソウテンソク 東方非想天則 ORIGINAL <b>SOUND</b> <b>TRACK),</b> first sold in Comiket 77 on December 30, 2009.|$|R
40|$|In this paper, {{we present}} an active {{audition}} system for humanoid robot “SIG the humanoid”. The audition {{system of the}} highly intelligent humanoid requires localization of sound sources and identification of meanings of the sound in the auditory scene. The active audition reported in this paper focuses on improved <b>sound</b> source <b>tracking</b> by integrating audition, vision, and motor movements. Given the <b>multiple</b> <b>sound</b> sources in the auditory scene, SIG actively moves its head to improve localization by aligning microphones orthogonal to the sound source and by capturing the possible sound sources by vision. However, such an active head movement inevitably creates motor noise. The system must adaptively cancel motor noise using motor control signals. The experimental result demonstrates that the active audition by integration of audition, vision, and motor control enables <b>sound</b> source <b>tracking</b> in variety of conditions...|$|R
50|$|Tekken 2 Original <b>Sound</b> <b>Tracks</b> (鉄拳2 オリジナルサウンドトラック) is the officially {{licensed}} {{soundtrack of}} the PlayStation video game Tekken 2, the second installment to the Tekken Series. It {{was released in}} two versions sets same as Tekken Original <b>Sound</b> <b>Tracks.</b>|$|R
40|$|This study {{examines}} the roles played by <b>sound</b> <b>track</b> type, attention to <b>sound</b> <b>track,</b> {{and meaning of}} <b>sound</b> <b>track</b> in mediating the effects of false autonomic feedback on attractiveness ratings of erotic stimuli. Male subjects were instructed either to ignore or {{to pay attention to}} a pulsed or continuous <b>sound</b> <b>track</b> that was described either as heart-rate feedback or as a neutral auditory stimulus while slides of nude females were shown. Slides associated with a change in either the pulsed <b>sound</b> <b>track</b> or the continuous-tone <b>sound</b> <b>track</b> (increase slides) were subsequently rated as significantly more attractive than those associated with steady sound (stable slides). This effect was contingent on the meaning given to the auditory stimuli, with subjects in the “heart-rate” condition showing a stronger tendency to rate increase slides more positively than stable slides, by comparison with subjects in the “neutral sounds” condition. Within the heart-rate condition, subjects told {{to pay attention to the}} feedback showed greater rating differences between these two types of slide than those told to ignore it. This pattern of findings contrasts with those of an earlier experiment (Parkinson & Manstead, 1981), where differential unpleasantness ratings of slides of skin diseases depended on the attention paid to the <b>sound</b> <b>track</b> but not on its meaning. It is concluded that the effects of false autonomic feedback are contingent upon the kind of emotional stimuli that are presented...|$|R
50|$|An {{original}} game soundtrack KanColle Original Sound Track: Dawn (KanColle Original Sound Track: Akatsuki) {{was released}} on August 3, 2014. Second original game soundtrack KanColle Original <b>Sound</b> <b>Track</b> 2: Wind (KanColle Original <b>Sound</b> <b>Track</b> 2: Kaze) {{was released on}} August 5, 2015.|$|R
5000|$|... 2010.12.8 Bear's School~Jackie&Katie movie {{original}} <b>sound</b> <b>track</b> ...|$|R
5000|$|ACECOMBAT 04 {{shattered}} skies Original <b>Sound</b> <b>Tracks</b> SCDC-00146 ...|$|R
50|$|There are {{two types}} of {{synchronised}} film soundtrack, optical and magnetic. Optical <b>sound</b> <b>tracks</b> are visual renditions of sound wave forms and provide sound through a light beam and optical sensor within the projector. Magnetic <b>sound</b> <b>tracks</b> are essentially the same as used in conventional analog tape recording.|$|R
5000|$|Jason`s {{first movie}} <b>sound</b> <b>track,</b> [...] "I'm Alive", co-written by Marius Brower and Sir Tim Rice, {{is one of}} the <b>sound</b> <b>tracks</b> of the {{animated}} movie [...] "Jock" [...] (Jock of the Bushveld), released in August 2011. This is the first 3D movie to be created in South Africa.|$|R
5000|$|The opening {{theme to}} Rose Guns Days is [...] "Ai wa Omerta" [...] (愛はオメルタ) by Rojak feat. Mayumi. A soundtrack titled Rose Guns Days <b>Sound</b> <b>Tracks</b> 1 was {{released}} on August 11, 2012, and a soundtrack titled Rose Guns Days <b>Sound</b> <b>Tracks</b> 2 {{was released on}} December 30, 2012.|$|R
50|$|The {{following}} is <b>sound</b> <b>track</b> in Malayalam dubbed version.|$|R
5000|$|Famicom 20th Anniversary Original <b>Sound</b> <b>Tracks</b> Vol. 1 SCDC-00317 ...|$|R
5000|$|Famicom 20th Anniversary Original <b>Sound</b> <b>Tracks</b> Vol. 2 SCDC-00318 ...|$|R
5000|$|Famicom 20th Anniversary Original <b>Sound</b> <b>Tracks</b> Vol. 3 SCDC-00319 ...|$|R
5000|$|<b>Sound,</b> <b>track</b> on {{compilation}} (Avon Calling Album, Heartbeat, 1979) ...|$|R
5000|$|Space Invaders Get Even Original <b>Sound</b> <b>Tracks</b> (2008) ZTTL-9014 ...|$|R
5000|$|The <b>sound</b> <b>track</b> was comsposed by Richard Horowitz https://soundcloud.com/richard-horowitz/sets/intersections ...|$|R
5000|$|... #Subtitle level 2: Modelling, {{commercials}} and movie <b>sound</b> <b>track</b> ...|$|R
50|$|Overdubbed is a clip {{show with}} the <b>sound</b> <b>track</b> altered.|$|R
50|$|This <b>sound</b> <b>track</b> has 6 {{songs are}} {{composed}} by Ilaiyaraja.|$|R
5000|$|... "Love My Life" [...] {{original}} <b>sound</b> <b>track</b> (2007.01.17 Delicious Label) ...|$|R
5000|$|Best <b>Sound</b> <b>Track</b> Album, Dramatic Picture Score or Original Cast ...|$|R
5000|$|Sökarna: <b>Sound</b> <b>track</b> (tracks with Chilly White and Power United) ...|$|R
5000|$|Kathryn Grayson, Show Boat Original Motion Picture <b>Sound</b> <b>Track,</b> 1951 ...|$|R
5000|$|... #Subtitle level 3: Tracks {{missing from}} the Original <b>Sound</b> <b>Track</b> ...|$|R
25|$|DoDonPachi DaiFukkatsu Black Label Original <b>Sound</b> <b>Track</b> was {{released}} on 2010-02-20.|$|R
50|$|A <b>sound</b> <b>track</b> album FUBAR: The Album, was {{released}} in 2003.|$|R
