2|44|Public
40|$|Abstract. The {{symplectic}} Euler method {{applied to}} Hamiltonian systems with holonomic constraints {{is known to}} preserve the symplectic structure of the flow on the constraint manifold. We consider two extensions of this method to a class of overdetermined differential-algebraic equations (ODAEs) arising in mechanics. It is shown that {{a natural extension of}} the symplectic Euler method is inconsistent for ODAEs which are nonlinear in the algebraic variables. A different non-trivial extension is given and shown to be consistent. Our results are confirmed numerically on two test problems. One test problem is a model of a mass moving on a surface with a nonlinearity in the Lagrange <b>multiplier.</b> <b>Key</b> words. Differential-algebraic equations, differential-algebraic inequalities, Hamiltonia...|$|E
40|$|Will you lend me to short? The {{role of the}} box in {{leverage}} and repo fails Jean-Marc Bottazzi a Jaime Luque b Mário Páscoa c Repo {{markets have}} recently attracted {{a lot of attention}} as policy makers tried to prevent un-orderly adjustments of leverage in the market. We build a repo market model to understand the role of the physical nature of securities for di¤erent scenarios: repo rolls, fails and security market leverage. It is impossible to have a short position in a security without managing to borrow (reverse in) it …rst. The constraint is captured by the concept of what is called the box in market parlance: the balance of title ownership in each security, which must be non-negative. The level of repo specialness is a function of how binding this constraint is. Leveraging a position becomes possible if engaging in a sequence of repo and security trades in a way that scarce collateral is allocated in agents’boxes. We call this process the repo collateral <b>multiplier.</b> <b>Key</b> words and phrases: repo, reverse repo, box, short sale, leverage, repo collateral multiplier, fail, specialness. This paper was presented in the 2007 QED meeting at Università ‘Ca’Foscari’Venice (Italy), and in 2008 at Universidad de Salamanca (Spain) and Universidade Nova de Lisboa (Portugal). We thank the comments of these audiences and, in particular, to Pier...|$|E
5000|$|<b>Multiply</b> the <b>key</b> by the {{predetermined}} constant m. This operation actually requires two machine words, {{but this}} can still by done in constant time.|$|R
3000|$|... {{receives}} a product from one member, and then generates a response by <b>multiplying</b> with the <b>key,</b> GK {{set in the}} storage. For example, R [...]...|$|R
50|$|The <b>multiplier</b> plays a <b>key</b> role in {{monetary}} policy, and {{the distinction}} between the multiplier being the maximum amount of commercial bank money created by a given unit of central bank money and approximately equal to the amount created has important implications in monetary policy.|$|R
40|$|The {{advances}} in Internet and information technologies {{in the last}} ten years have brought about a structural change in the way information is aggregated, transformed, and then disseminated. Most people of the older generation prefer to get their news the old-fashioned way i. e., from newspapers and magazines. The younger generation, on the other hand, logs on to online sources for their information needs. There is genuine concern that as the older generation moves on, the old media will also gradually disappear. The rise of the new media has put the old (print) media establishment on the defensive. The new is not displacing the old, however; rather, it is transforming the old by forcing it to accept transparency, responsiveness and e$ciency. Increased competition is making the old media to pull up its socks and provide the additional value demanded by a free market where the number of players has <b>multiplied.</b> <b>Key</b> words: media, print media, news print media, global media Back in the sixties and seventies at my home in New Delhi there used to be a daily tussle between my father and me. The sound of a newspaper falling on the floor of our balcony every morning would be enough to wake both of us in ou...|$|R
40|$|With {{onset of}} {{paradigms}} of System On Chip (SOC) {{to design a}} module for real time applications or voice codec‟s, The SOC‟s have different requirements for operands precision we propose a reusable FFT [2] using reconfigurable multiplier [6]. How ever, the FFT perform either combining N and N/ 2 bit multiplications in the same N bit tree <b>multiplier.</b> The <b>key</b> challenges in designing a reusable FFT are to limit the impact of flexibility on power operations that are needed for FFT butterfly to perform better than a conventional, dedicated FFT butterfly...|$|R
40|$|International audienceA {{method is}} {{proposed}} for deriving the optimal operating conditions {{of a given}} MESFET needed to obtain an optimal frequency <b>multiplier.</b> The <b>key</b> point {{of this approach is}} that no topology of the embedding network is to be chosen a priori. The optimum bias voltages and the optimum load impedances (including possible feedback circuit) are found. The method has been applied to design doublers at low frequencies from 10 - 20 GHz and at millimeter-wave frequencies from 20 - 40 GHz. Although the experimental doublers are still under measurement, first results have given good agreement with theoretical prediction...|$|R
50|$|It {{contained}} the floating-point register file, a load queue, a store queue, and two identical floating-point units. All instructions except for divide and square-root are pipelined. The R8010 implements an iterative division and square-root algorithm {{that uses the}} <b>multiplier</b> for a <b>key</b> part, requiring the pipeline to be stalled the unit {{for the duration of}} the operation.|$|R
40|$|AbstractWe {{designed}} and operated a 9 -bit single-flux-quantum (SFQ) digital-to-analog converter (DAC). SFQ pulse-frequency modulation (PFM) was employed for generation of variable quantum output voltage, where a 9 -bit variable pulse number multiplier and a 100 -fold voltage <b>multiplier</b> were the <b>key</b> components. Test chips were fabricated using a Nb Josephson integration technology. Arbitrary voltage waveforms were synthesized with the maximum voltage of 2. 54 mV. For ac voltage standard applications, {{relationships between the}} DAC resolution and the synthesized waveform frequency are discussed...|$|R
40|$|In this paper, we have {{developed}} a block cipher by modifying the Feistel cipher. In this, the plaintext is taken {{in the form of}} a pair of matrices. In one of the relations of encryption the plaintext is <b>multiplied</b> with the <b>key</b> matrix on both the sides. Consequently, we use the modular arithmetic inverse of the key matrix in the process of decryption. The cryptanalysis carried out in this investigation, clearly indicates that the cipher is a strong one, and it cannot be broken by any attack...|$|R
40|$|This paper {{discusses}} the numerical {{solution of the}} incompressible viscous flow by the fictitious domain method with distributed Lagrange multiplier. For {{the analysis of the}} finite element method, the mixed interpolation based on the bubble function is presented. How to use the fictitious domain method applied to the Navier-Stokes equation is explained. The incompressible viscous flow is restricted by the distributed Lagrange multiplier method. Advantage of the fictitious domain method based on distributed Lagrange <b>multiplier</b> is investigated. <b>KEY</b> WORDS finite element method, fictitious domain method, distributed Lagrange multiplier, Navier-Stokes equations, Newton second law...|$|R
40|$|On {{the basis}} of on-road energy consumption, fuel economy (FE) of {{hydrogen}} fuel cell light-duty vehicles is projected to be 2. 5 – 2. 7 times the fuel economy of the conventional gasoline internal combustion engine vehicles (ICEV) on the same platforms. Even with a less efficient but higher power density 0. 6 V per cell than the base case 0. 7 V per cell at the rated power point, the {{hydrogen fuel cell vehicles}} are projected to offer essentially the same fuel economy <b>multiplier.</b> The <b>key</b> to obtaining high fuel economy as measured on standardized urban and highway drive schedules lies in maintaining high efficiency of the fuel cell (FC) system at low loads. To achieve this, besides a high performance fuel cell stack, low parasitic losses in the air management system (i. e., turndown and part load efficiencies of the compressor–expander module) are critical. © 2004 Elsevier B. V. All rights reserved...|$|R
40|$|Abstract: The paper {{assesses the}} impacts of a {{proposed}} policy, which suggests a ban on commercial timber harvest in the U. S. national forests. Specifically, this study examines {{the effect of this}} policy on a small forest dependent county (Liberty County) in Florida and Florida State by applying a computable general equilibrium (CGE) model. The results indicate that the proposed policy would decrease overall economic output by $ 5 million in Liberty County. The decrease in economic output at the state level in response to this policy is only $ 1 million. Results suggest that the welfare index in response to the proposed policy will drop by 2. 9 % in Liberty County while the change at the state level is negligible. At the county level, where limited alternate opportunities for labor and capital mobility, the negative effect of the proposed policy is shown to have a <b>multiplying</b> effect. <b>Key</b> words: Computable General Equilibrium Model, commercial timber harvest, regional economic impacts, U. S. national forest...|$|R
40|$|Abstract: In this study, we had {{proposed}} architecture for high speed Truncation Adder Algorithm. In modern VLSI technology, {{the occurrence of}} all kinds of errors has become inevitable. By adopting an emerging concept in VLSI design and test, error tolerance (ET), a novel error-tolerant adder (ETA) is proposed. The ETA is able to ease the strict restriction on accuracy, {{and at the same time}} achieve tremendous improvements in both the power consumption and speed performance. When compared to its conventional counterparts, the proposed ETA is able to attain more than 74 % improvement. One important potential application of the proposed ETA is in digital signal processing systems that can tolerate certain amount of errors. The modifications to the conventional shift and add multiplier includes introduction of modified error tolerant technique for addition and enabling of adder cell by current multiplication bit of the <b>multiplier</b> constant. <b>Key</b> words: High speed arithmetic, error tolerant technique...|$|R
40|$|In this {{research}} paper, the Keynesian, Leontief’s and Miyazawa’s multiplier concepts are extended {{in order to}} decompose the factors that propagate to total mport requirements on such variables as domestic intermediate consumption, domestic final consumption, domestic investment and export. From these extended concepts, {{we are able to}} quantify the direct and indirect import requirements and determine the decomposition factors that induce total import requirements. Along with domestic output multipliers, policy makers would be able to look into and consider the import <b>multiplier</b> as a <b>key</b> determinant in sectoral economic planning and policy formulation. Keynesian, multiplier, input-output analysis...|$|R
40|$|We have {{extended}} the ACL 2 theorem prover to automatically prove properties of VHDL circuits with IBM’s Internal SixthSense verification system. We {{have used this}} extension to verify a multiplier used in an industrial floating point unit. The property we ultimately verify corresponds to the correctness of the component that produces a pair of bit-vectors whose summation {{is equal to the}} product. This property is beyond the scale of the SixthSense system alone. In this paper we show how we verified the <b>multiplier</b> by illustrating <b>key</b> ACL 2 lemmas and theorems, and also properties checked by SixthSense...|$|R
40|$|Abstract — RFID tags will {{supplant}} barcodes for {{product identification}} {{in the supply}} chain. The capability of a tag to be read without a line of sight is its principal benefit, but compromises {{the privacy of the}} tag owner. Public key cryptography can restore this privacy. Because of the extreme economic constraints of the application, die area and power consumption for cryptographic functions must be minimized. Elliptic curve processors efficiently provide the cryptographic capability needed for RFID. This paper proposes efficient architectures for elliptic curve processors in GF(2 m). One design requires six m-bit registers and six Galois field <b>multiply</b> operations per <b>key</b> bit. The other design requires five m-bit registers and seven Galois field <b>multiply</b> operations per <b>key</b> bit. These processors require a small number of circuit elements and clock cycles while providing protection from simple side-channel attacks. Synthesis results are presented for power, area, and delay in 250, 130 and 90 nm technologies. Compared with prior designs from the literature, the proposed processors require less area and energy. For the B- 163 curve, with bit-serial multiplier, the first proposed design synthesized in an IBM low-power 130 nm technology requires an area of 9613 gate equivalents, 163, 355 cycles and 4. 14 µJ for an elliptic curve point multiplication. The other proposed design requires 8756 gate equivalents, 190, 570 cycles and 4. 19 µJ. Index Terms—Elliptic Curve Cryptography, RFID, security I...|$|R
40|$|In this paper, we have {{developed}} a block cipher by offering a modification to the classical Feistel cipher. Unlike {{in the case of}} the classical Feistel cipher wherein we have a binary string as a plaintext, here we have taken the plaintext as a matrix, which is divided into a pair of matrices. One of these matrices is <b>multiplied</b> with the <b>key</b> matrix on both the sides. The process of encryption is supplemented with a pair of functions called Mix () and Permute (). In addition to these two, we have used XOR operation. The avalanche effect and the cryptanalysis indicate that cipher is a strong one...|$|R
40|$|In this investigation, we have {{generalized}} {{the classical}} Feistel cipher by representing the plaintext {{in the form}} of a matrix instead of a binary string used in the case of classical Feistel cipher. In this, the plaintext matrix is divided into two matrices and one of these two is <b>multiplied</b> with the <b>key</b> matrix on both the sides. In the iteration process, involved in this cipher, we have included a pair of functions namely Mix () and Permute (), and also utilized modular arithmetic addition. All these features are expected to strengthen the cipher. The avalanche effect and the cryptanalysis clearly show that the cipher is a potential one...|$|R
40|$|The Optimal Sink Position Selection Algorithm is {{proposed}} {{based on the}} maximum demands (OSPSA). In this algorithm the communication demands of the nodes and the communication failure probability between the nodes and the sinks are considered. The sinks <b>multiply</b> cover the <b>key</b> nodes to satisfy the maximum demands {{to improve the quality}} of service. Furthermore, the characteristics are analyzed in theory. Simulation experiments are conducted to analyze and compare the relationships between the failure probability, the coverage radius and the maximum coverage demands. Moreover the effects between the number and the maximum coverage demands and the effects between the coverage and the maximum coverage demands are also compared...|$|R
40|$|Probabilities are {{understood}} abstractly as forming a monoid {{in the category}} of effect algebras. They can be added, via a partial operation, and <b>multiplied.</b> This generalises <b>key</b> properties of the unit interval [0, 1]. Such effect monoids can be used to define a probability distribution monad, again generalising the situation for [0, 1]-probabilities. It will be shown that there are translations back-and-forth, {{in the form of an}} adjunction, between effect monoids and “convex ” monads. This convexity property is formalised, both for monads and for categories. In the end this leads to “triangles of adjunctions ” (in the style of Coumans and Jacobs) relating all the three relevant structures: probabilities, monads, and categories. ...|$|R
40|$|Abstract: In this paper, we {{have devoted}} our {{attention}} to the study of a block cipher which is obtained by modifying the classical Feistel cipher. In this, the plaintext block is divided into two matrices of equal size, and one of the matrices is <b>multiplied</b> by one <b>key</b> on the left side and the other key on the right side. The resulting expression is subjected to modulo operation. After interchanging the portions of the plaintext, they are blended very thoroughly (by converting the decimal numbers into binary bits) in each round of the iteration process. The avalanche effect shows that the cipher is reliable, and the cryptanalysis firmly confirms that the cipher is a strong one...|$|R
40|$|AbstractProbabilities are {{understood}} abstractly as forming a monoid {{in the category}} of effect algebras. They can be added, via a partial operation, and <b>multiplied.</b> This generalizes <b>key</b> properties of the unit interval [0, 1]. Such effect monoids can be used to define a probability distribution monad, again generalizing the situation for [0, 1]-probabilities. It will be shown that there are translations back and forth, {{in the form of an}} adjunction, between effect monoids and “convex” monads. This convexity property is formalized, both for monads and for categories. In the end, this leads to “triangles of adjunctions” (in the style of Coumans and Jacobs) relating all the three relevant structures: probabilities, monads, and categories...|$|R
5000|$|The above {{discussion}} {{assumed a}} static {{world in which}} policy actions and outcomes for only one moment in time were considered. However, the analysis generalizes to a context of multiple time periods in which both policy actions take place and target variable outcomes matter, and in which time lags in the effects of policy actions exist. In this dynamic stochastic control context with <b>multiplier</b> uncertainty, a <b>key</b> {{result is that the}} [...] "certainty equivalence principle" [...] does not apply: while in the absence of multiplier uncertainty (that is, with only additive uncertainty) the optimal policy with a quadratic loss function coincides with what would be decided if the uncertainty were ignored, this no longer holds in the presence of multiplier uncertainty.|$|R
40|$|An {{approach}} is described that investigates {{the potential of}} probabilistic "neural" architectures for computation with deep sub-micrometer (DSM) MOSFETs. Initially, noisy MOSFET models are based upon those for a 0. 35 /spl mu/m MOS technology with an exaggerated 1 /f characteristic. We explore the manifestation of the 1 /f characteristic at the output of a 2 -quadrant <b>multiplier</b> when the <b>key</b> n-channel MOSFETs are replaced by "noisy" MOSFETs. The stochastic behavior of this noisy multiplier has been mapped on to a software (Matlab) model of a continuous restricted Boltzmann machine (CRBM) - an analogue-input stochastic computing structure. Simulation of this DSM CRBM implementation shows little degradation {{from that of a}} "perfect" CRBM. This paper thus introduces a methodology for a form of "technology-downstreaming" and highlights the potential of probabilistic architectures for DSM computation...|$|R
40|$|In present generation, VLSI {{systems and}} their design became so much {{important}} in the Electronic Engineering. As the VLSI design {{is the basis for}} electronic components, one should optimise the constraints. For high performance systems such as digital signal processors and microprocessors, <b>Multiplier</b> is the <b>key</b> hardware block. In designing VLSI systems, the main criteria of interest are high speed, low power, less area, low cost. Many researchers have tried and are trying to design multipliers which offer either of the following design targets-high speed, low power consumption, regularity of layout and hence less area or even combination of them in one multiplier, thus making them suitable for various compact VLSI implementations. Improving speed results always in larger areas. So, this paper provides the techniques that optimise the area and speed up the multiplication process...|$|R
40|$|Abstract — An {{approach}} is described that investigates {{the potential of}} probabilistic “neural ” architectures for computation with Deep Sub-Micrometer (DSM) MOSFETs. Initially, noisy MOSFET models are based upon those for a 0. 35 µm MOS technology with an exaggerated 1 /f characteristic. We explore the manifestation of the 1 /f characteristic at the output of 2 -quadrant <b>multiplier</b> when the <b>key</b> n-channel MOSFETs are replaced by “noisy ” MOSFETs. The stochastic behavior of this noisy multiplier has been mapped on to a software (Matlab) model of a Continuous Restricted Boltzmann Machine (CRBM) – an analogue-input stochastic computing structure. Simulation of this DSM CRBM implementation shows little degradation {{from that of a}} “perfect ” CRBM. This paper thus introduces a methodology for a form of “technology-downstreaming ” and highlights the potential of probabilistic architectures for DSM computation. 1...|$|R
40|$|A single-photon {{avalanche}} detector (SPAD) for high-speed quantum-key {{generation has}} successfully been developed. It {{has the highest}} photon detection repetition frequency and the lowest dark count rate in the world, as a board-mountable sub-system. The SPAD consists of an ultra-small dual-avalanche photodiode (APD) module and a novel discriminator. The APD module design is consistent with cooling capability and high-frequency characteristics. The new module has a 3 GHz bandwidth enabling 1 GHz gate-pulse repetition. The bandwidth is extended 15 -fold relative to the most wideband peltier cooled APD module. The discriminator has a self-training mechanism to compensate charge pulse. Dark count rare of the SPAD is reduced 1 / 10 th relative to the lowest dark count single photon detector. The SPAD allows 3. 2 -fold <b>multiplying</b> the quantum <b>key</b> generation rate in theoretical estimation. Comment: 2 pages, 5 figure...|$|R
40|$|Data {{security}} {{is the major}} point of concern in today’s internet communication system for which cryptography plays a vital role. Modular <b>multiplier</b> plays a <b>key</b> role in modern cryptography system. Galois field arithmetic is being popularly used in such applications. Montgomery multiplication is the method for boosting up the speed of modular multiplication. Montgomery modular multiplier is implemented for larger operand size to design encryption and decryption algorithm for RSA security system. This paper contributes {{to the implementation of}} modular multiplier using Montgomery algorithm for RSA encryption and decryption,where existing architecture is implemented using carry select adder and modified carry select adder and it is concluded that later uses 23 % less area and approximate 4. 5 % less output delay as compared to former, in VHDL using Xilinx ISE 9. 2 i and has been simulated on FPGA device spartan 3, xc 3 s 200...|$|R
40|$|Physical {{therapists}} may {{not expect}} to have a pronounced effect on the neuro-developmental function of the cerebral palsied adult because the neuroplasticity of the child is no longer present in the adult. Adapting the environment to such an adult, therefore, becomes of utmost importance. The wheelchair {{may be the most}} important structure of the environment for cerebral palsied adults. I present methods for assessing the severely involved adult client and evaluating adapta-tions of the wheelchair for therapeutic seating. The anterior and posterior tilt of the pelvis and the vertical angle of the backrest are emphasized in achieving therapeutic seating for the severely <b>multiply</b> handicapped adult. <b>Key</b> Words: Adult, Cerebral palsy, Wheelchair. Adaptive seating for severely disabled cerebral palsied chil-dren has been a subject of increasing concern in recent years. The literature, however, has rarely addressed the needs of adults with cerebral palsy. As physical therapists, we have often focused our attention on mobile and changing childre...|$|R
40|$|Thatcher et al- 2 Objectives: To {{evaluate}} {{the reliability and}} validity of a Z-score normative EEG database for Low Resolution Electromagnetic Tomography (LORETA). Methods: EEG digital samples (2 second intervals sampled 128 Hz, 1 to 2 minutes eyes closed) were acquired from 106 normal subjects and the cross-spectrum was computed and <b>multiplied</b> by the <b>Key</b> Institute’s LORETA 2, 394 gray matter pixel T Matrix. After a log 10 transform or a Box-Cox transform the mean and standard deviation of the *. lor files were computed for each of the 2, 394 gray matter pixels for each of the subjects from 1 to 30 Hz. Tests of gaussianity were computed in order to best approximate a normal distribution for each frequency and gray matter pixel. The relative sensitivity of a Z score database was computed by measuring the approximation to a Gaussian distribution. The validity of the LORETA normative database was evaluated by the degree to which confirmed brain pathologies were localized using the LORETA normative database...|$|R
40|$|Modulo 2 n + 1 <b>multiplier</b> is the <b>key</b> {{block in}} the circuit {{implementation}} of cryptographic algorithm such as IDEA and also widely used {{in the area of}} data security applications such as residue arithmetic, digital signal processing, and data encryption that demands low-power, area and high-speed operation. In this paper, a new circuit implementation of an area and power efficient self-checking modulo 2 n + 1 multiplier based on residue codes are proposed. Modulo 2 n + 1 multiplier has the three major stages: partial product generation stage, partial product reduction stage, and the final adder stage. The last two stages determine the speed and power of the entire circuit. An efficient self-checking modulo 2 n + 1 multiplier based on residue codes are proposed to detect errors online at each single gate during the data transmission and produce an error at the gate output, which may propagate through the subsequent gates and generate an error at the output of the modulo multiplier. The proposed self-checking modulo multipliers for various values of input are specified in Verilog Hardware Description Language (HDL), simulated by using XILINX ISE and synthesized using cadence RTL encounter tool...|$|R
40|$|This paper {{analyzes}} {{the impact of}} trade reforms on household welfare. In particular, it studies the importance {{of each of the}} links that together constitute the impact using data from the Vietnamese experience in the 1990 s. The implementation of trade reforms in the 1990 s, most noteworthy of which was the liberalization of rice, resulted in substantial improvement in welfare as evidenced by the drastic decline in poverty. Using analytical and empirical methods, the author examines the role of each channel (direct versus indirect) in this improvement for different groups of households. Results indicate that the growth has been broad based and pro-poor. Poorer households experienced more growth for each and every group analyzed. And contrary to the standard literature, net buyer households had more growth compared with net sellers, emphasizing the importance of indirect links. Decomposition of the growth shows that for rural households, both the direct effect and the multiplier effect drive growth while the <b>multiplier</b> effect was <b>key</b> in urban areas. The importance of the secondary effects underscores the need for a broader model to estimate the impact of trade reforms fully. Rural Poverty Reduction,Economic Theory&Research,Small Area Estimation Poverty Mapping,Inequality,Consumption...|$|R
40|$|Abstract. In this paper, we {{investigate}} the multi-user setting both {{in public and}} in secret-key cryptanalytic applications. In this setting, the adversary tries to recover keys of many users in parallel more efficiently than with classical attacks, i. e., the number of recovered <b>keys</b> <b>multiplied</b> by the time complexity to find a single key, by amortizing the cost among several users. One possible scenario is to recover a single key in a large set of users more efficiently than to recover a key in the classical model. Another possibility is, after some shared precomputation, {{to be able to}} learn individual keys very efficiently. This latter model is close to traditional time/memory tradeoff attacks with precompu-tation. With these goals in mind, we introduce two new algorithmic ideas to improve collision-based attacks in the multi-user setting. Both ideas are derived from the paral-lelizable collision search as proposed by van Oorschot and Wiener. This collision search uses precomputed chains obtained by iterating some basic function. In our cryptanalytic application, each pair of merging chains can be used to correlate the key of two distinct users. The first idea is to construct a graph, whose vertices are keys and whose edges are these correlations. When the graph becomes connected, we simultaneously recove...|$|R
40|$|Over {{the last}} decades, {{there has been}} an {{increased}} interest in sustainability and it has become an important issue in production and manufacturing research. Referring to the definition by Brundtland, sustainable development is “development that meets the needs of the present without compromising the ability of future generations to meet their own needs” (Keeble 1988). This idea of sustainability might be understood easily, but determining concrete goals and measurements continues to be challenging. For manufacturing companies, sustainable manufacturing is one way to decrease the environmental impact of their products. In the literature, there are different approaches to assess sustainability. However, no approach aims to improve sustainability and costs since sustainability and cost reduction are often seen as conflictive and cannot be achieved at the same time. An overlap between cost reduction and sustainability can push companies to expend more effort in order to achieve long term business success while decreasing the environmental impact of their products. ^ This study presents a framework that aims to prove this overlap based on gathered data of a case study. Besides an assessment of the current state of manufacturing processes, alternative future state models are determined, which are more sustainable and decrease the costs of production. ^ All data gathered within this study was manipulated by a <b>key</b> <b>multiplier</b> to ensure the integrity of the manufacturer and does not represent the real manufacturing data. ...|$|R
