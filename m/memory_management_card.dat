1|3670|Public
50|$|The ND-100 was {{frequently}} sold {{together with a}} <b>memory</b> <b>management</b> <b>card,</b> the MMS. The combined power use of these boards was 90 watts. These boards would usually occupy slots 2 and 3, for the CPU and MMS, respectively. Slot 1 was reserved for the Tracer, a hardware debugger system.|$|E
40|$|This {{research}} paper examines memory managementissues associated with Smart card EEPROM and proposes a newtechnique for <b>memory</b> <b>management</b> for smart <b>card</b> files. Theentire work concentrates {{to suggest a}} new methodology onmemory allocation and de-allocation using pointers, which givesbetter memory utilization...|$|R
50|$|Modern-day game {{consoles}} and videogames, {{starting with the}} PC-Engine, all have a minimal BIOS that also provides some interactive utilities such as <b>memory</b> <b>card</b> <b>management,</b> audio or video CD playback, copy protection and sometimes carry libraries for developers to use etc. Few of these cases, however, would qualify as a true operating system.|$|R
50|$|Application-level <b>memory</b> <b>management</b> is {{generally}} categorized as either automatic <b>memory</b> <b>management,</b> usually involving garbage collection (computer science), or manual <b>memory</b> <b>management.</b>|$|R
50|$|The International Symposium on <b>Memory</b> <b>Management</b> (ISMM) is an ACM SIGPLAN {{symposium}} on <b>memory</b> <b>management.</b> Before becoming a conference {{it was known}} as the International Workshop on <b>Memory</b> <b>Management</b> (IWMM).|$|R
5000|$|... #Caption: Comparison of the I/O <b>memory</b> <b>management</b> unit (IOMMU) to the <b>memory</b> <b>management</b> unit (MMU).|$|R
50|$|Remote {{management}} can be enabled on many computers (not necessarily only servers) {{by adding}} a remote <b>management</b> <b>card</b> (while some cards only support a limited list of motherboards). Newer server motherboards often have built-in remote management and need no separate <b>management</b> <b>card.</b>|$|R
40|$|This paper proposes an {{implementation}} {{scheme for}} programming language interpreters that addresses both modular design of <b>memory</b> <b>management</b> system and execution efficiency. Modularity let the language designer {{and the application}} programmer incorporate the most efective algorithm in their systems. Modular implementations of <b>memory</b> <b>management</b> systems {{can be used as}} a base for empirical analysis of various <b>memory</b> <b>management</b> systems. The proposed system offers an abstract interface that can be used to implement various <b>memory</b> <b>management</b> algorithms. Our specialization technique takes the implementation of the interpreter and the application bytecode and generates their specialized versions whose <b>memory</b> <b>management</b> interface calls to the given <b>memory</b> <b>management</b> system. Benchmark results show that specialization technique eliminates the 5 - 10 % overhead and our system works as efficiently as hand-tuned programming language system...|$|R
40|$|The {{purpose of}} this is report is to compare the {{advantages}} and disadvantages of different <b>memory</b> <b>management</b> philosophies. Focus will be on comparing the different techniques of <b>memory</b> <b>management</b> in the operating systems eCos and RTLinux. As the two subjects of this study is diverted by their area of application the comparison between the <b>memory</b> <b>management</b> is relevant. This report may therefore be used when deciding which of the two is most suited for a specific usage. The issues this report intends to address: What defines a real‐time system? In what context is eCos generally preferred? In what context is RTLinux generally preferred? What defines <b>memory</b> <b>management?</b> What <b>memory</b> <b>management</b> techniques do the subjects use? What are the differences in the <b>memory</b> <b>management</b> techniques used by the subject operating systems? Why are these techniques used...|$|R
5000|$|... #Caption: AP9606, {{an early}} SmartSlot Web/SNMP <b>Management</b> <b>Card</b> ...|$|R
50|$|The basic <b>memory</b> <b>management</b> {{method is}} {{reference}} counting, which allows automatic <b>memory</b> <b>management</b> with deterministic timing, {{without the need}} for concurrent garbage collection.|$|R
40|$|Abstract—Dynamic <b>memory</b> <b>management</b> {{is one of}} {{the most}} {{expensive}} but ubiquitous operations in many C/C++ applications. Additional features such as security checks, while desirable, further worsen <b>memory</b> <b>management</b> overheads. With advent of multicore architecture, it is important to investigate how dynamic <b>memory</b> <b>management</b> overheads for sequential applications can be reduced. In this paper, we propose a new approach for accelerating dynamic <b>memory</b> <b>management</b> on multicore architecture, by offloading dynamic management functions to a separate thread that we refer to as <b>memory</b> <b>management</b> thread (MMT). We show that an efficient MMT design can give significant performance improvement by extracting parallelism while being agnostic to the underlying <b>memory</b> <b>management</b> library algorithms and data structures. We also show how parallelism provided by MMT can be beneficial for high overhead <b>memory</b> <b>management</b> tasks, for example, security checks related to <b>memory</b> <b>management.</b> We evaluate MMT on heap allocation-intensive benchmarks running on an Intel core 2 quad platform for two widelyused memory allocators: Doug Lea’s and PHKmalloc allocators. On average, MMT achieves a speedup ratio of 1. 19 × for both allocators, while both the application and <b>memory</b> <b>management</b> libraries are unmodified and are oblivious to the parallelization scheme. For PHKmalloc with security checks turned on, MMT reduces the security check overheads from 21 % to only 1 % on average. I...|$|R
50|$|Both in-band and {{out-of-band}} (OOB) {{management are}} usually done through a network connection, but an out-of-band <b>management</b> <b>card</b> {{can use a}} physically separated network connector if preferred. A remote <b>management</b> <b>card</b> usually has at least partially independent power supply, and can power the main machine on and off through the network.|$|R
40|$|<b>Memory</b> <b>management</b> is a {{critical}} issue for many large object-oriented applications, but in C++ only explicit memory reclamation through the delete operator is generally available. We analyse different possibilities for <b>memory</b> <b>management</b> in C++ and present a dynamic <b>memory</b> <b>management</b> framework which can be customised to the need of specific applications. The framework allows full integration and coexistence of different <b>memory</b> <b>management</b> techniques. The Customisable <b>Memory</b> <b>Management</b> (CMM) {{is based on a}} primary collector which exploits an evolution of Bartlett's mostly copying garbage collector. Specialised collectors can be built for separate memory heaps. A Heap class encapsulates the allocation strategy for each heap. We show how to emulate different garbage collection styles or user-specific <b>memory</b> <b>management</b> techniques. The CMM is implemented in C++ without any special support in the language or the compiler. The techniques used in the CMM are general enough to be applicable also to [...] ...|$|R
40|$|An {{embedded}} {{system is a}} computer system designed for specific control functions or for any dedicated application, often with real-time computing constraints. Real time operating system (RTOS) is specially used to meet the real time constraint and to support the sophisticated facilities provided by {{embedded system}}. While designing any embedded system <b>memory</b> <b>management</b> is an important issue. Embedded system developers commonly implement custom <b>memory</b> <b>management</b> facilities on top of what the underlying RTOS provides. That’s why understanding <b>memory</b> <b>management</b> is therefore an important aspect. In this paper {{we are dealing with}} different <b>memory</b> <b>management</b> strategies and algorithm that are used in real time operating system in order to improve the performance of the intended application. Firstly we have compared the static and dynamic <b>memory</b> <b>management</b> strategy and then we consider different algorithms {{that can be used to}} implement the dynamic <b>memory</b> <b>management</b> in real time operating system...|$|R
40|$|In general, hard {{real-time}} applications {{avoid the}} use of dynamic <b>memory</b> <b>management</b> systems due to the unbounded response times of dynamic <b>memory</b> <b>management</b> operations. Since the complexity of real-time applications grows, dynamic <b>memory</b> <b>management</b> systems are needed to increase their flexibility and functionalities. There exist <b>memory</b> <b>management</b> systems that offer O(1) operations’ response times, but do not consider memory fragmentation. In contrast is the Java domain, where memory fragmentation is handled by real-time garbage collected systems. This survey {{provides an overview of}} the approaches in both domains with focusing on the administration of memory...|$|R
40|$|This paper {{addresses}} {{the issue of}} improving the performance of <b>memory</b> <b>management</b> for real-time Java applications, building upon the real-time specification for Java (RTSJ) from the Real-Time Java Expert Group. In a first step, a collecting dynamic memory solution including both a real-time garbage collector and region-based <b>memory</b> <b>management,</b> is proposed. A thorough analysis of the parameters in¯uencing the performance of write barriers in <b>memory</b> <b>management,</b> together with ways of improvement are then presented. Finally, {{the implementation of a}} <b>memory</b> <b>management</b> solution compliant with the RTSJ and integrating the proposed improvements is sketched...|$|R
50|$|OpenStep uses {{reference}} counting {{to manage}} memory and object lifetimes, and provides Autorelease Pools {{as a form}} of automatic <b>memory</b> <b>management.</b> NeXTSTEP does not provide reference counted <b>memory</b> <b>management.</b>|$|R
40|$|Dealing {{with global}} on-chip memory allocation/de-allocation in a dynamic yet {{deterministic}} way {{is an important}} issue for upcoming billion transistor multiprocessor System-on-a-Chip (SAC) designs. To achieve this, we propose a new <b>memory</b> <b>management</b> hierarchy called Two-Level <b>Memory</b> <b>Management.</b> To implement this <b>memory</b> <b>management</b> scheme - which presents a paradigm shift in the way designers look at on-chip dynamic memory allocation- we present a System-on-a-Chip Dynamic <b>Memory</b> <b>Management</b> Unit (SoCDMMU) for allocation of the global on-chip memory, which we refer to as level two <b>memory</b> <b>management</b> (level one is the operating system <b>management</b> of <b>memory</b> allocated to a particular on-chip processor). In this way, heterogeneous processors in an SoC can request and be granted portions of the global memory in twenty clock cycles in the worst case for a four-processor SoC, which is at least an order of magnitude faster than software-based <b>memory</b> <b>management.</b> We present a sample implementation of the SoCDMMU and compare hardware and software implementations...|$|R
40|$|In {{this article}} we seek to compare the <b>memory</b> <b>management</b> sub-systems of two popular and freely {{available}} operating systems - FreeBSD and Linux. First a framework is developed, spelling out the components of a generic and modern <b>memory</b> <b>management</b> system. The framework is then used in a design level comparison of <b>memory</b> <b>management</b> in the two operating systems. (Also cross-referenced as UMIACS-TR- 98 - 45...|$|R
40|$|Region-based <b>memory</b> <b>management</b> is an {{interesting}} compiletime <b>memory</b> <b>management</b> technique. Implementing region-based <b>memory</b> <b>management</b> for a language is twofold, firstly developing a static region analysis that annotates programs with region instructions and secondly providing a region-aware runtime system that can run the region-annotated programs. In this report we develop the runtime support needed by the region-annotated programs which {{are the result of}} a region analysis that has been developed for Mercury. We implement the runtime support in a region simulator which allows us to evaluate the memory behaviour of a region-annotated program as if it is executed in a fully-implemented region-based <b>memory</b> <b>management</b> system. Using the region analyser and the region simulator we experiment with several benchmark programs. The obtained memory consumption results are very encouraging, in some programs optimal <b>memory</b> <b>management</b> is achieved...|$|R
5000|$|PowerChute Business Edition {{requires}} servers to {{be connected}} via serial port or USB to the monitored Smart-UPS equipment. It provides UPS management and safe server shutdown for up to 25 servers. [...] UPS Network <b>Management</b> <b>Cards</b> made by APC are enabling UPS management, by directly connecting the UPS to the network with its own IP address, avoiding dependence or {{the need for a}} server, which is particularly useful in wiring closets where frequently no servers are present. PowerChute Network Shutdown, together with the UPS Network <b>Management</b> <b>Card,</b> enables safe server shutdown by communicating over a network to any network-enabled APC Smart-UPS (those that contain an UPS network <b>management</b> <b>card).</b>|$|R
40|$|The paper {{introduces}} a new <b>memory</b> <b>management</b> approach for second gener-ation microkernels named M-M/S-CD {{that was designed}} {{in the spirit of}} minimality principle. It was developed from scratch based on analytical model of computer mem-ory system. M-M/S-CD <b>memory</b> <b>management</b> pushes out all <b>memory</b> <b>management</b> activities and policies into the user mode applications, where kernel only enforces two conditions are met that assure that memory system will remain in closed state...|$|R
5000|$|... newLISP uses {{a method}} of {{automatic}} <b>memory</b> <b>management</b> different from traditional garbage collection schemes, called One Reference Only (ORO) <b>Memory</b> <b>Management.</b> Each variable is referenced only by its context, and each context is referenced globally.|$|R
40|$|Abstract-Recent {{technological}} advances in <b>memory</b> <b>management</b> architectures, multiprocessor systems, and software architectures dictate a reevaluation {{of the virtual}} <b>memory</b> <b>management</b> support provided by an operating system. The problems posed by multiprocessor systems and the portability {{issues raised by the}} large variety of <b>memory</b> <b>management</b> units available have not been satisfactorily addressed by past virtual memory systems. In addition, increases in virtual memory functionality that can be provided by memory managed architectures have gone largely unnoticed by system designers. This paper describes the design, implementation, and evaluation of the Mach virtual <b>memory</b> <b>management</b> system. The Mach virtual memory system exhibits architecture indepedence, multiprocessor and distributed system support, and advanced functionality. The performance of this virtual memory system is shown to often exceed that of commercially developed <b>memory</b> <b>management</b> systems targeted at specific hardware architectures. Index Terms-Architecture independence, Mach, parallel operating systems, UNIX, virtual memory...|$|R
50|$|Addition {{of a new}} <b>memory</b> <b>management</b> {{architecture}} called Book-E, {{replacing the}} conventional paged <b>memory</b> <b>management</b> architecture for embedded applications. Book-E is application software compatible with existing PowerPC implementations, but needs {{minor changes to the}} operating system.|$|R
40|$|IA- 64 is Intel Corporation's {{recently}} released 64 -bit architecture. It includes {{features such as}} data/control speculation, instruction predication {{and a large number}} of parallel resources. Also included is a novel <b>memory</b> <b>management</b> unit that allows orthogonal translation and protection mechanisms to be used. This flexibility opens up opportunities for improved <b>memory</b> <b>management</b> techniques. This paper presents our enhancements to IA- 64 Linux <b>memory</b> <b>management</b> with focus on improving effective TLB coverage...|$|R
40|$|Manual <b>memory</b> <b>management</b> is error prone. Some of {{the errors}} it causes, in {{particular}} memory leaks and dangling pointers, {{are hard to}} find. Manual <b>memory</b> <b>management</b> becomes even harder when concurrency enters the picture. It therefore gets more and more important to overcome the problems of manual <b>memory</b> <b>management</b> in concurrent software as the interest in these applications increases {{with the development of}} new, multi-threaded, hardware. To ease the implementation of concurrent software many programming languages these days come with automatic <b>memory</b> <b>management</b> and support for concurrency. This support, called the concurrency model of the language, comes in many flavors (shared data structures, message passing, etc.). The performance and scalability of applications implemented using such programming languages depends on the concurrency model, the memory architecture, and the memory manager used by the language. It is therefore important to investigate how different memory architectures and <b>memory</b> <b>management</b> schemes affect the implementatio...|$|R
5000|$|... #Caption: Foundry FastIron II Plus chassis {{with two}} fiber <b>management</b> <b>cards</b> and six 16-port gigabit Ethernet cards ...|$|R
50|$|The OS {{manages the}} threads all by itself, {{allowing}} the hardware {{to switch from}} one thread to the other when appropriate, and also handles <b>memory</b> <b>management</b> and paging (to system memory and to disk) via integrated OS-kernel <b>memory</b> <b>management.</b>|$|R
50|$|Latency is a debated {{point that}} has changed over time, with early garbage {{collectors}} and simple implementations performing very poorly compared to manual <b>memory</b> <b>management,</b> but sophisticated modern garbage collectors often performing as well or better than manual <b>memory</b> <b>management.</b>|$|R
5000|$|The ND-110 {{combined}} the <b>Memory</b> <b>Management</b> System and CPU, previously separate cards, on one board. The single CPU/MMS board was {{plugged into the}} <b>memory</b> <b>management</b> board slot, usually numbered 3. The power consumption was reduced from 90 watts to 60.|$|R
40|$|Complex {{mechanisms}} for dynamic <b>memory</b> <b>management</b> and garbage collection {{are needed in}} modern imperative programming languages. Implementation of <b>memory</b> <b>management</b> functions efficiently {{both in terms of}} memory usage and execution performance becomes important for programs written in such languages. In this paper, we introduce a memory allocator that uses hardware assistance to improve the performance of a existing software allocator (PHK allocator). On average, our design reduces the execution time of <b>memory</b> <b>management</b> functions by 58. 9 %. ...|$|R
40|$|Abstract — In {{computer}} operating systems, {{demand paging}} (as opposed to anticipatory paging) {{is a method}} of virtual <b>memory</b> <b>management.</b> Mainly this paper focus {{on the process of}} execution of pages in physical memory. Mainly this paper tells that faulits of page. Mainly these paper exaplin the lazy loading technique. This lazy loading technique performs the evaluation of expressions in the virtual <b>memory</b> <b>management.</b> This paper attempts the Short-circuit evaluation KeyTerms: demand paging, virtual <b>memory</b> <b>management,</b> lazy loading technique, page fault, Short-circuit evaluation In computer operating systems, demand paging (as opposed to anticipatory paging) is a method of virtual <b>memory</b> <b>management.</b> In a system that uses demand paging, the operating system copies a disk page into physical memor...|$|R
40|$|With {{reference}} to a <b>memory</b> <b>management</b> system supporting the single address space abstraction and a uniform, persistent view of storage, we present a set of mechanisms that allow applications to exert explicit control over <b>memory</b> <b>management</b> activities. These mechanisms {{make it possible to}} move the contents of a virtual page to primary memory for fast processor access, or to push these contents back to secondary memory to free primary memory space. Our <b>memory</b> <b>management</b> scheme allows programs to exploit the memory reference pattern of the underlying algorithms, thereby improving utilisation of the system storage resources. This result is illustrated by using significant examples of <b>memory</b> <b>management</b> activities implemented at the application program level...|$|R
40|$|Abstract. Region-based <b>memory</b> <b>management</b> {{is a form}} of compiletime <b>memory</b> <b>management,</b> {{well-known}} {{from the}} functional programming world. This paper describes region-based <b>memory</b> <b>management</b> for the Mercury language using some points-to graphs that model the partition of the memory used by a program into separate regions and distribute the values of the program’s variables over the regions. First, a region analysis determines the different regions in the program. Second, the liveness of the regions is computed. Finally, a program transformation adds region annotations to the program for region support. Our approach obtains good results for a restricted set of deterministic Mercury programs and is a valid starting point to make region-based <b>memory</b> <b>management</b> work with general Mercury programs. ...|$|R
