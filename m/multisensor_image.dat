52|48|Public
50|$|In {{computer}} vision, <b>Multisensor</b> <b>Image</b> fusion is {{the process}} of combining relevant information from two or more images into a single image. The resulting image will be more informative than any of the input images.|$|E
40|$|Abstract: <b>Multisensor</b> <b>image</b> fusion is {{a process}} of {{combining}} or amalgamating information from multiple sensors. It has been applied {{to a wide variety of}} fields such as navigation, military surveillance, remote sensing, medical diagnosis, industrial process control and measurement, intelligent robot, and law enforcement. In this paper, the basic concept, advantage, general structure, methods, applications, and performance evaluation of <b>multisensor</b> <b>image</b> fusion are presented...|$|E
40|$|Abstract:- In {{this paper}} {{we examine the}} {{comparative}} use {{of different types of}} wavelets for Quickbird <b>multisensor</b> <b>image</b> fusion, for the purposes of high-resolution urban mapping. Based on the Discrete Wavelet Transform, several types of standard wavelets were implemented and evaluated. The best wavelet fusion results were combined with the IHS image fusion method using two types of colour composites. The IHS image fusion method was also implemented. The crossbred wavelet and IHS transform provides the most accurate colour representation of the spectral information of the initial bands, improving also their spatial resolution. Based on the results of the evaluation, a high-resolution fusion-based map of Heraclion, Crete was produced. Key-Words:- <b>Multisensor</b> <b>image</b> fusion, High resolution mapping, Wavelets, IHS transform 1...|$|E
40|$|A multivalued wavelet {{transform}} (MWT) is proposed to fuse <b>multisensor</b> <b>images</b> in feature space. First, feature space is constructed using image-derived features, {{and then the}} MWT is introduced. The <b>multisensor</b> <b>images</b> are then fused in the MWT domain using a voting and electing fuser based on the cross-feature scale guideline and the posterior probability of the MWT coefficient. The performance of the MWT is estimated using metric measures regarding various aspects of image quality. A fusion experiment using Thematic Mapper (TM) multispectral and SPOT panchromatic images of south China demonstrates that MWT outperforms smoothing filter-based intensity modulation (SFM) {{in terms of the}} fidelity to spectral properties and the injection of salient information. The experimental results confirm that the MWT is a superior fusion method for enhancing spatial quality of multispectral images with their spectral properties reliably preserved...|$|R
40|$|Registration and {{simultaneous}} {{analysis of}} <b>multisensor</b> <b>images</b> is useful because the multiple data sets {{can be compressed}} through image processing techniques to facilitate interpretation. This also allows integration of other spatial data sets. Techniques being developed to analyze <b>multisensor</b> <b>images</b> involve comparison of image data with a library of attributes based on physical properties measured by each sensor. This results {{in the ability to}} characterize geologic units based on their similarity to the library attributes, as well as discriminate among them. Several studies can provide information on ways to optimize multisensor remote sensing. Continued analyses of the Death Valley and San Rafael Swell data sets can provide insight into tradeoffs in spectral and spatial resolutions of the various sensors used to obtain the coregistered data sets. These include imagery from LANDSAT, SEASAT, HCMM, SIR-A, 11 -channel VIS-NIR, thermal inertia images, and aircraft L- and X-band radar...|$|R
40|$|This paper {{presents}} a real-time Hough-based algorithm for straight line segment extraction in complex <b>multisensor</b> <b>images,</b> {{which aims to}} avoid loss of spatial information {{as well as to}} eliminate spurious peaks and reduce discretization errors. A parameter space representation able to take into account spatial information during the voting phase is proposed. This representation allows the detection phase to be performed by focusing the algorithm on particular locations of the parameter space. The search space is consequently reduced, and a deeper decision strategy can be adopted, which takes into account the local distribution of segments along both a line and different lines, for comparable directions and positions. Experimental results on a large set of complex <b>multisensor</b> <b>images</b> (e. g. underwater images, low-light outdoor images, SAR images, etc.) are presented. The main advantages of the proposed method over both feature and image-space methods are evaluated in terms of computational efficiency, detection accuracy and noise robustness. (C) 2000 Academic Press...|$|R
40|$|Mutual {{information}} (MI) {{has been}} widely used in <b>multisensor</b> <b>image</b> matching, but it may lead to mismatch among images with messy background. However, additional prior information can be of great help in improving the matching performance. In this paper, a robust Bayesian estimated mutual information, named as BMI, for <b>multisensor</b> <b>image</b> matching is proposed. This method has been implemented by utilizing the gradient prior information, in which the prior is estimated by the kernel density estimate (KDE) method, and the likelihood is modeled according to the distance of orientations. To further improve the robustness, we restrict the matching within the regions where the corresponding pixels of template image are salient enough. Experiments on several groups of multisensor images show that the proposed method outperforms the standard MI in robustness and accuracy and is similar with Pluim’s method. However, our computation is far more cost saving...|$|E
40|$|The {{problem of}} {{objective}} evaluation of <b>multisensor</b> <b>image</b> fusion strategies is analysed {{for the design}} of a dual infrared system. Such a system should be used to enhance the sight effectiveness in assisting a driver or a pilot in bad visibility conditions. Two no-reference indexes are used to quantify the performance of different image fusion methods. Numerical results are presented and discussed in terms {{of the quality of the}} fused images...|$|E
40|$|<b>Multisensor</b> <b>image</b> data (SIR-A, Seasat SAR and Landsat MSS) over {{areas in}} nothern Algeria and eastern Utah have been coregistered {{in order to}} assess the {{complementary}} effects of the orbital sensors for geologic mapping in two very different terrains. This first attempt at registering such a data set shows that the radar backscatter information provided by the SIR-A image increases the classification accuracy of several geologic units over the Landsat image alone, and over combined Landsat and Seasat images...|$|E
40|$|The {{application}} of structured neural networks to the supervised classification of <b>multisensor</b> <b>images</b> is discussed. The {{purpose is to}} give a criterion for network architecture definition and to allow {{the interpretation of the}} network behavior. The latter result can be used to understand the importance of sensors and related channels to the classification task. The networks' architecture is configured by exploiting the characteristics of a given multisensor classification problem. Then, such networks are trained to solve the problem. Finally, they are transformed into equivalent networks to obtain a simplified representatio...|$|R
40|$|In the {{analysis}} and restoration {{of the content of}} ancient degraded documents, the main issue is often to separately extract and enhance the various layers of information overlapped in the document itself. We model <b>multisensor</b> <b>images</b> of a document as convolutive mixtures of the interfering patterns, and adopt a Bayesian estimation approach which exploits Gibbs priors, accounting also for well-behaved edges in the ideal images. We show applications to the removal of the bleed-through/show-through effects, and to the recovery of the original color of faded images. This latter application can be of interest in other cultural heritage contexts, such as the restoration of old photos and videos...|$|R
40|$|This paper {{deals with}} the {{statistical}} segmentation of <b>multisensor</b> <b>images.</b> In a Bayesian context the interest of using Hidden Markov Random Fields, which allow one to take contextual information into account, has been well known for about twenty years. In other situations, the Bayesian context is inadequate and one has {{to make use of}} the theory of evidence. The aim of our work is to propose an evidential model which can take into account contextual information via Markovian fields. We define a general evidential Markovian model and show that it is usable in practice. Some simulation results attest to the practical interest of the proposed model...|$|R
40|$|Abstract- The {{problem of}} {{objective}} evaluation of <b>multisensor</b> <b>image</b> fusion strategies is analysed {{for the design}} of a dual infrared system. Such a system should be used to enhance the sight effectiveness in assisting a driver or a pilot in bad visibility conditions. Two no-reference indexes are used to quantify the performance of different image fusion methods. Numerical results are presented and discussed in terms {{of the quality of the}} fused images. Index Terms – Image/video processing. Data fusion. Image quality indexes. I...|$|E
40|$|A {{statistical}} {{signal processing}} approach to <b>multisensor</b> <b>image</b> fusion is presented for concealed weapon detection (CWD). This approach {{is based on}} an image formation model in which the sensor images are described as the true scene corrupted by additive non-Gaussian distortion. The expectation-maximization (EM) algorithm is used to estimate the model parameters and the fused image. We demonstrate the efficiency of this approach by applying this method to fusion of visual and non-visual images with emphasis on CWD applications. 1...|$|E
40|$|We study {{two related}} topics in {{decision}} fusion for <b>multisensor</b> <b>image</b> classification. The first topic {{is the use}} of a weighted logarithmic opinion pool compared to the statistical product combination rule. The performance is compared on three data sets. The second topic is related to different criteria for parameter estimation for a statistical fusion model. We propose an alternative criterion for estimation of the mean vector and the covariance matrix of a Gaussian model based on minimizing the number of misclassified training samples and compare the performance of this to the traditional Maximum Likelihood approach...|$|E
40|$|The aim of {{this study}} is to conduct a forest {{resources}} study using optical and synthetic aperture radar (SAR) satellite images. For this purpose, a forest-dominated site around the Lake Khuvsgul located in northern Mongolia is selected. As remote sensing (RS) data sources, panchromatic and multispectral Landsat 7 images as well as ALOS PALSAR L-band HH polarization data are used. To produce a reliable land cover map from the <b>multisensor</b> <b>images,</b> a novel refined maximum likelihood classification based on the spectral and spatial thresholds are applied and for the accuracy assessment an overall accuracy is used. Overall, the research demonstrates that advanced spatial technologies based on optical and microwave RS are reliable tools for different forest studies...|$|R
40|$|Abstract — This paper proposes an {{efficient}} method for image fusion using Kuwahara filter, {{which is used}} for edge-preserving noise removal of images. Source images are fused by weighted average using the weights computed from the detail images that are extracted from the source images using Kuwahara filter. The performance of this method has been verified on several pairs of multifocus and <b>multisensor</b> <b>images</b> and compared with the existing methods visually. It is found that, none of the methods have shown consistence performance for all the performance measures. But as compared to them, the proposed method has shown good performance {{in most of the}} cases. Further, the visual quality of the fused image by the proposed method is superior to other methods...|$|R
40|$|This paper proposes the {{application}} of structured neural networks to land-cover classification in remote-sensing <b>images</b> (in particular, <b>multisensor</b> <b>images</b> are considered). Purpose of our approach is to give a criterion for network architecture definition and to allow {{the interpretation of the}} "network behaviour'. The first result aims to avoid a cumbersome trial-and-error process; the latter one can be used to obtain information about the relevance of sensors and related bands to land-cover classification. First of all, the architecture of structured networks is tailored to a multisensor classification problem. Then, they are trained and transformed into "simplified networks' which allow one to evaluate the relevance of sensors and related bands. Experimental results on a multisensor data set related to an agricultural area are reported. -from Author...|$|R
40|$|In {{this paper}} we apply the Multi-Look Joint Sparsity Fusion {{algorithm}} to <b>multisensor</b> <b>image</b> data. Our algorithm at first performs sparse unmixing of the hyperspectral data and selects pixels {{for a second}} unmixing of the multispectral image. This is done by applying a joint sparsity model, which exploits similarities within neighbouring pixels. We test our resolution enhancement method using a hyperspectral and a multispectral image with a spatial resolution of 30 m and 3 m, respectively. To asses the results we evaluate the classification result of the resolution enhanced and original images...|$|E
40|$|The use of {{more than}} one remote sensing {{technique}} is particularly important for Earth Science applications because of the compositional and textural information derivable from the images. The ability to simultaneously analyze images acquired by different sensors requires coregistration of the <b>multisensor</b> <b>image</b> data sets. In order to insure pixel to pixel registration in areas of high relief, images must be rectified to eliminate topographic distortions. Coregistered images can be analyzed using a variety of multidimensional techniques and the acquired knowledge of topographic effects in the images can be used in photogeologic interpretations...|$|E
30|$|Some authors [41, 42] {{state that}} <b>multisensor</b> <b>image</b> fusion is a {{trade-off}} between the spectral {{information from a}}n MS sensor and the spatial information from a PAN sensor and that wavelet transform fusion methods easily control this trade-off. The trade-off idea, however, is just a convenient simplification, as discussed in [10], and ideal fusion methods {{must be able to}} simultaneously reach both spectral and spatial quality, and not one {{at the expense of the}} other. To do so, the physics of the capture process have to be taken into account, and the methods have to adapt to the local properties of the images.|$|E
40|$|A new {{scheme is}} {{proposed}} for fusing <b>multisensor</b> <b>images</b> {{in which one}} image {{is regarded as the}} main image and the other the complementary, based on the evaluation of certain characteristics in the images. In effect, the scheme is used to fuse an image pair in which one image is superior to the other for interpretation in terms of higher resolution, better image quality, or having more recognizable features. Feature information is based on local statistical characteristics, which are extracted using the analysis of variance (ANOVA) method [21], in the framework of experimental designs. In effect, feature information from one image is used to influence the corresponding pixel values of the other image. The fused image leads to a better human and/or machine interpretation of the area of interest in the images...|$|R
40|$|A system (Integrated <b>Multisensor</b> <b>Imaging</b> and Processing System - IMIPS) is {{described}} {{which consists of}} techniques and protocols which have been implemented in Geneva to combine (through registration, visualization, navigation and processing) various multidimensional biomedical imaging sensors, including Electro-Magnetic Tomography (EMT), for studying, assessing, and localizing neurological (dys-) function for both clinical and research applications. The already well described interest for this combination stems from the broad variety of complementary information brought out by modern biomedical imaging modalities. In this context, the input of volumetric EMT permits direct sighting, in near real-time, of any EM (dys-) funcfional behavior. Besides allowing morphology, metabolism and function to be studied simultaneously and from different points of view, the global combination permitted by IMIPS is expected to show its best value when studying pathologies reflected by metabolic or electrophysiologic dysfunctions...|$|R
40|$|Abstract—A new {{scheme is}} {{proposed}} for fusing <b>multisensor</b> <b>images</b> {{in which one}} image {{is regarded as the}} main image and the other the complementary, based on the evaluation of certain characteristics in the images. In effect, the scheme is used to fuse an image pair in which one image is superior to the other for interpretation in terms of higher resolution, better image quality, or having more recognizable features. Feature information is based on local statistical characteristics, which are extracted using the analysis of variance (ANOVA) method [21], in the framework of experimental designs. In effect, feature information from one image is used to influence the corresponding pixel values of the other image. The fused image leads to a better human and/or machine interpretation of the area of interest in the images. Index Terms—ANOVA for edge detection, feature-based data fusion, image fusion. I...|$|R
40|$|Abstract- We study {{two related}} topics in {{decision}} fusion for <b>multisensor</b> <b>image</b> classification. The first topic {{is the use}} of a weighted logarithmic opinion pool compared to the statistical product combination rule. The performance is compared on three data sets. The second topic is related to different criteria for parameter estimation for a statistical fusion model. We propose an alternative criterion for estimation of the mean vector and the covariance matrix of a Gaussian model based on minimizing the number of misclassified training samples and compare the performance of this to the traditional Maximum Likelihood approach. 1...|$|E
40|$|<b>Multisensor</b> <b>image</b> fusion (e. g. IR with visual) is {{the process}} of {{combining}} relevant information from two or more images into a single image. The aim is to find an objective quality measure, which can be used in automatic applications, that correlates best with subjective observer trials. Not all combinations of image, algorithm, and test observer can be worked out. In this paper R. Fisher’s Design of Experiments approach based on Latin Squares is used for thinning out the number of experiments for each observer in such observer trials while preserving exactness and reliability of the result...|$|E
40|$|A new {{technique}} is proposed for <b>multisensor</b> <b>image</b> registration by matching the features using discrete {{particle swarm optimization}} (DPSO). The feature points are first extracted from the reference and sensed image using improved Harris corner detector available in the literature. From the extracted corner points, DPSO finds the three corresponding points in the sensed and reference images using multiobjective optimization of distance and angle conditions through objective switching technique. By this, the global best matched points are obtained which are {{used to evaluate the}} affine transformation for the sensed image. The performance of the image registration is evaluated and concluded that the proposed approach is efficient...|$|E
40|$|Image {{registration}} plays {{a critically}} {{important role in}} remote sensing applications. Due to the large volumes of remote-sensing data available today, automated registration of multitemporal and/or <b>multisensor</b> <b>images</b> is highly desired. In this work, a new automatic approach for elastic image registration of remotely sensed images is proposed. The critical elements for an automated image registration procedure are explored. The elements include control-point (CP) extraction, CP matching, and transformation parameters estimation. In the proposed algorithm, a new CPs extractor has been developed. This technique exploits the nonsubsampled contourlet transform (NSCT) to automatically extract a set of CPs where misalignment between images {{can be expected to}} appear. The proposed algorithm has been successfully applied to register multitemporal ALSAT- 1 images from urban and agricultural areas. The experimental results demonstrate the robustness, efficiency and accuracy of the proposed algorithm. 1...|$|R
40|$|Image {{registration}} {{is the process}} by which we determine a transformation that provides the most accurate match between two images. The search for the matching transformation can be automated {{with the use of a}} suitable metric, but it can be very time-consuming and tedious. In this paper, we introduce a registration algorithm that combines active contour segmentation together with mutual information. Our approach starts with a segmentation procedure. It is formed by a novel geometric active contour, which incorporates edge knowledge, namely Edgeflow, into active contour model. Two edgemap images filled with closed contours are obtained. After ruling out mismatched curves, we use mutual information (MI) as a similarity measure to register two edgemap images. Experimental results are provided to illustrate the performance of the proposed registration algorithm using both synthetic and <b>multisensor</b> <b>images.</b> Quantitative error analysis is also provided and several images are shown for subjective evaluation...|$|R
40|$|This paper {{deals with}} the {{statistical}} segmentation of <b>multisensor</b> <b>images.</b> In a Bayesian context, the interest of using hidden Markov random fields, which allows one to take contextual information into account, has been well known for about 20 years. In other situations, the Bayesian framework is insufficient and one must {{make use of the}} theory of evidence. The aim of our work is to propose evidential models that can take into account contextual information via Markovian fields. We define a general evidential Markovian model and show that it is usable in practice. Different simulation results presented show the interest of evidential Markovian field model-based segmentation algorithms. Furthermore, an original variant of generalized mixture estimation, making possible the unsupervised evidential fusion in a Markovian context, is described. It is applied to the unsupervised segmentation of real radar and SPOT images showing the relevance of the proposed models and corresponding segmentation methods in real situations...|$|R
40|$|A dual {{infrared}} {{system to}} assist a driver in bad visibility conditions is studied. The problem of selecting the best multiresolution-based image fusion technique is addressed {{with reference to}} automotive scenarios. A new method for objective evaluation of <b>multisensor</b> <b>image</b> fusion strategies is presented for the optimal design of the fusion process. Multiresolution-based fusion methodologies are compared, and experimental results obtained from a prototype dual infrared camera system are shown and analyzed. Numerical results, {{in terms of the}} quality of the fused images and of the computational load, are presented and discussed. The effectiveness of the dual infrared system in urban and extraurban automotive scenarios is illustrated with a number of examples...|$|E
40|$|Automatic {{co-registration}} {{is a basic}} step in multi-sensor {{data fusion}} for remote sensing applications. The effectiveness of Mutual Information (MI) as a similarity measure for <b>multisensor</b> <b>image</b> registration has previously been reported for medical and remote sensing applications. In this paper, a new intensity-based approach built on local MI principles is presented. The approach decreases the complexity of higher dimension optimization by measuring local MI on welldistributed tie points. In addition, the reliability of registration is improved due to utilization of redundant observations of similarity. The performance of the proposed method for the registration of WorldView 2 satellite imagery with LiDAR elevation and intensity data has been experimentally evaluated and the results obtained are presented...|$|E
40|$|A digital cartographic <b>multisensor</b> <b>image</b> {{database}} of excellent geometry and improved resolution {{was created by}} registering SIR-B images to a rectified Landsat TM reference image and applying intensity-hue-saturation enhancement techniques. When evaluated against geodetic control, RMSE(XY) values of approximately + or - 20 m were noted for the composite SIR-B/TM images. The completeness of cartographic features extracted from the composite images exceeded those obtained from separate SIR-B and TM image data sets by approximately 10 and 25 percent, respectively, indicating that the composite images may prove suitable for planimetric mapping at a scale of 1 : 100, 000 or smaller. At present, the most effective method for extracting cartographic information involves digitizing features directly from the image processing display screen...|$|E
40|$|The {{increasing}} {{amount of}} remotely sensed imagery from multiple platforms requires efficient analysis techniques. The leading {{idea of the}} presented work is to automate the interpretation of multisensor and multitemporal remote sensing images {{by the use of}} common prior knowledge about landscape scenes. In addition the system can use specific map knowledge of a GIS, information about sensor projections and temporal changes of scene objects. The prior knowledge is represented explicitly by a semantic net. A common concept has been developed to distinguish between the semantics of objects and their visual appearance in the different sensors considering the physical principle of the sensor and the material and surface properties of the objects. In this presentation the basic structure of the system and its use for sensor fusion on different structural and functional levels is presented. Results are shown for the extraction of roads from <b>multisensor</b> <b>images.</b> The approach for a multitemporal im [...] ...|$|R
40|$|The multitemporal {{classification}} of remote sensing images is a challenging problem, {{in which the}} efficient combination of different sources of information (e. g., temporal, contextual, or multisensor) can improve the results. In this paper, we present a general framework based on kernel methods for the integration of heterogeneous sources of information. Using the theoretical principles in this framework, three main contributions are presented. First, a novel family of kernel-based methods for multitemporal {{classification of}} remote sensing images is presented. The second contribution {{is the development of}} nonlinear kernel classifiers for the well-known difference and ratioing change detection methods by formulating them in an adequate high-dimensional feature space. Finally, the presented methodology allows the integration of contextual information and <b>multisensor</b> <b>images</b> with different levels of nonlinear sophistication. The binary support vector (SV) classifier and the one-class SV domain description classifier are evaluated by using both linear and nonlinear kernel functions. Good performance on synthetic and real multitemporal classification scenarios illustrates the generalization of the framework and the capabilities of the proposed algorithms. Publicad...|$|R
40|$|The {{availability}} {{of data from}} sensors operating in several different wavelength regions had {{led to the development}} of new techniques and strategies for both data management and image analysis. Work is ongoing to develop computer techniques for analysis of integrated data sets. These techniques include coregistration of <b>multisensor</b> <b>images,</b> rectification of radar images in areas of topographic relief to ensure pixel to pixel registration with planimetric data sets, calibration of data so that signatures can be applied to remote areas, normalization of data acquired with disparate sensors and determination of extended spectral signatures of surface units. In addition, software is being developed to analyze coregistrated digital terrain and image data so that automated stratigraphic and structural analyses can be performed. These software procedures include: strike and dip determination, terrain profile generation, stratigraphic column generation, stratigraphic thickness measurements, structural cross-section generation, and creation of 3 -D block diagrams. These techniques were applied to coregistered LANDSAT 4 Thematic Mapper (TM), Thermal Infrared Multispectral Scanner (TIMS), and multipolarization synthetic aperture radar (SAR) data of the Wind River Basin in Wyoming...|$|R
