1411|882|Public
25|$|Since 1984 the airport's {{capacity}} {{had been}} limited to a <b>maximum</b> <b>throughput</b> of 25million passengers per annum (25 mppa) in accordance with recommendations made by the 1984 public inquiry and confirmed {{by the government of}} the day.|$|E
25|$|The primary {{objective}} of a belt press filter is to dewater process sludge {{and much of}} this dewatering occurs in the gravity drainage zone. The gravity drainage zone can achieve a 5 to 10 percent increase in solids concentration. The degree of dewatering in the gravity drainage zone is greatly dependent {{on the type of}} solids, the filter media and the sludge conditioning. The dewatering achieved in the gravity drainage zone is adversely affected if the sludge is poorly spread across the belt or the residence time is insufficient. Sludge conditioning is the addition of chemicals to promote flocculation of particles to form a thickened sludge and to promote dewatering. Dewatering can be promoted by the addition of surfactant and flocculation is achieved via the addition of high molecular weight polymer. Flocculation is improved with optimum polymer dosage, polymer dilution and mixing. The pH of the feed slurry must also be monitored and controlled as low pH decreases flocculation. It is important to find the optimum value for each conditioning parameter as too much polymer or mixing can {{have a negative impact on}} flocculation and greatly increase operating expenses. The effects of sludge conditioning are most apparent in the gravity drainage zone which can be easily replicated on a laboratory scale where the optimum conditioning strategy can be determined. For a belt press filter to be industrially viable it must be economically efficient and thus <b>maximum</b> <b>throughput</b> is desired. Without sufficient conditioning, the gravity drainage is generally the limiting process step, but with optimum dilution the limiting process step can be shifted to the compression zone.|$|E
2500|$|A {{section of}} the roadway was barricaded in 1991 after erosion {{severely}} damaged a [...] section. [...] <b>Maximum</b> <b>throughput</b> reached 3,200 cars a day. This decision led to a strong effort to overturn that decision and have the road rebuilt. A competing campaign, led by the Sierra Club of DC, advocated for replacing the road with a bicycle, hiking, or bridle path.|$|E
30|$|As stated earlier, the <b>maximum</b> {{achievable}} <b>throughput</b> of a topology {{is limited}} by the performance bottleneck at the links that originate from the gateway, as well as the number of traffic sources using these links. For the scenario in Figure 4, there are four links emanating from the GW. The <b>maximum</b> achievable <b>throughput</b> for links 15 - 2 and 15 - 5 is 8.192 Mbps each since there is only one source using each link. The <b>maximum</b> achievable <b>throughput</b> for link 15 - 31 is 24.576 Mbps since there are three sources using this link. The <b>maximum</b> achievable <b>throughput</b> for link 15 - 8 is limited to 24.748 Mbps since there are more than three sources using this link. Hence, the total <b>maximum</b> achievable <b>throughput</b> for this scenario is 65.7 Mbps.|$|R
3000|$|Comparison {{between these}} two figures {{indicates}} that considering any BLER {{and in particular the}} reference BLER of 1 %, higher channel bit rates require higher SNR) to offer any given BLER, resulting in less coverage. However, higher channel bit rates can provide higher <b>maximum</b> <b>throughputs.</b> For [...]...|$|R
5000|$|The {{availability}} of ADSL2+ (including ADSL2+ Annex M) broadband services. The 20CN allows services up to ADSL Max with a <b>maximum</b> download <b>throughput</b> of 8Mbit/s whereas ADSL2+ allows a <b>maximum</b> theoretical download <b>throughput</b> of 24Mbit/s.|$|R
2500|$|Though {{incompatible}} {{in every}} way with any other consumer electronics product, the 64DD's magnetic storage technology resembles the generic floppy disk, and the large and sturdy shell of the proprietary Zip disk for personal computers. [...] Though various prominent sources have mistakenly referred to the medium as being magneto-optical technology, Nintendo's own developer documentation refers to it in detail as being magnetic. [...] Complementing their proprietary and copy-protected cartridge strategy, the proprietary 64MB disk format was Nintendo's faster, more flexible, and copy-protected answer to the commodity Compact Disc format, which is cheaper to produce but is much slower, read-only, and easier to copy on personal computers. The most advanced CD technology delivered by the contemporaneous Sega Saturn and Sony PlayStation game consoles can hold at least 650megabytes (MB) of information with a peak 300kB/s throughput and more than 200ms seek speed. This compares to the Nintendo 64's cartridge's 4 to 64MB size and 5 to 50MB/s of low latency and instantaneous load times, and the 64DD's 64MB disk size and 1MB/s peak throughput with 75 ms average seek latency. The high seek latency and low <b>maximum</b> <b>throughput</b> of a 2x CD-ROM drive contribute to stuttering and to very long loading times throughout a gameplay session in many titles, {{in addition to a}} much higher production cost, testing cycle, and potential development time for all the potential extra content.|$|E
5000|$|Proven {{event driven}} {{architecture}} for <b>maximum</b> <b>throughput</b> (<1ms) ...|$|E
50|$|<b>Maximum</b> <b>throughput</b> is {{essentially}} synonymous to digital bandwidth capacity.|$|E
3000|$|... min are SINR values where <b>maximum</b> {{and minimum}} <b>throughputs</b> are reached, and β is a constant. Then, the <b>maximum</b> {{achievable}} <b>throughput</b> {{is computed by}} multiplying throughput per PRB {{by the number of}} assigned PRBs obtained in (4). In this work, T [...]...|$|R
5000|$|... 2×, with a <b>maximum</b> data <b>throughput</b> of 300 kB/s (double speed), 150KB/s (normal) ...|$|R
30|$|When W≥ 348, {{for each}} W, we {{increase}} the input offered load according to (0.9 +j 0.05)Γ(k) Mbps as j increases from 1 to 3 {{and then find}} the <b>maximum</b> stable <b>throughput</b> and the corresponding total delay. From the figure, we see that when W increases from 348 to 1900, the simulated <b>maximum</b> stable HP <b>throughput</b> decreases while the corresponding delay increases quickly. The simulation curve of the <b>maximum</b> stable <b>throughput</b> is slightly below the theoretical curve of the saturation throughput, confirming that the saturation throughput is a tight upper bound on the stable throughput.|$|R
5000|$|This {{algorithm}} {{is designed for}} <b>maximum</b> <b>throughput</b> in most scenarios.|$|E
5000|$|<b>Maximum</b> <b>throughput</b> {{scheduling}} (gives {{low grade}} of service due to starvation) ...|$|E
50|$|The <b>maximum</b> <b>throughput</b> {{is often}} an {{unreliable}} measurement of perceived bandwidth, for example the file transmission data rate in bits per seconds. As pointed out above, the achieved throughput is often lower than the <b>maximum</b> <b>throughput.</b> Also, the protocol overhead affects the perceived bandwidth. The throughput is not a well-defined metric {{when it comes to}} how to deal with protocol overhead. It is typically measured at a reference point below the network layer and above the physical layer. The most simple definition is the number of bits per second that are physically delivered. A typical example where this definition is practiced is an Ethernet network. In this case the <b>maximum</b> <b>throughput</b> is the gross bitrate or raw bitrate.|$|E
30|$|Choose {{the grid}} point with the <b>maximum</b> {{estimated}} <b>throughput</b> as the desired UAV position.|$|R
3000|$|... = 1 {{indicates}} that the algorithm has achieved the <b>maximum</b> achievable <b>throughput</b> for that particular topology.|$|R
3000|$|... -regular LDPC {{code decoder}} on Xilinx FPGA device. This partly {{parallel}} decoder supports a <b>maximum</b> symbol <b>throughput</b> of [...]...|$|R
50|$|For DOCSIS 3.0, the {{theoretical}} <b>maximum</b> <b>throughput</b> {{for the number}} of bonded channels are listed in the table below.|$|E
50|$|In {{computer}} networks, especially wireless networks, scheduling algorithms {{may suffer}} from scheduling starvation. An example is <b>maximum</b> <b>throughput</b> scheduling.|$|E
5000|$|Digital {{bandwidth}} bit/s measures: {{gross bit}} rate (signalling rate), net bit rate (information rate), channel capacity, and <b>maximum</b> <b>throughput</b> ...|$|E
3000|$|... * {{that yields}} the <b>maximum</b> {{achievable}} <b>throughput</b> under the two constraints, {{which can be}} obtained by 1 D exhaustive search.|$|R
3000|$|... opt] and the {{simulated}} <b>maximum</b> stable <b>throughput</b> is about 2.18 Mbps, {{which is far}} less than 4.3 Mbps corresponding to k=k [...]...|$|R
3000|$|... {{which offers}} them to {{differentiate}} {{with respect to}} x and to find the <b>maxima</b> for <b>throughput</b> and thus the optimal F/N ratio.|$|R
5000|$|In {{advanced}} {{packet radio}} systems, {{for example the}} HSDPA 3.5G cellular system, channel-dependent scheduling is used instead of FIFO queuing {{to take advantage of}} favourable channel conditions to make best use of available radio conditions. <b>Maximum</b> <b>throughput</b> scheduling may be tempting in this context, especially in simulations where throughput of various schemes are compared. However, <b>maximum</b> <b>throughput</b> scheduling is normally not desirable, and channel-dependent scheduling should be used with care, as we will see below.|$|E
5000|$|Transport layer {{flow control}} and {{congestion}} avoidance: For example, TCP slow start may cause a lower goodput than the <b>maximum</b> <b>throughput.</b>|$|E
50|$|The <b>maximum</b> <b>throughput</b> is 1/e frames per frame-time (reached when G = 1), {{which is}} {{approximately}} 0.368 frames per frame-time, or 36.8%.|$|E
50|$|The <b>maximum</b> {{achievable}} <b>throughput</b> (the channel capacity) {{is affected}} by the bandwidth in hertz and signal-to-noise ratio of the analog physical medium.|$|R
50|$|The 802.11n draft allows up to 4 x 4 : 4. Common {{configurations}} of 11n devices are 2 x 2 : 2; 2 x 3 : 2; and 3 x 2 : 2. All three configurations {{have the same}} <b>maximum</b> <b>throughputs</b> and features, and differ only {{in the amount of}} diversity the antenna systems provide. In addition, a fourth configuration, 3 x 3 : 3 is becoming common, which has a higher throughput, due to the additional data stream.|$|R
3000|$|..., {{is defined}} as the ratio of the {{throughput}} achieved by e-TICA 2, e-TICA, and TICA over their <b>maximum</b> achievable <b>throughputs,</b> respectively. T [...]...|$|R
50|$|If {{the system}} has no concept of end-users, then {{performance}} goal {{is likely to be}} based on a <b>maximum</b> <b>throughput</b> or transaction rate.|$|E
5000|$|On {{the other}} hand, max-min {{fairness}} provides lower average throughput than <b>maximum</b> <b>throughput</b> resource management, where {{the least expensive}} flows are assigned all capacity they can use, and no capacity might remain for the most expensive flows. In a wireless network, an expensive user is typically a mobile station at far distance from the base station, exposed to high signal attenuation. However, a <b>maximum</b> <b>throughput</b> policy would result in starvation of expensive flows, and may result in fewer [...] "happy customers".|$|E
50|$|A greedy source traffic {{generation}} simulation model, or a greedy traffic generator, is useful when simulating and analysing or measuring the <b>maximum</b> <b>throughput</b> of a network.|$|E
3000|$|Experiment 2 to {{illustrate}} {{the relationship between the}} <b>maximum</b> stable <b>throughput</b> and the saturation throughput: In the second experiment, we consider Poisson arrivals and demonstrate the <b>maximum</b> stable HP <b>throughput</b> and the mean total packet delay when the HP CW is statically configured. In this experiment, we set n= 50 and L= 1000 bytes. The optimal total HP attempt rate k [...]...|$|R
3000|$|... is to {{find the}} optimal number of {{allowable}} users and their transmission rates, which achieves the <b>maximum</b> system <b>throughput</b> while maintaining the fairness property.|$|R
30|$|In what follows, we {{analyze the}} <b>maximum</b> stable <b>throughput</b> of the {{cognitive}} cooperative access scheme and {{compare with that of}} the non-cooperative access scheme.|$|R
