76|0|Public
40|$|Efficient use {{of limited}} {{computational}} resources {{is essential to}} intelligence. Selecting computations optimally according to rational <b>metareasoning</b> would achieve this, but rational <b>metareasoning</b> is computationally intractable. Inspired by psychology and neuroscience, we propose the first learning algorithm for approximating the optimal selection of computations. We derive a general, sample-efficient reinforcement learning algorithm for learning to select computations from the insight {{that the value of}} computation lies between the myopic value of computation and the value of perfect information. We evaluate the performance of our method against two state-of-the-art methods for approximate <b>metareasoning</b> [...] the meta-greedy heuristic and the blinkered policy [...] on three increasingly difficult <b>metareasoning</b> problems: <b>metareasoning</b> about when to terminate computation, <b>metareasoning</b> about how to choose between multiple actions, and <b>metareasoning</b> about planning. Across all three domains, our method achieved near-optimal performance and significantly outperformed the meta-greedy heuristic. The blinkered policy performed on par with our method in <b>metareasoning</b> about decision-making, but it is not directly applicable to <b>metareasoning</b> about planning where our method outperformed both the meta-greedy heuristic and a generalization of the blinkered policy. Our results are a step towards building self-improving AI systems that can learn to make optimal use of their limited computational resources to efficiently solve complex problems in real-time...|$|E
40|$|In most {{real-world}} settings, due {{to limited}} time or other resources, an agent cannot perform all potentially useful deliberation and information gathering actions. This {{leads to the}} <b>metareasoning</b> problem of selecting such actions. Decision-theoretic methods for <b>metareasoning</b> have been studied in AI, but there are few theoretical results on the complexity of <b>metareasoning.</b> We derive hardness results for three settings which most real <b>metareasoning</b> systems would have to encompass as special cases. In the firs...|$|E
40|$|We {{can achieve}} {{significant}} {{gains in the}} value of computation by <b>metareasoning</b> about the nature or extent of base-level problem solving before executing a solution. However, resources that are irrevocably committed to <b>metareasoning</b> are not available for executing a solution. Thus, it is important to determine the portion of resources we wish to apply to <b>metareasoning</b> and control versus to the execution of a solution plan. Recent research on rational agency has highlighted the importance of limiting the consumption of resources by <b>metareasoning</b> machinery. We shall introduce the metareasoning-partition problem—the problem of ideally apportioning costly reasoning resources to planning a solution versus applying resource to executing a solution to a problem. We exercise prototypical metareasoning-partition models to probe the relationships between time allocated to <b>metareasoning</b> and to execution for different problem classes. Finally, we examine the value of <b>metareasoning</b> in the context of our functional analyses...|$|E
40|$|<b>Metareasoning</b> {{research}} often {{lays out}} high-level principles, {{which are then}} applied {{in the context of}} larger systems. While this approach has proven quite successful, it sometimes obscures how <b>metareasoning</b> {{can be seen as a}} crisp computational problem in its own right. This alternative view allows us to apply tools from the theory of algorithms and computational complexity to <b>metareasoning.</b> In this paper, we consider some known results on how variants of the <b>metareasoning</b> problem can be precisely formalized as computational problems, and shown to be computationally hard to solve to optimality. We discuss a variety of techniques for addressing these hardness results...|$|E
40|$|Abstract. This work {{contains}} both {{a theoretical}} development and a novel application of ideas introduced in [1] for using reflection in formal <b>metareasoning.</b> From the theoretical side, we extend the <b>metareasoning</b> principles proposed in [1] {{to cover the}} case of metatheorems about equational theories which are unrelated by the inclusion relation. From the practical side, we apply the newly introduced <b>metareasoning</b> principles to formalize and prove semantic relations between equational theories used in formal specification. ...|$|E
40|$|Representations of an AI agent’s mental {{states and}} {{processes}} {{are necessary to}} enable <b>metareasoning,</b> i. e. thinking about thinking. However, the formulation of suitable representations remains an outstanding AI research challenge, with no clear consensus on how to proceed. This paper outlines an approach involving the formulation of anthropomorphic self-models, where the representations that are used for <b>metareasoning</b> are based on formalizations of commonsense psychology. We describe two research activities that support this approach, the formalization of broad-coverage commonsense psychology theories and use of representations in the monitoring and control of objectlevel reasoning. We focus specifically on <b>metareasoning</b> about memory, but argue that anthropomorphic self-model...|$|E
40|$|This {{manifesto}} {{proposes a}} simple model of <b>metareasoning</b> that constitutes a general framework to organize {{research on this}} topic. The claim is that <b>metareasoning,</b> like the action-perception cycle of reasoning, is composed of the introspective monitoring of reasoning and the subsequent meta-level control of reasoning. This model holds for single agent and multiagent systems and is broad enough to include models of self. We offer the model as a short conversation piece to which the community can compare and contrast individual theories...|$|E
40|$|Abstract. This paper {{seeks to}} extend notions of {{monitoring}} in <b>metareasoning</b> to include symbolic and linguistic expressions of self {{for purposes of}} communication and learning. The essay is intended to present a synthesis in plain language that challenges the agent community interested in <b>metareasoning</b> to consider {{what it means for}} a system to understand itself in any meaningful way. The basic claim is that if an agent truly knows what it is doing and why, it should be able explain itself to others using natural language or some other interactive mechanism with humans. To perform self-explanation it must be able to understand itself, and for this to occur it must monitor its own <b>metareasoning</b> and have an episodic memory that forms the basis of self. A further challenge is to incorporate self-explanation into an evaluation function that complements criteria based solely on action performance. ...|$|E
40|$|A <b>metareasoning</b> problem {{involves}} three parts: 1) a set {{of concrete}} problem domains; 2) reasoners to reason about the problems; and, 3) metareasoners to reason about the reasoners. We believe that the <b>metareasoning</b> community would benefit from agreeing {{on the first two}} problems. To support this kind of collaboration, we offer an open source 3 D simulator containing everyday, commonsense problems that take place in kitchens. This paper presents several arguments for using a simulator to solve commonsense problems. The paper concludes by describing future work in simulator-based unified generative benchmarks for AI...|$|E
40|$|Abstract—We {{examine the}} use of teleological <b>metareasoning</b> for self-adaptation in game-playing {{software}} agents. The goal of our work is to develop an interactive {{environment in which the}} game designer generates requirements for a new version of a game, and the legacy software agents from previous versions of the game adapt themselves to the new game requirements. We are develop-ing and testing our <b>metareasoning</b> technique for adapting game-playing agents in Freeciv, a mature program in the domain of turn-based, multi-player strategy games (www. freeciv. wikia. com). In this paper, we first present an analysis of adaptations to FreeCiv, next describe our general approach, and then describe a specific adaptation scenario. I...|$|E
40|$|To address {{computationally}} challenging problems, ingen-ious researchers often {{develop a}} broad variety of heuristics {{with which to}} reason and learn. The integration of such good ideas into a robust, flexible environment presents a va-riety of difficulties, however. This paper describes how <b>metareasoning</b> that relies upon expertise, bounded rational-ity, and self-awareness supports a self-adaptive architecture for learning and problem solving. The resultant programs develop considerable skill on problems in three very differ-ent domains. They also {{provide insight into the}} strengths and pitfalls of <b>metareasoning.</b> Anthropologists tell us that an expert is one who performs a task better and faster {{than the rest of us}} (D'Andrade, 1991). A programmed expert for challenging problems...|$|E
40|$|What role does <b>metareasoning</b> play in {{models of}} bounded ra-tionality? We examine the various {{existing}} computational ap-proaches to bounded rationality and divide them into three classes. Only {{one of these}} classes significantly relies on a <b>metareasoning</b> component. We explore the characteristics of this class of models and argue that it offers desirable prop-erties. In fact, many of the effective approaches to bounded rationality {{that have been developed}} since the early 1980 ’s match this particular paradigm. We conclude with some open research problems and challenges. Computational models of bounded rationality In the pursuit of building decision-making machines, arti-ficial intelligence researchers often turn to theories of “ra-tionality ” in decision theory and economics. Rationalit...|$|E
40|$|Recent {{advances}} in <b>metareasoning</b> for search has shown its usefulness in improving numerous search algorithms. This paper applies rational <b>metareasoning</b> to IDA* when several admissible heuristics are available. The obvious basic approach {{of taking the}} maximum of the heuristics is improved upon by lazy evaluation of the heuristics, resulting in a variant known as Lazy IDA*. We introduce a rational version of lazy IDA* that decides whether to compute the more expensive heuristics or to bypass it, based on a myopic expected regret estimate. Empirical evaluation in several domains supports the theoretical results, and shows that rational lazy IDA* is a state-of-the-art heuristic combination method. Comment: 7 pages, 6 tables, 20 reference...|$|E
40|$|The {{conventional}} model for online planning under uncertainty assumes that an agent can stop and plan without incurring {{costs for the}} time spent planning. However, planning time is not free in most real-world settings. For example, an autonomous drone is subject to nature’s forces, like gravity, even while it thinks, and must either {{pay a price for}} counteract-ing these forces to stay in place, or grapple with the state change caused by acquiescing to them. Pol-icy optimization in these settings requires metarea-soning—a process that trades off the cost of plan-ning and the potential policy improvement that can be achieved. We formalize and analyze the metar-easoning problem for Markov Decision Processes (MDPs). Our work subsumes previously studied special cases of <b>metareasoning</b> and shows that in the general case, <b>metareasoning</b> is at most polyno-mially harder than solving MDPs with any given algorithm that disregards the cost of thinking. For reasons we discuss, optimal general metareason-ing turns out to be impractical, motivating approx-imations. We present approximate <b>metareasoning</b> procedures which rely on special properties of the BRTDP planning algorithm and explore the effec-tiveness of our methods on a variety of problems. ...|$|E
40|$|In {{order to}} achieve optimal results, an agent's way of {{decision}} making might need to change according to the circumstances. One of the aspects an agent can adapt {{is the way it}} processes external events. Therewith it controls to what extend it is being influenced by external factors. We argue that influence control is a form of <b>metareasoning.</b> In this paper, we propose a model for <b>metareasoning</b> that allows the agent to select and prioritize heuristics for event processing. The model includes a performance measure based on goal achievement, a selection mechanism to select desired attitude and a control mechanism to adapt its attitude. We describe how to specify these components and we discuss the agent's performance in a scenario involving coordination. © 2009 IEEE...|$|E
40|$|Cognition may {{reasonably}} be distinguished into world-estimation and planning tasks. Our focus {{in this work}} is the world estimation task, i. e., the task of establishing and updating beliefs about the world. One aspect of being intelligent in this task is noticing one’s mistakes and correcting them. An intelligent system may be realized by dividing its operation into a base-level reasoning system and a <b>metareasoning</b> system. The base-level system is responsible for processing inputs from the world and recording its conclusions in a belief state. The <b>metareasoning</b> system moni-tors the base-level system {{so that it can}} detect symptoms of errors in the belief state and attempt belief revisions. We describe and evaluate such a system in this report. The base-level system is an abductive reasoner responsible for finding explanations for inputs given as reports of putative observations. When no plausible, consistent explanation is forthcoming for some reports, we say these unexplainable reports are anomalous. The presence of anomalies is a symptom of errors in the belief state since, in the usual case, all reports should be explainable. However, sometimes the anomalous reports are not reports of observations but rather false or noisy reports. An abduc-tive <b>metareasoning</b> system attempts to explain anomalies as errors of various kinds and makes the appropriate revisions. If a sufficiently plausible explanation is not found, an anomalous report is at-tributed to noise. We evaluate this two-level system in a pair of object tracking tasks, one simulated and one based on aerial surveillance. Both tasks are challenging due to limited sensor capabilities and a very high level of noise. The proposed two-level system realizes significantly more accurate belief states and better noise detection than a system that lacks abductive <b>metareasoning.</b> 1...|$|E
40|$|We {{introduce}} a methodology for concept learning from texts that relies upon secondorder reasoning about statements {{expressed in a}} (first-order) terminological representation language. This <b>metareasoning</b> approach allows for quality-based evaluation and selection of alternative concept hypotheses. Appeared in: S. Wermter, E. Riloff, G. Scheler (Eds.), Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing, Berlin etc: Springer, 1996, pp. 453 - 468, (LNAI 1040) Connectionist, 23 0 Language 92 - 9295 1040) Learning from Texts - A Terminological <b>Metareasoning</b> Perspective Udo Hahn, Manfred Klenner & Klemens Schnattinger Freiburg University Computational Linguistics Group F Europaplatz 1, D- 79085 Freiburg, Germany fhahn,klenner,schnattingerg@coling. uni-freiburg. de Abstract We {{introduce a}} methodology for concept learning from texts that relies upon second-order reasoning about statements expressed in a (first-order) terminological representation langua [...] ...|$|E
40|$|Abstract—This paper takes a metareasoning-based {{approach}} to classification learning, framing the learning problem {{as one of}} self-diagnosis and self-adaptation. Artificial Intelligence (AI) research on <b>metareasoning</b> for agent self-adaptation has generally focused on modifying the agent’s reasoning processes. In this paper, we describe the use of <b>metareasoning</b> for retrospective adaptation of the agent’s domain knowledge. In particular, we consider the use of meta-knowledge for structural credit assignment in a classification hierarchy when the classifier makes an incorrect prediction. We present a scheme in which the semantics of the intermediate abstractions in the classification hierarchy are grounded in percepts in the world, and show that this scheme enables self-diagnosis and self-repair of knowledge contents at intermediate nodes in the hierarchy. We also provide an empirical evaluation of the technique. I...|$|E
40|$|Abstract—We see {{the field}} of <b>metareasoning</b> to be the answer to many large {{organizational}} problems encountered when putting together an understandable cognitive architecture, capable of commonsense reasoning. In this paper we review the EM 1 implementation of the Emotion Machine critic-selector architecture, as well as explain the current progress we have made in redesigning this first version implementation. For this purpose of redesign and large-scale implementation, we have written a novel programming language, Funk 2, that focuses on efficient <b>metareasoning</b> and procedural reflection, the keystones of the critic-selector architecture. We present an argument for why the Funk 2 programming language lends itself to easing the burden on programmers that prefer to not be restricted to strictly declarative programming paradigms by allowing the learning of critic and selector activation strengths by credi...|$|E
40|$|ECCBR), {{is held in}} Alessandria, Italy, from July 19 through July 22, 2010. The Workshop Program enables dissemination, demonstration, and {{discussion}} of research in progress, facilitating interaction, feedback, and collaboration {{at the forefront of}} CBR research and development. Five workshops are included in this year’s program. Case-Based Reasoning for Computer Games: This is the third in a series of highly successful workshops focusing on CBR in computer gaming environments. The six papers included in this volume present work in meta-reasoning for adaptive behavior, case extraction from game replay repositories, automated feature selection, reinforcement learning, generic intelligent gaming frameworks, and domain-independent learning. Provenance-Aware CBR: Applications to Reasoning, <b>Metareasoning,</b> Maintenance and Explanation: New this year is an exploration of case provenance and its roles in trust and reputation, reasoning and <b>metareasoning,</b> and explanation. Provenance encompasses the sources of cases, case acquisition contexts...|$|E
40|$|Abstract. In complex domains, it {{is often}} {{necessary}} to determine which reasoning method {{would be the most}} appropriate for each task, and a combination of different methods has often shown the best results. We examine how two complementary reasoning methods, case-based reasoning and Bayesian networks, can be combined using <b>metareasoning</b> to form a more robust and better-performing system...|$|E
40|$|One of {{the most}} {{important}} elements of agent performance in multi-agent systems is the ability for an agent to predict how other agents will behave. In many domains there are often different modeling systems already available that one could use to make behavior predictions, but the choice of the best one for a particular domain and a specific set of agents is often unclear. To find the best available prediction, we would like to know which model would perform best in each possible world state of the domain. However, when we have limited resources and each prediction query has a cost we may need to decide which queries to pursue using only estimates of their benefit and cost: <b>metareasoning.</b> To estimate the benefit of the computation, a metareasoner needs a robust measurement of performance quality. In this work we present a <b>metareasoning</b> system that relies on a prediction performance measurement, and we propose a novel model performance measurement that fulfils this need: Weighted Prediction Divergence...|$|E
40|$|Philosophers and {{cognitive}} scientists of many persuasions have long wondered what {{is unique to}} human intelligence. Although a number of ideas have been proposed, a common differentiator {{appears to be a}} pervasive capacity for thinking about ourselves in terms of who we are, how others see us, and in terms of where we have been and where we want to go. As humans, we continually think about ourselves and our strengths and weaknesses in order to manage both the private and public worlds within which we exist. But the Artificial Intelligence community has not only wondered about these phenomena; it has attempted to implement actual machines that mimic, simulate, and perhaps even replicate this same type of reasoning called <b>metareasoning.</b> The term is an overloaded one, and no single consensus exists as to its definition. Some have described <b>metareasoning</b> computationally in terms of specific programs and algorithms; whereas others have analyzed metacognition and focused on data from human experience and behavior. Indeed Ann Brown (1987) described research into metacognition as a "many-headed monster of obscur...|$|E
40|$|To address {{computationally}} challenging problems, ingenious researchers often {{develop a}} broad variety of heuristics {{with which to}} reason and learn. The integration of such good ideas into a robust, flexible environment presents a variety of difficulties, however. This paper describes how <b>metareasoning</b> that relies upon expertise, bounded rationality, and self-awareness supports a self-adaptive architecture for learning and problem solving. The resultant programs develop considerable skill on problems in three very different domains. They also {{provide insight into the}} strengths and pitfalls of <b>metareasoning.</b> Anthropologists tell us that an expert is one who performs a task better and faster {{than the rest of us}} (D'Andrade, 1991). A programmed expert for challenging problems, however, is unlikely to be given every detail of its reasoning process in advance — rather, it is expected to learn its expertise on its own, to be self-adaptive. Ideally, expertise develops quickly. To accelerate its performance during both learning and testing, a self-adaptive system is likely to be subjected to bounded rationality, that is, to have limits placed on its space and time resources. As a result, computer scientists often construct self-aware programs that observe their own behavior and monitor their own reasoning to improve their performance, as in Figure 1 (Cox and Raja, 2007). The perils of such <b>metareasoning</b> become quickly evident in any ambitious application, however. 1 We believe that easy problems should be solved quickly, and that hard problems should take a bit longer. Rather than rely on thousands of learning experiences, the learners we describe develop considerable expertise after experience with relatively few problems. This paper recounts the challenges posed to one learning and problem-solving ar-Figure 1 : FORR addresses a problem. (Cox and Raja, 2007) ...|$|E
40|$|Metaresoning {{is again}} under {{focus in the}} AI community. Here in this paper, a new {{classification}} for types of <b>metareasoning</b> has been proposed. In recent years, only {{the ones that are}} here named as pre-metareasoning and para-metareasoning have been studied. The first one is for predicting the best computation path for having better performance programs. The second, mostly known as interruptible anytime algorithm, is to limit the computation time externally when the approximate answer is better than nothing. One other type of <b>metareasoning</b> (called here as post-metareasoning) is discussed in a case study. It has been shown as an effective method for reducing error in self-localization. Based on the measurements in the case study, the post-metareasoning argued as useful when the effectiveness of reasoning methods are not known by the designer or when the system learns the reasoning methods and should evaluate and use the best one automatically. As the post-metareasoning is {{based on the results of}} different isolated reasoning methods, it is possible to be handled in parallel. The speed of post-metareasoning in such a case is determined by the time required by the slowest reasoning method and the post-metaresoning itself...|$|E
40|$|<b>Metareasoning</b> {{is about}} reasoning"|in its {{broadest}} sense, any computational {{process that is}} concerned with the operation of some other computational process within the same entity (see also METACOGNITION). The term relies on a conceptual distinction between object-level deliberation about external entities|for example, considering the merits of various opening moves one might make in a game of chess|and metalevel deliberation about internal entities (computations, beliefs, and so on) |for example, deciding that it is not worth spending much time deliberating about which opening move to make. Genesereth and Nilsson (1987, Ch. ??) provide formal denitions along these lines. Smith (1986) makes a further distinction between introspection about purely internal entities and re ection relating internal and external entities. In this view, a proposition such as, I open the window I will know if the birds are singing " is re ective, since it relates a physical action to a future state of knowledge (see also MODAL LOGIC). The capacity for <b>metareasoning</b> serves several purposes in an intelligent agent. First, it allows the agent to control its object-level deliberations|to decide which ones to under-take and when to stop deliberating and act. This is essential given the pervasive problem 1 of COMPUTATIONAL COMPLEXITY in decision making and the consequent need fo...|$|E
40|$|Ahybrid {{knowledge-based}} architecture integrates different problem solvers for {{the same}} (sub) task through a control unit operating at a meta-level, the metareasoner, which coordi-nates the use of, and the communication between, the different problem solvers. A problem solver is defined to be an association between a knowledge intensive (sub) task, an inference mechanism and a knowledge domain view operated by the inference mechanism in order to perform the (sub) task. Important issues in a hybrid system are the <b>metareasoning</b> and learning aspects. <b>Metareasoning</b> encompasses the functions performed by the metareasoner, while learning reflects {{the ability of the}} system to evolve {{on the basis of its}} experiences in problem solving. Learning occurs at different levels, learning at the meta-level and learning at the level of the specific problem solvers. Meta-level learning reflects the ability of the metareasoner to improve the overall performance of the hybrid system by improving the efficiency of meta-level tasks. Meta-level tasks include the initial planning of problem solving strategies and the dynamic adaptation of chosen strategies depending on new events occurring dynamically during problem solving. In this paper we concentrate on metareason-ing and meta-level learning in the context of a hybrid architecture. The theoretical arguments presented in the paper are demonstrated in practice through a hybrid knowledge-based prototype system for the domain of breast cancer histopathology. © 1998 Elsevier Scienc...|$|E
40|$|We {{introduce}} a methodology for knowledge acquisition and concept learning from texts that relies upon a quality-based model of terminological reasoning. Concept hypotheses {{which have been}} derived {{in the course of}} the text understanding process are assigned specific "quality labels" (indicating their significance, reliability, strength). Quality assessment of these hypotheses accounts for conceptual criteria referring to their given knowledge base context as well as linguistic indicators (grammatical constructions, discourse patterns), which led to their generation. We advocate a <b>metareasoning</b> approach which allows for the quality-based evaluation and a bootstrapping-style selection of alternative concept hypotheses as text understanding incrementally proceeds...|$|E
40|$|In {{this paper}} we {{describe}} {{a system that}} tracks vehicles from overhead video using a self-adaptive bank of Kalman filters. The system utilizes a bank of base-level reasoners that promote their own hypotheses about vehicle models and make predictions about future vehicle motion. By evaluating how well the base reasoners predictions are realized by the vehicles, <b>metareasoning</b> allows leading base reasoners to be selected and modified {{in the course of}} the passage of a vehicle through the video. It is shown how multiple hypothesis tracking within a self-adaptive framework produces superior object tracking and prediction in the face of noisy data...|$|E
40|$|Abstract. In agent systems, meta-level {{reasoning}} {{is commonly used}} in enforcing rationality {{in the choice of}} goals and actions performed by an agent, ensuring that an agent behaves as effectively and efficiently as possible. Through <b>metareasoning</b> an agent is able to explicitly consider goals before committing to them, and consider courses of action before executing plans. In this paper, we argue that although seldom considered, a flexible {{meta-level reasoning}} component is a valuable addition to any agent architecture. We describe such a component for use in BDI architectures, underpinned by a model of motivation and a motivationbased description language, and demonstrate its effectiveness empirically. ...|$|E
40|$|We {{examine the}} problem of self-adaptation in game-playing agents as the game {{requirements}} evolve incrementally. The goal of our current work is to develop an interactive envi-ronment in which the game designer generates requirements for {{a new version of}} a game, and the legacy software agents from previous versions of the game adapt themselves to the new game requirements. We are developing and testing our <b>metareasoning</b> technique for adapting a game-playing agents in Freeciv, a mature program in the domain of turn-based, multi-player strategy games. In this paper, we first present an analysis of adaptations to FreeCiv, next describe our general approach, and then describe a specific adaptation scenario...|$|E
40|$|Goal Driven Learning (GDL) {{focuses on}} systems that {{determine}} by themselves {{what has to}} be learnt and how to learn it. Typically GDL systems use meta-reasoning capabilities over a base reasoner, identifying learning goals and devising strategies. In this paper we present a novel GDL technique to deal with complex AI systems where the <b>metareasoning</b> module has to analyze the reasoning trace of multiple components with potentially different learning paradigms. Our approach works by distributing the generation of learning strategies among the different modules instead of centralizing it in the meta-reasoner. We implemented our technique in the GILA system, that works in the airspace task orders domain, showing an increase in performance. ...|$|E
40|$|Recent {{years have}} seen a {{resurgence}} {{of interest in the}} use of metacognition in intelligent systems. This article is part of a small section meant to give interested researchers an overview and sampling of the kinds of work currently being pursued in this broad area. The current article offers a review of recent research in two main topic areas: the monitoring and control of reasoning (<b>metareasoning)</b> and the monitoring and control of learning (metalearning). What Is Metacognition in Computation? Rosie (the robot maid from the TV show The Jetsons) spends her days cooking, cleaning, ironing, and attending to the usual household tasks of late 21 st century life. Because of a bu...|$|E
40|$|We {{introduce}} a methodology for automated knowledge acquisition {{and learning from}} texts that relies upon a quality-based model of terminological reasoning. Concept hypotheses which have been derived {{in the course of}} the text understanding process are assigned specific "quality labels" (indicating their significance, reliability, strength). Quality assessment of these hypotheses accounts for conceptual criteria referring to their current knowledge base context as well as linguistic indicators (grammatical constructions, discourse patterns), which led to their generation. We advocate a <b>metareasoning</b> approach which allows for the quality-based evaluation and a bootstrapping-style selection of alternative concept hypotheses as text understanding incrementally proceeds. We also provide a preliminary empirical evaluation, with focus on the learning rates and the learning accuracy that were achieved using this approach...|$|E
40|$|Reasoning with {{incomplete}} or potentially incorrect {{knowledge is}} an important challenge for Artificial Intelligence. This paper presents a system that re-vises its knowledge about dynamic systems by constructing and evaluating explanations. Concep-tual knowledge is represented using compositional model fragments, which are used to explain phe-nomena via model formulation. <b>Metareasoning</b> is used to (1) score the resulting explanations numeri-cally along several dimensions and (2) evaluate preferred explanations for global consistency. Global inconsistencies cause the system to favor al-ternative explanations and thereby change its be-liefs. We simulate the belief changes of several students during clinical interviews about how the seasons change. We show that qualitative models reasonably represent student knowledge, and that our system revises its beliefs in a fashion similar to the students. ...|$|E
40|$|We {{introduce}} a concept learning methodology for text understanding systems {{that is based}} on terminological knowledge representation and reasoning. Quality-based <b>metareasoning</b> techniques allow for an incremental evaluation and selection of concept hypotheses. This methodology is particularly aimed at real-world text understanding environments where lexical/conceptual resources cannot be completely specified prior to text analysis and, as a consequence of partial understanding, competing concept hypotheses with different levels of credibility have to be managed. Appeared in: MLIA' 96 - Working Notes of the AAAI- 96 Spring Symposium on 'Machine Learning in Information Access', Stanford University, Stanford, Calif., March 25 - 27, 1996, American Association for Artificial Intelligence, pp. 104 - 106 (AAAI- 96 Spring Symposium Series). Automatic Concept Acquisition from Real-World Texts Udo Hahn, Manfred Klenner & Klemens Schnattinger Freiburg University, L F Computational Linguistics Group [...] ...|$|E
