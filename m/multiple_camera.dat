534|1805|Public
5|$|In {{the late}} 1970s, Kerry Packer {{established}} the rival World Series Cricket (WSC) competition. It introduced {{many of the}} now commonplace features of One Day International cricket, including coloured uniforms, matches played at night under floodlights with a white ball and dark sight screens, and, for television broadcasts, <b>multiple</b> <b>camera</b> angles, effects microphones to capture sounds from {{the players on the}} pitch, and on-screen graphics. The first of the matches with coloured uniforms was the WSC Australians in wattle gold versus WSC West Indians in coral pink, played at VFL Park in Melbourne on 17 January 1979. The success and popularity of the domestic one-day competitions in England {{and other parts of the}} world, as well as the early One-Day Internationals, prompted the ICC to consider organising a Cricket World Cup.|$|E
5|$|With a $45 million {{production}} budget, filming {{began on}} 12 November 2010 in Cape Town and took approximately 13 weeks, with second unit photography occurring over seven weeks. Filming locations included Johannesburg and Cape Town Film Studios (Dredd {{was the first}} project filmed at the studio). The project involved a majority of Cape Town crew members and about 40 imported crew. The producers chose to film in South Africa because of the lowered cost of employing cast and crew compared to locations in Europe and North America, and government incentives that offered to rebate up to 25% of the production costs. The film was shot digitally and primarily in 3D using RED MX, SI2K and Phantom Flex high-speed cameras. <b>Multiple</b> <b>camera</b> rigs were used. Some 2D elements were converted to 3D in post-production.|$|E
5|$|Jarvis {{planned to}} produce sequels, but the North American video game crash of 1983 halted most video game {{production}} {{for a few}} years. Prior to the full effects of the crash, Vid Kidz developed an official sequel, Blaster in 1983. The game {{is set in the}} same universe and takes place in 2085 in a world overrun by Robotrons. Williams considered creating a proper sequel in the mid-1980s as well as a movie adaptation. The company released a sequel with 3D graphics titled Robotron X in 1996 for the Sony PlayStation and personal computers. It was ported two years later to the Nintendo 64 as Robotron 64. In addition to the graphical update, the game includes new audio and <b>multiple</b> <b>camera</b> angles. Though the game features similar gameplay as the original, it was not as well received. Authors Andrew Rollings and Ernest Adams considered the moving camera in the 3D environment a negative update. They felt the original format—an overhead perspective of a single screen—presented the player with all the necessary information and relied on the player's skill. The moving camera angle, however, obscured areas of the playing field and could result in the player being shot by an enemy that suddenly appeared. Vince echoed similar statements, stating that the gameplay suffered from the loss of important aspects from the original. Rollings and Adams, however, attribute the fad of classic video game remakes in the late 1990s in part to Robotron Xs release.|$|E
40|$|We {{will show}} methods for {{interpolation}} of viewpoint from <b>multiple</b> <b>cameras</b> based on projective geometry. Projective relationship of <b>multiple</b> <b>cameras</b> {{can be obtained}} from weak calibration information, that can easily be corrected from the multiple view images. Such projective geometry provides sufficient information to reconstruct the 3 D shape of the object with scale and projective transformation ambiguity. Since such ambiguity does not affect to 2 D correspondence relationship between the multiple images, we can generate new view point images from <b>multiple</b> <b>cameras</b> by interpolating viewpoint according to the 2 D correspondence relationship. We will show following approaches for interpolating the view point of <b>multiple</b> <b>cameras</b> : 1) View interpolation from 3 D shape reconstruction with projective ambiguity in Projective Grid Space (PGS), 2) View interpolation of actual soccer scene taken with <b>multiple</b> <b>cameras</b> based on projective geometry...|$|R
30|$|In {{order to}} extend the area, <b>multiple</b> <b>cameras</b> are needed. A common subject can be tracked through <b>multiple</b> <b>cameras,</b> in dynamic scenes and can be {{analyzed}} without any issues [7]. Techniques like histograms and spatial relationships [7] have been highly successful in doing such analysis.|$|R
5000|$|Using <b>Multiple</b> <b>Cameras</b> to Image a Package. (United States Patent 4872052) ...|$|R
25|$|Attendance at {{the concert}} {{was free to}} the public, and HBO also {{broadcast}} the concert for free on cable television services on their usually subscription-only network. The Associated Press called it a “near-flawless production with <b>multiple</b> <b>camera</b> angles and a majestic backdrop in the giant statue of Abraham Lincoln”. The concert was broadcast around the world. In Finland it was broadcast live and free to air by YLE TV1. In the Netherlands it was broadcast live and free by Nederland 3. It was broadcast in Portugal by RTP 2 on January 24, 2009. In Sweden it was broadcast by TV8. HBO released the concert {{as part of a}} 2 DVD set (including the Inaugural Address and Neighborhood Ball) in April 2010. Also, it was shown for the crowd at Obama's inauguration two days later on megascreens in the hours before the ceremony began.|$|E
25|$|Markerless gait capture systems utilize {{one or more}} color cameras or 2.5D depth sensors (i.e. Kinect) to {{directly}} calculate the body joint positions from a sequence of images. The markerless system allows non-invasive human gait analysis in a natural environment without any marker attachment. Eliminating markers can expand the applicability of human gait measurement and analysis techniques, considerably reduce the preparation time, and enable efficient and accurate motion assessment {{in all kinds of}} applications. Currently, the main markerless system is the video-based motion capture with monocular camera or <b>multiple</b> <b>camera</b> studio. Nowadays, the depth sensor-based gait analysis for clinical applications becomes more and more popular. Since depth sensors can measure the depth information and provide a 2.5D depth image, they have effectively simplified the task of foreground/background subtraction and significantly reduced pose ambiguities in monocular human pose estimation.|$|E
500|$|ILM filmed starships using {{motion control}} for timed and {{computer-assisted}} model movement. The ship models required <b>multiple</b> <b>camera</b> passes because {{different parts of}} the ship and its lights were filmed at different exposure levels. The Excelsior required eight passes to supplement the main [...] "beauty pass", the Enterprise six. ILM could have combined passes with multiple exposures, but not without risk; [...] "If anything got out of synch, or somehow we dropped a frame, we would have to reshoot—and then you're stuck. You've ruined two pieces, two elements," [...] Farrar said.|$|E
30|$|Designating an {{effective}} layout for <b>multiple</b> <b>cameras</b> for gait recognition is straightforward using the directional performance characteristics. Personal authentication systems at building entrances, for example, can use <b>multiple</b> <b>cameras</b> installed {{at fixed positions}} to increase their authentication accuracy. Similarly, moving cameras such as drones can obtain gait features from multiple viewpoints as they move around.|$|R
40|$|Member, IEEE Abstract—Visual {{surveillance}} using <b>multiple</b> <b>cameras</b> {{has attracted}} increasing interest in recent years. Correspondence between <b>multiple</b> <b>cameras</b> {{is one of}} the most important and basic problems which visual surveillance using <b>multiple</b> <b>cameras</b> brings. In this paper, we propose a simple and robust method, based on principal axes of people, to match people across <b>multiple</b> <b>cameras.</b> The correspondence likelihood reflecting the similarity of pairs of principal axes of people is constructed according to the relationship between ”ground-points ” of people detected in each camera view and the intersections of principal axes detected in different camera views and transformed to the same view. Our method has the following desirable properties: 1) Camera calibration is not needed. 2) Accurate motion detection and segmentation are less critical due to the robustness of the principal axis-based feature to noise. 3) Based on the fused data derived from correspondence results, positions of people in each camera view can be accurately located even when the people are partially occluded in all views. The experimental results on several real video sequences from outdoor environments have demonstrated the effectiveness, efficiency, and robustness of our method. Index Terms—Correspondence between <b>multiple</b> <b>cameras,</b> principal axes, people tracking. ...|$|R
5000|$|Support for <b>multiple</b> <b>cameras</b> on the device, {{including}} a front-facing camera, if available.|$|R
500|$|The {{production}} spent $4 {{million to}} restore Dealey Plaza to 1963 conditions. Stone utilized {{a variety of}} film stocks. Richardson said, [...] "It depends {{whether you want to}} shoot in 35 or 16 or Super 8. In many cases the lighting has to be different." [...] For certain shots in the film, Stone employed <b>multiple</b> <b>camera</b> crews shooting at once, using five cameras {{at the same time in}} different formats. Richardson said of Stone's style of direction, [...] "Oliver disdains convention, he tries to force you into things that are not classic. There's this constant need to stretch." [...] This forced the cinematographer to use lighting in diverse positions and rely very little on classic lighting modes. The shoot lasted 79 days with filming finished five months before the release date.|$|E
500|$|Scott {{is known}} for his skill at filming with <b>multiple</b> <b>camera</b> set-ups and Body of Lies used a minimum of three simultaneously. Witt {{explained}} the benefits, [...] "Actors like multiple cameras because they’re always on-camera, so they’re always in character and not wasting time off-camera." [...] One shot of DiCaprio alone in the desert, for example, still used three cameras: one hand-held above the actor, a second capturing a three-quarter back profile, and the third photographing a close-up through the first cameraman's legs. Richard Cronn, the gaffer, attributed the success of this difficult approach to Scott's filmmaking intelligence, [...] "Ridley will stand at the monitors and tell you what's he's looking for – he'll look at four monitors and say, 'I'm cutting from this to this to this.' He knows exactly how he will cut it." ...|$|E
500|$|Several {{scenes in}} Inside Man {{required}} multiple-camera setups, {{which meant that}} Libatique had to instruct and work with <b>multiple</b> <b>camera</b> operators. Lee {{wanted to create a}} visual distinction between the characters Russell (Owen) and Frazier (Washington), while incorporating visual metaphors. Russell's scenes, in which he masterminds the bank heist, were shot with a Steadicam to suggest that the character is in control. Frazier's scenes, in which he is tasked with handling the hostage situation, were filmed with multiple hand-held cameras to display the character's confusion. Libatique explained, [...] "I said, 'We want {{to create a sense of}} control and largely centered frames with Clive’s character, and we want to have movement with Denzel’s.' Having three operators on the same character, I’d watch all three. In a handheld shot, a long lens has a little bit of movement and a wider lens is inherently smoother. I would actually talk to the operator and tell him not to be so steady. It was the first time I’d worked with so many operators where I wasn’t one myself." [...] Telephone conversations between Russell and Frazier were shot using two cameras simultaneously filming the actors performing on two different sets of a soundstage at Steiner Studios. [...] Steadicam operator Stephen Consentino estimated that 80% of the film was shot with hand-held cameras or a Steadicam. A total of seven cameras were used to film the scene where the hostages are finally released. A Technocrane was used for a crane shot that would cover the following moment, in which the hostages are placed in buses.|$|E
30|$|Redundant cameras {{increase}} {{not only}} processing time and algorithmic complexity, {{but also the}} installation cost. In contrast, a lack of cameras may cause some blind spots, that reduce {{the reliability of the}} surveillance system. Moreover, calibration is more complex when <b>multiple</b> <b>cameras</b> are employed and object matching among <b>multiple</b> <b>cameras</b> involves finding the correspondences between the objects in different images.|$|R
40|$|Abstract- In this work, we {{solve the}} pose {{estimation}} problem for robot motion by placing <b>multiple</b> <b>cameras</b> on the robot. In particular, we combine the Extended Kalman Filter (EKF) with the <b>multiple</b> <b>cameras.</b> An essential {{strength of our}} approach {{is that it does}} not require finding image feature correspondences among cameras which is a difficult classical problem. The initial pose, the tracked features, and their corresponding 3 D reconstruction are fed to the multiple-camera EKF which estimates the real-time pose. The reason for using <b>multiple</b> <b>cameras</b> is that the pose estimation problem is more constrained for <b>multiple</b> <b>cameras</b> than for a single camera, which has been verified by simulations and real experiments alike. Different approaches using single and two cameras have been compared, as well as two different triangulation methods for the 3 D reconstruction. Both the simulations and the real experiments show that our approach is fast, robust and accurate. 1...|$|R
30|$|We {{propose a}} novel multi-surface video {{analysis}} strategy {{that is different}} from using <b>multiple</b> <b>cameras.</b>|$|R
500|$|The {{stage was}} {{designed}} by production designer Steven Cohen and production manager Rob Brenner for the HBO special. This {{was the first time}} Spears used an entire new stage design after having used a typical end-stage with a ramp and stairs at the center as on her first 3 tours (the ...Baby One More Time Tour, the (You Drive Me) Crazy Tour, and the Oops!... I Did It Again Tour). Cohen designed the main stage with an oval shape so that Spears could perform around the stage and so that it would look good from <b>multiple</b> <b>camera</b> angles. He said {{that the rest of the}} stage was created with three main components in mind: a runway, a B-stage, and a flying device over the crowd. The last was developed, as explained by Cohen, [...] "around this Cleopatra's barge concept I got into my head while designing when the movie Cleopatra was playing in the background. It needed to be elegant and stylized but also high tech, because it was going to have to be traveling on conventional motors and transport mechanisms. Plus, it had to have a big enough performance area for her and the dancers." [...] Brenner continued, [...] "I wanted to try to give the kid in the back of the house the same experience as the one in the first 10 rows." [...] The runway uniting the main stage and the B-stage was suggested by one of Spears's managers, Johnny Wright. The entire stage was built by Michael Tait from Tait Towers. Cohen said, [...] "We took a more expanded role in preparing the drawings for Michael. We wanted to retain the essence of the look of the show, both in its overall footprint and in the execution of these various pieces. [...] did a great job on executing the fine details like the hand railings and the floor lights and the MR-16 covers. When you're doing something for TV, all of those pieces are foreground pieces. The mirrors on the platforms and the floor painting made the show look better on TV." ...|$|E
2500|$|... 2005 [...] "Outstanding Achievement <b>Multiple</b> <b>Camera</b> Editing for a Drama Series" ...|$|E
2500|$|... 2007 Outstanding Achievement in <b>Multiple</b> <b>Camera</b> Editing for a Drama Series ...|$|E
5000|$|... #Caption: <b>Multiple</b> <b>cameras</b> to take {{surround}} images (1900 Cinéorama system, {{for modern}} version see Circle-Vision 360° ...|$|R
30|$|With the {{popularity}} of surveillance cameras, security observation systems are applied ubiquitously, especially in public places such as supermarkets, airports, and hospitals. Such a system includes <b>multiple</b> <b>cameras</b> connected to an operation center. Operators who are displayed images recorded from cameras have to observe and perform various tasks: detecting, recognizing, and keeping track of characters. Among these tasks, tracking people crossing <b>multiple</b> <b>cameras</b> plays an important role.|$|R
40|$|We {{describe}} a peer-to-peer multiple-camera architecture for distributed real-time gesture recognition system. Previ-ous work attaches <b>multiple</b> <b>cameras</b> to a server. This simpli-fies many design problems but is impractical for real-world installations. Our architecture uses {{a network of}} relatively inexpensive cameras to gather images {{in order to provide}} high resolution at low cost. Computations are done at the embedded processors in each camera, without using a cen-tralized server. We also propose a methodology for trans-forming well-defined single-camera algorithms to <b>multiple</b> <b>cameras.</b> We migrate our single-camera gesture recogni-tion system into <b>multiple</b> <b>cameras</b> with slightly overlapped views. In order to minimize the communication bandwidth and power consumption, only selected contours or ellipses information is transmitted between the cameras. 1...|$|R
2500|$|... 2012 [...] "Outstanding Achievement <b>Multiple</b> <b>Camera</b> Editing for a Drama Series" ...|$|E
2500|$|In {{the late}} 1990s, pornographic films were {{distributed}} on DVD. These offered better quality picture and sound {{than the previous}} video format and allowed innovations such as [...] "interactive" [...] videos that let users choose such variables as <b>multiple</b> <b>camera</b> angles, multiple endings and computer-only DVD content.|$|E
2500|$|In the past, it was {{possible}} to avoid detection by changing lanes when SPECS average speed cameras were in use as they measured a vehicle's speed over distance in one lane only. [...] Since 2007, measures were taken to mitigate this limitation. [...] Although the cameras do operate in pairs on single lanes (it is a limitation of the technology not a restriction in the type approval) the authorities now install the cameras such that the monitored length of road overlaps between <b>multiple</b> <b>camera</b> pairs. [...] The driver cannot tell which cameras are 'entry' and which are 'exit' making it difficult to know when to change lane.|$|E
30|$|<b>Multiple</b> <b>Cameras.</b> A {{network of}} {{calibrated}} monocular or stereo cameras monitoring {{the scene from}} significantly different viewpoints.|$|R
5000|$|... #Caption: Photographer on the {{sideline}} of an American football game with <b>multiple</b> <b>cameras,</b> long lenses, and monopods.|$|R
40|$|Visual {{surveillance}} using <b>multiple</b> <b>cameras</b> {{has attracted}} increasing interest in recent years. Correspondence between <b>multiple</b> <b>cameras</b> {{is one of}} the most important and basic problems which visual surveillance using <b>multiple</b> <b>cameras</b> brings. In this paper, we propose a simple and robust method, based on principal axes of people, to match people across <b>multiple</b> <b>cameras.</b> The correspondence likelihood reflecting the similarity of principal axis pairs is constructed according to the relationship between “ground-points ” detected in each camera view and the intersections of principal axes detected in different camera views and transformed to the same view. Our method has the following desirable properties: (1) Camera calibration is not needed. (2) Accurate motion detection and segmentation are less critical due to the robustness of the principal axis-based feature to noise. (3) Based on the fused data derived from correspondence results, positions of people in each camera view can be accurately located even when the people are partially occluded in all views. The experimental results on several real video sequences from outdoor environments have demonstrated the effectiveness, efficiency and robustness of our method...|$|R
2500|$|Jackson {{worked in}} <b>multiple</b> <b>camera</b> and plate sizes, under {{conditions}} that were often incredibly difficult. His photography {{was based on}} the collodion process invented in 1848 and published in 1851 by Frederick Scott Archer. [...] Jackson traveled with as many as three camera-types—a stereographic camera (for stereoscope cards), a [...] "whole-plate" [...] or 8x10" [...] plate-size camera, and one even larger, as large as 18x22". [...] These cameras required fragile, heavy glass plates (photographic plates), which had to be coated, exposed, and developed onsite, before the wet-collodion emulsion dried. Without light metering equipment or sure emulsion speeds, exposure times required inspired guesswork, between five seconds and twenty minutes depending on light conditions.|$|E
2500|$|Jackson was a noted perfectionist on the Lord of the Rings shoot, {{where he}} demanded {{numerous}} takes of scenes, requesting additional takes by repeatedly saying, [...] "one more for luck". Jackson is also renowned within the New Zealand film industry for his insistence on [...] "coverage"—shooting {{a scene from}} as many angles as possible, giving him more options during editing. Jackson {{has been known to}} spend days shooting a single scene. This is evident in his work where even scenes featuring simple conversations often feature a wide array of <b>multiple</b> <b>camera</b> angles and shot-sizes as well as zooming closeups on characters' faces. One of his most common visual trademarks is shooting close-ups of actors with wide-angle lenses. He was an early user of computer enhancement technology and provided digital special effects to a number of Hollywood films.|$|E
2500|$|In {{the late}} 1970s, Kerry Packer {{established}} the rival World Series Cricket competition, and it introduced {{many of the}} features of One Day International cricket that are now commonplace, including coloured uniforms, matches played at night under floodlights with a white ball and dark sight screens, and, for television broadcasts, <b>multiple</b> <b>camera</b> angles, effects microphones to capture sounds from the players on the pitch, and on-screen graphics. The first of the matches with coloured uniforms was the WSC Australians in wattle gold versus WSC West Indians in coral pink, played at VFL Park in Melbourne on 17 January 1979. [...] This led not only to Kerry Packer's Channel 9 getting the TV rights to cricket in Australia but also led to players worldwide being paid to play, and becoming international professionals, no longer needing jobs outside cricket. Matches played with coloured kits and a white ball became more commonplace over time, and the use of white flannels and a red ball in ODIs was finally abandoned in 2001.|$|E
40|$|Robust object {{tracking}} {{still remains}} a difficult problem in computer vision research and surveillance applications. One promising development {{in this area}} is the increased availability of surveillance cameras with overlapping views. Intuitively, these overlapping views may lead to more robust object tracking and recognition. However, combining the information from the <b>multiple</b> <b>cameras</b> in a meaningful way is challenging. Our contribution in this work is a novel approach to object tracking by robustly and accurately recovering the full motion of the object from <b>multiple</b> <b>cameras.</b> This is accomplished by explicitly fusing the information from <b>multiple</b> <b>cameras</b> into a joint 3 D motion calculation. We apply this approach to the tracking of faces in <b>multiple</b> video <b>cameras</b> and utilize the 3 D cylinder model to realize the motion calculation. The method is demonstrated on a sequence of real data for pose estimation of the face. Also, the 3 D cylinder texture map from the tracking result is used in face recognition. The performance of fullmotion recovery from <b>multiple</b> <b>cameras</b> is shown to produce {{a significant increase in the}} accuracy of face pose estimation and results in a higher face recognition rate than from a single camera. Our approach may be applied to other types of object tracking such as vehicles. 1...|$|R
30|$|We propose an {{extrinsic}} {{calibration algorithm}} for <b>multiple</b> <b>cameras,</b> {{even if there}} is no overlapping field of view among them.|$|R
5000|$|Fox's Back to You {{is back to}} TV comedy basics: <b>multiple</b> <b>cameras,</b> live audiences but, mostly, laughs. — Los Angeles Times ...|$|R
