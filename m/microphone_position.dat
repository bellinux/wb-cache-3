51|235|Public
5000|$|... #Caption: Lemmy playing {{bass and}} singing, with his {{trademark}} high <b>microphone</b> <b>position</b> ...|$|E
50|$|Another handy {{device for}} {{adjusting}} microphone placement is a flexible goose neck tube. Made of a spiral-wound core of steel, goosenecks {{are made in}} various lengths and finishes and provide {{the ability to make}} minute changes in <b>microphone</b> <b>position.</b>|$|E
40|$|Source {{localization}} employing time-differences-of-arrival {{has been}} employed for many applications. The accuracy of source localiza-tion {{is limited by}} the errors in the time differences of arrival esti-mation as well as <b>microphone</b> <b>position</b> calibration errors. Because a <b>microphone</b> <b>position</b> error will affect multiple time differences of arrival, correlation between these quantities will be introduced. This work presents a new mathematical framework in which we quan-tify the localization performance of a microphone array in which the microphone positions are subject to such errors. Index Terms- Acoustic source localization, Acoustic arrays, Time-differences-of- arrival 1...|$|E
30|$|The <b>positions</b> of the <b>microphones</b> {{were defined}} {{according}} to ISO 3745 - 2003 [31], assuming {{that there is}} one reflecting plane in the sound-free field. As there are only five microphones available, and the sound power level (SWL) was calculated by averaging the sound pressure level (SPL) at ten <b>microphone</b> <b>positions,</b> the <b>microphone</b> <b>positions</b> were moved manually during the measurement. The measurement of SWL was divided into two steps. The first step was to measure the SPL at the first five <b>microphone</b> <b>positions,</b> and the second step was to measure the SPL at the other five <b>microphone</b> <b>positions.</b>|$|R
3000|$|The bound is {{evaluated}} {{for a specific}} location, parameter setting, and <b>microphone</b> <b>positioning,</b> collectively [...]...|$|R
40|$|Reflector {{localization}} {{has been}} the subject of growing research interest in recent years. This paper outlines an approach that performs reflector localization based on loudspeaker and <b>microphone</b> <b>positions</b> and their images. The positions of the latter are computed using pre-grouped sets of times of arrival (TOAs) estimated from room impulse responses. First, the TOA sets are used to estimate the <b>microphone</b> <b>positions.</b> Second, these are used with knowledge of the array geometry to determine the locations of reflection points on the available reflectors. Finally, the reflection points are used to obtain the reflector locations. It is shown that the proposed approach facilitates solving the reflector localization problem in ill-conditioned setups...|$|R
40|$|The {{speech of}} a person {{speaking}} in a noisy environment can be enhanced through electronic beamforming using spatially distributed microphones. As this approach demands precise information about the microphone locations, its application is limited in places where microphones must be placed quickly or changed on a regular basis. Highly precise calibration or measurement process can be tedious and time consuming. In order to understand tolerable limits on the calibration process, the impact of <b>microphone</b> <b>position</b> error on the intelligibility is examined. Analytical expressions are derived by modeling the <b>microphone</b> <b>position</b> errors as a zero mean uniform distribution. Experiments and simulations were performed to show relationships between precision of the microphone location measurement and loss in intelligibility. A variety of microphone array configurations and distracting sources (other interfering speech and white noise) are considered. For speech near the threshold of intelligibility, {{the results show that}} <b>microphone</b> <b>position</b> errors with standard deviations less than 1. 5 cm can limit losses in intelligibility to within 10 % of the maximum (perfect microphone placement) for all the microphone distributions examined. Of different array distributions experimented, th...|$|E
40|$|INTRODUCTION: Cough {{intensity}} {{is an important}} determinant of cough severity reported by patients. Cough sound analysis has been widely validated for the measurement of cough frequency but few studies have validated its use {{in the assessment of}} cough strength. We investigated the relationship between cough sound and physiological measures of cough strength. METHODS: 32 patients with chronic cough and controls underwent contemporaneous measurements of voluntary cough sound, flow and oesophageal pressure. Sound power, peak energy, rise-time, duration, peak-frequency, bandwidth and centroid-frequency were assessed and compared with physiological measures. The relationship between sound and subjective cough strength Visual Analogue Score (VAS), the repeatability of cough sounds and the effect of <b>microphone</b> <b>position</b> were also assessed. RESULTS: Sound power and energy correlated strongly with cough flow (median Spearman's r= 0. 87 - 0. 88) and oesophageal pressure (median Spearman's r= 0. 89). Sound power and energy correlated strongly with cough strength VAS (median Spearman's r= 0. 84 - 0. 86) and were highly repeatable (intraclass correlation coefficient= 0. 93 - 0. 94) but both were affected by change in <b>microphone</b> <b>position.</b> CONCLUSIONS: Cough sound power and energy correlate strongly with physiological measures and subjective perception of cough strength. Power and energy are highly repeatable measures but the <b>microphone</b> <b>position</b> should be standardised. Our findings support the use of cough sound as an index of cough strength. Peer-reviewedPublisher Versio...|$|E
30|$|Our earlier {{proposed}} system, {{presented in}} [15], {{is similar to}} the Dolphin system [2], except that it adopts trilateration instead of multilateration and audible sound instead of an ultrasound signal. The system deploys four tweeters and aims to locate a microphone. Two methods have been proposed. The first method uses four combinations of three of the four measured distances to generate four estimates of the microphone location. The resulting position is the center point of the four estimates. The second method uses the three most reliable distances for the computation of the <b>microphone</b> <b>position.</b> In [15], the first method was adopted and the system gives accuracy of 2 cm with 99 % precision. Inspired from [15], a novel acoustic localization system was presented in [16]. The system is a receiver localization system that uses CDMA operation. It differs from the system described in [15] in that it uses the fingerprinting technique instead of lateration. It deploys three tweeters and computes the <b>microphone</b> <b>position</b> through nonparametric kernel regression.|$|E
30|$|Another {{challenge}} {{resulting from}} the varying <b>microphone</b> <b>positions</b> is to process them as an array. One promising algorithm to this problem is the so-called adaptive microphone selection [9]. The algorithm applies a sensor switching based on the corresponding SNR.|$|R
3000|$|... [...]) only {{depends on}} the {{exponential}} terms averaged over all microphone pairs, which {{is directly related to}} the <b>microphone</b> <b>positions</b> and source signal frequencies. For the case where a signal source is located at the beamformer focal point, r [...]...|$|R
40|$|A {{simplified}} cylindrical {{model of}} an aircraft fuselage {{is used to}} investigate the mechanisms of interior noise suppression of the synchrophasing technique. This investigation allows isolation of important parameters to define the characteristics of synchrophasing. The optimum synchrophase angle for maximum noise reduction is found for several interior <b>microphone</b> <b>positions</b> with pure tone source conditions. Noise reductions of up to 30 dB are shown for some <b>microphone</b> <b>positions,</b> however, overall reductions are less. A computer algorithm is developed to decompose the modal composition of the cylinder vibration {{over a wide range}} of synchrophase angles. The circumferential modal response of the shell vibration is shown to govern the transmission of sound into the cylinder rather than localized transmission...|$|R
40|$|This {{study was}} {{conducted}} {{as part of a}} project involving the evaluation of a new type of noise exposure monitoring paradigm. Laboratory tests were conducted to assess how nonstandard dosimeter microphones and microphone po sitions measured noise levels under different acoustical condi tions (i. e., diffuse ?eld and direct ?eld). The data presented in this article re?ect measurement differences due to <b>microphone</b> <b>position</b> and mounting/supporting structure only and are not an evaluation of any particular complete dosimeter system. To varying degrees, the results obtained with the dosimeter microphones used in this study differed from the reference results obtained in the unperturbed (subject absent) sound ?eld with a precision (suitable for use in an ANSI Type 1 sound level meter) 1 / 2 -inch (12. 7 mm) measurement microphone. Effects of dosimeter microphone placement in a diffuse ?eld were found to be minor for most of the test microphones/locations, while direct ?eld microphone placement effects were found to be quite large depending on the <b>microphone</b> <b>position</b> and supporting structure, sound source location, and noise spectrum...|$|E
40|$|An {{evaluation}} is presented for whirl tower test {{results of the}} Model 360 helicopter's advanced, high-performance four-bladed composite rotor system intended to facilitate over- 200 -knot flight. During these performance measurements, acoustic data were acquired by seven microphones. A comparison of whirl-tower tests with theory indicate that theoretical prediction accuracies vary with both <b>microphone</b> <b>position</b> and the inclusion of ground reflection. Prediction errors varied from 0 to 40 percent of the measured signal-to-peak amplitude...|$|E
40|$|The {{research}} {{leading to}} these results has received {{funding from the}} People Programme (Marie Curie Actions) of the European Unions Seventh Framework Programme FP 7 / 2007 - 2013 / under REA grant agreement No. 605867 supporting the BATWOMAN ITN Project. Brass musical instruments act {{as a source of}} spherical waves for low frequencies while at higher frequencies the directivity produces a diffracting beam. The directivity and radius of the wavefronts (and therefore the source position) may be expected to depend on the frequency in addition to the geometry of the bell. In this work, experimental determination of the wavefronts propagating from the bell section of brass instruments was performed using a moveable line array of microphones. Exponential sine sweep measurements were performed for each <b>microphone</b> <b>position,</b> effectively giving synchronised impulse responses at every <b>microphone</b> <b>position</b> in a two-dimensional grid starting {{directly in front of the}} bell. Calculations were then carried out to check to what extent the observed field was consistent with the predictions from multimodal theory. The multimodal radiation impedance was only known previously for specific geometries such as the infinite baffle, but here an extension of the theory is set out in order to simulate a trombone radiating within a large radius, infinite length cylindrical pipe. Publisher PD...|$|E
30|$|Note {{that the}} delay-and-subtract signal in (30) {{is used in}} other {{applications}} as the output of a differential microphone array [17]. Obviously, this is not suitable for <b>microphone</b> <b>positions</b> that are sensitive to wind noise, because the noise terms are heavily amplified.|$|R
40|$|The "delay and sum beamformer" {{algorithm}} (") is {{a powerful}} tool for the localisation and quantioncation of acoustic sources with microphone arrays. For the calculation of beamforming maps the DSB algorithm requires the following input data: time series of all microphones, a grid of focus points which includes the region of interest, paramater of the ow for boundary layer or shear layer corrections and the accurate <b>position</b> of all <b>microphones.</b> The present paper is focused on the last item: the accurate estimation of the <b>microphone</b> <b>positions.</b> Especially for aeroacoustic applications the number of microphones should be large enough in order to obtain good beamforming results. The estimation of the accurate <b>microphone</b> <b>positions</b> can mean a huge time consuming effort. The method which will be presented in this paper is similar to the well known global positioning system: distances to satellites provide information about the position of a receiver. Here, several monopole-like acoustical point sources with known positions and a reference microphone which is installed close to the sound sources are used to compute the <b>position</b> of the <b>microphones</b> of a microphone array in the three-dimensional space. After pointing out the basic concepts and algorithms a practical implementation of the test sources is described. Eight test sources and the reference microphone are integrated in a so-called calibration unit. Afterwards a calibration of a microphone array with known <b>microphone</b> <b>positions</b> is presented to verify the method and to assess the accuracy that can be achieved. Furthermore the problem is addressed how many test sources are necessary to achieve accurate results. Finally, the procedure is used to calibrate an out-of-flow microphone array with a layout of <b>microphones</b> where the <b>positions</b> are only known with some uncertainty. Investigations concerning the frequency dependence of the calibration are presented. Beamforming on a loudspeaker is performed to show in how far more accurately known <b>microphone</b> <b>positions</b> can improve beamforming results, particularly in the higher frequency range...|$|R
40|$|A {{new method}} {{for the design}} of robust minimax {{far-field}} broadband beamformers with optimized microphone po-sitions is proposed. The method is formulated as an iterative optimization problem where the maximum passband 1 magnitude response error is minimized and the <b>microphone</b> <b>positions</b> are optimized while ensuring that the minimum stopband attenuation is above a prescribed level. To maintain robustness, we constrain a sensitivity parameter, namely, the white noise gain, to be above prescribed levels across the frequency band. An additional feature of the method, which is quite useful in certain applications, is that it provides the capability of constraining the gain in the transition band to always lie below the maximum gain in the passband. Performance comparisons with existing methods show that the optimization of the <b>microphone</b> <b>positions</b> results in beamformers with superior performance...|$|R
30|$|In speech enhancement, a {{microphone}} signal normally {{consists of a}} mixture of multiple sources. In this paper, we assume W-disjoint orthogonality (W-DO) [13, 14] for a mixed signal to simplify the observation model for the mixture. W-DO refers to the strong sparseness of a signal in the time-frequency domain, where {{it is assumed that}} a component from a single source dominates one time-frequency slot of a discrete STFT. In the proposed method, virtual microphone signals are generated in each time-frequency bin; thus, the relationship between the virtual <b>microphone</b> <b>position</b> and the propagating wavefront can be modeled as the propagation of a single wavefront.|$|E
40|$|Personalized {{ventilation}} (PV) has {{the ability}} to improve inhaled air quality and accommodate the individual thermal preference. In this paper one kind of personalized ventilation system which supplies fresh air at the <b>microphone</b> <b>position</b> is investigated numerically. A numerical thermal manikin with the real geometry of human body is used to study the airflows around the occupant equipped with PV. The performance of one RNG k-ε model and the standard k-ε model is compared. The benefits of PV under different uniform room ambient flow are analyzed. The results indicate that the orientation of the human body to the uniform flow plays a key role...|$|E
40|$|Finite element {{theory is}} used to {{calculate}} the acoustic field of a propeller in a soft walled circular wind tunnel and to compare the radiation patterns to the same propeller in free space. Parametric solutions are present for a "Gutin" propeller for a variety of flow Mach numbers, admittance values at the wall, <b>microphone</b> <b>position</b> locations, and propeller to duct radius ratios. Wind tunnel boundary layer is not included in this analysis. For wall admittance nearly equal to the characteristic value of free space, the free field and ducted propeller models agree in pressure level and directionality. In addition, the need for experimentally mapping the acoustic field is discussed...|$|E
40|$|Berkhout [l] showed that, {{for a given}} source position, {{the sound}} field in a hall can be {{acquired}} with full temporal and spatial information by recording or calculating impulse responses along an array of <b>microphone</b> <b>positions.</b> As an implementation of this concept, an array of loudspeakers is fed with these impulse responses such that the sound field can be auralized...|$|R
40|$|This bachelor's thesis {{presents}} evaluating of acoustic {{variables and}} anechoic chamber application. There are described physical {{requirements for the}} anechoic chambers. Part of this thesis deals with measurement of audio signals to calculation sound pressure level. The last part of this work includes audio signals of two <b>microphone</b> <b>positions</b> during the measurement sound source and finally their processing and evaluation...|$|R
3000|$|RCS(ℓ,k) for {{residual}} cross-talk suppression (RCS) within an extended noise reduction (ENR). This noise reduction block {{also has to}} deal with the preparation of the DSC. Due to the different <b>microphone</b> <b>positions</b> and types, the noise signal characteristics (especially noise level and coloration) may differ strongly across the microphone channels. Since annoying switching artifacts may occur in a combined signal, we propose to adjust all noise power spectral densities (PSDs) [...]...|$|R
40|$|In telecommunications, {{diversity}} combining {{for multiple}} receiving antennas is a commonly used technique to achieve robustness for fading channels. This paper proposes a frequency domain diversity approach {{for two or}} more microphone signals, e. g. for in-car applications. The microphones should be positioned separately to insure diverse signal conditions. This enables a better compromise for the <b>microphone</b> <b>position</b> with respect to different speaker sizes and noise sources. The microphone signals are weighted {{with respect to their}} signal-to-noise ratio and then summed similar to maximum-ratio-combining. The output SNR is significantly improved compared to single microphone noise reduction systems, even if one microphone is heavily corrupted by noise. 1...|$|E
40|$|The {{potential}} benefits of preserving high-frequency spectral cues created by the pinna in hearing-aid fittings were investigated in a combined laboratory and field test. In a single-blind crossover design, two settings of an experimental hearing aid were compared. One setting was characterized by a pinna cue-preserving <b>microphone</b> <b>position,</b> whereas the other was character-ized by a <b>microphone</b> <b>position</b> not preserving pinna cues. Participants were allowed 1 month of acclimatization to each setting before measurements of localization and spatial release from speech-on-speech masking were completed in the laboratory. Real-world experience with the two settings was assessed by means of questionnaires. Seventeen participants with mild to moderate sensorineural hearing impairments completed the study. An inconsistent pinna cue benefit pattern was observed across the outcome measures. In the localization test, the pinna cue-preserving setting provided a significant mean reduction of 22 in the root mean square (RMS) error in the front–back dimension, with 13 of the 17 participants showing a reduction of at least 15. No significant mean difference in RMS error between settings was observed in the left–right dimension. No significant differences between settings were observed in the spatial-unmasking test conditions. The ques-tionnaire data indicated a small, but nonsignificant, benefit of the pinna cue-preserving setting in certain real-life situations, which corresponded with a general preference for that setting. No significant real-life localization benefit was observed. The results suggest that preserving pinna cues can offer benefit in some conditions for individual hearing-aid users with mild to moderate hearing loss and is unlikely to harm performances for the rest...|$|E
30|$|In contrast, in this contribution, we want {{to focus}} on {{distributed}} microphones, where the arrangement is not limited to fixed geometries but where each speaker in the car cabin has a dedicated microphone close to his position. In the case at hand with multiple microphones and multiple speakers to be supported, the sensor signals have to be combined in a beneficial way. In the literature, it is often focussed on setups where multiple microphones are used to capture the speech signal of one single speaker. In this case, multiple spatially distributed microphones may be mounted in the direct vicinity of just one speaker in order to search for the optimal <b>microphone</b> <b>position.</b>|$|E
50|$|In March 2016, the Vienna Symphonic Library {{business}} offices {{moved into}} the new recording facility at Synchron Stage Vienna. VSL ushers {{in a new era}} in April 2017 with the release of “Synchron Percussion I” that was recorded at the newly revitalized scoring stage. 16 percussion instruments were captured with a phase-controlled multi-microphone set-up, making it the first sample library that provides several available <b>microphone</b> <b>positions</b> also for Auro-3D mixes.|$|R
40|$|A flight {{experiment}} {{was conducted to}} investigate the lateral attenuation of high by pass ratio engined airplanes. A B- 747 was flown at low altitudes over the ends of two microphone arrays. One array covering a lateral distance of 1600 m consisted of 14 <b>microphones</b> <b>positioned</b> over grass. The second array covered a lateral distance of 1200 m and consisted of 6 <b>microphones</b> <b>positioned</b> over a concrete runway. Sixteen runs were flown at altitudes ranging from 30 to 960 m. The acoustic information recorded in the field was reduced to one third octave band spectral time histories and synchronized with tracking and weather information. Lateral attenuation {{as a function of}} elevation angle was calculated in overall, A-weighted, tone-corrected perceived noise level, and effective perceived noise level units. The B- 747 results are compared with similar results for a turbojet-powered T- 38 airplane and the SAE recommended lateral attenuation prediction procedure. Less lateral attenuation was measured for the B- 747 than for the T- 38. The B- 747 lateral attenuation values also fell below the SAE curve...|$|R
50|$|WQXR was {{the first}} AM station in New York to {{experiment}} with broadcasting in stereo, beginning in 1952. During some of its live concerts, it used two <b>microphones</b> <b>positioned</b> six feet apart. The microphone on the right led to its AM feed, and {{the one on the}} left to its FM feed, so a listener could position two radios six feet apart, one tuned to 1560 and the other to 96.3, and listen in stereo.|$|R
40|$|This paper {{investigates the}} {{robustness}} of sound equalization using a room response inverse lter {{with respect to}} changing or uncertain source or microphone positions. It is shown that due to the variations of the transfer function from point topointinaroom,even small changes in the source or <b>microphone</b> <b>position</b> {{of just a few}} tenths of the acoustic wavelength can cause large degradations in the equalized room response. The robustness problem is especially acute at high frequencies, which areknown to carry some important attributes of the speech signal. The spatial extent of equalization, derived from the statistical-average properties of sound transmission in rooms, is illustrated by computer simulations which corroborate the theoretical results presented in the paper...|$|E
40|$|Traffic noise {{measurement}} is usually {{performed with the}} microphone either at 1, 5 m or 4 m above ground, being the latter the most recommended position. In order to test the influence of <b>microphone</b> <b>position</b> (including the distance from façade) a computer model has been developed which includes noise reflection at neighbouring surfaces as well as vehicle trajectory and its associated Doppler spectral warping. Detailed FFT spectrum as well as octave and one third of an octave spectra have been computed for different microphone configurations. Results suggest that influence is not negligible when spectral data are to be collected, for instance, for spectral noise mapping, and measurement position should, hence, be specified accurately. ...|$|E
30|$|This paper {{proposes a}} {{frequency}} domain diversity approach {{for two or}} more microphone signals, for example, for in-car applications. The microphones should be positioned separately to insure diverse signal conditions and incoherent recording of noise. This enables a better compromise for the <b>microphone</b> <b>position</b> with respect to different speaker sizes and noise sources. This work proposes a two-stage approach. In the first stage, the microphone signals are weighted {{with respect to their}} signal-to-noise ratio and then summed similar to maximum ratio combining. The combined signal is then used as a reference for a frequency domain least-mean-squares (LMS) filter for each input signal. The output SNR is significantly improved compared to coherence-based noise reduction systems, even if one microphone is heavily corrupted by noise.|$|E
5000|$|... #Caption: A modern {{version of}} the Kundt's tube experiment, used in a South American {{university}} physics class. Instead of a transparent tube with powder in it to reveal the nodes, this uses microphones mounted in the tube. The piston (right center) is moved back and forth. When the <b>microphone's</b> <b>position</b> is at the antinodes of the wave the sound pressure goes to zero. The sound power from the microphones is recorded on the chart recorder (center rear).|$|R
40|$|New {{recommendations}} for environmental noise levels {{have been issued}} in Sweden. The permissible levels at facades of new buildings have been increased, which {{has resulted in a}} risk for higher indoor low frequency noise levels, since the recommended indoor levels are A-weighted. The additional Swedish low frequency third octave band requirements might be violated. Therefore, {{there is a need for}} reviewing how well façade insulation properties are manifested in measurements, and how accurate the measurement results indicate the indoor noise situation from the residents' perspective. In this paper, the results of façade insulation measurements are compared with corresponding models, with a special attention to associated challenges (e. g. to establish representative <b>microphone</b> <b>positions</b> in low frequency sound fields). The measurements are performed in a demonstrator house, which replicates a modern single family house. The models are evaluated both with respect to the total sound energy integrated over the entire room volumes, and as sampled sound fields, where the sample points may correspond to <b>microphone</b> <b>positions.</b> The congruence of the measured and the modelled results are analysed and discussed, as well as the relevance of different approaches...|$|R
40|$|The spatial {{extent of}} the {{cancellation}} {{that can be achieved}} with a local active sound control system is limited, particularly at frequencies above about 300 Hz, so that control of the pressure at fixed points in space does not give satisfactory performance as the listener’s head moves about, unless the position of the head can be tracked. The availability of low-cost head tracking systems for gaming applications opens up the possibility of such a head tracking active control system at a modest cost. In the experiments reported here, such a system was used to track the head position in a local active sound controller, implemented in a headrest. The positions of the listener’s ears were calculated from the head position. This was used in lookup tables to estimate both the responses from the secondary sources to the remote <b>microphone</b> <b>positions</b> at the ear, and also the weightings on an array of monitoring microphones mounted on the headrest, used to estimate the pressures at these remote <b>microphone</b> <b>positions,</b> using an observer. These estimates were then used to adapt the two control filters driving the secondary sources...|$|R
