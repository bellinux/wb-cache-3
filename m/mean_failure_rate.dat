20|10000|Public
30|$|Regarding recent arthroscopically {{meniscus}} suture techniques, an further {{improvement of}} long-term outcomes and {{reduction of the}} failure rate is described. Lozano et al. reviewed the outcome after all-inside meniscus suturing and found a <b>mean</b> <b>failure</b> <b>rate</b> of 15 % (Lozano et al., 2007).|$|E
40|$|Meniscus {{integrity}} {{is the key}} for joint health of the knee. Therefore, the main goal of every meniscus treatment should be the maintenance of as much meniscus tissue as possible. Repair of meniscus tears {{can be achieved by}} meniscus suture. However, in a recently published meta-analysis, the long-term outcome of meniscus repair showed a <b>mean</b> <b>failure</b> <b>rate</b> of 24...|$|E
40|$|Recent {{statistical}} {{results on}} the distribution of extrema in a two-dimensional Gaussian random field are used to predict the <b>mean</b> <b>failure</b> <b>rate</b> of a block matching algorithm which uses the mean-normalised correlation as the matching metric. The failure rate depends on the noise model, the area of the correlation surface to be searched and the properties of the block to be matched. Reliability of tracking a particular block is characterised by the maximum possible search area predicted by the model for a given confidence of a correct match. Simulation results based on synthetic noise fields and blocks from real images are used to confirm that the <b>mean</b> <b>failure</b> <b>rate</b> of the algorithm matches the prediction obtained from the model. The analysis is then applied to real image sequences and the actual failure rate is found to be well within an order of magnitude of that predicted. These results have significant implications for the selection of image features for motion tracking and the design [...] ...|$|E
30|$|After {{electronic}} database search, a {{total of}} 63 relevant studies were eligible, of which 42 qualified for numerical data synthesis, 26 being retrospective studies. A data synthesis was performed by weighted <b>means</b> for survival/success/annual <b>failure</b> <b>rates.</b>|$|R
40|$|The {{effects of}} using {{two or more}} {{standardized}} patients (multiple SPs) to simulate the same case in a performance-based examination were studied at the case level by comparing case <b>means</b> and case <b>failure</b> <b>rates</b> for multiple SPs simulating the same case, {{using data from the}} classes of 1988, 1989, and 1990 at the Southern Illinois University School of Medicine. For total scores and scores on the students' written answers, the effects on <b>means</b> and <b>failure</b> <b>rates</b> were negligible and could be explained as due to sampling error. For scores on the checklists completed by the SPs, there were more significant differences than would be expected by chance alone, even though the number of significant differences was relatively small. The results demonstrate a need for caution in the interpretation of scores obtained from a case checklist completed by multiple SPs, particularly in regard to making pass-fail decisions...|$|R
5000|$|According to a 2012 {{review article}} by Demarco et al. {{covering}} 34 relevant clinical studies, [...] "90% {{of the studies}} indicated that annual <b>failure</b> <b>rates</b> between 1% and 3% can be achieved with Class I and II posterior tooth composite restorations depending on the definition of failure, and on several factors such as tooth type and location, operator dentist, and socioeconomic, demographic, and behavioral elements." [...] This compares to a 3% <b>mean</b> annual <b>failure</b> <b>rate</b> reported in a 2004 review article by Manhart et al. for amalgam restorations in posterior stress-bearing cavities.|$|R
40|$|The {{reliability}} of digital flight control systems {{can often be}} accurately predicted using Markov chain models. The cost of numerical solution depends on a model's size and stiffness. Acyclic Markov models, a useful special case, are particularly amenable to efficient numerical solution. Even in the general case, instantaneous coverage approximation allows the reduction of some cyclic models to more readily solvable acyclic models. After considering the solution of single-phase models, the discussion is extended to phased-mission models. Phased-mission reliability models are classified based on the state restoration behavior that occurs between mission phases. As an economical approach for the solution of such models, the <b>mean</b> <b>failure</b> <b>rate</b> solution method is introduced. A numerical example is used to show the influence of fault-model parameters and interphase behavior on system unreliability...|$|E
40|$|This {{probabilistic}} {{analysis of}} WIPP TRUDOCK crane failure {{is based on}} two sources of failure data. The source for operator errors is the report by Swain and Guttman, NUREG/CR- 1278 -F, August 1983. The source for crane cable hook breaks was initially made by WIPP/WID- 96 - 2196, Rev. O by using relatively old (1970 s) U. S. Navy data (NUREG- 0612). However, a helpful analysis by R. K. Deremer of PLG guided the authors to values that were more realistic and more conservative, with the recommendation that the crane cable/hook failure rate should be 2. 5 x 10 - 6 per demand. This value was adopted and used. Based on these choices a <b>mean</b> <b>failure</b> <b>rate</b> of 9. 70 x 10 - 3 (1 /yr) was calculated. However, a mean rate by itself does not reveal the level of confidence {{to be associated with}} this number. Guidance to making confidence calculations came from the report by Swain and Guttman, who stated that failure data could be described by lognormal distributions. This is in agreement with the widely use d reports (by DOE and others) NPRD- 95 and NPRD- 91, on failure data. The calculations of confidence levels showed that the <b>mean</b> <b>failure</b> <b>rate</b> of 9. 70 x 10 - 3 (1 /yr) corresponded to a percentile value of approximately 71; i. e. there is a 71 % likelihood that the failure rate is less than 9. 70 x 10 - 3 (1 /yr). One also calculated that there is a 95 % likelihood that the failure rate is less than 29. 6 x 10 - 3 (1 /yr). Or, as stated previously, there is a 71 % likelihood that not more than one dropped load will occur in 103 years. Also, there is a 95 % likelihood that not more than one dropped load will occur in approximately 34 years. It is the responsibility of DOE to select the confidence level at which it desires to operate...|$|E
40|$|Fault {{injection}} is {{a widely}} used method for evaluating dependable systems. The intention {{of this paper is}} to compare typical fault models used for fault injection regarding their accuracy in predicting the reliability of the system. For this purpose, we set up an experiment by injecting faults in a VHDL model of the DP 32 -processor at gate-level, pin-level and at register-transfer level. The experiment has been performed by using the simulation based fault injector VERIFY (VHDL-based Evaluation of Reliability by Injecting Faults efficientlY). The differences in the predicted <b>mean</b> <b>failure</b> <b>rate</b> of the system will be shown and a comparison of system's behavior after fault injection will be presented. The results demonstrate that faults have to be injected at least at gate-level in order to represent the correct timing behavior of the digital system after the fault has been injected and help the designer of a dependable system to find the weak components. 1. Introduction Mor [...] ...|$|E
40|$|This paper {{deals with}} the {{comparison}} between the overall whole-of-life costs of overhead lines (OHL) and those of underground insulated cables (UGC). Almost all the investigations published so far, when analyzing maintainability issues, take into account only the costs of planned/periodical maintenance; here, a method for assessing also the expenses sustained for repair after random failures is proposed. The number of random failure events for each kind of component over the entire service life of a transmission line can only be predicted on a probabilistic basis: its expected value is estimated by making use of the relevant <b>mean</b> <b>failure</b> <b>rates</b> from recent statistical surveys. The entire procedure is shown by carrying out a particular case study as an example; the break-even point between the OHL-UGC overall costs, corresponding to a typical rural land Italian market value wx= 26. 9 €/m 2, is identified. Nonetheless, the method may be widely applied to any type of OHL–UGC comparison...|$|R
40|$|This paper {{characterizes the}} general {{behaviors}} of the MRL (mean residual lives) for both continuous and discrete lifetime distributions, {{with respect to their}} <b>failure</b> <b>rates.</b> For the continuous lifetime distribution with <b>failure</b> <b>rates</b> with only one or two change-points, the characteristic of the MRL depends only on its <b>mean</b> and <b>failure</b> <b>rate</b> at time zero. For <b>failure</b> <b>rates</b> with 2 ̆ 2 roller coaster 2 ̆ 2 behavior, the subsequent behavior of the MRL depends on its MRL and failure-rates at the change points. Using the characterization, their behaviors for the: Weibull; lognormal; Birnbaum-Saunders; inverse Gaussian; and bathtub <b>failure</b> <b>rate</b> distributions are tabulated in terms of their shape parameters. For discrete lifetime distributions, for upside-down bathtub <b>failure</b> <b>rate</b> with only one change point, the characteristic of the MRL depends only on its mean and the probability mass function at time zero...|$|R
40|$|The basic {{methodology}} for determining sequences {{of events and}} their frequencies (event and fault trees) does not differ significantly from that of other risk studies. This applies analogously {{to the treatment of}} statistical data uncertainties and the description of results in the form of expected value with-uncertainty factor. System unavailabilities are determined by <b>means</b> of <b>failure</b> <b>rates,</b> most of which originate from the German Risk Study, and consecutive test intervals. Unlike in other risk studies, common mode failures of components of the same-kind are being considered by a mostly 10...|$|R
40|$|The {{purpose of}} this study has been to review data sources {{relevant}} to the failure rate and mean time to repair for the principal pumps of the Heber geothermal project. Based upon that review the distributions of failure rates, repair times and pump unavailability were established. A total of 16 pumps are represented in this study. The method used to develop data distributions has been to first review as many sources of pump data as are currently available. This review was followed by a study of the features of the pumps specified for the Heber installation and the effects of operation and the environment on those features as they relate to anticipated failure rates and repair times. From this, determinations were made for <b>mean</b> <b>failure</b> <b>rate</b> and repair time values appropriate to specific Heber pumps. Range factors are then selected and used to establish the expected variability of the data. Failure rates and repair times were then combined to obtain the unavailability distribution of each type of pump...|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimited. This thesis describes a simple-to-use, multi-echelon, single-item, simulation model written in SLAM II. The model simulates {{the operation of}} Recoverable Items (RIs) at one or more bases and the flow of supporting RIs through a multi-echelon maintenance system. The model can be configured by the user to simulate a system consisting of one to three maintenance echelons with one to six bases. Lateral resupply is also an option. The model uses an (s- 1,s) inventory policy. The model calculates several performance measures including operational availability, mean supply response time, and time-weighted backorders. The operating time for each RI is a exponential random variable. The <b>mean</b> <b>failure</b> <b>rate</b> is input by the user and may be different for each base. Each maintenance echelon has a single queue where failed RIs wait for an available maintenance stationserver. Each echelon can have any number of servers {{as determined by the}} user. The default distribution for repair time is the lognormal but other distributions can be used. The shipping times between all bases and echelons are also determined by the user. Squadron Leader, Royal Australian Air Forc...|$|E
40|$|The {{objective}} {{in this article}} is to identify the possible motives for the high failure rate in the subject Cost Accounting, offered to undergraduate Accountancy students at the Universidade Estadual de Maringá (UEM), representing a <b>mean</b> <b>failure</b> <b>rate</b> of 42 % for the period from 2008 till 2013. The data collection technique used were questionnaires with open and closed questions and, regarding the research strategy, the Collective Subject Discourse (CSD) was used to process and analyze the data obtained in the open questions. The percentage of students who failed due to their grade and the students who failed due to absence correspond to 16 % and 27 %, respectively. Thus, for an attempt to partially analyze the students who failed due to their grade, the anxiety variable was used, with a perceived perception of approximately 60 % in the student sample, departing from the Cognitive Psychology approach based on the Information Processing Theory. For the partial analysis of the students who failed due to absence, the variable lack of dedication and disinterest was used, perceived by 47 % of the student sample, based on the Theory of Procrastination...|$|E
40|$|The {{purpose of}} this study was to {{investigate}} long-term clinical effectiveness of treating painful cracked teeth with a direct bonded composite resin restoration. The hypothesis tested was that cracked teeth treated with or without cuspal coverage showed the same performance. Forty-one patients attended a dental practice with a painful cracked tooth that was restored with a direct composite resin restoration. Twenty teeth were restored without and 21 with cuspal coverage. After 7 years, 40 teeth could be evaluated. Three teeth without cuspal coverage needed an endodontic treatment, of which 2 failed as a result of fracture. No significant differences were found for tooth or pulp survival. Three more repairable restoration <b>failures</b> were recorded. <b>Mean</b> annual <b>failure</b> <b>rate</b> of restorations without cuspal coverage was 6 %; no failures in restorations with cuspal coverage occurred (P =. 009). A direct bonded composite resin restoration can be a successful treatment for a cracked tooth...|$|R
40|$|Classical {{reliability}} analysis techniques of manufacturing and defence industries {{are not a}} perfect fit {{for the assessment of}} the reliability of services. This is partly {{due to the lack of}} proper and valid reliability testing procedures in service systems and complications faced in identifying critical service parameters. Since most prominent performance indicators of a system can be associated with the maximum overall reliability it achieves, then factors that degrade the reliability can be identified with respect to its superior peers. This study utilizes the data envelopment analysis for the evaluation of reliability in service systems with a focus on healthcare. This approach comparably evaluates the performance of a service provider over a period of time by <b>means</b> of <b>failure</b> <b>rates</b> and identifies the factors affecting unreliable time phases. Application of the proposed method is illustrated with a private Turkish hospital along with an example of failure mode and effect analysis for inpatient treatment. Publisher's VersionAuthor Post Prin...|$|R
40|$|As we {{approach}} atomic-scale logic, we must accommodate an increased rate of manufacturing defects, transient upsets, and in-field persistent <b>failures.</b> High defect <b>rates</b> demand reconfiguration to avoid defective components, and transient upsets demand online error detection to catch failures. Combining these techniques we can detect in-field persistent failures when they occur and reconfigure around them. However, since failures may be logically masked {{for long periods}} of time, persistent failures may accumulate silently; this integration of errors over time <b>means</b> the effective <b>failure</b> <b>rate</b> for persistent errors can exceed transient upset rates. As a result, logic scrubbing is necessary to prevent the silent accumulation of an undetectable number of persistent errors. We provide simple analysis to illustrate quantitatively how this phenomena can be a concern. 1...|$|R
40|$|A {{total of}} twelve {{synaptic}} connections between pairs of pyramidal neurones in layer 2 / 3 of slices of rat visual cortex maintained in vitro was investigated using whole-cell voltage recordings under visual control. The connections varied widely in strength, with the mean peak amplitudes {{of the resulting}} excitatory postsynaptic potentials (EPSPs) ranging between approximately 40 μV and 2 mV at 23 °C. The smaller mean amplitudes included a substantial proportion of apparent failures of transmission. The properties of these EPSPs were examined over a range of temperatures between 13 and 36 °C. All the connections became more reliable, in that they showed fewer apparent failures of transmission, and showed less trial-to-trial variability at the higher temperatures. These changes appeared to be due primarily {{to an increase in}} the mean number of transmitter quanta released per presynaptic action potential. At 36 °C most connections were relatively reliable, with a <b>mean</b> <b>failure</b> <b>rate</b> of only 16 %. Five connections showed virtually no failures (1 % or fewer) at this temperature. We conclude that quantal transmitter release is temperature dependent at these synapses, and that experiments performed at room temperature could lead to an exaggerated impression of the unreliability of transmission at central excitatory synapses...|$|E
40|$|Disturbed {{synaptic}} transmission {{contributes to}} the pathophysiology of mood disorders. Post mortem studies reported reduced expression of the synaptic vesicle protein (SVP) complexins I and II in depression. Antidepressants were found to induce the expression of these genes. Since animals with congenital susceptibility to learned helplessness provide a valid animal model of depression, we investigated the expression of different SVPs in this system by semiquantitative in situ hybridization. Rats bred for congenital learned helpless behavior (cLH, N= 6) failed to interrupt foot shock currents by lever pressing (mean 12. 3 failures out of 15 trials). These animals showed significantly lower expression of complexins I and II mRNA in hippocampal, limbic and cortical brain areas compared to not helpless animals (cNLH, N= 6) with a <b>mean</b> <b>failure</b> <b>rate</b> of 0. 83 out of 15 trials. Expression levels of complexins I and II significantly correlated with the failure rate in the test paradigm. In contrast, the expressions of synaptotagmin I and synaptophysin were found unchanged. This investigation provides a further validation of the LH model of depression. The experimental data fit well into current pathogenetic concepts of mood disorders and support the hypothesis, that complexins are pivotal players in the pathophysiology of depression and tentative targets of antidepressants...|$|E
40|$|The {{prevalence}} of ear disease and hearing loss is greater for Indigenous children than for their non-Indigenous counterparts. In 2009, we established a mobile ear-screening service in South Burnett, {{in which an}} Indigenous Health Worker (IHW) assesses children at school and shares results by telemedicine with ear, nose and throat (ENT) specialists, who in turn provide review and biannual surgical outreach to the community. We reviewed service data {{for the first six}} years of the service (Jan 2009 -Dec 2014), to calculate: total number of completed assessments; total number of patients failing at least one screening test; and overall proportion of failed screening assessments per annum. Subgroup analysis was conducted by usual home postcode. The service has provided 5539 screening assessments. The mean screening failure rate for children outside of postcode 4605 (Cherbourg/Murgon area) was 22 % (range 17 - 29 %) and 38 % for children living inside postcode 4605 (range 34 - 41 %). While screening activity has increased by more than 50 % since 2009, there has been a slight reduction in the proportion of children failing assessment, with the <b>mean</b> <b>failure</b> <b>rate</b> changing from 33 % in 2009 to 26 % in 2014. These early results suggest that community-based screening, integrated with specialist ENT services may improve ear and hearing health...|$|E
40|$|Background: The {{number of}} dental implant {{treatments}} increases annually. Dental implants are manufactured by competing companies. Systematic reviews and meta-analysis {{have shown a}} clear association between pharmaceutical industry funding of clinical trials and pro-industry results. So far, the impact of industry sponsorship on the outcomes and conclusions of dental implant clinical trials has never been explored. The aim {{of the present study}} was to examine financial sponsorship of dental implant trials, and to evaluate whether research funding sources may affect the annual <b>failure</b> <b>rate.</b> Methods and Findings: A systematic approach was used to identify systematic reviews published between January 1993 and December 2008 that specifically deal with the length of survival of dental implants. Primary articles were extracted from these reviews. The <b>failure</b> <b>rate</b> of the dental implants included in the trials was calculated. Data on publication year, Impact Factor, prosthetic design, periodontal status reporting, number of dental implants included in the trials, methodological quality of the studies, presence of a statistical advisor, and financial sponsorship were extracted by two independent reviewers (kappa = 0. 90; CI 95 % [0. 77 – 1. 00]). Univariate quasi-Poisson regression models and multivariate analysis were used to identify variables that were significantly associated with <b>failure</b> <b>rates.</b> Five systematic reviews were identified from which 41 analyzable trials were extracted. The <b>mean</b> annual <b>failure</b> <b>rate</b> estimate was 1. 09 %. (CI 95 % [0. 84 – 1. 42]). The funding source was not reported in 63 % of the trials (26 / 41). Sixty-six percent of the trials were considered as having a risk of bias (27 / 41) ...|$|R
40|$|OBJECTIVES: To {{investigate}} the survival {{over a five-year}} period of posterior resin composite restorations placed by students. METHODS: Class I and II resin composite restorations placed by second-fourth year dental students were evaluated. Patients attended the dental school every 6 months for a regular check-up during which all restorations were checked on their clinical acceptability. In case of replacement or repair of a restoration, this was registered in the patient's record. From each record the survival time and reasons for failure of resin composite restorations were gathered. RESULTS: Seven-hundred three posterior resin composite restorations in 382 patients (49 % female and 51 % male, age 22 - 78) were evaluated. At 5 years 560 of the 703 restorations were still considered to be "clinically acceptable". Forty-nine restorations were considered as "functionally present", of which 44 were restored with a crown and four had received a new restoration adjacent to the existing restoration without its removal. Ninety-four restorations had failed. The main reasons for failure were restoration fracture, caries, endodontic treatment, defective margin and lack of proximal contact. The survival rate of the restorations was 87 % at 5 years, resulting in an annual <b>failure</b> <b>rate</b> of 2. 8 %. CONCLUSIONS: Dental students are able to place resin composite restorations in posterior teeth with an acceptable <b>mean</b> annual <b>failure</b> <b>rate...</b>|$|R
40|$|ABSTRACT: Treatment of latent {{tuberculosis}} (TB) infection with 3 months of rifampicin/isoniazid {{is a major}} part of preventive TB programmes. The effectiveness of treatment of latent TB infection can only be assessed by rates of subsequent breakdown and there are few outcome data for this combination of rifampicin/isoniazid. Therefore, the aim {{of the present study was}} to estimate the <b>failure</b> <b>rate</b> following treatment for the latent TB infection. A questionnaire survey was carried out in all parents of children aged, 16 yrs who completed treatment for latent TB infection at Leicester Royal Infirmary (Leicester, UK) over the period 1997 – 2003. Cases of treatment failure were identified by reviewing all re-referrals to the clinic, identifying children developing TB while on treatment and by postal questionnaire to all patients discharged. Of the 400 eligible children, 344 (86 %) replied. Three children who had latent TB infection subsequently developed TB disease over the time period. Of those three patients, one developed chest radiograph signs at the end of treatment and two presented with symptoms within 2 yrs of completing treatment. Overall, the <b>mean</b> treatment <b>failure</b> <b>rate</b> was 0. 87 % (95 % confidence interval 0. 3 – 2. 5) or 2. 2 cases per 1, 000 patient-yrs. In conclusion, rates of tuberculosis breakdown after treatment for {{latent tuberculosis}} infection with 3 months rifampicin/isoniazid are acceptably low...|$|R
40|$|OBJECTIVE — We {{sought to}} {{document}} the secondary failure rate of metformin monotherapy in a clinical practice setting and to explore factors that predict therapeutic failure. RESEARCH DESIGN AND METHODS — We studied 1, 799 type 2 diabetic patients who, between 2004 and 2006, lowered their A 1 C to � 7 % after initiating metformin monotherapy as their first-ever anti-hyperglycemic drug. We examined all A 1 C values recorded through 31 December 2008 (2 – 5 years of follow-up), defining secondary failure as a subsequent A 1 C � 7. 5 % or the addition or substitution of another anti-hyperglycemic agent. We used logistic regression to identify factors associated with the probability of secondary failure. RESULTS — Of the 1, 799 patients studied, 42 % (n � 748) experienced secondary failure; the <b>mean</b> <b>failure</b> <b>rate</b> was 17 % per year. However, patients who initiated metformin within 3 months of diabetes diagnosis failed at an age-and A 1 C-adjusted rate of 12. 2 % (10. 5 – 14. 4 %) per year, and patients who initiated while A 1 C was � 7 % failed at an adjusted rate of 12. 3 % per year. An interaction term between duration of diagnosed diabetes and A 1 C was not significant. Age, duration, and A 1 C at initiation were the only factors that predicted secondary failure. CONCLUSIONS — Although metformin failure may occur more rapidly in clinical practic...|$|E
40|$|Basal ganglia are {{interconnected}} subcortical nuclei, {{connected to}} the thalamus and all cortical areas involved in sensory motor control, limbic functions and cognition. The striatal output neurones (SONs), the major striatal population, are believed to act as detectors and integrators of distributed patterns of cerebral cortex inputs. Despite the key role of SONs in cortico-striatal information processing, {{little is known about}} their local interactions. Here, we report the existence and characterization of electrical and GABAergic transmission between SONs in rat brain slices. Tracer coupling (biocytin) incidence was high during the first two postnatal weeks and then decreased (postnatal days (P) 5 – 25, 60 %; P 25 – 30, 29 %; n = 61). Electrical coupling was observed between 27 % of SON pairs (coupling coefficient: 3. 1 ± 0. 3 %, n = 89 at P 15) and as shown by single-cell RT-PCR, several connexin (Cx) mRNAs were found to be expressed (Cx 31. 1, Cx 32, Cx 36 and Cx 47). GABAergic synaptic transmission (abolished by bicuculline, a GABAA receptor antagonist) observed in 19 % of SON pairs (n = 62) was reliable (<b>mean</b> <b>failure</b> <b>rate</b> of 6 ± 3 %), precise (variation coefficient of latency, 0. 06), strong (IPSC amplitudes of 38 ± 12 pA) and unidirectional. Interestingly, electrical and chemical transmission were mutually exclusive. These results suggest that preferential networks of electrically and chemically connected SONs, might be involved in the channelling of cortico-basal ganglia information processing...|$|E
40|$|To {{achieve an}} {{efficient}} risk management of a drinking water system {{the entire system}} has to be considered, from source to tap. An important part of risk management is to identify hazards and estimate risks, i. e. to conduct risk analyses. In order to provide a relevant basis for evaluating risks and efficiently prioritising risk-reduction options, a risk analysis needs to properly consider interaction between different parts and components of the system. This is especially important in complex systems. Logic tree models have the capability of properly reflect system functionality as well as facilitating quantification of risk levels. A fault tree model was therefore constructed for an integrated and probabilistic risk analysis of the drinking water system in Göteborg, Sweden. The main (top) event studied in the analysis was supply failure, which included quantity and quality failures. Quantity failure occurs when no water is delivered to the consumer and quality failure when water is delivered but {{unfit for human consumption}} according to existing water quality standards. Hard data and expert judgements were used for estimating probabilities of events, consequences and uncertainties of estimates. Monte Carlo simulations were used for the calculations in order to facilitate uncertainty analysis of risk levels. The risk analysis provided information on the probability of failure, <b>mean</b> <b>failure</b> <b>rate</b> and mean downtime of the system. The number of people affected was also included in the fault tree and risk levels were expressed as Costumer Minutes Lost. The primar...|$|E
50|$|On September 21, 2005, the 613 Institute of AVIC debuted the 2nd {{generation}} FILAT pod {{that has}} already been in Chinese service during Beijing International Air Show. The 2nd generation FILAT utilizes a new Staring array and increased its air-to-air capability. However, the developer admitted that the <b>Mean</b> time between <b>failures</b> <b>rate</b> is still much lower than the 662 hours of Sniper Advanced Targeting Pod and the operation life is also much lower than the 10,000 hours of Sniper Advanced Targeting Pod, though the actual numbers were not given. At the 6th Zhuhai Airshow in 2006, the 3rd generation of FILAT was debuted and for security reasons, very little information was released except that newer microelectronics have been used to improve reliability and other performance parameters.|$|R
25|$|<b>Mean</b> {{time between}} <b>failures</b> (MTBF) does not {{indicate}} reliability; the annualized <b>failure</b> <b>rate</b> is higher and usually more relevant.|$|R
30|$|Assess the {{reliability}} indices of product. For example, assess {{the reliability}} level, reliable life, <b>mean</b> time between <b>failures</b> (MTBF), and <b>failure</b> <b>rate.</b>|$|R
40|$|Purpose: To {{assess the}} {{literature}} on accuracy and clinical performance of computer technology applications in surgical implant dentistry. Materials and Methods: Electronic and manual literature searches were conducted to collect information about (1) the accuracy and (2) clinical performance of computer-assisted implant systems. Meta-regression analysis was performed for summarizing the accuracy studies. Failure/complication rates were analyzed using random-effects Poisson regression models to obtain summary estimates of 12 -month proportions. Results: Twenty-nine different image guidance systems were included. From 2, 827 articles, 13 clinical and 19 accuracy studies were included in this systematic review. The meta-analysis of the accuracy (19 clinical and preclinical studies) revealed a total mean error of 0. 74 mm (maximum of 4. 5 mm) at the entry point in the bone and 0. 85 mm at the apex (maximum of 7. 1 mm). For the 5 included clinical studies (total of 506 implants) using computer-assisted implant dentistry, the <b>mean</b> <b>failure</b> <b>rate</b> was 3. 36 % (0 % to 8. 45 %) after an observation period of at least 12 months. In 4. 6 % of the treated cases, intraoperative complications were reported; these included limited interocclusal distances to perform guided implant placement, limited primary implant stability, or need for additional grafting procedures. Conclusion: Differing levels and quantity of evidence were available for computer-assisted implant placement, revealing high implant survival rates after only 12 months of observation in different indications and a reasonable level of accuracy. However, future long-term clinical data are necessary to identify clinical indications and to justify additional radiation doses, effort, and costs associated with computer-assisted implant surgery...|$|E
40|$|The life-long {{supply of}} blood cells {{depends on the}} {{long-term}} function of hematopoietic stem cells (HSCs). HSCs are functionally defined by their multi-potency and self-renewal capacity. Because of their self-renewal capacity, HSCs were thought to have indefinite lifespans. However, there is increasing evidence that genetically identical HSCs differ in lifespan and that the lifespan of a HSC is predetermined and HSC-intrinsic. Lifespan is here defined as the time a HSC gives rise to all mature blood cells. This raises the intriguing question: what controls the lifespan of HSCs within the same animal, exposed to the same environment? We present here a new model based on reliability theory {{to account for the}} diversity of lifespans of HSCs. Using clonal repopulation experiments and computational-mathematical modeling, we tested how small-scale, molecular level, failures are dissipated at the HSC population level. We found that the best fit of the experimental data is provided by a model, where the repopulation failure kinetics of each HSC are largely anti-persistent, or mean-reverting, processes. Thus, failure rates repeatedly increase during population-wide division events and are counteracted and decreased by repair processes. In the long-run, a crossover from anti-persistent to persistent behavior occurs. The cross-over is due to a slow increase in the <b>mean</b> <b>failure</b> <b>rate</b> of self-renewal and leads to rapid clonal extinction. This suggests that the repair capacity of HSCs is self-limiting. Furthermore, we show that the lifespan of each HSC depends on the amplitudes and frequencies of fluctuations in the failure rate kinetics. Shorter and longer lived HSCs differ significantly in their pre...|$|E
40|$|Abstract We {{construct}} a probability model for rupture times on a recurrent earthquake source. Adding Brownian perturbations to steady tectonic loading produces a stochastic load-state process. Rupture {{is assumed to}} occur when this process reaches a critical-failure threshold. An earthquake relaxes the load state to a characteristic ground level and begins a new failure cycle. The load-state process is a Brownian relaxation oscillator. Intervals between events have a Brownian passage-time distribution that {{may serve as a}} temporal model for time-dependent, long-term seismic forecasting. This distribution has the following noteworthy properties: (1) the probability of immediate rerupture is zero; (2) the hazard rate increases steadily from zero at t � 0 to a finite maximum near the mean recurrence time and then decreases asymptotically to a quasi-stationary level, in which the conditional probability of an event becomes time independent; and (3) the quasi-stationary failure rate is greater than, equal to, or less than the <b>mean</b> <b>failure</b> <b>rate</b> because the coefficient of variation is less than, equal to, or greater than 1 / � 2 � 0. 707. In addition, the model provides expressions for the hazard rate and probability of rupture on faults for which only a bound can be placed on the time of the last rupture. The Brownian relaxation oscillator provides a connection between observable event times and a formal state variable that reflects the macromechanics of stress and strain accumulation. Analysis of this process reveals that the quasi-stationary distance to failure has a gamma distribution, and residual life has a related exponential distribution. It also enables calculation of “interaction ” effects due to external perturbations to the state, such as stress-transfer effects from earthquakes outside the target source. The influence of interaction effects on recurrence times is transient and strongly dependent on when in the loading cycle step perturbations occur. Transient effects may be much stronger than would be predicted by the “clock change ” method and characteristically decay inversely with elapsed time after the perturbation...|$|E
40|$|A {{discrete}} imperfect repair {{model is}} studied, {{it consists of}} units that try to perform jobs dynamically in time and that at failure may be repaired and are allowed {{to try to do}} again the jobs in which they failed until either eventual completions of the corresponding jobs or unsuccessful repairs of failed units. Of interest then is the numbers of completed jobs by the units before the occurrences of unsuccessful repairs, that is, the waiting times for an unsuccessful repair in the model. In many practical situations some information about the model is provided in the form of parameters. These parameters are usually quantities that indicate different levels of difficulty of the units in performing the jobs and the chances of repairing successfully failed units at any particular jobs time. In this work we first characterize, by <b>means</b> of <b>failure</b> <b>rates,</b> the distribution of the waiting times for an unsuccessful repair in terms of those parameters. Then we find necessary conditions on the parameters of two models that yield stochastical improvements of the numbers of completed jobs of the units of one model with respect to the other model. Using those results some ageing properties for the waiting times for an unsuccessful repair can be inferred from the parameters of the model. A class of discrete multivariate increasing <b>failure</b> <b>rate</b> distributions is also introduced and discussed. Some particular cases of the model are studied in some detail, and examples, counterexamples, and illustrations are given throughout the work...|$|R
40|$|Placing restorations due to {{dental caries}} {{is still a}} {{commonly}} performed treatment by dental practitioners in Norway. The aim of this thesis was to explore dentists’ treatment decisions on approximal caries and to assess the longevity of approximal restorations in posterior teeth and reasons for their failure. The research employed a questionnaire and included a practice-based study. The questionnaire revealed that, in 2009, 7 % of Norwegian dentists would restore approximal lesions confined to enamel, compared with (in similar studies) 18 % in 1995 and 66 % in 1983. A saucer-shaped preparation technique was most favoured in 2009. As restorative material, resin composite was preferred by 95 % of the dentists. In the practice-based study, amalgam (not today permitted) was placed significantly more often in male patients with caries experience (DMFT) and severe caries, and in molars. After an average follow-up period of 4. 6 yr, the <b>mean</b> annual <b>failure</b> <b>rate</b> was 2. 9 % for resin-composite restorations and 1. 6 % for amalgams. Multilevel Cox-regression analyses identified patient age, caries experience, deep cavity, saucer-shaped preparation technique and one brand of resin-composite as factors predisposing to reduced longevity of resin-composite restorations. Taking all relevant factors into account, dentists could improve the longevity of their restorations...|$|R
40|$|The {{local control}} of desmoid tumors {{constitutes}} a continuing treatment dilemma {{due to its}} high recurrence rates. The purpose of this systematic review was to critically examine the current treatment of these rare tumors and to specifically evaluate the local <b>failure</b> and response <b>rates</b> of surgery, radiation and systemic therapy. We comprehensively searched the literature for relevant studies across Cinahl, Embase, Medline and the Cochrane databases. Articles were categorized as surgery, radiation, surgery + radiation and systemic therapy (including cytotoxic and non cytotoxic). Methodological quality of included studies was assessed using the Newcastle-Ottawa Scale. Pooled odd ratios (OR) for comparative studies and weighted proportions with 95 % confidence intervals (CI) are reported. Thirty-five articles {{were included in the}} final analysis. Weighted <b>mean</b> local <b>failure</b> <b>rates</b> were 22 % [95 % CI (16 - 28 %) ], 35 % [95 % CI (26 - 44 %) ] and 28 % [95 % CI (18 - 39 %) ] for radiation alone, surgery alone and surgery + radiation respectively. In the analysis of comparative studies, surgery and radiation in combination had lower local <b>failure</b> <b>rates</b> than radiation alone [OR 0. 7 (0. 4, 1. 2) ] and surgery alone [OR 0. 7 (0. 4, 1. 0) ]. Weighted mean stable disease rates were 91 % [95 % CI (85 - 96 %) ] and 52 % [95 % CI (38 - 65 %) ] for non cytotoxic and cytotoxic chemotherapy respectively. The current evidence suggests that surgery alone has a consistently high rate of local recurrence in managing extra-abdominal desmoid tumors. Radiation therapy in combination with surgery improves local control rates. However, the limited data on systemic therapy for this rare tumor suggests the benefit of using both cytotoxic and non cytotoxic chemotherapy to achieve stable disease...|$|R
