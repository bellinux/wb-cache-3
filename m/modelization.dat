795|34|Public
50|$|Advanced Object <b>Modelization.</b>|$|E
5000|$|European Association for the <b>Modelization</b> of Complexity, MCX, Paris ...|$|E
5000|$|<b>Modelization</b> {{tool set}} (clipping plane, 2D projection, {{measurement}} tool, colors, view shot,…) ...|$|E
40|$|Much {{has been}} written in the {{economic}} literature about the theoretical and empirical effects of schooling on economic growth. Using different approaches, such as structural <b>modelizations,</b> and OLS and IV regressions, this subject has been giving contradictory results, using different databases and regression specifications...|$|R
30|$|Fractional {{calculus}} (see [1]) {{offers a}} very suggestive and stimulating scenario {{where we have}} the convergence of deep and fundamental mathematical questions, development of appropriate numerical algorithms, {{as well as the}} applications to <b>modelizations</b> in different frameworks. An illustration of the physical applications of fractional calculus is the recent following books and special issues on applications on nanotechnology and other important topics [2 – 6], among many others.|$|R
40|$|Projet M 3 NWe {{present in}} this report two <b>modelizations</b> of {{vibrational}} relaxation processes in a gaz: the Landau-Teller (LT) model and the master equations (ME). We give different models for VT and VV rate constants. We propose an algorithm to solve the equations of vibrational relaxation (LT or ME) coupled with conservation equations of momentum and total energy. Both models are compared on the computations of the flows around an infinite cylinder, at different Mach numbers...|$|R
5000|$|RayXpert"3D <b>modelization</b> {{software}} that calculates the gamma dose rate by Monte Carlo" ...|$|E
50|$|One of the {{objectives}} of systems biology is the <b>modelization</b> of biological processes using mathematics and computer simulation. The production of data from techniques of genomic analysis is not always amenable to interpretation mainly due {{to the complexity of}} the data and the large amount of data points. <b>Modelization</b> can handle the data and allow to test a hypothesis (for example, gene A is regulated by protein B) that can be verified experimentally.|$|E
50|$|With {{regards to}} training, SystemX is {{interested}} in academic-industrial relationships concerning the “systems, <b>modelization,</b> complexity” challenges - at the bachelor, master and PhD levels.|$|E
40|$|The {{development}} of nonlinear models might yield better {{insight into the}} dynamics of substance use-related disorders than linear models. Nonlinear <b>modelizations</b> are, however, not always easily intelligible. A metaphor is presented illustrating a nonlinear conceptualization of the {{development of}} drug addiction based on recent findings on neural plasticity. Ruts are described as correlates of especially strong mnesic traces, which function as attractors, and hegemonize cognitions and behavior toward drug use. Dopaminergic activity of addictive drugs is proposed to represent the weight of vehicles tracing ruts...|$|R
40|$|One of {{the major}} {{applications}} of the Domain Decomposition Time Marching Algorithm is the coupling of the Navier-Stokes systems with Boltzmann equations in order to compute transitional flows. Another important application, is the coupling of a global Navier-Stokes problem with a local one {{in order to use}} different <b>modelizations</b> and/or discretizations. Both of these applications involve a global Navier-Stokes systems with non standard boundary conditions. The purpose of this work is to prove, using the classical Leray-Schauder theory, that these boundary conditions are admissible and lead to a well posed problem...|$|R
40|$|Different {{types of}} observations, {{together}} with consistent and physical <b>modelizations,</b> suggest as realistic {{the hypothesis of}} enrichement of galactic nuclei by mean of massive globular clusters orbitally decayed and merged in the inner regions of early type galaxies. In this context, the scenario of globular cluster mergers and subsequent formation of a dense Super Star Cluster {{in the center of}} a triaxial galaxy is presented and discussed, together with its astrophysical implications, including that of massive black hole feeding and accretion {{in the center of a}} triaxial galaxy. © 2007 American Institute of Physics...|$|R
5000|$|... "The judge's {{discourse}} : {{research on}} the <b>modelization</b> of reasoning in law", in Artificial Intelligence and Legal Information Systems, vol. 1, C. Ciampi (ed.), North-Holland, Amsterdam, 1982 ...|$|E
50|$|The {{subjects}} taught include the mathematical bases of Statistics, Actuary and Econometry. The {{students of the}} faculty are provided with knowledges in <b>modelization</b> and data processing, applied in the domains of Health and Insurance.|$|E
50|$|This <b>modelization</b> {{gave the}} basis for the massive {{retaliation}} nuclear doctrine. The zero-sum fallacy and cooperative games would be theorized only later, while the evolution of nuclear technology and missiles made the massive retaliation nuclear strategy obsolete.|$|E
40|$|It seems {{reasonable}} to believe that problem solving with the Tower of Hanoi (TOH) task has been studied thoroughly enough to be well understood. Yet, {{the discovery of a}} new class of affordance-based strategies was reported recently (Guimberteau, 2003), with the finding that problem solving strategies issued from that class are capable of explaining the famous TOH protocol from Anzai & Simon (1979). The above discovery enriches the set of known strategies for the task, formalized several decades ago (Simon, 1975). Importantly, it also raises an issue, given the prolific nature of the research area concerned with problem solving with the TOH task: Why has not the new class been specified earlier? Such a question may be dismissed on the grounds that certain aspects of scientific inquiry are not explainable. Another approach is to consider that question closely, as an opportunity to learn from the past. The present analysis takes a first step in the latter direction. It examines past <b>modelizations</b> of Anzai & Simon (1979) ’s first problem solving episode (Episode 1), looking for clues to explain why those <b>modelizations</b> have not considered the affordance-driven explanation of the learner’s problem solving behavior. The strategy put forth to explain Episode 1 – Selective Search – constitutes a classic result in the cognitive science literature. The strategy simplifies search by not repeatin...|$|R
40|$|After {{having been}} a term of {{reflection}} in philosophy as well as psychology for ages, the fascination with human wisdom finally reaches the realms of computer science. In comparison to the first philosophical definition attempts, that date back to Aristotle (384 BC – 322 BC), the efforts in information science during the late 1980 s seem quite recent. Nevertheless have there been astonishing new insights provided by cognitive science since those first formal <b>modelizations</b> were designed – findings that strongly suggest a reconsideration of our current formalization of wisdom in the computer science domain. We suggest to establish a new, integrated view {{on the concept of}} wisdom, using the insights of cognitive sciences. Furthermore, we discuss possible measures that are able to cover at least fundamental properties of wisdom including its vague aspects...|$|R
40|$|In {{this paper}} {{we try to}} show that {{adaptation}} is a necessary behaviour feature to use when cooperation between agents is expected. We work with a widely used formal model coming from Game Theory: The classical iterated prisoner’s dilemma. We first describe the model, strategies, which are <b>modelizations</b> of behaviour, evaluation methods and some well known results about it. Then we introduce some new strategies which we have set up. Those new strategies have been built with adaptation in mind. We try to show through some experiments results {{that they seem to}} be more efficient as well as more robust than established strategies. Analysing those results leads us to state that adaptation is a complex task to achieve, but that {{it seems to be a}} key feature in agent behaviour, cooperation in multi-agent systems and furthermore in intelligence. ...|$|R
50|$|Starting {{from the}} {{analysis}} of motivations for organizational growth (1965b, 1966), Starbuck attempted a mathematical <b>modelization</b> of “organizational metamorphosis” (1968a, 1973). After a thorough review of growth motivations (self-realization, risk, prestige, executives incomes, profit, cost, monopoly, stability, and survival), Starbuck wondered : “Are goals producing growth, or is it growth that produces the goals ?” (1965b, p. 465).|$|E
50|$|Every auto maker who had {{any kind}} of {{presence}} at the show offered a glimpse {{into some kind of}} intelligent, driver-free technology, from parking to advanced object recognition. Audi showed four generations of driver-assist automated car tech. Unlike 3D TV, which has disappeared from the announcements at the CES 2015, 3D visualization is now more specialized and target the B2B environment, from <b>modelization</b> to immersive glasses and helmets for architects, healthcare specialists or gamers.|$|E
5000|$|Measurements {{with modern}} high-precision {{geodetic}} techniques and <b>modelization</b> of the measurements by the horizontal motions of independent rigid plates {{at the surface}} of a globe of free radius, were proposed as evidence that Earth is not currently increasing in size to within a measurement accuracy of 0.2 mm per year. The lead author of the study stated [...] "Our study provides an independent confirmation that the solid Earth is not getting larger at present, within current measurement uncertainties".|$|E
40|$|International audienceThe {{magnetic}} fluctuations, at the magnetopause and in {{the adjacent}} magnetosheath, exhibit power law spectra which are very reminiscent of turbulent spectra. In prospect of future <b>modelizations</b> of such a turbulence, new information is brought about the experimental properties of these fluctuations. The power laws spectra previously obtained in the ULF range are shown to hold also in VLF, up to the lower hybrid frequency. Concerning the polarization, 1) the direction {{with respect to the}} static magnetic field is shown to be dominantly perpendicular at low frequencies, consistently with Shear Alfven modes in this range, and 2) no right-hand sense of rotation can be evidenced at frequencies higher than the proton gyrofrequency, although one could expect the fast magnetosonic mode to be dominant in this range. The physical implications of this last observation for the non linear effects at work in the turbulence are briefly discussed...|$|R
40|$|International audienceA {{reactivity}} computation {{consists of}} computing the highest eigenvalue of a generalized eigenvalue problem, for which an inverse power algorithm is commonly used. Very fine <b>modelizations</b> {{are difficult to}} treat for our sequential solver, based on the simplified transport equations, in terms of memory consumption and computational time. A first implementation of a Lagrangian based domain decomposition method brings to a poor parallel efficiency because {{of an increase in}} the power iterations. In order to obtain a high parallel efficiency, we improve the parallelization scheme by changing the location of the loop over the subdomains in the overall algorithm and by benefiting from the characteristics of the Raviart-Thomas finite element. The new parallel algorithm still allows us to locally adapt the numerical scheme (mesh, finite element order). However, it can be significantly optimized for the matching grid case. The good behavior of the new parallelization scheme is demonstrated for the matching grid case on several hundreds of nodes for computations based on a pin-by-pin discretization...|$|R
40|$|International audienceQuasi-thermal noise {{spectroscopy}} is {{an efficient}} tool for measuring in situ macroscopic plasma properties in space, using a passive wave receiver at the ports {{of an electric}} antenna. This technique was pioneered on spinning spacecraft carrying very long dipole antennas in the interplanetary medium—like ISEE- 3 and Ulysses—whose geometry approached a “theoretician's dream. ” The technique has been extended to other instruments in various types of plasmas on board different spacecraft and will be implemented on several missions in the near future. Such extensions require different theoretical <b>modelizations,</b> involving magnetized, drifting, or dusty plasmas with various particle velocity distributions and antennas being shorter, biased, or made of unequal wires. We give new analytical approximations of the plasma quasi-thermal noise (QTN) and study how {{the constraints of the}} real world in space can (or cannot) be compatible with plasma detection by QTN spectroscopy. We consider applications to the missions Wind, Cassini, BepiColombo, Solar Orbiter, and Parker Solar Probe...|$|R
5000|$|Laws of {{economics}} are an attempt in <b>modelization</b> of economic behavior. Marxism criticized {{the belief in}} eternal [...] "laws {{of economics}}", which it considered {{a product of the}} dominant ideology. It claimed that in fact, those so-called [...] "laws of economics" [...] were only the historical laws of capitalism, that is of a particular historical social formation. With the advent, in the 20th century, of the application of mathematical, statistical, and experimental techniques to economics, economic theory matured into a corpus of knowledge rooted in the scientific method rather than in philosophical argument.|$|E
5000|$|... “The {{problem with}} most {{organizational}} growth models”, Starbuck concluded, “is that they imply {{a certain degree}} of predestination and autonomy which is difficult to reconcile with direct observation” (1965b, p. 494). The contrariety with process-decision models came from a focus on immediate and unique problems, leaving long-term evolutions emerging as by-products of short-term decisions. Thus, recognizing and underlining that little was done to take into account long-term learning, Starbuck searched models that would embrace the totality of the phenomenon from its emergence to its extinction. Metamorphic models seemed promising because they left room for unforeseen and fast adjustments, gave attention to details, to non-linearity and to intrinsic regulations that would take place in the course of action. Starbuck’s predilection for experimentation, and his abilities in mathematics, naturally led him to the works of Russian mathematician Lev Pontryagin (1961). Pontryagin demonstrated that it is more parsimonious to describe a revolution in three distinct groups of equations — each of them becoming comparatively more simple, instead of trying to put together a single algorithm for the totality of the phenomenon. These three systems would describe (a) a slow transformation before the revolution, (b) a fast transformation during the revolution, and (c) a slow transformation after the revolution, deriving these three phases from the <b>modelization</b> of burning of an electric bulb. Borrowing from this model, Starbuck discovered that better results are obtained when fine adjustments are successively introduced in the <b>modelization</b> process (1973: p. 108).|$|E
50|$|They {{are also}} {{characterized}} by non-parabolic energy-momentum dispersion that makes possible the parabolic effective-mass approximation only valid {{in a limited}} momentum range, and have a spin degree-of-freedom making them spinorial fluids able to sustain different polarization textures. Exciton-polaritons are composite bosons which can be observed to form Bose-Einstein condensates, to sustain polariton superfluidity and quantum vortices and are prospected for emerging technological applications. Many experimental works currently focus on polariton lasers, optically addressed transistors, nonlinear states such as solitons and shock waves, long-range coherence properties and phase transitions, quantum vortices and spinorial patterns. <b>Modelization</b> of exciton-polariton fluids mainly rely {{on the use of}} GPE (Gross-Pitaevskii equations) which are in the form of nonlinear Schrödinger equations.|$|E
40|$|Until {{present the}} study of the form factors {{associated}} to the vector and axial–vector components of the hadronic weak current has been carried out with a plethora of <b>modelizations</b> of the underlying strong interactions. While of importance to get an understanding of the dynamics involved, the amount and quality of the experimental data start to show some discrepancies with the analysed models. Moreover, and from a theoretical point of view, most of these models are not consistent with quantum chromodynamics (QCD). We propose a QCD–based model–independent procedure to analyse those decays through the use of the resonance chiral theory, the low– energy effective action of QCD in the relevant resonance region. Within this framework we study the hadronic off–shell width of the ρ meson and the vector form factor of pion in τ − → π − π 0 ντ. We also comment on the τ − → (πππ) − ντ decay. 1...|$|R
40|$|Since {{pneumatic}} membrane {{is usually}} flexible, wind loading on {{it should be}} determinedin due consideration {{of the interaction between}} wind and the structure. Analytical methodas interaction system is undertaken here, introducing some <b>modelizations</b> about wind. Someflow pattern models with due regard to the separation flow and wake were set herein incorrespondence with the state of high Reynolds number and numerical calculations werecarried out, applying them to solid cylinder first. It was depicted that numerical result withregard to one flow model shows quite good agreement with Roshko's experimental results. Thence, applying this flow model to the membrane, the interaction analysis was prosecuted,and some design charts about wind pressure distribution, deflections and stresses of themembrane were presented concerning to the several design parameters. Wind tunnelexperimental results are also presented in order to verify the adequency of the inodelizationabout wind. And moreover, the possibility of the representation of wind pressure distributionby a simple function is discussed...|$|R
40|$|A {{recently}} introduced analytical {{model for the}} nuclear density profile[1] is implemented in the Extended Thomas-Fermi (ETF) energy density functional. This allows to (i) shed a {{new light on the}} issue of the sign of surface symmetry energy in nuclear mass formulas, which is strongly related to the non-uniformity of the isospin asymmetry in finite nuclei, as well as to (ii) evaluate the in-medium corrections to the nuclear cluster energies in thermodynamic conditions relevant for the description of the (proto) -neutron star crust. The ground state configurations of the model are compared to Hartree-Fock calculations in spherical symmetry for some selected isotopic chains, and systematic errors are quantified. The in-medium modification of the nuclear mass due to the presence of a gas component is shown to strongly depend both on the density and the asymmetry of the nucleon gas. This shows the importance of accounting for such effects in the realistic <b>modelizations</b> of the equation of state for core-collapse supernovae and proto-neutron stars. Comment: 15 pages, 9 figure...|$|R
40|$|Grammar is a {{historically}} and conceptually defined technique - describing a human activity - {{in which a}} <b>modelization</b> is applied to a body of linguistic phenomena. The <b>modelization,</b> involving a macrostructural and microstructural organization {{and a number of}} decisions, is coupled with three types of strategies: analytical strategies, presentational strategies, and strategies with an eye at (grammar) acquisition. Beyond this <b>modelization</b> and the correlated strategies, grammar is conditioned by a number of 'material' factors, such as the cultural setting, the linguistic structure of the language(s) described and the writing system used. status: publishe...|$|E
40|$|A {{methodology}} for the <b>modelization</b> of final rings of the freight distribution is proposed, {{the analysis of}} connection infrastructures, as the harbours, is developed, using a methodology proposed in literature for the <b>modelization</b> with graphs of the intermodal terminals, then a multi-step model is proposed to simulate urban freight transport...|$|E
30|$|Jacques Gignoux, and Sébastien Barot are {{specialists in}} plant ecology, biostatistics, and <b>modelization.</b>|$|E
40|$|A general {{method for}} testing {{nonlinearity}} in time series is described {{and applied to}} measurements of different pressure data inside the draft tube surge of a real Francis turbine. Comparing the current original time series to an ensemble of surrogates time series, suitably constructed to mimic the linear properties of the original one, we was able to distinguish a linear stochastic from a nonlinear deterministic behaviour and, moreover, to quantify the degree of nonlinearity present in the related dynamics. The problem of detecting nonlinear structure in real data is quite complicated by the influence of various contaminations, like broadband noise and/or long coherence times. These difficulties have been overcame using {{the combination of a}} suitable nonlinear filtering technique and a qualitative redundancy statistic analysis. The above investigations allow a quantitative characterization of different dynamical regimes of motion of gas cavities inside real turbines and, moreover, allow to support the reliability of some related mathematical <b>modelizations.</b> Comment: uuencoded compressed postscript file, 12 pages paper with included figures. (source file: 4. 9 Mb...|$|R
40|$|AbstractAssuming {{that the}} radial {{excitations}} of q¯q meson states exactly follow linear Regge trajectories with constant residues, as prescribed by dual models, and using large Nc arguments and the matching to perturbative QCD in the deep-Minkowski region we obtain that: (a) the region dominated by resonances {{and the one}} saturated by perturbation theory approach each other as Nc increases; (b) the scales Λ(V,A) separating the resonance-dominated and the perturbative-saturated region in the V,A channels, respectively, grow as Nc, whereas the difference between (ΛV) 2 and (ΛA) 2 stays constant or even decreases as Nc increases; (c) the number of visible resonances increases as Nc; (d) {{in order to satisfy}} the Weinberg sum rules the slopes of Regge trajectories for mesons of opposite parities must coincide, but the intercepts may differ by a quantity of O(1) at most in the large Nc limit. This suggests that <b>modelizations</b> of QCD where these characteristics are not present and yet the resonances follow linear Regge trajectories are not compatible with the symmetries or short-distance properties of QCD...|$|R
40|$|The {{results of}} a {{numerical}} and analytical in-vestigation on hybrid steel truss RC beams are described. Hybrid steel truss RC beams are beams where, during the construction phase and the concrete casting (Phase I), the steel truss sys-tem only carries the vertical loads. In this con-struction phase, the verification against failure due to the instability of the upper steel bars or diagonal elements {{is the most important}} design require-ment. In the present study, four different beams are considered, with different steel trusses in Phase I condition. Finite Element <b>modelizations</b> of the structure are made and failure loads are obtained, taking into account second-order effects due to large displacements. It is shown that the stability of the steel truss strongly depends on the lateral stiffness of the diagonal elements of the truss. Analytical models for the prediction of the fail-ure load are proposed, based on the instability of a beam on elastic foundation and the lateral buck-ling due to bending moment. Starting from the proposed analytical model, some design criteria are illustrated and discussed...|$|R
