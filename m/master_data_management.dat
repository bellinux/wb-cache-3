147|10000|Public
25|$|IRI Voracity is a data {{management}} platform launched in December 2015 for data discovery, integration, migration, governance, and analytics. It consolidates key data curation {{activities in the}} IRI Workbench GUI, and transforms data in the CoSort engine or optionally in MapReduce, Spark, Storm, or Tez. Voracity includes all IRI software, and adds data profiling, ETL, meta{{data management}}, <b>master</b> <b>data</b> <b>management,</b> data federation, and multiple job design and control capabilities.|$|E
500|$|In 2002, the Text Miner {{software}} was introduced. Text Miner analyzes text data like emails for patterns in Business Intelligence applications. In 2004, SAS Version 9.0 was released, which was dubbed [...] "Project Mercury" [...] and {{was designed to}} make SAS accessible to {{a broader range of}} business users. Version 9.0 added custom user interfaces based on the user's role and established the point-and-click user interface of SAS Enterprise Guide as the software's primary graphical user interface (GUI). The Customer Relationship Management (CRM) features were improved in 2004 with SAS Interaction Management. In 2008 SAS announced Project Unity, designed to integrate data quality, data integration and <b>master</b> <b>data</b> <b>management.</b>|$|E
50|$|<b>Master</b> <b>data</b> <b>management</b> (MDM) is a {{comprehensive}} method of enabling an enterprise to link all of its critical data to one file, called a master file, that provides a common point of reference. When properly done, <b>master</b> <b>data</b> <b>management</b> streamlines data sharing among personnel and departments. In addition, <b>master</b> <b>data</b> <b>management</b> can facilitate computing in multiple system architectures, platforms and applications.|$|E
5000|$|Toward a {{functional}} reference model for <b>master</b> <b>data</b> quality <b>management</b> (with Boris Otto and Kai Hüner), Information Systems and e-Business Management (2012) ...|$|R
5000|$|... #Subtitle level 3: <b>Master</b> <b>data</b> management/Product {{information}} <b>management</b> ...|$|R
50|$|Windchill PDMLink - A web-based <b>master</b> product <b>data</b> <b>management</b> {{repository}} {{that also}} helps teams manage critical {{processes such as}} change/configuration management, and detailed design.|$|R
50|$|Other {{problems}} include (for example) {{issues with}} the quality of data, consistent classification and identification of data, and data-reconciliation issues. <b>Master</b> <b>data</b> <b>management</b> of disparate data systems requires data transformations as the data extracted from the disparate source data system is transformed and loaded into the <b>master</b> <b>data</b> <b>management</b> hub. To synchronize the disparate source master data, the managed master data extracted from the <b>master</b> <b>data</b> <b>management</b> hub is again transformed and loaded into the disparate source data system as the master data is updated. As with other Extract, Transform, Load-based data movement, these processes are expensive and inefficient to develop and to maintain which greatly reduces the return on investment for the <b>master</b> <b>data</b> <b>management</b> product.|$|E
50|$|The {{selection}} of entities considered for <b>master</b> <b>data</b> <b>management</b> depends somewhat {{on the nature}} of an organization. In the common case of commercial enterprises, <b>master</b> <b>data</b> <b>management</b> may apply to such entities as customer (customer data integration), product (product information management), employee, and vendor. <b>Master</b> <b>data</b> <b>management</b> processes identify the sources from which to collect descriptions of these entities. In the course of transformation and normalization, administrators adapt descriptions to conform to standard formats and data domains, making it possible to remove duplicate instances of any entity. Such processes generally result in an organizational <b>master</b> <b>data</b> <b>management</b> repository, from which all requests for a certain entity instance produce the same description, irrespective of the originating sources and the requesting destination.|$|E
5000|$|The tools include data networks, file systems, a data warehouse, data marts, an {{operational}} data store, data mining, data analysis, data visualization, data federation and data virtualization. One {{of the newest}} tools, virtual <b>master</b> <b>data</b> <b>management</b> utilizes data virtualization and a persistent metadata server to implement a multi-level automated <b>master</b> <b>data</b> <b>management</b> hierarchy[...].|$|E
40|$|A {{high quality}} of <b>master</b> <b>data</b> is vital for process {{automation}} and IS support in enterprises. Retailers and manufacturers have started improving their <b>master</b> <b>data</b> quality on a syntactical level. Many researchers address problems of syntactical <b>master</b> <b>data</b> quality (e. g. missing values, typo errors), but only few approaches target semantic issues of <b>master</b> <b>data</b> quality <b>management.</b> Bad semantic <b>data</b> quality {{can lead to a}} misalignment between real-world phenomena and data stored in the databases. Furthermore, semantic data quality relies on the current use of data, but {{is not limited to the}} present use of the data and its impact on existing business processes, but includes the likely future uses of the data as well. In this paper, we discuss the contribution of ontologies for identifying and assessing semantic <b>master</b> <b>data</b> quality problems. We develop a conceptual approach and procedure model for addressing the semantic <b>master</b> <b>data</b> quality problem. The method is applied within an scenario for automated coupon clearing in the retail industry...|$|R
5000|$|Hyperion <b>Master</b> <b>Data</b> Management/Oracle <b>Data</b> Relationship <b>Management</b> ...|$|R
40|$|Information about {{infrastructure}} in hospitals must be accurate, complete and relevant, {{but the current}} system  has not been optimally obtained. Now system in hospitals still use the conventional system. Conventional system was the process of storing data manually. These conventional systems make difficulties for employees to create reports, patients and visitors in search {{of information about the}} facilities and infrastructure was available at the  Hospital. System Information Infrastructures designed to help in the process of providing information that was easier for employees, patients and visitors as well as assist in the reporting process. Stages of making the system design was conducted using TAS (Total Architecture syntesis), they are determination of initial scope, determination of needs, determination of business processes, system design and evaluation. Infrastructures module has a recording process of <b>master</b> <b>data,</b> inventory <b>management</b> processes, management cleaning room, the asset management and reporting processes. This design {{can be used as a}} guide for programmers in the manufacture of Hospital Information System Integrated...|$|R
5000|$|Gartner Magic Quadrant for <b>Master</b> <b>Data</b> <b>Management</b> of Customer Data Solutions ...|$|E
5000|$|<b>Master</b> <b>Data</b> <b>Management</b> (MDM) - Global Customer Master, Global Supplier Master, Global Item Master ...|$|E
50|$|Sunopsis {{products}} provide {{solutions for}} data warehousing, data integration, data migration, data synchronization and <b>Master</b> <b>data</b> <b>management.</b>|$|E
40|$|Cycle time {{reduction}} in manufacturing using a scientific <b>data</b> <b>management</b> system E-manufacturing enables immediate {{communication between the}} various islands of shop floors, corporate business systems and laboratory information management systems so that the entire enterprise can react together to solve problems. Going paperless in manufacturing can allow one to manage the <b>master</b> <b>data</b> across the enterprise’s physical boundaries. What is needed is an application-independent, non-invasive <b>data</b> <b>management</b> system for the lab, the plant and beyond...|$|R
50|$|The {{general purpose}} of an ODS is to {{integrate}} data from disparate source systems {{in a single}} structure, using data integration technologies like data virtualization, data federation, or extract, transform, and load. This will allow operational access to the data for operational reporting, <b>master</b> <b>data</b> or reference <b>data</b> <b>management.</b>|$|R
40|$|Data is a {{valuable}} corporate asset and its effective management can be vital to success. This professional guide covers all the key areas of <b>data</b> <b>management,</b> including database development and corporate data modelling. The new edition covers web technology {{and its relation to}} databases and includes material on the <b>management</b> of <b>master</b> <b>data...</b>|$|R
5000|$|Microsoft SQL Server Master Data Services is a <b>Master</b> <b>Data</b> <b>Management</b> (MDM) {{product from}} Microsoft that ships {{as a part}} of the Microsoft SQL Server {{relational}} database management system. [...] Master Data Services (MDS) is the SQL Server solution for <b>master</b> <b>data</b> <b>management.</b> <b>Master</b> <b>data</b> <b>management</b> (MDM) enables your organization to discover and define non-transactional lists of data, and compile maintainable, reliable master lists. Master Data Services first shipped with Microsoft SQL Server 2008 R2. Microsoft SQL Server 2016 includes many enhancements to Master Data Services, such as improved performance and security, and the ability to clear transaction logs, create custom indexes, share entity data between different models, and support for many-to-many relationships. For more information, see What's New in Master Data Services (MDS) ...|$|E
5000|$|... 2005 - Hyperion acquires Razza Solutions (<b>Master</b> <b>data</b> <b>management)</b> and {{appoints}} Northdoor as a reseller in the UK and Ireland.|$|E
5000|$|... 2008 - QAD {{acquired}} FullTilt Solutions’ product suite, including Perfect Product Suite, called <b>master</b> <b>data</b> <b>management</b> (MDM) for Internet-enabled commerce.|$|E
40|$|Fifty-seven {{fundamental}} constants {{of nature}} were computerized from the up-to-date evaluations of E. R. Cohen and B. N. Taylor. The constants are annotated {{with regard to}} symbol, value, uncertainty, and scaling factor. This computerization {{is part of the}} scientific data base project of the Information Research Group at Lawrence Livermore Laboratory. The <b>MASTER</b> CONTROL <b>data</b> base <b>management</b> system is used. The computerized fundamental constants can be requested from the ERDA Computer Program Exchange and Information Center of the Argonne National Laboratory or from the National Technical Information Service of the U. S. Department of Commerce. This is {{the first of a series}} of releases on preparation of computerized scientific and technological data banks. The next release is a data bank of conversion factors for different units of measurements. 3 figures...|$|R
50|$|In 2017 the CC CDQ {{published}} another reference model {{called the}} Data Excellence Model. In {{accordance with the}} CC CDQ this was published because <b>data</b> <b>management</b> needs to broaden its scope to cover also other data types and not only <b>master</b> <b>data.</b> At the same time with this reference model they tried to extend the focus from the original focus on data quality (in the Framework for Corporate <b>Data</b> Quality <b>Management)</b> to additional aspects, such as data compliance or data risk.|$|R
40|$|In <b>Data</b> Stream <b>Management</b> Systems (DSMS) semi-stream {{processing}} {{has become}} a popular area of research due to the high demand of applications for up-to-date information (e. g. in real-time data warehousing). A common operation in stream processing is joining an incoming stream with disk-based <b>master</b> <b>data,</b> also known as semi-stream join. This join typically works under the constraint of limited main memory, which is generally not {{large enough to hold}} the whole disk-based <b>master</b> <b>data.</b> Many semi-stream joins use a queue of stream tuples to amortize the disk access to the <b>master</b> <b>data,</b> and use an index to allow directed access to <b>master</b> <b>data,</b> avoiding the loading of unnecessary <b>master</b> <b>data.</b> In such a situation the question arises which <b>master</b> <b>data</b> partitions should be accessed, as any stream tuple from the queue could serve as a lookup element for accessing the <b>master</b> <b>data</b> index. Existing algorithms use simple safe and correct strategies, but are not optimal {{in the sense that they}} maximize the join service rate. In this paper we analyze strategies for selecting an appropriate lookup element, particularly for skewed stream data. We show that a good selection strategy can improve the performance of a semi-stream join significantly, both for synthetic and real data sets with known skewed distributions...|$|R
50|$|One of the {{reference}} models developed is the Framework for Corporate Data Quality Management. This framework {{is focused on}} quality-oriented <b>master</b> <b>data</b> <b>management.</b>|$|E
50|$|TIBCO MDM is <b>master</b> <b>data</b> <b>management</b> for {{aligning}} enterprise data {{across multiple}} business units, departments and partners, synchronizing the information with downstream IT transactional systems.|$|E
5000|$|Have an {{enterprise}} view of all data, for uses such as <b>master</b> <b>data</b> <b>management,</b> where key data is needed, or data governance for improving data quality.|$|E
40|$|Product <b>master</b> <b>data</b> (PMD) can {{be defined}} as a set of data that {{represents}} a selection of characteristics and aspects of its accompanying physical product. For several reasons, these data sets are increasingly exchanged between organizations within supply chains. Although this process is traditionally often supported by non-automated technologies such as Excel spreadsheet, telephone, email, and fax, the adoption of data pools is on the rise. These inter-organizational systems allow the data supplying party to publish a product’s <b>master</b> <b>data</b> set in one centralized system after which it can be accessed by all subscribed <b>data</b> recipients. <b>Management</b> of Technolog...|$|R
50|$|<b>Master</b> <b>data</b> is {{also called}} <b>Master</b> {{reference}} <b>data.</b> This {{is to avoid}} confusion with the usage of the term <b>Master</b> <b>data</b> for original data, like an original recording (see also: <b>Master</b> Tape). <b>Master</b> <b>data</b> is nothing but unique data, i.e., there are no duplicate values.|$|R
40|$|<b>Master</b> <b>data</b> {{is present}} on many {{functions}} of modern organizations’ daily activities. It {{is used to}} support most transactional operations, including sales, invoicing, logistics, manufacturing, and customer care. <b>Master</b> <b>data</b> is the static and persistent data which describes entities {{that are relevant to}} the business of a company. <b>Master</b> <b>data</b> can be customer information, product information, or logistics routes to name a few examples. While the <b>master</b> <b>data</b> is often seen just as a basic building block of successful information system network. <b>Master</b> <b>data</b> systems are often a distributed set of systems having intricate structures. Especially when an organization reaches older age, a history of company changes reflects a lot on <b>master</b> <b>data</b> and <b>master</b> <b>data</b> systems as well. The structure of <b>master</b> <b>data</b> can change dramatically during the lifespan of an organization as it is likely to migrate from system to another and sometimes it is enriched in one system and this is not replicated back to the original system. In modern company culture the organization is likely to undergo organizational changes every now and then and this is reflected in information systems, also the ones containing <b>master</b> <b>data.</b> In this thesis we study the problems of <b>master</b> <b>data</b> in changing business environment. We study what and why causes problems with <b>master</b> <b>data,</b> and offer possible solutions to these problems by remodeling the <b>master</b> <b>data.</b> We studied the situation at Metso Mining and Construction by interviewing the current and previous <b>master</b> <b>data</b> managers. With the results of the interview we try to gather a better understanding how <b>master</b> <b>data</b> has been seen previously and how it is currently seen. Also we study how it has been modeled previously and how it is modeled currently. We learn about the lifespan of information systems, especially <b>master</b> <b>data</b> systems, varying appreciation of <b>master</b> <b>data</b> and study the need to remodel it. We also study some modeling techniques and some issues with outdated documentation are also covered. A segment of <b>master</b> <b>data,</b> customer <b>master,</b> is studied in closer detail and the segment is remodeled with the information available, here we learn the distributed structure and connecting elements of the set of <b>master</b> <b>data.</b> Also we learn the big picture about information systems and understand that where the complexity of the situation is derived from...|$|R
50|$|Amalto {{developed}} a <b>master</b> <b>data</b> <b>management</b> (MDM) product Xtentis by 2008. It {{was based on}} a native XML database and leveraged open-source technology, such as eXist XML server and JBoss.|$|E
50|$|Talend <b>Master</b> <b>Data</b> <b>Management</b> {{was created}} to help {{companies}} consolidate data across their businesses, such as product and customer data, {{in order to create}} a single “version of the truth”.|$|E
50|$|In business, <b>master</b> <b>data</b> <b>management</b> (MDM) {{comprises}} the processes, governance, policies, standards and tools that consistently define {{and manage the}} critical data of an organization to provide a single point of reference.|$|E
5000|$|<b>Master</b> <b>Data</b> Harmonisation - as for Content Consolidation, plus {{re-distribution}} of cleansed, consolidated <b>master</b> <b>data.</b>|$|R
50|$|Curating and {{managing}} <b>master</b> <b>data</b> {{is key to}} ensuring <b>master</b> <b>data</b> quality. Analysis and reporting is greatly dependent {{on the quality of}} an organization's <b>master</b> <b>data.</b> <b>Master</b> <b>data</b> may either be stored in a central repository, sourced from one or more systems, or referenced centrally using an index. However, when it is used by several functional groups it may be distributed and redundantly stored in different applications across an organization and this copy data may be inconsistent (and if so, inaccurate). Thus <b>Master</b> <b>Data</b> should have an agreed-upon view that is shared across the organization. Care should be taken to properly version <b>Master</b> <b>Data,</b> if the need arises to modify it, to avoid issues with distributed copies.|$|R
50|$|Market <b>Master</b> <b>Data</b> is {{the single}} source of common {{business}} data for an entire marketplace. Market <b>master</b> <b>data</b> is used among enterprises within the value chain. An example of Market <b>Master</b> <b>Data</b> is the UPC (Universal Product Code) found on consumer products.|$|R
