39|9145|Public
25|$|A {{few years}} before the Geek Code was published, similar codes existed for other purposes. The Natural Bears Classification System, first {{documented}} in 1989, is a similar code for the bear subculture. Like the Geek Code, it generally uses a single letter for the attribute and + or − signs for the grade. It {{was inspired by the}} Yerkes spectral classification system for describing stars. Unlike the Geek Code, the Yerkes system uses classes, subclasses and peculiarities for categorization. These systems differ in their orthogonality: the Geek Code is very orthogonal in the computer science sense (where variables may be projected onto basis vectors), where the Yerkes system is very orthogonal in the taxonomic sense (represent <b>mutually</b> <b>exclusive</b> <b>classes).</b>|$|E
5000|$|Assume for {{the moment}} {{that there are only}} two <b>mutually</b> <b>exclusive</b> <b>classes,</b> S and ¬S (e.g. spam and not spam), such that every element (email) is in either one or the other; ...|$|E
5000|$|Suppose that [...] {{observations}} {{in a random}} sample from a population are classified into [...] <b>mutually</b> <b>exclusive</b> <b>classes</b> with respective observed numbers [...] (...) , and a null hypothesis gives the probability [...] that an observation falls into the th class. So we have the expected numbers [...] for all , where ...|$|E
5000|$|The word equidimensional is {{sometimes}} used by geologists {{to describe the}} shape of three-dimensional objects. In that case it is a synonym for equant. [...] Deviations from equidimensional are used to classify the shape of convex objects like rocks or particles. [...] For instance Th. Zingg in 1935 pointed out that if a, b and c are the long, intermediate, and short axes of a convex structure, and R is a number greater than one, then four <b>mutually</b> <b>exclusive</b> shape <b>classes</b> may be defined by: ...|$|R
40|$|The {{following}} {{report will}} cover three <b>mutually</b> <b>exclusive</b> and exhaustive <b>classes</b> of knots, the torus, satellite and hyperbolic knots. The general construction of each knot {{will be treated}} in an intuitive manner. Torus and satellite knots will be explained very briefly, with the main focus {{on the construction of}} hyperbolic 3 -manifolds, culminating in an informal construction of the complement of the figure-eight knot...|$|R
40|$|AbstractIn {{this article}} the {{following}} three research questions were addressed: Firstly, Are there underlying types of motivation to lifelong learning? Secondly, are sex and learning skill are predictive of membership in types of motive toward lifelong learning?. For this research, I carried out latent classes and multinominal logistic regression. Latent class analysis (LCA) is a statistical method used to identify a set of discrete, <b>mutually</b> <b>exclusive</b> latent <b>classes</b> of individuals based on their responses {{to a set of}} observed categorical variables. I used PROC LCA, SAS procedure for latent class analysis and multinominal logistic regression. The result is following. Firstly, Six latent class is identified. Secondly, Learning Skill(p<. 05) was predictors of latent class membership. Based on research result, I proposed that learning skill be organized in curriculum of School of Engineering...|$|R
50|$|In the {{standard}} {{applications of the}} test, the observations are classified into <b>mutually</b> <b>exclusive</b> <b>classes,</b> {{and there is some}} theory, or say null hypothesis, which gives the probability that any observation falls into the corresponding class. The purpose of the test is to evaluate how likely it is between the observations and the null hypothesis.|$|E
5000|$|The loss layer {{specifies}} how training penalizes {{the deviation}} between the predicted and true labels and is normally the final layer. Various loss functions appropriate for different tasks {{may be used}} there. Softmax loss is used for predicting a single class of K <b>mutually</b> <b>exclusive</b> <b>classes.</b> Sigmoid cross-entropy loss is used for predicting K independent probability values in [...] Euclidean loss is used for regressing to real-valued labels [...]|$|E
50|$|A {{frequency}} distribution shows us a summarized grouping of data divided into <b>mutually</b> <b>exclusive</b> <b>classes</b> {{and the number}} of occurrences in a class. It is a way of showing unorganized data e.g. to show results of an election, income of people for a certain region, sales of a product within a certain period, student loan amounts of graduates, etc. Some of the graphs that can be used with {{frequency distribution}}s are histograms, line charts, bar charts and pie charts. Frequency distributions are used for both qualitative and quantitative data.|$|E
5000|$|Nagel and Newman create two <b>mutually</b> <b>exclusive</b> and {{exhaustive}} <b>classes</b> K1 and K2 {{into which}} fall (the outcome of) the axioms when their variables e.g. S1 and S2 are assigned from these classes. This {{also applies to}} the primitive formulas. For example: [...] "A formula having the form S1 V S2 is placed into class K2 if both S1 and S2 are in K2; otherwise it is placed in K1", and [...] "A formula having the form ~S is placed in K2, if S is in K1; otherwise it is placed in K1".|$|R
40|$|An {{unsupervised}} classification algorithm {{is derived from}} an ICA mixture model assuming that the observed data can be categorized into several <b>mutually</b> <b>exclusive</b> data <b>classes</b> whose components are generated by linear mixtures of independent non-Gaussian sources. The algorithm finds the independent sources, the mixing matrix for each class and also computes the class membership probability for each data point. The new algorithm can improve classification accuracy compared with standard Gaussian mixture models. When applied to blind source separation in nonstationary environments, the method can switch automatically between learned mixing matrices. The algorithm can learn efficient codes to represent images containing both natural scenes and text. This method shows promise for modeling structure in high-dimensional data and has many potential applications. Index Terms: Unsupervised classification, Gaussian mixture model, independent component analysis, blind source separation, image coding [...] ...|$|R
40|$|The present paper {{discusses}} the following problem; {{what is the}} best theoretical understanding of the social class distribution of health and mortality? The discussion identifies some theoretical problems. Some of these {{have to do with the}} importance of social causation of health on the one hand and health-related social mobility on the other. Each one of these two explanations has its own problems, but they are not <b>mutually</b> <b>exclusive.</b> The <b>class</b> distribution of early death can vary both between countries, between two periods in time and between causes of death. Such variability should be exploited for theoretical reasons. Empirical 'anomalies' should not be dismissed or ignored, but taken seriously. It seems clear that a theoretical over-simplification in analysing class and health will prove to be counter-productive. inequality health mortality social class social mobility selection genetical fallacy sociological inertia general susceptibility...|$|R
50|$|A {{few years}} before the Geek Code was published, similar codes existed for other purposes. The Natural Bears Classification System, first {{documented}} in 1989, is a similar code for the bear subculture. Like the Geek Code, it generally uses a single letter for the attribute and + or − signs for the grade. It {{was inspired by the}} Yerkes spectral classification system for describing stars. Unlike the Geek Code, the Yerkes system uses classes, subclasses and peculiarities for categorization. These systems differ in their orthogonality: the Geek Code is very orthogonal in the computer science sense (where variables may be projected onto basis vectors), where the Yerkes system is very orthogonal in the taxonomic sense (represent <b>mutually</b> <b>exclusive</b> <b>classes).</b>|$|E
40|$|Abstract. The {{statistical}} {{pattern recognition}} based on Bayes formula implies {{the concept of}} <b>mutually</b> <b>exclusive</b> <b>classes.</b> This assumption is not applicable {{when we have to}} identify some non-exclusive properties and therefore it is unnatural in biological neural networks. Considering the framework of probabilistic neural networks we propose statistical identification of non-exclusive properties by using one-class classifiers...|$|E
40|$|Supervised {{classification}} into c <b>mutually</b> <b>exclusive</b> <b>classes</b> {{based on}} n binary features is considered. The only information available is an n×c table with probabilities. Knowing {{that the best}} d features are not the d best, simulations were run for 4 feature selection methods and an application to diagnosing BSE in cattle and Scrapie in sheep is presented...|$|E
40|$|We {{present an}} {{unsupervised}} classification algorithm {{based on an}} ICA mixture model. A mixture model is a model in which the observed data can be categorized into several <b>mutually</b> <b>exclusive</b> data <b>classes.</b> In an ICA mixture model, {{it is assumed that}} the data in each class are generated by a linear mixture of independent sources. The algorithm finds the independent sources and the mixing matrix for each class and also computes the class membership probability of for each data point. This approach extends the Gaussian mixture model so that the clusters can have non-Gaussian structure. Performance on a standard classification problem, the Iris flower data set, demonstrates that the new algorithm can improve classification accurately over standard Gaussian mixture models. We also show that the algorithm can be applied to blind source separation in nonstationary environments. The method can switch automatically between learned miving matrices in different environments. 1...|$|R
40|$|This paper {{deals with}} the well-studied problem of how best to {{estimate}} the number of <b>mutually</b> <b>exclusive</b> and exhaustive <b>classes</b> in a population, based on a sample from it. Haas & Stokes review and provide non-parametric approaches, but there are associated difficulties especially for small sampling fractions and/or widely varying population class sizes. Sichel provided 'GIGP' methodology, for this problem and for other purposes; this paper utilizes the three-parameter GIGP distribution for this problem, and also for the estimation {{of the number of}} classes of size 1, {{as an alternative to the}} non-parametric approaches. Methodological and computational issues are considered, and examples indicate the potential for GIGP. ...|$|R
40|$|In this paper, {{we propose}} two new neuro [...] fuzzy schemes, one for {{classification}} {{and one for}} clustering problems. The classification scheme is based on Simpson's Fuzzy Min Max method, and relaxes some assumptions he makes. This enables our scheme to handle <b>mutually</b> non <b>exclusive</b> <b>classes.</b> The neuro [...] fuzzy clustering scheme is a multiresolution algorithm that is modeled after the mechanics of human pattern recognition. We also present data from an exhaustive comparison of these techniques with neural, statistical, machine learning and other traditional approaches to pattern recognition applications. The data sets used for comparisons include those from the machine learning repository at the University of California, Irvine. We find that our proposed schemes compare quite well with the existing techniques, and in addition offer the advantages of one pass learning and on [...] line adaptation. Keywords [...] - Pattern Recognition, Classification, Clustering, Neuro-Fuzzy Systems, Multiresolution, Visi [...] ...|$|R
40|$|Clustering {{seeks to}} group or to lump {{together}} objects or variables that share some observed qualities or, alternatively, to partition or to divide a set of objects or variables into <b>mutually</b> <b>exclusive</b> <b>classes</b> whose boundaries reflect differences in the observed qualities of their members. Clustering thus extracts typologies from data which in turn represent a reduction of data complexity and may lead to conceptual simplifications...|$|E
40|$|Abstract. We {{discuss the}} notion of spin {{squeezing}} considering two <b>mutually</b> <b>exclusive</b> <b>classes</b> of spin-s states, namely, oriented and non-oriented states. Our analysis shows that the oriented states are not squeezed while non-oriented states exhibit squeezing. We also present a new scheme for construction of spin-s states using 2 s spinors oriented along different axes. Taking the case of s = 1, we show that the ‘non-oriented ’ nature and hence squeezing arise from the intrinsic quantum correlations that exist among the spinors in the coupled state...|$|E
40|$|Mutual Exclusion Bootstrapping (MEB) was {{designed}} to overcome the problem of semantic drift suffered by iterative bootstrapping, where the meaning of extracted terms quickly drifts from the original seed terms (Curran et al., 2007). MEB works by extracting <b>mutually</b> <b>exclusive</b> <b>classes</b> in parallel which constrain each other. In this paper we explore the strengths and limitations of MEB by applying it to two novel lexical-semantic extraction tasks: extracting bigram named entities and WordNet lexical file classes (Fellbaum, 1998) from the Google Web 1 T 5 -grams. ...|$|E
40|$|We {{present an}} {{unsupervised}} classification algorithm {{based on an}} ICA mixture model. The ICA mixture model assumes that the observed data can be categorized into several <b>mutually</b> <b>exclusive</b> data <b>classes</b> in which the components in each class are generated by a linear mixture of independent sources. The algorithm finds the independent sources, the mixing matrix for each class and also computes the class membership probability for each data point. This approach extends the Gaussian mixture model so that the classes can have non-Gaussian structure. We demonstrate that this method can learn efficient codes to represent images of natural scenes and text. The learned classes of basis functions yield a better approximation of the underlying distributions of the data, and thus can provide greater coding efficiency. We believe that this method is well suited to modeling structure in high-dimensional data and has many potential applications. 1 Introduction Recently, Blind Source Separation (BSS) by [...] ...|$|R
40|$|Latent class {{analysis}} can identify unmeasured <b>mutually</b> <b>exclusive</b> categories (<b>class</b> membership) among participants for either observed categorical or continuous variables. More recently, latent class analysis {{has been applied}} to accelerometry to better understand the day-to-day patterns of physical activity and sedentary behavior. Typically, the class assignments are only relevant to the study for which they were derived and not made available for others to use. Using one-week accelerometry (ActiGraph #AM 7164) data collected from the National Health and Nutrition Examination Survey during 2003 – 2006, latent classes of physical activity and sedentary behavior were derived separately for youths 6 – 17 years and adults >= 18 years. The {{purpose of this article is}} to provide the latent class assignments developed on this source population (United States) available to others to apply to their studies using similarly collected accelerometry. This method will extend the usefulness of the latent class analysis and allow for comparisons across studies...|$|R
40|$|Minimally {{differentiated}} acute {{myeloid leukemia}} (AML-M 0) is a rare subtype of AML with poor prognosis. Although genetic alterations are increasingly reported in AML, the gene mutations have not been comprehensively studied in AML-M 0. We aimed to examine {{a wide spectrum of}} gene mutations in patients with AML-M 0 to determine their clinical relevance. Twenty gene mutations including class I, class II, class III of epigenetic regulators (IDH 1, IDH 2, TET 2, DNMT 3 A, MLL-PTD, ASXL 1, and EZH 2), and class IV (tumor suppressor genes) were analyzed in 67 patients with AML-M 0. Mutational analysis was performed with polymerase chain reaction–based assays followed by direct sequencing. The most frequent gene mutations from our data were FLT 3 -ITD/FLT 3 -TKD (28. 4 %), followed by mutations in IDH 1 /IDH 2 (28. 8 %), RUNX 1 (23. 9 %), N-RAS/K-RAS (12. 3 %), TET 2 (8. 2 %), DNMT 3 A (8. 1 %), MLL-PTD (7. 8 %), and ASXL 1 (6. 3 %). Seventy-nine percent (53 / 67) of patients had at least one gene mutation. Class I genes (49. 3 %) were the most common mutated genes, which were <b>mutually</b> <b>exclusive.</b> <b>Class</b> III genes of epigenetic regulators were also frequent (43. 9 %). In multivariate analysis, old age [hazard ratio (HR) 1. 029, 95 % confidence interval (CI) 1. 013 - 1. 044, P = . 001) was the independent adverse factor for overall survival, and RUNX 1 mutation (HR 2. 326, 95 % CI 0. 978 - 5. 533, P = . 056) had a trend toward inferior survival. In conclusion, our study showed a high frequency of FLT 3, RUNX 1, and IDH mutations in AML-M 0, suggesting that these mutations {{played a role in the}} pathogenesis and served as potential therapeutic targets in this rare and unfavorable subtype of AML...|$|R
40|$|We {{prove that}} generous non-nilpotent Borel subgroups of {{connected}} minimal simple groups of finite Morley rank are self-normalizing. We {{use this to}} introduce a uniform approach {{to the analysis of}} connected minimal simple groups of finite Morley rank through a case division incorporating four <b>mutually</b> <b>exclusive</b> <b>classes</b> of groups. We use these to analyze Carter subgroups and Weyl groups in connected minimal simple groups of finite Morley rank. Finally, the self-normalization theorem is applied to give a new proof of an important step in the classification of simple groups of finite Morley rank of odd type...|$|E
40|$|Abstract—An {{unsupervised}} classification algorithm is derived by modeling observed data as {{a mixture of}} several <b>mutually</b> <b>exclusive</b> <b>classes</b> that are each described by linear combinations of independent non-Gaussian densities. The algorithm estimates the data density in each class by using parametric nonlinear functions that fit to the non-Gaussian structure of the data. This improves classification accuracy compared with standard Gaussian mixture models. When applied to textures, the algorithm can learn basis functions for images that capture the statistically significant structure intrinsic in the images. We apply this technique {{to the problem of}} unsupervised texture classification and segmentation...|$|E
40|$|One of {{the main}} tasks of an {{educational}} system is to enrich the Cultural Capital of its students. The Cultural Capital linked to social origins is considered crucial in determining students'social life and subsequent professional achievement. This work moves from an ad hoc survey carried out on a sample of students who enrolled or applied for an entrance test at the university. The Cultural Capital is treated as a latent variable which students are supposed to possess at {{a greater or lesser}} degree. Latent Class Analysis is adopted in order to provide a non arbitrary scaling of Cultural Capital and to sort out <b>mutually</b> <b>exclusive</b> <b>classes</b> of students. Moreover, Item Response Models are implemented to assess the calibration of the questionnaire as an instrument to measure the Cultural Capital of the surveyed population...|$|E
40|$|Abstract — Two {{scalable}} dynamic code assignment (DCA) schemes with call {{admission control}} for OVSF-CDMA systems are studied in this research. The proposed schemes generate an average data throughput {{of the system}} close {{to that of the}} optimal scheme while demanding much lower design and implementation complexity than the optimal scheme. The capacity-partitioning scheme partitions the whole resource into several <b>mutually</b> <b>exclusive</b> subsets of resource and assigns each subset of resource to a group of users in proportion to the corresponding traffic load. The class-partitioning scheme partitions the set of service <b>classes</b> into <b>mutually</b> <b>exclusive</b> groups of <b>classes</b> and assigns a subset of the total resource to the corresponding group of classes. In either case, the call requests that belong to each subset of resource or each group of classes are served independently of others by the optimal DCA. Numerical evaluation confirms the superior performance of the proposed schemes with low complexity. I...|$|R
40|$|Latent Class Models (LCMs) {{assume that}} the population, from which the {{observed}} sample is taken, is composed of m <b>mutually</b> <b>exclusive</b> latent <b>classes.</b> The parameters of interest are the probabilities with which a randomly chosen subject belongs {{to each of the}} latent classes. For each person, L dichotomous measurements are made. In LCM it is assumed that, for each item, every class has a specific probability of positive responses: these are the parameters of interest in the conditional model. To ensure a coherent inference on the structural parameters, their identifiability is needed. Different solutions to this problem {{can be found in the}} psychometric literature. A first group can be found in the early works of Andersen (1954), McHugh (1956), Madansky (1960), Goodman (1974) and Clogg and Goodman (1984). These works are all related since they are based on linear equation systems defined on the marginal probabilities of response patterns of the individuals from the population as a whole. Another approach to analyze this identification problem is motivated by th...|$|R
40|$|Using {{data from}} the last European Survey on Income and Living Conditions (EU-SILC), this paper focuses on the {{measurement}} of well-being and on its association with education. EU-SILC survey gives information on several aspects of people’s daily life (i. e. housing, labour, health, education, finance, material deprivation and possession of durables) allowing a multi-dimensional approach {{to the study of}} well-being, poverty and social exclusion. For our aims we have considered only survey data collected in Italy. Due to the multidimensionality of well-being concept, we have se-lected some variables related principally to four main dimensions of well-being, which are finan-cial endowment, housing conditions and goods possessions, health status, and environment. A first explanatory analysis via multivariate regression model has highlighted the effect of education on the factors considered. Finally, a latent class regression analysis has been used to cluster individ-uals into <b>mutually</b> <b>exclusive</b> latent <b>classes</b> which identify different intensities of well-being (the latent trait) taking into account the effect of education in the membership probability of each la-tent class...|$|R
40|$|An {{unsupervised}} classification algorithm is derived by modeling observed data as {{a mixture of}} several <b>mutually</b> <b>exclusive</b> <b>classes</b> that are each described by linear combinations of independent, non-Gaussian densities. The algorithm estimates the density of each class {{and is able to}} model class distributions with non-Gaussian structure. The new algorithm can improve classification accuracy compared with standard Gaussian mixture models. When applied to blind source separation in nonstationary environments, the method can switch automatically between classes, which correspond to contexts with different mixing properties. The algorithm can learn efficient codes for images containing both natural scenes and text. This method shows promise for modeling non-Gaussian structure in high-dimensional data and has many potential applications. Index TermsUnsupervised classification, Gaussian mixture model, independent component analysis, blind source separation, image coding, automatic contex [...] ...|$|E
40|$|An {{extension}} of the Gaussian mixture model is presented using Independent Component Analysis (ICA) and the generalized Gaussian density model. The mixture model assumes that the observed data can be categorized into <b>mutually</b> <b>exclusive</b> <b>classes</b> whose components are generated by a linear combination of independent sources. The source densities are modeled by generalized Gaussians (Box and Tiao, 1973) that provide a general method for modeling non-Gaussian statistical structure of univariate distributions that have the form p(x) / exp(q). By inferring q, a wide class of statistical distributions can be characterized including uniform, Gaussian, Laplacian, and other suband super-Gaussian densities. The generalized Gaussian mixture model using ICA infers for each class the source parameters, the basis functions and bias vectors. The new method can improve classification accuracy compared with standard Gaussian mixture models and shows promise for accurately modeling structure in [...] ...|$|E
40|$|The {{clustering}} of high-dimensional {{data can}} be troublesome. In the case of high-dimensional data, a subspace clustering model {{can be used to}} achieve a proper recovery of the clusters and to obtain an insight into the structure of the variables relevant to the clustering. In such a model the objects are assigned to <b>mutually</b> <b>exclusive</b> <b>classes</b> in low dimensional spaces. In this paper, we present the Generic Subspace Clustering Model. As will be shown, this model encompasses a range of existing (subspace) clustering techniques as special cases. The specific properties of the model variants will be discussed. An algorithm for fitting the Generic Subspace Clustering Model is presented and its performance is evaluated by means of a simulation study. The value of the model for empirical research is illustrated with data from psychiatric diagnosis research. status: publishe...|$|E
40|$|This paper {{uses the}} {{algorithm}} employed {{in a number}} of recent template-based NLG systems to challenge the wide-spread assumption that template-based methods are inherently less well-founded than plan-based methods. Keywords: NLG paradigms, D 2 S, templates for NLG, plan-based NLG 1 Introduction: a caricature Natural Language Generation (NLG) systems are sometimes partitioned into two <b>mutually</b> <b>exclusive,</b> jointly exhaustive <b>classes</b> [1, 11, 13]: (A) theoretically well-founded systems, which embody generic linguistic insights and are, as a result, easily maintainable. Sometimes, the term `(full-blown) NLG' has been narrowed down to denote this class only; and (B) application-dependent systems which lack a proper theoretical foundation. These systems may be relatively easy to deploy but they are difficult to maintain. The following equalities tend to be stated or suggested: A = plan-based NLG systems; B = template-based NLG systems. 1 We will argue against these two identifications. We s [...] ...|$|R
40|$|The {{present study}} explores {{some of the}} factors that {{determine}} how difficult a classification will be to learn or remember. By a "classification " we mean, here, simply a grouping of a given set of stimuli into two or more <b>mutually</b> <b>exclusive</b> and exhaustive <b>classes.</b> The learning or memorization of a classification can be regarded as a process of associating, to each stimulus, a certain response. This response might be the verbal label arbitrarily assigned to the class containing that stimulus, or it might be the act of sorting that stimulus into the bin arbitrarily assigned to its class. The essential feature of a classification task, however, is that the same response is assigned to several different stimuli. Accordingly, we reserve the term identification task for cases in which a different response is paired with each stimulus. In either case, the word "memorization" is intended, here, to refer to those con...|$|R
40|$|Cationic {{antimicrobial}} peptides and proteins {{have historically}} been ascribed roles in innate immunity that infer killing of microbial and viral pathogens and protection of the host. In the context of sexually transmitted HIV- 1, we take an unconventional approach that questions this paradigm. It is becoming increasingly apparent {{that many of the}} cationic polypeptides present in the human genital or anorectal mucosa, or human semen, are capable of enhancing HIV- 1 infection, often in addition to other reported roles as viral inhibitors. We explore how the in vivo environment may select for or against the HIV-enhancing aspects of these cationic polypeptides by focusing on biological relevance. We stress that the distinction between enhancing and inhibiting HIV- 1 infection is not <b>mutually</b> <b>exclusive</b> to specific <b>classes</b> of cationic polypeptides. Understanding how virally enhancing peptides and proteins act to promote sexual transmission of HIV- 1 would be important for the design of topical microbicides, mucosal vaccines, and other preventative measures...|$|R
