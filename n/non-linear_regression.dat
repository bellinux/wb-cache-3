1561|372|Public
25|$|The {{liquidus}} temperature has been modeled by <b>non-linear</b> <b>regression</b> using neural networks and disconnected peak functions. The disconnected peak functions approach {{is based on}} the observation that within one primary crystalline phase field linear regression can be applied and at eutectic points sudden changes occur.|$|E
2500|$|... {{which can}} be {{estimated}} as the R squared from a <b>non-linear</b> <b>regression</b> of Y on X, using data drawn from the joint distribution of (X,Y). When [...] has a Gaussian distribution (and is an invertible function of X), or Y itself has a (marginal) Gaussian distribution, this explained component of variation sets a lower bound on the mutual information: ...|$|E
2500|$|The Lineweaver–Burk {{plot was}} widely used to {{determine}} important terms in enzyme kinetics, such as K'm and Vmax, before the wide availability of powerful computers and <b>non-linear</b> <b>regression</b> software. The y-intercept of such a graph {{is equivalent to the}} inverse of Vmax; the x-intercept of the graph represents 1/K'm. [...] It also gives a quick, visual impression of the different forms of enzyme inhibition.|$|E
40|$|The study {{deals with}} {{adsorption}} of Naphthol Green B on two unburned carbons and the parent coal, {{from which the}} UCs have been created in a fluidised-bed power station. Particular {{attention has been paid}} to the adsorption equilibrium modelling: experimental data has been analysed using 2 -parameter (Langmuir, Freundlich) and 3 -parameter (Redlich-Peterson) isotherms - both linear and <b>non-linear</b> <b>regressions</b> have been used for the estimation of the isotherm parameters. In the case of both UCs, the Langmuir isotherm model provides the worst fit, whereas 2 -parameter Freundlich and 3 -parameter Redlich-Peterson models are both good, from which 3 -parameter Redlich-Peterson isotherm provides slightly better results (despite the penalty used for the higher number of parameters). In the case of both UCs, the linear regression of Freundlich and Redlich-Peterson models provides good results (comparable with <b>non-linear</b> <b>regressions).</b> Unlike both UCs, the best fit of the experimental data from the adsorption on the coal has been achieved by the Langmuir isotherm model. The results based on the Freundlich or Redlich-Peterson model were (in this case) somewhat worse. Web of Science 251443...|$|R
30|$|In {{order to}} {{formulate}} the programming, {{it is critical}} to first determine the relative importance of CRs and the functional relationships. According to the previous literature, they were either confirmed by subjective assessments and judgments expressed as crisp, random or fuzzy variables [7 – 10], or by the frequent application of the fuzzy linear and <b>non-linear</b> <b>regressions</b> methods [11 – 14]. Even though the latter one seems more objective, practically speaking, it is much less feasible due to sparse data collection.|$|R
3000|$|The {{coefficients}} in Table  2 {{were determined}} by <b>non-linear</b> least-squares <b>regression</b> analysis and show great variation. These coefficients also provided a useful overview of the different E [...]...|$|R
2500|$|Many {{statistical}} methods seek {{to minimize the}} residual sum of squares, and these are called [...] "methods of least squares" [...] in contrast to Least absolute deviations. The latter gives equal weight to small and big errors, while the former gives more weight to large errors. Residual sum of squares is also differentiable, which provides a handy property for doing regression. Least squares applied to linear regression is called ordinary least squares method and least squares applied to nonlinear regression is called non-linear least squares. Also in a linear regression model the non deterministic part of the model is called error term, disturbance or more simply noise. Both linear regression and <b>non-linear</b> <b>regression</b> are addressed in polynomial least squares, which also describes the variance in a prediction of the dependent variable (y axis) {{as a function of}} the independent variable (x axis) and the deviations (errors, noise, disturbances) from the estimated (fitted) curve.|$|E
50|$|Non-linear {{least squares}} {{problems}} arise {{for instance in}} <b>non-linear</b> <b>regression,</b> where parameters in a model are sought such that the model is in good agreement with available observations.|$|E
50|$|MedCalc {{includes}} basic parametric and non-parametric {{statistical procedures}} and graphs such as descriptive statistics, ANOVA, Mann-Whitney test, Wilcoxon test, χ2 test, correlation, linear {{as well as}} <b>non-linear</b> <b>regression,</b> logistic regression, etc.|$|E
40|$|Face {{alignment}} is {{a critical}} problem in many face related applications such as facial expression analysis, face recognition, etc. This paper presents a novel real time face alignment algorithm based on Active Shape Model (ASM). In our algorithm, local textures of each label point is used to predict the displacement of each label point by applying boost <b>non-linear</b> <b>regressions</b> on the local search stage of the ASM framework. Experiments on different datasets show that our algorithm is much faster in speed and more robust to the initialization than previous ASM method. 1...|$|R
40|$|Feature {{extraction}} and defect parameters estimation from {{eddy current}} testing data has received special {{attention in the}} last years. Principal component analysis, wavelet decomposition and Fourier descriptors are some of the tools used for feature extraction. Particular interest is devoted to using artificial neural networks to perform parameters estimation and profile reconstruction of defects. This work reports the use of <b>non-linear</b> <b>regressions</b> for feature extraction based on the modeling of the measured response by a set of additive Gaussians and artificial neural networks to estimate the width and depth of defects...|$|R
40|$|This article {{discusses}} {{the determinants of}} racial inequality {{in the composition of}} the top incomes in Brazil. The results show that the factors explaining racial inequality behave unevenly across different levels of the income distribution, with the effect of discrimination reaching its maximum at the higher quantiles. This contradicts the thesis of “whitening” – embranquecimento – insofar as this thesis claims that blacks of a higher socioeconomic status may not suffer discrimination in Brazil or, at least, that they may be discriminated at a lesser extent. The data is from the 2010 Brazilian national Census. The methods are linear and <b>non-linear</b> <b>regressions...</b>|$|R
5000|$|From {{the well}} logging data, the {{velocity}} vs [...] plot can be drawn. On {{the basis of}} this plot, a no liner regression will give us an estimate of [...] and [...] The following plot show the <b>non-linear</b> <b>regression</b> and its result.|$|E
50|$|The {{liquidus}} temperature has been modeled by <b>non-linear</b> <b>regression</b> using neural networks and disconnected peak functions. The disconnected peak functions approach {{is based on}} the observation that within one primary crystalline phase field linear regression can be applied and at eutectic points sudden changes occur.|$|E
5000|$|The case of {{multiple}} predictor variables (possibly correlated) subject to variability (possibly correlated) has been well-studied for linear regression, {{and for some}} <b>non-linear</b> <b>regression</b> models. [...] Other non-linear models, such as proportional hazards models for survival analysis, have been considered only with a single predictor subject to variability.|$|E
40|$|ABSTRACT: In {{this paper}} we present an {{integrated}} approach to derive reservoir parameters from core and well-log data in clay–sand mixtures. This method {{is based on}} matching core and log data, and the linear and <b>non-linear</b> <b>regressions</b> are then used to build respective relationships between core and log data to determine formation parameters such as porosity, shale volume, clay content, permeability and fluid saturation. This information is then fed into a velocity prediction model to estimate seismic parameters such as elastic moduli, shear wave velocity and anisotropy coefficients. Finally, we test the method on real data from the North Sea and show that reservoir parameters can be accurately predicted...|$|R
40|$|The {{biochemical}} models describing {{complex and}} dynamic metabolic systems are typically multi-parametric and non-linear, thus {{the identification of}} their parameters requires nonlinear regression analysis of the experimental data. The stochastic nature of the experimental samples poses the necessity to estimate not only the values fitting best to the model, but also {{the distribution of the}} parameters, and to test statistical hypotheses about the values of these parameters. In such situations the application of analytical models for parameter distributions is totally inappropriate because their assumptions are not applicable for intrinsically <b>non-linear</b> <b>regressions.</b> That is why, Monte Carlo simulations are a powerful tool to model biochemical processes...|$|R
40|$|International audienceEach driver reacts {{differently}} {{to the same}} traffic conditions, however, most Advanced Driving Assistant Systems (ADAS) assume that all drivers are the same. This paper proposes a method to learn and to model the velocity profile that the driver follows as the vehicle decelerates towards a stop intersection. Gaussian Processes (GP), a machine learning method for <b>non-linear</b> <b>regressions</b> are used to model the velocity profiles. It is shown that GP are well adapted for such an application, using data recorded in real traffic conditions. It consists of the generation of a normally distributed speed, given {{a position on the}} road. By comparison with generic velocity profiles, benefits of using individual driver patterns for ADAS issues are presented...|$|R
5000|$|MLAB is {{intended}} for numerical computing, with special facilities for ordinary differential equation-solving (ODE-solving) and curve-fitting (<b>non-linear</b> <b>regression.)</b> It provides more than thirty command types and more than 450 built-in functions from the areas of elementary mathematics, transcendental functions, probability and statistics, linear algebra, optimization, cluster analysis, combinatorics, numeric input/output, and graphics.|$|E
5000|$|Transform-expand-sample (TES) {{models are}} <b>non-linear</b> <b>regression</b> models with modulo-1 arithmetic. They aim to capture both auto-correlation and {{marginal}} distribution of empirical data. TES models consist {{of two major}} TES processes: TES+ and TES-. TES+ produces a sequence which has positive correlation at lag 1, while TES- produces a negative correlation at lag 1.5 ...|$|E
50|$|The double {{reciprocal}} plot {{distorts the}} error {{structure of the}} data, and it is therefore unreliable for the determination of enzyme kinetic parameters. Although it is still used for representation of kinetic data, <b>non-linear</b> <b>regression</b> or alternative linear forms of the Michaelis-Menten equation such as the Hanes-Woolf plot or Eadie-Hofstee plot are generally used for the calculation of parameters.|$|E
40|$|Check loss {{function}} {{is used to}} define quantile regression. In the prospect of cross validation, it is also employed as a validation function when underlying truth is unknown. However, our empirical study indicates that the validation with check loss often leads to choosing an over estimated fits. In this work, we suggest a modified or L 2 -adjusted check loss which rounds the sharp corner {{in the middle of}} check loss. It has a large effect of guarding against over fitted model in some extent. Through various simulation settings of linear and <b>non-linear</b> <b>regressions,</b> the improvement of check loss by L 2 adjustment is empirically examined. This adjustment is devised to shrink to zero as sample size grows...|$|R
40|$|This paper {{reviews the}} {{empirical}} literature on international spillovers and contagion. Theoretical models of spillover and contagion {{imply that the}} reduced form observable variables suffer from two possible sources of bias: endogeneity and omitted variables. These econometric problems {{in combination with the}} heteroskedasticity that plagues the data produces time varying biases. Several empirical methodologies are evaluated from this perspective: non-parametric techniques such as correlations and principal components, as well as parametric methods such as OLS, VAR, event studies, ARCH, <b>Non-linear</b> <b>regressions,</b> etc. The paper concludes that there is no single technique that can solve the full fledge problem and discusses three methodologies that can partially address some of the questions in the literature...|$|R
30|$|One of the {{observations}} {{that can be}} made from Tables  1 and 2 is that the base <b>non-linear</b> <b>regressions</b> provide lower standard errors (respectively higher t-test statistics) than their counterparts that have been corrected for serial correlation. Since the autoregressive models provide superior fit (as indicated by both the summary goodness of fit statistics), as well as satisfy the assumption of independent residuals (as indicated by the graphical diagnostics), it may be concluded that the “ordinary” non-linear models underestimate the standard errors. An exhaustive discussion of this issue in the context of OLS is provided in Petersen [29]. This is a serious potential issue with models that ignore violations of the independence assumption, as it could lead to the acceptance of non-valid models as true.|$|R
5000|$|In a {{footnote}} {{in an article}} in the Journal of Latin American Studies Mario Pastore said that Whigham and Potthast, in attacking Reber's estimate, had misrepresented it; but, on the other hand, had failed to notice one of its weakest points, namely, [...] "that it was based on a <b>non-linear</b> <b>regression</b> with very few degrees of freedom".|$|E
50|$|The Lineweaver-Burk {{plot was}} widely used to {{determine}} important terms in enzyme kinetics, such as Km and Vmax, before the wide availability of powerful computers and <b>non-linear</b> <b>regression</b> software. The y-intercept of such a graph {{is equivalent to the}} inverse of Vmax; the x-intercept of the graph represents &minus;1/Km. It also gives a quick, visual impression of the different forms of enzyme inhibition.|$|E
50|$|His {{research}} on the living lens was used to understand diabetic cataract formation. During this time, in collaboration with Dr. Leo Chylack, Jr., he demonstrated the statistical correlation between diabetes and posterior subcapsular cataracts. For this specific work {{he was awarded the}} Soma Weiss Award from Harvard Medical School. Aguayo Martel further probed the association of human behavior and cataract formation using <b>non-linear</b> <b>regression</b> analysis.|$|E
40|$|In this paper, a semi-empirical {{method for}} the {{prediction}} of rain attenuation in slant paths and terrestrial links is proposed. The method uses the same simplified model of equivalent rain cell that {{is the basis for}} the ITU-R rain attenuation prediction methods but, additionally, the concept of an effective rain rate is introduced. This allows the use of the full rainfall rate distribution for {{the prediction of}} the rain attenuation distribution and the unification of the slant path and terrestrial links prediction algorithms. The numerical coefficients in the methods expressions were derived by multiple <b>non-linear</b> <b>regressions</b> using the experimental data currently available in the ITU-R data banks. Test results indicate that the proposed method provides significant improvement over the current ITU-R methods...|$|R
30|$|A dataset was {{compiled}} on the diameter {{growth rates of}} nearly 1800 trees {{from a wide range}} of published and unpublished sources for the middle North Island. <b>Non-linear</b> quantile <b>regressions</b> were used to model average growth and growth of the fastest 25 % of stems, termed rapid growth.|$|R
40|$|Abstract — In this paper, a semi-empirical {{method for}} the {{prediction}} of rain attenuation in slant paths and terrestrial links is proposed. The method uses the same simplified model of equivalent rain cell that {{is the basis for}} the ITU-R rain attenuation prediction methods but, additionally, the concept of an effective rain rate is introduced. This allows the use of the full rainfall rate distribution for {{the prediction of}} the rain attenuation distribution and the unification of the slant path and terrestrial links prediction algorithms. The numerical coefficients in the method’s expressions were derived by multiple <b>non-linear</b> <b>regressions</b> using the experimental data currently available in the ITU-R data banks. Test results indicate that the proposed method provides significant improvement over the current ITU-R methods. Index Terms—rain attenuation, propagation modeling, terrestrial links, satellite links. I...|$|R
5000|$|... {{which can}} be {{estimated}} as the R squared from a <b>non-linear</b> <b>regression</b> of Y on X, using data drawn from the joint distribution of (X,Y). When E( [...] Y &#124; X [...] ) has a Gaussian distribution (and is an invertible function of X), or Y itself has a (marginal) Gaussian distribution, this explained component of variation sets a lower bound on the mutual information: ...|$|E
50|$|Several {{improvements}} on {{the models}} have been made. In 1963 Cowan takes radiation and convection on the surface into account.Cape and Lehman consider transient heat transfer, finite pulse effects and also heat losses in the same year.Blumm and Opfermann improved the Cape-Lehman-Model with high order solutions of radial transient heat transfer and facial heat loss, <b>non-linear</b> <b>regression</b> routine in case of high heat losses and an advanced, patented pulse length correction.|$|E
5000|$|<b>Non-linear</b> <b>regression</b> is {{used when}} the {{underlying}} {{form of the}} function is known and regression is used only to estimate the parameters of that function. MARS, on the other hand, estimates the functions themselves, albeit with severe constraints {{on the nature of}} the functions. (These constraints are necessary because discovering a model from the data is an inverse problem that is not well-posed without constraints on the model.) ...|$|E
40|$|In kinesiology, medicine, {{biology and}} psychology, in which {{research}} {{focus is on}} dynamical self-organized systems, complex connections exist between variables. Non-linear nature of complex systems has been discussed and explained by the example of non-linear anthropometric predictors of performance in basketball. Previous studies interpreted relations between anthropometric features and measures of effectiveness in basketball by (a) using linear correlation models, and by (b) including all basketball athletes in the same sample of participants regardless of their playing position. In this paper the signifi cance and character of linear and non-linear relations between simple anthropometric predictors (AP) and performance criteria consisting of situation-related measures of effectiveness (SE) in basketball were determined and evaluated. The sample of participants consisted of top-level junior basketball players divided in three groups according to their playing time (8 minutes and more per game) and playing position: guards (N= 42), forwards (N= 26) and centers (N= 40). Linear (general model) and <b>non-linear</b> (general model) <b>regression</b> models were calculated simultaneously and separately for each group. The conclusion is viable: <b>non-linear</b> <b>regressions</b> are frequently superior to linear correlations when interpreting actual association logic among research variables...|$|R
40|$|We analyze how {{childhood}} hunger affects human aging for a {{panel of}} European individuals. For this purpose, we use six waves of the Survey of Health, Aging, and Retirement in Europe (SHARE) dataset and construct a health deficit index. Results from log-linear regressions suggest that, on average, elderly European men and women developed about 20 percent more health deficits when they experienced a hunger episode in their childhood. The effect becomes larger when the hunger episode is experienced earlier in childhood. In <b>non-linear</b> <b>regressions</b> (akin to the Gompertz-Makeham law), we obtain greater effects suggesting that health deficits in old age are up to 40 percent higher for children suffering from hunger. The wedge of health deficits between hungry and and non-hungry individuals increases absolutely and relatively with age. This implies that individuals who suffered from hunger as children age faster...|$|R
40|$|Effects of root-zone {{volume and}} {{fertigation}} frequency on 4 cultivars of substrate-grown strawberry (Fragaria×ananassa Duch., ‘Nyoho’, ‘Asukarubi’, ‘Akihime’ and ‘Tochiotome’) were investigated. Fertigation frequency had no {{significant effect on}} growth and yield of strawberry even in the minimum root-zone volume of 0. 6 L/plant. Total yield, mean berry weight, and root dry weight at end of harvest decreased with decrease in volume, but no significant difference was observed in number of harvested berries and subsequent growth of runners and daughter plants. In the yield and root growth, there were large differences between peat bags (2. 25 L/plant) and bowl-shaped containers (0. 6 - 1. 5 L/plant), and highly significant <b>non-linear</b> <b>regressions</b> between the two parameters and the root-zone volume. The differences {{may be caused by}} factors other than the volume, such as the shape of root-zone and edge of containers or drain property, and so on...|$|R
