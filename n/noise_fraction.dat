165|23|Public
40|$|Abstract—A {{generalization}} {{of the maximum}} <b>noise</b> <b>fraction</b> (MNF) transform is proposed. Powers of each band are included as new bands before the MNF transform is performed. The generalized MNF (GMNF) is shown to perform better than the MNF on a time dependent airborne electromagnetic (AEM) data filtering problem. ...|$|E
30|$|Reduction in {{acquisition}} length by half {{results in}} half the count density and a corresponding increase in <b>noise</b> <b>fraction</b> {{by a factor of}} √ 2. Of lesions that were test positive on 10  min-per-view, but test negative at 5  min-per-view (Table  3), only one was in a low count density study.|$|E
40|$|A {{generalization}} {{of the maximum}} <b>noise</b> <b>fraction</b> (MNF) transform is proposed. Powers of each band are included as new bands before the MNF transform is performed. The generalized MNF (GMNF) is shown to perform better than the MNF on a time dependent airborne electromagnetic (AEM) data filtering problem. Comment: 4 pages, 3 figure...|$|E
40|$|The {{robustness}} of Bell’s inequality (in CHSH form) violation by entangled {{state in}} the simultaneous presence of colored and white noise in the system is considered. A twophoton polarization state is modeled by twoparameter density matrix. Setting parameter values one can vary the relative fraction of pure entangled Bell’s state as well as white and colored <b>noise</b> <b>fractions.</b> Bell’s operator-parameter dependence analysis is made. Computational results are compared with experimental data [9] and with results computed using a oneparameter density matrix [8], which one can get as a special case of the model considered in this work. ...|$|R
40|$|As a {{supplement}} or {{an alternative to}} classification of hyperspectral image data the linear mixture model is considered {{in order to obtain}} estimates of abundance of each class or endmember in pixels with mixed membership. Full unmixing and the partial unmixing methods orthogonal subspace projection (OSP), constrained energy minimization (CEM) and an eigenvalue formulation alternative are dealt with. The solution to the eigenvalue formulation alternative proves to be identical to the CEM solution. Also, spectral angle mapping (SAM) is described. The matrix inversion involved in CEM can be avoided by working on (a subset of) orthogonally transformed data such as signal maximum autocorrelation factors, MAFs, or signal minimum <b>noise</b> <b>fractions,</b> MNFs. This will also cause the noise isolated in the MAF/MNFs not included in the analysis not to influence the partial unmixing result. CEM and the eigenvalue formulation alternative enable us to perform partial unmixing when we know the desired end- [...] ...|$|R
40|$|The Maximum <b>Noise</b> <b>Fractions</b> (MNF) {{transformation}} {{is used as}} a restoration tool in a 512 512 subscene of a 63 channel spectral dataset recorded over the Pyrite Belt in Southern Spain with the Geophysical Environmental Research Imaging Spectrometer (GERIS). The data obtained from such a scanning device are very useful in e. g. mineral exploration and environmental surveillance. Following the transformation from the original image space into the MNF space, a Fourier transformation of the MNFs (which are ordered by signal-tonoise ratio) will show more and more noise content. Also, the strong striping in primarily the visual bands of the scanner will be very conspicuous in the Fourier domain of only a few MNFs. We automatically detect the peaks in the Fourier spectra representing this striping, and if so desired we replace them by an iterated local mean value. Transforming back into the MNF space by the inverse Fourier transformation gives restored MNFs and transforming back into the original image space gives restored original bands. If we want to remove salt-and-pepper noise also, we can replace the noise-only MNFs by their mean value before transforming back into the original image space. This noise removal is very important alon...|$|R
40|$|Vegetation indices using multitemporal {{data from}} MODIS/TERRA sensor consent to {{describe}} the vegetation dynamics by viewing their phonological variation {{throughout the course of}} a year. However, temporal signatures are extremely susceptible to noise interferences, which hinder vegetation identification. Therefore, it is fundamental the use of techniques to minimize them. In the present work was utilized the Minimum <b>Noise</b> <b>Fraction</b> (MNF) transformation an efficient mathematical procedure for noise elimination. The study area is located in National Park of the Chapada of Veadeiros (GO). The MNF transformation can be subdivided into four stages: (a) obtaining a noise sample, (b) formulation of a <b>noise</b> <b>fraction</b> index, (c) implementation of a linear transformation function as PCA and (d) inversion of MNF considering only signs information. Subsequent retransformation results in cleaned images and spectrum with little signal loss. Pages: 6119 - 612...|$|E
40|$|The DAIS 7915 {{was flown}} over the Maktesh Ramon, a {{geological}} structure on a desertic mediterranean area devoid of vegetation. The day-time channels are corrected for noncoherent noise and atmospheric effects aiming to a spectral {{analysis of the}} imagery in terms of lithological spectral behaviour. Dominant calcareous contents on the exposed outcrop is mapped as different lithological units. Sharp changes in height are mapping guide lines in the area, acting as contact for different lithological units. The thermal infrared, sensitive to topography, is used for target selection on the imagery. Principal components analysis and minimum <b>noise</b> <b>fraction</b> transforms were used as first approaches on groups of channels selected under spectral lithological behaviour criteria based on field spectra to evaluate data variablility. The minimum <b>noise</b> <b>fraction</b> transforms on thermal infrared channels {{proved to be a}} good instrument for lithological discrimination. Spectral Angle Mapper using field spectra as endmembers, and Maximum Likelihood Classification based on selected training areas on the imagery resulted the best digital mapping methods...|$|E
30|$|As such, MAF {{transformation}} {{is a form}} of Minimum <b>Noise</b> <b>Fraction</b> (MNF) procedure that generates components with maximum Signal to Noise Ratio (SNR): assuming that the noise is derived from the evaluation of the difference between values of neighboring pixels, the first MAF component will exhibit maximum autocorrelation, identified as areas with maximum change, while the noise is expected to be present in lower order components [13].|$|E
40|$|ABSTRACT: As a {{supplement}} or {{an alternative to}} classification of hyperspectral image data the linear mixture model is considered {{in order to obtain}} estimates of abundance of each class or end-member in pixels with mixed membership. Full unmixing and the partial unmixing methods orthogonal subspace projection (OSP), constrained energy minimization (CEM) and an eigenvalue formulation alternative are dealt with. The solution to the eigenvalue formulation alternative proves to be identical to the CEM solution. The matrix inversion involved in CEM can be avoided by working on (a subset of) orthogonally transformed data such as signal maximum autocorrelation factors, MAFs, or signal minimum <b>noise</b> <b>fractions,</b> MNFs. This will also cause the noise isolated in the MAF/MNFs not included in the analysis not to influence the partial unmixing result. CEM and the eigenvalue formulation alternative enable us to perform partial unmixing when we know the desired end-member spectra only and not the full set of end-member spectra. This is an advantage over full unmixing and OSP. An example with a simple simulated 2 -band image shows the ability of the CEM method to isolate the desired signal. A case study with a 30 bands subset of AVIRIS data from the Mojave Desert, California, USA, indicates the utility of CEM to more realistic data. KEY WORDS: matched filtering; orthogonal subspace projection, OSP; constrained energy minimization, CEM; generalized eigenvalue proble...|$|R
40|$|Abstract. As a {{supplement}} or {{an alternative to}} classification of hyperspectral image data linear and semi-parametric mixture models are considered {{in order to obtain}} estimates of abundance of each class or end-member in pixels with mixed membership. Full unmixing based on both ordinary least squares (OLS) and non-negative least squares (NNLS), and the partial unmixing methods orthogonal subspace projection (OSP), constrained energy minimiza-tion (CEM) and an eigenvalue formulation alternative are dealt with. The solution to the eigenvalue formulation alternative proves to be identical to the CEM solution. The matrix inversion involved in CEM can be avoided by working on (a subset of) orthogonally transformed data such as signal maximum autocorrelation factors, MAFs, or signal minimum <b>noise</b> <b>fractions,</b> MNFs. This will also cause the partial unmixing result to be independent of the noise isolated in the MAF/MNFs not included in the analysis. CEM and the eigenvalue formulation alternative enable us to perform partial unmixing when we know one desired end-member spectrum only and not the full set of end-member spectra. This is an advantage over full unmixing and OSP. The eigenvalue formulation of CEM inspires us to suggest an iterated CEM scheme. Also the target constrained interference minimized filter (TCIMF) is described. Spectral angle mapping (SAM) is briefly described. Finally, semi-parametric unmixing (SPU) based on a combined linear and additive model with a non-linear, smooth function to represent end-member spectra un-accounted for is introduced. An example with two generated bands shows that both full unmixing, the CEM, th...|$|R
40|$|The recent seismic {{activity}} of the border faults of the Roer Graben has regional and local effects on topography {{as well as on}} the composition, chemistry and wetness of soils and on the vegetation overburden. Though sometimes quite important and visible on air photos and satellite imagery, these effects are most often quite subtle and a high spectral resolution is necessary to detect them. The objectives of our investigation were to map and quantify the variations in topography, soils and vegetation at the limit of the crustal blocs separated by known faults and to study the causes of these variations in relation with the fault activity, geometry and deformational mechanism. We focussed our analysis on the following phenomena: (1) change in soil mineralogical and physical composition (lithology) due to the vertical or lateral displacement of the faults that produce a contact between different lithological units, (2) change in soil moisture when a fault is acting as a dam, (3) change in the nature and density of vegetation related to soil composition or wetness and (4) vegetal stress related to water or to soil chemistry. After calibration of the image data and a field spectral measurement campaign, the hyperspectral data have been processed with different techniques, mainly based on ENVI concepts of minimum <b>noise</b> <b>fractions</b> (MNF), pixel purity index (PPI), n-dimensional visualizer and analyser, spectral endmembers, spectral unmixing and SAM classifications, in interactive and automatic “hourglass ” modes. Due to the very specific local effects of th...|$|R
30|$|Principal Component Analysis (PCA), Minimum <b>Noise</b> <b>Fraction</b> (MNF - Green et al., 1988) {{techniques}} {{have been applied}} to VNIR[*]+[*]SWIR ASTER data for lithological mapping in Muslim Bagh ophiolite complex, Pakistan. The PCA discriminated metamorphic sole, sheeted dike complex, basalt and cherts, diabase dikes and gabbro bodies. The MNF transformed data detected sedimentary units, metamorphic sole, laterite, depleted harzburgite and diabase dikes/sills (Khan et al., 2007).|$|E
40|$|In this paper, we {{investigate}} {{the use of}} random-projection-based dimensionality reduction for hyperspectral endmember extraction. It is data-independent and computationally more efficient than other widely used dimensionality reduction methods, such as principal component analysis and maximum <b>noise</b> <b>fraction</b> transform. Based on the preliminary result, random-projection-based dimensionality reduction is capable of providing better endmembers after effective decision fusion. Index Terms — dimensionality reduction, random projection, endmember extraction, hyperspectral imagery 1...|$|E
30|$|A hyperspectral {{image of}} a forest stand in {{north-eastern}} Poland taken using an AISA (Airborne Imaging Spectrometer for Application) Eagle camera was transformed to extract the most valuable spectral differences and was classified into seven tree types (birch, European beech, oak, hornbeam, European larch, Scots pine, and Norway spruce) using nine classification algorithms. The highest overall accuracy and kappa coefficient were 90.3 % and 0.9 respectively using three minimum <b>noise</b> <b>fraction</b> bands and maximum likelihood classifier.|$|E
40|$|When one {{collects}} multivariate data in some {{field of}} application a redundancy effect often arises because of covariation between variables. An interesting issue in reduction of dimensionality of the data is the desire to obtain simplicity for better understanding, visualizing and interpreting the data on the one hand, {{and the desire to}} retain sufficient detail for adequate representation on the other hand. E. g. a remote sensing device typically measures the emitted intensity at a number of discrete wavelengths or wavelength intervals for each element in a regular grid. This “repetition ” of the measurement at different wavelengths induces a high degree of redundancy in the dataset. This can be used for noise reduction and data compression. A traditional method used in this context is the celebrated principal components transformation. This is a pixel-wise operation that does not take the spatial nature of image data into account. Also, principal components will not always produce components that show decreasing image quality with increasing component number. It is perfectly imaginable that certain types of noise have higher variance than certain types of signal components. First I shall briefly consider the theory of principal components, see also Conradsen (1984), Anderson (1984) who both describe several other orthogonal transformations. Following this, two procedures for trans-formation of multivariate data given on a spatial grid (images) with the purpose of isolating signal from noise and data compression. These are the minimum/maximum autocorrelation factor transformation, which was first described by Switzer & Green (1984) and the maximum <b>noise</b> <b>fractions</b> transformation which was de-scribed by Green, Berman, Switzer, & Craig (1988). The methods are also described in Conradsen, Nielsen...|$|R
40|$|Statistical {{properties}} of the impulse response of avalanche photodiode (APDs) are determined. The model is based on recurrence equations. These equations are solved numerically to calculate the mean current impulse response and standard deviation {{as a function of}} time. In this paper, we investigate the effects of parameters such as ionization coefficient-multiplication thickness product (&alpha;w), dead space, excess <b>noise</b> factor, mole <b>fraction,</b> temperature on the mean current impulse response of APD in the Geiger mode...|$|R
40|$|In this study, a {{comparative}} analysis of capabilities of three sensors for mapping forest crown closure (CC) and {{leaf area index}} (LAI) was conducted. The three sensors are Hyperspectral Imager (Hyperion) and Advanced Land Imager (ALI) onboard EO- 1 satellite and Landsat- 7 Enhanced Thematic Mapper Plus (ETM+). A total of 38 mixed coniferous forest CC and 38 LAI measurements were collected at Blodgett Forest Research Station, University of California at Berkeley, USA. The analysis method consists of (1) extracting spectral vegetation indices (VIs), spectral texture information and maximum <b>noise</b> <b>fractions</b> (MNFs), (2) establishing multivariate prediction models, (3) predicting and mapping pixel-based CC and LAI values, and (4) validating the mapped CC and LAI results with field validated photo-interpreted CC and LAI values. The experimental {{results indicate that the}} Hyperion data are the most effective for mapping forest CC and LAI (CC mapped accuracy (MA) = 76. 0 %, LAI MA = 74. 7 %), followed by ALI data (CC MA = 74. 5 %, LAI MA = 70. 7 %), with ETM+ data results being least effective (CC MA = 71. 1 %, LAI MA = 63. 4 %). This analysis demonstrates that the Hyperion sensor outperforms the other two sensors: ALI and ETM+. This is because of its high spectral resolution with rich subtle spectral information, of its short-wave infrared data for constructing optimal VIs that are slightly affected by the atmosphere, and of its more available MNFs than the other two sensors to be selected for establishing prediction models. Compared to ETM+ data, ALI data are better for mapping forest CC and LAI due to ALI data with more bands and higher signal-to-noise ratios than those of ETM+ data...|$|R
40|$|In this paper, we {{outline the}} {{relationship}} between the Maximum <b>Noise</b> <b>Fraction</b> (MNF) method [...] an algorithm first proposed for cleaning noise from multispectral image data [...] and Blind Signal Separation (BSS). In particular we demonstrate under what conditions these methods are equivalent and indicate that MNF may be viewed as an extension to BSS for the case of subspace mixing. We present several examples and compare the results of the MNF method to algorithms for performing independent component analysis (ICA) ...|$|E
40|$|Aiming at signal de-noising of fault diagnosis, we need obtain {{fault signal}} of high {{signal to noise}} ratio with multi-wavelets which need little prior {{knowledge}} and are uninfluenced by waveform matching. Here, this paper determines the wavelet basis through contrast experiment, and the decomposition level is confirmed by the principles of making <b>noise</b> <b>fraction</b> from details and making low energy from general picture, threshold is ensured by the method of midpoint optimization. The simulation shows that this method can enhance {{signal to noise ratio}} obviously...|$|E
40|$|This paper {{presents}} an optimized kernel minimum <b>noise</b> <b>fraction</b> transformation (OKMNF) for feature extraction of hyperspectral imagery. The proposed approach {{is based on}} the kernel minimum <b>noise</b> <b>fraction</b> (KMNF) transformation, which is a nonlinear dimensionality reduction method. KMNF can map the original data into a higher dimensional feature space and provide a small number of quality features for classification and some other post processing. Noise estimation is an important component in KMNF. It is often estimated based on a strong relationship between adjacent pixels. However, hyperspectral images have limited spatial resolution and usually have a large number of mixed pixels, which make the spatial information less reliable for noise estimation. It is the main reason that KMNF generally shows unstable performance in feature extraction for classification. To overcome this problem, this paper exploits the use of a more accurate noise estimation method to improve KMNF. We propose two new noise estimation methods accurately. Moreover, we also propose a framework to improve noise estimation, where both spectral and spatial de-correlation are exploited. Experimental results, conducted using a variety of hyperspectral images, indicate that the proposed OKMNF is superior to some other related dimensionality reduction methods in most cases. Compared to the conventional KMNF, the proposed OKMNF benefits significant improvements in overall classification accuracy...|$|E
40|$|We {{investigate}} the regularity of spontaneous spiking activity on Newman-Watts small-world networks consisting of biophysically realistic Hodgkin-Huxley neurons with a tunable intensity of intrinsic <b>noise</b> and <b>fraction</b> of blocked voltage-gated sodium and potassium ion channels embedded in neuronal membranes. We {{show that there}} exists an optimal fraction of shortcut links between physically distant neurons, {{as well as an}} optimal intensity of intrinsic noise, which warrant an optimally ordered spontaneous spiking activity. This doubly coherence resonance-like phenomenon depends significantly, and can be controlled via the fraction of closed sodium and potassium ion channels, whereby the impacts can be understood via the analysis of the firing rate function as well as the deterministic system dynamics. Potential biological implications of our findings for information propagation across neural networks are also discussed. Comment: 6 two-column pages, 5 figures; accepted for publication in Europhysics Letter...|$|R
40|$|Abstract. The {{possibility}} of detecting the ¯νe {{burst from the}} collapse of a neutron star into a black hole is discussed for an existing SN neutrino detector. The expected signal has been evaluated {{on the basis of the}} model predictions on the ν emission and compared with the detector background. The experimental conditions are discussed in order to maximize the signal to <b>noise</b> ratio. A <b>fraction</b> up to 10 % (depending on the ν energy spectrum) of the stars of our Galaxy, distributed through distances which extent up to the Galactic Center, could be observed by a 1 kt liquid scintillator detector such as the Large Volume Detector at Gran Sasso. Key words: black hole physics – stars: neutro...|$|R
40|$|The {{macroscopic}} friction of particulate materials often weakens as {{the flow}} rate is increased, leading to potentially disastrous intermittent phenomena including earthquakes and landslides. We theoretically and numerically study this phenomenon in simple granular materials. We show that velocity-weakening, corresponding to a non-monotonic {{behavior in the}} friction law μ(I), is present even if the dynamic and static microscopic friction coefficients are identical, but disappears for softer particles. We argue that this instability is induced by endogenous acoustic noise, which tends to make contacts slide, leading to faster flow and increased noise. We show that soft spots, or excitable regions in the materials, correspond to rolling contacts that are about to slide, whose density is described by a nontrivial exponent θ_s. We build a microscopic theory for the non-monotonicity of μ(I), which also predicts the scaling behavior of acoustic <b>noise,</b> the <b>fraction</b> of sliding contacts χ and the sliding velocity, in terms of θ_s. Surprisingly, these quantities have no limit when particles become infinitely hard, as confirmed numerically. Our analysis rationalizes previously unexplained observations and makes new experimentally testable predictions. Comment: 6 pages + 3 pages S...|$|R
40|$|Abstract. In this research, we {{compared}} the performance of different processing chains resulting from combinations of spatial denoising filters, unsupervised feature transformation methods, and a support vector machine classifier. Two different training and test sample scenarios were investigated and conducted on an AVIRIS image over the Indian Pines region in Indiana, USA. The results showed that by using the process chain (adaptive enhanced Lee filter, maximum <b>noise</b> <b>fraction,</b> and support vector machine) the classification accuracies of the kappa coefficient were better {{than those of the}} best previously published techniques...|$|E
40|$|In {{this paper}} are {{described}} some enhancements for a straightforward method recently {{developed by the}} authors for evaluating post flood damages using Landsat TM/ETM+ data integrated with Digital Terrain Models (DTMs) {{and based on the}} Principal Components Transform (PCT). In particular, the main updates refer to the computational scheme in deriving the flood extension map {{with the use of the}} Minimum <b>Noise</b> <b>Fraction</b> (MNF) transformation and in estimating the peak water height and the volumes involved through the use of spline interpolators. Compared with the PCT-based method, the enhanced technique results in improved mapping accurac...|$|E
30|$|Recently, {{some new}} {{approaches}} {{have been proposed}} to deal with noise. One {{of the most popular}} ones is the maximum <b>noise</b> <b>fraction</b> (MNF) transform [6, 7]. Similar to PCA, MNF also transforms the original data to a feature space; however, features are arranged in terms of image quality, which is measured with signal-to-noise ratio (SNR). In MNF, noise covariance matrix (NCM) needs to be estimated [8 – 10], which is a key step. In the original MNF, only spatial information is used for NCM estimation, which may not effectively handle special noise with regular pattern, such as interference in HJ- 1 A data.|$|E
40|$|Coupling {{dynamics}} of {{the states of the}} nodes of a network to the {{dynamics of}} the network topology leads to generic absorbing and fragmentation transitions. The coevolving voter model is a typical system that exhibits such transitions at some critical rewiring. We study the robustness of these transitions under two distinct ways of introducing noise. Noise affecting all the nodes destroys the absorbing-fragmentation transition, giving rise in finite-size systems to two regimes: bimodal magnetisation and dynamic fragmentation. <b>Noise</b> Targeting a <b>fraction</b> of nodes preserves the transitions but introduces shattered fragmentation with its characteristic fraction of isolated nodes and one or two giant components. Both the lack of absorbing state for homogenous noise and the shift in the absorbing transition to higher rewiring for targeted noise are supported by analytical approximations. Comment: 20 page...|$|R
40|$|In this paper, {{we propose}} {{clipping}} noise cancellation scheme using compressed sensing (CS) for orthogonal frequency division multiplexing (OFDM) systems. In the proposed scheme, only the data tones with high reliability are exploited in reconstructing the clipping noise {{instead of the}} whole data tones. For reconstructing the clipping <b>noise</b> using a <b>fraction</b> of the data tones at the receiver, the CS technique is applied. The proposed scheme is also applicable to interleaved orthogonal frequency division multiple access (OFDMA) systems due to the decomposition of fast Fourier transform (FFT) structure. Numerical analysis shows that the proposed scheme performs well for clipping noise cancellation of both OFDM and OFDMA systems. Comment: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version {{may no longer be}} acccessibl...|$|R
40|$|Abstract: As {{technology}} {{becomes increasingly}} {{able to meet}} the requirements, interest in faster, noncoherent, frequency hopping rates to reduce the jamming of communication has heightened. The focus of this paper is on the performance of the fast frequency hopping spread spectrum system operating in the presence of partial band noise jamming. In this paper we consider a communication system that transmits binary data sequence or M frequency shift keying over a channel. With noncoherent detection, the MFSK tones on a given hop must be separated in frequency by an integer multiple of chip rate to provide orthogonality. The worst case partial-band <b>noise</b> jammer chooses <b>fraction</b> (ρ) to maximize the bit error probability (Pb) for a given M and signal to noise ratio. It has been observed from the simulation results that increases with K, illustrating the effectiveness of worst-case jamming (ρ) against FH/MFSK signals at typical operating points. It may be noted that ρ wc wc decreases as Eb/NJ gets larger...|$|R
40|$|Abstract- Frequency hopping spread {{spectrum}} is an efficient technique to combat jamming [...] In this paper we analysis {{the effect of}} partial band noise jamming in Fast Frequency hopping {{spread spectrum}} system. We consider a communication system that transmits MFSK over a channel. The partial band noise interference is model as AWGN Channel using the phase analysis method. We consider (ρ) as a worst case partial band <b>noise</b> <b>fraction</b> and Pb is bit error rate probability for given m and signal to noise ratio. Index Terms- Frequency hopping spread spectrum, interference, partial band noise, AWGN I...|$|E
30|$|Hubbard and Crowley (2005) {{utilized}} ALI, ASTER and Hyperion {{data for}} mineral mapping in a volcanic terrane {{area of the}} Chilen-Bolivian Altiplano. ASTER and ALI channels were co-registered and jointed to produce a 13 -channel reflectance cube spanning the visible to shortwave infrared radiation (0.4 - 2.4 μm). Minimum <b>Noise</b> <b>Fraction</b> (MNF) transformation, Pixel Purity Index (PPI) and n- Dimensional Visualizer were applied to identify spectral end-members. Spectral Angle Mapper (SAM) and Linear Spectral Unmixing (LSU) were applied to map altered rocks using extracted spectral end-members. Results showed that the Hyperion data was only marginally better for mineral mapping than the merged ALI[*]+[*]ASTER datasets.|$|E
40|$|We {{present the}} first {{construction}} of error-correcting codes {{which can be}} (list) decoded from a <b>noise</b> <b>fraction</b> arbitrarily close to 1 in linear time. Specifically, we present an explicit construction of codes which can be encoded in linear {{time as well as}} list decoded in linear time from a fraction (1 - ") of errors for arbitrary "> 0. The rate and alphabet size of the construction are constants that depend only on ". Our construction involves devising a new combinatorial approach to list decoding, in contrast to all previous approaches which relied on the power of decoding algorithms for algebraic codes like Reed-Solomon codes. Our resul...|$|E
40|$|In this paper, {{we present}} a novel, threshold-free robust {{estimation}} framework capable of efficiently fitting models to contaminated data. While RANSAC and its many variants have emerged as popular tools for robust estimation, their performance is largely dependent {{on the availability of}} a reasonable prior estimate of the inlier threshold. In this work, we aim to remove this threshold dependency. We build on the observation that models generated from uncontaminated minimal subsets are “consistent ” in terms of the behavior of their residuals, while contaminated models exhibit uncorrelated behavior. By leveraging this observation, we then develop a very simple, yet effective algorithm that does not require apriori knowledge of either the scale of the <b>noise,</b> or the <b>fraction</b> of uncontaminated points. The resulting estimator, RECON (REsidual CONsensus), is capable of elegantly adapting to the contamination level of the data, and shows excellent performance even at low inlier ratios and high noise levels. We demonstrate the efficiency of our framework on a variety of challenging estimation problems. 1...|$|R
40|$|A matrix {{network is}} a family of matrices, where the {{relationship}} between them is modeled as a weighted graph. Each node represents a matrix, and the weight on each edge represents the similarity between the two matrices. Suppose that we observe a few entries of each matrix with <b>noise,</b> and the <b>fraction</b> of entries we observe varies from matrix to matrix. Even worse, a subset of matrices in this family may be completely unobserved. How can we recover the entire matrix network from noisy and incomplete observations? One motivating example is the cold start problem, {{where we need to}} do inference on new users or items that come with no information. To recover this network of matrices, we propose a structural assumption that the matrix network can be approximated by generalized convolution of low rank matrices living on the same network. We propose an iterative imputation algorithm to complete the matrix network. This algorithm is efficient for large scale applications and is guaranteed to accurately recover all matrices, {{as long as there are}} enough observations accumulated over the network...|$|R
40|$|PENELOPE. We present {{here the}} new {{features}} and results of validation tests {{for the new}} version of PeneloPET that has been compared against data from real scanners. PeneloPET was built as {{a powerful tool for}} PET simulation, it is easy to use, fast and very accurate. Recently, many improvements {{have been made in the}} code with the incorporation of a very realistic signal processing chain and by adding the possibility of running simulations in parallel mode on cluster computers. A comparison between data obtained with two small-animal scanners and the results of PeneloPET simulations has been performed. The small-animal PET scanners were an eXplore Vista DR (GEHC) and a partial-ring, rotating rPET (SUINSA Medical Systems). Intrinsic resolution, scatter <b>fractions,</b> <b>noise</b> equivalent count rates and sensitivity measurements for the real acquisitions and simulations were compared. NEMA protocol was applied using mouse-size and rat-size cylinders, spheres and line sources as phantoms. Results show small differences (less than 10 %) between real acquisitions and simulated data, proving that PeneloPET is an accurate tool for PET simulations. I...|$|R
