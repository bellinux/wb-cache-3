284|131|Public
50|$|Speech {{denoising}} {{has been}} a long lasting problem in audio signal processing. There are lots of algorithms for denoising if the noise is stationary. For example, the Wiener filter is suitable for additive Gaussian noise. However, if the noise is non-stationary, the classical denoising algorithms usually have poor performance because the statistical information of the <b>non-stationary</b> <b>noise</b> is difficult to estimate. Schmidt et al. use NMF to do speech denoising under <b>non-stationary</b> <b>noise,</b> which is completely different from classical statistical approaches. The key idea is that clean speech signal can be sparsely represented by a speech dictionary, but <b>non-stationary</b> <b>noise</b> cannot. Similarly, <b>non-stationary</b> <b>noise</b> can also be sparsely represented by a noise dictionary, but speech cannot.|$|E
50|$|There {{may be some}} {{feedback}} in this sequence, {{in which}} the VAD decision is used to improve the noise estimate in the noise reduction stage, or to adaptively vary the threshold(s). These feedback operations improve the VAD performance in <b>non-stationary</b> <b>noise</b> (i.e. when the noise varies a lot).|$|E
5000|$|NPML {{detection}} {{was first}} described in 1996 [...] and eventually found wide application in HDD read channel design. The “noise predictive” concept was later extended to handle autoregressive (AR) noise processes and autoregressive moving-average (ARMA) stationary noise processes [...] The concept {{was extended to}} include a variety of <b>non-stationary</b> <b>noise</b> sources, such as head, transition jitter and media noise; it was applied to various post-processing schemes. Noise prediction became {{an integral part of}} the metric computation in a wide variety of iterative detection/decoding schemes.|$|E
40|$|In this paper, {{we propose}} a unique {{approach}} to enhance speech signals {{that have been}} corrupted by <b>non-stationary</b> <b>noises.</b> This approach {{is not based on}} a spectral subtraction algorithm, but on an algorithm that separates the speech signal and noise signal contributions in the autocorrelation domain. We call this technique the AR-HASE speech enhancement algorithm. In this initial study, we evaluate the performance of the new algorithm using the average PESQ score computed from 10 male utterances and 10 female utterances taken from the TIMIT database as a measure of speech quality. We test the algorithm using one broadband stationary <b>noise</b> and two <b>non-stationary</b> <b>noises.</b> We will show that the AR-HASE enhancement algorithm produces near transparent quality for clean speech, gives poor enhancement performance for broadband stationary noises, and gives significantly enhanced quality for the two nonstationary noises. Griffith Sciences, Griffith School of EngineeringNo Full Tex...|$|R
40|$|This {{contribution}} {{addresses the}} problem of additive noise reductionin speech {{picked up by a}} microphone in a noisy environment. Two systemsbelonging to the family of coherence-based noise cancellers arepresented. Suggested systems have the modular structure using 2 or 4 microphones and suppress <b>non-stationary</b> <b>noises</b> in the range of 4 to 17 dB depending on the chosen structure and noise characteristics. Thecommon properties are acceptable noise suppression, low speechdistortion and residual noise...|$|R
40|$|Abstract. At present, {{the dynamic}} {{analysis}} for <b>non-stationary</b> stochastic <b>noise</b> of ceramic paste inner stress {{is a difficult}} problem because a <b>non-stationary</b> stochastic <b>noise</b> has a time variant model and dynamic characteristics. In this paper, dynamic analysis ability of Short Time Power Spectrum (STPS) was systematically studied and improved in accordance with theoretical research and simulation analysis. The pressure signals between ceramic paste and head inwall of vacuum pug mill were studied so as to obtain {{the distribution of the}} ceramic paste inner stress. Experiments about the pressure signals had been carried out to verify the research result. Theoretical analysis and experimental result shows that: STPS with filtering performs well in analyzing <b>non-stationary</b> stochastic <b>noise</b> of ceramic paste inner stress in mutation situation. 1...|$|R
5000|$|Eleftheriou {{performed}} {{basic research}} in noise-predictive detection, which found wide application in magnetic recording systems and spurred further research on advanced noise-predictive schemes {{for a variety}} of stationary and <b>non-stationary</b> <b>noise</b> sources. [...] In this context, he developed the reduced state sequence detection approach, which is also the basic idea behind the so-called Noise-Predictive Maximum Likelihood (NPML) detection for magnetic recording. This work in its various instantiations, including iterative detection/decoding schemes, is the core technology of the read channel module in hard-disk drives (HDDs) and tape drive systems. The Eduard Rhein Foundation said Eleftheriou had [...] "a pioneering role in the introduction of innovative digital signal processing and coding techniques into hard disk drives".|$|E
3000|$|Figure 5 b,c {{depicts the}} results of VAD by HMM/GMM hybrid model at <b>non-stationary</b> <b>noise</b> environments. The number of the {{mixtures}} of GMM here is 4. The <b>non-stationary</b> <b>noise</b> is downloaded from [URL] [...]...|$|E
40|$|Classical single-channel speech {{enhancement}} algorithms have two convenient properties: they require pre-learning the noise model {{but not the}} speech model, and they work online. How-ever, they often have difficulties in dealing with <b>non-stationary</b> <b>noise</b> sources. Source separation algorithms based on non-negative spectrogram decompositions are capable of dealing with <b>non-stationary</b> <b>noise,</b> but do not possess the aforemen-tioned properties. In this paper we present a novel algorithm that combines the advantages of both classical algorithms and non-negative spectrogram decomposition algorithms. Experi-ments show that it significantly outperforms four categories of classical algorithms in <b>non-stationary</b> <b>noise</b> environments. Index Terms: {{speech enhancement}}, source separation, non-negative matrix factorization, online algorith...|$|E
40|$|This {{contribution}} {{addresses the}} problem of additive noise reduction in speech {{picked up by a}} microphone in a noisy environment. Two systems belonging to the family of coherence-based noise cancellers are presented. Suggested systems have the modular structure using 2 or 4 microphones and suppress <b>non-stationary</b> <b>noises</b> in the range of 4 to 17 dB depending on the chosen structure and noise characteristics. The common properties are acceptable noise suppression, low speech distortion and residual noise...|$|R
40|$|We {{present a}} {{sequential}} Monte Carlo method applied to additive noise compensation for robust speech recognition in time-varying noise. The method generates {{a set of}} samples according to the prior distribution given by clean speech models and noise prior evolved from previous estimation. An explicit model representing noise ef-fects on speech features is used, so that an extended Kalman ¯lter is constructed for each sample, generating the updated continuous state estimate as the estimation of the noise parameter, and predic-tion likelihood for weighting each sample. Minimum mean square error (MMSE) inference of the time-varying noise parameter is car-ried out over these samples by fusion the estimation of samples ac-cording to their weights. A residual resampling selection step and a Metropolis-Hastings smoothing step are used to improve calcula-tion e±ciency. Experiments were conducted on speech recognition in simulated <b>non-stationary</b> <b>noises,</b> where noise power changed ar-ti¯cially, and highly <b>non-stationary</b> Machinegun <b>noise.</b> In all the experiments carried out, we observed that the method can have sig-ni¯cant recognition performance improvement, over that achieved by noise compensation with stationary noise assumption. ...|$|R
3000|$|... ·u is the GSD noise. Since f is {{generally}} <b>non-stationary,</b> the <b>noise</b> v will be non-stationary as well. The term w is the signal-independent noise component and {{is generally}} {{assumed to be}} Gaussian distributed.|$|R
3000|$|... • When {{comparing}} Figure 7 a with Figure 8 a, {{the proposed}} VAD algorithm {{is much more}} robust to the stationary noise than the <b>non-stationary</b> <b>noise.</b>|$|E
40|$|Abstract:- The {{spectral}} subtraction (SS) {{method is}} well known as a speech enhancement technique and has been widely used. In this paper we study the noise spectrum estimation required for the SS method. It is set out to estimate directly the noise spectrum from the noise-corrupted speech frame. To accomplish this, a fundamental frequency of speech is detected and harmonic structure is constructed and utilized. We assume that <b>non-stationary</b> <b>noise</b> consists of its stationary part and non-stationary part. The non-stationary part is estimated from the harmon-ics obtained, while the stationary part is estimated in the conventional way. Both parts are combined, resulting in an accurate estimate of the noise spectrum. It is shown by experiments that the proposed method provides a performance improvement relative to the conventional SS methods in <b>non-stationary</b> <b>noise</b> environments. Key–Words:- Speech enhancement, spectral subtraction, noise spectrum, <b>non-stationary</b> <b>noise</b> estimation, har-monic structure...|$|E
3000|$|Finally, the {{algorithm}} employs the above-outlined spatial algorithm for smoothing the <b>non-stationary</b> <b>noise</b> remaining after {{application of the}} temporal filter, with the only modification in its threshold value of [...]...|$|E
3000|$|... [7] {{were widely}} used {{features}} {{because of their}} simplicity. However, the performance degrades easily when faced with low signal-to-noise ratio (SNR) or <b>non-stationary</b> background <b>noise.</b> To solve this problem, robust acoustic features such as spectrum [...]...|$|R
3000|$|... [21] and speech-shaped noise {{are added}} at five {{different}} SNR levels (− 10, − 5, 0, 5, and 10 dB) to the signal concatenated by all 240 sentences. The noise {{samples from the}} NOISEX- 92 database are resampled to 16 kHZ according to the experiment requirement. Among the 12 kinds of noises, white noise and pink noise are stationary noises while others are all <b>non-stationary</b> <b>noises,</b> namely tank, military vehicle, jet cockpit, HF channel, F- 16 cockpit, factory floor, car interior, machine gun, speech babble, and speech-shaped noises. The test set for each noise and SNR thus consisted of 28.10 min of noisy speech of which 62.51 % was only noise.|$|R
40|$|In {{this paper}} we {{consider}} the problem of speech enhancement in real-world like conditions where multiple noises can simultaneously corrupt speech. Most of the current literature on speech enhancement focus primarily on presence of single noise in corrupted speech which is far from real-world environments. Specifically, we deal with improving speech quality in office environment where multiple stationary as well as <b>non-stationary</b> <b>noises</b> can be simultaneously present in speech. We propose several strategies based on Deep Neural Networks (DNN) for speech enhancement in these scenarios. We also investigate a DNN training strategy based on psychoacoustic models from speech coding for enhancement of noisy speec...|$|R
40|$|We {{present a}} method for {{suppression}} of <b>non-stationary</b> <b>noise</b> in single channel recordings of speech. The method is based on nonnegative sparse coding and relies on a voice activity detector. In regions classified as non-speech, we learn an overcomplete basis for the noise which is then used to estimate the speech and the noise from the mixture. We compare the method to the classical approach where the noise spectrum is estimated as the average of non-speech frames. The proposed method significantly outperforms the classic approach when the noise is highly non-stationary. Index Terms — <b>Non-stationary</b> <b>noise,</b> spectral subtraction, sparse non-negative matrix factorization 1...|$|E
40|$|The {{detection}} of stationary and <b>non-stationary</b> <b>noise</b> in environmental vibration data {{is an important}} issue when considering the precision of the Watt balance, an electromechanical apparatus for the new definition of the kilogram in the international system of Units (SI). In this paper, the authors propose a frequency histogram method to find the structure of the stationary noise from large amount of datasets. For the <b>non-stationary</b> <b>noise,</b> the authors propose a wavelet based denoising methods to distinguish the transient events from the background “noise”, to find their duration and content and to identify their location in tim...|$|E
40|$|ABSTRACT: The famous filtered-x least {{mean square}} (FxLMS) {{algorithm}} for {{active noise control}} (ANC) systems may become unstable in <b>non-stationary</b> <b>noise</b> environment. To solve this problem, Sun’s algorithm and Akhtar’s algorithm are developed based on modifying the reference signal in update of FxLMS algorithm, but these two algorithms have dissatisfactory stability in dealing with sustaining impulsive noise. In proposed algorithm, probability estimation and zero-crossing rate (ZCR) control are used to improve the stability and performance, at the same time, an optimal parameter selection based on fuzzy system is utilized. Computer simulation results prove the proposed algorithm has faster convergence and better stability in <b>non-stationary</b> <b>noise</b> environment...|$|E
30|$|Comparisons {{between the}} SBA and the {{proposed}} algorithm in four different <b>noise</b> conditions, including <b>non-stationary</b> babble <b>noise,</b> show that the proposed method introduces less (in some cases up to 25 dB less) speech distortion for all evaluated input SNRs.|$|R
40|$|In this paper, we {{introduce}} a noise robust spectral estimation technique for speech signals that {{is derived from}} a windowed one-sided higher-lag autocorrelation sequence. We also {{introduce a}} new high dynamic range window design method, and utilise both techniques in a modi ed Mel Frequency Cepstral Coef cient (MFCC) algorithm to produce noise robust speech recognition features. We call the new features Autocorrelation Mel Frequency Cepstral Coef cients (AMFCCs). We compare the recognition performance of AMFCCs to MFCCs {{for a range of}} stationary and <b>non-stationary</b> <b>noises</b> on the Aurora II database. We show that the AMFCC features perform as well as MFCCs in clean conditions and have higher noise robustness in noisy conditions. Griffith Sciences, Griffith School of EngineeringFull Tex...|$|R
40|$|Abstract — In this paper, we {{introduce}} a noise robust spectral estimation technique for speech signals, which {{we refer to}} as Higher-lag Autocorrelation Spectral Estimation (HASE). By utilising only the higher-lag portion of the autocorrelation sequence to compute a spectral estimate, the HASE method reduces the contribution of noise components. We also {{introduce a}} high dynamic range window design method called DDR, and utilise both the HASE and DDR techniques in a modified Mel Frequency Cepstral Coefficient (MFCC) algorithm to produce noise robust speech recognition features. We call the new features Autocorrelation Mel Frequency Cepstral Coefficients (AMFCCs). We compare the recognition performance of AMFCCs to MFCCs {{for a range of}} stationary and <b>non-stationary</b> <b>noises</b> on the Aurora II database. We show that the AMFCC features perform as well as MFCCs in clean conditions and have higher noise robustness...|$|R
30|$|In Table 1, we give {{another three}} noise {{environment}}s as <b>non-stationary</b> <b>noise</b> environments, in-car noise environment and city street noise environment for test the proposed VAD algorithm, where the noise environment is named as NE for short.|$|E
40|$|In this paper, {{we present}} a {{multi-channel}} post-filtering approach for minimizing the log-spectral amplitude distortion in <b>non-stationary</b> <b>noise</b> environments. The beamformer is realistically assumed to have a steering error, a blocking matrix that is unable to block all of the desired signal components, and a noise canceller that is adapted to the pseudo-stationary noise, but not modified during transient interferences. A mild assumption is made, that a desired signal component is stronger at the beamformer output than at any reference noise signal, and a noise component is strongest {{at one of the}} reference signals. The ratio between the transient power at the beamformer output and the transient power at the reference noise signals is used for indicating whether such a transient is desired or interfering. Based on a Gaussian statistical model and combined with an appropriate spectral enhancement technique, we derive estimators for the signal presence probability, the noise power spectral density, and the clean signal. The proposed method is tested in various <b>non-stationary</b> <b>noise</b> environments. Compared to single-channel post-filtering, a significantly reduced level of <b>non-stationary</b> <b>noise</b> is achieved without further distorting the desired signal components...|$|E
3000|$|... ovl {{score of}} the {{proposed}} approach are relatively better than those of other approaches, particularly in low-SNR and <b>non-stationary</b> <b>noise</b> environments. And it indicates that speech enhancement based on DDBSE and UMVAD can provide a better trade-off between speech distortion and residual noise.|$|E
40|$|In {{real world}} speech processing, the signals are often con-tinuous and consist of {{momentary}} segments of speech over <b>non-stationary</b> background <b>noise.</b> It {{has been demonstrated}} that spectral factorisation using multi-frame atoms can be suc-cessfully employed to separate and recognise speech in ad-verse conditions. While in previous work full knowledge of utterance endpointing and speaker identity was used for noise modelling and speech recognition, this study proposes spec-tral factorisation and sparse classification techniques to de-tect, identify, separate and recognise speech from a continu-ous noisy input. Speech models are trained beforehand, but noise models are acquired adaptively from the input by us-ing voice activity detection without prior knowledge of noise-only locations. The results are evaluated on the CHiME cor-pus, containing utterances from 34 speakers over highly <b>non-stationary</b> multi-source <b>noise.</b> Index Terms — Spectral factorization, speech recogni-tion, speaker recognition, voice activity detection, speech separation 1...|$|R
30|$|As can be {{seen from}} Tables  1 and 2, DDBSE obtains a better {{performance}} than DD, whether MCRA or an easy recursive estimation is used. And the improvement is significant for stationary noises such as white and car. For example, when recursive estimation is adopted for noise estimation, DDBSE can obtain improvement up to 1  dB than DD does, and nearly 0.5 -dB improvement for white <b>noise.</b> For <b>non-stationary</b> <b>noises</b> such as babble and exhibition, DDBSE also obtains improvement up to nearly 0.2  dB. Obviously, DDBSE can obtain a better segSNR than DD, and it means that DDBSE can provide a better ability of noise suppression owing to the more precise a priori SNR estimation. The {{reason for this is that}} the a priori SNR estimation provided by DD is smoother than that provided by DDBSE; thus, there is more residual noise due to the small aggressiveness of the DD approach.|$|R
40|$|In this paper, {{we provide}} {{non-parametric}} statistical tools to test stationarity of microstructure noise in general hidden Ito semimartingales, and discuss {{how to measure}} liquidity risk using high frequency financial data. In particular, we investigate the impact of <b>non-stationary</b> microstructure <b>noise</b> on some volatility estimators, and design three complementary tests by exploiting edge effects, information aggregation of local estimates and high-frequency asymptotic approximation. The asymptotic distributions of these tests are available under both stationary and non-stationary assumptions, thereby enable us to conservatively control type-I errors and meanwhile ensure the proposed tests enjoy the asymptotically optimal statistical power. Besides it also enables us to empirically measure aggregate liquidity risks by these test statistics. As byproducts, functional dependence and endogenous microstructure noise are briefly discussed. Simulation with a realistic configuration corroborates our theoretical results, and our empirical study indicates the prevalence of <b>non-stationary</b> microstructure <b>noise</b> in New York Stock Exchange...|$|R
30|$|As {{experimental}} results show, DDBSE can provide larger noise suppression than DD, and UMVAD {{can improve the}} accuracy of noise estimation. DDBSE combined with UMVAD can obtain improvement in the quality and the intelligibility of speech, especially under <b>non-stationary</b> <b>noise</b> and low-SNR environments.|$|E
40|$|Colloque avec actes et comité de lecture. internationale. International audienceAutomatic speech {{recognition}} works quite well in clean conditions, and several algorithms {{have already been}} proposed to deal with stationary noise. The next challenge probably consists to compensate for <b>non-stationary</b> <b>noise</b> as well. This work studies this problem by proposing and comparing two adaptations of the Parallel Model Combination (PMC) algorithm for <b>non-stationary</b> <b>noise.</b> A third method, derived from the missing data framework, is further proposed and compared to the two previous ones. In musical noise, experimental results show an important improvement of the recognition accuracy for one PMC-derived algorithm, compared to the non adapted system. The missing-data algorithm also performs quite well, despite its simplicity and the strong assumptions he is using...|$|E
40|$|We {{propose the}} study of {{robustness}} measures for signal detection in <b>non-stationary</b> <b>noise</b> using differential geometric tools in conjunction with empirical distribution analysis. Our approach shows that the gradient {{can be viewed as}} a random variable and therefore used to generate sample densities allowing one to draw conclusions regarding the robustness. As an example, one can apply the geometric methodology to the detection of time varying deterministic signals in imperfectly known dependent nonstationary Gaussian noise. We also compare stationary to <b>non-stationary</b> <b>noise</b> and prove that robustness is barely reduced by admitting non-stationarity. In addition, we show that robustness decreases with larger sample sizes, but there is a convergence in this decrease for sample sizes greater than 14. We then move on to compare the effect on robustness for signal detection between non-Gaussian tail effects and residual dependency. The work focuses on robustness as applied to tail effects for the noise distribution, affecting discrete-time detection of signals in independent <b>non-stationary</b> <b>noise.</b> This approach makes use of the extension to the generalized Gaussian case allowing the comparison in robustness between the Gaussian and Laplacian PDF. The obtained results are contrasted with the influence of dependency on robustness for a fixed tail category and draws consequences on residual dependency versus tail uncertainty...|$|E
30|$|In {{the present}} report, we explore {{the use of}} a multi-resolution {{analysis}} for robust speaker verification. Our representation is simple, effective, and computationally-efficient. The proposed scheme is carefully optimized to be particularly sensitive to the information-rich spectro-temporal attributes of the signal while maintaining robustness to unseen noise distortions. The choice of model parameters builds on our current knowledge of psychophysical principles of speech perception in noise[6, 7] complemented with a statistical analysis of the dependencies between spectral details of the message and speaker information. We evaluate the proposed features in an ASV system and compare it against one of the best performing systems in NIST 2010 SRE evaluation[8] under detrimental conditions such as white <b>noise,</b> <b>non-stationary</b> additive <b>noise,</b> and reverberation.|$|R
40|$|New {{analytical}} and simulation results des-cribing {{the performance of}} an adaptive detection processor for narrowband signals are given. The simulation results compare the detection perfor-mance of the adaptive processor with an incoher-ently-averaged, magnitude-squared FFT processor for a class of <b>non-stationary</b> input <b>noise.</b> An ana-lytical derivation of the noise-only probability den-sity function of the adaptive processor's output prior to post-detection integration is presented...|$|R
40|$|Model-based speech {{enhancement}} methods, which rely on separately modeling the {{speech and the}} noise, {{have been shown to}} be powerful in many different problem settings. When the structure of the noise can be arbitrary, which is often the case in practice, model- based methods have to focus on developing good speech models, whose quality will be key to their performance. In this study, we propose a novel probabilistic model for {{speech enhancement}} which precisely models the speech by taking into account the underlying speech production process as well as its dynamics. The proposed model follows a source-filter approach where the excitation and filter parts are modeled as non-negative dynamical systems. We present convergence-guaranteed update rules for each latent factor. In order to assess performance, we evaluate our model on a challenging speech enhancement task where the speech is observed under <b>non-stationary</b> <b>noises</b> recorded in a car. We show that our model outperforms state-of-the-art methods in terms of objective measures...|$|R
