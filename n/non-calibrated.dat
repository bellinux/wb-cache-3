112|0|Public
2500|$|The sub-adult bone yielded <b>non-calibrated</b> [...] dates {{ranging from}} 29,990 ± 500 years BP to 37,800 ± 450 years BP. To date, the best chronological {{estimate}} for the hominid remains from Obi-Rakhmat is ca. 60,000 to 90,000 years BP [...] and 70,000 years BP.|$|E
50|$|For a long time, liquid dosages of {{medication}} were displayed {{in terms of}} both milliliters and the customary units of teaspoons and tablespoons, which are standardized as equal to 5 and 15 mL respectively. However, many people colloquially refer to the small spoon in a utensil set as the teaspoon and the big spoon as the tablespoon. After a major analysis in 2015, {{it was found that the}} inclusion of tea/tablespoon dosages likely encourages some people to use <b>non-calibrated</b> kitchen utensils as measuring devices. Due to this and reported confusion with the abbreviations TSP and TBSP, the FDA now recommends doctors and pharmaceutical manufacturers speak (and label their products) with milliliter only dosing instructions.  To assist in this transition, the FDA encourages drug makers and pharmacies to include a disposable measuring cup with liquid medications.|$|E
40|$|Many spectroscopic {{monitoring}} techniques employ chemometric algorithms like {{principal component}} regression (PCR) for calibration {{and evaluation of}} optical spectra. Systems based on this method, however, suffer from unknown spectral features appearing after calibration, which may result in major errors. The detection of <b>non-calibrated</b> absorption lines is important for treating errors in chemical processes. For these two reasons, the detection and classification of <b>non-calibrated</b> absorption features is of great importance in on-line spectroscopy. A novel approach is proposed here. A wavelet representation of principal components and measured spectra is shown to be appropriate for detection of <b>non-calibrated</b> spectral features. The algorithm can also be applied in combination with partial least-squares (PLS) ...|$|E
40|$|A 6 -bit 1. 2 Gs/s <b>non-calibrated</b> flash ADC in a {{standard}} 45 nm CMOS process, that achieves 0. 45 pJ/conv-step at full Nyquist bandwidth, is presented. Power efficient operation is achieved by a full optimization of amplifier blocks, and by innovations in the comparator and encoding stage. The performance of a <b>non-calibrated</b> flash ADC {{is directly related to}} device properties; a scaling analysis of our ADC in and across CMOS technologies gives insight into the excellent usability of 45 nm technology for AD converter design...|$|E
40|$|An {{effective}} method is proposed, {{in the present}} work, to reduce considerably the high errors normal in solar radiation data obtained by actinographs or by <b>non-calibrated</b> Eppley-type pyranometers. The method is based on constructing two annual distributions of clear sky solar radiation in each location studied. One of them should be constructed using measurements of an accurate instrument for this purpose, while the other {{is based on the}} actinograph or/and <b>non-calibrated</b> Eppley-type pyranometer under utilization. Then the correction factor can be deduced from these distributions. The correction factor for a Robitzsch-type pyranometer {{has been found to be}} strongly dependent on the ambient temperature. Unlike the case of the Robitzsch instrument, the correction factor for Eppley instrument registrations is practically independent of weather conditions, but it depends highly on the length of the <b>non-calibrated</b> period. Validation of the proposed method is provided by comparison of measurements between those of an accurate instrument and the corrected Robitzsch measurements: it was found that the corrected values are reasonably accurate. A substantial reduction in the standard procedure registers is obtained. ...|$|E
30|$|Using BRASS {{with either}} striatal or putaminal SBRs, {{there was no}} {{significant}} difference between the values of sensitivity and specificity across all reconstruction and calibration strategies although there were subtle differences in false negative rates using <b>non-calibrated</b> data, particularly for striatal SBR. Conversely, with the Southampton quantification method, although specificity remained similar across reconstructions and calibration strategies (82.4 – 88.2 %), there were areas with significant changes in sensitivity. Comparisons across calibrated and <b>non-calibrated</b> data showed significant (p[*]=[*] 0.002) improvements in the performance of ACSC data with calibration, with sensitivity increasing from 65.1 to 90.7 % and false negative numbers changing from 14 to 4. Other reconstructions showed slightly smaller, non-significant changes (IRNC 67.4 to 76.7 %, FBP 60.5 to 67.4 %), with false negative numbers changing from 14 to 10 (IRNC) and 17 to 14 (FBP). Assessments across reconstruction methods showed significantly better sensitivity in calibrated ACSC reconstructed data (90.7 %) than both IRNC at 76.7 % and FBP at 67.4 % (p[*]=[*] 0.03 and 0.002, respectively). False negative numbers changed from 4 when using ACSC to 10 for IRNC and 14 for FBP. No differences were found in <b>non-calibrated</b> data.|$|E
30|$|To {{assess whether}} a phantom scan is {{required}} for scanner characterisation, a similar process as described above was performed on <b>non-calibrated</b> database and follow-up data. That is, the ‘raw’ SBR values from the quantification software were used ‘as is’ and were not converted into true SBR using the phantom measurements.|$|E
40|$|We {{present the}} results of the {{analysis}} of satellite imagery to study light pollution in Spain. Both calibrated and <b>non-calibrated</b> DMSP-OLS images were used. We describe the method to scale the <b>non-calibrated</b> DMSP-OLS images which allows us to use differential photometry techniques in order to study the evolution of the light pollution. Population data and DMSP-OLS satellite calibrated images for the year 2006 were compared to test the reliability of official statistics in public lighting consumption. We found a relationship between the population and the energy consumption which is valid for several regions. Finally the true evolution of the electricity consumption for street lighting in Spain from 1992 to 2010 was derived, it have been doubled in the last 18 years in most of the provinces. Comment: Accepted in JQSRT 26 / 11 / 2013 Light pollution special Issu...|$|E
40|$|International audienceWe {{present a}} global {{approach}} {{that enables the}} production of 3 D soccer sequences from <b>non-calibrated</b> video cameras. Our system can produce a 3 D animated model of the scene from a single <b>non-calibrated</b> moving camera (a TV sequence for example). The results presented here are very encouraging even with a single camera approach and will probably improve with the future introduction of multiple images that will help resolving occlusion issues and integrating into a single model information coming from various locations on the field. The key point of our approach is that it doesn’t need any camera calibration and it still works when the camera parameters vary along the process. Details on the registration and tracking processes are given {{as well as the}} description of the “Virtual Reality” system used for displaying the resulting animated model...|$|E
30|$|The use of {{different}} reconstructions has {{little effect on}} the diagnostic performance of the BRASS quantification. We might expect performance to be equalised with calibration; however, the delivery of similar performance across reconstructions using <b>non-calibrated</b> data does at first seems surprising. We would expect that the attenuation of I- 123 gamma photons would be relatively consistent across subjects and also that the scatter environment would be similar too. Septal penetration, which we hope to be reduced using scatter correction, does differ across subjects scanned on different scanners (Tossici-Bolt in submission) but the results here suggest {{that this is not a}} major factor with BRASS quantification. Conversely, with the Southampton method, there are again significant differences in sensitivity between ACSC and IRNC reconstructions and ACSC and FBP reconstructions using calibrated data. Specificity remains unchanged. Once more, with the partial volume factors removed using this quantification method, the corrections for attenuation and scatter become more relevant. With <b>non-calibrated</b> data, any gain in diagnostic performance using corrections is lost, and differences between reconstructions no longer seen.|$|E
40|$|The {{design of}} a {{wideband}} reflectometer {{for the purpose of}} inclusion in a microwave imaging system is described. In order to accomplish reflection coefficient measurements over a large frequency band, wideband couplers, dividers and square-law power detectors are assumed to form the reflectometer. The imperfect operation of the chosen configuration of reflectometer is corrected by using a one-port calibration procedure. The operation of <b>non-calibrated</b> and calibrated instruments is studied with the use of Agilent ADS...|$|E
30|$|Comparing {{analysis}} methods, calibrated FBP data {{had significantly}} lower sensitivity with the Southampton method (67.4 %) with 14 false negatives compared to striatal BRASS SBRs at 83.7 % and 7 false negatives (p[*]=[*] 0.04). With <b>non-calibrated</b> data, putamen BRASS SBR was significantly {{more sensitive than}} the Southampton method for both ACSC (83.7 and 65.1 %) and FBP reconstructions (81.4 and 60.5 %) with p[*]=[*] 0.04 and 0.01, respectively (false negative figures are shown in Table  3).|$|E
40|$|Abstract. Automated {{inspection}} {{using multiple}} views (AMVI) has been recently developed to automatically detect flaws in manufactured objects. The principal {{idea of this}} strategy is that, unlike the noise that appears randomly in images, only the flaws remain stable in a sequence of images because they remain in their position relative to {{the movement of the}} ob-ject being analyzed. This investi- gation proposes a new strategy, based on the detection of flaws in a non- calibrated sequence of images. The method uses a scheme of elimination of potential flaws in two and three views. To improve the performance, intermediate blocks are introduced that elimi-nate those hypothetical flaws that are regular regions and real flaws. Use is made of images captured in a <b>non-calibrated</b> vision system, so there are no optical, geometric and noise disturbances in the image, forcing the pro-posed method to be robust, {{so that it can be}} applied in industry as a qual-ity control method in <b>non-calibrated</b> vision systems. the results show that it is possible to detect the real flaws and at the same time decrease most of the false alarms...|$|E
40|$|A {{problem with}} many {{contemporary}} musical robotic percus-sion systems {{lies in the}} fact that solenoids fail to respond lin-early to linear increases in input velocity. This nonlinearity forces performers to individually tailor their compositions to specific robotic drummers. To address this problem, we introduce a method of pre-performance calibration using metaheuristic search techniques. A variety of such tech-niques are introduced and evaluated and the results of the optimized solenoid-based percussion systems are presented and compared with output from <b>non-calibrated</b> systems...|$|E
30|$|This section {{describes}} how we align the theoretical {{model in the}} previous section to Spain’s economic circumstances during the interval 2002 - 2008. We follow a calibration approach: First, we assign values to the model unobservable parameters to reproduce some basic stylized facts obtained from our sample. Then, we aggregate the model predictions for each individual in our reference sample and compare the results to their in-sample counterparts (along both calibrated and <b>non-calibrated</b> dimensions). The process is iterated until a satisfactory set of parameters is found.|$|E
40|$|Etrophication and {{flooding}} are perennial problems in agricultural watersheds {{of the northern}} Great Plains. A high proportion of annual runoff and nutrient transport occurs with snowmelt in this region. Extensive surface drainage modification, frozen soils, and frequent backwater or ice-damming impacts on flow measurement represent unique challenges to accurately modelling watershed-scale hydrological processes. A physically based, <b>non-calibrated</b> model created using the Cold Regions Hydrological Modelling platform (CRHM) was parameterized to simulate hydrological processes within a low slope, clay soil, and intensively surface drained agricultural watershed. These characteristics are common to most tributaries of the Red River of the north. Analysis of the observed water level records for the study watershed (La Salle River) indicates that ice cover and backwater issues at time of peak flow may impact the accuracy of both modelled and measured streamflows, highlighting the value of evaluating a <b>non-calibrated</b> model in this environment. Simulations best matched the streamflow record in years when peak and annual discharges were equal to or above the medians of 6. 7  m 3  s − 1 and 1. 25  [*]×[*] 10 7  m 3, respectively, with an average Nash–Sutcliffe efficiency (NSE) of 0. 76. Simulation of low-flow years (below the medians) was more challenging (average NSE [*]<[*]  0), with simulated discharge overestimated by 90...|$|E
40|$|Version 2 In {{this report}} we propose a {{methodology}} for cost estimation for ontologies and analyze cost factors {{implied in the}} engineering process. We examine the appropriateness of a COCOMO-like parametric approach to ontology cost estimation and propose a <b>non-calibrated</b> ontology cost model, {{which is to be}} continuously refined along with the collection of empiric data on person month efforts invested in developing ontologies in real-world projects. We further describe the human-driven evaluation of the cost drivers described in the parametric model {{on the basis of the}} cos...|$|E
40|$|Traditional OCR {{engines are}} {{designed}} to the scanned documents in calibrated environment. Three dimensional perspective distortion and smooth distortion in images are critical problems caused by un-calibrated devices, e. g. image from smart phones. To meetthe growing demand of character recognition of texts embedded in the photos acquired from the <b>non-calibrated</b> hand-held devices, we address the problem in three categorical aspects: rotational invariant method of text region extraction, scale invariant method of text line segmentation, and three dimensional perspective mapping. With {{the integration of the}} methods, we developed an OCR for camera-captured images...|$|E
40|$|A {{comparative}} study of unloaded Q-factor measurements of a TE 011 mode sapphire dielectric resonator with unloaded Q-factor value of 731, 000 at a frequency of 10 GHz and temperature of 65 K using two best Q-factor measurement methods are presented. The Transmission (TMQF) and Reflection methods are based on relevant multi-frequency S-parameter measurements and circle fitting procedures to compute the unloaded Q-factor of the resonator. For accurate comparison of the methods a delay compensation procedure (introduced in the TMQF technique to remove delay due to <b>non-calibrated</b> cables) has been applied also to the reflection data. Comment: 4 pages, 7 figures, 1 tabl...|$|E
30|$|In this study, {{we present}} a {{calibration}} procedure attaining calibrated scanners for multicenter studies using 124 I and focusing on DTC and proved it to be feasible. Eighteen PET/CT scanners across the Netherlands were calibrated within 1  week with a convenient and easy to handle phantom, using a single set of 124 I reference activities and predefined scanner-specific acquisition and reconstruction protocols. The estimated parameters of the applied model were reproducible, making the procedure robust. The calibration resulted in a decrease in relative errors of calibrated activities compared to (<b>non-calibrated)</b> measured activities (Fig.  4), making quantitative data comparable among different centers.|$|E
30|$|Finally, {{in future}} editions, {{we would like}} to include other {{performance}} measures in the evaluation plan. In this evaluation, we only considered MTWV and ATWV. We have next included precision, recall, and the F-measure in the analysis of the results, but this was not planned in advance and was not used for the evaluation itself. For future editions, we would also like to allow the participants to submit calibrated likelihood ratios as well as <b>non-calibrated</b> scores in order to measure calibration as well as other figures of merit such as the normalized cross entropy cost (Cnxe) employed in the last query-by-example search on speech task of MediaEval evaluation [27].|$|E
40|$|We propose an {{approach}} for computing the arbitrage-free interval {{for the price}} of an American option in discrete incomplete market models via linear programming. The main idea is built replicating strategies that use both the basic asset and some European derivatives available on the market for trading. This method goes under the name of calibrated option pricing and it has given significant results for European options. Here, we extend the analysis to American options showing that the arbitrage-free interval can be characterized in terms of martingale measures and that it gets significantly reduced with respect to the <b>non-calibrated</b> case. © 2013 © 2013 Taylor & Francis...|$|E
40|$|This paper {{presents}} the practical results obtained {{on the field}} from two different methods for identifying and locating leaks in water distribution systems using network modeling based algorithms. Both methods {{are based on the}} sensitivity analysis of pressure measurements to the demand variation in any node in the distribution system. This work is mainly focused on the obtained results using both methodologies in two different leak episodes, both in Icaria pilot DMA sector in Barcelona. The first episode is a <b>non-calibrated</b> real multi-leak scenario. The second episode was a calibrated artificial leak. Results are similar for both methods, and the identification of location of leaks is found within 150 meter from the actual leaks. Peer ReviewedPostprint (published version...|$|E
40|$|Abstract. We {{propose a}} novel method for {{automatic}} detection of Object of Interest (OOI) and tracking from actively acquired videos. The proposed approach benefits the object-centered property of Active Video and facilitates self-initialization in tracking by a <b>non-calibrated</b> camera. We first use a color-saliency weighted Probability-of-Boundary (cPoB) map for keypoints filtering and salient region detection. Successive Classification Maximum Similarities (SCMS) feature matching {{is used for}} tracking between two consecutive frames. A strong classifier trained onthe-fly by AdaBoost is utilized for keypoint classification and subsequent Linear Programming rejects outliers. Experiments demonstrate the importance of active video {{during the data collection}} phase and confirm that our new approach can automatically detect and reliably track OOI in videos...|$|E
40|$|When {{assessing}} global {{water resources}} with hydrological models, {{it is essential}} to know about methodological uncertainties. The values of simulated water balance components may vary due to different spatial and temporal aggregations, reference periods, and applied climate forcings, as well as due to the consideration of human water use, or the lack thereof. We analyzed these variations over the period 1901 – 2010 by forcing the global hydrological model WaterGAP 2. 2 (ISIMIP 2 a) with five state-of-the-art climate data sets, including a homogenized version of the concatenated WFD/WFDEI data set. Absolute values and temporal variations of global water balance components are strongly affected by the uncertainty in the climate forcing, and no temporal trends of the global water balance components are detected for the four homogeneous climate forcings considered (except for human water abstractions). The calibration of WaterGAP against observed long-term average river discharge Q significantly reduces the impact of climate forcing uncertainty on estimated Q and renewable water resources. For the homogeneous forcings, Q of the calibrated and <b>non-calibrated</b> regions of the globe varies by 1. 6 and 18. 5  %, respectively, for 1971 – 2000. On the continental scale, most differences for long-term average precipitation P and Q estimates occur in Africa and, due to snow undercatch of rain gauges, also in the data-rich continents Europe and North America. Variations of Q at the grid-cell scale are large, except in a few grid cells upstream and downstream of calibration stations, with an average variation of 37 and 74  % among the four homogeneous forcings in calibrated and <b>non-calibrated</b> regions, respectively. Considering only the forcings GSWP 3 and WFDEI_hom, i. e., excluding the forcing without undercatch correction (PGFv 2. 1) and the one with a much lower shortwave downward radiation SWD than the others (WFD), Q variations are reduced to 16 and 31  % in calibrated and <b>non-calibrated</b> regions, respectively. These simulation results support the need for extended Q measurements and data sharing for better constraining global water balance assessments. Over the 20 th century, the human footprint on natural water resources has become larger. For 11 – 18 % of the global land area, the change of Q between 1941 – 1970 and 1971 – 2000 was driven more strongly by change of human water use including dam construction than by change in precipitation, while this was true for only 9 – 13  % of the land area from 1911 – 1940 to 1941 – 1970...|$|E
40|$|International audienceIn this work, Bayesian {{techniques}} are employed to quantify model-form and predictive {{uncertainty in the}} linear behavior of an elastically mounted airfoil undergoing pitching and plunging motions. The Bayesian model averaging approach is used to construct an adjusted stochastic model from different model classes for time-harmonic incompressible flows. From a set of deterministic function approximations, we construct different stochastic models, whose uncertain coefficients are calibrated using Bayesian inference {{with regard to the}} critical flutter velocity. Results show substantial reductions in the predictive uncertainties of the critical flutter speed compared to <b>non-calibrated</b> stochastic simulations. In particular, it is shown that an efficient adjusted model can be derived by considering a possible bias in the random error term on the posterior predictive distributions of the flutter index...|$|E
40|$|Abstract We {{propose a}} novel method for {{automatic}} detection and tracking of Object of Interest (OOI) from actively acquired videos by <b>non-calibrated</b> cameras. The proposed approach {{benefits from the}} objectcentered property of Active Video and facilitates selfinitialization in tracking. We first use a color-saliency weighted Probability-of-Boundary (cPoB) map for keypoint filtering and salient region detection. Successive Classif ication and Ref inement (SCR) is used for tracking between two consecutive frames. A strong classifier trained on-the-fly by AdaBoost is utilized for keypoint classification and subsequent Linear Programming solves a maximum similarity problem to reject outliers. Experiments demonstrate the importance of Active Video {{during the data collection}} phase and confirm that our new approach can automatically detect and reliably track OOI in videos...|$|E
40|$|We study online {{learning}} when {{the objective of}} the decision maker is to maximize her long-term average reward subject to certain sample path average constraints. We define the reward-in-hindsight as the highest reward the decision maker could have achieved, while satisfying the constraints, had she known Nature’s choices in advance. We show that in general the reward-in-hindsight is not attainable. The convex hull of the reward-in-hindsight function is, however, attainable. For the important case of a single constraint, the convex hull {{turns out to be the}} highest attainable function. Using a calibrated forecasting rule, we provide an explicit strategy that attains this convex hull. We also measure the performance of heuristic methods based on <b>non-calibrated</b> forecasters in experiments involving a CPU power management problem. 1...|$|E
30|$|The {{downloaded}} telemetry {{data from}} the Arase satellite will be stored in the archive system at ISAS/JAXA. We collect all raw data related to the PWE (hereinafter referred to as Level- 0 data). Next we divide the Level- 0 data into data product species, such as EFD, OFA-E, OFA-B, and HFA (hereinafter referred to as Level- 1 data), and record them in Common Data Format (CDF), which is a standardized data format that is suitable for solar-terrestrial physics. As the Level- 1 data are still <b>non-calibrated,</b> we calibrate and convert them to Level- 2 data in CDF. All of the products shown in Table  4 will be converted into Level- 2 CDF data and finally {{made available to the}} public at the ERG science center at Nagoya University (Miyoshi et al. 2017).|$|E
40|$|Abstract. This paper {{proposes a}} new vision-based {{system that can}} extract walking {{parameters}} from human demonstration. The system uses only a <b>non-calibrated</b> USB webcam connected to a standard PC, and the human is only required to put three color patches {{on one of his}} legs and walk roughly in a perpendicular plane with respect to camera orientation. The walking parameters are then extracted in real time, using a local tracking system to follow the markers and a fast decision layer to detect the main features of the leg movement. As only one leg can be tracked properly using only one camera, we assume symmetric movement for left and right legs. Once extracted, the parameters have been successfully tested by generating walking sequences for both simulated and real Robo-Erectus humanoid robots. ...|$|E
40|$|Dielectric barrier {{discharge}} (DBD) in air {{is characterized}} applying current measurement, numerical simulation and optical emission spectroscopy (OES). For OES, a <b>non-calibrated</b> spectrometer is used. This diagnostic method is applicable when cross-sectional {{area of the}} active plasma volume and current density can be determined. The nitrogen emission in the spectral range of 380 nm- 406 nm is used for OES diagnostics. Electric field in the active plasma volume is determined applying the measured spectrum, well-known Frank-Condon factors for nitrogen transitions and numerically- simulated electron distribution functions. The measured electric current density is used for determination of electron density in plasma. Using the determined plasma parameters, the dissociation rate of nitrogen and oxygen in active plasma volume are calculated, {{which can be used}} by simulation of the chemical kinetics. Comment: 17 pages, 5 figure...|$|E
40|$|This paper {{presents}} a new method based on 3 D reconstruction from images that demonstrates the utility {{and integration of}} close-range photogrammetry and computer vision as an efficient alternative to modelling complex objects and scenarios of forensic infography. The results obtained confirm {{the validity of the}} method compared to other existing alternatives as it guarantees the following: (i) flexibility, permitting work with any type of camera (calibrated and <b>non-calibrated,</b> smartphone or tablet) and image (visible, infrared, thermal, etc.); (ii) automation, allowing the reconstruction of three-dimensional scenarios in the absence of manual intervention, and (iii) high quality results, sometimes providing higher resolution than modern laser scanning systems. As a result, each ocular inspection of a crime scene with any camera performed by the scientific police can be transformed into a scaled 3 d model...|$|E
3000|$|... 24 {{post-operative}} cardiac {{patients were}} prospectively enrolled. Arterial pressure and {{central venous pressure}} was measured invasively. Cardiac output (CO) was measured with a <b>non-calibrated</b> LiDCOplus monitor (LiDCO, Cambridge). Pmsf was measured using the stop-flow arterial venous equilibrium pressure method (1). Sublingual microcirculation was recorded with CytoCam (Braedius Medical, Amsterdam, The Netherlands). Data was recorded at baseline, immediately after the fluid infusion, 5 and 10 minutes {{after the end of}} 4 ml/Kg of crystalloids infused in 5 minutes. At each time at least three sublingual microcirculation videos were acquired to assess total vessel density (TVD), microcirculatory flow index (MFI), proportion of perfused vessel (PPV), perfused vessel density (PVD) and microcirculatory heterogeneity index (MHI). Analysis was performed with AVA software v. 3.2 (MicroVision Medical, Amsterdam, The Netherlands). Responders are defined by an increase in CO greater than 10 %.|$|E
40|$|Abstract-Functional-structural plant {{modeling}} and plant phenotyping require {{the measurement of}} geometric features in specimens. This data acquisition is called plant digitizing. Actually, these measurements are performed manually, in invasive or even destructive ways, or using expensive laser scanning equipment. Computer vision based 3 D reconstruction is an accurate and low cost alternative for the digitizing of plants not presenting a dense canopy. Sparse canopies are found in several important annual plants in agriculture as soybean and maize, at least in their early stages of development. This paper shows as {{the state of the}} art in structure from motion and multiple view stereo is able to produce accurate 3 D models for specimens presenting sparse canopies. Three-dimensional triangular meshes are computed from a set of <b>non-calibrated</b> images, modeling a basil and an Ixora specimens and accurately representing their leaves and branches. 2012 SIBGRAPI 2012...|$|E
40|$|An {{electro-optical}} {{proximity sensor}} capable of measuring {{the distance and}} two-dimensional orientation of an object’s surface is presented. The robustness of the sensor, targeted for utilization in robotic active sensing, is achieved via {{the development of a}} novel amplitude-modulated-based electro-optical transducer, an electronic-interface circuit that provides very good noise immunity and a wide dynamic operating range, and an effective multi-region calibration process that significantly improves pose-estimations at near proximities. An experimental setup was designed and implemented for the development and verification of the proposed proximity sensor in a simulated robotic environment. Experimental results using a variety of calibrated surfaces and materials are presented and discussed. It is shown that average accuracies of 0. 01 mm and 0. 03 deg. can be achieved. The robustness of the proximity sensor is also verified for potential use in grasping objects with apriori <b>non-calibrated</b> surfaces. ...|$|E
40|$|Abstract. Establishing {{correspondence}} between {{features of a}} set of images has been a long-standing issue amongst the computer vision community. We propose a method that solves the multi-frame correspondence problem by imposing a rank constraint on the observed scene, i. e. rigidity is assumed. Since our algorithm is based solely on a geometrical (global) criterion, it does not suffer from issues usually associated to local methods, such as the aperture problem. We model feature matching by introducing the assignment tensor, which allows simultaneous feature alignment for all images, thus providing a coherent solution to the calibrated multi-frame correspondence problem in a single step of linear complexity. Also, an iterative method is presented that is able to cope with the <b>non-calibrated</b> case. Moreover, our method is able to seamlessly reject a large number of outliers in every image, thus also handling occlusion in an integrated manner. ...|$|E
