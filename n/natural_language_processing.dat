10000|10000|Public
5|$|In 2015, the {{engineering}} firm ENGEO created an online service via the IBM partner program named GoFetchCode. GoFetchCode applies Watson's <b>natural</b> <b>language</b> <b>processing</b> and question-answering capabilities to the International Code Council's model building codes.|$|E
5|$|Python {{has been}} used in {{artificial}} intelligence tasks. As a scripting language with modular architecture, simple syntax and rich text processing tools, Python is often used for <b>natural</b> <b>language</b> <b>processing</b> tasks.|$|E
5|$|The <b>natural</b> <b>language</b> <b>processing</b> {{capabilities}} of Cortana {{are derived from}} Tellme Networks (bought by Microsoft in 2007) and are coupled with a Semantic search database called Satori.|$|E
40|$|Abstract: With the {{currently}} {{growing interest in}} the Semantic Web, keywords/metad-ata extraction is coming to play an increasingly important role. Keywords extraction from documents is a complex task in <b>natural</b> <b>languages</b> <b>processing.</b> Ideally this task con-cerns sophisticated semantic analysis. However, {{the complexity of the}} problem make...|$|R
40|$|<b>Natural</b> <b>Languages</b> <b>Processing</b> (NLP) {{has many}} {{applications}} such as Database user interfaces, Machine Translation. Knowledge Acquisition and Report Abstraction. Several approaches {{have been used in}} dealing with NLP. This paper describes an ongoing research project about understanding <b>natural</b> <b>language</b> text using object-oriented techniques. It starts with difficulties and challenges in semantic analysis. Then, a description of the object-oriented semantic analyzer is given. Advantages and disadvantages of using object orientation in semantic analysis are discussed. Then the paper describes evaluation criteria for the semantic analyzer...|$|R
40|$|Word sense {{ambiguity}} {{is present}} in all words {{with more than one}} meaning in several <b>natural</b> <b>languages</b> and is a fundamental characteristic of human language. This has consequences in trans-lation as it is necessary to find the right sense and the correct translation for each word. For this reason, the English word fair can mean reasona-ble or market such as plant also can mean factory or herb. The disambiguation problem has been recog-nize as a major problem in <b>natural</b> <b>languages</b> <b>processing</b> research. Several words have several meanings or senses. The disambiguation task seeks to find out which sense of an ambiguou...|$|R
5|$|Watson {{was created}} as a {{question}} answering (QA) computing system that IBM built to apply advanced <b>natural</b> <b>language</b> <b>processing,</b> information retrieval, knowledge representation, automated reasoning, and machine learning technologies {{to the field of}} open domain question answering.|$|E
25|$|<b>Natural</b> <b>language</b> <b>processing</b> gives {{machines}} {{the ability}} to read and understand human language. A sufficiently powerful <b>natural</b> <b>language</b> <b>processing</b> system would enable natural language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of <b>natural</b> <b>language</b> <b>processing</b> include information retrieval, text mining, question answering and machine translation.|$|E
25|$|GATE: a <b>natural</b> <b>{{language}}</b> <b>processing</b> {{and language}} engineering tool.|$|E
40|$|International audienceIn {{order to}} {{demonstrate}} privacy threats in social networks we show how to infer user preferences by random walks in a multiple graph representing simultaneously attributes and relationships links. For {{the approach to}} scale in a rst phase we reduce the space of attribute values by partition in balanced homogeneous clusters. Following the Deepwalk approach, the random walks are considered as sentences. Hence unsu-pervised learning techniques from <b>natural</b> <b>languages</b> <b>processing</b> can be employed in second phase to deduce semantic similarities of some attributes. We conduct initial experiments on real datasets to evaluate our approach...|$|R
40|$|In <b>Natural</b> <b>Languages</b> <b>Processing,</b> {{there are}} lots of syntax trees {{corresponding}} to a input sentence. If we can choose the correct syntax tree meaningfully, the quality of the processing is improved. Conventionally, we have used selectional restrictions. But semantic categories used in selectional restrictions are so rough that we couldn 2 ̆ 7 t choose the correct syntactic structure precisely. This paper shows the method of building the dependency constraint into a context free grammar by subdividing nonterminals according to the meaning of the phrase generated from the nonterminal and by grasping production rules from superordinate-subordinate relation of their meanings in the thesaurus...|$|R
40|$|In <b>Natural</b> <b>Languages</b> <b>Processing,</b> {{there are}} lots of syntax trees {{corresponding}} to an input sentence. If we can choose the correct syntax tree meaningfully, the quality of the processing is improved. We proposed the method of building the dependency constraint into a context free grammar by subdividing nonterminals according to the meaning of the phrase generated from the nonterminal and by grasping production rules from superordinate-subordinate relation of their meanings in the thesaurus. This paper shows estimation of the PCFG building the Dependency Constraint by the experiment of disambiguating which of N_ 2 or N_ 3 governs N_ 1 in the noun phrase 2 ̆ 2 N_ 1 のN_ 2 のN_ 32 ̆ 2...|$|R
25|$|The novel's {{creation}} {{spanned the}} fields of artificial intelligence, expert systems, and <b>natural</b> <b>language</b> <b>processing.</b>|$|E
25|$|Also in December 2011, Tagged {{acquired}} Topicmarks, a <b>natural</b> <b>language</b> <b>processing</b> {{and machine}} learning company.|$|E
25|$|This section {{under the}} C-DAC is {{specialized}} in Indian language speech, <b>natural</b> <b>language</b> <b>processing</b> and assistive technologies.|$|E
40|$|The {{hypothesis}} {{of the paper}} is that the domain of <b>Natural</b> <b>Languages</b> <b>Processing</b> (NLP) resembles current research in music so one could benefit from this by employing NLP techniques to music. In this paper the similarity between both domains is described. The levels of NLP are listed with pointers to respective tasks within the research of computational music. A brief introduction to history of NLP enables locating music research in this history. Possible directions of research in music, assuming its affinity to NLP, are introduced. Current research in generational and statistical music modeling is compared to similar NLP theories. The paper is concluded with guidelines for music research and information retrieval. 1...|$|R
40|$|Beginning {{with the}} basic issues of NLP, this chapter aims to chart the major {{research}} activities in this area since the last ARIST Chapter in 1996 (Haas, 1996), including: (i) <b>natural</b> <b>language</b> text <b>processing</b> systems - text summarization, information extraction, information retrieval, etc., including domain-specific applications; (ii) <b>natural</b> <b>language</b> interfaces; (iii) NLP {{in the context of}} www and digital libraries; and (iv) evaluation of NLP systems...|$|R
5000|$|Automatic {{syntactic}} analysis has recently become important for both <b>natural</b> <b>language</b> data <b>processing</b> and syntax-directed compilers. A formal parsing system G = (V, &mu;, T, R) {{consists of two}} finite disjoint vocabularies, V and T, a many-many map, &mu;, from V onto T, and a recursive set R of strings in T called syntactic sentence classes ...|$|R
25|$|Façade by Michael Mateas, Andrew Stern and John Grieve (2005). An {{interactive}} drama using <b>natural</b> <b>language</b> <b>processing.</b>|$|E
25|$|In the U.S, {{the concept}} of logical syntax helped the {{development}} of <b>natural</b> <b>language</b> <b>processing</b> and compiler design.|$|E
25|$|NLTK (Natural Language Toolkit): A {{suite of}} {{libraries}} and programs for symbolic and statistical <b>natural</b> <b>language</b> <b>processing</b> (NLP) for the Python language.|$|E
40|$|Abstract: With the {{currently}} {{growing interest in}} the Semantic Web, keywords/metadata extraction is coming to play an increasingly important role. Keywords extraction from documents is a complex task in <b>natural</b> <b>languages</b> <b>processing.</b> Ideally this task concerns sophisticated semantic analysis. However, {{the complexity of the}} problem makes 1472 current semantic analysis techniques insufficient. Machine learning methods can support the initial phases of keywords extraction and can thus improve the input to further semantic analysis phases. In this paper we propose a machine learning-based keywords extraction for given documents domain, namely scientific literature. More specifically, the least square support vector machine is used as a machine learning method. The proposed method takes the advantages of machine learning techniques and moves the complexity of the task to the process of learning from appropriate samples obtaine...|$|R
40|$|Unsupervised {{dependency}} parsing {{is one of}} {{the most}} challenging tasks in <b>natural</b> <b>languages</b> <b>processing.</b> The task involves finding the best possible dependency trees from raw sentences without getting any aid from annotated data. In this paper, we illustrate that by applying a supervised incremental parsing model to unsupervised parsing; parsing with a linear time complexity will be faster than the other methods. With only 15 training iterations with linear time complexity, we gain results comparable to those of other state of the art methods. By employing two simple universal linguistic rules inspired from the classical dependency grammar, we improve the results in some languages and get the state of the art results. We also test our model on a part of the ongoing Persian dependency treebank. This work is the first work done on the Persian language. ...|$|R
40|$|We {{address the}} {{integration}} of information ex-traction (IE) and ontologies. In particular, us-ing an ontology to aid the IE process, and using the IE results to help populate the ontology. We perform IE by means of domain specic templates and the lightweight use of <b>Natural</b> <b>Languages</b> <b>Processing</b> techniques (NLP). Our main goal is to learn information from text {{by the use of}} templates and in this way to alleviate the main bottleneck in creating knowledge-base systems that is extraction of knowledge". Our domain of study is Planet", a Web-based news server for communication of stories between members in our institute. The main goals of our system are to classify an incom-ing story, obtain the relevant objects within the story, deduce the relationships between them, and to populate the ontology. Furthermore, we aim to do this with minimal help from the user. ...|$|R
25|$|The cache {{language}} model and other statistical {{language model}}s {{that are used}} in <b>natural</b> <b>language</b> <b>processing</b> are also examples of applications of probability theory.|$|E
25|$|The major {{tasks in}} {{semantic}} evaluation {{include the following}} areas of <b>natural</b> <b>language</b> <b>processing.</b> This list {{is expected to grow}} as the field progresses.|$|E
25|$|Jurafsky, D. and J. Martin. 2008. Speech and {{language}} processing: An introduction to <b>natural</b> <b>language</b> <b>processing,</b> computational linguistics, and speech recognition. Delhi, India: Pearson Education.|$|E
40|$|This paper {{proposes a}} simple {{mechanism}} for supporting multiple overlapping layers of annotations for <b>natural</b> <b>language</b> text <b>processing.</b> We present a query language for flexibly accessing annotated text, and demonstrate its use on examples {{taken from the}} NLP literature. We then report on experiments comparing different storage and indexing architectures using an RDBMS, showing that annotation-based queries {{can be made to}} scale to large corpora with many layers of annotations. ...|$|R
40|$|AbstractThe use of {{constrained}} formal/computational systems just {{adequate for}} modeling {{various aspects of}} language—syntax, semantics, pragmatics and discourse, among others, {{has proved to be}} an effective research strategy leading to deep understanding of these aspects, with implications to both machine processing and human processing. This approach enables one to distinguish between the universal and stipulative constraints. This is in contrast to an approach where we start with the most powerful formal/computational system and then model the phenomena by making all constraints stipulative in a sense. The use of constrained systems for modeling leads to some novel ways of describing locality of structures and brings out the relationship between the complexity of description of primitives and local computations over them. These ideas serve to unify theoretical, computational and statistical aspects of <b>natural</b> <b>languages</b> <b>processing</b> in AI. It is expected that this approach will be productive in other domains of AI...|$|R
40|$|This paper {{presents}} our {{preliminary work}} on adaptation of parsing technology toward <b>natural</b> <b>language</b> query <b>processing</b> for biomedical domain. We built a small treebank of <b>natural</b> <b>language</b> queries, and tested a state-of-theart parser, {{the results of}} which revealed that a parser trained on Wall-Street-Journal articles and Medline abstracts did not work well on query sentences. We then experimented an adaptive learning technique, to seek the chance to improve the parsing performance on query sentences. Despite the small scale of the experiments, the results are encouraging, enlightening the direction for effective improvement. ...|$|R
25|$|Language {{engineering}} {{involves the}} creation of <b>natural</b> <b>language</b> <b>processing</b> systems, whose cost and outputs are measurable and predictable, as well as establishment of language regulators, such as formal or informal agencies, committees, societies or academies as language regulators, to design or develop new structures to meet contemporary needs. It is a distinct field contrasted to <b>natural</b> <b>language</b> <b>processing</b> and computational linguistics. A recent trend of language engineering {{is the use of}} Semantic Web technologies for the creation, archiving, processing, and retrieval of machine processable language data.|$|E
25|$|Deep {{learning}} in artificial neural networks with many layers has transformed many important subfields of artificial intelligence, including computer vision, speech recognition, <b>natural</b> <b>language</b> <b>processing</b> and others.|$|E
25|$|Abductive logic {{programming}} {{has been used}} for fault diagnosis, planning, <b>natural</b> <b>language</b> <b>processing</b> and machine learning. It has also been used to interpret Negation as Failure as a form of abductive reasoning.|$|E
40|$|Most of the {{existing}} text mining approaches are proposed, keeping in mind, transaction databases model. Thus, the mined dataset is structured using just one concept: the “transaction”, whereas the whole dataset is modeled using the “set” abstract type. In such cases, {{the structure of the}} whole dataset and the relationships among the transactions themselves are not modeled and consequently, not considered in the mining process. We believe that taking into account structure properties of hierarchically structured information (e. g. textual document, etc …) in the mining process, can leads to best results. For this purpose, an hierarchical associations rule mining approach for textual documents is proposed in this paper and the classical set-oriented mining approach is reconsidered profits to a Direct Acyclic Graph (DAG) oriented approach. <b>Natural</b> <b>languages</b> <b>processing</b> techniques are used in order to obtain the DAG structure. Based on this graph model, an hierarchical bottom up algorithm is proposed. The main idea is that each node is mined with its parent node...|$|R
40|$|Lexical {{semantic}} resources, like WordNet, {{are often}} used in real applications of <b>natural</b> <b>language</b> document <b>processing.</b> For example, we integrated GermaNet in our document suite XDOC of processing of German forensic autopsy protocols. In addition to the hypernymy and synonymy relation, we want to adapt GermaNet's verb frames for our analysis. In this paper we outline an approach for the domain related enrichment of GermaNet verb frames by corpus based syntactic and co-occurred data analyses of real documents. Comment: 4 page...|$|R
40|$|Traditional {{approaches}} to <b>Natural</b> <b>Language</b> Text <b>Processing</b> limit performance and flexibility by committing to canonical reprentations of input text, while many NLP applications for general {{tasks such as}} Textual Entailment use ad-hoc architectures with limited flexibility, and which limit the expressiveness of inference procedures over components. We present a Modular Representation and Comparison Scheme (MRCS) that addresses these problems by combining a modular representation with a modular, unification-like inference algorithm that allows the system architect to defer appropriate disambiguation decisions until run-time. ...|$|R
