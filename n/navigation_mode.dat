69|96|Public
5|$|Users can now pan and zoom {{while in}} <b>navigation</b> <b>mode.</b>|$|E
500|$|... environment. End of Ages offers players three {{navigation}} modes to explore. The first, [...] "Classic mode", {{uses the}} same controls used in Myst and Riven; Ages are divided into locations of interest, or nodes, and the player's view is fixed at every node. Players advance to other nodes by clicking on portions of the screen. The [...] "Classic Plus" [...] mode uses the control scheme of [...] and movement is still node-based but players can rotate their view 360 degrees in any direction. The final <b>navigation</b> <b>mode,</b> known as [...] "Free Look" [...] or [...] "Advanced" [...] mode, allows players to navigate and observe the Ages freely like [...] The WASD keyboard keys are used for walking forward, backward, and sideways, while the mouse changes the player's point of view.|$|E
2500|$|In {{the summer}} of 1951, a B-36 crew on a {{training}} mission out of Carswell AFB, Texas, to the Eglin AFB bombing range in the Gulf of Mexico was to drop an unarmed obsolete nuclear gravity bomb, likely a Mark 4, on a water target. Due to past mechanical problems, the bombardier was briefed to open the bomb bay doors at the Initial Point (IP). Although the bomber's bombing navigation radar {{was still in the}} <b>navigation</b> <b>mode,</b> the bomb dropped unexpectedly when the bay doors were opened, and the [...] of high explosives in the weapon burst in the air over a non-designated target area. An intensive investigation concluded that a corroded D-2 switch, a hand-held bomb release switch, was found to be in the [...] "closed" [...] position and the bomb was dropped through equipment malfunction.|$|E
30|$|The {{definition}} of <b>navigation</b> <b>modes</b> {{according to the}} intersection between four tasks and four users’ learning styles.|$|R
40|$|Most Autonomous Underwater Vehicles (AUVs) {{mount an}} Acoustic Doppler Current Profilers (ADCP). Data from this sensor are rarely used in {{scientific}} studies {{due to the}} complexity of its processing and the lack of validation. Aside of that, AUV operators lack a set of guidelines regarding the optimal <b>navigation</b> <b>modes</b> and AUV-borne ADCP configurations to obtain the most accurate data possible. This study compares 12. 6 hours of AUV-borne ADCP currents measurements, taken in different AUV <b>navigation</b> <b>modes</b> and ADCP configurations, to those of a moored AWAC. Results show RMS errors of 5 cm/s for U (East) and V (North) measures and of 2 cm/s for vertical currents measures for most of the <b>navigation</b> <b>modes.</b> Cell size is found to be the most influential parameter in data accuracy and yo-yo type of surveys are proved to be as accurate as constant depth ones. Postprint (published version...|$|R
40|$|Dynamic {{taxonomies}} and faceted search {{are increasingly}} used {{to organize and}} browse document collections. The main function of dynamic taxonomies is {{to start with the}} full collection, and zoom-in to a small enough subset of items for direct inspection. In this paper, we present other <b>navigation</b> <b>modes</b> than zoom-in for less directed and more exploratory browsing of a document collection. The presented <b>navigation</b> <b>modes</b> are zoom-out, shift, pivot, and querying by examples. These modes correspond to query transformations, and make use of boolean operators. Therefore, the current focus is always clearly specified by a query...|$|R
50|$|Users can now pan and zoom {{while in}} <b>navigation</b> <b>mode.</b>|$|E
5000|$|Nokia Maps (with 3 {{months of}} turn-by-turn <b>navigation</b> <b>mode</b> trial) ...|$|E
5000|$|... #Caption: Of {{these two}} OpenTracker windows {{containing}} computer icons for BeOS software applications, the bottom window features a single-window <b>navigation</b> <b>mode</b> introduced in OpenTracker.|$|E
50|$|Campus Maps {{features}} One Tap <b>Navigation,</b> Satellite <b>Mode,</b> and Street View.|$|R
40|$|As {{detailed}} in Chapter??, system implementations for dynamic taxonomies and faceted search allow {{a wide range}} of query possibilities on the data. Only when these are made accessible by appropriate user interfaces, the resulting applications can support a variety of search, browsing and analysis tasks. User interface design in this area is confronted with specific challenges. This chapter presents an overview of both established and novel principles and solutions. Based on a definition of core principles (see Section 1. 1) and challenges (see Section 1. 2), we define a taxonomy of <b>navigation</b> <b>modes</b> observed in existing applications (see Section 1. 3). On that basis, design patterns for enabling these <b>navigation</b> <b>modes</b> in user interfaces (see Section 1. 4) as well as extensions and related approaches (see Section 1. 5) are discussed. The chapter closes with an approach to personalizing faceted search (see Section 1. 6) ...|$|R
40|$|Current VRML browser {{implementations}} {{lack the}} flexibility of adaptable user interfaces and <b>navigation</b> <b>modes,</b> which is in massive contradiction to the primary motivation for using 3 D, namely to give the user a more natural {{understanding of how to}} interact with computer systems, and, in return, to make computer work more timeefficient. Multimodal interaction, {{such as the use of}} gesture and speech recognition, promises further improvement of the usability of 3 D applications, but can only be seen in dedicated applications thus far. We present a user interface framework including the definition of a node set and the interfaces to other devices: As a key feature, we propose a DeviceSensor node that allows grabbing arbitrary user input, and a Camera-node to realize arbitrary <b>navigation</b> <b>modes.</b> The interface is based on the formalism of a context-free grammar providing the representation of domain- and device-independent multimodal information contents. 1...|$|R
50|$|Certain {{games in}} this version feature a <b>navigation</b> <b>mode</b> that shows various hints and tips {{throughout}} the gameplay {{to assist the}} player. The games that feature this mode are Galaga, The Tower of Druaga, Xevious, and Super Xevious.|$|E
50|$|Contributors {{have added}} support for on-line mapping {{sources such as}} OpenStreetMap {{and the ability to}} {{interpret}} KML files. Marble also provides route planning capabilities. A <b>navigation</b> <b>mode</b> called MarbleToGo was developed as part of Google Summer of Code 2010. It was later partially rewritten and renamed to Marble Touch.|$|E
5000|$|In {{this text}} <b>navigation</b> <b>mode</b> the ‘cursor’, often {{depicted}} as a blinking vertical line, appears within the text on-screen. The user can then navigate throughout the text by using the arrow navigation keys to cause the cursor to move; typically changing the cursor’s location in increments of character position horizontally and of text line vertically.|$|E
40|$|A Generic User Interface Framework Current VRML browser {{implementations}} {{lack the}} flexibility of adaptable user interfaces and <b>navigation</b> <b>modes,</b> in massive contradiction to the primary motivation for using 3 D, namely to give the user a more natural {{understanding of how to}} interact with computer systems and, in return, to make computer work more time-efficient. Multimodal interaction, {{such as the use of}} gesture and speech recognition, promises further improvement of the usability of 3 D applications but can only be seen in dedicated applications thus far. We present a user interface framework including the definition of a node set and the interfaces to other devices: As a key feature, we propose a DeviceSensor node that allows grabbing arbitrary user input, and a Camera node to realize arbitrary <b>navigation</b> <b>modes.</b> The interface is based on the abstract formalism of a context-free grammar providing the representation of domain- and device-independent multimodal information contents. By changing the grammer the behaviour of the system can easily be modified...|$|R
40|$|The paper {{collects}} {{arguments to}} present that the consumption- and emission {{characteristics of the}} rail and inland <b>navigation</b> <b>modes</b> {{are very close to}} each other. Considering that these modes are able to transport {{more or less the same}} groups of goods, it is a much better way to develop them within an integrated transport policy than trying to bring arguments for one of them against the other...|$|R
40|$|In this paper, we {{describe}} {{a framework for}} such an assisted navigation system within Haystack. Under this framework, an architect needs not consider the user interface at all and only needs to specify a set of possible navigation steps and their outcomes. The Haystack user interface takes care of presenting these steps to the user and letting him or her select one. Using this framework, we have built what {{we believe to be}} a number of natural <b>navigation</b> <b>modes...</b>|$|R
50|$|The {{weapon is}} a {{guidance}} kit {{based on the}} existing Enhanced Paveway II Enhanced Computer Control Group (ECCG) added to a modified Mk 82 general-purpose bomb with increased penetration performance. The new ECCG contains a Height of Burst (HOB) sensor enabling air burst fusing options, and a SAASM (Selective Availability Anti Spoofing Module) compliant GPS receiver. It can be launched either IMU (Inertial Measurement Unit) only, given sufficiently good Transfer Alignment, or using GPS guidance. Terminal laser guidance is available in either <b>navigation</b> <b>mode.</b>|$|E
5000|$|The {{handlebars}} can be {{remotely controlled}} via a smartphone app when {{connected to a}} Bluetooth Low Energy (4.0) enabled smartphone. This allows them to be switched between a visual speedometer mode where the rear LEDs change color based on your speed, and a turn-by-turn <b>navigation</b> <b>mode</b> where the rear LEDs guide you to a destination by blinking left or right when a turn is approaching. Additionally, turn signals, or [...] "blinkers," [...] can be activated by pressing a tactile button {{on either side of}} the stem.|$|E
50|$|The board {{concluded}} that the 37° turn was executed by the navigator using the autopilot's Doppler <b>navigation</b> <b>mode,</b> which when set maintained the desired heading while making corrections for wind drift. The navigator performed this turn after he saw the VOR signal indicating that the aircraft had intercepted the Maputo VOR 45° radial, the compass direction from Maputo on which the crew intended to turn and approach for a landing on runway 23. However the turn actually put the aircraft on a path following a 45° radial from the VOR beacon at Matsapa Airport, Swaziland.|$|E
40|$|The Vl’rof Tutor is a {{computer-based}} intelligent tutoring system (ITS) {{that teaches}} {{the use and}} understanding of vertical profile <b>navigation</b> <b>modes</b> to MD-l I pilots. This ITS is a proof-of-concept implementation of GT-ITACS (Georgia Tech-Intelligent Tutoring Architecture for Complex Systems). GT-ITACS is a domain- and platform- independent intelligent tutoring system shell designed to train onerators of corn&xdvnamic svstems. This naner introduces the features of GT-ITACS, using the VProf L,, I & Tutor to illustrate {{the capabilities of the}} system...|$|R
40|$|Abstract. Graphical {{information}} {{is very important}} in common information publishing. For visually impaired users this {{information is}} usually not accessible. Scalable Vector Graphics, a recommendation of the World Wide Web Consortium, describes graphical information in an XML document. We propose a transformation scheme into a tactile representation for this kind of graphics. <b>Navigation</b> <b>modes,</b> filters, and the output of meta information support the exploration of the graphics. Furthermore our software environment can simulate this transformation for all sizes of tactile devices. ...|$|R
5|$|In both <b>navigation</b> <b>modes,</b> Air-Cobot is {{also able}} to detect, track, {{identify}} and avoid obstacles that are in its way. The laser data from laser range sensors and visual data from the cameras {{can be used for}} detection, monitoring and identification of the obstacles. The detection and monitoring are better in the two-dimensional laser data, while identification is easier in the images from the cameras; the two methods are complementary. Information from laser data can be used to delimit work areas in the image.|$|R
50|$|Lakshya-II flew at sea {{skimming}} {{height of}} about 15 meters. In a flight lasting over 30 minutes, {{it was made}} to dive down from an altitude of around 800 m to just 12 m and maintained the requisite altitude for the specified time before demonstrating auto climb-out. It demonstrated various technologies and sub-systems to prevent loss of mission, engaging and flying in way point <b>navigation</b> <b>mode</b> while carrying tow targets. During the flight, one of the tow targets was released {{and the other was}} deployed while way point navigation was on.|$|E
50|$|During WWDC in June 2013, Apple {{announced}} {{the new version}} of Apple Maps in iOS 7. This new version had a new look and icon. A number of new functions were also implemented, including full-screen mode, night mode, real-time traffic information, navigation for pedestrians, and the Frequent Locations feature. The latter feature, which can be switched on and off, was introduced to record the most frequently visited destinations by users {{in order to improve}} Apple Maps. In addition, new satellite imagery was added once again. On September 18, 2013, Apple released iOS 7. At that time, the new iPhone 5S included a new motion coprocessor, the M7, which can identify whether a user is walking or driving in order to adjust the <b>navigation</b> <b>mode.</b>|$|E
5000|$|In {{the summer}} of 1951, a B-36 crew on a {{training}} mission out of Carswell AFB, Texas, to the Eglin AFB bombing range in the Gulf of Mexico was to drop an unarmed obsolete nuclear gravity bomb, likely a Mark 4, on a water target. Due to past mechanical problems, the bombardier was briefed to open the bomb bay doors at the Initial Point (IP). Although the bomber's bombing navigation radar {{was still in the}} <b>navigation</b> <b>mode,</b> the bomb dropped unexpectedly when the bay doors were opened, and the 5000 lb. of high explosives in the weapon burst in the air over a non-designated target area. An intensive investigation concluded that a corroded D-2 switch, a hand-held bomb release switch, was found to be in the [...] "closed" [...] position and the bomb was dropped through equipment malfunction.|$|E
40|$|We {{introduce}} an algorithm for navigation to a {{goal with}} obstacle avoidance for the Sony AIBO mobile robot. The algorithm {{makes use of}} the robot's single monocular camera for both localization and obstacle detection. The algorithm alternates between two different <b>navigation</b> <b>modes.</b> When the area {{in front of the}} robot is unobstructed, the robot navigates straight towards the goal. When the path is obstructed, the robot will follow the contours of the obstacles until the way is clear. We show how the algorithm [...] ...|$|R
50|$|In both <b>navigation</b> <b>modes,</b> Air-Cobot is {{also able}} to detect, track, {{identify}} and avoid obstacles that are in its way. The laser data from laser range sensors and visual data from the cameras {{can be used for}} detection, monitoring and identification of the obstacles. The detection and monitoring are better in the two-dimensional laser data, while identification is easier in the images from the cameras; the two methods are complementary. Information from laser data can be used to delimit work areas in the image.|$|R
40|$|Abstract. Cooperative {{navigation}} {{of multiple}} Unmanned Underwater Vehicles(multi-UUVs) {{is an important}} approach to solve localization problem of UUV formation. This paper expatiates on the popular cooperative <b>navigation</b> <b>modes</b> of Leader-Fellow structure and Moving Long Base Line(MLBL) structure, and provides the motion equations and the measure equation based on hydroacoustic Time-Of-Flight(TOF), and studies on the cooperative navigation methods which make use of two nonlinear filters of EKF and UKF. It is an obvious conclusion that adopting cooperative navigation methods can improve effectively localization accuracy of UUV equipped with low precision navigation sensors...|$|R
5000|$|Myst V: End of Ages is an {{adventure}} game {{taking place in}} the first person. Players travel across several worlds known as [...] "Ages", solving puzzles and gathering story clues by reading books or observing the environment. End of Ages offers players three navigation modes to explore. The first, [...] "Classic mode", uses the same controls used in Myst and Riven; Ages are divided into locations of interest, or nodes, and the player's view is fixed at every node. Players advance to other nodes by clicking on portions of the screen. The [...] "Classic Plus" [...] mode uses the control scheme of Myst III: Exile and Myst IV: Revelation; movement is still node-based but players can rotate their view 360 degrees in any direction. The final <b>navigation</b> <b>mode,</b> known as [...] "Free Look" [...] or [...] "Advanced" [...] mode, allows players to navigate and observe the Ages freely like Uru: Ages Beyond Myst. The WASD keyboard keys are used for walking forward, backward, and sideways, while the mouse changes the player's point of view.|$|E
50|$|The {{cockpit of}} the PC-21 {{features}} {{a high level}} of systems integration and conforms to modern avionics standards. The systems of the forward and rear cockpits can be 'de-coupled' between the student and instructor; the instructor may exercise real-time manipulation of the student's displays, sensor performance, and system modes such as to create synthetic air-to-air radar targets, artificial non-safety critical system failures, and controlled data degradation. The aircraft's fully digital glass cockpit features three large colour liquid crystal displays (LCD), one performing as the primary flight display (PFD) and two multi-function displays (MFDs) for system/mission management, in addition to CMC Electronics-provided head-up displays (HUD) for both the pilot and instructor. The trim gauge is the only analogue dial in the cockpit. For control simplicity, a Hands on Throttle and Stick (HOTAS) control philosophy has been followed. Both the display and control systems present also resemble their counterparts used upon modern front-line combat aircraft for greater realism during training; and can be further customized in order to be more representative of specific combat aircraft. The multi-sensor navigation system is capable of operating under a military tactical mode as well as a civil <b>navigation</b> <b>mode.</b>|$|E
5000|$|Brunton next {{introduced}} an electronic fluxgate compass imported from Taiwan, the Brunton Outback™, in 2000. The Outback had gimbal-mounted magnetic sensors which the manufacturer claimed allowed the unit to be tilted up to 15 degrees and still give accurate readings within its ultimate azimuth accuracy (plus or minus two degrees). The Outback stored up to 10 compass bearings in its memory, and featured a night <b>navigation</b> <b>mode</b> with illuminated arrows that warned if the user was moving off-track. The Outback was eventually {{replaced by the}} Brunton Nomad™ electronic compass. After complaints from owners about difficulties in calibrating the electronic compass feature and inaccurate bearings, the Nomad was discontinued in 2011. [...] In 2009, Brunton, Inc. was sold by Fiskars, Silva of Sweden's parent owner, and by the following year Brunton began to cease importing most Silva of Sweden compass products, including the Nexus and Elite lines {{as well as the}} Silva Model 54, a prismatic-sight baseplate compass relabeled as the Brunton 54LU™ for sale in North America. The Brunton 54LU was marketed to foresters, surveyors, geologists, SAR teams, and others as a precision navigation compass before being discontinued. [...] Some models that had formerly been imported from Sweden, including the Brunton 15TDCL and Brunton 16DLU, were later sourced from a production facility in China. In 2011, Brunton discontinued the Models 8010G, 8020, 8040G, 9020G, and 9030 compasses.|$|E
40|$|The paper explores {{innovative}} {{methods of}} navigation for experiencing and spatial comprehension of complex 3 D digital environments. Common <b>navigation</b> <b>modes</b> of digital environments {{are difficult to}} learn and use within complex multi level digital models and often result in the viewer becoming disoriented or stuck. By drawing on concepts from computer gaming and spatial way finding this research will explore intuitive navigation systems. These systems enable the user to engage and experience the digital space much more profoundly than current CAD and BIM model viewing software. The paper demonstrates these navigation spatial cognition systems through three case studies...|$|R
40|$|The paper {{reports the}} ongoing {{functional}} specification of a virtual archaeology system. Taking {{into account the}} goals of ISO standards MPEG- 7 and SEDRIS, we have summarized methodologies from related IT fields (visualization, multimedia, HCI and VR) relevant for virtual archaeology system functionality. One part of the ideas {{has been used to}} specify the functionality of a particular system for immersively exploring the ancient Greek excavations model within the Studierstube virtual reality installation. In particular, the visualization scenarios, <b>navigation</b> <b>modes</b> and sound spaces complete functionalities were specified. The results contribute both to current methodology and future research findings...|$|R
40|$|In {{order to}} assist {{daylight}} ambience design by referential procedures, we propose {{in this article}} {{an analysis of the}} modalities of reference activity in the field of architectural design. We have identified three different activities: selecting a potential reference, projection of the reference in the project, integration of the reference into the project, allowing intentions formulation. We have used the results of this analysis to propose <b>navigation</b> <b>modes</b> adapted to an exploitation of image references in design, in order to develop a tool supporting the formulation of luminous ambience intention. The purpose here is to inform on exploratory progress more than to communicate attested results. ...|$|R
