0|70|Public
2500|$|Consider {{the case}} {{where there is no}} sentient observer, i.e. no mind around to observe the experiment. In this case, the {{detector}} will be in an indefinite state. The photon is both passed and absorbed, and will remain in this state. The correlations are withheld in that none of the possible [...] "minds", or wave function states, correspond to <b>non</b> <b>correlated</b> results.|$|R
40|$|The {{volume of}} {{documents}} available electronically is growing fast, so it becomes difficult to access and select desired {{information in a}} fast and efficient way. In this context the automatic summarization task assumes a very imperative role; therefore one seeks {{to reduce the size}} of a document, preserving to the maximum its informative content. In this paper, it’s applied a model which uses sentence clusters from an ART 2 neural network to generate extractive summaries. Different models can be developed from distinct area documents. Hence, the aim of this work is to evaluate the performance of those models when they summarize documents from <b>correlated</b> or <b>non</b> <b>correlated</b> areas. Eje: V - Workshop de agentes y sistemas inteligente...|$|R
40|$|This paper aims {{to prove}} that in {{countries}} with no inter-zonal real estate divergence caused by lack of uniform economic development, labor migration trends or other causes, the real estate price movements tend to be <b>correlated</b> with <b>currency</b> movements, thus a certain vulnerability to hot money exists however it may be manageable. ...|$|R
40|$|We {{present a}} {{numerical}} {{study on the}} use of electrostatic force microscopy (EFM) as a non invasive subsurface characterization technique. We discuss the ability to resolve a buried object in a dielectric matrix considering two parameters: the detectability (i. e., signal superior to the noise) and the lateral resolution. The effects of the dielectric constant, thickness of the sample, and depth at which the object is buried are quantified. We show that the sensitivity reached in EFM permits to characterize subsurface objects in a dielectric matrix. We demonstrate that both lateral resolution and detectability decreases when the tip object distance increases. On the other hand, these two quantities increase with the dielectric constant of the matrix. A first step toward EFM tomography is proposed for objects creating <b>non</b> <b>correlated</b> signals. Peer Reviewe...|$|R
40|$|Phase {{transitions}} {{inside the}} pores of an aerogel are investigated by modelizing the aerogel structure by diffusion-limited cluster-cluster aggregation on a cubic lattice in a finite box and considering $q$-states Potts variables {{on the empty}} sites interacting via nearest-neighbours. Using a finite size scaling analysing of Monte-Carlo numerical results, it is concluded that for $q= 4 $ the transition changes from first order to second order as the aerogel concentration (density) increases. Comparison is made with the case $q= 3 $ (where the first order transition is weaker in three dimensions) and with the case $q= 4 $ but for randomly (<b>non</b> <b>correlated)</b> occupied sites. Possible applications to experiments are discussed. Comment: RevTex, 12 pages + 10 postscript figures compressed using "uufiles", To appear in J. of Non-Cryst. Solid...|$|R
40|$|This paper {{documents}} how currency speculators trade when {{international capital}} flows generate predictable exchange rate movements. The redefinition of the MSCI world equity index in December 2000 provides an ideal natural experiment identifying exogenous capital flows of index tracking equity funds. Currency speculators are shown to front-run international capital flows. Furthermore, they actively manage the portfolio risk of their speculative positions through hedging positions in <b>correlated</b> <b>currencies.</b> The exchange rate effect of separate risk hedging is economically significant {{and amounts to}} a return difference of 3. 6 percent over a 5 day event window between currencies with high and low risk hedging value. The results of the classical event study analysis are confirmed by {{a new and more}} powerful spectral inference isolating the high frequency cospectrum of currency pairs. The evidence supports the idea that international currency arbitrage is limited by the speculators' risk aversion. Cospectrum; Limited Arbitrage; Multi-Currency Risk Hedging; Spectral Inference; Speculative Trading...|$|R
40|$|The {{idea that}} a {{computer}} system {{could be used to}} motivate people to perform a certain task {{on the basis of a}} user model is certainly not novel. As early as the 80 s, intelligent tutoring systems would encourage students to learn by means of tailored feedback and hints [24], and in the 90 s patient education systems would attempt to address the problem of compliance to a medical regimen by means of information and personalised advice [1] or would encourage people to adopt healthier lifestyles [19]. It is however only recently that a number of, seemingly <b>non</b> <b>correlated,</b> extensive research efforts, from various perspectives, have started to focus on a more complex cognitive model of rational and extra-rational features, involving emotions, persuasion, motivation and argumentation. We can distinguish three parallel strands of research that have become prominent...|$|R
40|$|This paper investigates {{a method}} of Handwritten English Character Recognition using Artificial Neural Network (ANN). This {{work has been done}} in offline Environment for <b>non</b> <b>correlated</b> characters, which do not possess any linear {{relationships}} among them. We test that whether the particular tested character belongs to a cluster or not. The implementation is carried out in Matlab environment and successfully tested. Fifty-two sets of English alphabets are used to train the ANN and test the network. The algorithms are tested with 26 capital letters and 26 small letters. The testing result showed that the proposed ANN based algorithm showed a maximum recognition rate of 85 %. Comment: appeared in: proceedings of National Conference on Dynamics and Prospects of Data Mining: Theory and Practices (DPDM) - 2012; September 30, 2012, India; Publisher: OITS-BLS, Balasore Chapter; Proceeding ISBN: 987 - 93 - 81361 - 31 - 6, pp. 79 - 8...|$|R
40|$|A hanging glacier at {{the east}} face of Weisshorn broke off in 2005. We were able to monitor and measure surface motion and icequake {{activity}} for 21 days up to three days prior to the break-off. Results are presented from the analysis of seismic waves generated by the glacier during the rupture maturation process. Three types of precursory signals of the imminent catastrophic rupture were identified: (i) an increasing seismic activity within the glacier, (ii) {{a change in the}} size-frequency distribution of icequake energy, and (iii) a log-periodic oscillating behavior superimposed on power law acceleration of the inverse of waiting time between two icequakes. The analysis of the seismic activity gave indications of the rupture process and led to the identification of two regimes: a stable one where events are isolated and <b>non</b> <b>correlated</b> which is characteristic of diffuse damage, and an unstable and dangerous one in which events become synchronized and large icequakes are triggered. Comment: 5 pages, 3 figure...|$|R
40|$|We {{consider}} {{tests for}} lack of fit in ARMA models with non independent innovations. In this framework, the standard Box-Pierce and Ljung-Box portmanteau tests can perform poorly. Specifically, the usual text book formulas for asymptotic distributions are based on strong assumptions {{and should not be}} applied without careful consideration. In this paper, we derive the asymptotic covariance matrix Σρ̂m of a vector of autocorrelations for residuals of ARMA models under weak assumptions on the noise. The asymptotic distribution of the portmanteau statistics follows. A consistent estimator of Σρ̂m, and a modification of the portmanteau tests are proposed. This allows to construct valid asymptotic significance limits for the residual autocorrelations, and (asymptotically) valid goodness-of-fit tests, when the underlying noise process is assumed to be <b>non</b> <b>correlated</b> rather than independent or a martingale difference. A set of Monte-Carlo experiments, and an application to the Standard & Poor’s 500 returns, illustrate the practical relevance of our theoretical results...|$|R
40|$|The paper {{deals with}} optimal {{portfolio}} choice problems when risk levels are given by coherent risk mea sures, expectation bounded risk measures or general deviations. Both static and dynamic pricing models may be involved. Unbounded problems {{are characterized by}} new notions such as (strong) compatibility between prices and risks. Surprisingly, the lack of bounded optimal risk and/or return levels arises for important pricing models (Black and Scholes) and risk measures (VaR, CVaR, absolute deviation, etc.). Bounded problems present a Market Price of Risk and generate a pair of benchmarks. From these bench marks we introduce APT and CAPM like analyses, {{in the sense that}} the level of correlation between every available security and some economic factors explains the security expected return. The risk level <b>non</b> <b>correlated</b> with these factors has no influence on any return, despite the fact that we are dealing with risk functions beyond the standard deviation. Risk measure; Compatibility between prices and risks; Efficient portfolio; APT and CAPM-like models;...|$|R
40|$|A travel {{distance}} model for debris flows and slides is presented {{based on information}} collected in southeast British Columbia, Canada. The model incorporates a variable that represents terrain morphology by a single number, quantification made using a one-to-one correspondence between the binary and decimal numeration systems. The terrain morphology coding has a site-specific character, providing a process-based representation of local conditions. Multiple regression {{analysis was used to}} assess the dependence of event {{travel distance}} on terrain morphology, slope, stand height, terrain curvature and canopy closure (R 2 = 0. 975, p < 0. 001). The model fulfills all the assumptions and requirements of regression analysis (i. e. normality, homoscedasticity, <b>non</b> <b>correlated</b> errors, lack of colinearity or outliers). An independent data set was used to test the model. The model successfully predicted {{all but one of the}} test dataset events, and one of four outliers. The model consists of an equation that can be used in mass movement risk assessment associated, with different forest activities (e. g. harvesting, road building).  </span...|$|R
40|$|BASUKI RAKHMAT. NIM. H 0202031. “Fertilizing, Soil Organic Matter and Cation Exchange Capacity Relationship at Paddy Soil in Jatisrono, Wonogiri”. Under the {{supervision}} of Ir. Jauhari Syamsiyah, MS. and Mujiyo, SP., MP. Agriculture Faculty of Sebelas Maret University, Surakarta. This rsearch aims at knowing the correlation between fertilizing system with soil organic matter and cation exchange capacity (CEC) at paddy soil in Jatisrono, Wonogiri. This study is explorative and correlative research whose variable approach by survey on the location and supported with laboratory analysis. The act of determining sample point is taken randomly based on variation of fertilizing (kind and dosage of fertilizer) at each Soil Map Unit. The Fertilizing data {{was obtained from the}} result of interview with the farmers. While the data of soil organic matter and CEC available was obtained from the result of laboratory analyze. The result of this research shows that the fertilizing system in Jatisrono are <b>non</b> <b>correlated</b> significantly with the soil organic matter and CEC. The soil organic matter of Jatisrono paddy soil is ranged from 0. 71...|$|R
40|$|Compatibility between {{prices and}} risks Efficient {{portfolio}} APT and CAPM-like models a b s t r a c t The paper deals with optimal portfolio choice problems when risk levels are given by coherent risk mea sures, expectation bounded risk measures or general deviations. Both static and dynamic pricing models may be involved. Unbounded problems {{are characterized by}} new notions such as (strong) compatibility between prices and risks. Surprisingly, the lack of bounded optimal risk and/or return levels arises for important pricing models (Black and Scholes) and risk measures (VaR, CVaR, absolute deviation, etc.). Bounded problems present a Market Price of Risk and generate a pair of benchmarks. From these bench marks we introduce APT and CAPM like analyses, {{in the sense that}} the level of correlation between every available security and some economic factors explains the security expected return. The risk level <b>non</b> <b>correlated</b> with these factors has no influence on any return, despite the fact that we are dealing with risk functions beyond the standard deviation. 1...|$|R
40|$|This {{research}} has {{the objective of}} characterize the historical series as correlated in a high scope in base of the power law, non- correlated and anti- correlated with corporative business practices trades, in comparison with others without this practice, using the application method Detrended Fluctuation Analysis - DFA to the historical scrip series belonging to the Stock Exchange Index of São Paulo (IBOVESPA) and the Differentiated Corporate Governance Index - IGC of Stock Exchange, Commodities and Futures - BMF&BOVESPA in the period between January 2 nd, 2007 to December 31, 2012. The comparison between both groups indicates that the one formed by trade scrips with business corporative practices is preferable for the trade managers who aim abnormal not normaly, once they present a bigger percent of correlated actions in a high scope, basing on the power law with positive asymmetry, or anti correlated with negative asymmetry. In both groups, {{it was not possible}} to identify actions with <b>non</b> <b>correlated</b> historical series, responsible to the randomizing outing that characterizes the efficient marke...|$|R
40|$|Abstract: This paper {{presents}} {{the application of}} a probabilistic approach for variational inversion in acoustic tomography. The aim is to determine the time-evolving, range-averaged, vertical profile of speed of sound), (zc in a shallow water environment from the acoustic pressure fields generated by a monochromatic sound source and measured on a sparse vertical hydrophone array. A variational approach that minimizes a cost function which measures the distance between observations and their modelled counterparts is used. As the tomographic inversion is an ill-posed problem a regularization term {{in the form of a}} quadratic restoring term to a background is added. To avoid inverting for the variance-covariance matrix associated with the above weighted quadratic background, it is proposed to model the sound speed vector using probabilistic principal component analysis (PPCA). The probabilistic PCA introduces an optimum reduced number of <b>non</b> <b>correlated</b> latent variables which determine a new control vector and introduce a new regularization term, expressed as T. PPCA represents a rigorous formalism for the use of a priori information and allows for an efficient implementation of the variational inverse method. In the present work the probabilistic PCA is applied to an acoustic tomography scenario in the South Elba environment...|$|R
40|$|Abstract. As System on a Chip (SoC) testing faces new challenges, {{some new}} test {{architectures}} must be developed. This paper describes a Test Access Mechanism (TAM) named CAS-BUS that solves {{some of the}} new problems the test industry has to deal with. This TAM is scalable, flexible and dynamically reconfigurable. The CAS-BUS architecture is compatible with the IEEE P 1500 standard proposal in its current state of development, and is controlled by Boundary Scan features. This basic CAS-BUS architecture has been extended with two independent variants. The first extension has been designed in order to manage SoC made up with both wrapped cores and non wrapped cores with Boundray Scan features. The second deals with a test pin expansion method in order to solve the I/O bandwidth problem. The proposed solution is based on a new compression/decompression mechanism which provides significant results in case of <b>non</b> <b>correlated</b> test patterns processing. This solution avoids TAM performance degradation. These test architectures are based on the CAS-BUS TAM and allow trade-offs to optimize both test time and area overhead. A tool-box environment is provided, in order to automatically generate the needed component to build the chosen SoC test architecture...|$|R
40|$|Paris, June 29 - July 4 We {{present an}} Ocean Acoustic Tomography (OAT) {{inversion}} {{in a shallow}} water environment. The idea {{is to determine the}} celerity c(z), z is depth, knowing the acoustic pressures caused by a multiple frequencies source and collected by a sparse receiver array. The variational approach minimizes a cost function which measures the adequacy between the measurements and their forward model equivalent. This method introduces also a regularization term in the form (c(z) -c_b(z)) ^TB^- 1 (c(z) -c_b(z)), which supposes that c(z) follows an a priori normal law. To circumvent the problem of estimating B^- 1, we propose to model the celerity vectors by a probabilistic PCA. In contrast to the methods which use PCA as a regularization method and filter the useful information, we take a sufficient number of axes which allow the modelization of useful information and filter only the noise. The probabilistic PCA introduces a reduced number of <b>non</b> <b>correlated</b> latent variables η which act as new control parameters introduced in the cost function. This new regularization term, expressed as η^Tη, reduces the optimization computation time. In the following we apply the probabilistic PCA to an OAT problem, and present the results obtained when performing twin experiments...|$|R
40|$|The paper {{deals with}} optimal {{portfolio}} choice problems when risk levels are given by coherent risk measures, expectation bounded risk measures or general deviations. Both static and dynamic pricing models may be involved. Unbounded problems {{are characterized by}} new notions such as compatibility and strong compatibility between pricing rules and risk measures. Surprisingly, it is {{pointed out that the}} lack of bounded optimal risk and/or return levels arises in practice for very important pricing models (for instance, the Black and Scholes model) and risk measures (V aR, CV aR, absolute deviation and downside semi-deviation, etc.). Bounded problems will present a Market Price of Risk and generate a pair of benchmarks. From these benchmarks we will introduce APT and CAPM like analyses, {{in the sense that the}} level of correlation between every available security and some economic factors will expalin the security expected return. On the contray, the risk level <b>non</b> <b>correlated</b> with these factors will have no influence on any return, despite we are dealing with very general risk functions that are beyond the standard deviation. Research partially supported by “RD_Sistemas SA”, “Comunidad Autónoma de Madrid” (Spain), Grant s− 0505 /tic/ 000230, and “MEyC” (Spain), Grant SEJ 2006 − 15401 −C 0...|$|R
40|$|This paper {{describes}} various techniques using PROC SQL {{to improve}} efficiency, performance and clarity of SAS programs. Programmers working on post {{marketing and sales}} data are often presented {{with the challenge of}} summarizing datasets containing thousands of variables and millions of records. This can be accomplished by using arrays in conjunction with OF operator on some functions like SUM and NMISS in a DATA step. However, arrays and OF operators are not supported in select statement of PROC SQL which means all the variables in the dataset has to be listed in the summarizing function which is tedious and impractical when thousands of variables are involved. This paper starts with description of a technique which makes use of efficiency of PROC SQL without having to list all the variables. Then, a technique to convert correlated sub queries using PROC SQL into a left join and <b>non</b> <b>correlated</b> sub query using PROC SQL is presented. This improves clarity of pro-gramming and makes it easier to understand for beginners without compromising on performance. Some more techniques are discussed including the one which reproduces the results of PROC SORT with NODUP-KEY/NODUPLICATES options using PROC SQL with DISTINCT or UNIQUE and other undocumented PROC SQL options. All the techniques described are illustrated with different real time scenarios...|$|R
40|$|In a {{framework}} for risk management a model of an international firm under exchange rate uncertainty is discussed. The firm can cross-hedge the exchange rate risk by using forwards of other country's <b>currencies</b> <b>correlated</b> to the spot exchange rate in question. The study investigates the implications of hedging exchange rate risk of less common currencies for an exporting firm...|$|R
40|$|Indicators of {{financial}} crisis {{generally do not}} have a good track record. This paper presents an early warning system (EWS) for six countries in Asia in which indicators do work. Our binary choice model, which has been estimated for the period 1970 : 01 – 2001. 12, has the following features. We compare four different currency crisis definitions, extract a full list of currency crisis indicators from the literature, apply factor analysis to combine the indicators, and introduce dynamics. We find that money growth (M 1 and M 2), national savings, and import growth <b>correlate</b> with <b>currency</b> crises. financial crises, currency crises, early warning system, panel data, multivariate logit, factor analysis...|$|R
40|$|Autorregressive {{integrated}} {{moving average}} models ARIMA, were adjusted to series of monthly sun bright for 32 meteorological stations of The National Federation of Coffee Growers of Colombia. The {{structure of the}} adjusted models was ARIMA(0; 1; 1) * (0; 1; 1) 12 this is a moving average with a seasonality component each 12 month, the estimated parameters were sufficient to describe {{the behavior of the}} series, they were statistically different from zero and <b>non</b> <b>correlated.</b> The estimated forecasts were found very approximated to observed values, they are actualized monthly, this characteristic allow to readjust the model when the pattern series change and to plan activities related with absorption of solar energy. The greatest forecast error was 23 % and it is considered acceptable. Se ajustaron modelos ARIMA a series mensuales de brillo solar obtenidas en 32 estaciones meteorológicas de la Federación Nacional de Cafeteros de Colombia. La estructura de los modelos ajustados fue ARIMA(0; 1; 1) *(0; 1; 1) 12 de promedios móviles con componente estacional de 12 meses. Los parámetros estimados fueron suficientes para describir el comportamiento de la serie. Los pronósticos obtenidos fueron muy cercanos de los valores observados, actualizados mensualmente. Esta característica permite reajustar el modelo cuando haya cambios en el patrón de la serie y planificar actividades relacionadas con la absorción de la energía solar. El mayor error de pronóstico fue de 23 %, considerado como aceptable...|$|R
40|$|Networks {{in nature}} rarely {{function}} in isolation but instead interact {{with one another}} with a form of network of networks (NoN). Network of networks with interdependency between distinct networks contains instabilities of abrupt collapse related to the global rule of activation. As a remedy of the collapse instability, here we investigate a model of <b>correlated</b> <b>NoN</b> and find that the collapse instabilities can be removed with a specific pattern of correlated connectivity. We find that when hubs provide majority of interconnections and interconnections are convergent, a system of networks becomes stable systematically. Our study identifies a stable structure of <b>correlated</b> <b>NoN</b> against catastrophic failures. Our result further suggests a plausible way to enhance network robustness by manipulating connection patterns, along with other methods such as controlling the state of node based on local rule. Comment: 4 figure...|$|R
40|$|Population {{dynamic of}} leaf hopper (Amrasca biguttula biguttula) on brinjal crop and effect of abiotic factors on its dynamic were studied. The leaf hopper started the {{activity}} soon after transplanting. The serious activity was noticed from 21 st May to 6 th August. The highest leaf hopper number per leaf was found as 12. 96 + 0. 93 on 9. 7. 96. Mean maximum and minimum temperature were found as positively and {{significantly correlated with}} population change. Relative humidity and rainfall was found as negatively and non-significantly correlated with population fluctuation. Sunshine was also positively but <b>non</b> significant <b>correlated</b> factor...|$|R
40|$|Many {{techniques}} {{are applied to}} control coagulant dosing in a drinking water treatment plant. Coagulant dosing rate is <b>non</b> linear <b>correlated</b> to raw water parameters such as turbidity, conductivity, pH, temperature, etc. Manual method called Jar testing is used to decide the dosing rates of Alum and Lime. Since parameters of the water source are continuously changing, dosing rate of Alum and Lime are difficult to adjust manually. The {{aim of the research}} is to automate the system by obtaining a simple relationship to find optimum coagulant dosage and handle practical situations of water treatment plants...|$|R
40|$|Dyreson and Snodgrass {{as well as}} Dekhtyar et. al. have {{provided}} a probabilistic model (as well as compelling exam-ple applications) for why there may be temporal indetermi-nacy in databases. In this paper, we rst propose a formal model for aggregate computation in such databases when there is uncertainty {{not just in the}} temporal attribute, but also in the ordinary (non-temporal) attributes. We identify two types of aggregates: event <b>correlated</b> aggregates, and <b>non</b> event <b>correlated</b> aggregations, and provide efcient al-gorithms for both of them. We prove that our algorithms are correct, and we present experimental results showing that the algorithms work well in practice. ...|$|R
40|$|Correlation between {{production}} traits {{were obtained for}} 20 wheat varieties/lines. Path coefficient analysis {{were used to determine}} the direct and indirect effect of different characters on grain yield. A positive and significant genotypic correlation was observed between number of tillers per meter length, spike length, 1000 -grain weight and grain yield but highly significant at phenotypic level. A positive and significant genotypic correlation was observed between peduncle length and grain yield but non significant at phenotypic level. Whereas plant height was negatively and <b>non</b> significantly <b>correlated</b> with grain yield per meter length. Path analysis showed that 1000 -grain weight and spike length are the characters which contribute largely to grain yield...|$|R
40|$|In this paper, we {{consider}} the use of source codes and channel codes for asymmetric distributed source coding of <b>non</b> uniform <b>correlated</b> sources. In particular, we use distributed arithmetic codes as source codes and syndrome based turbo codes as channel codes. We compare the advantages and drawbacks of the two systems for different source probabilities and different compression ratio. We show that prior knowledge of the source distribution improves the performance of both approaches {{in terms of their}} distances to the Slepian-Wolf bound. Turbo codes are better when the puncturing is low, while distributed arithmetic codes are less impacted by the change of compression rate. 1...|$|R
40|$|We {{investigate}} {{credit spreads}} for euro-, sterling-, and US dollar-denominated credit instruments {{relative to their}} local swap curves, and show that monthly spread changes are strongly currencydependent {{during the study period}} May 1999 to May 2001. Sector-by-rating factor returns are at best weakly <b>correlated</b> across <b>currencies,</b> and U. S. dollar spread return volatilities are generally higher than the other two by a factor of two or three. This is contrary to what would be expected from covered interest arbitrage. We conclude that credit factor risk models {{in each of the three}} markets should be estimated separately, and risk forecasting models using a single set of spread factors to cover more than one of these markets will suffer from poor accuracy...|$|R
40|$|BACKGROUND : The {{accuracy}} of cervical cytology has been quwstioned {{due to high}} false negative rate. In order to improve the sensitivity of cytology it is prudent to analyze the factors which hamper with the diagnosis of high grade lesions. AIMS : To study the cyto-histologic agreement in High grade squamous intraepithelial lesions (HSIL) of uterine cervix and to analyze the smear characteristics in discrepant cases. SETTINGS AND DESIGN : Cervical smears of 100 histology proven cases of Cervical intraepithelial neoplasia III (CIN III) were retrieved and reviewed to study cyto-histologic agreement in the diagnosis of high grade lesions [...] The discrepant smears, undercalled on cytology, were further analyzed to determine the reasons for misinterpretations. Statistical analysis was performed to find out any significant factors for discrepancies. RESULTS : Cytology was able to correctly identify 74 HSILs while in 26 cases a diagnosis of Low grade squamous intraepithelial lesions (LSIL) or below was given. On review, 16 of these <b>non</b> <b>correlating</b> cases could be reclassified as HSIL on cytology while in 10 the diagnosis of LSIL or less persisted. 12 / 16 (75 &#x 0025;) discrepant cases, reclassified as HSIL represented interpretive errors. Sampling errors (7 / 10) and air drying (5 / 10) were more frequent in under diagnosed cases. The statistical analysis did not yield any {{significant differences in the}} two review groups. CONCLUSION : 26 &#x 0025; of HSIL cases were underdiagnosed on cervical smears. The major confounding factors responsible for under interpretation on cytology included air drying artifacts and metaplastic maturation of abnormal cells...|$|R
40|$|In this paper, the {{potential}} {{distribution of the}} Mesopotamian harvestman Discocyrtus dilatatus Sørensen, 1884 (Opiliones, Gonyleptidae) is modeled, and the species bioclimatic profile is described. Models were built with the presence-only methods MAXENT and BIOCLIM, using 85 unique records (of which 49 are new) and 11 <b>non</b> <b>correlated</b> bioclimatic variables as predictors. Both MAXENT and BIOCLIM supported the Mesopotamian-Yungas disjunct pattern observed in D. dilatatus, as well as confirmed {{the role of the}} sub-xeric Dry Chaco as an effective barrier for the two portions of the range. Like in other Mesopotamian harvestmen, temperature variables proved more relevant than precipitation ones in the final models. In the combined overall score obtained with MAXENT, bc 4 -temperature seasonality ranked as the most relevant, and only one precipitation variable (bc 18 - precipitation of warmest quarter, in second place) ranked among the top five. In the Most Limiting Factor analysis, which identifies the relevant variables in a local scale, temperature variables demonstrated again being more determining than precipitation ones on most of the range. One single variable, bc 5 -maximal temperature of warmest month proved critical on the boundaries of the modeled range and the Dry Chaco, suggesting that extremely high temperatures (and not the supposed aridity) are responsible for the 450 km distribution gap. Fil: Vergara Oficialdegui, Julia. Consejo Nacional de Investigaciones Cientificas y Tecnicas. Centro Cientifico Tecnologico Cordoba. Instituto de Diversidad y Ecologia Animal; ArgentinaFil: Acosta, Luis Eduardo. Consejo Nacional de Investigaciones Cientificas y Tecnicas. Centro Cientifico Tecnologico Cordoba. Instituto de Diversidad y Ecologia Animal; Argentin...|$|R
40|$|This thesis {{deals with}} the {{construction}} of a medical decision support system, and more specifically with the knowledge sources within the system that facilitate its operation. Simulations of some results from a proportion of these knowledge sources are created, the results correspond to the physical and electrophysiological tests carried out on a patient during neuromuscular diagnosis, and various methods of processing the acquired data for interpretation.;Chaos as a method of modelling myoelectric activity is assessed for the purpose of creating an EMG simulation knowledge source and for differentiating between disorder types. The construction of phase portraits, correlation dimension analysis and calculation of Lyapunov exponents are all used to attempt to establish the presence of chaotic behaviour in the myoelectric signal. However, it is proven that the dynamics of the EMG are not chaotic in nature, thus a more suitable model for EMG simulation is chosen.;The second knowledge source looked at in detail is that of EMG decomposition. Two methods of clustering MUAPs into their classes are assessed. Firstly the use of a neural network to cluster action potentials represented by correlated features and then <b>non</b> <b>correlated</b> factors. The method proves most effective when non-correlated factors are used. The second method looked at is that of multiple database principal component analysis. This method proves capable of clustering MUAP classes in the presence of noise and MUAP variation. The method is tested on real data and, within the limits of the study, the results are confirmed.;A study of time requirements is made for resolution of overlapping action potentials. Two methods are considered - a fast and a more thorough one. It is established that it would be appropriate for these methods to be used in complement with one another, in a method for automatic decomposition that includes both clustering methods discussed along with various other appropriate techniques such as firing time analysis...|$|R
40|$|Abstract. The Diffusion Entropy {{algorithm}} {{is a method}} that allows the study of <b>correlated</b> <b>non</b> stationary time series and allows the discrimination between signal and uncorrelated noise. DE provides a quantitative measure of the complexity {{by means of a}} scaling indexδ. The aim {{of this paper is to}} apply this method to study and statistically characterize Gamma-Ray Burst light curves and to introduce a method to constrain and test GRB models. Key words. gamma rays: bursts — methods: data analysis 1...|$|R
40|$|The Diffusion Entropy {{algorithm}} {{is a method}} that allows the study of <b>correlated</b> <b>non</b> stationary time series and allows the discrimination between signal and uncorrelated noise. DE provides a quantitative measure of the complexity {{by means of a}} scaling index delta. The aim {{of this paper is to}} apply this method to study and statistically characterize Gamma-Ray Burst light curves and to introduce a method to constrain and test GRB models. Comment: 9 pages, 8 figures,submitted to A&A, v 2 minor change...|$|R
40|$|Let X be {{a random}} matrix whose pairs of entries X_jk and X_kj are {{correlated}} and vectors (X_jk,X_kj), for 1 0 and Q> 0. Let s_n(X+ M_n) denote the least singular {{value of the}} matrix X+ M_n. It is shown that there exist positive constants A and B depending on K,Q,ρ only such that P(s_n(X+ M_n) < n^-A) < n^-B. As an application of this result we prove the elliptic law for this class of matrices with <b>non</b> identically distributed <b>correlated</b> entries. Comment: 27 pages, 1 figur...|$|R
