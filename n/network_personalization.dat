1|38|Public
40|$|The {{growing demand}} for efficient, {{flexible}} yet cost effective services has produced {{a new perspective on}} personalized service as a form of asynchronous interactive computing with seamless support for communications and <b>network.</b> <b>Personalization</b> of services exists at two levels: the user and remote service provider levels. At the user level is a customized interface that provides access to networked services unlimited by distance. At the remote service provider level, the aim is to offer services based on individual needs as expressed in the user customized interface. The gap between the two sides is filled by the activities of agents. Software agents are entities that constantly adapt {{to the needs of the}} user in terms of interests, time and space limitations. Agents observe and learn from the user the art of selecting information of value to the user. Autonomous agents have the right to make decisions on behalf of the user when dealing with other agents, resources or service providers. The processing involved can be done either locally (when static) or remotely (when mobile). This thesis presents the architecture and environment of an agent-based system. The design of news agents for personalized news delivery over a broadhand network is proposed. The mobile-agent paradigm has been derived from the demands of easy remote services accessibility. A new model, namely aclient-iserver model, has been created to provide an interactive and asynchronous solution to the existence of mobile agents. Personalization of services is achieved by collecting user interests locally and gathering information remotely, all transparent to the user...|$|E
40|$|Abstract — This paper {{discusses}} scenario {{construction and}} personalization of PN services based on work {{related to this}} area in MAGNET and ongoing work in MAGNET Beyond. The pilot services in MAGNET Beyond {{are based on the}} two main cases named MAGNET. Care and Nomadic@work, covering health care and professional work situations. The vision is to enable intelligent and personalized services for users of personal networks (PNs) by taking full advantage of user profiles and context information. Initial work is focused on developing a conceptual structure of user profiles, which is flexible and dynamic, supports trust management and conditional access control, and can be smoothly integrated with available context information. Index Terms—Personal communication <b>networks,</b> <b>personalization,</b> services, user profiles, scenarios...|$|R
40|$|AbstractIn Wireless Sensor <b>Networks,</b> <b>personalization</b> {{has been}} seen by {{researchers}} as the process of tailoring services to fulfill requests of different users with different profiles. This vision ignores that individual sensors commonly have different profiles and contexts and therefore different needs. In this paper, we aim at extending personalization by allowing sensors to support each other with services that mutually fit their differences. To this end, we propose an agent-based framework where sensor nodes delegate software agents (static or mobile) to collect valuable data about the neighboring sensors and the spatial characteristics of their surrounding environments. We also show how this framework {{may be used to}} make the routing and relocation processes more personalized...|$|R
40|$|Abstract: We {{propose a}} model for finding an {{appropriate}} book and detecting an opportunity for recommendation in real bookstores. Since the models are created using a Bayesian <b>network,</b> dynamic <b>personalization</b> can be provided to users. An evaluation is performed for a system that recommends physical books based on the model, {{and the result is}} described. ...|$|R
40|$|Abstract. The {{diffusion}} of the Web {{and the huge}} amount of information available online {{have given rise to}} the urgent need for systems able to intelligently assist users, when they browse the <b>network.</b> Web <b>personalization</b> offers this invaluable opportunity, representing {{one of the most important}} technologies required by an ever increasing number of real-world applications. This chapter presents an overview of the Web personalization in the endeavor of Intelligent systems. ...|$|R
40|$|Web usage mining {{attempts}} to discover useful knowledge from the secondary {{data obtained from}} the interactions of the users with the Web. Web usage mining has become very critical for effective Web site management, creating adaptive Web sites, business and support services, <b>personalization,</b> <b>network</b> traffic flow analysis and so on. This paper introduces the various ingredients of natural computation and further presents the important concepts of Web usage mining and its various practical applications. 1...|$|R
40|$|Personalization and {{adaptation}} of multi-media messages {{are well known}} and well studied problems. Ideally, each message should reflect its recipient 2 ̆ 7 s interests, device capabilities, and <b>network</b> conditions. Such <b>personalization</b> {{is more difficult to}} carry out given a compound multi-media presentation containing multiple spatially and temporally related elements. This paper describes a novel formal, yet practical approach, and an implemented system prototype for authoring and adapting compound multi-media presentations. Our approach builds on recent advances in preference specification and preferences-based constrained optimization techniques...|$|R
40|$|Abstract — Peer-to-Peer VoIP (voice over IP) networks, exem-plified by Skype [4], are {{becoming}} increasingly popular due to their significant cost advantage and richer call forwarding features than traditional public switched telephone networks. One {{of the most important}} features of a VoIP network is privacy (for VoIP clients). Unfortunately, most peer-to-peer VoIP <b>networks</b> neither provide <b>personalization</b> nor guarantee a quantifiable pri-vacy level. In this paper we propose novel flow analysis attacks that demonstrate the vulnerabilities of peer-to-peer VoIP net-works to privacy attacks. We present detailed experimental eval-uation that demonstrates these attacks quantifying performance and scalability degradation. I...|$|R
40|$|Abstract–In {{this paper}} {{we present a}} simple {{solution}} to provide secure access to users/terminals asking for Internet connectivity through a wireless access network. The proposed solution is based on some standard protocols (DHCP, Radius, EAP, and IPSec) and enables user authentication, <b>network</b> configuration parameters <b>personalization,</b> and secure communications on the wireless links. The main strength of our approach {{is that it can}} be easily implemented in a wireless local site (WLAN or WPAN) independent of any layer two mechanism and of the manufac-turer’s implemented features in the wireless user terminal. Index Terms — DHCP, IPSec, EAP, Radiu...|$|R
30|$|Despite {{the number}} of potentialities, video {{technologies}} for learning provide limited video-learner interaction (VLI). In order to increase VLI, Chatti et al., (2016) present the design, implementation, and evaluation of collaborative video annotation platform (called CourseMapper) that enables learners to collaborate and interact with a video lecture. CourseMapper as a mind map-based collaborative video annotation and analytics platform that enables learners’ collaboration and interaction around a video lecture. CourseMapper focuses on the application of learning analytics mainly from a learner perspective to support “smart” features like, self-organized and <b>networked</b> learning through <b>personalization</b> of the learning environment, monitoring of the learning process, awareness, self-reflection, motivation, and feedback.|$|R
40|$|Online social {{networks}} were originally conceived as means of sharing information and activities with friends, and their {{success has been}} one of the primary contributors of the tremendous growth of the Web. Social network activity feeds were devised as a means to aggregate recent actions of friends into a convenient list. But the volume of actions and content generated by social network users is overwhelming, such that keeping users up-to-date with friend activities is an ongoing challenge for social <b>network</b> providers. <b>Personalization</b> has been proposed as a solution to combat social network information overload and help users to identify the nuggets of relevant information in the incoming flood of network activities. In this paper, we propose and thoroughly evaluate a personalized model for predicting the relevance of the activity feed items, which informs the ranking of the feeds and facilitates personalization. Results of a live study show that the proposed feed personalization approach successfully identifies and promotes relevant feed items and boosts the uptake of the feeds. In addition, it increases the contribution of user-generated content to the social network and spurs interaction between users...|$|R
40|$|Abstract—Recently, mobile traffic has {{increased}} tremendously {{due to the}} deployment of smart devices such as smartphones and smart tablets. These devices use various types of access networks such as 3 G, WiFi, and mobile WiMAX. Network service providers also provide these access networks with various types of plans. There is a growing need to manage these smart devices and mobile networks. However, research on mobile network management {{has focused on the}} performance of the network itself. Few research has focused on applying the usage patterns of smartphone users to mobile network management. In this paper, we present an analysis of smartphone usage patterns. We define the five possible states of a smartphone based on such a phone’s basic operations. We collected real usage log data from real smartphone users over a two month period. We show that all users have their own usage pattern. We present a case study in order to show how to apply usage pattern information to power management of smartphones. We also discuss how to apply such information to mobile device management and network management. Index Terms—Usage pattern analysis, Smartphone manage-ment, Mobile <b>network</b> management, <b>Personalization</b> I...|$|R
40|$|This work investigates {{personalized}} social search {{based on}} the user’s social relations – search results are re-ranked according to their relations with individuals in the user’s social network. We study the effectiveness of several social network types for personalization: (1) Familiarity-based network of people related to the user through explicit familiarity connection; (2) Similarity-based network of people “similar ” to the user as reflected by their social activity; (3) Overall network that provides both relationship types. For comparison we also experiment with Topic-based personalization that is {{based on the}} user’s related terms, aggregated from several social applications. We evaluate the contribution of the different personalization strategies by an off-line study and by a user survey within our organization. In the off-line study we apply bookmark-based evaluation, suggested recently, that exploits data gathered from a social bookmarking system to evaluate personalized retrieval. In the on-line study we analyze the feedback of 240 employees exposed to the alternative personalization approaches. Our main results show that both in the off-line study and in the user survey social <b>network</b> based <b>personalization</b> significantly outperforms non-personalized social search. Additionally, as reflected by the user survey, all three SN-based strategies significantly outperform the Topic-based strategy...|$|R
40|$|Abstract. The wide {{availability}} of high bandwidth public wireless networks {{as well as}} the miniaturisation of medical sensors and network access hardware allow the development of advanced ambulant patient monitoring systems. The MobiHealth project developed a complete system and service that allows the continuous monitoring of vital signals and their transmission to the health care institutes in real time using GPRS and UMTS networks. The MobiHealth system is based on the concept of a Body Area <b>Network</b> allowing high <b>personalization</b> of the monitored signals and thus adaptation to different classes of patients. The system and service has been trialed in four European countries and for different patient cases. First results confirm the usefulness of the system and the advantages it offers to patients and medical personnel. ...|$|R
40|$|Current B 2 B (Business to Business) {{models are}} not capable to cover neither {{customer}} expectations {{in terms of}} quality nor <b>personalization.</b> <b>Network,</b> service and equipment providers are tied to traditional business models, missing the opportunity to increase their revenues derived from the integration of Quality of Experience (QoE) models in their frameworks. In this work, we propose a B 2 B QoE model which comprises the main guidelines to successfully integrate the QoE within the value chain and provide with added-value services to potential subscribers. We also evaluate the potential QoE end-user market for six European countries. Results indicate {{that there is a}} niche for QoE based models which rely on the joint action of value chain actors and its agreement with the regulatory environment. ...|$|R
40|$|With {{the rapid}} growth of the social web an {{increasing}} num- ber of people started to replicate their off-line preferences and lives in an on-line environment. Consequently, the social web provides an enormous source for social network data, which can be used in both commercial and research applications. However, people often take part in multiple social network sites and, generally, they share only a selected amount of data to the audience of a specific platform. Consequently, the interlink- age of social graphs from different sources getting increasingly impor- tant for applications such as social <b>network</b> analysis, <b>personalization,</b> or recommender systems. This paper proposes a novel method to enhance available user re-identification systems for social network data aggrega- tion based on face-recognition algorithms. Furthermore, the method is combined with traditional text-based approaches in order to attempt a counter-balancing of the weaknesses of both methods. Using two sam- ples of real-world social networks (with 1610 and 1690 identities each) we show that even though a pure face-recognition based method gets out- performed by the traditional text-based method (area under the ROC curve 0. 986 vs. 0. 938) the combined method significantly outperforms both of these (0. 998, p = 0. 0001) suggesting that the face-based method indeed carries complimentary information to raw text attributes...|$|R
40|$|Abstract. With {{the rapid}} growth of the social web an {{increasing}} number of people started to replicate their off-line preferences andlivesinan on-line environment. Consequently, the social web provides anenormous source for social network data, which can be used in both commercial and research applications. However, people often take part in multiple social network sites and, generally, they share only a selected amount of data to the audience of a specific platform. Consequently, the interlinkage of social graphs from different sources getting increasingly important for applications such as social <b>network</b> analysis, <b>personalization,</b> or recommender systems. This paper proposes a novel method to enhance available user re-identification systems for social network dataaggregation based on face-recognition algorithms. Furthermore, the method is combined with traditional text-based approaches in order to attempta counter-balancing of the weaknesses of both methods. Using two samples of real-world social networks (with 1610 and 1690 identities each) we show that even though a pure face-recognition based method gets outperformed by the traditional text-based method (area under the ROC curve 0. 986 vs. 0. 938) the combined method significantly outperforms both of these (0. 998, p = 0. 0001) suggesting that the face-based method indeed carries complimentary information to raw text attributes. ...|$|R
40|$|Delivering Web {{content to}} {{wireless}} handheld devices is a challenge. Current popular wireless handheld devices, such as WAP phone, Palm and Pocket PC, have many inherent limitations. In addition, relatively low wireless network bandwidth and user mobility make {{it necessary to}} deliver data as succinct as possible to reduce transmission delay and fit into the small screen display. To achieve this goal, Web content has to be tailored {{to adapt to the}} mobile Web. This research would examine adaptation challenges and presents a classification scheme for evaluating current adaptation approaches. A model for guiding the development and assessment of adaptive content delivery over the mobile Web is presented. The paper concludes with an agenda for future research. Statement of Problem Just like the Web has been the core platform of current Internet business, the mobile Web is the central data exchange channel for extending current Internet business model to wireless services model (Shim et al. 2002). However, due to inherent constraints of wireless handheld devices and the current state of wireless network, proper considerations should be given before delivering Web content to the wireless user. Removal of many unsupported data format and scripting component is necessary to reduce the data transmission over the wireless <b>network.</b> Furthermore, <b>personalization</b> techniques could be applied to the information to mee...|$|R
30|$|Over {{the past}} few years there has been an {{increasing}} interest to investigate the potential of Video-Based Learning (VBL) as a result of new forms of online education, such as flipped classrooms and Massive Open Online Courses (MOOCs) in order to engage learners in a self-organized and networked learning experience. However, current VBL approaches suffer from several limitations. These include the focus on the traditional teacher-centered model, the lack of human interaction, the lack of interactivity around the video content, lack of personalization, as well as assessment and feedback. In this paper, we investigate the effective design of VBL environments and present the design, implementation, and evaluation details of CourseMapper as a mind map-based collaborative video annotation and analytics platform that enables learners’ collaboration and interaction around a video lecture. Thereby, we focus on the application of learning analytics mainly from a learner perspective to support self-organized and <b>networked</b> learning through <b>personalization</b> of the learning environment, monitoring of the learning process, awareness, self-reflection, motivation, and feedback.|$|R
40|$|Abstract [...] - The World Wide Web {{maintaining}} its development at an incredible pace. The information {{available in the}} WWW is a gateway and an intermediate for carrying out business. Web mining is the extraction of exciting and constructive facts and inherent information from artifacts or actions related to the WWW. Web usage mining (WUM) puts an effort to determine valuable information from the secondary data obtained from the communications of the users with the Web. WUM {{has turned out to}} be an extremely significant for successful Web site organization, generating adaptive Web sites, business and maintenance services, <b>personalization,</b> <b>network</b> traffic flow examination and so on. WUM comprises of three steps, namely preprocessing, pattern discovery, and pattern analysis. WUM has become an active area of research in field of data mining due to its vital importance. This paper provides a comprehensive discussion of the all the phases in WUM and related works in this field...|$|R
40|$|The {{growing trend}} to use mobile devices and {{applications}} {{to collect data}} relating to fitness activities has resulted in large amounts of sensor data being generated. Further, {{in some cases the}} fitness data is shared over social networks. This collected data has potential uses in a number of fields including: public health and population health data, urban planning, fitness trends analysis, social <b>network</b> analysis and <b>personalization</b> of health information. As the motivation for creating this sensor data already exists for the individual in relation to fitness benefits and health monitoring, this type of participatory sensing approach has a lower barrier to entry. However, there is currently no structured approach to collect and re-use this sensor data. This paper describes the distinct types of fitness sensor applications; conceptual architecture for data collection and aggregation and the steps and developments that would improve the quality and usability of data collected. Further, the types of secondary uses for smart cities of this collected data are explored...|$|R
40|$|Presented on February 5, 2016 at 12 : 00 in the Klaus Advanced Computing Building, room 1116 West, Georgia Tech. Ren Ding is a Ph. D. {{student in}} the School of Computer Science, College of Computing, at the Georgia Institute of Technology, where he is advised by Professor Wenke Lee. He {{is a member of}} the Georgia Tech Information Security Center, {{affiliated}} with the Institute for Information Security & Privacy. He received his B. S. from Bowdoin College in 2012, double majoring in computer science and psychology. His research interests include system security, ma/ware analysis, and user privacy. Most recently, Ding's research focuses on ma/ware detection and neutralization, as well as software security in terms of memory safety and defense against advanced ROP attacks. Runtime: 43 : 43 minutesln-app advertising is an essential part of the ecosystem of free mobile applications. On the surface, this creates a win-win situation where app developers can profit from their work without charging the users. Meanwhile, ad <b>networks</b> employ <b>personalization</b> to improve the effectiveness/profitability of their ad placement. This need for serving personalized advertisements in turn motivates ad networks to collect profile data about users. As such, "free" apps are only free in monetary terms; they come with the price of potential privacy concerns. The question is, how much data are users giving away in exchange for "free apps"? In this paper, we study how much of the user's interest and demographic information is known to major ad networks on the mobile platform. We also study whether personalized ads can be used by the hosting apps to reconstruct some of the user information collected by the ad network. By collecting more than 200 real user profiles and the ads seen by surveyed users, we found that in-app advertising can leak potentially sensitive user information to any app that hosts personalized ads, and ad networks' current protection mechanisms are not sufficient for safe-guarding users' sensitive personal information. MailChim...|$|R
40|$|Abstract- The rapid {{e-commerce}} {{growth has}} made both {{business community and}} customers face a new situation. Due to intense competition {{on the one hand}} and the customer’s option to choose from several alternatives, the business community has realized the necessity of intelligent marketing strategies and relationship management. Web usage mining attempts to discover useful knowledge from the secondary data obtained from the interactions of the users with the Web. Web usage mining has become very critical for effective Web site management, creating adaptive Web sites, business and support services, <b>personalization,</b> <b>network</b> traffic flow analysis and so on. The study of ant colonies behavior and their self-organizing capabilities is of interest to knowledge retrieval/ management and decision support systems sciences, because it provides models of distributed adaptive organization, which are useful to solve difficult optimization, classification, and distributed control problems, among others [16][17][18]. In this paper, we propose an ant clustering algorithm to discover Web usage patterns (data clusters) and a linear genetic programming approach to analyze the visitor trends. Empirical results clearly show that ant colony clustering performs well when compared to a selforganizing map (for clustering Web usage patterns) even though the performance accuracy is not that efficient when compared to evolutionary-fuzzy clustering (i-miner) [1] approach. ...|$|R
40|$|Data mining is {{the process}} of {{discovering}} hidden and meaningful knowledge in a data set. It has been successfully applied to many real-life problems, for instance, web <b>personalization,</b> <b>network</b> intrusion detection, and customized marketing. Recent advances in computational sciences have led to the application of data mining to various scientific domains, such as astronomy and bioinformatics, to facilitate the understanding of different scientific processes in the underlying domain. In this thesis work, we focus on designing and applying data mining techniques to analyze spatial and spatiotemporal data originated in scientific domains. Examples of spatial and spatio-temporal data in scientific domains include data describing protein structures and data produced from protein folding simulations, respectively. Specifically, we have proposed a generalized framework to effectively discover different types of spatial and spatio-temporal patterns in scientific data sets. Such patterns can be used to capture a variety of interactions among objects of interest and the evolutionary behavior of such interactions. We have applied the framework to analyze data originated in the following three application domains: bioinformatics, computational molecular dynamics, and computational fluid dynamics. Empirical results demonstrate that the discovered patterns are meaningful in the underlying domain and can provide important insights into various scientific phenomena. 1...|$|R
40|$|The rapid {{e-commerce}} {{growth has}} made both {{business community and}} customers face a new situation. Due to intense competition {{on one hand and}} the customer's option to choose from several alternatives business community has realized the necessity of intelligent marketing strategies and relationship management. Web usage mining attempts to discover useful knowledge from the secondary data obtained from the interactions of the users with the Web. Web usage mining has become very critical for effective Web site management, creating adaptive Web sites, business and support services, <b>personalization,</b> <b>network</b> traffic flow analysis and so on. The study of ant colonies behavior and their self-organizing capabilities is of interest to knowledge retrieval/management and decision support systems sciences, because it provides models of distributed adaptive organization, which are useful to solve difficult optimization, classification, and distributed control problems, among others [17][18][16]. In this paper, we propose an ant clustering algorithm to discover Web usage patterns (data clusters) and a linear genetic programming approach to analyze the visitor trends. Empirical results clearly shows that ant colony clustering performs well when compared to a selforganizing map (for clustering Web usage patterns) even though the performance accuracy is not that efficient when comparared to evolutionary-fuzzy clustering (iminer) [1] approach...|$|R
40|$|Abstract—Web 2. 0 {{changed the}} {{interaction}} paradigm of Internet users, {{placing them in}} {{a more active role}} as both producers and consumers of digital contents. This concept has also triggered the appearance of social networks and cloud computing services, which have an increasing contribution to the total traffic amount. The increasing Internet complexity brings new challenges to network operators and managers, which need to understand new applications and know the exact properties of the generated traffic. The ability to accurately map traffic patterns to their corresponding application can be used to build efficient traffic and user profiles, which can be extremely helpful in several critical tasks like network resources optimization, service differentiation and <b>personalization,</b> <b>network</b> management and security. This paper proposes a classification approach that is able to accurately differentiate traffic flows in a core network and associate them with their underlying applications, allowing the construction of accurate traffic and user profiles. By performing a wavelet decomposition and analyzing the obtained scalograms, the captured traffic can be fully characterized in terms of its time and frequency components. As the different frequency components of the traffic are inferred, an appropriate communication profile characteristic of each application type can be defined. This way, it is possible to identify the distinct applications that are being used by the different connected clients and build useful user profiles...|$|R
40|$|The rapid {{e-commerce}} {{growth has}} made both {{business community and}} customers face a new situation. Due to intense competition {{on one hand and}} the customer's option to choose from several alternatives business community has realized the necessity of intelligent marketing strategies and relationship management. Web usage mining attempts to discover useful knowledge from the secondary data obtained from the interactions of the users with the Web. Web usage mining has become very critical for effective Web site management, creating adaptive Web sites, business and support services, <b>personalization,</b> <b>network</b> traffic flow analysis and so on. The study of ant colonies behavior and their self-organizing capabilities is of interest to knowledge retrieval/management and decision support systems sciences, because it provides models of distributed adaptive organization, which are useful to solve difficult optimization, classification, and distributed control problems, among others. In this paper, we propose an ant clustering algorithm to discover Web usage patterns (data clusters) and a linear genetic programming approach to analyze the visitor trends. Empirical results clearly shows that ant colony clustering performs well when compared to a self-organizing map (for clustering Web usage patterns) even though the performance accuracy is not that efficient when comparared to evolutionary-fuzzy clustering (i-miner) approach. KEYWORDS: Web Usage Mining, Swarm Intelligence, Ant Systems, Stigmergy, Data-Mining, Linear Genetic Programming. Comment: 8 pages, 11 figures, at [URL]...|$|R
40|$|Recently Web mining {{has become}} a hot {{research}} topic, which combines two of the prominent research areas comprising of data mining and the World Wide Web (WWW) [8]. Web usage mining attempts to discover useful knowledge from the secondary data obtained from the interactions of the users with the Web. Web usage mining has become very critical for effective Web site management, business and support services, <b>personalization,</b> <b>network</b> traffic flow analysis and so on. Our previous study on Web usage mining [10][11] using a concurrent neuro-fuzzy approach {{has shown that the}} usage trend analysis very much depends on the performance of the clustering of the number of requests. In this paper, a novel approach `intelligent-miner' (i-Miner) is introduced to optimize the concurrent architecture of a fuzzy clustering algorithm (to discover data clusters) and a fuzzy inference system to analyze the trends. In the concurrent neuro-fuzzy approach, selforganizing maps were used to cluster the web user requests. A hybrid evolutionary FCM approach is proposed in this paper to optimally segregate similar user interests. The clustered data is then used to analyze the trends using a Takagi-Sugeno fuzzy inference system learned using a combination of evolutionary algorithm and neural network learning. Empirical results clearly shows that the proposed technique is efficient with lesser number of if-then rules and improved accuracy at the expense of complicated algorithms and extra computational cost. I...|$|R
40|$|The {{success of}} the Web {{in the last decade}} has caused an {{evolution}} of the resources that are disseminated through the Internet. The initial static contents have been enriched by an increasing amount of multimedia and dynamically generated resources. This evolution has shifted the research focus from a nowadays mature content delivery scenario to a Web service generation and delivery scenario. The overall complexity is further increased by the so-called ubiquitous Web access that aims to allow the users to access Web-based services from any location through every class of devices. The key feature of the ubiquitous Web is represented by the content adaptation services that tailor the Web content and the Web-based services to the characteristics of the client devices and to the preferences of the users. This feature of the ubiquitous Web introduces new performance and security problems to the infrastructure that has to generate and disseminate the resources, but it also offers a wide range of novel service opportunities. The tutorial is divided in three parts: the first related to the services for the ubiquitous Web access, the second to the architectures to build scalable services, the third to the presentation of some case studies. In the first part, we present the adaptation services by differentiating transcoding from personalization services. Transcoding services tailor Web resources to the capabilities of the client and <b>network</b> infrastructure, while <b>personalization</b> requires more sophisticated services that aim to adapt the content to (a combinatio...|$|R
40|$|The rapid {{e-commerce}} {{growth has}} made both {{business community and}} customers face a new situation. Due to intense competition {{on one hand and}} the customer's option to choose from several alternatives business community has realized the necessity of intelligent marketing strategies and relationship management. Web usage mining attempts to discover useful knowledge from the secondary data obtained from the interactions of the users with the Web. Web usage mining has become very critical for effective Web site management, creating adaptive Web sites, business and support services, <b>personalization,</b> <b>network</b> traffic flow analysis and so on. In this paper, we present the important concepts of Web usage mining and its various practical applications. We further present a novel approach 'intelligent-miner' (i-Miner) to optimize the concurrent architecture of a fuzzy clustering algorithm (to discover web data clusters) and a fuzzy inference system to analyze the Web site visitor trends. A hybrid evolutionary fuzzy clustering algorithm is proposed in this paper to optimally segregate similar user interests. The clustered data is then used to analyze the trends using a Takagi-Sugeno fuzzy inference system learned using a combination of evolutionary algorithm and neural network learning. Proposed approach is compared with self-organizing maps (to discover patterns) and several function approximation techniques like neural networks, linear genetic programming and Takagi-Sugeno fuzzy inference system (to analyze the clusters). The results are graphically illustrated and the practical significance is discussed in detail. Empirical results clearly show that the proposed Web usage-mining framework is efficient...|$|R
40|$|Web usage mining {{attempts}} to discover useful knowledge from the secondary {{data obtained from}} the interactions of the users with the Web. Web usage mining has become very critical for effective Web site management, creating adaptive Web sites, business and support services, <b>personalization,</b> <b>network</b> traffic flow analysis etc., Web site under study {{is part of a}} nonprofit organization that does not sell any products. It was crucial to understand who the users were, what they looked at, and how their interests changed with time. To achieve this, one of the promising approaches is web usage mining, which mines web logs for user models and recommendations. Web usage mining algorithms have been widely utilized for modeling user web navigation behavior. In this study we advance a model for mining of user’s navigation pattern. The proposal of our work proceeds in the direction of building a robust web usage knowledge discovery system, which extracts the web user profiles at the web server, application server and core application level. The proposal optimizes the usage mining framework with fuzzy C means clustering algorithm (to discover web data clusters) and compare with Expected Maximization cluster system to analyze the Web site visitor trends. The evolutionary clustering algorithm is proposed to optimally segregate similar user interests. The clustered data is then used to analyze the trends using inference system. By linking the Web logs with cookies and forms, it is further possible to analyze the visitor behavior and profiles which could help an e-commerce site to address several business questions. Experimentation conducted with CFuzzy means and Expected Maximization clusters in Syskill Webert data set from UCI, shows that EM shows 5 % to 8 % better performance than CFuzzy means in terms of cluster number. 1...|$|R
40|$|Internet Tra c, Internet Applications, Internet Attacks, Tra c Pro ling, Multi-Scale Analysis {{abstract}} Nowadays, the Internet {{can be seen}} as an ever-changing platform {{where new}} and di erent types of services and applications are constantly emerging. In fact, many of the existing dominant applications, such as social networks, have appeared recently, being rapidly adopted by the user community. All these new applications required the implementation of novel communication protocols that present di erent network requirements, according to the service they deploy. All this diversity and novelty has lead to an increasing need of accurately pro ling Internet users, by mapping their tra c to the originating application, in order to improve many network management tasks such as resources optimization, <b>network</b> performance, service <b>personalization</b> and security. However, accurately mapping tra c to its originating application is a di cult task due to the inherent complexity of existing network protocols and to several restrictions that prevent the analysis of the contents of the generated tra c. In fact, many technologies, such as tra c encryption, are widely deployed to assure and protect the con dentiality and integrity of communications over the Internet. On the other hand, many legal constraints also forbid the analysis of the clients' tra c in order to protect their con dentiality and privacy. Consequently, novel tra c discrimination methodologies are necessary for an accurate tra c classi cation and user pro ling. This thesis proposes several identi cation methodologies for an accurate Internet tra c pro ling while coping with the di erent mentioned restrictions and with the existing encryption techniques. By analyzing the several frequency components present in the captured tra c and inferring the presence of the di erent network and user related events, the proposed approaches are able to create a pro le for each one of the analyzed Internet applications. The use of several probabilistic models will allow the accurate association of the analyzed tra c to the corresponding application. Several enhancements will also be proposed in order to allow the identi cation of hidden illicit patterns and the real-time classi cation of captured tra c. In addition, a new network management paradigm for wired and wireless networks will be proposed. The analysis of the layer 2 tra c metrics and the di erent frequency components that are present in the captured tra c allows an e cient user pro ling in terms of the used web-application. Finally, some usage scenarios for these methodologies will be presented and discussed. Tese de doutoramento em Metodologias para caracterização de tráfego em redes de comunicaçõe...|$|R
40|$|Mención Internacional en el título de doctorHuman {{mobility}} is key {{in fields}} like urban planning, protocols for mobile <b>networks,</b> or service <b>personalization,</b> among others. Besides, {{a large number}} of studies emerged in the last years thank to more complete mobility data sets, coming from the use of mobile phones as mobility proxies that continuously record their owners' locations. Traditionally, many of the applications of human mobility, like service personalization, were based on the current location of the user. However, this focus has recently started to shift to the user's mobility habits and her future location. This change allows having time in advance to provide services related to the usual habits of the user. This thesis focuses on broadening the understanding of human mobility through the analysis of the location data recorded by mobile devices, and finding ways to increment the probability of making right predictions about their future locations. To confront this challenge, it is divided into three stages: the mobility data collection, the extraction and analysis of the mobility features reflected into the recorded data, and the analysis of a set of prediction algorithms to propose some improvements. The intrinsic privacy risks associated to the disclosure of the location and mobility data of the user are also considered. In the first stage, the analysis of the sensors available in mobile devices and the requirements of the thesis lead to choose the cellular network as the source of mobility data. After analyzing the existing data sets containing this kind of data, it is decided to carry out a new mobility data collection campaign to obtain a more complete data set. The second stage is focused on extracting mobility features from the data chosen in the previous step, and spot the biases introduced by the data collection scheme. In order to eliminate these biases, several filtering techniques are proposed to delete the maximum number of events not representing the movement of the user. For the next stage, the specific family of LZ-based prediction algorithms is chosen to analyze their results when using mobility data obtained using different schemes and then filtered. By leveraging the mobility features studied in the previous stage, and based on their relationship with the prediction results, several modifications of the original algorithms are proposed to increase the fraction of right predictions. Finally, in the privacy preservation plane, the shift from disclosing static location profiles to mobility profiles leads to the proposal of a new privacy metric, based on the concept of entropy rate. The goal is to consider both the spatial as well as temporal information in a mobility profile. Some privacy-enhancing perturbation techniques are tested with both location and mobility profiles using the new privacy metric, which unveils the noticeable amount of information stored in the temporal correlations. Programa Oficial de Doctorado en Ingeniería TelemáticaPresidente: Rebeca P. Díaz Redondo. - Secretario: Andrés Marín López. - Vocal: Andrea Saracin...|$|R
30|$|Neural {{networks}} different architectures {{have been}} investigated and applied to language model estimations by many researchers. Feed forward neural networks [1] have been adapted in language modeling estimation [1]; feed forward neural network language models simultaneously learn the probability functions for word sequences and build the distributed representation for individual words, but this model has a drawback in that a fixed number of words {{can be considered as}} a context window for the current or target word. To enhance the conventional feed forward neural network language models training time, researchers proposed continuous space language modeling (CSLM), which is a modular open-source toolkit of feed forward neural network language models [13]; this model introduces support for GPU cards that enable neural networks to build models with corpora that contain more than five billion words in less than 24 hours with about a 20 % perplexity reduction [13]. Recurrent neural networks have been applied to estimate language models. However, with this model, {{there is no need to}} specify the context window size by using feedback from the hidden to the input layer as a kind of network memory for the word context. Experiment results have proved that recurrent neural networks in language models outperform n-gram language models [5, 6, 9, 14, 15]. An RNNLM toolkit was designed to estimate the class-based language model using recurrent neural networks [5, 6]. It can also provide functions such as an internist model evaluation using perplexity, N-best rescoring and model-based text generation. The training speed is the main RNNLM drawback, especially with large vocabulary sizes and large hidden layers. The RWTHLM [16] is another recurrent neural network-based toolkit with long short-term memory (LSTM) implementation, and the RWTHLM toolkits BLAS library was used to support reduced training time and efficient network training. The CUED-RNNLM [11] provides an implementation for the recurrent neural network-based model, and it has GPU support to achieve a more efficient training speed. Both the basic feed forward network and the recurrent neural network-based language models do not include any type of word level morphological features, but some researchers tried to add this type of word feature explicitly by input layer factorization. Factored neural language models (FNLM) [12] add word features explicitly in the neural network input layer in the feed-forward based neural network language model and the factored recurrent neural network language model (fRNNLM) [10]. They also add word features to the recurrent neural network input layer to model the results better than the basic model. Their complexity is higher than that of the original models since they add word features explicitly to the input layer. While adding these features improves network performance, it adds more complexity to the models estimation and the application performance, especially when applying it to large size vocabulary applications or language with rich morphological features. Researches tries to build RNNLM personalization models [17] using dataset collected from social media <b>networks,</b> model-based RNNLM <b>personalization</b> aims to captures patterns posted by used and his/her related friends while another approach is feature-based where RNNLM parameters are static throw users. Recently neural-based language modeling models added as an extension to Kaldi automatic speech recognition (Kaldi-RNNLM) [18] software, this architecture combines the use of subword features and one-hot encoding of words with high frequency to handle large vocabularies containing infrequent words. Also Kaldi-RNNLM architecture improves cross-entropy objective function to train unnormalized probabilities. In addition to feed forward network and the recurrent neural network-based language models architectures convolution neural network (CNN) [19] was applied to estimate language models with inputs to the network in the form of character and output predictions is at the word-level.|$|R
40|$|The rapid {{increases}} in network bandwidth and processing power {{have led to}} tremendous growth in Internet applications and {{changed the nature of}} delivering content. From earlier web application, which is only about retrieval of pre-computed static content, current content delivery architectures provide dynamic content and enable personalization of content. Recent interactive entertainment applications, such as multiplayer online games, require content to be created and distributed in real-time. In addition, the rapid increase in processor speed has led to various proposals to put real-time computation within or {{at the edge of the}} network that allow application specific processing on packet flow such as multimedia transcoding and content adaptation. In short, these emerging applications have a common characteristics that the contents of application flows are processed in real-time before being delivered to end users. We refer to these as applications that require real-time content creation. This thesis aims to develop models for real-time content creation and distribution. We examine both network architectures for delivering content as well as server processing resource management for content creation. We concentrate on a case study when content creation is from a dynamic set of dispersed sources. In particular, we examine the provision of an immersive voice communication service to massively multiplayer online games, which requires real-time creation of audio scenes from dynamic sets of participants. We present various delivery architectures for this service, evaluate the performance of these architectures and provide recommendations based on the evaluation. In addition, this thesis designs a server resource management architecture for sharing processing resource among real-time content creation applications. Our study begins with reviewing the evolution of content distribution over the Internet, ranging from simple caching proxies to content distribution <b>networks</b> and <b>personalization</b> of content. We then discuss current and future developments of content distribution which require real-time creation and distribution of content from dynamic sets of dispersed sources. These include state information processing and communication information processing in distributed virtual environments. While all networked games require state information processing, communication information processing has been recently seen as a key to enhance the reality and attractiveness of the virtual environment. In particular, this thesis reviews technologies and approaches for providing an immersive voice communication service to distributed virtual environments. Several delivery architectures are introduced for providing this service, namely peer-to-peer, central server, distributed locale server architecture, and distributed proxy architecture. Furthermore, we present a realistic simulation model that captures player distribution in the Internet and avatar distribution in the game virtual world and specify two key performance evaluation parameters: interactive delay and network bandwidth usage. In the central server architecture, two optimization objectives are proposed for choosing an optimal central server from a set of potential servers. We also propose a dynamic relocation of a central server in response to changes in player distribution due to time zone differences. It is shown that relocation of the central server in response to these changes can significantly reduce the interactive delay by up to 40 % and the network bandwidth usage by up to 50 %. In addition, the optimal central server can significantly reduce the interactive delay compared to a randomly located central server. In the distributed locale server architecture, the game virtual world is partitioned into smaller areas called locales and each locale is assigned to a server. We propose two server assignment algorithms for optimizing the latency performance of this architecture. The first algorithm is based on an Integer Linear Programming (ILP) model which provides an exact solution to the problem but is subject to high computation complexity. We then produce a new multi-layer graph representation of the problem and devise a greedy heuristic based on this graph. It is shown that the greedy heuristics has low run time complexity and provides solutions close to the optimal (within 5 % of the optimal in all cases). In addition, increasing the number of servers reduces the latency of the distributed locale server architecture significantly compared to the optimal central server when there is a physical/virtual world correlation. Specifically, with a reasonable number of servers, the distributed locale server architecture can reduce the delay of the central server by 20 % to 60 %. In the distributed proxy architecture, players are assigned to a close proxy and each proxy manages the audio mixing operation on behalf of players and forwards audio streams from players to other interested proxies. This thesis develops an ILP model for an optimal proxy assignment and adapts the multi-layer graph approach used earlier to devise a greedy heuristics for solving the proxy assignment problem efficiently. While the ILP model is unscalable, the greedy heuristics is highly scalable and suitable for practical implementation. This thesis also investigates the efficiency of network multicast in different player and avatar distribution scenarios. The effect of varying the number of proxies is also investigated. Extensive simulation experiments are carried out to evaluate the performance of all delivery architectures. In particular, since the distributed locale server architecture and the distributed proxy architecture are ‘dual’ of each other, we concentrate on comparing the performance of these. From the performance evaluation, we provide recommendations on choosing suitable delivery architectures based on the server resource availability, multicast, and game’s avatar aggregation behaviors. The quantitative study in this thesis will be of benefit to future immersive voice service providers in the design of a cost effective delivery architecture for this service. Finally, the thesis presents a resource management architecture for sharing processing resources among various real-time content creation applications including the immersive audio mixing application. Due to the inability of determining processing times for scheduling, a processing resources scheduling algorithm called Start-time Weighted Fair Queueing (SWFQ) is proposed. From analysis and simulation, it is shown that SWFQ offers good fairness and delay properties compared to current schemes. In fact, the fairness of SWFQ was comparable to Weighted Fair Queueing (WFQ) and the delay behavior is better than Start-time Fair Queueing (SFQ) ...|$|R

