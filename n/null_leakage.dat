4|4|Public
40|$|ABSTRACT. We {{describe}} the Keck Interferometer nuller theory of operation, data reduction, and on-sky per-formance, particularly {{as it applies}} to the nuller exozodiacal dust key science program that was carried out between 2008 February and 2009 January. We review the nuller implementation, including the detailed phasor processing involved in implementing the null-peak mode used for science data and the sequencing used for science observing. We then {{describe the}} Level 1 reduction to convert the instrument telemetry streams to raw null leakages, and the Level 2 reduction to provide calibrated null leakages. The Level 1 reduction uses conservative, primarily linear processing, implemented consistently for science and calibrator stars. The Level 2 processing is more flexible, and uses diameters for the calibrator stars measured contemporaneously with the interferometer’s K-band cophasing system in order to provide the requisite accuracy. Using the key science data set of 462 total scans, we assess the instrument performance for sensitivity and systematic error. At 2. 0 Jy we achieve a photometrically-limited <b>null</b> <b>leakage</b> uncertainty of 0. 25 % rms per 10 minutes of integration time in our broadband channel. From analysis of the Level 2 reductions, we estimate a systematic noise floor for bright stars of ∼ 0 : 2 % rms <b>null</b> <b>leakage</b> uncertainty per observing cluster in the broadband channel. A similar analysis is performed for the narrowband channels. We also provide additional information needed for science reduction, including details on the instrument beam pattern an...|$|E
40|$|We {{describe}} the Keck Interferometer nuller theory of operation, data reduction, and on-sky performance, particularly {{as it applies}} to the nuller exozodiacal dust key science program that was carried out between 2008 February and 2009 January. We review the nuller implementation, including the detailed phasor processing involved in implementing the null-peak mode used for science data and the sequencing used for science observing. We then {{describe the}} Level 1 reduction to convert the instrument telemetry streams to raw null leakages, and the Level 2 reduction to provide calibrated null leakages. The Level 1 reduction uses conservative, primarily linear processing, implemented consistently for science and calibrator stars. The Level 2 processing is more flexible, and uses diameters for the calibrator stars measured contemporaneously with the interferometer’s K-band cophasing system in order to provide the requisite accuracy. Using the key science data set of 462 total scans, we assess the instrument performance for sensitivity and systematic error. At 2. 0 Jy we achieve a photometrically-limited <b>null</b> <b>leakage</b> uncertainty of 0. 25 % rms per 10 minutes of integration time in our broadband channel. From analysis of the Level 2 reductions, we estimate a systematic noise floor for bright stars of ~ 0. 2 % rms <b>null</b> <b>leakage</b> uncertainty per observing cluster in the broadband channel. A similar analysis is performed for the narrowband channels. We also provide additional information needed for science reduction, including details on the instrument beam pattern and the basic astrophysical response of the system, and references to the data reduction and modeling tools...|$|E
40|$|The Keck Interferometer Nuller (KIN), {{the first}} {{operational}} separated-aperture infrared nulling interferometer, {{was designed to}} null the mid-infrared emission from nearby stars so as to ease the measurement of faint circumstellar emission. This paper describes {{the basis of the}} KIN's four-beam, two-stage measurement approach and compares it 10 the simpler case of a two-beam nuller. In the four-beam KIN system, the starlight is first nulled in a pair of nullers operating on parallel 85 m Keck-Keck baselines, after which "cross-combination" on 4 m baselines across the Keck apertures is used to modulate and detect residual coherent off-axis emission. Comparison to the constructive itellar fringe provides calibration. The response to an extended source is similar in the two cases, except that the four-beam response includes a term due to the visibility of the source on the cross-combiner baseline-a small effect for relatively compact sources. The characteristics of the dominant null depth errors are also compared for the two cases. In the two-beam nuller, instrumental imperfections and asymmetries lead to a series of quadratic, positivedefinite <b>null</b> <b>leakage</b> terms. For the four-beam nuller, the leakage is instead a series of correlation cross-tenns combining corresponding errors in each of the two nullers, which contribute offsets {{only to the extent that}} these errors are correlated on the timescale of the measurement. This four-beam architecture has allowed a significant (approx. order of magnitude) improvement in mid-infrared long-baseline fringe-visibility accuracies...|$|E
40|$|One of {{the biggest}} {{challenges}} associated with a nulling interferometer-based approach to detecting extra-solar Earth-like planets comes from the extremely stringent requirements of pathlength, polarization and amplitude matching in the interferometer. To the extent that the light from multiple apertures are not matched in these properties, light will leak through the nuller and confuse the search for a planetary signal. Here we explore the possibility of using the coherence properties of the starlight to separate contributions from the planet and <b>nuller</b> <b>leakage.</b> We find that straightforward modifications to the optical layout of a nulling interferometer will allow one to measure and correct for the leakage to a high degree of precision. This nulling calibration relaxes the field matching requirements substantially, and should consequently simplify the instrument design. Comment: 24 Pages, accepted for publication in Ap...|$|R
40|$|This paper {{presents}} a high performance level shifter with <b>null</b> static <b>leakage</b> current. Unlike the existing level shifter circuits, the proposed level shifter can shift threshold voltage level to full swing level without any static power consumption {{as long as}} the input signal level is higher than the threshold voltage of NMOS in output power domain. Moreover, the proposed level shifter has shorter propagation delay and consumes less dynamic power than existing designs. The proposed circuit is generic in nature and the range of shifting level is limited only by the scope of the semiconductor process. The proposed level shifter is designed in 40 nm CMOS technology and simulated in SPICE. The simulation results show that the proposed level shifter circuit is able to shift 0. 9 V of input level to 1. 8 V of operating voltage of the output domain 200 ps propagation delay and null static power consumption...|$|R
40|$|Wideband {{spectrum}} sensing for cognitive radios requires very demanding analog-to-digital conversion (ADC) speed and dynamic range. In this paper, a mixed-signal parallel compressive sensing architecture is developed to realize wideband {{spectrum sensing}} for cognitive radios at sub-Nqyuist rates by exploiting the sparsity in current frequency usage. Overlapping windowed integrators {{are used for}} analog basis expansion, that provides flexible filter <b>nulls</b> for clock <b>leakage</b> spur rejection. A low-speed experimental system, built with off-the-shelf components, is presented. The impact of circuit nonidealities is considered in detail, providing insight for a future integrated circuit implementation...|$|R
40|$|The Keck Interferometer Nuller is {{designed}} to detect faint off-axis mid-infrared light a few tens to a few hundreds of milliarcseconds from a bright central star. The starlight is suppressed by destructive combination along the long (85 m) baseline, which produces a fringe spacing of 25 mas at a wavelength of 10 m, with the central null crossing {{the position of the}} star. The strong, variable mid-infrared background is subtracted using interferometric phase chopping along the short (5 m) baseline. This paper presents an overview of the observing and data reduction strategies used to produce a calibrated measurement of the off-axis light. During the observations, the instrument cycles rapidly through several calibration and measurement steps, in order to monitor and stabilize the phases of the fringes produced by the various baselines, and to derive the fringe intensity at the constructive peak and destructive null along the long baseline. The data analysis involves removing biases and coherently demodulating the short-baseline fringe with the long-baseline fringe tuned to alternate between constructive and destructive phases, combining the results of many measurements to improve the sensitivity, and estimating the part of the <b>null</b> <b>leakage</b> signal which is associated with the finite angular size of the central star. Comparison of the results of null measurements on science target and calibrator stars permits the instrumental leakage - the "system null leakage" - to be removed and the off-axis light to be measured...|$|E
40|$|This paper investigates {{capabilities}} of the TVLA, {{which is one of}} the most promising tools for automated formal verification of programs manipulating unbounded dynamic data structures. We chose two areas to be verified with this tool and we hope that we will learn as much as possible from problems arising in the verification process. In the future we would like to eliminate some of these problems. The first set of examples contains the operations with binary sorted trees. After executing these procedures we verify if the tree is sorted after the insertion and if all the pointer manipulations were correct (no memory <b>leakage,</b> <b>null</b> pointer dereferences, etc.). The second example is the Bakery algorithm {{which is one of the}} most famous mutual exclusion algorithms. We want to verify safety of this algorithm. ...|$|R

