38|1|Public
5000|$|It DOES NOT use {{learning}} and <b>non-chronological</b> <b>backtracking</b> (introduced in 1996).|$|E
50|$|Beam Search Using Limited Discrepancy Backtracking (BULB) is {{a search}} {{algorithm}} that combines limited discrepancy search with beam search and thus performs <b>non-chronological</b> <b>backtracking,</b> which often outperforms the chronological backtracking done by Beam Stack Search and Depth-First Beam Search.|$|E
5000|$|Defining {{variants}} {{of the basic}} backtracking algorithm. The latter direction include <b>non-chronological</b> <b>backtracking</b> (aka backjumping) and clause learning. These refinements describe a method of backtracking after reaching a conflict clause which [...] "learns" [...] the root causes (assignments to variables) of the conflict {{in order to avoid}} reaching the same conflict again. The resulting Conflict-Driven Clause Learning SAT solvers are {{the state of the art}} in 2014.|$|E
40|$|Several {{approaches}} {{have been proposed}} to accelerate the NP-complete Boolean Satisfiability problem (SAT) us-ing reconfigurable computing. We present an FPGA based clause evaluator, where each clause is modeled as a shift register that is either right shifted, left shifted, or standstill according to whether the current assigned variable value satisfy, unsatisfy, or does not effect the clause, respectively. For a given problem instance, {{the effect of the}} value of each of its variables on its SAT formula is loaded in the FPGA on-chip memory. This results in less configuration effort and fewer hardware resources than other available SAT solvers. Also, we present a new approach for imple-menting conflict analysis based on a conflicting variables accumulator and priority encoder to determine backtrack level. Using these two new ideas, we implement an FPGA based SAT solver performing depth-first search with <b>non-chronological</b> conflict directed <b>backtracking.</b> We compare our SAT solver with other solvers through instances from DIMACS benchmarks suite...|$|R
5000|$|Modern SAT solvers (developed in {{the last}} ten years) come in two flavors: [...] "conflict-driven" [...] and [...] "look-ahead". Conflict-driven solvers augment the basic DPLL search {{algorithm}} with efficient conflict analysis, clause learning, <b>non-chronological</b> <b>backtracking</b> (a.k.a. backjumping), as well as [...] "two-watched-literals" [...] unit propagation, adaptive branching, and random restarts. These [...] "extras" [...] to the basic systematic search have been empirically shown to be essential for handling the large SAT instances that arise in electronic design automation (EDA). Look-ahead solvers have especially strengthened reductions (going beyond unit-clause propagation) and the heuristics, and they are generally stronger than conflict-driven solvers on hard instances (while conflict-driven solvers can be much better on large instances which actually have an easy instance inside).|$|E
40|$|A search {{algorithm}} solving multi-valued (MV) satisfiablity (SAT) {{problems is}} proposed in this report. It {{is based on}} the general Davis-Putnam search-pruning procedure. And it incorporates several speed-up techniques: an efficient constraint propagation process, conflict-based learning, and <b>non-chronological</b> <b>backtracking.</b> Decision heuristics and some implementation techniques are also presented...|$|E
40|$|Abstract. We {{introduce}} in {{this paper}} a lightweight technique for reducing work repetition caused by <b>non–chronological</b> <b>backtracking</b> commonly practiced by DPLL–based SAT solvers. The presented technique {{can be viewed as}} a partial component caching scheme. Empirical evaluation of the technique reveals significant improvements on a broad range of industrial instances. ...|$|E
40|$|The {{problem of}} proving that a propositional boolean formula is satisfiable (SAT) {{is one of}} the {{fundamental}} problems in computer science. The application of SAT solvers in VLSI CAD has become of major interest. The most popular SAT algorithms are based on the well known Davis-Putnam procedure. There, to guide the search, a branching rule is applied for selecting and assigning unassigned variables. Additionally, conflict analysis methods are available that result in <b>non-chronological</b> <b>backtracking</b> that prevents the SAT algorithm from searching nonrelevant parts of the search space. In this paper we focus on the impact of different branching rules and present an approach which (1) allows the use of several branching rules to be applied (not limited to one static rule) and (2) uses information from <b>non-chronological</b> <b>backtracking</b> to dynamically adapt the probabilities of the branching rules to be selected. Our approach results in a faster and more robust behaviour of the SAT algorithm. ...|$|E
40|$|In {{this paper}} we outline QuBE 7 ’s main features, {{describing}} first the options of the preprocessors, and then giving some details {{about how the}} core search-based solver (i) performs unit and pure literal propagation; and (ii) performs the “Conflict Analysis procedure” for <b>non-chronological</b> <b>backtracking,</b> generalised from the SAT to the QBF case. We conclude with the experimental evaluation, showing that QuBE 7. 0 is the a state-of-the-art single-engine QBF solver...|$|E
40|$|Recent {{state-of-the-art}} SAT solvers {{can handle}} hand-crafted instances {{with hundreds of}} thousands of variables and several million clauses. Only a few years ago, the ability to handle such instances appeared completely out of reach. The most effective complete solvers are generally based on Davis-Putnam-Loveland-Logemann style search procedures augmented with a number of special techniques, such as clause-learning, <b>non-chronological</b> <b>backtracking,</b> loolahead, fast unit-propagation, randomization, and restart strategies. The progress in this area has largely been driven by experimental work on diverse sets of benchmark problems, including regular SAT competions. One key open area of research is to obtain a better understanding as to why these methods work so well. In this paper, we hope to obtain advance our understanding of the effectivness of current techniques and analyze what features of practical instances makes them so amenable to these solution methods. Of the many enhancements of DPLL, we will focus our attention on the interplay between certain special features of problem instances, polytime propagation methods, and restart techniques. This analysys is clearly only part of the full story, since other enhancements, such as clause learnings and <b>non-chronological</b> <b>backtracking,</b> provide additional power to these solvers...|$|E
40|$|A new {{framework}} for presenting and analyzing the functionality {{of a modern}} DLL-based SAT solver is proposed. Our approach exploits the inherent relation between backtracking and resolution. We show how to derive the algorithm of a modern SAT solver from DLL step-by-step. We analyze the inference power of Boolean Constraint Propagation, <b>Non-Chronological</b> <b>Backtracking</b> and 1 UIP-based Conflict-Directed Backjumping. Our work can serve as an introduction to a modern SAT solver functionality and {{as a basis for}} future work on the inference power of a modern SAT solver and on practical SAT solver design...|$|E
40|$|Abstract. We {{present an}} online method for {{estimating}} {{the cost of}} solving SAT problems. Modern SAT solvers present several challenges to estimate search cost including <b>non-chronological</b> <b>backtracking,</b> learning and restarts. Our method uses a linear model trained on data gathered {{at the start of}} search. We show the effectiveness of this method using random and structured problems. We demonstrate that predictions made in early restarts can be used to improve later predictions. We also show that we can use such cost estimations to select a solver from a portfolio. ...|$|E
40|$|This paper {{addresses}} {{the problem of}} integrating different lower bounding techniques into Satisfiability-based algorithms for the Binate Covering Problem (BCP), a wellknown restriction of Boolean Optimization. The most significant aspect of integrating lower bounding techniques into Satisfiability-based algorithms for BCP {{is the ability to}} backtrack non-chronologically whenever lower bounding is applied. The lower bounding techniques considered include the well-known linear programming relaxations and maximum independent sets, among others. Besides establishing conditions for backtracking non-chronologically, we also develop conditions for simplifying the sets of explanations that are utilized for implementing <b>non-chronological</b> <b>backtracking...</b>|$|E
40|$|The idea of {{dependency}} directed backtracking proposed by Stallman and Sussman (1977) offers significant advantages over heuristic starch schemes with chronological backtracking which waste much effort by discarding many "good" choices when backtracking situations arise. However, {{we have found}} that existing <b>non-chronological</b> <b>backtracking</b> machinery is not suitable for certain types of problems, namely, those where choices do not follow logically from previous choices, but are based on a heuristic evaluation of a constrained set of alternatives. This is because a choice is not justified by a âset of supportâ (of previous choices), but because its advantages outweigh its drawbacks in comparison to its competitors. What is needed for these types of problems is a scheme where {{the advantages and disadvantages of}} choices are explicitly recorded during problem solving. Then, if an unacceptable situation arises, information about the nature of the unacceptability and the tradeoffs can be used to determine the most appropriate backtracking point. Further, this requires the problem solver to use its hindsight to preserve those "good" intervening choices that were made chronologically after the "bad" choice, and to resume its subsequent reasoning in fight of the modified set of constraints. In this paper, we describe a problem solver for <b>non-chronological</b> <b>backtracking</b> in situations involving tradeoffs. By endowing the backtracker with access to domain-specific knowledge, a highly contextual approach to reasoning in dependency directed backtracking situations can be achieved. ...|$|E
40|$|We {{describe}} a problem solver that met <b>non-chronological</b> <b>backtracking</b> in situations involving tradeoffs. The novel {{aspect of the}} problem solver is it ability to weigh {{advantages and disadvantages of}} alternatives at choke points. Whenever untenable situations arise, this information is available to the backtracker to determine the most appropriate backtracking point. By endowing the backtracker with access to domain-specific knowledge, a highly contextual approach to reasoning in dependency directed backtracking situations can be achieved. An area of investigation now commonly referred to as &quot;Dependency Directed Reasoning, &quot; has had a major impact on AI research in the last decade (de Kleer et. al...|$|E
40|$|Abstract. In {{order to}} {{facilitate}} automated reasoning about large Boolean combinations of non-linear arithmetic constraints involving transcendental functions, we extend the paradigm of lazy theorem proving to intervalbased arithmetic constraint solving. Algorithmically, our approach deviates substantially from “classical ” lazy theorem proving approaches in that it directly controls arithmetic constraint propagation from the SAT solver rather than completely delegating arithmetic decisions to a subordinate solver. From the constraint solving perspective, it extends intervalbased constraint solving with all the algorithmic enhancements that were instrumental to the enormous performance gains recently achieved in propositional SAT solving, like conflict-driven learning combined with <b>non-chronological</b> <b>backtracking.</b> ...|$|E
40|$|We {{present an}} online method for {{estimating}} {{the cost of}} solving SAT problems. Modern SAT solvers present several challenges to estimate search cost including <b>non-chronological</b> <b>backtracking,</b> learning and restarts. Our method uses a linear model trained on data gathered {{at the start of}} search. We show the effectiveness of this method using random and structured problems. We demonstrate that predictions made in early restarts can be used to improve later predictions. We also show that we can use such cost estimations to select a solver from a portfolio. Comment: 6 pages, 3 figures. Proc. of the 11 th International Conf. on Theory and Applications of Satisfiability Testing, Guangzhou, China, May 200...|$|E
40|$|Abstract. We {{experimentally}} {{evaluate the}} cache performance of different SAT solvers {{as a case}} study for efficient implementation of SAT algorithms. We evaluate several different BCP mechanisms and show their respective run time and cache performances on selected benchmark instances. From the experiments we conclude that cache friendly data structure is a key element for efficient implementation of SAT solvers. We also show empirical cache miss rates of several modern SAT solvers based on the Davis-Logemann-Loveland algorithm with learning and <b>non-chronological</b> <b>backtracking.</b> We conclude that recently developed SAT solvers are much more cache friendly in data structures and algorithm implementations compared with their predecessors. ...|$|E
40|$|Abstract. Most {{state-of-the-art}} SAT solvers {{are based}} on DPLL search and require the input formula to be in clausal form (cnf). However, typical formulas that arise in practice are non-clausal. We present a new non-clausal SAT-solver based on General Matings instead of DPLL search. Our technique is able to handle non-clausal formulas involving ∧, ∨, ¬ operators without destroying their structure or introducing new variables. We present techniques for performing search space pruning, learning, <b>non-chronological</b> <b>backtracking</b> {{in the context of}} a General Matings based SAT solver. Experimental results show that our SAT solver is competitive to current state-of-the-art SAT solvers on a class of non-clausal benchmarks. ...|$|E
40|$|AbstractCurrent Web {{technologies}} {{provide the}} basis for publishing and composing large number of Web Services which are char–acterized by functional, non-functional, and transactional properties. Although the research community has proposed several approaches to effciently solve problems as service selection and composition, some of these solutions may be incomplete, i. e., they may fail producing a solution when solutions exist. In this paper we propose a <b>non-chronological</b> <b>backtracking</b> strategy which is implemented in a state-of-the-art composition algorithm named PT-SAM, and complete–ness is achieved in the context of transactional web service composition. Empirical results suggest that the proposed approach may overcome the chronological backtracking strategy by up one order of magnitude...|$|E
40|$|Abstract — In this paper, we {{introduce}} a novel preimage computation technique that directly computes the circuit cofactors without an explicit search for any satisfiable solution. We use an implicit search on the primary inputs of a sequential circuit to compute all the circuit cofactors for the target preimage. In order {{to alleviate the}} computational cost, aggressive learning techniques are introduced that reason on the search-states by analyzing the relations among circuit cofactors. Such analysis generates search-state induced clauses that directly help to prune the cofactor space during preimage computation and to perform <b>non-chronological</b> <b>backtracking.</b> Experimental results show that a significant improvement can be achieved in both performance and capacity {{as compared to the}} existing techniques. I...|$|E
40|$|Unit propagation-based (UP) lower bounds {{are used}} in the vast {{majority}} of current Max-SAT solvers. However, lower bounds based on UP have seldom been applied in Pseudo-Boolean Optimization (PBO) algorithms derived from the DPLL procedure for Propositional Satisfiability (SAT). This paper enhances a DPLL-style PBO algorithm with an UP lower bound, and establishes conditions that enable constraint learning and <b>non-chronological</b> <b>backtracking</b> in the presence of conflicts involving constraints generated by the UP lower bound. From a theorical point of view, the paper highlights the relationship between the recent UP lower bound and the well-known Maximum Independent Set (MIS) lower bound. Finally, the paper provides preliminary results that show the effectiveness of the proposed approach for representative sets of instances...|$|E
40|$|Abstract. The {{utilization}} of cutting planes {{is a key}} technique in Integer Linear Programming (ILP). However, cutting planes have seldom been applied in Pseudo-Boolean Optimization (PBO) algorithms derived from the Davis-Logemann-Loveland (DLL) procedure for Propositional Satisfiability (SAT). This paper proposes the {{utilization of}} cutting planes in a DLL-style PBO algorithm, which incorporates the most effective techniques for PBO. We propose the utilization of cutting planes both during preprocessing and during the search process. Moreover, we also establish conditions that enable clause learning and <b>non-chronological</b> <b>backtracking</b> {{in the presence of}} conflicts involving constraints generated by cutting plane techniques. The experimental results, obtained on a large number of classes of instances, indicate that the integration of cutting planes with backtrack search is an extremely effective technique for PBO. ...|$|E
40|$|CMUSAT-Base is a satisfiability (SAT) solver for {{formulas}} {{expressed in}} {{conjunctive normal form}} (CNF). It uses the DPLL algorithm to decide the satisfiability of CNF formulas. The basic DPLL algorithm is enhanced using various standard techniques such as watch literal scheme for efficient Boolean Constraint Propagation, conflict driven learning, <b>non-chronological</b> <b>backtracking,</b> restarts, conflict clause minimization, and variable activity based decision. The new features of CMUSAT-Base are: 1) an optimization to the watch literal scheme which leads to consistent improvement, 2) simplified data structures based on standard template library (STL), and 3) efficient usage of STL to achieve a high performance SAT solver. Modern SAT solvers employ pre-processing techniques {{in order to simplify}} a given CNF formula before the actual SAT solving starts. CMUSAT solver combines a pre-processing frontend wit...|$|E
40|$|In the paper, SWORD is {{described}} [...] a decision procedure for bit-vector logic that uses SAT techniques and exploits word level information. The main idea of SWORD {{is based on}} the following observation: While current SAT solvers perform very well on instances with a large number of logic operations, their performance on arithmetic operations degrades with increasing data-path width. In contrast, pure word-level approaches are able to handle arithmetic operations very fast, but suffer from irregularities in the word-level structure (e. g. bit slicing). SWORD tries to combine the best of both worlds: On the one hand, it includes fast propagation, sophisticated data structures, as well as advanced techniques like <b>non-chronological</b> <b>backtracking</b> and learning from modern SAT solvers. On the other hand word-level information is exploited in the decision heuristic and during propagation...|$|E
40|$|Linear Pseudo-Boolean Optimization (PBO) {{has found}} {{applications}} in several areas, ranging from Artificial Intelligence to Electronic Design Automation. Due to important advances in Boolean Satisfiability (SAT), new algorithms for PBO have emerged, which are effective on highly constrained instances. However, those algorithms fail in dealing properly {{with the objective}} function of PBO. This paper proposes an algorithm that uses lower bound estimation methods for pruning the search tree in integration with techniques from SAT algorithms. Moreover, the paper shows that the utilization of lower bound estimates can dramatically improve the overall performance of PBO solvers for specific classes of instances. In addition, the paper describes how to apply <b>non-chronological</b> <b>backtracking</b> {{in the presence of}} conflicts that result from the bounding process, using different lower bound estimation methods. 1...|$|E
40|$|Propositional Satisability (SAT) is {{fundamental}} in solving many application problems in Articial Intelligence {{and in other}} elds of Computer Science and Engineering. In the past, {{it has already been}} shown that large simplications can be obtained using algebraic simpli- cation techniques. On the other hand, intelligent backtrack search algorithms for SAT have empirically been shown to be highly eective in pruning the amount of search, applying strategies for <b>non-chronological</b> <b>backtracking</b> and procedures for clause recording. In this paper we propose integrating some algebraic simplication techniques | namely two-variable equivalence and clause inference | within intelligent backtrack search algorithms. When integrated in SAT algorithms, these techniques target the simplication of a problem instance, reducing the associated search cost. With the obtained experimental results we show the importance of the proposed techniques, demonstrating that they are indeed applied in hard real-world problem instances. ...|$|E
40|$|Abstract. Modern Chaff-like SAT solvers enhance plain {{backtracking}} (DLL) by Conflict-Driven Learning (CDL), including 1 UIP-based Conflict-Directed Backjumping (CDB), <b>Non-Chronological</b> <b>Backtracking</b> (NCB), and 1 UIP-based Conflict-Clause Recording (CCR). We {{show how}} to add these enhancements step-by-step to plain DLL to derive Chaff’s Conflict-Driven Learning algorithm, separately and independently of BCP, and {{without reference to}} implication graphs. We demonstrate that DLL with 1 UIP-based CDB, DLL with NCB, plain DLL and tree-like resolution are equal in inference power; and provide a family of formulas linearly separating DLL from DLL with BCP. We demonstrate that a general resolution refutation with t shared subtrees can be simulated by DLL with CCR, making at most t restarts; and propose a new technique, called Conflict Non-Determinism (CND), which makes DLL, enhanced with CCR but without restarts, equal in power to general resolution. ...|$|E
40|$|The {{computation}} {{of prime}} implicants has several and significant applications in different areas, including Auto-mated Reasoning, Non-Monotonic Reasoning, Electronic Design Automation, among others. In this paper we describe {{a new model}} and algorithm for computing mini-mum-size prime implicants of propositional formulas. The proposed approach is based on creating an integer linear program (ILP) formulation for computing the minimum-size prime implicant, which simplifies existing formula-tions. In addition, we introduce two new algorithms for solving ILPs, {{both of which are}} built on top of an algo-rithm for propositional satisfiability (SAT). Given the organization of the proposed SAT algorithm, the resulting ILP procedures implement powerful search pruning tech-niques, including a <b>non-chronological</b> <b>backtracking</b> search strategy, clause recording procedures and identifi-cation of necessary assignments. Experimental results, obtained on several benchmark examples, indicate that the proposed model and algorithms are significantly more effi-cient than other existing solutions. ...|$|E
40|$|Modern, {{efficient}} Answer Set Programming solvers implement answer set search via <b>non-chronological</b> <b>backtracking</b> algorithms. The {{extension of}} these algorithms to answer set enumeration is nontrivial. In fact, adding blocking constraints to discard already computed answer sets is inadequate because the introduced constraints may not fit in memory or deteriorate {{the efficiency of}} the solver. On the other hand, the algorithm implemented by CLASP, which can run in polynomial space, requires invasive modifications of the answer set search procedure. The algorithm is revised in this paper so as to make it almost independent from the underlying answer set search procedure, provided that the procedure accepts as input a logic program and a list of assumption literals, and returns either an answer set (and associated branching literals) or an unsatisfiable core. The revised algorithm is implemented in wasp, and compared empirically to {{the state of the art}} solver CLASP...|$|E
40|$|Cutting {{planes are}} a well-known, widely used, and very eective {{technique}} for Integer Linear Programming (ILP). However, cutting plane techniques are seldom used in Pseudo-Boolean Optimization (PBO) algorithms. This paper addresses {{the utilization of}} Gomory mixed-integer and clique cuts, in Satisability-based algorithms for PBO, and shows how these cuts {{can be used for}} computing lower bounds and for learning new constraints. A side result of learning new constraints is that the utilization of cutting planes enables <b>non-chronological</b> <b>backtracking.</b> Besides cutting planes, the paper also shows that the utilization of search restarts in PBO can be eective in practice, allowing the computation of tighter lower bounds each time the search restarts. The more aggressive lower bounds result from the constraints learned due to the utilization of cutting planes. Experimental results show that the integration of cutting planes and search restarts in a SAT-based algorithm for PBO yields a competitive new solution for PBO...|$|E
40|$|We {{investigate}} {{the problem of}} generalizing acceleration techniques as found in recent satisfiability engines for conjunctive normal forms (CNFs) to linear constraint systems over the Booleans. The rationale behind this research is that rewriting the propositional formulae occurring in e. g. bounded model checking (BMC) [5] to CNF requires a blowup in either the formula size (worst-case exponential) or {{in the number of}} propositional variables (linear, thus yielding a worst-case exponential blow-up of the search space). We demonstrate that acceleration techniques like observation lists and lazy clause evaluation [14] as well as the more traditional <b>non-chronological</b> <b>backtracking</b> and learning techniques generalize smoothly to Davis-Putnam-like resolution procedures for the very concise propositional logic of linear constraint systems over the Booleans. Despite the more expressive input language, the performance of our prototype implementation comes surprisingly close to that of state-of-the-art CNF-SAT engines like ZCha [14]. First experiments with bounded model-construction problems show that the overhead in the satisfiability engine that {{can be attributed to the}} richer input language is often amortized by the conciseness gained in the propositional encoding of the BMC problem...|$|E
40|$|Abstract. In {{this paper}} {{we argue that}} an {{attractive}} and potentially very general way of achieving generalized arc consistency (GAC) on a constraint is by using unit propagation (UP) over a CNF encoding of the constraint. This approach to GAC offers a number of advantages over traditional constraint specific algorithms (propagators) : {{it is easier to}} implement, it automatically provides incrementality and decrementality in a backtracking context, and it can provide clausal reasons to support learning and <b>non-chronological</b> <b>backtracking.</b> Although UP on standard CNF encodings of a constraint fails to achieve GAC, we show here that alternate CNF encodings can be used on which UP does achieve GAC. We provide a generic encoding applicable to any constraint. We also give structure specific encodings for the regular, among, and gen-sequence constraints on which UP can achieve GAC with the same run time bounds as previously presented propagators. Finally, we explain how a UP engine can be added to a CSP solver to achieve a seamless integration of constraints encoded in CNF and propagated via UP and those propagated via traditional constraint specific propagators. ...|$|E
40|$|Goal-level Independent {{and-parallelism}} (IAP) is {{exploited by}} scheduling for simultaneous execution {{two or more}} goals which will not interfere with each other at run time. This can be done safely even if such goals can produce múltiple answers. The most successful IAP implementations to date have used recomputation of answers and sequentially ordered backtracking. While in principie simplifying the implementation, recomputation can be very inefficient if the granularity of the parallel goals is large enough and they produce several answers, while sequentially ordered backtracking limits parallelism. And, despite the expected simplification, {{the implementation of the}} classic schemes has proved to involve complex engineering, with the consequent difficulty for system maintenance and extensión, while still frequently running into the well-known trapped goal and garbage slot problems. This work presents an alternative parallel backtracking model for IAP and its implementation. The model features parallel out-of-order (i. e., <b>non-chronological)</b> <b>backtracking</b> and relies on answer memoization to reuse and combine answers. We show that this approach can bring significant performance advantages. Also, it can bring some simplification to the important engineering task involved in implementing the backtracking mechanism of previous approaches...|$|E
40|$|Abstract. This work {{presents}} a memory-efficient All-SAT engine which, given a propositional formula over sets of important and non-important variables, returns {{the set of}} all the assignments to the important variables, which can be extended to solutions (satisfying assignments) to the formula. The engine is built using elements of modern SAT solvers, including a scheme for learning conflict clauses and <b>non-chronological</b> <b>backtracking.</b> Re-discovering solutions that were already found is avoided by the search algorithm itself, rather than by adding blocking clauses. As a result, the space requirements of a solved instance do not increase when solutions are found. Finding the next solution is as efficient as finding the first one, {{making it possible to}} solve instances for which the number of solutions is larger than the size of the main memory. We show how to exploit our All-SAT engine for performing image computation {{and use it as a}} basic block in achieving full reachability which is purely SATbased (no BDDs involved). We implemented our All-SAT solver and reachability algorithm using the stateof-the-art SAT solver Chaff [19] as a code base. The results show that our new scheme significantly outperforms All-SAT algorithms that use blocking clauses, as measured by the execution time, the memory requirement, and the number of steps performed by the reachability analysis. ...|$|E
40|$|Abstract. The maximum {{constraint}} satisfaction problem MAX-CSP {{is a general}} framework in which many search problems can be readily modeled. We integrate two lines of research from the 1970 s, superresolution and P-optimal algorithms, into one MAX-CSP(Γ) -transition system SPOT. Superresolution is a non-redundant clause learning system with aggressive restarts that formalizes <b>non-chronological</b> <b>backtracking.</b> P-optimal algorithms satisfy in polynomial time a fraction τΓ of the the constraints for constraint language Γ while the fraction τΓ +ɛ is NP-complete. SPOT consists of three novel components: AR, IR and TS. We use a logarithmic abstract representation (AR) to map MAX-CSP(Γ) instances to look-ahead polynomials that provide a blurry, yet optimal view into the search space with outstanding peripheral vision. We provide a novel intermediate representation (IR) to very efficiently manipulate relations by representing them as integers. We introduce a transition system (TS) that generalizes superresolution from SAT to MAX-CSP. Superresolution counteracts the blurry vision of the look-ahead polynomials by pushing the maximum assignment into the periphery where the look-ahead polynomials see best. We discuss the implementation of SPOT and compare its behavior to zChaff and Yices with encouraging results. Our implementation uses principles of Adaptive and Aspect-Oriented Programming to provide for a solver that is easy to experiment with. ...|$|E
