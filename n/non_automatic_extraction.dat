0|3047|Public
40|$|Videokymography is {{a medical}} imaging method of {{revealing}} and diagnosing vocal cords vibrations in voice disorders. Manual data extraction is problematic while <b>automatic</b> <b>extraction</b> can facilitate and re ne the diagnostic process. However, automatic processing is hampered by signal noise and considerable variability in vocal cords vibrations of individual patients. The objective {{of the present study}} is to identify typical characteristics of vocal cords vibrations suitable for <b>automatic</b> <b>extraction</b> and diagnostic interpretation and to implement such <b>automatic</b> <b>extraction.</b> The <b>automatic</b> <b>extraction</b> tool that was implemented reects specifi c features of viodeokymographic images. The system for interpretation of <b>automatic</b> <b>extraction</b> results was developed and tested against manually extracted vibrations data and images. The tool can support kymographic diagnosis of vocal cords disorders...|$|R
40|$|<b>Automatic</b> <b>Extraction</b> of Man-Made Objects from Aerial and Space Images (II), pp. 87 - 96, Grün A., Baltsavias E. P. and Henricsson O. eds., 1997, Birkhaüser Verlag, Basel/Boston/Berlin (Proceedings second Ascona {{workshop}} on <b>automatic</b> <b>extraction</b> of man-made objects from aerial and space images (II), May 4 - 9, 1997, Ascona, Switzerland) status: publishe...|$|R
5000|$|FN P90, a {{personal}} defense weapon (PDW) designed and manufactured by FN Herstal (also called PS-90, <b>non</b> <b>automatic</b> type) ...|$|R
40|$|We {{report in}} this paper on an {{experiment}} on <b>automatic</b> <b>extraction</b> of a Tree Adjoining Grammar from the WSJ corpus of the Penn Treebank. We use an automatic tool developed by (Xia, 2001) properly adapted to our particular need. Rather than addressing general aspects of the <b>automatic</b> <b>extraction</b> {{we focus on the}} problems we have found to extract a linguistically (and computationally) sound grammar and approaches to handle them...|$|R
40|$|International audienceThe {{morphological}} analysis of axonal trees {{is an important}} problem in neuroscience. The first step for such an analysis is the extraction of the axon. Due to the high volume of generated image data and the tortuous nature of the axons, manual processing is not feasible. Therefore, {{it is necessary to}} develop techniques for the <b>automatic</b> <b>extraction</b> of the neuronal structures. In this paper we present a new approach for the <b>automatic</b> <b>extraction</b> of axons from fluorescent confocal microscopy images. It combines algorithms for filament enhancement, binarization, skeletonization and gap filling in a pipeline capable of extracting the axons. The performance of the proposed method was evaluated on real images. Results support the potential use of this technique in helping biologists perform <b>automatic</b> <b>extraction</b> of axons from fluorescent confocal microscopy images...|$|R
40|$|Coping with {{problems}} in grammars automatically extracted from treebanks We report {{in this paper}} on an experiment on <b>automatic</b> <b>extraction</b> of a Tree Adjoining Grammar from the WSJ corpus of the Penn Treebank. We use an automatic tool developed by (Xia, 2001) properly adapted to our particular need. Rather than addressing general aspects of the <b>automatic</b> <b>extraction</b> {{we focus on the}} problems we have found to extract a linguistically (and computationally) sound grammar and approaches to handle them. ...|$|R
40|$|Automatically extracting object {{models from}} images {{is a complex}} task We {{describe}} research in extracting 3 - 0 mod-els of buildings from aerial images. This work has resulted in several related systems including assisted extraction (minimal manual interaction to guide <b>automatic</b> process-ing). <b>automatic</b> <b>extraction</b> with limited imagery and limited building models, and <b>automatic</b> <b>extraction</b> with v e v good imagery and digital elevation models and more complex building models. Some results are provided for the assisted {{and one of the}} automatic systems. 1...|$|R
40|$|Conventional {{methods for}} <b>automatic</b> <b>extraction</b> of {{drainage}} networks usually use a threshold {{based on the}} minimum area of contribution criteria. However, these methods rarely present realistic results and cumbersome manual editing is required. This paper proposes selection of {{a new set of}} attributes using supervised learning methods (decision trees) to develop a classification methodology for the <b>automatic</b> <b>extraction</b> of drainage networks. Among the methods evaluated, the J 48 algorithm showed the best results with accuracy greater than 90 %. Pages: 5753 - 576...|$|R
5000|$|Zakonov A., Shalyto A. <b>Automatic</b> <b>Extraction</b> and Verification of State-Models for Web Applications // Lecture Notes in Electrical Engineering. 2012. V.133. Part 1, pp. 157-160.|$|R
5000|$|Its main {{concrete}} {{application is}} formal static analysis, the <b>automatic</b> <b>extraction</b> {{of information about}} the possible executions of computer programs; such analyses have two main usages: ...|$|R
40|$|In {{this paper}} we present and {{evaluate}} three approaches to measure comparability of documents in non-parallel corpora. We develop a task-oriented definition of comparability, {{based on the}} performance of <b>automatic</b> <b>extraction</b> of translation equivalents from the documents aligned by the proposed metrics, which formalises intuitive definitions of comparability for machine translation research. We demonstrate application of our metrics for the task of <b>automatic</b> <b>extraction</b> of parallel and semiparallel translation equivalents and discuss how these resources can be used in the frameworks of statistical and rule-based machine translation. ...|$|R
40|$|The <b>automatic</b> <b>extraction</b> of {{collocations}} from lare corpora has so {{far been}} restricted to binary structures (bigrams). This is mainly due to statistical issues, as {{it is not easy to}} extend the traditional scores (dice, log-likelihood, z-score, t-score, mutual information, etc.) to higher grams. There has also been criticism on the great variation in the results obtained by these scores. This paper proposes an alternative approach to the <b>automatic</b> <b>extraction</b> of collocations from corpora, that can be applied to higher grams and is based on the average proximity between the grams...|$|R
50|$|The Hawaii Warriors {{were the}} third team from a <b>non</b> <b>automatic</b> {{qualifier}} conference {{to play in}} a BCS bowl game. They played Georgia in the Sugar Bowl on January 1, 2008 in New Orleans.|$|R
5000|$|Daraselia N, Yuryev A, Egorov S, Mazo I, Ispolatov I. <b>Automatic</b> <b>extraction</b> of gene {{ontology}} annotation and its {{correlation with}} clusters in protein networks. BMC Bioinformatics. 2007 Jul 10;8(1):243 ...|$|R
40|$|Contextual {{information}} can facilitate <b>automatic</b> <b>extraction</b> of objects from digital imagery. This paper addresses {{the use of}} context for the <b>automatic</b> <b>extraction</b> of roads from aerial imagery. Context is restricted to knowledge about relations between roads and other objects and is hierarchically structured. More specific, context is used to guide road extraction on a global and on a local level. On a global level {{it is used to}} emphasize characteristic parts of the road model (context regions). On a local level it initiates contextual reasoning (context sketches). 1 Introduction The <b>automatic</b> <b>extraction</b> of objects from digital imagery is a very complex task. It is widely accepted that the complexity can be reduced by integrating context information into the extraction process, e. g. (Strat 1992). Generally speaking, context means that there exists knowledge not only about the object of interest but also about other relevant facts and their relations to the object of interest. Apart from [...] ...|$|R
50|$|Feature Analyst is {{available}} in two versions, Standard and Professional. The professional version includes building extraction and change detection tools. The Feature Analyst extension adds <b>automatic</b> <b>extraction</b> capability to Esri’s ArcGIS.|$|R
5000|$|Tools for the <b>Automatic</b> <b>Extraction</b> and Visualization of Concepts: Tools {{are being}} {{developed}} to improve the analysis of massive quantities of information and intelligence from various sources to support military decision-making.|$|R
5000|$|The <b>automatic</b> <b>extraction</b> of {{examples}} to train supervised learning algorithms reviewed has been, by far, the best explored approach to mine the web for word sense disambiguation. Some results are certainly encouraging: ...|$|R
40|$|Abstract: attack <b>automatic</b> feature <b>extraction</b> {{technology}} {{is an important}} research of network security technology. From the network present situation research proceed with, to attack the <b>automatic</b> feature <b>extraction</b> technology for definition and classifycation, and for each category of technology are introduced in detail, and presents several attacks of <b>automatic</b> feature <b>extraction</b> technology, finally to present these technical deficiencies and the possible development trend are discussed...|$|R
30|$|The first {{system of}} this nature was TERMINO, {{developed}} for the French language [2]. In Brazil, the beginning of investigations on <b>automatic</b> <b>extraction</b> of (candidate) terms occurred {{at the end of}} the 1990 s [3].|$|R
30|$|Also {{it would}} be {{important}} for the proposed framework to be expanded with <b>automatic</b> <b>extraction</b> methods of network traffic characteristics, with semi- and unsupervised learning, so that it would fully automate the process of identifying malicious applications.|$|R
40|$|In {{graduation}} thesis {{the main}} features and theoretical frameworks of terrestrial and airborne laser scanning are presented. The algorithm for Hough transform that is described in detail, was used for searching power lines in a point cloud and on a raster that is generalized from the laser scanning data. The whole procedure of extraction of power lines is described from the pre-processing of data to the final results. Our own program was used for <b>automatic</b> <b>extraction</b> of power lines from pre-treated point cloud. <b>Automatic</b> <b>extraction</b> of power lines was tested from the raster with another program of our own. Both programs that are mentioned above were written in Matlab programming language. In order to increase the effectiveness of both programs, the redundant points that do not represent power lines were eliminated by LAStools. Effectiveness of the methods was estimated in two ways. First it was estimated visually and then by comparing the calculated coordinates of identical intersections of power lines. Estimation was made for all four examples (<b>automatic</b> <b>extraction</b> of power lines and calculation of coordinates of intersections of power lines in the point cloud of terrestrial laser scanning and airborne laser scanning; <b>automatic</b> <b>extraction</b> of power lines and calculation of coordinates of intersections of power lines on raster that is generalized from the terrestrial and airborne laser scanning data). The effect of pre-treated data on processing speed of the program that automatically extracts power lines was evaluated. At the end there are ideas for possible improvements of the methodology and guidelines for further development...|$|R
40|$|A low-frequency {{nonlinear}} two-port characterization {{system is}} described and methods are developed {{to allow the}} <b>automatic</b> <b>extraction</b> of device and circuit parameters necessary for intermodulation prediction including memory effects. Nonlinear characterization has been achieved up to fifth-order. 3 page(s...|$|R
50|$|The {{results are}} {{displayed}} {{with a high}} resolution of 1 km x 1 ° x 230 km grid with 256 data levels. There is an <b>automatic</b> <b>extraction</b> of the storm motion which is integrated in the algorithms for corrections.|$|R
40|$|Abstract. Previous {{approaches}} on <b>automatic</b> <b>extraction</b> of lexical similarities {{have considered}} as semantic unit of text the word. However, the theoretical perspective of contextual lexical semantics suggests that larger segments of text, specifically non-compositional multiwords, are {{more appropriate for}} this role. We experimentally tested the applicability of this notion, applying <b>automatic</b> collocation <b>extraction</b> to identify and merge such multiwords prior to the similarity estimation process. Employing an automatic comparative evaluation scheme we ascertain improvement of the extracted lexico-semantic knowledge. ...|$|R
40|$|International audienceMuch recent {{research}} {{deals with the}} <b>automatic</b> <b>extraction</b> of multimedia metadata. While <b>automatic</b> <b>extraction</b> is already well understood for low-level features (e. g., color), it remains an open issue for high-level (semantic) features [1]. In this context, an evaluation of currently available MPEG- 7 annotation tools and frameworks has been performed [2]. Most tools can extract low-level features automatically, and some also provide functionalities to describe highlevel features manually. This paper highlights VAnalyzer 1, an MPEG- 7 based semantic video annotation tool, which is also able to extract certain semantic annotation automatically. Here, we only introduce {{the features of the}} VAnalyzerwithout discussing its architecture. Finally, the demonstration procedure will be highlighted...|$|R
40|$|In this paper, {{we study}} {{efficient}} and reliable <b>automatic</b> <b>extraction</b> algorithm {{to find out}} the open space area from the high resolution urban satellite imagery, and to detect changes from the extracted open space area during the period 2003, 2006 and 2008. This <b>automatic</b> <b>extraction</b> and change detection algorithm uses some filters, segmentation and grouping that are applied on satellite images. The resultant images may be used to calculate the total available open space area and the built up area. It may also be used to compare the difference between present and past open space area using historical urban satellite images of that same projection, which is an important geo spatial data management application. Comment: 07 page, 13 figure...|$|R
40|$|Newspaper {{articles}} and other natural-language texts describe actions, events, and states of affairs. A crucial {{first step toward}} the <b>automatic</b> <b>extraction</b> of information from these texts—for use in such applications as automatic question answering or summarization—is the capacity to identify what events are bein...|$|R
40|$|Abstract. This paper {{examines}} {{how far we}} are towards <b>automatic</b> <b>extraction</b> of building features, by comparing two pipelines from image data to building features: an ideal pipeline, based on the requirements of an on-going project, and a realistic pipeline, based on current computer vision technologies...|$|R
40|$|This study {{focuses on}} <b>automatic</b> <b>extraction</b> of {{sentiment}} expressions associated with given targets from Twitter. It addresses {{one of the}} key challenges in this work: Wide diversity and informal nature of sentiment expressions that cannot be trivially enumerated or captured using predefined lexical patterns...|$|R
40|$|Lexical {{alignment}} {{is one of}} {{the most}} challenging tasks in processing and exploiting parallel texts. There are numerous applications that may benefit from an accurate multilingual lexical alignment of bi- and multi-language corpora. We describe in this paper a hypothesistesting approach to the problem of <b>automatic</b> <b>extraction</b> of translation equivalents from sentence-aligned and tagged parallel corpora. The algorithm was used for <b>automatic</b> <b>extraction</b> of 6 bi-lingual lexicons with English as source language and Bulgarian, Czech, Estonian, Hungarian, Romanian and Slovene as the target one, as well as a 7 -language lexicon with English as a hub and the other 6 CEE languages. For the experiments described here we used the 7 -language aligned corpus based on Orwell’s “ 1984 ” novel. 1...|$|R
40|$|According to the {{analysis}} of the tectonic characteristics of thrust belt in the Longmen Mountain, the present study aims to build a methodology to extract liner fault structures in the study area. The methodology is an approach which includes <b>automatic</b> <b>extraction</b> of major faults based on combined calculation of landform factors from the SRTM-DEM and revision of the <b>automatic</b> <b>extraction</b> result according to remote sensing images and geologic data. Therein, these landform factors including elevation, slope, aspect and variation of aspect, slope of slope (SOS) and slope of aspect (SOA). The compound method, including the spatial analysis techniques based on SRTM-DEM, interpretation of remote sensing images, and some geosciences' researches, provides strong technical support to achieve the quantization of the morphotectonics research...|$|R
40|$|In the 21 st century, Aerial and {{satellite}} images are information rich. They are also complex to analyze. For GIS systems, many features require fast and reliable extraction {{of open space}} area from high resolution satellite imagery. In this paper we will study efficient and reliable <b>automatic</b> <b>extraction</b> algorithm {{to find out the}} open space area from the high resolution urban satellite imagery. This <b>automatic</b> <b>extraction</b> algorithm uses some filters and segmentations and grouping is applying on satellite images. And the result images may use to calculate the total available open space area and the built up area. It may also use to compare the difference between present and past open space area using historical urban satellite images of that same projection...|$|R
40|$|Previous {{studies on}} <b>automatic</b> <b>extraction</b> of lexical {{similarities}} have considered as semantic unit of text the word. However, {{the theory of}} contextual lexical semantics implies that larger segments of text, namely non-compositional multiwords, are more appropriate for this role. We experimentally tested the applicability of this notion applying <b>automatic</b> collocation <b>extraction</b> to identify and merge such multiwords prior to the similarity estimation process. Employing an automatic WordNet-based comparative evaluation scheme along with a manual evaluation procedure, we ascertain improvement of the extracted similarity relations...|$|R
40|$|A b s t r a c t Objective: The aim of {{this study}} was to {{construct}} automatically a knowledge base concerning the pharmacodynamic properties of antibiotics and a visualization tool. Design: The authors studied the various guidelines used to write the pharmacodynamics section of the Summary of Product Characteristics (SPC) for antibiotics and constructed a conceptual model of the information. Particular words, syntagms, and punctuation elements were marked in the SPC texts, and <b>automatic</b> <b>extraction</b> was then used to build a knowledge base. This base was used to create dynamic HTML tables displaying the activity spectra of the antibiotics. Measurements: The authors analyzed the performances of <b>automatic</b> <b>extraction</b> (recall and precision). Results: The conceptual pharmacodynamics model dealt with antibiotics, pathogens, susceptibility tests, and the prevalence of resistance. <b>Automatic</b> <b>extraction</b> had a recall rate of 97. 9 % and a precision of 96. 2 %. The tool displaying antibiotic spectra and resistance prevalences used color codes to identify differences in susceptibility. Conclusion: This tool can provide an overview of the prevalence of resistance as expressed in SPC in primary care settings. Its potential impact should be evaluated. j J Am Med Inform Assoc. 2004; 11 : 285 – 293. DOI 10. 1197 /jamia. M 1425. Bacterial resistance to antibiotics is becoming a major proble...|$|R
40|$|Methods for <b>automatic</b> <b>extraction</b> of left {{ventricular}} endocardium in echocardiograms have been proposed, which {{are required to}} quantitatively evaluate the functional performance of the left ventricle. In this pa-per, we propose a new <b>automatic</b> <b>extraction</b> method based on double thresholding for echocardiograms, and evaluate the effectiveness and the accuracy. B-mode echocardiograms are first binarized with a threshold determined by the discriminant analysis for the gray level histogram. Then the binary images are contracted n times to remove small regions and to disconnect the region of cardiac cavity from the other false regions. Among the obtained regions which corresponds to the cardiac cavity is selected and dilated 2 n times to create a mask which restricts {{the region of the}} second thresholding operation. The size and the location of the cardiac cavity in the preceding frame are utilized to select the corresponding region. The masked image of each frame is binarized in the restricted area {{in the same way as}} in the first thresholding operation. The evaluation test is carried out using the scatter diagram of radius of contours extracted by two observers and <b>automatic</b> <b>extraction</b> method. These results showed that the accuracy of the extracted contours was favorably compared to the accuracy of manually traced contours...|$|R
