0|889|Public
40|$|Several studies {{about the}} speech {{development}} of deaf children suggest that their speech development {{differs from that}} of <b>normally</b> <b>hearing</b> children. To establish in which respect this development differs and from what age onwards, the spoken utterances of deaf and <b>normally</b> <b>hearing</b> children from 12. 5 until 17. 5 months of age are studied. This paper reports about some preliminary results of a study on the total number of spoken utterances in a 10 -minutes period of monthly recordings and on the average duration of 50 utterances in the speech of deaf and <b>normally</b> <b>hearing</b> children. It became clear that at this age there are already some differences between deaf and <b>normally</b> <b>hearing</b> children. 1 Introduction Many studies indicate that the auditory perception influences the production of speech as early as {{in the first year of}} life. This is concluded along studies that compared the speech of <b>normally</b> <b>hearing</b> children with that of hearing impaired children. It seems that already early in the sp [...] ...|$|R
40|$|This study {{investigated}} {{the conditions under which}} communicative interactions were facilitated in hearing-impaired children and their caregivers as compared to <b>normally</b> <b>hearing</b> children and their caregivers. Participants were six <b>normally</b> <b>hearing</b> children and five hearing-impaired children, and their caregivers. Each interactant's communicative behaviors were coded for the intentions conveyed, discourse turn types, and verbal or nonverbal modalities of expression. Patterns emerged regarding caregiver communicative behaviors that facilitated children's participation in ongoing conversations. Caregiver behaviors most likely to be followed by on-topic responses from <b>normally</b> <b>hearing</b> and hearing-impaired children included caregiver requests, messages expressed through simultaneous verbal and nonverbal means, and turns that extended topics of conversations. Hearing-impaired children tended to produce more partially inadequate on-topic responses to their caregivers' turns than did the <b>normally</b> <b>hearing</b> children. Results are discussed with regard to clinical implications for the improvement or intervention with hearing-impaired children...|$|R
5000|$|... "To {{bring the}} cello to places you wouldn't <b>normally</b> <b>hear</b> it." ...|$|R
5000|$|... "To {{play music}} on the cello you wouldn't <b>normally</b> <b>hear</b> played on the instrument." ...|$|R
5000|$|There {{are several}} new {{telecommunications}} relay service technologies including IP Relay and captioned telephone technologies. A deaf or hard of <b>hearing</b> <b>person</b> can communicate {{over the phone}} with a <b>hearing</b> <b>person</b> via a human translator. Phone captioning is a service in which a hearing person's speech is captioned by a third party, enabling a deaf or hard of <b>hearing</b> <b>person</b> to conduct {{a conversation with a}} <b>hearing</b> <b>person</b> over the phone. Wireless, Internet and mobile phone/SMS text messaging are beginning to take over the role of the TDD.|$|R
50|$|The {{reference}} to deafness {{in the name}} of the school had become obsolete because an increasing number of the students enrolled had communication difficulties but were <b>normally</b> <b>hearing.</b> In particular, the Seashell Trust had developed considerable expertise in working with <b>normally</b> <b>hearing</b> autistic students. The deaf students now admitted by Seashell all have very complex additional needs, including visual impairments, physical difficulties and low general ability.|$|R
50|$|The court <b>normally</b> <b>hears</b> {{cases in}} the Four Courts {{building}} in Dublin, although it also has regular sittings outside the capital.|$|R
40|$|Deposited with {{permission}} of the author. © 1997 Dr. Raymond C. JeanesThe ability to communicate effectively requires individuals to possess knowledge {{in a number of}} areas as well as the skill to apply this knowledge in a wide range of practical communication contexts. Understanding the syntactic and semantic systems, and the ability to put this knowledge into practice are necessary, but not sufficient, to be a competent communicator. In order to be considered a competent communicator it is necessary also to be able to apply pragmatic rules appropriately in the variety of interactional contexts which occur in person to person interaction. It has been shown (e. g., Bench, 1992; Luetke-Stahlman & Luckner, 1991) that profoundly deaf children have difficulty in understanding and applying syntactic and semantic rules at the same levels of proficiency as their <b>normally</b> <b>hearing</b> peers. Major causes underlying this difference are the greatly reduced amount of linguistic input typically received by profoundly deaf children and the imperfect quality of that input, even when appropriate amplification is used. These conditions, in association with greatly reduced opportunity for profoundly deaf children to interact with more mature communicators, negatively affect the acquisition and application of syntactic and semantic rules. The hypotheses of this study are: (a) that these same conditions also result in difficulties for profoundly deaf children in understanding and applying pragmatic rules and strategies in various interactional contexts, and, (b) that the nature and extent of this difficulty has a negative impact on profoundly deaf children’s face-to-face interactions through the use of inappropriate or unproductive responses to the demands of the communicative context, to the demands of the listener, and to the demands of the interaction process. A referential communication task paradigm was employed to elicit face-to-face interactions between pairs of <b>normally</b> <b>hearing</b> students and profoundly deaf students, both from oral educational settings and educational settings in which sign is used. The tasks employed to elicit these interactions were designed to necessitate the use of pragmatic skills in order for the interactions to be completed successfully. Transcripts of the interactions were analysed for their effectiveness. A number of pragmatic skills were considered; these included the appropriateness and effectiveness of speakers’ responses to the contextual requirements of the different communication tasks, the appropriateness and effectiveness of speakers’ responses to the requirements of their listener, and the appropriateness and effectiveness of speaker and listener responses of the interactional process. Since the participants’ performances are an overt expression of the speakers’ and listeners’ conceptions of their role in face-to-face interaction, the interactions provide insights into the metacommunication knowledge of profoundly deaf children and <b>normally</b> <b>hearing</b> children. It is predicted that because of the reduction in the quantity and quality of interactions in which profoundly deaf children are involved, their capacity to apply pragmatic rules appropriately in face-to-face interactions will be less effective than that of their <b>normally</b> <b>hearing</b> peers. Other areas considered were the degree to which there was improvement with age in the use of pragmatic skills, and the degree to which the communicative performance of the students from oral settings resembled that of the <b>normally</b> <b>hearing</b> students, given that all the orally educated students were enrolled in integrated educational settings and, thus, had daily interaction with <b>normally</b> <b>hearing</b> students. It is predicted that there will be improvement with age in the skills being considered. It is further predicted that because of the day to day contact the oral students have with <b>normally</b> <b>hearing</b> and <b>normally</b> communicating peers, the performance of the oral students will more closely resemble the performance of the <b>normally</b> <b>hearing</b> group than the profoundly deaf group who sign. The results of the study showed there were significant differences between the <b>normally</b> <b>hearing</b> group and the profoundly deaf group in the overall effectiveness of the interactions, with the <b>normally</b> <b>hearing</b> group being more effective than either the oral group or the sign group. Similarly, there were significant differences between the <b>normally</b> <b>hearing</b> students and the two groups of profoundly deaf students in their ability to apply appropriately pragmatic knowledge to their interactions, suggesting that there are also differences between the <b>normally</b> <b>hearing</b> and the profoundly deaf groups in metacommunication knowledge. Some differences in pragmatic use between the oral group and the sign group were also found. Reasons for the difference in metacommunication knowledge and poor pragmatic performance, which are likely to originate in the early communicative environment and the early educational management of the profoundly deaf children, are suggested. The implications these findings have on current pragmatic acquisition theory for both <b>normally</b> <b>hearing</b> and profoundly deaf children are discussed, as is the significance of the findings on current practice in the education of profoundly deaf children. Areas for subsequent research arising from this study are suggested. Open Acces...|$|R
40|$|Topic of {{this thesis}} is the {{stereotype}} of a <b>hearing</b> <b>person</b> {{from the perspective of}} cultural and linguistic minority of the Deaf and how it is fixated in Czech Sign Language. The theoretical and methodological basis of the thesis lies in cognitive ethnolinguistic of J. Bartmiński and following its principles includes lexicon (analyses individual signs, collocations and idioms connected to the concept of HEARING) as well as text. On this level, different texts are explored: everyday communication in Czech Sign Language, artistic genres (storytelling, visual vernacular, fairy tales, humor, films) and texts written in Czech by Deaf authors. The stereotype of a <b>hearing</b> <b>person</b> thus reconstructed from these sources reflects various experiences of the cultural minority of the Deaf with <b>hearing</b> <b>persons</b> - both positive and negative (especially communication and behavior specific to <b>hearing</b> <b>persons</b> from the viewpoint of the Deaf) ...|$|R
25|$|Studies in {{this area}} {{generally}} compare the behaviour or brain activity in <b>normally</b> <b>hearing</b> monolingual speakers of an oral language, genetically deaf, native signers, and <b>normally</b> <b>hearing</b> bimodal bilinguals. With the use of functional Near-Infrared Imaging (fNIR), Kovelman (2009) compared the performance and brain activity of these three groups in picture-naming tasks. These researchers found that, although performance in all groups was similar, neuroimaging revealed that bilinguals showed greater signal intensity within the posterior temporal regions (Wernicke's area) while using both languages in rapid alternation than when they were only using one language.|$|R
40|$|The aim of {{this study}} was to examine {{auditory}} recognition and vocal production of emotions in three prelingually bilaterally profoundly deaf children aged 6 – 7 who received cochlear implants before age 2, and compare them with age-matched <b>normally</b> <b>hearing</b> children. No consistent advantage was found for the <b>normally</b> <b>hearing</b> participants. In both groups, sadness was recognized best and disgust was the most difficult. Confusion matrices among other emotions (anger, happiness, and fear) showed that children with and without hearing impairment may rely on different cues. Both groups of children showed that perception is superior to production. <b>Normally</b> <b>hearing</b> children were more successful in the production of sadness, happiness, and fear, but not anger or disgust. The data set is too small to draw any definite conclusions, but it seems that a combination of early implantation and regular auditory–oral-based therapy enables children with cochlear implants to process and produce emotional content comparable with children with normal hearing...|$|R
40|$|AbstractObjectiveThe {{purpose of}} this study was to examine the levels of {{depressive}} symptoms and the unique contribution of two aspects of emotion regulation (coping and mood states) to the development of depression in hearing-impaired children and a control group. MethodsIn order to compare the groups, self-report questionnaires concerning symptoms of depression, coping strategies, and mood states were used. The study group consisted of 27 children with cochlear implants, 56 children with conventional hearing aids, and 117 <b>normally</b> <b>hearing</b> children. ResultsHearing-impaired children reliably reported more symptoms of depression than their <b>normally</b> <b>hearing</b> peers. Degree of hearing loss, socioeconomic status, gender, and age were unrelated to the level of depressive symptoms. But attending mainstream schools or using exclusively speech for communication were related to fewer depressive symptoms. The associations with depressive symptoms differed between the groups. For hearing-impaired children, the cognitive aspects (coping) and the affective aspects (mood states) of emotional functioning contributed separately to the prediction of depressive symptoms. For <b>normally</b> <b>hearing</b> children an integration of cognitive and affective aspects was detected: adequate coping skills prevented the development of negative mood states and in turn depressive symptoms. ConclusionsHearing-impaired children reported more depressive symptoms than <b>normally</b> <b>hearing</b> children. Prevention and treatment of depression in hearing-impaired children could focus on the use of coping strategies adequately, because these strategies have a direct relation with the level of depression...|$|R
40|$|Thesis (M. Ed.) [...] University of Melbourne, Dept. of Learning and Educational Development, 2001 This study {{investigated}} shifting reference in young hearing-impaired and <b>normally</b> <b>hearing</b> children. Shifting reference {{is a critical}} aspect of communication. Words that shift in reference are unstable in that the referent changes as the circumstances of a conversation change. However, the words do not change their meaning even {{when there is a}} change to the event, or object, or person to which the reference refers. A listener can only determine the referent through the use of shared knowledge of the previous event, or conversation or person, or by being able to take the perspective of the speaker. Shifting reference is seen as a difficult aspect of communication to acquire. This study involved three profoundly hearing-impaired children and three <b>normally</b> <b>hearing</b> children aged 5 : 3 to 5 : 8 years of age. The {{purpose of this study was}} to make an initial investigation into the comprehension and production of shifting reference in young hearing-impaired and <b>normally</b> <b>hearing</b> children in the year prior to primary school. The study also investigated the use of an intervention program that focused on exposing the children to the terms under consideration. The results from the study suggest that the hearing-impaired participants were showing a delay in their comprehension and production of shifting reference when compared with the <b>normally</b> <b>hearing</b> participants. The final assessment of the hearing-impaired participants indicated that the language intervention program had some positive effects, as there was some improvement in most of the selected targeted word categories. The data also suggested that the <b>normally</b> <b>hearing</b> children also benefited from the language intervention program as they improved in both comprehension and production, in the targeted areas where mastery had not been reached. Restricted Access: Staff and Students of the University Onl...|$|R
25|$|Video Remote Interpreting (VRI), {{where the}} <b>hearing</b> <b>person</b> is {{co-located}} {{next to the}} signer.|$|R
5000|$|... {{the ability}} to invoke a relay service by deaf or hard of <b>hearing</b> <b>persons,</b> ...|$|R
5000|$|Video Remote Interpreting (VRI), {{where the}} <b>hearing</b> <b>person</b> is {{co-located}} {{next to the}} signer.|$|R
5000|$|... #Caption: A deaf person using {{a remote}} VRS {{interpreter}} {{to communicate with}} a <b>hearing</b> <b>person</b> ...|$|R
5000|$|MOPD {{information}} sheet on how deaf and hard of <b>hearing</b> <b>persons</b> can access emergency services ...|$|R
50|$|Although {{the pulse}} can be felt in {{multiple}} {{places in the}} head, people should not <b>normally</b> <b>hear</b> their heartbeats within the head. This is called pulsatile tinnitus, and it can indicate several medical disorders.|$|R
50|$|The sign {{language}} {{is used by}} many <b>hearing</b> <b>person,</b> with level of fluency that greatly varies.|$|R
40|$|Much {{research}} has shown that transient evoked otoacoustic emissions (TEOAEs) can successfully separate <b>normally</b> <b>hearing</b> and hearing impaired populations. However, this finding comes from TEOAEs recorded using conventional averaging at low stimulation rates. Presenting clicks according to maximum length sequences (MLSs) enables TEOAEs to be recorded at very high stimulation rates. This study compares conventional and MLS TEOAEs in <b>normally</b> <b>hearing</b> and hearing impaired adults. Stimulus presentation rates of 40 clicks/s (conventional) and 5000 clicks/s (MLS) were used. The ‘linear’ TEOAEs (i. e., the directly recorded waveforms), the ‘level nonlinear’ (LNL) TEOAEs (i. e., those derived from two linear waveforms separated by a known difference in stimulus level) and the ‘rate nonlinear’ (RNL) TEOAEs (i. e., obtained by subtracting the emission recorded at 5000 clicks/s from that at 40 clicks/s at a fixed stimulus level) were examined to compare how they separated the <b>normally</b> <b>hearing</b> and hearing impaired subjects. When compared to the results for both conventional and MLS linear or LNL TEOAEs, the present study found that the RNL results best reflected the patients’ hearing loss, although the conventional linear and LNL responses performed nearly as well. Only two impaired ears (2 %), both with a best threshold of 30 dB HL at 1000 Hz, produced RNL responses with amplitude within the range produced by 95 % of the normal group...|$|R
40|$|Master of EducationThe aims of {{this study}} were to {{determine}} whether mothers of preschool-age hearing-impaired children could adopt a less dominant and more responsive interaction style when instructed, whether hearing-impaired children could be more dominant and less responsive when interacting with a less dominant and more responsive mother, and whether these changes would result in mother-child interaction being similar to previous results for dyads with <b>normally</b> <b>hearing</b> children. Previous studies have found that mothers of hearing-impaired children use a more dominant interaction style than mothers of <b>normally</b> <b>hearing</b> children, and hearing-impaired children use poorer communication skills than <b>normally</b> <b>hearing</b> children of the same age. Furthermore, school-age hearing-impaired children have been shown to use improved communication skills when interacting with a teacher who was using a less dominant interaction style. In the current study, four dyads of <b>normally</b> <b>hearing</b> mothers and their profoundly hearing-impaired children aged 2 : 3 (years:months) were subjects. Data were collected over four sessions. Mothers were asked to play with their children as they normally would in the first (N) session, and were instructed to adopt a less dominant and more responsive interaction style in the subsequent three sessions (LD 1 -LD 3). Mothers were highly dominant in the N session. They used fewer dominating moves in the LD 1 -LD 3 sessions, but did not use more responsive moves. The children did not use more dominating moves in the LD 1 -LD 3 sessions, but used fewer responsive moves. This resulted in a less dominant maternal interaction style, and a more dominant child interaction style for three of the four dyads only in the LD 1 -LD 3 sessions. The fourth dyad was maternally dominant across all sessions. Also, interactions at the level of dyads were generally similar to previous results for dyads with <b>normally</b> <b>hearing</b> children in the N session. Therefore, instructing mothers to be less dominant and more responsive {{did not appear to be}} an appropriate strategy for use with dyads with preschool-age hearing-impaired children. Restricted Access: Metadata Onl...|$|R
40|$|This study {{investigates the}} {{relation}} between physical measurements of pure-tones, third-octave bands of noise and third-octave bands of speech and subjective judgments of auditory threshold, most-comfortable listening level (MCL) and uncomfortable-listening level (UCL) for three <b>normally</b> <b>hearing</b> listeners...|$|R
40|$|Thresholds for a 6. 5 -kHz {{sinusoidal}} signal, temporally {{centered in}} a 400 -ms broadband-noise masker, were measured {{as a function}} of signal duration for <b>normally</b> <b>hearing</b> listeners and listeners with cochlear hearing loss over a range of masker levels. For the <b>normally</b> <b>hearing</b> listeners, the slope of the function relating signal threshold to signal duration (integration function) was steeper at medium masker levels than at low or high levels by a factor of nearly 2, for signal durations between 2 and 10 ms, while no significant effect of level was found for signal durations of 20 ms and more. No effect of stimulus level was found for the hearing-impaired listeners at any signal duration. For signal durations greater than 10 ms, consistent with many previous studies, the slope of the integration function was shallower for the hearing-impaired listeners than for the <b>normally</b> <b>hearing</b> listeners. However, for shorter durations, {{there was no significant difference}} in slope between the results from the hearing-impaired listeners and those from the <b>normally</b> <b>hearing</b> listeners in the high- and low-level masker conditions. A model incorporating a compressive nonlinearity, representing the effect of basilar-membrane (BM) compression, and a short-term temporal integrator, postulated to be a more central process, can account well for changes in the short-term integration function with level, if it is assumed that the compression is greater at medium levels than at low or high levels by a factor of about 4. This is in reasonable agreement with physiological measurements of BM compression, and with previous psychophysical estimates...|$|R
40|$|Thesis (M. Ed.) [...] University of Melbourne, 1996 The {{subjects}} {{of this study}} were ten profoundly hearing impaired and ten <b>normally</b> <b>hearing</b> preschoolers. These subjects were matched for age (a mean age of four years seven months) and gender. Each subject was observed during three videotaped free play sessions. A forty minute sample from each of these sessions was analysed. This study used a coding scheme devised to code entry tactics and responses which was adapted from Roberts, Brown and Rickards (in press), and interactive behaviours which was adapted from Blank and Franklin (1980) and Hadley and Rice (1991). The results of this study showed that, despite being placed in an integrated setting, <b>normally</b> <b>hearing</b> and hearing impaired preschoolers preferred to attempt entry with children of 'similar' hearing status to themselves. Moreover, when attempting entry into ongoing play the hearing impaired subjects selected entry tactics from a reduced range, and unlike the <b>normally</b> <b>hearing</b> subjects, did not alter their tactics for subsequent entry attempts. Successful play interactions were analysed for duration, "summoning power" (Blank & Franklin, 1980) and communicative mode. The interactions between <b>hearing</b> impaired and <b>normally</b> <b>hearing</b> preschoolers were shown to be shorter in duration than when playing with a partner of the same hearing status; consisted of fewer interactive turns, and were characterised by less summoning power. These 'mixed dyad' interactions were significantly different from those where both partners were of similiar hearing status. The implications of the study for intervention are discussed together with suggestions for future research. Restricted Access: Staff and Students of the University Onl...|$|R
5000|$|... #Caption: A deaf or hard-of-hearing {{person at}} his {{workplace}} using a VRS {{to communicate with}} a <b>hearing</b> <b>person</b> in London.|$|R
5000|$|... #Caption: A {{person at}} her {{workplace}} communicating with a <b>hearing</b> <b>person</b> via a Video Interpreter (VI) {{and use of}} sign language.|$|R
40|$|This study {{assessed}} {{whether the}} increased demand of listening in hearing impaired individuals exacerbates the detrimental impact of auditory distraction on a visual task (useful {{field of view}} test), relative to <b>normally</b> <b>hearing</b> listeners. Auditory distraction negatively affects this visual task, which is linked with various driving performance outcomes. <b>Hearing</b> impaired and <b>normally</b> <b>hearing</b> participants performed useful field of view testing with and without a simultaneous listening task. They also undertook a cognitive test battery. For all participants, performing the visual and auditory tasks together reduced performance on each respective test. For a number of subtests, hearing impaired participants showed poorer visual task performance, though not to a statistically significant extent. Hearing impaired participants were significantly poorer at a reading span task than <b>normally</b> <b>hearing</b> participants and tended to score lower on the most visually complex subtest of the visual task {{in the absence of}} auditory task engagement. Useful field of view performance is negatively affected by auditory distraction, and hearing loss may present further problems, given the reductions in visual and cognitive task performance suggested in this study. Suggestions are made for future work to extend this study, given the practical importance of the findings...|$|R
5000|$|... #Caption: A deaf or hard-of-hearing person using a Video Relay Service at his {{workplace}} {{to communicate}} with a <b>hearing</b> <b>person</b> in London (2007).|$|R
40|$|Objectives: Children with {{hearing loss}} {{are at risk}} of {{developing}} psy-chopathology, which has detrimental consequences for academic and psychosocial functioning later in life. Yet, the causes of the extensive variability in outcomes are not fully understood. Therefore, the authors wanted to objectify symptoms of psychopathology in children with cochlear implants or hearing aids, and in <b>normally</b> <b>hearing</b> peers, and to identify various risk and protective factors. Design: The large sample (mean age = 11. 8 years) included three sub-groups with comparable age, gender, socioeconomic status, and nonver-bal intelligence: 57 with cochlear implants, 75 with conventional hearing aids, and 129 children who were <b>normally</b> <b>hearing.</b> Psychopathology was assessed by means of self- and parent-report measures. Results: Children with cochlear implants showed similar levels of symp-toms of psychopathology when compared with their <b>normally</b> <b>hearing</b> peers, but children with hearing aids had significantly higher levels of psychopathological symptoms, while their hearing losses were approxi-mately 43 dB lower than those of children with implants. Type of device was related with internalizing symptoms but not with externalizing symptoms. Furthermore, lower age and sufficient language and com-munication skills predicted less psychopathological symptoms. Conclusions: Children who are deaf or profoundly hearing impaired and have cochlear implants have lower levels of psychopathological symptoms than children with moderate or severe hearing loss who have hearing aids. Most likely, it is not the type of hearing device but rather the intensity of the rehabilitation program that can account for this dif-ference. This outcome has major consequences {{for the next generation of}} children with hearing loss because children with profound hearing impairment still have the potential to have levels of psychopathology that are comparable to children who are <b>normally</b> <b>hearing...</b>|$|R
40|$|Thesis (M. Ed.) [...] University of Melbourne, 1989 The aim of {{this study}} was to {{investigate}} the implications of previous research that hearing-impaired children are less attentive in class than <b>normally</b> <b>hearing</b> children. An additional aim was to examine the variability in attending behaviour within the hearing impaired group, and to explore the possible influence of a range of variables on this behaviour. Twelve hearing-impaired children and twelve <b>normally</b> <b>hearing</b> subjects attending the same kindergarten were used in the study. They were video-recorded over an extended period during the group story-reading activity which was conducted by their teachers as part of their normal programme. Attending behaviour, as indicated by the direction of their gaze, was observed and coded. A momentary time-sampling technique was used to quantify this behaviour. The levels of attending behaviour of the two groups were not found to be significantly different. However, the variability within the hearing-impaired group was found to be significantly greater than that within the <b>normally</b> <b>hearing</b> group. In the hearing-impaired group, four subjects were found to have low levels of attending. The other eight hearing-impaired subjects showed similar levels of attending to those of the <b>normally</b> <b>hearing</b> subjects. Chronological age, educational background and receptive language ability were found to be significantly associated with levels of attending in the hearing-impaired group. In a follow-up study one year later, each of the subjects from the lower attending group who was available for study showed increased levels of attending. Implications for the educational management of hearing-impaired children and future directions for research in this area are examined in the light of these findings. Restricted Access: Staff and Students of the University Onl...|$|R
50|$|Listening strategies: The {{process of}} {{teaching}} hard of <b>hearing</b> <b>persons</b> common and alternative strategies when listening {{with or without}} amplification to improve their communication.|$|R
50|$|Currently, {{there is}} renewed {{interest}} in using the FFR to evaluate: the role of neural phase-locking in encoding of complex sounds in <b>normally</b> <b>hearing</b> and hearing impaired subjects, encoding of voice pitch, binaural hearing, and evaluating {{the characteristics of the}} neural version of cochlear nonlinearity.|$|R
50|$|Single magistrates do not <b>normally</b> <b>hear</b> {{cases on}} their own, {{although}} {{they do have a}} limited jurisdiction. They usually sit as one of a bench of three magistrates, together with a qualified legal adviser who can advise them on matters of law and procedure.|$|R
40|$|This article {{reports on}} a study {{investigating}} the career development of hard-of-hearing high school students attending regular classes with itinerant teacher support. We compared 65 hard-of-hearing students with a matched group of <b>normally</b> <b>hearing</b> peers on measures of career maturity, career indecision, perceived career barriers, and three variables associated with social cognitive career theory career decision-making self-efficacy, outcome expectations, and goals. In addition, the predictors of career maturity and career indecision were tested in both groups. Results indicated that (a) the two {{groups did not differ}} on measures of career maturity, (b) the SCCT variables were less predictive of career behaviors for the hard-of-hearing students than for the <b>normally</b> <b>hearing</b> students, and (c) perceived career barriers related to hearing loss predicte...|$|R
40|$|The speech {{intelligibility}} index (SII) is an often used calculation method for estimating {{the proportion of}} audible speech in noise. For speech reception thresholds (SRTs), measured in <b>normally</b> <b>hearing</b> listeners using various types of stationary noise, this model predicts a fairly constant speech proportion of about 0. 33, necessary for Dutch sentence intelligibility. However, when the SII model is applied for SRTs in quiet, the estimated speech proportions are often higher, and show a larger inter-subject variability, than found for speech in noise near normal speech levels [65 dB sound pressure level (SPL) ]. The present model attempts to alleviate this problem by including cochlear compression. It {{is based on a}} loudness model for <b>normally</b> <b>hearing</b> and hearing-impaired listeners of Moore and Glasberg [(2004). Hear. Res. 188, 70 - 88]. It estimates internal excitation levels for speech and noise and then calculates the proportion of speech above noise and threshold using similar spectral weighting as used in the SII. The present model and the standard SII were used to predict SII values in quiet and in stationary noise for <b>normally</b> <b>hearing</b> and hearing-impaired listeners. The present model predicted SIIs for three listener types (normal hearing, noise-induced, and age-induced hearing loss) with markedly less variability than the standard SI...|$|R
