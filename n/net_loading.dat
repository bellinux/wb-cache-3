16|305|Public
5000|$|The way the {{sections}} can twist {{in relation to}} each other and the way the vehicle steers, making the back tires follow the same path as the front tires, provide for excellent off-road capabilities in combination with all-wheel drive. The top speed is limited at 55-60 km/h (the ungoverned Archer Artillery System has an average road speed of [...] "at least 70 km/h") and the <b>net</b> <b>loading</b> capacity is ranging from just below 25 to a little over 40 tonnes.|$|E
50|$|When {{scheduling}} {{a production}} order, the relevant tools, {{for the work}} are known, based on the tool list. Also, known is which assemblies, required for the machining process, are already located on the machine tool. Necessary, but not yet available assemblies are calculated and printed in a <b>net</b> <b>loading</b> list. They either have to be assembled or removed from the intermediate storage. With a coordinated logistic of the assemblies {{it is possible to}} reduce the time required for providing and replacement of assemblies at the machine.|$|E
40|$|We {{address the}} problem of {{choosing}} synaptic weights in a recursive (Hopfield) neural network so as to "optimize" the performance of the network on the recognition of binary strings. The problem has been called the <b>net</b> <b>loading</b> (or learning) problem in the literature [10]. The objective is to maximize the basins of attraction around the desired fixed points (binary strings) of the net. It is known that it is NP-hard to evaluate even the two-step radius of attraction of a recursive neural net [3]. We focus on the radius of direct (one-step) attraction and will refer to this as the loading problem. We have both theoretical and computational results on this problem, that we summarize below. ffl A proof that the <b>net</b> <b>loading</b> problem can be solved in polynomial time using linear programming techniques. This resolves a standing problem in the complexity of recursive neural networks [10]. ffl An alternate formulation of the <b>net</b> <b>loading</b> problem as a proximity problem in high-dimens [...] ...|$|E
40|$|In {{electricity}} systems, {{demand and}} supply {{must be in}} balance. The term <b>net</b> <b>load</b> refers to the portion of system demand that must be provided by non-renewable resources, equivalent to system demand minus the generation from variable energy resources such as solar and wind. The ramp rate of <b>net</b> <b>load</b> refers to its rate of change. The ramp rate of a power generator refers to {{the rate at which}} it can change its generation level. As more intermittent renewable resources are integrated into a system, the ramp rate of <b>net</b> <b>load</b> increases, and with that, the need for flexible generators with higher ramping capability (i. e. the ability to quickly ramp their power output up and down as needed). As more intermittent renewable resources are integrated into a system, the ramp rate of <b>net</b> <b>load</b> increases, and with that, the need for flexible generators with ramping capability. This Masters Project takes data on the forecast and realizations of load and renewable generation in the California Independent System Operator (CAISO) region from 05 / 01 / 2014 to 10 / 31 / 2014, and examines the statistical properties of the forecast errors of these quantities and the resulting ramp in <b>net</b> <b>load.</b> It focuses on addressing questions regarding the effects of increased penetration of renewables on market and system operations practices: 1) what is the pattern of forecast error of ramp in <b>net</b> <b>load</b> for different daily time periods? 2) Since <b>net</b> <b>load</b> is equal to system demand minus renewable generation, the forecast uncertainty of the two components contributes to the forecast uncertainty of ramp in <b>net</b> <b>load.</b> What is the element that has larger influence on the forecast error of ramp in <b>net</b> <b>load?</b> 3) A common assumptions about forecast error in system operation is that it follows a normal probability distribution. Is this assumption still valid under current renewable penetration levels? Does this assumption still hold when instead of looking at the forecast error during the day, the analysis is conducted independently for different daily time periods? 4) What are the implications of {{the findings of this study}} about the probability distribution of forecast error in <b>net</b> <b>load</b> to the procurement targets for reserves and ramp capability? Results show that a) the forecast error of ramp in the system’s <b>net</b> <b>load</b> is greatly affected by the forecast errors on generation from PV Solar, especially during twilight hours in the morning and evening, b) the data observed does not allow rejecting the hypothesis that forecast errors of ramp follow a normal probability distribution function. If the data used is representative of CAISO conditions, this suggests that at current penetrations of wind and solar energy, dispatching the system to provision ramping capability equal to 2 standard deviations above the mean of the forecast error of ramp in <b>net</b> <b>load,</b> would results in a system that is able to meet its ramping needs 95 % of the time...|$|R
40|$|Large scale {{wind power}} {{production}} and its variability {{is one of}} the major inputs to wind integration studies. This paper analyses measured data from large scale wind power production. Comparisons of variability are made across several variables: time scale (10 - 60 minute ramp rates), number of wind farms, and simulated vs. modeled data. Ramp rates for Wind power production, Load (total system <b>load)</b> and <b>Net</b> <b>load</b> (load minus wind power production) demonstrate how wind power increases the <b>net</b> <b>load</b> variability. Wind power will also change the timing of daily ramps...|$|R
40|$|Wetland {{restoration}} on peat {{islands in}} the Sacramento-San Joaquin Delta will change the quality of island drainage waters entering the Delta, a primary source of drinking water in California. Peat island drainage waters contain high concentrations of dissolved and particulate organic carbon (DOC and POC) and organic precursors to drinking water disinfection byproducts, such as trihalomethanes (THMs). We quantified the <b>net</b> <b>loads</b> of DOC, POC, and THM-precursors from a constructed subsidence mitigation wetland on Twitchell Island in the Delta to determine the change in drainage water quality that {{may be caused by}} conversion of agricultural land on peat islands to permanently flooded, non-tidal wetlands. Creation of permanently flooded wetlands halts oxidative loss of the peat soils and thereby may mitigate the extensive land-surface subsidence of the islands that threatens levee stability in the Delta. <b>Net</b> <b>loads</b> from the wetland were dominated by DOC flushed from the oxidized shallow peat soil layer by seepage flow out of the wetland. The permanently flooded conditions in the overlying wetland resulted in a gradual evolution to anaerobic conditions in the shallow soil layer and a concomitant decrease in the flow could be minimized by reducing the hydraulic gradient between the wetland and the adjacent drainage ditch. Estimates of <b>net</b> <b>loads</b> from the wetland assuming efflux of surface water only were comparable in magnitude to <b>net</b> <b>loads</b> from nearby agricultural fields, but the wetland and agricultural <b>net</b> <b>loads</b> had opposite seasonal variations. Wetland surface water <b>net</b> <b>loads</b> of DOC, POC, and THM-precursors were lower during the winter months when the greatest amounts of water are available for diversion from the Delta to drinking water reservoirs...|$|R
40|$|The authors {{address the}} problem of {{choosing}} synaptic weights in a recursive (Hopfield) neural network so as to “optimize�? the performance of the network on the recognition of binary strings. The problem has been called the <b>net</b> <b>loading</b> (or learning) problem in the literature. The objective is to maximize the basins of attraction around the desired fixed points (binary strings) of the net. It is known that it is NP-hard to evaluate even the two-step radius of attraction of a recursive neural net. They focus on the radius of direct (one-step) attraction and refer to this as the loading problem. They have both theoretical and computational results on this problem: a proof that the <b>net</b> <b>loading</b> problem can be solved in polynomial time using linear programming techniques. This resolves a standing problem in the complexity of recursive neural networks; an alternate formulation of the <b>net</b> <b>loading</b> problem as a proximity problem in high-dimensional convex geometry; the design and implementation of a hybrid algorithm for the said proximity problem; successful solution of large scale test problems including the optimal solution to a 900 × 900 Hopfield net with approximately $ 4 X 10 ^ 5 $ synaptic weights. It may be noted that the experiments indicate that the radius of direct attraction is actually a very good proxy of the intractable (multi-step) radius of attraction. In all the test problems that they have solved, the synaptic weights obtained as a a solution to the maximum radius of direct attraction also maximize the radius of (multi-step) attractio...|$|E
40|$|The {{continuum}} design {{sensitivity analysis}} (CDSA) {{has been applied}} to the magnetostatic and electrostatic force calculation. This method allows the computation of the <b>net</b> <b>loading</b> force on a body as well as the force distribution {{on the surface of the}} body. An algorithm for force calculation combined with a standard field analysis software package is presented. The efficiency and accuracy of the method is proved through the numerical implementation applied to a set of test examples. In addition, the new approach has several advantages over the traditional methods based on the Maxwell Stress Tensor, such as no air gap or artificial interference with the original model is required. Particularly, the performance analysis of a MEMS micro-mirror using CDSA torque calculation is conducted for the first time...|$|E
40|$|A {{wind tunnel}} study was {{performed}} to examine wind loads on canopies attached to the walls of low-rise buildings. A model of a building with an attached canopy of geometric scale of 1 ∶ 100 1 ∶ 100 was constructed and tested in a simulated open terrain exposure. The attached canopy model was equipped with pressure taps at both upper and lower surfaces to allow for simultaneous monitoring of wind pressures and evaluation of the overall load. A total of 63 different building/attached canopy configurations were tested for 28 wind directions. Pressure and correlation coefficients were generated to provide {{a better understanding of}} how the wind-loading patterns at upper and lower surfaces of the attached canopy contribute to the <b>net</b> <b>loading</b> effect. Current design guidelines and building code and standard provisions are assessed and compared with the experimental results of the present study. The influence of the geometry of each configuration on the experimental net pressure coefficients was assessed and recommendations for design wind load standards and codes of practice are made...|$|E
40|$|This paper {{investigates the}} {{frequency}} control of multi-machine power systems subject to uncertain and dynamic <b>net</b> <b>loads.</b> We propose distributed internal model controllers which coordinate synchronous generators and demand response {{to tackle the}} unpredictable nature of <b>net</b> <b>loads.</b> Frequency stability is formally guaranteed via Lyapunov analysis. Numerical simulations on the IEEE 68 -bus test system demonstrate {{the effectiveness of the}} controllers. Comment: Submitted to the IEEE Transaction on Automatic Contro...|$|R
40|$|Distributed {{renewable}} energy resources have attracted significant attention {{in recent years}} due to the falling cost of the {{renewable energy}} technology, extensive federal and state incentives, and the application in improving load-point reliability. This growing proliferation, however, is changing the traditional consumption load curves by adding considerable levels of variability and further challenging the electricity supply-demand balance. In this paper, the application of microgrids in effectively capturing the distribution network <b>net</b> <b>load</b> variability, caused primarily by the prosumers, is investigated. Microgrids provide a viable and localized solution to this challenge while removing the need for costly investments by the electric utility on reinforcing the existing electricity infrastructure. A flexibility-oriented microgrid optimal scheduling model is proposed and developed to coordinate the microgrid <b>net</b> <b>load</b> with the aggregated consumers/prosumers <b>net</b> <b>load</b> in the distribution network {{with a focus on}} ramping issues. The proposed coordination is performed to capture both inter-hour and intra-hour <b>net</b> <b>load</b> variabilities. Numerical simulations on a test distribution feeder with one microgrid and several consumers and prosumers exhibit the effectiveness of the proposed model. Comment: IEEE Transactions on Power System...|$|R
40|$|Global solar {{photovoltaic}} capacity increased by 35 % from 2013 to 2014, and this upward growth trend {{is likely to}} continue. Power grids must adapt to accommodate increasing shares of renewable energy penetration. The impact of increasing solar penetration is quantified {{in terms of the}} variability and the predictability of <b>net</b> <b>load</b> behavior. As expected, due to variable nature of solar technologies, the predictability of <b>net</b> <b>load</b> decreases with increasing penetration. The need for novel <b>net</b> <b>load</b> forecasting techniques that allow for improved management of grids with high solar penetration is discussed. Integrated <b>net</b> <b>load</b> forecasting methods (solar power forecasts are used as inputs) are recommended for grid operators and utilities. Analysis of forecast performance reveals that the solar variability plays a dominant role in driving the forecasting errors, even more so than the penetration levels. <b>Net</b> <b>load</b> and solar forecast errors are found to be co-integrated, sharing a common stochastic drift. Thus, the solar irradiance time series is sufficient to provide necessary information for the future planning of reserve allocation and storage design for power grids. The benefits of proposed techniques are presented for real- time energy imbalance markets. Design variables regulating the electricity markets and grid timelines govern the system dynamics, which in turn highlight the benefits of forecasting. Increased flexibility of operations at shorter time-scales emerges as a key factor for the reliable and efficient management of power grid...|$|R
40|$|AbstractThis work {{describes}} the conceptual {{design of a}} novel separation process for CO 2 removal from flue gas based on precipitating solvents. The process here described (DECAB) is an enhanced CO 2 absorption based on the Le Chatelier’s principle, which states that reaction equilibrium can be shifted by removing one of the constituents in the reaction. A conceptual design of this process has been developed based on literature data, thermodynamic principles and {{a limited number of}} experiments. As solvent example, the potassium salt of taurine was selected. The strategy followed is based on the compilation and determination of the key properties and parameters that govern the absorption and regeneration of the solvent. Then, the performance of the process is evaluated with the aid of short cut design methods. Results show that the key advantages of this process are environmental friendliness (no emissions to the air) and low energy consumption related to a lower vapor pressure of the solvent and higher <b>net</b> <b>loading</b> than conventional processes. The design developed allows for future economic evaluation and assessment of options that will further lead to benefits over conventional processes...|$|E
40|$|This work {{describes}} the conceptual {{design of a}} novel separation process for CO 2 removal from flue gas based on precipitating solvents. The process here described (DECAB) is an enhanced CO 2 absorption based on the Le Chatelier's principle, which states that reaction equilibrium can be shifted by removing one of the constituents in the reaction. A conceptual design of this process has been developed based on literature data, thermodynamic principles and {{a limited number of}} experiments. As solvent example, the potassium salt of taurine was selected. The strategy followed is based on the compilation and determination of the key properties and parameters that govern the absorption and regeneration of the solvent. Then, the performance of the process is evaluated with the aid of short cut design methods. Results show that the key advantages of this process are environmental friendliness (no emissions to the air) and low energy consumption related to a lower vapor pressure of the solvent and higher <b>net</b> <b>loading</b> than conventional processes. The design developed allows for future economic evaluation and assessment of options that will further lead to benefits over conventional processes. © 2011 Published by Elsevier Ltd...|$|E
40|$|An update is {{presented}} of the atmospheric loadings of 11 organochlorine chemicals, five trace elements and four polynuclear aromatic hydrocarbons (PAHs) to the Great Lakes. Intercomparison of this 1994 estimate {{is made with}} earlier loading estimates made in 1988 and 1992 by Strachan and Eisenreich. The flux calculations include wet deposition, dry deposition and two-film vapour transfer across each of the lakes. Of these processes, confidence is highest for wet deposition estimates and lowest for the gas transfer component. This is unfortunate since gas transfer has been estimated {{to be the most}} important process for the OC chemicals. PCBs, dieldrin, HCB, DDE, phenanthrene and pyrene are currently showing net loss from the lakes to the atmosphere via volatilization. p,p'-DDT is still being loaded into the lakes from the atmosphere. - and-HCHare near equilibrium with the water bodies and show volatilization in the summer and fall for-HCH but net deposition for the rest of the year. Hg assessment for the <b>net</b> <b>loading</b> to Lake Superior is given and points out the importance of each of the atmospheric deposition routes for this trace element. The results taken from the IADN program provide a detailed data set for the interpretation of atmospheric impact on the lakes...|$|E
40|$|Two {{critical}} issues have arisen in transmission expansion planning {{with the rapid}} growth of wind power generation. First, severe power ramping events in daily operation due to the high variability of wind power generation pose great challenges to multi-year planning decision making. Second, the long construction periods of transmission lines {{may not be able to}} keep pace with the fast growing uncertainty due to the increasing integration of renewable energy generation. To address such issues, we propose a comprehensive robust planning model considering different resources, namely, transmission lines, generators, and FACTS devices. Various factors are taken into account, including flexibility requirement, construction period, and cost. We construct the hourly <b>net</b> <b>load</b> ramping uncertainty (HLRU) set to characterize the variation of hourly <b>net</b> <b>load</b> including wind power generation, and the annual <b>net</b> <b>load</b> duration curve uncertainty (LDCU) set for the uncertainty of normal annual <b>net</b> <b>load</b> duration curve. This results in a two-stage robust optimization model with two different types of uncertainty sets, which are decoupled into two different sets of subproblems to make the entire solution process tractable. Numerical simulations with real-world data show that the proposed model and solution method are effective to coordinate different flexible resources, rendering robust expansion planning strategies...|$|R
40|$|In {{spite of}} all {{advantages}} of solar energy, its deployment will significantly change the typical electric load profile, thus necessitating a change in traditional distribution grid management practices. In particular, the <b>net</b> <b>load</b> ramping, created {{as a result of}} simultaneous solar generation drop and load increase at early evening hours, {{is one of the major}} operational issues that needs to be carefully addressed. In this paper, microgrids are utilized to offer a viable and localized solution to this challenge while removing the need for costly investments by the electric utility. In this regard, first the microgrid ramping capability is determined via a min-max optimization, and second, the microgrid optimal scheduling model is developed to coordinate the microgrid <b>net</b> <b>load</b> with the distribution grid <b>net</b> <b>load</b> for addressing the ramping issue. Numerical simulations on a test distribution feeder with one microgrid exhibit the effectiveness of the proposed model. Comment: Accepted to 2016 IEEE PES Innovative Smart Grid Technologies (ISGT), 6 - 9 Sep. 201...|$|R
40|$|This paper {{analyzes}} the e¤ects of an intermittent technology on long-run incentives for investment in non-renewable electricity generation technologies. I …nd {{conditions under which}} supporting an intermittent technology may in fact increase carbon emissions. The variability of load usually determines the long run mix of generating technologies in a competitive electricity market. When there is a signi…cant amount of intermittent production the mix of other generating technologies {{is determined by the}} variability of <b>net</b> <b>load</b> (<b>load</b> <b>net</b> of intermittent output). <b>Net</b> <b>load</b> may be more variable than load itself if the intermittent output is not too positively correlated with load. This increase in variability results in a substitution away from baseload generating technologies towards peaking and intermediate technologies. If peaking and intermediate technologies are more carbon intensive than non-renewable "baseload " technologies, this substitution can more than o¤set the emission bene…ts derived from the output of the renewable technology. ...|$|R
40|$|Durum wheat (Triticum turgidum L. subsp. durum Desf.) Line 149 {{contains}} two novel major genes for excluding Na+ from leaf blades, named Nax 1 and Nax 2. The genes were separated into families containing a single gene and near-isogenic homozygous lines were selected. Lines containing either Nax 1 or Nax 2 had {{lower rates of}} Na+ transport from roots to shoots than their near-isogenic pairs due to lower rates of <b>net</b> <b>loading</b> of the xylem, not to lower rates of net uptake from the soil or higher rates of retranslocation in the phloem. Nax 1 and Nax 2 lines also had higher rates of K+ transport from root to shoot, resulting in an enhanced discrimination of K+ over Na+. Lines containing Nax 1 differed from those containing Nax 2 by unloading Na+ from the xylem as it entered the shoot so that Na+ was retained {{in the base of}} the leaf, leading to a high sheath to blade ratio of Na+ concentration. Gradients in tissue concentrations of Na+ along the leaf suggested that Na+ was continually removed from the xylem. The Nax 2 line did not retain Na+ in the base of the leaf, suggesting that it functioned only in the root. The Nax 2 gene therefore has a similar function to Kna 1 in bread wheat (Triticum aestivum) ...|$|E
40|$|This paper {{analyses}} {{investments in}} green technologies when insurance {{is also an}} option. Green technologies are defined to {{have the power to}} increase productivity and decrease volatility of future revenues. The insurance options involve the scale and coverage either in a yield insurance or in an index insurance. The stochastic process is a combination of insurable stationary short-run process and non-stationary long run process. The optimal decision rules are solved numerically by stochastic dynamic programming. The results suggest that the index insurance maintains market based incentives to invest in green technologies whereas a yield insurance substantially decreases investments, as expected. An actuarially fair yield insurance decreases investments at high productivity firms. By contrast if the insurance premiums are supported {{to the extent that the}} <b>net</b> <b>loading</b> becomes negative, firms with the lowest productivity have strong incentives to collect the benefits of the subsidized insurance rather than invest in higher productivity and lower risks. The yield insurance is the most attractive for low productivity firms while the index insurance is the most attractive for high productivity firms. Nevertheless, the demand for actuarially fair index insurance is reduced also amongst the high productivity firms, when the correlation between the yield and the index falls below 50 %. investment, insurance, uncertainty, dynamic programming, green technology, Agribusiness, Agricultural Finance, Financial Economics, Risk and Uncertainty,...|$|E
40|$|AbstractReductions {{of capital}} cost and energy {{consumption}} {{are the key}} challenges {{for the development of}} amine-based CO 2 capture technology from flue gases. Lipophilic amine solvents exhibit a thermomorphic phase transition upon heating, leading to auto extractive behaviour, which intensifies desorption at temperatures well below the boiling point of the aqueous solutions. Solvent screening experiments in a 100 mL bubble column with CO 2 absorption at a partial pressure of 19. 4 kPa and desorption with N 2 gas stripping or magnetic agitation demonstrate that those solvents have a regeneration temperature of less than 80  °C combined with a high <b>net</b> <b>loading</b> capacity of 3. 34  mol−CO 2 /L. This permits the use of low value and even waste heat for desorption purposes and can thus improves the process economics for CO 2 capture in industrial complexes. The new biphasic solvent system was evaluated in a newly constructed benchmark unit, which is comprised of an absorber column (2. 5 cm in diameter and 145 cm in height) filled with high efficiency structured packing and a 500 mL stirred-tank as regenerator. In order to observe the phase transition phenomenon, the absorber and regenerator were made of glass. Three solvent formulations were tested at various regeneration temperatures ranging from 50 to 95  °C. A maximum 100 % recovery was attained with certain solvent formulations at a regeneration temperature around 90  °C with total gas flow rate of 300 NL/hr (85 % N 2 and 15 % CO 2) ...|$|E
40|$|The California {{generation}} fleet {{manages the}} existing variability and {{uncertainty in the}} demand for electric power (load). When wind power is added, the dispatchable generators manage the variability and uncertainty of the <b>net</b> <b>load</b> (load minus wind power). The variability and uncertainty of the <b>load</b> and the <b>net</b> <b>load</b> are compared when 8790 [*]MW of wind power {{are added to the}} California power system, a level expected when California achieves its 33 % renewable portfolio standard, using a data set of 26, 296 [*]h of synchronous historic load and modeled historic wind power output. Variability was calculated as the rate of change in power generated by wind farms or consumed by the load from 1 [*]h to the next (MW/h). Uncertainty was calculated as the 1 [*]h ahead forecast error [MW] of the wind power or of the load. The data show that wind power adds no additional variability than is already present in the load variability. However, wind power adds additional uncertainty through increased forecast errors in the <b>net</b> <b>load</b> compared with the load. Forecast errors in the <b>net</b> <b>load</b> increase 18. 7 % for negative forecast errors (actual less than forecast) and 5. 4 % for positive forecast errors (actual greater than forecast). The increase in negative forecast errors occurs only during the afternoon hours when negative load forecasts and positive wind forecasts are strongly correlated. Managing the integration of wind power in the California power system should focus on reducing wind power forecast uncertainty for wind ramp ups during the afternoon hours...|$|R
40|$|AbstractThe study {{concerns}} the ramp rate {{problem that is}} associated with the large-scale integration of wind power. As planned 3 GW wind farms are built in Taiwan, the potential variability of the <b>net</b> <b>load</b> must be estimated to determine the flexibility requirement. This work will use numerical weather predictions in Taiwan to estimate total power output from 3 GW wind farms, and analyze the ramping characteristics of the <b>net</b> <b>load</b> using statistical approaches. Its results can provide the operators of Taiwan's power generation system an important reference for determining the required ramping capability in the future...|$|R
40|$|Notwithstanding its {{variability}} {{and limited}} controllability, wind power {{is expected to}} contribute strongly to electricity generation from renewable energy sources in the coming decades. Treating wind power as non-dispatchable by subtracting its output from the original load profile, results in a <b>net</b> <b>load</b> profile, which must be covered by conventional power generation. The screening curve methodology is a first approximation to find the optimal generation technology mix, based on relative cost levels. However, increased variability of the <b>net</b> <b>load</b> profile, due to wind power generation, strongly influences system operation. Therefore a static linear programming investment model is developed to determine the optimal technology mix. This alternative methodology shows a reduced capacity of inflexible generation after including operational constraints to properly account for <b>net</b> <b>load</b> variability. In order to illustrate this methodology, an example is set up, showing the sensitivity with respect to ramp rates of conventional generation, transmission interconnection and energy storage. The comparison of those different sources of system flexibility suggests that energy storage facilities better facilitate the integration of wind power generation. status: publishe...|$|R
40|$|A {{previous}} {{study on the}} benefits of monolithically stacked 3 D-FPGA has estimated a 3. 2 x improvement in logic density, a 1. 7 x improvement in delay, and a 1. 7 x improvement in dynamic power consumption over a baseline 2 D-FPGA with no change in architecture. This paper describes a new routing fabric and shows that a 3 D-FPGA using this fabric can achieve a 3. 3 x improvement in logic density, a 2. 35 x improvement in delay, and a 2. 82 x improvement in dynamic power consumption over the same baseline 2 D-FPGA. The additional improvements in delay and power consumption are achieved by reducing <b>net</b> <b>loading</b> in several ways: (i) Only Single and Double interconnect segments are used. This reduces the total interconnect length used to implement each net. (ii) The routing fabric is hierarchical. Each logic block’s inputs and outputs connect first to local segments. These segments can be then programmably connected to local segments in neighboring routing blocks via programmable buffers and/or to interconnect segments in routing channels via muxes with buffered outputs. (iii) Interconnect segments can be directly connected to form longer segments using programmable buffers without going through routing blocks. (iv) The routing block provides switching capability beyond that of a conventional switch box. A 3 D-FPGA using this new routing fabric can be realized by stacking two configuration memory layers and a switch layer on top of a standard CMOS layer with a total of 12 metal layers interspersed between them. A CAD flow based on VPR with appropriate modifications to the routing graph generation and routing algorithm is developed and used in the performance analysis...|$|E
40|$|Australia {{and most}} other {{countries}} are adopting renewable energy generation as the dominant means of reducing dependence on fossil fuels. This has been made more feasible by the exponential take-up of solar photovoltaic (PV) systems and their concurrent production scale-up and cost decline. Rooftop solar PV, combined with battery storage, seems {{likely to be the}} dominant means of providing household electricity needs. In response to the technical challenges from rooftop PV, network utilities have implemented various low cost options to cope with PV’s impact on network voltages. However, if we want this clean energy technology to fully utilise the available roof space and eventually meet residential electricity needs, additional hardware, control and commercial options will need to be adopted by both network utilities and their customers to overcome the technical barriers, especially voltage rise. This paper presents the authors’ evaluations of options to mitigate voltage rise, including operating solar inverters with reactive power absorption (var absorbing), dependent only on solar power output or operating the solar inverters in a volt–var response mode (voltage droop control) where the inverter adjusts its reactive power (Q) in response to changes in its terminal voltage – Q(V). This paper also considers the fulltime Q(V) option, where an inverter’s reactive power capacity is independent of solar conditions – statcom mode. The network utility option of using line drop compensation (LDC – used on long rural MV feeders) on urban MV feeders during daylight hours is assessed to lessen voltage rise on LV feeders with low <b>net</b> <b>loading</b> or reverse power flow due to high solar PV generation. The paper concludes that a combination of solar inverters performing fast fulltime voltage droop control outside a voltage deadband (statcom mode) and HV/MV substation transformers with slow acting daytime LDC mitigates voltage rise, whilst limiting feeder reactive power requirements...|$|E
40|$|Head {{injuries}} {{in an explosion}} occur {{as a result of}} a sudden pressure changes (e. g. shock-blast) in the atmosphere (primary injury), high velocity impacts of debris (secondary injury) and people being thrown against the solid objects (tertiary injury) in the field. In this thesis, experimental and numerical approaches are used to delineate the intracranial loading mechanics of both primary (blast) and tertiary injuries (blunt). The blast induced head injuries are simulated using a fluid-filled cylinder. This simplified model represents the head-brain complex and the model is subjected to a blast with the Friedlander waveform type of loading. We measured the temporal variations in surface pressure and strain in the cylinder and corresponding fluid pressure. Based on these data, the loading pathways from the external blast to the pressure field in the fluid are identified. The results indicate that the <b>net</b> <b>loading</b> at a given point in the fluid comprises direct transmissive loads and deflection-induced indirect loads. The study also shows that the fluid pressure (analogue of intracranial pressure) increases linearly with increase in reflected blast overpressures (ROP) for a given shell thickness. When the ROP is kept constant, fluid pressure increases linearly with the decrease in shell thickness. For understanding the blunt induced head injuries, the complaint (acrylic gel complex) and rigid (aluminum body) head surrogates with an identical mass are impacted on target surfaces of different stiffnesses. The study indicates that the acceleration field in the gel-filled head surrogate varies from coup to counter-coup region, whereas the field is uniform in the rigid surrogate. The variation in the acceleration field is influenced by the shell deformation that in turn depends on the stiffness of the target surface. Impact studies on the helmet padding currently being used by the US Army are also carried out at different loading conditions. Our results indicate that for a fixed thickness of a foam pad, an increase in the stiffness of the pad will result in the increased absorption of the impact energy. Advisor: Namas Chandr...|$|E
5000|$|Twenty-foot, [...] "heavy tested" [...] {{containers}} {{are available}} for heavy goods such as heavy machinery. These containers allow a maximum weight of 67200 lb, an empty weight of 5290 lb, and a <b>net</b> <b>load</b> of 61910 lb.|$|R
40|$|Abstract — Notwithstanding its {{variability}} {{and limited}} controllability, wind power {{is expected to}} contribute strongly to electricity generation from renewable energy sources in the coming decades. Treating wind power as non-dispatchable by subtracting its output from the original load profile, results in a <b>net</b> <b>load</b> profile, which must be covered by conventional power generation. The screening curve methodology is a first approximation to find the optimal generation technology mix, based on relative cost levels. However, increased variability of the <b>net</b> <b>load</b> profile, due to wind power generation, strongly influences system operation. Therefore a static linear programming investment model is developed to determine the optimal technology mix. This alternative methodology shows a reduced capacity of inflexible generation after including operational constraints to properly account for <b>net</b> <b>load</b> variability. In order to illustrate this methodology, an example is set up, showing the sensitivity with respect to ramp rates of conventional generation, transmission interconnection and energy storage. The comparison of those different sources of system flexibility suggests that energy storage facilities better facilitate the integration of wind power generation. Keywords — Technology mix- wind power – screening curve – variability – wind power curtailment...|$|R
30|$|The {{majority}} {{of differences between}} transducer and known radial axis loads below load magnitudes of 80  N fell within the inter-quartile range for each <b>net</b> <b>load</b> direction. Loads below 80  N outside of this range had load magnitudes of less than 1  N. This result, {{as well as the}} results of the repeatability trials, validate the effectiveness of the interposed transducer device to accurately quantify intra-articular loading of the proximal radius.|$|R
40|$|Nutrient {{budgets of}} agroecosystems are {{constructed}} either (i) {{to increase the}} understanding of nutrient cycling, (ii) as performance indicator and awareness raiser in nutrient management and environmental policy, or (iii) as regulating policy instrument to enforce a certain nutrient management policy in practice. This paper explores nutrient budgeting approaches and summarizes sources of uncertainty associated with these approaches. Possible implications of uncertainties associated with the different methodologies and approaches for nutrient management and environmental policy are discussed. Three types of nutrient budgets have been distinguished, i. e. farm-gate, soil surface and soil systems budgets. A farm-gate budget is the most integrative measure of environmental pressure, and seems most suitable as environmental performance indicator. A soil surface budget is appropriate for estimating the <b>net</b> <b>loading</b> of the soil with nutrients. Soil system budgets account for nutrient inputs and outputs, recycling of nutrients within the system, nutrient loss pathways and changes in soil nutrient pools; {{it is the most}} detailed budget and provides detailed information for nutrient management. Case studies for the dairy farm De Marke indicate that the three budgeting approaches supplement each other. The accuracy and precision of the nutrient budget depend on budgeting approach, data acquisition strategy and type of agroecosystem. There is often a considerable amount of uncertainty in the nutrient budget, due to various possible biases and errors, notably in the partitioning of nutrient losses. Possible sources of biases are personal bias, sampling bias, measurement bias, data manipulation bias and fraud. Sources of errors are sampling and measurement errors. Both biases and errors in nutrient budget estimates may lead to confusion and wrong conclusions. Yet, there is little published evidence that uncertainties are taken into account in decision making. Uncertainties are usually smaller for a farm-gate budget than for a soil surface budget. Therefore, farm-gate budgets are preferred over soil surface budgets as policy instrument. Quantifying uncertainties requires: (a) system identification and analysis, (b) classification of uncertainties, (c) specification of distributions of probabilities of the various sources using Monte Carlo simulation, and (d) monitoring of the nutrient pools, inputs and outputs over time. Analyses of uncertainties in nutrient budgets may provide information about the weakest chain in establishing agri-environmental cause-effect relationships and, therefore, may assist to better focus research efforts. Data for the nitrogen budget of The Netherlands indicate relatively large uncertainties for the items denitrification and leaching, with coefficients of variation > 30 %. In conclusion, {{there is a need for}} standard procedures and guidelines in nutrient budgeting and uncertainty analyses, to improve the confidence in and applicability of nutrient budgets. (C) 2003 Elsevier B. V. All rights reserved...|$|E
40|$|In this paper, a flexibility-oriented {{microgrid}} optimal scheduling {{model is}} proposed to mitigate distribution network <b>net</b> <b>load</b> variability caused by large penetration distributed solar generation. The distributed solar generation variability, {{which is caused}} by increasing adoption of this technology by end-use consumers, is mainly addressed by electric utilities using grid reinforcement. Microgrids, however, provide viable and local solutions to this pressing challenge. The proposed model, which is developed using mixed-integer programming and employs robust optimization, not only can efficiently capture distribution network <b>net</b> <b>load</b> variations, mainly in terms of ramping, but also accounts for possible uncertainties in forecasting. Numerical simulations on a test distribution feeder with one microgrid and several consumers/prosumers indicate {{the effectiveness of the}} proposed model. Comment: Accepted to 2016 North American Power Symposium (NAPS), Denver, CO, 18 - 20 Sep. 201...|$|R
40|$|High <b>net</b> <b>load</b> variability, {{driven by}} high {{penetrations}} {{of wind and}} solar generation, will create challenges for system operators in the future, as installed wind generation capacities increase to unprecedented levels globally. Maintaining system reliability, particularly at shorter time-scales, leads to increased levels of conventional plant starts and ramping, {{and higher levels of}} wind curtailment, with sub-hourly unit commitment and economic dispatch required to capture the increased cycling burden. The role of energy storage in reducing operating costs and enhancing system flexibility is explored, with key storage plant characteristics for balancing at this time-scale identified and discussed in relation to existing and emerging grid-scale storage technologies. Unit dispatches for the additional storage plant with varying characteristics highlight the unsuitability of energy only markets in incen-tivizing suitable levels of flexibility for future systems with high <b>net</b> <b>load</b> variability...|$|R
40|$|We {{consider}} a microgrid with random load realization, stochastic renewable energy production, and an energy storage unit. The grid controller provides the total <b>net</b> <b>load</b> trajectory that the microgrid should {{present to the}} main grid and the microgrid must impose load shedding and renewable energy curtailment if necessary to meet that <b>net</b> <b>load</b> trajectory. The microgrid controller seeks to operate the local energy storage unit {{to minimize the risk}} of load shedding, and renewable energy curtailment over a finite time horizon. We formulate the problem of optimizing the operation of the storage unit as a finite stage dynamic programming problem. We prove that the multi-stage objective function of the energy storage is strictly convex in the state of charge of the battery at each stage. The uniqueness of the optimal decision is proven under some additional assumptions. The optimal strategy is then obtained. The effectiveness of the energy storage in decreasing load shedding and RE curtailment is illustrated in simulations. Comment: 7 page...|$|R
40|$|In {{the last}} years {{important}} improvements are developing in the electrical systems: the process of electrical market liberalization, extended to all the customers, small and residential included, and a strong encouragement towards the energy saving and the installation of small renewable power sources. The regulatory barriers appear insufficient {{to comply with the}} Nearly Zero-Energy Buildings strongly encouraged by European Directives. The actual distribution system for low voltage customers appears inadequate to comply with these improvements. Chaotic phenomena in the existing distribution networks will occur if the penetration of the generators will reach high level of the net energy that saturates the local load exigencies and requires the node <b>net</b> side as <b>load</b> server. The authors suggest the ecodesign of the residential and commercial low voltage distribution as a micro grid that allows to guarantee a reduced impact as ever <b>net</b> <b>load</b> on the <b>net</b> supply at least in a first evolution. Adequate sizing and optimal operation in order to maintain ever <b>net</b> <b>load.</b> Tha paper suggest an evoluted architecture for the micro grid in order to optimize the energy exchanges and to ensure an high level of reliability both for the user and for the distributor. © 2013 IEEE...|$|R
40|$|Unit {{commitment}} (UC) {{seeks the}} most cost effective generator commitment schedule for an {{electric power system}} to meet <b>net</b> <b>load</b> while satisfying the operational constraints on transmission system and generation resources. This problem is challenging {{because of the high}} level of uncertainty in <b>net</b> <b>load</b> which results from load uncertainty and renewable generation uncertainty. This dissertation addresses topics in modeling and computational aspects of considering risk in UC problems. We investigate and compare the performance of stochastic programming and robust optimization as the most widely studied approaches for unit commitment under <b>net</b> <b>load</b> uncertainty. We explicitly account for risk, via conditional value at risk (CVaR), in the stochastic programming objective function and by employing a CVaR-based uncertainty set in the robust optimization formulation. The numerical results indicate that the stochastic program with CVaR evaluated in a low probability tail is able to achieve better cost-risk trade-offs than the robust formulation. The CVaR-based uncertainty set similarly outperforms an uncertainty set based only on ranges. Being able to solve UC problem in short amount of time on a daily basis is one of the challenges power system operators face. Therefore, we also adopt a branch-and-cut approach to improve the solution algorithm for robust optimization formulation of the UC problem. Finally, we present an asymptotic approximation for the CVaR of cost in a power system accounting for generating unit outages. This approximation provides a fast computation of the risk emanating from a set of committed generators due to their imperfect reliability...|$|R
