18|4|Public
2500|$|Robert Harper, one of {{the authors}} of Standard ML, has given his reasons for not using Haskell to teach {{introductory}} programming. Among these are the difficulty of reasoning about resource use with <b>non-strict</b> <b>evaluation,</b> that lazy evaluation complicates the definition of data types and inductive reasoning, and the [...] "inferiority" [...] of Haskell's (old) class system compared to ML's module system.|$|E
5000|$|Under Church encoding, lazy {{evaluation}} of operators maps to <b>non-strict</b> <b>evaluation</b> of functions; for this reason, <b>non-strict</b> <b>evaluation</b> {{is often referred}} to as [...] "lazy". Boolean expressions in many languages use a form of <b>non-strict</b> <b>evaluation</b> called short-circuit evaluation, where evaluation returns as soon as it can be determined that an unambiguous Boolean will result—for example, in a disjunctive expression where true is encountered, or in a conjunctive expression where false is encountered, and so forth. Conditional expressions also usually use {{lazy evaluation}}, where evaluation returns as soon as an unambiguous branch will result.|$|E
50|$|In {{computer}} science, {{graph reduction}} implements an efficient version of <b>non-strict</b> <b>evaluation,</b> an evaluation strategy where the arguments to a function are not immediately evaluated. This form of <b>non-strict</b> <b>evaluation</b> {{is also known}} as lazy evaluation and used in functional programming languages. The technique was first developed by Chris Wadsworth in 1971.|$|E
5000|$|Functional {{languages}} can {{be categorized}} by whether they use strict (eager) or <b>non-strict</b> (lazy) <b>evaluation,</b> concepts that refer to how function arguments are processed when an expression is being evaluated. The technical difference is in the denotational semantics of expressions containing failing or divergent computations. Under strict evaluation, the evaluation of any term containing a failing subterm will itself fail. For example, the expression: ...|$|R
40|$|Context-sensitive {{rewriting}} is a computational {{restriction of}} term rewriting used to model <b>non-strict</b> (lazy) <b>evaluation</b> in functional programming. The {{goal of this}} paper is the study and development of techniques to analyze the termination behavior of context-sensitive rewrite systems. For that purpose, several methods have been proposed in the literature which transform contextsensitive rewrite systems into ordinary rewrite systems such that termination of the transformed ordinary system implies termination of the original contextsensitive system. In this way, the huge variety of existing techniques for termination analysis of ordinary rewriting can be used for context-sensitive rewriting, too. We analyze the existing transformation techniques for proving termination of context-sensitive rewriting and we suggest two new transformations. Our first method is simple, sound, and more powerful than the previously proposed transformations. However, it is not complete, i. e., there are terminating context-sensitive rewrite systems that are transformed into non-terminating term rewrite systems. The second method that we present in this paper is both sound and complete. All these observations also hold for rewriting modulo associativity and commutativity...|$|R
40|$|Motivated by an {{application}} in molecular biology, {{the prediction of}} biopolymer three-dimensional structures, an appropriate polymorphic tree search control structure has been implemented using a functional programming language to evaluate different tree search approaches to solve discrete combinatorial problems in three-dimensional space. The control structure {{is the basis of}} a constraint programming framework implemented in the functional programming paradigm. The <b>non-strict</b> semantic (lazy <b>evaluation)</b> and other features of higher-order functional programming languages have allowed to introduce constraint programming features in the functional programming paradigm. 1 Introduction In the last two years, we have developed a constraint programming (CP) framework using the functional programming (FP) language Miranda 1 [1] to solve discrete combinatorial problems using tree search strategies. Higher-order FP allows for the expression and abstraction of algorithms and data structures. Th [...] ...|$|R
50|$|In {{programming}} language theory, lazy evaluation, or call-by-need is an evaluation strategy which delays {{the evaluation of}} an expression until its value is needed (<b>non-strict</b> <b>evaluation)</b> and which also avoids repeated evaluations (sharing). The sharing can reduce the running time of certain functions by an exponential factor over other <b>non-strict</b> <b>evaluation</b> strategies, such as call-by-name.|$|E
50|$|In <b>non-strict</b> <b>evaluation,</b> {{arguments}} to a function are not evaluated {{unless they are}} actually used {{in the evaluation of}} the function body.|$|E
5000|$|Robert Harper, one of {{the authors}} of Standard ML, has given his reasons for not using Haskell to teach {{introductory}} programming. Among these are the difficulty of reasoning about resource use with <b>non-strict</b> <b>evaluation,</b> that lazy evaluation complicates the definition of data types and inductive reasoning, and the [...] "inferiority" [...] of Haskell's (old) class system compared to ML's module system.|$|E
40|$|EvE is a {{functional}} language {{designed for the}} research on programming parallel computers, especially dataflow machines. The language combines a simple syntax and semantics {{with most of the}} features widely used in functional programming: strong typing, higher order functions, delayed <b>evaluation,</b> <b>non-strict</b> functions and data types. This report defines the syntax of the language and informally describes its semantics on the basis of examples. A major program shows the capabilites of the language. Contents 1 Introduction 5 2 Reference Manual 9 2. 1 Hints for Further Reading : : : : : : : : : : : : : : : : : : : : : : : : : : : : 9 2. 2 Overall Program Structure : : : : : : : : : : : : : : : : : : : : : : : : : : : : 10 2. 3 Type Definitions : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 11 2. 4 Atomic Types : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 13 2. 4. 1 Integers : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 14 2. 4. 2 B [...] ...|$|R
50|$|CAL, and the {{associated}} tools and APIs forming the Quark Framework, was conceived in 1998 within Seagate Software (later Crystal Decisions, now Business Objects) {{as a way to}} enable a common framework for sharing business logic across business intelligence products. A framework was desired that would allow data behaviour to be captured, at all levels of abstraction, and for these components to be composable into the actual data flows that individual products required. In general terms, such a system had to provide a way to express data behaviour declaratively, with universal composition and typing laws. In essence, this places the problem firmly in the domain of functional languages, and the desire to allow machine compositions of functions without incurring increasing efficiency penalties strongly suggested a <b>non-strict</b> <b>evaluation</b> semantic.|$|E
5000|$|In the {{presence}} of lazy, or <b>non-strict</b> <b>evaluation,</b> [...] will immediately return the application of f {{to the head of}} the list and the recursive case of folding over the rest of the list. Thus, if f is able to produce some part of its result without reference to the recursive case on its [...] "right" [...] i.e., in its second argument, and the rest of the result is never demanded, then the recursion will stop (e.g., &thinsp;). This allows right folds to operate on infinite lists. By contrast, [...] will immediately call itself with new parameters until it reaches the end of the list. This tail recursion can be efficiently compiled as a loop, but can't deal with infinite lists at all — it will recurse forever in an infinite loop.|$|E
40|$|<b>Non-strict</b> <b>evaluation</b> {{improves}} the expressive power of functional languages {{at the expense}} of an apparent loss of efficiency. In this paper we give examples of this expressive power, taking as an example an interactive functional program and describing the programming techniques depending on <b>non-strict</b> <b>evaluation</b> which improved its design. Implementation methods for non-strict languages have delivered poor performance precisely when such programming techniques have been used. This need not be the case, however, and {{in the second part of}} the paper we describe Tim, a method of implementing non-strict languages for which the penalty for using lazy evaluation is very small. 1 Introduction Effort in the functional programming community is today divided into two main activities: making efficient implementations of functional languages and exploiting the expressive power of these languages by writing elegant programs. To a large extent these activities are carried out by separate groups of p [...] ...|$|E
40|$|Persimmon is {{a visual}} {{programming}} interface that leverages scikit-learn {{to provide a}} drag and drop interface for developing Machine Learning and Data Mining pipelines. It {{is based on the}} dataflow programming principles, giving the user a functional visual language with a type safety system that checks connections at write time, <b>non-strict</b> <b>evaluation,</b> task parallelization, and execution visualization. It has been evaluated by participants on a three-task form, overall receiving good reviews, being praised by the use of colors to indicate types, consistent design, easy to navigate and shallow learning curve...|$|E
40|$|In {{this article}} we explain two di#erent {{operational}} interpretations of functional programs by two di#erent logics. The programs are simply typed #-terms with pairs, projections, if-then-else, and least fixed point recursion. A logic for call-by-value evaluation and a logic for call-byname evaluation are obtained as as extensions of a system which we call the basic logic of partial terms (BPT). This logic is suitable to prove properties of programs that are valid under both strict and <b>non-strict</b> <b>evaluation.</b> We use methods from denotational semantics {{to show that the}} two extensions of BPT are adequate for call-by-value and call-byname evaluation. Neither the programs nor the logics contain the constant `undefined'. ...|$|E
40|$|Non-strict pure {{functional}} programming often requires redesigning algorithms and data structures {{to work more}} effectively under new constraints of <b>non-strict</b> <b>evaluation</b> and immutable state. Graph drawing algorithms, while numerous and broadly studied, have no presence in the non-strict pure {{functional programming}} model. Additionally, there is currently no freely licensed standalone toolkit used to quantitatively analyze aesthetics of graph drawings. This thesis addresses two previously unexplored questions. Can a force-directed graph drawing algorithm be implemented in a non-strict functional language, such as Haskell, and still be practically usable? Can an easily extensible aesthetic measuring tool be implemented in a language such as Haskell and still be practically usable? The focus of the thesis is on implementing one of the simplest force-directed algorithms, that of Fruchterman and Reingold, and comparing its resulting aesthetics to those of a well-known C++ implementation of the same algorithm...|$|E
40|$|Machine Peter Sestoft Department of Mathematics and Physics Royal Veterinary and Agricultural University Thorvaldsensvej 40, DK- 1871 Frederiksberg C, Denmark E-mail: sestoft@dina. kvl. dk Version 6 of March 13, 1996 Abstract We derive {{a simple}} {{abstract}} machine for lazy {{evaluation of the}} lambda calculus, starting from Launchbury's natural semantics. Lazy evaluation here means <b>non-strict</b> <b>evaluation</b> with sharing of argument evaluation, that is, call-by-need. The machine we derive is a lazy version of Krivine's abstract machine, which was originally designed for call-by-name evaluation. We extend it with datatype constructors and base values, so the final machine implements all dynamic aspects of a lazy functional language. 1 Introduction The development of an efficient abstract machine for lazy evaluation usually starts from either a graph reduction machine or an environment machine. Graph reduction machines perform substitution by rewriting the term graph, that is, the program itself [...] ...|$|E
40|$|AbstractHaskell {{employs a}} melange of strict and <b>non-strict</b> <b>evaluation</b> semantics, hence a Haskell {{verifier}} should {{be capable of}} checking assumptions that program variables {{may or may not}} denote well-defined values. The paper introduces a new strategy, called strength induction, that supports automatic checking of definedness assumptions. Strength induction has been implemented in Plover, an automated property-verifier for Haskell programs that has been under development {{for the past three years}} as a component of the Programatica project. In Programatica, predicate definitions and property assertions written in P-logic, a programming logic for Haskell, can be embedded in the text of a Haskell program module. Properties refine the type system of Haskell but cannot be verified by type-checking alone; a more powerful logical verifier is required. Plover codes the proof rules of P-logic, and additionally, embeds strategies and decision procedures for their application and discharge. It integrates a reduction system that implements a rewriting semantics for Haskell terms with a congruence-closure algorithm that supports reasoning with equality...|$|E
40|$|Context {{analysis}} calculates which {{components of}} arguments to functions may be evaluated eagerly without introducing non-termination. An amount of evaluation recommended by context analysis {{is less than}} the amount of evaluation which will occur at run-time. We may similarly derive contexts which are greater than the amount of run-time evaluation and hence determine which components of an expression are never evaluated and may be disposed of. 1 Introduction One of the major inefficiencies of functional language implementations is due to <b>non-strict</b> <b>evaluation</b> [...] - arguments which are passed lazily are stored with the values of the current variables until they need to be evaluated. The structure which associates an expression with the values of current variables is called a suspension, and it is the creation of this suspension which is wasteful. If we were to evaluate the expression when it is passed as an argument (as happens in common procedural languages), we would not need to create a [...] ...|$|E
40|$|The {{essence of}} data-parallelism is a O(1) map function. A data-parallel {{interpretation}} of map is {{the application of}} a function to every element of a parallel data structure at the same time. This model is at odds with a version of map over lists. Although list map can be interpreted as applying a function to every element of a list, in a non-strict functional language the function applications only occur to those elements of the list required by a subsequent computation. We reconcile these opposing views of map using a three tiered model: (1) a non-strict data-parallel evaluation mechanism based upon `aims' [5] is used that combines the "only evaluate what is required" philosophy of <b>non-strict</b> <b>evaluation,</b> with the "evaluate everything synchronously, and in parallel" mechanism of a data-parallel paradigm; (2) program transformations inspired by the map distributivity law are used to vectorize functional programs that contain map; (3) the resulting vectorized programs are compiled into [...] ...|$|E
40|$|Term graph {{rewriting}} {{provides a}} formalism for implementing term rewriting in an efficient manner by avoiding duplication. Infinitary term rewriting {{has been introduced}} to study infinite term reduction sequences. Such infinite reductions {{can be used to}} model <b>non-strict</b> <b>evaluation.</b> In this paper, we unify term graph rewriting and infinitary term rewriting thereby addressing both components of lazy evaluation: non-strictness and sharing. In contrast to previous attempts to formalise infinitary term graph rewriting, our approach is based on a simple and natural generalisation of the modes of convergence of infinitary term rewriting. We show that this new approach is better suited for infinitary term graph rewriting as it is simpler and more general. The latter is demonstrated by the fact that our notions of convergence give rise to two independent canonical and exhaustive constructions of infinite term graphs from finite term graphs via metric and ideal completion. In addition, we show that our notions of convergence on term graphs are sound w. r. t. the ones employed in infinitary term rewriting in the sense that convergence is preserved by unravelling term graphs to terms. Moreover, the resulting infinitary term graph calculi provide a unified framework for both infinitary term rewriting and term graph rewriting, which makes it possible to study the correspondences between these two worlds more closely...|$|E
40|$|This paper {{surveys and}} {{demonstrates}} {{the power of}} <b>non-strict</b> <b>evaluation</b> in applications executed on distributed architectures. We present the design, implementation, and experimental evaluation of single assignment, incomplete data structures in a distributed memory architecture and Abstract Network Machine (ANM). Incremental Structures (IS), Incremental Structure Software Cache (ISSC), and Dynamic Incremental Structures (DIS) provide non-strict data access and fully asynchronous operations that make them highly suited for the exploitation of fine-grain parallelism in distributed memory systems. We focus on split-phase memory operations and non-strict information processing under a distributed address space to improve the overall system performance. A novel technique of optimization at the communication level is proposed and described. We use partial evaluation of local and remote memory accesses not only to remove much of the excess overhead of message passing, but also {{to reduce the number}} of messages when some information about the input or part of the input is known. We show that split-phase transactions of IS, together with the ability of deferring reads, allow partial evaluation of distributed programs without losing determinacy. Our experimental evaluation indicates that commodity PC clusters with both IS and a caching mechanism, ISSC, are more robust. The system can deliver speedup for both regular and irregular applications. We also show that partial evaluation of memory accesses decreases the traffic in the interconnection network and improves the performance of MPI IS and MPI ISSC applications...|$|E

