0|56|Public
50|$|The AAR's S-918 {{specifications}} outline ten recommended frequencies {{ranging from}} 902.250 to 921.500 MHz, {{depending on the}} location of the reading device (in a yard or trackside), with a <b>nominal</b> <b>transmitting</b> power of 2.0 Watts (measured at the transmitter).|$|R
40|$|DAC sample rates over 1 GHz {{with low}} {{spurious}} levels will enable new applications, particularly in signal simulation test equip-ment. Hundreds of MHz {{are needed in}} radar simulations, while predistortion in communication channels may require five times the <b>nominal</b> <b>transmit</b> bandwidth to cover 5 th-order products, spreading out to over 100 MHz. This circuit was {{designed to meet the}} simultaneous requirements of very wide signal bandwidth and high dynamic range. In Fig. 6. 1. 1, two data ports at 600 MS/s are multiplexed together for a 1200 MS/s data stream. The nine LSBs switch nine unit cur-rent sources to the taps of a differential R/ 2 R ladder. The six MSBs are decoded into 64 current request signals which are pseudo-randomly scrambled for dynamic element matching (DEM) of the 64 MSB unit currents, which are added to the out-put of the R/ 2 R ladder. In optional modes, a single port can accep...|$|R
50|$|United Nations Security Council Resolution 79, adopted on January 17, 1950, having {{received}} {{and the text}} of United Nations General Assembly Resolution 300 concerning the regulation and general reduction of conventional armaments and armed forces, the Council decided to <b>transmit</b> the <b>resolution</b> to the Commission for Conventional Armaments for further study {{in accordance with the}} Commission’s plan of work.|$|R
50|$|In {{a typical}} image {{transmission}} setup, all stationary images are <b>transmitted</b> at full <b>resolution.</b> Moving pictures possess a lower resolution visually, based on complexity of interframe image content.|$|R
40|$|We {{examine the}} {{benefits}} of user cooperation under compute-and-forward. Much like in network coding, receivers in a compute-and-forward network recover finite-field linear combinations of transmitters' messages. Recovery is enabled by linear codes: transmitters map messages to a linear codebook, and receivers attempt to decode the incoming superposition of signals to an integer combination of codewords. However, the achievable computation rates are low if channel gains do not correspond to a suitable linear combination. In response to this challenge, we propose a cooperative approach to compute-and-forward. We devise a lattice-coding approach to block Markov encoding with which we construct a decode-and-forward style computation strategy. Transmitters broadcast lattice codewords, decode each other's messages, and then cooperatively <b>transmit</b> <b>resolution</b> information to aid receivers in decoding the integer combinations. Using our strategy, we show that cooperation offers a significant improvement both in the achievable computation rate and in the diversity-multiplexing tradeoff. Comment: submitted to IEEE Transactions on Information Theor...|$|R
3000|$|... (Joint {{localization}} and <b>transmit</b> ambiguity <b>resolution</b> problem (JLTAP)) In the JLTAP, {{the objective}} is to jointly estimate the Cartesian position of each agent based on the obtained range measurements. Inherently, it is necessary to resolve the TAs, i.e., to find a mapping between each measurement m_I_J→ i^k and the corresponding agent l∈ S(I_J) such that m^k_I_J→ i is a realization of the RV dl→i.|$|R
50|$|For DV-NTSC only 480 {{lines are}} used. The {{digitally}} <b>transmitted</b> horizontal <b>resolution</b> is usually 720 samples (which includes 16 samples for the horizontal sync and horizontal blanking) or 704 visible pixels with an aspect ratio of 4:3 (with vertically rectangular pixels) {{and therefore a}} display resolution of 640 × 480 (VGA); that is standard-definition television (SDTV) with a 4:3 aspect ratio (with square pixels).|$|R
50|$|United Nations Security Council Resolution 74, adopted on September 16, 1949, having {{received}} and examined {{a letter from}} the Chairman of the Atomic Energy Commission <b>transmitting</b> two <b>resolutions,</b> the Council directed the Secretary-General to transmit this letter and the accompanying resolutions, along with records of the discussion of this question in the AEC to the General Assembly and to the Member States of the UN.|$|R
30|$|To address both {{problems}} simultaneously, algorithms {{are needed}} that can jointly resolve the ambiguities and localize the agents. Such algorithms are key enablers {{for the application}} cases described above. In the following, this joint problem is called the joint localization and <b>transmit</b> ambiguity <b>resolution</b> problem (JLTAP). This work presents a thorough analysis of this problem and the derivation of the governing constraints {{as well as the}} formulation of both optimal and sub-optimal solutions.|$|R
5000|$|United Nations Security Council Resolution 284, adopted on July 29, 1970, {{submitted}} {{the following question}} to the International Court of Justice for an advisory opinion: [...] "What are the legal consequences for States of the continued presence of South Africa in Namibia notwithstanding Security Council resolution 276 (1970)?". The Council requested the Secretary-General to <b>transmit</b> the <b>resolution,</b> along with all documents likely to throw light upon to the question to the Court.|$|R
40|$|Abstract — In {{this paper}} {{we present a}} {{multiuser}} MIMO experimental system and the corresponding indoor measurement results that demonstrate power of distributed and coherentlycoordinated downlink transmit antennas using zero-forcing (ZF) beamforming. We present experimental performance under different conditions and communication scenarios. We consider different transmit power levels, number of <b>transmit</b> antennas, <b>resolution</b> of channel state information (CSI) quantizer as well as CSI feedback channel data rates. We demonstrate significant gains even {{in the presence of}} practical impairments. I...|$|R
40|$|This letter {{presents}} an efficient scheme for <b>transmitting</b> high <b>resolution</b> still images {{based on a}} lower resolution CCITT H. 261 codec. Two transmission schemes based on a subsampling approach are studied in terms of image quality, transmission delay, and compatibility with H. 261. It is found that the sequential frame-repeat scheme provides a good compromise among the different criteria. In addition, a simple progressive-reconstruction procedure for the decoded subimages is described. Simulation {{results show that the}} visual effects of such a reconstruction procedure is quite pleasing...|$|R
5000|$|Older {{video game}} {{consoles}} and home computers generated a standard NTSC or PAL signal, but their alternating even/odd interlaced fields were identical in content (or sometimes blanked). The <b>transmitted</b> analog <b>resolution</b> was 486i or 576i {{to be compliant with}} FCC or EBU restrictions, and properly decoded by the television receiver. However the effective bitmapped resolution was only 243p and 288p respectively. [...] The horizontal resolution ranged from 160 pixels to 720 pixels, {{depending on the}} video chip's capabilities (and the skill of the programmer).|$|R
40|$|The {{recently}} finalized High-Efficiency Video Coding (HEVC) {{standard was}} jointly {{developed by the}} ITU-T Video Coding Experts Group (VCEG) and the ISO/IEC Moving Picture Experts Group (MPEG) to improve the compression performance of current video coding standards by 50 %. Especially {{when it comes to}} <b>transmit</b> high <b>resolution</b> video like 4 K over the internet or in broadcast, the 50 % bitrate reduction is essential. This paper shows that real-time decoding of 4 K video with a framelevel parallel decoding approach using four desktop CPU cores is feasible...|$|R
40|$|Quietness and reliability, {{together}} with efficiency and lightweight design, are key requirements {{to compete in}} current mechanical industry. Within the latter, gearboxes {{play an important role}} as the usual choice to transmit mechanical power with high energy density, especially when using cylindrical involute gears. Noise and vibration performance are strongly influenced by tooth microgeometry modifications. Typical modifications are applied along the profile and the lead of the teeth. Profile modifications mainly compensate for tooth deflections; lead modifications mainly compensate for angular misalignments. Both modification types yield optimal performance at a given operating condition (e. g. <b>nominal</b> <b>transmitted</b> torque under ideal alignment), minimizing the meshing excitation. One key operating condition for the gear pair is represented by the instantaneous centre distance between the gears. Centre distance variations affect mainly the pressure angle for the transmitted contact force, the total contact ratio and the active tooth height. Furthermore after a change in centre distance, the contacting surfaces on the tooth flanks shift with respect to each other; this yields a mismatch with respect to the theoretical start for the tooth profile modifications. A precision gear test rig, where operating conditions can be varied and tightly controlled, is used in this paper to evaluate the effects of centre distance variations on the dynamic behaviour of a spur gear pair. The dynamic behaviour is characterized relying on the so-called Static Transmission Error (STE). Spectral analysis of the STE provides an indication of the internal excitation generated by gear meshing. Results show that the STE is sensitive to small changes in centre distance (in the order of 0. 1 % of the nominal value). In particular, it is also observed that the transmitted torque for obtaining minimum STE peak to peak value changes significantly {{as a function of the}} centre distance. status: submitte...|$|R
50|$|In {{satellite}} imaging, {{two types}} of images are available. The panchromatic image acquired by satellites is transmitted with the maximum resolution available and the multispectral data are <b>transmitted</b> with coarser <b>resolution.</b> This will usually be two or four times lower. At the receiver station, the panchromatic image is merged with the multispectral data to convey more information.|$|R
50|$|In {{the typical}} setup, three picture {{elements}} {{on a line}} were actually derived from three separate scans. Stationary images were <b>transmitted</b> at full <b>resolution.</b> However, as MUSE lowers the horizontal and vertical resolution of material that varies greatly from frame to frame, moving images were blurred {{in a manner similar}} to using 16 mm movie film for HDTV projection. In fact, whole-camera pans would result in a loss of 50% of horizontal resolution.|$|R
50|$|In 1933, The Crooked Circle was {{the first}} feature film shown on television. In Los Angeles, the Don Lee Broadcasting System showed the film on March 10, 1933 over their {{experimental}} station W6XAO, <b>transmitting</b> an 80-line <b>resolution</b> mechanical television picture to a half-dozen or fewer receiving sets in the greater Los Angeles area. The film was shown again on June 18, 1940 on the NBC Television experimental station WX2BS, now WNBC-TV in New York City.|$|R
50|$|The {{original}} 4 GB MinoHD {{only has}} a 3.5mm Jack socket (4-way TRRS : Tip-Ring-Ring-Sleeve or A/V : audio-video) to composite (RCA) output for connecting to a television or input into other media viewing monitors. This was a major drawback to quick viewing of videos on a High Definition Television, considering that the produced video is captured in 720p high definition and composite cables are unable to <b>transmit</b> HD <b>resolution</b> to HD capable televisions. This flaw was corrected in the later released 8 GB version that now harnesses a mini HDMI output port, which now gives the option for Mini HDMI to composite (RCA) or component cables as well as Mini HDMI to HDMI allowing videos to be viewed in full HD on an HD capable television directly from the MinoHD camcorder.|$|R
2500|$|The {{practice}} of limiting the time {{available to the}} states to ratify proposed amendments began in 1917 with the Eighteenth Amendment. [...] All amendments proposed since then, {{with the exception of the}} Nineteenth Amendment and the (still pending) Child Labor Amendment, have included a deadline, either in the body of the proposed amendment, or in the joint <b>resolution</b> <b>transmitting</b> it to the states. The ratification deadline [...] "clock" [...] begins running on the day final action is completed in Congress. An amendment may be ratified at any time after final congressional action, even if the states have not yet been officially notified.|$|R
50|$|The {{practice}} of limiting the time {{available to the}} states to ratify proposed amendments began in 1917 with the Eighteenth Amendment. All amendments proposed since then, {{with the exception of the}} Nineteenth Amendment and the Child Labor Amendment, have included a deadline, either in the body of the proposed amendment, or in the joint <b>resolution</b> <b>transmitting</b> it to the states. In its decision the Court concluded that Congress was quite aware in 1924 that - had it desired to do so - it could have imposed a deadline upon the Child Labor Amendment and Congress simply chose not to.|$|R
5000|$|The {{practice}} of limiting the time {{available to the}} states to ratify proposed amendments began in 1917 with the Eighteenth Amendment. All amendments proposed since then, {{with the exception of the}} Nineteenth Amendment and the (still pending) Child Labor Amendment, have included a deadline, either in the body of the proposed amendment, or in the joint <b>resolution</b> <b>transmitting</b> it to the states. The ratification deadline [...] "clock" [...] begins running on the day final action is completed in Congress. An amendment may be ratified at any time after final congressional action, even if the states have not yet been officially notified.|$|R
40|$|Abstract—The Internet {{has become}} an {{indispensable}} component of today’s transacting world. Though a powerful medium, the Internet cannot always quickly transfer web page having image in its current form. Such web pages not only take long time to reach their destination but sometimes completely slow down or block other traffic on the network. To improve response time, {{in this paper we}} propose real time technique as an efficient way out for. We propose to <b>transmit</b> low <b>resolution</b> (LR) image at the transmitter, and show high resolution (HR) image at receiver. At transmitting end, special filter is applied to HR image to yield LR image and high frequency components. These high frequency components are used to build a basis function, which is optimal in size, and is sent along with LR image. HR image is reconstructed using these two at receivers end. For proposed approach the quality of image is better and time for transmission is less than that of conventional approaches. Simulation results show the validity of our approach...|$|R
40|$|Copyright © 2013 Jeremy Straub. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The transmission of scientific data over long distances is required to enable interplanetary science expeditions. Current approaches include transmitting all collected data or <b>transmitting</b> low <b>resolution</b> data to enable ground controller review and selection of data for transmission. Model-based data transmission (MBDT) seeks {{to increase the amount}} of knowl-edge conveyed per unit of data transmitted by comparing high-resolution data collected in situ to a pre-existing (or po-tentially co-transmitted) model. This paper describes the application of MBDT to gravitational data and characterizes its utility and performance. This is performed by applying the MBDT technique to a selection of gravitational data previ-ously collected for the Earth and comparing the transmission requirements to the level required for raw data transmis-sion and non-application-aware compression. Levels of transmission reduction up to 31. 8 % (without the use maxi-mum-error-thresholding) and up to 97. 17 % (with the use of maximum-error-thresholding) resulted. These levels sig-nificantly exceed what is possible with non-application-aware compression...|$|R
40|$|This paper {{develops}} {{a series of}} tests to check whether the New Keynesian nominal rigidity hypothesis on the output-inflation tradeoff withstands new evidence. In so doing, I summarize and evaluate different estimation methods that have been applied in the literature to address this hypothesis. Both cross-country and over-time variations in the output-inflation tradeoff are checked with the tests that differentiate the effects on the tradeoff that are attributable to nominal rigidity (the New Keynesian argument) from those ascribable to variance in nominal growth (the alternative new classical explanation). I find that in line with the New Keynesian hypothesis, nominal rigidity is an important determinant of the tradeoff. Given less rigid prices in high-inflation environments, changes in <b>nominal</b> demand are <b>transmitted</b> to quicker and larger movements in prices and lead to smaller fluctuations in the real economy. The tradeoff between output and inflation is hence smaller. ...|$|R
30|$|As {{mentioned}} above, different slab thicknesses {{are required}} for different regions of wavelengths (channels) scanning and spectral resolution. With the thinner slabs more channels are transmitted, in which the spectral resolution is higher, whereas with thicker slabs less channels are transmitted, but with lower spectral resolution. Thus, there is a tradeoff between thicker and thinner slabs. Whether to use one thickness or another {{is determined by the}} circumstances and objectives of the system. For instance, as shown above, for a full C-band scan with a single transmitted channel a slab of 10  μm is required. However, the slabs at our disposal are of 470 and 50  μm thick. Therefore, in the experimental results shown hereafter, several channels across the C-band are <b>transmitted</b> with spectral <b>resolution</b> of up to 0.07  nm. This resolution can be further increased with better finesse.|$|R
40|$|Nowadays, {{wireless}} communications are becoming {{the center of}} attention. Among the different applications, much advancement {{has been made in}} video streaming over this type of networks. Wireless networks are error-prone networks. Therefore, {{as a result of the}} occurrence of an error, video streams can be incorrectly received and, thus, lost by being discarded by the lower layer entities. Consequently, the decoded video sequence becomes damaged and visual artifacts appear. The scope of this project consists in the implementation and testing of a method in order to increase the quality of H. 264 /AVC Baseline profile encoded video sequences with QCIF (144 x 176 pixels) <b>resolution</b> <b>transmitted</b> over error-prone IP-based channels, concretely UMTS networks. In order to increase the quality of this type of video sequences, the followed strategy lies in the protection of those packets which are estimated to cause higher distortion if they are lost...|$|R
40|$|The {{adaptation}} of proven space probe technology is proposed {{as a means}} of providing a solar activity monitoring platform which could be injected behind the Earth's orbital position to give 3 to 6 days advanced coverage of the solar phenomenon on the backside hemisphere before it rotates into view and affects terrestrial activities. The probe would provide some three dimensional discrimination within the ecliptic latitude. This relatively simple off-Earth probe could provide very high quality data to support the SCADM program, by <b>transmitting</b> both high <b>resolution</b> video data of the solar surface and such measurements of solar activity as particle, X-ray, ultraviolet, and radio emission fluxes. Topics covered include the orbit; constraints on the spacecraft; subsystems and their embodiments; optical imaging sensors and their operation; and the radiation-pressure attitude control system are described. The platform would be capable of mapping active regions on an hourly basis with one arc-second resolution...|$|R
40|$|The JPEG 2000 image {{compression}} standard provides many features to support interactive access to large images. These include efficient lossless and lossy compression, resolution scalability, quality scalability, {{region of interest}} coding and spatial random access. The ISO/IEC JPEG committee {{is in the process}} of finalizing the JPEG 2000 Internet Protocol (JPIP) standard for interacting with JPEG 2000 files. JPIP is tightly coupled to JPEG 2000 and provides a powerful and flexible client-server architecture. By combining JPIP and JPEG 2000 it is possible to store only one compressed file at the server and <b>transmit</b> the <b>resolution,</b> quality, and Window Of Interest (WOI) specified by the client, without having to transmit or decode the entire code-stream. This minimizes server computation, storage and bandwidth. It also reduces the latency for the client. By sending only the data that the client needs the effective compression ratio for client-server applications can be much higher than the file size compression ratio. A prototype JPIP client/server implementation is used to demonstrate resolution scalability, quality scalability and spatial random access of medical images. Efficiency, latency improvements and PSNR quality of the received images are measured as a function of the number of bytes transferred from the server to the client. The choice of JPEG 2000 compression parameters, such as precincts and tiles, and the trade-offs of stateful and stateless sessions are discussed. The inclusion of radiology reports as metadata in image files is also demonstrated...|$|R
30|$|Focussing on {{the video}} coding {{technology}} part, {{it is apparent that}} wireless endoscopy is subjected to severe constraints in terms of available computational capacity and power consumption. Contemporary capsule video chips employ conventional coding schemes operating in a low-complexity, intra-frame mode, i.e., Motion JPEG [34], or even no compression at all. Current capsule endoscopic video systems operate at modest frame resolutions, e.g., 256 × 256 pixels, and frame rates, e.g., 2 - 5 Hz, on a battery life time of approximately 7 h. Future generations of capsule endoscopes are intended to <b>transmit</b> at increased <b>resolution,</b> frame rate, and battery life time and will therefore require efficient video compression at a computational cost as low as possible. In addition, a video coding solution supporting temporal scalability has an attractive edge, enabling increased focus during the relevant stages of the capsules bodily journey. DVC is a strong candidate to fulfil the technical demands imposed by wireless capsule endoscopy, offering low-cost encoding, scalability, and high compression efficiency [10].|$|R
40|$|A sodar {{simulator}} {{capable of}} producing time series data emulating sodar signals has been developed and tested. The atmospheric fields used to populate the sodar simulator are taken from output of a large-eddy simulation code. The characteristics of the sodar (number and zenith angle of beams, beamwidth, <b>transmit</b> frequency, range <b>resolution,</b> etc.) are defined by the user to allow emulation of existing systems. The range of the reflected acoustic signal is calculated based upon a temperature-dependent speed of sound. Realistic acoustic background noise is simulated using filtered white noise. The raw acoustic time series data are processed using a Fourier transform to yield acoustic Doppler spectra, from which the radial velocities are calculated. The design of the simulator allows for the testing of and comparisons between various signal-processing techniques and averaging periods. An example case of feeding the sodar simulator with large-eddy simulation data representative of a developing convective boundary layer is presented and discussed. 1...|$|R
40|$|Abstract. Single-crystalline {{silicon nitride}} {{nanowires}} with high purity, controlled dimensionality {{have been prepared}} via nitriding the nanocrystalline silicon powders at 1300 °C~ 1400 °C. The nanocrystalline silicon powders with average particle size of 33 ~ 76 nm were obtained by cryomilling with the liquid nitrogen as the medium. Scanning electron microscopy, high <b>resolution</b> <b>transmitted</b> electron microscope, X-ray diffraction and UV-lamp microzone Raman spectrometer were used to characterize the as-synthesized nanowires. The effects of nitridation process (reaction temperature and holding time) and the particle size of nanocrystalline silicon powders on the phase and microstructure of the silicon nitride nanowires were analyzed. The obtained {{results show that the}} diameter of the nanowires can be controlled in the range of 38 ~ 85 nm, and the length of 20 µm. The formation of the nanowires {{can be explained by the}} vapor-solid growth mechanism. The room temperature photoluminescence spectra show that the silicon nitride nanowires exhibit a broad visible emission band which ranges from 370 nm to 700 nm...|$|R
40|$|This paper {{addresses}} {{the issue of}} multi-source collaborative object tracking in high-definition (HD) video sequences. Specifically, we propose a new joint tracking paradigm for the multiple stream electronic pan-tilt-zoom (EPTZ) cameras. These cameras are capable of <b>transmitting</b> a low <b>resolution</b> thumbnail (LRT) image of the whole field of view {{as well as a}} high-resolution cropped (HRC) image for the target region. We exploit this functionality to perform joint tracking in both low resolution image of the whole field of view as well as high resolution image of the moving target. Our system detects objects of interest in the LRT image by background subtraction and tracks them using iterative coupled refinement in both LRT and HRC images. We compared the performance of our joint tracking system with that of tracking only in the HD mode. The results of our experiments show improved performance in terms of higher frame rates and better localization. Keywords: Collaborative tracking, EPTZ tracking, Mean-shift analysis 1...|$|R
50|$|On September 19, 2008, SkyCable {{initiated}} the pay-per-view {{broadcast of the}} 2008 Ryder Cup golf tournament in high-definition (HD). It is <b>transmitted</b> in 1080i <b>resolution</b> and paves {{the way for the}} Philippines to convey the first HD signal. In July 2009, Skycable also commenced a locally produced HD program through, Balls HD, the collegiate basketball tournament—University Athletic Association of the Philippines and the National Collegiate Athletic Association. At present, SkyCable offers over 20 HD channels accessible through separate payment. Lineup consists of ABS-CBN HD, ABS-CBN Sports + Action HD, ANC HD, Discovery HD World, History HD, National Geographic Channel HD, HBO HD, NBA Premium TV HD, Fox Movies Premium HD, Fox Crime HD, Comedy Central HD, Fox Sports 3 HD, HBO Hits HD, Fox HD, MTV Live HD, Fox Family Movies HD, STAR World HD, ASN HD, Cartoon Network HD, Outdoor Channel HD, Fashion TV HD, Freeview Channel HD, AXN HD, Disney Channel HD, Fox Sports HD, and the Fox Sports 2 HD.|$|R
5000|$|MUSE had a four-field dot-interlacing cycle, {{meaning it}} took four fields to {{complete}} a single MUSE frame. Thus, stationary images were <b>transmitted</b> at full <b>resolution.</b> However, as MUSE lowers the horizontal and vertical resolution of material that varies greatly from frame to frame, moving images were blurred. Because MUSE used motion-compensation, whole camera pans maintained full resolution, but individual moving elements could be reduced to {{only a quarter of}} the full frame resolution. Because the mix between motion and non-motion was encoded on a pixel-by-pixel basis, it wasn't as visible as most would think. Later, NHK came up with backwards compatible methods of MUSE encoding/decoding that greatly increased resolution in moving areas of the image as well as increasing the chroma resolution during motion. This so-called MUSE-III system was used for broadcasts starting in 1995 and a very few of the last Hi-Vision MUSE LaserDiscs used it ("The River" [...] is one Hi-Vision LD that used it).|$|R
40|$|Part 1 : Traffic Engineering and Quality-of-ServiceInternational audienceThe {{future of}} digital video is envisioned {{to have an}} {{increase}} in both resolution and interactivity. New resolutions like 8 k UHDTV are up to 16 times as big in number of pixels compared to current HD video. Interactivity includes the possibility to zoom and pan around in video. We examine Tiled HTTP Adaptive Streaming (TAS) as a technique for supporting these trends and allowing them to be implemented on conventional Internet infrastructure. In this article, we propose three tile selection algorithms, for different use cases (e. g., zooming, panning). A performance evaluation of these algorithms on a TAS testbed, shows that they lead to better bandwidth utilization, higher static Region of Interest (ROI) video quality and higher video quality while manipulating the ROI. We show that we can <b>transmit</b> video at <b>resolutions</b> up to four times larger than existing algorithms during bandwidth drops, which results in a higher quality viewing experience. We can also increase the video quality by up to 40 percent in interactive video, during panning or zooming...|$|R
