94|24|Public
25|$|This random {{variable}} has a noncentral t-distribution with <b>noncentrality</b> <b>parameter</b> μ. This distribution {{is important in}} studies {{of the power of}} Student's t-test.|$|E
2500|$|... is {{sometimes}} called the <b>noncentrality</b> <b>parameter.</b> Note that some references define [...] in other ways, such as half of the above sum, or its square root.|$|E
5000|$|... is a noncentral t-distributed random {{variable}} with ν {{degrees of freedom}} and <b>noncentrality</b> <b>parameter</b> μ. Note that the <b>noncentrality</b> <b>parameter</b> may be negative.|$|E
5000|$|<b>Noncentrality</b> <b>parameters</b> {{are used}} in the {{following}} distributions: ...|$|R
5000|$|... #Subtitle level 2: Confidence {{intervals}} {{by means}} of <b>noncentrality</b> <b>parameters</b> ...|$|R
40|$|The {{purpose of}} this paper is to propose a method for {{estimating}} the <b>noncentrality</b> <b>parameters</b> of the F distribution involved in testing hypotheses about Î² 1 when there is no information about X 2 Î² 2. The estimated <b>noncentrality</b> <b>parameters</b> can be used to approximate the true size of the tests. Further uses of the estimates include choosing the most suitable proxies for X 2 and ranking competing models according to their proximity to the true model. Our theoretical results are supported by a suitably designed Monte Carlo experiment...|$|R
5000|$|The t-test {{for a pair}} of {{independent}} groups is a special case of one-way ANOVA. Note that the <b>noncentrality</b> <b>parameter</b> [...] of F is not comparable to the <b>noncentrality</b> <b>parameter</b> [...] of the corresponding t. Actually, , and [...]|$|E
50|$|If T is noncentral t-distributed with ν {{degrees of}} freedom and <b>noncentrality</b> <b>parameter</b> μ and F = T2, then F has a noncentral F-distribution with 1 {{numerator}} degree of freedom, ν denominator {{degrees of freedom}}, and <b>noncentrality</b> <b>parameter</b> μ2.|$|E
50|$|In particular, {{the mode}} always {{has the same}} sign as the <b>noncentrality</b> <b>parameter</b> μ. Moreover, the {{negative}} of the mode is exactly the mode for a noncentral t-distribution with {{the same number of}} degrees of freedom ν but <b>noncentrality</b> <b>parameter</b> −μ.|$|E
40|$|A {{relationship}} between the multivariate and univariate <b>noncentrality</b> <b>parameters</b> in repeated measures designs was developed {{for the purpose of}} assessing the relative power of the univariate and multivariate approaches. An application is provided examining the use of repeated measures designs to evaluate student achievement in a K- 12 school syste...|$|R
40|$|We use {{asymptotic}} linearity {{to derive}} confidence intervals for large <b>noncentrality</b> <b>parameters.</b> These results {{enable us to}} measure relevance of effects and interactions in multifactors models when we get highly statistically significant the values of F tests statistics. We show how to use our approach by considering two sets of data as application examples...|$|R
40|$|Description This package {{implements}} method(s) to (approximately unbiasedly) {{estimate the}} proportion of true null hypotheses, i. e., the pi 0, when {{a very large number}} of hypotheses are simultaneously tested, especially for the purpose of (local) false discovery rate control for microarray data. It also contains functions to estimate the distribution of <b>noncentrality</b> <b>parameters</b> from a large number of parametric tests...|$|R
50|$|When the {{denominator}} <b>noncentrality</b> <b>parameter</b> of a doubly noncentral t-distribution is zero, then {{it becomes}} a noncentral t-distribution.|$|E
5000|$|If [...] then [...] has a noncentral chi {{distribution}} with two {{degrees of freedom}} and <b>noncentrality</b> <b>parameter</b> [...]|$|E
5000|$|The {{cumulative}} distribution function of noncentral t-distribution with ν degrees of freedom and <b>noncentrality</b> <b>parameter</b> μ can be expressed as ...|$|E
5000|$|Confidence {{intervals}} of standardized effect sizes, especially Cohen's [...] and , {{rely on the}} calculation of confidence {{intervals of}} <b>noncentrality</b> <b>parameters</b> (ncp). A common approach to construct the confidence interval of ncp {{is to find the}} critical ncp values to fit the observed statistic to tail quantiles α/2 and (1 − α/2). The SAS and R-package MBESS provides functions to find critical values of ncp.|$|R
5000|$|<b>Noncentrality</b> <b>{{parameters}}</b> are {{parameters of}} families of probability distributions {{that are related}} to other [...] "central" [...] families of distributions. Whereas the central distribution describes how a test statistic is distributed when the difference tested is null, noncentral distributions describe the distribution of a test statistic when the null is false (alternative hypothesis). This leads to their use in statistics, especially calculating statistical power.|$|R
40|$|AbstractLet Y 1,…, Yn be {{independent}} identically distributed random variables with distribution function F(x, θ), θ = (θ′ 1, θ′ 2), where θi (i = 1, 2) is a vector of pi components, p = p 1 + p 2 and for ∀θ∈I, an open interval in Rp, F(x, θ) is continuous. In {{the present paper}} the author shows that the asymptotic distribution of modified Cramér-Smirnov statistic under Hn: θ 1 = θ 10 + n− 1 / 2 γ, θ 2 unspecified, where γ is a given vector independent of n, is the distribution of a sum of weighted noncentral χ 12 variables whose weights are eigenvalues of a covariance function of a Gaussian process and <b>noncentrality</b> <b>parameters</b> are Fourier coefficients of the mean function of the Gaussian process. Further, the author exploits the special form of the covariance function by using perturbation theory to obtain the <b>noncentrality</b> <b>parameters</b> and the weights. The technique is applicable to other goodness-of-fit statistics such as U 2 [G. S. Watson, Biometrika 48 (1961), 109 – 114]...|$|R
5000|$|If [...] is a noncentral chi-squared random {{variable}} with <b>noncentrality</b> <b>parameter</b> [...] and [...] {{degrees of freedom}}, and [...] is a chi-squared {{random variable}} with [...] degrees of freedom that is statistically independent of , thenis a noncentral F-distributed random variable.The probability density function (pdf) for the noncentral F-distribution iswhen [...] and zero otherwise.The degrees of freedom [...] and [...] are positive. The <b>noncentrality</b> <b>parameter</b> [...] is nonnegative.The term [...] is the beta function, where ...|$|E
50|$|The <b>noncentrality</b> <b>parameter</b> of the {{t-distribution}} may {{be negative}} or positive while the noncentral {{parameters of the}} other three distributions must be greater than zero.|$|E
50|$|The {{probability}} density function (pdf) for the noncentral t-distribution with ν > 0 {{degrees of freedom}} and <b>noncentrality</b> <b>parameter</b> μ can be expressed in several forms.|$|E
40|$|AbstractAsymptotic expansions, {{valid for}} large error degrees of freedom, are {{given for the}} multivariate noncentral F {{distribution}} and for the distribution of latent roots in MANOVA and discriminant analysis. The asymptotic results are {{expressed in terms of}} elementary functions which are easy to compute and the results of some numerical work are included. The Bartlett test of the null hypothesis that some of the <b>noncentrality</b> <b>parameters</b> in discriminant analysis are zero is also briefly discussed...|$|R
5000|$|In general, <b>noncentrality</b> <b>parameters</b> {{occur in}} {{distributions}} that are transformations {{of a normal}} distribution. The [...] "central" [...] versions are derived from normal distributions that have a mean of zero; the noncentral versions generalize to arbitrary means. For example, the standard (central) chi-squared distribution is the distribution of a sum of squared independent standard normal distributions, i.e., normal distributions with mean 0, variance 1. The noncentral chi-squared distribution generalizes this to normal distributions with arbitrary mean and variance.|$|R
40|$|Let Y 1, [...] ., Yn be {{independent}} identically distributed random variables with distribution function F(x, [theta]), [theta] = ([theta]' 1, [theta]' 2), where [theta]i (i = 1, 2) is a vector of pi components, p = p 1 + p 2 and for [for all][theta][set membership, variant]I, an open interval in p, F(x, [theta]) is continuous. In {{the present paper}} the author shows that the asymptotic distribution of modified Cramér-Smirnov statistic under Hn: [theta] 1 = [theta] 10 + n- 1 / 2 [gamma], [theta] 2 unspecified, where [gamma] is a given vector independent of n, is the distribution of a sum of weighted noncentral [chi] 12 variables whose weights are eigenvalues of a covariance function of a Gaussian process and <b>noncentrality</b> <b>parameters</b> are Fourier coefficients of the mean function of the Gaussian process. Further, the author exploits the special form of the covariance function by using perturbation theory to obtain the <b>noncentrality</b> <b>parameters</b> and the weights. The technique is applicable to other goodness-of-fit statistics such as U 2 [G. S. Watson, Biometrika 48 (1961), 109 - 114]. modified Cramer-Smirnov statistics noncentral [chi] 2 Fourier coefficients perturbation theory goodness-of-fit statistics...|$|R
5000|$|... is {{sometimes}} called the <b>noncentrality</b> <b>parameter.</b> Note that some references define [...] in other ways, such as half of the above sum, or its square root.|$|E
50|$|If T is noncentral t-distributed with ν {{degrees of}} freedom and <b>noncentrality</b> <b>parameter</b> μ and , then Z has a normal {{distribution}} with mean μ and unit variance.|$|E
5000|$|For {{procedures}} {{where the}} matrix [...] is symmetric and idempotent, and the errors are Gaussian with covariance matrix , [...] has a chi-squared distribution with [...] {{degrees of freedom}} and <b>noncentrality</b> <b>parameter</b> , where ...|$|E
40|$|Asymptotic expansions, {{valid for}} large error degrees of freedom, are {{given for the}} multivariate noncentral F {{distribution}} and for the distribution of latent roots in MANOVA and discriminant analysis. The asymptotic results are {{expressed in terms of}} elementary functions which are easy to compute and the results of some numerical work are included. The Bartlett test of the null hypothesis that some of the <b>noncentrality</b> <b>parameters</b> in discriminant analysis are zero is also briefly discussed. MANOVA and discriminant analysis latent roots asymptotic distributions...|$|R
40|$|AbstractWe {{show that}} if ϕ is an {{increasing}} convex function of the eigenvalues of a symmetric matrix argument, then Y→ϕ((YY′) 12) is a convex function. This has the consequence for the {{multivariate analysis of variance}} that statistical tests for μ= 0 which are defined by increasing convex functions of the square roots of the eigenvalues of (ZZ′) − 1 YY′ have acceptance regions which are convex in Y for fixed Z. Tests of this form have some good properties, including unbiasedness and power functions which are increasing in the <b>noncentrality</b> <b>parameters...</b>|$|R
40|$|This paper proposes the bivariate noncentral {{chi-square}} (BNC) distribution by {{compounding the}} Poisson probabilities with the bivariate central chi-square distribution. The probability density and cumulative distribution {{functions of the}} joint distribution of the two noncentral chi-square variables are derived for arbitrary values of the correlation coefficient, degrees of freedom(s), and <b>noncentrality</b> <b>parameters.</b> Computational procedures to calculate the upper tail probabilities {{as well as the}} percentile points for selected values of the parameters, for both equal and unequal degrees of freedom, are discussed. The graphical representation of the distribution for different values of the parameters are provided. Some applications of the distribution are outlined. ...|$|R
5000|$|... where [...] is a noncentral chi-squared random {{variable}} with {{degrees of freedom}} m and <b>noncentrality</b> <b>parameter</b> , and [...] is a central chi-squared {{random variable}} with degrees of freedom n, independent of [...]In this case, ...|$|E
50|$|If X {{follows a}} noncentral chi {{distribution}} with 1 {{degree of freedom}} and <b>noncentrality</b> <b>parameter</b> λ, then σX follows a folded normal distribution whose parameters are equal to σλ and σ2 for any value of σ.|$|E
50|$|If the <b>noncentrality</b> <b>parameter</b> of a {{distribution}} is zero, the distribution {{is identical to}} {{a distribution}} in the central family. For example, the Student's t-distribution is the central family of distributions for the noncentral t-distribution family.|$|E
40|$|We give {{a unified}} {{treatment}} of the statistical foundations of population based association mapping and of family based linkage mapping of quantitative traits in humans. A central ingredient in the unification involves the efficient score statistic. The discussion focuses on generalized linear models with an additional illustration of the Cox (proportional hazards) model for age of onset data. We give analytic expressions for <b>noncentrality</b> <b>parameters</b> and show how they give qualitative insight into the loss of power that occurs if the scientist‘s assumed genetic model differs from nature's “true” genetic model. Issues to be studied in detail in the future development of this approach are discussed...|$|R
40|$|The power {{function}} of the largest root test of normal multi'variate linear hyPOthesis or of independence between two sets of variates involves, in each case, aside from the degrees of freedom, certain nonnegative, <b>noncentrality</b> <b>parameters.</b> This report supplies a relatively simple and elegant proof that the {{power function}} monotonically increases as each parameter, separately, increases- a result that was conjectured and proved (but not pub 1 tshed) {{by one of the}} authors several years ago by a very lengthy and laborious method. ~ualified requestors may obtain copies of this report from the ASmlA Document Service Center, Arlington Hall Station, Arli~on 12, Virginia. Department of Defense contractors must be established for ASTIA services, or have their "need-to-know " certified by the cognizant military agency of their project or contract...|$|R
40|$|This paper {{develops}} an asymptotic {{theory for}} integrated and near-integrated time series whose range is constrained in some ways. Such a framework arises when integration and cointegration analysis {{are applied to}} persistent series which are bounded either by construction or because {{they are subject to}} control. The asymptotic properties of some commonly used integration tests are discussed; the bounded unit root distribution is introduced to describe the limiting distribution of the first-order autoregressive coefficient of a random walk under range constraints. The theoretical results show that the presence of such constraints can lead to drastically different asymptotics. Since deviations from the standard unit root theory are measured through <b>noncentrality</b> <b>parameters,</b> simple measures of the impact of range constraints on the asymptotic distributions are obtained. Finally, the proposed asymptotic framework provides an extremely adequate approximation of the finite sample properties of the unit root statistics under range constraints. ...|$|R
