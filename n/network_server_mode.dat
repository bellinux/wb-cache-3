0|2748|Public
5000|$|<b>Network</b> port (<b>server</b> <b>mode)</b> - the PBX {{connects to}} another {{application}} or buffer.|$|R
40|$|This paper {{presents}} the Vartalaap system developed at IIT, Bombay. Vartalaap is an hierarchical distributed system for multicast communication over a network, implemented in a hardware-independent fashion. The multicast is achieved {{without resorting to}} unnecessary broadcasting of messages over the network. Issues covered in this paper include the primitives for multicast, the multicast model and the system architecture. We discuss the implementation of Vartalaap and compare it with some other systems. We conclude with a discussion on {{the limitations of the}} current implementation and directions for future work. key words : Multicast communication Communication primitives Computer <b>networks</b> Client [...] <b>server</b> <b>mode...</b>|$|R
50|$|The Derby <b>network</b> <b>server</b> {{increases}} {{the reach of}} the Derby database engine by providing traditional client <b>server</b> functionality. The <b>network</b> <b>server</b> allows clients to connect over TCP/IP using the standard DRDA protocol. The <b>network</b> <b>server</b> allows the Derby engine to support networked JDBC, ODBC/CLI, Perl and PHP.|$|R
5000|$|... zeoraid - An {{open source}} {{solution}} {{that provides a}} proxy <b>Network</b> <b>Server</b> that distributes object stores and recovery across a series of <b>Network</b> <b>Servers.</b>|$|R
40|$|A {{cloud server}} {{connection}} {{consists of an}} occurrence of shared database architecture server {{and at least one}} front-end <b>network</b> <b>server.</b> When users request data from cloud server, the cloud application, running on the front-end <b>network</b> <b>server,</b> retrieves all the relevant data from backend to handle the manipulator request. Although this guarantees that all manipulators always see and find out the most up-to-date data, he has the weakness of needful a sub-optimal quantity of statistics traffic betweencloud server and the front-end <b>network</b> <b>servers</b> and consequently hypothetically sub-optimal performance and responsiveness to user requests, in addition to imperfect scalability of the hardware to achieve higher throughput heights. The cloud server uses caches built information retrieval and caches run on the front-end <b>network</b> <b>servers</b> of your cloud server farm. Every cache upholds reproductions of data nearby on the front-end <b>network</b> <b>server</b> so that cloud manipulator supplies can be checked by using the cached data and wherever applicable, circumventing unnecessary circulation amid backend server and the front-end <b>network</b> <b>servers</b> and CPU data management on the front-end <b>network</b> <b>server,</b> thus refining performance and scalability...|$|R
30|$|Network server: the LoRa <b>network</b> <b>server</b> {{manages the}} <b>network.</b> The <b>network</b> <b>server</b> acts to {{eliminate}} duplicate packets, schedules acknowledgment, and adapts data rates (adaptive data rate scheme). The {{communication between the}} LoRa gateway and the <b>network</b> <b>server</b> is IP-based, and the underlying carrier networks can be wired or wireless, Ethernet or 3 GPP cellular, public or private networks.|$|R
50|$|A ChatScript engine can run {{in local}} or <b>server</b> <b>mode.</b>|$|R
40|$|Abstract — Design {{patterns}} are generic solutions to recurring software design problems. The Correct Object-Oriented Patternbased Parallel Programming System (CO 2 P 3 S) uses design pattern templates to generate code for design patterns. CO 2 P 3 S {{has been used}} to generate small parallel and sequential applications. This research evaluates the utility and performance of CO 2 P 3 S on larger <b>network</b> <b>server</b> applications. The <b>Network</b> <b>Server</b> design pattern template is introduced, which significantly eases the complexities involved in <b>network</b> <b>server</b> application development. The <b>Network</b> <b>Server</b> is highly configurable and suitable {{for the construction of a}} large variety of <b>network</b> <b>server</b> applications, with a diverse range of functionality and performance requirements. In this paper we highlight a generated Web server with performance comparable to Apache. Index Terms—network servers, parallel programming, programming environments...|$|R
40|$|This article {{suggests}} {{the creation of}} transport wireless network. For system behavior analysis in transitive non-stationary operating mode we will use diffusion approximation method. In the given work <b>server</b> non-stationary operating <b>mode</b> at near to self-similar query stream influence is considered with the main accent on server relaxation time. In this case the model for research is cyclic closed network model consisting of terminal system and a <b>network</b> <b>server</b> which common solution has been developed by H. Kobayashi [1]...|$|R
30|$|To {{measure the}} {{achieved}} throughput of each wireless station, the Iperf measurement tool version 1.7. 0 is used. Iperf can {{run in the}} client or <b>server</b> <b>modes.</b> Therefore in our experiments, senders of any flow run iperf in the client mode, while the receivers run in the <b>server</b> <b>mode.</b> Iperf <b>servers</b> are configured to report the achieved throughput for every second.|$|R
50|$|As a <b>networked</b> <b>server.</b>|$|R
5000|$|On {{a single}} <b>server</b> <b>mode</b> H-Sphere consumes more server {{resources}} than other major single server control panels.|$|R
5000|$|Yate/YateClient {{supports}} Jingle in both {{client and}} <b>server</b> <b>mode,</b> audio and file transfer, also call transfer and DTMF.|$|R
5000|$|... "Queuing Model Based <b>Network</b> <b>Server</b> Performance Control" [...] (2002) ...|$|R
5000|$|... #Subtitle level 2: Progression to the Corporate <b>Network</b> <b>Server</b> (CNS) ...|$|R
5000|$|The Apple <b>Network</b> <b>Server</b> (ANS) was a {{short-lived}} line of PowerPC-based server computers manufactured by Apple Computer from February 1996 to April 1997, {{when it was}} discontinued due to poor sales. It was codenamed [...] "Shiner" [...] and originally consisted of two models, the <b>Network</b> <b>Server</b> 500/132 ("Shiner LE", i.e., [...] "low-end") and the <b>Network</b> <b>Server</b> 700/150 ("Shiner HE", i.e., [...] "high-end"), which got a companion model, the <b>Network</b> <b>Server</b> 700/200 (also [...] "Shiner HE") with a faster CPU in November 1996. They are {{not a part of}} the Apple Macintosh line of computers; they were designed to run IBM's AIX operating system and their ROM specifically prevented booting the classic Mac OS. This makes them the last non-Macintosh desktop computers made by Apple to date. The 500/132, 700/150, and 700/200 sold in the U.S. market for $11,000, $15,000 and $19,000, respectively.|$|R
5000|$|... rdate, a {{tool for}} {{querying}} the current time from a <b>network</b> <b>server</b> ...|$|R
5000|$|There {{is no need}} of <b>network</b> <b>server</b> {{to control}} the {{connectivity}} between workstations.|$|R
5000|$|An {{infrastructure}} landscape {{consists of}} several Working Areas (Storage, <b>Network,</b> <b>Server,</b> Middleware, Client Realm).|$|R
5000|$|Windows agent, {{which is}} {{provided}} for Microsoft Windows environments. The main application {{needs to be}} installed and configured for <b>server</b> <b>mode</b> to support the Windows Agent.|$|R
50|$|The time {{reference}} {{used by a}} time server could be another time <b>server</b> on the <b>network</b> or the Internet, a connected radio clock or an atomic clock. The most common true time source is a GPS or GPS master clock. Time servers are sometimes multi-purpose <b>network</b> <b>servers,</b> dedicated <b>network</b> <b>servers,</b> or dedicated devices. All a dedicated time server does is provide accurate time.|$|R
40|$|Efficiency and {{portability}} are conflicting {{objectives for}} clusterbased <b>network</b> <b>servers</b> that distribute the clients' requests across the cluster {{based on the}} actual content requested. Our work {{is based on the}} observation that this efficiency vs. portability tradeoff has not been fully evaluated in the literature. To fill this gap, in this paper we use modeling and experimentation to study this tradeoff {{in the context of an}} interesting class of content-based <b>network</b> <b>servers,</b> the locality conscious servers, under different inter-node communication subsystems. Based on our results, our main conclusion is that portability should be promoted in cluster-based <b>network</b> <b>servers</b> with low processor overhead, given its relatively low cost (# 16 %) in terms of throughput performance. For clusters with high processor overhead communication, efficiency should be the overriding concern, as the cost of portability can be very high (as high as 107 % on 96 nodes). We also conclude that user-level communication can be useful even for non-scientific applications such as <b>network</b> <b>servers...</b>|$|R
50|$|Currently all <b>network</b> <b>servers</b> support SSL connection. There are {{experimental}} servers {{that support}} UTF-8 encoding.|$|R
5000|$|PXELINUX, {{used for}} booting from a <b>network</b> <b>server</b> using the Preboot Execution Environment (PXE) system.|$|R
5000|$|Troubleshooting {{network devices}} that use <b>network</b> <b>servers</b> (send a packet and then analyze the response) ...|$|R
25|$|Enterprise {{infrastructure}} software {{supports the}} enterprise's software systems. Examples include databases, email <b>servers,</b> and <b>network</b> <b>servers.</b>|$|R
40|$|<b>Network</b> <b>servers</b> make special {{demands that}} {{other types of}} {{applications}} may not make on memory allocators. We describe a simple malloc() microbenchmark suite that tests the ability of malloc() to divide its work efficiently among multiple threads and processors. The purpose of this suite {{is to determine the}} suitability of an operating system's heap allocator for use with <b>network</b> <b>servers</b> running in an SMP environment...|$|R
50|$|Many {{applications}} and network equipment deployments require their network locations to be reachable from outside their local networks, following the originally envisioned model of IP end-to-end connectivity across the Internet, {{so they can}} operate as <b>network</b> <b>servers</b> and accept connections from remote clients. An example of such equipment is an IP camera, which includes a <b>network</b> <b>server</b> that provides remote surveillance over IP networks.|$|R
50|$|The {{name space}} is {{managed by the}} <b>network</b> <b>server,</b> which is started by the I/O server once the nucleus is booted on its first {{attached}} node. The <b>network</b> <b>server</b> uses a provided network map to allocate processor names and initialise drivers for hardware devices at specific nodes in the network. The kernel includes a name resolver, and manages a local cache of routes to previously resolved names.|$|R
40|$|A {{distributed}} system consists of independent workstations connected usually {{by a local}} area network. Due to {{the growing popularity of}} the Internet, data centers, <b>network</b> <b>servers</b> are anticipated to be the bottleneck in hosting network-based services, even though the network bandwidth continues to increase faster than the server capacity. It has been observed that <b>network</b> <b>servers</b> contribute to approximately 40 percent of the overall delay, and this delay is likely to grow with the increasing use of dynamic web contents. <b>Network</b> <b>server</b> provides an efficient way to distribute their work with the sub-servers which is also known as proxy servers. Allocating work to the sub-server based on their response time is the proposed Dynamic Load Balancing technique...|$|R
50|$|Typically, PXELINUX is {{used for}} {{performing}} Linux installations from a central <b>network</b> <b>server,</b> or for booting diskless workstations.|$|R
5000|$|... #Caption: A 200 MHz IBM PowerPC 604e {{processor}} on the CPU module of an Apple <b>Network</b> <b>Server</b> 700.|$|R
5000|$|Holds {{two extra}} shots in <b>Server</b> <b>Mode,</b> {{and has a}} second use as a stand in Stabilizer Mode. Also used to attach a second grip when in Stabilizer Mode.Available on Reflect Wyvern ...|$|R
50|$|All of <b>network</b> <b>servers</b> run on IRCnet's ircd {{with the}} current version 2.11 (latest {{software}} versions are maintained at IRC.ORG).|$|R
5000|$|Provide {{deployed}} Wide Area Network, and deployed Local Area <b>Network</b> <b>server</b> {{support for}} the ACE CE, and primary MACCS agencies.|$|R
40|$|Controlling {{the timing}} {{performance}} of a <b>network</b> <b>server</b> is a challenging problem. This paper presents a Queueing Model Based Feedback Control approach to keep the timing {{performance of a}} <b>network</b> <b>server</b> close to the service level specification. We show that in an instrumented Apache server, combining feedback control with a queueing model leads to better tracking of QoS specifications than with feedback control alone or queueing model based feed forward control alone. ...|$|R
