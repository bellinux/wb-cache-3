15|7|Public
50|$|Improved use {{of online}} storage and nearline storage {{in the image}} archive. The PACS can obtain lists of {{appointments}} and admissions in advance, allowing images to be pre-fetched from off-line storage or <b>near-line</b> <b>storage</b> onto online disk storage.|$|E
50|$|SCSI, SAS, and FC drives {{are more}} {{expensive}} than consumer-grade SATA drives, and usually used in servers and disk arrays, where SATA drives were sold to the home computer and desktop and <b>near-line</b> <b>storage</b> market and were perceived to be less reliable. This distinction is now becoming blurred.|$|E
5000|$|Near-line : <b>Near-line</b> <b>storage</b> is {{typically}} less accessible {{and less expensive}} than on-line storage, but still useful for backup data storage. A good example would be a tape library with restore times ranging from seconds to a few minutes. A mechanical device is usually used to move media units from storage into a drive where the data can be read or written. Generally it has safety properties similar to on-line storage.|$|E
40|$|Advances in robotic {{devices and}} storage media now make it {{possible}} to design <b>near-line</b> automated <b>storage</b> systems. These systems aim to provide responsive performance to users of tertiary storage devices. The Jaquith system is a prototype archive server that lets network users archive their own files using automated storage. It provides semi-interactive file access to its clients by combining a high-density robotic tape system with disk-based indexing. Jaquith presents an FTP interface whereby whole files are moved between the client and its storage archive. Each client's archive is separately governed to provide independent namespaces, added security, and parallel operation. A wildcard query mechanism lets users manipulate arbitrary subsets of their files. Two important aspects of the query system are abstracts, text tags that can be associated with files, and versions, date-stamps that are applied to archived files. Jaquith throughput is about 135 KB/second when archiving small (10 K [...] ...|$|R
40|$|Advances {{in storage}} {{technology}} have made <b>near-line</b> tertiary <b>storage</b> {{a viable alternative}} for database and data warehouse systems. Tertiary storage systems are employed in cases where secondary storage can not satisfy the data handling requirements or tertiary storage is more cost effective option. Tertiary storage devices have traditionally been used as archival storage. The new application domains require on-demand retrieval of data from these devices. This paper investigates issues in optimizing I/O time for a query whose data resides on automated tertiary storage containing multiple storage devices. We model the problem as a limited storage parallel two-machine flow-shop scheduling problem with additional constraints. Given a query, we establish an upper bound {{on the number of}} storage devices for an optimal I/O schedule and provide experimental proof for it. For queries that access small amounts of data from multiple media, we derive an optimal schedule analytically. For q [...] ...|$|R
40|$|Large {{multimedia}} document archives hold most {{of their}} data in <b>near-line</b> tertiary <b>storage</b> libraries for cost reasons. This paper de- velops an integrated approach to the vertical data migration between the tertiary and secondary storage in that it reconciles specu- lative preloading, to mask the high latency of the tertiary storage, with the replacement policy of the secondary storage. In addition, it considers the interaction of these policies with the tertiary storage scheduling and controls preloading aggressiveness by taking con- tention for tertiary storage drives into account. The integrated migration policy {{is based on a}} continuous-time Markov-chain (CTMC) model for predicting the expected number of accesses to a document within a specified time horizon. The parameters of the CTMC model, the probabilities of co-accessing certain documents and the interaction times between successive accesses, are dynami- cally estimated and adjusted to evolving workload patterns by keep [...] ...|$|R
5000|$|In this scenario, SAP Enterprise Resource Planning (ERP) data {{goes into}} SAP HANA which {{acts as an}} {{operational}} data store for immediate analysis. Once the data is analyzed it is integrated into SAP IQ via <b>Near-line</b> <b>storage</b> mechanisms (as described above). Here SAP IQ acts as an enterprise data warehouse that receives data {{from a variety of}} traditional sources (such as OLTP Databases and files systems), and SAP HANA Operational Data Store(ODS) ...|$|E
40|$|With {{the advent}} of {{multi-media}} and other applications that require the incorporation of large amounts of digital data, {{the need for a}} new level in the storage hierarchy has arisen. This new storage level is called <b>Near-Line</b> <b>Storage,</b> and is defined as an intermediate stage between traditional on-line and off-line storage levels. The goal {{of this paper is to}} provide a detailed survey for computer scientists about the device and systems technologies for building <b>near-line</b> <b>storage</b> systems. We first give a taxonomy of <b>near-line</b> <b>storage</b> devices according to their recording media and recording mechanisms, together with in-depth discussions of the devices' cost/performance characteristics. Greater emphasis is placed on magnetic and optical storage devices since they currently represent the technology of choice. Wherever possible, the architectural implications of particular technology/configuration parameters of these devices are investigated in detail. We then discuss existing and/or proposed [...] ...|$|E
40|$|Online {{disk space}} is a valuable, {{relatively}} expensive, and frequently scarce resource {{that is often}} abused by users who squander it on large quantities of inactive data. Large inactive files should instead be moved to cheaper and more abundantly available offline or <b>near-line</b> <b>storage.</b> Users, however, are often reluctant to utilize offline storage because {{it is difficult to}} use. An extension to the UNIX operating system that transparently migrates inactive data between online and offline storage is examined, enhanced, and evaluated...|$|E
40|$|Recently, {{technological}} advances {{have resulted in}} the wide availability of commercial products offering <b>near-line,</b> robot-based, tertiary <b>storage</b> libraries. Thus, such libraries have become a crucial component of modern largescale storage servers, given the very large storage requirements of modern applications. Although the subject of optimal data placement (ODP) strategies has received considerable attention for other storage devices (such as magnetic and optical disks and disk arrays), the issue of optimal data placement in tertiary libraries has been neglected. The latter issue is more critical since tertiary storage remains three orders of magnitude slower than secondary storage. In this paper, we address this issue by deriving such optimal placement algorithms. First, we study the ODP problem in disk libraries (jukeboxes) and subsequently, in tape libraries. In our studies, we consider different scheduling algorithms, different configurations of disk libraries and different tape l [...] ...|$|R
40|$|Storage of {{multimedia}} data {{is a critical}} issue for the overall system's per-formance and functionality. Multimedia applications {{must be able to}} support a variety of data defined as multimedia objects. Multimedia data consist of various objects such as text, image, video and graphics, which need to be synchronized and meet certain timing requirements. The development and evolution of these new applications characterized by high storage needs resulted in strengthening the role and importance of Tertiary Storage Systems. Recent technological ad-vances have resulted in wide availability of commercial products offering <b>near-line,</b> robot-based, tertiary <b>storage</b> libraries. Therefore, such libraries have become an important component of modern large-scale storage servers. The issue of optimal data placement strategies in tertiary storage is considered below. Different con-figurations of tape libraries and magnetic tape technologies as well as the special attributes of stored data {{have an impact on the}} optimal placement. 1 Introduction- Research Revie...|$|R
40|$|Advances in robotic {{devices and}} storage media now make it {{possible}} to design <b>near-line</b> automated <b>storage</b> systems. These systems aim to provide responsive performance to users of tertiary storage devices. The Jaquith system is a prototype archive server that lets network users archive their own files using automated storage. It provides semi-interactive file access to its clients by combining a high-density robotic tape system with disk-based indexing. Jaquith presents an FTP interface whereby whole files are moved between the client and its storage archive. Each client’s archive is separately governed to provide independent namespaces, added security, and parallel operation. A wildcard query mechanism lets users manipulate arbitrary subsets of their files. Two important aspects of the query system are abstracts, text tags that can be associated with files, and versions, date-stamps that are applied to archived files. Jaquith throughput is about 135 KB/second when archiving small (10 KB) user files to disk buffers. The use of synchronous disk writes by the server to ensure durability of each user file degrades throughput to 40 KB/second. The performance when writing disk buffers to Exabyte or Metrum tape is severely limited by the time to write a hardware filemark. Consequently, it is important to write several megabytes of data between filemarks for good performance. Report Documentation Page Form ApprovedOMB No. 0704 - 0188 Public reporting burden for the collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources, gathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this collection of information...|$|R
40|$|The declining {{costs of}} {{commodity}} disk drives is rapidly changing {{the economics of}} deploying large amounts of online or <b>near-line</b> <b>storage.</b> Conventional mass storage systems use either high performance RAID clusters, automated tape libraries {{or a combination of}} tape and disk. In this paper, we analyze an alternative design using massive arrays of idle disks, or MAID. We argue that this storage organization provides storage densities matching or exceeding those of tape libraries with performance similar to disk arrays. Moreover, we show that with effective power management of individual drives, this performance can be achieved using a very small power budget. In particular, we show that our power management strategy can result in the performance comparable to an always-on RAID system while using ¢¤£¥¢§¦©¨� � the power of such a RAID system. ...|$|E
40|$|Recent {{advances}} in computer technologies {{have made it}} feasible to provide multimedia services, such as news distribution and entertainment, via high bandwidth networks. The storage and retrieval of large multimedia objects (e. g., video) becomes a major design issue of the multimedia information system. While most other works on multimedia storage servers assume an on-line disk storage system [2, 12, 16, 17, 19], we consider a two-tier storage architecture with a robotic tape library as the vast <b>near-line</b> <b>storage</b> and an on-line disk system as the front-line storage. Magnetic tapes are cheaper, more robust, and have a larger capacity; hence they are more cost effective for large scale storage systems (e. g., video on demand (VOD) systems [10] may store tens of thousands of videos). We study in detail the design issues of the tape subsystem and propose some novel tape scheduling algorithms which give faster response and require less disk buffer space. We also study the disk str [...] ...|$|E
40|$|Recent {{advances}} of computer storage architectures, high speed networking technologies and compression techniques support {{a proliferation of}} multimedia information dissemination via computer networks. For example, applications like video-ondemand (VOD) and home shopping services are now possible. A major requirement of VOD application is that the VOD storage server has to store and retrieve {{a huge amount of}} video data in a continuous manner. Therefore, <b>near-line</b> <b>storage</b> devices, such as robotic tape library, have to be employed in VOD storage servers which can contain thousands of large video objects. In this paper, we study in detail the design issues of a hierarchical multimedia storage server that consists of a disk array for caching and a robotic tape library for the storage of all the video objects. We propose and study in detail the scheduling and replacement policies of the hierarchical multimedia storage server. We illustrate the file layout policy in the parallel disks system, [...] ...|$|E
40|$|The NASA EOS Data and Information System (EOSDIS) Core System (ECS) {{will contain}} {{one of the}} largest data {{management}} systems ever built - the ECS Science and Data Processing System (SDPS). SDPS is designed to support long term Global Change Research by acquiring, producing, and storing earth science data, and by providing efficient means for accessing and manipulating that data. The first two releases of SDPS, Release A and Release B, will be operational in 1997 and 1998, respectively. Release B will be deployed at eight Distributed Active Archiving Centers (DAAC's). Individual DAAC's will archive different collections of earth science data, and will vary in archive capacity. The storage and management of these data collections {{is the responsibility of the}} SDPS Data Server subsystem. It is anticipated that by the year 2001, the Data Server subsystem at the Goddard DAAC must support a <b>near-line</b> data <b>storage</b> capacity of one petabyte. The development of SDPS is a system integration effort in which COTS products will be used in favor of custom components in very possible way. Some software and hardware capabilities required to meet ECS data volume and storage management requirements beyond 1999 are not yet supported by available COTS products. The ECS project will not undertake major custom development efforts to provide these capabilities. Instead, SDPS and its Data Server subsystem are designed to support initial implementations with current products, and provide an evolutionary framework that facilitates the introduction of advanced COTS products as they become available. This paper provides a high-level description of the Data Server subsystem design from a COTS integration standpoint, and discussed some of the major issues driving the design. The paper focuses on features of the design that will make the system scalable and adaptable to changing technologies...|$|R
40|$|In this paper, we {{consider}} a storage server architecture for multimedia information systems. While most other works on multimedia storage servers assume on-line disk storage [12, 11, 15, 8, 2], {{we consider}} a two-tier storage architecture with a robotic tape library as the vast <b>near-line</b> <b>storage</b> and on-line disks as the front-line storage. Magnetic tapes are cheaper, more robust, {{and have a}} larger capacity; hence they are more cost effective for large scale storage systems (e. g., video on demand (VOD) systems [7] may store {{tens of thousands of}} videos). We study in details the design issues of the tape subsystem and propose some novel tape scheduling algorithms which give faster response and require less disk buffering. We also study the disk striping policy and the disk space organization in order to fully utilize the throughput of the robotic tape system and to minimize the size of on-line disk storage. 1 Introduction Recent advances in network technologies make it feasible to provi [...] ...|$|E
40|$|Abstract. Recent {{advances}} in computer technologies {{have made it}} feasible to provide multimedia services, such as news distribution and entertainment, via high-bandwidth networks. The storage and retrieval of large multimedia objects (e. g., video) becomes a major design issue of the multimedia information system. While most other works on multimedia storage servers assume an on-line disk storage system, we consider a two-tier storage architecture with a robotic tape library as the vast <b>near-line</b> <b>storage</b> and an on-line disk system as the front-line storage. Magnetic tapes are cheaper, more robust, and have a larger capacity; hence, they are more cost effective for large scale storage systems (e. g., videoon-demand (VOD) systems may store tens of thousands of videos). We study in detail the design issues of the tape subsystem and propose some novel tape-scheduling algorithms which give faster response and require less disk buffer space. We also study the disk-striping policy and the data layout on the tape cartridge in order to fully utilize the throughput of the robotic tape system and to minimize the on-line disk storage space. Key words: Multimedia storage – Scheduling – Data layout...|$|E
40|$|In today's large {{mainframe}} and supercomputer environment {{there exists}} a continuous demand for increased performance in digital storage systems. The user need for <b>near-line</b> <b>storage</b> capacity is currently doubling every four years. In addition to higher capacity, a desire exists for higher data transfer rates, and longer term database archivability, at lower, and lower cost. Each component of this quartet of demands appears to be insatiable. Magnetic tape technology presently dominates the digital mass storage markets, but the continuous growth of requirements is drawing attention to {{the limitations of the}} technology as an archival mass storage medium. The lowest cost option currently available for long term data storage is to use magnetic tape, although it is not well suited to meeting the need for many tens of years of reliable storage. Today, the majority of magnetic tape mass storage systems are based on the IBM 3480 / 3490 (or compatible) tape drives. These drives offer only moderate transfer rates and relatively small increments of storage, both of which create a logistics problem due to the large numbers of cartridges necessary in a typical system and the time taken to transfer data. Both higher cartridge capacity and data transfer rates are available in some helical scan magnetic tape systems; however, these command a substantially higher price, exacerbating the cost problem, and are not compatible with most installed systems or tape databases...|$|E
40|$|The National Space Science Data Center (NSSDC) was {{established}} by NASA {{to provide for the}} preservation and dissemination of scientific data from NASA missions. This paper describes the policies specifically related to lunar science data. NSSDC presently archives 660 lunar data collections. Most of these data (423 units) are stored offline in analog format. The remainder of this collection consists of magnetic tapes and discs containing approximately 1. 7 TB of digital lunar data. The active archive for NASA lunar data is the Planetary Data System (PDS). NSSDC has an agreement with the PDS Lunar Data Node to assist in the restoration and preparation of NSSDC-resident lunar data upon request for access and distribution via the PDS archival system. Though much of NSSDC's digital store also resides in PDS, NSSDC has many analog data collections and some digital lunar data sets that are not in PDS. NSSDC stands ready to make these archived lunar data accessible to both the research community and the general public upon request as resources allow. Newly requested offline lunar data are digitized and moved to <b>near-line</b> <b>storage</b> devices called digital linear tape jukeboxes. The data are then packaged and made network-accessible via FTP for the convenience of a growing segment of the user community. This publication will 1) discuss the NSSDC processes and policies that govern how NASA lunar data is preserved, restored, and made accessible via the web and 2) highlight examples of special lunar data requests...|$|E
40|$|By 1997, this {{facility}} will collect over 1 Terabyte of raw information/day accelerator operation from three concurrently operating experimental halls. With post-processing, {{it means that}} about 250 TB raw and formatted experimental data will be generated each year. By the year 2000, a total of one Petabyte will be stored on-line. Critical to the program is the networking and computational capability to collect, store, retrieve, and reconstruct data on this scale. Design criteria include support of a raw data stream of 10 - 12 MB/second from Experimental Hall B, which will operate the CEBAF Large Acceptance Spectrometer. Keeping up with this data stream implies design strategies that provide storage guarantees during accelerator operation, minimize {{the number of times}} data is buffered, allow seamless access to specific data sets for the researcher, synchronize data retrievals with scheduling of postprocessing calculations on the data reconstruction CPU farms, as well as support the site capability for data reconstruction and reduction at same overall rate that new data is being collected. Current implementation uses state of the art StorageTek Redwood tape drives and robotics library integrated with the Open Storage Manager Hierarchical Storage Management software (Computer Associates, International), the use of Fibre Channel RAID disks dual-ported between Sun Microsystems SMP servers, and a network-based interface to a 10, 000 SPECint 92 data processing CPU farm. Issues of efficiency, scaleability, and manageability will become critical to meet the year 2000 requirements for a Petabyte of <b>near-line</b> <b>storage</b> interfaced to over 30, 000 SPECint 92 of data processing power...|$|E
40|$|By 1997, the Thomas Jefferson National Accelerator Facility {{will collect}} over one Terabyte of raw {{information}} per day of Accelerator operation from three concurrently operating Experimental Halls. When post-processing is included, roughly 250 TB of raw and formatted experimental {{data will be}} generated each year. By the year 2000, a total of one Petabyte will be stored on-line. Critical to the experimental program at Jefferson Lab (JLab) is the networking and computational capability to collect, store, retrieve, and reconstruct data on this scale. The design criteria include support of a raw data stream of 10 - 12 MB/second from Experimental Hall B, which will operate the CEBAF (Continuous Electron Beam Accelerator Facility) Large Acceptance Spectrometer (CLAS). Keeping up with this data stream implies design strategies that provide storage guarantees during accelerator operation, minimize {{the number of times}} data is buffered allow seamless access to specific data sets for the researcher, synchronize data retrievals with the scheduling of postprocessing calculations on the data reconstruction CPU farms, as well as support the site capability to perform data reconstruction and reduction at the same overall rate at which new data is being collected. The current implementation employs state-of-the-art StorageTek Redwood tape drives and robotics library integrated with the Open Storage Manager (OSM) Hierarchical Storage Management software (Computer Associates, International), the use of Fibre Channel RAID disks dual-ported between Sun Microsystems SMP servers, and a network-based interface to a 10, 000 SPECint 92 data processing CPU farm. Issues of efficiency, scalability, and manageability will become critical to meet the year 2000 requirements for a Petabyte of <b>near-line</b> <b>storage</b> interfaced to over 30, 000 SPECint 92 of data processing power...|$|E

