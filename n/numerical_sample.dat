23|438|Public
30|$|The {{wavelength}} used in {{the experimental}} work means {{that most of the}} scattering comes from multiple reflections on the boundaries of the sample, rather than reflections from crystal boundaries (Griffiths et al. 2018). This wave scattering behavior is reproduced in the <b>numerical</b> <b>sample</b> as we do not include details of the crystal assembly, but only use the multiple reflections at the free boundaries of the sample.|$|E
40|$|We employ ab-initio {{molecular}} dynamics simulations {{to study the}} atomic structure of amorphous germanium. The preparation of an amorphous Ge <b>numerical</b> <b>sample</b> is performed by cooling down from the liquid phase. Calculated structural and thermal properties of the amorphous phase result in good agreement with experimental data. This is a necessary step for starting a complete characterization of the pressure effects on the amorphous germanium...|$|E
40|$|Summary. The {{concept of}} the {{asymptotic}} behaviour of particulate materials is de-scribed, including its enhancement considering asymptotic states in extension. A 3 D discrete element model with permanent elastic spherical particles is set up. The <b>numerical</b> <b>sample</b> is stretched from different initial states, {{and the influence of}} the strain rate direction on the final state is studied. Asymptotic behaviour is clearly observed. Existence of extension asymptotic states is demonstrated, and the notion of normal extension line is introduced...|$|E
40|$|Abstract: A {{numerical}} method {{based on}} Dual Reciprocity Boundary Element Method (DRBEM) has presented to interpolate twodimensional data with arbitrary pattern. This method is performed without specific boundary conditions. It claimed that interpolation function is true on the Poisson equation with unknown source function. The source function is estimated by radial basis functions expansion. Finally, <b>numerical</b> <b>sampling</b> has conducted on some specific functions as primary functions and interpolation values of <b>numerical</b> <b>sampling</b> have compared to primary function values {{in order to}} evaluate accuracy and precision of the method...|$|R
40|$|Fixed-precision {{numerical}} and binomial {{sequential sampling}} plans are reported for adults of Bemisia tabaci (Strain B) on cotton. Both plans {{are based on}} whole leaf sample units from the fifth mainstem node (counted from the terminal). <b>Numerical</b> <b>sampling</b> plans allow for the efficient estimation of adult population density. <b>Numerical</b> <b>sampling</b> stop lines are presented relating the cumulative number of adults counted {{to the number of}} leaves examined for two levels of statistical precision. Binomial plans were developed to allow classification of adult population density for pest management decision -making application. These plans were devised for three action threshold levels; 5, 10 or 15 adults per leaf Binomial sampling stop lines are presented relating the cumulative number of infested leaves to the number of leaves examined as an aid for determining the need for population suppression...|$|R
50|$|This {{is one of}} {{the more}} mathematically {{intensive}} chapters in the book. It deals with the transmission or recording of a varying analog signal as a sequence of <b>numerical</b> <b>samples,</b> and lays much of the groundwork for the development of digital audio and telemetry over the past six decades. It also examines the relationship between bandwidth, noise, and information capacity, as developed by Wiener in collaboration with Claude Shannon.|$|R
30|$|The {{waveform}} {{recorded at}} a given receiver in the simulation is subsequently the contribution of many reflected waves that have travelled along multiple paths through the sample. The <b>numerical</b> <b>sample</b> is discretized using a 2 D finite element mesh grid of 17244 elements with a characteristic length lc[*]=[*] 0.5  mm. This parameter corresponds to the characteristic distance between two neighboring nodes. The meshing of the sample is done using GMSH which is a GNU General Public License finite element mesh generator with 2 -D quadrangle meshes using a Delaunay algorithm.|$|E
40|$|In {{this paper}} {{the problem of}} {{resources}} distribution in optimal way among the units of the Logistic centre was observed. This task could be solved by using the method of dynamic programming. Using the programming language Mathcad 14 there was created the special program which allows to make the corresponding calculations. The solution of the real task for Logistic centre in Latvia is observed in this paper as the <b>numerical</b> <b>sample</b> of limited resource distribution between the units of the logistic centre {{in order to get}} the maximum profit...|$|E
30|$|The <b>numerical</b> <b>sample</b> {{intends to}} {{reproduce}} the mechanical behavior of the granite sample used in the laboratory experiments. In the simulation, {{we focus on the}} elastic deformation of the sample when the temperature is progressively increased from 20 to 450  °C in 10  °C increments. The mesh grid, which is an input for the wave propagation simulation, is progressively deformed. As the mechanical parameters are considered constant with temperature, the numerical scheme intends to test the effect of the material deformation (in particular of thermal dilatation of the sample), independent of intrinsic perturbations related to inelastic deformation (microcracks, plastic deformation, etc.).|$|E
40|$|AbstractIntegration by parts {{reduction}} {{is a standard}} component of most modern multi-loop calculations in quantum field theory. We present a novel strategy constructed to overcome the limitations of currently available reduction programs based on Laporta's algorithm. The key idea is to construct algebraic identities from <b>numerical</b> <b>samples</b> obtained from reductions over finite fields. We expect the method to be highly amenable to parallelization, show a low memory footprint during the reduction step, and allow for significantly better run-times...|$|R
40|$|The present {{multidisciplinary}} telescope-analysis approach, which encompasses thermal, structural, {{control and}} optical considerations, is illustrated {{for the case}} of an IR telescope in LEO; attention is given to end-to-end evaluations of the effects of mechanical disturbances and thermal gradients in measures of optical performance. Both geometric ray-tracing and surface-to-surface diffraction approximations are used in the telescope's optical model. Also noted is the role played by NASA-JPL's Integrated Modeling of Advanced Optical Systems computation tool, in view of <b>numerical</b> <b>samples...</b>|$|R
40|$|A domain {{decomposition}} technique is {{extended to the}} case of a dynamic crack propagation in a heterogeneous material. The fracture is described through a cohesive approach in a standard, displacement-based finite element method. To comply with the large scale computing requirements for three-dimensional problems and the stability condition for time integration, the {{domain decomposition}} is coupled with multi time step algorithms. The theoretical framework is here discussed and tested with <b>numerical</b> <b>samples</b> made in the polycrystalline silicon material typically adopted in the microsystem industr...|$|R
40|$|AbstractThe aim of {{this paper}} is to study the effects of {{material}} gradation on thermo-mechanical stresses in functionally graded beams. The composition of the beam varies gradually from ceramic to metal along both the thickness and width directions. Continuous gradations according to both the power law and exponential law variations are considered. In the presence of a thermal gradient and transverse distributed loads an analytical solution based on the Euler-Bernoulli beam theory is presented. <b>Numerical</b> <b>sample</b> where material gradations vary along both the thickness and width directions is carried out. It is found that the gradation of materials affects the neutral axis position...|$|E
40|$|The {{main goal}} of this thesis was to design new {{parallel}} processing strategies specially conceived for distributed environments in order to solve numerical and structural problems {{from the field of}} process systems engineering more efficiently. More specifically, the <b>numerical</b> <b>sample</b> problem addressed in this work was the optimization of nonlinear objective functions subjected to sets of nonlinear constraints, while the structural sample problem was the development of parallel-distributed structural techniques for process instrumentation designResumen de la tesis presentada por el autor en el 2002 para la obtención del título de Doctor en Ciencias de la Computación por la Universidad Nacional del Sur...|$|E
40|$|In {{this paper}} {{the problem of}} {{decision}} making process for creation of the new supply and distribution channel of the Logistic centre was observed. The task consists in the taking decision regarding the way selection from choosing the raw materials till final products creation that allows getting the maximum profits to the company. This task could be solved by using the method of dynamic programming. In this case it means to make decision for each unit individually. The solution of the real task for Logistic centre in Latvia is observed in this paper as the <b>numerical</b> <b>sample</b> of decision making process for the new supply and sales channel development for the logistic centre {{in order to get}} the maximum profit...|$|E
40|$|The {{dynamics}} of a disordered nonlinear chain {{can be either}} regular or chaotic with a certain probability. The chaotic behavior {{is often associated with}} the destruction of Anderson localization by the nonlinearity. In the presentwork it is argued that at weak nonlinearity chaos is nucleated locally on rare resonant segments of the chain. Based on this picture, the probability of chaos is evaluated analytically. The same probability is also evaluated by direct <b>numerical</b> <b>sampling</b> of disorder realizations and quantitative agreement between the two results is found...|$|R
40|$|Within the {{framework}} of this study, constitutive equations for describing creep behaviour under isotropic damage based on the Kachanov-Rabotnov model are discussed. The initial boundary problem {{for the analysis of}} thin-walled supports is formulated on this basis. In order to solve the problem, a special numerical method is presented. The efficiency of the calculations is discussed on the basis of <b>numerical</b> <b>samples.</b> The potential of the theoretical modelling is demonstrated using examples for thin plates. (orig.) SIGLEAvailable from TIB Hannover: RR 3478 (94 - 5) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
40|$|Integration by parts {{reduction}} {{is a standard}} component of most modern multi-loop calculations in quantum field theory. We present a novel strategy constructed to overcome the limitations of currently available reduction programs based on Laporta's algorithm. The key idea is to construct algebraic identities from <b>numerical</b> <b>samples</b> obtained from reductions over finite fields. We expect the method to be highly amenable to parallelization, show a low memory footprint during the reduction step, and allow for significantly better run-times. Comment: 4 pages. Version 2 is the final, published version of this articl...|$|R
40|$|The thesis {{analyses}} {{mid-nineteenth century}} electoral violence in England and Wales {{in order to}} contribute {{to our understanding of}} the character of Victorian electoral politics, and to assess the pace of political modernization as it has recently been defined. Historians have long acknowledged the presence of physical violence, rioting and intimidation during British elections from at least the Middle Ages to the turn of the twentieth-century, and yet the precise nature, frequency and scale of this phenomenon has remained somewhat obscured by a lack of statistical data on the subject. Therefore, by compiling a <b>numerical</b> <b>sample</b> of violence, based on strict definitional parameters, this research corrects the quantitative void in which discussions of English and Welsh election violence have largely been conducted...|$|E
40|$|International audienceIncreasing the {{pore volume}} {{fraction}} of porous ceramics enhances their functionality {{for a wide}} range of applications. However, the increased functionality comes at the expense of their toughness. Discrete element method (DEM) three-dimensional simulations, which operate at the length scale of individual particles, are used to investigate the toughness of microstructures typical of partially sintered ceramics. The method is first validated by comparing DEM simulations to the linear elastic fracture mechanics elastic solution at the crack tip of a pre-cracked <b>numerical</b> <b>sample.</b> The toughness of realistic random microstructures is then obtained using DEM simulations and compared to experimental data. Green density is shown to have a significant effect on toughness. Discrete simulations also suggest that the linear relationship between toughness and Young's modulus is primarily linked to the size of the solid necks formed during sintering of particle...|$|E
40|$|Abstract The {{concept of}} the {{asymptotic}} behaviour of particulate materials is described, including its en-hancement by considering asymptotic states in exten-sion. A 3 D discrete element model with elastic spherical particles and the granulometry of a real sand is set up. The <b>numerical</b> <b>sample</b> is stretched from different initial states, {{and the influence of}} the strain rate direction on the final state is studied within the stress ratio, void ratio and mean stress space. Asymptotic behaviour is clearly observed, although the grains remain intact (no grain crushing is considered). The extension asymptotic states are observed, and the notion of a normal exten-sion line is introduced. The extension asymptotic states coincide with the peak states observed in the shear tests with constant stress path direction in dense samples. Keywords asymptotic behaviour · critical state · discrete element method · particle crushing · sand...|$|E
30|$|This {{article is}} {{structured}} as follows: First, we briefly review Bayesian networks and introduce a general state-space model in Section 2. This state-space model will be further specified in Section 3 for {{the tasks of}} linear and nonlinear AEC. This is followed by applying several fundamental probabilistic inference techniques for deriving the NLMS algorithm with fixed/adaptive stepsize value (linear AEC, Section 4), {{as well as the}} Hammerstein group model and a <b>numerical</b> <b>sampling</b> scheme (nonlinear AEC, Section 5). Finally, the practical performance of the algorithms is illustrated in Section 6 and conclusions are drawn in Section 7.|$|R
30|$|The article “A Bayesian Network Approach to Linear and Nonlinear Acoustic Echo Cancellation”, by C. Huemmer, R. Maas, C. Hofmann, and W. Kellermann, {{presents}} a general Bayesian approach to linear and nonlinear acoustic echo cancellation (AEC), where a latent state vector in a state-space model captures all relevant information {{of the unknown}} system. Using probabilistic graphical models, the normalized least mean square algorithm (with fixed and adaptive step size), the Hammerstein group model and a <b>numerical</b> <b>sampling</b> scheme for nonlinear AEC can be represented in a unified way {{to serve as a}} powerful framework for future algorithmic development.|$|R
40|$|In this paper, {{we propose}} an {{approach}} that yields accurate approximations for the packet response times in a generic ATM switch. The approach combines three existing methodologies: power series algorithm for light traffic, saturation analysis for heavy traffic, and the Newton-Pade rational approximation for curve fitting. This approach works especially well for small to medium size switches, for which the traditional assumption of the Poisson arrival to the transmission channels does not apply well. <b>Numerical</b> <b>samples</b> reveal a close agreement between the approximant and the simulation result. (C) 2003 Elsevier Science B. V. All rights reserved...|$|R
40|$|Previous {{research}} has shown that the sample preparation method used to reconstitute specimens for granular materials can {{have a significant impact on}} its mechanistic behavior. As the Discrete Element Method becomes a more popular choice for modeling multiphysics problems involving granular materials, the sample heterogeneity should be correctly characterized in order to obtain accurate results. In order to capture the effect of sample preparation on the homogeneity of the sample, standard procedures were used to reconstitute samples composed of a homogeneous granular material. X-ray computed tomography and image analysis techniques were then used to characterize the spatial heterogeneity of a typical sample. The sample preparation method was modeled numerically using the Discrete Element program PFC 3 D. The resulting microstructure of the <b>numerical</b> <b>sample</b> was compared to the results of the image analysis to determine if the heterogeneity of the sample could be reproduced correctly for use in Discrete Element Modeling...|$|E
40|$|In {{this paper}} {{the problem of}} {{resources}} distribution in optimal way among the units of the Logistic centre was observed. Logistic centre has the treelike structure with several units. Each unit could be developed in different ways based on given resource and expected profit. The Logistic centre management task is to distribute the certain resource between units in the {{order to get the}} maximum profit from them. This task could be solved by using the method of dynamic programming created by Richard Bellman. The optimal strategy has the nature that for any prime condition and prime decision all the following solutions have to compose the optimal strategy in regard to condition that is gotten as a result of initial decision. Using the programming language Mathcad 14 there was created the special program which allows to make the corresponding calculations. The solution of the real task for Logistic centre in Latvia is observed in this paper as the <b>numerical</b> <b>sample</b> of limited resource distribution between the units of the logistic centre {{in order to get the}} maximum profit. ...|$|E
40|$|Using the {{existence}} theorem of Minkowski, {{we consider the}} mapping of a data set in IR d into a convex body called the Minkowski polytope. Elsewhere the first author has treated this as a data analytic tool. Here we show that the MP obeys a strong law {{in the sense of}} converging in the Hausdorff metric with increasing sample size to a convex body associated with the population distribution. 1 Introduction Traditionally a <b>numerical</b> <b>sample</b> is analyzed by considering one or more scalar or vector statistics. Motivated by recent work in the theory of random (geometric) sets, we have been considering a set [...] valued variant called the Minkowski polytope (MP). To our knowledge, the approach is novel to data analysis although the MP and related notions have been employed in physics [5], astronomy [6], and image processing [7]. In [2] and [3], the first author investigated the usefulness of the MP for data analytic issues such as the presence of outliers or clusters and correlation among variabl [...] ...|$|E
40|$|We {{discuss a}} new phase space method for the {{computation}} of quantum expectation values in the high frequency regime. Instead of representing a wavefunction by its Wigner function, which typically attains negative values, we define {{a new phase}} space density by adding a first-order Hermite spectrogram term as a correction to the Husimi function. The new phase space density yields accurate approximations of the quantum expectation values as well as allows <b>numerical</b> <b>sampling</b> from non-negative densities. We illustrate the new method by numerical experiments in up to $ 128 $ dimensions. Comment: 6 pages, 5 figure...|$|R
40|$|We {{present an}} {{approach}} to Bayesian mean estimation of quantum states using hyperspherical parametrization and an experiment-specific likelihood which allows utilization of all available data, even when qubits are lost. With this method, we report the first closed-form Bayesian mean estimate for the ideal single qubit. Due to computational constraints, we utilize <b>numerical</b> <b>sampling</b> to determine the Bayesian mean estimate for a photonic two-qubit experiment in which our novel analysis reduces burdens associated with experimental asymmetries and inefficiencies. This method {{can be applied to}} quantum states of any dimension and experimental complexity. Comment: 28 pages. Revision includes, in part, changes to the ideal single-qubit MLE sectio...|$|R
40|$|International audiencePorous ceramic {{samples were}} {{processed}} either by freeze-casting or by slip-casting with pore formers. They were partially sintered {{to obtain a}} total porosity in between 44 and 69 %. Samples were imaged by X-ray nanotomography with 75 nm resolution. The images, approximately 70 (3) to 90 (3) mu m(3) in size, were merged with randomly packed particles to obtain representative numerical microstructures. The <b>numerical</b> <b>samples</b> were crushed uniaxially using discrete element simulations with appropriate microscopic fracture properties. This revealed anisotropic behavior for freeze-cast samples. Simulated strength values were compared to experimental data, with some consideration given to sample volume. (C) 2015 Elsevier Ltd. All rights reserve...|$|R
40|$|Constant {{strain rate}} tests for a graded asphalt mixture under three {{constant}} strain {{rates have been}} undertaken in the laboratory. The Discrete Element Model {{has been used to}} simulate the laboratory tests with a <b>numerical</b> <b>sample</b> preparation procedure being developed to represent the physical specimen. The Burger’s model has been used to represent the time dependent behavior of the asphalt mixture. The Burger’s model was implemented to give bending and torsional resistance as well as in direct tension and compression. The stress-strain response for the laboratory tests and the simulations under three loading speeds were recorded. The results show reasonable agreement when the bond strengths in the model are made to be a function of strain rate. Both normal and Weibull distributions have been used for the bond strengths between the aggregate particles. The effects on the stress-strain response of bond strength variability and particle position are proved to be negligible. Bond breakage was recorded during the simulations to explain the internal damage within the sample. The modified Burger’s model {{has proved to be a}} useful tool in modeling the bending and torsional resistance at particle contacts in an asphalt mixture, in order to correctly predict observed behavior...|$|E
40|$|A {{combined}} {{experimental and}} molecular simulation {{study of the}} coadsorption of CO 2 and CH 4 in porous carbons is reported. We address the effect of surface chemistry by considering a numerical model of disordered porous carbons which has been modified to include heterochemistry (with a chemical composition consistent {{with that of the}} experimental sample). We discuss how realistic the <b>numerical</b> <b>sample</b> is by comparing its pore size distribution (PSD), specific surface area, porous volume, and porosity with those for the experimental sample. We also discuss the different criteria used to estimate the latter properties from a geometrical analysis. We demonstrate the ability of the MP method to estimate PSD of porous carbons from nitrogen adsorption isotherms. Both the experimental and simulated coadsorption isotherms resemble those obtained for pure gases (type I in the IUPAC classification). On the other hand, only the porous carbon including the heterogroups allows simulating quantitatively the selectivity of the experimental adsorbent for different carbon dioxide/methane mixtures. This result shows that taking into account the heterochemistry present in porous carbons is crucial to represent correctly adsorption selectivities in such hydrophobic samples. We also show that the adsorbed solution theory describes quantitatively the simulated and experimental coadsorption isotherms without any parameter adjustment...|$|E
40|$|AbstractThe Discrete Element Model {{has been}} used here to {{simulate}} constant strain rate uniaxial compression tests for a realistic asphalt mixture comprising graded aggregates. A <b>numerical</b> <b>sample</b> preparation procedure has been developed to represent the physical specimen. A parallel bond model {{has been used}} in the elastic modelling to give moment resistance at the contacts. Uniaxial constant strain rate loading and unloading tests have been simulated. The effects of the normal to shear contact stiffness ratio on the bulk properties, the parallel bond radius, the number of particles and their positions, and the loading speed have been investigated. A modified Burger's model has been used to introduce time-dependent contact stiffness with the ability to transmit moment and torsion. Two-ball clumps have been used to investigate the effect of particle shape. The effect of Burger's model parameters, the ratio of normal to shear Burger's model parameters, the bond radius multiplier, the friction coefficient and the bond strength distribution in the viscoelastic simulations have been investigated. Constant strain rate uniaxial compression tests have been undertaken in the laboratory where the axial stress–strain response has been measured for comparison with the numerical modelling results. The modified Burger's model has proved to be useful and ready for simulating uniaxial constant strain rate and creep tests in the laboratory...|$|E
40|$|Shrinkage {{porosity}} {{is a type}} {{of random}} distribution defects and exists in most large castings. Different from the periodic symmetry defects or certain distribution defects, shrinkage porosity presents a random “cloud-like” configuration, which brings difficulties in quantifying the effective performance of defected casting. In this paper, the influences of random shrinkage porosity on the equivalent elastic modulus of QT 400 - 18 casting were studied by a numerical statistics approach. An improved random algorithm was applied into the lattice model to simulate the “cloud-like” morphology of shrinkage porosity. Then, a large number of <b>numerical</b> <b>samples</b> containing random levels of shrinkage were generated by the proposed algorithm. The stress concentration factor and equivalent elastic modulus of these <b>numerical</b> <b>samples</b> were calculated. Based on a statistical approach, the effects of shrinkage porosity’s distribution characteristics, such as area fraction, shape, and relative location on the casting’s equivalent mechanical properties were discussed respectively. It is shown that the approach with randomly distributed defects has better predictive capabilities than traditional methods. The following conclusions can be drawn from the statistical simulations: (1) the effective modulus decreases remarkably if the shrinkage porosity percent is greater than 1. 5 %; (2) the average Stress Concentration Factor (SCF) produced by shrinkage porosity is about 2. 0; (3) the defect’s length across the loading direction plays a more important role in the effective modulus than the length along the loading direction; (4) the surface defect perpendicular to loading direction reduces the mean modulus about 1. 5 % more than a defect of other position...|$|R
40|$|Abstract. An {{algorithm}} for arbitrary polygonal aggregate {{generation is}} proposed based on secondary development of ANSYS in this paper. It is established {{on the basis}} of circular aggregate model, and the central angle is the control parameter to generate poristic polygon as the coarse aggregate of concrete. The concrete <b>numerical</b> <b>samples</b> with first gradation of aggregate and two gradation of aggregate are generated. The aggregate fraction of polygon sample is lower about 20 % than the original circular aggregate sample in the statistical sense. The results show that the proposed method can simulate gravel aggregate appropriately as long as the central angle and the aggregate percentage of original circular aggregate sample is reasonable controlled...|$|R
30|$|This article {{provides}} a general Bayesian {{approach to the}} tasks of linear and nonlinear acoustic echo cancellation (AEC). We introduce a state-space model with latent state vector modeling all relevant information of the unknown system. Based on three cases for defining the state vector (to model a linear or nonlinear echo path) and its mathematical relation to the observation, it is shown that the normalized least mean square algorithm (with fixed and adaptive stepsize), the Hammerstein group model, and a <b>numerical</b> <b>sampling</b> scheme for nonlinear AEC can be derived by applying fundamental techniques for probabilistic graphical models. As a consequence, the major contribution of this Bayesian approach is a unifying graphical-model perspective which {{may serve as a}} powerful framework for future work in linear and nonlinear AEC.|$|R
