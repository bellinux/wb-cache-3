177|13|Public
2500|$|Computational {{devices were}} created in CMOS, for both biophysical {{simulation}} and <b>neuromorphic</b> <b>computing.</b> Nanodevices for very large scale principal components analyses and convolution may create {{a new class of}} neural computing because they are fundamentally analog rather than digital (even though the first implementations may use digital devices.) ...|$|E
5000|$|SP9 <b>Neuromorphic</b> <b>Computing</b> Platform: Developing and {{applying}} brain-inspired computing technology ...|$|E
50|$|SpiNNaker {{is being}} used as one {{component}} of the <b>neuromorphic</b> <b>computing</b> platform for the Human Brain Project.|$|E
50|$|Based on {{the first}} event, a second IEEE Rebooting Computing Summit was held in May 2014 in Santa Cruz, California. Following a similar format to the first summit, a group of invited {{business}} and trade, academia, and government experts took part in discussing <b>neuromorphic</b> engineering, approximate <b>computing,</b> and adiabatic / reversible computing.|$|R
40|$|Despite the {{impressive}} amount of financial resources recently invested {{in carrying out}} large-scale brain simulations, it is controversial what the pay-offs are of pursuing this project. One idea is that from designing, building, and running a large-scale neural simulation, scientists acquire knowledge about the computational performance of the simulating system, rather than about the neurobiological system represented in the simulation. It has been claimed that this knowledge may usher {{in a new era}} of <b>neuromorphic,</b> cognitive <b>computing</b> systems. This study elucidates this claim and argues that the main challenge this era is facing is not the lack of biological realism. The challenge lies in identifying general neurocomputational principles for the design of artificial systems, which could display the robust flexibility characteristic of biological intelligence...|$|R
40|$|We {{review a}} novel {{paradigm}} {{that has emerged}} in analogue <b>neuromorphic</b> optical <b>computing.</b> The goal is to implement a reservoir computer in optics, where information is encoded in the intensity and phase of the optical field. Reservoir computing is a bio-inspired approach especially suited for processing time-dependent information. The reservoir’s complex and high-dimensional transient response to the input signal is capable of universal computation. The reservoir {{does not need to}} be trained, which makes it very well suited for optics. As such, much of the promise of photonic reservoirs lies in their minimal hardware requirements, a tremendous advantage over other hardware-intensive neural network models. We review the two main approaches to optical reservoir computing: networks implemented with multiple discrete optical nodes and the continuous system of a single nonlinear device coupled to delayed feedback...|$|R
50|$|Neuromorphic engineering, {{also known}} as <b>neuromorphic</b> <b>computing,</b> is a concept {{developed}} by Carver Mead, in the late 1980s, describing the use of very-large-scale integration (VLSI) systems containing electronic analog circuits to mimic neuro-biological architectures present in the nervous system. In recent times the term neuromorphic {{has been used to}} describe analog, digital, mixed-mode analog/digital VLSI, and software systems that implement models of neural systems (for perception, motor control, or multisensory integration). The implementation of <b>neuromorphic</b> <b>computing</b> on the hardware level can be realized by oxide-based memristors, threshold switches, and transistors.|$|E
50|$|Crossbar latches {{have been}} {{suggested}} as components of <b>neuromorphic</b> <b>computing</b> systems. One implementation of {{this is in the}} form of a neural network formed from nanowires as discussed in a patent by Greg Snider of Hewlett-Packard.|$|E
5000|$|Neuromemristive {{systems are}} a {{subclass}} of <b>neuromorphic</b> <b>computing</b> systems {{that focus on}} the use of memristors to implement neuroplasticity. While neuromorphic engineering focuses on mimicking biological behavior, neuromemristive systems focus on abstraction. [...] For example, a neuromemristive system may replace the details of a cortical microcircuit's behavior with an abstract neural network model.|$|E
40|$|This is {{the final}} version of the article. Available from E via the URL in this record. <b>Neuromorphic,</b> or brain-like, <b>computing</b> {{applications}} of phase-change devices have to date concentrated primarily on the implementation of phase-change synapses. However, a phase-change device can also mimic the integrative properties of a biological neuron. Here we demonstrate, using both physical and circuit modelling, that by combining a phase-change memory device with a simple external circuit we can readily deliver a self-resetting spiking phase-change neuron...|$|R
40|$|Electrooptic {{modulation}} {{performs the}} conversion between the electrical and optical domain with applications in data communication for optical interconnects, {{but also for}} novel optical compute algorithms such as providing nonlinearity at the output stage of optical perceptrons in <b>neuromorphic</b> analogue optical <b>computing.</b> Since the clock frequency for photonics on chip has a power overhead sweet slot around 10 s of GHz, ultrafast modulation may only be required in long distance communication, but not for short onchip links. Here we show a roadmap towards atto Joule per bit efficient modulators on chip {{as well as some}} experimental demonstrations of novel plasmon modulators with sub 1 fJ per bit efficiencies. We then discuss the first experimental demonstration of a photon plasmon-hybrid Graphene-based electroabsorption modulator on silicon. The device shows a sub 1 V steep switching enabled by near ideal electrostatics delivering a high 0. 05 dB per V um performance requiring only 110 aJ per bit. Improving on this design, we discuss a plasmonic slot based Graphene modulator design, where the polarization of the plasmonic mode matches with Graphenes inplane dimension. Here a push pull dual gating scheme enables 2 dB per V um efficient modulation allowing the device to be just 770 nm short for 3 dB small signal modulation. This in turn allows for a device-enabled two orders of magnitude improvement of electrical optical co integrated network on chips over electronic only architectures. The latter opens technological opportunities in in cognitive computing, dynamic data-driven applications system, and optical analogue compute engines to include <b>neuromorphic</b> photonic <b>computing...</b>|$|R
40|$|Resistive {{switching}} memories (RRAMs) are {{an emerging}} research field, {{which is currently}} of focused interest for both the interdisciplinary scientific community and industry. RRAMs are nano-electrochemical systems with great potential as a disruptive technology for the semiconductor industry {{as well as for}} a number of applications such as memory, logic and analog circuits, memristive operations, <b>neuromorphic</b> applications and <b>computing.</b> The present review aims to present the current state-of-the-art knowledge on redox-based resistive switching RRAMs, highlighting the role of the interfaces, discussing the electrochemical kinetics during formation of nanofilaments, and to relate them to the more fundamental issue of microscopic description of electrochemical processes at the atomic scale...|$|R
5000|$|Computational {{devices were}} created in CMOS, for both biophysical {{simulation}} and <b>neuromorphic</b> <b>computing.</b> Nanodevices for very large scale principal components analyses and convolution may create {{a new class of}} neural computing because they are fundamentally analog rather than digital (even though the first implementations may use digital devices.) Ciresan and colleagues (2010) in Schmidhuber's group showed that despite the vanishing gradient problem, GPUs makes back-propagation feasible for many-layered feedforward neural networks.|$|E
50|$|Another {{implementation}} is the TrueNorth processor from IBM. This processor contains 5.4 billion transistors, but {{is designed}} to consume very little power, only 70 milliwatts; most processors in personal computers contain about 1.4 billion transistors and require 35 watts or more. IBM refers to the design principle behind TrueNorth as <b>neuromorphic</b> <b>computing.</b> Its primary purpose is pattern recognition; while critics say the chip isn't powerful enough, its supporters {{point out that this}} is only the first generation, and the capabilities of improved iterations will become clear.|$|E
50|$|Constructing SDM from Spiking Neurons: Despite the {{biological}} likeness of SDM {{most of the}} work undertaken to demonstrate its capabilities to date has used highly artificial neuron models which abstract away the actual behaviour of neurons in the brain. Recent work by Steve Furber's lab at the University of Manchester proposed adaptations to SDM, e.g. by incorporating N-of-M rank codes into how populations of neurons may encode information—which may make it possible to build an SDM variant from biologically plausible components. This work has been incorporated into SpiNNaker (Spiking Neural Network Architecture) which is being used as the <b>Neuromorphic</b> <b>Computing</b> Platform for the Human Brain Project.|$|E
40|$|Abstract Several unique {{properties}} of biological systems, such as adaptation to nat-ural environment, or of animals to learn patterns when appropriately trained, are {{features that are}} extremely useful, if emulated by electronic circuits, in applications ranging from robotics to solution of complex optimization problems, traffic con-trol, etc. In this chapter, we discuss several examples of biologically-inspired cir-cuits that take advantage of memory circuit elements, namely, electronic elements whose resistive, capacitive or inductive characteristics depend on their past dynam-ics. We provide several illustrations {{of what can be}} accomplished with these ele-ments including learning circuits and related adaptive filters, <b>neuromorphic</b> and cel-lular <b>computing</b> circuits, analog massively-parallel computation architectures, etc. We also give examples of experimental realizations of memory circuit elements and discuss opportunities and challenges in this new field. ...|$|R
40|$|This {{project is}} focused on the {{application}} of new electronic and optical materials. In particular it involves examining the use of chalcogenide thin films as phase change and ion conducting glasses for emerging optoelectronic applications. The ability of this group of materials to easily change their state from glass to crystal has meant that they have been widely used in CD's and DVDs. However, their ability to also conduct electrons and ions, promises novel solutions for next generation logic and memory devices which will take us in the short term beyond the limits of the silicon chip and, into the world of <b>neuromorphic</b> cognitive <b>computing</b> (computers that think and adapt). Additionally, this reversible change in the structure of these thin films allows their utilisation in ultra-high speed optical and optoelectronic switches to power the internet and future computers. Three main goals are pursued within this research. First, next generation phase change (PCRAM) and nano-ionic resistive (ReRAM) memory is pursued for faster, non-volatile high density data storage. Secondly, the design of novel processing elements like next generation logic gates enabling neuromorphic cognitive processing and data storage in one structure based on material properties. Finally, the integration of phase change thin films with metamaterial arrays to produce electro-optic and all optical switches for future photonic computers and communication networks...|$|R
40|$|Several {{abilities}} of biological systems, such as adaptation to natural environment, or of animals to learn patterns when appropriately trained, are {{features that are}} extremely useful, if emulated by electronic circuits, in applications ranging from robotics to solution of complex optimization problems, traffic control, etc. In this chapter, we discuss several examples of biologically-inspired circuits that take advantage of memory circuit elements, namely, electronic elements whose resistive, capacitive or inductive characteristics depend on their past dynamics. We provide several illustrations {{of what can be}} accomplished with these elements including learning circuits and related adaptive filters, <b>neuromorphic</b> and cellular <b>computing</b> circuits, analog massively-parallel computation architectures, etc. We also give examples of experimental realizations of memory circuit elements and discuss opportunities and challenges in this new field. Comment: To be published in "Advances in Neuromorphic Memristor Science and Applications" (Springer), edited by R. Kozma, R. Pino, G. Pazienz...|$|R
40|$|<b>Neuromorphic</b> <b>computing</b> {{has come}} {{to refer to a}} variety of brain-inspired computers, devices, and models that {{contrast}} the pervasive von Neumann computer architecture. This biologically inspired approach has created highly connected synthetic neurons and synapses {{that can be used to}} model neuroscience theories as well as solve challenging machine learning problems. The promise of the technology is to create a brain-like ability to learn and adapt, but the technical challenges are significant, starting with an accurate neuroscience model of how the brain works, to finding materials and engineering breakthroughs to build devices to support these models, to creating a programming framework so the systems can learn, to creating applications with brain-like capabilities. In this work, we provide a comprehensive survey of the research and motivations for <b>neuromorphic</b> <b>computing</b> over its history. We begin with a 35 -year review of the motivations and drivers of <b>neuromorphic</b> <b>computing,</b> then look at the major research areas of the field, which we define as neuro-inspired models, algorithms and learning approaches, hardware and devices, supporting systems, and finally applications. We conclude with a broad discussion on the major research topics that need to be addressed in the coming years to see the promise of <b>neuromorphic</b> <b>computing</b> fulfilled. The goals of this work are to provide an exhaustive review of the research conducted in <b>neuromorphic</b> <b>computing</b> since the inception of the term, and to motivate further work by illuminating gaps in the field where new research is needed...|$|E
40|$|In {{nowadays}} {{big data}} environment, the conventional computing platform based on von Neumann architecture encounters the bottleneck {{of the increasing}} requirement of computation capability and efficiency. The “brain-inspired computing” <b>Neuromorphic</b> <b>Computing</b> has demonstrated great potential to revolutionize the technology world. It is considered {{as one of the}} most promising solutions by achieving tremendous computing and power efficiency on a single chip. The <b>neuromorphic</b> <b>computing</b> systems represent great promise for many scientific and intelligent applications. Many designs have been proposed and realized with traditional CMOS technology, however, the progress is slow. Recently, the rebirth of <b>neuromorphic</b> <b>computing</b> is inspired by the development of novel nanotechnology. In this thesis, I propose <b>neuromorphic</b> <b>computing</b> systems with the ReRAM (Memristor) crossbar array. It includes the work in three major parts: 1) Memristor devices modeling and related circuits design in resistive memory (ReRAM) technology by investigating their physical mechanism, statistical analysis, and intrinsic challenges. A weighted sensing scheme which assigns different weights to the cells on different bit lines was proposed. The area/power overhead of peripheral circuitry was effectively reduced while minimizing the amplitude of sneak paths. 2) <b>Neuromorphic</b> <b>computing</b> system designs by leveraging memristor devices and algorithm scaling in neural network and machine learning algorithms based on the similarity between memristive effect and biological synaptic behavior. First, a spiking neural network (SNN) with a rate coding model was developed in algorithm level and then mapped to hardware design for supervised learning. In addition, to further speed and accuracy improvement, another neuromorphic system adopting analog input signals with different voltage amplitude and a current sensing scheme was built. Moreover, the use of a single memristor crossbar for each neural net- work layer was explored. 3) The application-specific optimization for further reliability improvement of the developed neuromorphic systems. In this thesis, the impact of device failure on the memristor-based <b>neuromorphic</b> <b>computing</b> systems for cognitive applications was evaluated. Then, a retraining and a remapping design in algorithm level and hardware level were developed to rescue the large accuracy loss...|$|E
40|$|Dynamics, {{control and}} {{information}} in delay-coupled systems’. Subject Areas: complexity, optics, chaos theory, differential equations Keywords: nonlinear delay dynamics, electro-optic delay oscillators, chaos, microwave optoelectronic oscillators, photonic <b>neuromorphic</b> <b>computing,</b> reservoir computing Author for correspondence...|$|E
40|$|Resistive {{switches}} are {{non-volatile memory}} cells based on nano-ionic redox processes that offer energy efficient device architectures and open pathways to <b>neuromorphics</b> and cognitive <b>computing.</b> However, channel formation typically requires an irreversible, not well controlled electroforming process, giving difficulty to independently control ionic and electronic properties. The device performance is also {{limited by the}} incomplete understanding of the underlying mechanisms. Here, we report a novel memristive model material system based on self-assembled Sm-doped CeO 2 and SrTiO 3 films that allow the separate tailoring of nanoscale ionic and electronic channels at high density (similar to 10 (12) inch(- 2)). We systematically show that these devices allow precise engineering of the resistance states, thus enabling large on-off ratios and high reproducibility. The tunable structure presents an ideal platform to explore ionic and electronic mechanisms and we expect a wide potential impact also on other nascent technologies, ranging from ionic gating to micro-solid oxide fuel cells and neuromorphics...|$|R
40|$|The authors gratefully {{acknowledge}} {{financial support from}} the European Union [FPVII (2007 - 2013) under Grant Agreement No. 318287 Landauer], {{as well as the}} state of Bavaria. We present optically and electrically tunable conductance modifications of a site-controlled quantum-dot memristor. The conductance of the device is tuned by electron localization on a quantum dot. The control of the conductance with voltage and low-power light pulses enables applications in <b>neuromorphic</b> and arithmetic <b>computing.</b> As in neural networks, applying pre- and postsynaptic voltage pulses to the memristor allows us to increase (potentiation) or decrease (depression) the conductance by tuning the time difference between the electrical pulses. Exploiting state-dependent thresholds for potentiation and depression, we are able to demonstrate a memory-dependent induction of learning. The discharging of the quantum dot can further be induced by low-power light pulses in the nanowatt range. In combination with the state-dependent threshold voltage for discharging, this enables applications as generic building blocks to perform arithmetic operations in bases ranging from binary to decimal with low-power optical excitation. Our findings allow the realization of optoelectronic memristor-based synapses in artificial neural networks with a memory-dependent induction of learning and enhanced functionality by performing arithmetic operations. PostprintPeer reviewe...|$|R
40|$|The {{real time}} {{computation}} of motion from real images using a single chip with integrated sensors {{is a hard}} prob-lem. We present two analog VLSI schemes that use pulse domain <b>neuromorphic</b> circuits to <b>compute</b> motion. Pulses of variable width, rather than graded potentials, represent a natural medium for evaluating temporal relationships. Both algorithms measure speed by timing a moving edge in the image. Our first model is inspired by Reichardt's algorithm in the fiy and yields a non-monotonic response vs. velocity curve. We present data from a chip that implements this model. Our second algorithm yields a monotonic response vs. velocity curve and is currently being translated into silicon. 1 Introd uction Analog VLSI chips for the real time computation of visual motion have {{been the focus of}} much active research because of their importance as sensors for robotic applications. Correlation schemes such as those described in (Delbriick, 1993) {{have been found to be}} more robust than gradient schemes described in (Tanner and Mead, 1986), because they do not involve noise-sensitive operations like spatial-differentiation and division. A comparison of four experimental schemes may be found in (Horiuchi et al., 1992). In spite of years of work, however, there is still no motion chip that robustly computes motion under all environmental conditions...|$|R
40|$|Memristors are a {{new type}} of devices that act as linear {{resistors}} at low voltages, but can be programmed to higher or lower resistances when certain pulses are applied. The <b>neuromorphic</b> <b>computing</b> group at Boise State has been using square pulses to program memristors and now wants to investigate how STDP (spike-timing-dependent-plasticity) can be used to program memristive devices. Because STDP is thought to be the mechanism with which the synapses in our brains are stimulated and “programmed,” using STDP pulses is an attractive option for use in <b>neuromorphic</b> <b>computing</b> applications that are inspired by how the brain works. Simulations using Matlab and Cadence were performed to see how the shape of STDP pulses changed how memristors were programmed. A programmer capable of sending STDP pulses several microseconds long to a memristor was designed and built using an FPGA, high-speed data card, and custom circuit. The memristor programmer will be used by the <b>neuromorphic</b> <b>computing</b> group to investigate the effects of STDP on memristors and to improve their memristor model...|$|E
40|$|Resistive switches, {{commonly}} referred to as resistive memory (RRAM) devices and modeled as memristors, are an emerging nanoscale technology that can revolutionize data storage and computing approaches. Enabled by the advancement of nanoscale semiconductor fabrication and detailed understanding of the physical and chemical processes occurring at the atomic scale, resistive switches offer high speed, low-power, and extremely dense nonvolatile data storage. Further, the analog capabilities of resistive switching devices enables <b>neuromorphic</b> <b>computing</b> approaches which can achieve massively parallel computation with a power and area budget that is orders of magnitude lower than today’s conventional, digital approaches. This dissertation presents the investigation of tungsten oxide based resistive switching devices for use in <b>neuromorphic</b> <b>computing</b> applications. Device structure, fabrication, and integration are described and physical models are developed to describe the behavior of the devices. These models are used to develop array-scale simulations in support of <b>neuromorphic</b> <b>computing</b> approaches. Several signal processing algorithms are adapted for acceleration using arrays of resistive switches. Both simulation and experimental results are reported. Finally, guiding principles and proposals for future work are discussed...|$|E
40|$|Using simple fiber {{networks}} for proof-of-principle demonstrations, we give examples of natural computing in linear optical networks, like solving polynomial (P) and nondeterministic polynomial (NP) problems, and in nonlinear optical networks, like metaheuristic optimization and <b>neuromorphic</b> <b>computing...</b>|$|E
40|$|This {{work has}} been {{supported}} by the European FACETS-ITN project. Within the frameworkof this project, we contribute to the simulation of cortical cell types (employingexperimental electrophysiological data of these cells as references), using a specific VLSIneural circuit to simulate, at the single cell level, the models studied as references in theFACETS project. The real-time intrinsic properties of the <b>neuromorphic</b> circuits, whichprecisely <b>compute</b> neuron conductance-based models, will allow a systematic and detailedexploration of the models, while the physical and analog aspect of the simulations, as opposedthe software simulation aspect, will provide inputs {{for the development of}} the neuralhardware at the network level. The second goal of this thesis is to contribute to the designof a mixed hardware-software platform (PAX), specifically designed to simulate spikingneural networks. The tasks performed during this thesis project included: 1) the methodsused to obtain the appropriate parameter sets of the cortical neuron models that can beimplemented in our analog neuromimetic chip (the parameter extraction steps was validatedusing a bifurcation analysis that shows that the simplified HH model implementedin our silicon neuron shares the dynamics of the HH model); 2) the fully customizablefitting method, in voltage-clamp mode, to tune our neuromimetic integrated circuits usinga metaheuristic algorithm; 3) the contribution to the development of the PAX systemin terms of software tools and a VHDL driver interface for neuron configuration in theplatform. Finally, it also addresses the issue of synaptic tuning for future SNN simulation. Ces travaux ont été menés dans le cadre du projet européen FACETS-ITN. Nous avons contribué à la simulation de cellules corticales grâce à des données expérimentales d'électrophysiologie comme référence et d'un circuit intégré neuromorphique comme simulateur. Les propriétés intrinsèques temps réel de nos circuits neuromorphiques à base de modèles à conductance, autorisent une exploration détaillée des différents types de neurones. L'aspect analogique des circuits intégrés permet le développement d'un simulateur matériel temps réel à l'échelle du réseau. Le deuxième objectif de cette thèse est donc de contribuer au développement d'une plate-forme mixte - matérielle et logicielle - dédiée à la simulation de réseaux de neurones impulsionnels...|$|R
40|$|Abstract—This paper {{reviews the}} {{potential}} of spin-transfer torque devices {{as an alternative to}} complementary metal–oxide–semiconductor for non-von Neumann and non-Boolean computing. Recent experiments on spin-transfer torque devices have demonstrated high-speed magnetization switching of nanoscale magnets with small current densities. Coupled with other properties, such as nonvolatility, zero leakage current, high integration density, we discuss that the spin-transfer torque devices can be inherently suitable for some unconventional computing models for information processing. We review several spintronic devices in which magnetization can be manipulated by current induced spin transfer torque and explore their applications in <b>neuromorphic</b> <b>computing</b> and reconfigurable memory-based computing. Index Terms—Domain wall motion, in-memory computing, magnetic tunnel junction, <b>neuromorphic</b> <b>computing,</b> spin torque oscillator, spin transfer torque. I...|$|E
40|$|The {{performance}} of digital computers {{has begun to}} saturate due to material, size, and power limitations. In addition to solving these dilemmas, new computing paradigms are being investigated. This thesis explores <b>neuromorphic</b> <b>computing</b> as a possible new computational paradigm, specifically an all hardware approach based on biological neural processing. This thesis introduces <b>neuromorphic</b> <b>computing,</b> neurobiology, memristive devices for <b>neuromorphic</b> <b>computing,</b> and the memristive material lithium niobite (LiNbO 2). It then discusses the synthesis of lithium niobite by room temperature sputtering {{as well as some}} basic physical, optical, chemical, and electrical properties and explores more complex properties of lithium niobite including the effects of high energy radiation on lithium niobite devices and the effects of light interacting with the mobile ions in lithium niobite. The thesis discusses three devices useful for mimicking sub-structures within a biological neuron. These devices are two-terminal lithium niobite memristors, lithium niobite based batteries, and a new memdiode based on Nb 2 O 5. The thesis concludes by discussing device models for lithium niobite memristors and their application in several neuromorphic circuits to add biologically realistic behavior without increasing the complexity of the circuit. Ph. D...|$|E
40|$|Memristors {{have been}} {{extensively}} studied for nonvolatile memory storage, <b>neuromorphic</b> <b>computing,</b> and logic applications. Particularly, synapse emulation {{is viewed as}} a key step to realizing <b>neuromorphic</b> <b>computing,</b> because the biological synapse is the basic unit for learning and memory. In this study, a memristor with the simple structure of Ta/viologen diperchlorate [EV(ClO 4) (2) ]/terpyridyl-iron polymer (TPy-Fe) /ITO is fabricated to simulate the functions of the synapse. Essential synaptic plasticity and learning behaviours are emulated by using this memristor, such as spike-timing-dependent plasticity and spike-rate-dependent plasticity. It is demonstrated that the redox between a terpyridyl-iron polymer and viologen species leads to our memristor behavior. Furthermore, the learning behavior depending on different amplitudes of voltage pulses is investigated as well. These demonstrations help pave the way for building bioinspired neuromorphic systems based on memristors...|$|E
40|$|In recent year, {{heterogeneous}} architecture {{emerges as}} a promising technology to conquer the constraints in homogeneous multi-core architecture, such as supply voltage scaling, off-chip communication bandwidth, and application parallelism. Various forms of accelerators, e. g., GPU and ASIC, have been extensively studied for their tradeoffs between computation efficiency and adaptivity. But with the increasing demand of the capacity and the technology scaling, accelerators also face limitations on cost-efficiency due {{to the use of}} traditional memory technologies and architecture design. Emerging memory has become a promising memory technology to inspire some new designs by replacing traditional memory technologies in modern computer system. In this dissertation, I will first summarize my research on the application of Spin-transfer torque random access memory (STT-RAM) in GPU memory hierarchy, which offers simple cell structure and non-volatility to enable much smaller cell area than SRAM and almost zero standby power. Then I will introduce my research about memristor implementation as the computation component in the <b>neuromorphic</b> <b>computing</b> accelerator, which has the similarity between the programmable resistance state of memristors and the variable synaptic strengths of biological synapses to simplify the realization of neural network model. At last, a dedicated interconnection network design for multicore <b>neuromorphic</b> <b>computing</b> system will be presented to reduce the prominent average latency and power consumption brought by NoC in a large size <b>neuromorphic</b> <b>computing</b> system...|$|E
30|$|There {{have been}} several new {{breakthroughs}} with RRAM architectures and applications. Among them noteworthy in case of architectures {{is the use of}} materials such as graphene, amorphous carbon films, transition metal dichalcogenides (TMDs), black phosphorous in a RRAM device. <b>Neuromorphic</b> <b>computing</b> is a novel application scheme for RRAM devices which utilize the memory retention property to use them as synapse devices.|$|E
40|$|We {{present a}} new {{electronic}} synapse for <b>neuromorphic</b> <b>computing</b> {{consisting of a}} 1 T 1 R structure based on HfO 2 RRAM technology, and capable of STDP and pattern learning. Power consumption is reduced by adopting short POST spike and burst-mode integration. MNIST classification shows promising learning and classification efficiency. These results support RRAM as an enabling technology for low-power neuromorphic hardware...|$|E
40|$|Inspired by {{the fact}} that human brain is much more {{efficient}} than any nowadays computers, <b>neuromorphic</b> <b>computing</b> is aim at performing near human brain ability of processing huge amount of data in an extreme short time. For the hardware part, <b>neuromorphic</b> <b>computing</b> is also extended to systems facilitating the computation of neural network and machine learning algorithms. Recently, IBM Neurosynaptic system is one of the well-known project that dedicated on energy-efficient neural network applications. However, However, one of the known issues in TrueNorth design is the limited precision of synaptic weights, each of which can be selected from only four integers. To improve the computation accuracy and reduce the incurred hardware cost, in this work, we investigate seven different regularization functions in the cost function of the learning process on TrueNorth platform. Our experimental results proved that the proposed techniques considerably improve the computation accuracy of TrueNorth platform and reduce the incurred hardware and performance overheads...|$|E
40|$|Deep neural {{networks}} {{have been demonstrated}} impressive results in various cognitive tasks such as object detection and image classification. In order to execute large networks, Von Neumann computers store {{the large number of}} weight parameters in external memories, and processing elements are timed-shared, which leads to power-hungry I/O operations and processing bottlenecks. This paper describes a <b>neuromorphic</b> <b>computing</b> system that is designed from the ground up for the energy-efficient evaluation of large-scale {{neural networks}}. The computing system consists of a non-conventional compiler, a neuromorphic architecture, and a space-efficient microarchitecture that leverages existing integrated circuit design methodologies. The compiler factorizes a trained, feedforward network into a sparsely connected network, compresses the weights linearly, and generates a time delay neural network reducing the number of connections. The connections and units in the simplified network are mapped to silicon synapses and neurons. We demonstrate an implementation of the <b>neuromorphic</b> <b>computing</b> system based on a field-programmable gate array that performs the MNIST hand-written digit classification with 97. 64 % accuracy...|$|E
