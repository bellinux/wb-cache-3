14|10000|Public
5000|$|... #Caption: <b>Near</b> <b>infrared</b> <b>image</b> of the LCROSS Centaur {{separation}} as {{seen from}} the LCROSS Shepherding Spacecraft ...|$|E
50|$|Iris and Face Recognition from Portal Video: {{the goal}} is to develop {{algorithms}} that recognize people from <b>near</b> <b>infrared</b> <b>image</b> sequences and high definition video sequences. The sequences will be acquired as people walk through a portal.|$|E
40|$|Abstract. In {{the process}} of the {{high-power}} fiber laser welding, the weld pool feature is related to welding quality. Here, a <b>near</b> <b>infrared</b> <b>image</b> acquisition system was used to acquire the weld pool information. After acquiring the weld pool regional image, the methods such as filtering image denoising, image enhancement, morphological processing and image segmentation were applied to analyze the weld pool feature information. It offered a reliable visual information method for monitoring of welding quality...|$|E
5000|$|James Webb Space Telescope (JWST) Fine Guidance Sensor and <b>Near</b> <b>Infrared</b> <b>Imaging</b> and Slitless Spectrograph ...|$|R
40|$|Abstract—Visible {{images are}} usually merged with {{midrange}} <b>infrared</b> <b>images</b> for surveillance enhancement or for non visual tasks like face recognition. The IR images contain {{information that is}} not the same as in the visible range images. We test fusion of <b>near</b> <b>infrared</b> <b>images</b> with visible spectrum images for detail enhancement and contrast highlighting using several quality metrics. It is shown that computationally light fusion methods can be utilized for visual enhancement. PCA based approach produces promising results for low ambient light images merged with flash <b>near</b> <b>infrared</b> <b>images.</b> I...|$|R
40|$|We {{showed that}} radar can provide {{valuable}} insight in crop development. There {{is a strong}} relationship between radar and the vegetation index NDVI, which is derived from visible and <b>near</b> <b>infrared</b> <b>images.</b> With radar we can fill the gaps present in visible and <b>near</b> <b>infrared</b> <b>images</b> due to cloud cover. It is shown that dual-polarized radars are evenly capable of monitoring crops as quad-polarized radars. For ESA's Sentinel- 1 constellation (dual polarized) this shows great potential. Water ResourcesWater ManagementCivil Engineering and Geoscience...|$|R
40|$|This study {{aimed to}} the {{definition}} of a conservation strategy for burned/charred documents of Arquivo Histórico do Museu Bocage, which survived the Escola Politécnica fire, in 1978, in the custody of the Museu Nacional de História Natural e da Ciência, Lisbon. Two different intervention approaches will be presented and discussed: the use of non-invasive methods such as <b>near</b> <b>infrared</b> <b>image</b> for information retrieval; and the use of conservation and restoration methods for the physical recovery of the support, proposing an intervention protocol...|$|E
40|$|Abstract. Using {{airborne}} multispectral {{digital camera}} imagery, we compared {{a number of}} feature combination techniques in image classification to distinguish vineyard from non-vineyard land-cover types in northern California. Image processing techniques were applied to raw images to generate feature images including grey level co-occurrence based texture measures, low pass and Laplacian filtering results, Gram-Schmidt orthogonalization, principal components, and normalized difference vegetation index (NDVI). We used the maximum likelihood classifier for image classification. Accuracy assessment is performed using digitized boundaries of the vineyard blocks. The most successful classification as determined by t-tests of the Kappa coefficients was achieved based {{on the use of}} a texture image of homogeneity obtained from the <b>near</b> <b>infrared</b> <b>image</b> band, NDVI and brightness generated through orthogonalization analysis. This method averaged an overall accuracy of 81 per cent for six frames of images tested. With post-classification morphological processing (clumping and sieving) the overall accuracy was significantly increased to 87 per cent (with a confidence level of 0. 99). 1...|$|E
40|$|Recently with {{development}} of computer imaging, the application field of <b>near</b> <b>infrared</b> <b>image</b> processing becomes much wider. The potential of machine vision application in {{the determination of}} alkaloid in Dioscorea hispida rhizome was explored. A camera vision system used in this research is TETRACAM multispectral camera, which consists of three bands, namely red band (R), green band (G) and near infrared band (NIR). The first component is the hardware component that functions as an image acquisitioned for the system. The second component is the software part which converts data obtained from the hardware. From the design review, the images {{from a variety of}} harvested of Dioscorea hispida will be captured and the readings in multispectral wavelength index were tabulated. The statistical relationship between multispectral wavelength and alkaloid level in the fruit were determined. The development on this study is grouped as non destructive method to determine the dioscorine content {{which is one of the}} alkaloid components in the rhizome of Dioscorea hispida. </em...|$|E
50|$|The Chandra X-ray Observatory {{identified}} in 1999 more than 200 new point sources. Another space telescope, the Spitzer Space Telescope, found a parallelogram-shaped structure of dust in <b>near</b> <b>infrared</b> <b>images</b> of Centaurus A in 2006.|$|R
40|$|Double bars {{have been}} {{proposed}} {{as a means of}} transporting molecular gas past inner Lindblad resonances into the nuclear regions, where it can fuel active or starburst nuclei. Thus far, the existence of double bars has been determined predominantly through analysis of <b>near</b> <b>infrared</b> <b>images,</b> which can tell us little about the dynamics and inflow rates of these systems. We have observed two double bar galaxy candidates (NGC 2273 and NGC 5728) in 12 CO J= 1 − 0 with the Owens Valley Radio Observatory Millimeter Array. Despite the similarity in the <b>near</b> <b>infrared</b> <b>images</b> of these galaxies, we see rather different nuclear morphologies in the CO maps. NGC 2273 shows evidence of a nuclear gas bar, aligned with the nuclear stellar bar seen in the <b>near</b> <b>infrared</b> <b>images.</b> Both the nuclear gaseous and stellar bars are misaligned from the large scale bar by ∼ 90 ◦, which also allows the possibility that both are the result of stars and gas populating the x 2 orbits of the primary bar. Estimates using dynamical friction arguments and star formation rates suggest significant gas inflow rates along the nuclear ba...|$|R
40|$|<b>Near</b> <b>infrared</b> <b>images</b> are {{presented}} of the Herbig-Haro 110 jet centered {{at the molecular}} hydrogen lines. The ratio of these lines provides a preliminary diagnostic of molecular gas excitation, which is expected from low velocity shocks and turbulent processes. It is suggested that the morphological properties of the molecular hydrogen emission are consistent {{with that of a}} boundary layer...|$|R
40|$|Heterogeneous face {{recognition}} (HFR) refers to matching face images acquired from different sources (i. e., different sensors or different wavelengths) for identification. HFR {{plays an important}} role in both biometrics research and industry. In spite of promising progresses achieved in recent years, HFR is still a challenging problem due to the difficulty to represent two heterogeneous images in a homogeneous manner. Existing HFR methods either represent an image ignoring the spatial information, or rely on a transformation procedure which complicates the recognition task. Considering these problems, we propose a novel graphical representation based HFR method (G-HFR) in this paper. Markov networks are employed to represent heterogeneous image patches separately, which takes the spatial compatibility between neighboring image patches into consideration. A coupled representation similarity metric (CRSM) is designed to measure the similarity between obtained graphical representations. Extensive experiments conducted on multiple HFR scenarios (viewed sketch, forensic sketch, <b>near</b> <b>infrared</b> <b>image,</b> and thermal infrared image) show that the proposed method outperforms state-of-the-art methods. Comment: 13 pages, 10 figures, TPAMI 2016 accepte...|$|E
40|$|Human perceptual {{performance}} was tested {{with images of}} nighttime outdoor scenes. The scenes were registered both with a dual band (visual and <b>near</b> <b>infrared)</b> <b>image</b> intensified low-light CCD camera (DII) and with a thermal middle wavelength band (3 - 5 μm) infrared (IR) camera. Fused imagery was produced through a pyramid image merging scheme, in combination with different colour mappings. For all (individual and fused) image modalities, small patches of the scenes, displaying a range of different objects and materials, were briefly presented to human observers. The sensitivity of human observers was tested for different recognition tasks. The results show that greyscale image fusion yields improved performance levels for most perceptual tasks investigated here. When an appropriate colour mapping scheme is applied, the addition of colour to greyscale fused imagery significantly increases observer sensitivity for a given condition and a certain task. However, inappropriate use of colour significantly decreases observer performance compared to straightforward greyscale image fusion. This suggests that colour mapping should adapt to the visual task and the conditions (scene content) at han...|$|E
40|$|Human scene {{recognition}} {{performance was}} tested {{with images of}} night-time outdoor scenes. The scenes were registered both with a dual band (visual and <b>near</b> <b>infrared)</b> <b>image</b> intensified low-light CCD camera (DII) and with a thermal middle wavelength band (3  5 mm) infrared (IR) camera. Fused imagery was produced through a grayscale pyramid image merging scheme, in combination with two different colour mappings. Observer performance was tested {{for each of the}} (individual and fused) image modalities. The results show that DII imagery contributes most to global scene recognition (situational awareness), whereas IR imagery serves best for the detection and recognition of targets like humans and vehicles. Grayscale fused imagery yields appreciable performance levels in most conditions. With an appropriate colour mapping, colour fused imagery yields the best overall scene recognition performance. However, an inappropriate colour mapping significantly decreases observer performance compared to grayscale image fusion. The deployment of a DII system in addition to a 3 - 5 mu IR system through image fusion can increase the performance of human observers when the colour mapping relates {{to the nature of the}} visual task and the conditions (scene content) at hand...|$|E
40|$|The {{majority}} of the iris recognition algorithms available in the literature were developed to operate on <b>near</b> <b>infrared</b> <b>images.</b> A desirable feature of iris recognition systems with reduced constraints such as potential operability on commonly available hardware {{is to work with}} images acquired under visible wavelength. Unlike in <b>near</b> <b>infrared</b> <b>images,</b> in colour iris images the pigment melanin present in the iris tissue causes the appearance of reflections, which are one of the major noise factors present in colour iris images. In this paper we present an iris recognition system which is able to cope with noisy colour iris images by employing score level fusion between different channels of the iris image. The robustness of the proposed approach is tested on three colour iris images datasets, ranging from images captured with professional cameras in both constrained environment and less cooperative scenario, and finally to iris images acquired with a mobile phone...|$|R
50|$|NAIP {{imagery is}} {{acquired}} at a one-meter ground sample distance (GSD) with a horizontal accuracy that matches within six meters of photo-identifiable ground control points. The default spectral resolution is natural color (Red, Green and Blue, or RGB) but beginning in 2007, {{some states have}} been delivered with four bands of data: RGB and <b>Near</b> <b>Infrared.</b> <b>Images</b> have no more than 10% cloud cover per quarter quad tile, weather conditions permitting.|$|R
40|$|We {{reveal the}} stellar light {{emerging}} from the kiloparsec-scale, ring-like structure of the NGC 5128 (Centaurus A) galaxy in unprecedented detail. We use arcsecond-scale resolution <b>near</b> <b>infrared</b> <b>images</b> to create a "dust-free" view of the central region of the galaxy, which we then use to quantify {{the shape of the}} revealed structure. At the resolution of the data, the structure contains several hundreds of discreet, point-like or slightly elongated sources. Typical extinction corrected surface brightness of the structure is K_S = 16. 5 mag/arcsec^ 2, and we estimate the total <b>near</b> <b>infrared</b> luminosity of the structure to be M = - 21 mag. We use diffraction limited (FWHM resolution of ~ 0. 1 ", or 1. 6 pc) <b>near</b> <b>infrared</b> data taken with the NACO instrument on VLT to show that the structure decomposes into thousands of separate, mostly point-like sources. According to the tentative photometry, the most luminous sources have M_K = - 12 mag, naming them red supergiants or relatively low-mass star clusters. We also discuss the large-scale geometry implied by the reddening signatures of dust in our <b>near</b> <b>infrared</b> <b>images.</b> Comment: 5 pages, 4 figures, accepted for publication in A&A Letters. A version with high resolution images can be downloaded from [URL]...|$|R
40|$|The {{main issue}} of vison-based {{automatic}} harvesting manipulators is {{the difficulty in}} the correct fruit identification in the images under natural lighting conditions. Mostly, the solution {{has been based on}} a linear combination of color components in the multispectral images. However, the results have not reached a satisfactory level. To overcome this issue, this paper proposes a robust nonlinear fusion method to augment the original color image with the synchronized <b>near</b> <b>infrared</b> <b>image.</b> The two images are fused with Daubechies wavelet transform (DWT) in a multiscale decomposition approach. With DWT, the background noises are reduced and the necessary image features are enhanced by fusing the color contrast of the color components and the homogeneity of the near infrared (NIR) component. The resulting fused color image is classified with a C-means algorithm for reconstruction. The performance of the proposed approach is evaluated with the statistical F measure in comparison to some existing methods using linear combinations of color components. The results show that the fusion of information in different spectral components has the advantage of enhancing the image quality, therefore improving the classification accuracy in citrus fruit identification in natural lighting conditions...|$|E
40|$|Abstract. During deep {{penetration}} laser welding, {{a keyhole}} is {{formed in the}} molten pool. The characteristics of keyhole {{are related to the}} welding quality and stability. Analyzing the characteristic parameters of a keyhole during high power fiber laser welding is one of effective measures to control the welding quality and improve the welding stability. This paper studies a fiber laser butt-joint welding of type 304 austenitic stainless steel plate with a high power 10 kW continuous wave fiber laser. And an infrared sensitive high-speed video camera was used to capture the dynamic images of the molten pools. A combination filtering system with a filter length of 960 - 990 nm in front of the vision sensor was used to obtain the <b>near</b> <b>infrared</b> <b>image</b> and to eliminate other light disturbances. The width, area, leftmost point, rightmost point, upmost point and the bottommost point of a keyhole were defined as the keyhole characteristic parameters. By using the image preprocessing method, such as median filtering, Wiener filtering, threshold segmentation and Canny edge detection methods, the characteristic parameters of a keyhole were obtained. By analyzing the change of the keyhole characteristic parameters during welding process, it was found that these parameters could reflect the quality and stability of laser welding effectively...|$|E
40|$|Airborne LIght Detection And Ranging (LIDAR) {{provides}} accurate height {{information for}} objects on the earth, which makes LIDAR {{become more and}} more popular in terrain and land surveying. In particular, LIDAR data offer vital and significant features for land-cover classification which is an important task in many application domains. In this paper, an unsupervised approach based on an improved fuzzy Markov random field (FMRF) model is developed, by which the LIDAR data, its co-registered images acquired by optical sensors, i. e. aerial color image and <b>near</b> <b>infrared</b> <b>image,</b> and other derived features are fused effectively to improve the ability of the LIDAR system for the accurate land-cover classification. In the proposed FMRF model-based approach, the spatial contextual information is applied by modeling the image as a Markov random field (MRF), with which the fuzzy logic is introduced simultaneously to reduce the errors caused by the hard classification. Moreover, a Lagrange-Multiplier (LM) algorithm is employed to calculate a maximum A posteriori (MAP) estimate for the classification. The experimental results have proved that fusing the height data and optical images is particularly suited for the land-cover classification. The proposed approach works very well for the classification from airborne LIDAR data fused with its coregistered optical images and the average accuracy is improved to 88. 9...|$|E
40|$|<b>Near</b> <b>infrared</b> multi-spectral <b>image</b> {{analysis}} {{is a tool}} used for non-destructive determination of biological material properties. In this investigation a custom built imaging spectrometer is constructed and used for the image spectra instrumentation and tests are performed on this instrument to determine its spectral resolution and spectral range; a biological data set (moisture in potato crisps) is then captured using this instrument and this data set is modeled using <b>near</b> <b>infrared</b> multi-spectral <b>image</b> analysis. A common problem with <b>near</b> <b>infrared</b> multi-spectral quantitative <b>image</b> measurements is light scatter and light non-linearity resulting from sample shape contours/curvatures and optical aberrations from optical component selection/layout. In this paper we detail an imaging spectrometer {{and the use of}} orthogonal signal correction pre- processing combined with a neural network full spectrum model for measurement of material propert...|$|R
40|$|Discussed are {{the basic}} {{approaches}} reported in literature for atmospheric correction of airborne/spaceborne multispectral (visible to <b>near</b> <b>infrared)</b> <b>images</b> of clear waters pertaining to open ocean conditions, i. e. case I waters according to Morel's classification. The extent of applicability and inherent limitations of such approaches are analyzed and the persisting problems identified. (orig.) 93 refs. SIGLEAvailable from TIB Hannover: RR 1347 (308) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
40|$|This paper details a fully {{automated}} face authentication system using low-cost <b>near</b> <b>infrared</b> imaging. The <b>image</b> normalization step consists of eye center localization, scale correction and orientation correction. This paper investigates the comparison and combination of four face matchers on the automatically normalized face images: elastic bunch graph matching (EBGM), trace transform, PCA, and LDA. The performance evaluation is presented on the <b>near</b> <b>infrared</b> <b>images</b> acquired from the 102 users in two sessions with different pose and expressions. Our experimental results achieve the best results with the EER of 3. 92 % from the EBGM matcher while the combination of results from the different matchers can significantly improve the performance and achieve the EER of 2. 28 %. The <b>near</b> <b>infrared</b> face database developed in this work is also made publicly available to foster further research. 1...|$|R
40|$|For forest inventory, laser {{altimetry}} {{can provide an}} alternative to conventional stereoscopic methods or field measurements to obtain forest stand heights, {{an important factor in}} the inference of numerous other forestry parameters. When the density of LIDAR data becomes high enough, one can think in terms of individual tree heights. New systems could incorporate individual tree crown (ITC) delineation and species recognition from multispectral imagery with ITC-based height measurements from LIDAR data to produce precise, accurate and timely ITC-based forest inventories. Volume and biomass inferences could then be done on an ITC-basis. This study examines three aspects of the synergy between airborne laser altimeter data and multispectral video imagery: (a) the elimination of non-forested or poorly forested areas from the analysis of mature forests, (b) the potential improvements in ITC delineation, and (c), the possibility of a separate ITC analysis of young regenerating areas. A combination of masks generated from multispectral rules and by selecting a minimum LIDAR height led to a very good separation of the forested areas, and even of individual trees in open fields. The ITC delineation process was then applied to the unmasked forested areas, first on a smoothed version of the <b>near</b> <b>infrared</b> <b>image</b> and then, on a smoothed version of th...|$|E
30|$|During {{the recent}} {{conservation}} of the map, the main trade routes {{were found to}} be drawn {{at the back of the}} map [13] (see Fig.  4 in [1]). It was suggested that the trunk routes may have been drawn first before the rest of the map. A detailed examination of the map shows that the trade routes (Fig.  10) and in general the fine ink drawings (Fig.  10) were executed before the colorants were applied. Figure  10 a shows that the trade route is intersected by a white and a dark paint at the top and by dark paints further down. The pattern painted in white has clearly been painted-in uninterrupted by the trade route as shown in the 400  nm (near UV) image (Fig.  10 b) which shows just the top white layer on the surface, while the 880  nm (<b>near</b> <b>infrared)</b> <b>image</b> (Fig.  10 c) shows a faint trace of the trade route under the thinner regions of the white paint (the trade route is better shown as uninterrupted in Fig.  10 d). The dark drawings across the trade route disappears in the 800  nm because they were painted with indigo which is transparent at 880  nm. By comparing the images in Fig.  10, one can deduce that the trade routes were drawn first followed by indigo drawings and then a top layer of white paint. However, this does not answer the question of whether the coastlines or the trade routes were drawn first.|$|E
40|$|The {{addition}} of deep <b>near</b> <b>infrared</b> <b>images</b> to the database {{provided by the}} HDF WFPC 2 is essential to monitor the SEDs of the objects on a wide baseline and address {{a number of key}} issues including the total stellar content of baryonic mass, the effects of dust extinction, the dependence of morphology on the rest frame wavelength, the photometric redshifts, the detection and nature of extremely red objects (EROs). For these reasons deep <b>near</b> <b>infrared</b> <b>images</b> were obtained with the ISAAC instrument at the ESO VLT in the Js, H and Ks bands reaching, respectively, 23. 5, 22. 0, 22. 0 limiting Vega-magnitude (5 σ in an aperture of diameter 1 “. 2 ≡ 2 × FWHM, [3, 4]). 2 A multi-color catalog of the HDF-S A multi-color (F 300, F 450, F 606, F 814, Js, H, Ks) photometric catalog of the HDF-S has been produced [4] developing specific procedures to match HST and VLT data. Having in mind the generation of photometric redshifts we have chosen a conservative approach in the object detection, leading to a list of 1611 sources. After correcting for the incompleteness of the source counts, the objec...|$|R
40|$|This paper {{presents}} a new method for extracting sea-ice {{information from the}} multi-spectral AVHRR images (visible, near-infrared and <b>infrared</b> <b>images)</b> of a TIROS-N/NOAA series satellite. The original image data are calibrated and corrected. The difference in albedo (reflectivity) between visible and <b>near</b> <b>infrared</b> <b>images</b> is obtained. Further, {{the difference in the}} brightness temperature between the 3. 7 and 11 μm <b>infrared</b> <b>images</b> is computed. The resulting images are formed from these two difference images and displayed on the image display using the false color technique. By applying this method to data observed during the daytime, the sea ice area and cloud area can be easily distinguished...|$|R
5|$|The RBV was {{manufactured}} by the Radio Corporation of America (RCA). The RBV obtained visible light and <b>near</b> <b>infrared</b> photographic <b>images</b> of Earth. At launch, the RBV {{was considered the}} primary sensor.|$|R
40|$|We present {{visible and}} {{near-infrared}} {{images of the}} amorphous dwarf galaxy NGC 1705 in the $B$, $V$, $R$, $J$, $H$, and $K$ bands. Optical and <b>near</b> <b>infrared</b> colors in the galaxy are consistent with a composite population with colors {{similar to those of}} the bluest Sc nuclei. The contribution of young stars to the disk population of the galaxy decreases outwards from the center. In the <b>near</b> <b>infrared</b> <b>images</b> we detect three unresolved point sources, two of which have colors and luminosities comparable to intermediate age LMC clusters. Comment: uuencoded compressed tarred postscript including figures. Accepted for publication in AJ...|$|R
40|$|Abstract: An orientation-based face {{recognition}} method is proposed {{and applied to}} <b>near</b> <b>infrared</b> <b>images</b> in this paper. Two algorithms, FPW (face pattern word) and FPB (face pattern byte), are derived from the orientation-based method. The FPW (or FPB) algorithm actually extracts the orientational information using a set of Gabor wavelet transforms, and uses Hamming distance (HD) for face identification. The bit code of orientations are optimized with respect to HD and put into a 32 -bit word (FPW) or 8 -bit byte (FPB). The performance is evaluated by {{face recognition}} rate and compared with three classical algorithms, PCA, LDA and EBGM (elastic bunch graph matching). Our experiments are conducted with a ASUNIR face database that currently consists of <b>near</b> <b>infrared</b> (NIR) <b>images</b> from 79 subjects. The experimental {{results show that the}} FPW algorithm achieves 98. 43 % of recognition rate; while the results of PCA, LDA and EBGM are 74. 68 %, 94. 94 % and 96. 20 %, respectively. ...|$|R
40|$|International audienceThis paper {{presents}} two novel {{image fusion}} schemes for combining visible and <b>near</b> <b>infrared</b> face <b>images</b> (NIR), aiming at improving the verification performance. Sub-band decomposition is first {{performed on the}} visible and NIR images separately. In both cases, we further employ particle swarm optimization (PSO) to find an optimal strategy for performing fusion of the visible and NIR sub-band coefficients. In the first scheme, PSO {{is used to calculate}} the optimum weights of a weighted linear combination of the coefficients. In the second scheme, PSO is used to select an optimal subset of features from visible and <b>near</b> <b>infrared</b> face <b>images.</b> To evaluate and compare the efficacy of the proposed schemes, we have performed extensive verification experiments on the IRVI database. This database was acquired in our laboratory using a new sensor that is capable of acquiring visible and <b>near</b> <b>infrared</b> face <b>images</b> simultaneously thereby avoiding the need for image calibration. The experiments show the strong superiority of our first scheme compared to NIR and score fusion performance, which already showed a good stability to illumination variations...|$|R
40|$|The <b>near</b> <b>infrared</b> {{scattering}} <b>images</b> {{of human}} muscle include some information on bloodstream and hemoglobin concentration according to skin depth and time. This paper addressed {{a method of}} determining oxygen saturation and photoplethysmogram from the <b>near</b> <b>infrared</b> (NIR) scattering <b>images</b> of muscle. Depending on the modified Beer-Lambert Law and the diffuse scattering model of muscular tissue, we determined an extinction coefficient matrix of hemoglobin from the <b>near</b> <b>infrared</b> scattering <b>images</b> and analyzed distribution of oxygen saturation of muscle with a depth from the extinction coefficient matrix. And we determined a dynamic attenuation variation curve with respect to fragmentary image frames sensitive to bloodstream from scattering image frames of muscle with time and then obtained the photoplethysmogram and heart rate by Fourier transformation and inverse transformation. This method based on the NIR scattering images can be applied in measurement of an average oxygen saturation and photoplethysmogram even in local region of optically heterogeneous muscle and skin. Comment: 12 pages, 10 figure...|$|R
40|$|Human {{faces are}} one of the most {{important}} and most popular biometric modalities to recognize individuals in a broad range of applications. So far, Local Binary Patterns have been applied to face recognition based on 2 D illumination <b>images</b> and <b>near</b> <b>infrared</b> <b>images,</b> showing good robustness, discriminative ability and computational efficiency. In this paper, this method is extended to 3 D face images. We investigate the influence of several parameters of this method and show improvements in the recognition rates, proving that this new method is a very promising approach for 3 D face recognition...|$|R
40|$|The {{addition}} of deep <b>near</b> <b>infrared</b> <b>images</b> to the database {{provided by the}} HDF-S WFPC 2 is essential to monitor the SEDs of the objects on a wide baseline and address {{a number of key}} issues including the total stellar content of baryonic mass, the effects of dust extinction, the dependence of morphology on the rest frame wavelength, the photometric redshifts, the detection and nature of extremely red objects (EROs). For these reasons deep <b>near</b> <b>infrared</b> <b>images</b> were obtained with the ISAAC instrument at the ESO VLT in the Js, H and Ks bands reaching, respectively, 23. 5, 22. 0, 22. 0 limiting Vega-magnitude. A multi-color (F 300, F 450, F 606, F 814, Js, H, Ks) photometric catalog of the HDF-S has been produced. Photometric redshifts have been generated both fitting templates to the observed SEDs and with neural network techniques. Spectroscopic observations of the 9 candidates with I_AB < 24. 25 have confirmed all of them to be galaxies with 2 <z< 3. 5. The photometric redshifts for all the galaxies brighter than I_AB< 27. 5 have been used to study the evolution of galaxy clustering in the interval 0 <z< 4. 5. Comment: 2 pages Latex, To appear in the proceedings of "The mass of galaxies at low and high redshift", Venice, Oct 24 - 26, 2001,eds. R. Bender and A. Renzini (ESO Astrophysics Symposia, Springer-Verlag...|$|R
40|$|This paper {{presents}} two novel {{image fusion}} schemes for combining visible and <b>near</b> <b>infrared</b> face <b>images</b> (NIR), aiming at improving the verification performance. Sub-band decomposition is first {{performed on the}} visible and NIR images separately. In both cases, we further employ particle swarm optimization (PSO) to find an optimal strategy for performing fusion of the visible and NIR sub-band coefficients. In the first scheme, PSO {{is used to calculate}} the optimum weights of a weighted linear combination of the coefficients. In the second scheme, PSO is used to select an optimal subset of features from visible and <b>near</b> <b>infrared</b> face <b>images.</b> To evaluate and compare the efficacy of the proposed schemes, we have performed extensive verification experiments on the IRVI database. This database was acquired in our laboratory using a new sensor that is capable of acquiring visible and <b>near</b> <b>infrared</b> face <b>images</b> simultaneously thereby avoiding the need for image calibration. The experiments show the strong superiority of our first scheme compared to NIR and score fusion performance, which already showed a good stability to illumination variations. (C) 2010 Elsevier Ltd. All rights reserved...|$|R
