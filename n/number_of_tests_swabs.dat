0|10000|Public
40|$|Abstract Background Respiratory syncytial virus (RSV) is an {{important}} pathogen that can cause severe illness in infants and young children. In this study, we assessed whether data on RSV collected by the European Influenza Surveillance Scheme (EISS) {{could be used to}} build an RSV surveillance system in Europe. Methods Influenza and RSV data for the 2002 – 2003 winter season were analysed for England, France, the Netherlands and Scotland. Data from sentinel physician networks and other sources, mainly hospitals, were collected. Respiratory specimens were tested for influenza and RSV mainly by virus culture and polymerase chain reaction amplification. Results Data on RSV were entered timely into the EISS database. RSV contributed noticeably to influenza-like illness: in England sentinel RSV detections were common in all age groups, but particularly in young children with 20 (40. 8 %) <b>of</b> the total <b>number</b> <b>of</b> sentinel <b>swabs</b> <b>testing</b> positive for RSV. Scotland and France also reported the highest percentages of RSV detections in the 0 – 4 year age group, respectively 10. 3 % (N = 29) and 12. 2 % (N = 426). In the Netherlands, RSV was detected in one person aged over 65 years. Conclusion We recommend that respiratory specimens collected in influenza surveillance are also tested systematically for RSV and emphasize the use of both community derived data and data from hospitals for RSV surveillance. RSV data from the EISS have been entered in a timely manner and we consider that the EISS model can be used to develop an RSV surveillance system equivalent to the influenza surveillance in Europe. </p...|$|R
25|$|NB - <b>Number</b> <b>of</b> <b>Tests</b> played {{represents}} the <b>number</b> <b>of</b> <b>Tests</b> {{prior to the}} commencement of the series.|$|R
2500|$|The Chief Medical Officer of the WA Health Department, McGillivray, had testified as {{an expert}} witness on the {{recovered}} bone fragments. He identified himself as a bacteriologist with no experience as a forensic expert with his duties for the health department generally consisting <b>of</b> <b>testing</b> <b>swabs</b> for disease and infections (Question 460, sworn evidence of McGillivray). When shown an obvious hip joint he stated that it was [...] "too small to be of a human adult" [...] and when shown what everyone, including Wood, said they recognised {{as part of a}} human jawbone (Maxilla) complete with tooth sockets, McGillivray stated that he did not [...] "think it was human". Initially rejecting the teeth as human, under cross examination he admitted they did not resemble animal teeth so had to be human.|$|R
40|$|Software {{testing is}} a process of ratifying the {{functionality}} of software. It is one of the crucial area which consumes more time and high cost. The time spent on testing is mainly concerned with <b>testing</b> large <b>number</b> <b>of</b> <b>test</b> cases, which are unreliable. Our goal is to reduce the <b>number</b> <b>of</b> <b>test</b> cases and to give reliable test cases. To extract reliable test cases from large <b>number</b> <b>of</b> <b>test</b> cases, clustering algorithm is used which is a data mining approach to reduce the <b>number</b> <b>of</b> <b>test</b> cases...|$|R
40|$|The {{problem of}} fault {{diagnosis}} in multiprocessor systems is considered under a probabilistic fault model. The {{focus is on}} minimizing the <b>number</b> <b>of</b> <b>tests</b> that must be conducted in order to correctly diagnose the state of every processor in the system with high probability. A diagnosis algorithm that can correctly diagnose the state of every processor with probability approaching one {{in a class of}} systems performing slightly greater than a linear <b>number</b> <b>of</b> <b>tests</b> is presented. A nearly matching lower bound on the <b>number</b> <b>of</b> <b>tests</b> required to achieve correct diagnosis in arbitrary systems is also proven. Lower and upper bounds on the <b>number</b> <b>of</b> <b>tests</b> required for regular systems are also presented. A class of regular systems which includes hypercubes is shown to be correctly diagnosable with high probability. In all cases, the <b>number</b> <b>of</b> <b>tests</b> required under this probabilistic model is shown to be significantly less than under a bounded-size fault set model. Because the <b>number</b> <b>of</b> <b>tests</b> that must be conducted {{is a measure of the}} diagnosis overhead, these results represent a dramatic improvement in the performance of system-level diagnosis techniques...|$|R
50|$|The maximum <b>number</b> <b>of</b> <b>test</b> {{cases is}} the Cartesian product of all classes of all classifications in the tree, quickly {{resulting}} {{in large numbers}} for realistic <b>test</b> problems.The minimum <b>number</b> <b>of</b> <b>test</b> cases is the <b>number</b> <b>of</b> classes in the classification with the most containing classes.|$|R
40|$|In this paper, {{the problem}} of fault {{diagnosis}} in multiprocessor sys-tems is considered under a uniformly probabilistic model in which pro-cessors are faulty with probability p. This work focuses on minimizing the <b>number</b> <b>of</b> <b>tests</b> that must be conducted in order to correctly diag-nose the state of every processor in the system with high probability. A diagnosis algorithm that can correctly diagnose the state of every processor with probability approaching one {{in a class of}} systems per-forming slightly greater than a linear <b>number</b> <b>of</b> <b>tests</b> is presented. A nearly matching lower bound on the <b>number</b> <b>of</b> <b>tests</b> required to achieve correct diagnosis in arbitrary systems is also proven. The <b>number</b> <b>of</b> <b>tests</b> required under this probabilistic model is shown to be significantly less than under a bounded-size fault set. model. Because the <b>number</b> <b>of</b> <b>tests</b> that must be conducted {{is a measure of the}} diagnosis overhead, these results represent a dramatic imp_ovement in the performance of system-level diagnosis techniques. ...|$|R
40|$|Abstract—We {{introduce}} a novel probabilistic group testing framework, termed Poisson group testing, {{in which the}} <b>number</b> <b>of</b> defectives follows a right-truncated Poisson distribution. The Poisson model applies to a <b>number</b> <b>of</b> <b>testing</b> scenarios, where the subjects {{are assumed to be}} ordered based on their arrival times and where the probability of being defective decreases with time. For this model, we consider nonadaptive and semi-adaptive methods to identify the defectives. For the nonadaptive methods, we find a lower bound on the <b>number</b> <b>of</b> <b>tests</b> required to identify the defectives with a probability of error that asymptotically con-verges to zero; in addition, we propose test matrix constructions for which the <b>number</b> <b>of</b> <b>tests</b> closely matches the lower bound. For the semi-adaptive methods, we also find a lower bound on the expected <b>number</b> <b>of</b> <b>tests</b> required to identify the defectives with zero error probability. In addition, we propose a stage-wise algorithm for which the expected <b>number</b> <b>of</b> <b>tests</b> tightly matches the lower bound (only a constant factor away). All these methods only require an estimate <b>of</b> the average <b>number</b> <b>of</b> <b>tests</b> and do not make use of individual probabilities of subjects being defective. Index Terms—Adaptive group testing, Binomial group testing, Boolean compressed sensing, Dynamical group testing, Huffma...|$|R
30|$|For each {{application}} we collected, for example, the <b>number</b> <b>of</b> <b>test</b> cases {{required to}} cover 100 % of all-nodes, all-edges and all-uses of each unit (#u.TCs in Table 1) and the <b>number</b> <b>of</b> additional <b>test</b> cases required to cover requirements {{derived from the}} <b>testing</b> criteria <b>of</b> each approach (#ad.TCs in Table 1). Note that in these studies, we targeted optimal test sets with the minimum <b>number</b> <b>of</b> <b>test</b> cases as possible.|$|R
40|$|The all-du-paths {{structural}} testing criterion {{is one of}} {{the most}} discriminating of the data flow testing criteria. Unfortunately, in the worst case, the criterion requires an intractable <b>number</b> <b>of</b> <b>test</b> cases. In a case study of an industrial software system, we find that the worst case scenario is rare. Eighty percent of the subroutines require ten or fewer test cases. Only one subroutine out of 143 requires an intractable <b>number</b> <b>of</b> <b>tests.</b> However, the <b>number</b> <b>of</b> required <b>test</b> cases becomes tractable when using the all-uses criterion. This paper includes a formal specification of both the all-du-paths criterion and the software tools used to estimate a minimal <b>number</b> <b>of</b> <b>test</b> cases necessary to meet the criterion...|$|R
25|$|Note: <b>Number</b> <b>of</b> <b>Tests</b> played {{is given}} in brackets.|$|R
40|$|We {{introduce}} a novel probabilistic group testing framework, termed Poisson group testing, {{in which the}} <b>number</b> <b>of</b> defectives follows a right-truncated Poisson distribution. The Poisson model has a <b>number</b> <b>of</b> new applications, including dynamic testing with diminishing relative rates of defectives. We consider both nonadaptive and semi-adaptive identification methods. For nonadaptive methods, we derive a lower bound on the <b>number</b> <b>of</b> <b>tests</b> required to identify the defectives with a probability of error that asymptotically converges to zero; in addition, we propose test matrix constructions for which the <b>number</b> <b>of</b> <b>tests</b> closely matches the lower bound. For semi-adaptive methods, we describe a lower bound on the expected <b>number</b> <b>of</b> <b>tests</b> required to identify the defectives with zero error probability. In addition, we propose a stage-wise reconstruction algorithm for which the expected <b>number</b> <b>of</b> <b>tests</b> is only a constant factor away from the lower bound. The methods rely only on an estimate <b>of</b> the average <b>number</b> <b>of</b> defectives, {{rather than on the}} individual probabilities of subjects being defective...|$|R
5000|$|... #Subtitle level 4: SAT Subject <b>Tests</b> (and <b>number</b> <b>of</b> <b>test</b> takers) ...|$|R
5000|$|The average <b>number</b> <b>of</b> <b>test</b> cycles until Zero Bug Bounce (ZBB) ...|$|R
40|$|The all-du-paths {{software}} testing criterion {{is the most}} discriminating of the data flow <b>testing</b> criteria <b>of</b> Rapps and Weyuker. Unfortunately, in the worst case, the criterion requires an exponential <b>number</b> <b>of</b> <b>test</b> cases. To investigate the practicality of the criterion, we develop tools to count the <b>number</b> <b>of</b> complete program paths necessary to satisfy the criterion. This count is an estimate <b>of</b> the <b>number</b> <b>of</b> <b>test</b> cases required. In {{a case study of}} an industrial software system, we find that in eighty percent of the subroutines the all-du-paths criterion is satisfied by testing ten or fewer complete paths. Only one subroutine out of 143 requires an exponential <b>number</b> <b>of</b> <b>test</b> cases...|$|R
50|$|The {{courts have}} {{formulated}} a <b>number</b> <b>of</b> <b>tests</b> for drawing the distinction.|$|R
40|$|Group testing with inhibitors (GTI) {{introduced}} by Farach at al. is studied in this paper. There are {{three types of}} items, d defectives, r inhibitors and n-d-r normal items in a population of n items. The presence of any inhibitor in a test can prevent {{the expression of a}} defective. For this model, we propose a probabilistic non-adaptive pooling design with a low complexity decoding algorithm. We show that the sample complexity <b>of</b> the <b>number</b> <b>of</b> <b>tests</b> required for guaranteed recovery with vanishing error probability using the proposed algorithm scales as T=O(d n) and T=O(r^ 2 /d n) in the regimes r=O(d) and d=o(r) respectively. In the former regime, the <b>number</b> <b>of</b> <b>tests</b> meets the lower bound order while in the latter regime, the <b>number</b> <b>of</b> <b>tests</b> is shown to exceed the lower bound order by a r/d multiplicative factor. When only upper bounds on the <b>number</b> <b>of</b> defectives D and the <b>number</b> <b>of</b> inhibitors R are given instead of their exact values, the sample complexity <b>of</b> the <b>number</b> <b>of</b> <b>tests</b> using the proposed algorithm scales as T=O(D n) and T=O(R^ 2 n) in the regimes R^ 2 =O(D) and D=o(R^ 2) respectively. In the former regime, the <b>number</b> <b>of</b> <b>tests</b> meets the lower bound order while in the latter regime, the <b>number</b> <b>of</b> <b>tests</b> exceeds the lower bound order by a R multiplicative factor. The time complexity of the proposed decoding algorithms scale as O(nT). Comment: Updated with results for the case of knowledge of only upper bounds on no. of defectives and inhibitors; 11 pages, 2 figure...|$|R
25|$|Matches is {{the total}} <b>number</b> <b>of</b> <b>Tests</b> played, which is not {{necessarily}} the <b>number</b> <b>of</b> matches keeping wicket.|$|R
2500|$|Smith {{holds the}} record for scoring the most <b>number</b> <b>of</b> <b>test</b> runs as captain(8659) ...|$|R
5000|$|The <b>number</b> <b>of</b> <b>tests</b> {{needed for}} a zero {{probability}} of error scales as [...]|$|R
5000|$|Smith {{holds the}} record for scoring the most <b>number</b> <b>of</b> <b>test</b> runs as captain(8659) ...|$|R
25|$|The minimum <b>number</b> <b>of</b> <b>test</b> {{cases is}} the <b>number</b> <b>of</b> {{classes in the}} {{classification}} with the most containing classes.|$|R
25|$|The <b>number</b> <b>of</b> <b>test</b> days {{allocated}} to each team was reduced {{from four to}} three. A compulsory two-day test was held at Sydney Motorsport Park on 7–8 February 2015, with teams allocated one further day <b>of</b> private <b>testing</b> {{that can be used}} at their discretion. The amount of track time on Fridays at eight rounds has been increased to account for the reduced <b>number</b> <b>of</b> <b>test</b> days.|$|R
5000|$|In the {{presence}} of suspicious symptoms a <b>number</b> <b>of</b> <b>test</b> are helpful in the diagnosis: ...|$|R
5000|$|The <b>number</b> <b>of</b> <b>tests</b> {{needed for}} an {{asymptotically}} small average {{probability of error}} scales as [...]|$|R
5000|$|Most <b>number</b> <b>of</b> <b>test</b> wins against South Africa by an All Black (16 test wins) 1996-2004 ...|$|R
5000|$|... n = <b>number</b> <b>of</b> <b>test</b> eggs available, n = 0, 1, 2, 3, ..., N &minus; 1.|$|R
5000|$|... 1955, Crest with Fluoristan was {{launched}} in a <b>number</b> <b>of</b> <b>test</b> markets in the United States.|$|R
5000|$|Total <b>number</b> <b>of</b> <b>test</b> {{cases are}} less, yet code {{coverage}} is more, due to static analysis ...|$|R
40|$|We {{proposed}} {{to reduce the}} <b>number</b> <b>of</b> <b>tests</b> by focusing on pairs of SNPs that belong to genes known to interact in some metabolic network. Although some interactions might be missed, these pairs of genes are good candidates for epistasis. Furthermore the use of protein interaction databases (such as the STRING database) may reduce the <b>number</b> <b>of</b> <b>tests</b> {{by a factor of}} 5, 000. |$|R
40|$|We {{study the}} problem <b>of</b> group <b>testing</b> with a non-adaptive {{randomized}} algorithm in the random incidence design (RID) model where each {{entry in the}} test is chosen randomly independently from { 0, 1 } with a fixed probability p. The property that is sufficient and necessary for a unique decoding is the separability <b>of</b> the <b>tests,</b> but unfortunately no linear time algorithm is known for such tests. In order to achieve linear-time decodable tests, the algorithms in the literature use the disjunction property that gives almost optimal <b>number</b> <b>of</b> <b>tests.</b> We define a new property for the tests which we call semi-disjunction property. We {{show that there is}} a linear time decoding for such test and for d→∞ the <b>number</b> <b>of</b> <b>tests</b> converges to the <b>number</b> <b>of</b> <b>tests</b> with the separability property and is therefore optimal (in the RID model). Our analysis shows that, in the RID model, the <b>number</b> <b>of</b> <b>tests</b> in our algorithm is better than the one with the disjunction property even for small d...|$|R
25|$|Research topics will be {{categorised}} {{and subject}} to a <b>number</b> <b>of</b> <b>tests</b> before proceeding with the research.|$|R
50|$|This is a {{simplified}} case; the number n {{is actually the}} <b>number</b> <b>of</b> degrees of freedom in the <b>tests,</b> or the <b>number</b> <b>of</b> effectively independent <b>tests.</b> If they are not fully independent, the number may be lower than the <b>number</b> <b>of</b> <b>tests.</b>|$|R
40|$|Simple {{expressions}} {{are derived}} for lower and upper support limits {{for the system}} failure probability of a series or parallel system based on binomial failure data. These limits are shown to be non-decreasing functions <b>of</b> the <b>number</b> <b>of</b> failures of any component for a fixed <b>number</b> <b>of</b> <b>tests</b> and non-increasing functions <b>of</b> the <b>number</b> <b>of</b> <b>tests</b> <b>of</b> any component for a fixed <b>number</b> <b>of</b> failures. This logically essential property, not shared by many other approximate upper limits, {{is critical to the}} efficient computation of Buehler bounds, using support limits as an ordering function. Buehler bounds Profile likelihood Exact confidence limits...|$|R
30|$|Many {{works have}} been {{proposed}} {{to deal with these}} aspects. In [9], a fast pre-processing is proposed to generate estimations of the RD costs. Operating on the original frame instead of the reconstructed one, the pre-processing allows to reduce the data dependency from the reconstruction loop. Then, the generated data is used to reduce the <b>number</b> <b>of</b> <b>tested</b> prediction unit levels as well as the <b>number</b> <b>of</b> <b>tested</b> intra modes.|$|R
40|$|We {{address some}} {{potential}} {{problems with the}} existing procedures of outlier detection in time series. Also we propose modifications in estimating model parameters and outlier effects {{in order to reduce}} the <b>number</b> <b>of</b> <b>tests</b> and to increase the detection accuracy. Experiments with some artificial data sets show that the proposed procedure significantly reduces the <b>number</b> <b>of</b> <b>tests</b> and enhances the accuracy of estimated parameters as well as the detection power...|$|R
