0|10000|Public
30|$|Figure  2 {{reports the}} time series of some {{variables}} related to the inspection system between 2005 and 2011. Panels (a) and (b) show, for {{the country as a}} whole, the <b>number</b> <b>of</b> <b>inspected</b> firms and the <b>number</b> <b>of</b> <b>inspected</b> firms per hundred formal firms respectively. Both variables present the same overall pattern, with a reduction over time, especially between 2006 and 2011. As mentioned in the previous section, since the Labor Regulation Law, inspections have been adjusted using information from past experiences in order to achieve the same <b>number</b> <b>of</b> non-registered workers through the inspection of fewer firms (MTEySS 2013). This can be seen in panel (c), which shows the increase over time in the <b>number</b> <b>of</b> non-registered workers detected as a percentage <b>of</b> the total <b>number</b> <b>of</b> <b>inspected</b> workers.|$|R
40|$|In {{the present}} paper is {{developed}} a statistical process control inspection procedure based on a new simple-to-implement and effective double sampling scheme for the c control chart, aimed at the minimization <b>of</b> the <b>number</b> <b>of</b> <b>inspected</b> observation units and warranting fixed levels for the type I and II error risks. In particular, the formulations of the false alarm risk α, the power P of the chart, and the expected <b>number</b> <b>of</b> <b>inspected</b> observation units for the developed inspection procedure are given, whereas a macro of Microsoft Excel is adopted to solve the tackled problem. In order to illustrate {{the application of the}} developed approach and to investigate on the influence of several operating parameters, numerical examples are carried out and the related considerations are given. Finally, by comparing the performance of the developed inspection procedure with that of the related classic c chart scheme, meaningful reduction <b>of</b> the <b>number</b> <b>of</b> the <b>inspected</b> observation units can be achieved by adopting the proposed approach...|$|R
40|$|Security {{personnel}} who operate X-ray units {{for the control}} of hand luggage and personal items at airports are generally not under dosimetric surveillance. A {{significant increase in the}} <b>number</b> <b>of</b> <b>inspected</b> items per passenger, due to rigorous air traffic security measures, raises a question of extended exposure of these workers to scattered X-ray radiation. A new approach to in-vestigating directions of breaches of scattered X-ray radiation in the area near to an X-ray cabinet system, which is based on using active electronic dosemeters is presented. Influence of the increase in the <b>number</b> <b>of</b> <b>inspected</b> items in time on the dose rate is described. Time-dependent dose rates have showed a very good correlation with passengers undergoing security control prior to boarding an airplane. Measurements confirmed that an increase in the dose rate, coinciding with rush hours, was caused by scattered radiation passing through incompletely closed lead curtains. It is found that the doses {{at the entrance to the}} inspection tunnel are 50 % higher than those at the exit, which is a consequence of inherent operational characteristics of X-ray cabinet systems...|$|R
25|$|Possibly due to {{pressure}} from large agribusiness, the United States has drastically {{cut back on the}} <b>number</b> <b>of</b> cows <b>inspected</b> for BSE.|$|R
30|$|The {{measure of}} {{enforcement}} of labor market regulations {{in this paper}} is the <b>number</b> <b>of</b> <b>inspected</b> firms per hundred formal firms {{in each of the}} 24 provinces, 10 productive sectors and year, from 2005 to 2011. Enforcement is expected to vary at the province and sector level since labor inspections are planned by the local inspection agencies considering the productive structure of local economies, the <b>number</b> <b>of</b> workers participating in the main activities and their seasonality, among other factors.|$|R
40|$|Since T. Rado in 1962 {{defined the}} busy beaver game several {{approaches}} have used computer technology to search busy beavers or even compute special values of Σ. Σ(5) {{is not yet}} known. A new approach to the computation of Σ(5) is presented, together with preliminary results, especially Σ(5) ≥ 4098. This approach includes techniques to reduce the <b>number</b> <b>of</b> <b>inspected</b> Turing machines, to accelerate simulation of Turing machines and to decide nontermination of Turing machines. 1...|$|R
40|$|International audiencen {{this paper}} we {{describe}} {{the use of an}} index to continuously monitor the risk of producing defective parts in a semiconductor production line. This index is used by product inspection policy to select the best lot to be controlled in order to decrease uncertainty on production tool's health. The approach was tested on data straight from STMicroelectronics Crolles 300 production line. We propose to evaluate the efficiency of the inspection policy based on the percentage <b>of</b> wafers <b>inspected</b> unnecessarily from the total <b>number</b> <b>of</b> <b>inspected</b> wafers...|$|R
40|$|We {{present a}} case study in {{monitoring}} a high-volume production process with a high yield. Testing the products is difficult and is only possible in a destructive way with a defect/no-defect result. We review several attribute charting procedures for high-yield processes. It turns out that monitoring the <b>number</b> <b>of</b> conforming items between the occurrence of non-conforming items is appropriate. We discuss several implementation aspects of CCCr charts in our case study. The implementation is based on a new formula for the standard deviation <b>of</b> the <b>number</b> <b>of</b> <b>inspected</b> items before a signal...|$|R
40|$|Reachability {{analysis}} {{is a powerful}} formal method for analysis of concurrent and distributed finite state systems. It suffers from the state space explosion problem, however: the state space of a system can be far too large to be completely generated. This report considers two promising methods, Valmari's stubborn set method and Godefroid's sleep set method, to avoid generating all of the state space when searching for undesirable reachable terminal states, also called deadlocks. What makes deadlocks especially interesting {{is the fact that}} the verification of a safety property can often be reduced to deadlock detection. The considered methods utilize the independence of transitions to cut down on the <b>number</b> <b>of</b> states <b>inspected</b> during the search. These methods have been combined by Godefroid, Pirottin, and Wolper to further reduce the <b>number</b> <b>of</b> <b>inspected</b> states. Petri nets are a widely used model for concurrent and distributed systems. This report shows that the stubborn set method a [...] ...|$|R
30|$|Taking {{advantage}} of the highly decentralized labor inspection system in Argentina, I constructed an enforcement measure (logarithm <b>of</b> the <b>number</b> <b>of</b> <b>inspected</b> firms per hundred formal firms) with variation at the province, sector, and time level. The econometric strategy linked indicators of compliance with labor regulations and other labor outcomes with the enforcement measure and with a rich set of individual characteristics, and economic, institutional and development characteristics of Argentine provinces. To deal with the possible endogeneity of the enforcement measure in this setting, I instrumented it using {{a measure of the}} arrival cost of labor inspectors to the firms.|$|R
40|$|We {{analyze the}} problem of {{preventing}} biological invasions caused by ships transporting internationally traded goods between countries and continents. Specifically, we ask the following question: Should a port manager have a small <b>number</b> <b>of</b> inspectors <b>inspect</b> arriving ships less stringently or should this manager have a large <b>number</b> <b>of</b> inspectors <b>inspect</b> the same ships more stringently? We use a simple queuing-theoretic framework and show that if decreasing the economic cost of regulation is very important then {{it makes more sense}} for the port manager to choose the less stringent inspection regime. In contrast, if reducing the damage from biological invasions is more salient then the port manager ought to pick the more stringent inspection regime. ...|$|R
40|$|This paper reports an {{empirical}} study that investigated associations between {{the quality of}} care received by older people in residential settings and features of the care homes in which they live. Data were gathered from the first announced inspection reports (2002 – 2003) of all 258 care homes for older people in one county of England (Surrey). The <b>number</b> <b>of</b> <b>inspected</b> standards failed in each home was used as the main indicator of quality of care. Independent variables (for each home) were: size, type, specialist registration, on-site nursing, ownership, year registered, location, maximum fee, vacancies, resident dependency,whether the home took publicly funded residents, care staff qualifications and managerial quality. Quality of care was modelled using a Poisson count maximum likelihood method based on 245 (91...|$|R
40|$|The aim of {{this study}} was to examine observers’ ability to {{discriminate}} numerical proportions depending on the <b>number</b> and attributes <b>of</b> the elements. Observers’ task was to decide which one of the two overlapping sets of elements, distinguished by colour or orientation, was more numerous. Bernoulli response model (based on hypergeometrical distribution) with a single free parameter K (the supposed <b>number</b> <b>of</b> <b>inspected</b> elements on which the choice was made) was applied to describe the choice probabilities. According to the Bernoulli model, these K elements are chosen randomly, their number limited by perceptual capacity. With the growth <b>of</b> the total <b>number</b> <b>of</b> displayed elements N = 9, 13, 33, 65, the <b>number</b> <b>of</b> accounted elements increased disproportionately, with colour being a stronger discriminating feature than orientation. It is concluded that the Bernoulli model is an alternative for the habitual Thurstonian-type model for examining observers’ ability to discriminate proportions...|$|R
50|$|The USDA {{has issued}} recalls of beef {{supplies}} that involved introduction of downer cows {{into the food}} supply. Hallmark/Westland Meat Packing Company {{was found to have}} used electric shocks to prod downer cows into the slaughtering system in 2007.Possibly due to pressure from large agribusiness, the United States has drastically cut back on the <b>number</b> <b>of</b> cows <b>inspected</b> for BSE.|$|R
40|$|This paper {{presents}} the MCSP-F-L for {{the concept of}} a fractional sampling plan that has been developed from the CSP-F-L continuous sampling plan. The attractive feature of the MCSP-F-L is that addition a maximum allowable <b>number</b> <b>of</b> <b>inspected</b> units for prevention long length of inspection at level 2 in the procedure of CSP-F-L plan. The conventional measures of performance for continuous sampling plans have been derived using a Markov Chain model, namely average fraction inspected (AFI), average fraction of total produced accepted on sampling basis (Pa(p)), average outgoing quality (AOQ) and average outgoing quality limit (AOQL). The accuracy of all performance measures has been verified by extensive simulations. The performance measures of the proposed plan were compared with the CSP-F-L plan and the Modified MLP-T- 2 plan and a numerical comparison at various levels of incoming quality levels and plan parameters is illustrated in this paper...|$|R
40|$|I {{propose a}} queuing theoretic {{research}} agenda for studying five {{questions about the}} effects that alternate invasive species control regulations have on consumers and producers in a nation such as the USA. The five questions are as follows. First, when can one justify a trade ban as an effective regulatory policy? Sec-ond, what are the attributes of credible pre-export certification schemes? Third, how does one determine the optimal <b>number</b> <b>of</b> inspectors in a stochastic context in which arriving ships {{may or may not}} be able to queue in a particular port? Fourth, should a port manager have a small <b>number</b> <b>of</b> inspectors <b>inspect</b> ships less stringently or should this manager have a large <b>number</b> <b>of</b> inspectors <b>inspect</b> ships more stringently? Finally, when should a port manager in (say) the USA use information about (i) the dollar value of the products being transported by ships from two exporting firms and (ii) the mean time it takes to inspect ships from these two firms to grant preferential treatment to one or the other exporting firm...|$|R
40|$|One of {{the basic}} {{activities}} of the Water Reuse Monitoring and Control Program is the supervision of self-control programs–which should be put into practice by the concessionaires that reuse the water provided by the River Basin Organization, in the Health Areas managed by the Environmental Health Service–to check compliance with Annex I of Royal Decree 1620 / 2007. To facilitate these tasks, this Service issued a Water Reuse Monitoring and Control Technical Instruction in June 2012. In order to test the e effectiveness of monitoring activities concerning water reuse after the issuance of the Technical Instruction, the results obtained from the inspection activities carried out in 2012 were compared with those obtained after the 2014 inspections. The results obtained show that the performance of inspections and the sending of reports to the Basin Organization have led {{to an increase in}} compliance with R. D. 1620 / 2007. All <b>of</b> the <b>inspected</b> plants have a self-control program in place. Furthermore, the <b>number</b> <b>of</b> <b>inspected</b> plants that perform analytical determinations with a frequency below that set by current regulations has decreased drastically. </p...|$|R
40|$|Reachability {{analysis}} {{is a powerful}} formal method for analysis of concurrent and distributed finite state systems. It suffers from the state space explosion problem, however: the state space of a system can be far too large to be completely generated. This paper considers two promising methods, Valmari's stubborn set method and Godefroid's sleep set method, to avoid generating all of the state space when searching for undesirable reachable terminal states, also called deadlocks. These methods have been combined by Godefroid, Pirottin, and Wolper to further reduce the <b>number</b> <b>of</b> <b>inspected</b> states. However, the combination presented by them places assumptions on the stubborn sets used. This paper shows that at least in place/transition nets, the stubborn set method can be combined with the sleep set method {{in such a way}} that all reachable terminal states are found, without having to place any assumption on the stubborn sets used. This result is shown by showing a more general result which [...] ...|$|R
40|$|The {{application}} of protective gel, {{which is a}} subprocess of the electronic assembly of the exhaust gas recirculation sensor, is a highly capable process with the fraction of nonconforming units as low as 200 ppm. Every unit is inspected immediately after gel application. The conventional Shewhart chart is of no use here, and {{the approach based on}} the Bernoulli process is therefore considered. The <b>number</b> <b>of</b> conforming items in a row until the occurrence of first or the r-th nonconforming is determined and CCC-r, CCC-r EWMA, and CCC CUSUM charts are applied. The aim of the control is to detect the process deterioration, and so the one-sided charts are used. So that the charts based on the geometric or negative binomial distribution can be compared, their performance is assessed through the average <b>number</b> <b>of</b> <b>inspected</b> units until a signal (ANOS). Our study confirmed that CCC-r EWMA and CCC CUSUM are able to detect the process shift more quickly than the CCC-r chart. Of the two charts, the first is easier to construct. Web of Science 7 art. no. 1...|$|R
40|$|The Inspection of {{collective}} tapwater installations in 2005. Progress and findings. Since 2004 {{the drinking water}} companies in the Netherlands have, by law, had the task <b>of</b> <b>inspecting</b> connected tapwaterinstallations for both the risk of contamination of the public mains system and the risks posed to the users of such an installation. This annual report, commissioned by the Dutch Ministry of VROM (Inspectorate of the Environment as enforcing body) describes the progress and findings of this inspection. The results of the inspections seem to confirm the outcome of 2004. About twenty per cent of the installations in both existing and new installations show a heightened risk of contamination. This is especially remarkable for new installations, as they must comply with the regulations amended in January 2002. Inspectors believe this {{to be caused by}} a lack of communication between the many parties involved in the building process, and the insufficient knowledge of these new requirements among fitters. From 2005 on, installations have also been inspected for Legionella prevention measures. Priority installations like hospitals and hotels take precedence here. Almost ninety per cent <b>of</b> the <b>inspected</b> <b>installations</b> failed to meet the necessary requirements. Primarily because the risk analysis and management plans of the installation were either missing or insufficient. According to the inspectors, the owners know of the requirements, but are not aware of the risks involved with Legionella. Ninety-five per cent of the problems are solved when the inspector returns for a second inspection. The remaining five per cent are turned over to VROM Inspection for enforcement of the necessary requirements. In 2005 the <b>number</b> <b>of</b> inspections declined by almost 3000 to around 40, 000 inspections. The main reason for this decline is the amount of time it takes to <b>inspect</b> priority <b>installations</b> due to their size and complexity. This undermines the ambition to <b>inspect</b> 50, 000 <b>installations</b> as of 2006. The initial step in achieving better tapwaterinstallations is to create awareness among the owners and other parties involved in the installation. This seems to create willingness to make improvements. RIVM recommends investigating the effectiveness of centrally based communication as means to better communication...|$|R
30|$|In {{this paper}} I explore {{microdata}} from Argentine household surveys {{for the period}} 2005 – 2011 to analyze (i) how changes in the enforcement of labor market regulations affect different indicators of compliance with the labor law among {{men and women and}} (ii) how changes in enforcement generates adjustments of some labor outcomes (different than the compliance level) for men and women separately. I take advantage of the highly decentralized labor inspection system in Argentina which allows me to construct an enforcement measure (<b>number</b> <b>of</b> <b>inspected</b> firms per hundred formal firms) with variation at the province, productive sector, and time level. The econometric strategy links indicators of compliance with labor regulations and other labor market outcomes such as hourly wages, percentiles of the wage distribution, indicators of the provision of non-mandated benefits, and the structure of occupation by employment categories (wage employment versus self-employment), with the enforcement measure and with a rich set of individual socioeconomic and labor characteristics, and economic, institutional, and development characteristics of Argentine provinces.|$|R
40|$|Most modern object {{trackers}} {{combine a}} motion prior with sliding-window detection, using binary classifiers that predict {{the presence of}} the target object based on histogram features. Although the accuracy of such trackers is gener-ally very good, they are often impractical because of their high computational requirements. To resolve this problem, the paper presents a new approach that limits the compu-tational costs of trackers by ignoring features in image re-gions that — after inspecting a few features — are unlikely to contain the target object. To this end, we derive an up-per bound on the probability that a location is most likely to contain the target object, and we ignore (features in) loca-tions for which this upper bound is small. We demonstrate the effectiveness of our new approach in experiments with model-free and model-based trackers that use linear mod-els in combination with HOG features. The results of our experiments demonstrate that our approach allows us to re-duce the average <b>number</b> <b>of</b> <b>inspected</b> features by up to 90 % without affecting the accuracy of the tracker. 1...|$|R
40|$|The last {{generation}} of CAD software systems allows {{the creation of}} models that consider the whole product lifecycle. Along the product development phase important activities {{are related to the}} geometrical tolerances prescription and their control planning. However, the Geometrical and Dimensional Tolerances (GD&T) representation, analysis and verification processes are still rarely taken into account in CAD systems. Such a bottleneck implies a “over the wall” communication between design and quality control departments. On the other hand, the tolerances verification process needs an high level of automation in order to extend the <b>number</b> <b>of</b> <b>inspected</b> products and to shorten the time from control strategy definition to the measurement process. Our research work is focused on the development of an approach for the automatic inspection planning, simulation and optimisation of geometrical tolerances. The approach is based on the integration of three technologies: the augmented CAD models, the 3 D optical digitizing systems and the articulated robot systems. In this paper the methodology is presented both for specific geometrical tolerances verification and for the global shape control...|$|R
40|$|Due to the {{complexity}} of real structures and in-service environment, the probability of detection (POD) curve generated from a laboratory environment and simple coupon samples may not be representative of in-service nondestructive inspection capability and experience. A study was carried out to assess the capability of a recent Berens model to estimate the POD using in-service inspection data. This paper presents the Berens model as well as the results of five case studies, where two types of mean POD curves were estimated and compared with each other. The first POD estimation used the standard POD method, described in the Military Handbook 1823, and used both hit and miss (detected and nondetected cracks) data. The second POD estimation used the Berens model and only hit (detected cracks) and percentage <b>of</b> crack detection (<b>number</b> <b>of</b> detected cracks per <b>number</b> <b>of</b> <b>inspected</b> sites) data. It is shown that the a 90 values estimated by the Berens model are close to those from the first POD approach, especially when the percentage of crack detection is known. The study demonstrated the possibility of using the Berens model for estimating an "effective" POD curve from in-service data, where often not all data required by the standard POD approach are available. 9 2013 Government of Canada. Peer reviewed: YesNRC publication: Ye...|$|R
40|$|From 1997 to 2004, 67213 ha were {{surveyed}} in Vojvodina {{in order to}} determine the incidence and distribution of beet necrotic yellow vein virus (BNYVV) the causer of Rhizomania on sugar beet in the fields in Vojvodina. The <b>number</b> <b>of</b> <b>inspected</b> hectares was different and ranged from 4. 427 ha in 2004 to 19. 254 ha in 2002. The survey showed that BNYVV is not equally widespread in all sugar beet growing areas of Vojvodina. The regions of Srem and Banat had higher incidence of the virus, while in region of Bačka the incidence of virus was lower than in other parts of Vojvodina. The BNYVV was found, on average, on 46, 2 % in Banat, on 40, 6 % in Srem and on 32, 9 % in Bačka of sugar beet acreages involved, during the period of eight years (1997 - 2004). These results show that BNYVV is widespread in Vojvodina, since the virus was found on 36, 7 % (24. 674 ha) of acreages from 67. 213 ha of total sugar beet acreages <b>inspected</b> on incidence <b>of</b> BNYVV in the period from 1997 to 2004...|$|R
30|$|Column (1) of Table 1 {{displays}} the annual {{growth in the}} rate of formalization of workers following inspections which is captured by the <b>number</b> <b>of</b> workers registered during labor inspections divided by the <b>number</b> <b>of</b> workers covered by these same inspections. This ratio increases from 1.8 % in 1996 – 2000 to 2.6 % in 2001 – 2006. Column (2) shows that in these two periods, the annual average <b>number</b> <b>of</b> plants <b>inspected</b> by each inspector decreased from over 141 to less than 120. Therefore, an increase {{in the rate of}} formalization seems to have been motivated by better and more targeted inspections rather than by more inspections.|$|R
40|$|The {{impact of}} urban {{ecosystem}} factors {{leads to the}} weakening of introduced and wild-growing tree and shrub plants, which makes them more accessible to diseases and can eventually lead {{to the loss of}} decorativeness, fragility and even plant death. Phytopathological monitoring was carried out using routing research methods. They examined the urban plantings of 5 categories, which differ in the degree of anthropogenic change. During the research, they determined the type and the nature of specific species diseases, the pathogen causing it, and the intensity and the prevalence <b>of</b> a <b>number</b> <b>of</b> diseases. An ocular 5 -point scale was used {{to take into account the}} intensity of diseases: 0 points - the absence of lesions; 1 point - up to 10 % of the surface is damaged; 2 points - 11 - 25 % is damaged; 3 points - 26 - 50 % is damaged; 4 points - more than 50 % of the surface is damaged. The prevalence of the disease was calculated in %, to the total <b>number</b> <b>of</b> <b>inspected</b> plants. The result of research showed that trees and shrubs were affected by three groups of diseases most often: spotting, rust and powdery mildew. The most affected species in the urban environment under study: Tilia córdata Mill., Malus domestica Borkh., Acer platanoides L. Key words: plant diseases, green plantations, pathogens...|$|R
40|$|This {{appendix}} {{describes in}} detail the several sources of data used in the paper {{and the construction of}} the variables. First, we use administrative data on the enforcement of labor regulations (in 2002), collected by the Department of Inspections at the Ministry of Labor. This data contains information on the <b>number</b> and location <b>of</b> regional labor offices, <b>number</b> <b>of</b> <b>inspected</b> firms, <b>number</b> <b>of</b> fines issued in each city, and <b>number</b> <b>of</b> inspectors per state (which we multiply by 10000 and then divide by the <b>number</b> <b>of</b> firms in the state). Our main measure of enforcement is the log inspections per firm in the city, which is computed with log <b>number</b> <b>of</b> inspections in the city multiplied by 100 (plus one) minus the log <b>of</b> the <b>number</b> <b>of</b> firms in the city. We also compute the proportion <b>of</b> workers <b>inspected,</b> with the log of the ratio of workers covered by inspections to total workers in the city. In this measure we cannot rule out double counting if the same worker is covered by multiple inspections to the same firm. Finally, we compute the <b>number</b> <b>of</b> inspectors per firm in the state, where we multiply total inspectors by 10, 000 and divide by the <b>number</b> <b>of</b> firms in the state. Second, we compute several city level labor market indicators using the 10 % sample of the Brazilian Census in 2000. In particular, we compute the share of workers who are registered, unregistered, or self-employed, the share of non-employed (either unemployed or out of the labor force), and the distribution of wages for each type of worker. Table A 1 reports the proportion of the working age adult population in each employment category. Registered and unregistered wage earners, self-employed, and non-employed individuals, together account for 87 % of the adult population in 2000. 1 In the empirical work we focus on these four groups. Informal employment and self-employment are considered two separate categories, as emphasized in th...|$|R
3000|$|Starting in 1995, the Ministry of Labor and Employment (MTE), {{under the}} Secretary of Work Inspection (SIT), {{implemented}} {{a series of}} reforms aiming {{to increase the efficiency}} of inspections. 8 The reform emphasized a new way of monitoring outcomes of labor inspections (see Miguel 2004). The primary objective was the standardization of the results of labor inspections at the national level. The creation of the Federal System of Labor Inspection (SFIT) was an important tool for this aim. First, the system allowed the creation of a routine to plan labor inspections throughout the country. Schedules with the targeted outcomes (goals) began to be sent annually by various Regional Offices of Labor to create a system of inspections. This reform made policies less reactive to complaints about labor standards and more proactive and based on long-term planning. In addition, the reform developed financial incentives so that labor inspections played became more efficient. The system awarded bonuses linked to performance. The bonuses were granted in accordance with the enforcement goals initially established. These goals generally considered the <b>number</b> <b>of</b> <b>inspected</b> plants and the total financial amount collected from fines. It is worth noting that the bonus system is not the only incentive mechanism. Pires (2011) argues that the formation of regional and sector teams with common goals is an additional incentive mechanism to individual bonuses. 9 [...]...|$|R
40|$|Abstract—Testing {{multithreaded code}} is hard and expensive. A multithreaded unit test creates {{two or more}} threads, each {{executing}} one or more methods on shared objects of the class under test. Such unit tests can be generated at random, but basic random generation produces tests that are either slow or do not trigger concurrency bugs. Worse, such tests have many false alarms, which require human effort to filter out. We present BALLERINA, a novel technique for automated random generation of efficient multithreaded tests that effectively trigger concurrency bugs. BALLERINA makes tests efficient by having only two threads, each executing a single, randomly selected method. BALLERINA increases chances that such simple parallel code finds bugs by appending it to more complex, randomly generated sequential code. We also propose a clustering technique to reduce the manual effort in <b>inspecting</b> failures <b>of</b> automatically generated multithreaded tests. We evaluate BALLERINA on 14 real-world bugs from six popular codebases: Groovy, JDK, JFreeChart, Apache Log 4 j, Apache Lucene, and Apache Pool. The experiments show that tests generated by BALLERINA find bugs on average 2 X- 10 X faster than basic random generation, and our clustering technique reduces the <b>number</b> <b>of</b> <b>inspected</b> failures on average 4 X- 8 X. Using BALLERINA, we found three previously unknown bugs, two of which were already confirmed and fixed. I...|$|R
40|$|Decision {{procedures}} for monitoring industrial processes can {{be based on}} application of control charts. The commonly used p-chart and np-chart are unsatisfactory for monitoring high-quality processes with a low fraction nonconforming. To overcome this difficulty, one may develop models based on the <b>number</b> <b>of</b> items <b>inspected</b> until r (⩾ 1) nonconforming items are observed. The cumulative count control chart (CCC-chart) is such an example. Like many other control charts, the CCC-charts suggested in the literature are one-stage control charts in which a decision is made when a signal for out of control appears. A CCC-chart with a small value of r requires less items inspected {{in order to obtain}} a signal for out of control, but is less reliable in detecting shifts of p than a CCC-chart with a large value of r (because the standard deviation <b>of</b> the <b>number</b> <b>of</b> items <b>inspected</b> in order to observe the rth nonconforming item, when divided by the mean, is proportional to Full-size image (< 1 K)). In the present paper, inspired by the idea of double sampling procedures in acceptance sampling, a two-stage CCC-chart is proposed in order to improve the performance of the one-stage CCC-chart. Analytic expressions for the average <b>number</b> <b>inspected</b> (ANI) <b>of</b> this two-stage CCC-chart is obtained, which is important for further studies of the chart. As an application of this result, an economic model is used to calculate the optimal values of probabilities of false alarm set at the first and second stages of the two-stage CCC-chart so that an expected total cost can be minimized...|$|R
40|$|Evaluation of {{usability}} is {{well researched}} {{in the area}} of HCI. One widely used method is a heuristic evaluation which relies on a small <b>number</b> <b>of</b> evaluators <b>inspecting</b> an interface to see to what extent it complies with a set of heuristics. Once a problem is identified it is categorised to a heuristic and a severity rating is attached. Severity ratings indicate the potential impact of the problem. Using a corpus of usability problems within CAA this paper reports on the development of domain specific heuristics and severity ratings for evaluating the usability of CAA applications. The heuristics are presented and the paper concludes with practical guidance on the application of the method in CAA...|$|R
50|$|The {{first study}} was {{conducted}} by Kristin Diehl from the University of South Carolina. Her research discovered that reducing search cost led to lower quality choices. The reason behind this discovery was that 'consumers make worse choices because lower search costs cause them to consider inferior options.' It also showed that if consumers have a specific goal in mind, they would further their search, resulting in an even worse decision. The study by Gerald Haubl from the University of Alberta and Benedict G.C. Dellaert from Maastricht University mainly focused on recommendation systems. Both studies concluded that a personalized search and recommendation system significantly improved consumers' decision quality and reduced the <b>number</b> <b>of</b> products <b>inspected.</b>|$|R
40|$|Petri nets are {{a widely}} used model for {{concurrent}} and distributed systems. This report {{shows that the}} stubborn set method and the sleep set method can be combined {{without any of the}} assumptions previously placed on the stubborn sets as far as the detection of reachable terminal states in place/transition nets, a class of Petri nets, is concerned. The obtained result is actually more general and gives a sufficient condition for a method to be compatible with the sleep set method in the detection of reachable terminal states in place/transition nets. The <b>number</b> <b>of</b> enabled transitions in a stubborn set can drastically affect the <b>number</b> <b>of</b> states <b>inspected</b> by the stubborn set method during the search for reachable terminal states. This work presents some heuristics for relieving the problem...|$|R
40|$|A major {{challenge}} for intrusion prevention system (IPS) sensors in today’s Internet {{is the amount}} of traffic these devices have to inspect. Hence this paper presents a linear program (LP) for traffic scheduling in multi-sensor environments that alleviates inspection loads at IPS sensors. The model discriminates traffic flows so that the amount <b>of</b> <b>inspected</b> suspicious traffic is maximized. While the LP is not constrained to integral solutions, traffic belonging to a flow is mostly scheduled for inspection to a single sensor, which facilitates the collection of state information.  An analysis of how the Simplex algorithm solves the model and numerical results demonstrate that state information can be preserved without imposing integral constraints. This benefit also prevents the LP from becoming an integer LP, and this is essential for efficiently implementing the proposed model. The paper also shows that the ratio <b>of</b> the total <b>number</b> <b>of</b> flows integrally <b>inspected</b> by a single sensor to the total number of flows inspected in a multi-sensor environment depends upon the ratio of IPS sensor capacity to flow traffic rate. Finally, some practical deployment observations are also presented...|$|R
40|$|The thesis {{describes}} {{characteristics of}} the study area, Královská obora, where the investigation {{was carried out in}} the field. It also engages in the description of the studied trees, wood-decaying fungi and damage of trees that occurs and causes problems here, in Stromovka, especially in the most visited areas of the park. Various injuries are a common cause of infection of pathogenic fungi that threatens a stability of trees and hence a safety of the park visitors. Health assessment conducted in location in the park Stromovka, which are problematic due to the occurrence of wood-decaying fungi. The locations were placed at the Planetarium, for the track and along the track. It was focused on the occurrence Meripilus giganteus on beeches, whom they are in the park problems with, particularly on heavily visited sites. 663 trees were inspected in total. The statistical analysis showed that most of the damages of trees in the park Stromovka was dry branches (12 % of the total trees), probably it was as a result of above-average temperatures in 2015. Only 3 % <b>of</b> the total <b>number</b> <b>of</b> <b>inspected</b> trees were infected by wood decaying fungi. Most of the trees were infected by Inonotus cuticularis (23 % <b>of</b> the total <b>number</b> <b>of</b> found wood-destroying fungi). Meripilus giganteus caused 14 % <b>of</b> the total <b>number</b> <b>of</b> found wood-destroying fungi dameges on the trees in the area. The infestation by pathogenic fungi was not significant on the inspected trees, it could be caused by above average temperatures and below-average rainfall in 2015. At the same time their presence was influent by a felling of trees in studied area from November 2014 to the end of March 2015. It was decided on the basis of dendrological research, that the identified riskiest trees infested by fungi and dying trees with disrupted stabilitye...|$|R
