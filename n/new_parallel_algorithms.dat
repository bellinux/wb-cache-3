105|10000|Public
50|$|In 2015, he {{published}} the book Distributed and Sequential Algorithms for Bioinformatics, where he presents a unified coverage of bioinformatics topics relating to both biological sequences and biological networks, combining DNA and protein sequence analysis and protein network analysis and offering about 15 <b>new</b> <b>parallel</b> <b>algorithms.</b>|$|E
50|$|Over {{the past}} several decades there has been {{significant}} research on deriving <b>new</b> <b>parallel</b> <b>algorithms</b> for a variety of problems, with the goal of designing highly parallel (polylogarithmic depth), work-efficient (linear in the sequential running time) algorithms. For some problems, tree {{turns out to be a}} nice solution. Addressing these problems, we can sometimes get more parallelism simply by representing our problem as a tree.|$|E
40|$|The {{investigation}} of <b>new</b> <b>parallel</b> <b>algorithms</b> for MIMD computers requires some postprocessing facilities for quickly evaluating {{the behavior of}} those algorithms We present two kinds of visualization tool implementations for 2 D and 3 D finite element applications to be used on a parallel computer and a host workstation...|$|E
40|$|Fast {{multiplication}} in {{a finite}} field GF(2 m) is a basis step in communications engineering applications, such as error-correcting codes or cryptograph <b>algorithms.</b> A <b>new</b> <b>parallel</b> <b>algorithm</b> on the polynomial basis bit-parallel multiplier is presented. This <b>new</b> <b>parallel</b> <b>algorithm</b> saves about 25 % execution time while comparing with the conventional algorithms. The hardware version {{for the proposed}} <b>parallel</b> <b>algorithm</b> is also invented. The new hardware structure requires only the space complexity of O(m) while existing multipliers need the space complexity of O(m 2). The time complexity of the proposed multiplier takes {{only about half of}} the time complexity of the existing Lee’s multiplier...|$|R
40|$|This paper {{presents}} a <b>new</b> <b>parallel</b> <b>algorithm</b> for planarity testing {{based upon the}} work of Klein and Reif [14]. Our new approach gives correct answers on instances that provoke false positive and false negative results using Klein and Reif's algorithm. The new algorithm has the same complexity bounds as Klein and Reif's algorithm and runs in O n processors of a Concurrent Read Exclusive Write (CREW) Parallel RAM (PRAM). Implementations of the major steps of this <b>parallel</b> <b>algorithm</b> exist for symmetric multiprocessors and exhibit speedup {{when compared to the}} best sequential approach. Thus, this <b>new</b> <b>parallel</b> <b>algorithm</b> for planarity testing lends itself to a high-performance shared-memory implementation...|$|R
40|$|With {{the advent}} of {{multicore}} processors, it has become imperative to write parallel programs if one wishes to exploit {{the next generation of}} processors. This paper deals with skyline computation as a case study of parallelizing database operations on multicore architectures. We compare two parallel skyline algorithms: a parallel version of the branch-and-bound algorithm (BBS) and a <b>new</b> <b>parallel</b> <b>algorithm</b> based on skeletal parallel programming. Experimental results show despite its simple design, the <b>new</b> <b>parallel</b> <b>algorithm</b> is comparable to parallel BBS in speed. For sequential skyline computation, the new algorithm far outperforms sequential BBS when the density of skyline tuples is low...|$|R
40|$|Several <b>new</b> <b>parallel</b> <b>algorithms</b> for {{the single}} source {{shortest}} paths and for the negative cycle detection problems on directed graphs with real edge weights and given by adjacency list are developed, analysed, and experimentally compared. The algorithms are to be performed on clusters of workstations that communicate via a message passing mechanism...|$|E
40|$|Abstract. Sequential fast matrix {{multiplication}} algorithms of Strassen and Winograd are studied; {{the complexity}} bound given by Strassen is improved. These algorithms are parallelized on MIMD distributed memory architectures of ring and torus topologies; a generalization to a hyper-torus is also given. Complexity and efficiency are analyzed and good asymptotic behaviour is proved. These <b>new</b> <b>parallel</b> <b>algorithms</b> are compared with standard algorithms on a 128 -processor parallel computer; experiments confirm the theoretical results...|$|E
40|$|We present <b>new</b> <b>parallel</b> <b>algorithms</b> {{for solving}} the problem of many body {{interactions}} in molecular dynamics (MD). Such algorithms are essential in the simulation of irradiation effects in crystals, where the high energy of the impinging particles dictates computing {{with large numbers of}} atoms and for many time cycles. We realized the algorithms using two parallelization methods and compared their performance. Experimental results obtained on a Meiko machine demonstrate that the new algorithms exploit parallelism effectively and can be used to simulate large crystals...|$|E
30|$|This {{paper is}} {{organized}} as follows: In Sect.  2, we introduce a Crank–Nicolson scheme and four corresponding Saul’yev asymmetric difference schemes {{to construct the}} <b>parallel</b> <b>algorithm</b> for parabolic equations. For simplicity of presentation, we focus on a model problem, namely one-dimensional parabolic equations. The <b>new</b> <b>parallel</b> <b>algorithm</b> and detailed presentations are given. The accuracy of the new algorithm is given in Sect.  3. The existence and uniqueness of solution by the new algorithm are discussed in Sect.  4, while {{the stability of the}} new algorithm is given in Sect.  5. In Sect.  6, we extend the <b>new</b> <b>parallel</b> <b>algorithm</b> to solve two-dimensional parabolic equations by ADI technique. Finally, we give some numerical experiments, which illustrate the accuracy and efficiency of the new algorithm proposed in this paper.|$|R
40|$|This {{research}} paper presents a <b>new</b> <b>parallel</b> <b>algorithm</b> for computing the formal concepts {{in a formal}} context. The proposed shared memory <b>parallel</b> <b>algorithm</b> Parallel-Task-In-Close 3 parallelizes Andrews's In-Close 3 serial algorithm. The paper presents the key parallelization strategy used and presents experimental results of the parallelization using the OpenMP framewor...|$|R
40|$|IEEE Beijing Section; Hunan University; Liverpool Hope University; Peking University; National Natural Science Foundation of ChinaIn {{the context}} of the prosperous {{development}} of Proteomics in life science, protein quantification, especially these based on Mass Spectrometry (short for MS) method, becomes an essential part of research. In our previous work, we developed a new software package called QuantWiz for high performance Liquid Chromatography (short for LC) -MS-based label-free protein quantification. We solved those problems of portability, applicability and longtime running existed in other software for protein quantification based on MS method. In this paper, we first compared the LC-MS-based label-free protein quantification accuracy of QuantWiz with the well-known Census software package. Then we designed and implemented a distributed memory version <b>parallel</b> <b>algorithm</b> for QuantWiz. Finally, we performed scalability testing of our <b>new</b> <b>parallel</b> <b>algorithm</b> and showed that our <b>new</b> <b>parallel</b> <b>algorithm</b> can scale up to 512 processes on Dawning 5000 A...|$|R
40|$|Intra-query {{parallelism}} is {{a well-established}} mechanism for achieving high performance in (object-) relational database systems. However, the methods have yet not {{been applied to}} the upcoming field of multidimensional array databases. Specific properties of multidimensional array data require <b>new</b> <b>parallel</b> <b>algorithms.</b> This paper presents {{a number of new}} techniques for parallelizing queries in multidimensional array database management systems. It discusses their implementation in the RasDaMan DBMS, the first DBMS for generic multidimensional array data. The efficiency of the techniques presented is demonstrated using typical queries on large multidimensional data volumes...|$|E
40|$|We present {{algorithms}} for parallel {{probabilistic model}} checking on general purpose graphic processing units (GPGPUs). For this purpose we exploit {{the fact that}} some of the basic algorithms for probabilistic model checking rely on matrix vector multiplication. Since this kind of linear algebraic operations are implemented very efficiently on GPGPUs, the <b>new</b> <b>parallel</b> <b>algorithms</b> can achieve considerable runtime improvements compared to their counterparts on standard architectures. We implemented our parallel algorithms on top of the probabilistic model checker PRISM. The prototype implementation was evaluated on several case studies in which we observed significant speedup over the standard CPU implementation of the tool...|$|E
40|$|Most of {{the data}} on the {{relative}} efficiency of different implementations of the alpha-beta algorithm is neither readily available nor in a form suitable for easy comparisons. In the present study four enhancements to the alpha-beta algorithm—iterative deepening, aspiration search, memory tables and principal variation search—are compared separately and in various combinations to determine the most effective alpha-beta implementation. The rationale for this work {{is to ensure that}} <b>new</b> <b>parallel</b> <b>algorithms</b> incorporate the best sequential techniques. Rather than relying on simulation or searches of specially constructed trees, a simple chess program was used to provide a uniform basis for comparisons. ...|$|E
30|$|To {{illustrate}} the accuracy {{and stability of}} the <b>new</b> <b>parallel</b> <b>Algorithm</b> 1 and Algorithm  2 for parabolic equations, we present two numerical experiments to verify the accuracy, convergence order in space, stability, and parallel efficiency. In addition, we will compare {{the accuracy of the}} new algorithm with the existing method.|$|R
40|$|Abstract—Next Generation Sequencing (NGS) {{is gaining}} in-terests {{due to the}} {{increased}} requirements and the decreased sequencing cost. The important and prerequisite step of most NGS applications is the mapping of short sequences, called reads, to the template reference sequences. Both the explosion of NGS data with over billions of reads generated each day and the data-intensive computations pose great challenges to the capability of existing computing systems. In this paper, we take a hash-index based algorithm (PerM) as an example to investigate the optimization approaches for accelerating NGS reads mapping on multi-core architectures. First, we propose a <b>new</b> <b>parallel</b> <b>algorithm</b> that reorders bucket access in hash index among multiple threads so that data locality in shared cache is improved. Second, {{in order to reduce}} the number of empty hash bucket, we propose a serialized hash index compression algorithm, which coincides with the sequential access nature of our <b>new</b> <b>parallel</b> <b>algorithm.</b> With reduced hash index size, it also becomes possible for us to use longer hash keys, which alleviates the hash conflicts and improves the query performance. Our experiment on an 8 -socket 8 -cores Intel Xeon X 7550 SMP with 128 GB memory shows that the <b>new</b> <b>parallel</b> <b>algorithm</b> reduces LLC miss ratio to be 8 % ∼ 15 % of the original algorithm and the overall performance is improved by 4 ∼ 11 times (6 times avg.). I...|$|R
40|$|In {{this paper}} a <b>new</b> <b>parallel</b> <b>algorithm</b> is {{presented}} for generation of all m [...] block partitions of n [...] element set, 1 m n. Computations run in an associative processor model. Objects are generated in lexicographic order, with O(1) time per object. The algorithm is well suitedforcolumn/masks generation in associative processors. ...|$|R
40|$|Abstract. We present {{algorithms}} for parallel {{probabilistic model}} checking on general purpose graphic processing units (GPGPUs). For this purpose we exploit {{the fact that}} some of the basic algorithms for probabilistic model checking rely on matrix vector multiplication. Since this kind of linear algebraic operations are implemented very efficiently on GPGPUs, the <b>new</b> <b>parallel</b> <b>algorithms</b> can achieve considerable runtime improvements compared to their counterparts on standard architectures. We implemented our parallel algorithms on top of the probabilistic model checker PRISM. The prototype implementation was evaluated on several case studies in which we observed significant speedup over the standard CPU implementation of the tool. ...|$|E
40|$|In {{this paper}} we {{describe}} algorithms for solving nonlinear least-squares problems on a message-passing multiprocessor. We demonstrate <b>new</b> <b>parallel</b> <b>algorithms,</b> including an efficient parallel algorithm {{for determining the}} Levenberg-Marquardt parameter and a new row-oriented QR factorization algorithm. Experimental results obtained on an Intel iPSC hypercube are presented and compared with sequential MINPACK code executed on a single processor. These experimental results show that essentially full efficiency is obtained for problems where the row size is sufficiently larger {{than the number of}} processors. These algorithms have the advantage of involving only simple data movements and consequently are not constrained to the hypercube architecture...|$|E
40|$|AbstractThe modular exponentiation {{operation}} of the current algorithms for asymmetric cryptography {{is the most expensive}} part in terms of computational cost. The RSA algorithm, for example, uses the modular exponentiation algorithm in encryption and decryption procedure. Thus, the overall performance of those asymmetric cryptosystems depends heavily on the performance of the specific algorithm used for modular exponentiation. This work proposes <b>new</b> <b>parallel</b> <b>algorithms</b> to perform this arithmetical operation and determines the optimal number of processors that yields the greatest speedup. The optimal number is obtained by balancing the processing load evenly among the processors. Practical implementations are also performed to evaluate the theoretical proposals...|$|E
40|$|Projet PARADISThis paper {{presents}} a <b>new</b> <b>parallel</b> <b>algorithm</b> {{to find all}} vertices of a convex polytope. This algorithm is of Monte-Carlo type and requires no assumption of problem nondegeneracy. Redundant constraints have no influence on the main computation. The vertex locating routine uses a new algorithm for nearest point problem in polytopes...|$|R
40|$|Abstract — In this paper, {{we propose}} a <b>new</b> <b>parallel</b> <b>algorithm</b> {{that can help}} the maximum neural network escape from local minima for maximum cut problem. By adding a {{nonlinear}} self-feedback to the maximum neural network, the proposed <b>parallel</b> <b>algorithm</b> has richer and more flexible dynamics and can prevent the network from getting stuck at local minima. A large number of instances have been simulated to verify the proposed algorithm...|$|R
40|$|AbstractA <b>new</b> <b>parallel</b> <b>algorithm</b> for the {{solution}} of linear systems, based upon the Monte Carlo approach, is shown. The method allows one to obtain {{the solution}} of a linear system with parallel cost growing as the logarithm {{of the size of}} the coefficient matrix, and with “probabilistic” error bounded in terms of the Chebyshev inequality...|$|R
40|$|Given a {{text and}} a pattern, {{the problem of}} pattern {{matching}} consists of determining all {{the positions of the}} text where the pattern occurs. When the text and the pattern are strings, the matching problem is said to be unidimensional. We examine a variation of this problem where we allow that the pattern can be scaled. We propose <b>new</b> <b>parallel</b> <b>algorithms,</b> under the Coarse Grained Multicomputer model, that require linear local computing time and only one communication round. The proposed algorithms were implemented on a Parsytec PowerXplorer parallel computer. The experimental results obtained are promising and show signicant speedups. Keywords: Parallel algorithms, coarse-grained multicomputer, BSP, string matching with scaling...|$|E
40|$|Finding the {{connected}} {{components of}} a graph is a basic computational problem. In recent years, there were several exciting results in breaking the log ’ n-time barrier to finding connected components on parallel machines using shared memory without concurrent-write capability. This paper further presents two <b>new</b> <b>parallel</b> <b>algorithms</b> both using less than log 2 7 ~ time. The merit of the first algo-rithm is that it uses only a sublinear number of processors, yet retains the time complexity of the fastest existing algorithm. The second algorithm is slightly slower but its work (i. e., the time-processor product) is closer to op-timal than all previous algorithms using less than log’n time. ...|$|E
40|$|This {{paper will}} present the {{implementation}} and comparison of <b>new</b> <b>parallel</b> <b>algorithms</b> for the convex hull problem. These algorithms are a parallel adaptation of the Jarvis March and the Quickhull algorithms. The computational model selected for these algorithms is the associative computing model #ASC# and the multiple associative computing model #MASC#. Both models support massive parallelism {{through the use of}} data parallelism and constant time associative search and maximum functions. Also, ASC can be supported on many SIMD computers. These algorithms requires O#n# space, O#log n# #i. e., O#log 2 n## average running time, and O#n# worst case running time. These algorithms have been compared using random data...|$|E
40|$|Abstract. In {{this paper}} a <b>new</b> <b>parallel</b> <b>algorithm</b> is {{presented}} for generation of t–ary trees. Computations run in an associative processor model. Tree sequences are generated in lexicographic order, with O(1) time per object, {{in a new}} representation, as combinations with repetitions with restricted growth. The corresponding full t–ary trees (x–sequences) appear in antilexicographic order. ...|$|R
40|$|Abstract. In {{this paper}} we propose a <b>parallel</b> tabu search <b>algorithm</b> based on the {{consecutive}} tabu algorithm constructed by us earlier {{to solve the problem of}} the distributed database optimal logical structure synthesis. Also we provide a reader with some information about the performance of our <b>new</b> <b>parallel</b> <b>algorithm</b> and the quality of the solutions obtained with help of it...|$|R
40|$|A <b>new</b> <b>parallel</b> <b>algorithm</b> for the maximal {{independent}} set {{problem is}} constructed. It runs in O(log 4 n) time when implemented on a linear number of EREW-processors. This {{is the first}} deterministic algorithm for the maximal independent set problem (MIS) whose running time is polylogarithmic and whose processor-time product is optimal up to a polylogarithmic factor...|$|R
40|$|We study {{parallel}} comparison-based algorithms {{for finding}} all equivalence classes {{of a set}} of $n$ elements, where sorting according to some total order is not possible. Such scenarios arise, for example, in applications, such as in distributed computer security, where each of $n$ agents are working to identify the private group to which they belong, with the only operation available to them being a zero-knowledge pairwise-comparison (which is sometimes called a "secret handshake") that reveals only whether two agents are in the same group or in different groups. We provide <b>new</b> <b>parallel</b> <b>algorithms</b> for this problem, as well as new lower bounds and distribution-based analysis...|$|E
40|$|In this paper. we show <b>new</b> <b>parallel</b> <b>algorithms</b> {{for a set}} of {{classical}} string comparison problems. computation of string alignments. longest common subsequences (LCS) or edit distances, and longest increasing subsequence computation. These problems have a wide range of applications, in particular in computational biology and signal processing. We discuss the scalability of our <b>new</b> <b>parallel</b> <b>algorithms</b> in computation time, in memory, and in commumcation Our new algorithms are based on an efficient parallel method for (min, +) -multiplication of distance matrices The core result of this paper is a scalable parallel algorithm for multiplying Implicit simple unit-Monge matrices of size n x n on p processors using lime O(n log n/p), communication O(n log p/p) and O(log p) supersteps. This algorithm allows us to implement scalable LCS computation for two strings of length n using time O(n(2) /p) and communication O(n/root P) requiring local memory of size O(n/root P) on each processor Furthermore, our algorithm can be used to obtain the first generally work-scalable algorithm for computing the longest increasing subsequence (LIS) Our algorithm for LIS computation requires computation O(n log(2) n/p), communication O(n log(2) p/p), and O(log(2) p) supersteps for computing the LIS of a sequence of length n This is within a log n factor of work-optimality for the LIS problem. which can be solved sequentially in time O(n log n) in the comparison-based model. Our LIS algorithm is also within a log p-factor of achieving perfectly scalable communication and furthermore has perfectly scalable memory size requirements of O(n/p) per processo...|$|E
40|$|International audienceIn {{order to}} {{understand}} the large between-subject variability observed in brain organization and assess factor risks of brain diseases, massive eﬀorts {{have been made in the}} last few years to acquire high-dimensional neuroimaging and genetic data on large cohorts of subjects. The statistical analysis of such high-dimensional and complex data is carried out with increasingly sophisticated techniques and represents a great computational challenge. To be fully exploited, the concurrent increase of computational power then requires designing <b>new</b> <b>parallel</b> <b>algorithms.</b> The MapReduce framework coupled with eﬃcient algorithms permits to deliver a scalable analysis tool that deals with high-dimensional data and hundreds of permutations in a few hours. On a real functional MRI dataset, this tool shows promising results...|$|E
40|$|International audienceWe {{present a}} novel 3 D {{curvilinear}} skeletonization algorithm which produces ltered skeletons without needing any user input, {{thanks to a}} <b>new</b> <b>parallel</b> <b>algorithm</b> based on the cubical complex framework. These skeletons are used in a modi ed path tracing algorithm {{in order to produce}} less noisy images in less time than the classical approach...|$|R
40|$|In {{this paper}} {{we present a}} <b>new</b> <b>parallel</b> <b>algorithm</b> for the LU {{decomposition}} of a general sparse matrix Among its features are matrix redistribution at regular intervals and a dynamic pivot search strategy that adapts itself {{to the number of}} pivots produced. Experimental results obtained on a network of transputers show that these features considerably improve the performance...|$|R
40|$|Abstract—The {{shortest}} path question is in a graph theory model question, {{and it is}} applied in many fields. The most short-path question may divide into two kinds: Single sources most short-path, all apexes to most short-path. This article mainly introduces the problem of all apexes to most short-path, and gives a <b>new</b> <b>parallel</b> <b>algorithm</b> of all apexes to most short-path according to the Dijkstra algorithm. At last this paper realizes the <b>parallel</b> <b>algorithms</b> in the technology of C # multithreading. Keywords—Dijkstra <b>algorithm,</b> <b>parallel</b> <b>algorithms,</b> multi-threa...|$|R
