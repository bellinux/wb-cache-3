43|1962|Public
50|$|Information about odors may be {{encoded in}} the {{mushroom}} body by {{the identities of}} the responsive neurons as well as the timing of their spikes. Experiments in locusts have shown that Kenyon cells have their activity synchronized to 20-Hz neural oscillations and are particularly responsive to projection <b>neuron</b> <b>spikes</b> at specific phases of the oscillatory cycle.|$|E
5000|$|In an [...] "asynchronous" [...] dynamic {{simulation}} if a <b>neuron</b> <b>spikes</b> at [...] Hz, {{the average}} rate of synaptic updates provoked by the activity of that neuron is [...] In a synchronous simulation with step [...] the number of synaptic updates per second would be [...] As [...] has to be chosen {{much smaller than the}} average interval between two successive afferent spikes, which implies , giving an average of synaptic updates equal to [...] Therefore, spike-driven synaptic dynamics leads to a linear scaling of computational complexity O(N) per neuron, compared with the O(N2) in the [...] "synchronous" [...] case.|$|E
3000|$|... {{when the}} post-synaptic <b>neuron</b> <b>spikes.</b> This {{accounts}} for the positive part of Figure  6. Similarly, the negative part corresponds to [...]...|$|E
40|$|It {{is crucial}} for a <b>neuron</b> <b>spike</b> sorting {{algorithm}} to cluster data from different neurons efficiently. In this study, the search capability of the Genetic Algorithm (GA) is exploited for identifying the optimal feature subset for <b>neuron</b> <b>spike</b> sorting with a clustering algorithm. Two important objectives of the optimization process are considered: {{to reduce the number}} of features and increase the clustering performance. Specifically, we employ a binary GA with the silhouette evaluation criterion as the fitness function for <b>neuron</b> <b>spike</b> sorting using the Super-Paramagnetic Clustering (SPC) algorithm. The clustering results of SPC with and without the GA-based feature selector are evaluated using benchmark synthetic <b>neuron</b> <b>spike</b> data sets. The outcome indicates the usefulness of the GA in identifying a smaller feature set with improved clustering performance...|$|R
5000|$|... where [...] is {{the time}} {{interval}} between a <b>neurons</b> <b>spike</b> and the one preceding it.|$|R
40|$|We model <b>neuron</b> <b>spiking</b> data {{by a set}} of {{logistic}} regressions, one {{for each}} neuron. We regularize them with a Group Lasso penalty on the pairwise differences between coefficient vectors. 1 Introduction- <b>Neuron</b> <b>Spiking</b> Data A neuronal spike is a sudden increase in voltage, followed by a decay. <b>Neurons</b> can <b>spike</b> in response to physical stimuli, either from the environment or from adjacent neurons. In this report, we model spikes as binary events, and all spiking events as independent of each other 1, conditional on the parameters of the logistic regression...|$|R
40|$|In {{this paper}} we present an analog {{integrated}} circuit containing a matched pair of silicon cochleae and an address event interface. Each section of the cochlea, modeled by a second-order low-pass filter, {{is followed by a}} simplified Inner Hair Cell circuit and a Spiking Neuron circuit. When the <b>neuron</b> <b>spikes,</b> an Address Event is generated on the asynchronous data bus. Measurements with pure tones played from different positions are presented...|$|E
40|$|It is {{believed}} that the color and the shape movement etc. of objects are expressed with time series of <b>neuron</b> <b>spikes</b> in the brain. We {{do not have any}} answer to realize the process, “What kind of neuron dynamics works and is able to express the processes? ” To solve this problem, we need at least to study the neural coding where information is expressed by the spike sequence...|$|E
40|$|We study a {{stochastic}} process describing the continuous time {{evolution of the}} membrane potentials of finite system of neurons {{in the absence of}} external stimuli. The values of the membrane potentials evolve under the effect of chemical synapses, electrical synapses and a leak current. The evolution of the process can be informally described as follows. Each <b>neuron</b> <b>spikes</b> randomly following a point process with rate depending on its membrane potential. When a <b>neuron</b> <b>spikes,</b> its membrane potential is immediately reset to a resting value. Simultaneously, the membrane potential of the neurons which are influenced by it receive an additional positive value. Furthermore, between consecutive spikes, the system follows a deterministic motion due both to electrical synapses and the leak current. Electrical synapses push the system towards its average potential, while the leak current attracts the membrane potential of each neuron to the resting value. We show that in the absence leakage the process converges exponentially fast to an unique invariant measure, whenever the initial configuration is non null. More interesting, when leakage is present, we proved the system stops spiking after a finite amount of time almost surely. This implies that the unique invariant measure is supported only by the null configuration...|$|E
40|$|Abstract—The Hindmarsh-Rose (HR) model could {{describe}} different discharge property of an excitatory or inhibitory neuron {{by changing the}} parameter r. In this paper, HR model is {{used to be the}} dynamical equations of the <b>spiking</b> model <b>neurons,</b> and different neurons in one neuronal population are connected with WS small-world network. A <b>neurons</b> <b>spiking</b> model in the hippocampus CA 3 based on small-world network is established on the Matlab platform. Spike trains of the <b>neurons</b> <b>spiking</b> model are simulated when no stimulus and a pulse current acted on the model. Then rate coding and synchrony coding are used to analyze the simulated spiking trains. Experiment results indicate when no stimulus acts on the <b>neurons</b> <b>spiking</b> model, the spike firing of hippocampus CA 3 is sparse. When a stimulus acts on the <b>neurons</b> <b>spiking</b> model, the mean population firing rate increased obviously. The increasing of neurons firing rate could present the ensemble activities, which highly correlate with memory. Index Terms—Hindmarsh-Rose (HR) model, small-world network, spike trains, hippocampus CA 3, neuronal ensemble codin...|$|R
40|$|Abstract—Spiking Learning vector {{quantization}} (S-LVQ) is trained by supervised learning {{vector quantization}} algorithm. In this network, {{instead of using}} the common <b>neuron,</b> <b>spiking</b> <b>neurons</b> are used as the processing elements. A <b>spiking</b> <b>neuron</b> is a simplified model of the biological neuron. This paper reports on the application of <b>spiking</b> <b>neurons</b> networks to perform the classification of wood defects. Experiments conducted with S-LVQ networks have shown that {{they are capable of}} doing better discrimination between the various types of defects [...] Moreover, they can perform the defect classification better in terms of classification time. However, they still lack of good learning algorithm for classification...|$|R
25|$|Scalp EEG {{activity}} shows oscillations at {{a variety}} of frequencies. Several of these oscillations have characteristic frequency ranges, spatial distributions and are associated with different states of brain functioning (e.g., waking and the various sleep stages). These oscillations represent synchronized activity over a network of neurons. The neuronal networks underlying some of these oscillations are understood (e.g., the thalamocortical resonance underlying sleep spindles), while many others are not (e.g., the system that generates the posterior basic rhythm). Research that measures both EEG and <b>neuron</b> <b>spiking</b> finds {{the relationship between the two}} is complex, with a combination of EEG power in the gamma band and phase in the delta band relating most strongly to <b>neuron</b> <b>spike</b> activity.|$|R
30|$|In {{the recent}} years, {{numerous}} studies {{focused on the}} use of the memristor as a discrete element in a circuit to model phenomena or to implement novel functions. Recent advances in memristor lead to the realization of large-scale artificial neural systems subserving perception, cognition, and learning [1 – 9]. Memristor acts as a modulating synapse interconnection between neurons; plasticity is accomplished through adjusting the memristance via current spikes based on the relative timings of pre-synaptic and postsynaptic <b>neuron</b> <b>spikes.</b> By using memristor as synapse in artificial neural systems, the potential in creating neuromorphic computing hardware through its variable memristance is unlimited.|$|E
40|$|In this paper, {{we present}} an analog {{integrated}} circuit containing a matched pair of silicon cochleae and an address event interface. Each section of the cochlea, modeled by a second-order low-pass filter, {{is followed by a}} simplified inner hair cell circuit and a spiking neuron circuit. When the <b>neuron</b> <b>spikes,</b> an address event is generated on the asynchronous data bus. We present the results of the chip characterization and the results of an interaural time difference based sound localization experiment using the address event representation (AER) EAR. The chip was fabricated in a 3 -metal 2 -poly 0. 5 -µm CMOS process...|$|E
40|$|In {{this paper}} we present an {{analogue}} integrated circuit containing a matched pair of silicon cochleae and an address event interface. Each section of the cochlea, modelled by a second-order low-pass filter, {{is followed by a}} simplified Inner Hair Cell circuit and a Spiking Neuron circuit. When the <b>neuron</b> <b>spikes,</b> an Address Event is generated on the asynchronous data bus. We present the results of the chip characterisation and the results of an Interaural Time Difference based sound localisation experiment using the AER EAR. The chip was fabricated in a 3 -metal 2 -poly 0. 5 &# 956;m CMOS process...|$|E
40|$|Fast-oopsi was {{developed}} by Joshua Vogelstein in 2009, which is now widely used to extract <b>neuron</b> <b>spike</b> activities from calcium fluorescence signals. Here, we propose detailed implementation of the fast-oopsi algorithm in python programming language. Some corrections are also made to the original fast-oopsi paper...|$|R
5000|$|Siebert [...] modeled the <b>neuron</b> <b>spike</b> {{firing pattern}} using a non-homogeneous Poisson process model, {{following}} experiments involving the auditory system. According to Siebert, {{the probability of}} a spiking event at the time interval [...] is proportional to a non negative function , where [...] is the raw stimulus.: ...|$|R
5000|$|... where [...] is {{synaptic}} weight that expresses {{the increase of}} membrane potential of neuron [...] because of <b>neuron</b> 's <b>spike,</b> [...] is a function that models the leak of potential and [...] is the most recent period of <b>neuron</b> 's <b>spike</b> before the given time period , considering the formula ...|$|R
3000|$|Another {{learning}} {{mechanism of}} biological synapses is spike-timing-dependent plasticity (STDP) [29], which {{implies that the}} change of synaptic weight is a strong function of the timing between the pre- and post-neuron spikes. It is widely accepted that STDP {{is responsible for the}} Hebbian learning [30]. In order to emulate STDP functionality in the fabricated memristors, we use the previously proposed [31] and experimentally implemented [32] methodology. Briefly, the electrodes of the device are connected to two separate arbitrary waveform generators serving as pre- and post-synaptic neurons. The output voltage pulses emulate the shape of real <b>neuron</b> <b>spikes</b> [33]: the negative trapezoidal pulse (τ [...]...|$|E
40|$|Abstract—In this paper, {{we present}} an analog {{integrated}} circuit containing a matched pair of silicon cochleae and an address event interface. Each section of the cochlea, modeled by a second-order low-pass filter, {{is followed by a}} simplified inner hair cell circuit and a spiking neuron circuit. When the <b>neuron</b> <b>spikes,</b> an address event is generated on the asynchronous data bus. We present the results of the chip characterization and the results of an interaural time difference based sound localization experiment using the ad-dress event representation (AER) EAR. The chip was fabricated in a 3 -metal 2 -poly 0. 5 - m CMOS process. Index Terms—Analog integrated circuits, neuromorphic engi-neering, silicon cochlea, sound localization. I...|$|E
40|$|Abstract. The {{selective}} fine-mesh {{modification of}} soma-dendrite (SD) neuronal membrane is analyzed. The mechanism of local synaptic controlled {{changes of the}} volt-conformation characteristics (VCC) of SD-membrane units is studied. These modified units, located between synapses; contain dimer receptive clusters, which can be in three conformations. The transitions between two of them result in energy accumulating and then it releasing that triggers endogenous mechanism of neuron excitation. Some part of the clusters, having VCC hysteretic loops before learning process, passes in the third conformation states, where hysteretic properties are lost as well as ability to generate the endogenous spikes. Remaining hysteretic units can read out the written information inversely {{in the form of}} "spontaneous " <b>neuron</b> <b>spikes...</b>|$|E
3000|$|... [...]. We use {{here the}} {{following}} convention. The index k {{is used for}} a post-synaptic neuron while the index j refers to pre-synaptic <b>neurons.</b> <b>Spiking</b> events are used to update the conductance of neuron k according to spikes emitted by pre-synaptic neurons. That is why we label the spike times with an index j.|$|R
50|$|Artificial neural networks, {{depending}} on type, {{may or may}} {{not take into account the}} timing of inputs. Those that do, such as spiking neural networks, fire only when the pooled inputs reach a membrane potential is reached. Because this mimics the firing of biological <b>neurons,</b> <b>spiking</b> neural networks are viewed as a more biologically accurate model of synaptic activity.|$|R
40|$|In paper [1] a {{possible}} way was noticed regarding how a neuron retains or responds to periodic stimulation. This new feature was {{established as a}} result of computational study of the deep differential structure of actual <b>neuron</b> <b>spike</b> trains. We observed, that for many cases the sequences of higher order finite differences, taken from periodically stimulated neuro...|$|R
40|$|In this paper, {{we propose}} a {{methodology}} quantifying temporal patterns of nonlinear hashtag time series. Our approach {{is based on}} an analogy between <b>neuron</b> <b>spikes</b> and hashtag diffusion. We adopt the local variation, originally developed to analyze local time delays in neuron spike trains. We show that the local variation successfully characterizes nonlinear features of hashtag spike trains such as burstiness and regularity. We apply this understanding in an extreme social event and are able to observe temporal evaluation of online collective attention of Twitter users to that event. Comment: 5 pages, 3 figures. Technical Report of the International AAAI Conference on Weblogs and Social Media (ICWSM- 15) Workshop 3 : Modeling and Mining Temporal Interaction...|$|E
40|$|Synchronization of {{neuronal}} {{activity is}} observed in high-and low-level {{functions of the}} nervous system. For example, during memory tasks, neural activity in differ-ent brain regions phase-locks [1, 2], while synchronized cells in the brainstem contribute to respiratory function [3]. In a two-cell system, network phase {{is a measure of}} when one <b>neuron</b> <b>spikes</b> with respect to the other neu-ron, normalized by the network period; phase-locked systems have a constant network phase, and here we define synchronized systems as those with a network phase close to zero. Understanding how and under what conditions neurons synchronize and phase-lock is important for understanding how neuronal populations function. Phase resetting curves (PRCs) describe how a neuron’...|$|E
40|$|This {{paper is}} an attempt to {{incorporate}} the idea of spiking neural P systems as an early seed into the area of Operating System Design, regarding their capability to solve some classical computer science problems. It is reflecting the power of such systems to simulate well known parallel computational models, like logic gates, arithmetic operation, and sorting. In these devices, the time (when the neurons fire and/or spike) plays an essential role. For instance, the result of a computation is the time between the moments when a specified <b>neuron</b> <b>spikes.</b> Seen as number computing devices, SN P systems are shown to be computationally complete, and with such capabilities, arithmetic operations, logic, and timing, some first steps could be taken towards an OS design...|$|E
40|$|This paper {{describes}} {{neural networks}} based on biological findings and, as an example, the application to tasks of a mobile robot. Some examples are tested in simulations others in physical systems. The {{aim is to}} develop neural networks suitable for hardware implementations and real-world problems. The notion "analog" is used here for continuous valued <b>neurons.</b> <b>Spikes</b> are not considered...|$|R
40|$|An ultralow {{current sensor}} {{system based on}} the Izhikevich neuron model is {{presented}} in this paper. The Izhikevich neuron model {{has been used for}} its superior computational efficiency and greater biological plausibility over other well-known <b>neuron</b> <b>spiking</b> models. Of the many biological <b>neuron</b> <b>spiking</b> features, regular spiking, chattering, and neostriatal spiny projection spiking have been reproduced by adjusting the parameters associated with the model at hand. This paper also presents a modified interpretation of the regular spiking feature in which the firing pattern {{is similar to that of}} the regular spiking but with improved dynamic range offering. The sensor current ranges between 2 [*]pA and 8 [*]nA and exhibits linearity in the range of 0. 9665 to 0. 9989 for different spiking features. The efficacy of the sensor system in detecting low amount of current along with its high linearity attribute makes it very suitable for biomedical applications...|$|R
40|$|Abstract. We propose an {{implementation}} of covert attention mecha-nisms with <b>spiking</b> <b>neurons.</b> <b>Spiking</b> neural models describe {{the activity of}} a neuron with precise spike-timing rather than firing rate. We inves-tigate the interests offered by such a temporal code for low-level vision and early attentional process. This paper describes a spiking neural net-work which achieves saliency extraction and stable attentional focus of a moving stimulus. Experimental results obtained using real visual scene illustrate the robustness and the quickness of this approach. Key words: <b>spiking</b> <b>neurons,</b> precise spike-timing, covert attention, saliency...|$|R
40|$|One of the {{fundamental}} problems in neuroscience is to understand the biological mechanisms of learning and memory, at the anatomical, biophysical, cellular and molecular levels. To that end, simple model systems, like the marine mollusc Aplysia, have been exceptionally useful, {{primarily because of the}} tractability of their nervous system. The tail-elicited siphon withdrawal reflex of Aplysia displays short- and long-term sensitization, a form of learning that involves the augmentation of a response elicited by a weak stimulus following training with a strong stimulus. Long-term memory for sensitization has been associated with changes in the properties of sensory neurons, including synaptic plasticity. Whereas short-term sensitization partly relies on broadening of sensory <b>neuron</b> <b>spikes</b> and facilitation of transmitter release, the contribution of spike broadening in long-term sensitization has not been previously examined. Long-term sensitization, induced by four days of training, is partly mediated by increases in the number of synaptic contacts between sensory neurons and motor neurons. However, it is not known whether long-term sensitization is also accompanied by increases in the amount of transmitter release. Here, we first adopt a computational approach to examine how the properties of synaptic transmission would be expected to change, if transmitter release were upregulated. We find that, under conditions of enhanced transmitter release, short-term homosynaptic depression would be augmented due to desensitization of postsynaptic receptors. Subsequently, we present experimental data suggesting that short-term homosynaptic depression of sensorimotor synapses is, indeed, partly dependent on receptor desensitization, and would, therefore, be sensitive to changes in amount of transmitter release. Further experimental data indicate that the dynamics of synaptic depression are not affected by long-term sensitization training, suggesting that there is no increase in transmitter release. Interestingly, rather than broadening the sensory <b>neuron</b> <b>spikes,</b> long-term sensitization leads to spike narrowing, which may serve to improve the fidelity of sensory neuron responses to peripheral stimuli. Finally, we present data for a latent effect of long-term sensitization training: priming of animals for further learning. ...|$|E
40|$|This paper {{presents}} exploratory {{results on}} the influence of bursting spiking behavior on the information content of <b>neuron</b> <b>spikes</b> in a three layered model of a cortical micro column. The bursting behavior is introduced in three parts of this model: the input, the recurrent layers and the output of the cortical micro column. Our hypotheses are as follows: 1. Bursting behavior in the input increases the information content of the <b>neuron</b> <b>spikes</b> in the model. 2. Input injection in layers closer to the output layer of the model increases the information content of the spikes. 3. Bursting in the recurrent layers of the network decreases the information content. 4. Bursting in the output of the column increases the information content of the output neurons spikes. The information content of the neurons in the model is analyzed with two methods: firstly a newly created method for assessing the correlated firing of neurons. This method is based on the FFT response of the pooled action potentials of these neurons. The second analytical tool is the Shannon mutual information metric. This metric is adapted for high temporal precision. This allows quantitative and qualitative tracking of information flow through the network. During the simulations large quantitative difference were found between the different neurons types in the model. Inhibitory neurons lacking direct input contained no information regarding the injected input. The bursting neurons in the model layers and the output contained a larger amount of information when compared with the regular spiking neurons. The bursting neurons retained information for a longer period. The introduction of bursting behavior in the input resulted in a decrease of information contained in the model. Two theoretical advances have been made: first the explicit inclusion of the input {{as a part of the}} network and secondly new insights in the visualization of the connections and layering of the cortical micro column. The application of these theoretical approaches allowed an improved functional analysis of the results. ...|$|E
40|$|We {{describe}} a neuromorphic chip that uses binary synapses with spike timing-dependent plasticity (STDP) to learn stimulated patterns of activity and {{to compensate for}} variability in excitability. Specifically, STDP preferentially potentiates (turns on) synapses that project from excitable neurons, which spike early, to lethargic neurons, which spike late. The additional excitatory synaptic current makes lethargic neurons spike earlier, thereby causing neurons that {{belong to the same}} pattern to spike in synchrony. Once learned, an entire pattern can be recalled by stimulating a subset. 1 Variability in Neural Systems Evidence suggests precise spike timing is important in neural coding, specifically, in the hippocampus. The hippocampus uses timing in the spike activity of place cells (in addition to rate) to encode location in space [1]. Place cells employ a phase code: the timing at which a <b>neuron</b> <b>spikes</b> relative to the phase of the inhibitory theta rhythm (5 - 12 Hz) convey...|$|E
40|$|Abstract [...] The {{computational}} {{power of}} formal models for networks of <b>spiking</b> <b>neurons</b> is {{compared with that}} of other neural network models based on McCulloch Pitts neurons (i. e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of <b>spiking</b> <b>neurons</b> are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single <b>spiking</b> <b>neuron</b> (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of <b>spiking</b> <b>neurons.</b> This article does not assume prior knowledge about <b>spiking</b> <b>neurons,</b> and it contains an extensive list of references to the currently available literature on computations in networks of <b>spiking</b> <b>neurons</b> and relevant results from neurobiology...|$|R
40|$|We use a two-layered {{bio-inspired}} {{neural network}} to segregate sound sources, i. e. double-vowels or intruding noises in speech. The {{architecture of the}} network consists of <b>spiking</b> <b>neurons.</b> The <b>spiking</b> <b>neurons</b> in both layers are modelized by relaxation oscillators. The first layer of the network is locally connected, while the second layer is a fully connected network. Our auditory image {{is based on the}} reassigned spectrum technique. No prior estimation or knowledge of pitch is necessary for the segregation...|$|R
5000|$|At time [...] before , <b>neuron</b> [...] <b>spikes,</b> {{restoring}} the membrane potential to its initial value.|$|R
