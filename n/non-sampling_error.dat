44|56|Public
25|$|If {{the exact}} {{confidence}} intervals are used, then {{the margin of}} error takes into account both sampling error and <b>non-sampling</b> <b>error.</b> If an approximate confidence interval is used (for example, by assuming the distribution is normal and then modeling the confidence interval accordingly), then {{the margin of error}} may only take random sampling error into account. It does not represent other potential sources of error or bias such as a non-representative sample-design, poorly phrased questions, people lying or refusing to respond, the exclusion of people who could not be contacted, or miscounts and miscalculations.|$|E
2500|$|All {{statistical}} work presents {{opportunities for}} error, but it's possible to reduce error to manageable amounts. A statement reads: [...] "An important aim of our ongoing {{work is to}} understand, manage, control and report on all known sources of error... which simply reflect the inherent variability that exists among the units we are seeking to measure... This variability manifests itself in sampling error when we use samples for cost-effectiveness reasons to estimate characteristics about a population. Sampling errors are relatively easy to measure.... Other sources reflect process, measurement and inference errors, and {{are referred to as}} <b>non-sampling</b> <b>error.</b> It is not possible to eliminate all sources of error. However, our continued efforts at understanding and managing variability and error ensure we are exercising a high level of control on all known sources of error." ...|$|E
50|$|Sampling error can be {{contrasted with}} <b>non-sampling</b> <b>error.</b> <b>Non-sampling</b> <b>error</b> is a {{catch-all}} {{term for the}} deviations from the true value that are not {{a function of the}} sample chosen, including various systematic errors and any random errors that are not due to sampling. Non-sampling errors are much harder to quantify than sampling error.|$|E
40|$|Data from {{interview}} {{surveys of}} households or health facilities {{are used to}} assess community parameters such as health status and factors related to the ability and willingness of individuals {{to pay for health}} services. Although the effect of sample size on confidence intervals is generally well understood by the survey designers and policy-makers who use the results, the typical survey is also subject to <b>non-sampling</b> <b>errors</b> whose magnitude may exceed that of the sampling <b>errors.</b> The <b>non-sampling</b> <b>errors</b> associated with surveys are only rarely assessed and reported, even though they may have a major effect on the interpretation of findings. The present study reports the <b>non-sampling</b> <b>errors</b> associated with a household survey in Sierra Leone by comparing the results of reinterviews with the responses given during the original interviews. Certain types of questions were subject to greater <b>non-sampling</b> <b>errors</b> than others. The findings should be of use to designers of similar surveys and to those who rely on such surveys for making policy decisions...|$|R
2500|$|<b>Non-sampling</b> <b>errors</b> {{are other}} errors which can impact the final survey estimates, caused by {{problems}} in data collection, processing, or sample design. They include: ...|$|R
40|$|Abstract: In our {{application}} {{practice of}} sample survey, we mostly neglect some <b>non-sampling</b> <b>errors</b> such as sampling frame errors. Actually, {{the influence of}} <b>non-sampling</b> <b>errors</b> to the total survey deviation can not be ignored. In view of this topic, this paper briefly discussed the sampling frame <b>errors</b> as <b>non-sampling</b> <b>errors.</b> First {{a brief review of}} the sampling frame, together with the type and structure of the sampling frame, is given. Next the distinction between sampling frame errors and sampling errors is made theoretically in general. Then through the analysis of a series of non-random impact factors and the application of corresponding improvements or solutions, the sampling frame errors are reduced or controlled within a certain range. Finally, this paper summed up and sorted out the influencing factors based on the sample units or elements for the sampling frame, and also discussed the problems and solutions...|$|R
5000|$|The term [...] "observational error" [...] is also {{sometimes}} {{used to refer}} to response errors and some other types of <b>non-sampling</b> <b>error.</b> In survey-type situations, these errors can be mistakes in the collection of data, including both the incorrect recording of a response and the correct recording of a respondent's inaccurate response. These sources of <b>non-sampling</b> <b>error</b> are discussed in Salant and Dillman (1995) and Bland and Altman (1996).|$|E
5000|$|An {{excellent}} {{discussion of}} issues pertaining to <b>non-sampling</b> <b>error</b> {{can be found}} in several sources such as Kalton (1983) and Salant and Dillman (1995), ...|$|E
50|$|In statistics, <b>non-sampling</b> <b>error</b> is a {{catch-all}} {{term for}} the deviations of estimates from their true values that are not {{a function of the}} sample chosen, including various systematic errors and random errors that are not due to sampling. Non-sampling errors are much harder to quantify than sampling errors.|$|E
40|$|On-farm data {{collection}} {{consists of a}} dynamic interaction between the interviewer and respondent via a questionnaire. <b>Non-sampling</b> <b>errors</b> introduced by these sources during the measurement process often account for {{a greater proportion of}} the total survey error than sampling error alone. A two pronged approach was used to evaluate <b>non-sampling</b> <b>errors</b> in the National Animal Health Monitoring System’s National Swine Survey. First, results from two supplemental questionnaires, administered to field coordinators and in-terviewers of the National Swine Survey, were used to assess correlates of <b>non-sampling</b> <b>errors.</b> S’econd, since questionnaires contained multiple indicators of the same underlying concept, an index of inconsistency was used to quantify the level of response error for several variables. Bias due to the ecologic fallacy was shown by elevated estimates of response error for several indicators of preventive practices. Correlates of respondent error included the presence of multiple respondents for at least one interview {{for more than half of}} the inter-viewers. Correlates of interviewer error included demographic characteristics of inter...|$|R
2500|$|Survey {{results are}} {{typically}} subject to some error. Total errors {{can be classified}} into sampling <b>errors</b> and <b>non-sampling</b> <b>errors.</b> The term [...] "error" [...] here includes systematic biases as well as random errors.|$|R
40|$|This paper {{examines}} {{the accuracy of}} data in annual unlinked passenger trips reported to the National Transit Database (NTD) at the individual agency level. This examination takes a twostep approach. The first step compares the ridership reported by member agencies to the American Public Transportation Association (APTA) and the ridership reported to the NTD as recipients of transit formula grants. The NTD ridership can {{be as high as}} 50 percent more than the APTA ridership, and such significant positive deviation exists persistently over time across many agencies. The second step explores potential sources of these positive deviations by examining their components. Random errors, including both sampling errors and some of the <b>non-sampling</b> <b>errors,</b> do not help explain these one-sided deviations. Nor do occasional annual adjustments such as special events ridership to a direct count in the NTD ridership. Much of these positive deviations appear to be attributable to systematic <b>non-sampling</b> <b>errors</b> that result from undercounting in direct counts, from unintentional biases in procedures, or perhaps from intentional manipulation. Limited evidence in the literature, however, suggests that undercounting in direct counts is small at the systemwide level. The paper then quantitatively examines how these systematic <b>non-sampling</b> <b>errors</b> affect the allocation of two formula grants to Florida transit agencies: the Urbanized Area Formula Grant Program at the federal level and Florida’s Transit Block Grant Program at the state level. The paper also discusses a strategy for reducing these systematic <b>non-sampling</b> <b>errors...</b>|$|R
5000|$|In {{business}} research, {{companies must}} often generate samples of customers, clients, employees, {{and so forth}} to gather their opinions. Sample design is also {{a critical component of}} marketing research and employee research for many organizations. During sample design, firms must answer questions such as:- What is the relevant population, sampling frame, and sampling unit?- What is the appropriate margin of error that should be achieved?- How should sampling error and <b>non-sampling</b> <b>error</b> be assessed and balanced? ...|$|E
50|$|If {{the exact}} {{confidence}} intervals are used, then {{the margin of}} error takes into account both sampling error and <b>non-sampling</b> <b>error.</b> If an approximate confidence interval is used (for example, by assuming the distribution is normal and then modeling the confidence interval accordingly), then {{the margin of error}} may only take random sampling error into account. It does not represent other potential sources of error or bias such as a non-representative sample-design, poorly phrased questions, people lying or refusing to respond, the exclusion of people who could not be contacted, or miscounts and miscalculations.|$|E
5000|$|All {{statistical}} work presents {{opportunities for}} error, but it's possible to reduce error to manageable amounts. A statement reads: [...] "An important aim of our ongoing {{work is to}} understand, manage, control and report on all known sources of error... which simply reflect the inherent variability that exists among the units we are seeking to measure... This variability manifests itself in sampling error when we use samples for cost-effectiveness reasons to estimate characteristics about a population. Sampling errors are relatively easy to measure.... Other sources reflect process, measurement and inference errors, and {{are referred to as}} <b>non-sampling</b> <b>error.</b> It is not possible to eliminate all sources of error. However, our continued efforts at understanding and managing variability and error ensure we are exercising a high level of control on all known sources of error." ...|$|E
40|$|Survey {{estimates}} are often affected by <b>non-sampling</b> <b>errors</b> due to missing data, coverage error, and measurement or response <b>error.</b> Such <b>non-sampling</b> <b>errors</b> {{can be difficult}} to assess, and possibly correct for, using information from a single survey. Thus, combining information from multiple surveys can be beneficial. In addition, combining information from multiple surveys can help to reduce sampling error. This article describes four examples of projects undertaken by researchers within and outside the National Center for Health Statistics of the Centers for Disease Control and Prevention, in which information from multiple surveys was combined to adjust for <b>non-sampling</b> <b>errors</b> and thereby enhance estimation of various measures of health. The four projects can be described briefly as follows: (1) combining estimates from a survey of households and a survey of nursing homes to extend coverage; (2) using information from an interview survey to bridge the transition in race reporting in the United States census; (3) combining information from an examination survey and an interview survey to improve on analyses of self-reported data; and (4) combining information from two interview surveys to enhance small-area estimation. The article highlights the goals, techniques, and results from the four projects and discusses issues that can arise when information is combined from multiple surveys. Published in 2007 by John Wiley & Sons, Ltd...|$|R
40|$|Marketing {{research}} uses {{two sources}} of data: primary and secondary. There are many advantages in use of secondary data but also {{there are many}} limitations such as different types of errors and biases that can arise in these data. Secondary data should be accurate, reliable, precise, unbiased, valid, appropriate and timely. Four categories of potential errors can reduce accuracy of secondary data: sampling and <b>non-sampling</b> <b>errors,</b> errors that invalidate the data, errors that require data reformulation and errors that reduce reliability. All sources of errors can lower {{the reliability and validity}} of results. This implies that secondary data have to be treated carefully...|$|R
50|$|During {{his time}} at the Census Bureau, Hansen made {{contributions}} to the {{theory and practice of}} sampling, as well as to <b>non-sampling</b> <b>errors.</b> In 1947 he was elected as a Fellow of the American Statistical Association. He also served as President of the Institute of Mathematical Statistics in 1953 and President of the American Statistical Association in 1960.|$|R
40|$|In {{this paper}} we {{introduce}} the particular {{issues involved in}} analysing the 2002 NATSISS. We discuss a number of aspects of the survey methodology including the scope, sample design and interviewing techniques. We {{pay particular attention to}} the different survey methodology used in Community Areas and Non Community Areas and the implications for analysis of the data, particularly that which uses the Confidentialised Unit Record File. A number of issues to do with sampling and <b>non-sampling</b> <b>error</b> are outlined, including how users can take into account sampling and <b>non-sampling</b> <b>error</b> when making conclusions. In particular, we give three examples of potential <b>non-sampling</b> <b>error</b> that show how users {{need to be aware of}} questionnaire design, interviewing techniques and imputation strategy when using the NATSISS. 1...|$|E
40|$|It will be {{discussed}} if the confidence in {{the results of the}} production of economic and social data will be justified. Probability based conclusions are possible concerning the sampling error. In order to quantify the <b>non-sampling</b> <b>error</b> an accuracy check is necessary which causes practical problems. Therefore special methods are applied to reduce the errors in surveys before the results are published. The confidence in statistics on this level depends on the collaboration of the official statistics with the applied statistical science. Sampling error, <b>non-sampling</b> <b>error,</b> error reducing measures...|$|E
40|$|The {{precision}} of a small-domain sample estimator {{can be improved}} by estimating simultaneously its true value and sampling and <b>non-sampling</b> <b>error</b> components. In principle, this simultaneous estimation is superior to any two-step estimation of the true value and sampling error components, ignoring the <b>non-sampling</b> <b>error</b> component. In this paper, a time series model for state employment or unemployment is used to demonstrate the limitations of a two-step method. A cross-sectional model for state employment or unemployment is used to explain the advantages of simultaneously estimating a true value and the sums of sampling and non-sampling errors in two or more sample estimators of the true value. Key Words. Indirect model-dependent estimate; domain indirect; time indirect; domain and time indirect; coefficient driver. 1...|$|E
40|$|The study aims at {{assessing}} the differential effects of face-to-face paper and computer assisted interviewing {{in terms of}} efficacy, efficiency {{and the production of}} <b>non-sampling</b> <b>errors.</b> The research ground is constituted by the analysis of the customer satisfaction of a large-scale retail trade group owning many shops in Sicily. The reaction of respondents to paper versus electronic questionnaires is investigated by means of an experimental design in terms of non sampling error amounts...|$|R
40|$|It {{is widely}} known that pre-electoral polls often suffer from <b>non-sampling</b> <b>errors,</b> mainly due to {{imperfect}} frames, non-responses, {{other forms of}} selection bias. These <b>non-sampling</b> <b>errors</b> might also be more relevant than sampling errors. In order to correct for biases due to <b>non-sampling</b> <b>errors,</b> the pollsters implement diverse ad hoc adjustments, including expert opinions in final estimates, thus leading to the well-known house effects. We consider data on pre-election polls for Italian political elections in 2006, 2008 and 2013 carried out by various pollsters and made available on a free-access governmental website. The response variables are the estimated vote shares of the principal Italian parties (those which are included in all available polls). Since various pollsters carry {{out a number of}} pre-electoral polls in the observed time frame, the data have a hierarchical structure in which groups are defined to be the pollsters. We propose a model to assess the relevance of the variability induced by the house effects with respect to the total variability. In particular we consider a hierarchical Bayesian model in which each party share of votes is separately analyzed. The model involves two-stages, in which the first stage allows for the within-pollster variability and also includes a non linear time trend, whereas the second stage describes the between-pollsters variability, by means of a random effect vector. A Gaussian distribution is employed both for observations and for random effects. Such Gaussian distributions are parametrized so to allow for the different variability due to the various sample sizes and underlying probability. In general, results confirm a large house effect in Italian pre-election polls. The effect is quite heterogeneous between parties and between pollsters. Such conclusion appear to be quite stable across the considered years...|$|R
50|$|CHFS {{developed}} a proprietary interview system and management platform for both face-to-face interviews and for telephone interviews. This integrated system provides a full package for each computer-based household interview. The Computer-assisted personal interviewing (CAPI) system effectively decreases potential man-made <b>non-sampling</b> <b>errors</b> by presetting {{the range of}} possible answers, catching typing errors, and avoiding general human errors (such as skipping questions). The system ensures the confidentiality of the data and ensures real-time accessibility, significantly improving data quality.|$|R
40|$|This paper {{focuses on}} the {{statistical}} aspects of a census. It addresses {{issues such as the}} coverage, classification, sampling, <b>non-sampling</b> <b>error,</b> post collection processing, weighting and disclosure avoidance. The intent of the paper is to demonstrate that most (if not all) of the statistical issues that are important in conducting a survey are equally germane to conducting a census...|$|E
40|$|The {{use of the}} {{internet}} as a method to conduct survey research has expanded rapidly over the past decade. High speeds of response and lower expenses have driven this rapid growth. Relatively low response rates, however, suggest online surveys may be compromised by high levels of <b>non-sampling</b> <b>error.</b> This paper examines a major component of <b>non-sampling</b> <b>error</b> and the consequences that may be associated with internet survey non-response. Known population parameters are compared to point estimates from a census as well as a random sample of non-respondents in order to provide insight on the magnitude and direction of non- response error. Issue salience and response latency are found to exhibit a significant relationship to self-selection and response valance biases. Specifically, lower rates of non- response were obtained from respondents who perceived the topic of the survey as more important and patterns of response were more favorable among initial study participants...|$|E
40|$|Nationally {{representative}} household {{surveys are}} increasingly relied upon to measure maternal, newborn, {{and child health}} (MNCH) intervention coverage at the population level in low- and middle-income countries. Surveys are the best tool we have for this purpose and are central to national and global decision making. However, all survey point estimates have {{a certain level of}} error (total survey error) comprising sampling and <b>non-sampling</b> <b>error,</b> both of which must be considered when interpreting survey results for decision making. In this review, we discuss the importance of considering these errors when interpreting MNCH intervention coverage estimates derived from household surveys, using relevant examples from national surveys to provide context. Sampling error is usually thought of as the precision of a point estimate and is represented by 95 % confidence intervals, which are measurable. Confidence intervals can inform judgments about whether estimated parameters are likely to be different from the real value of a parameter. We recommend, therefore, that confidence intervals for key coverage indicators should always be provided in survey reports. By contrast, the direction and magnitude of <b>non-sampling</b> <b>error</b> is almost always unmeasurable, and therefore unknown. Information error and bias are the most common sources of <b>non-sampling</b> <b>error</b> in household survey estimates and we recommend that they should always be carefully considered when interpreting MNCH intervention coverage based on survey data. Overall, we recommend that future research on measuring MNCH intervention coverage should focus on refining and improving survey-based coverage estimates to develop {{a better understanding of how}} results should be interpreted and used...|$|E
50|$|Both the Diary and Interview Surveys utilize a {{representative}} sample to measure the buying habits of Americans. Only {{a small percentage of}} the US population is being surveyed, and therefore the data are subject to sampling errors. The division publishes standard error tables on their website. <b>Non-sampling</b> <b>errors</b> include, but are not limited to, respondents who are either unwilling or unable to provide accurate answers, mistakes made in collecting or recording obtained data, and estimation of missing data.|$|R
40|$|Household {{surveys of}} the {{distribution}} of income and expenditure are discussed in this paper. The potential for <b>non-sampling</b> <b>errors,</b> effecting both the mean and measures of dispersion, is noted. These errors are shown to result in substantial discrepancies between the survey data and national accounts-based estimates of the incidence of poverty and trends in living standards. It is argued that the reconciliation of these discrepancies offers the best way forward for improving both types of data. 1...|$|R
40|$|It {{is widely}} known that pre-electoral polls often suffer from <b>non-sampling</b> <b>errors</b> which pollsters try to {{compensate}} in ﬁnal estimates {{by means of}} diverse ad hoc adjustments, thus leading to the well-known house effects. We analyze vote share predictions from election polls in Italy in 2006, 2008 and 2013 in order to investigate the relative role of house effects on their variability. We are able to conﬁrm that the variability due to house effect {{is the most important}} source of variatio...|$|R
40|$|BACKGROUND Data {{on blood}} donor status {{obtained}} from general surveys and health interview surveys {{have been widely}} used. However, the integrity of data on self-reported blood donor status from surveys may be threatened by sampling and <b>non-sampling</b> <b>error.</b> Our study aimed to compare self-reported blood donors (including one-time as well as regular donors) from the Swiss Health Survey 2012 (SHS) with register-based blood donors recorded by blood establishments and evaluate the direction and magnitude of bias in the SHS. METHODS We compared population-weighted SHS point {{estimates of the number}} of blood donors with their corresponding 95...|$|E
40|$|Abstract: Count {{data are}} subject to {{considerable}} sources of what {{is often referred to}} as <b>non-sampling</b> <b>error.</b> Errors such as misclassification, measurement error and unmeasured confounding can lead to substantially biased estimators. It is strongly recommended that epidemiologists not only acknowledge these sorts of errors in data, but incorporate sensitivity analyses into part of the total data analysis. We extend previous work on Poisson regression models that allow for misclassification by thoroughly discussing the basis for the models and allowing for extra-Poisson variability in the form of random effects. Via simulation we show the improvements in inference that are brought about by accounting for both the misclassification and the overdispersion...|$|E
40|$|Abstract: Nationally {{representative}} household {{surveys are}} increasingly relied upon to measure maternal, newborn, {{and child health}} (MNCH) intervention coverage at the population level in low- and middle-income countries. Surveys are the best tool we have for this purpose and are central to national and global decision making. However, all survey point estimates have {{a certain level of}} error (total survey error) comprising sampling and <b>non-sampling</b> <b>error,</b> both of which must be considered when interpreting survey results for decision making. In this review, we discuss the importance of considering these errors when interpreting MNCH intervention coverage estimates derived from household surveys, using relevant examples from national surveys to provide context. Sampling error is usually thought of a...|$|E
40|$|Perhaps, one of {{the most}} {{relevant}} issues in constructing regional input-output tables is the estimation of interregional trade flows. Hence, the Regional Statistical Office of Andalusia (Spain) is promoting new research on survey-based estimates of trade flows between the own region and the rest of Spain. Especially, survey approach has been seen to result more reliable outcomes (Eding & Nijmeijer, 1998) than non-survey constructs. This paper will focus on survey design features, sample methods, treatment of sampling and <b>non-sampling</b> <b>errors</b> and others aspects concerning data collection and processing in the case of Andalusia (Spain) ...|$|R
40|$|Abstract. LUCAS (Land Use/Cover Area-frame Survey) {{has been}} {{launched}} by Eurostat to obtain harmonised agricultural and environmental {{data for the}} European Union (EU). Major surveys {{have been carried out}} in 2001, 2003 and 2006. We describe the methodology and sampling plan: non-stratified two-stage sample of points in 2001 and 2003, and two-phase sampling with incomplete stratification of non-clustered points in 2006. The relative efficiency of both sampling plans is analyzed concluding that the LUCAS 2006 method was superior for the EU context. We also analyze the sources of <b>non-sampling</b> <b>errors,</b> expected accuracy and current evolution of LUCAS. JRC. DG. G. 3 -Monitoring agricultural resource...|$|R
40|$|Conclusions about {{poverty and}} the {{distribution}} of incomes are typically based on information obtained from sample surveys. However, sample surveys are subject to sampling and <b>non-sampling</b> <b>errors.</b> Statistical inference allows us to deal with sampling errors. In this paper, we demonstrate the usefulness of bootstrapping techniques for carrying out statistical inference for poverty and inequality measures. We analyse poverty and income inequality among pensioners in Hungary, Luxembourg and the United Kingdom. We carry out comparisons of the living standards of pensioners across countries and over time. Our results have far-reaching policy implications for the reforms of public pension systems currently under way. Poverty, inequality, pensioners, pension reforms, bootstrapping. ...|$|R
