260|1217|Public
25|$|One {{can also}} return {{out of a}} {{subroutine}} executing the looped statements, breaking out of both the <b>nested</b> <b>loop</b> and the subroutine. There are other proposed control structures for multiple breaks, but these are generally implemented as exceptions instead.|$|E
50|$|Hash join {{is similar}} to <b>nested</b> <b>loop</b> join but faster than <b>nested</b> <b>loop</b> join and hash join is used for equi join.|$|E
5000|$|The block <b>nested</b> <b>loop</b> join {{algorithm}} improves on {{the simple}} <b>nested</b> <b>loop</b> join by only scanning [...] once for every group of [...] tuples. For example, one {{variant of the}} block <b>nested</b> <b>loop</b> join reads an entire page of [...] tuples into memory and loads them into a hash table. It then scans , and probes the hash table to find [...] tuples that match any of the tuples in the current page of [...] This reduces the number of scans of [...] that are necessary.|$|E
40|$|Loop transformations are {{critical}} for compiling high-performance code for modern computers. Existing work has focused on transformations for perfectly <b>nested</b> <b>loops</b> (that is, loops in which all assignment statements are contained within the innermost loop of a <b>loop</b> <b>nest).</b> In practice, most <b>loop</b> <b>nests,</b> {{such as those in}} matrix factorization codes, are imperfectly nested. In some programs, imperfectly <b>nested</b> <b>loops</b> can be converted into perfectly <b>nested</b> <b>loops</b> by loop distribution, but this is not always legal. In this paper, we present an approach to transforming imperfectly <b>nested</b> <b>loops</b> directly. Our approac...|$|R
40|$|Usually {{the most}} {{computationally}} intensive {{part of a}} program is attributed to the <b>nested</b> <b>loops</b> it contains. It is therefore of interest to try to parallelize <b>nested</b> <b>loops</b> {{in order to reduce}} the overall computation time. A special category of FOR(DO) <b>nested</b> <b>loops</b> are the uniform dependence loops, which are the focus of this paper. The primary goals in thi...|$|R
40|$|Most {{existing}} {{solutions to}} pipelining <b>nested</b> <b>loops</b> are developed for general purpose processors, {{and may not}} work efficiently for field-programmable gate arrays due to loop control overhead. This is especially true when the <b>nested</b> <b>loops</b> have nonrectangular iteration spaces (IS). Thus we propose a novel method that can transform triangular IS-the most frequently found type of nonrectangular IS-into rectangular ones, so that other loop transformations can be effectively applied and the overall performance of <b>nested</b> <b>loops</b> can be maximized. Our evaluation results using the state-of-the-art Vivado high-level synthesis tool demonstrate that our technique can improve the performance of <b>nested</b> <b>loops</b> with nonrectangular IS significantly. clos...|$|R
5000|$|The block <b>nested</b> <b>loop</b> runs in [...] I/Os where [...] is {{the number}} of {{available}} pages of internal memory and [...] and [...] is size of [...] and [...] respectively in pages. Notethat block <b>nested</b> <b>loop</b> runs in [...] I/Os if [...] fits in the available internal memory.|$|E
50|$|Three {{fundamental}} algorithms {{for performing}} a join operation exist: <b>nested</b> <b>loop</b> join, sort-merge join and hash join.|$|E
5000|$|This is {{essentially}} the same as the block <b>nested</b> <b>loop</b> join algorithm. This algorithm scans [...] more times than necessary.|$|E
40|$|Microsoft SQL Server was {{successful}} {{for many years}} for transaction processing and decision support workloads with neither merge join nor hash join, relying entirely on <b>nested</b> <b>loops</b> and index <b>nested</b> <b>loops</b> join. How much difference do additional join algorithms really make, and how much system performance do they actually add? In a pure OLTP workload that requires only record-to-record navigation, intuition agrees that index <b>nested</b> <b>loops</b> join is sufficient. For a DSS workload, however, the question is much more complex. To answer this question, we have analyzed TPC-D query performance using an internal build of SQL Server with merge-join and hash-join enabled and disabled. It shows that merge join and hash join are both required to achieve the best performance for decision support workloads. 1. 0 Introduction For a long time, most relational database systems employed only <b>nested</b> <b>loops</b> join, in particular {{in the form of}} index <b>nested</b> <b>loops</b> join, and merge join. The general rule of thumb, [...] ...|$|R
40|$|Multi-dimensional systems {{containing}} <b>nested</b> <b>loops</b> {{are widely}} used to model scientific applications such as image processing, geophysical signal processing and fluid dynamics. However, branches within these loops may degrade the performance of pipelined architectures. This paper presents the theory, supporting hardware and experiments of a novel technique, based on multi-dimensional retiming, for reducing pipeline hazards caused by branches within <b>nested</b> <b>loops.</b> This technique, called Multi-Dimensional Branch Anticipation Scheduling, is able to achieve nearoptimal schedule length for <b>nested</b> <b>loops</b> containing branch instructions. 1...|$|R
30|$|For {{the control}} practice, {{students}} were first {{given the same}} 1 -h lecture on <b>nested</b> <b>loops</b> as the experimental group, including {{an explanation of the}} characteristics of <b>nested</b> <b>loops.</b> We subsequently conducted the 15 -min pre-test. Then, they studied <b>nested</b> <b>loops</b> using textbooks and the lecture material, without using LEPA 2. Before studying, the teacher explained that the aim {{of the study was to}} understand <b>nested</b> <b>loops</b> using a sample program. The sample program was identical to the one in the experimental practice. The teacher also explained that, in particular, they should study tracing the program. After a 1 -h study period, we conducted the 15 -min post-test. Both pre- and post-tests were the same as those given to the experimental group.|$|R
5000|$|This {{algorithm}} is {{a variation on}} the simple <b>nested</b> <b>loop</b> join used to join two relations [...] and [...] (the [...] "outer" [...] and [...] "inner" [...] join operands, respectively). Suppose [...] In a traditional <b>nested</b> <b>loop</b> join, [...] will be scanned once for every tuple of [...] If there are many qualifying [...] tuples, and particularly if there is no applicable index for the join key on , this operation will be very expensive.|$|E
50|$|A <b>nested</b> <b>loop</b> join is a naive {{algorithm}} that joins {{two sets}} by using two nested loops. Join operations {{are important to}} database management.|$|E
50|$|Solving {{the problem}} with SQL {{is a bit more}} code and {{requires}} a bit more creative thought than the <b>nested</b> <b>loop</b> approach of cursors.|$|E
40|$|Loop {{unwinding}} is {{a well-known}} technique for reducing loop overhead, exposing parallelism, and increasing the efficiency of pipelining. Traditional loop unwinding {{is limited to the}} innermost loop of a set of <b>nested</b> <b>loops</b> and the amount of unwinding is either fixed or must be specified by the user. In this paper we present a general technique, loop quantization, for unwinding multiple <b>nested</b> <b>loops,</b> explain its advantages over other transformations, and illustrate its practical effectiveness. An abstraction of <b>nested</b> <b>loops</b> is presented which leads to results about the complexity of computing quantizations and an algorithm...|$|R
30|$|In this paper, we {{describe}} a code-reading support environment and practical classroom applications using this environment to understand <b>nested</b> <b>loops.</b> Previously, {{we developed a}} code-reading support system based on visualization of the relationships among the program code, target domain world, and operations. We implemented the proposed system in exercises with <b>nested</b> <b>loops.</b> The evaluation results suggested that students could frequently fulfill learning objectives using the proposed system. However, we also discovered that some students experienced a learning impasse in the classroom. We attempted to address these students with two supporting approaches: bridging {{the gap between the}} generalization structures in the program code and their corresponding operations and enabling learners to predict the behavior of the <b>nested</b> <b>loops.</b> In this paper, we extend our previous system with new functions based on our two supporting approaches. Further, we implement the system in another classroom for <b>nested</b> <b>loops.</b> We describe a correlation between the proposed system and an understanding of <b>nested</b> <b>loops</b> using pre-/post-test comparisons. We discuss how code reading using the proposed system allows learners to cultivate a superior understanding of the program code.|$|R
5000|$|... #Subtitle level 3: Multiple early exit/exit from <b>nested</b> <b>loops</b> ...|$|R
5000|$|The block <b>nested</b> <b>loop</b> join {{algorithm}} is a generalization {{of the simple}} nested loops algorithm that takes advantage of additional memory {{to reduce the number}} of times that the [...] relation is scanned.|$|E
5000|$|In 1999, ASE 12.0 was released, {{providing}} support for Java, high availability and distributed transaction management. Merge joins were added, previous all joins were <b>nested</b> <b>loop</b> joins. In additional cache partitions {{were added to}} improve performance.|$|E
5000|$|If we wish {{to iterate}} through the bits of a bit array, {{we can do this}} {{efficiently}} using a doubly <b>nested</b> <b>loop</b> that loops through each word, one at a time. Only n/w memory accesses are required: ...|$|E
50|$|The Art and Science of <b>Nested</b> <b>Loops,</b> {{seminar in}} Orlando, Florida.|$|R
40|$|On modern computers, the {{performance}} of programs is often limited by memory latency rather than by processor cycle time. To reduce the impact of memory latency, the restructuring compiler community has developed localityenhancing program transformations, the most well-known of which is loop tiling. Tiling is restricted to perfectly <b>nested</b> <b>loops,</b> but many imperfectly <b>nested</b> <b>loops</b> can be transformed into perfectly <b>nested</b> <b>loops</b> that can then be tiled. Recently, we proposed an alternative approach to locality enhancement called data shackling. Data shackling reasons about data traversals rather than iteration space traversals, and can be applied directly to imperfectly <b>nested</b> <b>loops.</b> We have implemented shackling in the SGI MIPSPro compiler which already has a sophisticated implementation of tiling. Our experiments on the SGI Octane workstation with dense numerical linear algebra programs show that shackled code obtains double {{the performance}} of tiled code for most of these programs, and ob [...] ...|$|R
30|$|<b>Nested</b> <b>loops</b> are a {{learning}} target with which novice learners frequently have an initial difficulty. This is because to fully comprehend this concept {{requires that the}} learner understands {{all three of the}} abovementioned fundamentals. Koppelman and van Dijk (2010) emphasized the importance of <b>nested</b> <b>loops</b> as one of the targets required to understand the concept of abstraction. However, limited exposure in programming courses constrains the efforts of learners to develop a thorough understanding of these fundamental concepts. The purpose of our study is to encourage students to learn these concepts efficiently. We have introduced learning support systems into classroom exercises in <b>nested</b> <b>loops</b> for several years (Kogure et al. 2013).|$|R
5000|$|One {{can also}} [...] {{out of a}} {{subroutine}} executing the looped statements, breaking out of both the <b>nested</b> <b>loop</b> and the subroutine. There are other proposed control structures for multiple breaks, but these are generally implemented as exceptions instead.|$|E
5000|$|Skewing - this {{technique}} is applied to a <b>nested</b> <b>loop</b> iterating over a multidimensional array, where each iteration of the inner loop depends on previous iterations, and rearranges its array accesses so that the only dependencies are between iterations of the outer loop.|$|E
50|$|Note on {{efficiency}} class: Clearly {{the running}} {{time of this}} algorithm is , based on the <b>nested</b> <b>loop</b> and the computation of the profit of new packing. This does not contradict the fact the QKP is NP-hard since W is not polynomial in {{the length of the}} input.|$|E
30|$|In this paper, we {{described}} our {{learning support}} system and classroom practices with the proposed system for an improved understanding of <b>nested</b> <b>loops.</b> <b>Nested</b> <b>loops</b> are an appropriate target for learning the fundamental skills of programming. We believe that learning support systems efficiently and effectively {{contribute to an}} understanding of fundamental programming concepts and the acquisition of the skills required to utilize them.|$|R
30|$|A 4. The student {{used the}} {{function}} {{to observe the}} characteristics of <b>nested</b> <b>loops</b> (Ex 4).|$|R
3000|$|... {{specified}} in (19). These calculations require four <b>nested</b> <b>loops,</b> but note {{that we can}} decrease the number of <b>loops</b> to three <b>nested</b> <b>loops</b> by considering only the word pairs that {{are present in the}} training documents instead of all word pairs. Thus the time complexity in the M-step is O(KNB) where B is the average number of the word pairs in the training documents.|$|R
50|$|Despite {{having a}} <b>nested</b> <b>loop</b> structure, the running {{time of this}} {{algorithm}} is linear, because every iteration of the inner loop removes an item that had been added in some previous iteration of the outer loop. It {{is closely related to}} an algorithm of Knuth for sorting with a stack (for inputs that can be sorted in this way).|$|E
50|$|In {{compiler}} theory, loop interchange is {{the process}} of exchanging the order of two iteration variables used by a <b>nested</b> <b>loop.</b> The variable used in the inner loop switches to the outer loop, and vice versa. It is often done to ensure that the elements of a multi-dimensional array are accessed in the order in which they are present in memory, improving locality of reference.|$|E
50|$|The {{evaluation}} procedure {{can be thought}} of as a <b>nested</b> <b>loop.</b> In general, the language allows to express a range of imaging, signal processing, and statistics operations. The limit is given because the language is safe in evaluation, that is: every request is guaranteed to terminate after a finite number of steps. This excludes recursion. Still, algorithms like classification, filter kernels and general convolutions, histograms, and Discrete Fourier Transform are expressible.|$|E
40|$|This paper {{presents}} {{the influence of}} the <b>loop</b> <b>nest</b> splitting source code optimization on the worst-case execution time (WCET). <b>Loop</b> <b>nest</b> splitting minimizes the number of executed if-statements in <b>loop</b> <b>nests</b> of embedded multimedia applications. It identifies iterations of a <b>loop</b> <b>nest</b> where all if-statements are satisfied and splits the <b>loop</b> <b>nest</b> such that if-statements are not executed at all for large parts of the <b>loop</b> <b>nest's</b> iteration space...|$|R
40|$|Time skewing and loop tiling {{has been}} {{known for a long time}} to be a highly {{beneficial}} acceleration technique for <b>nested</b> <b>loops</b> especially on bandwidth hungry multi-core processors, but it is little used in practice because efficient implementations utilize complicated code and simple or abstract ones show much smaller gains over naive <b>nested</b> <b>loops.</b> We break this dilemma with an essential time skewing scheme that is both compact and fast...|$|R
40|$|Software {{pipelining}} for <b>nested</b> <b>loops</b> {{remains a}} challenging problem for embedded system design. The existing software pipelining techniques for single loops can only explore the parallelism of the innermost loop, so the final timing performance is inferior. While multi-dimensional (MD) retiming can explore the outer loop parallelism, it introduces large overheads in loop index generation and code size due to transformation. In this paper, we use MD retiming {{to model the}} software pipelining problem of <b>nested</b> <b>loops.</b> We show that the computation time and code size of a software-pipelined <b>loop</b> <b>nest</b> is affected by execution sequence and retiming function. The algorithm of Software PIpelining for <b>NEsted</b> <b>loops</b> technique (SPINE) is proposed to generate fully parallelized loops efficiently with the overheads as small as possible. The experimental results show that our technique outperforms both the standard software pipelining and MD retiming significantly. 1...|$|R
