53|2|Public
50|$|The kusarigama is for {{the most}} part taught only to {{advanced}} students who have achieved a high level of proficiency in the Shinto Muso-ryu Jodo forms, though the level required is not standardized and different Jodo-organizations have different requirements. Modern Isshin-ryu exponents use a wooden version of the kusarigama for safety-reasons. The handguard (goken) is still made of metal but the chain and weight replaced by rope and a leather bag. A kusarigama with a metal (though <b>non-sharp)</b> blade is sometimes used for demonstrations.|$|E
5000|$|Shortly {{after the}} accident, Charlotte Pendragon {{published}} {{an account of}} the event. She wrote, [...] "Jonathan is in the hospital following an accident involving an arrow from his archery. He fell on the <b>non-sharp</b> broken end of the arrow while trying to hang a light fixture. The arrow pierced through his stomach, liver, an artery and several inches in his heart. It is through speed of hospitalization, modern surgical techniques and Jonathan's will to live that he continues with us today. His surgeon ... said this injury is always fatal and it is a miracle Jonathan is alive. He is recovering well after several hours of surgery including open heart surgery." ...|$|E
50|$|Many {{configurations}} {{can be used}} {{to separate}} mixtures into the same products, though some schemes are more efficient, and different column sequencings are used to achieve different needs. For example, a zeotropic mixture ABC can be first separated into A and BC before separating BC to B and C. On the other hand, mixture ABC can be first separated into AB and C, and AB can lastly be separated into A and B. These two configurations are sharp-split configurations in which the intermediate boiling substance does not contaminate each separation step. On the other hand, the mixture ABC could first be separated into AB and BC, and lastly split into A, B, and C in the same column. This is a <b>non-sharp</b> split configuration in which the substance with the intermediate boiling point is present in different mixtures after a separation step.|$|E
5000|$|Mastretta's logo {{features}} a <b>non-sharped</b> shield with the colours of the Mexican flag (green, white and red) and a diagonal {{black and white}} racing stripe, representing the Mexican coat of arms. The name [...] "Mastretta" [...] appears across the top.|$|R
40|$|Biohazardous waste {{refers to}} wastes that are {{potentially}} infectious to humans, {{as well as}} wastes from animal or plant research that could be potentially infectious to these organisms, or could alter their genetic selection process. Research resulting in generation of biohazardous waste is typically conducted at large, research-based universities. The {{purpose of this study}} was to examine how 122 universities manage their biohazardous waste through a survey of environmental health and safety professionals responsible for waste management at these institutions. Based on the data colIected from this survey (82. 6 % response rate), university biohazardous waste policies are heavily influenced by state environmental regulations, the OSHA Bloodborne Pathogens Standard, and CDCINIH biosafety guidelines. Biosafety or hazardous materials professionals are the individuals most likely to be responsible for program administration. Contaminated wastes, both sharps and <b>non-sharps,</b> are almost exclusively treated as biohazardous waste by these institutions if they are a potential infection risk to humans. They are also likely to be treated as biohazardous waste if they are an infection risk fo...|$|R
40|$|Radius {{constants}} {{for several}} classes of analytic functions {{on the unit}} disk are obtained. These include the radius of starlikeness of a positive order, radius of parabolic starlikeness, radius of Bernoulli lemniscate starlikeness, and radius of uniform convexity. In the main, the radius constants obtained are sharp. Conjectures on the <b>non-sharp</b> constants are given...|$|E
40|$|We {{reconsider the}} {{applicability}} of classical nucleation theory (CNT) to the calculation of the free energy of solid cluster formation in a liquid and its use to the evaluation of interface free energies from nucleation barriers. Using two different freezing transitions (hard spheres and NaCl) as test cases, we first observe that the interface-free-energy estimates based on CNT are generally in error. As successive refinements of nucleation-barrier theory, we consider corrections due to a <b>non-sharp</b> solid-liquid interface and to a non-spherical cluster shape. Extensive calculations for the Ising model show that corrections due to a <b>non-sharp</b> and thermally fluctuating interface account for the barrier shape with excellent accuracy. The experimental solid nucleation rates that are measured in colloids are better accounted for by these non-CNT terms, whose effect appears to be crucial {{in the interpretation of}} data and in the extraction of the interface tension from them. Comment: 20 pages (text + supplementary material...|$|E
40|$|Abstract. Adaptation rules {{adapt the}} pre-post {{specification}} of a procedure to contexts {{where it is}} called. Such rules are important for practical reasons, and are necessary for completeness of proof systems for languages with recursive procedures. A sharp rule is one that gives the weakest precondition {{with respect to a}} given postcondition. A number of rules have been proposed for simple imperative languages with recursive procedures, most unsound or incomplete or <b>non-sharp.</b> Taking an algebraic approach, we clarify and extend the applicability of previously proposed sharp rules for total correctness, and show how further rules may be found...|$|E
40|$|We report {{results on}} the effect of a <b>non-sharp</b> and disordered {{potential}} in Quantum Well Infrared Photodetectors (QWIP). Scanning electronic transmission microscopy is used to measure the alloy profile of the structure which is shown to present a gradient of composition along the growth axis. Those measurements are used as inputs to quantify the effect on the detector performance (peak wavelength, spectral broadening and dark current). The influence of the random positioning of the doping is also studied. Finally we demonstrate that QWIP properties are quite robust with regard to the non ideality of the energy band profile...|$|E
40|$|We {{introduce}} a bidirectional associative memory. The stable {{points of the}} memory are natu-rally interpreted as (<b>non-sharp)</b> concepts|the memory performs association of extents and intents of concepts. We show that this memory is stable and that the set of all stable points forms a complete lattice. We propose a learning algorithm and prove that it enables perfect learning provided the train-ing set forms a consistent conceptual structure. Examples demonstrating the results are presented. Unlike {{in the case of}} other associative memories [1], the formal apparatus, architecture, dynamics and convergence proof etc. are based on algebraic structures of fuzzy logic in narrow sense...|$|E
40|$|Adaptation rules {{adapt the}} pre-post {{specification}} of a procedure to contexts {{where it is}} called. Such rules are important for practical reasons, and are necessary for completeness of proof systems for languages with recursive procedures. A sharp rule is one that gives the weakest precondition {{with respect to a}} given postcondition. A number of rules have been proposed for simple imperative languages with recursive procedures, most unsound or incomplete or <b>non-sharp.</b> Taking an algebraic approach, we clarify and extend the applicability of previously proposed sharp rules for total correctness, and show how further rules may be found...|$|E
40|$|Abstract. Gaussian {{stochastic}} diffusion {{processes are}} used to derive cosmic mass functions. To get analytic relations previous studies exploited the sharp k-space filter assumption yielding zero drift terms in the corresponding Fokker-Planck (Kolmogorov’s forward) equation and thus simplifying analytic treatments significantly (excursion set formalism). In the present paper methods are described to derive for given diffusion processes and Gaussian random fields the corresponding mass and filter functions by solving the Kolmogorov’s forward and backward equations including nonzero drift terms. This formalism {{can also be used}} in cases with <b>non-sharp</b> k-space filters and for diffusion processes exhibiting correlations between different mass scales...|$|E
40|$|In this paper, {{we use the}} {{perspective}} of linear series, and in particular results following from the degeneration tools of limit linear series, to give {{a number of new}} results on existence and non-existence of branched covers of the projective line in positive characteristic. Our results are both in terms of ramification indices and the sharper invariant of monodromy groups, and the first class of results are obtained by intrinsically algebraic and positive-characteristic arguments. Comment: 19 pages. Heavily revised. <b>Non-sharp</b> existence results removed, many examples added, and main theorem stated in stronger form with simpler proof, using the results of math. AG/ 060911...|$|E
40|$|Let S {{denote the}} family of all {{univalent}} functions f in the unit disk with the normalization f(0) = 0 = f'(0) - 1. There is an intimate relationship between the operator P_f(z) =f(z) /f'(z) and the Danikas-Ruscheweyh operator T_f:=∫_ 0 ^z(tf'(t) /f(t)) dt. In this paper we mainly consider the univalence problem of F=P_f, where f belongs to some subclasses of S. Among several sharp results and <b>non-sharp</b> results, we also show that if f∈ S, then F ∈ U in the disk |z|<r with r≤ r_ 6 ≈ 0. 360794 and conjecture that the upper bound for such r is √(2) - 1. Comment: 11 page...|$|E
40|$|This paper {{studies the}} issue of {{similarity}} relations in fuzzy concept lattices. Fuzzy concepts and fuzzy concept lattices represent a formal approach to the modelling of <b>non-sharp</b> (fuzzy) concepts and conceptual structures {{in the sense of}} traditional (Port-Royal) logic. Applications of concept lattices are in representation of conceptual knowledge and in conceptual analysis of (fuzzy) data. Similarity relations are defined and considered on three levels: similarity of objects (and similarity of attributes), similarity of concepts, and similarity of concept lattices. We show a way to factorize (simplify) concept lattices by the similarity of concepts. Also shown is how to reduce the computation of the similarity relations...|$|E
40|$|We study, via Monte Carlo simulation, {{the dynamic}} {{critical}} {{behavior of the}} Chayes-Machta dynamics for the Fortuin-Kasteleyn random-cluster model, which generalizes the Swendsen-Wang dynamics for the q-state Potts ferromagnet to non-integer q > 1. We consider spatial dimension d= 2 and 1. 25 β/ν is violated, though we also present plausible fits compatible with this conjecture. We show that the Li-Sokal bound z_CM>α/ν is close to being sharp over the entire range 1 < q < 4, but is probably <b>non-sharp</b> by a power. As a byproduct of our work, we also obtain evidence concerning the corrections to scaling in static observables. Comment: LaTeX 2 e, 75 pages including 26 Postscript figure...|$|E
40|$|Gaussian {{stochastic}} diffusion {{processes are}} used to derive cosmic mass functions. To get analytic relations previous studies exploited the sharp $k$-space filter assumption yielding zero drift terms in the corresponding Fokker-Planck (Kolmogorov's forward) equation and thus simplifying analytic treatments significantly (excursion set formalism). In the present paper methods are described to derive for given diffusion processes and Gaussian random fields the corresponding mass and filter functions by solving the Kolmogorov's forward and backward equations including nonzero drift terms. This formalism {{can also be used}} in cases with <b>non-sharp</b> $k$-space filters and for diffusion processes exhibiting correlations between different mass scales. Comment: 17 pages, 8 figures, accepted for publication in Astronomy and Astrophysics, also available at [URL]...|$|E
40|$|Given a {{monotone}} graph property P, consider p (P), {{the probability}} that a random graph with edge probability p will have P. The function d p (P) =dp is the key to understanding the threshold behavior of the property P. We show that if d p (P) =dp is small (corresponding to a <b>non-sharp</b> threshold), then there is a list of graphs of bounded size such that P can be approximated by the property of having one of the graphs as a subgraph. One striking consequences of this result is that a coarse threshold for a random graph property can only happen when the value of the critical edge probability is a rational power of n...|$|E
40|$|In 1997, Thomas Wolff proved sharp L^ 3 bounds for his {{circular}} maximal function, and in 1999, Kolasa and Wolff proved certain <b>non-sharp</b> L^p inequalities for {{a broader}} class of maximal functions arising from curves of the form {Φ(x,·) =r}, where Φ(x,y) satisfied Sogge's cinematic curvature condition. Under the additional hypothesis that Φ is algebraic, we obtain a sharp L^ 3 bound on the corresponding maximal function. Since the function Φ(x,y) =|x-y| is algebraic and satisfies the cinematic curvature condition, our result generalizes Wolff's L^ 3 bound. The algebraicity condition allows us to employ the techniques of vertical cell decompositions and random sampling, which have been extensively developed in the computational geometry literature. Comment: 26 pages, 2 figure...|$|E
40|$|Abstract. In 1997, Thomas Wolff proved sharp L 3 bounds for his {{circular}} maximal function, and in 1999, Kolasa and Wolff proved certain <b>non-sharp</b> Lp inequalities for {{a broader}} class of maximal functions arising from curves of the form {Φ(x, ·) = r}, where Φ(x, y) satisfied Sogge’s cinematic curvature condition. Under the additional hypothesis that Φ is algebraic, we obtain a sharp L 3 bound on the corresponding maximal function. Since the function Φ(x, y) = |x − y | is algebraic and satisfies the cinematic curvature condition, our result generalizes Wolff’s L 3 bound. The algebraicity condition allows us to employ the techniques of vertical cell decompositions and random sam-pling, which have been extensively developed in the computational geometry literature...|$|E
40|$|We {{prove that}} given a {{hyperbolic}} manifold endowed with an auxiliary Riemannian metric with negative sectional curvature and sufficently small volume {{in comparison to}} the hyperbolic one, we can always find for any radius at least 1 a ball in its universal cover whose volume is bigger than the hyperbolic one. This is a corollary of another result holding without any curvature assumption that can be interpreted as a <b>non-sharp</b> macroscopic version of a conjecture by R. Schoen about scalar curvature. The main ingredient in the proof of these results is an inequality due to M. Gromov called smoothing inequality. One purpose of this work is to present a full and detailed account of this inequality which involves simplicial volume and deserves to be better known. Comment: 18 page...|$|E
40|$|Abstract. For a hyponormal operator, C. R. Putnam’s {{inequality}} {{gives an}} {{upper bound on}} the norm of its self-commutator. In the special case of a Toeplitz operator with analytic symbol in the Smirnov space of a domain, {{there is also a}} geometric lower bound shown by D. Khavinson (1985) that when combined with Putnam’s inequality implies the classical isoperimetric inequality. For a nontrivial domain, we compare these estimates to exact results. Then we consider such operators acting on the Bergman space of a domain, and we obtain lower bounds that also reflect the geometry of the domain. When combined with Putnam’s inequality they give rise to the Faber-Krahn inequality for the fundamental frequency of a domain and the Saint-Venant inequality for the torsional rigidity (but with <b>non-sharp</b> constants). 1...|$|E
40|$|Superstructure {{approaches}} are {{the solution to}} the difficult problem which involves the rigorous economic design of a distillation column. These methods require complex initialization procedures and they are hard to solve. For this reason, these methods have not been extensively used. In this work, we present a methodology for the rigorous optimization of chemical processes implemented on a commercial simulator using surrogate models based on a kriging interpolation. Several examples were studied, but in this paper, we perform the optimization of a superstructure for a <b>non-sharp</b> separation to show the efficiency and effectiveness of the method. Noteworthy {{that it is possible to}} get surrogate models accurate enough with up to seven degrees of freedom. The authors with to acknowledge the financial support by the Ministry of Economy and Competitiveness from Spain, under the project CTQ 2012 - 37039 -C 02 - 02...|$|E
40|$|The {{effects of}} {{different}} filtering strategies on the statistical {{properties of the}} resolved-to-sub-filter scale (SFS) energy transfer are analyzed in forced homogeneous and isotropic turbulence. We carry out a priori analyses of statistical characteristics of SFS energy transfer by filtering data obtained from direct numerical simulations (DNS) with up to $ 2048 ^ 3 $ grid points {{as a function of}} the filter cutoff scale. In order to quantify the dependence of extreme events and anomalous scaling on the filter, we compare a sharp Fourier Galerkin projector, a Gaussian filter and a novel class of Galerkin projectors with <b>non-sharp</b> spectral filter profiles. Of interest is the importance of Galilean invariance and we confirm that local SFS energy transfer displays intermittency scaling in both skewness and flatness {{as a function of the}} cutoff scale. Furthermore, we quantify the robustness of scaling as a function of the filtering type...|$|E
40|$|Recent {{experiments}} have reached detection efficiencies sufficient {{to close the}} detection loophole, testing the Clauser-Horne (CH) version of Bell's inequality. For a similar future experiment to be completely loophole-free, {{it will be important}} to have discrete experimental trials with randomized measurement settings for each trial, and the statistical analysis should not overlook the possibility of a local state varying over time with possible dependence on earlier trials (the "memory loophole"). In this paper, a mathematical model for such a CH experiment is presented, and a method for statistical analysis that is robust to memory effects is introduced. Additionally, a new method for calculating exact p-values for martingale-based statistics is described; previously, only <b>non-sharp</b> upper bounds derived from the Azuma-Hoeffding inequality have been available for such statistics. This improvement decreases the required number of experimental trials to demonstrate non-locality. The statistical techniques are applied to the data of recent experiments and found to perform well. Comment: To appear in Journal of Physics A: Mathematical and Theoretica...|$|E
40|$|We present two {{possible}} thermodynamical approaches towards a derivation of a model, proposed by Korteweg {{at the beginning}} of the 20 th century, that is suitable to describe phase transitions liquid-vapor with <b>non-sharp</b> interfaces. The first approach (Dunn, Serrin (1985)) is based on classical rational continuum thermodynamics. The second approach (Heida, Málek (2010)) stems from the principles of classical nonequilibrium continuum thermodynamics. We compare both approaches in favor of the second one. The considered constitutive equation for the Cauchy stress is nonlinear. Nonlinearity and higher order derivatives of the density makes the analysis of relevant problems for the Navier-Stokes- Korteweg (NSK) fluid more difficult in comparison to problems concerning Navier-Stokes equations. Special attention is devoted to the appropriate choice of the boundary conditions. We also investigate the influence of compressibility on the stability of bubbles by comparing numerical simulations for compressible NSK fluid and its incompressible variant. Instabilities observed for a compressible NSK fluid are due to the pressure that has a different meaning for incompressible fluid. Powered by TCPDF (www. tcpdf. org...|$|E
40|$|Many {{results have}} been proved for various nuclear norm penalized estimators of the uniform {{sampling}} matrix completion problem. However, most of these estimators are not robust: {{in most of the}} cases the quadratic loss function and its modifications are used. We consider robust nuclear norm penalized estimators using two well-known robust loss functions: the absolute value loss and the Huber loss. Under several conditions on the sparsity of the problem (i. e. the rank of the parameter matrix) and on the regularity of the risk function sharp and <b>non-sharp</b> oracle inequalities for these estimators are shown to hold with high probability. As a consequence, the asymptotic behavior of the estimators is derived. Similar error bounds are obtained under the assumption of weak sparsity, i. e. the case where the matrix is assumed to be only approximately low-rank. In all our results we consider a high-dimensional setting. In this case, this means that we assume n≤ pq. Finally, various simulations confirm our theoretical results. Comment: 45 pages, 4 figure...|$|E
40|$|Abstract. We {{establish}} long-time {{stability of}} multi-dimensional viscous shocks {{of a general}} class of symmetric hyperbolic–parabolic systems with variable multiplicities, notably including the compressible magnetohydrodynamics (MHD) equations in dimensions d ≥ 2. We show that the L 2 stability estimate for the low-frequency regime established by O. Guès, G. Métivier, M. Williams, and K. Zumbrun (GMWZ) via the construction of degenerate Kreiss ’ symmetrizers, together with high-frequency estimates for the solution operator investigated by K. Zumbrun, is sufficient for our analysis to provide the long-time stability of arbitrary-amplitude multi-dimensional viscous shocks with (possibly <b>non-sharp)</b> rates of decay, provided the uniform spectral, or Evans, stability condition. This extends the existing result of K. Zumbrun, by relaxing the constant multiplicity assumption (H 4) to a variable multiplicity assumption (H 4 ’) and dropping the assumption (H 5) on structure of the so–called glancing set. The key idea to the improvement is to introduce a new simple argument for obtaining a L 1 → L p resolvent bound, replacing the one obtained b...|$|E
40|$|Given a {{monotone}} graph property P, consider p(P), {{the probability}} that a random graph with edge probability p will have P. The function d p(P) =dp is the key to understanding the threshold behavior of the property P. We show thatifd p(P) =dp is small (corresponding to a <b>non-sharp</b> threshold), then there is a list of graphs of bounded size such that P can be approximated by the property ofhaving one of the graphs as a subgraph. One striking consequences of this result is that a coarse threshold for a random graph property can only happen when the value of the critical edge probability is a rational power of n. As an application of the main theorem we settle the question of the existence of a sharp threshold for the satis ability of a random k-CNF formula. An appendix by Jean Bourgain was added after the rst version of this paper was written. In this appendix some of the conjectures raised in this paper are proven, along with more general results...|$|E
40|$|The rounded {{leading edge}} shapes include low, medium, and high leadingedge radii. The {{experimental}} data base {{is used to}} expand the knowledge about the flow topology and flow physics and to verify and validate computational codes. This paper focuses on the flow topology around the VFE- 2 delta wing with medium rounded leading edges at different Reynolds numbers and angles of attack using various turbulence models, especially RANS and hybrid models such as DES and DDES. The overall goal is to understand more fully the flow topology for these <b>non-sharp</b> leading-edge delta wings. Previous numerical studies on the VFE- 2 delta wings have been limited, with Londenberg showing results for the sharp leading-edge delta wing under transonic conditions and Chiba and Obayashi performing calculations of the dual primary vortices that form on the medium radius leading edge. The topology of the dual primary vortices is especially interesting, and {{formed the basis for}} the majority of papers in two special sessions at the 46 th AIAA Aerospace Sciences Meeting and Exhibit in 2008...|$|E
40|$|This {{article was}} {{published}} in the journal, Drug Delivery [© Informa] and the definitive version is available at: [URL] recent years there has been a surge in the research and development of microneedles, a transdermal delivery system that combines the technology of transdermal patches and hypodermic needles. The needles are in the hundreds of micron length range and therefore allow relatively little or no pain. For example, biodegradable microneedles have been researched in the literature and have several advantages compared to solid or hollow microneedles, as they produce <b>non-sharp</b> waste and can be designed to allow rapid or slow release of drugs. However they also pose a disadvantage as successful insertion into the stratum corneum layer of the skin relies on sufficient mechanical strength of the biodegradable material. This review looks at the various technologies developed in microneedle research and shows the rapidly growing numbers of research papers and patent publications since the first invention of microneedles (using time series statistical analysis). This provides the research and industry communities a valuable synopsis of the trends and progress being made in this field...|$|E
40|$|We {{study the}} {{calculation}} of exact p-values for a large class of <b>non-sharp</b> null hypotheses about treatment effects in a setting with data from experiments involving members of a single connected network. The class includes null hypotheses that limit the effect of one unit's treatment status on another according to the distance between units; for example, the hypothesis might specify that the treatment status of immediate neighbors has no effect, or that units more than two edges away have no effect. We also consider hypotheses concerning the validity of sparsification of a network (for example based {{on the strength of}} ties) and hypotheses restricting heterogeneity in peer effects (so that, for example, only the number or fraction treated among neighboring units matters). Our general approach is to define an artificial experiment, such that the null hypothesis that was not sharp for the original experiment is sharp for the artificial experiment, and such that the randomization analysis for the artificial experiment is validated by the design of the original experiment. Comment: 40 page...|$|E
40|$|Abstract Background Adequate {{management}} of healthcare waste (HCW) {{is a prerequisite}} for efficient delivery of healthcare services. In Nigeria, there are several constraints militating against proper {{management of}} HCW. This is raising some environmental concerns among stakeholders in the health sector. In this study, we analyzed the practices of HCW management and determinants of risky/safe indices of HCW disposal. Methods The study used the 2013 / 2014 Service Delivery Indicator (SDI) data that were collected from 2480 healthcare facilities in Nigeria. Descriptive statistics, Principal Component Analysis (PCA) and Ordinary Least Square (OLS) regression were used to analyze the data. Results The results showed that 52. 20 % and 38. 21 % of the sampled healthcare facilities from Cross River and Bauchi states possessed guidelines for HCW management, respectively. Trainings on management of HCW were attended by 67. 18 % and 53. 19 % of the healthcare facilities from Cross River and Imo states, respectively. Also, 32. 32 % and 29. 50 % of healthcare facilities from rural and urban areas previously sent some of their staff members for trainings on HCW management, respectively. Sharp and <b>non-sharp</b> HCW were burnt in protected pits in 45. 40 % and 45. 36 % of all the sampled healthcare facilities, respectively. Incinerators were reported to be functional in only 2. 06 % of the total healthcare facilities. In Bauchi and Kebbi states, 23. 58 % and 21. 05 % of the healthcare facilities respectively burnt sharp HCW without any protection. Using PCA, computed risky indices for disposal of sharp HCW were highest in Bayelsa state (0. 3070) and Kebbi state (0. 2172), while indices of risky disposal of <b>non-sharp</b> HCW were highest in Bayelsa state (0. 2868) and Osun state (0. 2652). The OLS results showed that at 5 % level of significance, possession of medical waste disposal guidelines, staff trainings on HCW management, traveling hours from the facilities to local headquarters and being located in rural areas significantly influenced indices of risky/safe medical waste disposal (p <  0. 05). Conclusion The study concluded that there was low compliance with standard HCW management. It was recommended that possession of HCW management guidelines, staff training on HCW disposal and provision of requisite equipment for proper treatment of HCW would promote environmental safety in HCW disposal...|$|E
40|$|Student Number : 9510423 G PhD Thesis School of Chemical and Metallurgical Engineering Faculty of Engineering and the Built EnvironmentTechniques for {{the design}} and {{analysis}} of simple column separations are well established. Shortcut design techniques have been employed in the initial design of these “traditional” distillation systems {{for a number of}} years and these columns are well understood. However, few currently available techniques are useful in the design of novel or complex configurations. The techniques that are available tend to be configuration specific. An all inclusive or universal, design and analysis tool, that can be applied to any and all configurations, is required. Tapp et al (2004) introduced Column Profile Maps (CPMS) as a means of addressing this issue. These are maps of composition profiles for column sections with defined net-molar-flow and reflux ratio. It is suggested that by producing CPMs for a configuration a designer can essentially superimpose these, determine feasible operating profiles and hence column operating parameters. In this thesis we show that this technique can be used to, not only produce quick and easy complex column designs but gain a comprehensive understanding of the steady-state operation of these arrangements. We demonstrate this analytical potential first by application of the CPM technique to the two-product feed distribution problem. It is shown that feed distribution can lower the minimum required reflux ratio for <b>non-sharp</b> separations and in some cases produce feasible separations from previously infeasible product specifications. A composition region of operation for all distributed feed policies is also found. The potential for detailed analysis, design and optimisation of complex configurations is demonstrated via application of the CPM procedure to the fully thermally coupled (Petlyuk) distillation column at both sharp and <b>non-sharp</b> split conditions. A detailed design methodology for any configuration results from this. It is found that the Petlyuk column can operate under five possible bulk/net flow conditions and that very interesting and counter-intuitive net-molar-flows are possible. A feasible column parameter region equivalent to the optimality region (Halvorsen and Skogestad, 2001) is found for zeotropic systems. Importantly a minimum reflux condition for the Petlyuk column is found. This condition can be applied to all zeotropic systems for all product specifications. It is also demonstrated that the CPM technique can be used for design optimisation of separation systems...|$|E
40|$|We {{investigate}} {{the rate of}} convergence of linear sampling numbers of the embedding H^α,β (T^d) H^γ (T^d). Here α governs the mixed smoothness and β the isotropic smoothness in the space H^α,β(T^d) of hybrid smoothness, whereas H^γ(T^d) denotes the isotropic Sobolev space. If γ>β we obtain sharp polynomial decay rates for the first embedding realized by sampling operators based on "energy-norm based sparse grids" for the classical trigonometric interpolation. This complements earlier work by Griebel, Knapek and Dũng, Ullrich, where general linear approximations have been considered. In addition, we study the embedding H^α_mix (T^d) H^γ_mix(T^d) and achieve optimality for Smolyak's algorithm applied to the classical trigonometric interpolation. This {{can be applied to}} {{investigate the}} sampling numbers for the embedding H^α_mix (T^d) L_q(T^d) for 2 <q≤∞ where again Smolyak's algorithm yields the optimal order. The precise decay rates for the sampling numbers in the mentioned situations always coincide with those for the approximation numbers, except probably in the limiting situation β = γ (including the embedding into L_ 2 (T^d)). The best what we could prove there is a (probably) <b>non-sharp</b> results with a logarithmic gap between lower and upper bound...|$|E
40|$|Oxy-chloride bismuth-borate {{glasses with}} {{composition}} xMgCl 2 ·(30  − x) MgO· 20 Bi 2 O 3 · 50 B 2 O 3 containing 2  mol% doping of V 2 O 5 (x =  12, 15, 20, 25 and 30) are prepared by melt-quenching technique. The structural, thermal and optical behaviors are explained {{by analyzing the}} data obtained from density (D), molar volume (Vm), theoretical optical basicity (Λth), differential scanning calorimetry (DSC), FTIR and UV–vis results. A decrease in D and increase in Vm (except for sample MBV 3 for which D is maximum) on increasing chloride content suggests the formation of non-bridging oxygen atoms. Maximum glass transition temperature (Tg) and crystallization temperature (Tx) have been observed for sample MBV 3. The glass stability (S) and stability ratio (S/Tg) have been calculated from the values of Tg and Tx and both are having maximum values for sample MBV 3. Study of the FTIR spectra in the mid-IR range reveals the presence of both triangular and tetrahedral coordinated boron. The optical studies through UV–vis spectral analysis show <b>non-sharp</b> edge. The optical band gap (Eg) is also maximum for sample MBV 3...|$|E
