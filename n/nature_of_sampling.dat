31|10000|Public
50|$|The {{simplest}} algorithm. The pixel {{is split}} into several sub-pixels, and a sample {{is taken from}} the center of each. It is fast and easy to implement. Although, due to the regular <b>nature</b> <b>of</b> <b>sampling,</b> aliasing can still occur if a low number of sub-pixels is used.|$|E
40|$|Protein {{identification}} and quantitation using mass spectrometry has evolved {{as the dominant}} technique for studying the protein complement of a system: cell, tissue or organism. The proteomics of body fluids is a very active research area as there is great potential for protein biomarker discovery; application of such technologies would revolutionise medical practice and treatment. Saliva, through its non intrusive <b>nature</b> <b>of</b> <b>sampling,</b> is an ideal body fluid for disease diagnosis, screening and monitoring. Gingivitis is a gum disease with symptoms including bleeding, swollen, and receding gums. After dental decay, gingivitis {{is estimated to be}} the most common disease worldwide, and around 40...|$|E
40|$|The {{development}} and use of pest damage functions involves measurement and experimental errors associated with cultural, environmental, and distributional factors. Damage predictions are more valuable if considered with associated probability. Collapsing population densities into a geometric series of population classes allows a pseudo-replication removal of experimental and sampling error in damage function development. Recognition of the <b>nature</b> <b>of</b> <b>sampling</b> error for aggregated populations allows assessment of probability associated with the population estimate. The product of the probabilities incorporated in the damage function and in the population estimate provides a basis for risk analysis of the yield loss prediction and the ensuing management decision...|$|E
30|$|The result {{showed that}} the {{rheological}} <b>nature</b> <b>of</b> <b>samples</b> had acceptable correlation with the factors obtained by thermal analysis method. In other words, in this work a simple and reproducible experimental method was developed to efficiently predict the rheological properties of rubber blends.|$|R
40|$|Syringe-push {{membrane}} a hu Urine is {{an ideal}} source for clinical proteomic analysis due to non-invasive <b>nature</b> <b>of</b> <b>sample</b> collection [1, 2]. In omic analysis [1, 2]. Therefore, good processing <b>of</b> urine <b>samples</b> is crucial for non-invasive biomarker discovery precipitation rovide a high ss, some tech-e-consuming, and/or high...|$|R
40|$|Palladium hollow spheres were {{synthesized}} at {{room temperature}} using cobalt nanoparticles (NPs) as sacrificing templates. Cobalt NPs can be prepared simply by solvothermal method. The hollow <b>nature</b> <b>of</b> <b>sample</b> Pd were observed from the TEM image and the SAED pattern indicates the polycrystalline <b>nature</b> <b>of</b> the <b>sample.</b> It was found that Pd hollow spheres showed high catalytic activity towards the electrooxidation of alcohols, especially ethanol with the current density up to 2047 mA mg- 1. The formation mechanism and the structure-property relationship of Pd hollow spheres were discussed based on the experimental results...|$|R
40|$|We {{study the}} {{statistical}} convergence and consistency of regularized Boosting methods, where the samples are not independent and identically distributed (i. i. d.) but come from empirical processes of stationary β-mixing sequences. Utilizing {{a technique that}} constructs a sequence of independent blocks close in distribution to the original samples, we prove {{the consistency of the}} composite classifiers resulting from a regularization achieved by restricting the 1 -norm of the base classifiers ’ weights. When compared to the i. i. d. case, the <b>nature</b> <b>of</b> <b>sampling</b> manifests in the consistency result only through generalization of the original condition on the growth of the regularization parameter. ...|$|E
40|$|Abstract—This paper proposes an {{adaptation}} engine for a 2 blind sampling ADC-based receiver. The proposed adaptive engine uses a triangular desired waveform, {{instead of two}} fixed desired levels, to shape the equalizer output in spite of blind <b>nature</b> <b>of</b> <b>sampling.</b> The measured results confirm the adaptive engine restores a 5 Gb/s eye subjected to 13 dB of attenuation at Nyquist frequency to an equivalent of 320 mV of vertical opening. The receiver consumes 192 mW, out of which 78 mW {{is used by the}} digital CDR. Index Terms—Adaptation, ADC, blind sampling, CDR, DFE, equalizer. Fig. 1. Block diagram of (a) a typical binary CDR and (b) an ADC-based CDR. I...|$|E
40|$|In {{a recent}} paper, Davies and Anderssen (1997) {{examined}} {{the range of}} relaxation times, on which the linear viscoelasticity relaxation spectrum could be reconstructed, when the oscillatory shear data were only known on a fixed finite interval of frequencies. In particular, they showed that, for such oscillatory shear data, knowledge about the relaxation spectrum could only be recovered on a specific finite interval of relaxation times. They referred to this phenomenon as sampling localisation. The purpose of this note is show how their result can be proved using a duality argument, and, thereby, establish the fundamental <b>nature</b> <b>of</b> <b>sampling</b> localisation in relaxation spectrum recover...|$|E
40|$|An {{attempt was}} made to {{investigate}} the social network of thirty two first admission cases of Schizophrenia, vis-a-vis thirty one non-schizophrenic psyhiatric patients. The social network of the two groups did not differ significantly. The findings are discussed in relation to the <b>nature</b> <b>of</b> <b>sample</b> and the control group...|$|R
40|$|We specify {{necessary}} {{conditions for}} getting parametric convergence rate of kernel density estimators. For continuous-time processes observed over [0, T], {{we show that}} two possible exact rates are (ln T) /T and 1 /T, according to the <b>nature</b> <b>of</b> <b>sample</b> paths. Nonparametric estimation Superoptimal rate Continuous-time process Kernel density estimator...|$|R
40|$|Abstract We {{review the}} variety of {{existing}} modelling approaches applied to species habitat mapping and we discuss issues arising from the availability and <b>nature</b> <b>of</b> <b>sampled</b> biological data and corresponding ecological and environmental habitat descriptors, {{as well as the}} different spatial analysis approaches that are selected according to specific hypotheses. We focus on marine species habitat mapping, presenting an overview of work o...|$|R
40|$|We {{consider}} a market where buyers can access unbiased samples of private data by appropriately compensating the individuals {{to whom the}} data corresponds (the sellers) according to their privacy attitudes. We show how bundling the buyers’ demand can decrease the price that buyers have to pay per data point, while ensuring that sellers are willing to participate. Our approach leverages the inherently randomized <b>nature</b> <b>of</b> <b>sampling,</b> along with the risk-averse attitude of sellers. We take a prior-free approach and introduce mechanisms that incentivize each individual to truthfully report his preferences in terms of different payment schemes. We then show that our mechanisms provide optimal price guarantees in several settings...|$|E
40|$|We {{have tested}} the {{hypothesis}} that coarse-scale environmental features are associated with spatial variation in bovine tuberculosis (BTB) prevalence, based on extensive sampling and testing of cattle {{in the state of}} Jalisco, Mexico. Ecological niche models were developed to summarize relationships between BTB occurrences and aspects of climate, topography and surface. Model predictions, however, reflected the distributions of dairy cattle versus beef cattle, and the non-random <b>nature</b> <b>of</b> <b>sampling</b> any cattle, but did not succeed in detecting environmental correlates at spatial resolutions of 1 km. Given that the tests employed seek any predictivity better than random expectations, making the finding of no environmental associations conservative, we conclude that BTB prevalence is independent of coarsescale environmental features...|$|E
40|$|Abstract — This paper {{studies the}} {{statistical}} convergence and consistency of regularized boosting methods, where the samples {{need not be}} independent and identically distributed but can come from stationary weakly dependent sequences. Consistency is proven for the composite classifiers that result from a regular-ization achieved by restricting the 1 -norm of the base classifiers’ weights. The less restrictive <b>nature</b> <b>of</b> <b>sampling</b> considered here is manifested in the consistency result through a generalized condition on {{the growth of the}} regularization parameter. The weaker the sample dependence, the faster the regularization parameter is allowed to grow with increasing sample size. A consistency result is also provided for data-dependent choices of the regularization parameter. Index Terms — Bayes-risk consistency, beta-mixing, boosting, classification, dependent data, empirical processes, memory...|$|E
40|$|In mammals, an {{adequate}} level of iodine consumption {{is necessary for}} maintaining normal functioning and development. In human studies, measurement of urinary iodide is preferable due to the non-invasive <b>nature</b> <b>of</b> <b>sample</b> collection if reproducibility of determination procedures can be assured. We compare here urinary iodide measurements using an ion selective electrode and ion chromatography-mass spectrometry. The applicability <b>of</b> a <b>sample</b> treatment procedure previously developed for perchlorate in urine to iodide analysis is explored...|$|R
30|$|The first {{important}} step in scRNA-seq is to isolate single-cells from tissues keeping their expression patterns as accurate as possible. Several technologies have been used, such as: FACS (Fluorescence-activated cell sorting), MACS (Magnetic-activated cell sorting), LCM (Laser capture microdissection), manual cell picking and microfluidics. Depending on the <b>nature</b> <b>of</b> <b>samples,</b> different methods may be more suitable for single-cell isolation in distinct samples. In this section, we will discuss some methods used for isolating brain cells.|$|R
40|$|Although {{several studies}} {{in recent years}} have {{provided}} evidence of a relationship between month of birth and height during childhood, the association remains less clear for adult (final) height. Here, I investigated this relationship using a large international <b>sample</b> <b>of</b> adult actors. Analyses considered both the sample as a whole, as well as subsamples based on nationality, and treated men and women separately. In all instances, I found no relationship between birth month or season and height, even after controlling for year of birth. This {{may be due to the}} particular <b>nature</b> <b>of</b> <b>samples</b> <b>of</b> actors, who are taller than the general population, or could suggest more broadly that birth month effects are minimal or absent in adults...|$|R
40|$|Speech {{assessments}} are commonly based on structured elicitation tasks. Despite {{the value of}} these tasks, the extent to which their results are a valid reflection of natural speech performance is being increasingly questioned. This is particularly warranted in the light of research findings indicating significant differences in normal speech behaviour across sampling tasks. There is, however, a paucity of research into how disordered speakers' performance varies across elicitation tasks. This study investigated ten prosodic parameters in structured and unstructured speech tasks (reading and conversation) in 12 dysarthric and 12 control subjects. The results suggest that the <b>nature</b> <b>of</b> <b>sampling</b> task affected dysarthric speakers differently to the control group. The implications of these findings for the assessment of disordered speakers are addressed...|$|E
40|$|Consider {{the context}} of {{constrained}} simulation optimization (SO), that is, optimization problems where the objective function and constraints are known through a Monte Carlo simulation, with corresponding estimators possibly dependent. We identify the <b>nature</b> <b>of</b> <b>sampling</b> plans that characterize efficient algorithms, particularly in large countable spaces. We show that in a certain asymptotic sense, the optimal sampling characterization, that is, the sampling budget for each system that guarantees optimal convergence rates, depends on a single easily estimable quantity called the score. This result provides a useful and easily implementable sampling allocation that approximates the optimal allocation, which is otherwise intractable due to it being the solution to a difficult bilevel optimization problem. Our results point to a simple sequential algorithm for efficiently solving large-scale constrained simulation optimization problems on finite sets. ...|$|E
30|$|Fire-scarred slabs were sanded {{to a high}} polish, then cross-dated {{against a}} master {{chronology}} using standard dendrochronological techniques to assign calendar years to fire scars (specific methodology was as explained in Brown and Wu 2005). Except when confined by the fire scar study area boundary, we mapped the spatial extent of fires recorded by scars within our study area by constructing a convex hull polygon around trees (3 minimum) that recorded a particular fire (Bekker and Taylor 2001). While a complete census of all fire-scarred trees would be optimal for the most accurate reconstruction of fire extent, doing so would be infeasible due to the effort required and destructive <b>nature</b> <b>of</b> <b>sampling</b> fire scars. Our relatively complete spatial coverage across the Illilouette and Sugarloaf study areas (Figure 1) allows us to make reasonable assertions on tree scarring patterns.|$|E
500|$|Decreased foramaniferal {{abundance}} – which due to {{the pristine}} <b>nature</b> <b>of</b> many <b>samples</b> cannot be attributed to preservational bias and has been related to reduced salinity (Bond 1992) ...|$|R
30|$|Overall, therefore, {{this study}} {{had access to}} over 100 returns in total with 85 fully {{completed}} and useful questionnaires. The <b>nature</b> <b>of</b> this <b>sample</b> is discussed in the next sub-section.|$|R
30|$|The use of {{population}} registers for sampling is a {{gold standard for}} obtaining representative probabilistic samples (Reichel & Morales, 2017), however they do not always contain the necessary categories to identify immigrant population, or their coverage of this target population is imperfect, which also hinders the representativeness and unbiased <b>nature</b> <b>of</b> <b>samples</b> obtained from these registers. This article focuses on the specific challenges to sample immigrant population in two recent destination countries, Spain and Italy, which furthermore register high levels of irregularity.|$|R
40|$|In {{networked}} control systems, {{the advent}} of event-triggering strategies in the sampling process {{has resulted in the}} usage reduction of network capacities, such as communication bandwidth. However, the aperiodic <b>nature</b> <b>of</b> <b>sampling</b> periods generated by event-triggering strategies has hindered the schedulability of such networks. In this study, we propose a framework to construct a timed safety automaton that captures the sampling behavior of perturbed LTI systems with an L_ 2 -based triggering mechanisms proposed in the Literature. In this framework, the state-space is partitioned into a finite number of convex polyhedral cones, each cone representing a discrete mode in the abstracted automaton. Adopting techniques from stability analysis of retarded systems accompanied with a polytopic embedding of time, LMI conditions to characterize the sampling interval associated with each region are derived. Then, using reachability analysis, the transitions in the abstracted automaton are derived. Comment: 8 pages, 4 figures, technical repor...|$|E
40|$|AbstractBrand {{experience}} has been gaining increased importance in marketing literature, as marketers consider it a vital strategy in building long term consumer-brand relationship. This study attempts to do a comprehensive assessment and synthesis of academic literature on brand experience. To do this, authors take up a systematic review, identifies and analyses 73 relevant articles from 38 journals. The analysis provides significant information about–empirical versus conceptual studies, industry focus, country of research, research design, data analysis techniques and <b>nature</b> <b>of</b> <b>sampling</b> method and respondents. This study presents methodological trend in brand experience studies with reference to Meredith,Raturi, Amoako-Gyampah, and Kaplan (1989) framework, {{and it has been}} found that majority of the studies are based on people's perception of object reality (logical positivist/empiricist paradigm based researches). A conceptual framework about brand experience antecedents and consequences is also presented. At last, we provide discussion and suggestions for future research, followed by limitations of the study...|$|E
40|$|Consider {{the context}} of {{constrained}} simulation optimization (SO), that is, optimization problems where the objective and constraint functions are known through dependent Monte Carlo estimators. We identify the <b>nature</b> <b>of</b> <b>sampling</b> plans that characterize efficient algorithms for solving such problems, particularly in large finite spaces. We show that in a certain asymptotic sense, the sampling budget across systems that guarantees optimal convergence rates depends on a single intuitive measure called the score. This result inspires a useful and easily implementable sampling allocation scheme that consistently approximates the optimal allocation, otherwise intractable due {{to the need to}} solve a bilevel optimization problem. Numerical experience with the proposed sampling scheme shows great promise toward solving large-scale constrained SO problems. For instance, examples of constrained SO problems having several thousands of systems have been solved within seconds on a typical laptop computer. Our results subsume various sampling heuristics for specialized SO contexts that have appeared in the literature recently. Key words: constrained simulation optimization; ranking and selectio...|$|E
30|$|SnO–V 2 O 5 –SiO 2 glass anode sample {{prepared}} by simple a mechanical milling technique. The amorphous <b>nature</b> <b>of</b> <b>sample</b> identified using with XRD technique. This glass anode has an initial charge capacity of 560 mAhg− 1 and discharge capacity of 483 mAhg− 1. After 20 charge–discharge cycles, charge and discharge capacities achieved to be 389 and 379 mAhg− 1 at 0.1 C, respectively. The loss in discharge capacity is up to[*]~[*] 45.22 % even at high rate 5 C.|$|R
25|$|Various buffer {{systems are}} used in PAGE {{depending}} on the <b>nature</b> <b>of</b> the <b>sample</b> and the experimental objective. The buffers used at the anode and cathode may be the same or different.|$|R
40|$|Monitoring of root systems {{development}} and crop residues decomposition is only possible if these constituents can be discriminated from soil and quantified. In this work, Near Infrared (NIR) combined with Hyperspectral Imaging (HSI) and Partial Least Square Discriminant Analysis (PLS-DA) is proposed {{as a new}} rapid and reliable method to discriminate soil, roots and straws. NIR-HSI provides simultaneously spectral and spatial information and PLS-DA allows discrimination between classes based on spectra of each pixel linked to chemical <b>nature</b> <b>of</b> <b>sample</b> constituents on the image...|$|R
40|$|In {{this work}} {{we deal with}} {{correlated}} failure time (age at onset) data arising from population-based case-control studies, where case and control probands are selected by population-based sampling {{and an array of}} risk factor measures is collected for both cases and controls and their relatives. Parameters of interest are effects of risk factors on the hazard function of failure times and within-family dependencies of failure times after adjusting for the risk factors. Due to the retrospective <b>nature</b> <b>of</b> <b>sampling,</b> a large sample theory for existing methods has not been established. We develop a novel estimation techniques for estimating these parameters under a general semiparametric shared frailty model. We also present a simple, easily computed, and non-iterative nonparametric estimator for the cumulative baseline hazard function. A rigorous large sample theory for the proposed estimators of these parameters is given along with simulations and a real data example illustrate the utility of the proposed method. Comment: 45 page...|$|E
40|$|This paper {{presents}} a path planning approach for Micro Aerial Vehicles (MAVs) in urban environments. We {{show that it}} is feasible to extend the endurance and range of an MAV by exploiting the orographic lifts from buildings in windy conditions. A sampling based rapidlyexploring random tree algorithm is implemented to generate feasible paths between the start and goal in a modelled urban environment. A cost function is proposed that leverages sampling based planner metric sensitivity to properly capture the aircraft&# 039;s dynamics and utilize the environment for soaring. A three-degree of freedom aircraft model with a high fidelity control space is used to generate realistic reference trajectories. Multiple scenarios are setup to assess the behaviour of the planner {{and the effectiveness of}} the proposed metrics. The results obtained from the presented experiments validate the potential of utilising orographic lift for improving MAV endurance. This work also highlights the sensitive <b>nature</b> <b>of</b> <b>sampling</b> based planners to implementation parameters and emphasises the need for an adaptive parameter scheme...|$|E
30|$|McGuire {{raised a}} {{practical}} issue concerning {{the effectiveness of}} informed consent documents used in Human Microbiome Project as they were too long and complex for the average research subject to understand. As she explained, these documents “not only {{did they have to}} address consent for the storage and use of biological specimens and the attendant privacy risks that get implicated in genomic research, but they also had to address the physical risks associated with the complicated <b>nature</b> <b>of</b> <b>sampling</b> from 15 – 18 body sites” (McGuire et al., 2012). Although there are proposed changes to shorten the documents, it remains unclear, what would constitute a set of minimum appropriate information which should be included for informed consent, in order for patient/subject to make educated, autonomous decisions regarding their treatment or participation in research. As in the case of FMT, guidance is needed on whether we should outline every current potential issue to the patient (including the possibility of transmission of depression and anxiety?), or whether only what we currently understand to be principal concerns associated with FMT.|$|E
50|$|This {{technique}} {{is used to}} date sequences that generally lack fossils or interbedded igneous rocks. The continuous <b>nature</b> <b>of</b> the <b>sampling</b> means that {{it is also a}} powerful technique for the estimation of sediment-accumulation rates.|$|R
40|$|Motivation: The {{biomarker}} discovery {{process in}} high-throughput genomic profiles has presented the statistical learning {{community with a}} challenging problem, namely learning {{when the number of}} variables is comparable or exceeding the sample size. In these settings, many classical techniques including linear discriminant analysis (LDA) falter. Poor performance of LDA is attributed to the ill-conditioned <b>nature</b> <b>of</b> <b>sample</b> covariance matrix when the dimension and sample size are comparable. To alleviate this problem regularized LDA (RLDA) has been classically proposed in which the sample covariance matrix is replaced by its ridge estimate. However, the performance of RLDA depends heavily on the regularization parameter used in the ridge estimate <b>of</b> <b>sample</b> covariance matrix...|$|R
40|$|Transparent {{glasses of}} lithium tetraborate (Li 2 B 4 O 7) were {{prepared}} by {{a splat quenching}} technique. X-ray powder diffraction (XRD) and high resolution transmission electron microscopic studies revealed the amorphous <b>nature</b> <b>of</b> the as-quenched <b>samples.</b> The glassy <b>nature</b> <b>of</b> these <b>samples</b> was confirmed by differential thermal analysis. Physical properties such as density, dielectric and ac conductivity have been studied. Glasses of L(i) 2 B(4) O(7) exhibit a dielectric anomaly close to the crystallization temperature which is attributed to the interfacial polarization caused by Li+ ion motion within the berate network...|$|R
