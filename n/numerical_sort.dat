1|16|Public
5000|$|Because the {{hydraulic}} conductivity rapidly increases {{as the water}} content moves towards saturation, with reference to Fig.1, right-most bins in both capillary groundwater fronts and infiltration fronts can [...] "out-run" [...] their neighbors to the left. In the finite water content discretization, these shocks are dissipated {{by the process of}} capillary relaxation, which represents a pore-scale free-energy minimization process that produces no advection beyond the REV scale [...] Numerically, this process is a <b>numerical</b> <b>sort</b> that places the fronts in monotonically-decreasing magnitude from left-right.|$|E
5000|$|The cyclic Gilbreath {{permutations}} {{of order}} n are in {{one-to-one correspondence with}} the real numbers c for which the iteration [...] (starting from [...] ) underlying the Mandelbrot set is periodic with period n. In this correspondence, the permutation that corresponds to a given value c describes the <b>numerical</b> <b>sorted</b> order of the iterates for c. The number of cyclic Gilbreath permutations (and therefore also the number of real periodic points of the Mandelbrot set), for n = 1, 2, 3, ..., is given by the integer sequence ...|$|R
40|$|The {{computational}} {{properties of}} an econometric method are fundamental determinants of its importance and practical usefulness, {{in conjunction with}} the method's statistical properties. Computational methods in econometrics are advanced through successfully combining ideas and methods in econometric theory, computer science, numerical analysis, and applied mathematics. The leading classes of computational methods particularly useful for econometrics are matrix computation, <b>numerical</b> optimization, <b>sorting,</b> <b>numerical</b> approximation and integration, and computer simulation. A computational approach that holds considerable promise for econometrics is parallel computation, either on a single computer with multiple processors, or on separate computers networked in an intranet or over the internet...|$|R
30|$|ST, {{hence the}} {{long-term}} flicker describes the flicker severity {{for the last}} 2  h. Because the block is actually a discrete implementation in a digital processor, it requires <b>numerical</b> procedures for <b>sorting</b> and mathematical calculation.|$|R
40|$|The {{problem of}} {{rectangular}} objects packing into a semi-endless strip is under consideration. Here we propose {{to solve this}} problem by linear cutting approximation that may be presented as block structure of packing. Sometimes it becomes necessary to rearrange elements inside linear cutting blocks. The determined method of "reconstruction"(REC) proposed below helps to get solutions close to optimal for some classes of problems. But as usual REC does not ensure even local minimum. Two probabilistic methods that can ensure the best goal function parameters are considered in the paper: genetic algorithm and dynamic <b>sorting.</b> <b>Numerical</b> experiment results are shown...|$|R
40|$|This paper {{presents}} a new algorithm {{to improve the}} speed of threshold searching process in C 4. 5 by using the technique of genetic algorithms. In the threshold searching process in C 4. 5, the values in a <b>numerical</b> attribute are <b>sorted</b> first and then the mid-point between every two consecutive values is calculated and designated as a candidate threshold. This process can be time consuming {{and it is not}} practical for large data. Our algorithm generates a population of possible thresholds and converges to the best threshold value rapidly. Our experimental results have shown that significant time reduction has been achieved by using our algorithm in threshold searching process...|$|R
40|$|River {{sediment}} dispersal on the near-shore of “flash-flood” rivers is investigated using a coupled wave-current-sediment transport model. Besòs and Llobregat rivers (short and mountainous {{rivers in}} NW Mediterranean Sea, near to Barcelona City) {{are used as}} examples to study the sediment transport under “flash-flood” regime. The modeling system COWAST which includes the coupling between the water circulation model ROMS and the wave model SWAN, is applied to assess the sediment dispersal mechanisms and deposition in the coastal area off the two river mouths. Preferential depositional areas such as mud-belts were identified from the simulations. The sediment dispersal pattern obtained by the model agrees with observational measurments. Complementary <b>numerical</b> simulations revealed <b>sorting</b> of sediment grain size in the cross-shelf direction. Peer ReviewedPostprint (published version...|$|R
40|$|Differential semblance {{is unique}} amongst {{velocity}} inversion objectives in having well-defined and smooth high frequency asymptotics. A version appropriate {{for analysis of}} CMP gathers and layered models is particularly easy to analyse and economical for numerical experimentation. For model-consistent data, the DS objective measures the error in RMS velocity, weighted by the energy in the data - without requiring event-picking of any <b>sort.</b> <b>Numerical</b> experiments with synthetic data illustrate the theoretical properties. Tests with field CMPs suggest that differential semblance optimization is sufficiently robust to function as an automatic alternative or enhancement to interactive velocity analysis in some circumstances. Introduction The core problem of primaries-only (linearized, Born approximation) modeling, imaging, and inversion is that of finding an accurate reference velocity. Since the typical survey is highly redundant, predictions of reflectivity are redundant, and unlikely to be [...] ...|$|R
40|$|A {{comparative}} study of the bacterial flora of the water of Chesapeake Bay and Tokyo Bay was undertaken to assess {{similarities and differences between}} the autochthonous flora of the two geographical sites and to test the hypothesis that, given similarities in environmental parameters, similar bacterial populations will be found, despite extreme geographic distance between locations. A total of 195 aerobic, heterotrophic bacterial strains isolated from Chesapeake Bay and Tokyo Bay water were examined for 115 biochemical, cultural, morphological, nutritional, and physiological characters. The data were analyzed by the methods of <b>numerical</b> taxonomy. From <b>sorted</b> similarity matrices, 77 % of the isolates could be grouped into 30 phena and presumptively identified as Acinetobacter-Moraxella, Caulobacter, coryneforms, Pseudomonas, and Vibrio spp. Vibrio and Acinetobacter species were found to be common in the estuarine waters of Chesapeake Bay, whereas Acinetobacter-Moraxella and Caulobacter predominated in Tokyo Bay waters, at the sites sampled in the study...|$|R
40|$|Point pattern sets {{arise in}} many {{different}} areas of physical, biological, and applied research, representing many random realizations of underlying pattern formation mechanisms. These pattern sets can be heterogeneous with respect to underlying spatial processes, {{which may not be}} visually distiguishable. This heterogeneity can be elucidated by looking at statistical measures of the patterns sets and using these measures to divide the pattern sets into distinct groups representing like spatial processes. We introduce here a <b>numerical</b> procedure for <b>sorting</b> point pattern sets into spatially homogenous groups using functional principal component analysis (FPCA) applied to the approximated Minkowski functionals of each pattern. We demonstrate that this procedure correctly sorts pattern sets into similar groups both when the patterns are drawn from similar processes and when the second-order characteristics of the pattern are identical. We highlight this routine for distinguishing the molecular patterning of fluorescently labeled cell membrane proteins, a subject of much interest in studies investigating complex spatial signaling patterns involved in the human immune response...|$|R
40|$|This paper {{presents}} a technique for <b>sorting</b> <b>numerical</b> data in an efficient way. The numbers of comparisons i. e. the running {{time of this}} technique is dependent on distribution or diversity {{of the value of}} data items as like as other efficient algorithms. When the total number of data is even, this method groups that data into a collection of pairs and therefore establishes the sorting constraints on each of the pairs. The control is traversed through the list of elements by changing the position of each pair which is the major principle of this technique. On the other hand, when the total number of elements is odd, this method sorts all elements except the last one in the same was as mentioned earlier and the last element is sorted using the general Insertion Sort. This algorithm is therefore a hybrid sorting method that sorts elementary numeric data in a faster and efficient manner...|$|R
30|$|The {{following}} {{may serve}} as an example. At {{the end of the}} 19 th century Herman Hollerith combined punch cards having holes in specific places – a device known from mechanic musical instruments – with the cognitive concept of coding numbers by the arrangement of holes on the cards. In mechanic musical instruments, this technique was used for coding musical notes. Air pressure passing through the holes of the punch cards triggered an acoustic tone in pipes, strings or bells associated with the holes. Hollerith not only replaced musical notes by numbers. He also combined his punch cards with an electric reading device replacing air pressure: spring-mounted needles made an electrical connection when passing through the holes. Taken in isolation, all of the elements which Hollerith combined were no new concepts, yet their combination was. In fact, it was the first electro-mechanically machine able to tabulate and <b>sort</b> <b>numerical</b> information automatically. This {{turned out to be a}} major innovation when introduced to the market by the Tabulating Machine Company, later Computer Tabulating Recording Company renamed IBM in 1924 (see (Kistermann 1991)).|$|R
40|$|A G-strand is a map g(t, s) : R × R → G for a Lie group G {{that follows}} from Hamilton’s {{principle}} {{for a certain}} class of G-invariant Lagrangians. The SO(3) -strand is the G-strand version of the rigid body equation {{and it may be}} regarded physically as a continuous spin chain. Here, SO(3) K-strand dynamics for ellipsoidal rotations is derived as an Euler-Poincaré system for a certain class of variations and recast as a Lie-Poisson system for coadjoint flow with the same Hamiltonian structure as for a perfect complex fluid. For a special Hamiltonian, the SO(3) K-strand is mapped into a completely integrable generalization of the classical chiral model for the SO(3) -strand. Analogous results are obtained for the Sp(2) -strand. The Sp(2) -strand is the G-strand version of the Sp(2) Bloch-Iserles ordinary differential equation, whose solutions exhibit dynamical <b>sorting.</b> <b>Numerical</b> solutions show nonlinear interactions of coherent wave-like solutions in both cases. Diff(R) -strand equations on the diffeomorphism group G = Diff(R) are also introduced and shown to admit solutions with singular support (e. g., peakons) ...|$|R
40|$|Inverse {{problems}} of parameter identification and source identification in partial differential equations are highly ill-posed problems {{and for their}} satisfactory theoretical and <b>numerical</b> treatment some <b>sort</b> of regularization is necessary. In this thesis, we pose this inverse problem as an optimization problem and perform the regularization in Tikhonov sense. The most crucial aspect {{of the study of}} the regularized optimization problem is a proper selection of the regularization parameter. Although the theory {{for one of the most}} efficient methods for choosing an optimal regularization parameter, the so-called Morozov discrepancy principle, is well-developed for linear inverse problems, its use for nonlinear inverse problems is rather heuristic. In this thesis, we investigate the inverse problem of parameter identification using an equation error approach in which the coefficient appear linearly. Using the results known for linear inverse problems, we develop a rigorous Morozov discrepancy principle for nonlinear inverse problems. We present a detailed computational experimentation to test the feasibility of the developed approach. We also study the inverse problem of source identification in fourth-order boundary value problem...|$|R
40|$|The {{research}} {{behind this}} article primarily concerns {{the development of}} mobile robots for nuclear decommissioning. The robotic platform under study has dual, seven-function, hydraulically actuated manipulators, for which the authors have developed a vision based, assisted teleoperation interface for common decommissioning tasks such as pipe cutting. However, to improve safety, task execution speed and operator training-time, high performance control of the nonlinear manipulator dynamics is required. Hence, the present article focuses on an associated dynamic model, and addresses the challenging generic task of parameter estimation for a highly convex and nonlinear system. A novel approach for estimation of the fundamental parameters of the manipulator, {{based on the idea}} of multi-objectivization, is proposed. Here, a single objective output error identification problem is converted into a multi-objective optimization problem. This is solved using a multi-objective genetic algorithm with non-dominated <b>sorting.</b> <b>Numerical</b> and experimental results using the nuclear decommissioning robot, show that the performance of the proposed approach, in terms of both the output error index and the accuracy of the estimated parameters, is superior to the previously studied single-objective identification problem...|$|R
40|$|Multiple {{criteria}} {{decision analysis}} (MCDA) techniques are developed to address challenging classification problems arising in engineering management and elsewhere. MCDA {{consists of a}} set of principles and tools to assist a decision maker (DM) to solve a decision problem with a finite set of alternatives compared according to two or more criteria, which are usually conflicting. The three types of classification problems to which original research contributions are made are Screening: Reduce a large set of alternatives to a smaller set that most likely contains the best choice. Sorting: Arrange the alternatives into a few groups in preference order, so that the DM can manage them more effectively. Nominal classification: Assign alternatives to nominal groups structured by the DM, so that the number of groups, and the characteristics of each group, seem appropriate to the DM. Research on screening is divided into two parts: the design of a sequential screening procedure that is then applied to water resource planning in the Region of Waterloo, Ontario, Canada; {{and the development of a}} case-based distance method for screening that is then demonstrated using a <b>numerical</b> example. <b>Sorting</b> problems are studied extensively under three headings. Case-based distance sorting is carried out with Model I, which is optimized for use with cardinal criteria only, and Model II, which is designed for both cardinal and ordinal criteria; both sorting approaches are applied to a case study in Canadian municipal water usage analysis. Sorting in inventory management is studied using a case-based distance method designed for multiple criteria ABC analysis, and then applied to a case study involving hospital inventory management. Finally sorting is applied to bilateral negotiation using a case-based distance model to assist negotiators that is then demonstrated on a negotiation regarding the supply of bicycle components. A new kind of decision analysis problem, called multiple criteria nominal classification (MCNC), is addressed. Traditional classification methods in MCDA focus on sorting alternatives into groups ordered by preference. MCNC is the classification of alternatives into nominal groups, structured by the DM, who specifies multiple characteristics for each group. The features, definitions and structures of MCNC are presented, emphasizing criterion and alternative flexibility. An analysis procedure is proposed to solve MCNC problems systematically and applied to a water resources planning problem...|$|R
40|$|This thesis {{develops}} a computational model, a programming notation, {{and a set}} of programming principles to further and to demonstrate the practicality of programming fine grain concurrent computers. Programs are expressed in the computational model as a collection of definitions of autonomous computing agents called objects. In the execution of a program, the objects communicate data and synchronize their actions exclusively by message-passing. An object executes its definition only in response to receiving a message, and its actions may include sending messages, creating new objects, and modifying its own internal state. The number of actions that occur in response to a message is finite; Turing computability is achieved not within a single object, but through the interaction of objects. A new concurrent programming notation Cantor is used to demonstrate the cognitive process of writing programs using the object model. Programs for <b>numerical</b> sieves, <b>sorting,</b> the eight queens problem, and Gaussian elimination are fully described. Each of these programs involve up to thousands of objects in their exectuion. The general programming strategy is to first partition objects by their overall behavior and then to program the behaviors to be self-organizing. The semantics of Cantor are made precise through the definition of a formal semantics for Cantor and the object model. Objects are modelled as finite automata. The formal semantics is useful for proving program properties and for building frameworks to capture specific properties of object programs. The mathematical frameworks are constructed for building object graphs independently of program execution and for systematically removing objects that are irrelevant to program execution (garbage collection). The formal semantics are complemented by experiments that allow one to study the dynamics of the execution of Cantor programs on fine grain concurrent computers. The clean semantics of Cantor suggests simple metrics for evaluating the execution of concurrent programs for an ideal, abstract implementation. Program performance is also evaluated for environments where computing resources are limited. From the results of these experiments, hardware and software architectures for organizing fine grain message- passing computations is proposed, including support for fault tolerance and for garbage collection...|$|R

