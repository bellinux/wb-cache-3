0|10000|Public
50|$|However, {{the data}} {{processor}} or controller {{do not have}} <b>to</b> notify the <b>data</b> <b>subjects</b> if anonymized <b>data</b> is breached. Specifically,  the notice <b>to</b> <b>data</b> <b>subjects</b> is not required if the data controller has implemented pseudonymisation techniques like encryption along with adequate technical and organizational protection measures <b>to</b> the personal <b>data</b> affected by the data breach (Article 34).|$|R
40|$|Necessary and {{sufficient}} conditions for consistency {{of a simple}} estimator of Kendall’s tau under bivariate censoring are presented. The results are extended <b>to</b> <b>data</b> <b>subject</b> <b>to</b> bivariate left truncation as well as right censoring. Some key words: Bivariate survival; Clayton’s model; Cross-ratio function; Frailty; Left truncation. 1...|$|R
5000|$|The {{legislation}} gives certain rights <b>to</b> personal <b>data</b> <b>subjects</b> {{in respect}} of personal data held about them. These include: ...|$|R
30|$|Consequently, {{the data}} {{collection}} mechanism {{was replaced by a}} new one built on the following abstractions: data sources, data sinks, and data sets. Data sources are just that, sources of data. A nonaggregate data source receives a single object (e.g., an agent) and returns some data value, typically but not necessarily a property of that agent. An aggregate data source receives multiple objects, and performs some aggregate operation over all of the objects. It then returns the result of that operation. For example, it might calculate the mean value of some property over all of the objects. A data sink writes the output of these data sources, for example, to a file or a chart. A data set manages a collection of sources and sinks, providing the objects on which the data sources operate and directing the results <b>to</b> <b>data</b> sinks. Each data source {{can be thought of as}} a column in a tabular spreadsheet type of format, and each row is the result of recording data from each data source associated with a data set. Crucially, a data set also provides <b>notifications</b> <b>to</b> <b>data</b> sinks, notifying them that a new row of data is being started, that a row has ended, and that the entire record phase for the current time period has ended. It provides similar <b>notifications</b> <b>to</b> the <b>data</b> sources, for example, notifying an aggregate data source that the current row has started and thus any previous aggregate values should be reset. The new code embodying these abstractions is proving to be much more flexible than the previous Log 4 J code and has provided the basis for a more simple and more efficient user interface.|$|R
40|$|This article {{considers}} {{the legal issues}} that may arise from cloud computing, including the infringement of intellectual property rights, cybercrime and criminal damage <b>to</b> stored <b>data,</b> and data protection issues relating <b>to</b> <b>data</b> <b>subjects</b> and <b>data</b> protection authorities, and looks at EU developments. Discusses the future of standard clauses in cloud computing contracts, and the danger {{of a lack of}} competition between cloud service providers. ...|$|R
2500|$|Special {{personal}} data may, however, be processed {{where it is}} necessary or the <b>data</b> <b>subject</b> has given consent to the processing (Section 37(2)). Processing of {{personal data}} is necessary where it is to exercise a right, or fulfil an obligation conferred or imposed by law on an employer (Section 37(3)). Special personal <b>data</b> relating <b>to</b> <b>data</b> <b>subjects</b> may also be processed where {{it is necessary for}} the protection of the vital interest of the <b>data</b> <b>subject,</b> where it is impossible for the <b>data</b> <b>subject</b> <b>to</b> give consent, or the data controller cannot reasonably be expected to obtain consent, or consent by the <b>data</b> <b>subject</b> has been unreasonably withheld. (Section 37(4)) ...|$|R
5000|$|... (b) {{that the}} data are not {{processed}} {{in such a way}} that substantial damage or substantial distress is, or is likely to be, caused <b>to</b> any <b>data</b> <b>subject.</b>|$|R
50|$|According <b>to</b> the Personal <b>Data</b> Ordinance {{which was}} enacted in 2012, a person commits an offence {{if the person}} {{discloses}} any personal data of a <b>data</b> <b>subject</b> which was obtained from a data user without the data user’s consent, with an intent to cause loss or gain in other property or cause harm <b>to</b> the <b>data</b> <b>subject.</b>|$|R
40|$|This article {{considers}} to {{what extent}} database possessors (such as credit card companies and universities) can {{be held liable for}} harm caused <b>to</b> <b>data</b> <b>subjects</b> (such as consumers, applicants, and alumni) when information relating to those persons is hacked or otherwise subject to improper access. Addressing common-law and statutory sources (including new legislation in 17 states) the article clearly differentiates the duty <b>to</b> safeguard <b>data</b> from the duty <b>to</b> notify <b>data</b> <b>subjects</b> that the security of their information has been breached. By analogy to the “medical-monitoring damages” which some states award in toxic-exposure cases, the article argues that “security-monitoring damages” should be available in database-intrusion cases. More specifically, the article proposes that, in cases of ordinary negligence, the interests of society will be best served by limiting recoverable economics losses to the cost of security-monitoring damages once a database possessor discloses to the affected individual the fact that data has been improperly accessed. This approach will encourage database possessors to discover and reveal instances of data intrusion. It will also place <b>data</b> <b>subjects</b> in a position to protect their own interests by monitoring their economic and personal security when there is heightened vulnerability...|$|R
40|$|This article {{describes}} a ten-country European study investigating the practical aspects of exercising access rights {{from the perspective}} of <b>data</b> <b>subjects.</b> • It uses a mixture of quantitative and qualitative methodology to illustrate the restrictions faced by <b>data</b> <b>subjects</b> in exercising their access rights. • It concludes by making key recommendations <b>to</b> assist <b>data</b> <b>subjects</b> in their attempts to exercise access rights...|$|R
40|$|Privacy advocates claim privacy {{violation}} is {{a social}} cost of the widespread trade in personal information driven by advances in information management technologies and the Internet. Data users claim that significant benefits from free information exchange are passed on <b>to</b> <b>data</b> <b>subjects</b> and that these benefits outweigh any potential privacy violations. A central issue in this ongoing debate is answering the question, “who owns and who controls personal information”. Using the theory of property rights, we argue that personal information is a public good. We analyze responses from 459 New Zealanders to a contingent valuation survey to estimate the economic value <b>data</b> <b>subject’s</b> place on a hypothetical change <b>to</b> <b>data</b> protection laws that gives <b>data</b> <b>subject’s</b> an enforceable, property right in their personal information. The results are compared with other recent property rights studies to provide guidance {{for the use of}} opt-in versus opt-out legislative exclusion to protect information privacy. 1...|$|R
40|$|Because {{regulatory}} frameworks {{are complex}} and relatively untested, database custodians in Australia and overseas have been confused as to what conduct is required to comply with various regulations. Some database custodians believe that compliance with privacy requirements will allay public anxiety and consequently support research. Others argue that data managers have become fearful of litigation and that this will restrict the access of researchers <b>to</b> <b>data.</b> Two of the significant ethical issues to be considered are the right to privacy, and whether using information poses a risk <b>to</b> <b>data</b> <b>subjects.</b> <b>Data</b> custodians have sought to comply with increasing privacy regulation in two main ways. The first is by seeking informed consent from those whose data is collected. There are significant, but not insurmountable, practical difficulties in seeking consent from large numbers of individuals. The second way of complying with regulation is by ensuring anonymity. Security measures which are designed to reduce risks <b>to</b> <b>data</b> <b>subjects</b> without offering the opportunity to consent are often nominated as a response <b>to</b> <b>data</b> protection regulation. These {{can be achieved by}} using administrative procedures or business rules for record linkage processes that offer a high level of security for the stored data. In this paper we present a review of the current literature on possible responses of database custodians <b>to</b> <b>data</b> protection regulations. We outline a variety of examples and responses, some of which have the effect of restricting research, while others are enabling research to proceed with privacy protection in place. We argue that finding solutions to research within the privacy regulations requires attention to a range of factors. There are challenges both in engaging populations about consent procedures, and in encouraging the use by researchers and health care professionals of technical solutions where these are available. ...|$|R
40|$|State and Federal {{legislation}} governing {{health information}} and privacy in Australia {{is complex and}} relatively untested, causing confusion amongst database custodians as to what conduct is required. Some database custodians believe that providing privacy will allay public anxiety and consequently support research. Others argue that data managers have become fearful of litigation and that this will restrict the access of researchers <b>to</b> <b>data.</b> Two of the significant ethical issues to be considered are the right to privacy, and whether using information poses a risk <b>to</b> <b>data</b> <b>subjects.</b> <b>Data</b> custodians have sought to address concerns about privacy in two main ways. The first is by seeking informed consent from those whose data is collected. There are significant, but not insurmountable, practical difficulties in seeking consent from large numbers of individuals. The second way of addressing privacy concerns has been through security measures which are designed to reduce risks <b>to</b> <b>data</b> <b>subjects.</b> These measures are often nominated {{as a response to}} privacy requirements; however, they do not necessarily offer the opportunity to consent to information disclosures. In this paper we present a review of the current literature on possible responses of database custodians to demands for increased privacy. We outline a variety of examples and responses, some of which have the effect of restricting research, while others are enabling research to proceed with greater privacy protection in place. We argue that finding ways to proceed with research while protecting privacy requires attention to a range of factors. There are challenges both in engaging populations about consent procedures, and in encouraging the use by researchers and health care professionals of technical solutions where these are available. 5 page(s...|$|R
25|$|This {{interface}} is {{not called}} by the container, but internally by the object to allow it <b>to</b> receive <b>notifications</b> of when its DataObject is running, thereby allowing it <b>to</b> subscribe <b>to</b> <b>notifications</b> of <b>data</b> changes of that object and thus allowing it to update the cached presentation properly.|$|R
50|$|Concerning the {{obligations}} and {{duties of the}} operator of a search engine, the Court held that {{in the present case}} Article 7(f) of the Directive, relating to legitimacy of processing, requires a balancing of the opposing rights and interests of the <b>data</b> <b>subject</b> (González) and the data controller (Google), taking into account the <b>data</b> <b>subject's</b> rights deriving from Articles 7 (respect for private and family life) and 8 (protection of personal data) of the Charter of Fundamental Rights of the European Union. Article 14(a) of the Directive, relating <b>to</b> the <b>data</b> <b>subject's</b> rights, allows the <b>data</b> <b>subject,</b> at least in the cases covered by Articles 7(e) and 7(f), to object at any time on compelling legitimate grounds relating to his particular situation to the processing of <b>data</b> relating <b>to</b> him, save where otherwise provided by national legislation. Article 12(b) of the Directive, relating <b>to</b> the <b>data</b> <b>subject's</b> right of access <b>to</b> the <b>data,</b> allows the <b>data</b> <b>subject</b> <b>to</b> request erasure of the data. Such request may be made directly of the controller, who must then duly examine the merits of the request. If the request is not granted, the <b>data</b> <b>subject</b> may then direct the request to a supervisory authority or the judicial authority so that it carries out the necessary checks and orders the controller to take specific measures accordingly.|$|R
50|$|For {{transport}}, ATSC {{uses the}} MPEG systems specification, {{known as an}} MPEG transport stream, <b>to</b> encapsulate <b>data,</b> <b>subject</b> <b>to</b> certain constraints. ATSC uses 188-byte MPEG transport stream packets <b>to</b> carry <b>data.</b> Before decoding of audio and video takes place, the receiver must demodulate and apply error correction to the signal. Then, the transport stream may be demultiplexed into its constituent streams.|$|R
5000|$|Marc Rotenberg has {{described}} the modern right to privacy as Fair Information Practices, [...] "the rights and responsibilities associated with the collection and use of personal information". Rotenberg emphasizes that the allocation of rights are <b>to</b> the <b>data</b> <b>subject</b> and the responsibilities are assigned <b>to</b> the <b>data</b> collectors because of {{the transfer of the}} data and the asymmetry of information concerning data practices.|$|R
40|$|In October of 1998, the European Union Data Privacy Directive (2 ̆ 2 Directive 2 ̆ 2) became effective. Consistent with Europe 2 ̆ 7 s serious {{approach}} to consumer privacy, the Directive mandates that Member States adopt the most rigorous privacy legislation {{the world has}} seen. The specific requirements of the Directive are complex, and I have discussed them in some detail in another article. Very generally, the Directive places obligations on data collectors and provides rights <b>to</b> <b>data</b> <b>subjects.</b> The most significant of these protections from a global privacy perspective is the Directives 2 ̆ 2 opt-in 2 ̆ 2 approach, which presumes an expectation of data privacy as the default position, and (with certain exceptions) allows the processing of personal information only if 2 ̆ 2 the <b>data</b> <b>subject</b> has unambiguously given his consent. 2 ̆ 2 [CONT...|$|R
50|$|The GDPR {{refers to}} {{pseudonymisation}} {{as a process}} that transforms personal data {{in such a way}} that the resulting data cannot be attributed <b>to</b> a specific <b>data</b> <b>subject</b> without the use of additional information. An example of pseudonymisation is encryption, which renders the original data unintelligible and the process cannot be reversed without access to the correct decryption key. The GDPR requires that this additional information (such as the decryption key) be kept separately from the pseudonymised data. Pseudonymisation is recommended to reduce the risks <b>to</b> the concerned <b>data</b> <b>subjects</b> and also help controllers and processors to meet their data-protection obligations (Recital 28).|$|R
40|$|Statistical {{agencies}} that own different databases on overlapping subjects can benefit greatly from combining their data. These benefits are passed on <b>to</b> secondary <b>data</b> analysts when the combined <b>data</b> are disseminated <b>to</b> the public. Sometimes combining data across agencies or sharing these data {{with the public}} is not possible: {{one or both of}} these actions may break promises of confidentiality that have been given <b>to</b> <b>data</b> <b>subjects.</b> We describe an approach that is based on two stages of multiple imputation that facilitates data sharing and dissemination under restrictions of confidentiality. We present new inferential methods that properly account for the uncertainty that is caused by the two stages of imputation. We illustrate the approach by using artificial and genuine data. Copyright (c) 2009 Royal Statistical Society. ...|$|R
40|$|A {{numerical}} approximation {{scheme for}} {{the estimation of}} functional parameters in Euler-Bernoulli models for the transverse vibration of flexible beams with tip bodies is developed. The method permits the identification of spatially varying flexural stiffness and Voigt-Kelvin viscoelastic damping coefficients which appear in the hybrid system of ordinary and partial differential equations and boundary conditions describing the dynamics of such structures. An inverse problem is formulated as a least squares fit <b>to</b> <b>data</b> <b>subject</b> <b>to</b> constraints {{in the form of}} a vector system of abstract first order evolution equations. Spline-based finite element approximations are used to finite dimensionalize the problem. Theoretical convergence results are given and numerical studies carried out on both conventional (serial) and vector computers are discussed...|$|R
40|$|We {{analyze the}} sizes of {{standard}} cointegration tests applied <b>to</b> <b>data</b> <b>subject</b> <b>to</b> lin-ear interpolation, discovering evidence of substantial size distortions induced by the interpolation. We propose modifications to these tests to effectively eliminate size dis-tortion from such tests conducted on data interpolated from end-of-period sampled low-frequency series. Our results generally do not support linear interpolation when alternatives such as aggregation or mixed-frequency-modified tests are possible. JEL Classification: C 12, C 32 Key words and phrases: linear interpolation, cointegration, trace test, residual-based cointegration tests ∗The authors are grateful to Peter Phillips and other participants of the 2013 Advances in Econometrics Conference in Honor of Peter Phillips for useful comments. The first author acknowledges support of a Mari...|$|R
40|$|We provide several {{illustrations}} of Bayesian semiparametric regression analyses in the BRugs package. BRugs facilitates {{use of the}} BUGS inference engine from the R computing environment and allows analyses to be managed using scripts. The examples are chosen to represent an array of non-standard situations, for which mixed model software is not viable. The situations include: the response variable being outside of the one-parameter exponential family, <b>data</b> <b>subject</b> <b>to</b> missingness, <b>data</b> <b>subject</b> <b>to</b> measurement error and parameters entering the model via an index. ...|$|R
40|$|A cubic spline based Galerkin-like {{method is}} {{developed}} for the identification of a class of hybrid systems which describe the transverse vibration to flexible beams with attached tip bodies. The identification problem is formulated as a least squares fit <b>to</b> <b>data</b> <b>subject</b> <b>to</b> the system dynamics given by a coupled system of ordnary and partial differential equations recast as an abstract evolution equation (AEE) in an appropriate infinite dimensional Hilbert space. Projecting the AEE into spline-based subspaces leads naturally to a sequence of approximating finite dimensional identification problems. The solutions to these problems are shown to exist, are relatively easily computed, and are shown to, in some sense, converge to solutions to the original identification problem. Numerical results {{for a variety of}} examples are discussed...|$|R
5000|$|Garrett also {{testified that}} Smith {{instructed}} him <b>to</b> falsify <b>subject</b> <b>data,</b> {{which he said}} was a [...] "common practice".|$|R
25|$|A <b>data</b> <b>subject</b> can, <b>subject</b> <b>to</b> {{proving the}} <b>data</b> <b>subject’s</b> identity, request a <b>data</b> {{controller}} <b>to</b> confirm if the data controller holds that <b>data</b> <b>subject’s</b> personal <b>data,</b> describe {{the nature of}} the personal data held, and the identity of any third party who has or has previously had access <b>to</b> that <b>data</b> (Section 32(1)). The request must however be made in a reasonable manner, within a reasonable time, after paying any prescribed fees and in a form that is generally understandable (Section 32(2)).|$|R
40|$|The article {{discusses}} {{ethical and}} moral issues raised with {{the concepts of}} privacy and confidentiality in the prescreening and review process for research which uses human subjects. In the article the authors offer their opinions {{on the importance of}} privacy as it relates <b>to</b> <b>subject</b> <b>data</b> in research which uses human subjects and on several points which are raised in the article 2 ̆ 2 You Don 2 ̆ 7 t Know Me, But: Access <b>to</b> Patient <b>Data</b> and <b>Subject</b> Recruitment in Human Subjects 2 ̆ 2 by Toby Schonfeld et al...|$|R
40|$|Two cubic spline based {{approximation}} {{schemes for}} {{the estimation of}} structural parameters associated with the transverse vibration of flexible beams with tip appendages are outlined. The identification problem is formulated as a least squares fit <b>to</b> <b>data</b> <b>subject</b> <b>to</b> the system dynamics which are given by a hybrid system of coupled ordinary and partial differential equations. The first approximation scheme is based upon an abstract semigroup formulation of the state equation while a weak/variational form {{is the basis for}} the second. Cubic spline based subspaces together with a Rayleigh-Ritz-Galerkin approach were used to construct sequences of easily solved finite dimensional approximating identification problems. Convergence results are briefly discussed and a numerical example demonstrating the feasibility of the schemes and exhibiting their relative performance for purposes of comparison is provided...|$|R
50|$|Data {{localization}} builds {{upon the}} concept of data sovereignty that regulates certain data types by the laws applicable <b>to</b> the <b>data</b> <b>subject</b> or processor. While, data sovereignty may require records about a nations citizens or residents follow its personal or financial data processing laws, data localization goes a step further in requiring that initial collection, processing, and storage occur first within the national boundaries. In some cases, data about a nation's citizens or residents must also be deleted from foreign systems before being removed from systems in the <b>data</b> <b>subject's</b> nation.|$|R
40|$|Abstract. Organizations that {{collect and}} use {{large volumes of}} {{personal}} information are expected under the principle of accountable <b>data</b> governance <b>to</b> take measures <b>to</b> protect <b>data</b> <b>subjects</b> from risks that arise from inapproriate uses of this information. In this paper, we focus on a specific class of mechanisms— audits to identify policy violators coupled with punishments—that organizations such as hospitals, financial institutions, and Web services companies may adopt <b>to</b> protect <b>data</b> <b>subjects</b> from privacy and security risks stemming from inappropriate information use by insiders. We model {{the interaction between the}} organization (defender) and an insider (adversary) during the audit process as a repeated game. We then present an audit strategy for the defender. The strategy requires the defender to commit to its action and when paired with the adversary’s best response to it, provably yields an asymmetric subgame perfect equilibrium. We then present two mechanisms for allocating the total audit budget for inspections across all games the organization plays with different insiders. The first mechanism allocates budget to maximize the utility of the organization. Observin...|$|R
50|$|The project {{expects to}} weed out duplicate, fake and ineligible voters, and voters who have shifted to other regions from the databases. The {{projects}} will also acquire mobile numbers and emails of voters to send them poll related <b>notifications.</b> According <b>to</b> the <b>data</b> provided by UIDAI to the Election Commission, 50,00,00,000 of the country's 85,00,00,000 voters are currently registered with the UIDAI. The UIDAI is expected to complete the registration of all voters in a few months.|$|R
50|$|The Optometry {{building}} {{is equipped with}} research laboratories supported by metal, wood, electronic and optical workshops, a vision science library centre, histology and live-animal housing facilities. Researchers also have controlled access <b>to</b> clinic <b>data</b> and <b>subjects.</b>|$|R
40|$|The {{data privacy}} field is {{currently}} {{in the moment of}} asking whether providing more control <b>to</b> the <b>data</b> <b>subject</b> can be a solution applicable in the real world {{for the protection of the}} right to privacy. The critics of a control-oriented approach base their arguments on the practical, conceptual and moral difficulties of the model, but mainly on the fact that the consent, as the main mechanism of control of the <b>data</b> <b>subject,</b> has so far proved to be impractical and inefficient. The objective of the following analysis is to restore the position of the concept of informed consent as the primary way of control for the <b>data</b> <b>subject,</b> while recognizing that to achieve such informed consent, the <b>data</b> <b>subject</b> must be provided with more suitable conditions. The implementation of said conditions demands to analyze the implications of the field of behavioral economics and legal economics in the data privacy scenario. The goal of implementing a behavioral economics perspective is to create a conscientious decision-making scenario for the users. This work will analyze a proposal for the creation of such a suitable scenario, first with implementing alternative ways to provide information <b>to</b> the <b>data</b> <b>subject.</b> Furthermore, the creation of such scenario requires shifting the model of exchange of data, by providing a value from a consumer’s perspective. It will be argued that this model may create awareness and responsibility but, at the same time, recognizes the paramount economic and social importance of data processing in the current state of development of the technology industry...|$|R
40|$|A {{critical}} component of spline smoothing is the choice of knots, especially for curves with varying shapes and frequencies in its domain. We consider a two-stage knot selection scheme for adaptively fitting splines <b>to</b> <b>data</b> <b>subject</b> <b>to</b> noise. A potential set of knots is chosen based on information from certain wavelet decompositions with the intention to place more points where the curve shows rapid changes. The final knot selection is then made based on statistical model selection ideas. We show that the proposed method is well suited {{for a variety of}} smoothing and noise filtering needs. Index Terms: Least squares; Model selection; Knot; Smoothing; Spline; Wavelet decomposition. I. Introduction The task of fitting a spline <b>to</b> noisy <b>data</b> is often performed in diverse domains of applications such as computer aided design, pattern recognition, data smoothing and denoising in engineering. Suppose that n pairs of observations f(x i; y i); i = 1; 2; : : :; ng are available from y i = f( [...] ...|$|R
40|$|Abstract [...] - A Cloud is a {{collection}} of terminals and servers that are publicly accessible via the internet. One of the primary use of cloud computing is data storage. In Cloud computing data are stored in encrypted form to ensure confidentiality. For more confidentiality two layer encryption approaches is implemented. The third party auditor will audit the data files and stored in cloud environment. There is chance to third party auditor will change the data. My proposed system has the notification method. If Third party auditor attempts <b>to</b> modify the <b>data,</b> the application will sends <b>notification</b> <b>to</b> the corresponding <b>data</b> owner. The third party auditor has rights <b>to</b> audit the <b>data</b> only. Until the user verifies the notification, the modification is not committed to the database...|$|R
40|$|An {{interval}} predictor model (IPM) is a {{computational model}} that predicts {{the range of}} an output variable given input-output data. This paper proposes strategies for constructing IPMs based on semidefinite programming and sum of squares (SOS). The models are optimal {{in the sense that}} they yield an interval valued function of minimal spread containing all the observations. Two different scenarios are considered. The first one is applicable to situations where the data is measured precisely whereas the second one is applicable <b>to</b> <b>data</b> <b>subject</b> <b>to</b> known biases and measurement error. In the latter case, the IPMs are designed to fully contain regions in the input-output space where the <b>data</b> is expected <b>to</b> fall. Moreover, we propose a strategy for reducing the computational cost associated with generating IPMs as well as means to simulate them. Numerical examples illustrate the usage and performance of the proposed formulations...|$|R
