188|17|Public
5|$|In {{order for}} a chain {{reaction}} to occur, fissioning uranium atoms had to emit additional neutrons to keep the reaction going. At Columbia University in New York, Enrico Fermi, John Dunning, Herbert L. Anderson, Eugene T. Booth, G. Norris Glasoe, and Francis G. Slack conducted the first nuclear fission experiment in the United States on 25 January 1939. Subsequent work confirmed that fast neutrons were indeed produced by fission. Szilard obtained permission {{from the head of}} the Physics Department at Columbia, George B. Pegram, to use a laboratory for three months, and persuaded Walter Zinn to become his collaborator. They conducted a simple experiment on the seventh floor of Pupin Hall at Columbia, using a radium-beryllium source to bombard uranium with neutrons. They discovered significant <b>neutron</b> <b>multiplication</b> in natural uranium, proving that a chain reaction might be possible.|$|E
25|$|Boric acid {{is used in}} some {{nuclear power}} plants as a neutron poison. The boron in boric acid reduces the {{probability}} of thermal fission by absorbing some thermal neutrons. Fission chain reactions are generally driven by the probability that free neutrons will result in fission and {{is determined by the}} material and geometric properties of the reactor. Natural boron consists of approximately 20% boron-10 and 80% boron-11 isotopes. Boron-10 has a high cross-section for absorption of low energy (thermal) neutrons. By increasing boric acid concentration in the reactor coolant, the probability that a neutron will cause fission is reduced. Changes in boric acid concentration can effectively regulate the rate of fission taking place in the reactor. Boric acid is used only in pressurized water reactors (PWRs) whereas boiling water reactors (BWRs) employ control rod pattern and coolant flow for power control. BWRs use an aqueous solution of boric acid and borax or Sodium Pentaborate for an emergency shut down system. Boric acid may be dissolved in spent fuel pools used to store spent fuel elements. The concentration is high enough to keep <b>neutron</b> <b>multiplication</b> at a minimum. Boric acid was dumped over Reactor 4 of the Chernobyl Nuclear Power Plant after its meltdown to prevent another reaction from occurring.|$|E
500|$|Even the {{inherent}} statistical fluctuations of <b>neutron</b> <b>multiplication</b> within {{a chain reaction}} have implications with regard to implosion speed and symmetry. In November 1944, David Hawkins and Ulam addressed this problem in a report entitled [...] "Theory of Multiplicative Processes". This report, which invokes probability-generating functions, is also an early entry in the extensive literature on statistics of branching and multiplicative processes. [...] In 1948, its scope was extended by Ulam and Everett.|$|E
40|$|The authors {{performed}} 1 -D coupled, neutron-gamma transport calculations for lithium-vanadium {{blankets and}} lithium-sodium cauldron pot blankets in cylindrical and spherical geometries. Parametric fits {{to the data}} are supplied for subsequent use in systems code models. Scaling relationships are given for various neutronics parameters of interest, including: tritium breeding ratio, <b>neutron</b> energy <b>multiplication,</b> magnet dose rates, magnet heating rates, and integrated magnet fluence...|$|R
40|$|Neutron {{characteristics}} of salt blanket micromodels containing eutectic mixtures of sodium, zirconium and uranium sulphides were measured on FKBN- 2 M, BIGR and MAKET installations. The effective fission cross sections of neptunium, plutonium, americium and curium isotopes were measured on the neutron spectra formed by micromodels. KEYWORDS: transmutation, minor actinides, fluoride salts, micromodel, critical assembly, <b>neutron</b> spectrum, <b>multiplication</b> coefficient, fission, effective cross section, nuclear track detector, nuclear data librar...|$|R
40|$|Basic {{research}} on the accelerator-driven system is conducted by combining 235 U-fueled and 232 Th-loaded cores in the Kyoto University Critical Assembly with the pulsed neutron generator (14 MeV neutrons) and the proton beam accelerator (100 MeV protons with a heavy metal target). The results of experimental subcriticality are presented {{with a wide range}} of subcriticality level between near critical and 10, 000 pcm, as obtained by the pulsed neutron source method, the Feynman-α method, and the <b>neutron</b> source <b>multiplication</b> method...|$|R
500|$|... where M is {{the surface}} area and k is the average <b>neutron</b> <b>multiplication</b> factor. The {{neutrons}} in preceding reactions will be amplified by a factor k, the second generation of fission events will produce k2, the third k3 and so on. In order for a self-sustaining nuclear chain reaction to occur, k {{must be at least}} 3 or 4 percent greater than 1. In other words, k must be greater than 1 without crossing the prompt critical threshold that would result in a rapid, exponential {{increase in the number of}} fission events.|$|E
500|$|Szilard and Zinn {{conducted}} a simple experiment {{on the seventh}} floor of Pupin Hall at Columbia, using a radium-beryllium source to bombard uranium with neutrons. Initially nothing registered on the oscilloscope, but then Zinn realized that it was not plugged in. On doing so, they discovered significant <b>neutron</b> <b>multiplication</b> in natural uranium, proving that a chain reaction might be possible. Szilard later described the event: [...] "We turned the switch and saw the flashes. We watched them for a little while and then we switched everything off and went home." [...] He understood the implications and consequences of this discovery, though. [...] "That night, there was very little {{doubt in my mind that}} the world was headed for grief".|$|E
500|$|The {{basic concept}} of {{implosion}} {{is to use}} chemical explosives to crush a chunk of fissile material into a critical mass, where <b>neutron</b> <b>multiplication</b> leads to a nuclear chain reaction, releasing {{a large amount of}} energy. [...] Cylindrical implosive configurations had been studied by Seth Neddermeyer, but von Neumann, who had experience with shaped charges used in armor-piercing ammunition, was a vocal advocate of spherical implosion driven by explosive lenses. [...] He realized that the symmetry and speed with which implosion compressed the plutonium were critical issues, and enlisted Ulam to help design lens configurations that would provide nearly spherical implosion. [...] Within an implosion, because of enormous pressures and high temperatures, solid materials behave much like fluids. [...] This meant that [...] hydrodynamical calculations were needed to predict and minimize asymmetries that would spoil a nuclear detonation. [...] Of these calculations, Ulam said: ...|$|E
40|$|In Monte Carlo (MC) {{criticality}} calculations, {{source error}} propagation through the stationary cycles and source convergcnce in the settling (inactive) cycles are both {{dominated by the}} dominance ratio (DR) of fission kernels, Le., {{the ratio of the}} second largest to largest eigenvalues. For symmetric two fissile component systems with DR close to unity, the extinction of fission source sites can occur in one of the components even when the initial source is symmetric and the number of histories per cycle is larger than one thousand. When such a system is made slightly asymmetric, the <b>neutron</b> effective <b>multiplication</b> factor (kern) at the inactive cycles does not reflect the convergence to stationary source distribution. To overcome this problem, relative entropy (Kullback Leibler distance) is applied to a slightly asymmetric two fissile component problem with a dominance ratio of 0. 9925. Numerical results show that relative entropy is effective as a posterior diagnostic tool...|$|R
40|$|The H 5 B is {{a concept}} of an accelerator-driven sub-critical {{research}} facility (ADSRF) being developed {{over the last couple}} of years at the Vinča Institute of Nuclear Sciences, Belgrade, Serbia. Using well-known computer codes, the MCNPX and MCNP, this paper deals with the results of a tar get study and neutron flux calculations in the sub-critical core. The neutron source is generated by an interaction of a proton or deuteron beam with the target placed inside the sub-critical core. The results of the total neutron flux density escaping the target and calculations of neutron yields for different target materials are also given here. Neutrons escaping the target volume with the group spectra (first step) are used to specify a neutron source for further numerical simulations of the neutron flux density in the sub-critical core (second step). The results of the calculations of the <b>neutron</b> effective <b>multiplication</b> factor keff and neutron generation time L for the ADSRF model have also been presented. Neutron spectra calculations for an ADSRF with an uranium tar get (highest values of the neutron yield) for the selected sub-critical core cells for both beams have also been presented in this paper...|$|R
40|$|The {{study of}} {{subcritical}} reactors needs some test to correctly evaluate many parameters {{that must be}} introduced in a reactor model. The Sub-critical Multiplication installation at the University of Pavia {{was used to measure}} <b>neutron</b> fluxes and <b>multiplication</b> factors that will be modelled with a MCNP Monte Carlo numerical simulation. The comparison between the measurements and the simulations were very promising demonstrating that also in a sub-critical system the Monte Carlo model could be very helpful in describing the reactor characteristics. Using all the collected data from measurements and simulations, it was possible to determine the k(eff) of the reactor plant with a reasonable accuracy. The ratio between the fast and the thermal component of the neutron fluxes was also determined...|$|R
2500|$|Hawkins saw {{his role}} {{as that of a}} go-between, {{mediating}} between the civilian scientists and the military leadership at Los Alamos; but he also found a kindred spirit in the Polish mathematician Stan Ulam, who was working in Edward Teller's [...] "Super" [...] Group. They investigated the problem of branching a <b>neutron</b> <b>multiplication</b> in a nuclear chain reaction. Stan Frankel and Richard Feynman had tackled the problem using classical physics, but Ulam and Hawkins approached it using probability theory, creating a new sub-field now known as branching process theory. They investigated branching chains using a characteristic function. After the war, Ulam would extend and generalise this work. He described Hawkins as [...] "the most talented amateur mathematician I know." ...|$|E
5000|$|... #Subtitle level 2: Nuclear weapons {{application}} of <b>neutron</b> <b>multiplication</b> ...|$|E
50|$|In this formula, k is the {{effective}} <b>neutron</b> <b>multiplication</b> factor, described below.|$|E
40|$|Applicability of the {{modified}} <b>Neutron</b> Source <b>Multiplication</b> (NSM) method with extraction {{of the fundamental}} mode to subcriticality measurement has been proposed. Following the feasibility verification in the previous study based on numerical analyses, its applicability has been proven in a more realistic situation; in a withdrawal sequence of control rod banks during the PWR startup. Subcriticalities with various control rod insertion configurations were estimated based on {{the modified}} NSM method. The subcriticality could be evaluated with a good accuracy even with the mockup experiment where any special treatments for accurate measurement were not taken into account and fur-thermore the insensitivity of measured signals by reactivity changes and their large fluctuations were seen. Based on this fact, we further investigated a feasibility to use neutron count rate data obtained during the control rod drop testing, which is carried out before the reactor physics tests at hot zero power condition. When it is proven that these data {{could be used for}} the estimation of each control rod worth, the following reactor physics tests could be performed with the advanced knowledge of each control rod worth and procedures for detailed control rod worth measurement could be simplified or eliminated from the reactor physics tests...|$|R
40|$|The Np- 237 neutron-induced fission {{cross section}} has been {{recently}} measured {{in a large}} energy range (from eV to GeV) at the n_TOF facility at CERN. When compared to previous measurements the n_TOF fission cross section appears to be higher by 5 - 7 % beyond the fission threshold. To check {{the relevance of the}} n_TOF data, we considered a criticality experiment performed at Los Alamos with a 6 kg sphere of Np- 237, surrounded by uranium highly enriched in U- 235 so as to approach criticality with fast <b>neutrons.</b> The <b>multiplication</b> factor k(eff) of the calculation is in better agreement with the experiment when we replace the ENDF/B-VII. 0 evaluation of the Np- 237 fission cross section by the n_TOF data. We also explored the hypothesis of deficiencies of the inelastic cross section in U- 235 which has been invoked by some authors to explain the deviation of 750 pcm. The large modification needed to reduce the deviation seems to be incompatible with existing inelastic cross section measurements. Also we show that the. of Np- 237 can hardly be incriminated because of the high accuracy of the existing data. Fission rate ratios or averaged fission cross sections measured in several fast neutron fields seem to give contradictory results on the validation of the Np- 237 cross section but {{at least one of the}} benchmark experiments, where the active deposits have been well calibrated for the number of atoms, favors the n_TOF data set. These outcomes support the hypothesis of a higher fission cross section of Np- 237...|$|R
40|$|The 237 Np neutron-induced fission {{cross section}} has been {{recently}} measured {{in a large}} energy range (from eV to GeV) at the n_TOF facility at CERN. When compared to previous measurement the n_TOF fission cross section appears to be higher by 5 - 7 % beyond the fission threshold. To check the relevance of n_TOF data, we apply a criticality experiment performed at Los Alamos with a 6 kg sphere of 237 Np, surrounded by enriched uranium 235 U so as to approach criticality with fast <b>neutrons.</b> The <b>multiplication</b> factor ke f f of the calculation is in better agreement with the experiment (the deviation of 750 pcm is reduced to 250 pcm) when we replace the ENDF/B-VII. 0 evaluation of the 237 Np fission cross section by the n_TOF data. We also explore the hypothesis of deficiencies of the inelastic cross section in 235 U which has been invoked by some authors to explain the deviation of 750 pcm. With compare to inelastic large distortion calculation, it is incompatible with existing measurements. Also we show that the v of 237 Np can hardly be incriminated {{because of the high}} accuracy of the existing data. Fission rate ratios or averaged fission cross sections measured in several fast neutron fields seem to give contradictory results on the validation of the 237 Np cross section but {{at least one of the}} benchmark experiments, where the active deposits have been well calibrated for the number of atoms, favors the n_TOF data set. These outcomes support the hypothesis of a higher fission cross section of 237 Np...|$|R
50|$|During World War II, Fischer {{worked in}} the German nuclear energy project, {{also known as the}} Uranverein (Uranium Club). His {{contributions}} included determination of the rate of <b>neutron</b> <b>multiplication</b> in heterogeneous uranium-moderator combinations.|$|E
5000|$|The {{effective}} <b>neutron</b> <b>multiplication</b> factor, k, is {{the average}} number of neutrons from one fission that cause another fission. The remaining neutrons either are absorbed in non-fission reactions or leave the system without being absorbed. The value of k determines how a nuclear chain reaction proceeds: ...|$|E
50|$|The {{average number}} of {{neutrons}} that cause new fission events is called the effective <b>neutron</b> <b>multiplication</b> factor, usually denoted by the symbols k-effective, k-eff or k. When k-effective is equal to 1, the assembly is called critical, if k-effective is less than 1 the assembly {{is said to be}} subcritical, and if k-effective is greater than 1 the assembly is called supercritical.|$|E
40|$|This paper investigates an {{analytical}} derivation {{of the distribution}} of the number of neutrons and photons emitted by a multiplying sample. The relationship between the statistics of the generated and detected neutrons and photons is also described. The analytical model described in this paper accounts for absorption, thus extending the model presented in previous studies. By using this new, improved model, one can investigate the relative feasibilities of measuring neutrons or gamma photons for the analysis of a specific fissile sample. In fact, larger mass will lead to larger self-shielding for gamma photons, whereas for neutrons a larger mass will lead to increased multiplicities due to an increased probability to induce fission for each neutron, with absorption playing a minor role. The results suggest that although photons have a larger initial (source) <b>multiplication,</b> <b>neutrons</b> might be more favourable to measure in the case of large samples because of the increasing self-shielding effect for gamma photons. Key Words: nuclear safeguards, neutron and photon numbers, number distribution, master equations 1...|$|R
40|$|The {{purpose of}} this paper is to present new {{analytical}} derivations to describe the emission and detection statistics of neutrons and photons generated in and emitted from fissile samples, with absorption included. The results of the analytical approach are compared with and validated by corresponding Monte Carlo simulations. The joint statistics of the generated and detected neutrons and photons are also described. The analytical model described in this paper accounts for absorption and detection, thus extending the model presented in previous studies. By using this new, improved model, one can investigate the relative feasibilities of measuring neutrons, gamma photons or combinations thereof, for the analysis of a specific fissile sample. It is seen that for larger mass samples photon absorption in the sample strongly decreases the multiplicity of emitted photons, whereas this is not the case for neutrons. The model correctly accounts for this strong self-shielding effect and confirm previous observations that although photons have a larger initial (source) <b>multiplication,</b> <b>neutrons</b> might be more favourable to measure in the case of large samples because of the increasing self-shielding effect for gamma photons...|$|R
40|$|Nuclear {{safeguards}} is {{a collective}} {{term for the}} tools and methods needed to ensure nonproliferation and safety in connection to utilization of nuclear materials. It encompasses a variety of concepts from legislation to measurement equipment. The objective of this thesis is to present a number of research results related to nuclear materials control and accountability, especially the area of nondestructive assay. Physical aspects of nuclear materials are often {{the same as for}} materials encountered in everyday life. One special aspect though is that nuclear materials also emit radiation allowing them to be qualitatively and quantitatively measured without direct interaction with the material. For the successful assay of the material, the particle generation and detection needs to be well understood, and verified with measurements, simulations and models. Four topics of research are included in the thesis. First the generation and <b>multiplication</b> of <b>neutrons</b> and gamma rays in a fissile multiplying sample is treated. The formalism used enables investigation of the number of generated, absorbed and detected particles, offering understanding of the different processes involved. Secondly, the issue of relating the coincident detector signals, generated by both neutrons and gamma rays, to sample parameters is dealt with. Fission rate depends directly on the sample mass, while parameters such as neutron generation by alpha decay and <b>neutron</b> leakage <b>multiplication</b> are parameters that depend on the size, composition and geometry of the sample. Artificial neural networks are utilized to solve the inverse problem of finding sample characteristics from the measured rates of particle multiples. In the third part the interactions between neutrons and organic scintillation detectors are treated. The detector material consists of hydrogen and carbon, on which the neutrons scatter and transfer energy. The problem shares many characteristics with the area of neutron moderation found in reactor physics. Finally {{the last part of the}} thesis consists of measurement systems. Measuring coincident neutrons and gamma rays using fast scintillation detectors and data acquisition systems, can enable development of new types of methods for interpreting material signatures...|$|R
5000|$|In 1936, Szilárd {{attempted}} {{to create a}} chain reaction using beryllium and indium, but was unsuccessful. Nuclear fission was discovered and proved by Otto Hahn and Fritz Strassmann in December 1938. [...] A few months later, Frédéric Joliot, H. Von Halban and L. Kowarski in Paris searched for, and discovered, <b>neutron</b> <b>multiplication</b> in uranium, proving that a nuclear chain reaction by this mechanism was indeed possible.|$|E
5000|$|Even the {{inherent}} statistical fluctuations of <b>neutron</b> <b>multiplication</b> within {{a chain reaction}} have implications with regard to implosion speed and symmetry. In November 1944, David Hawkins and Ulam addressed this problem in a report entitled [...] "Theory of Multiplicative Processes". This report, which invokes probability-generating functions, is also an early entry in the extensive literature on statistics of branching and multiplicative processes. In 1948, its scope was extended by Ulam and Everett.|$|E
50|$|By {{the end of}} the war, {{following}} an idea of Alvin Weinberg, natural uranium fuel elements were arranged in a lattice in ordinary water {{at the top of the}} X10 reactor to evaluate the <b>neutron</b> <b>multiplication</b> factor. The purpose of this experience was to determine the feasibility of a nuclear reactor using light water as a moderator and coolant, and cladded solid uranium as fuel. The results showed that, with a lightly enriched uranium, criticality could be reached. This experience was the first practical step toward light-water reactor.|$|E
40|$|Three-dimensional (3 D) silicon {{detectors}} offer {{advantages over}} standard planar devices as more radiation hard sensors. These detectors and their {{applications in the}} upgrades of the LHC experiments are discussed. 3 D detectors with a double-sided geometry have been fabricated as very short strip detectors with similar inter-column spacing as proposed for the ATLAS pixel detector and LHCb vertex locator upgrades. The detectors have been irradiated up to a fluence of 2 × 1016 cm- 2 1 MeV equivalent neutrons, which is twice the expected dose of the inner pixel layer of the ATLAS detector and of the upgraded LHCb vertex locator for LHC high luminosity upgrade (HL-LHC) operation. Electrical measurements show a lateral depletion voltage of only 4 V for the device before irradiation which increases to 200 V after an irradiation to a fluence of 1 × 1016 cm- 2 1 MeV equivalent neutrons. The strip isolation of the p-type detectors was robust to the maximum fluence. Charge collection studies have been performed with analogue readout with 25 ns shaping time, as required for LHC experiments. The response of the detectors to high energy electrons from a 90 Sr source and a collimated pulsed laser light source are shown and compared with planar devices. The 3 D detector, operated at no more than 350 V, is shown to have superior charge collection characteristics to planar devices for all the fluence range expected at HL-LHC even when compared to planar devices operating at 1000 V. When operated at a bias voltage of 350 V the 3 D detector collects 2. 8 times more charge than a p-type planar device operated at 1000 V after a fluence of 1016 cm- 2 1 MeV equivalent <b>neutrons.</b> Charge <b>multiplication</b> in 3 D detectors is also reported, in both 90 Sr and laser tests, which leads to further enhancement in the charge collection and signal-to-noise ratio of the detector. The effect is demonstrated, throu- - gh laser tests, to occur close to the junction electrode...|$|R
40|$|Measurement and {{monitoring}} of reactivity in a subcritical state, e. g. during the loading {{of a power}} reactor, has a clear safety relevance. The methods currently available for the measurement of k(eff) in stationary subcritical conditions should be improved as they refer to the critical state. This is also very important {{in the framework of}} ADS (accelerator driven systems) where the measurement of a subcritical level without knowledge of the critical state is looked for. An alternative way to achieve this is by mean of the Cf- 252 source-detector method. The method makes use of three detectors inserted in the reactor: two "ordinary" neutron detectors and one Cf- 252 source-detector which contains a small amount of Cf- 252 that introduces neutrons in the system through spontaneous fission. By observing fissions through the detection system and correlating the signals of the three detectors, the reactivity rho (and hence the multiplication factor k) can be determined. Before the actual measurements took place, a suitable data acquisition system was realized in order to process the signals and compute the auto and cross power spectral densities. The measurements were then performed in the VENUS reactor, using the Cf- 252 source-detector and two BF 3 <b>neutron</b> detectors. The <b>multiplication</b> factor was determined using the Cf source method and compared with measurements using other methods and with computational results (Monte Carlo simulations). The Cf method was benchmarked at a UOX core to other experimental methods that used the critical state as reference and to calculations. Afterwards, the Cf source technique was analyzed in a MOX core to study the possible impact of a significant intrinsic source on the results. This benchmarking gives the possibility to validate the Cf method as a reliable technique for the measurement of subcritical levels in steady state and for cores with an intrinsic source like MOX or burnt fuel cores. (C) 2010 Elsevier Ltd. All rights reserved...|$|R
40|$|Este trabalho apresenta uma nova abordagem {{experimental}} para determinar a reatividade de sistemas subcríticos. O método a ser apresentado utiliza o modelo da cinética subcrítica desenvolvido por Gandini e Salvatores e baseia-se apenas em grandezas medidas, tais como a taxa de contagem no detector, e nos parâmetros que surgem do ajuste dos mínimos quadrados APSD (Auto Power Spectral Density) e CPSD (Cross Power Spectral Density), não sendo necessário lidar com as quantidades de maior complexidade como a eficiência de detector. A única hipótese feita neste método foi que a fração efetiva de nêutrons atrasados e o tempo de geração de nêutrons prontos fossem independentes do nível de subcriticalidade do sistema. O método proposto foi aplicado nas medidas de reatividade de várias configurações subcríticas do reator IPEN/MB- 01. Foram realizadas medidas da APSD e CPSD em diversos graus de subcriticalidade (até em torno de - 7000 pcm). Nos dados das densidades espectrais foram feitos ajustes por meio do método de mínimos quadrados para obter a constante de decaimento pronto (α) e outras grandezas. Com a finalide de melhorar as estatísticas de contagem de nêutrons, fonte externa de nêutrons de Am-Be foi instalada próximo ao núcleo, além da fonte de partida. O método experimental proposto mostra claramente que, a teoria da cinética pontual clássica não descreve a reatividade medida. Em vez disso, a reatividade inferida a partir do modelo da cinética pontual clássica é próxima, em seus valores absolutos, ao índice de subcriticalidade (ζ) para um determinado arranjo das fontes do experimeno. A concordância dos resultados obtidos por MCNP 5 e GPT-TORT, ambos utilizando os dados nucleares da biblioteca ENDF/B-VII. 0, com os resultados experimentais correspondentes são de boa qualidade. This work {{presents a}} new experimental approach {{to determine the}} reactivity levels of subcritical systems. The method employs the subcritical kinetic model developed by Gandini and Salvatores and it is based only on measured quantities such as counting rates of the detectors employed in the experiments and the parameters arising from the least squares fitting of the APSD (Auto Power Spectral Density) and CPSD (Cross Power Spectral Density). Detector efficiencies, quantity required in other procedures such as <b>Neutron</b> Source <b>Multiplication</b> (NSM) method, are not needed in the proposed method. The only hypothesis made in the method was {{the independence of the}} effective delayed neutron fraction and the prompt neutron generation time to the subcriticality level of the system. The proposed method was applied to measure the reactivity of several subcritical configurations of the IPEN/MB- 01 reactor. Measurements of APSD and CPSD were performed in several degrees of subcriticality (up to around - 7000 pcm). The spectral densities data were least squares fitted to get the prompt decay mode (α) and other quantities. Beside the startup source of the facility, an external neutron source of Am-Be was installed near the core in order to improve neutron counting statistics. The final experimental results are of good quality. The proposed experimental method shows clearly that the classical point kinetic theory cannot describe the measured reactivity. Instead, the reactivity inferred from this model follows closely the subcriticality index (ζ) for the source arrangements in the experiment. The agreement of the MCNP 5 and GPT-TORT results, both with ENDF/B-VII. 0 as the basic nuclear data library, when compared to the corresponding experimental ones was also good...|$|R
5000|$|... where M is {{the surface}} area and k is the average <b>neutron</b> <b>multiplication</b> factor. The {{neutrons}} in preceding reactions will be amplified by a factor k, the second generation of fission events will produce k2, the third k3 and so on. In order for a self-sustaining nuclear chain reaction to occur, k {{must be at least}} 3 or 4 percent greater than 1. In other words, k must be greater than 1 without crossing the prompt critical threshold that would result in a rapid, exponential {{increase in the number of}} fission events.|$|E
50|$|An FN Tandem Van de Graaff Generator with {{a maximum}} {{terminal}} voltage of 10 Mega Volts. The facility can produce light ion beams made up of Protons, Deuterons, 3He Nuclei, and 4He Nuclei. The proton and neutron beams produced at the Tandem Laboratory are available either polarized or unpolarized depending on the experiment requirements. Through secondary beam collisions, the lab can also produce polarized neutron beams, allowing the lab to study neutron interactions. The Tandem Lab is primarily intended to study the Strong force at low energies. Research at Tandem includes few-nucleon dynamics, 2-nucleon transfer reactions, and <b>neutron</b> <b>multiplication.</b>|$|E
5000|$|A {{numerical}} {{measure of}} a critical mass {{is dependent on the}} effective <b>neutron</b> <b>multiplication</b> factor , the average number of neutrons released per fission event that go on to cause another fission event rather than being absorbed or leaving the material. When k = 1, the mass is critical, and the chain reaction is barely self-sustaining. A subcritical mass is a mass of fissile material that does not have the ability to sustain a fission chain reaction. A population of neutrons introduced to a subcritical assembly will exponentially decrease. In this case, k < 1. A steady rate of spontaneous fissions causes a proportionally steady level of neutron activity. The constant of proportionality increases as [...] increases.|$|E
40|$|This {{thesis is}} {{concerned}} with the development of mesh-input-free diagnostics for the determination of the iteration at which the source distribution of a Monte Carlo simulation has reached a stationary state, as well as the sufficiency of particle population size for a given tally cell volume, so as to reduce bias and increase accuracy of estimations of physical properties. Such physical properties can include, but are not limited to, <b>neutron</b> effective <b>multiplication,</b> power distribution, <b>neutron</b> flux and various interaction rates. When the physical properties of a Monte Carlo simulation are accurately estimated, they can be used to predict the actual behavior of a nuclear system, only being limited to the assumptions used to create the model. 	Five methods were used to describe the state of the source distribution. Four of the methods were established indicators of the source distribution’s state that required the input of a mesh, which divided the geometry into bins. These indicators are the Shannon entropy, Jensen measure, the progressive relative entropy and the posterior relative entropy. The fifth indicator of the source distribution’s state was developed as to eliminate the need for the input of a mesh upon the geometry. This method will be identified as the regionwise average position indicator or RAPI and is calculated by taking the sum of the distances of the regionwise average particle positions in the model at each cycle from the corresponding regionwise average particle positions at the first cycle. In conjunction with the Shannon entropy, Jensen measure, progressive relative entropy and the RAPI, an on-the-fly step-refined judgment of the indicators of the source distribution’s state will be employed to determine at which cycle or iteration the indicators have reached convergence, signifying that the simulated source distribution has begun to fluctuate around the true source distribution. This step-refined on-the-fly diagnostic of the source distribution was developed from the Wilcoxon rank sum in non-parametric statistics. The posterior relative entropy cycle of convergence is determined to be the cycle at which the posterior relative entropy becomes less than the average value of the posterior relative entropy over the second half of active cycles. The cycle of convergence was determined for three different models by the use of the above described methods. The resulting cycle of convergence obtained by the use of the indicators requiring a mesh input was compared against that obtained from the mesh-input-free indicator, RAPI, for each of the models. It was found that the RAPI was an excellent representation of the source distribution’s state and more conservative than the posterior relative entropy diagnosis. The RAPI can be used to determine the cycle at which the source distribution converged to an equilibrium fluctuation range of stationary state, thus eliminating the need for mesh-input for physical property estimation. 	Applications of graph theory techniques to Monte Carlo methods were also investigated as a means of meshless convergence indication, but drawbacks for such an application led to a particle population diagnostic investigation. This was done because meshless particle population diagnosis for the power distribution has yet to be done in Monte Carlo source iteration methods. In power distribution calculations, tally cells are used to estimate the power distribution in a model. To approach this problem, the concept of Euclidian minimum spanning trees (EMST) was applied to the source distribution to develop a meshless diagnosis of the particle population. One source particle effect is the characteristic volume of one particle and is defined to be the cubic of the average edge length of an EMST. Then using this characteristic volume, weak and strong requirements of the particle population size were defined for minimum tally cell volume. This diagnostic was compared against a verified population diagnostic, which requires a mesh input, termed as PD-MESH in this thesis. These diagnostic methods were used in the analysis of a pressurized water reactor initial full core simulation. The comparison of the EMST-based population diagnosis to PD-MESH showed that {{it can be used to}} determine if a population size is of sufficient size for power distribution calculations, eliminating the need for mesh-based diagnosis. Nuclear EngineeringMastersUniversity of New Mexico. Dept. of Chemical and Nuclear EngineeringUeki, TaroUeki, TaroBusch, RobertPrinja, Ani...|$|R
40|$|The {{purpose of}} this study is to analyze the {{theoretical}} criticality of a spherical uranium-hexafluoride reactor with a transient, pulsed shockwave emanating from the center of the sphere in an outward-radial direction. This novel nuclear reactor design, based upon pulsed fission in a spherical enclosure is proposed for possible use in direct energy conversion, where the energy from fission products is captured through the use of electrostatic fields or through induction. An analysis of the dynamic behavior of the shockwave in this reactor is the subject of this thesis. As a shockwave travels through a fluid medium, the characteristics of the medium will change across the shockwave boundary. Pressure, temperature, and density are all affected by the shockwave. Changes in these parameters will affect the neutronic characteristics of a fissile medium. If the system is initially in a subcritical state, the increases in pressure, temperature, and density, all brought about by the introduction of the shockwave, will increase the reactivity of the nuclear system, creating a brief super critical state that will return to a subcritical state after the shockwave dissipates. Two major problems are required to be solved for this system. One is the effects of the shockwave on the gas, and the second is the resulting effects on system criticality. These problems are coupled due to the unique nature of the speed of the expanding shockwave in the uranium-hexafluoride medium and the energy imparted to the system by the shockwave with respect to the fissile uranium-hexafluoride. Using compressible flow and shockwave theories, this study determines the properties of the gaseous medium for reference points before, during, and behind the shockwave as it passes through the fissile medium. These properties include pressure changes, temperature changes, and density changes that occur to the system. Using the parameters calculated from the shockwave, the neutron transport equation is solved with the appropriate boundary conditions to identify system criticality, neutron flux, and the appropriate changes to system variables such as buckling, and migration length. The analytical solution is then verified using MCNPX, a Monte Carlo method for computational analysis of the neutron transport equation. Through manipulation of the initial pressure of the system, which is intrinsically linked to the density of the system by the ideal gas Equation of State, <b>neutron</b> and flux <b>multiplication</b> trends are corroborated. The results show that both compressible flow theory and shockwave theory are in relatively close agreement for parameter changes across, after, and along the shockwave expansion. The solution to the analytical transport equation is in good agreement with the results from MCNPX. The change in the effective multiplication factor is similar between both the analytical solution and the computational solution. Furthermore, a new method for determining the transient effective multiplication factor is devised. These results show the maximum criticality of the reactor is at the initiation of the shockwave. The shockwave creates a local supercriticality until the wave dissipates below Mach 1. Several tools and methods are employed in this study, including the use of Monte Carlo numerical methods, Euler method solutions, and computer programs, such as MCNP, MATLAB, and Mathcad, which provide necessary the necessary computational abilities to understand the mathematical model of the system...|$|R
5000|$|Hawkins saw {{his role}} {{as that of a}} go-between, {{mediating}} between the civilian scientists and the military leadership at Los Alamos; but he also found a kindred spirit in the Polish mathematician Stan Ulam, who was working in Edward Teller's [...] "Super" [...] Group. They investigated the problem of branching a <b>neutron</b> <b>multiplication</b> in a nuclear chain reaction. Stan Frankel and Richard Feynman had tackled the problem using classical physics, but Ulam and Hawkins approached it using probability theory, creating a new sub-field now known as branching process theory. They investigated branching chains using a characteristic function. After the war, Ulam would extend and generalise this work. He described Hawkins as [...] "the most talented amateur mathematician I know." ...|$|E
