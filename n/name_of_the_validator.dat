0|10000|Public
30|$|As {{discussed}} in the last section, each authoring tool has its own data structure to represent the NCL document being edited, and such structures {{are different from the}} ones maintained by <b>the</b> <b>Validator</b> Model described in Sect. 4.1. According to [34], the design pattern Adapter converts a class interface to a client interface, allowing different classes with incompatible interfaces work together (this is <b>the</b> exactly case <b>of</b> <b>the</b> <b>Validator</b> and <b>the</b> Composer interfaces). Thereby, the integration between the implemented validation and any authoring tool consist simply in creating an adapter that converts the tool model to <b>the</b> <b>Validator</b> Model and ensures that both are synchronized.|$|R
40|$|<b>The</b> purpose <b>of</b> this {{research}} is to realize a scientific presentation assessment instrument {{of a high school}} consisting performance assessment and process assessment instrument. <b>The</b> development <b>of</b> <b>the</b> research used the model developed by Borg and Gall. Trial data collected by document analysis, interviews, and administration <b>of</b> <b>the</b> <b>validator</b> and student questionnaires, then analyzed using qualitative and quantitative techniques. Based on <b>the</b> data <b>of</b> assessment instruments score, scientific presentations was feasible and ready to be implemented...|$|R
5000|$|XPath V2.0: CAM uses XPath {{extensively}} {{for defining}} rules and path target expressions {{that are at}} <b>the</b> heart <b>of</b> <b>the</b> CAM <b>validator</b> processing.|$|R
30|$|A first {{observation}} {{that can be}} made is that this execution environment is <b>the</b> simplest <b>of</b> all we tested: excluding the code for coordinating Mappers and Reducers (itself made of only 250 lines <b>of</b> code), <b>the</b> total implementation <b>of</b> <b>the</b> <b>validator</b> amounts to 1, 000 lines of Java code. This should be put in contrast with BeepBeep, which is also implemented in Java and rather uses the classical, on-the-fly algorithm for <b>the</b> evaluation <b>of</b> LTL formulæ on traces [13]; BeepBeep is is made up of twice as many lines of Java code.|$|R
30|$|It is {{important}} to emphasize again that the instant that the primitives are called to update the Model and the instant that validation occurs are distinct. This enable in theory <b>the</b> possibility <b>of</b> one implementation <b>of</b> <b>the</b> <b>validator</b> allow <b>the</b> entity tool to interfere in the primitive calls (e.g., though listeners) making them more costly (this could happen while the document is being edited, for example) without affecting <b>the</b> validation time <b>of</b> <b>the</b> Model after. Although <b>the</b> focus <b>of</b> this work is on (incremental) validation, we briefly describe <b>the</b> complexity <b>of</b> <b>the</b> Model primitives in the next subsection.|$|R
30|$|The {{network has}} been trained using the {{back-propagation}} algorithm. The training set is generated from <b>the</b> results <b>of</b> <b>the</b> previous detection module that were manually labelled. Initially, a training set, composed by 1973 examples, has been created. It contains 902 pedestrians, and 1071 nonpedestrians examples ranging from traffic sign poles, vehicles, to trees. Then, the training set has been expanded to 4456 examples (1897 of pedestrian and 2559 of nonpedestrian) {{in order to}} cover different situations and temperature conditions and to avoid the overfitting. Moreover, an additional test set has been created in order to evaluate <b>the</b> performance <b>of</b> <b>the</b> <b>validator.</b>|$|R
40|$|Provenance is {{a record}} that {{describes}} the people, institutions, entities, and activities involved in producing, influencing, or delivering a piece of data or a thing. The W 3 C Provenance Working group has just published <b>the</b> PROV family <b>of</b> specifications, which include a data model for provenance on the Web. The working group introduces a notion of valid PROV document whose intent {{is to ensure that}} a PROV document represents a consistent history of objects and their interactions that is safe to use for <b>the</b> purpose <b>of</b> reasoning and other kinds of analysis. Valid PROV documents satisfy certain definitions, inferences, and constraints, specified in PROV-CONSTRAINTS. This paper discusses <b>the</b> design <b>of</b> ProvValidator, an online service for validating provenance documents according to PROV-CONSTRAINTS. It discusses <b>the</b> algorithmic design <b>of</b> <b>the</b> <b>validator,</b> <b>the</b> complexity <b>of</b> <b>the</b> algorithm, how we demonstrated compliance with the standard, and its REST API...|$|R
40|$|Testing {{real-time}} systems under probabilistically distributed stimuli helps uncover faults that elude {{other forms}} of testing. In such testing, it is highly desirable that failures be detected rapidly, so that relevant internal states and traces can be collected. This paper describes a real-time validator which monitors inputs and outputs to the system under test and determines in real-time that a failure has occurred. It presents <b>the</b> key component <b>of</b> <b>the</b> <b>validator,</b> <b>the</b> models <b>of</b> beliefs about <b>the</b> legal evolutions <b>of</b> system behavior. <b>The</b> model is applicable to real-time systems whose external behavior is specified through communicating finite state machine models. The paper presents <b>the</b> derivation <b>of</b> belief models from the specification model and describes a more efficient, rule-based representation of such models. At the end, the paper describes experience with one implementation of a belief-based validator and its use in failure data collection for a small telephone exchange. 1. INTR [...] ...|$|R
40|$|A dynamic {{validation}} process is described for an application (metadata extraction from scanned documents) where a moderate failure rate is acceptable provided that instances of failures during operation could be identified. Lacking a plausible exact oracle for the application, {{a series of}} statistical models of output characteristics is employed. Flexibility and adaptability is achieved by developing a customized scripting language describing how the various tests should be combined to obtain an overall measure of confidence in a program output. <b>The</b> suitability <b>of</b> <b>the</b> <b>validator</b> was demonstrated by an experiment measuring its ability to mimic human judgments as to which of several alternate outputs for the same document would be preferred. ...|$|R
40|$|International audienceTranslation {{validation}} {{consists of}} transforming a {{program and a}} posteriori validating {{it in order to}} detect a modification of its semantics. This approach {{can be used in a}} verified compiler, provided that validation is formally proved to be correct. We present two such validators and their Coq proofs <b>of</b> correctness. <b>The</b> <b>validators</b> are designed for two instruction scheduling optimizations: list scheduling and trace scheduling...|$|R
40|$|A {{computer}} program partly automates <b>the</b> task <b>of</b> determining whether an HDF-EOS 5 file is valid {{in that it}} conforms to specifications for such characteristics as attribute <b>names,</b> dimensionality <b>of</b> data products, and ranges of legal data values. ["HDF-EOS" and variants thereof are defined in "Converting EOS Data From HDF-EOS to netCDF" (GSC- 15007 - 1), which is <b>the</b> first <b>of</b> several preceding articles {{in this issue of}} NASA Tech Briefs. ] Previously, validity of a file was determined in a tedious and error-prone process in which a person examined human-readable dumps <b>of</b> data-file-format information. <b>The</b> present software helps a user to encode the specifications for an HDFEOS 5 file, and then inspects the file for conformity with the specifications: First, the user writes the specifications in Extensible Markup Language (XML) by use of a document type definition (DTD) that is part <b>of</b> <b>the</b> program. Next, <b>the</b> portion <b>of</b> <b>the</b> program (denoted <b>the</b> <b>validator)</b> that performs <b>the</b> inspection is executed, using, as inputs, the specifications in XML and the HDF-EOS 5 file to be validated. Finally, the user examines <b>the</b> output <b>of</b> <b>the</b> <b>validator...</b>|$|R
30|$|ADRC {{may only}} {{consider}} evidence concerning the conduct or management <b>of</b> <b>the</b> Validation Visit if, in <b>the</b> opinion <b>of</b> ADRC, <b>the</b> <b>Validator</b> omitted {{to allow the}} service’s delegate adequate opportunities to enter comments on the Validation Report thus resulting in NCAC’s Accreditation Decision being based on biased evidence or incomplete evidence. Complaints concerning NCAC’s administrative practices would not otherwise constitute grounds for a review <b>of</b> <b>the</b> Accreditation Decision.|$|R
40|$|In {{this paper}} we present Valido, {{a tool that}} {{supports}} <b>the</b> difficult task <b>of</b> validating sense choices produced by a set <b>of</b> annotators. <b>The</b> <b>validator</b> can analyse <b>the</b> semantic graphs resulting from each sense choice and decide which sense is more coherent with respect to <b>the</b> structure <b>of</b> <b>the</b> adopted lexicon. We describe the interface and report an evaluation <b>of</b> <b>the</b> tool in <b>the</b> validation <b>of</b> manual sense annotations. ...|$|R
3000|$|As the service’s {{practices}} are assessed by <b>the</b> <b>Validator</b> to be occurring or not occurring, there is potential for bias based in interpretation. <b>The</b> <b>Validator</b> {{is expected to}} be neutral and unbiased when deciding whether the practice in question is occurring or not occurring. However, as Douglas (2006, p. 208) notes [...]..there is inherent difficulties in this concept <b>of</b> neutrality. <b>The</b> <b>Validator</b> needs to interpret <b>the</b> intent <b>of</b> <b>the</b> quality Indicator and then apply that interpretation to determine whether the practice in question is occurring. Even though Validators undergo extensive training and are required to demonstrate competency by the accrediting body — NCAC (NCAC, 2006, p. 15) <b>the</b> concept <b>of</b> neutrality is ever present. This is highlighted by the following comment made by a service: We have concern about <b>the</b> <b>Validator</b> interpretation <b>of</b> <b>the</b> principles and quality Indicators; opinions can differ and <b>the</b> <b>Validator</b> had said to us that she had to mark on how she interprets the points and acknowledged that we may see it differently.|$|R
40|$|Translation {{validation}} {{consists of}} transforming a {{program and a}} posteriori validating {{it in order to}} detect a modification of its semantics. This approach {{can be used in a}} verified compiler, provided that validation is formally proved to be correct. We present two such validators and their Coq proofs <b>of</b> correctness. <b>The</b> <b>validators</b> are designed for two instruction scheduling optimizations: list scheduling and trace scheduling. Categories and Subject Descriptors F. 3. 1 [Logics and Meaning...|$|R
40|$|Instructional {{media can}} showed {{what the teacher}} can 2 ̆ 7 t say with words, so that the {{abstract}} can be more real with the instructional media. This research is a research and development, aims to produce media-based learning multimedia wich is valid, effective and practical. This research use software Ashampoo MyAutoplay, concept of sense systems in Class XI MAN 2 Model Makassar. This research was conducted using the integrated development model Plomp with Luther 2 ̆ 7 s development model. The subjects were students of class XI IPA 4 MAN 2 Model Makassar. Techniques of data collection in this study there are three, namely validity, obtained through a validation by the validator; effectiveness, acquired through learning achievement and students 2 ̆ 7 response to instructional media; practicality, obtained by evaluation <b>of</b> instrument by <b>validator.</b> <b>The</b> results showed that <b>the</b> average value <b>of</b> <b>the</b> total validity <b>of</b> <b>the</b> <b>validator</b> is 3. 6. Media effectiveness obtained student 2 ̆ 7 s learning achievement showed 91. 9...|$|R
5000|$|Ruby is <b>the</b> {{principal}} maintainer <b>of</b> <b>the</b> Feed <b>Validator</b> validator, {{which he}} developed along with Mark Pilgrim. <b>The</b> Feed <b>Validator</b> About page states, [...] "The validator was conceived and designed by Mark Pilgrim, who also wrote most <b>of</b> <b>the</b> test cases and designed the web front end. Much <b>of</b> <b>the</b> actual back end coding {{was done by}} Sam Ruby." [...] It's able to validate Atom feeds as well as RSS 0.90, 0.91, 0.92, 0.93, 0.94, 1.0, 1.1 and 2.0 feeds.|$|R
40|$|TIMMO Project {{aimed to}} develop a Domain {{specific}} Modeling language for handling timing information while developing automotive distributed embedded systems. Hence timing analysis becomes an obvious step in <b>the</b> validation phase <b>of</b> TIMMO results i. e. TADL, the modelling language and TIMMO methodology, guidelines for using this language. To facilitate timing analysis process, a tool survey was conducted followed by tool inventory {{in order to have}} a selection of most suitable tools that are currently available for timing analysis. A validator system, basically an automotive embedded system was developed to validate the TIMMO results at Volvo Technology. This validator system was modeled with the timing properties using one of these selected tools. The timing models thus created defined <b>the</b> <b>validator</b> system with timing information associated with it and were analysed to study <b>the</b> behaviour <b>of</b> its timing properties. A set of structured steps were defined in <b>the</b> form <b>of</b> heuristics to be followed while modeling such automotive embedded systems along with their timing information. These steps were applied to two different abstraction levels of timing model <b>of</b> <b>the</b> <b>validator</b> system. A timing information flow analysis was also conducted for the different tools involved in defining <b>the</b> <b>validator</b> system in order to find out <b>the</b> possibility <b>of</b> transferring <b>the</b> timing information from one tool to another. By developing a parser in java, it was studied that the timing information defined for modeling an automotive system in one tool can be extracted and can be restructured to model it in another tool...|$|R
40|$|User-input validators play an {{essential}} role in guarding a web application against application-level attacks. Hence, <b>the</b> security <b>of</b> <b>the</b> web application can be compromised by defective validators. To detect defects in validators, testing is one <b>of</b> <b>the</b> most commonly used methodologies. Testing can be performed by manually writing test inputs and oracles, but this manual process is often laborintensive and ineffective. On the other hand, automated test generators cannot generate test oracles in <b>the</b> absence <b>of</b> specifications, which are often not available in practice. To address this issue in testing validators, we propose a novel approach, called MiTV, that applies Multiple-implementation Testing for Validators, i. e., comparing <b>the</b> behavior <b>of</b> a <b>validator</b> under test with other <b>validators</b> <b>of</b> <b>the</b> same type. These other <b>validators</b> <b>of</b> <b>the</b> same type can be collected from either open or proprietary source code repositories. To show <b>the</b> effectiveness <b>of</b> MiTV, we applied MiTV on 53 different validators (of 6 common types) for web applications. Our results show that MiTV detected real defects in 70 % <b>of</b> <b>the</b> <b>validators...</b>|$|R
40|$|Objectives to be {{achieved}} {{in this study were}} (1) Finding the problems and needs of blind students, planning, and prototype book enriching appreciation of literature in Braille that can be developed in school inclusion. (2) Develop prototype (draft) enrichment of literary appreciation books in Braille for blind students in school inclusion. (3) Test <b>the</b> effectiveness <b>of</b> <b>the</b> application <b>of</b> <b>the</b> enrichment <b>of</b> literary appreciation books <b>of</b> <b>the</b> <b>validator</b> in Braille for blind students in school inclusion. The method in this study research design development. The subjects were blind students who will use <b>the</b> product <b>of</b> <b>the</b> enrichment books and Indonesian language and literature teacher who will conduct an assessment <b>of</b> <b>the</b> indicators <b>of</b> achievement <b>of</b> <b>the</b> basic competencies <b>of</b> students with visual impairment. Plan activities that have been carried out in this research is <b>the</b> development <b>of</b> book design enrichment phases: (1) a preliminary study; (2) the development stage; (3) the testing stage book; (4) dissemination <b>of</b> <b>the</b> results <b>of</b> <b>the</b> final product, namely enrichment of literary appreciation books in Braille. The final product in <b>the</b> form <b>of</b> books enrichment appreciation of literature in Braille can be used by blind students in inclusive classrooms...|$|R
40|$|AbstractPurposeThe Japan Prosthodontic Society (JPS) has {{proposed}} a new diagnostic nomenclature system (DNS), based on pathogenesis and etiology, to facilitate and improve prosthodontic treatment. This system specifies patient disability and the causative factor (i. e. “B (disability) caused by A (causative factor) ”). <b>The</b> purpose <b>of</b> {{this study was to}} examine the reliability and validity of this DNS. Study selectionThe JPS Clinical Guideline Committee assessed mock patient charts and formulated disease names using the new DNS. Fifty validators, comprising prosthodontic specialists and dental residents, made diagnoses using the same patient charts. Reliability was evaluated as <b>the</b> consistency <b>of</b> <b>the</b> disease <b>names</b> among <b>the</b> <b>validators,</b> and validity was evaluated using <b>the</b> concordance rate <b>of</b> <b>the</b> disease <b>names</b> with the reference disease names. ResultsKrippendorff's α was 0. 378 among all validators, 0. 370 among prosthodontic specialists, and 0. 401 among dental hospital residents. Krippendorff's α for 10 validators (3 specialists and 7 residents) with higher concordance rates was 0. 524. Two validators (1 specialist and 1 resident) with the highest concordance rates had a Krippendorff's α of 0. 648. Common disease names had higher concordance rates, while uncommon disease names showed lower concordance rates. These rates did not show correlation with clinical experience <b>of</b> <b>the</b> <b>validator</b> or time taken to devise the disease name. ConclusionsHigh reliability was not found among all validators; however, validators with higher concordance rates showed better reliability. Furthermore, common disease names had higher concordance rates. These findings indicate that the new DNS for prosthodontic dentistry exhibits clinically acceptable reliability and validity...|$|R
40|$|The {{polyhedral}} model provides {{techniques to}} optimize Static Control Programs (SCoP) using some complex transformations which improve data-locality and which can exhibit parallelism. These advanced transformations {{are now available}} in both GCC and LLVM. In this paper, we focus on <b>the</b> correctness <b>of</b> these transformations and in particular on <b>the</b> problem <b>of</b> integer overflows. Indeed, <b>the</b> strength <b>of</b> <b>the</b> polyhedral model is to produce an abstract mathematical representation of a loop nest which allows high-level transformations. But this abstract representation is valid only when we {{ignore the fact that}} our integers are only machine integers. In this paper, we present a method to deal with this problem <b>of</b> mismatch between <b>the</b> mathematical and concrete representations of loop nests. We assume <b>the</b> existence <b>of</b> polyhedral optimization transformations which are proved to be correct in a world without overflows and we provide a self-verifying compilation function. Rather than verifying <b>the</b> correctness <b>of</b> this function, we use an approach based on a validator, which is a tool that is run by the compiler after the transformation itself and which confirms that the code produced is equivalent to the original code. As we aim at <b>the</b> formal proof <b>of</b> <b>the</b> <b>validator</b> we implement this <b>validator</b> using <b>the</b> Coq proof assistant as a programming language [4]...|$|R
40|$|<b>The</b> purpose <b>of</b> {{this review}} of {{software}} metrics {{is to examine}} <b>the</b> quality <b>of</b> <b>the</b> metrics gathered in the 2010 IV&V and to set an outline for results of updated metrics runs to be performed. We find from the review that <b>the</b> maintenance <b>of</b> accepted quality standards presented in the SAPHIRE 8 initial Independent Verification and Validation (IV&V) of April, 2010 is most easily achieved by continuing to utilize the tools used in that effort while adding a metric of bug tracking and resolution. Recommendations from the final IV&V were to continue periodic measurable metrics such as McCabe's complexity measure to ensure quality is maintained. The four software tools used to measure quality in the IV&V were CodeHealer, Coverage Validator, Memory Validator, Performance Validator, and Thread Validator. These are evaluated based on their capabilities. We attempted to run their latest revisions with the newer Delphi 2010 based SAPHIRE 8 code that has been developed and was successful with all <b>of</b> <b>the</b> <b>Validator</b> series <b>of</b> tools on small tests. Another recommendation from the IV&V was to incorporate a bug tracking and resolution metric. To improve our capability of producing this metric, we integrated our current web reporting system with the SpiraTest test management software purchased {{earlier this year to}} track requirements traceability...|$|R
40|$|In <b>the</b> process <b>of</b> {{teaching}} and learning activities (KBM) there are three main components involved in it, that component namely teachers, students and learning materials. Teachers {{as much as possible}} to create a fun learning atmosphere for students interested in pursuing teaching. To create a fun atmosphere, teachers can use Macromedia flash 8 as one choice of learning media. So expect a package of learning materials using Macromedia flash 8, students better understand the material and are interested in following <b>the</b> KBM. Development <b>of</b> instructional media of learning is to determine validity, practicality and effectiveness of instructional media that will be used by teachers in the classroom teaching process. This type <b>of</b> research is <b>the</b> development <b>of</b> instructional media. <b>The</b> experiment was conducted on 29 November 2011 semester of odd academic year 2011 - 2012 at <b>the</b> Laboratory <b>of</b> Hassanuddin Malang Islamic junior high, with 9 students research subjects. The instrument used in <b>the</b> form <b>of</b> a questionnaire given to media experts, scholars and students <b>of</b> material. <b>The</b> data collected is qualitative and quantitative. Based on <b>the</b> results <b>of</b> <b>the</b> validation media and trials to <b>the</b> <b>validator</b> and 9 students in junior high Hassanuddin Islam Malang by filling a questionnaire provided, then obtained the conclusion that <b>the</b> medium <b>of</b> learning is valid, practical and effective for use in the teaching process. If <b>the</b> value <b>of</b> <b>the</b> <b>validator</b> validation and assessment of students to instructional media are among 3 ≤ RTKTK ≤ 4 then declared valid instructional media and the media are not revised. <b>The</b> value validation <b>of</b> expert material that is 3, 867, <b>the</b> value <b>of</b> validation from <b>the</b> media experts 3, 733 and <b>the</b> average ratings <b>of</b> 9 students to the media that is 3, 519. Practicality of learning media that is easy for teachers and students to operate the media Instructional media effectively if ≤ 75...|$|R
40|$|This {{research}} aims {{to produce}} a TIMSS characterized math problems that are valid and reliable. <b>The</b> method <b>of</b> this research is Design Research. <b>The</b> sample <b>of</b> this study were 31 students of SMP Negeri 1 Inderalaya. <b>The</b> procedure <b>of</b> this study through <b>the</b> stages <b>of</b> Preliminary Evaluation and Formative Evaluation. Based on the results obtained 7 of TIMSS characterized with characteristics (1) using real-life contexts, (2) using characteristics of TIMSS, and (3) <b>the</b> type <b>of</b> problem-solving that problem logically and empirically valid  and reliable. Valid logically be fulfilled from <b>the</b> results <b>of</b> <b>the</b> assessment <b>validator,</b> where <b>the</b> <b>validator</b> comment on <b>the</b> terms <b>of</b> <b>the</b> content, construct, and  language. Valid empirically criteria for both internally for items validity and externally for the whole items validity. Items also expressed reliable {{with a high level}} <b>of</b> confidence as <b>the</b> test instrument through items with the analysis result reliability coefficient of 0, 703. Keywords : TIMSS, Design Research, Problem Solving, Geometry, Volume Cube and Rectangular Prism</p...|$|R
3000|$|... 50 % of {{services}} stated insufficient time was allocated {{for the service}} to discuss issues <b>of</b> concern with <b>the</b> <b>Validator</b> assessment/s following <b>the</b> completion <b>of</b> <b>the</b> assessment process; 25 % {{of services}} considered all documentation was not taken into account when <b>the</b> assessment <b>of</b> their practices was made; 20 % of services stated proper consideration was not given to documentation that was presented to <b>the</b> <b>Validator</b> and/or accrediting body; and 5 % of services stated unrelated reasons {{as to why the}} service was assessed as not meeting <b>the</b> intent <b>of</b> <b>the</b> quality Indicator. As noted by Douglas (2006) and Groves and Lee (2007), procedural fairness would require the service to have a reasonable opportunity to present their case, that <b>the</b> intent <b>of</b> <b>the</b> quality Indicator was being met at <b>the</b> time <b>of</b> <b>the</b> Validation Visit, to the accrediting body.|$|R
40|$|<b>The</b> purpose <b>of</b> this {{research}} is to make product design development of stick and ball sports in gateball. The approach {{used in this study}} is a method of Research and Development. <b>The</b> subject <b>of</b> {{this research}} is the Central Java on gateball club event gateball in Semarang and Yogyakarta. Experts and expert expert gateball expert in mechanical engineering. The data analysis phase the work field, and the data analysis stage include observation, observation, interviews, and documentation <b>of</b> <b>the</b> test kefektifan products, expert judgment expert expert gateball and expert mechanical engineering expert. <b>The</b> results <b>of</b> this research are stick and ball exercise for beginner players gateball gateball. <b>The</b> result <b>of</b> <b>the</b> <b>validator</b> 3 expert expert from the expert gateball and expert mechanical engineering product validation data beginning the first phase obtained a score above 73 definitions <b>of</b> <b>the</b> criteria <b>of</b> “good”, on <b>the</b> second stage <b>of</b> <b>the</b> product validation data obtained a score above the 81 criteria for “excellent”. <b>The</b> results <b>of</b> <b>the</b> interviews to <b>the</b> development <b>of</b> gateball players 19 stick and ball gateball {{can not be used to}} play in a match and can be used for subsequent exercises but for beginners a product development tool model stick and ball gateball “ INC. “can be used to enhance <b>the</b> ability <b>of</b> basic techniques in motion game for players, gateball...|$|R
40|$|International audienceThe {{polyhedral}} model provides {{techniques to}} optimize Static Control Programs (SCoP) using some complex transforma- tions which improve data-locality and which can exhibit par- allelism. These advanced transformations {{are now available}} in both GCC and LLVM. In this paper, we focus on <b>the</b> cor- rectness <b>of</b> these transformations and in particular on <b>the</b> problem <b>of</b> integer overflows. Indeed, <b>the</b> strength <b>of</b> <b>the</b> polyhedral model is to produce an abstract mathematical representation of a loop nest which allows high-level trans- formations. But this abstract representation is valid only when we {{ignore the fact that}} our integers are only machine integers. In this paper, we present a method to deal with this problem <b>of</b> mismatch between <b>the</b> mathematical and concrete representations of loop nests. We assume <b>the</b> exis- tence <b>of</b> polyhedral optimization transformations which are proved to be correct in a world without overflows and we provide a self-verifying compilation function. Rather than verifying <b>the</b> correctness <b>of</b> this function, we use an approach based on a validator, which is a tool that is run by the com- piler after the transformation itself and which confirms that the code produced is equivalent to the original code. As we aim at <b>the</b> formal proof <b>of</b> <b>the</b> <b>validator</b> we implement this <b>validator</b> using <b>the</b> Coq proof assistant as a programming language [4]...|$|R
5000|$|Necessity: critics, {{such as the}} Public Transport Users Association, {{questioned}} why a new {{ticketing system}} was needed, when Melbourne already had an adequate one. The Metcard validating equipment already had built-in support for a contactless ticket (the yellow circles on <b>the</b> front <b>of</b> <b>the</b> former Metcard <b>validators,</b> {{as well as on}} Ticket Vending Machines (TVMs).|$|R
40|$|This {{research}} is a developmental research {{which aims to}} produce computer-based learning media interactive tutorial model on the subject circle for class VIII SMP/ MTs that is valid and practical. This developmental research used development model based on <b>the</b> teory <b>of</b> Borg and Gall. The stages are: (1) potential and problem; (2) literature collection; (3) product design; (4) product validation; (5) product revision; (6) product tested; (7) product revision; (8) product tested in large group; (9) product revision. In the first stages, the researcher analyzed potentials and problems. After that, the researcher collected the reference materials, then designed the product {{and put it into}} a computer. The learning media that had been developed was be evaluated by three <b>validators</b> based on <b>the</b> aspects <b>of</b> learning, display, program and curriculum, and revised according to <b>the</b> advice <b>of</b> <b>the</b> <b>validator.</b> Next, <b>the</b> learning media that had been revised was be tested in two stages: product testing in small groups with <b>the</b> subject <b>of</b> five students of class VIII SMP Juara Pekanbaru and product testing in large groups with <b>the</b> subject <b>of</b> 25 students class VIII SMP Juara Pekanbaru. Based on <b>the</b> results <b>of</b> data analysis and discussion, it can be concluded that the computer-based learning media interactive tutorial model for the subject circle class VIII SMP / MTs assessed valid by experts with an average value of 3. 59 and received a very good response from students of class VII...|$|R
40|$|Poster at Open Repositories 2014, Helsinki, Finland, June 9 - 13, 2014 Posters, Demos and Developer "How-To's"This poster {{presents}} <b>the</b> {{new developments}} <b>of</b> <b>the</b> second version <b>of</b> <b>the</b> RCAAP <b>validator.</b> It introduces new contexts of validation, {{a more detailed}} validation option for each set and the possibility to extend to new validation profiles. This validator also includes a format validation tool {{to be used with}} digital preservation plans. Finally, a new interface and an English translation make it usable by all repository managers to promote interoperability. Carvalho, José (University of Minho, Portugal) Rodrigues, Eloy (University of Minho, Portugal) Príncipe, Pedro (University of Minho, Portugal) Moreira, João (FCT/FCCN, Portugal...|$|R
50|$|In Norway, <b>the</b> <b>name</b> <b>of</b> <b>the</b> {{language}} is samisk, and <b>the</b> <b>name</b> <b>of</b> <b>the</b> people is Same; in Finland, <b>the</b> <b>name</b> <b>of</b> <b>the</b> {{language is}} spelled saame and <b>the</b> <b>name</b> <b>of</b> <b>the</b> people saamelainen.|$|R
40|$|The Subtitle (if available) /undertitel om sådan finns <b>The</b> <b>name</b> <b>of</b> <b>the</b> Author/författarens namn University/Faculty logo (if requested) /universitets- eller fakultetslogo Link to {{printable}} logos/länk till tryckfärdiga logos <b>The</b> <b>name</b> <b>of</b> <b>the</b> department/institution, <b>the</b> <b>name</b> <b>of</b> <b>the</b> Division/avdelning <b>The</b> <b>name</b> <b>of</b> <b>the</b> faculty/fakulte...|$|R
5000|$|And {{he called}} <b>the</b> <b>name</b> <b>of</b> <b>the</b> first {{daughter}} Jemimah, and <b>the</b> <b>name</b> <b>of</b> <b>the</b> second Keziah, and <b>the</b> <b>name</b> <b>of</b> <b>the</b> third Keren-happuch ...|$|R
50|$|<b>The</b> <b>name</b> <b>of</b> a salt {{starts with}} <b>the</b> <b>name</b> <b>of</b> <b>the</b> cation (e.g., sodium or ammonium) {{followed}} by <b>the</b> <b>name</b> <b>of</b> <b>the</b> anion (e.g., chloride or acetate). Salts are {{often referred to}} only by <b>the</b> <b>name</b> <b>of</b> <b>the</b> cation (e.g., sodium salt or ammonium salt) or by <b>the</b> <b>name</b> <b>of</b> <b>the</b> anion (e.g., chloride salt or acetate salt).|$|R
50|$|An object (referent, denotation) has a <b>name,</b> <b>the</b> <b>name</b> <b>of</b> <b>the</b> object. The object has {{a concept}} (sense), <b>the</b> concept <b>of</b> <b>the</b> object, {{associated}} with <b>the</b> <b>name</b> <b>of</b> <b>the</b> object. A <b>name</b> or concept are themselves objects, and have <b>names,</b> <b>the</b> <b>name</b> <b>of</b> <b>the</b> <b>name</b> <b>of</b> <b>the</b> object, and <b>the</b> <b>name</b> <b>of</b> <b>the</b> concept <b>of</b> <b>the</b> object. Similarly they have concepts {{as any other}} object. A name is said to denote the object {{for which it is}} the name.|$|R
