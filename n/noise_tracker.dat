9|14|Public
5000|$|He {{first began}} {{composing}} songs {{at the age}} of eight, using an Amiga computer and applications like <b>Noise</b> <b>Tracker.</b> He did not like to use of ready-made samples so he started creating the samples with a home construction sampler connected to the computer. He continued to develop his skills until releasing his first music in 1994; the American company Almathera published the first CD-ROM intended for Polish users {{in the history of the}} Amiga, [...] "CDPL",and added Jakub Rene Kosik's material, among many other things. Many of his samples were later used in the so-called music modules, including the CD-ROM [...] "The Sound and Modules" [...] (EXE, PL).|$|E
30|$|In future, {{we would}} like to extend the pre-image {{iteration}} method by a <b>noise</b> <b>tracker</b> to generalize the method from stationary noise to other noise types such as babble noise. Furthermore, we plan to build a recognizer for data of the Noizeus database for speech enhancement.|$|E
40|$|Acoustic environments provide many {{valuable}} cues for context-aware computing applications. From {{the acoustic}} environment we can infer {{the types of}} activity, communication modes and other actors involved in the activity. Environmental or background noise can be classified {{with a high degree}} of accuracy using recordings from microphones commonly found in PDAs and other consumer devices. We describe an acoustic environment recognition system incorporating an adaptive learning mechanism and its use in a <b>noise</b> <b>tracker.</b> We show how this information is exploited in a mobile context framework. To illustrate our approach we describe a context-aware multimodal weather forecasting service, which accepts spoken or written queries and presents forecast information in several forms, including email, voice and sign languag...|$|E
40|$|Noise {{tracking}} is {{an important}} component of speech enhance-ment algorithms. Of the many <b>noise</b> <b>trackers</b> proposed, Min-imum Statistics (MS) is a particularly popular one due to its simple parameterization {{and at the same time}} excellent perfor-mance. In this paper we propose to further reduce the number of MS parameters by giving an alternative derivation of an optimal smoothing constant. At the same time the noise tracking perfor-mance is improved as is demonstrated by experiments employ-ing speech degraded by various noise types and at different SNR values. Index Terms: speech enhancement, noise tracking, optimal smoothin...|$|R
30|$|Existing phase <b>noise</b> estimators or <b>trackers</b> {{have one}} thing in common. Their {{derivation}} does not stem from a probabilistic analysis, but is rather driven by pragmatic (and scenario dependent) arguments. Incidentally, the use of feedback loops or phase-locked loops is common practice [1].|$|R
40|$|Tracking {{maneuvering}} targets with radar {{is complicated}} because radar cannot measure target accelerations. We use the range rate measurement to calculate a new statistic {{that is a}} surrogate measurement of target acceleration under a coordinate turn model. Its distribution is found via simulation. A threshold test of the statistic {{turns out to be}} a reliable detector of a maneuver, and its receiver operating characteristic is found. A tracker that uses a threshold test of the new statistic of accelerations to detect maneuvers and set the state noise in a Kalman filter tracker is devleoped and compared to other, common maneuvering track filters. The new method outperforms a two mode interacting multiple model <b>tracker</b> and a <b>noise</b> switching <b>tracker</b> that switches based on the position measurement residuals...|$|R
40|$|University of Minnesota M. S. E. E. thesis. Deember 2015. Major: Electrical Engineering. Advisor: Tom Luo. 1 {{computer}} file (PDF); iv, 49 pages. Despite good performance in quiet environments, {{there are still}} significant gaps in speech perception in noise between normal-hearing listeners and hearing-impaired listeners using devices like hearing aids or cochlear implants (CIs). Much effort has been invested to develop noise reduction algorithms that could fulfill these gaps, but few of them {{have the ability to}} enhance speech intelligibility without any prior knowledge of the speech signal, including both statistical properties and location information. In this study, a single-channel noise reduction algorithm, based on a noise tracking algorithm and the binary masking (BM) method, was implemented for CI users. The noise tracking algorithm was able to catch detailed spectral information of the noise with a fast <b>noise</b> <b>tracker</b> during the noise-like frames and update the estimated accumulative noise level with a slow <b>noise</b> <b>tracker</b> during speech-like frames. Next, this noise tracking algorithm was used to estimate the signal-to-noise ratio (SNR) of each temporal-spectral region, termed “time-frequency unit” in the BM method, to determine whether to eliminate or retain each unit. Finally, a sentence perception test was employed to investigate the effects of this noise reduction algorithm in various types of background noise and input SNR conditions. Results showed that the mean percent correct for CI users is improved in most conditions by the noise reduction process. Improvements in speech intelligibility were observed at all input SNR conditions for the babble and speech-shaped noise conditions; however, challenges still remain for the non-stationary restaurant noise...|$|E
40|$|In this paper, we {{analyze the}} minimum {{mean square error}} (MMSE) based {{spectral}} noise power estimator [1] and present an improve-ment. We will show that the MMSE based spectral noise power estimate is only updated when the a posteriori signal-to-noise ratio (SNR) is lower than one. This threshold on the a posteriori SNR can be interpreted as a voice activity detector (VAD). We propose in this work to replace the hard decision of the VAD by a soft speech presence probability (SPP). We show that by doing so, the proposed estimator does not require a bias cor-rection and safety-net as is required by the MMSE estimator pre-sented in [1]. At the same time, the proposed estimator maintains the quick noise tracking capability which is characteristic for the MMSE <b>noise</b> <b>tracker,</b> results in less noise power overestimation and is computationally less expensive. Index Terms — Noise power estimation, speech enhancement, noise reduction. 1...|$|E
40|$|In this paper, {{we focus}} on methods for {{estimating}} the a posteriori proba-bility of a signal segment being voiced which employ a harmonic signal model. Fisher et al. [1] present two likelihood functions for voiced and unvoiced speech from which the posterior probability can be derived. However, due to the chosen models, the a posteriori probability of a signal segment being voiced does not go to 0 % in unvoiced speech. Thus, a novel algorithm is proposed, which incorporates the expected unvoiced speech energy and allows for obtaining low probabilities. Further, it explicitly models the statistics of the segment energy and employs a state-of-the-art <b>noise</b> <b>tracker.</b> Experiments which were conducted on the TIMIT database for different noise types and noise levels show that the proposed method results in lower over-estimation and under-estimation of the voicing probability as compared to [1]. Index Terms — voiced-unvoiced decision, likelihood ratio test, harmonic model, voicing determination, a posteriori probability 1...|$|E
40|$|A {{satellite}} precision {{attitude control}} system was designed, based {{on the use of}} STARS as the principal sensing system. The entire system was analyzed and simulated in detail, considering the nonideal properties of the control and sensing components and realistic spacecraft mass properties. Experimental results were used to improve the star <b>tracker</b> <b>noise</b> model. The results of the simulation indicate that STARS performs in general as predicted in a realistic application and should be a strong contender in most precision earth pointing applications...|$|R
40|$|We {{present an}} {{efficient}} algorithm for {{the enhancement of}} speech signals which are heavily corrupted by short-time stationary, acoustically or electrically added disturbances. The algorithm is based on spectral amplitude estimation using an overlapadd FFT filter bank system. Compared to other systems, the improved performance of our speech enhancement system is achieved by {{the combination of the}} best known spectral amplitude estimators of the noisy speech signal and a new efficient and reliable <b>noise</b> spectrum <b>tracker.</b> As a result, our speech enhancement system requires no speech pause detection for noise estimation and needs only 14 % [...] 23 % of the resources of a commercially available digital signal processor. I. Introduction T HE enhancement of noisy speech is a challenging research field with applications including suppression of environmental noise in machinery halls, mobile radio communications systems, noise suppressors for automatic speech recognition systems, and hearing aids [...] . ...|$|R
40|$|A multibeam {{microwave}} radar altimeter concept is numerically simulated to evaluate its capability to remotely sense mesoscale oceanographic features and eddies in particular. The study tests {{the sensitivity of}} the sensor to variations of systematic and environmental parameters, including sensor attitude angle, sensor position, and system errors. A novel concept of computing eddy vorticity from the multibeam data is explored. Application of this concept to the detection of simulated ocean eddies in the presence of <b>tracker</b> <b>noise</b> data gives excellent results; the technique is shown to be simple and accurate. The minimum size of the eddy detectable by the multibeam altimeter is presented for a given performance characteristic of the radar...|$|R
40|$|In this paper, {{we address}} the small {{vocabulary}} track (track 1) {{described in the}} CHiME 2 challenge dedicated to recognize utterances of a target speaker with small head movements. The utterances are recorded in a reverberant room acoustics corrupted with highly non-stationary noise sources. Such adverse noise scenario imposes a challenge to state-of-the-art automatic speech recognition systems. We developed two individual front ends for {{the output of the}} delay-and-sum beamformer: (i) a model-driven single-channel speech enhancement stage which combines the knowledge of the speaker identity modeled by a trained vector quantizer with a minimum statistics based <b>noise</b> <b>tracker,</b> and (ii) asingle-channelsourceseparationstagewhichemploysmodels of the target speaker as well as the background noise as codebooks. Our perceived signal quality and separation results averaged on the CHiME 2 development set justify the effectiveness of both strategies in terms of recovering the target speech signal. Also, our best results on keyword recognition accuracy show 20 % improvement over the provided baseline results on the development and test sets. Index Terms — Single-channel source separation, Modeldriven speech enhancement, Automatic speech recognition...|$|E
40|$|Tracking non-rigid and {{articulated}} {{objects in}} live video is a challenging task, particularly because object geometry and appearance can undergo rapid changes between video frames. Color-based trackers do {{not rely on}} geometry, yet {{they have to make}} assumptions on the background’s color as to avoid confusion with the foreground object. This chapter presents “Flocks of Features, ” a tracking method that combines motion cues and a learned foreground color distribution for fast and robust 2 D tracking of highly articulated objects. Many independent image artifacts are tracked from one frame to the next, adhering only to local constraints. This concept is borrowed from nature since these tracks mimic the flight of flocking birds – exhibiting local individualism and variability while maintaining a clustered entirety. The method’s benefits lie in its ability to track objects that undergo vast and rapid deformations, its ability to overcome failure modes from the motion cue as well as the color cue, its speed, and its robustness against background <b>noise.</b> <b>Tracker</b> performance is demonstrated on hand tracking with a nonstationary camera in unconstrained indoor and outdoor environments. When compared to a CamShift tracker on the highly varied test data, Flocks of Features tracking yields a threefold improvement {{in terms of the number}} of frames of successful target tracking...|$|E
40|$|Recently we have {{developed}} a non-linear feature-domain noise reduction algorithm based on the {{minimum mean square error}} (MMSE) criterion on Mel-frequency cepstra (MFCC) for environment-robust speech recognition. Our novel algorithm operates on the power spectral magnitude of the filter-bank’s outputs and outperforms the log-MMSE spectral amplitude noise suppressor proposed by Ephraim and Malah in both recognition accuracy and efficiency as demonstrated on the Aurora- 3 corpora. This paper serves two purposes. First, we show that the algorithm is effective on large vocabulary tasks with tri-phone acoustic models. Second, we report improvements on the suppression rule of the original MFCC-MMSE noise suppressor by smoothing the gain over the previous frames to prevent the abrupt change of the gain over frames and adjusting gain function based on the noise power so that the suppression is aggressive when the noise level is high and conservative when the noise level is low. We also propose an efficient and effective parameter tuning algorithm named step-adaptive discriminative learning algorithm (SADLA) to adjust the parameters used by the <b>noise</b> <b>tracker</b> and the suppressor. We observed a 46 % relative word error (WER) reduction on an in-house large-vocabulary noisy speech database with a clean trained model, which translates into a 16 % relative WER reduction over the original MFCC-MMSE noise suppressor, and 6 % relative WER reduction on the Aurora- 3 corpora over our original MFCC-MMSE algorithm or 30 % relative WER reduction over the CMN baseline...|$|E
40|$|The main {{subsystems}} of the CMS Tracker {{have been}} assembled {{together in a}} dedicated large clean room at CERN, prior to the installation in CMS. Following {{the integration of the}} Tracker a long commissioning period took place, during which, up to 15 % of the silicon modules were operated and read out simultaneously at different temperatures. Some of the achievements of this commissioning phase are discussed in details, like <b>Tracker</b> <b>noise</b> performance, signal-to-noise measurements and hit reconstruction efficiency. The Tracker was inserted in CMS in December 2007 and the commissioning of the full Tracker started. A sketch of the commissioning procedure followed at CMS and the actual status of the Tracker are presented...|$|R
40|$|We {{describe}} a software framework {{to evaluate the}} performance of model-based optical trackers in virtual environments. The framework {{can be used to}} evaluate and compare the performance of different trackers under various conditions, to study the effects of varying intrinsic and extrinsic camera properties, and to study the effects of environmental conditions on tracker performance. The framework consists of a simulator that, given various input conditions, generates a series of images. The input conditions of the framework model important aspects, such as the interaction task, input device geometry, camera properties and occlusion. As a concrete case, we illustrate the usage of the proposed framework for input device tracking in a near-field desktop virtual environment. We compare the performance of an in-house tracker with an ARToolkitPlus-based tracker under a fixed set of conditions. We also show how the framework can be used to assess the quality of various camera placements given a pre-recorded interaction task. Finally, we use the framework to determine the minimum required camera resolution for a desktop, Workbench and CAVE environment, and study the influence of random <b>noise</b> on <b>tracker</b> accuracy. The framework is shown to provide an efficient and simple method to study various conditions affecting optical tracker performance. Furthermore, it {{can be used as a}} valuable development tool to aid in the construction of optical trackers...|$|R
40|$|Visuo-haptic {{augmented}} reality systems enable users {{to see and}} touch digital information that {{is embedded in the}} real world. PHANToM haptic devices are often employed to provide haptic feedback. Precise co-location of computer-generated graphics and the haptic stylus is necessary to provide a realistic user experience. Previous work has focused on calibration procedures that compensate the non-linear position error caused by inaccuracies in the joint angle sensors. In this article we present a more complete procedure that additionally compensates for errors in the gimbal sensors and improves position calibration. The proposed procedure further includes software-based temporal alignment of sensor data and a method for the estimation of a reference for position calibration, resulting in increased robustness against haptic device initialization and external <b>tracker</b> <b>noise.</b> We designed our procedure to require minimal user input to maximize usability. We conducted an extensive evaluation with two different PHANToMs, two different optical trackers, and a mechanical tracker. Compared to state-of-the-art calibration procedures, our approach significantly improves the co-location of the haptic stylus. This results in higher fidelity visual and haptic augmentations, which are crucial for fine-motor tasks in areas such as medical training simulators, assembly planning tools, or rapid prototyping applications...|$|R
40|$|International audienceA {{solution}} for interaction using finger tracking in a cubic immersive virtual reality system (or immersive cube) is presented. Rather than using a traditional wand device, users can manipulate objects with fingers of both {{hands in a}} close-to-natural manner for moderately complex, general purpose tasks. Our solution couples finger tracking with a real-time physics engine, combined with a heuristic approach for hand manipulation, which is robust to <b>tracker</b> <b>noise</b> and simulation instabilities. A first study has been performed to evaluate our interface, with tasks involving complex manipulations, such as balancing objects while walking in the cube. The users finger-tracked manipulation was compared to manipulation with a 6 degree-of-freedom wand (or flystick), {{as well as with}} carrying out the same task in the real world. Users were also asked to perform a free task, allowing us to observe their perceived level of presence in the scene. Our results show that our approach provides a feasible interface for immersive cube environments and is perceived by users as being closer to the real experience compared to the wand. However, the wand outperforms direct manipulation in terms of speed and precision. We conclude with a discussion of the results and implications for further research...|$|R
40|$|Abstract: We {{present a}} {{solution}} for interaction using finger tracking in a cubic immersive virtual reality system (or immersive cube). Rather than using a traditional wand device, users can manipulate objects with fingers of both hands in a close-to-natural manner for moderately complex, general purpose tasks. Our solution couples finger tracking with a real-time physics engine, combined with a heuristic approach for hand manipulation, which is robust to <b>tracker</b> <b>noise</b> and simulation instabilities. We performed an exploratory study to evaluate our interface, with tasks involving complex manipulations, such as balancing objects while walking in the cube. The user’s finger-tracked manipulation was compared to manipulation with a 6 -DOF wand (or flystick), {{as well as with}} carrying out the same task in the real world. Users were also asked to perform a free task, allowing us to observe their perceived level of presence in the scene. Our results show that our approach provides a feasible interface for immersive cube environments and is perceived by users as being closer to the real experience compared to the wand. However, the wand outperforms direct manipulation in terms of speed and precision. We conclude with a discussion of the results and implications for further research. This project has been submitted to Virtual Reality journal in March 2013...|$|R
40|$|Abstract A {{solution}} for interaction using finger tracking in a cubic immersive virtual reality system (or immersive cube) is presented. Rather than using a traditional wand device, users can manipulate objects with fingers of both {{hands in a}} close-to-natural manner for moderately complex, general purpose tasks. Our solution couples finger tracking with a real-time physics engine, combined with a heuristic approach for hand manipulation, which is robust to <b>tracker</b> <b>noise</b> and simulation instabilities. A first study has been performed to evaluate our interface, with tasks involving complex manipulations, such as balancing objects while walking in the cube. The users finger-tracked manipulation was compared to manipulation with a 6 degree-of-freedom wand (or flystick), {{as well as with}} carrying out the same task in the real world. Users were also asked to perform a free task, allowing us to observe their perceived level of presence in the scene. Our results show that our approach provides a feasible interface for immersive cube environments and is perceived by users as being closer to the real experience compared to the wand. However, the wand outperforms direct manipulation in terms of speed and precision. We conclude with a discussion of the results and implications for further research...|$|R
40|$|This paper {{presents}} a computationally cheap algorithm for near-optimal trajectory generation in presence of control constraints. We consider {{the problem of}} moving an omnidirectional vehicle from a specified initial state to a desired final state while maintaining a good trade-off between the maneuver time and the final state-error. A parameterized spline that satisfies the boundary conditions {{of the problem is}} used as an reference trajectory. The reference trajectory is parameterized by total maneuver time which also serves as an optimization parameter. Dynamic inversion is used to calculate the control required for tracking the reference trajectory. However, perfect tracking is not possible because of actuator saturation and <b>noise.</b> Therefore a <b>tracker</b> is implemented to set reasonable error-dynamics between the commanded and achieved trajectories. An optimization problem is posed to achieve the desired trade-off between the total time and final state-error. The performance of the algorithm is evaluated by comparing the generated trajectories with benchmark solutions obtained from a Chebyshev based pseudo-spectral optimization method. Nomenclature A Non-dimensional damping matrix C Matrix of controller parameters (damping) e Non-dimensional error vector K Matrix of controller parameters (stiffness) P Matrix appearing in the EOM g Function of the reference trajectory J Cost function t Non-dimensional time u Non-dimensional voltage input to motor x Non-dimensional displacement of vehicle c. g. along the x-axis y Non-dimensional displacement of vehicle c. g. along the y-axi...|$|R
40|$|This report {{documents}} {{the integration of}} machine vision into the minifactory environment. Minifactory is an automated factory system being developed at the Microdynamic Systems Laboratory at Carnegie Mellon University and is aimed toward the assembly of small mechatronic devices. Machine vision can aid assembly systems by {{eliminating the need for}} complicated part holding jigs, end effectors, and part feeding equipment. In addition, the position accuracy of a visually servoed robot can be made relatively insensitive to robot calibration errors. By using the visual control and communications systems described in this report, two high-precision 2 -DOF robotic agents were visually guided to precisely align parts of a sub-assembly. Test results show that open-loop look-and-move alignment of parts took an average of 3. 7 iterations and 3. 6 seconds while visual servoing alignment took an average of 1. 3 seconds. The standard deviation of the visual servoing alignment errors for the u and v axes were 4. 6 mand 5 m respectively. However, they were limited by <b>tracker</b> <b>noise</b> which was approximately 10 m peak to peak {{with a standard deviation of}} 2 mintheu axis of the image plane and 20 m peak to peak with a standard deviation of 6 minthev axis. Overall, the vision project’s greatest success was making two 2 -DOF agents transiently cooperate to function as a single 4 -DOF robot to perform visual servoing tasks...|$|R

