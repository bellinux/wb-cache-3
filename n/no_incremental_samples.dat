0|305|Public
40|$|<b>Incremental</b> <b>sampling</b> {{methodology}} (ISM) is {{a structured}} composite sampling and processing protocol having specific elements {{designed to reduce}} data variability and increase sample representativeness for a specified volume of soil under investigation. Variability in measured contaminant concentrations between discrete soil samples is due primarily to the particulat...|$|R
30|$|IRS: The <b>incremental</b> random <b>sampling</b> {{algorithm}} {{shown in}} algorithm 2.|$|R
30|$|Possible feature {{reduction}} {{techniques are}} {{techniques such as}} principle components, heuristic feature selection with wrapper method and feature selection with decision trees. Examples for case reduction techniques are <b>incremental</b> <b>samples,</b> average samples, increasing the sampling period and strategic sampling of key events. For value reduction prominent techniques are rounding, using k-means clustering and discretization using entropy minimization.|$|R
40|$|Effectiveness and {{side-effects}} of high- versus low-dose neuroleptic {{treatment of}} chronic psychosis have been assessed through a meta-analysis of 22 published randomized control trials comparing different neuroleptic doses. <b>No</b> <b>incremental</b> clinical improvement {{was found at}} doses above 375 mg equivalent of chlorpromazine, while {{a significant increase in}} adverse reactions was observe...|$|R
50|$|There {{seems to}} be <b>no</b> <b>incremental</b> {{development}} in phonology patterns. Monolingual children learning the language have shown acquisition of aspiration and deobstruentization but difficulty with sibilants and affricates, and other children show the reverse. Also, some children have been observed fronting palatoalveolars, others retract lamino-alveolars, and still others retract both.|$|R
40|$|Sampling {{can be a}} {{significant}} source of error in the measurement process. The characterization and cleanup of hazardous waste sites require data that meet site-specific levels of acceptable quality if scientifically supportable decisions are to be made. In support of this effort, the US Environmental Protection Agency (EPA) is investigating methods that relate sample characteristics to analytical performance. Predicted uncertainty levels allow appropriate study design decisions to be made, facilitating more timely and less expensive evaluations. Gy sampling theory can predict {{a significant}} fraction of sampling error when certain conditions are met. We report on several controlled studies of subsampling procedures to evaluate the utility of Gy sampling theory applied to laboratory subsampling practices. Several sample types were studied and both analyte and non-analyte containing particles were shown to play important roles affecting the measured uncertainty. Gy sampling theory was useful in predicting minimum uncertainty levels provided the theoretical assumptions were met. Predicted fundamental errors ranged from 46 to 68 % of the total measurement variability. The study results also showed sectorial splitting outperformed <b>incremental</b> <b>sampling</b> for simple model systems and suggested that sectorial splitters divide each size fraction independently. Under the limited conditions tested in this study, <b>incremental</b> <b>sampling</b> with a spatul...|$|R
40|$|Abstract. The Hammersley and Halton point sets, two {{well known}} low {{discrepancy}} sequences, {{have been used}} for quasi-Monte Carlo integration in previous research. A deterministic formula generates a uniformly distributed and stochastic-looking sampling pattern, at low computational cost. The Halton point set is also useful for <b>incremental</b> <b>sampling.</b> In this paper, we discuss detailed implementation issues and our experience of choosing suitable bases of the point sets, not just on the 2 D plane, but also on a spherical surface. The sampling scheme is also applied to ray tracing, with a significant improvement in error. ...|$|R
40|$|The forward-greedy {{algorithm}} {{based on}} the neighborhood rough set is a simple and effective method for the attribute reduction. However, it is non-incremental reduction method, which limits its application in the dynamic decision system. In this article, an improved incremental attribute reduction algorithm is proposed by introducing concept of the relative positive region, which can update the original reduction set quickly and handle both the incremental attributes and the <b>incremental</b> <b>samples.</b> Finally, the correctness and effectiveness of the proposed algorithm are demonstrated by examples and experiments on 5 standard data sets from UCI...|$|R
2500|$|Desalinated {{water can}} be {{produced}} in open- or hybrid-cycle plants using surface condensers to turn evaporated seawater into potable water. System analysis indicates that a 2-megawatt plant could produce about [...] of desalinated water each day. Another system patented by Richard Bailey creates condensate water by regulating deep ocean water flow through surface condensers correlating with fluctuating dew-point temperatures. This condensation system uses <b>no</b> <b>incremental</b> energy and has no moving parts.|$|R
40|$|Many {{people take}} photos and videos with {{smartphones}} {{and more recently}} with 360 -degree cameras at popular places and events, and share them in social media. Such visual content is produced in large volumes in urban areas, {{and it is a}} source of information that online users could exploit to learn what has got the interest of the general public {{on the streets of the}} cities where they live or plan to visit. A key step to providing users with that information is to identify the most popular k spots in specified areas. In this paper, we propose a clustering and <b>incremental</b> <b>sampling</b> (C&IS) approach that trades off accuracy of top-k results for detection speed. It uses clustering to determine areas with high density of visual content, and <b>incremental</b> <b>sampling,</b> controlled by stopping criteria, to limit the amount of computational work. It leverages spatial metadata, which represent the scenes in the visual content, to rapidly detect the hotspots, and uses a recently proposed Gaussian probability model to describe the capture intention distribution in the query area. We evaluate the approach with metadata, derived from a non-synthetic, user-generated dataset, for regular mobile and 360 -degree visual content. Our results show that the C&IS approach offers 2. 8 x- 19 x reductions in processing time over an optimized baseline, while in most cases correctly identifying 4 out of 5 top locations...|$|R
40|$|In {{this study}} we {{evaluate}} the performance of actively managed equity mutual funds against a set of passively managed index funds. We find that the return spread between the best performing actively managed funds and a factor-mimicking portfolio of passive funds is positive and as large as 3 to 5 percent per annum. Our findings are inconsistent with the view that active funds have little or <b>no</b> <b>incremental</b> economic value over low-cost index funds...|$|R
40|$|ObjectivesThis study {{sought to}} {{evaluate}} the efficacy of beta-blockers (BBs) for primary prevention of heart failure (HF) in patients with hypertension. BackgroundThe American College of Cardiology/American Heart Association staging for HF classifies patients with hypertension as stage A HF, for which BBs are a treatment option. However, the evidence to support this is unknown. MethodsWe conducted a MEDLINE/EMBASE/CENTRAL search of randomized controlled trials that evaluated BB as first-line therapy for hypertension with follow-up for at least 1 year and with data on new-onset HF. The primary outcome was new-onset HF. Secondary outcomes were all-cause mortality, cardiovascular mortality, myocardial infarction, and stroke. ResultsAmong the 12 randomized controlled trials, which evaluated 112, 177 patients with hypertension, BBs reduced blood pressure by 12. 6 / 6. 1 mm Hg when compared with placebo, resulting in a 23 % (trend) reduction in HF risk (p = 0. 055). When compared with other agents, the antihypertensive efficacy of BBs was comparable, which resulted in similar but <b>no</b> <b>incremental</b> benefit for HF risk reduction in the overall cohort (risk ratio: 1. 00; 95 % confidence interval: 0. 92 to 1. 08), in the elderly (≥ 60 years) or in the young (< 60 years). Analyses of secondary outcomes showed that BBs confirmed similar but <b>no</b> <b>incremental</b> benefit for the outcomes of all-cause mortality, cardiovascular mortality, and myocardial infarction but increased stroke risk by 19 % in the elderly. ConclusionsIn hypertensive patients, primary prevention of HF {{is strongly dependent on}} blood pressure reduction. When compared with other antihypertensive agents, there was similar but <b>no</b> <b>incremental</b> benefit of BBs for the prevention of HF. However, given the increased risk of stroke in the elderly, BBs should not be considered as first-line agents for prevention of HF...|$|R
40|$|Abstract — This paper studies a {{class of}} approach-evasion {{differential}} games, in which one player aims to steer the state of a dynamic system to the given target set in minimum time, while avoiding some set of disallowed states, and the other player desires to achieve the opposite. We propose {{a class of}} novel anytime computation algorithms, analyze their convergence properties and verify their performance via a number of numerical simulations. Our algorithms significantly outperform the multi-grid method for the approach-evasion differential games both theoretically and numerically. Our technical approach leverages <b>incremental</b> <b>sampling</b> in robotic motion planning and viability theory. I...|$|R
50|$|First Component. RAD's first {{component}} {{governs the}} conversion of assistance under section 9 of the Act (i.e., public housing funding) to PBRA or PBV assistance. The language authorizing RAD caps public housing conversions at 225,000 units nationwide. PHAs wishing to convert under this component must go through a selection process. There is <b>no</b> <b>incremental</b> funding tied to these conversions; instead, PHAs convert their public housing funding to PBRA or PBV assistance at approximately their current funding levels.|$|R
40|$|The {{heterogeneous}} three-dimensional {{spatial distribution}} of mycotoxins {{has proven to be}} one of the main limitations for the design of effective sampling protocols. Current sample collection protocols for mycotoxins have been designed to estimate the mean concentration and fail to characterise the {{spatial distribution of}} the mycotoxin concentration due to the aggregation of the <b>incremental</b> <b>samples.</b> Geostatistical techniques have been successfully applied to overcome similar problems in many research areas. However, little work has been developed on the use of geostatistics for the design of sampling protocols for mycotoxins. This paper focuses on the analysis of the two and three-dimensional spatial structure of fumonisins B 1 (FB 1) and B 2 (FB 2) in maize in a bulk store using a geostatistical approach and on how results help determine the number and location of <b>incremental</b> <b>samples</b> to be collected. The spatial correlation between FB 1 and FB 2, as well as between the number of kernels infected and the level of contamination was investigated. For this purpose, a bed of maize was sampled at different depths to generate a unique three-dimensional data set of FB 1 and FB 2. The analysis found no clear evidence of spatial structure in either the two- dimensional or three-dimensional analyses. The number of Fusarium infected kernels was not a good indicator for the prediction of fumonisin concentration and there was no spatial correlation between the concentrations of the two fumonisins...|$|R
30|$|Algorithm 2 {{shows the}} {{procedure}} of <b>incremental</b> <b>sampling.</b> Firstly, we reuse the previous structure SW_i- 1 (Line 4). Then tuples, which {{are beyond the}} range of current window, are removed from SW_i (Line 6). Function remove_head is used to remove the first item in SW_i.indexarr and update SW_i.sh depending on how many tuples are removed. Then we use a temporary structure T_SW to store the indexes of newly sampled tuples {{in the range from}} SW_i.indexarr[SW_i.st] to W_i.t (Line 9 – 11). Next, we append the indexes in T_SW.indexarr to SW_i and update SW_i.st (Line 12). Finally, we aggregate the tuples in SW_i to estimate the final result (Line 13 – 14).|$|R
40|$|This paper {{examines}} the time-series relations among expected return, risk, and book-to-market (B/M) at the portfolio level. I find that B/M predicts economically and statistically significant time-variation in expected stock returns. Further, B/M is {{strongly associated with}} changes in risk, {{as measured by the}} Fama and French (1993) (Journal of Financial Economics, 33, 3 [...] 56) three-factor model. After controlling for risk, B/M provides <b>no</b> <b>incremental</b> information about expected returns. The evidence suggests that the three-factor model explains time-varying expected returns better than a characteristics-based model...|$|R
40|$|Previous {{research}} {{finds the}} volatility implied by S&P 100 index option prices to be a biased and inefficient forecast of future volatility and to contain little or <b>no</b> <b>incremental</b> information beyond that in past realized volatility. In contrast, {{we find that}} implied volatility outperforms past volatility in forecasting future volatility and even subsumes the information content of past volatility in some of our specifications. Our results differ from previous studies because we use longer time series and nonoverlapping data. A regime shift around the October 1987 crash explains why implied volatility is mor...|$|R
40|$|We {{study the}} dynamic {{relation}} between market risks and risk premia using time series of index option surfaces. We find that priced left tail risk cannot be spanned by market volatility (and its components) and {{introduce a new}} tail factor. This tail factor has <b>no</b> <b>incremental</b> predictive power for future volatility and jump risks, beyond current and past volatility, but is critical in predicting future market equity and variance risk premia. Our findings suggest a wide wedge between the dynamics of market risks and their compensation, with the latter typically display...|$|R
30|$|For many drug therapies, {{there is}} little {{knowledge}} about the ultimate distribution patterns of the compounds within tissue compartments following treatment. It is possible to label drugs with a tracer and follow their uptake using technologies such as positron-emission tomography (PET) and autoradiography. For both of these methods the physical manipulation of the compound by the labeling could change {{the properties of the}} compound. Over the last decade a method to identify unlabeled drugs in tissue has been under development using MALDI-MSI. With MALDI-MSI continual <b>incremental</b> <b>sampling</b> can be performed upon tissue taken directly from the body to identify cellular locations that contain the specific drug ion signatures of the compound in question [21].|$|R
40|$|Abstract — In this paper, the {{filtering}} {{problem for}} a large class of continuous-time, continuous-state stochastic dynam-ical systems is considered. Inspired by recent advances in asymptotically-optimal sampling-based motion planning algo-rithms, such as the PRM ∗ and the RRT∗, an incremen-tal sampling-based algorithm is proposed. Using <b>incremental</b> <b>sampling,</b> this approach constructs a sequence of Markov chain approximations, and solves the filtering problem, in an incremental manner, on these discrete approximations. It is shown that the trajectories of the Markov chain approximations converge in distribution to the trajectories of the original stochastic system; moreover, the optimal filter calculated on these Markov chains converges to the optimal continuous-time nonlinear filter. The convergence results are verified {{in a number of}} simulation examples. I...|$|R
2500|$|A 2001 {{review of}} the medical {{research}} conducted by the Public Health Agency of Canada {{concluded that there was}} no link between MMR vaccine and either inflammatory bowel disease or autism. The review noted, [...] "An increase in cases of autism was noted by year of birth from 1979 to 1992; however, <b>no</b> <b>incremental</b> increase in cases was observed after the introduction of MMR vaccination." [...] After the introduction of MMR, [...] "A time trend analysis found no correlation between prevalence of MMR vaccination and the incidence of autism in each birth cohort from 1988 to 1993." ...|$|R
40|$|Consistent with {{findings}} in other markets, implied volatility is a biased predictor of the realized {{volatility of gold}} futures. No existing explanation—including a price of volatility risk—can completely explain the bias, but much of this apparent bias {{can be explained by}} persistence and estimation error in implied volatility. Statistical criteria reject the hypothesis that implied volatility is informationally efficient with respect to econometric forecasts. But delta hedging exercises indicate that such econometric forecasts have <b>no</b> <b>incremental</b> economic value. Thus, statistical measures of bias and information efficiency are misleading measures of the information content of option prices. Gold; Futures; Forecasting...|$|R
40|$|This article {{proposes that}} subword paraiielism [...] prallel {{computation}} on lower precisicm data packed into a word [...] is an {{efficient and effective}} solution for accelerat- ing media processing. As an example, t describes MAX- 2, a very lean. RISCdike et of media acceleration primitives included in the 64 -bit PA-R 1 SC 2. 0 architecture. Because MAX- 2 strives 1 o be a minhnal set of instree~ dons, the article dbcusses both instructions included and excluded. Several examples filustrate the use of MAX- 2 instructions, which provide subword paralleiism in a word oriented general-purpose processor at essentially <b>no</b> <b>incremental</b> cos...|$|R
40|$|The informational {{content in}} live cattle and hog {{deferred}} futures prices is assessed using a direct test of incremental forecast ability for two- to twelve-month horizons. For 1976 - 2007, {{the results indicate}} that hog futures prices add incremental information at all horizons, but unique information in live cattle prices declines quickly beyond the eight-month horizon with <b>no</b> <b>incremental</b> information at the twelve-month horizon. The contrast in performance is likely attributable to differences in the quality of public information {{and the nature of the}} production process. forecast evaluation, forecast information, futures markets, Demand and Price Analysis, Risk and Uncertainty,...|$|R
50|$|Peer-to-Peer Assisted Streaming Solution {{refers to}} {{peer-to-peer}} (P2P) software applications designed to redistribute video streams {{in real time}} on a P2P network; the distributed video streams are typically TV channels {{from all over the}} world but may also come from other sources. The draw to these applications is significant because they have the potential to make any TV channel globally available by any individual feeding the stream into the network where each peer joining to watch the video is a relay to other peer viewers, allowing a scalable distribution among a large audience with <b>no</b> <b>incremental</b> cost for the source.|$|R
5000|$|A 2001 {{review of}} the medical {{research}} conducted by the Public Health Agency of Canada {{concluded that there was}} no link between MMR vaccine and either inflammatory bowel disease or autism. The review noted, [...] "An increase in cases of autism was noted by year of birth from 1979 to 1992; however, <b>no</b> <b>incremental</b> increase in cases was observed after the introduction of MMR vaccination." [...] After the introduction of MMR, [...] "A time trend analysis found no correlation between prevalence of MMR vaccination and the incidence of autism in each birth cohort from 1988 to 1993." ...|$|R
40|$|Queries {{over large}} scale (petabyte) data bases often mean waiting {{overnight}} for a result to come back. Scale costs time. Such time {{also means that}} potential avenues of exploration are ignored because the costs {{are perceived to be}} too high to run or even propose them. With sampleAction we have explored whether interaction techniques to present query results running over only <b>incremental</b> <b>samples</b> can be presented as sufficiently trustworthy for analysts both to make closer to real time decisions about their queries and to be more exploratory in their questions of the data. Our work with three teams of analysts suggests that we can indeed accelerate and open up the query process with such incremental visualizations. Author Keywords Incremental visualizations, large data, exploratory dat...|$|R
40|$|Knowing {{whether or}} not a company is {{financial}} stable has always been a top concern for analysts and money managers. This paper compares the effectiveness of default prediction using two different types of measures: accounting and market based. Accounting measures have been the most popular even though, according to theory, a market based measure reflects all available information. Theory goes as far to say that accounting measures can add <b>no</b> <b>incremental</b> value to a market based measure. In my research I found that accounting based measures can be effective in their predictive power; the market-based measure (BSM) results were much more difficult to estimate within the limits of this research project...|$|R
40|$|We use isotopic {{analyses}} of authigenic siderite and calcite cements within Rosselia socialis burrows from shoreface deposits in the Upper Cretaceous Horseshoe Canyon Formation of Alberta, Canada, to re-veal the early cementation {{history of the}} burrow and geochemical conditions of the initial sedimentary environment. Within the Horse-shoe Canyon Formation, two forms of the Rosselia burrows are pres-ent: bulbous in situ burrows, and transported, spindlelike burrows, which display similar internal shaft diameters but smaller overall size compared to in situ forms. Transverse, <b>incremental</b> <b>sampling</b> of cal-cite and siderite cements in the Rosselia burrows reveals symmetrical isotopic deviation in 13 C and 18 O around the burrow core, rep-resenting accretionary records of evolving pore-water conditions. The number of isotopic deviations recorded in bulbous specimens is equal to those observed in spindle-shaped burrows, suggesting that in sit...|$|R
40|$|In this paper, the {{filtering}} {{problem for}} a large class of continuous-time, continuous-state stochastic dynamical systems is considered. Inspired by recent advances in asymptotically-optimal sampling-based motion planning algorithms, such as the PRM* and the RRT*, an incremental sampling-based algorithm is proposed. Using <b>incremental</b> <b>sampling,</b> this approach constructs a sequence of Markov chain approximations, and solves the filtering problem, in an incremental manner, on these discrete approximations. It is shown that the trajectories of the Markov chain approximations converge in distribution to the trajectories of the original stochastic system; moreover, the optimal filter calculated on these Markov chains converges to the optimal continuous-time nonlinear filter. The convergence results are verified {{in a number of}} simulation examples. United States. Army Research Office. Multidisciplinary University Research Initiative (Grant W 911 NF- 11 - 1 - 0046...|$|R
40|$|This paper {{focuses on}} a continuous-time, continuous-space {{formulation}} of the stochastic optimal control problem with nonlinear dynamics and observation noise. We lay the mathematical foundations to construct, via <b>incremental</b> <b>sampling,</b> an approximating sequence of discrete-time finite-state partially observable Markov decision processes (POMDPs), such that the behavior of successive approximations converges to {{the behavior of the}} original continuous system in an appropriate sense. We also show that the optimal cost function and control policies for these POMDP approximations converge almost surely to their counterparts for the underlying continuous system in the limit. We demonstrate this approach on two popular continuous-time problems, viz., the Linear-Quadratic-Gaussian (LQG) control problem and the light-dark domain problem. United States. Army Research Office. Multidisciplinary University Research Initiative (Grant W 911 NF- 11 - 1 - 0046...|$|R
40|$|The aim of {{this paper}} was to update the {{sampling}} plan for analysis of mycotoxins in grains, formerly published by the author. The proposed alterations were based on the acquired experience on its application and on FAO recommendations. This update restricts the scope of the former plan and establishes a sampling plan for analysis of aflatoxin in peanuts and corn, by means of modified formulas, the minimum number of sacks or points (when in bulk) from which <b>incremental</b> <b>samples</b> should be drawn to make a bulk sample. Fractional exponents (square roots) of the formulas proportionally decrease the number of sacks/points to be sampled as the lot size increases. Operating Characteristic (OC) curves developed for in-shell and shelled peanuts and corn as well as trend curves of the coefficient variation for different sample sizes (weights) are presented...|$|R
40|$|Abstract. A {{recent study}} shows that industry-specific {{analysis}} has <b>no</b> <b>incremental</b> advantage over economy-wide analysis in forecasting firm profitability. This result seems puzzling because some earlier studies have documented the importance of industry effects in explaining firm profitability. We reconcile the apparent inconsistency by showing that industry effects on profitability forecasting exist at the more refined business segment level, but are obscured by aggregated reporting at the firm level. Using segment-level analysis as well as firm-level analysis that also utilizes segment-level information, we provide consistent evidence supporting that industry-specific analysis is more accurate than economy-wide analysis in predicting the profitability of business segments and the profitability of single-segment firms. (JEL L 25, G 17, M 21, M 41...|$|R
40|$|This article {{analyzes}} the intraday interdependence of order flows and price movements for actively traded NYSE stocks and their Chicago Board Options Exchange (CBOE) -traded options. Stock net trade volume (buyer-initiated volume minus seller-initiated volume) has strong predictive ability for stock and option quote revisions, but option net trade volume has <b>no</b> <b>incremental</b> predictive ability. This suggests that informed investors initiate trades {{in the stock}} market but not in the option market. On the other hand, both stock and option quote revisions have predictive ability for each other. Thus, while information {{in the stock market}} is contained in both quote revisions and trades, information in the option market is contained only in quote revisions...|$|R
40|$|We present {{procedures}} for selecting the best or near-best of {{a finite number}} of simulated systems when best is defined by maximum or minimum expected performance. The procedures are appropriate when it is possible to repeatedly obtain small, <b>incremental</b> <b>samples</b> from each simulated system. The goal of such a sequential procedure is to eliminate, at an early stage of experimentation, those simulated systems that are clearly inferior, and thereby reduce the overall computational effort required to find the best. The procedures we present accommodate unequal variances across systems and the use of common random numbers. However, they are based on the assumption of normally distributed data, so we analyze the impact of batching (to achieve approximate normality or independence) on the performance of the procedures. Comparisons with existing procedures are also provided. Key Words: Output Analysis; Multiple Comparisons; Ranking and Selection; Variance Reduction 1 Introduction In a series of [...] ...|$|R
