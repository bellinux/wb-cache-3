7|10000|Public
40|$|Connectionist {{modeling}} experiments tested anomalous-face and baby-face overgeneralization hypotheses {{proposed to}} explain consensual trait impressions of faces. Activation of a <b>neural</b> <b>network</b> <b>unit</b> trained {{to respond to}} anomalous faces predicted impressions of normal adult faces varying in attractiveness {{as well as several}} elderly stereotypes. Activation of a <b>neural</b> <b>network</b> <b>unit</b> trained to respond to babies’ faces predicted impressions of adults varying in babyfaceness as well as 1 elderly stereotype. Thus, similarities of normal adult faces to anomalous faces or babies ’ faces contribute to impressions of them quite apart from knowledge of overlapping social stereotypes. The evolutionary importance of appropriate responses to unfit individuals or babies is presumed to produce a strong response preparedness that is overgeneralized to faces resembling the unfit or babies. We are enjoined not to judge a book by its cover, and we are cautioned that beauty is only skin deep. These warnings suggest that our natural proclivity is in fact to judge people by their appearance and to prefe...|$|E
40|$|In {{this paper}} we present {{optoelectronic}} measurement system for monitoring the industrial gas pollutants. The system {{consists of a}} source of light, an optical fiber as a data transmission link, a spectrometer, an optical detection system and a <b>neural</b> <b>network</b> <b>unit</b> for a real-time spectral data processing. We have paid the major attention to the neural network structure and its properties in gas recognition and gas concentration estimation...|$|E
40|$|AbstractIn this paper, {{based on}} the deeper {{analysis}} {{of the features of}} fuzzy logic and approximate reasoning, the concept of approximate case-based reasoning (ACBR) is introduced. According to the inference mechanism of ACBR, an implementation on neural networks is proposed. Mapping the implication relation between the premise(s) and the consequence of a fuzzy rule to the weight of a corresponding <b>neural</b> <b>network</b> <b>unit,</b> an approximate case-based reasoning on neural networks can be realized. The self-organizing and self-learning procedure can be executed by modifying the weight...|$|E
40|$|This paper {{proposes a}} {{bootstrap}} artificial <b>neural</b> <b>network</b> based panel <b>unit</b> root test in a dynamic heterogeneous panel context. An application to {{a panel of}} bilateral real exchange rate series with the US Dollar from the 20 major OECD countries is provided to investigate the Purchase Power Parity (PPP). The combination of <b>neural</b> <b>network</b> and bootstrapping significantly changes {{the findings of the}} economic study in favour of PPP. Artificial <b>neural</b> <b>network,</b> panel <b>unit</b> root test, bootstrap, Monte Carlo experiments, exchange rates. ...|$|R
40|$|MicroRNAs (miRNAs) {{have been}} shown to be {{promising}} biomarkers in predicting cancer prognosis. However, inappropriate or poorly optimized processing and modeling of miRNA expression data can negatively affect prediction performance. Here, we propose a holistic solution for miRNA biomarker selection and prediction model building. This work introduces the use of a <b>neural</b> <b>network</b> cascade, a cascaded constitution of small artificial <b>neural</b> <b>network</b> <b>units,</b> for evaluating miRNA expression and patient outcome. A miRNA microarray dataset of nasopharyngeal carcinoma was retrieved from Gene Expression Omnibus to illustrate the methodology. Results indicated a nonlinear relationship between miRNA expression and patient death risk, implying that direct comparison of expression values is inappropriate. However, this method performs transformation of miRNA expression values into a miRNA score, which linearly measures death risk. Spearman correlation was calculated between miRNA scores and survival status for each miRNA. Finally, a nine-miRNA signature was optimized to predict death risk after nasopharyngeal carcinoma by establishing a <b>neural</b> <b>network</b> cascade consisting of 13 artificial <b>neural</b> <b>network</b> <b>units.</b> Area under the ROC was 0. 951 for the internal validation set and had a prediction accuracy of 83 % for the external validation set. In particular, the established <b>neural</b> <b>network</b> cascade was found to have strong immunity against noise interference that disturbs miRNA expression values. This study provides an efficient and easy-to-use method that aims to maximize clinical application of miRNAs in prognostic risk assessment of patients with cancer...|$|R
40|$|This paper {{describes}} {{an attempt to}} devise a knowledge discovery model that is inspired from the two theoretical frameworks of selectionism and constructivism in human cognitive learning. The “selectionist ” nature of human decision making indicates {{the use of an}} evolutionary paradigm for composing rudimentary <b>neural</b> <b>network</b> <b>units,</b> while the “constructivist ” component takes the form of neural weight training during the learning process. We explore the possibility of amalgamating these two ideas into a neural learning system for the discovery of meaningful rules in the context of pattern discovery in data. 1...|$|R
40|$|In {{order to}} improve speech naturalness of a unit {{selection}} TTS system {{it is necessary to}} annotate prosodic phrase boundaries in the whole source corpus, which is extremely difficult to achieve manually. It is thus usefull to employ a machine classifier. This paper discusses suitable feature selection for such classification of a Czech TTS corpus, presents results of experiments with linear and quadratic classifiers and artificial neural networks, and compares them with human annotators. Index Terms: speech synthesis, prosody, prosodic phrase, classification, <b>neural</b> <b>network,</b> <b>unit</b> selection, corpu...|$|E
40|$|DC motors {{are widely}} used in {{industry}} such as mechanics, robotics, and aerospace engineering. In this paper, we present a high performance control method for position control of DC motors. Fault-tolerant control model are also addressed to combine with neuro-robust control approach. It is shown that with the proposed control algorithms, external disturbances and coupled dynamics inherent in the system are effectively compensated using <b>neural</b> <b>network</b> <b>unit</b> in which no analytical estimation on the upper bound of the reconstruction error and uncertainties is needed. Simulations on various flight conditions also confirm {{the effectiveness of the}} proposed methods...|$|E
40|$|This study {{concerns}} with {{the dynamics of}} a quantum <b>neural</b> <b>network</b> <b>unit</b> {{in order to examine}} the suitability of simple neural computing tasks. More specifically, we examine the dynamics of an interacting spin model chosen as a candidate of a quantum perceptron for closed and open quantum systems. We adopt a collisional model enables examining both Markovian and non-Markovian dynamics of the proposed quantum system. We show that our quantum neural network (QNN) unit has a stable output quantum state in contact with an environment carrying information content. By the performed numerical simulations one can compare the dynamics in the presence and absence of quantum memory effects. We find that our QNN unit is suitable for implementing general neural computing tasks in contact with a Markovian information environment and quantum memory effects cause complications on the stability of the output state. Comment: 10 Pages, 4 Figure...|$|E
5000|$|Pulse {{computation}} {{is primarily}} studied {{as part of}} the field of <b>neural</b> <b>networks.</b> The processing <b>unit</b> in such a network is called a [...] "neuron".|$|R
40|$|This paper {{presents}} and investigates a <b>neural</b> <b>network</b> structure which can perform general fuzzy inference. This system {{consists of a}} number of parallel <b>neural</b> <b>network</b> <b>units</b> which are called ""flexible inference cells"" (FICs). Each FIC implements a single-input/single-output (SISO) IF-THEN rule of a fuzzy knowledge base. The assumption of SISO fuzzy rules allows the implementation of any complex fuzzy inference algorithm (for control or other decision making purposes), since any MIMO (multi-input/multi-output) rule can be decomposed into an equivalent set of MISO (multi-input/single-output) rules, and a MISO rule can be decomposed to a set of SISO rules. The paper discusses the assumptions and requirements for the proposed neurofuzzy structure, and classifies the FICs into four categories. Some results derived by simulation using 3125 exemplar patterns produced computationally are provided...|$|R
40|$|This paper {{describes}} a novel control architecture for autonomous robots, called "Cerebellar Adaptive Modular Behavior" (CAMB). A CAMB controller is a dynamical system of behavior-oriented modules, similar {{in principle to}} the subsumption architecture. The behavior of the robot is emergent from the interaction of these modules. <b>Neural</b> <b>network</b> <b>units</b> (based on the CMAC) are added to allow the discovery of some control parameters from the environment and to suppress unproductive behaviors. The application of CAMB to the control of a simulated mobile robot is described. The robot is able to quickly adapt itself to its environment, performing simple search and obstacle avoidance strategies successfully in order to traverse its environment towards a target point. Keywords: Autonomous robots, Emergent behavior, Subsumption architecture, CMAC <b>neural</b> <b>network.</b> 1 Introduction Autonomous robots which can survive in unstructured environments without continuous human guidance are difficult [...] ...|$|R
40|$|The {{window unit}} {{in the design of}} the complex {{logarithmic}} r-¿ mapping for hybrid optical neural network filter can allow multiple objects of the same class to be detected within the input image. Additionally, the architecture of the <b>neural</b> <b>network</b> <b>unit</b> of the complex logarithmic r-¿ mapping for hybrid optical neural network filter becomes attractive for accommodating the recognition of multiple objects of different classes within the input image by modifying the output layer of the unit. We test the overall filter for multiple objects of the same and of different classes' recognition within cluttered input images and video sequences of cluttered scenes. Logarithmic r-¿ mapping for hybrid optical neural network filter is shown to exhibit with a single pass over the input data simultaneously in-plane rotation, out-of-plane rotation, scale, log r-¿ map translation and shift invariance, and good clutter tolerance by recognizing correctly the different objects within the cluttered scenes. We record in our results additional extracted information from the cluttered scenes about the objects' relative position, scale and in-plane rotation. © 2009 SPIE...|$|E
40|$|Abstract. In this article, a <b>neural</b> <b>network</b> {{document}} classifier with linguistic {{feature selection}} and multi-category output is presented. It {{consists of a}} feature selection unit and a hierarchical <b>neural</b> <b>network</b> classification <b>unit.</b> In feature selection unit, we extract terms from some original documents by text processing, and then we analyze the conformity and uniformity of each term by entropy function which is characterized to measure the significance of term. Terms with high significance will be selected as input features for <b>neural</b> <b>network</b> document classifiers. In {{order to reduce the}} input dimension, we perform a mechanism to merge synonyms. According to the uniformity analysis, we obtain a term similarity matrix by fuzzy relation operation. By this method, we can construct a synonym thesaurus to reduce input dimension. In the hierarchical <b>neural</b> <b>network</b> classification <b>unit,</b> we adopt the well-known back-propagation learning model to build some proper hierarchical classification units. In our experiments, a product description database from an electronic commercial company is employed. The experimental results show that this classifier achieves sufficient accuracy to help human classification. It can save much manpower and working time for classifying a large database. ...|$|R
40|$|In this paper, {{we build}} upon {{previous}} results {{to show that}} our facial expression recognition system, an extremely simple <b>neural</b> <b>network</b> containing six <b>units,</b> trained by backpropagation, is a surprisingly good computational model that obtains a natural #t to human data from experiments that utilize a forced-choice classi #cation paradigm. The model begins by computing a biologically plausible representation of its input, which is a static image of an actor portraying a prototypical expression of either Happiness, Sadness, Fear, Anger, Surprise, Disgust, or Neutrality. This representation of the input {{is fed to a}} single-layer <b>neural</b> <b>network</b> containing six <b>units,</b> one for each non-neutral facial expression...|$|R
50|$|In summary, {{the basic}} {{components}} of a <b>neural</b> <b>network</b> are the <b>units,</b> the connections between the units, the weights, and the thresholds. So, in order to fully simulate an artificial <b>neural</b> <b>network</b> one must somehow encode these components in a linear chromosome and {{then be able to}} express them in a meaningful way.|$|R
40|$|Application {{of modern}} {{computational}} methods {{for the analysis}} of right censored follow-up data is subject of this thesis. Major question is the prognosic quality of statistical methods in comparison to artificial <b>neural</b> <b>networks.</b> Analyses were performed using Kaplan-Meier estimates, classification and regression trees, Cox proportional hazards regression and artificial <b>neural</b> <b>networks</b> with two <b>units</b> in the hidden layer and artificial <b>neural</b> <b>networks</b> with ten <b>units</b> in the hidden layer. In a first step the four methods were compared using simulated data. In a second step data from the German Malignant Melanom Registry of the German Dermatological Society were analyzed with minor differences in prognosic quality for the different methods. The results demonstrate that the used artifical <b>neural</b> <b>networks</b> can not replace statistical methods {{for the analysis of}} censored follow-up data. In future, artificial <b>neural</b> <b>networks</b> may be used for quality check of statistical methods...|$|R
40|$|For transmembrane {{proteins}} {{experimental determination}} of three-dimensional structure is problematic. However, membrane proteins have important impact for molecular biology in general, and for drug design in particular. Thus, prediction method are needed. Here we introduce {{a method that}} started from {{the output of the}} profile-based <b>neural</b> <b>network</b> system PHDhtm (Rost, et al. 1995). Instead of choosing the <b>neural</b> <b>network</b> output <b>unit</b> with maximal value as prediction, we implemented a dynamic programming-like refinement procedure that aimed at producing the best model for all transmembrane helices compatible with the <b>neural</b> <b>network</b> output. The refined prediction was used successfully to predict transmembrane topolog...|$|R
5000|$|He {{proposed}} landmark theoretical {{formulations of}} neural activity and generative processes that influenced diverse {{fields such as}} cognitive sciences and psychology, philosophy, neurosciences, computer science, artificial <b>neural</b> <b>networks,</b> cybernetics and artificial intelligence, together with {{what has come to}} be known as the generative sciences. He is best remembered for having written along with Warren McCulloch, a seminal paper entitled [...] "A Logical Calculus of Ideas Immanent in Nervous Activity" [...] (1943). This paper proposed the first mathematical model of a <b>neural</b> <b>network.</b> The <b>unit</b> of this model, a simple formalized neuron, is still the standard of reference in the field of <b>neural</b> <b>networks.</b> It is often called a McCulloch-Pitts neuron.|$|R
40|$|A {{board is}} {{described}} {{that contains the}} ANN A neural-network chip, and a DSP 32 C digital signal processor. The ANNA (Analog <b>Neural</b> <b>Network</b> Arithmetic <b>unit)</b> chip performs mixed analog/digital processing. The combination of ANNA with the DSP allows high-speed, end-to-end ex-ecution of numerous signal-processing applications, including the prepro-cessing, the neural-net calculations, and the postprocessing steps. The ANNA board evaluates <b>neural</b> <b>networks</b> 10 to 100 {{times faster than the}} DSP alone. The board is suitable for implementing large (million con-nections) networks with sparse weight matrices. Three applications have been implemented on the board: a convolver network for slant detection of text blocks, a handwritten digit recognizer, and a <b>neural</b> <b>network</b> for recognition-based segmentation. ...|$|R
40|$|ABSTRACT This paper {{describes}} {{a new model}} for an artificial <b>neural</b> <b>network</b> processing <b>unit</b> or neuron. It is slightly different to a traditional feedforward network {{by the fact that}} it favours a mechanism of trying to match the wave-like ‘shape’ of the input with the shape of the output against specific value error corrections. The expectation is then that a best fit shape can be transposed into the desired output values more easily. This allows for notions of reinforcement through resonance and also the construction of synapses...|$|R
40|$|Recurrent <b>neural</b> <b>networks</b> of analog <b>units</b> are {{computers}} for realvalued functions. We study the time complexity of real computation in general recurrent <b>neural</b> <b>networks.</b> These have sigmoidal, linear, and product units of unlimited order as nodes and no {{restrictions on the}} weights. For networks operating in discrete time, we exhibit a family of functions with arbitrarily high complexity, and we derive almost tight bounds on {{the time required to}} compute these functions. Thus, evidence is given of the computational limitations that time-bounded analog recurrent <b>neural</b> <b>networks</b> are subject to...|$|R
40|$|A {{synchronous}} Hopfield [...] type <b>neural</b> <b>network</b> model containing <b>units</b> with analog inputand binary output, {{which is}} suitable for parallel implementation, is examined inthe context of solving discrete optimization problems. A hybrid parallel update schemeconcerning the stochastic input-output behaviour of each unit is presented. This parallelupdate scheme maintains the solution quality of the Boltzmann Machine optimizer, whichis inherently sequential. Experimental results o...|$|R
40|$|This paper {{sketches}} {{a hypothetical}} cortical architecture for visual 3 D object recognition {{based on a}} recent computational model. The view-centered scheme relies on modules for learning from examples, such as Hyperbf-like networks. Such models capture a class of explanations we call Memory-Based Models (MBM) that contains sparse population coding, memory-based recognition, and codebooks of prototypes. Unlike the sigmoidal units of some artificial <b>neural</b> <b>networks,</b> the <b>units</b> of MBMs {{are consistent with the}} description of cortical neurons. We describe how an example of MBM may be realized in terms of cortical circuitry and biophysical mechanisms, consistent with psychophysical and physiological data...|$|R
40|$|We {{describe}} {{an application of}} an encoder-decoder recurrent <b>neural</b> <b>network</b> with LSTM <b>units</b> and attention to generating headlines from the text of news articles. We find that the model is quite effective at concisely paraphrasing news articles. Furthermore, we study how the <b>neural</b> <b>network</b> decides which input words to pay attention to, and specifically we identify {{the function of the}} different neurons in a simplified attention mechanism. Interestingly, our simplified attention mechanism performs better that the more complex attention mechanism on a held out set of articles...|$|R
40|$|We {{propose a}} Spatial Artificial <b>Neural</b> <b>Network</b> (SANN) with spatial {{architecture}} {{which consists of}} a multilayer feedforward <b>neural</b> <b>network</b> with hidden <b>units</b> adopt recurrent lateral inhibition connection, all input and hidden neurons have synapses connections with the output neurons. In addition, a supervised learning algorithm based on error back propagation is developed. The proposed network has shown a superior generalization capability in simulations with pattern recognition and non-linear function approximation problems. And, the experimental also shown that SANN has the capability of avoiding local minima problem...|$|R
40|$|Even though sequence-to-sequence neural machine {{translation}} (NMT) model have achieved state-of-art performance in the recent fewer years, but it is widely concerned that the recurrent <b>neural</b> <b>network</b> (RNN) <b>units</b> are very hard to capture the long-distance state information, which means RNN can hardly find the feature with long term dependency as the sequence becomes longer. Similarly, convolutional <b>neural</b> <b>network</b> (CNN) is introduced into NMT for speeding recently, however, CNN focus on capturing the local feature of the sequence; To relieve this issue, we incorporate a relation network into the standard encoder-decoder framework to enhance information-propogation in <b>neural</b> <b>network,</b> ensuring that the information of the source sentence can flow into the decoder adequately. Experiments show that proposed framework outperforms the statistical MT model and the state-of-art NMT model significantly on two data sets with different scales. Comment: i am planned to improve my experiments and modified our pape...|$|R
40|$|International audienceWe {{consider}} sequential {{decision making}} in the case where a generative model and a parametric policy are available. Such a framework is naturally tackled with Direct Policy Search, i. e. parametric op-timisation over simulations. We propose a simple method that combines this parametric policy with a more generic <b>neural</b> <b>network,</b> where all parameters are trained simultaneously. As such, our approach doesn't require any computational overhead. We show that the resulting policy significantly outperforms both the domain specific policies and the <b>neural</b> <b>network</b> on a <b>unit</b> commitment test problem...|$|R
40|$|This paper {{proposes a}} novel <b>neural</b> <b>network</b> method for {{sequential}} detection. We first examine the optimal parametric Sequential Probability Ratio Test (SPRT) {{and make a}} simple equivalent transformation of the SPRT that makes it suitable for <b>neural</b> <b>network</b> architectures. We then discuss how <b>neural</b> <b>networks</b> can learn the SPRT decision functions from observation data and labels. Conventional supervised learning algorithms have difficulties handling the variable length observation sequences, but a reinforcement learning algorithm, the Temporal Difference (TD) learning algorithm works ideally in training the <b>neural</b> <b>network.</b> The entire <b>neural</b> <b>network</b> is composed of context units followed by a feedforward <b>neural</b> <b>network.</b> The context <b>units</b> are necessary to store dynamic information {{that is needed to}} make good decisions. For an appropriate <b>neural</b> <b>network</b> architecture, trained with iid observations by the TD learning algorithm, we show that the <b>neural</b> <b>network</b> sequential detector can c [...] ...|$|R
40|$|The {{objective}} of the present work is to explore the non-linear relationship between money and inflation in Colombia through an artificial <b>neural</b> <b>network</b> using monthly information for the variation of {{the consumer price index}} and the monetary aggregate M 3 since January 1982 through February 2005. Artificial <b>neural</b> <b>networks</b> turn up as an excellent alternative for monetary authorities to count on the best models to forecast inflation and guide their policy decisions. This article incorporates some innovations in money and inflation modeling that allow to generate more reliable forecasts given that the model approximates reality with greater accuracyartificial <b>neural</b> <b>network,</b> non-linearity, hidden <b>unit,</b> activation function, rolling test, asymmetric lost function. ...|$|R
40|$|Product units {{provide a}} method of {{automatically}} learning the higher-order input combinations required for the efficient synthesis of Boolean logic functions by <b>neural</b> <b>networks.</b> Product <b>units</b> also have a higher information capacity than sigmoidal networks. However, this activation function has not received much attention in the literature. A possible {{reason for this is}} that one encounters some problems when using standard backpropagation to train <b>networks</b> containing these <b>units.</b> This report examines these problems, and evaluates the performance of three training algorithms on networks of this type. Empirical results indicate that the error surface of <b>networks</b> containing product <b>units</b> have more local minima than corresponding <b>networks</b> with summation <b>units.</b> For this reason, a combination of local and global training algorithms were found to provide the most reliable convergence. We then investigate how `hints' can be added to the training algorithm. By extracting a common frequency from t [...] ...|$|R
40|$|Many novel {{techniques}} for reconstructing rainfall-runoff processes require hydrometeorologic and geomorphologic information for modelling. However, certain {{information is not}} always measurable. In this paper, we employ a special recurrent <b>neural</b> <b>network</b> to reconstruct the rainfall-runoff process by using collected rainfall data. In addition, we propose an indirect system identification to overcome the drawback of a traditional, time-consuming trial-and-error search. The indirect system identification is an efficient method to recognize {{the structure of a}} recurrent <b>neural</b> <b>network.</b> The <b>unit</b> hydrograph can be derived directly from the weights of the network due to a state-space form embedded in the recurrent <b>neural</b> <b>network.</b> This improves the link between the weights of the network and the physical concepts that most <b>neural</b> <b>networks</b> fail to connect. The case studies of 41 events from 1966 to 1997 have been implemented in Taiwan’s Wu-Tu watershed, where the runoff path-lines are short and steep. Two recurrent <b>neural</b> <b>networks</b> and one state-space model are utilized to simulate the rainfall-runoff processes for comparison. The results are validated by four criteria: coefficient of efficiency; peak discharge error; time to peak arrival error; total discharge volume error. The resulting data from the recurrent <b>neural</b> <b>network</b> reveal that the <b>neural</b> <b>network</b> proposed herein is appropriate for hydrological systems. Copyright © 2005 John Wiley & Sons, Ltd. KEY WORDS recurrent neural network; system identification; state space; rainfall-runoff process; unit hydrograp...|$|R
40|$|Real Time Strategy Games {{are one of}} {{the most}} popular game schemes in PC markets and offer a dynamic {{environment}} that involves several interacting agents. The core strategies that need to be developed in these games are unit micro management, building order, resource management, and the game main tactic. Unfortunately, current games only use scripted and fixed behaviors for their artificial intelligence (AI), and the player can easily learn the counter measures to defeat the AI. In this paper, we describe a system based on <b>neural</b> <b>networks</b> that controls a set of units of the same type in the popular game StarCraft. Using the <b>neural</b> <b>networks,</b> the <b>units</b> will either choose a unit to attack or evade from the battlefield. The system uses reinforcement learning combined with <b>neural</b> <b>networks</b> using online Sarsa and neural-fitted Sarsa, both with a short term memory reward function. We also present an incremental learning method for training the units for larger scenarios involving more <b>units</b> using trained <b>neural</b> <b>networks</b> on smaller scenarios. Additionally, we developed a novel sensing system to feed the environment data to the <b>neural</b> <b>networks</b> using separate vision grids. The simulation results show superior performance against the human-made AI scripts in StarCraft...|$|R
40|$|Abstract | We survey {{learning}} algorithms for recurrent <b>neural</b> <b>networks</b> {{with hidden}} <b>units,</b> {{and put the}} various techniques into a common framework. We discuss xedpoint learning algorithms, namely recurrent backpropagation and deterministic Boltzmann Machines, and non- xedpoint algorithms, namely backpropagation through time, Elman's history cuto, and Jordan's output feedback architecture. Forward propagation, an online technique that uses adjoint equations, and variations thereof, are also discussed. In many cases, the uni ed presentation leads to generalizations of various sorts. We discuss {{advantages and disadvantages of}} temporally continuous <b>neural</b> <b>networks</b> in contrast to clocked ones, continue with some of the trade" for training, using, and simulating continuous time and recurrent <b>neural</b> <b>networks.</b> We present somesimulations, and at the end, address issues of computational complexity and learning speed...|$|R
40|$|Deep Belief Networks (DBN) are {{generative}} {{models with}} {{many layers of}} hidden causal variables, recently introduced by Hinton et al. (2006), along with a greedy layer-wise unsupervised learning algorithm. Building on Le Roux and Bengio (2008) and Sutskever and Hinton (2008), we show that deep but narrow generative networks do not require more parameters than shallow ones to achieve universal approximation. Exploiting the proof technique, we prove that deep but narrow feed-forward <b>neural</b> <b>networks</b> with sigmoidal <b>units</b> can represent any Boolean expression...|$|R
40|$|We {{study the}} number of hidden layers {{required}} by a multilayer <b>neural</b> <b>network</b> with threshold <b>units</b> to compute a dichotomy f from R d to f 0; 1 g, defined by a finite set of hyperplanes. We show that this question is far more intricate than computing Boolean functions, although this well-known problem is underlying our research. We present recent advances on the characterization of dichotomies, from R 2 to f 0; 1 g, which require two hidden layers to be exactly realized...|$|R
