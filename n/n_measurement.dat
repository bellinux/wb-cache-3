45|1470|Public
3000|$|... where y is the {{observed}} vector, x is an s-sparse vector (contains at most s non-zero elements) and Φ is an m×n (m ≪ <b>n)</b> <b>measurement</b> matrix which {{in our case}} is the partial DFT matrix formed by selecting N [...]...|$|E
3000|$|... 3 - analysis). Total N and P were {{determined}} after a UV/per sulphate destruction. Concentrations of total N and P in sediment {{were determined}} on a segmented flow analyser after destruction with sulphuric acid/salicylic acid/ selenium/ hydrogen peroxide, with total <b>N</b> <b>measurement</b> {{based on the}} Berthelot reaction and total P measured as phosphate molybdenum (Novozamsky et al. 1983; Novozamsky et al. 1984).|$|E
30|$|It is {{attractive}} that CS is also applicable to images with sparse or compressible coefficients in the transform domain since y {{can be written}} as y= ΦΨ x, in which ΦΨ {{can be seen as}} M × <b>N</b> <b>measurement</b> matrix. In the sequel, without generality loss we shall focus on the images, sparse or compressible in the pixel domain. However, in our experiments of Section 4, we shall also consider the images, compressible in wavelet domain.|$|E
5000|$|Given {{a set of}} <b>N</b> <b>measurements</b> [...] {{the mean}} value of z is defined as: ...|$|R
5000|$|The {{sample mean}} {{of a set}} of <b>N</b> <b>measurements</b> [...] drawn from a {{circular}} uniform distribution is defined as: ...|$|R
5000|$|Method 1: average the <b>n</b> <b>measurements</b> of T, {{use that}} mean in Eq(2) {{to obtain the}} final g estimate; ...|$|R
3000|$|... and K ≪ N. Consider also an M × <b>N</b> <b>measurement</b> matrix Φ, M ≪ N, {{where the}} rows of Φ are {{incoherent}} with the columns of Λ. Incoherency between rows of the measurement matrix and the basis vectors means that we need all of the vectors in the second set to expand each of the vectors in the first set and vice versa. CS theory states that only m (m) is of O(K·log(N)) incoherent measurements y = Φx, are required to reconstruct the signal, x, with a high probability.|$|E
40|$|Pulsed IVanalysis {{allows the}} {{development}} of more accurate nonlinear models for RF and microwave device operation. An analysis ofpulsedlV waveforms allows better exploitation of measurement capabilities to produce accurate results. Static and anamic IV measurement waveforms produced by a commercially available pulsedIV analyzer are examined. Because transistors can become unstable during any ype, of <b>N</b> <b>measurement,</b> the use of bias tees allows a frequency-dependent impedance to be presented. However, it is shown that care must be used when using bias tees in pulsed IV measurement to choose a bias tee with an inductor time constant significantly higher than the pulsing ffequency but significantly lower than the ffeguency at which oscillations develop. I...|$|E
40|$|Compressed sensing {{is a novel}} {{technique}} {{where one}} can recover sparse signals from the undersampled measurements. In this correspondence, a K × <b>N</b> <b>measurement</b> matrix for compressed sensing is deterministically constructed via additive character sequences. The Weil bound is then used {{to show that the}} matrix has asymptotically optimal coherence for N=K^ 2, and to present a sufficient condition on the sparsity level for unique sparse recovery. Also, the restricted isometry property (RIP) is statistically studied for the deterministic matrix. Using additive character sequences with small alphabets, the compressed sensing matrix can be efficiently implemented by linear feedback shift registers. Numerical results show that the deterministic compressed sensing matrix guarantees reliable matching pursuit recovery performance for both noiseless and noisy measurements...|$|E
25|$|The main {{advantage}} of the information filter is that <b>N</b> <b>measurements</b> can be filtered at each timestep simply by summing their information matrices and vectors.|$|R
3000|$|Since [...] rank(H)< m, {{at least}} <b>n</b> <b>measurements</b> are {{required}} to extract the optimal state estimation and [...] n-m [...] measurement units {{should be used to}} enhance resilience against errors.|$|R
3000|$|N) [7]. If {{there are}} K out of <b>N</b> <b>measurements</b> within the local {{neighbourhood}} window for the ordinary Kriging interpolation, the computational time {{complexity of the}} Kriging method is O(M [...]...|$|R
40|$|A generic {{tool for}} {{analyzing}} sparse approximation algorithms is the restricted isometry property (RIP) introduced by Candès and Tao (2005) [11]. If R(k, n, N) is the RIP constant with support size k for an n × <b>N</b> <b>measurement</b> matrix, we investigate {{the trend of}} reducing the support size of the RIP constants for qualitative comparisons between sufficient conditions. For example, which condition is easier to satisfy, R (4 k, n, N) R (2 k, n, N) < 0. 025 ? Using a quantitative comparison via phase transitions for Gaussian measurement matrices, three examples from the literature of such support size reduction are considered. In each case, utilizing a larger support size for the RIP constants results in a sufficient condition for exact sparse recovery that is satisfied by a significantly larger subset of Gaussian matrices...|$|E
40|$|The {{extraction}} {{of information from}} a quantum system unavoidably implies a modification of the measured system itself. It has been demonstrated recently that partial measurements {{can be carried out}} in order to extract only a portion of the information encoded in a quantum system, at the cost of inducing a limited amount of disturbance. Here we analyze experimentally the dynamics of sequential partial measurements carried out on a quantum system, focusing on the trade-off between the maximal information extractable and the disturbance. In particular we consider two different regimes of measurement, demonstrating that, by exploiting an adaptive strategy, an optimal trade-off between the two quantities can be found, as observed in a single measurement process. Such experimental result, achieved for two sequential measurements, can be extended to <b>N</b> <b>measurement</b> processes. Comment: 5 pages, 3 figure...|$|E
40|$|Let A {{be a real}} M × <b>N</b> <b>measurement</b> matrix and b∈R^M be an {{observations}} vector. The affine feasibility {{problem with}} sparsity and nonnegativity (AFP_SN for short) {{is to find a}} sparse and nonnegative vector x∈R^N with Ax=b if such x exists. In this paper, we focus on establishment of optimization approach to solving the AFP_SN. By discussing tangent cone and normal cone of sparse constraint, we give the first necessary optimality conditions, α-Stability, T-Stability and N-Stability, and the second necessary and sufficient optimality conditions for the related minimization problems with the AFP_SN. By adopting Armijo-type stepsize rule, we present a framework of gradient support projection algorithm for the AFP_SN and prove its full convergence when matrix A is s-regular. By doing some numerical experiments, we show the excellent performance of the new algorithm for the AFP_SN without and with noise...|$|E
5000|$|A {{series of}} <b>N</b> <b>measurements</b> [...] {{drawn from a}} wrapped Cauchy {{distribution}} {{may be used to}} estimate certain parameters of the distribution. The average of the series [...] is defined as ...|$|R
3000|$|<b>N</b> <b>measurements</b> {{associated}} with it (i.e. it is not consistent enough with the data). This value is set by noting that {{the average number of}} measurements generated by each target is P [...]...|$|R
5000|$|A {{series of}} <b>N</b> <b>measurements</b> [...] {{drawn from a}} von Mises {{distribution}} {{may be used to}} estimate certain parameters of the distribution. (Borradaile, 2003) The average of the series [...] is defined as ...|$|R
40|$|Graduation date: 2006 Four {{aspects of}} factors {{influencing}} {{the accuracy of}} nondestructive chlorophyll (Chl) and nitrogen (<b>N)</b> <b>measurement</b> in fresh leaves were studied: (1) optimum wavelength (OW) identification; (2) indices development and evaluation; (3) influence of leaf properties; and (4) influence of meter parameters and sampling technique. Results were used to develop indices and prototype meters for Chl and N assessment. Our {{results indicated that the}} simple linear coefficient of determination (R 2) between spectral reflectance or transmission and Chl or N in combination with spectral sensitivity was the most reliable method for determining the OW for Chl and <b>N</b> <b>measurement</b> in fresh leaves. There were two ranges of wavelengths, one in visible region (550 - 580 nm) and the other in the red edge region (700 - 730 nm), we determined that had the highest spectral sensitivity and largest R 2 with smallest root mean square error over a wide-range of Chl concentrations (160 – 1188 µmol. m- 2), and could be used as the OW to develop indices for Chl and N assessment. The OW in the red edge region could be used for Chl assessment across all species tested and the OW in the visible region could be used across anthocyanins-free species. The best indices were the indices developed with the Chl-related OW either from visible or red edge region in combination with a reference wavelength (RW) from the near infrared (NIR) region (750 – 1100 nm) that was sensitive to leaf texture but insensitive to Chl as the form of a simple ratio (RRW/ROW) or normalized difference vegetation index (RRW – ROW) /(RRW + ROW). With RW, the differences in reflectance in the visible and red edge regions caused by variation in leaf texture or other optical properties could be eliminated. This was particularly important when the R 2 of a single-wavelength index was small for Chl or <b>N</b> <b>measurement</b> (e. g. R 2 < 0. 8000 for Chl or R 2 < 0. 6000 for N). Parameters used by hand-held Chl meters (CCM- 200, SPAD- 502, and CM- 1000) affected their accuracy for Chl and N assessment. Our results showed that SPAD- 502 was more accurate than CCM- 200 and CM- 1000 for assessing Chl and N in fresh leaves. The Chl-sensitive wavelength used by CM- 1000 (700 nm) was more accurate for estimating Chl than the wavelengths used by SPAD- 502 (650 nm) and CCM- 200 (660 nm); however, we found that variation in sampling distance, orientation, light intensity, and the inconsistency of light intensity between ambient light sensor and the target leaf made the CM- 1000 less accurate than the other two meters. Using the indices and OW determined through our research, we developed three prototype meters that were more accurate than or similar to the commercial hand-held meters in measuring Chl or N in fresh leaves. Among them, the prototype-III was more accurate than all the commercial hand-held meters for Chl and than the CM- 1000 for N assessments across all the species we tested...|$|E
40|$|We {{present a}} new method for {{describing}} quantum measurements in relativistic systems that applies (i) to any QFT and for any field-detector coupling, (ii) to {{the measurement of}} any observable, and (iii) to arbitrary size, shape and motion of the detector. We explicitly construct the probabilities associated to <b>n</b> <b>measurement</b> events, while treating the spacetime coordinates of the events are random variables. These probabilities define a linear functional of a 2 n unequal time correlation function of the field, and thus, they are Poincaré covariant. The probability assignment depends on {{the properties of the}} measurement apparatuses, their state of motion, intrinsics dynamics, initial states and couplings to the measured field. For each apparatus, this information is contained in a function, the detector kernel, that enters into the probability assignment. In a companion paper, we construct the detector kernel for different types of measurement. Comment: 29 page...|$|E
40|$|Consider {{the noisy}} underdetermined system of linear equations: y=Ax 0 + z 0, with n x <b>N</b> <b>measurement</b> matrix A, n (δ). The phase {{boundary}} ρ = (δ) {{is identical to}} the previously-known phase transition curve for equivalence of l 1 - l 0 minimization in the k-sparse noiseless case. Hence a single phase boundary describes the fundamental phase transitions both for the noiseless and noisy cases. Extensive computational experiments validate the predictions of this formalism, including the existence of game theoretical structures underlying it. Underlying our formalism is the AMP algorithm introduced earlier by the authors. Other papers by the authors detail expressions for the formal MSE of AMP and its close connection to l 1 -penalized reconstruction. Here we derive the minimax formal MSE of AMP and then read out results for l 1 -penalized reconstruction. Comment: 40 pages, 13 pdf figure...|$|E
40|$|AbstractSuppose that n {{points are}} located at n {{mutually}} distinct but unknown {{positions on the}} line, and we can measure their pairwise distances. How many measurements are needed to determine their relative positions uniquely? The problem is motivated by DNA mapping techniques based on pairwise distance measures. It is also interesting by itself for its own and surprisingly deep. Continuing our earlier work on this problem, we give a simple randomized two-round strategy that needs, with high probability, only (1 +o(1)) <b>n</b> <b>measurements.</b> We show that deterministic strategies cannot manage the task in two rounds with (1 +o(1)) <b>n</b> <b>measurements</b> in the worst case. We improve an earlier deterministic bound to roughly 4 n/ 3 measurements...|$|R
40|$|Compressive sensing aims {{to recover}} a high-dimensional sparse signal from a {{relatively}} small number of measurements. In this paper, a novel design of the measurement matrix is proposed. The design is inspired by the construction of generalized low-density parity-check codes, where the capacity-achieving point-to-point codes serve as subcodes to robustly estimate the signal support. In the case that each entry of the n-dimensional k-sparse signal lies in a known discrete alphabet, the proposed scheme requires only O(k <b>n)</b> <b>measurements</b> and arithmetic operations. In the case of arbitrary, possibly continuous alphabet, an error propagation graph is proposed to characterize the residual estimation error. With O(k ^ 2 <b>n)</b> <b>measurements</b> and computational complexity, the reconstruction error can be made arbitrarily small with high probability. Comment: accepted to ICASSP 201...|$|R
5000|$|If we have {{a series}} of <b>n</b> <b>measurements</b> of X and Y written as xi and yi for i = 1, 2, ..., n, then the sample {{correlation}} coefficient can be used to estimate the population Pearson correlation r between X and Y. The sample correlation coefficient is written as ...|$|R
40|$|New {{algorithms}} for {{correlation analysis}} are presented {{that allow the}} mapping of brain activity from functional MRI (fMRI) data in real time during the ongoing scan. They combine the computation of the correlation coefficients between measured fMRI time-series data and a reference vector with “detrending,” a technique for the suppression of non-stimulus-related signal components, and the “sliding-window technique. ” Using this technique, which limits the correlation computation to the last <b>N</b> <b>measurement</b> time points, the sensitivity to changes in brain activity is maintained throughout the whole experiment. For increased sensitivity in activation detection a fast and robust optimization of the reference vector is proposed, which takes into account a realistic model of the hemodynamic response function to adapt the parameterized reference vector to the measured data. Based on the described correlation method, real-time fMRI experiments using visual stimulation paradigms have been performed successfully on a clinical MR scanner, which was linked to an external workstation for image analysis...|$|E
40|$|Abstract—Force sensors provide {{critical}} information about robot manip-ulators, manufacturing processes, and haptic interfaces. Commercial force sensors, however, {{are generally not}} adapted to specific system requirements, resulting in sensors with excess size, cost, and fragility. To overcome these issues, 3 -D printers {{can be used to}} create components for the quick and inexpensive development of force sensors. Limitations of this rapid proto-typing technology, however, require specialized design principles. In this paper, we discuss techniques for rapidly developing simple force sensors, including selecting and attaching metal flexures, using inexpensive and sim-ple displacement transducers, and 3 -D printing features to aid in assembly. These design methods are illustrated through the design and fabrication of a miniature force sensor for the tip of a robotic catheter system. The resulting force sensor prototype can measure forces with an accuracy of as low as 2 % of the 10 <b>N</b> <b>measurement</b> range. Index Terms—Force sensors, rapid prototyping, sensor design. I...|$|E
40|$|Abstract We derive a {{generalized}} Bell inequality for N qubits which involves an arbitrary number of settings {{for each of}} the local measuring apparatuses. The inequality forms a necessary condition for the existence of a local realistic model for the values of a correlation function, given in a n-setting Bell experiment. We show that a local realistic model for the values of a correlation function, given in a two-setting Bell experiment, cannot construct a local realistic model for the values of a correlation function, given in an arbitrary number of n-setting Bell experiment, even though there exist two-setting models for the <b>n</b> <b>measurement</b> directions chosen in the given n-setting experiment. Therefore, the property of two-setting model is different from the property of n-setting model. We discuss classification of local realistic theories in further detail more than the result presented in (J. Phys. A: Math. Theor. 41 : 155308, 2008). The generalized Bell inequality covers the previous results correctly...|$|E
3000|$|Finally, for {{practical}} implementation, {{it is necessary}} to analyse also the computational complexity of compared RF-REM construction methods. If there are <b>N</b> <b>measurements</b> available in a given time moment and M RF-REM locations for estimating signal levels, the computational time complexity of the IDW and IDW 2 methods is O(M [...]...|$|R
50|$|Recently, it {{was shown}} that the {{principles}} of 'Compressed-Sensing' can be directly utilized {{to reduce the number}} of measurements required for image reconstruction in ghost imaging. This technique allows an N pixel image to be produced with far less than <b>N</b> <b>measurements</b> and may have applications in LIDAR and microscopy.|$|R
5000|$|Over {{the time}} {{interval}} to be averaged across, <b>n</b> <b>measurements</b> of wind direction (θ) {{will be made}} and two totals are accumulated without storage of the n individual values. At {{the end of the}} interval the calculations are as follows: with the average values of sin θ and cos θ defined as ...|$|R
40|$|Compressive sensing is {{a method}} for {{acquiring}} high dimensional signals (e. g., images) using {{a small number of}} linear measurements. Consider an n-pixel image x ∈ R[superscript n], where each pixel p has value x[subscript p]. The image is acquired by computing the measurement vector Ax, where A is an m x <b>n</b> <b>measurement</b> matrix, for some m << n. The goal is to design the matrix A and the recovery algorithm which, given Ax, returns an approximation to x. It is known that m=O(k log(n/k)) measurements suffices to recover the k-sparse approximation of x. Unfortunately, this result uses matrices A that are random. Such matrices are difficult to implement in physical devices. In this paper we propose compressive sensing schemes that use matrices A that achieve the near-optimal bound of m=O(k log n), while being highly "local". We also show impossibility results for stronger notions of locality. Charles Stark Draper LaboratoryNational Science Foundation (U. S.) (Award NSF CCF- 1012042) David & Lucile Packard Foundatio...|$|E
40|$|Consider {{the noisy}} underdetermined system of linear equations: y = Ax 0 + z 0, with n × <b>N</b> <b>measurement</b> matrix A, n ρMSE(δ). The phase {{boundary}} ρ = ρMSE(δ) {{is identical to}} the previously-known phase transition curve for equivalence of ` 1 − ` 0 minimization in the k-sparse noiseless case. Hence a single phase boundary describes the fundamental phase transitions both for the noiseless and noisy cases. Extensive computational experiments validate the predictions of this formalism, including the existence of game theoretical structures underlying it (saddlepoints in the payoff, least-favorable signals and maximin penalization). Underlying our formalism is an approximate message passing soft thresholding algorithm (AMP) introduced earlier by the authors. Other papers by the authors detail expressions for the formal MSE of AMP and its close connection to ` 1 -penalized reconstruction. Here we derive the minimax formal MSE of AMP and then read out results for ` 1 -penalized reconstruction...|$|E
40|$|Abstract. We {{consider}} {{the problem of}} recovering a block (or group) sparse signal from an underdetermined set of random linear measurements, which appear in compressed sensing applica-tions such as radar and imaging. Recent results of Donoho, Johnstone, and Montanari have shown that approximate message passing (AMP) in combination with Stein’s shrinkage outperforms group LASSO for large block sizes. In this paper, we prove that, for a fixed block size and in the strong undersampling regime (i. e., having very few measurements compared to the ambient dimension), AMP cannot improve upon group LASSO, thereby complementing the results of Donoho et al. Key words. Group sparsity; group LASSO; approximate message passing; phase transition 1. Introduction. The field of compressed sensing (CS) aims to recover a sparse signal from an undetermined systems of linear equations. Concretely, CS can be modeled as y = Ax, where y is the n-dimensional measurement vector, A is the (typically random) n × <b>N</b> <b>measurement</b> matrix, and x is an N dimensional vector with at most k nonzero entries (often referred to as k-sparse vector). Our goal is t...|$|E
40|$|A {{problem of}} {{allocation}} of measurements for a linear calibration process is considered in this article. It {{is assumed that}} a total of <b>N</b> <b>measurements</b> are made {{some of which may}} be measurements on two distinct standards, while the remaining measurements are on m different unknown specimens. We discuss allocation of the <b>N</b> <b>measurements</b> for the two standards and m unknown specimens based on A-optimality criterion, which is applied to asymptotic variances of maximum likelihood estimators for the true values of unknown specimens. It can be shown that the optimal allocation depends on the true values of unknown specimens. Hence, the user may resort to locally or Bayesian A-optimal measurement designs. Some practical solution is presented. Furthermore, the impact of prior on the allocation is also discussed. Copyright Springer-Verlag 2005 Calibration model, A-optimality criterion, measurement design, Bayesian design,...|$|R
2500|$|... {{constitutes}} the model, where F is the independent variable. To estimate the force constant, k, {{a series of}} <b>n</b> <b>measurements</b> with different forces will produce a set of data, , where yi is a measured spring extension. Each experimental observation will contain some error. [...] If we denote this error , we may specify an empirical model for our observations, ...|$|R
40|$|We {{consider}} {{the impact of}} two recent pi- p [...] >eta <b>n</b> <b>measurements</b> on the etaN scattering length and etaN branching fractions for the N(1535) and N(1520) resonances within a coupled-channel analysis of piN elastic scattering and etaN production data. The sensitivity of these results to model input is also explored. Comment: 11 pages, 5 figure...|$|R
