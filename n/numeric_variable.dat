33|214|Public
5000|$|Example: Assuming that [...] is a <b>numeric</b> <b>variable,</b> the {{assignment}} [...] {{means that the}} content of the variable [...] is doubled after the execution of the statement.|$|E
5000|$|... {{creates a}} loop where the <b>numeric</b> <b>variable</b> (num) runs from start number to end number in {{increments}} of number (STEP). If step is omitted, 1 is assumed ...|$|E
5000|$|Numeric {{variables}} {{have only}} one type, a binary floating point implementation. Each <b>numeric</b> <b>variable</b> consumes 5 bytes of memory and {{can be in the}} range from -1E+38 up to 1E+37 ...|$|E
2500|$|R-Psychologist [...] {{visualization}} of correlation between two <b>numeric</b> <b>variables</b> ...|$|R
40|$|In SAS ® {{everyone}} knows about missing values for character and <b>numeric</b> <b>variables</b> {{and some people}} know about special missing values {{that allow you to}} have more than one meaning for a missing value on <b>numeric</b> <b>variables.</b> What about character variables? Can we mimic the same behaviour? This paper will look at special missing values and a technique to achieve the same results for character variables using non-printable hex codes...|$|R
50|$|A {{selection}} of other datatypes for <b>numeric</b> <b>variables</b> would include:binary_float, binary_double, dec, decimal, double precision, float, integer, int, numeric, real, smallint, binary_integer.|$|R
50|$|In computing, signedness is a {{property}} of data types representing numbers in computer programs. A <b>numeric</b> <b>variable</b> is signed {{if it can}} represent {{both positive and negative}} numbers, and unsigned if it can only represent non-negative numbers (zero or positive numbers).|$|E
5000|$|Accessors {{conversely}} {{allow for}} synthesis of useful data representations from internal variables while keeping their structure encapsulated and hidden from outside modules. A monetary [...] accessor may build a string from a <b>numeric</b> <b>variable</b> {{with the number}} of decimal places defined by a hidden [...] parameter.|$|E
5000|$|R:Next line {{of input}} replaces current {{contents}} of accept buffer A: R:Next line of input replaces accept buffer, and string variable 'FREE' A:$FREE R:Next 3 lines of input assigned to string variables 'X', 'Y' and 'Z' A:$X,$Y,$Z R:Numeric input assigned to <b>numeric</b> <b>variable</b> [...] "Q" [...] A:#Q ...|$|E
30|$|The {{categorical}} variables were summarized by numbers and percentages and the <b>numeric</b> <b>variables,</b> by their mean ± SD (standard deviation). Differences in patients’ demographics were compared across the subgroups using the Chi square test or Fisher’s exact test for {{categorical variables}} and the independent t test or the Mann–Whitney U test for <b>numeric</b> <b>variables,</b> as appropriate. Correlations were tested using the non-parametric Spearman’s rank correlation coefficient. p values < 0.05 were considered significant. All {{statistical analyses were performed}} using SPSS 21.0 (SPSS, Inc., Chicago, IL, USA).|$|R
50|$|SQR {{has four}} scalar data types. The first three are <b>numeric</b> (<b>variables</b> begin with “#”), {{character}} string (variables begin with “$”), and date (variables begin with “$”, same as with character string variables.). Date variables must be declared, to {{be distinguished from}} character string variables. There is the option to declare <b>numeric</b> <b>variables</b> to specify them more precisely (integer, floating point, etc.). The last data type is a database column (variables begin with “&”). The values of database columns are set only by a SQL “select” statement; no other command can change their values.|$|R
5000|$|<b>Numeric</b> <b>variables</b> of {{the form}} [...] "A" [...] or [...] "An" [...] (where A is a single letter and n a single, {{optional}} digit) stored as 32-bit floating-point numbers ...|$|R
50|$|Color BASIC understands {{one type}} of <b>numeric</b> <b>variable</b> and string variables. Variable names in Color BASIC have the first two {{characters}} significant. The first character of the variable name must be a letter. The second can be either a letter or number. String variables are indicated by adding a dollar sign ($) after the variable name.|$|E
5000|$|To {{define a}} <b>numeric</b> <b>variable,</b> the {{programmer}} appends the variable type NUMBER {{to the name}} definition.To specify the (optional) precision (P) and the (optional) scale (S), one can further append these in round brackets, separated by a comma. ("Precision" [...] in this context refers {{to the number of}} digits the variable can hold, and [...] "scale" [...] refers to the number of digits that can follow the decimal point.) ...|$|E
50|$|In computing, in {{particular}} compiler construction, value range analysis {{is a type}} of data flow analysis that tracks the range (interval) of values that a <b>numeric</b> <b>variable</b> can take on at each point of a program's execution.The resulting information can be used in optimizations such as redundancy elimination, dead code elimination, instruction selection, etc., but {{can also be used to}} improve the safety of programs, e.g. in the detection of buffer overruns. Techniques for value range analysis typically use symbolic analysis extensively.|$|E
50|$|XOR {{can be used}} to swap two <b>numeric</b> <b>variables</b> in computers, {{using the}} XOR swap algorithm; however this is {{regarded}} as more of a curiosity and not encouraged in practice.|$|R
30|$|Descriptive {{analysis}} of frequency was employed for categorical variables, expressed as absolute frequency and percentages, whereas measures of central tendency {{were used for}} <b>numeric</b> <b>variables.</b> The Chi-square test or Fisher's exact test (for expected values[*]<[*] 5) {{was used to compare}} categorical variables, the Mann-Whitney test employed to compare <b>numeric</b> <b>variables</b> between two groups, and the Kruskal-Wallis for comparisons of three or more groups. Prevalence ratios of frailty and pre-frailty were explored using multivariate and univariate Poisson regression analysis with Stepwise selection criteria. The level of significance adopted for the statistical tests was 5  %, i.e. p[*]<[*] 0.05.|$|R
50|$|MARS {{can handle}} both {{continuous}} and categorical data. MARS {{tends to be}} better than recursive partitioning for numeric data because hinges are more appropriate for <b>numeric</b> <b>variables</b> than the piecewise constant segmentation used by recursive partitioning.|$|R
50|$|This {{extension}} of PDDL2.1 from around 2002-2006 {{provides a more}} flexible model of continuous change {{through the use of}} autonomous processes and events.The key this extension provides is the ability to model the interaction between the agent's behaviour and changes that are initiated by the agent's environment. Processes run over time and have a continuous effect on numeric values. They are initiated and terminated either by the direct action of the agent or by events triggered in the environment. This 3-part structure {{is referred to as the}} start-process-stop model. Distinctions are made between logical and numeric states: transitions between logical states are assumed to be instantaneous whilst occupation of a given logical state can endure over time. Thus in PDDL+ continuous update expressions are restricted to occur only in process effects. Actions and events, which are instantaneous, are restricted to the expression of discrete change. This introduces the before mentioned 3-part modelling of periods of continuous change: (1) an action or event starts a period of continuous change on a <b>numeric</b> <b>variable</b> expressed by means of a process; (2) the process realizes the continuous change of the numeric variable; (3) an action or event finally stops the execution of the process and terminates its effect on the <b>numeric</b> <b>variable.</b> Comment: the goals of the plan might be achieved before an active process is stopped.|$|E
40|$|This paper {{examines}} {{the completion of}} an w-ordered sequence of recursive definitions which {{on the one hand}} defines an increasing sequence of nested set and on the other redefines successively a <b>numeric</b> <b>variable</b> as the cardinal of the successively defined nested sets. The consequence is a contradiction involving the consistency of w-order and then that of the Axiom of Infinity. Comment: Obsolete versio...|$|E
40|$|Interpretation of {{regression}} coefficients {{is sensitive to}} {{the scale of the}} inputs. One method often used to place input variables on a common scale is to divide each <b>numeric</b> <b>variable</b> by its standard deviation. Here we propose dividing each <b>numeric</b> <b>variable</b> by two times its standard deviation, so that the generic comparison is with inputs equal to the mean ± 1 standard deviation. The resulting coefficients are then directly comparable for untransformed binary predictors. We have implemented the procedure as a function in R. We illustrate the method with two simple analyses that are typical of applied modeling: a linear regression of data from the National Election Study and a multilevel logistic regression of data on the prevalence of rodents in New York City apartments. We recommend our rescaling as a default option—an improvement upon the usual approach of including variables in whatever way they are coded in the data file—so that the magnitudes of coefficients can be directly compared as a matter of routine statistica...|$|E
5000|$|ID5R (1989) output {{the same}} tree as ID3 for a dataset {{regardless}} of the incremental training order. This was accomplished by recursively updating the tree's subnodes. It did not handle <b>numeric</b> <b>variables,</b> multiclass classification tasks, or missing values.|$|R
40|$|Abstract. Shared and mutable data-structures pose major {{problems}} in static analysis and most analyzers {{are unable to}} keep track of the values of <b>numeric</b> <b>variables</b> stored in the heap. In this paper, we first identify sufficient conditions under which heap allocated <b>numeric</b> <b>variables</b> in object oriented programs (i. e., numeric fields) can be handled as nonheap allocated variables. Then, we present a static analysis to infer which numeric fields satisfy these conditions at the level of (sequential) bytecode. This allows instrumenting the code with ghost variables which make such numeric fields observable to any field-insensitive value analysis. Our experimental results in termination analysis show that we greatly enlarge the class of analyzable programs with a reasonable overhead. ...|$|R
40|$|The CANadian Census Edit and Imputation System (CANCEIS) will do {{deterministic}} imputation plus perform minimum change donor imputation for all <b>variables</b> (both <b>numeric</b> and categorical) in the 2006 Canadian Census. Significant enhancements {{have been}} made to CANCEIS for the 2006 Census, including the ability to perform deterministic imputation, process alphanumeric variables, do outlier detection of <b>numeric</b> <b>variables</b> and use failed records as donors. In addition, it is now easier to write compact decision logic tables and improvements {{have been made}} in the handling of <b>numeric</b> <b>variables.</b> These changes were implemented by methodologists, subject matter experts and systems developers working in a collaborative fashion. CANCEIS, or an earlier version of the software, has been used in th...|$|R
40|$|This paper further {{develops}} Aumann and Lindell 2 ̆ 7 s [3] {{proposal for}} a variant of association rules for which the consequent is a <b>numeric</b> <b>variable.</b> It is argued that these rules can discover useful interactions with numeric data that cannot be discovered directly using traditional association rules with discretization. Alternative measures for identifying interesting rules are proposed. Efficient algorithms are presented that enable these rules to be discovered for dense data sets for which application of Auman and Lindell 2 ̆ 7 s algorithm is infeasible. <br /...|$|E
40|$|The Naïve Bayes {{model is}} used for text {{classification}} and the data is considered by using the Naïve Bayes classifier and also the probabilistic based model. To define the discrete variable we use the multinomial distribution and for the <b>numeric</b> <b>variable</b> we use the Gaussian distribution. In this research, graphical structure has been considered due to properties of Naïve Bayes classifier such as flexibility, energy efficient and high performance. The main idea of classification has been introducedthat is the basic techniques for data classification which includes Naive Bayesian classifier...|$|E
30|$|Procedure {{times were}} {{recorded}} for all {{subjects in the}} subacute group based on real-time videos of each procedure; these times {{were taken from the}} start of transvaginal sonography to the end of RF ablation with the VizAblate System. Procedure times for women in the acute group were not considered because of confounding ancillary measurements, image optimization procedures as part of the device development process at that time, and additional delays owing to the need for subsequent laparotomy in these subjects. Subjects in the subacute group were interviewed regarding pain during the VizAblate procedure and recovery using a 10 -point <b>numeric</b> <b>variable</b> analog scale (VAS) before discharge from the hospital after their VizAblate procedure and again when they returned for their hysterectomy; the latter interview covered the interval between the VizAblate procedure and the hysterectomy over 2  weeks later.|$|E
40|$|Shared and mutable data-structures pose major {{problems}} in static analysis and most analyzers {{are unable to}} keep track of the values of <b>numeric</b> <b>variables</b> stored in the heap. In this paper, we first identify sufficient conditions under which heap allocated <b>numeric</b> <b>variables</b> in object oriented programs (i. e., numeric fields) can be handled as non-heap allocated variables. Then, we present a static analysis to infer which numeric fields satisfy these conditions at the level of (sequential) bytecode. This allows instrumenting the code with ghost variables which make such numeric fields observable to any field-insensitive value analysis. Our experimental results in termination analysis show that we greatly enlarge the class of analyzable programs with a reasonable overhea...|$|R
40|$|Abstract. The purely propositional {{representation}} traditionally used {{to express}} AI planning problems is not adequate to express <b>numeric</b> <b>variables</b> when modeling real-world continuous resources. This paper presents a heuristic planning approach that uses a richer representation with capabilities for <b>numeric</b> <b>variables,</b> including du-rations of actions, and multiobjective optimisation. The approach consists of two stages. First, a spike construction process estimates {{the values of the}} variables associated with propositions/actions, with-out relaxing numeric effects in the calculus of the estimation. Sec-ond, a heuristic search process generates a relaxed plan according to the estimations of the first stage, and then performs search in a plan space. The relaxed plan and the heuristic estimations help the process find a plan while trying to optimise the multiobjective criterion. ...|$|R
5000|$|The network {{construction}} (based on soft thresholding {{the correlation}} coefficient) preserves the continuous {{nature of the}} underlying correlation information. For example, weighted correlation networks that are constructed {{on the basis of}} correlations between <b>numeric</b> <b>variables</b> do not require the choice of a hard threshold. Dichotomizing information and (hard)-thresholding may lead to information loss.|$|R
40|$|We {{extend a}} {{planning}} algorithm to cover simple forms of arithmetics. The operator preconditions {{can refer to}} the values of numeric variables and the operator postconditions can modify the values of numeric variables. The basis planning algorithm is based on techniques from propositional satisfiability testing and does not restrict to forward or backward chaining. When several operations affect a <b>numeric</b> <b>variable</b> by increasing and decreasing its value in parallel, the effects have to be combined in a meaningful way. This problem is especially acute in planning algorithms that maintain an incomplete state description of every time point of a plan execution. The approach we take requires that for operators that are executed in parallel, all linearizations of the operations to total orders behave equivalently. We provide an efficient and general solution to the problem. 1 Introduction In automated planning and for example in generating counterexamples in verification of saf [...] ...|$|E
40|$|Abstract. The paper {{addresses}} {{the task of}} multi-target polynomial regression, i. e., the task of inducing polynomials that can predict the value of more then one <b>numeric</b> <b>variable.</b> As in other learning tasks, we face the problem of finding an optimal trade-off between {{the complexity of the}} induced model and its predictive error. We propose a minimal description length scheme for multi-target polynomial regression, which includes coding schemes for polynomials and their predictive errors on training data. The proposed MDL scheme is implemented in an algorithm for polynomial induction that can also take into account language constraints, i. e., constraints on terms {{to be included in the}} induced polynomials. We empirically compare the multi-target model with the multiple single target models. The results of the experiments show that there is no loss in predictive performance when using multi-target models as compared to multiple target models and that fewer equation structures are considered in the former case. ...|$|E
40|$|Bayesian Network (BN) is a {{classification}} technique {{widely used in}} Artificial Intelligence. Its structure is a Direct Acyclic Graph (DAG) used to model the association of categorical variables. However, {{in cases where the}} variables are numerical, a previous discretization is necessary. Discretization methods are usually based on a statistical approach using the data distribution, such as division by quartiles. In this article we present a discretization using a heuristic that identifies events called peak and valley. Genetic Algorithm was used to identify these events having the minimization of the error between the estimated average for BN and the actual value of the <b>numeric</b> <b>variable</b> output as the objective function. The BN has been modeled from a database of Bit’s Rate of Penetration of the Brazilian pre-salt layer with 5 numerical variables and one categorical variable, using the proposed discretization and the division of the data by the quartiles. The results show that the proposed heuristic discretization has higher accuracy than the quartiles discretization...|$|E
5000|$|ITI (1997) is an {{efficient}} method for incrementally inducing decision trees. The same tree is produced for a dataset {{regardless of the}} data's presentation order, or whether the tree is induced incrementally or non incrementally (batch mode). It can accommodate <b>numeric</b> <b>variables,</b> multiclass tasks, and missing values. Code {{is available on the}} web. http://www-lrn.cs.umass.edu/iti/index.html ...|$|R
30|$|The {{pharmacodynamic}} data analysis {{was carried out}} using the GraphPad Prism version 6.02 (Registered trademark of GraphPad software, Inc). All the <b>numeric</b> <b>variables</b> were expressed as Mean[*]±[*]Standard Error of Mean (SEM) and results were statistically analyzed using One Way-Analysis of Variance (ANOVA) followed by Dunnett’s Multiple Comparison Test. For all tests a probability (p[*]<[*] 0.0001) was considered significant.|$|R
50|$|XOR swap {{uses the}} XOR {{operation}} to swap two <b>numeric</b> <b>variables.</b> It is generally touted to be {{faster than the}} naive method mentioned above; however it does have disadvantages. XOR swap is generally used to swap low-level data types, like integers. However, it is, in theory, capable of swapping any two values which can be represented by fixed-length bitstrings.|$|R
