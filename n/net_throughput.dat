52|32|Public
5000|$|... #Caption: Benchmarks: <b>Net</b> <b>Throughput</b> with/without RTS/CTS (Pommer, p.179) ...|$|E
5000|$|... 802.11g is {{the third}} {{modulation}} standard for wireless LANs. It works in the 2.4 GHz band (like 802.11b) but operates at a maximum raw data rate of 54 Mbit/s. Using the CSMA/CA transmission scheme, 31.4 Mbit/s is the maximum <b>net</b> <b>throughput</b> possible for packets of 1500 bytes in size and a 54 Mbit/s wireless rate (identical to 802.11a core, except for some additional legacy overhead for backward compatibility). In practice, access points may not have an ideal implementation and may therefore {{not be able to}} achieve even 31.4 Mbit/s throughput with 1500 byte packets. 1500 bytes is the usual limit for packets on the Internet and therefore a relevant size to benchmark against. Smaller packets give even lower theoretical throughput, down to 3 Mbit/s using 54 Mbit/s rate and 64 byte packets. Also, the available throughput is shared between all stations transmitting, including the AP so both downstream and upstream traffic is limited to a shared total of 31.4 Mbit/s using 1500 byte packets and 54 Mbit/s rate.|$|E
40|$|Efficient use of {{resources}} in a production line that processes multiple product types with high volume of demand is necessary for overall success in many production facilities. Motivated by a problem in a frozen food processing facility, we analyze effects of several factors on the <b>net</b> <b>throughput</b> of heavily loaded production lines. The <b>net</b> <b>throughput</b> {{is affected by the}} amount of rework and experienced downtime. We identify factors and levels that would lead to improvement in these performance measures...|$|E
50|$|MoCA 1.1 {{provides}} 175 Mbit/s <b>net</b> <b>throughputs</b> (275 Mbit/s PHY rate) {{and operates}} in the 500 to 1500 MHz frequency range.|$|R
50|$|MoCA Access is {{intended}} for multiple dwelling units (MDUs) such as hotels, resorts, hospitals, or educational facilities. It {{is based on the}} current MoCA 2.0 standard which is capable of 1 Gbps <b>net</b> <b>throughputs,</b> and MoCA 2.5 which is capable of 2.5 Gbps.|$|R
50|$|The 802.11a {{standard}} {{uses the}} same data link layer protocol and frame format as the original standard, but an OFDM based air interface (physical layer). It operates in the 5 GHz band with a maximum net data rate of 54 Mbit/s, plus error correction code, which yields realistic <b>net</b> achievable <b>throughput</b> in the mid-20 Mbit/s.|$|R
3000|$|..., to {{identify}} {{that the value}} of the sub-carrier bandwidth, which will maximize the <b>net</b> <b>throughput</b> of the SUs, within the power budget, while mitigating the PU interference. The algorithm is as follows: [...]...|$|E
30|$|The {{synthesis}} of the proposed decoder on a 65 [*]nm low-power CMOS technology reached the clock frequency of 240 [*]MHz, which corresponds to a <b>net</b> <b>throughput</b> ranging from 131 to 334 [*]Mbps with UOP and 12 decoding iterations, outperforming similar designs.|$|E
40|$|We {{consider}} {{three types}} of application layer coding for streaming over lossy links: random linear coding, systematic random linear coding, and structured coding. The file being streamed is divided into sub-blocks (generations). Code symbols are formed by combining data belonging to the same generation, and transmitted in a round-robin fashion. We compare the schemes based on delivery packet count, <b>net</b> <b>throughput,</b> and energy consumption {{for a range of}} generation sizes. We determine these performance measures both analytically and in an experimental configuration. We find our analytical predictions to match the experimental results. We show that coding at the application layer brings about a significant increase in net data throughput, and thereby reduction in energy consumption due to reduced communication time. On the other hand, on devices with constrained computing resources, heavy coding operations cause packet drops in higher layers and negatively affect the <b>net</b> <b>throughput.</b> We find from our experimental results that low-rate MDS codes are best for small generation sizes, whereas systematic random linear coding has the best <b>net</b> <b>throughput</b> and lowest energy consumption for larger generation sizes due to its low decoding complexity. Comment: NetCod' 1...|$|E
40|$|Abstract—In this paper, we {{consider}} scalable video multicast to LTE-A user groups. We {{focus on the}} problem in accommodating the varying channel conditions amongst group members to adaptively select modulation schemes that meet the desired QoS objectives. We envision a fair provisioning of base layer to ensure baseline quality to all users and opportunistic provisioning of enhancement layers to maximize aggregated group through-put. We formulate component-carrier assignment for base and enhancement layers as NP-Hard problems and design greedy approximations to solve them. Further, this paper discusses a scheduling mechanism to handle contention of resources amongst groups. We developed and integrated a carrier aggregation mod-ule in network simulator NS 3 to conduct extensive simulations. In different scenarios, we demonstrate improvements in terms of achieved base and enhancement layer <b>throughputs,</b> <b>net</b> downlink LTE-A <b>throughput</b> and satisfiability of the groups. I...|$|R
40|$|Abstract. An {{overview}} {{is given}} {{of the new}} IEEE 802. 11 n standard. This is the first wireless LAN standard based on MIMO-OFDM, a technique pioneered by Airgo Networks to give a significant performance increase in both range and rate relative to conventional wireless LAN. Performance results show that <b>net</b> user <b>throughputs</b> over 100 Mbps are achievable, which is about four {{times larger than the}} maximum achievable throughput using IEEE 802. 11 a/g. For the same throughput, MIMO-OFDM achieves a range that is about 3 times larger than non-MIMO systems. This significant improvement in range-rate performance makes MIMO-OFDM the ideal solution not only for wireless LAN, but also for home entertainment networks and 4 G networks...|$|R
40|$|This paper {{introduces}} and implements a point-to-point error -resilient {{image coding}} and transmission scheme over a CDPD wireless channel, combining a low-delay UDP transport protocol {{in conjunction with}} a channel-optimized wavelet-based image coder. The image coder uses a robust channel-optimized trellis -coded quantization (COTCQ) stage that is designed to optimize the image coding based on the channel characteristics. Packets are formed with the property that image information is spread over different frequency bands. The channel characterization is conducted in such a way so as to minimize the packet loss rate and maximize the <b>net</b> data <b>throughput.</b> Furthermore, a receiver-based rate control mechanism is presented at the application level to significantly reduce the image distortions and packet loss rate. Results are presented to illustrate the performance of the proposed system. ...|$|R
30|$|The {{core of the}} HopScotch {{network is}} based on the IEEE 802.11 n {{standard}} which exploits techniques such as spatial multiplexing, channel bonding and frame aggregation to maximise throughput. A proprietary time division multiple access (TDMA) medium access controller (MAC) further improves the <b>net</b> <b>throughput</b> of the system over long distances.|$|E
40|$|State {{of the art}} audio coders {{exploit the}} {{redundancy}} in audio signals by shaping their quantization noise below the signal's masking curve, which is a signal-dependent threshold of audibility. This framework can be extended to the context of data hiding, where the data {{play the role of}} noise. To minimize audio distortion the data power should be closely adapted to the time-varying masking curve; each power switch, however, reduces the <b>net</b> <b>throughput</b> via its associated side information. This tradeoff can be cast in a rate/distortion framework: the optimal sequence of power levels and the optimal sequence of power switchpoints is found by minimizing a Lagrange cost functional relating perceptual audio distortion to throughput, and is implemented as a linear-time trellis search. For 16 -bit, 44. 1 KHz PCM stereo signals, a <b>net</b> <b>throughput</b> of the order of 30 kbits/sec can usually be achieved at no perceptual cost in an algorithmically efficient way. Keywords: Steganography, data hiding, rate [...] ...|$|E
40|$|Abstract—We propose an {{interference}} {{management scheme}} for providing {{quality of service}} (QoS) {{in the absence of}} automatic repeat request (ARQ) in cellular networks augmented with fixed relays. The high packet error rate in a system with ARQ not only incurs additional packet delay, which is undesirable for real-time services, but also reduces link throughput because of the increased over-the-air signaling overhead and retransmissions. The proposed scheme strives for improvements in packet error rate and <b>net</b> <b>throughput</b> while maintaining acceptable delay through the use of inter-cell coordination. The inter-cell coordination uses backbone network for information exchange and thereby transfers over-the-air signaling overhead to the high-speed backbone network. In our scheme, a group of base stations, each of which is either a recipient of or a contributor to dominant interference, form an interferer group and exchange channel state information with each other. Based on this instantaneous channel quality information, the proposed scheme makes intelligent scheduling and routing decisions taking the interference into account. The performance of the scheme is compared with that of an uncoordinated scheme through extensive simulations. It has been observed that the proposed scheme achieves significant performance benefits in terms of packet error rate and <b>net</b> <b>throughput...</b>|$|E
40|$|This paper {{addresses}} the computation of upper bounds for the steady-state throughput of stochastic Petri net systems with immediate and generally distributed timed transitions. It is achieved {{through the use}} of a kind of decomposition of the whole net system. Results are obtained deeply bridging stochastic Petri net theory to untimed Petri net and queueing network theories. Previous results are improved by considering some embedded product-form queueing networks (generated by the support of some left annullers of the incidence matrix of the net). The obtained results for the case of live and bounded free choice systems are of special interest. In this case, the subnets generated by the minimal left annullers of the incidence matrix always have a topology of product-form closed monoclass queueing networks. Keywords: Stochastic Petri <b>net</b> systems, <b>throughput</b> bounds, embedded product-form queueing networks. 1 Introductio...|$|R
50|$|The {{simulations}} {{performed in}} the Femto Forum WG2 and 3GPP RAN4 encompass a wide spectrum ofpossible deployment scenarios including shared channel and dedicated channel deployments. In addition, thestudies looked at the impact in different morphologies, {{as well as in}} closed versus open access. The followingare broad conclusions from the studies::1. When femtocells are used in areas of poor or no coverage, macro/femto interference is unlikely to be a problem.:2. If the femto network is sharing the channel (co-channel) with the macro network, interference can occur. However, if the interference management techniques advocated by the Femto Forum are adopted, the resulting interference can be mitigated in most cases.:3. A femtocell network deployed on an adjacent dedicated channel is unlikely to create interference to a macro network. Additionally, the impact of a macro network on the performance of a femtocell on an adjacent channel is limited to isolated cases. If the interference mitigation techniques advocated by the Femto Forum are used, the impact is further marginalised.:4. Closed access represents the worst-case scenario for creation of interference. Open access reduces the chances of User Equipment (mobile phone handsets, 3G data dongles, etc.) on the macro network interfering with a proximate femtocell.:5. The same conclusions were reached for both the 850 MHz (3GPP Band 17) and 2100 MHz (3GPP Band 1) deployments that were studied.The conclusions are common to the 850 MHz and 2100 MHz bands that were simulated in the studies, and can beextrapolated to other mobile bands. With interference mitigation techniques successfully implemented, simulations showthat femtocell deployments can enable very high capacity networks by providing between a 10 and 100 timesincrease in capacity with minimal deadzone impact and acceptable noise rise.Femtocells can also create a much better user experience by enabling substantially higher data rates than can be obtained with a macro network and <b>net</b> <b>throughputs</b> that will be ultimately limited by backhaul in most cases (over 20 Mbps in 5 MHz).|$|R
40|$|International audienceFinite element schemes {{based on}} {{discontinuous}} Galerkin methods possess features amenable to massively parallel computing accelerated with general purpose graphics processing units (GPUs). However, the computational performance of such schemes strongly {{depends on their}} implementation. In the past, several implementation strategies have been proposed. They are based exclusively on specialized compute kernels tuned for each operation, or they can leverage BLAS libraries that provide optimized routines for basic linear algebra operations. In this paper, we present and analyze up-to-date performance results for different implementations, tested in a unified framework on a single NVIDIA GTX 980 GPU. We show that specialized kernels written with a one-node-per-thread strategy are competitive for polynomial bases up to the fifth and seventh degrees for acoustic and elastic models, respectively. For higher degrees, a strategy that makes use of the NVIDIA cuBLAS library provides better results, able to reach a <b>net</b> arithmetic <b>throughput</b> 35. 7 % of the theoretical peak value...|$|R
40|$|Transmit {{beamforming}} increases throughput {{and transmission}} {{range of a}} wireless communication system. However, the required feedback of channel state information (CSI) consumes radio resources that otherwise {{can be used for}} data transmission. This makes "Feedback or no feedback?" a relevant question to ask. This paper answers this question by proposing intelligent feedback control using a Markov decision process. The feedback controller turns feedback on/off according to the channel state and the criterion of maximum <b>net</b> <b>throughput,</b> namely throughput minus average feedback cost. Assuming channel isotropicity and Markovity, the state of the feedback controller reduces to two channel parameters. This allows the optimal control policy to be efficiently computed using dynamic programming. The optimal control policy is proved to be of the threshold type. Under this policy, feedback is performed whenever a channel parameter indicating the accuracy of transmit CSI is below a threshold, which varies with channel power. The above result holds regardless of whether the controller's state space is discretized or continuous. Simulation shows that feedback control increases <b>net</b> <b>throughput</b> by up to 0. 5 bit/s/Hz without requiring additional bandwidth or antennas. © 2010 IEEE. link_to_subscribed_fulltex...|$|E
40|$|The {{local loop}} market {{deregulation}} {{and the increased}} data traffic demand have been the main drivers behind the development of 1 st generation Broadband Wireless Access (BWA) systems. Ericsson has developed a 1 st generation BWA in the 24 to 31 GHz bands exploiting a TDM/TDMA/FDD scheme and supporting voice and data services. An efficient MAC protocol provides fast dynamic allocation of the capacity, exceeding 30 Mb/s <b>net</b> <b>throughput.</b> Approach to 2 nd generation systems has started already, with main goals of throughput enhancement and enabling of low cost equipment. Such systems will be still based on a point-to-multipoint cellular architecture providing highquality access (BER < 10 - 11), at <b>net</b> <b>throughput</b> exceeding 115 Mb/s in 28 MHz. In this paper, after a short overview of 1 st generation system features, requirements, architecture and performances of 2 nd generation systems are described. Main results of investigations upon some key implementation aspects are also reported. The modulation scheme adopted is a four levels constant envelope (C-QPSK), also known as Tamed Frequency Modulation (TFM), allowing 37. 5 Mb/s in 28 MHz symmetric RF channels, while enabling very high system gain. Key system features of this product are summarized in table 1...|$|E
30|$|The {{critical}} design {{factors that}} determine {{the quality of}} a wireless mesh network are performance, reliability, and scalability. Performance starts at the physical layer where the hardware defines the maximal capacity of a link. Current state-of-the-art WiFi cards and access points achieve a <b>net</b> <b>throughput</b> of 54 [*]Mbps, as defined by the 802.11 a/g standards. Capacity enhancements have been promised with 802.11 n, where directional and smart antennas as well as MIMO and multiradio/multichannel systems promise rates of up to 600 [*]Mbps.|$|E
40|$|Opportunistic {{selection}} selects the node that {{improves the}} overall system performance the most. Selecting the best node is challenging as the nodes are geographically distributed and have only local knowledge. Yet, selection must be fast {{to allow more}} time {{to be spent on}} data transmission, which exploits the selected node's services. We analyze the impact of imperfect power control on a fast, distributed, splitting based selection scheme that exploits the capture effect by allowing the transmitting nodes to have different target receive powers and uses information about the total received power to speed up selection. Imperfect power control makes the received power deviate from the target and, hence, affects performance. Our analysis quantifies how it changes the selection probability, reduces the selection speed, and leads to the selection of no node or a wrong node. We show that the effect of imperfect power control is primarily driven by the ratio of target receive powers. Furthermore, we quantify its effect on the <b>net</b> system <b>throughput...</b>|$|R
40|$|Finite element schemes {{based on}} {{discontinuous}} Galerkin methods possess features amenable to massively parallel computing accelerated with general purpose graphics processing units (GPUs). However, the computational performance of such schemes strongly {{depends on their}} implementation. In the past, several implementation strategies have been proposed. They are based exclusively on specialized compute kernels tuned for each operation, or they can leverage BLAS libraries that provide optimized routines for basic linear algebra operations. In this paper, we present and analyze up-to-date performance results for different implementations, tested in a unified framework on a single NVIDIA GTX 980 GPU. We show that specialized kernels written with a one-node-per-thread strategy are competitive for polynomial bases up to the fifth and seventh degrees for acoustic and elastic models, respectively. For higher degrees, a strategy that makes use of the NVIDIA cuBLAS library provides better results, able to reach a <b>net</b> arithmetic <b>throughput</b> 35. 7 % of the theoretical peak value. Comment: Paper submitted to Computers & Geosciences, 21 page...|$|R
40|$|Abstract—Opportunistic {{selection}} aims {{to select}} a node that improves the overall system performance the most. Selection is challenging as the nodes are geographically distributed and have only local knowledge. Yet, selection needs to be fast in order to allocate more time to the data transmission phase that exploits the selected node’s services. In this paper, we analyze the impact of imperfect power control on a fast, distributed, splitting-based selection scheme that exploits the capture effect by allowing the transmitting nodes to have different target receive powers and uses information about the total received power to speed up selection. The scheme owes its speed {{to the use of}} different target powers that facilitate capture. However, imperfect power control makes the received power deviate from the target and, hence, affects performance. Our analysis quantifies how it changes the selection speed, leads to the selection of wrong node, or no node getting selected. We also quantify the effect of imperfect power control on the <b>net</b> system <b>throughput</b> and the extent of error beyond which power control is not useful. I...|$|R
40|$|In {{this paper}} we study the {{multi-user}} diversity {{gain in the}} downlink of single-hop and multi-hop infrastructure-based networks. We propose a base-station coordinated cooperative relaying method, Cooperative Induced Multi-user Diversity Relaying (CIMDR), to overcome the fundamental limitations on the average achieved <b>net</b> <b>throughput</b> per-user. In the proposed method, multi-user diversity is induced and then exploited in a 2 -hop relaying scheme to improve per user achieved data throughput. We show that by using the proposed method, the throughput per-user and the packet-drop-ratio are significantly improved...|$|E
40|$|AbstractIt {{is shown}} that a large class of {{flexible}} manufacturing cells can be modeled using timed Petri nets. Net models of simple schedules (i. e., schedules in which exactly one part enters and one leaves the cell during each cycle) are conflict-free nets. Two complementary approaches to analysis of such models are presented: invariant analysis and throughput analysis. Invariant analysis provides analytic (or symbolic) solutions for the cycle time of a cell analyzing (invariant) subnets of the original <b>net.</b> <b>Throughput</b> analysis performs a series of performance-preserving net reductions to simplify the original model. Several directions for further research are indicated...|$|E
40|$|This paper {{presents}} the network output load at the Fully Functional Device (FFD) and Reduced Functional Devices (RFD‟s) of IEEE 802. 15. 4 for different modulation schemes. From the simulations it is revealed that Minimum Shift Keying (MSK) is {{best suited for}} all types of devices in 802. 15. 4 for wireless sensor networks (WSNs) if the network output load is to be maximized as more is the output load, more will be the <b>net</b> <b>throughput.</b> Simulations also reveal that Binary Phase Shift keying (BPSK) at all type of devices and Quadrature Amplitude Modulation of 64 bits (QAM_ 64) at the PAN (Personal Area Network) coordinator are unsuitable...|$|E
40|$|Abstract—Opportunistic {{selection}} selects the node that im-proves {{the overall}} system performance the most. Selecting the best node is challenging as the nodes are geographically dis-tributed and have only local knowledge. Yet, selection must be fast {{to allow more}} time {{to be spent on}} data transmission, which exploits the selected node’s services. We analyze the impact of imperfect power control on a fast, distributed, splitting based selection scheme that exploits the capture effect by allowing the transmitting nodes to have different target receive powers and uses information about the total received power to speed up selection. Imperfect power control makes the received power deviate from the target and, hence, affects performance. Our analysis quantifies how it changes the selection probability, reduces the selection speed, and leads to the selection of no node or a wrong node. We show that the effect of imperfect power control is primarily driven by the ratio of target receive powers. Furthermore, we quantify its effect on the <b>net</b> system <b>throughput.</b> Index Terms—Selection, splitting, imperfect power control, capture, medium access control protocols, throughput. I...|$|R
40|$|Opportunistic relay {{selection}} in a multiple source-destination (MSD) cooperative system requires quickly allocating to each source-destination (SD) pair a suitable relay based on channel gains. Since the channel knowledge {{is available only}} locally at a relay and not globally, efficient relay selection algorithms are needed. For an MSD system, in which the SD pairs communicate in a time-orthogonal manner {{with the help of}} decode-and-forward relays, we propose three novel relay selection algorithms, namely, contention-free en masse assignment (CFEA), contention-based en masse assignment (CBEA), and a hybrid algorithm that combines the best features of CFEA and CBEA. En masse assignment exploits the fact that a relay can often aid not one but multiple SD pairs, and, therefore, can be assigned to multiple SD pairs. This drastically reduces the average time required to allocate an SD pair when compared to allocating the SD pairs one by one. We show that the algorithms are much faster than other selection schemes proposed in the literature and yield significantly higher <b>net</b> system <b>throughputs.</b> Interestingly, CFEA is as effective as CBEA over a wider range of system parameters than in single SD pair systems...|$|R
40|$|Abstract—Opportunistic relay {{selection}} in a multiple source-destination (MSD) cooperative system requires quickly allocating to each source-destination (SD) pair a suitable relay based on channel gains. Since the channel knowledge {{is available only}} locally at a relay and not globally, efficient relay selection algorithms are needed. For an MSD system, in which the SD pairs communicate in a time-orthogonal manner {{with the help of}} decode-and-forward relays, we propose three novel relay se-lection algorithms, namely, contention-free en masse assignment (CFEA), contention-based en masse assignment (CBEA), and a hybrid algorithm that combines the best features of CFEA and CBEA. En masse assignment exploits the fact that a relay can often aid not one but multiple SD pairs, and, therefore, can be assigned to multiple SD pairs. This drastically reduces the average time required to allocate an SD pair when compared to allocating the SD pairs one by one. We show that the algorithms are much faster than other selection schemes proposed in the literature and yield significantly higher <b>net</b> system <b>throughputs.</b> Interestingly, CFEA is as effective as CBEA over a wider range of system parameters than in single SD pair systems. Index Terms—Relay selection, Multiple source-destination net...|$|R
40|$|Transmit {{beamforming}} is {{a simple}} multi-antenna technique for increasing throughput and the transmission range of a wireless communication system. The required feedback of channel state information (CSI) can potentially result in excessive overhead especially for high mobility or many antennas. This work concerns efficient feedback for transmit beamforming and establishes a new approach of controlling feedback for maximizing <b>net</b> <b>throughput,</b> defined as throughput minus average feedback cost. The feedback controller using a stationary policy turns CSI feedback on/off according to the system state that comprises the channel state and transmit beamformer. Assuming channel isotropy and Markovity, the controller's state reduces to two scalars. This allows the optimal control policy to be efficiently computed using dynamic programming. Consider the perfect feedback channel free of error, where each feedback instant pays a fixed price. The corresponding optimal feedback control policy is proved {{to be of the}} threshold type. This result holds regardless of whether the controller's state space is discretized or continuous. Under the threshold-type policy, feedback is performed whenever a state variable indicating the accuracy of transmit CSI is below a threshold, which varies with channel power. The practical finite-rate feedback channel is also considered. The optimal policy for quantized feedback is proved to be also of the threshold type. The effect of CSI quantization is shown to be equivalent to an increment on the feedback price. Moreover, the increment is upper bounded by the expected logarithm of one minus the quantization error. Finally, simulation shows that feedback control increases <b>net</b> <b>throughput</b> of the conventional periodic feedback by up to 0. 5 bit/s/Hz without requiring additional bandwidth or antennas. Comment: 29 pages; submitted for publicatio...|$|E
40|$|Abstract. In today’s highly {{competitive}} business environment, manufacturers {{have to offer}} {{a great variety of}} products on a high quality level, in the least amount of time for an acceptable price. Therefore machine maintenance and in general, implementing an appropriate maintenance strategy has become increasingly im-portant for manufacturing companies to accomplish these requirements. Total productive maintenance (TPM) {{has become one of the}} most popular maintenance strategies to ensure high machine reliability. In this pa-per and through system dynamics concepts, effects of implementation of TPM on machine reliability, process quality and <b>net</b> <b>throughput</b> has been analyzed. Results obtained show the effectiveness and usefulness of TPM in reducing breakdown maintenance (BM) tasks as well as enhancing machine reliability, process quality and product’s throughput...|$|E
40|$|We present linear {{precoding}} {{methods for}} down-link transmission in multi-user multiple-input multiple-output (MIMO) systems where channel state information (CSI) {{can be obtained}} through training. In this paper, channel training overhead and estimation error are rigorously accounted for while determining the net system throughput. First, we consider the case with training on the reverse link only. We study a precoding method which {{is a combination of}} two schemes: selection of users with largest estimated gains and zero-forcing to selected users. Next, we consider the case with training on both reverse and forward links. We obtain a lower bound on the weighted-sum capacity, and propose an algorithm to determine an efficient precoding matrix. This precoding method effectively utilizes the training on the reverse and forward links in improving <b>net</b> <b>throughput.</b> 7 page(s...|$|E
50|$|The 802.11a {{amendment}} to the original standard was ratified in 1999. The 802.11a standard uses the same core protocol as the original standard, operates in 5 GHz band, and uses a 52-subcarrier orthogonal frequency-division multiplexing (OFDM) with a maximum raw data rate of 54 Mbit/s, which yields realistic <b>net</b> achievable <b>throughput</b> in the mid-20 Mbit/s. The data rate is reduced to 48, 36, 24, 18, 12, 9 then 6 Mbit/s if required. 802.11a originally had 12/13 non-overlapping channels, 12 {{that can be used}} indoor and 4/5 of the 12 {{that can be used in}} outdoor point to point configurations. Recently many countries of the world are allowing operation in the 5.47 to 5.725 GHz Band as a secondary user using a sharing method derived in 802.11h. This will add another 12/13 Channels to the overall 5 GHz band enabling significant overall wireless network capacity enabling the possibility of 24+ channels in some countries. 802.11a is not interoperable with 802.11b as they operate on separate bands, except if using equipment that has a dual band capability. Most enterprise class Access Points have dual band capability.|$|R
40|$|International Telemetering Conference Proceedings / November 14 - 16, 1978 / Hyatt House Hotel, Los Angeles, CaliforniaThe genesis {{and design}} of a unique Tracking, Telemetry, and Command (TT&C) System for the Navstar Global Positioning System (GPS) is {{described}} {{from the perspective of}} the System Architect/Engineer. Working from the diverse and sometimes conflicting mission requirements, derivative performance requirements for the TT&C System were generated. System design tradeoffs were performed in an effort to compromise conflicting requirements which affected the frequency domain, link budgets, antenna sizing, and modulation schemes. The characteristics of the resulting TT&C System included the following: a. Primary uplinking to the satellite on a spread spectrum secure link at X-Band. b. Use of a closed-loop uplink which takes advantage of existing onboard functions as references to achieve precise ground-space synchronization. c. Incorporation of state-of-the-art error control techniques to achieve high <b>net</b> data <b>throughputs</b> with concurrently "zero error" data transfer from ground to space. d. Hybrid frequency ground antennas to accommodate both the primary and backup command links, with compatible telemetry downlinks. A common S-Band frequency input within the satellite to both the primary wideband Pseudo Random Noise (PRN) correlation receiver and the backup Space Ground Link System (SGLS) receiver...|$|R
40|$|Channel-aware {{assignment}} of subchannels to {{users in the}} downlink of an OFDMA system requires extensive feedback of channel state information (CSI) to the base station. Since bandwidth is scarce, schemes that limit feedback are necessary. We develop a novel, low feedback, distributed splitting-based algorithm called SplitSelect to opportunistically assign each subchannel to its most suitable user. SplitSelect explicitly handles multiple access control aspects associated with CSI feedback, and scales well {{with the number of}} users. In it, according to a scheduling criterion, each user locally maintains a scheduling metric for each subchannel. The goal is to select, for each subchannel, the user with the highest scheduling metric. At any time, each user contends for the subchannel for which it has the largest scheduling metric among the unallocated subchannels. A tractable asymptotic analysis of a system with many users is central to SplitSelect's simple design. Extensive simulation results demonstrate the speed with which subchannels and users are paired. The <b>net</b> data <b>throughput,</b> when the time overhead of selection is accounted for, is shown to be substantially better than several schemes proposed in the literature. We also show how fairness and user prioritization can be ensured by suitably defining the scheduling metric...|$|R
