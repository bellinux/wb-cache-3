1569|2256|Public
5|$|While an Australian Cattle Dog {{generally}} works silently, it will bark {{in alarm}} or to attract attention. It has a distinctive intense, high-pitched bark. Barking {{can be a}} sign of boredom or frustration, although research has shown that pet dogs increase their vocalisation when raised in a <b>noisy</b> <b>environment.</b> It responds well to familiar dogs, but when multiple dogs are present, establishing a pecking order can trigger aggression. It is not a breed that lives in a pack with other dogs.|$|E
25|$|Vision is {{the primary}} sense for humans, but speech {{perception}} is multimodal, which means that it involves information {{from more than one}} sensory modality, in particular, audition and vision. The McGurk effect arises during phonetic processing because the integration of audio and visual information happens early in speech perception. The McGurk effect is very robust; that is, knowledge about it seems to have little effect on one's perception of it. This is different from certain optical illusions, which break down once one 'sees through' them. Some people, including those that have been researching the phenomenon for more than twenty years, experience the effect even when they are aware that it is taking place. With the exception of people who can identify most of what is being said from speech-reading alone, most people are quite limited in their ability to identify speech from visual-only signals. A more extensive phenomenon is the ability of visual speech to increase the intelligibility of heard speech in a <b>noisy</b> <b>environment.</b> Visible speech can also alter the perception of perfectly audible speech sounds when the visual speech stimuli are mismatched with the auditory speech. Normally, speech perception is thought to be an auditory process; however, our use of information is immediate, automatic, and, to a large degree, unconscious and therefore, despite what is widely accepted as true, speech is not only something we hear. Speech is perceived by all of the senses working together (seeing, touching, and listening to a face move). The brain is often unaware of the separate sensory contributions of what it perceives. Therefore, when it comes to recognizing speech the brain cannot differentiate whether it is seeing or hearing the incoming information.|$|E
2500|$|The {{personal}} pronouns of Esperanto all end in i {{and some}} {{may be difficult to}} distinguish in a <b>noisy</b> <b>environment</b> (especially mi and ni). The personal pronouns of Novial use various vowels making them more distinct, although some differ only in the initial consonant (e.g. nus, vus and lus). A later form of nus – nos, more distinct from vus – has sometimes been used. Novial does not distinguish familiar and polite forms of “you” (e.g. French tu and vous). Novial’s inventor argued that such a distinction has no place in a language intended solely for international use. The distinction is available in Esperanto [...] but is little used in practice.|$|E
40|$|AbstractSpeech and non-speech {{identification}} {{along with}} its classification method {{that need to be}} improved in the endpoint detection for speech in <b>noisy</b> <b>environments.</b> The proposed method uses few features to increase the robustness in various <b>noisy</b> <b>environments,</b> and the classification used here KNN technique is applied to effectively combine these multiple features for classification of each speech signal. We evaluate the performance of the proposed method by conducting speech and non-speech classification experiments on noisy speech. We also investigate the importance of various features on speech and non-speech classification in <b>noisy</b> <b>environments</b> and by using this KNN algorithm to obtaining 80 % accuracy...|$|R
5000|$|... #Caption: Using an assistive {{listening}} device to hear better in <b>noisy</b> <b>environments</b> ...|$|R
30|$|It is {{well known}} that {{significant}} performance degradation occurs when speech recognition is used in <b>noisy</b> <b>environments.</b> Various research efforts have previously been directed at noise-robust speech recognition such as noise-robust feature extraction, speech enhancement, and feature and model parameter compensation [1 – 5]. These approaches are used independently or in combination with each other to improve the performance of speech recognition under <b>noisy</b> <b>environments.</b>|$|R
2500|$|The pronouns of Ido were {{revised to}} make them more acoustically {{distinct}} than those of Esperanto, which all end in i. Especially the singular and plural first-person pronouns mi and ni may be difficult to distinguish in a <b>noisy</b> <b>environment,</b> so Ido has me and ni instead. Ido also distinguishes between intimate (tu) and formal (vu) second-person singular pronouns as well as plural second-person pronouns (vi) not marked for intimacy. Furthermore, Ido has a pan-gender third-person pronoun lu (it can mean [...] "he", [...] "she", or [...] "it", depending on the context) in addition to its masculine (il), feminine (el), and neuter (ol) third-person pronouns.|$|E
2500|$|On 4 October, a {{group of}} protesters who were arrested on the bridge {{filed a lawsuit against}} the city, alleging that {{officers}} had violated their constitutional rights by luring them into a trap and then arresting them. In June 2012, a federal judge ruled that the protesters had not received sufficient warning of arrest pending entrance onto the Brooklyn Bridge. Although video evidence showed the police warning protesters by bullhorn, after reviewing it, Judge Jed S. Rakoff sided with plaintiffs, saying, [...] "a reasonable officer in the <b>noisy</b> <b>environment</b> defendants occupied would have known that a single bull horn could not reasonably communicate a message to 700 demonstrators".|$|E
2500|$|De-noise mode is an {{alternative}} to Active noise reduction. It provides for relatively noise-free listening to audio in a <b>noisy</b> <b>environment.</b> In this mode, audio intelligibility is improved due to selective gain reduction of the ambient noise. This method splits external signals into frequency components by [...] "filterbank" [...] (according to the peculiarities of human perception of specific frequencies) and processing them using adaptive audio compressors. Operation thresholds in adaptive audio compressors (in contrast to [...] "ordinary" [...] compressors) are regulated depending on ambient noise levels for each specific bandwidth. Reshaping of the processed signal from adaptive compressor outputs is realised in a synthesis filterbank. This method improves the intelligibility of speech signals and music. The best effect is obtained while listening to audio in the environment with constant noise (in trains, automobiles, planes), or in environments with fluctuating noise level (e.g. in a metro). Improvement of signal intelligibility in condition of ambient noise allows users to hear audio well and preserve hearing ability, in contrast to regular volume amplification.|$|E
25|$|Reducing of {{background}} noise level increases the user’s comfort (especially in <b>noisy</b> <b>environments,</b> e.g. on the street).|$|R
30|$|This section {{evaluates the}} {{robustness}} {{of the proposed}} feature extraction method under various types of <b>noisy</b> <b>environments.</b>|$|R
5000|$|Reducing of {{background}} noise level increases the user’s comfort (especially in <b>noisy</b> <b>environments,</b> e.g. on the street).|$|R
2500|$|Duration is {{perceived}} as how [...] "long" [...] or [...] "short" [...] a sound is and relates to onset and offset signals created by nerve responses to sounds. The duration of a sound usually lasts {{from the time the}} sound is first noticed until the sound is identified as having changed or ceased. Sometimes this is not directly related to the physical duration of a sound. For example; in a <b>noisy</b> <b>environment,</b> gapped sounds (sounds that stop and start) can sound as if they are continuous because the offset messages are missed owing to disruptions from noises in the same general bandwidth. This can be of great benefit in understanding distorted messages such as radio signals that suffer from interference, as (owing to this effect) the message is heard as if it was continuous. Figure 2 gives an example of duration identification. When a new sound is noticed (see Figure 2, Green arrows), a sound onset message is sent to the auditory cortex. When the repeating pattern is missed, a sound offset messages is sent.|$|E
5000|$|In a <b>noisy</b> <b>environment,</b> {{detecting}} transitions is less error-prone than comparing signal levels {{against a}} threshold.|$|E
5000|$|... #Caption: A clip-on tuner {{attaches}} to the instrument and senses the vibrations from the instrument, even in a <b>noisy</b> <b>environment.</b>|$|E
40|$|This paper {{proposes a}} new {{environmental}} noise classification using {{principal component analysis}} (PCA) for robust speech recognition. Once the type of noise is identified, speech recognition performance can be enhanced by selecting the identified noise specific acoustic model. The proposed model applies PCA {{to a set of}} noise features, and results from PCA are used by a pattern classifier for noise classification. Instead of including both clean and <b>noisy</b> <b>environments</b> in a single classifier, two-step classification is introduced by separating the clean from <b>noisy</b> <b>environments</b> and then identifying the type of <b>noisy</b> <b>environments.</b> The proposed model is evaluated with four types of noise: white, pink, babble, and car from NOISEX- 92 and shows a promising result regardless of signal-to-noise ratio (SNR). 1...|$|R
50|$|The {{computation}} {{process is}} executed using a provided simulator. <b>Noisy</b> <b>environments</b> can be simulated using {{parameters of the}} simulator.|$|R
40|$|Based on {{biological}} selective attention mechanism, a new algorithm is developed to improve recognition accuracy of isolated speeches in <b>noisy</b> <b>environments.</b> The attention adaption algorithm utilizes the gradient-descent algorithm with the error back-propagation rule. With a newly-dened error measure at the input domain after the attention adaptation, the developed algorithm demonstrated high recognition rates for isolated Korean speeches in <b>noisy</b> <b>environments.</b> 1 Introduction The {{poor performance in}} <b>noisy</b> <b>environments</b> prevents current speech recognition systems from the popularity in real world. Although noise-robust feature extractions based on auditory models demonstrated some imporvements in recognition rates, they suer from enormous computational requrirements [1, 2]. In constrast to these diculties, human can easily listen to desired speech signals against heavy background noises. This so-called `cocktail party phenomenon' is the outcomes of the `selective attention', the capabi [...] ...|$|R
50|$|Quantum {{illumination}} is {{a paradigm}} that uses quantum entanglement beneficially {{even if the}} original entanglement is completely destroyed by a lossy and <b>noisy</b> <b>environment.</b>|$|E
50|$|In Hong Kong, sync {{sound was}} not widely used until the 1990s, as the {{generally}} <b>noisy</b> <b>environment</b> and lower production budgets {{made such a}} method impractical.|$|E
5000|$|As the {{viewfinder}} {{does not go}} dark, there is no visual indication that the shutter has fired. This {{could be a problem}} in a <b>noisy</b> <b>environment</b> where the shutter cannot be heard.|$|E
40|$|In this paper, we {{describe}} a new speech/non-speech classification method that improves the endpoint detection performance for speech recognition in <b>noisy</b> <b>environments.</b> The proposed method uses multiple features {{to increase the}} robustness in <b>noisy</b> <b>environments,</b> and the classification and regression tree(CART) technique is applied to effectively combine these multiple features for classification of each frame. We evaluate {{the performance of the}} proposed method by conducting speech/non-speech classification experiments on noisy speech. We also investigate the importance of various features on speech/non-speech classification in <b>noisy</b> <b>environments</b> In particular, the proposed method is applies to the endpoint detection algorithm for isolated speech recognition of voicedialing cellular phone. We simulate the speech recognition experiments in various noise environments, and the effects of proposed method on speech recognition performance are evaluated. 1...|$|R
5000|$|Cutting through noise: Placing the Wireless Mic near a {{sound source}} {{isolates}} that specific sound in <b>noisy</b> <b>environments</b> {{or from a}} distance.|$|R
40|$|People can {{comprehend}} speech even in <b>noisy</b> <b>environments.</b> Yet, {{the same}} task for machines still {{remains to be}} an elusive ambition. In this paper, by implementing a speech recognition prototype as proof of concept for Volvo Construction Equipment, we illustrate possibility of voice-commanding construction machines in heavy <b>noisy</b> <b>environments.</b> The findings of our research {{are not limited to}} Volvo Construction Equipment, and this paper can be studied as a guideline for boosting noise robustness of speech recognition applications...|$|R
50|$|The {{operator}} possesses average {{experience for}} this role. The individual is in a control room {{that has a}} relatively <b>noisy</b> <b>environment</b> and poor lighting. There is a time window of five minutes for the required task.|$|E
50|$|The {{code was}} {{developed}} from the need to communicate via poor-quality radio links in the <b>noisy</b> <b>environment</b> of the aircraft then in service with the SAF. It {{was used by the}} SAF from around the start of the Second World War until 1998.|$|E
50|$|In {{military}} and non-military usage in German and Spanish, a casino or kasino is an officers' mess. In Italian—the source-language of the word—a casino {{is either a}} brothel, a mess, or a <b>noisy</b> <b>environment,</b> while a gaming house is called a casinò.|$|E
30|$|This article {{presented}} a psychoacoustical masking and critical band variance normalization based spectral subtraction approach {{to improve the}} speech recognition performance in <b>noisy</b> <b>environments.</b>|$|R
50|$|A noise-canceling {{microphone}} is {{a microphone}} {{that is designed}} to filter ambient noise from the desired sound, which is especially useful in <b>noisy</b> <b>environments.</b>|$|R
40|$|Based on {{biological}} selective attention mechanism, a new algorithm {{was developed to}} improve recognition accuracy of isolated speeches in <b>noisy</b> <b>environments.</b> The attenuating "early filtering" model was implemented by inserting an attention layer just after the input layer. Attention gains, i. e., one-to-one synaptic weights between the original sensor input vector and the attended input vector at the attention layer, were adapted with the error backpropagation algorithm. After attention adaptation, {{the distance between the}} original sensor input and the attended vectors became a confidence measure for classification. The developed algorithm demonstrated high recognition rates for isolated Korean words in <b>noisy</b> <b>environments.</b> INTRODUCTION Speech recognition has been investigated for a while, and demonstrated some success for clean speeches. However, poor performance in <b>noisy</b> <b>environments</b> prevents current speech recognition systems from popularity in real world. There have been 3 [...] ...|$|R
50|$|One {{simple method}} for {{checking}} earmuff fit is to lift {{one or both}} muffs away from the head while in a <b>noisy</b> <b>environment.</b> If the noise is considerably louder with the adjustment, then the earmuffs are providing at least some degree of noise reduction.|$|E
50|$|Then {{the orbital}} {{position}} data, or ephemeris, from the navigation message {{is used to}} calculate precisely where the satellite was {{at the start of the}} message. A more sensitive receiver will potentially acquire the ephemeris data more quickly than a less sensitive receiver, especially in a <b>noisy</b> <b>environment.</b>|$|E
50|$|Following the {{acquisition}} of Wavion Wireless in 2011 Alvarion has been focused in delivering Wi-Fi based platforms supporting the latest IEEE 802.11ac standard. The first Wi-Fi platform was WBS supporting IEEE 802.11g with the first beamforming technology. Alvarion developed a noise mitigation algorithm provision continues service in a <b>noisy</b> <b>environment.</b>|$|E
3000|$|... • The mix 4 {{has much}} stable result {{than any other}} {{mixtures}} in most <b>noisy</b> <b>environments</b> using the phoneme recognition method based on HMM/GMM hybrid model.|$|R
3000|$|According to the {{obtained}} results, one {{can conclude}} that the conventional SV system is quite sensitive to high Gaussian noise. In <b>noisy</b> <b>environments</b> especially for [...]...|$|R
50|$|In quiet conditions, speech {{discrimination}} is {{no worse than}} normal hearing in those with partial deafness; however, in <b>noisy</b> <b>environments</b> speech {{discrimination is}} almost always severe.|$|R
