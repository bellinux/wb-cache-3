26|0|Public
40|$|Continuing bug {{reports and}} {{exploits}} in hypervisors indicate that hypervisors face similar integrity threats as tradition software. Previous approaches {{to protect a}} hypervisor that utilize hardware features {{are not easy to}} be extended. Besides, they mainly focus on code or control data integrity, without pay much attention to protecting <b>non-control</b> <b>data.</b> In this paper, we present HyperVerify, a novel architecture to monitor hypervisor <b>non-control</b> <b>data</b> using a trusted VM. Since a VM cannot directly access a hypervisor's memory, HyperVerify programs a popular device driver to read the hypervisor's hardware state in the trusted VM. Then a memory analysis library is used to translate the low-level hardware state into the high level hypervisor context. Several monitoring processes use such context to monitor hypervisor <b>non-control</b> <b>data</b> integrity. Each of the processes is responsible for monitoring one kind of <b>non-control</b> <b>data.</b> It is flexible for HyperVerify to support monitoring new kinds of data structure. The experimental evaluation of our prototype shows that HyperVerify incurs at most 4 % performance overhead to end users. Continuing bug reports and exploits in hypervisors indicate that hypervisors face similar integrity threats as tradition software. Previous approaches to protect a hypervisor that utilize hardware features are not easy to be extended. Besides, they mainly focus on code or control data integrity, without pay much attention to protecting <b>non-control</b> <b>data.</b> In this paper, we present HyperVerify, a novel architecture to monitor hypervisor <b>non-control</b> <b>data</b> using a trusted VM. Since a VM cannot directly access a hypervisor's memory, HyperVerify programs a popular device driver to read the hypervisor's hardware state in the trusted VM. Then a memory analysis library is used to translate the low-level hardware state into the high level hypervisor context. Several monitoring processes use such context to monitor hypervisor <b>non-control</b> <b>data</b> integrity. Each of the processes is responsible for monitoring one kind of <b>non-control</b> <b>data.</b> It is flexible for HyperVerify to support monitoring new kinds of data structure. The experimental evaluation of our prototype shows that HyperVerify incurs at most 4 % performance overhead to end users...|$|E
40|$|Hypervisors are {{becoming}} a widespread virtualisation layer in current computer systems. Recent successful attacks against hypervisors indicate that they face the similar integrity threats as traditional operating systems. Current approaches that secure hypervisors mainly focus on code or control-data integrity, without paying attention to <b>non-control</b> <b>data</b> integrity. In this study the authors construct attacks that target hypervisor <b>non-control</b> <b>data</b> to demonstrate which types of data within the Xen hypervisor are critical to system security. It shows privilege, resource utilisation and security policy related data are vulnerable to return-oriented programming or DMA attacks. By modifying their values from one to another, the whole system's performance will be affected. By discussing current approaches that secure hypervisors, which are not suitable for <b>non-control</b> <b>data,</b> the work is to motivate new innovation in this area to protect them. Hypervisors {{are becoming}} a widespread virtualisation layer in current computer systems. Recent successful attacks against hypervisors indicate that they face the similar integrity threats as traditional operating systems. Current approaches that secure hypervisors mainly focus on code or control-data integrity, without paying attention to <b>non-control</b> <b>data</b> integrity. In this study the authors construct attacks that target hypervisor <b>non-control</b> <b>data</b> to demonstrate which types of data within the Xen hypervisor are critical to system security. It shows privilege, resource utilisation and security policy related data are vulnerable to return-oriented programming or DMA attacks. By modifying their values from one to another, the whole system's performance will be affected. By discussing current approaches that secure hypervisors, which are not suitable for <b>non-control</b> <b>data,</b> the work is to motivate new innovation in this area to protect them...|$|E
40|$|Abstract—Rootkits affect system {{security}} by modifying kernel data structures {{to achieve a}} variety of malicious goals. While early rootkits modified control data structures, such as the system call table and values of function pointers, recent work has demonstrated rootkits that maliciously modify <b>non-control</b> <b>data.</b> Most prior techniques for rootkit detection have focused solely on detecting control data modifications and, therefore, fail to detect such rootkits. This article presents a novel technique to detect rootkits that modify both control and <b>non-control</b> <b>data.</b> The main idea is to externally observe {{the execution of the}} kernel during an inference phase and hypothesize invariants on kernel data structures. A rootkit detection phase uses these invariants as specifications of data structure integrity. During this phase, violation of invariants indicates an infection. We have implemented Gibraltar, a prototype tool that infers kernel data structure invariants and uses them to detect rootkits. Experiments show that Gibraltar can effectively detect previously-known rootkits, including those that modify <b>non-control</b> <b>data</b> structures. Index Terms—Kernel-level rootkits, <b>non-control</b> <b>data</b> attacks, invariant inference, static and dynamic program analysis. ...|$|E
40|$|BinArmor {{is a novel}} {{technique}} to protect existing C binaries from memory corruption attacks on both control data and <b>non-control</b> <b>data.</b> Without access to source code, <b>non-control</b> <b>data</b> attacks cannot be detected with current techniques. Our approach hardens binaries against both kinds of overflow, without requiring the programs’ source or symbol tables. We show that BinArmor is able to stop real attacks—including the recent noncontrol data attack on Exim. Moreover, we did not incur a single false positive in practice. On the downside, the current overhead of BinArmor is high—although no worse than competing technologies like taint analysis that do not catch attacks on <b>non-control</b> <b>data.</b> Specifically, we measured an overhead of 70 % for gzip, 16 %- 180 % for lig[URL] and 190 % for the nbench suite. ...|$|E
40|$|Kernel-level {{rootkits}} affect {{system security}} by modifying key kernel data structures {{to achieve a}} variety of malicious goals. While early rootkits modified control data structures, such as the system call table and values of function pointers, recent work has demonstrated rootkits that maliciously modify <b>non-control</b> <b>data.</b> Prior techniques for rootkit detection fail to identify such rootkits either because they focus solely on detecting control data modifications or because they require elaborate, manually-supplied specifications to detect modifications of <b>non-control</b> <b>data.</b> This paper presents a novel rootkit detection technique that automatically detects rootkits that modify both control and <b>non-control</b> <b>data.</b> The key idea is to externally observe {{the execution of the}} kernel during a training period and hypothesize invariants on kernel data structures. These invariants are used as specifications of data structure integrity during an enforcement phase; violation of these invariants indicates the presence of a rootkit. We present the design and implementation of Gibraltar, a tool that uses the above approach to infer and enforce invariants. In our experiments, we found that Gibraltar can detect rootkits that modify both control and <b>non-control</b> <b>data</b> structures, and that its false positive rate and monitoring overheads are negligible. 1...|$|E
40|$|Most {{malicious}} attacks compromise {{system security}} through memory corruption exploits. Recently proposed techniques attempt to defeat these attacks by protecting program control data. We have constructed {{a new class}} of attacks that can compromise network applications without tampering with any control data. These <b>non-control</b> <b>data</b> attacks represent a new challenge to system security. In this paper, we propose an architectural technique to defeat both control data and <b>non-control</b> <b>data</b> attacks based on the notion of pointer taintedness. A pointer is said to be tainted if user input can be used as the pointer value. A security attack is detected whenever a tainted value is dereferenced during program execution. The proposed architecture is implemented on the SimpleScalar processor simulator and is evaluated using synthetic programs as well as real-world network applications. Our technique can effectively detect both control data and noncontrol data attacks, and it offers better security coverage than current methods. The proposed architecture is transparent to existing programs...|$|E
40|$|Abstract. This paper {{introduces}} YARRA, {{a conservative}} extension to C to protect applications from <b>non-control</b> <b>data</b> attacks. YARRA programmers specify their data integrity requirements by declaring critical data types and ascribing these critical types to important data structures. YARRA guarantees that such critical data is only written through pointers with the given static type. Any attempt {{to write to}} critical data through a pointer with an invalid type (perhaps because of a buffer overrun) is detected dynamically. We formalize YARRA’s semantics and prove the soundness of a program logic designed for use with the language. A key contribution {{is to show that}} YARRA’s semantics are strong enough to support sound local reasoning and the use of a frame rule, even across calls to unknown, unverified code. We eval-uate a prototype implementation of a compiler and runtime system for YARRA by using it to harden four common server applications against known <b>non-control</b> <b>data</b> vulnerabilities. We show that YARRA successfully defends the applications against these attacks. In our initial experiments, we find that the performance impact of YARRA is small, provided the amount of critical data is small and the application is not compute intensive...|$|E
40|$|Vulnerabilities in {{software}} programs {{made possible the}} widespread and frequent occurrence of malware outbreaks. Extensive research {{has been devoted to}} detection and prevention of control hijacking attacks due to their prevalence. The <b>non-control</b> <b>data</b> attacks are not yet so prevalent, but, as more and more avenues are closed for the malicious software authors they will gain in popularity. Our paper presents a defense mechanism against <b>non-control</b> <b>data</b> attacks. The solution we propose is to store security sensitive data in a special protected storage. The programmer is responsible to mark data appropriately using our C language extension. The memory pages where security critical data is allocated are marked as read-only. Updates of this data are allowed only in special marked sections and the compiler will generate the function calls necessary to change the permissions to memory pages. Our solution offers strong security guaranties by not allowing any writes of protected data with the exception of very short intervals. This defense must be used together with a defense against control data attacks, which prevents attacks like code injection, return-tolibc. More general the control data attack must prevent system calls to be injected and system calls to be skipped. ...|$|E
40|$|Minos is a {{microarchitecture}} that implements Biba's lowwater -mark {{integrity policy}} on individual words of data. Months of testing have revealed a robust system that stops attacks which corrupt control data to hijack program control flow. The low-water-mark policy is orthogonal {{to the memory}} model so that it works with existing software and middleware. The key is that Minos tracks the integrity of all data, but protects control flow by checking this integrity when a program uses the data for control transfer. Existing policies, in contrast, need to differentiate between control and <b>non-control</b> <b>data</b> a priori...|$|E
40|$|This paper evaluates pointer tainting, an {{incarnation}} of Dynamic Information Flow Tracking (DIFT), which has recently {{become an important}} technique in system security. Pointer tainting {{has been used for}} two main purposes: detection of privacy-breaching malware (e. g., trojan keyloggers obtaining the characters typed by a user), and detection of memory corruption attacks against <b>non-control</b> <b>data</b> (e. g., a buffer overflow that modifies a user’s privilege level). In both of these cases the attacker does not modify control data such as stored branch targets, so the control flow of the target program does not change. Phrased differently, in terms of instructions executed, the program behaves ‘normally’. As a result, these attacks are exceedingly difficult to detect. Pointer tainting {{is considered one of the}} only methods for detecting them in unmodified binaries. Unfortunately, almost all of the incarnations of pointer tainting are flawed. In particular, we demonstrate that the application of pointer tainting to the detection of keyloggers and other privacybreaching malware is problematic. We also discuss whether pointer tainting is able to reliably detect memory corruption attacks against <b>non-control</b> <b>data.</b> We found that pointer tainting generates itself the conditions for false positives. We analyse the problems in detail and investigate various ways to improve the technique. Most have serious drawbacks in that they are either impractical (and incur many false positives still), and/or cripple the technique’s ability to detect attacks. In conclusion, we argue that depending on architecture and operating system, pointer tainting may have som...|$|E
40|$|Memory {{corruption}} attacks {{remain the}} primary threat for computer security. Information flow tracking or taint analysis {{has been proven}} to be effective against most memory corruption attacks. However, there are two shortcomings with current taint analysis based techniques. First, these techniques cause application slowdown by about 76 % thereby limiting their practicality. Second, these techniques cannot handle <b>non-control</b> <b>data</b> attacks i. e., attacks that do not overwrite control data such as return address, but instead overwrite critical application configuration data or user identity data. In this work, to address these problems, we describe a coarse-grained taint analysis technique that uses information flow tracking {{at the level of}} application data objects. We propagate a one-bit taint over each application object that is modified by untrusted data thereby reducing the taint management overhead considerably. We performed extensive experimental evaluation of our approach and show that it can detect all critical attacks such as buffer overflows, and format string attacks, including <b>non-control</b> <b>data</b> attacks. Unlike the currently known approaches that can detect such a wide range of attacks, our approach does not require the source code or any hardware extensions. Run-time performance overhead evaluation shows that, on an average, our approach causes application slowdown by only 37 % which is an order of magnitude improvement over existing approaches. Finally, since our approach performs run-time binary instrumentation, it is easier to integrate it with existing applications and systems...|$|E
30|$|In DTrace prototype, {{disabling}} Intel PT {{is implemented}} in statically linked destructors. The destructor is invoked automatically {{after the program}} leaves main function. However, the destructor still has a return operation back to C runtime provided by libc. DTrace focuses on data integrity enforcement. We assume a control flow integrity (CFI) enforcement is deployed. Under CFI assumption, the attacker cannot control the program execution directly into the trap operation in the destructor into kernel to disable Intel PT, and jump back to continue program execution without instruction tracing. Furthermore, DTrace works as an enhancement to CFI system as <b>non-control</b> <b>data</b> attacks are a great threat to security-critical applications.|$|E
40|$|We {{introduce}} Minos, a microarchitecture that implements Biba's low-water-mark {{integrity policy}} on individual words of data. Minos stops attacks that corrupt control data to hijack program control flow but is orthogonal {{to the memory}} model. Control data is any data which is loaded into the program counter on control flow transfer, or any data used to calculate such data. The key is that Minos tracks the integrity of all data, but protects control flow by checking this integrity when a program uses the data for control transfer. Existing policies, in contrast, need to differentiate between control and <b>non-control</b> <b>data</b> a priori, a task made impossible by coercions between pointers and other data types such as integers in the C language...|$|E
40|$|Current taint {{checking}} architectures monitor tainted {{data usage}} mainly with control transfer instructions. An alarm is raised once the program counter becomes tainted. However, such architectures are not effective against <b>non-control</b> <b>data</b> attacks. In this paper {{we present a}} generic instructionlevel runtime taint checking architecture for handling noncontrol data attacks. Under our architecture, instructions are classified as either Taintless-Instructions or Tainted-Instructions prior to program execution. An instruction is called a Tainted-Instruction if {{it is supposed to}} deal with tainted data. Otherwise it is called a Taintless-Instruction. A security alert is raised whenever a Taintless-Instruction encounters tainted data at runtime. The proposed architecture is implemented on the SimpleScalar simulator. The preliminary results from experiments on SPEC CPU 2000 benchmarks show that there are a significant amount of Taintless-Instructions. We also demonstrate effective usages of our architecture to detect buffer overflow and format string attacks...|$|E
40|$|Generally speaking, {{malicious}} code leverages hooks within {{a system to}} divert the control flow. Without them, an attacker is blind to the events occurring in the system, rendering her unable to perform malicious activities (e. g., hiding of files or capturing of keystrokes). However, while hooks {{are an integral part}} of modern attacks, they are at the same time one of their biggest weaknesses: Even the most sophisticated attack can be easily identified if one of its hooks is found. In spite of this fact, hooking mechanisms have remained almost unchanged over the last years and still rely on the persistent modification of code or control data to divert the control flow. As a consequence, hooks represent an abnormality within the system that is permanently evident and can in many cases easily be detected as the hook detection mechanisms of recent years amply demonstrated. In this paper, we propose a novel hooking concept that we refer to as dynamic hooking. Instead of modifying persistent control data permanently, this hooking mechanisms targets transient control data such as return addresses at run-time. The hook itself will thereby reside within <b>non-control</b> <b>data</b> and remains hidden until it is triggered. As a result, there is no evident connection between the hook and the actual control flow change, which enables dynamic hooks to successfully evade existing detection mechanisms. To realize this idea, dynamic hooks make use of exploitation techniques to trigger vulnerabilities at run-time. Due to this approach, dynamic hooks cannot only be used to arbitrarily modify the control flow, but can also be applied to conduct <b>non-control</b> <b>data</b> attacks, which makes them more powerful than their predecessors. We implemented a prototype that makes uses of static program slicing and symbolic execution to automatically extract paths for dynamic hooks that can then be used by a human expert for their realization. To demonstrate this, we used the output provided by our prototype to implement concrete examples of dynamic hooks for both modern Linux and Windows kernels...|$|E
40|$|Modern {{stealthy}} exploits {{can achieve}} attack goals without introducing illegal control flows, e. g., tampering with <b>non-control</b> <b>data</b> {{and waiting for}} the modified data to propa-gate and alter the control flow legally. Existing program anomaly detection systems focusing on legal control flow at-testation and short call sequence verification are inadequate to detect such stealthy attacks. In this paper, we point out the need to analyze program execution paths and discover event correlations in large-scale execution windows among millions of instructions. We propose an anomaly detection approach with two-stage machine learning algorithms to rec-ognize diverse normal call-correlation patterns and detect program attacks at both inter- and intra-cluster levels. We implement a prototype of our approach and demonstrate its effectiveness against three real-world attacks and four syn-thetic anomalies with less than 0. 01 % false positive rates and 0. 1 ~ 1. 3 ms analysis overhead per behavior instance (1 k to 50 k function or system calls) ...|$|E
40|$|Anomaly {{detection}} {{has been}} popular {{for a long}} time due to its ability to detect novel attacks. However, its practical deployment has been limited due to false positives. Taint-based techniques, on the other hand, can avoid false positives for many common exploits (e. g., code or script injection), but their applicability to a broader range of attacks (<b>non-control</b> <b>data</b> attacks, path traversals, race condition attacks, and other unknown attacks) is limited by the need for accurate policies on the use of tainted data. In this paper, we develop a new approach that combines the strengths of these approaches. Our combination is very effective, detecting attack types that have been problematic for taint-based techniques, while significantly cutting down the false positives experienced by anomaly detection. The intuitive justification for this result is that a successful attack involves unusual program behaviors that are exercised by an attacker. Anomaly detection identifies unusual behaviors, while fine-grained taint can filter out behaviors that do not seem controlled by attacker-provided data...|$|E
40|$|Computer {{security}} is severely threatened by memory corruption vulnerabilities, such as buffer overflows and format string bugs. Information flow tracking or taint analysis {{has proved to}} be one of the most effective techniques in defending against a wide range of such attacks. It works by tracking the source of each byte of data that is manipulated by the program, and detects attacks that overwrites pointers with untrusted data. However, current taint analysis based approaches are not very practical as they either require source code or non-trivial hardware extensions or incur prohibitive run time overheads. More importantly, they do not defend against <b>non-control</b> <b>data</b> attacks, making them susceptible to privilege escalation. In this paper, we propose Object Level Dynamic Taint Analysis, a very low-overhead information flow tracking technique. We propagate taint on contiguous chunks of memory designated as objects, rather than individual words of memory. Our experiments with several exploits show that Object Level Dynamic Taint Analysis effectively detects various types of memory corruption attacks, including noncontrol data attacks. Also, as it incurs modest performance overhead, it is practical for use in production environments...|$|E
40|$|We {{introduce}} Minos, a microarchitecture that implements Biba’s low-water-mark {{integrity policy}} on individual words of data. Minos stops attacks that corrupt control data to hijack program control flow but is orthogonal {{to the memory}} model. Control data is any data which is loaded into the program counter on control flow transfer, or any data used to calculate such data. The key is that Minos tracks the integrity of all data, but protects control flow by checking this integrity when a program uses the data for control transfer. Existing policies, in contrast, need to differentiate between control and <b>non-control</b> <b>data</b> a priori, a task made impossible by coercions between pointers and other data types such as integers in the C language. Our implementation of Minos for Red Hat Linux 6. 2 on a Pentium-based emulator is a stable, usable Linux system on the network on which we are currently running a web server [3]. Our emulated Minos systems running Linux and Windows have stopped several actual attacks. We present a microarchitectural implementation of Minos that achieves negligible impact on cycle time with a small investment in die area, and {{minor changes to the}} Linux kernel to handle the tag bits and perform virtual memory swapping. ...|$|E
40|$|Abstract—The {{traditional}} {{virtual machine}} usage model advocates placing security mechanisms in a trusted VM layer {{and letting the}} untrusted guest OS run unaware {{of the presence of}} virtualization. In this work we challenge this traditional model and propose a collaboration approach between a virtualizationaware operating system and a VM layer to prevent tampering against kernel code and data. Our integrity model is a relaxed version of Biba’s and the main idea is to have all attempted writes into kernel code and data segments checked for validity at VM level. The OS-VM collaboration bridges the semantic gap between tracing low integrity objects at OS-level (files, processes, modules, allocated areas) and architecture-level (memory and registers). We have implemented this approach in a proofof-concept prototype and have successfully tested it against 6 rootkits (including a <b>non-control</b> <b>data</b> attack) and 4 realworld benign LKM/drivers. All rootkits were prevented from corrupting kernel space and no false positive was triggered for benign modules. Performance measurements show that the average overhead to the VM for the OS-VM communication is low (7 %, CPU benchmarks). The greatest overhead is caused by the memory monitoring module inside the VM: 1. 38 X alone and 1. 46 X when combined with the OS-VM communication. For OS microbenchmarks the slowdown for the OS-VM communication was 1. 16 X on average. I...|$|E
40|$|Abstract. Over {{the past}} several years, US-CERT advisories, {{as well as most}} {{critical}} updates from software vendors, have been due to memory corruption vulnerabilities such as buffer overflows, heap overflows, etc. Several techniques have been developed to defend against the exploitation of these vulnerabilities, with the most promising defenses being based on randomization. Two randomization techniques have been explored so far: address space randomization (ASR) that randomizes the location of objects in virtual memory, and instruction set randomization (ISR) that randomizes the representation of code. We explore a third form of randomization called data space randomization (DSR) that randomizes the representation of data stored in program memory. Unlike ISR, DSR is effective against <b>non-control</b> <b>data</b> attacks as well as code injection attacks. Unlike ASR, it can protect against corruption of nonpointer data as well as pointer-valued data. Moreover, DSR provides a much higher range of randomization (typically 2 32 for 32 -bit data) as compared to ASR. Other interesting aspects of DSR include (a) it does not share a weakness common to randomization-based defenses, namely, susceptibility to information leakage attacks, and (b) it is capable of detecting some exploits that are missed by full bounds-checking techniques, e. g., some of the overflows from one field of a structure to the next field. Our implementation results show that with appropriate design choices, DSR can achieve a performance overhead in the range of 5 % to 30 % for a range of programs...|$|E
40|$|Data flow {{integrity}} enforcement overview Data {{flow integrity}} enforcement uses static analysis to computer a data flow graph. Program excute following such data – flow graph. Data flow integrity enforcement can be automatically applied to C & C++ without any mofification. It has no false positive and low overhead Compare other proposals to prevent attacks on software: • Its overhead is lower; • Not defend from attacks that overwrite specific targets or {{specific types of}} Vulnerabilities, but a broad class of attacks and prevent both control data attacks and <b>non-control</b> <b>data</b> attacks using data-flow integrity; • No false positives. TU Dresden, 04,Jun, 2007 Securing software by enforcing data-flow integrity Folie 3 von 23 Generel technology about data-flow integrity enforcement How to ensure runtime data flow integrity? The implement uses reaching definitions analysis to compute a static data-flow graph to enforce data-flow integrity at runtime. Maintains a table with the identifier of the last instruction to write to each memory positon. Each memory position Identifier of the last instruction to write • Only compute the set of instructions that may write the value to low overhead and increase performance • We need {{check to make sure}} whether the value read from the table is computed by the static analysis or not. If not, we raise an exception • Update the table before every write • Prevent the attacker from tampering with the table TU Dresden, 04,Jun, 2007 Securing software by enforcing data-flow integrity Folie 4 von 23 Reduce overhead Compute equivalence classes of instructions and assigns the same identifier to all the instructions in the same Class. Identifiers for different equivalence classes of instruction Different equivalence classes of instructio...|$|E
40|$|Modern {{applications}} contain {{libraries and}} components written by different people {{at different times}} in different languages, often including unsafe languages like C or C++. As a result, one bug, such as a buffer overflow, in any component, can compromise the security and reliability of every other component. To help mitigate these problems, we introduce YARRA, a conservative extension to C with mechanisms for enforcing data integrity and partial safety, even when code is linked against unknown C libraries or binaries. YARRA programmers specify their data integrity requirements by declaring critical data types and ascribing these critical types to important data structures. YARRA guarantees that such critical data is only written through pointers with the given static type. Any attempt to write to critical data through a pointer with an invalid type (perhaps because of a buffer overrun) is detected dynamically. We formalize YARRA’s semantics and prove the soundness of a program logic designed for use with the language. A key con-tribution {{is to show that}} YARRA’s semantics are strong enough to support sound local reasoning and the use of a frame rule, even across calls to unknown, unverified code. We also demonstrate that YARRA’s semantics can be implemented in several different ways, with different performance and pragmatic tradeoffs. In one imple-mentation, we perform a source-to-source program transformation to ensure correct execution. In a second implementation, we do not rely upon having access to the entire source code, but instead use conventional hardware permissions to protect critical data. We eval-uate our implementations using SPEC benchmarks to understand their performance. Additionally, we apply YARRA to four common applications with known <b>non-control</b> <b>data</b> vulnerabilities. We are able to use YARRA to defend against these attacks while sustaining a negligible impact on their end-to-end performance. 1...|$|E
40|$|The {{most common}} {{cyber-attack}} vector is exploit of software vulnerability. Despite much efforts toward building secure software, software systems of even modest complexity still routinely have serious vulnerabilities. More alarmingly, even the {{trusted computing base}} (e. g. OS kernel) still contains vulnerabilities that would allow attackers to subvert security mechanisms such as the application sandbox on smartphones. Among all vulnerabilities, memory corruption {{is one of the}} most ancient, prevalent, and devastating vulnerabilities. This thesis proposed three projects on mitigating this threat. There are three popular ways to exploit a memory corruption vulnerability [...] -attacking the code (a. k. a. code injection attack), the control data (a. k. a. control-flow hijacking attack), and the <b>non-control</b> <b>data</b> (a. k. a. data-oriented attack). Theoretically, code injection attack can be prevented with the executable XOR writable policy; but in practice, this policy is undermined by another important technique [...] -dynamic code generation (e. g. JIT engines). In the first project, we first showed that this conflict is actually non-trivial to resolve, then we introduced a new design paradigm to fundamentally solve this problem, by relocating the dynamic code generator to a separate process. In the second project, we focused on preventing data-oriented attacks against operating system kernel. Using privilege escalation attacks as an example, we (1) demonstrated that data-oriented attacks are realistic threats and hard to prevent; (2) discussed two important challenges for preventing such attacks (i. e., completeness and performance); and (3) presented a system that combines program analysis techniques and system designs to solve these challenges. During these two projects, we found that lacking sufficient hardware support imposes many unnecessary difficulties in building robust and efficient defense mechanisms. In the third project, we proposed HDFI (hardware-assisted data-flow isolation) to overcome this limitation. HDFI is a new fine-grained isolation mechanism that enforces isolation at the machine word granularity, by virtually extending each memory unit with an additional tag that is defined by data-flow. This capability allows HDFI to enforce a variety of security models such as the Biba Integrity Model and the Bell [...] LaPadula Model. For demonstration, we developed and ported several security mechanisms to leverage HDFI, including stack protection, standard library enhancement, virtual function table protection, code pointer protection, kernel data protection, and information leak prevention. The evaluation results showed that HDFI is easy to use, imposes low performance overhead, and allows us to create simpler and more secure solutions. Ph. D...|$|E

