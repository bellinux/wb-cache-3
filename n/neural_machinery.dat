59|5|Public
2500|$|In V1 {{the simple}} three-color {{segregation}} begins to break down. Many cells in V1 respond to {{some parts of}} the spectrum better than others, but this [...] "color tuning" [...] is often different depending on the adaptation state of the visual system. A given cell that might respond best to long wavelength light if the light is relatively bright might then become responsive to all wavelengths if the stimulus is relatively dim. Because the color tuning of these cells is not stable, some believe that a different, relatively small, population of neurons in V1 is responsible for color vision. These specialized [...] "color cells" [...] often have receptive fields that can compute local cone ratios. Such [...] "double-opponent" [...] cells were initially described in the goldfish retina by Nigel Daw; their existence in primates was suggested by David H. Hubel and Torsten Wiesel and subsequently proven by Bevil Conway. As Margaret Livingstone and David Hubel showed, double opponent cells are clustered within localized regions of V1 called blobs, and are thought to come in two flavors, red–green and blue–yellow. Red–green cells compare the relative amounts of red–green in one part of a scene with the amount of red–green in an adjacent part of the scene, responding best to local color contrast (red next to green). Modeling studies have shown that double-opponent cells are ideal candidates for the <b>neural</b> <b>machinery</b> of color constancy explained by Edwin H. Land in his retinex theory.|$|E
5000|$|Polger, T. 2004. <b>Neural</b> <b>Machinery</b> and Realization. Philosophy of Science. 71 (5): 997-1006.|$|E
5000|$|Lennie {{provided}} fundamental {{insights into}} the <b>neural</b> <b>machinery</b> of vision, especially how the eye communicates with the brain. His research [...] "sits at the interface between visual perception and visual physiology". He concentrated particularly on how the successive stages of the visual pathway from the eye and the brain’s cortex encode and represent information about the form and color of objects.|$|E
3000|$|To try to {{understand}} how neural modules hook together, it is also very helpful {{to look at the}} principles of brain development across multiple species. The papers (Murakami et al. 2005) and (Baslow 2011) are good examples of this kind of work. Understanding these principles also helps shape our view of how to build approximations to <b>neural</b> processing <b>machinery.</b> For example, what is a good minimal neural system which will exhibit some of the cognitive behaviors we see in small animals? Do we need models of working memory? Do we need emotional subcircuits? [...]...|$|R
40|$|Intelligent systems {{based on}} first-order logic {{on the one}} hand, and on {{artificial}} neural networks (also called connectionist systems) on the other, di#er substantially. It would be very desirable to combine the robust <b>neural</b> networking <b>machinery</b> with symbolic knowledge representation and reasoning paradigms like logic programming {{in such a way}} that the strengths of either paradigm will be retained. Current state-of-the-art research, however, fails by far to achieve this ultimate goal. As one of the main obstacles to be overcome we perceive the question how symbolic knowledge can be encoded by means of connectionist systems: Satisfactory answers to this will naturally lead the way to knowledge extraction algorithms and to integrated neural-symbolic systems...|$|R
40|$|Modeling a {{collection}} of similar regression or classification tasks can be improved by making the tasks `learn from each other'. In machine learning, this subject is approached through `multitask learning', where parallel tasks are modeled as multiple outputs of the same network. In multilevel analysis this is generally implemented through the mixed-effects linear model where a distinction is made between `fixed effects', which are {{the same for all}} tasks, and `random effects', which may vary between tasks. In the present article we will adopt a Bayesian approach in which some of the model parameters are shared (the same for all tasks) and others more loosely connected through a joint prior distribution that can be learned from the data. We seek in this way to combine the best parts of both the statistical multilevel approach and the <b>neural</b> network <b>machinery.</b> The standar...|$|R
5000|$|In this way, the bat modulates {{something}} that {{is relatively easy to}} control (the pulses it produces) while maintaining <b>neural</b> <b>machinery</b> that is sensitive to only a narrow range of frequencies. If the bat consistently produced the same pulse frequency as it approached the target, the echoes would increase way beyond this narrow range of sensitivity. This would result in the need for <b>neural</b> <b>machinery</b> that is extremely sensitive to a very wide range of frequencies, and more complicated neural computations. [...] These computations would entail a very specific determination of the exact change in the echo frequency relative to the expected echo frequency, and then that information would somehow need {{to be related to the}} properties and distance of the target. On the other hand, simply detecting the change that is made to the pulse frequency and relating that to target properties is a lot simpler, in terms of a neural computation. Therefore, the overall function of the DSC is to allow echoes to be analyzed within a narrow range of optimal sensitivity, which ultimately reduces the computational strain on the bat’s nervous system.|$|E
5000|$|In a 1997 Society for Neuroscience talk, Ramachandran {{hypothesized}} {{that there may}} be a neural basis for some religious experiences. He stated that [...] "There may be dedicated <b>neural</b> <b>machinery</b> in the temporal lobes concerned with religion. This may have evolved to impose order and stability on society." [...] Ramachandran described an experiment in which he measured the galvanic skin responses of two subjects who had experienced temporal lobe seizures. Ramachandran measured the subjects' responses to a mixture of religious, sexual and neutral words and images and found that religious words and images elicited an unusually high response. Ramachandran has also discussed his ideas about the neural basis of religion in a number of talks and in Phantoms In The Brain. He cautions that his ideas are tentative, and so far he has not published any research on this subject.|$|E
5000|$|While {{the human}} hand has unique {{anatomical}} features, including a longer thumb and fingers {{that can be}} controlled individually to a higher degree, the hands of other primates are anatomically similar and the dexterity of the human hand {{can not be explained}} solely on anatomical factors. The <b>neural</b> <b>machinery</b> underlying hand movements is a major contributing factor; primates have evolved direct connections between neurons in cortical motor areas and spinal motoneurons, giving the cerebral cortex monosynaptic control over the motoneurons of the hand muscles; placing the hands [...] "closer" [...] to the brain.The recent evolution of the human hand is thus {{a direct result of the}} development of the central nervous system, and the hand, therefore, is a direct tool of our consciousness — the main source of differentiated tactile sensations — and a precise working organ enabling gestures — the expressions of our personalities.|$|E
40|$|Intelligent systems {{based on}} first-order logic {{on the one}} hand, and on {{artificial}} neural networks (also called connectionist systems) on the other, differ substantially. Logic programs, for example, are highly recursive and well understood {{from the perspective of}} knowledge representation and reasoning: Their semantics has been studied extensively in the past, which makes it easy to encode problem specifications directly as programs. One reason for the success of artificial neural networks {{lies in the fact that}} they can be trained using raw data, and in some problem domains the generalization from the raw data made during the learning process turns out to be highly adequate for the problem at hand, even if the training data contains noise. Successful architectures, however, often do not use recursive (or recurrent) structures. Furthermore, the knowledge encoded by a trained neural network is only very implicitly represented, and no fully satisfactory methods for extracting this knowledge in symbolic form are currently known. It would be very desirable to combine the robust <b>neural</b> networking <b>machinery</b> with symbolic knowledge representation and reasoning paradigms like logic programming in such a way that the strengths of either paradigm will be retained. Current state-of-thear...|$|R
40|$|Modeling a {{collection}} of similar regression or classification tasks can be improved by making the tasks ‘learn from each other’. In machine learning, this subject is approached through ‘multitask learning’, where parallel tasks are modeled as multiple outputs of the same network. In multilevel analysis this is generally implemented through the mixed-effects linear model where a distinction is made between ‘fixed effects’, which are {{the same for all}} tasks, and ‘random effects’, which may vary between tasks. In the present article we will adopt a Bayesian approach in which some of the model parameters are shared (the same for all tasks) and others more loosely connected through a joint prior distribution that can be learned from the data. We seek in this way to combine the best parts of both the statistical multilevel approach and the <b>neural</b> network <b>machinery.</b> The standard assumption expressed in both approaches is that each task can learn equally well from any other task. In this article we extend the model by allowing more differentiation in the similarities between tasks. One such extension is to make the prior mean depend on higher-level task characteristics. More unsupervised clustering of tasks is obtained if we go from a single Gaussian prior to a mixture of Gaussians. This can be further generalized to a mixture of experts architecture with the gates depending on task characteristics. All three extensions are demonstrated through application both on an artificial data set and on two realworld problems, one a school problem and the other involving single-copy newspaper sales...|$|R
5000|$|In V1 {{the simple}} three-color {{segregation}} begins to break down. Many cells in V1 respond to {{some parts of}} the spectrum better than others, but this [...] "color tuning" [...] is often different depending on the adaptation state of the visual system. A given cell that might respond best to long wavelength light if the light is relatively bright might then become responsive to all wavelengths if the stimulus is relatively dim. Because the color tuning of these cells is not stable, some believe that a different, relatively small, population of neurons in V1 is responsible for color vision. These specialized [...] "color cells" [...] often have receptive fields that can compute local cone ratios. Such [...] "double-opponent" [...] cells were initially described in the goldfish retina by Nigel Daw; their existence in primates was suggested by David H. Hubel and Torsten Wiesel and subsequently proven by Bevil Conway. As Margaret Livingstone and David Hubel showed, double opponent cells are clustered within localized regions of V1 called blobs, and are thought to come in two flavors, red-green and blue-yellow. Red-green cells compare the relative amounts of red-green in one part of a scene with the amount of red-green in an adjacent part of the scene, responding best to local color contrast (red next to green). Modeling studies have shown that double-opponent cells are ideal candidates for the <b>neural</b> <b>machinery</b> of color constancy explained by Edwin H. Land in his retinex theory.|$|E
40|$|A {{possible}} neurobiological {{basis for}} the “oblique effect” {{is linked to the}} finding that more <b>neural</b> <b>machinery</b> is devoted to processing cardinal vs. oblique orientations in primary visual cortex (V 1). We used optical imaging to determine whether more territory is devoted to processing horizontal and vertical orientations than oblique orientations in owl monkey middle temporal visual area (MT), a visual area highly sensitive to moving stimuli. We found that more of MT was devoted to representing cardinal than oblique orientations, and that the anisotropy was more prominent in parts of MT representing central vision (≤ 10 °). Neural responses to orientations of 0 ° and 90 ° were also greater than those to 45 ° and 135 °. In comparison, an overrepresentation of cardinal orientations in the representation of central vision in owl monkey V 1 was relatively small and inconsistent. Our data could explain the greater sensitivity to motion discrimination when stimuli are moved along cardinal meridians and suggest that the <b>neural</b> <b>machinery</b> necessary to explain the motion oblique effect either originates in MT or is enhanced at this level...|$|E
40|$|A {{rapidly growing}} number of studies {{indicate}} that imagining or simulating possible future events depends on {{much of the same}} <b>neural</b> <b>machinery</b> as does remembering past events. One especially striking finding is that the medial temporal lobe (MTL), which has long been linked to memory function, appears to be similarly engaged during future event simulation. This paper focuses on the role of two MTL regions—the hippocampus and parahippocampal cortex—in thinking about the future and building mental simulations...|$|E
40|$|In {{brain mapping}} studies of sensory, cognitive, and motor operations, {{specific}} waveforms of dynamic neural activity are predicted based on theoretical models of human information processing. For example in event-related functional MRI (fMRI), the general linear model (GLM) is employed in mass-univariate analyses {{to identify the}} regions whose dynamic activity closely matches the expected waveforms. By comparison multivariate analyses based on PCA or ICA provide greater flexibility in detecting spatiotemporal properties of experimental data that may strongly support alternative neuroscientific explanations. We investigated conjoint multivariate and mass-univariate analyses that combine the capabilities to (1) verify activation of <b>neural</b> <b>machinery</b> we already understand and (2) discover reliable signatures of new <b>neural</b> <b>machinery.</b> We examined combinations of GLM and PCA that recover latent neural signals (waveforms and footprints) with greater accuracy than either method alone. Comparative results are illustrated with analyses of real fMRI data, adding to Monte Carlo simulation support. Copyright © 2006 J. R. Moeller and C. G. Habeck. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. 1...|$|E
40|$|Individuals {{differ in}} their {{susceptibility}} to simultaneous contrast. Are the underlying differences in <b>neural</b> <b>machinery</b> conserved across different stimulus dimensions? We measured {{the extent to which}} 101 subjects perceived simultaneous contrast on the dimensions of luminance, colour, luminance contrast, colour contrast, orientation, spatial frequency, motion and numerosity. Individual differences showed re-test reliability for each dimension (0. 32 ICC(c, 1) 0. 78, p 0. 05), but susceptibility to simultaneous contrast, with a few exceptions, was not correlated across dimensions. Either susceptibility to contrast arises empirically from an individual's interactions with the environment, or it is genetically determined but independently for different dimensions...|$|E
40|$|Are faces {{processed}} {{differently from}} other complex visual stimuli? For {{this to be}} the case, three main criteria would have to be fulfilled: (1) face recognition would exhibit functional characteristics not found in the recognition of other visual stimuli, (2) the <b>neural</b> <b>machinery</b> that mediates face recognition would be anatomically separate from the neurons mediating general object recognition, and (3) faces would be represented differently from other visual stimuli at the neural level. This paper assesses the data bearing on these criteria and discusses whether they do indeed constitute evidence for a special face processing system...|$|E
40|$|Evolution brought {{brains and}} minds {{into a world}} {{initially}} devoid of inteUlgent life. The evolutionary process designed the <b>neural</b> <b>machinery</b> that generates in-tehgent behavior, and important insights into how this machinery works can be gained by understanding how evolution constructs organisms. This is the ratio-nale that underlies research in evolutionary psychology. Evolutionary psychology was founded on interloclang contributions from evolutionary biology, cognitive science, psychology, anthropology, and neuro-science. It reflects an attempt to think through, from first principles, how cur-rent knowledge from these various fields can be integrated into a single, consistent, sciennfic framework {{for the study of}} the mind and brain (Cosmide...|$|E
40|$|Numerous {{sources of}} {{evidence}} suggest that primate brains have special-purpose <b>neural</b> <b>machinery</b> that is selectively {{involved in the}} perception of faces. Physiological measurements, especially single-unit recordings in macaques and event-related potentials in humans, provide some of the richest sources of evidence on the specificity of these systems. However, these techniques do not allow us to quantify responses from specific regions of the human brain. The goal of the present effort was to provide a detailed characterisation of the response properties of a region of human extrastriate cortex called the fusiform face area (Kanwisher, McDermott, & Chun, 1997). We begin with a brief outline of the neurophysiological evidence for face-specific neural systems...|$|E
40|$|Offline {{trial and}} error is {{probably}} the basic way of solving novel problems and, where fancier procedures such as algorithms are used, trial-and-error was probably the main way of evolving them. We {{need to know how}} humans evolved such simulation abilities. And {{it would be nice to}} know some alternative paths that an extraterrestrial intelligence might have followed. I'm going to give an example of the <b>neural</b> <b>machinery</b> that intelligence might require, a brief description of how it might have evolved, then discuss hominid evolution more generally and speculate about what might happen in the next century as we better understand the machinery underlying our own higher intellectual functions...|$|E
40|$|AbstractStudies of {{biological}} motion have identified specialized <b>neural</b> <b>machinery</b> for {{the perception of}} human actions. Our experiments examine behavioral and neural responses to novel, articulating and non-human ‘biological motion’. We find that non-human actions are seen as animate, but do not convey body structure when viewed as point-lights. Non-human animations fail to engage the human STSp, and neural responses in pITG, ITS and FFA/FBA are reduced only for the point-light versions. Our results suggest that STSp is specialized for human motion and ventral temporal regions support general, dynamic shape perception. We also identify a region in ventral temporal cortex ‘selective’ for non-human animations, which we suggest processes novel, dynamic objects...|$|E
40|$|Text {{comprehension}} is {{a psychological}} activity that has attracted {{the interest of}} cognitive science for a long time. Nevertheless, just recently, neuroscientific studies have emerged in order to unveil the <b>neural</b> <b>machinery</b> behind thisactivity. This paper reviews some of the classical and, particularly, current works in cognitive science and new advancesin the neuroscience of text comprehension. Later on, a potential neurocognitive model for text comprehension basedon the core concepts of the cognitive and neuroscientific approaches is presented. This model preserves the predictionsmade by cognitive models as regards comprehension and {{the architecture of the}} new neuropsychological models asregards neurocognitive development. Finally, questions for future research in both domains and some general conclusionsare offered...|$|E
30|$|Recent {{studies in}} the field of {{neuroscience}} demonstrate that imagining the future largely depends on the same <b>neural</b> <b>machinery</b> that is required for remembering the past, and this finding suggests the concept of a ‘prospective brain’, a specific cerebral function used to imagine, simulate, and predict possible future events from stored information [35]. The ability to imagine fictitious or future events and choice situations that require imagining potential outcomes involves regions of the brain associated with memory, such as the hippocampus [21, 42]. However, other anatomical correlates contribute to the prospective brain, such as the amygdala, which is more active when imagining positive future events relative to negative ones, suggesting a key role in mediating the optimism bias through the process of monitoring emotional salience [37].|$|E
40|$|The human infant {{brain is}} the only known machine able to master a natural {{language}} and develop explicit, symbolic, and communicable systems of knowledge that deliver rich representations of the external world. With the emergence of non-invasive brain imaging, we now {{have access to the}} unique <b>neural</b> <b>machinery</b> underlying these early accomplishments. After describing early cognitive capacities in the domains of language and number, we review recent findings that underline the strong continuity between human infants’ and adults’ neural architecture, with notably early hemispheric asymmetries and involvement of frontal areas. Studies of the strengths and limitations of early learning, and of brain dynamics in relation to regional maturational stages, promise to yield {{a better understanding of the}} sources of human cognitive achievements. This work was supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF – 1231216...|$|E
40|$|The brain {{constantly}} infers {{the causes}} of the inputs it receives and uses these inferences to generate statistical expectations about future observations. Experimental evidence for these expectations and their violations include explicit reports, sequential effects on reaction times, and mismatch or surprise signals recorded in electrophysiology and functional MRI. Here, we explore the hypothesis that the brain acts as a near-optimal inference device that constantly attempts to infer the time-varying matrix of transition probabilities between the stimuli it receives, even when those stimuli are in fact fully unpredictable. This parsimonious Bayesian model, with a single free parameter, accounts for a broad range of findings on surprise signals, sequential effects and the perception of randomness. Notably, it explains the pervasive asymmetry between repetitions and alternations encountered in those studies. Our analysis suggests that a <b>neural</b> <b>machinery</b> for inferring transition probabilities lies at the core of human sequence knowledge...|$|E
40|$|Recognition {{of objects}} and scenes is a {{fundamental}} function of the human brain, necessitating a complex <b>neural</b> <b>machinery</b> that transforms low level visual information into semantic content. Despite significant advances in characterizing the locus and function of key visual areas, integrating the temporal and spatial dynamics of this processing stream has posed a decades-long challenge to human neuroscience. In this talk I will describe a brain mapping approach to combine magnetoencephalography (MEG), functional MRI (fMRI) measurements, and convolutional neural networks (CNN) by representational similarity analysis to yield a spatially and temporally integrated characterization of neuronal representations when observers perceive visual events. The approach is well suited to characterize the duration and sequencing of perceptual and cognitive tasks, and to place new constraints on the computational architecture of cognition. In collaboration with: D. Pantazis, R. M Cichy, A. Torralba, S. M. Khaligh-Razavi, C. Mullin, Y. Mohsenzadeh, B. Zhou, A. Khosl...|$|E
40|$|It is {{hypothesized}} that colour vision and opponent processing of colour signals {{in the visual}} system evolved {{as a means of}} overcoming the extremely unfavourable lighting conditions in the natural environ-ment of early vertebrates. The signi¢cant £icker of illumination inherent in the shallow-water environment complicated the visual process in the achromatic case, in particular preventing early detec-tion of enemies. The presence of two spectral classes of photoreceptors and opponent interaction of their signals at a subsequent retinal level allowed elimination of the £icker from the retinal image. This new visual function provided certain advantages concerning reaction times and favoured survival. This assumption explains why the building blocks for colour vision arose so early, i. e. just after the active predatory lifestyle was mastered. The principal functions of colour vision inherent in extant animals required a more complex <b>neural</b> <b>machinery</b> for colour processing and evolved later {{as the result of a}} change in visual function favouring colour vision...|$|E
40|$|This {{special issue}} {{describes}} important {{recent developments in}} applying reinforcement learning models to capture neural and cognitive function. But reinforcement learning, as a theoretical framework, can apply at two very different levels of description: mechanistic and rational. Reinforcement learning is often viewed in mechanistic terms – as describing the operation of aspects of an agent’s cognitive and <b>neural</b> <b>machinery.</b> Yet {{it can also be}} viewed as a rational level of description, specifically, as describing a class of methods for learning from experience, using minimal background knowledge. This paper considers how rational and mechanistic perspectives differ, and what types of evidence distinguish between them. Reinforcement learning research in the cognitive and brain sciences is often implicitly committed to the mechanistic interpretation. Here the opposite view is put forward: that accounts of reinforcement learning should apply at the rational level, unless there is strong evidence for a mechanistic interpretation. Implications of this viewpoint for reinforcement-based theories in the cognitive and brain sciences are discussed...|$|E
40|$|Behavioral {{research}} {{has led to}} the view that items in short-term memory can be parsed into two categories: a single item in the focus of attention that is available for immediate cognitive processing and a small set of other items that are in a heightened state of activation but require retrieval for further use. We examined this distinction by using an item-recognition task. The results show that the item in the focus of attention is represented by increased activation in inferior temporal representational cortices relative to other information in short-term memory. Functional connectivity analyses suggest that activation of these inferior temporal regions is maintained via frontal- and posterior-parietal contributions. By contrast, other items in short-term memory demand retrieval mechanisms that are represented by increased activation in the medial temporal lobe and left mid-ventrolateral prefrontal cortex. These results show that there are two distinctly different sorts of access to information in short-term memory, and that access by retrieval operations makes use of <b>neural</b> <b>machinery</b> similar to that used in long-term memory retrieval...|$|E
40|$|Although environment-driven {{learning}} can explain much of postnatal neural development, substantial organization and functional ability is present even at birth. Recent experimental discoveries of widespread spontaneous neural activity suggest that prenatal development may utilize very similar mechanisms and principles as postnatal learning, driven by internally generated sources {{instead of the}} environment. This chapter shows how this idea can explain features of the organization and function of the primary visual cortex (V 1) and higher level face-processing areas. Specifically, we simulate how neural preferences for contour orientation and human faces can develop prenatally from internally generated activity and postnatally from natural image stimuli. These simulations are based on HLISSOM, a hierarchical self-organizing model {{of the development of}} topographic neural maps. The results match experimental neuroimaging and psychophysical data from newborn and older animals and humans, and provide concrete predictions about infant behavior and neural activity for future experiments. They also suggest that combining internally generated activity with a learning algorithm is an efficient way to develop complex <b>neural</b> <b>machinery.</b> ...|$|E
40|$|SummaryFacial motion transmits {{rich and}} ethologically vital {{information}} [1, 2], but {{how the brain}} interprets this complex signal is poorly understood. Facial form is analyzed by anatomically distinct face patches in the macaque brain [3, 4], and facial motion activates these patches and surrounding areas [5, 6]. Yet, {{it is not known}} whether facial motion is processed by its own distinct and specialized <b>neural</b> <b>machinery,</b> and if so, what that machinery’s organization might be. To address these questions, we used fMRI to monitor the brain activity of macaque monkeys while they viewed low- and high-level motion and form stimuli. We found that, beyond classical motion areas and the known face patch system, moving faces recruited a heretofore unrecognized face patch. Although all face patches displayed distinctive selectivity for face motion over object motion, only two face patches preferred naturally moving faces, while three others preferred randomized, rapidly varying sequences of facial form. This functional divide was anatomically specific, segregating dorsal from ventral face patches, thereby revealing a new organizational principle of the macaque face-processing system...|$|E
40|$|SummaryLiving organisms need {{to search}} for and ingest {{nutritional}} chemicals, and gustation {{plays a major role}} in detecting and discriminating between chemicals present in the environment. Using Drosophila as a model organism, we asked whether animals have the ability to evaluate the nutritional value of sugars. In flies, chemosensilla on the tarsi and labellum are the gustatory organs used to discriminate between edible and nonedible compounds [1, 2]. We noticed that Drosophila do not assign nutritional values to all sweet chemicals. D-arabinose is sweet to flies, but it provides them with no nutrition. By contrast, the sugar alcohol D-sorbitol is not sensed as sweet, but flies can live on it. We performed behavioral and electrophysiological measurements to confirm these gustatory and feeding responses. We found that Drosophila can learn the nutritional value of nonsweet D-sorbitol when it is associated with an odor cue. The learning process involved the synapsin molecule, suggesting that a neuronal mechanism is involved. We propose that Drosophila uses <b>neural</b> <b>machinery</b> to detect, evaluate, and learn the nutritional value of foods after ingestion...|$|E
40|$|Recent {{behavioral}} {{evidence suggests}} that dogs, like humans and monkeys, are capable of visual face recognition. But do dogs also exhibit specialized cortical face regions similar to humans and monkeys? Using {{functional magnetic resonance imaging}} (fMRI) in six dogs trained to remain motionless during scanning without restraint or sedation, we found a region in the canine temporal lobe that responded significantly more to movies of human faces than to movies of everyday objects. Next, using a new stimulus set to investigate face selectivity in this predefined candidate dog face area, we found that this region responded similarly to images of human faces and dog faces, yet significantly more to both human and dog faces than to images of objects. Such face selectivity was not found in dog primary visual cortex. Taken together, these findings: (1) provide the first evidence for a face-selective region in the temporal cortex of dogs, which cannot be explained by simple low-level visual feature extraction; (2) reveal that <b>neural</b> <b>machinery</b> dedicated to face processing is not unique to primates; and (3) may help explain dogs’ exquisite sensitivity to human social cues...|$|E
40|$|Consciousness fully supervenes {{when the}} 1. 5 kgm mass of {{protoplasm}} {{in the head}} directs the body into material and social environments and engages in reciprocity. While consciousness is not susceptible to direct measurement, a limited form exercised in animals and pre-lingual children can be measured indirectly with biological assays of arousal, intention and attention. In this essay consciousness is viewed as operating simultaneously in a field at all levels ranging from subatomic to social. The relations and transpositions between levels require sophisticated mathematical treatments that are largely still to be devised. In anticipation of those developments the available experimental data are reviewed concerning the state variables in several levels that collectively constitute the substrate of biological consciousness. The basic metaphors are described that represent the <b>neural</b> <b>machinery</b> of transposition in consciousness. The processes are sketched by which spatiotemporal neural activity patterns emerge as fields that may represent the contents of consciousness. The results of dynamical analysis are discussed in terms serving {{to distinguish between the}} neural point processes dictated by the neuron doctrine vs. continuously variable neural fields generated by neural masses in cortex. (c) 2007 Elsevier Ltd. All rights reserved...|$|E
40|$|This {{contribution}} {{focuses on}} the neural infrastructure for parsing and syntactic encoding. From an anatomical point of view, {{it is argued that}} Broca's area is an ill-conceived notion. Functionally, Broca's area and adjacent cortex (together Broca's complex) are relevant for language, but not exclusively for this domain of cognition. Its role can be characterized as providing the necessary infrastructure for unification (syntactic and semantic). A general proposal, but with required level of computational detail, is discussed to account for the distribution of labor between different components of the language network in the brain. Arguments are provided for the immediacy principle, which denies a privileged status for syntax in sentence processing. The temporal profile of event-related brain potential (ERP) is suggested to require predictive processing. Finally, since, next to speed, diversity is a hallmark of human languages, the language readiness of the brain might not depend on a universal, dedicated <b>neural</b> <b>machinery</b> for syntax, but rather on a shaping of the neural infrastructure of more general cognitive systems (e. g., memory, unification) in a direction that made it optimally suited for the purpose of communication through language...|$|E
40|$|This {{article focuses}} on the neural and {{cognitive}} processes that support imagining or simulating future events, a topic that has recently emerged {{in the forefront of}} cognitive neuroscience. We begin by considering concepts of simulation from a number of areas of psychology and cognitive neuroscience in order to place our use of the term in a broader context. We then review neuroimaging, neuropsychological, and cognitive studies that have examined future-event simulation and its relation to episodic memory. This research supports the idea that simulating possible future events depends on much of the same <b>neural</b> <b>machinery,</b> referred to here as a core network, as does remembering past events. After discussing several theoretical accounts of the data, we consider applications of work on episodic simulation for research concerning clinical populations suffering from anxiety or depression. Finally, we consider other aspects of future-oriented thinking that we think are related to episodic simulation, including planning, prediction, and remembering intentions. These processes together comprise what we have termed “the prospective brain, ” whose primary function is to use past experiences to anticipate future events. Key words: episodic memory; simulation of future events; neuroimaging; constructive memory...|$|E
