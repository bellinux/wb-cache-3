3|4002|Public
5000|$|... "¡" [...] and [...] "¿" [...] {{are both}} {{located within the}} Unicode Common block, and are both {{inherited}} from ISO-8859-1. [...] "¡" [...] has Unicode codepoint U+00A1 (decimal entity reference [...] ) and HTML <b>named</b> <b>entity</b> <b>reference</b> [...] [...] "¿" [...] has Unicode codepoint U+00BF (decimal entity reference [...] ) and has HTML <b>named</b> <b>entity</b> <b>reference</b> [...] In both cases, the [...] "i" [...] in the <b>named</b> <b>entity</b> <b>reference</b> is an initialism for [...] "inverted".|$|E
5000|$|Internal (parsed) {{entities}} are associating a {{name with}} any arbitrary textual content defined in their declaration (which {{may be in}} the internal subset or in the external subset of the DTD declared in the document). When a <b>named</b> <b>entity</b> <b>reference</b> is then encountered {{in the rest of the}} document (including in the rest of the DTD), and if this entity name has effectively been defined as a parsed entity, the reference itself is replaced immediately by the textual content defined in the parsed entity, and the parsing continues within this replacement text.|$|E
5000|$|Note that {{internal}} entities may {{be defined}} in any order, {{as long as they}} are not referenced and parsed in the DTD or in the body of the document, in their order of parsing: it is valid to include a reference to a still undefined entity within the content of a parsed entity, but it is invalid to include anywhere else any <b>named</b> <b>entity</b> <b>reference</b> before this entity has been fully defined, including all other internal entities referenced in its defined content (this also prevents circular or recursive definitions of internal entities). This document is parsed as if it was: ...|$|E
50|$|Older browsers, such as Netscape Navigator 4.77 and Internet Explorer 6, {{can only}} display text {{supported}} by the current font associated with the character encoding of the page, and may misinterpret numeric character references as being references to code values within the current character encoding, rather than references to Unicode code points. When you are using such a browser, {{it is unlikely that}} your computer has all of those fonts, or that the browser can use all available fonts on the same page. As a result, the browser will not display the text in the examples above correctly, though it may display a subset of them. Because they are encoded according to the standard, though, they will display correctly on any system that is compliant and does have the characters available. Further, those characters given names for use in <b>named</b> <b>entity</b> <b>references</b> {{are likely to be more}} commonly available than others.|$|R
5000|$|Predefined <b>named</b> {{character}} <b>entities</b> {{are similar}} to internal entities: 5 of them however are treated specially in all SGML, HTML and XML parsers. These entities are a bit different from normal parsed entities, because when a <b>named</b> character <b>entity</b> <b>reference</b> is encountered in the document, the reference is also replaced immediately by the character content defined in the entity, but the parsing continues after the replacement text, which is immediately inserted literally in the currently parsed token (if such character is permitted in the textual value of that token). This allows some characters that are needed for the core syntax of HTML or XML themselves to be escaped from their special syntactic role (notably [...] "&" [...] which is reserved for beginning <b>entity</b> <b>references,</b> [...] "<" [...] or [...] ">" [...] which delimit the markup tags, and [...] "double" [...] or 'single' quotation marks, which delimit the values of attributes and entity definitions). Predefined character entities also include numeric character references that are handled {{the same way and}} {{can also be used to}} escape the characters they represent, or to bypass limitations in the character repertoire supported by the document encoding.|$|R
40|$|Messages often {{refer to}} {{entities}} such as people, places and events. Correct {{identification of the}} intended reference {{is an essential part}} of communication. Lack of shared unique <b>names</b> often complicates <b>entity</b> <b>reference.</b> Shared knowledge can be used to construct uniquely identifying descriptive <b>references</b> for <b>entities</b> with ambiguous <b>names.</b> We introduce a mathematical model for `Reference by Description', derive results on the conditions under which, with high probability, programs can construct unambiguous <b>references</b> to most <b>entities</b> in the domain of discourse and provide empirical validation of these results...|$|R
50|$|In {{addition}} to native character encodings, characters {{can also be}} encoded as character references, which can be numeric character references (decimal or hexadecimal) or character <b>entity</b> <b>references.</b> Character <b>entity</b> <b>references</b> are also {{sometimes referred to as}} <b>named</b> <b>entities,</b> or HTML entities for HTML. HTML's usage of character references derives from SGML.|$|R
5000|$|Parameter <b>entities</b> are <b>referenced</b> {{by placing}} the <b>entity</b> <b>name</b> between [...] "" [...] and [...] "". Parsed general <b>entities</b> are <b>referenced</b> {{by placing the}} <b>entity</b> <b>name</b> between [...] "" [...] and [...] "". Unparsed <b>entities</b> are <b>referenced</b> by placing the <b>entity</b> <b>name</b> {{in the value of}} an {{attribute}} declared as type ENTITY.|$|R
40|$|This page {{refers to}} a {{collection}} of datasets related to the Dutch Parliament and Senate of the period 1814 - 2012, they {{are all part of}} the 2012 project PoliticalMashup. These datasets are created by a group of researchers of the Informatics Institute, University of Amsterdam. The collection includes: A. Biographical data of all Members of Parliament of the Netherlands from 1814 - april 2012 (dataset "PoliticalMashup 1814 - 2012 ") B. Data on all Political Parties of the Netherlands with at least one seat in Parliament or the Senate from 1814 - april 2012 (dataset "PoliticalMashup 1814 - 2012 ") C. The proceedings of both Parliament and Senate. The proceedings are available in three forms: 1) enriched and non-semanticized (dataset "Dutch parliamentary proceedings 1814 - 2012 non-semanticized") 2) enriched and semanticized in FoLiA annotation (dataset "Dutch parliamentary proceedings 1930 - 2012, semanticized") 3) as a list of <b>named</b> <b>entities</b> with <b>references</b> back to the text (dataset "Dutch parliamentary proceedings 1930 - 2012, named entities") ...|$|R
50|$|<b>Names</b> for <b>entities</b> {{must follow}} the rules for SGML names, and there are {{limitations}} on where <b>entities</b> can be <b>referenced.</b>|$|R
5000|$|In contrast, a {{character}} <b>entity</b> <b>reference</b> refers to {{a character}} by the <b>name</b> of an <b>entity</b> which has the desired character as its replacement text. The entity must either be predefined (built into the markup language) or explicitly declared in a Document Type Definition (DTD). The format {{is the same as}} for any entity reference: ...|$|R
40|$|Name {{ambiguity}} {{arises from}} the polysemy of names and causes uncertainty about the true identity of <b>entities</b> <b>referenced</b> in unstructured text. This {{is a major problem}} in areas like information retrieval or knowledge management, for example when searching for a speci c entity or updating an existing knowledge base. We approach this problem of <b>named</b> <b>entity</b> disambiguation (NED) using thematic information derived from Latent Dirichlet Allocation (LDA) to compare the entity mention's context with candidate entities in Wikipedia represented by their respective articles. We evaluate various distances over topic distributions in a supervised classi cation setting to nd the best suited candidate entity, which is either covered in Wikipedia or unknown. We compare our approach to a state of the art m ethod and show that it achieves significantly better results in predictive performance, regarding both entities covered in Wikipedia as well as uncovered entities. We show that our approach is in general language independent as we obtain equally good results for <b>named</b> <b>entity</b> disambiguation using the English, the German and the French Wikipedia...|$|R
40|$|In {{this paper}} an open-domain factoid {{question}} answering system for Polish, RAFAEL, is presented. The system goes beyond finding an answering sentence; it also extracts a single string, {{corresponding to the}} required entity. Herein the focus is placed on different approaches to entity recognition, essential for retrieving information matching question constraints. Apart from traditional approach, including <b>named</b> <b>entity</b> recognition (NER) solutions, a novel technique, called Deep Entity Recognition (DeepER), is introduced and implemented. It allows a comprehensive search {{of all forms of}} <b>entity</b> <b>references</b> matching a given WordNet synset (e. g. an impressionist), based on a previously assembled entity library. It has been created by analysing the first sentences of encyclopaedia entries and disambiguation and redirect pages. DeepER also provides automatic evaluation, which makes possible numerous experiments, including over a thousand questions from a quiz TV show answered on the grounds of Polish Wikipedia. The final results of a manual evaluation on a separate question set show that the strength of DeepER approach lies in its ability to answer questions that demand answers beyond the traditional categories of <b>named</b> <b>entities...</b>|$|R
5000|$|Character {{entities}} can {{be included}} in an HTML document via the use of <b>entity</b> <b>references,</b> which take the form ''''''EntityName'''''', where EntityName is the <b>name</b> of the <b>entity.</b> For example, , much like [...] or , represents : the em dash character [...] " [...] - [...] " [...] even if the character encoding used doesn't contain that character.|$|R
30|$|The first level, {{commonly}} referred to as <b>named</b> <b>entity</b> recognition (NER), is usually understood as the problem to identify <b>referenced</b> <b>entity</b> types. For instance, occurrences of the strings “London” and “Frankfurt” in a text can be identified as references to locations and for occurrences like “Einstein” and “Goethe” the reference type could be person.|$|R
40|$|This paper {{addresses}} {{the problem of}} mining <b>named</b> <b>entity</b> translations from comparable corpora, specifically, mining English and Chinese <b>named</b> <b>entity</b> translation. We first observe that existing approaches use {{one or more of}} the following <b>named</b> <b>entity</b> similarity metrics: entity, entity context, and relationship. Inspired by this observation, in this paper, we propose a new holistic approach, by (1) combining all similarity types used and (2) additionally considering relationship context similarity between pairs of <b>named</b> <b>entities,</b> a missing quadrant in the taxonomy of similarity metrics. We abstract the <b>named</b> <b>entity</b> translation problem as the matching of two <b>named</b> <b>entity</b> graphs extracted from the comparable corpora. Specifically, <b>named</b> <b>entity</b> graphs are first constructed from comparable corpora to extract relationship between <b>named</b> <b>entities.</b> Entity similarity and entity context similarity are then calculated from every pair of bilingual <b>named</b> <b>entities.</b> A reinforcing method is utilized to reflect relationship similarity and relationship context similarity between <b>named</b> <b>entities.</b> According to our experimental results, our holistic graph-based approach significantly outperforms previous approaches...|$|R
5000|$|Unlike {{traditional}} HTML {{with its}} large range of character <b>entity</b> <b>references,</b> in XML {{there are only}} five predefined character <b>entity</b> <b>references.</b> These are used to escape characters that are markup sensitive in certain contexts: ...|$|R
3000|$|... is {{the term}} {{generated}} in the last step; more specifically, it is the segment result for person <b>name</b> <b>entity</b> recognition step and is the person <b>name</b> <b>entity</b> recognition result for location <b>name</b> <b>entity.</b> The {{same is true for}} group and organization <b>name</b> <b>entity</b> recognition. y [...]...|$|R
40|$|Abstract. The rapidly {{increasing}} use of large-scale data on the Web has made <b>named</b> <b>entity</b> disambiguation a key research challenge in Information Extraction (IE) {{and development of the}} Semantic Web. In this paper we propose a novel disambiguation framework that utilizes background semantic information, typically in the form of Linked Data, to accurately determine the intended meaning of detected semantic <b>entity</b> <b>references</b> within texts. The novelty of our approach lies in the definition of a structured semi-automatic process that enables the custom selection and use of the semantic data that is optimal for the disambiguation scenario at hand. This process allows our framework to adapt to the particular characteristics of different domains and scenarios and, as experiments show, to be more effective than approaches primarily designed to work in open domain and unconstrained situations. ...|$|R
40|$|Named Entity Recognition (NER) aims at {{locating}} and classifying <b>named</b> <b>entities</b> in text. In {{some use}} cases of NER, including cases where detected <b>named</b> <b>entities</b> are used in creating content recommendations, {{it is crucial to}} have a reliable confidence level for the detected <b>named</b> <b>entities.</b> In this work we study the problem of finding confidence levels for detected <b>named</b> <b>entities.</b> We refer to this problem as Named Entity Sequence Classification (NESC). We frame NESC as a binary classification problem and we use NER as well as recurrent neural networks to find the probability of candidate <b>named</b> <b>entity</b> is a real <b>named</b> <b>entity.</b> We apply this approach to Tweet texts and we show how we could find <b>named</b> <b>entities</b> with high confidence levels from Tweets...|$|R
40|$|We {{investigate}} how the automatic identification of noun compounds and <b>named</b> <b>entities</b> {{can contribute to}} keyphrase extraction and we also show how previously identified noun compounds affect <b>named</b> <b>entity</b> recognition and vice versa, how noun compound detection is supported by identified <b>named</b> <b>entities.</b> Our experiments demonstrate that already known noun compounds yield better performance in <b>named</b> <b>entity</b> recognition and already known <b>named</b> <b>entities</b> enhance noun compound detection. The integration of noun compound and <b>named</b> <b>entity</b> related features into a keyphrase extractor also proves {{to be more effective}} than the model not including them. Our results indicate that the above features tend to be beneficial in several NLP-related tasks. ...|$|R
40|$|Many <b>named</b> <b>entities</b> contain other <b>named</b> <b>entities</b> inside them. Despite this fact, {{the field}} of <b>named</b> <b>entity</b> {{recognition}} has almost entirely ignored nested <b>named</b> <b>entity</b> recognition, but due to technological, rather than ideological reasons. In this paper, we present a new technique for recognizing nested <b>named</b> <b>entities,</b> by using a discriminative constituency parser. To train the model, we transform each sentence into a tree, with constituents for each <b>named</b> <b>entity</b> (and no other syntactic structure). We present results on both newspaper and biomedical corpora which contain nested <b>named</b> <b>entities.</b> In {{three out of four}} sets of experiments, our model outperforms a standard semi-CRF on the more traditional top-level entities. At the same time, we improve the overall F-score by up to 30 % over the flat model, which is unable to recover any nested entities. ...|$|R
40|$|Translation of <b>named</b> <b>entities</b> (NE), {{including}} proper names, {{temporal and}} numerical expressions, {{is very important}} in multilingual natural language processing, like crosslingual information retrieval and statistical machine translation. In this paper we present an integrated approach to extract a <b>named</b> <b>entity</b> translation dictionary from a bilingual corpus {{while at the same time}} improving the <b>named</b> <b>entity</b> annotation quality. Starting from a bilingual corpus where the <b>named</b> <b>entities</b> are extracted independently for each language, a statistical alignment model is used to align the <b>named</b> <b>entities.</b> An iterative process is applied to extract <b>named</b> <b>entity</b> pairs with higher alignment probability. This leads to a smaller but cleaner <b>named</b> <b>entity</b> translation dictionary and also to a significant improvement of the monolingual <b>named</b> <b>entity</b> annotation quality for both languages. Experimental result shows that the dictionary size is reduced by 51. 8 % and the annotation quality is improved from 70. 03 to 78. 15 for Chinese and 73. 38 to 81. 46 in terms of F-score. 1...|$|R
50|$|The task of <b>named</b> <b>entity</b> {{recognition}} {{is to recognize}} and to categorize all <b>named</b> <b>entities</b> contained in a text (assignment of a <b>named</b> <b>entity</b> to a predefined category). This works by application of grammar based methods or statistical models.|$|R
30|$|Given some text, <b>name</b> <b>entity,</b> {{sentiment}} carrier, sentiment {{orientation of}} carrier, and relationship between <b>name</b> <b>entity</b> and sentiment carrier {{can be calculated}} by employing the method mentioned earlier. This section turns to calculate sentiment orientation for <b>name</b> <b>entity</b> and text.|$|R
5000|$|In natural {{language}} processing, <b>entity</b> linking, <b>named</b> <b>entity</b> linking (NEL), <b>named</b> <b>entity</b> disambiguation (NED), <b>named</b> <b>entity</b> recognition and disambiguation (NERD) or <b>named</b> <b>entity</b> normalization (NEN) {{is the task}} of determining the identity of entities mentioned in text. For example, given the sentence [...] "Paris is the capital of France", {{the idea is to}} determine that [...] "Paris" [...] refers to the city of Paris and not to Paris Hilton or any other entity that could be referred as [...] "Paris". NED is different from <b>named</b> <b>entity</b> recognition (NER) in that NER identifies the occurrence or mention of a <b>named</b> <b>entity</b> in text but it does not identify which specific entity it is.|$|R
5000|$|... <b>entity</b> <b>references</b> and non-special {{character}} {{references are}} expanded ...|$|R
5000|$|In HTML, the {{horizontal}} ellipsis character may {{be represented by}} the <b>entity</b> <b>reference</b> [...] (since HTML 4.0), and the vertical ellipsis character by the <b>entity</b> <b>reference</b> [...] (since HTML 5.0). Alternatively, in HTML, XML, and SGML, a numeric character reference such as [...] or [...] can be used.|$|R
5000|$|This is {{possible}} because the replacement text {{specified in the}} internal entity definitions permits a distinction between parameter <b>entity</b> <b>references</b> (that are introduced by the [...] "%" [...] character and whose replacement applies to the parsed DTD contents) and general <b>entity</b> <b>references</b> (that are introduced by the [...] "&" [...] character and whose replacement is delayed until they are effectively parsed and validated). The [...] "%" [...] character for introducing parameter <b>entity</b> <b>references</b> in the DTD loses its special role outside the DTD {{and it becomes a}} literal character.|$|R
40|$|Named entity {{recognition}} {{is important in}} sophisticated information service system such as Question Answering and Text Mining {{since most of the}} answer type and text mining unit depend on the <b>named</b> <b>entity</b> type. Therefore we focus on <b>named</b> <b>entity</b> recognition model in Korean. Korean <b>named</b> <b>entity</b> {{recognition is}} difficult since each word of <b>named</b> <b>entity</b> has not specific features such as the capitalizing feature of English. It has high dependence on the large amounts of hand-labeled data and the <b>named</b> <b>entity</b> dictionary, even though these are tedious and expensive to create. In this paper, we devise HMM based <b>named</b> <b>entity</b> recognizer to consider various context models. Furthermore, we consider weakly supervised learning technique, CoTraining, to combine labeled data and unlabeled data...|$|R
40|$|This paper {{describes}} {{the creation of}} a fine-grained <b>named</b> <b>entity</b> annotation scheme and corpus for Dutch, and experiments on automatic main type and subtype <b>named</b> <b>entity</b> recognition. We give an overview of existing <b>named</b> <b>entity</b> annotation schemes, and motivate our own, which describes six main types (persons, organizations, locations, products, events and miscellaneous <b>named</b> <b>entities)</b> and finer-grained information on subtypes and metonymic usage. This was applied to a one-million-word subset of the Dutch SoNaR reference corpus. The classifier for main type <b>named</b> <b>entities</b> achieves a micro-averaged F-score of 84. 91 %, and is publicly available, along with the corpus and annotations...|$|R
40|$|This paper {{describes}} {{and demonstrates}} a <b>names</b> <b>entity</b> similarity metric developed for, and currently in use by, the FuzzyPhoto project. The presented metric is effective at comparing <b>named</b> <b>entity</b> data in and across syntax less data schemas such as are often encounter in GLAM collections. The {{efficiency of the}} approach was compared to an existing <b>named</b> <b>entity</b> similarity metric and is {{shown to be a}} significant improvement when comparing messy <b>named</b> <b>entity</b> data...|$|R
40|$|Named entity {{disambiguation}} {{has become}} an im-portant research area providing the basis for im-proving search engine precision and for enabling semantic search. Current approaches for the <b>named</b> <b>entity</b> disambiguation are usually based on exploiting structured semantic and lingual re-sources (e. g. WordNet, DBpedia). Unfortu-nately, each of these resources cover indepen-dently from each other insufficient information for the task of <b>named</b> <b>entity</b> disambiguation. On the one hand WordNet comprises a relative small number of <b>named</b> <b>entities</b> while {{on the other hand}} DBpedia provides only little context for <b>named</b> <b>entities.</b> Our approach is based on the use of multi-lingual Wikipedia data. We show how the combination of multi-lingual resources can be used for <b>named</b> <b>entity</b> disambiguation. Based on a German and an English document corpus, we evaluate various similarity measures and algo-rithms for extracting data for <b>named</b> <b>entity</b> dis-ambiguation. We show that the intelligent filter-ing of context data and the combination of multi-lingual information provides high quality <b>named</b> <b>entity</b> disambiguation results. ...|$|R
40|$|In {{this paper}} the author {{presents}} TildeNER – an open source freely available <b>named</b> <b>entity</b> recognition toolkit {{and the first}} multi-class <b>named</b> <b>entity</b> recognition system for Latvian and Lithuanian languages. The system is built upon a supervised conditional random field classifier and features heuristic and statistical refinement methods that improve supervised classification, thus boosting the overall system’s performance. The toolkit provides means for <b>named</b> <b>entity</b> recognition model bootstrapping, plaintext document and also pre-processed (morpho-syntactically tagged) tab-separated document <b>named</b> <b>entity</b> tagging and evaluation on test data. The paper presents {{the design of the}} system, describes the most important data formats and briefly discusses extension possibilities to different languages. It also gives evaluation on human annotated gold standard test corpora for Latvian and Lithuanian languages as well as comparative performance analysis to a state-of-the art English <b>named</b> <b>entity</b> recognition system using parallel and strongly comparable corpora. The author gives analysis of the Latvian and Lithuanian <b>named</b> <b>entity</b> tagged corpora annotation process and the created <b>named</b> <b>entity</b> annotated corpora...|$|R
40|$|This paper {{focuses on}} the change of <b>named</b> <b>entities</b> over time and its {{influence}} {{on the performance of}} the <b>named</b> <b>entity</b> tagger. First, we analyze Japanese named enti-ties which appear in Mainichi Newspaper articles published in 1995, 1996, 1997, 1998 and 2005. This analysis reveals that the number of <b>named</b> <b>entity</b> types and the number of <b>named</b> <b>entity</b> tokens are almost steady over time and that 70 ∼ 80 % of <b>named</b> <b>entity</b> types in a certain year occur in the articles published either in its succeeding year or in its preceding year. These facts lead that 20 ∼ 30 % of <b>named</b> <b>entity</b> types are replaced with new ones every year. The experiment against these texts shows that our propos-ing semi-supervised method which com-bines a small annotated corpus and a large unannotated corpus for training works ro-bustly although the traditional supervised method is fragile against the change of <b>name</b> <b>entity</b> distribution. ...|$|R
30|$|Recall (R): {{the number}} of {{correctly}} recognized <b>named</b> <b>entities</b> divided {{by the total number}} of <b>named</b> <b>entities</b> in the test set.|$|R
