0|10000|Public
40|$|Abstract: The new dual-pivot Quicksort by Vladimir Yaroslavskiy — used in Oracle’s Java runtime library since version 7 — {{features}} intriguing asymmetries in its behavior. They {{were shown}} to cause a basic variant of this algorithm to use less comparisons than classic single-pivot Quicksort implementations. In this paper, we extend the analysis to the case where the two pivots are chosen as fixed order statistics of a random sample and give the precise leading term <b>of</b> the average <b>number</b> <b>of</b> comparisons, <b>swaps</b> and <b>executed</b> Java Bytecode instructions. It turns out that — unlike for classic Quicksort, where it is optimal to choose the pivot as median of the sample — the asymmetries in Yaroslavskiy’s algorithm render pivots with a systematic skew more efficient than the symmetric choice. Moreover, the optimal skew heavily depends on the employed cost measure; most strikingly, abstract costs like the <b>number</b> <b>of</b> <b>swaps</b> and comparisons yield a very different result than counting Java Bytecode instructions, which can be assumed most closely related to actual running time...|$|R
40|$|The new dual-pivot Quicksort by Vladimir Yaroslavskiy - used in Oracle's Java runtime library since version 7 - {{features}} intriguing asymmetries in its behavior. They {{were shown}} to cause a basic variant of this algorithm to use less comparisons than classic single-pivot Quicksort implementations. In this paper, we extend the analysis to the case where the two pivots are chosen as fixed order statistics of a random sample and give the precise leading term <b>of</b> the average <b>number</b> <b>of</b> comparisons, <b>swaps</b> and <b>executed</b> Java Bytecode instructions. It turns out that - unlike for classic Quicksort, where it is optimal to choose the pivot as median of the sample - the asymmetries in Yaroslavskiy's algorithm render pivots with a systematic skew more efficient than the symmetric choice. Moreover, the optimal skew heavily depends on the employed cost measure; most strikingly, abstract costs like the <b>number</b> <b>of</b> <b>swaps</b> and comparisons yield a very different result than counting Java Bytecode instructions, which can be assumed most closely related to actual running time. Comment: presented at AofA 2014 ([URL]...|$|R
5000|$|For the {{complete}} edge set flip (a requirement that can arise only for cubes of even size), the <b>number</b> <b>of</b> <b>swaps</b> will be [...] The overall <b>number</b> <b>of</b> <b>swaps</b> {{will be even}} if [...] is even (i.e. [...] is odd). The overall <b>number</b> <b>of</b> <b>swaps</b> will be odd if [...] is even. Hence overall parity will be even if [...] is odd and odd if [...] is even.|$|R
25|$|The <b>number</b> <b>of</b> <b>swaps</b> can {{be reduced}} by calculating the {{position}} of multiple elements before moving them. For example, if the target position of two elements is calculated before they are moved into the right position, the <b>number</b> <b>of</b> <b>swaps</b> {{can be reduced}} by about 25% for random data. In the extreme case, this variant works similar to merge sort.|$|R
5000|$|If all {{elements}} to be sorted are distinct, the expected <b>number</b> <b>of</b> comparisons {{performed in the}} average case by randomized bogosort is asymptotically equivalent to , and the expected <b>number</b> <b>of</b> <b>swaps</b> in the average case equals [...] The expected <b>number</b> <b>of</b> <b>swaps</b> grows faster than the expected <b>number</b> <b>of</b> comparisons, because if the elements are not in order, this will usually be discovered {{after only a few}} comparisons, no matter how many elements there are; but the work of shuffling the collection is proportional to its size. In the worst case, the <b>number</b> <b>of</b> comparisons and <b>swaps</b> are both unbounded, {{for the same reason that}} a tossed coin might turn up heads any <b>number</b> <b>of</b> times in a row.|$|R
5000|$|Dodgson's method {{extends the}} Condorcet method by {{swapping}} candidates until a Condorcet winner is found. The winner is the candidate which requires the minimum <b>number</b> <b>of</b> <b>swaps.</b>|$|R
40|$|Recently, Aumüller and Dietzfelbinger {{proposed}} {{a version of}} a dual-pivot Quicksort, called "Count", which is optimal among dual-pivot versions {{with respect to the}} average <b>number</b> <b>of</b> key comparisons required. In this master's thesis we provide further probabilistic analysis of "Count". We derive an exact formula for the average <b>number</b> <b>of</b> <b>swaps</b> needed by "Count" as well as an asymptotic formula for the variance <b>of</b> the <b>number</b> <b>of</b> <b>swaps</b> and a limit law. Also for the <b>number</b> <b>of</b> key comparisons the asymptotic variance and a limit law are identified. We also consider both complexity measures jointly and find their asymptotic correlation...|$|R
50|$|The parity of a {{permutation}} {{refers to}} whether that permutation is even or odd. An even permutation {{is one that}} can be represented by an even <b>number</b> <b>of</b> <b>swaps</b> while an odd permutation is {{one that can be}} represented by an odd <b>number</b> <b>of</b> <b>swaps.</b> An odd permutation followed by an odd permutation will represent an overall even permutation (adding two odd numbers always returns an even number). Since a quarter turn is made up <b>of</b> a <b>number</b> <b>of</b> 4-cycles each involving three <b>swaps,</b> if the <b>number</b> <b>of</b> 4-cycles is odd, overall parity of the quarter turn permutation will be odd and vice versa.|$|R
30|$|The only {{difference}} to the case <b>of</b> single <b>swap</b> is the logarithmic term (log 2 w), which depends only on the <b>number</b> <b>of</b> <b>swaps</b> needed. Even this is a too pessimistic estimation since the probability of the first successful swap is up to w 2 times higher than that <b>of</b> the last <b>swap.</b> This is because there are potentially w times more choices for the successful removal and addition. Experimental observations show that 2.7 swaps are required with S 1 –S 4, on average, and the <b>number</b> <b>of</b> iterations is multiplied roughly {{by a factor of}} 1.34, when compared to the case <b>of</b> a single <b>swap.</b> However, the main problem of using the Eq. (13) in practice is that the <b>number</b> <b>of</b> <b>swaps</b> (w) is unknown.|$|R
40|$|Abstract—Many {{algorithms}} {{are available}} for sorting the unordered elements. Most important of them are Bubble sort, Heap sort, Insertion sort and Shell sort. These algorithms have their own pros and cons. Shell Sort which is an enhanced version of insertion sort, reduces the <b>number</b> <b>of</b> <b>swaps</b> <b>of</b> the elements being sorted to minimize the complexity and time as compared to insertion sort. Shell sort improves the efficiency of insertion sort by quickly shifting values to their destination. Average sort time is O(n 1. 25), while worstcase time is O(n 1. 5). It performs certain iterations. In each iteration it <b>swaps</b> some elements <b>of</b> the array {{in such a way}} that in last iteration when the value of h is one, the <b>number</b> <b>of</b> <b>swaps</b> will be reduced. Donald L. Shell invented a formula to calculate the value of ‘h’. this work focuses to identify some improvement in the conventional Shell sort algorithm. “Enhanced Shell Sort algorithm ” is an improvement in the algorithm to calculate the value of ‘h’. It has been observed that by applying this algorithm, <b>number</b> <b>of</b> <b>swaps</b> can be reduced up to 60 percent as compared to the existing algorithm. In some other cases this enhancement was found faster than the existing algorithms available. Keywords—Algorithm, Computation, Shell, Sorting. I...|$|R
5000|$|Because F is alternating, {{the columns}} [...] can be swapped {{until it becomes}} the identity. The sign {{function}} [...] is defined to count the <b>number</b> <b>of</b> <b>swaps</b> necessary and account for the resulting sign change. One finally gets: ...|$|R
5000|$|To {{grasp the}} intuition behind this {{difference}} in complexity, note that the <b>number</b> <b>of</b> <b>swaps</b> that may occur during any one siftUp call increases with {{the depth of the}} node on which the call is made. The crux is that there are many (exponentially many) more [...] "deep" [...] nodes than there are [...] "shallow" [...] nodes in a heap, so that siftUp may have its full logarithmic running-time on the approximately linear <b>number</b> <b>of</b> calls made on the nodes at or near the [...] "bottom" [...] of the heap. On the other hand, the <b>number</b> <b>of</b> <b>swaps</b> that may occur during any one siftDown call decreases as the depth of the node on which the call is made increases. Thus, when the [...] begins and is calling [...] on the bottom and most numerous node-layers, each sifting call will incur, at most, a <b>number</b> <b>of</b> <b>swaps</b> equal to the [...] "height" [...] (from the bottom of the heap) of the node on which the sifting call is made. In other words, about half the calls to siftDown will have at most only one swap, then {{about a quarter of the}} calls will have at most two swaps, etc.|$|R
5000|$|Efficient: every swap in the sorted lists {{causes a}} {{constant}} <b>number</b> <b>of</b> insertions and deletions in the kinetic priority queues. Assuming {{the motion of}} the points is pseudo-algebraic, there are a polynomial <b>number</b> <b>of</b> <b>swaps,</b> and hence a polynomial <b>number</b> <b>of</b> events are processed by this KDS, making it efficient ...|$|R
2500|$|To {{grasp the}} intuition behind this {{difference}} in complexity, note that the <b>number</b> <b>of</b> <b>swaps</b> that may occur during any one siftUp call increases with {{the depth of the}} node on which the call is made. The crux is that there are many (exponentially many) more [...] "deep" [...] nodes than there are [...] "shallow" [...] nodes in a heap, so that siftUp may have its full logarithmic running-time on the approximately linear <b>number</b> <b>of</b> calls made on the nodes at or near the [...] "bottom" [...] of the heap. On the other hand, the <b>number</b> <b>of</b> <b>swaps</b> that may occur during any one siftDown call decreases as the depth of the node on which the call is made increases. Thus, when the siftDown heapify begins and is calling siftDown on the bottom and most numerous node-layers, each sifting call will incur, at most, a <b>number</b> <b>of</b> <b>swaps</b> equal to the [...] "height" [...] (from the bottom of the heap) of the node on which the sifting call is made. In other words, about half the calls to siftDown will have at most only one swap, then {{about a quarter of the}} calls will have at most two swaps, etc.|$|R
40|$|The {{relevance}} <b>of</b> {{the electronic}} <b>swap</b> in the stopping process of proton by hydrogen is investigated. To this end, the Classical Trajectory Monte-Carlo method {{is used to}} calculate the k-stopping cross-section, i. e. the stopping cross-section given the occurrence of k-swaps during the collision. It is found that electron swaps can be used to label electron trajectories, as it seems to describe fairly well the extent of the electron-ion interaction during the collision. Depending on the ion energy, the <b>number</b> <b>of</b> <b>swaps</b> entering the stopping cross section may vary. In the keV range the <b>number</b> <b>of</b> <b>swaps</b> can be as large as five or more, whereas, at larger energies, only three or less electron swaps may take place in collisions of relevance to stopping. Comment: 13 pages (text+figures), and 6 figure...|$|R
30|$|It {{is worth}} noting that the ability BSS can serve at one time {{interval}} is influenced by both the <b>number</b> <b>of</b> EV batteries fully charged and the <b>number</b> <b>of</b> <b>swapping</b> robots. During high swapping demand period, EVs should wait in the queue for a short time if BSS can’t provide swapping service at once.|$|R
30|$|Overall, our {{conclusion}} is that for datasets with clear clustering structure, the last swap is the bottleneck and the additional work for all the previous swaps at most doubles the total work load. We therefore conclude that knowing the exact <b>number</b> <b>of</b> <b>swaps</b> needed is not very {{important to have a}} good estimate for the required <b>number</b> <b>of</b> iterations.|$|R
2500|$|Specifically, the {{expected}} <b>number</b> <b>of</b> comparisons needed to sort [...] elements (see [...] ) with random pivot selection is [...] Median-of-three pivoting brings this down to , {{at the expense}} of a three-percent increase in {{the expected}} <b>number</b> <b>of</b> <b>swaps.</b> An even stronger pivoting rule, for larger arrays, is to pick the ninther, a recursive median-of-three (Mo3), defined as ...|$|R
50|$|In short, we {{must find}} the voting profile with minimum Kendall tau {{distance}} from the input, such {{that it has a}} Condorcet winner; they are declared the victor. Computing the winner or even the Dodgson score of a candidate (the <b>number</b> <b>of</b> <b>swaps</b> needed to make him a winner) is a PNP||-complete problem.|$|R
40|$|We {{investigate}} how robust are results of committee elections to {{small changes in}} the input preference orders, depending on the voting rules used. We find that for typical rules the effect of making a single <b>swap</b> <b>of</b> adjacent candidates in a single preference order is either that (1) at most one committee member can be replaced, or (2) {{it is possible that}} the whole committee can be replaced. We also show that the problem of computing the smallest <b>number</b> <b>of</b> <b>swaps</b> that lead to changing the election outcome is typically NP-hard, but there are natural FPT algorithms. Finally, for a <b>number</b> <b>of</b> rules we assess experimentally the average <b>number</b> <b>of</b> random <b>swaps</b> necessary to change the election result...|$|R
40|$|We {{present an}} {{improved}} training strategy for dependency parsers that use online reordering to handle non-projective trees. The new strategy improves both efficiency and accuracy {{by reducing the}} <b>number</b> <b>of</b> <b>swap</b> operations performed on non-projective trees by up to 80 %. We present state-ofthe-art results for five languages with the best ever reported results for Czech. ...|$|R
5000|$|Features include: {{the ability}} to disable ELF core dumps, reduce the <b>number</b> <b>of</b> <b>swap</b> files, use <b>of</b> the SLOB memory allocator, ability to disable BUG (...) [...] For {{measuring}} and accounting features include: ability for kmalloc/kfree allocations to be monitored through /proc/kmalloc; and measurement of inline usage during kernel compiling. TinyLinux requires Intel 80386 or better to run.|$|R
40|$|AbstractWe {{investigate}} the <b>number</b> <b>of</b> <b>swaps</b> made by Quick Select (a variant of Quick Sort for finding order statistics) {{to find an}} element with a randomly selected rank under realistic partition algorithms such as Lomuto’s or Hoare’s. This kind of grand average provides a smoothing over all individual distributions for specific fixed order statistics. The grand distribution for the <b>number</b> <b>of</b> <b>swaps</b> (when suitably scaled) is a perpetuity (a sum of products of independent mixed continuous random variables supported on the interval (0, 1)). The tool for this proof is contraction in the Wasserstein metric space, and identifying the limit as the fixed-point solution of a distributional equation. The same methodology carries over when Quick Select is commissioned to find an extremal order statistic (of a relatively small or relatively large rank) {{and the results are}} of similar nature. It is one of our purposes to show that analysis under different partition algorithms leads to different results...|$|R
25|$|Another {{series of}} {{crossovers}} {{is planned for}} late 2017, with a <b>number</b> <b>of</b> characters <b>swapping</b> over for episodes.|$|R
25|$|Bubble sort is {{asymptotically}} {{equivalent in}} running time to insertion sort {{in the worst}} case, but the two algorithms differ greatly in the <b>number</b> <b>of</b> <b>swaps</b> necessary. Experimental results {{such as those of}} Astrachan have also shown that insertion sort performs considerably better even on random lists. For these reasons many modern algorithm textbooks avoid using the bubble sort algorithm in favor of insertion sort.|$|R
50|$|The Kendall tau rank {{distance}} is a metric that counts the <b>number</b> <b>of</b> pairwise disagreements between two ranking lists. The larger the distance, the more dissimilar the two lists are. Kendall tau {{distance is}} also called bubble-sort distance {{since it is}} equivalent to the <b>number</b> <b>of</b> <b>swaps</b> that the bubble sort algorithm would make to place one list in the same order as the other list. The Kendall tau distance was created by Maurice Kendall.|$|R
40|$|We {{introduce}} several {{modifications of}} the partitioning schemes used in Hoare’s quicksort and quickselect algorithms, including ternary schemes which identify keys less {{or greater than}} the pivot. We give estimates for the <b>numbers</b> <b>of</b> <b>swaps</b> made by each scheme. Our computational experiments indicate that ternary schemes allow quickselect to identify all keys equal to the selected key at little additional cost. Key words. Sorting, selection, quicksort, quickselect, partitioning. ...|$|R
40|$|Abstract. Given two n-bit (cyclic) binary strings, A and B, {{represented}} on a circle (necklace instances). Let each sequence {{have the same}} <b>number</b> k <b>of</b> 1 ’s. We are interested in computing the cyclic swap distance between A and B, i. e., the minimum <b>number</b> <b>of</b> <b>swaps</b> needed to convert A into B, minimized over all rotations of B. We show that this distance may be approximated in O(n + k 2) time. ...|$|R
50|$|The {{decline in}} the <b>number</b> <b>of</b> debt-for-nature <b>swaps</b> in recent years likely results {{in part from the}} higher prices of {{commercial}} debt in secondary markets. In the late 1980s and early 1990s, conservation organizations could purchase relatively large debt obligations on the secondary market at highly discounted rates. During this period, conservation organizations and national governments negotiated swaps at a rate of approximately five agreements per year. Since 2000, the <b>number</b> <b>of</b> <b>swap</b> agreements has dropped to about two per year.Additionally, other agreements for debt restructuring and cancellation, such as the Heavily Indebted Poor Countries (HIPC) initiative, lower a developing country’s debt obligation by much more than the relatively small contribution debt-for-nature swaps make.Also, debt-for-nature swaps have undergone thorough critique by skeptics; these criticisms {{may have contributed to the}} decline of the debt-for-nature financing mechanism.|$|R
40|$|Given two n-bit (cyclic) binary strings, A and B, {{represented}} on a circle (necklace instances). Let each sequence {{have the same}} <b>number</b> k <b>of</b> 1 ’s. We are interested in computing the cyclic swap distance between A and B, i. e., the minimum <b>number</b> <b>of</b> <b>swaps</b> needed to convert A to B, minimized over all rotations of B. We show that, given the compressed representation of A and B, this distance may be computed in O(k 2) ...|$|R
25|$|The only {{exception}} is the snub 24-cell, which is generated by half of the coordinate permutations, only an even <b>number</b> <b>of</b> coordinate <b>swaps.</b> φ=(√5+1)/2.|$|R
50|$|As a consequence, {{swap bodies}} {{do not have}} upper corner fittings, are not stackable, and must be lifted by the bottom frame, unlike the more {{widespread}} shipping containers (ISO containers). This makes them unsuitable for ship-based overseas transportation. Because they are not stackable and are lifted by the bottom corners, they require special handling when transported by rail. Due to security concerns, an increasing <b>number</b> <b>of</b> <b>swap</b> bodies have a hard surface instead of curtains and tarpaulins.|$|R
50|$|The Linux kernel {{supports}} a virtually unlimited <b>number</b> <b>of</b> <b>swap</b> backends (devices or files), supporting {{at the same}} time assignment of backend priorities. When the kernel needs to <b>swap</b> pages out <b>of</b> physical memory, it uses the highest-priority backend with available free space. If multiple swap backends are assigned the same priority, they are used in a round-robin fashion (which is somewhat similar to RAID 0 storage layouts), providing improved performance as long as the underlying devices can be efficiently accessed in parallel.|$|R
40|$|Although each {{iteration}} of {{the popular}} k-Means clustering heuristic scales well to larger problem sizes, it often requires an unacceptably-high <b>number</b> <b>of</b> iterations to converge to a solution. This paper introduces an enhancement of k-Means in which local search is used to accelerate convergence without greatly increasing the average computational cost of the iterations. The local search involves a carefully-controlled <b>number</b> <b>of</b> <b>swap</b> operations resembling those of the more robust k-Medoids clustering heuristic. We show empirically that the proposed method improves convergence results when compared to standard k-Means. 1...|$|R
50|$|One {{weakness}} of insertion sort {{is that it}} may require a high <b>number</b> <b>of</b> <b>swap</b> operations and be costly if memory write is expensive. Library sort may improve that somewhat in the insertion step, as fewer elements need to move to make room, but is also adding an extra cost in the rebalancing step. In addition, locality of reference will be poor compared to mergesort as each insertion from a random data set may access memory that is no longer in cache, especially with large data sets.|$|R
40|$|AbstractIn k-means {{clustering}} we {{are given}} a set of n data points in d-dimensional space Rd and an integer k, {{and the problem is}} to determine a set of k points in Rd, called centers, to minimize the mean squared distance from each data point to its nearest center. No exact polynomial-time algorithms are known for this problem. Although asymptotically efficient approximation algorithms exist, these algorithms are not practical due to the very high constant factors involved. There are many heuristics that are used in practice, but we know of no bounds on their performance. We consider the question of whether there exists a simple and practical approximation algorithm for k-means clustering. We present a local improvement heuristic based on swapping centers in and out. We prove that this yields a (9 +ε) -approximation algorithm. We present an example showing that any approach based on performing a fixed <b>number</b> <b>of</b> <b>swaps</b> achieves an approximation factor of at least (9 −ε) in all sufficiently high dimensions. Thus, our approximation factor is almost tight for algorithms based on performing a fixed <b>number</b> <b>of</b> <b>swaps.</b> To establish the practical value of the heuristic, we present an empirical study that shows that, when combined with Lloyd's algorithm, this heuristic performs quite well in practice...|$|R
