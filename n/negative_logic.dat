20|40|Public
2500|$|Each <b>negative</b> <b>logic</b> {{selector}} bail that {{is displaced}} by the interposer in turn pulls a latch interposer and link which causes a selector latch near the cycle shaft to be {{pulled away from the}} latch bail. The latches pulled away in this manner are disengaged {{for the rest of the}} cycle, while the remaining latches take part in character selection, hence the term [...] "negative logic". The minus five selector bail pulls an interposer and link which causes a latch to disengage from a cam, allowing it to move an additional input into the whiffletree that subtracts five units of rotation from any <b>negative</b> <b>logic</b> inputs. An additional [...] "low velocity" [...] selector latch is also engaged by certain keys, such as '.' and '_', which require a reduced striking force so as not to cut the paper; this selector latch engages the low velocity control cam follower, which pulls the low velocity cable connected to the cam in the carrier, causing the low velocity lobe to be used instead of the usual high velocity lobe. Additionally, punctuation marks are deliberately placed about the ball so the maximum amount of energy is used to position the element prior to striking, further reducing the impact.|$|E
5000|$|In Boolean algebra it is {{recognized}} that a positive logic OR is a <b>negative</b> <b>logic</b> AND. Similarly a positive logic AND is a <b>negative</b> <b>logic</b> OR.|$|E
5000|$|Isomorphism - NOT {{operator}} as isomorphism between {{positive logic}} and <b>negative</b> <b>logic</b> ...|$|E
40|$|This article {{presents}} a sequent calculus for a <b>negative</b> free <b>logic</b> with identity, called N. The main theorem (in part 1) is the admissibility of the Cut-rule. The {{second part of}} this essay is devoted to proofs of soundness, compactness and completeness of N relative to a standard semantics for <b>negative</b> free <b>logic.</b> ...|$|R
40|$|AbstractThe aim of {{this article}} is to give a compact and {{self-contained}} description of the class of paraconsistent extensions of Johansson's (or minimal) logic (denoted Lj). The class of all non-trivial Lj-extensions is divided into three classes: the class Int of intermediate logics, the class Neg of <b>negative</b> <b>logics</b> (with axiom ¬p), and the class Par of proper paraconsistent Lj-extensions. For elements of Par, we define their intuitionistic and negative counterparts from classes Int and Par, respectively, and study to which extend paraconsistent logics are determined by their counterparts. To this end we need special presentation of j-algebras, which is also given in the article. In conclusion, we study Kripke semantics for paraconsistent Lj-extensions...|$|R
40|$|The {{logic of}} partial terms (LPT) is {{a variety of}} <b>negative</b> free <b>logic.</b> In LPT, functions, as well as predicates, are strict, and free {{variables}} are given the generality interpretation. Both nonconstructive (classical) and intuitionist brands of <b>negative</b> free <b>logic</b> have served in foundational investigations, and Hilbert-style axiomatizations, natural deduction systems, and Gentzen-style sequents {{have been developed for}} them. This paper focuses on nonconstructive LPT with denite descriptions, called LPD, lays the foundation for tableaux systems by dening the concept of an LPD model system and establishing Hintikka's Lemma, and summarizes the corresponding tableaux proof rules. Philosophical Roots of <b>Negative</b> Free <b>Logics</b> [...] . not even with these (contraries `Socrates is well' and `Socrates is sick') is it necessary always for one to be true and the other false. For if Socrates exists one will be true and the other false, but if he does not both will be false [...] (Aristotle, Categories, x, 13 b 12) A robust sense of reality is necessary in framing a correct analysis of propositions about [...] . round squares and other such pseudo-objects [...] we shall insist that in the analysis of propositions, nothing " is to be admitted. (Bertrand Russell...|$|R
50|$|The {{assignment}} of 1 and 0 {{to the positive}} and negative signal levels respectively is an option of the logic designer using the AND or OR circuits. With this assignment it assumes that the logic is positive. It is just as likely that the assignment might be the reversed where 1 is the negative voltage and 0 is the positive voltage. This would be <b>negative</b> <b>logic.</b> Switching between positive and <b>negative</b> <b>logic</b> is commonly used to achieve a more efficient logic design.|$|E
50|$|Similarly for the AND it was stated, “If input A or B or C is 0 {{the output}} will be 0.” In <b>negative</b> <b>logic</b> each node {{at the lower}} voltage would become a logic 1, making the statement, “If input A OR B OR C is 1 the output will be 1.” That is the {{definition}} of an OR function.|$|E
50|$|In digital electronics, a {{high voltage}} usually refers to that {{representing}} a logic 1 in positive logic and a logic 0 in <b>negative</b> <b>logic.</b> It {{is not used}} to indicate a hazardous voltage and levels between ICs to TTL/CMOS standards and their modern derivatives are well below hazardous levels. The highest in mainstream use were 15V for original CMOS and 5V for TTL but modern devices use 3.3V, with 1.8V or lower used in many applications.|$|E
40|$|This paper {{presents}} {{a fundamental difference}} between negative semantics for free logics and positive ones regarding the logical relations between existence and predication. We conclude that this difference {{is the key to}} understand why <b>negative</b> free <b>logics</b> are stronger, i. e., they prove more, than positive free logics...|$|R
40|$|Halbach {{has argued}} that Tarski biconditionals are not ontologically {{conservative}} over classical logic, but his argument is undermined {{by the fact that}} he cannot include a theory of arithmetic, which functions as a theory of syntax. This article is an improvement on Halbach's argument. By adding the Tarski biconditionals to inclusive <b>negative</b> free <b>logic</b> and the universal closure of minimal arithmetic, which is by itself an ontologically neutral combination, one can prove that at least one thing exists. The result can then be strengthened to the conclusion that infinitely many things exist. Those things are not just all Gödel codes of sentences but rather all natural numbers. Against this background inclusive <b>negative</b> free <b>logic</b> collapses into non-inclusive free logic, which collapses into classical logic. The consequences for ontological deflationism with respect to truth are discussed. status: publishe...|$|R
40|$|In {{this paper}} I am {{concerned}} with {{an analysis of}} negative existential sentences that contain proper names only by using negative or neutral free logic. I will compare different versions of neutral free logic with the standard system of <b>negative</b> free <b>logic</b> (Burge, Sainsbury) and aim to defend my version of neutral free logic that I have labeled non-standard neutral free logic...|$|R
50|$|This {{relationship}} {{can easily be}} recognized by reading the above description of their operation. In the OR it stated, “Only if all inputs, A and B and C are 0 will the output be 0.” In <b>negative</b> <b>logic</b> each node at the lower voltage would become a logic 1, making the statement, “Only if all inputs, A AND B AND C are 1 will the output be 1.” That {{is the definition of}} an AND function.|$|E
5000|$|Each <b>negative</b> <b>logic</b> {{selector}} bail that {{is displaced}} by the interposer in turn pulls a latch interposer and link which causes a selector latch near the cycle shaft to be {{pulled away from the}} latch bail. The latches pulled away in this manner are disengaged {{for the rest of the}} cycle, while the remaining latches take part in character selection, hence the term [...] "negative logic". The minus five selector bail pulls an interposer and link which causes a latch to disengage from a cam, allowing it to move an additional input into the whiffletree that subtracts five units of rotation from any <b>negative</b> <b>logic</b> inputs. An additional [...] "low velocity" [...] selector latch is also engaged by certain keys, such as '.' and '_', which require a reduced striking force so as not to cut the paper; this selector latch engages the low velocity control cam follower, which pulls the low velocity cable connected to the cam in the carrier, causing the low velocity lobe to be used instead of the usual high velocity lobe. Additionally, punctuation marks are deliberately placed about the ball so the maximum amount of energy is used to position the element prior to striking, further reducing the impact.|$|E
5000|$|.....the null {{hypothesis}} is never proved or established, {{but it is}} possibly disproved, {{in the course of}} experimentation. Every experiment may be said to exist only in order to give the facts a chance of disproving the {{null hypothesis}}." [...] (Fisher in The Design of Experiments) Many reasons for confusion exist including the use of double <b>negative</b> <b>logic</b> and terminology resulting from the merger of Fisher's [...] "significance testing" [...] (where the null hypothesis is never accepted) with [...] "hypothesis testing" [...] (where some hypothesis is always accepted).|$|E
40|$|Shenzhen metro {{has been}} applied the VFD control {{technique}} and close loop <b>negative</b> control <b>logic</b> to adjust and control the temperature and humidity of public area and conserve the energy on HVAC system of children palace station and Fumin station of NO. 4 line of the first phase project of the metro, which can save over 70 % electrical energy than before. And the equipment operated very well {{in more than one}} year, and the environment quality is very stable, has achieved obvious efficient...|$|R
40|$|Concept Learning is a Machine Learning {{technique}} {{in which the}} learning process is driven by providing positive and negative examples to the learner. From those examples, the learner builds a hypothesis (concept) that describes the positive examples and excludes the <b>negative</b> examples. Inductive <b>Logic</b> Programming (ILP) systems hav...|$|R
40|$|We {{investigate}} the parallel complexity of computing the stable model of acyclic general logic programs. Within {{this class of}} logic programs, we consider the cases of <b>negative</b> and definite <b>logic</b> programs. Both cases are proved to be P-complete. We prove the same for a related problem, namely that of computing the kernel of a directed acyclic graph...|$|R
5000|$|The {{machine was}} 10 ft high, 8 ft deep and 50 ft long. The power {{supplies}} for the machine were so large that it required designing a single tongue fork lift to remove and reinstall the power supply. The power supply bus bars on the machine spanned distances greater than three feet, and were octopus-like in design. Thick copper, the busses were coated in epoxy that often cracked resulting in shorts {{and a number of}} other issues. ILLIAC IV was designed by Burroughs Corporation and built in quadrants in Great Valley, PA during the years of 1967 through 1972. It had a traditional one address accumulator architecture, rather than the revolutionary stack architecture pioneered by Burroughs in the 5500/6500 machines. Illiac IV was designed in fact to be a [...] "back end processor" [...] to a B6700. The cost overruns caused by not getting the LSI chips and other design screw ups by Burroughs (the control unit was built with positive logic and the PEs with <b>negative</b> <b>logic,</b> etc.) made the project untenable.|$|E
5000|$|The ILLIAC IV {{was one of}} {{the first}} {{attempts}} at a massively parallel computer. Key to the design as conceived by Daniel Slotnick, the director of the project, was fairly high parallelism with up to 256 processors, used to allow the machine to work on large data sets in what would later be known as array processing. The machine was to have 4 quadrants. Each quadrant had a Control Unit (CU) and 64 Processor Elements (PEs). Originally Texas Instruments made a commitment to build the Processing Elements (PEs) out of large scale integrated (LSI) circuits. Several years into the project, TI backed out and said that they could not produce the LSI chips at the contracted price. This required a complete redesign using medium scale integrated circuits,leading to large delays and greatly increasing costs. This also led to scaling the system back from four quadrants to a single quadrant, owing to the fact that the MSI version was going to be many times larger than the LSI version would have been. This led to the CU having pull out 'cards' that were on the order of two feet square. For the PEs what should have been chips about 1 inch in diameter were now roughly 6 by 10 inches. Space, power and air conditioning (not to mention budget) did not allow for a four quadrant machine. The machine was 10' high, 8' deep and 50' long. There could be 10-12 instructions being sent from the CU on the wires to the PEs at any time. The power supplies for the machine were so large that it required designing a single tongue fork lift to remove and reinstall the power supply. The power supply buss bars on the machine spanned distances greater than three feet, and were octopus-like in design. Thick copper, the busses were coated in epoxy that often cracked resulting in shorts and an array of other issues. ILLIAC IV was designed by Burroughs Corporation and built in quadrants in Great Valley, PA during the years of 1967 through 1972. It had a traditional one address accumulator architecture, rather than the revolutionary stack architecture pioneered by Burroughs in the 5500/6500 machines. Illiac IV was designed in fact to be a [...] "back end processor" [...] to a B6700. The cost overruns caused by not getting the LSI chips and other design screw ups by Burroughs (the control unit was built with positive logic and the PEs with <b>negative</b> <b>logic,</b> etc.) made the project untenable.|$|E
40|$|Transistors {{consist of}} {{lower number of}} atoms with every {{technology}} generation. Such atoms may be displaced due to the stress caused by high temperature, frequency and current, leading to failures. NBTI (negative bias temperature instability) {{is one of the}} most important sources of failure affecting transistors. NBTI degrades PMOS transistors whenever the voltage at the gate is <b>negative</b> (<b>logic</b> inputPeer ReviewedPostprint (published version...|$|E
40|$|Positive or <b>negative</b> enable <b>logic</b> Stable {{with small}} 2. 2 µF ceramic output {{capacitor}} Input voltage range: − 2. 7 V to − 28 V Maximum output current: − 200 mA Low dropout voltage: − 185 mV at − 200 mA load Initial accuracy: ± 1 % Accuracy over line, load, and temperature + 2 % maximum/− 3 % minimum Low quiescent current, IGND = − 650 µA with − 200 mA load Low shutdown current: − 2 µA Adjustable output from − 1. 22 V to −VIN + VDO Current-limit and {{thermal overload protection}} 8 -lead LFCSP and 5 -lead TSOT APPLICATIONS Regulation to noise sensitive applications Analog-to-digital converter (ADC) and digital-to-analog converter (DAC) circuits, precision amplifiers Communications and infrastructure Medical and healthcar...|$|R
40|$|The {{most popular}} works of Chinese North American {{literature}} {{can be read}} as structurally centered upon a logic of the “neither/nor”: texts exemplified by the work of Amy Tan that display allegiance to neither America (the “hostland”) nor to China (the “homeland”). Rather than a doubling of allegiance, through a positive rhetoric of “both/and” national belonging, texts within this canon display a double <b>negative.</b> This <b>logic</b> betrays the residual power of racialized nationalism, in the contexts of hyphenated identities and diasporic community formation. In contrast to the pernicious influence of this nationalistic “neither here nor there” rhetoric, the work of writers like Fred Wah and Larissa Lai engage a local-global dynamism through a “both/and” paradigm for diasporic identity. These writers explore, complicate, and critique in productive ways the rhetorical dynamics of Orientalism/Occidentalism that are shaped in the transnational context of shifting Sino-American relations...|$|R
40|$|The {{critical}} {{behaviors of}} NP-complete {{problems have been}} studied extensively, and numerous results have been obtained for the problems of Boolean formula satisfiability (SAT) and constraint satisfaction (CSP), among others. However, few results are known for the critical behaviors of NP-hard nonmonotonic reasoning problems so far. In this paper we consider random <b>negative</b> two-literal <b>logic</b> programs under the answer set semantics. We prove that under {{what we call the}} quadratic model, the problem of whether these random logic programs have answer sets exhibits almost a phase transition. We also show that due to a connection between these random logic programs and random graphs, our result includes as a special case de la Vega’s theorem on the existence of kernels in random directed graphs. We report some experimental results, which in turn further justify the theoretical result on phase transition. 1...|$|R
40|$|NBTI {{is one of}} {{the most}} {{important}} sources of failure affecting transistors. NBTI degrades PMOS transistors whenever the voltage at the gate is <b>negative</b> (<b>logic</b> input “ 0 ”). Memory cells of storage blocks (e. g., register files) observe a “ 0 ” in the input of one of the two inverters at least 50 % of the time. This paper proposes a new memory-cell design for highly-ported structures consisting in a number of NAND gates arranged in a ring-manner that allows reducing the maximum degradation ratio due to NBTI below 50 %. 1...|$|E
40|$|Open AccessWe {{demonstrate}} {{the manipulation of}} transmitted light through an optical Fabry-Pérot cavity, built around a spectroscopy cell containing enriched rubidium vapor. Light resonant with the Rb 87 D 2 (F= 2,F= 1) ↔F′ manifold {{is controlled by the}} transverse intersection of the cavity mode by another resonant light beam. The cavity transmission can be suppressed or enhanced depending on the coupling of atomic states due to the intersecting beams. The extreme manifestation of the cavity-mode control is the precipitous destruction (<b>negative</b> <b>logic</b> switching) or buildup (positive logic switching) of the transmitted light intensity on intersection of the transverse control beam with the cavity mode. Both the steady-state and transient responses are experimentally investigated. The mechanism behind the change in cavity transmission is discussed in brief...|$|E
40|$|We {{demonstrate}} {{the manipulation of}} transmitted light through an optical Fabry-Perot cavity, built around a spectroscopy cell containing enriched rubidium vapor. Light resonant with the ^ 87 Rb D_ 2 (F= 2 /F= 1) F' manifold, is controlled by transverse intersection of the cavity mode by another resonant light beam. The cavity transmission can be suppressed or enhanced depending on the coupling of atomic states due to the intersecting beams. The extreme manifestation of cavity mode control is the precipitious destruction (<b>negative</b> <b>logic</b> switching) or buildup (positive logic switching) of the transmitted light intensity, on intersection of the transverse control beam with the cavity mode. Both the steady state and transient response are experimentally investigated. The mechanism behind the change in cavity transmission is discussed in brief. Comment: 9 pages, 13 figure...|$|E
40|$|Abstract—A {{vertically}} integrated npnp Si-based resonant interband tunneling diode (RITD) pair {{is realized}} with low-temperature {{molecular beam epitaxy}} by stacking two RITDs with a connecting backward diode between them. The current–voltage characteristics of the vertically integrated RITD pair demonstrates two sequential negative differential resistance regions in the forwardbiasing condition. Tri-state logic is demonstrated by using the vertically integrated RITDs as the drive and an off-chip resistor as the load. Index Terms—Molecular beam epitaxy (MBE), multivalued <b>logic,</b> <b>negative</b> differential resistance (NDR), resonant interband tunneling diodes (RITD), silicon, silicon germanium. I...|$|R
40|$|The {{logic of}} partial terms (LPT) is {{a variety of}} <b>negative</b> free <b>logic</b> in which functions, as well as predicates, are strict. A {{companion}} paper focused on nonconstructive LPT with de nite descriptions, called LPD, and {{laid the foundation for}} tableaux systems by de ning the concept of an LPD model system and establishing Hintikka's Lemma, from which the strong completeness of the corresponding tableaux system readily follows. The present paper utilizes the tableaux system in establishing an Extended Joint Consistency Theorem for LPD that incorporates the Robinson Joint Consistency Theorem and the Craig-Lyndon Interpolation Lemma. The method of proof is similar to that originally used in establishing the Extended Joint Consistency Theorem for positive free logic. Proof of the Craig-Lyndon Interpolation Lemma for formulas possibly having free variables is readily had in LPT and its intuitionistic counterpart. The paper concludes with a brief discussion of the theory of definitions in LPD...|$|R
40|$|We {{argue that}} {{the dream of a}} ‘perfect language’ – namely, a universal, {{unambiguous}} and semantically transparent medium of expression –, whose intriguing story has been told by Umberto Eco (1993), is deeply intertwined with the myth of instant rationality: the idea that a perfect language is one in which all logical relations beco- me immediately visible, so that the language itself “does the thinking for us” (Frege 1884). In {{the first part of this}} paper we trace this ver- sion of the dream in the works of Leibniz, Frege, Russell and Witt- genstein. In the second part we re-examine it in the light of more re- cent <b>negative</b> results in <b>logic</b> and theoretical computer science...|$|R
40|$|Memtranstor that {{correlates}} {{charge and}} magnetic flux via nonlinear magnetoelectric effects {{has a great}} potential in developing next-generation nonvolatile devices. In addition to multi-level nonvolatile memory, we demonstrate here that nonvolatile logic gates such as NOR and NAND can be implemented in a single memtranstor made of the Ni/PMN-PT/Ni heterostructure. After applying two sequent voltage pulses (X 1, X 2) as the logic inputs on the memtranstor, the output magnetoelectric voltage can be positive high (logic " 1 "), positive low (logic " 0 "), or <b>negative</b> (<b>logic</b> " 0 "), depending on the levels of X 1 and X 2. The underlying physical mechanism {{is related to the}} complete or partial reversal of ferroelectric polarization controlled by inputting selective voltage pulses, which determines the magnitude and sign of the magnetoelectric voltage coefficient. The combined functions of both memory and logic could enable the memtranstor as a promising candidate for future computing systems beyond von Neumann architecture. Comment: 8 pages, 5 figure...|$|E
40|$|Transistors {{consist of}} {{lower number of}} atoms with every {{technology}} generation. Such atoms may be displaced due to the stress caused by high temperature, frequency and current, leading to failures. NBTI (negative bias temperature instability) {{is one of the}} most important sources of failure affecting transistors. NBTI degrades PMOS transistors whenever the voltage at the gate is <b>negative</b> (<b>logic</b> input “ 0 ”). The main consequence is a reduction in the maximum operating frequency and an increase in the minimum supply voltage of storage structures to cope for the degradation. Many PMOS transistors affected by NBTI can be found in both combinational and storage blocks since they observe a “ 0 ” at their gates most of the time. This paper proposes and evaluates the design of Penelope, an NBTI-aware processor. We propose (i) generic strategies to mitigate degradation in both combinational and storage blocks, (ii) specific techniques to protect individual blocks by applying the global strategies, and (iii) a metric to assess the benefits of reduced degradation and the overheads in performance and power...|$|E
40|$|German social theorist Ulrich Beck has {{consistently}} {{maintained that the}} logic of social distribution in western cultures has been reconfigured {{over the last three}} decades. Beck believes that, in the first industrial modernity, political and economic energies were directed toward the dissemination of śocial goods,́ such as healthcare, employment and wealth. By contrast, in the second modernity - or risk society - the positive logic of goods distribution is displaced by a <b>negative</b> <b>logic</b> of śocial bads,́ exemplified by environmental despoliation, terrorism and nuclear accidents. Critically, whilst the logic of goods is sectoral - some win and some lose, some are protected, some exposed - social bads follow a universalising logic which threatens rich and poor alike. This article interrogates and challenges these core claims by fusing together and developing empirical and theoretical criticisms of the theory of distributional logic. Empirically, it is demonstrated that Beck draws upon a narrow range of examples, is insensitive to continuities in social reproduction and glosses over the intensification of traditional inequalities. Theoretically, the paper asserts that the risk society perspective constructs an unsustainable divide between interconnected modes of distribution, neglects the way in which political discourses can be used to reinforce hegemonic interests and overlooks uneven patterns of risk distribution. Risk Distribution, Social Reproduction, Politics of Risk...|$|E
40|$|From Leibniz to Krauss {{philosophers}} and scientists {{have raised the}} question as to why there is something rather than nothing (henceforth, the Question). Why-questions request a type of explanation and this is often thought to include a deductive component. With classical logic in the background only trivial answers are forthcoming. With free logics in the background, be they of the negative, positive or neutral variety, only question-begging answers are to be expected. The same conclusion is reached for the modal version of the Question, namely `Why is there something contingent rather than nothing contingent?' (except that possibility of answers with neutral free logic in the background is not explored). The categorial version of the Question, namely `Why is there something concrete rather than nothing concrete?', is also discussed. The conclusion is reached that deductive explanations are question-begging, whether one works with classical logic or positive or <b>negative</b> free <b>logic.</b> I also look skeptically at the prospects of giving causal-counterfactual or probabilistic answers to the Question, although the discussion of the options is less comprehensive and the conclusions are more tentative. The meta-question, viz. `Should we not stop asking the Question', is accordingly tentatively answered affirmatively. status: publishe...|$|R
500|$|The film {{contains}} 3,000 {{visual effects}} shots, completed by ten different visual effects studios, including Industrial Light & Magic (ILM), Trixter, Double <b>Negative,</b> Animal <b>Logic,</b> Framestore, Lola VFX, Territory, Perception, Method Studios, Luma Pictures and The Third Floor. ILM opened a facility in London, citing Avengers: Age of Ultron {{as a catalyst}} for the expansion, and developed a new motion capture system for the film called Muse, which can better capture an actor's performance and combine different takes. About the motion capture process, Ruffalo called it [...] "more of a collaboration" [...] since the technology is advancing, with [...] "the face capture and the motion capture can now [...] put together, [...] you [...] get a lot more latitude as a performer… you're no longer constricted by the attributes that you have as a person: your age, or weight, or size. None of that matters anymore. And so there's this whole exciting place to go that is kind of unknown." [...] Visual effects supervisor Christopher Townsend said that the visual effects team considered depicting the Hulk when manipulated by Wanda Maximoff as being grey skinned with red eyes, but eventually decided against it, as {{they did not want to}} confuse audiences who might associate it with [...] "Joe Fixit", the grey Hulk from the comics.|$|R
40|$|The {{critical}} {{behaviors of}} NP-complete {{problems have been}} studied extensively, and numerous results have been obtained for Boolean formula satisfiability (SAT) and constraint satisfaction (CSP), among others. However, few results are known for the critical behaviors of NP-hard nonmonotonic reasoning problems so far; in particular, a mathematical model for phase transition in nonmonotonic reasoning is still missing. In this article, we investigate the phase transition of <b>negative</b> two-literal <b>logic</b> programs under the answer-set semantics. We choose this class of logic programs {{since it is the}} simplest class for which the consistency problem of deciding if a program has an answer set is still NP-complete. We first introduce a new model, called quadratic model for generating random logic programs in this class. We then mathematically prove that the consistency problem for this class of logic programs exhibits a phase transition. Furthermore, the phase-transition follows an easy-hard-easy pattern. Given the correspondence between answer sets for negative two-literal programs and kernels for graphs, as a corollary, our result significantly generalizes de la Vega's well-known theorem for phase transition on the existence of kernels in random graphs. We also report some experimental results. Given our mathematical results, these experimental results are not really necessary. We include them here as they suggest that our phase-transition result is more general and likely holds for more general classes of logic programs. The critical behaviors of NP-complete problems have been studied extensively, and numerous results have been obtained for Boolean formula satisfiability (SAT) and constraint satisfaction (CSP), among others. However, few results are known for the critical behaviors of NP-hard nonmonotonic reasoning problems so far; in particular, a mathematical model for phase transition in nonmonotonic reasoning is still missing. In this article, we investigate the phase transition of <b>negative</b> two-literal <b>logic</b> programs under the answer-set semantics. We choose this class of logic programs since it is the simplest class for which the consistency problem of deciding if a program has an answer set is still NP-complete. We first introduce a new model, called quadratic model for generating random logic programs in this class. We then mathematically prove that the consistency problem for this class of logic programs exhibits a phase transition. Furthermore, the phase-transition follows an easy-hard-easy pattern. Given the correspondence between answer sets for negative two-literal programs and kernels for graphs, as a corollary, our result significantly generalizes de la Vega's well-known theorem for phase transition on the existence of kernels in random graphs. We also report some experimental results. Given our mathematical results, these experimental results are not really necessary. We include them here as they suggest that our phase-transition result is more general and likely holds for more general classes of logic programs...|$|R
