729|4913|Public
25|$|In November 2016, 8 {{months after}} Lee Sedol was {{defeated}} by computer program AlphaGo, Cho Chikun played a 3 game challenge match against program Zen. Cho won a close game 1, lost game 2 when his invasion into enemy territory was killed, and won game 3. Zen uses neural <b>network</b> <b>techniques</b> similar to AlphaGo, however ran on more modest hardware during the match.|$|E
50|$|Dynamic <b>network</b> <b>techniques</b> are {{particularly}} useful for assessing trends {{and changes in}} networks over time, identification of emergent leaders, and examining the co-evolution of people and ideas.|$|E
5000|$|Real-time fault {{diagnosis}} — Using occupancy grids and neural <b>network</b> <b>techniques,</b> IEA of Artificial Intelligence and Expert Systems Lecture Notes in Computer Science Volume 604, 1992, pp 636-640.|$|E
40|$|International audienceAsphaltene {{precipitation}} {{is traditionally}} modeled using polymer solution theories or cubic equations of state. We propose another approach based on artificial neural <b>network</b> <b>technique</b> to model onset of precipitation of dissolved asphaltene in {{the solution of}} solvent + precipitant. A mathematical model based on feed-forward artificial neural <b>network</b> <b>technique,</b> which takes advantage of a modified Levenberg-Marquardt optimization algorithm, {{has been used to}} model onset of precipitation of dissolved asphaltene in the solvent + precipitant solution. The experimental data reported in the literature have been used to develop this model. The acceptable agreement between the results of this model and experimental data demonstrates the capability of the neural <b>network</b> <b>technique</b> for estimating onset of precipitation of dissolved asphaltene in the solution of solvent + precipitant...|$|R
40|$|Computer is used {{by every}} people either at their work or at home. Our aim is to make {{computers}} that can understand human language and can develop a user friendly human computer interfaces (HCI). Human gestures are perceived by vision. The research is for determining human gestures to create an HCI. Coding of these gestures into machine language demands a complex programming algorithm. In this project, We have first detected, recognized and pre-processing the hand gestures by using General Method of recognition. Then We have found the recognized image’s properties and using this, mouse movement, click and VLC Media player controlling are done. After {{that we have done}} all these functions thing using neural <b>network</b> <b>technique</b> and compared with General recognition method. From this we can conclude that neural <b>network</b> <b>technique</b> is better than General Method of recognition. In this, I have shown the results based on neural <b>network</b> <b>technique</b> and comparison between neural network method & general method...|$|R
40|$|This paper {{presents}} the assistant diagnostic system for epilepsy detection {{based on the}} neural <b>network</b> <b>technique.</b> A goal of EEG signals analysis is not only human psychologically and functionality states definition but also pathological activity detection. In this paper we describe an approach for epileptiform activity detection by the artificial neural <b>network</b> <b>technique</b> for EEG signal segmentation and for the highest Lyapunov’s exponent computing. The EEG segmentation by the neural network approach {{makes it possible to}} detect an abnormal activity in signals. We examine our system for segmentation and anomaly detection on the EEG signal where the anomaly is an epileptiform activity...|$|R
5000|$|Besides, two {{shortcomings}} are (1) {{complexity of}} the FMEA worksheet (2) intricacy of its use. Entries in a FMEA worksheet are voluminous. The FMEA worksheet is hard to produce, hard to understand and read, as well as hard to maintain. The use of neural <b>network</b> <b>techniques</b> to cluster and visualise failure modes were suggested, recently.|$|E
50|$|In November 2016, 8 {{months after}} Lee Sedol was {{defeated}} by computer program AlphaGo, Cho Chikun played a 3 game challenge match against program Zen. Cho won a close game 1, lost game 2 when his invasion into enemy territory was killed, and won game 3. Zen uses neural <b>network</b> <b>techniques</b> similar to AlphaGo, however ran on more modest hardware during the match.|$|E
5000|$|In {{the book}} Personal Construct Methodology, {{researchers}} Brian R. Gaines and Mildred L.G. Shaw {{noted that they}} [...] "have also found concept mapping and semantic network tools to be complementary to repertory grid tools and generally use both in most studies" [...] but that they [...] "see less use of network representations in PCP construct psychology studies than is appropriate". They encouraged practitioners to use semantic <b>network</b> <b>techniques</b> {{in addition to the}} repertory grid.|$|E
40|$|Face {{recognition}} {{is the process}} of identifying one or more people in images or videos. It {{is an important part of}} biometric, security & surveillance system, and image indexing systems. Various face recognition techniques have been proposed in literature such as: Eigen-faces, Feature based, Hidden Markov model and Neural <b>network</b> based <b>techniques.</b> The first three techniques mostly include a phase of feature extraction or preprocessing closely related to the type of image to recognize. On the other hand Neural <b>network</b> <b>technique</b> does not need specific data about the type of image, thus can be applied to any type of image and at the same time provides better accuracy. In this paper we made an effort to combine neural <b>network</b> <b>technique</b> with fuzzy logic. Our experimental result shows that combining the two provide better accuracy in comparison to other techniques mentioned above...|$|R
40|$|This paper {{presents}} a novel soft cluster neural <b>network</b> <b>technique</b> for {{the classification of}} suspicious areas in digital mammograms. The technique introduces the concept of soft clusters within a neural network layer and combines them with least squares for optimising neural network weights. The idea of soft clusters is proposed {{in order to increase}} the generalisation ability of the neural network by providing a mechanism to more aptly depict the relationship between the input features and the subsequent classification as either a benign or malignant class. Soft clusters with least squares make the training process faster and avoid iterative processes which have many problems. The proposed neural <b>network</b> <b>technique</b> has been tested on the DDSM benchmark database. The results are analysed and discussed in this paper...|$|R
40|$|In {{this paper}} a new {{approach}} from the combination of band ratioing function and MLP Neural <b>Networks</b> <b>technique</b> is proposed to differentiate between clouds and background in Landsat ETM+ and MSG SEVIRI data. First, {{in order to increase}} the contrast of the clouds and background, a band ratioing function is applied to each sub-image. Second, the sub-images are segmented by MLP Neural <b>Networks</b> <b>technique.</b> The proposed approach was tested on 40 Landsat ETM+ sub-images of Gulf of Mexico and on 40 MSG SEVIRI sub-images over Italy. The same parameters were used in all tests. For the overall dataset, the average accuracy of 89 % was obtained for Landsat ETM+ images and the average accuracy of 85 % was obtained for MSG SEVIRI images. Our experimental results demonstrate that the proposed approach is robust and effective...|$|R
50|$|CO-MIMO is a {{technique}} useful for future cellular networks which consider wireless mesh networking or wireless ad hoc networking. In wireless ad hoc networks, multiple transmit nodes communicate with multiple receive nodes. To optimize the capacity of ad hoc channels, MIMO concepts and techniques {{can be applied to}} multiple links between the transmit and receive node clusters. Contrasted to multiple antennas in a single-user MIMO transceiver, participating nodes and their antennas are located in a distributed manner. So, to achieve the capacity of this <b>network,</b> <b>techniques</b> to manage distributed radio resources are essential. Strategies such as autonomous interference cognition, node cooperation, and network coding with dirty paper coding have been suggested to optimize wireless network capacity.|$|E
50|$|CPC2013 is {{distinctive}} {{in taking}} a prescriptive {{approach to the}} management of time and associated cost risk and combining critical path <b>network</b> <b>techniques</b> with resource-based planning. The time model, {{referred to as the}} Working Schedule, combines a high-density, short-term look-ahead similar in concept to that used in agile software development with medium and long-term lower density schedule along the lines of that used in the waterfall model planning technique, the whole being revised regularly on the Rolling Wave planning principle. In the short-term look-ahead, the logic is to be resource and location-related, instead of activity based, as it is in waterfall. The agile part of the schedule is to have its activity durations calculated by reference to the resources to be applied and their expected productivity.|$|E
5000|$|Most {{artificial}} or electronic nose instruments work {{by combining}} output from {{an array of}} non-specific chemical sensors to produce a finger print of whatever volatile chemicals it is exposed to. Most electronic noses need to be [...] "trained" [...] to recognize whatever chemicals are of interest for the application in question {{before it can be}} used. The training involves exposure to chemicals with the response being recorded and statistically analyzed, often using multivariate analysis and neural <b>network</b> <b>techniques,</b> to [...] "learn" [...] the chemicals. Many current electronic nose instruments suffer from problems with reproducibility subject to varying ambient temperature and humidity. An example of this type of technology is the colorimetric sensor array, which visualizes odor through color change and creates a [...] "picture" [...] of it.|$|E
40|$|The {{relationship}} between the severity of obstructive sleep apnea (OSA) (measured by sleep study) and daytime sleepiness is poor. Variation {{in the degree of}} arousal accompanying obstructive respiratory events might help explain this poor correlation. Polysomnographic records from patients with OSA were reviewed in order to extract representative examples of apneas and hypopneas (in 10 patients), as well as events both supine and decubitus (in 12 patients). The EEG accompanying each obstructive event was processed with a neural <b>network</b> <b>technique</b> to describe sleep depth on a second-by-second basis. The lengths of any visually evident microarousals were also measured manually. There was considerable interindividual variation in the degree of sleep disturbance using the neural <b>network</b> <b>technique</b> (p < 0. 005), but not using the lengths of the visually scored microarousals (p = 0. 6). The arousals accompanying apneic events caused greater variability in sleep depth quantified using the neural <b>network</b> <b>technique</b> (p = 0. 03), and also lasted longer based on the visual scoring (mean, 12. 6; SD, 1. 7 s) than the hypopneic events (mean, 9. 9; SD, 2. 4 s; p = 0. 02). There {{were no significant differences between}} events occurring supine versus decubitus with either technique (p = 0. 7). These differences in arousal magnitude may explain some of the poor correlations between conventional measures of sleep apnea severity and daytime sleepiness...|$|R
40|$|An {{approach}} to the formulation of fuzzy if-then rules based on clustering objective functions is proposed. The membership functions are then calibrated with the generalized neural <b>networks</b> <b>technique</b> to achieve a desired input-output mapping. The learning procedure is basically a gradient-descent algorithm. A Kalman filter algorithm is used to improve the overall performance...|$|R
40|$|Abstract. This article {{introduced}} the developmental status about networking of NC, discussed Internet-based project of <b>network</b> <b>technique</b> and topology structure, that used communicate controller to connect common NC machine tools to Internet and monitor long-distance；gave out the method to realize communicate controller that used MCU and RTL 8019 AS Ethernet controller chip...|$|R
50|$|Modern {{traffic sign}} {{recognition}} systems are being developed using convolutional neural networks, mainly driven by the requirements of autonomous vehicles and self driving cars. In these scenarios, the detection system need to identify a variety of traffic signs and not just speed limits. This is where the Vienna Convention on Road Signs and Signals comes to help. A convolutional neural network can be trained to take in these predefined traffic signs and 'learn' using Deep Learning techniques. The neural net in turn uses Image Processing and Computer Vision to train the network with its potential outcomes. The trained neural net can then be used in real time to detect new traffic signs in real time. Self driving car companies like Waymo and Uber are generating and outsourcing traffic sign data sets along with Map and Navigation companies like Tom Tom. Advanced computer vision and neural <b>network</b> <b>techniques</b> make this goal highly efficient and achievable in real time.|$|E
5000|$|Hilton {{writes that}} [...] "Themes running through his papers are Hamiltonian cycles, Eulerian graphs, {{spanning}} trees, the marriage problem, detachments, reconstruction, and infinite graphs."In his first papers Nash-Williams considered the knight's tour and random walk problems on infinite graphs; the latter paper included an important recurrence criterion for general Markov chains, {{and was also}} the first to apply electrical <b>network</b> <b>techniques</b> of Rayleigh to random walks. His dissertation, which he finished in 1958, concerned generalizations of Euler tours to infinite graphs. Welsh writes that his subsequent work defining and characterizing the arboricity of graphs (discovered in parallel and independently by W. T. Tutte) has [...] "had a huge impact," [...] in part because of its implications in matroid theory. Nash-Williams also studied k-edge-connected graphs, Hamiltonian cycles in dense graphs, versions of the reconstruction conjecture for infinite graphs, and the theory of quasi-orders. He also gave a short elegant proof of Kruskal's tree theorem.|$|E
50|$|The {{lane keeping}} assist system are being {{achieved}} in modern driverless vehicle systems using image processing techniques called hough transform and canny edge detection techniques. These advanced image processing techniques derive lane data from forward facing cameras attached {{to the front of}} the vehicle. Real-time image processing using powerful computers like Nvidia's Drive PX1 are being used by many Vehicle OEMs to achieve fully autonomous vehicles in which Lane detection algorithm plays a key part. Advanced lane detection algorithms are also being developed using deep learning and neural <b>network</b> <b>techniques.</b> Nvidia has achieved high accuracy in developing self-driving features including lane keeping using the neural network based training mechanism in which they use a front facing camera in a car and run it through a route and then uses the steering input and camera images of the road fed into the neural network and make it 'learn'. The neural network then will be able to change the steering angle based on the lane change on the road and keep the car in the middle of the lane.|$|E
40|$|The {{application}} of {{artificial neural network}} to compressor performance map prediction is investigated. Different types of artificial neural networks such as general regression neural network, rotated general regression neural network proposed by the authors, radial basis function network, and multilayer perceptron network are considered. Two different models are utilized in simulating the performance map. The results indicate that while the rotated general regression neural network has the least mean error and best agreement to the experimental data; it is however, limited to interpolation application. On the other hand, if one considers a tool for interpolation as well as extrapolation applications, multilayer perceptron <b>network</b> <b>technique</b> {{is the most powerful}} candidate. Further, the compressor efficiency based on the multilayer perceptron <b>network</b> <b>technique</b> is determined. Excellent agreement between the predictions and the experimental data is obtained. Axial compressor Performance map Neural networks...|$|R
40|$|A Dynamic Preisach Model for the {{description}} of the hysteresis in Nickel Metal Hydride Battery is presented. Both the hysteresis and the dynamical features of charging and discharging cycles are described. The identification of the model is obtained by using a neural <b>network</b> <b>technique</b> developed for magnetic systems. The model is validated by some experimental tests on commercial batteries...|$|R
40|$|A neural <b>network</b> <b>technique</b> is {{used here}} to {{discriminate}} between quark and gluon jets produced in the qg-> q+photon and qq-> g+photon processes at the LHC. Considering the network as a trigger and using the PYTHIA event generator and the full event fast simulation package for the CMS detector CMSJET the signal to background ratios are obtained...|$|R
30|$|The Artificial Neural Network, Support Vector Machine and Functional <b>network</b> <b>techniques</b> are {{effectively}} useful {{to estimate the}} oil–gas ratio.|$|E
40|$|Abstract — In postal {{services}} addresses written over the envelopes {{is an important}} area where neural <b>network</b> <b>techniques</b> are very helpful. The most frequent goal of finding address constants such as City, State, and country from the letters is the recognition of offline handwritten character information. In this paper a process for extracting useful information about the address using neural <b>network</b> <b>techniques</b> has been presented. The main advantage of this process as compared with other similar approaches is that these methods are easier to implement, requires less memory and time, and also cost effective...|$|E
40|$|We {{propose to}} use a Radial Basis Function (RBF) network for source {{localization}} in the brain, and systematically compare its performance {{with that of the}} backpropagation neural network (BPNN). Also, these two neural <b>network</b> <b>techniques</b> are compared with a conventional technique, the Levenberg-Marquardt (LM) technique. We conclude that the RBF and BPNN techniques are complementary to each other in that each one excels in estimating different source parameters. Both <b>network</b> <b>techniques</b> are superior to the LM technique in the presence of noisy data typical of clinical EEG measurements...|$|E
40|$|Recent {{experiments}} incorporating multiple fast switching {{elements and}} automated system configuration in a circulating loop apparatus have enabled {{the study of}} aspects of long-haul WDM transmission unique to optically transparent <b>networks.</b> <b>Techniques</b> include per-span switching to measure the performance limits due to dispersion compensation granularity and mesh network walk-off, and applied constant-gain amplification to evaluate wavelength reconfiguration penalties...|$|R
40|$|A {{statistical}} {{approach to}} time-lapse cross-equalization, using a back-propagation Neural <b>Network</b> <b>technique</b> is presented. Analysis {{of the differences}} between two vintage datasets is done by training at a region away from the production zone. The same concept is used for offset equalization prior to AVO analysis. Synthetic tests and a real data example are presented, demonstrating the concept...|$|R
40|$|The main {{objectives}} of this note are {{to point out}} some strengths and some limitations of Kirkwood's algebraic method for decision problems, and to propose a modification to address the limitations. The modification {{is based on the}} valuation <b>network</b> <b>technique,</b> and it enables us to better relate Kirkwood's method to the graphical <b>techniques</b> of valuation <b>networks</b> and influence diagrams...|$|R
40|$|In this paper, {{visualization}} and neural <b>network</b> <b>techniques</b> {{are applied}} together to a power transformer condition monitoring system. Through visualizing {{the data from}} the chromatogram of oil-dissolved gases by 2 -D and/or 3 -D graphs, the potential failures of the power transformers become easy to be identified. Through employing some specific neural <b>network</b> <b>techniques,</b> {{the data from the}} chromatogram of oil-dissolved gases as well as those from the electrical inspections can be effectively analyzed. Experiments show that the described system works quite well in condition monitoring of power transformers...|$|E
30|$|The logger {{application}} logs power-related records {{using the}} smart battery interface inside the device. The datasets logged overtime are {{then used to}} develop power models using neural <b>network</b> <b>techniques.</b>|$|E
30|$|Our ASR {{back-end}} {{relies on}} neural <b>network</b> <b>techniques</b> for acoustic and language modeling to achieve high recognition performance. Moreover, we also employ unsupervised environmental adaptation {{to mitigate the}} mismatch between training and testing acoustic conditions.|$|E
40|$|Scheduling of {{semiconductor}} {{wafer fabrication}} system {{is identified as}} a complex problem, involving multiple and conflicting objectives (meeting due dates and minimizing waiting time for instance) to satisfy. In this study, we propose an effective approach based an artificial neural <b>network</b> <b>technique</b> embedded in a multiobjective optimization loop for multi-decision scheduling problems in a semiconductor wafer fabrication environment...|$|R
40|$|International audienceIntegration {{of product}} {{representation}} and process planning is necessarily to couple features of product data and machining processes. The product representation {{and knowledge of}} design and process planning should be shared and distributed between a product designer and process planner. Cooperative design and process planning works are proposed in this paper in order to integrate and exchange information between team members to obtain the efficiency of product design and process planning. In addition, this paper presents the integration of product representation and process planning of rotational parts based on neural <b>networks</b> <b>technique.</b> The neural <b>networks</b> <b>technique</b> is used to contribute in selecting suitable machining process of rotational parts. In addition, we also present CoDeMo (Cooperative Designing Modeler). It is a platform using support cooperative methodology for integrating the rotational product representation and process planning. The case study is tested with a sample part from the exemplary company...|$|R
40|$|Integrated use of {{statistical}} process control (SPC) and engineering process control (EPC) has better performance than that by solely using SPC or EPC. But integrated scheme {{has resulted in the}} problem of “Window of Opportunity” and autocorrelation. In this paper, advanced T 2 statistics model and neural networks scheme are combined to solve the above problems: use T 2 statistics technique {{to solve the problem of}} autocorrelation; adopt neural <b>networks</b> <b>technique</b> to solve the problem of “Window of Opportunity” and identification of disturbance causes. At the same time, regarding the shortcoming of neural <b>network</b> <b>technique</b> that its algorithm has a low speed of convergence and it is usually plunged into local optimum easily. Genetic algorithm was proposed to train samples in this paper. Results of the simulation ex-periments show that this method can detect the process disturbance quickly and accurately as well as identify the dis-turbance type...|$|R
