13|10|Public
40|$|Task {{management}} (TM) {{is always}} {{performed on the}} flight deck, although not always explicitly, consistently, or rigorously. Nowhere is TM as important {{as it is in}} dealing with <b>non-normal</b> <b>situations.</b> The objective {{of this study was to}} analyze pilot TM behavior for <b>non-normal</b> <b>situations.</b> Specifically, the study observed pilots ’ performance in a full workload environment in order to discern their TM strategies. This study identified four different TM prioritization and allocation strategies: ‘Aviate-Navigate-Communicate-Manage Systems; ’ ‘Perceived Severity; ’ ‘Procedure Based; ’ and ‘Event/Interrupt Driven. ’ Subjects used these strategies to manage their personal workload and to schedule monitoring and assessment of the situation. The ‘Perceived Severity ’ strategy for personal workload management combined with the ‘Aviate-Navigate-Communicate- Manage Systems ’ strategy for monitoring and assessing appeared to be the most effective (fewest errors and fastest response times) in responding to the novel system failure used in this study...|$|E
40|$|This thesis, using a {{computer}} simulation, studies {{the effect of the}} normal distribution assumption on the power of several many-sample location and scale test procedures. It also suggests an almost robust parametric test, namely numerical likelihood ratio test (NLRT) for <b>non-normal</b> <b>situations.</b> The NLRT is found better than all of the tests considered. Some real life data sets were used as examples...|$|E
40|$|The {{goal of this}} {{research}} is increased safety and human performance in aviation. Human errors are often consequences of actions brought about by poor design. The pilot communicates with the aircraft system through an interface in cockpit. In an alerting situation this interface includes an auditory alerting system. Pilots complain that they may be both disturbed and annoyed of alerts, which may affect performance, especially in <b>non-normal</b> <b>situations</b> when the mental workload is high. This research is based on theories in human factors /ergonomics and cognitive engineering with the assumption that improved human performance within a system increase safety. Cognitive engineering is a design philosophy for reducing the effort required by cognitive functions by changing the technical interface, which may lead to improved performance...|$|E
40|$|Abstract In this paper, {{the single}} {{sampling}} plan for variables under measurement error for non-normal distributions represented by the first four terms of an Edgeworth series is studied for known σ case. The effect of using the normal theory sampling plan in a <b>non-normal</b> <b>situation</b> is studied by obtaining the distorted errors {{of the first and}} second kind. As one will be interested in having a suitable sampling plan under measurement error for non-normal variables, the values of n and k are determined...|$|R
40|$|This chapter {{contains}} {{information on}} dealing with <b>non-normal</b> and emergency <b>situations</b> that may occur in flight. The key to successful management of an emergency situation, and/or preventing a <b>non-normal</b> <b>situation</b> from progressing into a true emergency, is a thorough familiarity with, and adherence to, the procedures developed by the airplane manufacturer and contained in the FAA-approved Airplane Flight Manual and/or Pilot’s Operating Handbook (AFM/POH). The following guidelines are generic and {{are not meant to}} replace the airplane manufacturer’s recommended procedures. Rather, they are meant to enhance the pilot’s general knowledge in the area of non-normal and emergency operations. If any of the guidance in this chapter conflicts in any way with the manufacturer’s recommended procedures for a particular make and model airplane, the manufacturer’s recommended procedures take precedence. EMERGENCY LANDINGS This section contains information on emergency landing techniques in small fixed-wing airplanes. The guidelines that are presented apply to the more adverse terrain conditions for which no practical training is possible. The objective is to instill in the pilot the knowledge that almost any terrain can be considered “suitable ” for a survivable crash landing if the pilot knows how to use the airplane structure for self-protection and the protection of passengers. TYPES OF EMERGENCY LANDINGS The different types of emergency landings are defined as follows...|$|R
40|$|Process {{capability}} {{indices are}} very important process quality assessment tools in automotive industries. The common process capability indices (PCIs) Cp, Cpk, Cpm are widely used in practice. The use of these PCIs {{based on the assumption}} that process is in control and its output is normally distributed. In practice, normality is not always fulfilled. Indices developed based on normality assumption are very sensitive to non- normal processes. When distribution of a product quality characteristic is non-normal, Cp and Cpk indices calculated using conventional methods often lead to erroneous interpretation of process capability. In the literature, various methods have been proposed for surrogate process capability indices under non normality but few literature sources offer their comprehensive evaluation and comparison of their ability to capture true capability in <b>non-normal</b> <b>situation.</b> In this paper, five methods have been reviewed and capability evaluation is carried out for the data pertaining to resistivity of silicon wafer. The final results revealed that the Burr based percentile method is better than Clements method. Modelling of non-normal data and Box-Cox transformation method using statistical software (Minitab 14) provides reasonably good result as they are very promising methods for non - normal and moderately skewed data (Skewness <= 1. 5) ...|$|R
40|$|Many {{tests for}} mean {{differences}} utilize statistics based on a. comparison of 'hypothesis ' and 'residual ' sums of squares. The probability distribution of such statistics usually is derived {{under the assumption}} of normally distributed errors. The frequent occurrence of data from non-normal distributions leads one to ask how closely the actual distributions are approximated by their normally derived counter-parts. Permutation theory, which {{has been used to}} investigate this question in univariate situations, is applied here to the multivariate trace statistic. The results, summa. rized at the end of section 4, indicate that the permutation distri-bution of the trace statistic is reasonably approximated by its normally derived counterpart for a wide class of <b>non-normal</b> <b>situations.</b> For example, the nature of the regression matrix is an important determinant of this agreement. Otherwise an approximation incorporating fourth order k-statistics is suggested...|$|E
40|$|The {{effect size}} (ES) has been mainly {{introduced}} and investigated {{for changes in}} location under an assumption of Normality for the underlying population. However, there are many circumstances where populations are non-Normal, or depend on scale and shape {{and not just a}} location parameter. Our mo- tivating application from e-commerce requires an ES which is appropriate for long-tailed distributions. We review some common ES measures. We then introduce two novel alternative ES for two-sample comparisons, one scale-free and one on the original scale of measurement, and analyse some theoretical properties. We examine these ES for two-sample comparison studies under an assumption of Normality and investigate what happens when both location and scale parameters differ. We explore ES for phe- nomena for <b>non-Normal</b> <b>situations,</b> using the Weibull family for illustration. Finally, for an application, we assess differences in customer behaviour when browsing E-commerce websites...|$|E
40|$|For {{some time}} {{aircraft}} manufacturers and {{researchers have been}} pursuing mechanisms for reducing crew workload and providing better decision support to the pilots, especially during <b>non-normal</b> <b>situations.</b> Some previous attempts to develop task managers or pilot decision support tools have not resulted in robust and fully functional systems. However, the increasing sophistication of sensors and automated reasoners, and the exponential surge {{in the amount of}} digital data that is now available create a ripe environment {{for the development of a}} robust, dynamic, task manager and decision support tool that is context sensitive and integrates information from a wide array of on-board and off aircraft sourcesa tool that monitors systems and the overall flight situation, anticipates information needs, prioritizes tasks appropriately, keeps pilots well informed, and is nimble and able to adapt to changing circumstances. This presentation will discuss the many significant challenges and issues associated with the development and functionality of such a system for use on the aircraft flight deck...|$|E
40|$|In today&# 039;s {{competitive}} business environment, it {{is becoming}} more crucial than ever to assess precisely process losses due to non-compliance to customer specifications. To assess these losses, industry is widely using process capability indices for performance evaluation of their processes. Determination of the performance capability of a stable process using the standard process capability indices requires that the underlying process data should follow a normal distribution. However, if the data is non-normal, measuring process capability using conventional methods can lead to erroneous results. Different process capability indices such as Clements percentile method and data transformation method have been proposed {{to deal with the}} <b>non-normal</b> <b>situation.</b> Although these methods are practiced in industry, there is insufficient literature to assess the accuracy of these methods under mild and severe departures from normality. This article reviews the performances of the Clements non [...] normal percentile method, the Burr based percentile method and Box [...] Cox method for non-normal cases. A simulation study using Weibull, Gamma and lognormal distributions is conducted. Burr&# 039;s method calculates process capability indices for each set of simulated data. These results are then compared with the capability indices obtained using Clements and Box [...] Cox methods. Finally, a case study based on real world data is presented...|$|R
40|$|Building {{on earlier}} work on {{abnormal}} SME growth trajectories, this paper investigates {{to what extent}} the analysis can be extended to the study of an unusual but “normal” growth pattern. The detailed case histories of two firms which might be called micro-giants are presented. These are companies that would be categorised as small firms but are actually competing, and competing successfully, in non-niche markets with much larger firms, or even multinational giants. The resource based view and modelling approaches developed in the earlier <b>non-normal</b> growth <b>situations</b> is then applied to these cases. It is argued that by viewing the management of strategic assets as part of the normal business management process, but recognising that both normal and abnormal growth behaviours can ensue, is a physiological approach. This is distinct from the “where things went wrong” or pathological approach of the earlier work...|$|R
40|$|AbstractUsing both time-series and {{cross-sectional}} data, {{a linear}} model incorporating autocorrelated random effects and sampling errors was previously proposed in small area estimation. However, in practice {{there are many}} situations that we have time-related counts or proportions in small area estimation; for example a monthly dataset {{on the number of}} incidences in small areas. The frequentist analysis of these complex models is computationally difficult. On the other hand, the advent of the Markov chain Monte Carlo algorithm has made the Bayesian analysis of complex models computationally convenient. Recent introduction of the method of data cloning has made frequentist analysis of mixed models also equally computationally convenient. We use data cloning to conduct frequentist analysis of small area estimation for Normal and <b>non-Normal</b> data <b>situations</b> with incorporating cross-sectional and time-series data. Another important feature of the proposed approach is to predict small area parameters by providing prediction intervals. The performance of the proposed approach is evaluated through several simulation studies and also by a real dataset...|$|R
40|$|Emergency and {{abnormal}} situations {{occur on}} flights everyday around the world. They range from minor situations readily managed to extremely serious and highly time-critical situations that deeply challenge {{the skills of}} even the most effective crews. How well crews respond to these situations is a function of several interacting sets of issues: (1) the design of non-normal procedures and checklists, (2) design of aircraft systems and automation, (3) specific aspects of the non-normal situation, such as time criticality and complexity of the situation, (4) human performance capabilities and cognitive limitations under high workload and stress, (5) design of training for <b>non-normal</b> <b>situations,</b> (6) philosophies, policies and practices within the industry, and (7) economic and regulatory constraints. Researchers and pilots working on NASA's Emergency and Abnormal Situations project are addressing these issues in a long-range study. In this paper we discuss these issues and illustrate them with examples from recent incidents and accidents...|$|E
40|$|An {{incident}} {{tracing system}} (ITS) is an online rapid assessment system {{to track and}} monitor disasters that may affect the country. A mixed method used to collect needed data to conduct the research (documents, interviews, and observations). It is composed {{of a set of}} modules implemented by a coordinated group of humanitarian experts to support the core functions that should be undertaken in disasters. The tools implemented for disaster risk management program monitoring. The initiative was focused on linking the humanitarian actors and providing a platform for collaboration. This collaborative online platform should facilitate interaction and assist the exchange of knowledge. This paper proposes the implementation of ITS as a comprehensive knowledge management system for disaster management with a sustainable data collection mechanism for reliable and timely information management to support decision makers in making the right decisions in a timely manner. ITS explains how KM can be brought to <b>non-normal</b> <b>situations</b> (disasters) and decision-making in disaster management practice. In a country like Sudan, ITS has played a valuable role in achieving disaster management objectives by leveraging existing knowledge, converting new knowledge into action and aid in early warning...|$|E
40|$|Abstract Background Blood leukocytes {{constitute}} two interchangeable sub-populations, the marginated and circulating pools. These two sub-compartments {{are found}} in normal conditions and are potentially affected by <b>non-normal</b> <b>situations,</b> either pathological or physiological. The dynamics between the compartments is governed by rate constants of margination (M) and return to circulation (R). Therefore, estimates of M and R may prove of great importance to {{a deeper understanding of}} many conditions. However, there has been a lack of formalism in order to approach such estimates. The few attempts to furnish an estimation of M and R neither rely on clearly stated models that precisely say which rate constant is under estimation nor recognize which factors may influence the estimation. Results The returning of the blood pools to a steady-state value after a perturbation (e. g., epinephrine injection) was modeled by a second-order differential equation. This equation has two eigenvalues, related to a fast- and to a slow-component of the dynamics. The model makes it possible to identify that these components are partitioned into three constants: R, M and S B; where S B is a time-invariant exit to tissues rate constant. Three examples of the computations are worked and a tentative estimation of R for mouse monocytes is presented. Conclusions This study establishes a firm theoretical basis for the estimation of the rate constants of the dynamics between the blood sub-compartments of white cells. It shows, for the first time, that the estimation must also take into account the exit to tissues rate constant, S B. </p...|$|E
40|$|As is well known, process {{capability}} analysis {{for more than}} one quality variables is a complicated and sometimes contentious area with several quality measures vying for recognition. When these variables exhibit <b>non-normal</b> characteristics, the <b>situation</b> becomes even more complex. The aim {{of this paper is to}} measure Process Capability Indices (PCIs) for bivariate non-normal process using the bivariate Burr distribution. The univariate Burr distribution has been shown to improve the accuracy of estimates of PCIs for univariate non-normal distributions (see for example, [7] and [16]). Here, we will estimate the PCIs of bivariate non-normal distributions using the bivariate Burr distribution. The process of obtaining these PCIs will be accomplished in a series of steps involving estimating the unknown parameters of the process using maximum likelihood estimation coupled with simulated annealing. Finally, the Proportion of Non-Conformance (PNC) obtained using this method will be compared with those obtained from variables distributed under the bivariate Beta, Weibull, Gamma and Weibull-Gamma distributions...|$|R
40|$|Abstract:- As is well known, process {{capability}} analysis {{for more than}} one quality variables is a complicated and sometimes contentious area with several quality measures vying for recognition. When these variables exhibit <b>non-normal</b> characteristics, the <b>situation</b> becomes even more complex. The aim {{of this paper is to}} measure Process Capability Indices (PCIs) for bivariate non-normal process using the bivariate Burr distribution. The univariate Burr distribution has been shown to improve the accuracy of estimates of PCIs for univariate non-normal distributions (see for example, [7] and [16]). Here, we will estimate the PCIs of bivariate non-normal distributions using the bivariate Burr distribution. The process of obtaining these PCIs will be accomplished in a series of steps involving estimating the unknown parameters of the process using maximum likelihood estimation coupled with simulated annealing. Finally, the Proportion of Non-Conformance (PNC) obtained using this method will be compared with those obtained from variables distributed under the bivariate Beta, Weibull, Gamma and Weibull-Gamma distributions. Key-Words:- Process Capability Index (PCI), bivariate Burr distribution, simulated annealing algorithm, nonnorma...|$|R
40|$|In {{this paper}} we {{consider}} the problem of generating multi-period predictions from two simple dynamic models, an autoregressive model and a geometric random walk. The autoregressive model constitutes a useful paradigm {{for many of the}} practical problems of prediction because it possesses a number of features that differentiate it sharply from the standard linear regression model. The geometric random walk model is widely used in macroeconomics and finance and is fundamentally <b>non-normal.</b> The ideal <b>situation</b> for the prediction problem would be to know the true density of the future observations. Unfortunately, that density depends on parameters that are unknown and must be estimated. We analyze six prediction functions- approximations of the true density- that attempt o circumvent this problem. We contrast he theoretical properties of the likelihood prediction function proposed by Cooley and Parke (1986) with certainty equivalence prediction functions and mean-squared error prediction functions. The results of a Monte Carlo study illustrate the relative performance of the alternative prediction functions for conditional predic-tions and for the analysis of policy interventions. The results confirm the importance of accounting for parameter uncertainty and approximating the true shape of the future density. 1...|$|R
40|$|This {{thesis is}} {{concerned}} with providing further statistical development {{in the area of}} web usage analysis to explore web browsing behaviour patterns. We received two data sources: web log files and operational data files for the websites, which contained information on online purchases. There are many research question regarding web browsing behaviour. Specifically, we focused on the depth-of-visit metric and implemented an exploratory analysis of this feature using clickstream data. Due to the large volume of data available in this context, we chose to present effect size measures along with all statistical analysis of data. We introduced two new robust measures of effect size for two-sample comparison studies for <b>Non-normal</b> <b>situations,</b> specifically where the difference of two populations is due to the shape parameter. The proposed effect sizes perform adequately for non-normal data, as well as when two distributions differ from shape parameters. We will focus on conversion analysis, to investigate the causal relationship between the general clickstream information and online purchasing using a logistic regression approach. The aim is to find a classifier by assigning the probability of the event of online shopping in an e-commerce website. We also develop the application of a mixture of hidden Markov models (MixHMM) to model web browsing behaviour using sequences of web pages viewed by users of an e-commerce website. The mixture of hidden Markov model will be performed in the Bayesian context using Gibbs sampling. We address the slow mixing problem of using Gibbs sampling in high dimensional models, and use the over-relaxed Gibbs sampling, as well as forward-backward EM algorithm to obtain an adequate sample of the posterior distributions of the parameters. The MixHMM provides an advantage of clustering users based on their browsing behaviour, and also gives an automatic classification of web pages based on the probability of observing web page by visitors in the website. ...|$|E
40|$|Abstract. The {{study of}} sums of {{possibly}} associated Bernoulli random variables has been hampered by an asymmetry between positive correlation and negative correlation. The Conway-Maxwell Binomial (COMB) distribution and its multivariate extension, the Conway-Maxwell Multinomial (COMM) distribution, gracefully model {{both positive and}} negative association. Sufficient statistics and a family of proper conjugate distributions are found. The relationship of this distribution to the exchangeable special case is ex-plored, and two applications are discussed. 1. Sums of Possibly Associated Bernoulli Variables There often are reasons to suggest that Bernoulli random variables, while identically dis-tributed, may not be independent. For example, suppose pots are planted with six seeds each, where each pot has seeds from a unique plant, but different pot’s seeds came from different plants. Suppose that success of a seedling is well-defined. If genetic similarity is the dominant source of non-independence, it is reasonable to suppose positive association. However, if competition for nutrients and sunlight predominates, association could be neg-ative. Hence, it makes sense to find a functional form that gracefully allows for either positive or negative association. “Association ” here means something more general than correlation. Correlation is a particular measure of association, familiar because of its connection with the normal dis-tribution, and its simple relationship to certain expectations. However, there is no partic-ular reason why correlation should be used in <b>non-normal</b> <b>situations</b> if it has undesirable properties. The desire for a functional form that allows for {{both positive and negative}} association runs into the following familiar fact, which is well-known, but for completeness is proved in Appendix A: Proposition 1. Suppose X 1, [...] ., Xm have (possibly different) means and variances and common pairwise correlations ρ. Then ρ ≥ − 1 /(m − 1). There are (at least) three different possible strategies for dealing with the asymmetry between positive and negative correlation revealed by the proposition: a) abandon correlation as a measure of association b) abandon exchangeability of the Bernoulli random variables 1 a...|$|E
40|$|The {{goal of this}} {{research}} is increased safety in aviation. Aviation is a highly automated and complex, as well as, safety critical human-machine system. The pilot communicates with the system via a human-machine interface in cockpit. In an alerting situation this interface is in part an auditory alerting system. Human errors are often consequences of actions brought about by poor design. Pilots complain that they may be both disturbed and annoyed of alerts, which may affect performance, especially in <b>non-normal</b> <b>situations</b> when the mental workload is high. This research is based on theories in ergonomics and cognitive engineering with the assumption that improved human performance within a system increase safety. Cognitive engineering is a design philosophy for reducing the effort required by cognitive functions by changing the technical interface, which may lead to improved performance. Knowledge of human abilities and limitations and multidisciplinary interrelated theories between humans, sounds and warnings are used. Several methods are involved in {{this research}}, such as literature studies, field studies, controlled experiments and simulations with pilots. This research defines design requirements for sounds appropriate in auditory alerts as Natural Warning Sounds. For example, they have a natural meaning within the user’s context, are compatible with the auditory information process, are pleasant to listen to (not annoying), are easy to learn and are clearly audible. A design process for auditory alerting systems is suggested. It includes methods of associability and sound imagery, which develop Natural Warning Sounds, and combines these with an appropriate presentation format. Associability is introduced and represents the required effort to associate sounds to their assigned alert function meaning. An associable sound requires less effort and fewer cognitive resources. Soundimagary is used to develop sound images. A sound image is a sound, which by its acoustics characteristics has a particular meaning to someone without prior training in a certain context. Simulations of presentation formats resulted in recommendations for cancellation capabilities and avoiding continuously repeated alerts. This research brings related theories closer to practice and demonstrates general methods that will allow designers, together with the users of the system, to apply them in their own system. QC 2010091...|$|E
40|$|The {{objective}} {{of this research is}} to develop and test a cockpit procedural aid that can compose and present procedures that are appropriate for the given flight situation. The procedure would indicate the status of the aircraft engineering systems, and the environmental conditions. Prescribed procedures already exist for normal as well as for a number of <b>non-normal</b> and emergency <b>situations,</b> and can be presented to the crew using an interactive cockpit display. However, no procedures are prescribed or recommended for a host of plausible flight situations involving multiple malfunctions compounded by adverse environmental conditions. Under these circumstances, the cockpit procedural aid must review the prescribed procedures for the individual malfunction (when available), evaluate the alternatives or options, and present one or more composite procedures (prioritized or unprioritized) in response to the given situation. A top-down function-based conceptual approach towards composing and presenting cockpit procedures is being investigated. This approach is based upon the thought process that an operating crew must go through while attempting to meet the flight objectives given the current flight situation. In order to accomplish the flight objectives, certain critical functions must be maintained during each phase of the flight, using the appropriate procedures or success paths. The viability of these procedures depends upon the availability of required resources. If resources available are not sufficient to meet the requirements, alternative procedures (success paths) using the available resources must be constructed to maintain the critical functions and the corresponding objectives. If no success path exists that can satisfy the critical functions/objectives, then the next level of critical functions/objectives must be selected and the process repeated. Information is given in viewgraph form...|$|R
40|$|The {{goal of this}} {{research}} is increased safety and human performance in aviation. Human errors are often consequences of actions brought about by poor design. The pilot communicates with the aircraft system through an interface in cockpit. In an alerting situation this interface includes an auditory alerting system. Pilots complain that they may be both disturbed and annoyed of alerts, which may affect performance, especially in <b>non-normal</b> <b>situations</b> when the mental workload is high. This research is based on theories in human factors /ergonomics and cognitive engineering with the assumption that improved human performance within a system increase safety. Cognitive engineering is a design philosophy for reducing the effort required by cognitive functions by changing the technical interface, which may lead to improved performance. Knowledge of human abilities and limitations and multidisciplinary interrelated theories between humans, sounds and warnings are integrated into {{this research}}. Several methods are included, such as literature studies, field studies, controlled experiments and simulations with pilots. This research provides design requirements for sounds appropriate as auditory alerts, defined as Natural Warning Sounds. These sounds either have a natural meaning within the user's context, or are compatible with the human's natural auditory information process, or both, they are also pleasant to listen to (not annoying), easy to learn and clearly audible. In an experimental study associability of different sounds were compared. Associability is the required effort to associate sounds to their assigned alert function meaning. The more associable a sound is it requires less effort and fewer cognitive resources. The study shows that auditory icons and animal sounds were more associable than conventional alerts! In another listening study the method of Soundimagery was used to develop soundimages. A soundimage is a sound, which by its acoustics characteristics has a particular meaning to someone without prior training in a certain context. Soundimages were successfully developed, however {{it may be difficult to}} come up with sound candidates for functions that lack sound or are not associated to a particular sound. In a simulation study different presentation formats were compared. The results show that auditory systems should have cancellation capabilities and avoid continuously repeated alerts. This research brings related theories closer to practice and demonstrates methods that will allow designers, together with the users of the system, to apply them in their own system design...|$|E

