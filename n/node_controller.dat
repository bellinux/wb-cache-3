67|182|Public
50|$|PACTOR radio {{equipment}} {{consists of an}} HF transceiver, a computer and a terminal <b>node</b> <b>controller.</b> Software running on the computer drives the terminal <b>node</b> <b>controller.</b> The most commonly used Amateur program for this purpose is Airmail.|$|E
50|$|The Zone {{control unit}} (ZCU) (aka <b>Node</b> <b>Controller),</b> {{is the middle}} layer of parking {{ultrasonic}} detector, which is to manage a group of ultrasonic detectors, detects then loops the information of the detectors and send the relevant information to a higher element or directly to central controller. One zone / <b>node</b> <b>controller</b> can support between 16 and 100 detectors depending on the manufacturer of Parking Guidance System.|$|E
50|$|The Ultra-High Frequency (UHF) unit {{contains}} a radio and a terminal <b>node</b> <b>controller</b> (TNC) {{and is the}} spacecraft’s primary communications system.|$|E
5000|$|... 6PACK, {{used with}} some {{terminal}} <b>node</b> <b>controllers,</b> uses {{a different set}} of 64 characters.|$|R
40|$|A new {{framework}} is proposed {{to cope with}} the uncertain time delay of networked control system. Event-clock-driven <b>controller</b> <b>nodes,</b> together with clock-driven sensor nodes and actuator nodes are required in this framework. Queuing Strategy is introduced both in <b>controller</b> <b>nodes</b> and actuator nodes while the time delay between <b>controller</b> <b>node</b> and actuator node is compensated by multi-step control increment given by the algorithm of General Predictive Control. An output error prediction model is built using BP neural network to deal with the time delay between sensor <b>node</b> and <b>controller</b> <b>node.</b> The principle of this model is to revise the predictive output of general predictive control model using predictive error signal; if the value of time delay exceeds the upper limit, <b>controller</b> <b>nodes</b> will immediately produce the control strategies adopting the revised predictive output, and thus the compensation for time delay between sensor <b>nodes</b> and <b>controller</b> <b>nodes</b> would be accomplished. Simulation experiments are practiced over Ethernet network which embraces both kinds of time delay. It is proved that the scheme of complete compensation remains a good control performance. Keywords...|$|R
30|$|Communication between nodes {{utilizes}} non-persistent socket connections, {{such that}} the <b>controller</b> <b>node</b> maintains a static pre-determined port for receiving messages, while other nodes may use any available port on the system. Thus, each node in the cloud, excluding the <b>controller</b> <b>node,</b> automatically selects an available port at boot time. Initial communication between nodes is done during boot time to establish {{a connection to the}} <b>controller</b> <b>node.</b> We utilize a methodology for automatically finding and connecting to the <b>controller</b> <b>node</b> via linear search over the fourth octet of the private IP range (xxx.xxx.xxx. 0 to xxx.xxx.xxx. 255). Our assumption in this case is that the <b>controller</b> <b>node</b> will exist on a predefined subnet that allows us to easily establish lines of communication without having to manually register nodes. Additionally, we can guarantee sequential ordering of IP addresses with our privately managed DHCP server. Once a communication link is established between a <b>node</b> and the <b>controller</b> <b>node,</b> the node will request membership within a specific logical group, after which communication between the <b>controller</b> <b>node</b> and that logical group will contain the node in question.|$|R
50|$|The main mission {{ground station}} {{consists}} of tracking antennas, an Ultra-High Frequency (UHF) radio, an S-Band to Very-High-Frequency (VHF) down-converter, a VHF radio, a Terminal <b>Node</b> <b>Controller</b> (TNC) and a controlling computer. It {{is the primary}} command station for controlling the spacecraft.|$|E
50|$|David V. James {{was a major}} {{contributor}} for writing the specifications including the executable C-code. Stein Gjessing’s group at the University of Oslo used formal methods to verify the coherence protocol and Dolphin Server Technology implemented a <b>node</b> <b>controller</b> chip including the cache coherence logic.|$|E
50|$|Traditionally, amateur radio {{operators}} have {{connected to}} AX.25 networks {{through the use}} of a terminal <b>node</b> <b>controller,</b> which contains a microprocessor and an implementation of the protocol in firmware. These devices allow network resources to be accessed using only a dumb terminal and a transceiver.|$|E
30|$|AsterixDB {{may also}} be used for {{processing}} of streaming data. One of the main design goals of AsterixDB has been to create a ‘one size fits a bunch’ architecture, where one technology can be utilized in multiple use cases without gluing multiple technologies together [45]. AsterixDB has a flexible data model and query language (AQL) for describing, querying, and analysing semi-structured data [13]. Algebricks is a data model-agnostic layer in AsterixDB for parallel query processing and optimization [46]. It pushes jobs into AsterixDB’s Hyracks run time as distributed acyclic graphs (DAG). The implementation architecture of AsterixDB consists of a cluster controller, metadata <b>controller,</b> and <b>node</b> <b>controllers</b> [45]. The cluster controller accepts AQL statements pushed from clients (over HTTP), which are distributed as job descriptions to Hyracks data flow engine [47], and <b>node</b> <b>controllers</b> [45].|$|R
3000|$|... a new <b>controller</b> <b>node</b> {{is elected}} in each BAN. Note {{that if the}} <b>controller</b> <b>node</b> is fixed, then R is the WSN lifetime.|$|R
50|$|As is it {{planned to}} use a PC system with a sound-card {{connected}} to the radios, all signal decoding and processing can be done inside of the PC software. This makes the system flexible and low cost comparing to hardware decoders like Terminal <b>Node</b> <b>Controllers.</b> The CPU power of a standard home PC is enough {{to do all the}} encoding calculations.|$|R
5000|$|The Cluster Controller (CC) {{is written}} in C and acts as the front end for a cluster within a Eucalyptus cloud and {{communicates}} with the Storage Controller and <b>Node</b> <b>Controller.</b> It manages instance (i.e., virtual machines) execution and Service Level Agreements (SLAs) per cluster.|$|E
50|$|A {{terminal}} <b>node</b> <b>controller</b> (TNC) is {{a device}} used by amateur radio operators {{to participate in}} AX.25 packet radio networks. It is similar in function to the Packet Assembler/Disassemblers used on X.25 networks, {{with the addition of}} a modem to convert baseband digital signals to audio tones.|$|E
5000|$|The <b>Node</b> <b>Controller</b> (NC) {{is written}} in C and hosts the virtual machine {{instances}} and manages the virtual network endpoints. It downloads and caches images from Walrus as well as creates and caches instances. While there is no theoretical limit {{to the number of}} Node Controllers per cluster, performance limits do exist.|$|E
5000|$|... 1,200 bit/s AFSK <b>node</b> <b>controllers</b> on 2 meters (144-148 MHz) are {{the most}} {{commonly}} found packet radio. For 1,200/2,400 bit/s UHF/VHF packet radio, amateurs use commonly available narrow band FM voice radios. For HF packet, 300 bit/s data is used over single side band (SSB) modulation. For high speed packet (9,600 bit/s upwards), special radios or modified FM radios must be used.|$|R
50|$|In late 2012, Quantum {{introduced}} the Lattus product family OEM'd from Amplidata, a scale-out object storage system composed of storage nodes, access <b>nodes</b> and <b>controller</b> <b>nodes</b> that are built for multiple petabyte data stores. Lattus-X {{is the first}} of a series of disk-based archives in the Lattus family that includes a native HTTP REST interface, and CIFS and NFS access to applications.|$|R
5000|$|Networking - There {{are three}} {{networking}} modes. In Managed Mode Eucalyptus manages a local network of instances, including security groups and IP addresses. In System Mode, Eucalyptus assigns a MAC address and attaches the instance's network interface {{to the physical}} network through the <b>Node</b> <b>Controller's</b> bridge. System Mode does not offer elastic IP addresses, security groups, or VM isolation. In Static Mode, Eucalyptus assigns IP addresses to instances. Static Mode does not offer elastic IPs, security groups, or VM isolation.|$|R
5000|$|An APRS {{infrastructure}} comprises {{a variety}} of Terminal <b>Node</b> <b>Controller</b> (TNC) equipment put in place by individual amateur radio operators. This includes sound cards interfacing a radio to a computer, simple TNCs, and [...] "smart" [...] TNCs. The [...] "smart" [...] TNCs are capable of determining what has already happened with the packet and can prevent redundant packet repeating within the network.|$|E
50|$|KISS (keep it simple, stupid) is a {{protocol}} for communicating with a serial terminal <b>node</b> <b>controller</b> (TNC) device used for amateur radio. This allows the TNC to combine more features {{into a single}} device and standardizes communications. KISS was developed by Mike Chepponis and Phil Karn to allow transmission of AX.25 packet radio frames containing IP packets over an asynchronous serial link, for use with the KA9Q NOS program.|$|E
5000|$|The Storage Controller (SC) {{is written}} in Java and is the Eucalyptus {{equivalent}} to AWS EBS. It communicates with the Cluster Controller and <b>Node</b> <b>Controller</b> and manages Eucalyptus block volumes and snapshots to the instances within its specific cluster. If an instance requires writing persistent data to memory outside of the cluster, it would need to write to Walrus, which is available to any instance in any cluster.|$|E
40|$|This paper {{contains}} distributed {{sensor system}} design for temperature, air humidity, and light intensity monitoring in greenhouse based Arduino Uno board. System contains 2 sensor-actuator <b>nodes,</b> and 1 <b>controller</b> <b>node</b> connected to Ethernet network through Ethernet Shield board. Sensor-actuator node with DHT 11 sensor works for taking environment informations such as temperature, air humidity, and light intensity, runs actuation {{in the form}} of emulating LED lights; and communicates with <b>controller</b> <b>node</b> which will process data using serial wire as a communication tool between nodes. Monitoring datas and user control interface is provided by <b>controller</b> <b>node</b> which can be accessed online in web browser. The system ability for monitoring environment in greenhouse and online access of environmental data generates controllable and automatic monitoring and management of plants...|$|R
30|$|In these experiments, {{two sets}} of metrics were captured. The first set of metrics {{is related to the}} time {{necessary}} for detecting and reacting to an abnormal behaviour. The second set of metrics is related to resource consumption of the MAPE-K <b>controller</b> <b>node</b> and the OpenStack <b>controller</b> <b>node.</b>|$|R
30|$|These {{steps are}} {{repeated}} after each <b>controller</b> <b>node</b> re-election.|$|R
50|$|Link-ZA is a {{multi-platform}} {{secure network}} protocol operating over HF, VHF or UHF radio or satellite link. It uses TDMA and CSMA to establish links and share data {{with up to}} 31 active nodes and an unlimited number of passive nodes. Static or dynamic routing tables are supported. Link-ZA node controllers have store and forward capability to transfer data between different radio nets. A <b>node</b> <b>controller</b> can access multiple radios and automatically select the most appropriate link.|$|E
5000|$|TAPR is an {{international}} amateur radio organization. It was founded in Tucson, Arizona, in 1981 {{by a group of}} amateurs interested in developing a terminal <b>node</b> <b>controller</b> (TNC) for amateur use. Thus, the group was named Tucson Amateur Packet Radio, Inc. After developing one of the first widely available TNCs, TAPR rapidly became a national and then international group. It now identifies itself simply by the acronym TAPR rather than the spelled-out name. TAPR no longer has any direct connection with Tucson, Arizona.|$|E
50|$|The {{communications}} {{architecture is}} based on a system flown on PCSat2. The FASTRAC implementation consists of two receivers, one transmitter, a terminal <b>node</b> <b>controller</b> (TNC), a transmitter relay board, and a receiver relay board. On FASTRAC 1 “Sara Lily”, two R-100 VHF receivers and one TA-451 UHF transmitter from Hamtronics are used. On FASTRAC 2 “Emma”, two R-451 UHF receivers and one TA-51 VHF transmitter from Hamtronics are used. The TNC used is a KPC-9612+ from Kantronics. Both the transmitter and receiver relay boards were designed and manufactured in house.|$|E
40|$|Some shared-memory {{applications}} have execution times linear in {{the number}} of processors due to unfortunate allocation of the home and ownership of cache lines. We present a modified coherency protocol which avoids this effect. Read requests are routed via "proxies", randomly-selected intermediate nodes. We present results from executiondriven simulations of a cc-numa architecture which show that proxying can yield a large speedup in cases where read contention is extreme, while only causing small slowdowns in other benchmarks. We investigate how many proxies should be used and what effect the scheme has on traffic levels and queuing of requests at <b>node</b> <b>controllers...</b>|$|R
5000|$|PU1 <b>nodes</b> are {{terminal}} <b>controllers</b> such as IBM 6670 or IBM 3767 ...|$|R
40|$|Abstract. Some shared-memory {{applications}} have execution times linear in {{the number}} of processors due to unfortunate allocation of the home and ownership of cache lines. We present a modi ed coherency protocol which avoids this e ect. Read requests are routed via &quot;, randomly-selected intermediate nodes. We present results from executiondriven simulations of a cc-numa architecture which show that proxying can yield a large speedup in cases where read contention is extreme, while only causing small slowdowns in other benchmarks. We investigate how many proxies should be used and what e ect the scheme has on tra c levels and queuing of requests at <b>node</b> <b>controllers.</b> ...|$|R
50|$|There {{are a few}} radios on {{the market}} that include a {{built-in}} AX.25 Terminal <b>Node</b> <b>Controller</b> and APRS software, and are capable of working {{with or without the}} need for an external GPS device. Common models are the mobile Kenwood TM-D700A, its replacement, the Kenwood TM-D710A and the handheld Kenwood TH-D7 series, which include the TH-D7A(G), the TH-D72, and the TH-D74, which all have a built-in GPS receiver. Yaesu entered the APRS market with their VX-8R(G) handheld and FTM-350R mobile radio (no longer in production), and also offer the newer FT1DE/DR and FT2DE/DR handhelds and FTM-400DE/DR mobile transceivers.|$|E
50|$|A basic {{packet radio}} station {{consists}} of a computer or dumb terminal, a modem, and a transceiver with an antenna. Traditionally, the computer and modem are combined in one unit, the terminal <b>node</b> <b>controller</b> (TNC), with a dumb terminal (or terminal emulator) used to input and display data. Increasingly, however, personal computers are taking over {{the functions of the}} TNC, with the modem either a standalone unit or implemented entirely in software. Alternatively, multiple manufacturers (including Kenwood and Alinco) now market handheld or mobile radios with built-in TNCs, allowing connection directly to the serial port of a computer or terminal with no other equipment required.|$|E
50|$|Cost is an {{important}} consideration when choosing PACTOR equipment. PACTOR I is open technology and modems can be purchased in the $50-$150 price range and are in ample supply. Three enhanced modes, PACTOR II, PACTOR III and PACTOR IV, are much faster but have been kept proprietary by the German company, SCS, that developed them. As a result, SCS is the only source for modems capable of these modes. The price of these modems--in some cases {{as much as an}} HF radio--discourage many potential users. As the data is compressed, and the decompression algorithm is not publicly known, the contents of PACTOR transmissions are unreadable to anyone without a PACTOR capable terminal <b>node</b> <b>controller.</b>|$|E
5000|$|Amateur radio {{operators}} began {{experimenting with}} packet radio in 1978, when—after obtaining authorization from the Canadian government—Robert Rouleau, VE2PY; Bram Frank, VE2BFH; Norm Pearl, VE2BQS; and Jacques Orsali, VE2EHP of the Montreal Amateur Radio Club Montreal, Quebec began experimenting with transmitting ASCII encoded data over VHF amateur radio frequencies using homebuilt equipment. [...] In 1980, Doug Lockhart VE7APU, and the Vancouver Area Digital Communications Group (VADCG) in Vancouver, British Columbia began producing standardized equipment (Terminal <b>Node</b> <b>Controllers)</b> in quantity {{for use in}} amateur packet radio networks. In 2003, Rouleau was inducted into CQ Amateur Radio magazine's hall of fame {{for his work on}} the Montreal Protocol in 1978.|$|R
30|$|Secure time {{synchronization}} is a paramount {{service for}} {{wireless sensor networks}} (WSNs) constituted by multiple interconnected body area networks (BANs). We propose a novel approach to securely and efficiently synchronize nodes at BAN level and/or WSN level. Each BAN develops its own notion of time. To this effect, the nodes of a BAN synchronize with their BAN <b>controller</b> <b>node.</b> Moreover, <b>controller</b> <b>nodes</b> of different BANs cooperate {{to agree on a}} WSN global and/or to transfer UTC time. To reduce the number of exchanged synchronization messages, we use an environmental-aware time prediction algorithm. The performance analysis in this paper shows that our approach exhibits very advanced security, accuracy, precision, and low-energy trade-off. For comparable precision, our proposal outstands related clock synchronization protocols in energy efficiency and risk of attacks. These results are based on computations.|$|R
3000|$|..., BAN <b>controller</b> <b>nodes</b> use the {{long-lasting}} synchronization methods. Right at {{the beginning}} of each of these periods, [...]...|$|R
