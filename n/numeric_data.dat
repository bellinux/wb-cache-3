668|221|Public
5|$|Type {{safety is}} {{variable}} in COBOL. <b>Numeric</b> <b>data</b> is converted between different representations and sizes silently and alphanumeric {{data can be}} placed in any data item that can be stored as a string, including numeric and group data. In contrast, object references and pointers may only be assigned from items of the same type and their values may be restricted to a certain type.|$|E
500|$|Also {{like the}} IRIG timecode, <b>numeric</b> <b>data</b> (minute, hour, day of year, and last two digits of year) are sent in binary-coded decimal (BCD) format {{rather than as}} simple binary integers: ...|$|E
2500|$|Gemini was {{the first}} astronaut-carrying {{spacecraft}} to include an onboard computer, the Gemini Guidance Computer, to facilitate management and control of mission maneuvers. This computer, sometimes called the Gemini Spacecraft On-Board Computer (OBC), was {{very similar to the}} Saturn Launch Vehicle Digital Computer. The Gemini Guidance Computer weighed [...] Its core memory had 4096 addresses, each containing a 39-bit word composed of three 13-bit [...] "syllables". All <b>numeric</b> <b>data</b> was 26-bit two's-complement integers (sometimes used as fixed-point numbers), either stored in the first two syllables of a word or in the accumulator. Instructions (always with a 4-bit opcode and 9 bits of operand) could go in any syllable.|$|E
50|$|ThinBASIC {{supports}} {{a wide range}} of <b>numeric</b> and string <b>data</b> types.|$|R
40|$|Using certain {{artificial}} intelligence techniques, stock data mining has given encouraging results in both trend analysis and similarity search. However, representing stock data effectively {{is a key}} issue in ensuring {{the success of a}} data mining process. In this paper, we aim to compare the performance of <b>numeric</b> and symbolic <b>data</b> representation of a stock dataset in terms of similarity search. Given the properly normalized dataset, our empirical study suggests that the results produced by <b>numeric</b> stock <b>data</b> are more consistent as compared to symbolic stock data. ...|$|R
5000|$|Some BACHO {{fields are}} {{interpreted}} differently {{depending on whether}} they contain <b>numeric</b> or alphabetic <b>data.</b>|$|R
50|$|In August 2001, the Association of Research Libraries (ARL) {{published}} SPEC Kit 263: <b>Numeric</b> <b>Data</b> Products and Services, presenting {{results from}} a survey of ARL member institutions involved in collecting and providing services for <b>numeric</b> <b>data</b> resources.|$|E
50|$|Common Lisp {{provides}} a <b>numeric</b> <b>data</b> type for arbitrarily sized rational numbers: RATIO.|$|E
5000|$|Converting <b>numeric</b> <b>data</b> types such as enums to ints or ints to floats.|$|E
30|$|In {{order to}} {{reallocate}} <b>numeric</b> values of <b>data</b> objects among distributed nodes, {{it is necessary}} to compute additional slacks of data objects at each node.|$|R
5000|$|DATA - after a dummy 0 <b>numeric</b> value, the <b>data</b> for {{the table}} follow, each row preceded by a BOT value, the entire table {{terminated}} by an EOD value ...|$|R
40|$|Although {{they can}} learn from raw data, many concept {{learning}} algorithms require that the training data contain only discrete data. However, real world problems contain, more often than not, both <b>numeric</b> and discrete <b>data.</b> So before these algorithms can be applied, data discretization (quantization) is needed. This paper introduces X 2 R, a simple and fast algorithm {{that can be applied}} to both <b>numeric</b> and discrete <b>data,</b> and generate rules from datasets like Season-Classification, Golf-Playing that contain continuous and/or discrete data. The empirical results demonstrate that X 2 R can effectively generate rules from the raw data and perform better than some of its peers in terms of the quality of rules and time complexities. 1 Introduction Concept learning is a task to learn some concepts from raw data. Real world problems normally contain both <b>numeric</b> and discrete <b>data.</b> Many concept learning algorithms can only handle discrete data. Before running these algorithms, discretization is nec [...] ...|$|R
5000|$|TACPOL {{supports}} fixed-point binary <b>numeric</b> <b>data,</b> fixed-length character strings up to 512 bytes, and fixed-length bit strings up to 32 bits. There is {{no support}} for floating point <b>numeric</b> <b>data</b> or for pointers. Arrays may {{have up to}} three dimensions, but dynamic bounds are not permitted. Additional types are records, called groups, limited to a single level of nesting, tables (arrays of groups), and unions, called cells.|$|E
5000|$|An example {{would be}} a program to {{multiply}} two vectors of <b>numeric</b> <b>data.</b> A scalar approach would be something like: ...|$|E
50|$|Through its Observatorio, MAV {{analyzes}} {{and provides}} objective, <b>numeric</b> <b>data</b> {{to inform the}} situation of visual arts professionals in Spain.|$|E
40|$|Certain visual {{information}} displays {{can be better}} than others in conveying similar information [1, 2, 3]. Representational analysis was conducted to determine the accuracy and efficiency of the newly designed graphic data display of the <b>numeric</b> bioenvironmental <b>data</b> display currently used by the Biomedical Engineers (BMEs) to monitor the International Space Station's (ISS) environment. Results support the practical application of representational analysis {{in the design of}} relational information displays...|$|R
40|$|Evolutionary {{algorithms}} {{have successfully}} {{been applied to}} software testing. Not only approaches that search for <b>numeric</b> test <b>data</b> for procedural test objects have been investigated, but also techniques for automatically generating test programs that represent object-oriented unit test cases. Compared to <b>numeric</b> test <b>data,</b> test programs optimized for object-oriented unit testing are more complex. Method call sequences that realize interesting test scenarios must be evolved. An arbitrary method call sequence is not necessarily feasible due to call dependences which exist among the methods that potentially appear in a method call sequence. The approach {{presented in this paper}} relies on a tree-based representation of method call sequences by which sequence feasibility is preserved throughout the entire search process. In contrast to other approaches in this area, neither repair of individuals nor penalty mechanisms are required. Stronglytyped genetic programming is employed to generate method call trees. In order to deal with runtime exceptions, we use an extended distance-based fitness function. We performed experiments with four test objects. The initial results are promising: high code coverages were achieved completely automatically for all of the test objects...|$|R
5000|$|It {{works as}} {{transactional}} high-speed OLTP database for XML and JSON data objects. New content can be added, updated and deleted in real-time, with real-time all changed data indexing, including full text, date, <b>numeric,</b> geospatial <b>data.</b> Index data immediately {{can be read}} for search and analytics after each document has been inserted, updated or deleted, while ACID-compliant transactions provide security and consistency. Database API also supports storage and processing of binary data as part of document data object model.|$|R
50|$|Industrial data {{patterns}} {{can be highly}} transient and interpreting them requires domain expertise, which can hardly be harnessed by merely mining <b>numeric</b> <b>data.</b>|$|E
50|$|A violin plot is {{a method}} of {{plotting}} <b>numeric</b> <b>data.</b> It is similar to box plot with a rotated kernel density plot on each side.|$|E
50|$|Some {{authors have}} criticized that most control charts focus on <b>numeric</b> <b>data.</b> Nowadays, process {{data can be}} much more complex, e.g. non-Gaussian, mix {{numerical}} and categorical, or be missing-valued.|$|E
40|$|SDS is a {{discovery}} system from <b>numeric</b> measurement <b>data.</b> It outperforms the existing systems {{in every aspect}} of search e ciency, noise tolerancy, credibility of the resulting equations and complexity of the target system that it can handle. The power of SDS comes from the use of the scale-types of the measurement data and mathematical property of identity by which to constrain the admissible solutions. Its algorithm is described with a complex working example and the performance comparison with other systems are discussed. ...|$|R
5000|$|In a {{dimensional}} approach, {{transaction data}} are partitioned into [...] "facts", which are generally <b>numeric</b> transaction <b>data,</b> and [...] "dimensions", {{which are the}} reference information that gives context to the facts. For example, a sales transaction can be broken up into facts such {{as the number of}} products ordered and the total price paid for the products, and into dimensions such as order date, customer name, product number, order ship-to and bill-to locations, and salesperson responsible for receiving the order.|$|R
40|$|AbstractThe {{purpose of}} this {{research}} is to determine the 4 th grade primary school students’ level of attaining critical reading gains in their Turkish lessons. In the study also it was aimed to reach opinions of the teachers about examining of the 4 th grade primary students’ level of attaining critical reading skills. According to the results of the study, implementation of the available activitie and critical reading gains can be said to that it provides contribute to critical reading skills of the students. However, when <b>numeric</b> <b>datas</b> are analyzed, critical reading attainment level averages of the students are seen to vary in between 32. 75 and 72. 94, and is observed to be critical reading skills an intermediate level of the students. It has further been concluded that, nearly total of the students could not have attained the gain “Determines, and questions the emotional and exaggerated elements in what he/she reads. (32. 75) ” at all. That have not still reached gains of some critical reading or that have possessed of a critical reading skills of intermediate level in the 4 th grade of students should be interrogated when considering of the gains of critical reading taught from the 2 nd grade. Expected that it provides contribute to the literature and applications with these aspects of the research...|$|R
50|$|Time series {{analysis}} {{can be applied}} to real-valued, continuous data, discrete <b>numeric</b> <b>data,</b> or discrete symbolic data (i.e. sequences of characters, such as letters and words in the English language).|$|E
50|$|Many {{control charts}} {{work best for}} <b>numeric</b> <b>data</b> with Gaussian assumptions. The {{real-time}} contrasts chart was proposed to monitor process with complex characteristics, e.g. high-dimensional, mix numerical and categorical, missing-valued, non-Gaussian, non-linear relationship.|$|E
50|$|In addition, {{the doors}} of the box contain the first powers of the digits, the {{coefficients}} of the terms of the first powers of the binomial and the <b>numeric</b> <b>data</b> of the regular polyhedra.|$|E
40|$|PROC MEANS {{is a basic}} {{procedure}} within BASE SAS ® used primarily for answering questions about quantities (How much?, What is the average?, What is the total?, etc.) It is the procedure that I use second only to PROC FREQ in both data management and basic data analysis. PROC MEANS {{can also be used}} to conduct some basic statistical analysis. This beginning tutorial will touch upon many of the practical uses of PROC MEANS and some helpful tips to expand one’s knowledge of <b>numeric</b> type <b>data</b> and give a framework to build upon and extend your knowledge of the SAS System...|$|R
40|$|Abstract: When {{investigating}} the soil erosion, we apply the satellite remote image of scale 1 : 100, 000, Set up the texture interpretation keys. Study shadow character of water erosion (include squama surface erosion, plowland surface erosion, little ditch erosion, channel erosion and ravine erosion, {{the intensity of}} soil erosion is increased), and shadow character of wind erosion. Combine RS with GIS, using the sloping analyze system and numeric information of ground, assistant by the computer, exchange each other. Deal with <b>numeric</b> image <b>data.</b> Set up the database of soil erosion intensity and Fig. database, formed the map of soil erosion...|$|R
40|$|This R (R Development Core Team, 2011) package {{contains}} software {{designed to}} recover latent dimensions (i. e. a basic space) from a <b>numeric</b> matrix of <b>data.</b> The initial development {{was conducted by}} Poole (1998), who wrote the Fortran executable that was previously used by social scientists to analyze survey data in publications such as Saiegh (2009) and Abrajan...|$|R
50|$|Until the Proposed Recommendation draft, XSD 1.1 also {{proposed}} {{the addition of}} a new <b>numeric</b> <b>data</b> type, precisionDecimal. This proved controversial, and was therefore dropped from the specification at a late stage of development.|$|E
50|$|A graph or chart is a {{information}} graphic {{that represents}} tabular, <b>numeric</b> <b>data.</b> Charts {{are often used}} {{to make it easier}} to understand large quantities of data and the relationships between different parts of the data.|$|E
50|$|MARS {{can handle}} both {{continuous}} and categorical data. MARS {{tends to be}} better than recursive partitioning for <b>numeric</b> <b>data</b> because hinges are more appropriate for numeric variables than the piecewise constant segmentation used by recursive partitioning.|$|E
50|$|These {{devices are}} the {{standard}} entry method for phones {{and easy to}} understand but are a slow means for alphanumeric data entry. They may be suitable for <b>numeric</b> entry into <b>data</b> fields. The user enters numbers on the keypad in response to prompts on the IA screen so this method is only suitable for entry of quantifiable standard information.|$|R
40|$|Lempel-Ziv (LZ) is {{a popular}} {{lossless}} data compression algorithm that produces good compression performance, but suffers from relatively slow processing speed. This paper proposes an enhanced version of the Lempel-Ziv algorithm, through incorporation of a neural pre-processor in the popular predictor-encoder implementation. It is found {{that in addition to}} the known dramatic performance increase in compression ratio that multi-stage predictive techniques achieve, the results in this paper show that overall processing speed for the multi-stage scheme can increase by more than 15 times for lossless LZ compression of <b>numeric</b> telemetry <b>data.</b> The benefits of the proposed scheme may be expanded to other areas and applications...|$|R
40|$|In this report, I first {{introduce}} {{three areas}} of interest to collaborative filtering researchers, namely: (a) how to solve the sparsity and scalability problems in recommendation systems; (b) how to rapidly develop and test collaborative filtering algorithms; and (c) how to apply collaborative filtering to unbounded <b>numeric</b> preference <b>data.</b> In the next three chapters, I described my contributions to these three areas: (a) my work on the CoFE recommendation engine; (b) my work on the SVD based algorithm; and (c) my attempt to design a new algorithm for the iTunes play count data. A summary and prospects for future work are given in the final chapter...|$|R
