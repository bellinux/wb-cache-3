260|1403|Public
50|$|HP Network Node Manager i Smart Plug-in Modules (iSPIs) extend HP Network Node Manager i softwareâ€™s (NNMi) {{fault and}} {{availability}} management with HP NNM iSPIs for performance and advanced network services. The HP Smart Plug-ins integrate fault, availability, performance and advanced network services for physical and virtualized network infrastructure. They allow network operators to determine and display <b>network</b> <b>fault,</b> availability, performance and advanced services status in one view, progress through a unified workflow, and drill down in context.|$|E
50|$|PSQM as {{originally}} conceived was not developed {{to account for}} network Quality of Service perturbations common in Voice over IP applications, items such as packet loss, delay variance (jitter) or non-sequential packets. These conditions usually give inappropriate results under heavy network load simulations, failing to account for a very real perceived loss of voice quality. Attempts to duplicate <b>network</b> <b>fault</b> conditions by introducing significant packet loss result in PSQM values that correspond to falsely inflated MOS values.|$|E
5000|$|HP Automated Network Management (ANM) {{software}} bundles HP Network Node Manager i, HP Network Automation {{and several}} HP Smart Plug-ins to unify <b>network</b> <b>fault,</b> availability, change, configuration, compliance, performance monitoring and automated diagnostics {{into a single}} solution package. [...] HP Network Node Manager i delivers a common console for unified fault, performance and configuration of IT networks. The second product in the bundle is the HP NNM iSPIs for Performance (metrics, traffic, quality assurance), designed to monitor and ensure performance of the network. The third product in the bundle is the HP iSPI Network Engineering Toolset (NET), which automates common operator tasks, and provides trap analytics and map export capabilities. HP Network Automation, which handles network change and configuration management, is the fourth product in the bundle.|$|E
5000|$|Tolerant to <b>network</b> <b>faults</b> - able {{to operate}} without an active {{connection}} between client and server ...|$|R
40|$|<b>Network</b> <b>faults,</b> such as router failures, cable outages, and {{configuration}} errors, could seriously affect network performance. In this paper, we use <b>network</b> <b>faults</b> very loosely, {{including those}} that will yield unfavorable end-to-end network performance, such as packet reordering and suboptimal routes. Diagnosing <b>network</b> <b>faults</b> on end-to-end paths is a very challenging problem, because it generally involves other domains. Even {{if it can be}} done, the process is very time consuming, because multiple sources of data, which are scattered in different places, are needed for such diagnosis. In this paper, we consider the problem of making the fault diagnosis as automatic as possible. Based on coordinated active measurement from a set of end systems, we propose a procedure of detecting <b>network</b> <b>faults</b> and identifying their locations. Although this procedure cannot be fully automated for the time being, we show that some of the components could be automated, and we are automating them in a preliminary system called MonoScope. We demonstrate the efficacy of this procedure through several real-world cases that we have encountered in our four years of network monitoring experience. Department of ComputingRefereed conference pape...|$|R
40|$|Abstract. This paper {{introduces}} the system structure of neural <b>network</b> in <b>fault</b> diagnosis, and summarizes some applications of neural <b>network</b> in <b>fault</b> diagnosis. The {{most commonly used}} neural <b>network</b> in <b>fault</b> diagnosis is BP network. The second is RBF network {{and the third is}} ART. For each neural network, the paper will discuss the neural network, and the introduce some applications. It also {{introduces the}} combination of neural networks and other techniques. In the last part, this paper points out the development trend of the neural <b>network</b> in <b>fault</b> diagnosis...|$|R
50|$|Wheel speed {{data are}} also vital in a {{brake-by-wire}} system to avoid skidding. The {{design of a}} brake-by-wire car should provide safeguards against missing some of the data samples provided by the safety-critical sensors. Popular solutions are to provide redundant sensors and to apply a fail-safe mechanism. In addition to a complete sensor loss, the electronic control unit may also suffer an intermittent (temporary) data loss. For example, sensor data can sometimes fail to reach the electronic control unit. This may happen due to a temporary problem with the sensor itself or with the data transmission path. It may also result from an instantaneous short circuit or disconnection, a communication <b>network</b> <b>fault,</b> or a sudden increase in noise. In such cases, for a safe operation, the system has to be compensated for missing data samples.|$|E
5000|$|A dual {{signalling}} {{communication device}} {{is attached to}} a control panel on a security installation and is the component that transmits the alarm to the ARC. It can do this {{in a number of different}} ways, via the GPRS radio path, via the GSM radio path or via the telephone line/or IP if that has been chosen. These multiple signalling paths are all present and live at the same time backing each other up to minimise exposure of the property to intruders. Should one fail there is always one form of back up and depending on the manufacturer chosen up to three paths working simultaneously at any one time. Prior to the availability of dual signalling systems, police and keyholders were often called out to the premises because of an alarm signal on the telephone path only to discover that it was a <b>network</b> <b>fault</b> and not a genuine alarm ...|$|E
50|$|Also, {{legitimate}} mail {{might not}} get delivered if the retry comes from a different IP address than the original attempt. When the source of an email is a server farm or goes out through {{some other kind of}} relay service, it is likely that a server other than the original one will make the next attempt. For <b>network</b> <b>fault</b> tolerance, their IPs can belong to completely unrelated address blocks, thereby defying the simple technique of identifying the most significant part of the address. Since the IP addresses will be different, the recipient's server will fail to recognize that a series of attempts are related, and refuse each of them in turn. This can continue until the message ages out of the queue if the number of servers is large enough. This problem can partially be bypassed by proactively identifying as exceptions such server farms. Likewise, exception have to be configured for multihomed hosts and hosts using DHCP. In the extreme case, a sender could (legitimately) use a different IPv6 address for each outbound SMTP connection. There is however little technical benefit in this design and no significant reason including fault tolerance why systems cannot retry from the same IP address. Indeed, retries almost always come from a very similar IP address to the first attempt in any case.|$|E
3000|$|... (ii)Fault diagnosis: the {{detection}} of <b>network</b> <b>faults</b> is implemented by the behavioral model. The model is able to detect and signal bus line short circuits and power supplies failures.|$|R
40|$|Hybrid {{multilevel}} converters (HMCs) {{are more}} attractive than the traditional multilevel converters, such as modular converters, because they offer all the features needed in a modern voltage source converter-based dc transmission system with reduced size and weight, at a competitive level of semiconductor losses. Therefore this study investigates the viability of a HMC that uses dc side H-bridge chain links, for high-voltage dc and flexible ac transmission systems. In addition, its operating principle, modulation and capacitor voltage balancing, and control are investigated. This study focuses on response of this HMC to ac and dc <b>network</b> <b>faults,</b> with special attention paid to device issues that may arise under extreme <b>network</b> <b>faults.</b> Therefore the HMC with dc side chain links is simulated as one station of point-to-point dc transmission system that operates in an inversion mode, with all the necessary control systems incorporated. The major results and findings of subjecting {{this version of the}} hybrid converter to ac and dc <b>networks</b> <b>faults</b> are presented and discussed...|$|R
40|$|This paper {{investigates the}} fault ride-through (FRT) {{capability}} of a hybrid AC/DC microgrid during both AC and DC <b>network</b> <b>faults.</b> In this investigation, commonly proposed FRT {{strategies for the}} distributed energy resources and AC and DC microgrids are implemented while the interlinking bidirectional converter is operated in power transfer mode. The investigations have shown that improvement in the AC network voltage is minimal during both AC and DC <b>network</b> <b>faults.</b> However, the DC network voltage improves and rapidly recovers after both AC and DC <b>network</b> <b>faults.</b> This is because while the AC network is relatively weak during the fault, the interlinking bi-directional converter tracks the pre-fault power reference following the fault clearance and assists with restoration of the DC bus voltage. However, this response could be detrimental if the hybrid AC/DC microgrid is operated in an islanded mode. Hence {{it is important to}} design a robust fault ride-through support scheme for the interlinking bi-directional converter in a hybrid AC/DC microgrid...|$|R
5000|$|Sam Pitroda hired on at Wescom Inc around 1974, and {{developed}} some early digital switching technology.The '580" [...] name represented the 5 functional areas or frames {{of the original}} [...] "Large PBX (lpbx)" [...] design. They were the Line, Trunk, Network, Service and Control frames. The [...] "80" [...] represented the 1980s decade which was quickly approaching while Wescom was developing its first commercial digital PBX during the 1975 to 1980 time period. The 580L PBX {{was the first of}} the 580 family of products from Wescom.In addition to an Intel 8080 CPU complex, the heart of the 580 was the digital network frame which implemented a 64 kb time-division multiplexing digital network as the basic switching fabric of the 580 DSS. The first product in the family was the 3072 timeslot 580L-PBX which had a set of six Intel 8080 microprocessor pairs, for handling individual tasks in its control complex (State, Database, Console, Register, Trunk and Line micro complexes(CPU, memory, IPBs). Each of these actually consisted of redundant processor cards, and each micro card had dual 8080 chips using hardware matching between two 8080 chips. Faults detected on any of the online micros would automatically switch to its standby copy. Intercommunication between the various micros was loaded into the appropriate software queues and sent via the hardware Interprocessor buffers (IBPs). The 580L, M and S systems also incorporated a standby Network block which could switch seamlessly into operation without dropping existing calls if a <b>Network</b> <b>fault</b> was detected. The network blocks used memory locations to contain voice data. In smaller sized systems the tasks were combined in fewer physical processors. This led to the term [...] "monogeneric" [...] software and hardware for the various sized systems.|$|E
30|$|Effects of <b>network</b> <b>fault.</b> In case of <b>network</b> <b>fault,</b> the {{protection}} and BCU on bay level will lose the capability of sampling and tripping due to shared-network of SMV and GOOSE, and {{this is also a}} problem which must be solved.|$|E
40|$|Abstract. <b>Network</b> <b>fault</b> {{location}} is {{the premise of}} fault repair. Event correlation technique is an important fault location strategy {{which has its own}} advantages, but this technique also has some defects. Automatic fault location has not been realized and it worthy further study. This paper proposes a fault location method based on event correlation and realizes a <b>network</b> <b>fault</b> location system, which uses the relationship of topological structure of network node to generate fault correlation graph and the adjacency matrix, and through the fault correlation algorithm to locate the sources of faults. At the same time, the fault data is stored in case retrieval library for next <b>network</b> <b>fault</b> location, the system improves <b>network</b> <b>fault</b> locating speed and reduces workload of network management...|$|E
30|$|The post-copy {{technique}} is effective when {{the majority of}} pages are transferred to target server before page faulty occur at destination VM and minor page faults occur due to <b>network</b> <b>faults.</b>|$|R
40|$|To devise {{effective}} {{network engineering}} strategies {{and to assess}} the quality of upstream providers, network operators would greatly benefit from the knowledge of which Internet paths might be traversed by the traffic flows entering their networks {{in the case of}} <b>network</b> <b>faults</b> or when traffic engineering measures are used. However, current methodologies do not provide this information. This paper presents methodologies to discover alternate paths that might be selected in the presence of <b>network</b> <b>faults</b> or different routing policies and to deduce the routing policies of other operators. The techniques are validated through extensive experimentation on the Internet. ...|$|R
50|$|Post-copy VM {{migration}} is initiated by suspending the VM at the source. With the VM suspended, a minimal {{subset of the}} execution state of the VM (CPU state, registers and, optionally, non-pageable memory) is transferred to the target. The VM is then resumed at the target. Concurrently, the source actively pushes the remaining memory pages of the VM to the target - an activity known as pre-paging. At the target, if the VM tries to access a page {{that has not yet}} been transferred, it generates a page-fault. These <b>faults,</b> known as <b>network</b> <b>faults,</b> are trapped at the target and redirected to the source, which responds with the faulted page. Too many <b>network</b> <b>faults</b> can degrade performance of applications running inside the VM. Hence pre-paging can dynamically adapt the page transmission order to <b>network</b> <b>faults</b> by actively pushing pages {{in the vicinity of the}} last fault. An ideal pre-paging scheme would mask large majority of <b>network</b> <b>faults,</b> although its performance depends upon the memory access pattern of the VM's workload. Post-copy sends each page exactly once over the network. In contrast, pre-copy can transfer the same page multiple times if the page is dirtied repeatedly at the source during migration. On the other hand, pre-copy retains an up-to-date state of the VM at the source during migration, whereas with post-copy, the VM's state is distributed over both source and destination. If the destination fails during migration, pre-copy can recover the VM, whereas post-copy cannot.|$|R
40|$|GMPLS-based optical <b>network</b> <b>fault</b> {{recovery}} {{does not}} consider an integration of connection when configuring a backup path. This can cause greater damages likely when a fault occurs to a link or path concentrated with many connections. Also, the concentration of such traffic results in a negative effect in terms of network survivability. This paper attempted to minimize {{the damage done by}} a <b>network</b> <b>fault</b> by selecting a more stable path and avoiding ones with lower survivability {{based on the number of}} connections to a node or link by expanding LSA of the link state algorithm. Key words: GMPLS, Optical <b>Network,</b> <b>Fault</b> Recover...|$|E
40|$|Mobile agent {{technology}} has been recognised as a potential tool for realising distributed <b>network</b> <b>fault</b> management. Mobile agents require services from mobile agent systems. Being aware of what failure semantic such services have are especially importent when <b>network</b> <b>fault</b> management is the issue. This report describes how a selected set of mobile agent systems where evaluated with respect to service failure semantics. Contents...|$|E
40|$|Abstract. In {{distance}} education network transmission process, because transmission distance is too long, transmission network {{will be affected}} by complicated external environment factors, which leads to network failure and failure in remote education video image formation, and finally causes unsmooth transmission. This paper puts forward a distributed <b>network</b> <b>fault</b> detection technology to perform fault detection for remote education transmission network nodes and characteristic analysis of the use of <b>network</b> <b>fault</b> by using genetic neural network, accurately locate fault node area so as to realize the remote education networkâ€™s fault detection. Experiments show that this method can avoid {{distance education}} <b>network</b> <b>fault</b> resulted from long transmission distance and improve the transmission efficiency of remote education video image...|$|E
40|$|The authors {{describe}} a learning classifier system (LCS) which employs genetic algorithms (GA) for adaptive online diagnosis of power transmission <b>network</b> <b>faults.</b> The system monitors switchgear indications {{produced by a}} transmission <b>network,</b> reporting <b>fault</b> diagnoses on any patterns indicative of faulted components. The system evaluates the accuracy of diagnoses via a fault simulator developed by National Grid Co. and adapts to reflect the current network topology by use of genetic algorithms...|$|R
30|$|MPI aims {{to explore}} a {{practically}} feasible solution to help network admins to automate network troubleshooting by automatically modeling the causality relationship between <b>network</b> <b>faults</b> in SDN and their related symptoms. The challenge we are tackling is to localize <b>network</b> <b>faults</b> in a large-scale SDN network with: (1) a high-level policy driven and centrally controlled network architecture; and (2) the need for dynamic and agile service provisioning. MPI uses Belief Network [24] to model {{the correlation between the}} symptoms (e.g., state mismatching) and the corresponding hardware and software faults in an SDN network. In the following, we elaborate the major steps used in MPI.|$|R
40|$|As {{consumer}} grade networking hardware {{has become}} ubiquitous in households {{there is an}} increasing need for a tool that can simplify diagnosing 802. 11 <b>network</b> <b>faults.</b> There are several tools available for diagnosing faults in large scale networks. A consumer grade diagnosis tool must be trivial {{to set up and}} provide straightforward indication of <b>network</b> <b>faults.</b> Today, consumers are limited to using observed signal strength to diagnose problems with wireless connectivity. Low signal is one cause of slowed or disrupted wireless service but a large portion of problematic wireless networks are the result of factors including but not limited to: interference from external sources operating on the same frequency, oversubscriptio...|$|R
40|$|Abstract. In the {{distribution}} <b>network</b> <b>fault</b> location, {{the impact of}} information distortion needs to be to focus on, especially when the short-circuit current is used as the fault information. Considering the distortion or failure of real-time information and other issues, the quick location method of the failure point in distribution network is analyzed. Based on the mathematical model of distribution <b>network</b> <b>fault</b> location, firefly algorithm is applied. According to the characteristics of fault location objective function in distribution network, convergence criterion is proposed, which is suitable for fault location mathematical model...|$|E
40|$|Rapid {{growth in}} the {{deployment}} of networked electronic control units (ECUs) and enhanced software features within automotive vehicles has occurred {{over the past two}} decades. This inevitably results in difficulties and complexity in in-vehicle <b>network</b> <b>fault</b> diagnostics. To overcome these problems, a framework for on-board in-vehicle network diagnostics has been proposed and its concept has previously been demonstrated through experiments. This paper presents a further implementation of <b>network</b> <b>fault</b> detection within the framework Adaptive OSEK Network Management, a new technique for detecting network level faults, is presented. It is demonstrated in this paper that this technique provides more accurate fault detection and the capability to cover more fault scenarios. ...|$|E
40|$|Abstract. The {{low-voltage}} distribution {{networks have}} some structural features, such as short supply line, more lines branch {{and influence of}} transition resistance of the short-circuit current. These characteristics seriously affect the development of fault location technology. The paper, based {{on the basis of}} the structural features about the low-voltage distribution networks, create the distribution networks of description matrix by knowledge of mathematical topology and use the distribution <b>network</b> <b>fault</b> location algorithm based on web-based structure matrix. By the algorithm, the area of fault judgment and the actual distribution <b>network</b> <b>fault</b> location are fully consistent. The new theory provides a new way of thinking for fault location in low-voltage distribution networks...|$|E
40|$|As {{computer}} networks increase in size, heterogeneity, complexity and pervasiveness, effective managementofsuch networks simultaneously {{becomes more important}} and more difficult. This paper explores in detail one aspect of <b>network</b> management, <b>fault</b> identification. Fault identification is the process whereby the existence and nature of <b>network</b> <b>faults</b> are ascertained. Characteristics of the fault identification problem are explored and existing approaches are surveyed. Interestingly,much {{of the work in}} this area makes use of techniques from Artificial Intelligence, especially expert systems...|$|R
40|$|As the {{complexity}} of communication networks increases, it becomes increasingly difficult to isolate and diagnose <b>network</b> <b>faults.</b> This maintenance problem {{is due to the}} large number of functional elements within the networks, the elements' technical complexity, and their inherent interaction. One technique to solve this problem is to use expert system technology to manage the vast amount of status information produced by these networks and to provide an automated diagnostic reasoning about the location and cause of observed faults. In this thesis, a prototype expert system based diagnostic tool for cable trunk amplifier networks is presented. This tool is capable of isolating and diagnosing the most common <b>network</b> level <b>faults</b> which occur in these type of networks. This tool was created as a proof-of-principle of the use of expert system based diagnostic tools on this type of communication network. As such, the tool was tested on a series of <b>network</b> <b>faults</b> occurring within the Rogers Ca [...] ...|$|R
50|$|TTI Telecom has a {{registered}} patent in the United States and a patent application pending in Europe. The US patent addresses the functionality of a topology-based reasoning system for root-cause analysis of <b>network</b> <b>faults,</b> {{a component of}} the Netrac FaM product line.|$|R
30|$|The other {{research}} challenges in Live VM migration are <b>Network</b> <b>fault</b> [133], memory intensive application [133], memory state between clusters [133], Live migration of nested VMM [42], Live migration of VM attached to pass-through accelerators [42] pointed by authors.|$|E
40|$|Abstractâ€”This paper {{proposes a}} {{framework}} for troubleshooting network faults pertaining to Internet applications. The system is called ANFIT which stands for Automated <b>Network</b> <b>Fault</b> Inference Tool. We have designed the system in two layered architecture in order to efficiently troubleshoot the faults. The first layer is dedicated to detect where the network has gone wrong and the second layer is to identify the cause of fault. However, at present we narrow down our focus on Web Service application. We have analyzed real failure scenarios and ANFIT has been tested against them. This paper however, presents only the parts on system framework and overall architecture of ANFIT. Index Termsâ€”automated <b>network</b> <b>fault</b> identification, network diagnosis, network troubleshooting. I...|$|E
40|$|Abstract. In {{order to}} ensure the high performance, the high reliability, the high {{availability}} and the high service quality of <b>network,</b> <b>fault</b> management has become an urgent problem to be solved. The application of Rule-Based Reasoning (RBR) and Case-Based Reasoning (CBR) is recognized as an economically viable <b>network</b> <b>fault</b> process technology. To {{meet the demands of}} <b>network</b> <b>fault</b> management, this paper presents an association analysis and processing strategy for network events based on the combination of RBR and CBR. The network events are firstly passed through pretreatment module, the useful ones are saved for the following processing. Then, the first processing strategy which is more appropriate is select by RBR/CBR selector. Besides, a new CBR processing strategy is proposed by this paper. By the use of the algorithm based on the preliminary screening and the calculating of variance, the processing efficiency of CBR improved. At last, if the alarm event is not been solved, the system will alarm the related people and the solution can be used to rich the rule base and the case base. Based on these steps, experimental results are given to verify the proposed strategy...|$|E
30|$|Recent {{advances}} in computing offer {{storage and processing}} capabilities required for training and testing ML models for the voluminous data. For instance, Cloud Computing offers seemingly infinite compute and storage resources, while Graphics Processing Units [342] (GPUs) and Tensor Processing Units [170] (TPUs) provide accelerated training and inference for voluminous data. It {{is important to note}} that a trained ML model can be deployed for inference on less capable devices e.g. smartphones. Despite these advances, network operations and management still remains cumbersome, and <b>network</b> <b>faults</b> are prevalent primarily due to human error [291]. <b>Network</b> <b>faults</b> lead to financial liability and defamation in reputation of network providers. Therefore, there is immense interest in building autonomic (i.e. self-configuring, self-healing, self-optimizing and self-protecting) networks [28] that are highly resilient.|$|R
40|$|This paper {{presents}} a methodology for the relative location of voltage sags source based on voltage measurements only. <b>Network</b> <b>faults</b> {{are the most}} frequent disturbances in the electrical systems and in turn are the causes that generate most voltage sags. Thus, the proposed algorithm considers only voltage sags by <b>network</b> <b>faults</b> and {{a minimum of three}} voltage meters are required. Power quality can be evaluated automatically using the characterising and extracting information from voltage records. The positive sequence voltages are the descriptors used to determine the relative location of the voltage sags causes and the methodology is applied to a simulation where its effectiveness is verified. Matlab was used for validating this methodology, receiving voltage records of simulated voltage sags in ATP-EMTP...|$|R
40|$|Abstractâ€”This paper {{presents}} an availability study of {{storage area network}} (SAN) systems built on TCP/IP networks. We use a new benchmark tool called N-SPEK (Networked-Storage Performability Evaluation Kernelmodule) to measure performance dynamics under commercial workloads with various faulty conditions of different parts of a SAN system. By injecting <b>network</b> <b>faults,</b> controller faults, and disk faults into the SAN system, we observe and analyze system availability in terms of performability (performance + availability). Two specific SAN systems are considered in this paper: iSCSI-based SAN and STICS (SCSI-To-IP Cache Storage) [1] based SAN. Experiments are carried out to measure and compare performability of the two SAN systems under different faulty conditions. It is observed that STICS-based SAN shows more stable performance and better availability than iSCSI-based SAN when <b>network</b> <b>faults</b> are injected. I...|$|R
