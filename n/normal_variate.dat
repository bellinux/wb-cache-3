133|104|Public
5000|$|... where Z is a {{standard}} <b>normal</b> <b>variate,</b> independent of both Z1 and Z2, ε is a zero-mean error and d is a parameter. From these relationships, the associated RMM quantile function is (Shore, 2011): ...|$|E
50|$|The polar form {{requires}} 3/2 multiplications, 1/2 logarithm, 1/2 square root, and 1/2 division {{for each}} <b>normal</b> <b>variate.</b> The {{effect is to}} replace one multiplication and one trigonometric function with a single division and a conditional loop.|$|E
5000|$|By {{the normal}} {{approximation}} to a binomial {{this is the}} squared of one standard <b>normal</b> <b>variate,</b> and hence is distributed as chi-squared with 1 degree of freedom. Note that the denominator is one standard deviation of the Gaussian approximation, so can be written ...|$|E
40|$|AbstractIn {{this paper}} first a {{characterization}} of the multivariate skew normal distribution is given. Then the joint moment generating functions of two quadratic forms, and a linear compound and a quadratic form in skew <b>normal</b> <b>variates,</b> have been derived and conditions for their independence are given. Distribution of the ratios of quadratic forms in skew <b>normal</b> <b>variates</b> has also been studied...|$|R
3000|$|Two sets of n {{standard}} <b>Normal</b> <b>variates</b> are randomly generated (Nd(0, 1), Nh(0, 1)) and column {{bound to}} form matrix [N] [...]...|$|R
5000|$|Let z [...] (z1, …, zN)T be a vector whose {{components}} are N independent standard <b>normal</b> <b>variates</b> (which can be generated, for example, {{by using the}} Box-Muller transform).|$|R
5000|$|Expanding Yk, as {{given on}} the right-hand-side, into a Taylor series around zero, {{in terms of}} powers of Z (the {{standard}} <b>normal</b> <b>variate),</b> and then taking expectation on both sides, assuming that cZ<<η so that η+cZ≈η, an approximate simple expression for the k-th non-central moment, based on the first six terms in the expansion, is: ...|$|E
5000|$|The {{basic form}} {{requires}} two multiplications, 1/2 logarithm, 1/2 square root, and one trigonometric function for each <b>normal</b> <b>variate.</b> On some processors, the cosine and sine {{of the same}} argument can be calculated in parallel using a single instruction. Notably for Intel-based machines, one can use the fsincos assembler instruction or the expi instruction (usually available from C as an intrinsic function), to calculate complex ...|$|E
50|$|In {{probability}} theory, the slash {{distribution is}} the probability distribution {{of a standard}} <b>normal</b> <b>variate</b> divided by an independent standard uniform variate. In other words, if the random variable Z has a normal distribution with zero mean and unit variance, the random variable U has a uniform distribution on 0,1 and Z and U are statistically independent, then the random variable X = Z / U has a slash distribution. The slash distribution {{is an example of}} a ratio distribution. The distribution was named by William H. Rogers and John Tukey in a paper published in 1972.|$|E
5000|$|This {{method of}} {{producing}} a pair of independent standard <b>normal</b> <b>variates</b> by radially projecting a random point on the unit circumference to a distance given by the square root of a chi-square-2 variate is called the polar method for generating a pair of normal random variables, ...|$|R
40|$|A b s t r a c t Ratios of {{quadratic}} {{forms in}} <b>normal</b> <b>variates</b> arise in many econometrie and statistical applications. Their exact distribution can be computed using e. g. a procedure due to Imhof (1961). In this paper two examples arising in dynamic models will be considered. First, {{the distribution of}} a test of linear restrictions on the coeffi-cients of a regression model with autocorrelated errors will be analyzed. Second, {{the distribution of the}} sample autocorrelations of a series generated by an autoregressive- integrated- moving average model will be investigated. In both cases, the exact distribution will be compared with the (approximate) distributions used in applied work. Some remarks on the usefulness of the exact distribution of quotients of quadratic forms in <b>normal</b> <b>variates</b> conclude the paper...|$|R
40|$|It {{is shown}} that matrix quotients of submatrices of a spherical matrix are {{distributed}} as matrix Cauchy. This generalizes known results for scalar ratios of independent <b>normal</b> <b>variates.</b> The derivations are simple and {{make use of}} the theory of invariant measures on manifolds. Cauchy quotients invariant measures matrix variates spherical distributions...|$|R
5000|$|Response Modeling Methodology (RMM) is {{a general}} {{platform}} for modeling monotonic convex relationships. RMM had been initially developed {{as a series of}} extensions to the original inverse Box-Cox transformation:   where y is a percentile of the modeled response, Y (the modeled random variable), z is the respective percentile of a <b>normal</b> <b>variate</b> and λ is the Box-Cox parameter. Note that as λ goes to zero, the inverse Box-Cox transformation becomes:  an exponential model. Therefore, the original inverse Box-Cox transformation contains a trio of models: linear (λ=1), power (λ≠1, λ≠0) and exponential (λ=0). This implies that on estimating λ, using sample data, the final model is not determined in advance (prior to estimation) but rather as a result of estimating. In other words, data alone determine the final model.|$|E
40|$|We offer a {{procedure}} for generating a gamma variate as the cube of a suitably scaled <b>normal</b> <b>variate.</b> It is fast and simple, assuming {{one has a}} fast way to generate normal variables. In brief: generate a <b>normal</b> <b>variate</b> x and a uniform variate U until In(U) 1. The gamm{{a procedure}} is particularly fast for C implementation if the <b>normal</b> <b>variate</b> is generated in-line, via the #define feature. We include such an inline version, based on our ziggurat method. With it, and an inline uniform generator, gamma variates can be produced in 400 MHz CPUs at better than 1. 3 million per second, with the parameter a changing from call to call. Categories and Subject Descriptors: G. 4 [Mathematics of Computing]: Mathematical Software; 1. 6 [Computing Methodologies]: Simulation and Modeling. link_to_OA_fulltex...|$|E
3000|$|... and z is a {{standard}} <b>normal</b> <b>variate.</b> In addition, if the assets have mean returns, μ, the portfolio return may be accessed {{with the knowledge of}} three numbers m=a [...]...|$|E
40|$|Grant No. AFOSR- 62 [...] 148 Methods of {{construction}} of cumulative sum control charts for folded <b>normal</b> <b>variates</b> are described. These charts {{are likely to}} be useful Then the sign of an approximately normally distributed quantity is lost in measurement. Some assessment is given of the information lost by omission of the sign...|$|R
5000|$|Generate {{independent}} gamma , and <b>normal</b> [...] <b>variates,</b> {{independently of}} past random variates.|$|R
40|$|In {{this paper}} we extend {{the result of}} Bateman (1949) to obtain the joint {{conditional}} characteristic function of a sum of squares of n noncentral squares of independent <b>normal</b> <b>variates</b> and s 1 of their linear combinations given that these variates lie in a subspace of dimension n - s 2. Characteristic function Chi-bar square Subspace...|$|R
40|$|Using Weyl's {{formula for}} {{the volume of}} the tube about a {{manifold}} in the unit sphere, we show that the distribution of the squared length of the projection of the <b>normal</b> <b>variate</b> to any smooth convex cone is a mixture of chi-squared distributions and we give the explicit formulas for the weights. We also give the application of our work to circular cones. Weyl's formula Tube volume Chi-bar squared distribution Projection Convex cone...|$|E
40|$|Consistency of the {{bootstrap}} second moments {{does not}} usually follow from the proofs of {{consistency of the}} distribution of the bootstrap. Here it is shown that the convergence of the bootstrap distribution to a <b>normal</b> <b>variate</b> implicitly defines a consistent estimator for the asymptotic second moments. The estimator is based on the L-estimation of the scale parameter of arbitrary linear combinations of the bootstrap sequence and uses Classical Minimum Distance techniques to impose the positive semi-definiteness restrictions. Copyright 2005 Royal Economic Society...|$|E
40|$|In {{this thesis}} {{we present a}} {{solution}} for the problem of predicting the chemical and physical properties of paper from spectrometric data. We used a data set that consists of over 1000 samples of paper. For each sample 15 chemical and physical properties and its near-infrared spectra were measured. We used the following machine learning methods to predict the properties of paper: linear regression, pace regression, a nearest neighbor-based model, regression trees, a support vector machine, principal component regression, partial least squares regression, a multi-layer perceptron, and a radial basis function network. The prediction task {{turned out to be}} linear. Therefore, linear regression, principal component regression, and partial least squares regression gave the best results. Many outside factors affect the spectra and cause different types of interference. We used the following spectra preprocessing methods to remove the interference and improve the predictions: absorbance transformation, Kubelka-Munk transformation, multiplicative scatter correction, standard <b>normal</b> <b>variate</b> transformation, spectra derivation and orthogonal signal correction. We also investigated how preprocessing affects the machine learning methods. The results show that most preprocessing methods improve the models' predictions. The standard <b>normal</b> <b>variate</b> transformation and multiplicative scatter correction gave the best results. We tried to further improve the predictions with calibration. However, calibration did not improve the predictions...|$|E
40|$|Strongly {{reproductive}} exponential {{models with}} affine dual foliations {{are known to}} allow of a decomposition analogous to the standard decomposition theorem for Chi-squared distributed quadratic forms in <b>normal</b> <b>variates.</b> It is shown that when the components are identically distributed, then necessarily each component follows the gamma law. affine dual foliations Choquet-Deny theorem decomposition Gamma distribution independence natural exponential family...|$|R
5000|$|... where [...] is {{standard}} <b>normal</b> random <b>variate.</b> The exponential random variate is : ...|$|R
5000|$|Note that ε1 {{represents}} uncertainty (measurement imprecision or otherwise) in {{the explanatory}} variables (included in the LP). This is {{in addition to}} uncertainty associated with the response (ε2). Expressing ε1 and ε2 in terms of standard <b>normal</b> <b>variates,</b> Z1 and Z2, respectively, having correlation ρ, and conditioning Z2 | Z1=z1 (Z2 given that Z1 is equal to a given value z1), we may write {{in terms of a}} single error, ε: ...|$|R
40|$|Measurement error {{effect on}} the power of control charts for zero {{truncated}} Poisson distribution and ratio of two Poisson distributions are recently studied by Chakraborty and Khurshid (2013 a) and Chakraborty and Khurshid (2013 b) respectively. In this paper, in addition to the expression for the power of control chart for ZTBD based on standardized <b>normal</b> <b>variate</b> is obtained, numerical calculations are presented to see the effect of errors on the power curve. To study the sensitivity of the monitoring procedure, average run length (ARL) is also considered...|$|E
40|$|Classification of {{data that}} arise as signals or images often {{requires}} a standard-ization step so that information extracted from biologically equivalent signals can be quantified for comparison across classes. Differences in global trend, total en-ergy, high-frequency noise and/or local background can arise from variabilities due to instrumentation or conditions during data collection. This article considers some common ways in which such variation is adjusted for and introduces a generalization of the popular “standard <b>normal</b> <b>variate</b> ” transformation. Examples from three types of spectroscopy data illustrate the method and its properties...|$|E
40|$|Sample size can be {{calculated}} from many online calculators or tables. But {{the use of these}} instruments is rational only when we understand our input data and the concept behind them completely. Terminologies like confidence interval, confidence limit, standard error of mean, margin of error, standard <b>normal</b> <b>variate,</b> power, significance level etc. and extent to which population size or chances of occurrence of an outcome can affect our sample size remain to be well understood before using these software solutions. [Int J Basic Clin Pharmacol 2012; 1 (3. 000) : 223 - 224...|$|E
40|$|This article extends and amplifies {{on results}} from a paper of over forty years ago. It {{provides}} software for evaluating the density and distribution functions of the ratio z/w for any two jointly <b>normal</b> <b>variates</b> z, w, and provides details on methods for transforming a general ratio z/w into a standard form, (a+x) /(b+y), with x and y independent standard normal and a, b non-negative constants. It discusses handling general ratios when, in theory, none of the moments exist yet practical considerations suggest there should be approximations whose adequacy can be verified {{by means of the}} included software. These approximations show that many of the ratios of <b>normal</b> <b>variates</b> encountered in practice can themselves be taken as normally distributed. A practical rule is developed: If a < 2. 256 and 4 < b then the ratio (a+x) /(b+y) is itself approximately normally distributed with mean µ = a/(1. 01 b −. 2713) and variance σ 2 = (a 2 + 1) /(b 2 +. 108 b − 3. 795) − µ 2...|$|R
40|$|This paper {{uses the}} {{approach}} of Im, Pesaran and Shin [Im, K. S., Pesaran, M. H., Shin, Y, 2003. Testing for unit roots in heterogeneous panels. Journal of Economics 115, 53 - 74. ] to propose seasonal unit root tests for dynamic heterogeneous panels. The standardised t-bar and F-bar statistics are simply averages of the HEGY tests across groups. These statistics converge to standard <b>normal</b> <b>variates.</b> (C) 2004 Elsevier B. V. All rights reserved. ...|$|R
40|$|We suggest several goodness-of-fit (GOF) methods {{which are}} {{appropriate}} with Type-II right censored data. Our {{strategy is to}} transform the original observations from a censored sample into an approximately i. i. d. sample of <b>normal</b> <b>variates</b> and then perform a standard GOF test for normality on the transformed observations. A simulation study with several well known parametric distributions under testing reveals the sampling properties of the methods. We also provide theoretical analysis of the proposed method...|$|R
40|$|Visible-near-infrared hyperspectral imaging {{was tested}} for its {{suitability}} for monitoring the moisture content (MC) of wood samples during natural drying. Partial least-squares regression (PLSR) prediction of MC {{was performed on}} the basis of average reflectance spectra obtained from hyperspectral images. The validation showed high prediction accuracy. The results were compared concerning the PLSR prediction of MC mapping from raw spectra and standard <b>normal</b> <b>variate</b> (SNV) treatment. SNV pretreatment leads to the best results for visualizing the MC distribution in wood. Hyperspectral imaging has a high potential for monitoring the water distribution of wood. (Résumé d'auteur...|$|E
40|$|Frequent {{variations}} in spectral intensity due to particle size and/or of {{particle size distribution}} are observed in plant products processed in powder form and scanned with near infrared reflectance (NIR). In this study, two grinders, with differences in time consumption, practicality and providing homogenates with different particle size range and distribution, were tested to evaluate their effects on NIR spectra. Optimisation of NIR calibration was necessary before predicting lignocellulosic compounds in sugarcane (Saccharum spp.) samples with coarse particle size to supply a pre-existing ecophysiological growth model. Sixty samples from three varieties, grown in four contrasting pedoclimatic areas and from five anatomical parts were scanned and then analysed by biochemical fractionation. Different calibration methods, resulting in a combination of multiple linear regressions (MLR) applied to three calibration sets (fine, coarse and mixed particle sizes) treated with six data pretreatments-first derivative (D), second derivative (D 2), multiplicative scatter correction (MSC), standard <b>normal</b> <b>variate</b> and detrend (SNVD), standard <b>normal</b> <b>variate</b> and detrend successively followed by first derivative (SNVD-D) or second derivative (SNVD-D 2) -were investigated. The best NIR model statistical values were obtained by calibration developed on a mixed calibration set treated by SNVD-D 2. Results confirmed that NIR spectroscopy could be an accurate and efficient method to predict lignocellulosic compounds in different botanical parts of sugarcane samples when used as input to an ecophysiological growth model. (Résumé d'auteur...|$|E
40|$|Measurement {{error is}} the {{difference}} between the true value and the measured value of a quantity that exists in practice and may considerably affect the performance of control charts in some cases. Measurement error variability has uncertainty which can be from several sources. In this paper, we have studied the effect of these sources of variability on the power characteristics of control chart and obtained the values of average run length (ARL) for zero-truncated Poisson distribution (ZTPD). Expression of the power of control chart for variable sample size under standardized <b>normal</b> <b>variate</b> for ZTPD is also derived...|$|E
40|$|Abstract In {{this paper}} {{we examine the}} ¯nite-sample {{properties}} of the approximate maximum likelihood estimate (MLE) of the fractional di®erencing parameter d in an ARFIMA(p, d, q) model based on the wavelet coe±cients. Ignoring wavelet coe±cients of higher order of resolution, the remaining wavelet coe±cients approximate a sample of independently and identically distributed <b>normal</b> <b>variates</b> with homogeneous variance within each level. The approximate MLE performs satisfactorily and provides a robust estimate for which the short memory component need not be speci¯ed...|$|R
40|$|Log {{periodogram}} (LP) regression {{is shown}} to be consistent {{and to have a}} mixed normal limit distribution when the memory parameter d= 1. Gaussian errors are not required. The proof relies on a new result showing that asymptotically infinite collections of discrete Fourier transforms (dft 2 ̆ 7 s) of a short memory process at the fundamental frequencies {{in the vicinity of the}} origin can be treated as asymptotically independent <b>normal</b> <b>variates,</b> provided one does not include too many dft 2 ̆ 7 s in the collection...|$|R
40|$|Wallace has {{proposed}} {{a new class of}} pseudo-random generators for <b>normal</b> <b>variates.</b> These generators do not require a stream of uniform pseudo-random numbers, except for initialisation. The inner loops are essentially matrix-vector multiplications and are very suitable for implementation on vector processors or vector/parallel processors such as the Fujitsu VPP 300. In this report we outline Wallace's idea, consider some variations on it, and describe a vectorised implementation RANN 4 which is more than three times faster than its best competitors (the Polar and Box-Muller methods) on the Fujitsu VP 2200 and VPP 300...|$|R
