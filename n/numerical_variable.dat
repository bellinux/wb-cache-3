38|674|Public
50|$|Optimal {{discriminant}} analysis may {{be thought of}} as a generalization of Fisher's linear {{discriminant analysis}}. Optimal discriminant analysis is an alternative to ANOVA (analysis of variance) and regression analysis, which attempt to express one dependent variable as a linear combination of other features or measurements. However, ANOVA and regression analysis give a dependent variable that is a <b>numerical</b> <b>variable,</b> while optimal discriminant analysis gives a dependent variable that is a class variable.|$|E
5000|$|Languages with no {{explicit}} Boolean data type, like C90 and Lisp, {{may still}} represent truth values {{by some other}} data type. Common Lisp uses an empty list for false, and any other value for true. C uses an integer type, where relational expressions like [...] and logical expressions connected by [...] and [...] are defined to have value 1 if true and 0 if false, whereas the test parts of , , , etc., treat any non-zero value as true. Indeed, a Boolean variable may be regarded (and implemented) as a <b>numerical</b> <b>variable</b> with one binary digit (bit), which can store only two values. The implementation of Booleans in computers are most likely represented as a full word, rather than a bit; this is usually due to the ways computers transfer blocks of information.|$|E
50|$|Globally-optimal {{classification}} tree analysis (GO-CTA) (also called hierarchical optimal discriminant analysis) is a generalization of optimal discriminant analysis {{that may be}} used to identify the statistical model that has maximum accuracy for predicting the value of a categorical dependent variable for a dataset consisting of categorical and continuous variables. The output of HODA is a non-orthogonal tree that combines categorical variables and cut points for continuous variables that yields maximum predictive accuracy, an assessment of the exact Type I error rate, and an evaluation of potential cross-generalizability of the statistical model. Hierarchical optimal discriminant analysis may {{be thought of as a}} generalization of Fisher's linear discriminant analysis. Optimal discriminant analysis is an alternative to ANOVA (analysis of variance) and regression analysis, which attempt to express one dependent variable as a linear combination of other features or measurements. However, ANOVA and regression analysis give a dependent variable that is a <b>numerical</b> <b>variable,</b> while hierarchical optimal discriminant analysis gives a dependent variable that is a class variable.|$|E
40|$|International audienceAcceleration {{methods are}} {{commonly}} used for computing precisely the effects of loops in the reachability analysis of counter machine models. Applying these methods on synchronous data-flow programs with Boolean and <b>numerical</b> <b>variables,</b> e. g. Lustre programs, firstly requires the enumeration of the Boolean states {{in order to obtain}} a control graph with <b>numerical</b> <b>variables</b> only. Secondly, acceleration methods {{have to deal with the}} non-determinism introduced by <b>numerical</b> input <b>variables.</b> In this article we address the latter problem by extending the concept of abstract acceleration of Gonnord et al. to <b>numerical</b> input <b>variables...</b>|$|R
40|$|Many pattern {{classification}} algorithms such as Support Vector Machines (SVMs), Multi-Layer Perceptrons (MLPs), and K-Nearest Neighbors (KNNs) require data {{to consist}} of purely <b>numerical</b> <b>variables.</b> However many real world data consist of both categorical and <b>numerical</b> <b>variables.</b> In this paper we suggest an effective method of converting the mixed data of categorical and <b>numerical</b> <b>variables</b> into data of purely <b>numerical</b> <b>variables</b> for binary classifications. Since the suggested method {{is based on the}} theory of learning Bayesian Network Classifiers (BNCs), it is computationally efficient and robust to noises and data losses. Also the suggested method is expected to extract sufficient information for estimating a minimum-error-rate (MER) classifier. Simulations on artificial data sets and real world data sets are conducted to demonstrate the competitiveness of the suggested method when the number of values in each categorical variable is large and BNCs accurately model the data. ...|$|R
30|$|Variables were {{expressed}} as median values and ranges for <b>numerical</b> <b>variables</b> and as frequencies and percentages for categorical variables. Categorical variables were compared using the Chi-square and Fisher's exact tests. <b>Numerical</b> <b>variables</b> were compared using parametric test (Student's test) or nonparametric tests (Wilcoxson, Kruskal-Wallis) {{according to the}} sample size of the groups, the number of groups, and the normality of parameters. Statistical significance was accepted at the 5 % level.|$|R
40|$|If a <b>numerical</b> <b>variable</b> can {{be assumed}} to be normally, but differently, {{distributed}} in each {{of two or more}} populations, then for an 'unknown' individual whose numerical value is known the relative probability of his belonging to each of the populations can be simply calculated. We briefly review the method and its application in genetic counselling...|$|E
40|$|The {{purpose and}} {{goal of this}} {{assignment}} was to design and implement a small system to predict a class of a single <b>numerical</b> <b>variable</b> in a binomial class problem. In order to do this, it was requested to implement or to think {{of one or more}} “ 1 D classifiers”, discussing their computational complexities in the learning phases, the performances on the given dataset, th...|$|E
40|$|This paper aims {{to assess}} the {{information}} loss {{and its effect on}} r when making a continuous <b>numerical</b> <b>variable</b> discrete by categorising the data. A simulation is used {{in order to determine the}} true extent of decrease in r while at the same time correcting for the assumption Morrison made regarding the uniformity of the error distribution. The results are then compared with those obtained using the approach suggested by Morrison...|$|E
40|$|Abstract. Accelerationmethodsarecommonlyusedforspeedingupthe {{convergence}} of loops in reachability analysis of counter machine models. Applying these methods to synchronous data-flow programs with Boolean and <b>numerical</b> <b>variables,</b> e. g., Lustre programs, requires the enumeration of the Boolean states {{in order to}} obtain a control flow graph (CFG) with <b>numerical</b> <b>variables</b> only. Our goal is to apply acceleration techniques to data-flow programs without resorting to this exhaustive enumeration. To this end, we present (1) logico-numerical abstract acceleration methods for CFGs with Boolean and <b>numerical</b> <b>variables</b> and (2) partitioning techniquesthatmake logical-numerical abstract acceleration effective. Experimental results show that incorporating these methods in a verification tool based on abstract interpretation provides not only significant advantage in terms of accuracy, but also a gain in performance in comparison to standard techniques...|$|R
40|$|The APRON {{library is}} {{dedicated}} to the static analysis of the <b>numerical</b> <b>variables</b> of a program by Abstract Interpretation [1]. The aim of such an analysis is to infer invariants about the values of <b>numerical</b> <b>variables,</b> like “at control point k, variables x, y and z satisfy the property 1 ≤ x + y ≤ z”. In this context, the APRON library provides a common interface to various libraries implementing numerical abstract domains...|$|R
40|$|International audienceAcceleration {{methods are}} {{commonly}} used for speeding up the convergence of loops in reachability analysis of counter machine models. Applying these methods to synchronous data-flow programs with Boolean and <b>numerical</b> <b>variables,</b> e. g., Lustre programs, requires the enumeration of the Boolean states {{in order to obtain}} a control flow graph (CFG) with <b>numerical</b> <b>variables</b> only. Our goal is to apply acceleration techniques to data-flow programs without resorting to this exhaustive enumeration. To this end, we present (1) logico-numerical abstract acceleration methods for CFGs with Boolean and <b>numerical</b> <b>variables</b> and (2) partitioning techniques that make logical-numerical abstract acceleration effective. Experimental results show that incorporating these methods in a verification tool based on abstract interpretation provides not only significant advantage in terms of accuracy, but also a gain in performance in comparison to standard techniques...|$|R
30|$|This is how {{the program}} distinguishes between {{numerical}} variables and categorical/factor variables. For instance, in the sample dataset Plasma.xls, the factor ‘diet’ with the two levels low-fat and high-fat should be coded, for instance as ‘LF’ and ‘HF’, not 0 s (for low-fat) and 1 s (for high-fat). The latter will lead to an error stating the program {{was unable to find}} two factors in your dataset (since one of them is treated as a <b>numerical</b> <b>variable),</b> and thus cannot perform two-way ANOVA.|$|E
3000|$|A {{linguistic}} variable differs from an ordinary <b>numerical</b> <b>variable</b> in that its values are not numbers but words or sentences {{in a natural}} or artificial language. It is formally characterized by a quintuple ([...] X, T([...] X), U, G, M), in which X {{is the name of}} the variable; T([...] X) denotes the term-set of X—the set of names of linguistic values of X, with each value being a fuzzy variable denoted generically by X and ranging over a universe of discourse [...]...|$|E
40|$|Modelica {{models are}} {{mathematical}} descriptions and therefore their simulation output typically shows <b>numerical</b> <b>variable</b> trajectories. While universal {{for all kinds}} of simulations, this representation is oftentimes difficult to understand. In the field of multi-body simulations, 3 D visualizations present a way of displaying vast amounts of numerical data in an intuitive way which is instantly understandable, even by people without specialized knowledge. For integration of visualization in Modelica multi-body simulations, the "DLR Visualization Library" has been developed. This paper presents the newest additions to the library and shows their application in several DLR projects...|$|E
30|$|<b>Numerical</b> <b>variables</b> were {{presented}} by mean (SD; range, i.e. minimum–maximum value) and categorical ones by number (%). The descriptive statistics were computed using Microsoft Excel 2010.|$|R
30|$|The RM 190 {{microsatellite}} {{was analyzed}} using the GeneMapper software (Applied Biosystem). Sequence assembly was assessed with the ContigExpress tool of Vector NTI Software (Invitrogen) using the Nipponbare genomic sequence as reference. Sequence comparison {{was carried out}} by MultAlin software ([URL] All data were analysed with the Systat 12 software (SPSS Inc., Chicago, IL, USA). The relationships between <b>numerical</b> <b>variables</b> (AAC and grain biometrical characters) were evaluated by Pearson correlation coefficients and regression analysis. The associations between <b>numerical</b> <b>variables</b> (AAC) and categorical variables (marker haplotypes) were analysed according to the General Linear Model (GLM) procedure.|$|R
30|$|Chi-square {{test was}} used (with Yates’ {{correction}} for continuity) for the investigation of independence of <b>numerical</b> <b>variables</b> and the determination of linear trends (Ptrend) among the groups classified by tumor receptor status.|$|R
40|$|In {{this paper}} {{we make a}} summary of {{psychological}} investigation about statistics association. The results of experimental study about previous conceptions are shown. This study has comprised the students' judgments of association. Using factorial analysis, we have identified five factors, which determine the structure of students' strategies. We also show a qualitative study about students' strategies in 2 x 2 and r x c contingency tables, scatterplots, and comparison of a <b>numerical</b> <b>variable</b> in different samples. Finally we describe four different misconceptions about statistical association and the conclusions of this paper...|$|E
40|$|This work tested if brasilian {{technology}} companies {{has a greater}} systematic risk than traditional companies in Brazil. For to achieve tje purpose, two companies samples, one of {{technology companies}} and the other of traditional companies, were composed. The tecnique employed was a multiple regression analysis considering a dichotomous variable wich represents the technological factor and another <b>numerical</b> <b>variable</b> wich represents the intangibility degree of  companies. As a dependent variable was considered the CAPM systematic risk. The results indicated that technology companies have a greater systematic risk than traditional companies regardless {{of the degree of}} intangibility...|$|E
40|$|Abstract. We {{recall the}} concept of a {{linguistic}} variable and the representation of its values (i. e. linguistic terms) by means of fuzzy sets. In this framework adverbs are represented by fuzzy modifiers, i. e. operators acting on these fuzzy sets. We investigate two important classes of popular fuzzy modifiers. Grounding on results from psycholinguistic research, we discuss their pro’s and contra’s for representing the adverb very. 19. 1 Linguistic variables 19. 1. 1 The concept of a linguistic variable The concept of a linguistic variable was introduced by Zadeh in the 70 ’s [ZAD 1975]. While the values of a <b>numerical</b> <b>variable</b> (often used in classical mathematics, physics, economics, [...] .) are numbers, the values of a linguistic variable are linguistic terms. E. g. the <b>numerical</b> <b>variable</b> size has values 5 cm 2, 100 cm 2, [...] . while the linguistic variable Size has values large, small, very large, rather small, not very large and not small, [...] The set consisting of all possible values of a linguistic variable is called the term set. Perhaps the most important computational beauty of {{the concept of}} a linguistic variable {{is the fact that the}} elements of its term set show a specific structure. Starting from one, two, or more base terms (e. g. large, small), every other term can be constructed using the following scheme...|$|E
30|$|For {{statistical}} analysis of the results Windows SPSS 15.0 program was used. Descriptive statistics were given in terms of numbers and percentages for categorical variables, {{and in terms of}} the mean, standard deviation and the median for the <b>numerical</b> <b>variables.</b> Comparison of two independent groups of variables was carried out using the Student T test when meeting the normal distribution criteria, or by the Mann–Whitney U test when these criteria were not met. Relationship between <b>numerical</b> <b>variables</b> was assessed by means of the Spearman Correlation Analysis. The differences between categorical variables were evaluated by the Chi square analysis. Statistical α (alpha) significance level was accepted with the ‘p’ value below 0.05.|$|R
30|$|Data were collected, {{tabulated}} then statistically {{analyzed using}} Statistical Package for Social Sciences (SPSS); computer software version (15). <b>Numerical</b> <b>variables</b> were presented as {{mean and standard}} deviation (±SD), while categorical variables were presented as number and percentage.|$|R
30|$|Volumetric {{comparisons}} were performed using the dice similarity coefficient (DSC), a validated approach to measure spatial overlap [51, 52]. In addition, the true positive volume fraction (TPFV) was calculated to indicate segmentation sensitivity and one minus the false positive volume fraction (1 -FPVF) to indicate specificity. Statistical {{analysis was performed}} using Statistica Version 13 ©. For <b>numerical</b> <b>variables</b> we report median, range and 25 th and 75 th percentiles to accommodate the modest sample size included in this pilot project. Agreement measures are reported using a Bland-Altman plot showing only bias and values and not confidence intervals and standard deviations. We report the correlation coefficient and p values for correlations between <b>numerical</b> <b>variables.</b>|$|R
40|$|Interval {{prediction}} can be {{more useful}} than single value prediction in many continuous data streams. This paper introduces a novel Interval Prediction Tree IP 3 algorithm for interval prediction of numerical target variables from temporal mean-variance aggregated continuous data. This algorithm characterized by: processing incoming mean-variance aggregated multivariate temporal data, splitting each of the continuous features of the input according to the best mean-variance and making stable interval predictions of a target <b>numerical</b> <b>variable</b> with a given degree of statistical confidence. As shown by empirical evaluations in forest fires data set the proposed method provides better performance than existing regression tree models...|$|E
40|$|AbstractThis {{paper is}} devoted to a general {{discussion}} of the combination of distinct imprecise or uncertain pieces of information pertaining to the same logical or <b>numerical</b> <b>variable</b> in rule-based expert systems using numerical approximate reasoning techniques. The reasons {{that the results of}} this combination may be meaningless are considered in detail. In particular, the presence of implicit default assumptions in the condition part of a rule is discussed and coped with. Moreover, the paper studies why the conclusions obtained by the most specific rule must be definitely preferred to conclusions derived using more general rules. Specificity ordering is defined within the framework of possibility theory...|$|E
40|$|Group-theoretical {{analysis}} of arbitrary polarization devices is performed, {{based on the}} theory of the Lorentz group. In effective "non-relativistic" Mueller case, described by 3 -dimensional orthogonal matrices, results of the one polarization measurement determine group theoretical parameters within the accuracy of an arbitrary <b>numerical</b> <b>variable.</b> There are derived formulas, defining Muller parameter of the non-relativistic Mueller device uniquely and in explicit form by by the results of two independent polarization measurements. Analysis is extended to Lorentzian optical devices, described by 4 -dimensional Mueller matrices. Comment: 22 pages; Report to be held: XV International School-Conference "Foundations and Advances in Nonlinear Science" September 20 - 23, Minsk 201...|$|E
30|$|Windows program SPSS 15.0 {{was used}} for the {{statistical}} analysis of the results. Descriptive statistics were given in terms of numbers and percentages for categorical variables, {{and in terms of the}} mean, standard deviation and the median for the <b>numerical</b> <b>variables.</b> Comparison of two independent groups of variables was carried out using the Student T test when meeting the normal distribution criteria, or by the Mann–Whitney U test when these criteria were not met. Relationship between <b>numerical</b> <b>variables</b> was assessed by means of the Spearman Correlation Analysis. The differences between categorical variables were evaluated by the Chi square analysis. Statistical α (alpha) significance level was accepted with the ‘p’ value below 0.05.|$|R
30|$|<b>Numerical</b> <b>variables</b> were {{tabulated}} using mean, standard deviation, and ranges. Categorical {{variables were}} tabulated using number of observations and percent. All statistics were performed at α[*]=[*] 0.05 two-sided significance level. Rates between arms were compared using Fisher’s exact test. No missing data was imputed.|$|R
30|$|Statistical {{analyses}} were performed using SAS (version 9.3). Variables were expressed as mean with standard deviation for <b>numerical</b> <b>variables</b> and as frequencies and percentages for categorical variables. Groups were compared using Wilcoxon, Chi-square, or Fisher’s exact tests, as appropriate, with a statistical significance threshold of 0.05.|$|R
40|$|Two {{coefficients}} {{are proposed}} {{for measuring the}} extent of overlap in distributions as a direct function of the variance between the arithmetic means (»disco« and »odisco «). They are designed to answer such questions as: »Given {{the value of a}} <b>numerical</b> <b>variable</b> x, to which population should an individual be assigned so that minimum error would be incurred?« This is just the reverse of the question addressed by ANOVA. These coefficients are shown to be analytic in x and they are related to. Pearson's eta and Fisher's F. Extensions of these coefficients (designed for univariate, one way discrimination) to k-way and multivariate discriminant analysis and measurement of »interaction « are suggested...|$|E
40|$|Prediction paper {{properties}} {{based on}} {{a limited number of}} measured variables can be an important tool for the industry. Mathematical models were developed to predict mechanical and optical properties from the corresponding paper density for some softwood papers using support vector machine regression with the Radial Basis Function Kemel. A dataset of different properties of paper handsheets produced from pulps of pine (Pinus pinaster and P. sylvestris) and cypress species (Cupressus lusitanica, C. sempervirens e C. arizonica) beaten at 1000, 4000, and 7000 revolutions was used. The results show {{that it is possible to}} obtain good models (with high coefficient of determination) with two variables: the <b>numerical</b> <b>variable</b> density and the categorical variable density...|$|E
40|$|It is unwise, though common practice, to base {{decisions}} on numerical values without knowing {{how they can}} be justified as correctly describing aspects of reality. Scientists have great responsibility in this regard, especially in the social sciences where it is easy to provide an appearance of rigour through the use of numbers and mathematical apparatus. We must be prepared to justify any numbers we use by clarifying the relationship between a <b>numerical</b> <b>variable</b> and a “real thing”. The article defines fundamental, explicit, scientific measurements and how they may be used in a meaningful way. It then considers instruments, in particular pointer measurements, that simulate these fundamental measurements. It concludes {{with a look at the}} validity of the resulting information. ...|$|E
40|$|In planning, {{hybrid system}} states {{consisting}} of logical and <b>numerical</b> <b>variables</b> are usually {{assumed to be}} completely known. In particular, for <b>numerical</b> state <b>variables</b> full knowledge of their exact values is assumed. However, in real world applications states are results of noisy measurements and imperfect actuators. Therefore, a planned sequence of state transitions might fail to lead a hybrid system to the desired goal. We show how to propagate and reason about uncertain state information directly in the planning process, enabling hybrid systems to find plans that satisfy numerical goals with predefined confidence...|$|R
40|$|Abstract. Linear Relation Analysis [11] is an {{abstract}} interpretation {{devoted to the}} automatic discovery of invariant linear inequalities among <b>numerical</b> <b>variables</b> of a program. In this paper, we apply such an analysis to the verification of quantitative time properties of two kinds of systems: synchronous programs and linear hybrid systems...|$|R
40|$|Existing {{models for}} complex systems are {{often based on}} quantitative, {{numerical}} methods such as Dynamical Systems Theory (DST) [Ashby 1952, Port and Gelder 1995]. Such approaches often use <b>numerical</b> <b>variables</b> to describe global aspects and specify how they affect each other over time; for example, how the number of predator...|$|R
