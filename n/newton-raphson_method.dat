893|238|Public
25|$|In {{numerical}} analysis, Newton's method (also {{known as}} the <b>Newton–Raphson</b> <b>method),</b> named after Isaac Newton and Joseph Raphson, is a method for finding successively better approximations to the roots (or zeroes) of a real-valued function. It {{is one example of}} a root-finding algorithm.|$|E
25|$|The method {{uses the}} same {{iterative}} scheme as the <b>Newton–Raphson</b> <b>method</b> yields when applied to the function y = f(x) = x2 − a, using {{the fact that its}} slope at any point is dy/dx = f(x) = 2x, but predates it by many centuries.|$|E
2500|$|The <b>Newton–Raphson</b> <b>method</b> in one {{variable}} is implemented as follows: ...|$|E
40|$|Abstract. A barycentric {{interpolation}} <b>Newton-Raphson</b> iterative <b>method</b> {{for solving}} nonlinear beam bending problems {{is presented in}} this article. The nonlinear governing differential equation of beam bending problem is discretized by barycentric interpolation collocation method to form a system of nonlinear algebraic equations. <b>Newton-Raphson</b> iterative <b>method</b> is applied to solve the system of nonlinear algebraic equations. The Jacobian derivative matrix in <b>Newton-Raphson</b> iterative <b>method</b> is formulated by the Hadamard product of vectors. Some numerical examples are given {{to demonstrate the validity}} and accuracy of proposed method...|$|R
40|$|We {{investigate}} {{the problem of}} sequential linear data prediction for real life big data applications. The second order algorithms, i. e., <b>Newton-Raphson</b> <b>Methods,</b> asymptotically achieve {{the performance of the}} "best" possible linear data predictor much faster compared to the first order algorithms, e. g., Online Gradient Descent. However, implementation of these methods is not usually feasible in big data applications because of the extremely high computational needs. Regular implementation of the <b>Newton-Raphson</b> <b>Methods</b> requires a computational complexity in the order of $O(M^ 2) $ for an $M$ dimensional feature vector, while the first order algorithms need only $O(M) $. To this end, in order to eliminate this gap, we introduce a highly efficient implementation reducing the computational complexity of the <b>Newton-Raphson</b> <b>Methods</b> from quadratic to linear scale. The presented algorithm provides the well-known merits of the second order methods while offering the computational complexity of $O(M) $. We utilize the shifted nature of the consecutive feature vectors and do not rely on any statistical assumptions. Therefore, both regular and fast implementations achieve the same performance in the sense of mean square error. We demonstrate the computational efficiency of our algorithm on real life sequential big datasets. We also illustrate that the presented algorithm is numerically stable...|$|R
5000|$|The <b>Newton-Raphson</b> interative <b>method</b> {{is used to}} find a solution, which is: ...|$|R
2500|$|Tjalling J. Ypma, Historical {{development}} of the <b>Newton-Raphson</b> <b>method,</b> SIAM Review 37 (4), 531–551, 1995[...]|$|E
2500|$|The STM numerically solves {{equation}} 3 {{through an}} iterative process. [...] This {{can be done}} using the bisection or <b>Newton-Raphson</b> <b>Method,</b> and is essentially solving for total head at a specified location using equations 4 and 5 by varying depth at the specified location.|$|E
2500|$|A large {{error in}} the initial {{estimate}} can contribute to non-convergence of the algorithm. To overcome this problem one can often linearise the function that is being optimized using calculus, logs, differentials, or even using evolutionary algorithms, such as the Stochastic Funnel Algorithm. Good initial estimates lie close to the final globally optimal parameter estimate. In nonlinear regression, the sum of squared errors (SSE) is only [...] "close to" [...] parabolic {{in the region of}} the final parameter estimates. Initial estimates found here will allow the <b>Newton-Raphson</b> <b>method</b> to quickly converge. It is only here that the Hessian matrix of the SSE is positive and the first derivative of the SSE is close to zero.|$|E
40|$|A {{geometric}} {{version of}} the well known <b>Newton-Raphson</b> <b>methods</b> is introduced. This root finding method is adapted to find the zero of a function defined on the group of rigid body displacements. At {{each step of the}} algorithm a rigid displacement is found that approximates the solution. The method is applied to the forward kinematics problem of the Gough-Stewart platform. © 2009 Springer-Verlag Berlin Heidelberg...|$|R
40|$|AbstractThe paper {{considers}} water solidification in porous materials. Mathematical model describing {{heat and}} water transport in deformable porous materials considering the kinetics of water phase change was proposed. The crystallization pressure was determine using the volume averaged Everett's equation. The ice-induced destruction of concrete was modeled {{by means of}} the delayed damage approach. The numerical code was developed using finite element, finite difference and <b>Newton-Raphson</b> <b>methods...</b>|$|R
40|$|In {{this paper}} we {{consider}} the problem of constructing an interpolatory spline in tension that matches the convexity and monotonicity properties of the data. In this connection, an algorithm is presented relying on the asymptotic properties of the splines in tension and making use of the generalized <b>Newton-Raphson</b> <b>methods</b> developed by Ben-Israel. The numerical performance of the proposed algorithm is tested and discussed for several data sets. © 1988...|$|R
2500|$|The {{estimate}} of the person parameter - the [...] "score" [...] on a test with IRT - is computed and interpreted {{in a very different}} manner as compared to traditional scores like number or percent correct. [...] The individual's total number-correct score is not the actual score, but is rather based on the IRFs, leading to a weighted score when the model contains item discrimination parameters. [...] It is actually obtained by multiplying the item response function for each item to obtain a likelihood function, the highest point of which is the maximum likelihood {{estimate of}} [...] [...] This highest point is typically estimated with IRT software using the <b>Newton-Raphson</b> <b>method.</b> [...] While scoring is much more sophisticated with IRT, for most tests, the (linear) correlation between the theta estimate and a traditional score is very high; often it is [...]95 or more. [...] A graph of IRT scores against traditional scores shows an ogive shape implying that the IRT estimates separate individuals at the borders of the range more than in the middle.|$|E
5000|$|... #Caption: An {{example of}} using <b>Newton-Raphson</b> <b>method</b> {{to solve the}} {{equation}} [...] or equivalently, to find a root of [...] (when [...] is the depicted function). The <b>Newton-Raphson</b> <b>method</b> is a procedure to find a numerical solution.|$|E
5000|$|The {{optimizing}} {{problem is}} solved by finding {{the roots of}} the derivative of the penalty function after equating it with zero. Because the equation is non-linear a numerical searching approach such as <b>Newton-Raphson</b> <b>method</b> is usually employed. The <b>Newton-Raphson</b> <b>method</b> is an iterative root search method with the iteration ...|$|E
30|$|This {{paper is}} {{organized}} into seven sections. Section  2 gives a brief in train movement and performance calculations. Section  3 is {{a review of}} DC railway power systems and its power flow solution methods. Section  4 describes <b>Newton–Raphson</b> <b>methods</b> for DC railway power systems in both power and current expressions. Section  5 illustrates multi-train system simulation integrated with power network solvers. Simulation results and conclusion remarks are in Sects.  6 and 7, respectively.|$|R
3000|$|Using {{the finite}} element {{difference}} method, a dynamic discrete grid system is established and solved by <b>Newton–Raphson</b> iterative <b>method,</b> and {{the relevant factors}} are analyzed; [...]...|$|R
50|$|Whereas <b>Newton-Raphson</b> <b>methods</b> {{solve the}} flow and {{structural}} {{problem for the}} state in the entire fluid and solid domain, it is also possible to reformulate an FSI problem as a system with only the degrees of freedom in the interface’s position as unknowns. This domain decomposition condenses the error of the FSI problem into a subspace related to the interface. The FSI problem can hence be written as either a root finding problem or a fixed point problem, with the interface’s position as unknowns.|$|R
5000|$|... {{which is}} the {{objective}} function of the <b>Newton-Raphson</b> <b>method.</b>|$|E
5000|$|The <b>Newton-Raphson</b> <b>method</b> in one {{variable}} is implemented as follows: ...|$|E
5000|$|Use of {{iterative}} {{methods to}} solve equations including <b>Newton-Raphson</b> <b>method</b> ...|$|E
40|$|Various {{non-linear}} equation solvers are adapted to handle linear constraints via the Lagrange-multiplier technique. This adaptation process {{turns out to}} be quite straightforward for <b>Newton-Raphson</b> <b>methods</b> and rank-two Quasi-Newton methods (BFGS and DFP), but rather more involved for Broyden method. In fact, two Broyden methods can be obtained: the standard one and a modified one, better adapted to the Lagrange-multiplier environment. Some numerical examples are used to assess the relative performance of the various adapted solvers. These tests illustrate the superiority of the modified Broyden method over the standard one. Peer ReviewedPostprint (author’s final draft...|$|R
40|$|This paper {{describes}} {{the basic principles}} {{for the development of}} an automated planar mechanism dimensional synthesis procedure. The procedure generates the synthesis equations by impos-ing length constraint along with the constraints of the motion program. The synthesis equations are formu-lated in a quadratic form. A numerical algorithm designed to solve the systems of quadratic algebraic equ-ations is developed. The algorithm is based on a combination of steepest descent and the second order <b>Newton-Raphson</b> <b>methods.</b> A six-bar and an eight-bar mechanisms were synthesized using the develop-ment presented in this paper...|$|R
40|$|A {{number of}} facts about {{quadratic}} power flow problems f(x) = y + g(x) = 0, x 2 R n x, y 2 R n y and applied <b>Newton-Raphson</b> <b>methods</b> with optimal multipliers are presented. The main results are about solution structure, singular points and Newton-Raphson solutions. Comments and discussions are given. Although we address {{here to the}} power flow problems, there are many areas where presented results may be effectively used. Actually they are valid for any problem described by an algebraic system of quadratic equations. INTRODUCTION The <b>Newton-Raphson</b> (NR) <b>method</b> and its various modifications {{are the most popular}} numerical techniques used in load flow problems - see for instance [1]-[5]. There are two main forms used for the load flow equations: the polar and rectangular forms. Both of them have some advantages. The polar form provides significant reduction of computations. For instance, the method, which uses PQ decomposition of the load flow problem [3], is widely used on practice [...] . ...|$|R
50|$|Alternatively, {{one can use}} (some {{modification}} of) the <b>Newton-Raphson</b> <b>method</b> {{to solve}} the algebraic equation.|$|E
5000|$|Tjalling J. Ypma, Historical {{development}} of the <b>Newton-Raphson</b> <b>method,</b> SIAM Review 37 (4), 531-551, 1995[...]|$|E
5000|$|A <b>Newton-Raphson</b> <b>method</b> for the {{solution}} of systems of equations, J. Math. Anal. Appl. 15(1966), 243-252 ...|$|E
40|$|This article {{presents}} the theoretical derivation {{as well as}} practical steps for implementing Naive Bayes (NB) and Logistic Regression (LR) classifiers. A generative learning under Gaussian Naive Bayes assumption and two discriminative learning techniques based on gradient ascent and <b>Newton-Raphson</b> <b>methods</b> are described to estimate the parameters of LR. Some limitation of learning techniques and implementation issues are discussed as well. A set of experiments are performed for both the classifiers under different learning circumstances and their performances are compared. From the experiments, {{it is observed that}} LR learning with gradient ascent technique outperforms general NB classifier. However, under Gaussian Naive Bayes assumption, both classifiers NB and LR perform similar...|$|R
40|$|The paper {{describes}} a newly developed algorithm for power flow solution {{based on a}} complex admittance matrix. The conciseness and close-to-reality iterative procedure make the method extremely attractive for self-made software implementation. The complex algorithm approach enables network connections, loads, generators, controlled bus voltages, including slack bus, {{to be considered in}} a single complex matrix. The power flow solution is achieved with iterations in complex form without the need of real/imaginary decomposition. The method has shown to have advantages over other traditional and available methods in terms of accuracy and convergence also in highly ill-conditioned cases. The cpu-time is comparable and sometimes competitive with those derived from <b>Newton-Raphson</b> <b>methods...</b>|$|R
40|$|AbstractIn this paper, we are {{concerned}} with Markov decision processes under the average cost criterion. By taking a fractional programming appraoch, we first show that the problem {{can be reduced to}} a nonlinear equation whose unknown variable is the optimal average cost to be determined. Next, for this nonlinear equation, we propose a family of solution algoriths parametrized by a natural number (including +∞), whose extreme cases, that is, the algorithms with parameters 1 and +∞ correspond to the policy iteration and <b>Newton-Raphson</b> <b>methods,</b> respectively. This result show a relationship between thhe above two methods, and suggests that a suitable choice of the parameter enable us to solve efficiently a given application problem with a specific structure...|$|R
5000|$|... {{which has}} poor {{convergence}} properties but very little memory requirements and isstraightforward to implement; the full <b>Newton-Raphson</b> <b>method</b> ...|$|E
5000|$|Alternatively, a <b>Newton-Raphson</b> <b>method</b> converges {{relatively}} fast. To {{reduce the}} complexity of the notation, the following variables are introduced: ...|$|E
5000|$|Compute {{successively}} {{more accurate}} estimates [...] of the reciprocal. This is where one employs the <b>Newton-Raphson</b> <b>method</b> as such.|$|E
40|$|In {{this work}} {{alternative}} methodologies are proposed for following post-buckling paths {{without the need}} for a complete factorization of the stiffness matrix or any factorization at all. This is achieved with two different approaches. The first employs nonlinear versions of preconditioned conjugate-like methods and the so called conjugate and secant-Newton methods have been tested. The second approach is based on the classical Newton-Raphson or modified <b>Newton-Raphson</b> <b>methods,</b> while for the linearized problem in each iteration the preconditioned Lanczos method is employed. Both methodologies combine the convergence properties of Newton-like methods and the low storage requirements of pure iterative methods by varying the storage demands for the preconditioning matrix according to the available computer storage facilities...|$|R
40|$|A {{family of}} {{non-linear}} solution methods is investigated based on limited-memory quasi-Newton updates. Depending upon {{the number of}} updates and the updating formula, a number of solution schemes may be constructed such as the conjugate- and secant-Newton methods, the conventional and modified <b>Newton-Raphson</b> <b>methods</b> {{and a variety of}} quasi-Newton updates. Under the proposed implementation, the preconditioned truncated Lanczos method is used for the solution of the linearized problem in each non-linear iteration. The complete factorization of the stiffness matrix is avoided and large-scale problems can be solved efficiently both in terms of computing time and storage. The non-linear iterative scheme is properly modified to account for loading variation inside the increment {{in order to be able}} to trace post-critical equilibrium paths...|$|R
40|$|Inverse shape {{design for}} elastic objects greatly eases the design ef-forts by letting users focus on desired target shapes without {{thinking}} about elastic deformations. Solving this problem using classic it-erative <b>methods</b> (e. g., <b>Newton-Raphson</b> <b>methods),</b> however, often suffers from slow convergence toward a desired solution. In this paper, we propose an asymptotic numerical method that exploits the underlying mathematical structure of specific nonlinear material models, and thus runs orders of magnitude faster than traditional Newton-type methods. We apply this method to compute rest shapes for elastic fabrication, where the rest shape of an elastic object is computed such that after physical fabrication the real object deforms into a desired shape. We illustrate the performance and robustness of our method {{through a series of}} elastic fabrication experiments...|$|R
