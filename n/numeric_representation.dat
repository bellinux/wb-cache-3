82|53|Public
500|$|To {{resolve this}} deficiency, Pozdniakov (1996) reanalyzed {{thirteen}} {{of the better}} preserved texts, attempting to identify all ligatures and allographs {{in order to better}} approach a one-to-one correspondence between graphemes and their <b>numeric</b> <b>representation.</b> He observed that all these texts but I and G verso consist predominantly of shared phrases (sequences of glyphs), which occur in different orders and contexts on different tablets. By 2007 he had identified some one hundred shared phrases, each between ten and one hundred glyphs long. Even setting aside the completely parallel texts Gr–K and the 'Grand Tradition' of H–P–Q, he found that half of the remainder comprises such phrases: ...|$|E
2500|$|On 20 October, a taxi drivers' {{union and}} the owner of CITIC Tower were granted a court {{injunction}} against the occupiers of sections of several roads. In his first interview to international journalists {{since the start of the}} protests, CY Leung said that Hong Kong had been [...] "lucky" [...] that Beijing had not yet intervened in the protests, and repeated Chinese claims that [...] "foreign forces" [...] were involved. He defended Beijing's stance on screening candidates. He said that open elections would result in pressure on candidates to create a welfare state, arguing that [...] "If it's entirely a numbers game – <b>numeric</b> <b>representation</b> – then obviously you'd be talking to half the people in Hong Kong [...] earn less than US$1,800 a month [...] You would end up with that kind of politics and policies." [...] A SCMP comment by columnist Alex Lo said of this interview: [...] "Leung has set the gold standard on how not to do a media interview for generations of politicians to come." ...|$|E
5000|$|Digital clocks {{display a}} <b>numeric</b> <b>representation</b> of time. Two numeric display formats are {{commonly}} used on digital clocks: ...|$|E
5000|$|Project Interactivate [...] {{has many}} {{activities}} linking visual, verbal and <b>numeric</b> <b>representations.</b> There are currently 159 different activities available, {{in many areas}} of math, including numbers and operations, probability, geometry, algebra, statistics and modeling.|$|R
40|$|Many {{problems}} in statistical analysis include time-of-day variables, but Stata offers limited support for time-of-day calculations. Support {{is needed for}} dates with times, times alone, and durations or timings. This article presents two new programs as general utilities to convert {{back and forth between}} string and <b>numeric</b> <b>representations.</b> ntimeofday, stimeofday, time of day, time series, calendar...|$|R
40|$|Two {{sonification}} {{tools are}} presented {{for use in}} calculus instruction. The first is a web-based tool for teaching students to interpret sonifications. The other is a spreadsheet-based tool that uses sonification to support and reinforce graphical and <b>numeric</b> <b>representations</b> of functions. We also illustrate how the tools could be used, and present data on the usability of the tools {{and the ability of}} students to interpret our sonifications. 1...|$|R
50|$|Each alpha character's <b>numeric</b> <b>representation</b> is {{multiplied by}} the inverse of its ordinal {{position}} within the NHI Number. The first value is multiplied by 7, the second by 6 and so on.|$|E
50|$|When the Motorola 68040 {{processor}} was introduced, {{it included}} the FPU internally. Most instructions and <b>numeric</b> <b>representation</b> modes from the 68881 were supported in hardware, but some were not, and were emulated in software.|$|E
50|$|Each alpha {{character}} {{is given a}} <b>numeric</b> <b>representation</b> equivalent to its ordinal position within the alphabet, starting at A through to Z. The letters I and O are omitted making the ordinal range 1 - 24.|$|E
40|$|Presented at the 12 th International Conference on Auditory Display (ICAD), London, UK, June 20 - 23, 2006. Two {{sonification}} {{tools are}} presented {{for use in}} calculus instruction. The first is a web-based tool for teaching students to interpret sonifications. The other is a spreadsheet-based tool that uses sonification to support and reinforce graphical and <b>numeric</b> <b>representations</b> of functions. We also illustrate how the tools could be used, and present data on the usability of the tools {{and the ability of}} students to interpret our sonifications...|$|R
25|$|ISO 8601 Data {{elements}} and interchange formats – Information interchange – Representation of dates and times {{is an international}} standard covering the exchange of date and time-related data. It was issued by the International Organization for Standardization (ISO) and {{was first published in}} 1988. The purpose of this standard is to provide an unambiguous and well-defined method of representing dates and times, so as to avoid misinterpretation of <b>numeric</b> <b>representations</b> of dates and times, particularly when data are transferred between countries with different conventions for writing numeric dates and times.|$|R
30|$|In a {{forecasting}} problem, {{categorical variables}} like the day type at moment t should {{be converted to}} <b>numeric</b> <b>representations</b> in order to fit the most numerical solved formulas. Most common techniques are direct numbering and one-hot encoding. Generally speaking, embedding is technique mapping 1 -dimensional categorical variables to numerical features into high dimensional space. It is {{turned out that the}} categorical variables mapped by embedding technique capture more information of categorical variables than other common techniques due to its flexibility in output vector dimensions and the complexity of embedding parameters.|$|R
5000|$|STI is a <b>numeric</b> <b>representation</b> {{measure of}} {{communication}} channel characteristics whose value varies from 0 = bad to 1 = excellent. [...] On this scale, an STI {{of at least}} [...]5 is desirable for most applications.|$|E
50|$|In computers, {{a serial}} decimal <b>numeric</b> <b>representation</b> {{is one in}} which ten bits are {{reserved}} for each digit, with a different bit turned on depending on which of the ten possible digits is intended. ENIAC and CALDIC used this representation.|$|E
5000|$|A {{digital image}} is a <b>numeric</b> <b>representation</b> (normally binary) of a {{two-dimensional}} image. Depending on whether the image resolution is fixed, it may be of vector or raster type. By itself, the term [...] "digital image" [...] usually refers to raster images or bitmapped images (as opposed to vector images).|$|E
50|$|ISO 8601 Data {{elements}} and interchange formats - Information interchange - Representation of dates and times {{is an international}} standard covering the exchange of date and time-related data. It was issued by the International Organization for Standardization (ISO) and {{was first published in}} 1988. The purpose of this standard is to provide an unambiguous and well-defined method of representing dates and times, so as to avoid misinterpretation of <b>numeric</b> <b>representations</b> of dates and times, particularly when data are transferred between countries with different conventions for writing numeric dates and times.|$|R
50|$|When the ARINC 429 word {{format is}} {{illustrated}} with Bit 32 to the left, the <b>numeric</b> <b>representations</b> {{in the data}} field generally read with the Most significant bit on the left. However, in this particular bit order presentation, the Label field reads with its most significant bit on the right. Like CAN Protocol Identifier Fields, ARINC 429 label fields are transmitted most significant bit first. However, like UART Protocol, Binary-coded decimal numbers and binary numbers in the ARINC 429 data fields are generally transmitted least significant bit first.|$|R
25|$|Like early {{programming}} languages such as Fortran, Algol, Cobol and Lisp, assemblers {{have been}} available since the 1950s and the first generations of text based computer interfaces. However, assemblers came first as they are far simpler to write than compilers for high-level languages. This is because each mnemonic along with the addressing modes and operands of an instruction translates rather directly into the <b>numeric</b> <b>representations</b> of that particular instruction, without much context or analysis. There have also been several classes of translators and semi automatic code generators with properties similar to both assembly and high level languages, with speedcode as {{perhaps one of the}} better known examples.|$|R
5000|$|A {{cardinal}} {{social welfare}} function {{is a function}} that takes as input numeric representations of individual utilities (also known as cardinal utility), and returns as output a <b>numeric</b> <b>representation</b> of the collective welfare. The underlying assumption is that individuals utilities can be put on a common scale and compared. Examples of such measures can be: ...|$|E
5000|$|A {{digital readout}} (DRO) is a numeric display, usually with an {{integrated}} keyboard and some means of <b>numeric</b> <b>representation.</b> Its integral computer reads signals generated by linear encoders or (less frequently) rotary encoders installed to track machine axes, using these measures {{to keep track}} of and display to a machine operator the workpiece position (e.g., milling machines), or tool position (lathes, grinders, etc) in space.|$|E
50|$|The 68881 {{had eight}} 80-bit data {{registers}} (a 64-bit mantissa plus a sign bit, and a 15-bit signed exponent). It allowed seven different modes of <b>numeric</b> <b>representation,</b> including single-precision, double-precision, and extended-precision, {{as defined by}} the IEEE floating-point standard, IEEE 754. It was designed specifically for floating-point math and was not a general-purpose CPU. For example, when an instruction required any address calculations, the main CPU would handle them before the 68881 took control.|$|E
40|$|A study {{identifying}} organizational {{values in}} emerging companies revealed values that clearly differed in their nature and purpose. A theoretical framework for describing these differences was developed {{drawing on the}} distinction made by Dees and Starr (1992) between 'ethical' and 'psychological' values, interpreted as continuum rather than dichotomous choice. Applying this framework to 96 values identified at 14 companies revealed widely differing interpretations of values between companies, simply illustrated as a graphical “profile”. Basic statistical analysis of <b>numeric</b> <b>representations</b> of values orientations suggested that espoused values {{were more likely to}} be ethical in orientation whereas implicit values {{were more likely to be}} psychological in orientation...|$|R
50|$|Like early {{programming}} languages such as Fortran, Algol, Cobol and Lisp, assemblers {{have been}} available since the 1950s and the first generations of text based computer interfaces. However, assemblers came first as they are far simpler to write than compilers for high-level languages. This is because each mnemonic along with the addressing modes and operands of an instruction translates rather directly into the <b>numeric</b> <b>representations</b> of that particular instruction, without much context or analysis. There have also been several classes of translators and semi automatic code generators with properties similar to both assembly and high level languages, with speedcode as {{perhaps one of the}} better known examples.|$|R
40|$|We {{compute the}} Gabor matrix for Schrödinger-type {{evolution}} operators. Precisely, we analyze the Heat Equation, already presented in 2012 arXiv 1209. 0945 C, giving the exact {{expression of the}} Gabor matrix which leads to better numerical evaluations. Then, using asymptotic integration techniques, we obtain an upper bound for the Gabor matrix in one-dimension for the generalized Heat Equation, new in the literature. Using Maple software, we show <b>numeric</b> <b>representations</b> of the coefficients' decay. Finally, we show the super-exponential decay of the coefficients of the Gabor matrix for the Harmonic Repulsor, together with some numerical evaluations. This work is the natural prosecution of the ideas presented in 2012 arXiv 1209. 0945 C and MR 2502369. Comment: 29 pages, 7 figure...|$|R
50|$|A clear, concise {{objective}} {{drives the}} rest of the OGSM model. The objective should be worded as a customized, specific statement that is specific to the organization. Goals should be numeric, usually over three to five years, financial and/or operational and should support the objective. The strategy should also use words which are focused and clearly written, typically around growth, productivity and people. Measures should be a <b>numeric</b> <b>representation</b> of the strategic that are traceable and have one owner.|$|E
5000|$|A Lexile {{measure is}} defined as [...] "the <b>numeric</b> <b>representation</b> of an individual's readingability or a text's {{readability}} (or difficulty), followed by an [...] "L" [...] (Lexile)". There {{are two types of}} Lexile measures: Lexile reader measures and Lexile text measures. A Lexile reader measure typically is obtained when an individual completes a reading comprehension test. Once a field study has been performed to link Lexile Framework with the test, the individual's reading score can be reported as a Lexile measure.|$|E
5000|$|The 802.3av defines several {{power budget}}s, denoted either PR or PRX. PRX power budget {{describes}} asymmetric-rate PHY for PON operating at 10 Gbit/s downstream and 1 Gbit/s upstream. PR power budget describes symmetric-rate PHY for PON operating at 10 Gbit/s downstream and 10 Gbit/s upstream. Each power budget is further {{identified with a}} <b>numeric</b> <b>representation</b> of its class, where value of 10 represents low power budget, value of 20 represents medium power budget, and value of 30 represents high power budget. The 802.3av draft standard defines the following power budgets: ...|$|E
50|$|It is a {{software}} library that decodes the Vorbis audio format. It is free software released under the New BSD license. Tremor uses fixed-point and movable-point arithmetic <b>numeric</b> <b>representations</b> in its implementation {{so that it}} can be used by small embedded devices, which typically do not have floating-point processors. Thus, Tremor enables small embedded devices to play audio files stored in the Vorbis format. Tremor was originally developed by Xiph.Org as a part of a contract for the Iomega HipZip, but was since opened up to encourage wider use of the Vorbis format. Almost all hardware devices that can play Vorbis, and many software implementations on embedded devices (such as mobile phones) use Tremor or some descendant.|$|R
5000|$|Some implementations, {{for example}} IBM {{mainframe}} systems, support zoned decimal <b>numeric</b> <b>representations.</b> Each decimal digit {{is stored in}} one byte, with the lower four bits encoding the digit in BCD form. The upper four bits, called the [...] "zone" [...] bits, are usually set to a fixed value so that the byte holds a character value corresponding to the digit. EBCDIC systems use a zone value of 1111 (hex F); this yields bytes in the range F0 to F9 (hex), which are the EBCDIC codes for the characters [...] "0" [...] through [...] "9". Similarly, ASCII systems use a zone value of 0011 (hex 3), giving character codes 30 to 39 (hex).|$|R
40|$|Background: DNA-binding {{proteins}} play {{a pivotal}} role in various intra- and extra-cellular activities ranging from DNA replication to gene expression control. Identification of DNA-binding proteins {{is one of the major}} challenges in the field of genome annotation. There have been several computational methods proposed in the literature to deal with the DNA-binding protein identification. However, most of them can't provide an invaluable knowledge base for our understanding of DNA-protein interactions. Results: We firstly presented a new protein sequence encoding method called PSSM Distance Transformation, and then constructed a DNA-binding protein identification method (SVM-PSSM-DT) by combining PSSM Distance Transformation with support vector machine (SVM). First, the PSSM profiles are generated by using the PSI-BLAST program to search the non-redundant (NR) database. Next, the PSSM profiles are transformed into uniform <b>numeric</b> <b>representations</b> appropriately by distance transformation scheme. Lastly, the resulting uniform <b>numeric</b> <b>representations</b> are inputted into a SVM classifier for prediction. Thus whether a sequence can bind to DNA or not can be determined. In benchmark test on 525 DNA-binding and 550 non DNA-binding proteins using jackknife validation, the present model achieved an ACC of 79. 96 %, MCC of 0. 622 and AUC of 86. 50 %. This performance is considerably better than most of the existing state-of-the-art predictive methods. When tested on a recently constructed independent dataset PDB 186, SVM-PSSM-DT also achieved the best performance with ACC of 80. 00 %, MCC of 0. 647 and AUC of 87. 40 %, and outperformed some existing state-of-the-art methods. Conclusions: The experiment results demonstrate that PSSM Distance Transformation is an available protein sequence encoding method and SVM-PSSM-DT is a useful tool for identifying the DNA-binding proteins. A user-friendly web-server of SVM-PSSM-DT was constructed, which is freely accessible to the public at the web-site on [URL]...|$|R
5000|$|In higher education, most {{subjects}} are graded ‘Pass/No pass’ ('Credit/No Credit') (зачёт/незачёт, pronounced [...] "zachòt/nyezachòt"), {{and the rest}} are graded on the five-point scale. The 'Pass/No Pass' grades have no official <b>numeric</b> <b>representation.</b> When [...] "zachòt"-type {{subjects are}} graded ‘Pass/No pass’ (sometimes translated as ‘Credit/No credit’), this simply represents a student's good/poor knowledge of a subject. [...] "Zachòt"-type subjects are also called [...] "non-exams" [...] {{due to lack of}} numerical representations. Each university applies its own standards of the level of knowledge required to pass each course. Students in Russia typically must pass all courses taken in order to graduate.|$|E
5000|$|At {{universities}} some {{subjects are}} graded [...] "Pass/No pass" [...] or [...] "Credit/No Credit" [...] (зачёт/незачёт, pronounced [...] "zachòt/nyezachòt"); {{the rest are}} typically graded on the five-point scale. The [...] "Pass/No Pass" [...] grades {{do not have any}} official <b>numeric</b> <b>representation.</b> When zachòt - (credit- or pass-) type subjects are graded as [...] "Pass/No pass", this represents a students knowledge of a subject. Each university applies its own standards with respect to the knowledge a student must have in order to pass a subject. Zachòt equival to pass with mark of minimum 77% to maximum 100%. Students in Russia must pass all prescribed courses in order to graduate.|$|E
5000|$|Related to <b>numeric</b> <b>representation</b> is {{the size}} and {{precision}} of integer numbers that a CPU can represent. In {{the case of a}} binary CPU, this is measured by the number of bits (significant digits of a binary encoded integer) that the CPU can process in one operation, which is commonly called [...] "word size", [...] "bit width", [...] "data path width", [...] "integer precision", or [...] "integer size". A CPU's integer size determines the range of integer values it can directly operate on. For example, an 8-bit CPU can directly manipulate integers represented by eight bits, which have a range of 256 (28) discrete integer values.|$|E
40|$|AbstractText mining is the {{analysis}} of unstructured data by combining techniques from knowledge discovery in databases, natural language processing, information retrieval, and machine learning. Text mining allows us to analyze web content dynamically to find meaningful patterns within large collections of textual data. There are too many economic news articles to read. Therefore, it is a necessary to summarize them. In this study, TM is {{used to analyze the}} vast amount of text produced in newspaper articles in Turkey. We mine unstructured economy news with natural language processing techniques including tokenization, transform cases, filtering stopwords and stemming. Similarity analysis is also used to determine similar documents. The word vector is extracted. Therefore, economy news is structured into <b>numeric</b> <b>representations</b> that summarize them. In addition, k-means clustering is used. Consequently, the clusters and similarities of the articles are obtained...|$|R
40|$|Graphical {{representations}} for probabilistic {{relationships have}} recently received considerable attention in A 1. Qualitative probabilistic networks abstract {{from the usual}} <b>numeric</b> <b>representations</b> by encoding only qualitative relationships, which are inequality constraints on the joint probability distribution over the variables. Although these constraints are insufficient to determine probabilities uniquely, {{they are designed to}} justify the deduction of a class of relative likelihood conclusions that imply useful decision-making properties. Two types of qualitative relationship are defined, each a probabilistic form of monotonicity constraint over a group of variables. Qualitative influences describe the direction of the relationship between two variables. Qualitative synergies describe interactions among influences. The probabilistic definitions chosen justify sound and efficient inference procedures based on graphical manipulations of the network. These procedures answer queries about qualitative relationships among variables separated in the network and determine structural properties of optimal assignments to decision variables...|$|R
40|$|Concepts {{involved}} {{in real world}} applications usually possess graded sttuctures. Instead of being equivalent. examples of a concept with a graded structure may be characterized by a degree of typicality in representing the concept. Both pure symbolic and subsymbolic representations are not adequate for describing concepts with graded structures. A pure symbolic representation fails to describe the graded structure of a concept. and a pure subsymbolic representation is unable to capture the central tendency of a concept. This chapter presents an integrated approacb that combines a symbolic approach with a subsymbolic one to learn concepts with graded structures. Concepts in this approach are represented by a bybrid representation that {{is a combination of}} the symbolic and <b>numeric</b> <b>representations.</b> In the bybrid representation. the symbolic element explicitly captures the central tendency of a concept, and the numeric element impliCitly bandIes the atypical aspect of a concepl A learning algorithm that adjusts both the symbolic and numeric elements of the representation to achieve the best fit between the descriplion and the given concept examples is described. The method bas been tested o...|$|R
