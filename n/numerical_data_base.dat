5|10000|Public
40|$|Thermomechanical loads in rocket engines can be {{drastically}} reduced by a reliable cooling system. The regenerative cooling system uses pro-pellants as coolant which §ows through milled cooling channels {{in the chamber}} walls. Due to centrifugal forces, dynamic secondary motions appear in cooling-channel curvatures, which strongly modify heat trans-fer. Three-dimensional (3 D) numerical calculations have been performed in order to compare this heat §ux modi¦cation with empirical correla-tions. Di¨erent turbulence models and wall treatments have been tested to develop a complete <b>numerical</b> <b>data</b> <b>base</b> about asymmetrical (concave side) heat transfer in curved cooling channels of rocket engine. ...|$|E
40|$|This study acquires the {{attitude}} dynamics of floating bodies with irregular configurations using an effective computational model, {{which has been}} validated theoretically and verified by experiments. By comparison a correlation formula was described to predict inclinations for the floating slender body imitating an excise torpedo. Thereafter a computational model was developed to account for bodies with attitudes in more general situations. For demonstration, a submersible was simulated to reveal that the inclinations vary abruptly around certain longitudinal locations of center of gravity. The property variations during water ingress assumption were presented. Similar to the virtue tank, an innovative concept of building the <b>numerical</b> <b>data</b> <b>base</b> for a specific floating body has been proposed, by which the position of its center of gravity {{can be obtained by}} interpolation from attitude data in tables as determined by the present computational model...|$|E
40|$|Copyright © 2014 Jiann-Lin Chen et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. This study acquires the attitude dynamics of floating bodies with irregular configurations using an effective computational model, which has been validated theoretically and verified by experiments. By comparison a correlation formula was described to predict inclinations for the floating slender body imitating an excise torpedo. Thereafter a computational model was developed to account for bodies with attitudes in more general situations. For demonstration, a submersible was simulated to reveal that the inclinations vary abruptly around certain longitudinal locations of center of gravity. The property variations during water ingress assumption were presented. Similar to the virtue tank, an innovative concept of building the <b>numerical</b> <b>data</b> <b>base</b> for a specific floating body has been proposed, by which the position of its center of gravity {{can be obtained by}} interpolation from attitude data in tables as determined by the present computational model. 1...|$|E
5000|$|... maximizing synergies between {{different}} fields contributing to planetary sciences: space observations, earth-based observations, laboratory studies, <b>numerical</b> simulations, <b>data</b> <b>base</b> development; ...|$|R
40|$|In {{conjunction}} with the increasing availability of massive computerised diachronic corpora, advances in computational visualisation apparatus have further equipped diachronic corpus linguists {{with an array of}} elegant analytical tools to study and model diachronic constructional changes, which are often times too intricate to be detected through a mere eyeballing on tabular <b>numerical</b> <b>data.</b> <b>Based</b> on the Corpus of Historical American English (COHA), this paper exemplifies the application of one such tool called Motion Chart to visualise recent change in two English Future Constructions, i. e. will+INF and be going to+INF, regarding their infinitival collocates distribution. ...|$|R
40|$|One {{important}} task in data integration {{is to identify}} truth from noisy and conflicting data records collected from multiple sources, i. e., the truth finding problem. Previously, several methods have been proposed {{to solve this problem}} by simultaneously learning the quality of sources and the truth. However, all those methods are mainly designed for handling categorical <b>data</b> but not <b>numerical</b> <b>data.</b> While in practice, <b>numerical</b> <b>data</b> is not only ubiquitous but also of high value, e. g. price, weather, census, polls, economic statistics, etc. Quality issues on <b>numerical</b> <b>data</b> can also be even more common and severe than categorical data due to its characteristics. Therefore, in this work we propose a new truth-finding method specially designed for handling <b>numerical</b> <b>data.</b> <b>Based</b> on Bayesian probabilistic models, our method can leverage the characteristics of <b>numerical</b> <b>data</b> in a principled way, when modeling the dependencies among source quality, truth, and claimed values. Experiments on two real world datasets show that our new method outperforms existing state-of-the-art approaches. 1...|$|R
40|$|The CTR <b>numerical</b> <b>data</b> <b>base</b> {{generated}} by direct simulation of homogeneous anisotropic turbulence {{was used to}} calculate all of the terms in the spectral balance equations for the turbulent Reynolds stresses. The aim in not only to test the main closure assumptions used in the split-spectrum models, but also to try to devise improved hypotheses deduced from the statistical information. Numerical simulations of turbulent flows provide {{a large amount of}} data, a thought provoking wealth of information. The main advantage of this type of comparison is that a great variety of flows can be considered, and this is necessary to test closure hypotheses. Moreover various initial conditions can be introduced in the calculation, even if they are not experimentally feasible. All the terms in the spectral equations can be calculated. The limited Reynolds numbers of the simulations and the statistical noise caused by a small sample, particularly at the large scales, causes some difficulty in the interpretation of the results, but the method of approach proved to be a powerful tool for testing and improving spectral closures...|$|E
40|$|The {{described}} {{works have}} been carried out in the framework of a mid-term study initiated by the Centre Electronique de l'Armement and led by ADERSA, a French company of research under contract. The aim was to study the techniques of regular dividing of numerical data sets so as to provide tools for problem solving enabling to model multidimensional numerical objects and to be used in computer-aided design and manufacturing, in robotics, in image analysis and synthesis, in pattern recognition, in decision making, in cartography and <b>numerical</b> <b>data</b> <b>base</b> management. These tools are relying on the principle of regular hierarchical decomposition and led to the implementation of a multidimensional generalization of quaternary and octernary trees: the trees of order 2 **k or 2 **k-trees mapped in binary trees. This first tome, dedicated to the hierarchical modeling of multidimensional numerical data, describes the principles used for building, transforming, analyzing and recognizing patterns on which is relying the development of the associated algorithms. The whole so developed algorithms are detailed in pseudo-code {{at the end of this}} document. The present publication especially describes: - a building method adapted disordered and overcrowded data streams; - its extension in inductive limits; - the computation of the homographic transformation of a tree; - the attribute calculus based on generalized moments and the provision of Eigen trees; - perception procedures of objects without any covering in affine geometry; - several supervised and unsupervised pattern recognition methods. Comment: 170 pages, 19 figures, research repor...|$|E
40|$|International audienceThis paper {{considers}} {{the task of}} constructing fuzzy prototypes for <b>numerical</b> <b>data</b> in order to characterize the data subgroups obtained after a clustering step. The proposed solution is motivated by the will of describing prototypes with a richer representation than point-based methods, and also to provide a characterization of the groups that catches not only the common features of the data pertaining to a group, but also their specificity. It transposes a method that has been designed for fuzzy <b>data</b> to <b>numerical</b> <b>data,</b> <b>based</b> on a prior computation of typicality degrees that are defined according to concepts used in cognitive science and psychology. The paper discusses the construction of prototypes and how their desirable semantics and properties can guide {{the selection of the}} various operators involved in the construction process...|$|R
40|$|The {{heart of}} NASA's STI {{system is a}} {{collection}} of scientific and technical information gathered from worldwide sources. Currently containing over 2. 2 million items, the <b>data</b> <b>base</b> is growing at the rate of 140, 000 items per year. In addition to announcement journals, information is disseminated through the NASA RECON on-line bibliographic search system. One part of RECON is NALNET which lists journals and books held by the NASA Centers. Another service now accessible by recon is a directory of <b>numerical</b> <b>data</b> <b>bases</b> (DND) which can be shared by NASA staff and contractors. The DND describes each <b>data</b> <b>base</b> and gives the name and phone number of a contact person. A NASA-wide integrated library system is being developed for the Center libraries which will include on-line catalog and subsystems for acquisition, circulation control, information retrieveal, management information, and an authority file. These subsystems can interact with on-line bibliographic, patron, and vendor files...|$|R
40|$|In {{the present}} study, we aimed at {{investigating}} what factors affect {{the judgment of}} a typical reader {{when he or she}} deals with numerical information in an ecological context. Participants read a story about a man who was not treated with heparin after hernia surgery and then died. Their task was to assess the liability of the medical staff after receiving ambiguous <b>numerical</b> <b>data</b> <b>based</b> on percentages, and again after receiving unambiguous <b>data</b> <b>based</b> on frequencies. Participants also assessed the likelihood of survival/death for heparin-treated vs. not-treated patients. The unambiguous numerical information they were given was different in terms of numerousness of the reference class and framing. Results show that even when unambiguous frequency-based information is available, the participants' judgments were strongly affected by both frame and reference class. Findings also indicate that likelihood and liability judgments are strongly related, and that liability is accounted for by likelihood, but not vice versa...|$|R
40|$|Background/purpose: Atypical nevi (AN) {{share some}} dermoscopic {{features}} with early melanoma (MM), and computer elaboration of digital images could represent a useful support to diagnosis to assess automatically colors in AN, and {{to compare the}} data with those referring to clearly benign nevi (BN) and MMs. Methods: An image analysis program enabling the numerical description of color areas in melanocytic lesions was used on 459 videomicroscopic images, referring to 76 AN, 288 clearly BN and 95 MMs. Results: Black, white and blue-gray were more frequently found in AN than in clearly BN, but less frequently than in MMs. Color area values significantly differed between the three groups. Conclusion: The clinical-morphological interpretation of the <b>numerical</b> <b>data,</b> <b>based</b> on the mathematical description of the aspect and distribution of different color areas in different lesion types {{may contribute to the}} characterization of AN and their distinction from MMs...|$|R
40|$|This {{bibliography}} lists 641 reports, articles, {{and other}} documents introduced into the NASA scientific and technical information system during the period January 1, 1981 through June 30, 1982. The directory was compiled {{to assist in the}} location of <b>numerical</b> and factual <b>data</b> <b>bases</b> and <b>data</b> <b>base</b> handling and management systems...|$|R
40|$|<b>Numerical</b> <b>data</b> <b>based</b> on stomach content {{analysis}} of the zooplanktivorous freshwater fish, Retropinna semoni, were {{used to examine the}} effect of fish sample size on mean counts of dominant prey items. Fifty adult R. semoni were collected from throughout the open-water of Lake Benanee, Australia at each of five times over a diel period. Bootstrapping was used to generate confidence intervals around sample means, and markedly more accurate means were obtained from samples collected in the day than the night. High variation in night samples was the by-product of a diurnal feeding regime. Traditional sample sizes of 10 to 15 stomachs resulted in reasonable confidence intervals of sample means derived from collections on the first day, corresponding to uniform feeding patterns in the population. However, increased sample sizes were required to describe more complex feeding behaviour on the second day, when a proportion of the population switched to an alternative prey source. No Full Tex...|$|R
5000|$|Because of the {{difficulty}} in retrieving formal USSR Government records, the <b>numerical</b> <b>data</b> are <b>based</b> on reports obtained from former POWs and elsewhere by the former Ministry of Health and Welfare and the current Ministry of Labor, Health and Welfare of the Japanese Government. The Japanese Government is disinterring {{the remains of the}} Japanese POWs who died in the USSR; more data may be anticipated, for example, at sites such as http://www.mhlw.go.jp/seisaku/2009/11/01.html “Investigation of records regarding persons deceased during detention in Siberia.” (Ministry of Labor, Health and Welfare Policy Reports 2009.) ...|$|R
40|$|Multidisciplinary design {{optimization}} (MDO) {{is presented as}} a rapidly growing body of methods, algorithms, and techniques that will provide a quantum jump in the effectiveness and efficiency of the quantitative side of design, and will turn that side into an environment in which the qualitative side can thrive. MDO borrows from CAD/CAM for graphic visualization of geometrical and <b>numerical</b> <b>data,</b> <b>data</b> <b>base</b> technology, and in computer software and hardware. Expected benefits from this methodology are a rational, mathematically consistent approach to hypersonic aircraft designs, designs pushed closer to the optimum, and a design process either shortened or leaving time available for different concepts to be explored...|$|R
40|$|Results of {{numerical}} simulations {{obtained by}} a staggered finite difference scheme {{together with an}} efficient immersed boundary method are presented to understand {{the effects of the}} shape of three-dimensional obstacles on the transition of a boundary layer from a laminar to a turbulent regime. Fully resolved Direct Numerical Simulations (DNS), highlight that the closer to the obstacle the symmetry is disrupted the smaller is the transitional Reynolds number. It has been also found that the transition can not be related to the critical roughness Reynolds number used in the past. The simulations highlight the differences between wake and inflectional instabilities, proving that two-dimensional tripping devices are more efficient in promoting the transition. Simulations at high Reynolds number demonstrate that the reproduction of a real experiment with a solid obstacle at the inlet is an efficient tool to generate <b>numerical</b> <b>data</b> <b>bases</b> for understanding the physics of boundary layers. The quality of the numerical method to fully resolve the small scales, that is one ingredient for a DNS was shown by a comparison of the exponential range of the velocity spectra, in Kolmogorov units, with those for isotropic turbulence. The good comparison reinforces the idea of local isotropy at the smallest scales...|$|R
40|$|The {{results from}} an {{experimental}} investigation at IIT were combined with Spalart's (1988) Direct <b>Numerical</b> Simulation <b>data</b> <b>base</b> {{to investigate the}} scaling of the spanwise length scales of the dominant structures in the near-wall region of a turbulent boundary layer. To achieve this goal, the scaling of the spanwise correlation coefficient between the wall-shear stress and the streamwise velocity, at various heights in the boundary layer, was studied over the Reynolds number range, 670 to 5961. In addition, the scaling of the conditional velocity field associated with high and low wall-shear stress events was examined. The {{results indicate that the}} spanwise correlation coefficient scales with inner variables for 'small' spanwise offsets...|$|R
40|$|Atypical nevi {{share some}} dermoscopic {{features}} with early melanoma, and computer elaboration of digital images could represent a useful support to diagnosis. The aim {{of our study}} was to automatically assess colors in atypical nevi, and to compare the data with those referring to clearly benign nevi and melanomas. Dermoscopic images of 459 melanocytic lesions, referring to 76 atypical nevi, 288 clearly benign nevi and 95 melanomas, were acquired {{by means of a}} digital videomicroscope (Videocap 100, DS-Medica, Italy) employing a 20 -fold magnification. An image analysis program, based on an approach, which shares some similarities with the human perception of colors, was employed. For the evaluation of colors in melanocytic lesion images, the identification of the six main color groups (black, dark brown, light brown, red, white and blue-gray) and the numerical description of color areas were obtained. Black, white and blue-gray were more frequently found in atypical nevi than in clearly benign nevi, but less frequently than in melanomas. Color area values significantly differed between the three groups, showing increasing irregularity in color distribution from benign lesions to atypical nevi and melanomas. The clinical–morphological interpretation of the <b>numerical</b> <b>data,</b> <b>based</b> on the mathematical description of the aspect and distribution of different color areas in different lesion types may contribute to the characterization of atypical nevi and their distinction from melanomas...|$|R
40|$|The {{described}} {{works have}} been carried out in the framework of a mid-term study initiated by the Centre Electronique de l'Armement, then by an advanced study launched by the Direction de la Recherche et des Etudes Technologiques in France in the aim to develop new techniques for multidimensional hierarchical modeling and to port them on parallel architecture computers for satisfying the future needs in processing huge <b>numerical</b> <b>data</b> <b>bases.</b> Following the first tome describing the modeling principles, the second tome details the way used for developing the modeling software and for porting it on different computers, especially on parallel architecture computers. In addition to these works, it is gone through new algorithms that have been developed after those that have been presented in the former tome and that are described in pseudo-code in annex of the present document: - operators for constructive geometry (building simple shapes, Boolean operators, slice handling); - integral transformations (epigraph, hypograph, convex hull); - homotopic transformations (boundary, erosion, dilation, opening, closing); - median transformations (median filtering, thinning, median set, intrinsic dimension); - transformations of (hyper-) surface manifolds (median filtering, extension, polynomial fitting of a simple function). The present publication is ending with the software porting on two distributed memory parallel computers: - a thin-grained synchronous computer; - a coarse-grained asynchronous computer. Comment: 214 pages, 22 figures, research repor...|$|R
40|$|The glass {{transition}} {{remains one of}} the great unsolved mysteries of contemporary condensed matter physics. When crystallization is bypassed by rapid cooling, a supercooled liquid, retaining amorphous particle arrangment, results. The physical phenomenology of supercooled liquids is as vast as it is interesting. Most significant, the viscosity of the supercooled liquid displays an incredible increase over a narrow temperature range. Eventually, the supercooled liquid ceases to flow, becomes a glass, and gains rigidity and solid-like behaviors. Understanding what underpins the monumental growth of viscosity, and how rigidity results without long range order is a long-sought goal. Many theories of the glassy slowdown require the growth of static lengthscale related to structure with lowering of the temperature. To that end, we have proposed a new, natural lengthscale- "the shear penetration depth". This lengthscale quantifies the structural connectivity of the supercooled liquid. The shear penetration depth is defined as the distance up to which a shear perturbation applied to the boundary propagates into the liquid. We provide <b>numerical</b> <b>data,</b> <b>based</b> on the simulations of $NiZr_ 2 $, illustrating that this length scale exhibits dramatic growth and eventual divergence upon approach to the {{glass transition}}. We further discuss this in relation to percolating structural connectivity and a new theory of the glass transition. Comment: 9 pages, 4 figures, special journal articl...|$|R
40|$|The {{field of}} {{computational}} fluid dynamics (CFD) has advanced {{to the point where}} it can now be used for the purpose of fluid dynamics physics education. Because of the tremendous wealth of information available from numerical simulation, certain fundamental concepts can be efficiently communicated using an interactive graphical interrogation of the appropriate <b>numerical</b> simulation <b>data</b> <b>base.</b> In other situations, a large amount of aerodynamic information can be communicated to the student by interactive use of simple CFD tools on a workstation or even in a personal computer environment. The emphasis in this presentation is to discuss ideas for how this process might be implemented. Specific examples, taken from previous publications, will be used to highlight the presentation...|$|R
40|$|The eld of {{robotics}} {{employs a}} vast amount of coupled sub-systems. These need to interact cooperatively and concurrently in order to yield the desired results. Some hybrid algorithms also require intensive cooperative interactions internally. The architecture proposed lends it- self amenable to problem domains that require rigorous calculations that are usually impeded by the capacity of a single machine, and incompatibility issues between software computing elements. Implementations are abstracted away from the physical hardware for ease of de- velopment and competition in simulation leagues. Monolithic developments are complex, and the desire for decoupled architectures arises. Decoupling also lowers the threshold for using distributed and parallel resources. The ability to re-use and re-combine components on de- mand, therefore is essential, while maintaining the necessary degree of interaction. For this reason we propose to build software components on top of a Service Oriented Architecture (SOA) using Web Services. An additional bene t is platform independence regarding both the operating system and the implementation language. The robot soccer platform as well as the associated simulation leagues are the target domain for the development. Furthermore are machine vision and remote process control related portions of the architecture currently in development and testing for industrial environments. We provide <b>numerical</b> <b>data</b> <b>based</b> on the Python frameworks ZSI and SOAPpy undermining the suitability of this approach for the eld of robotics. Response times of signi cantly less than 50 ms even for fully interpreted, dynamic languages provides hard information showing the feasibility of Web Services based SOAs even in time critical robotic applications...|$|R
40|$|The {{field of}} {{robotics}} employs {{a vast amount}} of coupled sub-systems. These need to interact cooperatively and concurrently in order to yield the desired results. Some hybrid algorithms also require intensive cooperative interactions internally. The architecture proposed lends it-self amenable to problem domains that require rigorous calculations that are usually impeded by the capacity of a single machine, and incompatibility issues between software computing elements. Implementations are abstracted away from the physical hardware for ease of de-velopment and competition in simulation leagues. Monolithic developments are complex, and the desire for decoupled architectures arises. Decoupling also lowers the threshold for using distributed and parallel resources. The ability to re-use and re-combine components on de-mand, therefore is essential, while maintaining the necessary degree of interaction. For this reason we propose to build software components on top of a Service Oriented Architecture (SOA) using Web Services. An additional benefit is platform independence regarding both the operating system and the implementation language. The robot soccer platform as well as the associated simulation leagues are the target domain for the development. Furthermore are machine vision and remote process control related portions of the architecture currently in development and testing for industrial environments. We provide <b>numerical</b> <b>data</b> <b>based</b> on the Python frameworks ZSI and SOAPpy undermining the suitability of this approach for the field of robotics. Response times of significantly less than 50 ms even for fully interpreted, dynamic languages provides hard information showing the feasibility of Web Services based SOAs even in time critical robotic applications...|$|R
40|$|We {{study the}} mining of {{interesting}} {{patterns in the}} presence of numerical attributes. Instead of the usual discretization methods, we propose the use of rank based measures to score the similarity of sets of numerical attributes. New support measures for <b>numerical</b> <b>data</b> are introduced, <b>based</b> on extensions of Kendall’s tau, and Spearman’s Footrule and rho. We show how these support measures are related. Furthermore, we introduce a novel type of pattern combining numerical and categorical attributes. We give efficient algorithms to find all frequent patterns for the proposed support measures, and evaluate their performance on real-life datasets...|$|R
40|$|This study {{demonstrates}} {{a simple and}} efficient strategy for the sensitivity improvement in detection of biomolecules via surface plasmon resonance field enhancement in a Kretschmann configuration. Synergistic coupling effects between propagating and localized surface plasmons (SPs) were demonstrated by incorporating arrays of Au nanoparticles (AuNPs) in-between DNA sensing assays. AuNPs with 5 nm or 15 nm diameter were incorporated respectively {{on the top of}} the streptavidin layer, and the coupling-induced sensitivity enhancement was systematically investigated. Uniform dispersion of AuNPs was confirmed by TEM analysis. The overall sensing capability of each system was investigated in terms of the reflectivity change, angular shift, and affinity constant for the DNA hybridization process and it was found that AuNP-arrays with appropriate size and lateral distribution led to the best efficiency. The experimental results were in good agreement with <b>numerical</b> simulation <b>data</b> <b>based</b> on a rigorous coupled wave analysis (RCWA) ...|$|R
40|$|Medical {{records of}} A-bomb {{survivors}} include <b>numerical</b> <b>data</b> and non-numerical data such as handwritten description. We have been storing the <b>numerical</b> <b>data</b> in medical records into a <b>data</b> <b>base.</b> We started {{to store the}} nonnumerical data on optical disks. We analyzed the significance and usefulness of storing them. The nonnumerical data of symptoms can not be evaluated by but can be analyzed with the <b>numerical</b> <b>data.</b> It was concluded that storing non-numerical data in the medical records on the optical disks would be worthy...|$|R
40|$|International audienceThe dynamic mode {{decomposition}} (DMD) is a data-decomposition {{technique that}} allows the extraction of dynamically relevant flow features from time-resolved experimental (or <b>numerical)</b> <b>data.</b> It is <b>based</b> on a sequence of snapshots from measurements that are subsequently processed by an iterative Krylov technique. The eigenvalues and eigenvectors of a low-dimensional representation of an approximate inter-snapshot map then produce flow information that describes the dynamic processes contained in the data sequence. This decomposition technique applies equally to particle-image velocimetry data and image-based flow visualizations and is demonstrated on <b>data</b> from a <b>numerical</b> simulation of a flame based on a variable-density jet and on experimental data from a laminar axisymmetric water jet. In both cases, the dominant frequencies are detected and the associated spatial structures are identified...|$|R
40|$|Direct <b>numerical</b> {{simulation}} <b>data</b> <b>bases</b> for compressible homogeneous shear ow {{are used}} to evaluate the performance of recently proposed Reynolds stress closures for compressible turbulence. Three independent pressure-strain models are considered along with a variety of explicit compressible corrections that account for dilatational dissipation and pressure-dilatation e ects. The ability of the models to predict both time evolving elds and equilibrium states is systematically tested. Consistent with earlier studies, it is found that the addition of simple dilatational models allows for the prediction of the reduced growth rate of turbulent kinetic energy in compressible homogeneous shear ow. However, a closer examination of the equilibrium structural parameters uncovers a major problem. None of the models are able to predict the dramatic increase in the normal Reynolds stress anisotropies or the signi cant decrease in the Reynolds shear stress anisotropy that arise from compressible e ects. The physical origin of this de ciency is attributed to the neglect of compressible terms in the modeling of the deviatoric part of the pressure-strain correlation...|$|R
40|$|International audienceThe UBL/CLU {{experiment}} is a side {{project of the}} regional photochemistry experiment ESCOMPTE over the Berre-Marseille area. It {{took advantage of the}} large experimental set-up, with chemistry and dynamics, ground-based and airborne instrumentations, including a large array of vertical and 3 D sounders. With additional specific instrumentation in the lower urban atmosphere, the UBL/CLU project aimed at documenting the dynamics and thermodynamics of the urban boundary layer (UBL) of the Marseille area during sunny periods. To date the initial data analyses include (a) the quality control inter-comparison of energy flux instrumentations, (b) the quality evaluation of the measurements at the urban stations, (c) the comparison of the Town Energy Balance model with the data obtained over the city center, (d) the evaluation of heat flux measurements with the scintillometers, (e) the temperature and moisture variability at the canopy level, (f) the 3 D structure of the UBL during sea breeze episodes, (g) the visible and thermal infrared signatures of the urban canopy, (h) the <b>numerical</b> urban <b>data</b> <b>base</b> and satellite <b>data</b> analysis to generate high resolution land use and aerodynamic roughness maps...|$|R
40|$|International audienceThe aim of {{this series}} of two papers is to propose an {{original}} and low-cost tool dedicated to industrial applications {{and based on the}} reflection ellipsometry technique for in situ characterization of dielectric materials at microwave frequencies. In this first paper, different theoretical developments are presented that concern first a specific numerical method for calculating the complex permittivity of a single-layer sample from the measured parameters. Based on contour line charts, this method allows obtaining simultaneously the relative uncertainties on the real and imaginary parts of the complex permittivity. Secondly, for experimental comparisons with the classical Fresnel method, a <b>numerical</b> <b>data</b> processing method <b>based</b> on contour line charts has also been developed, which aims at the determination of the reflection coefficients in both parallel and perpendicular polarizations of the material...|$|R
40|$|Abstract—The aim of {{this series}} of two papers is to propose an {{original}} and low-cost tool dedicated to industrial applications {{and based on the}} reflection ellipsometry technique for in situ character-ization of dielectric materials at microwave frequencies. In this first paper, different theoretical developments are presented that con-cern first a specific numerical method for calculating the complex permittivity of a single-layer sample from the measured param-eters. Based on contour line charts, this method allows obtaining simultaneously the relative uncertainties on the real and imaginary parts of the complex permittivity. Secondly, for experimental com-parisons with the classical Fresnel method, a <b>numerical</b> <b>data</b> pro-cessing method <b>based</b> on contour line charts has also been devel-oped, which aims at the determination of the reflection coefficients in both parallel and perpendicular polarizations of the material. Index Terms—Complex permittivity, ellipsometry, free-space methods, Fresnel coefficients, material characterization, mi...|$|R
40|$|Abstract—In this paper, the {{transmission}} line theory is utilized to characterize the metamaterials comprising of microscopic elements of a periodic array, specifically, the traditional split-ring resonators (SRRs), as an example. The bianisotropic property of the metamaterials is characterized {{in a new way}} different from the existing wave methods. As evident from both simulations and experiments, the SRR array structure is found to be quite lossy even though it is made of very good conductor or even perfect conductor as in simulation. With the present characterization, we are able to explain physically very well on how or why the energy gets lost in this structure. Finally, the theoretical result is compared with <b>numerical</b> simulation <b>data</b> obtained <b>based</b> on quasi-static Lorentz theory to further verify our analysis. 1...|$|R
40|$|The {{issue of}} waste {{management}} within airports {{is becoming increasingly}} important with enormous increases in passenger numbers and is a key responsibility of the facilities manager. Airports are notoriously poor environmental performers and this growth in the industry is leading to increasing levels of waste production. The {{purpose of this paper}} is to assess the efficiency of waste management operations at BAA airports, with reference to best practices within airports in continental Europe. The paper presents the findings of a survey of waste management methods in a sample of UK airports. The analysis of <b>numerical</b> <b>data</b> is <b>based</b> on those airports in the BAA group. Many of these are among the busiest airports in Britain, and Heathrow and Gatwick are two of the world's busiest. Data constraints prevented a more detailed analysis of other airports outside BAA. The paper highlights some difficulties in measuring BAA's waste management efficiency based on the waste hierarchy and concludes that some European airports have achieved greater efficiency in waste management. The situation is now changing though and BAA is taking environmental management seriously. However, a more co-ordinated approach to environmental strategy is needed across the industry and this is best produced at government level. Airports, Facilities Management, Environment, Recycling, Waste,...|$|R
40|$|We {{have given}} the {{education}} of manual designing and drafting to the undergraduate students (sophomore, junior, senior) over the twenty years or so. The manual educational program composes of the basic drafting, mechanism-design, material-design, fundamental design-formulae, calculation of <b>numerical</b> design <b>data</b> and its drafting. The basic drafting based on JIS (Japanese Industrial Standard) and/or ISO (International organization for standardization) contains the draftings of lines, symbols, dimensional lines, a double-ended spanner, a worm gear, a plain bearing, a screw jack (with a sketch of it) and so on. The material design includes the choice of best fit materials for the design parts on which various kinds of force work using the JIS material handbooks or others. Students {{should be able to}} use the proper design-formulae for the spacial design parts out of the numerous fundamental formulae to calculate strength and deflection of various machine parts and the mechanical structures referring to design text books and JIS design manuals. The <b>numerical</b> design <b>data</b> <b>based</b> on the proper mechanism should be calculated for each machine part using the these material-design and design-formulas. All of the above mentioned educational programs are also prepared using a personal computer and a 2 -D Mutoh CAD system as a trial by filing the necessary informations in floppy disks. Some efforts are given to use them in the practical education. The comparison and discussion of the both educational programs are given in details in this report...|$|R
40|$|Abstract: This paper {{develops}} a general methodology of nonparametric and semiparametric regression for group testing data, relating group testing responses to covariates at individual level. We fit nonparametric and semiparametric models and obtain estimators of the parameters and the nonparametric regression function by maximizing penalized likelihood function. For implementation, we develop a modified EM algorithm with individual responses as complete data and observed group testing responses as observed <b>data.</b> <b>Numerical</b> results <b>based</b> on simulations and chlamydia data {{collected in a}} Nebraska study show that our estimation methods perform well for estimating both the individual probability of positive outcome and the prevalence rate in the population...|$|R
