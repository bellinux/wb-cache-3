17|2729|Public
5000|$|A matrix with [...] is {{positive}} definite, {{and one with}} [...] is negative definite. Such matrices have inverses. The inverse of a <b>negative</b> <b>definite</b> <b>matrix</b> is bounded by ...|$|E
40|$|In this paper, we {{prove that}} the MLEs of the {{parameters}} [mu] and [sigma] of a normal population, based on general progressively Type-II censored samples, exist and are unique. Log-concavity Location-scale family Normal distribution Progressively Type-II censored samples Hessian matrix <b>Negative</b> <b>definite</b> <b>matrix...</b>|$|E
30|$|Noting that A is a {{diagonal}} <b>negative</b> <b>definite</b> <b>matrix,</b> we can easily choose proper matrices Λ and K {{such that the}} condition (28) is satisfied. For example, if we choose K= 1 / 2 A, then for arbitrary positive definite matrix Λ, (28) can always be guaranteed.|$|E
3000|$|..., {{the result}} is {{well-known}} Kantorovich inequality. Moreover, it holds for <b>negative</b> <b>definite</b> Hermite <b>matrices,</b> even for any invertible Hermite matrix, there exists a similar inequality.|$|R
40|$|The {{class of}} Schoenberg transformations, {{embedding}} Euclidean distances into higher dimensional Euclidean spaces, is presented, and derived from theorems on positive <b>definite</b> and conditionally <b>negative</b> <b>definite</b> <b>matrices.</b> Original {{results on the}} arc lengths, angles and curvature of the transformations are proposed, and visualized on artificial data sets by classical multidimensional scaling. A distance-based discriminant algorithm and a robust multidimensional centroid estimate illustrate the theory, closely connected to the Gaussian kernels of Machine Learning...|$|R
40|$|A {{systematic}} Bayesian {{framework is}} developed for physics constrained parameter inference of stochastic differential equations (SDE) from partial observations. Physical constraints are derived for stochastic climate models but are applicable for many fluid systems. A condition is derived for global stability of stochastic climate models based on energy conservation. Stochastic climate models are globally stable when a quadratic form, which {{is related to}} the cubic nonlinear operator, is <b>negative</b> <b>definite.</b> A new algorithm for the efficient sampling of such <b>negative</b> <b>definite</b> <b>matrices</b> is developed and also for imputing unobserved data which improve the accuracy of the parameter estimates. The performance of this framework is evaluated on two conceptual climate models...|$|R
40|$|The global {{exponential}} {{stability and}} uniform {{stability of the}} equilibrium point for high-order delayed Hopfield neural networks with impulses are studied. By utilizing Lyapunov functional method, the quality of <b>negative</b> <b>definite</b> <b>matrix,</b> and the linear matrix inequality approach, some new stability criteria for such system are derived. The results {{are related to the}} size of delays and impulses. Two examples are also given to illustrate the effectiveness of our results...|$|E
40|$|Let A ∈ Rn×n and let B ∈ Rn×p and {{consider}} the Lyapunov matrix equation AX + XAT + BBT = 0. If A + AT < 0, then the extended Krylov subspacemethod (EKSM) {{can be used to}} compute a sequence of low rank approximations of X. In this paper we show how to construct a symmetric <b>negative</b> <b>definite</b> <b>matrix</b> A and a column vector B, for which the EKSM generates a predetermined residual curve...|$|E
30|$|The {{following}} notations {{are used}} throughout the paper. The superscript “T” denotes the transpose of a matrix. ^n stands for the set of real vectors with dimension n. R > 0 denotes a symmetric positive definite matrix and R < 0 denotes a symmetric <b>negative</b> <b>definite</b> <b>matrix.</b> In a symmetric matrix, the symbol “*” is used to denote the term that is induced by symmetry. The symbol ⊗ stands for the Kronecker product. In addition, matrices whose dimensions are not explicitly stated {{are assumed to be}} compatible for algebraic operations.|$|E
30|$|In this paper, we {{introduce}} {{some new}} bounds for several Kantorovich-type inequalities for commutative positive <b>definite</b> Hermitian <b>matrix</b> pairs. As a particular situation, in Corollary  2.4, when A and B are both positive definite, the result provides a sharpened upper {{bound for the}} matrix version of the well-known Greub-Rheinboldt inequality. Moreover, it holds for <b>negative</b> <b>definite</b> Hermite <b>matrices.</b> Also, a refinement of Kantorovich-type inequalities concerning positive <b>definite</b> <b>matrices</b> is presented together with an application to the Hadamard product.|$|R
3000|$|... (< 0, ≤ 0, ≥ 0) {{to denote}} a {{positive}} (<b>negative,</b> semi-negative, semi-positive) <b>definite</b> <b>matrix</b> P. The symmetric term in a symmetric matrix is denoted as ∗.|$|R
3000|$|Notations. The notations in {{this paper}} are {{presented}} as follows. R^n denotes the n-dimensional Euclidean space. R^n × m denotes {{the set of the}} n × m real matrices. R > 0 [...] (≥ 0) and R < 0 (≤ 0) denote the positive definite (semi-positive <b>definite)</b> and <b>negative</b> <b>definite</b> (semi-negative <b>definite)</b> <b>matrices,</b> respectively. “I “and “ 0 ” denote the identity and the zero matrix with appropriate dimensions, respectively. The superscripts “T” and “− 1 ” denote the matrix transposition and matrix inverse, respectively. diag{...} denotes the block-diagonal matrix. {∙} denotes the maximum value of the term “•”. “*” denotes the vector term that is induced by symmetry.|$|R
3000|$|We denote by λ_m(D), λ_M(D), and D^T {{the minimum}} eigenvalue, the maximum eigenvalue, and the {{transpose}} of a square matrix D, respectively. The Euclidean norm of the vector x is denoted [...] x [...]. The matrix norm · is {{also referred to}} the Euclidean norm. We will use D> 0 to display a symmetric positive definite matrix D, D< 0 to display a symmetric <b>negative</b> <b>definite</b> <b>matrix</b> D, D≤ 0 to display a symmetric seminegative definite matrix D, and D≥ 0 to display a symmetric semi-positive definite matrix D. We denote f(x(a^-))=_t→ af(x(t)).|$|E
3000|$|Denote D=diag (d_ 1, d_ 2, [...]..., d_n [...]). I_n is an n× n {{identity}} matrix. For the {{symmetric matrix}} T, T> 0 (T< 0) means that T {{is a positive}} definite (<b>negative</b> <b>definite)</b> <b>matrix,</b> and T≥ 0 (T≤ 0) means that T is a semi-positive definite (semi-negative definite) matrix. For matrices Q=(q_ij)_n× n and H=(h_ij)_n× n, Q≫H (Q≪H) means that q_ij≥ h_ij (q_ij≤ h_ij), for i,j= 1, 2,...,n. And by the interval matrix [Q,H], it follows that Q≪H. For any matrix L=(l_ij)_n× n∈[Q,H], it means Q≪L≪H, i.e., q_ij≤ l_ij≤ h_ij for i,j= 1, 2,...,n. The symmetric terms in a symmetric matrix are denoted by ‘∗’.|$|E
40|$|Click on the DOI link {{below to}} access the article (may not be free). The {{variogram}} matrix function is an important measure for the dependence of a vector random field with second-order increments, and is {{a useful tool for}} linear predication or cokriging. This paper proposes an efficient approach to construct variogram matrix functions, based on three ingredients: a univariate variogram, a conditionally <b>negative</b> <b>definite</b> <b>matrix,</b> and a Bernstein function, and derives three classes of variogram matrix functions for vector elliptically contoured random fields. Moreover, various dependence structures among components can be derived through appropriate mixture procedures demonstrated in this paper. We also obtain covariance matrix functions for second-order vector random fields through the Schoenberg–Lévy kernels. Peer reviewe...|$|E
5000|$|More generally, a twice-differentiable real {{function}} f on n real variables has local minimum at arguments z1, ..., zn if its gradient is {{zero and}} its Hessian (the matrix of all second derivatives) is positive semi-definite at that point. Similar statements {{can be made}} for <b>negative</b> <b>definite</b> and semi-definite <b>matrices.</b>|$|R
40|$|Abstract. In this paper, {{we first}} {{consider}} the parameter estimation of a multivariate random process distribution using multivariate Gaussian mixture law. The labels of the mixture {{are allowed to}} have a general probability law which gives the possibility to modelize a temporal structure of the process under study. We generalize the case of univariate Gaussian mixture in [1] {{to show that the}} likelihood is unbounded and goes to infinity when one of the covariance matrices approaches the boundary of singularity of the non <b>negative</b> <b>definite</b> <b>matrices</b> set. We characterize the parameter set of these singularities. As a solution to this degeneracy problem, we show that the penalization of the likelihood by an Inverse Wishart prior on covariance matrices results to a penalized or maximum a posteriori criterion which is bounded. Then, the existence of positive <b>definite</b> <b>matrices</b> optimizing this criterion can be guaranteed. We also show that with a modified EM procedure or with a Bayesian sampling scheme, we can constrain covariance matrices to belong to a particular subclass of covariance matrices. Finally, we study degeneracies in the source separation problem where the characterization of parameter singularity set is more complex. We show, however, that Inverse Wishart prior on covariance matrices eliminates the degeneracies in this case too. We consider a double stochastic process...|$|R
40|$|Abstract. In [25] a new non-stagnation {{condition}} for the convergence of GMRES on indefinite problems was proposed. In this paper we derive an enhanced strategy leading to a more general non-stagnation condition. Moreover, we show that the analysis also provides a good setting to derive asymptotic convergence rate estimates for indefinite problems. The analysis is then explored {{in the context of}} saddle point matrices, when these are preconditioned in a way so as to lead to nonsym-metric and indefinite systems. Our results indicate that these matrices may represent an insightful training set towards the understanding of the interaction between indefiniteness and stagnation. 1. Introduction. A real n×nmatrix A is said to be positive definite (or positive real) if x⊤Ax> 0 for any real nonzero vector x of length n, where x ⊤ is the transpose of x. A similar definition holds for <b>negative</b> <b>definite</b> <b>matrices.</b> Large nonnormal real linear systems of the form Ax = b are known to be particularly difficult to solve by iterative Krylov subspace methods whenever A is not definite, that is when th...|$|R
40|$|It {{is shown}} that the Wilson {{renormalization}} group flow of couplings on the space of cutoff field theories, after subtracting two terms (to account for wavefunction renormalization at the cutoff scale and normal ordering of higher order interactions), is related by a particular <b>negative</b> <b>definite</b> <b>matrix</b> (the so-called Zamolodchikov `metric') to the gradient of a positive-definite function, in any dimension. In particular, the one-form dual to the Wilson flow, using this matrix, is not even closed. Thus, with this choice of `metric', there is no function on the space of cutoff field theories which has critical points precisely where the Wilson renormalization group flow has fixed points. In the case of two-dimensional scalar field theory, the linearized tachyon equation of motion in string theory arises as a combination of terms that are gradients and linear terms subtracted from the Wilson flow, showing explicitly that these linear terms are physically important...|$|E
40|$|Multivariate {{meta-analysis}} {{has potential}} over its univariate counterpart. The most common challenge in uni-variate or multivariate meta-analysis is estimating heterogeneity parameters in non-negative domains under the random-effects model assumption. In this context, two new multivariate estimation methods are demonstrated; first, by extending the Sidik and Jonkman (2005) univariate estimates to a multivariate setting, and second, by considering an iterative {{version of the}} Sidik and Jonkman method, namely, a Hybrid method developed in Wouhib (2013). These two methods are compared with extended DerSimonian and Laird methods (Jackson et al. 2009; Chen et al. 2012) by using an example and simulation in random-effects multivariate meta-analysis. Finally, {{the benefits of the}} proposed estimates are evaluated in terms of precision in estimating vectors of effect sizes and associated covariance matrices via simulation. Also, some limitations and remedies resulting from <b>negative</b> <b>definite</b> <b>matrix</b> in estimating heterogeneity parameters will be discussed...|$|E
40|$|Among {{the fastest}} methods for solving stiff PDE are {{exponential}} integrators, which require {{the evaluation of}} f(A), where A is a <b>negative</b> <b>definite</b> <b>matrix</b> and f is the exponential function {{or one of the}} related "φ functions" such as φ_ 1 (z) = (e^z- 1) /z. Building on previous work by Trefethen and Gutknecht, Gonchar and Rakhmanov, and Lu, we propose two methods for the fast evaluation of f(A) that are especially useful when shifted systems (A+zI) x=b can be solved efficiently, e. g. by a sparse direct solver. The first method method is based on best rational approximations to f on the negative real axis computed via the Carathéodory-Fejér procedure, and we conjecture that the accuracy scales as (9. 28903 [...] .) ^- 2 n, where n is the number of complex matrix solves. In particular, three matrix solves suffice to evaluate f(A) to approximately six digits of accuracy. The second method is an application of the trapezoid rule on a Talbot-type contour...|$|E
40|$|Presented at MaxEnt 01. To {{appear in}} Bayesian Inference and Maximum Entropy Methods, B. Fry (Ed.), AIP Proceedings. 11 pages, 3 Postscript figuresIn this paper, we first {{consider}} the parameter estimation of a multivariate random process distribution using multivariate Gaussian mixture law. The labels of the mixture {{are allowed to}} have a general probability law which gives the possibility to modelize a temporal structure of the process under study. We generalize the case of univariate Gaussian mixture in [Ridolfi 99] {{to show that the}} likelihood is unbounded and goes to infinity when one of the covariance matrices approaches the boundary of singularity of the non <b>negative</b> <b>definite</b> <b>matrices</b> set. We characterize the parameter set of these singularities. As a solution to this degeneracy problem, we show that the penalization of the likelihood by an Inverse Wishart prior on covariance matrices results to a penalized or maximum a posteriori criterion which is bounded. Then, the existence of positive <b>definite</b> <b>matrices</b> optimizing this criterion can be guaranteed. We also show that with a modified EM procedure or with a Bayesian sampling scheme, we can constrain covariance matrices to belong to a particular subclass of covariance matrices. Finally, we study degeneracies in the source separation problem where the characterization of parameter singularity set is more complex. We show, however, that Inverse Wishart prior on covariance matrices eliminates the degeneracies in this case too...|$|R
40|$|Abstract. In Simoncini and Szyld [Numer. Math., 109 (2008), pp. 477 – 487] a new non-stagnation {{condition}} for the convergence of GMRES on indefinite problems was proposed. In this paper we derive an enhanced strategy leading to a more general non-stagnation condition. Moreover, we show that the analysis also provides a good setting to derive asymptotic convergence rate estimates for indefinite problems. The analysis is then explored {{in the context of}} saddle point matrices, when these are preconditioned in a way so as to lead to nonsymmetric and indefinite systems. Our results indicate that these matrices may represent an insightful training set towards the understanding of the interaction between indefiniteness and stagnation. Key words. saddle point matrices, large linear systems, GMRES, stagnation. AMS subject classifications. 65 F 10, 65 N 22, 65 F 50. 1. Introduction. A real n × n matrix A is said to be positive definite (or positive real) if x ⊤ Ax> 0 for any real nonzero vector x of length n, where x ⊤ is the transpose of x. A similar definition holds for <b>negative</b> <b>definite</b> <b>matrices.</b> Large nonnormal real linear systems of the form Ax = b are known to be particularly difficult to solve by iterative Krylov subspace methods whenever A is not definite, that is when the quantity x ⊤ Ax changes sign dependin...|$|R
30|$|Throughout this paper, we use P^T, λ_M(P) and λ_m(P) {{to denote}} the transpose, the maximum {{eigenvalue}} and the minimum eigenvalue of a square matrix P, respectively. x {{is used to}} denote the Euclidean norm of the vector x. The matrix norm · is {{also referred to as}} the Euclidean norm. We use P> 0 (< 0, ≤ 0, ≥ 0) to denote a symmetrical positive (<b>negative,</b> semi-negative, semi-positive) <b>definite</b> <b>matrix</b> P. f(x(t_ 1 ^-)) is defined by f(x(t_ 1 ^-))=_t→ t_ 1 ^-f(x(t)).|$|R
3000|$|The {{solutions}} of {{the networks}} discussed in the following are intended in the Filippov sense throughout this paper. R^n is n-dimensional Euclidean space. C([-τ, 0],R^n) is Banach space of all continuous functions. · denotes the Euclidean norm of a vector and its induced norm of a matrix. co{Π,Π} denotes closure of the convex hull generated by real numbers Π̃ and Π̂ or real matrices Π̃ and Π̂. Let w_ij^m={ŵ_ij^m,w̌_ij^m}, w_ij^m={ŵ_ij^m,w̌_ij^m}, w_ij^m={|ŵ_ij^m|,|w̌_ij^m|}, Λ^m_ij={|Λ^m_ij|,|Λ^m_ij|} for i,j= 1, 2,...,n. Denote K=diag(k_ 1,k_ 2,...,k_n), W^m=(w̃^m_ij)_n× n, Λ^m=(Λ^m_ij)_n× n. I_n is an n× n identity matrix. For symmetric matrix T, T> 0 [...] (T< 0) means that T is a positive definite (<b>negative</b> <b>definite)</b> <b>matrix.</b> For matrices Q=(q_ij)_n× n and H=(h_ij)_n× n, Q≫ H (Q≪ H) means that q_ij≥ h_ij (q_ij≤ h_ij), for i,j= 1, 2,...,n. And by the interval matrix [Q,H], it follows that Q≪ H. For any matrix L=(l_ij)_n× n∈[Q,H], it means Q≪L≪H, i.e., q_ij≤ l_ij≤ h_ij for i,j= 1, 2,...,n. The symmetric terms in a symmetric matrix are denoted by ‘∗’.|$|E
40|$|Volatility, {{represented}} {{in the form of}} conditional heteroscedasticity, plays an impor- tant role in controlling and forecasting risks in various financial operations including asset pricing, portfolio allocation, and hedging futures. However, modeling and fore- casting multi-dimensional conditional heteroscedasticity are technically challenging. As the volatilities of many financial assets are often driven by a few common and latent factors, we propose in this paper a dimension reduction method to model a multivariate volatility process and to estimate a lower-dimensional space, to be called the volatility space, within which the dynamics of the multivariate volatility process is confined. The new method is simple to use, as technically it boils down to an eigenanalysis for a non- <b>negative</b> <b>definite</b> <b>matrix.</b> Hence it is applicable to the cases when the number of assets concerned is in the order of thousands (using an ordinary PC/laptop). On the other hand, the model has the capability to cater for complex conditional heteroscedastic- ity behavior for multi-dimensional processes. Some asymptotic properties for the new method are established. We further illustrate the new method using both simulated and real data examples...|$|E
40|$|As {{it is well}} known, Runge-Kutta-Nyström (RKN) {{methods are}} used to {{integrate}} nu-merically differential equations of second order in time. In this work, we are considering stiff problems like utt(t) = Au(t) + f(t), with A a symmetric and <b>negative</b> <b>definite</b> <b>matrix.</b> There are several definitions of stability intervals in the literature [1, 2]. However, up to our knowledge, a clear connection between these intervals and the stability of RKN methods {{has not yet been}} made. As the natural norm is the energy norm (in particular, for space discretizations of PDEs), we denote by R(θ) the stability matrix that appears with this norm. Then, we define the stability interval as C? = {θ ∈ R+/ρ(R(θ)) ≤ 1, and the eigenvalues of unit modulus have single geometric multiplicity Let B be a symmetric and positive definite matrix such that B 2 = −A. Then, if σ(kB) ⊂ C?, with k the time step-size, the powers of R(kB) are bounded, but this bound, in general, is not independent {{of the size of the}} eigenvalues of kB. We have proved that it is necessary to impose certain condition over the coefficients of the RKN method to guarantee even the bound of the stability matrix itself (and so that of its powers) independently of the stiffness of the problem. We have found a RKN method with C? = R+ such that its coefficients satisfy the new condition and we have made comparisons with others in the literature [1]...|$|E
5000|$|... is <b>negative</b> <b>definite</b> {{for some}} {{positive}} <b>definite</b> <b>matrix</b> [...] (The relevant Lyapunov function is [...]) ...|$|R
40|$|An {{algorithm}} is presented which solves the multi-dimensional advection-diffusion equation on complex shapes to 2 -order accuracy and is asymptotically stable in time. This bounded-error result {{is achieved by}} constructing, on a rectangular grid, a differentiation matrix whose symmetric part is <b>negative</b> <b>definite.</b> The differentiation <b>matrix</b> accounts for the Dirichlet boundary condition by imposing penalty like terms. Numerical examples in 2 -D show that the method is effective even where standard schemes, stable by traditional definitions, fail. It gives accurate, non oscillatory results even when boundary layers are not resolved...|$|R
40|$|Let (X,O) be a germ of {{a normal}} surface singularity, π : X̃⟶ X be the minimal {{resolution}} of singularities and let A=(a_i,j) be the n× n symmetrical intersection matrix of the exceptional set of X̃. In an old preprint Nash proves that the set of arcs on a surface singularity is a scheme H, and defines a map N from the set of irreducible components of H to the set of exceptional components of the minimal resolution of singularities of (X,O). He proved that this map is injective and ask if it is surjective. In this paper we consider the canonical decomposition H=∪_i= 1 ^n N̅_i: o For any couple (E_i,E_j) of distinct exceptional components, we define Numerical Nash condition (NN_(i,j)). We have that (NN_(i,j)) implies N̅_i⊂N̅_j. In this paper we prove that (NN_(i,j)) is always true {{for at least the}} half of couples (i,j). o The condition (NN_(i,j)) is true for all couples (i,j) with i=j, characterizes a certain class of <b>negative</b> <b>definite</b> <b>matrices,</b> that we call Nash matrices. If A is a Nash matrix then the Nash map N is bijective. In particular our results depends only on A and not on the topological type of the exceptional set. o We recover and improve considerably almost all results known on this topic and our proofs are new and elementary. o We give infinitely many other classes of singularities where Nash Conjecture is true. The proofs are based on my old work M and in Plenat P. Comment: 17 pages, 5 figure...|$|R
40|$|The {{standard}} model for sea ice dynamics treats the ice pack as a viscous-plastic material that flows plastically under typical stress conditions but behaves as a linear viscous fluid where strain rates {{are small and}} the ice becomes nearly rigid. Because of large viscosities in these regions, implicit numerical methods are necessary for timesteps larger than a few seconds. Current solution methods for these equations use iterative relaxation methods, which are time consuming, scale poorly with mesh resolution, and are not well adapted to parallel computation. To remedy this, we have developed and tested two separate methods. First, by demonstrating that the viscous-plastic rheology can be represented by a symmetric, <b>negative</b> <b>definite</b> <b>matrix</b> operator, we have implemented the faster and better behaved preconditioned conjugate gradient method. Second, realizing that only {{the response of the}} ice on time scales associated with wind forcing need be accurately resolved, we have modified the model to reduce to the viscous-plastic model at these time scales; at shorter time scales the adjustment process takes place by a numerically efficient elastic wave mechanism. This modification leads to a fully explicit numerical scheme which further improves the computational efficiency and is an advantage for implementations on parallel machines. Furthermore, we observe that the standard viscous-plastic model has poor dynamic response to forcing on a daily time scale, given the standard time step (1 day) used by the ice modeling community. In contrast, the explicit discretization of the elastic wave mechanism allows the elastic-viscous-plastic model to capture the ice response to variations in the imposed stress more accurately. Thus, the elastic-viscous-plastic model provides more accurate results for shorter time scales associated with physical forcing, reproduces viscous-plastic model behavior on longer time scales, and is computationally more efficient. 49 refs., 13 figs., 6 tabs...|$|E
40|$|Modelling high {{dimensional}} {{time series}} and non-stationary time series are two import aspects in {{time series analysis}} nowadays. The main objective of this thesis is {{to deal with these}} two problems. The first two parts deal with high dimensionality and the third part considers a change point detection problem. In the first part, we consider a class of spatio-temporal models which extend popular econometric spatial autoregressive panel data models by allowing the scalar coefficients for each location (or panel) different from each other. The model is of the following form: yt = D(λ 0) Wyt + D(λ 1) yt− 1 + D(λ 2) Wyt− 1 + εt, (1) where yt = (y 1,t,..., yp,t) T represents the observations from p locations at time t, D(λk) = diag(λk 1,..., λkp) and λkj is the unknown coefficient parameter for the j-th location, and W is the p×p spatial weight matrix which measures the dependence among different locations. All the elements on the main diagonal of W are zero. It is a common practice in spatial econometrics to assume W known. For example, we may let wij = 1 /(1 + dij), for i ̸= j, where dij ≥ 0 is an appropriate distance between the i-th and the j-th location. It can simply be the geographical distance between the two locations or the distance reflecting the correlation or association between the variables at the two locations. In the above model, D(λ 0) captures the pure spatial effect, D(λ 1) captures the pure dynamic effect, and D(λ 2) captures the time-lagged spatial effect. We also assume that the error term εt = (ε 1,t, ε 2,t,..., εp,t) T in (1) satisfies the condition Cov (yt− 1, εt) = 0. When λk 1 = · · · = λkp for all k = 1, 2, 3, (1) reduces to the model of Yu et al. (2008), in which there are only 3 unknown regressive coefficient parameters. In general the regression function in (1) contains 3 p unknown parameters. To overcome the innate endogeneity, we propose a generalized Yule-Walker estimation method which applies the least squares estimation to a Yule-Walker equation. The asymptotic theory is developed under the setting that both the sample size and the number of locations (or panels) tend to infinity under a general setting for stationary and α-mixing processes, which includes spatial autoregressive panel data models driven by i. i. d. innovations as special cases. The proposed methods are illustrated using both simulated and real data. In part 2, we consider a multivariate time series model which decomposes a vector process into a latent factor process and a white noise process. Let yt = (y 1,t, · · ·, yp,t) T be an observable p × 1 vector time series process. The factor model decomposes yt in the following form: yt = Axt + εt, (2) where xt = (x 1,t, · · ·, xr,t) T is a r × 1 latent factor time series with unknown r ≤ p and A = (a 1, a 2, · · ·, ar) is a p × r unknown constant matrix. εt is a white noise process with mean 0 and covariance matrix Σε. The first part of (2) is a dynamic part and the serial dependence of yt is driven by xt. We will achieve dimension reduction once r ≪ p {{in the sense that the}} dynamics of yt is driven by a much lower dimensional process xt. Motivated by practical needs and the characteristic of high dimensional data, the sparsity assumption on factor loading matrix is imposed. Different from Lam, Yao and Bathia (2011) ’s method, which is equivalent to an eigenanalysis of a non <b>negative</b> <b>definite</b> <b>matrix,</b> we add a constraint to control the number of nonzero elements in each column of the factor loading matrix. Our proposed sparse estimator is then the solution of a constrained optimization problem. The asymptotic theory is developed under the setting that both the sample size and the dimensionality tend to infinity. When the common factor is weak in the sense that δ > 1 / 2 in Lam, Yao and Bathia (2011) ’s paper, the new sparse estimator may have a faster convergence rate. Numerically, we employ the generalized deflation method (Mackey (2009)) and the GSLDA method (Moghaddam et al. (2006)) to approximate the estimator. The tuning parameter is chosen by cross validation. The proposed method is illustrated with both simulated and real data examples. The third part is a change point detection problem. we consider the following covariance structural break detection problem: Cov(yt) I(tj− 1 ≤ t < tj) = Σtj− 1, j = 1, · · ·, m + 1, where yt is a p × 1 vector time series, Σtj− 1 ̸ = Σtj and t 1,..., tm are change points, 1 = t 0 < t 1 < · · · < tm+ 1 = n. In the literature, the number of change points m is usually assumed to be known and small, because a large m would involve a huge amount of computational burden for parameters estimation. By reformulating the problem in a variable selection context, the group least absolute shrinkage and selection operator (LASSO) is proposed to estimate m and the locations of the change points t 1,..., tm. Our method is model free, it can be extensively applied to multivariate time series, such as GARCH and stochastic volatility models. It is shown that both m and the locations of the change points t 1,..., tm can be consistently estimated from the data, and the computation can be efficiently performed. An improved practical version that incorporates group LASSO and the stepwise regression variable selection technique are discussed. Simulation studies are conducted to assess the finite sample performance...|$|E
40|$|Let (X, O) be a germ of {{a normal}} surface singularity, π: ˜ X − → X be the minimal {{resolution}} of singularities and let A = (ai,j) be the n × n symmetrical intersection matrix of the exceptional set of ˜ X. In an old preprint Nash proves that the set of arcs on a surface singularity is a scheme H, and defines a map N from the set of irreducible components of H to the set of exceptional components of the minimal resolution of singularities of (X, O). He proved that this map is injective and ask if it is surjective. In this paper we consider the canonical decomposition H = ∪ n i= 1 ¯ Ni: • For any couple (Ei, Ej) of distinct exceptional components, we define Numerical Nash condition (NN (i,j)). We have that (NN (i,j)) implies ¯ Ni ̸ ⊂ ¯ Nj. In this paper we prove that (NN (i,j)) is always true {{for at least the}} half of couples (i, j). • The condition (NN (i,j)) is true for all couples (i, j) with i ̸ = j, characterizes a certain class of <b>negative</b> <b>definite</b> <b>matrices,</b> that we call Nash matrices. If A is a Nash matrix then the Nash map N is bijective. In particular our results depends only on A and not on the topological type of the exceptional set. • We recover and improve considerably almost all results known on this topic and our proofs are new and elementary. • We give infinitely many other classes of singularities where Nash Conjecture is true. The proofs are based on my old work [7] and in Plenat [9]...|$|R
40|$|In his {{fundamental}} paper [5], Zariski {{established the}} following result: Theorem. Let D {{be an effective}} Q-divisor on a smooth projective surface X. Then there are uniquely determined effective (possibly zero) Q-divisors P and N with D = P + N such that (i) P is nef, (ii) N is zero or has <b>negative</b> <b>definite</b> intersection <b>matrix,</b> (iii) P · C = 0 for every irreducible component C of N. The decomposition D = P + N is called the Zariski decomposition of D, the divisors P and N are respectively {{the positive and negative}} parts of D. Zariski’s result has been used to study linear series on surfaces, and in the classification of surfaces (see [1, Chapt. 14] and [4, Sect. 2. 3. E], as well as the references therein). We also mention that there is an extension to pseudo-effective divisors due to Fujita (see [2] and the nice account in [1]). Given an effective divisor D, Zariski’s original proof employs a rather sophisticate...|$|R
30|$|In {{the last}} few years, many authors have been greatly {{interested}} in developing the theory and numerical approaches for positive definite solutions to the nonlinear matrix equations of the form (1.1) and (1.2). Similar types of (1.1) and (1.2) have been investigated [8 – 12]. The matrix equations X± A^*X^- 1 A=Q have been studied by several authors [1 – 4, 13, 14] and different iterative algorithms for computing the positive definite solutions with linear and quadratic rate of convergence are proposed. Ivanov et al. [15] derived sufficient conditions {{for the existence of}} positive definite solutions for the matrix equations X± A^*X^- 2 A=I and they proposed iterative algorithms for obtaining positive definite solutions of these equations. El-Sayed [16] presented two iterative methods for calculating the positive definite solutions of the matrix equation X-A^*X^-nA=Q, for the integer n≥ 1, the first method is derived for a normal matrix A and for the second method a sufficient condition for convergence is given for n = 2 ^k. El-Sayed and Ran [17] studied the general matrix equation X+ A^*F(X)A=Q where F maps positive <b>definite</b> <b>matrices</b> either into positive <b>definite</b> <b>matrices</b> or into <b>negative</b> <b>definite</b> <b>matrices</b> and satisfies some monotonicity property. Hasanov and Ivanov [18] considered the matrix equations X± A^*X^-nA=Q, they studied the solutions and perturbation analysis of these solutions. They also derived a sufficient condition for the existence of a unique positive definite solution of the equation X- A^*X^-nA=Q. Hasanov [19] established and proved theorems for the necessary and sufficient conditions of the existence of positive definite solutions for the matrix equations X± A^*X^-qA=Q with 0 < q≤ 1, he showed that the equation X- A^*X^-qA=Q has a unique positive definite solution by using the properties of matrix sequence in Banach space. Also, in [5] some conditions for the existence of positive definite solution of the equation X+∑_i= 1 ^mA_i^*X^- 1 A_i=I have been obtained and two iterative algorithms to find the maximal positive definite solution of this equation have been presented. Duan et al. [20] gave two perturbation estimates for the positive definite solution of the equation X-∑_i= 1 ^mA_i^*X^δ_iA_i=Q with 0 < |δ_i|< 1. Duan et al. [6] studied the equation X-∑_i= 1 ^mN_i^*X^- 1 N_i=I, they used the Thompson metric to prove that the matrix equation always has a unique positive definite solution and they derived a precise perturbation bound for the unique positive definite solution. In addition, other nonlinear matrix equations such as X^s± A^TX^-tA=I_n [21], AX^ 2 + BX+C = 0 [22], and X=Q +A^H(I⊗ X-C)^-δA^* [23] have been investigated.|$|R
40|$|Four generalizations of the Phase Integral Approximation (PIA) to sets of N {{ordinary}} {{differential equations}} of the Schroedinger type: u_j''(x) + Sum{k = 1 to N} R_{jk}(x) u_k(x) = 0, j = 1 to N, are described. The recurrence relations for higher order corrections {{are given in}} the form valid in arbitrary order and for the matrix R_{jk} either hermitian or non-hermitian. For hermitian and <b>negative</b> <b>definite</b> R <b>matrices,</b> the Wronskian conserving PIA theory is formulated which generalizes Fulling's current conserving theory pertinent to positive <b>definite</b> R <b>matrices.</b> The idea of a modification of the PIA, well known for one equation: u''(x) + R(x) u(x) = 0, is generalized to sets. A simplification of Wronskian or current conserving theories is proposed which in each order eliminates one integration from the formulas for higher order corrections. If the PIA is generated by a non-degenerate eigenvalue of the R matrix, the eliminated integration {{is the only one}} present. In that case, the simplified theory becomes fully algorithmic and is generalized to non-hermitian R matrices. General theory is illustrated by a few examples generated automatically by using author's program in Mathematica, published in arXiv: 0710. 5406. Comment: 27 pages, RevTeX, accepted for publication in J. Math. Phy...|$|R
