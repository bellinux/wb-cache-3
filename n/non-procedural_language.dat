11|26|Public
50|$|NPL (for NonProcedural Language) was a {{relational}} database language developed by T.D. Truitt et al. in 1980 for Apple II and MS-DOS.In general, a <b>non-procedural</b> <b>language</b> (also called a declarative language) requires the programmer to specify what the program should do, rather than (as with a procedural language) providing the sequential steps indicating how the program should perform its task(s).|$|E
40|$|Abstract—This {{paper will}} {{introduce}} {{the reader to}} the basic concepts of query processing and query optimization in the relational database domain. How a database processes a query {{as well as some}} of the algorithms and rule-sets utilized to produce more efficient queries will also be presented. This is responsible for translating a user submitted query usually written in a <b>non-procedural</b> <b>language</b> in to an efficient query evaluation program that can be executed against database...|$|E
40|$|Developing and {{evaluating}} “connectionist models” (“neural models”) {{is currently a}} difficult and time-consuming task. To address this issue, we implemented a software system called MIRRORS/II for developing connectionist models in biomedicine and other fields. MIRRORS/II is distinguished from related systems by its support of a very high-level <b>non-procedural</b> <b>language,</b> a general-purpose event-handling mechanism, and an indexed library for the accumulation of system resources. These features make MIRRORS/II a convenient software tool for individuals in biomedicine. This paper summartzes MIRRORS/II and gives a small example of its use...|$|E
50|$|Another {{variation}} {{replaces the}} parse table by pattern-matching rules in <b>non-procedural</b> <b>languages</b> such as Prolog.|$|R
40|$|WOROS (Continu, on revere elde If necemary and idmntiy by block nuaiber) Abstract {{data types}} {{programmer}} productivity modularity Nopal 20. ABSTRACT (Coftiue an reverse aide It necessary Wnd Idaitfy by WOek nursbr) iThis dissertation presents abstract data tipes {{as a means}} of introducing modularity in <b>non-procedural</b> <b>languages.</b> <b>Non-procedural</b> <b>languages</b> based on equational specifications have been proposed in recent years to improve programmer productivity reliability. Issues of structured programming (i. e. discipline...|$|R
50|$|Recently, {{with the}} {{availability}} of massive computing power, {{there has been a}} resurgence of mutation analysis within the computer science community, and work has been done to define methods of applying mutation testing to object oriented programming <b>languages</b> and <b>non-procedural</b> <b>languages</b> such as XML, SMV, and finite state machines.|$|R
40|$|Abstract: The {{application}} of <b>non-procedural</b> <b>language</b> Norma is {{considered for the}} solution of the nonstationary gas dynamics testing problems. The Norma language is a tool aimed at automated solution of the mathematical physics problems on parallel computer systems. The purpose of the Norma language is to eliminate the programming phase which is necessary to pass from computation formulas, derived by an application specialist to a computer program. There is no essential difference between computation formulas and the Norma program structures these formulas are an input for the Norma translation system. Note: Publication language:russia...|$|E
40|$|Includes bibliographical {{references}} (pages 122 - 123) The {{goal of the}} Visible Algorithms Project at California State University, Northridge is {{to develop}} a series of CAI packages that simulate walkthroughs of common algorithms. Initially these CAI packages were developed in a "terminal/machine dependent" environment using a procedural language. A 'Virtual Screen' project was subsequently developed to support these CAI packages on a broad range of terminals, machines, and/or operating systems. The primary goal of this project was to prototype three merge algorithms, with <b>non-procedural</b> <b>language,</b> in the MS/DOS environment utilizing the 'Virtual Screen' and three tools (Help, Q/A, and VAprompt). The second goal was to analyze this developmental environment. This package includes three merge lessons (polyphase, optimal, and two-way). Each lesson contains a demonstration sub-lesson and a simulation sub-lesson. A walkthrough of the polyphase merge lesson is included. The internal design and implementation techniques are also discussed. Finally, this report describes problems encountered during the project's development...|$|E
40|$|This paper reviews key query {{optimization}} techniques {{required by}} industrial-strength commercial query optimizers, using the DB 2 family of relational database products as examples. The currently available {{members of this}} family are DB 2 / 2, DB 2 / 6000, and DB 2 for MVS 1. 1 Introduction Query optimization {{is the part of}} the query compilation process that translates a data manipulation statement in a high-level, <b>non-procedural</b> <b>language,</b> such as SQL, into a more detailed, procedural sequence of operators, called a plan. Query optimizers usually select a plan by modelling the estimated cost of performing many alternative plans and then choosing the least expensive amongst them. Ever since the invention of the relational model in 1970, IBM has been actively involved in research on relational query optimization, beginning with the pioneering work in System R [SAC + 79] and continuing with the R* distributed relational DBMS prototype [DN 82], [LDH + 84] and the Starburst extensible DBMS [...] ...|$|E
40|$|The {{currently}} operational relational-like structure, {{as well as}} {{a primitive}} database management system is described. The proposed file structure integrates a B-tree variant, inverted files, and other structures to provide the underlying facility. The database management system supports multi-user, multi-database retrieval through relational views of both data and documents, as well as the interface to <b>non-procedural</b> <b>languages.</b> Emphasis regarding design decisions and tradeoffs were related to: 1) the Unix* operating system; 2) the access methods supported; 3) future development, such as document processing (information storage and retrieval), concurrency control and recovery...|$|R
40|$|Data {{requests}} ro mulriaiztabase (MDBSs) are posed through <b>non-procedural</b> <b>languages</b> such as SQL and for {{a global}} data request optimization must be performed to achieve good system performance. However, the issues are ofren complicated in multidatabases, due to addirional issues arising because of the autonomy and heterogeneity restrictions of the independent local DBMSs. The data translation problem between various local systems can be observed at the schema level and at the instance level. We have identified {{the need for a}} domain translation table in mulridatabase query processing and discuss methods of implementing it. Some observations about multidatabase inter-site joins are made and fou...|$|R
40|$|This paper {{focuses on}} the use of {{high-level}} <b>non-procedural</b> <b>languaGes</b> for stating system requirements in computer-aided design of larqe-scale information systems. Necessary and desirable features of such a language are considered along with the resolution to a 9 ro-blem definition technique composed of two requirement statement languages and their analyzers as they relate to the infor~ation ~Y 5 tem design process. Desirable features of such a high-level language include the following:. facilitates Machine Independent problem statement machine analyzable (for completeness and design) ability to provide complete information for design and optimization process provides non-procedural representation oriented toward non-prog~ammers...|$|R
40|$|Based on {{a simple}} <b>non-procedural</b> <b>language</b> with {{temporal}} logic operators, Lucid underlies a family of multi-dimensional programming languages based on intensional logic. Intension is a concept rooted in an aspect of natural language called "intensional context", in which {{the meaning of a}} statement (extension) depends on the context in which it is uttered (intension). The implicit temporal feature of Lucid makes it suitable for use as a means of describing dynamic systems. In the past, experiments have been performed and real applications have been developed with programs written in Lucid. However, these systems focused mainly on improving the execution performance of one dialect of Lucid and not address the problem of interpreting variants of Lucid. The GIPSY system is designed to not only process current Lucid variants efficiently but also to be modified easily to accept new dialects of Lucid. In the thesis, we discuss the essence of executing intensional programming languages using the eduction (also called demand-driven or lazy) execution model; describe experiments with different approaches to interpreting programs written in Lucid; and focuses on execution over a network of processors. We describe the implementation of a prototype for executing Lucid programs in a distributed environment. We also explore the advantages of applying the object concept to distributed systems and describe experiments with these methods. In addition, the thesis includes estimates of the impact of integrating computation functions into the Lucid code and proposes an advanced execution model consisting of self-contained and intelligent clients associated with a meta-level resource management...|$|E
40|$|A modular pro-gram {{contains}} {{blocks of}} code with single entry and exit points. You can reuse well written sections of code in other programs {{or in other}} sections of an existing program. If you reuse an existing segment of code, you needn’t design, code, nor debug that section of code since (presumably) you’ve already done so. Given the rising costs of software develop-ment, modular design will become more important as time passes. The basic unit of a modular program is the module. Modules have different meanings to different people, herein you can assume that the terms module, subprogram, subrou-tine, program unit, procedure, and function are all synonymous. The procedure {{is the basis for}} a programming style. The procedural languages include Pascal, BASIC, C++, FORTRAN, PL/I, and ALGOL. Examples of non-procedural lan-guages include APL, LISP, SNOBOL 4 ICON, FORTH, SETL, PROLOG, and others that are based on other programming constructs such as functional abstraction or pattern match-ing. Assembly language is capable of acting as a procedural or <b>non-procedural</b> <b>language.</b> Since you’re probably much more familiar with the procedural programming paradigm this text will stick to simulating procedural constructs in 80 x 86 assembly language. 11. 0 Chapter Overview This chapter presents an introduction to procedures and functions in assembly lan-guage. It discusses basic principles, parameter passing, function results, local variables, and recursion. You will use most of the techniques this chapter discusses in typical assem-bly language programs. The discussion of procedures and functions continues in the next chapter; that chapter discusses advanced techniques that you will not commonly use in assembly language programs. The sections below that have a “• ” prefix are essential. Those sections with a “ o ” discuss advanced topics that you may want to put off for a while. • Procedures...|$|E
40|$|Abstract: Properly used, Prolog is {{as fast as}} any {{language}} with comparable power. This paper presents guidelines for using Prolog efficiently. Some of these guidelines rely on implementation- dependent features such as indexing and tail recursion optimization; others are matters of pure algorithmic complexity. Many people think Prolog is inefficient. This is {{partly because of the}} poor performance of early experimental implementations, but another problem is that some programmers use Prolog inefficiently. Properly used, Prolog performs automated reasoning as fast as any other language with comparable power. It is certainly as fast as Lisp, if not faster. There are still those who rewrite Prolog programs in C “for speed, ” but this is tantamount to boasting, “I can implement the core of Prolog better than a professional Prolog implementor. ” 1 This paper will present some practical guidelines for using Prolog efficiently. The points made here are general and go well beyond the implementationspecific advice normally given in manuals. 1 Think procedurally as well as declaratively. Prolog is usually described as a declarative or <b>non-procedural</b> <b>language.</b> This is a half-truth. It would be better to say that most Prolog clauses can be read two ways: as declarative statements of information and as procedures for using that information. For instance, in(X,usa) :- in(X,georgia). means both “X is in the U. S. A. if X is in Georgia ” and “To prove that X is in the U. S. A., prove that X is in Georgia. ” Prolog is not alone in this regard. The Fortran statement X=Y+Z can be read both declaratively as the equation x = y + z and procedurally as the instructions LOAD Y, ADD Z, STORE X. Of course declarative readings pervade Prolog to a far greater extent than Fortran. Sometimes the declarative and procedural readings conflict. For example, Fortran lets you utter the mathematical absurdity X=X+ 1. More subtly, the Fortran statement...|$|E
5000|$|When asked, [...] "How {{could you}} {{possibly}} have done the first interactive graphics program, the first <b>non-procedural</b> programming <b>language,</b> the first object oriented software system, all in one year?" [...] Ivan replied: [...] "Well, I didn't know it was hard." ...|$|R
40|$|Abstract:- Semantic Web Technologies {{have proven}} their great {{potential}} in realizing the knowledge management solutions, {{as it is}} their vision to provide means for the unification of information resources. However, when used for real-world applications, sometimes there are some puzzles missing for effective implementation. In this paper, we study and present an approach to implement a knowledge management system {{with the use of}} semantic web technologies in combination with a <b>non-procedural</b> rule-based programming <b>language.</b> We used the both to develop a prototype system that should assist in project team building activities. In this manner, a system is proposed that enables project managers to build project teams of highly skilled, personally compatible and interested individuals. Key-Words:- semantic web, knowledge management, <b>non-procedural</b> programming <b>language,</b> team building approaches...|$|R
40|$|AbstractOne of {{the current}} major {{developments}} of computer science is a trend away from procedural programming languages, towards the creation of <b>non-procedural</b> <b>languages.</b> The paper examines {{the implications of this}} trend on large-scale mathematical modelling. In a procedural program, the basic rule is the assignment statement. In contrast, a non-procedural program consists of an underdetermined system of equations and nothing else. Consequently a non-procedural program is far more flexible and powerful than its procedural counterpart. While the latter describes only one problem the former may be used to solve every legitimate problem about the object represented by the program. The first major difficulty in designing a non- procedural modelling system is to specify the information to be derived from the non- procedural program. An interactive solution to this problem is presented,based on a purely structural analysis of the program. This solution fully exploits thesparsity of the program, can be efficiently implemented, and enables the user both to identify and to solve every legitimate problem associated with the program...|$|R
40|$|This {{dissertation}} {{deals with}} two related problems: {{development of a}} methodology for achieving memory and computation efficiency of computer programs, {{and the use of}} this methodology in very high-level programming and associated automatic program generators. Computer efficiency of programs has many aspects. Usually additional memory saves computation by avoiding the need to recompute certain variables. Our emphasis has been on reducing memory use by variables sharing memory space, without requiring recomputation. It will be shown that this also reduces computation overhead. The most significant savings are due to sharing memory in iterative steps. This is the focus of the reported research. The evaluation of memory use of the many possible alternatives for realizing a computation is highly complex and requires lengthy and expensive computations. We have developed a heuristic approach, which has been very effective in our experience, and which is practical and economical in use of the computer. Basically it consists of evaluating global memory usage altertnatives on each level of nested iteration loops, starting with the outside level and moving inwardly. Thus we neglect the rare impact of a nested iteration loop on the memory usage calculated for an outside iteration. This has lead to the principle of maximizing size of loop scopes in a program as a means to attaining a more efficient program for present-day sequential computers. The automatic design of efficient programs is also essential in use of very high level languages. The use of very high level languages offers many benefits, such as less program coding, less required proficiency in programming and analysis, and ease in understanding maintenance and updating of programs. All these benefits are conditioned on whether the language processor can produce satisfactorily efficient program. The dissertation reports the design and implementation of {{a new version of the}} MODEL language and processor which incorporates algorithms for producing more efficient programs. The dissertation describes briefly the MODEL <b>non-procedural</b> <b>language</b> and the analysis, scheduling, and code generation tasks...|$|E
40|$|Information System {{development}} involves various activities; {{the process}} of developing information systems is considered to be the production of a series of documents. The information derived from the activities of the life cycle needs to be stored {{in a way that will}} facilitate the carrying out of subsequent activities. That is, information must be stored with a consistent, semantically rich, flexible, and efficient structure that will make it accessible for use by various tools employed in carrying out the development process. In this research, knowledge base management system (KBMS) to manage the information created by the information system development process was designed and implemented. Several contemporary popular knowledge representation schemes can be managed conveniently by this KBMS, which utilized efficient database techniques to facilitate fast retrieval and traversal of the underlying semantic inheritance net and frame knowledge structure. Inference and logic deduction capability was made a part of the static knowledge structure to further extend the functionality of the KBMS. Furthermore, a specially designed relational database management system was implemented and interfaced with the KBMS to alleviate the possibility of a storage saturation problem and to facilitate the storage of detailed exclusive information of terms defined in the knowledge base. Models that are applicable to various information system development activities were identified and stored in the knowledge base. The aggregation of those models is, in fact, a conceptual <b>non-procedural</b> <b>language</b> that provides a concise descriptive framework to help the user gather and manage information derived from various activities during the information system development process. The knowledge base, the language, and several knowledge-base related tools were used by more than seventy graduate students in a case study for a system analysis and design course. An information system methodology specifically tailored for this knowledge base supported environment was proposed and applied in a simplified case to illustrate {{the process of}} how a database-centered information system can be derived from the initial strategic planning phase. The methodology explored and made use of the storage structure of the closely coupled knowledge base and database. Finally, future research direction was identified...|$|E
40|$|The goal of Reverse Software Engineering is the reuse of old {{outdated}} {{programs in}} developing new systems which have an enhanced functionality and employ modern programming languages and new computer architectures. Mere transliteration of programs {{from the source}} language to the object language does not support enhancing the functionality {{and the use of}} newer computer architectures. The main concept in this report is to generate a specification of the source programs in an intermediate nonprocedural, mathematically oriented language. This specification is purely descriptive and independent of the notion of the computer. It may serve as the medium for manually improving reliability and expanding functionally. The modified specification can be translated automatically into optimized object programs in the desired new language and for the new platforms. This report juxtaposes and correlates two classes of computer programming languages: procedural vs. nonprocedural. The nonprocedural languages are also called rule based, equational, functional or assertive. <b>Non-procedural</b> <b>languages</b> are noted for the absence of "side effects " and the freeing of a user from "thinking like a computer " when composing or studying a procedural language program. Nonprocedural languages are therefore advantageous for software development and maintenance. Non procedural languages us...|$|R
40|$|This text {{contains}} {{description of}} the syntax and semantics of the language, MODEL, and techniques for its use. MODEL is a fifth-generation computer language. It is equational and non-procedural. (What these terms mean will be made clear to you as you begin {{to get involved in}} the MODEL system.) In this chapter, we shall discuss the value of the language. MODEL is a tool for systems and program design and development. Like most computer languages, the MODEL system comes with a compiler which is used to receive and analyze the language statements. But as we shall see later on, the whole process of analysis and coding is radically different in the MODEL system from programming methods in current practice. Using today's conventional technology, it is necessary for the analyst to have knowledge of how a computer works internally. Otherwise, the analysis is often unusable by the programmers. To express data processing requirements that are translatable into a procedural language requires knowledge of how a computer executes the solution of the problem <b>Non-procedural</b> <b>languages</b> are problem-oriented and independent of knowledge of how the computer works. MODEL eliminates the need for transfer of information from analyst to programmer. The MODEL system uses the computer to perform program design and coding automatically. In traditional systems design, afte...|$|R
40|$|A data {{dictionary}} {{system with a}} query compiler is implemented in a symbol manipulation language, separate from the underlying database system. The query compiler (or program generator) generates COBOL programs for database access. These programs are optimized at generation time using information from the {{data dictionary}}. The implementation technique {{makes it possible to}} combine pilot implementation with production implementation of database application programs. Furthermore, an example is given of how the architecture of the system is convertible to different underlying database systems. Key concepts: data dictionary, program generator, query language compilation, query <b>language</b> interpretation, <b>non-procedural</b> query <b>language.</b> I...|$|R
5000|$|Though used {{earlier in}} papers and discussions, the term 4GL {{was first used}} {{formally}} by James Martin in his 1981 book Applications Development Without Programmers [...] to refer to <b>non-procedural,</b> high-level specification <b>languages.</b> In some primitive way, early 4GLs {{were included in the}} Informatics MARK-IV (1967) product and Sperry's MAPPER (1969 internal use, 1979 release).|$|R
40|$|Tree pattern {{matching}} {{is an important}} operation in Computer Science on which a number of tasks such as mechanical theorem proving, term-rewriting, symbolic computation and <b>non-procedural</b> programming <b>languages</b> are based on. Work has begun on a systematic approach {{to the construction of}} tree pattern matchers by deterministic pushdown automata which read subject trees in prefix notation. The method is analogous to the construction of string pattern matchers: for given patterns, a non-deterministic pushdown automaton is created and then it is determinised. In this first paper, we present the proposed non-deterministic pushdown automaton which will serve as a basis for the determinisation process, and prove its correctness. ...|$|R
40|$|Two {{complementary}} approaches were investigated. In {{the first}} approach software design techniques {{were used to}} design {{the structure of a}} code generator for Halmat. The major result was the development of an intermediate code form known as 7 UP. The second approach viewed the problem as one in providing a tool to the code generator programmer. The major result was the development of a <b>non-procedural,</b> problem oriented <b>language</b> known as CGGL (Code Generator Generator Language) ...|$|R
40|$|We {{propose a}} {{functional}} query language for databases where both syntax and semantics {{are based on}} conventional mathematics. We argue that database theory should {{not be separated from}} other fields of Computer Science, and that database languages should have the same properties as those of other <b>non-procedural</b> <b>languages.</b> The data are represented in our database as a collection of sets, and the relationships between the data are represented by functions mapping these sets to each other. A database is therefore a many-sorted algebra; i. e. a collection of indexed sets and indexed operations. As in abstract data type specification, we specify the consequences of applying operations to the data without reference to any particular internal structure of the data. A query is simply an expression which is built up from symbols in the signature of the algebra and which complies with the formation rules given by the language. The meaning of a query is the value which is assigned to it by the algebra. There are several ways of extending our language. Twos ways are studied here. The first extension is to allow queries in which sets are defined inductively (i. e. recursively). This mechanism is essential for queries dealing with transitive closures over some interrelated objects. Secondly, since incomplete information is common to many databases, we extend our language to handle partially available data. One main principle guides our extensions: ‘whatever information is added to an incomplete database, subsequent answers to queries must not be less informative than previously’. Finally, we show the correspondence between Varga and methods used in current database software. A subset of Varga, including all features whose implementation is not obvious, is mapped to relational algebra thus showing that our language, though it has been designed with no reference to internal structure, is not incompatible with present database software...|$|R
40|$|This thesis {{addresses}} {{the challenge of}} locating people, resources, and other objects in the global Internet. As the Internet grows beyond a million hosts in {{tens of thousands of}} organizations, it is increasingly difficult to locate any particular object. Hierarchical name services are frustrating, because users must guess the unique names for objects or navigate the name space to find information. Descriptive (i. e. relational) name services offer the promise of simple resource location through a <b>non-procedural</b> query <b>language.</b> Users locate resources by describing resource attributes. This thesis makes the promise of descriptive name services real by providing fast query processing in large internets. The key to speed in descriptive query processing is constraining the search space using two new techniques, called an active catalog and meta-data caching. The active catalog constrains the search space for a query by returning a list of data repositories where the answer to the query is li [...] ...|$|R
40|$|Decision trees {{appeared}} in 50 - 60 s {{of the last}} century in theoretical computer science [14, 64, 80] and applications [24, 37]. Similar objects are also considered by natural and social sciences, for example, taxonomy keys [30] or questionnaires [63]. Decision trees naturally represent identification and testing algorithms that specify the next test to perform {{based on the results of}} the previous tests. A number of particular formulations were generalized by Garey [27] as identification problem that is a problem of distinguishing objects described by a common set of attributes. More general formulation is provided by decision table framework [34, 65] where objects can have incomplete set of attributes and non-unique class labels. In that case, acquiring class label is enough to solve the problem: identifying a particular object is not required. In this context, decision trees found many applications in test theory [39, 45, 46, 81], fault diagnosis [14, 60, 72], rough set theory [61, 62], discrete optimization, <b>non-procedural</b> programming <b>languages</b> [34], analysis of algorithm complexity [38], computer vision [74], computational geometry [69]. © Springer-Verlag Berlin Heidelberg 2011...|$|R
40|$|Object-relational {{database}} applications {{implemented in}} conventional procedural programming languages such as C, C++, and Java {{along with the}} embedded statements expressed in the <b>non-procedural</b> programming <b>languages</b> such as OQL, SQL and XQuery. Therefore, using transformation rules to optimise these applications by balancing the data processing load between the client and the server sides is required. Refactoring object-oriented applications, {{is one way to}} preserve output of the application but apply changes on design level. Implementation of object-relational applications with a large amount of procedural code, remains the majority of the data-processing to the client side. This often has catastrophic consequences for the performance of the application. Transformation rules need to be applied in an efficient way to come up with optimised applications. This research evaluates whether using transformation rules can be consider as a refactoring technology which can transfer the non-optimise object-relational application to the optimise ones. A systematic experimental study was conducted by incorporating transformation rules to monitor the number of Blocks-Read operations before and after applying the rules. It was concluded that as rules applied in an efficient way, the performance of applications increased. Also the efficient way of applying the rules is proposed...|$|R
40|$|The goal of Reverse Software Engineering is the reuse of old {{outdated}} {{programs in}} developing new systems which have an enhanced functionality and employ modern programming languages and new computer architectures. Mere transliteration of programs {{from the source}} language to the object language does not support enhancing the functionality {{and the use of}} newer computer architectures. The main concept in this report is to generate a specification of the source programs in an intermediate nonprocedural, mathematically oriented language. This specification is purely descriptive and independent of the notion of the computer. It may serve as the medium for manually improving reliability and expanding functionally. The modified specification can be translated automatically into optimized object programs in the desired new language and for the new platforms. This report juxtaposes and correlates two classes of computer programming languages: procedural vs. nonprocedural. The nonprocedural languages are also called rule based, equational, functional or assertive. <b>Non-procedural</b> <b>languages</b> are noted for the absence of 2 ̆ 2 side effects 2 ̆ 2 and the freeing of a user from 2 ̆ 2 thinking like a computer 2 ̆ 2 when composing or studying a procedural language program. Nonprocedural languages are therefore advantageous for software development and maintenance. Non procedural languages use mathematical semantics and therefore are more suitable for analysis of the correctness and for improving the reliability of software. The difference in semantics between the two classes of languages centers on the meaning of variables. In a procedural language a variable may be assigned multiple values, while in a nonprocedural language a variable may assume one and only one value. The latter is the same convention as used in mathematics. The translation algorithm presented in this report consists of renaming variables and expanding the logic and control in the procedural program until each variable is assigned one and only one value. The translation into equations can then be performed directly. The source program and object specification are equivalent in that there is a one to one equality of values of respective variables. The specification that results from these transformations is then further simplified to make it easy to learn and understand it when performing maintenance. The presentation of translation algorithms in this report utilizes FORTRAN as the source language and MODEL as the object language. MODEL is an equational language, where rules are expressed as algebraic equations. MODEL has an effective translation into the object procedural languages PL/ 1, C and Ada...|$|R
40|$|This text {{contains}} {{description of}} the syntax and semantics of the language, MODEL, and techniques for its use. MODEL is a fifth-generation computer language. It is equational and non-procedural. (What these terms mean will be made clear to you as you begin {{to get involved in}} the MODEL system.) In this chapter, we shall discuss the value of the language. MODEL is a tool for systems and program design and development. Like most computer languages, the MODEL system comes with a compiler which is used to receive and analyze the language statements. But as we shall see later on, the whole process of analysis and coding is radically different in the MODEL system from programming methods in current practice. Using today 2 ̆ 7 s conventional technology, it is necessary for the analyst to have knowledge of how a computer works internally. Otherwise, the analysis is often unusable by the programmers. To express data processing requirements that are translatable into a procedural language requires knowledge of how a computer executes the solution of the problem <b>Non-procedural</b> <b>languages</b> are problem-oriented and independent of knowledge of how the computer works. MODEL eliminates the need for transfer of information from analyst to programmer. The MODEL system uses the computer to perform program design and coding automatically. In traditional systems design, after the requirements and analysis phases are completed, the programming task begins. Specifications are given to programmers who fmt perform the program 2 ̆ 6 sign and then write and debug the programs. In MODEL, once a specification is completed, the 2 ̆ 2 programming 2 ̆ 2 task is also done as a byproduct The specification itself is entered into the computer; submitted to the MODEL compiler. A PL/I program is generated, as well as a series of reports about the newly generated program. MODEL has facilities for automating all program development phases: design, coding and testing. It reduces the analyst 2 ̆ 7 s involvement with computer execution through having the compiler interface with the computer and its environment. The analyst writes a specification which is entered into the computer. The specification is transformed into a PL/I program by the MODEL compiler. As soon as the specification is completed the system is ready for testing. In short, MODEL is an outgrowth of a widespread need to make programming more natural and more accessible to non-programmers. Welcome to the realm of non-procedurality. You are going to learn a new methodology for systems analysis. It will help you to complete complex projects and enable you to conceptualize problems in a clear, precise manner, without having to at the same time worry about its implementation in a computer...|$|R
40|$|Viable {{articulated}} computer-graphic {{representations of}} the human figure have recently been developed by O'Rourke, Zeltzer, and others. In this work, a figure implemented by Maxwell provides {{the starting point for}} the development of tools for controlling the movement and action of figures in a simulated three-dimensional environment. The figures representational quality is improved for the purpose of animation, and its capabilities are extended to allow multiple figures to follow arbitrary paths, with posture and movement determined by any combination of key-frames, body-tracking, and algorithmic movement description. Objects in the figure's visual environment arc designed using a program for computer graphic sculpture. A sophisticated computer sound synthesis system was implemented and provided the basis for a script-driven multiprocess approach to specifying the interaction s of multiple figures in a changing environment The resulting system, incorporating figures in an animated visual environment with coordinated sound, may be considered as a vehicle for realizing "electronic cinema". While the animation scripts essentially define a specialized <b>non-procedural</b> programming <b>language,</b> knowledge of a general (procedural) computer language is not required, and figure animations have been realized by artists and filmmakers having no previous background in three-dimensional computer graphics. by John Peter Lewis. Thesis (M. S. V. S.) [...] Massachusetts Institute of Technology, Dept. of Architecture, 1984. MICROFICHE COPY AVAILABLE IN ARCHIVES AND ROTCH. Includes bibliographical references (leaves 82 - 90) ...|$|R
40|$|This {{dissertation}} introduces 2 ̆ 2 open predicate path expressions 2 ̆ 2 [...] a <b>non-procedural,</b> very-high-level <b>language</b> notation for the synchronization of concurrent accesses to {{shared data}} in distributed computer systems. The target environment {{is one in}} which 2 ̆ 2 resource modules 2 ̆ 2 (totally encapsulated instances of abstract data types) are the basic building blocks in a network of conventional, von Neumann computers or of functional, highly parallel machines. Each resource module will contain two independent submodules: a synchronization submodule which coordinates requests for access to the resource 2 ̆ 7 s data and an access-mechanism submodule which localizes the code for operations on that data;Open predicate path expressions are proposed as a specification language for the synchronization submodule and represent a blend of two existing path notations: open path expressions and predicate path expressions. Motivations for the adoption of this new notation are presented, and an implementation semantics for the notation is presented in the form of dataflow graphs;An algorithm is presented which will automatically synthesize an open predicate path expression into a dataflow graph, which is then implemented by a network of communicating submodules written in either a sequential or an applicative language. Finally, an extended notation for the synchronization submodule is proposed, the purpose of which is to provide greater expressive power for certain synchronization problems which are difficult to specify using path expressions alone...|$|R
40|$|This {{document}} {{describes the}} algorithms and mechanisms of the MODEL Processor, {{which is a}} software system performing a program writing function. It also documents the program structure and procedures of the Processor. The MODEL Processor {{has been designed to}} automate the program design, coding and debugging of software development, based on a non-procedural specifications of a program module in the MODEL language. A program module is formally described and specified in the MODEL language, whose statements are then submitted to the Processor. The set of MODEL statements describing a program module is referred to as a specification. The Processor, performs the analysis (including checking for the completeness and consistency of the entire specification), program module design (including generating a flowchart-like sequence of events for the module), and code generation functions, thus replacing the tasks of an application programmer/coder. The Processor 2 ̆ 7 s capability to process a <b>non-procedural</b> specification <b>language</b> is built on application of graph theory to the analysis of such specification and to the program generation task. Another important function of the Processor is to interact with the specifier to indicate necessary supplements or changes to the submitted statements. The Processor produces a complete PL/ 1 program ready for compilation as well as various reports concerning the specification and the generated program. The Processor output reports include a listing of the specification, a cross-reference report, subscript range report, a flowchart-like report of the generated program, and a listing of the generated program...|$|R
40|$|Modern {{computer}} science has developed languages along many distinct paths; three are: Operating System Languages (e. g., OS/JCL), High Level Procedural Languages (e. g., FORTRAN), and High Level <b>Non-Procedural</b> Data Base <b>Languages</b> (e. g., ALPHA, SQUARE, GPLAN). The purpose {{of each of}} these is to solve a particular problem, namely, to simplify the work of the programmer, so that a majority of his time could be spent on his own application. The development of data manipulation procedures has also proceeded independently; of programming languages only in the programming language LISP are data and program expressed in a common manner. We feel {{that the time has come}} for a new approach to computer language evolution, especially for business oriented users. The combination of data, programs, and operating system into a single language would make a great simplification of the current state of affairs. The BL/I language is presented as a prototype for a data base oriented computer system, combining features from operating systems, programming languages, and data base languages...|$|R
