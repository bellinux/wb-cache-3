28|2650|Public
50|$|The R225 was a discless {{version of}} the R260. It {{required}} a <b>network</b> <b>file</b> <b>server</b> or an R260 to boot.|$|E
50|$|Other notable {{features}} include compression of disk image files, support for backup/restore from a <b>network</b> <b>file</b> <b>server</b> and data encryption.|$|E
50|$|Neiman was {{a system}} {{architect}} at Maxitron Corporation in Marin County during the mid-1980s, and then Vice President of Product Development at Dahlgren Control Systems in San Francisco. In 1988 he became Vice President of Product Development for the TOPS Division of Sun Microsystems, that was developing the TOPS <b>network</b> <b>file</b> <b>server</b> system.|$|E
40|$|Network storage {{architecture}} separates bit movementfrom control processing. In this architecture, traditional <b>network</b> <b>file</b> <b>servers</b> now mainly {{support the}} functionsof name translation, access control, and relaying the bits between network storage servers and clients. Be-cause {{most of the}} bits exchanged between clients and network storage servers pass through the network fileservers without additional interpretation, in theory the <b>file</b> <b>servers</b> {{should be able to}} relay them without incur-ring additional data copying overheads, just like normal IP routers. In practice, however, this is rarely the case...|$|R
40|$|Protocols {{like the}} Direct Access File System (DAFS) {{leverage}} user-level memory-mapped communication to enable low overhead access to network-attached storage for applications. DAFS offers {{significant improvement in}} application performance using features like direct data transfer and RDMA. Our goal is to build high performance <b>network</b> <b>file</b> <b>servers</b> using DAFS. The benefits of the DAFS protocol can be extended to cluster-based servers, using low overhead user-level communication within the cluster...|$|R
5000|$|The term [...] "server" [...] {{highlights}} {{the role of}} the virtual machine in the client-server scheme, where the clients are the applications accessing the storage. The <b>file</b> <b>server</b> usually does not run application programs on behalf of the clients. It enables storage and retrieval of data, where the computation is provided by the client. With a storage area network (SAN), the server(s) act purely as virtual storage devices, with a client maintaining the file system. With network-attached storage (NAS), the <b>server(s)</b> manage the <b>file</b> system. Both SAN and NAS servers may be virtualized so the users do not have to know which physical devices is hosting the files. A virtual <b>file</b> <b>server</b> typically combines the security of virtual private <b>networks</b> (VPN) with <b>file</b> synchronization, distribution and sharing services of <b>network</b> <b>file</b> <b>servers.</b>|$|R
50|$|In 1994, {{he earned}} the Ralph Budd Award {{for the best}} Ph.D. thesis in Engineering from Rice University. For 3 years, he was holder of IBM {{graduate}} fellowship while {{a graduate student at}} Rice. Mootaz won a Research Division Award at IBM T.J. Watson Research Center (1992) for his contributions to the Highly Available <b>Network</b> <b>File</b> <b>Server</b> (HANFS) Project.|$|E
5000|$|Ingex is an {{open-source}} (GPL) {{suite of}} {{software for the}} digital capture of audio and video data, developed and heavily used by the BBC. SDI capture is supported, as well as real-time transcoding (with MXF). Portions of the suite also act as a <b>network</b> <b>file</b> <b>server</b> for media files, as well as archiving to LTO-3 data tape.|$|E
50|$|Disk imaging {{applications}} enable bare-metal restores by storing copies (images) of {{the entire}} contents of hard disks to networked or other external storage, and then writing those images to other physical disks. The disk image application itself can include an entire operating system, bootable from a live CD or <b>network</b> <b>file</b> <b>server,</b> which contains all the required application code to create and restore the disk images.|$|E
40|$|A {{menu driven}} Urinalysis Result Reporting System based on {{multiple}} IBM-PC Workstations connected {{together by a}} local area network was developed for the Clinical Chemistry Section of the Clinical Pathology Department at the National Institutes of Health's Clinical Center. Two <b>Network</b> <b>File</b> <b>Servers</b> redundantly save the test results of each urine specimen. When all test results for a specimen are entered into the system, the results are transmitted to the Department's Laboratory Computer System where they are {{made available to the}} ordering physician. The Urinalysis Data Management System has proven easy to learn and use...|$|R
40|$|One of {{the unique}} {{features}} that distinguishes digital multimedia from traditional computer data {{is the presence of}} multiple media streams, whose display must proceed in a mutually synchronized manner. The design of techniques for synchronization of multimedia data at the time of storage, and retrieval from <b>network</b> <b>file</b> <b>servers</b> is the subject matter of this paper. We present algorithms by which a <b>file</b> <b>server</b> can create a relative time system and synchronize media units transmitted by different sources on a network to construct a multimedia object. These algorithms stay robust in the absence of global clocks, presence of transmission jitter and generation rate mismatches. We develop a feedback technique using which the <b>file</b> <b>server</b> can detect asynchronies in display devices during retrieval of multimedia objects, and even restore synchrony by deleting or duplicating media units destined for asynchronous destinations. We then present strategies by which the <b>file</b> <b>server</b> can actually predict [...] ...|$|R
40|$|Network {{attached}} storage (NAS) is both used by {{and is an}} application of massively parallel computing. The increasing scale of networked storage has exposed issues such as data integrity and access latency to distributed data and computation. One of the approaches to reduce the wasted network bandwidth is, following the classic localityof-data principle, to partition interrelated data objects between networked storage nodes. The paper describes an algorithm for data clustering based on the relative interconnectivity between data objects. Because of its simplicity, the method could be incorporated in network attached hard disk storage with all range of complexity from embedded controllers to complex <b>network</b> <b>file</b> <b>servers.</b> 1...|$|R
50|$|The LINK 480Z {{supported}} a proprietary 800 kbit/s CHAIN {{local area network}} that ran over a coaxial cable {{in a similar manner}} to 10BASE2 Ethernet. Each station on the network required a unique, 8-bit network address that was set by means of a DIP switch on the rear of the unit. Using the built-in Z-Net firmware a diskless 480Z could be directly booted from a <b>network</b> <b>file</b> <b>server</b> (typically a Research Machines 380Z).|$|E
50|$|A {{definitive}} {{software library}} (DSL) is a secure location, consisting of physical media or a software repository {{located on a}} <b>network</b> <b>file</b> <b>server,</b> in which the definitive authorized versions of all software configuration items (CIs) are stored and protected. The DSL is separate from development, quality assurance or production software storage areas. It contains master copies of all controlled software and includes definitive copies of purchased software, as well as licensing information for software developed on-site or purchased from an external vendor. All related documentation, related to any software stored in the DSL, is also stored in the DSL.|$|E
5000|$|Ingex is an {{open-source}} (GPL) {{suite of}} {{software for the}} digital capture of audio and video data, {{without the need for}} traditional audio or video tape or cassettes. [...] Serial digital interface (SDI) capture is supported, as well as real-time transcoding (with MXF). [...] Portions of the software suite also act as a <b>network</b> <b>file</b> <b>server</b> for media files, as well as archiving to LTO-3 data tape. [...] Audio and video media files can also be stored on USB hard drives or Network Attached Storage. [...] The software is heavily used by the BBC, and was developed by the BBC Research Laboratory.|$|E
40|$|The Department of Veterans Affairs (VA) DHCP Imaging System {{digitally}} records {{clinically significant}} diagnostic images selected by medical specialists {{in a variety}} of hospital departments, including radiology, cardiology, gastroenterology, pathology, dermatology, hematology, surgery, podiatry, dental clinic, and emergency room. These images, which include true color and gray scale images, scanned documents, and electrocardiogram waveforms, are stored on <b>network</b> <b>file</b> <b>servers</b> and displayed on workstations located throughout a medical center. All images are managed by the VA's hospital information system (HIS), allowing integrated displays of text and image data from all medical specialties. Two VA medical centers currently have DHCP Imaging Systems installed, and other installations are underway...|$|R
40|$|The paper {{describes}} {{a set of}} patterns that extend the pattern language proposed in [Meszaros 96] for improving the capacity of reactive systems. The intent of these patterns is to identify some specific causes that limit the efficiency of a distributed layered client-server system with multi-threaded servers, and to find appropriate corrective measures. The type of systems considered here is a subclass of the larger category of reactive systems, and the new patterns are dealing with their specific performance characteristics. The effects of the patterns are illustrated with performance measurements conducted on a layered client-server system. INTRODUCTION Problem Domain Many distributed applications {{are based on the}} client-sever paradigm and use various kinds of software servers (as for example, name <b>servers,</b> databases, <b>network</b> <b>file</b> <b>servers,</b> web servers, etc.) The performance of such systems depends strongly not only on the contention and queueing delays for hardware devices (such as [...] ...|$|R
40|$|Abstract—Output of <b>network</b> <b>file</b> <b>servers</b> {{exhibits}} {{bursty traffic}} patterns, and this sometimes contends with control traffic. An example is contention between data traffic and write acknowl-edgments on a loaded server. In such a situation, {{we can improve}} the write performance by prioritizing write acknowledgments at the network interface of the server. To validate this scheme, we conducted an empirical study of the prioritization of write acknowledgments. Systematic experiments revealed that the pro-posed scheme can improve write latency and throughput of loaded servers without influencing read performance. The results suggested that the technique is widely applicable to systems where transactions are a mixture of read and write requests, and especially if the degree of concurrency is high. I...|$|R
50|$|Nevertheless, {{none of the}} {{software}} available represented a unified solution fully supported by Apple. Following the early removal of the Macintosh XL, Apple finally delivered its first hard drive for the Macintosh. Nine months after announcing it, the Hard Disk 20 was a mere 20MB hard drive. Though a welcome addition, it was slow and delivered none of {{the promise of a}} <b>network</b> <b>file</b> <b>server.</b> Though third party products made good use of it, Apple would not offer another installment of the poorly implemented Macintosh Office for well over a year. Instead Apple canceled the UNIX-based Big Mac file-server concept and chose to focus on the next generation Macintosh II.|$|E
50|$|This {{split in}} duties led to one very real {{performance}} improvement. Since programs could share the memory objects, and microkernel systems like Spring {{are based on}} the idea of copying memory around, Spring allowed programs sharing memory in this fashion to share it in the VM system as well. Thus under Mach if a <b>network</b> <b>file</b> <b>server</b> is handing data to a program both programs will end up using up memory in the VM system, whereas under Spring the two would naturally share the same memory objects, as the pager implementing that memory object would simply return another handle to the same memory. Only inside the VM would they be considered different objects, and would be handled by separate cache managers. Therefore, the data would only be cached in RAM once. In theory this could lead to considerably better real-world RAM usage.|$|E
5000|$|The RM Nimbus AX and VX {{models were}} {{launched}} in 1986 {{and used the}} 80286 (later the 80386) processor. They were fully IBM compatible, as were all subsequent RM computers. The AX and VX were offered {{for use as a}} <b>network</b> <b>file</b> <b>server</b> or as a high-end workstation. They employed either EGA or VGA graphics cards, and were equipped with an ESDI interface for a hard drive, as well as a 3 1/2" [...] floppy drive. By default they were equipped with a Zilog Z-Net interface card, but a second Ethernet card could be added alongside to allow both network interfaces to be used simultaneously, however, the two network interfaces were not able to be bridged. Expansion cards could be added to standard 8-bit and 16-bit ISA sockets, which were both on the motherboard, and on an attached expansion board which was supplied as standard.|$|E
50|$|Scality {{released}} version 4.2 in October 2013 which added native {{file access}} protocols including <b>Network</b> <b>File</b> System (NFS), <b>Server</b> Message Block (SMB), Apple Filing Protocol (AFP), and FTP.|$|R
5000|$|The {{first set}} of {{concerns}} were rendered moot when the specifications were introduced in March 1983 in the [...] "Functional Requirements for Microcomputers for Educational Use in Ontario Schools--Stage I." [...] The physical design required a PET-like all-in-one case, headphones output for voice and sound effects, and a trackball for mouse-like pointing support. Inside the case, the specification called for a processor and support systems to allow a multitasking operating system to be used, selecting the Intel 80186 as the CPU. Color graphics were specified, at least as an option, along with monochrome and color monitors on top. Voice synthesis was built in, and the keyboard provided for accented characters. Additionally, the systems would include no local storage at all, and would instead rely on a <b>networked</b> <b>file</b> <b>server</b> containing a hard drive.|$|R
40|$|If {{you are a}} {{developer}} with BeagleBone experience and want {{to learn how to}} use it to set up a <b>network</b> and <b>file</b> <b>server,</b> then this book is ideal for you. To make the most of this book, you should be comfortable with the Linux operating system and know how to install software from the Internet, but you do not have to be a network guru...|$|R
5000|$|NetWare 286 2.x {{normally}} {{required a}} dedicated PC {{to act as}} the server, where the server used DOS only as a boot loader to execute the operating system file net$os.exe. All memory was allocated to NetWare; no DOS ran on the server. However, a [...] "non-dedicated" [...] version was also available for price-conscious customers. In this, DOS 3.3 or higher would remain in memory, and the processor would time-slice between the DOS and NetWare programs, allowing the server computer to be used simultaneously as a <b>network</b> <b>file</b> <b>server</b> and as a user workstation. Because all extended memory (RAM above 1 MB) was allocated to NetWare, DOS was limited to only 640 KB; expanded memory managers that used the MMU of 80386 and higher processors, such as EMM386, would not work; 8086-style expanded memory on dedicated plug-in cards was possible however. Time slicing was accomplished using the keyboard interrupt, which required strict compliance with the IBM PC design model, otherwise performance was affected.|$|E
40|$|This paper {{presents}} {{the design and}} implementation of a Highly Available <b>Network</b> <b>File</b> <b>Server</b> (HA-NFS). We separate the problem of <b>network</b> <b>file</b> <b>server</b> reliability into three different subproblems: server reliability, disk reliability, and network reliability. HA-NFS offers a different solution for each: dual-ported disks and impersonation are used to provide server reliability, disk mirroring {{can be used to}} provide disk reliability, and optional network replication can be used to provide network reliability. The implementation shows that HA-NFS provides high availability without the excessive resource overhead or the performance degradation that characterize traditional replication methods. Ongoing operations are not aborted during fail-over and recovery is completely transparent to applications. HA-NFS adheres to the NFS protocol standard and can be used by existing NFS clients without modification. 1 Introduction Traditional approaches for providing reliability in network file systems [...] ...|$|E
40|$|Distributed {{systems in}} use today depend heavily on network {{communications}} between clients and servers. In this report, we describe the design {{and implementation of the}} network architecture (hardware, software and protocols) of the RAID-II system. RAID-II is a high speed <b>network</b> <b>file</b> <b>server</b> connected to an UltraNetwork. In order to support high bandwidth network transfers with the RAID-II server, we partitioned the networking software among the various processors in the system. Measurements of the system show that the RAID-II server can sustain 21 MB/ s of data bandwidth to the Ultranet...|$|E
5000|$|In large {{enterprise}} <b>networks,</b> a centralized <b>file</b> <b>server</b> or print server, sometimes denoted client-server paradigm, is typically used. A client process {{on the local}} user computer takes the initiative to start the communication, while a server process on the <b>file</b> <b>server</b> or print server remote computer passively waits for requests to start a communication session ...|$|R
40|$|DAFS) {{leverage}} user-level memory-mapped {{communication to}} enable low overhead access to network-attached storage for applications. DAFS offers {{significant improvement in}} application performance using features like direct data transfer and RDMA. Our goal is to build high performance <b>network</b> <b>file</b> <b>servers</b> using DAFS. The benefits of the DAFS protocol can be extended to cluster-based servers, using low overhead user-level communication within the cluster. In this paper, we present Federated DAFS, a scalable and efficient cluster-based direct access <b>file</b> <b>server.</b> Federated DAFS combines an efficient user-space DAFS implementation with a low overhead clustering layer to present a scalable clustering solution for DAFS servers. Federated DAFS uses a portable mechanism for distribution and handling of client requests across the servers in the cluster. Federated DAFS also minimizes the intra-cluster communication by caching data blocks and by matching the file placement on the servers with the distribution of requests from the clients. Our results show that reasonable speedups(2. 6 on four nodes and 4. 5 on eight nodes) can be achieved using Federated DAFS on server clusters of up to eight nodes. I...|$|R
40|$|An {{integrated}} {{controlling system}} based on the unified database newly designed, is developed and realized for high-throughput protein crystallography experiments on synchrotron beam lines. Main features of protein crystallography experiments (purification, crystallization, loop preparation, data collecting, data processing) are dealt with the software. All information necessary to perform protein crystallography experiments is stored (except raw data, that are stored in a <b>Network</b> <b>file</b> <b>servers)</b> in a relational database (MySQL). The control system consists of several local servers and clients connected through network [1, 2]. All communications are performed through TCP/IP sockets. Secure network connections such as OpenSSL, an open-source implementation of the SSL (Secure Sockets Layer) and TLS (Transport Layer Security) protocols are used wherever secure server-client communication is needed. Secure remote access to the system is possible from any operating system with X-terminal and SSH/X 11 (Secure Shell with graphical user interface) support...|$|R
40|$|Data {{is useless}} {{unless you have}} a means of storing and {{accessing}} that data. Network Attached Storage (NAS) utilizing Network File System (NFS) {{is one of the main}} ways of storing data on a server and having it accessible from other servers and computers. In the process of building the system, the administrator needs to setup the server to work in tandem with other servers on the network. This is our experience in setting up a <b>network</b> <b>file</b> <b>server</b> on the Computer Science network at Northwest Nazarene University...|$|E
40|$|One of {{the first}} steps in star ting a program on a clus ter {{is to get the}} execu t able, which {{generally}} resides on some <b>network</b> <b>file</b> <b>server.</b> This creates not only conten t i on on the network, but causes unnecessary strain on the network file system as well, which is busy serving other reques t s at the same time. This approach is certainly not scalable as clusters grow larger. We presen t a new approach tha t uses a high speed interconnec t, novel network features, and a scalable design. We provide a fast, efficient, and scalable solution to the distribu t i on of executab le files on produc tion parallel machines...|$|E
40|$|RAID-II is a high-bandwidth, networkattached storage server {{designed}} and implemented at the University of California at Berkeley. In this paper, we measure {{the performance of}} RAID-II and evaluate various architectural decisions made during the design process. We first measure the end-to-end performance of the system to be approximately 20 MB/s for both disk array reads and writes. We then perform a bottleneck analysis by examining the performance of each individual subsystem and conclude that the disk subsystem limits performance. By adding a custom interconnect board with a high-speed memory and bus system and parity engine, {{we are able to}} achieve a performance speedup of 8 to 15 over a comparative system using only off-theshelf hardware. 1 Introduction RAID-II is a high-bandwidth, <b>network</b> <b>file</b> <b>server</b> {{designed and}} implemented at the University of California at Berkeley as part of a project to study high-performance, large-capacity, highly-reliable storage systems. RAID-II is desig [...] ...|$|E
40|$|Tiger Shark is a {{parallel}} file system for IBM's AIX operating system. It {{is designed to}} support interactive multimedia, particularly large-scale systems such as interactive television (ITV). Tiger Shark scales across the entire RS/ 6000 product line, from small desktop machines to the SP 2 parallel supercomputer. Tiger Shark's primary features are support for continuoustime data, scalability, high availability, and manageability, {{all of which are}} crucial in its role in large-scale video servers. Interestingly, most of the features that make Tiger Shark a good video server are important for other largescale applications such as technical computing, data mining, digital library, and scalable <b>network</b> <b>file</b> <b>servers.</b> This paper briefly describes Tiger Shark: the environment that makes it important, the key technology it embodies, and the efforts to build products based on it. Introduction Over the past several years, radical changes have occurred in the underlying technology of computing and [...] ...|$|R
40|$|Tiger Shark is a scalable, {{parallel}} {{file system}} designed to support interactive multimedia applications, particularly large-scale ones such as interactive television (ITV). Tiger Shark runs under the IBM AIX operating system, on machines ranging from RS/ 6000 desktop workstations to the SP 2 parallel supercomputer. In addition to supporting continuous-time data, Tiger Shark provides scalability, high availability, and on-line system management, {{all of which are}} crucial in large-scale video servers. These latter features also enable Tiger Shark to support non-multimedia applications such as scientific computing, data mining, digital library, and scalable <b>network</b> <b>file</b> <b>servers.</b> Tiger Shark has been employed in a number of customer ITV trials. Based on experience obtained from these trials, Tiger Shark has recently been released in several IBM video server products. This paper describes the architecture and implementation of Tiger Shark, discusses the experience gained from trials, and compa [...] ...|$|R
25|$|Because of {{the nature}} of the HTPC, higher than average {{capacities}} are required for HTPC units to allow storage of pictures, music, television shows, videos, and other multimedia. Designed almost as a 'permanent storage' device, space can quickly run out on these devices. Because of restrictions on internal space for hard disk drives and a desire for low noise levels, many HTPC units utilize a NAS (Network Attached Storage) device, or another type of <b>network</b> connected <b>file</b> <b>server.</b>|$|R
