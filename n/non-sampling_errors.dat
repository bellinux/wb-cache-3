58|42|Public
2500|$|<b>Non-sampling</b> <b>errors</b> {{are other}} errors which can impact the final survey estimates, caused by {{problems}} in data collection, processing, or sample design. They include: ...|$|E
2500|$|Survey {{results are}} {{typically}} subject to some error. Total errors {{can be classified}} into sampling errors and <b>non-sampling</b> <b>errors.</b> The term [...] "error" [...] here includes systematic biases as well as random errors.|$|E
5000|$|<b>Non-sampling</b> <b>errors</b> {{are other}} errors which can impact the final survey estimates, caused by {{problems}} in data collection, processing, or sample design. They include: ...|$|E
40|$|It will be {{discussed}} if the confidence in {{the results of the}} production of economic and social data will be justified. Probability based conclusions are possible concerning the sampling error. In order to quantify the <b>non-sampling</b> <b>error</b> an accuracy check is necessary which causes practical problems. Therefore special methods are applied to reduce the errors in surveys before the results are published. The confidence in statistics on this level depends on the collaboration of the official statistics with the applied statistical science. Sampling <b>error,</b> <b>non-sampling</b> <b>error,</b> error reducing measures...|$|R
5000|$|The term [...] "observational error" [...] is also {{sometimes}} {{used to refer}} to response errors and some other types of <b>non-sampling</b> <b>error.</b> In survey-type situations, these errors can be mistakes in the collection of data, including both the incorrect recording of a response and the correct recording of a respondent's inaccurate response. These sources of <b>non-sampling</b> <b>error</b> are discussed in Salant and Dillman (1995) and Bland and Altman (1996).|$|R
40|$|In {{this paper}} we {{introduce}} the particular {{issues involved in}} analysing the 2002 NATSISS. We discuss a number of aspects of the survey methodology including the scope, sample design and interviewing techniques. We {{pay particular attention to}} the different survey methodology used in Community Areas and Non Community Areas and the implications for analysis of the data, particularly that which uses the Confidentialised Unit Record File. A number of issues to do with sampling and <b>non-sampling</b> <b>error</b> are outlined, including how users can take into account sampling and <b>non-sampling</b> <b>error</b> when making conclusions. In particular, we give three examples of potential <b>non-sampling</b> <b>error</b> that show how users {{need to be aware of}} questionnaire design, interviewing techniques and imputation strategy when using the NATSISS. 1...|$|R
5000|$|Survey {{results are}} {{typically}} subject to some error. Total errors {{can be classified}} into sampling errors and <b>non-sampling</b> <b>errors.</b> The term [...] "error" [...] here includes systematic biases as well as random errors.|$|E
50|$|In statistics, {{non-sampling error}} is a {{catch-all}} {{term for the}} deviations of estimates from their true values that are not {{a function of the}} sample chosen, including various systematic errors and random errors that are not due to sampling. <b>Non-sampling</b> <b>errors</b> are much harder to quantify than sampling errors.|$|E
50|$|Sampling error can be {{contrasted with}} non-sampling error. Non-sampling error is a {{catch-all}} {{term for the}} deviations from the true value that are not {{a function of the}} sample chosen, including various systematic errors and any random errors that are not due to sampling. <b>Non-sampling</b> <b>errors</b> are much harder to quantify than sampling error.|$|E
5000|$|An {{excellent}} {{discussion of}} issues pertaining to <b>non-sampling</b> <b>error</b> {{can be found}} in several sources such as Kalton (1983) and Salant and Dillman (1995), ...|$|R
40|$|This paper {{focuses on}} the {{statistical}} aspects of a census. It addresses {{issues such as the}} coverage, classification, sampling, <b>non-sampling</b> <b>error,</b> post collection processing, weighting and disclosure avoidance. The intent of the paper is to demonstrate that most (if not all) of the statistical issues that are important in conducting a survey are equally germane to conducting a census...|$|R
40|$|The {{use of the}} {{internet}} as a method to conduct survey research has expanded rapidly over the past decade. High speeds of response and lower expenses have driven this rapid growth. Relatively low response rates, however, suggest online surveys may be compromised by high levels of <b>non-sampling</b> <b>error.</b> This paper examines a major component of <b>non-sampling</b> <b>error</b> and the consequences that may be associated with internet survey non-response. Known population parameters are compared to point estimates from a census as well as a random sample of non-respondents in order to provide insight on the magnitude and direction of non- response error. Issue salience and response latency are found to exhibit a significant relationship to self-selection and response valance biases. Specifically, lower rates of non- response were obtained from respondents who perceived the topic of the survey as more important and patterns of response were more favorable among initial study participants...|$|R
50|$|During {{his time}} at the Census Bureau, Hansen made {{contributions}} to the {{theory and practice of}} sampling, as well as to <b>non-sampling</b> <b>errors.</b> In 1947 he was elected as a Fellow of the American Statistical Association. He also served as President of the Institute of Mathematical Statistics in 1953 and President of the American Statistical Association in 1960.|$|E
50|$|CHFS {{developed}} a proprietary interview system and management platform for both face-to-face interviews and for telephone interviews. This integrated system provides a full package for each computer-based household interview. The Computer-assisted personal interviewing (CAPI) system effectively decreases potential man-made <b>non-sampling</b> <b>errors</b> by presetting {{the range of}} possible answers, catching typing errors, and avoiding general human errors (such as skipping questions). The system ensures the confidentiality of the data and ensures real-time accessibility, significantly improving data quality.|$|E
50|$|Both the Diary and Interview Surveys utilize a {{representative}} sample to measure the buying habits of Americans. Only {{a small percentage of}} the US population is being surveyed, and therefore the data are subject to sampling errors. The division publishes standard error tables on their website. <b>Non-sampling</b> <b>errors</b> include, but are not limited to, respondents who are either unwilling or unable to provide accurate answers, mistakes made in collecting or recording obtained data, and estimation of missing data.|$|E
40|$|Nationally {{representative}} household {{surveys are}} increasingly relied upon to measure maternal, newborn, {{and child health}} (MNCH) intervention coverage at the population level in low- and middle-income countries. Surveys are the best tool we have for this purpose and are central to national and global decision making. However, all survey point estimates have {{a certain level of}} error (total survey error) comprising sampling and <b>non-sampling</b> <b>error,</b> both of which must be considered when interpreting survey results for decision making. In this review, we discuss the importance of considering these errors when interpreting MNCH intervention coverage estimates derived from household surveys, using relevant examples from national surveys to provide context. Sampling error is usually thought of as the precision of a point estimate and is represented by 95 % confidence intervals, which are measurable. Confidence intervals can inform judgments about whether estimated parameters are likely to be different from the real value of a parameter. We recommend, therefore, that confidence intervals for key coverage indicators should always be provided in survey reports. By contrast, the direction and magnitude of <b>non-sampling</b> <b>error</b> is almost always unmeasurable, and therefore unknown. Information error and bias are the most common sources of <b>non-sampling</b> <b>error</b> in household survey estimates and we recommend that they should always be carefully considered when interpreting MNCH intervention coverage based on survey data. Overall, we recommend that future research on measuring MNCH intervention coverage should focus on refining and improving survey-based coverage estimates to develop {{a better understanding of how}} results should be interpreted and used...|$|R
5000|$|In {{business}} research, {{companies must}} often generate samples of customers, clients, employees, {{and so forth}} to gather their opinions. Sample design is also {{a critical component of}} marketing research and employee research for many organizations. During sample design, firms must answer questions such as:- What is the relevant population, sampling frame, and sampling unit?- What is the appropriate margin of error that should be achieved?- How should sampling <b>error</b> and <b>non-sampling</b> <b>error</b> be assessed and balanced? ...|$|R
25|$|If {{the exact}} {{confidence}} intervals are used, then {{the margin of}} error takes into account both sampling <b>error</b> and <b>non-sampling</b> <b>error.</b> If an approximate confidence interval is used (for example, by assuming the distribution is normal and then modeling the confidence interval accordingly), then {{the margin of error}} may only take random sampling error into account. It does not represent other potential sources of error or bias such as a non-representative sample-design, poorly phrased questions, people lying or refusing to respond, the exclusion of people who could not be contacted, or miscounts and miscalculations.|$|R
40|$|Data from {{interview}} {{surveys of}} households or health facilities {{are used to}} assess community parameters such as health status and factors related to the ability and willingness of individuals {{to pay for health}} services. Although the effect of sample size on confidence intervals is generally well understood by the survey designers and policy-makers who use the results, the typical survey is also subject to <b>non-sampling</b> <b>errors</b> whose magnitude may exceed that of the sampling errors. The <b>non-sampling</b> <b>errors</b> associated with surveys are only rarely assessed and reported, even though they may have a major effect on the interpretation of findings. The present study reports the <b>non-sampling</b> <b>errors</b> associated with a household survey in Sierra Leone by comparing the results of reinterviews with the responses given during the original interviews. Certain types of questions were subject to greater <b>non-sampling</b> <b>errors</b> than others. The findings should be of use to designers of similar surveys and to those who rely on such surveys for making policy decisions...|$|E
40|$|Abstract: In our {{application}} {{practice of}} sample survey, we mostly neglect some <b>non-sampling</b> <b>errors</b> such as sampling frame errors. Actually, {{the influence of}} <b>non-sampling</b> <b>errors</b> to the total survey deviation can not be ignored. In view of this topic, this paper briefly discussed the sampling frame errors as <b>non-sampling</b> <b>errors.</b> First {{a brief review of}} the sampling frame, together with the type and structure of the sampling frame, is given. Next the distinction between sampling frame errors and sampling errors is made theoretically in general. Then through the analysis of a series of non-random impact factors and the application of corresponding improvements or solutions, the sampling frame errors are reduced or controlled within a certain range. Finally, this paper summed up and sorted out the influencing factors based on the sample units or elements for the sampling frame, and also discussed the problems and solutions...|$|E
40|$|On-farm data {{collection}} {{consists of a}} dynamic interaction between the interviewer and respondent via a questionnaire. <b>Non-sampling</b> <b>errors</b> introduced by these sources during the measurement process often account for {{a greater proportion of}} the total survey error than sampling error alone. A two pronged approach was used to evaluate <b>non-sampling</b> <b>errors</b> in the National Animal Health Monitoring System’s National Swine Survey. First, results from two supplemental questionnaires, administered to field coordinators and in-terviewers of the National Swine Survey, were used to assess correlates of <b>non-sampling</b> <b>errors.</b> S’econd, since questionnaires contained multiple indicators of the same underlying concept, an index of inconsistency was used to quantify the level of response error for several variables. Bias due to the ecologic fallacy was shown by elevated estimates of response error for several indicators of preventive practices. Correlates of respondent error included the presence of multiple respondents for at least one interview {{for more than half of}} the inter-viewers. Correlates of interviewer error included demographic characteristics of inter...|$|E
40|$|BACKGROUND Data {{on blood}} donor status {{obtained}} from general surveys and health interview surveys {{have been widely}} used. However, the integrity of data on self-reported blood donor status from surveys may be threatened by sampling and <b>non-sampling</b> <b>error.</b> Our study aimed to compare self-reported blood donors (including one-time as well as regular donors) from the Swiss Health Survey 2012 (SHS) with register-based blood donors recorded by blood establishments and evaluate the direction and magnitude of bias in the SHS. METHODS We compared population-weighted SHS point {{estimates of the number}} of blood donors with their corresponding 95...|$|R
40|$|Abstract: Count {{data are}} subject to {{considerable}} sources of what {{is often referred to}} as <b>non-sampling</b> <b>error.</b> Errors such as misclassification, measurement error and unmeasured confounding can lead to substantially biased estimators. It is strongly recommended that epidemiologists not only acknowledge these sorts of errors in data, but incorporate sensitivity analyses into part of the total data analysis. We extend previous work on Poisson regression models that allow for misclassification by thoroughly discussing the basis for the models and allowing for extra-Poisson variability in the form of random effects. Via simulation we show the improvements in inference that are brought about by accounting for both the misclassification and the overdispersion...|$|R
40|$|Abstract: Nationally {{representative}} household {{surveys are}} increasingly relied upon to measure maternal, newborn, {{and child health}} (MNCH) intervention coverage at the population level in low- and middle-income countries. Surveys are the best tool we have for this purpose and are central to national and global decision making. However, all survey point estimates have {{a certain level of}} error (total survey error) comprising sampling and <b>non-sampling</b> <b>error,</b> both of which must be considered when interpreting survey results for decision making. In this review, we discuss the importance of considering these errors when interpreting MNCH intervention coverage estimates derived from household surveys, using relevant examples from national surveys to provide context. Sampling error is usually thought of a...|$|R
40|$|This paper {{examines}} {{the accuracy of}} data in annual unlinked passenger trips reported to the National Transit Database (NTD) at the individual agency level. This examination takes a twostep approach. The first step compares the ridership reported by member agencies to the American Public Transportation Association (APTA) and the ridership reported to the NTD as recipients of transit formula grants. The NTD ridership can {{be as high as}} 50 percent more than the APTA ridership, and such significant positive deviation exists persistently over time across many agencies. The second step explores potential sources of these positive deviations by examining their components. Random errors, including both sampling errors and some of the <b>non-sampling</b> <b>errors,</b> do not help explain these one-sided deviations. Nor do occasional annual adjustments such as special events ridership to a direct count in the NTD ridership. Much of these positive deviations appear to be attributable to systematic <b>non-sampling</b> <b>errors</b> that result from undercounting in direct counts, from unintentional biases in procedures, or perhaps from intentional manipulation. Limited evidence in the literature, however, suggests that undercounting in direct counts is small at the systemwide level. The paper then quantitatively examines how these systematic <b>non-sampling</b> <b>errors</b> affect the allocation of two formula grants to Florida transit agencies: the Urbanized Area Formula Grant Program at the federal level and Florida’s Transit Block Grant Program at the state level. The paper also discusses a strategy for reducing these systematic <b>non-sampling</b> <b>errors...</b>|$|E
40|$|Survey {{estimates}} are often affected by <b>non-sampling</b> <b>errors</b> due to missing data, coverage error, and measurement or response error. Such <b>non-sampling</b> <b>errors</b> {{can be difficult}} to assess, and possibly correct for, using information from a single survey. Thus, combining information from multiple surveys can be beneficial. In addition, combining information from multiple surveys can help to reduce sampling error. This article describes four examples of projects undertaken by researchers within and outside the National Center for Health Statistics of the Centers for Disease Control and Prevention, in which information from multiple surveys was combined to adjust for <b>non-sampling</b> <b>errors</b> and thereby enhance estimation of various measures of health. The four projects can be described briefly as follows: (1) combining estimates from a survey of households and a survey of nursing homes to extend coverage; (2) using information from an interview survey to bridge the transition in race reporting in the United States census; (3) combining information from an examination survey and an interview survey to improve on analyses of self-reported data; and (4) combining information from two interview surveys to enhance small-area estimation. The article highlights the goals, techniques, and results from the four projects and discusses issues that can arise when information is combined from multiple surveys. Published in 2007 by John Wiley & Sons, Ltd...|$|E
40|$|The study aims at {{assessing}} the differential effects of face-to-face paper and computer assisted interviewing {{in terms of}} efficacy, efficiency {{and the production of}} <b>non-sampling</b> <b>errors.</b> The research ground is constituted by the analysis of the customer satisfaction of a large-scale retail trade group owning many shops in Sicily. The reaction of respondents to paper versus electronic questionnaires is investigated by means of an experimental design in terms of non sampling error amounts...|$|E
40|$|Statistics is a toll {{of survey}} {{research}}. There is polling {{in a survey}} research. In survey research methodology, statistical techniques are used to design the sampling. In survey research, the precision factor that must always be considered is sampling <b>error</b> and <b>non-sampling</b> <b>error.</b> Survey is also used for economic research, including the Islamic economy. As a research tool, the statistics should always be considered carefully, how statistics used in polls and surveys. As a science that emphasizez the scientific aspects, Islamic economics also use survey research to see whether Islamic economics {{has been able to}} provide a positive impact on the community of science DOI: 10. 15408 /aiq. v 3 i 2. 2134 </p...|$|R
40|$|The use of CATI {{methods for}} {{conducting}} population health surveys is an enduring and popular practice. Although {{it is one}} of the most reliable ways to collect data, there is a range of sampling and non sampling errors which can potentially affect the abiliity of CATI surveys to provide accurate results. This thesis examined the impact of a particular type of <b>non-sampling</b> <b>error</b> - question order effects - in CATI surveys. Two studies were conducted one which examined order effects in data collected using a standard health survey instrument designed to measure and classify physical activity behaviour, and one which examined order effects in data collected using two question blocks designed to evaluate health related knowledge and attitudes" [...] Abstract...|$|R
2500|$|All {{statistical}} work presents {{opportunities for}} error, but it's possible to reduce error to manageable amounts. A statement reads: [...] "An important aim of our ongoing {{work is to}} understand, manage, control and report on all known sources of error... which simply reflect the inherent variability that exists among the units we are seeking to measure... This variability manifests itself in sampling error when we use samples for cost-effectiveness reasons to estimate characteristics about a population. Sampling errors are relatively easy to measure.... Other sources reflect process, measurement and inference errors, and {{are referred to as}} <b>non-sampling</b> <b>error.</b> It is not possible to eliminate all sources of error. However, our continued efforts at understanding and managing variability and error ensure we are exercising a high level of control on all known sources of error." ...|$|R
40|$|It {{is widely}} known that pre-electoral polls often suffer from <b>non-sampling</b> <b>errors,</b> mainly due to {{imperfect}} frames, non-responses, {{other forms of}} selection bias. These <b>non-sampling</b> <b>errors</b> might also be more relevant than sampling errors. In order to correct for biases due to <b>non-sampling</b> <b>errors,</b> the pollsters implement diverse ad hoc adjustments, including expert opinions in final estimates, thus leading to the well-known house effects. We consider data on pre-election polls for Italian political elections in 2006, 2008 and 2013 carried out by various pollsters and made available on a free-access governmental website. The response variables are the estimated vote shares of the principal Italian parties (those which are included in all available polls). Since various pollsters carry {{out a number of}} pre-electoral polls in the observed time frame, the data have a hierarchical structure in which groups are defined to be the pollsters. We propose a model to assess the relevance of the variability induced by the house effects with respect to the total variability. In particular we consider a hierarchical Bayesian model in which each party share of votes is separately analyzed. The model involves two-stages, in which the first stage allows for the within-pollster variability and also includes a non linear time trend, whereas the second stage describes the between-pollsters variability, by means of a random effect vector. A Gaussian distribution is employed both for observations and for random effects. Such Gaussian distributions are parametrized so to allow for the different variability due to the various sample sizes and underlying probability. In general, results confirm a large house effect in Italian pre-election polls. The effect is quite heterogeneous between parties and between pollsters. Such conclusion appear to be quite stable across the considered years...|$|E
40|$|Household {{surveys of}} the {{distribution}} of income and expenditure are discussed in this paper. The potential for <b>non-sampling</b> <b>errors,</b> effecting both the mean and measures of dispersion, is noted. These errors are shown to result in substantial discrepancies between the survey data and national accounts-based estimates of the incidence of poverty and trends in living standards. It is argued that the reconciliation of these discrepancies offers the best way forward for improving both types of data. 1...|$|E
40|$|It {{is widely}} known that pre-electoral polls often suffer from <b>non-sampling</b> <b>errors</b> which pollsters try to {{compensate}} in ﬁnal estimates {{by means of}} diverse ad hoc adjustments, thus leading to the well-known house effects. We analyze vote share predictions from election polls in Italy in 2006, 2008 and 2013 in order to investigate the relative role of house effects on their variability. We are able to conﬁrm that the variability due to house effect {{is the most important}} source of variatio...|$|E
40|$|This study {{explores the}} {{potential}} contribution of DHS data in improving knowledge of trends in neonatal mortality in developing countries. It outlines {{the causes and}} possible consequences of sampling and <b>non-sampling</b> <b>error</b> in survey data of this nature, before using DHS and World Fertility Survey estimates to describe apparent trends in neonatal mortality {{over the last few}} decades. It also examines the association between neonatal mortality and per capita gross domestic product (GDP) at national level. The study draws out how both patterns of progress and relationship with GDP differ markedly in the neonatal period than in post-neonatal infancy and early childhood. The discussion summarises the potential limitations in using DHS estimates for NMR, as well as outlining potential factors underlying the relatively poor progress being made in reducing neonatal deaths...|$|R
40|$|Research {{concerning}} crafts-artists in the United States involved two phases: {{a survey}} of craft organizations and members and {{a survey of}} professional and subscriber crafts-artists. This report describes the sampling, data collection, and data processing procedures used in the surveys, describes the questionnaires and,other materials sent to crafts organizations and crafts-artists, and provides documentation {{for the results of}} the surveys. It also forms the basis for assessing the impact of <b>non-sampling</b> <b>error</b> on the information collected. The report is organized into six chapters. Following an introduction and summary of the report, the second chapter describes the two surveys, including acquisition of membership lists and selection of the samples of crafts-artists. Chapter 3 describes the development and pretesting of the questionnaire, while the following two chapters describe the dat...|$|R
5000|$|All {{statistical}} work presents {{opportunities for}} error, but it's possible to reduce error to manageable amounts. A statement reads: [...] "An important aim of our ongoing {{work is to}} understand, manage, control and report on all known sources of error... which simply reflect the inherent variability that exists among the units we are seeking to measure... This variability manifests itself in sampling error when we use samples for cost-effectiveness reasons to estimate characteristics about a population. Sampling errors are relatively easy to measure.... Other sources reflect process, measurement and inference errors, and {{are referred to as}} <b>non-sampling</b> <b>error.</b> It is not possible to eliminate all sources of error. However, our continued efforts at understanding and managing variability and error ensure we are exercising a high level of control on all known sources of error." ...|$|R
