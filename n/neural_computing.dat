231|220|Public
25|$|Yan, C., Dobbs, D., and Honavar, V. Identifying Protein-Protein Interaction Sites from Surface Residues  A Support Vector Machine Approach. <b>Neural</b> <b>Computing</b> Applications. Vol. 13. pp.123–129, 2004.|$|E
2500|$|Computational {{devices were}} created in CMOS, for both biophysical {{simulation}} and neuromorphic computing. Nanodevices for very large scale principal components analyses and convolution may create {{a new class of}} <b>neural</b> <b>computing</b> because they are fundamentally analog rather than digital (even though the first implementations may use digital devices.) ...|$|E
5000|$|The Promise of Neural Networks (Perspectives in <b>Neural</b> <b>Computing),</b> (1993), [...]|$|E
40|$|ABSTRACT: After {{twenty years}} of disfavor, a {{technology}} has returned which imitates the processes of the brain. Natural language experiments (Sejnowski & Rosenberg: 1986) demonstrate that <b>neural</b> network <b>computing</b> architecture can learn from actual spoken language, observe rules of pronunciation, and reproduce sounds from the patterns derived by its own processes. The consequences of <b>neural</b> network <b>computing</b> for natural language processing activities, including second language acquisition and representation, machine translation, and knowledge processing may be more convulsively revolutionary than anything imagined in current technology. This paper introduces neural network concepts to a traditional natural language processing audience...|$|R
5000|$|Fathom is a USB stick {{containing}} a Myriad 2 processor, allowing a vision accelerator {{to be easily}} added to devices using ARM processors including PCs, drones, robots, IoT devices and video surveillance for tasks such as identifying people or objects. It can run between 80 and 150 GFLOPS performance at below 1W of power. The company switched from a previous 65nm process to a 28 nm one to increase its chip’s efficiency by 20-30x. The Fathom was expected to cost under $100 per unit [...] After Intel's acquisition of Movidius, the Movidius™ <b>Neural</b> <b>Compute</b> Stick was released on July 21, 2017 {{at a cost of}} $79 in the USA.|$|R
5000|$|This {{functional}} form {{is commonly}} called a single-layer perceptron or single-layer artificial neural network. A single-layer <b>neural</b> network <b>computes</b> a continuous output {{instead of a}} step function. The derivative of pi with respect to X = (x1, ..., xk) is computed from the general form: ...|$|R
5000|$|Fifth International Conference on Fuzzy and <b>Neural</b> <b>Computing</b> 2015 (December 17 -19, 2015) ...|$|E
5000|$|Topping, B.H.V., Bahreininejad, A., <b>Neural</b> <b>Computing</b> for Structural Mechanics, Saxe-Coburg Publications, Edinburgh, UK, 1997 ...|$|E
5000|$|Visual Structures and Integrated Functions (Research Notes in <b>Neural</b> <b>Computing,</b> No 3) by Michael A. Arbib, Jorg-Peter Ewert ...|$|E
5000|$|Doctoral Program (PhD) in Cellular Automata, Web Intelligence, Distributed <b>Computing,</b> <b>Neural</b> Networks, Artificial Intelligence, Multimedia Systems and Compiler Design.|$|R
5000|$|A {{multi-layer}} <b>neural</b> network can <b>compute</b> {{a continuous}} output {{instead of a}} step function. A common choice is the so-called logistic function: ...|$|R
40|$|The robustified {{numerical}} {{technique for}} real-time sensor array reconstructive image processing is developed as required for remote sensing imaging with large scale array/synthesized array radars. The addressed technique is designed via performing the regularized robustification of the fused Bayesian-regularization imaging method aggregated with the efficient real-time numerical implementation scheme that employs the <b>neural</b> network <b>computing...</b>|$|R
50|$|He is the President and CEO of KnuEdge (formerly Intellisis), {{a company}} he founded in 2005 that {{produces}} <b>neural</b> <b>computing</b> hardware.|$|E
50|$|The {{original}} name of {{the company}} was Financial <b>Neural</b> <b>Computing.</b> The company’s focus changed and the name was changed to FNC.|$|E
5000|$|Dynamic Interactions in Neural Networks: Models and Data (Research Notes in <b>Neural</b> <b>Computing)</b> by Michael A. Arbib, Shun-Ichi Amari (January 1, 1989) ...|$|E
40|$|Training single {{neural network}} is a {{difficult}} task. In each training session, the network is trained for hundred of epochs and some problem may involve {{a large amount of}} variables and data. Thus, training single network is time consuming. Therefore, distributed learning approaches such as hierarchical, multi-stage, parallel <b>neural</b> network <b>computing</b> and multi-modal <b>neural</b> network was introduced...|$|R
40|$|Logistic {{units in}} the rst hidden layer of a {{feedforward}} <b>neural</b> network <b>compute</b> the relative probability of a data point under two Gaussians. This leads us to consider substituting other density models. We present an architecture for performing discriminative learning of Hidden Markov Models using a network of many small HMM's. Experiments on speech data show it to be superior to the standard method of discriminatively training HMM's...|$|R
40|$|Two {{dimensional}} image motion detection {{neural networks}} {{have been implemented}} using a general purpose analog neural computer. The neural circuits perform spatiotemporal feature extraction based on the cortical motion detection model of Adelson and Bergen. The neural computer provides the neurons, synapses and synaptic time-constants required to realize the model in VLSI hardware. Results show that visual motion estimation can be implemented with simple sum-and-threshold neural hardware with temporal computational capabilities. The <b>neural</b> circuits <b>compute</b> general 20 visual motion in real-time. ...|$|R
5000|$|Yan, C., Dobbs, D., and Honavar, V. Identifying Protein-Protein Interaction Sites from Surface Residues  A Support Vector Machine Approach. <b>Neural</b> <b>Computing</b> Applications. Vol. 13. pp. 123-129, 2004.|$|E
5000|$|J. Li, K. Ouazzane, H. Kazemian, Y. Jing, R. Boyd (2011) ‘ A neural Network Based Solution for Automatic Typing Errors Correction’, Journal of <b>Neural</b> <b>Computing</b> Applications; DOI: 10.1007/s00521-010-0492-3 ...|$|E
50|$|In {{computer}} graphics and robotics, geometric algebras have been revived {{in order to}} efficiently represent rotations and other transformations. For applications of GA in robotics (screw theory, kinematics and dynamics using versors), computer vision, control and <b>neural</b> <b>computing</b> (geometric learning) see Bayro (2010).|$|E
40|$|A {{neural network}} {{approach}} {{for dealing with}} the solution of frictional contact problems is proposed. Such an approach permits the rational treatment of the aforementioned limit states. In particular, discretizing the structure by means of a suitable finite element scheme, the structural behavior is described by a discrete hemivariational inequality. An effective algorithm equivalently transforms the initial nonmonotone problem into a sequence of monotone, Coulomb friction problems. Then, a <b>neural</b> network <b>computing</b> system is applied in order to solve efficiently the arising optimization problems...|$|R
40|$|<b>Neural</b> network <b>computing</b> {{is applied}} into medical {{electrocardiogram}} signal processing, classification and diagnosis. The electrocardiogram (ECG) is {{the measurement of}} the electrical activity of the heart, and {{it is called the}} language of the heart, since from which the heart function and abnormality can be assessed, and this analysis process can be greatly assisted by current computer technology. In this thesis, artificial neural networks are introduced, and applied into the analysis and diagnosis of ECGs. The heart rate diagram is produced using the Backpropagation Neural Network (BPNN). A diagnosis conclusion of certain disease according to the heart rate is given here. Then the beat classification result for any types of record is achieved by the Adaptive Resonance Theory (ART) Network, by which thousands of QRS complexes (the main part of the ECU) are classified into less than sixty-six categories, these classification results can be treated as a simplification of the original record. All the test records are taken from the MIT-BIH Database stored in a particular CD. In this thesis, the basic knowledge of ECU diagnosis and <b>Neural</b> Network <b>computing</b> is introduced in the early chapters. The principles of the BPNN and ART network are demonstrated in the middle chapters, the program results are provided {{at the end of the}} thesis...|$|R
40|$|Abstract. The genetic {{algorithm}} applied to switch electrical appliances electric arc feature extraction, based on {{genetic algorithm}}, the switch electrical arc feature extraction model was established. The initial pool formation, evaluation individual, reproduction, crossover and mutation {{have done a}} detailed representation. This model can eliminate the slow convergence and so easy {{to fall into the}} local minimum shortcomings of BP <b>neural</b> network <b>computing</b> graphics weights. The experiment showed that genetic algorithm can better converge to the global optimal solution, more in line with the arc Feature Extraction fact, and more effectively improving the quality of graphics extraction...|$|R
50|$|In 2002, Stanford Ovshinsky {{described}} an analog <b>neural</b> <b>computing</b> medium in which phase change material {{has the ability}} to cumulatively respond to multiple input signals. An electrical alteration of the resistance of the phase change material is used to control the weighting of the input signals.|$|E
5000|$|Matthews has {{published}} research in refereed journals {{on a wide}} variety of subjects ranging from Bayesian inference and probability to astronomy, cryptology and <b>neural</b> <b>computing.</b> He has also won awards for his research, including an Ig Nobel Prize, awarded in 1996 for his paper Tumbling toast, Murphy's Law and the fundamental constants.|$|E
50|$|These {{algorithms}} {{have become}} important tools in artificial intelligence, machine learning, <b>neural</b> <b>computing</b> and engineering applications. Since 2009, more than 1,000 peer-reviewed research papers cited the firefly algorithm and/or cuckoo search. In addition, the Van Flandern-Yang hypothesis {{was derived from}} his collaboration with Tom Van Flandern to explain the gravity variations during the 1997 solar eclipse, and this theory {{is related to the}} well-known Allais effect and other phenomena.|$|E
40|$|In this paper, {{we propose}} a novel {{approach}} for evolving the architecture of a multi-layer neural network. Our method uses combined ART 1 algorithm and Max-Min neural network to self-generate nodes in the hidden layer. We have applied the proposed method to the optimal channel allocation problem in mobile cellular networks. Experimental {{results show that the}} proposed method has better performance than conventional neural networks and the resulting <b>neural</b> network <b>computes</b> the optimal guard channel number g within ignorable error bound for GoS. Key words: ART 1, neural network, channel optimization, guard channel, cellular networks. 1...|$|R
40|$|Layer-wise {{relevance}} propagation is {{a framework}} which allows to decompose {{the prediction of}} a deep <b>neural</b> network <b>computed</b> over a sample, e. g. an image, down to relevance scores for the single input dimensions of the sample such as subpixels of an image. While this approach can be applied directly to generalized linear mappings, product type non-linearities are not covered. This paper proposes an approach to extend layer-wise relevance propagation to neural networks with local renormalization layers, {{which is a very}} common product-type non-linearity in convolutional neural networks. We evaluate the proposed method for local renormalization layers on the CIFAR- 10, Imagenet and MIT Places datasets...|$|R
5000|$|The Jeffres Map was {{a theory}} of how the brain might compute {{interaural}} time differences (ITD), or differences in time of stimulus arrival between the two ears. Jeffres was famous for producing a theoretical mechanism for making a place map out of timing information, this explained how some animals could {{appear to have a}} [...] "look-up map" [...] for where a sound came from. The <b>neural</b> system <b>computes</b> this ITD in the Owl Auditory System and the real neural system was found to almost exactly match the Jeffres Map theory. The Jeffres Map shows how ITD signals are used to determine distance and direction in the owl.|$|R
5000|$|Computational {{devices were}} created in CMOS, for both biophysical {{simulation}} and neuromorphic computing. Nanodevices for very large scale principal components analyses and convolution may create {{a new class of}} <b>neural</b> <b>computing</b> because they are fundamentally analog rather than digital (even though the first implementations may use digital devices.) Ciresan and colleagues (2010) in Schmidhuber's group showed that despite the vanishing gradient problem, GPUs makes back-propagation feasible for many-layered feedforward neural networks.|$|E
50|$|Non-invasive lie {{detection}} using non-verbal {{behavior is}} {{performed by the}} Silent Talker Lie Detector. Silent Talker monitors large numbers of microexpressions over time slots and encodes them into large vectors which are classified as showing truthful or deceptive behavior by artificial intelligence or statistical classifiers. Silent Talker research has been peer-reviewed in the Journal of Applied Cognitive Psychology and in the Journal of <b>Neural</b> <b>Computing</b> and Applications. The architecture was invented between 2000 and 2002 by a team at Manchester Metropolitan University.|$|E
5000|$|Following his PhD, Daugman held a post-doctoral fellowship, then {{taught at}} Harvard for five years. After short {{appointments}} in Germany and Japan, {{he joined the}} University of Cambridge in England to research and to teach computer vision, <b>neural</b> <b>computing,</b> information theory, and pattern recognition. He held the Johann Bernoulli Chair of Mathematics and Informatics at the University of Groningen in the Netherlands, and the Toshiba Endowed Chair at the Tokyo Institute of Technology in Japan [...] before becoming Professor at Cambridge.|$|E
40|$|The {{thesis is}} about {{computer}} architectures specially tuned to an application area. This {{means that the}} work spans the area from implementation technology via processor and computer system organization to the applications themselves. The work reported here is {{in the area of}} embedded high performance computing, near the area of application specific hardware. The thread throughout the thesis is how to design computers to suit a specific application area, while maintaining as much computing performance, programmability, scalability and flexibility as possible. The idea is that the multiple SIMD computing model can be a flexible and reasonably scalable concept for the high end applications considered. To test this hypothesis the approach taken is to use application examples, algorithm analysis and implementation experiments to derive suitable computing modules. These modules are then evaluated according to scalability, generality, efficiency, and implementation aspects. The application areas are artificial <b>neural</b> network <b>computing</b> and signal processing in phased array radar. For the artificial <b>neural</b> network <b>computing</b> a multiple SIMD architecture is suggested and artificial neural network algorithms are mapped onto a typical such module. Implementation aspects are discussed and the design of a prototype is shown. Then the use of artificial neural networks in an industrial real-time application is presented. The artificial neural networks are used to extract information from noisy and non-linear signals in combustion engines. It is shown that the neural networks are feasible, and close to optimal, in this application. In the area of signal processing for phased array radar, two application examples are analyzed and architectures suitable for the these are derived. An intermodule communication for implementation on a fiber-optic network is evaluated in a radar application. Then implementation issues for the processing modules are considered and discussed. This is done in the light of instruction statistics gathered from the application examples. Finally, the results are combined and the VEGA architecture is described and motivated. In the thesis it is shown that the modular, multiple SIMD model can be efficiently used in both signal processing for phased array radar and artificial <b>neural</b> network <b>computing.</b> Furthermore, a conclusion drawn is that the linear array SIMD module with broadcast and ring communication is enough for many popular neural network models. It is also concluded that the moderately parallel MIMD machine with moderately parallel SIMD computing modules is a feasible architecture for signal processing in phased array radar...|$|R
2500|$|Earlier {{challenges}} in training deep neural networks were successfully addressed with {{methods such as}} unsupervised pre-training, while available computing power increased {{through the use of}} GPUs and distributed <b>computing.</b> <b>Neural</b> networks were deployed on a large scale, particularly in image and visual recognition problems. This became known as [...] "deep learning", although deep learning is not strictly synonymous with deep neural networks.|$|R
40|$|This paper {{presents}} basics {{and brief}} about neural network, {{artificial neural network}} (ANN), biological neural network (BNN) in soft <b>computing.</b> <b>Neural</b> network are of interest to {{quite a lot of}} people from different fields. The environmental nature and related functioning, marketing business as well as designing of any such systems can be implemented via neural network; NNs are useful for mapping problems...|$|R
