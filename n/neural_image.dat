37|375|Public
5000|$|Damasio’s {{definition}} of emotion {{is that of}} an unconscious reaction to any internal or external stimulus which activates neural patterns in the brain. [...] ‘Feeling’ emerges as a still unconscious state which simply senses the changes affecting the Protoself due to the emotional state. These patterns develop into mental images, which then float into the organism’s awareness. Put simply, consciousness is the feeling of knowing a feeling. When the organism becomes aware of the feeling that its bodily state (Protoself) is being affected by its experiences, or response to emotion, Core Consciousness is born. The brain continues to present nonverbal narrative sequence of images {{in the mind of}} the organism, based on its relationship to objects. An object in this context can be anything from a person, to a melody, to a <b>neural</b> <b>image.</b> Core consciousness is concerned only with the present moment, here and now. It does not require language or memory, nor can it reflect on past experiences or project itself into the future.|$|E
40|$|The {{aim of this}} {{research}} was investigate the possibility of using methods of computer image analysis and artificial neural networks for to assess the amount of dry matter in the tested compost samples. The research lead {{to the conclusion that the}} <b>neural</b> <b>image</b> analysis may be a useful tool in determining the quantity of dry matter in the compost. Generated neural model may be the beginning of research into the use of <b>neural</b> <b>image</b> analysis assess the content of dry matter and other constituents of compost. The presented model RBF 19 : 19 - 2 - 1 : 1 characterized by test error 0. 092189 may be more efficient...|$|E
40|$|Modern <b>neural</b> <b>image</b> {{captioning}} systems typically {{adopt the}} encoder-decoder framework {{consisting of two}} principal components: a convolutional neural network (CNN) for image feature extraction and a recurrent neural network (RNN) for caption generation. Inspired by the robustness analysis of CNN-based image classifiers to adversarial perturbations, we propose Show-and-Fool, a novel algorithm for crafting adversarial examples in <b>neural</b> <b>image</b> captioning. Unlike image classification tasks with a finite set of class labels, finding visually-similar adversarial examples in an image captioning system is much more challenging since the space of possible captions in a captioning system is almost infinite. In this paper, we design three approaches for crafting adversarial examples in image captioning: (i) targeted caption method; (ii) targeted keyword method; and (iii) untargeted method. We formulate the process of finding adversarial perturbations as optimization problems and design novel loss functions for efficient search. Experimental results on the Show-and-Tell model and MSCOCO data set show that Show-and-Fool can successfully craft visually-similar adversarial examples with randomly targeted captions, and the adversarial examples can be made highly transferable to the Show-Attend-and-Tell model. Consequently, the presence of adversarial examples leads to new robustness implications of <b>neural</b> <b>image</b> captioning. To {{the best of our}} knowledge, this is the first work on crafting effective adversarial examples for image captioning tasks...|$|E
40|$|Abstract. Horseshoe crabs use {{vision to}} find mates. They can {{reliably}} detect objects resembling potential mates under {{a variety of}} lighting conditions. To understand how they achieve this remarkable performance, we constructed a cellbased realistic model of the lateral eye to compute the ensembles of optic nerve activity (“neural images”) it transmits to the brain. The <b>neural</b> <b>images</b> reveal a robust encoding of mate-like objects that move underwater during the day. The <b>neural</b> <b>images</b> are much less clear at night, even though the eyes undergo large circadian increases of sensitivity that nearly compensate for the millionfold decrease in underwater lighting after sundown. At night the <b>neural</b> <b>images</b> are noisy, dominated by bursts of nerve impulses from random photon events that occur at low nighttime levels of illumination. Deciphering the eye’s input to the brain begins at the first synaptic level with lowpass temporal and spatial filtering. Both neural filtering mechanisms improve the signal-to-noise properties of the eye’s input, yielding clearer <b>neural</b> <b>images</b> of potential mates, especially at night. Insights about visual processing by the relatively simple visual system of Limulus may aid in the design of robotic sensors for the marine environment...|$|R
40|$|It {{has been}} {{suggested}} that the first steps in visual processing strive to compress as much information as possible about the outside world into the limited dynamic range of the visual channels. Here I compare measured <b>neural</b> <b>images</b> with theoretical calculations based on maximizing information, taking into account the statistical structure of natural <b>images.</b> <b>Neural</b> <b>images</b> were obtained by scanning an image while recording from a second-order neuron in the fly visual system. Over a 5. 5 -log-units-wide range of mean intensities, experiment and theory correspond well. At high mean intensities, redundancy in the image is reduced by spatial and temporal antagonism. At low mean intensities, spatial and temporal low-pass filtering combat noise and increase signal reliability. ...|$|R
40|$|Abstract The {{vertebrate}} retina {{generates a}} stack {{of about a dozen}} different movies that represent the visual world as dynamic <b>neural</b> <b>images.</b> The stack is embodied as separate strata that span the inner plexiform layer (IPL). At each stratum, ganglion cell dendrites reach up to read out inhibitory interactions between three different amacrine cell classes that shape bipolar-to-ganglio...|$|R
40|$|Introduction: 'Filling-in' {{occurs when}} an {{attribute}} such as brightness or motion is induced in a blank {{region of the}} visual field by the surrounding stimulus. Measuring the neural correlates of filling in with fMRI is complicated by spatio-temporal blurring and nonlinearities associated with the BOLD signal. Here we avoid these complexities by visualizing the effects of filling-in using a novel <b>neural</b> <b>image</b> method based on population receptive fields (pRF) 1. Methods: We estimated the pRFs that best predicted each voxel's time course to a multifocal (spatiotemporally random) stimulus in areas V 1 -V 3 in three normally sighted individuals. We then measured fMRI responses to a drifting bar within a 16 ° aperture either {{with or without a}} central 2 ° blank 'scotoma'. For both stimuli, 'neural image' time-courses were generated by summing each voxel's Gaussian pRF in visual space scaled by its fMRI response at that time-point. To account for spatio-temporal blurring and nonlinearities in the BOLD signal, we compared these 'real neural images' to a 'model neural image' generated by convolving the stimulus time-course with each subject's estimated HDR and pRFs, with the inclusion of a model of BOLD spatio-temporal nonlinearities. Results: For the stimulus without a scotoma, model and real neural images are remarkably similar and resemble the drifting bar stimulus, delayed in time by BOLD hemodynamics. With the scotoma, the model <b>neural</b> <b>image</b> shows the expected drop in foveal response. In contrast, the scotoma had almost no effect on the real <b>neural</b> <b>image.</b> Differences between the model and real 'neural image' can be attributed to neural 'filling in'. Conclusion: We describe here a novel <b>neural</b> <b>image</b> method that estimates neural responses independently of the effects of spatiotemporal blurring and nonlinearities, and show that it can demonstrate the effects of neural filling in for a drifting bar stimulus in foveal V 1 -V 3. Meeting abstract presented at VSS 201...|$|E
40|$|The {{convergence}} time for training back propagation neural network for image compression is slow ascompared to other traditional image compression techniques. This article proposes a pre-processingtechnique i. e. Pre-processed Back propagation <b>neural</b> <b>image</b> compression (PBN) with an enhancement inperformance measures like better {{convergence time}} {{with respect to}} decoded picture quality andcompression ratios as compared to simple back-propagation based image compression and other imagecoding techniques for color images...|$|E
40|$|The {{dynamics}} of the receptive fields of retinal horizontal cells were examined by applying a spatio-temporal modulated light signal to the retina. The spatio-temporal receptive fields of both cone- and rod-driven horizontal cells, estimated through cross-correlation between the modulated light signal and the cells’ responses, showed their receptive fields (the space-dependent component) to be reduced in size with time. In cone-driven horizontal cells, the reduction in receptive field size was initially small but then rapidly became prominent with time. The time to peak of the time-dependent component of spatio-temporal receptive fields did {{not depend on the}} distance from the centre. Application of a small amount of Co 2 +, an agent blocking the cone-driven horizontal cells’ feedback action on cones, or GABA, resulted in a reversal of the time-dependent shrinkage of receptive fields to time-dependent expansion. In rod-driven horizontal cells, the receptive field shrinkage was slow. The time to peak of the time-dependent component decreased with the distance from the centre. Image processing experiments examining the response pattern in the horizontal cell layer (<b>neural</b> <b>image)</b> to a moving square of light showed smudging of the <b>neural</b> <b>image</b> when the time-dependent receptive field expansion was present, while there was essentially no smudging under conditions of receptive field shrinkage...|$|E
40|$|This is {{a conference}} paper. This paper {{outlines}} {{a training program}} based on the regular practised generation and manipulation of <b>neural</b> <b>images</b> {{that has been used}} to improve the visual mental imagery (VMI) of design students. Most people can produce mental images, although there is variability in terms of the vividness, detail and control that can be achieved. Research indicates that VMI is an important feature of activities such as inventing and solving complex problems. Perceived images such as sketches or diagrams facilitate creative problem solving and therefore VMI should facilitate problem-solving within design activities. Further research has found that professional designers have varying degrees of imagery generation and manipulation that correlates with their level of expertise. Studies have found {{that it is possible to}} improve people’s ability to create mental images and others have improved the control of <b>neural</b> <b>images.</b> This research has developed strategies to concurrently improve design students’ vividness and control of their VMI. The application of the program within the Design and Technology learning environment and the influence on students’ design ability is discussed...|$|R
5000|$|... #Caption: Role of cell adhesions in <b>neural</b> development. <b>Image</b> {{courtesy}} of Wikipedia user JWSchmidt under the GNU Free Documentation License ...|$|R
5000|$|... 1. Networking2. Big Data Mining3. GIS & Geoinformatics4. Machine Learning & <b>Neural</b> Networks5. <b>Image</b> Processing6. Information Security7. Image {{enhancement}} and retrieval8. Image Registration {{and satellite}} image processing ...|$|R
40|$|The retina {{reports the}} visual scene {{to the brain}} through many {{parallel}} channels, each carried by a distinct population of retinal ganglion cells. Among these, the population with the smallest and densest receptive fields encodes the <b>neural</b> <b>image</b> with highest resolution. In human retina, and those of cat and macaque, these high-resolution ganglion cells act as generic pixel encoders: They serve to represent many different visual inputs and convey a <b>neural</b> <b>image</b> of the scene downstream for further processing. Here we identify and analyze high-resolution ganglion cells in the mouse retina, using a transgenic line in which these cells, called “W 3 ”, are labeled fluorescently. Counter to the expectation, these ganglion cells {{do not participate in}} encoding generic visual scenes, but remain silent during most common visual stimuli. A detailed study of their response properties showed that W 3 cells pool rectified excitation from both On and Off bipolar cells, which makes them sensitive to local motion. However, they also receive unusually strong lateral inhibition, both pre- and postsynaptically, triggered by distant motion. As a result, the W 3 cell can detect small moving objects down to the receptive field size of bipolar cells, but only if the background is featureless or stationary—an unusual condition. A survey of naturalistic stimuli shows that W 3 cells may serve as alarm neurons for overhead predators...|$|E
40|$|AbstractThe {{perceived}} blur of drifting sinusoidal gratings {{was compared}} to that of static, blurred “square wave” gratings before and after adaptation to a missing fundamental (MF) pattern. The results indicate that the perceived blur of a drifting sine grating is inversely related to its drift speed. However, after adaptation to a MF pattern, this effect is reduced. The adaptation effect is most profound for low contrast gratings. The results provide tentative evidence for a non-linear stage in motion processing which serves to introduce higher frequencies into the <b>neural</b> <b>image</b> which are not present in the original signal. Copyright © 1996 Elsevier Science Ltd...|$|E
40|$|This paper {{presents}} an algorithm for automatic <b>neural</b> <b>image</b> analysis in immunostained vertebrate retinas. We present {{a useful tool}} for cell quantification avoiding the lost of information of traditional binary techniques in automatic recognition of images. The application is based on the extension of the mathematical morphology to colour images. In the paper, we define the basics and more complex morphological operations to vectorial image processing. We propose and demonstrate a colour image reconstruction by geodesic transformations. In addition, we adapt the morphological segmentation of greyscale image to the segmentation of multispectral images of retinas of monkeys. This work has been partially supported by DGESIC PB 98 - 0972...|$|E
40|$|This paper {{focuses on}} the {{evaluation}} of an ideal midsagittal plane (iMSP) extraction algorithm. The algorithm was developed for capturing the iMSP from 3 D normal and pathological <b>neural</b> <b>images.</b> The main challenges are the drastic structural asymmetry that often exists in pathological brains, and the sparse, nonisotropic data sampling that is common in clinical practice. A simple edge-based, cross-correlation approach is presented that decomposes the iMSP extraction problem into discovery of symmetry axes from 2 D slices, followed by robust estimation of 3 D plane parameters. The algorithm's tolerance to brain asymmetries, input image offsets and image noise is quantitatively measured...|$|R
40|$|Contrast-dependent {{orientation}} illusions are {{phenomena in}} which {{the appearance of the}} illusion depends not only on geometrical arrangements of the constituents of illusory configurations, but also on their luminance levels. Whereas certain standard configurations may evoke strong illusory effects, their contrast-manipulated variants (configurations in which only the luminance contrast polarity of some of their elements is manipulated, while retaining the geometry of the standard versions) may show weakened or no illusory effects, or even reversed illusions. Although generally rather salient, the contrast-dependent illusions have not been researched in much detail, except for the well-known Münsterberg (Café Wall) illusion. Here I report how this class of effects may be accounted for by a simple model involving banks of oriented filters. Given a 2 D visual image (luminance distribution) as input, the model produces as output corresponding <b>neural</b> <b>images</b> (simulated 2 D neural activity distributions). The simulations show that the model’s reactions to illusory tilt stimuli contain characteristic sub-patterns which are structurally similar to sub-patterns of its reactions to actually tilted stimuli. Furthermore, such ‘tilted’ sub-patterns are less prominent, absent, or even reversed in <b>neural</b> <b>images</b> of corresponding contrast-manipulated configurations. Thus the explanation why such configurations induce illusory appearance of tilt is that they are partial metamers of configurations that induce veridical appearance of tilt. In addition to now classical effects such as the Café Wall and the Twisted Cords illusion, this account also applies to some more recent, salient effects devised by Akiyoshi Kitaoka and Baingio Pinna...|$|R
50|$|For a {{discussion}} of the aforementioned applications of <b>neural</b> networks in <b>image</b> processing, see e.g.|$|R
40|$|In {{this paper}} we present an {{approach}} to multi-language image description bringing together insights from neural machine translation and <b>neural</b> <b>image</b> description. To create a description of an image for a given target language, our sequence generation models condition on feature vectors from the image, the description from the source language, and/or a multimodal vector computed over the image and a description in the source language. In image description experiments on the IAPR-TC 12 dataset of images aligned with English and German sentences, we find significant and substantial improvements in BLEU 4 and Meteor scores for models trained over multiple languages, compared to a monolingual baseline. Comment: Under review as a conference paper at ICLR 201...|$|E
40|$|Image {{processing}} by the eye {{is treated}} as a classical example of concatentated linear filters followed by a sampling operation. The first filter is optical and is characterized by an optical point-spread function. The second filter is neural and {{is characterized by the}} neural point-spread function, which is shown {{to be related to the}} receptive fields of retinal neurons. Sampling renders the internal &quot;neural image &quot; a discrete signal subject to the effects of aliasing. Conditions responsible for aliasing are formulated in terms of the amount of overlap of retinal samplers. Evidence of aliasing in human vision is presented along with a simulation of an aliased <b>neural</b> <b>image</b> in the peripheral visual field. 1...|$|E
40|$|International audienceThis {{contribution}} {{describes a}} bio-inspired image ﬁltering method using spiking neurons. Bio-inspired approaches aim at identifying key properties of biological systems or models and proposing efﬁcient implementations of these properties. The <b>neural</b> <b>image</b> ﬁltering method {{takes advantage of}} the temporal integration behavior of spiking neurons. Two experimental validations are conducted to demonstrate the interests of this neural-based method. The ﬁrst set of experiments compares the noise resistance of a classical DOG ﬁltering method and the neuronal DOG method on a synthetic image. The other experiment explores the edges recovery ability on a natural image. The results show that the neural-based DOG ﬁltering method is more resistant to noise and provides a better edge preservation than classical DOG ﬁltering method...|$|E
50|$|Elaborating on this idea, {{psychoanalyst}} Gilbert Rose {{argues that}} our responsiveness to music {{begins with the}} nonverbal emotional rapport of the earliest infant-parent interplay. Reaching back even further, since the fetus has an active auditory system 3-4 months before birth, {{the rhythm of the}} mothers womb and the sound of her heartbeat could be the start of our responsiveness to music. Neuroscientist Antonio Damasio states that when an organism interacts with an object, nonverbal <b>neural</b> <b>images</b> map the organism, the object and the interaction between them. As psychoanalysis gives verbal insight of non-verbal emotional involvement, and recent neurosciences found that music is able to contact this non-verbal emotions, music is stated to help the unison of thinking and feeling.|$|R
40|$|Initializing source {{locations}} and widths. We use “hotspots ” in the <b>neural</b> <b>images</b> {{to estimate the}} {{locations and}} widths of the sources. We can then solve for the source weights using linear regression. Honing the parameter esti-mates. We use a scalable stochastic variational inference-based fitting procedure to hone the parameter values given the observed neural and behavioral data. Fitting the models Towards a unified model of corpora and cognition. Our ap-proach attempts to infer the evolving state of mental context using text, behavioral, and neural data. Experimental methods. Participants in an fMRI scanner view 60 words, repeated 3 times each. They then study and freely recall 12 -item lists of the same words...|$|R
40|$|<b>Neural</b> {{networks}} and <b>image</b> pyramids are massively parallel processing structures. In this paper we exploit the similarities {{as well as}} the differences between these structures. The general goal is to exchange knowledge between these two fields. After introducing the basic concepts of <b>neural</b> {{networks and}} <b>image</b> pyramids we give a translation table of the vocabulary used in image pyramids and those used in neural networks. In the following sections we compare <b>neural</b> networks and <b>image</b> pyramids in detail. We show how a modified Hopfield network can be used for irregular decimation. We examine the type of knowledge stored and the processing performed by pyramids and neural networks. In the case of numerical information, so called "numerical pyramids" are rather similar to neural networks...|$|R
40|$|Abstract-Image {{processing}} requires {{free access}} to information about all parts of an image. but a nerve cell in VI can only interact directly with {{a tiny fraction of}} the other cells in VI. The problem this poses might be alleviated by forming secondary “neural images ” in which information is re-arranged, and some possible rules of projection for forming such images are explored. It is also suggested that all parts ol the cerebral cortex detect, and subsequently signal. suspicious coincidences in their inputs. Acqmring knowledge of the associative structure of sensory messages, in the form of the unexpected coincidences that occur, may represent the beginning of the formation of a working model, or cognitive map. of the environment. Visual cortex Image-processing Computer-vision Segregation Mapping Flow-lield <b>Neural</b> <b>image...</b>|$|E
40|$|In <b>neural</b> <b>image</b> {{captioning}} systems, {{a recurrent}} neural network (RNN) is typically {{viewed as the}} primary `generation' component. This view suggests that the image features should be `injected' into the RNN. This {{is in fact the}} dominant view in the literature. Alternatively, the RNN can instead be viewed as only encoding the previously generated words. This view suggests that the RNN should only be used to encode linguistic features and that only the final representation should be `merged' with the image features at a later stage. This paper compares these two architectures. We find that, in general, late merging outperforms injection, suggesting that RNNs are better viewed as encoders, rather than generators. Comment: Appears in: Proceedings of the 10 th International Conference on Natural Language Generation (INLG' 17...|$|E
40|$|Entity images {{could provide}} {{significant}} visual information for knowledge representation learning. Most conventional methods learn knowledge representations merely from structured triples, ignoring rich visual information extracted from entity images. In this paper, we propose a novel Image-embodied Knowledge Representation Learning model (IKRL), where knowledge representations are learned with both triple facts and images. More specifically, we first construct representations for all images of an entity with a <b>neural</b> <b>image</b> encoder. These image representations are then integrated into an aggregated image-based representation via an attention-based method. We evaluate our IKRL models on knowledge graph completion and triple classification. Experimental results demonstrate that our models outperform all baselines on both tasks, {{which indicates the}} significance of visual information for knowledge representations and the capability of our models in learning knowledge representations with images. Comment: 7 pages; Accepted by IJCAI- 201...|$|E
40|$|AbstractSegmentation of {{functional}} parts in image series {{of functional}} activity {{is a common}} problem in neuroscience. Here we apply regularized non-negative matrix factorization (rNMF) to extract glomeruli in intrinsic optical signal (IOS) images of the olfactory bulb. Regularization allows us to incorporate prior knowledge about the spatio-temporal characteristics of glomerular signals. We demonstrate how to identify suitable regularization parameters on a surrogate dataset. With appropriate regularization segmentation by rNMF is more resilient to noise and requires fewer observations than conventional spatial independent component analysis (sICA). We validate our approach in experimental data using anatomical outlines of glomeruli obtained by 2 -photon imaging of resting synapto-pHluorin fluorescence. Taken together, we show that rNMF provides a straightforward method for problem tailored source separation that enables reliable automatic segmentation of functional <b>neural</b> <b>images,</b> with particular benefit in situations with low signal-to-noise ratio as in IOS imaging...|$|R
40|$|Abstract. Extracting linear structures, such {{as blood}} vessels or dendrites, from images {{is crucial in}} many medical imagery applications, and many {{handcrafted}} features have been proposed to solve this problem. However, such features rely on assumptions that are never entirely true. Learned features, on the other hand, can capture image characteristics difficult to define analytically, but tend to be much slower to compute than handcrafted features. We propose to complement handcrafted methods with features found using very recent Machine Learning techniques, and we show that even few filters are sufficient to efficiently leverage handcrafted features. We demonstrate our approach on the STARE, DRIVE, and BF 2 D datasets, and on 2 D projections of <b>neural</b> <b>images</b> from the DIADEM challenge. Our proposal outperforms handcrafted methods, and pairs up with learning-only approaches {{at a fraction of}} their computational cost. ...|$|R
40|$|This paper {{presents}} a novel deep learning-based method for learning a functional representation of mammalian <b>neural</b> <b>images.</b> The method uses a deep convolutional denoising autoencoder (CDAE) for generating an invariant, compact representation of {{in situ hybridization}} (ISH) images. While most existing methods for bio-imaging analysis were not developed to handle images with highly complex anatomical structures, the results {{presented in this paper}} show that functional representation extracted by CDAE can help learn features of functional gene ontology categories for their classification in a highly accurate manner. Using this CDAE representation, our method outperforms the previous state-of-the-art classification rate, by improving the average AUC from 0. 92 to 0. 98, i. e., achieving 75 % reduction in error. The method operates on input images that were downsampled significantly with respect to the original ones to make it computationally feasible...|$|R
40|$|Developers of {{large-scale}} document processing and image recognition systems {{are in need}} of a dynamically robust character segmentation component. Without this essential module, potential turn-key products will remain in the laboratory indefinitely. An experiment of evolving a biologically-based <b>neural</b> <b>image</b> processing system which has the ability to isolate characters within an unstructured text image is presented. In this study, organisms are simulated using a genetic algorithm with the goal of learning the intelligent behavior required for locating and consuming text image characters. Each artificial life-form is defined by a genotype containing a list of interdependent control parameters which contribute to specific functions of the organism. Control functions include vision, consumption, and movement. Using asexual reproduction in conjunction with random mutation, a domain independent solution for text segmentation is sought. For this experiment, an organism's vision system utilize [...] ...|$|E
40|$|Motion {{tracking}} is {{a challenge}} the visual system has to solve by reading out the retinal population. Here we recorded a large population of ganglion cells in a dense patch of salamander and guinea pig retinas while displaying a bar moving diffusively. We show that the bar position can be reconstructed from retinal activity with a precision in the hyperacuity regime using a linear decoder acting on 100 + cells. The classical view would {{have suggested that the}} firing rates of the cells form a moving hill of activity tracking the bar's position. Instead, we found that ganglion cells fired sparsely over an area much larger than predicted by their receptive fields, so that the <b>neural</b> <b>image</b> did not track the bar. This highly redundant organization allows for diverse collections of ganglion cells to represent high-accuracy motion information in a form easily read out by downstream neural circuits. Comment: 23 pages, 7 figure...|$|E
40|$|This paper {{presents}} {{the work that}} has resulted in the SAT processor; a dedicated hardware implementation of a binary <b>neural</b> <b>image</b> processor. The SAT processor is aimed specifically at supporting the ADAM algorithm and is currently being integrated into {{a new version of the}} C-NNAP parallel image processor. The SAT processor performs binary matrix multiplications, a task that is computationally complex for a CPU with a standard instruction set. It can perform the matrix multiplication and thresholding between 100 and 200 times faster than the DSP 32 C that uses an in-house produced dedicated coprocessor. This speed-up will allow the SAT to process images of up to 220 x 220 pixels at 25 -Hz frame rates. 1 Introduction A significant obstacle to the use of binary associative memories in real-time image processing systems is the large quantity of data that requires processing. To overcome the processing bottleneck the Advanced Computer Architecture Group of the Department of Computer Science h [...] ...|$|E
40|$|Segmentation of {{functional}} parts in image series {{of functional}} activity {{is a common}} problem in neuroscience. Here we apply regularized non-negative matrix factorization (rNMF) to extract glomeruli in intrinsic optical signal (IOS) images of the olfactory bulb. Regularization allows us to incorporate prior knowledge about the spatio-temporal characteristics of glomerular signals. We demonstrate how to identify suitable regularization parameters on a surrogate dataset. With appropriate regularization segmentation by rNMF is more resilient to noise and requires fewer observations than conventional spatial independent component analysis (sICA). We validate our approach in experimental data using anatomical outlines of glomeruli obtained by 2 -photon imaging of resting synapto-pHluorin fluorescence. Taken together, we show that rNMF provides a straightforward method for problem tailored source separation that enables reliable automatic segmentation of functional <b>neural</b> <b>images,</b> with particular benefit in situations with low signal-to-noise ratio as in IOS imaging...|$|R
50|$|According to the UC Irvine {{academic}} catalogue, HSSoE research areas include: biochemical and bioreactor engineering, earthquake engineering, water resources, transportation, parallel {{and distributed}} computer systems, intelligent systems and <b>neural</b> networks, <b>image</b> and signal processing, opto-electronic devices and materials, high-frequency devices and systems, integrated micro and nanoscale systems, fuel cell technology, fluid mechanics, combustion and jet propulsion, materials processing, robotics, and modern control theory.|$|R
40|$|Abstract. This paper {{focuses on}} the {{evaluation}} of an ideal midsagittal plane (iMSP) extraction algorithm. The algorithm was developed for capturing the iMSP from 3 D normal and pathological <b>neural</b> <b>images.</b> The main challenges are the drastic structural asymmetry that often exists in pathological brains, and the sparse, nonisotropic data sampling that is common in clinical practice. A simple edge-based, cross-correlation approach is presented that decomposes the iMSP extraction problem into discovery of symmetry axes from 2 D slices, followed by robust estimation of 3 D plane parameters. The algorithm's tolerance to brain asymmetries, input image o sets and image noise is quantitatively measured. It is found that the algorithm can extract the iMSP from input 3 D images with (1) large asymmetrical lesions; (2) arbitrary initial yaw and roll angle errors; and (3) low signal-to-noise level. Also, no signi cant di erence is found between the iMSP computed by the algorithm and the midsagittal plane estimated by two trained neuroradiologists...|$|R
