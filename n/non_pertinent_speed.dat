0|12|Public
40|$|Abstract. In {{this paper}} {{we present a}} method to {{recognize}} shapes by analyzing a polygonal approximation of their boundaries. The method is independent of the used approximation method since its recognition strategy does not rely {{on the number of}} segments composing the shape. Length and turning angle information are extracted from the chain of seg-ments. The comparison method is invariant to scale, translation and some occlusions of the extracted contour. A simple pre-processing method, also based on arc-length features, is presented {{to be used as a}} coarse fitting method to determine angle rotation and as a first filter to eliminate <b>non</b> <b>pertinent</b> candidates. ...|$|R
30|$|The sixth test, “Colour Word Interference Task,” {{measures}} selectivity and {{the capacity}} to inhibit interference of <b>non</b> <b>pertinent</b> signals. It is an adjustment of classic Stroop test (1935) that requires the naming of the colour of ink used to print a word describing a different color (for example “red” written using blue ink), overcoming the interference originating from the habit of reading the word. The computerized adaptation of this test consists of two sequential tasks, the first, base line task, used as baseline and the second, interference task, as interference test. In this study this test was not used, considering that participants were not able to read.|$|R
5000|$|Questioned {{this myth}} of the {{presence}} of meaning in itself ("objective") and/or for itself ("subjective") Derrida will start a long deconstruction of all texts where conceptual oppositions are put to work in the actual construction of meaning and values based on the subordination of the movement of [...] "différance": At {{the point at which the}} concept of différance, and the chain attached to it, intervenes, all the conceptual oppositions of metaphysics (signifier/signified; sensible/intelligible; writing/speech; passivity/activity; etc.)- to the extent that they ultimately refer to the presence of something present (for example, in the form of the identity of the subject who is present for all his operations, present beneath every accident or event, self-present in its [...] "living speech," [...] in its enunciations, in the present objects and acts of its language, etc.)- become <b>non</b> <b>pertinent.</b> They all amount, at one moment or another, to a subordination of the movement of différance in favor {{of the presence of}} a value or a meaning supposedly antecedent to différance, more original than it, exceeding and governing it in the last analysis. This is still the presence of what we called above the [...] "transcendental signified." ...|$|R
40|$|Since the financial, {{social and}} {{economical}} scandals (from Enron to Parmalat), we try {{with the help}} of the laws concerning the corporate governance, to make less isolated the power of the companies from the exclusive confiscation of the managers concerning the participation of the parties. To achieve this objective, we are establishing a corporate governance closer to the Galbraithian technostructure. To reach this decentralization of power, we need the new technologies of information and communication to set up a knowledge governance widely spreading the information. Now, those who are at the first place take advantage of a hypermediatic system, to inundate it with <b>non</b> <b>pertinent</b> information, which deprive those who are in charge, in each level, of an essential subtract for a correct managing decision. The kickback was immediate. Depuis les scandales économiques, sociaux et financiers (d'Enron à Parmalat) on tente par la force des lois sur la corporate governance de désenclaver le pouvoir des entreprises; de la confiscation exclusive des dirigeants à la participation aux parties prenantes. Pour cela on est en train d'instituer une corporate governance plus proche de la technostructure Galbraitienne. Pour arriver à cette décentralisation du pouvoir on s'aide des nouvelles technologies d'information et de communication pour mettre en place une knowledge governance diffusant largement les in-formations. Or les caciques profitent d'un système hypermédiatique pour justement l'inonder d'informations non pertinentes qui privent des responsables de tous niveaux d'un substrat essen-tiel à la bonne décision de gestion. Le retour de bâton ne s'est pas fait attendre...|$|R
40|$|On August 23, 1978, a long cirrus plume, as {{detected}} by the GOES E satellite, made a sharp anticyclonic turn and traveled a total distance of 2800 km from the generating thunderstorm, as determined from satellite imagery. During a five-hour period {{the leading edge}} moved a distance of 550 km, giving a speed of 30 m/sec. This is in good agreement with the <b>pertinent</b> wind <b>speeds</b> at the presumed height of the cloud, which may indicate that cirrus evaporation {{may not have been}} too important. In a relatively dense portion of the cirrus the minimum equivalent blackbody temperature was 226 K...|$|R
40|$|The {{present study}} {{explored}} {{the effect of}} different degrees of relevance in discourse comprehension by using ERPs analysis. A principle of pragmatic relevance is supposed to guide inferential mechanism underlying discourse processing. Discourse level comprehension needs a system of predictions about which information is more relevant in order to process the ongoing sentence meaning. This system should construct a specific mental model, where inferences related to the present sentence are stored and maintained. Three degrees of relevance of a new information (new sentence) with respect to an old information (target sentence) were manipulated: directly relevant; indirectly relevant; not relevant. Twenty-one subjects participated to the experiment and {{they were asked to}} try to comprehend a set of two paired sentences (old-new paired sentences) based on their conceptual relevance. Two negative deflections, peaking respectively at about 410 msec post-stimulus (N 400), more right anterior-centrally distributed, and at about 550 msec (late negativity, LrN), more right central localized, were found. Repeated measures ANOVA found that the amplitude of both the N 400 and LrNis modulated by the degree of relevance and by the strength of the underlying associations between the two sentences. Indirect relevance resulted in increased negativities in comparison with direct relevance. Contrarily, non-relevant condition did not produce an increasing in N 400 and LrNamplitude. Unrelevance of the knowledge related to the actual mental model of sentences may induce a rapid and costless discarding of <b>non</b> <b>pertinent</b> information. The conclusive inference is that a subset of neural processes responding to degree of relevance of information is separable and cortically more frontally and centrally localized. Functional differences between N 400 and LrN for relevance were discussed...|$|R
40|$|International audienceToday, {{spatial data}} are {{increasingly}} {{available on the}} web and users can update their datasets more easily. Different sets of updates result from diverse sources are furnished to the user, each containing updates acquired in different manners, with different quality and at different times. A special context where the data and updates could come from different sources is a military mission. Indeed, the actors are distributed between different sites and one particularity {{is that they can}} be either a producer or a user of the data. They have their own dataset and can update them in several ways but must regularly supply their evolutions to the others actors in order to guarantee the success of the mission. Therefore, each actor receives many heterogeneous sets of updates and must integrate them in their own dataset in accordance with their needs. In this context, the user receives several set of heterogeneous updates which can have different quality, which can contain errors due to the manner they were acquired and they have to integrate them in their personal dataset. Thus, all the evolutions are not necessarily interesting for the user, and conversely one set of updates may not cover all the user needs. These heterogeneous sets of updates could also be concurrent each others and be concurrent with the user dataset. In this context, how can a user efficiently update his spatial dataset with some evolutions which are not necessarily pertinent and probably concurrent? This is the essential question to answer if we want to improve the update of spatial data by different sets of evolutions which are coming from multiple sites. In this paper, we will study the main problem arising when we integrate concurrent and heterogeneous updates and we will propose a process which helps the user to integrate efficiency multi-source updates into his dataset. This process comprises several steps : Firstly, we classify the evolutions to remove the heterogeneity, secondly we take into account the user needs and exclude the <b>non</b> <b>pertinent</b> data, thirdly we check the concurrency control between all the updates, and finally we reconcile the data if a conflict was detected. This process uses metadata to choose the “best” evolution to be integrated in the dataset. The metadata used are structured in accordance with the ISO 19115 standard specifications...|$|R
40|$|Researchers {{are turning}} {{more and more}} to {{evolutionary}} algorithms (EAs) as a flexible and effective technique for addressing timetabling problems in their institutions. We present a class of specialised mutation operators for use in conjunction with the commonly employed penaltyfunction based EA approach to timetabling which shows significant improvement in performance over a range of real and realistic problems. We also discuss the use of delta evaluation, an obvious and recommended technique which speeds up the implementation of the approach, and leads to a more <b>pertinent</b> measure of <b>speed</b> than the commonly used `number of evaluations'. A suite of realistically difficult benchmark timetabling problems is described and made available for use in comparative research...|$|R
40|$|A primary {{problem in}} the turbine {{industry}} {{is associated with the}} mitigation of bending vibration modes of high-speed rotating shafts. This is especially <b>pertinent</b> at <b>speeds</b> approaching the critical frequencies. Here, a shaft, complete with eccentric sleeves at the free ends, is designed and developed, with a view to passively control critical speeds and vibration induced bending. In this article, using the Extended Hamiltonâ��s principle, the equations of motion (axial, torsional, inplane and out-of-plane bending) for a rotating flexible shaft are derived; considering non-constant rotating speed, Coriolis and centrifugal forces, with the associated boundary conditions due to the eccentric sleeves and torsional springs in angular deformations of lateral vibrations in bending. The numerical dynamic analysis showed that considering the sleeves as flexible only had a small effect upon the first critical speed of the shaft. Therefore, rigid body modelling of the sleeves is sufficient to capture the essential dynamics of the system. The derived equations of motion with the associated boundary conditions show {{that in the case of}} constant rotating speed, the eccentric sleeves are coupling xy-bending with xz-bending and also torsion. Also the derived equations of motion and the associated boundary conditions in the case of non-constant rotating speed are essentially nonlinear due to inertia terms. This work is essential to the advance of linear and nonlinear dynamic analysis of the system by means of determination of normal modes and critical speeds of the shaft. Â© Springer International Publishing Switzerland 2015...|$|R
40|$|As {{an aid to}} {{airplane}} designers {{interested in}} providing pursuit airplanes with decelerating devices intended to increase the firing time when overtaking another airplane, formulas are given relating the <b>pertinent</b> distances and <b>speeds</b> in horizontal flight to the drag increase required. Charts are given for a representative parasite-drag coefficient from which the drag increase, the time gained, and the closing distance may be found. The charts are made up for three values of {{the ratio of the}} final speed of the pursuing airplane to the speed of the pursued airplane and for several values of the ratio of the speed of the pursued airplane to the initial speed of the pursuing airplane. Charts are also given indicating the drag increases obtainable with double split flaps and with conventional propellers. The use of the charts is illustrated by an example in which it is indicated that either double split flaps or, under certain ideal conditions, reversible propellers should provide the speed reductions required...|$|R
40|$|The {{past few}} years has {{witnessed}} tremendous upsurge in information availability in the electronic form, attributed to the ever mounting use of the World Wide Web (WWW). For many people, the World Wide Web has become an essential means of providing and searching {{for information leading to}} large amount of data accumulation. Searching web in its present form is however an infuriating experience {{for the fact that the}} data available is both superfluous and diverse in form. Web users end up finding huge number of answers to their simple queries, consequentially investing more time in analyzing the output results due to its immenseness. Yet many results here turn out to be irrelevant and one can find some of the more interesting links left out from the result set. Chapter 1 Introduces our motivation behind the research: One of the principal explanations for the unsatisfactory condition in information retrieval is the reason that majority of the existing data resources in its present form are designed for human comprehension. When using these data with machines, it becomes highly infeasible to obtain good results without human interventions at regular levels. So, one of the major challenges faced by the users as providers and consumers of web era is to imagine intelligent tools and theories in knowledge representation and processing for making the present data, machine understandable. Chapter 2 evaluates and studies the existing methods and their short falls: Several researches has been carried out in enable machines to understand data and some of the most interesting solutions proposed are the semantic web based ontology to incorporate data understanding by machines. The objective here is to intelligently represent data, enabling machines to better understand and enhance capture of existing information. Here the main emphasis is given to the thought for constructing meaning related concept networks for knowledge representation. Eventually the idea is to direct machines in providing output results of high quality with minimum or no human intervention. In recent years the development of ontology is fast gaining attention from various research groups across the globe. There are several definitions of ontology purely contingent on the application or task it is intended for. Chapter 3 presents the platform ToxNuc-E and positioning of our research around this platform: Given the practical and theoretical importance of ontology development, it is not surprising to find a large number of enthusiastic and committed research groups in this field. Extended Semantic Network is one such innovative approach proposed by us for knowledge representation and ontology like network construction, which looks for sets of associations between nodes semantically and proximally. Our objective here is to achieve semi-supervised knowledge representation technique with good accuracy and minimum human intervention, using the heuristically developed information processing and integration methods. The main goal of our research is to find an approach for automatic knowledge representation that can eventually be used in classification and search algorithms in the platform ToxNuc-E. Chapter 4 elaborates on the concept of Proximal Network modeling, generated by mathematical models: As stated earlier the basic idea of Extended Semantic Network is to identify an efficient knowledge representation and ontology construction method to overcome the existing constraints in information retrieval and classification problems. To realize this we put our ideas into practice via a two phase approach. The first phase consists in processing large amount of textual information using mathematical models to make our proposal of automatic ontology construction scalable. This phase of our proposal is carried out by realising a network of words mathematically computed using different statistical and clustering algorithms. Thus creating a proximal network computationally developed, depending essentially on word proximity in documents. The proximal network is basically representing the recall part of our approach. Chapter 5 investigates the semantic network modelling and introduces a design model proposed by us to enable efficient cost effective design: Semantic Network is basically a labelled, directed graph permitting the use of generic rules, inheritance, and object-oriented programming. It is often used as a form of knowledge representation where concepts represented by nodes are connected to one another using the relational links represented by arcs. Semantic network is constructed with the help of expert knowledge and understanding of a domain. Hence it is mainly a human constructed network with very good precision. Chapter 6 in effect details the extended semantic network: The second phase of our research mainly consists in examining carefully and efficiently the various possibilities of integrating information obtained from our mathematical model with that of the manually developed mind model. This phase is ensured by a heuristically developed method of network extension using the outputs from the mathematical approach. This is achieved by considering the manually developed semantic mind model as the entry point of our concept network. Here, the primary idea is to develop a innovative approach obtained by combining the features of man and machine theory of concepts, whose results can be of enormous use in the latest knowledge representation, classification, retrieval, pattern matching and ontology development research fields. In this research work we illustrate the methods used by us for information processing and integration aimed at visualising a novel method for knowledge representation and ontology construction. Chapter 7 illustrates some of the experiments carried out using our extended semantic network and opens directions for future perspectives: The question on knowledge representation, management, sharing and retrieval are both fascinating and complex, essentially with the co-emergence between man and machine. This research presents a novel collaborative working method, specifically in the context of knowledge representation and retrieval. The proposal is to attempt at making ontology construction faster and easier. The advantages of our methodology with respect to the previous work, is our innovative approach of integrating machine calculations with human reasoning abilities. The resulting network so obtained is later used in several tools ex: document classifier to illustrate our research approach. We use the precise, non estimated results provided by human expertise in case of semantic network and then merge it with the machine calculated knowledge from proximal results. The fact that we try to combine results from two different aspects forms one of the most interesting features of our current research. We view our result as structured by mind and calculated by machines. One of the main future perspectives of this research is finding the right balance for combining the concept networks of semantic network with the word network obtained from the proximal network. Our future work would be to identify this accurate combination between the two vast methods and setting up a benchmark to measure our prototype efficiency. Ces dernières années ont vu le déferlement d'une vague d'information sous forme électronique liée à l'usage croissant du World Wide Web (WWW). Pour beaucoup, le World Wide Web est devenu un moyen essentiel pour mettre à disposition ou rechercher de l'information, conduisant à une forte accumulation de données. La recherche sur Internet dans sa forme présente devient vite exaspérante car les données disponibles peuvent être superficielles et de formes très diverses. Les utilisateurs du Web en ont assez d'obtenir des ensembles gigantesques de réponses à leurs requêtes simples, ce qui les oblige à investir de plus en plus de temps pour analyser les résultats. De nombreux résultats s'avèrent <b>non</b> <b>pertinents</b> et les liens les plus intéressants restent souvent en dehors de l'ensemble des résultats. Le chapitre 1 introduit la motivation de notre travail de recherche. L'une des principales explications concernant la difficulté à effectuer une recherche d'information efficace est que les ressources existantes sur le web sont exprimées sous une forme destinée à la compréhension humaine. En d'autres termes, ces données sont difficilement utilisables par la machine et l'intervention humaine s'avère indispensable. Ainsi, l'un des principaux challenges est d'imaginer des outils intelligents fondés sur les concepts et méthodes autour de la représentation et du traitement des connaissances pour créer des données exploitables par la machine et obtenir de meilleurs résultats. Le chapitre 2 évalue et étudie les méthodes existantes et leurs limitations. De nombreux chercheurs ont travaillé sur la problématique de la compréhension des données par la machine et certaines des solutions les plus intéressantes sont les ontologies basées sur le « web sémantique ». Les ontologies permettent une meilleure « compréhension » des documents et facilitent à l'aide d'outils appropriés la qualité des recherches dans l'information existante. L'accent est mis sur la réflexion nécessaire à la construction de la signification du concept relié aux réseaux pour la représentation des connaissances. L'idée est de tendre vers la production semi-automatique voire complètement automatique de résultats de grande qualité. Autrement dit, l'objectif est de minimiser l'intervention humaine est de maximiser la qualité des résultats obtenus. Le chapitre 3 présente la plate-forme ToxNuc-E et le positionnement de notre recherche autour de cette plate-forme. Etant donné l'importance pratique et théorique du développement d'ontologies, il n'est pas surprenant de retrouver un grand nombre de chercheurs, fervents et engagés dans ce domaine de recherche. Dans le cadre de notre travail de recherche nous proposons une approche nouvelle, dite ESN (« Extended Semantic Network »), qui contrairement aux approches classiques, basées sur les mots clés, fonde la construction d'ontologie sur la convergence d'associations entre concepts ou nœuds sémantiques sur un ensemble de thèmes et la proximité des termes dans un ensemble de documents. Notre terrain d'application est le programme de toxicologie nucléaire environnementale français : ToxNuc-E. Le chapitre 4 précise le concept de « réseau de proximité », généré par des modèles mathématiques. L'idée de base de notre approche ESN est de construire efficacement une ontologie adaptée à la recherche d'information dans de larges corpus. La première phase consiste à traiter une grande quantité d'information textuelle en utilisant des modèles mathématiques pour automatiser la construction d'un embryon d'ontologie. L'objectif est d'obtenir un réseau de mots qui peut être assez volumineux. Celui-ci est calculé en utilisant des outils mathématiques venant de l'analyse de données et la classification automatique. Ainsi, la création d'un réseau de proximité repose alors sur la proximité des mots dans un document. Le chapitre 5 présente la construction des « réseaux sémantiques » et introduit notre modèle de conception pour gagner en efficacité. Le réseau sémantique est essentiellement un graphe orienté étiqueté permettant l'utilisation de règles génériques, de l'héritage, et de la représentation orientée objet. Il est souvent utilisé comme une forme de représentation des connaissances, où les concepts représentés par les nœuds sont connectés l'un à l'autre en utilisant les liens relationnels représentés par des arcs. Le réseau sémantique est construit de façon manuelle avec l'aide d'experts de la connaissance possédants la compréhension d'un domaine. Il est donc principalement construit par les hommes, dans notre approche de taille assez réduite, et d'une très bonne précision. Le chapitre 6 détaille le « réseau sémantique étendu ». La deuxième phase de traitement consiste à examiner attentivement et de manière efficace les différentes possibilités d'intégrer les informations issues du modèle mathématique (réseau de proximité) et du modèle cognitif développé manuellement (réseau sémantique). Cette phase se base sur une méthode heuristique développée dans l'extension des réseaux et utilisant les résultats de la méthode mathématique. Cette phase se termine en considérant le modèle humain (développé manuellement) comme le point d'entrée de notre réseau de concepts. L'idée principale est de développer une approche novatrice combinant les caractéristiques humaines et la théorie des concepts utilisée par la machine. Les résultats peuvent présenter un grand intérêt dans différents champs de recherche tels que la représentation des connaissances, la classification, l'extraction, ainsi que le filtrage des données. Le chapitre 7 illustre quelques expérimentations réalisées à l'aide de notre réseau sémantique étendu et ouvre des orientations pour les perspectives d'avenir. Les questions concernant la représentation des connaissances, la gestion, le partage et l'extraction d'information sont passionnantes et complexes. Cet attrait est en toute évidence essentiellement du aux rapports entre l'homme et la machine. Le fait que nous essayons de combiner les résultats de deux aspects différents constitue l'une des caractéristiques les plus intéressantes de notre recherche actuelle. Notre proposition peut faciliter la construction d'ontologies de manière plus rapide et plus simple. Le réseau sémantique étendu peut être utilisé, à la place d'une ontologie plus classique, par des outils comme par exemple : un classificateur de documents. Nous considérons notre résultat comme étant structuré par l'esprit et calculé par la machine. L'une des principales perspectives pour le travail à suivre est de trouver un bon compromis entre concepts du réseau sémantique et graphes de mot issus du réseau de proximité. D'autres perspectives à ce travail consistent à mettre en place des benchmarks dans différents contextes pour mesurer l'efficacité de notre prototype...|$|R

