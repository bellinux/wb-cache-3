6|6|Public
25|$|OSIRIS (Optical, Spectroscopic, and Infrared Remote Imaging System). The {{camera system}} has a <b>narrow-angle</b> <b>lens</b> (700mm) and a {{wide-angle}} lens (140mm), with a 2048×2048 pixel CCD chip. The instrument {{was constructed in}} Germany.|$|E
50|$|The imager payload aboard CanX-1 {{consists}} of two Agilent CMOS imagers. The color imager {{in conjunction with a}} wide-angle lens was intended primarily for taking photographs of Earth, and the monochrome imager in conjunction with a <b>narrow-angle</b> <b>lens</b> was for testing the feasibility of taking star, moon, and horizon pictures which could then be used for attitude determination and control.|$|E
50|$|During {{this first}} broadcast, the crew gave {{a tour of}} the {{spacecraft}} and attempted to show how the Earth appeared from space. However, difficulties aiming the <b>narrow-angle</b> <b>lens</b> without the aid of a monitor to show what it was looking at made showing the Earth impossible. Additionally, the Earth image became saturated by any bright source without proper filters. In the end, all the crew could show the people watching back on Earth was a bright blob. After broadcasting for 17 minutes, the rotation of the spacecraft took the high-gain antenna out of view of the receiving stations on Earth and they ended the transmission with Lovell wishing his mother a happy birthday.|$|E
40|$|We have {{developed}} a new stereoscopic video system (the Q stereoscopic system) which has higher resolution at the central area than others. The Q stereoscopic video system is composed of four video cameras and four video displays. Two of tile four cameras, to which wide-angle lenses are attached, are combined into a stereoscopic camera system. And the remaining two cameras, to which <b>narrow-angle</b> <b>lenses</b> are attached, are adjusted {{to have the same}} optical center axis as each of the wide-angle cameras. The Q stereoscopic display system is composed of two large video displays and two smaller video displays. The former receive images from the wide-angle stereoscopic cameras, and the latter receive images from the narrow-angle stereoscopic cameras. With this system, human operators can see wide stereoscopic compound images that have a high resolution center. In cases in which it is necessary to do detailed work with objects that scattered over a wide working space, the Q stereoscopic system is highly effective...|$|R
25|$|The Imaging Science Subsystem, {{made up of}} a {{wide angle}} and a narrow angle camera, is a {{modified}} version of the slow scan vidicon camera designs that were used in the earlier Mariner flights. The Imaging Science Subsystem consists of two television-type cameras, each with eight filters in a commandable filter wheel mounted in front of the vidicons. One has a low resolution 200mm focal length wide-angle lens with an aperture of f/3 (the wide angle camera), while the other uses a higher resolution 1500mm <b>narrow-angle</b> f/8.5 <b>lens</b> (the narrow angle camera).|$|R
40|$|Abstract. This paper {{proposes a}} generic self-calibration method for central cam-eras. The method {{requires}} two-view point correspondences and estimates both {{the internal and}} external camera parameters by minimizing angular error. In the minimization, we use a generic camera model which is suitable for central cam-eras with different kinds of radial distortion models. The proposed method can be hence applied to a large range of cameras from <b>narrow-angle</b> to sh-eye <b>lenses</b> and catadioptric cameras. Here the camera parameters are estimated by minimiz-ing the angular error which does not depend on the 3 D coordinates of the point correspondences. However, the error still has several local minima and in order to avoid these we propose a multi-step optimization approach. We demonstrate our method in experiments with synthetic and real data. ...|$|R
40|$|We present two simple {{approaches}} to calibrate a stereo camera setup with heterogeneous lenses: a wide-angle fish-eye lens and a <b>narrow-angle</b> <b>lens</b> in {{left and right}} sides, respectively. Instead of using a conventional black-white checkerboard pattern, we design an embedded checkerboard pattern by combining two differently colored patterns. In both approaches, we split the captured stereo images into RGB channels and extract R and inverted G channels from left and right camera images, respectively. In our first approach, we consider the checkerboard pattern as the world coordinate system and calculate left and right transformation matrices corresponding to it. We use these two transformation matrices to estimate the relative pose of the right camera by multiplying the inversed left transformation with the right. In the second approach, we calculate a planar homography transformation to identify common object points in left-right image pairs and treat them with the well-known Zhangs camera calibration method. We analyze the robustness of these two approaches by comparing reprojection errors and image rectification results. Experimental {{results show that the}} second method is more accurate than the first one...|$|E
40|$|An {{infrared}} scanner covering the 200 to 540 -nanometer wavelength region has been flown over the coastline of the Puna and Kau Districts {{on the island}} of Hawaii. The images were monitored in real-time and recorded on film. Only a 5 ° x 5 ° lens (narrow-angle) was available, hence the flight line had to be at an altitude of 11, 000 feet in order to make each image about 1000 feet on a side. The films of the images have been processed and catalogued. A few areas have been mosaicked to facilitate interpretation. This report briefly describes the equipment used, the field procedures followed, and presents an index to the catalogued films. A few frames and mosaics are presented to illustrate the image quality. The procedure in its entirety is rather complex and much practice is necessary to obtain high quality images. The greatest difficulty seems to be due to the high-level flight line demanded by the <b>narrow-angle</b> <b>lens.</b> Future surveys will use wide angle lens, such as has just become available. U. S. Department of the Interior Grant/Contract No. 14 - 01 - 0001 - 1494; B- 008 -H...|$|E
40|$|We {{propose a}} method of {{simultaneously}} calibrating the radialdistortion functionof a camera alongwith the otherinternal calibration parameters. The method relies {{on the use of}} a planar (or alternatively non-planar) calibration grid, which is captured in several images. In this way, the determination of the radial distortion is an easy add-on to the popular calibration method proposed by Zhang [17]. The method is entirely non-iterative, and hence is extremely rapid and immune from the problem of local minima. Our method determines the radial distortion in a parameter-free way, not relying on any particular radial distortion model. This makes it applicable to a large range of cameras from <b>narrow-angle</b> to fish-eye <b>lenses.</b> The method also computes the centre of radial distortion, which we argue is important in obtaining optimal results. Experiments show that this point may be significantly displaced from the centre of the image, or the principal point of the camera. ...|$|R
40|$|Abstract—We {{propose a}} method of {{simultaneously}} calibrating the radial distortion function of a camera and the other internal calibration parameters. The method relies {{on the use of}} a planar (or, alternatively, nonplanar) calibration grid which is captured in several images. In this way, the determination of the radial distortion is an easy add-on to the popular calibration method proposed by Zhang [24]. The method is entirely noniterative and, hence, is extremely rapid and immune to the problem of local minima. Our method determines the radial distortion in a parameter-free way, not relying on any particular radial distortion model. This makes it applicable to a large range of cameras from <b>narrow-angle</b> to fish-eye <b>lenses.</b> The method also computes the center of radial distortion, which, we argue, is important in obtaining optimal results. Experiments show that this point may be significantly displaced {{from the center of the}} image or the principal point of the camera. Index Terms—Radial distortion, camera calibration, fundamental matrix. ...|$|R

