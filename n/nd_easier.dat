1|11|Public
40|$|Border {{trade between}} India and its {{neighbouring}} countries is largely determined by ethnic ties, affi nity, long porous borders and low transaction costs. The ineffi ciencies and high transaction {{costs associated with}} formal trade have helped to promote informal trade, which traders fi <b>nd</b> <b>easier</b> and more convenient. The feature that distinguishes cross-border trade between India and Myanmar from trade with other neighbouring countries is {{the adoption of a}} barter system. There is also a missing link between the border trade and production structure (both agriculture and industry) of the northeastern region of India, particularly Manipur, so that the larger gains from trade accrue to traders operating beyond the northeastern region...|$|E
40|$|L. Dubins, J. Feldman, M. Smorodinsky and B. Tsirelson gave {{an example}} of an {{equivalent}} measure Q on standard Wiener space such that each adapted Q-Brownian motion generates a strictly smaller ltration then the original one. The construction of this important example is complicated and technical. We give a variant of their construction which di ers in some of the technicalities but essentially follows their ideas, hoping that some readers may <b>nd</b> our presentation <b>easier</b> to digest than the original papers. 1...|$|R
40|$|Since their introduction, {{hundreds}} of dierent design patterns {{have been discovered}} and documented to address a variety of problems we encounter in software design and construction. However, to use {{any one of these}} design patterns eectively and quickly, one must have access to a design pattern denition that unambiguously gives away its intended purpose, and <b>nd</b> an <b>easy</b> way to choose one design pattern from among a family of related design patterns. Existing research is either lacking or has not addressed these issues adequately. We propose a new process by which we can organize design patterns and allow for easy identication and dierentiation among them. We rely on and adapt some linguistic theories to analyze design patterns; use some complex algebraic structures to structure hierarchical concepts that de-scribe design patterns; and utilize some general and reliable classication theories that were used successfully in compiling dictionaries and thesauri of natural languages. ...|$|R
40|$|Tesi realitzada en el marc d'un conveni de col·laboració amb la Aalto University. Analysis and {{implementation}} of a SSO solution for several web portal. When we talk about Single Sign-On (SSO), there is much new research done during the last years. The main goal of SSO {{is to provide a}} unique way to authenticate users along many websites. Due to the structure of the Active Life and the other partners portals, a SSO is needed to access to the data by the easiest way. Moreover, the portal is targeted also to elderly people who should <b>nd</b> as <b>easy</b> as possible to authenticate within the portal. This is the reason why the SSO needs to be properly implemented. The theoretical part of this Thesis is focused in the existing SSO systems, which one ts better into the system and how do they work. After this, the implementation of the selected SSO is explained and discussed, as well as linked with the theory. At the end of the Thesis, the conclusions and di culties found are reported...|$|R
40|$|Effective Polyakov line {{actions are}} a {{powerful}} tool to study the finite temperature behaviour of lattice gauge theories. They are much simpler to simulate than the original (3 + 1) dimensional LGTs and are affected by a milder sign problem. However {{it is not clear}} to which extent they really capture the rich spectrum of the original theories, a feature which is instead of great importance if one aims to address the sign problem. We propose here a simple way to address this issue based on the so called second moment correlation length ξ_ 2 nd. The ratio ξ/ξ_ 2 nd between the exponential correlation length and the second moment one is equal to 1 if only a single mass is present in the spectrum, and becomes larger and larger as the complexity of the spectrum increases. Since both ξ_exp and ξ_ 2 <b>nd</b> are <b>easy</b> to measure on the lattice, this is an economic and effective way {{to keep track of the}} spectrum of the theory. In this respect we show using both numerical simulation and effective string calculations that this ratio increases dramatically as the temperature decreases. This non-trivial behaviour should be reproduced by the Polyakov loop effective action. Comment: 8 pages, 1 figure. Talk presented at the 35 th International Symposium on Lattice Field Theory, 18 - 24 June 2017, Granada, Spai...|$|R
40|$|Most {{automated}} theorem provers {{suffer from}} the problem that they can produce proofs only in formalisms difficult to understand even for experienced mathematicians. Effort {{has been made to}} reconstruct natural deduction (ND) proofs from such machine generated proofs. Although the single steps in <b>ND</b> proofs are <b>easy</b> to understand, the entire proof is usually at a low level of abstraction, containing too many tedious steps. To obtain proofs similar to those found in mathematical textbooks, we propose a new formalism, called ND style proofs at the assertion level, where derivations are mostly justified by the application of a definition or a theorem. After characterizing the structure of compound ND proof segments allowing assertion level justification, we show that the same derivations can be achieved by domain-specific inference rules as well. Furthermore, these rules can be represented compactly in a tre structure. Finally, we describe a system called PROVERB, which substantially sh [...] ...|$|R
40|$|Most {{automated}} theorem provers {{suffer from}} the problem thatthey can produce proofs only in formalisms difficult to understand even forexperienced mathematicians. Effort {{has been made to}} reconstruct naturaldeduction (ND) proofs from such machine generated proofs. Although thesingle steps in <b>ND</b> proofs are <b>easy</b> to understand, the entire proof is usuallyat a low level of abstraction, containing too many tedious steps. To obtainproofs similar to those found in mathematical textbooks, we propose a newformalism, called ND style proofs at the assertion level, where derivationsare mostly justified by the application of a definition or a theorem. Aftercharacterizing the structure of compound ND proof segments allowing asser-tion level justification, we show that the same derivations can be achieved bydomain-specific inference rules as well. Furthermore, these rules can be rep-resented compactly in a tree structure. Finally, we describe a system calledPROVERB, which substantially shortens ND proofs by abstracting them tothe assertion level and then transforms them into natural language...|$|R
40|$|Non-determinism (ND) is a {{fundamental}} concept in com-puter science, and comes in two main flavors. One {{is the kind of}} ND that appears in automata theory and formal lan-guages. The other, which we term operative, appears in non-deterministic programming languages and in the context of concurrent and distributed systems. We believe {{that it is important to}} teach the two types of ND, especially as ND has become a very prominent characteristic of computerized systems. Currently, students are mainly introduced to ND of the first type, which is known to be hard to teach and learn. Our findings suggest that learning operative <b>ND</b> might be <b>easier,</b> and that students can reach a significant understand-ing of this concept when it is introduced in the context of a programming course that deals with a non-deterministic programming language like the language of Live Sequence Charts (LSC). Based on that, we suggest teaching operative ND in the context of concurrent and distributed program-ming, a topic which is covered by a new knowledge area tha...|$|R
40|$|Effective Polyakov line {{actions are}} a {{powerful}} tool to study the finite temperature behaviour of lattice gauge theories. They are much simpler to simulate than the original lattice model and are affected by a milder sign problem, {{but it is not}} clear to which extent they really capture the rich spectrum of the original theories. We propose here a simple way to address this issue based on the so called second moment correlation length ξ_ 2 nd. The ratio ξ/ξ_ 2 nd between the exponential correlation length and the second moment one is equal to 1 if only a single mass is present in the spectrum, and it becomes larger and larger as the complexity of the spectrum increases. Since both ξ and ξ_ 2 <b>nd</b> are <b>easy</b> to measure on the lattice, this is a cheap and efficient way to keep track of the spectrum of the theory. As an example of the information one can obtain with this tool we study the behaviour of ξ/ξ_ 2 nd in the confining phase of the (D= 3 + 1) SU(2) gauge theory and show that it is compatible with 1 near the deconfinement transition, but it increases dramatically as the temperature decreases. We also show that this increase can be well understood in the framework of an effective string description of the Polyakov loop correlator. This non-trivial behaviour should be reproduced by the Polyakov loop effective action; thus, it represents a stringent and challenging test of existing proposals and it may be used to fine-tune the couplings and to identify the range of validity of the approximations involved in their construction. Comment: 1 + 17 pages, 3 pdf figures; v 2 : 1 + 17 pages, 3 pdf figures: discussion in section 1, 2 and 5 expanded, misprints corrected; matches journal versio...|$|R
40|$|The goal of {{the study}} was to examine whether {{speakers}} naming pairs of objects would retrieve the names of the objects in parallel or in equence. To this end, we recorded the speakers’ eye movements and determined whether the difficulty of retrieving the name of the 2 nd object affected the duration of the gazes to the 1 st object. Two experiments, which differed in the spatial arrangement of the objects, showed that the speakers looked longer at the 1 st object when the name of the 2 <b>nd</b> object was <b>easy</b> than when it was more difficult to retrieve. Thus, the easy 2 nd-object names interfered more with the processing of the 1 st object than the more difficult 2 nd-object names. In the 3 rd experiment, the processing of the 1 st object was rendered more difficult by presenting it upside down. No effect of 2 nd-object difficulty on the gaze duration for the 1 st object was found. These results suggest that speakers can retrieve the names of a foveated and an extrafoveal object in parallel, provided that the processing of the foveated object is not too demandin...|$|R
40|$|The {{last decade}} {{has seen a}} signifi cant {{increase}} in {{the research and development}} of CO 2 capture and storage (CCS) technology. CCS is now considered {{to be one of the}} key options for climate change mitigation. This perspective provides a brief summary of the state of the art regarding CCS development and discusses the implications for the further development of CCS, particularly with respect to climate change policy. The aim is to provide general perspectives on CCS, although examples used to illustrate the prospects for CCS are mainly taken from Europe. The rationale for developing CCS should be the over-abundance of fossil fuel reserves (and resources) in a climate change context. However, CCS will only be implemented if society is willing to attach a suffi ciently high price to CO 2 emissions. Although arguments have been put forward both in favor and against CCS, the author of this perspective argues that the most important outcome from the successful commercialization of CCS will be that fossil-fuel-dependent economies will fi <b>nd</b> it <b>easier</b> to comply with stringent greenhouse gas (GHG) reduction targets. In contrast, failure to implement CCS will require that the global community agrees almost immediately to start phasing out the use of fossil fuels; such an agreement seems more unrealistic than reaching a global agreement on stringent GHG reductions. Thus, in the near term, it is crucial to initiate demonstration projects, such as those supported by the EU. If this is not done, there is a risk that the introduction of CCS will be signifi cantly delayed. Among the stakeholders in CCS technologies (R&D actors in industry and academia), the year 2020 is typically considered to be the year in which CCS will be commercially available. Considering the lead times for CCS development and the slow pace of implementation of climate policy (post-Copenhagen), the target year of 2020 seems rather optimistic...|$|R
40|$|An {{alternative}} to the traditional approaches to model separately 2 D/ 3 D space, time, scale and other parametrisable characteristics in GIS lies in the higher-dimensional modelling of geographic information, in which a chosen set of non-spatial characteristics, e. g. time and scale, are modelled as extra geometric dimensions perpendicular to the spatial ones, thus creating a higher dimensional model. While higher-dimensional models are undoubtedly powerful, they are also hard to create and manipulate due to our lack of an intuitive understanding in dimensions higher than three. As {{a solution to this}} problem, this paper proposes a methodology that makes <b>nD</b> object generation <b>easier</b> by splitting the creation and manipulation process into three steps: (i) constructing simple nD objects based on nD prismatic polytopes—analogous to prisms in 3 D—, (ii) defining simple modification operations at the vertex level, and (iii) simple postprocessing to fix errors introduced in the model. As a use case, we show how two sets of operations can be defined and implemented in a dimension-independent manner using this methodology: the most common transformations (i. e. translation, scaling and rotation) and the collapse of objects. The nD objects generated in this manner can then be used as a basis for an nD GIS. 3 D Geo-Informatio...|$|R

