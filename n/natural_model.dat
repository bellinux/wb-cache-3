697|3367|Public
5|$|Reversible {{cellular}} automata form a <b>natural</b> <b>model</b> of reversible computing, {{a technology}} {{that could lead to}} ultra-low-power computing devices. Quantum cellular automata, one way of performing computations using the principles of quantum mechanics, are often required to be reversible. Additionally, many problems in physical modeling, such as the motion of particles in an ideal gas or the Ising model of alignment of magnetic charges, are naturally reversible and can be simulated by reversible cellular automata.|$|E
25|$|A <b>natural</b> <b>model</b> {{of passive}} {{learning}} is Valiant's probably approximately correct (PAC) learning. Here the learner receives random examples (x,c(x)), where x is distributed {{according to some}} unknown distribution D. The learner's goal is to output a hypothesis function h such that h(x)=c(x) with high probability when x is drawn according to D. The learner {{has to be able}} to produce such an 'approximately correct' h for every D and every target concept c in its concept class.|$|E
25|$|Besides {{providing}} a uniform description of circles, ellipses, parabolas, and hyperbolas, conic sections {{can also be}} understood as a <b>natural</b> <b>model</b> of the geometry of perspective in the case where the scene being viewed consists of circles, or more generally an ellipse. The viewer is typically a camera or the human eye and the image of the scene a central projection onto an image plane, i.e., all projection rays pass a fixed point O, the center. The lens plane is a plane parallel to the image plane at the lens O.|$|E
40|$|Advertisements often display ideal female bodies which create {{unattainable}} {{standards of}} beauty, generating body anxiety and disorders in female viewers. Accordingly, public health concerns would encourage {{the use of}} <b>natural,</b> unedited <b>models</b> in advertisements. However, the advertising performance of <b>natural</b> <b>models</b> remains contentious. We argue that previous inconsistent findings about this performance may result from a complex causal framework in which <b>natural</b> <b>models</b> impact performance through two affective mediators (body anxiety, and repulsion toward the model), while allowing moderation by the viewer's own body mass index (BMI). Data collected in a nationally representative sample of 400 young women largely (but not entirely) validate this causal framework. <b>Natural</b> <b>models</b> triggered repulsion in viewers with higher BMI, which hurt advertising performance. Body anxiety, however, was positively correlated with advertising performance, and did not mediate any effect of <b>natural</b> <b>models...</b>|$|R
5000|$|... 1989: John Torreano: <b>Natural</b> <b>Models</b> and Material Illusions. The Corcoran Gallery of Art, Washington DC ...|$|R
40|$|While {{modelling}} research typically {{concentrates on}} its more technical and formal aspects, this paper provides {{a case for}} what we coin <b>natural</b> <b>modelling.</b> Modelling has always been and will always remain a humanintensive activity. To be adopted at large, modelling technologies should be perceived as natural as possible. In order to characterise what natural means, this paper briefly provides an anthropological and historical perspective on modelling. Constituting per se a first contribution, this retrospective allows to exhibit fundamental modelling concepts, spanning across ages. By looking backwards {{to understand what was}} <b>natural</b> (in) <b>modelling</b> in the past, this paper aims to define some elements for what could what computer-assisted <b>natural</b> <b>modelling</b> could be in the future. More specifically, it is argued that (1) the need for compromises between flexibility and formality is rather natural than extreme, (2) languages are emergent by their very nature and continuously evolve, and (3) <b>natural</b> interaction with <b>modelling</b> technology should be provided to all stakeholders, as it strongly promotes stakeholders participation. Although these aspects took different forms in historical developments of technology, we argue that the principles are still relevant today, and that these should be considered in the future research. The paper ends with some simple illustrations, which help provide the insight on how computer-assisted <b>natural</b> <b>modelling</b> could look like in a possible future...|$|R
2500|$|Graph {{theory is}} also used to study {{molecules}} in chemistry and physics. In condensed matter physics, the three-dimensional structure of complicated simulated atomic structures can be studied quantitatively by gathering statistics on graph-theoretic properties related to the topology of the atoms. In chemistry a graph makes a <b>natural</b> <b>model</b> for a molecule, where vertices represent atoms and edges bonds. This approach is especially used in computer processing of molecular structures, ranging from chemical editors to database searching. In statistical physics, graphs can represent local connections between interacting parts of a system, as well as the dynamics of a physical process on such ...|$|E
60|$|For {{the first}} few miles our path lay over a country cleared for rice-fields, {{consisting}} entirely of small but deep and sharply-cut ridges and valleys without a yard of level ground. After crossing the Kayan river, a main branch of the Sadong, we got on to the lower slopes of the Seboran Mountain, and the path lay along a sharp and moderately steep ridge, affording an excellent view of the country. Its features were exactly those of the Himalayas in miniature, as they are described by Dr. Hooker and other travellers, and looked like a <b>natural</b> <b>model</b> of some parts of those vast mountains {{on a scale of}} about a tenth--thousands of feet being here represented by hundreds. I now discovered the source of the beautiful pebbles which had so pleased me in the riverbed. The slatey rocks had ceased, and these mountains seemed to consist of a sandstone conglomerate, which was in some places a mere mass of pebbles cemented together. I might have known that such small streams could not produce such vast quantities of well-rounded pebbles of the very hardest materials. They had evidently been formed in past ages, by the action of some continental stream or seabeach, before the great island of Borneo had risen from the ocean. The existence of such a system of hills and valleys reproducing in miniature all the features of a great mountain region, has an important bearing on the modern theory that the form of the ground is mainly due to atmospheric rather than to subterranean action. When {{we have a number of}} branching valleys and ravines running in many different directions within a square mile, it seems hardly possible to impute their formation, or even their origination, to rents and fissures produced by earthquakes. On the other hand, the nature of the rock, so easily decomposed and removed by water, and the known action of the abundant tropical rains, are in this case, at least, quite sufficient causes for the production of such valleys. But the resemblance between their forms and outlines, their mode of divergence, and the slopes and ridges that divide them, and those of the grand mountain scenery of the Himalayas, is so remarkable, that we are forcibly led to the conclusion that the forces at work in the two cases have been the same, differing only in the time they have been in action, and the nature of the material they have had to work upon.|$|E
50|$|Matrix {{planting}} {{is based}} on this <b>natural</b> <b>model.</b> It aims to set up similar self-sustaining communities in gardens, by bringing together plants that meld {{with one another in}} a balance: all survive and flourish; weeds are excluded.|$|E
30|$|Both {{regression}} and single-label classification methods {{suffer from}} the same problem: two different (clusters of) emotions cannot be simultaneously predicted. Multi-label classification allows for a <b>natural</b> <b>modeling</b> of this issue.|$|R
40|$|This {{thesis is}} divided into two parts. In the first of these we {{consider}} Ackermann-type set theories and many of our results concern <b>natural</b> <b>models.</b> We prove a number of results about the existence of <b>natural</b> <b>models</b> of Ackermann's set theory, A, and applications of this work are shown to answer several questions raised by Reinhardt in [56]. A + (introduced in [56]) is another Ackermann-type set theory and we show that its set theoretic part is precisely ZF. Then we introduce the notion of <b>natural</b> <b>models</b> of A + and show how our results on <b>natural</b> <b>models</b> of A extend to these models. There are a number of results about other Ackermann-type set theories and some of the work which was already known for ZF is extended to A. This includes permutation models, which are shown to answer another of Reinhardt's questions. In the second part we consider the different approaches to set theory; dealing mainly with the more philosophical aspects. We reconsider Cantor's work, suggest that it has frequently been misunderstood and indicate how quasi-constructive set theories seem to use a definite part of Cantor's earlier ideas. Other approaches to set theory are also considered and criticised. The section on NF includes some more technical observations on ordered pairs. There is also an appendix, in which we outline some results on extended ordinal arithmetic. <p...|$|R
40|$|In {{this paper}} we compare the {{estimates}} of the range model in Lye and McDonald (2005 a) with estimates of a <b>natural</b> rate <b>model.</b> We find that the range model is superior to the <b>natural</b> rate <b>model</b> according to econometric criteria and economic plausibility. Our estimates of the range model suggest that a significantly lower rate of unemployment is obtainable at the current time by aggregate demand policy, indeed a rate of 3. 1 per cent for 2003 : 3 compared with about 6. 5 per cent for the <b>natural</b> rate <b>model.</b> Thus we conclude that basing macroeconomic policy on the <b>natural</b> rate <b>model</b> would underrate the possibilities for economic welfare in Australia. Copyright Blackwell Publishing Ltd/ University of Adelaide and Flinders University 2006. ...|$|R
50|$|Simplicial {{objects in}} a {{category}} are a frequent source of model categories; for instance, simplicial commutative rings or simplicial R-modules admit <b>natural</b> <b>model</b> structures. This follows {{because there is}} an adjunction between simplicial sets and simplicial commutative rings (given by the forgetful and free functors), and in nice cases one can lift model structures under an adjunction.|$|E
5000|$|The {{notion of}} a tuple in type theory and that in set theory are related in the {{following}} way: If we consider the <b>natural</b> <b>model</b> of a type theory, and use the Scott brackets to indicate the semantic interpretation, then the model consists of some sets [...] (note: the use of italics here that distinguishes sets from types) such that: ...|$|E
5000|$|Performing {{empirical}} {{statistics on}} this tangent {{space at the}} identity is the natural way for inducing probability laws on the statistics of shape. Since both the vector fields and the Eulerian momentum [...] are in a Hilbert space the <b>natural</b> <b>model</b> {{is one of a}} Gaussian random field, so that given test function , then the inner-products with the test functions are Gaussian distributed with mean and covariance.|$|E
40|$|We {{construct}} and study space homogeneous and isotropic random measures (MMRM) which generalize the so-called MRM measures constructed in [1]. Our measures satisfy an exact scale invariance equation (see equation (1) below) {{and are therefore}} <b>natural</b> <b>models</b> in dimension 3 for the dissipation measure in a turbulent flow...|$|R
2500|$|Hilborn, Ray (2011) [...] <b>Natural</b> Resource <b>Modeling,</b> 25 (1): 122–144.|$|R
40|$|Abstract. We {{study the}} {{simultaneous}} zeros of a random family of d polynomials in d variables over the p-adic numbers. For {{a family of}} <b>natural</b> <b>models,</b> we obtain an explicit constant for the expected number of zeros that lie in the d-fold Cartesian product of the p-adic integers. This expected value, which is 1 +...|$|R
50|$|Reversible {{cellular}} automata form a <b>natural</b> <b>model</b> of reversible computing, {{a technology}} {{that could lead to}} ultra-low-power computing devices. Quantum cellular automata, one way of performing computations using the principles of quantum mechanics, are often required to be reversible. Additionally, many problems in physical modeling, such as the motion of particles in an ideal gas or the Ising model of alignment of magnetic charges, are naturally reversible and can be simulated by reversible cellular automata.|$|E
50|$|Besides {{providing}} a uniform description of circles, ellipses, parabolas, and hyperbolas, conic sections {{can also be}} understood as a <b>natural</b> <b>model</b> of the geometry of perspective in the case where the scene being viewed consists of circles, or more generally an ellipse. The viewer is typically a camera or the human eye and the image of the scene a central projection onto an image plane, i.e., all projection rays pass a fixed point O, the center. The lens plane is a plane parallel to the image plane at the lens O.|$|E
50|$|The idea {{of higher}} {{category}} theory (at least, higher category theory when higher morphisms are invertible) is that, {{as opposed to}} the standard notion of a category, there should be a mapping space (rather than a mapping set) between two objects. This suggests that a higher category should simply be a topologically enriched category. The model of quasi-categories is, however, better suited to applications than that of topologically enriched categories, though it has been proved by Lurie that the two have <b>natural</b> <b>model</b> structures that are Quillen equivalent.|$|E
40|$|Hybrid {{systems are}} {{dynamical}} systems which exhibit both continuous flow and discrete jumps. They are <b>natural</b> <b>modeling</b> formalism for the systems {{composed of a}} discrete con-troller interacting with a physical environment. Since hybrid systems often appear in safety-critical situations, it is non-trivial to study their behavior. A typical {{way to do that}} is t...|$|R
40|$|We study two <b>natural</b> <b>models</b> of {{randomly}} generated {{constraint satisfaction}} problems. We determine {{how quickly the}} domain size must grow with n to ensure that these models are robust {{in the sense that}} they exhibit a non-trivial threshold of satisfiability, and we determine the asymptotic order of that threshold. We also provide resolution complexity lower bounds for these models...|$|R
40|$|Coalgebraic {{techniques}} {{allow for}} a very <b>natural</b> <b>models</b> of various types of state based systems. We propose and discuss a specification language {{which can be used}} to formulate µ-calculus like assertions regarding the behaviour of systems modelled coalgebraically. We also report a case study indicating, that verification times can sometimes be drastically reduced if one uses coalgebraic techniques...|$|R
50|$|While the {{background}} and receiver noise in the assumed data model {{can be thought of}} as emanating from a large number of independent noise sources, the same is usually not the case for the emitter signals. It therefore appears natural to model the noise as a stationary Gaussian white random process whereas the signal waveforms are deterministic (arbitrary) and unknown. According to the Deterministic ML the signals are considered as unknown, deterministic quantities that need to be estimated in conjunction with the direction of arrival. This is a <b>natural</b> <b>model</b> for digital communication applications where the signals are far from being normal random variables, and where estimation of the signal is of equal interest.|$|E
50|$|Transaction Logic is an {{extension}} of predicate logic that accounts in a clean and declarative way for the phenomenon of state changes in logic programs and databases. This extension adds connectives specifically designed for combining simple actions into complex transactions and for providing control over their execution. The logic has a <b>natural</b> <b>model</b> theory and a sound and complete proof theory. Transaction Logic has a Horn clause subset, which has a procedural as well as a declarative semantics. The important features of the logic include hypothetical and committed updates, dynamic constraints on transaction execution, non-determinism, and bulk updates. In this way, Transaction Logic is able to declaratively capture a number of non-logical phenomena, including procedural knowledge in artificial intelligence, active databases, and methods with side effects in object databases.|$|E
5000|$|This {{resulted}} in reflections about urbanism. The Lumières' model town {{would be a}} joint effort between public provision and sympathetic architects, to create administrative or utilitarian buildings (town halls, hospitals, theatres, commisariats) all provided with views, squares, fountains, promenades, and so on.The French Académie royale d'architecture was {{of the opinion that}} [...] ("The beautiful is the pleasant"). For Abbé Laugier, on the contrary, the beautiful was that which was in line with rationality. The <b>natural</b> <b>model</b> for all architecture was the log cabin supported by four tree trunks, with four horizontal parts and a roof, respectively columns, entablature, and pediments. The model of a Greek temple was thus extended into the décor and the structure. This paradigm {{resulted in}} a change of style {{in the middle of the}} 18th century: Rococo was dismissed, Ancient Greece and Palladian architecture became the principal references for neoclassical architecture.|$|E
40|$|Genetic {{algorithms}} are search or classification algorithms {{based on}} <b>natural</b> <b>models.</b> They present {{a high degree}} of internal parallelism. We developed two versions, differing in the way the population is organized and we studied and compared their characteristics and performances when applied to the optimization of multidimensional function problems. All the implementations are realized on transputer networks...|$|R
40|$|Constraint-based {{techniques}} are frequently used in solving real-life scheduling problems thanks to <b>natural</b> <b>modeling</b> capabilities and strong constraint propagation techniques encoded within global constraints. In this paper we present new incremental propagation rules for shrinking time windows of activities allocated to a disjunctive resource. These rules use information about precedence constraints between {{the activities and}} support optional activities...|$|R
30|$|The {{unfolding}} {{of this work}} begins with a general formulation of the phase-field approach, comprising useful properties of the isotropic model. Next, the proposed anisotropies are defined and then incorporated into two different objective functionals of Ginzburg–Landau type. Thus, the classical and <b>natural</b> <b>models</b> differ in the formulations and in the corresponding moving equations. For the special anisotropy functions, for which the surface stiffness becomes negative, an additional term is incorporated into the functional to regularize the evolution equations. The extended models {{are referred to as}} regularized classical and regularized <b>natural</b> <b>models.</b> The simulation results corresponding to the defined anisotropy functions are elucidated in the subsequent section, which are then comprehensively discussed in the following paragraph. Then, an outlook of the presented approaches to multiphase systems is provided to emphasize its significance for the collective grain growth simulations. In the last section, we conclude the results presented in this work.|$|R
5000|$|A <b>natural</b> <b>model</b> {{of passive}} {{learning}} is Valiant's probably approximately correct (PAC) learning. Here the learner receives random examples (x,c(x)), where x is distributed {{according to some}} unknown distribution D. The learner's goal is to output a hypothesis function h such that h(x)=c(x) with high probability when x is drawn according to D. The learner {{has to be able}} to produce such an 'approximately correct' h for every D and every target concept c in its concept class.We can consider replacing the random examples by potentially more powerful quantum examples [...] In the PAC model (and the related agnostic model), this doesn't significantly reduce the number of examples needed: for every concept class, classical andquantum sample complexity are the same up to constant factors. However, for learning under somefixed distribution D, quantum examples can be very helpful, for example for learning DNF underthe uniform distribution. When considering time complexity, there exist concept classes that can be PAC-learned efficiently by quantum learners, even from classical examples, but not by classical learners (again, under plausible complexity-theoretic assumptions).|$|E
50|$|Graph {{theory is}} also used to study {{molecules}} in chemistry and physics. In condensed matter physics, the three-dimensional structure of complicated simulated atomic structures can be studied quantitatively by gathering statistics on graph-theoretic properties related to the topology of the atoms. In chemistry a graph makes a <b>natural</b> <b>model</b> for a molecule, where vertices represent atoms and edges bonds. This approach is especially used in computer processing of molecular structures, ranging from chemical editors to database searching. In statistical physics, graphs can represent local connections between interacting parts of a system, as well as the dynamics of a physical process on suchsystems. Similarly, in computational neuroscience graphs can be used to represent functional connections between brain areas that interact to give rise to various cognitive processes, where the vertices represent different areas of the brain and the edges represent the connections between those areas. Graph theory {{plays an important role in}} electrical modelling of electrical networks, here, weights are associated with resistance of the wire segments to obtain electrical properties of network structures. Graphs are also used to represent the micro-scale channels of porous media, in which the vertices represent the pores and the edges represent the smaller channels connecting the pores.|$|E
5000|$|Wright came to {{the studio}} in the 1940s, and became well known {{throughout}} the ensuing decades for his endearingly gloomy and sullen personality traits {{as well as his}} bass voice. He {{turned out to be a}} <b>natural</b> <b>model</b> for Eeyore when the studio began development on Winnie the Pooh and the Honey Tree. He, along with his fellow Disney contemporaries, was a pioneer in the use of [...] "gags" [...] within cartoons, often acted out in front of the [...] "story board," [...] a bulletin board pinned with sequential sketches of the cartoon's scenes. Early on, with [...] "Goofy's Glider" [...] and other [...] "How To" [...] cartoons, Ralph pioneered the story concept featuring a hero's failed attempt at achieving his goals. This technique is still in use today in most major animation studios. Warner Brothers later would incorporate this premise into [...] "Roadrunner," [...] Sylvester and Tweety, and Bugs Bunny and Donald Duck cartoons. This highly reusable format proved to be wildly successful. In fact, full credit was attributed by Frank Tashlin interviewed by Michael Barrier in 2004: [...] "That all came from a marvelous fellow who came from Tillamook, Oregon, a fellow by the name of Ralph Wright. He came down, and his pants were twelve inches too short for him, and he wore suspenders—he was out of the hills. But he had a crazy, crazy mind, almost as wild as Roy Williams, who is the best of all. Ralph did the first story of that type for Jack Kinney, called How to Ride a Horse. The Goof tried to stay on the horse—boom, off, another joke. That was the beginning of what still seems to be going on today. Then he and Kinney made more—a series of jokes, just one problem and working it out. It's like a symphony, with a theme and then the development of that theme." ...|$|E
40|$|International audienceIs extreme {{modeling}} so extreme? We advocate that <b>natural</b> <b>modeling</b> {{might be}} a better term. After all, the ultimate goal is to enable modelers to perform their job naturally. In the century of the "disappearing computer", it definitively makes sense to search for non invasive and flexible modeling technologies. This paper considers modeling from an anthropological point of view. A retrospective starting back to the Prehistoric Age leads to new perspectives for <b>natural</b> <b>modeling</b> in the Information Age. It is shown (1) that the need for compromises between flexibility and formality is "natural" rather than "extreme", (2) that the languages are emergent by nature, and (3) that natural interfaces should be provided to all stakeholders. We advocate that surface computing, tangible user-interfaces, collaborative modeling and emergent (meta) modeling are future research directions to be investigated in order to make "extreme" modeling just "natural". Just as it should be...|$|R
50|$|They also {{introduced}} several systems to write state-finite grammars and <b>natural</b> language <b>models</b> systems.|$|R
40|$|While {{there exists}} a large {{multitude}} of inflationary models, the connection of inflation to particle physics is still an unsolved puzzle. In particular, in supergravity theories, where the so-called η-problem tends to spoil slow-roll inflation, the construction of convincing and technically <b>natural</b> <b>models</b> of inflation is challenging. We discuss some recent developments regarding the quest for particle physics models of inflation in supergravity...|$|R
