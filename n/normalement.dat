21|0|Public
50|$|Peter Mayle and {{his wife}} move to Provence, and are soon met with {{unexpectedly}} fierce weather, underground truffle dealers and unruly workers, who work around their <b>normalement</b> schedule. Meals in Provençal restaurants {{and work on the}} Mayles' house, garden and vineyard are features of the book, whose chapters follow the months of the year.|$|E
5000|$|Ce [...] "grand Dérangement" [...] provoqua des changements irréversibles et marquants chez ce peuple; l'une de ces séquelles fut l'établissement d'un certain nombre d'Acadiens au sud-ouest de la Nouvelle-Écosse. En 1768, Joseph Dugas établit à Grosses Coques (4) les premiers éléments de ce qui allait devenir la Ville française de la Baie Sainte-Marie (5) dans le comté actuel de Digby, et c'est vers la même époque que sont fondés les villages acadiens du comté actuel de Yarmouth. (6) Tous ces villages constitueront en fin de compte le champ d'apostolat de l'abbé Jean Mandé Sigogne. De surcroît, pendant près d'un demi-siècle, ces Acadiens démunis et illettrés furent, bien involontairement, privés de {{services}} pastoraux, ainsi que des autres services dont ils disposaient <b>normalement</b> avant la Déportation. La présence sporadique de missionnaires itinérants, le plus souvent de langue anglaise, s'avérait impuissante à satisfaire leurs besoins religieux les plus élémentaires, aussi bien que ceux qui étaient relatifs à leur instruction rudimentaire.|$|E
40|$|Larvae of the caddisfly {{suborder}} Integripalpia normally pupate in {{the last}} instar larval tube-case. Measurements of case struc-tures show that larvae of Micrasema longulum differ in adding a long parallel-sided anterior section to their tube-cases, shortly before pupation. They pupate in the newly built section, discarding the slightly conical larval case. Literature data suggest that two additional species of Micrasema exhibit similar behaviour. Production of a special section of tube-case for pupation is remi-niscent {{of the situation in}} the primitive suborders Annulipalpia and Spicipalpia which build a pupal case which is often the only construction during the entire life cycle. It is uncertain if the behaviour of Micrasema is atavistic, or if it developed indepen-dently. Micrasema longulum (Trichoptera: Brachycentridae) construit un fourreau nymphal spécial Mots-clés: Trichoptère, construction de fourrreau, étui, étui nymphal, trait atavistique. Les larves de Trichoptères du sous-ordre des Integripalpia <b>normalement</b> se nymphosent dans le fourreau larvaire. Des mesure...|$|E
40|$|Abstract — The {{accepted}} {{practice for}} the estimation of thin (2 D) vein deposits recommends {{the use of the}} grade x thickness service variable (i. e., the accumulation). Grade estimates are obtained indi-rectly by the estimated accumulation/estimated thickness ratio. This practice stems from the varying support (thickness) problem and the resulting non-additive nature of the grade variable. We compare the actual performance of the direct grade estimation approach used by some practitioners to that of the indirect approach using accumulation. Our simulated and real data indicate that the direct approach is more accurate for point grade estimation where the grade-thickness correlation coeffi-cient is positive (and vice-versa). Moreover, the relative gain of the direct method increases with the (positive) correlation coefficient. This finding contradicts common thinking that the indirect approach should be the preferred method where grade-thickness correlation is strongly positive. Also, for a given positive grade-thickness correlation, the relative gain of the direct method increases with the coefficient of variation of the grade and thickness. © 2003 Canadian Institute of Mining, Metallurgy and Petroleum. All rights reserved. Résumé — L’estimation de veines minces (2 D) minéralisées est <b>normalement</b> réalisée à l’aide de la variable auxiliaire épaisseur x teneur (i. e., accumulation). Les estimés des teneurs sont alors obtenu...|$|E
40|$|Although {{individually}} both continuum and discontinuum numerical methods {{provide useful}} means to analyze rock slope stability problems, complex failures typically involve mechanisms related to both deformation along existing discontinuities and brittle fracture of intact rock. One such {{example is the}} 1991 Randa rockslide in the Swiss Alps, where failure involved several complex mechanisms, which require the consideration of progressive failure and brittle fracture propagation. This paper presents results {{from a series of}} hybrid finite-/discrete-element models directed towards the explicit modelling of brittle fracturing in natural rock slopes simulating the formation of a step-path failure surface. Two series of models are presented, the first starting from the assumption of an initial continuum (i. e. pre-existing discrete fractures are not included), the second including pre-existing fractures of limited persistence. These results demonstrate that massive rock slope failure involves the initiation and propagation of brittle fractures driven by extension strain, which interact with natural pre-existing discontinuities to form basal and internal shear planes. RÉSUMÉ Même si individuellement les méthodes numériques dites de continuum et discontinu procurent une façon utile d’analyser les problèmes de stabilité des pentes rocheuses, les ruptures complexes impliquent <b>normalement</b> des mécanismes reliés à la déformation le long des discontinuités pré-éxistantes et aux fractures fragiles de roche intacte. Un exemple d...|$|E
40|$|ABSTRACT Two {{improvements}} to the Non-linear Principal Component Analysis (NLPCA) method are presented. In the normal application of this method, a non-linear curve C is found that best fits the data. The method provides a projection function mapping from the data space to the curve C. However, this projection function is faulty in that points in the data space are generally not projected onto their closest neighbours on C. Here, a new projection function is introduced which ensures that the data points are projected onto their closest neighbours on C, resulting {{in an increase in}} the amount of variance explained by the NLPCA mode. This is illustrated by an analysis of the sea surface temperature anomaly data from the tropical Pacific, where the El Niño-Southern Oscillation (ENSO) phenomenon is manifested. A second shortcoming of the NLPCA method is that the curve C comes with a parametrization which is arbitrary and has no physical interpretation. Here, the curve is re-parametrized by arc length. This allows the computation of more meaningful time series, which we illustrate through an analysis of the Quasi-Biennial Oscillation (QBO) in the equatorial stratospheric zonal wind data. RÉSUMÉ [traduit par la rédaction] On présente deux améliorations à la méthode d’analyse non linéaire des composantes principales (NLPCA). <b>Normalement,</b> avec cette méthode, on trouve une courbe non linéaire C qui satisfait au mieux les données. La méthode fournit une fonction de projection établissant une correspondance entre l’espace de données et la courbe C. Cependant, cette fonction de projection est imparfaite car les point...|$|E
40|$|International audienceThe few {{surviving}} pre-Islamic inscriptions in {{both the}} Arabic language and the Arabic script show {{the absence of a}} standard written language. We will take as a sample of variation the inscriptions of Jabal Usays (AD 528 - 529) and Harrân (AD 568). A meticulous examination of the first inscription suggests that its author, a soldier, writes the way he speaks in a case-less variety of Arabic. In this context, I will examine the famous bilingual Greek-Arabic papyrus PERF 558 (22 / 643), in which the name Ibn Abû Qîr occurs twice. The Arabic Abû Qîr is the Greek Apa Kyros. In order to get to the form Abû Qîr, one has to go througth the form *Abâ Qîr, reinterpreted as the accusative of the three-case (triptotic) inflection Abû/Abâ/Abî. Both types of Arabic, the so-called Old Arabic (inflected) and the so-called Neo-Arabic (non-inflected) coexist, but the scribe uses the New Arabic type. However, it is the Old Arabic type which was codified and became Classical Arabic. I will try to reach an understanding of the reasons for this choice. Les quelques inscriptions préislamiques, à la fois en arabe et en écriture arabe, montrent qu'il n'y a pas de langue écrite standard. On donnera comme exemple de variation les deux inscriptions du Jabal Usays (538 - 529 ap. JC) et de Harrân (569 ap. JC) L'examen de la première suggère que son auteur écrit comme il parle et qu'il parle une langue non fléchie. Dans ce contexte, on examinera le célèbre papyrus bilingue grec/arabe de 22 / 643. On y trouve deux fois Ibn Abû Qîr. Abû Qîr est le grec Apa Kyros. Pour arriver à Abû Qîr, il faut donc passer par Abâ Qîr, réinterprété comme l'accusatif de la flexion triptote Abû/Abâ/Abî. Les deux types ancien arabe (fléchi) et néo-arabe (non fléchi) coexistent, mais le scribe utilise <b>normalement</b> le type néo-arabe. Pourtant, c'est le type ancien arabe qui sera codifié et deviendra l'arabe classique. On se demandera pourquoi...|$|E
40|$|NOUS IDENTIFIONS OU ISOLONS POUR LA PREMIERE FOIS, ONZE SOUCHES 7 -EPIMERISANTES DE L'ECOSYSTEME INTESTINAL DE SUJETS SAINS. ELLES APPARTIENNENT AUX GENRES CLOSTRIDIUM, EUBACTERIUM ET RUMINOCOCCUS. NOUS IDENTIFIONS EGALEMENT PLUSIEURS SOUCHES DE CET ECOSYSTEME, CAPABLES DE REALISER L'UNE OU L'AUTRE DES DEUX ETAPES DE LA 7 -EPIMERISATION DE CDC EN UDC. EN REVANCHE, AUCUNE DES SOIXANTE-SEIZE BACTERIES LACTIQUES (SOUCHES D'INTERET AGRO-ALIMENTAIRES) TESTEES N'EST ACTIVE DANS NOS CONDITIONS EXPERIMENTALES. UNE SOUCHE 7 -EPIMERISANTE IN VITRO (CLOSTRIDIUM ABSOMUM CHOISI COMME MODELE) EXPRIME EGALEMENT CETTE ACTIVITE IN VIVO, LORSQU'ELLE TRANSITE VIVANTE, DANS L'INTESTIN DE PORCS VIGILES ET <b>NORMALEMENT</b> ALIMENTES. DANS CES CONDITIONS, LA REABSORPTION INTESTINALE D'UDC DANS LA VEINE PORTE EST MULTIPLIEE PAR UN FACTEUR 3, 5 A 7, 5. IL EST DONC POSSIBLE D'AUGMENTER UDC DANS L'INTESTIN ET LA VEINE PORTE VIA L'ADMINISTRATION DE BACTERIES VIVANTES. L'ENJEU SUIVANT CONSISTERA A FAIRE EXPRIMER CETTE ACTIVITE PAR DES BACTERIES D'INTERET AGRO-ALIMENTAIRE, AFIN DE PROPOSER DE NOUVELLES SOUCHES PROBIOTIQUES DANS LE CADRE D'UNE NUTRITION PREVENTIVE DE PATHOLOGIES MAJEURES DONT LE DEVELOPPEMENT EST RALENTI VOIRE SUPPRIME PAR UDC. WE IDENTIFIED OR ISOLATED FOR THE FIRST TIME, ELEVEN 7 -EPIMERISING BACTERIAL STRAINS FROM THE INTESTINAL MICROBIOTA OF HEALTHY VOLUNTEERS. THESE STRAINS WERE MEMBERS OF THE CLOSTRIDIUM, EUBACTERIUM AND RUMINOCOCCUS GENERA. WE ALSO IDENTIFIED SEVERAL STRAINS CARRYING ONE OF BOTH ENZYMATIC ACTIVITIES INVOLVED IN THE 7 -EPIMERISATION OF CDC TO UDC. CONVERSELY, NONE OF THE SEVENTY-SIX LACTIC BACTERIA (SAFE FOOD MICRO-ORGANISMS) WAS FOUND TO BE ACTIVE UNDER OUR STUDY CONDITIONS. ONE OF THE ACTIVE STRAINS (CLOSTRIDIUM ABSONUM) WAS TAKEN AS A MODEL FOR ASSAYING ITS ACTIVITY IN VIVO, DURING ITS TRANSIT IN THE INTESTINE OF AWAKED AND NORMALLY FED PIGS. WE DEMONSTRATED THAT UDC ABSORBED INTO THE PORTAL VEIN, INCREASED 3 ? 5 ? 7 ? 5 -FOLD, UNDER ADMINISTRATION OF LIVING COMPARED TO KILLED BACTERIA. IT IS THEREFORE FEASIBLE TO INCREASE UDCA IN THE INTESTINE AND PORTAL BLOOD OF CONVENTIONAL PIGS TREATED WITH LIVING 7 -EPIMERISING BACTERIA. THIS MAY REPRESENT A NEW INTERESTING PROBIOTIC ACTIVITY, USEFUL FOR THE PREVENTION OF MAJOR PATHOLOGIES WHOSE DEVELOPMENT IS KNOWN TO BE SLOWER OR SUPPRESSED UNDER UDC-THERAPY, PROVIDED THAT IN THE FUTURE, THE 7 -EPIMERISING ACTIVITY COULD BE EXPRESSED BY A SAFE FOOD MICRO-ORGANISM. ORSAY-PARIS 11 -BU Sciences (914712101) / SudocSudocFranceF...|$|E
40|$|Nous étudions la problématique de détermination de prix d'options lorsque la volatilité est stochastique. <b>Normalement,</b> la présence d'une volatilité stochastique entraîne une incomplétude des marchés. Nous proposons une approche par arbitrage, malgré cette apparente incomplétude. Elle {{consiste}} à exploiter une modélisation de la volatilité, proposée par Clark (1973), fondée sur une distinction entre un temps calendaire et un temps de transaction. En faisant cette distinction et en supposant qu'il y a une simple variable d'état binomiale en temps de transaction et un taux sans risque en temps calendaire, nous discutons les conditions d'absence d'opportunités d'arbitrage. Nous caractérisons les conditions permettant la détermination des prix d'options par arbitrage dynamique dans le sens de Harrison et Pliska (1981) et nous montrons que les restrictions à la Merton (1973) ne s'appliquent plus. One of {{the early}} examples of stochastic volatility models is Clark [1973]. He suggested that asset price movements should be tied to {{the rate at which}} transactions occur. To accomplish this, he made a distinction between transaction time and calendar time. This framework has hitherto been relatively unexploited to study derivative security pricing. This paper studies the implications of absence of arbitrage in economies where: (i) trade takes place in transaction time, (ii) there is a single state variable whose transaction-time price path is binomial, (iii) there are risk-free bonds with calendar-time maturities, and (iv) the relation between transaction time and calendar time is stochastic. The state variable could be interpreted in various ways. For example, it could be the price of a share of stock, as in Black and Scholes [1973], or a factor that summarizes changes in the investment opportunity set, as in Cox, Ingersoll and Ross [1985], or one that drives changes in the term structure of interest rates (Ho and Lee [1986], Heath, Jarrow and Morton [1992]). Property (iv) generally introduces stochastic volatility in the process of the state variable when recorded in calendar time. The paper investigates the pricing of derivative securities with calendar-time maturity. The restrictions obtained in Merton (1973) using simple buy-and-hold arbitrage portfolio arguments do not necessarily hold. Conditions are derived for all derivatives to be priced by dynamic arbitrage, i. e., for market completeness in the sense of Harrison and Pliska [1981]. A particular class of stationary economies where markets are indeed complete is characterized...|$|E
40|$|The {{entangled}} {{relations between}} man and animals amongst the Mòosé (Burkina Faso) {{does not allow for}} the identification of a ‘cultural keystone' animal. One mouse however occupies a special place within divination practices. Considered an offspring of the rodent lineage, the grandfather of which {{is said to be the}} Thieving Rat, the mouse is purported to have fled the bush to live among men. In daily life, it is disparaged because of the thefts and damage attributed to it, and is therefore hunted, killed, even eaten. Things are completely different in the courtyard of the mouse diviner, where mouse capacities for seeing, understanding and relaying what goes on in places not normally accessible to humans are valued and put to use. Because it is said to hold a symbolic place between the profane and religious worlds, and to be useful for communicating with the bush spirits, it is locally raised to the status of animal-soothsayer. Other African societies also use living animals like foxes and spiders in divination. In that case, the animal is considered to possess special capabilities, which allow it to see and to explore what is invisible to man, to create a communication channel between the sacred and profane worlds, and lastly to formulate answers in the form of tracks left on a divinatory table or by modifying a previously arranged pattern of objects. Such animals never seem to be domesticated, but it is nevertheless likely that their particular status may be due to their proximity and their behavior towards humans. As far as the mouse is concerned in Mòosé society, this interpretation also revolves around the modifications in the daily relations between humans and animals, at least within the space allotted for the diviner's residence. Identifier un animal “clef de voûte de la culture” chez les Mòosé n'est pas possible. Une souris occupe néanmoins une place particulière dans le cadre de la divination. Considérée comme originaire du lignage des rongeurs, elle aurait fuit la brousse pour vivre parmi les hommes. Au quotidien, elle est décriée du fait des vols et des détériorations qui lui sont attribués et donc chassée, tuée voire mangée. Il en va autrement dans la cour du devin, lieu dans lequel les capacités qui lui sont reconnues de voir, de comprendre et de dire ce qui se passe dans des espaces <b>normalement</b> inaccessibles aux hommes sont valorisées et utilisées. Du fait de la place symbolique entre mondes profane et religieux qui lui est conférée et des fonctions de communication qui lui sont attribuées, elle accède localement au statut d'animal-devin...|$|E
40|$|LE NOYAU ATOMIQUE PEUT ADOPTER, A HAUT MOMENT ANGULAIRE, UNE FORME TRES ALLONGEE DE RAPPORT D AXES 2 : 1 : C EST LE PHENOMENE DE SUPERDEFORMATION. SI AUJOURD HUI PLUS DE 300 BANDES SUPERDEFORMEES ONT ETE IDENTIFIEES, L ASSIGNATION DES ENERGIES, SPINS ET PARITES DES ETATS ASSOCIES N A PU ETRE EFFECTUEE QUE POUR UN DIXIEME DE CES BANDES. CETTE ASSIGNATION NE PEUT SE FAIRE QUE PAR LA MESURE DE TRANSITIONS GAMMA DISCRETES RELIANT LES ETATS SUPERDEFORMES (SD) AUX ETATS <b>NORMALEMENT</b> DEFORMES (ND). DANS LE CADRE DE CE TRAVAIL DE THESE, NOUS NOUS SOMMES INTERESSES AU NOYAU 192 HG, PREDIT DOUBLEMENT MAGIQUE DANS SON ETAT SD ET DONC NOYAU DE REFERENCE DE LA REGION DE MASSE A~ 190. UNE EXPERIENCE A ETE MENEE AUPRES DU MULTIDETECTEUR EUROBALL IV A STRASBOURG DANS LE BUT DE MESURER LES OBSERVABLES E*, I, PI DES ETATS SD DE CE NOYAU. LA RECHERCHE DES TRANSITIONS DE LIEN DIRECT S EST AVEREE A LA LIMITE DES CAPACITES D OBSERVATION DES MULTIDETECTEURS ACTUELS, UTILISANT DES BOUCLIERS ANTI-COMPTON. LA PROCHAINE GENERATION DE MULTIDETECTEUR GAMMA ABANDONNERA CES BOUCLIERS ET UTILISERA DES ALGORITHMES DE TRACKING GAMMA POUR RECONSTRUIRE LES TRAJECTOIRES DES PHOTONS. LA SECONDE PARTIE DE CETTE THESE A ETE AXEE SUR UN TRAVAIL DE R&D POUR LE PROJET EUROPEEN AGATA. NOUS AVONS EN PARTICULIER EFFECTUE DES SIMULATIONS AU MOYEN DU CODE GEANT 4 ET ESSAYE D AMELIORER LES ALGORITHMES DE TRACKING EXISTANTS PAR LA MISE AU POINT DE METHODES DE RECONSTRUCTION DES EVENEMENTS CREATION DE PAIRE. AGATA DEVRAIT VOIR LE JOUR A L HORIZON 2015 - 2020, ET PERMETTRA AINSI DE REPOUSSER LES LIMITES D OBSERVATION DE DEUX ORDRES DE GRANDEUR ENVIRON. THE ATOMIC NUCLEUS CAN ADOPT A VERY ELONGATED SHAPE WITH AN AXIS RATIO 2 : 1 : THIS IS THE SUPERDEFORMATION PHENOMENON. NOWADAYS MORE THAN 300 SUPERDEFORMED BANDS HAVE BEEN IDENTIFIED AT HIGH SPIN, BUT THE DETERMINATION OF EXCITATION ENERGIES, SPINS AND PARITIES OF THE ASSOCIATED STATES HAVE BEEN ESTABLISHED FOR ONLY ONE TENTH OF THESE BANDS. THE FORMER QUANTITIES (E*, I, p) CAN ONLY BE DETERMINED VIA THE LINKING g-TRANSITIONS BETWEEN THE SUPERDEFORMED (SD) AND THE NORMALLY DEFORMED (ND) STATES. WITHIN THE FRAMEWORK OF THIS THESIS, WE HAVE INVESTIGATED THE 192 HG NUCLEUS IN ORDER TO ESTABLISH E*, I AND p. THIS NUCLEUS IS PREDICTED TO BE DOUBLY MAGIC AT SUPERDEFORMATION AND HENCE IS TAKEN AS A REFERENCE IN THE MASS A~ 190 REGION. THE EXPERIMENT WAS CARRIED OUT AT STRASBOURG USING THE EUROBALL IV ARRAY AND THE VIVITRON ACCELERATOR. THE OBTAINED RESULTS ARE NOT CONVINCING AND SEEM TO BE AT THE LIMIT OF THE PERFORMANCES OF EUROBALL. NEXT GENERATION OF ARRAYS WILL ABANDON THE COMPTON-SHIELDS AND USE TRACKING CONCEPT TO RECONSTRUCT THE TRAJECTORIES OF INCIDENT PHOTONS, AND THEREFORE WE EXPECT A HUGE INCREASE OF EFFICIENCY. THE SECOND PART OF THIS PH. D. WAS FOCUSED ON THE R&D WORK FOR THE AGATA PROJECT. WE HAVE PERFORMED SIMULATIONS WITH THE GEANT 4 CODE AND DEVELOPPED TRACKING METHODS TO RECONSTRUCT PAIR-CREATION EVENTS. THE FULL AGATA WILL BE OPERATIONNAL AROUND 2015 AND WILL ENHANCE BY AROUND TWO ORDERS OF MAGNITUDE THE OBSERVATIONAL LIMITS. ORSAY-PARIS 11 -BU Sciences (914712101) / SudocSudocFranceF...|$|E
40|$|Le but de cet article est d'examiner l’influence modératrice des besoins dits supérieurs ou intrinsèques (besoin d'accomplissement, de développement personnel, de compétence) sur la {{relation}} entre les caractéristiques du travail <b>normalement</b> associées à l'enrichissement des tâches (e. g. complexité, autonomie, variété) d'une part et la satisfaction et la motivation de l'employé d'autre part. À la suite d'une revue de la littérature pertinente, les auteurs présentent et discutent les résultats d'une recherche effectuée auprès de 176 employés d'un hôpital du Québec. La conclusion résume les implications de ces résultats pour les chercheurs et pour les administrateurs. The {{purpose of}} this article is to examine the moderating influence of superior (higher order) needs on the relationship between certain task characteristics normally associated with job enrichment and the employee's satisfaction and motivation. A review of the literature indicates that while the "main effects" of these characteristics are generally supported, studies dealing with the moderating influence of superior needs have produced conflicting or ambiguous results. One source of difficulty may be that most authors have adopted a ready-made questionnaire to measure four or five characteristics of the task, without determining the dimensions actually perceived by their particular sample group. In this study, a factor analysis of 31 items borrowed from the literature or created by the authors produced four dimensions with adequate reliability: complexity and use of abilities, autonomy and influence, feedback and personal development, variety. The following hypotheses were verified with a sample of 176 hospital employees: 1. the four dimensions are related separately and jointly to job satisfaction and job motivation. 2. the relationships are stronger in the case of employees with higher intrinsic or superior needs. In general, the hypotheses are well supported. With regard to main effects, there is one exception: variety does not correlate with motivation. The moderating influence of superior needs is usually strong. For instance, the correlations between "complexity and use of abilities" and job satisfaction are. 03,. 41 and. 60 respectively for low, medium and high levels of superior needs. With motivation as the dependent variable, these correlations become. 10,. 26 and. 48. Contrary to the hypotheses, however, the relationships between "autonomy and influence" and both satisfaction and motivation are not influenced significantly by the level of superior needs. The discussion of these results bear on the following points: the usefulness of factor analysis for studies of this kind, the ambiguous role of "variety" as a potential determinant of satisfaction and motivaton, the choice of superior (or higher-order) needs as possibly the most appropriate moderating variable, the unexpected findings with "autonomy and influence" as the independent variable. The conclusion points out that a distinction should be made between the process of job enrichment and the simple presence or absence of characteristics associated with an enriched job. The theoretical and practical importance of the results obtained is also discussed at some length. Readers are reminded that several other studies have produced different results and that very few studies have shown a negative moderating influence on the relationships between such job characteristics and employees' reactions. This would seem to indicate that administrators do not stand to lose much by attempting to enrich all jobs, provided the process itself is carried out with some caution...|$|E
40|$|Cet article examine le fonctionnement de quelque dix-sept comités paritaires de {{formation}} professionnelle mis en place aux niveaux local et sectoriel au Québec. La question posée est de savoir si de tels comités paritaires participent d'une évolution des relations du travail davantage axées sur la coopération dans un domaine, celui de {{la formation}} de la main-d’œuvre, <b>normalement</b> exclu du champ de la négociation collective ? Si la réponse est positive {{en ce qui concerne}} les comités sectoriels, au niveau des comités locaux les résultats de l'étude dégagent plutôt trois figures de relations du travail dont la plus importante demeure celle de relations mixtes faites à la fois de coopération et de conflit. This article explores {{the extent to}} which the establishment of joint occupational training committees is contributing to the development of more cooperative labour relations. Quebec, like the rest of North America, has usually been ranked well behind most European countries as regards the establishment of mechanisms of concertation. More recently, however, a number of factors linked to the economie crisis and the coming to power of the Parti quebecois have stimulated the development of mechanisms of concertation. The creation of the Societe quebecoise de developpement de la main-d'oeuvre (SQDM) and the adoption of the Act to Foster the Development of Manpower Training (Loi favorisant le developpement de la formation professionnelle) should, in our view, speed up the establishment of joint occupational training committees. Although it is too early to evaluate their quantitative impact, our study examined seventeen existing committees in order to assess {{the extent to which the}}y have contributed to the development of more cooperative labour relations. The results of our case studies indicate that the context of economie crisis and increased competition has been the principal factor triggering the establishment of joint occupational training committees. The interest of employers in increasing workers' skill levels so as to meet the new requirements of production Systems, such as ISO certification norms, is the counterpart of the unions' search for greater job security. However, at the sectoral level, the objectives are broad (e. g., the establishment of institutional training programs) and are aimed as much, if not more, at training the future work force than those who are already employed. Thus, sectoral committees are generally able to avoid conflicts linked to labour-management relations, whereas at the firm level concertation efforts more often affect the objects of negotiation (e. g., classification, promotions, seniority rights) and may create conflict. Consequently, it is not surprising that the existence of joint occupational training committees does not necessarily go hand in hand with the development of more cooperative labour relations. From our study emerge three general patterns of labour relations, of which the traditional pattern based on a mixture of cooperation and conflict dominates. In only one case out of the thirteen local committees studied were we able to make a direct link between the existence of a joint occupational training committee and the development of more cooperative labour relations. What can be concluded on the basis of seventeen case studies in which, despite the broad context of social change, traditional approaches appear to overshadow innovative ones ? We would argue that a number of adjustments are currently being made that nevertheless fit within the traditional framework of industrial relations in Quebec. More particularly, we would say that, after many years of opposing such change, Quebec unions seem to have agreed to tackle the question of work organization and, as a result, to give greater weight to occupational training within the overall System of job allocation. However, they remain strongly attached to the principle of bureaucratized management of employment based on negotiated rules, especially the seniority principle which remains fundamental. Nevertheless, the situation may still change. In fact, in light of the SQDM's recent Sectoral Initiatives Policy (Politique d'intervention sectorielle), which seeks to encourage the creation of joint occupational training committees, it will be interesting to pursue the present analysis...|$|E
40|$|In recent years, {{advances}} in wireless communication technology {{have led to}} the widespread use of cellular phones. Because of noisy environmental conditions and competing surrounding conversations, users tend to speak loudly. As a consequence, private policies and public legislation tend to restrain the use of cellular phone in public places. Silent speech which can only be heard by a limited set of listeners close to the speaker is an attractive solution to this problem if it can effectively be used for quiet and private communication. The motivation of this research thesis was to investigate ways of improving the naturalness and the intelligibility of synthetic speech obtained from the conversion of silent or whispered speech. A Non-audible murmur (NAM) condenser microphone, together with signal-based Gaussian Mixture Model (GMM) mapping, were chosen because promising results were already obtained with this sensor and this approach, and because the size of the NAM sensor is well adapted to mobile communication technology. Several improvements to the speech conversion obtained with this sensor were considered. A first set of improvement concerns characteristics of the voiced source. One of the features missing in whispered or silent speech with respect to loud or modal speech is F 0, which is crucial in conveying linguistic (question vs. statement, syntactic grouping, etc.) as well as paralinguistic (attitudes, emotions) information. The proposed estimation of voicing and F 0 for converted speech by separate predictors improves both predictions. The naturalness of the converted speech was then further improved by extending the context window of the input feature from phoneme size to syllable size and using a Linear Discriminant Analysis (LDA) instead of a Principal Component Analysis (PCA) for the dimension reduction of input feature vector. The objective positive influence of this new approach {{of the quality of the}} output converted speech was confirmed by perceptual tests. Another approach investigated in this thesis consisted in integrating visual information as a complement to the acoustic information in both input and output data. Lip movements which significantly contribute to the intelligibility of visual speech in face-to-face human interaction were explored by using an accurate lip motion capture system from 3 D positions of coloured beads glued on the speaker's face. The visual parameters are represented by 5 components related to the rotation of the jaw, to lip rounding, upper and lower lip vertical movements and movements of the throat which is associated with the underlying movements of the larynx and hyoid bone. Including these visual features in the input data significantly improved the quality of the output converted speech, in terms of F 0 and spectral features. In addition, the audio output was replaced by an audio-visual output. Subjective perceptual tests confirmed that the investigation of the visual modality in either the input or output data or both, improves the intelligibility of the whispered speech conversion. Both of these improvements are confirmed by subjective tests. Finally, we investigated the technique using a phonetic pivot by combining Hidden Markov Model (HMM) -based speech recognition and HMM-based speech synthesis techniques to convert whispered speech data to audible one in order to compare the performance of the two state-of-the-art approaches. Audiovisual features were used in the input data and audiovisual speech was produced as an output. The objective performance of the HMM-based system was inferior to the direct signal-to-signal system based on a GMM. A few interpretations of this result were proposed together with future lines of research. La parole silencieuse ou murmurée est définie comme la production articulée de sons, avec très peu de vibration des cordes vocales dans le cas du chuchotement, et aucune vibration dans le cas du murmure, produite par les mouvements et les interactions des organes de la parole tels que la langue, le voile du palais, les lèvres, etc., dans le but d'éviter d'être entendue par plusieurs personnes. La parole silencieuse ou murmurée est utilisée généralement pour la communication privée et confidentielle ou peut être employée par les personnes présentant un handicap laryngé et qui ne peuvent pas parler <b>normalement.</b> Cependant, il est difficile d'employer directement la parole silencieuse (murmurée) pour la communication face à face ou avec un téléphone portable parce que le contenu linguistique et l'information paralinguistique dans le message prononcé sont dégradés fortement quand le locuteur murmure ou chuchote. Une piste récente de recherche est donc celle de la conversion de la parole silencieuse (ou murmurée) en voix claire afin d'avoir une voix plus intelligible et plus naturelle. Avec une telle conversion, des applications potentielles telles que la téléphonie silencieuse " ou des systèmes d'aides robustes pour les handicaps laryngés deviendraient envisageables. Notre travail dans cette thèse se concentre donc sur cette piste...|$|E
40|$|The {{clinical}} experience concerning the mentally handicapped {{child is a}} very complex one. The defences that the families, and in particular the mothers, set up in order to cope with the suffering created by the handicap make the transferential relationships really hard to establish. The principal observations highlight clinical facts that appear with a certain frequency in most of the families: the omnipresence of the mother concerning the child’s care and the symbolic father’s disappearance in the family system. The lack of the paternal third-party, who is supposed to symbolize the oedipal metaphor, generates an ambivalent attitude of the mother which leads to a situation where the child becomes an enjoyment object such as the idol for the pervert. Without otherness, without a third-party, dealing with the diagnosis is frequently impossible and leads to a denial of the handicap along with a speech tinged with persecution and rivalry between the different persons being part of the child’s and the mother’s environment. Like the only child who, on the occasion of a baby brother’s birth, can psycho-affectively regress (i. e. : he was house-trained until the baby brother’s was born), the mother, subsequently to the trauma created by the announcement of the diagnosis, would know a psychic regression caused by the collapse of the ideal, collapse which is induced by giving birth to a handicapped child. This thesis intends to demonstrate that these attitudes are, according to us, the result of a mostly superego’s distress. The approach we chose for this work is the superego’s perspective because we believe that there is no {{clinical experience}} that better illustrates this notion of criticism, censorship and judgment to decide between normal and pathologic than the one of the handicapped child. We assumed hypothetically that after the announcement of the handicap, the mother, normally pacified by the oedipal paternal superego (the superego as it was conceived by S. Freud), would all of a sudden find herself in a pre-oedipal superego’s position (the superego as it was conceived by J. Lacan and M. Klein). Through a conceptual study of the superego and the interlinking with the feminine, we suggest, by means of this thesis, to connect the clinical experience and the theory. Several clinical case vignettes will support our assumptions and, in fine, we will describe our therapeutic clinical approach which aims at re-introducing the symbolic paternal third-party and help the mother take the reverse course. La clinique de l'enfant en situation de handicap est une clinique très complexe. Les défenses psychiques mises en place par les familles et plus particulièrement par les mères pour faire face à la souffrance engendrée par le handicap rendent les relations transférentielles très difficiles à mettre en place. Les principales observations mettent en évidence des faits cliniques qui apparaissent avec une certaine fréquence dans la plupart des familles : omniprésence de la mère autour de la prise en charge de l'enfant et disparition du père symbolique du dispositif familial. L'absence de tiers paternel quiest sensé symboliser la métaphore oedipienne, entraîne une attitude de la mère ambivalente à la suite de laquelle l'enfant devient une sorte d'objet de jouissance à l'instar du fétiche pour le pervers. Sans altérité, sans tiers, faire le deuil du diagnostic devient bien souvent impossible et cela entraîne souvent un déni du handicap accompagné de l'apparition d'un discours teinté de persécution et d'une rivalité entre les différentes personnes qui gravitent autour de l'enfant et les mères. À l'instar de l'enfant unique qui, à la naissance d'un petit frère, peut régresser psycho-affectivement (ex : il était propre, il redevient sale) la mère à la suite du traumatisme engendré par l'annonce du handicap subirait une régression psychique causée par l’effondrement de l’idéal que l'enfant en situation handicap mental produit chez la mère. Cette thèse veut démontrer que ces attitudes sont, selon nous, le fruit d'un bouleversement principalement surmoïque. Nous avons voulu aborder cette thèse sous l'angle du Surmoi car nous pensons qu'aucune clinique comme celle de l'enfant en situation de handicap ne nous confronte autant à cette notion de critique, censure et jugement pour départager le normal du pathologique. Nous avons émis l’hypothèse que suite à l'annonce du handicap, la mère <b>normalement</b> pacifiée par le Surmoi paternel oedipien (le Surmoi Freudien), basculerait dans un positionnement surmoïque pré-oedipien (le Surmoi Lacanien etKleinien). À travers une étude du concept de Surmoi et la mise en lien avec le féminin nous nous proposons, par le biais de cette thèse, de faire des liens entre la clinique et la théorie. Plusieurs vignettes cliniques viendront étayer nos propos et in fine, nous décrirons notre démarche clinique thérapeutique qui vise à la ré-introduction du tiers paternel symbolique et de permettre à la mère de faire le chemin inverse...|$|E
40|$|The {{study of}} the {{collective}} behavior {{of a large number}} of interacting agents, often called a “crowd”, has drawn a growing attention from several scientific communities. This research topic has an impact on civil engineering (problems of emergency egress and road traffic), robotics (coordination of robots and networked control), computer science and sociology (social networks), and biology (groups, herds and flocks). Some major difficulties are deeply related to the use of such models. First of all, from the theoretical viewpoint, standard analytical tools are not very useful in this context, since the presence {{of a large number of}} agents corresponds to a state space of big dimension. Moreover, for human and animal crowds, the dynamics of each agent is not clearly identified, since it is highly sensitive to internal and external perturbations (such as stress, panic and presence of obstacles). For these reason, stimulated by the numerous theoretical and applied challenges, a large number of researcher currently works on crowd models. The first question to address, in this context, is the choice of a mathematical framework for the description of the dynamics of agents. The crowd can be described with three frameworks: microscopic, macroscopic or multi-scale. In the microscopic approach, the crowd is represented by the position of each agent, and its dynamics is a system of ordinary differential equations of very big dimension. In the macroscopic approach, the crowd is given by the density of agents, and its dynamics is a partial differential equation (PDE in the following), often of transport type. In the multi-scale approach, also called “granular”, the population is composed both of a microscopic part of “remarkable” agents (such as leaders), and of a macroscopic part for the rest of the crowd. In this third framework, in which I develop most of my researches, measures are the main tool. In Section 1, I present my results of analysis in this context. I focus on a particular class of PDEs for dynamics of measures. This class of transport equations with non-local velocities is at the core of models for crowds. Indeed, each agent in a crowd interacts with its neighbors, generating a dynamics depending not only on its position (local term), but also on positions of others (non-local term). In Section 1. 1, I describe a rigorous and mathematically rich framework in which transport equations with non-local velocities enjoy good properties: existence and uniqueness of solutions, continuous dependance, etc. I then study some numerical schemes for such equations, described in Section 1. 2, for which I also prove convergence. After this, I define in Section 1. 3 a generalization of the Wasserstein distance to mass-varying measures. For this distance, I prove interesting properties related to the transport PDE with source, and in particular a generalization of the Benamou-Brenier formula. I finally present in Section 1. 4 some specific results for the transport equation in a non-smooth setting, useful for models of road traffic. Beside the problem of analyzing the collective behavior of crowds, it is interesting to understand what behavior changes can be induced on them by an external agent – e. g. a policy maker or some leaders. The research mainstream for such problems has been focused on creating efficient facilities or rules, with a static point of view. Recently, such setting has been challenged by a more dynamic and time-dependent point of view. This implies a change of approach: we pass from a static optimization problem to a control problem, depending on time and on configurations. For example, if we consider emergency egress problems, with a statical point of view the infrastructure is designed with a given configuration and it cannot be modified. With the new, dynamical point of view, one can introduce light signals or portable devices to drive the crowd to the best direction. This innovative approach leads to the problem of control of crowds: one wants to understand what changes of behavior can be induced to the crowd by some leaders or by an external policy maker. Such problems have already been studied in control theory for coordination of agents of very different natures, such as flying drones formations, routing in telecommunication networks, smart grids and power network control. In this general framework, I worked on the control of the transport equation with non-local velocities. My results are presented in Section 2. I first discuss in Section 2. 1 a theoretical problem for crowd control. When one passes from a microscopic to a macroscopic model, the indistinguishability of agents is a necessary requirement: this is in sharp contrast with the fact that controls are applied to specific agents. For this reason, I present two specific control problems. In Section 2. 2, I describe the control the kinetic Cucker-Smale problem to a flocking configuration. This is one of the few known results of control of the transport equation with non-local velocity, and the only one with localized control. Section 2. 3 is focused on an optimal control problem for a system coupling a controlled dynamical system for leaders and a transport PDE for the rest of the crowd. The main result is a generalization of the Pontryagin Maximum Principle to this measure setting, in which the Hamiltonian equation is written in terms of a Wasserstein gradient. This thesis also contains some other research results in control and system theory, as well as analysis of PDEs. They are shortly described in Section 3. These results are quite independent with respect to topics in previous sections. Nevertheless, research tools used in the three sections are common, being based on geometric control. Moreover, I focus on PDE models, and in particular on limits permitting to pass from a finite-dimensional system to the associated PDE. See some examples in Sections 1. 1, 2, 3. 1 and 3. 2. Finally, a Curriculum Vitae is presented in Section 4. L’étude du comportement collectif d’un grand nombre d’agents en interaction, souvent dénommé “foule”, a suscité un grand intérêt de la part des communautés scientifiques. Ce sujet de recherche touche aussi bien le Génie civil (évacuation de bâtiments et problèmes du trafic routier), la Robotique (coordination de robots volants), l’Informatique et la Sociologie (réseaux sociaux), que la Biologie (groupes, troupeaux et vols d’oiseaux). Des difficultés majeures sont intimement liées à l’utilisation de ces modèles. En effet, d’un point de vue théorique, la présence d’un grand nombre d’agents rend les outils classiques de l’analyse mathématique peu utiles, car l’espace d’état est de très grande dimension. De plus, pour les foules humaines ou d’animaux, la dynamique de chaque agent n’est pas clairement identifiée, car elle est très sensible aux facteurs intérieurs et extérieurs (comme le stress, la panique, la présence d’obstacles). C’est pour cela que, stimulés par les multiples défis théoriques et applicatifs, de nombreux chercheurs travaillent sur les modèles de foules. La première question qu’il est nécessaire de se poser, en ce contexte, concerne le choix d’un cadre mathématique pour la description de la dynamique des agents. La population peut se décrire de trois façons : microscopique, macroscopique ou multiéchelle. Dans l’approche microscopique, la foule est représentée par la position de chaque agent, et sa dynamique est un système d’équations aux dérivées ordinaires de dimension très grande. Dans l’approche macroscopique, la foule est donnée par la densité d’agents, et sa dynamique est une équation aux dérivées partielles (EDP dans la suite), souvent de type transport. Dans l’approche “multi-échelle”, dite aussi “granulaire”, la population se compose tout autant d’une partie microscopique d’agents “significatifs” (tels que les leaders) que d’une partie macroscopique pour le reste de la foule. Dans cette troisième approche, dans laquelle je développe la plupart de mes recherches, les mesures sont l’outil principal utilisé. La Section 1 présente mes résultats d’analyse dans ce contexte. Je m’intéresse à une classe particulière d’EDP pour la dynamique des mesures. Cette classe d’équations de transport avec vitesses non-locales est au coeur des modèles pour les foules. En effet, chaque agent dans une foule est en interaction avec ses voisins, engendrant ainsi une dynamique qui ne dépend pas seulement de sa position (terme locale), mais aussi des positions des autres (terme non-local). En Section 1. 1, j’expose d’abord un cadre assez rigoureux et riche dans lequel les équations de transport avec vitesses non-locales ont de bonnes propriétés : existence et unicité de la solution, dépendance continue, etc. Puis, j’étudie certains schémas numériques pour ces équations, décrits en Section 1. 2, et je démontre leur convergence. Je définis ensuite en Section 1. 3 une généralisation de la distance de Wasserstein aux mesures de masse variable. Pour cette distance, je prouve des propriétés intéressantes en lien avec l’EDP de transport avec source, et notamment une généralisation de la formule de Benamou-Brenier. Enfin, je présente en Section 1. 4 certains résultats spécifiques pour l’équation de transport dans un cadre non-lisse, qui est utilisée dans des modèles de trafic routier. Au-delà de la description et de l’analyse du comportement collectif, il est intéressant de se demander quels changements un agent extérieur – un gouvernement régulateur ou des leaders, par exemple – peut induire sur une foule. La plupart des recherches dans ce domaine ont été consacrées à la création de structures ou de règles efficientes, avec un point de vue statique. Aujourd’hui cependant, ce point de vue est remis en question par une vision dynamique et variable dans le temps. On assiste à un changement de paradigme : d’un problème d’optimisation statique on passe à un problème de commande, dépendant du temps et des configurations. Si l’on considère les problèmes d’évacuation, par exemple, avec un point de vue statique, l’infrastructure est conçue dans une configuration donnée et elle ne peut subir aucune modification. Avec le nouveau paradigme dynamique, quand une sortie de secours est congestionnée, on peut introduire des signaux lumineux ou des dispositifs portables pour envoyer la foule vers la direction la plus convenable. Cette approche introduit le problème de la commande des foules : on souhaite comprendre quels changements de comportement peuvent être produits sur la foule par des leaders ou par un régulateur extérieur. Ces problèmes ont déjà été étudiés en automatique pour la coordination d’agents dans des situations très variées, comme les formations de drones en vol, le routing dans les réseaux de télécommunication, les problèmes d’énergie avec les “smart grids”. Dans ce cadre très général, j’ai travaillé à la commande de l’équation de transport avec vitesse non-locale. La Section 2 en présente les résultats. Je discute d’abord en Section 2. 1 d’un problème conceptuel pour la commande des foules. Pour passer d’un modèle microscopique à un modèle macroscopique, l’indistinguabilité des agents est nécessaire : cette propriété s’oppose au fait que les commandes agissent <b>normalement</b> sur des agents précis. Pour cette raison, je présente des problèmes de commande dans deux cas particuliers. En Section 2. 2, je montre la commande du modèle de champ moyen de Cucker et Smale vers une configuration d’alignement. C’est l’un des rares résultats en littérature de commande de l’équation de transport avec vitesse non-locale, et le seul avec commande localisée. En Section 2. 3, j’étudie un problème de commande optimale où la dynamique est donnée par le couplage d’un système contrôlé pour des leaders avec une EDP de transport pour le reste de la foule. Le résultat principal est la généralisation du Principe de Maximum de Pontryaguine à ce problème de mesures, dans lequel l’équation de Hamilton est écrite comme un gradient de Wasserstein. Ce mémoire contient aussi plusieurs autres résultats de recherche dans le domaine de l’automatique, de la commande et de l’analyse des EDP. La Section 3 les décrit plus brièvement. Ces résultats sont assez indépendants par rapport aux sujets présentés dans les sections précédentes. Il est à noter, cependant, que les instruments de recherche utilisés dans les trois sections relèvent tous de la commande géométrique. Je focalise également mon attention sur les modèles d’EDP, et en particulier sur les méthodes de limite permettant de passer d’un système en dimension finie à une EDP associée. Voire des exemples en Sections 1. 1, 2, 3. 1 et 3. 2. Enfin, un CV détaillé est présenté en Section 4...|$|E
40|$|Video {{signals are}} {{sequences}} of natural images, where images are often modeled as piecewise-smooth signals. Hence, video {{can be seen}} as a 3 D piecewise-smooth signal made of piecewise-smooth regions that move through time. Based on the piecewise-smooth model and on related theoretical work on rate-distortion performance of wavelet and oracle based coding schemes, one can better analyze the appropriate coding strategies that adaptive video codecs need to implement in order to be efficient. Efficient video representations for coding purposes require the use of adaptive signal decompositions able to capture appropriately the structure and redundancy appearing in video signals. Adaptivity needs to be such that it allows for proper modeling of signals in order to represent these with the lowest possible coding cost. Video is a very structured signal with high geometric content. This includes temporal geometry (normally represented by motion information) as well as spatial geometry. Clearly, most of past and present strategies used to represent video signals do not exploit properly its spatial geometry. Similarly to the case of images, a very interesting approach seems to be the decomposition of video using large over-complete libraries of basis functions able to represent salient geometric features of the signal. In the framework of video, these features should model 2 D geometric video components as well as their temporal evolution, forming spatio-temporal 3 D geometric primitives. Through this PhD dissertation, different aspects on the use of adaptivity in video representation are studied looking toward exploiting both aspects of video: its piecewise nature and the geometry. The first part of this work studies the use of localized temporal adaptivity in subband video coding. This is done considering two transformation schemes used for video coding: 3 D wavelet representations and motion compensated temporal filtering. A theoretical R-D analysis as well as empirical results demonstrate how temporal adaptivity improves coding performance of moving edges in 3 D transform (without motion compensation) based video coding. Adaptivity allows, at the same time, to equally exploit redundancy in non-moving video areas. The analogy between motion compensated video and 1 D piecewise-smooth signals is studied as well. This motivates the introduction of local length adaptivity within frame-adaptive motion compensated lifted wavelet decompositions. This allows an optimal rate-distortion performance when video motion trajectories are shorter than the transformation "Group Of Pictures", or when efficient motion compensation can not be ensured. After studying temporal adaptivity, the second part of this thesis is dedicated to understand the fundamentals of how can temporal and spatial geometry be jointly exploited. This work builds on some previous results that considered the representation of spatial geometry in video (but not temporal, i. e, without motion). In order to obtain flexible and efficient (sparse) signal representations, using redundant dictionaries, the use of highly non-linear decomposition algorithms, like Matching Pursuit, is required. General signal representation using these techniques is still quite unexplored. For this reason, previous to the study of video representation, some aspects of non-linear decomposition algorithms and the efficient decomposition of images using Matching Pursuits and a geometric dictionary are investigated. A part of this investigation concerns the study on the influence of using a priori models within approximation non-linear algorithms. Dictionaries with a high internal coherence have some problems to obtain optimally sparse signal representations when used with Matching Pursuits. It is proved, theoretically and empirically, that inserting in this algorithm a priori models allows to improve the capacity to obtain sparse signal approximations, mainly when coherent dictionaries are used. Another point discussed in this preliminary study, on the use of Matching Pursuits, concerns the approach used in this work for the decompositions of video frames and images. The technique proposed in this thesis improves a previous work, where authors had to recur to sub-optimal Matching Pursuit strategies (using Genetic Algorithms), given the size of the functions library. In this work the use of full search strategies is made possible, at the same time that approximation efficiency is significantly improved and computational complexity is reduced. Finally, a priori based Matching Pursuit geometric decompositions are investigated for geometric video representations. Regularity constraints are taken into account to recover the temporal evolution of spatial geometric signal components. The results obtained for coding and multi-modal (audio-visual) signal analysis, clarify many unknowns and show to be promising, encouraging to prosecute research on the subject. Video signals are sequences of natural images, where images are often modeled as piecewise-smooth signals. Hence, video {{can be seen as}} a 3 D piecewise-smooth signal made of piecewise-smooth regions that move through time. Based on the piecewise-smooth model and on related theoretical work on rate-distortion performance of wavelet and oracle based coding schemes, one can better analyze the appropriate coding strategies that adaptive video codecs need to implement in order to be efficient. Efficient video representations for coding purposes require the use of adaptive signal decompositions able to capture appropriately the structure and redundancy appearing in video signals. Adaptivity needs to be such that it allows for proper modeling of signals in order to represent these with the lowest possible coding cost. Video is a very structured signal with high geometric content. This includes temporal geometry (normally represented by motion information) as well as spatial geometry. Clearly, most of past and present strategies used to represent video signals do not exploit properly its spatial geometry. Similarly to the case of images, a very interesting approach seems to be the decomposition of video using large over-complete libraries of basis functions able to represent salient geometric features of the signal. In the framework of video, these features should model 2 D geometric video components as well as their temporal evolution, forming spatio-temporal 3 D geometric primitives. Through this PhD dissertation, different aspects on the use of adaptivity in video representation are studied looking toward exploiting both aspects of video: its piecewise nature and the geometry. The first part of this work studies the use of localized temporal adaptivity in subband video coding. This is done considering two transformation schemes used for video coding: 3 D wavelet representations and motion compensated temporal filtering. A theoretical R-D analysis as well as empirical results demonstrate how temporal adaptivity improves coding performance of moving edges in 3 D transform (without motion compensation) based video coding. Adaptivity allows, at the same time, to equally exploit redundancy in non-moving video areas. The analogy between motion compensated video and 1 D piecewise-smooth signals is studied as well. This motivates the introduction of local length adaptivity within frame-adaptive motion compensated lifted wavelet decompositions. This allows an optimal rate-distortion performance when video motion trajectories are shorter than the transformation "Group Of Pictures", or when efficient motion compensation can not be ensured. After studying temporal adaptivity, the second part of this thesis is dedicated to understand the fundamentals of how can temporal and spatial geometry be jointly exploited. This work builds on some previous results that considered the representation of spatial geometry in video (but not temporal, i. e, without motion). In order to obtain flexible and efficient (sparse) signal representations, using redundant dictionaries, the use of highly non-linear decomposition algorithms, like Matching Pursuit, is required. General signal representation using these techniques is still quite unexplored. For this reason, previous to the study of video representation, some aspects of non-linear decomposition algorithms and the efficient decomposition of images using Matching Pursuits and a geometric dictionary are investigated. A part of this investigation concerns the study on the influence of using a priori models within approximation non-linear algorithms. Dictionaries with a high internal coherence have some problems to obtain optimally sparse signal representations when used with Matching Pursuits. It is proved, theoretically and empirically, that inserting in this algorithm a priori models allows to improve the capacity to obtain sparse signal approximations, mainly when coherent dictionaries are used. Another point discussed in this preliminary study, on the use of Matching Pursuits, concerns the approach used in this work for the decompositions of video frames and images. The technique proposed in this thesis improves a previous work, where authors had to recur to sub-optimal Matching Pursuit strategies (using Genetic Algorithms), given the size of the functions library. In this work the use of full search strategies is made possible, at the same time that approximation efficiency is significantly improved and computational complexity is reduced. Finally, a priori based Matching Pursuit geometric decompositions are investigated for geometric video representations. Regularity constraints are taken into account to recover the temporal evolution of spatial geometric signal components. The results obtained for coding and multi-modal (audio-visual) signal analysis, clarify many unknowns and show to be promising, encouraging to prosecute research on the subject. Le signal vidéo est une séquence d'images en mouvement, dont les images sont souvent modelées comme des signaux réguliers par morceaux. Ainsi, le signal vidéo peut être considéré comme un signal 3 D régulier par morceaux, et composé de régions qui suivent un certain mouvement a travers le temps. La modélisation du signal vidéo par morceaux permet d'analyser en détail le comportement de différentes stratégies de codage, et ainsi de déterminer quelles sont les approches les plus appropriées pour maximiser le taux de compression. Afin de permettre un codage efficace de la vidéo, il est nécessaire d'utiliser des méthodes adaptatives de décomposition du signal. Cette adaptabilité doit être optimisée pour garantir une modélisation du signal avec un coût de codage minimum. La nature du signal vidéo est fortement liée à sa structure, avec une forte composante géométrique. Celle-ci inclut tant la géométrie temporelle (<b>normalement</b> représentée par l'information du mouvement) que la géométrie spatiale. La plupart des méthodes utilisées pour la représentation du signal vidéo ne tient pas compte de sa géométrie spatiale. De même que dans le cas des images, une stratégie prometteuse pour exploiter conjointement la structure géométrique spatio-temporelle est celle qui utilise des dictionnaires redondants avec une forte composante géométrique. Dans le contexte de la vidéo, les primitives géométriques 2 D doivent suivre une évolution temporelle en formant des complexes primitives 3 D qui ont la fonction de représenter, en même temps, les composantes géométriques spatiales et temporelles du signal. Dans cette thèse de doctorat, plusieurs aspects concernant l'utilisation de méthodes adaptatives pour la modélisation du signal vidéo sont traités. Cette thèse traite particulièrement des aspects structurels de la vidéo ainsi que de sa nature géométrique. La première partie du présent travail porte sur l'étude de l'utilisation de décompositions temporelles adaptatives dans des approches basées sur la décomposition de la vidéo en sous-bandes. L'influence de l'adaptabilité est notamment discutée pour deux stratégies de codage: les transformées en ondelettes 3 D et le filtrage temporel avec compensation de mouvement. Les avantages de l'utilisation d'adaptabilité dans des représentations basées sur la transformée en ondelettes 3 D sont démontrés à l'aide d'une étude théorique R-D ainsi que par des résultats expérimentaux. L'utilisation de l'adaptabilité dans le cadre du filtrage temporel avec compensation du mouvement est aussi étudiée en faisant une analogie entre le signal vidéo, avec le mouvement compensé, et les signaux réguliers par morceaux 1 D. Cette analogie suggère l'introduction des transformées de longitude localement variable dans des schémas de décomposition par ondelettes bases sur des lifting steps. Cette modification permet une plus forte compression du signal grâce à une meilleure adaptation de la représentation des trajectoires de mouvement avec une longueur inférieure à celle du Groupe d'Images (GOP - en anglais -) ou quand l'erreur due à la compensation de mouvement est trop élevé. Après l'étude d'adaptabilité temporelle, une deuxième partie de cette thèse se concentre également sur l'étude et la compréhension des concepts de base pour exploiter, conjointement, la structure géométrique spatio-temporelle du signal. Cette recherche se base sur des études précédentes qui tenaient compte de la géométrie spatiale de la vidéo, sans considérer son évolution temporelle (mouvement). Afin d'obtenir des représentations flexibles et efficaces (parcimonieuses), avec des dictionnaires redondants, il faut utiliser des algorithmes de décomposition hautement non linéaires, tels que les algorithmes gloutons (Greedy algorithms et Matching Pursuits en anglais). L'utilisation de ces techniques est encore peu explorée. Pour cette raison, avant d'étudier de telles représentations, certains aspects liés à l'utilisation de ces algorithmes conjointement avec des dictionnaires cohérents pour l'approximation des images et de la vidéo sont étudiés. Une partie de cette étude présente l'utilisation des modèles à priori dans des algorithmes non-linéaires comme les Matching Pursuits. En fonction du dictionnaire utilisé, et du signal, les Matching Pursuits peuvent avoir des grandes difficultés pour arriver à obtenir des expansions parcimonieuses optimales. Basé sur ce résultat, il peut être démontré, de manière théorique et expérimentale, que l'utilisation des modèles à priori (comme par exemple des modèles probabilistes) peut contribuer très significativement à l'amélioration des performances de ces algorithmes. Une autre partie de l'étude préliminaire, pour l'utilisation des Matching Pursuits, concerne l'approche utilisée dans cette thèse pour la décomposition du signal vidéo et des images. L'approche proposé dans cette thèse améliore une méthode existante de Matching Pursuits utilisée dans le passé dans un but similaire. Cette méthode était basée, pour des raisons de complexité calculatoire, sur l'utilisation d'algorithmes génétiques. La méthode proposée dans cette thèse rend possible, d'une manière plus rapide et efficace, la substitution de l'algorithme génétique par une recherche exhaustive. Finalement, l'utilisation des Matching Pursuits avec des modèles à priori pour la décomposition du signal vidéo est étudiée. Des critères de régularité ont étés imposés afin de capturer l'évolution temporelle des composantes géométriques 2 D. Les résultats obtenus pour le codage de ces représentations, ainsi que les résultats issus des analyses multimodales (audio/vidéo) d'une séquence, permettent d'éclaircir une grand partie des points incompris jusqu'alors sur l'utilisation des dictionnaires redondants avec des Matching Pursuits pour les représentations géométriques adaptatives en espace et en temps du signal vidéo...|$|E
40|$|Canine {{idiopathic}} {{pulmonary fibrosis}} (cIPF) is a fibrotic disease of the pulmonary parenchyma, mainly seen in the West Highland white terrier. It is characterized by exercise intolerance and cough with a progressive deterioration until death from respiratory insufficiency. Clinical, tomodensitometric and histological characteristics of cIPF have been described recently. However, this disease remains largely unknown and the clinicians are dealing with two major challenges: confirmation of the diagnosis, which requires many complementary exams, and absence of effective treatment. Identification of a targeted therapy is difficult without having {{a good understanding of}} the mechanisms leading to pulmonary parenchyma fibrosis. A similar disease, the {{idiopathic pulmonary fibrosis}} (IPF) is recognized in humans and cIPF might be interesting as a spontaneous model. This project in dogs was undertaken to answer, at least partly, to these challenges. The aims were to elucidate some mechanisms involved in cIPF pathogenesis and to identify biomarkers {{that could be used in}} the diagnosis process. The hypotheses were first that analysis of the transcriptome through microarray experiment would identify altered biological functions in cIPF, highlight specific molecules with an altered expression and identify potential biomarkers. Another hypothesis was the transforming growth factor beta 1 (TGFB 1) pathways, considered central in the pathogenesis of IPF, would also be modified in cIPF. Finally, ET 1, a known biomarker in human IPF, might also be an interesting biomarker in dogs. Gene expression analysis through microarray analysis, combined with the use of IPA, a data analysis program, identified altered biological functions in cIPF: cellular growth and proliferation, developmental processes, cellular movement, cell to cell signaling and interaction and antigen presentation. Some genes highlighted in the microarray experiment were then analyzed individually. Quantitative RT-PCR analysis confirmed an upregulation of the expression of CCL 2, CCL 7, CXCL 14, IL 8 and FAP (fibroblast activation protein) as well as a downregulation of the expression of PLUNC (palate, lung and nasal epithelium associated). We then complete the gene expression analysis with a search for potential biomarkers. Thirty-four potential biomarkers were identified with 32 biomarkers potentially measurable in blood (including CCL 2, serum amyloid 1, IL 8) and 2 biomarkers measurable only in the bronchoalveolar lavage fluid (BALF) (PLUNC and mesothelin). This approach was validated by measurement in serum of one of this biomarker: CCL 2. CCL 2 serum concentration was higher in affected WHWT compared to healthy WHWT and also higher in dogs with cIPF compared to dogs with chronic bronchitis (CB) or eosinophilic bronchopneumopathy (EBP). Based on serum CCL 2 determination, cIPF was diagnosed with a sensibility of 92 % and a specificity of 80 %. We then studied TGFB 1 and part of its storage, activation and signaling pathways. TGFB 1 gene expression was not significantly different in the pulmonary parenchyma between affected and control dogs. However, in affected dogs, increased TGFB 1 protein levels were seen by immunohistochemistry in fibrotic areas. High expression of bothTGFB 1 type I receptor and phosphorylated Smad 2 / 3, markers of an active intracellular TGFB 1 signal, were seen in epithelial cells. No difference in expression for the storage proteins LTBP 1 and LTBP 2 was seen while expression of LTBP 4 was significantly decreased in dogs with cIPF. Concerning the proteins involved in TGFB 1 activation, gene expression was decreased for integrin subunit β 8, increased for thrombospondin- 1 and not modified for integrin subunit β 6. Expression of Smad 7, involved in intracellular TGFB 1 signal inhibition, was not modified. No difference for TGFB 1 serum concentration was seen between WHWT with cIPF and healthy WHWT. A multivariate analysis performed on healthy dogs showed no age effect but a significant breed effect with higher levels in predisposed breeds. We evaluated part of the serotonin pathway, as one of its receptor (5 HTR 2 B) was highlighted during the gene expression analysis. Serotonin has also been involved in the pathogenesis of human IPF and described to be of potential use as a biomarker in degenerative mitral valve disease in dogs. Expression of 2 serotonin receptors (5 HTR 2 A and 5 HTR 2 B), evaluated by quantitative RT-PCR in pulmonary tissue, was not different between dogs with cIPF and control dogs while expression of the serotonin transporter (5 HTT) was significantly lower in affected dogs. No difference in serotonin serum level was seen between affected and healthy WHWT or between dogs with cIPF, CB or EBP. ET 1 was evaluated as a biomarker in serum and BALF. ET 1 serum concentration was not different between healthy WHWT and Beagles. Covariance analysis did not reveal any significant age effect. Serum levels were significantly higher in dogs with cIPF compared to dogs with CB or EBP. ROC curve analysis was then used to evaluate its diagnostic performances. The area under the curve was 0, 818 with a sensitivity of 91. 7 % and a specificity of 87. 5 %. ET 1 was also measured in the BALF in a small number of dogs. Its concentration was measurable in all dogs with cIPF while it was below the detection limit in all other dogs tested (healthy and with CB). Even though cIPF and human IPF are not completely identical from clinical, tomodensitometric or histological points of view, these results show that both canine and human diseases share molecular pathways, supporting the idea that cIPF might have an interest as spontaneous model. 	 This work allowed a better understanding of cIPF pathogenesis. Gene expression analysis in the pulmonary parenchyma of affected dogs first identified several altered biological functions that should be analyzed in details in further studies. A more targeted analysis of some genes confirmed an upregulated expression of CCL 2, CCL 7, CXCL 14, IL 8 and FAP. Such a positive regulation of the expression of various inflammatory cytokines tends to suggest that inflammation might have a role in cIPF pathogenesis. Some of these cytokines also have profibrotic properties. PLUNC was one of the top down-regulated genes. Roles of the protein are still largely unknown; it might have a role in the inflammatory response and in the innate immunity. Developmental pathways were also altered in cIPF and quantitative RT-PCR confirmed an upregulation of FAP, a protein normally expressed in areas of tissue remodeling during fetal development and also positively regulated in human IPF. This study has shown that there is an active TGFB 1 signal in the lungs of dogs with cIPF, especially at the level of the pathological epithelium. TGFB 1 storage and activation pathways also seemed to be altered. Elevated TGFB 1 circulating levels were found in predisposed breeds, which might explain at least partly their susceptibility for cIPF. Because of these results and its well-known profibrotic properties, we can suggest that TGFB 1 is probably involved in cIPF pathogenesis and that modulation of its storage, activation or intracellular signaling might offer potential therapeutic targets. Our preliminary results are not in favor of a significant modification of the serotonin pathways in cIPF, although a decreased expression of 5 HTT was seen in affected dogs and might have an impact on the amount of serotonin present locally. However, other studies are needed to conclude. Finally, several potential biomarkers have been identified and some of them were evaluated in details. While serum measurements performed for TGFB 1 and serotonin indicated that these molecules have no interest as diagnostic biomarkers, ET 1 and CCL 2 were identified as interesting candidates with good diagnostic performances. However these results need to be confirmed in an independent validation cohort and the interest of combining both biomarkers should be evaluated. La fibrose pulmonaire idiopathique canine (FPIc) est une affection fibrotique du parenchyme pulmonaire, majoritairement rencontrée chez le West Highland White Terrier (WHWT). Elle se traduit par une intolérance à l’effort et de la toux avec aggravation progressive jusqu’au décès de l’animal par insuffisance respiratoire. Ses caractéristiques cliniques, tomodensitométriques et histologiques ont été décrites récemment. Cette maladie reste toutefois très peu connue et le clinicien doit faire face à deux challenges majeurs : la confirmation du diagnostic, qui requiert de nombreux examens complémentaires, et l’absence d’un traitement efficace. Or, l’identification d’une thérapie ciblée est très difficile en l’absence d’une bonne compréhension des mécanismes conduisant à la fibrose du parenchyme pulmonaire. Une affection comparable est par ailleurs rencontrée chez l’homme, la fibrose pulmonaire idiopathique (FPI), et la FPIc pourrait avoir un intérêt en tant que possible modèle spontané. Ce projet a donc été entrepris afin de répondre au moins partiellement à ces différents challenges. Ces objectifs étaient ainsi d’élucider certains mécanismes intervenant dans la pathogénie de la FPIc et d’identifier des biomarqueurs pouvant aider à son diagnostic. Les hypothèses de travail étaient tout d’abord que l’analyse du transcriptome au niveau pulmonaire par la technique des microdamiers permettrait d’identifier de grandes fonctions biologiques altérées lors de FPIc, de mettre en avant plus spécifiquement certaines molécules dont l’expression est fortement altérée et d’identifier des biomarqueurs potentiels. Une autre hypothèse était que les voies du « transforming growth factor beta 1 » (TGFB 1), molécule centrale dans la pathogénie de la FPI chez l’homme, seraient également altérées lors de FPIc. Enfin, l’endothéline- 1 (ET 1), biomarqueur connu dans la FPI humaine, pourrait également avoir un intérêt en tant que biomarqueur chez le chien. L’analyse du transcriptome au niveau pulmonaire, par la technique des microdamiers et grâce à l’utilisation d’un programme informatique d’analyse de données, a tout d’abord identifié différentes fonctions biologiques altérées lors de FPIc : la croissance, la prolifération, le mouvement et le développement cellulaires, le développement et le fonctionnement du système musculo-squelettique, le développement embryonnaire, la signalisation et les interactions intercellulaires et la présentation antigénique. Certains gènes mis en avant par cette analyse (particulièrement surexprimés ou sous-exprimés chez l’animal malade,) ont ensuite été étudiés individuellement. L’analyse par RT-PCR quantitative a confirmé une régulation positive de l’expression de CCL 2, CCL 7, CXCL 14, IL 8 et FAP (fibroblast activation protein) ainsi qu’une régulation négative de la PLUNC (palate, lung and nasal epithelium associated). Nous avons ensuite complété l’analyse du profil d’expression par une recherche de biomarqueurs potentiels. Trente-quatre biomarqueurs potentiels ont ainsi pu être identifiés dont 32 pourraient être mesurables dans le sang (dont le CCL 2, l’amyloïde sérique 1 et l’IL 8), et 2 uniquement dans le liquide de lavage bronchoalvéolaire (LLBA) (PLUNC et mésothéline). La validité de cette approche a été confirmée par la mesure dans le sérum de l’un de ces biomarqueurs : le CCL 2. Une concentration sérique plus élevée a été retrouvée chez les WHWT atteints en comparaison de WHWT sains. Elle était également plus élevée chez les chiens atteints de FPIc que chez ceux atteints de bronchite chronique (BC) ou de bronchopneumopathie éosinophilique (BPE); une FPIc étant diagnostiquée avec une sensibilité de 92 % et une spécificité de 80 %. Nous avons ensuite étudié le TGFB 1 et certaines de ses voies de stockage, d’activation et de signalisation. L’expression génique pour le TGFB 1 n’était pas significativement différente au niveau du parenchyme pulmonaire entre des chiens atteints de FPIc et des chiens contrôles. Toutefois, lors de FPIc, des taux élevés de la protéine TGFB 1 ont été mis en évidence par immunohistochimie dans les zones fibrotiques. Les cellules épithéliales présentaient également une expression importante en récepteur de type I du TGFB 1 et en Smad 2 / 3 phosphorylées, marqueur d’une activation de la signalisation intracellulaire du TGFB 1. Aucune différence d’expression génique n’était notée entre des chiens atteints et des chiens contrôles pour les protéines de stockage LTBP 1 et LTBP 2 alors que l’expression de LTBP 4 était significativement diminuée chez les chiens atteints. Concernant l’expression des protéines impliquées dans l’activation du TGFB 1, l’expression de la sous-unité intégrine β 8 était significativement diminuée et l’expression de la thrombospondine- 1 significativement augmentée lors de FPIc; celle de la sous-unité β 6 n’était pas modifiée. L’expression de Smad 7, une protéine inhibant la signalisation intracellulaire du TGFB 1, n’était pas non plus modifiée. Aucune différence dans la concentration sérique en TGFB 1 n’était notée entre des WHWT atteints et sains. Une analyse multivariée réalisée chez des chiens sains de différentes races n’a pas mis en évidence d’effet de l’âge mais un effet significatif du facteur race avec une concentration sérique en TGFB 1 significativement plus élevée dans les races prédisposées. Nous avons ensuite analysé une partie des voies de la sérotonine, un de ces récepteurs (5 HTR 2 B) ayant été retrouvé lors de l’analyse du profil d’expression de la FPIc. La sérotonine a également déjà été impliquée dans la pathogénie de la FPI chez l’homme et décrite comme biomarqueur potentiel chez le chien lors d’endocardiose mitrale. L’expression des deux récepteurs de la sérotonine (5 HTR 2 A, 5 HTR 2 B), évaluée par RT-PCR quantitative à partir du tissu pulmonaire, n’était pas différente entre les chiens avec FPIc et les chiens contrôles, alors que l’expression du transporteur de la sérotonine (5 HTT) était significativement plus faible dans le groupe FPIc. Concernant la concentration sérique en sérotonine, aucune différence n’a été notée entre les WHWT atteints de FPIc et les WHWT sains ni entre les chiens avec FPIc et les chiens avec BC ou BPE. L’ET 1 a été évaluée en tant que biomarqueur dans le sérum et le LLBA. Aucune différence significative n’a été mise en évidence entre les concentrations sériques en ET 1 obtenues chez les WHWT sains et les Beagles. L’analyse de covariance n’a pas mis en évidence d’influence du facteur âge. La concentration sérique en ET 1 était significativement plus élevée lors de FPIc par rapport à la BPE et à la BC. Les performances de l’ET 1 à distinguer une FPIc d’une BC ou d’une BPE ont ensuite été évaluées par l’analyse de la courbe ROC. L’aire sous la courbe était de 0, 818 et la sensibilité et la spécificité de 91, 7 % et 87, 5 % respectivement. Au cours de cette étude, l’ET 1 a également été mesurée dans le LLBA chez un nombre de limité de chiens. Elle était mesurable chez tous les chiens atteints de FPIc alors que sa concentration était inférieure au seuil de détection chez les autres chiens testés (sains et atteints de BC). Même si la FPIc et la FPI chez l’homme ne sont pas parfaitement identiques d’un point de vue tomodensitométrique, histologique ou pathogénique, ces résultats mettent enfin en évidence que ces deux affections partagent certains mécanismes moléculaires et que la FPIc pourrait ainsi avoir un intérêt en tant que modèle spontané. Ce travail nous a permis de mieux comprendre la pathogénie de la FPIc. L’étude du profil d’expression génique au niveau pulmonaire chez les chiens atteints a d’abord permis d’identifier différentes fonctions biologiques altérées lors de FPIc et qui pourront faire l’objet par la suite d’une étude plus détaillée. L’analyse plus ciblée de certains gènes a confirmé une surexpression de CCL 2, CCL 7, CXCL 14, IL 8 et de FAP. Ces résultats indiquent une régulation positive de l’expression de différentes cytokines inflammatoires, suggérant que l’inflammation pourrait avoir un rôle dans la pathogénie de la FPIc. Par ailleurs, certaines de ces cytokines ont également des propriétés profibrotiques. Le gène de la PLUNC était l’un de ceux dont l’expression était nettement réprimée. Le rôle de cette protéine reste encore à définir, elle pourrait notamment intervenir dans la réponse inflammatoire et l’immunité innée. Les voies du développement faisait également partie des voies altérées dans la FPIc. Parmi les gènes impliqués, l’analyse par RT-PCR quantitative a confirmé une surexpression de la FAP, protéine <b>normalement</b> exprimée dans les zones de remodelage tissulaire lors du développement embryonnaire et également régulée positivement lors de FPI chez l’homme. Cette étude a permis de démontrer qu’une signalisation active en TGFB 1 existait au sein des poumons atteints de FPIc, notamment au niveau de l’épithélium pathologique. Elle suggère également que les voies de stockage et d’activation du TGFB 1 sont altérées lors de FPIc. Des taux élevés de TGFB 1 circulant sont retrouvés dans les races prédisposées, ce qui pourrait au moins partiellement influencer leur susceptibilité à la FPIc. Au regard des propriétés profibrotiques du TGFB 1 et de ces résultats, nous pouvons suggérer que le TGFB 1 est probablement impliqué dans la pathogénie de la FPIc et que la modulation de son stockage, de son activation ou de sa signalisation intracellulaire représente des cibles thérapeutiques potentielles. Nos premiers résultats ne sont pas en faveur d’une modification importante des voies de la sérotonine dans la FPIc et donc de son implication dans la pathogénie. Une expression pulmonaire plus faible du transporteur 5 HTT a toutefois été notée chez les chiens atteints de FPIc en comparaison de chiens sains. Cette régulation négative de l’expression du 5 HTT pourrait avoir un impact sur la quantité de sérotonine présente au sein du tissu. Il s’agit toutefois de spéculations et d’autres études sont nécessaires pour conclure. Au cours de ce travail, différents biomarqueurs potentiels ont été identifiés et certains ont été évalués en détail. Alors que les mesures sériques réalisées lors de l’étude du TGFB 1 et de la sérotonine indiquent que ces derniers n’ont pas d’intérêt en tant que biomarqueur diagnostique, il semble que l’ET 1 et le CCL 2 sériques présentent de très bonnes performances diagnostiques. Ces résultats doivent toutefois être validés sur une population indépendante. La combinaison de différents biomarqueurs identifiés par la suite pourrait également s’avérer intéressante...|$|E
40|$|It {{has been}} known for more than 150 years that action effects in bridges due to traffic action are higher than it has to be {{expected}} for purely static loads. In the design of road bridges, this difference is considered by multiplying static traffic loads with a "dynamic amplification factor". The amplification factors defined in codes are based on dynamic load tests on existing bridges. Despite of hundreds of tests in several countries, experimental investigation has not given satisfactory explanation of the observed phenomena, which has resulted in marked differences between amplification factors defined in different codes. This {{is due to the fact}} that the core of the matter – the dynamic interaction between vehicles and bridges– is a complex mechanical problem. Based on a detailed analysis it is shown in the introduction, that it can also be attributed to the fact, that the experimental investigation is more part of the problem than its solution. This thesis aims at getting a solid and systematic grounding in the problem using theoretical analysis. The centre of attention is the question, which importance dynamic phenomena have in those scenarios which are effectively relevant for the structural safety of a bridge. All scenarios are considered that justify an amplification factor, and not only dynamic vehicle – bridge interaction. The structural safety evaluation of a bridge includes the verification of the ultimate and the fatigue limit state. Accordingly, this thesis distinguishes between the interaction at ultimate limit state, for which inelastic bridge behaviour is assumed, and the interaction at service limit state with linear elastic bridge behaviour. The structural analysis of a bridge shows in addition, that the elements of the bridge deck differ considerably from the main girders: For the elements of the deck – i. e. primarily for the deck slab – dynamic interaction is of little importance, and amplification of action effects is essentially due to amplification of traffic action. In the case of the main girders, action effects are additionally amplified due to the oscillations of the structure. In order to analyse interaction at service limit state in detail, very sophisticated models are required, which do not only cover all relevant eigenmodes of the bridge but also the non-linear, dynamic behaviour of heavy vehicles and the precise road surface profile. Design and analysis of such models are mostly conferred to specialists in numeric analysis and structural dynamics. In the contrary, this thesis aims at capturing the fundamental connections by simple models, which facilitates the identification of the key parameters and the interpretation of their influence. The most important result of the analysis of vehicle – bridge interaction at service limit state is that the amplification factor is most influenced by the weight and the number of vehicles on a bridge. Whereas the amplification is negligible for high vehicle loads, tests with relatively lightweight vehicles on long bridges lead to a significant over-estimation of amplification factors. Furthermore it is shown that neither the span nor the natural frequency of a bridge is appropriate for fixing the amplification factor for a particular bridge and safety verification, respectively. It has been observed in dynamic load tests that deflection measurements consistently result in higher amplification factors than strain measurements. This phenomenon {{has been known}} for more than fifty years, but no explanation has been given so far. In this thesis an explanation is proposed and it is shown that deflection measurements result in an over-estimation of amplification factors. Similar considerations lead to a proposal for a more suitable application of amplification factors in the verification of shear force. A completely new approach is chosen for the analysis of vehicle – bridge interaction at ultimate limit state. The effective behaviour at rupture is taken into account, which necessitates first to deal with the influence of loading velocity on material strength. It is shown that only for impact loading of deck slabs due to dynamic tyre forces a minor increase in concrete strength can be expected. An important prerequisite for the understanding of dynamic behaviour at ultimate limit state is the "gravity effect", which is shown to cause massive reduction in the dissipation capacity of a structure. The determinant criterion with inelastic behaviour is deformability and not stiffness. Simple models are used to study the influence of deformability and gravity effect in the most important cases of dynamically amplified traffic action. The results show, under which conditions the dynamic amplification of action effects can be compensated by plastic deformation of the structure without causing its failure. If the steel yield stress is already attained due to the static part of traffic action, compensation of the dynamic part is only assured if the rupture behaviour is characterised by strain hardening. A simple condition of equilibrium shows that dynamic amplification due to centrifugal forces cannot be absorbed by deformations of the structure. However, rupture behaviour characterised by significant deformation causes a delay in the failure of the structure, which can be sufficient to prevent the definitive rupture anyway, depending on the scenario. In addition to these reflections, it is attempted to determine the importance of shear failures with respect to flexural failures, in order to estimate the probability of this comparatively brittle failure mechanism. In view of the application of the findings, the relevant results are synthesized and a concept for the safety verification accounting for dynamic traffic action is developed. The concept is based on the distinction between verifications at ultimate and service limit state on the one hand, and the separate treatment of elements of the deck and main girders on the other hand. This differentiation allows integrating risk based considerations using explicit hazard scenarios. An important point in the application of the findings is the recommendation to emphasize the benefit of good road surface evenness in the maintenance of structures. A necessary complement in establishing the recommended amplification factors is the detailed analysis of the reaction of vehicles to road surface irregularities. The dynamic tyre forces for different vehicle and axle types, respectively, are analysed, since the findings indicate that the amplification of tyre forces is much more important in fixing amplification factors than the dynamic behaviour of bridges. The investigations clearly show that higher axle loads imply lower amplification factors, and that the maximum amplification of axle forces in axle groups never occurs simultaneously for all axles. The thesis is finished by an annexe including introductions to the dynamic behaviour of vehicles and bridges as well as to the modelling of traffic loads and road surface irregularities. In addition to an extensive review of the state of the art, these introductions constitute an important basis of the work and facilitate understanding of the calculations in the main part. Seit mehr als 150 Jahren ist bekannt, dass die Beanspruchung einer Brücke bei der Belastung durch bewegte Fahrzeuge höher ist als bei Stillstand derselben Fahrzeuge. Diesem Unterschied wird in der Bemessung von Strassenbrücken dadurch Rechnung getragen, dass die statischen Verkehrslasten mit einem "dynamischen Vergrösserungsfaktor" multipliziert werden. Die in den Tragsicherheitsnachweisen verwendeten Vergrösserungsfaktoren stützen sich auf Lastversuche an bestehenden Brücken. Trotz hunderter Versuche in diversen Ländern haben diese Versuche jedoch keine befriedigende Erklärung der Phänomene geliefert, sodass sich die Vergrösserungsfaktoren von Land zu Land teilweise beträchtlich unterscheiden. Dies hängt damit zusammen, dass es sich beim Kernproblem – der dynamischen Wechselwirkung zwischen Fahrzeug und Brücke – um eine komplizierte mechanische Fragestellung handelt. Aufgrund einer eingehenden Analyse in der Einleitung wird dies jedoch auch darauf zurückgeführt, dass die experimentelle Untersuchung mehr Teil des Problems als dessen Lösung ist. Diese Arbeit zielt darauf ab, die Fragestellung aufgrund einer theoretischen Analyse systematisch aufzubereiten. Im Zentrum steht dabei die Fragestellung, welche Bedeutung dynamische Phänomene in jenen Szenarien haben, welche effektiv für die Tragsicherheit einer Brücke massgeblich sind. Zudem werden alle Szenarien betrachtet, welche einen Vergrösserungsfaktor rechtfertigen, und nicht nur die Szenarien mit dynamischer Wechselwirkung. Der Tragsicherheitsnachweis einer Brücke umfasst die Nachweise des Bruch- und des Ermüdungswiderstands. Dementsprechend wird unterschieden zwischen der Wechselwirkung auf Bruchniveau, bei der von inelastischem Materialverhalten ausgegangen wird, sowie der Wechselwirkung auf Gebrauchsniveau unter Beschränkung auf rein elastisches Verhalten. Die Analyse des Tragverhaltens einer Brücke zeigt zudem, dass sich die Elemente der Fahrbahn von den Brückenlängsträgern ganz wesentlich unterschieden: Bei den Elementen der Fahrbahn – das heisst vor allem bei der Fahrbahnplatte – spielt die dynamische Wechselwirkung praktisch keine Rolle, und die Vergrösserung der Beanspruchung besteht im Wesentlichen aus der Lastvergrösserung. Bei den Brückenlängsträgern erhöht sich die Beanspruchung, zusätzlich zur Lastvergrösserung, durch deren eigene Schwingungen. Zur genauen Erfassung der dynamischen Wechselwirkung auf Gebrauchniveau sind sehr komplizierte Modelle erforderlich, welche nicht nur alle Eigenschwingungsformen der Brücke sondern auch das nicht-lineare, dynamische Verhalten von Fahrzeugen sowie die Fahrbahnunebenheiten präzise abbilden. Erstellung und Analyse dieser Modelle werden daher meistens von Spezialisten der Numerik und Baudynamik übernommen. In der vorliegenden Arbeit wird im Gegensatz dazu versucht, die wesentlichen Zusammenhänge durch möglichst einfache Modelle zu erfassen. Dies vereinfacht es, den Einfluss der wichtigsten Parameter zu erfassen und auszuwerten. Das wichtigste Resultat der Analyse der Wechselwirkung auf Gebrauchsniveau ist, dass das Fahrzeuggewicht sowie die Anzahl an Fahrzeugen auf einer Brücke einen enormen Einfluss auf den Vergrösserungsfaktor haben. Während die dynamische Vergrösserung bei hohen Verkehrslasten praktisch vernachlässigbar ist, führen Versuche mit relativ leichten Fahrzeugen auf langen Brücken zu einer markanten Überschätzung des Vergrösserungsfaktors für den Tragsicherheitsnachweis. Weiters konnte gezeigt werden, dass sich weder die Spannweite einer Brücke noch deren Grundfrequenz zur Festlegung eines Vergrösserungsfaktors eignen. Bei dynamischen Lastversuchen ergeben Durchbiegungsmessungen durchwegs höhere Vergrösserungsfaktoren als Dehnungsmessungen. Dieses Phänomen ist seit fünfzig Jahren bekannt, ohne dass bisher eine Erklärung gegeben werden konnte. In dieser wird eine Erklärung vorgeschlagen und gezeigt, dass der Vergrösserungsfaktor aufgrund von Durchbiegungsmessungen deutlich überschätzt wird. Analoge Überlegungen erlauben auch zu zeigen, wie die dynamische Vergrösserung der Querkraft besser erfasst werden kann als dies bis anhin der Fall ist. Für die Analyse der Wechselwirkung auf Bruchniveau wird ein gänzlich neuer Ansatz gewählt, der das effektive Bruchverhalten der Brücke berücksichtigt. Daher wird zuerst grundsätzlich auf den Einfluss der Belastungsgeschwindigkeit bei der Beanspruchung durch Verkehrslasten eingegangen. Es zeigt sich, dass nur bei der stossförmigen Belastung der Fahrbahnplatte durch dynamische Radkräfte eine gewisse Erhöhung der Festigkeiten erwartet werden kann. Eine wichtige Voraussetzung für das Verständnis des dynamischen Verhaltens auf Bruchniveau ist die Schwerkraftwirkung. Diese bewirkt eine drastische Verringerung der Dissipationskapazität des Tragwerks. Entscheidend ist bei inelastischem Verhalten die Verformbarkeit und nicht die Steifigkeit des Tragwerks. Anhand einfacher Modelle wird versucht, die wichtigsten Szenarien mit dynamischer Vergrösserung zu erfassen, wobei in erster Linie das Versagen auf Biegung untersucht wird. Anhand des Vergleichs der Resultate für verschiedene Kraft-Verschiebungs-Diagramme wird abgeschätzt, unter welchen Voraussetzungen der dynamische Anteil der Beanspruchung durch plastische Verformungen aufgenommen werden kann, ohne dass es zum Bruch kommt. Wenn die statische Beanspruchung bereits das Fliessmoment erreicht, dann gelingt dies aufgrund der Schwerkraftwirkung nur noch bei einem Bruchverhalten mit Dehnungsverfestigung. Anhand einer einfachen Gleichgewichtsbetrachtung wird gezeigt, dass bei der dynamischen Lastvergrösserung infolge von Kurvenfahrt oder Bremsung der dynamische Anteil der Einwirkung nicht dissipiert werden kann. Ein verformungsreiches Bruchverhalten führt in diesem Fall jedoch zu einer Verzögerung des Bruchs, die je nach Szenario ausreichen kann, damit ein Auto den Gefahrenbereich verlässt. Darüber hinaus wird auch versucht, die Bedeutung des Schubbruchs im Vergleich zum Biegebruch zu bestimmen, um die Wahrscheinlichkeit dieses verformungsarmen Bruchs abzuschätzen. Die gewonnenen Erkenntnisse fliessen schliesslich in ein Nachweiskonzept ein, in welchem geeignete Vergrösserungsfaktoren angegeben werden, wobei einerseits zwischen Bruch- und Gebrauchsniveau und andererseits zwischen Elementen der Fahrbahn und Brückenlängsträgern unterschieden wird. Die empfohlenen Werte beruhen dabei auf expliziten Gefährdungsbildern, was die Einbeziehung von Risikoüberlegungen ermöglicht. Die Erkenntnisse zeigen bei der Erhaltung bestehender Brücken künftig mehr auf die Gewährleistung einer möglichst ebenen Fahrbahn zu achten. Abgerundet wird die Arbeit durch ausführliche Einführungen zum dynamischen Verhalten von Schwerfahrzeugen und Strassenbrücken, sowie zu Verkehrslasten und Fahrbahnunebenheiten. Dies erleichtert Fachleuten aus dem Brückenbau den Zugang, welche nicht Spezialisten der Baudynamik sind. Den dynamischen Radkräften verschiedener Fahrzeug- bzw. Achstypen infolge von Fahrbahnunebenheiten wird sehr grosse Aufmerksamkeit gewidmet, da dieser Aspekt oft zu Gunsten der Fokussierung auf das Verhalten der Brücke vernachlässigt wurde. Il est connu depuis plus de 150 ans que les efforts internes d'un pont sollicité par le trafic sont plus grands quand les charges sont en mouvement que quand elles sont à l'arrêt. Cette différence est prise en compte lors du dimensionnement d'un pont routier en multipliant les charges de trafic statiques par un « facteur d'amplification dynamique ». Les facteurs d'amplification utilisés dans la vérification structurale se basent sur des essais de charge sur des ponts routiers existants. Malgré des centaines d'essais dans différents pays, l'expérimentation n'a pas fourni une explication satisfaisante des phénomènes observés. En conséquence, les facteurs d'amplification prescrits dans les normes varient parfois considérablement. D'une coté ceci peut être ramené au fait que le cœur du problème – l'interaction dynamique entre un véhicule et un pont – est un problème mécanique complexe. D'un autre coté, une analyse approfondie dans l'introduction de cette thèse montre que l'étude expérimentale fait plutôt partie du problème que de sa solution. Cette thèse a pour but de traiter le problème de manière systématique à l'aide d'une approche théorique. Le cœur est formé par la question : quelle est l'importance des phénomènes dynamiques dans les scénarios, qui sont effectivement déterminants pour la sécurité structurale d'un pont. Tous les scénarios, qui justifient un facteur d'amplification, sont considérés, et non pas seulement l'interaction dynamique véhicule – pont. L'évaluation de la sécurité structurale d'un pont comprend la vérification de la résistance à l'état ultime ainsi qu'à la fatigue. En conséquence, cette thèse distingue entre l'interaction véhicule – pont à l'état ultime, caractérisée par un comportement inélastique du pont, et l'interaction à l'état de service, où un pont se comporte essentiellement de manière linéaire élastique. L'analyse du comportement structural d'un pont montre de plus que, les éléments du tablier se distinguent fondamentalement des poutres longitudinales : pour les éléments du tablier – principalement la dalle de roulement – l'interaction dynamique n'a pratiquement pas d'importance, et l'amplification de la sollicitation est due à l'oscillation des véhicules. Pour les poutres longitudinales s'ajoutent les oscillations de la structure aux oscillations des véhicules. Une étude théorique précise de l'interaction dynamique au niveau de service nécessite des modèles très complexes, qui reproduisent non seulement les modes d'oscillation d'un pont mais aussi le comportement non-linéaire et dynamique des véhicules ainsi que le profil précis de la chaussée. Par conséquence, le développement et l'analyse de tels modèles sont <b>normalement</b> pris en charge par des spécialistes du calcul numérique et dynamique. Cette thèse tente, au contraire, de reproduire les effets principaux à l'aide de modèles les plus simples possibles. Ceci facilite l'identification des paramètres clés et la mise en évidence de leurs influences. Le résultat principal de l'analyse de l'interaction véhicules - pont à l'état de service est l'identification du poids et du nombre des véhicules comme paramètre principal pour le facteur d'amplification. Alors que l'amplification dynamique est pratiquement négligeable pour des charges très élevées, les essais avec des véhicules relativement légers, sur un grand pont, résultent dans une surestimation significative du facteur d'amplification pour une vérification structurale. En outre on montre que ni une portée, ni la fréquence fondamentale d'un pont, ne sont des critères adéquats pour déterminer un facteur d'amplification dans le cas concret d'une vérification structurale. Lors d'un essai dynamique, les mesures de flèches résultent dans des facteurs d'amplification plus élevés que des mesures de déformations. Ce phénomène est connu depuis cinquante ans, sans qu'une explication n'ait été fournie. Cette thèse propose une explication et montre la surestimation de facteurs d'amplification dérivés de mesures de flèches. Des réflexions analogues amènent à une proposition pour une meilleure application du facteur d'amplification dans la vérification de l'effort tranchant. Une approche nouvelle est utilisée pour analyser l'interaction dynamique à l'état ultime. Elle tient compte du comportement effectif à la rupture, ce qui nécessite d'étudier d'abord l'influence de la vitesse de chargement sur la résistance apparente des matériaux. Dans le cas de charges de trafic, seul une légère augmentation de la résistance du béton de la dalle de roulement est à attendre, si une roue heurte un obstacle. Une condition essentielle pour comprendre le comportement à l'état ultime est « l'effet de la gravité », qui cause une réduction radicale de la capacité de dissipation de la structure. Le critère déterminant dans un comportement inélastique est la déformabilité et non la rigidité. Des modèles simples sont utilisés pour étudier l'influence de la déformabilité ainsi que de l'effet de la gravité dans les scénarios avec une amplification dynamique importante. Les résultats montrent sous quelles conditions l'amplification dynamique peut être compensée par la déformation plastique de la structure sans qu'une rupture n'ait lieu. Si l'acier atteint sa limite d'élasticité sous l'effet des charges statiques, une sollicitation dynamique additionnelle ne peut être compensée si l'acier présente un comportement durcissant. Une simple considération d'équilibre montre que l'amplification dynamique due aux forces centrifuges ou aux forces de freinage ne peut pas être compensé par une déformation de la structure. Dans ce cas, un comportement ductile aide à ralentir la rupture, ce qui peut être suffisante pour permettre un véhicule de passer la zone critique. En outre, des réflexions sont présentées sur l'importance d'une rupture à l'effort tranchant, qui consiste généralement en un mode de rupture avec peu de déformation. On montre que la probabilité que ce mode ait lieu avant une rupture à la flexion est faible. En vue de l'application des résultats, les points les plus importants sont résumés et un concept pour la vérification structurale est développé, qui contient de valeurs explicites pour le facteur d'amplification. Le concept se base sur la distinction entre l'état ultime et l'état de service. On distingue également le cas des éléments du tablier et celui des poutres longitudinales. Cette différentiation permet l'intégration de critères de risque sur la base de scénarios détaillés. En plus du concept de vérification, il est recommandé de mettre l'accent plus explicitement sur le bénéfice d'une bonne planéité de la chaussée lors de la maintenance d'une structure. Un complément nécessaire pour l'établissement des facteurs d'amplification recommandés est l'analyse détaillée de l'excitation de véhicules par les irrégularités dans la chaussée. Les forces de roues dynamiques pour différents types de véhicules et d'essieux, respectivement, sont analysées, car les résultats des autres chapitres indiquent que l'amplification des forces d'essieux est nettement plus importante que le comportement dynamique du pont. Les résultats de cette analyse montrent clairement que des essieux plus chargés ont des facteurs d'amplification plus bas, et que la force maximale n'est jamais atteinte pour tous les essieux d'un groupe simultanément...|$|E
40|$|A {{wide range}} of {{different}} image modalities can be found today in medical imaging. These modalities allow the physician to obtain a non-invasive view of the internal organs {{of the human body}}, such as the brain. All these three dimensional images are of extreme importance in several domains of medicine, for example, to detect pathologies, follow the evolution of these pathologies, prepare and realize surgical planning with, or without, the help of robot systems or for statistical studies. Among all the medical image modalities, Magnetic Resonance (MR) imaging has become of great interest in many research areas due to its great spatial and contrast image resolution. It is therefore perfectly suited for anatomic visualization of the human body such as deep structures and tissues of the brain. Medical image analysis is a complex task because medical images usually involve a large amount of data and they sometimes present some undesirable artifacts, as for instance the noise. However, the use of a priori knowledge in the analysis of these images can greatly simplify this task. This prior information is usually represented by the reference images or atlases. Modern brain atlases are derived from high resolution cryosections or in vivo images, single subject-based or population-based, and they provide detailed images that may be interactively and easily examined in their digital format in computer assisted diagnosis or intervention. Then, in order to efficiently combine all this information, a battery of registration techniques is emerging based on transformations that bring two medical images into voxel-to-voxel correspondence. One of the main aims of this thesis is to outline the importance of including prior knowledge in the medical image analysis framework and the indispensable role of registration techniques in this task. In order to do that, several applications using atlas information are presented. First, the atlas-based segmentation in normal anatomy is shown as it is a key application of medical image analysis using prior knowledge. It consists of registering the brain images derived from different subjects and modalities within the atlas coordinate system to improve the localization and delineation of the structures of interest. However, the use of an atlas can be problematic in some particular cases where some structures, for instance a tumor or a sulcus, exists in the subject and not in the atlas. In order to solve this limitation of the atlases, a new atlas-based segmentation method for pathological brains is proposed in this thesis as well as a validation method to assess this new approach. Results show that deep structures of the brain can still be efficiently segmented using an anatomic atlas even if they are largely deformed because of a lesion. The importance of including a priori knowledge is also presented in the application of brain tissue classification. The prior information represented by the tissue templates can be included in a brain tissue segmentation approach thanks to the registration techniques. This is another important issue presented in this thesis and it is analyzed through a comparative study of several non-supervised classification techniques. These methods are selected to represent the whole range of prior information {{that can be used in}} the classification process: the image intensity, the local spatial model, and the anatomical priors. Results show that the registration between the subject and the tissue templates allows the use of prior information but the accuracy of both the prior information and the registration highly influence the performance of the classification techniques. Another aim of this thesis is to present the concept of dynamic medical image analysis, in which the prior knowledge and the registration techniques are also of main importance. Actually, many medical image applications have the objective of statically analyzing one single image, as for instance in the case of atlas-based segmentation or brain tissue classification. But in other cases the implicit idea of changes detection is present. Intuitively, since the human body is changing continuously, we would like to do the image analysis from a dynamic point of view by detecting these changes, and by comparing them afterwards with templates to know if they are normal. The need of such approaches is even more evident in the case of many brain pathologies such as tumors, multiple sclerosis or degenerative diseases. In these cases, the key point is not only to detect but also to quantify and even characterize the evolving pathology. The evaluation of lesion variations over time can be very useful, for instance in the pharmaceutical research and clinical follow up. Of course, a sequence of images is needed in order to do such an analysis. Two approaches dealing with the idea of change detection are proposed as the last (but not least) issue presented in this work. The first one consists of performing a static analysis of each image forming the data set and, then, of comparing them. The second one consists of analyzing the non-rigid transformation between the sequence images instead of the images itself. Finally, both static and dynamic approaches are illustrated with a potential application: the cortical degeneration study is done using brain tissue segmentation, and the study of multiple sclerosis lesion evolution is performed by non-rigid deformation analysis. In conclusion, the importance of including a priori information encoded in the brain atlases in medical image analysis has been put in evidence with a {{wide range of}} possible applications. In the same way, the key role of registration techniques is shown not only as an efficient way to combine all the medical image modalities but also as a main element in the dynamic medical image analysis. A wide range of different image modalities can be found today in medical imaging. These modalities allow the physician to obtain a non-invasive view of the internal organs of the human body, such as the brain. All these three dimensional images are of extreme importance in several domains of medicine, for example, to detect pathologies, follow the evolution of these pathologies, prepare and realize surgical planning with, or without, the help of robot systems or for statistical studies. Among all the medical image modalities, Magnetic Resonance (MR) imaging has become of great interest in many research areas due to its great spatial and contrast image resolution. It is therefore perfectly suited for anatomic visualization of the human body such as deep structures and tissues of the brain. Medical image analysis is a complex task because medical images usually involve a large amount of data and they sometimes present some undesirable artifacts, as for instance the noise. However, the use of a priori knowledge in the analysis of these images can greatly simplify this task. This prior information is usually represented by the reference images or atlases. Modern brain atlases are derived from high resolution cryosections or in vivo images, single subject-based or population-based, and they provide detailed images that may be interactively and easily examined in their digital format in computer assisted diagnosis or intervention. Then, in order to efficiently combine all this information, a battery of registration techniques is emerging based on transformations that bring two medical images into voxel-to-voxel correspondence. One of the main aims of this thesis is to outline the importance of including prior knowledge in the medical image analysis framework and the indispensable role of registration techniques in this task. In order to do that, several applications using atlas information are presented. First, the atlas-based segmentation in normal anatomy is shown as it is a key application of medical image analysis using prior knowledge. It consists of registering the brain images derived from different subjects and modalities within the atlas coordinate system to improve the localization and delineation of the structures of interest. However, the use of an atlas can be problematic in some particular cases where some structures, for instance a tumor or a sulcus, exists in the subject and not in the atlas. In order to solve this limitation of the atlases, a new atlas-based segmentation method for pathological brains is proposed in this thesis as well as a validation method to assess this new approach. Results show that deep structures of the brain can still be efficiently segmented using an anatomic atlas even if they are largely deformed because of a lesion. The importance of including a priori knowledge is also presented in the application of brain tissue classification. The prior information represented by the tissue templates can be included in a brain tissue segmentation approach thanks to the registration techniques. This is another important issue presented in this thesis and it is analyzed through a comparative study of several non-supervised classification techniques. These methods are selected to represent the whole range of prior information that can be used in the classification process: the image intensity, the local spatial model, and the anatomical priors. Results show that the registration between the subject and the tissue templates allows the use of prior information but the accuracy of both the prior information and the registration highly influence the performance of the classification techniques. Another aim of this thesis is to present the concept of dynamic medical image analysis, in which the prior knowledge and the registration techniques are also of main importance. Actually, many medical image applications have the objective of statically analyzing one single image, as for instance in the case of atlas-based segmentation or brain tissue classification. But in other cases the implicit idea of changes detection is present. Intuitively, since the human body is changing continuously, we would like to do the image analysis from a dynamic point of view by detecting these changes, and by comparing them afterwards with templates to know if they are normal. The need of such approaches is even more evident in the case of many brain pathologies such as tumors, multiple sclerosis or degenerative diseases. In these cases, the key point is not only to detect but also to quantify and even characterize the evolving pathology. The evaluation of lesion variations over time can be very useful, for instance in the pharmaceutical research and clinical follow up. Of course, a sequence of images is needed in order to do such an analysis. Two approaches dealing with the idea of change detection are proposed as the last (but not least) issue presented in this work. The first one consists of performing a static analysis of each image forming the data set and, then, of comparing them. The second one consists of analyzing the non-rigid transformation between the sequence images instead of the images itself. Finally, both static and dynamic approaches are illustrated with a potential application: the cortical degeneration study is done using brain tissue segmentation, and the study of multiple sclerosis lesion evolution is performed by non-rigid deformation analysis. In conclusion, the importance of including a priori information encoded in the brain atlases in medical image analysis has been put in evidence with a wide range of possible applications. In the same way, the key role of registration techniques is shown not only as an efficient way to combine all the medical image modalities but also as a main element in the dynamic medical image analysis. Resumen Hoy en día existen muchas modalidades de imágenes médicas digitales que permiten a los médicos el estudio in vivo de los órganos del cuerpo humano, como por ejemplo del cerebro. Estas imágenes son muy útiles en muchos campos de la medicina como por ejemplo en la detección, seguimiento y estudio de patologías, en la preparación y realización de operaciones quirúrgicas asistidas por ordenador o en estudios estadísticos. De entre todos los tipos de imágenes medicas, destaca la imagen de Resonancia Magnética (RM) por su alta resolución espacial, su gran variedad de posibles contrastes y su inocuidad al no utilizar radiación ionizante. Estas características hacen que la imagen por RM sea muy adecuada para la visualización anatómica del cuerpo humano, por ejemplo para visualizar las estructuras y los tejidos del cerebro. El análisis de imágenes médicas es una tarea compleja ya que normalmente estas imágenes consituyen grandes volúmenes de datos y, además, presentan ruido y otros artefactos de la imagen como los cambios de iluminación. Sin embargo, la inclusión de información a priori en el análisis de estas imágenes puede facilitar mucho su estudio. La información a priori está normalmente representada por las imágenes de referencia o atlas que determinan un espacio concreto en el cual se describe la anatomía, por ejemplo, del cerebro humano. Actualmente los atlas del cerebro (creados a partir de secciones criogénicas o de imágenes in vivo, basados en un solo sujeto o en toda una población) proporcionan imágenes digitales muy detalladas que pueden ser examinadas interactiva y fácilmente en el diagnostico de tratamientos y planificación de los mismos por ordenador. En consecuencia, para poder combinar de manera eficiente toda la información contenida en los distintos tipos de imágenes médicas surgen las técnicas de registro* que proporcionan las transformaciones geométricas que sitúan dos imágenes en correspondencia anatómica voxel a voxel. Uno de los objetivos principales de esta tesis es remarcar la importancia de incluir información a priori en el proceso de análisis de imágenes médicas así como resaltar el papel indispensable de los métodos de registro en este proceso. Para demostrarlo, presentamos distintas aplicaciones que utilizan atlas. Primero, presentamos la aplicación de segmentación basada en atlas en sujetos con anatomía normal ya que es una de las aplicaciones principales que incluyen información a priori. La segmentación basada en atlas consiste en registrar una o varias imágenes del cerebro en el sistema de referencia del atlas para facilitar la localización y segmentación de las estructuras de interés. Sin embargo, el uso del atlas está limitado en algunos casos donde puede haber estructuras, como un tumor o un sulcus, que estén presentes en el paciente pero no en el atlas. Para solventar este problema, se propone un nuevo método de segmentación basado en atlas para cerebros patológicos así como un método para su validación. Los resultados obtenidos demuestran que las estructuras de interés del cerebro se pueden segmentar utilizando la información contenida en un atlas aunque estén muy deformadas debido a una lesión. La importancia de la utilización de la información a priori se demuestra también en la clasificación de los distintos tejidos del cerebro. La información a priori contenida en los atlas de tejidos del cerebro puede ser utilizada por los métodos de clasificación gracias al registro de imágenes. ésta es también una aplicación importante y se presenta a través del estudio comparativo de varias técnicas de clasificación no supervisadas. Los métodos de clasificación analizados han sido elegidos de manera que representen la diversidad de información a priori que se puede utilizar, es decir, la intensidad de la imagen, la información local espacial y la información global contenida en los atlas. Los resultados obtenidos demuestran que el uso de atlas es posible gracias a las técnicas de registro pero que la calidad de la clasificación depende mucho de la precisión del método de registro y de la calidad de la información a priori utilizados. El tercer objetivo de esta tesis es presentar el concepto de análisis dinámico de las imágenes médicas, en el cual, la información a priori y los métodos de registro siguen siendo de mucha importancia. En realidad, muchas aplicaciones de las imágenes medicas tienen como objetivo el análisis estático de una imagen como, por ejemplo, en el caso de la segmentación basada en atlas o en la clasificación de tejidos del cerebro. Pero en otros casos la idea de detección de cambios es implícita. Intuitivamente, ya que en el cuerpo se producen cambios continuamente, podríamos analizar las imágenes medicas desde un punto de vista dinámico, es decir, detectando los cambios que se producen y comparándolos con modelos de cambios para determinar si son normales. La necesidad de detección de cambios es aún más evidente en el estudio de ciertas patologías del cerebro como por ejemplo tumores, esclerosis múltiple o enfermedades degenerativas. En estos casos, la clave está no sólo en detectar sino también en cuantificar e incluso caracterizar la evolución de la lesión. Este tipo de estudios pueden ser muy útiles por ejemplo en la investigación farmacéutica o en el seguimiento clínico. Evidentemente, para realizar este tipo de estudios evolutivos se considera que se dispone de una secuencia de imágenes a distintos intervalos de tiempo. Dos métodos distintos que lidian con la idea de detección de cambios son presentados en esta tesis. El primero consiste en realizar el análisis estático de cada una de las imágenes que forman la secuencia y luego comparar los resultados. El segundo método consiste en realizar el análisis de la transformación obtenida entre las imágenes de la secuencia, en vez de realizar el análisis de cada imagen. Finalmente, presentamos una aplicación potencial de cada uno de los métodos como ejemplo: el estudio de la degeneración cortical del cerebro que esta hecho a partir de la clasificación de tejidos y el estudio de la evolución de esclerosis múltiple que esta hecha a partir del análisis de la transformación obtenida por registro. En conclusión, se ha puesto en evidencia la importancia de considerar la información a priori de los atlas anatómicos del cerebro en el análisis de imágenes médicas en una gran variedad de aplicaciones. De la misma manera, el papel decisivo de los métodos de registro ha sido presentado no sólo como una manera eficiente de combinar las distintas modalidades de imágenes médicas sino también como un elemento importante en el análisis dinámico de las mismas. [...] * Anglicismo de registration. Dans le domaine de l'imagerie médicale il existe une grande variété de modalités d'images 3 D qui permettent aux médecins d'obtenir une visualisation non invasive des organes du corps humain, comme par exemple du cerveau. Toutes ces modalités d'images sont très importantes dans divers domaines de la médicine comme par exemple pour détecter certaines pathologies, pour suivre l'évolution des ces pathologies, pour préparer et pour réaliser des opérations chirurgicales avec ou sans l'aide de systèmes robotiques ou même pour des études statistiques. Parmi toutes les modalités d'images médicales, l'Imagerie par Résonance Magnétique (IRM) est devenue très importante grâce à sa grande résolution spatiale et son fort contraste pour les tissues mous. L'IRM est donc très bien adaptée pour la visualisation anatomique du corps humain, par exemple des structures profondes ou des tissus du cerveau. L'analyse des images médicales est très complexe car ces images sont représentées par de grandes quantités de données et elles présentent parfois des effets non désirables comme le bruit. Cependant l'utilisation d'information a priori pendant le traitement d'images peut faciliter beaucoup leur analyse. <b>Normalement,</b> cette information a priori est représentée par les images dites de référence ou atlas, qui déterminent un espace commun ou l'anatomie humaine peut être précisément représent ée comme c'est le cas du cerveau. Aujourd'hui les atlas sont dérivés des images cryosectionées de grande résolution ou des images in vivo et ils sont basés sur un seul individu ou sur une population d'individus. Dans tous les cas, elles fournissent des images très détaillées qui peuvent être facilement analysées dans leur format digital pour des applications comme la vision et l'aide au diagnostic par ordinateur. Finalement, il existe une grande variété des techniques de recalage basées sur des transformations qui donnent une correspondance voxel-a-voxel des images et qui permettent de combiner très efficacement toutes les informations contenues dans les images médicales. Un des principaux objectifs de cette thèse c'est de souligner l'importance d'inclure dans l'analyse des images médicales l'information connue a priori et le rôle indispensable des techniques de recalage. Différentes applications qui utilisent l'information contenue dans des atlas sont présentées. Tout d'abord, la segmentation basée sur un atlas est présentée car c'est une application de pointe dans l'utilisation d'information a priori. Il s'agit de recaler des images du cerveau dérivées des différents individus ou modalités d'image avec un atlas qui permettra d'améliorer la localisation et segmentation des structures d'intérêt. Cependant, l'utilisation d'atlas et parfois limitée dans certains cas ou quelques structures, par exemple un sulcus ou une tumeur, sont présents dans le patient mais ne sont pas présents dans l'atlas. On propose dans ce travail une nouvelle méthode de segmentation basée sur un atlas dans les cas de cerveaux pathologiques ainsi qu'une méthode pour sa validation. Les résultats montrent que les structures profondes du cerveau peuvent encore être segmentées efficacement à l'aide d'un atlas même si elles ont été largement déformées par une lésion. La pertinence d'inclure l'information a priori est aussi présentée dans le cadre de la segmentation des tissus principaux du cerveau. L'information con...|$|E
40|$|Crossing Places of Exile: Sewing the Fragments Back Together Martine Hovanessian Presentation {{text for}} Accreditation to Supervise Research 29 Avril 2009 This dissertation, as I explain in the Introduction, {{was written in}} the desire to {{contribute}} to the opening out of an inner landscape, a landscape tormented in many ways, and which cannot be imagined if one is attempting to produce a straightforward monographic study. What is it about? An adventure similar to "an anthropology of nooks and crannies", in which I propose to discern the key structural issues of a fragment in the order of the discontinuous identities that came into being through a denial whose structural support is related to the Armenian genocide perpetrated in 1915, but which I enlarge upon in a comparison with the Shoah. The lamentation over Deir ez Zor, as well as the testimonies collected during a period of many years, gave direction to my project: to develop the features of an extreme exile in which the themes of separation and enforced migration are insufficient notions to convey the condition of the 'throwaway person' elaborated by Fethi Benslama, a 'throwaway'person who {{in the case of a}} collective destruction, of a still not officially recognised State violence, continues to 'act', in an almost 'clandestine' manner, at one and the same time in the development of a generational continuum (transmission) starting from a radical break and suspended over a gaping hole, but also in a victorious apprehension of a principle of restoration of the ideal of generation, and chiefly carried by the recognised social structures of memory. Without counting, except to explore those experiences of a collapse that haunts the imagination, often with no possibility of translation, I passed through other places than those of oral expression, places of territorialisation aiming to represent the places of 'the community' around a will to re-establish an 'idea of the territory', an organising principle, a material culture, an adding up of symbols, places of a tormented national imagination in Armenia where irredentist, ethnicised struggles take their form from a failed national question still waiting for a resolution, places criss-crossed with the writings of exile, where the choice of language implies more than supposed, half-hearted claims (or-not) of integration, it also speaks of 'onboard' experiences, of reconnection to a symbolic body. I insist on the connections, which justifies my use of the idea of the 'fragment'as a 'spare part' that is the consequence of the breaking down of ancient references 'into little bits' [...] to use Michel de Certeau's expression [...] relics of a lost social entity, detached from the whole of which they had been a part, planted in another social 'body', in the manner of the 'little shards of truth' that Freud claimed to have discovered in the 'displacements' of a tradition, and which no longer have a language to symbolise or reunite them. " Sewing the Fragments Back Together" is a specific invitation to give an account of, and to expose, these identity-seeking quests for a language in which débris, 'leftovers', are deposited in people's memories, but which instead of bearing witness to a displacement of tradition with the possible accommodations that could be expected in a land of exile, and which have the connotation of inventions of continuity, reveal on the contrary [...] against a background of tragedy [...] a language that has been destroyed. The experience of post-catastrophic exile, as shown in post-catastrophic Armenian literature [...] writings about survival and restoration, my commentaries on Nicolas Sarafian's text translated from the Armenian, Le Bois de Vincennes [...] invites us to work on the question of 'un-belonging', a concept in need of a theory, and which I understand not in the simplistic perspective of 'the loss of a culture', an expression that stirs no resonance in me, but in the sense of a loss of the relationship with the 'other', a splitting off, a state of being enclosed, an incapacity to conceive of 'otherness', to project oneself into a future, given a condition of exile following on a process of de-symbolisation. For me, genocide and its denial involve a whole, ongoing work around the disappearance of the disappearance, the eradication of traces, the rubbing out of the Names of the Father, the erasure of meaning, the dis-affiliation, the feeling of ruin, subjectivity charged with meaning coming up against objective criteria of the deterioration of a patrimony [...] a patrimony that is nonetheless celebrated as the carrier of recognition of the violence that had taken place [...] criteria that resort to political language to express the scale of the destruction: a language with religious accents, "with stone boots," as the poet Mandelstam says, submerged villages, represented as places of purity, and as moral destinations, ancient monuments split open, monuments to the martyrs of 1915, a decapitated political patrimony that was founded on the emancipation of the nation and, for certain political parties, on Marxist foundations, a ruling elite and intellectuals systematically eliminated in Constantinople on April 24, 1915. It would seem that the mood of this celebration of the patrimony takes on the role of representation that is inscribed in the very limitations of a powerless political language, set at a disadvantage, incapable of developing a period of mourning, a mourning that indeed became a mourning of long duration. So many features of a silent and murderous de-territorialisation inhabiting the imagination, to which are added a migratory memory of dispossession, the escapee-refugees parked in camps, the world of the orphans of the 1920 s, statelessness, migratory wandering, the submission of this population stripped of its nationality to recruiters of immigrant labourers for heavy industry in France going to orphanages to distribute work contracts. I had treated this migratory memory of dispossession in Le Lien Communautaire, in which I explained that the very nature of the rupture with national origins had given rise to singular social behaviours, notably in efforts at re-founding a 'collective self' on a small scale, based on identifications tied to a place, carried by social practices of enrolment records, where the illusion of a 'new beginning', or continuity, the establishment of inner and outer boundaries, will be treated later through my interrogations about the notion of diaspora [spiurk], which I designate as a space of living fiction, sketched against the backdrop of an awareness of the dispersion in the exile, considering again the question of a violence of exclusion that had most definitely occurred. From this point of view, the work of Alain Medam on Jewishness in exile was very helpful, and we participated with several researchers on the uses and semantic field of the notion of diaspora since the 1990 s, in a comparative perspective. We believe that exile in its eschatological dimension and the concept of diaspora are two mutually clarifying notions, inasmuch as both revert to a collapse, to expulsions, to collective exclusions, to repeated persecutions in which notions of group, of minority, of community, ethnic or religious, or of an ethnic-religious 'community' of a diaspora, tend to converge towards the notion of a people, a more universal representation of a political conscience, an abstract ideal serving to update certain questions, national causes that have been struck off the map, unresolved, unfinished, 'poorly buried', victims of imperialist powers. This is the reason why we continue our search for conceptual instruments that will enable us to develop an anthropology of modern violence that overlaps simultaneously with an anthropology of the nation and an anthropology of exile. The stakes seem to lie less in the workability of forms of alliance than in the preservation of the symbolic effectiveness of a link in which it is possible to bring up to date, under diverse and varied forms of the languages and accounts of the rupture, the myths of return, the relationship between capacities of organisation and collective representations undergirded by the will to open up a territory of the singular and of the multiple, combining the traditional modes of the sedentary and those on the move, circumventing the principles of the political institutionalisation of borders, while at the same time creating ties with a 'political centre'. Belonging to a diaspora also reflects a culture that has become marginal, a culture of prudence and negotiation between distance and nearness, by virtue of weaving one's way through the games of power, and of having endured oppression and persecutions, by virtue of an apprenticeship in being 'without rights'. The experience of a new configuration born of 'misfortune' draws its strength at the same time from a mode of dispersion of the most prestigious elites (the merchant colonies of the 17 th century, the intellectual elites of the 19 th century), making it possible to confer a positive value, a historicity, to the present experience of dispersion. The diaspora is also a place of authorized nomadism, a synonym not of a wandering equated with a loss of meaning and of points of reference, but of a wandering linked to the space-time of a collective history, simultaneously defining a place of freedom, an escape route, the ideal place where one can best live as foreigners, by being given the right to combine identities. Thus for Chantal Bordes-Benayoun, the question of the relation to the Other is at the heart of the diasporas: "The diaspora requires an effort of sublimation of 'otherness' through a collection of answers that reconcile multiple demands of loyalty'. This particular work of mine does not belong in the category of 'the duty of memory' so often instilled through a doubtful political discourse that produces dependence on a stereotypical, standardised form of writing (including writings stuck on the phenomenon of diasporas), but rather in the category of nuances, of hesitant steps, doubts reinstated by certain poetic or literary texts exhorting us to evoke a condition of survival linking a particular report to space-time, vacillating in the present, and whose written output perpetuates the very condition in question. We stress the idea of a 'repertory of practices' that form the body of the 'assets' of belonging, that is, a structure of action. At the same time, this repertory delineates an economy of language that avoids the tone of institutional doctrines, unconventional, subversive forms that resist all efforts at ideological or normative translation. The study of writings on violence is distributed over a broad spectrum; the texts are often characterised by their subordinate status in comparison to writings based on academic learning: reactive texts developed by organic intellectuals, between scholarly and political texts, oral testimonies, personal diaries, literary essays, family memoirs, psychoanalytical studies, aesthetic creations, poetic writings, epistolary exchanges, texts translated from one language to another. The writings of Charlotte Delbo, of Georges Pérec, through selected extracts, are not motivated by a cathartic literary intention, but by an impossibility, the impossibility of adhering to "this institution of bearing witness", and summon up voices, prolonging the existence of the "body" of the people, plunge into the ever-present indescribable and un-representable, approach the edges of the void and of the strangeness contained in a vaporisation of the subject that can no longer connect to the "other", where nothing now "holds the subject" anymore, and connecting at many points with my own journey as a subject placed at the crossroads of catastrophes that have occurred, unable to localise the place of a vague and intrusive anxiety. A place of extreme exile, a place where one is "beside oneself", a place of the crushing of the possibility of symbolising life and death. Distraction, loss of boundaries, wanderings in exile where points of departure and points of arrival cancel each other out. "Sewing the Fragments Back Together" is a project of reconfiguration of what cannot be expressed, and this has necessitated other methodological supports than the translation of denial by certain historians of the Armenian genocide whose colossal work around the search for proof and the historic meaning through archives has contributed to bringing to light a mechanism of negation, a historiographic perversion that makes use of the processes of rationalisation, of relativising and of trivialising, to refute the factor of intentionality at the heart of the genocidal principle, and produce, according to Richard Hovanissian, a hodgepodge of half-truths, of infinite circumlocutions that are infinitely more devastating than total negation. As an anthropologist, and returning by choice to my early literary training, making use of the particular sensibility that is developed after a long experience of psychoanalysis as an analyst, I have favoured the nomadic and perceptible ('felt') forms of exile, without in any way wishing to prove something, and I threw myself into the work of subjectivation, that of the process that calls for the maturation of the subject. I think it is necessary to free oneself from the injunction to 'prove' something, the order of the torturer, some would say, in the search for ultimate proof, a sort of tyranny set in motion by the actors of political power, the language of domination in which the status of the victim is transformed into a teary plaint, de-politicised to "make room" for polysemous subjectivisms, narrations, evocations. To leave the discourse of historic proof of the annihilation and of self-justification, and allow myself to move to a form of writing in which denial has struck me in my own autobiographical trajectory, my family novel, my researcher's journey, and whose seams I am attempting to sew. "Letting oneself go" means catching a glimpse of the freedom of the subject, allowing the subject to catch up with himself as he takes off his chains and frees himself from alienation in and through this crossing over. Leaving the context of proof as an element in a process of establishing a scientific reality that would provide support for a procedure of authentification and an imperative of veracity. Allowing oneself to be carried by the threads of the disconnection (narrative anthropology, poetic metaphor). In this way, the terrain in this case concerns not only the presence in a geographical place or in a social unit for the present-day analysis of social relations, but involves a much more complex configuration. The terrain is also the breadth of the links and associations with other temporalities that the signifieds collected in an empirical space will help to achieve with other temporalities, calling for other supports, other crossing places, in order to form a mixed semiotic. Gérard Althabe, who was my thesis supervisor (1993), in his theory of the position of the researcher 'on the ground', already favored a heuristic approach, which advances by trial and error and in stages, inviting us to carry out the 'to-ing and fro-ing' and the links between levels which add up cumulatively or are superimposed in the interpretation of an act or an event, at several levels of resonances, on several scales. Not a blending, but a mixed semiotic in which exile as a total social reality calls for a superimposition of planes, of levels of interpretation, giving rise to the use of multiple supports, as we have said, in order to create a text, a body of literature, a web peopled with voices and phantoms, from which would surge dissociations, cleavages, dismantlings, splinters, cries and quests, as well as heroic struggles, and which at the same time would offer a way [...] perhaps an aesthetic and utopian way [...] of seeing foreclosure as a reality in the past. Obviously the issue of the relationship of the researcher to his object is raised in the haunting question of distance and nearness, of "too much attachment" to the object, which could distort the way of seeing, or else contribute to an "ethnicisation", a reification, that would confuse the understanding of one's purpose. This would be to misunderstand the direction of my approach: not to formulate truths of the order of the propaganda discourse of a group, but to address a philosophical question: "How and why write about 'a devastation' " of a collective magnitude that has affected far more than the subjectivity of the researcher, obliging him/her to carry out the restoration of something unimagineable. There must be great constraint in this exercise, in my case not the constraint of the literature associated with the pleasure of the un-linking, but that of an existential pressure to glue the fragments back together, to sew them together, to fill in, not to repair or bring about recognition, but to reconnect with a dimension of the "normally alive". And at this point, psychoanalysis introduces a considerable theoretical contribution that works on dissociations, impossible means of access to the ordinary extended memory, in the sense of a diversionary release mechanism. I think of the work of the psychoanalyst Anne Lise Stern, a student of Lacan's, in her book Le Savoir Déporté after Auschwitz, in which the writing constructs the conditions of her release. On the contrary, I wish to say, that sort of proximity with the object, instead of being a place of enclosure, opens up the horizon, a sort of "unconscious of the text", distinct from that of both author and reader which, as Julia Kristeva, psychoanalyst and semiotician, specifies, opens towards "scenes of representations, of modalities, of psychic inscriptions, traces, marks, distinctiveness", breaches as well, which in my view are opposed to the smooth writing of the dissertation that slides over the signifier. What can we say of this 'engaged' [...] committed [...] writing that has been emphasised, and of my position as a 'committed' researcher? If we speak of 'engaged' literature in work about subjectivisms that reconsider the weight of a historiographical perversion, questioning again a dynamic of impunity, asking again the why of the genocide "without reason", then at this point I affirm that my writing is 'committed'. But if instead of that, one 'ethnicises'a cause, I would agree that it is a question of a return of perversion, in which 'commitment' becomes militancy, in the sense that the researcher becomes the mouthpiece of a community. Ethnocentrism in researchers has often been denounced, whether they be historians or others, who attempt to show the mechanism of perversion at work in the Armenian genocide of 1915 and its denial. Just as the leaders of the CUP (Ittihad or Committee of Union and Progress) used the shameful nationalist argumentation with respect to the Armenians and in the context of the First World War to justify the mass massacres that international law has difficulty qualifying as genocide, as is shown by the elimination of Paragraph 30 in 1979 in the report on the question of the prevention and suppression of the crime of genocide in the sub-commission on Human Rights at the U. N., when this same commission, in 1974, had recognized the genocide of the Armenians as the first genocide of the Twentieth Century. The stakes in the definition remain highly topical, and certain politicians prefer to evoke the expression 'incomparable atrocities' rather than use the term 'genocide'. I hope that this work in a meandering style that I claim as my own, conscious of complexity and the spiral, will contribute to restoring, under my pen, the substance of an unspeakable reconfiguring, in which denial has produced this type of knowledge, a body of writing, a notion that I and Maryse Tripier, as she accompanied me in this arduous labour, have attempted to theorise. Martine Hovanessian Résumé HDR " Traversée de lieux exilés : recoudre les fragments " 29 avril 2009 Ce mémoire souhaiterait contribuer au déploiement d'un paysage d'une intériorité tourmentée sous bien des aspects et que l'on ne peut imaginer si l'on s'applique au strict exercice monographique. Il s'agit d'une aventure apparentée à " une anthropologie des coins et des recoins " où je me propose de cerner l'enjeu structurel du fragment dans l'ordre des identités discontinues nées d'un déni, dont le support concerne le génocide des Arméniens perpétré en 1915 mais que j'élargis dans la comparaison avec la Shoah. La question philosophique et anthropologique " comment et pourquoi " écrire sur la destruction répondent à une immense contrainte, celle de la dette mais à travers cette réparation se dessine la réinvention d'un ordre du " <b>normalement</b> vivant ". Les témoignages capturés sur de longues années condensent le sens de mon projet : élaborer des figures d'un exil extrême où le thème de la migration contrainte est une notion insuffisante pour traduire une condition " de l'homme jetable " élaboré par Fethi Benslama et qui dans le cas d'une destruction collective, d'une violence d'Etat toujours non reconnue continue à " agir clandestinement " (Altounian) dans l'élaboration d'une position générationnelle (la transmission) à partir d'une scission radicale, sur un trou béant. Les expériences d'un effondrement qui hantent les imaginaires, souvent en manque de traduction possible, ont nécessité de traverser d'autres lieux que ceux de l'énonciation orale. Nous avons observé des lieux de la territorialisation représentant des lieux de " la communauté " autour d'une volonté de rétablir " une pensée du territoire ", un principe organisationnel, une culture matérielle, une addition de symboles, puis analysé un imaginaire nati...|$|E

