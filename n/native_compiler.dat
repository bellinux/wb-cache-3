42|113|Public
2500|$|... mtouch – the <b>Native</b> <b>compiler</b> and tool used {{to deploy}} {{to the target}} device ...|$|E
5000|$|The {{proprietary}} <b>native</b> <b>Compiler</b> for machine A (1) (e.g. compiler from Microsoft Visual Studio) is used {{to build}} the gcc <b>native</b> <b>compiler</b> for machine A (2).|$|E
5000|$|... mtouch - the <b>Native</b> <b>compiler</b> and tool used {{to deploy}} {{to the target}} device ...|$|E
5000|$|Martin Guy's gcc-crunch {{patches and}} <b>native</b> <b>compilers,</b> a {{development}} of the futaris patches, which generate reliable code and pass all testsuites.|$|R
25|$|Java's {{performance}} has improved substantially {{since the early}} versions. Performance of JIT <b>compilers</b> relative to <b>native</b> <b>compilers</b> has in some optimized tests {{been shown to be}} quite similar.|$|R
5000|$|By {{the early}} 1990s, DDC-I offered Ada <b>native</b> <b>compilers</b> for VAX/VMS, Sun-3 and SPARC under SunOS, and Intel 80386 under UNIX System V and OS/2, and offered cross compilers for the Motorola 680x0 and Intel i860 in {{addition}} to the abovementioned targets.|$|R
50|$|Steel Bank Common Lisp (SBCL) {{is a free}} Common Lisp {{implementation}} {{that features}} ahigh performance <b>native</b> <b>compiler,</b> Unicode support and threading.|$|E
5000|$|The gcc <b>native</b> <b>{{compiler}}</b> for machine A (2) is used {{to build}} the gcc cross compiler from machine A to machine B (3) ...|$|E
50|$|IDE {{features}} include: Workspace Manager, project builder (interactive and batch),resource editor, project converter, class viewer, <b>native</b> <b>compiler</b> support, debugger with integrated debugging (via WinDBG).|$|E
5000|$|The first {{generation}} TeleSoft compiler was very slow, but compilation speeds improved considerably with the TeleGen2 product. TeleSoft sold both <b>native</b> <b>compilers</b> and cross compilers for various embedded systems architectures.The customer {{base for the}} compiler grew to include many large corporations, including IBM, Sun Microsystems, Intel, Cray Research, Motorola, and Unisys.|$|R
5000|$|... an {{interpreter}} and a <b>native</b> code <b>compiler</b> for Lisp Machine Lisp ...|$|R
5000|$|Run-time {{compiling}} {{can potentially}} use {{information about the}} platform on which the code is being executed to improve code more effectively. However, most state-of-the-art native (C, C++, etc.) compilers generate multiple code paths to employ the full computational abilities of the given system. Also, the inverse argument {{can be made that}} <b>native</b> <b>compilers</b> can better exploit architecture-specific optimizing and instruction sets than multi-platform JVM distributions.|$|R
50|$|AOT {{produces}} machine optimized code, {{just like}} a standard <b>native</b> <b>compiler.</b> The difference is that AOT transforms the bytecode of an extant virtual machine (VM) into machine code.|$|E
50|$|It {{translates}} C and Fortran {{programs with}} OpenMP pragmas into C code suitable for compiling with a <b>native</b> <b>compiler</b> linked withthe Omni OpenMP runtime library. It does for loop parallelization.|$|E
5000|$|SML# is an {{extension}} of SML providing record polymorphism and C language interoperability. It is a conventional <b>native</b> <b>compiler</b> and its name is not an allusion to running on the [...]NET framework.|$|E
5000|$|Safety {{guarantees}} {{come at a}} run-time cost. For example, the compiler {{is required}} to put appropriate range checks in the code. Guarding each array access with a range check is not efficient, so most JIT compilers will try to eliminate them statically or by moving them out of inner loops (although most <b>native</b> <b>compilers</b> for C++ {{will do the same}} when range-checks are optionally used).|$|R
5000|$|... ocamlcc is a {{compiler}} from OCaml to C, {{to complement}} the <b>native</b> code <b>compiler</b> for unsupported platforms.|$|R
40|$|The Amsterdam Compiler Kit is {{a widely}} used {{compiler}} building system. Up until now, the emphasis has been on producing good object code. In this paper we describe recent work that has focused on reducing compile time. The techniques described in this paper have resulted in C compilers for the Sun- 3 and VAX that are 3 to 4 {{times faster than the}} <b>native</b> <b>compilers</b> provided by the manufacturers. 1...|$|R
5000|$|Bootstrapping {{to a new}} platform. When {{developing}} {{software for}} a new platform, or the emulator of a future platform, one uses a cross compiler to compile necessary tools such as the operating system and a <b>native</b> <b>compiler.</b>|$|E
50|$|Currently, {{there are}} two open source {{alternative}} implementations of Turing: Open Turing, an open source version of the original interpreter, and TPlus, a <b>native</b> <b>compiler</b> for the concurrent systems programming language variant Turing Plus. OpenT, a project to develop a compiler for Turing, {{is no longer in}} development.|$|E
50|$|For the CM-2 models the C* {{compiler}} {{translated the}} code into serial C, calling PARIS (Parallel Instruction Set) functions, {{and passed the}} resulting code to the front end computer's <b>native</b> <b>compiler.</b> The resulting executables were executed {{on the front end}} computer with PARIS calls being executed on the Connection Machine.|$|E
50|$|It {{features}} a rich run time library, a powerful source-level debugger, a <b>native</b> code <b>compiler</b> and a built-in Emacs-like editor called Edwin.|$|R
5000|$|The company {{achieved}} {{its first}} official validated Ada compiler in January 1985. [...] Verdix became {{known for the}} large number of Ada compilers it offered on many different systems, selling both <b>native</b> <b>compilers</b> and cross-compilers for embedded systems architectures. By 1992 Verdix had 105 different Ada compilers on the Ada Joint Program Office validated compilers list, easily the most of any Ada vendor (next highest was Alsys with 60). [...] Its revenues were around $13 million.|$|R
40|$|This thesis {{describes}} {{the design and}} implementation of Jcc, an optimizing <b>native</b> Java <b>compiler.</b> The system translates Java source code directly to native executables. The system is almost self contained using its own parser generator (Jade) and frontend and backend. The thesis also {{describes the}} novel implementation of RMI and the facilities to dynamically load Java byte code into a running executable. The Java runtime system is currently built upon Panda[4], a portable platform to support parallel programming languages. The system runs on both Sparc/Solaris and x 86 processors running Linux 2. x. x or BSD/OS 3. 0 by BSDI. Keywords: Java, Bytecode, Offline <b>native</b> <b>compilers,</b> parser generators, <b>native</b> interface. 1 Contents 1 Introduction 4 1. 1 Java................................ 4 1. 2 Previous Work.......................... 5 2 Using Jade to create the parser 5 2. 1 Introduction to Jade................... [...] . ...|$|R
50|$|Xerox PARC later {{developed}} Cedar, {{which was}} a superset of Mesa, {{with a number of}} additions including garbage collection, better string support, called Ropes, and later a <b>native</b> <b>compiler</b> for Sun SPARC workstations. Most importantly, Cedar contained a type-safe subset and the compiler had a subset-checking mode to ensure deterministic execution and no memory leaks from conformant Cedar code.|$|E
50|$|At {{least two}} free Internet {{distributions}} exist for native Aztec C Compilers for the Apple II; one for Apple II DOS 3.3 {{and the other}} for Apple II ProDOS 8. A third free Internet distribution exists for Aztec C for the Commodore Amiga. A fourth free Internet distribution exists for their MS-DOS 8086 <b>native</b> <b>compiler,</b> and a fifth exists for a limited version of their MS-DOS cross-compiler for Apple II ProDOS 8.|$|E
50|$|Compilers {{were made}} for Kongsberg Våpenfabrikk's SM-4 and Norsk Data Nord-10/ND-100 mini-computers. The {{original}} Mary compiler was written in NU ALGOL, ran on the Univac-1100 series and was used to bootstrap a <b>native</b> <b>compiler</b> for ND-100/SINTRAN-III. RUNIT implemented a CHILL compiler written in Mary which ran on ND-100 and had Intel 8086 and 80286 targets. When this compiler was ported to the VAX platform, a common backend for Mary and CHILL was implemented. Later, backends for i386 and SPARC were available. Since the Mary compiler was implemented in Mary, {{it was possible to}} run the compiler on all these platforms.|$|E
5000|$|Mozilla's {{benchmark}} from December 2013 {{showed significant}} improvements: [...] "Firefox with float32 optimizations can run all those benchmarks at around 1.5× slower than native, or better." [...] Mozilla {{points out that}} the performance of natively compiled code is not a single measure but rather a range, with different <b>native</b> <b>compilers</b> (in this case Clang and GCC) delivering code of differing performance. [...] "In fact, on some benchmarks, like Box2D, FASTA and copy, asm.js is as close or closer to Clang than Clang is to GCC. In one case, asm.js even beats Clang by a slight amount on Box2D." ...|$|R
50|$|The <b>native</b> code <b>compiler</b> is {{available}} for many platforms, including Unix, Microsoft Windows, and Apple macOS. Portability is achieved through native code generation support for major architectures: IA-32, X86-64 (AMD64), Power, SPARC, ARM, and ARM64.|$|R
5000|$|C++Builder is {{equivalent}} to Delphi, but based on the C++ programming language instead of Pascal, using the Delphi Visual Component Library and a <b>native</b> C++ <b>compiler.</b> Most components developed in Delphi {{can be used in}} C++Builder with no modification, although the reverse is not true.|$|R
50|$|The {{original}} Visual Objects project (code-named Aspen) {{was started}} {{as part of}} Nantucket's attempts to bring the Clipper language to Windows, and move from the procedural to the object-oriented style. It also converted Clipper from a p-code system to being a true <b>native</b> <b>compiler</b> and introduced more elements of the C language (such as typed variables), while including Windows extensions (such as COM, ODBC, and later ADO). With its symbol datatype, it offers the ability to form name-based linkages, which {{may be used to}} connect menu events to object methods or form direct linkages between server columns and controls.|$|E
50|$|TinyOS {{is fully}} non-blocking: {{it has one}} call stack. Thus, all input/output (I/O) {{operations}} that last longer than a few hundred microseconds are asynchronous and have a callback. To enable the <b>native</b> <b>compiler</b> to better optimize across call boundaries, TinyOS uses nesC's features to link these callbacks, called events, statically. While being non-blocking enables TinyOS to maintain high concurrency with one stack, it forces programmers to write complex logic by stitching together many small event handlers. To support larger computations, TinyOS provides tasks, which are similar to a Deferred Procedure Call and interrupt handler bottom halves. A TinyOS component can post a task, which the OS will schedule to run later. Tasks are non-preemptive and run in first in, first out order. This simple concurrency model is typically sufficient for I/O centric applications, but its difficulty with CPU-heavy applications has led to developing a thread library for the OS, named TOSThreads.|$|E
40|$|We {{present a}} new scheme for {{performing}} binary translation that produces code comparable to {{or better than}} existing binary translators with much less engineering effort. Instead of hand-coding the translation from one instruction set to another, our approach automatically learns translation rules using superoptimization techniques. We have implemented a PowerPC-x 86 binary translator and report results on small and large computeintensive benchmarks. When compared to the <b>native</b> <b>compiler,</b> our translated code achieves median performance of 67 % on large benchmarks and in some small stress tests actually outperforms the <b>native</b> <b>compiler.</b> We also report comparisons with the open source binary translator Qemu and a commercial tool, Apple’s Rosetta. We consistently outperform the former and are comparable to or faster than the latter on all but one benchmark. ...|$|E
5000|$|The first {{business}} sold both <b>native</b> <b>compilers</b> {{and cross}} compilers, {{with the latter}} more common since Ada was primarily used in the embedded systems realm. One of the first cross compilers that DDC-I developed was from VAX/VMS to the Intel 8086 and Intel 80286; the effort was already underway by early 1985. [...] It began as {{a joint venture with}} the Italian defense electronics company Selenia that would target both their MARA-860 and MARA-286 multi-microprocessor computers, based on the 8086 and 80286 architectures, and generic embedded and OS-hosting 8086 and 80286 systems. [...] This work was the start of what would become the largest-selling product line for the firm. JwC3PWU. DDC-I developed a reputation for quality Ada cross compilers and runtime systems for Intel 80x86 processors.|$|R
40|$|Dynamic {{languages}} enable rapid prototyping, while statically typed languages offer early error-detection {{and efficient}} execution. As a result, the usual practice in software development {{is to build}} a prototype in a dynamic language and then rewrite the application in C or Fortran for high performance. Our thesis is that this costly rewriting step can be avoided if we have good <b>native</b> code <b>compilers</b> for dynamic languages. To overcome the difficulties in building good <b>native</b> code <b>compilers</b> from scratch, we propose that dynamic languages can be compiled into high-performance native code executables by translating to typed functional languages and reusing existing functional language compilers. We demonstrate this approach by compiling a popular dynamic language, Python, by translating it to OCaml, a strongly typed functional language. On performing a compar tive evaluation against several available Python implementations on both Windows and Linux platforms, we obtain highly encouraging results. In this paper, we use Python as proof-of-concept to demonstrate that our approach delivers efficient <b>native</b> code <b>compilers</b> for dynamic languages. We describe how source dynamic language objects and constructs can be expressed in terms of target typed functional language data types. Finally, we present a comparative performance analysis against different Python implementations such as CPython, IronPython, PyPy and Jython to illustrate the effectiveness of our approach...|$|R
50|$|Support for {{the latest}} ANSI/ISO C++ {{language}} specifications, including a host of compiler enhancements including Dynamic Compilation and Adaptive Compiler Technology (ACT), which radically speed compiler build processes; full ANSI/ISO template implementation; full ANSI/ISO STL (standard template library) support; and a high-performance 32-bit ANSI C++ <b>native</b> code <b>compiler.</b>|$|R
