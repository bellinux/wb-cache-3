2|34|Public
40|$|It has {{previously}} been demonstrated that for smooth dynamic systems, using relatively few sample points from a single trajectory, a neural network can be trained to perform very accurate short-term prediction over {{a large part of}} the phase space. In this paper, we exploit the capability of a Locally Predictive Network (LPN) to derive an adaptive control architecture for a satellite equipped with controllable, bidirectional thrusters on each of the three principal axes. It is assumed that a hardware implementation of the neural network is available. The inputs for the network are a small history of system states up to the present time and a set of current control inputs, the outputs are the next system state. Once the LPN has been trained successfully, at each time step a genetic algorithm searches the space of hypothetical control inputs. Given a set of control signals, the LPN is used to predict the state of the system at the next sample point. This enables the ‘fitness’ of each set of hypothetical control torques to be evaluated very rapidly. In effect, the genetic algorithm determines a satisfactory solution to the inverse kinematic problem in time to apply the solution (set of control torques) at the next control point. With the exception of the <b>neuromodelling</b> (which is repeated only when the system dynamics change), the whole process is then repeated. The results presented indicate that such an architecture is easily able to master the attitude control problem for arbitrary slew angles, with arbitrary a priori unknowndynamics and noise in the sensor system...|$|E
40|$|This book {{provides}} a unified description of several adaptive neural and fuzzy networks and introduces the associative memory class of systems - which describe {{the similarities and}} differences existing between fuzzy and neural algorithms. Three networks are described in detail - the Albus CMAC, the B-spline network and a class of fuzzy systems - and then analysed, their desirable features (local learning, linearly dependent on the parameter set, fuzzy interpretation) are emphasised and the algorithms are all evaluated on a common time series problem and applied to a common ship control benchmark. Chapters: 1. An Introduction to Learning Modelling and Control 1. 1 Preliminaries 1. 2 Intelligent Control 1. 3 Learning Modelling and Control 1. 4 Artificial Neural Networks 1. 5 Fuzzy Control Systems 1. 6 Book Description 2. Neural Networks for Modelling and Control 2. 1 Introduction 2. 2 <b>Neuromodelling</b> and Control Architectures 2. 3 Neural Network Structure 2. 4 Training Algorithms 2. 5 Validation of a Neural Model 2. 6 Discussion 3. Associative Memory Networks 3. 1 Introduction 3. 2 A Common Description 3. 3 Five Associative Memory Networks 3. 4 Summary 4. Adaptive Linear Modelling 4. 1 Introduction 4. 2 Linear Models 4. 3 Performance of the Model 4. 4 Gradient Descent 4. 5 Multi-Layer Perceptrons and Back Propagation 4. 6 Network Stability 4. 7 Conclusion 5. Instantaneous Learning Algorithms 5. 1 Introduction 5. 2 Instantaneous Learning Rules 5. 3 Parameter Convergence 5. 4 The Effects of Instantaneous Estimates 5. 5 Learning Interference in Associative Memory Networks 5. 6 Higher Order Learning Rules 5. 7 Discussion 6. The CMAC Algorithm 6. 1 Introduction 6. 2 The Basic Algorithm 6. 3 Adaptation Strategies 6. 4 Higher Order Basis Functions 6. 5 Computational Requirements 6. 6 Nonlinear Time Series Modelling 6. 7 Modelling and Control Applications 6. 8 Conclusions 7. The Modelling Capabilities of the Binary CMAC 7. 1 Modelling and Generalisation in the Binary CMAC 7. 2 Measuring the Flexibility of the Binary CMAC 7. 3 Consistency Equations 7. 4 Orthogonal Functions 7. 5 Bounding the Modelling Error 7. 6 Investigating the CMAC's Coarse Coding Map 7. 7 Conclusion 8. Adaptive B-spline Networks 8. 1 Introduction 8. 2 Basic Algorithm 8. 3 B-spline Learning Rules 8. 4 B-spline Time Series Modelling 8. 5 Model Adaptation Rules 8. 6 ASMOD Time Series Modelling 8. 7 Discussion 9. B-spline Guidance Algorithms 9. 1 Introduction 9. 2 Autonomous Docking 9. 3 Constrained Trajectory Generation 9. 4 B-spline Interpolants 9. 5 Boundary and Kinematic Constraints 9. 6 Example: A Quadratic Velocity Interpolant 9. 7 Discussion 10. The Representation of Fuzzy Algorithms 10. 1 Introduction: How Fuzzy is a Fuzzy Model? 10. 2 Fuzzy Algorithms 10. 3 Fuzzy Sets 10. 4 Logical Operators 10. 5 Compositional Rule of Inference 10. 6 Defuzzification 10. 7 Conclusions 11. Adaptive Fuzzy Modelling and Control 11. 1 Introduction 11. 2 Learning Algorithms 11. 3 Plant Modelling 11. 4 Indirect Fuzzy Control 11. 5 Direct Fuzzy Control References. Appendix A. Modified Error Correction Rule Appendix B. Improved CMAC Displacement Tables Appendix C. Associative Memory Network Software Structure C. 1 Data Structures C. 2 Interface Functions C. 3 Sample C Code Appendix D. Fuzzy Intersection Appendix E. Weight to Rule Confidence Vector Map For further information about this book (mailing/shipping costs etc.) and other neurofuzzy titles in the Prentice Hall series please contact: LIZ DICKINSON Prentice Hall Paramount Publishing International Campus 400 Maylands Avenue Hemel Hempstead, HP 2 7 EZ United Kingdom Tel: 0442 881900 Fax: 0442 257115 Content...|$|E
40|$|A {{powerful}} {{concept in}} <b>neuromodeling</b> of microwave circuits based on Space Mapping technology is described. The ability of Artificial Neural Networks (ANN) to model high-dimensional and highly nonlinear problems is exploited {{in the implementation}} of the Space Mapping concept. By taking advantage of the vast set of empirical models already available for many microwave structures, Space Mapping based <b>neuromodels</b> decrease the number of EM simulations for training, improve the generalization and extrapolation performance and reduce the complexity of the ANN topology with respect to the conventional <b>neuromodeling</b> approach. Five innovative techniques are proposed to create Space Mapping based <b>neuromodels</b> for microwave circuits: Space Mapped <b>Neuromodeling</b> (SMN), Frequency-Dependent Space Mapped <b>Neuromodeling</b> (FDSMN), Frequency Space Mapped <b>Neuromodeling</b> (FSMN), Frequency Mapped <b>Neuromodeling</b> (FMN) and Frequency Partial-Space Mapped <b>Neuromodeling</b> (FPSM). Excepting SMN, all these approaches establish a frequency-sensitive neuromapping to expand the frequency region of accuracy of the empirical models already available for microwave components that were developed using quasi-static analysis. We contrast our approach with the conventional <b>neuromodeling</b> approach employed in the microwave arena, as well as with other state-ofthe-art <b>neuromodeling</b> techniques. We use Huber optimization to efficiently train the simple ANN that implements the mapping in our SM-based <b>neuromodels.</b> The five space mapping based <b>neuromodeling</b> techniques are illustrated by two case studies: a microstrip right angle bend and a hightemperature superconducting (HTS) quarter-wave parallel coupled-line microstrip filter...|$|R
40|$|For {{the first}} time, we present {{modeling}} of microwave circuits using artificial neural networks (ANN's) based on space-mapping (SM) technology. SM-based <b>neuromodels</b> decrease {{the cost of}} training, improve generalization ability, and reduce {{the complexity of the}} ANN topology with respect to the classical <b>neuromodeling</b> approach. Five creative techniques are proposed to generate SM-based <b>neuromodels.</b> A frequency-sensitive neuromapping is applied to overcome the limitations of empirical models developed under quasi-static conditions. Huber optimization is used to train the ANN's. We contrast SM-based <b>neuromodeling</b> with the classical <b>neuromodeling</b> approach as well as with other state-of-the-art <b>neuromodeling</b> techniques. The SMbased <b>neuromodeling</b> techniques are illustrated by a microstrip bend and a high-temperature superconducting filter...|$|R
40|$|For {{the first}} time, we present <b>neuromodeling</b> of {{microwave}} circuits based on Space Mapping (SM) technology. SM based <b>neuromodels</b> decrease {{the cost of}} training, improve generalization ability and reduce {{the complexity of the}} ANN topology w. r. t. classical <b>neuromodeling.</b> Three novel techniques are proposed to generate SM based neuromodels: Space-Mapped <b>Neuromodeling</b> (SMN), Frequency-Dependent Space-Mapped <b>Neuromodeling</b> (FDSMN), and Frequency Space-Mapped <b>Neuromodeling</b> (FSMN). Huber optimization is proposed to train the neuro-space-mapping (NSM). The techniques are illustrated by a microstrip right angle bend and a microstrip line with high dielectric constant...|$|R
40|$|We {{review the}} Space Mapping (SM) {{approach}} to circuit design and discuss modeling of microwave circuits using Artificial Neural Networks (ANN). We show that SM and ANN methodologies {{can be combined}} into a powerful design framework. SM based <b>neuromodels</b> decrease the cost of training, improve generalization ability and reduce {{the complexity of the}} ANN topology with respect to the classical <b>neuromodeling</b> approach. We present and illustrate a variety of possible SM based <b>neuromodels,</b> including SMN, FDSMN, FSMN, FMN and FPSM. We contrast SM based <b>neuromodeling</b> with the classical <b>neuromodeling</b> approach as well as with other state-of-the-art <b>neuromodeling</b> techniques. The SM based <b>neuromodeling</b> techniques are illustrated by a microstrip line, a microstrip right angle bend and an HTS filter...|$|R
40|$|This paper {{presents}} {{recent advances}} in model development for RF/microwave components exploiting two powerful technologies: Artificial Neural Networks (ANN) and Space Mapping (SM). We survey the fundamental issues on classical <b>neuromodeling.</b> We review some state-of-the-art <b>neuromodeling</b> techniques, emphasizing SM based <b>neuromodeling</b> techniques. We show how SM based <b>neuromodels</b> decrease the cost of training, improve generalization ability and reduce {{the complexity of the}} ANN topology w. r. t. the classical <b>neuromodeling</b> approach. We illustrate these novel approaches through a practical microwave modeling problem. We conclude by proposing some possible exciting future applications of ANN and SM in microwave CAD...|$|R
40|$|We present novel realizations of SM based <b>neuromodels</b> of {{microwave}} components using available software. In the SM based <b>neuromodeling</b> techniques a {{neural network}} {{is used to}} implement a mapping from the electromagnetic to the circuit-theoretic input space. The implicit knowledge in the circuit model allows us to decrease not only the number of learning points needed, but also {{the complexity of the}} neural network and to improve the generalization performance. A Frequency Space Mapped <b>Neuromodel</b> (FSMN) of a microstrip right angle bend is implemented using NeuroModeler, and entered into ADS as a library component through an ADS plug-in module...|$|R
40|$|Artificial Neural Networks (ANN) {{are very}} {{convenient}} in modeling high-dimensional and highly nonlinear components, as {{those found in}} the microwave and high frequency arena, due to their ability to learn and generalize from data, their non-linear processing nature, and their massively parallel structure. In modeling high frequency components the learning data is usually obtained from a detailed or “fine ” model (EM simulator or measurements). This is generally very time consuming because the simulation/measurements must be performed for many combinations of different values of input parameters. This is the main drawback of classical ANN modeling. Without sufficient learning samples, the neural models may not be reliable. Several innovative strategies to develop <b>neuromodels</b> take advantage of empirical or “coarse ” models already available (circuit-equivalent models and analytical formulas) : the hybrid EM-ANN modeling approach [1], the PKI modeling method [1], the knowledge based ANN [2] (KBNN) approach, and the Space Mapping (SM) based <b>neuromodeling</b> techniques [3]. Space Mapping Based <b>Neuromodeling</b> Let the vectors xf and xc represent the design parameters of the fine and coarse models, respectively, and Rf (xf) and Rc(xc) the corresponding model responses. Rf is accurate but slow to evaluate while Rc is fast but not very accurate. In the Space-Mapping <b>Neuromodeling</b> (SMN) technique an ANN is used to implement the mapping from the fine to the coarse input parameter space. The mapping can be found by solving the optimization proble...|$|R
40|$|We propose, for {{the first}} time, neural space-mapping (NSM) {{optimization}} for electromagnetic-based design. NSM optimization exploits our space-mapping (SM) -based <b>neuromodeling</b> techniques to efficiently approximate the mapping. A novel procedure that does not require troublesome parameter extraction to predict the next point is proposed. The initial mapping is established by performing upfront fine-model analyses at a reduced number of base points. Coarse-model sensitivities are exploited to select those base points. Huber optimization is used to train, without testing points, simple SM-based <b>neuromodels</b> at each NSM iteration. The technique is illustrated by a high-temperature superconducting quarter-wave parallel coupled-line microstrip filter and a bandstop microstrip filter with quarter-wave resonant open stubs...|$|R
40|$|In {{this work}} we present an {{improved}} {{version of the}} Neural Space-Mapping algorithm with regulated nonlinearity. The new version uses a nonlinear two-layer perceptron (2 LP), instead of a three layer perceptron (3 LP), to train the space-mapping (SM) -based <b>neuromodel.</b> The 2 LP mapping nonlinearity is automatically regulated with classical optimization algorithms. Additionally, the new algorithm uses a different optimization method to train the SM-based <b>neuromodel.</b> With these three main improvements we obtain a more efficient and faster algorithm. In order to verify the algorithm performance, we design a stopband microstrip filter with quarter-wave resonant opens stubs, and a microstrip notch filter with mitered bends. Both circuits use a full-wave electromagnetic simulator...|$|R
40|$|Artificial Neural Networks (ANN) are {{suitable}} in modeling high-dimensional and highly nonlinear elements, {{such as those}} found in the microwave arena. In modeling microwave components, the learning data is obtained from a detailed or “fine” model (typically an EM simulator), which is accurate but slow to evaluate. This is aggravated because simulations are needed for many combinations of input parameter values. This is the main drawback of conventional ANN modeling. We use available equivalent circuits or “coarse” models to overcome this limitation. In the Space Mapping (SM) based <b>neuromodeling</b> techniques an ANN is used to implement a suitable mapping from the fine to the coarse input space. The implicit knowledge in the coarse model not only allows us to decrease significantly the number of learning points needed, but also to reduce the complexity of the ANN and to improve the generalization performance. We present novel realizations of SM based <b>neuromodels</b> of practical passive components using commercial software. An SM-based <b>neuromodel</b> of a microstrip right angle bend is developed using NeuroModeler, and entered into HP ADS as a library component through an ADS plug-in module...|$|R
40|$|We review Neural Space Mapping (NSM) {{optimization}} for electromagnetic-based {{design of}} RF and microwave circuits. NSM optimization exploits our Space Mapping-based <b>neuromodeling</b> techniques to efficiently approximate a suitable mapping at each iteration. Coarse model sensitivities are exploited to select suitable fine model base {{points for the}} initial mapping...|$|R
40|$|We propose, for {{the first}} time, Neural Space Mapping {{optimization}} for EM-based design. It exploits our Space Mapping-based neuro-modeling techniques, avoiding troublesome parameter extraction. Simple <b>neuromodels</b> are trained, without testing points, during each optimization iteration. Coarse model sensitivities are exploited to select suitable fine model base points for the initial mapping...|$|R
40|$|Electromagnetic (EM) {{simulators}} {{are regarded}} as highly accurate to predict the behavior of microwave circuits. With the increasing availability of commercial EM field solvers, it is very desirable to include them in the statistical analysis and yield-driven design of high speed circuits. Given the high cost in computational effort imposed by EM simulators, smart procedures must be searched to efficiently use them for statistical analysis and design. Artificial Neural Networks (ANN) and Space Mapping (SM) have been efficiently combined to formulate EM-based design algorithms. We describe in this work the use of neural space mapping methods for efficient and accurate EM-based statistical analysis and yield optimization of high frequency electronic structures. We formulate the yield optimization problem using SMbased <b>neuromodels,</b> which can be obtained either from a modeling process or from a design process. The SM-based <b>neuromodel</b> combines the computational efficiency of coarse models (typically equivalent circuit models) with the accuracy of fine models (typically EM simulators). The statistical analysis and design is realized in the frequency domain. A general equation to express {{the relationship between the}} fine and coarse model sensitivities through a nonlinear, frequency-sensitive neuromapping is reviewed. We describe the use of SM-based <b>neuromodels</b> for symmetric and asymmetric variations in the tolerances of the physical design parameters. We illustrate our technique by the yield analysis and optimization of a high-temperature superconducting (HTS) quarter-wave parallel coupledline microstrip filter...|$|R
50|$|His work {{centred on}} the {{modelling}} capability of artificial neural networks. He devised <b>neuromodels</b> {{of the visual}} system in primates, visuo-verbal system in humans, the effect of anaesthetics on awareness, and artificial consciousness. He designed {{one of the first}} neural pattern recognition systems, the WISARD (marketed by CRS, Wokingham) in the 1980s.|$|R
40|$|Accurate yield {{optimization}} {{and statistical}} analysis of microwave components are crucial in manufacturabilitydriven designs in a time-to-market development environment. Yield optimization requires intensive simulations to cover the entire statistic of possible outcomes of a given manufacturing process. Performing direct yield optimization using accurate full wave electromagnetic (EM) simulations does not appear feasible. Here, an efficient procedure to realize EM-based yield optimization and {{statistical analysis of}} microwave structures using space mapping-based <b>neuromodels</b> is proposed. We have mathematically formulated the yield optimization problem using SM-based <b>neuromodels.</b> A general equation to express {{the relationship between the}} fine and coarse model sensitivities through a nonlinear, frequency-sensitive neuromapping has been found. We illustrate our technique by the yield analysis and optimization of an HTS filter. Here we assume symmetric variations in the physical parameters due to tolerances. Efficient procedures have also been developed for the asymmetric case...|$|R
40|$|Artificial Neural Networks (ANN) {{are very}} {{convenient}} in modeling high-dimensional and highly nonlinear components, as {{those found in}} the microwave and high frequency arena, due to their ability to learn and generalize from data, their non-linear processing nature, and their massively parallel structure. In modeling high frequency components the learning data is usually obtained from a detailed or “fine” model (EM simulator or measurements). This is generally very time consuming because the simulation/measurements must be performed for many combinations of different values of input parameters. This is the main drawback of classical ANN modeling. Without sufficient learning samples, the neural models may not be reliable. Several innovative strategies to develop <b>neuromodels</b> take advantage of empirical or “coarse” models already available (circuit-equivalent models and analytical formulas). Here we describe space mapping based <b>neuromodeling</b> of high frequency circuits...|$|R
40|$|In this work, an {{efficient}} procedure to realize electromagnetics-based yield optimization and {{statistical analysis of}} microwave structures using space mapping-based <b>neuromodels</b> is proposed. A generalized relationship between the fine and coarse model sensitivities through the Jacobian of the neuromapping is proposed. Our technique {{is illustrated by the}} EM-based statistical analysis and yield optimization of an HTS microstrip filter...|$|R
40|$|Accurate yield {{optimization}} {{and statistical}} analysis of microwave components are crucial ingredients for manufacturability-driven designs in a time-to-market development environment. Yield optimization requires intensive simulations to cover the entire statistic of possible outcomes of a given manufacturing process. Performing direct yield optimization using accurate full-wave electromagnetic simulations does not appear feasible. In this article, an efficient procedure to realize electromagnetics (EM) based yield optimization and {{statistical analysis of}} microwave structures using space mapping-based <b>neuromodels</b> is proposed. Our technique {{is illustrated by the}} EM-based statistical analysis and yield optimization of a high temperature superconducting (HTS) microstrip filter...|$|R
40|$|International audienceNeural {{networks}} are powerful tools for black box system identification. However, their main drawback {{is the large}} number of parameters usually required to deal with complex systems. Classically, the model's parameters minimize a L 2 -norm-based criterion. However, when using strongly corrupted data, namely, outliers, the L 2 -norm-based estimation algorithms become ineffective. In order to deal with outliers and the model's complexity, the main contribution {{of this paper is to}} propose a robust system identification methodology providing <b>neuromodels</b> with a convenient balance between simplicity and accuracy. The estimation robustness is ensured by means of the Huberian function. Simplicity and accuracy are achieved by a dedicated neural network design based on a recurrent three-layer architecture and an efficient model order reduction procedure proposed in a previous work (Romero-Ugalde et al., 2013, “Neural Network Design and Model Reduction Approach for Black Box Nonlinear System Identification With Reduced Number of Parameters,” Neurocomputing, 101, pp. 170 – 180). Validation is done using real data, measured on a piezoelectric actuator, containing strong natural outliers in the output data due to its microdisplacements. Comparisons with others black box system identification methods, including a previous work (Corbier and Carmona, 2015, “Extension of the Tuning Constant in the Huber's Function for Robust Modeling of Piezoelectric Systems,” Int. J. Adapt. Control Signal Process., 29 (8), pp. 1008 – 1023) where a pseudolinear model was used to identify the same piezoelectric system, show the relevance of the proposed robust estimation method leading balanced simplicity-accuracy <b>neuromodel...</b>|$|R
40|$|Manufacturability-driven {{designs in}} a {{time-to-market}} development industrial environment demand accurate yield optimization and {{statistical analysis of}} the electronic components. Yield optimization requires intensive simulations to cover the entire statistic of possible outcomes of a given manufacturing process. Full wave electromagnetic simulations are usually needed to accurately characterize high frequency electronic circuits. Performing direct yield optimization using accurate full wave electromagnetic simulations for high frequency circuits does not appear feasible. In this paper, an efficient procedure to perform electromagnetics-based yield optimization and statistical analysis of high frequency structures using space mapping-based <b>neuromodels</b> is proposed. Our technique {{is illustrated by the}} EM-based statistical analysis and yield optimization of an HTS filter...|$|R
40|$|The Hebbian {{synaptic}} weight learning rule {{is the most}} basic and wide spread learning rule used in <b>neuromodeling.</b> However, to date {{there has been little}} work done in applying this simple learning mechanism to significantly largescale cortex models. The visual cortex of a freshwater turtle, when stimulated by a pattern of light, produces waves of activity that have been both recorded exper mentally and simulated using a large scale model cortex. It has been shown using the model cortex that the cortex waves encode spatial information of visual input and can be used fordetection. This paper explores the effects of Hebbian learning on the wave activity patterns of the freshwater cortex model. ...|$|R
40|$|Artificial Neural Networks (ANN) and Space Mapping (SM) are eficiently {{combined}} to formulate EM-based design algorithms. Neural Space Mapping (NSM) optimization and Neural Inverse Space Mapping (NISM) optimization are reviewed. NSM optimization exploits the SM-based <b>neuromodeling</b> techniques to efficiently approximate the mapping. The next point is predicted avoiding parameter extraction (PE). The initial mapping is established by performing upfront fine model analyses at a reduced number of base points. Coarse model sensitivities are exploited to select those base points. Huber optimization {{is used to}} train, without testing points, simple SM-based <b>neuromodels</b> at each NSM iteration. EM-based yield optimization is efficiently realized after NSM optimization. NISM optimization is the first space mapping algorithm that explicitly makes use of the inverse of the mapping from the fine to the coarse model parameter spaces. NISM follows an aggressive formulation by not requiring a number of up-front fine model evaluations to start building the mapping. An statistical procedure to PE avoids the need for multipoint matching and frequency mappings. It can also overcome poor local mimima during PE. An ANN whose generalization performance is controlled through a network growing strategy approximates the inverse mapping at each iteration. In this manner, the ANN always starts from a 2 -layer perceptron and automatically migrates to a 3 -layer perceptron only if the amount of nonlinearity found in the inverse mapping becomes significant. The NISM step consists of evaluating the current neural network at the optimal coarse solution. This step is equivalent to a quasi-Newton step while the inverse mapping is essentially linear, and gradually departs from a quasi-Newton step {{as the amount of}} nonlinearity in the inverse mapping grows. Contrast is made between neural space mapping design methods. A number of industrially relevant microwave design problems are efficiently solved...|$|R
40|$|Parallelism and {{distribution}} {{have been considered}} the key features of neural processing. The term parallel distributed processing is even used as a synonym for artificial neural networks. Nevertheless, the actual implementations are still {{in search of the}} appropriate model to "naturally represent" neural computing. And the final judgement is always given in performance figures [...] keeping the parallelization issue high on the neurosimulation agenda. Two approaches have yielded the best results: parallel simulations on general-purpose computers, and specially developed neurohardware. Programming neural networks on parallel machines requires high-level techniques reflecting both inherent features of <b>neuromodels</b> and characteristics of the underlying computers. On the other hand, emulation of the neuroparadigm requires that the functioning of neural operations be mimicked directly by the hardware. Both approaches are presented, and their advantages and shortcomings are outlined...|$|R
40|$|This thesis {{deals with}} the {{high-performance}} parallel implementation of biologically realistic neural networks on distributed architectures. There are two parts in this thesis: the General Background,and the Simulations with SPLIT. In the first part,the place within neuroscience which large-scale simulations occupy is described and the main concepts of the <b>neuromodeling</b> and simulations are introduced. We also show how to model biological neural networks and how to write parallel applications using a specialized simulation library,SPLIT. In the second part,the programming environment of the distributed memory Linux cluster Lucidor is described and the simulation results are presented and analyzed. The main contributions are: • Usage of the SPLIT library in the parallel environment of the IBM Itanium 2 Linux cluster Lucidor (lucidor. pdc. kth. se) is described. • Simulations of small-scale and large-scale neural networks on singl...|$|R
40|$|Many {{believe that}} the most {{important}} result {{to come out of the}} last ten years of neural network research is the significant change in perspective in the neuroscience community towards a theory of computational neurobiology and functional <b>neuromodels.</b> Arriving on a fast moving train from the other direction is semiconductor technology, one of the greatest technology success stories of all time – transistors are now approaching deep submicron (less than 100 nanometers) in size, and we will soon be building silicon chips with over 1 billion transistors. The marriage of these two technologies is creating what Andy Grove (ex-CEO of Intel) refers to as a strategic inflection point. Although previous attempts at merging these technologies were premature, silicon and computational neurobiology are now merging to create an extremely powerful, and radically new form of computation. 1...|$|R
40|$|Functional neuroimaging {{has made}} {{fundamental}} contributions {{to our understanding}} of brain function. It remains challenging, however, to translate these advances into diagnostic tools for psychiatry. Promising new avenues for translation are provided by computational modeling of neuroimaging data. This article reviews contemporary frameworks for computational neuroimaging, with a focus on forward models linking unobservable brain states to measurements. These approaches-biophysical network models, generative models, and model-based fMRI analyses of neuromodulation-strive to move beyond statistical characterizations and toward mechanistic explanations of neuroimaging data. Focusing on schizophrenia as a paradigmatic spectrum disease, we review applications of these models to psychiatric questions, identify methodological challenges, and highlight trends of convergence among computational neuroimaging approaches. We conclude by outlining a translational <b>neuromodeling</b> strategy, highlighting the importance of openly available datasets from prospective patient studies for evaluating the clinical utility of computational models...|$|R
40|$|A neural space mapping {{optimization}} algorithm based on nonlinear two layer perceptrons (2 LP) {{is described in}} this article. This work is an improved version of the Neural Space-Mapping (NSM) algorithm that uses three layer perceptrons (3 LP) to implement a nonlinear input mapping function at each iteration. The new version uses a nonlinear 2 LP whose nonlinearity is automatically regulated with classical {{optimization algorithm}}s. Additionally, the new algorithm uses a different optimization method to train the SM-based <b>neuromodel</b> and a more efficient manner to predict the next iterate. With these improvements, we obtain a more efficient and faster algorithm. To verify the algorithm performance, we design some synthetic circuits, {{as well as a}} stopband microstrip filter with quarter-wave resonant opens stubs, a bandpass microstrip filter, and a microstrip notch filter with mitered bends. The last three cases use commercially available full-wave electromagnetic simulators. A rigorous comparison is made with the original NSM algorithm, showing the performance improvement achieved by our proposed new formulation...|$|R
40|$|We {{review the}} Space Mapping (SM) concept and its {{applications}} in engineering optimization and modeling. The aim of SM {{is to avoid}} computationally expensive calculations encountered in simulating an engineering system. The existence of less accurate but fast physically-based models is exploited. SM drives the optimization iterates of the time-intensive model using the fast model. Several algorithms {{have been developed for}} SM optimization, including the original SM algorithm, Aggressive Space Mapping (ASM), Trust Region Aggressive Space Mapping (TRASM) and Hybrid Aggressive Space Mapping (HASM). An essential subproblem of any SM based optimization algorithm is parameter extraction. The uniqueness of this optimization subproblem has been crucial to the success of SM optimization. Different approaches to enhance the uniqueness are reviewed. We also discuss new developments in Space Mapping-based Modeling (SMM). These include Space Derivative Mapping (SDM), Generalized Space Mapping (GSM) and Space Mapping-based <b>Neuromodeling</b> (SMN). Finally, we address open points for research and future development...|$|R
40|$|Abstract—An {{artificial}} {{neural network}} (ANN) is proposed to predict the input impedance of a broadband antenna {{as a function of}} its geometric parameters. The input resistance of the antenna is first parameterized by a Gaussian model, and the ANN is constructed to approximate the nonlinear relationship between the antenna geometry and the model parameters. Introducing the model simplifies the ANN and decreases the training time. The reactance of the antenna is then constructed by the Hilbert transform from the resistance found by the <b>neuromodel.</b> A hybrid gradient descent and particle swarm optimization method is used to train the neural network. As an example, an ANN is constructed for a loop antenna with three tuning arms. The antenna structure is then optimized for broadband operation via a genetic algorithm that uses input impedance estimates provided by the trained ANN in place of brute-force electromagnetic computations. It is found that the required number of electromagnetic computations in training the ANN is ten times lower than that needed during the antenna optimization process, resulting in significant time savings. Index Terms—Artificial neural network, broadband antenna...|$|R
40|$|The Space Mapping concept {{intelligently}} links companion “coarse” and “fine” engineering {{models of}} different complexities, e. g., fullwave electromagnetic (EM) simulations and empirical circuit-theory based models. A comprehensive framework to engineering device modeling {{which we call}} Generalized Space Mapping (GSM) has been developed. GSM is a tableau-based approach. It permits many different practical implementations. As a result the accuracy of available empirical models of microwave devices can be significantly enhanced in selected regions {{of interest in the}} parameter space. We present two fundamental illustrations: a basic Space Mapping Super Model (SMSM) which maps designable device parameters and a Frequency-Space Mapping Super Model (FSMSM) which also maps the frequency variable. The SMSM and FSMSM concepts have been verified on several modeling problems, typically utilizing a few relevant full-wave EM simulations. We present several microstrip examples, yielding remarkable modeling improvement. We consider the GSM technique to be very easy to implement. It has been reported to be very useful in the RF industry for development of new library models involving commercial software such as Agilent Momentum and ADS. Accurate yield optimization and statistical analysis of microwave components are crucial for manufacturability-driven designs in a time-tomarket development environment. Yield optimization requires intensive simulations to cover the entire statistic of possible outputs of a given manufacturing process. An efficient procedure to realize EM-based yield optimization and statistical analysis of microwave structures using space mapping based <b>neuromodels</b> will be presented. Several practical microwave components illustrate our technique using commercial EM simulators...|$|R
40|$|Cognition is {{hypothesized}} {{to require the}} globally coordinated, functionally relevant integration of otherwise segregated information processing carried out by specialized brain regions. Studies of the macroscopic connectome as well as recent neuroimaging and <b>neuromodeling</b> research have suggested a densely connected collective of cortical hubs, termed the rich club, to provide a central workspace for such integration. In order for rich club regions to fulfill this role they must dispose of a dynamic mechanism by which they can actively shape networks of brain regions whose information processing needs to be integrated. A potential candidate for such a mechanism {{comes in the form}} of oscillations which might be employed to establish communication channels among relevant brain regions. We explore this possibility using an integrative approach combining whole-brain computational modeling with neuroimaging, wherein we investigate the local dynamics model brain regions need to exhibit in order to fit (dynamic) network behavior empirically observed for resting as well as a range of task states. We find that rich club regions largely exhibit oscillations during task performance but not during rest. Furthermore, oscillations exhibited by rich club regions can harmonize a set of asynchronous brain regions thus supporting functional coupling among them. These findings are in line with the hypothesis that the rich club can actively shape integration using oscillations. Authors MS and RG were supported by the European Research Council under the European Union's Seventh Framework Programme (ERC- 2010 -AdG, ERC grant agreement no. 269853). Author GD was supported by the ERC Advanced Grant: DYSTRUCTURE (no. 295129), by the Spanish Research ProjectSAF 2010 - 16085 and by European Community's Seventh Framework Programme under the project “BrainScales” (project number 269921). Author MPvdH was supported by a VENI grant of The Netherlands Organization for Scientific Research (NWO) (451 - 12 - 001) and by a Fellowship of the Brain Center Rudolf Magnus...|$|R
40|$|The {{purpose of}} this {{literature}} review is to examine whether Pavlovian eye blink conditioning in the rabbit consists solely of a specific motor reflex or involves other extracerebellar control systems. Castiglioni et al. (2009) utilized a transfer design in which retention of learning in different environments and {{the expression of the}} original learning was not limited to a single motor reflex measure. Subjects were trained in a traditional Pavlovian stock to differentiate between an S+ signal of a brief tone paired with an unconditioned stimulus (US) of cutaneous shock. Then, subjects were tested for what they had learned in a different environment. The results showed that the presentation of the S+ produced completely different behavior in the open environment as compared to the Pavlovian stock. In the restricted environment of the Pavlovian stock, presentation of the S+ produced eye blink responses without any additional motor or emotional reactions. In the transfer environment, reaction to the S+ produced: (a) a prolonged disruption of ongoing behavior, (b) a wide range of complex emotional responses, and (c) a complete absence of eye blink response. Reaction to the S- in the Pavlovian stock or in the open environment, did not elicit an eye blink response. These findings provide strong evidence that Pavlovian conditioning is not just a specific motor reflex, but instead involves a difference in meaning and significance of the S+ for the subjects when presented in two discrete environments. This is observed in the subjects? different response patterns which unmasked a significant emotional component of the conditioning. This lead to the conclusion that nictitating membrane (NM) conditioning consists of more than an invariant, discrete cerebellar oculomotor reflex. The clear emotional component to the conditioning indicates the involvement of extracerebellar control mechanisms, potentially a widespread cerebral network in addition to the microcerebellar control of the specific motor reflex, a contradiction to current <b>neuromodels...</b>|$|R

