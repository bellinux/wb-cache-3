80|10000|Public
30|$|To {{account for}} these properties, <b>new</b> <b>techniques</b> <b>are</b> <b>required</b> {{which do not}} assure the {{integrity}} of the digital representation of visual data but its visual appearance or perceptual content. In the area of multimedia security, two types of approaches have been proposed so far: semifragile watermarking and robust/perceptual/visual multimedia hashes.|$|E
30|$|Higher-index PDAEs (differentiation index {{greater than}} one) {{are known to}} be {{difficult}} to treat even numerically. Often such problems are first transformed to index-one systems before applying numerical integration methods. This procedure called index-reduction, can be very expensive and may change the properties of the solution. Since applications problems in science and engineering often lead to higher-index PDAEs, <b>new</b> <b>techniques</b> <b>are</b> <b>required</b> to solve these problems efficiently.|$|E
40|$|Complex "smart" devices made of {{heterogeneous}} {{components and}} incorporating functions of sensing, actuation and control are increasingly requested, but, {{for the development}} of next generation systems, <b>new</b> <b>techniques</b> <b>are</b> <b>required</b> for managing the increasing design complexity. The SMAC Project aims at developing a common solution for Smart System design where cross-sectional flows converge into a common Platform, based on (co-) simulation and model abstraction methodologies. This paper describes the main requirements and features of the SMAC Platform and two industrial case studie...|$|E
50|$|Borosilicate {{glass is}} created by {{combining}} together and melting boric oxide, silica sand, soda ash, and alumina. Since borosilicate glass melts at a higher temperature than ordinary silicate glass, some <b>new</b> <b>techniques</b> <b>were</b> <b>required</b> for industrial production. The manufacturing process depends on the product geometry and can be differentiated between different methods like floating, tube drawing, or moulding.|$|R
40|$|Abstract—When {{it comes}} to cloud data {{protection}} methods, no particularly <b>new</b> <b>technique</b> <b>is</b> <b>required.</b> Protecting data in the cloud can be similar to protecting data within a traditional data center. Authentication and identity, access control, encryption, secure deletion, integrity checking, and data masking are all data protection methods that have applicability in cloud computing. Th is paper will b riefly review few methods and will note anything that is particularly unique to when these are deployed in a cloud...|$|R
40|$|Conventional {{techniques}} for measuring creep {{are limited to}} about 1700 C, so a <b>new</b> <b>technique</b> <b>is</b> <b>required</b> for higher temperatures. This <b>technique</b> <b>is</b> based on electrostatic levitation (ESL) of a spherical sample, which is rotated quickly enough to cause creep deformation by centrifugal acceleration. Creep of samples has been demonstrated at up to 2300 C in the ESL facility at NASA MSFC, while ESL itself has been applied at over 3000 C, and has no theoretical maximum temperature. The preliminary results and future directions of this NASA-funded research collaboration will be presented...|$|R
40|$|In {{order to}} analyze {{increasingly}} common 3 D image data, <b>new</b> <b>techniques</b> <b>are</b> <b>required.</b> Some {{of these techniques}} {{can be derived from}} traditional 2 D image processing, while others must be created for a particular problem. Using various 3 D techniques, we are analyzing high resolution tomographic data of concrete in order to study its fracture energy and permeability. The techniques we are using include: thresholding, boundary finding, connected component analysis and a newly developed technique based on relative motion analysis...|$|E
30|$|Our work {{opens up}} a new {{approach}} to dealing with high PAPR through clipping and the correction of clipping errors. <b>New</b> <b>techniques</b> <b>are</b> <b>required</b> to aid in differentiating reliably from unreliably snapped constellations to improve the performance. We have briefly considered some of these methods {{in the context of a}} pseudo-inverse approach to the Equation-Method and will consider them in the context of the square-matrix approach in our future work. Performance of the square-matrix in the presence of additive white Gaussian noise will also be addressed in the future work.|$|E
40|$|Securing large {{corporate}} communication networks {{has become an}} increasingly difficult task. Sensitive information routinely leaves the company network boundaries and falls {{into the hands of}} unauthorized users. <b>New</b> <b>techniques</b> <b>are</b> <b>required</b> in order to classify packets based on user identity in addition to the traditional source and destination host addresses. This paper introduces Gaussian cryptographic techniques and protocols to assist network administrators in the complex task of identifying the originators of data packets on a network and more easily policing their behavior. The paper provides numerical examples that illustrate certain basic ideas...|$|E
40|$|Advanced {{research}} in experimental fluid dynamics required a familiarity with sophisticated measurement techniques. In some cases, {{the development and}} application of <b>new</b> <b>techniques</b> <b>is</b> <b>required</b> for difficult measurements. Optical methods and in particular, the laser Doppler velocimeter (LDV) are now recognized as the most reliable means for performing measurements in complex turbulent flows. And such, the experimental fluid dynamicist should {{be familiar with the}} principles of operation of the method and the details associated with its application. Thus, the goals of this primer are to efficiently transmit the basic concepts of the LDV method to potential users and to provide references that describe the specific areas in greater detail...|$|R
40|$|Thus <b>new</b> <b>techniques</b> <b>were</b> <b>required</b> {{to develop}} for {{attracting}} private sector investment in infrastructure projects. One such <b>technique</b> <b>is</b> built-operate-transfer (BOT) and its different variants. Under this scheme an infrastructure projects conceptualized by the government/public. Bids are then invited from {{private sector to}} arrange funds, build the facility and operate over a specified concession period collecting revenue as a toll from the user to recover the invested capital plus an adequate return on the investment usually 15 to 20 percent. After the concession period the ownership of the created facility is transferred back to the government. Therefore, the BOT scheme is a limited-recourse project financing technique for implementing infrastructure projects by using private funding...|$|R
40|$|Traditional imaging <b>techniques</b> <b>are</b> quite limited for {{the study}} of the {{relationship}} between blood vessels and lymphatic vessels. Therefore, a <b>new</b> imaging <b>technique</b> <b>is</b> <b>required</b> based on blood vessel and lymphatic endothelial-specific molecular markers. In this short report, vascular molecular markers are reviewed and a <b>new</b> molecular imaging <b>technique</b> for blood vessel and lymphatic co-staining is introduced...|$|R
40|$|The {{classical}} straightening theorem as proved by Douady and Hubbard {{shows that}} a polynomial-like sequence is hybrid equivalent to a polynomial. We generalize this result to non-autonomous iteration where one considers composition sequences arising from a varying sequence of functions. In order to do this, <b>new</b> <b>techniques</b> <b>are</b> <b>required</b> to control the distortion and quasiconformal dilatation of the hybrid equivalence. In particular, the Caratheodory topology for pointed domains allows us to specify the appropriate bounds on the sequence of sets on which the polynomial-like mapping sequence is defined and give us good estimates {{on the degree of}} distortion and quasiconformality...|$|E
40|$|Most soil/water/crop growth {{models are}} based on the 1 -D {{conceptualization}} paradigm and lack the spatio-temporal dimensions advocated in recent times. The literature abounds with agricultural systems models that {{are based on}} point scale or paddock scale soil water balance coupled to a crop growth process. Some of these models were adapted to represent lumped characterization of spatial processes. They are ideal for simulating crop development on a relatively homogeneous area such as a paddock. To account for spatial heterogeneity over a larger area such as an irrigation district or a river basin, <b>new</b> <b>techniques</b> <b>are</b> <b>required.</b> The spatial dimension of agricultural production systems makes geographic informatio...|$|E
40|$|There is {{a growing}} demand for Internet-wide {{real-time}} collaborations. <b>New</b> <b>techniques</b> <b>are</b> <b>required</b> for real-time applications to perform well {{in the face of}} changing network conditions that often include long delays. We present some of the key issues for developers of real-time web-based collaborative applications, including choices on centralized versus replicated data distribution, synchronous versus asynchronous message protocols, and state divergence. We present an implementation of a Java-based version of the classic Pong game, called Ppong!. Ppong! was selected for implementation because it illustrates essential components of real-time collaborative simulation. A novel feature of Ppong! is implementation of a heuristic for "retarding" a user's view of the simulation to accommodate network delays...|$|E
40|$|In this manuscript, we {{determine}} the optimal approximation rate for Skorohod integrals of sufficiently regular integrands. This generalizes the optimal approximation results for Itô integrals. However, without adaptedness and the Itô isometry, <b>new</b> proof <b>techniques</b> <b>are</b> <b>required.</b> The main tools are a characterization via S-transform and a reformulation of the Wiener chaos decomposition {{in terms of}} Wick-analytic functionals...|$|R
50|$|In {{his best}} known work, joint with Steven Rudich, he {{introduced}} {{the notion of}} natural proofs, a class of strategies used to prove fundamental lower bounds in computational complexity. In particular, Razborov and Rudich showed that, {{under the assumption that}} certain kinds of one-way functions exist, such proofs cannot give a resolution of the P = NP problem, so <b>new</b> <b>techniques</b> will <b>be</b> <b>required</b> in order to solve this question.|$|R
40|$|Tracheal {{intubation}} {{remains a}} common procedure during neonatal intensive care. Rapid confirmation of correct tube placement {{is important because}} tube malposition is associated with serious adverse outcomes. The current gold standard test to confirm tube position is a chest radiograph, however this is often delayed until after ventilation has commenced. Hence, point of care methods to confirm correct tube placement have been developed. The aim {{of this article is}} to review the available literature on tube placement in newborn infants. We reviewed books, resuscitation manuals and articles from 1830 to the present with the search terms "Infant, Newborn", "Endotracheal intubation", "Resuscitation", "Clinical signs", "Radiography", "Respiratory Function Tests", "Laryngoscopy", "Ultrasonography", and "Bronchoscopy". Various <b>techniques</b> have <b>been</b> studied to help clinicians assess tube placement. However, despite 85 years of clinical practice, the search for higher success rates and quicker intubation continues. Currently, chest radiography remains the gold standard test to confirm tube position. However, rigorous evaluation of <b>new</b> <b>techniques</b> <b>is</b> <b>required</b> to ensure the safety of newborn infants. Restricted Access: Metadata Onl...|$|R
30|$|The final {{analytical}} {{stage to}} be completed in future research is to further extend AutoflowU’s capability to deal with commercial property. <b>New</b> <b>techniques</b> <b>are</b> <b>required</b> to allow this model to analyse data on a real-time basis without relying on the previously trained knowledge. The high level of accuracy obtained through the verification process on USA data is a promising outcome for this study. However, in order for AutoflowU to become a highly accurate, adaptable and autonomous software that has worldwide commercial application, further training, testing and validation, using samples from independent homes from various urban areas within different countries, will also need to be carried out to confirm the accuracy level of this application for various situational contexts (e.g. country, region, etc.).|$|E
40|$|Nanofabrication is {{the core}} task {{performed}} and constantly further developed by today’s and future semiconductor industry. Optimization of throughput and minimizing process cost and complexity thus increasing fabrication reliability constitute the main challenges within this development. As integrated circuits continue to go smaller, laying down circuit patterns on semiconductor material becomes more expensive and <b>new</b> <b>techniques</b> <b>are</b> <b>required.</b> CMOS performance has always been strictly depending on the capabilities of lithography in terms of minimum feature size and overlay. Lithography has the strongest influence on production costs of integrated circuits. In this paper, {{some of the recent}} advances in lithography are summarized with special reference to the microelectronics and nano electronics industry. Stringentdemands will be made on reliability, contamination control, particle detection, and yield enhancement...|$|E
40|$|Ontologies {{are being}} {{successfully}} used to overcome semantic heterogeneity, and are becoming fundamental {{elements of the}} Semantic Web. Recently, {{it has also been}} shown that ontologies can be used to build more accurate and more personalized recommendation systems by inferencing missing user’s preferences. However, these systems assume the existence of ontologies, without considering their construction. With product catalogs changing continuously, <b>new</b> <b>techniques</b> <b>are</b> <b>required</b> in order to build these ontologies in real time, and autonomously from any expert intervention. This paper focuses on this problem and show {{that it is possible to}} learn ontologies autonomously by using clustering algorithms. Results on the MovieLens and Jester data sets show that recommender system with learnt ontologies significantly outperform the classical recommendation approach...|$|E
40|$|Increasing {{demands on}} the {{fidelity}} of simulations for real-time and high-fidelity simulations are stressing the capacity of modern processors. <b>New</b> integration <b>techniques</b> <b>are</b> <b>required</b> that provide maximum efficiency for systems that are parallelizable. However many current techniques make assumptions that {{are at odds with}} non-cascadable systems. A new serial multi-step/multi-rate integration algorithm for dual-timescale continuous state systems is presented which applies to these systems, and is extended to a parallel multi-step/multi-rate algorithm. The superior performance of both algorithms is demonstrated through a representative example...|$|R
40|$|In {{this project}} {{we aim at}} {{addressing}} {{the study of the}} full manufacturing process of a photonic integrated circuit, from the initial stage of components design to the tests required to ensure its proper functioning. Its most innovative aspect compared to the existing technology is that the wavelength used belongs to the visible light spectrum. Thus the dimensions of the waveguides have to be significantly reduced. For this reason, the analysis of new manufacturing protocols, using new materials and <b>new</b> <b>techniques,</b> <b>is</b> <b>required.</b> In addition, the current methods will be also modified in order to be optimized for our scenario. In a first step, design and simulation of the desired devices were conducted so that a set of different configurations can be approached. After that, the integration of the maximum number of these configurations was settled in a chromium mask design. This mask was then used in the photolithography process to harden SU- 8 photoresist over a silicon substrate. Good fabrication results were obtained, being able to reach waveguides structures of 0. 5 μm thick and 1. 5 μm wide. The final chips were characterized in a dark room with two different laser input and proper light guidance was demonstrated as well as output switching...|$|R
40|$|It is {{increasingly}} apparent that target-based drug discovery is not delivering adequate numbers of clinical candidates {{for treatment of}} malignancies. The main problems encountered are target identification, validation and late stage attrition. <b>New</b> complementary <b>techniques</b> <b>are</b> <b>required</b> to increase the success rate of cancer drug discovery. Phenotype-guided discovery, using chemicai genetic screens, provides an alternative strategy that circumvents {{many of the issues}} associated with target-based discovery. Zebrafish is a vertebrate model uniquely suited to such high throughput screens, and establishing relevant neoplasia models would enable screening for novel anti-cancer therapeutics. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Abstract- Nanofabrication is {{the core}} task {{performed}} and constantly further developed by today’s and future semiconductor industry. Optimization of throughput and minimizing process cost and complexity thus increasing fabrication reliability constitute the main challenges within this development. As integrated circuits continue to go smaller, laying down circuit patterns on semiconductor material becomes more expensive and <b>new</b> <b>techniques</b> <b>are</b> <b>required.</b> CMOS performance has always been strictly depending on the capabilities of lithography in terms of minimum feature size and overlay. Lithography has the strongest influence on production costs of integrated circuits. In this paper, {{some of the recent}} advances in lithography are summarized with special reference to the microelectronics and nano electronics industry. Stringent demands will be made on reliability, contamination control, particle detection, and yield enhancement...|$|E
40|$|We {{discuss the}} {{hardware}} and software challenges in building a 2 Mbit per second wireless handheld communications device. Of primary importance is power dissipation. A host of <b>new</b> <b>techniques</b> <b>are</b> <b>required</b> {{at all levels of}} the design hierarchy. Innovative VLSI circuit techniques combined with low power process technologies will provide opportunities for high integration ultra-low power ICs. Application specific techniques for parallelizing saturating arithmetic will also become important. Highly configurable programmable structures will enable multiprotocol systemon-a-chip solutions. To program complex SOCs, new software techniques will be required. Hardware implementations will need to be intimately aware of these software techniques. In particular, both Signal Processing code written in C and Control code written in Java will drive new compilation techniques to enable broadband 3 G wireless systems. 1...|$|E
40|$|There is {{a growing}} demand for {{real-time}} collaborative applications through the World Wide Web. <b>New</b> <b>techniques</b> <b>are</b> <b>required</b> for real-time applications to perform well {{in the face of}} changing network conditions that often include long delays. We present some of the key issues for implementors of real-time web-based applications, including choices on centralized versus distributed control, two versus multiuser considerations, synchronous versus asynchronous message protocols, and simulation divergence. We present an implementation for a web-based version of the classic Pong game, called Ppong!. Ppong! was selected for implementation since it strips to its essentials many components of real-time collaborative simulation. A key feature of Ppong! is implementation of a heuristic for "retarding" a user's view of the simulation to accommodate network delays...|$|E
40|$|Recent {{theoretical}} and empirical advances have brought income and wealth distributions back into a prominent position in growth and development theories, and as determinants of specific socio-economic outcomes, such as health or levels of violence and related phenomenon of inequality. To improve empirical investigation, <b>new</b> <b>techniques</b> <b>were</b> <b>required</b> for the simulation of small scale welfare indicators, such as income and its related distribution. Elbers, Lanjouw and Lanjouw (2003) designed a statistical procedure to combine different types of data {{and take advantage of}} the detail in household sample surveys and the comprehensive coverage of a census. The method extends the literature on small area statistics (Ghosh and Rao (1994), Rao (1999)) by developing estimators of population parameters which are non-linear functions of the underlying variable of interest (for example per capita income) by deriving them from the full unit level distribution of that variable. The most famous output of these exercises is known as “poverty maps”. The use of these poverty maps is an important poverty reduction policy implementation tool used for selecting the poorest villages in the country (or villages where the greatest number of poor people are), such as the programs Bolsa Escuela in Brasil, Progreso in Mexico, Puente in Chile, Bolsa Familia in Argentina, Bono de Desarrollo Humano in Ecuador or Tekopora in Paraguay; all of these conditional cash transfer programs, directly to extremely poor households. ...|$|R
40|$|Deposit {{insurers}} {{are particularly}} concerned about high-cost failures. When the factors driving such failures differ systematically from the determinants of low- and moderate-cost failures, a <b>new</b> estimation <b>technique</b> <b>is</b> <b>required.</b> Using a sample of more than 1, 000 bank failures in the U. S. between 1984 and 2003, I present a quantile regression approach that illustrates {{the sensitivity of the}} dollar value of losses in different quantiles to my explanatory variables. These findings suggest that reliance on standard econometric techniques results in misleading inferences, and that losses are not homogeneously driven by the same factors across the quantiles. I also find that liability composition affects time to failure...|$|R
5000|$|The {{dome shape}} of the roof, by design, causes both {{vertical}} and horizontal reactions or forces on the buildings walls and monoliths. In order to make Max Abramovitz design a reality, a relatively <b>new</b> post-tensioning <b>technique</b> <b>was</b> <b>required.</b> The post-tensioning <b>techniques</b> required {{for the construction of}} the Assembly hall were first developed for Titan missile base construction. Felmley-Dickerson Co sub-contracted Preload Co. of New York City to post-tension a concrete ring girder {{around the perimeter of the}} dome. [...] Preload Co. borrowed a special horizontal-wheeled tractor from the missile silo work to wind the steel wire around the dome. The wrapping machine required some slight modifications for this project.|$|R
40|$|We {{study the}} {{envelope}} approximation and its applicability to first-order phase transitions {{in the early}} universe. We demonstrate that the power laws seen in previous studies exist independently of the nucleation rate. We also compare the envelope approximation prediction to results from large-scale phase transition simulations. For phase transitions where the contribution to gravitational waves from scalar fields dominates over that from the coupled plasma of light particles, the envelope approximation is in agreement, giving a power spectrum of the same form and order of magnitude. In all other cases the form and amplitude of the gravitational wave power spectrum is markedly different and <b>new</b> <b>techniques</b> <b>are</b> <b>required.</b> Comment: 9 pages, 7 figures; v 2 : references added, very minor changes to text, version accepted by PR...|$|E
40|$|Abstract. Systematic {{computation}} of Stark units over nontotally real base fields {{is carried}} {{out for the first}} time. Since the information provided by Stark’s conjecture is significantly less in this situation than the information provided over totally real base fields, <b>new</b> <b>techniques</b> <b>are</b> <b>required.</b> Precomputing Stark units in relative quadratic extensions (where the conjecture is already known to hold) and coupling this information with the Fincke-Pohst algorithm applied to certain quadratic forms leads to a significant reduction in search time for finding Stark units in larger extensions (where the conjecture is still unproven). Stark’s conjecture is verified in each case for these Stark units in larger extensions and explicit generating polynomials for abelian extensions over complex cubic base fields, including Hilbert class fields, are obtained from the minimal polynomials of these new Stark units. 1...|$|E
40|$|Sustainable Drainage Systems (SuDS) {{have been}} shown to be the {{preferred}} solution in dealing with excess urban flooding compared with traditional drainage methods (Woods-Ballard et al, 2007). Aside from flood prevention and water purification, SuDS also have the potential to offer a variety of other ecosystem services such as climate regulation, recreation, and aesthetic. Traditional SuDS variables do not show the potential of these ecosystem services. Therefore, <b>new</b> <b>techniques</b> <b>are</b> <b>required</b> to examine ecosystem services generation potential of different SuDS systems. The aim is to develop a rapid ecosystem services assessment tool for SuDS. This tool will combine on-site measurements of traditional SuDS variables, along with biodiversity and cultural services variables. Biodiversity is an important variable to many ecosystem services (see Figure 7). The research area will be within the Greater Manchester region...|$|E
40|$|Abstract. While {{traditional}} single-rating recommender {{systems have}} been successful in a number of personalization applications, the research area of multi-criteria recommender systems has been largely untouched. In order {{to take full advantage of}} multi-criteria ratings in various applications, <b>new</b> recommendation <b>techniques</b> <b>are</b> <b>required.</b> In this paper we propose two new approaches – the similarity-based approach and the aggregation function-based approach – to incorporating and leveraging multi-criteria rating information in recommender systems. We also discuss multiple variations of each proposed approach, and perform empirical analysis of these approaches using a real-world dataset. Our experimental results show that multi-criteria ratings can be successfully leveraged to improve recommendation accuracy, as compared to traditional single-rating recommendation techniques...|$|R
40|$|Coral {{bleaching}} {{and mortality}} {{is predicted to}} increase under global climate change. A <b>new</b> observation <b>technique</b> <b>is</b> <b>required</b> to monitor regional coral conditions. To this end, we developed a {{light detection and ranging}} (LIDAR) system installed in a towable buoy for boat observations, which acquires continuous fluorescent images of the seabed during day-time. Most corals have innate fluorescent proteins in their tissue, and they emit fluorescence by ultraviolet excitation. This fluorescence distinguishes living coral from dead coral skeleton, crustose coralline algae, and sea algae. This paper provides a proof of concept for using the LIDAR system and fluorescence to map coral distribution within 1 km scale and coral cover within 100 m scale for a single reef in Japan...|$|R
40|$|This paper {{provides}} lower bounds on {{the energy}} consumption and demonstrates an energy-time trade-off in optical computations. All the lower bounds are shown to have the matching upper bounds for a transitive function – shifting. Since the energy consumption in an optical transmission is a non-linear function of the distance, a <b>new</b> set of <b>techniques</b> <b>was</b> <b>required</b> to derive these lower bounds. We also characterize the energy requirements of 3 -D VLSI computations. ...|$|R
