33|62|Public
50|$|The STC {{number is}} derived from sound {{attenuation}} values tested at sixteen standard frequencies from 125 Hz to 4000 Hz. These Transmission Loss values are then plotted on a sound pressure level graph and the resulting curve is compared to a standard <b>reference</b> <b>contour.</b> Acoustical engineers fit these values to the appropriate TL Curve (or Transmission Loss) to determine an STC rating. The measurement is accurate for speech sounds, but much less so for amplified music, mechanical equipment noise, transportation noise, or any sound with substantial low-frequency energy below 125 Hz. Sometimes, acoustical labs will measure TL at frequencies below the normal STC boundary of 125 Hz, possibly down to 50 Hz or lower, thus giving additional valuable data to evaluate transmission loss at very low frequencies, such as a subwoofer-rich home theater system would produce. Alternatively, Outdoor-Indoor Transmission Class (OITC) is a standard used for indicating the rate of transmission of sound between outdoor and indoor spaces in a structure that considers frequencies down to 80 Hz (Aircraft/Rail/Truck traffic) and is weighted more to lower frequencies.|$|E
40|$|An {{interactive}} {{method for}} segmentation of abdominal aortic aneurysms is presented. After manual segmentation {{of the first}} slice, the method automatically detects the contour in subsequent slices, using the result from previous slices as a reference. If an obtained contour is not correct, the user can intervene and provide an additional manual <b>reference</b> <b>contour...</b>|$|E
40|$|A model-based {{approach}} to interactive segmentation of abdominal aortic aneurysms from CTA data is presented. After manual delineation of the aneurysm sac {{in the first}} slice, the method automatically detects the contour in subsequent slices, using the result from the previous slice as a reference. If an obtained contour is not su#ciently accurate, the user can intervene and provide an additional manual <b>reference</b> <b>contour...</b>|$|E
40|$|PURPOSE: The aim of {{this paper}} is to define the {{requirements}} and describe the design and implementation of a standard benchmark tool for evaluation and validation of PET-auto-segmentation (PET-AS) algorithms. This work follows the recommendations of Task Group 211 (TG 211) appointed by the American Association of Physicists in Medicine (AAPM). METHODS: The recommendations published in the AAPM TG 211 report were used to derive a set of required features and to guide the design and structure of a benchmarking software tool. These items included the selection of appropriate representative data and <b>reference</b> <b>contours</b> obtained from established approaches and the description of available metrics. The benchmark was designed in a way that it could be extendable by inclusion of bespoke segmentation methods, while maintaining its main purpose of being a standard testing platform for newly developed PET-AS methods. An example of implementation of the proposed framework, named PETASset, was built. In this work, a selection of PET-AS methods representing common approaches to PET image segmentation was evaluated within PETASset for the purpose of testing and demonstrating the capabilities of the software as a benchmark platform. RESULTS: A selection of clinical, physical, and simulated phantom data, including "best estimates" <b>reference</b> <b>contours</b> from macroscopic specimens, simulation template, and CT scans was built into the PETASset application database. Specific metrics such as Dice Similarity Coefficient (DSC), Positive Predictive Value (PPV), and Sensitivity (S), were included to allow the user to compare the results of any given PET-AS algorithm to the <b>reference</b> <b>contours.</b> In addition, a tool to generate structured reports on the evaluation of the performance of PET-AS algorithms against the <b>reference</b> <b>contours</b> was built. The variation of the metric agreement values with the <b>reference</b> <b>contours</b> across the PET-AS methods evaluated for demonstration were between 0. 51 and 0. 83, 0. 44 and 0. 86, and 0. 61 and 1. 00 for DSC, PPV, and the S metric, respectively. Examples of agreement limits were provided to show how the software could be used to evaluate a new algorithm against the existing state-of-the art. CONCLUSIONS: PETASset provides a platform that allows standardizing the evaluation and comparison of different PET-AS methods on a wide range of PET datasets. The developed platform will be available to users willing to evaluate their PET-AS methods and contribute with more evaluation datasets...|$|R
40|$|This paper {{discusses}} the trajectory generation algorithm, contour error construction method {{and finally the}} contour controller design. In the trajectory generation algorithm combination of elliptical Fourier descriptors (EFD) and time based spline approximation (TBSA) is used to generate position, velocity and acceleration <b>references.</b> <b>Contour</b> error is constructed using transformation of trajectory tracking errors. Transformation is computationally efficient and requires only <b>reference</b> velocity information. <b>Contour</b> controller is designed using sliding mode control. Experiments are performed on planar linear motion stage and significant contour error reduction is observed...|$|R
40|$|We {{propose a}} method for {{automatically}} setting the foreground detection threshold implicit in background subtraction algorithms by measuring the similarity between {{the shape of a}} detected foreground region and a set of <b>reference</b> <b>contours</b> over a range of thresholds, and selecting the threshold that maximises this similarity measure. This method is shown to select appropriate thresholds for a range of unseen video frames. 1...|$|R
40|$|Object {{recognition}} {{is a very}} interesting task with multiple applications and for that reason it has been dealt with very intensively in the last years. In particular, the application to naval ship pictures may facilitate the work of the coastguards or the navy. However, this type of images entails some difficulties due to their specific environment. Water reflects the light and as a consequence, some areas may presumably show different brightness and color. Waves from wind or moving ships pose a problem due to the additional edges that they produce. The camouflage of ships in the military context is also an issue to take into account. Therefore, it is difficult to propose a simple method that is valid for every image. A discussion about which techniques may solve these problems is presented and finally a combined solution based on contour {{recognition is}} suggested. Test images are preprocessed by histogram stretching. Then, the Canny method is applied to the image and to the <b>reference</b> <b>contour</b> in order to obtain not only their edges, but also their respective orientations. The problem of recognizing the <b>reference</b> <b>contour</b> within the detected edges is addressed by making use of the Generalized Hough Transform (GHT) ...|$|E
40|$|This article {{deals with}} image and video {{segmentation}} using active contours. The proposed variational approachs {{is based on}} a criterion combining geometric prior and statistical features computed on the inside region of the contours. The geometric prior involves a free form deformation from a <b>reference</b> <b>contour</b> as opposed to a parametric transformation. Differentiation of this geometric prior criterion is provided. Introducing such a free form deformation has proven to be beneficial for interactive image segmentation. A tracking application where the geometric prior results from the segmentation of the previous frame is presented...|$|E
40|$|Control of {{prosodic}} characteristics {{is one of}} {{the most}} important problems in the area of speech synthesis. Fujisaki’s model is probably the best model for pitch variations and its inversion is suitable for being integrated within speech synthesizres. This paper proposes a speech synthesis method based on Fujisaki’s model (combined direct and inverse modeling) in order to preserve natural soundness of synthesized speech. The idea is to modify a pitch contour on the basis of Fujisaki’s features and a <b>reference</b> <b>contour.</b> Experimental results have shown that using constraints related to Fujisaki’s model guarantees good natural-sounding speech synthesis. 1...|$|E
40|$|In this paper, {{we propose}} {{to use an}} active contour method to attract active {{surfaces}} towards non-smoothed segmentation masks. To achieve this task, we introduce a new region-based term for active contour segmentation in the multiphase level set framework. This term attracts evolving curves to <b>reference</b> <b>contours</b> while being constrained by rigidity terms. This technique considerably reduces flickering on {{the boundaries of the}} segmentation masks. ...|$|R
40|$|Purpose: To {{investigate}} {{the use of}} non-rigid registration for transforming and fusing data from multiple lung cancer patients into a common spatial reference ("Virtual Patient') in order to perform spatial-based statistics. This allows us to study the eflects ot radiotherapy by comparing the spatial distribution of data such as PET and dose distribution for multiple patients {{with or without a}} complication or a relapse. Furthermore, the reverse transformation can be applied on the <b>reference</b> <b>contours</b> in order to automatically segment the patient anatomy. Materials: CT imaging was performed for 6 lung cancer patients. One patient was taken as reference and the lungs and spinal cord were delineated. The 5 other patients were also delineated for validation purposes. An intensity based affine alignment followed by a log-domain phase-based non-rigid registration were applied on these data, producing for each patient a deformation field representing the transformation from the reference to the patient, and its inverse. For each patient, the tumor was delineated and ignored during the deformation field computation. The direct transformation was used to deform each patient CT towards the reference anatomy. while the inverse transformation was used to deform the <b>reference</b> <b>contours</b> towards the patient anatomy. These contours were compared to manual contours for each patient In order to validate the registration process. Results: CT, PET and dose distribution were successfully deformed towards the reference configuration ("Virtual Patient") using the deformation fields resulting from registration (see Figure 1). After registration, the DICE coefficient, used as a measurement of overlap between deformed <b>reference</b> <b>contours</b> and manual contours of the lungs was of 92 ± 3 % (1 SO). Conclusions: These preliminary results showed that non-rigid registration was able to match accurately the lung <b>contours</b> of the <b>reference</b> with the lung contours of the patients. The resulting transformations can then be used to deform the CT, PET and dose distribution accordingly, in order to transform the individual patient information into a common spatial configuration for performing spatial-based statistical analysis on two populations (e. g. with and without complications) inside two ("Virtual") reference patients summarizing respectively the PET images and dose distribution of patients with and without a complication. This approach allows to "simplify" large complex datasets or randomized trials and to generate new hypotheses...|$|R
40|$|In {{this paper}} we present three methods for the {{automatic}} segmentation of pulmonary regions in X-ray CT images. Before applying any method, each image is pre–processed. The first two methods rely on intensity oriented image processing techniques {{based on the}} mapping between the peaks and valleys of the histogram and groups of organs located in the thoracic region. The second method also uses morphologic filters to remove spurious structures. The third method explores the technique of active contours applied to {{each one of the}} lungs. The resulting contours obtained by each method are qualitatively compared with corresponding <b>reference</b> <b>contours</b> drawn by two expert radiologists...|$|R
40|$|Abstract – Pulmonary {{contours}} in chest CT {{images are}} closed curves that may, in some cases, exhibit multiple concave and convex irregularities. In this paper we assess {{the quality of}} pulmonary contours obtained by several fully automated methods. A comparison among these contours and corresponding manually drawn reference contours was performed and several figures of merit were assigned to {{each one of the}} automated contours extraction algorithms. Likeness between a computed contour and <b>reference</b> <b>contour</b> was measured through the Pratt figure of merit, similarity index, mean error and fraction of errors greater than 5 pixels. For each of these figures we present an exploratory statistical analysis and discuss its sensibility to the longitudinal location of the CT slice...|$|E
40|$|Jupiter's main {{auroral oval}} is {{associated}} with the ionosphere-magnetosphere coupling current system which is related to the breakdown of corotation in the middle magnetosphere. Its auroral footpath is usually represented as a smooth line closing around the pole. However, this simplistic view is misleading in many regards. We have constructed a new <b>reference</b> <b>contour</b> in the northern hemisphere (Figure 1), based on more than 1000 HST/UV images, which does not look like an oval and does not close around the pole. We use this <b>reference</b> <b>contour</b> to quantify the effects of temporal and local time variability of the magnetospheric plasma characteristics on the location of the main auroral emission. Beyond the orbit of Ganymede (15 RJ), two key ingredients are expected to have a measurable influence on the instantaneous shape of the main emission contour: the azimuthal current flowing in the current sheet [1, 2] and the corotation breakdown distance. The former affects the radial extent of the magnetic field lines, and the latter determines the radial location of the field aligned currents transmitting momentum from the planet to the lagging plasma. So far, models used to magnetically map the auroral main emission between the ionosphere and the equatorial plane assumed that these two parameters are constant and axisymmetric. However, in situ observations, mainly by Galileo, have revealed large local time asymmetries and temporal variations in the plasma flows and distribution. These variations {{have an impact on the}} azimuthal current and the distance at which the plasma angular velocity becomes significantly smaller than planetary rotation. We use a new magnetic field model [3], inherited from VIP 4 and including a magnetic anomaly in the northern hemisphere, to simulate the effects of these asymmetries on the location of the main auroral emission, and interpret the large scattering of the corresponding HST data point...|$|E
40|$|The method {{involves}} storing {{a partial}} data set (5) comprising {{data in a}} communication device (4) i. e. transponder, and carrying out group reading of the data stored in the communication device for identification of loading goods (3 a- 3 h), where the data comprises information about position and dimension of the loading goods. A <b>reference</b> <b>contour</b> and an actual contour of a loading unit (1) or loading goods are produced by an optical device i. e. time-of-flight-camera, under usage of the data stored in the communication device, where the reference and actual contours are compared with one another. Independent claims are also included for the following: (1) a reading gate for executing a method for automatic identification of loading goods of loading unit (2) a computer program for a computer device...|$|E
40|$|It {{has been}} {{strongly}} requested to get automatically a precise {{digital elevation model}} from a topographic contour image. But, because of overlapping other symbols, the image usually includes many broken contours. To connect these correctly, a global restoration technique considering states of adjacent contours is needed. In this {{paper we propose a}} new global restoration method using an extended Voronoi diagram that produces a relationship graph of adjacent contours. Based on an idea of <b>reference</b> <b>contours,</b> it determines pairs of broken contours to be connected and interpolates their gaps with spline curves. It can satisfactorily restore broken contours that have been considered difficult to connect...|$|R
40|$|Although echocardiographic image {{segmentation}} {{has been a}} hot topic for long and several methods exist for robust endocardial segmentation, {{little attention has been}} directed to full myocardial segmentation. In fact, full myocardial segmentation is particularly challenging due to the high heterogeneity in the appearance of the epicardial boundary in US images. In the present paper, we propose an extension to the recently introduced Active Geometric Functions segmentation framework in order to cope with data inhomogeneities. This method has been successfully applied to short axis B-mode images acquired in a clinical setting. The mean absolute distance between the algorithm and the <b>reference</b> <b>contours</b> provided by an expert physician is 2. 81 ± 0. 7 pixels. The computation time per frame is around 1 second, in a non-optimized MATLAB implementation, which shows that this method can be extended to achieve realtime performance. status: publishe...|$|R
40|$|This paper investigates ways {{to explore}} the between frame {{correlation}} of shape information {{within the framework of}} an operationally rate-distortion (ORD) optimal coder. Contours are approximated both by connected second-order spline segments, each defined by three consecutive control points, and by segments of the motioncompensated <b>reference</b> <b>contours.</b> Consecutive control points are then encoded predictively using angle and run temporal contexts. We utilize a novel criterion for selecting global object motion vectors, which further improves efficiency. Formulating this problem as Lagrangian minimization, we employ an iterative technique to remove dependency on a particular VLC and jointly arrive at the ORD optimal solution and its underlying conditional parameter distribution. 1. INTRODUCTION In the process of evaluating competing techniques for the MPEG- 4 standard, several binary coders were considered. These coders, however, lack optimality in their both intra and inter modes of ope [...] ...|$|R
40|$|A {{method was}} {{examined}} for joint {{construction of a}} selenocentric fundamental system which can be realized by a coordinate catalog of <b>reference</b> <b>contour</b> points uniformly positioned over the entire lunar surface, and determination of the parameters characterizing the gravitational field, rotation, and orbital motion of the moon. Characteristic of the problem formulation is {{the introduction of a}} new complex of inconometric measurements which can be made using pictures obtained from an artificial lunar satellite. The proposed method can be used to solve similar problems on any other planet for which surface images can be obtained from a spacecraft. Characteristic of the proposed technique for solving the problem is the joint statistical analysis of all forms of measurements: orbital iconometric, earth-based trajectory, and also a priori information on the parameters in question which is known from earth-based astronomical studies...|$|E
40|$|Abstract: Based on the {{extracted}} {{contours of}} objects from images, {{one point to}} point (P 2 P) method is proposed for shape matching and image retrieval. Taking contour of one object as <b>reference,</b> <b>contour</b> of another object is transformed to reach their best match, during which the similarity is evaluated by comparison of two corresponding sets of contour points. Translation, scaling and rotation are all considered in transformation, thus the algorithm is robust to objects with different position, size and posture. The experimental results are presented and compared with those from two popular shape based techniques, Hu invariant moments and Zernike moments. Performance of our new approach has proved its efficiency in both matching accuracy and computational expense, {{and it can be}} used in related applications together with the other kinds of shape features or even color features, texture features, etc...|$|E
40|$|The {{increasing}} {{availability and}} deployment of imaging sensors operating in multiple spectral bands {{has led to}} a large research effort in image fusion, resulting in a plethora of pixel-level image fusion algorithms. However, the cognitive aspects of multisensor image fusion have not received much attention in the development of these methods. In this study we investigate how humans interpret visual and infrared images, and we compare the interpretation of these individual image modalities to their fused counterparts, for different image fusion schemes. This was done in an attempt to test to what degree image fusion schemes can enhance human perception of the structural layout and composition of realistic outdoor scenes. We asked human observers to manually segment the details they perceived as most prominent in a set of corresponding visual, infrared and fused images. For each scene, the segmentations of the individual input image modalities were used to derive a joint reference ("gold standard") contour image that represents the visually most salient details from both of these modalities and for that particular scene. The resulting reference images were then used to evaluate the manual segmentations of the fused images, using a precision-recall measure as the evaluation criterion. In this sense, the best fusion method provides the largest number of correctly perceived details (originating from each of the individual modalities that were used as input for the fusion scheme) and the smallest amount of false alarms (fusion artifacts or illusory details). A comparison with an objective score of subject performance indicates that the <b>reference</b> <b>contour</b> method indeed appears to characterize the performance of observers using the results of the fusion schemes. The results show that this evaluation method can provide valuable insight into the way fusion schemes combine perceptually important details from the individual input image modalities. Given a <b>reference</b> <b>contour</b> image, the method can potentially be used to design image fusion schemes that are optimally tuned to human visual perception for different applications and scenarios (e. g. environmental or weather conditions). © 2009 Elsevier B. V. All rights reserved...|$|E
40|$|We have {{analyzed}} {{more than}} 1000 HST/ACS images of Jupiter’s ultraviolet auroral emission {{in the northern}} hemisphere. A systematic planet center finding algorithm {{made it possible to}} infer reliable and consistent jovicentric location of the auroral footprints of Io, Europa and Ganymede. These footprints form <b>reference</b> <b>contours</b> which provide an absolute magnetic mapping from the ionosphere of Jupiter to the equatorial plane, independent of any magnetic field model. So far, the VIP 4 magnetic field model is the most accurate in terms of fitting the auroral emissions. However, it cannot reproduce the distorted shape of the satellites UV footpaths in the “kink region” in the northern ionosphere between S 3 longitudes 80 ̊- 150 ̊. We show that the model is significantly improved by decreasing the VIP 4 surface magnetic field in the kink region and by adding a localized dipolar perturbation field beneath the surface...|$|R
5000|$|In {{the case}} of a {{function}} [...] considered in terms of relation , <b>reference</b> to the <b>contour</b> sets of the function is implicitly to the contour sets of the implied relation ...|$|R
40|$|Motion {{control is}} an {{essential}} part of industrial machinery and manufacturing systems. In this article, the adaptive fuzzy controller is proposed for precision trajectory tracking control in biaxial X-Y motion stage system. The theoretical analyses of direct fuzzy control which is insensitive to parameter uncertainties and external load disturbances are derived to demonstrate the feasibility to track the reference trajectories. The Lyapunov stability theorem has been used to testify the asymptotic stability of the whole system, and all the signals are bounded in the closed-loop system. The intelligent position controller combines the merits of the adaptive fuzzy control with robust characteristics and learning ability for periodic command tracking of a servo drive mechanism. The simulation and experimental results on square, triangle, star, and circle <b>reference</b> <b>contours</b> are presented to show that the proposed controller indeed accomplishes the better tracking performances with regard to model uncertainties. It is observed that the convergence of parameters and tracking errors can be faster and smaller compared with the conventional adaptive fuzzy control in terms of average tracking error and tracking error standard deviation...|$|R
40|$|This paper {{focuses on}} three key points of {{intonation}} modelling: interpolation of fundamental frequency contour, sentence by sentence parameter extraction and data scarcity. In some cases, they introduce noise and inconsistency on training data reduc-ing {{the performance of}} machine learning techniques. We consider that the F 0 contour is segmented into prosodic units (such as accent groups, minor phrases, etc). Each segment of F 0 contour has a corresponding feature vector with linguistic and non-linguistic components. We propose to face the limitations mentioned above using a technique based on clustering using different feature vector dimensions. The clustering of feature vectors produces also a partition in the F 0 contour space. The proposal consists on a procedure to select the dimension that contributes to predict the best fundamental frequency contour from a RMSE sense com-pared to a <b>reference</b> <b>contour.</b> Experimental results show an im-provement compared to other approaches. 1...|$|E
40|$|This report {{examines}} {{in detail}} {{a family of}} efficacy-toxicity trade-off functions simpler and more general than those originally proposed in [1]. The new trade-off functions are based on distance in Lp norm to the ideal point and were first presented in [2]. We define and illustrate these functions and demonstrate how to compute their parameters based on elicited values. 1 Desirability trade-off functions Let x and y represent posterior mean probabilities of efficacy and toxicity re-spectively. A desirability trade-off function is a function u(x, y) such that u(x, y) > u(x′, y′) {{if and only if}} a treatment with probabilities (x, y) is more desirable than a treatment with probabilities (x′, y′). It follows that u must be an increasing function of x and a decreasing function of y. The efficacy-toxicity tradeoff function given in [1] was constructed by first 1 identifying a <b>reference</b> <b>contour</b> of the form y = a+...|$|E
40|$|Facing data {{scarcity}} using variable {{feature vector}} dimension This paper focuses on three key points of intonation modelling: interpolation of fundamental frequency contour, sentence by sentence parameter extraction and data scarcity. In some cases, they introduce noise and inconsistency on training data reducing {{the performance of}} machine learning techniques. We consider that the F 0 contour is segmented into prosodic units (such as accent groups, minor phrases, etc). Each segment of F 0 contour has a corresponding feature vector with linguistic and non-linguistic components. We propose to face the limitations mentioned above using a technique based on clustering using different feature vector dimensions. The clustering of feature vectors produces also a partition in the F 0 contour space. The proposal consists on a procedure to select the dimension that contributes to predict the best fundamental frequency contour from a RMSE sense compared to a <b>reference</b> <b>contour.</b> Experimental results show an improvement compared to other approaches. 1...|$|E
40|$|A digital {{elevation}} model (DEM) developed from Landsat TM images of a rugged terrain area in north Georgia by automated stereocorrelation techniques yielded an rms error (z), RMSE(z), value of + or - 42 m. Based on the B/H ratio of 0. 18 for the Landsat data, this Z-error corresponds to a planimetric correlation accuracy of about + or - 0. 3 pixels, confirming that precise correlation can be achieved with operational satellite data. Contours at a 100 -m interval interpolated from the DEM show a deviation of + or - 33 m from <b>reference</b> <b>contours</b> obtained from existing 1 : 24, 000 -scale maps. The 28. 5 -m pixel resolution and the weak B/H ratio impose limitations on the accuracy {{that can be achieved}} with Landsat TM data. However, it is anticipated that RMSE(z) values of + or - 10 m or less can be achieved with SPOT- 1 panchromatic stereo images of 10 -m resolution recorded at B/H ratios of 0. 5 to 1. 0. DEMs generated by stereocorrelation techniques can be used to create orthoimages, perspective views, and topographic map products...|$|R
40|$|Introduction: Image-based {{brachytherapy}} for {{cervical cancer}} using MRI has been implemented in Australia and New Zealand. The aims {{of this study}} were to measure variability in High-risk CTV (HR-CTV) delineation and evaluate dosimetric consequences of this. Methods: Nine radiation oncologists, one radiation therapist and two radiologists contoured HR-CTV on 3 T MRI datasets from ten consecutive patients undergoing cervical brachytherapy at a single institution. Contour comparisons were performed using the Dice Similarity Coefficient (DSC) and Mean Absolute Surface Distance (MASD). Two <b>reference</b> <b>contours</b> were created for brachytherapy planning: a Simultaneous Truth and Performance Level Estimation (STAPLE) and a consensus contour (CONSENSUS). Optimized plans (8  Gy) for both these contours were applied to individual participant 2 ̆ 7 s contours to assess D 90 and D 100 coverage of HR CTV. To compare variability in dosimetry, relative standard deviation (rSD) was calculated. Results: Good concordance (mean DSC≥ 0. 7, MASD≤ 5  mm) was achieved in 8 / 10 cases when compared to the STAPLE reference and 6 / 10 cases when compared to the CONSENSUS reference. Greatest variation was visually seen in the cranio-caudal direction. The average mean rSD across all patients was 27...|$|R
40|$|Abstract Background To analyze interfraction {{motion of}} seminal vesicles (SV), and its motion {{relative}} to rectal and bladder filling. Methods and Materials SV and prostate were contoured on 771 daily computed tomography “on rails” scans from 24 prostate cancer patients undergoing radiotherapy. Random and systematic errors for SV centroid displacement were measured {{relative to the}} prostate centroid. Margins required for complete geometric coverage of SV were determined using isotropic expansion of <b>reference</b> <b>contours.</b> SV motion relative to rectum and bladder was determined. Results Systematic error for the SV was 1. 9 [*]mm left-right (LR), 2. 9 [*]mm anterior-posterior (AP) and 3. 6 [*]mm superior-inferior (SI). Random error was 1. 4 [*]mm (LR), 2. 7 [*]mm (AP) and 2. 1 [*]mm (SI). 10 [*]mm margins covered the entire left SV and right SV on at least 90 % of fractions in 50 % and 33 % of patients and 15 [*]mm margins covered 88 % and 79 % respectively. SV AP movement correlated with movement of the most posterior point of the bladder (mean R 2 [*]=[*] 0. 46, SD[*]=[*] 0. 24) and rectal area (mean R 2 [*]=[*] 0. 38, SD[*]=[*] 0. 21). Conclusions Considerable interfraction displacement of SV was observed in this cohort of patients. Bladder and rectal parameters correlated with SV movement. </p...|$|R
40|$|We {{introduce}} an e#cient predictive binary shape coding {{method that}} consists of # 1 # global motion estimation, # 2 # local motion estimation, # 3 # matched segment coding, and # 4 # residual segment coding. Global and local motion estimation use contour pel matching and knowledge of previously reconstructed contours. After motion compensation, we code the one-dimensional <b>reference</b> <b>contour</b> indices of the matched contour positions. The #nal step codes the mismatched contour segments using residual coding. We use a maximum shape distortion tolerance parameter #dmax #, which is zero for lossless coding, for both motion estimation and residual coding. We apply the new shape coding method to MPEG- 4 binary mask test sequences in QCIF and SIF formats {{for a wide range}} of dmax values. The key contribution of our method is in lossy shape coding in which the average coding gain is more than 100 # over generalized di#erential chain coding. The proposed scheme can be applied to MPEG- 4 compliant shape coding and to e#cient shape representation for future MPEG- 7 applications...|$|E
40|$|International {{audience}} Multi-view video plus depth {{is emerging}} as the most flexible format for 3 D video representation, as witnessed by the current standardization efforts by ISO and ITU. In particular, in depth representation, arguably the most important information lies in object contours. As a consequence, an interesting approach consists in performing a lossless coding of object contours, possibly followed by a lossy coding of per-object depth values. In this context, we propose a new technique for lossless coding of object contours, based on the elastic deformation of curves. Using the square-root velocity representation for {{the elements of the}} space of curves, we can model a continuous evolution of elastic deformations between two <b>reference</b> <b>contour</b> curves. An elastically deformed version of the reference contours can be sent to the decoder with a reduced coding cost and used as side information to improve the lossless coding of the actual contour. Experimental results on several multiview video sequences show remarkable gains with respect to the reference techniques and to the state of the art. </p...|$|E
40|$|Lack of {{temporal}} coherence in video segmentation algorithms {{often leads to}} flickering or to discrepancies on the segmentation mask boundaries. Active contour video segmentation algorithms can lead to very smooth segmentation masks when they are defined in three dimensions (two spatial and one temporal). In this paper, we use an active contour method to attract an active surface toward a non-smoothed segmentation mask boundary. This active surface produces a new segmentation mask which is smoother than the first one. To achieve this task, we introduce a new region-based term for active contour segmentation in the variational framework. This term attracts the evolving curve to a <b>reference</b> <b>contour.</b> The energy criterion and the evolution equation are defined in n-dimension and we investigate the particular case of two regions. The use of active surfaces to smooth video segmentation masks {{appears to be a}} very powerful tool for video postprocessing. The resulting masks are smoother than the original ones, the discrepancies of the segmentation masks are removed and the flickering on the boundary of the segmentation masks are considerably reduced. Anglai...|$|E
40|$|To {{validate}} autocontouring software (AS) in {{a clinical}} practice including a two steps delineation quality assurance (QA) procedure. The existing delineation agreement among experts for rectal cancer and the overlap and time criteria {{that have to be}} verified to allow the use of AS were defined. Median Dice Similarity Coefficient (MDSC), Mean slicewise Hausdorff Distances (MSHD) and Total-Time saving (TT) were analyzed. Two expert Radiation Oncologists reviewed CT-scans of 44 patients and agreed the reference-CTV: the first 14 consecutive cases were used to populate the software Atlas and 30 were used as Test. Each expert performed a manual (group A) and an automatic delineation (group B) of 15 Test patients. The delineations were compared with the <b>reference</b> <b>contours.</b> The overlap between the manual and automatic delineations with MDSC and MSHD and the TT were analyzed. Three acceptance criteria were set: MDSC ≥ 0. 75, MSHD ≤ 1 mm and TT sparing ≥ 50 %. At least 2 criteria had to be met, one of which had to be TT saving, to validate the system. The MDSC was 0. 75, MSHD 2. 00 mm and the TT saving 55. 5 % between group A and group B. MDSC among experts was 0. 84. Autosegmentation systems in rectal cancer partially met acceptability criteria with the present version...|$|R
40|$|The {{application}} of a source derivation technique to topographic mapping of the pattern-reversal visual evoked potential is described. Comparisons were made with non-cephalic and common average reference recordings. Source derivation yielded wave forms which were less influenced by activity of reference origin. Source derivation wave forms {{were similar to those}} obtained with common average <b>referencing</b> but <b>contour</b> plots showed less spread of regions of maximal activity in the case of source derivation. It is suggested that source derivation may be useful in further studies of the topography and sources of cerebral evoked potentials...|$|R
5000|$|In {{the case}} of a real-valued {{function}} [...] (whose arguments might or might not be themselves real numbers), <b>reference</b> to the <b>contour</b> sets of the function is implicitly to the contour sets of the relationNote that the arguments to [...] might be vectors, and that the notation used might instead be ...|$|R
