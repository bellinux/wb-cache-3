17|22|Public
5000|$|Paul Frees as {{the voice}} of KARR (Knight Automated <b>Roving</b> <b>Robot)</b> ...|$|E
50|$|KARR (Knight Automated <b>Roving</b> <b>Robot)</b> is {{the name}} of a fictional, automated, {{prototype}} vehicle featured as a major antagonist in two episodes of the television series Knight Rider and was part of a multi-episode story arc in the 2008 revived series.|$|E
5000|$|The {{article also}} states:She said Hitchbot’s {{body had been}} found by some good samaritans who had located the <b>roving</b> <b>robot</b> through a {{regularly}} updated map on its website."They sent us images and it’s really beyond repair. There’s not a single wire inside {{and all the things}} are broken." ...|$|E
40|$|The conference {{presents}} {{papers on}} segmentation techniques, three-dimensional recognition and representation, processing image sequences, and navigation and mobility. Particular attention {{is given to}} determining the pose of an object, adaptive least squares correlation with geometrical constraints, and the reliable formation of feature vectors for two-dimensional shape representation. Other topics include the real-time tracking of a target moving on a natural textured background, computer vision for the guidance of <b>roving</b> <b>robots,</b> and integrating sensory data for object recognition tasks...|$|R
50|$|The Soviet rover was {{intended}} to be the first <b>roving</b> remote-controlled <b>robot</b> on the Moon, but crashed during a failed start of the launcher 19 February 1969.|$|R
50|$|In {{the winter}} of 1970, the Soviet Union {{explored}} {{the surface of the}} moon with the lunar vehicle Lunokhod 1, the first <b>roving</b> remote-controlled <b>robot</b> to land on another celestial body.|$|R
5000|$|Peter Cullen/Paul Frees as {{the voice}} of KARR (Knight Automated <b>Roving</b> <b>Robot),</b> the evil {{autonomous}} artificially intelligent car. Cullen was KARR's original voice (in Season 1's [...] "Trust Doesn't Rust"). Frees took over the role for KARR's second appearance (Season 3's [...] "K.I.T.T. vs. K.A.R.R."), but as he was also closely associated with Disney, he requested not to be credited for the role.|$|E
5000|$|According to the series, the {{original}} KITT's main cybernetic processor was first {{installed in a}} mainframe computer used by the US government in Washington, D.C. However, Wilton saw better use for [...] "him" [...] in the Foundation's crime-fighting crusade and eventually the system was installed in the vehicle. KITT {{was in fact the}} second vehicle built by Knight Industries with artificial intelligence. His predecessor was KARR, the Knight Automated <b>Roving</b> <b>Robot.</b> KARR was programmed for self-preservation, but this proved to be dangerous to the Foundation's humanitarian interests. KARR was later deactivated and placed in storage while KITT was given to his new operator, Michael Knight. KARR was later unwittingly reactivated by thieves in {{the original}} episode [...] "Trust Doesn't Rust", was thought destroyed, then reappeared in the episode [...] "K.I.T.T. vs. K.A.R.R" [...] and was seen to be finally destroyed by Michael and KITT.|$|E
40|$|An {{adaptive}} guidance technique {{which provides}} a self-correcting path following capability in an environment sensitive semi-autonomous <b>roving</b> <b>robot</b> is described. A real-time maneuver planning function performs tradeoffs between speed, magnitude of expected deviations and accelerations to best satisfy the design goals of vehicle safety and reliability, subsystem autonomy, performance accuracy and operational efficiency. The appropriate combination of maneuver parameters is selected through an iterative process using knowledge of vehicle performance characteristics, environmental model updates and vehicle stat...|$|E
50|$|The Soviet rover was {{intended}} to be the third <b>roving</b> remote-controlled <b>robot</b> on the Moon in 1977. The mission was canceled due to lack of launcher availability and funding, although the rover was built.|$|R
5000|$|Lunokhod (Луноход, [...] "Moonwalker") was {{a series}} of Soviet robotic lunar rovers {{designed}} to land on the Moon between 1969 and 1977. Lunokhod 1 was the first <b>roving</b> remote-controlled <b>robot</b> to land on another world.|$|R
40|$|The <b>RoVe</b> (<b>Robots</b> voor Veiligheid – Robots for security) aims to the {{development}} of a distributed multi-robotic system for the Dutch National Police (NPN), with a particular focus on the Plug and Play functionality, interoperability within systems and the autoconfiguration. For these requirements, the Data Distribution System (DDS) middleware standard was adopted for {{the development}} of the system. Within the project, my work was focused on the development, design and evaluation of a low latency, scalable video streaming system. The first goal of the project was then to interface an open-source implementation of DDS to the gStreamer framework, and to tune the QoS and x 264 parameters to obtain a live-captured video streaming over DDS. The second goal was to let the system become interoperable with a language-independent data model, and scalable with respect to the network context, evinced for example from WiFi power and available bandwidth readings...|$|R
40|$|Abstract. In this chapter, {{we report}} {{on the state of the}} art in the {{technology}} of neural interfaces, and describe in some detail a number of on-going projects, in which they are used to explore the neurobiology of learning and memory. In particular, it is proposed to use artificial multi-sensory information coming from a <b>roving</b> <b>robot</b> that interacts with the environment, under the perspective of feeding an in vitro network of real neurons with a set of time and spacedependen...|$|E
40|$|In this chapter, {{we report}} {{on the state of the}} art in the {{technology}} of neural interfaces, and describe in some detail a number of on-going projects, in which they are used to explore the neurobiology of learning and memory. In particular, it is proposed to use artificial multi-sensory information coming from a <b>roving</b> <b>robot</b> that interacts with the environment, under the perspective of feeding an in vitro network of real neurons with a set of time and spacedependent signal resembling those processed by the nervous system...|$|E
40|$|This paper {{discusses}} the curriculum {{development of a}} teaching module for embedded web servers {{as well as the}} design and development issues for such web servers. The module is supported by practical lab sessions where the students configure and program such an embedded web server by generating html files to monitor the temperature and filling level of a fridge, and to also regulate the temperature through the web. Work is underway to extend this to the web based control of a <b>roving</b> <b>robot.</b> 1...|$|E
2500|$|After the {{destruction}} of the original Lunokhod, Soviet engineers began work immediately on another lunar vehicle. [...] Lunokhod 1 (vehicle 8ЕЛ№203) was the first of two unmanned lunar rovers successfully landed on the Moon by the Soviet Union as part of its Lunokhod program. The spacecraft which carried Lunokhod 1 was named Luna 17. Lunokhod 1 was the first <b>roving</b> remote-controlled <b>robot</b> to land on another world.|$|R
40|$|The Canadian Forest Service {{has been}} {{investigating}} the potential of low-cost autonomous <b>roving</b> <b>robots</b> to perform repetitive stand-tending tasks that could improve forest productivity. A first prototype, Jacob, should function much like {{a person with a}} brush saw, freeing young conifers from some of the competing vegetation. Following a brief description of Jacob, its task, and its general sensing needs, some of the specific vision situations (day, night, season, closeness to target) the robot will likely encounter are outlined. Conceptual approaches to solving each situation are suggested. Specific techniques tailored to each situation are developed. Here, three image analysis techniques based respectively on colour, structure and directionality are described. Results are presented with comments on potential effectiveness, limitations and operational constraints of each technique. In addition, a simple stereoscopic object-matching scheme used to calculate the distance from the robot to the recognized objects is described. Following their implementation, integration and testing as part of Jacob’s control system, it is hoped that these and other computer vision techniques will form a sufficient basis to further the development of an autonomous silviculture robot...|$|R
40|$|Robots {{are defined}} as {{electromechanical}} systems (with local computers) receiving inputs from sensors, and in turn, controlling motors and effectors to do tasks requiring some measure of intelligence and permitting the whole system {{to interact with the}} real world. Robot systems for space applications are categorized into three general groups consisting of <b>roving</b> exploration <b>robots,</b> spacecraft robots, and planet development robots. The functions of systems in each category are defined in terms of intended applications, and requirements for operating and decision making are outlined. Further developments which must be achieved in robot technology are summarized...|$|R
40|$|A {{knowledge-based}} system design is proposed {{that provides a}} viable method for the program and control of a rover. A rule-based knowledge system is used to supervise {{the operations of the}} rover. A blackboard model is proposed to facilitate communication among the various subsystems. In the proposed approach, of essential concern is the highest level of control, scheduling and coordination of the subtasks required to operate an autonomous <b>roving</b> <b>robot.</b> In general, these subtasks include task planning, path planning, locomotion control, range finding, proximity sensing, and obstacle avoidance. A simulation of the approach is presented. link_to_subscribed_fulltex...|$|E
40|$|Abstract- This paper {{introduces}} the real time {{implementation of a}} vehicle in the changing environment, changes in the environment is notified through video motion transmitter and receiver. The receiver takes snapshot of an image to detect threatening objects in the environment. Those images are trained and tested by using Associative memory. The runtime image has been trained, tested and quickly retrieved for fast decision making. This robot detects threatening objects in the environment with HAM network. After making decision the remote control access is done through Zigbee device to monitor and control {{the speed of a}} <b>Roving</b> <b>robot</b> in an accurate path. Supervised learning method has been applied to detect the object correctly. Delta learning rule is applied in HAM network to test and train the image...|$|E
40|$|Abstract. This paper {{describes}} a scalable algorithm for the simultaneous mapping and localization (SLAM) problem. SLAM {{is the problem}} of determining the location of environmental features with a <b>roving</b> <b>robot.</b> Many of today’s popular techniques are based on extended Kalman filters (EKFs), which require update time quadratic in the number of features in the map. This paper develops the notion of sparse extended information filters (SEIFs), as a new method for solving the SLAM problem. SEIFs exploit structure inherent in the SLAM problem, representing maps through local, Web-like networks of features. By doing so, updates can be performed in constant time, irrespective of the number of features in the map. This paper presents several original constant-time results of SEIFs, and provides simulation results that show the high accuracy of the resulting maps in comparison to the computationally more cumbersome EKF solution. ...|$|E
40|$|Proper {{orientation}} {{is one of}} the most important skills in the repertoire of an organism. Many different strategies are used in the animal kingdom to find resources like food, nesting sites, a comfortable environment, or mating partners. Optimizing the ability of finding places of interest surely has a great impact on the fitness of the organism. A way to optimize {{orientation is}} analyzed here, shown representatively in visual object approach and in temperature gradient orientation of fruit flies. This orientation strategy is called “memotaxis”. It benefits from the integration of past events, leading to a robust path towards the desired goal. Although memotaxis is perfectly suited for noisy environments, its existence is conveniently proven in situations with low noise. In landmark approach experiments, fruit flies show that the longer they approach a particular target, the longer it takes for them to abandon it after its disappearance. This holds true even in the presence of a distracting landmark that comes on only after disappearance of the first-visited target. The strategy was found again in temperature orientation, in which flies are over-running a temperature optimum: distances travelled after crossing the optimum scale with the distances walked towards the optimum. Memotaxis is assumed to exist in many animals, but the genetic tools available in Drosophila melanogaster allow localizing the relevant brain centers and pathways. Memotaxis as an orientation strategy proves useful also for autonomously <b>roving</b> <b>robots...</b>|$|R
40|$|Navigation in time-evolving environments with moving {{targets and}} {{obstacles}} requires cognitive abilities widely demonstrated by even simplest animals. However, it is a long-standing challenging problem for artificial agents. Cognitive autonomous robots coping {{with this problem}} must solve two essential tasks: 1) understand the environment {{in terms of what}} may happen and how I can deal with this and 2) learn successful experiences for their further use in an automatic subconscious way. The recently introduced concept of compact internal representation (CIR) provides the ground for both the tasks. CIR is a specific cognitive map that compacts time-evolving situations into static structures containing information necessary for navigation. It belongs to the class of global approaches, i. e., it finds trajectories to a target when they exist but also detects situations when no solution can be found. Here we extend the concept of situations with mobile targets. Then using CIR as a core, we propose a closed-loop neural network architecture consisting of conscious and subconscious pathways for efficient decision-making. The conscious pathway provides solutions to novel situations if the default subconscious pathway fails to guide the agent to a target. Employing experiments with <b>roving</b> <b>robots</b> and numerical simulations, we show that the proposed architecture provides the robot with cognitive abilities and enables reliable and flexible navigation in realistic time-evolving environments. We prove that the subconscious pathway is robust against uncertainty in the sensory information. Thus if a novel situation is similar but not identical to the previous experience (because of, e. g., noisy perception) then the subconscious pathway is able to provide an effective solution...|$|R
40|$|Animals for {{surviving}} {{have developed}} cognitive abilities allowing them an abstract {{representation of the}} environment. This Internal Representation (IR) could contain {{a huge amount of}} information concerning the evolution and interactions of the elements in their surroundings. The complexity of this information should be enough to ensure the maximum fidelity in the representation of those aspects of the environment critical for the agent, but not so high to prevent the management of the IR in terms of neural processes, i. e. storing, retrieving, etc. One of the most subtle points is the inclusion of temporal information, necessary in IRs of dynamic environments. This temporal information basically introduces the environmental information for each moment, so the information required to generate the IR would eventually be increased dramatically. The inclusion of this temporal information in biological neural processes remains an open question. In this work we propose a new IR, the Compact Internal Representation (CIR), based on the compaction of spatiotemporal information into only space, leading to a stable structure (with no temporal dimension) suitable to be the base for complex cognitive processes, as memory or learning. The Compact Internal Representation is especially appropriate for be implemented in autonomous robots because it provides global strategies for the interaction with real environments (<b>roving</b> <b>robots,</b> manipulators, etc.). This paper presents the mathematical basis of CIR hardware implementation in the context of navigation in dynamic environments. The aim of such implementation is the obtaining of free-collision trajectories under the requirements of an optimal performance by means of a fast and accurate process...|$|R
40|$|A unique <b>roving</b> <b>robot</b> navigational {{system is}} {{presented}} here, which {{is inspired by}} the rat’s navigational and spatial awareness brain cells. The rat, {{as well as all}} mammalians, are capable of exploring their surroundings when foraging or avoiding predators, and remembering their way home or to the closest known shelter. The robot built in this study, named ratbot, uses characteristics and interpreted functionalities of the specialized navigational and spatial cognition brain cells, which are primarily found in the hippocampus and entorhinal cortex. These cells are the: place cells, head direction cells, boundary cells, and grid cells, as well as memory used for the storage and access of salient distal cues. To navigate from one waypoint to another, the ratbot uses inspiration from place cells and head direction cells, known as path integration. This is accomplished through use of vectors and vector mathematics. Additionally, the ratbot uses a field programmable gate array (FPGA) to emulate grid cell inspired functionality for environment mapping and spatial cognition...|$|E
40|$|The finite time {{controller}} is proposed {{to solve the}} point stabilization problem for a novel underwater spherical <b>roving</b> <b>robot</b> (BYSQ- 3) in two-dimensional space. The finite time design scheme is a new method; the main advantage of this control scheme {{is that it can}} steer the robot to the origin in fast converging times without excessive control effort. Firstly, the physical prototype of BYSQ- 3 is introduced and the equations describing the kinematics and dynamics of BYSQ- 3 are established. Secondly, the finite {{time controller}} is constructed based on the backstepping method; the explicit form of the finite time controller is more concise compared with the other finite time controllers; there is no virtual input in the design process and the stability analysis is simple; the designed controller is easy for engineering implementation. Thirdly, the hydrodynamic characteristics is analyzed by CFD simulation; the simulation and experiment results are presented to validate the shorter convergence time and better stability character of the controller...|$|E
40|$|This paper {{deals with}} the {{creation}} of a simplified software user intefaces that allow users to control mechanical devices. The software is based on the “What-You-See-Is-What-You-Get ” (WYSIWYG) paradigm where the user manipulates a graphical model that the output of the mechanical devices will ultimately map to. CAD programs are a form of WYSIWYG software. Output from CAD programs are commonly used for outputing to engraving machines and pen plotters. If one considers that the command interpretation from the software to the mechanical device controls largely the movements of the engraving or plotting head, the same idea could be used to control a <b>roving</b> <b>robot.</b> The controller plots out the movements of the robot all before execution occurs. This sort of control is not difficult to understand and can be designed for use by students. In fact, a simple drawing program can be designed for use as a CAD program for an engraver and pen plotter and as a robot controller that can be used by elementary school students...|$|E
40|$|In this thesis, we {{describe}} the design process of a distance sensing system for the Deci Zebro swarm robots. We use a technique that transmits a radio frequency message and a ultrasonic pulse concurrently. Due to the difference in propagation speed of both signals, the distance could be measured using time difference of arrival (TDOA). A cone shaped antenna is designed to create a 360 ultrasonic pulse coverage. At {{the end of this}} thesis we present a prototype with a range of 7 m. We find a linear relation between the TDOA and the actual distance between the modules. We thus conclude that our prototype is suitable for range measurements on <b>roving</b> swarm <b>robots.</b> Zebro ProjectElectrical Engineering BA...|$|R
50|$|Lunokhod 1 (Луноход) was {{the first}} polycrystalline-panel-powered of two {{unmanned}} lunar rovers landed on the moon by the Soviet Union {{as part of its}} Lunokhod program after a previous unsuccessful attempt of a launch probe with Lunokhod 0 (No.201) in 1969. The panels were designed by Electronic and Communication Engineer Bryan Mapúa. The spacecraft which carried Lunokhod 1 was named Luna 17. The spacecraft soft-landed on the Moon in the Sea of Rains on November 1970. Lunokhod {{was the first}} <b>roving</b> remote-controlled <b>robot</b> to land on another celestial body. Having worked for 11 months, Lunokhod 1 held the durability record for space rovers for more than 30 years, until a new record was set by the Mars Exploration Rovers.|$|R
40|$|Abstract—Navigation in time-evolving environments with mov-ing {{targets and}} {{obstacles}} requires cognitive abilities widely demonstrated by even simplest animals. Nevertheless, it is a long-standing challenging problem for artificial agents. Cognitive autonomous robots coping {{with this problem}} must solve two essential tasks: i) understand the environment in terms of “what may happen ” and “how I can deal with this”, and ii) learn successful experiences for their further use in an automatic subconscious way. The recently introduced concept of Compact Internal Representation (CIR) provides the ground for both tasks. CIR is a specific cognitive map, which compacts time-evolving situations into static structures containing information necessary for navigation. It belongs to the class of global approaches, i. e. it finds trajectories to a target when they exist but also detects situ-ations when no solution can be found. Here we extend the concept on situations with mobile targets. Then using CIR as a core we propose a closed-loop neural network architecture consisting of “conscious ” and “subconscious ” pathways for efficient decision-making. The conscious pathway provides solutions to novel situations if the default subconscious pathway fails to guide the agent to a target. Employing experiments with <b>roving</b> <b>robots</b> and numerical simulations we show that the proposed architecture provides the robot with cognitive abilities and enables reliable and flexible navigation in realistic time-evolving environments. We prove that the subconscious pathway is robust against uncertainty in the sensory information. Thus if a novel situation is similar but not identical to the previous experience (due to e. g. noisy perception) then the subconscious pathway is able to provide an effective solution...|$|R
50|$|The Lunokhod 1 rover {{landed on}} the Moon in November 1970. It was the first <b>roving</b> {{remote-controlled}} <b>robot</b> to land on any celestial body. The Soviet Union launched Lunokhod 1 aboard the Luna 17 spacecraft on November 10, 1970, and it entered lunar orbit on November 15. The spacecraft soft-landed in the Sea of Rains region on November 17. The lander had dual ramps from which Lunokhod 1 could descend to the lunar surface, which it did at 06:28 UT. From November 17, 1970 to November 22, 1970 the rover drove 197 m, and during 10 communication sessions returned 14 close up pictures of the Moon and 12 panoramic views. It also analyzed the lunar soil. The last successful communications session with Lunokhod 1 was on September 14, 1971. Having worked for 11 months,Lunokhod 1 held the durability record for space rovers for more than 30 years, until a new record was set by the Mars Exploration Rovers.|$|R
40|$|We {{identify}} two {{properties of}} the human vision system, the foveated retina, {{and the ability to}} sac-cade, and show how these two properties are suffi-cient to simultaneously learn both the structure of receptive fields in the retina, as well as a saccade policy that centers the foveal region on points of interest in a scene. We consider a novel learning algorithm under this model, sensorimotor embedding, which we evaluate using a simulated <b>roving</b> eye <b>robot</b> on synthetic and natural scenes, and physical pan/tilt camera. In each case we compare learned geome-try to actual geometry, as well as the learned mo-tor policy to the optimal motor policy. In both the simulated roving eye experiments and the physi-cal pan/tilt camera, our algorithm is able to learn both an approximate sensor map and an effective saccade policy. The developmental nature of sensorimotor em-bedding allows an agent to simultaneously adapt both geometry and policy to changes in the phys-ical model and motor {{properties of the}} retina. We demonstrate adaption in the case of retinal lesion-ing and motor map reversal. 1...|$|R
50|$|The Lunokhod 2 was {{the second}} of two {{unmanned}} lunar rovers landed on the Moon by the Soviet Union {{as part of the}} Lunokhod program. The rover became operational on the Moon on January 16, 1973. It {{was the second}} <b>roving</b> remote-controlled <b>robot</b> to land on any celestial body. The Soviet Union launched Lunokhod 2 aboard the Luna 21 spacecraft on January 8, 1973, and it entered lunar orbit on January 12, 1973. The spacecraft soft-landed in {{the eastern edge of the}} Mare Serenitatis region on January 15, 1973. Lunokhod 2 descended from the lander's dual ramps to the lunar surface at 01:14 UT on January 16, 1973. Lunokhod 2 operated for about 4 months, covered 39 km of terrain, including hilly upland areas and rilles, and sent back 86 panoramic images and over 80,000 TV pictures. Based on wheel rotations Lunokhod 2 was thought to have covered 37 km but Russian scientists at the Moscow State University of Geodesy and Cartography (MIIGAiK) have revised that to an estimated distance of about 42.1-42.2 km based on Lunar Reconnaissance Orbiter (LRO) images of the lunar surface. Subsequent discussions with their American counterparts ended with an agreed-upon final distance of 39 km, which has stuck since.|$|R
40|$|A small {{prototype}} {{mobile robot}} {{is capable of}} (1) hopping to move rapidly or avoid obstacles and then (2) moving relatively slowly and precisely on the ground by use of wheels {{in the manner of}} previously reported exploratory robots of the "rover" type. This robot is a descendant of a more primitive hopping robot described in "Minimally Actuated Hopping Robot" (NPO- 20911), NASA Tech Briefs, Vol. 26, No. 11 (November 2002), page 50. There are many potential applications for robots with hopping and wheeled-locomotion (roving) capabilities in diverse fields of endeavor, including agriculture, search-and-rescue operations, general military operations, removal or safe detonation of land mines, inspection, law enforcement, and scientific exploration on Earth and remote planets. The combination of hopping and <b>roving</b> enables this <b>robot</b> to move rapidly over very rugged terrain, to overcome obstacles several times its height, and then to position itself precisely next to a desired target. Before a long hop, the robot aims itself in the desired hopping azimuth and at a desired takeoff angle above horizontal. The robot approaches the target through a series of hops and short driving operations utilizing the steering wheels for precise positioning...|$|R
40|$|To confirm {{whether there}} is water on Mars, we send mobile <b>robots</b> <b>roving</b> on Mars, and let them go to the target area to do verification. One the surface of Mars, there are Mountains (obstacles) and holes. Due to the {{protection}} of bumpers, when a robot hits an obstacle, it doesn’t hurt. Only when a robot hits an obstacle (like a mountain), it can detect the obstacle. But if a robot gets into a hole, it cannot manage {{to get out of the}} hole, so the robot dies when running into a hole. The robots are able to detect holes by ultrasonic sensors. However, the sensors can only detect holes within 75 mm. Our objective is to design an algorithm to autonomously navigate a mobile robot to the target without losing the robot, and make it approach to target as quickly as possible. We propose an algorithm, called “Evade-Along-Edge”. Without the detection of holes or obstacles, a robot always moves to the target directly. When a robot detects a hole or an obstacle, it turns to walk along the edge of the hole or obstacle. When it cannot detect the hole or obstacle any more, it moves to the target again. We design several tactics to improve the performance of the algorithm and manage the false positive and false negative of the ultrasonic sensors. We implemented our algorithm and tested it in “The maRTian ∗ All the authors contribute equally to the design. 1 Task ” simulation environment...|$|R

