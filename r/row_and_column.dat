1681|10000|Public
5|$|Although {{there exist}} {{polynomial}} time algorithms {{to find a}} matrix having given <b>row</b> <b>and</b> <b>column</b> sums, the solution may be far from unique: any submatrix {{in the form of}} a 22 identity matrix can be complemented without affecting the correctness of the solution. Therefore, researchers have searched for constraints on the shape to be reconstructed that can be used to restrict the space of solutions. For instance, one might assume that the shape is connected; however, testing whether there exists a connected solution is NP-complete. An even more constrained version that is easier to solve is that the shape is orthogonally convex: having a single contiguous block of squares in each <b>row</b> <b>and</b> <b>column.</b>|$|E
25|$|The {{resulting}} matrix is singular, so its determinant is zero. However, deleting the <b>row</b> <b>and</b> <b>column</b> for an arbitrarily chosen vertex {{leads to}} a smaller matrix whose determinant is exactlyt(G).|$|E
25|$|If the row, or the column, or both, are ≡ 1 (mod 4) {{the entry}} is blue or green; if both <b>row</b> <b>and</b> <b>column</b> are ≡ 3 (mod 4), it is yellow or orange.|$|E
5000|$|Totally four {{combinations}} are provided1) <b>Row</b> locked <b>and</b> <b>Column</b> locked2) <b>Row</b> unlocked <b>and</b> <b>Column</b> locked3) <b>Row</b> locked <b>and</b> <b>Column</b> unlocked4) <b>Row</b> unlocked <b>and</b> <b>Column</b> unlocked ...|$|R
50|$|For biclusters with {{coherent}} {{values on}} <b>rows</b> <b>and</b> <b>columns,</b> an overall {{improvement over the}} algorithms for biclusters with constant values on rows or on columns should be considered. That means a sophisticated algorithm is needed. This algorithm may contain analysis of variance between groups, using co-variance between both <b>rows</b> <b>and</b> <b>columns.</b> In Cheng <b>and</b> Church's theorem, a bicluster {{is defined as a}} subset of <b>rows</b> <b>and</b> <b>columns</b> with almost the same score. The similarity score is used to measure the coherence of <b>rows</b> <b>and</b> <b>columns.</b>|$|R
5000|$|The Jacobsthal matrix Q for GF(q) is the q×q matrix with <b>rows</b> <b>and</b> <b>columns</b> indexed by finite field {{elements}} {{such that the}} entry in <b>row</b> a <b>and</b> <b>column</b> b is χ(a − b). For example, in GF(7), if the <b>rows</b> <b>and</b> <b>columns</b> of the Jacobsthal matrix are indexed by the field elements 0, 1, 2, 3, 4, 5, 6, then ...|$|R
25|$|Let H be an Hadamard {{matrix of}} order 4m in {{standardized}} form (first <b>row</b> <b>and</b> <b>column</b> entries are all +1). Delete {{the first row}} and take the transpose to obtain the desired orthogonal array.|$|E
25|$|This method {{can also}} be used to {{calculate}} a result, if you make the table in such a way that you can conveniently and reliably rearrange the order of the candidates on both <b>row</b> <b>and</b> <b>column</b> (use the same order on both at all times).|$|E
25|$|The <b>row</b> <b>and</b> <b>column</b> indices (shown {{across the}} top, {{and down the}} left side of the Karnaugh map) are ordered in Gray code rather than binary {{numerical}} order. Gray code ensures that only one variable changes between each pair of adjacent cells. Each cell of the completed Karnaugh map contains a binary digit representing the function's output for that combination of inputs.|$|E
50|$|A {{spreadsheet}} {{is essentially}} a grid made up of <b>rows</b> <b>and</b> <b>columns.</b> New <b>rows</b> <b>and</b> <b>columns</b> can be inserted into a workbook with existing content. Row insertion pushes all the content below it down. Column insertion pushes content after it to the right.|$|R
40|$|Shannon’s {{calculation}} {{of the number of}} crosswords assumed that the <b>rows</b> <b>and</b> <b>columns</b> of crosswords contain typical strings from the language. However, in most languages, most crosswords will have <b>rows</b> <b>and</b> <b>columns</b> that are atypical. This atypicality modifies {{the way in which we}} count the number of crosswords. ...|$|R
5000|$|With the {{exception}} of the identity matrix, an idempotent matrix is singular; that is, its number of independent <b>rows</b> (<b>and</b> <b>columns)</b> is less than its number of <b>rows</b> (<b>and</b> <b>columns).</b> This can be seen from writing , assuming that [...] has full rank (is non-singular), and pre-multiplying by [...] to obtain [...]|$|R
25|$|The {{sampling}} theorem {{is usually}} formulated for functions {{of a single}} variable. Consequently, the theorem is directly applicable to time-dependent signals and is normally formulated in that context. However, the sampling theorem can be extended in a straightforward way to functions of arbitrarily many variables. Grayscale images, for example, are often represented as two-dimensional arrays (or matrices) of real numbers representing the relative intensities of pixels (picture elements) located at the intersections of <b>row</b> <b>and</b> <b>column</b> sample locations. As a result, images require two independent variables, or indices, to specify each pixel uniquely—one for the row, {{and one for the}} column.|$|E
25|$|In Italy, crosswords {{are usually}} oblong and larger than French ones, 13×21 being a common size. As in France, they usually are not symmetrical; two-letter words are allowed; {{and the number}} of shaded squares is minimized. Nouns (including surnames) and the infinitive or past participle of verbs are allowed, as are abbreviations; in larger crosswords, it is {{customary}} to put {{at the center of the}} grid phrases made of two to four words, or forenames and surnames. A variant of Italian crosswords does not use shaded squares: words are delimited by thickening the grid. Another variant starts with a blank grid: the solver must insert both the answers and the shaded squares, and Across and Down clues are either ordered by <b>row</b> <b>and</b> <b>column</b> or not ordered at all.|$|E
25|$|A cycle graph {{of length}} {{four or five}} is well-covered: in each case, every maximal {{independent}} set has size two. A cycle of length seven, and a path of length three, are also well-covered. Every complete graph is well-covered: every maximal independent set consists of a single vertex. Similarly, every cluster graph (a disjoint union of complete graphs) is well-covered. A complete bipartite graph is well covered if {{the two sides of}} its bipartition have equal numbers of vertices, for these are its only two maximal independent sets. A rook's graph is well covered: if one places any set of rooks on a chessboard so that no two rooks are attacking each other, it is always possible to continue placing more non-attacking rooks until there is one on every <b>row</b> <b>and</b> <b>column</b> of the chessboard.|$|E
50|$|Likewise, {{additional}} {{reference grid}} <b>rows</b> <b>and</b> <b>columns</b> are inserted ±32 pixels from the center, making a 12-layer symbol 67×67 pixels. In this case, the 12th layer occupies rings ±31 and ±33 pixels from the center. The pattern continues indefinitely outward, with 15-pixel {{blocks of data}} separated by <b>rows</b> <b>and</b> <b>columns</b> of the reference grid.|$|R
2500|$|Specifically, {{to compute}} t(G), one {{constructs}} a square matrix {{in which the}} <b>rows</b> <b>and</b> <b>columns</b> are both indexed by the vertices of G. The entry in <b>row</b> i <b>and</b> <b>column</b> j {{is one of three}} values: ...|$|R
30|$|M and N are {{the number}} of <b>rows</b> <b>and</b> <b>columns</b> both images.|$|R
500|$|For large (R,C), {{the method}} of Kevin Kilfoil (generalised method:) is used to {{estimate}} the number of grid completions. The method asserts that the Sudoku <b>row</b> <b>and</b> <b>column</b> constraints are, to first approximation, conditionally independent given the box constraint. Omitting a little algebra, this gives the Kilfoil-Silver-Pettersen formula: ...|$|E
500|$|Improving several {{previous}} solutions, [...] {{showed how}} to reconstruct connected orthogonally convex shapes efficiently, using 2-SAT. The idea of {{their solution is}} to guess the indexes of rows containing the leftmost and rightmost cells of the shape to be reconstructed, and then {{to set up a}} 2-satisfiability problem that tests whether there exists a shape consistent with these guesses and with the given <b>row</b> <b>and</b> <b>column</b> sums. They use four 2-satisfiability variables for each square that might be part of the given shape, one to indicate whether it belongs to each of four possible [...] "corner regions" [...] of the shape, and they use constraints that force these regions to be disjoint, to have the desired shapes, to form an overall shape with contiguous rows and columns, and to have the desired <b>row</b> <b>and</b> <b>column</b> sums. Their algorithm takes time [...] where [...] is the smaller of the two dimensions of the input shape and [...] is the larger of the two dimensions. [...] The same method was later extended to orthogonally convex shapes ...|$|E
500|$|The size {{ordering}} of Sudoku puzzle {{can be used}} to define an integer series, e.g. for square Sudoku, the integer series of possible solutions [...] Sudoku with square N×N regions are more symmetrical than immediately obvious from the One Rule. Each <b>row</b> <b>and</b> <b>column</b> intersects N regions and shares N cells with each. The number of bands and stacks also equals N. Rectangular Sudoku do not have these properties. The [...] "3×3" [...] Sudoku is additionally unique: N is also the number of row-column-region constraints from the One Rule (i.e. there are N=3 types of units). See the Glossary of Sudoku for an expanded list of variants.|$|E
40|$|AbstractWe study subpolytopes Ωn(d) of the Birkhoff polytope Ωn of doubly {{stochastic}} matrices {{of order}} n whose <b>rows</b> <b>and</b> <b>columns</b> (or just one row {{or just the}} main diagonal) are majorized by a given stochastic vector d. In addition, we consider the (not necessarily convex) set Ωn*(d) of matrices in Ωn whose <b>rows</b> <b>and</b> <b>columns</b> majorize d...|$|R
40|$|This chapter reviews {{some basic}} matrix algebra {{concepts}} {{that we will}} use throughout the book. Updated: August 15, 2013. 1. 1 Matrices and Vectors A matrix is just an array of numbers. The dimension of a matrix is deter-mined {{by the number of}} its <b>rows</b> <b>and</b> <b>columns.</b> For example, a matrix A with <b>rows</b> <b>and</b> <b>columns</b> is illustrated below...|$|R
50|$|The {{algorithm}} is called lexicographic breadth-first search because the order it produces is an ordering that {{could also have}} been produced by a breadth-first search, and because if the ordering is used to index the <b>rows</b> <b>and</b> <b>columns</b> of an adjacency matrix of a graph then the algorithm sorts the <b>rows</b> <b>and</b> <b>columns</b> into lexicographical order.|$|R
500|$|Memory cells (blue squares in the illustration) {{are further}} {{organized}} into matrices and addressed through rows and columns. [...] A memory address {{applied to a}} matrix is broken into the row address and column address, which are processed by the <b>row</b> <b>and</b> <b>column</b> address decoders (in the illustration, vertical and horizontal green rectangles, respectively). [...] After a row address selects the row for a read operation (the selection {{is also known as}} row activation), bits from all cells in the row are transferred into the sense amplifiers that form the row buffer (red squares in the illustration), from which the exact bit is selected using the column address. [...] Consequently, read operations are of a destructive nature because the design of DRAM requires memory cells to be rewritten after their values have been read by transferring the cell charges into the row buffer. [...] Write operations decode the addresses in a similar way, but {{as a result of the}} design entire rows must be rewritten for the value of a single bit to be changed.|$|E
500|$|A {{part of a}} solver {{for full}} nonogram puzzles, [...] used 2-satisfiability to combine {{information}} obtained from several other heuristics. Given a partial solution to the puzzle, they use dynamic programming within each row or column {{to determine whether the}} constraints of that row or column force any of its squares to be white or black, and whether any two squares in the same row or column can be connected by an implication relation. They also transform the nonogram into a digital tomography problem by replacing the sequence of block lengths in each <b>row</b> <b>and</b> <b>column</b> by its sum, and use a maximum flow formulation to determine whether this digital tomography problem combining all of the rows and columns has any squares whose state can be determined or pairs of squares that can be connected by an implication relation. If either of these two heuristics determines the value of one of the squares, it is included in the partial solution and the same calculations are repeated. However, if both heuristics fail to set any squares, the implications found by both of them are combined into a 2-satisfiability problem and a 2-satisfiability solver is used to find squares whose value is fixed by the problem, after which the procedure is again repeated. This procedure may or may not succeed in finding a solution, but it is guaranteed to run in polynomial time. Batenburg and Kosters report that, although most newspaper puzzles do not need its full power, both this procedure and a more powerful but slower procedure which combines this 2-satisfiability approach with the limited backtracking of [...] are significantly more effective than the dynamic programming and flow heuristics without 2-satisfiability when applied to more difficult randomly generated nonograms.|$|E
2500|$|Each symbol occurs exactly once in each <b>row</b> <b>and</b> <b>column</b> of the array, and ...|$|E
5000|$|The {{detailed}} {{definition is}} as follows. A square matrix B of size n is doubly stochastic (or bistochastic) if all its <b>rows</b> <b>and</b> <b>columns</b> sum to 1 {{and all its}} entries are nonnegative real numbers, each of whose <b>rows</b> <b>and</b> <b>columns</b> sums to 1. It is orthostochastic if there exists an orthogonal matrix O such that ...|$|R
5000|$|Table analysis: {{constructing}} tables combining {{criteria and}} arranging data in <b>rows</b> <b>and</b> <b>columns.</b>|$|R
40|$|Abstract This paper studies a batch machine {{scheduling}} problem in which decisions on grouping jobs into batches and scheduling batches on parallel machines are jointly made. To address the problem, we model it as two-stage set-partitioning (TSSP) type formulation with exponential number of <b>rows</b> <b>and</b> <b>columns.</b> To find solutions, we propose a row-and-column generation method. The proposed method {{starts with a}} restricted version of the linear relaxation of (TSSP), and enlarges the model through iteratively generating needed <b>rows</b> <b>and</b> <b>columns.</b> The integer solution is obtained by solving the final integer programming with generated <b>rows</b> <b>and</b> <b>columns.</b> Experimental results show {{the efficiency of the}} proposed method...|$|R
2500|$|A {{frequency}} square (F-square) is {{a higher}} order generalization of a Latin square. Let S = {s1,s2, ..., sm} be a set of distinct symbols and (λ1, λ2, ...,λm) a frequency vector of positive integers. A frequency square of order n is an n × n array in which each symbol si occurs λ'i times, i = 1,2,...,m, in each <b>row</b> <b>and</b> <b>column.</b> The order n = λ1nbsp&+nbsp&λ2nbsp&+nbsp&...nbsp&+nbsp&λ'm. An F-square is in standard form if in the first <b>row</b> <b>and</b> <b>column,</b> all occurrences of s'i precede those of s'j whenever i < j.|$|E
2500|$|The boson matrix for [...] {{is found}} {{by taking the}} [...] matrix from the [...] {{representation}} of [...] and adding an extra <b>row</b> <b>and</b> <b>column</b> for the right-handed neutrino. The bosons are found by adding a partner {{to each of the}} 20 charged bosons (2 right-handed W bosons, 6 massive charged gluons and 12 X/Y type bosons) and adding an extra heavy neutral Z-boson to make 5 neutral bosons in total. The boson matrix will have a boson or its new partner in each <b>row</b> <b>and</b> <b>column.</b> These pairs combine to create the familiar 16D Dirac spinor matrices of [...]|$|E
2500|$|Finally, {{we want to}} {{make sure}} that doing <b>row</b> <b>and</b> <b>column</b> {{operations}} on [...] corresponds to a geometric operation. Indeed, it isn't hard to show (best done by drawing a picture) that sliding a k-handle [...] over another k-handle [...] replaces [...] by [...] in the basis for [...]|$|E
40|$|In the multifrontal method, each frontal matrix {{must hold}} {{all of its}} pivot <b>rows</b> <b>and</b> <b>columns</b> at one time. Moving data between frontal {{matrices}} is costly, but the method can handle arbitrary fill-reducing orderings. In the unifrontal method, pivot <b>rows</b> <b>and</b> <b>columns</b> are shifted out of the frontal matrix as the factorization proceeds. Data movement is simpler, but higher fill-in can result. We consider a hybrid unifrontal/multifrontal algorithm. Fill-reducing orderings can still be applied, but data movement is reduced by allowing pivot <b>rows</b> <b>and</b> <b>columns</b> to be shifted {{into and out of}} each frontal matrix (just as in the unifrontal method). Performance results on a Cray YMP supercomputer are presented...|$|R
30|$|Because {{of space}} constraints, this paper omits an actual Hokkaido ISAM database: there are, in total, 45 <b>rows</b> <b>and</b> 45 <b>columns,</b> {{including}} export/import <b>and</b> the sums of <b>rows</b> <b>and</b> <b>columns.</b> Please contact Hidekazu ITOH at hito@kwansei.ac.jp {{to obtain the}} Japanese ISAM.|$|R
2500|$|... the <b>rows</b> <b>and</b> <b>columns</b> are {{orthogonal}} unit vectors, therefore their dot {{products are}} zero.|$|R
