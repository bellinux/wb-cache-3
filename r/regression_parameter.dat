415|1865|Public
50|$|In high-dimension, when {{number of}} {{covariates}} p is large {{compared to the}} sample size n, the LASSO method {{is one of the}} classical model-selection strategies. Tibshirani (1997) has proposed a Lasso procedure for the proportional hazard <b>regression</b> <b>parameter.</b> The Lasso estimator of the <b>regression</b> <b>parameter</b> β is defined as the minimizer of the opposite of the Cox partial log-likelihood under an L1-norm type constraint.|$|E
50|$|Unlike {{proportional}} hazards models, the <b>regression</b> <b>parameter</b> {{estimates from}} AFT models are robust to omitted covariates. They are also less {{affected by the}} choice of probability distribution.|$|E
50|$|With MARS models, as {{with any}} {{non-parametric}} <b>regression,</b> <b>parameter</b> confidence intervals and other checks on the model cannot be calculated directly (unlike linear regression models). Cross-validation and related techniques must be used for validating the model instead.|$|E
40|$|This paper {{presents}} {{analytical and}} simulation {{results on the}} properties of two tests for forecast encompassing, allowing throughout for dependence of the forecasts on estimated <b>regression</b> <b>parameters.</b> One test, which was intended for forecasts that do not depend on <b>regression</b> <b>parameters,</b> was developed by Harvey, Leyboume and Newbold (1998). This test works relatively well when {{the size of the}} sample of forecast errors is small. A second test, which explicitly accounts for uncertainty about the <b>regression</b> <b>parameters,</b> otherwise is comparable or preferable...|$|R
40|$|An {{efficient}} algorithm is derived for solving the quantile regression problem {{combined with a}} group sparsity promoting penalty. The group sparsity of the <b>regression</b> <b>parameters</b> is achieved by using a $ell_{ 1,infty}$-norm penalty (or constraint) on the <b>regression</b> <b>parameters.</b> The algorithm is efficient {{in the sense that}} it obtains the <b>regression</b> <b>parameters</b> for a wide range of penalty parameters, thus enabling easy application of a model selection criteria afterwards. A Matlab implementation of the proposed algorithm is provided and some applications of the methods are studied. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|In this paper, we {{consider}} a parametric survival regression {{model with a}} change-point in both hazard and <b>regression</b> <b>parameters.</b> Change-point occurs at an unknown time point. Estimators of the change-point, hazard and <b>regression</b> <b>parameters</b> are proposed and shown to be consistent. Change-point Hazard function Change in regression Censored data Consistency...|$|R
50|$|The Helmert-Wolf {{blocking}} (HWB) {{method of}} estimating linear regression parameters can find an optimal solution only if all cross-correlations between the data blocks are zero. They can always be made to vanish by introducing a new <b>regression</b> <b>parameter</b> for each common factor. The gCCA method {{can be used for}} finding those harmful common factors that create cross-correlation between the blocks. However, no optimal HWB solution exists if the random variables do not contain enough information on all of the new regression parameters.|$|E
50|$|The range (−V, V) can be {{employed}} in deciding whether a trend estimated from the actual data is unlikely {{to have come from}} a data series that truly has a zero trend. If the estimated value of the <b>regression</b> <b>parameter</b> a lies outside this range, such a result could have occurred {{in the presence of a}} true zero trend only, for example, one time out of twenty if the confidence value S=95% was used; in this case, it can be said that, at degree of certainty S, we reject the null hypothesis that the true underlying trend is zero.|$|E
40|$|This paper {{deals with}} the {{proportional}} hazards model proposed by D. R. Cox in a high-dimensional and sparse setting for a <b>regression</b> <b>parameter.</b> To estimate the <b>regression</b> <b>parameter,</b> the Dantzig selector is applied. The variable selection consistency of the Dantzig selector for the model will be proved. This property enables us to reduce the dimension of the parameter and to construct asymptotically normal estimators for the <b>regression</b> <b>parameter</b> and the cumulative baseline hazard function. Comment: 11 page...|$|E
30|$|Compute the <b>regression</b> <b>parameters,</b> {{mean and}} {{variance}} of the corresponding channel pair.|$|R
40|$|Abstract: In this paper, {{we propose}} a bivariate Weibull {{regression}} models for survival time {{derived from the}} bivariate exponential distribution of Freund (1961). There are some biomet-rical applications which motivated to study these particular models. We obtain estimators of <b>regression</b> <b>parameters</b> and develop a test procedure for testing the significance of <b>regression</b> <b>parameters</b> based on censored samples...|$|R
40|$|In this paper, {{we propose}} two bivariate Weibull {{regression}} {{models for the}} survival data based on bivariate exponential distribution of Gumbel (1960). There are some biometrical applications which motivated to study these particular models. We obtain the estimation of <b>regression</b> <b>parameters</b> and derive the test procedure for testing the significance of <b>regression</b> <b>parameters</b> based on censored samples...|$|R
40|$|AbstractThis paper {{considers}} {{large sample}} inference for the <b>regression</b> <b>parameter</b> in a partly linear model for right censored data. We introduce an estimated empirical likelihood for the <b>regression</b> <b>parameter</b> {{and show that}} its limiting distribution {{is a mixture of}} central chi-squared distributions. A Monte Carlo method is proposed to approximate the limiting distribution. This enables one to make empirical likelihood-based inference for the <b>regression</b> <b>parameter.</b> We also develop an adjusted empirical likelihood method which only appeals to standard chi-square tables. Finite sample performance of the proposed methods is illustrated in a simulation study...|$|E
40|$|This paper {{considers}} {{large sample}} inference for the <b>regression</b> <b>parameter</b> in a partly linear model for right censored data. We introduce an estimated empirical likelihood for the <b>regression</b> <b>parameter</b> {{and show that}} its limiting distribution {{is a mixture of}} central chi-squared distributions. A Monte Carlo method is proposed to approximate the limiting distribution. This enables one to make empirical likelihood-based inference for the <b>regression</b> <b>parameter.</b> We also develop an adjusted empirical likelihood method which only appeals to standard chi-square tables. Finite sample performance of the proposed methods is illustrated in a simulation study. empirical likelihood partly linear model product-limit estimator random censorship...|$|E
40|$|To {{enhance the}} {{efficiency}} of <b>regression</b> <b>parameter</b> estimation by modeling the correlation structure of correlated binary error terms in quantile regression with repeated measurements, we propose a Gaussian pseudolikelihood approach for estimating correlation parameters and selecting the most appropriate working correlation matrix simultaneously. The induced smoothing method is applied to estimate the covariance of the <b>regression</b> <b>parameter</b> estimates, which can bypass density estimation of the errors. Extensive numerical studies indicate that the proposed method performs well in selecting an accurate correlation structure and improving <b>regression</b> <b>parameter</b> estimation efficiency. The proposed method is further illustrated by analyzing a dental dataset...|$|E
40|$|In this paper, {{we apply}} {{empirical}} likelihood method to inference for the <b>regression</b> <b>parameters</b> in the partial functional linear regression models based on B spline. We {{prove that the}} empirical log likelihood ratio for the <b>regression</b> <b>parameters</b> converges in law to a weighted sum of independent chi square distributions and run simulations to assess the finite sample performance of our method...|$|R
30|$|Compute the <b>regression</b> <b>parameters</b> b̂ and â of {{the above}} values using (4) and (5).|$|R
40|$|Abstract. The aim of {{the paper}} is to provide an {{algorithm}} for the computation of the <b>regression</b> <b>parameters</b> estimation {{in the framework of}} generalized linear model for count data. <b>Regression</b> <b>parameters</b> are estimated through the minimization of the quasi-likeli-hood and the main feature of that algorithm, which relies on MM method, is not to resort to matrix inversion as in Newton-Raphson algorithm and Fisher-Scoring method...|$|R
40|$|A {{weighted}} rank estimating {{function is}} proposed {{to estimate the}} <b>regression</b> <b>parameter</b> vector in an accelerated failure time model with right censored data. In general, rank estimating functions are discontinuous in the <b>regression</b> <b>parameter,</b> creating difficulties in determining the asymptotic distribution of the estimator. A local distribution function is {{used to create a}} rank based estimating function that is continuous and monotone in the <b>regression</b> <b>parameter</b> vector. A weight is included in the estimating function to produce a bounded influence estimate. The asymptotic distribution of the regression estimator is developed and simulations are performed to examine its finite sample properties. A lung cancer data set is used to illustrate the methodology...|$|E
40|$|This paper {{deals with}} the {{estimation}} problem {{in a system of}} two seemingly unrelated regression equations where the <b>regression</b> <b>parameter</b> is distributed according to the normal prior distribution. Resorting to the covariance adjustment technique, we obtain the best Bayes estimator of the <b>regression</b> <b>parameter</b> and prove its superiority over the best linear unbiased estimator (BLUE) in terms of the mean square error (MSE) criterion. Also, under the MSE criterion, we show that the empirical Bayes estimator of the <b>regression</b> <b>parameter</b> is better than the Zellner type estimator when the covariance matrix of error variables is unknown. Bayes method Seemingly unrelated regressions Covariance adjusted approach Mean square error criterion...|$|E
40|$|Consider {{estimation}} of the <b>regression</b> <b>parameter</b> in the accelerated failure time model, when data are obtained by cross sectional sampling. It is shown {{that it is possible}} under regularity of the model to construct an efficient estimator of the unknown Euclidean <b>regression</b> <b>parameter</b> if the distribution of the covariate vector is known and also if it is unknown with vanishing mean...|$|E
40|$|The Lasso {{estimate}} for linear <b>regression</b> <b>parameters</b> {{can be interpreted}} as a Bayesian posterior mode estimate when the <b>regression</b> <b>parameters</b> have in-dependent Laplace (double-exponential) priors. Gibbs sampling from this pos-terior is possible using an expanded hierarchy with conjugate normal priors for the <b>regression</b> <b>parameters</b> and independent exponential priors on their vari-ances. A connection with the inverse Gaussian distribution provides tractable full conditional distributions. The Bayesian Lasso provides interval estimates (Bayesian credible intervals) that can guide variable selection. Moreover, the structure of the hierarchical model provides both Bayesian and likelihood meth-ods for selecting the Lasso parameter. Slight modifications lead to Bayesian versions of other Lasso-related estimation methods like bridge regression and a robust variant...|$|R
40|$|Prentice (1986) {{proposed}} the case-cohort design and studied a pseudolikelihood estimator of <b>regression</b> <b>parameters</b> in Cox's model. We derive {{a class of}} estimating equations for case-cohort sampling, each depending on a different estimator of the population distribution, which lead naturally to simple estimators that improve on Prentice's pseudolikelihood estimator. We also discuss an equivalence between case-control and case-cohort sampling {{in terms of the}} estimation of <b>regression</b> <b>parameters</b> in Cox's model...|$|R
40|$|One of the {{difficulties}} that arise in the statistical analysis of autoregressive schemes is the very complex nature of {{the domain of the}} <b>regression</b> <b>parameters.</b> In the present paper we study an alternative parametrization of autoregressive models of finite order, namely the parametrization by the partial autocorrelations. These are shown to vary freely from - 1 to + 1 and to be in a one-to-one, continuously differentiable correspondence with the <b>regression</b> <b>parameters.</b> Properties of the asymptotic normal distribution of the maximum likelihood estimates are discussed, and we present a new deduction of Quenouille's result on the asymptotic independence of some of the estimated partial autocorrelations. Autoregressive processes partial autocorrelations variation independent parametrization domain of <b>regression</b> <b>parameters</b> asymptotic distribution of estimates asymptotic independence of estimates conditional correlations...|$|R
40|$|AbstractWe study a spline-based {{likelihood}} {{method for}} the partly linear model with monotonicity constraints. We use monotone B-splines to approximate the monotone nonparametric function {{and apply the}} generalized Rosen algorithm to compute the estimators jointly. We show that the spline estimator of the nonparametric component achieves the possible optimal rate of convergence under the smooth assumption and that the estimator of the <b>regression</b> <b>parameter</b> is asymptotically normal and efficient. Moreover, a spline-based semiparametric likelihood ratio test is established to make inference of the <b>regression</b> <b>parameter.</b> Also an observed profile information method to consistently estimate the standard error of the spline estimator of the <b>regression</b> <b>parameter</b> is proposed. A simulation study is conducted to evaluate the finite sample performance of the proposed method. The method is illustrated by an air pollution study...|$|E
40|$|This note {{discusses}} the asymptotic distribution of two scale and location invariant estimators of two scale parameters in the {{multiple linear regression}} model. Both of these estimators need an initial estimator of the <b>regression</b> <b>parameter</b> vector. The asymptotic distribution {{of one of these}} estimators does not depend on this initial estimator. Both of these estimators are useful in the computation of scale and translation invariant adaptive estimators and M-estimators of the <b>regression</b> <b>parameter</b> vector. 62 G 05 62 J 05, 62 F 12...|$|E
40|$|Abstract. The Cox (1972) {{regression}} model is extended to include discrete and mixed continuous/discrete failure time data by retaining the multiplicative hazard rate {{form of the}} absolutely continuous model. Application of martingale arguments to the <b>regression</b> <b>parameter</b> estimating function show the Breslow (1974) estimator to be consistent and asymptotically Gaussian under this model. A computationally convenient estimator of the variance of the score function can be developed, again using martingale arguments. This estimator reduces to the usual hypergeometric form in the special case of testing equality of several survival curves, and it leads more generally to a convenient consistent variance estimator for the <b>regression</b> <b>parameter.</b> A small simulation study is carried out to study the <b>regression</b> <b>parameter</b> estimator and its variance estimator under the discrete Cox model special case and an application to a bladder cancer recurrence dataset is provided...|$|E
3000|$|... where m, q and k {{are unknown}} <b>regression</b> <b>parameters</b> and {{depend on the}} ratio of App users to event attendees.|$|R
40|$|Application of {{the minimum}} {{distance}} method to the linear regression model for estimating <b>regression</b> <b>parameters</b> is a difficult and time-consuming process due {{to the complexity of}} its distance function, and hence, it is computationally expensive. To deal with the computational cost, this paper proposes a fast algorithm which mainly uses technique of coordinate-wise minimization in order to estimate the <b>regression</b> <b>parameters.</b> R package based on the proposed algorithm and written in Rcpp is available online...|$|R
40|$|In {{the case}} of the random design nonparametric regression, to correct for the {{unbounded}} nite-sample variance of the local linear estimator (LLE), Seifert and Gasser (J. Amer. Statist. Assoc. 91 (1996) 267 – 275) apply the idea of ridge regression to the LLE, and propose the local linear ridge regression estimator (LLRRE). However, the nite sample and the asymptotic properties of the LLRRE are not discussed there. In this paper, upper bounds of the nite-sample variance and bias of the LLRRE are obtained. It is shown that if the ridge <b>regression</b> <b>parameters</b> are not properly selected, then the resulting LLRRE has some drawbacks. For example, it may have a nonzero constant asymptotic bias, may su er from boundary e ects, or may be unable to share the nice asymptotic bias quality of the LLE. On the other hand, if the ridge <b>regression</b> <b>parameters</b> are properly selected, then the resulting LLRRE does not su er from the above problems, and has the same asymptotic mean-square error as the LLE. For this purpose, the ridge <b>regression</b> <b>parameters</b> are allowed to depend on the sample size, and converge to 0 as the sample size increases. In practice, to select both the bandwidth and the ridge <b>regression</b> <b>parameters,</b> the idea of cross-validation is applied. Simulation studies demonstrate that the LLRRE using the cross-validated bandwidth and ridge <b>regression</b> <b>parameters</b> could have smaller sample mean integrated square error than the LLE using the cross-validated bandwidth, in reasonable sampl...|$|R
40|$|We {{consider}} {{estimation of}} the <b>regression</b> <b>parameter</b> in the single index model where the link function ψ is monotone. For this model it has been proposed to estimate the link function nonparametrically by the monotone least square estimate ψ̂_nα for a fixed <b>regression</b> <b>parameter</b> α and to estimate the <b>regression</b> <b>parameter</b> by minimizing the sum of squared deviations ∑_i{Y_i-ψ̂_nα(α^TX_i) }^ 2 over α, where Y_i are the observations and X_i the corresponding covariates. Although it is natural to propose this least squares procedure, it is still unknown whether it will produce √(n) -consistent estimates of α. We show that the latter property will hold if we solve a score equation corresponding to this minimization problem. We also compare our method with other methods such as Han's maximum rank correlation estimate, which has been proved to be √(n) -consistent. Comment: 51 pages, 2 figure...|$|E
40|$|We {{consider}} partly {{linear transformation}} models applied to current status data. The unknown quantities are the transformation function, a linear <b>regression</b> <b>parameter</b> and a nonparametric regression effect. It is {{shown that the}} penalized MLE for the <b>regression</b> <b>parameter</b> is asymptotically normal and efficient and converges at the parametric rate, although the penalized MLE for the transformation function and nonparametric regression effect are only $n^{ 1 / 3 }$ consistent. Inference for the <b>regression</b> <b>parameter</b> based on a block jackknife is investigated. We also study computational issues and demonstrate the proposed methodology with a simulation study. The transformation models and partly linear regression terms, coupled with new estimation and inference techniques, provide flexible alternatives to the Cox model for current status data analysis. Comment: Published at [URL] in the Annals of Statistics ([URL] by the Institute of Mathematical Statistics ([URL]...|$|E
40|$|We study a spline-based {{likelihood}} {{method for}} the partly linear model with monotonicity constraints. We use monotone B-splines to approximate the monotone nonparametric function {{and apply the}} generalized Rosen algorithm to compute the estimators jointly. We show that the spline estimator of the nonparametric component achieves the possible optimal rate of convergence under the smooth assumption and that the estimator of the <b>regression</b> <b>parameter</b> is asymptotically normal and efficient. Moreover, a spline-based semiparametric likelihood ratio test is established to make inference of the <b>regression</b> <b>parameter.</b> Also an observed profile information method to consistently estimate the standard error of the spline estimator of the <b>regression</b> <b>parameter</b> is proposed. A simulation study is conducted to evaluate the finite sample performance of the proposed method. The method is illustrated by an air pollution study. Empirical process Generalized Rosen algorithm Maximal likelihood method Monotone B-splines Monte Carlo...|$|E
40|$|The semiparametric normal copula {{model is}} studied with a {{correlation}} matrix {{that depends on}} a covariate. The bivariate version of this regression-copula model has been proposed for statistical analysis of Quantitative Trait Loci (QTL) via twin data. Appropriate linear combinations of Van der Waerden’s normal scores rank correlation coefficients yield √(n) -consistent estimators of the coefficients in the correlation function, i. e. of the <b>regression</b> <b>parameters.</b> They are used to construct semiparametrically efficient estimators of the <b>regression</b> <b>parameters...</b>|$|R
40|$|Tsou (2003 a) {{proposed}} a parametric procedure for making robust inference for mean <b>regression</b> <b>parameters</b> {{in the context}} of generalized linear models. This robust procedure is extended to model variance heterogeneity. The normal working model is adjusted to become asymptotically robust for inference about <b>regression</b> <b>parameters</b> of the variance function for practically all continuous response variables. The connection between the novel robust variance regression model and the estimating equations approach is also provided. Generalized linear models, variance function, robust profile likelihood, normal regression,...|$|R
40|$|Thesis (Ph. D.) [...] University of Washington, 2016 - 12 Time-varying {{covariates}} {{are often}} encountered in survival analysis. The Cox {{proportional hazards model}} can incorporate time-varying covariates, while the interpretation of <b>regression</b> <b>parameters</b> is less straightforward. We instead propose a complementary log-log survival model. When covariates are time-independent, the proposed model reduces to the Cox proportional hazards model; however, when they are time-varying, the proposed model provides a direct interpretation of <b>regression</b> <b>parameters</b> in the survival function. We develop semiparametric estimation procedures based on estimating equations, and establish the asymptotic properties of the estimators for the <b>regression</b> <b>parameters</b> and survival functions. In addition, we include weight functions to the estimating equations to improve efficiency. We demonstrate the proposed methods by simulation studies and application to the Mayo Clinic Primary Biliary Cirrhosis data and data from a landmark HIV randomized prevention trial...|$|R
