6|28|Public
40|$|Over {{the past}} two years, Western Libraries has created {{numerous}} online, video tutorials {{with the intent of}} helping students grasp various information literacy concepts. These video tutorial are mounted on Western’s YouTube channel, and on Western Libraries’ website. Tutorial topics were determined by identifying <b>recurring</b> <b>Information</b> Literacy issues, by examining existing library instruction material, and by surveying faculty. The tutorials utilize various styles. While many tutorials teach concepts, some teach specific library tools. Our poster includes a summary report of assessment results...|$|E
40|$|Clustering {{is one of}} the {{important}} methods in data exploratory in this era because it is widely applied in data mining. Clustering of data is necessary to produce geo-demographic classification where k-means algorithm is used as cluster algorithm. K-means {{is one of the}} methods commonly used in cluster algorithm because it is more significant. However, before any data are executed on cluster analysis it is necessary to conduct some analysis to ensure the variable used in the cluster analysis is appropriate and does not have a <b>recurring</b> <b>information.</b> One analysis {{that needs to be done}} is the standardization data analysis. This study observed which standardization method was more effective in the analysis process of Malaysia’s population and housing census data for the Perak state. The rationale was that standardized data would simplify the execution of k-means algorithm. The standardized methods chosen to test the data accuracy were the z-score and range standardization method. From the analysis conducted it was found that the range standardization method was more suitable to be used for the data examined...|$|E
40|$|The {{definition}} of an expectation gap is, when the local municipal politician and the audited apprehensions and expectations gets apart about what auditors {{are going to work}} with and {{what they are going to}} accomplish. Svenska Kommunförbundet writes in their publication Fullmäktige och revisionen (2004) that the communication between the auditors and the audited is important so the final result becomes great. Apart from the communication, the <b>recurring</b> <b>information</b> about auditing is important to increase the knowledge and understanding. Are there expectations on what the auditors are going to review and discover among the audited, when there probably are expectations from the inhabitants on the auditing. This leads us to our purpose of our essay which is to investigate and describe if there exist an expectation gap between the auditors and the social welfare boards in the primary municipality. The method we used to collect our data was a guided telephone interview with 66 persons. The persons were the chairperson among the auditors and the social welfare boards. After analysing our data we found out that we can’t exactly say that there is an expectation gap but there are some signs...|$|E
50|$|The {{following}} are <b>recurring</b> characters, <b>information</b> on non-recurring characters {{may be found}} in Thief: The Dark Project, Thief II: The Metal Age and Thief: Deadly Shadows.|$|R
40|$|We {{investigate}} {{the design of}} incentives for quality provision in a dynamic regulation model where maintenance efforts and quality shocks have durable effects. When the regulator hires a sequence of agents, asymmetric information can lead to over-provision of quality, reflecting a dynamic rent extraction motive. When the regulator hires a single agent, the efficiency of their relationship depends crucially on the regulator’s ability to transfer rents across periods. From a social viewpoint, contracting with a single agent with unlimited liability is preferable to contracting with a sequence of agents, even if no commitment is feasible. By contrast, if the agent has limited liability, the regulator {{is not able to}} extract future rents. Because quality physically links periods together, this generates a ratchet effect in spite of <b>recurring</b> private <b>information,</b> an...|$|R
40|$|Primarily {{issues of}} the {{newsletter}} of the Williamsburg Area Bicyclists, "The Flying Wheel," dated from July 2006 to May 2007. There is also artwork, <b>recurring</b> advertisements, and <b>information</b> on {{the production of the}} newsletter. There is also a list of members and their contact information, but these files are restricted to use in the Special Collections Research Center in Swem Library only. From the Williamsburg Area Bicyclists Records, Mss. Acc. 2011. 382, Special Collections Research Center, Swem Library, College of William and Mary...|$|R
40|$|This {{dissertation}} {{explores the}} positionings (discourses and activities) of the Belgrade and Zagreb feminists vis-à-vis the (post-) Yugoslav wars and one another between 1991 and 2000. Primarily applying a Bourdieuian framework {{and based on}} a comprehensive literature review, extensive semi-structured qualitative interviews, and a thorough examination of organisational documents and printed media articles, this socio-historical analysis attends {{to a number of}} biases, lacunae and incorrect or insufficiently precise (<b>recurring)</b> <b>information</b> in the scholarship. Thereby, this thesis enriches the existing knowledge on the war-related feminist activism in Belgrade and Zagreb in the 1990 s, and raises pressing epistemological questions about this knowledge. In short, I challenge the common suggestion that the outbreak of the war violence in 1991 led to the same reorganisation of the Belgrade and Zagreb feminist fields: The activists in each city, who had up until then worked together without tensions, divided into antinationalists and nationalists and began clashing with each other because of the different war-related positionings. I show that there were significant differences between Belgrade and Zagreb in the contents of those positionings and in the intra-feminist dynamics, due to which these two cities should not be considered interchangeable locations. Furthermore, I demonstrate that the designations ‘antinationalist’ and ‘nationalist’ were not completely value-free, objective descriptions. They were instead {{an essential part of the}} local and international efforts to stop the (sexual) war violence, and of the struggle for legitimacy among the feminists in each city - endeavours in which many Western (feminist) academics, activists, and funders were involved, too...|$|E
40|$|A {{security}} {{pattern is}} a well-understood {{solution to a}} <b>recurring</b> <b>information</b> security problem. They are patterns in the sense originally defined by Christopher Alexander (the basis {{for much of the}} later work in design patterns and pattern languages of programs), applied to the domain of information security. A security pattern encapsulates security expertise in the form of worked solutions to these recurring problems, presenting issues and trade-offs in the usage of the pattern. This document presents version 1. 0 of our Security Patterns Repository. The Security Patterns Repository Version 1. 0 consists of 26 patterns and 3 mini-patterns. (A mini-pattern is a shorter, less formal discussion of security expertise in terms of just a problem and its solution.) To define the scope of the problems our patterns address, we focused on the domain of web application security. The patterns are divided between structural patterns and procedural patterns. Structural patterns are patterns that can be implemented in an application; they encompass design patterns (such as those presented by the Gang of Four), but can also apply at the architectural or implementation levels. Procedural patterns are patterns {{that can be used to}} improve the process for development of security-critical software; they often impact the organization or management of a development project. Following the presentation of security patterns in this document, we include a comprehensive bibliography collecting references from all the patterns with other relevant web application security and patterns material. To supplement this patterns repository document, we have developed a Web application that is a functional repository for these Security Patterns. Our repository application enables viewing of patterns, submitting of feedback on the patterns, and editing of patterns for authorized users. We will include relevant example code within the repository document when this application is finalized. The Security Patterns repository is available a...|$|E
40|$|Every day in websites, news portals {{the huge}} amount of {{information}} is often redundant. In a multitude of information {{it is very easy}} to get lost and not find the necessary information. Automatically analysing websites, news portals, published Lithuanian articles face with a problem that is inserted into the ontology <b>recurring</b> <b>information.</b> In semantically annotated texts, find the necessary information would be much easier and more convenient if the ontology would {{be given the opportunity to}} automatically identify similar ontology individuals and link them by similarity. In this master's degree work an ontology is analysed which was created by Informatics Systems Department during "Syntactic-semantic analysis and search system for Lithuanian Internet, corpus and public sector applications „SemantikaLT“" carried out by Lithuanian Economics growth actions program 3 rd priority "Information Society for Everyone" realization means Num. VP 2 - 3. 1 -IVPK- 12 -K "Lithuanian Language in Information Society". This ontology individuals of Person class which were automatically created by analysing article texts in Lithuanian language published in the Internet. Creating ontology Persons individuals this way, duplicated Persons were created too. The master goal is to make possible to automatically identify similar ontology individuals, to link them and thereby minimize information of ontology duplication. Master thesis objective algorithm was developed and written in SPARQL query that includes the ability to automatically identify similar ontology individuals and link them. This helps to reduce the duplication of ontology information. About specimen collected and analysed information the result is displayed on the ontology that searching every time do not need to analyse the ontology individual’s similarity. Created solution easily adoptable for this type of ontology. In ontology structure there is label_lemma (a generic form of the word), using label_lemma reduced ontology individuals repetitions, merging individuals by similarity for the purpose to provide concrete, structured information...|$|E
40|$|Title {{devised by}} cataloguer.; Published in the Canberra Times on 22 February 1989.; Part of the Pryor {{collection}} of cartoons and drawings.; Also available in an electronic version via the Internet at: [URL] With the Hawke {{government on the}} lookout for ways of increase savings, John Button, Minister for industry and Commerce makes comments about the possibility of removing tax on interest earned from savings - a suggestion which is immediately jumped on by Treasurer Paul Keating who dismisses the debate as a <b>recurring</b> 'fad'. [...] <b>Information</b> provided by Geoff Pryor...|$|R
40|$|It {{is often}} assumed {{that there is}} a small number of primitive, universal, and perhaps innate {{syntactic}} categories. Mixed category constructions involve lexical items that seem to be central members of more that one part of speech and so pose a problem for the standard view of syntactic categories. For example, the verbal gerund phrase in Chris worried about Pat's frequently eating hamburgers has some internal properties of a VP but the external distribution of an NP. The verbal gerund eating has both verbal and nominal properties. It combines with a direct object and an adverb, but it also combines with possessor and occurs as the object of a preposition. This paper presents an HPSG analysis of English verbal gerunds based on a more fine-grained theory of syntactic categories. A category like `noun' is actually a bundle of <b>recurring</b> grammatical <b>information</b> represented as constraints on types in the hierarchical lexicon. Mixed categories have an atypical combination of information. For [...] ...|$|R
40|$|This paper {{addresses}} {{the problem of}} a single rumor source de-tection with multiple observations, from a statistical {{point of view of}} a spreading over a network, based on the susceptible-infectious model. For tree networks, multiple sequential ob-servations for one single instance of rumor spreading cannot improve over the initial snapshot observation. The situation dramatically improves for multiple independent observations. We propose a unified inference framework based on the union rumor centrality, and provide explicit detection performance for degree-regular tree networks. Surprisingly, even with mere-ly two observations, the detection probability at least doubles that of a single observation, and further approaches one, i. e., reliable detection, with increasing degree. This indicates that a richer diversity enhances detectability. For general graph-s, a detection algorithm using a breadth-first search strategy is also proposed and evaluated. Besides rumor source detec-tion, our results can be used in network forensics to combat <b>recurring</b> epidemic-like <b>information</b> spreading such as online anomaly and fraudulent email spams...|$|R
40|$|The {{idea for}} the present article came from a Thematic Categorical Analysis made {{to a set of}} nine {{interviews}} to Portuguese enterprises occurred between July and November 2007. The semi-directive interviews that where submitted to a content analysis aim to focus upon an eventual relationship between the public relations function and the information and communication technologies (ICT). This text mainly explores the codification process of ‘registration unities’ (made from cutting the transcript interviews) and the inferences resulting from that. This work is reduced to brief passages taken from one of the several investigation techniques used in a larger research which integrates a PhD thesis in sociology. In this thesis we try to discover if public relations effectiveness is better achieved, or not, by <b>recurring</b> to <b>information</b> and communication technologies in different scenarios from an infrastructural component to an organic design of the PR function or even to the tasks and policies performance & control. Electronic Public Relations, ICT, Content Analysis...|$|R
40|$|Abstract—This paper {{addresses}} {{the problem of}} rumor source detection with multiple observations, from a statistical {{point of view of}} a spreading over a network, based on the susceptible-infectious model. For tree networks, multiple independent obser-vations can dramatically improve the detection probability. For the case of a single rumor source, we propose a unified inference framework based on the joint rumor centrality, and provide explicit detection performance for degree-regular tree networks. Surprisingly, even with merely two observations, the detection probability at least doubles that of a single observation, and further approaches one, i. e., reliable detection, with increasing degree. This indicates that a richer diversity enhances detectabil-ity. Furthermore, we consider the case of multiple connected sources and investigate the effect of diversity. For general graphs, a detection algorithm using a breadth-first search strategy is also proposed and evaluated. Besides rumor source detection, our results can be used in network forensics to combat <b>recurring</b> epidemic-like <b>information</b> spreading such as online anomaly and fraudulent email spams. Index Terms—Graph networks, inference algorithms, maxi-mum likelihood detection, multiple observations, rumor spread-ing I...|$|R
40|$|Introduction. This paper {{proposes a}} model of {{information}} behaviour of women during their life-long struggle to maintain normal weight. Method. The model is integrative and contextual, built on existing models in information science and several other disciplines, and the life stories of about fifty Israeli women aged 25 - 55 and interviews with professionals. Analysis. The life stories of the participating women were analyzed qualitatively, major themes and phases were identified. Results. Weight loss and/or maintenance behaviour is a lifetime process in which distinctive stages were identified. In most cases the weight gain - weight loss - maintenance cycle is a <b>recurring</b> cycle. <b>Information</b> is a major resource during the process: several roles of information were defined: enabling, motivating, reinforcing, providing background information related to weight problems and creating the internal cognitive schema related to food and weight. Information behaviour and the roles of information vary with the different stages. Information needs are also influenced by the specific stage of the process. Information gathered at previous cycles is reused, and information gained through previous experience effects behaviour in the current cycle. Conclusion. The model has both theoretical and practical implications...|$|R
40|$|Part 3 : DesignInternational audienceSoftware design {{patterns}} are documented best practice solutions {{that can be}} applied to <b>recurring</b> problems. The <b>information</b> about used patterns and their placement in the system can be crucial when trying to add a new feature without degradation of its internal quality. In this paper a new method for recognition of given patterns in object-oriented software is presented. It is based on static and semidynamic analysis of intermediate code, which is precised by the run-time analysis. It utilizes own XML based language for the pattern description and the graph theory based approach for the final search. The proof of concept is provided by the tool searching for the patterns in. Net framework intermediate language and presenting the results using common UML-like diagrams, text and tree views...|$|R
40|$|The World Wide Web can be {{considered}} an infinite source of information for both individuals and organizations. Yet, if the main standard of publication on the Web (HTML) is quite suited to human reading, its poor semantics {{makes it difficult for}} computers to process and use embedded data in a smart and automated way. In this paper, we propose to build a bridge between HTML documents and external applications by means of so-called mapping rules. Such rules mainly record a semantic interpretation of <b>recurring</b> types of <b>information</b> in a cluster of similar Web documents and their location in those doc-uments. Relying on these rules, HTML-embedded data can be extracted towards a more computable format. The defi-nition of mapping rules is based on direct user input mainly for the interpretation part, and on automatic computing for the location of data in HTML tree structures. This approach is supported by a user-friendly tool called Retrozilla. 1...|$|R
40|$|Information is {{characterized}} as {{the reduction of}} uncertainty and by {{a change in the}} state of a receiving organism. Thus, organisms can acquire information about their environment that reduces uncertainty and increases their likelihood of choosing a best-matching strategy. We define the ecology of information as the study of how organisms acquire and use information in decision-making and its significance for populations, communities, landscapes and ecosystems. As a whole, it encompasses the reception and processing of information, decision-making, and the ecological consequences of making informed decisions. The first two stages constitute the domains of, e. g. sensory ecology and behavioral ecology. The exploration of the consequences of information use at larger spatial and temporal scales in ecology has lagged behind these other disciplines. In our overview we characterize information, discuss statistical decision theory as a quantitative framework to analyze information and decision-making, and discuss potential ecological ramifications. Rather than attempt a cursory review of the enormity of the scope of information we highlight information use in development, breeding habitat selection, and interceptive eavesdropping on alarm calls. Through these topics we discuss specific examples of ecological information use and the emerging ecological consequences. We emphasize <b>recurring</b> themes: <b>information</b> is collected from multiple sources, over varying temporal and spatial scales, and in many cases links heterospecifics to one another. We conclude by breaking from specific ecological contexts to explore implications of information as a central organizing principle, including: information webs, information as a component of the niche concept, and information as an ecosystem process. With information having such an enormous reach in ecology we further cast a spotlight on the potential harmful effects of anthropogenic noise and info-disruptio...|$|R
40|$|One of the <b>recurring</b> {{themes in}} <b>{{information}}</b> theory and quantum information theory is correlation corruption and correlation recover. Correlation corruption {{refers to the}} situation where Alice and Bob share information that is not perfectly correlated (or perfectly entangled, if they share quantum information). Correlation corruption arises in many natural situations, including transmitting information through a noisy channel, measuring a noisy signal source, quantum decoherence, and adversarial distortion. Correlation recovery refers to the action Alice and Bob takes to " the correlation/entanglement by agreeing on some perfectly correlated/entangled information. Traditionally correlation repair is done via a preventive strategy, namely error correction. Using this strategy, Alice encodes her information using an error correcting code or a quantum error correcting code before sending it through a noisy channel to Bob, who then decodes and recovers the original information. Error correcting codes and quantum error correcting codes are extremely useful objects in information theory with numerous applications in many other areas of science and technology. They are well studied and well understood. However they have limitations. We shal...|$|R
40|$|Data Mining plays a {{vital role}} in today’s information-oriented world where it has been widely applied in various {{organizations}}. The current trend is that organizations need to share data for mutual benefit. This has led to a lot of concern over privacy in the recent years. It has also raised a potential threat of revealing sensitive data of an individual when the data is released publicly. Various methods have been proposed to tackle the privacy preservation problem. But the <b>recurring</b> problem is <b>information</b> loss. The loss of sensitive information about certain individuals may affect the data quality and in extreme cases the data may become completely useless. In recent years Privacy preserving data mining has emerged as a key domain of research. One of the methods used for preserving privacy is k-anonymization. k-anonymity demands that every tuple in the dataset released be indistinguishably related to no fewer than k respondents. But the distribution preservation is not guaranteed. In this work a modified k-anonymity model is introduced where the privacy in a dataset is preserved while preserving the distribution also...|$|R
40|$|This study investigates whether Iconic Linkage - {{the use of}} the {{identical}} wording to present the same <b>information</b> <b>recurring</b> in a text - can improve the usability of user guides. Drawing on research literature in technical communication, cognitive psychology and human-computer interfaces, Iconic Linkage is presented as a writing strategy that potentially allows users to work more quickly and effectively and which promotes better retention of information. The usefulness of Iconic Linkage was tested in a laboratory-based usability study that combined (1) objective task-based evaluation and (2) users’ subjective evaluations of a software program used in recording parliamentary debates. A post-test survey designed to test subjects’ retention of information contained in the user guides was also administered. The study shows that Iconic Linkage significantly improved usability of the user guide: in all tasks, subjects worked more effectively and made fewer mistakes; while in the three timed tasks, subjects completed the tasks much more quickly. Subjects also gave higher ratings for the software and their retention of information was noticeably improved. The study concludes by discussing the implications and potential future applications of this research...|$|R
40|$|A <b>recurring</b> {{question}} in <b>information</b> retrieval is whether term associations can be properly integrated in traditional information retrieval models while preserving their robustness and effectiveness. In this paper, we revisit {{a wide spectrum}} of existing models (Pivoted Document Normalization, BM 25, BM 25 Verboseness Aware, Multi-Aspect TF, and Language Modelling) by introducing a generalisation of the idea of the translation model. This generalisation is a de facto transformation of the translation models from Language Modelling to the probabilistic models. In doing so, we observe a potential limitation of these generalised translation models: they only affect the term frequency based components of all the models, ignoring changes in document and collection statistics. We correct this limitation by extending the translation models with the 15 statistics of term associations and provide extensive experimental results to demonstrate the benefit of the newly proposed methods. Additionally, we compare the translation models with query expansion methods based on the same term association resources, as well as based on Pseudo-Relevance Feedback (PRF). We observe that translation models always outperform the first, but provide complementary information with the second, such that by using PRF and our translation models together we observe results better than {{the current state of the}} art...|$|R
30|$|The {{representation}} of information flow through structural networks, as depicted by functional networks, does not coincide exactly with the anatomical {{configuration of the}} networks. Model free correlation methods including transfer entropy (TE) and a Gaussian convolution-based correlation method (CC) detect functional networks, i.e. temporal correlations in spiking activity among neurons, and depict information flow as a graph. The influence of synaptic topology on these functional correlations is not well-understood, though nonrandom features of the resulting functional structure (e.g. small-worldedness, motifs) are believed to {{play a crucial role}} in information-processing. We apply TE and CC to simulated networks with prescribed small-world and recurrence properties to obtain functional reconstructions which we compare with the underlying synaptic structure using multiplex networks. In particular, we examine the effects of the surrounding local synaptic circuitry on functional correlations by comparing dyadic and triadic subgraphs within the structural and functional graphs in order to explain <b>recurring</b> patterns of <b>information</b> flow on the level of individual neurons. Statistical significance is demonstrated by employing randomized null models and Z-scores, and results are obtained for functional networks reconstructed across a range of correlation-threshold values. From these results, we observe that certain triadic structural subgraphs have strong influence over functional topology.|$|R
40|$|It has {{recently}} become possible {{to study the}} dynamics of information diffusion in techno-social systems at scale, due {{to the emergence of}} online platforms, such as Twitter, with millions of users. One question that systematically <b>recurs</b> is whether <b>information</b> spreads according to simple or complex dynamics: does each exposure to a piece of information have an independent probability of a user adopting it (simple contagion), or does this probability depend instead on the number of sources of exposure, increasing above some threshold (complex contagion) ? Most studies to date are observational and, therefore, unable to disentangle the effects of confounding factors such as social reinforcement, homophily, limited attention, or network community structure. Here we describe a novel controlled experiment that we performed on Twitter using `social bots' deployed to carry out coordinated attempts at spreading information. We propose two Bayesian statistical models describing simple and complex contagion dynamics, and test the competing hypotheses. We provide experimental evidence that the complex contagion model describes the observed information diffusion behavior more accurately than simple contagion. Future applications of our results include more effective defenses against malicious propaganda campaigns on social media, improved marketing and advertisement strategies, and design of effective network intervention techniques. Comment: 10 pages + 4 pages of supplementary information. 4 + 1 figure...|$|R
40|$|Objective: Discussing {{prognosis}} is often confronting and complex for cancer patients. This study investigates bow patients' psychological characteristics {{relate to their}} preferences concerning the disclosure of prognosis. Methods: One hundred and seventy-six esophageal cancer patients participated in the study. They had undergone esophagectomy within the past 28 months {{and did not have}} evidence of cancer recurrence. Patients completed a questionnaire eliciting their preferences for prognostic information. Sociodemographic characteristics, involvement preferences, anxiety, depression, fear of recurrence, striving for quality of life (QOL) or quantity of life and trust in physicians were explored as predictors for (a) wanting to be informed about prognosis and (b) the initiation of discussion about prognosis. Results: Patients wanting all prognostic information had more fear for the disease to recur (p < 0. 05) and were inclined to be more actively involved during consultation (p < 0. 001). Post hoc analyses showed that patients with worse QOL scores reported more fear of recurrence. Anxiety, depression, trust and tendency to strive for QOL or quantity of life were not related to preferences concerning prognostic information. Conclusions: The more fear patients have for esophageal cancer to <b>recur,</b> the more <b>information</b> they want about prognosis. Thus, patient's fear for recurrent disease is not a reason for withholding prognostic information. Results also suggest that there is no harm in asking patients what information they want. Copyright (C) 2009 John Wiley & Sons, Lt...|$|R
40|$|Background: Information on the {{epidemiology}} of venomous snake species {{responsible for}} envenomation to humans in Iran {{has not been}} well documented. In the Kashan city, venomous snakebite remains a <b>recurring</b> medical problem. <b>Information</b> providing the correct identification of snake species responsible for envenomation in this geographic region {{would be useful to}} regional medical clinics and personnel for the effective and optimal management of the patients. Materials and Methods: In this cross-sectional study, all patient data was collected from Kashan city and its suburbs. The specific data relating to the taxonomic identification of snakes responsible for envenomation were evaluated. A general approach to the diagnosis and management of patients was also provided. Snakes responsible for bites were transported to a laboratory, where their taxonomic classification was confirmed based on key anatomical features and morphological characteristics. Results: A total of 46 snakes were examined. Of these, 37 (80 %) were non-venomous species, and 9 (20 %) were identified as venomous. Seven of the nine venomous snake species (78 %) were of the family Viperidae, and two specimens (22 %) were in the family Colubridae. Specifically, the viperid species were Macrovipera lebetina obtusa, Pseudocerastes persicus, Pseudocerastes fieldi, and Echis carinatus. The two colubrid species were Malpolon monspessulanus insignitus and Psammophis schkari. Conclusion: Five different species of venomous snakes responsible for envenomation in the Kashan city region were confirmed. The viper, P. fieldi, was reported {{for the first time in}} the central part of Iran...|$|R
40|$|For {{the past}} several years, {{the number of women}} and {{children}} seeking shelter from the City of Chicago's Department of Human Services (CDHS) during the warm weather months has far exceeded the supply of shelter beds. Officials at CDHS wanted to know whether this increase was related to external factors, such as the demolition of public housing units, or to public policies, such as women reaching the 60 -month time limit for receipt of TANF (cash assistance). The City of Chicago is determined to end homelessness by 2013 with a "housing first" policy, significantly reducing the number of shelter beds and creating interim housing and increasing permanent housing linked with the necessary social services. By providing more stable housing along with linkages to mainstream resources, the City believes that it can better prevent <b>recurring</b> homelessness. Current <b>information</b> about the causes of family homelessness, as well as the needs of homeless women and children, is critical to the City as it implements its new programs. To better understand the situations of the women and children currently homeless, CDHS, in collaboration with the Ounce of Prevention Fund, commissioned the Center for Impact Research (CIR) to undertake a study focused on this population. CIR conducted structured interviews with 45 homeless women living in shelters in Chicago. The study provides critical information and insight that can inform CDHS policy and practice vis-a-vis homeless families in Chicago within the limitations of the scope of the study...|$|R
40|$|In this thesis, we use concepts, principles, and {{theoretical}} results from Physical Chemistry to engineer communication and networking systems. We focus on system dynamics and exploit laws from chemical kinetics {{in order to}} govern the dynamics of a communication network. This is achieved by orchestrating the interactions among network nodes by means of “artificial chemistries”. We provide {{a new perspective on}} traditional issues concerning the design, the formal analysis and the deployment of distributed algorithms and communication protocols, ultimately leading to programmable network dynamics with provable properties. Specifically, (i) we introduce a class of chemistry-inspired flow controllers that can easily be customized to accommodate many requirements of network (resource) management, such as distributed coordination of flow aggregates, capacity allocation, access regulations and service differentiation among user flows or flow bundles. (ii) We show the benefit of the chemical approach in designing solutions to the “distributed consensus problem” for wireless sensor networks. After having designed and analyzed the required interaction rules “on paper”, we use the derived communication protocol in a hardware testbed. Salient features of this minimalistic setup are mainly three. Nodes achieve consensus based only on asynchronously emitted RF pulses. No media access control is used. The protocol works in an embodied fashion by exploiting subtle timing differences and without <b>recurring</b> to symbolic <b>information.</b> (iii) Finally, in order to demonstrate the use of Chemistry-driven mechanisms also for high performance tasks (e. g., high-rate packet-pacing), we describe the implementation of artificial chemistries on an FPGA-based hardware. At the same time, we provide an abstraction for designing runtime-programmable hardware controllers...|$|R
40|$|Problem Statement: Failure of {{computer}} based information systems {{had been a}} source of major concern in the modern technological era. Information System (IS) researchers have spent a significant amount of their time and effort in understanding the <b>recurring</b> failure of <b>Information</b> Systems. Studies in this regard have ranged from being primarily technical in their approach to those having a much stronger socio-technical bias. The purpose of this paper was to analyze information system failures using the lens of complexity theory. Approach: Complexity theory was proposed as an alternative paradigm for understanding and analyzing Information System failures. Other research frameworks within which system failures were studied were also discussed. The core concepts of complexity and the salient features of information systems were elucidated. It was shown that information systems could be interpreted as complex entities both from the structural and functional viewpoints. Pictorial representations were given to corroborate this point. Results: It was shown that the complexity framework could be utilized to understand the different types of system failures, viz. process, correspondence and interaction failures in a more meaningful way. The idea of recurrent failures was also examined in the context of complexity theory. It was shown how such failures could be tackled much better by using lessons drawn from complexity. The inadequacy of the systems approach was pointed out that necessiated the introduction of complexity. Conclusions: It appeared that adopting certain features of complexity in the analysis, design and management of information systems could help in avoiding certain failures related to information systems. Some of these features were facilitating the process of co-evolution, exploring the space of possibilities and encouraging self-organization and emergent behaviour...|$|R
40|$|BACKGROUND: Rhabdomyosarcoma (RMS) has 2 major histologic subtypes: {{alveolar}} (ARMS) and embryonal (ERMS). ARMS is {{more aggressive}} {{and prone to}} distant tumor dissemination, whereas ERMS tends to expand and <b>recur</b> locally. Little <b>information</b> is available on bone marrow involvement by RMS. METHODS: We determined the sensitivity and specificity of MyoD 1, myogenin, and PAX-FKHR transcripts as RMS markers and used them to study prospectively by reverse-transcriptase polymerase chain reaction (RT-PCR) a series of consecutive unselected RMS patients enrolled in the Italian Association of Pediatric Hematology and Oncology national trial. Prevalence of minimal disseminated disease (MDD) and its response kinetics to chemotherapy were assessed. RESULTS: MyoD 1 and myogenin were specifically associated with RMS, independently of histologic subtype, whereas PAX 3 / 7 -FKHR transcripts were expressed only in ARMS. Sensitivity was higher for MyoD 1 compared with myogenin and PAX-FKHR. Out of a cohort of 40 patients, MDD positivity was limited to ARMS, with the sole exception of 1 ERMS. Prevalence of MDD positivity increased when a real-time polymerase chain reaction approach was used on a subgroup of patients. RT-PCR was more sensitive than microscopic examination of bone marrow biopsies. The study of the response kinetics of MDD showed that in {{approximately half of the}} cases, bone marrow was cleared of disease after 1 cycle of chemotherapy. CONCLUSIONS: MyoD 1 and myogenin transcripts can be used as tumor markers for MDD assessment in virtually all RMS cases, whereas PAX-FKHR is specific for ARMS. Sensitivity of RT-PCR methods was superior compared with standard morphologic assays. Our study suggests that bone marrow involvement is more common in ARMS compared with ERMS, and that MDD can be often cleared by the initial chemotherapy cycles...|$|R
40|$|The ambitious late Gothic vaults {{created in}} the 15 th and 16 th centuries with their complex shape and {{complicated}} meshes of ribs soaring along spatial curves, were extremely demanding in their geometric design. This regards both {{the design of the}} whole structure, as also the design specifications for the single stone elements which were prefabricated and fit together on the building site with astonishing precision. In consequence, the particular character of these structures and their geometric features are intrinsically linked to the design routines and the geometric concepts used by the Master Builders. At present, these procedures and methods are not well understood, because they are not documented in original drawings, and because they differ in principle from the modern practice. In consequence, necessary works of repairing and restoring cannot <b>recur</b> to any <b>information</b> related to the original design. Moreover, understanding the characteristics of information transfer from the design to the execution, would cast a light on the information society in which these constructions were created. In several case studies, the geometric concepts of the intricate spatial curve systems of late Gothic vaults have been clarified on the basis of detailed surveys and geometrical analyses carried out on the built objects. On this background, also the existing sources such as historical design treatises could be re-interpreted. In a collaboration between the research group working on the design principles of late Gothic vaults at the Technische Universität Dresden, and expert stone masons specialized on historical working techniques and practical stereotomy at the Cathedral Workshop Œuvre Notre-Dame de Strasbourg, the phases of the design process, such as full-scale drawings on the tracing floor and the production of full-scale models and samples of ribs and keystones, are currently investigated in practical experiments. As result, we propose a complete picture of the design process from the general concept to the setting-out of the single stone elements. Further, we are able to drive general considerations on the Late Medieval and Early Modern design practice for stone structures and trace a new interpretation of the early treatises of stereotomy...|$|R
40|$|Ad-hoc {{wireless}} networks use multi-hop transmissions to communicate, without exploiting any infrastructure. Logical links create unreliable {{connections between}} nodes: {{the capacity of}} the channel can unpredictably change due to the presence of obstructions, interferences between nodes and stochastic phenomena such as fading. Moreover the medium is multi-access and resources are contended by different users. It is possible to notice that adjusting the power at the physical layer affects the interference perceived, which in turn modifies the resources availability, alters the queue length at the network layer and eventually influences the source rates at the transport layer. To this end, a lot of works have shown that a better understanding of inherent coupling between different layers in the networking stack is worth. Specifically, network performances can be increased if the traditionally separated network layers are jointly optimized. Network utility maximization has emerged as a powerful framework for studying such cross-layer issues and optimizing performances overall the network. In particular, we focus on distributed cross-layer algorithms that achieve a global optimum <b>recurring</b> to local <b>information</b> only. Although the literature is vast in this field, most of works remain as theory. We aim at clarifying the practical feasibility of such theoretical dissertations and what considerations are needed in order to establish a bridge between theory and practice. After analyzing different crosslayer methods, we focus on the work of Papandriopoulos et al [...] We first discuss its theoretical benefits in an interference limited system such as CDMA, without accounting physical constraints of the network. In order to validate the performances in a more realistic scenario, we implement the algorithm of Papandriopoulos et al. in the NS- 2 network simulator without breaking up the hierarchy of the standard ISO/OSI stack. We focus on modeling physical, data link, network and transport layer, underlining issues and possible solutions from a practical perspective. For instance, we propose a novel approach to calculate the congestion prices of the network. After discussing benefits and drawbacks of the underlying theory, we propose several results under many simulation scenarios and eventually a comparison with the standard protocol for wireless networks IEEE/ 802. 11...|$|R
40|$|Waste {{management}} {{has changed from}} being mainly a question of transporting out of sight to being an issue entwined {{in all parts of}} society, from product planning to the private domestic sphere. This has imposed new conditions and constraints for waste management, the description of which is the objective of this thesis. The overall policy in Sweden is that all waste should be treated according to its characteristics and reincorporated into societal material flows. The main aim is to reduce the quantities of household waste generated and the amounts sent to landfill. To give waste management a broader perspective and to establish a waste hierarchy, producer responsibility legislation was introduced in Sweden in 1994. According to this, paper/newsprint and packaging waste have to be sorted at source and collected separately. Source separation is today an established part of legislation and public thinking and is probably here to stay so waste management providers must adapt to this situation. In order to obtain high participation rates in source separation programmes, they have to be designed so as to decrease any barriers to participation. The design of collection systems has many aspects since they must be both technically feasible and accepted and understood by the public. <b>Recurring</b> and adequate <b>information</b> to households are is very important for the function of the collection system, but both these and other design parameters should be adapted to local conditions. The differences in the systems used in Sweden today do not lie mainly in technical features but rather in how, why, by and for whom they were developed. To plan waste management, the characteristics of the waste must be known, due to temporal and regional variations these are best evaluated through waste component analysis. The aim of such analysis determines the level on which it should be conducted: national, regional or household level. When post-collection sampling is possible at a treatment plant, the procedure can be made more efficient and less resource-demanding. The methods for waste component analysis presented in this thesis can be a useful tool in future waste management planning...|$|R
40|$|This {{study focused}} {{on the use of}} Assistive Technology (AT) in {{enhancing}} the educational support of all learners in a mainstream school. The theoretical frameworks used in this study were Wellness Theory and Cultural Historical Activity Theory (CHAT). The main aim {{of this study was to}} determine the efficacy of Assistive Technology in promoting the educational support of all learners in a mainstream school. This use of AT thus benefiting inclusion and inclusive practices and enhancing learning and support for all students in a mainstream school. The study was embedded in an interpretivist paradigm and used a qualitative research approach. Sampling was purposive and participants were selected based on the researcher’s pre-defined purpose for the study. Ethical approval was sought from the University of South Africa and prior to conducting research consent forms were signed by all participants. Data were collected using questionnaires with open-ended questions, face to face interviews and document analysis. Data analysis was done through thematic coding (noting <b>recurring</b> patterns of <b>information)</b> and the development of major themes based on qualitative data collected. Findings revealed the need for more technology in the research site (such as iPads and laptops), as well as the need for staff training in order to effectively use the technology. Furthermore, having more educational assistants to support students with more complex needs was also highlighted. Findings from face-to-face interviews indicated themes articulating with the above mentioned. This included the need for time to plan for the use of Assistive Technology in the classroom, along with time to familiarize oneself with the various forms of technology available. Training to effectively implement and support the technology was highlighted, as was time to engage with other colleagues and develop a collegial enquiry for the effective use of Assistive Technology to support all learners in the mainstream class. Findings from documents reviewed showed significant focus on the need for diagnosis to be able to select intervention strategies for the classroom and instruction. When staff were aware of a child’s medical, cognitive or mental health diagnosis, appropriate supports could be explored. The school support documents reviewed indicated a clear requirement for updated testing and setting of goals for students, to be supported by the strategies. Recommendations made for the effective use of AT included the promotion of professional development in staff and the establishment of professional learning communities which value the sharing and exchange of information regarding knowledge and skills. Furthermore, a framework is proposed which may be used by schools using assistive technology in supporting learners in mainstream schools so that learning may be enhanced. A further longitudinal study was recommended for the future to determine the impact of the use of AT to support inclusion when relevant staff training is available, applicable and ongoing. Inclusive EducationD. Ed. (Inclusive Education...|$|R

