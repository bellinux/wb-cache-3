11|21|Public
40|$|In this paper, {{reversible}} data-hiding (RDH) {{systems with}} modified fluctuation functions and <b>rate-matched</b> Reed–Solomon (RS) codes are proposed {{to enhance the}} data recovery from encrypted images. The modified fluctuation functions are used for estimating embedded codeword bits from the correlation of pixels. Instead of direct data-bit embedding, codeword bits of RS codes are embedded by a data-hider. With {{the help of the}} error-correcting capability of RS codes, the encrypted message can be recovered from the weak correlation of adjacent pixels in the image. In the experimental results, bit error rate (BER) and peak signal to noise ratio (PSNR) performances of the proposed system are better than those of referenced data-hiding systems for three images. The proposed schemes based on the modified fluctuation function or <b>rate-matched</b> codes can be applied to various RDH systems with better data transmission and image recovery performance...|$|E
40|$|Regenerating code is a {{class of}} code very {{suitable}} for distributed storage systems, which can maintain optimal bandwidth and storage space. Two types of important regenerating code have been constructed: the minimum storage regeneration (MSR) code and the minimum bandwidth regeneration (MBR) code. However, in hostile networks where adversaries can compromise storage nodes, the storage capacity of the network can be significantly affected. In this paper, we propose two optimal constructions of regenerating codes through rate-matching that can combat against this kind of adversaries in hostile networks: 2 -layer <b>rate-matched</b> regenerating code and $m$-layer <b>rate-matched</b> regenerating code. For the 2 -layer code, we can achieve the optimal storage efficiency for given system requirements. Our comprehensive analysis shows that our code can detect and correct malicious nodes with higher storage efficiency compared to the universally resilient regenerating code which is a straightforward extension of regenerating code with error detection and correction capability. Then we propose the $m$-layer code by extending the 2 -layer code and achieve the optimal error correction efficiency by matching the code rate of each layer's regenerating code. We also demonstrate that the optimized parameter can achieve the maximum storage capacity under the same constraint. Compared to the universally resilient regenerating code, our code can achieve much higher error correction efficiency. Comment: 31 pages, 7 figures, journal pape...|$|E
30|$|LTE {{features}} a Hybrid-ARQ mechanism based on incremental redundancy. A transport block (consisting of data bytes to be transmitted in a subframe) is encoded using a rate 1 / 3 Turbo encoder and, {{depending on the}} CQI feedback, assigned RBs, and modulation, the encoded transport block is <b>rate-matched</b> appropriately to match the code rate supported by the indicated CQI. With each subsequent retransmission, additional coded bits can be sent reducing the effective code rate and/or improving the SINR. Though LTE allows the retransmission to be made at a different modulation scheme compared to the first transmission, this flexibility is not exploited in this paper.|$|E
50|$|Best rate {{guaranteed}} is {{the most}} generous <b>rate-matching</b> program a hotel guest can get (only when communicating directly with the hotel).|$|R
40|$|We {{consider}} {{a class of}} general Gt/Gt/ 1 single-server queues, including the Mt/Mt/ 1 queue, with unlimited waiting space, service in order of arrival and a time-varying arrival rate, where the service rate at each time is subject to control. We study the <b>rate-matching</b> control, where the service rate is made proportional to the arrival rate. We show that the model with the <b>rate-matching</b> control {{can be regarded as}} a deterministic time transformation of a stationary G/G/ 1 model, so that the queue length distribution is stabilized as time evolves. However, the time-varying virtual waiting time is not stabilized. We show that the time-varying expected virtual waiting time with the <b>rate-matching</b> service-rate control becomes inversely proportional to the arrival rate in a heavy-traffic limit. We also show that no control that stabilizes the queue length asymptotically in heavy-traffic can also stabilize the virtual waiting time. Then we consider two square-root service-rate controls and show that one of these stabilizes the waiting time when the arrival rate changes slowly relative to the average service time, so that a pointwise stationary approximation is appropriate...|$|R
40|$|We {{consider}} a general Gt/Gt/ 1 single-server queue with unlimited waiting {{space and a}} time-varying arrival rate, where the the service rate at each time is subject to control. We study the <b>rate-matching</b> control, where the the service rate is made proportional to the arrival rate. We show that the model with the <b>rate-matching</b> control {{can be regarded as}} a deterministic time transformation of a stationary G/G/ 1 model, so that the queue length distribution is stabilized as time evolves. However, the time-varying virtual waiting time is not stabilized. We show that the time-varying expected virtual waiting time with the <b>rate-matching</b> service-rate control becomes inversely proportional to the arrival rate in a heavy-traffic limit. We also show that no control that stabilizes the queue length asymptotically in heavy-traffic can also stabilize the virtual waiting time. Then we consider two square-root service-rate controls. We show that these alternative square-root service-rate controls stabilize the waiting time when the arrival rate changes very slowly relative to the average service time, so that a pointwise stationary approximation is appropriate...|$|R
40|$|International audienceProviding {{performance}} guarantee {{is one of}} the most important issues in a heterogeneous network for a large number of concurrent sessions. A common question in the network control and resource scheduling is how to provide end-to-end delay bounds and offer service guarantees in a relatively distributed manner. In this paper, we will narrow down the question and address specifically on the MRBS multiple access. It supports each user a flexible <b>rate-matched</b> time sharing with efficient resource scheduling. A generalized system modeling and analytical framework is developed based on the techniques of network calculus. The result extends from single-node scheduling to multiple layered scenarios with deterministic {{performance guarantee}}s. Potential applications are discussed at last...|$|E
40|$|In {{a recent}} study, {{frequent}} ectopy during recovery from exercise {{was reported to}} bear an increased risk for death, whereas frequent ectopy during exercise did not. We compared exercise- and recovery ECGs to corroborate the hypothesis that {{dispersion of ventricular repolarization}} is augmented during recovery. In healthy male subjects spanning a large range of fitness, we analyzed all 10 -s ECGs recorded during maximal oxygen consumption tests. We selected for every recovery ECG the best heart <b>rate-matched</b> exercise ECG in the same subject, and compared several ECG parameters between the matched ECGs. The observed recovery-exercise differences in these parameters indicate that dispersion of ventricular repolarization increases early during recovery, particularly due to increased action potential duration heterogeneity. Increased vagal tone during recovery may be the cause of this potential threat, apparently most outspoken in highly fit subjects. 1...|$|E
40|$|A {{practical}} rate-matching {{system for}} constructing rate-compatible polar codes is proposed. The proposed polar code circular buffer rate-matching {{is suitable for}} transmissions on communication channels that support hybrid automatic repeat request (HARQ) communications, {{as well as for}} flexible resource-element rate-matching on single transmission channels. Our proposed circular buffer rate matching scheme also incorporates a bit-mapping scheme for transmission on bit-interleaved coded modulation (BICM) channels using higher order modulations. An interleaver is derived from a puncturing order obtained with a low complexity progressive puncturing search algorithm on a base code of short length, and has the flexibility to achieve any desired rate at the desired code length, through puncturing or repetition. The rate-matching scheme is implied by a two-stage polarization, for transmission at any desired code length, code rate, and modulation order, and is shown to achieve the symmetric capacity of BICM channels. Numerical results on AWGN and fast fading channels show that the <b>rate-matched</b> polar codes have a competitive performance when compared to the spatially-coupled quasi-cyclic LDPC codes or LTE turbo codes, while having similar rate-dematching storage and computational complexities...|$|E
50|$|EHCI was {{designed}} to work with 32-bit or 64-bit operating systems, so it does not need a bounce buffer or IOMMU {{to work with a}} 64-bit operating system as long as a <b>rate-matching</b> hub is implemented to provide full-speed and low-speed connectivity instead of companion controllers.|$|R
40|$|A {{design of}} rate-compatible polar codes {{suitable}} for HARQ communications is proposed in this paper. An {{important feature of}} the proposed design is that the puncturing order is chosen with low complexity on a base code of short length, which is then further polarized to the desired length. A practical <b>rate-matching</b> system that has the flexibility to choose any desired rate through puncturing or repetition while preserving the polarization is suggested. The proposed <b>rate-matching</b> system is combined with channel interleaving and a bit-mapping procedure that preserves the polarization of the rate-compatible polar code family over bit-interleaved coded modulation systems. Simulation results on AWGN and fast fading channels with different modulation orders show the robustness of the proposed rate-compatible polar code in both Chase combining and incremental redundancy HARQ communications. Comment: Accepted for publication at 2015 IEEE Global Communications Conference (Globecom...|$|R
50|$|Also, SATA uses some of {{the special}} {{characters}} defined in 8b/10b. In particular, the PHY layer uses the comma (K28.5) character to maintain symbol-alignment. A specific four-symbol sequence, the ALIGN primitive, is used for clock <b>rate-matching</b> between the two devices on the link. Other special symbols communicate flow control information produced and consumed in the higher layers (link and transport).|$|R
40|$|Anecdotal {{evidence}} suggests that unfamiliar languages sound faster than one’s native language. Empirical evidence for this impression has come from explicit tempo judgments. However, it is unknown whether such perceived rate differences between native and foreign languages (FLs) have effects on implicit speech processing. Our measure of implicit perception was ‘rate normalization’: Dutch and German listeners interpret vowels midway between /ɑ/ and /a:/ more often as /a:/ if the target vowel follows a fast (vs. slow) sentence. We asked whether such a ‘rate normalization’ effect may be observed when the context is not actually faster but simply spoken in a foreign language. Dutch and German participants listened to Dutch and German (<b>rate-matched)</b> fast and slow sentences, followed by non-words that contained vowels from an /a-a:/ duration continuum. Participants indicated which vowel they heard (fap vs. faap). Across three experiments, we consistently found that German listeners reported more /a:/ responses after foreign sentences (vs. native), suggesting that foreign sentences were indeed perceived as faster. However, mixed results were found for the Dutch groups. We conclude that the subjective impression that FLs sound fast may {{have an effect on}} implicit speech processing, influencing how language learners perceive spoken segments in a FL...|$|E
40|$|Historically, {{ventricular}} demand, nonphysiologic (VVI) pacing {{has been}} the most commonly used modality to treat 3 rd-degree atrioventricular (AV) block. The goal {{of this study was to}} determine the feasibility of using a commercial, single-lead, physiologic (VDD) pacemaker in dogs with 3 rd-degree AV block. Furthermore, we hoped to characterize and identify differences in the radiographic, echocardiographic, neurohormonal, and quality of life consequences of physiologic versus nonphysiologic pacing. We evaluated 10 dogs during a 12 -week crossover study. Acutely, <b>rate-matched</b> physiologic pacing reduced pulmonary capillary wedge pressure by 19 % compared with nonphysiologic pacing. VDD pacing significantly reduced left atrial size normalized to body weight, left atrial-to-aortic root ratio, and left ventricular end-systolic dimension and increased fractional shortening, aortic Doppler velocity, cardiac output, and stroke volume compared with VVI pacing. Variable rate VDD pacing resulted in a significantly slower heart rate (HR) during echocardiography than fixed-rate (100 bpm) VVI pacing. AV synchronous pacing reduced circulating N-terminal proatrial natriuretic peptide (ANP), norepinephrine (NOR), and epinephrine (EPI) concentrations compared with asynchronous pacing. There were no significant differences in systemic blood pressure, thoracic radiographs, or owner-perceived quality of life. The median percentage of AV synchronous pacing during the VDD modality was 99. 8 % (range, 1. 2 to 99. 9 %). This study confirms the potential to achieve physiologic pacing with a commercial, single-lead system in dogs. VDD pacing improved hemodynamics and neurohormonal profiles over asynchronous pacing although the long-term clinical benefits of these changes remain to be determined. ...|$|E
40|$|AbstractOBJECTIVESThe aim of {{this study}} was to {{determine}} the time course of autonomic nervous system activity preceding ambulatory ischemic events. BACKGROUNDVagal withdrawal can produce myocardial ischemia and may be involved in the genesis of ambulatory ischemic events. We analyzed trajectories of heart rate variability (HRV) 1 h before and after ischemic events, and we examined the role of exercise and mental stress in preischemic autonomic changes. METHODSMale patients with stable coronary artery disease (n = 19; 62. 1 ± 9. 3 years) underwent 48 -h ambulatory electrocardiographic monitoring. Frequency domain HRV measures were assessed for 60 min before and after each of 68 ischemic events and during nonischemic heart <b>rate-matched</b> control periods. RESULTSHigh-frequency HRV decreased from − 60, − 20 to − 10 min before ischemic events (4. 8 ± 1. 3; 4. 6 ± 1. 3; 4. 4 ± 1. 2 ln [ms 2], respectively; p = 0. 04) and further from − 4, − 2 min, until ischemia (4. 4 ± 1. 3; 4. 1 ± 1. 3; 3. 7 ± 1. 2 ln [ms 2]; p’s < 0. 01). Low frequency HRV decreases started at − 4 min (p < 0. 05). Ischemic events occurring at high mental activities were preceded by depressed high frequency HRV levels compared with events at low mental activity (p = 0. 038 at − 4 min, p = 0. 045 at − 2 min), whereas the effects of mental activities were not observed during nonischemic control periods. Heart rate variability measures remained significantly decreased for 20 min after recovery of ST-segment depression when events were triggered by high activity levels. CONCLUSIONSAutonomic changes consistent with vagal withdrawal can act as a precipitating factor for daily life ischemia, particularly in episodes triggered by mental activities...|$|E
40|$|This paper compares two Hybrid Automatic Repeat Request (HARQ) schemes using Incremental Redundancy (IR) {{which have}} been {{proposed}} for the UMTS (W-CDMA) High Speed Downlink Shared Channel (HSDSCH). Their relative throughput performance is reported for various channel conditions. It is shown that the twostage <b>rate-matching</b> scheme has marginally worse performance compared to the alternative scheme for certain coding rates and under some channel conditions...|$|R
40|$|Abstract — This paper {{discusses}} {{circular buffer}} rate matching (CBRM) algorithms for the turbo code in the Long Term Evolution (LTE) of the WCDMA-based air interface. To enhance performance at high code rates, systematic bit puncturing {{is incorporated in}} conjunction with the CBRM. The RM algorithm is further optimized based on the algebraic properties of the QPP interleavers and the 8 -state recursive systematic convolutional code of the LTE turbo code. Index Terms — turbo codes, <b>rate-matching,</b> circular buffers, catastrophic puncturing. I...|$|R
40|$|A novel inter-frame coding {{approach}} {{to the problem of}} varying channel-state conditions in broadcast wireless communication is developed in this paper; this problem causes the appropriate code-rate to vary across different transmitted frames and different receivers as well. The main aspect of the proposed approach is that it incorporates an iterative <b>rate-matching</b> process into the decoding of the received set of frames, such that: throughout inter-frame decoding, the code-rate of each frame is progressively lowered to or below the appropriate value, prior to applying or re-applying conventional physical-layer channel decoding on it. This iterative <b>rate-matching</b> process is asymptotically analyzed in this paper. It is shown to be optimal, in the sense defined in the paper. Consequently, the data-rates achievable by the proposed scheme are derived. Overall, it is concluded that, compared to the existing solutions, inter-frame coding presents a better complexity versus data-rate tradeoff. In terms of complexity, the overhead of inter-frame decoding includes operations that are similar in type and scheduling to those employed in the relatively- simple iterative erasure decoding. In terms of data-rates, compared to the state-of-the-art two-stage scheme involving both error-correcting and erasure coding, inter-frame coding increases the data-rate by a factor that reaches up to 1. 55 x...|$|R
40|$|SUMMARY To {{assess the}} {{feasibility}} of detecting wall motion abnormalities with echocardiography during exercise-induced ischemia, we performed echocardiograms on 13 patients with angiographically documented coronary artery disease at rest and during supine bicycle exercise at increasing work loads until angina or ischemic electrocardiographic changes appeared. We analyzed echocardiographic indices of regional left ven-tricular function in these patients and 11 age- and heart <b>rate-matched</b> normal volunteers. In the 13 patients, 22 of 25 echocardiographically defined wall segments (13 septa, nine posterior left ventricular walls) were supplied by coronary arteries with> 70 % stenosis and were compared with the corresponding 22 segments from the 11 normals. Mean systolic septal thickening increased in the 22 segments of normals from 56 ± 3 % (SEM) at rest to 77 ± 7 % in exercise (p < 0. 01) while in the patients ' 22 wall segments supplied by stenotic vessels the mean value fell during peak exercise from 59 6 to 35 ± 3 % (p < 0. 005). Mean systolic posterior left ventricular wall thickening rose similarly in normals from 89 ± 9 to 115 ± 8 % (p < 0. 005) but fell during peak exercise from 75 ± 9 to 54 ± 9 % (p < 0. 01) in the patients ' nine abnormally perfused segments. Max-imal velocity of diastolic wall thinning rose from rest to exercise in the septa and posterior left ventricular walls of normals from 5. 5 ± 0. 3 to 7. 7 ± 0. 6 cm/sec (p < 0. 005) and from 8. 4 ± 0. 8 to 11. 8 ± 1. 2 cm/sec (p < 0. 001), respectively. In patients, these same indices fell at peak exercise from 5. 9 ± 0. 5 to 4. 3 ± 0. ...|$|E
40|$|Fourteen patients, aged 1 {{month to}} 13 years, with {{congenital}} semilunar valve stenosis (11 pulmonary and 3 aortic) were studied for orifice area quantification calculated from a Doppler echocardiographic equation: Area = SV/ 0. 88 × V 2 × VET, where SV = stroke volume, V 2 = maximal velocity and VET = ventricular ejection time. Results from individual measurements {{used in this}} formula and derived area were compared with individual results from cardiac catheterization and valve area derived from the Gorlin formula. Ventricular ejection time by cardiac catheterization ranged from 0. 17 to 0. 44 second (mean ± standard deviation [SD] 0. 27 ± 0. 09), and by Doppler study from 0. 20 to 0. 41 second (mean ± SD 0. 29 ± 0. 06) (r = 0. 65, standard error of the estimate [SEE] = 0. 03, y = 0. 149 + 0. 528 x). Pressure gradient by catheterization ranged from 30 to 125 mm Hg (mean ± SD 56. 6 ± 33. 1), and by Doppler study from 17. 6 to 100 mm Hg (mean ± SD 46. 8 ± 27. 9) (r = 0. 91, SEE = 8. 8, y = 1. 23 + 0. 904 x). Stroke volume was measured by Doppler study simultaneously with cardiac catheterization in nine patients; results at cardiac catheterization with thermodilution measurements (cardiac output/heart rate) ranged from 5. 5 to 53. 4 cc (mean ± SD 24. 7 ± 20), and by Doppler study from 5. 8 to 46. 9 cc (mean ± SD 23 ± 18) (r = 0. 96, SEE = 3. 5). Area quantification was performed in two ways. In Group 1, heart <b>rate-matched</b> stroke volumes from cardiac catheterization {{were used in the}} derived equation for Doppler study (all patients). In Group 2, the stroke volume used was that obtained by Doppler study, which was performed simultaneously with cardiac catheterization (nine patients). Results for Gorlin formula area quantification in Group 1 ranged from 0. 05 to 1. 42 cm 2 (mean ± SD 0. 41 ± 0. 36), and for the Doppler-derived equation in this group from 0. 05 to 0. 91 cm 2 (mean ± SD 0. 32 ± 0. 25) (r = 0. 90, SEE = 0. 08, y = 0. 053 ± 0. 665 x). When results were compared in the simultaneously studied patients, catheterization (Gorlin formula) -calculated areas ranged from 0. 05 to 1. 424 cm 2 (mean ± SD 0. 52 ± 0. 42), and for the Doppler-derived equation, areas ranged from 0. 06 to 0. 97 cm 2 (mean ± SD 0. 35 ± 0. 29) (r = 0. 94, SEE = 0. 07, y = 0. 037 ± 0. 656 x). This study shows that accurate quantification of stenotic semilunar valve orifice areas can be made by Doppler echocardiography...|$|E
50|$|Bit {{stuffing}} is {{used for}} various purposes, such as for bringing bit streams that do not necessarily have the same or rationally related bit rates up to a common rate, or to fill buffers or frames. The location of the stuffing bits is communicated to {{the receiving end of}} the data link, where these extra bits are removed to return the bit streams to their original bit rates or form. Bit stuffing may be used to synchronize several channels before multiplexing or to <b>rate-match</b> two single channels to each other.|$|R
40|$|Simulation {{is used to}} {{evaluate}} the performance of alternative service-rate controls designed to stabilize performance in a queue with time-varying arrival rate, service in order of arrival and unlimited waiting space. Both Markovian and non-Markovian models are considered. Customer service requirements are specified separately from the service rate, which is subject to control. New versions of the inverse method exploiting tables constructed outside the simulation are developed to efficiently generate both the arrival times and service times. The simulation experiments show that a <b>rate-matching</b> service-rate control successfully stabilizes the expected queue length, but not the expected waiting time, while a new square-root service-rate control, based on a assuming that a pointwise-stationary approximation is appropriate, successfully stabilizes the expected waiting time when the arrival rate changes slowly compared to the expected service time. ...|$|R
30|$|There {{is another}} {{optimization}} order where the relays are first designed {{to maximize the}} achievable sum-rates on the second hop. Then interference pricing is used {{to take into account}} the timesharing and second-hop rates in the design the transmitters to approximately maximize end-to-end achievable rates. Depending on channel realizations on two hops, one order of the optimization outperforms the other in terms of end-to-end sum-rate maximization and vice versa. We prefer our order of optimization due to overhead considerations. Specifically, as the relays themselves estimate the received SINR on the first hop, our proposed order of optimization only requires the receivers estimate and send back the second-hop SINR to the relays to perform two-hop rate matching. The other order of optimization, however, requires the relays and receivers to send back the SINR on two hops to the transmitters to perform two-hop <b>rate-matching.</b>|$|R
30|$|It {{includes}} the complete physical layer signal processing such as timing/frequency synchronization, channel estimation, subcarrier demapping, <b>rate-matching,</b> and turbo decoding. H-ARQ based on CRC of coded blocks is also enabled to support chase combine (CC) {{with up to}} three retransmissions. The bandwidth is set to be 5 MHz in the simulation, the velocity of UE is 3 [*]km/h and the scenario is urban micro [19]. Perfect synchronization and channel estimation are assumed to focus the simulation on detection performance. The Turbo decoder runs at most six iterations with early stopping. The WiMAX simulator [17] also works on 5 MHz bandwidth. Two channel coding methods used in the simulation are Reed-Solomon with Convolutional (RS-Conv) and Low-Density Parity-Check (LDPC) coding. Two channel models namely the 3 GPP SCME [19] and ITU Pedestrian B (PedB) [17] channel models are used in this paper. It is assumed the channel is quasistatic within one OFDM symbol duration. Note that the 1 -TTI latency is introduced for uplink ACK/NACK in the simulation.|$|R
40|$|The {{problem of}} {{transmission}} of information over arbitrarily permuted parallel channels is studied here. The transmitter does not know over which channel a certain code-sequence will actually be transmitted, however the receiver knows how the sequences are permuted. The permutation is arbitrary but constant during the (simultaneous) transmission of the code-sequences via the parallel channels. It is shown first that {{the sum of the}} capacities of each channel is achievable for such a communication system in the special case where the capacity achieving input distributions of all channels are identical. More important is that this sum-capacity can also be achieved using a single channel code for all channels combined with a sequential decoding method. The construction of a <b>rate-matching</b> code based on maximum distance separable (MDS) codes turns out to be crucial. Finally, the case where the parallel channels have different capacity-achieving input distributions is investigated. Also for this case the capacity is determined. Again, this capacity is achievable with a sequential decoding procedure...|$|R
40|$|In this paper, we {{describe}} the design and instantiation of a multimedia edge service architecture (MESA) for enhanced video transmission over wireless networks. MESA encompasses simple and novel <b>rate-matching</b> and shaping mechanisms as building blocks that ensure that the video rate matches the instantaneous available wire-less channel capacity at fine timescales. Designing such a rate matching scheme as a service at the wired-wireless edge (transition point) enables three distinct advan-tages: it (1) achieves high accuracy leading to bet-ter video quality, (2) facilitates immediate deployment, and (3) enables a generic design applicable to several wireless technologies, with the augmentation of a few technology-specific mechanisms. We implement a MESA prototype and evaluate it on both WiMAX and WiFi testbeds using static and mobile client scenarios. Our results show that MESA selectively drops up to 5 % low priority frames to improve the PSNR of video sessions significantly—by 7 dB on an average. By enabling a WiMAX-WiFi handover, we demonstrate that MESA adds negligible overhead to intra- and inter-technology handovers. 1...|$|R
40|$|We {{study the}} {{convergence}} of the predictive surface of regression trees and forests. To support our analysis we introduce a notion of adaptive concentration for regression trees. This approach breaks tree training into a model selection phase in which we pick the tree splits, followed by a model fitting phase where we find the best regression model consistent with these splits. We then show that the fitted regression tree concentrates around the optimal predictor with the same splits: as d and n get large, the discrepancy is with high probability bounded {{on the order of}} sqrt(log(d) log(n) /k) uniformly over the whole regression surface, where d is the dimension of the feature space, n is the number of training examples, and k is the minimum leaf size for each tree. We also provide <b>rate-matching</b> lower bounds for this adaptive concentration statement. From a practical perspective, our result enables us to prove consistency results for adaptively grown forests in high dimensions, and to carry out valid post-selection inference in the sense of Berk et al. [2013] for subgroups defined by tree leaves...|$|R
40|$|The newly defined NB-IoT {{standard}} currently lacks a toolkit and simulator. In {{order to}} develop algorithms for this new standard {{there is a need}} for channels and signals as reference during tests. MATLAB is commonly used for testing LTE signals and therefore the toolkit was developed in this environment. The toolkit focuses primarily on the Layer 1 -relevant functionality of NB-IoT, the grid generation, encoding, <b>rate-matching</b> and modulation of channels. The simulator focuses on testing the developed toolkit in a virtual LTE NB-IoT environment. The virtual environment attempts to emulate a base station and a terminal. The path followed is scheduling, channel processing, grid generation, QPSK and OFDM modulation through a modeled channel, OFDM demodulation, channel estimation, equalisation, QPSK demodulation and reversal of channel processing. The simulator tests primarily the NPDSCH channel implementations. Measurements of bit error and block error rates were made and it was concluded that they follow the expected trends. More testing is required to validate the remaining channels. A sector equaliser and an interpolating equaliser were tested by measuring block error rate and checking constellation diagrams and it was concluded that the performance of the interpolation equaliser is more consistent. In order to improve the equalisation further the noise estimation must be reworked...|$|R
40|$|The technology-push of die {{stacking}} and application-pull of Big Data {{machine learning}} (BDML) {{have created a}} unique opportunity for processing-near-memory (PNM). This paper makes four contributions: (1) While previous PNM work explores general MapReduce workloads, we identify three workload characteristics: (a) irregular-and-compute-light (i. e., perform only a few operations per input word which include data-dependent branches and indirect memory accesses); (b) compact (i. e., the computation has a small intermediate live data and uses {{only a small amount}} of contiguous input data); and (c) memory-row-dense (i. e., process the input data without skipping over many bytes). We show that BDMLs have or can be transformed to have these characteristics which, except for irregularity, are necessary for bandwidth- and energyefficient PNM, irrespective of the architecture. (2) Based on these characteristics, we propose RowCore, a row-oriented PNM architecture, which (pre) fetches and operates on entire memory rows to exploit BDMLs’ row-density. Instead of this row-centric access and compute-schedule, traditional architectures opportunistically improve row locality while fetching and operating on cache blocks. (3) RowCore employs well-known MIMD execution to handle BDMLs’ irregularity, and sequential prefetch of input data to hide memory latency. In RowCore, however, one corelet prefetches a row for all the corelets which may stray far from each other due to their MIMD execution. Consequently, a leading corelet may prematurely evict the prefetched data before a lagging corelet has consumed the data. RowCore employs novel cross-corelet flow-control to prevent such eviction. (4) RowCore further exploits its flow-controlled prefetch for frequency scaling based on novel coarse-grain compute-memory <b>rate-matching</b> which decreases (increases) the processor clock speed when the prefetch buffers are empty (full). Using simulations, we show that RowCore improves performance and energy, by 135 % and 20 % over a GPGPU with prefetch, and by 35 % and 34 % over a multicore with prefetch, when all three architectures use the same resources (i. e., number of cores, and on-processor-die memory) and identical diestacking (i. e., GPGPUs/multicores/RowCore and DRAM) ...|$|R
40|$|Next {{generation}} {{wireless communication}} systems will require support for many different applications {{as well as}} improved quality compared to existing second generation systems like GSM (Global System for Mobile communications). Since {{there will be more}} users and higher data rates, the capacity must also be increased. This thesis studies channel coding and multiuser detection, two techniques that are of vital importance for designing a flexible system with high capacity and high quality. In {{the first part of the}} thesis optimum distance spectrum (ODS) convolutional encoders are presented. These encoders generate maximum free distance codes and have superior information error weights. Results show that the ODS codes outperform previously published maximum free distance codes at no extra cost. We next use the ODS encoders as parent encoders to find large and flexible families of multirate codes. These multirate codes are obtained both by puncturing and nesting of the parent ODS codes, and are shown to perform almost as well as unpunctured codes, and to be well suited for <b>rate-matching</b> in direct-sequence code-division multiple-access (DS-CDMA) systems. A study of the performance of a number of multiuser detectors shows that such advanced receiver structures are quite sensitive to errors in phase and timing estimates. With parameter estimation errors the performance of all investigated detectors approach that of the conventional matched filter detector. This emphasizes even more the important role of channel coding in CDMA systems. A family of powerful very low-rate maximum free distance convolutional codes is found by nesting of rate 1 / 4 ODS codes. These codes are proposed for combined coding and spreading in CDMA systems, and are shown to be both more flexible and more powerful than previously known very low-rate convolutional codes. When applied in a CDMA system, we obtain significantly better performance than with a conventionally coded and spread scheme. Detailed investigations of parallel and successive interference cancellation in combination with channel code decoding show performance very close to the single user bound for the very low-rate code. All results with interference cancellation assume that decisions are taken before regeneration and subtraction of the signal. Accurate analysis of such non-linear interference cancellation is difficult. We therefore present iterative approximative analysis techniques that give results close to simulation results. Sequential decoding of convolutional codes is a suboptimum technique that makes it possible to decode very long constraint length codes and thus obtain very low error rates. We evaluate the performance of sequential decoding theoretically and by simulations for Rayleigh fading channels. A tailbiting coding scheme together with sequential decoding is proposed and shown to give improved throughput for wireless packet data transmission...|$|R
40|$|In this thesis, new {{detection}} and modulation methods for multicarrier systems are presented. The proposed multicarrier detectors {{are based on}} feedback of previously detected symbols {{and the idea is}} to exploit the correlation, both in time between consecutive symbols, and in frequency between neighboring sub-carriers. This enables us to calculate a reliable channel estimate, to be used for coherent detection. The proposed detectors have significantly lower irreducible bit error probabilities compared to a conventional differential detector. Furthermore, a Parallel Combinatory - Orthogonal Frequency Division Multiplexing (PC-OFDM) system is proposed and analyzed. Here, some of the information bits select, in each symbol interval, a subset of the available sub-carriers. The selected sub-carriers are then modulated by points from an M-PSK signal constellation. PC-OFDM systems can be designed to have lower bit error probability on Gaussian channels, lower Peak-to-Average Power Ratio (PAPR) and higher bandwidth efficiency compared to conventional OFDM systems. The thesis is further focused on convolutional channel codes of multiple rates. New high-rate encoders obtained by puncturing, and low-rate encoders obtained by nesting are presented. These new codes are rate-compatible, they have higher constraint lengths and a wider range of code rates than what has previously been presented. The new codes are applied to a multicode direct-sequence code-division multiple-access (DS-CDMA) system and are shown to provide good performance and <b>rate-matching</b> capabilities. Further presented in this thesis is a family of very low-rate convolutional codes which all have maximum free distance. This low-rate family of codes are suited for bandwidth expansion instead of conventional direct-sequence spreading in CDMA systems. The performance of a CDMA system employing these very low-rate maximum free distance codes for combined coding and spreading is analyzed when successive or parallel interference cancellation is applied in the detector. Results show that the code spread system outperforms the conventionally spread system. Without interference cancellation in a multiuser system the single-user bound is never reached (except for one user). With two stages of parallel interference cancellation, a code-spread system with a load only slightly less than 1 bit/chip obtains a bit error rate very close to that of a single user system even for rather low signal-to-noise ratios. The thesis also derives a new metric for Turbo decoding on Rayleigh fading channels with noisy channel estimates. By including the error variance of the channel estimator in the decoder metric derivation, we calculate the correct channel reliability factor for this case. The gain by using this new metric, compared to what we obtain if we ignore the uncertainty of the channel estimator, may be as large as 1 dB at a bit error probability of 0. 001...|$|R
40|$|This thesis {{focuses on}} two of the most active fields of {{chemical}} physics. One is long-range charge transfer in complex molecular systems such as DNA, and another is quantum dissipation that is about the general theory of complex molecular system. Part I is on charge transfer in DNA molecules. Starting with the introduction of the standard electron transfer theory, we overview and summarize the current research status of charge transfer in DNA in both theory and experiment in Chapter 1. To build a bridge between theoretical calculations and experimental chemical yields, Chapter 2 presents a formulation based on a superexchange-mediated sequential hopping model. An exact mapping between the stationary chemical yields and the normalized electric currents is established, followed naturally by the Ohm's law for the kinetic multistep hopping processes. To determine the coherent unistep (superexchange) contributions, the scattering matrix technique is exploited. In order to examine the possibility and effects of partially incoherent tunneling in DNA systems, a generalized scattering matrix formalism is constructed in Chapter 3. This is a generalized Büttiker phase-breaking formalism that clearly elucidates the interplay of electron resonance, coherence, dephasing, inelastic scattering, and heterogeneity effects, which are known to be physically important in long range electron transfer/transport processes. Obtained is an analytical expression of partially incoherent tunneling probability in model donor-bridge-acceptor systems with arbitrary lengths and sequences. To take the effects of electronic structure and its incoherent interaction with aqueous solution into account, Chapter 4 gives a quantum chemistry based Green’s function formulation, and thus elucidates the mechanism of long-range charge transfer in DNA double helix at a microscopic level. Semiquantitive comparisons with experiments are also obtained. Part II is about the development of quantum dissipation theory, together its application to a general topic of quantum stochastic resonance transport. After a general overview of the background knowledge in Chapter 5, a Liouville-space algebraic approach is exploited in Chapter 6 to revisit and further bridge between two most commonly used quantum dissipation theories, the Bloch-Redfield theory and Fokker-Planck equations. The nature of the common approximation scheme involving in these two theories is analyzed in detail. With the general theory built on a solid basis, the cooperative effects of driving and dissipation on transport in a model two-level system is then studied in Chapter 7. Analyzed in detail are the <b>rate-matching</b> and Rabi resonance conditions for the tunneling stochastic resonance. Large amplitude transport is found near not only the fundametal-harmonics region, but also higher harmonic resonance vicinities. Demonstrations are carried out to highlight the interplay between the strength of dissipation, and the intensity and frequency of external driving field. Finally, we make a brief summary of this thesis research, followed by a discussion of future directions toward understanding structure dynamics correlation in complex molecular systems...|$|R

