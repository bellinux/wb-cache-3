10|32|Public
40|$|A large {{irregular}} shaped aero triangulation block containing 5, 101 images, {{for which}} the projection centers have been determined by relative kinematics GPS-positioning, with 175 ground control points distributed over 112 flight strips including 18 cross strips, 81 check points evenly distributed over the entire covered area of approximately 20, 500 km 2, and 15, 455 tie points, was flown at a scale 1 : 19, 200 (1 "= 1600 '), observed and adjusted for the Delaware Valley Regional Planning Commission (DVRPC) in the United States of America. The objective was to gather up-to-date information in terms of digital orthophotographs and digital maps for the regular activities of the Commission. The approach being followed for planning, flight execution, observations, combined simultaneous <b>rigorous</b> <b>adjustment,</b> the obtained results (i. e., internal and external accuracy), the statistical analysis of the results for different control patterns, covariance analysis, elimination of systematic effects, will be described...|$|E
40|$|This paper {{summarizes}} {{a preliminary}} progress made in our ongoing R&D project concerned with {{developing a new}} paradigm for orientation and registration of SAR images. The basic idea is to replace traditional orientation procedures that use only point features with methods accommodating higher level features in general, and one-dimensional features in particular within the employed optimization frameworks of SAR-imagery orientation. Our major strands in this paper are first, to motivate the use of Feature-Based Photogrammetry (FBP) methods particularly as they pertain to support autonomous orientation and registration of SAR images and secondly to present a mathematically and stochastically <b>rigorous</b> <b>adjustment</b> model to accommodate such features explicitly. While this project is just at its very preliminary stages, the new ideas it brings will definitely {{open the door for}} FBP techniques, originally developed for frame imagery, to evolve and have a great impact on other remote sensing technologies. 1...|$|E
40|$|Background Leg length {{inequality}} (LLI) {{was identified}} as a problem of total hip arthroplasty soon after its introduction. Leg lengthening is {{the most common form of}} LLI. Possible consequences are limping, neuronal dysfunction and aseptic component loosening. LLI can result in an increased strain both on the contralateral hip joint and on the abductor muscles. We assessed the influence of leg lengthening and shortening on walking capacity, hip pain, limping and patient satisfaction at 2 -year follow-up. Methods 478 cases with postoperative lengthening and 275 with shortening were identified, and matched with three controls each. <b>Rigorous</b> <b>adjustment</b> for potential differences in baseline patient characteristics was performed by propensity-score matching of covariates. The arbitrarily defined desired outcomes were a walking capacity > 60 minutes, no hip pain, no limping, and excellent patient satisfaction. Differences in not achieving the desired outcomes between the groups were expressed as odds ratios. Results In the lengthened case group, the odds ratio for not being able to walk for an hour was 1. 70 (95...|$|E
40|$|The generous {{mortgage}} {{tax relief}} enjoyed in the Netherlands {{and the possible}} existence of a house price bubble cannot explain the sharp decrease of house prices in the Netherlands in the period from 2011 – 2013. This sharp decline can, however, {{be explained by the}} <b>rigorous</b> <b>adjustments</b> to mortgage lending criteria after 2011. Key financial institutions in the Netherlands were more directly responsible for the deep crisis of the home-ownership market during this period. This was largely due to the specific interests of these organisations, mainly based on macro-economic considerations and the desire to enlarge the equity of the banks, which outweighed the problems on the housing market. </p...|$|R
40|$|Motivation: 16 S rDNA {{pyrosequencing}} is {{a powerful}} approach that requires extensive usage of computational methods for delineating microbial compositions. Previously, it was shown that outcomes of studies relying on this approach vastly depend on the choice of pre-processing and clustering algorithms used. However, obtaining in-sights into the effects and accuracy of these algorithms is challeng-ing due to difficulties in generating samples of known composition with high enough diversity. Here, we employ in silico microbial da-tasets to better understand how the experimental data are trans-formed into taxonomic clusters by computational methods. Results: We were able to qualitatively replicate the raw experi-mental pyrosequencing data after <b>rigorous</b> <b>adjustments</b> on existing simulation software. This allowed us to simulate datasets of real-life complexity, which we {{used to assess the}} influence and performanc...|$|R
40|$|Abstract. This paper {{presents}} {{a method for}} measuring total station coordinate traverse, and the method of using indirect <b>adjustment</b> and <b>rigorous</b> indirect <b>adjustment</b> with restrictions Based on Visual Studio 2010 programming environment,use C # programming language，GDI + graphics processing and software engineering technology to research related program design. The Program is designed to achieve the automation, intelligence and high precision of outcome traverse adjustment...|$|R
40|$|French Research vessels {{have been}} {{collecting}} thermo-salinometer (TSG) data since 1999 {{to contribute to}} the Global Ocean Surface Underway Data (GOSUD) programme. The instruments are regularly calibrated and continuously monitored. Water samples are taken on a daily basis by the crew and later analysed in the laboratory. We present here the delayed mode processing of the 2001 – 2013 dataset and an overview of the resulting quality. Salinity measurement error was a few hundredths of a unit or less on the practical salinity scale (PSS), due to careful calibration and instrument maintenance, complemented with a <b>rigorous</b> <b>adjustment</b> on water samples. In a global comparison, these data show excellent agreement with an ARGO-based salinity gridded product. The Sea Surface Salinity and Temperature from French REsearch SHips (SSST-FRESH) dataset is very valuable for the ‘calibration and validation ’ of the new satellite observations delivered by the Soil Moisture and Ocean Salinity (SMOS) and Aquarius missions. Design Type(s) observation design • data integration objective Measurement Type(s) sea surface salinity • sea surface temperature Technology Type(s) thermo-salinomete...|$|E
40|$|This thesis {{investigated}} {{the effects of}} daily changes in exposure (delta) and short-term exposure patterns {{on the relationship between}} air pollution and health in time series studies. Using data from London and Hong Kong, delta was defined as the difference in particulate matter (PM 10) concentration between successive days. Short-term exposure pattern series were defined based on number of peaks in PM 10 within rolling weekly blocks. The mathematical equivalence of identifiable models for delta with conventional distributed lag model was derived and alternative model specifications were proposed. Measurement error and missing data exhibited more impact on delta than the absolute metrics in simulation studies. Evidence of association for delta PM 10 with mortality was found only in Hong Kong which attenuated towards the null with more <b>rigorous</b> <b>adjustment</b> for weather. The pattern analysis approach hypothesized, in addition to amount (dose) and duration of exposure, epidemiological studies ought to take patterns of exposure into account. However, convincing evidence was not found for the effect of short-term exposure patterns on mortality risk estimates both in London and Hong Kong. Refining the definition of exposure patterns and methodological improvements including analysing data from multiple cities are highly recommended in related studies in the future...|$|E
40|$|The {{algorithm}} of {{the strict}} adjustment of horizontal geodetic networks using least square adjustment method {{is well known}} and widely described in the literature. Referring to the Regulation of the minister of administration and digitization of 14 February 2012 on geodetic, gravimetric and magnetic control networks, which is in force in Poland, the authors {{draw attention to the}} important provision contained in this Ordinance: Observa-tions should be adjusted using a <b>rigorous</b> <b>adjustment,</b> based on least square adjustment method, assuming zero variance for references points. Assumption of zero standard deviations for references points causes that, despite net-work adjustment process is rigorous, results obtained, both adjusted coordinates and the assessment of the accuracy of the coordinates, depend on the method of establishing the network, the number of points and the actual accuracy of references points. On the ex-ample of the small test network, there was demonstrated how important differences can be. The only {{solution to the problem of}} the ambiguity of the results of strict network ad-justment is taking into account the accuracy of references points. It should be noted that the coordinates of references points can be a result of adjustment of various networks in various time periods, so they can be determined with various precision. Taking into ac-count this fact can only be done by determining reliable relationship between weights of observations and coordinates of references points. This research was financed by the Department of Geomatics of the AGH University of Science and Technology in Kraków statutory research funds. Edward Prewed...|$|E
40|$|The {{simultaneous}} {{adjustment of}} very large nets of overlapping plates covering the celestial sphere becomes computationally feasible {{by virtue of}} a twofold process that generates a system of normal equations having a bordered-banded coefficient matrix, and solves such a system in a highly efficient manner. Numerical results suggest that when a well constructed spherical net is subjected to a <b>rigorous,</b> simultaneous <b>adjustment,</b> the exercise of independently established control points is neither required for determinancy nor for production of accurate results...|$|R
40|$|The SMX 4500 {{laser tracker}} has proven {{itself to be}} a {{beneficial}} addition to SLAC's set of alignment tools. Through actual field surveys and laboratory testing, a question regarding some unknown scale factor appearing after adjusting the combined tracker and total station results arose. Through a simple line survey and instrument analysis and then progressing through more and more <b>rigorous</b> network <b>adjustments,</b> the authors deduced that the apparent scale problem was in fact more likely attributed to wrong offset values introduced into the adjustment by mixing TC 2002 total station data with the laser tracker measurements. A recalibration procedure of all of SLAC's total station prisms was designed and analyzed...|$|R
40|$|These authors contributed {{equally to}} this work. The aims {{of this study}} were: (i) to {{determine}} to what degree multiple sclerosis-associated loci discovered in European populations also influence susceptibility in African Americans; (ii) to assess {{the extent to which}} the unique linkage disequilibrium patterns in African Americans can contribute to localizing the functionally relevant regions or genes; and (iii) to search for novel African American multiple sclerosis-associated loci. Using the ImmunoChip custom array we genotyped 803 African American cases with multiple sclerosis and 1516 African American control subjects at 130 135 autosomal single nucleotide polymorphisms. We con-ducted association analysis with <b>rigorous</b> <b>adjustments</b> for population stratification and admixture. Of the 110 non-major histo-compatibility complex multiple sclerosis-associated variants identified in Europeans, 96 passed stringent quality control in our African American data set and of these, 470 % (69) showed over-representation of the same allele amongst cases, including 21 with nominally significant evidence for association (one-tailed test P 5 0. 05). At a further eight loci we found nominally significant association with an alternate correlated risk-tagging single nucleotide polymorphism from the same region. Outside the regions known to be associated in Europeans, we found seven potentially associated novel candidate multiple sclerosis variants (P 5 104), one of which (rs 2702180) also showed nominally significant evidence for association (one-tailed test P = 0. 034) in an independent second cohort of 620 African American cases and 1565 control subjects. However, none of these novel associations reached genome-wide significance (combined P = 6. 3 105). Our data demonstrate substantial overlap between African American an...|$|R
40|$|BACKGROUND: In this study, we {{primarily}} investigated whether ICU admission or ICU stay at weekends (Saturday and Sunday) {{is associated}} with a different risk of ICU mortality or chance of ICU discharge than ICU admission or ICU stay on weekdays (Monday to Friday). Secondarily, we analysed whether weekend ICU admission or ICU stay influences risk of hospital mortality or chance of hospital discharge. METHODS: A retrospective study was performed for all adult patients admitted to 119 ICUs participating in the benchmarking project of the Austrian Centre for Documentation and Quality Assurance in Intensive Care (ASDI) between 2012 and 2015. Readmissions to the ICU during the same hospital stay were excluded. RESULTS: In a multivariable competing risk analysis, a strong weekend effect was observed. Patients admitted to ICUs on Saturday or Sunday had a higher mortality risk after adjustment for severity of illness by Simplified Acute Physiology Score (SAPS) 3, year, month of the year, type of admission, ICU, and weekday of death or discharge. Hazard ratios (95 % confidence interval) for death in the ICU following admission on a Saturday or Sunday compared with Wednesday were 1. 15 (1. 08 - 1. 23) and 1. 11 (1. 03 - 1. 18), respectively. Lower hazard ratios were observed for dying on a Saturday (0. 93 (0. 87 - 1. 00)) or Sunday (0. 85 (0. 80 - 0. 91)) compared with Wednesday. This is probably related to the reduced chance of being discharged from the ICU at the weekend (0. 63 (0. 62 - 064) for Saturday and 0. 56 (0. 55 - 0. 57) for Sunday). Similar results were found for hospital mortality and hospital discharge following ICU admission. CONCLUSIONS: Patients admitted to ICUs at weekends are at increased risk of death in both the ICU and the hospital even after <b>rigorous</b> <b>adjustment</b> for severity of illness. Conversely, death in the ICU and discharge from the ICU are significantly less likely at weekends. info:eu-repo/semantics/publishedVersio...|$|E
40|$|Abstract Background Leg length {{inequality}} (LLI) {{was identified}} as a problem of total hip arthroplasty soon after its introduction. Leg lengthening is {{the most common form of}} LLI. Possible consequences are limping, neuronal dysfunction and aseptic component loosening. LLI can result in an increased strain both on the contralateral hip joint and on the abductor muscles. We assessed the influence of leg lengthening and shortening on walking capacity, hip pain, limping and patient satisfaction at 2 -year follow-up. Methods 478 cases with postoperative lengthening and 275 with shortening were identified, and matched with three controls each. <b>Rigorous</b> <b>adjustment</b> for potential differences in baseline patient characteristics was performed by propensity-score matching of covariates. The arbitrarily defined desired outcomes were a walking capacity > 60 minutes, no hip pain, no limping, and excellent patient satisfaction. Differences in not achieving the desired outcomes between the groups were expressed as odds ratios. Results In the lengthened case group, the odds ratio for not being able to walk for an hour was 1. 70 (95 % CI 1. 28 - 2. 26) for cases compared to controls, and the odds ratio for having hip pain at follow-up was 1. 13 (95 % CI 0. 78 - 1. 64). The odds ratio for limping was 2. 08 (95 % CI 1. 55 - 2. 80). The odds ratio for not achieving excellent patient satisfaction was 1. 67 (95 % CI 1. 23 - 2. 28). In the shortening case group, the odds ratio for not being able to walk for an hour was 1. 23 (95 % CI 0. 84 - 1. 81), and the odds ratio for having hip pain at follow-up was 1. 60 (95 % CI 1. 05 - 2. 44). The odds ratio for limping for cases was 2. 61 (95 % CI 1. 78 - 3. 21). The odds ratio for not achieving excellent patient satisfaction was 2. 15 (95 % CI 1. 44 - 3. 21). Conclusions Walking capacity, limping and patient satisfaction were all significantly associated with leg lengthening, whereas pain alleviation was not. In contrast, hip pain, limping and patient satisfaction were all significantly associated with leg shortening, whereas walking capacity was not. </p...|$|E
40|$|Height {{differences}} from geometric leveling, gravity and GPS measurements carried out from 1979 until {{now in the}} network of Volvi area are systematically analyzed. Various methods and algorithmic techniques based on integrated approach are rigorously applied in order to extract a more reliable estimation of the vertical components of the deformation field. Signals, i. e. the gravity field parameters, their variations in time and the vertical displacements are treated in a combined analytical-stochastic approach. Finally {{the interpretation of the}} results at the interesting area of the Volvi Lake is attempted. The estimation of displacement and especially the height differences at Volvi area is very important in Greece due to its seismic activity. Volvi area is located at northern Greece (Central Macedonia) and 40 Km from the city of Thessaloniki. Volvi take up an area of 10 X 15 km including two lakes (Lagada and Volvi) and is considered as a geodynamically interesting area. The largest earthquake took place in May 23, 1978 (Ms= 5. 8), June 19, 1978 (Ms= 5. 2) and June, 20 1978 (Ms= 6. 2) followed by a series of postseismic activity affected socially and financially the city of Thessaloniki. In order to study the geodynamical behaviour and investigate the crustal movements a geodetic and gravimetric network was established with 16 and 26 pillars respectively. Classical measurements are available for the epoch 1979, gravity measurements took place in 1979 and 1999 while GPS measurements performed in 1994, 1995, 1996 and 2003. Integrated geodesy in time deals with the analysis of the above observations for the study of network geometry and its variation with time, when these observations depend on the gravity field of the earth and its temporal variation. Integrated adjustment has been introduced as a <b>rigorous</b> <b>adjustment</b> of observations with both geometric and gravimetric information using precise mathematical goals. Furthermore, integrated geodesy is a method for the adjustment of observations depending not only on discrete parameters but also on unknown functions. Parameters appearing in the mathematical model can be treated as: a) deterministic b) stochastic c) analytical - stochastic way and these leads to an adjustment with signals. Geodetic-gravimetric network deals with GPS baselines, leveling and gravity observations in different epochs so orthometric heights are much easier to calculate. The object of the present dissertation is the simultaneously analysis of GPS baselines with classical geodetic observations (angles and height differences) and physical data related to the gravity field (deviations of the vertical, intensity of gravity field) and/or seismological data (geophysical model, P waves) with models of integrated geodesy, having as main purpose the estimation of orthometric heights. In the first chapter informations are given about the reference frames and the relationships between them. An extensive reference is made to concepts and definitions in relation with heights. In the second chapter modelling alternatives in deformation measurements are given. In the third chapter the linearized observation equations are analyzed for the global positioning system GPS, height differences, gravity and seismic waves. In the fourth chapter analytical and stochastic models are presented for vertical movements. Moreover, in the fifth chapter the covariance of the gravity field is given and the models of the covariance functions are presented (exponential, Reilly, Moritz, Poisson). In the six chapter the height differences in Volvi area is presented. Signals s take for granted that are unchangeably from 1994 unit 2003 but gravity measurements which took place in 1979 and 1999 are changed since points are moved. That simplifies the mathematical model and makes calculations easier. In the end, we will define integrated geodesy as a powerful mathematical tool which manipulates physical and geometrical observations measured in different epochs making signal connection by the covariance gravity model. Height differences calculated with high accuracy. Also, the biggest height differences occurred near to points which indicate the epicentre of the earthquakes. In the seven chapter conclusions are given coming from different solutions. ...|$|E
40|$|Nowadays {{there are}} a lot of changes in the {{transport}} business. To keep in an advantageous position a region must stay competitive and operate as a crucial link in the chain of logistics. The VenIo region is such an area, which has to compete with other regions to have the best position concerning the transport business. Therefore this thesis has been made, to analyse the VenIo region on its way to a second line logistic node. In this thesis it is proved by results of a questionnaire that the VenIo region is definitely on its way to a second line logistic node. On the moment the region develops strategies to keep competitive. The region does this by developments in the infrastructural environment. The best way to develop a thorough logistic node is to construct an infrastructure of road, rail, waterway and industrial areas that is united in one strategy. The latest development on this moment is the modal shift of road transport. This modal shift requires a good inter/multimodal logistic node where these activities can take place. In this research the VenIo region appeared to be a good logistic node where this can take place. The infrastructure is of a good capacity level and well developed and can play an international role. Only the infrastructure of the waterways turned out to be insufficient developed, not enough capacity and it cannot function as an international infrastructure. Because of two reasons one has to invest in the infrastructure of waterways. The first is because with an easy expansion the capacity can be increased without <b>rigorous</b> <b>adjustments</b> in the infrastructure. The second reason is that with an expansion of the waterway infrastructure a modal shift can take place as desired. These developments make it possible for the VenIo region to grow into a 2 "" line logistic node. The most important issue, the region has to pay attention to is that the region will not congest and the development will not stagnate...|$|R
40|$|In {{order to}} solve certain special CERN {{metrology}} problems, analytical terrestrial photogrammetry {{may have some}} advantages which are first discussed along with their drawbacks and limitations. In this application, {{it is necessary to}} carry out a <b>rigorous</b> and global <b>adjustment</b> of the observations and simultaneously process all the perspective ray bundles. The basic principles, the least squares solution and the stochastic analysis of the results are presented. However, for the CERN project, one wonders if the production of digital theodolites is going to reduce the advantages of the photogrammetric method. (12 refs) ...|$|R
40|$|Photogrammetric network {{design is}} the process of {{optimizing}} a network configuration in terms of the accuracy of object-points. This accuracy is improved by selecting the best set of intersection rays in a bundle adjustment. This paper explains the approach followed to achieve the development of a practical network design using a real robotic system. The aim is to integrate a simulation-based network design into a practical vision metrology system. The simulation is carried out with a population search metaheuristic inspired by the evolutionary computing paradigm. The proposed approach uses an analytical criterion to search for a suitable first order design in a fraction of the computational time required by the evolutionary approach using a <b>rigorous</b> bundle <b>adjustment.</b> The combination of an evolutionary algorithm simulation with the very well-established bundle adjustment provides a straightforward approach to network design. An example of a photogrammetric network design is provided to illustrate the result of a complete network design...|$|R
40|$|After birth, our {{gastrointestinal}} (GI) tract is colonized by {{a highly}} complex assemblage of microbes, collectively termed the GI microbiota, that develop intimate interactions with our body. Recent {{evidence indicates that}} the GI microbiota and its products {{may contribute to the}} development of obesity and related diseases. This, coupled with the current worldwide epidemic of obesity, has moved microbiome research into the spotlight of attention. Although the main cause of obesity and its associated metabolic complications is excess caloric intake compared with expenditure, differences in GI tract microbial ecology between individuals might be an important biomarker, mediator or even new therapeutic target. Nevertheless, it is currently still unclear which bacterial groups play a role in the development of the metabolic syndrome in humans. This might partly be explained by: 1. Biological factors such as the heterogeneity in genotype, lifestyle, diet; and the often complex aetiology of human disease of which the metabolic syndrome is no exception. 2. Technological factors, such as the use of miscellaneous incompatible methods to assess the gut microbiota, often enumerating specific groups rather than using broad 16 S rRNA gene surveys or metagenomics. 3. Studies vary greatly in the populations considered, their designs, and the degree of control for potential confounding factors such as lifestyle and diet. Nevertheless, recent research on this matter has shown a conceptual shift by focusing on more homogenous subpopulations, based on stricter control over variables such age range or through the use of both anthropometric (weight, total body fat) as well as biochemical variables (insulin resistance, hyperlipidaemia) to define groups. Perturbations in microbial diversity and community structure in adults with overweight and obesity may be partly due to long-term dietary habits or physiological changes in these subjects. As such, exploring the association between the gut microbiota and variation in BMI and weight in early life, prior to or close to the onset of overweight, might provide additional insights into these processes. Therefore, we studied the fecal microbiota of 295 six-seven year old children from the KOALA Birth Cohort, living in the south of the Netherlands. This age range is relatively uncharted microbiota territory. We found that its composition seems to conform to tot same ecosystem rules as that of adults. The bimodal distribution pattern of several bacterial groups as well as their co-correlating groups that were reported previously, including Uncultured Clostridiales II (UCII), Prevotella spp. and Dialister were confirmed. Furthermore, one of the previously described bimodal groups (Uncultured Clostridiales I) was shown before to exhibit very clear shifting state probabilities associated with ageing, where the high abundance state was mainly observed above 40 years of age. This was corroborated as no support for bimodality of this group was observed in the children included in the study described here. A large part of the variation in microbiota composition was explained by the abundance of aforementioned groups in contrast to the anthropometric outcomes, suggesting that in this group of healthy children within a relatively normal weight range, weight and associated parameters were not major drivers of overall genus-level microbial composition or vice versa. Hereafter, multiple linear and logistic regression models with <b>rigorous</b> <b>adjustment</b> for confounders were applied to investigate individual microbiota features association with weight related anthropometric outcomes. Previously reported parameters such as diversity, richness and Bacteroidetes to Firmicutes ratio, were not significantly associated with any of the outcomes. Nevertheless, the abundance of several specific bacterial taxa; Akkermansia, Sutterella wadsworthia et rel. and Bryantella formatexigens et rel. and the dichotomous abundance state of the bi-modally distributed UCII was consistently associated with weight-related outcomes. Other biochemical features of the metabolic syndrome have been associated with the gut microbiome. Mainly rodent studies have indicated that antibiotic treatment may improve glucose homeostasis and metabolic impairments. Therefore, the effects of gut microbiota manipulation by antibiotics (7 d administration of amoxicillin, vancomycin or a placebo) on tissue-specific insulin sensitivity, energy metabolism, gut permeability and inflammation in 57 obese, pre-diabetic men from the same geographical region, were investigated. Vancomycin decreased bacterial diversity and significantly reduced well known butyrate- producing Firmicutes from Clostridium clusters IV and XIVa and bacterial groups involved in bile acid metabolism. These changes occurred concomitantly with altered plasma and fecal concentrations of these metabolites. In adipose tissue, gene expression of oxidative pathways was upregulated by antibiotics, whereas immune-related pathways were downregulated by vancomycin. However, antibiotic treatment had no significant effects on tissue-specific insulin sensitivity, energy/substrate metabolism, postprandial hormones and metabolites, systemic inflammation, gut permeability and adipocyte size. Importantly, despite a still considerably altered microbial composition at eight weeks follow-up, energy harvesting, adipocyte size and whole-body insulin sensitivity (HOMA-IR) remained unaltered. Overall these data indicate that interference with adult microbiota by antibiotic treatment for 7 days had no clinically relevant impact on metabolic health in obese humans. These data are in contrast with several rodent studies as well as a human intervention. The present study, which was well-powered and placebo-controlled, indicates that the previously reported vancomycin-induced effects on human peripheral insulin sensitivity are probably of minor physiological significance. The aforementioned group that was relatively homogeneous with regards to phenotype was combined with another cohort with similar phenotypical characteristics (obese, male and pre-diabetic) from another region of the Netherlands, to investigate whether tissue specific insulin sensitivity, as measured by the golden standard hyperinsulinemic-euglycemic clamp technique, is related to a specific microbial pattern. Remarkably, despite the fact that both cohorts were constructed based on comparable recruitment strategies, the average microbiota composition in both cohorts showed pronounced differences. Firstly, we found no consistent and significant association between liver, adipose tissue or skeletal muscle insulin sensitivity and the microbiota in both cohorts. Nevertheless, Random Forests classifiers using microbiota composition as predictors revealed taxa associated with fasting glucose concentrations and HbAc 1 but only in one cohort. The top microbial features distinguishing classes were different Proteobacteria and groups involved in butyrogenesis, such as Faecalibacterium prausnitzii, Roseburia intestinalis, and Eubacterium rectale and related species, for fasting glucose levels. For HbAc 1 these taxa were Oscillospira guillermondii, Sporobacter termitidis, Lactobacillus gasseri and Peptococcus niger and related species. The striking cohort-specific observations suggest that the relation between microbiota composition and type 2 diabetes mellitus as well as other characteristics of the metabolic syndrome is very dependent on the selected cohort of patients and their respective baseline microbiota composition. Similar observations have been made by other researchers as well. It could be that differences in microbiota composition are not associated with the insulin resistance phenotype when the overweight and/or obese state of the patient is already established, as is the case for our metabolic syndrome patients. In the latter case we cannot exclude that the composition of the fecal microbiota may play a role in the worsening of insulin sensitivity in an early stage in the development from a lean towards an overweight/obese phenotype. Furthermore, the observation of a subgroup- specific microbiota only observed in one of the cohorts might indicate an alternative state of microbiota composition driven by yet unknown forces. Nevertheless, this study clearly demonstrated that cohort-specific microbiota differences hamper finding a consensus biological interpretation between cross-sectional studies. This, combined with the complexity of individual disease pathogenesis, as well as the individual-specific differences in microbiota composition, may explain the inconsistency in observations between different studies concerning the identification of signature microbes for obesity, irritable bowel syndrome and other diseases. Besides the biological drivers for cohort specific inconsistencies in identified microbial biomarkers, there are also technological factors. Although high-throughput sequencing of short, hypervariable segments of the 16 S ribosomal RNA (rRNA) gene has transformed the methodological landscape describing microbial diversity within and across complex biomes, evidence is increasing that methodology rather than the biological variation is responsible for observed sample composition and distribution. Large meta-analyses would aid in elucidating whether the basis for these observed inconsistencies is biological, technical or maybe a combination of both. To facilitate these meta-analyses of microbiota studies we developed NG-Tax, a pipeline for 16 S rRNA gene amplicon sequence analysis that was validated with different Mock Communities (MC). NG-Tax demonstrated high robustness against choice of region and other technical biases associated with 16 S rRNA gene amplicon sequencing studies. The analysis of α- and β-diversity of these MC confirmed conclusions guided by biology rather than the methodological aspects. This pipeline was applied to biological samples to monitor the developing communities an in vitro gut model (TIM- 2) fed either with a normal diet, or modified versions from which the carbohydrate (MPLC) or protein fraction was diluted (LPMC) for 72 h. In combination with global metatranscriptomics and metabolomics this revealed that each diet produced distinct microbial communities and temporal patterns and ratios of metabolites. The microbiota in reactors fed diets containing normal carbohydrate levels were enriched in members of the genera Prevotella, Subdoligranulum, Blautia and Bifidobacterium, all associated with carbohydrate fermentation. In turn, the microbiota in the reactors fed the MPLC diet, containing ten-fold less carbohydrates, was enriched in the genus Bacteroides, which is associated with diets rich in protein and animal fat. This setup allows researchers to study the (trophic) interactions and task division within a community and how they are impacted by diet-related factors under controlled conditions, which may assist in defining causal links between specific diet-derived parameters microbial groups and their activities. In conclusion, currently it seems that GI microbiota based biomarkers associated with metabolic impairments and anthropometric variables associated with the metabolic syndrome are cohort specific or possibly individual, which could partly be due to the use of incompatible analytical approaches. Nevertheless, there is growing evidence that human health is a collective property of the human body and its associated microbiome and thus requires to study the interface of two very complex systems, i. e. on one side the extraordinary coding capacity, high inter-individuality and complex dynamics of the microbiome and on the other side the multifactorial individual nature of human disease. In light of these observations the manifestation of individual dynamics of the microbiota with the host when homeostasis is lost seems plausible and likely...|$|E
40|$|This paper {{describes}} the geometric accuracy {{testing of the}} IRS- 1 D and SPOT- 4 images when combining together as stereo, over a test field in Zanjan province in the west part of Iran. For reconstruction of the image orientation we have used two different models: (i) a <b>rigorous</b> bundle <b>adjustment</b> program using an orbital parameters model and (ii) a generalized sensor model as rational function model. These models have already been tested for stereo SPOT Level 1 A, Level 1 B, IRS- 1 C, MOMS- 02, as well as IKONOS. These mathematical models and analytical photogrammetric solution are first described in brief. This {{is followed by the}} results of the various 3 D geometric accuracy tests carried out with these images using different sets and combinations of control and check points. The GCPs for these tests are extracted from 1 : 25, 000 scale topographic maps produced by National Cartographic Centre (NCC) of Iran using 1 : 40, 000 scale aerial photographs. Finally an analysis of the results is given...|$|R
40|$|The {{purpose of}} this study was to warn the dental {{community}} about a possible problem in function with partial implant-supported prostheses used for long periods. The misalignment between natural teeth and the implant-supported prosthesis on teeth 11 and 12, observed in a 14 -year clinical follow-up, illustrates the fact. The metal-ceramic crowns were placed in 1995 after a <b>rigorous</b> occlusal <b>adjustment.</b> Evaluations were made at 4, 6, 9, and 14 years, when it was noticed that the restorations were positioned palatally and extruded in comparison with the natural teeth. After 9 years, a greater discrepancy was noticed, with anterior occlusion and esthetic changes. The possible causes have been discussed: occlusal problems, parafunctional habits, and natural movement. The first 2 options were discarded after clinical analysis and diagnosis. Therefore, the natural movement probably deriving from an interaction of mechanical and genetic factors might have been the cause. The implants do not have periodontal ligaments but rather ankylosis, so they do not suffer those movements. This case emphasizes the need to inform patients that implants can last more than 10 years in function, but this is not the case with restorations, which lose function and esthetics and must be replaced...|$|R
40|$|Orthostatic {{hypotension}} (OH) is {{a common}} cause of transient cerebral hypoperfusion in the population. Cerebral hypoperfusion is widely implicated in cognitive impairment, but whether OH contributes to cognitive decline and dementia is uncertain. We aimed to determine the association between OH {{and the risk of}} developing dementia in the general population. Between 4 October 1989 and 17 June 1993, we assessed OH in non-demented, stroke-free participants of the population-based Rotterdam Study. OH was defined as a ≥ 20 mm Hg drop in systolic blood pressure (SBP) or ≥ 10 mm Hg drop in diastolic blood pressure (DBP) within 3 min from postural change. We furthermore calculated within participant variability in SBP related to postural change, expressed as coefficient of variation. Follow-up for dementia was conducted until 1 January 2014. We determined the risk of dementia in relation to OH and SBP variability, using a Cox regression model, adjusted for age; sex; smoking status; alcohol intake; SBP; DBP; cholesterol:high-density lipoprotein ratio; diabetes; body mass index; use of antihypertensive, lipid-lowering, or anticholinergic medication; and apolipoprotein E genotype. Finally, we explored whether associations varied according to compensatory increase in heart rate. Among 6, 204 participants (mean ± standard deviation [SD] age 68. 5 ± 8. 6 y, 59. 7 % female) with a median follow-up of 15. 3 y, 1, 176 developed dementia, of whom 935 (79. 5 %) had Alzheimer disease and 95 (8. 1 %) had vascular dementia. OH was associated with an increased risk of dementia (adjusted hazard ratio [aHR] 1. 15, 95 % CI 1. 00 - 1. 34, p = 0. 05), which was similar for Alzheimer disease and vascular dementia. Similarly, greater SBP variability with postural change was associated with an increased risk of dementia (aHR per SD increase 1. 08, 95 % CI 1. 01 - 1. 16, p = 0. 02), which was similar when excluding those who fulfilled the formal criteria for OH (aHR 1. 08, 95 % CI 1. 00 - 1. 17, p = 0. 06). The risk of dementia was particularly increased in those with OH who lacked a compensatory increase in heart rate (within lowest quartile of heart rate response: aHR 1. 39, 95 % CI 1. 04 - 1. 85, p-interaction = 0. 05). Limitations of this study include potential residual confounding despite <b>rigorous</b> <b>adjustments,</b> and potentially limited generalisability to populations not of European descent. In this population predominantly of European descent, OH was associated with an increase in long-term risk of dementia...|$|R
40|$|We {{present a}} novel {{approach}} for a <b>rigorous</b> bundle <b>adjustment</b> for omnidirectional and multi-view cameras, which enables an efficient maximum-likelihood estimation with image and scene points at infinity. Multi-camera systems are used to increase the resolution, to combine cameras with different spectral sensitivities (Z/I DMC, Vexcel Ultracam) or – like omnidirectional cameras – to augment the effective aperture angle (Blom Pictometry, Rollei Panoscan Mark III). Additionally multi-camera systems gain in importance for the acquisition of complex 3 D structures. For stabilizing camera orientations – especially rotations – one should generally use points at the horizon {{over long periods of}} time within the bundle adjustment that classical bundle adjustment programs are not capable of. We use a minimal representation of homogeneous coordinates for image and scene points. Instead of eliminating the scale factor of the homogeneous vectors by Euclidean normalization, we normalize the homogeneous coordinates spherically. This way we can use images of omnidirectional cameras with single-view point like fisheye cameras and scene points, which are far away or at infinity. We demonstrate the feasibility and the potential of our approach on real data taken with a single camera, the stereo camera FinePix Real 3 D W 3 from Fujifilm and the multi-camera system Ladybug 3 from Point Grey. ...|$|R
40|$|BACKGROUND: Disease {{management}} has been implemented {{for patients with}} asthma in various ways. We describe the approaches to and components of adult asthma disease-management interven-tions, examine the outcomes evaluated, and assess the quality of published studies. METHODS: We searched the MEDLINE, EMBASE, CINAHL, PsychInfo, and Cochrane databases for studies pub-lished in 1986 through 2008, on adult asthma management. With the studies that met our inclusion criteria, we examined the clinical, process, medication, economic, and patient-reported outcomes re-ported, and the study designs, provider collaboration during the studies, and statistical methods. RE-SULTS: Twenty-nine articles describing 27 studies satisfied our inclusion criteria. There was great variation in the content, extent of collaboration between physician and non-physician providers respon-sible for intervention delivery, and outcomes examined across the 27 studies. Because of limitations {{in the design of}} 22 of the 27 studies, the differences in outcomes assessed, and the lack of <b>rigorous</b> statistical <b>adjustment,</b> we could not draw definitive conclusions about the effectiveness or cost-effectiveness of the asthma disease-management programs or which approach was most effective. CONCLUSIONS: Few well-designed studies with rigorous evaluations have been conducted to evaluate disease-management interventions for adults with asthma. Current evidence is insufficient to recommend any particular intervention. Key words: asthma, disease management, outcomes, study design, study quality. [Respir Car...|$|R
40|$|This paper details GPS surveys {{undertaken}} in Falls Creek Ski Resort for a research project. Static, rapid-static and RTK GPS surveys were undertaken {{to establish a}} framework of accurate positional points with in the study area. Campaigns involved control surveys, coordination of photo control and elevation profiles, utilising the different GPS positioning techniques listed. The logistical problems of coordinating survey marks in areas of sparse survey control, deploying photo control targets over snow for image acquisition are discussed. The imagery acquired, in both winter (snow cover) and spring (no-snow cover), was later used to create surface models. The required positional accuracies resulting from the GPS surveys, for the photogrammetric validation purposes, were < 20 mm for both Easting and Northing (MGA 94, Zone 55), and < 50 mm for elevation (AHD). The required post-processing {{and the results of}} <b>rigorous</b> network <b>adjustment</b> are also detailed. GPS static data was network adjusted from simultaneous state-wide GPSnet data using MGA 94 coordinates derived from the ARGN. Network adjustments were required to obtain the best possible coordinates for control marks and photo control targets. Ausgeiod 98 was used to model AHD elevations since no AHD benchmark was available. Network adjusted control marks agreed well with independent checks obtained from the online AUSPOS GPS data processing service. All network adjustment residuals satisfied the required accuracies...|$|R
40|$|Health {{insurance}} and provider payment reforms {{all over the}} world beg a key empirical question: what are the potential impacts of patient cost-sharing on health care utilization, cost and outcomes? The unique health insurance system and rich electronic medical record (EMR) data in China provides us a unique opportunity to study this topic. Four years (2010 to 2014) of EMR data from one medical center in China were utilized, including 10, 858 adult patients with liver diseases. We measured patient cost-sharing using actual reimbursement ratio (RR) which is allowed us to better capture financial incentive than using type of health insurance. A <b>rigorous</b> risk <b>adjustment</b> method was employed with both comorbidities and disease severity measures acting as risk adjustors. Associations between RR and health use, costs and outcome were analyzed by multivariate analyses. After risk adjustment, patients with more generous health insurance coverage (higher RR) were found to have longer hospital stay, higher total cost, higher medication cost, and higher ratio of medication to total cost, as well as higher number and likelihood that specific procedures were performed. Our study implied that patient cost-sharing affects health care services use and cost. This reflects how patients and physicians respond to financial incentives in the current healthcare system in China, and the responses could be a joint effect of both demand and supply side moral hazard. In order to contain cost and improve efficiency in the system, reforming provide payment and insurance scheme is urgently needed...|$|R
40|$|Mask {{topography}} effects need to {{be taken}} into consideration for a more accurate solution of source mask optimization (SMO) in advanced optical lithography. However, rigorous 3 D mask models generally involve intensive computation and conventional SMO fails to manipulate the mask-induced undesired phase errors that degrade the usable depth of focus (uDOF) and process yield. In this work, an optimization approach incorporating pupil wavefront aberrations into SMO procedure is developed as an alternative to maximize the uDOF. We first design the pupil wavefront function by adding primary and secondary spherical aberrations through the coefficients of the Zernike polynomials, and then apply the conjugate gradient method to achieve an optimal source-mask pair under the condition of aberrated pupil. We also use a statistical model to determine the Zernike coefficients for the phase control and <b>adjustment.</b> <b>Rigorous</b> simulations of thick masks show that this approach provides compensation for mask topography effects by improving the pattern fidelity and increasing uDOF. published_or_final_versio...|$|R
40|$|Many {{experiences}} {{have been done}} in the past in order to promote a wide diffusion of the photogrammetry both in teaching and professional works. Only the digital evolution allowed a real step forward in this direction. In the last years prof. Jachimski and prof. Grussenmeyer offer interesting and low-cost software solutions which help a lot the diffusion of the photogrammetric approach as a standard tool for architectural and archaeological applications. The paper presents a new easy-to-use but rigorous photogrammetric software named Z-Glif, produced by Menci Software, a private Italian software house which collaborates with Politecnico di Torino in order to produce new solutions in digital photogrammetry. Z-Glif allows a single model orientation and plotting. Both aerial and terrestrial, metric and non metric digital images can be used. Exterior orientation can be performed by using: the traditional two-steps approach (relative and absolute); the <b>rigorous</b> bundle <b>adjustment</b> solution; a simple method based on the relative orientation of a stereo-pair and the subsequent scaling by using just a known distance on the object to be surveyed (so absolutely oriented in a local 3 D reference system). Considering that an automatic relative orientation can be computed by the software, Z-Glif is open also to unskilled users: the 3 x 3 rules for a correct stereo-pair acquisition and a basic use of the software is the only skill required to manage a complete and rigorous photogrammetric survey in a local reference system. The fit of the local system into the survey reference system can be performe...|$|R
40|$|University of Minnesota Ph. D. dissertation. December 2012. Major: Experimental & Clinical Pharmacology. Advisor: Dr. Angela K. Birnbaum. 1 {{computer}} file (PDF); xiii, 130 pages, appendices p. 124 - 130. In spite of <b>rigorous</b> dose <b>adjustments</b> {{by way of}} therapeutic drug monitoring, {{a large proportion of}} kidney transplant recipients are unable to achieve the target tacrolimus trough concentrations. This is attributed to the narrow therapeutic window of the drug (10 - 15 ng/mL) and large inter-individual variability in pharmacokinetic parameter such as clearance. There is a need for development of clinical dosing models that can help prospectively predict the dose for an individual, especially in the critical period immediately post-transplant. Therefore, we established and quantified the effect of clinical and genetic factors on tacrolimus clearance (CL/F) using a large population of adult kidney transplant recipients. Tacrolimus troughs (n= 11823) from 681 transplant recipients over the first 6 -months post-transplant were analyzed using non-linear mixed effects modeling approach in NONMEM®. The troughs were characterized by a steady state infusion model. Covariates were analyzed using a forward selection (p TM. One desirable feature in this new software package is a graphical user interface and menu-driven covariate selection options. Therefore, we compared these two software packages in terms of covariates selected and predictive performance using both clinical and simulated data. For the tacrolimus data, NONMEM® predictions had lower bias and imprecision as compared to Phoenix® NLME TM. For the clinical data, NONMEM® predictions had higher bias but were more precise than the Phoenix® NLME TM predictions. ...|$|R
40|$|Extant therian mammals {{comprise}} marsupials and placentals. The lineages {{leading to}} these {{groups have been}} evolving separately since the Jurassic, resulting in substantially lower ecological and taxonomic diversity of marsupials than placentals. In order to elucidate the potential evolutionary mechanisms for this, the comparative cranial morphology between marsupials and placentals and patterns of taxonomic diversity through the fossil record were investigated. Cranial morphologies of a comprehensive range of extant placentals, marsupials and fossil metatherians were quantified using a geometric morphometrics. Variation in total skull morphology, and that of developmentally significant regions, of extant marsupials and placentals, was calculated and compared. Principal components analysis and delta variance tests were used to visualise and statistically investigate the data. Entire cranial shape {{was found to be}} significantly less varied in extant marsupials than in extant placentals, also true specifically in the viscerocranium. However, marsupial and placental neurocrania showed no significant difference in morphological varianc. Inclusion of fossil metatherians with the extant marsupial data did not significantly increase the variance of metatherian morphology. These findings are consistent with expectations based on the developmental constraint hypothesis. Metatherian fossil data were compiled from the literature and subjected to <b>rigorous</b> statistical <b>adjustments,</b> namely shareholder quorum subsampling (SQS) an d classic rarefaction, to ameliorate effects bias in the fossil record. Metatherian diversity was shown to fluctuate through time largely in accordance with major environmental changes. The diversity patterns revealed here contra st those based on raw data. Specifically, SQS analysis found North American Paleocene diversity to be higher than in the late Cretaceous, challenging the idea of an end Cretaceous decimation. Further, metatherian diversity in the late Miocene of Oceania was found to increase rather than decrease from the middle Miocene. This dual angle approach supports a combination of developmental and environmental effects on the evolution of metatherian biodiversity...|$|R
40|$|Travel {{times are}} {{essential}} for processing and velocity determination from VSP surveys. Even though many wells drilled today are deviated from vertical, there is very limited geophysical literature {{on the effects of}} well deviation on travel time measurements and processing issues when a VSP is conducted in a deviated well. An investigation of the processing considerations associated with acquiring precise travel times from a vertical incidence and walkaway survey conducted in a deviated well was carried out. Compensation for well deviation by rotating the vertical component in-line with the downgoing P-wave particle motion for each source-receiver pair of the vertical incident survey had a negligible effect on acquired travel times. Rotation of the vertical component in-line with the downgoing P-wave particle motion for each source-receiver pair of the walkaway survey proved to follow conventional practice and the deviation of the well was not an issue. [...] The issue of well deviation when acquiring travel times from VSP surveys conducted in deviated wells is a concern when characterizing a reservoir by determining aspects like anisotropic characteristics of a specific rock layer. Using the travel times acquired from both the vertical incidence and walkaway surveys, it is demonstrated, by producing a percent velocity anisotropy estimate of 17. 1 % for a marine shale, that the travel time-inversion method is well suited for a deviated well setting. This estimate is appropriate when compared to published values and to an independent estimate of 17. 9 % obtained by modifying the phase-slowness method using the same assumptions that govern the travel time-inversion method. Modifying the phase-slowness method also made it operationally less intense. In general, with the application of reasonable assumptions, velocity anisotropy measurements can be obtained within a deviated well without <b>rigorous</b> computational <b>adjustments...</b>|$|R
40|$|Thesis (M. Sc.) [...] Memorial University of Newfoundland, 2008. Earth ScienceIncludes bibliographical {{references}} (leaves 115 - 118) Travel {{times are}} essential for processing and velocity determination from VSP surveys. Even though many wells drilled today are deviated from vertical, there is very limited geophysical literature {{on the effects of}} well deviation on travel time measurements and processing issues when a VSP is conducted in a deviated well. An investigation of the processing considerations associated with acquiring precise travel times from a vertical incidence and walkaway survey conducted in a deviated well was carried out. Compensation for well deviation by rotating the vertical component in-line with the downgoing P-wave particle motion for each source-receiver pair of the vertical incident survey had a negligible effect on acquired travel times. Rotation of the vertical component in-line with the downgoing P-wave particle motion for each source-receiver pair of the walkaway survey proved to follow conventional practice and the deviation of the well was not an issue. [...] The issue of well deviation when acquiring travel times from VSP surveys conducted in deviated wells is a concern when characterizing a reservoir by determining aspects like anisotropic characteristics of a specific rock layer. Using the travel times acquired from both the vertical incidence and walkaway surveys, it is demonstrated, by producing a percent velocity anisotropy estimate of 17. 1 % for a marine shale, that the travel time-inversion method is well suited for a deviated well setting. This estimate is appropriate when compared to published values and to an independent estimate of 17. 9 % obtained by modifying the phase-slowness method using the same assumptions that govern the travel time-inversion method. Modifying the phase-slowness method also made it operationally less intense. In general, with the application of reasonable assumptions, velocity anisotropy measurements can be obtained within a deviated well without <b>rigorous</b> computational <b>adjustments...</b>|$|R
40|$|One {{of the key}} {{outcomes}} of open economy macroeconomics refers to a crucial importance of an investment-saving relation affecting a current account determination. However, despite a relative diversity in exchange rate regimes in European transition economies, {{there is still a}} substantial potential to analyze price effects of real exchange rate dynamics on current account <b>adjustments.</b> <b>Rigorous</b> investigation of relative changes in real exchange rates leading paths and associated adjustments in current accounts may reveal causal relationship between real exchange rate dynamics and international competitiveness in order to observe its redistributive effects. This purpose is even more significant provided that economic crisis has intensified cross-country expenditure shifting effects that still provide quite diverse and thus spurious effects on current account adjustments. In the paper we analyze main aspects of current account adjustments in European transition economies. Our main objective is to observe a relationship between real exchange rate dynamics and current account adjustments (in countries with different exchange rate arrangements). From estimated VAR model we calculate responses of the current account to the real exchange rate (REER calculated on CPI and ULC base) shock. To provide more rigorous insight into the problem of the current account adjustments according to real exchange rate dynamics we estimate the model for each particular country employing data for two subsequent periods 2000 - 2007 and 2000 - 2012. ...|$|R
40|$|The Stanford Linear Accelerator Center (SLAC) is in {{the process}} of {{building}} a new particle collider, the Stanford Linear Collider (SLC). The tunnel which houses the SLC is about 3 km long and contains approximately 1000 magnets. Besides a very precise absolute positioning of these magnets, the alignment of adjacent magnet ends is of particular importance to the success of the whole project. Because of this and the limited time frame, a survey method which was not only reliable and self-checking but also fast had to be developed. Therefore, the concept of MAS (Magnet Alignment System) was developed. This system utilizes the on-line data collection and the <b>rigorous</b> least-squares bundle <b>adjustment</b> of the KERN ECDSPC system to fulfill these requirements. The ECDS software is embedded in a project tailored software system with modules which take care of: fixture and magnet calibration corrections, the calculation of ideal coordinates and their comparison to measured coordinates, the translation of detected misalignments into the coordinate system of the mechanical adjustments and the control of the adjustments with on-line electronic dial-gauges. This paper gives a brief introduction to the SLC project and some of the survey problems which are unique to this machine. The basic ideas of the KERN ECDS-PC system are explained and a discussion of the practical aspects, such as targeting and set-ups are given. MAS and its modules are explained in detail...|$|R
40|$|Aims: We build a {{catalogue}} PPM-Extended (PPMX) on the ICRS system which is complete {{down to a}} well-defined limiting magnitude and contains the best presently available proper motions to be suited for kinematical studies in the Galaxy. Methods: We perform a <b>rigorous</b> weighted least-squares <b>adjustment</b> of individual observations, spread over more than a century, to determine mean positions and proper motions. The stellar content of PPMX is taken from GSC 1. 2 supplemented by catalogues like ARIHIP, PPM and Tycho- 2 at the bright end. All observations have been weighted according to their individual accuracy. The catalogue has been screened towards rejecting false entries in the various source catalogues. Results: PPM-Extended (PPMX) is {{a catalogue}} of 18, 088, 920 stars containing astrometric and photometric information. Its limiting magnitude is about 15. 2 in the GSC photometric system. PPMX consists of three parts: a) a survey complete down to R_U = 12. 8 in the magnitude system of UCAC 2; b) additional stars of high-precision proper motions, and c) all other stars from GSC 1. 2 identified in 2 MASS. The typical accuracy of the proper motions is 2 mas/y for 66 percent of the survey stars (a) and the high-precision stars (b), and about 10 mas/y for all other stars. PPMX contains photometric information from ASCC- 2. 5 and 2 MASS. Comment: 9 pages, 8 figures, accepted for publication in Astronomy and Astrophysic...|$|R
40|$|Purpose This study {{aimed to}} {{investigate}} current issues and areas for {{improvement in the}} Korean Dental Hygienist National Licensing Examination (KDHNLE) through an expert Delphi survey. Methods A Delphi survey was conducted from May through August 2016 in Korea. This Delphi survey included 20 persons representing the field of dental hygiene (7 groups from various dental hygiene-related organizations). The Delphi survey was administered through e-mail as 3 rounds of questionnaire surveys regarding the issues facing the KDHNLE and potential solutions to those challenges. The primary Delphi survey was an open questionnaire. In each round, subjects’ responses were categorized according to the detailed themes of their responses. The minimum value of the content validity ratio of the survey results {{was determined by the}} number of panels participating in the Delphi survey. Results Issues facing the KDHNLE were identified from the results of the Delphi survey. The following 4 items had an average importance score of 4. 0 or higher and were considered as important by over 85 % of the panels: the failure of the practical test to reflect actual clinical settings, the focus of the practical test on dental scaling, the gap between the items evaluated on the national examination and actual practical work, and insufficiency in strengthening the expertise of licensed dental hygienists. The following items were suggested for improvement: more <b>rigorous</b> rater training, <b>adjustment</b> of the difficulty of the licensing examination, the introduction of a specialized dental hygienist system, and more rigorous refresher training for licensed dental hygienists. Conclusion Based on the above results, the KDHNLE should be improved according to the core competencies of dental hygienists, including on-site clinical practice experience...|$|R
