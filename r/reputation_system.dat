726|765|Public
5|$|Because of {{the large}} number of factions created for the game, {{developers}} reintroduced the <b>reputation</b> <b>system</b> that was first used in Fallout 2 and had been absent in Fallout 3. Much like Karma, a player's standing with a faction can change depending on how they interact with them and what decisions they make. If, for example, players help a faction, their reputation with them improves in all locations controlled by that faction; opting to kill their members will cause a loss of reputation. The type of reputation the player has with each faction affects how non-player characters (NPCs) behave towards them; a good reputation might make completing some quests easier, provide discounts with the faction's vendors, and cause faction members to offer gifts; a bad reputation may lead to the faction refusing to help the player or attacking them on sight, or sending thugs after the player.|$|E
25|$|Version 0.24, titled First Contract and {{released}} on 17 July 2014, added the contracts and <b>reputation</b> <b>system</b> to the game's career mode; however, players were {{still able to}} play career mode without these features in the new science mode. Contracts reward the player with currency and reputation. Funds {{can be used to}} purchase rocket parts, and reputation results in better and more lucrative contracts.|$|E
25|$|Peerage of Science is an {{independent}} service and a community where reviewer recruitment happens via Open Engagement: authors submit their manuscript to the service where it is made accessible for any non-affiliated scientist, and 'validated users' choose themselves {{what they want to}} review. The motivation to participate as a peer reviewer comes from a <b>reputation</b> <b>system</b> where the quality of the reviewing work is judged and scored by other users, and contributes to user profiles. Peerage of Science does not charge any fees to scientists, and does not pay peer reviewers. Participating publishers however pay to use the service, gaining access to all ongoing processes and the opportunity to make publishing offers to the authors.|$|E
40|$|Abstract — <b>Reputation</b> <b>systems</b> provide {{mechanisms}} {{through which}} multiple parties can quantify the trust between one another. These systems seek to generate an accurate assessment {{in the face}} of unprecedented community size, while providing anonymity and resilience to malicious attacks. We focus on attacks and defense mechanisms in <b>reputation</b> <b>systems.</b> We present an analysis framework that allows for general decomposition of existing <b>reputation</b> <b>systems.</b> We classify attacks against <b>reputation</b> <b>systems</b> by identifying which system components and design choices are the target of attacks. We survey defense mechanisms employed by existing <b>reputation</b> <b>systems.</b> Finally, we analyze several landmark systems, characterizing their individual strengths and weaknesses. Our work contributes to understanding 1) which design components of <b>reputation</b> <b>systems</b> are most vulnerable, 2) what are the most appropriate defense mechanisms and 3) how these defense mechanisms can be integrated into existing or future <b>reputation</b> <b>systems</b> to make them resilient to attacks...|$|R
50|$|The {{attacks against}} <b>reputation</b> <b>systems</b> are {{classified}} {{based on the}} goals of the <b>reputation</b> <b>systems</b> targeted by the attacks.|$|R
40|$|<b>Reputation</b> <b>systems</b> provide {{mechanisms}} {{to produce a}} metric encapsulating reputation for a given domain for each identity within the system. These systems seek to generate an accurate assessment {{in the face of}} various factors including but not limited to unprecedented community size and potentially adversarial environments. We focus on attacks and defense mechanisms in <b>reputation</b> <b>systems.</b> We present an analysis framework that allows for general decomposition of existing <b>reputation</b> <b>systems.</b> We classify attacks against <b>reputation</b> <b>systems</b> by identifying which system components and design choices are the target of attacks. We survey defense mechanisms employed by existing <b>reputation</b> <b>systems.</b> Finally, we analyze several landmark systems in the peer-to-peer domain, characterizing their individual strengths and weaknesses. Our work contributes to understanding 1) which design components of <b>reputation</b> <b>systems</b> are most vulnerable, 2) what are the most appropriate defense mechanisms and 3) how these defense mechanisms can be integrated into existing or future <b>reputation</b> <b>systems</b> to make them resilient to attacks...|$|R
500|$|The {{game was}} [...] "intentionally {{designed}} as a cross between Halo and Silverado." [...] O'Connor said Halo was [...] "of course" [...] an inspiration, comparing Darkwatch to the horror aspects of Halo, and senior designer Brent Disbrow said he expected it to [...] "stand on par with games like Halo 2." [...] Other video game inspirations recounted by O'Connor and Valdez included Half-Life, Medal of Honor, Metroid Prime and TimeSplitters. Lead level designer Matt Tieger said that a creation {{of one of the}} game's bosses was [...] "inspired by all the fun" [...] that he had while playing the Metal Slug 2D shooter series with its [...] "crazy bosses". O'Connor said the game's <b>reputation</b> <b>system</b> was inspired by the contrast between the Old West figures such as Billy the Kid and the likes of Wyatt Earp, who [...] "both were feared gunslingers, but one was a psychopathic killer and the other was a good guy/lawman." ...|$|E
500|$|Darkwatch {{features}} a <b>reputation</b> <b>system</b> that affects player's abilities {{in addition to}} the player character Jericho's starting, neutral vampiric powers of [...] "Blood Shield" [...] (a regenerating force field similar to the energy shield from [...] ), [...] "Vampire Jump" [...] (a [...] that can be aborted at any moment) and [...] "Blood Vision" [...] (a system of heat vision highlighting enemies and objects that also acts as a zoom). Through the game, Jericho is met with multiple choices of a good or evil variety, allowing the player to select morality awarding Jericho new powers, called [...] "Brands", based on the choices he made. This system was compared to the one used in the role-playing video game [...] The good path powers are [...] "Silver Bullet" [...] (making the player's weapons cause more damage), [...] "Fear" [...] (confusing minor enemies), [...] "Mystic Armor" [...] (an extra shield system) and [...] "Vindicator" [...] (bolts of lightning destroying all nearby enemies). The evil powers are [...] "Blood Frenzy" [...] (granting an immunity to damage and extremely powerful melee attacks), [...] "Turn" [...] (turning undead enemies into allies), [...] "Black Shroud" [...] (stealing life force from nearby enemies) and [...] "Soul Stealer" [...] (destroying nearby enemies and stealing their souls). The powers can be activated for a limited time when the HUD's blood bar, which is fueled through collecting souls of the slain enemies, is completely full. Jericho's health is also restored through collecting the souls.|$|E
50|$|Memestreams {{employs a}} <b>reputation</b> <b>system.</b>|$|E
40|$|Although online {{communities}} {{make it possible}} for a far greater number of participants to interact on the Web, there are challenges in creating mechanisms that reveal reputations for participants. <b>Reputation</b> <b>Systems</b> provide a proxy that establishes trust in e-commerce communities, social communities, and social news communities. There remain questions as to how <b>reputation</b> <b>systems</b> can be more widely used in {{online communities}} without damaging user confidence because participants have strong privacy expectations. This paper will review <b>reputation</b> <b>systems</b> in online communities, examine types, properties, and issues of <b>reputation</b> <b>systems,</b> survey the use of social networks and <b>reputation</b> <b>systems</b> in popular online communities, and present a researc...|$|R
40|$|In recent years, we have {{witnessed}} an increasing use of trust and <b>reputation</b> <b>systems</b> in different areas of ICT. The idea {{at the base of}} trust and <b>reputation</b> <b>systems</b> is of letting users to rate the provided services after each interaction. Other users may use aggregate ratings to compute reputation scores for a given party. The computed reputation scores are a collective measure of parties trustworthiness and are used to drive parties interactions. Due to the widespread use of <b>reputation</b> <b>systems,</b> research work on them is intensifying and several models have been proposed. This calls for a methodology for the analysis and the evaluation of trust and <b>reputation</b> <b>systems</b> that can help researcher and developers in studying, designing and implementing such systems. In this thesis we propose different kinds of theoretical results and software tools that could be useful means for researchers and developers in area of trust and <b>reputation</b> <b>systems.</b> Our work addresses the three main stages of trust and <b>reputation</b> <b>systems</b> development, namely study, design and implementation. We provide: 1) a general framework based on Bayesian decision theory for the assessment of trust and reputation models, 2) an analysis methodology for <b>reputation</b> <b>systems</b> based on a coordination language, 3) a software tool for network-aware evaluation of <b>reputation</b> <b>systems</b> and their rapid prototyping...|$|R
40|$|In {{an online}} environment, {{the aim of}} reputationsystems is to let parties rate {{each other and to}} help {{consumers}} indeciding whether or not to transact with a given party. Incurrent <b>reputation</b> <b>systems</b> for e-commerce, users have to trustunreliable information sources and anonymous people. As aresult, users are not only hesitant to trust online seller but alsoreputation systems. Therefore, {{there is a need to}} improvecurrent <b>reputation</b> <b>systems</b> by allowing users to make buyingdecision based on reliable source of information. This paperproposes a new approach of sharing knowledge and experiencein <b>reputation</b> <b>systems</b> by utilizing social interactions. This studyexamines the potentials of integrating social relationsinformation in <b>reputation</b> <b>systems</b> by proposing a model ofacceptance of feedbacks in <b>reputation</b> <b>systems.</b> This can assistusers to access trustworthy information sources by knowing theexperience and feedback from people within their socialcommunities. Through this approach, feedback will be filteredand presented based on evaluation of three factors. They arehomophily, tie strength and source credibility based onrelations between submitter and receiver of feedback toincrease effectiveness of <b>reputation</b> <b>systems...</b>|$|R
5000|$|Self-promoting Attack. The {{attacker}} falsely {{increases their}} own reputation by falsely increase it. A typical {{example is the}} so-called Sybil attack where an attacker subverts the <b>reputation</b> <b>system</b> by creating {{a large number of}} pseudonymous entities, and using them to gain a disproportionately large influence. A reputation system's vulnerability to a Sybil attack depends on how cheaply Sybils can be generated, {{the degree to which the}} <b>reputation</b> <b>system</b> accepts input from entities that do not have a chain of trust linking them to a trusted entity, and whether the <b>reputation</b> <b>system</b> treats all entities identically.|$|E
5000|$|WikiTrust, a <b>reputation</b> <b>system</b> for Wikipedia {{authors and}} content ...|$|E
5000|$|A <b>reputation</b> <b>system</b> {{that affects}} the rate of officers' loyalties towards their lords ...|$|E
40|$|<b>Reputation</b> <b>systems</b> evolve as a {{mechanism}} to build trust in virtual communities. In this paper we evaluate different metrics for computing <b>reputation</b> in multi-agent <b>systems.</b> We present a formal model for describing metrics in <b>reputation</b> <b>systems</b> and show how different well-known global reputation metrics are expressed by it. Based on the model a generic simulation framework for reputation metrics was implemented. We used our simulation framework to compare different global <b>reputation</b> <b>systems</b> to find their strengths and weaknesses. The strength of a metric is measured by its resistance against different threat-models, i. e. different types of hostile agents. Based on our results we propose a new metric for <b>reputation</b> <b>systems.</b> 1...|$|R
40|$|The {{focus of}} the paper is to {{investigate}} the design of current merchant <b>reputation</b> <b>systems</b> on shopping agent websites. The study explores their roles and impacts in customer decision-making process, identifies their rating methodology and rating reliability. The findings will help industrial practitioners for their design of merchant <b>reputation</b> <b>systems,</b> and will benefit online shoppers and e-merchants for their utilization of merchant <b>reputation</b> <b>systems.</b> 1...|$|R
40|$|Parties of <b>{{reputation}}</b> <b>systems</b> rate {{each other}} and use ratings to compute reputation scores that drive their interactions. When deciding which reputation model to deploy in a network environment, {{it is important to}} find the most suitable model and to determine its right initial configuration. This calls for an engineering approach for describing, implementing and evaluating <b>reputation</b> <b>systems</b> while taking into account specific aspects of both the <b>reputation</b> <b>systems</b> and the networked environment where they will run. We present a software tool (NEVER) for network-aware evaluation of <b>reputation</b> <b>systems</b> and their rapid prototyping through experiments performed according to user-specified parameter...|$|R
50|$|In a Sybil attack, the {{attacker}} subverts the <b>reputation</b> <b>system</b> of a peer-to-peer network {{by creating a}} large number of pseudonymous identities, using them to gain a disproportionately large influence. A reputation system's vulnerability to a Sybil attack depends on how cheaply identities can be generated, {{the degree to which the}} <b>reputation</b> <b>system</b> accepts inputs from entities that do not have a chain of trust linking them to a trusted entity, and whether the <b>reputation</b> <b>system</b> treats all entities identically. , evidence showed that large-scale Sybil attacks could be carried out in a very cheap and efficient way in extant realistic systems such as BitTorrent Mainline DHT.|$|E
50|$|Epinions.com’s <b>reputation</b> <b>system</b> is not abuse-proof, but {{the company}} {{maintains}} a Customer Care unit should a dispute arise.|$|E
5000|$|NCShield is a decentralized, goosip-based {{trust and}} <b>reputation</b> <b>system</b> to secure Phoenix and other matrix factorization-based NC systems.|$|E
40|$|Abstract <b>Reputation</b> <b>systems</b> take as input {{ratings from}} members in a community, and can produce {{measures}} of reputation, trustworthiness or reliability of entities {{in the same}} community. Binomial and multinomial Bayesian <b>reputation</b> <b>systems</b> are discrete in nature meaning that they normally take discrete ratings such as “aver-age ” or “good ” as input. However, in many situations it is natural to provide input ratings to <b>reputation</b> <b>systems</b> based on continuous measures. This paper describes the principles of discrete Bayesian <b>reputation</b> <b>systems,</b> and how continuous mea-sures can provide input ratings to such systems. The method is based on fuzzy set membership functions. ...|$|R
40|$|Existing testbeds to {{evaluate}} <b>reputation</b> <b>systems</b> are mainly simulation based {{and are not}} flexible to perform robustness evaluations against unfair rating attacks. In this paper, we present a novel comprehensive testbed, which can evaluate <b>reputation</b> <b>systems</b> using both simulations and real data. The testbed incorporates sophisticated deception models and unfair rating attack models, and introduces several perfor-mance metrics to fully test and compare the effectiveness and robustness of different <b>reputation</b> <b>systems...</b>|$|R
40|$|Recent {{advances}} in ICT {{have led to}} a vast and expeditious development of e-services and technology. Trust is a fundamental aspect for the acceptance and adoption of these new services. Reputation is commonly employed as the measure of the trustworthiness of users in on-line communities. However, to facilitate their acceptance, <b>reputation</b> <b>systems</b> should {{be able to deal with}} the trust challenges and needs of those services. The aim of this survey is to propose a framework for the analysis of <b>reputation</b> <b>systems.</b> We elicit the requirements for reputation metrics along with the features necessary to achieve such requirements. The identified requirements and features form a reference framework which allows an objective evaluation and comparison of <b>reputation</b> <b>systems.</b> We demonstrate its applicability by analyzing and classifying a number of existing <b>reputation</b> <b>systems.</b> Our framework can serve as a reference model for the analysis of <b>reputation</b> <b>systems.</b> It is also helpful for the design of new <b>reputation</b> <b>systems</b> as it provides an analysis of the implications of design choices. Keywords: Reputation systems; Reference model; Trust requirement...|$|R
5000|$|Jack Vance uses a <b>reputation</b> <b>system</b> called [...] "strakh" [...] as {{currency}} in his short story The Moon Moth, published in 1961.|$|E
5000|$|Sybil. An pseudonymous attacker, {{who usually}} uses {{a large number}} of identities. For example, Sybil may attempt to subvert a <b>reputation</b> <b>system.</b> See Sybil attack.|$|E
50|$|These {{insights}} {{have been}} built on to explore more generally the role of legal institutions in coordinating and incentivizing decentralized enforcement mechanisms like the multilateral <b>reputation</b> <b>system.</b>|$|E
40|$|<b>Reputation</b> <b>systems</b> {{make the}} users of a {{distributed}} application {{accountable for their}} behavior. The reputation of a user is computed as an aggregate of the feedback provided by other users in the system. Truthful feedback is clearly a prerequisite for computing a reputation score that accurately represents {{the behavior of a}} user. However, it has been observed that users often hesitate in providing truthful feedback, mainly due to the fear of retaliation. Privacy preserving <b>reputation</b> <b>systems</b> enable users to provide feedback in a private and thus uninhibited manner. In this paper, we describe analysis frameworks for <b>reputation</b> <b>systems</b> and privacy preserving <b>reputation</b> <b>systems.</b> We use these analysis frameworks to review and compare the existing privacy preserving <b>reputation</b> <b>systems</b> in the literature. We identify {{the strengths and weaknesses of}} the various systems. We also discuss some open challenges...|$|R
40|$|Part 2 : Short PapersInternational audienceParties of <b>{{reputation}}</b> <b>systems</b> rate {{each other}} and use ratings to compute reputation scores that drive their interactions. When deciding which reputation model to deploy in a network environment, {{it is important to}} find the most suitable model and to determine its right initial configuration. This calls for an engineering approach for describing, implementing and evaluating <b>reputation</b> <b>systems</b> while taking into account specific aspects of both the <b>reputation</b> <b>systems</b> and the networked environment where they will run. We present a software tool (NEVER) for network-aware evaluation of <b>reputation</b> <b>systems</b> and their rapid prototyping through experiments performed according to user-specified parameters...|$|R
30|$|Recently, {{scholars}} have been focusing on redesigning <b>reputation</b> <b>systems</b> {{in the era}} of blockchain technology. For instance, Vandervort (2014) discusses the feasibility and challenges of designing the bitcoin-based <b>reputation</b> <b>systems.</b> As privacy is an important concern for users who are reluctant to provide information, Schaub et al. (2016) propose how to utilize digital signatures to design <b>reputation</b> <b>systems</b> that can protect users’ privacy. In a similar vein, Soska and Christin (2015) propose a system “Beaver,” which protects users’ privacy, while being resistant against sybil attacks by charging fees. Dennis and Owenson (2016) design <b>reputation</b> <b>systems</b> with underlying blockchain technology. These systems generate and broadcast a binary P 2 P rating on receiving the correct file.|$|R
50|$|The <b>reputation</b> <b>system</b> is also {{connected}} to a filter. Users {{have the ability to}} filter out responses of other members by selecting the minimum score they want to see.|$|E
50|$|Attack {{classification}} of <b>reputation</b> <b>system</b> {{is based on}} identifying which system components and design choices are the targets of attacks. While the defense mechanisms are concluded based on existing reputation systems.|$|E
5000|$|TrustedSource is an Internet <b>reputation</b> <b>system</b> {{originally}} developed by CipherTrust and {{now owned by}} Intel Security. It provides reputation scores for Internet identities, such as IP addresses, URLs, domains, and email/web content.|$|E
30|$|In this work, {{we aim to}} {{encourage}} reuse {{in the development of}} <b>reputation</b> <b>systems</b> by providing a framework for creating <b>reputation</b> <b>systems</b> based on reusable components. Design approaches for reuse have been given much attention in the software engineering community. The research in trust and <b>reputation</b> <b>systems</b> could also profit from benefits like effective use of specialists, accelerated development and increased reliability. Toward this goal, we propose a hierarchical taxonomy for components of computation engines used in <b>reputation</b> <b>systems.</b> Thereto, we decompose the computation phase of common reputation models to derive single building blocks. The classification based on their functions serves as a natural framework for the design of new <b>reputation</b> <b>systems.</b> Moreover, we set up a component repository containing artifacts on both a conceptual and an implementation level to facilitate the reuse of the identified components. On the conceptual level, we describe each building block as a design pattern-like solution. On the implementation level, we provide already implemented components by means of web services.|$|R
40|$|Background: Centralized Online <b>Reputation</b> <b>Systems</b> (ORS) {{have been}} widely used by {{internet}} companies. They collect users’ opinions on products, transactions and events as reputation information then aggregate and publish the information to the public. Aim: Studies of <b>reputation</b> <b>systems</b> evaluation to date have tended to focus on isolated systems or their aggregating algorithms only. This paper proposes an evaluation mechanism to measure different <b>reputation</b> <b>systems</b> in the same context. Method: <b>Reputation</b> <b>systems</b> naturally have differing interfaces, and track different aspects of user behavior, however, from information system perspective, they all share five underlying components: Input, Processing Storage, Output and Feedback Loop. Therefore, <b>reputation</b> <b>systems</b> can be divided into these five components and measured by their properties respectively Results: The paper concentrates on the evaluation of Input and develops a set of simple formulas to represent the cost of reputation information collection. This is then applied to three different sites and the resulting analysis shows {{the pros and cons of}} the differing approaches of each of these sites...|$|R
5000|$|Collaborative filtering, {{used most}} {{commonly}} in recommender systems, {{are related to}} <b>reputation</b> <b>systems</b> in that they both collect ratings from members of a community. [...] The core difference between <b>reputation</b> <b>systems</b> and collaborative filtering is {{the ways in which}} they use user feedback. In collaborative filtering, the goal is to find similarities between users in order to recommend products to customers. The role of <b>reputation</b> <b>systems,</b> in contrast, is to gather a collective opinion in order to build trust between users of an online community.|$|R
