23|104|Public
50|$|According to {{the paper}} of Checkoway et al, it is {{possible}} to perform return-oriented-programming on x86 and ARM architectures without using a <b>return</b> <b>instruction</b> (0xC3 on x86). They instead used carefully crafted instruction sequences that already exist in the machine's memory to behave like a <b>return</b> <b>instruction.</b> A <b>return</b> <b>instruction</b> has two effects: firstly, it searches for the four-byte value {{at the top of the}} stack, and sets the instruction pointer to that value, and secondly, it increases the stack pointer value by four. On the x86 architecture, sequences of jmp and pop instructions can act as a <b>return</b> <b>instruction.</b> On ARM, sequences of load and branch instructions can act as a <b>return</b> <b>instruction.</b>|$|E
5000|$|Software may use {{the full}} {{subroutine}} stack depth; interrupts are masked while the stack is full, and will be taken {{as soon as a}} <b>return</b> <b>instruction</b> is executed.|$|E
50|$|<b>Return</b> <b>instruction</b> {{pointers}} {{are usually}} protected by stack canaries. A stack canary causes {{the program to}} crash if its value is modified by a buffer overrun. In the BROP model of attack, the buffer overrun is carried byte by byte. Each try at the overrun results either in program crash or continued execution. A program crash implies that the stack value was incorrectly guessed, therefore in 256 tries (average case is 128 tries) the stack value can be probably estimated. On 64 bit machines, 4 such stack reads {{would be required to}} leak the canary. Once the canary is leaked, the <b>return</b> <b>instruction</b> pointer can be perturbed in the same way. It may however be noted that though the estimation of the stack canary is exact, the same cannot be said about the <b>return</b> <b>instruction</b> address. The attacker would be satisfied to be able to leak any address within the text segment of the address space.|$|E
50|$|One {{approach}} for defending against return-oriented programming {{would be to}} create a compiler-based defense mechanism that eliminated <b>return</b> <b>instructions</b> so that an adversary or return-oriented rootkit could not make return-oriented gadgets. To eliminate <b>return</b> <b>instructions,</b> a technique called return indirection replaces the return address in the stack frame with an index. Thus, an adversary cannot use return addresses in the stack frame anymore. To prevent blocking legitimate instructions, two techniques called register allocation and peephole optimization can be used. The peephole optimization replaces return opcodes with non-return opcodes.|$|R
40|$|We {{show that}} on the x 86 it is {{possible}} to mount a return-oriented programming attack without using any <b>return</b> <b>instructions.</b> Our new attack instead makes use of certain instruction sequences that behave like a return; we show that these sequences occur with sufficient frequency in large Linux libraries to allow creation of a Turing-complete gadget set. Because it does not make use of <b>return</b> <b>instructions,</b> our new attack has negative implications for two recently proposed classes of defense against return-oriented programming: those that detect the toofrequent use of <b>returns</b> in the <b>instruction</b> stream, and those that detect violations of the last-in, first-out invariant that is normally maintained for the return-address stack. ...|$|R
5000|$|... (0x81) Stack pointer SP. This is an 8-bit {{register}} used by subroutine call and <b>return</b> <b>instructions.</b> The stack grows upward; the SP is incremented before pushing, and decremented after popping a value.|$|R
50|$|Since {{this new}} {{approach}} {{does not use}} a <b>return</b> <b>instruction,</b> it has negative implications for defense. When a defense program checks not only for several returns but also for several jump instructions, this attack may be detected.|$|E
50|$|A {{function}} will normally {{return to}} where it is called from. The <b>return</b> <b>instruction</b> is an indirect jump that reads its target address from the call stack. Many microprocessors have a separate prediction mechanism for return instructions. This mechanism {{is based on a}} so-called return stack buffer, which is a local mirror of the call stack. The size of the return stack buffer is typically 4 - 16 entries.|$|E
5000|$|It is {{therefore}} possible {{to search for}} an opcode that alters control flow, most notably the <b>return</b> <b>instruction</b> (0xC3) and then look backwards in the binary for preceding bytes that form possibly useful instructions. These sets of instruction [...] "gadgets" [...] can then be chained by overwriting the return address, via a buffer overrun exploit, with {{the address of the}} first instruction of the first gadget. The first address of subsequent gadgets is then written successively onto the stack. At the conclusion of the first gadget, a <b>return</b> <b>instruction</b> will be executed, which will pop the address of the next gadget off the stack and jump to it. At the conclusion of that gadget, the chain continues with the third, and so on. By chaining the small instruction sequences, an attacker is able to produce arbitrary program behavior from pre-existing library code. Shacham asserts that given any sufficiently large quantity of code (including, but not limited to, the C standard library), sufficient gadgets will exist for Turing-complete functionality.|$|E
5000|$|... {{switching}} to an available task during an interrupt <b>return</b> (IRET) <b>instruction</b> ...|$|R
50|$|Another approach, {{taken by}} kBouncer, modifies the {{operating}} system to verify that <b>return</b> <b>instructions</b> actually divert control flow back to a location immediately following a call instruction. This prevents gadget chaining, but carries a heavy performance penalty, and is not effective against jump-oriented programming attacks which alter jumps and other control-flow-modifying <b>instructions</b> instead of <b>returns.</b>|$|R
40|$|The Fourier Transform Sum-Product Algorithm (FT-SPA) used in non-binary Low-Density Parity-Check (LDPC) {{decoding}} makes {{extensive use}} of the Walsh–Hadamard Transform (WHT). We have developed a massively parallel Fast Walsh–Hadamard Transform (FWHT) which exploits the Graphics Processing Unit (GPU) pipeline and memory hierarchy, thereby minimizing the level of memory bank conflicts and maximizing the number of <b>returned</b> <b>instructions</b> per clock cycle for different generations of graphics processors, with considerable speedup gains in FT-SPA based non-binary LDPC decoding...|$|R
5000|$|In this technique, an {{attacker}} gains {{control of}} the call stack to hijack program control flow and then executes carefully chosen machine instruction sequences that are already present in the machine's memory, called [...] "gadgets". Each gadget typically ends in a <b>return</b> <b>instruction</b> and {{is located in a}} subroutine within the existing program and/or shared library code. Chained together, these gadgets allow an attacker to perform arbitrary operations on a machine employing defenses that thwart simpler attacks.|$|E
5000|$|A {{variant of}} return-to-libc is return-oriented programming, which {{sets up a}} series of return addresses, each of which executes a small {{sequence}} of cherry-picked machine instructions within the existing program code or system libraries, sequence which ends with a return. These so-called gadgets each accomplish some simple register manipulation or similar execution before returning, and stringing them together achieves the attacker's ends. It is even possible to use [...] "returnless" [...] return-oriented programming by exploiting instructions or groups of instructions that behave much like a <b>return</b> <b>instruction.</b>|$|E
50|$|Thus, to {{interact}} with an application running in part as a daemon (in another process), a user's process simply performed a normal procedure-call instruction to a code segment to which it had dynamically linked (a code segment that implemented some operation associated with the daemon). The code in that segment could then modify data maintained and used in the daemon. When the action necessary to commence the request was completed, a simple procedure <b>return</b> <b>instruction</b> returned control of the user's process to the user's code.|$|E
40|$|Return-oriented {{programming}} (ROP) is {{a technique}} that enables an adversary to construct malicious programs with the desired behavior by combining short instruction sequences that already reside in the memory space of a program. ROP attacks have already been demonstrated on various processor architectures ranging from PCs to smartphones and special-purpose systems. In this paper, we present our tool, ROPdefender, that dynamically detects conventional ROP attacks (that are based on <b>return</b> <b>instructions)</b> with a reasonable runtime overhead of 2 x. In contrast to existing solutions, (i) ROPdefender does not rely on side information (e. g., source code or debugging information) and (ii) it instruments all <b>return</b> <b>instructions</b> issued during program execution including all returns from dynamic libraries, even if the adversary subverts the control-flow by other means. Moreover, ROPdefender can handle Unix signals, non-local control transfers, C++ exceptions, lazy binding, and {{can be applied to}} multi-threaded applications such as Mozilla Firefox or Acrobat Reader. Finally our implementation supports mainstream operating systems (Windows and Linux) for the Intel x 86 architecture. As proof of concept we show that ROPdefender successfully detects recent Acrobat Reader exploits on Windows. ...|$|R
50|$|He then <b>returned</b> to <b>instruction</b> {{duties in}} early 1941, with No. 53 Operational Training Unit, at RAF Heston and as Chief Flying Instructor at RAF Llandow until September 1941.|$|R
40|$|Abstract. There is {{a growing}} {{interest}} {{in the use of}} speculative multithreading to speed up the execution of sequential programs. In this execution model, threads are extracted from sequential code and are speculatively executed in parallel. This makes it possible to use parallel processing to speed up ordinary applications, which are typically written as sequential programs. This paper has two objectives. The first is to highlight the problems involved in performing accurate return address predictions in speculative multithreaded processors, where many of the subroutine call <b>instructions</b> and <b>return</b> <b>instructions</b> are fetched out of program order. A straightforward application of a return address stack popular scheme for predicting return addresses in single-threaded environments does not work well in such a situation. With out-of-order fetching of call instructions as well as <b>return</b> <b>instructions,</b> pushing and popping of return addresses onto and from the return address stack happen in a somewhat random fashion. This phenomena corrupts the return address stack, resulting in poor prediction accuracy for return addresses. The second objective of the paper is to propose a fixup technique for using the return address stack in speculative multithreaded processors. Our technique involves the use of a distributed return address stack, with facilities for repair when out-of-order pushes and pops happen. Detailed simulation results of the proposed schemes show significant improvements in the predictability of return addresses in a speculative multithreaded environment. ...|$|R
50|$|The {{concept of}} a code cave is often used by hackers to execute {{arbitrary}} code in a compiled program. It can be an extremely helpful tool to make additions and removals to a compiled program including the addition of dialog boxes, variable modification, or removal of software key validation checks. Often using a call instruction commonly found on many CPUs, the code jumps to the new subroutine and pushes the next address onto the stack. After execution of the subroutine, a <b>return</b> <b>instruction</b> {{can be used to}} pop the previous location off of the stack into the program counter. This allows the existing program to jump to the newly added code without making significant changes to the program itself.|$|E
5000|$|In software, {{a shadow}} stack is a {{mechanism}} for maintaining control-flow integrity by mitigating return address overwrites such as those seen during exploitation of a stack buffer overflow. The technique is to first keep {{a record of the}} legitimate return address for some function call, and then to check that the return address is still correct before returning. [...] This can be accomplished by adding additional instructions to function calls and function epilogues: on calls, store the legitimate return address (that is, the address of the instruction after the call), and on returns, check before actually returning. A stack buffer overflow would be adequate to overwrite the return address on the stack, but not the shadow stack's record of the return address. If the return address and the shadow return address differ, the check inserted before the <b>return</b> <b>instruction</b> will fail; the usual action in such cases is to crash the program, and in some cases alert administrators to the possibility of an intrusion attempt.|$|E
5000|$|Programs {{had access}} to 64 registers, and many {{instructions}} were triadic. Sixteen registers (registers 48 to 63) were referred to as [...] "global registers" [...] and they correspond to the registers of a typical CPU, {{in that they are}} static and always visible. The other 48 registers were actually the top of the subroutine stack. Thirty-two of them (0-31) were local registers for the current subroutine, and registers 32-47 were used to pass up to 16 parameters to the next subroutine called. During a subroutine call, the register stack moved up 32 words, so the caller's registers 32-47 became the called subroutine's registers 0-15. The <b>return</b> <b>instruction</b> dropped the stack by 32 words so return parameters would be visible to the caller in registers 32-47. The stack cache held 16 levels in the CPU and stack overflow and underflow was automatically handled by the microcode of the CPU. The programming model had two stacks, one for the register stack, and one for subroutine local variables. One grew up from a designated address {{in the middle of the}} address space, and the other grew down from the top of the user mode address space.|$|E
30|$|While in the ED, {{the patient}} {{received}} a fluid bolus of normal saline and morphine intravenously for analgesia. Initially, a surgical consult was called with concern for appendicitis. After the CT results were reviewed, {{the patient was}} reassessed. His abdomen was now non-tender to palpation. The patient tolerated fluids orally, and his condition continued to improve. Serial examinations continued for a total ED course of 7 h. There was no return of abdominal pain or tenderness. The patient was discharged home after arranging close follow-up with his pediatrician and discussion of <b>return</b> <b>instructions.</b> The final diagnosis of transient intussusception was made.|$|R
40|$|Modern runtime attacks {{increasingly}} {{make use}} of the powerful return-oriented programming (ROP) attack techniques and principles such as recent attacks on Apple iPhone and Acrobat products to name some. These attacks even work under the presence of modern memory protection mechanisms such as data execution prevention (DEP). In this paper, we present our tool, ROPdefender, that dynamically detects conventional ROP attacks (that are based on <b>return</b> <b>instructions).</b> In contrast to existing solutions, ROPdefender can be immediately deployed by end-users, since it does not rely on side information (e. g., source code or debugging information) which are rarely provided in practice. Currently, our tool adds a runtime overhead of 2 x which is comparable to similar instrumentation-based tools...|$|R
5000|$|Note that, in {{protected}} mode, code may always modify all segment registers except CS (the code segment selector). This {{is because}} the current privilege level (CPL) of the processor is stored in the lower 2 bits of the CS register. The only way to raise the processor privilege level (and reload CS) is through the lcall (far call) and int (interrupt) instructions. Similarly, {{the only way to}} lower the privilege level (and reload CS) is through lret (far return) and iret (interrupt <b>return)</b> <b>instructions.</b> In real mode, code may also modify the CS register by making a far jump (or using an undocumented [...] instruction on the 8086 or 8088)). Of course, in real mode, there are no privilege levels; all programs have absolute unchecked access to all of memory and all CPU instructions.|$|R
40|$|Information about {{calls to}} the {{operating}} system (or kernel libraries) made by a binary executable {{may be used to}} determine whether the binary is malicious. Being aware of this approach, malicious programmers hide this information by making such calls without using the call instruction. For instance, the ‘call addr’ instruction may be replaced by two push instructions and a <b>return</b> <b>instruction,</b> the first push pushes the address of instruction after the <b>return</b> <b>instruction,</b> and the second push pushes the address addr. The code may be further obfuscated by spreading the three instructions and by splitting each instruction into multiple instructions. This paper presents a method to statically detect obfuscated calls in binary code. The notion of abstract stack is introduced to associate each element in the stack to the instruction that pushes the element. An abstract stack graph is a concise representation of all abstract stacks at every point in the program. An abstract stack graph, created by abstract interpretation of the binary executables, may be used to detect obfuscated calls and other stack related obfuscations. 1...|$|E
30|$|For a full method load {{into the}} cache, {{we need to}} know the length of the method. This {{information}} is available in the Java class file. For compiled C code, this information can be provided in the executable. A simple convention, implemented in the linker, is to store the method length one word before the actual method starts. In order to use the method cache in an RISC processor, the ISA is extended with a prefetch instruction to force the cache load. The prefetch instruction can be placed immediately before the call or <b>return</b> <b>instruction.</b> It can also be scheduled earlier to hide the cache load latency.|$|E
40|$|We {{show that}} {{on both the}} x 86 and ARM {{architectures}} {{it is possible to}} mount return-oriented programming attacks without using return instructions. Our attacks instead make use of certain instruction sequences that behave like a return, which occur with sufficient frequency in large libraries on (x 86) Linux and (ARM) Android to allow creation of Turing-complete gadget sets. Because they do not make use of return instructions, our new attacks have negative implications for several recently proposed classes of defense against return-oriented programming: those that detect the too-frequent use of returns in the instruction stream; those that detect violations of the last-in, first-out invariant normally maintained for the return-address stack; and those that modify compilers to produce code that avoids the <b>return</b> <b>instruction...</b>|$|E
50|$|As {{a mobile}} unit {{engaged in a}} call moves away from a cell site or {{formally}} known as Base transceiver station and its signal weakens, the BSC(GSM) or RNC(3G UMTS) will automatically instruct it to tune to a different frequency, one assigned to the newly entered BTS. This process is called handoff. The BSC/RNC determines when handoff should take place by analyzing measurements of radio signal strength made by the present controlling cell site and by its neighbors. The <b>returning</b> <b>instructions</b> for handoff sent during a call must use the voice channel. The data regarding the new channel are sent rapidly (in about 50 milliseconds), and the entire returning process takes only about 300 milliseconds. After handoff, if the SID on the control channel does not match the SID programmed into the phone, then the phone assumes that it is roaming.|$|R
40|$|Abstract. Programmers obfuscate their code {{to defeat}} manual or {{automated}} analysis. Obfuscations {{are often used}} to hide malicious behavior. In particular, malicious programs employ obfuscations of stack-based instructions, such as call and <b>return</b> <b>instructions,</b> to prevent an analyzer from determining which system functions it calls. Instead of using these instructions directly, a combination of other instructions, such as PUSH and POP, are used {{to achieve the same}} semantics. This paper presents an abstract interpretation based analysis to detect obfuscation of stack instructions. The approach combines Reps and Balakrishnan’s value set analysis (VSA) and Lakhotia and Kumar’s Abstract Stack Graph, to create an analyzer that can track stack manipulations where the stack pointer may be saved and restored in memory or registers. The analysis technique may be used to determine obfuscated calls made by a program, an important first step in detecting malicious behavior. ...|$|R
40|$|This paper {{describes}} the run-time {{implementation of a}} parallel programming language. Unlike traditional designs, our system exploits both shared memory aspects and message passing features. It enjoys the benefits of both polling and interrupts, giving more weight to the former, i. e. processors do not interrupt each other unless absolutely necessary. The language/system interface deals with groups of parallel activities as whole, {{so as not to}} impose unnecessary serialization on the language implementation. Parallel block-oriented and other constructs are implemented on top of a real-time operating system. Algorithms and data structures for the distribution of newly spawned activities and for the termination of activities via parallel break and <b>return</b> <b>instructions</b> are described. Performance measurements are given to compare between possible algorithms and explain the behavior of selected ones. Keywords: groups of activities, group creation, parallel termination, dynamic load adaptation, [...] ...|$|R
40|$|A buffer {{overflow}} attack {{is perhaps the}} most common attack used to compromise the security of a host. A {{buffer overflow}} can be used to change the function return address and redirect execution to execute the attacker 2 ̆ 7 s code. We present a hardware-based solution, called SmashGuard, to protecting the return addresses stored on the program stack. SmashGuard protects against all known forms of attack on the function return address pointer. With each function call instruction a new return address is pushed onto an extra hardware stack. A <b>return</b> <b>instruction</b> compares its return address to the address {{from the top of the}} hardware stack. If a mismatch is detected, then an exception is raised. Because the stack operations and checks are done in hardware, and in parallel with the usual execution of call and return instructions, our bestperforming implementation scheme has virtually no performance overhead. While previous software-based approaches 2 ̆ 7 average performance degradation for the SPEC 2000 benchmarks is only 2. 8...|$|E
40|$|We {{introduce}} program shepherding, {{a method}} for monitoring control flow transfers during program execution {{to enforce a security}} policy. Program shepherding provides three techniques as building blocks for security policies. First, shepherding can restrict execution privileges on the basis of code origins. This distinction can ensure that malicious code masquerading as data is never executed, thwarting a large class of security attacks. Second, shepherding can restrict control transfers based on instruction class, source, and target. For example, shepherding can forbid execution of shared library code except through declared entry points, and can ensure that a <b>return</b> <b>instruction</b> only targets the instruction after a call. Finally, shepherding guarantees that sandboxing checks placed around any type of program operation will never be bypassed. We have implemented these capabilities efficiently in a runtime system with minimal or no performance penalties. This system operates on unmodified native binaries, requires no special hardware or operating system support, and runs on existing IA- 32 machines under both Linux and Windows. ...|$|E
40|$|Abstract. This paper {{presents}} a logical framework for low-level ma-chine code and code generation. We first define a calculus, called sequen-tial sequent calculus, of intuitionistic propositional logic. A {{proof of the}} calculus only contains left rules and has a linear (non-branching) struc-ture, which reflects the properties of sequential machine code. We then establish a Curry-Howard isomorphism between this proof system and machine code based on the following observation. An ordinary machine instruction corresponds to a polymorphic proof transformer that extends a given proof with one inference step. A <b>return</b> <b>instruction,</b> which turns a sequence of instructions into a program, corresponds to a logical ax-iom (an initial proof tree). Sequential execution of code corresponds to transforming a proof to a smaller one by successively eliminating the last inference step. This logical correspondence enables us to present and an-alyze various low-level implementation processes of a functional language within the logical framework. For example, a code generation algorithm for the lambda calculus is extracted from a proof of the equivalence the-orem between the natural deduction and the sequential sequent calculus. ...|$|E
40|$|Programmers obfuscate their code {{to defeat}} manual or {{automated}} analysis. Obfuscations {{are often used}} to hide malicious behavior. In particular, malicious programs employ obfuscations of stack-based instructions, such as call and <b>return</b> <b>instructions,</b> to prevent an analyzer from determining which system functions it calls. Instead of using these instructions directly, a combination of other instructions, such as PUSH and POP, are used {{to achieve the same}} semantics. This paper presents an abstract interpretation based analysis to detect obfuscation of stack instructions. The approach combines Reps and Balakrishnan's value set analysis (VSA) and Lakhotia and Kumar's Abstract Stack Graph, to create an analyzer that can track stack manipulations where the stack pointer may be saved and restored in memory or registers. The analysis technique may be used to determine obfuscated calls made by a program, an important first step in detecting malicious behavior...|$|R
50|$|The sapper then <b>returns</b> to the <b>Instruction</b> Grouping for two further {{months for}} his fire training. He is then {{permanently}} {{attached to a}} fire company.|$|R
25|$|During the struggle, Duhesme {{pointed out}} to Kléber that the Austrian left flank was weak and {{suggested}} an attack. Kléber brought the idea to Desjardin, but that general declined to directly order Mayer's division to advance because it belonged to the Army of the Ardennes. Desjardin {{felt that he had}} to send the orders through Charbonnier, but that general was too far away for the <b>return</b> <b>instructions</b> to reach Mayer in time. On 19 May Charbonnier had sent a note warning Desjardin that Mayer would only obey orders coming from his own army commander. He was reluctant to follow the orders of Pichegru to cooperate with {{the right wing of the}} Army of the North and still considered himself an independent commander. He was also focused on Charleroi which he believed was held by 8,000 enemies. On 21 May Charbonnier was near Fontaine-l'Evêque rounding up livestock for his army's use.|$|R
