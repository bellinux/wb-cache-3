269|505|Public
5000|$|Sensory Intelligence: Fundamentals of <b>robotic</b> <b>vision</b> and data-intensive computing.|$|E
5000|$|... #Article: Australian Research Council Centre of Excellence for <b>Robotic</b> <b>Vision</b> ...|$|E
50|$|Peter Corke is an Australian roboticist {{known for}} his work on Visual Servoing, field robotics, online {{education}} and the MATLAB Toolboxes for Robotics and Machine Vision. He is currently director of the Australian Research Council Centre of Excellence for <b>Robotic</b> <b>Vision</b> http://roboticvision.org, and a Professor of Robotics and Control at Queensland University of Technology (QUT). At QUT his research is concerned with <b>robotic</b> <b>vision,</b> flying robots and robots for agriculture.|$|E
40|$|Recent advancements in {{the areas}} of tracking, communications, and <b>robotics</b> <b>vision</b> sensors being pursued within NASA, as {{applicable}} to space programs, are presented. Optical and laser-based communications and tracking systems and applications to space programs are discussed. Communication systems for multiple access, broadband, high data rate, and efficient operations are given. Current efforts at 20 / 30 GHz and millimeter wave bands are summarized. The use of optical data processing in control system applications for rendezvous and docking is presented. <b>Robotics</b> <b>vision,</b> based on television, laser, and microwave sensors for space applications, is discussed. The fusion of these technologies for remote control, station keeping, tracking, inspection, and satellite repair is detailed...|$|R
30|$|Considering the {{application}} types (i.e., <b>robotics</b> <b>vision,</b> imaging, video, etc.) {{and availability of}} commercial microcontrollers (MCUs), in this work, we have set the following design objectives to facilitate the interfacing of high-speed image sensors with low-performance MCU.|$|R
40|$|International Conference on <b>Robotics,</b> <b>Vision,</b> Signal Processing & Power Applications (ROVISP) is {{organized}} by School of Electrical and Electronic Engineering, Universiti Sains Malaysia. ROVISP 2016 welcomes researchers, scientists, engineers, academicians {{as well as}} industrial professionals {{from all around the}} globe to present their research results and development activities for oral or poster presentations...|$|R
50|$|After Harvard, he co-founded a Silicon Valley <b>robotic</b> <b>vision</b> {{company that}} was covered by The New York Times. Later, he {{consulted}} for Microsoft for 18 months. In 2006, he became a full-time travel writer.|$|E
50|$|The Australian Centre for <b>Robotic</b> <b>Vision</b> is an unincorporated {{collaborative}} {{venture with}} funding of $25.6m {{over seven years}} to pursue an ambitious research agenda tackling the critical and complex challenge of applying robotics in the real world.|$|E
50|$|Image {{quality is}} {{important}} in applications that require excellent <b>robotic</b> <b>vision.</b> Algorithm based on wavelet transform for fusing images of different spectra and different foci improves image quality. Robots can gather more accurate information from the resulting improved image.|$|E
40|$|Abstract. - An {{approach}} to the design and implementation of a <b>robotics</b> <b>vision</b> system based on agent inserted in a generic multi-level architectures for mobile robotics is presented, {{that is based on}} the Unified Modelling Language. The main goal of the work is to provide a framework to perform a rigorous agent-base...|$|R
40|$|It is {{necessary}} for the system such as the <b>robotics</b> <b>vision</b> and the monitoring camera to detect the motion of the object and recognize the target in real time. However, this is difficult in conventional image processing systems constructed with a charge coupled device (CCD) camera and Neumann-type computer since information processing in this setup i...|$|R
50|$|Universal’s Spatial Vision line of {{products}} was created {{during the development}} of Neocortex. The products provide 3D vision and include Spatial <b>Vision,</b> Spatial <b>Vision</b> <b>Robotics,</b> and Spatial <b>Vision</b> Inspection.|$|R
50|$|The Centre aims {{to achieve}} {{breakthrough}} {{science and technology}} in <b>robotic</b> <b>vision</b> by addressing four key research objectives: Robust Vision (RV), Vision and Action (VA), Semantic Vision (SV), Algorithms and Architecture (AA). Together the four research objectives form the Centre’s research themes, which serve as organisational groupings of the Centre’s research projects.|$|E
50|$|In 1996, <b>Robotic</b> <b>Vision</b> Systems, Inc. (RVSI) {{first brought}} a patent {{infringement}} lawsuit against VIEW Engineering {{related to the}} coplanarity measurement of packaged semiconductor devices. In 2000, RVSI's patent was finally declared invalid and the U.S. District Court for the Central District of California {{ruled in favor of}} VIEW Engineering. Even after this ruling, RVSI contemplated continuing its appeals through 2001.|$|E
50|$|Research {{areas at}} USM include brain and neuroscience, {{environmental}} science, aquaculture, biomedical and pharmaceutical studies, {{natural language processing}} and computer aided translation, information technology, food technology, polymer science and technology, biotechnology, distance education, geographical information system, structure analysis, materials science, engineering, surface chemistry, and <b>robotic</b> <b>vision.</b> Penang has research facilities for collaborative search, particularly in coastal pollution, mangrove ecosystem and marine aquaculture.|$|E
50|$|Automatix raised {{large amounts}} of venture capital, and went public in 1983, but was not {{profitable}} until the early 1990s. In 1994, Automatix merged with another machine vision company, Itran Corp., to form Acuity Imaging, Inc. Acuity was acquired by <b>Robotics</b> <b>Vision</b> Systems Inc. (RVSI) in September 1995. As of 2004, RVSI supported the evolved Automatix machine vision package under the PowerVision brand.|$|R
40|$|The {{application}} of high-speed machine vision for close-loop position control, or visual servoing, of a robot manipulator. It provides a comprehensive coverage of {{all aspects of}} the visual servoing problem: <b>robotics,</b> <b>vision,</b> control, technology and implementation issues. While much of the discussion is quite general the experimental work described is based on the use of a high-speed binary vision system with a monocular "eye-in-hand" camera...|$|R
50|$|Both Spatial <b>Vision</b> <b>Robotics</b> and Spatial <b>Vision</b> Inspection use {{a variety}} of sensors and cameras for multi-D sensing, such as {{structured}} light sensors, camera pairs (stereopsis), webcams, lasers, Light Detection And Ranging (LIDAR), and Time Of Flight sensors.|$|R
50|$|After {{beginning}} her government {{career as}} a presidential management intern, she worked on Capitol Hill, as a senior engineer at NASA Goddard, as a senior policy analyst at the White House Office of Science and Technology Policy, and as deputy division director for technology at NASA Headquarters. Hartman has built and launched scientific balloon payloads, worked on <b>robotic</b> <b>vision,</b> overseen {{the development of the}} command and data handling systems for a variety of Earth-observing spacecraft, and served as NASA program manager for dozens of missions, the most successful of which was the Cosmic Background Explorer. Data from the COBE spacecraft gained two NASA-sponsored scientists the Nobel Prize in physics in 2006.|$|E
40|$|Modeling of {{welding process}} by <b>robotic</b> <b>vision</b> is {{basically}} a theoretical problem, means mainly on physical problem, and also technological problem. To obtain a good model of welding process by <b>robotic</b> <b>vision,</b> theoretical researches are required but also constant experimental researches of several welding processes. Until today researches of welding processes {{has been based on}} empirical and detailed experimentation. In this paper is presented welding process by robotic and automation points of view with application of new technologies. Welding robotic system has been designed with possibility to control and inspect this process. Parameters that should be controlled during the process have been identified to reach desired quality. Figure of control system of welding process by <b>robotic</b> <b>vision</b> is given in this paper...|$|E
40|$|Algorithms {{based on}} the {{correlation}} of image patches can be robust in practice but are computationally intensive due to the computational complexity of their search-based nature. Performing the search over time instead of over space is linear in nature, rather than quadratic, and results in a very efficient algorithm. This, combined with implementations which are highly efficient on standard computing hardware, yields performance of 9 frames per second on a scientific workstation. Although the resulting velocities are quantized with resulting quantization error, they {{have been shown to}} be sufficiently accurate for many <b>robotic</b> <b>vision</b> tasks such as time-to-collision and robotic navigation. Thus, this algorithm is highly suitable for realtime <b>robotic</b> <b>vision</b> research. 1 Introduction For <b>robotic</b> <b>vision</b> to be successful and practical in real-world environments, it must be robust, fast, and sufficiently accurate as appropriately defined for a given task. If an algorithm is not robust and o [...] ...|$|E
5000|$|By {{combining}} the Neocortex intelligence platform with modular sensing and control software products, Universal Robotics currently provides flexible applications for materials handling. Today’s software products include 3D machine vision products (SpatialVision, Spatial <b>Vision</b> <b>Robotics,</b> Spatial <b>Vision</b> Inspection, and automated robot programming (Autonomy). Applications include Unlimited Box Moving, Unlimited Depalletization, Random Bin Picking, Random Bag Picking, and 3D Inspection.|$|R
50|$|Motai {{also taught}} at the University of Vermont, {{offering}} classes {{in the fields of}} Sensory-based <b>robotics,</b> Computer <b>vision,</b> and Ubiquitous computing.|$|R
50|$|Universal Robotics offers three modular {{software}} product families: Neocortex provides real-time intelligence. Spatial Vision performs multi-dimensional sensing (Spatial <b>Vision</b> <b>Robotics</b> - 3D <b>vision</b> guidance, Spatial Vision Inspection - 3D visual inspection). Autonomy provides automated enhanced control of robots and machines.|$|R
40|$|Microwave Vision (MV), {{a concept}} {{originally}} developed in 1985, {{could play a}} significant role in the solution to <b>robotic</b> <b>vision</b> problems. Originally our Microwave Vision concept was based on a pattern matching approach employing computer based stored replica correlation processing. Artificial Neural Network (ANN) processor technology offers an attractive alternative to the correlation processing approach, namely the ability to learn and to adapt to changing environments. This paper describes the Microwave Vision concept, some initial ANN-MV experiments, and the design of an ANN-MV system that has led to a second patent disclosure in the <b>robotic</b> <b>vision</b> field...|$|E
40|$|Abstract:- In this work, we {{show that}} using the pinhole model as a basic single-camera, image-formation process is not most {{appropriate}} for accurate depth calculation. This is particularly true in <b>robotic</b> <b>vision</b> applications where, often, relatively close-range images must be acquired before final handling of objects. Therefore, a non-negligible error is introduced when the distance between lens center and image plane is set equal to the constant focal length regardless of object depth (i. e., a pinhole camera). The case of the lateral stereo-camera geometry is investigated, where an improved formulation for providing depth information is derived, including the related error analysis. Key-Words:- <b>robotic</b> <b>vision,</b> depth estimation, stereo camera modeling. ...|$|E
40|$|Optical {{correlator}} uses commercially-available liquid-crystal television (LCTV) {{screen as}} spatial light modulator. Correlations with this device done at video frame rates, making such operations as bar-code recognition possible at reasonable cost. With further development, such correlator useful in automation, <b>robotic</b> <b>vision,</b> and optical image processing...|$|E
40|$|Recently, the {{requirement}} for learning is constantly increasing. MOOC – massive open online courses represent educational revolution of the century. A MOOC is an online course accessible to unlimited number of participation and is an open access via the web. Mayor participants in the MOOCS are: Coursera, Udacity (Stanford, since 2012) and edX (Harvard, MIT, since 2012). In this paper two MOOCs are considered: Introduction for <b>Robotics</b> and <b>Robotics</b> <b>Vision,</b> both from the Queensland University of Technology, Brisbane, Australia...|$|R
50|$|Levin's {{most recent}} work centers around {{interactive}} <b>robotics,</b> machine <b>vision,</b> and {{the theme of}} gaze as a primary new mode for human-machine communication.|$|R
50|$|In May 2015, Kuffner brought {{together}} researchers in <b>robotics,</b> computer <b>vision,</b> and machine learning technology within Google Research to help realize the original Cloud Robotics concept.|$|R
40|$|AbstractThe {{concept of}} {{symmetry}} {{is one of}} the great universal principles used to comprehend the enormous amounts of data encountered in both the worlds of natural phenomenon and of abstract knowledge. With the advent of computers, methodology has evolved to process and generate huge amounts of information. This information is often inconsistent and ambiguous and is similar to that encountered by human perception. This article develops some commonalities between applications of symmetry and applications of computer methodology to visual perception (<b>robotic</b> <b>vision),</b> to explore the impact of developing technology on general understandings about human knowledge. These commonalities suggest that advances in <b>robotic</b> <b>vision</b> will enlarge the study of symmetry, reveal astonishing new types of symmetry, and produce unexpected applications of philosophical interrelationships between abstract and perceptual knowledge...|$|E
40|$|Abstract:- In {{this paper}} a Cellular Fuzzy Associative Memory {{containing}} fuzzy rules for gray image fuzzification is designed, {{considered as a}} subsystem of a CNN-based architecture able to store bidimensional patterns. After establishing the fuzzy rules which characterize the required FAM, these rules are properly codified and stored in a Cellular Nonlinear Network behaving as a memory. A numerical example concerning with the stereoscopic vision of a mobile robot is reported {{to show how the}} synthesized memory can process bidimensional patterns for <b>robotic</b> <b>vision</b> purposes. Key words: CNN-based systems, cellular fuzzy processor, fuzzy associative memories It is well known that in <b>robotic</b> <b>vision</b> systems significant performances are required for pattern recognition to assure safety to any automatic process. For this reason, the specific extraction of informatio...|$|E
40|$|The {{field of}} <b>robotic</b> <b>vision</b> has {{advanced}} dramatically recently {{with the development}} of new range sensors. Tremendous progress has been made resulting in significant impact on areas such as robotic navigation, scene/environment understanding, and visual learning. This edited book provides a solid and diversified reference source for some of the most recent important advancements in the field of <b>robotic</b> <b>vision.</b> The book starts with articles that describe new techniques to understand scenes from 2 D/ 3 D data such as estimation of planar structures, recognition of multiple objects in the scene using different kinds of features as well as their spatial and semantic relationships, generation of 3 D object models, approach to recognize partially occluded objects, etc. Novel techniques are introduced to improve 3 D perception accuracy with other sensors such as a gyroscope, positioning accuracy with a visual servoing based alignment strategy for microassembly, and increasing object recognition reliability using related manipulation motion models. For autonomous robot navigation, different vision-based localization and tracking strategies and algorithms are discussed. New approaches using probabilistic analysis for robot navigation, online learning of vision-based robot control, and 3 D motion estimation via intensity differences from a monocular camera are described. This collection will be beneficial to graduate students, researchers, and professionals working in the area of <b>robotic</b> <b>vision...</b>|$|E
40|$|Abstract- An {{approach}} to the design and implementation of a <b>robotics</b> <b>vision</b> system based on agent inserted in a generic multilevel architectures for mobile robotics is presented, {{that is based on}} the Unified Modelling Language. The main goal of the work is to provide a framework to perform a rigorous agent-based design process for cognitive architectures both {{in the case of a}} single robot, and in a multi-robot scenario. Details of the methodology, system implementation using FIPA-OS environment, along with real experiments are reported...|$|R
40|$|The {{proceeding}} is {{a collection}} of research papers presented, at the 8 th International Conference on <b>Robotics,</b> <b>Vision,</b> Signal Processing and Power Applications (ROVISP 2013), by researchers, scientists, engineers, academicians as well as industrial professionals from all around the globe. The topics of interest are as follows but are not limited to: • Robotics, Control, Mechatronics and Automation • Vision, Image, and Signal Processing • Artificial Intelligence and Computer Applications • Electronic Design and Applications • Telecommunication Systems and Applications • Power System and Industrial Applications...|$|R
50|$|CogPrints is an {{electronic}} archive in which authors can self-archive papers {{in any area}} of cognitive science, including psychology, neuroscience, and linguistics, and many areas of computer science (e.g., artificial intelligence, <b>robotics,</b> <b>vision,</b> learning, speech, neural networks), philosophy (e.g., mind, language, knowledge, science, logic), biology (e.g., ethology, behavioral ecology, sociobiology, behaviour genetics, evolutionary theory), medicine (e.g., psychiatry, neurology, human genetics, imaging), anthropology (e.g., primatology, cognitive ethnology, archeology, paleontology), {{as well as any}} other portions of the physical, social and mathematical sciences that are pertinent to the study of cognition.|$|R
