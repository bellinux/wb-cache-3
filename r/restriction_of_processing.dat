2|10000|Public
3000|$|Notification {{obligation}} regarding rectification or erasure {{of personal}} data, or <b>restriction</b> <b>of</b> <b>processing</b> [...]...|$|E
40|$|This thesis {{examined}} {{working memory}} (WM) and high-level cognition (HLC) in children. Previous {{research has shown}} that reducing maintenance opportunities in complex span tasks (CSTs) by restricting processing times can strengthen the WM-HLC relationship. This suggests that maintenance strategies are unimportant in the WM-HLC relationship. However, the <b>restriction</b> <b>of</b> <b>processing</b> times equally for all participants has not previously been addressed. This thesis assessed WM in 92 children aged seven to eight years of age using computer-paced numerical, verbal and visuospatial CSTs that titrated processing times individually for each child. Performance was compared to that in a condition where processing times were not restricted. Based on multi-component theories of WM, domain-specific and domain-general relationships with HLC (i. e. nonverbal reasoning, reading, mathematics) were examined. The effects of time constraints on the underlying mechanisms of each CST (storage, processing time, recall time, processing accuracy), their relationships with each other, and with HLC were investigated. In addition, the contributions of the broader executive abilities of inhibition and task-switching to the WM-HLC relationship were examined. Finally, the link between current WM abilities and mathematics performance two years later was also explored. Results showed that the two administration conditions accounted for shared and unique variance in HLC, suggesting measurement of different and similar cognitive abilities important in certain higher-order cognitive tasks. Examination of the underlying CST mechanisms showed that numerical WM best predicted concurrent HLC, with processing time replacing storage as a predictor when time constraints were introduced. Longitudinally, numerical, verbal and visuospatial WM predicted mathematics two years later. This identified WM capacity in seven to eight year olds important in mathematical ability at the ages of nine to ten years. Task-switching and inhibition did not predict HLC. Implications for multi-component and attention-based theories of WM, the importance of processing speeds and the role of maintenance strategy in the WM-HLC relationship are discussed...|$|E
40|$|Abstract：In this paper, {{we propose}} a {{resin-based}} composite materials and its preparation process, because traditional composite materials craft has shortcomings such as labor-intensive, low productivity and quality unstable. It can {{eliminate the need}} for mold processing and manufacturing sectors, and the manufacturing costs reduce significantly. Reinforcing materials can play a full role to enhance, and the volume of products can be great without the <b>restrictions</b> <b>of</b> traditional <b>processing</b> equipment. The speed of product replacement is accelerated...|$|R
40|$|We {{demonstrate}} a standards-based middleware platform, including the QuO adaptive middleware framework and the TAO CORBA A/V Streaming Service, for developing adaptive multimedia applications that are better architected {{and easier to}} modify than ad-hoc architectures and that can adapt to changes in resource availability to meet QoS requirements. These are presented {{in the context of}} an Unmanned Aerial Vehicle (UAV) video distribution application. We present experimental results showing how the UAV application uses adaptive behavior to meet timeliness requirements in the face <b>of</b> <b>restrictions</b> in <b>processing</b> power or network bandwidth. 1...|$|R
40|$|Heterologous gene {{expression}} in either (1) the glycosylation-defective, mutant Chinese hamster ovary cell line, Lec 3. 2. 8. 1, or (2) {{the presence of}} the alpha-glucosidase inhibitor, N-butyldeoxynojirimycin facilitates the trimming of N-linked glycans of glycoproteins to single N-acetylglucosamine (GlcNAc) residues with endoglycosidase H (endo H). Both approaches are somewhat inefficient, however, with as little as 12 % of the total protein being rendered fully endo H-sensitive under these conditions. It is shown here that the combined effects of these approaches on the <b>restriction</b> <b>of</b> oligosaccharide <b>processing</b> are essentially additive, thereby allowing the production of glycoproteins that are essentially completely endo H-sensitive. The preparation of a soluble chimeric form of CD 58, the ligand of the human T-cell surface recognition molecule CD 2, illustrates the usefulness of the combined approach when expression levels are low or the deglycosylated protein is unstable at low pH. The endo H-treated chimera produced crystals of space group P 3 (1) 21 or P 3 (2) 21, and unit cell dimensions a = b = 116. 4 A, c = 51. 4 A alpha = beta = 90 degrees, gamma = 120 degrees, that diffract to a maximum resolution of 1. 8 A...|$|R
40|$|As {{is known}} from psychometrics, <b>restriction</b> <b>of</b> task <b>processing</b> {{time by the}} {{instruction}} to respond as quickly and accurately as possible leads to task-unspecific cognitive processing. Since this task processing mode is used in most functional neuroimaging studies of human cognition, this may evoke cortical activity that is functionally not essential for the particular task under investigation. Using topographic recordings of event-related slow cortical potentials, two experiments have been performed to investigate whether cortical activity during <b>processing</b> <b>of</b> a visuo-spatial imagery task is substantially influenced by the time provided to process the task. Furthermore, it was investigated whether this effect is additionally modulated by a subjects task-specific ability. The instruction to respond as quickly and accurately as possible led to increased negative slow cortical potential amplitudes over parietal and frontal regions and significantly interacted with task-specific ability. While cortical activity recorded over parietal and frontal regions was different between subjects with low and high spatial ability when processing time was unrestricted, no such {{differences were found between}} ability groups when subjects were instructed to answer both quickly and accurately. These results suggest that restricting processing time has considerable effects on the amount and the pattern of brain activity during cognitive processing and should be taken into account more explicitly in the experimental design and interpretation of neuroimaging studies of cognition...|$|R
40|$|Reading {{comes with}} a clear {{binocular}} advantage, expressed in shorter fixation times and fewer regressions in binocular relative to monocular visual presentations. Little is known, however, about whether the cost associated with monocular viewing derives primarily from the encoding of foveal information or in obtaining a preview benefit from upcoming parafoveal text. In the present sentence reading eye tracking experiment, the authors used a novel dichoptic binocular gaze-contingent moving window technique to selectively manipulate the amount of text {{made available to the}} reader both binocularly and monocularly in the fovea and parafovea on a fixation-by-fixation basis. This technique allowed the authors to quantify disruption to reading caused by prevention of binocular fusion during direct fixation of words and parafoveal preprocessing of upcoming text. Sentences were presented (a) binocularly; (b) monocularly; (c) with monocular text to the left of fixation; (d) with monocular text to the right of fixation; or (e) with all words other than the fixated word presented binocularly. A robust binocular advantage occurred for average fixation duration and regressions. Also, while there was a limited cost associated with monocular foveal <b>processing,</b> the <b>restriction</b> <b>of</b> parafoveal <b>processing</b> to monocular information was particularly disruptive. The findings demonstrate the critical importance of a unified binocular input for the efficient preprocessing text to the right of fixation...|$|R
40|$|Abstract — Wireless Sensor Network (WSNs) {{have become}} a new {{information}} collection and monitoring solution {{for a variety of}} application. In WSN, sensor nodes have strong hardware and software <b>restriction</b> in terms <b>of</b> <b>processing</b> power, memory capability, power supply and communication throughput. Due to these restrictions, fault may occur in sensor. This paper presents a distance based fault detection (DBFD) method for wireless sensor network using the average of confidence level and sensed data of sensor node. Simulation results show that sensor nodes with permanent faults and without fault which was judged as faulty are identified with high accuracy {{for a wide range of}} fault rate, and keep false alarm rate for different levels of sensor fault model and also correct nodes are identified by accuracy. Keywords-wireless sensor networks; sensor nodes; communication throughput; distance based fault detection; confidence level; I...|$|R
40|$|Virus {{discovery}} {{based on}} cDNA-AFLP (amplified fragment length polymorphism) (VIDISCA) {{is a novel}} approach that provides a fast and effective tool for amplification of unknown genomes, e. g., of human pathogenic viruses. The VIDISCA method is based on double <b>restriction</b> enzyme <b>processing</b> <b>of</b> a target sequence and ligation of oligonucleotide adaptors that subsequently serve as priming sites for amplification. As the method {{is based on the}} common presence <b>of</b> <b>restriction</b> sites, it results in the generation of reproducible, species-specific amplification patterns. The method allows amplification and identification of viral RNA/DNA, with a lower cutoff value of 10 (5) copies/ml for DNA viruses and 10 (6) copies/ml for the RNA viruses. Previously, we described the identification of a novel human coronavirus, HCoV-NL 63, {{with the use of the}} VIDISCA metho...|$|R
40|$|In this paper, we {{describe}} new concept services based on speech processing technologies {{for the new}} digital/mobile era called a ubiquitous society. First, we propose a compact and noise robust embedded speech recognition middleware implemented on microprocessors aiming for sophisticated HMIs (Human Machine Interfaces) of car information systems. The compactness is essential for embedded systems because there are strict <b>restrictions</b> <b>of</b> CPU (Central <b>Processing</b> Unit) power and available memory capacities. Second, we report a promising multi-language interpreter named “MobilingualTM ” based on speech recognition. Our research activities aim to realize sophisticated and human-centered intelligent HMIs that will be absolutely necessary in the ubiquitous social environment. For the embedded speech middleware, we propose first, a noise robust and compact Spectral Subtraction(SS) method after exhausting evaluation stages using real speech data recorded at car running environments. Next, we propose very novel memory assignment of acoustic models based on the product codes or sub-vector quantization technique resulting on 1 fourth memory reduction for the 2000 -word vocabulary...|$|R
50|$|A {{study which}} {{directly}} tested {{the relationship between}} the <b>restriction</b> <b>of</b> the attentional window in simultanagnosia compared with the vision of healthy participants with normal limits <b>of</b> visual <b>processing</b> confirmed the limitations of difficulties of patients with simultanagnosia.|$|R
40|$|Impossibility {{of cloning}} and {{deleting}} of unknown states are important <b>restrictions</b> on <b>processing</b> <b>of</b> {{information in the}} quantum world. On the other hand, a known quantum state can always be cloned or deleted. However if we restrict the class of allowed operations, there will arise restrictions {{on the ability of}} cloning and deleting machines. We have shown that cloning and deleting of known states is in general not possible by local operations. This impossibility hints at quantum correlation in the state. We propose dual measures of quantum correlation based on the dual <b>restrictions</b> <b>of</b> no local cloning and no local deleting. The measures are relative entropy distances of the desired states in a (generally impossible) perfect local cloning or local deleting process from the best approximate state that is actually obtained by imperfect local cloning or deleting machines. Just like the dual measures of entanglement cost and distillable entanglement, the proposed measures are based on important processes in quantum information. We discuss their properties. For the case of pure states, estimations of these two measures are also provided. Interestingly, the entanglement of cloning for a maximally entangled state of two two-level systems is not unity. Comment: 13 pages, 3 figures, RevTeX 4; v 2 : published versio...|$|R
40|$|Adaptation of {{distributed}} software {{to maintain the}} best possible application performance {{in the face of}} changes in available resources is an increasingly important and complex problem. In this paper, we discuss the application of the QuO adaptive middleware framework and the CORBA A/V Streaming Service to the development of real-time embedded applications. We demonstrate a standards-based middleware platform for developing adaptive applications that are better architected and easier to modify and that can adapt to changes in resource availability to meet QoS requirements. These are presented {{in the context of an}} Unmanned Aerial Vehicle (UAV) video distribution application. The UAV application is developed using QuO and the A/V Streaming Service, and uses adaptive behavior to meet timeliness requirements in the face <b>of</b> <b>restrictions</b> in <b>processing</b> power and network bandwidth. We also present some experimental results we have gathered for this application. ...|$|R
5000|$|There {{are many}} surprises in the language, for example that <b>restriction</b> <b>of</b> {{elements}} works differently from <b>restriction</b> <b>of</b> attributes.|$|R
40|$|This {{thesis is}} an {{investigation}} of the role of formulaic language in second language (L 2) speech fluency development, within a cognitive and information processing framework. Fluency has been studied and defined in terms of temporal variables of speech such as rate of speech, pause frequency and distribution, and the length of fluent runs between pauses. It has been suggested by several researchers that the key to fluency in spontaneous speech is mastery of a repertoire of formulaic language sequences, multiword strings processed mentally as single words (Schmidt, 1991; Towell, Hawkins, and Bazergui, 1996; Chambers, 1998). If formulaic sequences are automatized or stored and retrieved as wholes from long term memory so as to allow longer lexical units to be produced within the limits <b>of</b> controlled <b>processing</b> (McLaughlin, Rossman, and McLeod, 1983; Kahnemann and Treismann, 1984; DeKeyser, 2001) and short term memory (Anderson, 1983; Baddeley, 1988), then they may facilitate spontaneous speech under the constraints of real time. The present study was designed to examine whether this could be so. The study draws on a synthesis of research from three areas: fluency and its development in second language (L 2) speech; formulaic language, multi-word lexical units which are stored and retrieved in long-term memory so as to be retrieved as wholes; social and cultural factors related to fluency development and formulaic language use, including first language and culture, voice, and identity. The research was interpreted in light of psycholinguistic knowledge about mental processes underlying L 2 speech production, particularly the growing evidence that formulaic language sequences are fundamental to fluent language production as they allow production to occur despite the <b>restrictions</b> <b>of</b> controlled <b>processing</b> and the constraints of short term memory capacity. The hypotheses which frame the research centre around the idea that increased use of formulaic language units by learners over time facilitates the development of speech fluency as measured by temporal variables such as speech rate, pause phenomena, and the length of fluent runs occurring between pauses. Specifically, it was hypothesized that, with continued learning and experience, L 2 speech would exhibit a faster rate of production, a greater proportion of production time spent speaking as opposed to pausing, longer runs between pauses, and that formulaic sequences would appear more frequently in the longer runs between pauses. (Abstract shortened by UMI. ...|$|R
50|$|In the 1990s, Japan's {{environmental}} legislation was further tightened. In 1993 the government reorganized the environment law system and legislated the Basic Environment Law (環境基本法) and related laws. The law includes <b>restriction</b> <b>of</b> industrial emissions, <b>restriction</b> <b>of</b> products, <b>restriction</b> <b>of</b> wastes, improvement of energy conservation, promotion <b>of</b> recycling, <b>restriction</b> <b>of</b> land utilization, arrangement of environmental pollution control programs, relief of victims and provision for sanctions. The Environment Agency {{was promoted to}} full-fledged Ministry of the Environment in 2001, {{to deal with the}} deteriorating international environmental problems.|$|R
40|$|This {{research}} {{effort to}} search the contents president power restriction in achieving constitutional governmant in Indonesia. The <b>restriction</b> power <b>of</b> president related to <b>restriction</b> <b>of</b> president authority. In other sides <b>restriction</b> <b>of</b> president power can be viewed thorought functional relation among president with House of representative council (DPR), representative people assembly (MPR), Local Representative Council (DPD), and functional relation among president with Supreme of court (MA) and Constitutional Court (MK). The result of research shown that the <b>restriction</b> content <b>of</b> president power can be viewed not only <b>restriction</b> the time <b>of</b> president 2 ̆ 7 s office but also <b>restriction</b> <b>of</b> content presiden authority, i. e restriction to choose state officers and restriction in law making. And <b>restriction</b> <b>of</b> content president power can be viewed in functional president relation with legislative and constitutive institutions...|$|R
40|$|Wider {{coverage}} of observation missions will increase onboard power restrictions while, {{at the same}} time, pose higher demands from the perspective <b>of</b> <b>processing</b> time, thus asking for the exploration of novel high-performance and low-power processing architectures. In this paper, we analyze the acceleration of spectral unmixing, a key technique to process hyperspectral images, on multicore architectures. To meet onboard processing restrictions, we employ a low-power Digital Signal Processor (DSP), comparing processing time and energy consumption with those of a representative set of commodity architectures. We demonstrate that DSPs offer a fair balance between ease of programming, performance, and energy consumption, resulting in a highly appealing platform to meet the <b>restrictions</b> <b>of</b> current missions if onboard processing is required...|$|R
40|$|Warpage {{and poor}} {{dimensional}} stability of rotomoulded products {{are two of}} the main obstacles to the use of this technique in the production of engineering parts. The knowledge of the effect <b>of</b> the <b>processing</b> conditions on the shrinkage of rotomoulded parts will allow overcoming some <b>of</b> the <b>restrictions</b> <b>of</b> this process. In the present work the influence <b>of</b> the <b>processing</b> conditions on the development of shrinkage and warpage of rotomoulded parts was studied. The moulding of the parts was performed using a rotational moulding machine build at the University of Minho. The shrinkage and the warpage of the moulded parts were assessed using 3 D MMC (3 D measuring Machine Control) equipment, and understanding the microstructural development...|$|R
5000|$|<b>Restriction</b> <b>of</b> scalars can {{be viewed}} as a functor from -modules to -modules. An -homomorphism [...] {{automatically}} becomes an -homomorphism between the <b>restrictions</b> <b>of</b> [...] and [...] Indeed, if [...] and , then ...|$|R
40|$|The {{present study}} used the N 400, an {{electrophysiological}} correlate <b>of</b> semantic <b>processing,</b> to investigate 19 - and 24 -month-old children's ability {{to integrate the}} meaning of words in a sentential context. Children listened passively to semantically appropriate sentences and to sentences in which the object noun violates the selection <b>restriction</b> <b>of</b> the verb. The event-related potentials of both age groups revealed an N 400 on inappropriate object nouns. This indicates that the children are able to semantically integrate words into sentence contexts. Furthermore, the result implies that selection <b>restrictions</b> are part <b>of</b> the children's first verb representations...|$|R
25|$|Informally, a <b>restriction</b> <b>of</b> a {{function}} f {{is the result}} of trimming its domain. More precisely, if S is any subset <b>of</b> X, the <b>restriction</b> <b>of</b> f to S is the function f|S from S to Y such that f|S(s) = f(s) for all s in S. If g is a <b>restriction</b> <b>of</b> f, then it is said that f is an extension of g.|$|R
30|$|When {{comparing}} {{treatment and}} growth {{changes of the}} three groups, {{it was observed that}} there is a <b>restriction</b> <b>of</b> maxillary forward displacement in both experimental groups compared to the control group (Table  7). Regarding the effective length of the maxilla (Co-A), there was a statistically significant <b>restriction</b> <b>of</b> maxillary growth between G 1 and the control group; however, <b>restriction</b> <b>of</b> maxillary growth of G 2 was similar to G 1 and the control group. These results agree with previous studies that also found significant <b>restrictions</b> <b>of</b> maxillary growth during Jasper Jumper [10],[11],[14],[17] and Bionator therapies [18],[19].|$|R
40|$|Abstract. In {{order to}} solve the {{bottleneck}} problem <b>of</b> polymer product <b>processing</b> striving for micro scale and precision or macro scale and complication in modern manufacturing, a concept of differential and integral method applied in advanced manufacture of polymer materials is brought up. On the base of this concept, principles of injection molding, extrusion, electrostatic spinning, nano-composite processing and structure innovation of polymer products have been studied; a series of new methods <b>of</b> polymer <b>processing</b> and molding, new equipments, and new technologies of product application have been invented. Some industrial application results prove that, the concept of differential and integral method applied in advanced manufacture of polymer materials is a valuable guide {{to break through the}} <b>restriction</b> <b>of</b> traditional manufacturing mode, and to develop new method <b>of</b> polymer <b>processing</b> and new technologies of polymer products application...|$|R
40|$|In {{this paper}} we {{consider}} examples of partially hyperbolic actions: <b>restrictions</b> <b>of</b> Weyl chamber flows on SL(n, R) /Γ (n ≥ 4). We show that generic <b>restrictions</b> <b>of</b> rank {{at least two}} are locally rigid. Our approach combines the geometry of the invariant foliations for the action and the algebraic properties of the group SL(n, R). The method is applicable to <b>restrictions</b> <b>of</b> Weyl chamber flows on other homogeneous spaces...|$|R
3000|$|... the <b>restriction</b> <b>of</b> x to its N largest-magnitude components; by x|T (A|T) the <b>restriction</b> <b>of</b> x (A) to the {{elements}} (columns) of indices in the set T; and by |T| the cardinality of the set T.|$|R
50|$|The <b>Restriction</b> <b>of</b> Hazardous Substances Directive 2002/95/EC, (RoHS 1), {{short for}} Directive on the <b>restriction</b> <b>of</b> {{the use of}} certain {{hazardous}} substances in electrical and electronic equipment, was adopted in February 2003 by the European Union.|$|R
50|$|Similar European {{directives}} {{protecting the}} environment and health, parallel to the Battery Directive, are the <b>Restriction</b> <b>of</b> Hazardous Substances (RoHS), Waste Electrical and Electronic Equipment (WEEE) and Registration, Evaluation, Authorisation and <b>Restriction</b> <b>of</b> Chemicals (REACH) directives.|$|R
50|$|The b-sentences above do {{not contain}} {{violations}} <b>of</b> the c-selectional <b>restrictions</b> <b>of</b> the predicates is wilting and drank; they are, rather, well-formed from a syntactic point of view (hence #, not *), for the arguments the building and a car satisfy the c-selectional <b>restrictions</b> <b>of</b> their respective predicates, these restrictions requiring their arguments to be nouns or noun phrases. Just the s-selectional <b>restrictions</b> <b>of</b> the predicates is wilting and drank are violated in the b-sentences.|$|R
40|$|Efficient {{utilization}} <b>of</b> <b>processing</b> {{resources in}} a large, multiuser parallel computer depends on processor allocation algorithms that minimize system fragmentation. We propose three processor allocation algorithms for the k-ary n-cube class of parallel architectures, {{which includes the}} hypercube and multidimensional torus. The k-ary Partner strategy is a conventional contiguous processor allocation strategy that improves subcube recognition. The non-contiguous Multiple Buddy and Multiple Partner strategies lift the <b>restriction</b> <b>of</b> contiguity {{in order to address}} the problem of fragmentation associated with contiguous strategies. Simulations compare the performance of these three strategies with the performance of other k-ary n-cube allocation strategies, showing that non-contiguous allocation provides significantly increased system utilization by eliminating fragmentation. 1 Introduction Our work addresses the problem of processor allocation in distributed memory multicomputers. Allocat [...] ...|$|R
40|$|In this paper, {{we present}} the {{information}} search system using object category recognition, which is queried by image from mobile phone camera or from photo sharing service on internet. In such system, processing speed {{is an important}} requirement. We adopted “Standard Model” proposed by T. Serre in 2005, and improved processing speed by replacing Gabor filter to Haar wavelet, vector quantization of feature patch, and <b>restriction</b> <b>of</b> calcula-tion area. In addition, by retaining the information of each feature’s position, it compensates the accuracy {{which is a little}} reduced in exchange <b>of</b> <b>processing</b> speed. We implemented this method to server system, and proved this system can work in practical processing time. Through the experiment for Caltech- 101 image database, we confirmed value of this system. 1...|$|R
30|$|A {{solution}} of (2.2) {{is said to}} be maximal if it is not a proper <b>restriction</b> <b>of</b> another solution. As in the case of ODEs, Zorn’s lemma implies that any solution is the <b>restriction</b> <b>of</b> a maximal solution.|$|R
3000|$|As {{noted in}} Definition  2.8, the <b>restriction</b> <b>of</b> π to S is injective. More generally, in Definition  2.10, the <b>restriction</b> <b>of</b> π_n to the subset (S^X^n, 1) of G_ 0 [...] ^n S_d = G_ 0 ^X^n S_d^(n) is injective.|$|R
40|$|This {{article is}} devoted to the {{investigation}} of forensic and psychological features of persons sentenced to <b>restriction</b> <b>of</b> liberty {{on the basis of a}} psychological and sociological analysis of persons sentenced to <b>restriction</b> <b>of</b> freedom registered at penal institutions of the Kaliningrad region. An analysis of the results of the study suggest that, during the sentence period, those sentenced to <b>restriction</b> <b>of</b> freedom either do not reject the commonly accepted norms, values, and behavior patterns or demonstrate the medium degree of rejection. This category of convicted persons shows either low or medium degree of readiness for delinquent behavior and aggression. In most cases, those sentenced to <b>restriction</b> <b>of</b> liberty are able to control the behavioral manifestations of emotional reactions...|$|R
40|$|This article {{examines}} <b>restrictions</b> <b>of</b> activity experienced by partially sighted individuals when accessing football opportunities {{at the grassroots}} level. The social relational understanding of disability enables {{an understanding of the}} manifestation <b>of</b> socially imposed <b>restrictions</b> <b>of</b> activity and ‘impairment effects’ within this particular sporting context. Although some players experience impairment effects, <b>restrictions</b> <b>of</b> activity are also socially imposed and constitute disability. The organisation of the British Blind Sport Visually Impaired Football League (BBSVIFL) forces players to travel long distances to participate and poor awareness of opportunities presents a further socially imposed <b>restriction</b> <b>of</b> activity. An increasing emphasis on competition over participation in the BBSVIFL and the classification of partially sighted footballers are socially imposed <b>restrictions</b> <b>of</b> activity for players with more severe visual impairment. A change in the format of football in the BBSVIFL from five-a-side to Futsal, the format of small-sided football recognised by Federation Internationale de Football Association and played in all international tournaments, raises further concerns. For players with more severe visual impairment, this change could lead to another socially imposed <b>restriction</b> <b>of</b> activity which has the potential to leave them in ‘no man’s land’ in terms of access to football opportunities...|$|R
40|$|It is {{of great}} {{importance}} that enemy aircraft can be detected by a radar. Good knowledge about one’s own detectability is also needed to make one’s own visibility as low as possible. Obtaining the aircraft radar signature involves solving a scattering problem with a large, low-observable aircraft. Briefly explained; the incident radar wave induces a current distribution {{on the surface of}} the scatterer. Using theMethod ofMoments (MoM), this current distribution can be found as the solution of an integral equation. The current distribution is expanded in a set of basis functions. Because every pair of basis functions interacts through the Green’s function, the continuous equation turns into a matrix equation after discretization. The matrix in this equation is a dense matrix. It is not desirable for practical problems to save the large system matrix, because this limits the problem size considerably. The Fast Multipole Method (FMM) became popular because it makes it possible to reduce the memory storage and the work needed to solve the discretized integral equation greatly. The work scales proportional to O(N 3 2), where N is the number of unknowns. The Multi Level Fast Multipole Algorithm (MLFMA) reduces the required memory and computational complexity even more to O(N logN) by having different levels of clustering. Radar signature computations are, with the use of theMulti Level FastMultipole Algorithm, still computationally intensive. Graphics Processing Units (GPU’s) have the potential of high computational power at relatively low cost. Given the hardware and software <b>restrictions</b> <b>of</b> Graphics <b>Processing</b> Units, some parts of the Multi Level FastMultipole Algorithmare better suited for calculations onGraphics ProcessingUnits than others. Only by perfectly understanding the properties <b>of</b> Graphics <b>Processing</b> Units, the applicability of theMulti Level Fast Multipole Algorithmcan be fully exploited. Matrix vector multiplications are the most time consuming parts in the Multi Level Fast Multipole Algorithm and are suitable for parallel computations. Therefore, this part of the algorithmis implemented on theGraphics Processing Units. A discretized Poisson equation will serve as a model problem for the Multi Level Fast Multipole Algorithm computation. The Poisson equation is discretized with finite differences on a structured grid in two dimensions. The discretized Poisson equation is iteratively solved on a Graphics Processing Unit. When the calculations are performed on a Graphics Processing Unit, they take up to 11 times less time in comparison with the same system performed on a single core <b>of</b> a Central <b>Processing</b> Unit (CPU). Three small test problems for theMulti Level FastMultipole Algorithm are used to compare the performance of different implementation methods. The test problems have a realistic structure, but have a smaller number of unknowns compared to real problems. Like inmany other applications, the bottleneck <b>of</b> Graphics <b>Processing</b> Units is the fact that information has to be sent back and forth. When a large amount of data has to be sent back and forth, the Graphics Processing Unit is not faster than a Central Processing Unit. Three test problems are acceleraElectrical Engineering, Mathematics and Computer ScienceNumerical AnalysisApplied Mathematic...|$|R
