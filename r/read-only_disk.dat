3|28|Public
50|$|All {{converted}} {{files are}} available and writable in the default subvolume of the Btrfs. A sparse file holding all of the references to the original ext2/3/4 filesystem is created in a separate subvolume, which is mountable on its own as a <b>read-only</b> <b>disk</b> image, allowing both original and converted file systems to be accessed at the same time. Deleting this sparse file frees up the space and makes the conversion permanent.|$|E
40|$|Two {{methods of}} multiple/large/foreign {{databases}} processing using massively parallel computers are described. The first method employs a Distributed Cache Subsystem (DCS) offering the total memory of parallel processing nodes {{as a very}} large <b>read-only</b> <b>disk</b> cache for other parallel processing nodes. The second method {{is based on a}} Database Slicing (DS) algorithm that provides logical partitioning of the entire database between the processing nodes. These methods were implemented using n-parallel PROLOG from Paralogic. Results of experiments on an nCUBE- 2 parallel computer are presented. INTRODUCTION It is well-known that Prolog language can be used efficiently as a 4 GL query language to access and process relational databases [1]. Furthermore the Prolog language is well suited to run on a massively parallel computers. In recent years a large amount of work has been done investigating parallel Prolog execution models [2]. Our interest is determining whether parallel Prolog running on [...] ...|$|E
40|$|ECMA Technical Committee TC 31 was {{established}} in 1984 for the standardization of Optical Disks and Optical Disk Cartridges (ODC). Since its establishment, the Committee has made major contributions to ISO/IEC SC 23 toward the development of International Standards for 90 mm, 120 mm, 130 mm, 300 mm, and 356 mm media. Numerous standards have been developed by TC 31 and published by ECMA, almost {{all of which have}} also been adopted by ISO/IEC under the fasttrack procedure as International Standards. In February 1997 a group of ten Companies, known as the DVD Consortium, proposed to TC 31 to develop an ECMA Standard for the first member of a family of 120 mm optical disks. TC 31 adopted this project and started work on a first ECMA Standard for DVD- Read-Only disks. This ECMA Standard specifies the physical characteristics of such a disks which can be used for video, audio or data applications. A standard for volume and file structure common to these three types of application has been developed in ECMA Technical Committee TC 15. Further work has been undertaken for a rewritable disk known as DVD-RAM, for a case for such disks, and for a writable disk DVD-R. This work is supported by nine members of the DVD Forum. This Standard ECMA- 267 specifies four Types of DVD- Read-Only disks with a nominal capacity from 4, 7 Gbytes to 17, 0 Gbytes. Standard ECMA- 268 specifies a 80 mm DVD- <b>Read-Only</b> <b>disk</b> which differs from that of this Standard ECMA- 267 only where the relevant parameters depend on the dimension of the diameter. Four Types of such DVD disks wit...|$|E
5000|$|A small notch disk {{identifies}} {{that it is}} writable, {{detected by}} a mechanical switch or phototransistor above it; {{if it is not}} present, the disk can be written; in the 8-inch disk the notch is covered to enable writing while in the 5¼-inch disk the notch is open to enable writing. Tape may be used over the notch to change the mode of the disk. Punch devices were sold to convert <b>read-only</b> <b>disks</b> to writable ones and enable writing on the unused side of single sided disks; such modified disks became known as flippy disks.|$|R
40|$|The {{objective}} {{of this paper is}} to present an efficient implementation of a recently known index for text databases presented in the literature, when the database is stored on <b>read-only</b> optical <b>disks,</b> known as cd-roms. The implementation is built on top of a new and simple index for texts called pat array (also called suffix array). Considering the limitations of <b>read-only</b> optical <b>disks,</b> which are 10 to 20 times slower than magnetic disks, we propose an additional data structure and searching algorithm for pat arrays that reduces the number of disk accesses and the distance traveled by the optical head...|$|R
50|$|Forensic disk {{controllers}} intercept write commands {{from the}} host operating system, {{preventing them from}} reaching the drive. Whenever the host bus architecture supports it the controller reports that the drive is <b>read-only.</b> The <b>disk</b> controller can either deny all writes to the disk and report them as failures, or use on-board memory to cache the writes {{for the duration of}} the session.|$|R
40|$|The atomic force {{microscope}} (AFM), {{with its}} ability to image and modify surfaces on the nanometer scale, offers the potential for simple, compact, high-density data-storage devices. At {{the heart of the}} technique is a microfabricated cantilever with a sharp tip on the end. Using modern micromachining techniques, it is possible to batch fabricate cantilevers with tips that are sharp on the scale of 100 Å. We have pursued a particular AFM storage scheme based on mechanical readback of topographic data using high-frequency, piezoresistive silicon cantilevers. Areal densities of 65 Gbit/in 2 have been demonstrated, with readback rates greater than 10 Mbit/s. Nanoreplication techniques have been used to produce <b>read-only</b> <b>disks.</b> In addition, a write-once scheme was developed that uses integrated heating elements on the cantilevers in order to perform thermomechanical writing on a polymer substrate. Considerable {{progress has been made in}} addressing critical issues such as data rate, reliability, and practical implementation, but significant challenges still remain, both in the technology and in finding the most suitable applications. Keywords—Atomic force microscope, memories, microelectro-mechanical devices, piezoresistive devices. I...|$|R
40|$|Digital {{library is}} a {{collection}} of documents in organized electronic form, available on the Internet or on CD-ROM (compact-disk <b>read-only</b> memory) <b>disks.</b> They are basically stored materials in electronic format and manipulate large collections of those materials effectively. Depending on the specific library, so this study explains the concept and definitions of digital library and including benefits and limitations of digital libraries, finally this study highlights the Indian and foreign digital libraries...|$|R
40|$|Compact <b>disk</b> <b>read-only</b> {{memories}} (CD-ROMs) {{of proposed}} type store digital data in volume holograms {{instead of in}} surface differentially reflective elements. Holographic CD-ROM consist largely of parts {{similar to those used}} in conventional CD-ROMs. However, achieves 10 or more times data-storage capacity and throughput by use of wavelength-multiplexing/volume-hologram scheme...|$|R
40|$|Interactive Image Display Program (IMDISP) is {{interactive}} image-displaying {{utility program}} for IBM personal computer (PC, XT, and AT models) and compatibles. Magnifications, contrasts, and/or subsampling selected for whole or partial images. IMDISP developed {{for use with}} CD-ROM (Compact <b>Disk</b> <b>Read-Only</b> Memory) storage system. Written in C language (94 percent) and Assembler (6 percent) ...|$|R
40|$|The 8 -inch {{floppy disk}} was a {{magnetic}} storage disk {{for the data}} introduced commercially by IBM in 1971. It was designed by an IBM team as an inexpensive way to load data into the IBM System / 370. Plus it was a <b>read-only</b> bare <b>disk</b> containing 80 KB of data. The first read-write version was introduced in 1972 by Memorex and could contain 175 KB on 50 tracks (with 8 sectors per track). Other improvements have led to various coatings and increased capacities. Finally, it was surpassed by the mini diskette of 5. 25 inches introduced in 1976...|$|R
5000|$|The entire {{motherboard}} could {{slide out}} of the back of the cabinet for easy access to perform upgrades and repairs. The system was equipped with four 50-pin Apple II bus compatible slots for expansion cards. External 5.25" [...] and 8" [...] floppy disk drive peripherals (made by Fujitsu) were available for the Concept. The 8" [...] drive had a formatted capacity of 250kB. The 5.25" [...] drive was <b>read-only,</b> and <b>disks</b> held 140kB. The video card was integrated in the monitor's update circuitry. The system had a battery-backed hardware clock that stored the date and month, but not the year. There was a leap year switch that set February to have 29 days.|$|R
40|$|This {{tutorial}} {{will prepare}} participants {{to use the}} open-source BitCurator environment and BitCurator Access Webtools to acquire, process and provide access to born-digital materials. There will be a brief lecture and discussion {{that focuses on the}} motivation for using the tools and several foundational technical concepts. The remainder of the tutorial will be devoted to demonstration and hands-on exercises that feature specific tools and methods. Participants will learn how to mount media as <b>read-only,</b> create <b>disk</b> images, mount forensically packaged disk images, export individual files or entire directories from disk images, use specialized scripts to perform batch activities, generate and interpret Digital Forensics XML (DFXML), generate a variety of standard and customized reports (including PREMIS records), identify various forms of sensitive data within collections, and provide browser-based search and navigation of files and folders...|$|R
40|$|The cyclic {{oxidation}} {{test results}} for some 1000 high temperature commercial and experimental alloys {{have been collected}} in an EXCEL database. This database represents over thirty years of research at NASA Glenn Research Center in Cleveland, Ohio. The data {{is in the form}} of a series of runs of specific weight change versus time values for a set of samples tested at a given temperature, cycle time, and exposure time. Included on each run is a set of embedded plots of the critical data. The nature of the data is discussed along with analysis of the cyclic oxidation process. In addition examples are given as to how a set of results can be analyzed. The data is assembled on a <b>read-only</b> compact <b>disk</b> which is available on request from Materials Durability Branch, NASA Glenn Research Center, Cleveland, Ohio...|$|R
25|$|The Dom0 domain {{manages the}} virtual disks {{of the other}} VMs, which are {{actually}} stored as files on the dom0 filesystem(s). Disk space is saved by virtue of various virtual machines (VM) sharing the same root file system in a <b>read-only</b> mode. Separate <b>disk</b> storage is only used for userʼs directory and per-VM settings. This allows software installation and updates to be centralized. It is also possible to install software only on a specific VM, by installing it as the non-root user, or by installing it in the non-standard, Qubes-specific /rw hierarchy.|$|R
40|$|Abstract. With the {{prevalence}} of multi-core processors and cloud com-puting, the server consolidation using virtualization has increasingly ex-panded its territory, {{and the degree of}} consolidation has also become higher. As a large number of virtual machines individually require their own disks, the storage capacity of a data center could be exceeded. To ad-dress this problem, copy-on-write storage systems allow virtual machines to initially share a template disk image. This paper proposes a hybrid copy-on-write storage system that combines solid-state disks and hard disk drives for consolidated environments. In order to take advantage of both devices, the proposed scheme places a <b>read-only</b> template <b>disk</b> im-age on a solid-state disk, while write operations are isolated to the hard disk drive. In this hybrid architecture, the disk I/O performance benefits from the fast read access of the solid-state disk, especially for random reads, precluding write operations from the degrading flash memory per-formance. We show that the hybrid virtual disk, in terms of performance and cost, is more effective than the pure copy-on-write disks for a highly consolidated system...|$|R
40|$|Conceitos e definições {{digital library}} A digital library is a {{collection}} of documents in organized electronic form, available on the Internet or on CD-ROM (compact-disk <b>read-only</b> memory) <b>disks.</b> Depending on the specific library, a user may be able to access magazine articles, books, papers, images, sound files, and videos. On the Internet, the use of a digital library is enhanced by a broadband connection such as cable modem or DSL. Dial-up connections can be used to access plain-text documents and some documents containing images, but for complex files and those with animated video content, a downstream data speed of at least several hundred kilobits per second (Kbps) can make the user's experience less tedious, as well as more informative. Internetbased digital libraries can be updated on a daily basis. This {{is one of the greatest}} assets of this emerging technology. On CD-ROM, the amount of data is limited to several hundred megabytes (MB) per disk, but access is generally much faster than on an Internet connection. Several CD-ROM...|$|R
40|$|A novel <b>read-only</b> memory (ROM) <b>disk</b> with an AgOx mask layer was {{proposed}} and studied in this letter. The AgOx films sputtered on the premastered substrates, with pits depth of 50 nm and pits length of 380 nm, were studied by an atomic force microscopy. The transmittances of these AgOx films were also {{measured by a}} spectrophotometer. Disk measurement {{was carried out by}} a dynamic setup with a laser wavelength of 632. 8 nm and a lens numerical aperture (NA) of 0. 40. The readout resolution limit of this setup was λ/(4 NA) (400 nm). Results showed that the super-resolution readout happened only when the oxygen flow ratios were at suitable values for these disks. The best super-resolution performance was achieved at the oxygen flow ratio of 0. 5 with the smoothest film surface. The super-resolution readout mechanism of these ROM disks was analyzed as well...|$|R
40|$|For {{the benefit}} of the first-year gross anatomy students, we {{digitized}} and published on a Web site images that had been collected over a 30 -year period. We provided a CD-ROM (compact <b>disk,</b> <b>read-only</b> media) containing the image set in higher quality format to students and faculty. We supplemented basic images with hot topics such as CT angiography, virtual colonography, computer-aided diagnosis, and 3 D post-processing. Full motion video and moving JPEG (Joint Photo Expert Group) animations were integrated into the atlas. On the post course questionnaire medical students reported that the images on CD-ROM were helpful during the course and for review prior to examinations. Faculty and medical students used the CD-ROM for problem-based learning sections and facilitator training. The images were clear and easily projected during review sessions and were useful for the small group sessions, where they served as examples of normal anatomy...|$|R
40|$|Virtual Desktop Infrastructure (VDI) {{deployments}} run {{large numbers}} of desktops in a virtualized environment to increase flexibility and address cost. One of the major challenges VDI faces today {{is the cost of}} high bandwidth interconnection networks to shared storage. VDI storage workloads have a number of unique characteristics which make them a target for optimization. For example, VDI workloads exhibit high amount of redundant data transfers (from shared OS images), highly bursty behavior (from daily work patterns), and a common storage format (virtual disks). This thesis performs a detailed study of VDI workload and evaluates effectiveness of four hypervisor side optimization techniques. To eliminate network read requests and serve data from locally cached blocks, we evaluate two read caches, namely, location-addressed and content-addressed. We also compare these read cache with a simple mechanism which stores shared <b>read-only</b> virtual <b>disks</b> on hypervisor side local media. To eliminate transfer of redundant data that is written to the storage server, we evaluate the effectiveness of inline write deduplication. All the experiments are carried out in two setting, for full clone virtual desktops and linked clone virtual desktops. A detailed trace-driven simulation study of the mechanisms with a realistic VDI workload shows up to 75 % reduction in the total network I/O traffic. We propose some recommended setting for choosing the right optimizations, for example, for full clone virtual desktops content-addressed cache outperforms location-addressed cache by 50 %...|$|R
40|$|Many {{thousands}} of chemicals are produced industrially {{and many more}} occur naturally. Information on the toxicology of these chemicals is often minimal or absent. The International Agency for Research on Cancer (IARC) has published evaluations of the carcinogenic risk to humans of over 700 chemicals, groups of chemicals, and complex mixtures as a regular series of monographs. A database has been created containing summaries of all the relevant epidemiological, animal carcinogenicity, and other relevant biological data for each chemical or mixture evaluated. Additional databases have been created for ongoing epidemiological studies of cancer in humans and for long-term carcinogenicity studies in rodents, {{as well as a}} database containing information on genotoxic and related effects of chemicals. Some of these databases have been published in print form. IARC now plans to publish them electronically, together with other databases, {{in the form of a}} CDROM (compact <b>disk,</b> <b>read-only</b> memory). The objective will be to make the entire IARC database of cancer information as widely available as possible in an integrated format conducive to efficient and combined exploitation of all the component databases...|$|R
40|$|An {{international}} standard has emerged {{for the first}} true multimedia format. Digital Versatile Disk (by its official name), you may know it as Digital Video Disks. DVD has applications in movies, music, games, information CD-ROMS, and many other areas where massive amounts of digital information is needed. Did I say massive amounts of data? Would you believe over 17 gigabytes on {{a single piece of}} plastic the size of an audio-CD? That`s the promise, at least, by the group of nine electronics manufacturers who have agreed to the format specification, and who hope to make this goal a reality by 1998. In this major agreement, which didn`t come easily, the manufacturers will combine Sony and Phillip`s one side double-layer NMCD format with Toshiba and Matsushita`s double sided Super-Density disk. By Spring of this year, they plan to market the first 4. 7 gigabyte units. The question is: Will DVD take off? Some believe that <b>read-only</b> <b>disks</b> recorded with movies will be about as popular as video laser disks. They say that until the eraseable/writable DVD arrives, the consumer will most likely not buy it. Also, DVD has a good market for replacement of CD- Roms. Back in the early 80 `s, the international committee deciding the format of the audio compact disk decided its length would be 73 minutes. This, they declared, would allow Beethoven`s 9 th Symphony to be contained entirely on a single CD. Similarly, today it was agreed that playback length of a single sided, single layer DVD would be 133 minutes, long enough to hold 94 % of all feature-length movies. Further, audio can be in Dolby`s AC- 3 stereo or 5. 1 tracks of surround sound, better than CD-quality audio (16 -bits at 48 kHz). In addition, there are three to five language tracks, copy protection and parental ``locks`` for R rated movies. DVD will be backwards compatible with current CD-ROM and audio CD formats. Added versatility comes by way of multiple aspect rations: 4 : 3 pan-scan, 4 : 3 letterbox, and 16 : 9 widescreen. MPEG- 2 is the selected image compression format, with full ITU Rec. 601 video resolution (72 Ox 480). MPEG- 2 and AC- 3 are also part of the U. S. high definition Advance Television standard (ATV). DVD has an average video bit rate of 3. 5 Mbits/sec or 4. 69 Mbits/sec for image and sound. Unlike digital television transmission, which will use fixed length packets for audio and video, DVD will use variable length packets with a maximum throughput of more than 1 OMbits/sec. The higher bit rate allows for less compression of difficult to encode material. Even with all the compression, narrow-beam red light lasers are required to significantly increase the physical data density of a platter by decreasing the size of the pits. This allows 4. 7 gigabytes of data on a single sided, single layer DVD. The maximum 17 gigabyte capacity is achieved by employing two reflective layers {{on both sides of the}} disk. To read the imbedded layer of data, the laser`s focal length is altered so that the top layer pits are not picked up by the reader. It will be a couple of years before we have dual-layer, double-sided DVDS, and it will be achieved in four stages. The first format to appear will be the single sided, single layer disk (4. 7 gigabytes). That will allow Hollywood to begin releasing DVD movie titles. DVD-ROM will be the next phase, allowing 4. 7 gigabytes of CD-ROM-like content. The third stage will be write-once disks, and stage four will be rewritable disks. These last stages presents some issues which have yet to be resolved. For one, copyrighted materials may have some form of payment system, and there is the issue that erasable disks reflect less light than today`s DVDS. The problem here is that their data most likely will not be readable on earlier built players...|$|R
40|$|Two novel <b>read-only</b> memory (ROM) <b>disks,</b> {{one with}} an AgOx mask layer {{and the other with}} an AgInSbTe mask layer, are {{proposed}} and studied. The AgOx and the AgInSbTe films sputtered on the premastered substrates with pit depths of 50 nm and pit lengths (space) of 380 nm are studied by atomic force microscopy. Disk readout measurement is carried out using a dynamic setup with a laser wavelength of 632. 8 nm and an object lens numerical aperture (NA) of 0. 40. Results show that the superresolution effect happens only at a suitable oxygen flow ratio for the AgOx ROM disk. The best superresolution readout effect is achieved at an oxygen flow ratio of 0. 5 with the smoothest film surface. Compared with the AgOx ROM disk, the AgInSbTe ROM disk has a much smoother film surface and better superresolution effect. A carrier-to-noise ratio (CNR) of above 40 dB can be obtained at an appropriate readout power and readout velocity. The readout CNR of both the AgOx and AgInSbTe ROM disks have a nonlinear dependence on the readout power. The superresolution readout mechanisms for these ROM disks are analyzed and compared as well. (c) 2005 Society of Photo-Optical Instrumentation Engineers...|$|R
40|$|This paper {{presents}} {{an overview of}} an Information Interchange Reference Model (IIRM) currently being developed by individuals participating in the Consultative Committee for Space Data Systems (CCSDS) Panel 2, the Planetary Data Systems (PDS), and the Committee on Earth Observing Satellites (CEOS). This is an ongoing research activity and is not an official position by these bodies. This reference model provides a framework for describing and assessing current and proposed methodologies for information interchange within and among the space agencies. It is hoped that this model will improve interoperability between the various methodologies. As such, this model attempts to address key information interchange issues as seen by the producers and users of space-related data and to put them into a coherent framework. Information is understood as the knowledge (e. g., the scientific content) represented by data. Therefore, concern is not primarily on mechanisms for transferring data from user to user (e. g., compact <b>disk</b> <b>read-only</b> memory (CD-ROM), wide-area networks, optical tape, and so forth) but on how information is encoded as data and how the information content is maintained with minimal loss or distortion during transmittal. The model assumes open systems, {{which means that the}} protocols or methods used should be fully described and the descriptions publicly available. Ideally these protocols are promoted by recognized standards organizations using processes that permit involvement by those most likely to be affected, thereby enhancing the protocol's stability and the likelihood of wide support...|$|R
40|$|The {{recently}} completed Mars mosaicked digital image model (MDIM) and the soon-to-be-completed Mars {{digital terrain model}} (DTM) are being transcribed to optical disks to simplify distribution to planetary investigators. These models, completed in FY 1991, provide a cartographic base to which all existing Mars data can be registered. The digital image map of Mars is a cartographic extension {{of a set of}} compact <b>disk</b> <b>read-only</b> memory (CD-ROM) volumes containing individual Viking Orbiter images now being released. The data in these volumes are pristine {{in the sense that they}} were processed only to the extent required to view them as images. They contain the artifacts and the radiometric, geometric, and photometric characteristics of the raw data transmitted by the spacecraft. This new set of volumes, on the other hand, contains cartographic compilations made by processing the raw images to reduce radiometric and geometric distortions and to form geodetically controlled MDIM's. It also contains digitized versions of an airbrushed map of Mars as well as a listing of all feature names approved by the International Astronomical Union. In addition, special geodetic and photogrammetric processing has been performed to derive rasters of topographic data, or DTM's. The latter have a format similar to that of MDIM, except that elevation values are used in the array instead of image brightness values. The set consists of seven volumes: (1) Vastitas Borealis Region of Mars; (2) Xanthe Terra of Mars; (3) Amazonis Planitia Region of Mars; (4) Elysium Planitia Region of Mars; (5) Arabia Terra of Mars; (6) Planum Australe Region of Mars; and (7) a digital topographic map of Mars...|$|R
40|$|CD-ROM {{dictionaries}} are dictionaries on {{a compact}} <b>disk</b> <b>read-only</b> medium, which basically contain {{the same information}} as their paper counterparts. During the last ten years, {{a significant number of}} CD-ROM dictionaries have appeared on the market. Given that the content of CD-ROM dictionaries is almost identical to that of paper dictionaries, in what way do they differ from their traditional counterparts? Do CD-ROM dictionaries offer any specific advantages over paper dictionaries for translators? This thesis will address these and other questions. Before establishing {{the strengths and weaknesses of}} CD-ROM dictionaries, we had to examine their main characteristics. We first established various criteria for evaluating the characteristics of ten CD-ROM dictionaries. These criteria, in tabular form, were used to evaluate the dictionaries in terms of user-friendliness, presentation, content, search capabilities, text management options, and technical environment. However, these tables say little about users' consultation and search habits. We therefore administered a test to twelve subjects in order to gather data on the use of three CD-ROM and three paper dictionaries. We also asked six of these subjects to fill out a questionnaire in order to obtain their feedback on both types of dictionaries. Using the tables and test results, we were able to draw a comparison between CD-ROM and paper dictionaries and determine their advantages and disadvantages. This study shows that CD-ROM dictionaries have definite advantages over their paper counterparts: flexible consultation, easy handling, speedy navigation, powerful and varied search capabilities, and useful text management options. Nevertheless, they have some considerable drawbacks, especially regarding technical aspects. In conclusion, it is safe to say that CD-ROM dictionaries have the potential to increase translators' productivity as long as translators know how to take full advantage of the dictionaries' capabilities...|$|R
40|$|A well-designed cache {{system has}} {{positive}} {{impacts on the}} 3 D real-time rendering engine. As the amount of visualization data getting larger, the effects become more obvious. They are {{the base of the}} 3 D real-time rendering engine to smoothly browsing through the data, which is out of the core memory, or from the internet. In this article, a new kind of caches which are based on multi threads and large file are introduced. The memory cache consists of three parts, the rendering cache, the pre-rendering cache and the elimination cache. The rendering cache stores the data that is rendering in the engine; the data that is dispatched according to the position of the view point in the horizontal and vertical directions is stored in the pre-rendering cache; the data that is eliminated from the previous cache is stored in the eliminate cache and is going to write to the disk cache. Multi large files are used in the disk cache. When a disk cache file size reaches the limit length（ 128 M is the top in the experiment）, no item will be eliminated from the file, but a new large cache file will be created. If the large file number is greater than the maximum number that is pre-set, the earliest file will be deleted from the disk. In this way, only one file is opened for writing and reading, and the rest are <b>read-only</b> so the <b>disk</b> cache {{can be used in a}} high asynchronous way. The size of the large file is limited in order to map to the core memory to save loading time. Multi-thread is used to update the cache data. The threads are used to load data to the rendering cache as soon as possible for rendering, to load data to the pre-rendering cache for rendering next few frames, and to load data to the elimination cache which is not necessary for the moment. In our experiment, two threads are designed. The first thread is to organize the memory cache according to the view point, and created two threads: the adding list and the deleting list, the adding list index the data tha...|$|R
40|$|This report {{constitutes}} {{the final report}} for NASA Contract NASW- 5054. This project processed Clementine I high resolution images of the Moon, mosaicked these images together, and created a 22 -disk set of compact <b>disk</b> <b>read-only</b> memory (CD-ROM) volumes. The mosaics were produced through semi-automated registration and calibration of the high resolution (HiRes) camera's data against the geometrically and photometrically controlled Ultraviolet/Visible (UV/Vis) Basemap Mosaic produced by the US Geological Survey (USGS). The HiRes mosaics were compiled from non-uniformity corrected, 750 nanometer ("D") filter high resolution nadir-looking observations. The images were spatially warped using the sinusoidal equal-area projection at a scale of 20 m/pixel for sub-polar mosaics (below 80 deg. latitude) and using the stereographic projection at a scale of 30 m/pixel for polar mosaics. Only images with emission angles less than approximately 50 were used. Images from non-mapping cross-track slews, which tended to have large SPICE errors, were generally omitted. The locations of the resulting image population {{were found to be}} offset from the UV/Vis basemap by up to 13 km (0. 4 deg.). Geometric control was taken from the 100 m/pixel global and 150 m/pixel polar USGS Clementine Basemap Mosaics compiled from the 750 nm Ultraviolet/Visible Clementine imaging system. Radiometric calibration was achieved by removing the image nonuniformity dominated by the HiRes system's light intensifier. Also provided are offset and scale factors, achieved by a fit of the HiRes data to the corresponding photometrically calibrated UV/Vis basemap, that approximately transform the 8 -bit HiRes data to photometric units. The sub-polar mosaics are divided into tiles that cover approximately 1. 75 deg. of latitude and span the longitude range of the mosaicked frames. Images from a given orbit are map projected using the orbit's nominal central latitude. Polar mosaics are tiled into squares 2250 pixels on a side, which spans approximately 2. 2 deg. Two mosaics are provided for each pole: one corresponding to data acquired while periapsis was in the south, the other while periapsis was in the north. The CD-ROMs also contain ancillary data files that support the HiRes mosaic. These files include browse images with UV/Vis context stored in a Joint Photographic Experts Group (JPEG) format, index files ('imgindx. tab' and 'srcindx. tab') that tabulate the contents of the CD, and documentation files...|$|R
40|$|The Interactive Image Display Program (IMDISP) is an {{interactive}} image display utility for the IBM Personal Computer (PC, XT and AT) and compatibles. Until recently, efforts to utilize small computer systems for display {{and analysis of}} scientific data have been hampered {{by the lack of}} sufficient data storage capacity to accomodate large image arrays. Most planetary images, for example, require nearly a megabyte of storage. The recent development of the "CDROM" (Compact <b>Disk</b> <b>Read-Only</b> Memory) storage technology makes possible the storage of up to 680 megabytes of data on a single 4. 72 -inch disk. IMDISP was developed for use with the CDROM storage system which is currently being evaluated by the Planetary Data System. The latest disks to be produced by the Planetary Data System are a set of three disks containing all of the images of Uranus acquired by the Voyager spacecraft. The images are in both compressed and uncompressed format. IMDISP can read the uncompressed images directly, but special software is provided to decompress the compressed images, which can not be processed directly. IMDISP can also display images stored on floppy or hard disks. A digital image is a picture converted to numerical form {{so that it can be}} stored and used in a computer. The image is divided into a matrix of small regions called picture elements, or pixels. The rows and columns of pixels are called "lines" and "samples", respectively. Each pixel has a numerical value, or DN (data number) value, quantifying the darkness or brightness of the image at that spot. In total, each pixel has an address (line number, sample number) and a DN value, which is all that the computer needs for processing. DISPLAY commands allow the IMDISP user to display all or part of an image at various positions on the display screen. The user may also zoom in and out from a point on the image defined by the cursor, and may pan around the image. To enable more or all of the original image to be displayed on the screen at once, the image can be "subsampled. " For example, if the image were subsampled by a factor of 2, every other pixel from every other line would be displayed, starting from the upper left corner of the image. Any positive integer may be used for subsampling. The user may produce a histogram of an image file, which is a graph showing the number of pixels per DN value, or per range of DN values, for the entire image. IMDISP can also plot the DN value versus pixels along a line between two points on the image. The user can "stretch" or increase the contrast of an image by specifying low and high DN values; all pixels with values lower than the specified "low" will then become black, and all pixels higher than the specified "high" value will become white. Pixels between the low and high values will be evenly shaded between black and white. IMDISP is written in a modular form to make it easy to change it to work with different display devices or on other computers. The code can also be adapted for use in other application programs. There are device dependent image display modules, general image display subroutines, image I/O routines, and image label and command line parsing routines. The IMDISP system is written in C-language (94 %) and Assembler (6 %). It was implemented on an IBM PC with the MS DOS 3. 21 operating system. IMDISP has a memory requirement of about 142 k bytes. IMDISP was developed in 1989 and is a copyrighted work with all copyright vested in NASA. Additional planetary images can be obtained from the National Space Science Data Center at (301) 286 - 6695...|$|R

