87|0|Public
50|$|Most {{processing}} operations on digital audio involve <b>requantization</b> of samples, and thus introduce additional rounding error {{analogous to the}} original quantization error introduced during analog to digital conversion. To prevent rounding error larger than the implicit error during ADC, calculations during processing must be performed at higher precisions than the input samples.|$|E
40|$|<b>Requantization</b> {{transcoding}} is {{a method}} for reducing the bit rate of compressed video bitstreams. Most research on re-quantization {{is concerned with the}} architectural design, the selection of a suitable quantizer, or the reduction of <b>requantization</b> errors. In this paper, we propose to incorporate a new dimension in <b>requantization</b> transcoding: the quantization offset. We compare two <b>requantization</b> methods: increasing the quantization step size and decreasing the quantization offset. Furthermore, we propose a novel heuristic for <b>requantization</b> transcoding based on a theoretical rate-distortion analysis. The experimental results for H. 264 /AVC video show that <b>requantization</b> is improved in rate-distortion sense with gains up to 1 dB for open-loop <b>requantization</b> of B pictures compared to <b>requantization</b> with fixed quantization offset...|$|E
40|$|This paper {{presents}} a transrating (bit-rate reduction) algorithm for H. 264 intra-coded frames via <b>requantization.</b> Previous works focused on adapting the input prediction modes {{to the lower}} bit rate and hence performed <b>requantization</b> using a one-pass algorithm. We propose a model-based algorithm for uniform <b>requantization</b> of the transform coefficients in intracoded frames. The spatial prediction in such frames introduces block dependencies. We suggest a novel statisticalbased closed-loop model for estimating {{the relation between the}} rate and the <b>requantization</b> step that overcomes the dependency problem. The performance of an overall transrating system for H. 264 coded video, incorporating this work for intra-coded frames and our previous work for inter-coded frames is also examined. Index Terms — <b>Requantization,</b> H. 264, video coding 1...|$|E
40|$|This paper {{presents}} a model-based transrating (bit-rate reduction) system for H. 264 coded video via <b>requantization.</b> In works related to previous standards, optimal <b>requantization</b> step-sizes were obtained via Lagrangian optimization that minimizes the distortion {{subject to a}} rate constraint. Due to H. 264 advanced coding features, the choices of quantization step-size and coding modes are dependent and the rate control becomes computationally expensive. Therefore, optimal <b>requantization</b> algorithms developed for previous standards cannot be applied as is. Hence, previous works on transrating in H. 264 focused on changing the input coding decisions rather on rate control, while <b>requantization</b> was addressed by a simple one-pass algorithm. Here we propose new model-based optimal <b>requantization</b> algorithms for transrating of H. 264 coded video. The optimal <b>requantization</b> goal is to achieve the target bit rate with minimal effect on video quality. Incorporation of the proposed models serves two goals. For intra-coded frames, a novel closed-loop statistical estimator that overcomes spatial neighbors dependencies is developed. For inter-coded frames, the proposed macroblock-level models reduce the computational burden of the optimization. Overall, as compared to re-encoding (cascaded decoder-encoder), the proposed system reduces the computational complexity {{by a factor of}} about 4, at an average PSNR loss of only 0. 4 [dB] for transrating CIF/SIF sequences from 2 [Mbps] to 1 [Mbps]. In comparison with a simple one-pass <b>requantization,</b> the proposed algorithm achieves better performance (an average PSNR gain of 0. 45 [dB]), at the cost of just twice the complexity. Index Terms Bit rate control, H. 264 video coder, <b>requantization,</b> transrating...|$|E
40|$|<b>Requantization</b> {{transcoding}} is a fast {{technique for}} video bitrate reduction. In our previous work, {{we proposed a}} hybrid architecture for the <b>requantization</b> of H. 264 /AVC bitstreams. In this architecture, the B pictures were open-loop transcoded. When B pictures are not used as reference for coding neighboring pictures, this is an acceptable approach, since the <b>requantization</b> errors, originating from the B pictures, can not propagate to other pictures. In this paper, however, we compare different transcoding methods in case the coded video streams are composed of hierarchical B pictures. Here, the necessity for compensating the accumulated <b>requantization</b> error in reference B pictures needs to be investigated. We show that extended compensation techniques result in transcoded sequences that approach the rate-distortion optimal decoder-encoder cascade within I dB. Compensation of intra-coded macroblocks only is {{proven to be a}} low-complexity alternative, with only minor concessions in rate-distortion performance...|$|E
40|$|We {{propose a}} new method for requantizing JPEG images, {{based on the}} {{well-known}} Laplacian distribution of the AC discrete cosine transform (DCT) coefficients and on an anal-ysis of the error introduced by <b>requantization.</b> The result-ing images have improved perceptual image quality over a “blind ” <b>requantization</b> approach, that is, {{one that does not}} consider the properties of the quantization matrices. 1...|$|E
40|$|Video transcoders are {{devices that}} convert one video {{bitstream}} into {{another type of}} bitstream, either with or without standard format conversion. One step to be applied in video transcoders is the <b>requantization</b> of the transform coefficients, if an adaptation to a lower data rate is necessary. During this step, the quality is in most cases degraded compared to a single quantization. This {{is a consequence of}} nonoverlapping quantization characteristics of the input and the output quantizer. In this work we propose a new choice of the reconstruction level for the <b>requantization</b> step depending on the effective quantization curve of both quantization parameters involved. The reconstruction level is calculated such that it is centered in each effective quantization interval after <b>requantization.</b> Compared to the standard midpoint <b>requantization</b> this leads to quality gains of 3 dB PSNR for most pairs of input and output quantization parameters (QP). The algorithm is useful for intra- and inter-frame coding. 1...|$|E
40|$|Nowadays, most video {{material}} is coded using a non-scalable format. When transmitting these single-layer video bitstreams, {{there may be}} a problem for connection links with limited capacity. In order to solve this problem, <b>requantization</b> transcoding is often used. The <b>requantization</b> transcoder applies coarser quantization {{in order to reduce the}} amount of residual information in the compressed video bitstream. In this paper, we extend a, <b>requantization</b> transcoder for H. 264 /AVC video bitstreams with a rate-control algorithm. A simple algorithm is proposed which limits the computational complexity. The bit allocation is based on the bit distribution in the original video bitstream. Using the bit budget and a, linear model between rate and quantizer, the new quantizer is calculated. The target bit rate is attained with an average deviation lower than 6 %, while the rate-distortion performance shows small improvements over transcoding without rate control...|$|E
40|$|Abstract—Requantization {{is a key}} {{technology}} for reducing the bit rate of a previously compressed data. When recompression ratio is high, the requantizer may cause unacceptable quality degradation. To {{improve the quality of}} the requantized image, an optimization scheme for the <b>requantization</b> codebook has been proposed. The proposed scheme constructs an optimal <b>requantization</b> codebook in an iterative manner for a given original quantization codebook of transmitter. The construction of codebook is iteratively repeated until they reach a local op-timum solution. Our approach can be applied not only to the scalar quantization, but to any method which employs vector quantization-based system. Simulation results show that the optimized system based on the proposed algorithm outperforms the conventional system which is made without consideration of <b>requantization.</b> The proposed algorithm enables a reliable image communication over heterogeneous networks. Index Terms—Requantization, scalar quantization (SQ), vector quantization (VQ). I...|$|E
40|$|In this paper, we {{show that}} it is {{possible}} to efficiently transcode single-layer H. 264 /AVC bitstreams, to SNR-scalable SVC streams with CGS layers. Using <b>requantization</b> error compensation techniques, our architecture is able to restrain the drift that arises due to the absence of a closed prediction loop at the different dependency layers. Implementation results show that transcoding can generate SVC bitstreams with rate-distortion performance approaching that of the rate-distortion optimal encoder within 1 to 2 dB. Gains of more than 2 dB are obtained when compared to open-loop <b>requantization...</b>|$|E
40|$|This {{research}} investigates {{techniques for}} extreme scalable video rate transcoding. Traditional <b>requantization</b> based rate transcoding offers a reduction ratio close to 1 : 5. Unfortunately, the current bandwidth differential between Internet egress points easily exceeds more than 1 : 60. In this paper we present {{the analysis of}} a joint transcoder technique which combines <b>requantization</b> and re-tiling and dramatically extends the transcoding ratio. We demonstrate optimum operation point based on the joint error and entropy analysis of the system, and share some experiments based on live video transcoding performance...|$|E
40|$|Efficient bitrate {{reduction}} of video content {{is necessary in}} order to satisfy the different constraints imposed by decoding devices and transmission networks. <b>Requantization</b> is a fast technique for bitrate reduction, and has been successfully applied for MPEG- 2 bitstreams. Because of the newly introduced intra prediction in H. 264 /AVC, the existing techniques are rendered useless. In this paper we examine <b>requantization</b> transcoding of H. 264 /AVC bitstreams, focusing on the intra 4 x 4 prediction modes. Two architectures are proposed, one in the pixel domain and the other in the frequency domain, that compensate the drift introduced by the <b>requantization</b> of intra 4 x 4 predicted blocks. Experimental results show that these architectures perform approximately equally well as the full decode and recode architecture for low to medium bitrates. Because of the reduced computational complexity of these architectures, in particular the frequency-domain compensation architecture, they are highly suitable for real-time adaptation of video content...|$|E
40|$|Images {{from sources}} like digital camera, {{internet}} and the like are in the JPEG format. There is a tremendous need for recompression of JPEG images {{in order to satisfy}} the space constraints and to transmit the images with limited bandwidth. Several techniques have been developed for recompressing the JPEG image in order to achieve low bit rate and to have good visual quality. In this paper, we concentrated on <b>requantization</b> method to achieve recompression. We have analyzed the occurrence of <b>requantization</b> errors empirically for Normal rounding technique. Based on our experience, we have proposed the Enhanced rounding technique for <b>requantization</b> of JPEG images. The resulting images are generally smaller in size and have improved perceptualimage quality over Normal rounding technique. We have compared the recompression results for standard benchmark 256 x 256 gray scale images against image quality measures such as image size, compression ratio,bits per pixel and Peak Signal to Noise Ratio (PSNR) ...|$|E
40|$|Abstract — Transcoding is a {{technique}} to convert one video bitstream into another. While homogeneous transcoding is done at the same coding standard, inhomogeneous transcoding converts from one standard format to another standard. Inhomogeneous transcoding between MPEG- 2, MPEG- 4 or H. 263 was performed using the same transform. With the standardisation of H. 264 also a new transform basis and different block size was defined. For <b>requantization</b> from block size��to��this leads {{to the effect that}} the quantization error of one coefficient in a block of size��is distributed over multiple coefficients in blocks of size��. In our work, we analyze the <b>requantization</b> process for inhomogeneous transcoding with different transforms. The deduced equations result in an expression for the correlation of the error contributions from the coefficients of block size ��at each coefficient of block size��. We then compare the mathematical analysis to simulations on real sequences. The reference to the <b>requantization</b> process is the direct quantization of the undistorted signal. It will be shown that the loss is as high as 3 dB PSNR at equivalent step size for input and output bitstream. Also an equation for the choice of the second quantization step size in dependency of the <b>requantization</b> loss is deduced. The model is then extended from the DCT to the integer-based transform as defined in H. 264. I...|$|E
40|$|Abstract—In this paper, {{we report}} a novel {{heuristic}} for requan-tizing JPEG images. The resulting images are generally smaller and often have improved perceptual image quality over a “blind” <b>requantization</b> approach, that is, {{one that does}} not consider the properties of the quantization matrices. The heuristic is supported by a detailed mathematical treatment which incorporates the well-known Laplacian distribution of the AC discrete cosine transform (DCT) coefficients with an analysis of the error introduced by re-quantization. We note that the technique is applicable to any image compression method which employs discrete cosine transforms and quantization. Index Terms—Compression, JPEG image format, quantization, recompression, <b>requantization.</b> I...|$|E
40|$|Transcoding is a {{fast and}} elegant {{solution}} for the adaptation of video content. In the case of bitrate adaptation, an important technique is <b>requantization</b> transcoding. In this paper, we extend our previous work, that focused on <b>requantization</b> of intra-coded pictures, to P and B pictures. We show that by {{using a combination of}} techniques, depending on the slice and macroblock type, improved results are obtained when compared to previously existent architectures. We also show that in the important case of transcoding to low bitrates, results of this hybrid architecture approximate the rate-distortion performance of the computationally complex decoder-encoder cascade...|$|E
40|$|Abstract—A {{major problem}} in {{oversampling}} digital-to-analog converters and fractional- frequency synthesizers, which are ubiquitous in modern communication systems, is that the noise they introduce contains spurious tones. The spurious tones {{are the result of}} digitally generated, quantized signals passing through nonlinear analog components. This paper presents a new method of digital <b>requantization</b> called Successive <b>Requantization,</b> special cases of which avoids the spurious tone generation problem. Sufficient conditions are derived that ensure certain statistical properties of the quantization noise, including the absence of spurious tones after nonlinear distortion. A practical example is presented and shown to satisfy these conditions. Index Terms—Dither techniques, nonlinearities, quantization. I...|$|E
40|$|We {{consider}} source <b>requantization</b> in {{two forms}} — successive degradation (i. e., source fidelity reduction) and bit stealing (i. e., information embedding) — when no forward planning {{has been done}} to facilitate the <b>requantization.</b> We focus on finite-alphabet sources with arbitrary distortion measures as well as the Gaussian-quadratic scenario. For the successive degradation problem, we show an achievable distortion-rate trade-off for non-hierarchically structured rate-distortion achieving codes, and compare it to the distortion-rate trade-off of successively refinable codes. We further consider source <b>requantization</b> in the form of bit stealing, whereby an information embedder acts on a quantized source, producing an output at the same rate. Building on the successive degradation results, we develop achievable distortion-rate trade-offs. Two cases are considered, corresponding to whether the source decoder is informed of any bit stealing or not. In the latter case, the embedder must produce outputs in the original source codebook. For the Gaussian-quadratic scenario, all trade-offs are within 0. 5 bits/sample of the distortion-rate bound. Furthermore, for bit stealing, the use of simple post-reconstruction processing that is only a function of the embedded rate can eliminate the loss experienced by uninformed decoders. ...|$|E
30|$|In conclusion, for the {{steganalysis}} algorithm {{which is}} proposed in this paper, we can safely conclude {{that it has}} a good robustness for the attacks such as resample, <b>requantization.</b> But it is sensitive to Gaussian white noise and G. 729 compression encoding.|$|E
40|$|A {{theoretical}} analysis, {{aimed at}} characterizing the degradation {{induced by the}} resampling and <b>requantization</b> processes applied to band-limited Gaussian signals with flat power spectrum, available through their digitized samples, is presented. The analysis provides an efficient algorithm for computing the complete {joint} bivariate discrete probability distribution associated to the true quantized version of the Gaussian signal and to the quantity estimated after resampling and <b>requantization</b> of the input digitized sequence. The use of Fourier transform techniques allows deriving {approximate} analytical expressions for the quantities of interest, as well as implementing their efficient computation. Numerical experiments {{are found to be}} in good agreement with the theoretical results, and confirm the validity of the whole approach. Comment: Submitted to Digital Signal Processin...|$|E
40|$|<b>Requantization</b> {{is one of}} {{the tools}} for bit-rate {{reduction}} of pre-encoded video to adapt it to various network bandwidth constraints. Several recent works propose using Lagrangian optimization to find the optimal quantization step for each coded macro-block, to meet a desired rate at minimum distor-tion. In this paper we propose to extend the Lagrangian op-timization procedure by allowing the modification of quan-tized coefficients values, including setting their values to zero, in addition to quantization step-size selection. Coef-ficient value modification and quantization step-size selec-tion are optimally done using a low complexity trellis-based procedure. The proposed <b>requantization</b> algorithm provides higher PSNR values than the Lagrangian-based optimization method that only handles the selection of quantization steps, and still does not exceed considerably its complexity. 1...|$|E
40|$|Many image {{compression}} techniques involve segmentation of a gray level image. With such tech-niques, information is extracted {{that describes the}} regions in the segmented image, and this information is then used to form a coded version of the image. In this paper we present a region-growing-based seg-mentation technique that incorporates human visual system properties, and describe {{the use of this}} tech-nique in {{image compression}}. We also discuss the effect of requantizing a segmented image. <b>Requantization</b> of a segmented image is useful because it can lead to a {{reduction in the number of}} bits required to code the description of the regions in the segmented image. This results in a lower data rate. We show that the number of gray levels in a segmented image can be reduced by a factor of at least twelve, without noticeable degradation in the quality of the segmented image. This result is attributable to human visual system properties having to do with contrast sensitivity, and to the fact that <b>requantization</b> of a segmented image does not usually reduce significantly the number of distinct segments in the image. In addition, in this paper we explore the relationship between the number of segments in an image, and the extent of <b>requantization</b> possible before noticeable degradation occurs in the image...|$|E
40|$|<b>Requantization</b> {{techniques}} for H. 264 /AVC rate reduction transcoding Abstract—In order {{to cope with}} the increasing number of different display devices and the heterogeneity of transmission networks, fast and elegant adaptation of video content is required. Transcoding can be used for reduction of the bitrate, without fully decoding and recoding the bitstream. A significant reduction in computational complexity can be achieved by reusing information from the incoming bitstream, such as motion vectors, and by working as much as possible in the transform domain. We investigated architectures for bitrate reduction transcoding of intra-coded pictures, comparing the decoder-encoder cascade with different reduced complexity transcoders. Results show that the transform-domain architecture can achieve the quality of the pixel-domain transcoder, and approximates the quality of a decoder-encoder cascade. Keywords—H. 264 /AVC, transcoding, <b>requantization,</b> rate reduction I...|$|E
30|$|Table 7 shows {{test results}} of Rock 1 audio signal with no attack, re-sampling, <b>requantization,</b> {{low-pass}} filtering, addition of noise, cropping, and MPEG 1 Layer III compression with compression rates of 128, 96, 64 [*]kbps and 56 [*]kbps, respectively. The BER of watermark signal and the SNR of {{digital audio signal}} are also displayed.|$|E
3000|$|... {{has been}} {{assigned}} to 24 [*]dB in all experiments. During GA-based optimization processes, three attacks are chosen to evaluate the robustness of the embedded watermark. They are MP 3 compression at 64 [*]kbps (Attack 1), Gaussian noise addition (Attack 2), and <b>requantization</b> (Attack 3). Details of these attacks will be thoroughly described in Section 4.3. After obtaining the [...]...|$|E
40|$|In {{the context}} of Universal Multimedia Access, {{efficient}} techniques are needed for the adaptation of video content. An important example is {{the reduction of the}} bitrate in order to satisfy the bandwidth constraints imposed by the network or the decoding capability of the terminal devices. <b>Requantization</b> transcoding is a fast technique for bitrate reduction, and has been successfully applied in previous video coding standards such as MPEG- 2. In this paper, we examine <b>requantization</b> in H. 264 /AVC, focusing on the intra 16 x 16 prediction modes. Due to the newly introduced coding tools in H. 264 /AVC, new techniques are needed that are able to lower the bitrate at a minimal quality loss. We propose two novel architectures, one in the pixel domain and one in the frequency domain, that reuse the information from the incoming bitstream in an efficient way, and perform approximately equally well as a cascade of decoder and encoder. Due to their low computational complexity, the introduced architectures are highly suitable for on-the-fly video adaptation scenarios...|$|E
40|$|Constrained {{dynamics}} on finite-dimensional trial manifolds {{of quantum}} state vectors appears in time-dependent variational calculations. This work presents a <b>requantization</b> method, by which {{properties of the}} exact eigenstates can be retrieved from the phase portrait of such approximations. Applications to the coherent states dynamics, small amplitude vibrations and collective rotations, show that this approach extends standard procedures of the quantum many-body theory, such as the method of the projection operators and the random phase approximation...|$|E
40|$|In this paper, {{we present}} a novel audio {{watermarking}} scheme using direct sequence spread spectrum (DSSS) method by which we can embed a text message as a watermark into an audio signal imperceptibly. The watermark embedding and extraction {{are based on the}} psychoacoustic model in the frequency domain. Experimental results show good robustness of the approach against amplitude compression, echo addition, noise addition, resampling, <b>requantization,</b> filtering and MP 3 compression attacks. I...|$|E
40|$|In {{this paper}} the basic {{equations}} {{for evaluating the}} power of harmonic and intermodulation distortions due to <b>requantization</b> (rounding or truncation) of fixed-point numbers are derived. In contrast to the papers of Abuelma'atti and Blachman [1]-[5] we show that not only odd harmonics and intermodulation products but also even ones are produced. Special emphasis {{is given to the}} analysis of the DC error introduced by two's complement rounding. Finally we suggest some ways to circumvent this DC error...|$|E
40|$|Quantum {{dynamics}} of the Bose-Hubbard Model is investigated through a semiclassical hamiltonian picture provided by the Time-Dependent Variational Principle method. The system is studied within a factorized slow/fast dynamics. The semiclassical <b>requantization</b> procedure allows one {{to account for the}} strong quantum nature of the system when t/U≪ 1. The phase diagram is in good agreement with Quantum Monte Carlo results and third order strong coupling perturbative expansion. Comment: 4 pages Revtex, 2 figures. eps, to be published in PR...|$|E
40|$|Abstract—Most model-based {{rate control}} {{solutions}} have the generally questionable assumption that video sequence is stationary. In addition, they often {{suffer from the}} fundamental problem of model parameter misestimation. In this paper, we propose a sequence-based frame-level bit allocation framework employing a rate-complexity model that has the capability of tracking the nonstationary characteristics in the video source without look-ahead encoding. In addition, a new nonlinear model parameter estimation approach is proposed to overcome the existing problems in previous model parameter estimation schemes where quantization parameter (QP) is determined to achieve the allocated bits for a frame. Furthermore, a general concept of bit allocation guarantee is discussed and its importance is highlighted. The proposed rate control solution can achieve smoother video quality with less quality flicker and motion jerkiness. Both a complete solution where <b>requantization</b> is employed to guarantee {{the achievement of the}} allocated bits, and a simplified solution without <b>requantization</b> are studied. Experimental results show that they both provide significantly better performance, in terms of average peak-signal-to-noise ratio and quality smoothness, than the MPEG- 4 Annex L frame-level rate control solution. Index Terms—Bit allocation, model parameter estimation, rate control, real-time encoding, smooth quality, stationarity assumption. I...|$|E
40|$|We present several {{mechanisms}} that enable effective spreadspectrum audio watermarking systems: prevention against detection desynchronization, cepstrum filtering, and chess watermarks. We have incorporated these techniques {{into a system}} capable of reliably detecting a watermark in an audio clip that has been modified using a composition of attacks that degrade the original audio characteristics well beyond the limit of acceptable quality. Such attacks include: fluctuating scaling in the time and frequency domain, compression, addition and multiplication of noise, resampling, <b>requantization,</b> normalization, filtering, and random cutting and pasting of signal samples...|$|E
40|$|In {{previous}} work, {{we introduced}} an H. 264 /AVC-to-SVC transcoder for creating SVC streams with multiple quality layers from a single-layer H. 264 /AVC stream. This architecture {{was able to}} restrain the error drift due to <b>requantization</b> of the residual coefficients. In-this paper, we show {{that it is possible}} to further reduce the complexity, and completely eliminate the drift in the enhancement layer, by making use of the bitstream rewriting functionality in SVC. We propose different novel architectures, which are able to flexibly distribute the data among the different created layers...|$|E
40|$|In {{bit rate}} {{reduction}} video transcoding, blockness in the transcoded result {{can become a}} major problem. Previous works have shown that deblocking {{can be achieved by}} recomputing some of the DCT coefficients. However, in video transcoding, these DCT coefficients are subject to a re-quantization process, which may render the deblocking ineffective. We propose to consider deblocking in conjunction with the <b>requantization</b> process therefore accelerating the transcoding processes. In addition, the method also motivates a design of an optimized quantizer selection algorithm that boosts the deblocking capability of the video transcoder. 1...|$|E
40|$|This paper {{proposes a}} robust spread {{spectrum}} based audio watermarking scheme using Discrete wavelet transform (DWT). Here {{we use a}} peak detection algorithm to obtain high robustness. In this watermarking scheme, watermarks are embedded into the peak value of detail coefficients of, transformed audio signal. It is a blind watermarking technique which is used for providing copyright protection and content authentication for digital content. Tests shows that the proposed watermarking scheme is robust against signal processing attacks like resampling, <b>requantization,</b> MP 3 compression, noise addition. Performance of this technique is analyzed by calculating the percentage match and SNR values...|$|E
40|$|It is {{well known}} that both the rate and the {{distortion}} of recompressed images depend primarily on the ratio between the new and the old quantization steps used. In this paper we provide a theoretical basis to this observation, and introduce an efficient algorithm to select the recompression quantization step. Our approach is based on the structure of the quantizer and the distribution of DCT coefficients in subband coding. These results can be readily generalized to <b>requantization</b> of other data types. Our conclusion is that the proposed approach could be instrumental in recompression of still images, while offering straightforward generalization to higher and lower dimension signals. 1...|$|E
