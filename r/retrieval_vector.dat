16|124|Public
40|$|This paper {{provides}} an enhancement {{of an existing}} method of information retrieval which is a modification of Vector Space Model for information retrieval. This enhanced model is modified to be applied on protein sequence data whereas the normal vector space model has been applied on text data. The {{results show that the}} enhanced model achieved very good results in performance but the setup time is somehow high for a large collection of protein sequences Key words: Information <b>retrieval,</b> <b>Vector</b> Space Model, Protein sequence...|$|E
40|$|Abstract:- Recently, lots of {{researchers}} {{are attracted to}} retrieving multi-media databases by impression[1][2]. As an example, Ikezoe et al. propose to retrieve multi-media databases by using eight pairs of opposite impression words[3]. In case of realizing this approach by applying Salton’s vector space[4], we are required to rectify each weight of eight axes. In this paper, we propose three rectifying methods and evaluate which method is the most appropriate. Concerning the best one, we also develop a pilot system and execute a relative comparison from the conventional method. Key-Words:- Multi-media database, music database, ambiguous retrieval, impression-based retrieval. 1 Problem Description The Ikezoe’s music impression space[3] is multi-dimensional, and it has eight pairs of opposite impression words. Each axis has seven levels from minus three to plus three(Fig. 1). It {{is based on the}} SD(Semantic Differential) method[5], which represents an object by the combination of each value on multiple axes of opposite impression words. A music is placed in the space according to each value. A retrieval condition is represented as a <b>retrieval</b> <b>vector,</b> and the corresponding retrieval result is produced by neighborhood retrieval[6]. This approach has the following problem: even if a user has an image of a certain music and provides the <b>retrieval</b> <b>vector</b> for it, the music is not always emerged in upper rank of the retrieval result...|$|E
40|$|Information Retrieving is task of recuperating {{information}} with high relevance, precision and recall. Basic methods for information retrieval include Boolean Retrieval, Fuzzy <b>retrieval,</b> <b>Vector</b> Space model. Searching depends on matching keywords between user-query and document. Ontology {{can be used}} in information retrieval. In software engineering and information science, ontology is a formal naming and meaning of the types, properties, and interrelationships of the elements that truly or in a broad sense exist for a specific domain of discourse. Ontology provides us with vocabulary of terms. New terms and relations could be found out using the existing relations. Many Information retrieval techniques exist amongst which many depend o...|$|E
5000|$|Vector - A {{variant of}} array {{supported}} only when publishing for Flash Player 10 or above. Vectors are typed, dense Arrays (values must be defined or null) {{which may be}} fixed-length, and are bounds-checked during <b>retrieval.</b> <b>Vectors</b> are not just more typesafe than Arrays but also perform faster.|$|R
40|$|International audienceAmong {{available}} wind sources, i. e. measured data, numeric weather models, the <b>retrieval</b> of wind <b>vectors</b> from Synthetic Aperture Radar (SAR) data / {{images is}} particularly preferred {{due to a}} lot of SAR systems (available data in most meteorological conditions, revisit mode, high resolution, etc.). For this purpose, the <b>retrieval</b> of wind <b>vectors</b> is principally based on the empirical (EP) models, e. g. CMOD series in C-band. Little studies have been reported about the use of the electromagnetic (EM) models for wind <b>vector</b> <b>retrieval,</b> since it is quite complicated to invert. However, the EM models can be applied for most cases of polarization, frequency and wind regime. In order to evaluate the advantages and limits of the EM models for wind <b>vector</b> <b>retrieval,</b> we compare in this study estimated results by the EM and EP models for both cases of polarization (vertical-vertical, or VV-pol and horizontal- horizontal, or HH-pol) ...|$|R
30|$|Aggregated vectors, such as VLAD [8] and FV [10], {{are proven}} to be more {{effective}} than BoW in terms of efficiency and memory cost in large-scale image <b>retrieval.</b> Aggregated <b>vectors</b> use a small-sized codebook and can be further reduced by dimension reduction while preserving excellent performance.|$|R
40|$|We {{consider}} {{approaches for}} exact similarity search {{in a high}} dimensional space of correlated features representing image datasets, based on principles of clustering and vector quantization. We develop an adaptive cluster distance bound based on separating hyperplanes, that complements our index in selectively retrieving clusters that contain data entries closest to the query. Experiments conducted on real data-sets confirm the efficiency of our approach with random disk IOs reduced by 100 X, {{as compared with the}} popular Vector Approximation-File (VA-File) approach, when allowed (roughly) the same number of sequential disk accesses, with relatively low preprocessing storage and computational costs. Index Terms — Similarity search, multi-dimensional indexing, <b>retrieval,</b> <b>vector</b> quantization, clusterin...|$|E
40|$|Abstract. The eect {{of spatial}} {{variability}} of the atmo-spheric CO 2 distribution on temperature and water vapor retrievals from high spectral resolution observations of in-frared emission is estimated by performing 4 dierent re-trieval experiments. Using a global mean CO 2 value, as currently routinely used, introduces {{errors in the}} retrieved temperature prole of up to 0. 85 K compared to a retrieval in which the CO 2 prole is known exactly. Including CO 2 in the <b>retrieval</b> <b>vector</b> reduces these errors to 0. 3 K. A more practical alternative, especially for data assimilation, {{is to use a}} monthly mean zonal mean CO 2 value, which produces errors of up to 0. 35 K in the temperature prole...|$|E
40|$|This {{invention}} {{provides a}} method for combining overlapping DNA molecules comprising: (a) providing first and second DNA fragments, the first having a region homologous to a region in the second; (b) tagging the first DNA fragment with a selectable marker; (c) cloning the first DNA sequence into a <b>retrieval</b> <b>vector</b> to form a DNA-vector complex; (d) linearizing the DNA-vector complex; and (e) inserting the first DNA fragment from the DNA-vector complex into the second DNA fragment using homologous recombination to form a combined DNA molecule; and (f) removing the selectable marker, thereby generating a combined DNA molecule. The invention further provides a vector for retrieving and inserting a selected DNA molecule into a target DNA molecule. published_or_final_versio...|$|E
40|$|In {{this thesis}} we generalize {{the problem of}} phase <b>retrieval</b> of <b>vector</b> to that of multi-vector. The {{identification}} of the multi-vector is done up to some special classes of isometries in the space. We give some upper and lower estimates on the minimal number of multi-linear operators needed for the retrieval. The results are preliminary and far from sharp...|$|R
40|$|Retrievals of {{atmospheric}} information from satellite observations permit {{the investigation of}} otherwise inaccessible atmospheric phenomena. The recovery of this information from optical instrumentation located in orbit requires both an inversion algorithm like the Saskatchewan Multiplicative Algebraic Reconstruction Technique and a forward model like the SASKTRAN radiative transfer model. These are used together at the University of Saskatchewan to retrieve sulphate aerosol extinction profiles from the radiance measurements made by the Canadian built OSIRIS instrument. Although these retrievals are highly successful the process currently does not consider the polarization of light or OSIRIS's polarization sensitivities because SASKTRAN is a scalar model. In this work {{the development of a}} vector version of SASKTRAN that can perform polarized radiative transfer calculations is presented. The vector SASKTRAN's results compare favorably with vector SCIATRAN, another polarized model that is in development at the University of Bremen. Comparisons of the stratospheric aerosol <b>retrieval</b> <b>vectors</b> generated from the scalar and vector SASKTRAN results indicate that the polarized calculations are an important factor in future work to improve the aerosol retrievals and to recover particle size or composition information...|$|R
40|$|This thesis {{researches}} {{the issue}} of text data mining and information retrieval. It describes the most common representations of text documents and retrieval strategies. The aim of this thesis is design and implementation of application, which realises information <b>retrieval</b> via <b>vector</b> space model. The application implements three different ways of similarity calculation: cosine measure, the Jaccard coefficient and the Dice coefficient. Achieved results are assessed. Possible continuance of the project is outlined...|$|R
40|$|This Invention Provides A Method For Combining Overlapping Dna Molecules Comprising: (A) Providing First And Second Dna Fragments, The First Having A Region Homologous To A Region In The Second; (B) Tagging The First Dna Fragment With A Selectable Marker; (C) Cloning The First Dna Sequence Into A <b>Retrieval</b> <b>Vector</b> To Form A Dna-Vector Complex; (D) Linearizing The Dna-Vector Complex; And (E) Inserting The First Dna Fragment From The Dna-Vector Complex Into The Second Dna Fragment Using Homologous Recombination To Form A Combined Dna Molecule; And (F) Removing The Selectable Marker, Thereby Generating A Combined Dna Molecule. The Invention Further Provides A Vector For Retrieving And Inserting A Selected Dna Molecule Into A Target Dna Molecule. published_or_final_versio...|$|E
40|$|Global sea-surface {{temperatures}} (SST) from MODIS measured brightness temperatures generated {{using the}} regression methods, {{have been available}} to users {{for more than a}} decade, and are used extensively {{for a wide range of}} atmospheric and oceanic studies. However, as evidenced by a number of studies, there are indications that the retrieval quality and cloud detection are somewhat sub-optimal. To improve the performance of both of these aspects, we endorse a new physical deterministic algorithm, based on truncated total least squares (TTLS), using multiple channels and parameters, in conjunction with a hybrid cloud detection scheme using a radiative transfer model atop a functional spectral difference method. The TTLS method is a new addition that improves the information content of the retrieval compared to our previous work using modified total least squares (MTLS), which is feasible because more measurements are available, allowing a larger <b>retrieval</b> <b>vector.</b> A systematic study is conducted to ascertain the appropriate channel selection for SST retrieval from the 16 thermal infrared channels available from the MODIS instrument. Additionally, since atmospheric aerosol is a well-known source of degraded quality of SST retrieval, we include aerosol profiles from numerical weather prediction in the forward simulation and include the total column density of all aerosols in the <b>retrieval</b> <b>vector</b> of our deterministic inverse method. We used a slightly modified version of our earlier reported cloud detection algorithm, namely CEM (cloud and error mask), for this study. Time series analysis of more than a million match-ups shows that our new algorithm (TTLS+CEM) can reduce RMSE by ~ 50 % while increasing data coverage by ~ 50 % compared to the operationally available MODIS SST...|$|E
40|$|Abstract. This study {{presents}} a robust indexing and retrieval scheme for digital photos with speech annotations {{based on the}} syllable-transformed patterns. In speech retrieval application, out-of-vocabulary and recognition error problems are generally prone to incorrect transcription and therefore degrade the retrieval performance. In this study, the recognized n-best syllable candidates for each syllable is regarded as an ordered pattern and converted into an “image-like” pattern using the multidimensional scaling (MDS) method for indexing and <b>retrieval.</b> <b>Vector</b> quantization is then applied to cluster image vectors into the indexing codeword. Finally, a VSM-based indexing mechanism is used for photo retrieval with speech query. Experiments were conducted on the speech annotations of 1, 055 collected digital photos. Compared to other conventional methods, the syllable-transformed pattern method shows a promising improvement on speech-annotated photo retrieval...|$|E
40|$|A Ka-band {{backscatter}} {{model and}} an algorithm for {{measurement of the}} wind speed and direction over the sea surface by a frequency-modulated continous-wave radar demonstrator system operated in scatterometer mode have been developed. To evaluate the proposed algorithm, a simulation of the wind <b>vector</b> <b>retrieval</b> has been performed...|$|R
40|$|Content Based Image Retrieval {{systems are}} {{helpful to the}} radiologists in {{diagnosis}} of breast cancer. This paper presents a method for retrieving breast tissue as normal, benign or malignant in mammograms by using FuzzyTextons. In feature extraction first fuzzy texton images of mammograms are calculated. During the detection of fuzzy texton, fuzzy based quantization is performed to get more accurate textons. Then feature vectors are extracted for fuzzy textons and for efficient classification and <b>retrieval</b> Support <b>Vector</b> Machine is used. The proposed method was tested for a mammogram set from MIAS database...|$|R
40|$|This paper {{presents}} {{different ways}} at different steps of question answering process to improve question answer match. First we discuss {{about the role}} {{and the importance of}} question categorization to guide the pairing. In order to process linguistic criteria, we describe a question pattern based categorization. Then we propose a statistical method and a linguistic method to enhance the pairing probability. The statistical method aims to modify weights of keywords and expansions within the classical Information <b>Retrieval</b> (IR) <b>vector</b> space model whereas the linguistic method is based on answer pattern matching...|$|R
40|$|We {{present an}} {{analysis}} of information content for sea surface temperature (SST) retrieval from the Advanced Microwave Scanning Radiometer 2 (AMSR 2). We find that SST uncertainty of ∼ 0. 37 K can be achieved within an optimal estimation framework {{in the presence of}} wind, water vapour and cloud liquid water effects, given appropriate assumptions for instrumental uncertainty and prior knowledge, and using all channels. We test all possible combinations of AMSR 2 channels and demonstrate the importance of including cloud liquid water in the <b>retrieval</b> <b>vector.</b> The channel combinations, with the minimum number of channels, that carry most SST information content are calculated, since in practice calibration error drives a trade-off between retrieved SST uncertainty and the number of channels used. The most informative set of five channels is 6. 9 V, 6. 9 H, 7. 3 V, 10. 7 V and 36. 5 H and these are suitable for optimal estimation retrievals. We discuss the relevance of microwave SSTs and issues related to them compared to SSTs derived from infra-red observations...|$|E
40|$|We {{present a}} {{recommender}} system {{intended to be}} used by a community of gamers. The system uses free-form text reviews of games written by the members of the community, along with information about the games that a particular user likes, in order to recommend new games that are likely to be of interest to that user. The system uses the frequency of co-occurrence of word pairs that appear in the reviews of a game as features that represent the game. The pairs consist of adjectives and context words; i. e., words that appear close to an adjective in a review. Because of the extremely large number of possible combinations of adjectives and con-text words, we use information-theoretic co-clustering of the adjective-context word pairs to reduce the dimen-sionality. Games are represented using the standard in-formation <b>retrieval</b> <b>vector</b> space model, in which vector features are based on the frequency of occurrence of co-cluster pairs. We present the results of three experiments with our system. In the first experiment, we use a vari-ety of strategies to relate frequencies of co-cluster pairs to vector features, to see which produces the most ac-curate recommendations. In the second, we explore the effects of co-cluster dimensionality on the quality of our system’s recommendations. In the third experiment, we compare our approach to a baseline approach using a bag-of-words technique and conclude that our approach produces higher quality recommendations...|$|E
40|$|Abstract—One central {{problem of}} {{information}} retrieval {{is to determine}} the relevance of documents with respect to the user information needs. The choice of similarity measure is crucial for improving search effectiveness of a retrieval system. Different similarity measures have been suggested to match the query and documents. This study investigates the use of Genetic Algorithm to increase the efficiency of information retrieval by defining a combined similarity measure. Genetic Algorithm has been used for learning weights of the components of the combined similarity measure. We have provided a weight-learning algorithm for the same. We have considered order based and non-order based fitness functions to evaluate the goodness of the solution. A non-order based fitness function is based on recall-precision values only. However, it has been observed that a better fitness function can be obtained if we also consider the order in which relevant documents are retrieved. This leads to an idea of order based fitness functions. We evaluated the efficacy of a genetic algorithm with various fitness functions. Further, we provide a framework for applying genetic algorithms to improve the retrieval efficiency by combing various similarity measures. The experiments have been carried out on TREC data collection. The results have been compared with various well-known similarity measures. Index Terms—Document retrieval, genetic algorithms, similarity measures, information <b>retrieval,</b> <b>vector</b> space Model. I...|$|E
40|$|Requirements Tracing on Target (RETRO) is {{software}} for after-the-fact tracing of textual requirements to support independent verification and validation of software. RETRO applies {{one of three}} user-selectable information-retrieval techniques: (1) term frequency/inverse document frequency (TF/IDF) <b>vector</b> <b>retrieval,</b> (2) TF/IDF <b>vector</b> <b>retrieval</b> with simple thesaurus, or (3) keyword extraction. One component of RETRO is the graphical user interface (GUI) for use in initiating a requirements-tracing project (a pair of artifacts to be traced to each other, such as a requirements spec and a design spec). Once the artifacts have been specified and the IR technique chosen, another component constructs {{a representation of the}} artifact elements and stores it on disk. Next, the IR technique is used to produce a first list of candidate links (potential matches between the two artifact levels). This list, encoded in Extensible Markup Language (XML), is optionally processed by a filtering component designed to make the list somewhat smaller without sacrificing accuracy. Through the GUI, the user examines a number of links and returns decisions (yes, these are links; no, these are not links). Coded in XML, these decisions are provided to a "feedback processor" component that prepares the data for the next application of the IR technique. The feedback reduces the incidence of erroneous candidate links. Unlike related prior software, RETRO does not require the user to assign keywords, and automatically builds a document index...|$|R
40|$|Current {{methods for}} {{retrieving}} near surface winds from scatterometer observations {{over the ocean}} surface require a foward sensor model which maps the wind vector to the measured backscatter. This paper develops a hybrid neural network forward model, which retains the physical understanding embodied in ¸mod, but incorporates greater flexibility, allowing a better fit to the observations. By introducing a separate model for the mid-beam and using a common model for the fore- and aft-beams, we show a significant improvement in local wind <b>vector</b> <b>retrieval.</b> The hybrid model also fits the scatterometer observations more closely. The model is trained in a Bayesian framework, accounting for the noise on the wind vector inputs. We show that adding more high wind speed observations in the training set improves wind <b>vector</b> <b>retrieval</b> at high wind speeds without compromising performance at medium or low wind speeds...|$|R
40|$|This {{document}} {{describes the}} construction process of an information retrieval system (IRS) for our participation in CLEF− 2001. We use the vector model. First, the document provides {{a brief description}} of the information <b>retrieval</b> problem, the <b>vector</b> model and the evaluation of the IRS. Next, the lexical analysis applied to documents and queries is described. Finally, we show the results and the conclusions...|$|R
40|$|Abstract: Current {{studies on}} {{content-based}} image retrieval mainly rely on bags of visual words. This model of image description allows to perform image retieval {{in the same}} way as text retrieval: documents are described as vectors of (visual) word frequencies, and documents are match by computing a distance or similarity measure between the vectors. But instead of raw frequencies, documents can also be described as vectors of word weights, each weight corresponding to the importance of the word in the document. Although the problem of determining automatically such weights, and therefore which words describe well documents, has been widely studied in the case of text retrieval, there is very little litterature applying this idea to the case of image retrieval. In this report, we explore how the use of standard weighting schemes and distance from text retrieval can help to improve the performance of image retrieval systems. We show that there is no distance or weighting scheme that can improve performance on any dataset, but choosing weights or a distance consistent with some properties of a given dataset can improve the performance up to 10 %. However, we also show that in the case of very varied and general datasets, the performance gain is not significant. Key-words: Weighting schemes, content-based image retrieval, bag of visual words, information <b>retrieval,</b> <b>vector</b> space model, probabilistic model, Minkowski distance, divergence from randomness, BM 25, TF*IDF Un aperçu des schémas de pondération pour la recherche d’images par sac de mots visuels Résumé: Les travaux actuels en recherche d’image par le contenu se basent sur un modèle en sac de mots visuels...|$|E
40|$|The {{scattered}} sunlight measurements {{made by the}} Optical Spectrograph and InfraRed Imaging System (OSIRIS) on the Odin spacecraft {{are used}} to retrieve vertical profiles of stratospheric aerosol extinction at 750 nm. The recently released OSIRIS Version 5 data product contains the first publicly released stratospheric aerosol extinction retrievals, and these are now available for the entire Odin mission, which extends from the present day back to launch in 2001. A proof-of-concept study for the retrieval of stratospheric aerosol extinction from limb scatter measurements was previously published and the Version 5 data product retrievals are based on this work, but incorporate several important improvements to the algorithm. One of the primary changes {{is the use of}} a new <b>retrieval</b> <b>vector</b> that greatly improves the sensitivity to aerosol scattering by incorporating a forward modeled calculation of the radiance from a Rayleigh atmosphere. Additional improvements include a coupled retrieval of the effective albedo, a new method for normalization of the measurement vector to improve signal-to-noise, and the use of an initial guess that is representative of very low background aerosol loading conditions, which allows for maximal retrieval range. Furthermore, the Version 5 data set is compared to SAGE III 755 nm extinction profiles during the almost four years of mission overlap from 2002 to late 2005. The vertical structure in coincident profile measurements is well correlated and the statistics on a relatively large set of tight coincident measurements show agreement between the measurements from the two instruments to within approximately 10 % throughout the 15 to 25 km altitude range, which covers the bulk of the stratospheric aerosol layer for the mid and high latitude cases studied here...|$|E
40|$|To detect {{changes in}} our {{environment}} earlier, and to investigate {{the atmosphere of the}} Earth in more detail, the environmental satellite (ENVISAT) will be launched by the European space agency (ESA) in a polar orbit {{at the end of the}} year 2000. One of its payload instruments is the Fourier spectrometer MIPAS (Michelson interferometer for passive atmospheric sounding), measuring the emission of molecules in the atmosphere in a limb viewing mode. The goal of this experiment is to derive vertical profiles of pressure and temperature, as well as of the trace gases O_ 3, H_ 2 O, CH_ 4, N_ 2 O, and HNO_ 3 from the spectra operationally on a global scale. A major topic in the analysis of the computational methods to obtain the profiles is how available a priori knowledge can be used in the forward model and the retrieval algorithm, and how this a priori knowledge affects the corresponding results. Several retrieval methods were compared and it was shown that the optimal estimation algorithm can be used in a highly flexible way for this kind of data analysis. Depending on the choice of the regularisation, other retrieval methods like Tikhonov regularisation or Levenberg-Marquardt, can be simulated. In addition, different constraints for the different parameters can be considered simultaneously in one <b>retrieval</b> <b>vector.</b> Beyond this, scientific analysis tools, like estimated standard deviation, vertical resolution, or degrees of freedom, were provided as criteria to assess the quality of the result. On the basis of this analysis optimised regularisation parameters were determined and the huge influence of the choice of the regularisation and discretisation on the result could be demonstrated 68 refs. Available from TIB Hannover: RA 437 (2000 - 01) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|E
40|$|SVI is a {{promising}} new scheme for indexing high-dimensional points and vectors {{for use in}} <b>vector</b> <b>retrieval</b> and for finding the k-nearest neighbours. SVI performs an approximate search; that is, it trades off the completeness {{of the search for}} speed. The indexing scheme is built around a rule that was found by applying data mining techniques to sets of random vectors. This approach could well lead to further improvements in the indexing scheme. 1 Introduction This paper introduces {{a promising}} new scheme for indexing high-dimensional points and vectors called sub-vector indexing (SVI). SVI is used to reduce the time expended in processes such as <b>vector</b> <b>retrieval</b> and finding the k-nearest neighbours. Also described is the approach taken in developing SVI, for it is believed that this approach may lead to further improvements in the indexing scheme. It must be noted that the search performed in SVI is incomplete (or approximate), for it generally fails to locate some of the desired ite [...] ...|$|R
40|$|In {{this paper}} {{we deal with}} the problem of {{addition}} of new documents in collection when documents are represented in lower dimensional space by concept indexing. Concept indexing (CI) is a method of feature construction that is relying on concept decomposition of term-document matrix. By using CI original representations of documents are projected on the space spread by centroids of clusters, which are called concept vectors. This problem is especially interesting for application on World Wide Web. Proposed methods are tested for the task of information <b>retrieval.</b> <b>Vectors</b> on which the projection is done in the process of dimension reduction are constructed on the basis of representations of all documents in the collection, and computation of the new representations in the space of reduced dimension demands recomputation of concept decomposition. The solution to this problem is the development of methods which will give approximate representation of newly added documents in the space of reduced dimension. In the paper are introduced two methods for addition of new documents in the space of reduced dimension. In the first method there no addition of new index terms and added documents are represented by existing list of index terms, while in the second method list of index terms is extended and representations of documents and concept vectors are extended in dimensions of newly added terms. It is shown that representation of documents by extended list of index terms does not improve performance of information retrieval significantly. Povzetek: Predstavljeni sta dve metodi konceptualnega indeksiranja dokumentov. ...|$|R
40|$|In {{this paper}} we have {{proposed}} user feedback driven Information retrieval model. The proposed model assigns weights to the retrieved documents {{based on its}} context. The documents are re-ranked based on the user profile and his feedback. Proposed Information <b>retrieval</b> system uses <b>vector</b> space model and expert system. Need for user profile and relevance of information while searching and extracting information, from information retrieval system is highlighted...|$|R
40|$|Tsui, Wing Wun. Thesis (M. Phil.) [...] Chinese University of Hong Kong, 2011. Includes bibliographical {{references}} (leaves 125 - 137). Abstracts in English and Chinese. Thesis committee [...] - p. iiStatement [...] - p. iiiAbstract [...] - p. ivChinese abstract [...] - p. viAcknowledgements [...] - p. viiiGeneral abbreviations [...] - p. XList {{of figures}} [...] - p. xivList of tables [...] - p. XVTable of contents [...] - p. xviChapter Chapter 1 [...] - Introduction [...] - p. 1 Chapter 1. 1 [...] - Literature review on LIM-homeobox genes in mouse development [...] - p. 1 Chapter 1. 1. 1 [...] - LIM-homeobox genes [...] - p. 1 Chapter 1. 1. 2 [...] - Mouse Lhx 1 gene and development [...] - p. 5 Chapter 1. 1. 3 [...] - Mouse Lhx 5 gene and development [...] - p. 21 Chapter 1. 2 [...] - Mouse cerebellar Purkinje neurons [...] - p. 26 Chapter 1. 2. 1 [...] - Cerebellar cortex [...] - p. 26 Chapter 1. 2. 2 [...] - Neuronal circuitry and cerebellar functions [...] - p. 29 Chapter 1. 2. 3 [...] - Development of cerebellar Purkinje neurons [...] - p. 29 Chapter 1. 2. 3. 1 [...] - Neurogenesis [...] - p. 30 Chapter 1. 2. 3. 2 [...] - Migration and positioning [...] - p. 30 Chapter 1. 2. 3. 3 [...] - Specification and differentiation [...] - p. 31 Chapter 1. 2. 3. 4 [...] - Maturation [...] - p. 31 Chapter 1. 3 [...] - Green Fluorescent Protein (GFP) and tau protein [...] - p. 32 Chapter 1. 3. 1 [...] - Introduction to tau proteins [...] - p. 32 Chapter 1. 3. 2 [...] - Tau-GFP fusion protein and its application in tracing neuronal projections [...] - p. 33 Chapter 1. 4 [...] - Project background and aim [...] - p. 34 Chapter Chapter 2 [...] - Generation of Lhx 1 -tau-GFP knock-in mice [...] - p. 38 Chapter 2. 1 [...] - Introduction [...] - p. 38 Chapter 2. 2 [...] - Materials for molecular biological work [...] - p. 39 Chapter 2. 2. 1 [...] - Chemicals and kits [...] - p. 39 Chapter 2. 2. 2 [...] - Enzymes [...] - p. 40 Chapter 2. 2. 3 [...] - Plasmid vectors [...] - p. 40 Chapter 2. 2. 4 [...] - Oligonucleotide linkers [...] - p. 41 Chapter 2. 2. 5 [...] - Bacterial strains [...] - p. 41 Chapter 2. 2. 6 [...] - Solutions and media [...] - p. 41 Chapter 2. 2. 7 [...] - Radioactive isotopes and materials for autoradiography [...] - p. 43 Chapter 2. 2. 8 [...] - DNA probes for Southern blot hybridization [...] - p. 43 Chapter 2. 3 [...] - Materials for cell culture [...] - p. 44 Chapter 2. 3. 1 [...] - "Chemicals, sera and others" [...] - p. 44 Chapter 2. 3. 2 [...] - Culture solutions and media [...] - p. 44 Chapter 2. 3. 3 [...] - Culture cells [...] - p. 45 Chapter 2. 4 [...] - PCR primers [...] - p. 46 Chapter 2. 5 [...] - Animals [...] - p. 46 Chapter 2. 6 [...] - Methods for molecular biological work [...] - p. 46 Chapter 2. 6. 1 [...] - Preparation of plasmid DNA [...] - p. 46 Chapter 2. 6. 1. 1 [...] - Miniprep using simple crude method [...] - p. 47 Chapter 2. 6. 1. 2 [...] - Miniprep using purification kits [...] - p. 48 Chapter 2. 6. 1. 3 [...] - Midiprep using purification kit [...] - p. 50 Chapter 2. 6. 2 [...] - Purification of specific DNA fragments [...] - p. 51 Chapter 2. 6. 2. 1 [...] - QIAquick gel extraction kit [...] - p. 51 Chapter 2. 6. 2. 2 [...] - QIAquick PCR purification kit [...] - p. 52 Chapter 2. 6. 3 [...] - Subcloning of DNA fragments [...] - p. 53 Chapter 2. 6. 3. 1 [...] - Traditional approach based on restriction endonuclease and DNA ligase [...] - p. 53 Chapter 2. 6. 3. 2 [...] - Preparation of subcloning inserts and vectors [...] - p. 54 Chapter 2. 6. 3. 3 [...] - Two-way ligation of inserts and vectors [...] - p. 55 Chapter 2. 6. 4 [...] - Transformation of competent cells with recombinant DNA [...] - p. 56 Chapter 2. 6. 4. 1 [...] - CaCl 2 method [...] - p. 56 Chapter 2. 6. 4. 2 [...] - Electroporation [...] - p. 57 Chapter 2. 6. 5 [...] - Southern hybridization [...] - p. 59 Chapter 2. 6. 5. 1 [...] - Restriction endonuclease digestion and {{agarose gel electrophoresis}} [...] - p. 59 Chapter 2. 6. 5. 2 [...] - Capillary transfer and fixation of DNA [...] - p. 60 Chapter 2. 6. 5. 3 [...] - Radioactive labeling of DNA probe [...] - p. 60 Chapter 2. 6. 5. 4 [...] - Purification of radioactive labeled probe for hybridization [...] - p. 61 Chapter 2. 6. 5. 5 [...] - Hybridization [...] - p. 61 Chapter 2. 6. 5. 6 [...] - Post-hybridization wash and autoradiography for signal detection [...] - p. 62 Chapter 2. 7 [...] - Methods for generation and analysis of Lhx 1 -tau-GFP knock-in Mice [...] - p. 63 Chapter 2. 7. 1 [...] - Construction of targeting vector (pLhx 1 -tauGFP) for gene targeting of Lhx 1 locus [...] - p. 63 Chapter 2. 7. 2 [...] - Generation of targeted embryonic stem (ES) cell clones [...] - p. 66 Chapter 2. 7. 2. 1 [...] - Preparation of feeder cells [...] - p. 66 Chapter 2. 7. 2. 2 [...] - Culture of ES cells on feeder layers and passage [...] - p. 69 Chapter 2. 7. 2. 3 [...] - Harvest of cultured ES cells [...] - p. 70 Chapter 2. 7. 2. 4 [...] - Preparation of targeting vector for transfection of ES cells [...] - p. 71 Chapter 2. 7. 2. 5 [...] - Electroporation for transfection of ES cells [...] - p. 71 Chapter 2. 7. 2. 6 [...] - Drug selection for targeted ES cell clones using PNS strategy [...] - p. 72 Chapter 2. 7. 2. 7 [...] - Picking and expansion of targeted ES cell clones [...] - p. 72 Chapter 2. 7. 2. 8 [...] - Replica plating and freezing of targeted ES cell clones [...] - p. 74 Chapter 2. 7. 2. 9 [...] - Genomic DNA extraction from targeted ES cell clones [...] - p. 75 Chapter 2. 7. 2. 10 [...] - Screening of homologous recombinants by Southern hybridization analysis [...] - p. 76 Chapter 2. 7. 2. 11 [...] - Thawing and expansion of correct targeted ES cell clones [...] - p. 76 Chapter 2. 7. 2. 12 [...] - Chromosome counting of ES cells [...] - p. 78 Chapter 2. 7. 3 [...] - Generation of germline chimeric mice [...] - p. 80 Chapter 2. 7. 3. 1 [...] - Standard procedure [...] - p. 80 Chapter 2. 7. 4 [...] - Breeding and genotyping of mice [...] - p. 81 Chapter 2. 7. 5 [...] - Imaging of tau-GFP-labelled Purkinje neurons [...] - p. 84 Chapter 2. 7. 5. 1 [...] - Animal dissection and tissue preparation [...] - p. 84 Chapter 2. 7. 5. 2 [...] - Confocal laser scanning microscopy (CLSM) [...] - p. 84 Chapter 2. 8 [...] - Results [...] - p. 84 Chapter 2. 8. 1 [...] - Generation of Lhx 1 targeting vector (pLhx 1 -tauGFP) [...] - p. 84 Chapter 2. 8. 2 [...] - Targeted replacement of the mouse Lhx 1 coding sequences by tau-GFP genetic reporter [...] - p. 87 Chapter 2. 8. 3 [...] - Germline transmission of Lhx 1 -tau-GFP allele and generation of Lhx 1 -tau-GFP knock-in mouse [...] - p. 93 Chapter 2. 8. 4 [...] - Imaging of Lhx 1 -tau-GFP expressing Purkinje neurons [...] - p. 96 Chapter 2. 9 [...] - Discussion [...] - p. 98 Chapter 2. 9. 1 [...] - Tau-GFP labeling of Lhx 1 -expressing Purkinje neurons: implications for real-time live cell imaging [...] - p. 98 Chapter 2. 9. 2 [...] - Use of Lhx 1 -tau-GFP knock-in mice for study of Lhx 1 and Lhx 5 functions in Purkinje neurons survival and/or maintenance [...] - p. 99 Chapter Chapter 3 [...] - Generation of Lhx 5 -tau-GFP knock-in allele: alternative approach for real-time tracing of Purkinje neurons [...] - p. 102 Chapter 3. 1 [...] - Introduction: Recombineering-based approach for DNA subcloning [...] - p. 102 Chapter 3. 1. 1 [...] - λ phage-encoded Red recombination system [...] - p. 102 Chapter 3. 1. 2 [...] - DNA subcloning from bacterial artificial chromosome (BAC) [...] - p. 104 Chapter 3. 2 [...] - Materials for molecular biological work [...] - p. 105 Chapter 3. 2. 1 [...] - Chemicals and kits [...] - p. 105 Chapter 3. 2. 2 [...] - Enzymes [...] - p. 105 Chapter 3. 2. 3 [...] - Plasmid vectors and BAC DNA [...] - p. 105 Chapter 3. 2. 4 [...] - Bacterial strains [...] - p. 105 Chapter 3. 2. 5 [...] - Solutions and media [...] - p. 106 Chapter 3. 2. 6 [...] - PCR primers [...] - p. 106 Chapter 3. 3 [...] - Methods for construction of targeting vector for mouse Lhx 5 gene [...] - p. 107 Chapter 3. 3. 1 [...] - PCR amplification of homology sequences on BAC DNA [...] - p. 107 Chapter 3. 3. 2 [...] - Synthesis of retrieval arms for recombineering [...] - p. 109 Chapter 3. 3. 3 [...] - DNA sequencing analysis [...] - p. 110 Chapter 3. 3. 4 [...] - Construction of <b>retrieval</b> <b>vector</b> [...] - p. 110 Chapter 3. 3. 5 [...] - Preparation of electrocompetent cells for recombineering [...] - p. 111 Chapter 3. 3. 6 [...] - Recombineering-based retrieval of homology arms [...] - p. 112 Chapter 3. 4 [...] - Results [...] - p. 113 Chapter 3. 4. 1 [...] - The targeting vector (pLhx 5 -tauGFP) for mouse Lhx 5 gene [...] - p. 113 Chapter 3. 5 [...] - Discussion [...] - p. 118 Chapter 3. 5. 1 [...] - Use of recombineering-based approach to generate targeting vector [...] - p. 118 Chapter 3. 5. 2 [...] - Further generation of Lhx 5 -tau-GFP knock-in mice [...] - p. 119 Chapter Chapter 4 [...] - Conclusion and future perspectives [...] - p. 120 Chapter 4. 1 [...] - Conclusion [...] - p. 120 Chapter 4. 2 [...] - Potential applications of Lhx 1 -tau-GFP knock-in mice for study of Lhx 1 and other gene functions in cerebellum [...] - p. 120 Chapter 4. 3 [...] - Potential applications of Lhx 1 -tau-GFP knock-in mice for study of Lhx 1 -expressing cells development [...] - p. 122 References [...] - p. 12...|$|E
40|$|We {{present a}} new {{technique}} for content based image <b>retrieval</b> where feature <b>vector</b> to be matched is very much specific to the query image. A particular Peano scan which is optimal in encoding the query, image is used to convert the scanning pattern of all database images. Features are derived from these scan converted images to calculate the similarity measure. The features being query specific, a much improved performance is achieved for retrieval purpose...|$|R
40|$|In {{this paper}} a hybrid {{algorithm}} for image retrieval based on texture feature extraction is proposed. Proposed algorithm {{can be implemented}} for texture feature <b>retrieval</b> using <b>Vector</b> Quantization (VQ). For texture feature retrieval Linde-Buzo-Gray (LBG) algorithms is used by dividing each image into pixel blocks of size 2 X 2 where each pixel consists of green, red and blue component. A training vector of dimension 12 {{can be obtained by}} putting these in a row. A training set is collection of such training vectors. Size of codebook will be 16 X 12. In the proposed method K-means algorithm is applied on existing LBG codebook and results are compared with LBG algorithm. From experiments it is found that proposed algorithm gives better relevance percentage as compared to the LBG algorithm...|$|R
40|$|An {{approach}} to the <b>retrieval</b> of a <b>vector</b> wind field from Doppler lidar observations is developed in general terms. The field of radial velocity measurements from each look angle is modeled by a smooth surface, {{the parameters of the}} model being determined from the data by least squares techniques. The vector wind field and higher order fields are obtained from the two modeled surfaces. Estimated measurement errors are taken into account, and error estimates are available for all output data sets...|$|R
40|$|Abstract. Audio data is one {{of typical}} {{multimedia}} data and it contains plenty of information. Audio retrieval is becoming important content in multimedia information retrieval. In multimedia retrieval researches, it {{becomes more and more}} important research part how to construct better classifiers for audio classification and <b>retrieval.</b> Support <b>Vector</b> Machines, a novel method of the Pattern Recognition, presents excellent performance in solving the problems with small sample, nonlinear and local minima. But audio classification is a multi-class classification problem and it’s just one of problems to be solved in SVM researches. In this paper, it compares several common Support Vector Machines and proposes a hierarchical Support Vector Machines based on audio features cluster method, combining audio features and hierarchical SVMS. It uses hierarchical classification method to classify audio data and it’s proved better performance by experiments...|$|R
40|$|One of {{the core}} {{components}} in information retrieval(IR) is the document-term-weighting scheme. In this paper,we will propose a novel learning-based term-weighting approach to improve the <b>retrieval</b> performance of <b>vector</b> space model in homogeneous collections. We first introduce a simple learning system to weighting the index terms of documents. Then, we deduce a formal computational approach according to some theories of matrix computation and statistical inference. Our experiments on 8 collections will show that our approach outperforms classic tfidf weighting, about 20 %∼ 45 %...|$|R
