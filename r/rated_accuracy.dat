7|4539|Public
5000|$|A {{standard}} one-inch micrometer has readout {{divisions of}} [...]001 {{inch and a}} <b>rated</b> <b>accuracy</b> of +/- [...]0001 inch ("one tenth", in machinist parlance). Both the measuring instrument and the object being measured should be {{at room temperature for}} an accurate measurement; dirt, abuse, and low operator skill are the main sources of error.|$|E
5000|$|A {{refinement}} now popular is {{the replacement}} of the analog dial with an electronic digital display on which the reading is displayed as a single value. Rather than a rack and pinion, they have a linear encoder. Some digital calipers can be switched between centimeters or millimeters, and inches. All provide for zeroing the display at any point along the slide, allowing the same sort of differential measurements as with the dial caliper. Digital calipers may contain some sort of [...] "reading hold" [...] feature, allowing the reading of dimensions even in awkward locations where the display cannot be seen.Ordinary 6-in/150-mm digital calipers are made of stainless steel, have a <b>rated</b> <b>accuracy</b> of 0.001 in (0.02mm) and resolution of 0.0005 in (0.01 mm).The same technology is used to make longer 8-in and 12-in calipers; the accuracy for bigger measurements declines to 0.001 in (0.03 mm) for 100-200 mm and 0.0015 in (0.04 mm) for 200-300 mm.|$|E
5000|$|The game's {{gameplay}} {{is similar}} to that of other rhythm games in which players must press a series of buttons according to the sequence on the screen. The game primarily makes use of the 4 main symbols, X, circle, square and triangle, which are the face buttons for the PlayStation Portable. Various floating gray buttons of those symbols will appear on the screen, and the colored version of those symbols will begin to float in from the various sides of the screen. The player is required to press the face button once the colored symbol lands on its grayed version and based on the player's timing their accuracy is <b>rated.</b> <b>Accuracy</b> is described with a word displayed in the bottom right corner of the screen, ranging from [...] "cool" [...] to [...] "worst". The game is scored on accuracy and the player is awarded with a rank ranging from [...] "Perfect" [...] to [...] "Mistake" [...] (denoted by MissXTake). It also includes a chance mode whereby the combo system compounds points earned, for example one perfect note gives you 100 points, if you have a combo of 34 notes, the 34th note alone gives you an additional 3400 points.|$|E
40|$|The {{research}} literature on performance appraisal {{is well established}} but suffers from two inter-related problems. First, rater training has lacked theoretical justification. This void {{has resulted in a}} myriad of training programs, with post-hoc explanations used to understand their relative failures and successes. Second, performance appraisal research has focused on rating errors, not the more important issue of <b>rating</b> <b>accuracy.</b> While recent attempts have been made toward understanding accuracy, these attempts again lack theoretical structure. The problem with these shot-gun approaches is that scientific understanding is not advanced in a systematic manner, since there are few attempts to disprove theories. ^ The present study was an attempt to understand previous performance appraisal findings by incorporating theories and research from the person-perception field of psychology. Specifically, the current 3 x 2 x 3 study manipulated theoretically-based cognitive schema rater training (Person/Event/Control) and rating time (immediate/delay) as between subjects factors and rating instrument format (behavior frequency scale/performance evaluation scale) as a within subjects factor. The major hypothesis predicted that the type of cognitive schema employed by raters as they watched videotaped lectures would interact with the instrument format to affect <b>rating</b> <b>accuracy.</b> It was also hypothesized that <b>rating</b> <b>accuracy</b> would be related to one 2 ̆ 7 s memory, such that as time and schemas affected memory that there would be corresponding changes in <b>rating</b> <b>accuracy.</b> ^ Results showed that only one of the three component measures of <b>rating</b> <b>accuracy</b> (differential elevation) was affected by an interaction between rater training and rating format. While recognition bias and sensitivity behaved as predicted (prototypical bias exceeded antiprototypical bias, antiprototypical sensitivity exceeded prototypical sensitivity, antiprototypical bias decreased across time), an improvement in <b>rating</b> <b>accuracy</b> was not associated with a reduction in antiprototypical bias. ^ Overall, the present study could not explain some of the previous research findings on <b>rating</b> <b>accuracy.</b> However it represents an important step toward a theoretical integration of rater training with the rating instrument form. ...|$|R
40|$|Performance {{appraisal}} must {{be accurate}} {{because it is}} used the decisions about promotions, salary increase, assignments, and education. This article reviewed previous research on performance appraisal focusing on <b>rating</b> <b>accuracy.</b> First, research on ratee 2 ̆ 7 s information processing models and the factors that affect the processing and rating was reviewed. Next three measures of <b>rating</b> <b>accuracy,</b> that is, <b>rating</b> <b>accuracy</b> measure, <b>rating</b> error measure, and psychometric criteria, were discussed. <b>Rating</b> <b>accuracy</b> measure is mainly described by how close an actual rating compares with an expert 2 ̆ 7 s rating. Rating error measures indicate to what to extent rating errors, such as halo and leniency, are represented. Psychometric criteria is defined by reliability, such as the rating differences among individuals, and validity, such as construct validity. Rating error measures and psychometric criteria are calculated based on {{means and standard deviations}} of actual ratings. It was noted that there are problems with these measures of <b>rating</b> <b>accuracy</b> related to the application of performance appraisal in real situation, and only measure relative <b>rating</b> <b>accuracy.</b> After the problems were described, it was concluded that the rating differences among individuals were worthy of note when considering the application in a real situation. A new information processing model was presented, taking into consideration the rating differences among individuals. Finally, several research issues were presented which are relevant when studying accuracy of performance appraisal in the future. パフォーマンスの評価は, 報酬分配, 人事配置, 教育などを目的として行われるので, 正確である必要がある。本稿では, 評価の正確さに焦点を絞り, パフォーマンスの評価に関する先行研究を概観した。まず, 評価者の情報処理過程のモデルやその情報処理過程に影響を及ぼす要因についての先行研究を概観した。次に, それらの先行研究で用いられている 3 つの評価の正確さの測度, すなわち, 評価の正確さの測度, 評価のエラーの測度, そして, 心理測度について示した。評価の正確さの測度は, 主に, 評価のエキスパートが下した評価に, 実際に評価を下した評価者たちの評価がどのくらい近いかによって表される。評価のエラーの測度は, ハローエラーや寛大化エラーなどの評価のエラーがどの程度みられるかによって示される。心理測度は, 評価の個人差などの信頼性, および構成概念妥当性などの妥当性によって示される。そして, 評価のエラーの測度や心理測度は, 実際に下された評価の平均値や標準偏差をもとに算出される。評価の正確さに関する測度は, 現実場面の人事考課への適用に関してそれぞれ問題点をもっており, 相対的な評価の正確さを測定しているにすぎないことが述べられた。それぞれの問題点が指摘された後, 評価の現実場面における適用を考慮する場合には, 評価の個人差を測度として取り上げる価値があることを指摘した。そして, この評価の個人差の生起メカニズムを理解するための従来とは異なる評価者の情報処理過程モデルを提示した。最後に, 今後, 評価の正確さを検討するために必要とされる研究課題について述べた...|$|R
40|$|Graduation date: 1992 The {{purpose of}} this {{research}} {{study was to examine}} the impact of the consulting teacher model on referral and verification rates to special education. A population of schools which implemented the model (N = 17) was compared with a randomly selected comparison group of schools which did not (N = 30). All schools were from the Portland, Oregon, Public School District. The research was designed to cover a three school year period of time (1987 to 1990). Three different types of data were collected: the number of children who were discussed at regular education pre-referral meetings, the number of children who were referred for special education assessment and the number of children who verified as eligible for special education services. Three primary research questions addressed (a) the impact of the consulting teacher model on the number of children in the process, (b) the longitudinal impact of the model on referral <b>rate</b> <b>accuracy</b> and (c) referral <b>rate</b> <b>accuracy</b> differences between the consulting teacher and comparison group schools. Results from the first question indicated a difference in the numbers of children discussed at the initial regular education pre-referral step; 17 more children were discussed in the consulting teacher schools. Differences were also found between the 1987 - 88 school year and every other year; seven more children were in the process in the first year of the study than in the later years. Results from the second question found that length of time on the model does have a significant effect on referral <b>rate</b> <b>accuracy</b> in the consulting teacher schools. Two differences were found in this question: an increase in referral <b>rate</b> <b>accuracy</b> between years three and four and a decrease in referral <b>rate</b> <b>accuracy</b> between years four and five. Results from the third question indicated no differences between the type of school and school year. Referral <b>rate</b> <b>accuracy</b> remained the same in both the consulting teacher and comparison group schools throughout all three years of this study...|$|R
3000|$|... “They are not trustworthy. Sometimes {{they say}} it is going to rain in the {{afternoon}} and it is dry, sometimes they hit the target and sometimes they don't.” (ASADA 7, <b>rated</b> <b>accuracy</b> of 5) [...]...|$|E
40|$|Gain {{trimming}} {{is almost}} always required in instrumentation amplifier based systems. Gain uncertainties, most notable in transducers, necessitate such a trim. Figure 1, a conceptual system, shows several points as candidates for the trim. In practice, {{only one of these}} must actually be used. The appropriate trim location varies with the individual application. Figure 2 approaches gain trimming by altering transducer excitation. The gain trim adjustment results in changes in the LT 1010 ’s output. The LT 1027 reference and LT 1097 ensure output stability. Transducer output varies with excitation, making this a viable approach. It is important to consider that gain “lost ” by reducing transducer drive translates into reduced signal-to-noise ratio. As such, gain reduction by this method is usually limited to small trims, e. g. 5 - 10 %. Similarly, too much gain introduced by this method can cause excessive transducer drive, degrading accuracy. The transducer manufacturer’s data sheet should list the maximum permissible drive for <b>rated</b> <b>accuracy...</b>|$|E
40|$|Two {{studies were}} {{conducted}} to examine expert opinions of criteria used to select forecasting techniques. In Study One, while "accuracy " was a dominant criterion, the ratings of five of thirteen criteria varied by {{the role of the}} forecaster. Researchers <b>rated</b> <b>accuracy</b> relatively higher than did practitioners, educators or decision-makers. Decision makers rated implementation-related criteria, such as "ease " criteria, relatively higher than the other groups. In Study Two, forecasting experts significantly varied their ratings on six of seven criteria according to situations. Other criteria were often as important or more important than accuracy, especially when the situation involved making many forecasts. In general, there was much agreement across roles and across situations that accuracy was the most important criterion, but other criteria were rated as being almost as important. In particular, factors related to implementation, such as ease of interpretation and ease of use, were highly rated. expert opinion, forecaster's role, forecast situation, implementatio...|$|E
40|$|We {{substantiate}} {{the feasibility}} of a market mechanism that addresses ratings shopping, ratings inflation, and encourages competition over <b>rating</b> <b>accuracy</b> among credit <b>rating</b> agencies (CRAs). An issuer strate-gically delegates the task to acquire ratings, from CRAs, to a pass-through non-monitoring platform (the “trust”). The trust operates as a commitment mechanism for the issuer and pays outcome-contingent fees, {{a large portion of}} which is paid upfront. In turn, high credit <b>rating</b> <b>accuracy</b> assures investors’ participation in the market, creating the surplus that guarantees voluntary participation of CRAs and issuers. Overall, the mechanism creates a Pareto-improving equilibrium that requires minimal regulatory intervention...|$|R
40|$|The {{predictive}} {{influence of}} assessor individual differences on <b>rating</b> errors and <b>accuracy</b> was evaluated {{in a field}} study of assessment centers. Rater errors were based on archival data containing over 20, 000 assessments of candidates for assembly line positions. Cronbach 2 ̆ 7 s four components of rater accuracy were determined by providing assessors with behavioral performance data for candidates who had previously performed in an assessment center. ^ Rater errors {{are assumed to be}} relatively stable rating characteristics. Rater errors investigated were halo error, range restriction, and leniency. Individual differences in ability and motivation were expected to predict rating biases. An interaction model combining assessor ability and motivation was utilized to predict <b>rating</b> <b>accuracy.</b> ^ Eighty-two assessors were measured on five scales: attributional complexity, conscientiousness, intelligence, need to evaluate, and self-monitoring. Assessors were provided with dimensional ratings for 12 candidates. Ratings were then compared to known true scores to determine accuracy. ^ It was hypothesized that assessors with higher levels of ability and motivation would make fewer rating errors. Regression analyses indicated attributionally complex assessors showed less range restriction. More intelligent assessors gave more lenient ratings. Halo error decreased as assessors 2 ̆ 7 experience increased. ^ For <b>rating</b> <b>accuracy,</b> it was hypothesized that higher levels of ability and motivation would interact to predict greater <b>rating</b> <b>accuracy.</b> Moderate support was found for the ability x motivation interactions in predicting accuracy. Regression analyses revealed a mixed pattern of significant interactions. Need to evaluate seems {{to play an important role}} in <b>rating</b> <b>accuracy</b> and appeared in four of the five significant interactions. For less attributionally complex assessors with a higher need to evaluate, greater elevation, differential, and stereotype accuracy were found. More intelligent assessors with higher levels of need to evaluate showed an increase in differential accuracy. ^ Further studies are required to better understand the role of need to evaluate in <b>rating</b> <b>accuracy.</b> Results also suggest that the design of the assessment center and training of assessors may be key elements in producing accurate, unbiased ratings. ...|$|R
50|$|Strengthen CRA Operations. The SEC {{should use}} its inspection, examination, and {{regulatory}} authority to ensure credit rating agencies institute internal controls, credit rating methodologies, and employee {{conflict of interest}} safeguards that advance <b>rating</b> <b>accuracy.</b>|$|R
40|$|ABSTRACT. Grain {{temperature}} and moisture content (MC) {{are considered to}} be principal factors for safe storage of grain. Continuous monitoring of temperatures within grain masses is relatively easy using thermocouples, but monitoring of MC is limited by availability of sensors. However, {{temperature and}} relative humidity (RH) can be used to predict grain MC based on equilibrium moisture content (EMC) equations such as the Modified Henderson, Chung-Pfost, or Oswin. These models are limited to quasi-static thermodynamic conditions but do provide a method to predict MC with commercial sensors. Error analysis was performed using EMC relationships for wheat to determine the error in grain MC prediction due to sensor error. EMC prediction errors were found to be 0. 25 % to 0. 65 % MCdb between the RH ranges of 20 % to 70 % RH. At higher RH levels, prediction error increased substantially. Sensor error was set to 2 % RH and 0. 4 C, for the error analysis. The sensor error was adopted from a commercial sensor that could be potentially used for a cabled monitoring system. At higher levels of sensor error (3 % RH, 0. 4 C and 4 % RH, 0. 4 C), prediction error increased from 0. 38 % to 0. 96 % MCdb and from 0. 65 % to 1. 29 % MCdb, respectively, for the same RH range. Prediction error due to sensor error was found to be of the same magnitude as the standard errors of regression models developed for wheat. Measurements of sensor accuracy were also performed and accuracy was found to be within or better than rated manufacturer specifications for RH but temperature accuracy was less than <b>rated</b> <b>accuracy...</b>|$|E
30|$|The {{proposed}} VAD algorithm {{was trained}} and tested using a speech database that is phonetically balanced. The system was evaluated using the error <b>rate</b> and <b>accuracy</b> <b>rate</b> metrics.|$|R
40|$|The {{current study}} {{is the first to}} {{investigate}} whether individual differences in personality are related to improved first impression accuracy when appraising psychopathy in female offenders from thin-slices of information. The study also investigated the types of errors laypeople make when forming these judgments. Sixty-seven undergraduates assessed 22 offenders on their level of psychopathy, violence, likability, and attractiveness. Psychopathy <b>rating</b> <b>accuracy</b> improved as rater extroversion-sociability and agreeableness increased and when neuroticism and lifestyle and antisocial characteristics decreased. These results suggest that traits associated with nonverbal <b>rating</b> <b>accuracy</b> or social functioning may be important in threat detection. Raters also made errors consistent with error management theory, suggesting that laypeople overappraise danger when rating psychopathy...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe U. S. Navy’s answer for many future manpower and financial policy questions {{rests on the}} ability of the individual performance appraisal system to optimally signal officer productivity. This paper utilizes the economics literature on individual performance appraisals and promotion systems as the lens through which to conduct a comparative analysis between the Navy and Marine performance appraisal systems. <b>Rating</b> <b>accuracy,</b> differentiation of talent, and performance comparison methods comprise the bulk of the analysis. The results show a Marine system that exceeds the Navy’s in signal officer productivity. The Navy’s system provides limited assurance for <b>rating</b> <b>accuracy</b> and the differentiation of talent. Once insight is gained through analysis, a metric is developed to further improve the measurement of individual productivity. This paper recommends the Navy improve <b>rating</b> <b>accuracy</b> through leadership messaging, policy change, and rater training. Second, relative comparison methods should be required to force differentiation of talent and align with the Navy’s tournament theory incentive structure. Third, to reduce costs and improve human capital management an individual productivity metric should be developed that is based on the output of the performance appraisal. Lieutenant Commander, United States Nav...|$|R
40|$|A network Intrusion Detection System (IDS) is a {{security}} tool {{that acts as}} a defensive line. One of the most important challenges in network intrusion detection research area is designing an accurate intrusion detection system in terms of high detection <b>rate,</b> high <b>accuracy</b> and low false alarm rate. Hybrid learning approaches employ to deal with this challenge since, they have promising results in terms of detection <b>rate,</b> <b>accuracy</b> and false alarm rate. This paper, proposed a general structure of a hybrid learning approach. Then, the proposed approach has been implemented using K-means Clustering and Multiple Classifiers (KCMC). The data have been partitioned based on K-means clustering algorithm. Then, each partition classified using a distinct classifier. Naïve Bayes, Support Vector Machines and OneR classification algorithms have been used as the classifiers. The proposed hybrid approach has better results comparing to single classifiers in terms of detection <b>rate,</b> <b>accuracy</b> and false alarm rate. The detection rate of the proposed hybrid learning approach is 99. 50 %...|$|R
40|$|Intrusion Detection System (IDS) has {{increasingly}} become a crucial issue for computer and network systems. Optimizing performance of IDS becomes an important open problem which receives {{more and more}} attention from the research community. This paper, design and develop a proposed multi-layer intrusion detection model to achieve high efficiency and improve the detection and classification <b>rate</b> <b>accuracy.</b> Also the proposed model was improved the detection rate for known and unknown attacks by training the hybrid model on the known intrusion data. Then the model applied for unknown attacks by introducing new types of attacks that are never seen by the training module. The experimental {{results showed that the}} proposed multi-layer model using C 5 decision tree achieves higher classification <b>rate</b> <b>accuracy,</b> and less false alarm rate...|$|R
30|$|Count <b>rate</b> <b>accuracy</b> was {{estimated}} by extrapolating the true rate for low-activity concentrations (where count losses and randoms can be effectively neglected) back to higher activity levels and {{comparing it to}} the measured and corrected trues rate. Data was reconstructed using the FORE algorithm and FBP.|$|R
30|$|Mean bias for count <b>rate</b> <b>accuracy</b> {{was higher}} for the mMR (4.9  %) than that for the mCT (1.9  %) at peak NECRs. For {{activity}} concentration in the clinical range, the mean bias was slightly {{higher for the}} mCT (1.3  %) compared to that for the mMR (0.9  %).|$|R
40|$|Website © 2008 Ingenta. Article {{copyright}} remains {{with the}} publisher, society or author(s) as specified within the articleDifferent types of rating scales {{have been developed}} to guide the qualitative analysis of sports technique and improve <b>rating</b> <b>accuracy.</b> However, it remains unclear what type of scale is more accurate and how <b>rating</b> <b>accuracy</b> is influenced by scale effects. This study aimed to: i) investigate the <b>accuracy</b> of <b>rating</b> scale type (analogue, numerical analogue, Likert and numerical Likert) for the rating of kinematic variables; and ii) explore how <b>rating</b> <b>accuracy</b> is influenced by scale effects. One experienced rater constructed the 100 mm-long scales and a group of 327 novice analysts rated the video-recorded soccer kick performance of 32 school children. Estimation error was calculated as the difference between estimated values and objective digitized values. Over-and under-estimation tendencies were assessed. The scale range was divided into equal-length intervals (e. g., low, middle, high angular range) to assess scale effects. Statistical analysis consisted of an exploratory principal components analysis with varimax rotation, where items were forced into a three-factor solution. Numerical Likert scale designs may be suggested as optimum for the instruction of novice raters. Central-tendency error adversely affected visual estimations; however, other scale effects enhanced accuracy. The findings have implications for optimum scale design and improved instruction in qualitative analysis. Marqués-Bruna Pascual, Lees Adrian and Grimshaw Pau...|$|R
30|$|Thus, Naïve Bayes {{algorithm}} {{demonstrated the}} highest <b>rate</b> of <b>accuracy</b> at 87.5 % for sex classification {{by using the}} selected parameters of the left foot, whereas Random Tree algorithm showed the lowest <b>accuracy</b> <b>rate</b> of 82.8 % among all.|$|R
30|$|The REP Tree {{algorithm}} exhibited an <b>accuracy</b> <b>rate</b> of 82.5 %, {{whereas the}} TP values were 0.826 and 0.824 for females and males, respectively. Through the Naïve Bayes algorithm, the <b>accuracy</b> <b>rate</b> was 0.906 for females and 0.852 for males, whereas the overall <b>accuracy</b> <b>rate</b> of sex classification {{was observed at}} 87.8 % (Table  4).|$|R
40|$|This study {{examined}} the impact of measurement scale wording on rater judgment and leniency in an employee performance evaluation context. Participants evaluated ratees in a task simulation video using a five-point anchored scale with either unipolar, bipolar, or no anchor labels. Findings partially supported the hypotheses, suggesting scale descriptors may affect performance <b>rating</b> <b>accuracy...</b>|$|R
40|$|Abstract—This paper {{presents}} an experiment that determines {{the ability of}} a multi-layer neural network implemented in Matlab to identify handwriting samples of the single digits 0 - 9. Specifically, the implementation in Matlab was based on a Multi-Layer Perceptron Network (MLPN) trained with back propagation. The network performs with an overall recognition <b>rate</b> (<b>accuracy)</b> of 81. 6 %...|$|R
50|$|To ensure {{interoperability}} {{and reliable}} communication, CANaerospace specifies the electrical characteristics, bus transceiver requirements and data rates with the corresponding tolerances based on ISO 11898. The bit timing calculation (baud <b>rate</b> <b>accuracy,</b> sample point definition) and robustness to electromagnetic interference are given special emphasis. Also addressed are CAN connector, wiring considerations and design guidelines to maximize electromagnetic compatibility.|$|R
5000|$|... #Caption: Adaptive {{plasticity}} {{along with}} practice in three levels. In behavior level, performance (e.g., successful <b>rate,</b> <b>accuracy)</b> improved after practice. In cortical level, motor representation {{areas of the}} acting muscles enlarged; functional connectivity between primary motor cortex (M1) and supplementary motor area (SMA) is strengthened. In neuronal level, the number of dendrites and neurotransmitter increase with practice.|$|R
40|$|International audienceA {{study is}} carried out in order to {{discriminate}} different spreading technologies and improve them regarding their environmental performances. We define 45 sewage sludge spreading scenarios covering {{a wide range of}} situations in France. Several models are used to (i) assess nitrogen losses due to sewage sludge spreading and (ii) calculate additional flow resulting from the technologies performances such as spatial distribution heterogeneity, application <b>rate</b> <b>accuracy</b> and soil compaction of the spreading machine. NH 3 volatilisation due to the spreader performances is generally low and the highest for splash plate technology. Additional emissions are mainly caused by application <b>rate</b> <b>accuracy</b> problems. It is not possible to link NO 3 leaching to the technologies performances: this kind of emissions greatly depends on soil and climate conditions. Denitrification greatly increases in sensitive sites and observed differences between scenarios are only due to the specific compaction impact of each spreader...|$|R
40|$|One hundred seventy-eight {{subjects}} observed videotaped {{incidents of}} a secretary performing {{on the job}} and rated her performance across four performance dimensions (and overall performance). <b>Rating</b> <b>accuracy,</b> behavior recognition <b>accuracy,</b> and <b>rating</b> level were measured under conditions of viewing improving or deteriorating performance, with behavior-based or impression-based processing methods, and with or without time pressure to complete the rating task. Results display robust main effects for both processing method and performance pattern on rating level. Raters viewing performance that improved over time gave the secretary lower ratings than raters viewing performance that deteriorated over time. Raters using behavior-based processing methods rated performance higher than raters using impression-based processing methods during the rating task. Processing method influenced <b>rating</b> <b>accuracy</b> for two of the performance dimensions; effects were mixed. Small relationships among measures of memory discrimination and response bias and <b>rating</b> <b>accuracy</b> and performance pattern were also discovered. Time pressure had no stable effect on any of the dependent variables. The results illustrate the pervasiveness of primacy effects in performance rating tasks. They also underscore the importance of standardizing rating procedures that are used to compare performance of different individuals. Additional research in applied settings is needed to capture the organizational influences on the performance rating process. Because of the complexities involved in performance rating systems in organizations, it may be prudent to change the typical way in which supervisor input about employee performance is used in human resources decisions...|$|R
30|$|As an {{efficient}} classifier, neural networks {{are widely used}} for classification in many fields such as image recognition, natural language processing, etc. In this paper, we use neural networks to classify malicious and legitimate executables. Multi-layers neural networks (Fernándezcaballero et al. 2003; Esmaily et al. 2015; Salai Selvam et al. 2011; Salcedo Parra et al. 2014) as one of deep learning methods achieve faster convergence <b>rate</b> and higher <b>accuracy</b> <b>rate</b> by comparing with single hidden layer neural networks, but also bring some drawbacks, such as gradient disappearance, over-fitting, etc. To overcome these drawbacks and further improve convergence <b>rate</b> and <b>accuracy</b> <b>rate,</b> we propose our principal component initialized multi-layers neural networks.|$|R
30|$|The {{selected}} datasets include MSR Action [22], CASIA [23], INRIA [24], Weizmann [25], KTH [25], UIUC [26], and Muhavi [27]. The proposed {{method is}} verified with five classification method, while multi-class SVM {{acts as a}} base classifier. The performance of our proposed algorithm is based on multiple measures which include recall rate, false positive rate, false negative <b>rate,</b> <b>accuracy,</b> and precision.|$|R
40|$|Abstract — The {{rate control}} {{algorithm}} is of essential importance to a video encoder. It enables the encoded bitstream {{to meet the}} bandwidth and storage requirement while maintaining good video quality. Most existing works adjust the quantization step size to achieve the required bit <b>rate</b> <b>accuracy.</b> This paper introduces a new dimension: the quantization rounding offset into a frame-level fine rate control algorithm. Specifically, we propose a novel fine rate control algorithm based on a linear model between the bit rate and the rounding offset. Unlike the quantization step size that has {{a limited number of}} choices, the quantization rounding offset is a continuously adjustable variable which allows the rate control algorithm to reach any precision in principle. Extensive experiment results show that the proposed algorithm greatly improves the bit <b>rate</b> <b>accuracy</b> and provides better visual quality by fine tuning of the rounding offset in addition to the quantization step size. I...|$|R
40|$|Rating format {{research}} {{has largely been}} ignored since Landy and Farr 2 ̆ 7 s(1980) call fora moratorium over a decade ago. Their conclusion that ratings were not affected by changes in scale format was based on research that treated all raters alike. However, individuals differ {{in the way in}} which they perceive and integrate information. This article investigates the proposition that differences in <b>rating</b> <b>accuracy</b> associated with different rating formats are contingent on rater characteristics. The study tested the <b>rating</b> <b>accuracy</b> and affective reactions toward performance appraisal of field-dependent (FD) and field-independent (FI) raters on four different performance measures. As hypothesized, FIs were more accurate raters than FDs only when scale formats were holistic, and only FDs 2 ̆ 7 ratings were significantly affected by the level of structure in the scale format. FI raters were also more confident in their ratings and less frustrated and confused with the rating task than were FDs...|$|R
40|$|The {{effect of}} an {{instructional}} package, which included modeling, reinforcement, and remedial {{feedback on the}} <b>rate,</b> <b>accuracy,</b> and topography of sentences composed by four hearing impaired and aphasic children, was examined. In a specially designed classroom, students wrote sentences describing a stimulus picture on acetate sheets placed {{on the stage of}} an overhead projector which was built into each student's desk. This arrangement provided the teacher and other students immediate and continuous visual access to each student's sentences. In a multiple baseline design across behaviors, model sentences were projected and token reinforcment and remedial feedback were made contingent upon writing correct sentences containing prenominal adjectives only, then adverbs only, then prenomial adjectives plus adverbs. During baseline all student displayed poor written language skills and seldom wrote sentences containing modifiers. When the instructional package was implemented, all students demonstrated significant increases in response <b>rate,</b> <b>accuracy,</b> and percentage of correct sentences including prenominal adjectives and adverbs...|$|R
40|$|Continuous glucose sensors (CGS) {{offer the}} {{potential}} to greatly change {{the lives of people}} with diabetes. Even though two of these systems (Guardian RT, Medtronic, Northridge, CA, and DexCom STS, DexCom, San Diego, CA) have been approved by the Food and Drug Administration for use as adjuncts to self-blood glucose monitoring (SBGM), questions remain concerning the accuracy of these devices. When considering accuracy, two distinct approaches should be emphasized: (1) numerical and (2) clinical. Because CGS data are a process in time, each of these two approaches includes two subtypes of accuracy: point and rate. Conventional statistics such as correlation coefficients, mean and median relative absolute differences, and International Standards Organization criteria are measures of numerical point accuracy. A new measure, the R deviation, is introduced to quantify numerical <b>rate</b> <b>accuracy.</b> Error-grid analysis (Clarke EGA) measures clinical point accuracy. The only measure of both clinical point <b>accuracy</b> and <b>rate</b> <b>accuracy</b> is continuous glucose error-grid analysis. This analysis is a combination of two components, P-EGA measuring point accuracy and R-EGA measuring <b>rate</b> <b>accuracy,</b> which are designed to assess the information that distinguishes continuous glucose measurements from intermittent SBGM determinations. Further, {{a better understanding of the}} source of the error associated with time lag and its effect on CGS readings may improve sensor output. Finally, the reliability of the CGS sensors, in terms of initial calibration and long-term application, needs to be assessed carefully if current CGS systems are to be used as hypoglycemia monitors or incorporated in the future design of closed loop (artificial pancreas) systems...|$|R
5000|$|... #Caption: The <b>rate</b> of <b>accuracy</b> with [...] "TD" [...] {{indicated}} the flow {{level of the}} solution ...|$|R
