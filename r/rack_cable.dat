0|28|Public
40|$|The {{infrastructure}} for the electronics, such as cabling, mains power distribution, {{low and high}} voltage power supplies, detector safety system, grounding and its installation in the LHCb experimental cavern is presented. In addition, <b>racks,</b> <b>cable</b> ducts installation and optical fiber link tests are described...|$|R
50|$|Housed in {{purpose-built}} modules {{of standard}} shipping container form-factor of either 20 feet or 40 {{feet in length}} the data centers are shipped preconfigured with <b>racks,</b> <b>cabling</b> and equipment for power and cooling. They can support technologies from HP or third parties. The claimed capacity {{is the equivalent of}} up to 10,000 square feet of typical data center capacity depending on the model. Depending on the model, they use either chilled water cooling or a combination of direct expansion air cooling.|$|R
50|$|The {{expense of}} a large concert active speaker system {{is less than the}} {{expense of a}}n {{equivalent}} passive system. The passive system, or integrated active system with external electronics, requires separate components such as crossovers, equalizers, limiters and amplifiers, all mounted in rolling <b>racks.</b> <b>Cabling</b> for passive concert systems is heavy, large-diameter speaker cable, more expensive than smaller diameter AC power cables and much smaller audio signal cables. For high-end home use, active speakers usually cost more than passive speakers because of the additional amplifier channels required.|$|R
5000|$|Overhead or {{underfloor}} <b>cable</b> <b>rack</b> (tray) and fibreguide, {{power cables}} usually on separate rack from data.|$|R
25|$|The Federal Reserve Board has a quality-adjusted {{price index}} for {{large-scale}} enterprise storage systems including {{three or more}} enterprise HDDs and associated controllers, <b>racks</b> and <b>cables.</b> Prices for these large-scale storage systems improved {{at the rate of}} ‒30% per year during 2004–2009 and ‒22% per year during 2009–2014.|$|R
50|$|Mouxy {{connects the}} Valley of Aix-les-Bains to the mountain. The Revard ski station in 1908, {{was the first}} ski resort in France, which participated {{actively}} {{in the construction of}} infrastructure of transport through Mouxy (<b>rack</b> and <b>cable</b> car) to carry skiers to the Summit, and this until system was improved in 1969. Mouxy thus had two stations.|$|R
50|$|The {{environment}} {{drives the}} installation methods for raised floors, including site preparation, <b>cable</b> and <b>cable</b> <b>racking,</b> bonding and grounding, and fire resistance. The actual installation {{should be in}} accordance with the customer’s practices.|$|R
50|$|The {{beautiful}} {{panoramic view}} from the summit and its easy access over the <b>rack</b> railway and <b>cable</b> car have made the Wendelstein {{one of the best}} known and most popular mountains in the Bavarian Alps.|$|R
5000|$|Wheel and axle: Hoist, winch, {{rack and}} pinion, chain drive, belt drive, rigid chain and rigid belt {{actuators}} {{operate on the}} principle of the wheel and axle. A rotating wheel moves a <b>cable,</b> <b>rack,</b> chain or belt to produce linear motion.|$|R
50|$|Depending on the {{government}} organization, utilizing an alarmed carrier PDS in conjunction with interlocking armored cable may, in some cases, allow {{for the elimination of}} the carrier systems altogether. In these instances, the cables being protected can be installed in existing conveyance (wire basket, ladder <b>rack)</b> or suspended <b>cabling</b> (on D-rings, J-Hooks, etc.).|$|R
40|$|At the {{beginning}} of the design and construction of the STAR Detector, the collaboration assigned a team of physicists and engineers the responsibility of coordinating the construction of the detector. This group managed the general space assignments for each sub-system and coordinated the assembly and planning for the detector. Furthermore, as this group was the only STAR group with the responsibility of looking at the system as a whole, the collaboration assigned it several tasks that spanned the different sub-detectors. These items included grounding, <b>rack</b> layout, <b>cable</b> distribution, electrical, power and water, and safety systems. This paper describes these systems and their performance. ...|$|R
5000|$|Wheel and axle: Hoist, winch, {{rack and}} pinion, chain drive, belt drive, rigid chain and rigid belt {{actuators}} {{operate on the}} principle of the wheel and axle. By rotating a wheel/axle (e.g. drum, gear, pulley or shaft) a linear member (e.g. <b>cable,</b> <b>rack,</b> chain or belt) moves. By moving the linear member, the wheel/axle rotates.|$|R
50|$|In 1928 {{the rack}} railway section was {{replaced}} with a funicular section, and the <b>rack</b> locomotives by <b>cable</b> tractors. However, the original four-wheel trams continued running until 1935, when they were replaced by new bogie cars. The extension to Villa Opicina station was closed in 1938. After nearly 60 years of private ownership, the line {{was taken over by}} the municipality of Trieste in 1961.|$|R
50|$|A powered speaker usually weighs {{more than}} an {{equivalent}} passive speaker because the internal amplifier circuitry usually outweighs a speaker-level passive crossover. A loudspeaker associated with an integrated active system is even lighter because it has no internal crossover. A lightweight loudspeaker can be more easily carried and it {{is less of a}} load in rigging (flying). However, active speakers using lightweight Class-D amplifiers have narrowed the difference. Trucking for a sound system involves transporting all of the various components including amplifier <b>racks,</b> speaker <b>cabling</b> and loudspeaker enclosures. Overall shipping weight for an active loudspeaker system may be less than for a passive system because heavy passive speaker cable bundles are replaced by lighter AC cables and small diameter signal cables. Truck space and weight is reduced by eliminating amplifier racks.|$|R
40|$|The LCLS project {{databases}} provide key nomenclature information while integrating many {{engineering and}} physics {{processes in the}} building of an accelerator. Starting with the elements existing in the beam line optics files, the engineers add non-beam-line elements, and controls engineers assign ''Formal Device Names'' to these elements. Inventory, power supplies, <b>racks,</b> crates and <b>cable</b> plants are databases that are being integrated into the project database. This approach replaces individual spreadsheets and/or integrates standalone existing institutional databases...|$|R
25|$|Before flight, {{ground support}} {{equipment}} (GSE) supplies cooled, filtered ventilating air to the IU, entering via the large duct {{in the middle of}} the umbilical panel (location 7), and branching into two ducts at the top that are carried around the IU in the <b>cable</b> <b>rack.</b> Downward pointing vents from these ducts release ventilating air to the interior of the IU. During fueling, gaseous nitrogen was supplied instead of air, to purge any propellant gases that might otherwise accumulate in the IU.|$|R
50|$|On {{the summit}} of the {{mountain}} is the Wendelstein Chapel, an observatory, a weather station, a geopark and a transmission mast for the Bayerischer Rundfunk that can be seen from a long way off. About one hundred metres below the summit, on the ridge between the Wendelstein and the Schwaigerwand, lie the mountain inn, the termini of the <b>rack</b> railway and <b>cable</b> car, the service building for the mast, the former mountain hotel (above the station), a hut for the mountain rescue service and the well-known Wendelstein Church.|$|R
50|$|Cable {{ties are}} {{generally}} viewed as single-use devices; they are typically cut off rather than loosened and reused. However, if a closed loop {{needs to be}} opened again, rather than destroying the cable tie by cutting, {{it may be possible}} to release the ratchet from the <b>rack.</b> While some <b>cable</b> ties are designed for reuse with a tab that releases the ratchet, in most cases a sewing needle or similar object (for example a small screwdriver) will need to be interposed between the ratchet and the rack. Ties reused in this way will be weaker than new ones.|$|R
5000|$|Signals vehicle. Originally {{mounted on}} the QLC chassis/cab, special QLR chassis were soon put into production, which {{differed}} from the standard type in having special electrical equipment, radio suppression, fitment of a 660 W auxiliary generator driven by the transfer case power-take-off and, like the QLT, two 16 gallon petrol tanks instead of one behind the cab. The interior furniture, partitioning and radio equipment varied from the different functions. On vehicles installed for the wireless role, a tent could be erected at the rear. Between cab and man body were lockers for aerial masts and other equipment. Beneath the body were further lockers and <b>racks</b> for <b>cable</b> drums, batteries, tyre chains, 20 gallon drinking water tank, rectifier box, tools, fuel tank for the auxiliary engine, jerrycans and other items. The basic body shells were produced by Duple, Lagonda, Mulliner, Tickford and others. A revised body was introduced in during 1944 for the Command High and Low Power and Wireless High Power roles. This body had an improved [...] "L"-shaped tent which could be erected alongside the left-hand side and rear of the body.|$|R
50|$|The potline {{buildings}} were considered the longest buildings in Australiaat nearly a kilometer {{in length and}} requiring for each potline 7,300 tonnes of steel, 32,000 cubic meters of concrete and 75,000sq meters of roofing and siding, with 7500 tonnes of aluminium busbar each. First concrete was placed in March 1980, and first steel in June 1980. In November 1981 the site was connected to electricity at 132 kV. For the initial smelter there were 1,500,000 cu m of earthworks, 116,000 cu m of concrete, 20,000 tonnes of steel, 250,000 sq m of sheeting, 1,000 electric motors, 560 km of cables, 50 km of piping and 60 km of <b>cable</b> <b>racking.</b>|$|R
2500|$|On-stage theatrics {{included}} Ogre being {{suspended from}} <b>racks</b> and <b>cables,</b> {{play with a}} hangman's noose, Key cutting steel with an angle grinder, and mock executions of Ogre and George H.W. Bush. Following the 2004 Presidential Election in the United States, promoters began to ask the band to refrain from using fake blood during their performances. This reaction was prompted by {{the performance of a}} mock execution on stage, during which Ogre was decapitated by actors dressed as then U.S. President George W. Bush and Vice President Dick Cheney. The band was also asked by Samsung (who had been asked by Ogre to sponsor the band with a large flat screen) to [...] "not insult the president" [...] while performing on stage. In a 1987 television interview with Kim Clarke Champniss, Key explained that while Ogre follows a [...] "rough guideline" [...] during a live performance, a majority of his on-stage theatrics are thought up of spontaneously. Key told Champniss that Ogre's demeanor on stage could [...] "range from just a sort of laid back kind of lurking to a rampant psycho". Ogre once remarked that touring was, for himself, like [...] "dating hydrogen peroxide", referencing the numerous injuries which he would acquire over the course of touring.|$|R
40|$|In {{this paper}} we explore the design of "Do-It-Yourself" RAIDs: RAID systems that can {{assembled}} by the end user from commercially available disks, enclosures, <b>cables,</b> <b>racks,</b> computers, and networks. We quantitatively evaluate the tradeoffs in cost, performance, and reliability of these DIY-RAID systems. Our principal result is an architecture that scales from 10 s to 1000 s of disks; we demonstrate that a 1995 implementation would have much lower cost, better and more scalable performance, and roughly the same reliability as commercially available hardware RAID systems. Furthermore, if current trends continue, these DIY-RAIDs will replace near-line tape libraries within a few years. 1. Introduction Recently, a number of applications have emerged that require active use of very large storage systems. Examples include multimedia digital libraries, video on demand, and enterprise-wide decision support. To address this opportunity, {{a number of researchers}} are designing systems software to t [...] ...|$|R
5000|$|A new {{approach}} to the inter-rack cabling was taken. A false ceiling was built above {{the top of the}} <b>racks,</b> creating a <b>cable</b> loft. The cables were just pushed through holes in the cable loft and taken to where they were going by the shortest route. The holes were sealed after all the cables had been put in place, as a fire precaution. The result was a complete mess of a cable loft, but all cables were labelled; it was quicker and easier than the normal way of lacing all the cables. The exchange was housed in a prototype K-type single-story building having a special provision reinforced ceiling for the overhead cabling already mentioned. The construction included thermal insulation panels and double-glazing to minimise heat loss, and heating was by under-floor electrical heaters operated on off-peak supplies. Ventilation arrangements were by eight ventilating units, each handling 600 cu. ft. per min, and a series of [...] "hit-and-miss"-type louvers above the windows {{on each side of the}} building provided outlets for heated air.|$|R
40|$|Editor’s Note: This {{draft of}} the paper has been {{submitted}} to a conference. As we will revise the paper, please beware this is a working document and the information content will change. Given that you have requested {{a copy of this}} draft, we would be delighted to get your reactions and comments on how to improve the paper. (In fact, by asking for his early draft we hope you feel an obligation to send comments!) Please send them via email, fax, or US mail via the address above. In this paper we explore the design of “Do-It-Yourself ” RAIDs: RAID systems that can assembled by the end user from commercially available disks, enclosures, <b>cables,</b> <b>racks,</b> computers, and networks. We quantitatively evaluate the tradeoffs in cost, performance, and reliability of these DIY-RAID systems. Our principal result is an architecture that scales from 10 s to 1000 s of disks; we demonstrate that a 1995 implementation would have much lower cost, better and more scalable performance, and roughly the same reliability as commercially available hardware RAID systems. Furthermore, if current trends continue, these DIY-RAIDs will replace near-line tape libraries within a few years. 1...|$|R
40|$|NASA {{recently}} assembled {{one of the}} world's fastest operational supercomputers to {{meet the}} agency's new high performance computing needs. This large-scale system, named Columbia, consists of 20 interconnected SGI Altix 512 -processor systems, {{for a total of}} 10, 240 Intel Itanium- 2 processors. High-fidelity CFD simulations were performed for the NASA Advanced Supercomputing (NAS) computer room at Ames Research Center. The purpose of the simulations was to assess the adequacy of the existing air handling and conditioning system and make recommendations for changes {{in the design of the}} system if needed. The simulations were performed with NASA's OVERFLOW- 2 CFD code which utilizes overset structured grids. A new set of boundary conditions were developed and added to the flow solver for modeling the roomls air-conditioning and proper cooling of the equipment. Boundary condition parameters for the flow solver are based on cooler CFM (flow rate) ratings and some reasonable assumptions of flow and heat transfer data for the floor and central processing units (CPU). The geometry modeling from blue prints and grid generation were handled by the NASA Ames software package Chimera Grid Tools (CGT). This geometric model was developed as a CGT-scripted template, which can be easily modified to accommodate any changes in shape and size of the room, locations and dimensions of the CPU racks, disk racks, coolers, power distribution units, and mass-storage system. The compute nodes are grouped in pairs of racks with an aisle in the middle. High-speed connection <b>cables</b> connect the <b>racks</b> with overhead <b>cable</b> trays. The cool air from the cooling units is pumped into the computer room from a sub-floor through perforated floor tiles. The CPU cooling fans draw cool air from the floor tiles, which run along the outside length of each rack, and eject warm air into the center isle between the racks. This warm air is eventually drawn into the cooling units located near the walls of the room. One major concern is that the hot air ejected to the middle isle might recirculate back into the cool rack side and cause thermal short-cycling. The simulations analyzed and addressed the following important elements of the computer room: 1) High-temperature build-up in certain regions of the room; 2) Areas of low air circulation in the room; 3) Potential short-cycling of the computer rack cooling system; 4) Effectiveness of the perforated cooling floor tiles; 5) Effect of changes in various aspects of the cooling units. Detailed flow visualization is performed to show temperature distribution, air-flow streamlines and velocities in the computer room...|$|R

