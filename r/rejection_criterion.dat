42|124|Public
3000|$|Since D,I, and F {{data are}} involved, model {{estimation}} is a nonlinear optimization problem. We solve {{it with a}} Newton algorithm, using a L 2 measure of the data misfit together with a <b>rejection</b> <b>criterion.</b> We first build, starting from COV-OBS, an intermediate model rejecting data for which the residual magnitude is above 10 σ [...]...|$|E
40|$|This paper proposes an {{efficient}} three-stage classifier for handwritten digit recognition based on NN (Neural Network) and SVM (Support Vector Machine) classifiers. The classification is performed by 2 NNs and one SVM. The first NN {{is designed to}} provide a low misclassification rate using a strong <b>rejection</b> <b>criterion.</b> It is applied on a small set of easy to extract features. Rejected patterns are forwarded to the second NN that uses additional, more complex features, and utilizes a wellbalanced <b>rejection</b> <b>criterion.</b> Finally, rejected patterns from the second NN are forwarded to an optimized SVM that considers only the “top k ” classes as ranked by the NN. This way a very fast SVM classification is obtained without sacrificing the classifier accuracy. The obtained recognition rate is among the best on the MNIST database and the classification time is much better compared to the single SVM applied on the same feature set. 1...|$|E
40|$|Nonparametric {{support for}} two {{important}} hypotheses relevant to econometric model specification is examined. Results of various nonparametric tests for behavioural objective and aggregation level of Mexican agricultural production data are reported. The evidence does not refute {{the hypothesis that}} producers behave collectively {{as though they are}} a price-taking, profit-maximizing firm. The empirical results also support exhaustive aggregation of input categories. Aggregation possibilities among outputs are fewer and are highly sensitive to the <b>rejection</b> <b>criterion.</b> ...|$|E
40|$|We have {{developed}} a reject option for VQ-based supervised Bayesian classification to improve classification accuracy by sieving out patterns that are classified with a low confidence value. A small codebook extracted from a learning vector quantizer (LVQ) is used to estimate the class-conditional densities of the feature vector. We adapt the two commonly used <b>rejection</b> <b>criteria,</b> outlier <b>rejection</b> and ambiguity rejection, for the VQ-based Bayesian classifiers. Using three high-level image classification problems, we demonstrate how local <b>rejection</b> <b>criteria</b> can improve the error vs. reject characteristics of our classifier over a global rejection method...|$|R
5000|$|Level 1 are {{technicians}} {{qualified to}} perform only specific calibrations and tests under close supervision and direction by higher level personnel. They can only report test results. Normally they work following specific work instructions for testing procedures and <b>rejection</b> <b>criteria.</b>|$|R
50|$|When {{there is}} {{uncertainty}} whether a defect found during visual inspection meets the <b>rejection</b> <b>criteria,</b> additional tests may be applied, such as ultrasonic measurement of pitting wall thickness, or weight checks to establish total weight lost to corrosion. Hardness tests on aluminium cylinders are {{done on the}} cylindrical body and must avoid making deep impressions.|$|R
40|$|This paper {{proposes a}} Simulated Annealing variant for {{optimization}} problems {{in which the}} solution quality can only be estimated by sampling from a random distribution. The aim is to nd the solution with the best expected performance, as for example is typical for problems where solutions are evaluated using a stochastic simulation. Assuming Gaussian noise with known standard deviation, we derive a fully sequential sampling procedure and decision rule. The procedure starts with a single sample {{of the value of}} a proposed move to a neighboring solution and then continues to draw more samples until it is able to make a decision to finally accept or reject the move. Under constraints of equilibrium detailed balance at each draw, we find a decoupling between the acceptance criterion and the choice of the <b>rejection</b> <b>criterion.</b> We derive a universally optimal acceptance criterion in the sense of maximizing the acceptance probability per sample, and thus the e ciency of the optimization process. We show that the choice of the move <b>rejection</b> <b>criterion</b> depends on expectations of possible alternative moves and propose a simple and practical (albeit more empirical) solution that still preserves detailed balance. An empirical evaluation shows that the resulting approach is indeed more efficient than several previously proposed Simulated Annealing variants. ...|$|E
40|$|To the Editor: The usual {{method for}} {{measuring}} p-aminobenzoic acid (PABA) in the PABA test for assessment of exocrine pancreatic function {{is that of}} Bratton and Marshall as modifIed by Smith et al. (1). This reaction is subject to inter-ference from aromatic aniines present in urine {{at the start of}} the test. Rejec-tion of testsisusual when these com-pounds, measured as PABA, are pres-ent in high concentration in an un-timed basal urine collection. Braganza et al. use a <b>rejection</b> <b>criterion</b> of 30 mgfL (2); we have used 10 mg/L (3, 4) ...|$|E
40|$|A {{sophisticated}} {{methodology of}} legal amount recognition {{based on the}} word segmentation hypotheses is introduced for automatic bank check processing. Word segmentation hypotheses are derived according to the grapheme level segmentation results of legal amount. Novel hybrid schemes of HMM-MLP classifiers are also introduced for producing the ordered legal word recognition results with reliable decision values. These values {{can be used for}} obtaining an optimal word segmentation path of over-segmentation hypotheses as well as an efficient <b>rejection</b> <b>criterion</b> of word recognition result. Simulation was performed with CENPARMI bank check database and shows quite encouraging results. 1...|$|E
40|$|It {{is always}} {{difficult}} {{to justify the}} rejection of a doubtful value {{from a series of}} measurements. Provided the total number of observations is large, a fluctuation of fairly large magnitude is tolerable in terms of its effect on the average. Objective <b>rejection</b> <b>criteria,</b> past and present, are reviewed and discussed. Peer reviewed: NoNRC publication: Ye...|$|R
40|$|In this paper, the {{cooperation}} of two feature families for handwritten digit recognition using a committee of Neural Network (NN) classifiers will be examined. Various cooperation schemes will be investigated and corresponding results will be presented. To improve the system reliability,we will upgrade the committee scheme using multistage classification based on rule-based and statistical cooperation. The rule-based cooperation enables an easy and efficient implementation of various <b>rejection</b> <b>criteria</b> while the statistical cooperation offers better possibility for fine-tuning of the recognition versus the reliability tradeoff. The final system has been implemented using rule-based reasoning with <b>rejection</b> <b>criteria</b> for classifier decision fusion and the generalized committee cooperation scheme for classification of the rejected digit patterns. The presented results show that we propose a successful approach for reliability control in committee classifier environment and indicate that a suitable cooperation of statistical and rule-based decision fusion is a promising approach in handwritten recognition systems...|$|R
40|$|See the {{editorial}} commentary by Rosenblatt on pages 979 – 80) Background. Examination of multiple stool specimens per patient {{to rule out}} parasitic infection continues to be recommended in the literature. Attractive alternatives have been proposed, such as examination of a single specimen, but data to support their use have been inconclusive. Methods. We reviewed the results of comprehensive stool ova and parasite examinations performed during a 1 -year period to determine the incremental value of examining 11 specimen. Next, we implemented <b>rejection</b> <b>criteria,</b> allowing analysis of only a single specimen in most cases, and studied {{the impact of the}} change by reviewing data from a subsequent year. Results. Prior to implementation of <b>rejection</b> <b>criteria,</b> 91 % of parasites were detected in the first specimen submitted, although many clinical evaluations (72 %) involved the submission of only 1 stool specimen. When at least 3 specimens were submitted, the sensitivity of examining the first in the series was 72 %. Even the latter sensitivity provides negative predictive values of ∼ 98 %, ∼ 97 %, ∼ 95 %, or ∼ 93 % when the prevalence of parasites among those tested is 5 %, 10 %, 15 %, or 20 %, respectively. Examination of additional specimens after examination of the first specimen that yielded a positive finding revealed previously undetected parasites in only 10 % of cases. After the application of <b>rejection</b> <b>criteria,</b> the parasite detection rate did not change significantly...|$|R
3000|$|We {{show the}} mean ratios (y/x) {{of the wind}} {{components}} for the zonal and meridional components of the 55  MHz (y) to 33.2  MHz (x) systems for completeness and ease of comparison with previous studies. These were calculated for each height bin using an outlier rejection scheme with a 2.5 standard deviation <b>rejection</b> <b>criterion</b> and only where x [...] 0. The results show a value consistently less than one. In addition to assuming zero error in one parameter, the mean ratio estimate is more susceptible {{to the influence of}} outliers than the regression method for determining g_ 0, so additional caution must be taken when using it as a metric.|$|E
40|$|International audienceIn this paper, {{we propose}} a {{comprehensive}} solution to 3 D human action recognition including feature extraction, classification, and multiple classifier combination. We effectively present two feature extraction methods, four {{different types of}} well-known classifiers, and four multiple classifier combination strategies including a specially designed belief based method. In order to enhance the recognition accuracy, we propose a new <b>rejection</b> <b>criterion</b> based on the conflict from the information sources: the classifier outputs. We test our method on the MSRAction 3 D dataset. Discarding examples using the conflict based criterion shows superior results than other combination approaches. Moreover this criterion allows choosing a tradeoff between the performance and rejection rate...|$|E
40|$|Abstract. Approximate Bayesian Computation {{encompasses}} {{a family of}} likelihood-free algorithms for performing Bayesian inference in models {{defined in terms of}} a generating mechanism. The different algorithms rely on simulations of some sum-mary statistics under the generative model and a <b>rejection</b> <b>criterion</b> that determines if a simulation is rejected or not. In this paper, I incorporate Approximate Bayesian Computation into a local Bayesian regression framework. Using an empirical Bayes approach, we provide a simple criterion for 1) choosing the threshold above which a simulation should be rejected, 2) choosing the subset of informative summary statistics, and 3) choosing if a summary statistic should be log-transformed or not...|$|E
50|$|When {{considering}} several hypotheses, {{the problem}} of multiplicity arises: the more hypotheses we check, the higher {{the probability of a}} Type I error (false positive). The Holm-Bonferroni method is one of many approaches that control the family-wise error rate (the probability that one or more Type I errors will occur) by adjusting the <b>rejection</b> <b>criteria</b> of each of the individual hypotheses or comparisons.|$|R
40|$|Light-pair {{corrections}} to small-angle Bhabha scattering {{have been}} computed in a realistic set-up for luminosity measurements at LEP. The effect of acollinearity and acoplanarity <b>rejection</b> <b>criteria</b> has been carefully analysed for typical calorimetric event selections. The {{magnitude of the}} correction, depending {{on the details of}} the considered set-up, is comparable with the present experimental error. Comment: 6 pages, LaTeX (elsart. sty), 4 tables, 1 figur...|$|R
50|$|The {{cylinder}} is inspected for dents, cracks, gouges, cuts, bulges, laminations {{and excessive}} wear, heat damage, torch or electric arc burns, and corrosion damage. The cylinder is also checked for illegible, incorrect or unauthorised permanent stamp markings, and unauthorised additions or modifications. If the cylinder exceeds the <b>rejection</b> <b>criteria</b> for these items it is unsuitable for further service {{and will be}} made permanently unserviceable.|$|R
40|$|This paper {{discusses}} {{the quality of}} surface finish when threading titanium-based alloy under dry condition. The quality of surface finish was studied at various cutting parameters and at the two extreme stages of the machining process, i. e. {{at the beginning and}} end of the process. The objective is to evaluate the effect of a worn-out tool on the quality of surface finish. PVD-coated carbide tools were used in this study. Experiments were conducted at two cutting speeds, 35 and 55 m/min, two depths of cut, 0. 2 and 0. 25 mm, and a constant pitch of 2. 0 mm. The tool wear and the quality of surface finish were inspected visually by microscope. The tool’s flank wear was measured gradually and machining was stopped when the flank wear reached the <b>rejection</b> <b>criterion</b> of 0. 3 mm. The microstructure beneath the machined surface was also evaluated. It was found that, at the beginning of machining, there was only a feed mark on the surface finish. When the machining was prolonged until the tools reached the <b>rejection</b> <b>criterion,</b> a bad surface finish was produced. Metal debris, surface cavities and a boundary crack were observed. Results show that machining with a worn-out tool can cause microstructure alteration beneath the machined surface. The selection of cutting parameters and monitoring of tool wear are crucial in order to obtain a good surface finish. Characterization of the surface finish with respect to the threading process under a dry condition would ultimately help in the development of suitable parameters for machining titanium-based alloys. Surface finish, microstructure, dry machining...|$|E
40|$|A {{new method}} is {{described}} that permits quickly and easily, a 2 -dimensional search for TeV gamma-ray sources over large fields of view (~ 6 °) with instruments utilising the imaging atmospheric Cerenkov technique. It employs as a background estimate, events normally rejected {{according to a}} cosmic-ray background <b>rejection</b> <b>criterion</b> based on image shape, but with reconstructed directions overlapping the source of interest. This so-called template background model is demonstrated using example data taken with the stereoscopic HEGRA System of Cerenkov Telescopes. Discussion includes comparisons with a conventional background estimate and limitations of the model. The template model is well suited {{to the search for}} point-like, moderately extended sources and combinations thereof, and compensates well for localised systematic changes in cosmic-ray background response...|$|E
40|$|This paper {{describes}} everal experiments combining {{natural language}} and acoustic onstraints o improve overall {{performance of the}} MIT VOYAGER spoken language system. This system cou-ples the SUMMIT speech recognition system with the TINA lan-guage understanding system to answer spoken queries about nav-igational assistance in the Cambridge, MA, area. The overall goal of our research is to combine acoustic, syntactic and seman-tic knowledge sources. Our first experiment showed improvement by combining acoustic score and parse probability normalized for number of terminals. Results were further improved {{by the use of}} an explicit <b>rejection</b> <b>criterion</b> based on normalized parse prob-abilities. The use of the combined parse/acoustic score, together with the <b>rejection</b> <b>criterion,</b> gave an improvement in overall score of more than 33 % on both training and test data, where score is defined as percent correct minus percent incorrect. Experiments on a fully integrated system which uses the parser to predict pos-sible next words to the recognizer are now underway. BACKGROUND The experiments that we report on in this paper repre-sent some initial steps in combining speech knowledge with syntactic and semantic knowledge. These experiments have been performed using the MIT VOYAGER system [10], which provides navigational ssistance for finding directions and lo-cations of various objects (e. g., hotels, restaurants, banks) in a geographic region (Cambridge, MA). VOYAGER, accepts spoken queries from untrained users and produces answers {{in the form of a}} map, written answers, and spoken output. The system has a vocabulary of some 320 words and handles questions, indirect questions, and various forms of interac-tive dialogue, including anaphoric reference and clarification dialogue. In this research, we have taken an incremental pproach to combining speech and language. First, we have explored how use of combined knowledge sources can influence the shape of the search space, by changing the overall scores as- 1 This research was supported by DARPA under Contract N 00014...|$|E
40|$|OBJECTIVES OF THE STUDY: The {{purpose of}} the thesis is to provide new {{evidence}} and address the partially lacking understanding of business angel decision-making. This thesis studies the issue by investigating both the investment <b>criteria</b> and the <b>rejection</b> <b>criteria</b> business angels use to decide whether an opportunity should advance beyond the initial screening stage to the due diligence. The study focuses on the pitch meetings, in which entrepreneurs try to sell their ideas and equity to business angels in exchange for capital. DATA: The unique hand-coded data on business angels is sourced from a TV show called the Dragons' Den. By analysing the latest two UK production seasons, I was able to observe the decision-making process of seven business angels, of which three were female. The total number of observed pitch meetings amounts to 129, which consists of 27 successful pitches and 102 declined ones. The empirical evidence of business angel <b>rejection</b> <b>criteria</b> is based on 241 rejection reason provided by the investors. The above-average sample size {{is considered to be}} reasonable in the area of studying business angel decision-making. RESULTS: The results suggest that business angels invest primarily in early stage or start-up companies seeking for expansion financing. In their investment decision-making, business angels place emphasis on the entrepreneur, product and financials and intend to add value by taking hands-on roles. On the other hand, the partially contradictory findings to prior literature suggest, that the most important <b>rejection</b> <b>criteria</b> are related to financials, product and market. My findings also suggest that the investor fit criteria and investors' gender is affecting the decision-making of business angels...|$|R
40|$|Abstract. Aiming at {{improving}} {{the reliability of}} a recognition system, this paper presents a novel SVM-based rejection measurement (SVMM) and voting based combination methods of multiple classifier system (MCS) for pattern rejection. Compared with the previous heuristic designed criteria, SVMM is more straight-forward and can make use of much more information from the training data. The voting based combination methods for rejection is a preliminary attempt to adopt MCS for rejection. Comparison of SVMM with other wellknown <b>rejection</b> <b>criteria</b> proves that it achieves the highest performance. Two different methods (structural modification and dataset re-sampling) are used to build MCSs. The basic classifier is the convolution neural network (CNN) which has achieved promising performances in numerous applications. Rejection based on MCS is then evaluated on MNIST and CENPARMI digit databases. Specifically, different <b>rejection</b> <b>criteria</b> (FRM, FTRM and SVMM) are individually combined with MCS for pattern rejection. Experimental results indicate that these combinations improve the rejection performance consistently and MCS built by dataset re-sampling works better than that with structural modification in rejection. ...|$|R
40|$|In pattern recognition, the {{reliability}} and the recognition accuracy of a classification system are of same importance, because even {{a small percentage of}} errors could cause a huge loss in real-life handwritten numeral recognition systems, like cheque-reading at financial institutions. 	Aiming at improving {{the reliability}} of recognition systems, this thesis presents two novel learning-based <b>rejection</b> <b>criteria</b> for single classifiers including SVM-based measurement (SVMM) and Area Under the Curve measurement (AUCM). 	Voting based combination methods of multiple classifier system (MCS) are also proposed for rejecting poor handwritten digits. Different <b>rejection</b> <b>criteria</b> (FRM, FTRM and SVMM) are individually combined with MCSs as weight parameters in voting. This method is then evaluated on three renowned databases including MNIST, CENPARMI and USPS. Experimental results indicate that these combinations improve the rejection performances consistently. To further improve the performance of the MCS based rejection method, specialist information has been integrated into the combination process by introducing a new confidence weight parameter. The best result on MNIST is obtained by the simpler one of the two proposed methods of deriving this parameter, which reaches 100...|$|R
40|$|This paper {{describes}} {{several experiments}} combining natural language and acoustic constraints to improve overall {{performance of the}} MIT VOYAGER spoken language system. This system cou-ples the SUMMIT speech recognition system with the TINA lan-guage understanding system to answer spoken queries about nav-igational assistance in the Cambridge, MA, area. The overall goal of our research is to combine acoustic, syntactic and seman-tic knowledge sources. Our first experiment showed improvement by combining acoustic score and parse probability normalized for number of terminals. Results were further improved {{by the use of}} an explicit <b>rejection</b> <b>criterion</b> based on normalized parse prob-abilities. The use of the combined parse/acoustic score, together with the <b>rejection</b> <b>criterion,</b> gave an improvement in overall score of more than 33 % on both training and test data, where score is defined as percent correct minus percent incorrect. Experiments on a fully integrated system which uses the parser to predict pos-sible next words to the recognizer are now underway. BACKGROUND The experiments that we report on in this paper repre-sent some initial steps in combining speech knowledge with syntactic and semantic knowledge. These experiments have been performed using the MIT VOYAGER system [10], which provides navigational assistance for finding directions and lo-cations of various objects (e. g., hotels, restaurants, banks) in a geographic region (Cambridge, MA). VOYAGER, accepts spoken queries from untrained users and produces answers {{in the form of a}} map, written answers, and spoken output. The system has a vocabulary of some 320 words and handles questions, indirect questions, and various forms of interac-tive dialogue, including anaphoric reference and clarification dialogue. In this research, we have taken an incremental approach to combining speech and language. First, we have explored how use of combined knowledge sources can influence the shape of the search space, by changing the overall scores as...|$|E
40|$|A {{recent article}} (Pavelescu, 2009) proposes a {{correction}} {{to the conventional}} student-t test of significance in linear regression models, but offers no formal description of its properties. This comment formally characterizes the sampling properties of the corrected student-t statistic. In application to multifactorial regressions, {{it turns out that}} the corrected student-t statistic is not ancillary – its sampling distribution depends on unknown nuisance parameters. Therefore, it is impossible to reasonably compute critical values and operatively designate a <b>rejection</b> <b>criterion</b> using such a test statistic, which makes the proposed testing procedure impractical. Some suggestions regarding the search for similar testing procedures are proposed and a Bayesian alternative is further discussed. multifactorial classical normal regression, collinearity, multicollinearity, significance test, sampling distributions, power functions, Bayesian linear regression, prior information, posterior distributions...|$|E
40|$|International audienceThis paper {{describes}} {{the participation of}} Inria IMEDIA 2 Team, within the Pl@ntNet project 4, at the ImageCLEF 2012 plant identi cation task. The runs used very distinct approaches, sometimes relying on similar extracted features. For Scan and Scan-like categories, the rst two runs combine distinct local and contour approaches in two ways (late and early fusion), while the third run explores the learning capacity of a multi-class SVM technique on a contour based descriptor. For Photo- graph our runs used local features positioned towards {{the center of the}} image to reduce the impact of background features. In the second run, an automatic segmentation with a <b>rejection</b> <b>criterion</b> was attempted. In the third run, points were associated with interesting zones. In general, even if they were distinct, the methods used performed very well...|$|E
40|$|Introduction: The {{emergency}} {{laboratory in}} Hacettepe University Hospitals receives specimens from emergency departments (EDs), inpatient servi-ces and intensive care units (ICUs). The samples are accepted {{according to the}} <b>rejection</b> <b>criteria</b> of the laboratory. In this study, we aimed to evaluate the sample rejection ratios according to the types of pre-preanalytical errors and collection areas. Materials and methods: The samples sent to the emergency laboratory were recorded during 12 months between January to December, 2013 i...|$|R
40|$|Igwebuike V Onyiaorah, 1 Cornelius O Ukah, 1 Daniel CD Anyiam, 1 Maxy AC Odike, 1 Ikewelugo CA Oyeka 21 Department of Histopathology, Nnamdi Azikiwe University/Teaching Hospital, Nnewi, Anambra State, Nigeria; 2 Department of Statistics, Nnamdi Azikiwe University, Awka, Anambra State, NigeriaAims: This study {{sought to}} analyze the effect of three {{remedial}} measures, namely, hiring more pathologists, increasing the frequency of clinicopathologic conferences, and stepwise {{increase in the level}} of <b>rejection</b> <b>criteria,</b> on the adequacy of laboratory request form completion by clinicians. Based on the findings, recommendations were made that may reduce rejection rate of specimens and facilitate histopathology investigations. Methods: This is a retrospective study covering a period of 7 years (2004 &ndash; 2010). Data were retrieved from histopathology laboratory request forms submitted to three laboratories in Eastern Nigeria. These data were entered in SPSS statistical software and were analyzed using simple linear regression analysis. Results: A total of 8573 completed and submitted forms were analyzed, out of which 74. 7 % were found to be inadequately completed. The effect of increasing the number of pathologists in the employ on the adequacy of laboratory request form completion was found not to be statistically significant. Similarly, change in the frequency of clinicopathologic conferences was also found not to significantly affect the adequacy of laboratory form completion. However, change in the aggregated level of <b>rejection</b> <b>criteria</b> used by the laboratories was found to significantly affect the clinician&# 39;s compliance to laboratory request form completion. For every 1 unit increase (or decrease) in the level of <b>rejection</b> <b>criteria</b> used there was, on the average, a 4. 7 % increase (or decrease) in the proportion of adequately completed laboratory request forms submitted. Conclusion: The findings highlight the need to enforce and implement policies that would possibly enhance compliance with the requirements of laboratory request form completion. Keywords: clinicopathologic conference, rejection criteri...|$|R
40|$|This paper {{addresses}} two of {{the measurement}} specifications used in analyzing spent fuel packages to gain burnup credit. The philosophy and calculation of <b>rejection</b> <b>criteria</b> and measurement accuracy are discussed. Any assembly for which the declared measured value and reactor record value deviate by more than 10 % will be rejected. Measurement accuracy requirements are established for dependent and independent systems. The requirements have been tested and are achievable, ensuring safe operation without extra cost. 6 refs...|$|R
40|$|The {{acidification}} power test {{provides a}} fast and simple method of assessing {{the ability of}} cells to perform a successful fermentation. It {{has been used as}} a <b>rejection</b> <b>criterion</b> for assessing the technological quality of starter yeast cultures in brewing, cider production, baking, as well as cheese making based on lactic acid bacteria. The cell acidification power responses to pH decrease of the environment after glucose addition. We have prepared novel recognition elements of pH sensors suitable for evaluation of yeast acidification power by absorption of two pH sensitive sulfonphthalein dyes (bromocresol green and bromophenol blue) into hydrogel of poly(2 -hydroxyethyl methacrylate-co-ethylene dimethacrylate). The absorption spectra, function ranges, pKa values, and response times for each absorbed dye were evaluated, compared with the free dyes, and further discussed with regard to its application to the acidification power test...|$|E
40|$|BackgroundAbout {{a decade}} ago, {{the concept of}} rotamer {{libraries}} was introduced to model sidechains given known mainchain coordinates. Since then, several groups have developed methods to handle the challenging combinatorial problem that is faced when searching rotamer libraries. To avoid a combinatorial explosion, the dead-end elimination method detects and eliminates rotamers that cannot be members of the global minimum energy conformation (GMEC). Several groups have applied and further developed this method {{in the fields of}} homology modelling and protein design. ResultsThis work addresses at the same time increased prediction accuracy and calculation speed improvements. The proposed enhancements allow the elimination of {{more than one-third of the}} possible rotameric states before applying the dead-end elimination method. This is achieved by using a highly detailed rotamer library allowing the safe application of an energy-based <b>rejection</b> <b>criterion</b> without risking the elimination of a GMEC rotamer. As a result, we gain both in modelling accuracy and in computational speed. Being completely automated, the current implementation of the dead-end elimination prediction of protein sidechains can be applied to the modelling of sidechains of proteins of any size on the high-end computer systems currently used in molecular modelling. The improved accuracy is highlighted in a comparative study on a collection of proteins of varying size for which score results have previously been published by multiple groups. Furthermore, we propose a new validation method for the scoring of the modelled structure versus the experimental data based upon the volume overlap of the predicted and observed sidechains. This overlap criterion is discussed in relation to the classic RMSD and the frequently used ± 40 ° window in comparing χ 1 and χ 2 angles. ConclusionWe have shown that a very detailed library allows the introduction of a safe energy threshold <b>rejection</b> <b>criterion,</b> thereby increasing both the execution speed and the accuracy of the modelling program. We speculate that the current method will allow the sidechain prediction of medium-sized proteins and complex protein interfaces involving up to 150 residues on low-end desktop computers...|$|E
40|$|Preconditioning {{techniques}} {{based on}} incomplete Cholesky factorization are very efficient in increasing the convergence rates of basic iterative methods. Complicated addressings and high demands for auxiliary storage, or increased factorization time, have reduced their appeal as general purpose preconditioners. In this study an elegant computational implementation is presented which succeeds in reducing both computing storage and factorization time. The proposed implementation {{is applied to}} two incomplete factorization schemes. The first {{is based on the}} rejection of certain terms according to their magnitude, while the second is based on a <b>rejection</b> <b>criterion</b> relative to the position of the zero terms of the coefficient matrix. Numerical results demonstrate the superiority of the proposed preconditioners over other types of preconditioning matrices, particularly for ill-conditioned problems. They also show their efficiency for large-scale problems in terms of computer storage and CPU time, over a direct solution method using the skyline storage scheme. © 1994...|$|E
3000|$|... c 5 ++ {{eliminates}} outlier delay values {{within a}} session {{according to a}} 3 -sigma criteria. Additionally, in order to eliminate crude outliers, we used for all analysis runs a <b>rejection</b> <b>criteria</b> of 1000 μs and 50 μs for the absolute values of UT 1 -UTC residuals and corresponding formal errors, respectively, for each session. To ensure robustness, only sessions which appear in all configurations after the outlier elimination {{were included in the}} comparison of the results from different setups.|$|R
40|$|This paper {{presents}} a coin recognition system based completely {{on the direction}} of the gradient vectors. To optimally align two coins we search for a rotation such that as most as possible corresponding gradient vectors point into the same direction. After discretizing the gradient directions this can be done quickly by the use of the Fast Fourier Transform. The classification is done by a simple nearest neighbor search followed by several <b>rejection</b> <b>criteria</b> to meet the demand of a low false positive rate. ...|$|R
40|$|Abstract—In {{this paper}} we give an {{overview}} of our work on an asynchronous BCI (where the subject makes self-paced decisions on when to switch from one mental task to the next) that responds every 0. 5 seconds. A local neural classifier tries to recognize three different mental tasks; it may also respond “unknown ” for uncertain samples as the classifier has incorporated statistical <b>rejection</b> <b>criteria.</b> We report our experience with 15 subjects. We also briefly describe two brainactuated applications we have developed: a virtual keyboard and a mobile robot (emulating a motorized wheelchair) ...|$|R
