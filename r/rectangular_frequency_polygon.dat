0|103|Public
40|$|A {{piecewise}} linear competitor to the <b>frequency</b> <b>polygon,</b> the edge <b>frequency</b> <b>polygon,</b> is proposed: instead of joining histogram ordinates at midpoints of bins by straight lines, one connects values at bin edges by straight lines, those values being averages of contiguous histogram ordinates. The new proposal {{is as simple}} and interpretable as the ordinary <b>frequency</b> <b>polygon</b> while holding theoretical and practical advantages...|$|R
40|$|The {{purpose of}} this paper is to {{investigate}} the <b>frequency</b> <b>polygon</b> as a density estimator for stationary strong mixing processes. Optimal bin widths which asymptotically minimize integrated mean square errors (IMSE) are derived. Under weak conditions, <b>frequency</b> <b>polygons</b> achieve the same rate of convergence to zero of the IMSE as kernel estimators. They can also attain the optimal uniform rate of convergence ((n- 1 logn) 1 / 3 under general conditions. <b>Frequency</b> <b>polygons</b> thus appear to be very good density estimators with respect to both criteria of IMSE and uniform convergence. Density estimation Mixing process Bin width <b>Frequency</b> <b>polygons...</b>|$|R
40|$|Jones et al. (Biometrica 85, 235) {{proposed}} an edge <b>frequency</b> <b>polygon</b> estimator to estimate a probability density function. Their estimator has a smaller asymptotic mean integrated squared error {{than that of}} the <b>frequency</b> <b>polygon</b> estimator. In this paper we introduce a generalized edge <b>frequency</b> <b>polygon</b> estimator. Instead of averaging heights of two bins at each bin edge, we take weighted averages of the heights in the neighboring 2 k (k[greater-or-equal, slanted] 1) bins, which further reduces the asymptotic mean integrated squared error. Density estimation Histogram Integrated squared error...|$|R
30|$|As {{pointed out}} by Scott [5], the <b>frequency</b> <b>polygon</b> has {{convergence}} rates {{similar to those of}} kernel density estimators and greater than the rate for a histogram. As for computation, the computational effort of the <b>frequency</b> <b>polygon</b> is equivalent to the one of the histogram. For large bivariate data sets, the computational simplicity of the <b>frequency</b> <b>polygon</b> and the ease of determining exact equiprobable contours may outweigh the increased accuracy of a kernel density estimator. Bivariate contour plots based on millions of observations are increasingly required in applications including high-energy physics simulation experiments, cell sorters and geographical data representation. Moreover, such data are usually collected in a binned form. Therefore, the <b>frequency</b> <b>polygon</b> can be a useful tool for examination and presentation of data. Since the <b>frequency</b> <b>polygon</b> has the advantages mentioned above, it attracts the attention of some scholars, and they have derived some results. For the explicit results obtained, one can refer to the references listed in Yang and Liang [6] and Xing et al. [7], which gave the strong consistency of <b>frequency</b> <b>polygons.</b> Among the obtained results, the study on asymptotic normality can be found in Carbon et al. [8]. The relevant Berry-Esséen bound for ϕ-mixing samples has not been seen. This motivates us to investigate the Berry-Esséen bound of <b>frequency</b> <b>polygon</b> under ϕ-mixing samples. Under the given assumptions, we give the corresponding Berry-Esséen bound. Furthermore, by the obtained Berry-Esséen bound, the relevant convergence rate of uniformly asymptotic normality is also derived, which is nearly O(n^- 1 / 6) under the given conditions.|$|R
40|$|Statistical {{computing}} when input/output {{is driven}} by a Graphical User Interface is considered. A proposal is made for automatic control of computational flow to ensure that only strictly required computations are actually carried on. The computational flow is modeled by a directed graph for implementation in any object-oriented programming language with symbolic manipulation capabilities. A complete implementation example is presented to compute and display frequency based piecewise linear density estimators such as histograms or <b>frequency</b> <b>polygons.</b> Histogram, <b>frequency</b> <b>polygon,</b> bin width, object oriented programming, interactive graphics, statistical computing...|$|R
30|$|Under some mild assumptions, the Berry-Esséen bound of <b>frequency</b> <b>polygons</b> for ϕ-mixing samples is presented. By the bound derived, we {{obtain the}} {{corresponding}} convergence rate of uniformly asymptotic normality, which is nearly O(n^- 1 / 6) under the given conditions.|$|R
40|$|This paper {{establishes}} the asymptotic normality of <b>frequency</b> <b>polygons</b> {{in the context}} of stationary strongly mixing random fields indexed by ^d. Our method allows us to consider only minimal conditions on the width bins and provides a simple criterion on the mixing coefficients. In particular, we improve in several directions a previous result by Carbon, Francq and Tran (2010) ...|$|R
40|$|We {{introduce}} simple nonparametric density estimators that generalize {{the classical}} histogram and <b>frequency</b> <b>polygon.</b> The new estimators are expressed as linear combination of density functions that are piecewise polynomials, where the coe#cients are optimally chosen {{in order to}} minimize the integrated square error of the estimator. We establish the asymptotic behaviour of the proposed estimators, and study their performance in a simulation study...|$|R
50|$|The {{continuous}} Fourier transform of the normalized sinc (to ordinary frequency) is ,where {{the rectangular}} function is 1 for argument between − and , and zero otherwise. This {{corresponds to the}} fact that the sinc filter is the ideal (brick-wall, meaning <b>rectangular</b> <b>frequency</b> response) low-pass filter.|$|R
40|$|We {{introduce}} nonparametric density estimators that generalize {{the classical}} histogram and <b>frequency</b> <b>polygon.</b> The new estimators are expressed as linear combinations of density functions that are piecewise polynomials, where the coefficients are optimally chosen {{in order to}} minimize an approximate version of the integrated square error of the estimator. We establish the asymptotic behaviour of the proposed estimators, and study their performance in a simulation study...|$|R
40|$|This report {{presents}} ViSta-ANOVA, the ViSta {{procedure for}} performing analysis of variance. This procedure {{is capable of}} analyzing balanced or unbalanced, complete (i. e., every cell must have at least 1 observation) n-way data for main effects and two-way interactions. ViSta-ANOVA’s unique visualization includes a box, diamond, and dot plot; a <b>frequency</b> <b>polygon</b> and histogram; a profile plot; a residual plot; and a partial regression plot. ...|$|R
40|$|We {{contribute}} {{to the study of}} data binning in density estimation. The particular disadvantage of histograms due to the effect of bin edge placement is stressed (again). We investigate how simple methods, both existing (such as the <b>frequency</b> <b>polygon)</b> and novel (proposing other natural piecewise linear adaptations), improve on the basic histogram (and on each other). Lurking in the background throughout are links with kernel density estimation...|$|R
50|$|MSK and GMSK are {{particular}} cases of continuous phase modulation. Indeed, MSK {{is a particular}} case of the sub-family of CPM known as continuous-phase frequency shift keying (CPFSK) which is defined by a <b>rectangular</b> <b>frequency</b> pulse (i.e. a linearly increasing phase pulse) of one-symbol-time duration (total response signaling).|$|R
40|$|The <b>frequency</b> <b>polygon</b> is not {{compatible}} with the given frequency distribution {{in the sense that}} the areas within the classes are not proportional to the frequencies. As a consequence, the polygon is too flat. Therefore, an alternative polygon is constructed as a continuous version of the histogram by area-matching within each class. The result is a useful tool for visualizing frequency distributions, which is continuous, {{compatible with}} the frequencies and easy to understand...|$|R
40|$|Abstract – Nonparametric density {{estimation}} {{is considered}} for a discretely observed stationary continuous-time process. For each of three given time sampling procedures either random or deterministic, we establish that histograms and <b>frequency</b> <b>polygons</b> can reach the same optimal L 2 -rates as in the independent and identically distributed case. Moreover, thanks to a suitable “high frequency ” sampling design, these rates are derived together with a minimized time of observation depending on the regularity of sample paths...|$|R
40|$|Statistical {{computing}} when input/output {{is driven}} by a Graphical User Interface is considered. A proposal is made for automatic control of computational flow to ensure that only strictly required computations are actually carried on. The computational flow is modeled by a directed graph for implementation in any object-oriented programming language with symbolic manipulation capabilities. A complete implementation example is presented to compute and display frequency based piecewise linear density estimators such as histograms or <b>frequency</b> <b>polygons.</b> ...|$|R
40|$|Barron-type estimators are histogram-based {{distribution}} estimators {{that have}} been proved to have good consistency properties according to several information theoretic criteria. However they are not continuous. In this paper, we examine {{a new class of}} continuous distribution estimators obtained as a combination of Barron-type estimators with the <b>frequency</b> <b>polygon.</b> We prove the consistency of these estimators in expected information divergence and expected chi(2) -divergence. For one of them we evaluate the rate of convergence in expected chi(2) -divergence. status: publishe...|$|R
40|$|AbstractWe {{construct}} a simple algorithm, based on Newton's method, which permits asymptotic minimization of L 1 distance for nonparametric density estimators. The technique is applicable to multivariate kernel estimators, multivariate histogram estimators, and smoothed histogram estimators such as <b>frequency</b> <b>polygons.</b> It has an “adaptive” or “data-driven” version. We show theoretically that both theoretical and adaptive {{forms of the}} algorithm do indeed minimize asymptotic L 1 distance. Then we apply the algorithm to derive concise formulae for asymptotically optimal smoothing parameters. We also give numerical examples of applications of the adaptive algorithm...|$|R
40|$|Normal {{values have}} been {{established}} for haemoglobin and plasma calcium, inorganic phosphate, magnesium, iron and copper {{in the blood of}} Angora goats maintained in the Cape Midlands of South Africa. With the exception of the values obtained for haemoglobin, the data collected for these determinations present slightly to considerably skewed distribution curves. Normal values {{have been established}} by using cumulative relative <b>frequency</b> <b>polygons</b> constructed from these data. The journals have been scanned in colour with a HP 5590 scanner; 600 dpi. Adobe Acrobat v. 11 was used to OCR the text and also for the merging and conversion to the final presentation PDF-format...|$|R
40|$|We {{construct}} a simple algorithm, based on Newton's method, which permits asymptotic minimization of L 1 distance for nonparametric density estimators. The technique is applicable to multivariate kernel estimators, multivariate histogram estimators, and smoothed histogram estimators such as <b>frequency</b> <b>polygons.</b> It has an "adaptive" or "data-driven" version. We show theoretically that both theoretical and adaptive {{forms of the}} algorithm do indeed minimize asymptotic L 1 distance. Then we apply the algorithm to derive concise formulae for asymptotically optimal smoothing parameters. We also give numerical examples of applications of the adaptive algorithm. asymptotic optimality histogram estimator kernel estimator L 1 distance nonparametric density estimator...|$|R
40|$|We study {{piecewise}} linear density estimators from the L- 1 point of view: the <b>frequency</b> <b>polygons</b> investigated by SCOTT (1985) and JONES et al. (1997), {{and a new}} {{piecewise linear}} histogram. In contrast to the earlier proposals, a unique multivariate generalization of the new piecewise linear histogram is available. All these estimators are shown to be universally L- 1 strongly consistent. We derive large deviation inequalities. For twice differentiable densities with compact support their expected L- 1 error is shown {{to have the same}} rate of convergence as have kernel density estimators. Some simulated examples are presented. status: publishe...|$|R
40|$|The {{variance}} reduction {{established by}} importance sampling strongly {{depends on the}} choice of the importance sampling distribution. A good choice is often hard to achieve especially for high-dimensional integration problems. Nonparametric estimation of the optimal importance sampling distribution (known as nonparametric importance sampling) is a reasonable alternative to parametric approaches. In this article nonparametric variants of both the self-normalized and the unnormalized importance sampling estimator are proposed and investigated. A common critique on nonparametric importance sampling is the increased computational burden compared to parametric methods. We solve this problem to a large degree by utilizing the linear blend <b>frequency</b> <b>polygon</b> estimator instead of a kernel estimator. Mean square error convergence properties are investigated leading to recommendations for the efficient application of nonparametric importance sampling. Particularly, we show that nonparametric importance sampling asymptotically attains optimal importance sampling variance. The efficiency of nonparametric importance sampling algorithms heavily relies on the computational efficiency of the employed nonparametric estimator. The linear blend <b>frequency</b> <b>polygon</b> outperforms kernel estimators in terms of certain criteria such as efficient sampling and evaluation. Furthermore, it is compatible with the inversion method for sample generation. This allows to combine our algorithms with other variance reduction techniques such as stratified sampling. Empirical evidence for the usefulness of the suggested algorithms is obtained by means of three benchmark integration problems. As an application we estimate the distribution of the queue length of a spam filter queueing system based on real data. Comment: 29 pages, 7 figure...|$|R
40|$|OBJECTIVES: This study {{explains}} why <b>frequency</b> <b>polygons</b> for US birthweights in 100 -g weight classes appear spiky {{compared with their}} European counterparts. METHODS: A probability model is used to describe how unit conversion can induce misclassification. Birthweights from the United States and Norway are used to illustrate that misclassification operates in grouped US data. RESULTS: Spikiness represents misclassification that arises when measured birthweights are rounded to the nearer ounce, converted to grams, and then grouped into weight classes. Misclassification is ameliorated, not eliminated, with 200 -g weight classes. CONCLUSIONS: Possible biases from misclassification should be carefully evaluated when fitting statistical models to grouped US birthweights...|$|R
40|$|The {{variance}} reduction {{established by}} importance sampling strongly {{depends on the}} choice of the importance sampling distribution. A good choice is often hard to achieve especially for high-dimensional integration problems. Nonparametric estimation of the optimal importance sampling distribution (known as ‘‘nonparametric importance sampling’’) is a reasonable alternative to parametric approaches. In this article, nonparametric variants of both the self-normalized and the unnormalized importance sampling estimator are proposed and investigated. A common critique of nonparametric importance sampling is the increased computational burden compared with parametric methods. We solve this problem to a large degree by utilizing the linear blend <b>frequency</b> <b>polygon</b> estimator instead of a kernel estimator. Mean square error convergence properties are investigated, leading to recommendations for the efficient application of nonparametric importance sampling. Particularly, we show that nonparametric importance sampling asymptotically attains optimal importance sampling variance. The efficiency of nonparametric importance sampling algorithms relies heavily on the computational efficiency of the nonparametric estimator used. The linear blend <b>frequency</b> <b>polygon</b> outperforms kernel estimators in terms of certain criteria such as efficient sampling and evaluation. Furthermore, it is compatible with the inversion method for sample generation. This allows one to combine nonparametric importance sampling with other variance reduction techniques such as stratified sampling. Empirical evidence for the usefulness of the suggested algorithms is obtained by means of three benchmark integration problems. We show empirically that these methods may work in higher dimensions, at least up to dimension eight. As an application, we estimate the distribution of the queue length of a spam filter queuing system based on real data...|$|R
40|$|Abstract. E cient {{variance}} {{reduction is}} crucial to Monte Carlo simulation based derivative pricing. Importance sampling {{is one of the}} most promising approaches for variance reduction but typically neither the optimal importance sampling distribution itself nor a reliable approximation is available. We suggest an algorithm that applies a multivariate <b>frequency</b> <b>polygon</b> to estimate the optimal importance sampling distribution nonparametrically. Nonparametric importance sampling is ine cient in high-dimensional problems due to the curse of dimensionality. We tackle this problem by restricting our procedure to a low-dimensional subspace. We apply Quasi Monte Carlo techniques for the further improvement of our method. We demonstrate our method's potential to reduce Monte Carlo variance through path-dependent and multi-asset option pricing problems...|$|R
40|$|The {{earliest}} {{reference to}} the fecundity of the Indian mackerel was by Devanesan and John (1940) who estimated the number of ripe eggs in the mackerel ovary as 94, 000. Subsequent work was directed mostly towards finding out the spawning behaviour of this fish, by {{the study of the}} intra-ovarian eggs. Pradhan (1956) indicated the possibility of the Indian mackerel spawning the eggs in successive batches over a prolonged period, like its Atlantic counter-part Scomber scombrus (L). Pradhan and Palekar (1956) described the maturity stages I to VII, based on the external appearance of the ovary, its size relative to the abdominal cavity, and the range of ova-diameter readings. However, they have not given any ova-diameter <b>frequency</b> <b>polygons...</b>|$|R
40|$|The {{variance}} reduction {{established by}} importance sampling strongly {{depends on the}} choice of the importance sampling distribution. A good choice is often hard to achieve especially for high-dimensional integration problems. Nonparametric estimation of the optimal importance sampling distribution (known as nonparametric importance sampling) is a reasonable alternative to parametric approaches. A common critique on nonparametric importance sampling is the increased computational burden compared to parametric methods. We solve this problem to a large degree by utilizing a multivariate <b>frequency</b> <b>polygon</b> instead of a kernel estimator. Mean square error convergence properties are investigated leading to recommendations for the efficient application of nonparametric importance sampling. Empirical evidence for the usefulness of the suggested algorithms is obtained by means of three benchmark integration problems including an option pricing example...|$|R
5000|$|... #Caption: The <b>rectangular</b> function, the <b>frequency</b> {{response}} of the sinc filter.|$|R
40|$|Statistical {{computing}} when input/output {{is driven}} by a Graphical User Interface is considered. A proposal is made for automatic control of computational flow to ensure that only strictly required computations are actually carried on. The computational flow is modeled by a directed graph for implementation in any object-oriented programming language with symbolic manipulation capabilities. A complete implementation example is presented to compute and display frequency based piecewise linear density estimators such as histograms or <b>frequency</b> <b>polygons.</b> JEL clasification: C 10; C 13; C 43. Keywords: Histogram; Frequencypolygon; Bin width; Object oriented programming; Interactive graphics; Statistical computing. 2 1 Introduction Controlling computation flow in classical programs is not a difficult task: some conditional or case statements would do the job in most cases. When user interaction is needed, the program prompts for it, then it waits for an answer, processes the respons [...] ...|$|R
40|$|Statistical {{computing}} when input/output {{is driven}} by a Graphical User Interface is considered. A proposal is made for automatic control of computational flow to ensure that only strictly required computations are actually carried on. The computational flow is modeled by a directed graph for implementation in any object-oriented programming language with symbolic manipulation capabilities. A complete implementation example is presented to compute and display frequency based piecewise linear density estimators such as histograms or <b>frequency</b> <b>polygons.</b> Controlling computation flow in classical programs is not a difficult task: some conditional or case statements would do the job in most cases. When user interaction is needed, the program prompts for it, then it waits for an answer, processes the response and produces output. If we consider statistical computing in a graphical user interface (GUI) environment, things are very different. The user can decide at any moment to change [...] ...|$|R
40|$|Kalman-Yakubovich-Popov (KYP) lemma {{has played}} a {{significant}} role in one-dimensional systems theory. However, there has been no two-dimensional (2 -D) KYP lemma in the literature, even for the infinite frequency domain. This paper develops a generalized KYP lemma for 2 -D systems described by discrete Roesser model. The generalized KYP lemma relates frequency-domain properties of the 2 -D system, such as positive realness and bounded realness over any given <b>rectangular</b> <b>frequency</b> domain, to a linear matrix inequality, enabling efficient computation for both the analysis and the design. As special cases of the lemma, 2 -D bounded realness and positive realness are investigated. Numerical examples on the design of 2 -D digital filters are given to demonstrate the relevance of the lemma...|$|R
5000|$|For example, in {{the case}} of a <b>rectangular</b> room, low <b>frequency</b> modes are {{determined}} relative to the room dimensions as ...|$|R
40|$|Abstract. Importance {{sampling}} is {{a promising}} variance reduction technique for Monte Carlo simulation based derivative pricing. Existing importance sampling methods {{are based on}} a parametric choice of the proposal. This article proposes an algorithm that estimates the optimal proposal nonparametrically using a multivariate <b>frequency</b> <b>polygon</b> estimator. In contrast to parametric methods, nonparametric estimation allows for close approximation of the optimal proposal. Standard nonparametric importance sampling is inefficient for highdimensional problems. We solve this issue by applying the procedure to a low-dimensional subspace, which is identified through principal component analysis and the concept of the effective dimension. The mean square error properties of the algorithm are investigated and its asymptotic optimality is shown. Quasi-Monte Carlo is used for further improvement of the method. It is easy to implement, particularly it does not require any analytical computation, and it is computationally very efficient. We demonstrate through path-dependent and multi-asset option pricing problems that the algorithm leads to significant efficiency gains compared to other algorithms in the literature...|$|R
5000|$|The {{window is}} {{cylindrical}} with the height equal {{to one and}} the base equal to 2a. The vertical cross-section of this window is a 1-D <b>rectangular</b> window.The <b>frequency</b> response of the window after substituting the window function as defined above, using the Hankel transform, is as shown below ...|$|R
40|$|We {{investigate}} the polarization state dynamics of single photon pulse for optical fiber quantum communication channels. On {{the basis of}} a birefringence vector model in which amplitude and direction are both stochastic variables, Jones vector is obtained by solving the frequency domain wave equation. The fidelity of output quantum state and degree of polarization of the pulse are also obtained from the density operators. It is shown that the fidelity of quantum state decreases quickly and tends to a stable value along optical fiber, and increases for larger mean fluctuation magnitude of the stochastic fiber birefringence. Degree of polarization is nearly constant for small mean fluctuation magnitude of the birefringence. The fidelity and degree of polarization vary in the same way for Gaussian and <b>rectangular</b> <b>frequency</b> spectrum envelope, while the value of Lorentzian spectrum is smaller. Comment: Any comment is welcom...|$|R
40|$|We {{study the}} problem of {{estimating}} the Schwarzschild radius of a massive body using Gaussian quantum probe states. Previous calculations assumed that the probe state remained pure after propagating a large distance. In a realistic scenario, there would be inevitable losses. Here we introduce a practical approach to calculate the Quantum Fisher Informations (QFIs) for a quantum probe that has passed through a lossy channel. Whilst for many situations loss means coherent states are optimal, we identify certain situations for which squeezed states have an advantage. We also study {{the effect of the}} frequency profile of the wavepacket propagating from Alice to Bob. There exists an optimal operating point for a chosen mode profile. In particular, employing a smooth <b>rectangular</b> <b>frequency</b> profile significantly improves the error bound on the Schwarzschild radius compared to a Gaussian frequency profile. Comment: 14 pages, 18 figure...|$|R
