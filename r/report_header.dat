2|11|Public
5000|$|... allows user {{interface}} designers to access a common pool of screen and <b>report</b> <b>header</b> labels ...|$|E
40|$|All {{records are}} of equal length- 228 bytes. *There are 3 {{different}} record types, each uniquely identified by card code, as follows: card codes 01 through 02, & 99. ACCOUNT / <b>REPORT</b> <b>HEADER</b> RECORDS (CARD CODE 01) Control record which signifies {{the beginning of}} the report for a given account. Contains recipient account and report identification items. COMPARED POOL INSTRUCT DETAIL RECORD (CARD CODE 02) Detail record containing a single status item for a compared pool instruct record...|$|E
40|$|The Appellate Body is issuing these Reports in {{the form}} of a single {{document}} constituting three separate Appellate Body Reports: WT/DS 339 /AB/R; WT/DS 340 /AB/R; and WT/DS 342 /AB/R. The cover page, preliminary pages, Sections I through VIII, and the Annex are common to the three <b>Reports.</b> The page <b>header</b> throughout the document bears three document symbols: WT/DS 339 /AB/R, WT/DS 340 /AB/R, an...|$|R
40|$|Note by the Secretariat: These Panel Reports are in {{the form}} of a single {{document}} constituting three separate Panel Reports: WT/DS 431 /R, WT/DS 432 /R and WT/DS 433 /R. The cover page, preliminary pages, sections 1 through 7 are common to the three <b>Reports.</b> The page <b>header</b> throughout the document bears the three document symbols WT/DS 431 /R, WT/DS 432 /R and WT/DS 433 /R, with th...|$|R
5000|$|The {{well-known}} mass-mailing [...] macro {{computer virus}} called the [...] "Melissa virus" [...] was originally distributed via the alt.sex newsgroup. It was hidden inside a list purporting to contain passwords to pornographic websites. The messages containing the virus were posted with message headers {{claiming that the}} post had been written using the America Online (AOL) account of Scott Steinmetz, whose username was [...] "skyroket". Kizza <b>reports</b> that the <b>headers</b> on the post were probably forged by Melissa's author, David L. Smith.|$|R
40|$|At past Bird Strike Conferences, {{the need}} for having a good {{database}} to track and analyze wildlife activities has been expressed. Sadly, most airports/wildlife contractors still depend on archaic log sheets. At best, some have tapped into the limited capability of spreadsheets. Limiting yourself to this method severely restricts your abilities to track activities effectively. And if the data isn’t available then you cannot make informed decisions. Toronto’s Pearson International Airport’s Field Superintendent John Meehan put it best by saying… “I cannot imagine any airport trying to oversee wildlife initiatives without an effective data analysis tool…it would be meaningless…”. If {{you do not have}} accurate, timely data like John says, then how can you realistically determine Threat Assessments, Hazard Analysis, Trends, Primary Attractants, Deterrent Success rates or Geographical Hot Spots to name a few. And if you cannot produce data results such as these then how can you take effective measures? Is spending X amount of dollars on a spray program really making a difference? Or keeping the grass in a particular area an inch shorter really better? Maybe your efforts are good, but did it spark another situation somewhere else? How do you track dynamics such as these? I have developed a software program that specifically addresses these problems. AIRMAN (Animal Interdiction Report Manager) is a complete stand-alone program that reports on all aspects of wildlife intervention and stores this information in a modern Relational Database. All wildlife encountered, its surrounding variables, equipment and methods used are recorded on one simple data entry screen. Once the data is entered, AIRMAN can recall this data and produce a host of professional reports that allow you to make informed decisions. All reports and query engines have unrestricted date ranges to report on. Everything is consistent because all data comes from the same reliable source. This means no integrity errors. You have full control over what you want to see. You can predefine <b>report</b> <b>headers</b> to explain the nature of the report such as Annual, Migratory, Special (ie. Anywhere Airport Annual Strike Report). Here {{are a few of the}} reports available…...|$|R
30|$|Another widely {{available}} cross-domain data sharing mechanism is Cross-Origin Resource Sharing (CORS) [22]. CORS allows a Web page associated with one origin to access resources {{associated with a}} different one. Based on the Origin <b>header</b> <b>reported</b> by the browser, the target Web site may choose to allow or deny access, or, more granularly, accept or expose certain HTTP headers (including Cookie and Set-Cookie). Like Web Storage/Web Messaging, the CORS specification is supported by all major browser vendors. Its drawback {{is that it can}} only be used with AJAX (JavaScript) requests [23]. Our cross-domain cookies work like traditional cookies; they can be used with both browser-native and JavaScript-issued HTTP requestsd.|$|R
40|$|Note by the Secretariat: The Panels issue these Reports in {{the form}} of a single {{document}} constituting two separate Panel Reports: WT/DS 412 /R and WT/DS 426 /R. Each Panel Report relates to one of the two complaints in these disputes. The cover page, preliminary pages, Sections I through VII, Section IX and the Annexes are common to both Panel <b>Reports.</b> The page <b>header</b> throughout the document bears two document symbols, WT/DS 412 /R and WT/DS 426 /R, with the following exceptions: Section VIII on page JPN- 139, which bears the document symbol for and contains the Panel's conclusions and recommendations in the Panel Report WT/DS 412 /R; and Section VIII on page EU- 140, which bears the document symbol for and contains the Panel's conclusions an...|$|R
40|$|In {{cognitive}} radio networks, cooperative spectrum sensing schemes are {{proposed to improve}} the performance of detecting licensees by secondary users. Commonly, the cooperative sensing can be realized by means of hard decision fusion (HDF) or soft decision fusion (SDF) schemes. The SDF schemes are superior to the HDF ones {{in terms of the}} detection performance whereas the HDF schemes are outperforming the SDF ones when the traffic overhead is taken into account. In this paper, a hybrid SFD-HDF cluster-based approach is developed to jointly exploit the advantages of SFD and HDF schemes. Different SDF schemes have been proposed and compared within a given cluster whereas the OR-rule base HDF scheme is applied to combine the decisions <b>reported</b> by cluster <b>headers</b> to a common receiver or base station. The computer simulations show promising results as the performance of the proposed scenario of hybridizing soft and hard fusion schemes is significantly outperforming other different combinations of conventional SDF and HDF schemes while it noticeably reduces the network traffic overhead...|$|R
5000|$|As an example, if slow.example.com is a [...] "real" [...] web server, and www.example.com is the Squid {{cache server}} that [...] "accelerates" [...] it, {{the first time}} any page is {{requested}} from www.example.com, the cache server would get the actual page from slow.example.com, but later requests would get the stored copy directly from the accelerator (for a configurable period, after which the stored copy would be discarded). The end result, without any action by the clients, is less traffic to the source server, meaning less CPU and memory usage, and less need for bandwidth. This does, however, mean that the source server cannot accurately report on its traffic numbers without additional configuration, as all requests {{would seem to have}} come from the reverse proxy. A way to adapt the reporting on the source server is to use the X-Forwarded-For HTTP <b>header</b> <b>reported</b> by the reverse proxy, to get the real client's IP address.|$|R
40|$|Conference on Optoelectronic Devices and Integration, Beijing, China,, 8 - 11 November, 2004 We will {{describe}} recent results in all-optical packet switching with all-optical header processing using Fabry-Perot laser diodes (FP-LD). First, we will <b>report</b> an all-optical <b>header</b> processor and control signal generator using a single FP-LD {{with a special}} two-intensity-level control signal and a novel self-routing address format for the data packets. We then show that the special control signal can be generated by direct modulation of a DFB laser with square electrical pulses thus simplifying implementation. We will demonstrate that a single Fabry-Perot laser diode can also serve as an all-optical on/off switch with all-optical header processing. The header rate is 5 Gb/s and the payload rate is 10 Gb/s. The all-optical on/off switch can also be realized by using a FP-LD as the header processor only and executing the packet switching at a separate stage. The two-stage implementation of all-optical on/off switch eliminates the residue header bits problems if only a single FP-LD is used. Finally, we propose an all-optical packet-switched ring network which can be constructed from the all-optical on/off switches demonstrated. Department of Electronic and Information EngineeringRefereed conference pape...|$|R
40|$|One of the {{invisible}} aspects of large research projects {{in the social sciences}} is the method by which observations and other collected data are managed. In sufficiently large projects, it may be effective to address the data management problem at the outset by creating a database architecture and data processing workflow. Research methods, assumptions and technical limitations often drive the structure of the data to be collected, but this is rarely discussed {{within the framework of the}} research. This design process represents a complex selection and trade-off matrix of predictive approximation, given that aspects of the analysis are not performed until the data is collected, and the design is done before the data collection is started. An elegant design can afford an equally elegant analysis of the data, but also creates a cycle where the data structure dictates the focus and granularity of the analysis. We were faced with the problem of creating a system to support the projected data collection projects for a major, multi-method, 5 -year research project on data curation practices. Our research focuses on specific techno-social practices of astronomers and will rely on a large volume of complex and heterogeneous source materials, such as email archives, scholarly publications, websites, <b>reports,</b> metadata <b>headers,</b> as well as in-person interviews. The research questions focus on the data management, curation, and sharing practices of astronomers, how these practices evolved, and mapping who shares what, when, with whom, and why, with specific interest in what data they generate, use, keep and discard. We also ask what is most important to curate, and how do they do so, what do they expect to use and decide will be of future use to others, and who do they envision as future users? The database structure will act as the connective tissue for the full term of the project while embodying the research methods, facilitating analysis, enabling data sharing, and minimizing effort. However, the process also represents a complex selection and trade-off matrix of predictive approximation of the intended analysis as the design defines the data set and the data set drives the analysis. This process-oriented poster documents the matrix we followed, the challenges and the solutions developed while operationalizing a data system for a large research project with major relational and descriptive aspects. Our resulting system utilizes existing competencies and departmental resources while meeting basic prerequisites for data security, sharing, interoperability, best practices and extensibility...|$|R
40|$|Objective: To {{update the}} current SPONCOM {{software}} to SponCom 2. 0 with a Windows-based platform, using tabs and easy-to-navigate screens for entering or selecting data. These user interface enhancements {{would continue to}} make the SPONCOM software an effective tool in determining the relative spontaneous combustion potential of coal, and thereby contribute to safer mining work environments. Background: Statistics show that in 2011 approximately 15 % of all underground coal mine fires are still caused by the spontaneous combustion of coal. Spontaneous combustion fires usually occur in mined-out or gob areas. Fires in these areas are difficult to detect and extinguish, and present a serious safety hazard to mine personnel. Prior knowledge of the spontaneous combustion potential of the mining operation and the factors that increase that risk can be strategic in preventing spontaneous combustion fires. The previous version of SPONCOM (1. 0) is a DOS-based computer program that determines a coal's relative spontaneous combustion potential based on the coal's proximate/ultimate analyses and heating value. The program evaluates {{the impact of the}} coal properties, geologic and mining conditions, and mining practices relative to the risk of spontaneous combustion. Since 1994 the SPONCOM program has been distributed to over 300 users and is used throughout the mining industry as the standard for spontaneous combustion assessment. The DOS platform is now considered obsolete, with new computers having limited or no support for DOS programs. SponCom 2. 0 ensures the continuing use of the SPONCOM technology in the mining industry as SponCom 2. 0, now running on a Windows-based platform, offers the same functionality as the original version. Approach: The original SPONCOM program (1. 0) was developed by the Nationals Institute for Occupational Safety and Health (NIOSH) to aid its researchers and U. S. Mine Safety and Health Administration (MSHA) personnel, mining operators, and consultants in the assessment of the spontaneous combustion risk in an underground mining operation. To develop the program, information was gathered from the literature, from interactions with experts in ground control, ventilation, and geology, and from mine personnel who have experienced self-heating events at their operations. The information from these sources was correlated with NIOSH's experimental studies (on the self-heating tendencies of coals) to form the knowledge base for the program. SponCom 2. 0 uses the same data inputs and analyses algorithms as the original SPONCOM program, but improves the user interface. The SponCom 2. 0 interface is divided into six sections represented by the following tabs that help the user to easily select a data input or <b>report</b> screen: <b>Header,</b> Coal Properties, Geological Properties, Mining Conditions/ History, Mining Methods, and Report. The first five tabs allow the user to enter data or information; the last tab enables the user to view the results of those entries. The tabs {{do not have to be}} accessed in any particular order. However, each section must be properly filled out in order to generate a valid report. The data entry elements consist of those commonly found in a Windows format, such as checkboxes, drop-down selections, numerical up-downs, textboxes, and radio buttons. Considerable care was used by NIOSH programmers in making the data entry process easier, which in turn enables users' entry of data to be more accurate and complete. How it Works: SponCom 2. 0 determines the coal's rank and relative self-heating potential based on the coal's proximate and ultimate analyses, heating value, and prior spontaneous combustion history. The coal's proximate and ultimate analysis is critical to generating an accurate, valid report. Two mechanisms contribute to heat generation by the coal-the heat of oxidation and the heat of wetting. The heat of oxidation is the heat generated by the adsorption of oxygen by the coal. The heat of wetting is the heat generated by the adsorption of water vapor by the coal surfaces. Coal properties that affect the rate of heat generation include the coal's reactivity, its moisture content, friability, and the presence of pyrite and other impurities; these coal properties are entered through the Coal Properties data entry screen. The contribution of each of these factors to the overall spontaneous combustion risk is determined by the SPONCOM software. The input data are stored to a data file, from which the data can be recalled and updated as needed. Data files generated from the original SPONCOM program can be imported as desired. The Report tab displays the self-heating risk of the coal and provides details on each of the factors that increase the risk of spontaneous combustion in the mining operation. In addition, a valid report can be printed out as desired. There are three different types of Help included with the SponCom 2. 0 software: (1) To view popup Help, click the right mouse button on any screen item, and select the topic from the popup menu; (2) To view a topic from the program's Help File, select Help from the Help menu on the menu bar or press F 1; (3) To view the user manual (included with the SponCom 2. 0 software), open the appropriate PDF file. " - NIOSHTIC- 2 "December 2011. "Also available via the World Wide Web as an Acrobat. pdf file (0. 3 MB, 2 pages) ...|$|R

