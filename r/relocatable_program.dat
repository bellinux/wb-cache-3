3|10|Public
50|$|IBM's SQUOZE was a {{representation}} of a <b>relocatable</b> <b>program</b> object file with a symbol table on punched cards in the SHARE 709 operating system. A program in this format was called a SQUOZE deck.|$|E
40|$|Program {{reference}} patterns {{can have}} a more profound effect on paging performance in a virtual memory system than page re-placement algorithms. This paper describes experimental techniques that can sign$-cantly reduce paging exceptions in existing, frequently executed programs. Automated procedures reorder <b>relocatable</b> <b>program</b> sectors, and computer displays of memory usage facilitate fur-ther optimization qf program structure. Program restructuring for virtual memory by D. J. Hatfield and J. Gerald Experimental techniques {{have been developed for}} improving the performance of programs in virtual memory Systems'J by rearranging, or by duplicating and rearranging, relocatable sectors of code. Experimental results were obtained from finished programs, rather than from programs in the design stage. Improvements i...|$|E
40|$|Traditionally, {{execution}} of a program follows a straight and inflexible path starting from source code, extending through a compiled executable file on disk, and culminating in an executable image in memory. This dissertation enables more flexible programs through new compilation mechanisms and binary editing techniques. To assist analysis of functions in binaries, a new compilation mechanism generates data representing control flow graphs of each function. These data allow binary analysis tools to identify the boundaries of basic blocks {{and the types of}} edges between them without examining individual instructions. A similar compilation mechanism is used to create individually relocatable basic blocks that can be relocated anywhere in memory at runtime to simplify runtime instrumentation. The concept of generating <b>relocatable</b> <b>program</b> components is also applied at function-level granularity. Through link-time function relocation, unused functions in shared libraries are moved to a section that is not loaded into the memory at runtime, reducing the memory footprint of these shared libraries. Moreover, function relocation is extended to the runtime where functions are continuously moved to random addresses to thwart system intrusion attacks. The techniques presented above result in a 74 % reduction in binary parsing times as well as an 85 % reduction in memory footprint of the code segment of shared libraries, while simplifying instrumentation of binary code. The techniques also provide a way to make return-oriented programming attacks virtually impossible to succeed...|$|E
40|$|Specific {{modifications}} in the Disk Operational System Unified Series {{to insure the}} relocatability of programs stored permanently in the core image library is described. A self-relocating method for loading programs into the working memory with re-editing all the programs recorded in the core image library is presented. The modified linkage editor can {{be included in a}} relocation dictionary containing data about each address constant at the assembly stage {{at the request of the}} programmer. The relocation dictionary increases the dimension of the RL-phase in comparison with the dimension of this same phase when edited by the standard method, making possible the creation of multiphase program complexes. Generation and use of the modified system using Assembly language is described. An example of the use of the system is given, and limitations of the use of the <b>relocatable</b> <b>programs</b> in the modified system are outlined...|$|R
40|$|The MIDAS {{linking loader}} is a PDP- 6 program to load relocatable-format output from the MIDAS assemblers, with {{facilities}} to handle symbolic cross-reference between independently assembled programs. Although it is arranged primarily to load from DECtape, the loader is able also to load paper-tape <b>relocatable</b> <b>programs.</b> To use the loader, load {{it off the}} MACDMOP SYSTEM tape as the file STINK (A file STINK NEW may exist, repairing old bugs or introducing new features.) Then the loader expects commands to be typed in on the on-line Teletype; two successive ALT MODE characters terminate the string of commands. The commands in a string are not performed until the string is thus terminated. While a command in a string has not been terminated, RUBOUT will erase the last typed-in character (and type it out again as a reminder). A command string may contain any number of commands, and the effect is the same whether the commands are together in one string or are in successively typed-in strings each delimited by two ALT MODES...|$|R
40|$|ABSTRACT Digital Signal Processors {{are widely}} used in {{critical}} embedded systems to pilot low-level, often critical functionalities. We describe a static analyzer based on abstract interpretation and designed to validate industrial assembler programs for a DSP. The validation consists of guaranteeing the absence of runtime errors such as incorrect memory accesses and of tracking the sources of inaccuracies introduced by floating-point computations. Our first contribution is a new static analysis for <b>relocatable</b> assembler <b>programs</b> {{able to cope with}} dynamically computed branching addresses. Our second contribution is the analyzer itself and its graphical interface which helps the user to understand the numerical inaccuracies...|$|R
40|$|Examples {{are given}} that {{describe}} how the Little Man Computer (LMC) Model {{and its associated}} assembly language code {{can be used to}} illustrate a wide variety of core programming topics including a loader <b>program,</b> <b>relocatable</b> and impure code, array processing, function calls, and multitasking. We share this experience as an example “best practice ” for incorporating core programming concepts within a computer engineering course...|$|R
50|$|While compilers (and assemblers) {{generally}} produce {{machine code}} directly executable by computer hardware, they can often (optionally) produce an intermediate form called object code. This {{is basically the}} same machine specific code but augmented with a symbol table with names and tags to make executable blocks (or modules) identifiable and <b>relocatable.</b> Compiled <b>programs</b> will typically use building blocks (functions) kept in a library of such object code modules. A linker is used to combine (pre-made) library files with the object file(s) of the application to form a single executable file. The object files {{that are used to}} generate an executable file are thus often produced at different times, and sometimes even by different languages (capable of generating the same object format).|$|R
40|$|Allocates {{primary memory}} to {{processes}} Maps process address space to primary memory Minimizes access time using cost effective memory configuration ◮ Memory management approaches range from primitive bare-machine approach to sophisticated paging and segmentation strategies for implementing virtual memory. Relocating Executables ◮ Compile, Link, and Load phases. ◮ Source <b>program,</b> <b>relocatable</b> object modules, absolute program. ◮ Dynamic address relocation using relocation registers. ◮ Memory protection using limit registers. (violating the limit generates an hardware interrupt, often called segment violation, {{that results in}} a fatal execution error.) Building the address spac...|$|R
40|$|Abstract. The {{approximate}} {{string matching}} {{problem is to}} find all locations at which a query of length m matches a substring of a text of length n with k-or-fewer differences. Nowadays, {{with the advent of}} novel high throughput sequencing technologies, the approximate string matching algorithms are used to identify similarities, molecular functions and abnormalities in DNA sequences. We consider a generalization of this problem, the fixed-length approximate string matching problem: given a text t, a pattern ρ and an integer ℓ, compute the optimal alignment of all substrings of ρ of length ℓ and a substring of t. We present a practical parallel algorithm of comparable simplicity that requires only O (nm⌈ℓ/w⌉ p) time, where w is the word size of the machine (e. g. 32 or 64 in practice) and p the number of processors, by virtue of computing a bit representation of the <b>relocatable</b> dynamic <b>programming</b> matrix for the problem. Thus the algorithm’s performance is independent of k and the alphabet size |Σ|...|$|R
40|$|The {{approximate}} {{string matching}} {{problem is to}} find all locations at which a query of length m matches a substring of a text of length n with k-or-fewer differences. Simple and practical bitvector algorithms have been designed for this problem, most notably the one used in agrep. These algorithms compute a bit representation of the current state-set of the k-difference automaton for the query, and asymptotically run in O(nmk=w) time where w is the word size of the machine (e. g. 32 or 64 in practice). Here we present an algorithm of comparable simplicity that requires only O(nm=w) time by virtue of computing a bit representation of the <b>relocatable</b> dynamic <b>programming</b> matrix for the problem. Thus the algorithm's performance is independent of k, and it {{is found to be}} more efficient than the previous results for many useful choices of k and small m. Moreover, because the algorithm is not dependent on k, {{it can be used to}} rapidly compute blocks of the dynamic programming matrix as in the [...] ...|$|R
40|$|Abstract. The {{approximate}} {{string matching}} {{problem is to}} find all locations at which a query of length m matches a substring of a text of length n with k-or-fewer differences. Simple and practical bit-vector algorithms have been designed for this problem, most notably the one used in agrep. These algorithms compute a bit representation of the current state-set of the k-difference automaton for the query, and asymptotically run in either O(nmk/w) orO(nm log �/w) time where w is the word size of the machine (e. g., 32 or 64 in practice), and � {{is the size of}} the pattern alphabet. Here we present an algorithm of comparable simplicity that requires only O(nm/w) time by virtue of computing a bit representation of the <b>relocatable</b> dynamic <b>programming</b> matrix for the problem. Thus, the algorithm’s performance is independent of k, and it is found to be more efficient than the previous results for many choices of k and small m. Moreover, because the algorithm is not dependent on k, {{it can be used to}} rapidly compute blocks of the dynamic programming matrix as in the 4 -Russians algorithm of Wu et al. [1996]. This gives rise to an O(kn/w) expected-time algorithm for the case where m may be arbitrarily large. In practice this new algorithm, that computes a region of the dynamic programming (d. p.) matrix w entries at a time using the basic algorithm as a subroutine, is significantly faster than our previous 4 -Russians algorithm, that computes the same region 4 or 5 entries at a time using table lookup. This performance improvement yields a code that is either superior or competitive with all existing algorithms except for some filtration algorithms that are superior when k/m is sufficiently small...|$|R

