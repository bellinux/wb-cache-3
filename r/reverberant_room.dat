122|85|Public
50|$|A <b>reverberant</b> <b>room</b> {{generates a}} short {{critical}} distance and an acoustically dead (anechoic) room generates a longer critical distance.|$|E
50|$|In the {{aerospace}} industry, acoustic chambers {{are the main}} facilities for such tests. A chamber is a <b>reverberant</b> <b>room</b> that creates a diffuse sound field and is composed of an empty volume (from 1 m3 to 2900 m3) and a multifrequency sound generation system.|$|E
5000|$|Before {{the advent}} of {{electronic}} reverb and echo processing, physical means were used to generate the effects. An echo chamber, a large <b>reverberant</b> <b>room,</b> could be equipped with a speaker {{and at least two}} spaced microphones. Signals were then sent to the speaker and the reverberation generated in the room was picked up by the two microphones, constituting a [...] "stereo return".|$|E
30|$|We use {{the four}} <b>reverberant</b> <b>rooms,</b> i.e., rooms A, B, C and D, to {{evaluate}} the performance. The acoustical properties of the four rooms {{can be found in}} Table 2 in Section 6.1.|$|R
3000|$|... (t) {{represents}} later high-order reflections, {{which are}} perceived as reverberation. These reflections are incoherent with the direct sound and constitute the main factor for temporal smearing and quality degradation in <b>reverberant</b> <b>rooms.</b> The parameter T [...]...|$|R
5000|$|The most {{controversial}} and difficult {{step in this}} process is detecting pitch. [...] The most successful pitch methods operate in the frequency domain, not the time domain. While time-domain methods have been proposed, they can break down for real-world musical instruments played in typically <b>reverberant</b> <b>rooms.</b>|$|R
5000|$|The NSMRL {{auditory}} laboratory {{includes a}} large, 1000 m3 Anechoic Chamber. The suspended cable floor and fiberglass wedges provide an [...] "echo-free" [...] {{environment that is}} essential for efforts on spatialized auditory displays and transducer evaluation. Additionally, there are ten fully instrumented soundproof booths and a <b>reverberant</b> <b>room.</b> These facilities are integral to the work on human-machine interfaces, combat systems displays, hearing conservation, audio signal enhancement, noise reduction techniques, and diver hearing.|$|E
50|$|ANSI/AMCA Standard 300 - <b>Reverberant</b> <b>Room</b> Method for Sound Testing of Fans {{applies to}} fans {{of all types}} and sizes. It {{is limited to the}} {{determination}} of airborne sound emission for the specified setups. Vibration is not measured, nor is the sensitivity of airborne sound emission to vibration effects determined. The test setup requirements in this standard establish the laboratory conditions necessary for a successful test. Rarely will it be possible to meet these requirements in a field situation. This standard is not intended for field measurements.|$|E
5000|$|He built {{a simple}} passive mixing system that {{directly}} fed the electronics of his Ampex 350 and 351 tape machines. Also, DuNann told Stereophile that Contemporary sessions were recorded [...] "dry" [...] (without electronic echo added or in a <b>reverberant</b> <b>room).</b> Sometimes, {{such as in}} the case of Sonny Rollins' Way Out West, a plate reverb unit was inserted between the tape machine and the LP disc cutting lathe. This is why some later LP and CD reissues of Contemporary albums sound [...] "dry" [...] and [...] "dead" [...] compared to the original LPs mastered by DuNann.|$|E
40|$|National audienceSmall <b>reverberant</b> <b>rooms</b> {{are usually}} {{used in the}} {{automotive}} industry, like the well-known Alpha Cabin, for diffuse field absorption coefficient measurements of porous materials. The advantage is that rather small flat samples are necessary here, typically 1, 2 m by 1 m. Real parts can be measured as well, like engine hoods, in sufficient quantity close the 1, 2 m² area. With a Schroeder frequency of 1250 Hz, the simulation of the Alpha Cabin is rather problematic. There are diffusivity issues in the middle frequency range that are varying {{with the level of}} absorption of the sample. Moreover, critical diffractions due to the finite size effects of the 1, 2 m² flat sample occur and must be taken into account. Different simulation approaches of small <b>reverberant</b> <b>rooms</b> are investigated in this paper and compared to the large <b>reverberant</b> <b>rooms</b> situation (with 12 m² material in that case). The first approach, for solving the diffraction issues, consists in applying recent spatial windowing techniques combined with the efficient Transfer Matrix Method (TMM) for porous materials, sometimes called Finite Transfer Matrix Method (FTMM). The second approach, for solving the diffusivity issues, consists in modelizing the Alpha Cabin with the Ray-Tracing Methods with statistical prolongations and compare directly the reverberation times with measurements. In order to take into account both issues {{at the same time and}} potentially strong coupling between the porous domain and the fluid domain in the middle frequency range, a complete FEM model, as third approach, is built using poro-elastic finite elements with the (u,p) formulation. All simulation techniques will be compared with oneanother and correlated with measurements carried out in small and large <b>reverberant</b> <b>rooms</b> showing the advantages and limitations of each approach...|$|R
40|$|Measurements of the random-incidence {{scattering}} {{coefficients of}} a sine-shaped surface (3 meter diameter) {{have been performed}} in real-size <b>reverberant</b> <b>rooms,</b> according to the procedure described in the ISO document ISO/DIS 17497 - 11. A round-robin test has been organized, using two sets of measuring instruments, two similar sine-shaped samples and two reverberation room...|$|R
5000|$|Four <b>Reverberant</b> Sound <b>Rooms</b> {{ranging in}} size from 6,300 cu.ft. to 61,700 cu.ft.|$|R
5000|$|A-weighting is also {{in common}} use for {{assessing}} potential hearing damage caused by loud noise, though {{this seems to be}} based on the widespread availability of sound level meters incorporating A-Weighting rather than on any good experimental evidence to suggest that such use is valid. The distance of the measuring microphone from a sound source is often [...] "forgotten", when SPL measurements are quoted, making the data useless. In the case of environmental or aircraft noise, distance need not be quoted as it is the level at the point of measurement that is needed, but when measuring refrigerators and similar appliances the distance should be stated; where not stated it is usually one metre (1 m). An extra complication here is the effect of a <b>reverberant</b> <b>room,</b> and so noise measurement on appliances should state [...] "at 1 m in an open field" [...] or [...] "at 1 m in anechoic chamber". Measurements made outdoors will approximate well to anechoic conditions.|$|E
5000|$|During an {{interview}} with Chris Pike from BBC R&D in September 2012, Pike stated that [...] "you may get good spatial impression but timbral coloration is often an issue". The issue of timbral coloration is mentioned in {{a large amount of}} spatial enhancement research and is sometimes seen as the outcome of the misuse or insufficient amount of HRTF data when reproducing binaural audio for example, or the fact that the end-user simply will not respond well to the collected HRTF data. Francis Rumsey states in the 2011 article 'Whose head is it anyway?' [...] that [...] "badly implemented HRTFs can give rise to poor timbral quality, poor externalisation, {{and a host of other}} unwanted results". Getting the HRTF data correct is obviously a key point in making the final product a success, and possibly by making the HRTF data as extensive as possible, there will be less room for error such as timbral issues. The HRTFs used for Private Peaceful were designed by measuring impulse responses in a <b>reverberant</b> <b>room,</b> done so to capture a sense of space, but is not very external and there are obvious timbral issues as pointed out by Pike.|$|E
50|$|Wow and flutter are {{particularly}} audible on music with oboe, string, guitar, flute, brass, or piano solo playing. While wow is perceived clearly as pitch variation, flutter {{can alter the}} sound of the music differently, making it sound ‘cracked’ or ‘ugly’. There is an interesting reason for this. A recorded 1 kHz tone {{with a small amount of}} flutter (around 0.1%) can sound fine in a ‘dead’ listening room, but in a <b>reverberant</b> <b>room</b> constant fluctuations will often be clearly heard. These are the result of the current tone ‘beating’ with its echo, which since it originated slightly earlier, has a slightly different pitch. What is heard is quite pronounced amplitude variation, which the ear is very sensitive to. This probably explains why piano notes sound ‘cracked’. Because they start loud and then gradually tail off, piano notes leave an echo that can be as loud as the dying note that it beats with, resulting in a level that varies from complete cancellation to double-amplitude at a rate of a few Hz: instead of a smoothly dying note we hear a heavily modulated one. Oboe notes may be particularly affected because of their harmonic structure. Another way that flutter manifests is as a truncation of reverb tails. This may be due to the persistence of memory with regard to spatial location based on early reflections and comparison of Doppler effects over time. The auditory system may become distracted by pitch shifts in the reverberation of a signal that should be of fixed and solid pitch.|$|E
40|$|In {{this paper}} {{we present a}} new on-line Blind Signal Separation method capable to {{separate}} convolutive speech signals of moving speakers in highly <b>reverberant</b> <b>rooms.</b> The separation network used is a recurrent network which performs separation of convolutive speech mixtures in the time domain, without any prior knowledge of the propagation media, based on the Maximum Likelihood Estimation (MLE) principle. The proposed method proved {{to be able to}} improve significantly (more than 10 % in all adverse mixing situations) the performance of a continuous phoneme-based speech recognition system and therefore {{can be used as a}} front-end to separate simultaneous speech of speakers who are moving in arbitrary directions in <b>reverberant</b> <b>rooms.</b> 1. INTRODUCTION Humans have the ability to focus their listening attention on a single talker among a din of conversations and background noise, and recognize a specific voice, known as the "cocktail party effect". The problem of Blind source separation (BSS) c [...] ...|$|R
30|$|In {{the last}} section, {{a set of}} {{experiments}} using simulations of <b>reverberant</b> <b>rooms</b> were presented. Besides considering these simulations, {{the applicability of the}} proposed method can be substantially enhanced by providing some notes on the real-time implementation of a working prototype. Two objectives are pursued with this implementation. First, to demonstrate that the computational cost of this technique is reduced enough to be implemented in a practical embedded system. Second, having a real-time system allowed us to plan future interactive experiments where conditions related to scene changes can be experienced as they occur.|$|R
40|$|One {{of the big}} {{challenges}} {{in the field of}} Automatic Speech Recognition (ASR) consists in developing suitable solutions able to work properly also in adverse acoustic conditions, like in presence of additive noise and/or in <b>reverberant</b> <b>rooms.</b> Recently a certain {{attention has been paid to}} deeply integrate the noise suppressor in the feature extraction pipeline. In this paper, different single-channel MMSE-based noise reduction schemes have been implemented both in the frequency and cepstral domains and the related recognition performances evaluated on the AURORA 2 and AURORA 4 databases, therefore providing a useful reference for the scientific community...|$|R
40|$|Several {{measurement}} techniques {{are available for}} {{the determination of the}} sound absorbing properties of material packages. The Kundt's method and the <b>reverberant</b> <b>room</b> method are the most commonly used techniques and they are standardized. However, both methods cannot be used in situ. In the past {{it has been shown that}} the PU in situ method can be used in a broad frequency range (typically from 300 Hz up to 10 kHz), on small samples (typically 0. 03 m 2 to 0. 38 m 2 or larger), while hardly being affected by background noise and reflections. Several studies revealed that similar results can be obtained as with the Kundt's tube if the measurements are performed under certain circumstances. A thorough comparison with the <b>reverberant</b> <b>room</b> method has not been conducted yet. In this paper preliminary results are presented of a comparison of the <b>reverberant</b> <b>room</b> method, the PU in situ method, and measurements with PU probes in a <b>reverberant</b> <b>room.</b> Several factors that may cause discrepancies amongst the methods are discussed. In addition, edge effects, which are experienced with the <b>reverberant</b> <b>room</b> method due to the finite size of the sample, are visualized with 3 D intensity measurements that are performed in a reverberant roo...|$|E
40|$|The Structural Acoustics Loads and Transmission (SALT) {{facility}} at the NASA Langley Research Center {{is comprised of}} an anechoic room and a <b>reverberant</b> <b>room,</b> and may act as a transmission loss suite when test articles are mounted in a window connecting the two rooms. In the latter configuration, the <b>reverberant</b> <b>room</b> acts as the noise source side and the anechoic room as the receiver side. The noise generation system used for qualification testing in the <b>reverberant</b> <b>room</b> was previously shown to achieve a maximum overall sound pressure level of 141 dB. This {{is considered to be}} marginally adequate for generating sound pressure levels typically required for launch vehicle payload qualification testing. Recent enhancements to the noise generation system increased the maximum overall sound pressure level to 154 dB, through the use of two airstream modulators coupled to 35 Hz and 160 Hz horns. This paper documents the acoustic performance of the enhanced noise generation system for a variety of relevant test spectra. Additionally, it demonstrates the capability of the SALT facility to conduct transmission loss and absorption testing in accordance with ASTM and ISO standards, respectively. A few examples of test capabilities are shown and include transmission loss testing of simple unstiffened and built up structures and measurement of the diffuse field absorption coefficient of a fibrous acoustic blanket...|$|E
40|$|Using {{statistical}} room acoustics {{we investigate}} {{the performance of}} Blind Source Separation and Deconvolution (BSSD) algorithms when used in a <b>reverberant</b> <b>room.</b> We focus on the case {{where one of the}} sources moves, and examine the relative impact of source movement and room reverberation on the expected performance. We derive theoretical expressions, and verify these through image model simulations. 1...|$|E
40|$|Abstract. Automatic Speech Recognition (ASR) in <b>reverberant</b> <b>rooms</b> can be {{improved}} by choosing training data from the same acoustical environment as the test data. In a real-world application this is often not possible. A solution for this problem is to use speech signals from a closetalking microphone and reverberate them artificially with multiple room impulse responses. This paper shows results on recognizers whose training data differ in size and percentage of reverberated signals {{in order to find}} the best combination for data sets with different degrees of reverberation. The average error rate on a close-talking and a distant-talking test set could thus be reduced by 29 % relative. ...|$|R
3000|$|Real {{recordings}} {{are captured}} in a <b>reverberant</b> meeting <b>room</b> {{from two different}} distances: near (≈ 100 cm) and far (≈ 250 cm). The development and evaluation sets of these recordings are not analysed in terms of measured C [...]...|$|R
40|$|Multichannel blind source {{separation}} performances rapidly degrade {{when the}} mixtures are highly reverberated. In fact, blind source separation algorithms usually {{focus on the}} sepa-ration task without dealing with the dereverberation problem. Some recent studies attempted to reduce the reverberation by introducing a dereverberation module {{before or after the}} blind source separation but only limited success was obtained in improving the separation performance in highly <b>reverberant</b> <b>rooms.</b> In this article, we conduct a number of experiments combining state of the art spectral enhancement-based dere-verberation and source separation algorithms showing that, in this particular case, speech enhancement does not improve the performance of blind source separation. Index Terms — Blind source separation, speech derever-beration, spectral subtraction, microphone array. 1...|$|R
3000|$|The {{database}} {{provided in}} REVERB Challenge comprises three {{different sets of}} eight-channel recordings: training set, development set and evaluation set. Real data recorded in a <b>reverberant</b> <b>room</b> and simulated data created by convolving non-reverberant utterances with measured RIRs {{are included in the}} development set and evaluation set, whereas the training set only comprises simulated data. This section analyses the RIRs of different data sets in terms of C [...]...|$|E
30|$|The second CD {{codebook}} employed, {{referred to}} as CD- 2, models normal speech in reverberant conditions for the same speaker as modeled by CD- 1. CD- 2 was trained using training utterances of duration around 10 min, convolved with the same impulse response as used in the previous experiments (corresponding to a distance of 50 cm from the microphone, in a <b>reverberant</b> <b>room</b> with T 60 = 800 ms).|$|E
40|$|Presented at the 21 st International Conference on Auditory Display (ICAD 2015), July 6 - 10, 2015, Graz, Styria, Austria. We report three {{experiments}} {{measuring the}} upper limits, defined as auditory velocity thresholds beyond which listeners {{are no longer}} able to perceptually resolve a smooth circular trajectory in various reverberate conditions. These thresholds were measured for white noise, band-limited white noise and band-limited white noise mixed with a pure tone, in different reverberation conditions: acoustically dry room, two simulated source-image-based reverberations and natural reverberation with different configurations of loudspeaker arrays. Experiment 1 took place in a dry room and thresholds were measured with and without a reverberation simulation of an actual <b>reverberant</b> <b>room.</b> In Experiment 2, various simulated reverberation parameters were tested in the same dry room, and two different loudspeaker configurations were tested in a <b>reverberant</b> <b>room.</b> Experiment 3 investigated the effect of audio source type in simulated reverberation condition and for high velocities. No significant effects were observed among reverberation conditions, suggesting that the upper limit is robust against reverberation...|$|E
40|$|Abstract—In {{distributed}} meeting applications, microphone arrays {{have been}} widely used to capture superior speech sound and perform speaker localization through sound source localization (SSL) and beamforming. This paper presents a unified maximum likelihood framework of these two techniques, and demonstrates how such a framework can be adapted to create efficient SSL and beamforming algorithms for <b>reverberant</b> <b>rooms</b> and unknown directional patterns of microphones. The proposed method is closely related to steered response power-based algorithms, which are known to work extremely well in real-world environments. We demonstrate the effectiveness of the proposed method on challenging synthetic and real-world datasets, including over 6 hours of recorded meetings. Index Terms—Microphone array, sound source localization, beamforming, directional mics (a) I...|$|R
40|$|For {{measuring}} the sound insulation of building elements in laboratory three standardized methods based on different acoustic principles are available. According to ISO 140 - 3 the element under test is installed between two <b>reverberant</b> <b>rooms.</b> The measurements acc. to ISO 140 - 5 combine free field excitation with a <b>reverberant</b> receiving <b>room</b> and ISO 15186 - 1 uses sound intensity for determination of transmission loss. All methods assume idealized acoustic conditions that differ {{more or less}} from the situation found in practice. In addition to the inherent statistic variation of the measuring results this gives rise to systematic deviations between the different measuring methods. Since the deviations are so far only partly understood, they were investigated {{by means of an}} extensive series of tests. The tests comprised three different types of building elements (a chipboard, a lightweight double-leaf construction and a membrane partition) and were performed under well-defined conditions in the test facilities of the Fraunhofer-Institute for Building Physics. Apart from comparing the different measuring methods additional investigations on the influence of the most important measuring parameters (reverberation time, number and position of microphones, etc.) are presented. The results of the investigations contribute {{to a better understanding of}} accuracy and reliability in measuring sound insulation...|$|R
30|$|Sequential Monte Carlo {{methods have}} been {{recently}} proposed {{to deal with the}} problem of acoustic source localisation and tracking using an array of microphones. Previous implementations make use of the basic bootstrap particle filter, whereas a more general approach involves the concept of importance sampling. In this paper, we develop a new particle filter for acoustic source localisation using importance sampling, and compare its tracking ability with that of a bootstrap algorithm proposed previously in the literature. Experimental results obtained with simulated reverberant samples and real audio recordings demonstrate that the new algorithm is more suitable for practical applications due to its reinitialisation capabilities, despite showing a slightly lower average tracking accuracy. A real-time implementation of the algorithm also shows that the proposed particle filter can reliably track a person talking in real <b>reverberant</b> <b>rooms.</b>|$|R
30|$|In this section, we conduct {{experiments}} for speech {{signals to}} evaluate the estimators using both simulated and real impulse responses in <b>reverberant</b> <b>room</b> environments. A real female speech signal is convolved with the room impulse responses to generate microphone signals. The microphone signals are partitioned into non-overlapping frames with a frame size of 600 samples. In addition, mutually independent zero-mean white Gaussian noise is introduced to each microphone signal to control the SNR.|$|E
40|$|A new {{analogue}} {{random signal}} correlator for measuring auto and the cross-correlation coefficient {{has been designed}} using sensistors. The design required the development of new: a) A. -c. power amplifiers b) Square law device c) D. C. sum and difference amplifiers e) A normalizing divider circuit. The instrument was tested by measuring the cross-correlation coefficient in a <b>reverberant</b> <b>room</b> of known characteristics. It {{was found that the}} instrument has an accuracy of better than 2 percent...|$|E
40|$|This paper {{presents}} a room equalization method based on iterative simple complex smoothing of measured acoustic impulse responses. This {{is useful in}} cases of long duration impulse responses. Corresponding time reduced impulse responses are derived which conform to perceptual principles. The smoothed impulse responses are then used to design equalization filters. Results from an audio-conferencing <b>reverberant</b> <b>room</b> using objective and subjective tests show that we can improve the measured and perceived quality of audio reproduction. 1...|$|E
40|$|Localization of {{acoustic}} {{sources in}} the presence of reverberation is still a challenging task in audio signal processing. As a matter of fact, commonly adopted models are not adequate to describe real scenarios. Moreover, practical systems should not employ sophisticated and expensive architectures, that require precise synchronization and fast data shuffling among sensors. This work describes a new robust multi-step procedure for speaker localization in <b>reverberant</b> <b>rooms.</b> The proposed approach is based on a disturbed harmonics model of time delays in the frequency domain and employs the well-known ROOT-MUSIC algorithm, after a proper pre-processing of the received signals. Final clustering of raw TDOA estimates gives candidate source positions. Among the appealing features of the proposed approach are the capability of tracking multiple speakers simultaneously and the high accuracy of the closed form TDOA estimato...|$|R
40|$|Binaural {{features}} of interaural level difference and interaural phase difference {{have proved to}} be very effective in training deep neural networks (DNNs), to generate timefrequency masks for target speech extraction in speech-speech mixtures. However, effectiveness of binaural features is reduced in more common speech-noise scenarios, since the noise may over-shadow the speech in adverse conditions. In addition, the reverberation also decreases the sparsity of binaural features and therefore adds difficulties to the separation task. To address the above limitations, we highlight the spectral difference between speech and noise spectra and incorporate the log-power spectra features to extend the DNN input. Tested on two different <b>reverberant</b> <b>rooms</b> at different signal to noise ratios (SNR), our proposed method shows advantages over the baseline method using only binaural features in terms of signal to distortion ratio (SDR) and Short-Time Perceptual Intelligibility (STOI) ...|$|R
40|$|The Wave Based Method (WBM) is used {{to predict}} the {{airborne}} and structure-borne sound insulation of building structures. In building acoustics, the frequency range of interest is 50 - 5000 Hz. Prediction models in building acoustics often assume infinite structures (like the transfer matrix method) or diffuse sound fields (statistical energy methods). These models cannot explain the inter-laboratory differences typically encountered in the lower frequency range. A wave based prediction model has therefore been developed to describe the direct sound transmission through a structure placed between two <b>reverberant</b> <b>rooms.</b> The rectangular geometry, often encountered in buildings, allows to introduce numerical simplifications which make computations up to 3150 Hz possible on a standard desktop pc. The WBM results are validated with airborne and structure-borne sound insulation measurements of single and double wall structures and a sandwich element. status: publishe...|$|R
