0|777|Public
40|$|We {{present a}} 3 D object <b>relighting</b> {{technique}} for multiview-multi-lighting (MVML) image sets. Our <b>relighting</b> technique is {{a fusion of}} multi-view stereo (MVS) technique and image based <b>relighting</b> (IBL) technique. The MVML dataset consists of multiple camera view with each view filmed under multiple time-multiplex illumination modes. A multi-view 3 D reconstruction algorithm is first applied using traditional multi-view stereo algorithm. After this, the reconstructed model is <b>relighted</b> through an image based <b>relighting</b> scheme for each camera view, followed with view-independent texture mapping procedure. Interactive <b>relighting</b> results demonstrate our high quality reconstruction accuracy, realistic <b>relighting</b> effects and realtime <b>relighting</b> performance. Moreover, our <b>relighting</b> technique is suitable for dynamic 3 D object <b>relighting.</b> Index Terms — Multi-view stereo, Image based <b>relighting,</b> <b>relighting,</b> time-multiplex illuminatio...|$|R
40|$|A {{test program}} was {{conducted}} to evaluate the altitude <b>relight</b> capabilities of a short-length, double-annular, ram-induction combustor which was designed for Mach 3 cruise operation. The use of distorted inlet-air flow profiles was tried to evaluate their effect on the <b>relight</b> performance. No significant improvement in altitude <b>relight</b> performance was obtained with this approach. A study was also made {{to determine the effects}} of the reference Mach number, the fuel temperature, and the fuel volatility (ASTM-A 1 against JP- 4) on the altitude <b>relight</b> performance. Decreasing the reference Mach number, increasing the fuel temperature, and using more volatile fuel all decrease the combustor pressure necessary for <b>relight...</b>|$|R
40|$|<b>Relighting</b> {{has been}} used in many image productions. <b>Relighting</b> {{requires}} object shape information and reflectance, and previously one had to manually retouch the image or use special equipment. We therefore present a novel system for <b>relighting</b> with Kinect, which is a relatively inexpensive depth camera. First, we capture target objects and calculate their shapes. We then estimate reflectance from illumination that is calculated from an environment map taken at the same place. Finally, we <b>relight</b> the object using new illumination. The direction and intensity of the light can be adjusted by the user. This system enables the user to <b>relight</b> objects without complicated operations or expensive equipment...|$|R
40|$|In {{this paper}} we {{address the problem of}} <b>relighting</b> with sparsely sampled {{reflectance}} fields. We present a technique that approximates the correct result of <b>relighting</b> from intermediate light source positions. The acquisition of reflectance fields is a time consuming process, and typically the sampling resolution in the light source positions is rather limited. As a consequence, smoothly moving highlights and shadows due to <b>relighting</b> with a moving light source are hard to generate. Using light source interpolation, densely sampled reflectance fields can be simulated, enabling <b>relighting</b> with area light sources and smooth animation of highlights and shadows. Using light source interpolation we can <b>relight</b> with arbitrarily sampled 4 D incident light fields from complex or near-by light sources. ...|$|R
40|$|Usually, <b>relighting</b> {{techniques}} require {{knowledge about}} {{the shape of a}} target object and the lighting environment. The quality of the <b>relighting</b> is highly dependent on the normals accuracy of the object since they are used for the computation of the illumination. We pro-pose a new <b>relighting</b> approach for arbitrary shaped objects using an RGB-D camera such as the Microsoft’s Kinect. The generated depth map is useful to estimate the normals of the object, but can be inaccurate because of the noise such as discrete depth values or missing data. An accurate segmentation of the target region for <b>relighting</b> is also an open issue since the boundaries in the depth map does not always match color’s ones. We focus on the depth map modification to segment the object region, and normal estima-tion for an accurate <b>relighting.</b> Our implementation of the method achieves a <b>relighting</b> at 15 fps...|$|R
40|$|Abstract- This paper {{presents}} and compares six novel approaches for capturing, synthesising and <b>relighting</b> real 3 D surface textures. Unlike 2 D texture synthesis these techniques allow the captured textures to be relit using illumination conditions, and viewing angles, {{that differ from}} those of original. Our approaches each comprise two stages: synthesis and <b>relighting.</b> Synthesis can be applied either before or after <b>relighting.</b> The <b>relighting</b> stage is implemented in three different ways: using image-based, gradient-based, and height-based approaches. Thus there are a total of six different ways in which we may combine these functions. We present a representative set of results selected from our experiments with 30 textures. The best images are obtained when image-based or gradient-based <b>relighting</b> is used after synthesis. I...|$|R
40|$|Image <b>relighting</b> is a {{very unique}} special visual effect which {{promises}} to have many important practical applications. Image <b>relighting</b> is essentially the process of, given one or more images of some scene, computing what that scene would look like under some other (arbitrary) lighting conditions, e. g., changing positions and colors of light sources. Image <b>relighting</b> can for example be used for interior light design. This paper describes an approach to image <b>relighting</b> which can be implemented to run in real-time by utilizing graphics hardware, as opposed to other state-of-the-art approaches which at best run at a few frames per second. ...|$|R
40|$|Significant {{energy savings}} are {{available}} through <b>relighting</b> with modern, energy efficient systems. As a demonstration, a <b>relighting</b> project was recently completed at Robins Air Force Base, Warner-Robins, Georgia. The project was designed to overcome a reluctance to pursue large scale <b>relighting</b> of the entire facility due to prior unfavorable experiences and an unusually large non-office working environment. The project followed contemporary lighting design practices, with the added dimension of involving building occupants in the process. Involving building occupants promoted their acceptance {{of the project and}} provided needed critical feedback. Their involvement helped secure their assistance in resolving special design concerns involving radio frequency interference and glare. Although often cited as simple, <b>relighting</b> projects are commonly confronted with problems. This document describes problems, foreseen and unforeseen, encountered by this <b>relighting</b> demonstration, and their solutions...|$|R
40|$|Abstract — We {{present a}} novel method to <b>relight</b> video {{sequences}} for multimedia applications given known surface shape and original illumination. The method preserves fine visual details. It requires single view video frames, approximate 3 D shape and known illumination only, making it applicable for multimedia and studio production. The technique is demonstrated for <b>relighting</b> video sequences of faces. Index terms — <b>relighting,</b> face, 3 D, specularity I...|$|R
40|$|Abstract—Usually, <b>relighting</b> {{techniques}} require {{knowledge about}} {{the shape of the}} target object and the lighting environment. The quality of the result is highly dependent on the normals of the object because they are used in the computation of the illumination. In this paper, we propose a new <b>relighting</b> approach for arbitrarily shaped objects using an RGB-D camera such as the Microsoft’s Kinect. The depth map is useful to estimate the normals of the object, but can be inaccurate because of the noise such as discrete depth values or missing data. An accurate segmentation of the target region for <b>relighting</b> is also an open issue since the boundaries in the depth map does not always match color’s ones. We focus on the depth map modification to segment the object region and normal estimation for accurate re-lighting. In our experiments, we adapted some normal estimation methods from modified depth map and evaluated the accuracy of the <b>relighting</b> results. We discuss the effectiveness of <b>relighting</b> approach for an arbitrarily shaped object and the possibility of a real time <b>relighting.</b> I...|$|R
40|$|Image based Relighting(IBRL) has {{attracted}} {{a lot of interest}} in the computer graphics research, gaming, and virtual cinematography communities for its ability to <b>relight</b> objects or scenes, from novel illuminations captured in natural or synthetic environments. However, the advantages of an image-based framework conflicts with a drastic increase in the storage caused by the huge number of reference images pre-captured under various illumination conditions. To perform fast <b>relighting,</b> while maintaining the visual fidelity, one needs to preprocess this huge data into an appropriate model. In this paper, we propose a novel and efficient two-stage <b>relighting</b> algorithm which creates a compact representation of the huge IBRL dataset and facilitates fast <b>relighting.</b> In the first stage, using Singular Value Decomposition, a set of eigen image bases and <b>relighting</b> coefficients are computed. In the second stage, and in contrast to prior methods, the correlation among the <b>relighting</b> coefficients is harnessed using Spherical Harmonics. The proposed method thus has lower memory and computational requirements. We demonstrate our results qualitatively and quantitatively with new generated image data...|$|R
40|$|Figure 1 : LampPost and PipeSet relit using a {{light source}} with novel direction, color and intensity. Image based Relighting(IBRL) has {{attracted}} {{a lot of interest}} in the computer graphics research, gaming, and virtual cinematography communities for its ability to <b>relight</b> objects or scenes, from novel illuminations captured in natural or synthetic environments. However, the advantages of an image-based framework conflicts with a drastic increase in the storage caused by the huge number of reference images pre-captured under various illumination conditions. To perform fast <b>relighting,</b> while maintaining the visual fidelity, one needs to preprocess this huge data into an appropriate model. In this paper, we propose a novel and efficient two-stage <b>relighting</b> algorithm which creates a compact representation of the huge IBRL dataset and facilitates fast <b>relighting.</b> In the first stage, using Singular Value Decomposition, a set of eigen image bases and <b>relighting</b> coefficients are computed. In the second stage, and in contrast to prior methods, the correlation among the <b>relighting</b> coefficients is harnessed using Spherical Harmonics. The proposed method thus has lower memory and computational requirements. We demonstrate our results qualitatively and quantitatively with new generated image data...|$|R
40|$|The {{ability to}} change {{illumination}} is a crucial factor in image-based modeling and rendering. Image-based <b>relighting</b> offers such capability. However, the trade-off is the enormous increase of storage requirement. In this paper, we propose a compression scheme that effectively reduces the data volume while maintaining the real-time <b>relighting</b> capability. The proposed method is based on principal component analysis (PCA). A block-wise PCA is used to practically process the huge input data. The output of PCA {{is a set of}} eigenimages and the corresponding <b>relighting</b> coefficients. By dropping those low-energy eigenimages, the data size is drastically reduced. To further compress the data, eigenimages left are compressed using transform coding and quantization while the <b>relighting</b> coefficients are compressed using uniform quantization. We also suggest the suitable target bit rate for each phase of the compression method in order to preserve the visual quality. Finally, we propose a real-time engine that <b>relights</b> images from the compressed data...|$|R
5000|$|Recorded {{and mixed}} at <b>Relight</b> Studios, Hilvarenbeek, The Netherlands ...|$|R
5000|$|... <b>relighting</b> - recent area {{concerned}} with quickly re-rendering scenes ...|$|R
5000|$|... both engines {{had been}} shut down, either {{intentionally}} or not, {{during the course}} of the short flight. The crew had subsequently tried to restart both engines, but had attempted to <b>relight</b> the second engine before the first one had reached sufficient speed, causing the <b>relight</b> of both engines to fail.|$|R
5000|$|... #Caption: Master Jacques {{repeatedly}} <b>relights</b> {{a candle}} behind Harpagon's back.|$|R
40|$|In {{this paper}} we {{introduce}} a <b>relighting</b> algorithm for diffuse outdoor scenes that {{enables us to}} create geometrically correct and illumination consistent models {{from a series of}} range scans and a set of overlapping photographs that have been taken under different illumination conditions. To perform the <b>relighting</b> we compute a set of mappings from the overlap region of two images. We call these mappings Irradiance Ratio Maps (IRMs). Our algorithm handles cast shadows, being able to <b>relight</b> shadowed regions into nonshadowed regions and vice-versa. We solve these cases by computing four different IRMs, to handle all four combinations of shadowed vs. non-shadowed surfaces. To <b>relight</b> the non-overlapping region of an image, we look into the appropriate IRM which we index on surface normal, and apply its value to the corresponding pixels. The result is an illumination consistent set of images. 1...|$|R
40|$|Hyperspectral {{reflectance}} data {{allows for}} highly accu-rate spectral <b>relighting</b> under arbitrary illumination, which is invaluable to applications ranging from archiving cul-tural e-heritage to consumer product design. Past methods for capturing the spectral reflectance of scenes has proven successful in <b>relighting</b> {{but they all}} share a common as-sumption. All the methods do not consider the effects of fluorescence despite fluorescence being found in many ev-eryday objects. In this paper, we describe the very different ways that reflectance and fluorescence interact with illumi-nants and show the need to explicitly consider fluorescence in the <b>relighting</b> problem. We then propose a robust method based on well established theories of reflectance and fluo-rescence for imaging each of these components. Finally, we show that we can <b>relight</b> real scenes of reflective-fluorescent surfaces with much higher accuracy in comparison to only considering the reflective component. 1...|$|R
40|$|This paper {{proposes a}} novel {{technique}} for 3 D scene <b>relighting</b> with interactive viewpoint changes. The proposed technique {{is based on}} a deep framebuffer framework for fast <b>relighting</b> computation which adopts image-based techniques to provide arbitrary view-changing. In the preprocessing stage, the shading parameters required for the surface shaders, such as surface color, normal, depth, ambient/diffuse/specular coefficients, and roughness, are cached into multiple deep framebuffers generated by several caching cameras which are created in an automatic manner. When the user designs the lighting setup, the <b>relighting</b> renderer builds a map to connect a screen pixel for the current rendering camera to the corresponding deep framebuffer pixel and then computes illumination at each pixel with the cache values taken from the deep framebuffers. All the <b>relighting</b> computations except the deep framebuffer pre-computation are carried out at interactive rates by the GPU...|$|R
60|$|He {{suspended}} his striking tribute {{in order}} to <b>relight</b> his cigar.|$|R
50|$|Most hanging ceiling lamps {{tend to be}} passively cooled, with a {{combined}} ballast and lamp fixture; immediately restoring power to a hot lamp before it has re-struck can make it take even longer to <b>relight,</b> because of power consumption and heating of the passively cooled lamp ballast that is attempting to <b>relight</b> the lamp.|$|R
50|$|<b>Relight</b> My Fire is {{the fourth}} {{full-length}} album from singer-songwriter Dan Hartman.|$|R
50|$|The song is {{from the}} 1979 Dan Hartman album <b>Relight</b> My Fire.|$|R
60|$|He paused, {{knocked out}} some ashes from his pipe, and <b>relighted</b> it.|$|R
60|$|Having {{said this}} the King <b>relighted</b> his pipe, which had gone out.|$|R
40|$|We {{present a}} novel method to <b>relight</b> video {{sequences}} for multimedia applications given known surface shape and original illumination. The method preserves fine visual details. It requires single view video frames, approximate 3 D shape and known illumination only, making it applicable for multimedia and studio production. The technique is demonstrated for <b>relighting</b> video sequences of faces. </p...|$|R
5000|$|Approximately 1,200 celebrants {{attended}} the May 2009 festival and <b>relighting</b> ceremony. An invocation by Frank Ettawageshik, of the Little Traverse Bay Bands of Odawa Indians, {{was followed by}} a [...] "stirring performance by four Native American drummers." [...] The official <b>relighting</b> was switched on by United States Senator Debbie Stabenow and James Tamlyn, Emmet County Board of Commissioners chairman.|$|R
40|$|In this paper, {{we present}} a novel {{framework}} to address the confounding effects of illumination variation in face recognition. By augmenting the gallery set with realistically relit images, we enhance recognition performance in a classifier-independent way. We describe a novel method for single-image <b>relighting,</b> Morphable Reflectance Fields (MoRF), which does not require manual intervention and provides <b>relighting</b> superior to that of existing automatic methods. We test our framework through face recognition experiments using various state-of-the-art classifiers and popular benchmark datasets: CMU PIE, Multi-PIE, and MERL Dome. We demonstrate that our MoRF <b>relighting</b> and gallery augmentation framework achieves improvements {{in terms of both}} rank- 1 recognition rates and ROC curves. We also compare our model with other automatic <b>relighting</b> methods to confirm its advantage. Finally, we show that the recognition rates achieved using our framework exceed those of state-of-the-art recognizers on the aforementioned databases. 1...|$|R
40|$|Abstract: With the {{development}} of digital library technology, library books made of paper can be digital released and read, and Endangered Cultural Heritages can be preserved. Traditional library’s contents and functions can be greatly enhanced by digital technologies. For these new library objects, the primary key problem is precisely reconstructing their 3 D models. When con-structing complete 3 D models, multiple color texture maps are often necessary. A commonly encountered problem uncounted during fusing of textures from multiple color images is color distortion. Each texture of a single 3 D model may be obtained under possibly different lighting conditions and color response of the camera. To remove any visible seam and improve color consistency between the textures while avoiding color distortion, we propose a new efficient algorithm to <b>relight</b> all the texture images globally, spread residual light difference, and recolor each image by homogeneous transformation. A relative illumination model was adopted to obtain the <b>relighting</b> function. We choose lαβ color space with minimal correlation between channels for many natural scenes, for calculating the <b>relighting</b> result. Looking into two overlapped images A and B, we can pairwise <b>relight</b> B into A’s luminosity condition in two steps. We first scale B’s l channel by the lA/lB ratio of the overlapped region. We can assume A and B are in a same color plane now. Then a homogeneous transformation is applied to B’s α and β channels which moves B into A’s hue and saturation condition. For multiple overlapped color textures, a patch based weighted global <b>relighting</b> method was proposed to minimize the total color difference. The pairwise <b>relighting</b> method was used between each two overlapped images, and the difference in every overlapped region after <b>relighting</b> was weighted and summed up to construct an energy value. We use...|$|R
60|$|Mabane paused. He {{looked at}} his pipe, {{but he did not}} <b>relight</b> it.|$|R
40|$|We {{present a}} {{practical}} approach for realistic rerendering of landscape photographs. We extract a view dependent depth map from single input landscape images by examining global and local pixel color distributions and demonstrate applications of depth dependent rendering such as novel viewpoints, digital refocusing and dehazing. We also present a simple approach to <b>relight</b> the input landscape photograph under novel sky illumination. Here, we assume diffuse reflectance and <b>relight</b> landscapes by estimating the irradiance due {{the sky in}} the input photograph. Finally, we also take into account specular reflections on water surfaces which are common in landscape photography and demonstrate a semiautomatic process for <b>relighting</b> scenes with still water...|$|R
50|$|It {{can extend}} depth-of-field, remove objects, stitch panoramas, and <b>relight</b> objects, among other features.|$|R
60|$|John {{laid the}} roll of bills beside his coffee cup, and <b>relighted</b> his cigar.|$|R
50|$|Beast is {{a content}} {{pipeline}} tool used for advanced global illumination and dynamic character <b>relighting.</b> Beast enables advanced global illumination that enhances {{the look of}} video games with little effort. Beast can precalculate lighting for light maps, shadow maps and point clouds, to bake occlusion or normal maps or to generate light fields for dynamic <b>relighting</b> of characters and objects.|$|R
40|$|This paper {{describes}} a <b>relighting</b> method of designing cinematic lighting for filmmaking. The <b>relighting</b> method enables mixed real-ity based pre-visualization called MR-PreViz to change conditions of illumination. The method allows the MR-PreViz to have ad-ditional virtual lighting and {{the removal of}} actual illumination in designing cinematic lighting. The effects of lighting are applied correctly to both real objects and virtual objects...|$|R
