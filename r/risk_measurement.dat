829|608|Public
2500|$|Investors in {{hedge funds}} are, in most countries, {{required}} to be qualified investors who {{are assumed to be}} aware of the investment risks, and accept these risks because of the potential returns relative to those risks. Fund managers may employ extensive risk management strategies in order to protect the fund and investors. According to the Financial Times, [...] "big hedge funds have some of the most sophisticated and exacting risk management practices anywhere in asset management." [...] Hedge fund managers that hold a large number of investment positions for short durations are likely to have a particularly comprehensive risk management system in place, and it has become usual for funds to have independent risk officers who assess and manage risks but are not otherwise involved in trading. A variety of different measurement techniques and models are used to estimate risk according to the fund's leverage, liquidity and investment strategy. Non-normality of returns, volatility clustering and trends are not always accounted for by conventional <b>risk</b> <b>measurement</b> methodologies and so in addition to value at risk and similar measurements, funds may use integrated measures such as drawdowns [...]|$|E
5000|$|The FRM Exam Part II {{focuses on}} the {{application}} of the tools acquired in the FRM Exam Part I through a deeper exploration of: Market <b>Risk</b> <b>Measurement</b> and Management, Credit <b>Risk</b> <b>Measurement</b> and Management, Operational and Integrated Risk Management, Risk Management and Investment Management, Current Issues in Financial Markets.|$|E
5000|$|OWASP {{proposes a}} {{practical}} <b>risk</b> <b>measurement</b> guideline based on: ...|$|E
40|$|The {{simulation}} of distributions of financial positions {{is an important}} issue for financial institutions. If risk measures are evaluated for a simulated distribution instead of the model-implied distribution, errors of <b>risk</b> <b>measurements</b> needs to be analyzed. For distribution-invariant risk measures which are continuous on compacts we employ the theory of large deviations to study the probability of large errors. If the approximate <b>risk</b> <b>measurements</b> are based on the empirical distribution of independent samples, the rate function equals the minimal relative entropy under a risk measure constraint. For shortfall risk and average value at risk (AVaR) we solve this minimization problem explicitly...|$|R
40|$|In {{order to}} manage model risk, {{financial}} institutions {{need to set}} up validation processes so as to monitor {{the quality of the}} models on an ongoing basis. Validation can be considered from both a quantitative and qualitative point of view. Backtesting and benchmarking are key quantitative validation tools, and the focus of this paper. In backtesting, the predicted <b>risk</b> <b>measurements</b> (PD, LGD, EAD) will be contrasted with observed measurements using a workbench of available test statistics to evaluate the calibration, discrimination and stability of the model. A timely detection of reduced performance is crucial since it directly impacts profitability and risk management strategies. The aim of benchmarking is to compare internal <b>risk</b> <b>measurements</b> with external <b>risk</b> <b>measurements</b> so as to better gauge the quality of the internal rating system. This paper will focus on the quantitative PD validation process within a Basel II context. We will set forth a traffic light indicator approach that employs all relevant statistical tests to quantitatively validate the used PD model, and document this approach with a real-life case study. The set forth methodology and tests are the summary of the authors' statistical expertise and experience of world-wide observed business practices...|$|R
50|$|The Controls section briefly {{introduces}} the three dimensions of a controls landscape.Measuring <b>Risk</b> briefly discusses <b>measurement</b> concepts and challenges, and then provides a high-level discussion of <b>risk</b> factor <b>measurements.</b>|$|R
50|$|The Advisory Board of The Journal of Performance Measurement {{inducted}} Black {{into the}} Performance & <b>Risk</b> <b>Measurement</b> Hall of Fame in 2017. The announcement {{appears in the}} Winter 2016/2017 issue of the journal. The Hall of Fame recognizes individuals who have {{made significant contributions to}} investment performance and <b>risk</b> <b>measurement.</b>|$|E
5000|$|An Introduction to Market <b>Risk</b> <b>Measurement</b> (2002). Hoboken, N.J.: John Wiley.|$|E
5000|$|Controlling {{interest}} rate risk and establishing {{interest rate}} <b>risk</b> <b>measurement</b> techniques ...|$|E
40|$|The aim {{of credit}} risk models is to {{identify}} and quantify future outcomes {{of a set of}} <b>risk</b> <b>measurements.</b> In other words, the model's purpose is to provide as good an approximation as possible of what constitutes the true underlying risk relationship between a set of inputs and a target variable. These parameters are used for regulatory capital calculations to determine the capital needed that serves a buffer to protect depositors in adverse economic conditions. In order to manage model risk, financial institutions need to set up validation processes so as to monitor the quality of the models on an ongoing basis. Validation is important to inform all stakeholders (e. g. board of directors, senior management, regulators, investors, borrowers, …) and as such allow them to make better decisions. Validation can be considered from both a quantitative and qualitative point of view. Backtesting and benchmarking are key quantitative validation tools. In backtesting, the predicted <b>risk</b> <b>measurements</b> (PD, LGD, CCF) will be contrasted with observed measurements using a workbench of available test statistics to evaluate the calibration, discrimination and stability of the model. A timely detection of reduced performance is crucial since it directly impacts profitability and risk management strategies. The aim of benchmarking is to compare internal <b>risk</b> <b>measurements</b> with external <b>risk</b> <b>measurements</b> so to allow to better gauge the quality of the internal rating system. This paper will focus on the quantitative PD validation process within a Basel II context. We will set forth a traffic light indicator approach that employs all relevant statistical tests to quantitatively validate the used PD model, and document this complete approach with a reallife case-study. Framework; Benchmarking; Credit; Credit scoring; Control;...|$|R
40|$|Risky {{conditions}} {{in conjunction with}} individuals' attitude to risk would normally lead to risk-averse behavior (Fishbein & Ajzen, 1975; Ajzen & Fishbein, 1980). In this research, risk-averse behavior (the dependent variable) relates to the "going-concern" opinion of financially distressed firms. A logistic regression model used as predictors of <b>risk</b> <b>measurements</b> (risky conditions and risk attitude) correctly predicts 97. 6...|$|R
40|$|In {{an earlier}} paper [11], the exact and {{complete}} return attribution framework of Singer and Karnosky [16] {{was extended to}} include market <b>risk</b> <b>measurements</b> for n countries. Exploiting a selection matrix based on the cash accounting identities, the resulting degenerate portfolio choice problem is solved as a lower dimensional, non-degenerate problem of fundamental investment choices between stock market premiums and currency swap returns...|$|R
50|$|A {{different}} approach to dynamic <b>risk</b> <b>measurement</b> has been suggested by Novak.|$|E
5000|$|Risk Management and Modelling Group - {{point of}} contact with the {{industry}} on the latest advances in <b>risk</b> <b>measurement</b> and management ...|$|E
50|$|There {{are various}} ways to {{quantify}} the error of some estimates. One approach is to estimate a confidence interval of the <b>risk</b> <b>measurement.</b>|$|E
40|$|Portfolio {{rebalancing}} {{strategy is}} of great importance {{to minimize the risk}} taken so as to ensure profitable investments. Regular rebalancing keeps the portfolio developing as it was planned and achieved initial invest goals. The relevant literature of the technical analysis on rebalancing strategy is scarce. After elaborating the four traditional rebalancing strategies and a set of <b>risk</b> <b>measurements,</b> the thesis proposed the multiplier rebalancing strategy, which combines the traditional periodically rebalancing strategy with the interval rebalancing strategy, and Relative Strength Index (RSI) rebalancing strategy based on technical analysis. In order {{to evaluate the effectiveness of}} the multiplier and RSI rebalancing strategies, the thesis conducts an experiment to compare the performances of two proposed strategies with the other four traditional strategies in terms of the rewards and <b>risk</b> <b>measurements</b> by using nineteen years Canadian stock and bond Indices and Exchange Traded Funds data from 1983 to 2010. [...] Leaf ii. The original print copy of this thesis may be available here: [URL]...|$|R
40|$|The {{ability of}} the Generalised Extreme Value and Generalised Logistic {{distributions}} to describe adequately extreme financial returns is examined. The empirical results strongly reject the Generalised Extreme Value in favour of the fatter tailed Generalised Logistic. This implies that <b>risk</b> <b>measurements</b> {{which are based on}} the Generalised Extreme Value may underestimate risk since it assigns lower probabilities to the really ruinous events located deep into the tails of the returns distribution...|$|R
25|$|Mathematical <b>risk</b> <b>measurements</b> {{are also}} useful {{only to the}} degree that they reflect investors' true concerns—there is no point {{minimizing}} a variable that nobody cares about in practice. MPT uses the mathematical concept of variance to quantify risk, and this might be justified under the assumption of elliptically distributed returns such as normally distributed returns, but for general return distributions other risk measures (like coherent risk measures) might better reflect investors' true preferences.|$|R
50|$|The basic {{approach}} or {{basic indicator}} approach {{is a set of}} operational <b>risk</b> <b>measurement</b> techniques proposed under Basel II capital adequacy rules for banking institutions.|$|E
50|$|The term {{standardized}} approach (or standardised approach) {{refers to}} a set of credit <b>risk</b> <b>measurement</b> techniques proposed under Basel II capital adequacy rules for banking institutions.|$|E
5000|$|Advanced Measurement Approaches - {{based on}} the {{internally}} developed <b>risk</b> <b>measurement</b> framework of the bank adhering to the standards prescribed (methods include IMA, LDA, Scenario-based, Scorecard etc.) ...|$|E
40|$|Abstract — The {{ability of}} the Generalised Extreme Value and Generalised Logistic {{distributions}} to describe adequately extreme financial returns is examined. The empirical results strongly reject the Generalised Extreme Value in favour of the fatter tailed Generalised Logistic. This implies that <b>risk</b> <b>measurements</b> {{which are based on}} the Generalised Extreme Value may underestimate risk since it assigns lower probabilities to the really ruinous events located deep into the tails of the returns distribution...|$|R
50|$|FactSet {{provides}} {{financial information}} and analytical applications to global buy and sell-side professionals, including portfolio managers, market research and performance analysts, risk managers, sell-side equity researchers, investment bankers, and fixed income professionals. FactSet's software platform, also called FactSet, includes real-time news and quotes, company and portfolio analysis, multi-company comparisons, industry analysis, company screening, portfolio optimization and simulation, predictive <b>risk</b> <b>measurements,</b> alphatesting and tools to value and analyze {{fixed income securities}} and portfolios.|$|R
40|$|The paper {{discusses}} {{the development of}} a device for directional characteristics measurements of RFID tags marked objects. Current procedures for carrying out laboratory tests of UHF RFID devices rely on relatively high involvement of human labour associated with higher <b>risk</b> of <b>measurements</b> errors. The newly developed system that performs great part of manual operations autonomously reduces the <b>risk</b> of <b>measurement</b> errors and enables experiments to be performed faster, more accurate and in repeatable manner...|$|R
50|$|In {{the context}} of {{operational}} risk, the standardized approach or standardised approach {{is a set of}} operational <b>risk</b> <b>measurement</b> techniques proposed under Basel II capital adequacy rules for banking institutions.|$|E
50|$|The term Advanced IRB or A-IRB is an {{abbreviation}} {{of advanced}} internal ratings-based approach, and {{it refers to}} a set of credit <b>risk</b> <b>measurement</b> techniques proposed under Basel II capital adequacy rules for banking institutions.|$|E
5000|$|... vielife {{has done}} {{research}} into the effect of health promotion on employee health risks and work productivity; {{the development of a}} corporate health <b>risk</b> <b>measurement</b> tool; and the effect of office lighting on employee well-being and work performance.|$|E
40|$|Singer and Karnosky's (1995) exact and {{complete}} return attribution framework {{does not account}} for risk, since it ignores accumulated historical information. Its implied investment strategy selection is based on simple return maximization and ignores that investment strategies are correlated via intra- and inter-market risks. Using simple tensor algebra we extend their exact accounting framework to include market <b>risk</b> <b>measurements</b> for n countries. The resulting n&sup 2; &times; n&sup 2; strategy risk matrix [...] ...|$|R
50|$|Mathematical <b>risk</b> <b>measurements</b> {{are also}} useful {{only to the}} degree that they reflect investors' true concerns—there is no point {{minimizing}} a variable that nobody cares about in practice. MPT uses the mathematical concept of variance to quantify risk, and this might be justified under the assumption of elliptically distributed returns such as normally distributed returns, but for general return distributions other risk measures (like coherent risk measures) might better reflect investors' true preferences.|$|R
50|$|Danielsson and {{his colleagues}} have {{expressed}} concerns about systemic <b>risk</b> <b>measurements,</b> such as SRISK and CoVaR, because they are based on market outcomes that happen multiple times a year, so that the probability of systemic risk as measured does not correspond to the actual systemic risk in the financial system. They argue that systemic financial crises happen once every 43 years for a typical OECD country and that <b>measurements</b> of systemic <b>risk</b> should target that probability.|$|R
50|$|In {{the context}} of <b>risk</b> <b>measurement,</b> a risk metric is the concept {{quantified}} by a risk measure. When choosing a risk metric, an agent is picking an aspect of perceived risk to investigate, such as volatility or probability of default.|$|E
50|$|Although some of {{the sources}} listed here treat only one kind of VaR as legitimate, most of the recent ones seem to agree that risk {{management}} VaR is superior for making short-term and tactical decisions today, while <b>risk</b> <b>measurement</b> VaR {{should be used for}} understanding the past, and making medium term and strategic decisions for the future. When VaR is used for financial control or financial reporting it should incorporate elements of both. For example, if a trading desk is held to a VaR limit, that is both a risk-management rule for deciding what risks to allow today, and an input into the <b>risk</b> <b>measurement</b> computation of the desk's risk-adjusted return {{at the end of the}} reporting period.|$|E
50|$|The {{book also}} boasts a first in its area {{in that it}} brings {{together}} previously separated topics and practitioners or ex-post performance measurement and ex-ante performance <b>risk</b> <b>measurement.</b> It is also the first book to explain {{the role of the}} Transition Manager.|$|E
40|$|This paper {{develops}} a contingent claim model to analyze {{certain aspects of}} retail leasehold contracts. The approach allows for the explicit consideration of risk without any ad hoc risk adjustment. Both "straight" leases and "percentage" leases are examined with the value of sales as the underlying asset. Each lease value is expressed as a combination of options on sales. The effects of the lease value's determinants and equilibrium <b>risk</b> <b>measurements</b> are also analyzed. Copyright American Real Estate and Urban Economics Association. ...|$|R
5000|$|Introduce {{additional}} safeguards against model <b>risk</b> and <b>measurement</b> error by supplementing {{the risk}} based measure with a simpler measure {{that is based}} on gross exposures.|$|R
40|$|Various {{concepts}} {{appeared in}} the existing literature to evaluate the risk exposure of a financial or insurance firm/subsidiary/line of business due to the occurrence of some extreme scenarios. Many of those concepts, such as Marginal Expected Shortfall or Tail Conditional Expectation, are simply some conditional expectations that evaluate the risk in adverse scenarios and are useful for signaling to a decision-maker the poor performance of its risk portfolio or to identify which sub-portfolio is likely to exhibit a massive downside risk. We investigate the latter risk {{under the assumption that}} it is measured via a coherent risk measure, which obviously generalizes the idea of only taking the expectation of the downside risk. Multiple examples are given and our numerical illustrations show how the asymptotic approximations can be used in the capital allocation exercise. We have concluded that the expectation of the downside risk does not fairly take into account the individual risk contribution when allocating the VaR-based regulatory capital, and thus, more conservative <b>risk</b> <b>measurements</b> are recommended. Finally, we have found that more conservative <b>risk</b> <b>measurements</b> do not improve the fairness of the cost of capital allocation when the uncertainty with parameter estimation is present, even at a very high level...|$|R
