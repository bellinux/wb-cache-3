10|44|Public
50|$|Suffix {{validation}} requires additional investigation. <b>Record</b> <b>layout</b> specifications {{indicate the}} suffix is always “ØØ” for facility records, or a sequentially ascending suffix beginning at “FØ” for prescriber or location records. This would imply a suffix of '10' is invalid.|$|E
50|$|The {{database}} access program is already compiled. It reads database description files at run time. The <b>record</b> <b>layout</b> and validation criteria are specified in one schema file. The specifications for the screen displays are entered into format files. Both {{are created by}} the user with any text editor. A variety of formats may be created to view or update different parts of a database record.|$|E
40|$|This paper {{describes}} {{our project}} to electronically disseminate the Integrated Public Use Microdata Series (IPUMS). The IPUMS—the world’s largest publicly available demographic database—is a coherent series of individual-level census data drawn from eleven census years between 1850 and 1990. Prior to the IPUMS, the U. S. census samples were a haphazard assortment of files created by different researchers at different times, {{each with its}} own unique <b>record</b> <b>layout</b> and codin...|$|E
50|$|Finally, John Szuch at Deep Elm Records is {{responsible}} for the <b>record's</b> <b>layout</b> and design.|$|R
5000|$|Jesse F. Keeler - bass, synthesizer, songwriting, <b>recording,</b> design, <b>layout</b> ...|$|R
40|$|Turning health-care {{data files}} (such as Medicare data) into SAS ® data sets {{can be a}} complex and {{cumbersome}} process. To facilitate the processing of Medicare data, the Center for Medicare and Medicaid Services (CMS) provides documentation (generally referred to as <b>record</b> <b>layouts)</b> that defines the structure and content of CMS data files. Although this metadata documentation has a clearly defined structure, it can be somewhat irregular. Regardless of this, SAS can process these metadata files and translate the health-care data files into SAS data sets. This paper presents a technique for using the capabilities of Perl Regular Expressions in the SAS® 9 version of Base SAS to programmatically perform an extract, transform, and load (ETL) process {{that is based on}} the CMS <b>record</b> <b>layouts.</b> This ETL process turns CMS data files into SAS data sets...|$|R
40|$|Background: The VDW TUMOR {{database}} {{is constructed}} using nationally standardized variable definitions. The North American Association of Central Cancer Registries (NAACCR) {{is a professional}} agency for establishing data standards. The database is NAACCR compatible with respect to variable definitions and <b>record</b> <b>layout.</b> Many of the CRN sites are also Surveillance, Epidemiology, and End Results (SEER) Program sites. SEER collects data from specific geographic regions representing 26 % of US population and is demographically diverse. Access to SEER data provides a mature data source and familiar variable list for use in cancer research. Non SEER site can access comparable data using either hospital based or State based data collection systems...|$|E
40|$|Comments and {{suggestions}} {{on this and}} other NAACCR standards documents are welcome. Please send your comments to the Editor or {{any member of the}} NAACCR Board of Directors. The other volumes in the series, Standards for Cancer Registries, are: � Volume I, Data Exchange Standards and Record Description Intended for programmers and selected users of central cancer registry data, this Volume provides the record layouts and specifications for a number of standard NAACCR record formats, including: the standard record layouts for data exchange among central cancer registries; an update/correction record layout; and an analysis <b>record</b> <b>layout</b> that provides standard recodes for grouping selected variables such as race and primary site, as well as algorithms for converting data from one version of the International Classification of Diseases for Oncology to another...|$|E
40|$|Comments and {{suggestions}} {{on this and}} other NAACCR standards documents are welcome. Please send your comments to the Editor or {{any member of the}} NAACCR Board of Directors. The other volumes in the series, Standards for Cancer Registries, are:! Volume I, Data Exchange Standards and Record Description Intended for programmers, this provides the <b>record</b> <b>layout</b> and specifications for the standard for data exchange, including correction and analysis formats. Released annually as an electronic document and posted on the NAACCR Web Site. ! Volume III, Standards for Completeness, Quality, Analysis, and Management of Data Intended for central registries, this provides detailed standards for many aspects of the operation of a population-based cancer registry. ! Volume IV, Standard Data Edits This documents standard computerized edits for data corresponding to the data standards in Volume II...|$|E
40|$|Institute of Computational Linguistics in its fifty-year {{history has}} {{accumulated}} {{a wide variety}} of texts and corpora that have been stored in various formats and <b>record</b> <b>layouts.</b> Today, the memory of the procedures and codes of the past is still documented and the people who worked there are in service, we must thus plan a recovery strategy that maintains digital preservation and reuse...|$|R
5000|$|By {{the late}} 1940s, the {{magazines}} ties to The New Yorker were {{so strong that}} designers from that magazine consulted on The <b>Records</b> <b>layout</b> and design. By the 1950s, the Record had established the [...] "Cartoonist of the Year" [...] award, which brought people like Walt Kelly, the creator of Pogo, to New Haven to dine and swap stories with the staff.|$|R
5000|$|Crude Oil Data Exchange (CODE) is an {{electronic}} business standard {{sanctioned by the}} American Petroleum Institute. [...] CODE was initially implemented as the standard in 1978. It provides field formats and <b>record</b> <b>layouts</b> to facilitate the transmission of crude oil run tickets between oil producers and oil transporters. Oil statement records {{were added to the}} system in January 1986. In 1989, tank increment records were added to the standard.|$|R
40|$|The National Death Index (NDI) is {{a central}} {{computerized}} index of death record information on file in the state vital statistics offices. Working with these state offices, NCHS established the NDI as a resource to aid epidemiologists and other health and medical investigators with their mortality ascertainment activities. Suggested citation: National Center for Health Statistics. National Death Index user 22 ̆ 0 ac 2 ̆ 122 s guide. Hyattsville, MD. 2013. NDI data use restrictions [...] NCHS confidentiality and data security provisions [...] Chapter 1. How to use the National Death Index: steps in the process [...] Chapter 2. Preparing your records: <b>record</b> <b>layout</b> and coding specifications [...] Chapter 3. Your NDI results [...] Chapter 4. Assessing NDI output [...] Appendix A. Probabilistic scoring approach for assessing National Death Index match results [...] Appendix B. Coded causes of death [...] Exhibits [...] Appendix table. Surveillance and Investigatio...|$|E
40|$|Chair, Volume II Subcommittee of the Uniform Data Standards Committee Comments and {{suggestions}} {{on this and}} other NAACCR standards documents are welcome. Please send your comments to the Editor or {{any member of the}} NAACCR Board of Directors. The other volumes in the series, Standards for Cancer Registries, are: Volume I, Data Exchange Standards and Record Description Intended for programmers and selected users of central cancer registry data, this Volume provides the record layouts and specifications for a number of standard NAACCR record formats, including: the standard record layouts for data exchange among central cancer registries; an update/correction record layout; and an analysis <b>record</b> <b>layout</b> that provides standard recodes for grouping selected variables such as race and primary site, as well as algorithms for converting data from one version of the International Classification of Diseases for Oncology to another. Volume III, Standards for Completeness, Quality, Analysis, and Management of Data Intended for central registries, this provides detailed standards for many aspects of the operation of a population-based cancer registry. Volume IV, Standard Data Edit...|$|E
40|$|This paper {{illustrates}} how to design an appropriate input program {{to handle a}} complex file layout using data collected from pharmacy and health insurance information about individuals. Various INFILE and INPUT options are illustrated in the process, and some related functions are considered. The input file is the output of a COBOL program pulling data from a DB 2 database which is then brought to the PC via FTP. Each record contains 6 types of information, called segments, for a person. The segments and the fields within are divided by unprintable hexadecimal codes, which SAS represents with notations like the hexadecimal numbers 1 E (Segment separator) and 1 C (Field separator) respectively. A further complication {{is the use of}} 1 D which is the group separator to separate repeating segments. There are also groups of repeating fields within a segment. Since the fields do not have a fixed length and they may be missing on some records, there is no fixed <b>record</b> <b>layout</b> for the file. Although the program was written for the PC, the technique is applicable for any system. All the tools discussed are in BASE SAS ®. The typical attendee or reader will have some experience in SAS, but not a lot of experience dealing with the input of external data...|$|E
50|$|A design <b>layout</b> <b>record</b> (DLR) {{or circuit}} <b>layout</b> <b>record</b> (CLR) {{is used in}} the {{telecommunication}} industry to describe the detailed design path of a completed circuit, including all equipment and network components {{from one end of the}} circuit to the other.|$|R
40|$|A {{computer-based}} system to produce listings of topical sub;ect terms and geographically subdivided terms is described. The system files and their associated listings {{are called the}} Subject Authority File (SAF) and the Geographic Authority File (GAF). Conversion, operation, problems, and costs of the system are presented. Details of the optical scanning conversion, with illustrations, show the relative ease of the technique for simple upper case data files. Program and data characteristics are illustrated with <b>record</b> <b>layouts</b> and sample listings...|$|R
5000|$|Aleksi Munter - keyboards; <b>recording,</b> art direction, <b>layout,</b> {{photography}} ...|$|R
40|$|Background: Pharmacies {{often provide}} {{prescription}} records to private research firms, {{on the assumption}} that these records are de-identified (i. e., identifying information has been removed). However, concerns have been expressed about the potential that patients can be re-identified from such records. Recently, a large private research firm requested prescription records from the Children’s Hospital of Eastern Ontario (CHEO), {{as part of a larger}} effort to develop a database of hospital prescription records across Canada. Objective: To evaluate the ability to re-identify patients from CHEO’S prescription records and to determine ways to appropriately de-identify the data if the risk was too high. Methods: The risk of re-identification was assessed for 18 months’ worth of prescription data. De-identification algorithms were developed to reduce the risk to an acceptable level while maintaining the quality of the data. Results: The probability of patients being re-identified from the original variables and data set requested by the private research firm was deemed quite high. A new de-identified <b>record</b> <b>layout</b> was developed, which had an acceptable level of re-identification risk. The new approach involved replacing the admission and discharge dates with the quarter and year of admission and the length of stay in days, reporting the patient’s age in weeks, and including only the first character of the patient’s postal code. Additional requirements were included in the data-sharing agreement with the private research firm (e. g., audit requirements and a protocol for notification of a breach of privacy). Conclusions: Without a formal analysis of the risk of re-identification, assurances of data anonymity may not be accurate. A formal risk analysis at one hospital produced a clinically relevant data set that also protects patient privacy and allows the hospital pharmacy to explicitly manage the risks of breach of patient privacy...|$|E
50|$|Photographer Tyler Coray {{took the}} {{photograph}} {{on the cover}} of the <b>record.</b> Design and <b>layout</b> by Derek Vander Griend.|$|R
40|$|Rapid {{advances}} in microcomputer processing power have accelerated {{the development of}} multi-object databases. These new information constructs require different <b>record</b> <b>layouts,</b> demand the inclusion on non-searchable strings, and place different demands upon the query logic in the software and {{in the mind of}} the searcher. Traditional databases are typically collections of fairly uniform records. These are usually abstracts, indices, and full text in a range of combinations. Such traditional databases are collections or small data constructs. The new databases combine text, images, recorded or synthesized voice, and other objects. Databases that contain multiple objects represent the data. Such representations are large data constructs. This new terminology reminds the database builder and the consumer of information that fundamentally different approaches to large data constructs are the only way to explore these radically different databases. Berkeley Sunday: Hit Fat Apple’s, check out the New York Times and Sun Jose Mercury News, ond flip through the most recent Whole forth Review. I am sitting in the sun an...|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceIn this paper, {{a method}} based {{on part of}} speech tagging (PoS) is used for bibliographic {{reference}} structure. This method operates on a roughly structured ASCII file, produced by OCR. Because of the heterogeneity of the reference structure, the method acts in a bottom up way, without an a priori model, gathering structural elements from basic tags to sub-fields and fields. Significant tags are first grouped in homogeneous classes according to their grammar categories and then reduced in canonical forms corresponding to record fields: ``authors'', title, conference name, date, etc. Non labelled tokens are integrated in one or another field by either applying PoS correction rules or using a structure model generated from well detected records. The designed prototype operates with a great satisfaction on different <b>record</b> <b>layouts</b> and character recognition qualities. Without manual intervention, 96. 6 % words are correctly attributed, and about 75, 9 % references are completely segmented from 2500 references...|$|R
40|$|In this paper, {{a method}} based on part-of-speech tagging (PoS) {{is used for}} bibliographic {{reference}} structure. This method operates on a roughly structured ASCII file, produced by OCR [...] Because of the heterogeneity of the reference structure, the method acts in a bottom-up way, without an a priori model, gathering structural elements from basic tags to sub-fields and fields. Significant tags are first grouped in homogeneous classes according to their categories and then reduced in canonical forms corresponding to record fields: ``authors'', “title”, “conference name”, “date”, etc. Non labeled tokens are integrated in one or another field by either applying PoS correction rules or using a inter- or intra-field model generated from well-detected records. The designed prototype operates with a great satisfaction on different <b>record</b> <b>layouts</b> and character recognition qualities. Without manual intervention, 96. 6 % words are correctly attributed, and about 75, 9 % references are completely segmented from 2, 575 references. 1...|$|R
40|$|This paper {{reports on}} the {{accident}} research carried out {{as a part of}} a large project started in 1983. For this accident research an inventory was made of a large number of intersections. <b>Recorded</b> were <b>layout</b> features, accident data and estimates of traffic volumes. Attention will be given to the preparations for this activity, to the analysis and to the results. The initial conclusions are presented...|$|R
5000|$|In 2004, The Mind's I was re-released under Osmose Productions and in 2005 by Century Media <b>Records</b> {{with new}} <b>layouts,</b> the four-song Enter Suicidal Angels EP, two live videos {{and the music}} video for the song [...] "Hedon".|$|R
25|$|Market Square. Now {{the main}} street of Carlingford, this was the area where a weekly market was held with <b>records</b> of its <b>layout</b> going back to 1358. It is now the {{intersection}} of Dundalk Street and the beginning of River Lane.|$|R
500|$|After {{a five-day}} journey down the Holston, French Broad, and Little Tennessee rivers, Timberlake {{arrived in the}} Overhill town of Tomotley. There he was greeted by Ostenaco and {{witnessed}} a ceremonial return of a Cherokee war party. [...] After smoking a peace pipe with Ostenaco, Timberlake proceeded southward to Chota, where he was met by some 400 Cherokee. [...] Timberlake smoked a peace pipe with several tribal leaders, and <b>recorded</b> the <b>layout</b> and design of the town's large council-house.|$|R
50|$|Stanley Ipkiss is a shy and unlucky bank clerk {{working at}} the local Edge City bank. He is {{frequently}} ridiculed by everyone around him, except for his Jack Russell Terrier Milo, and his co-worker and best friend Charlie Schumaker. Meanwhile, gangster Dorian Tyrell, owner of the Coco Bongo nightclub, plots to overthrow his boss Niko. One day, Tyrell sends his singer girlfriend Tina Carlyle into Stanley's bank to <b>record</b> its <b>layout,</b> in preparation to rob the bank.|$|R
25|$|Due to the {{temporary}} {{nature of the}} station, no images of it or <b>records</b> of its <b>layout</b> are known to exist, but a contemporary engraving by George Dodgson Callow and William Radclyffe shows a train on the bridge in its immediate vicinity.|$|R
5000|$|The {{suggestion}} for these files came from Luria Ben-Zion, an historian from the Hebrew University of Jerusalem, {{who wrote in}} 1940 to the Jewish National Fund (JNF) that [...] "This would greatly help the redemption of the land". Yossef Weitz, {{the head of the}} JNF settlement department immediately suggested that they be turned into a [...] "national project". Yitzhak Ben-Zvi suggested that, apart from topographically <b>recording</b> the <b>layout</b> of the villages, the project should also include exposing the [...] "Hebraic origins" [...] of each village.|$|R
50|$|On 28 November 1942, {{following}} the German {{invasion of the}} Zone Libre, Jacques Chastenet and Émile Mireaux, the two co-directors of Le Temps, jettisoned the newspaper. At Charles de Gaulle's request, Le Monde was founded on 19 December 1944 to replace Le Temps as the newspaper of <b>record,</b> borrowing the <b>layout</b> and typeface of Le Temps for the new newspaper.|$|R
5000|$|The villa has a {{generally}} fortified appearance; it is block-like with corner bastions {{and has a}} belvedere terrace at the top; there were occasional attacks by pirates along the coast. The plan <b>layout,</b> <b>recorded</b> in drawings by Pier Leone Ghezzi (circa 1735), is simple and straightforward and lacks the formal inventiveness of Cortona's later architectural work, including the Villa Pigneto del Marchese Sacchetti.|$|R
500|$|At its {{greatest}} extent, in the mid-16th century, the Little Moreton Hall estate occupied {{an area of}} [...] and contained a cornmill, orchards, gardens, and an iron bloomery with water-powered hammers. The gardens lay abandoned until their 20th-century re-creation. As there were no surviving <b>records</b> of the <b>layout</b> of the original knot garden it was replanted according to a pattern published in the 17th century.|$|R
5000|$|This re-recorded version (of the {{original}} four {{songs on the}} [...] "December EP" [...] plus [...] "Disclosure") was recorded @ Jumbosound Studios in El Cajon, California. Produced and mixed by Sean O'Donnell. The songs were re-worked, with new instrumentation and arrangements. It was done {{in an attempt to}} [...] "right the wrongs" [...] of what happened with the first <b>recording</b> in 2002. <b>Layout</b> by Brady Clark.|$|R
50|$|The castle is an {{excellent}} example of a renaissance flatland fortification, and retains its trapezoidal 16th-century <b>layout.</b> <b>Records</b> suggest construction took place in three phases: between 1530 and 1550, the basic fortress took shape, with four corner towers connected by walls; between 1567 and 1579, when the east and west tracts were added; and finally, between 1586 and 1590 or 1601, the northern tract and arcaded inner passageways.|$|R
40|$|The {{database}} contains records each {{representing a}} language {{in contact with}} another language or group of languages. Each <b>record</b> contains several <b>layouts,</b> each layout is devoted to a particular domain of structure. The records provide information about the structural categories, domains, and sub-categories that are affected by contact, the type of contact influence (matter or pattern replication), and text fields provide glossed examples of structures that {{are believed to have}} emerged as a result of contact. The entire database can be queried for any of the above information...|$|R
