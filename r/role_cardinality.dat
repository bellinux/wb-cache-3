0|17|Public
5000|$|A Gellish Fact Table {{consists}} of columns {{for the main}} fact {{and a number of}} columns for auxiliary facts. The auxiliary facts enable to specify things such as <b>roles,</b> <b>cardinalities,</b> validity contexts, units of measure, date of latest change, author, references, etcetera.: The columns for the main fact in a Fact Table are: - a UID of the fact that is expressed on this row in the table [...] - a UID of the intention with which the fact is communicated or stored (e.g. as a statement, a query, etc.) [...] - a UID of a left-hand object [...] - a UID of a relation type [...] - a UID of a right-hand object [...] - a UID of a unit of measure (optional) [...] - a string that forms a description (textual definition) of the left hand object.|$|R
40|$|For {{the basic}} Description Logics {{reasoning}} {{with respect to}} finite models amounts to reasoning with respect to arbitrary ones, but finiteness of the domain needs to be considered if expressivity is increased and the finite model property fails. Procedures for reasoning with respect to arbitrary models in very expressive Description Logics have been developed, {{but these are not}} directly applicable in the finite case. We first show that we can nevertheless capture a restricted form of finiteness and represent finite modeling structures such as lists and trees, while still reasoning with respect to arbitrary models. The main result of this paper is a procedure to reason with respect to finite models in an expressive Description Logic equipped with inverse <b>roles,</b> <b>cardinality</b> constraints, and in which arbitrary inclusions between concepts can be specified without any restriction. This provides the necessary expressivity to go beyond most semantic and object-oriented Database models, and capt [...] ...|$|R
40|$|International audienceRole-Based Access Control (RBAC) {{models are}} {{becoming}} a de facto standard, greatly simplifying management and administration tasks. Organizational constraints were introduced (e. g. : mutually exclusive <b>roles,</b> <b>cardinality,</b> prerequisite <b>roles)</b> to reflect peculiarities of organizations. Thus, the number of rules is increasing and policies {{are becoming more and}} more complex: understanding and analyzing large policies in which several security officers are involved can be a tough job. There is a serious need for administration tools allowing analysis and inference on access control policies. Such tools should help security officers to avoid defining conflicting constraints and inconsistent policies. This paper shows that theoretical tools from relational databases are suitable for expressing and inferring on RBAC policies and their related constraints. We focused on using Constrained Tuple-Generating Dependencies (CTGDs), a class of dependencies which includes traditional other ones. We show that their great expressive power is suitable for all practical relevant aspects of RBAC. Moreover, proof procedures have been developed for CTGDs: they permit to reason on policies. For example, to check their consistency, to verify a new rule is not already implied or to check satisfaction of security properties. A prototype of RBAC policies management tool has been implemented, using CTGDs dedicated proof procedures as the underlying inference engine...|$|R
40|$|Many {{semantic}} web applications require support for mappings between roles (or properties) defined in multiple independently developed ontology modules. Distributed Description Logics (DDL) and Package-based Description Logics (P-DL) offer alternative logical formalisms that support such mappings. We prove that (a) variants of DDL that allow negated <b>roles</b> or <b>cardinality</b> restrictions in bridge rules or inverse bridge rules that connect ALC ontologies are undecidable; (b) {{a variant of}} P-DL ALCHIO(¬) P that support role mappings between ontology modules in ALCHIO(¬) (an extension of ALC that allows general role inclusions, inverse roles, nominals and negated roles) is decidable...|$|R
40|$|This paper {{presents}} {{current work}} on generating textual explanations for subsumption within an expressive fraction of OWL Lite TBoxes. Our approach {{is based on}} a tableau-style algorithm. We describe how to explain subsumptions within ALE extended by <b>role</b> hierarchies, transitivity, <b>cardinality</b> restrictions, and domain as well as range restrictions. We also illustrate some optimization features, comment on our implementation, and discuss future extensions concerning more expressive languages. ...|$|R
40|$|Abstract — Fuzzy Databases {{have been}} a fertile {{research}} area that has produced {{a wide variety of}} remarkable solutions for the storage and manipulation of imperfect information. Proposals {{can be found in the}} three most relevant data models: relational, object-oriented, and object-relational. Query capabilities have been especially studied in the context of the relational data model, while in object models many problems continue being a matter of research. In this paper, we focus on the resolution of “division queries ” (in its relational sense) in an object oriented data model. As we will see, the presence of fuzzily described objects in the database make necessary to use suitable operators that take into account the resemblance that governs the comparison in the underlying reference universe. We also analyze the <b>role</b> of <b>cardinality</b> in this kind of queries...|$|R
40|$|The {{division}} operator {{is well known}} in the context of fuzzy relational databases. Fuzzy approaches to this operator {{can be found in the}} literature to solve flexible queries: these approaches try to compute to which extent each element of a candidate set is connected with a given (fuzzy) set of elements. This kind of queries is also interesting in the framework of fuzzy object databases, where the management of complex objects instead of plain tuples causes additional difficulties. The presence of fuzzily described objects in the database makes necessary to use suitable operators that take into account the resemblance that governs the comparison in the underly-ing reference universe. In this paper, we propose a method to solve this type of queries founded on the use of fuzzy inclusion operators. We study two different alternatives for the way resemblance is considered and we also analyze the <b>role</b> of <b>cardinality</b> in the process...|$|R
40|$|No-Free-Lunch Theorems state, roughly speaking, {{that the}} {{performance}} of all search algorithms is the same when averaged over all possible objective functions. This fact was precisely formulated {{for the first time}} in a now famous paper by Wolpert and Macready, and then subsequently refined and extended by several authors, always in the context of a set of functions with discrete domain and codomain. Recently, Auger and Teytaud have shown that for continuum domains there is typically no No-Free-Lunch theorems. In this paper we provide another approach, which is simpler, requires less assumptions, relates the discrete and continuum cases, and that we believe that clarifies the <b>role</b> of the <b>cardinality</b> and structure of the domain...|$|R
40|$|For the {{mainstream}} relational database management systems, histograms play im-portant <b>roles</b> in <b>cardinality</b> estimation. The main histogram-based cardinality estimation approaches {{can be classified}} into two categories: proactive approaches and reactive ap-proaches. For the former, histograms are constructed and updated by periodical data scan {{which is also the}} essential reason affecting the accuracy and performance of this kind of approaches. Data scan is avoided in the latter, as an alternative, query feedback records (QFRs) are collected to construct and update histograms. But some time-consuming al-gorithms such as the effective QFR set calculation, the hole drilling algorithm and the iterative scaling algorithm are used by reactive approaches, which makes it inefficient. In this paper, we address cardinality estimation issue with a new notion and propose a novel cardinality estimation approach by combining proactive approach with QFRs. In our approach, data scan will be executed only once to construct the initial first-level his-togram. And then, corresponding to all buckets of the first-level histogram, second-level histograms will be constructed and updated based on QFRs. The existence of sec-ond-level histograms and the elaborated mechanism dealing with the data update proble...|$|R
40|$|This paper {{proposes a}} logic based {{framework}} that extends role based access control systems with dynamic delegation in a decentralised environment. It allows delegation of administrative privileges for both roles and access rights between roles. We have introduced {{the notion of}} trust in delegation and have shown how extended logic programs {{can be used to}} express and reason about roles and their delegations with trust degrees, roles' privileges and their propagations, delegation depth as well as conflict resolution. Furthermore, our framework is able to enforce various role constraints such as separation of duties, <b>role</b> composition and <b>cardinality</b> constraints. The implementation of the framework is also discussed. The proposed framework is flexible and provides a sound basis for specifying and evaluating sophisticated role based access control policies in decentralised environments. 25 page(s...|$|R
40|$|It {{has been}} a subject of a {{significant}} amount of research to automate the execution of workflows (or business processes) on computer resources. However, many workflow scenarios still require human involvement, which introduces additional security and authorization concerns. This paper presents a novel mechanism for modeling the execution of workflows with human involvement under Role-based Authorization Control. Our modeling approach applies Colored Timed Petri-Nets to allow various authorization constraints to be modeled, including <b>role,</b> temporal, <b>cardinality,</b> BoD (Binding of Duty), SoD (Separation of Duty), role hierarchy constraints etc. We also model the execution of tasks with different levels of human involvement and as such allow the interactions between workflow authorization and workflow execution to be captured. The modeling mechanism is developed {{in such a way that}} the construction of the authorization model for a workflow can be automated. This feature is very helpful for modeling large collections of authorization policies and/or complex workflows. A Petri-net toolkit, the CPN Tools, is utilized in the development of the modeling mechanism and to simulate the constructed models. This paper also presents the methods to analyze and calculate the authorization overhead as well as the performance data in terms of various metrics through the model simulations. Based on the simulation results, this paper further proposes the approaches to improving performance given the deployed authorization policies. This work can be used for investigating the impact of authorization, for capacity planning, for the design of workload management strategies, and also to estimate execution performance, when human resources and authorization policies are employed in tandem...|$|R
40|$|AbstractSemialgebraic sets (subsets of Rn {{defined by}} {{polynomial}} inequalities) and (discontinuous) semialgebraic maps form a category {{with many of}} the desirable properties of the category of finite sets, suggesting that groups in this category should be somewhat like finite groups. We develop this idea, in the more general setting of the category of definable sets and maps in an o-minimal structure. In this category Euler characteristic plays the <b>role</b> played by <b>cardinality</b> in the category of finite sets. We generalize Sylow's theorems to definable groups, with some new features arising: there are 0 -groups as well as p-groups. Introducing the notion of parametrizable sets of definable subgroups allows us to generalize the Sylow-Frobenius theorem. We prove several properties of definable groups; among them are: groups with bounded exponent are finite (Proposition 6. 1), groups of Euler characteristic one are uniquely divisible (Proposition 4. 1), definable 0 -groups are abelian (Corollary 5. 17), semialgebraic 0 -groups are monogenic, and have only countably many “maximal” subgroups (Corollaries 5. 14 and 5. 15), maximal tori are conjugate (Corollary 5. 19). We also give some examples of “exotic” groups...|$|R
40|$|AbstractSemantic web {{applications}} {{based on}} the web ontology language (OWL) often {{require the use of}} numbers in class descriptions for expressing cardinality restrictions on properties or even classes. Some of these cardinalities are specified explicitly but quite a few are entailed and need to be discovered by reasoning procedures. Due to the description logic (DL) foundation of OWL those reasoning services are offered by DL reasoners which employ reasoning procedures that are arithmetically uninformed and substitute arithmetic reasoning by “don't know” non-determinism in order to cover all possible cases. This lack of information about arithmetic problems dramatically degrades the performance of DL reasoners in many cases, especially with ontologies relying on the use of nominals (O) and qualified cardinality restrictions (Q). In this article we present a new algebraic tableau reasoning procedure for the DL SHOQ that combines tableau procedures and algebraic methods, namely linear integer programming, to ensure arithmetically better informed reasoning procedures. SHOQ extends the standard DL ALC (which is equivalent to the multi-modal logic Km) with transitive roles, <b>role</b> hierarchies, qualified <b>cardinality</b> restrictions, and nominals, and forms an expressive subset of the web ontology language OWL 2. Although the proposed algebraic tableau (in analogy to standard tableau) is still double exponential in the worst case, it deals with cardinalities in a very informed way due to its arithmetic component and can be considered as a novel foundation for informed reasoning procedures addressing cardinality restrictions...|$|R
40|$|Semantic Web {{applications}} {{based on}} the Web Ontology Language (OWL) often {{require the use of}} numbers in class descriptions for expressing cardinality restrictions on properties or even classes. Some of these cardinalities are specified explicitly, but quite a few are entailed and need to be discovered by reasoning procedures. Due to the Description Logic (DL) foundation of OWL, those reasoning services are offered by DL reasoners. Existing DL reasoners employ reasoning procedures that are arithmetically uninformed and substitute arithmetic reasoning by "don't know" non-determinism in order to cover all possible cases. This lack of information about arithmetic problems dramatically degrades the performance of DL reasoners in many cases, especially with ontologies relying on the use of Nominals and Qualied Cardinality Restrictions. The contribution of this thesis is twofold: on the theoretical level, it presents algebra�ic reasoning with DL (ReAl DL) using a sound, complete, and terminating reasoning procedure for the DL SHOQ. ReAl DL combines tableau reasoning procedures with algebraic methods, namely Integer Programming, to ensure arithmetically better informed reasoning. SHOQ extends the standard DL ALC with transitive roles, <b>role</b> hierarchies, qualified <b>cardinality</b> restrictions (QCRs), and nominals, and forms an expressive subset of OWL. Although the proposed algebraic tableau is double exponential in the worst case, it deals with cardinalities with an additional level of information and properties that make the calculus amenable and well suited for optimizations. In order for ReAl DL to have a practical merit, suited optimizations are proposed towards achieving an efficient reasoning approach that addresses the sources of complexity related to nominals and QCRs. On the practical level, a running prototype reasoner (HARD) is implemented {{based on the}} proposed calculus and optimizations. HARD is used to evaluate the practical merit of ReAl DL, as well as the effectiveness of the proposed optimizations. Experimental results based on real world and synthetic ontologies show that ReAl DL outperforms existing reasoning approaches in handling the interactions between nominals and QCRs. ReAl DL also comes with some interesting features such as the ability to handle ontologies with cyclic descriptions without adopting special blocking strategies. ReAl DL can form a basis to provide more efficient reasoning support for ontologies using nominals or QCRs...|$|R
40|$|Business {{processes}} or workflows {{are often}} used to model enterprise or scientific applications. It has received considerable attention to automate workflow executions on computing resources. However, many workflow scenarios still involve human activities and consist of a mixture of human tasks and computing tasks. Human involvement introduces security and authorization concerns, requiring restrictions on who is allowed to perform which tasks at what time. Role- Based Access Control (RBAC) is a popular authorization mechanism. In RBAC, the authorization concepts such as roles and permissions are defined, and various authorization constraints are supported, including separation of duty, temporal constraints, etc. Under RBAC, users are assigned to certain roles, while the roles are associated with prescribed permissions. When we assess resource capacities, or evaluate the performance of workflow executions on supporting platforms, it is often assumed that when a task is allocated to a resource, the resource will accept the task and start the execution once a processor becomes available. However, when the authorization policies are taken into account,” this assumption {{may not be true}} and the situation becomes more complex. For example, when a task arrives, a valid and activated role has to be assigned to a task before the task can start execution. The deployed authorization constraints may delay the workflow execution due to the roles’ availability, or other restrictions on the role assignments, which will consequently have negative impact on application performance. When the authorization constraints are present to restrict the workflow executions, it entails new research issues that have not been studied yet in conventional workflow management. This thesis aims to investigate these new research issues. First, {{it is important to know}} whether a feasible authorization solution can be found to enable the executions of all tasks in a workflow, i. e., check the feasibility of the deployed authorization constraints. This thesis studies the issue of the feasibility checking and models the feasibility checking problem as a constraints satisfaction problem. Second, it is useful to know when the performance of workflow executions will not be affected by the given authorization constraints. This thesis proposes the methods to determine the time durations when the given authorization constraints do not have impact. Third, when the authorization constraints do have the performance impact, how can we quantitatively analyse and determine the impact? When there are multiple choices to assign the roles to the tasks, will different choices lead to the different performance impact? If so, can we find an optimal way to conduct the task-role assignments so that the performance impact is minimized? This thesis proposes the method to analyze the delay caused by the authorization constraints if the workflow arrives beyond the non-impact time duration calculated above. Through the analysis of the delay, we realize that the authorization method, i. e., the method to select the roles to assign to the tasks affects the length of the delay caused by the authorization constraints. Based on this finding, we propose an optimal authorization method, called the Global Authorization Aware (GAA) method. Fourth, a key reason why authorization constraints may have impact on performance is because the authorization control directs the tasks to some particular roles. Then how to determine the level of workload directed to each role given a set of authorization constraints? This thesis conducts the theoretical analysis about how the authorization constraints direct the workload to the roles, and proposes the methods to calculate the arriving rate of the requests directed to each role under the <b>role,</b> temporal and <b>cardinality</b> constraints. Finally, the amount of resources allocated to support each individual role may have impact on the execution performance of the workflows. Therefore, it is desired to develop the strategies to determine the adequate amount of resources when the authorization control is present in the system. This thesis presents the methods to allocate the appropriate quantity for resources, including both human resources and computing resources. Different features of human resources and computing resources are taken into account. For human resources, the objective is to maximize the performance subject to the budgets to hire the human resources, while for computing resources, the strategy aims to allocate adequate amount of computing resources to meet the QoS requirements...|$|R

