28|35|Public
5000|$|Productions {{consist of}} two parts: a sensory {{precondition}} (or [...] "IF" [...] statement) and an action (or [...] "THEN"). If a production's precondition matches {{the current state}} of the world, then the production is said to be triggered. If a production's action is executed, it is said to have fired. A production system also contains a database, sometimes called working memory, which maintains data about current state or knowledge, and a <b>rule</b> <b>interpreter.</b> The <b>rule</b> <b>interpreter</b> must provide a mechanism for prioritizing productions when more than one is triggered.|$|E
50|$|Real-time {{and expert}} systems, in contrast, {{often have to}} choose between {{mutually}} exclusive productions --- since actions take time, only one action can be taken, or (in the case of an expert system) recommended. In such systems, the <b>rule</b> <b>interpreter,</b> or inference engine, cycles through two steps: matching production rules against the database, followed by selecting which of the matched rules to apply and executing the selected actions.|$|E
40|$|This paper {{describes}} the SeRPenS production <b>rule</b> <b>interpreter.</b> SeRPenS permits {{the description of}} the coded <b>rule</b> <b>interpreter</b> in the form of executable production rules. The interpreter description con be used to interpret the basic match-deliberate-act cycle in inspectable form, permitting o limited degree of introspection, The paper also describes ways in which planning con be incorporated, Although the system appears to have considerable power, it is limited by {{the fact that there is}} no general theory of action within which to describe the activity of the system. The limitations of SeRPenS ore outlined...|$|E
50|$|Holdren {{also serves}} as the track and field <b>rules</b> <b>interpreter</b> {{for the state of}} Virginia.|$|R
30|$|QoS Negotiation Systems: it is a Java {{application}} {{responsible for}} receiving a QoS specification, a subclass of QoSSpec expressing the customer requirements and identifying what CoS meets the customer requirements. This system is composed by three components—SLS Negotiator, <b>Rules</b> <b>Interpreter,</b> and Knowledge Base (KB).|$|R
50|$|As an educator, Nemmers {{also began}} his career in officiating. He officiated both high school {{football}} and basketball for 18 years and was selected to officiate in four state final championships. Nemmers also served as the Illinois High School <b>rules</b> <b>interpreter</b> for 15 years.|$|R
40|$|This paper {{provides}} an overview of the ELEKTRA production <b>rule</b> <b>interpreter.</b> Although of an outwardly traditional nature, ELEKTRA differs from other interpreters by providing considerable support for meta -level inference. The paper describes the representions employed in the system, together with the interface to user-defined code. It also describes ways in which control problem in production systems can be solved by increasing use of rules. Finally, the reflective properties of the system are introduced and examples are given. These examples centre round the ability of ELEKTRA to encode and to model rule interpreters of different kinds. It is shown that an interpreter on which the entire ELEKTRA system runs can be implemented as ELEKTRA rules. It is also shown that any <b>rule</b> <b>interpreter</b> which is written in the form of ELEKTRA rules can be interpreted by itself...|$|E
40|$|Routing has an {{important}} influence {{on the performance of}} interconnection networks in parallel computers. Besides simple oblivious schemes like xy-routing for 2 D grids there exist a lot of sophisticated adaptive and fault-tolerant routing algorithms which could however not be implemented so far, because there are no fast hardware routers which are able to support them. In this paper such a flexible and programmable router design is proposed which is based on a rule-based representation of routing algorithms. By making use of the ARON method a fast and efficient hardware <b>rule</b> <b>interpreter</b> can be implemented. The basic principle of rule-based routers is discussed taking typical adaptive routing algorithms as examples. The structure of a prototype is also presented. The influence of increased routing decision time by the <b>rule</b> <b>interpreter</b> is studied by means of simulations. (orig.) Available from TIB Hannover: RR 6673 (34) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|E
40|$|This paper {{outlines}} {{a framework}} for modelling organisational-·,communication. It also describes an object oriented environment (the AME) {{that has been used}} to explore such models. The AME consists of a database that holds a description of the structure of an organisation and its on-going activities. A <b>rule</b> <b>interpreter</b> makes use of the database to assist in the processing of activity related messages and their routing between organisational roles. 1...|$|E
50|$|<b>Rule</b> <b>interpreters</b> {{generally}} {{execute a}} forward chaining algorithm for selecting productions to execute to meet current goals, which can include updating the system's data or beliefs. The condition portion of each rule (left-hand side or LHS) is tested {{against the current}} state of the working memory.|$|R
30|$|The {{property}} mappingTo (Fig.  4) {{allows the}} SLS Negotiator {{to identify the}} individual containing the mapping rules of the QoE parameter used by the customer (i.e., MOS). In this illustrative scenario, mappingTo identifies the mapping rules of the parameter MOS, which are those kept in the individual QoSto-MOS-SWRL of the class MOSMapping. In {{order to determine the}} minimum MOS score guaranteed by each CoSs, the SLS Negotiator calls the <b>Rules</b> <b>Interpreter</b> (Fig.  7) to interpret these mapping rules kept in the individual QoStoMOS-SWRL. Interpreting these <b>rules,</b> the <b>Rules</b> <b>Interpreter</b> creates new individuals belonging the class CoS specifying the quality level guaranteed by COSA and CoSB, now using MOS parameters and codec G. 711. For this, the mapping rule available in the individual QoStoMOS-SWRL is interpreted twice, each one considering the OWD and PLR guaranteed by one of the CoSs of the NSP. The output variable’s value returning from each interpretation is the minimum MOS score guaranteed by the considered CoS.|$|R
30|$|The SWRL {{language}} {{does not}} support the dynamic generation of OWL individuals. This automatic generation of individuals belonging to the class QoSSpec (and other related individuals) based on the SWRL mapping rules is accomplished by the <b>Rules</b> <b>Interpreter</b> in our QoS Negotiation System. With this objective, we developed a simple SWRL interpreter, implemented in Java, and used the OWL API to populate the KB of the NSP with the new individuals.|$|R
40|$|Abstract: This paper {{describes}} a novel method for displaying and examining the execution {{space of a}} <b>rule</b> <b>interpreter.</b> This method provides both coarse-grained and fine-grained views. The coarsegrained view, based on temporal rather than logical dependencies, provides an abstraction of the execution history not available from text or tree based traces. The fine grained views allow the user to examine sections of the execution history in detail. A detailed scenario with screen snapshots is presented...|$|E
40|$|Describes the ELEKTRA {{reflective}} production <b>rule</b> <b>interpreter,</b> which {{differs from}} other interpreters by providing considerable support for meta-level inference and reflection. Also describes the representations {{employed in the}} system, in which the control problem in production systems can be solved by increasing use of rules. Introduces the reflective properties {{of the system and}} gives examples. Shows that the interpreter on which the entire ELEKTRA system runs can be implemented as ELEKTRA rules...|$|E
40|$|Optimisations to the {{standard}} Rete algorithm are presented {{as a means of}} bringing advanced, rule-based artificial intelligence techniques to low-memory systems — in particular, current and future generations of games consoles. A brief introduction to Rete and the issues involved in its implemention on low memory hardware is followed by a discussion of the solutions developed. By sharing resources it is possible to enable the algorithm to run efficiently on low memory machines. A brief overview of the implementation of a <b>rule</b> <b>interpreter</b> which makes use of these optimisations is included...|$|E
40|$|Logic {{programming}} {{emerged from}} the realization that expressing knowledge in an appropriate clausal form in logic was akin to programming. The basic construct of a logic program {{can be viewed as}} a rule. This chapter will review rules from a logic programming perspective with an eye to developments within modern rule languages. It mentions <b>rule</b> <b>interpreters,</b> hybrid computing, interaction with the Web, and agents. An extended example is given concerning rule-based modelling and simulation of traffic at airports...|$|R
5000|$|Oswald Tower (November 23, 1883 - May 28, 1968) was an American {{basketball}} {{administrator and}} instructor at Phillips Academy Andover 1910-49. Born in North Adams, Massachusetts, {{he served on}} the National Basketball Rules Committee from 1910 to 1960, was {{an editor of the}} Official Basketball Guide and an official <b>rules</b> <b>interpreter</b> from 1915 to 1960. He was enshrined in the inaugural class of the Naismith Memorial Basketball Hall of Fame in 1959 as a contributor [...]|$|R
40|$|<b>Rule</b> <b>interpreters</b> usually {{start with}} an initial {{database}} and perform the inference procedure in cycles, ending with a final database. In a real time environment {{it is possible to}} receive updates to the initial database after the inference procedure has started or even after it has ended. We present an algorithm for incremental maintenance of the deductive database in the presence of such updates. Interestingly, the same algorithm is useful for parallel and distributed rule processing in the following sense.|$|R
40|$|The {{problem of}} expert system {{development}} for selecting efficient reserved power source for small ship electrical system {{is important for}} sustainability of on-board power supply system. It is important to create an expert system which can estimate and choose the necessary electric equipment conform to set criteria. Problem of possible equipment alternative ranking expert system development for selecting efficient electrical devices for small ship electrical system consists of three main blocks: development of the knowledge base; the database and the <b>rule</b> <b>interpreter.</b> The <b>rule</b> <b>interpreter</b> is often known as an inference engine and controls the knowledge base using the set of facts to produce even more facts. In this article ELECTRE III based rule interpretation are used. Nowadays often energy saving decision making problems for small ship use only one criteria, as energy consumption level, but usage multi criteria decision making methods, as ELECTRE family methods for development power supply system for small ships, as also choosing reserved power supply equipment could help to make decision by multi criteria, as short term and long term costs, repairing time, safety and others. This problem is actual also in reserved electric power equipment and other equipment choosing. The difficulty of expert system building, for this problem solving, {{that it is not}} possible to define a completed set of the criteria in general set of criteria, it could be defined just only for very special cases like choosing reserved power supply equipment for small ships...|$|E
40|$|Abstract. Cohen’s [1] {{refinement}} rules {{provide a}} flexible mechanism for introducing intentional background knowledge in an ILP system. Whereas Cohen used a limited second order theorem prover {{to implement the}} <b>rule</b> <b>interpreter,</b> we extend the method to use a full Prolog interpreter. This makes the introduction of more complex background knowledge possible. Although refinement rules {{have been used to}} generate literals for a general-to-specific search, we show how they can also be used as filters {{to reduce the number of}} literals in an RLGG algorithm. Each literal constructed by the LGG is tested against the refinement rules and only admitted if a refinement rule has been satisfied. ...|$|E
40|$|Aim of {{the present}} paper is to address the {{requirements}} of a subsidiary information level to be integrated into a prototypal system for the dynamic generation and management of process and data models of industrial products described elsewhere [1]. The subsidiary information level {{is devoted to the}} association into the basic data structure of additional critical information on: motivations for significant choices, comments, timing and liability data. Such information could be used not only to store the project development history, but also to automatically synthesize implicit interrelations among critical elements of the data structure or of the design process. The integration of such information level into the originally proposed Engineering Knowledge Base architecture is detailed and exemplified, and the adoption of a pre-defined vocabulary of key-words and a syntactic <b>rule</b> <b>interpreter</b> is proposed in order to improve ease of use and effectiveness...|$|E
5000|$|All {{decisions}} made by the umpire(s) {{are considered to be}} final. Only decisions where a rule might have been misinterpreted are considered to be protestable. At some tournaments there might be a <b>rules</b> <b>interpreter</b> or Tournament Chief Umpire (TCU) (also known as the Umpire In Chief, or UIC) available to pass judgment on such protests, but it is usually up to the league or association involved to decide if the protest would be upheld. Protests are never allowed on what are considered [...] "judgment calls" [...] - balls, strikes, and fouls.|$|R
40|$|Describes {{a number}} of <b>rule</b> <b>interpreters,</b> {{each of which is}} {{represented}} as a set of production rules which can be executed as an ordinary ruleset in the ELEKTRA system. The interpreters override the default behaviour of the ELEKTRA interpreter: the default behaviour is forward-chaining; shows how to implement backward-chaining and content-directed control. Some of the interpreters described are capable of interpreting themselves. Shows that ELEKTRA is powerful enough to support a wide variety of different interpreters without requiring any changes to its code. None of the interpreters requires additional system code in order to work: ELEKTRA provides all of the facilities used by the rulesets as part of its standard library. Provides additional evidence of the enormous power of reflective systems and of ELEKTRA in particular...|$|R
5000|$|The free {{scientific}} research is a jusphilosophical school precursor of the jurisprudence of values, which defends basically that, {{in order to}} discover the origins of law's principles and <b>rules,</b> the <b>interpreter's</b> studies may have support on various [...] "sciences" [...] such as sociology, economics, linguistics, philosophy and theology, that previous law teachers had not used before.|$|R
40|$|This paper {{describes}} a hybrid approach towards distributed systems management. In our distributed environment the management policies {{are represented by}} rules. Interpretation of the rules and automated activation of appropriate management tools {{is done by the}} software development environment Marvel. Rule chaining is supported in forward and backward direction. The encapsulation feature of Marvel allows an easy integration of separate management tools. Policy enforcement is guaranteed, because every management activity is controlled by Marvel. Activity is initiated either by a human administrator or automatically by monitoring the status of the system. This allows the delegation of simple management tasks to the system. The potential for incorrect management decisions is reduced, because the <b>rule</b> <b>interpreter</b> checks every request for conformance with the given rules and the actually recorded status of the system. Keywords: Distributed systems management, production rules, policy enforce [...] ...|$|E
40|$|Most {{real world}} domains {{differ from the}} micro-worlds {{traditionally}} used in A. I. in {{that they have an}} incomplete factual database which changes over time. Understanding in these domains {{can be thought of as}} the generation of plausible inferences which are able to use the facts available, and respond to changes in them. A traditional <b>rule</b> <b>interpreter</b> such as Planner can be extended to construct plausible inferences in these domains by A) allowing assumptions to be made in applying rules, resulting in simplifications of rules which can be used in an incomplete database; B) monitoring the antecedents and consequents of a rule so that inferences can be maintained over a changing database. The resulting chains of inference can provide a dynamic description of an event. This allows general reasoning processes to be used to understand in domains for which large numbers of Schema-like templates have been proposed as the best model...|$|E
40|$|Abstract. The classic {{theory of}} {{computation}} initiated by Turing and his contemporaries provides {{a theory of}} effective procedures — algorithms that can be executed by the human mind, deploying cognitive processes constituting the conscious <b>rule</b> <b>interpreter.</b> The cognitive processes constituting the human intuitive processor potentially call for a different theory of computation. Assuming that important functions computed by the intuitive processor can be described abstractly as symbolic recursive functions and symbolic grammars, we ask which symbolic functions can be computed by the human intuitive processor, and how those functions are best specified — given that these functions must be computed using neural computation. Characterizing the automata of neural computation, we begin {{the construction of a}} class of recursive symbolic functions computable by these automata, and the construction of a class of neural networks that embody the grammars defining formal languages. 1 Effective Procedures vs. Intuitive Cognitive Processe...|$|E
40|$|Multiple {{instance}} {{learning is}} a challenging task in supervised learning and data mining. How- ever, algorithm performance becomes slow when learning from large-scale and high-dimensional data sets. Graphics processing units (GPUs) are being used for reducing computing time of algorithms. This paper presents an implementation of the G 3 P-MI algorithm on GPUs for solving multiple instance problems using classification rules. The GPU model proposed is distributable to multiple GPUs, seeking for its scal- ability across large-scale and high-dimensional data sets. The proposal is compared to the multi-threaded CPU algorithm with SSE parallelism over a series of data sets. Experimental results report that the com- putation time can be significantly reduced and its scalability improved. Specifically, an speedup of up to 149 × can be achieved over the multi-threaded CPU algorithm when using four GPUs, and the <b>rules</b> <b>interpreter</b> achieves great efficiency and runs over 108 billion Genetic Programming operations per second...|$|R
40|$|In this paper, we {{describe}} {{a number of}} <b>rule</b> <b>interpreters,</b> {{each of which is}} presented in production rule form. Each of the interpreters can be executed as an ordinary ELEKTRA ruleset which interprets all or some of the rules in an ELEKTRA system. The interpreters, therefore, override the default behaviour of the ELEKTRA interpreter. Some of the interpreters that {{we describe}} are capable of interpreting themselves: others can be combined into larger, reflective interpreters. The aim of the paper is not, however, to show how sophisticated reflective processing can be achieved in ELEKTRA, but, rather, to show that ELEKTRA is powerful enough to support a wide variety of different interpreters without requiring any changes to its code. None of the interpreters requires additional system code in order to work: ELEKTRA provides all of the facilities used by the rulesets as part of its standard library. This paper is offered as additional evidence of the enormous power of the ELEKTRA system...|$|R
40|$|The paper {{describes}} the basic implementation of GCLA II's control level. The {{basis of the}} implementation is a compiling scheme for transforming inference rules and strategies operating on the object level to an interpreter in Prolog, where the inference rules of the control level are coded inline. This is possible since the operational semantics of the control level is deterministic, i. e. the choice of inference rule to apply on a control level goal is determined solely by {{the parts of the}} goal. To handle dynamic clauses, a context list, accessible through some new C-functions linked together with the Prolog system. GCLA I and GCLA II are described shortly, followed by a discussion of a Horn clause representation of inference rules versus functions coding inference rules. Then the transformation of inference rules and strategies is described followed by some examples. Keywords: GCLA, inference <b>rules,</b> <b>interpreters,</b> program transformation - 1. Introduction GCLA is a specification tool [...] ...|$|R
40|$|The 'Knowledge Engineer's Assistant' (KEATS) is a {{software}} environment suitable for constructing knowledge based systems. In this paper, we discuss {{its role in}} supporting the knowledge engineer in the tasks of knowledge elicitation and domain understanding. KEATS is based upon our own investigations of the behaviour and needs of knowledge engineers and provides two enhancements to other modern 'shells', 'toolkits', and 'environments' for knowledge engineering: (i) transcript analysis facilities, and (ii) a sketchpad on which the KE may draw a freehand representation of the domain, from which code is automatically generated. KEATS uses a hybrid representation formalism that includes a frame based language and a <b>rule</b> <b>interpreter.</b> We describe the novel components of KEATS in detail, and present {{an example of how}} KEATS was used to build an electronic fault diagnosis system. Acknowledgements: The KEATS project is conducted jointly by the Human Cognition Research Laboratory at the Open Uni [...] ...|$|E
40|$|The {{intelligent}} {{behavior of}} a system is based upon its represented knowledge and inference capabilities. In this paper we report on a knowledge representation and reasoning system, developed at the University of Karlsruhe, called Mantra. The system provides four different knowledge representation methods [...] first-order logic, terminological language, semantic networks, and production rules [...] distributed into a three levels architecture. The first three methods form {{the lowest level of}} the architecture, the epistemological level. The supported hybrid inferences as well as the management of knowledge bases form the second level, called logical level. Finally, the third level, the heuristic level, provides representation of procedural knowledge of a domain, and the introduction of ad hoc rules. This knowledge is represented in terms of production rules which are processed by a Ops 5 -like <b>rule</b> <b>interpreter.</b> This paper mainly describes the introduction of this level into the hybr [...] ...|$|E
40|$|Work on {{reflection}} {{has frequently}} concentrated on programming languages and operating systems. This work either {{involves the use}} of tower reflection or meta-object protocols. The subject of this paper is a different form of reflection that is, we believe, more powerful and fundamental than the other kinds. Self modelling is a process that has not received attention in the literature; indeed, we believe that we are the first to study the topic in a systematic fashion. We will explain the concept of a self-modelling program and describe some example programs that construct and manipulate models of themselves. The programs that we consider are: a learning program, a conceptual modelling system and a production <b>rule</b> <b>interpreter.</b> We also consider the benefits that are to be gained from engaging in self modelling and we show how the programs that we have described benefit from the additional work required of them. We indicate how additional power can be derived by engaging in self modelling...|$|E
30|$|During the QoS negotiation, the SLS Negotiation System {{proceeds}} as follows. The SLS Negotiator {{receives the}} subclass of QoSSpec and verifies {{if there is}} already in the KB an equivalent subclass of QoSSpec. If yes, then the inference process has already been done, and the SLS Negotiator can reach the CoS satisfying the quality requirement of the customer and present it to the user’s application (as presented in Sect. 5.3). Otherwise, the new QoSSpec must be included in the KB. The <b>Rules</b> <b>Interpreter</b> is called when new QoE/QoS parameters are used by a subclass of QoSSpec specifying the customer’s requirements. Before the rules are applied, this component is responsible for including in the KB new individuals belonging to the classes CoS and Parameter using the new QoE/QoS parameter for each individual CoS. After this operation, the SLS Negotiator can call the Reasoner to do the classification and realization on the KB. Finally, the SLS Negotiator can reach the CoS satisfying the quality requirement of the customer and present it to the user’s application.|$|R
5000|$|An {{inference}} engine or semantic reasoner, which infers information or takes action {{based on the}} interaction of input and the <b>rule</b> base. The <b>interpreter</b> executes a production system program by performing the following match-resolve-act cycle: ...|$|R
40|$|In thii paper, we {{consider}} MOBY. a distributed architecture {{to support the}} development of expert database systems in a rule based language. It combines standard indexing and horizontal data partitioning techniques with a <b>rule</b> based <b>interpreter</b> to achieve the reasonable performance. The major difficulty in developing this architecture is to maintain a high effective parallelism {{as the number of}} processors increases. Analytic results suggest that when data is masonably well balanced across a local area network, MOBY has a high effective parallelism. Simulation results support this claim by showing that the effective parallelism is proportional to 40 % of the number of processors. A discussion of some crucial issues in our current network based implementation is also given...|$|R
