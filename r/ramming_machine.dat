1|219|Public
5000|$|In 1911 work {{started on}} {{expanding}} the site {{at the corner}} of Heegermühler Strasse/Boldtstrasse. The company was known the world over for manufacturing foundry machinery. It was particularly famous for a pipe <b>ramming</b> <b>machine,</b> patented in 1907. This device enabled the manufacture of cast-iron pipes on an industrial scale for the first time. However, cranes were the main products made. In 1912 the factory was inaugurated at its present location. In 1913 all four sons were made equal partners and the company’s title was changed to Ardeltwerke GmbH.|$|E
5000|$|On a <b>RAM</b> <b>machine</b> with {{word size}} [...] and integer inputs , the {{problem can be}} solved in [...] {{operations}} {{by means of the}} fast Fourier transform.|$|R
5000|$|In particular, the cache-oblivious {{model is}} an {{abstract}} machine (i.e. a theoretical model of computation). It {{is similar to}} the <b>RAM</b> <b>machine</b> model which replaces the Turing machine's infinite tape with an infinite array. Each location within the array can be accessed in [...] time, similar to the Random access memory on a real computer. Unlike the <b>RAM</b> <b>machine</b> model, it also introduces a cache: a second level of storage between the RAM and the CPU. The other differences between the two models are listed below. In the cache-oblivious model: ...|$|R
50|$|Memory: 32 kB ROM, 8, 16, 24, or 32kB static <b>RAM.</b> <b>Machines</b> {{with less}} than 32 kB can be {{expanded}} in 8 kB increments of plug-in static RAM modules. An additional 32 kB Option ROM can be installed.|$|R
30|$|The {{proposed}} 3 D {{face reconstruction}} required about 0.1 [*]s per test image using our proposed algorithm {{based on an}} alternation methodology and about 3.6 [*]s per test image using the algorithm based on a one-step methodology. The computation times were measured on an Intel Core i 5 CPU 750, 2.7 [*]GHz, 3 [*]GB <b>RAM</b> <b>machine.</b>|$|R
40|$|We {{develop a}} new multi-party {{generalization}} of Naor-Nissim indirect indexing, {{making it possible for}} many participants to simulate a <b>RAM</b> <b>machine</b> with only poly-logarithmic blow-up. Our most efficient instantiation (built from length-flexible additively homomorphic public key encryption) improves the communication complexity of secure multi-party computation for a number of problems in the literature. Underlying our approach is a new multi-party variant of oblivious transfer which may be of independent interest...|$|R
40|$|We suggest two new methodologies for {{the design}} of {{efficient}} secure protocols, that differ with respect to their underlying computational models. In one methodology we utilize the communication complexity tree (or branching for f and transform it into a secure protocol. In other words, "any function f that can be computed using communication complexity c can be can be computed securely using communication complexity that is polynomial in c and a security parameter". The second methodology uses the circuit computing f, enhanced with look-up tables as its underlying computational model. It is possible to simulate any <b>RAM</b> <b>machine</b> in this model with polylogarithmic blowup. Hence it is possible to start with a computation of f on a <b>RAM</b> <b>machine</b> and transform it into a secure protocol. We show many applications of these new methodologies resulting in protocols efficient either in communication or in computation. In particular, we exemplify a protocol for the "millionaires problem", where two participants want to compare their values but reveal no other information. Our protocol is more efficient than previously known ones in either communication or computation...|$|R
50|$|In 2006, {{the company}} {{developed}} High Energy Applied Technology (HEAT) for wire EDMs {{to increase speed}} in wire EDMing, and released the EDAC1 micro EDM <b>ram</b> <b>machine.</b> Makino is also the only manufacturer of a horizontal wire EDM, the UPJ-2. In 2007, Makino introduced SurfaceWIZARD wire EDM technology, designed to eliminate witness lines in stepped parts. Makino created ADVANTiGE™ Technology for the machining of titanium in 2010, which was recognized as a winner of Aviation Week's 2012 Innovation Challenge.|$|R
40|$|The {{theoretical}} view of cryptography usually models all parties, legitimate ones {{as well as}} attackers, as idealized computational devices with designated interfaces, {{and their}} security and computational complexity are evaluated in some convenient computational model – usually PC-like <b>RAM</b> <b>machines.</b> This dissertation investigates several cases where reality significantly deviates from this model, leading to previously unforeseen cryptanalytic attacks. The {{first part of the}} dissertation investigates the concrete cost of factoring integers, and in particular RSA keys of commonly used sizes such as 1024 bits. Until recently, this task was considered infeasible (i. e., its cost was estimated as trillions of dollars), based on extrapolations that assumed implementation of factoring algorithms on sequential PC-like computers. We have shown that the situation changes significantly when one introduces custom-built hardware architectures, with algorithms and parametrization that are optimized for concrete technological tradeoffs and do not fit the <b>RAM</b> <b>machine</b> model. Focusing on the Number Field Sieve (NFS) factoring algorithm, we propose hardware architectures for both of its computational steps: the sieving step and the linear algebra step. Detailed analysis and a careful choice of the NFS parameters show that for breaking 1024 -bit RSA keys, NFS can be be implemented at a fairly practical cost of a few millio...|$|R
40|$|Theorem 1 (Main Theorem). Every {{non-deterministic}} RAM computation in time t can be simulated by a non-deterministic oblivious two-tape TM in time t polylog(t). We {{prove this}} theorem in two steps. First, we show how to simulate non-deterministic <b>RAM</b> <b>machines</b> using non-deterministic multi-tape TMs with polylogarithmic overhead. Then, we show how to simulate multi-tape TMs using oblivious two-tape TMs. 1 RAM to Multi-tape Lemma 1. Every non-deterministic RAM computation in time t can be simulated by a non-deterministic multi-tape TM in time t polylog(t). Definition 1 (Nearly linear time). A function is in nearly linear time if {{and only if}} it is in time(n(log n) O(1)). Definition 2 (NQL). NQL is the class of languages accepted by non-deterministic multi-tape TMs in nearly linear time. Definition 3 (NNLT). NNLT is the class of languages accepted by non-deterministic random access machines in nearly linear time. We assume that random-access <b>machines</b> (<b>RAM</b> <b>machines,</b> random-access TMs, etc.) are equivalent for nearly linear time. The proofs are straightforward, but {{beyond the scope of this}} proof. Lemma 2. Multi-tape TMs can sort in nearly linear time. This lemma is due to Schnorr [4]. We will take it for granted. The idea is that since merging two lists can be done in linear time on a 3 -tape TM, sorting a list using merge sort can be done in nearly linear time...|$|R
5000|$|Dynamic <b>RAM</b> disk <b>machines</b> with 64 or 128 kB RAM {{followed}} soon after, with a WD2793 Floppy Disk Controller incorporated on {{the core}} board. Later disk machines used 3.5" [...] floppy disks.|$|R
40|$|We {{introduce}} a compressed suffix array representation that, on a text T of length n over an alphabet of size sigma, {{can be built}} in O(n) deterministic time, within O(nlogsigma) bits of working space, and counts the number of occurrences of any pattern P in T in time O(|P| + loglog_w sigma) on a <b>RAM</b> <b>machine</b> of w=Omega(log n) -bit words. This new index outperforms all the other compressed indexes that can be built in linear deterministic time, and some others. The only faster indexes can be built in linear time only in expectation, or require Theta(nlog n) bits...|$|R
5000|$|A pointer-based {{implementation}} for <b>RAM</b> <b>machines,</b> supporting decrease-key, can {{be achieved}} using three pointers per node, by representing the children of a node by a singly-linked list: a pointer to the node's first child, one to its next sibling, and one to its previous sibling (or, for the leftmost sibling, to its parent). Alternatively, the previous-pointer can be omitted by letting the last child point back to the parent, if a single boolean flag is added to indicate [...] "end of list". This achieves a more compact structure {{at the expense of}} a constant overhead factor per operation.|$|R
50|$|The Pep/7 is {{a direct}} {{descendant}} of the Pep/6 virtual machine, the only major difference {{is that it has}} been expanded from 4KiB to 32KiB of system <b>RAM.</b> The <b>machine</b> code format remains the same.|$|R
50|$|Hibernation is {{an example}} that uses {{an image of the}} entire <b>machine's</b> <b>RAM.</b>|$|R
5000|$|Enterprise servers, {{supporting}} nodes {{with four}} sockets, each carrying 8-, 10- or 12-core modules, for {{a maximum of}} 16 sockets, 128 cores and 16 TB of <b>RAM.</b> These <b>machines</b> can run AIX, IBM i, or Linux.|$|R
40|$|Inclusion between XML types is {{important}} but expensive, and {{is much more}} expensive when unordered types are considered. We prove here that inclusion for XML types with interleaving and counting can be decided in polynomial time in presence of two important restrictions: no element appears twice in the same content model, and Kleene star is only applied to disjunctions of single elements. Our approach {{is based on the}} transformation of each such content model into a set of constraints that completely characterizes the generated language. We then reduce inclusion checking to constraint implication. We exhibit a quadratic algorithm to perform inclusion checking on a <b>RAM</b> <b>machine.</b> Key words: PACS...|$|R
50|$|The RASP is a {{universal}} Turing machine (UTM) built on a random-access <b>machine</b> <b>RAM</b> chassis.|$|R
50|$|Future File: The most {{speculative}} register {{state of}} the <b>machine.</b> <b>RAM</b> indexed by logical register number.|$|R
50|$|An {{optional}} 512K RAM cartridge {{was considered}} to boost the total <b>RAM</b> for the <b>machine</b> to 768K.|$|R
5000|$|... {{allows the}} {{creation}} of a CPU (a virtual one), including the registers, <b>RAM,</b> microinstructions, and <b>machine</b> instructions; ...|$|R
5000|$|The Model D came preinstalled with 256, 512, or 640 KB of <b>RAM.</b> Lower-capacity <b>machines</b> were user {{upgradeable}} to 640 KB. [...] Motherboard revisions 7, 8, WC1 and WC2 {{came with}} 768 KB of RAM installed (640 KB {{available to the}} user).|$|R
30|$|In case of {{the sample}} {{generator}} {{this would be the}} case if even one sample would be too large for an individual <b>machine’s</b> <b>RAM.</b>|$|R
40|$|Correctness of {{algorithms}} in {{computational geometry}} are usually proved using the unrealistic Real <b>RAM</b> <b>machine</b> model of computation with the undesirable result that correct algorithms, when implemented, turn into unreliable programs. In this paper, {{we use a}} domain-theoretic approach to recursive analysis to develop {{the basis of an}} effective and realistic framework for solid modeling. This framework is equipped with a well-defined and realistic notion of computability which reflects the observable properties of real solids. It is closed under the Boolean operations, admits non-regular sets and supports a design methodology for actual robust algorithms. Within this model, some unavoidable limitations of solid modeling computations are proved and a sound framework to design specifications for feasible modeling operators is provided. Some consequences in computation with the boundary representation paradigm are sketched that can incorporate existing methods into a general, mathematically we [...] ...|$|R
40|$|There the {{mathematical}} dependences {{for the design}} of peak values of stresses on the different levels of compaction zone, the dependences {{for the design of}} reduced mass of soil, the numerical values of coefficients, which characterize the change of spreading speed of loading waves and of off-loading waves have been presented. The determination technique of rational characteristics of soil-compacting machines of impact action, the compaction method of soils by the ramming, which was protected by the Inventor's Certificate, have been developed. The determination technique of rational characteristics of working heads of <b>ramming</b> <b>machines,</b> the recommendations for the up-dating of DU- 12 rammer are introduced. The application fields are the enterprises for the designing, for the production and for the use of soil-compacting machinesAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|The final {{publication}} {{is available}} at Springer via [URL] this work, we design an explicit time-stepping solver for the simulation of the incompressible turbulent flow through the combination of VMS methods and artificial compressibility. We evaluate {{the effect of the}} artificial compressibility on the accuracy of the explicit formulation for under-resolved LES simulations. A set of benchmarks have been solved, e. g., the 3 D Taylor–Green vortex problem in turbulent regimes. The resulting method is proven to be an effective alternative to implicit methods in some application ranges (in terms of problem size and computational resources), providing comparable results with very low memory requirements. As an example, with the explicit approach, we are able to solve accurately the Taylor-Green vortex benchmark in a fine mesh with 5123 cells on a 12 cores 64 GB <b>ram</b> <b>machine.</b> Peer ReviewedPostprint (author's final draft...|$|R
40|$|Solid {{modelling}} and {{computational geometry}} {{are based on}} classical topology and geometry in which the basic predicates and operations, such as membership, subset inclusion, union and intersection, are not continuous and therefore not computable. But a sound computational framework for solids and geometry can only be built in a framework with computable predicates and operations. In practice, correctness of algorithms in computational geometry is usually proved using the unrealistic Real <b>RAM</b> <b>machine</b> model of computation, which allows comparison of real numbers, with the undesirable result that correct algorithms, when implemented, turn into unreliable programs. Here, we use a domaintheoretic approach to recursive analysis to develop {{the basis of an}} eective and realistic framework for solid modelling. This framework is equipped with a well-dened and realistic notion of computability which reects the observable properties of real solids. The basic predicates and operations o [...] ...|$|R
40|$|This paper {{describes}} {{what is the}} parallel time for sequential models, what is the sequential time for parallel models, and proves that the well-known computational models <b>RAM,</b> vector <b>machines,</b> Turing machines, uniform circuits, uniform aggregates, storage modification machines, hardware modification machines,…, are all similar {{in the sense that}} their parallel time, their sequential time, and their space complexities are polynomially related simultaneously...|$|R
25|$|A Turing {{machine is}} a {{mathematical}} model of a general computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, {{but rather as a}} thought experiment representing a computing machine—anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a Turing machine that solves the problem. Indeed, this is the statement of the Church–Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as a <b>RAM</b> <b>machine,</b> Conway's Game of Life, cellular automata or any programming language can be computed on a Turing machine. Since Turing machines are easy to analyze mathematically, and are believed to be as powerful as any other model of computation, the Turing machine is the most commonly used model in complexity theory.|$|R
40|$|We {{present a}} new {{algorithm}} for on-line approximate string matching. The algorithm {{is based on}} the simulation of a non-deterministic nite automaton built from the pattern and using the text as input. This simulation uses bit operations on a <b>RAM</b> <b>machine</b> with word length O(log n), being n the maximum size of the text. The running time achieved is O(n) for small patterns (i. e. m = O (p log n)), independently of the maximum number of errors allowed, k. This algorithm is then used to design two general algorithms. One of them partitions the problem into subproblems, while the other partitions the automaton into subautomata. These algorithms are combined to obtain a hybrid algorithm which on average is O(n) for moderate k=m ratios, O (p mk = log nn) for medium ratios, and O((m; k) kn = log n) for large ratios. We show experimentally that this hybrid algorithm is faster than previous ones for moderate size patterns, which is the case in text searching...|$|R
40|$|We {{present a}} unified view to {{sequential}} algorithms for many pattern matching problems, using a finite automaton built from the pattern which uses {{the text as}} input. We show the limitations of deterministic finite automata (DFA) and the advantages of using a bitwise simulation of non-deterministic finite automata (NFA). This approach gives very fast practical algorithms which have good complexity for small patterns on a <b>RAM</b> <b>machine</b> with word length O(log n), where n {{is the size of}} the text. For generalized string matching the time complexity is O(mn= log n) which for small patterns is linear. For approximate string matching we show that the two main known approaches to the problem are variations of the NFA simulation. For this case we present a different simulation technique which gives a running time of O(n) independently of the maximum number of errors allowed, k, for small patterns. This algorithm improves the best bit-wise or comparison based algorithms of running ti [...] ...|$|R
50|$|A Turing {{machine is}} a {{mathematical}} model of a general computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, {{but rather as a}} thought experiment representing a computing machine—anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a Turing machine that solves the problem. Indeed, this is the statement of the Church-Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as a <b>RAM</b> <b>machine,</b> Conway's Game of Life, cellular automata or any programming language can be computed on a Turing machine. Since Turing machines are easy to analyze mathematically, and are believed to be as powerful as any other model of computation, the Turing machine is the most commonly used model in complexity theory.|$|R
40|$|We {{study the}} problem of {{designing}} a data structure that reports {{the positions of the}} distinct τ-majorities within any range of an array A[1, n], without storing A. A τ-majority in a range A[i, j], for 0 < τ < 1, is an element that occurs more than τ(j−i+ 1) times in A[i, j]. We show that Ω(ndlog(1 /τ) e) bits are necessary for any data structure just able to count the number of distinct τ-majorities in any range. Then, we design a structure using O(ndlog(1 /τ) e) bits that returns one position of each τ-majority of A[i, j] in O((1 /τ) log logw(1 /τ) log n) time, on a <b>RAM</b> <b>machine</b> with word size w (it can output any further position where each τ-majority occurs in O(1) additional time). Finally, we show how to remove a log n factor from the time by adding O(n log log n) bits of space to the structure...|$|R
40|$|The PRAM {{model of}} {{computation}} {{consists of a}} collection of sequential <b>RAM</b> <b>machines</b> accessing a shared memory in lock-step fashion. The PRAM is a very high-level abstraction of a parallel computer, and its direct realization in hardware is beyond reach of the current (or even foreseeable) technology. In this paper we present a deterministic simulation scheme to emulate PRAM computation on a mesh-connected computer, a feasible machine where each processor has its own memory module and is connected to at most four other processors via point-to-point links. In order to achieve a good worst-case performance, any deterministic simulation scheme has to replicate each variable in a number of copies. Such copies are stored in the local memory modules according to a Memory Organization Scheme (MOS), which is known to all the processors. A variable is then accessed by routing packets to its copies. All deterministic schemes in the literature make use of a MOS whose existence is proved via the prob [...] ...|$|R
40|$|Ricardo Baeza-Yates Gonzalo Navarro Department of Computer Science University of Chile Blanco Encalada 2120 - Santiago - Chile frbaeza,gnavarrog@dcc. uchile. cl Abstract We {{present a}} new {{algorithm}} for on-line approximate string matching. The algorithm {{is based on}} the simulation of a non-deterministic finite automaton built from the pattern and using the text as input. This simulation uses bit operations on a <b>RAM</b> <b>machine</b> with word length O(log n), being n the maximum size of the text. The running time achieved is O(n) for small patterns (i. e. m = O(p log n)), independently of the maximum number of errors allowed, k. This algorithm is then used to design two general algorithms. One of them partitions the problem into subproblems, while the other partitions the automaton into subautomata. These algorithms are combined to obtain a hybrid algorithm which on average is O(n) for moderate k=m ratios, O(p mk= log n n) for medium ratios, and O((m Γ k) kn= log n) for large ratios. We [...] ...|$|R
25|$|Random access <b>machine</b> (<b>RAM)</b> – {{a counter}} machine with {{indirect}} addressing and, usually, an augmented instruction set. Instructions {{are in the}} finite state machine {{in the manner of}} the Harvard architecture.|$|R
