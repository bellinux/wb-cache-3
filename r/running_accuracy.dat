10|61|Public
40|$|Calibration of a {{small size}} hexapod machine tool using {{coordinate}} measuring machine Guoqing Zhang 1, 2, Jianjun Du 1 and Suet To 2 Hexapod machine tool (HMT) is a device designed for micro milling; however, the deviations of the HMT’s kinematic parameters due to manufacture and assembly errors can definitely affect its <b>running</b> <b>accuracy.</b> To identify the real kinematic parameters so as to improve the <b>running</b> <b>accuracy</b> of the HMT, a novel calibration test was performed on a bridge-type coordinate measuring machine. In the present research, a mathematical model was derived to present the relationship between pose errors and the errors of kinematic parameters of the HMT, the measurement method based on coordinate measuring machine was designed and a calibration experiment was carried out subsequently. The experi-mental results reveal that after calibration, both the position errors and orientation errors of the HMT decreased significantly, the symmetrical errors were improved as well. In addition, {{it is found that}} the <b>running</b> <b>accuracy</b> of the HMT is running direction dependent, which depends on the HTM’s structures. The present research provides researchers with a new and effective calibration method to improve the <b>running</b> <b>accuracy</b> of HMTs...|$|E
40|$|Current {{trends in}} high-precision {{applications}} stress {{the need for}} reliable and well-designed air-bearing systems. In this work, the influence and the interaction are studied of the different air bearings of an axis of rotation system on the radial error motion with the objective to increase the <b>running</b> <b>accuracy</b> to the sub-nanometer level (< 5 nm). To this end, a 5 -DOF film model is developed that can account for the minutest details affecting the error motion and the dynamic film forces. status: publishe...|$|E
40|$|Abstract: The bearing pre-tightening {{force on}} the guide of high speed punch press has {{immediately}} influenced the <b>running</b> <b>accuracy</b> of the slide, {{as well as the}} precision of the high speed punch press. So, the control of bearing pre-tightening {{force on the}} guide of high speed punch press was a very important issue in the study of high-speed presses. Through the research and analysis of the guidance system structure, the method of adjusting and controlling the guide rail bearing pre-tightening up force has been proposed in this article...|$|E
40|$|This article aims {{to address}} the use of 3 D {{printers}} in the stages of design, development and final presentation in projects of architecture and urbanism. To evaluate the performance of 3 D printers, we emphasize {{in each of these}} stages of the project, the representational demands and cognitive processes involved as well as analytical categories taken as cost, <b>running</b> time, <b>accuracy</b> and level finish, the representation of materials, scale and size of three-dimensional models and possibilities for intervention in the models themselves...|$|R
40|$|This paper {{presents}} a scalable learning algorithm to classify numerical, low dimensionality, high-cardinality, time-changing data streams. Our approach, named SCALLOP, provides {{a set of}} decision rules on demand which improves its simplicity and helpfulness for the user. SCALLOP updates the knowledge model every time a new example is read, adding interesting rules and removing out-of-date rules. As the model is dynamic, it maintains the tendency of data. Experimental results with synthetic data streams show a good performance with respect to <b>running</b> time, <b>accuracy</b> and simplicity of the model...|$|R
30|$|Construct {{validity}} threats {{may be due}} to simplifications {{and assumptions}} made when evaluating our approach. During the evaluation of the database modelling stage of the approach, 15 real-world database schemas and logs were used. Similarly, our evaluation of cloud migration costs and duration compared the predictions of our database migration simulations to real-world migrations. On the other hand, cloud <b>running</b> cost <b>accuracy</b> was inferred from database capacity accuracy (for the reasons presented in the results analysis from the previous section). Real long-term experiments to assess this cost would be necessary to increase the confidence that this result is accurate.|$|R
40|$|The preload force, by the {{significant}} changes produced on the bearings functioning, i. e. kinematics, both internal load distribution and amount, thermal regime, appears {{as an important}} influence factor on a high speed assembly main reliability parameters: service life, dynamic and thermal stability, <b>running</b> <b>accuracy.</b> Having in view the complexity of these interactions the both design and realisation of active preload systems, i. e. feed-back systems, accurate and reliable, able to apply and secure constant preload forces during functioning could be an efficient solution to improve the working performances of the high speed rolling bearings assemblies...|$|E
40|$|In this work, a {{nanometer}} accurate 2 D-orbit {{model is}} developed for analysing {{the influence of}} the minutest details affecting the radial error motion of a porous aerostatic journal bearing. This allows us to increase the <b>running</b> <b>accuracy</b> of an axis of rotation system, such as an aerostatic spindle or rotary table, to the sub-nanometer level. The orbit model is validated experimentally by measuring the radial error motion of a porous aerostatic rotary table {{with the use of a}} special measurement technique. The difference between the outcome of the orbit model and radial error motion of the rotary table under test is only 6 nm. status: publishe...|$|E
40|$|The goal of {{this work}} is to propose a {{suitable}} methodology for measuring and evaluating the geometric precision of spindle rotation. Identification and classification of errors while moving spindle. Part of this work should be also a program in LabVIEW that evaluate the errors in {{the motion of the}} spindle. Practical functionality of the proposed measurement system should be tested at selected MCV 754 QUICK machines, lathes SV 18 and milling machine FNG 32. For processing of the results should be used basic statistical procedures. This thesis includes research in the field of machine tool spindles and different ways of measuring spindle motion deviations from the ideal path. There is also included the effect of sensors to measuring spindle <b>running</b> <b>accuracy</b> and identification of suitable sensors applicable for this application. There is a proposal of measurement of selected machinery, and defines all the components required for measurements that were used during spindle running precision measurement. Part of this work is a basic description of the program developed for evaluating errors in the motion of the spindle...|$|E
5000|$|As {{described}} by Andreotti et al in 2012, Antilope {{is a combination}} of Lagrangian relaxation and an adaptation of Yen's k shortest paths. It is based on 'spectrum graph' method and contains different scoring functions, and can be comparable on the <b>running</b> time and <b>accuracy</b> to [...] "the popular state-of-the-art programs" [...] PepNovo and NovoHMM.|$|R
40|$|In this paper, several {{modifications}} {{are introduced}} to the functional approximation method iterLap to reduce the approximation error, including stopping rule adjustment, proposal of new residual function, starting point selection for numerical optimisation, scaling of Hessian matrix. Illustrative examples are also provided to show the trade-off between <b>running</b> time and <b>accuracy</b> of the original and modified methods...|$|R
40|$|In {{this rather}} brief note we present and discuss {{techniques}} for solving Kronecker matrix product least squares problems. Our main contribution is an iterative approach {{that uses the}} efficient Kronecker matrix-vector multiplication strategy (Fernandes et al. 1998) with a conjugate gradient solver. Numerical results contrast this approach [...] -in terms of <b>running</b> times and <b>accuracy</b> [...] -against the direct approach. Comment: 4 page...|$|R
40|$|This paper {{presents}} a compound fuzzy control algorithm method having modifiable factors based on PLC, and the modified fuzzy controller and PI regulator is realized by PLC, the system solves problems of imprecise paper cutter speeds, instability, and paper cuttings of different lengths. The {{results show that}} the system can effectively restrain influences from pure time-delays while maintaining stability and strong robustness. Paper cutter speed control {{is one of the most}} important processes involving paper cutting production; paper cutter speed can directly affect product quality. When the paper cutter is running, both the paper roller speed and the knife roller speed determine the length of the paper cutting. While we can control the proportion of the two kinds of speed to get the required paper cutting length, the speeds themselves are time-varied, lagged, and largely random. If the operator operates two potentiometers to control two different direction speeds, as in the traditional way, it would be very difficult to maintain <b>running</b> <b>accuracy</b> based on the proportion. In this paper, we focus on the Fuzzy PI control algorithm, as the software algorithm, and the PLC, as the hardware, thus, we can achieve an ideal control result while the system provides good stability and robustness. 1...|$|E
40|$|Advances in the {{semiconductor}} industry, material science and ultra-precision machining sector have heightened {{the need for}} more accurate axis-of-rotation systems. Since the requirements go beyond the capabilities of conventional bearing technologies, gas lubricated bearings are typically used. Their advantages are widely recognised: virtually wear-free and frictionless operation, no lubrication, clean solution in a wide temperature range and infinite lifetime. Although the bearing surfaces do not make contact in a gas bearing, the machining accuracy of the bearing surfaces, imbalance and environmental fluctuations limit their further evolution toward attaining nanometre accuracy for novel ultra-precision applications. The main objective of this dissertation is to reduce the error motion of an aerostatic rotary table to the nanometre level (i. e. < 10 nm). To realise this goal, a numerical gas film model is developed to study the influence of several manufacturing errors, bearing parameters and feeding geometries on the <b>running</b> <b>accuracy</b> of an air-bearing system. An experimental validation of the design guidelines is used to support the theoretical results. To this end, a new spindle error motion separation technique is developed to measure the error motion with sub-nanometre uncertainty. The contributions of this work are situated in three domains. Firstly, this work presents a gas film model for analysing the influence of the minutest details affecting the error motion of an aerostatic bearing. A steady-state model and orbit model is developed and compared for both an orifice-compensated bearing and porous bearing. From this study, a set of dimensionless design guidelines are formulated. It is found that the error motion of an aerostatic bearing is mainly influenced by the form error of the rotor, while the form error of the stator and variations in orifice diameter are of secondary importance. Moveover, it is seen that the error motion increases drastically if the feed number is greater than that corresponding to the maximal direct stiffness of the gas film. The most interesting finding, however, is that the error motion of an aerostatic bearing can be most effectively reduced by increasing the number of feedholes as it results in a uniform pressure distribution. Secondly, this work presents the design and validation of a sub-nanometre spindle error motion separation technique. This technique overcomes typical measurement error sources arising from sensor indexing or the repositioning of the artifact. Various known reversal and multiprobe techniques are compared and assessed by means of a new error analysis method. From this, an improved implementation of the multiprobe method is proposed. The suppression of the low-order harmonics is reduced by an optimisation of measurement angles. Repeatability tests show a measurement uncertainty of 0. 23 nm of the improved multiprobe method. Lastly, this work describes the design, manufacturing and experimental validation of newly developed air-bearing system. The selected morphology for increasing the <b>running</b> <b>accuracy</b> is tested by measuring the error motion of a porous aerostatic rotary table. The outcome of the experiments confirm the design theory proposed in this work, namely, a uniform pressure distribution, which can be obtained by increasing the number of feedholes (i. e. a porous bearing has an infinite number of feedholes), results in an ultra-precise rotation of a gas bearing system. A synchronous radial error motion of 3 - 4 nm and a synchronous axial error motion of 1 - 2 nm is obtained. The asynchronous error of the porous aerostatic rotary table is around 1 nm. status: publishe...|$|E
40|$|Background: Football is {{the most}} popular sport in the world. Kicking the ball to goal can do if a {{football}} player have limb muscles good, and running fast so, it expected to create a goal. The results of pre study to 25 students in kick practice to goal, 16 students missing kick. The objectives of Research: To know association between power limb muscles and speed running to accuracy of shooting ball to goal of primary school students of Gawanan Karanganyar. The Benefit of Research: Expected in this research can increase knowledge and repertoire of football in particular ways and techniques in a football game. The Method of Resarch: The kind of Research is quantitative, and crossectional approach. Sample are 50 male students of 4. 5, and 6 class. Taking Sample use porpusive sampling technique. data collected by measures power limb muscles with jump test. Speed run use measure time from sprint of 30 meters. The accuracy shooting with 10 times from 12 metres disctance. Data analysis use correlation pearson product moment and linear regression multiple test. Result of the Research: Results that association between power limb muscles with accuration shooting ball to goal with p = 0, 001. Association between speed running 30 meters with accuration shooting ball to goal with p = 0, 001. linear regression multiple test with equation Y= 82, 710 + 0, 632 X 1 - 7, 873 X 2. From simultant test with Ftest= 35, 574; Ftable = 3, 32 and p = 0, 001 Conclusion: There was a association between power limb muscles and speed running to accuracy of shooting ball to goal of primary school students of gawanan karanganyar Keyword : Power Limb Muscles, Speed <b>Running,</b> <b>Accuracy</b> of Shooting, Football, Student...|$|E
40|$|Abstract. We {{present a}} template-based {{pipeline}} that performs realtime speed-limit-sign recognition using an embedded {{system with a}} lowend GPU as the main processing element. Our pipeline operates in the frequency domain, and uses nonlinear composite filters and a contrastenhancing preprocessing step to improve its <b>accuracy.</b> <b>Running</b> at interactive rates, our system achieves 90 % accuracy over 120 EU speed-limit signs on 45 minutes of video footage, superior to the 75 % accuracy of a non-real-time GPU-based SIFT pipeline. ...|$|R
40|$|We {{explore the}} concept of hybrid grammars, which formalize and generalize a range of {{existing}} frameworks for dealing with discontinuous syntactic structures. Covered are both discontinuous phrase structures and non-projective dependency structures. Technically, hybrid grammars are related to synchronous grammars, where one grammar component generates linear structures and another generates hierarchical structures. By coupling lexical elements of both components together, discontinuous structures result. Several types of hybrid grammars are characterized. We also discuss grammar induction from treebanks. The main advantage over existing frameworks {{is the ability of}} hybrid grammars to separate discontinuity of the desired structures from time complexity of parsing. This permits exploration of a large variety of parsing algorithms for discontinuous structures, with different properties. This is confirmed by the reported experimental results, which show a wide variety of <b>running</b> time, <b>accuracy</b> and frequency of parse failures. Publisher PDFPeer reviewe...|$|R
40|$|A dynamic {{user context}} {{inference}} method {{is one of}} the important technologies for realizing context-aware services. In this paper, we show a context inference scheme that realizes a user posture inference with only one acceleration sensor embedded in a mobile handset. To improve inference accuracy, the system automatically detects the sensor position on the user's body and dynamically selects the most relevant inference method. Our experimental results show that the system can infer a user’s posture (sitting, standing, walking, and <b>running)</b> with an <b>accuracy</b> of more than 96 %...|$|R
40|$|Circular {{feature is}} one of the most common part {{features}} used in machines. Since it is practically impossible to make a part with perfect geometry, tolerances are specified to ensure the functionality of a final product while maintaining a low cost. This study presents fundamental treatments for circularity tolerance modeling, analysis, and design. First, a roundness profile model is presented. At present, the standard for geometric dimensioning and tolerancing, ASME Y 14. 5 M, specifies a circularity tolerance based on the tolerance zones defined by two concentric circular boundaries. To represent profile variation within the tolerance zones, a harmonic roundness model using Fourier series expansions is proposed. A cutting profile simulation model has also been developed to illustrate the relationship between the radial error motion of a machine tool spindle and the resultant part profiles. The profile model has been verified statistically by a large number of real profiles produced by turning and cylindrical grinding. Second, the effect of out-of-roundness on positioning accuracy is investigated for various cylindrical fit conditions. Analytical approaches and computer simulations are used together to facilitate more extensive investigations. Systematic procedures are also proposed for assigning circularity tolerance by prescribing a fit condition and a desirable process capability of assembly. As a result, new circularity tolerance guidelines are suggested for fit conditions. Third, the study is further extended to spindle design analysis. The geometrical accuracy of a machine tool spindle has been investigated to examine the effect of circularity and concentricity tolerance on spindle <b>running</b> <b>accuracy.</b> The study is verified through real spindle design data obtained from a custom-built Purdue High Speed Spindle. Finally, an experimental study is provided to verify the simulation routines used in the analysis of positioning accuracy. ...|$|E
40|$|Using an {{optimization}} algorithm {{to solve a}} machine learning problem is one of mainstreams {{in the field of}} science. In this work, we demonstrate a comprehensive comparison of some state-of-the-art first-order {{optimization algorithm}}s for convex optimization problems in machine learning. We concentrate on several smooth and non-smooth machine learning problems with a loss function plus a regularizer. The overall experimental results show the superiority of primal-dual algorithms in solving a machine learning problem from the perspectives of the ease to construct, <b>running</b> time and <b>accuracy.</b> Comment: Part of the OAGM 2014 proceedings (arXiv: 1404. 3538...|$|R
40|$|Abstract: 2 ̆ 2 We {{define a}} class of Markov chains that are called {{recursive}} foreground-background quasi-birth-and-death (RFBQBD) processes, and describe approximate (nearly exact) analyses of an RF-BQBD process. An RFBQBD process consists of a foreground QBD process whose transitions depend {{on the level of}} a background QBD process, where the transitions of the background QBD process may depend on the level of another background QBD process, and this dependency may be repeated recursively. We also evaluate the <b>running</b> time and <b>accuracy</b> of the analyses numerically by applying them to analyze the performance of a particular task assignment policy in a multiserver system. 2 ̆...|$|R
40|$|Maintenance actions {{cannot be}} defined and {{undertaken}} {{in isolation from}} the business and production objectives of a typical company. They must be predicted and subsequently planned into the production schedule. Condition monitoring identifies changes within defined monitoring parameters to trigger maintenance. These changes when combined with engineering knowledge, historical data and other monitoring parameters enable the prediction and identification of these changes in state. The data carries with it uncertainties in measurement <b>accuracy,</b> <b>running</b> conditions, and regularity. This paper reviews methods for trending and prediction, and describes how an adaptive approach {{to the definition of}} alarm levels can be used to improve the prediction capabilities when analysing routine condition monitoring measurement data...|$|R
40|$|Abstract This paper {{focuses on}} a new {{extension}} version of double Divide and Conquer (dDC) algorithm to eigen decomposition. Recently, dDC was proposed for singular value decomposition (SVD) of rectangular matrix. The dDC for SVD consists of two parts. One is Divide and Conquer (D&C) for singular value {{and the other is}} twisted factorization for singular vector. The memory usage of dDC is smaller than that of D&C. Both theoretical and running time are also shorter than those of D&C. In this paper, a new dDC for eigen decomposition is proposed. A shift of origin is introduced into our dDC. By some numerical tests, dDC is evaluated with respect to <b>running</b> time and <b>accuracy...</b>|$|R
40|$|In {{this paper}} we tackle {{the problem of}} {{matching}} two colored point sets in R 3 under the bottleneck distance. First we present an exact matching algo-rithm that requires the computation of intersections of complex algebraic surfaces. To avoid this, we also present an approximate algorithm that is im-plementable and has improved asymptotic cost {{at the price of}} having the risk of ”missing ” some solu-tions. For the case of sets with very different cardi-nality, we speed up calculations by using a Lossless Filtering preprocess that discards the zones of the bigger set where matches cannot occur. We provide formal and experimental discussion on the <b>running</b> time and <b>accuracy</b> of the approximate algorithm (with and without Lossless Filtering preprocess). ...|$|R
40|$|A fast corn {{grading system}} can replace the {{traditional}} method in unofficial corn grading locations. The initial {{design of the}} system proved that it can classify corn kernels with a high success rate. This study tested the robustness of the system against samples from different locations with different moisture contents. The experimental results were compared with the official grading results for 3 out of the 6 samples. This study also tested {{the limitations of the}} segmentation algorithm. The results showed that 60 to 70 kernels in a 100 cm 2 could be correctly segmented in a relatively short <b>running</b> time. Classification <b>accuracy</b> would improve with modifications to the system, including increased training samples of damaged kernels, uniform illumination, color calibration, and improved weight approximation of the kernels...|$|R
40|$|Abstract — The Challenge Problem {{posed by}} Pevzner et al. showed that especial {{algorithms}} are necessity to detect weak motifs in bio-sequences, where the the classical approaches, such as MEME and Gibbs Sampler, fail. Though several algorithms {{have since been}} developed to solve the weak motif recognition problem, their {{focus has been on}} exact datasets and their performances show poor tolerance to the noisy datasets, i. e., for datasets bearing sequences without any motif instances. We propose a novel approach to find weak motifs that is robust to noise in the datasets. The experiments with synthetic datasets show improvements in <b>running</b> time and <b>accuracy</b> in detecting weak motifs over the existing approaches. The application of the algorithm on some promoter datasets from yeast genomes found previously-proven binding sites. I...|$|R
40|$|Deep {{learning}} architectures {{are showing}} great promise in various computer vision domains including image classification, object detection, event detection and action recognition. In this study, we investigate {{various aspects of}} convolutional neural networks (CNNs) from the big data perspective. We analyze recent studies and different network architectures {{both in terms of}} <b>running</b> time and <b>accuracy.</b> We present extensive empirical information along with best practices for big data practitioners. Using these best practices we propose efficient fusion mechanisms both for single and multiple network models. We present state-of-the art results on benchmark datasets while keeping computational costs at a lower level. Another contribution of our paper is that these state-of-the-art results can be reached without using extensive data augmentation techniques. Comment: To appear in The Second IEEE International Conference on Multimedia Big Data (IEEE BigMM 2016...|$|R
40|$|In most {{probabilistic}} risk assessments, {{there is}} a subset of accident scenarios that involves physical challenges to the system, such as high heat rates and/or accelerations. The system`s responses to these challenges may be complicated, and their prediction may {{require the use of}} long-running computer codes. To deal with the many scenarios demanded by a risk assessment, the authors have been investigating the use of artificial neural networks (ANNs) as a fast-running estimation tool. They have developed a multivariate linear spline algorithm by extending previous ANN methods that use radial basis functions. They have applied the algorithm to problems involving fires, shocks, and vibrations. They have found that within the parameter range for which it is trained, the algorithm can simulate the nonlinear responses of complex systems with high <b>accuracy.</b> <b>Running</b> times per case are less than one second...|$|R
40|$|We {{present a}} {{threefold}} {{contribution to the}} computational task of motif discovery, a key component in the effort of delineating the regulatory map of a genome: (1) We constructed a comprehensive large-scale, publicly-available compendium of transcription factor and microRNA target gene sets derived from diverse high-throughput experiments in several metazoans. We used the compendium as a benchmark for motif discovery tools. (2) We developed Amadeus, a highly efficient, user-friendly software platform for genome-scale detection of novel motifs, applicable {{to a wide range}} of motif discovery tasks. Amadeus improves upon extant tools in terms of <b>accuracy,</b> <b>running</b> time, output information, and ease of use and is the only program that attained a high success rate on the metazoan compendium. (3) We demonstrate that by searching for motifs based on their genome-wide localization or chromosomal distributions (without using a predefined target set), Amadeus uncovers diverse known phenomena, as well as novel regulatory motifs...|$|R
40|$|Dependency parsers are {{critical}} components within many NLP systems. However, currently available dependency parsers each exhibit {{at least one}} of several weaknesses, including high <b>running</b> time, limited <b>accuracy,</b> vague dependency labels, and lack of nonprojectivity support. Furthermore, no commonly used parser provides additional shallow semantic interpretation, such as preposition sense disambiguation and noun compound interpretation. In this paper, we present a new dependency-tree conversion of the Penn Treebank along with its associated fine-grain dependency labels and a fast, accurate parser trained on it. We explain how a non-projective extension to shift-reduce parsing can be incorporated into non-directional easy-first parsing. The parser performs well when evaluated on the standard test section of the Penn Treebank, outperforming several popular open source dependency parsers; it is, {{to the best of our}} knowledge, the first dependency parser capable of parsing more than 75 sentences per second at over 93 % accuracy. ...|$|R
40|$|Due to the advancements in {{technology}} number of {{entries in the}} structural database of pro-teins are increasing day by day. Methods for retrieving protein tertiary structures from this large database {{is the key to}} comparative analysis of structures which plays an important role to under-stand proteins and their function. In this paper, we present fast and accurate methods for the retrieval of proteins from a large database with tertiary structures similar to a query protein. Our proposed methods borrow ideas from the field of computer vision. The speed and accuracy of our methods comes from the two newly introduced features, the co-occurrence matrix of the ori-ented gradient and pyramid histogram of oriented gradient and from the use of Euclidean distance as the distance measure. Experimental results clearly indicate the superiority of our approach in both <b>running</b> time and <b>accuracy.</b> Our method is readily available for use from this website...|$|R
40|$|In recent years, {{researchers}} in decision analysis and artificial intelligence (AI) have used Bayesian belief networks to build models of expert opinion. Using standard methods {{drawn from the}} theory of computational complexity, workers in the field {{have shown that the}} problem of exact probabilistic inference on belief networks almost certainly requires exponential computation in the worst ease [3]. We have previously described a randomized approximation scheme, called BN-RAS, for computation on belief networks [1, 2, 4]. We gave precise analytic bounds on the convergence of BN-RAS and showed how to trade <b>running</b> time for <b>accuracy</b> in the evaluation of posterior marginal probabilities. We now extend our previous results and demonstrate the generality of our framework by applying similar mathematical techniques to the analysis of convergence for logic sampling [7], an alternative simulation algorithm for probabilistic inference. Comment: Appears in Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence (UAI 1990...|$|R
40|$|We {{consider}} convex stochastic {{programs with}} an (approximate) initial probability distribution P having finite support supp P, i. e., finitely many scenarios. Such stochastic programs behave stable {{with respect to}} perturbations of P {{measured in terms of}} a Fortet-Mourier probability metric. The problem of optimal scenario reduction consists in determining a probability measure which is supported by a subset of supp P of prescribed cardinality and is closest to P in terms of such a probability metric. Two new versions of forward and backward type algorithms are presented for computing such optimally reduced probability measures approximately. Compared to earlier versions, the computational performance (<b>accuracy,</b> <b>running</b> time) of the new algorithms is considerably improved. Numerical experience is reported for different instances of scenario trees with computable optimal lower bounds. The test examples also include a ternary scenario tree representing the weekly electrical load process in a power management model...|$|R
50|$|Overall, {{the style}} of play is {{typically}} slower than other action games. Jumping techniques are sometimes de-emphasized {{in order to promote}} realism, with some games {{going so far as to}} omit a jump button. In contrast to games that emphasize running and shooting, tactical shooters require more caution and patience (making use of cover and avoiding being caught in the open), plus tactical shooters are usually designed so that shooting becomes inaccurate while <b>running</b> which increasing <b>accuracy</b> for crouching or prone stances. Players often have the choice of shooting from the hip ("hippie") which is less accurate but gives a wider view of the area, or using the scope/iron sights for better zoom-in accuracy but at the penalty of restricted view. Some tactical shooters such as the InfiltrationMod for Unreal Tournament (1999) even lack the crosshair seen in other first-person shooters, in order to achieve a high degree of realism.|$|R
40|$|Wearable {{devices that}} measure and {{recognise}} human activity {{in real time}} require classification algorithms that are both fast and accurate when implemented on limited hardware. A decision-tree-based method for differentiating between individual walking, running, stair climbing and stair descent strides using a single channel of a foot-mounted gyroscope suitable for implementation on embedded hardware is presented. Temporal features unique to each activity were extracted using an initial subject group (n = 13) and a decision-tree-based classification algorithm was developed using the timing information of these features. A second subject group (n = 10) completed the same activities to provide data for verification of the system. Results indicate that the classifier was able to correctly match each stride to its activity with > 90 % <b>accuracy.</b> <b>Running</b> and walking strides in particular matched with > 99 % accuracy. The outcomes demonstrate that a lightweight yet robust classification system is feasible for implementation on embedded hardware for real-time daily monitoring...|$|R
40|$|Quantiles {{are very}} {{important}} statistics information {{used to describe the}} distribution of datasets. Given the quantiles of a dataset, we can easily know the distribution of the dataset, which is a fundamental problem in data analysis. However, quite often, computing quantiles directly is inappropriate due to the memory limitations. Further, in many settings such as data streaming and sensor network model, even the data size is unpredictable. Although the quantiles computation has been widely studied, it was mostly in the sequential setting. In this paper, we study several quantile computation algorithms in the distributed setting and compare them in terms of space usage, <b>running</b> time, and <b>accuracy.</b> Moreover, we provide detailed experimental comparisons between several popular algorithms. Our work focuses on the approximate quantile algorithms which provide error bounds. Approximate quantiles have received more attentions than exact ones since they are often faster, can be more easily adapted to the distributed setting while giving sufficiently good statistical information on the data sets. Comment: M. S. Thesi...|$|R
