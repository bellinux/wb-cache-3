347|1455|Public
25|$|The {{value of}} the <b>rank</b> <b>function</b> is always a non-negative integer.|$|E
25|$|A poset is graded if {{and only}} if every {{connected}} component of its comparability graph is graded, so further characterizations will suppose this comparability graph to be connected. On each connected component the <b>rank</b> <b>function</b> is only unique up to a uniform shift (so the <b>rank</b> <b>function</b> can always be chosen so that the elements of minimal rank in their connected component have rank 0).|$|E
25|$|In {{some common}} posets {{such as the}} face lattice of a convex polytope {{there is a natural}} grading by dimension, which if used as <b>rank</b> <b>function</b> would give the minimal element, the empty face, rank –1. In such cases it might be {{convenient}} to bend the definition stated above by adjoining the value –1 to the set of values allowed for the <b>rank</b> <b>function.</b> Allowing arbitrary integers as rank would however give a fundamentally different notion; for instance the existence of a minimal element would no longer be assured.|$|E
40|$|AbstractThe Spohnian {{paradigm}} of <b>ranking</b> <b>functions</b> {{is in many}} respects like an order-of-magnitude reverse of subjective probability theory. Unlike probabilities, however, <b>ranking</b> <b>functions</b> are only indirectly—via a pointwise <b>ranking</b> <b>function</b> on the underlying set of possibilities W—defined on a field of propositions A over W. This research note shows under which conditions <b>ranking</b> <b>functions</b> on a field of propositions A over W and rankings on a language L are induced by pointwise <b>ranking</b> <b>functions</b> on W and the set of models for L, ModL, respectively...|$|R
40|$|A {{method and}} {{apparatus}} for determining a <b>ranking</b> <b>function</b> by regression using relative preference data. A number of iterations are performed {{in which to}} following is performed. The current <b>ranking</b> <b>function</b> is used to compare pairs of elements. The comparisons are checked against actual preference data to determine for which pairs the <b>ranking</b> <b>function</b> mis-predicted (contradicting pairs). A regression function is fitted {{to a set of}} training data that is based on contradicting pairs and a target value for each element. The target value for each element may be based on the value that the <b>ranking</b> <b>function</b> predicted for the other element in the pair. The <b>ranking</b> <b>function</b> for the next iteration is determined based, at least in part, on the regression <b>function.</b> The final <b>ranking</b> <b>function</b> is established based on the regression functions. For example, the final <b>ranking</b> <b>function</b> may be based on a linear combination of regression functions...|$|R
40|$|Learning to rank {{has become}} a popular method for web search ranking. Traditionally, expert-judged {{examples}} are the major training resource for machine learned web ranking, which is expensive to get for training a satisfactory <b>ranking</b> <b>function.</b> The demands for generating speciﬁc web search <b>ranking</b> <b>functions</b> tailored for different domains, such as <b>ranking</b> <b>functions</b> for different regions, have aggravated this problem. Recently, a few methods have been proposed to extract training examples from user clickthrough log. Due to the low cost of getting user preference data, it is attractive to combine these examples in training <b>ranking</b> <b>functions.</b> However, because of the different natures of {{the two types of}} data, they may have different inﬂuences on <b>ranking</b> <b>function.</b> Therefore, it is challenging to develop methods for effectively combining them in training <b>ranking</b> <b>functions.</b> In this paper, we address the problem of adapting an existing <b>ranking</b> <b>function</b> to user preference data, and develop a framework for conveniently tuning the contribution of the user preference data in the tuned <b>ranking</b> <b>function.</b> Experimental results show that with our framework it is convenient to generate a batch of adapted <b>ranking</b> <b>functions</b> and to select functions with different trade-offs between the base function and the user preference data...|$|R
25|$|The <b>rank</b> <b>function</b> of {{a linear}} matroid {{is given by}} the matrix rank of submatrices of this matrix, or {{equivalently}} by the dimension of the linear span of subsets of vectors.|$|E
25|$|A matroid {{is said to}} be {{connected}} if it is not the direct sum of two smaller matroids; that is, it is connected if and only if there do not exist two disjoint subsets of elements such that the <b>rank</b> <b>function</b> of the matroid equals the sum of the ranks in these separate subsets. Graphic matroids are connected if and only if the underlying graph is both connected and 2-vertex-connected.|$|E
25|$|A {{candidate}} <b>rank</b> <b>function,</b> {{compatible with}} the ordering, makes a poset into graded poset if and only if, whenever one has xnbsp&<nbsp&z with z of rank n+1, an element y of rank n can be found with xnbsp&≤nbsp&ynbsp&<nbsp&z. This condition is sufficient because if z is taken to be a cover of x, the only possible choice is ynbsp&=nbsp&x showing that the ranks of x and z differ by 1, and it is necessary because in a graded poset one can take for y any element of maximal rank with xnbsp&≤nbsp&ynbsp&<nbsp&z, which always exists and is covered by z.|$|E
40|$|Abstract <b>Ranking</b> <b>function</b> {{synthesis}} is a {{key component}} of modern termination provers for imperative programs. While it is well-known how to generate linear <b>ranking</b> <b>functions</b> for relations over (mathematical) integers or rationals, efficient synthesis of <b>ranking</b> <b>functions</b> for machine-level integers (bit-vectors) is an open problem. This is particularly relevant for the verification of low-level code. We propose several novel algorithms to generate <b>ranking</b> <b>functions</b> for relations over machine integers: a complete method based on a reduction to Presburger arithmetic, and a template-matching approach for predefined classes of <b>ranking</b> <b>functions</b> based on reduction to SAT- and QBF-solving. The utility of our algorithms is demonstrated on examples drawn from Windows device drivers...|$|R
40|$|<b>Ranking</b> <b>functions</b> are {{instrumental}} for {{the success}} of an information retrieval (search engine) system. However nearly all existing <b>ranking</b> <b>functions</b> are manually designed based on experience, observations and probabilistic theories. This paper tested a novel <b>ranking</b> <b>function</b> discovery technique proposed in [Fan 2003 a, Fan 2003 b] – ARRANGER (Automatic geneRation of <b>RANking</b> <b>functions</b> by GEnetic pRogramming), which uses Genetic Programming (GP) to automatically learn the “best ” <b>ranking</b> <b>function,</b> for the robust retrieval task. <b>Ranking</b> <b>function</b> discovery is essentially an optimization problem. As the search space here is not a coordinate system, most of the traditional optimization algorithms could not work. However, this ranking discovery problem could be easily tackled by ARRANGER. In our evaluations on 150 queries from the ad-hoc track of TREC 6, 7, and 8, the performance of our system (in average precision) was improved by nearly 16 %, after replacing Okapi BM 25 function with a function automatically discovered by ARRANGER. By applying pseudo-relevance feedback and ranking fusion on newly discovered functions, we improved the retrieval performance by up to 30 %. The results of our experiments showed that our <b>ranking</b> <b>function</b> discovery technique – ARRANGER – is very effective in discovering high-performing <b>ranking</b> <b>functions.</b> 1...|$|R
50|$|One of the {{simplest}} <b>ranking</b> <b>functions</b> is computed by summing the tf-idf for each query term; many more sophisticated <b>ranking</b> <b>functions</b> are variants of this simple model.|$|R
25|$|It is also {{possible}} to define a notion of branch-decomposition for matroids that generalizes branch-decompositions of graphs. A branch-decomposition of a matroid is a hierarchical clustering of the matroid elements, represented as an unrooted binary tree with {{the elements of the}} matroid at its leaves. An e-separation may be defined {{in the same way as}} for graphs, and results in a partition of the set M of matroid elements into two subsets A and B. If ρ denotes the <b>rank</b> <b>function</b> of the matroid, then the width of an e-separation is defined as , and the width of the decomposition and the branchwidth of the matroid are defined analogously. The branchwidth of a graph and the branchwidth of the corresponding graphic matroid may differ: for instance, the three-edge path graph and the three-edge star have different branchwidths, 2 and 1 respectively, but they both induce the same graphic matroid with branchwidth 1. However, for graphs that are not trees, the branchwidth of the graph is equal to the branchwidth of its associated graphic matroid. The branchwidth of a matroid is equal to the branchwidth of its dual matroid, and in particular this implies that the branchwidth of any planar graph that is not a tree is equal to that of its dual.|$|E
25|$|A graded poset (with {{positive}} integer ranks) cannot {{have any}} elements x for which arbitrarily long chains with greatest element x exist, as otherwise {{it would have}} to have elements of arbitrarily small (and eventually negative) rank. For instance, the integers (with the usual order) cannot be a graded poset, nor can any interval (with more than one element) of rational or real numbers. (In particular, graded posets are well-founded, meaning that they satisfy the descending chain condition (DCC): they do not contain any infinite descending chains. has arbitrarily long chains descending fromnbsp&, but has no infinite descending chains.) Henceforth we shall therefore only consider posets in which this does not happen. This implies that whenever xnbsp&<nbsp&y we can get from x to y by repeatedly choosing a cover, finitely many times. It also means that (for positive integer rank functions) compatibility of ρ with the ordering follows from the requirement about covers. As a variant of the definition of a graded poset, Birkhoff allows rank functions to have arbitrary (rather than only nonnegative) integer values. In this variant, the integers can be graded (by the identity function) in his setting, and the compatibility of ranks with the ordering is not redundant. As a third variant, Brightwell and West define a <b>rank</b> <b>function</b> to be integer-valued, but don't require its compatibility with the ordering; hence this variant can grade even e.g. the real numbers by any function, as the requirement about covers is vacuous for this example.|$|E
2500|$|Some {{examples}} of graded posets (with the <b>rank</b> <b>function</b> in parentheses) are: ...|$|E
40|$|Abstract. We present two {{algorithms}} {{to prove}} termination of programs by synthesizing linear <b>ranking</b> <b>functions.</b> The first uses an invariant generator based on iterative forward propagation with widening and extracts <b>ranking</b> <b>functions</b> from the generated invariants by manipulating polyhedral cones. It {{is capable of}} finding subtle <b>ranking</b> <b>functions</b> which are linear combinations of many program variables, but is limited to programs with few variables. The second, more heuristic, algorithm targets the class of structured programs with single-variable <b>ranking</b> <b>functions.</b> Its invariant generator uses a heuristic extrapolation operator to avoid iterative forward propagation over program loops. For the programs we have considered, this approach converges faster and the invariants it discovers are sufficiently strong to imply the existence of <b>ranking</b> <b>functions...</b>|$|R
40|$|Fan et al. 2 <b>Ranking</b> <b>function</b> is {{instrumental}} in affecting {{the performance of}} a search engine. Designing and optimizing a search engine’s <b>ranking</b> <b>function</b> remains a daunting task for computer and information scientists. Recently, genetic programming (GP), a machine learning technique based on evolutionary theory, has shown promise in tackling this very difficult problem. <b>Ranking</b> <b>functions</b> discovered by GP {{have been found to be}} significantly better than many of the other existing <b>ranking</b> <b>functions.</b> However, current GP implementations for <b>ranking</b> <b>function</b> discovery are all de-signed utilizing the Vector Space model in which the same term weighting strategy is applied to all terms in a document. This may not be an ideal representation scheme at the individual query level considering the fact that many query terms should play different roles in the final ranking. In this paper, we propose a novel nonlinear <b>ranking</b> <b>function</b> representation scheme and compare this new design to the well-known Vector Space model. We theoretically show that the new represen-tation scheme subsumes the traditional Vector Space model representation scheme as a special case and hence allows for additional flexibility in term weighting. We test the new representation scheme with the GP-based discovery framework in a personalized search (information routing) context using a TREC web corpus. The experimental results show that the new <b>ranking</b> <b>function</b> representation de-sign outperforms the traditional Vector Space model for GP-based <b>ranking</b> <b>function</b> discovery. ...|$|R
40|$|Suppose all the {{individuals}} in a field are linearly ordered. Groups of individuals form teams. Is there a perfect <b>ranking</b> <b>function</b> of each team based on {{the members of the}} team? We prove that under a very mild and reasonable set of axioms for the <b>ranking</b> <b>function,</b> no such <b>ranking</b> <b>function</b> exists. AMS Subject Classification: 68 R 05, 91 F 10, 06 A 05, 06 A 07...|$|R
2500|$|A lattice [...] {{is called}} graded, {{sometimes}} ranked (but see Ranked poset {{for an alternative}} meaning), {{if it can be}} equipped with a <b>rank</b> <b>function</b> r from L to ℕ, sometimes to ℤ, compatible with the ordering (so [...] whenever [...] ) such that whenever y covers x, then [...] [...] The value of the <b>rank</b> <b>function</b> for a lattice element is called its rank.|$|E
2500|$|... be the <b>rank</b> <b>function</b> of P and let P'S be the S-rank {{selected}} subposet, {{which consists}} of the elements from P whose rank is in S: ...|$|E
2500|$|The <b>rank</b> <b>function</b> is {{compatible}} with the ordering, meaning that for every x and y in the order with x<y, it must be the case that ρ(x)<ρ(y), and ...|$|E
40|$|The final {{publication}} {{is available}} at link. springer. com. International audienceTermination analyzers generally synthesize <b>ranking</b> <b>functions</b> or relations, which represent checkable proofs of their results. In [], we proposed an approach for conditional termination analysis based on abstract fixpoint computation by policy iteration. This method {{is not based on}} <b>ranking</b> <b>functions</b> and does not directly provide a ranking relation, which makes the comparison with existing approaches difficult. In this paper we study the relationships between our approach and <b>ranking</b> <b>functions</b> and relations, focusing on extensions of linear <b>ranking</b> <b>functions.</b> We show that it can work on programs admitting a specific kind of segmented <b>ranking</b> <b>functions,</b> and that the results can be checked by the construction of a disjunctive ranking relation. Experimental results show the interest of this approach...|$|R
40|$|We study <b>rank</b> <b>functions</b> (also {{known as}} graph homomorphisms onto Z), ways of {{imposing}} graded poset structures on graphs. We {{first look at}} a variation on <b>rank</b> <b>functions</b> called discrete Lipschitz functions. We relate the number of Lipschitz functions of a graph G {{to the number of}} <b>rank</b> <b>functions</b> of both G and G × E. We then find generating functions that enable us to compute the number of <b>rank</b> or Lipschitz <b>functions</b> of a given graph. We look at a subset of graphs called squarely generated graphs, which are graphs whose cycle space has a basis consisting only of 4 -cycles. We show that the number of <b>rank</b> <b>functions</b> of such a graph is proportional to the number of 3 -colorings of the same graph, thereby connecting <b>rank</b> <b>functions</b> to the Potts model of statistical mechanics. Lastly, we look at some asymptotics of <b>rank</b> and Lipschitz <b>functions</b> for various types of graphs. ...|$|R
40|$|The {{scope of}} this work is the constraint-based {{synthesis}} of termination arguments for the restricted class of programs called linear lasso programs. A termination argument consists of a <b>ranking</b> <b>function</b> {{as well as a}} set of supporting invariants. We extend existing methods in several ways. First, we use Motzkin's Transposition Theorem instead of Farkas' Lemma. This allows us to consider linear lasso programs that can additionally contain strict inequalities. Existing methods are restricted to non-strict inequalities and equalities. Second, we consider several kinds of ranking functions: affine-linear, piecewise and lexicographic <b>ranking</b> <b>functions.</b> Moreover, we present a novel kind of <b>ranking</b> <b>function</b> called multiphase <b>ranking</b> <b>function</b> which proceeds through a fixed number of phases such that for each phase, there is an affine-linear <b>ranking</b> <b>function.</b> As an abstraction to the synthesis of specific <b>ranking</b> <b>functions,</b> we introduce the notion <b>ranking</b> <b>function</b> template. This enables us to handle all <b>ranking</b> <b>functions</b> in a unified way. Our method relies on non-linear algebraic constraint solving as a subroutine which is known to scale poorly to large problems. As a mitigation we formalize an assessment of the difficulty of our constraints and present an argument why they are of an easier kind than general non-linear constraints. We prove our method to be complete: if there is a termination argument of the form specified by the given <b>ranking</b> <b>function</b> template with a fixed number of affine-linear supporting invariants, then our method will find a termination argument. To our knowledge, the approach we propose is the most powerful technique of synthesis-based discovery of termination arguments for linear lasso programs and encompasses and enhances several methods having been proposed thus far. Comment: Master's Thesi...|$|R
2500|$|Let [...] be a matroid on {{a finite}} set , with <b>rank</b> <b>function</b> [...] as above. [...] The closure [...] of a subset [...] of [...] is the set ...|$|E
2500|$|In mathematics, in {{the branch}} of combinatorics, a graded poset is a {{partially}} ordered set (poset) P equipped with a <b>rank</b> <b>function</b> ρ from P to N satisfying the following two properties: ...|$|E
2500|$|A finite lattice is modular if {{and only}} if it is both upper and lower semimodular. For a graded lattice, (upper) semimodularity is {{equivalent}} to the following condition on the <b>rank</b> <b>function</b> r: ...|$|E
40|$|The {{dramatic}} {{growth in}} the number of application domains that naturally generate probabilistic, uncertain data has resulted in a need for efficiently supporting complex querying and decision-making over such data. In this paper, we present a unified approach to ranking and top-k query processing in probabilistic databases by viewing it as a multi-criteria optimization problem, and by deriving a set of features that capture the key properties of a probabilistic dataset that dictate the ranked result. We contend that a single, specific <b>ranking</b> <b>function</b> may not suffice for probabilistic databases, and we instead propose two parameterized <b>ranking</b> <b>functions,</b> called P RF ω and P RF e, that generalize or can approximate many of the previously proposed <b>ranking</b> <b>functions.</b> We present novel generating functions-based algorithms for efficiently ranking large datasets according to these <b>ranking</b> <b>functions,</b> even if the datasets exhibit complex correlations modeled using probabilistic and/xor trees or Markov networks. We further propose that the parameters of the <b>ranking</b> <b>function</b> be learned from user preferences, and we develop an approach to learn those parameters. Finally, we present a comprehensive experimental study that illustrates the effectiveness of our parameterized <b>ranking</b> <b>functions,</b> especially P RF e, at approximating other <b>ranking</b> <b>functions</b> and the scalability of our proposed algorithms for exact or approximate ranking. 1...|$|R
40|$|Machine Learned Ranking {{approaches}} have shown successes in web search engines. With the increasing demands on developing effective <b>ranking</b> <b>functions</b> for different search domains, {{we have seen}} a big bottleneck, i. e., the problem of insufficient training data, which has significantly limited the fast development and deployment of machine learned <b>ranking</b> <b>functions</b> for different web search domains. In this paper, we propose a new approach called tree based <b>ranking</b> <b>function</b> adaptation (“tree adaptation”) to address this problem. Tree adaptation assumes that <b>ranking</b> <b>functions</b> are trained with regression-tree based modeling methods, such as Gradient Boosting Trees. It takes such a <b>ranking</b> <b>function</b> from one domain and tunes its tree-based structure {{with a small amount of}} training data from the target domain. The unique features include (1) it can automatically identify the part of model that needs adjustment for the new domain, (2) it can appropriately weight training examples considering both local and global distributions. Experiments are performed to show that tree adaptation can provide better-quality <b>ranking</b> <b>functions</b> for a new domain, compared to other modeling methods...|$|R
40|$|The {{problem of}} ranking, {{in which the}} goal is to learn a real-valued <b>ranking</b> <b>function</b> that induces a ranking or {{ordering}} over an instance space, has recently gained attention in machine learning. We define a model of learnability for <b>ranking</b> <b>functions</b> in a particular setting of the ranking problem known as the bipartite ranking problem, and derive a number of results in this model. Our first main result provides a sufficient condition for the learnability of a class of <b>ranking</b> <b>functions</b> F: we show that F is learnable if its bipartite rank-shatter coefficients, which measure the richness of a <b>ranking</b> <b>function</b> class {{in the same way as}} do the standard VC-dimension related shatter coefficients (growth function) for classes of classification functions, do not grow too quickly. Our second main result gives a necessary condition for learnability: we define a new combinatorial parameter for a class of <b>ranking</b> <b>functions</b> F that we term the rank dimension of F, and show that F is learnable only if its rank dimension is finite. Finally, we investigate questions of the computational complexity of learning <b>ranking</b> <b>functions...</b>|$|R
2500|$|The [...] "top twelve" [...] letters {{constitute}} about 80% of {{the total}} usage. The [...] "top eight" [...] letters constitute about 65% {{of the total}} usage. Letter frequency {{as a function of}} rank can be fitted well by several rank functions, with the two-parameter Cocho/Beta <b>rank</b> <b>function</b> being the best. Another <b>rank</b> <b>function</b> with no adjustable free parameter also fits the letter frequency distribution reasonably well (the same function has been used to fit the amino acid frequency in protein sequences.) A spy using the VIC cipher or some other cipher based on a straddling checkerboard typically uses a mnemonic such as [...] "a sin to err" [...] (dropping the second [...] "r") ...|$|E
2500|$|A bounded poset admits a grading if {{and only}} if all maximal chains in P have the same length: and [...] both being maximal chains. setting the rank of the least element to 0 then determines the <b>rank</b> <b>function</b> completely. This covers many finite cases of interest; see picture for a {{negative}} example. However, unbounded posets can be more complicated.|$|E
2500|$|The {{value of}} the <b>rank</b> <b>function</b> for {{an element of the}} poset is called its rank. Sometimes a graded poset is called a ranked poset but that phrase has other meanings; see ranked poset. A rank or [...] rank level of a graded poset is the subset of all the {{elements}} of the poset that have a given rank value.|$|E
40|$|Learning <b>ranking</b> (or preference) <b>functions</b> {{has been}} a major issue in the machine {{learning}} community and has produced many applications in information retrieval. SVMs (Support Vector Machines) - a classification and regression methodology- have also shown excellent performance in learning <b>ranking</b> <b>functions.</b> They effectively learn <b>ranking</b> <b>functions</b> of high generalization based on the “large-margin ” principle and also systematically support nonlinear ranking by the “kernel trick”. In this paper, we propose an SVM selective sampling technique for learning <b>ranking</b> <b>functions.</b> SVM selective sampling (or active learning with SVM) has been studied in the context of classification. Such techniques reduce the labeling effort in learning classification functions by selecting only the most informative samples to be labeled. However, they are not extendable to learning <b>ranking</b> <b>functions,</b> as the labeled data in ranking is relative ordering, or partial orders of data. Our proposed sampling technique effectively learns an accurate SVM <b>ranking</b> <b>function</b> with fewer partial orders. We apply our sampling technique to the data retrieval application, which enables fuzzy search on relational databases by interacting with users for learning their preferences. Experimental results show a significant reduction of the labeling effort in inducing accurate <b>ranking</b> <b>functions...</b>|$|R
40|$|<b>Ranking</b> <b>functions</b> are {{qualitative}} {{degrees of}} uncertainty ascribed to events charged by uncertainty and taking as their values non-negative in-tegers {{in the sense}} of ordinal numbers. Introduced are <b>ranking</b> <b>functions</b> induced by real-valued possibilistic measures and it is shown that differ-ent possibilistic measures with identical <b>ranking</b> <b>functions</b> yield the same results when applied in decision procedures based on qualitative compa-ration of the magnitudes of the possibilistic measures in question ascribed to the uncertain events...|$|R
40|$|Abstract. The {{discovery}} of invariants and <b>ranking</b> <b>functions</b> plays {{a central role}} in program verification. In our previous work, we investi-gated invariant generation and non-linear <b>ranking</b> <b>function</b> discovering of polynomial programs by reduction to semi-algebraic systems solving. In this paper we will first summarize our results on the two topics and then show how to generalize the approach to discovering more expressive invariants and <b>ranking</b> <b>functions,</b> and applying to more general programs...|$|R
