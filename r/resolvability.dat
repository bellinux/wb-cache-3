339|0|Public
25|$|A typical HTM {{network is}} a tree-shaped {{hierarchy}} of levels that {{are composed of}} smaller elements called nodes or columns. A single level in the hierarchy is also called a region. Higher hierarchy levels often have fewer nodes and therefore less spatial <b>resolvability.</b> Higher hierarchy levels can reuse patterns learned at the lower levels by combining them to memorize more complex patterns.|$|E
25|$|The {{celestial}} sphere has been divided into 88 constellations. The International Astronomical Union (IAU) constellations are {{areas of the}} sky. Each of these contains remarkable X-ray sources. Some of them are have been identified from astrophysical modeling to be galaxies or black holes at the centers of galaxies. Some are pulsars. As with sources already successfully modeled by X-ray astrophysics, striving to understand the generation of X-rays by the apparent source helps to understand the Sun, the universe as a whole, and how these affect us on Earth. Constellations are an astronomical device for handling observation and precision independent of current physical theory or interpretation. Astronomy {{has been around for}} a long time. Physical theory changes with time. With respect to celestial X-ray sources, X-ray astrophysics tends to focus on the physical reason for X-ray brightness, whereas X-ray astronomy tends to focus on their classification, order of discovery, variability, <b>resolvability,</b> and their relationship with nearby sources in other constellations.|$|E
2500|$|The <b>resolvability</b> {{criterion}} {{states that}} [...] "the probability of an exact tie must diminish as more votes are cast". IRV meets this criterion.|$|E
6000|$|... "The Nubecula Major, {{like the}} Minor, {{consists}} partly of large [...] tracts and ill-defined patches of irresolvable nebula, and of [...] nebulosity in {{every stage of}} resolution, up to perfectly resolved [...] stars like the Milky Way, as also of regular and irregular nebulæ [...] properly so called, of globular clusters in every stage of [...] <b>resolvability,</b> and of clustering groups sufficiently insulated and [...] condensed to come under the designation of 'clusters of [...] stars.'"--Cape Observations, p. 146.|$|E
6000|$|Among the [...] "irregular nebulæ," [...] says Sir John Herschel, [...] "may be [...] comprehended all which, to a want of {{complete}} {{and in most}} [...] instances even of partial <b>resolvability</b> {{by the power of}} the [...] 20-feet reflector, unite such a deviation from the circular or [...] elliptic form, or such a want of symmetry (with that form) as [...] preclude their being placed in class 1, or that of Regular Nebulæ. [...] This second class comprises many of the most remarkable and [...] interesting objects in the heavens, as well as the most extensive [...] in respect of the area they occupy." ...|$|E
6000|$|On {{the other}} hand, what follows {{if the truth}} of the {{assumption}} be granted? The arguments used to justify this assumption {{in the case of the}} stars, equally justify it in the case of the nebulæ. It cannot be contended that, on the average, the apparent sizes of the stars indicate their distances, without its being admitted that, on the average, the apparent sizes of the nebulæ indicate their distances--that, generally speaking, the larger are the nearer and the smaller are the more distant. Mark, now, the necessary inference respecting their <b>resolvability.</b> The largest or nearest nebulæ will be most easily resolved into stars; the successively smaller will be successively more difficult of resolution; and the irresolvable ones will be the smallest ones. This, however, is exactly the reverse of the fact. The largest nebulæ are either wholly irresolvable, or but partially resolvable under the highest telescopic powers; while large numbers of quite small nebulæ are easily resolved by far less powerful telescopes. An instrument through which the great nebula in Andromeda, two and a half degrees long and one degree broad, appears merely as a diffused light, decomposes a nebula of fifteen minutes diameter into twenty thousand starry points. At the same time that the individual stars of a nebula eight minutes in diameter are so clearly seen as to allow of their number being estimated, a nebula covering an area five hundred times as great shows no stars at all! What possible explanation of this can be given on the current hypothesis? ...|$|E
6000|$|In {{the centre}} of a spiral nebula is seen a mass both more {{luminous}} and more resolvable than the rest. Assume that, in process of time, all the spiral streaks of luminous matter which converge to this centre are drawn into it, as they must be; assume further, that the flocculi, or other discrete portions constituting these luminous streaks, aggregate into larger masses {{at the same time}} that they approach the central group, and that the masses forming this central group also aggregate into larger masses; and there will finally result a cluster of such larger masses, which will be resolvable with comparative ease. And, as the coalescence and concentration go on, the constituent masses will gradually become fewer, larger, brighter, and more densely collected around the common centre of gravity. See now how completely this inference agrees with observation. [...] "The circular form is that which most commonly characterises resolvable nebulæ," [...] writes Arago. Resolvable nebulæ, says Sir John Herschel, [...] "are almost universally round or oval." [...] Moreover, {{the centre of}} each group habitually displays a closer clustering of the constituent masses than the outer parts; and it is shown that, under the law of gravitation, which we now know extends to the stars, this distribution is not one of equilibrium, but implies progressing concentration. While, just as we inferred that, according to circumstances, the extent to which aggregation has been carried must vary; so we find that, in fact, there are regular nebulæ of all degrees of <b>resolvability,</b> from those consisting of innumerable minute masses, to those in which their numbers are smaller and the sizes greater, and to those in which there are a few large bodies worthy to be called stars.|$|E
6000|$|... "This {{combination}} of characters, rightly considered, is {{in a high}} [...] degree instructive, affording an insight into the probable [...] comparative distance of stars and nebulæ, and the real [...] brightness of individual stars as compared with one another. Taking [...] the apparent semidiameter of the nubecula major at three degrees, [...] and regarding its solid form as, roughly speaking, spherical, its [...] nearest and most remote parts differ in their distance from us by a [...] {{little more than a}} tenth part of our distance from its center. The [...] brightness of objects situated in its nearer portions, therefore, [...] cannot be much exaggerated, nor that of its remoter much [...] enfeebled, by their difference of distance; yet within this [...] globular space, we have collected upwards of six hundred stars of [...] the seventh, eighth, ninth, and tenth magnitudes, nearly three [...] hundred nebulæ, and globular and other clusters, of all degrees of [...] <b>resolvability,</b> and smaller scattered stars innumerable of every [...] inferior magnitude, from the tenth to such as by their multitude [...] and minuteness constitute irresolvable nebulosity, extending over [...] tracts of many square degrees. Were there but one such object, it [...] might be maintained without utter improbability that its apparent [...] sphericity is only an effect of foreshortening, and that in reality [...] a much greater proportional difference of distance between its [...] nearer and more remote parts exists. But such an adjustment, [...] improbable enough in one case, must be rejected as too much so for [...] fair argument in two. It must, therefore, be taken as a [...] demonstrated fact, that stars of the seventh or eighth magnitude [...] and irresolvable nebula may co-exist within limits of distance not [...] differing in proportion more than as nine to ten."--Outlines of [...] Astronomy (10th Ed.), pp. 656-57.|$|E
5000|$|<b>Resolvability</b> {{criterion}}The <b>resolvability</b> criterion {{states that}} [...] "the probability of an exact tie must diminish as more votes are cast". IRV meets this criterion.|$|E
5000|$|To {{carry out}} an {{assessment}} of the banks’ <b>resolvability</b> and to adopt resolution plans ...|$|E
50|$|<b>Resolvability</b> {{criterion}} {{can refer}} to any voting system criterion that ensures a low possibility of tie votes.|$|E
5000|$|... {{a partial}} (not complete) <b>resolvability</b> of these contradictions within the {{framework}} of international institutions or - in other words - by the cartel method, ...|$|E
5000|$|The Borda count {{satisfies}} the monotonicity criterion, the consistency criterion, the participation criterion, the <b>resolvability</b> criterion, the plurality criterion (trivially), reversal symmetry, and the Condorcet loser criterion ...|$|E
50|$|Minimum {{detectable}} {{temperature difference}} (MDTD), also called minimum detectable temperature (MDT), {{is not the}} same phenomenon as MRTD and is only subtly different. Like MRTD, it {{is a measure of the}} performance of infrared cameras.However, MDTD is a measure of visibility, not <b>resolvability.</b>|$|E
50|$|Resolution {{in terms}} of {{electron}} density {{is a measure of}} the <b>resolvability</b> in the electron density map of a molecule. In X-ray crystallography, resolution is the highest resolvable peak in the diffraction pattern, while resolution in cryo-electron microscopy is a frequency space comparison of two halves of the data, which strives to correlate with the X-ray definition.|$|E
5000|$|... to the neofunctionalist Europe-science and the communitarian {{method of}} Jean Monnet: The {{belief in the}} <b>resolvability</b> of the inner-European divergences of interests, in the {{feasibility}} of an efficient and conciliable Europe, is criticized by state cartel theory as naíve-idealistic. On the other hand, both integration theories agree {{with regard to the}} importance they attach to institution-building in state communities.|$|E
50|$|A typical HTM {{network is}} a tree-shaped {{hierarchy}} of levels that {{are composed of}} smaller elements called nodes or columns. A single level in the hierarchy is also called a region. Higher hierarchy levels often have fewer nodes and therefore less spatial <b>resolvability.</b> Higher hierarchy levels can reuse patterns learned at the lower levels by combining them to memorize more complex patterns.|$|E
50|$|The unit used in {{the object}} {{diameter}} results in the smallest resolvable features at that unit. In the above example they are approximated in kilometers resulting in the smallest resolvable Moon craters being 3.22 km in diameter. The Hubble Space Telescope has a primary mirror aperture of 2400 mm that provides a surface <b>resolvability</b> of Moon craters being 174.9 meters in diameter, or sunspots of 7365.2 km in diameter.|$|E
5000|$|... i.Promoting {{a coordinated}} {{programme}} of reforms to deliver resilient sources of market-based finance, including addressing structural vulnerabilities associated with asset management activities;ii.Developing robust financial market infrastructure, including assessing policies on central counterparty resilience, recovery and <b>resolvability,</b> and recommending any necessary improvements; andiii.Supporting effective macroprudential arrangements, by drawing lessons from national {{experiences of the}} practical application of macroprudential policy frameworks and tools working {{in partnership with the}} International Monetary Fund and Bank for International Settlements.|$|E
5000|$|Steiner triple {{systems were}} defined {{for the first}} time by W.S.B. Woolhouse in 1844 in the Prize {{question}} #1733 of Lady's and Gentlemen's Diary. The posed problem was solved by [...] In 1850 Kirkman posed a variation of the problem known as Kirkman's schoolgirl problem, which asks for triple systems having an additional property (<b>resolvability).</b> Unaware of Kirkman's work, [...] reintroduced triple systems, and as this work was more widely known, the systems were named in his honor.|$|E
5000|$|A {{part of the}} Internet {{community}} has praised the initiative, with some recent scholarship proposing that alternative DNS roots may allow for a more democratic network control structure. Yet many others considered it harmful to the Internet. Using an alternative DNS root breaks the principle of universal <b>resolvability,</b> unless {{it is for a}} strictly private purpose. From a DNS perspective, it prevents some parts of the Internet to reach other parts. Jon Postel, a significant contributor to Internet standards, asserted that it would lead to chaos. [...] In May 2000, the Internet Architecture Board spoke out strongly against alternative roots in RFC 2826.|$|E
5000|$|Additionally, in Russian and ex-USSR {{computer}} jargon, {{the term}} [...] "any key" [...] is sometimes associated with reset button of PC. Explanations of such association vary: from considering {{it as being}} based on real pranks when some more advanced (in computers and in English) office workers had put stickers [...] "Any key" [...] to reset buttons of office computers, causing their less experienced colleagues to misinterpret the message — to considering it just as being a sarcasm about software-related difficulties solving skills of novice users (seeing a message you didn't expect? ahh, panic! don't even try to read it and understand!! just press reset!!!), or a Murphy's law-similar pessimism about actual <b>resolvability</b> of some types of work-flow problems caused by bugs in software.|$|E
50|$|The {{first part}} of his work (De systemate orbis cometici) {{followed}} Galileo's ideas on comets. The second part (De admirandis coeli characteribus) consisted of four main sections. The first concerns the classification of nebulaes. Hodierna classified the objects into three types according to their <b>resolvability.</b> Luminosae, or star clusters to the naked eye, Nebulae, or clusters that appeared nebulous to the naked eye, but which were resolvable in his telescope, and Occultae, which did not resolve even {{with the aid of}} his telescope. The second part is a list of 40 nebulae, of which roughly 25 have been identified as known objects, the others having too unclear a description for a modern identification. The third section is an attempt at a unifying theory of celestial objects, and the fourth concerns Copernican heliocentrism.|$|E
50|$|In summary, range voting {{satisfies}} the monotonicity criterion, the participation criterion, the consistency criterion, independence of irrelevant alternatives, <b>resolvability</b> criterion, and reversal symmetry, provided voters {{do not have}} perfect information (see below; if they do have perfect information, it becomes a Condorcet method, which means it fails participation, consistency, and independence of irrelevant alternatives). It is immune to cloning, except for the obvious specific {{case in which a}} candidate with clones ties, instead of achieving a unique win. It does not satisfy either the Condorcet criterion (i.e., is not a Condorcet method) or the Condorcet loser criterion, although with all-strategic voters and perfect information the Condorcet winner is a Nash equilibrium. It does not satisfy the later-no-harm criterion, meaning that giving a positive rating to a less preferred candidate can cause a more preferred candidate to lose.|$|E
50|$|The {{celestial}} sphere has been divided into 88 constellations. The International Astronomical Union (IAU) constellations are {{areas of the}} sky. Each of these contains remarkable X-ray sources. Some of them are have been identified from astrophysical modeling to be galaxies or black holes at the centers of galaxies. Some are pulsars. As with sources already successfully modeled by X-ray astrophysics, striving to understand the generation of X-rays by the apparent source helps to understand the Sun, the universe as a whole, and how these affect us on Earth. Constellations are an astronomical device for handling observation and precision independent of current physical theory or interpretation. Astronomy {{has been around for}} a long time. Physical theory changes with time. With respect to celestial X-ray sources, X-ray astrophysics tends to focus on the physical reason for X-ray brightness, whereas X-ray astronomy tends to focus on their classification, order of discovery, variability, <b>resolvability,</b> and their relationship with nearby sources in other constellations.|$|E
5000|$|Ulrich Körner is Chairman of the Widder Hotel in Zurich and Vice President of the Board of Lyceum Alpinum Zuoz. He is also Deputy Chairman of the Supervisory Board of UBS Deutschland AG, {{a member}} of the Board of Directors of OOO UBS Bank Russia, Chairman of the Foundation Board of the UBS Pension Fund, {{a member of}} the Financial Service Chapter Board of the Swiss-American Chamber of Commerce, {{a member of the}} Advisory Board of the Department of Banking and Finance at the University of Zurich [...] {{and a member of the}} {{business}} advisory council of the Laureus Foundation Switzerland. [...] He formerly served on the Board of Winterthur Group, AXA Leben AG, and AXA Versicherungen AG and as a member of the Board of Clariden Leu AG as well as of the Bank Leu AG. He is also the former Vice-Chairman of the Committee of the Governing Board of the Swiss Bankers Association. As a UBS representative in the Swiss Expert Commission, he advised Swiss politicians on both the <b>resolvability</b> of the large banks and the future strategy of Switzerland's financial industry.|$|E
50|$|In X-ray crystallography, {{resolution}} {{is a measure}} of the <b>resolvability</b> or precision in the electron density map of a molecule. Resolution is usually reported in Angstroms (10-10 meters) for X-ray crystal structures. The smaller the number, the better the degree of atomic resolution. In protein X-ray crystallography the best resolution typically attainable is about 1 Angstrom. This level of resolution allows individual hydrogen atoms to be visualized and heavy atoms (C, O, N) to be very accurately mapped. Most protein structures solved today have a resolution of 1.5 to 2.5 Angstroms, which means the hydrogen atoms are not visible and there is some uncertainty in the precise location of the heavy atoms. Protein structures with a resolution of >2.5 Angstroms generally have a number of coordinate inaccuracies as well as other structural problems. When the {{resolution is}} greater than 3.5 Angstroms, there is often considerable uncertainty in both the atom locations and even the identity of individual amino residues. In other words, resolution is inversely correlated with structure quality (i.e. higher numbers mean poorer structures). This trend in protein structure quality for X-ray resolution matches very closely to the trend seen the quality of NMR-determined protein structures. Some NMR structures have large numbers of constraints (NOEs, H-bonds, J-couplings, dipolar couplings), excellent geometry, high structure quality and very tight ensembles with excellent atomic precision (RMSDs < 1 Angstrom). Other NMR structures have very few constraints, poor geometry or poor structure quality and very loose ensembles (RMSDs > 3 Angstroms). However, there is no simple mapping between NMR RMSD values and X-ray resolution values. That is, an NMR ensemble with 1 Angstrom RMSD does not correspond in quality or precision to an X-ray structure with 1 Angstrom resolution. This is because the RMSD measure is both a function of the number of structures used in the ensemble and the selection bias of the spectroscopist who desposits the structural ensemble. Likewise, in NMR it is possible to generate high quality, precisely determined protein structures using relatively few, well-chosen constraints. It is also possible to generate very low quality NMR structures from large numbers of carelessly assessed, mistaken or mis-assigned constraints.|$|E
40|$|We {{introduce}} {{the problem of}} variable-length source <b>resolvability,</b> where a given target probability distribution is approximated by encoding a variable-length uniform random number, and the asymptotically minimum average length rate of the uniform random numbers, called the (variable-length) <b>resolvability,</b> is investigated. We first analyze the variable-length <b>resolvability</b> with the variational distance as an approximation measure. Next, we investigate the case under the divergence as an approximation measure. When the asymptotically exact approximation is required, it is shown that the <b>resolvability</b> under the two kinds of approximation measures coincides. We then extend the analysis {{to the case of}} channel <b>resolvability,</b> where the target distribution is the output distribution via a general channel due to the fixed general source as an input. The obtained characterization of the channel <b>resolvability</b> is fully general in the sense that when the channel is just the identity mapping, the characterization reduces to the general formula for the source <b>resolvability.</b> We also analyze the second-order variable-length <b>resolvability.</b> Comment: Submitted to IEEE Trans. on Inf. Theory, Jan. 201...|$|E
40|$|In {{the problem}} of channel <b>resolvability,</b> where a given output {{probability}} distribution via a channel is approximated by transforming the uniform random numbers, characterizing the asymptotically minimum rate {{of the size of}} the random numbers, called the channel <b>resolvability,</b> has been open. This paper derives formulas for the channel <b>resolvability</b> for a given general source and channel pair. We also investigate the channel <b>resolvability</b> in an optimistic sense. It is demonstrated that the derived general formulas recapture a single-letter formula for the stationary memoryless source and channel. When the channel is the identity mapping, the established formulas reduce to an alternative form of the spectral sup-entropy rates, which play a key role in information spectrum methods. The analysis is also extended to the second-order channel <b>resolvability.</b> Comment: Extended version for the paper submitted to 2017 IEEE International Symposium on Information Theory (ISIT 2017...|$|E
40|$|This paper {{presents}} a new sensor placement measure called <b>resolvability.</b> This measure provides a technique for estimating the relative ability of various sensor systems, including single camera systems, stereo pairs, multi-baseline stereo systems, and 3 D rangefinders, to accurately control visually manipulated objects. The measure also indicates {{the capability of}} a visual sensor to provide spatially accurate data on objects of interest. The term <b>resolvability</b> refers {{to the ability of}} a visual sensor to resolve object positions and orientations. Our main interest in <b>resolvability</b> is in determining the accuracy with which a manipulator being observed by a camera can visually servo an object to a goal position and orientation. The <b>resolvability</b> ellipsoid is introduced to illustrate the directional nature of <b>resolvability,</b> and can be used to direct camera motion and adjust camera intrinsic parameters in real-time so that the servoing accuracy of the visual servoing system improves with cam [...] ...|$|E
40|$|This paper {{introduces}} a sensor placement measure called <b>resolvability.</b> The measure provides a technique for estimating the relative ability of various visual sensors, including monocular systems, stereo pairs, multi-baseline stereo systems, and 3 D rangefinders, to accurately control visually manipulated objects. The <b>resolvability</b> ellipsoid illustrates the directional nature of <b>resolvability,</b> {{and can be}} used to direct camera motion and adjust camera intrinsic parameters in real-time so that the servoing accuracy of the visual servoing system improves with camera-lens motion. The Jacobian mapping from task space to sensor space is derived for a monocular system, a stereo pair with parallel optical axes, and a stereo pair with perpendicular optical axes. <b>Resolvability</b> ellipsoids based on these mappings for various sensor configurations are presented. Visual servoing experiments demonstrate that <b>resolvability</b> can be used to direct camera-lens motion in order to increase the ability of a visually servoed manipulator to precisely servo objects...|$|E
40|$|Abstract- We {{study the}} {{randomness}} {{necessary for the}} simu-lation of a random process with given distributions, {{in terms of the}} finite-precision <b>resolvability</b> of the process. Finite-precision <b>resolvability</b> is defined as the minimal random-bit rate required by the simulator {{as a function of the}} accuracy with which the distributions are replicated. The accuracy is quantified by means of various measures: variational distance, divergence, Ornstein, Prohorov and related measures of distance between the distributions of random processes. In the case of Ornstein, Prohorov and other distances of the Kantorovich-Vasershtein type, we show that the finite-precision <b>resolvability</b> is equal to the rate-distortion function with a fidelity criterion derived from the accuracy measure. This connection leads to new results on nonstationary rate-distortion theory. In the case of variational distance, the <b>resolvability</b> of stationary ergodic processes is shown to equal entropy rate regardless of the allowed accuracy. In the case of normalized divergence, explicit expressions for finite-precision <b>resolvability</b> are obtained in many cases of interest; and connections with data compression with minimum probability of block error are shown. Index Terms- Shannon theory, rate-distortion theory, data compression, <b>resolvability,</b> simulation complexity, variational dis...|$|E
40|$|Building upon {{previous}} {{work on the}} relation between secrecy and channel <b>resolvability,</b> we revisit a secrecy proof for the multiple-access channel (MAC) {{from the perspective of}} <b>resolvability.</b> We then refine the approach in order to obtain some novel results on the second-order achievable rates. Establishing a conceptually simple converse proof for <b>resolvability</b> over the memoryless MAC, which relies on uniform continuity of Shannon's entropy with respect to the variational distance, we characterize the <b>resolvability</b> region. In a discussion of the operational meaning of the information theoretic concept of semantic security {{from the point of view}} of Ahlswede's General Theory of Information Transfer, we show some interesting implications on the resilience against a wide-ranging class of attacks even if no assumption can be made about the distributions of the transmitted messages. We then give details on how the <b>resolvability</b> results can be used to construct a wiretap code that achieves semantic security. Comment: Substantially extended version of arXiv: 1707. 0415...|$|E
40|$|A {{sufficient}} condition for maximal <b>resolvability</b> of topological spaces Jerzy Bienias, Ma lgorzata Terepeta Abstract. We show a new theorem {{which is a}} {{sufficient condition}} for maximal resolvabi-lity of a topological space. We also discuss some relationships between various theorems about maximal <b>resolvability...</b>|$|E
40|$|The <b>resolvability</b> of {{equations}} in integers containing truncated Newton's binomial, {{is determined}} by the divisibility of the binomial by the characteristic parameters of the equation, which most often is the binomial exponent. Two types of equations containing binomials from two and three integers are investigated. Conditions of <b>resolvability</b> of the equations are specified based on the characteristics of their parameters. Comment: 6 page...|$|E
40|$|This paper {{considers}} {{the problem of}} variable-length intrinsic randomness. We propose the average variational distance as the performance criterion {{from the viewpoint of}} a dual relationship with the problem formulation of variable-length <b>resolvability.</b> Previous study has derived the general formula of the ϵ-variable-length <b>resolvability.</b> We derive the general formula of the ϵ-variable-length intrinsic randomness. Namely, we characterize the supremum of the mean length under the constraint the value of the average variational distance is smaller than or equal to some constant. Our result clarifies a dual relationship between the general formula of ϵ-variable-length <b>resolvability</b> and that of ϵ-variable-length intrinsic randomness. We also derive a lower bound of the quantity characterizing our general formula...|$|E
