17|64|Public
25|$|In theory, {{authoritative}} {{name servers}} are {{sufficient for the}} operation of the Internet. However, with only authoritative name servers operating, every DNS query must start with recursive queries at the root zone of the Domain Name System and each user system would have to implement resolver software capable of <b>recursive</b> <b>operation.</b>|$|E
5000|$|Gentzen {{defines a}} notion of [...] "reduction {{procedure}}" [...] for proofs in Peano arithmetic. For a given proof, such a procedure produces a tree of proofs, with the given one serving as {{the root of the}} tree, and the other proofs being, in a sense, [...] "simpler" [...] than the given one. This increasing simplicity is formalized by attaching an ordinal < ε0 to every proof, and showing that, as one moves down the tree, these ordinals get smaller with every step. He then shows that if there were a proof of a contradiction, the reduction procedure would result in an infinite descending sequence of ordinals smaller than ε0 produced by a primitive <b>recursive</b> <b>operation</b> on proofs corresponding to a quantifier-free formula.|$|E
40|$|Data {{clustering}} is {{an important}} problem in communication systems. In this paper a new algorithm for data clustering in a communication system is presented. The algorithm combines two techniques, the minimum difference tree and the PRI transform, to cluster the interleaved pulse trains. Since the method uses matrix and recursive computation, it has inherently the ability of parallel execution. To parallelize the algorithm a systolic array, the best parallel structure for matrix and <b>recursive</b> <b>operation,</b> is designed and the improvement in the total execution time is discussed. 1...|$|E
5000|$|<b>Recursive</b> <b>operations</b> on {{directory}} trees (copy, {{move and}} delete) ...|$|R
30|$|To {{avoid the}} error {{propagation}} {{caused by a}} shortage of the speed observation in <b>recursive</b> <b>operations,</b> the one-step backward algorithm is proposed for speed estimation. The correction phases with improved messages for the speed estimation are described by the following steps.|$|R
30|$|The clique-width is {{calculated}} based on <b>recursive</b> <b>operations</b> on vertex-labeled graphs [20]. These operations construct a new clique-width k-expression tree. In the following, G = (V_G,E_G,lab_G) denotes a k-labeled graph where each vertex label {{is given by}} the mapping lab_G: V_G→ [k], with [k] being the set of natural numbers [k]:= 1,…,k [21].|$|R
40|$|Abstract — This paper {{presents}} an improved front-end digitizer for pipeline/two-step ADC. It achieves a high linearity by replacing the front-end stage’s sub-ADC from the flash type that involves synchronous operation of several comparators, {{to the one}} that uses successive approximation (SA). This shift not only frees the ADC from an extra front-end sample-and-hold circuit, but also guarantees an inherent monotonicity because of no comparator mismatch (since the SA-ADC involves just one comparator in <b>recursive</b> <b>operation).</b> Two examples of a 100 -MHz 3. 5 -bit/stage pipeline ADC and an 11 -bit 30 -MHz two-step ADC, validate the feasibility of such a digitizer. I...|$|E
40|$|Graduation date: 1992 A new {{structure}} {{for the implementation of}} bit/serial adaptive IIR filter is presented. The bit level system consists of gated full adders for the arithmetic unit and data latches for the data path. This approach allows <b>recursive</b> <b>operation</b> of the IIR filter to be implemented without any global interconnections, minimal delay time, chip area and I/O pins. The coefficients of the filter can be updated serially in real time for time invariant and adaptive filtering. A fourth order bit/serial IIR filter is implemented on a 2 micron CMOS technology clocked at 55 MHz...|$|E
40|$|AbstractPVS is {{a highly}} {{automated}} framework for specification and verification. We show how the language and deduction features of PVS {{can be used to}} formalize, mechanize, and apply some useful program transformation techniques. We examine two such examples in detail. The first is a fusion theorem due to Bird where the composition of a catamorphism (a <b>recursive</b> <b>operation</b> on the structure of a datatype) and an anamorphism (an operation that constructs instances of the datatype) are fused to eliminate the intermediate data structure. The second example is Wand's continuation-based transformation technique for deriving tail-recursive functions from non-tailrecursive ones. These examples illustrate the utility of the language and inference features of PVS in capturing these transformations in a simple, general, and useful form...|$|E
30|$|On {{the other}} hand, to tune up {{this kind of}} {{operations}} is tedious because the chain structure (see Figure 7) must be modified. <b>Recursive</b> <b>operations</b> over {{the same set of}} data make the implementation in stream processors much more complex than in cellular processors, and these operations are common during the first stages of image processing.|$|R
40|$|Abstract. We {{introduce}} {{the concept of}} guarded saturated sets, saturated sets of strongly normalizing terms closed under folding of corecursive functions. Using this tool, we can model equi-inductive and equicoinductive types with terminating recursion and corecursion principles. Two type systems are presented: Mendler (co) iteration and sized types. As an application we show that we can directly represent the mixed inductive/coinductive type of stream processors with associated <b>recursive</b> <b>operations.</b> ...|$|R
5000|$|Comparability graphs {{formed from}} {{partially}} ordered sets by connecting pairs of elements by an edge whenever they are related in the partial order. These include the bipartite graphs, the complements of interval graphs, the trivially perfect graphs, the threshold graphs, the windmill graphs, the permutation graphs (graphs {{in which the}} edges represent pairs of elements that are reversed by a permutation), and the cographs (graphs formed by <b>recursive</b> <b>operations</b> of disjoint union and complementation).|$|R
30|$|This paper {{presents}} {{a method to}} improve the calculation of functions which specially demand {{a great amount of}} computing resources. The method is based on the choice of a weighted primitive which enables the calculation of function values under the scope of a <b>recursive</b> <b>operation.</b> When tackling the design level, the method shows suitable for developing a processor which achieves a satisfying trade-off between time delay, area costs, and stability. The method is particularly suitable for the mathematical transforms used in signal processing applications. A generic calculation scheme is developed for the discrete fast Fourier transform (DFT) and then applied to other integral transforms such as the discrete Hartley transform (DHT), the discrete cosine transform (DCT), and the discrete sine transform (DST). Some comparisons with other well-known proposals are also provided.|$|E
40|$|It is {{well known}} that in order to study {{primitive}} recursion in higher types it is useful to unfold the primitive recursion operators into infinite terms. A similar phenomenon occurs in proof theory, where one expands induction axioms. For applications it then is often necessary to code these infinite objects by natural numbers. A standard method to design such a coding is to proceed as in Kleene's system O of ordinal notations; cf. [6] for a recursion theoretic and [7] for a proof theoretic application of this method. However, working with such codes is not easy. For instance, to prove that the standard operation reducing the cut rank by one can be represented by a primitive <b>recursive</b> <b>operation</b> on codes requires some careful applications of Kleene's recursion theorem for primitive recursive functions...|$|E
40|$|This paper {{presents}} {{a method to}} improve the calculation of functions which specially demand {{a great amount of}} computing resources. The method is based on the choice of a weighted primitive which enables the calculation of function values under the scope of a <b>recursive</b> <b>operation.</b> When tackling the design level, the method shows suitable for developing a processor which achieves a satisfying trade-off between time delay, area costs, and stability. The method is particularly suitable for the mathematical transforms used in signal processing applications. A generic calculation scheme is developed for the discrete fast Fourier transform (DFT) and then applied to other integral transforms such as the discrete Hartley transform (DHT), the discrete cosine transform (DCT), and the discrete sine transform (DST). Some comparisons with other well-known proposals are also provided. </p...|$|E
40|$|AbstractWe {{present a}} {{definition}} of <b>recursive</b> multi-valued <b>operations</b> over topological structures (which include structures for the real numbers and other spaces used in analysis). One of the main results states that over a certain class of structures, so-called perfect structures, <b>recursive</b> <b>operations</b> coincide with computable operations, as defined via Turing machines in computable analysis. Moreover, by a Stability Theorem, perfect structures uniquely characterize their own computability theory. We propose a general method to derive perfect structures from recursive metric spaces and we exhibit this method {{for a number of}} general hyper and function spaces which {{play an important role in}} computable analysis. Finally, we define classes of recursive sets over structures and we show that these notions are generalizations of the classical notions from recursion theory and computable analysis...|$|R
5000|$|... where pi {{represent}} the ith prime. It {{can be shown}} that, with this representation, the ordinary operations on sequences are all primitive <b>recursive.</b> These <b>operations</b> include ...|$|R
40|$|Keywords: A new {{operator}} to compute time differentiation in an image sequence is presented. It {{is founded on}} hybrid filters combining morphological and linear <b>recursive</b> <b>operations.</b> It estimates recursively the amplitude of time-variation within a certain interval. It combines the change detection capability of the temporal morphological gradient, and the (exponential) smoothing effect of the linear recursive average. It is particularly suited to small and low amplitude motion. We show how to use this filter within an adaptive motion detection algorithm. hybrid filter, temporal morphology, motion detection...|$|R
40|$|PVS is {{a highly}} {{automated}} framework for specification and verification. We show how the language and deduction features of PVS {{can be used to}} formalize, mechanize, and apply some useful program transformation techniques. We examine two such examples in detail. The first is a fusion theorem due to Bird where the composition of a catamorphism (a <b>recursive</b> <b>operation</b> on the structure of a datatype) and an anamorphism (an operation that constructs instances of the datatype) is fused to eliminate the intermediate data structure. The second example is Wand's continuation-based transformation technique for deriving tail-recursive functions from non-tail-recursive ones. These examples illustrate the utility of the language and inference features of PVS in capturing these transformations in a simple, general, and useful form. 1 Introduction Correctness-preserving program transformations [15] often capture deep algorithmic insight and therefore pose interesting challenges for mechanization. The [...] ...|$|E
30|$|Compared {{with most}} of the current deep {{learning}} speech enhancement systems based on the spectrum analysis framework [11 – 15], GAN and the variant algorithm of GAN work end-to-end with the raw speech data without hand-crafted features extracted and assumptions about the raw data utilized. Because further studies show that outperformance of speech quality is possible, especially when a clean phase spectrum and high frequency information are known [16 – 18], the raw data retain both phase information and frequency information. GAN and the variant algorithm of GAN provide a sample process without <b>recursive</b> <b>operation</b> in recurrent neural networks and long short-term memory networks [19 – 22]. But the current GAN system performance in the low-data regime and tasks like unseen data learning still lag, because of the instability of training and the problem of gradient disappearing resulting in an inadequate training and the overfitting caused by the complex model.|$|E
40|$|When {{it comes}} to {{high-performance}} filtration, separation, sunlight collection, surface charge storage or catalysis, the effective surface area is what counts. Highly regular fractal structures {{seem to be the}} perfect candidates, but manufacturing can be quite cumbersome. Here it is shown-–for the first time—that complex 3 D fractals can be engineered using a <b>recursive</b> <b>operation</b> in conventional micromachining of single crystalline silicon. The procedure uses the built-in capability of the crystal lattice to form self-similar octahedral structures with minimal interference of the constructor. The silicon fractal can be used directly or as a mold to transfer the shape into another material. Moreover, they can be dense, porous, or like a wireframe. We demonstrate, after four levels of processing, that the initial number of octahedral structures is increased by a factor of 625. Meanwhile the size decreases 16 times down to 300 nm. At any level, pores of less than 100 nm can be fabricated at the octahedral vertices of the fractal. The presented technique supports the design of fractals with Hausdorff dimension D free of choice and up to D = 2. 322...|$|E
40|$|Also {{published}} online by CEUR Workshop Proceedings (CEUR-WS. org, ISSN 1613 - 0073)  Model finders enable numerous verification approaches {{based on}} searching {{the existence of}} models satisfying certain properties of interest. One of such approaches is anATLyzer, a static analysis tool for ATL transformations, which relies on USE Validator to provide fine grained analysis based on finding witness models that satisfy the OCL path conditions associated to particular errors. However it {{is limited by the}} fact that USE Validator does not include built-in support for analysing <b>recursive</b> <b>operations</b> and the iterate collection operator. This paper reports our approach to allow USE Validator to analyse OCL path conditions containing <b>recursive</b> <b>operations</b> and iterate, with the aim of widening the amount of actual transformations that can be processed by anATLyzer. We present our approach, based on unfolding recursion into a finite number of steps, and we discuss how to take into account practical aspects such as inheritance and details about the implementation. This work has been supported by the Spanish MINECO (TIN 2011 - 24139 and TIN 2014 - 52129 -R), the R&D programme of the Madrid Region (S 2013 /ICE- 3006), and the EU commission (FP 7 -ICT- 2013 - 10, # 611125) ...|$|R
40|$|An {{architecture}} for {{the parallel}} implementation of an orthogonal transform of images is presented. Images are preprocessed by the ""regular decomposition"" procedure and {{converted into a}} quad-tree representation. The orthogonal transformation is performed progressivelly by adjusting to the various hierarchies of the quad-tree nodes. The architecture of the proposed machine {{is based on the}} data-driven model of computation in which an operation is executed when its operands are available. The specific requirements of the image processing algorithms have been taken into account, principally the efficient handling of array data-structures. The tagged-token method supports <b>recursive</b> <b>operations</b> and helps to better exploit the inherent parallelism of the transformation algorithms. © 1985...|$|R
40|$|This paper {{presents}} an algorithm for recursive data processing in directed graphs. The proposed algorithm applies graph reduction {{in order to}} determine both starting points and a correct ordering of <b>recursive</b> <b>operations,</b> provided the directed graph is a-cyclic. Therefore it is essential that the algorithm is also able to detect cycles efficiently. The algorithm arose from the implementation of recursive, semantic query specifications and is implemented in a DBMS prototype. Experiments confirmed that the theoretically estimated time complexity is O(dN), where N is the number of arcs and d is the depth of the graph (d £ N). The worst-case performance is O(N 2), also for cycle detection...|$|R
40|$|State {{of charge}} (SOC) {{estimation}} {{is the core}} of any battery management system. Most closed-loop SOC estimation algorithms are based on the equivalent circuit model with fixed parameters. However, the parameters of the equivalent circuit model will change as temperature or SOC changes, resulting in reduced SOC estimation accuracy. In this paper, two SOC estimation algorithms with online parameter identification are proposed to solve this problem based on forgetting factor recursive least squares (FFRLS) and nonlinear Kalman filter. The parameters of a Thevenin model are constantly updated by FFRLS. The nonlinear Kalman filter is used to perform the <b>recursive</b> <b>operation</b> to estimate SOC. Experiments in variable temperature environments verify the effectiveness of the proposed algorithms. A combination of four driving cycles is loaded on lithium-ion batteries to test the adaptability of the approaches to different working conditions. Under certain conditions, the average error of the SOC estimation dropped from 5. 6 % to 1. 1 % after adding the online parameters identification, showing that the estimation accuracy of proposed algorithms is greatly improved. Besides, simulated measurement noise is added to the test data to prove the robustness of the algorithms...|$|E
40|$|In {{this paper}} we develop a model which {{represents}} the addressing of resources by processes executing on a virtual machine. The model distinguishes two maps: the ~-map {{which represents the}} map visible to the operating system software running on the virtual machine, and the f-map which is invisible to that software but which is manipulated by the virtual machine monitor running on the real machine. The ~-map maps process names into resource names and the f-map maps virtual resource names into real resource names. Thus, a process running on a virtual machine addresses its resources under the composed map f o ~. In <b>recursive</b> <b>operation,</b> f maps from one virtual machine level to another and we have f o f o [...] . o f o ~. The model is used to describe and characterize previous virtual machine designs. We also introduce and illustrate a general approach for implementing virtual machines which follows directly from the model. This design, the Hardware Virtualizer, handles all process exceptions directly within the executing virtual machine without software intervention. All resource faults (VM-faults) generated by a virtual machine are directed to the appropriate virtual machine monitor without the knowledge of processes on the virtual machin...|$|E
40|$|This thesis has two {{independent}} parts concerned with {{different aspects of}} laziness in functional programs. The first part is a theoretical study of productivity for very restricted stream programs. In the second part we define a programming abstraction over a recursive pattern for defining circular traversals modularly. Productivity is in general undecidable. By restricting ourselves to mutually recursive polymorphic stream equations having only three basic operations, namely "head", "tail", and "cons", we aim to prove interesting properties about productivity. Still undecidable for this restricted class of programs, productivity of polymorphic stream functions {{is equivalent to the}} totality of their indexing function, which characterise their behaviour in terms of operations on indices. We prove that our equations generate all possible polymorphic stream functions, and therefore their indexing functions are all the computable functions, whose totality problem is indeed undecidable. We then further restrict our language by reducing the numbers of equations and parameters, but despite those constraints the equations retain their expressiveness. In the end we establish that even two non-mutually recursive equations on unary stream functions are undecidable with complexity Π_ 2 ^ 0. However, the productivity of a single unary equation is decidable. Circular traversals have been used in the eighties as an optimisation to combine multiple traversals in a single traversal. In particular they provide more opportunities for applying deforestation techniques since it is the case that an intermediate datastructure can only be eliminated if it is consumed only once. Another use of circular programs is in the implementation of attribute grammars in lazy functional languages. There is a systematic transformation to define a circular traversal equivalent to multiple traversals. Programming with this technique is not modular since the individual traversals are merged together. Some tools exist to transform programs automatically and attribute grammars have been suggested as a way to describe the circular traversals modularly. Going to the root of the problem, we identify a recursive pattern that allows us to define circular programs modularly in a functional style. We give two successive implementations, the first one is based on algebras and has limited scope: not all circular traversals can be defined this way. We show that the recursive scheme underlying attribute grammars computation rules is essential to combine circular programs. We implement a generic <b>recursive</b> <b>operation</b> on a novel attribute grammar abstraction, using containers as a parametric generic representation of recursive datatypes. The abstraction makes attribute grammars first-class objects. Such a strongly typed implementation is novel and make it possible to implement a high level embedded language for defining attribute grammars, with many interesting new features promoting modularity...|$|E
40|$|We {{present a}} survey of results {{concerning}} the use of inductive constructions to study the rigidity of frameworks. By inductive constructions we mean simple graph moves which can be shown to preserve the rigidity of the corresponding framework. We describe {{a number of cases}} in which characterisations of rigidity were proved by inductive constructions. That is, by identifying <b>recursive</b> <b>operations</b> that preserved rigidity and proving that these operations were sufficient to generate all such frameworks. We also outline the use of inductive constructions in some recent areas of particularly active interest, namely symmetric and periodic frameworks, frameworks on surfaces, and body-bar frameworks. As the survey progresses we describe the key open problems related to inductions...|$|R
40|$|AbstractAn axiomatic {{theory of}} sets and rules is formulated, which permits {{the use of}} sets as data {{structures}} and allows rules to operate on rules, numbers, or sets. We might call it a “polymorphic set theory”. Our theory combines the λ-calculus with traditional set theories. A natural set-theoretic model of the theory is constructed, establishing {{the consistency of the}} theory and bounding its proof-theoretic strength, and giving in a sense its denotational semantics. Another model, a natural recursion-theoretic model, is constructed, in which only <b>recursive</b> <b>operations</b> from integers to integers are represented, even though the logic can be classical. Some related philosophical considerations on the notions of set, type, and data structure are given in an appendix...|$|R
40|$|Recently, {{in order}} to mix {{algebraic}} and logic styles of specification in a uniform framework, {{the notion of a}} logic labelled transition system (Logic LTS or LLTS for short) has been introduced and explored. A variety of constructors over LLTS, including usual process-algebraic operators, logic connectives (conjunction and disjunction) and standard temporal operators (always and unless), have been given. However, no attempt has made so far to develop general theory concerning (nested) <b>recursive</b> <b>operations</b> over LLTSs and a few fundamental problems are still open. This paper intends to study this issue in pure process-algebraic style. A few fundamental properties, including precongruence and the uniqueness of consistent solutions for equations, will be established. Comment: 66 page...|$|R
30|$|We first give a brief {{explanation}} of the constant time filtering process for accumulating the contributions to the expected energy and then show how the filter is employed in our two-pass algorithm. Gastal and Oliveira [8] showed that processing signals with infinite impulse response (IIR) filters can be performed using a summation of first-order <b>recursive</b> <b>operations.</b> In other words, a K-th order IIR filter that needs K feedback operations per pixel can be replaced with a summation of K first-order filters that need one feedback operation per pixel. For a two-dimensional signal f, two orthogonal 1 D filters G in the horizontal direction and H in the vertical direction are used such that H∗G∗f corresponds to a 2 D filtering of signal f.|$|R
40|$|Prime-based {{ordering}} {{which is}} {{proved to be}} admissible, is the encoding of indeterminates in power-products with prime numbers and ordering them by using the natural number order. Using Eiffel, four versions of Buchberger's improved algorithm for obtaining Groebner Bases have been developed: two total degree versions, representing power products as strings {{and the other two}} as integers based on prime-based ordering. The versions are further distinguished by implementing coefficients as 64 -bit integers and as multiple-precision integers. By using primebased power product coding, iterative or <b>recursive</b> <b>operations</b> on power products are replaced with integer operations. It is found that on a series of example polynomial sets, significant reductions in computation time of 30 % or more are almost always obtained. Comment: 10 pages, 2 tables, 4 ref...|$|R
40|$|A {{morphological}} operation using a large {{structuring element}} can be decomposed equivalently into {{a sequence of}} <b>recursive</b> <b>operations,</b> each using a smaller structural element. However, an optimal decomposition of arbitrarily shaped structural elements {{is yet to be}} found. In this paper, we have derived an optimal decomposition of a specific class of structuring elements - convex sets - for a specific type of machine - 4 -connected parallel array processors. The cost of morphological operation on 4 -connected parallel array processors is the total number of 4 -connected shifts required by the set of structuring elements. First, the original structuring element is decomposed into a set of prime factors, and their locations are determined while minimizing the cost function. Proofs are presented to show the optimality of the decomposition. Examples of optimal decomposition are given and compared to an existing decomposition reported by Xu. link_to_subscribed_fulltex...|$|R
40|$|Cordic based QRD-MVDR {{adaptive}} beamforming algorithms possess desirable {{properties for}} VLSI implementation such as regularity and good finite-word length behavior. But this algorithm suffers from speed limitation constraint {{due to the}} presence of <b>recursive</b> <b>operations</b> in the algorithm. In this paper, a fine-grain pipelined Cordic based QRD-MVDR adaptive beamforming algorithm is developed using the matrix lookahead technique. The proposed architecture can operate at arbitrarily high sample rates, and consists of only Givens rotations which can be mapped onto a Jacobi specific dataflow processor. It requires a complexity of O(M(p 2 + Kp)) Givens rotations per sample time, where p is the number of antenna elements, K is the number of look direction constrains, and M is the pipelining level. 1. INTRODUCTION QR decomposition based minimum variance distortionless response (QRD-MVDR) adaptive beamforming algorithm [1] possess desirable properties for VLSI implementation such as regularity a [...] ...|$|R
40|$|A novel {{algorithm}} for computing the two-dimensional discrete cosine transform (2 -D DCT) is presented. It {{is based}} on a one-dimensional fast cosine transform (1 -D FCT) algorithm. Instead of computing the 2 -D transform using the row-column method, the 1 -D algorithm is extended by means of the vector-radix approach. Derivation based on both the sequence splitting and Kronecker matrix product method are discussed. The sequence splitting approach has the advantage that all the underlying operations are shown clearly, while the matrix product representations are more compact and readily generalized to higher dimensions. The bit reversal operations are placed before the recursive additions so that the <b>recursive</b> <b>operations</b> can be performed in a very regular manner. This greatly simplifies the indexing problem in the software implementation of the algorithms. The complexity of the proposed algorithm is described. The vector-radix algorithm saves 25 % multiplications as compared with the row-column method. link_to_subscribed_fulltex...|$|R
40|$|Abstract. Siegenthaler {{proved that}} an n input 1 output, m-resilient (balanced mth order {{correlation}} immune) Boolean function with algebraic degree d satisfies the inequality: m + d ≤ n − 1. We provide a new construction method {{using a small}} set of <b>recursive</b> <b>operations</b> for a large class of highly nonlinear, resilient Boolean functions optimizing Siegenthaler’s inequality m + d = n − 1. Comparisons to previous constructions show that better nonlinearity {{can be obtained by}} our method. In particular, we show that as n increases, for almost all m, the nonlinearity obtained by our method is better than that provided by Seberry et al in Eurocrypt’ 93. For small values of n, the functions constructed by our method is better than or at least comparable to those constructed using the methods provided in papers by Filiol et al and Millan et al in Eurocrypt’ 98. Our technique can be used to construct functions on large number of input variables with simple hardware implementation...|$|R
