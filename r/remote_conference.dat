8|64|Public
50|$|Venkatachari {{has been}} a {{frequent}} speaker at conferences, most recently AllFacebook Marketing Conference, San Francisco June 2013 and The Lost <b>Remote</b> <b>Conference,</b> New York April 2013.|$|E
5000|$|Next, {{three pieces}} of his art were censored from a show at Tri-C West. Smith agreed to the removal {{as long as a}} [...] "censored" [...] notice was put on the wall in place of the missing art. The opening night poetry reading was reassigned to a <b>remote</b> <b>conference</b> room. During the reading Smith {{discovered}} that Tri-C neglected to post the notes. He wrote [...] "CENSORED" [...] on the wall with a ball point pen. Poet Daniel Thompson decided to read in the original gallery, and mouthed the words to his poem silently as a Tri-C co-director sanded the words off the wall.|$|E
40|$|We have {{implemented}} an augmented reality videoconferencing system that inserts virtual graphics overlays into the live video stream of <b>remote</b> <b>conference</b> participants. The virtual objects are manipulated using {{a novel interaction technique}} cascading bimanual tangible interaction and eye tracking. User studies prove that our user interface enriches remote collaboration by offering hitherto unexplored ways for collaborative object manipulation such as gaze controlled raypicking of remote physical and virtual objects...|$|E
50|$|Zoom Video Communications is {{a company}} {{operating}} from San Jose, California that provides <b>remote</b> <b>conferencing</b> services using cloud computing. Offering both meeting and webinar software, Zoom combines video conferencing, online meetings, and mobile collaboration.|$|R
50|$|ASAM {{provides}} the work infrastructure {{for the project}} team, i.e. an issue tracking system, a file repository and versioning control system, means for <b>remote</b> <b>conferencing,</b> process descriptions and guidelines, document templates and the support through the staff of its head office.|$|R
5000|$|Pan-Oceanic <b>Remote</b> Sensing <b>Conference</b> Association, Treasurer, 2006 {{to present}} ...|$|R
40|$|We {{demonstrate}} a software system {{that runs on}} the Symbian smartphone platform, and allows a group to {{capture the essence of}} a face-to-face meeting or <b>remote</b> <b>conference</b> call in a decentralized manner. We show how the users setup a meeting, record elements from the meeting, and are able to continue the collaboration after the original meeting has ended. We show how the information collected during the meeting can be used by members to analyze the collective impression of the meeting, as well view consensus or differences of opinions...|$|E
40|$|The {{advent of}} conference mobile call demands the {{security}} communication between end users. However, currently {{there is no}} efficient secure end-to-end protocol exists for conference mobile call. This slows down the steps of conference communication. In this paper a secure end-to-end protocol for <b>remote</b> <b>conference</b> is designed base on previous experts work, which is one-to-one end-to-end protocol. In addition, security analysis from perspectives of confidentiality, authenticity, anonymity, freshness as well as preventing from denial of service (DoS) attack on the protocol is made. At the end, the efficiency of this protocol is discussed...|$|E
40|$|This paper reports {{our recent}} {{experience}} with a 3 -day technical conference, which was fully augmented by a chat system and a telepresence camera. In this trial, the chat acted as a sub-channel to reality; participants both in local and <b>remote</b> <b>conference</b> rooms can freely interchange their thoughts or opinions inspired by presentations through the chat. We observed several interactions between virtual (chat) and real discussions during the conference - namely, (1) Chat discussions often activated discussions in the real world, while treating tiny questions, (2) Co-authors could provide supplemental information through the chat while the first author was presenting, and (3) Participants who were {{not familiar with the}} research topic could get more understanding from the chat. We also observed the effect of anthropomorphic representation by switching the chat system between text- and comic-based...|$|E
5000|$|Distinguished Science Award, Pan Oceanic <b>Remote</b> Sensing <b>Conference</b> Assoc. (2002) ...|$|R
40|$|Textual {{information}} about KAUST is displayed as a video fly-through the campus {{plays in the}} background. Then the video focuses on the Visualization Laboratory Facilities. The video is intended for use at <b>remote</b> <b>conferences</b> and KAUST events. A visual and textual overview of King Abdullah University of Science and Technology (KAUST) campus in the Kingdom of Saudi Arabia and KAUST Visualization Laboratory (KVL) ...|$|R
50|$|He began {{programming}} at age 14 at the University of Wisconsin-Milwaukee and by age 15 {{was working}} professionally as a programmer at Northwestern Mutual Life Insurance. He received his computer engineering degree in 1980 from the University of Wisconsin-Madison. He worked at Apple Computer from 1980 to 2005. He is currently employed at Cisco Systems, {{where he has}} worked on the Cisco TelePresence <b>remote</b> <b>conferencing</b> system.|$|R
40|$|When {{interpreting}} {{takes place}} in a videoconference setting, the intrinsic technological challenges and the very remoteness of the interpreters' location compound the complexity of the task. Existing research on remote interpreting and the problems it entails focusses on <b>remote</b> <b>conference</b> interpreting, in which the interpreters are physically separated from the conference site while the primary interlocutors are together on site as usual. In an effort to broaden the scope of {{research in the area of}} remote interpreting to include other types and to address other questions, in particular that of the interpreters' adaptability to new working conditions, this paper analyses small-group videoconferences in which the primary interlocutors as well as the interpreters all work from different locations. The findings from an empirical case study (based on recordings of videoconference sessions as well as introspective data) are used to identify and exemplify different types of interpreter adaptation...|$|E
40|$|In 1999, Fred Brooks, {{virtual reality}} pioneer and Professor of Computer Science at the University of North Carolina at Chapel Hill, {{published}} a seminal paper describing {{the current state}} of virtual reality (VR) technologies and applications (Brooks in IEEE Comput Graph Appl 19 (6) : 16, 1999). Through his extensive survey of industry, Brooks concluded that virtual reality had finally arrived and “barely works”. His report included a variety of industries which leveraged these technologies to support industry-level innovation. Virtual reality was being employed to empower decision making in design, evaluation, and training processes across multiple disciplines. Over the past two decades, both industrial and academic communities have contributed to a large knowledge base on numerous virtual reality topics. Technical advances have enabled designers and engineers to explore and interact with data in increasingly natural ways. Sixteen years have passed since Brooks original survey. Where are we now? The research presented here seeks to describe {{the current state of}} the art of virtual reality as it is used as a decision-making tool in product design, particularly in engineering-focused businesses. To this end, a survey of industry was conducted over several months spanning fall 2014 and spring 2015. Data on virtual reality applications across a variety of industries was gathered through a series of on-site visits. In total, on-site visits with 18 companies using virtual reality were conducted as well as <b>remote</b> <b>conference</b> calls with two others. The authors interviewed 62 people across numerous companies from varying disciplines and perspectives. Success stories and existing challenges were highlighted. While virtual reality hardware has made considerable strides, unique attention was given to applications and the associated decisions that they support. Results suggest that virtual reality has arrived: it works! It is mature, stable, and, most importantly, usable. VR is actively being used in a number of industries to support decision making and enable innovation. Insights from this survey can be leveraged to help guide future research directions in virtual reality technology and applications...|$|E
5000|$|AR {{technologies}} and services assist intelligent marketing comprehensively, which {{are widely used}} in planning and design, production standard management, warehousing and transportation, <b>remote</b> production <b>conference</b> and many other scenarios.|$|R
40|$|To {{make people}} at {{different}} places {{participate in the}} same conference, speak and discuss freely, the interactive <b>remote</b> video <b>conferencing</b> system is designed and realized based on multi-Agent collaboration. FEC (forward error correction) and tree P 2 P technology are firstly used to build a live conference structure to transfer audio and video data; then the branch conference port can participate to speak and discuss {{through the application of}} becoming a interactive focus; the introduction of multi-Agent collaboration technology improve the system robustness. The experiments showed that, under normal network conditions, the system can support 350 branch conference node simultaneously to make live broadcasting. The audio and video quality is smooth. It can carry out large-scale <b>remote</b> video <b>conference...</b>|$|R
50|$|In December 2011, Brother diversified its offerings by {{acquiring}} Nefsis, an innovator in web-based <b>remote</b> collaboration and <b>conferencing</b> software.|$|R
40|$|As {{a way of}} {{reinforcing}} classroom-based lessons, {{especially for}} continuous evaluation, we experimented with <b>remote</b> <b>conferences</b> and tutoring. These seminars were directed at three different groups of students: those who are struggling with the subject, those who were unable to attend all the lessons, and those seeking deeper insight. We experimented with different platforms for computer-assisted learning and with teaching through metaverses (Second Life and Open Sims). We experienced better results with the latter rather than with the platforms specially designed for computer-assisted learning. The metaverse sessions were also used as videos, recording the screen to later {{become part of the}} videos used for remote teaching. The sessions were also used to broadcast live conferences to people who were unable to attend them in person. A brief analysis was made of the videos? usefulness for teaching, combined with conferences, seminars through metaverses, etc...|$|R
40|$|Online {{meetings}} {{allow for}} <b>remote</b> <b>conferencing</b> and collaborative work among geographically dispersed participants and can {{save time and}} expenses that an ordinary face-toface meeting would require. However, carrying real-time communication within the packet-switched Internet is a challenging task, especially in an African context, which is characterized by low bandwidth and unstable Internet connections. This paper presents and evaluates a tool {{that was designed to}} enhance the user experience for Webbased conferencing, given the constraints of Internet conditions typical of Africa. Approaches used to achieve this goal included: reprioritisation of multimedia streams, image differentiation, half duplex communication mode and stream compression. It was found that less than 56 kbps of bandwidth was required in order to: transmit audio; use video to convey presence; share slides and screen; and support text-based chat and floor control. Furthermore, users were largely satisfied with the tool and felt that it created a good user experience...|$|R
40|$|To {{illustrate}} research {{regarding how}} to augment people's experiences in office meetings of different types, {{we have developed}} EMCE (Enhanced Multimodal Conferencing Environment), a prototypic conference room. EMCE assists meeting participants in performing a host of functions including {{but not limited to}} passing private messages, taking electronic notes, accessing personal files, writing both public and private annotations on projected objects, automatically creating meeting minutes and <b>remote</b> <b>conferencing.</b> Our multimodal approach allows people to interact with the conference room through spoken or handwritten commands and drawn information. The room reacts in a multimedia fashion, outputting sound, video, text, etc. To make EMCE's use as intuitive as possible, our interface consists of a virtual view of the conference room that users can access either with screens embedded in a conference table or on their personal laptops. Our goal is to create an augmented environment that is as nat [...] ...|$|R
40|$|How can we {{integrate}} {{digital information}} into our physical lives? How can we {{dive into the}} full digital experience with our whole body {{and all of our}} senses? InReach represents one approach for including proprioception and embodied interaction into an environment for remote collaboration. It explores how remote collaborators can "reach into " a shared digital workspace where they can manipulate virtual objects and data. The collaborators see their live threedimensional (3 D) recreated mesh in a shared virtual space on a large screen {{in front of them and}} can use their bodies to “inhabit ” and interact with 3 D models. They can grab digital objects with their bare hands, translate, scale, and rotate them. In contrast with the traditional view for <b>remote</b> <b>conferencing</b> InReach is particularly useful for situations in which users can benefit from seeing their own and the their collaborator’s body in relation to the data and can use their bodies to navigate and manipulate the data. Copyright is held by the author/owner(s) ...|$|R
40|$|This {{presentation}} {{offers an}} understanding of the rapidly changing medical market and devices, and provides ways for Medical Informatics Systems to keep up with this rapidly changing environment. The Infinitt Company of South Korea as one of the pioneers in the field of imaging informatics will present its three major solutions to meet these new trends. The Infinitt G 3 will be presented as fully web-based RIS/PACS solution with advanced 3 D capabilities all operating on a single platform, i. e. a solution for simultaneous fusion of RIS, PACS and 3 D functions. "nThe Infinitt Star PACS is presented as an on-demand PACS solution, which can operate in a web-based environment for easier image distribution, <b>remote</b> <b>conferencing</b> and Teleradiology practices. Infinitt Rapidia, which is a 3 D imaging technology, that visualizes 3 D images out of a large quantity of 2 D images is presented as a tool to support diagnostic and surgery demands...|$|R
40|$|<b>Remote</b> <b>conferencing</b> using desktop {{workstations}} {{is becoming}} commonplace. Typical audio conferencing hardware {{consists of a}} room loudspeaker (often built into the workstation) and a stand-alone microphone. Because there can be strong coupling between the loudspeaker and mike, undesirable echo signals can result. We propose to eliminate these signals using well understood echo cancellation algorithms running on a vendor-supplied, off-board DSP coprocessor. We have extended the Ptolemy code generation domain to produce suitable output for the DECaudio 56001 DSP, and have used this system to implement an LMS echo canceler. We have built a 95 tap prototype which has achieved a meager echo return loss enhancement (ERLE) of 5 dB. While this level is unsatisfactory, we argue from our simulations that a 10 dB design will be realizable. 1 Introduction A new trend in networked multimedia has caught on in the Internet. Audio and video conferencing is being carried out on global scale, over an IP M [...] ...|$|R
5000|$|A. Shepelev, C. Chung, C. Chu, R. Gadh, [...] "Mesh Network Design for Smart Charging Infrastructure and Electric Vehicle <b>Remote</b> Monitoring", International <b>Conference</b> on ICT Convergence 2013, Jeju, Korea, Oct. 14-16, 2013 ...|$|R
50|$|In April 2007, Telus {{was awarded}} the $16.3 million {{contract}} to provide the buildings with high-tech video recording, video <b>conferencing,</b> <b>remote</b> witness facilitation and remote management. The west block of the complex {{is scheduled to open}} in August 2007.|$|R
50|$|A typical {{courtroom}} layout {{consists of}} a witness box, a public gallery, the bar table (at which the parties sit), a raised bench for seating the sitting magistrate and a clerk and sometimes a dock for housing defendants in custody. Many Victorian magistrates' courts have video link facilities for witnesses to appear via <b>remote</b> video <b>conference</b> rather than in person and is used for when witnesses cannot travel or the prisoner is deemed too high-risk to travel to court in person.|$|R
40|$|International audienceAudio is {{a domain}} where signal {{separation}} {{has long been}} considered as a fascinating objective, potentially offering {{a wide range of}} new possibilities and experiences in professional and personal contexts, by better taking advantage of audio material and finely analyzing complex acoustic scenes. It has thus always been a major area for research in signal separation and an exciting challenge for industrial applications. Starting with blind separation of toy mixtures in the mid 90 's, research has progressed up to real-world scenarios today, with applications to speech enhancement and recognition, music editing, 3 D sound rendering, and audio information retrieval, among others. This has mostly been made possible by the development of increasingly informed separation techniques incorporating knowledge about the sources and/or the mixtures at hand. For instance, speech source separation for <b>remote</b> <b>conferencing</b> can benefit from prior knowledge of the room geometry and/or the names of the speakers, while music remastering will exploit instrument characteristics and knowledge of sound engineers mixing habits. After a brief historical account, we provide an overview of recent and ongoing research in this field, illustrating a variety of models and techniques designed so as to guide the audio source separation process towards efficient and robust solutions...|$|R
40|$|In {{this paper}} we {{evaluate}} a layered coding technique based on subband coding {{for the purpose}} of encoding medical images for realtime transmission over heterogeneous networks. The objective of this research is to support a medical conference in a heterogeneous networking scenario. The scalable coding scheme under study in this paper generates a single bit-stream, from which a number of sub-streams of varying bit-rates can be extracted. This makes it possible to support a multicast transmission scenario, where the different receivers are capable of receiving different bit-rate streams from the same source, in an efficient and scalable way. The multirate property also allows us to provide graceful degradation to loss when used over networks which support multiple priorities. This paper evaluates the quality of the video images encoded with the layered encoding technique at different bit-rates in terms of the Peak Signal to Noise Ratio (PSNR) for cine-angiogram video. It also describes experiments with the transmission of the video across an Aysnchronous Transfer Mode (ATM) Local Area Network (LAN), using a two layer encoded video stream, and assigning different network service classes to the two layers. We study how the quality of the reconstructed signal changes with the ratio of the bit-rates of the high and low priority layers, for various levels of congestion in the ATM network. Keywords: Multi-rate coding, scalable compression, medical imaging, heterogeneous networks, <b>remote</b> <b>conferencing</b> 1...|$|R
40|$|The current Internet {{architecture}} as {{embodied in}} the IP network protocol oers a very simple service model pointtopoint besteort service In recent years several new classes of distributed applications have been developed such as <b>remote</b> video multimedia <b>conferencing</b> data fusion visualization and virtual reality It is becoming increasingly clear that the Internets primitiv...|$|R
50|$|Facilities {{include a}} <b>remote</b> {{learning}} video <b>conferencing</b> suite {{and more than}} 800 computers, with the library (Independent Learning Centre) having {{been converted into a}} room for homework assistance and computer access. Other facilities are a gymnasium, a multi-use hall, fitness suite, tennis/netball courts, and a playing field used for football, rugby and athletics. Some pupils attend local clubs including those for rugby and swimming.|$|R
40|$|We present two {{schemes for}} multiparty quantum <b>remote</b> secret <b>conference</b> {{in which each}} {{legitimate}} conferee can read out securely the secret message announced by another one, but a vicious eavesdropper can get nothing about it. The first one {{is based on the}} same key shared efficiently and securely by all the parties with Greenberger-Horne-Zeilinger (GHZ) states, and each conferee sends his secret message to the others with one-time pad crypto-system. The other one is based on quantum encryption with a quantum key, a sequence of GHZ states shared among all the conferees and used repeatedly after confirming their security. Both these schemes are optimal as their intrinsic efficiency for qubits approaches the maximal value. Comment: 4 pages, 1 figur...|$|R
40|$|Video-mediated {{communication}} (VMC) {{is currently}} the prevalent mode of telecommunication for applications such as remote collaboration, teleconferencing, and distance learning. It is generally assumed that transmitting real-time talking-head videos of participants {{in addition to their}} audio is beneficial and desirable, enabling <b>remote</b> <b>conferencing</b> to feel almost the same as face-to-face collaboration. However, compared to being face-to-face, VMC still feels distant, artificial, cumbersome, and detached. One limitation of standard video-collaboration that contributes to this feeling is that the 3 D context between people and their shared workspace given in face-to-face collaboration is lost. It is therefore not possible for participants to tell from the video what others are looking at, what they are working on, or who they are talking to. Video Collaborative Virtual Environments (video-CVEs) are novel VMC interfaces which address these problems by re-introducing a virtual 3 D context into which distant users are mentally "transported" to be together and interact with the environment and with each other, represented by their spatially controllable video-avatars. To date, research efforts following this approach have primarily focused on the demonstration of working prototypes. However, maturation of these systems requires a deeper understanding of human factors that emerge during mediated collaborative processes. This thesis contributes to a deeper understanding of human factors. It investigates the hypothesis that video-CVEs can effectively support face-to-face aspects of collaboration which are absent in standard video-collaboration. This hypothesis is tested in four related comparative user studies involving teams of participants collaborating in video-CVEs, through standard video-conferencing systems, and being face-to-face. The experiments apply and extend methods from the research fields of human-computer interaction, computer-supported cooperative work, and presence. Empirical findings indicate benefits of video-CVEs for user experience dimensions such as social presence and copresence, but also highlight challenges for awareness and usability that need to be overcome to unlock the full potential of this type of interface...|$|R
40|$|This article {{presents}} {{an argument for}} the use of networked interactive whiteboards (NIWBs) in regional Australian higher education and identifies new pedagogies for this context. Most Australian universities operate multiple campuses, and many use video conference facilities to deliver courses across these sites. For students at <b>remote</b> video <b>conference</b> sites, their classroom experience is often one of isolation and limited student to student contact. In this article, NIWBs are proposed as a tool to enhance this mode of delivery and exploratory research into the additional affordances they provide is presented. By using networking with IWBs, annotation and gesture can be shared across distances. Emerging possibilities from the integration of NIWBs with video conference, web conference and lecture capture systems are also explored. Three new pedagogies for regional Australian higher education are proposed based on these new capabilities. <br /...|$|R
40|$|Being {{obliged to}} work online {{with someone you}} do not know and may never meet brings an {{exciting}} added dimension to educational and professional experiences. Working online can be even more exciting and sometimes more challenging, when the participants come from particularly diverse backgrounds. This paper focuses on a learning experience designed to develop skills in pre-professionals equipping them to perform in both multicultural and virtual working environments. The paper explores an online collaborative project which uses WebCT, {{one of a number of}} virtual learning environments which supports <b>remote</b> <b>conferencing.</b> Although increasingly communications technologies is used for open and distance learning in both academic and professional domains, this project has a distinctive perspective. It brings together disparate learning communities specifically to explore cultural differences online and to develop new communications skills in the process. The 100 students per year, representing over 70 nationalities, collaborate in small multicultural work teams to produce online reports critiquing culturally sensitive websites. For instance, sites reviewed include those on intercultural communication in the workplace, linguistic differences in foreign professional settings, in online expression and presentation, virtual team working and remote co-operation through negotiation. Along with developing multicultural communication skills, the materials themselves with which the teams engage, help to develop their cultural sensitivity, important in increasingly diverse face-to-face and virtual professional environments. All of these complex skills are vital in developing pro-active networks and building cultural bridges in the future. (Authors' abstract) Cet article se concentre sur une expérience d'apprentissage créée pour développer des compétences pré-professionnelles permettant de travailler dans des environnements virtuels et multiculturels. Les auteurs décrivent un projet collaboratif sur Internet qui utilise WebCT, un des nombreux environnements d'apprentissage virtuel qui supporte la télé-conférence. Ce projet regroupe chaque année des étudiants de 70 nationalités différentes qui collaborent dans de petits groupes de travail produisant des rapports sur certains sites en fonctionnement faisant preuve d'une identité culturelle forte...|$|R
40|$|FI) system. Second International Airborne <b>Remote</b> Sensing <b>Conference</b> and Exhibition, San Francisco, CA, June 24 - 27. Capelie, G. A., et al. 1994. Laser-induced {{fluorescence}} imaging for remote sensing. 1994 ASPRS/ACSM Annual Convention and Exposition, April 25 - 28, Reno, NV. Sponsored by the American Society for Photogrammetry and Remote Sensing and the American Congress on Surveying and Mapping. Capelie, G., et al. 1993 a. Laser-induced fluorescence remote sensing of DOE sites: results from laboratory, laser range, and field tests. Depleted Uranium Health & Safety Exchange Meeting, Oak Ridge, TN, November 30 -December 1. Sponsored by DOE Oak Ridge Operations Office. Capelie, G., et al. 1993 b. Laser-induced fluorescence remote sensing of DOE sites: results from laboratory, laser range, and field tests. 9 th Thematic <b>Conference</b> on Geologic <b>Remote</b> Sensing, Pasadena, CA, February 9. DiBenedetto, J., et al. 1993. Laser-induced {{fluorescence imaging}} of uranium for DOE environmental restoratio...|$|R
40|$|A novel {{algorithm}} is proposed to downscale microwave brightness temperatures (T_B), at scales of 10 - 40 km such as those from the Soil Moisture Active Passive mission to a resolution meaningful for hydrological and agricultural applications. This algorithm, called Self-Regularized Regressive Models (SRRM), uses auxiliary variables correlated to T_B along-with a limited set of in-situ SM observations, which are converted to high resolution T_B observations using biophysical models. It includes an information-theoretic clustering step based on all auxiliary variables to identify areas of similarity, followed by a kernel regression step that produces downscaled T_B. This was implemented on a multi-scale synthetic data-set over NC-Florida for one year. An RMSE of 5. 76 K with standard deviation of 2. 8 k was achieved during the vegetated season and an RMSE of 1. 2 K {{with a standard deviation}} of 0. 9 K during periods of no vegetation. Comment: 7 pages, 4 figures, submitted to be presented at the International Geoscience and <b>Remote</b> Sensing <b>Conference</b> 201...|$|R
