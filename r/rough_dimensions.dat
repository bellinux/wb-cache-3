9|22|Public
50|$|Today, little remain of {{fortification}} {{walls and}} towers which are spreading {{on the top}} of the hill, on a plateau with <b>rough</b> <b>dimensions</b> of 50 m diameter. From it, the terrain steep drops on all sides to dry ditch, which is spreading around the entire fortress to protected the access to it.|$|E
50|$|In September 1943, the B-29 was {{selected}} as the carrier for the Atomic Bomb. At first, the team responsible for the adaptation of the B-29 to the atomic bomb would only be provided with <b>rough</b> <b>dimensions</b> of the bomb, since even the scientists were not yet sure what it would look like. The technicians fitted a new H-frame hoist, carrier assembly and release unit to the B-29. The first drop tests using dummy bombs were carried out at Muroc AAF, California on 28 February 1944. These lead to the fitting of an entirely new suspension mechanism to the B-29.|$|E
50|$|Parallels {{are first}} {{machined}} to <b>rough</b> <b>dimensions,</b> leaving a few millimeters {{to allow the}} rest to be ground. Parallels that only have 2 or 4 precision faces will often have the tool-marks from the machining on the non-ground sides. They are then paired {{and placed in a}} grinding machine, and each face is ground until the overall dimensions are correct - they are paired during this stage so that even if the dimensions are not correct, they are still parallel to each other. Then, the individual finishes are applied, from drilling to machining a chamfer along the edges to remove any burrs or sharpened edges. They may also be lapped to achieve a mirror smooth surface. Most parallels are also hardened.|$|E
25|$|There {{are several}} other {{applications}} resembling flagstone in using <b>rough</b> <b>dimension</b> (or crushed) stone, usually as quarried, sometimes made smaller (i.e. by a jackhammer), often simply put in place: dry stone and riprap.|$|R
25|$|<b>Rough</b> {{engineering}} <b>dimensions</b> for Tornado {{were obtained}} from measuring Blue Peter at the National Railway Museum (NRM). Due to there being no general arrangement drawing of a Peppercorn A1, one from an A2 was used.|$|R
50|$|The barn is set {{northeast}} {{of the house and}} is oriented parallel to the road. It is a large structure, measuring about 40 x 70 ft, with a gable roof and a large sliding door at the center of its main facade. Above this door is an extended multi-light rectangular transom window, with a sash window {{to the left of the}} door and another above in the gable. Attached to the building to the right of the door is a single-story equipment shed with two vehicle doors. The main barn matches in <b>rough</b> <b>dimension</b> a barn described in a 1798 inventory of the property; the attached shed is present in photographs from later in the 19th century.|$|R
40|$|A {{method for}} {{installing}} fragile, {{high temperature insulation}} batting in an elongated cavity or in a resilient wire sleeve to form a resilient seal. The batting is preformed to <b>rough</b> <b>dimensions</b> and wrapped in a plastic film, the film being of a material which is fugitive at a high temperature. The film is heat sealed and trimmed to form a snugly fit skin which overlaps at least at one end to permit attachment of a pull cord. The film absorbs the tensile force of pulling the film enclosed batting through the cavity or wire mesh sleeve and is subsequently driven off by high temperature baking, leaving only the insulation in the cavity or wire mesh sleeve...|$|E
40|$|We have {{previously}} reported results using a high precision gravimeter to probe local gravity {{changes in the}} neighborhood of bulk-processed high temperature superconductor disks. Others have indicated that large annular disks (on the order of 25 cm diameter) and AC levitation fields play an essential role in their observed experiments. We report experiments in processing such large bulk superconductors. Successful results depend on material mechanical characteristics, and pressure and heat treat protocols. Annular disks having <b>rough</b> <b>dimensions</b> of 30 cm O. D., 7 cm I. D. and 1 cm thickness have been routinely fabricated and tested under AC levitation fields ranging from 45 to 300 OHz. Implications for space transportation initiatives and power storage flywheel technology will be discussed...|$|E
40|$|Abstract. The {{nondestructive}} testing using ultrasonic pulse-echo data {{is an effective}} method especially for metal structure. Typically, the ultrasonic pulse-echo data is processed {{and the results are}} shown in A-scan, B-scan or C-scan data formats. In conventional testing using ultrasonic pulse-echo data, the inspector is able to identify the location of faults as well as their <b>rough</b> <b>dimensions</b> upon viewing B-scan and C-scan data. In this paper, we propose an approach using 3 -D visualization of ultrasonic pulse-echo data. The main idea of the proposed method is to use various 3 -D visualization methods frequently used in medical image visualization systems, namely, surface rendering (SR), volume rendering (VR) and maximum intensity projection (MIP). Such 3 -D visualization of ultrasonic pulse-echo data enables easier identification of the location and dimension of faults more accurately...|$|E
40|$|This paper {{discusses}} {{the framework for}} the development of an Energy Toolbox (ETB). The aim of the ETB is to support the design of domestic Zero Emission Buildings (ZEBs), according to the concept of net zero-energy buildings during the early architectural design and planning phases. The ETB concept is based on the calculation of the energy demand for heating, cooling, lighting, and appliances. Based on a building’s energy demand, technologies for the onsite conversion and production of the specific forms and quantities of final and primary energy by means of renewable energy carriers can be identified. The calculations of the ETB are based on the building envelope properties of a primary building design, as well as the physical and climate parameters required for the calculation of heat transfer coefficients, heat gains, and heat losses. The ETB enables the selection and <b>rough</b> <b>dimensioning</b> of technologies and systems to meet, and, wherever possible, reduce the thermal and electric energy demand of a building. The technologies included comprise green facades, adaptable dynamic lighting, shading devices, heat pumps, photovoltaic generators, solar thermal collectors, adiabatic cooling, and thermal storage. The ETB facilitates the balancing of the energy consumption and the production of renewable energies of a primary building design...|$|R
40|$|Abstract—Global {{approximation}} using metamodel {{for complex}} mathematical function or computer model {{over a large}} variable domain is often needed in sensibility analysis, computer simulation, optimal control, and global design optimization of complex, multiphysics systems. To overcome {{the limitations of the}} existing response surface (RS), surrogate or metamodel modeling methods for complex models over large variable domain, a new adaptive and regressive RS modeling method using quadratic functions and local area model improvement schemes is introduced. The method applies an iterative and Latin hypercube sampling based RS update process, divides the entire domain of design variables into multiple cells, identifies rougher cells with large modeling error, and further divides these cells along the <b>roughest</b> <b>dimension</b> direction. A small number of additional sampling points from the original, expensive model are added over the small and isolated rough cells to improve the RS model locally until the model accuracy criteria are satisfied. The method then combines local RS cells to regenerate the global RS model with satisfactory accuracy. An effective RS cells sorting algorithm is also introduced to improve the efficiency of model evaluation. Benchmark tests are presented and use of the new metamodeling method to replace complex hybrid electrical vehicle powertrain performance model in vehicle design optimization and optimal control are discussed. Keywords—Global approximation, polynomial response surface, domain decomposition, domain combination, multiphysics modeling, hybrid powertrain optimization I...|$|R
40|$|We present {{photometric}} {{observations of}} the near-Earth asteroid (25143) 1998 SF 36 from the 2001 apparition campaign, and we discuss the corresponding physical model. The asteroid's photometric behaviour is consistent with an S-type object, it has a retrograde pole at lambda = 355 °, beta = - 84 ° ± 5 °, and its sidereal rotation period is P = 12. 132 ± 0. 0005 hours. 1998 SF 36 is elongated, with <b>rough</b> global <b>dimension</b> ratios a/b = 2. 0, b/c = 1. 3, but the elongation is not due to a bifurcated shape. The surface {{is not likely to}} contain major concavities. No significant albedo variegation was detected...|$|R
40|$|We {{describe}} {{a new concept}} for a microwave circuit functioning as a charged-particle accelerator at mm-wavelengths, permitting an accelerating gradient higher than conventional passive circuits can withstand consistent with cyclic fatigue. The device provides acceleration for multiple bunches in parallel channels, and permits a short exposure time for the conducting surface of the accelerating cavities. Our analysis includes scalings based on a smooth transmission line model and a complementary treatment with a coupled-cavity simulation. We provide also an electromagnetic design for the accelerating structure, arriving at <b>rough</b> <b>dimensions</b> for a seven-cell accelerator matched to standard waveguide and suitable for bench tests at low power in air at 91. 392 GHz. A critical element in the concept is a fast mm-wave switch suitable for operation at high-power, and we present the considerations for implementation in an H-plane tee. We discuss the use of diamond as the photoconductor switch medium...|$|E
30|$|The {{original}} map (with <b>rough</b> <b>dimensions</b> of 10, 000  ×  15, 000 cells where each cell is of 1.25 m× 1.25 m) is {{incorporated into the}} proposed city model after dividing the original file into partitions. This work focuses on more interesting central region {{of the city as}} shown in Fig.  3 a. The space thus selected comprises of 5000  ×  10, 000 cells, and it is divided into 200 regions (Fig.  2). Each region is a map distribution unit for parallel execution and it (the corresponding process of a region) is assigned to a dedicated processor. These regions are numbered from 0 to 199 and arranged in 20 rows and 10 columns. Each process is responsible to simulate a region comprises of 500 × 500 cells (Fig.  3 b). To perform an activity such as a movement, the agents on top of cells utilize the spatial information to recognize the morphological features of the space underneath them (which include streets, obstacles and displays).|$|E
40|$|This {{program was}} {{intended}} to develop theory, {{a broad range of}} algorithms and proof of concept in detection, estimation, and reconstruction of objects embedded in turbid media, which hamper visibility (such as fog, clouds, smoke, and other types of aerosol particles). In particular, the program addresses the following eight specific areas: 1. We exploit recent advances in the physical design of fast optical systems which enable active imaging and ranging with ”ballistic ” light. In this modality, fast bursts of optical energy are transmitted into a medium, and the ballistic component of light (which travels through a medium with minimal diffusive distortion) is detected in either backscatter from the target, or in trans-illuminated form through the medium. 2. We simultaneously optimize the shape and duration of the optical pulses and the design of the optical detectors to achieve maximum signal detectability. The currently existing ballistic imaging practice has been based largely on ad-hoc choices of the optical waveforms, and static detector designs based on time-gating. 3. We study the ballistic imaging problem as (1) a detection problem where the simple presence or absence of some target and its <b>rough</b> <b>dimensions</b> are sought; and (2) a reconstruction problem, wher...|$|E
40|$|At about noon on July 9, 1974, {{a number}} of pupils (109) at the Seta Junior High School, Setagaya, Tokyo, Were {{affected}} by photochemical smog. A sharp peak of oxidant concentration amounting to 0. 29 ppm with a half-width duration of 15 min was recorded at 11 : 50 at the Tamagawa monito-ring station situated 1. 7 km on the windward of the school. Records of oxidant concentration-time curves at four monitoring stations on the leeward have been compared with each other including that of Tamagawa. Although the peak concentration decayed gradually with the distance from Tamagawa, principal feature was retained through ca. 10 km and for ca. 50 min. The delay of time of maximum oxidant concentration at each measuring point approximately agrees with the time required for the wind to reach each measuring point which is calculated from the distance and the mean wind speed. Oxidant concentration-time curves recorded at four monitoring stations in Kawasaki, Kanagawa, {{the opposite side of}} Tama River, were also examined. In addition, the maximum (one-hour) oxidant concentrations and the directions of wind at that time measured at over thirty monitoring stations have been plotted on a map, and the transport of the air mass with high oxidant concentration has been illustrated. The <b>rough</b> <b>dimension</b> of the air mass has been estimated. The sharp peak found at Tamagawa has been ascribed to the sudden descent of air mass including oxidant of high concentration from high above the neighboring area on the windward of Tamagawa...|$|R
40|$|Increasing water scarcity, {{caused by}} either climate change or {{increasing}} consumption or both, has drawn attention to climate-sensitive adaptive strategies. These strategies include {{the possibility of}} re-engineering the urban water cycle to implement water recycling and reuse practices. For this reason {{a new generation of}} decision support tools capable of coping with these challenges is needed. UWOT (Urban Water Optioneering Tool) answers to this request by modelling the total urban water cycle and assessing its sustainability through a set of indicators. UWOT can support the planning of adaptive strategies for existing or new developments. Existing developments, for example, may include the installation of retrofit technologies (e. g. low flush toilets, in house water treatment units etc). In this case, UWOT can be used along with optimization algorithms to identify the optimum trade-off between the potable water demand reduction and the required cost (including energy). For new developments, more radical solutions (like central grey/rain water treatment units) can be adopted to manage the available water resources more efficiently. In this case, UWOT can help in the preliminary study of the required investment providing a <b>rough</b> <b>dimensioning</b> and an estimation of the pay-back period. Another issue that UWOT can help with is the investigation of the influence of climatic trends on the efficiency of water saving technologies. Rainwater harvesting, for example, directly depends on climatic conditions. UWOT can be used along with a stochastic model to provide a probabilistic approach for studying this uncertainty. Furthermore, UWOT can be used to examine a health issue related with the prolonged storage of harvested rainwater. Long periods of storage may result in significant degradation of the water quality rendering imperative the implementation of measures to maintain quality standards. UWOT can be used to investigate the necessity of such measures by calculating the Residence Time Index that characterizes the operation of a tank...|$|R
40|$|The {{trends in}} chatter {{prediction}} are to compute stability lobes showing the maximal {{depth of cut}} versus spindle speed, following the work of Tlusty, Tobias and, more recently, Altintas. For mass production such as the production of automotive parts, this kind of approach is not suitable because {{the goal is to}} find cutting conditions stable and independent of perturbations inherent to machining (clamping, <b>rough</b> part <b>dimensions</b> [...] .). Still, in this method, the greatest allowable depth of cut to avoid chatter at any spindle speed is considered. The model is based on Tlusty's theory and the local stiffness of the machined surface is computed through a static finite element analysis. The result is a chatter map of the machined surface showing the maximal depth of cut at each node. Peer reviewe...|$|R
40|$|A {{successive}} approximation (SA) scheme {{is applied to}} the problem of scattering from a perfectly conducting surface, <b>rough</b> in one <b>dimension.</b> The SA scheme is based on appropriate reformulation of the extinction theorem integral equation, in combination with a convenient representation of the source function. An explicit expression is given for the general term, which allows derivation of the general term of a related perturbation series and of corrections to the Kirchhoff approximation to all orders...|$|R
40|$|In our ongoing {{studies of}} uranium {{complexes}} we have determined the crystal structure of UO{sub 2 }(urea) {sub 5 }(NO{sub 3 }) {sub 2 } by X-ray diffraction. Gentile and Campisi reported {{the preparation of}} this compound and concluded, on the basis of infrared spectra, that the nitrate groups are not coordinated to uranium, a fact which we confirm. The uranyl ion is coordinated by oxygen atoms of the five urea molecules in a complex which is monomeric, not a polymer as suggested earlier. From an aqueous solution of uranyl nitrate and urea which was allowed to evaporate slowly overnight, small fluorescent lime-green crystals precipitated. The crystals were stable in air and showed no decomposition during the two weeks the X-ray experiments were being conducted. Weissenberg photography showed the crystal to be monoclinic, and <b>rough</b> cell <b>dimensions</b> were obtained...|$|R
5000|$|The {{publication}} of the ideas of Kahn and Wiener {{were part of a}} study commissioned in 1965 by the American Academy of Arts and Sciences, which published the results of the commission's findings in the summer of 1967 as [...] "Toward the Year 2000: Work in Progress", a special issue of Dædalus, journal of the academy. In their portion of the work, Kahn and Wiener, discussing urbanization, began by writing the following. The pair went on to give <b>rough</b> geographic <b>dimensions</b> to the areas. BosWash was described as [...] "the megalopolis that will extend from Washington to Boston" [...] along [...] "an extremely narrow strip of the North Atlantic coast." [...] ChiPitts, mentioned as being from Chicago to Pittsburgh but extending east to Rochester, New York, was laid out as [...] "on Lake Erie and the southern and western shores of Lake Michigan and Lake Ontario" [...] and SanSan as [...] "an even more narrow strip on the West Coast" [...] from either Santa Barbara or San Francisco to San Diego in California.|$|R
40|$|AbstractDue to {{the strict}} discussions {{regarding}} energy saving {{and the goal}} to reduce CO 2 emissions to 95 g CO 2 /km, specified for the year 2020 (BUMD, 2009), {{there is a strong}} demand for lighter and lightweight design automotive structures to support the energy saving targets. In view of a holistic approach, and to prospectively meet the requirements of the automotive sector, economic and production-orientated aspects, as well as joining technologies within the scope of multi-material design must also be considered to achieve a great leap towards medium to large-scale production. To accomplish these goals, a comprehensive method for urban vehicle concepts with electric powertrain and their necessary vehicle structures is presented. The dimensions and packaging of the presented vehicle are based on demands of a future urban vehicle with a four-passenger capacity that includes baggage, steerable front system wheels and a rear axle with an electric powertrain. At the beginning of the method, the relevant user requirements, e. g. space for occupants and baggage and range for the urban vehicle, are defined. In addition, input variables are discharged through state-of-the-art electric vehicles. In this step, {{it is important to consider}} additional requirements, such as crash requirements or requirements for electrical components in the vehicle design. With the defined requirements, the package of the urban car has to be defined. Two paths are determined to a geometrically and a simulative way. The simulative consideration is limited to the vehicle longitudinal dynamics; thus, a <b>rough</b> <b>dimensioning</b> of the drive components is derived. The outputs of the simulation are the performance measures, which are converted into components for the overall model to dimension, for example, the electric motor or battery. The geometric design phase begins with the positioning of the occupants in the passenger compartment and the ergonomic layout. Based on this conception of the complete vehicle, various FEM optimisations (topology, topography, size) are carried out for the body in white, in order to construct structures for individual (functional) components/modules. This top-down approach gives the opportunity to obtain constructive innovations, which must be integrated within this early concept phase, also to reduce costs when aiming to develop a series product. With this holistic approach, a load-specific optimised structural design is generated virtually and evaluated, and an outlook on dynamic loads (crash behaviour) is also given. The focus here is on the potential for innovations by the definition of novel package alignments in combination with the useful application of multi-material-design methods, resulting in a light modular vehicle structure...|$|R
40|$|By {{the strict}} discussions {{regarding}} energy saving {{and the goal}} to reduce CO 2 emissions to 95 g CO 2 /km, which is specified for the year 2020, [1] there is a keen demand for lighter and lightweight designed automotive structures to support the energy saving targets. In view of a holistic approach and also to prospectively {{meet the requirements of}} the automotive sector, beside the previously mentioned challenges, economic and production-orientated aspects, as well as joining technologies, within the scope of multi-material design, have to be considered to realize a great leap forward medium to large-scale productions. To achieve these goals, a comprehensive method for urban vehicle concepts with electric powertrain and their necessary vehicle structures is presented. The dimensions and packaging of the presented vehicle is based on demands of a future urban vehicle with space for four occupants including baggage, steerable front system wheels and a rear axle including an electric powertrain. At the beginning of the method the relevant user requirements, e. g. space for persons and baggage, range for the urban vehicle are defined. In addition, input variables are discharged through {{the state of the art}} of electric vehicles. It is also an important point in this step to look on further requirements such as crash requirements or requirements for electrical components in the vehicle design. With the defined requirements the package of the urban car has to be defined. Two paths are determined to a geometrically and a simulative way. The simulative consideration is limited to the vehicle longitudinal dynamics, thus a <b>rough</b> <b>dimensioning</b> of the drive components is derived. The outputs of the simulation are the performance measures which are then converted into components for the overall model for dimensioning for example electric motor or battery. The geometric design phase begins with the positioning of the occupants in the passenger compartment and ergonomic layout. Based on this conception of the complete vehicle, various FEM optimizations (topology, topography, size) are carried out for the body in white in order to construct structures towards individual (functional) components/modules. This top-down approach raises the opportunity to extract constructive innovations, which must be integrated within this early concept phase, also to reduce costs when aiming to development of a series product. With this holistic approach a load-specific optimized structural design is virtually generated and evaluated, and also an outlook on dynamic loads (crash behavior) is given. The focus here is on the potential in innovations by the definition of novel package alignments in combination with the useful application of multi-material-design method, resulting in a light modular vehicle structure...|$|R
40|$|Simulation is a ﬂexible {{means for}} {{assessment}} {{of the quality of}} service offered by a telecommunication system. However, when very strict requirements are put on the quality of service, the simulation becomes inefﬁcient because the performance depends on rare events to occur. A rare event is, for instance, a cell loss or a system breakdown. A simulation technique that speeds up the experiments must be added. Various techniques are known from the literature and they should be combined to achieve additional speedups. The most efﬁcient speedup techniques for systems dependent on rare events, are importance sampling and RESTART. The importance sampling technique is very sensitive to the change of the underlying simulation process. This is denoted the biasing of the simulation parameters. In this thesis, explicit expressions of the variance of importance sampling estimates and the likelihood ratio are developed for an M/M/ 1 /N queue. The study of how the variance expressions vary as the biasing changes, demonstrates that the importance sampling is very efﬁcient in a narrow region, and that the variance is unbounded outside. It is also observed that, seemingly, the likelihood ratio and its variance may be used as an indication of the accuracy of simulation results, in combination with the variance of the estimate itself. Neither importance sampling nor RESTART are easily applied to multidimensional models, e. g. a model of a telecommunication network with a variety of different users. In this thesis, the focus is on how to do importance sampling simulations of telecommunication networks with balanced utilisation of the resources. A network system are described by a multidimensional model. The balanced resource utilisation implies that the system performance is not given by a single bottleneck. Hence, previous approaches for importance sampling biasing are no longer efﬁcient. The reason is that they assume that the performance of a single resource signiﬁcantly constrains the system performance, and under this assumption, the parameters can be biased with respect to the bottleneck resource only. A new adaptive biasing technique is deﬁned for dynamically setting up the simulation parameters in the importance sampling experiment. This is the major contribution of this thesis, and it has been successfully applied to several networks. The basic idea is to change the simulation parameters to make the simulation process move toward the parts of the state space where the most important rare events occur. Because this importance depends on the current state, the change of parameters is adapted to the state changes in the simulation process. The networks used for feasibility demonstration are offered trafﬁc from (i) users with different resource capacities and trafﬁc parameters, (ii) users with and without alternative routing strategies, and (iii) users with different preemptive priority levels and a network with a link failure. The simulation results are validated by comparison with exact results, <b>rough</b> <b>dimensioning</b> rules, and correctness indicators given by the observed likelihood ratio. dr. ing. dr. ing...|$|R
40|$|A {{class of}} solid-on-solid growth models with short range {{interactions}} and sequential updates is studied. The models exhibit both smooth and <b>rough</b> phases in <b>dimension</b> d= 1. Some {{of the features}} of the roughening transition which takes place in these models are related to contact processes or directed percolation type problems. The models are analyzed using a mean field approximation, scaling arguments and numerical simulations. In the smooth phase the symmetry of the underlying dynamics is spontaneously broken. A family of order parameters which are not conserved by the dynamics is defined as well as conjugate fields which couple to these order parameters. The corresponding critical behavior is studied and novel exponents identified and measured. We also show how continuous symmetries can be broken in one dimension. A field theory appropriate for studying the roughening transition is introduced and discussed. Comment: RevTeX, 18 pages, 15 postscript figure...|$|R
40|$|In {{models of}} large extra dimensions, the string and Planck scales become {{accessible}} at future colliders. When the energy scale {{is above the}} string scale or Planck scale a number of interesting phenomena occur, namely, production of stringy states, $p$-branes, string balls, black hole, etc. In this work, we systematically study the production cross sections of black holes, string balls, and $p$-branes at hadronic supercolliders. We also discuss their signatures. At the energy scale between the string scale $M_s$ and $M_s/g_s^ 2 $, where $g_s$ is the string coupling, the production is dominated by string balls, while beyond $M_s/g_s^ 2 $ it is dominated by black holes. The production of $p$-brane is only comparable to black holes when the $p$-brane wraps entirely on small extra <b>dimensions.</b> <b>Rough</b> estimates on the sensitivity reaches on the fundamental Planck scale $M_D$ are also obtained, {{based on the number}} of raw events...|$|R
40|$|In {{models of}} large extra dimensions, the string and Planck scales become {{accessible}} at future colliders. When the energy scale {{is above the}} string scale or Planck scale a number of interesting phenomena occur, namely, production of stringy states, p-branes, string balls, black hole, etc. In this work, we systematically study the production cross sections of black holes, string balls, and p-branes at hadronic supercolliders. We also discuss their signatures. At the energy scale between the string scale M_s and M_s/g_s^ 2, where g_s is the string coupling, the production is dominated by string balls, while beyond M_s/g_s^ 2 it is dominated by black holes. The production of a p-brane is only comparable to black holes when the p-brane wraps entirely on small extra <b>dimensions.</b> <b>Rough</b> estimates on the sensitivity reaches on the fundamental Planck scale M_D are also obtained, {{based on the number}} of raw events. Comment: 30 pages, to match the published version in PRD, added reference...|$|R
40|$|The fractal or Hausdorff {{dimension}} {{is a measure}} of roughness (or smoothness) for time series and spatial data. The graph of a smooth, differentiable surface indexed in R^d has topological and fractal dimension d. If the surface is nondifferentiable and <b>rough,</b> the fractal <b>dimension</b> takes values between the topological dimension, d, and d+ 1. We review and assess estimators of fractal dimension by their large sample behavior under infill asymptotics, in extensive finite sample simulation studies, and in a data example on arctic sea-ice profiles. For time series or line transect data, box-count, Hall [...] Wood, semi-periodogram, discrete cosine transform and wavelet estimators are studied along with variation estimators with power indices 2 (variogram) and 1 (madogram), all implemented in the R package fractaldim. Considering both efficiency and robustness, we recommend the use of the madogram estimator, which can be interpreted as a statistically more efficient version of the Hall [...] Wood estimator. For two-dimensional lattice data, we propose robust transect estimators that use the median of variation estimates along rows and columns. Generally, the link between power variations of index p> 0 for stochastic processes, and the Hausdorff dimension of their sample paths, appears to be particularly robust and inclusive when p= 1. Comment: Published in at [URL] the Statistical Science ([URL] by the Institute of Mathematical Statistics ([URL]...|$|R
40|$|In both {{physical}} and social sciences, we usually use controlled differential equation to model various continuous evolving system; describing how a response y relates to another process x called control. For regular controls x, the unique existence of the response y is guaranteed while {{it would never be}} the case for non-smooth controls via the classical approach. Besides, uniform closeness of controls may not imply closeness of their corresponding responses. Theory of rough paths provides a solution to both concerns. Since the creation of rough path theory, it enjoys a fruitful development and finds wide applications in stochastic analysis. In particular, rough path theory provides an effective method to study irregularity of curves and its geometric consequences in relation to integration of differential forms. In the chapter 2, we demonstrate the power of rough path theory in classical complex analysis by showing the rough path nature of the boundaries of a class of Holder's domains; as an immediate application, we extend the classical Gauss-Green's theorem. Until recently, there has been only limited research on applications of theory of rough paths to high dimensional geometry. It is clear to us that many geometric objects, in some senses appearing as solids, are actually comprised of filaments. In the chapter 3, two basic results in the theory of rough paths which will motivate later development of my thesis has been included. In the chapters 4 and 5, we identify a sensible way to do geometric calculus via those filaments (more precisely, space-filling <b>rough</b> paths) in <b>dimension</b> 3. In a recent joint work of Hambly and Lyons, they have shown that every rectifiable path can be completely characterized, up to tree-like deformation, by an algebraic object called the signature, tensor of all iterated integrals, of the path. It is clear that all tree-like deformation of the path would not change its topological features. For instance, the number of times a planar loop of finite length winds around a point (not lying on the path) is unaltered if one deforms the path in tree-like ways. Therefore, it should be plausible to extract this topological information out from the signature of the loop since the signature is a complete algebraic invariant. In the chapter 6, we express the winding number of a nice loop (respectively linking number of a pair of nice loops) as a linear functional of the signature of the loop (respectively signatures of the pair of loops). </p...|$|R

