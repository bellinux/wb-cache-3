1528|6713|Public
25|$|In contrast, a <b>real</b> <b>image</b> is {{one that}} is formed when the {{outgoing}} rays form a point converging at a real location. Real images can be projected onto a diffuse reflecting screen, but a screen is not necessary for the image to form.|$|E
25|$|In {{some cases}} S2 is negative, {{indicating}} that the image is formed {{on the opposite side}} of the lens from where those rays are being considered. Since the diverging light rays emanating from the lens never come into focus, and those rays are not physically present at the point where they appear to form an image, this is called a virtual image. Unlike real images, a virtual image cannot be projected on a screen, but appears to an observer looking through the lens as if it were a real object at the location of that virtual image. Likewise, it appears to a subsequent lens as if it were an object at that location, so that second lens could again focus that light into a <b>real</b> <b>image,</b> S1 then being measured from the virtual image location behind the first lens to the second lens. This is exactly what the eye does when looking through a magnifying glass. The magnifying glass creates a (magnified) virtual image behind the magnifying glass, but those rays are then re-imaged by the lens of the eye to create a <b>real</b> <b>image</b> on the retina.|$|E
25|$|Other uses are in imaging {{systems such}} as monoculars, binoculars, telescopes, microscopes, cameras and projectors. Some of these {{instruments}} produce a virtual image when applied to the human eye; others produce a <b>real</b> <b>image</b> that can be captured on photographic film or an optical sensor, or can be viewed on a screen. In these devices lenses are sometimes paired up with curved mirrors to make a catadioptric system where the lens's spherical aberration corrects the opposite aberration in the mirror (such as Schmidt and meniscus correctors).|$|E
30|$|Tested and {{discussed}} results of <b>real</b> <b>images</b> {{taken from a}} mobile device. From our review of related work, only the work of Chu (2013) also tested their proposed algorithm on <b>real</b> <b>images</b> from a mobile device [3].|$|R
30|$|As {{shown in}} Fig.  12, virtual view images of {{amethyst}} and chess are similar with <b>real</b> <b>images.</b> Synthesized image in ball blurs obviously.|$|R
5000|$|... #Subtitle level 3: Opium, <b>real</b> <b>images,</b> {{and dreaming}} as a channel ...|$|R
25|$|A {{diverging}} lens (one that is thicker {{at the edges}} than the middle) or a convex mirror forms a virtual image. Such an image is so reduced in size {{when compared to the}} original object. A converging lens (one that is thicker in the middle than at the edges) or a concave mirror is also capable of producing a virtual image if the object is within the focal length. Such an image will be magnified. In contrast, an object placed in front of a converging lens or concave mirror at a position beyond the focal length produces a <b>real</b> <b>image.</b> Such an image may be magnified or reduced depending on the position of the object.|$|E
25|$|Linear {{magnification}} M is {{not always}} the most useful measure of magnifying power. For instance, when characterizing a visual telescope or binoculars that produce only a virtual image, one would be more concerned with the angular magnification—which expresses how much larger a distant object appears through the telescope compared to the naked eye. In the case of a camera one would quote the plate scale, which compares the apparent (angular) size of a distant object {{to the size of the}} <b>real</b> <b>image</b> produced at the focus. The plate scale is the reciprocal of the focal length of the camera lens; lenses are categorized as long-focus lenses or wide-angle lenses according to their focal lengths.|$|E
500|$|Principal {{photography}} {{concluded in}} New York City, where filming occurred over two days. Filming locations in New York City included Park Avenue and Central Park. For scenes {{taking place in}} Manhattan, visual effects supervisor Jake Morrison shot aerial footage for over three days to use as background plates, elaborating that his main objective was to [...] "get as much aerial work in as possible for the audience to see the big expanses, the wide establishing shots, while also {{making sure that the}} effects work doesn't look too computer generated". [...] "We're getting much better at making entirely computer-generated environments," [...] Morrison explained, [...] "but {{there is no substitute for}} starting with a <b>real</b> <b>image</b> and adding what you need." ...|$|E
50|$|Several image {{processing}} techniques, such as unsharp masking, {{can increase the}} acutance in <b>real</b> <b>images.</b>|$|R
40|$|Iterative methods showed {{until now}} {{encouraging}} results to resolve shape from shading. This kind of methods generally work on synthetic images, and occasionally on <b>real</b> <b>images,</b> even if such images {{do not agree}} in general with the hypotheses of shape from shading. In this article, we describe the assumptions mentioned above, and propose an original methodology, which enables the production of <b>real</b> <b>images</b> and the process allowing to correct most of their defects {{in order to make}} them correspond to most of these assumptions. Moreover, we propose a descent gradient iterative scheme, thanks to which we prove that shape from shading can work as well on <b>real</b> <b>images</b> as on synthetic images. ...|$|R
30|$|In this section, {{we present}} first some {{criterion}} {{of performance and}} then we show {{the results obtained on}} <b>real</b> <b>images.</b>|$|R
2500|$|Using a {{positive}} lens of focal length f, a virtual image results when , the lens thus being used {{a magnifying glass}} (rather than if [...] as for a camera). Using a negative lens (...) with a real object (...) can only produce a virtual image (...) , {{according to the above}} formula. It is also possible for the object distance S1 to be negative, in which case the lens sees a so-called virtual object. This happens when the lens is inserted into a converging beam (being focused by a previous lens) before the location of its <b>real</b> <b>image.</b> In that case even a negative lens can project a <b>real</b> <b>image,</b> as is done by a Barlow lens.|$|E
2500|$|The Islamic Information Center (IIC) (IIC) is a [...] "grass-roots" [...] {{organization}} that has been formed {{for the purpose of}} informing the public, mainly through the media, about the <b>real</b> <b>image</b> of Islam and Muslims. The IIC is run by chairman (Hojatul-Islam) Imam Syed Rafiq Naqvi, various committees, and supported by volunteers.|$|E
2500|$|Therefore, if {{an object}} is placed at a {{distance}} [...] from a positive lens of focal length f, we will find an image distance S2 according to this formula. If a screen is placed {{at a distance}} S2 {{on the opposite side of}} the lens, an image is formed on it. This sort of image, which can be projected onto a screen or image sensor, is known as a <b>real</b> <b>image.</b>|$|E
3000|$|We next {{present the}} {{experiments}} on both synthetic and <b>real</b> <b>images</b> with intensity inhomogeneity, noise and complex background. The function [...]...|$|R
50|$|For <b>real</b> <b>images,</b> such as images {{projected}} on a screen, size means a linear dimension (measured, for example, in millimeters or inches).|$|R
30|$|In this section, {{a series}} of {{experiments}} are conducted on <b>real</b> <b>images</b> to evaluate the validity of analytical derivations and performance of the proposed method.|$|R
2500|$|Typically, a lens is used {{to focus}} the light {{reflected}} or emitted from objects into a <b>real</b> <b>image</b> on the light-sensitive surface inside a camera during a timed exposure. With an electronic image sensor, this produces an electrical charge at each pixel, which is electronically processed and stored in a digital image file for subsequent display or processing. The result with photographic emulsion is an invisible latent image, which is later chemically [...] "developed" [...] into a visible image, either negative or positive depending on {{the purpose of the}} photographic material and the method of processing. A negative image on film is traditionally used to photographically create a positive image on a paper base, known as a print, either by using an enlarger or by contact printing.|$|E
2500|$|The {{earliest}} known {{examples of}} compound microscopes, which combine {{an objective lens}} near the specimen with an eyepiece to view a <b>real</b> <b>image,</b> appeared in Europe around 1620. The design {{is very similar to}} the telescope and, like that device, its inventor is unknown. Again claims revolve around the spectacle making centers in the Netherlands including claims it was invented in 1590 by Zacharias Janssen and/or his father, Hans Martens, claims it was invented by rival spectacle maker, Hans Lippershey, and claims it was invented by expatriate Cornelis Drebbel who was noted to have a version in London in 1619. Galileo Galilei (also sometimes cited as a compound microscope inventor) seems to have found after 1609 that he could close focus his telescope to view small objects and, after seeing a compound microscope built by Drebbel exhibited in Rome in 1624, built his own improved version. The name [...] "microscope" [...] was coined by Giovanni Faber, who gave that name to Galileo Galilei's compound microscope in 1625.|$|E
60|$|But in the {{somewhat}} stiff portraiture of that epoch {{it is perhaps}} a little difficult to trace the <b>real</b> <b>image,</b> the inner individuality {{of one of the}} most interesting personalities at the Court of Mary Tudor.|$|E
30|$|For data augmentation, image {{synthesis}} is {{a useful}} approach for reducing the effort of manually annotation. Wong et al. [34] investigate a benefit of data augmentation for MNIST handwritten character dataset. For object detection, Khail et al. [35] propose an image synthetic method in which <b>real</b> object <b>images</b> and <b>real</b> background <b>images</b> are synthesized. For text localization in natural images, Gupta et al.[36] also propose an image synthetic method in which computer-generated texts and natural <b>real</b> <b>images</b> are synthesized. Sun and Saenko [37] and Su et al.[38] employ 3 D CAD object models with <b>real</b> background <b>images</b> for image synthesis. Castro et al.[39] propose a method of generating synthetic structural magnetic resonance images for learning schizophrenia.|$|R
40|$|We {{introduce}} {{a novel approach}} {{to the problem of}} localizing objects in an image and estimating their fine-pose. Given exact CAD models, and a few <b>real</b> training <b>images</b> with aligned models, we propose to leverage the geometric information from CAD models and appearance information from <b>real</b> <b>images</b> to learn a model that can accurately estimate fine pose in <b>real</b> <b>images.</b> Specifically, we propose FPM, a fine pose parts-based model, that combines geometric information in the form of shared 3 D parts in deformable part based models, and appearance information in the form of objectness to achieve both fast and accurate fine pose estimation. Our method significantly outperforms current state-of-the-art algorithms in both accuracy and speed...|$|R
40|$|We propose DTI-DeformIt: a {{framework}} to generate realis-tic synthetic datasets from {{a smaller number}} of, or even one, annotated image(s). Our approach extends the DeformIt tech-nique of Hamarneh et al. [1] to handle the deformations and noise conditions of diffusion tensor images. An implemen-tation of our proposed framework is also provided as a free download. We further show that DTI-DeformIt generates im-ages that, according to eigenvector distance, are no different from <b>real</b> <b>images</b> than other <b>real</b> <b>images,</b> making them suit-able for machine learning and validation...|$|R
6000|$|... "Why {{should one}} {{made in the}} <b>real</b> <b>image</b> of God suffer his natur' to be {{provoked}} by a mere effigy of reason?" [...] he said in English, and in tones much louder than those in which Weucha had chosen to pitch the conversation. The latter profited by the unintentional offence of his captive, and, seizing him by the thin, grey locks, that fell from beneath his cap, was {{on the point of}} passing the blade of his knife in malignant triumph around their roots, when a long, shrill yell rent the air, and was instantly echoed from the surrounding waste, as if a thousand demons opened their throats in common at the summons. Weucha relinquished his grasp, and uttered a cry of exultation.|$|E
6000|$|His {{knowledge}} of German Literature, very slight at this time, limited itself altogether to writers on Church matters,--Evidences, Counter-Evidences, Theologies and Rumors of Theologies; by the Tholucks, Schleiermachers, Neanders, and I know not whom. Of the true sovereign souls of that Literature, the Goethes, Richters, Schillers, Lessings, he had {{as good as}} no knowledge; and of Goethe in particular an obstinate misconception, with proper abhorrence appended,--which did not abate for several years, nor quite abolish itself till a very late period. Till, in a word, he got Goethe's works fairly read and studied for himself! This was often enough the course with Sterling in such cases. He had a most swift glance of recognition for the worthy and for the unworthy; and was prone, in his ardent decisive way, to put much faith in it. [...] "Such a one is a worthless idol; not excellent, only sham-excellent:" [...] here, on this negative side especially, you often had to admire how right he was;--often, but not quite always. And he would maintain, with endless ingenuity, confidence and persistence, his fallacious spectrum to be a <b>real</b> <b>image.</b> However, it was sure to come all right in the end. Whatever real excellence he might misknow, you had but to let it stand before him, soliciting new examination from him: none surer than he to recognize it at last, and to pay it all his dues, with the arrears and interest on them. Goethe, who figures as some absurd high-stalking hollow play-actor, or empty ornamental clock-case of an [...] "Artist" [...] so-called, in the Tale of the Onyx Ring, was in the throne of Sterling's intellectual world before all was done; and the theory of [...] "Goethe's want of feeling," [...] want of &c. &c. appeared to him also abundantly contemptible and forgettable.|$|E
50|$|Qube is a {{subsidiary}} of <b>Real</b> <b>Image</b> Media Technologies.|$|E
40|$|We have {{developed}} a new optimisation based shape from shading algorithm which is able {{to make use of}} sophisticated camera and reflectance models and does not require a good initialising surface. Surface shape consistent with ground truth is obtained when the technique is applied to both synthetic rendered surfaces and <b>real</b> <b>images</b> captured by the Mars Express orbiter and HRSC instrument. The obtained surfaces provide improved fine surface detail over that found using stereo techniques and demonstrate the applicability of the technique to <b>real</b> <b>images.</b> Peer reviewe...|$|R
40|$|Abstract. A new method, {{based on}} ground truth, for {{evaluating}} edge detection error {{is presented in}} the paper. Edge detection is fundamental in computer vision and imaging processing, among which, object detection {{is one of the most}} direct goals. Therefore, we evaluate edge detection error from a new perspective-evaluate them according to their effect on locating salient boundary in <b>real</b> <b>images.</b> To conduct a systematic evaluation, we collect a large data set (1030) of <b>real</b> <b>images</b> with ground truth object boundaries manually extracted. First, we apply canny detection on all <b>real</b> <b>images,</b> then extract detected edges coming from ground truth. Based on extracted edges, we build several edge error models, and also have background edge-maps. Second, we apply above error models with same parameters on ground truths, then combine each ground truth with corresponding background edge-map. Third, we apply boundary detection algorithms ratio-contour to detect boundaries from above combined images, and compare its performance on combined images with that on <b>real</b> <b>images.</b> Statistically, it shows that above tow performances are almost same, which indicates that our edge error models are close to real edge errors distribution. We also show that edge missing and dislocation error are two key factors effecting overall performance of boundary detection ratio-contour, while dislocation error is more crucial. ...|$|R
40|$|The {{present study}} {{describes}} {{a way of}} appraising the aesthetic meaning of dance motor skills generated by professional modern dancers. Using a motion capture system (Vicon MX), both <b>real</b> <b>images</b> and 3 D stick figures were simultaneously obtained from 96 trials of dance motor skills performed by four experienced contemporary dancers. Subsequently, 101 students of Physical Activity and Sport Sciences used semantic differentials to appraise the aesthetic value of each type of motor dance skill, comparing the virtual and <b>real</b> <b>images</b> of dancers. Author Keywords Aesthetic movement, aesthetic perception, motion capture...|$|R
5000|$|... #Caption: A {{camera lens}} forms a <b>real</b> <b>image</b> {{of a distant}} object.|$|E
5000|$|Pentax - PRIME (Pentax <b>Real</b> <b>IMage</b> Engine) (newer {{variants}} {{based on}} Fujitsu Milbeaut) ...|$|E
50|$|REAL-IMAGE SHORT FILMS. Official section. Recent {{productions}} of <b>real</b> <b>image</b> short films in competition.|$|E
40|$|We {{propose a}} novel {{approach}} to synthesizing images that are effective for training object detectors. Starting from a small set of <b>real</b> <b>images,</b> our algorithm estimates the rendering parameters required to synthesize similar images given a coarse 3 D model of the target object. These parameters can then be reused to generate an unlimited line of training images of the object of interest in arbitrary 3 D poses, which can then be used to increase classification performances. A key insight of our approach is that the synthetically generated images should be similar to <b>real</b> <b>images,</b> {{not in terms of}} image quality, but rather in terms of features used during the detector training. We show in the context of drone, plane, and car detection that using such synthetically generated images yields significantly better performances than simply perturbing <b>real</b> <b>images</b> or even synthesizing images in such way that they look very realistic, as is often done when only limited amounts of training data are available...|$|R
40|$|Abstract—Computer-generated (CG) {{images have}} {{achieved}} {{high levels of}} realism. This realism, however, comes {{at the cost of}} long and expensive manual modeling, and often humans can still distinguish between CG and <b>real</b> <b>images.</b> We introduce a new data-driven approach for rendering realistic imagery that uses a large collection of photographs gathered from online repositories. Given a CG image, we retrieve a small number of <b>real</b> <b>images</b> with similar global structure. We identify corresponding regions between the CG and <b>real</b> <b>images</b> using a mean-shift cosegmentation algorithm. The user can then automatically transfer color, tone, and texture from matching regions to the CG image. Our system only uses image processing operations and does not require a 3 D model of the scene, making it fast and easy to integrate into digital content creation workflows. Results of a user study show that our hybrid images appear more realistic than the originals. Index Terms—Image enhancement, image databases, image-based rendering. ...|$|R
40|$|The present Master Thesis {{describes}} a new Pose Estimation method based on Convolutional Neural Networks (CNN). This method divides the three-dimensional space in several regions and, given an input image, returns {{the region where}} the camera is located. The {{first step is to}} create synthetic images of the object simulating a camera located at di↵erent points around it. The CNN is pre-trained with these thousands of synthetic images of the object model. Then, we compute the pose of the object in hundreds of <b>real</b> <b>images,</b> and apply transfer learning with these labeled <b>real</b> <b>images</b> over the existing CNN, in order to refine the weights of the neurons and improve the network behaviour against <b>real</b> input <b>images.</b> Along with this deep learning approach, other techniques have been used trying {{to improve the quality of}} the results, such as the classical sliding window or a more recent class-generic object detector called objectness. It is tested with a 2 D-model in order to ease the labeling process of the <b>real</b> <b>images.</b> This document outlines all the steps followed to create and test the method, and finally compares it against a state-of-the-art method at di↵erent scales and levels of blurring...|$|R
