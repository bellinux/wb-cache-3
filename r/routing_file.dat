9|30|Public
40|$|Self-stabilization is a {{theoretical}} framework of non-masking fault-tolerance for distributed networks. A self-stabilizing system is capable of tolerating any unexpected transient fault without outside intervention and, regardless of the initial state, it can converge to a legitimate global state, a predefined vector of local states, in finite time. Self-stabilization has rendered a good problem solving paradigm of networks over the last decade. In this report, we survey the self-stabilizing solutions for various network optimization problems such as network flow, load balancing, load and resource distribution, <b>routing,</b> <b>file</b> distribution, shortest paths etc. The report also summarizes some recent works presenting how the convergence of a self-stabilizing distributed network can be modelled as a convex optimization problem with the exploitation of an analogy between self-stabilizing systems and stable feedback systems. The works pertaining to gradient adaptation of self-stabilizing system are also presented...|$|E
40|$|Networking {{encompasses}} {{a variety of}} tasks related to the communication of information on networks; it has a substantial economic and societal impact on {{a broad range of}} areas including transportation systems, wired and wireless communications and a range of Internet applications. As transportation and communication networks become increasingly more complex, the ever increasing demand for congestion control, higher traffic capacity, quality of service, robustness and reduced energy consumption requires new tools and methods to meet these conflicting requirements. The new methodology should serve for gaining better understanding of the properties of networking systems at the macroscopic level, {{as well as for the}} development of new principled optimization and management algorithms at the microscopic level. Methods of statistical physics seem best placed to provide new approaches as they have been developed specifically to deal with nonlinear large-scale systems. This review aims at presenting an overview of tools and methods that have been developed within the statistical physics community and that can be readily applied to address the emerging problems in networking. These include diffusion processes, methods from disordered systems and polymer physics, probabilistic inference, which have direct relevance to network <b>routing,</b> <b>file</b> and frequency distribution, the exploration of network structures and vulnerability, and various other practical networking applications...|$|E
40|$|Peer-to-Peer系统（简称PZP系统）以其分布式管理、高效路由、容错性强和可扩展等优秀性能给信息社会带来一股新的活力。本文对PZP系统的研究和发展现状做出比较全面的总结。尤其对其中四种主流的PZP文件存储系统（包括无结构／结构化的PZP文件存储系统）的路由策略、文件存储策略以及负载均衡策略进行系统分析。根据对目前的PZP文件存储系统的优缺点分析和未来数字化部队信息系统的需求，我们提出并实现一种基于双层ID空间的PZP文件存储系统DISPFS（Double ID Space based PZP File System）。本文详细介绍了DISPFS的系统设计、系统维护和负载均衡策略。DISPFS的创新点在于：虚拟存储节点和虚拟存储节点内部负载均衡策略的设计能动态地根据每个参与节点的具体存储容量、网络处理能力等情况做出合理、快速的负载均衡调整，从而有效地提高系统利用率和文件插入成功率。为了准确检测DISPFS的系统性能，如系统利用率、文件插入成功率和系统在很大的存储压力下的负载均衡性能，我们采用了大规模节点（节点个数为 1 护数量级）的模拟测试。试验结果显示了DISPFS的高效、可扩展以及负载均衡性能优良的特性。继而，本文探讨了DISPFS在未来数字化部队信息系统中的应用层次、应用优势以及所需要的改进。最后，对全文工作做了总结，并对DISPFS系统做出展望。Peer-to-Peer (P 2 P) {{systems have}} become popular for their {{excellent}} performances, such as decentralization, efficiency, fault-tolerance and scalability. This paper gives a comprehensive {{research on the}} development of current P 2 P systems, especially those of <b>routing,</b> <b>file</b> storage and load balancing mechanisms in four typical P 2 P file storage systems. According to the requirement of future digital forces and analyses of advantages and disadvantages in those typical P 2 P file storage systems, we design and implement DISPFS (Double ID Space based P 2 P File System). There is a detail description of system design, system maintenance and load balancing mechanism. Our contribution lies in the design of virtual storage node and corresponding load balancing mechanisms, which increases system utility through efficient load balancing matching with concrete conditions of each node. We also design large-scale experiments in order to give an accurate evaluation on the performances of DISPFS. The experimental results show that DISPFS is efficient, scalable and owns good load balancing performance. Additionally, discussions of the application of DISPFS in digital forces, including its application layer, application advantages and required improvements are presented. Lastly, there is a complete summary on the work of this paper and a discussion of our future work...|$|E
25|$|Copper {{cladding}} can be cut, <b>routed,</b> sawed, <b>filed,</b> drilled, screwed, welded, and curved to form complex shapes. A {{variety of}} finishes and colors are available.|$|R
50|$|SPEF is {{extracted}} after routing in Place and route stage. This helps in accurate calculation of IR-drop analysis and other analysis after <b>routing.</b> This <b>file</b> contains the R and C parameters {{depending on the}} placement of our tile/block and the routing among the placed cells.|$|R
40|$|We {{present a}} P 2 P filesharing {{system that allows}} {{redundant}} storage of shared files {{in a way that}} no participating server ever stores data that could compromise its operator. Instead, only fragments that do not contain any information about the original file in the information theoretic sense are uploaded. Reconstruction of a file requires all fragments it has been decomposed into. By this, in conjunction with other cryptographic methods, we yield significant legal advantages for server operators, as well as censorship-resistance, anonymity, secure <b>routing,</b> authenticated <b>file</b> update and integrity checks...|$|R
40|$|Abstract—As data {{progressively}} grows within data centers, {{the cloud}} storage systems continuously face challenges in saving storage capacity and providing capabilities necessary to move big data within an acceptable time frame. In this paper, we present the Boafft, a cloud storage system with distributed deduplication. The Boafft achieves scalable throughput and capacity using multiple data servers to deduplicate data in parallel, with a minimal loss of deduplication ratio. Firstly, the Boafft uses an efficient data routing algorithm {{based on data}} similarity that reduces the network overhead by quickly identifying the storage location. Secondly, the Boafft maintains an in-memory similarity indexing in each data server that helps avoid {{a large number of}} random disk reads and writes, which in turn accelerates local data deduplication. Thirdly, the Boafft constructs hot fingerprint cache in each data server based on access frequency, so as to improve the data deduplication ratio. Our comparative analysis with EMC’s stateful routing algorithm reveals that the Boafft can provide a comparatively high deduplication ratio with a low network bandwidth overhead. Moreover, the Boafft makes better usage of the storage space, with higher read/write bandwidth and good load balance. Index Terms—Big data, cloud storage, data deduplication, data <b>routing,</b> <b>file</b> system. F...|$|E
40|$|Efficient {{networking}} has {{a substantial}} economic and societal impact {{in a broad}} range of areas including transportation systems, wired and wireless communications and a range of Internet applications. As transportation and communication networks become increasingly more complex, the ever increasing demand for congestion control, higher traffic capacity, quality of service, robustness and reduced energy consumption require new tools and methods to meet these conflicting requirements. The new methodology should serve for gaining better understanding of the properties of networking systems at the macroscopic level, {{as well as for the}} development of new principled optimization and management algorithms at the microscopic level. Methods of statistical physics seem best placed to provide new approaches as they have been developed specifically to deal with non-linear large scale systems. This paper aims at presenting an overview of tools and methods that have been developed within the statistical physics community and that can be readily applied to address the emerging problems in networking. These include diffusion processes, methods from disordered systems and polymer physics, probabilistic inference, which have direct relevance to network <b>routing,</b> <b>file</b> and frequency distribution, the exploration of network structures and vulnerability, and various other practical networking applications. Comment: (Review article) 71 pages, 14 figure...|$|E
40|$|Scheduling {{is one of}} the important. {{parts of}} {{manufacturing}} and engineering. There are a lot of factors should be considered before taking the best scheduling approaches. The Production System Laboratory of UAJY has a long-term research project about the effect of product structure complexity, process routing complexity, and setup time-run time ratio on makespan minimization in multilevel product scheduling. The writer takes a part of this long-term research project. The writer concerns to product structure which is limited on	 3 	levels and maximum	 3 	parts in one level. The objective of this research is to define the optimum lot size by evaluating the effect of product structure complexity. There are 	 6 	possible combinations of product structure which have been generated. The <b>routing</b> <b>file</b> is generated to shows step-by-step set of instructions describing how the product is made. The routing files generated to create 5 replications for each product structure, all routing files have the same operations and work centers, the difference is on setup time and run time according to the random number generation. Makespan is found by Gantt chart simulation using Microsoft Excel program. There are several lot size examined, they are	 4,	 8,	 16,	and	 32. 	Setup-run time ratio is the function of lot setup time divided by lot size times unit run time. Setup-run time ratio represents optimum lot size in ANOVA test. Based on Gantt chart simulation, every case has its own optimum lot size; number of optimum lot size is randomly distributed. Most of optimum lot size is defined when lot size	=	 8 	or lot size	=	 16. 	Based on ANOVA Single Factor result, writer concludes that there is no significant difference between variation of product structure and optimum lot size. ...|$|E
40|$|This paper present s and evaluatj t hest] 20) {{management}} and caching in PAST, a large-scale peer-t 8 fi eer persistfi t stsist utsis y. PAST {{is based on}} a self-organizing, Intfi] 08) based overlaynet work of st 30 j 2 nodest hat cooperat] ely <b>rout</b> <b>file</b> queries, st 3 j mult 0]) replicas of files, and cache addit 8 fiF$ copies of popular files. In tfi PASTsyst$ 8 st 38 $$ nodes and files are each assigned uniformly dist) (fiFj) identenfi 3 (and replicas of a file are stO 3) at nodes whose identenfi mat hes most closelyt he file's identenfi) This st$ 288 fiFjO assignment of filest stsfi] 8 nodes approximat]O balancest he number of filesstsfi] on each node. However, non-uniform st] 23 O nodecapacitFj and file sizes require more explicit sticit load balancing t permit graceful behavior under high global st]$) 0 ut$ lizat 08 fi likewise, non-uniform popularit y of files requires cachingt o minimize fet hdist 0 Ofi andt o balanceta query load. We present and evaluat PAST, wit an emphasis on it st](80 {{management and}} cachingsyst 3 (ExtjjOO et] 00 j driven experiment s showt hat t hesystj minimizes fet h dist]($fi t hat it balancest he query load for popular files, andt hat it displays graceful degradat] 8 of performance as the global storage utilization increases beyond 95 %...|$|R
40|$|Multiple paths can {{be created}} between source and {{destination}} nodes in a network by multi-path <b>routing.</b> If the <b>file</b> contents is sent in a deterministic way the adversary might acquire the complete information hence {{it would lead to}} loss of data so we divide the file into N packets and traverse them through various random paths. This can be implemented using the following module...|$|R
40|$|In {{this paper}} we {{evaluate}} {{a method of}} using interleaved spanning trees to compose a resilient, high performance overlay mesh. Though spanning trees of arbitrary type {{could be used to}} construct an overlay mesh, we focus on a distributed algorithm that computes k minimum spanning trees on an arbitrary graph. The principal motivation behind this strategy is to provide applications with a k-redundant, high quality mesh suitable for demanding applications like A/V broadcast, video conferencing, data collection, multi-path <b>routing,</b> and <b>file</b> mirroring/transfer. We elaborate details of k-MST, pointing out advantages and potential problem points of the protocol, and then analyze its performance using a variety of metrics with simulation as well as a functional PlanetLab implementation...|$|R
40|$|New {{uniqueness}} constraints for database {{tables and}} validations for corresponding models; new RSpec tests; several bug fixes. This release implements several value and uniqueness constraints on database tables aimed at {{ensuring that the}} BETYdb database will not contain multiple rows describing the same citation, site, species, treatment, or other entity. In conjunction with the database changes, new model validations {{have been added to}} several of the models so that potentially invalid database insertions or updates are caught at the Rails level before the insertion or update is attempted on the database. Second, several bugs existed that prevented access to many pages of the site [...] especially pages for editing database entities. Many of these were introduced by changes to the <b>routing</b> <b>file</b> that eliminated most wildcard routes. These bugs have now been fixed and several new tests have been added to ensure these bugs don't re-appear. Changes Pertinent to PEcAn Users Administrators need to do a database migration. See "Database Changes" below. Summary of Changes New Features New Validations to Prevent Duplicate Rows and Missing Data Bug Fixes Many pages that were previously inaccessible are once again reachable. Prior to this update, attempting to visit these pages yielded the following error: The page you were looking for doesn't exist. You may have mistyped the address or the page may have moved. Affected pages included (for example) the Covariate editing page the Model editing page the Modeltype editing page the Species editing page the Traits editing page Steps Needed for Upgrade Database Changes Administrators need to do database migrations! One migration has been added that new value and uniqueness constraints and also adds some convenience functions for implementing these constraints. The database version for this release is 20150202220519. Status of RSpec Tests All tests continue to pass when run in the default environment and can be run using the command bundle exec rspec Every effort has been made to make this command idempotent: You should be able to run the tests multiple times without reloading the test fixtures between runs. Complete details for running the rspec tests are on the updated Wiki page at [URL]...|$|E
40|$|Overlay {{networks}} {{have been used}} for adding and enhancing functionality to the end-users without requiring modifications in the Internet core mechanisms. Overlay {{networks have}} been used for a variety of popular applications including <b>routing,</b> <b>file</b> sharing, content distribution, and server deployment. Previous work has focused on devising practical neighbor selection heuristics under the assumption that users conform to a specific wiring protocol. This is not a valid assumption in highly decentralized systems like overlay networks. Overlay users may act selfishly and deviate from the default wiring protocols by utilizing knowledge they have about the network when selecting neighbors to improve the performance they receive from the overlay. This thesis goes against the conventional thinking that overlay users conform to a specific protocol. The contributions of this thesis are threefold. It provides a systematic evaluation of the design space of selfish neighbor selection strategies in real overlays, evaluates the performance of overlay networks that consist of users that select their neighbors selfishly, and examines the implications of selfish neighbor and server selection to overlay protocol design and service provisioning respectively. This thesis develops a game-theoretic framework that provides a unified approach to modeling Selfish Neighbor Selection (SNS) wiring procedures on behalf of selfish users. The model is general, and takes into consideration costs reflecting network latency and user preference profiles, the inherent directionality in overlay maintenance protocols, and connectivity constraints imposed on the system designer. Within this framework the notion of user’s "best response" wiring strategy is formalized as a k-median problem on asymmetric distance and is used to obtain overlay structures in which no node can re-wire to improve the performance it receives from the overlay. Evaluation results presented in this thesis indicate that selfish users can reap substantial performance benefits when connecting to overlay networks composed of non-selfish users. In addition, in overlays that are dominated by selfish users, the resulting stable wirings are optimized to such great extent that even non-selfish newcomers can extract near-optimal performance through naïve wiring strategies. To capitalize on the performance advantages of optimal neighbor selection strategies and the emergent global wirings that result, this thesis presents EGOIST: an SNS-inspired overlay network creation and maintenance routing system. Through an extensive measurement study on the deployed prototype, results presented in this thesis show that EGOIST’s neighbor selection primitives outperform existing heuristics on a variety of performance metrics, including delay, available bandwidth, and node utilization. Moreover, these results demonstrate that EGOIST is competitive with an optimal but unscalable full-mesh approach, remains highly effective under significant churn, is robust to cheating, and incurs minimal overheads. This thesis also studies selfish neighbor selection strategies for swarming applications. The main focus is on n-way broadcast applications where each of n overlay user wants to push its own distinct file to all other destinations as well as download their respective data files. Results presented in this thesis demonstrate that the performance of our swarming protocol for n-way broadcast on top of overlays of selfish users is far superior than the performance on top of existing overlays. In the context of service provisioning, this thesis examines the use of distributed approaches that enable a provider to determine the number and location of servers for optimal delivery of content or services to its selfish end-users. To leverage recent advances in virtualization technologies, this thesis develops and evaluates a distributed protocol to migrate servers based on end-users demand and only on local topological knowledge. Results under a range of network topologies and workloads suggest that the performance of the distributed deployment is comparable to that of the optimal but unscalable centralized deployment. National Science Foundation; Telefónica Research-Barcelona; the European Commissio...|$|E
40|$|This thesis {{presents}} {{new techniques}} that exploit system diversity {{within a particular}} class of peer-to-peer publish-subscribe systems. We show that by directly addressing interest and network diversity as a first class design principle, the scale and performance of such systems can be improved. This thesis makes four major contributions. Firstly, we present Confluence, a system that significantly reduces the time to transfer large files from multiple publishers (sources) to a single subscriber (sink node) {{as compared to the}} direct transfer strategy. Confluence lets scientists rapidly collect logs from either multiple PlanetLab hosts or multi-site cloud computing infrastructures. It uses a novel source- 2 -source (s 2 s) overlay to speed up the transfer of file blocks towards the sink. Intuitively, the s 2 s overlay facilitates a source node (with a congested path to the sink) to utilize other source nodes as intermediaries for <b>routing</b> <b>file</b> blocks to the sink. Concretely, our approach first poses the problem as a variant of flow optimization among the source nodes. This captures the spatial diversity in bandwidth. We provide a theoretically optimal solution to this problem. Next, we augment this static solution with on-the-fly recomputation. This helps us exploit temporal diversity in bandwidth. Using Confluence, with 25 source nodes in a PlanetLab-like environment, 80 % of nodes see a reduction in transfer time of at least 20 % over the direct transfer strategy. Our second system, Rappel, is a peer-to-peer delivery mechanism for RSS feeds. Rappel is the first subject-based publish-subscribe system to be noiseless, be truly peer-to-peer, and perform soft real-time dissemination of messages. Noiselessness implies that a subscriber never receives messages for feeds that it is not subscribed to, and is important because it improves fairness: the load imposed by the system on each participating node is proportional to the node's demands from the system. Rappel exploits interest and network diversity via the use of periodic utility computations, wherein the utility of a peer (``friend'') is derived using Bloom filters and network coordinates. Bloom filters succinctly capture the subscription interest of a node, whereas network coordinates help capture the network location of a node. Via push-pull gossip, a node seeks to find a set of friends that provide good subscription coverage while being in close network proximity. By having peers in close network proximity, messages are disseminated with very low latency. The third contribution of this thesis is the Realistic Application-level Network Simulation (RANS) framework. This is motivated by two observations. Firstly, system deployment is a labor-intensive exercise, and thus, limited in scale. For instance, PlanetLab, a large wide-area experimental network testbed, usually only has about 400 accessible nodes at any given moment. Secondly, due to the presence of extrinsic interferences, experiments are not replayable. Simulations provide an acceptable solution to these problems, however, they often fail to mimic realistic network conditions. In contrast to these two approaches, the RANS framework provides a modular programming interface that can be leveraged to produce both realistic simulation results and a ready-to-deploy sockets binary. Our main contributions are in (1) developing a realistic and reusable selective granularity discrete-event simulator for PlanetLab, and (2) showing that the results generated by the RANS simulation framework closely match the results obtained by performing the same experiments on a PlanetLab deployment. Fourthly, the systems described in this thesis have been comprehensively evaluated via both PlanetLab deployment and simulation. Our deployments used up to 400 PlanetLab servers world-wide. Our largest simulations model 10, 000 nodes. Our experimental methodology is constructed using an extensive amount of real-world traces. For instance, to evaluate Rappel using realistic user subscriptions, we gathered the subscription profiles of 1. 8 million LiveJournal users over six months. The evaluation presented in this thesis also makes use of the following previously collected traces: Internet topology, end-to-end latency fluctuations between PlanetLab nodes, bandwidth availability between PlanetLab nodes, and end user churn observed in peer-to-peer file sharing applications. unpublishedis peer reviewe...|$|E
40|$|ABSTRACT We {{study the}} {{performance}} of a simple greedy on-linealgorithm for <b>routing</b> large <b>file</b> transfers in a network. The goal of the algorithm is to minimize network con-gestion. We show that the competitive ratio of the greedy algorithm is O Γ L min ΦΛ *, IΨ log(nI) Δ where Lis the length of the longest path assigned to a file transfer, Λ * is the ratio of the maximum to minimum filelength, I is a lower bound on the overlap of optimalpaths, and n is the number of nodes in the network. We also show that this upper bound is close to being tight when L is small by proving that the competitiveratio is ΩΓ L + log Γ nL- LΔΔ...|$|R
50|$|Napster was {{the first}} peer to peer service {{to be subject to}} {{copyright}} infringement litigation. In this case, the issue was regarding the infringement of copyrights through the ‘Music Share’ software of Napster. Whenever, this software was used on a computer system, it would collect information about the MP3 files stored on the computer and send it to Napster servers. Based on this information, the Napster created a centralised index of files available for download on the Napster network. When someone wanted to download that file, the Music Share software would use the Napster index to locate the user who already had that file on their system and then connect the two users directly to facilitate the download of the MP3 <b>file,</b> without <b>routing</b> the <b>file</b> through Napster’s servers.|$|R
40|$|DSP {{architectures}} often feature multiple register files with sparse {{connections to}} a large set of ALUs. For such DSPs, traditional register allocation algorithms suffer {{from a lot of}} problems, including a lack of retargetability and phase-ordering problems. This paper studies alternative register allocation techniques based on placement and <b>routing.</b> Different register <b>file</b> models are studied and evaluated on a state-of-the art coarse-grained reconfigurable array DSP, together with a new post-pass register allocator for rotating register files...|$|R
5000|$|Potential Trouble Sources are {{spared the}} Dead File if they handle or {{disconnect}} from the SP."A potential trouble source order is {{not given the}} entheta DEAD <b>FILE</b> <b>routing</b> unless the person refuses to disconnect or handle. At this time the person's name is put on a despatch stamped with the entheta stamp and is routed to CF (central files), etc., as above. Sometimes a PTS refusing to disconnect is declared suppressive and {{in such a case}} it is handled as an SP above." ...|$|R
40|$|Application servers {{such as a}} {{mail server}} in the {{integrated}} network are required high availability because the server failure stops all systems in the network. Adding redundant network interfaces and service program, our application server keeps their service when a server get into troubled. We implement these approaches on our network and evaluate its efficacy under real network system operation. In consequence, <b>routing</b> schemes for <b>file</b> servers can reduce roundabout routing, and high availability application servers have been continued minimum level services for users in the network. リサーチレポート（北陸先端科学技術大学院大学情報科学研究科...|$|R
50|$|Tumbleweed {{products}} {{were used to}} block security threats, protect information, and conduct business online. Tumbleweed provided solutions for inbound and outbound email protection, secure <b>file</b> <b>routing,</b> and identity validation that allow organizations to conduct business over the Internet. Tumbleweed offered these solutions in three product suites: MailGate, SecureTransport, and Validation Authority. MailGate provides protection against spam, viruses, and attacks, and enables policy-based message filtering, encryption, and routing. SecureTransport enables customers to safely exchange large files and transactions without proprietary software. Validation Authority determines the validity of digital certificates.|$|R
40|$|In {{a packet}} network, the terms "bandwidth " or "throughput" often {{characterize}} {{the amount of}} data that the network can transfer per unit of time. Bandwidth estimation is of interest to users wishing to optimize end-to-end transport performance, overlay network <b>routing,</b> and peer-to-peer <b>file</b> distribution. Techniques for accurate bandwidth estimation are also important for traffic engineering and capacity planning support. Existing bandwidth estimation tools measure {{one or more of}} three related metrics: capacity, available bandwidth, and bulk transfer capacity (BTC). Currently available bandwidth estimation tools employ a variety of strategies to measure these metrics. In this survey we review the recent bandwidth estimation literature focusing on underlying techniques and methodologies as well as open source bandwidth measurement tools...|$|R
5000|$|The /WEB-INF {{directory}} in the WAR file {{contains a}} file named web.xml which defines {{the structure of}} the web application. If the web application is only serving JSP files, the web.xml file is not strictly necessary. If the web application uses servlets, then the servlet container uses web.xml to ascertain to which servlet a URL request will be <b>routed.</b> The web.xml <b>file</b> is also used to define context variables which can be referenced within the servlets and it is used to define environmental dependencies which the deployer is expected to set up. An example of this is a dependency on a mail session used to send email. The servlet container is responsible for providing this service.|$|R
40|$|Electronic Router (E-Router) is an {{application}} program for routing documents among the cognizant individuals {{in a government}} agency or other organization. E-Router supplants a prior 14 NASA Tech Briefs, May 2005 system in which paper documents were routed physically in packages by use of paper slips, packages could be lost, routing times were unacceptably long, tracking of packages was difficult, {{and there was a}} need for much photocopying. E-Router enables a user to create a digital package to be routed. Input accepted by E-Router includes the title of the package, the person(s) to whom the package is to be <b>routed,</b> attached <b>files,</b> and comments to reviewers. Electronic mail is used to notify reviewers of needed actions. The creator of the package can, at any time, see the status of the package in the routing structure. At the end of the routing process, E-Router keeps a record of the package and of approvals and/or concurrences of the reviewers. There are commercial programs that perform the general functions of E-Router, but they are more complicated. E-Router is Web-based, easy to use, and does not require the installation or use of client software...|$|R
40|$|Abstract — In {{a packet}} network, the terms “bandwidth” or “throughput ” often {{characterize}} {{the amount of}} data that the network can transfer per unit of time. Bandwidth estimation is of interest to users wishing to optimize end-to-end transport performance, overlay network <b>routing,</b> and peer-to-peer <b>file</b> distribution. Techniques for accurate bandwidth estimation are also important for traffic engineering and capacity planning support. Existing bandwidth estimation tools measure {{one or more of}} three related metrics: capacity, available bandwidth, and bulk transfer capacity (BTC). Currently available bandwidth estimation tools employ a variety of strategies to measure these metrics. In this survey we review the recent bandwidth estimation literature focusing on underlying techniques and methodologies as well as open source bandwidth measurement tools. I...|$|R
40|$|International audienceThe {{increase}} in the variety and capability of mobile communications devices carried by people today {{has made it possible}} to envision a new class of networks called Pocket Switched Networks (PSNs). In a PSN, because the nodes are constantly moving and their communication abilities are limited, the design of networking protocols and applications is challenging. This paper presents a new communications scheme for PSN, called Osmosis, based on the biological phenomenon. We show how this scheme can be applied to file sharing. This scheme uses epidemic <b>routing</b> to perform <b>file</b> lookup and achieves controlled flooding for file transfer. The flooding requires very little state information, which is collected during the lookup. This paper analyzes the performance of Osmosis in simulation studies based on real mobility traces...|$|R
40|$|Abstract — A {{foundational}} issue underlying many {{overlay network}} applications ranging from <b>routing</b> to peer-to-peer <b>file</b> sharing {{is that of}} the network formation, i. e., folding new arrivals into an existing overlay, and re-wiring to cope with changing network conditions. Previous work has considered the problem from two perspectives: devising practical heuristics for the case of cooperative peers, and performing game theoretic analysis for the case of selfish peers. In our work, we unify the aforementioned thrusts by defining and studying the Selfish Neighbor Selection (SNS) game and its application to overlay routing. At the heart of SNS stands the restriction that peers are allowed up to a certain number of neighbors. This makes SNS substantially different from existing network formation games that impose no bounds on peer degrees. Having bounded degrees has important practical consequences as it permits the creation of overlay structures tha...|$|R
40|$|Abstract Peer-to-peer {{computing}} is a {{term used}} to describe the current trend toward utilizing the full resources available within a widely distributed network of nodes with increasing computational power. These resources include the exchange of information, processing cycles, cache storage, and disk storage for <b>files.</b> <b>Routing,</b> locating and transmitting of resources, becomes an extremely important issue then. First steps toward robust peer-to-peer systems include extensions of centralized models of resource sharing (e. g. Napster), but more recent attempts acknowledge the limitations of such systems and also address issues of performance, reliability, scalability, maintenance, and usability. We focus on the problem of sharing data and in the context of these issues offer a survey of the following systems: Napster, Gnutella, TRIAD, Pastry, Plaxton, Tapestry, Chord, and CAN. The upshot is that we isolate what we see as both the crucial issues and solutions to the challenge of routing in the peer-to-peer environment, give a comparative summary for all systems. Finally based on framework and analysis, we propose some further questions and potential approaches for future investigation. Keywords Peer-to-peer, Locating, Routing, Data sharing 1...|$|R
40|$|ABSTRACT A {{foundational}} issue underlying many {{overlay network}} ap-plications ranging from <b>routing</b> to peer-to-peer <b>file</b> sharing {{is that of}} connectivity management, i. e., folding new ar-rivals into an existing overlay, and re-wiring to cope with changing network conditions. Previous work has consid-ered the problem from two perspectives: devising practical heuristics for specific applications designed to work well inreal deployments, and providing abstractions for the underlying problem that are analytically tractable, especially viagame-theoretic analysis. In this paper, we unify these two thrusts by using insights gleaned from novel, realistic theo-retic models {{in the design of}} Egoist- a distributed overlayrouting system that we implemented, deployed, and evaluated on PlanetLab. Using extensive measurements of pathsbetween nodes, we demonstrate that Egoist's neighbor se-lection primitives significantly outperform existing heuristics on a variety of performance metrics, including delay,available bandwidth, and node utilization. Moreover, we demonstrate that Egoist is competitive with an optimal, butunscalable full-mesh approach, remains highly effective under significant churn, is robust to cheating, and incurs min-imal overhead. Finally, we use a multiplayer peer-to-peer game to demonstrate the value of Egoist to end-user appli-cations...|$|R
40|$|The ACPD flow {{is vital}} for {{accelerated}} mixed-signal layout design. This paper will provide the flow details, tools, and the steps involved. Automatic layout generation and connectivity extraction using standard cells for digital blocks will be explained. Automatic placement is done using the Virtuoso Custom Placer(VCP. Advanced pcells are utilized for layout generation of the analog blocks. Virtuoso XL(VXL) features such as Show Incomplete Nets and incremental updates will be discussed. Manual area based placement is done for the analog blocks. The analog and digital blocks are routed at the device level using the Virtuoso Custom Router(VCR). Placement of these routed blocks is done at the top level in VXL. Critical Nets are pre-routed in VXL using the Wire Editor tool. Setup of the Wire Editor and its features will be discussed. Abstract views will be created for these layout blocks. The Cadence Chip Assembly Router(CCAR) is utilized for block level <b>routing.</b> The. do <b>file</b> setup and commands will be explained. Once the routing is completed the layout design is accomplished. The design is then imported back into VXL for physical verification. 1...|$|R
40|$|Recently {{scale of}} LAN systems is rapidly increasing, and {{integrated}} network systems {{are required to}} improve usability and reduce maintenance cost. However there are many problems to construct the integrated networks such as network design, network connection for file servers and designing application servers. This paper addresses schemes for integrated network systems based on a real integrated network in our university. Network designing policy, routing schemes for central huge file servers and high availability schemes for application servers are discussed. Our proposal for network design is construction with two different generation network facilities to avoid hardware and software failure. For file servers which has many network interface to improve bandwidth, many routing algorithms are standardized to select network interface for packets from file servers, {{but there are no}} effective implementation for client which throw packets toward file servers. We propose network interface selecting method that looks up optimal interface in NIS maps and set as "automount" arguments. We implement these approaches on our network and evaluate its efficacy under real network system operation. In consequence, <b>routing</b> schemes for <b>file</b> servers can reduce roundabout routing. リサーチレポート（北陸先端科学技術大学院大学情報科学研究科...|$|R
40|$|A {{foundational}} issue underlying many {{overlay network}} applications ranging from <b>routing</b> to peer-to-peer <b>file</b> sharing {{is that of}} connectivity management, i. e., folding new arrivals into an existing overlay, and rewiring to cope with changing network conditions. Previous work has considered the problem from two perspectives: devising practical heuristics for specific applications designed to work well in real deployments, and providing abstractions for the underlying problem that are analytically tractable, especially via game-theoretic analysis. In this paper, we unify these two thrusts by using insights gleaned from novel, realistic theoretic models {{in the design of}} Egoist – a distributed overlay routing system that we implemented, deployed, and evaluated on PlanetLab. Using extensive measurements of paths between nodes, we demonstrate that Egoist’s neighbor selection primitives significantly outperform existing heuristics on a variety of performance metrics, including delay, available bandwidth, and node utilization. Moreover, we demonstrate that Egoist is competitive with an optimal, but unscalable full-mesh approach, remains highly effective under significant churn, is robust to cheating, and incurs minimal overhead. Finally, we use a multiplayer peer-to-peer game to demonstrate the value of Egoist to end-user applications. This technical report supersedes BUCS-TR- 2007 - 013. NSF (CISE/CSR 0720604, ENG/EFRI 0735974, CNS/ITR 0205294, CISE/EIA RI 0202067, CAREER Grant 0446522); European Commission (RIDS- 011923...|$|R
40|$|An {{extensible}} {{file system}} raises {{the level of}} file abstraction which provides benefits to both the end-user and programmer. The Modify-on-Access file system provides safe and simple user-defined extensibility through transformations, which are modular operations on input and output streams. A user inserts transformations into input and output streams, which modify the data accessed. Untrusted transformations execute in user space for safety. Performance of user-level transformations, although much slower than that of in-kernel transformations, is comparable to other user-level approaches, such as pipes. This paper presents several interesting user-level transformations. For example, the command transformation executes a shell script whose input and output are <b>routed</b> from/to the <b>file</b> system. A file guarded by the ftp transformation is a “mount ” point to an FTP server. The php transformation creates dynamic documents from PHP source when read. A file written to a sound device that is guarded by the mp 3 transformation is decoded on the fly, in the file system, before reaching the sound device. Mona is a novel approach to file system extensibility that provides heretofore unseen flexibility. Mona is finegrained: a user defines actions on a per-file basis. It is modular: transformations can be stacked upon one another. Mona supports two classes of transformations: kernel-resident and user-level. ...|$|R
40|$|An {{increasing}} number of consumer products include user interfaces that rely on touch input. While digital fabrication techniques such as 3 D printing {{make it easier to}} prototype the shape of custom devices, adding interactivity to such prototypes remains a challenge for many designers. We introduce Midas, a software and hardware toolkit to support the design, fabrication, and programming of flexible capacitive touch sensors for interactive objects. With Midas, designers first define the desired shape, layout, and type of touch sensitive areas, as well as routing obstacles, in a sensor editor. From this high-level specification, Midas automatically generates layout files with appropriate sensor pads and <b>routed</b> connections. These <b>files</b> are then used to fabricate sensors using digital fabrication processes, e. g., vinyl cutters and conductive ink printers. Using step-by-step assembly instructions generated by Midas, designers connect these sensors to the Midas microcontroller, which detects touch events. Once the prototype is assembled, designers can define interactivity for their sensors: Midas supports both record-and-replay actions for controlling existing local applications and WebSocket-based event output for controlling novel or remote applications. In a first-use study with three participants, users successfully prototyped media players. We also demonstrate how Midas can be used to create a number of touch-sensitive interfaces. ACM Classification...|$|R
40|$|VPR (Versatile Place and Route) is an FPGA {{placement}} and routing tool. VPR has four required and many optional parameters; it is invoked by typing:> vpr netlist. net architecture. xml placement. p routing. r [-options] Netlist. net is the netlist describing the circuit {{to be placed}} and/or routed, while architecture. xml describes {{the architecture of the}} FPGA in which the circuit is to be realized. If VPR is placing a circuit, the final placement will be written to placement. p; if VPR is routing a previously placed circuit, the placement is read from placement. p. The final routing of a circuit is written to <b>file</b> <b>routing.</b> r. The format of each of these files is described in Section 0. VPR can be run in one of two basic modes. In its default mode, VPR places a circuit on an FPGA and then repeatedly attempts to route it in order to find the minimum number of tracks required by the specified FPGA architecture to route this circuit. If a routing is unsuccessful, VPR increases the number of tracks in each routing channel and tries again; if a routing is successful, VPR decreases the number of tracks before trying to route it again. Once the minimum number of tracks required to route the circuit is found, VPR exits. The other mode of VPR is invoked when a user specifies a specific channel width for routing. In this case, VPR places a circuit and attempts to route it only once, with the specified channel width. If the circui...|$|R
40|$|A {{introductory}} issue essential many superimpose network applications {{ranging from}} <b>routing</b> to peer-to-peer <b>file</b> distribution {{is that of}} the network configuration, i. e., flop new arrivals into an presented overlie, and re-wiring to survive with varying network environments. Earlier effort has measured the crisis from two perspectives: devising levelheaded heuristics for the crate of supportive peers, and performing game theoretic analysis for the crate of egotistic peers. As a solution, we amalgamate the above mentioned thrusts by important and studying the Selfish Neighbor Selection (SNS) game and its purpose to superimpose routing. At the spirit of SNS stands the constraint that peers are permissible up to a convinced number of neighbors. This makes SNS considerably unusual from obtainable network structure games that force no boundaries on peer degrees. Having surrounded degrees has imperative realistic penalty as it permits the formation of superimpose structures that entail O(n) in its place of O(n 2) link monitoring transparency. We demonstrate that a node’s finest reaction cabling policy amounts to solving a k-means dilemma on asymmetric distance. Finest reaction wirings have extensive realistic value as they allow egotistic nodes to collect sizeable presentation profit when linking to overlays of non-selfish nodes. A extra difficult upshot is that smooth non-selfish nodes can profit from the survival of a few egotistic nodes while the final, by way of their local optimizations, generate a extremely optimized spine, winning which even easy heuristic wirings defer high-quality recital. To take advantage of on the above properties we intend, erect and position, EGOIST, and SNS-inspired model superimpose routing system. We demonstrate that EGOIST outperforms obtainable heuristic superimpose on a diversity of performance metrics, with setback, accessible bandwidth, and node consumption, whilst it residue spirited with an finest, but unscalable full-mesh superimpose...|$|R
