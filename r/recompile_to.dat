4|189|Public
50|$|A menu {{system was}} written, {{but not a}} menu editor. All menus were {{hard-coded}} C structures, requiring a full <b>recompile</b> <b>to</b> see a menu change. The over-head turn based combat system {{had a very good}} editor written for it. Each ship in the game had its own map. And the semi 3D engine was written. SSI provided the sound library. There were no standards so each common sound card had to be supported. The other interesting routine was the movie player. It looked at a series of computer pictures, found and stored the differences and stored them as compressed blocks. Cybertech hired an assembly whiz to write the de-compressor. Russell wrote everything else from scratch. The team used some of Zoidâ€™s ideas, but none of his code made it into the final game.|$|E
50|$|Recovery {{shepherding}} is {{a lightweight}} technique to enable software programs {{to recover from}} otherwise fatal errors such as null pointer dereference and divide by zero. Comparing to the failure oblivious computing technique, recovery shepherding works on the compiled program binary directly and {{does not need to}} <b>recompile</b> <b>to</b> program. It uses the just-in-time binary instrumentation framework Pin. It attaches to the application process when an error occurs, repairs the execution, tracks the repair effects as the execution continues, contains the repair effects within the application process, and detaches from the process after all repair effects are flushed from the process state. It does not interfere with the normal execution of the program and therefore incurs negligible overhead. For 17 of 18 systematically collected real world null-dereference and divide-by-zero errors, a prototype implementation enables the application to continue to execute to provide acceptable output and service to its users on the error-triggering inputs.|$|E
40|$|We have {{developed}} a software package to automatically generate spectrometers with minimal user input. Spectrometer design is often done by building the instrument from scratch. We have automated this design, creating a parameterized spectrometer that only requires a <b>recompile</b> <b>to</b> implement a change in specification. This spectrometer combines FPGAs and GPUs, doing coarse channelization on the FPGA and sending each subband to the GPUs for further processing. The server software is designed for flexibility, allowing astronomers to easily modify the processing algorithm run on the GPU and customize the instrument to fit their science goals. ...|$|E
5000|$|Often {{carefully}} written {{source code}} [...] - [...] written with source code compatibility and software portability in mind [...] - [...] can be <b>recompiled</b> <b>to</b> {{run on a}} variety of processors, even ones with different data word lengths or different address widths or both.|$|R
50|$|Palm OS Emulator {{supports}} Palm OS 4.x and earlier. It cannot support Palm OS 5.x and later, {{as those}} versions {{are based on}} the ARM processor. PalmSource provides simulators for Palm OS 5.x and up, where the Palm OS has been <b>recompiled</b> <b>to</b> run natively under Windows.|$|R
5000|$|In {{addition}} {{to all of the}} efforts listed above, all applications had <b>to</b> be <b>recompiled</b> <b>to</b> become LFS-aware. The resulting binaries were typically not running on older releases of the same operating system. This was, and to some extent still remains, a problem for some application vendors.|$|R
40|$|Reverse {{engineering}} of {{binary code}} {{is an essential}} step for malware analysis. However, it is a tedious and time-consuming task. Decompilation facilitates this process by transforming machine code into a high-level representation that is more concise and easier to understand. This paper describes REcompile, an efficient and extensible decompilation framework. REcompile uses the static single assignment form (SSA) as its intermediate representation and performs three main classes of analysis. Data flow analysis removes machine-specific details from code and transforms it into a concise high-level form. Type analysis finds variable types based on how those variables are used in code. Control flow analysis identifies high-level control structures such as conditionals, loops, and switch statements. These steps enable <b>REcompile</b> <b>to</b> produce well-readable decompiled code. The overall evaluation, using real programs and malware samples, shows that REcompile achieves a comparable {{and in many cases}} better performance than state-of-the-art decompilers...|$|E
5000|$|XCP {{allows a}} client to access memory on the ECU using a format defined in a {{separate}} A2L file. Because the A2L format file contains all the information to access the information, the ECU code does not have <b>to</b> be <b>recompiled</b> <b>to</b> access different measurements or calibrations.|$|R
50|$|All {{computer}} {{operating systems}} {{are designed for}} a particular computer architecture. Most software applications are limited to particular operating systems running on particular architectures. Although architecture-independent operating systems and applications exist, most need <b>to</b> be <b>recompiled</b> <b>to</b> run on a new architecture. See also a list of common operating systems and their supporting architectures.|$|R
25|$|In {{addition}} to those existing forms of memory protection, Internet Explorer 9 now opts-in to SEHOP (Structured Exception Handler Overwrite Protection) which works by validating {{the integrity of the}} exception handling chain before dispatching exceptions. This helps ensure that structured exception handling cannot be used as an exploit vector, even when running outdated browser add-ons that have not been <b>recompiled</b> <b>to</b> take advantage of SafeSEH.|$|R
50|$|At a time (in the 1960s and 1970s) when IBM/360 series {{programs}} had <b>to</b> be <b>recompiled</b> <b>to</b> run {{in different}} machine and/or operating system environments, one significant {{feature of the}} 1900 series was that programs would function unaltered on any 1900 system, i.e. {{without the need for}} recompilation. Unfortunately ICT, and later ICL, was unable to capitalise on this major advantage to make significant inroads into IBM's customer base.|$|R
50|$|There {{is a great}} body of code {{which has}} been {{developed}} for other IBM Power processors that could potentially be adapted and <b>recompiled</b> <b>to</b> run on the SPU. This code base includes VMX code that runs under the PowerPC version of Apple's Mac OS X, where it is better known as Altivec. Depending on how many VMX specific features are involved, the adaptation involved can range anywhere from straightforward, to onerous, to completely impractical. The most important workloads for the SPU generally map quite well.|$|R
50|$|Cheat Engine, {{commonly}} abbreviated as CE, is an {{open source}} memory scanner/hex editor/debugger created by Eric Heijnen ("Dark Byte") for the Windows operating system. Cheat Engine is mostly used for cheating in computer games, and is sometimes modified and <b>recompiled</b> <b>to</b> evade detection. This program resembles L. Spiro's Memory Hacking Software, TSearch, and ArtMoney. It searches for values input by the user {{with a wide variety}} of options that allow the user to find and sort through the computer's memory. Cheat Engine can also create standalone trainers that can operate independently of Cheat Engine.|$|R
5000|$|The {{technique}} used was to only virtualize the guest interrupt control. This method allowed the real-time kernel {{to convert the}} guest operating system into a system that was completely preemptible but that could still directly control, for example, storage devices. In particular, standard drivers for the guest worked without source modification although they needed <b>to</b> be <b>recompiled</b> <b>to</b> use the virtualization [...] "hooks". See also paravirtualization. The UNIX [...] "pipe" [...] was adapted to permit real-time and non-real-time programs to communicate although other methods such as shared memory were also added.|$|R
5000|$|IP Pascal Implements the {{language}} [...] "Pascaline" [...] (named after Pascal's calculator), {{which is a}} highly extended Pascal compatible with original Pascal according to ISO 7185. It features modules with namespace control, including parallel tasking modules with semaphores, objects, dynamic arrays of any dimensions that are allocated at runtime, overloads, overrides, and many other extensions. IP Pascal has a built-in portability library that is custom tailored to the Pascal language. For example, a standard text output application from 1970's original Pascal can be <b>recompiled</b> <b>to</b> work in a window and even have graphical constructs added.|$|R
25|$|Because macOS is POSIX compliant, many {{software}} packages {{written for the}} other Unix-like systems such as Linux can be <b>recompiled</b> <b>to</b> run on it, including much scientific and technical software. Third-party projects such as Homebrew, Fink, MacPorts and pkgsrc provide pre-compiled or pre-formatted packages. Apple and others have provided versions of the X Window System graphical interface which can allow these applications to run with an approximation of the macOS look-and-feel. The current Apple-endorsed method is the open-source XQuartz project; earlier versions could use the X11 application provided by Apple, or before that the XDarwin project.|$|R
50|$|The {{properties}} and triggers {{defined in the}} application model are inherited by being copied into the component. The definitions can be changed at the component level to provide specific functionality. This breaks {{the link between the}} application model and the component (although it is possible to restore the link to the model). If the model code or properties are changed at the model level, all components holding that object need only be <b>recompiled</b> <b>to</b> collect the new definitions. This provides benefits in maintenance and ensures that the rules associated with the object are available wherever it is used.|$|R
40|$|We {{describe}} a system level programming language and integrated environment for programming {{development on the}} DADO parallel computer. In addition a set of language constructs augmenting LISP for programming parallel computation on tree structured parallel machine are defined. We discuss the architecture or the DADO machine and present several examples to illustrate the language. In particular we describe how the language provides an integrated approach to the problem or parallel software design. Parallel algorithms may be designed analyzed on a sequential machine under simulation and then simply <b>recompiled</b> <b>to</b> run on a parallel machine. In concluding sections we outline the implementation using the Portable Standard LISP Compiler...|$|R
40|$|The RAP {{machine is}} a high {{performance}} parallel processor developed at ICSI as described in previous technical reports. This report documents the RAP software environment. It is intended for the moderately experienced C programmer who wishes to program the RAP. The RAP software environment {{is very similar to}} the UNIX C programming environment. However, there are some differences arising from the hardware that the programmer must keep in mind. Also described is the RAP library which contains hand-optimized matrix, vector and inter-processor communications routines. SIMD programs can be developed under UNIX with a simulated RAP library and then <b>recompiled</b> <b>to</b> run on the RAP. Other parallel programming styles are also described...|$|R
5000|$|As Ruby is an {{interpreted}} language, there's no need <b>to</b> <b>recompile</b> {{the application}} frequently during development.|$|R
5000|$|PHP {{interface}} - For {{the creation}} of custom web pages without having <b>to</b> <b>recompile</b> the cgi's ...|$|R
5000|$|The {{compiler}} {{was particularly}} noteworthy, {{as could be}} expected given Multiflow's technology. The company built a new compiler, in a similar style to that developed at Yale, but industrial-strength and with the incorporation of much commercially-necessary capability. In addition to implementing aggressive trace scheduling, it was known for its reliability, for its incorporation of state-of-the-art optimization, and {{for its ability to}} handle simultaneously many different language variants and all of the different object-code incompatible models of the Multiflow Traces. (While code from a 7/X00 could run correctly on a 14/X00, the nature of the architecture mandated that it would have <b>to</b> be <b>recompiled</b> <b>to</b> run faster than it did on the 7/.) ...|$|R
40|$|In an {{interactive}} program development environment, small program changes are very frequent. When a definition is changed and compiled in Standard ML, every other definition {{that depends on}} that definition must be <b>recompiled</b> <b>to</b> make the change visible. This is because SML uses static binding at the top level. If there are many definitions, {{it is very hard}} to keep track of all dependencies between definitions. Often it is easier <b>to</b> <b>recompile</b> the entire program than manually trying to figure out which definitions must be recompiled. SML Make offers a convenient development environment that takes care of this problem. When invoked, it starts SML as an inferior process in an Emacs buffer. The user then edits SML source code in one or more buffers. With certain keystrokes the contents of the current buffer is sent to SML Make. SML Make parses the code and derives dependencies. If it is the first time the buffer is sent for compiling, everything is passed on to the SML process in the correct [...] ...|$|R
25|$|In {{the late}} 18th century, {{there were several}} {{attempts}} <b>to</b> <b>recompile</b> the major halakhic opinions into a simpler, more accessible form.|$|R
50|$|There {{are some}} minor {{compatibility}} issues with C and assembly programs {{developed for the}} original TI-89. Some have <b>to</b> be <b>recompiled</b> <b>to</b> work on the Titanium due to various small hardware changes, though {{in most cases the}} problems can be fixed by using a utility such as GhostBuster, by Olivier Armand and Kevin Kofler. This option is generally preferred as it requires no knowledge of the program, works without the need of the program's source code, is automated, and doesn't require additional computer software. In some cases, only one character needs to be changed (the ROM base on TI-89 is at 0x200000, whereas the TI-89 Titanium is at 0x800000) by hand or by patcher. Most, if not all, of these problems are caused by the mirror memory (ghost space) or lack thereof.|$|R
50|$|ACARM-ng's daemon allows {{addition}} {{and removal}} of new plug-ins {{without the need}} <b>to</b> <b>recompile</b> the core package. It makes system development and testing much easier.|$|R
5000|$|PHP4Delphi {{allows you}} to embed the PHP {{interpreter}} into your Delphi application so you can extend and customize the application without having <b>to</b> <b>recompile</b> it.|$|R
50|$|Windows Interface Source Environment (or WISE) was a {{licensing}} {{program from}} Microsoft which allowed developers <b>to</b> <b>recompile</b> and run Windows-based applications on UNIX and Macintosh platforms.|$|R
40|$|Graduation date: 1990 This thesis {{discusses}} {{an approach}} whereby Microsoft's MS OS/ 2 {{is provided with}} a means of running the Department of Defense's Transmission Control Protocol/Internet Protocol (TCP/IP). This is done by developing a Packet Protocol Device Driver. This device driver complies with the Packet Driver Specification from FTP Software Inc. and with the Network Driver Interface Specification (NDIS) from 3 Com and Microsoft Corporations. This packet protocol device driver co-resides with other protocol device drivers and shares one medium access control (MAC) device driver as defined in the NDIS. With the successful implementation of the packet protocol device driver, an existing Microsoft MS-DOS version of a TCP/IP package was ported and with minor modifications <b>recompiled</b> <b>to</b> run under MS OS/ 2. This method allows users to retain utility {{and use of the}} OS/ 2 LAN Manager, a networking strategy provided within MS OS/ 2...|$|R
40|$|The thesis {{describes}} a Universal meta cross assembler and an emulator for the Intel 8086 microprocessor. The utility {{is designed to}} be used as an instructional tool to teach assembly language programming to students. One implementation is available to allow students to run Intel 8086 programs on the university's vax mainframe, so that students can test their programs at their convenience. This setup also results in low operating costs with no additional equipment requirements. Several options are provided in the emulator to debug the 8086 assembly language programs composed by students. The assembler, besides generating Intel 8086 machine code, has the capability to generate machine code for a number of microprocessors or microcontrollers. The machine code file generated by the assembler is the input to the emulator. Both the assembler and the emulator are completely portable and can be <b>recompiled</b> <b>to</b> run on any system with a standard C compiler...|$|R
50|$|NaCl uses {{software}} {{fault detection}} and isolation for sandboxing on x86-64 and ARM. The x86-32 implementation of Native Client is notable for its novel sandboxing method, which {{makes use of}} the x86 architecture's rarely used segmentation facility. Native Client sets up x86 segments to restrict the memory range that the sandboxed code can access. It uses a code verifier to prevent use of unsafe instructions {{such as those that}} perform system calls. To prevent the code from jumping to an unsafe instruction hidden {{in the middle of a}} safe instruction, Native Client requires that all indirect jumps be jumps to the start of 32-byte-aligned blocks, and instructions are not allowed to straddle these blocks. Because of these constraints, C and C++ code must be <b>recompiled</b> <b>to</b> run under Native Client, which provides customized versions of the GNU toolchain, specifically GNU Compiler Collection (GCC), GNU Binutils, and LLVM.|$|R
50|$|Most often, the {{makefile}} directs make on how {{to compile}} and link a program. Using C/C++ as an example, when a C/C++ source file is changed, it must be recompiled. If a header file has changed, each C/C++ source file that includes the header file must be <b>recompiled</b> <b>to</b> be safe. Each compilation produces an object file corresponding to the source file. Finally, if any source file has been recompiled, all the object files, whether newly made or saved from previous compilations, must be linked together to produce the new executable program. These instructions with their dependencies are specified in a makefile. If none of the files that are prerequisites have been changed {{since the last time}} the program was compiled, no actions take place. For large software projects, using Makefiles can substantially reduce build times if only a few source files have changed.|$|R
5000|$|At first IBM {{described}} MVS {{as simply}} a new release of OS/VS2, but it was, in fact a major rewrite. OS/VS2 release 1 was an upgrade of OS/360 MVT that retained most of the original code and, like MVT, was mainly written in assembly language. The MVS core was almost entirely written in Assembler XF, although a few modules were written in PL/S, but not the performance-sensitive ones, in particular not the Input/Output Supervisor (IOS). IBM's use of [...] "OS/VS2" [...] emphasized upwards compatibility: application programs that ran under MVT did not even need <b>recompiling</b> <b>to</b> run under MVS. The same Job Control Language files could be used unchanged; utilities and other non-core facilities like TSO ran unchanged. IBM and users almost unanimously called the new system MVS from the start, and IBM continued {{to use the term}} MVS in the naming of later major versions such as MVS/XA.|$|R
40|$|Virtual {{memory is}} the {{simulation}} of a storage space {{so large that}} users do not need <b>to</b> <b>recompile</b> their works when the capacity of a local memory or the configruation of a network changes. January 2008 Rev 6 / 5 / 08 Virtual memory is the simulation of a storage space so large that users do not need <b>to</b> <b>recompile</b> their works when storage configurations change. Every byte of the virtual memory is addressed in the same way, regardless of the placement of address pace components in the memory hierarchy...|$|R
40|$|In {{the context}} of the {{submissions}} of exposure estimates of pesticides in the soil and according to regulation (EC) 1107 / 2009 a set of spatial data pertinent to evaluating the environmental fate and behaviour of pesticides in the soil was published in 2011 as support to the FATE and the ECOREGION EFSA PPR Working Groups. After the first EFSA Spatial Data set was made available in 2011 users commented on inconsistencies in the data, mainly with respect to the spatial characteristics of various layers. The JRC found that the problem was more complex than just a geographic misalignment of layers and concluded that to fully address the problem all data layers needed to be reprocessed from their respective sources and <b>recompiled</b> <b>to</b> comply with the specifications. This task was performed by the JRC, which resulted in an update to the previous data referred to as EFSA Spatial Data Version 1. 1. JRC. H. 5 -Land Resources Managemen...|$|R
5000|$|Unlike most emulators, the SoftWindows {{product used}} <b>recompiled</b> Windows {{components}} <b>to</b> improve performance in most business applications, providing almost native performance (but this meant that, unlike SoftPC, SoftWindows was not upgradable) ...|$|R
