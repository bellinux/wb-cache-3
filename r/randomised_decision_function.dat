0|1526|Public
50|$|In {{statistical}} <b>decision</b> theory, a <b>randomised</b> <b>decision</b> rule {{or mixed}} decision rule {{is a decision}} rule that associates probabilities with deterministic decision rules. In finite <b>decision</b> problems, <b>randomised</b> <b>decision</b> rules define a risk set which is the convex hull of the risk points of the nonrandomised decision rules.|$|R
5000|$|The {{introduction}} of <b>randomised</b> <b>decision</b> rules thus creates a larger decision space {{from which the}} statistician may choose his decision. As non-randomised decision rules are a special case of <b>randomised</b> <b>decision</b> rules where one decision or action has probability 1, the original decision space [...] is a proper subset of the new decision space [...]|$|R
5000|$|As with nonrandomised <b>decision</b> rules, <b>randomised</b> <b>decision</b> rules may satisfy {{favourable}} properties such as admissibility, minimaxity and Bayes. This {{shall be}} {{illustrated in the}} case of a finite decision problem, i.e. a problem where the parameter space is a finite set of, say, [...] elements.The risk set, henceforth denoted as , is the set of all vectors in which each entry is the value of the risk function associated with a <b>randomised</b> <b>decision</b> rule under a certain parameter: it contains all vectors of the form [...] Note that by the definition of the <b>randomised</b> <b>decision</b> rule, the risk set is the convex hull of the risks [...]|$|R
5000|$|A minimax Bayes rule is {{one that}} minimises the {{supremum}} risk [...] among all decision rules in [...] Sometimes, a <b>randomised</b> <b>decision</b> rule may perform better than all other nonrandomised decision rules in this regard.|$|R
5000|$|Alternatively, a <b>randomised</b> <b>decision</b> rule may assign probabilities {{directly}} on {{elements of the}} actions space [...] for {{each member of the}} sample space. More formally, [...] denotes the probability that an action [...] is chosen. Under this approach, its loss function is also defined directly as: [...]|$|R
5000|$|Let [...] be {{a set of}} non-randomised {{decision}} rules with associated probabilities [...] Then the <b>randomised</b> <b>decision</b> rule [...] {{is defined}} as [...] and its associated risk function [...] is [...] This rule can {{be treated as a}} random experiment in which the decision rules [...] are selected with probabilities [...] respectively.|$|R
40|$|In a {{previous}} paper (see Proc. of IEEE Malaysia International Conference on Communication, p. 280 - 4, 2001) {{we proposed a}} nonlinear <b>decision</b> <b>function</b> for adaptive equalization {{in the presence of}} Rayleigh fading. A conventional <b>decision</b> <b>function</b> in adaptive equalization makes use of a hard decision threshold device to generate a difference signal (sometimes also called error signal) necessary in the process of updating the tap weights of the equalizer. This has the disadvantage of not differentiating a very weak signal from a strong signal. Our proposed nonlinear <b>decision</b> <b>function</b> approach weighs less on weak signals and is shown to provide enhancement over a conventional <b>decision</b> <b>function.</b> In this paper, we attempt to justify the use of the proposed clipped parabolic nonlinear <b>decision</b> <b>function</b> and investigate various possible forms of nonlinear <b>decision</b> <b>functions.</b> Department of Electronic and Information EngineeringRefereed conference pape...|$|R
40|$|AbstractWe are {{interested}} in the formulation of multi-criteria <b>decision</b> <b>functions</b> based on the use of a measure over the space of criteria. Specifically the relationship between the criteria is expressed using a fuzzy measure. We then use the Choquet integral to construct <b>decision</b> <b>functions</b> based on the measure. We look at a number of different <b>decision</b> <b>functions</b> generated from specific classes of measure...|$|R
40|$|A model {{selection}} method {{based on}} tabu search is proposed {{to build support}} vector machines (binary <b>decision</b> <b>functions)</b> of reduced complexity and efficient generalization. The aim {{is to build a}} fast and efficient support vector machines classifier. A criterion is defined to evaluate the <b>decision</b> <b>function</b> quality which blends recognition rate and the complexity of a binary <b>decision</b> <b>functions</b> together. The selection of the simplification level by vector quantization, of a feature subset and of support vector machines hyperparameters are performed by tabu search method to optimize the defined <b>decision</b> <b>function</b> quality criterion in order to find a good sub-optimal model on tractable times...|$|R
40|$|Approved for Public Release; {{distribution}} unlimitedThis thesis {{presents an}} application of Multidimensional Scaling (MDS) used in the prioritization of ASW <b>decision</b> <b>functions</b> in the S- 3 A. The ASW decision space was divided into 14 discrete <b>decision</b> <b>functions</b> {{for purposes of this}} analysis. The problem of developing a prioritization methodology was approached from two independent directions. First, an unconstrained sorting task was preformed to provide input to a Multidimensional Scaling algorithm. The result of this analysis provided a three dimensional representation of the decision space with dimensional interpretation. Second, a series of ranking tasks were preformed to provide input to an Unfolding Analysis algorithm. The Generalized Distance Model was selected as the model most representative of the ranking data. The <b>decision</b> <b>function</b> coordinates for the MDS algorithm and the <b>decision</b> <b>function</b> coefficients for the Unfolding Analysis algorithm were combined in a regression-like equation to provide a prioritization methodology for the 14 <b>decision</b> <b>functions</b> of the S- 3 A ASW decision space. [URL] United States Nav...|$|R
40|$|Abstract: The goal of {{the paper}} is to {{estimate}} misclassification probability for <b>decision</b> <b>function</b> by training sample. Here are presented results of investigation an empirical risk bias for nearest neighbours, linear and decision tree classifier in comparison with exact bias estimations for a discrete (multinomial) case. This allows {{to find out how}} far Vapnik–Chervonenkis risk estimations are off for considered <b>decision</b> <b>function</b> classes and to choose optimal complexity parameters for constructed <b>decision</b> <b>functions.</b> Comparison of linear classifier and decision trees capacities is also performed...|$|R
40|$|This paper {{provides}} {{two general}} classes of multiple <b>decision</b> <b>functions</b> where {{each member of}} the first class strongly controls the family-wise error rate (FWER), while {{each member of the}} second class strongly controls the false discovery rate (FDR). These classes offer the possibility that an optimal multiple <b>decision</b> <b>function</b> with respect to a pre-specified criterion, such as the missed discovery rate (MDR), could be found within these classes. Such multiple <b>decision</b> <b>functions</b> can be utilized in multiple testing, specifically, but not limited to, the analysis of high-dimensional microarray data sets. Comment: 19 page...|$|R
40|$|This {{paper is}} {{concerned}} with application of linear <b>decision</b> <b>functions</b> to the pattern identification problem and describes an experimental pattern recognition system for the magnetic ink character font now used in the banking industry. A pattern identification system using linear <b>decision</b> <b>functions</b> The system {{is based on a}} linear <b>decision</b> <b>function</b> determined by means of a variant of an “adaptive training ” technique due to Rosenblatt. The system has been partially implemented (in part, through simula-tion with aid of a digital computer and, in part, by hardware) an...|$|R
40|$|The work is {{supported}} by RFBR, grant 04 - 01 - 00858 -aThe goal of the paper is to estimate misclassification probability for <b>decision</b> <b>function</b> by training sample. Here are presented results of investigation an empirical risk bias for nearest neighbours, linear and decision tree classifier in comparison with exact bias estimations for a discrete (multinomial) case. This allows {{to find out how}} far Vapnik–Chervonenkis risk estimations are off for considered <b>decision</b> <b>function</b> classes and to choose optimal complexity parameters for constructed <b>decision</b> <b>functions.</b> Comparison of linear classifier and decision trees capacities is also performed...|$|R
40|$|Abstract—Successive {{interference}} cancellation (SIC) {{refers to}} a family of low-complexity multiuser detection methods for directsequence code-division multiple-access systems. The performance of multistage SIC depends on the <b>decision</b> <b>function</b> used in the interference cancellation iterations, e. g., hard, soft, or linear <b>decision</b> <b>functions.</b> Due to error propagation, multistage SIC with hard data bit decisions may perform more poorly than multistage SIC with linear or soft <b>decision</b> <b>functions.</b> We propose and analyze a family of generalized unit-clipper bit <b>decision</b> <b>functions</b> that better combine linear and hard decisions. Performance within 0. 4 dB of the single-user bound can be obtained. We then make robust the above soft-decision SIC to time-delay errors as large as half a PN chip and evaluate its performance. Index Terms—Code-division multiple access, iterative methods, multiuser channels, successive interference suppression. I...|$|R
40|$|This paper {{investigates the}} {{performance}} of turbo-coded orthogonal frequency and code division multiplexing (OFCDM) systems with soft multi-code interference (MCI) cancellation. In order to regenerate the soft interference signal, the conventional turbo decoding algorithm must be modified to provide log likelihood ratio (LLR) values for all coded bits. Based on the LLR outputs of turbo decoder, two soft <b>decision</b> <b>functions</b> are proposed, i. e., LLR-soft-decision and Gaussian-soft-decision functions. By means of computer simulations, it is shown that in a highly frequency selective channel, soft MCI cancellation and MMSE detection can significantly improve {{the performance of}} turbo-coded OFCDM systems. Two iterations in turbo decoding are sufficient for both hard and soft <b>decision</b> <b>functions.</b> The proposed soft <b>decision</b> <b>functions</b> outperform the hard <b>decision</b> <b>function</b> with various channel conditions and system parameters. © 2006 IEEE. published_or_final_versio...|$|R
40|$|That {{criterion}} and parameters F, M, N assign {{method of}} constructing sample <b>decision</b> <b>function.</b> In order {{to estimate the}} presented method quality we do statistical modeling. The average of the criterion of sample <b>decision</b> <b>function</b> on samples of fixed size mF (c) = EV F(c, f) is estimated for fixed nature strategy. Conclusion An approach to solving the problem of heterogeneous multivariate variable recognition {{with respect to the}} sample size was considered in this paper. The solution of this problem was assigned by means of presented criterion. The universality of the logical <b>decision</b> <b>function</b> class with respect to presented criterion makes the possible to introduce a measure of distribution complexity and solve this problem for small sample size. For the nature strategy and the class of logical <b>decision</b> <b>function</b> the criterions properties are presented by means of statements and consequences for pattern recognition problem. The relationship of the mF (c) = EV F(c, f) estimate with N respect to <b>decision</b> <b>function</b> class complexity for fixed nature strategy complexity demonstrates the method quality...|$|R
40|$|Statistical {{multiplexing}} {{requires a}} <b>decision</b> <b>function</b> to classify which source combinations can be multiplexed through a given packet network node while meeting {{quality of service}} guarantees. This chapter shows there are no practical fixed statistical multiplexing <b>decision</b> <b>functions</b> that carry reasonable loads and rarely violate {{quality of service requirements}} under all distributions of source combinations. It reviews adaptive alternatives and presents statistical-classification -based <b>decision</b> <b>functions</b> that show promise across many distributions including difficult-to-analyze ethernet data, distributions with cross-source correlations, and traffic with mis-specified parameters. Keywords: Asynchronous Transfer Mode, Quality of Service, Admission Control, Statistical Multiplexing, Adaptive Methods. 1...|$|R
5000|$|Condition 2. The group <b>decision</b> <b>function</b> treats each voter identically. (anonymity) ...|$|R
40|$|In [6], Guha gave a {{complete}} characterization of path independent social <b>decision</b> <b>functions</b> which satisfy {{the independence of}} irrelevant alternatives condition, the strong Pareto principle, and UII, i. e., unanimous indifference implies social indifference. These conditions necessarily imply that a path independent social <b>decision</b> <b>function</b> is neutral and monotonic. In this paper, we extend Guha's characterization to the class of neutral monotonic social functions. We show that neutral monotonic social functions and their specializations to social <b>decision</b> <b>functions,</b> path independent social <b>decision</b> <b>functions,</b> and social welfare functions can be uniquely represented {{as a collection of}} overlapping simple games, each of which is defined on a nonempty set of concerned individuals. Moreover, each simple game satisfies intersection conditions depending on the number of social alternatives; the number of individuals belonging to the concerned set under consideration; and the collective rationality assumption. We also provide a characterization of neutral, monotonic and anonymous social <b>decision</b> <b>functions,</b> where the number of individuals in society exceeds the (finite) number of social alternatives, that generalizes both the representation theorem of May [10] and the representation theorems of Ferejohn and Grether [5]. ...|$|R
5000|$|Sometimes, a minimax {{estimator}} {{may take}} the form of a <b>randomised</b> <b>decision</b> rule. An example is shown on the left. The parameter space has just two elements and each point on the graph corresponds to the risk of a decision rule: the x-coordinate is the risk when the parameter is [...] and the y-coordinate is the risk when the parameter is [...] In this decision problem, the minimax estimator lies on a line segment connecting two deterministic estimators. Choosing [...] with probability [...] and [...] with probability [...] minimises the supremum risk.|$|R
30|$|The <b>decision</b> <b>function</b> {{essentially}} {{picks the}} label of the class whose PCs {{are better able to}} recreate the test image and hence have shorter distance, i.e., smaller reconstruction error. The two sets of PCs and the <b>decision</b> <b>function</b> thus form our image reconstruction-based classifier. This classifier is user-specific and needs to be generated for each user individually.|$|R
40|$|Abstract. In this paper, {{we focus}} on MPI {{collective}} algorithm selection process and explore {{the applicability of the}} quadtree encoding method to this problem. During the algorithm selection process, a particular MPI collective algorithm is selected based on the collective operation parameters. We construct quadtrees with different properties from the measured algorithm performance data and analyze the quality and performance of <b>decision</b> <b>functions</b> generated from these trees. The experimental data indicates that in some cases, the <b>decision</b> <b>function</b> based on quadtree structure with a mean depth of 3 can incur as little as a 5 % performance penalty on average. The exact, experimentally measured, <b>decision</b> <b>function</b> for all tested collectives could be fully represented using quadtrees with a maximum of 6 levels. These results indicate that quadtrees may be a feasible choice for both processing of the performance data and automatic <b>decision</b> <b>function</b> generation. ...|$|R
40|$|In both {{classical}} and Bayesian approaches, statistical inference is unified and generalized by the corresponding decision theory. This {{is not the}} case for the likelihood approach to statistical inference, in spite of the manifest success of the likelihood methods in statistics. The goal of the present work is to fill this gap, by extending the likelihood approach in order to cover decision making as well. The resulting <b>decision</b> <b>functions,</b> called likelihood <b>decision</b> <b>functions,</b> generalize the usual likelihood methods (such as ML estimators and LR tests), in the sense that these methods appear as the likelihood <b>decision</b> <b>functions</b> in particular <b>decision</b> problems. In general, the likelihood <b>decision</b> <b>functions</b> maintain some key properties of the usual likelihood methods, such as equivariance and asymptotic optimality. By unifying and generalizing the likelihood approach to statistical inference, the present work offers a new perspective on statistical methodology and on the connections among likelihood methods. ...|$|R
40|$|This thesis {{presents}} an adaptive technique that uses feedback to provide practical information during a planar near-field measurement scan. The feedback {{is used to}} decide with certainty when to terminate the planar near-field measurement process. The developed adaptive planar near-field method utilizes a rectangular spiral-type acquisition pattern to acquire the near-field measurements. At {{the end of each}} scan iteration, a set of <b>decision</b> <b>functions</b> are rapidly calculated which provide a quality measurement of the resulting far-zone transformation. The <b>decision</b> <b>functions</b> are based on the far-zone radiated patterns, directivity, and the fractional plane wave spectrum error. The <b>decision</b> <b>functions</b> were evaluated using actual planar near-field data set of five different antennas. These experiments have identified those <b>decision</b> <b>functions</b> that are directly related to antenna performance measures and would allow for the termination of the planar near-field test based on a set of relevant stopping conditions...|$|R
40|$|Active {{safety systems}} utilize {{information}} about the vehicle’s state and possibly the surrounding environment to assist the driver if a traffic situation is considered hazardous. The decision to assist the driver is based on sensors that {{are more or less}} subjected to errors. In this paper, we study the influence of input perturbations on <b>decision</b> <b>functions</b> in active safety systems. We present a framework for evaluation of system performance, specification of input requirements and <b>decision</b> <b>function</b> tuning. By introducing a robustness measure, describing the robustness to error for the <b>decision</b> <b>function,</b> we derive efficient methods for analyzing the system performance. The framework is demonstrated on experimental data...|$|R
40|$|We {{explore the}} {{applicability}} of the quadtree encoding method to the run-time MPI collective algorithm selection problem. Measured algorithm performance data was used to construct quadtrees with different properties. The quality and performance of generated <b>decision</b> <b>functions</b> and in-memory <b>decision</b> systems was evaluated. Experimental data shows that in some cases, a <b>decision</b> <b>function</b> based on a quadtree structure with a mean depth of 3 can incur as little as a 5 % performance penalty on average. Experimentally measured data was fully represented using quadtrees with maximum of 6 levels. Our results indicate that quadtrees may be a feasible choice for both processing of the performance data and automatic <b>decision</b> <b>function</b> generation. ...|$|R
40|$|It is {{well-known}} {{that in a}} given decision problem if T is a sufficient statistic then given any <b>decision</b> <b>function</b> there exists an equivalent <b>decision</b> <b>function</b> {{that depends on the}} sample point only through T. In this note, it is shown that the same result does not hold if conditional inference is used unless the sufficient statistic satisfies an additional condition. ...|$|R
40|$|Abstract. Selecting the close-to-optimal {{collective}} algorithm {{based on}} {{the parameters of the}} collective call at run time is an important step in achieving good performance of MPI applications. In this paper, we focus on MPI collective algorithm selection process and explore the applicability of the quadtree encoding method to this problem. We construct quadtrees with different properties from the measured algorithm performance data and analyze the quality and performance of <b>decision</b> <b>functions</b> generated from these trees. The experimental data shows that in some cases, the <b>decision</b> <b>function</b> based on a quadtree structure with a mean depth of 3 can incur as little as a 5 % performance penalty on average. The exact, experimentally measured, <b>decision</b> <b>function</b> for all tested collectives could be fully represented using quadtrees with a maximum of 6 levels. These results indicate that quadtrees may be a feasible choice for both processing of the performance data and automatic <b>decision</b> <b>function</b> generation. ...|$|R
40|$|This paper {{studies the}} {{relationships}} between learning about rules of thumb (represented by classifier systems) and dynamic programming. Building on a result about Markovian stochastic approximation algorithms, we characterize all <b>decision</b> <b>functions</b> that can be asymptotically obtained through classifier system learning, provided the asymptotic ordering of the classifiers is strict. We demonstrate in a robust example that the learnable <b>decision</b> <b>function</b> is in general not unique, not characterized by a strict ordering of the classifiers, and may not coincide with the <b>decision</b> <b>function</b> delivered by {{the solution to the}} dynamic programming problem even if that function is attainable. As an illustration we consider the puzzle of excess sensitivity of consumption to transitory income: classifier systems can generate such behavior even if one of the available rules of thumb is the <b>decision</b> <b>function</b> solving the dynamic programming problem, since bad decisions in good times can "feel better" than good decisions in bad times. ...|$|R
40|$|This paper {{analyses}} {{the convergence}} behaviour of the parallel interference cancellation (PIC) detector in code {{division multiple access}} (CDMA) systems. Using the results from previous stability analysis of an iterated-map neural network, the paper derives a general condition from which the sufficient condition for convergence of the PIC detector with tentative <b>decision</b> <b>functions</b> that are monotonically increasing at a sublinear rate can be calculated. As examples, the paper derives the sufficient conditions for convergence of the PIC detector with the clip decision and the hyperbolic tangent <b>decision</b> <b>functions.</b> The paper also examines the convergence behaviour of the PIC detector with hyperbolic tangent <b>decision</b> <b>function</b> via computer simulation and compares it with the analytical results. <br /...|$|R
40|$|Successive {{interference}} cancellation (SIC) is {{a family}} of low complexity multiuser detection methods for DS/CDMA systems. The performance of the multistage SIC depends on the <b>decision</b> <b>function</b> used in the interference cancellation iterations, whether hard decision, soft decision or linear decision. Due to error propagation, multistage SIC with hard data bit decisions may perform more poorly than multistage SIC with linear or soft <b>decision</b> <b>functions.</b> We propose and analyze a family of generalized unit-clipper bit <b>decision</b> <b>functions</b> that better combine linear and hard decisions. Performance within 0. 4 dB of the single-user bound can be obtained. We then robustify the above soft-decision SIC to time delay errors as large as half a PN chip...|$|R
40|$|In {{this paper}} we {{experimentally}} compare the classification {{uncertainty of the}} <b>randomised</b> <b>Decision</b> Tree (DT) ensemble technique and the Bayesian DT technique with a restarting strategy on a synthetic dataset {{as well as on}} some datasets commonly used in machine learning community. For quantitative evaluation of classification uncertainty, we use an Uncertainty Envelope dealing with the class posterior distribution and a given confidence probability. Counting the classifier outcomes, this technique produces feasible evaluations of the classification uncertainty. Using this technique in our experiments, we found that the Bayesian DT technique is superior to the randomised DT ensemble technique...|$|R
3000|$|This {{classification}} <b>decision</b> <b>function</b> has two inputs. One is {{the vanishing}} component polynomial set {fn 1,[*]…,[*]f [...]...|$|R
50|$|Methods of {{constructing}} a <b>decision</b> <b>function</b> include themaximum likelihood rule, themaximum a posteriori rule, and theminimum distance rule.|$|R
5000|$|Condition 1. The group <b>decision</b> <b>function</b> sends {{each set}} of {{preferences}} to a unique winner. (resolute, unrestricted domain) ...|$|R
