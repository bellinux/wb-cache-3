390|10000|Public
25|$|Data {{science and}} machine {{learning}} analysis and modelling methods are being increasingly employed in portfolio performance and portfolio <b>risk</b> <b>modelling,</b> {{and as such}} data science and machine learning Master's graduates are also in demand as quantitative analysts.|$|E
25|$|On 18 April 1906, a major {{earthquake}} and resulting fires destroyed more than 80 per {{cent of the}} Californian city of San Francisco. This event {{was to have a}} profound influence on building practices, <b>risk</b> <b>modelling,</b> and the insurance industry.|$|E
5000|$|Act on {{evidence-based}} forecasts from predictive <b>risk</b> <b>modelling</b> {{in order}} to reduce non-elective secondary care (acute hospital) usage ...|$|E
40|$|A {{systematic}} {{calibration procedure}} is described for incorporating {{more than one}} <b>risk</b> <b>model</b> in a portfolio construction strategy. The addition of a second <b>risk</b> <b>model</b> can lead to just as conservative portfolios and better overall performance than one <b>risk</b> <b>model</b> alone provided that the strategy is calibrated so that both <b>risk</b> <b>models</b> affect the optimal portfolio solution. We report results using Axioma’s Japanese <b>risk</b> <b>models</b> and two <b>risk</b> constraints in the portfolio construction strategy. In all cases, Axioma’s daily fundamental factor Japanese <b>risk</b> <b>model</b> is the primary <b>risk</b> <b>model</b> {{which is used to}} define the tracking error of the portfolio, the primary risk constraint in the strategy. Three different second <b>risk</b> <b>model</b> constraints are considered: a) Constrain active risk using Axioma’s statistical factor <b>risk</b> <b>model.</b> b) Constrain total risk using Axioma’s statistical factor <b>risk</b> <b>model.</b> c) Constrain specific risk using Axioma’s fundamental factor <b>risk</b> <b>model.</b> Calibration of the portfolio construction parameters is essential since the region over which both <b>risk</b> <b>models</b> affect the solution is difficult to predict a priori and can be relatively narrow. In many cases, calibration results give a clear, optimum set of portfolio construction parameters in which the second <b>risk</b> <b>model</b> synergistically improves portfolio performance...|$|R
30|$|The {{compound}} binomial <b>risk</b> <b>model</b> {{has been}} studied by many authors, for example, Gerber [1], Shiu [2], Willmot [3] and Dickson [4]. Recently, some extensions have been made on this model. Yang et al. [5] study the ruin probabilities in a discrete Markov <b>risk</b> <b>model.</b> Yang and Zhang [6] consider a discrete renewal <b>risk</b> <b>model</b> with two-sided jumps. Gerber et al. [7] modify the compound binomial <b>risk</b> <b>model</b> by dividend payments. Chen et al. [8] study the survival probabilities in a discrete semi-Markov <b>risk</b> <b>model.</b>|$|R
40|$|OBJECTIVES: In {{the absence}} of {{long-term}} randomized clinical trials (RCTs) {{on the effectiveness of}} pharmacological treatment for primary cardiovascular disease (CVD) prevention, <b>risk</b> prediction <b>models</b> are used to project changes in CVD incidence due to changes on risk factor levels observed in short-term RCTs. This study aims to summarize the literature on the application of these CVD <b>risk</b> <b>models</b> in pharmacoeconomic studies for primary CVD prevention interventions in high in- come countries. METHODS: We systematically reviewed the literature on the application of CVD <b>risk</b> <b>models</b> in pharmacoeconomic studies. We assessed the quality of incorporation of <b>risk</b> <b>models</b> in these studies by evaluating the agreement of the population characteristics and the time horizon applied between the <b>risk</b> <b>model</b> and the pharmacoeconomic study, the appropriateness of the <b>risk</b> <b>model</b> for the population studied, and the incorporation of the uncertainty of the <b>risk</b> <b>model</b> in the sensitivity analysis. RESULTS: We identified 12 studies using published CVD <b>risk</b> <b>models.</b> The studies demonstrated the usefulness of projecting intermediate effectiveness endpoints to long term, health and cost related, benefits. However, our quality assessment highlighted the distance between the populations of the <b>risk</b> <b>model</b> and the studies reviewed, the disagreement between <b>risk</b> <b>model</b> and study time horizons, and the lack of consideration of all uncertainty surrounding risk predictions. CONCLUSIONS: Given that utilizing a <b>risk</b> <b>model</b> to project the effect of a pharmacological intervention to CVD events provides an estimate of the intervention's clinical and economic impact, consideration should be paid on the agreement between the study and <b>risk</b> <b>model</b> populations as well as the level of uncertainty that these predictions add to the decision-analytic model. In {{the absence of}} hard endpoint trials, the value of <b>risk</b> <b>models</b> to model pharmacological efficacy in primary CVD prevention remains high, although their limitation should be acknowledged...|$|R
50|$|CH2M HILL are the {{developers}} of Flood Modeller Pro, an industry-leading flood <b>risk</b> <b>modelling</b> and real-time flood forecasting suite of software.|$|E
50|$|Finance Group - {{active in}} {{quantitative}} finance research. The group has particular interests in derivative pricing, capital markets research, credit <b>risk</b> <b>modelling,</b> risk management and financial econometrics.|$|E
50|$|Data {{science and}} Machine Learning {{analysis}} and modelling methods are being increasingly employed in portfolio performance and portfolio <b>risk</b> <b>modelling,</b> {{and as such}} data science and machine learning Masters graduates are also in demand as Quantitative analysts.|$|E
40|$|The Pólya-Aeppli {{process as}} a {{generalization}} of the homogeneous Poisson process is defined. We consider the <b>risk</b> <b>model</b> in which the counting process is the Pólya-Aeppli process. It is called a Pólya-Aeppli <b>risk</b> <b>model.</b> The problem of finding the ruin probability and the Cramér-Lundberg approximation is studied. The Cramér condition and the Lundberg exponent are defined. Finally, the comparison between the Pélya-Aeppli <b>risk</b> <b>model</b> and the corresponding classical <b>risk</b> <b>model</b> is given...|$|R
40|$|The P&# 243;lya-Aeppli {{process as}} a {{generalization}} of the homogeneous Poisson process is defined. We consider the <b>risk</b> <b>model</b> in which the counting process is the P&# 243;lya-Aeppli process. It is called a P&# 243;lya-Aeppli <b>risk</b> <b>model.</b> The problem of finding the ruin probability and the Cram&# 233;r-Lundberg approximation is studied. The Cram&# 233;r condition and the Lundberg exponent are defined. Finally, the comparison between the P&# 233;lya-Aeppli <b>risk</b> <b>model</b> and the corresponding classical <b>risk</b> <b>model</b> is given...|$|R
40|$|This paper {{reports the}} results of an {{empirical}} comparison of various types of competing <b>risk</b> <b>models</b> in predicting the timing and duration of activities. In particular, three types of models are compared: a non-competing <b>risk</b> <b>model,</b> an unconditional competing <b>risk</b> <b>model,</b> and a conditional competing <b>risk</b> <b>model.</b> The models are applied to an activity diary, collected in the Netherlands. The results of the comparison indicate that the conditional competing <b>risk</b> <b>model</b> performs best, indicating that the choice and timing of activities depends on the nature and duration of the activity conducted previously. The specific structure of these dependent transition probabilities are discussed in detail. Several socio-demographic variables are found to be significantly related to the transition probabilities...|$|R
50|$|On 18 April 1906, a major {{earthquake}} and resulting fires destroyed more than 80 per {{cent of the}} Californian city of San Francisco. This event {{was to have a}} profound influence on building practices, <b>risk</b> <b>modelling,</b> and the insurance industry.|$|E
5000|$|In December 2014, the TRC was {{included}} as a collaborating partner with the Microsimulation & <b>Risk</b> <b>Modelling</b> Group, at the University of Wollongong. The project with them is assessing the tactics and counter tactics involved in lone wolf knife attacks on the public.|$|E
50|$|In November 2010, it was {{announced}} that Towers Watson had signed a definitive agreement to acquire EMB Consultancy. EMB specialized in property & casualty consulting. EMB also had software dealing with pricing, reserving, spatial smoothing analysis, capital and <b>risk</b> <b>modelling.</b> The deal was completed as of February 1, 2011.|$|E
30|$|The perturbed {{compound}} Poisson <b>risk</b> <b>model,</b> {{first proposed}} by Gerber [1], {{is an extension}} of the classical <b>risk</b> <b>model</b> by adding diffusion process to denote small volatility in the surplus process. Since then, a lot of contributions have been made to this model and its extension. See e.g. Tsai and Willmot [2] for the compound Poisson <b>risk</b> <b>model,</b> Li and Garrido [3] for a Sparre Andersen <b>risk</b> <b>model</b> with Erlang inter-claim times, Zhang and Yang [4] for a perturbed compound Poisson model with dependence between inter-claim times and claim sizes, and Zhang et al. [5] for a Sparre Andersen <b>risk</b> <b>model</b> with time dependent claim sizes.|$|R
30|$|When g(x)=c, the <b>risk</b> <b>model</b> {{is reduced}} to the {{classical}} <b>risk</b> <b>model,</b> Theorem 1 coincides exactly with Lemma 3.1 in Wu et al. (2003).|$|R
40|$|In {{the recent}} {{financial}} crisis, risk management tools {{have been proven}} inadequate. <b>Model</b> <b>risk,</b> {{a key component of}} bank risk, has shown its negative impact. It seems that <b>risk</b> <b>models</b> did not cover the included risks comprehensively and were not kept up-to-date by banks, and also rating agencies. Consequently, {{in the aftermath of the}} crisis banks must adjust their models to reduce <b>model</b> <b>risk.</b> We discuss if banks undertake enough effort to improve their <b>risk</b> <b>models.</b> Furthermore, the paper deals with the optimal organizational structure of this improvement process. We take a close look at <b>risk</b> <b>models</b> of banks and discuss if banks generally invest enough effort to improve their <b>risk</b> <b>models.</b> The question of <b>risk</b> <b>model</b> innovation is analyzed from a managerial as well as from a welfare perspective in the context of a principal agent model - where the bank has to incentivize an agent to perform innovative improvement in the <b>risk</b> <b>model</b> technology...|$|R
50|$|Risk Management Solutions (RMS), which targets {{the global}} {{property}} and casualty reinsurance industry, producing risk analysis models, services, expertise and data solutions {{for use in the}} quantification and management of catastrophic risk, is a market leader in catastrophe <b>risk</b> <b>modelling,</b> and is a subsidiary of the DMGT group.|$|E
50|$|Statistical {{measures}} for financial risk are not intuitive. Increasing the confidence level (e.g. from 99.0% to 99.9%) does not capture very rare events with possibly high impact. The only way around {{is to use}} extreme value theory for modelling the distribution tails. In other words: Statistical liquidity <b>risk</b> <b>modelling</b> approaches do not provide certainty {{in terms of a}} reliable lower limit for future liquidity.|$|E
50|$|The third application, Control of {{emerging}} pests, diseases and pathogens, is being tackled by techniques from <b>risk</b> <b>modelling,</b> such as Pollett’s calibration of stochastic models from discrete-sampled infection data, from Taylor’s work in complex networks {{in which he}} develops models that account for spatial structure in the spread of infection, by Brak’s work in critical phenomena - determining conditions for endemicity and other stable regimes, and Froyland’s work in dynamical systems in which he assesses the relative stability of endemic and non-endemic states.|$|E
40|$|There is no {{diabetes}} <b>risk</b> <b>model</b> {{that includes}} dietary predictors in Asia. We sought {{to develop a}} diet-containing noninvasive diabetes <b>risk</b> <b>model</b> in Northern China and to evaluate whether dietary predictors can improve model performance and predictive ability. Cross-sectional data for 9, 734 adults aged 20 - 74 years old were used as the derivation data, and results obtained for a cohort of 4, 515 adults with 4. 2 years of follow-up were used as the validation data. We used a logistic regression model to develop a diet-containing noninvasive <b>risk</b> <b>model.</b> Akaike's information criterion (AIC), area under curve (AUC), integrated discrimination improvements (IDI), net classification improvement (NRI) and calibration statistics were calculated to explicitly assess the effect of dietary predictors on a diabetes <b>risk</b> <b>model.</b> A diet-containing type 2 diabetes <b>risk</b> <b>model</b> was developed. The significant dietary predictors including the consumption of staple foods, livestock, eggs, potato, dairy products, {{fresh fruit and vegetables}} were included in the <b>risk</b> <b>model.</b> Dietary predictors improved the noninvasive diabetes <b>risk</b> <b>model</b> with {{a significant increase in the}} AUC (delta AUC = 0. 03, P< 0. 001), an increase in relative IDI (24. 6 %, P-value for IDI < 0. 001), an increase in NRI (category-free NRI = 0. 155, P< 0. 001), an increase in sensitivity of the model with 7. 3 % and a decrease in AIC (delta AIC = 199. 5). The results of the validation data were similar to the derivation data. The calibration of the diet-containing diabetes <b>risk</b> <b>model</b> was better than that of the <b>risk</b> <b>model</b> without dietary predictors in the validation data. Dietary information improves model performance and predictive ability of noninvasive type 2 diabetes <b>risk</b> <b>model</b> based on classic risk factors. Dietary information may be useful for developing a noninvasive diabetes <b>risk</b> <b>model...</b>|$|R
30|$|When g(x)=c, the <b>risk</b> <b>model</b> {{simplifies}} to {{the classical}} compound Poisson <b>risk</b> <b>model,</b> Theorem 5 {{is the same as}} Lemma 3.5 in Wu et al. (2003).|$|R
50|$|Multiple <b>risk</b> <b>models</b> for the {{prediction}} of cardiovascular risk of individual patients have been developed. One such key <b>risk</b> <b>model</b> is the Framingham Risk Score.|$|R
5000|$|Operating on the Oasis LMF, Boat Oasis, the multi-peril cat <b>risk</b> <b>modelling</b> platform, {{has been}} brought to market by Boat Services to provide the {{insurance}} industry with {{a deeper understanding of}} risk. The Boat Oasis platform allows model providers {{from all over the world}} to make their models available to the industry using the Oasis framework. By creating a marketplace where vendors can make their models available via a single user interface, the platform lowers the barriers to entry in the cat model marketplace and encourages the development of new and improved cat risk models.|$|E
50|$|Analysis of {{probability}} failure trees for open circuit scuba shows {{that use of}} a parallel or redundant system reduces risk considerably more than improving the reliability of components in a single critical system. These <b>risk</b> <b>modelling</b> techniques were applied to CCRs, and indicated a risk of equipment failure some 23 times that for a manifolded twin cylinder open circuit set. When sufficient redundant breathing gas supply {{in the form of}} open circuit scuba is available, the mechanical failure risk of the combination becomes comparable to that for open circuit. This does not compensate for poor maintenance and inadequate pre-dive checks, high risk behavior, or for incorrect response to failures. Human error appears to be a major contributor to accidents.|$|E
5000|$|The {{predictive}} model used for identifying patients {{for admission to}} a virtual ward {{is also used to}} prompt the virtual ward staff when it is time to consider discharging the patient. When a patient has been assessed by all relevant virtual ward staff, and has been cared for uneventfully for several months in the [...] "monthly review" [...] section of the ward, then the ward staff may feel that the patient is ready to be discharged to an alternative service, which might include self-directed care, care of the GP or care of another community service. A discharge summary is recorded at the practice, and a discharge letter (written using lay terminology) is sent to the patient. After discharge the patient is still able to contact the virtual ward for advice, and may be readmitted if their clinical need dictates it. This not only ensures that the patient is borne in mind, but these quarterly review data serve as positive feedback to the predictive <b>risk</b> <b>modelling</b> algorithm.|$|E
40|$|The American Joint Committee on Cancer (AJCC) has {{increasingly}} {{recognized the need}} for more personalized probabilistic predictions than those delivered by ordinal staging systems, particularly through the use of accurate <b>risk</b> <b>models</b> or calculators. However, judging the quality and acceptability of a <b>risk</b> <b>model</b> is complex. The AJCC Precision Medicine Core conducted a 2 -day meeting to discuss characteristics necessary for a quality <b>risk</b> <b>model</b> in cancer patients. More specifically, the committee established inclusion and exclusion criteria necessary for a <b>risk</b> <b>model</b> to potentially be endorsed by the AJCC. This committee reviewed and discussed relevant literature before creating a checklist unique to this need of AJCC <b>risk</b> <b>model</b> endorsement. The committee identified 13 inclusion and 3 exclusion criteria for AJCC <b>risk</b> <b>model</b> endorsement in cancer. The emphasis centered on performance metrics, implementation clarity, and clinical relevance. The facilitation of personalized probabilistic predictions for cancer patients holds tremendous promise, and these criteria will hopefully greatly accelerate this process. Moreover, these criteria might be useful for a general audience when trying to judge the potential applicability of a published <b>risk</b> <b>model</b> in any clinical domain...|$|R
40|$|We {{study the}} {{asymptotic}} {{behavior of the}} Gerber-Shiu expected discounted penalty function in the renewal <b>risk</b> <b>model.</b> Under {{the assumption that the}} claim-size distribution has a convolution-equivalent density function, which allows both heavy-tailed and light-tailed cases, we establish some asymptotic formulas for the Gerber-Shiu function with a fairly general penalty function. These formulas become completely transparent in the compound Poisson <b>risk</b> <b>model</b> or for certain choices of the penalty function in the renewal <b>risk</b> <b>model.</b> A by-product of this work is an extension of the Wiener-Hopf factorization to include the times of ascending and descending ladders in the continuous-time renewal <b>risk</b> <b>model.</b> Asymptotics Convolution equivalence Duality principle Gerber-Shiu function Renewal <b>risk</b> <b>model</b> Wiener-Hopf factorization...|$|R
40|$|Abstract—This paper {{investigates the}} finite time ruin {{probability}} in non-homogeneous Poisson <b>risk</b> <b>model,</b> conditional Poisson <b>risk</b> <b>models</b> and renewal <b>risk</b> <b>model</b> with stochastic returns. Under {{the assumption that}} the claimsize is subexponentially distributed, a simple asymptotic relation is established when the initial capital tends to infinity. The results obtained extend the corresponding results of constant interest force. Key Words...|$|R
5000|$|Since October 2012, Master's {{students}} of TU Munich {{in cooperation with}} the volunteers organization TECHO Haïti have been performing extensive research in Onaville, the most eastern part of Canaan. The topics of research performed by the research platform Urban Strategies for Onaville, Haiti (TUM-USO) have been: flooding risk of Ravine Madanièl (Ravine Lan Couline) and integrated water management, infrastructure mapping, participatory urban development strategies, urban design, locally adapted gardenig techniques, etc.. Research results are shared with key actors from Haitian Government and the [...] "International Community", NGOs, local administration, and especially with local leaders and residents. In field workshops findings have been brought back to the community and verified. Improved flood <b>risk</b> <b>modelling</b> and testing of flood protection infrastructure variants performed based on UAV-Data from Humanitarian OpenStreetMap and IOM GIS-Unit revealed that Onaville and Canaan is exposed to high flooding risk: In a 100 year event, over 3200 buildings (about 15.000 persons - when stating average Haitian household size of 4.5 persons) would be affected by the powerful flows of Ravine Madanièl. A 5 year event would still endanger about 350 houses and shacks (about 1.600 persons).|$|E
30|$|In {{this paper}} {{we have shown}} how big data and, specifically, tweet data, can be usefully {{employed}} {{in the field of}} financial systemic <b>risk</b> <b>modelling.</b>|$|E
40|$|This article (i) iterates what {{is meant}} by credit risks and the mathematical-statistical {{modelling}} thereof, (ii) elaborates the conceptual and technical links between credit <b>risk</b> <b>modelling</b> and capital adequacy framework for financial institutions, particularly as per the New Capital Accord (Basel II) ’s Internal Ratings-Based (IRB) approach, (iii) proffer a simple and intuitive taxonomy on contemporary credit <b>risk</b> <b>modelling</b> methodologies, and (iv) discuses in some details a number of key models pertinent, in various stages of development, to various application areas in the banking and financial sector...|$|E
40|$|Background: Long-term trials on the {{effectiveness}} of pharmacological treatment for primary cardiovascular disease prevention are scant. For that reason <b>risk</b> prediction <b>models</b> are used as a tool to project changes in cardiovascular disease incidence due to changes in risk factor levels observed in short-term randomized clinical trials. In this article, we summarize the literature on the application of these <b>risk</b> <b>models</b> in pharmacoeconomic studies for primary cardiovascular disease prevention interventions in high-income countries. Methods and results: We systematically reviewed the available literature on the application of cardiovascular disease <b>risk</b> <b>models</b> in pharmacoeconomic studies and assessed the quality of incorporation of <b>risk</b> <b>models</b> in these studies. Quality assessment indicated the distance between the characteristics of populations of the <b>risk</b> <b>model</b> and the studies reviewed, the frequent disagreement between <b>risk</b> <b>model</b> and study time horizons and the lack of proper consideration of the uncertainty surrounding risk predictions. Conclusion: Given that utilizing a <b>risk</b> <b>model</b> to project the effect of a pharmacological intervention to cardiovascular events provides an estimate of the intervention's clinical and economical impact, consideration should be paid to the agreement between the study and <b>risk</b> <b>model</b> populations as well as the level of uncertainty that these predictions add to the outcome of a decision-analytic model. In the absence of hard endpoint trials, the value of <b>risk</b> <b>models</b> to model pharmacological efficacy in primary cardiovascular disease prevention remains high, although their limitations should be acknowledged...|$|R
40|$|Duality {{principle}} Gerber–Shiu function Renewal <b>risk</b> <b>model</b> Wiener–Hopf factorization We {{study the}} asymptotic {{behavior of the}} Gerber–Shiu expected discounted penalty function in the renewal <b>risk</b> <b>model.</b> Under {{the assumption that the}} claim-size distribution has a convolution-equivalent density function, which allows both heavy-tailed and light-tailed cases, we establish some asymptotic formulas for the Gerber–Shiu function with a fairly general penalty function. These formulas become completely transparent in the compound Poisson <b>risk</b> <b>model</b> or for certain choices of the penalty function in the renewal <b>risk</b> <b>model.</b> A by-product of this work is an extension of the Wiener–Hopf factorization to include the times of ascending and descending ladders in the continuous-time renewal <b>risk</b> <b>model.</b> © 2009 Elsevier B. V. All rights reserved. 1...|$|R
40|$|A {{quantitative}} {{risk assessment}} system (QRAS) builds a <b>risk</b> <b>model</b> of a system for which risk of failure is being assessed, then analyzes {{the risk of the}} system corresponding to the <b>risk</b> <b>model.</b> The QRAS performs sensitivity analysis of the <b>risk</b> <b>model</b> by altering fundamental components and quantifications built into the <b>risk</b> <b>model,</b> then re-analyzes the risk of the system using the modifications. More particularly, the <b>risk</b> <b>model</b> is built by building a hierarchy, creating a mission timeline, quantifying failure modes, and building/editing event sequence diagrams. Multiplicities, dependencies, and redundancies of the system are included in the <b>risk</b> <b>model.</b> For analysis runs, a fixed baseline is first constructed and stored. This baseline contains the lowest level scenarios, preserved in event tree structure. The analysis runs, at any level of the hierarchy and below, access this baseline for risk quantitative computation as well as ranking of particular risks. A standalone Tool Box capability exists, allowing the user to store application programs within QRAS...|$|R
