33|314|Public
60|$|In {{a similar}} manner we may inquire into {{the cause of a}} given effect. Let a be the effect. Here, as shown in the last chapter, we have only the {{resource}} of observation without experiment: we can not take a phenomenon of which we know not the origin, and try to find its mode of production by producing it: if we succeeded in such a <b>random</b> <b>trial</b> it could only be by accident. But if we can observe a in two different combinations, a b c and a d e; and if we know, or can discover, that the antecedent circumstances in these cases respectively were A B C and A D E, we may conclude by a reasoning similar to that in the preceding example, that A is the antecedent connected with the consequent a by a law of causation. B and C, we may say, can not be causes of a, since on its second occurrence they were not present; nor are D and E, for they were not present on its first occurrence. A, alone of the five circumstances, was found among the antecedents of a in both instances.|$|E
5000|$|In {{probability}} theory, {{the sample}} space {{of an experiment}} or <b>random</b> <b>trial</b> is the set of all possible outcomes or results of that experiment. A sample space is usually denoted using set notation, and the possible ordered outcomes are listed as elements in the set. It is common {{to refer to a}} sample space by the labels S, Ω, or U (for [...] "universal set").|$|E
40|$|A simple {{generalization}} of the MHD model {{accounting for the}} fluctuations of the configurations due to kinetic effects in plasmas in short times small scales is considered. The velocity of conductive fluid and the magnetic field are considerd as the stochastic fields (or <b>random</b> <b>trial</b> trajectories) for which the classical MHD equations {{play the role of}} the mean field equations in the spirit of stochastic mechanics of E. Nelson. Comment: 27 pages, 6 figure...|$|E
30|$|The {{experimental}} result {{also shows that}} eight LBP features, i.e., LBP, LTP, SLBP, CLBP, CCLBP, CCLTP, CCSLBP, and CCCLBP, are robust for infrared ATR, because they are fairly stable in 10 <b>random</b> <b>trials</b> for each case.|$|R
40|$|This {{paper is}} {{a sequel to}} the series of papers [1 - 9]. The problem {{of the meaning of}} {{objective}} a priori probability for individual <b>random</b> <b>trials</b> without repetition is considered. A sequence of such trials, namely quantum jumps, is realized in indeterministic dynamics of the universe. A hidden selector for the quantum jumps is constructed. ...|$|R
500|$|Monte Carlo methods, which {{evaluate}} {{the results of}} multiple <b>random</b> <b>trials,</b> {{can be used to}} create approximations of [...] Buffon's needle is one such technique: If a needle of length [...] is dropped [...] times on a surface on which parallel lines are drawn [...] units apart, and if [...] of those times it comes to rest crossing a line (>0), then one may approximate [...] based on the counts: ...|$|R
40|$|Abstract. To {{explore the}} effect of spatial locality, {{crowding}} differential evolu-tion is incorporated with spatial locality for multimodal optimization. Instead of <b>random</b> <b>trial</b> vector generations, it takes advantages of spatial locality to generate fitter trial vectors. Experiments were conducted to compare the proposed algo-rithm (CrowdingDE-L) with the state-of-the-art algorithms. Further experiments were also conducted on a real world problem. The experimental results indicate that CrowdingDE-L has a competitive edge over the other algorithms tested. ...|$|E
40|$|Out of 500 <b>random</b> <b>trial</b> subjects, {{taken for}} a mass-screening for early {{detection}} of diabetes mellitus, the Authors tried a correlation between {{the reliability of the}} "two-hour test" and the 2 h OGTT. The latter method provides more reliable results, allowing us to diagnose a high percentage of cases which is not possible if the simple two-hour test were used. Research of glycosuria in the course of OGTT did not show any real reliability, whereas it did prove useful in the preliminary phase of our research in order to distinguish the subjects for whom a deeper investigation would be advisable...|$|E
40|$|Abstract — Little and Venkatesh conjectured that, for an {{interactive}} VoD {{system with a}} single <b>random</b> <b>trial</b> resource selection scheme, the blocking probability of a user’s request is minimized when the overall movie traffic load is spread uniformly on each disk in the system. In this paper, we generalize this conjecture to the situation where there can be repeated random trials or where a least busy fit resource selection scheme is used. We support our conjecture with a simulation of a realistic system, and propose a metric following the idea of our conjecture to assess the goodness of movie assignment in the system. I...|$|E
30|$|Ideally, where {{options and}} {{forwards}} are not advantageous to the provider, consumers should receive no discount. However, the provider’s method for determining if contracts {{should be established}} is not perfect, and occasionally the provider confirms contracts where it is subsequently found that no scheduling advantage is realised. This could potentially be improved by running more <b>random</b> <b>trials</b> prior to confirming contracts, or using {{a number of other}} bin packing algorithms.|$|R
5000|$|Monte Carlo methods, which {{evaluate}} {{the results of}} multiple <b>random</b> <b>trials,</b> {{can be used to}} create approximations of [...] Buffon's needle is one such technique: If a needle of length [...] is dropped [...] times on a surface on which parallel lines are drawn [...] units apart, and if [...] of those times it comes to rest crossing a line ( [...] > 0), then one may approximate [...] based on the counts: ...|$|R
40|$|An {{unsupervised}} learning method of an evaluation function is proposed. By this function, a robot {{can learn a}} series of motion to achieve a given purpose. The evaluation function is calculated by a neural network and time derivative of this function is reduced during motions with <b>random</b> <b>trials.</b> We confirmed by simulation that a robot with asymmetric motion feature could obtain an appropriate asymmetric evaluation function and become to achieve a given purpose along an almost optimal path. 1...|$|R
40|$|This paper {{describes}} a novel algorithm especially devoted to detect "interesting" objects {{defined as a}} set of close measured values that spring out from a uniform or textured background. In particular such an algorithm has been developed with the purpose to define a movement strategy for a remotely piloted rover useful in applied geophysics. The method could be represented by a Viper that moves with a <b>random</b> <b>trial</b> over the image with the purpose to detect the presence of an object emerging from the background, and to adapt the sampling interval to the shape of the detected object. Simulations on real geophysics images show good results with reduced algorithm complexit...|$|E
40|$|An {{iterative}} learning scheme-based fault estimation observer {{is designed}} for a class of nonlinear systems with randomly changed trial length. This is achieved by presenting a state observer for monitoring the system state and an iterative learning law for fault estimation {{in the presence of}} imprecise system model. An average factor is defined to deal with the lack and redundancy in tracking information caused by <b>random</b> <b>trial</b> length. Via the convergence analysis, sufficient design conditions are developed for estimation of fault signal. The observer gains and iterative learning law indexes are computed by solving the proposed conditions under λ-norm constraints. Numerical examples are presented to demonstrate the validity, the effectiveness, and the superiority of this method...|$|E
30|$|Some {{limitations}} of the studies in this paper are that students were not randomly assigned to groups {{and there were no}} baseline measures of engagement. While this is typical of in situ studies, where researchers must be willing to work around the primary needs of the school, it does limit our ability to make full conclusions as to causality. On the other hand, since schools rarely make classroom assignments on a random basis, these results may be more typical of field conditions than a fully <b>random</b> <b>trial</b> would have been. Further large-scale studies will attempt to determine if the high levels of student engagement seen among Reasoning Mind students generalizes more broadly, but these results offer promising support for the engagingness of blended learning systems, particularly when they incorporate appropriate design principles.|$|E
40|$|This {{paper is}} {{a sequel to}} the series of papers [gr-qc/ 9409010, gr-qc/ 9505034, gr-qc/ 9603022, gr-qc/ 9609035, gr-qc/ 9609046, gr-qc/ 9704033, gr-qc/ 9704038, gr-qc/ 9708014, gr-qc/ 9802016]. The problem {{of the meaning of}} {{objective}} a priori probability for individual <b>random</b> <b>trials</b> without repetition is considered. A sequence of such trials, namely quantum jumps, is realized in indeterministic dynamics of the universe. A hidden selector for the quantum jumps is constructed. Comment: 5 pages, LATEX 2. 0...|$|R
30|$|The MCS {{results in}} FD {{analysis}} presented an unstable condition in trials up to n[*]=[*] 400, {{which indicates that}} much more simulations are required in complex types of analysis; thus, PEM, despite differences mentioned earlier, can be preferable to MCS in predicting pf values in serviceability reliability analysis of deep excavations with much less computational effort needed. The sampling procedure in PEM and MCS are quiet different, but {{it was observed that}} the statistical moments of input variables in both of these methods was in good agreement for normal distribution functions. From the parametric study performed in limit equilibrium analysis, {{it was found that the}} effect of varying the number of <b>random</b> <b>trials</b> was not significant beyond 1000 <b>random</b> <b>trials</b> in MCS and reasonable results regarding stability analysis can be achieved by this method in stability analysis of deep excavations. The paper showed that combining the probabilistic deformation analysis using PEM (under specific conditions) and MCS using finite difference methods with probabilistic stability analysis by MCS using limit equilibrium analysis could be a desirable procedure which is recommended in reliability analysis of deep excavations problems.|$|R
40|$|The {{influence}} of structure and age on sequence learning was investigated by testing 24 young and 24 older participants for 10 sessions in an alternating serial response time task in which pattern <b>trials</b> alternated with <b>random</b> <b>trials.</b> Individuals encountered lag- 2 or lag- 3 structure, and learning {{was measured by}} the difference (in response time and accuracy) between pattern and <b>random</b> <b>trials.</b> Both ages learned lag- 2 structure, but the young learned more than the older participants. Only the young people learned lag- 3 structure, and they did so more slowly and to a lesser degree than they learned lag- 2 structure. These age deficits in higher order sequence learning after extended practice are consistent with simultaneity theory and with theories positing that age-related deficits in neuromodulation lead to less distinctive representations. Implicit learning occurs when people become sensitive to co-variations in the environment without intending to do so and without becoming aware of what they have learned (e. g., Cleere-mans, Destrebecqz, & Boyer, 1998). Despite burgeoning interest in implicit learning over the past decade, there has been relatively little research on its aging (for a review see Prull, Gabrieli, &...|$|R
40|$|The {{focuses on}} {{environment}} and reverse supply chain have increased in recent years among academic and industry circle. Yet, Bangladesh poultry is to achieve environmental sustainability in her extended forward and reverse supply chain. In this paper, supply chain model developed based on a case poultry industry. Design science and case method under positivist and quantitative paradigm followed to develop simulation model using simul 8 application to fit the real poultry case. The objectives of this paper are to review literature, develop simulation supply chain model and later tested it through historic data. The results briefly discussed and model capturing the relationship among forward, reverse and mainstream supply chain of the case. Different <b>random</b> <b>trial</b> runs of the simulation model have shown in the result section to find out optimality...|$|E
40|$|We {{consider}} a random trial-based telegraph process, which describes a motion {{on the real}} line with two constant velocities along opposite directions. At each epoch of the underlying counting process the new velocity {{is determined by the}} outcome of a <b>random</b> <b>trial.</b> Two schemes are taken into account: Bernoulli trials and classical Pólya urn trials. We investigate the probability law of the process and the mean of the velocity of the moving particle. We finally discuss two cases of interest: (i) the case of Bernoulli trials and intertimes having exponential distributions with linear rates (in which, interestingly, the process exhibits a logistic stationary density with non-zero mean), and (ii) the case of Pólya trials and intertimes having first Gamma and then exponential distributions with constant rates. Comment: 26 pages, 8 figure...|$|E
40|$|A 2 × 2 randomized, {{factorial}} pretest/posttest group {{design was}} used {{to evaluate the effectiveness of}} self-help smoking cessation methods at the worksite. The study investigated the effect of a multicomponent health education and skill intervention versus the effect of a monetary incentive to the employee for quitting. All employees received, in addition, a standardized self-help smoking cessation manual and maintenance manual. Following agreement to participate and a baseline smoking history, all participants were followed for 6 weeks, 6 months, and 12 months. Saliva was obtained for thiocyanate (SCN) analysis of smoking status. Of the estimated 2000 smokers at the site, 387 smokers were recruited. Employees were randomly assigned to one of four groups. Results of this <b>random</b> <b>trial</b> indicate that those employees receiving a multicomponent program were most successful in quitting and remaining abstinent. The monetary incentive appears to have no effect on quit rate...|$|E
40|$|Contrary {{to popular}} belief, {{we show that}} the optimal {{parameters}} for IBM Model 1 are not unique. We demonstrate that, for a large class of words, IBM Model 1 is indifferent among a continuum of ways to allocate probability mass to their translations. We study {{the magnitude of the}} variance in optimal model parameters using a linear programming approach as well as multiple <b>random</b> <b>trials,</b> and demonstrate that it results in variance in test set log-likelihood and alignment error rate. ...|$|R
40|$|We {{describe}} an implementation of {{floating point numbers}} in Reversible Forth using immutable references, and outline {{the advantages and disadvantages}} of this approach for the user and system. Via a probabilistic algorithm example which requires a large number of <b>random</b> <b>trials</b> to create a sufficient sample size, we demonstrate the disadvantage of a naive program with regard to garbage creation, and its semi-automatic resolution using inbuilt features of the reversible virtual machine. This allows otherwise prohibitively memory-intensive operations to be split into manageable pieces, interim results being saved while garbage is collected after each stage...|$|R
5000|$|The Great Conspiracy <b>Trial.</b> <b>Random</b> House (1970) [...] http://www.amazon.com/great-conspiracy-trial-liberty-Constitution/dp/0394419065/ref=sr_1_7?s=books&ie=UTF8&qid=1427750160&sr=1-7&keywords=jason+epstein ...|$|R
40|$|Recent fMRI {{findings}} indicate that the visual analysis of temporal, spatial, and object-specific patterns engages different regions within the premotor cortex (PMC) (Schubotz and von Cramon, 2001 a). This was taken to reflect an automatic sensorimotor mapping according to a rough somatotopy. The present fMRI study tested that hypothesis, using auditory stimuli. Four tasks were presented in a <b>random</b> <b>trial</b> design. Within each trial, 12 artificial noises were presented sequentially. Participants were required to monitor temporal (when), spatial (where), or qualitative (what) patterns for deviants in a forced-choice task. A baseline controlled for perceptual and response effects. Results replicated premotor activations. Thus, inferior PMC responded to when patterns, dorsal PMC to where patterns, and middle PMC to what patterns. In contrast to former findings in the visual paradigm, auditory what patterns elicited additional activations in inferior PMC, pointing to a dual representation including both manual and articulatory motor effectors...|$|E
40|$|Summary. -A <b>random</b> <b>trial</b> {{in which}} cyclophosphamide, {{nandrolone}} decanoate {{and the two}} drugs in combination {{were used in the}} treatment of advanced breast carcinoma is described. The results suggest that it is preferable to use cyclophosphamide on its own. WATSON and Turner (1959) have suggested that a combination of thiotepa and testosterone is superior to the agents used singly. The object of this study has been to assess whether combination of a proven alkylating agent with an androgenic steroid is more effective than each agent used singly in patients with advanced carcinoma of the breast and within 5 years of the menopause. Provisional results have been reported (Cole, 1970). Because thiotepa proved to be rather toxic, cyclophosphamide was selected for this trial. In an earlier series of 79 patients with breast cancer who received cyclophosphamide a response rate of 30 % (24 / 79) was recorded, as see...|$|E
40|$|We {{introduce}} {{an investment}} algorithm for a market of individual securities. The investment algorithm {{is derived from}} constraints depending on investment parameters in order to limit the risk and {{to take into account}} an individual investor. One constraint is devoted to trading costs. Purchased securities are selected randomly among securities that meet the buy condition, making trading a <b>random</b> <b>trial.</b> Simulations with historical price data are demonstrated for a simple example: The buy condition is evaluated {{on the basis of the}} price relationship for two subsequent trading days and the sales condition is defined by holding securities only for one day. A trading expert evaluates the expected return for the investment algorithm with respect to the random selection. Thus, the expert informs precisely on how many market players perform using the same investment algorithm. Its findings are for a parametrized set of buy conditions simultaneously, which makes a trading expert a valuable tool for theorists as well as for practitioners. In our example, the trading expert demonstrated clearly a significant mean reversion effect for a horizon of one day...|$|E
40|$|Crystallographic studies {{frequently}} {{involve the}} determination of a previously unknown crystal structure; General Structure Analysis System (GSAS) -II provides two methods for this purpose. The Monte Carlo/simulated annealing method is fundamentally stochastic in nature; <b>random</b> <b>trials</b> are tested for suitability by comparing calculated structure factors with a suite of observed ones. In contrast, the charge flipping method may begin with a suite of random structure factor phases, but the subsequent mathematical steps are entirely deterministic even though they appear to display chaotic behavior. This paper will briefly describe these methods as implemented in GSAS-II, illustrating their use with examples...|$|R
40|$|This paper {{presents}} a systematic {{comparative study of}} CMEA (constraint method-based evolutionary algorithm) with several other commonly reported mulitobjective evolutionary algorithms (MOEAs) in solving a three-objective optimization problem. The best estimate of the noninferior space was also obtained by solving this multiobjective (MO) problem using a binary linear programming procedure. Several quantitative metrics are {{used to compare the}} noninferior solutions with respect to relative accuracy, as well as spread and distribution of solutions in the noninferior space. Results based on multiple <b>random</b> <b>trials</b> of the MOEAs indicate that overall CMEA performs better than the other MOEAs for this three-objective problem...|$|R
50|$|Due to few <b>random</b> control <b>trials</b> and {{generally}} weak evidence, {{more research is}} needed to gain a complete understanding of the ideal type and parameters of therapeutic interventions for treatment of acquired brain injuries.|$|R
40|$|The aim of {{this study}} was to {{investigate}} the effectiveness of group counseling with cognitive – behavioral method in reducing mother’s stress of child with mental retardation less than 6 years old covered of Khorramabad province welfare organization (2012). The statistical society of this study consisted of 52 mothers of child with mental retardation who their children had file in the welfare office. 30 persons were selected by simple random sampling and were divided into two groups including trial group (15 persons) and control group (15 persons). The method of study was quasi – experimental way with control group and <b>random</b> <b>trial</b> and data gathering tool such as Friedrich, Greenberg and Crink resources and stress questionnaire. To perform the study; the first step was pretest trial and control group and then 10 group counseling sessions with cognitive- behavioral method had hold among trial group. The control group’s mothers did not receive any counseling. Then, it established post – testing of both group again and another test provided to following – up step for two weeks after test...|$|E
40|$|THE RESULTS of {{treatment}} {{presented in this}} paper are those obtained in Northern Ireland in certain cases of breast cancer during the years 1955 to 1959. The year 1955 was chosen {{for the start of the}} study, as in that year for the first time a sufficient number of simple mastectomies for comparison with radical mastectomies was carried out. For various reasons it was not possible to initiate a <b>random</b> <b>trial</b> though it is fully recognised that such a trial would have been the proper way to investigate the value of each treatment method. The study, therefore, is a retrospective one, and contains within it a group of cases in which thyroid hormone was used as a prophylactic agent against metastases. This group of cases was contrasted by random selection against a similar group receiving no thyroid hormone, and there is no difference in the results {{of treatment}} between the two groups at the period chosen for assessment. A full report of this investigation will be published elsewhere. It is not considered that the presence of these groups can influence the conclusions which can be drawn from the overall results in this paper...|$|E
40|$|Research on {{cognitive}} processes {{in decision making}} has identified heuristics that often work well but sometimes lead to serious errors. This paper presents {{an investigation of the}} performance of heuristics in a complex dynamic setting, characterized by repeated decisions with feedback. There are three components: (1) A simulated task resembling medical decision problems (diagnosis and treatment) is described. (2) Computer models of decision strategies are developed. These include models based {{on cognitive}} heuristics as well as benchmark strategies that indicate the limit of the heuristic strategies' performance. The upper benchmark is based on statistical decision theory, the lower one on <b>random</b> <b>trial</b> and error. (3) Selected task characteristics are systematically varied and their influence on performance evaluated in simulation experiments. Results indicate that task characteristics often studied in past research (e. g., symptom diagonosticity, disease base-rates) have less influence on performance relative to feedback-related aspects of the task. These dynamic characteristics are a major determinant of when heuristics perform well or badly. The results also provide insights about {{the costs and benefits of}} various cognitive heuristics. In addition, the possible contribution of this research to the design and evaluation of decision aids is considered. decision strategies, heuristics, medical decisions...|$|E
40|$|This paper {{presents}} an extension {{to the maximum}} likelihood estimation sample consensus (MLESAC) algorithm by estimating the prior validity of correspondences using both the measured data and a model hypothesis. Validity is determined based on the data set associated with the model that is considered as the best one {{so far in the}} previous <b>random</b> <b>trials.</b> The proposed robust algorithm is applied to estimate the fundamental matrix using randomly generated synthetic test data. Experiment results show that at various outlier ratios the proposed algorithm reduces the Sampson error and is also faster (in {{terms of the number of}} trials) in comparison to other conventional algorithms. 1...|$|R
40|$|The {{recently}} introduced shift method {{is applied to}} detect and characterize burst-pulse vocalizations produced by marine mammals. To this end, burst pulses are modeled as sequences of click-like events that are repeated after a certain inter-click interval (ICI). The shift method is used to first emphasize events that repeat within an input signal. Afterwards, the ICI can be estimated. A qualitative comparison of the method is made against classical cepstrum using real data. The detection performance is measured using <b>random</b> <b>trials</b> of simulated data with impulsive noise. It is shown that although the cepstrum outperforms in Gaussian noise at low signal-to-noise ratio, the shift method performs significantly better in impulsive noise...|$|R
40|$|A set of 15 indolylpyrimidine {{derivatives}} {{with their}} antibacterial activities {{in terms of}} minimum inhibitory concentration against the gram-negative bacteria Pseudomonas aeruginosa and gram-positive Staphylococcus aureus were selected for 2 D {{quantitative structure activity relationship}} (QSAR) analysis. QSAR was performed using a combination of various descriptors such as steric, electronic and topological. Stepwise regression method was used to derive the most significant QSAR equation for predicting the inhibitory activity of this class of molecules. The best QSAR model was further validated by a leave one out technique {{as well as by the}} <b>random</b> <b>trials.</b> A high correlation between experimental and predicted inhibitory values was observed. A comparative picture of behavior of indolylpyrimidines against both of the microorganisms is discussed...|$|R
