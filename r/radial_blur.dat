5|14|Public
50|$|Zoom burst is a {{technique}} which entails the variation of the focal length of a zoom lens during a longer exposure. In the moment that the shutter is opened, the lens is zoomed in, changing the focal length during the exposure. The center of the image remains sharp, while the details away from the center form a <b>radial</b> <b>blur,</b> which causes a strong visual effect, forcing the eye {{into the center of}} the image.|$|E
50|$|Pixel Aspect Ratio must {{be taken}} into {{consideration}} by video editing software products that edit video files with non-square pixels, especially when mixing video clips with different pixel aspect ratios. This would be the case when creating a video montage from various cameras employing different video standards (a relatively rare situation). Special effects software products must also take the pixel aspect ratio into consideration, since some special effects require calculation of the distances from a certain point so that they look visually correct. An example of such effects would be <b>radial</b> <b>blur,</b> motion blur, or even a simple image rotation.|$|E
5000|$|Some of the better-known {{games that}} utilise this are the recent Need for Speed titles, Unreal Tournament III, The Legend of Zelda: Majora's Mask, among many others. There {{are two main}} methods used in video games to achieve motion blur: cheaper full-screen effects, which {{typically}} only take camera movement (and sometimes how fast the camera is moving in 3-D Space to create a <b>radial</b> <b>blur)</b> into mind, and more [...] "selective" [...] or [...] "per-object" [...] motion blur, which typically uses a shader to create a velocity buffer to mark motion intensity for a motion blurring effect {{to be applied to}} or uses a shader to perform geometry extrusion.|$|E
50|$|The {{software}} {{is capable of}} simulating soft-shading using curved gradients within an area so that the animator doesn't have to draw shading into every single frame. There is also {{a wide variety of}} other real-time effects that can be applied to layers or groups of layers like <b>radial</b> <b>blurs,</b> color tweaks that all are resolution-independent. Other features include the ability to control and animate the width of lines at their individual control points, and the ability to link any related data from one object to another. Synfig also works with High Dynamic Range Imaging.|$|R
40|$|Abstract. In {{this paper}} we {{describe}} a virtual ultrasound imaging {{system for the}} simulation of ultrasound guided needle insertion procedures, {{which is designed to}} improve the early training stages of interventional radiology trainees. A pair of calibrated magnetic 3 D motion sensors are used to capture the position and orientation of a mock ultrasound probe and needle, whilst emulational ultrasound images are generated in real-time from a labelled volumetric data set that is non-rigidly aligned to a physical model of human body. To achieve a realistic simulation of ultrasound imaging, a set of volumetric textures are constructed to represent the typical appearance of ultrasound images, and an alpha blending method is applied to produce the <b>radial</b> <b>blurring</b> effect. The procedures of volumetric registration, sensor calibration, construction of texture bank, and image rendering, are presented. ...|$|R
30|$|In this section, {{we study}} in some depth how the {{described}} deformable filtering techniques {{have been applied}} in two SV filtering cases: BLUR 1 (synthetic scaled <b>radial</b> PSFs) and <b>BLUR</b> 3 (Hubble PSFs).|$|R
40|$|Foveal vision {{makes up}} less than 1 % of the visual field. The other 99 % is {{peripheral}} vision. Precisely what human beings see in the periphery is both obvious and mysterious in that we see it with our own eyes but can't visualize what we see, except in controlled lab experiments. Degradation of information in the periphery is far more complex than what might be mimicked with a <b>radial</b> <b>blur.</b> Rather, behaviorally-validated models hypothesize that peripheral vision measures {{a large number of}} local texture statistics in pooling regions that overlap and grow with eccentricity. In this work, we develop a new method for peripheral vision simulation by training a generative neural network on a behaviorally-validated full-field synthesis model. By achieving a 21, 000 fold reduction in running time, our approach is the first to combine realism and speed of peripheral vision simulation to a degree that provides a whole new way to approach visual design: through peripheral visualization...|$|E
40|$|The Smart Image Processing (SIP) {{library was}} {{developed}} to provide automated real-time digital image processing functions on camera phones with integer microprocessors. Many of the functions are not available on commercial camera phones and some are not found even in desktop image processing software. Five patents are pending for key functions in this library. These functions create realistic water reflections in varying weather conditions, perform localized magnification and pinching, transform photographs to perspective view, provide fast, high-quality spin <b>radial</b> <b>blur,</b> and provide a fast integer implementation for arbitrary rotation. Details on all pending patents are given in five chapters of this thesis. Other operations performed by the library include adding fog and shadow, creating a neon image, and creating a translucent comer fold. All library functions have been successfully implemented on an integer microprocessor for real-time performance in an existing camera phone system. The library also provides solutions {{to a number of}} long-standing problems in image processing, including direct application of transforms in subsampled YCbCr and YCrCb images. by Mengyao Zhou. Thesis (M. Eng.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2005. Includes bibliographical references (p. 181 - 183) ...|$|E
40|$|Abstract — Quantitative {{accuracy}} in PET imaging {{is essential for}} longitudinal studies and monitoring tumor response to treatment. The goal of this work {{is to improve the}} quantitative accuracy of whole-body PET imaging through the use of an accurate, measured system model. Past empirically measured system response functions used line sources positioned at various locations in the imaging field of view. Here, we present a practical method for measuring the detector blurring component of a whole-body PET system with a non-collimated point source. We employ Monte Carlo simulations to show that a non-collimated point source is acceptable for modeling the <b>radial</b> <b>blurring</b> present in a PET tomograph. And, we justify the use of a Na 22 point source for collecting these measurements. We measure the system response, simplify it to a two-dimensional function, and incorporate a parameterized version of this response into a modified OSEM algorithm. Reconstructions of measured data from an image quality and line source phantom reveal improved quantitative accuracy and resolution with the modified system model. Index Terms — PET, quantitation, statistical reconstruction, system modeling, PS...|$|R
40|$|Ultrasound is {{currently}} {{widely used in}} clinical diagnosis because of its fast and safe imaging principles. As the anatomical structures present in an ultrasound image are not as clear as CT or MRI. Physicians usually need advance clinical knowledge and experience to distinguish diseased tissues. Fast simulation of ultrasound provides a cost-effective way for the training and correlation of ultrasound and the anatomic structures. In this paper, a novel method is proposed for fast simulation of ultrasound from a CT image. A multiscale method is developed to enhance tubular structures so as to simulate the blood flow. The acoustic response of common tissues is generated by weighted integration of adjacent regions on the ultrasound propagation path in the CT image, from which parameters, including attenuation, reflection, scattering, and noise, are estimated simultaneously. The thin-plate spline interpolation method is employed to transform the simulation image between polar and rectangular coordinate systems. The Kaiser window function is utilized to produce integration and <b>radial</b> <b>blurring</b> effects of multiple transducer elements. Experimental {{results show that the}} developed method is very fast and effective, allowing realistic ultrasound to be fast generated. Given that the developed method is fully automatic, it can be utilized for ultrasound guided navigation in clinical practice and for training purpose...|$|R
40|$|An {{image-based}} {{technique for}} measuring the complex field in the pupil of an imaging system is presented. Two point source images, one with a small modification introduced in the pupil, are combined using a simple and non-iterative algorithm. The non-interferometric method {{is based on the}} change in the optical transfer function (OTF), giving a differential OTF (dOTF). The dOTF includes two images of the complex pupil field, conjugated and reflected about the position of the pupil modification, leaving an overlap that obscures some the the pupil. The overlap can be minimized by introducing the modification {{near the edge of the}} pupil. The overlap region can be eliminated altogether by using a second modification and a third point source image. The pupil field is convolved by the change in the pupil field, so smaller modification areas are preferred. The non-monochromatic light, but the result incurs a proportional <b>radial</b> <b>blurring</b> determined by the fractional bandwidth. We include some simple demonstration experiments, including using a pupil blockage and moving a single deformable mirror actuator as the pupil modification. In each case the complex wavefront is easily recovered, even when the pupil mask is unknown and the wavefront aberrations are large. Comment: 13 pages, 14 figures. Open access in Optical Engineering. [URL]...|$|R
40|$|Projective {{texturing}} is {{a commonly}} used image based rendering technique {{that enables the}} synthesis of novel views from the blended reprojection of nearby views on a coarse geometry proxy approximating the scene. When scene geometry is inexact, aliasing artefacts occur. This introduces disturbing artefacts in applications such as street-level immersive navigation in mobile mapping imagery, since a pixel-accurate modelling of the scene geometry and all its details is {{most of the time}} out of question. The filtered blending approach applies the necessary 1 D low-pass filtering on the projective texture to trade out the aliasing artefacts at the cost of some <b>radial</b> <b>blurring.</b> This paper proposes extensions of the filtered blending approach. Firstly, we introduce Integral Radial Images that enable constant time radial box filtering and show how they can be used to apply box-filtered blending in constant time independently of the amount of depth uncertainty. Secondly, we show a very efficient application of filtered blending where the scene geometry is only given by a loose depth interval prior rather than an actual geometry proxy. Thirdly, we propose a silhouette-aware extension of the box-filtered blending that not only account for uncertain depth along the viewing ray but also for uncertain silhouettes that have to be blurred as well...|$|R
40|$|Despite the {{increasing}} adoption of other imaging modalities, ultrasound guidance {{is widely used}} for surgical procedures and clinical imaging due to its low cost, non-invasiveness, and real-time visual feedback. Many ultrasound-guided procedures require extensive training and where possible training on simulations should be preferred over patients. Computational resources for existing approaches to ultrasound simulation are usually limited by real-time requirements. Unlike previous approaches we simulate freehand ultrasound images from CT data on the Graphics Processing Unit (GPU). We build upon the method proposed by Wein et al. for estimating ultrasound reflection properties of tissue and modify it to a computationally more efficient form. In addition to previous approaches, we also estimate ultrasound absorption properties from CT data. Using NVIDIA’s “Compute Unified Device Architecture ” (CUDA), we provide a physically plausible simulation of ultrasound reflection, shadowing artifacts, speckle noise and <b>radial</b> <b>blurring.</b> The same algorithm {{can be used for}} simulating either linear or radial imaging, and all parameters of the simulated probe are interactively configurable at runtime, including ultrasound frequency and intensity as well as field geometry. With current hardware we are able to achieve an image width of up to 1023 pixels from raw CT data in real-time, without any pre-processing and without any loss of information from the CT image other than from interpolation of the input data. Visual comparison to real ultrasound images indicates satisfactory results. Keywords...|$|R
40|$|Dual or {{multi-layer}} crystal blocks {{have been}} proposed to minimise the <b>radial</b> <b>blurring</b> effect in PET scanners with small ring diameters. We measured two potential PET detector blocks' performance in a configuration which would allow 16 blocks in a ring which could be inserted in a small animal 7 T MRI scanner. Two crystal sizes, 1. 6071. 60 mm 2 and 1. 2071. 20 mm 2, were investigated. Single layer blocks had 10 or 12 mm deep crystals, the dual layer blocks had 4 mm deep crystals on the top layer and 6 mm deep crystals on the bottom layer. The crystals in the dual layer blocks are offset by of the crystal pitch to allow for purely geometric crystal identification. Both were read out with SensL 474 SiPM arrays. The software identifies 64 crystals in the single layer and either 85 or 113 crystals in the dual layer array, (either 49 or 64 in the lower layers and 36 or 49 in the upper layers). All the crystals were clearly visible in the crystal identification images and their resolvability indexes (average FWHM/crystal separation) were shown to range from 0. 29 for the best single layer block to 0. 33 for the densest dual layer block. The best coincidence response FWHM was 0. 95 mm for the densest block at {{the centre of the}} field. This degraded to 1. 83 mm at a simulated radial offset of 16 mm from the centre, while the single layer crystals blurred this result to 3. 4 mm. The energy resolution was 16. 412. 2...|$|R
40|$|Radial stellar {{migration}} in galactic discs has received much attention {{in studies of}} galactic dynamics and chemical evolution, but remains a dynamical phenomenon {{that needs to be}} fully quantified. We present results from Halle et al 2015 and extensions on the churning (change in angular momentum) and <b>blurring</b> (<b>radial</b> epicyclic oscillations) in simulations of bar-dominated discs, and we discuss the influence of radial migration on the dynamical heating of stellar discs...|$|R
30|$|Some of {{the other}} {{recently}} introduced no-reference blur assessment methods include the following: In[41] a method based on multiscale gradients and wavelet decomposition of images is given, an image sharpness based on Riemannian tensor mapping into a non-Euclidean space has been found in[42], <b>radial</b> analysis of <b>blurred</b> images in frequency domain is done in[43] to set an image quality index for blur estimation, and reference[44] presents a perceptual blur method to assess quality of Gaussian blurred images. A method based on blur measure in salient regions has been presented in[45]. The perceptually relevant areas in an image are identified through elements of visual attention, namely, color contrast, object size, orientation, and eccentricity. Quality values in correlation with subjective scores are produced by localizing the degradation measure in these elements.|$|R
40|$|Abstract As {{a result}} of the shallow depth of focus of the optical imaging system, the use of {{standard}} filtered back projection in optical projection tomography causes space-variant tangential blurring that increases with the distance to the rotation axis. We present a novel optical tomographic image reconstruction technique that incorporates the point spread function (PSF) of the imaging lens in an iterative reconstruction. The technique is demonstrated using numerical simulations, tested on experimental optical projection tomography data of single fluorescent beads, and applied to high-resolution emission optical projection tomography imaging of an entire zebrafish larva. Compared to filtered back projection our results show greatly reduced <b>radial</b> and tangential <b>blurring</b> over the entire 5. 2 x 5. 2 mm 2 field of view, and a significantly improved signal to noise ratio...|$|R
40|$|The goal of {{this work}} was to provide {{techniques}} and hardware for 23 Na MRI of the human brain, heart and muscle in a clinical scanner at 1. 5 T. For this purpose, radiofrequency (RF) coils were developed and a transmit/receive switch was adapted to 16. 84 MHz. A 3 D radial gradient echo (GRE) sequence was implemented, with a minimum echo time TEmin = 0. 07 ms for 1 H and 0. 2 ms for 23 Na, allowing to detect both the short (T 2 = 0. 5 ms) and the long (T 2 = 12 - 25 ms) components of the 23 Na NMR signal for total 23 Na content evaluation. A gridding reconstruction algorithm with a Kaiser-Bessel window and a rho filter was implemented and optimised for both 23 Na and 1 H MRI. At an acquisition time Tacq= 10 min and a nominal resolution Dx= 4 mm, the signal-to-noise ratio SNR of the in-vivo 23 Na 3 D radial images was twofold higher than in standard cartesian GRE MRI (TEmin= 2 ms). In the <b>radial</b> images <b>blurring</b> due to T 2 signal decay during data acquisition was observed, reducing the resolution by approximately a factor of two. Both cartesian and radial GRE methods were compared at 1. 5 T and 4 T. An SNR increase of SNR(4 T) /SNR(1. 5 T) ~ 4 was measured in-vivo. In brain tumour patients, a 20 % 23 Na MRI signal increase in the tumour region was detected. A contrast-to-noise ratio CNR = 23 % between healthy tissue and tumour achieved with the 3 D radial was 20 % higher than the CNR of the cartesian sequence. In patients with a 23 Na channel disfunction, a 23 Na MRI signal increase of ~ 10 % was measured. This method allows {{for the detection of}} changes in the intracellular 23 Na concentration and may provide a new tool to non-invasively evaluate tissue vitality...|$|R
40|$|Image {{degradation}} generally occurs due to {{transmission channel}} error, camera mis-focus, atmospheric turbulence, relative object-camera motion, etc. Such degradations are unavoidable while a scene is captured through a camera. As degraded images are having less scientiﬁc values, restoration of such images is extremely essential in many practical applications. In this thesis, {{attempts have been}} made to recover images from their degraded observations. Various degradations including, out-of-focus blur, motion blur, atmospheric turbulence blur along with Gaussian noise are considered. Basically image restoration schemes are based on classical, regularisation parameter estimation and PSF estimation. In this thesis, ﬁve diﬀerent contributions have been made based on various aspects of restoration. Four of them deal with spatial invariant degradation and in one of the approach we attempt for removal of spatial variant degradation. Two diﬀerent schemes are proposed to estimate the motion blur parameters. Two dimensional Gabor ﬁlter has been used to calculate the direction of the <b>blur.</b> <b>Radial</b> basis function neural network (RBFNN) has been utilised to ﬁnd the length of the blur. Subsequently, Wiener ﬁlter has been used to restore the images. Noise robustness of the proposed scheme is tested with diﬀerent noise strengths. The blur parameter estimation problem is modelled as a pattern classiﬁcation problem and is solved using support vector machine (SVM). The length parameter of motion blur and sigma (σ) parameter of Gaussian blur are identiﬁed through multi-class SVM. Support vector regression (SVR) has been utilised to obtain a true mapping of the images from the observed noisy blurred image. The parameters in SVR play a key role in SVR performance and these are optimised through particle swarm optimisation (PSO) technique. The optimised SVR model is used to restore the noisy blurred images. Blur in the presence of noise makes the restoration problem ill-conditioned. The regularisation parameter required for restoration of noisy blurred image is discussed and for the purpose, a global optimisation scheme namely PSO is utilisedto minimise the cost function of generalised cross validation (GCV) measure, which is dependent on regularisation parameter. This eliminates the problem of falling into a local minima. The scheme adapts to degradations due to motion and out-of-focus blur, associated with noise of varying strengths. In another contribution, an attempt has been made to restore images degraded due to rotational motion. Such situation is considered as spatial variant blur and handled by considering this as a combination of a number of spatial invariant blurs. The proposed scheme divides the blurred image into a number of images using elliptical path modelling. Each image is deblurred separately using Wiener ﬁlter and ﬁnally integrated to construct the whole image. Each model is studied separately, and experiments are conducted to evaluate their performances. The visual as well as the peak signal to noise ratio (PSNR in dB) of restored images are compared with competent recent schemes...|$|R

