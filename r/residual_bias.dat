80|161|Public
40|$|We {{discuss in}} this paper the {{underlying}} physics of a <b>residual</b> <b>bias</b> phenomenon, whereby the metalized Mylar films of air‐coupled film transducers accept and retain a residual electrostatic charge. Experimental measurements to demonstrate and quantify this effect are reported here, along with a hypothesis of the mechanism of charge transfer and embedding. The measurements show the amplitude performance of the capacitive film transducers {{as a function of}} applied bias voltage and frequency. Factors such as humidity and decay time also play roles in the acquisition and holding of charge on a film. We hypothesize that charge transfers from the conductive backplate and collects on the non‐metalized side of the film. The charged films therefore are electrostatically attracted to the transducer backplate even with no applied voltage bias. Typically, an externally applied bias voltage is needed to charge the capacitor. With a persistent <b>residual</b> <b>bias</b> effect, these air‐coupled capacitive film transducers could be used like conventional piezoelectric transducers with no biasing required. This effect has substantial implications for the operation of air‐coupled film transducers...|$|E
40|$|Model {{applicability}} to core-scale {{solute transport}} is evaluated using breakthrough data from column experiments conducted with conservative tracers tritium (H- 3) and sodium- 22, and the retarding solute uranium- 232. The three models considered are single-porosity, double-porosity with single-rate mobile-immobile mass-exchange, and the multirate model, {{which is a}} deterministic model that admits the statistics of a random mobile-immobile mass-exchange rate coefficient. The experiments were conducted on intact Culebra Dolomite core samples. Previously, {{data were analyzed using}} single- and double-porosity models although the Culebra Dolomite is known to possess multiple types and scales of porosity, and to exhibit multirate mobile-immobile-domain mass transfer characteristics at field scale. The data are reanalyzed here and null-space Monte Carlo analysis is used to facilitate objective model selection. Prediction (or <b>residual)</b> <b>bias</b> is adopted as a measure of the model structural error. The analysis clearly shows single- and double-porosity models are structurally deficient, yielding late-time <b>residual</b> <b>bias</b> that grows with time. On the other hand, the multirate model yields unbiased predictions consistent with the late-time - 5 / 2 slope diagnostic of multirate mass transfer. The analysis indicates the multirate model is better suited to describing core-scale solute breakthrough in the Culebra Dolomite than the other two models...|$|E
30|$|As {{explained}} earlier, using Hypr-IDM-Hypr, it {{is possible}} to correct for PVE while preserving SNR even in the case of low statistics (Fig.  4). This was not possible when IDM was combined with spatial noise regularisation. Although Hypr-IDM-Hypr was able to substantially correct for PVE, complete recovery was not possible (Fig.  4 b). PVE also depends on the tissue fraction within a voxel (as a result of the voxel size), which cannot be corrected using IDM and HYPR. This likely explains the observed <b>residual</b> <b>bias</b> of about 10 – 15 % in the measured grey matter activity concentrations of the Hoffman phantom.|$|E
40|$|Over {{the past}} few years the network-based GPS {{surveying}} technique has been widely discussed. The main advantage of the network-based technique is that the distance-dependent errors (i. e, <b>residual</b> atmospheric <b>biases</b> and orbit error effects) can be reduced and the performance of conventional single reference station, carrier phase-based techniques can be extended over longer baselines. However, even though the errors can largely be reduced by such network techniques, in practice the positioning performance is still affected by the <b>residual</b> <b>biases</b> due to imperfect network functional models. The <b>residual</b> <b>biases</b> contribute to the noise terms {{and it is difficult to}} define a functional model that can deal with them. An alternative approach is to account for these <b>residual</b> <b>biases</b> (and observation noise) within the stochastic model. In this study, a network stochastic model estimated from least squares residuals is proposed to account for residual systematic errors. Using a twostage approach, the network measurements are transformed into a new set of measurements which are largely free of temporal correlations. The variancecovariance matrix of the transformed measurements can be estimated using a rigorous statistical method. The analysis of residual time series shows that more realistic positioning results can be obtained with the proposed network stochastic model. This paper will describe the proposed stochastic modelling method fo...|$|R
40|$|Precise RTK {{positioning}} {{is usually}} performable only on short length bases, to limit distance correlated biases, as atmosphere and ephemerides. However, {{it is possible}} to recover some <b>residual</b> <b>biases</b> also over long distance using appropriate area models, improving the performances of long base RTK positioning up to 100 km base length. Permanent reference station networks are used to estimate the bias model in surveying type applications requiring centimeter accuracy, reducing the worth of traditional single baseline methods. The well known advantages provided by reference station network information include improved modeling of the residual tropospheric, ionospheric and orbit biases. The system state vector, including the parameters of the bias model, is evaluated via Kalman filtering from the undifferenced observation equations. On the rover side, corrections are applied to the observations as single differences, then the model estimates and recovers the undifferentiated <b>residual</b> <b>biases.</b> 1...|$|R
40|$|Residual confounding, after {{adjustment}} for age, {{is the major}} criticism of observational studies on breast cancer screening effectiveness. We developed realistic scenarios for the prevalence and strength of risk factors on screened and not screened groups, and explored the impact of <b>residual</b> confounding <b>bias.</b> Our results demonstrate that <b>residual</b> confounding <b>bias</b> is a minor issue in screening programme evaluations...|$|R
40|$|We {{discuss the}} {{analytic}} {{properties of the}} cross-power spectrum estimator from multi-detector CMB anisotropy maps. The method is computationally convenient and it provides unbiased estimates under very broad assumptions. We also propose a new procedure to test {{for the presence of}} <b>residual</b> <b>bias</b> due to improper noise subtraction in pseudo-C_ℓ estimates. We derive the analytic behaviour of this procedure under the null hypothesis, and use Monte Carlo simulations to investigate its efficiency properties, which appear very promising. For instance, for full sky maps with isotropic white noise the test is able to identify an error of 1...|$|E
40|$|Withdrawn) This work {{describes}} an efficient user-side method of calibrating and correcting quantum annealing computers. For quantum annealing computers {{based on the}} Ising model, the method measures the <b>residual</b> <b>bias</b> of the h and J coefficients. Once measured, these biases can then be nulled in subsequent runs for any problem of interest. This method also returns a temperature for each qubit {{based on the measured}} versus the expected qubit distributions computed from a Boltzmann distribution model. Comment: This preprint was withdrawn because the theoretical discussion of the inferred temperature of qubit couplers assumes an equilibrium distribution, which is not the case during the annealing cycle...|$|E
40|$|We {{discuss the}} {{derivation}} of the analytic {{properties of the}} crosspower spectrum estimator from multi-detector CMB anisotropy maps. The method is computationally convenient and it provides unbiased estimates under very broad assumptions. We also propose a new procedure for testing {{for the presence of}} <b>residual</b> <b>bias</b> due to inappropriate noise subtraction in pseudo-C(l) estimates. We derive the analytic behaviour of this procedure under the null hypothesis, and use Monte Carlo simulations to investigate its efficiency properties, which appear very promising. For instance, for full sky maps with isotropic white noise, the test is able to identify an error of 1 % on the noise amplitude estimate...|$|E
40|$|Fermentation is {{a complex}} {{phenomenon}} well studied which still provides challenges to brewers. In this study, artificial neural network, precisely multi layer perceptron and recurrent one were utilised for modelling either static (yeast quantity to add to wort for fermentation) or dynamic (fermentation process) phenomena. In both cases, the simulated responses {{are very close to}} the observed ones with <b>residual</b> <b>biases</b> inferior to 4. 5 %. Thus, ANN models present good predictive ability confirming the suitability of ANN for industrial process modelling...|$|R
50|$|The primary {{advantage}} of utilizing the Schmidt-Kalman filter instead {{of increasing the}} dimensionality of the state space is the reduction in computational complexity. This can enable the use of filtering in real-time systems. Another usage of Schmidt-Kalman is when <b>residual</b> <b>biases</b> are unobservable; that is, {{the effect of the}} bias cannot be separated out from the measurement. In this case, Schmidt-Kalman is a robust way to not try and estimate the value of the bias, but only keep track of the effect of the bias on the true error distribution.|$|R
40|$|The {{potential}} of a semidynamic method for an estimation of satellite position was investigated in a real data environment, using observations of Lageos collected during the MERIT campaign. In this method, quasi-simultaneous laser range observations of Lageos by pairs of stations were transformed to simultaneous range differences (SRDs), {{in order to reduce}} the effects of orbital and observational <b>residual</b> <b>biases.</b> Baselines obtained via the SRD method were compared to those obtained by the geometric method. It was found that, for baselines of regional extent, the SRD method is very efficient and at least as accurate as the more complex dynamic methods...|$|R
40|$|This paper {{describes}} the near-infrared detector system noise generator (NG) that we {{wrote for the}} James Webb Space Telescope (JWST) Near Infrared Spectrograph (NIRSpec). NG simulates many important noise components including; (1) white "read noise", (2) <b>residual</b> <b>bias</b> drifts, (3) pink 1 /f noise, (4) alternating column noise, and (5) picture frame noise. By adjusting the input parameters, NG can simulate noise for Teledyne's H 1 RG, H 2 RG, and H 4 RG detectors with and without Teledyne's SIDECAR ASIC IR array controller. NG {{can be used as}} a starting point for simulating astronomical scenes by adding dark current, scattered light, and astronomical sources into the results from NG. NG is written in Python- 3. 4...|$|E
40|$|This paper {{analyzes}} {{the relationship between}} a firm’s demand for different quality auditors and opportunities for earnings management. In our model, the firm simultaneously chooses the bias it introduces into its pre-audited earnings and the quality of its auditor. We show that firms that choose a highlevel of bias also choose a low-quality auditor, even though the market-maker makes a correction for the level of <b>residual</b> <b>bias</b> in audited reports. Firms that choose a low level of bias choose a high-quality auditor. We also study the effect of changes in the regulatory environment on the market equilibrium. Our analysis shows that stricter regulation leads to more firms choosing low-quality auditors, thus it is not in the interest of high quality auditors to support such measures. </p...|$|E
40|$|We {{describe}} work {{conducted to}} calibrate and then validate {{the geometry of}} ENVISAT ASAR products. A systematic error in range location was observed in ASAR products during the commissioning phase. A careful and complete analysis has been performed to establish the precise error. It has been compensated by updating the range gate bias (or sampling window start time bias). Validation of the absolute location accuracy of most ASAR products was performed subsequently. The location of surveyed targets is predicted using the satellite state vectors and ancillary timing information via the range and Doppler equations. The prediction's accuracy is affected by instrument bias, ionospheric and atmospheric path delay, as well as target survey errors. Transponders are in addition subject to internal delay uncertainty. The positions of the strong transponder and corner reflector targets in the images are measured to sub-sample accuracy by employing large oversampling factors. Initial and <b>residual</b> <b>bias</b> determinations were made using image acquisitions covering transponders and corner reflectors in the Netherlands, Canada, and Switzerland. Using {{a large number of}} independent targets helps reduce the influence of their independent survey errors. The highest resolution slant range single look complex (SLC) products (IMS, APS) were mainly used for testing. In addition, absolute location error was also measured on selected ground range products (IMP, APP, IMM, APM, WSM). Some ground range products also require treatment of multiple slant/ground range polynomials- proper handling is validated. For all test cases processed with precise orbits to date, the <b>residual</b> <b>bias</b> in the slant range direction has been smaller than the size of a single range sample. Predictability of target image location within ASAR image products is very high-better than experience with ERS- 1 / 2, JERS- 1, and RADARSAT- 1. This result is encouraging, as it opens possibilities for ground control point (GCP) free terrain-geocoding and simplified interferometric processing...|$|E
40|$|A new {{format for}} {{presenting}} {{uncertainty in the}} results of multiple epidemiologic studies of the same outcome is suggested. A set of 95 % confidence intervals for relative risk, RR, is transformed to a frequency distribution of the normalized deviations, ln(RR) /SE(ln(RR)), from the null value ln(RR) =O (RR=l). I assume that deviations from RR = 1 are due to unaccounted <b>residual</b> <b>biases</b> and compare the distribution of these deviations with the distributions of the actual errors in physical measurements where the true values have subsequently become known, and the incidence of large errors can be estimated. Comparison of these distributions can, by analogy, help to understand how convincing is the evidence of elevated risk in observational studies. ...|$|R
40|$|Real-time high {{precision}} GPS/GLONASS surveying and navigation applications have been constrained to the short-range case {{due to the}} presence of distancedependent biases in the between-receiver singledifferenced observables. Over the past few years, the use of a GPS/GLONASS reference station network approach, to extend the inter-receiver distances (user-to-reference receiver separation), has shown great promise. In order to account for the distance-dependent <b>residual</b> <b>biases,</b> such as the atmospheric biases and orbit errors, several techniques have been developed. They include the Linear Combination Model, Distance-Based Linear Interpolation Method, Linear Interpolation Method, Lower-Order Surface Model, and Least [...] Squares Collocation. All of these methods aim to model (or interpolate) the distancedependent biases between the base station(s) and the user receiver with the support of a multiple reference station network...|$|R
40|$|One of {{the most}} pernicious {{theoretical}} systematics facing upcoming gravitational lensing surveys is the uncertainty introduced by the effects of baryons on the power spectrum of the convergence field. One method that has been proposed to account for these effects is to allow several additional parameters (that characterize dark matter halos) to vary and to fit lensing data to these halo parameters concurrently with the standard set of cosmological parameters. We test this method. In particular, we use this technique to model convergence power spectrum predictions from a set of cosmological simulations. We estimate biases in dark energy equation of state parameters that would be incurred {{if one were to}} fit the spectra predicted by the simulations either with no model for baryons, or with the proposed method. We show that neglecting baryonic effect leads to biases in dark energy parameters that are several times the statistical errors for a survey like the Dark Energy Survey. The proposed method to correct for baryonic effects renders the <b>residual</b> <b>biases</b> in dark energy equation of state parameters smaller than the statistical errors. These results suggest that this mitigation method may be applied to analyze convergence spectra from a survey like the Dark Energy Survey. For significantly larger surveys, such as will be carried out by the Large Synoptic Survey Telescope, the biases introduced by baryonic effects are much more significant. We show that this mitigation technique significantly reduces the biases for such larger surveys, but that a more effective mitigation strategy will need to be developed in order ensure that the <b>residual</b> <b>biases</b> in these surveys fall below the statistical errors. Comment: 16 pages, 9 figures. Submitted to Physical Review D. Comments Welcom...|$|R
40|$|Aclinician may {{be faced}} with the question“What is the risk of drug-induced liverinjury if I {{prescribe}} drug X compared with drug Y? ” In a related CMAJ article, Pater-son and colleagues report a significantly higher risk of drug-induced liver injury {{with the use of}} levofloxacin and moxifloxacin compared with clarithromycin, ciprofloxacin or cefuroxime. 1 However, <b>residual</b> <b>bias</b> and the rarity of hep-atotoxicity for all of the agents studied means that the choice between these antibiotics remains a matter of clinical need rather than hedging the risk of toxicity. In other words, one should still choose the antibiotic most likely to cover the infection and worry less about the liver. Nevertheless, if a clinician has narrowed the choice to 2 or 3 drugs, he or she may just want t...|$|E
40|$|This paper {{deals with}} small area {{indirect}} estimators under area level ran- dom effect models when only area level {{data are available}} and the random effects are correlated. The performance of the Spatial Empirical Best Linear Unbiased Predictor (SEBLUP) is explored with a Monte Carlo simulation study on lattice data and it {{is applied to the}} results of the sample survey on Life Conditions in Tuscany (Italy). The mean squared error (MSE) problem is discussed illustrating the MSE estimator in comparison with the MSE of the empirical sampling distribution of SEBLUP esti- mator. A clear tendency in our empirical findings is that the introduction of spatially correlated random area effects reduce both the variance and the bias of the EBLUP estimator. Despite some <b>residual</b> <b>bias,</b> the coverage rate of our confidence intervals comes close to a nominal 95 %...|$|E
40|$|Background: Selecting {{covariates}} for adjustment or {{inclusion in}} propensity score (PS) analysis is a trade-off between reducing confounding bias and {{a risk of}} amplifying <b>residual</b> <b>bias</b> by unmeasured confounders. Objectives: To assess the covariate balancing properties of PS matching with respect to unmeasured covariates {{and its impact on}} bias. Methods: Simulation studies were conducted in binary covariates, treatment and outcome data. In different scenarios, instrumental variables (IV, i. e., variables related to treatment but not to the outcome or other covariates), risk factors (variables related only to the outcome), unmeasured covariates, and confounders with various associations among each other were considered. Treatment effects estimates (risk ratio) were derived after PS matching using Poisson models; balance for each covariate was checked before and after matching using the absolute standardized difference. The choice of covariates for the PS model was compared with respect to bias in the treatment-outcome relation and balance of (unobserved) covariates. Results: PS matching improved balance of measured covariates included in the PS model but exacerbated the imbalance of the unmeasured covariate that was unrelated to measured covariates compared to the full unmatched sample. Inclusion of instrumental variables, independent of unmeasured covariates, exacerbated the imbalance in unmeasured covariates and amplified the <b>residual</b> <b>bias.</b> However, including instrumental variables that were associated with unmeasured covariates improved the balance of unmeasured covariates and reduced bias. When the PS model included variables related to the outcome, exclusion of instrumental variables that were related to unmeasured covariates exacerbated the balance of unmeasured covariates and increased the bias. Conclusions: In choosing covariates for a PS model, the pattern of association among covariates has substantial impact on other covariates' balance and the bias of the treatment effect. Investigators should not rely only on covariate association with treatment or outcome but should take into account possible associations among covariates and explore the balance of other covariates after PS matching...|$|E
30|$|In the following, we {{use this}} idea to correct {{for some of}} the {{potential}} <b>residual</b> unobserved ability <b>bias</b> in our augmented wage regression.|$|R
40|$|The {{observational}} {{record for}} determining Outgoing Longwave Radiation (OLR) from satellites remains largely fragmented with gaps {{over the past}} three decades among the Earth Radiation Budget Experiment (ERBE), Earth Radiation Budget Satellite (ERBS) and Clouds and the Earth s Radiant Energy System (CERES) measurements. Multi-band OLR retrievals are thus an important supplement to the broadband measurements. The most semi-continuous set of OLR retrievals comes from the University of Maryland (UMD) algorithm that uses four HIRS (High Resolution Infrared Sounder) channels on the NOAA polar orbiting satellites to estimate OLR. but <b>residual</b> <b>biases</b> due principally to diurnal drift of the polar orbiter platforms remain an issue. Here we show how an alternative recalibration of the UMD retrievals taking advantage of the relative diurnal drift rates between "morning" and "evening" satellite platforms removes much of the remaining uncertainty due to changes in equator crossing times...|$|R
40|$|This paper {{studies the}} finite sample {{properties}} of the kernel regression method of Boudoukh et al. (1998) for estimating multifactor continuous-time term structure models. Monte Carlo simulations are employed, with a grid-search technique to find the optimal kernel bandwidth. The estimator exhibits truncation and correlated <b>residuals</b> <b>biases</b> near {{the boundaries of the}} data. However, the variance of the estimator is so high that the biases are unlikely to be relevant from a hypothesis testing point of view. The performance of the estimator is also studied under model misspecification. Irrelevant regressors reduce efficiency and induce additional biases in the estimates. Using Treasury bill data, I test whether the estimates produced by the nonparametric estimator are statistically distinguishable from estimates obtained under a parametric model. The kernel regressions pick up nonlinearities in the data that the parametric model cannot capture. Interest rates; Econometric models; Time-series analysis...|$|R
40|$|Circumstances {{in which}} both {{randomized}} controlled trial and observational study data are available provide an important opportunity to identify biases and improve study design and analysis procedures. In addition, joint analyses of data from the two sources can extend clinical trial findings. The US Women’s Health Initiative includes randomized controlled trials of use of estrogen by posthysterectomy women and of estrogen plus progestin by women with a uterus, along with corresponding observational study components. In this paper, for coronary heart disease, stroke, and venous thromboembolism, results are first presented from joint analysis of estrogen clinical trial and observational study data to show that <b>residual</b> <b>bias</b> patterns {{are similar to those}} previously reported for estrogen plus progestin. These findings support certain combined analyses of the observational data on estrogen and the estrogen plus progestin clinical trial and observational study data to give adjusted observational stud...|$|E
40|$|In {{choosing}} covariates for adjustment or {{inclusion in}} propensity score analysis, researchers must weigh {{the benefit of}} reducing confounding bias carried by those covariates against the risk of amplifying <b>residual</b> <b>bias</b> carried by unmeasured confounders. The latter is characteristic of covariates that act like instrumental variables (IV); that is, variables that are more strongly associated with the exposure than with the outcome (1). In {{this issue of the}} journal, Myers et al. (2) compare the bias amplification of a near-IV confounder with its bias-reducing potential and suggest that, in practice, the latter outweighs the former. This commentary sheds broader light on this comparison by considering the cumulative effects of conditioning on multiple covariates, and showing that bias amplification may build up at a faster rate than bias reduction. We further derive a partial order on sets of covariates which reveals preference for conditioning o...|$|E
40|$|Abstract — Fusion of {{data from}} {{multiple}} sensors can be hindered by systematic errors known as biases, which generally include both deterministic and stochastic components. The deterministic errors can be estimated and then used to debias the sensor measurements prior to fusion. However, the remaining stochastic part, typically {{referred to as a}} “residual ” bias, can still severely degrade tracking performance. Specifically, residual biases can lead to degradation in covariance consistency, data misassociation, and spurious/redundant tracks, if left unaddressed. This paper presents an algorithm based on the Schmidt-Kalman filter for mitigating the effects of residual biases on sensor attitude and measurement generation. The algorithm incorporates the <b>residual</b> <b>bias</b> covariance into the track state update and “shapes” the state covariance. We also introduce a Schmidt-IMM filter implementation {{to address the problem of}} maneuvering targets. Simulation studies are presented to demonstrate the effectiveness of the Schmidt-Kalman and the Shcmidt-IMM filters in the presence of residual biases. Significant improvements are shown for data association, covariance consistency, and position/velocity accuracy. I...|$|E
3000|$|The <b>biased</b> <b>residual</b> width at a {{considered}} plane i decreases {{with increasing}} plane distance dz and towards lower beam energies. These effects {{stem from the}} term σ [...]...|$|R
40|$|NASA 2 ̆ 7 s Orbiting Carbon Observatory- 2 (OCO- 2) {{has been}} {{measuring}} carbon dioxide column-averaged dry-air mole fraction, XCO 2, in the Earth 2 ̆ 7 s atmosphere for over 2 years. In this paper, {{we describe the}} comparisons between the first major release of the OCO- 2 retrieval algorithm (B 7 r) and XCO 2 from OCO- 22 ̆ 7 s primary ground-based validation network: the Total Carbon Column Observing Network (TCCON). The OCO- 2 XCO 2 retrievals, after filtering and bias correction, agree well when aggregated around and coincident with TCCON data in nadir, glint, and target observation modes, with absolute median differences less than 0. 4  ppm and RMS differences less than 1. 5  ppm. After <b>bias</b> correction, <b>residual</b> <b>biases</b> remain. These biases appear to depend on latitude, surface properties, and scattering by aerosols. It is thus crucial to continue measurement comparisons with TCCON to monitor and evaluate the OCO- 2 XCO 2 data quality throughout its mission...|$|R
40|$|NASA's Orbiting Carbon Observatory- 2 (OCO- 2) {{has been}} {{measuring}} carbon dioxide column-averaged dry air mole fractions, XCO 2, in the Earth’s atmosphere {{for almost two}} years. In this paper, we describe the comparisons between the OCO- 2 version 7 Br retrievals and XCO 2 estimates from OCO- 2 's primary ground-based validation network: the Total Carbon Column Observing Network (TCCON). The OCO- 2 XCO 2 retrievals, after bias correction, agree well globally with the TCCON for nadir, glint, and target observations, with median differences less than 0. 5 ppm and RMS differences typically below 1. 5 [*]ppm. Target observations over TCCON stations correlate best with the TCCON data (R 2 [*]=[*] 0. 83) on a global scale. At local scales, the target comparisons reveal <b>residual</b> <b>biases</b> likely related to surface properties and aerosol scattering. It is thus crucial to continue measurement comparisons with TCCON to monitor and evaluate the OCO- 2 XCO 2 data quality throughout its mission...|$|R
40|$|Characterization of {{measurement}} uncertainty {{in terms of}} root sums of squares of both un-known systematic as well as random error components is given meaning {{in the sense of}} predic-tion intervals. Both types of errors are commonly encountered with industrial hygiene air monitoring of hazardous substances. Two extreme types {{of measurement}} methods are pre-sented for illustrating how confidence levels may be ascribed to prediction intervals defined by such uncertainty values. In the case of method calibration at each measurement, systematic error or bias may enter from a biased calibrant. At another extreme, a single initial method evaluation may leave <b>residual</b> <b>bias</b> owing to random error in the evaluation itself or to the use of a biased reference method. Analysis is simplified through new simple approximations to probabilistic limits (quantiles) on the magnitude of a non-central Student t-distributed ran-dom variable. Connection is established between traditional confidence limits, accuracy meas-ures in the case of bias minimization and an uncertainty measure...|$|E
40|$|Analysis of {{linkage disequilibrium}} (ȓ 2 =mean squared {{correlation}} of allele frequencies at different gene loci) {{provides a means}} of estimating effective population size (Ne) from a single sample, but this method has seen much less use than the temporal method (which requires at least two samples). It is shown that for realistic numbers of loci and alleles, the linkage disequilibrium method can provide precision {{comparable to that of}} the temporal method. However, computer simulations show that estimates of Ne based on ȓ 2 for unlinked, diallelic gene loci are sharply biased downwards (N^e=N 3 ̆c 0. 1 in some cases) if sample size (S) is less than true Ne. The bias is shown to arise from inaccuracies in published formula for E (ȓ 2) when S and/or Ne are small. Empirically derived modifications to E(ȓ 2) for two mating systems (random mating and lifetime monogamy) effectively eliminate the bias (<b>residual</b> <b>bias</b> in N^e 3 ̆c 5...|$|E
40|$|Fusion of {{data from}} {{multiple}} sensors can be hindered by systematic errors known as biases, which generally include both deterministic and stochastic components. The deterministic errors can be estimated and then used to debias the sensor measurements prior to fusion. However, the remaining stochastic part, typically {{referred to as a}} "residual" bias, can still severely degrade tracking performance. Specifically, residual biases can lead to degradation in covariance consistency, data misassociation, and spurious/redundant tracks, if left unaddressed. This paper presents an algorithm based on the Schmidt-Kalman filter for mitigating the effects of residual biases on sensor attitude and measurement generation. The algorithm incorporates the <b>residual</b> <b>bias</b> covariance into the track state update and "shapes" the state covariance. We also introduce a Schmidt-IMM filter implementation {{to address the problem of}} maneuvering targets. Simulation studies are presented to demonstrate the effectiveness of the Schmidt-Kalman and the Schmidt-IMM filters in the presence of residual biases. Significant improvements are shown for data association, covariance consistency, and position/velocity accuracy...|$|E
40|$|NASA's Orbiting Carbon Observatory- 2 (OCO- 2) {{has been}} {{measuring}} carbon dioxide column-averaged dry-air mole fraction, X CO 2, in the Earth's atmosphere for over 2  years. In this paper, {{we describe the}} comparisons between the first major release of the OCO- 2 retrieval algorithm (B 7 r) and X CO 2 from OCO- 2 's primary ground-based validation network: the Total Carbon Column Observing Network (TCCON). The OCO- 2 X CO 2 retrievals, after filtering and bias correction, agree well when aggregated around and coincident with TCCON data in nadir, glint, and target observation modes, with absolute median differences less than 0. 4  ppm and RMS differences less than 1. 5  ppm. After <b>bias</b> correction, <b>residual</b> <b>biases</b> remain. These biases appear to depend on latitude, surface properties, and scattering by aerosols. It is thus crucial to continue measurement comparisons with TCCON to monitor and evaluate the OCO- 2 X CO 2 data quality throughout its mission...|$|R
3000|$|Assuming {{normally}} distributed <b>residuals,</b> the <b>biased</b> pull distributions {{are normally}} distributed and centred at zero {{with a standard}} deviation of one, N(0, 1), if the material and the scattering therein is known and correctly described. A standard deviation differing from one originates from an under- or overestimated residual prediction √(σ _int^ 2 - σ _t,b^ 2), which in turn stems from an inaccurate estimate of either the intrinsic resolution or the track resolution. The latter is a consequence of inaccurate inputs for the standard deviation Θ [...]...|$|R
40|$|Global Navigation Satellite Systems-Reflectometry (GNSS-R) is an {{emerging}} {{remote sensing technique}} that uses navigation signals reflected on the Earth’s surface as sources of opportunity for scatterometry and altimetry. The time-domain statistics of the electromagnetic bias in GNSS-R altimetry are investigated to assess the <b>residual</b> electromagnetic <b>bias</b> after averaging during the dwell time (as long as 100 s). A three-dimensional time-evolving sea surface is generated using Elfouhaily’s ocean surface height spectrum and spreading function. This surface is illuminated by a right hand circular polarization electromagnetic wave at L-band. Then, the scattered waves are computed using the Physical Optics method under the Kirchhoff Approximation. The electromagnetic bias is estimated using a numerical technique previously validated at C- and Ku-bands, and then extrapolated at L-band. Montecarlo simulations for different sea surface realizations consecutive in time are performed so as to analyze the electromagnetic bias statistics up to the 4 PthP order moments. Histograms and distribution of the time domain electromagnetic bias are also used for statistical interpretation. All statistical descriptors confirmed that the electromagnetic bias has a non-Gaussian behavior. This study is important to assess the <b>residual</b> electromagnetic <b>bias</b> in future GNSS-R altimetry missions, such as the “GNSS Reflectometry, Radio Occultation and Scatterometry on board the International Space Station” experiment onboard the International Space Station...|$|R
