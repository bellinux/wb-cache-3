11|7|Public
50|$|Discover {{method was}} {{designed}} to model all the discovery methods possible in OLEDB including various schema <b>rowset,</b> properties, keywords, etc. Discover method allows users to specify both {{what needs to be}} discovered and the possible restrictions or properties.The result of Discover method is a <b>rowset.</b>|$|E
5000|$|Some <b>Rowset</b> class methods (Select, SelectNew, Fill, and so on.) ...|$|E
50|$|The {{result of}} Execute command could be Multidimensional Dataset or Tabular <b>Rowset.</b>|$|E
5000|$|When {{discussing}} {{access to}} distributed databases, Microsoft favors the term distributed query, which it defines in protocol-specific manner as [...] "any SELECT, INSERT, UPDATE, or DELETE statement that references tables and <b>rowsets</b> {{from one or}} more external OLE DB data sources".Oracle provides a more language-centric view in which distributed queries and distributed transactions form part of distributed SQL.|$|R
50|$|OLE DB {{separates}} the data store from the application that needs {{access to it}} {{through a set of}} abstractions that include the datasource, session, command, and <b>rowsets.</b> This was done because different applications need access to different types and sources of data, and do not necessarily want to know how to access functionality with technology-specific methods. OLE DB is conceptually divided into consumers and providers. The consumers are the applications that need access to the data, and the providers are the software components that implement the interface and thereby provides the data to the consumer. OLE DB is part of the Microsoft Data Access Components (MDAC) stack.|$|R
5000|$|The OLE DB/SQL API {{implements}} the functionality for searching and querying {{across the}} indices and property stores. It uses {{a variant of}} SQL in which to represent the query (regular SQL with certain restrictions) and returns results as OLE DB <b>Rowsets.</b> Whenever a query executes, {{the parts of the}} index it used are temporarily cached so that further searches filtering the result set need not access the disk again, in order to improve performance. Windows Search stores its index in an Extensible Storage Engine file named [...] that exists, by default, in the [...] folder {{at the root of the}} system drive in Windows Vista or in later versions of Windows. (The corresponding location in Windows XP is [...] inside the [...] folder.) ...|$|R
50|$|The SQL From clause is {{the source}} of a <b>rowset</b> to be {{operated}} upon in a Data Manipulation Language (DML) statement. From clauses are very common, and will provide the <b>rowset</b> to be exposed through a Select statement, the source of values in an Update statement, and the target rows to be deleted in a Delete statement.|$|E
5000|$|The From clause can {{generally}} be anything that returns a <b>rowset,</b> a table, view, function, or system-provided information like the Information Schema, which is typically running proprietary commands and returning {{the information in}} a table form.|$|E
50|$|Starting with version 3.1, JDBC {{has been}} {{developed}} under the Java Community Process. JSR 54 specifies JDBC 3.0 (included in J2SE 1.4), JSR 114 specifies the JDBC <b>Rowset</b> additions, and JSR 221 is the specification of JDBC 4.0 (included in Java SE 6).|$|E
2500|$|The OLE DB/SQL API {{implements}} the functionality for searching and querying {{across the}} indices and property stores. It uses {{a variant of}} SQL in which to represent the query (regular SQL with certain restrictions) and returns results as OLE DB <b>Rowsets.</b> Whenever a query executes, {{the parts of the}} index it used are temporarily cached so that further searches filtering the result set need not access the disk again, in order to improve performance. Windows Search stores its index in an Extensible Storage Engine file named Windows.edb that exists, by default, in the [...] \ProgramData\Microsoft\Search\Data\Applications\Windows\ folder {{at the root of the}} system drive in Windows Vista or in later versions of Windows. (The corresponding location in Windows XP is \All Users\Application Data\Microsoft\Search\Data\Applications\Windows\ inside the Documents and Settings folder.) ...|$|R
40|$|We {{explore the}} {{applicability}} of parallel processing techniques for OLAP query processing. In particular, we exploit the natural partitionability of a star schema and render it even more efficient by applying a storage and access structure that serves both as an index as well as data and lends itself naturally to vertical partitioning of the data. We propose a declustering strategy which incorporates both task and data partitioning and present the Parallel Star Join (PSJ) algorithm, which provides a means to perform a star join in parallel using efficient operations involving only <b>rowsets</b> and projection columns. We compare the performance of this algorithm with two parallel query processing strategies. The first strategy is a parallel join strategy utilizing the Bitmap Join Index (BJI), arguably {{the state of the}} art OLAP join structure in use today. For the second strategy we choose a well known parallel join algorithm from the OLTP domain, namely the Hybrid Hash algorithm. To assist in [...] ...|$|R
40|$|This paper {{presents}} an architecture {{overview of the}} distributed, heterogeneous query processor (DHQP) in the Microsoft SQL Server database system to enable queries over a large collection of diverse data sources. The paper highlights three salient aspects of the architecture. First, the system introduces welldefined abstractions such as connections, commands, and <b>rowsets</b> that enable sources to plug into the system. These abstractions are formalized by the OLE DB data access interfaces. The generality of OLE DB and its broad industry adoption enables our system to reach a very large collection of diverse data sources ranging from personal productivity tools, to database management systems, to file system data. Second, the DHQP is built-in to the relational optimizer and execution engine of the system. This enables DH queries and updates {{to benefit from the}} cost-based algebraic transformations and execution strategies available in the system. Finally, the architecture is inherently extensible to support new data sources as they emerge as well as serves as a key extensibility point for the relational engine to add new features such as full-text search and distributed partitioned views. 1...|$|R
5000|$|... dBase {{features}} an IDE with a Command Window and Navigator, a just-in-time compiler, a preprocessor, a virtual-machine interpreter, a linker for creating dBase application [...]EXEs, a freely available runtime engine, and numerous two-way GUI design tools including a Form Designer, Report Designer, Menu Designer, Label Designer, Datamodule Designer, SQL Query Designer, and Table Designer. Two-way Tools {{refers to the}} ability to switch back and forth between using a GUI design tool and the source code editor. Other tools include a Source Code Editor, a Project Manager that simplifies building and deploying a dBase application, and an integrated Debugger. dBase features structured exception handling and has many built-in classes that can be subclassed via single inheritance. There are visual classes, data classes, and many other supporting classes. Visual classes include Form, SubForm, Notebook, Container, Entryfield, RadioButton, SpinBox, ComboBox, ListBox, PushButton, Image, Grid, ScrollBar, ActiveX, Report, ReportViewer, Text, TextLabel and many others. Database classes include Session, Database, Query, <b>Rowset,</b> Field, StoredProc and Datamodule classes. Other classes include File, String, Math, Array, Date, Exception, Object and others. dBase objects can be dynamically subclassed by adding new properties to them at runtime.|$|E
40|$|Recent {{advances}} in atomic algorithms and cacheable communication are usually {{at odds with}} the transistor. After years of technical research into evolutionary programming, we argue the development of Smalltalk. our fo-cus in our research is not on whether Inter-net QoS and voice-over-IP can interfere to solve this quagmire, but rather on describ-ing a peer-to-peer tool for controlling SMPs (<b>RowSet).</b> ...|$|E
40|$|Large {{organizations}} have {{a multitude of}} data sources across the enterprise and want to obtain business value from all of them. While {{the majority of these}} data sources may be consolidated in an enterprise data warehouse, many business units have their own data marts where analysis is carried out against data stored in multidimensional data structures. It is often critical to pose queries which span both these sources. This is a challenge since these sources have differing models and query languages (SQL vs MDX). The Siebel Analytics Server enables this requirement to be fulfilled. In this paper, we describe how the multidimensional metadata is modeled relationally within Siebel Analytics, efficient SQL to MDX translation algorithms and the conversion protocols required to convert a multidimensional result into a relational <b>rowset.</b> 1...|$|E
40|$|As a {{high level}} {{development}} environment, the Java technologies offer support to the development o f distributedapplications, independent of the platform, providing a robust set of methods to access the databases, used to createsoftware components on the server side, {{as well as on}} the client side. Analyzing the evolution of Java tools to access data, we notice that these tools evolved from simple methodsthat permitted the queries, the insertion, the update and the deletion of the data to advanced implementations such asdistributed transactions, cursors and batch files. The client-server architectures allows through JDBC (the Java Database Connectivity) the execution of SQL(Structured Query Language) instructions and the manipulation of the results in an independent and consistent manner. The JDBC API (Application Programming Interface) creates the le vel of abstractization needed to allow the call ofSQL queries to any DBMS (Database Management System). In JDBC the native driver and the ODBC (Open DatabaseConnectivity) -JDBC bridge and the classes and interfaces of the JDBC API will be described. The four steps needed to build a JDBC driven application are presented briefly, emphasizing on the way eachstep has to be accomplished and the expected results. In each step there are evaluations on the characteristics of thedatabase systems and the way the JDBC programming interface adapts to each one. The data types provided by SQL 2 and SQL 3 standards are analyzed by comparison with the Java data types,emphasizing on the discrepancies between those and the SQL types, but also the methods that allow the con versionbetween different types of data through the methods of the ResultSet object. Starting from the metadata role and studying the Java programming interfaces that allow the query of resultsets, we will describe the advanced features of the data mining with JDBC. As alternative to result sets, the <b>Rowsets</b> add new functionalities that enhance the flexibility of the applications. These are analyzed and the approach is described. Next, we will describe Java Data Objects (JDO) Application Programming Interf ace, which is a way to storepersistent data in databases, using plain old Java objects (POJO) to represent persistent data. The approach makespossible separation between data manipulation and database manipulatio...|$|R
40|$|On-Line Analytical Processing (OLAP) {{refers to}} the {{technologies}} that allow users to eÆciently retrieve data from the data warehouse for decision-support purposes. Data ware-houses tend to be extremely large- {{it is quite possible}} for a data warehouse to be hundreds of gigabytes to terabytes in size [3]. Queries tend to be complex and ad-hoc, often requir-ing computationally expensive operations such as joins and aggregation. Given this, we are interested in developing strategies for improving query processing in data warehouses by exploring the applicability of parallel processing techniques. In particular, we exploit the natural partitionability of a star schema and render it even more eÆcient by apply-ing DataIndexes { a storage structure that serves both as an index as well as data and lends itself naturally to vertical partitioning of the data. Dataindexes are derived from the various special purpose access mechanisms currently supported in commercial OLAP products. Specically, we propose a declustering strategy which incorporates both task and data partitioning and present the Parallel Star Join (PSJ) Algorithm, which provides a means to perform a star join in parallel using eÆcient operations involving only <b>rowset...</b>|$|E
40|$|This paper proposes an {{algorithm}} to hierarchically cluster documents. Each {{cluster is}} actually a cluster of documents and an associated cluster of words, thus a document–word co-cluster. Note that, the vector model for documents creates the document–word matrix, of which every co-cluster is a submatrix. One would intuitively expect a submatrix made up of high values {{to be a good}} document cluster, with the corresponding word cluster containing its most distinctive features. Our algorithm looks to exploit this. We have defined matrix density, and our algorithm basically uses matrix density considerations in its working. The algorithm is a partitional–agglomerative algorithm. The partitioning step involves the identification of dense submatrices so that the respective row sets partition the row set of the complete matrix. The hierarchical agglomerative step involves merging the most “similar ” submatrices until we are down to the required number of clusters (if we want a flat clustering) or until we have just the single complete matrix left (if we are interested in a hierarchical arrangement of documents). It also generates apt labels for each cluster or hierarchy node. The similarity measure between clusters used for merging is {{based on the fact that}} the clusters here are co-clusters, and is a key point of difference from existing agglomerative algorithms. We will refer to the proposed algorithm as RPSA (<b>Rowset</b> Partitioning and Submatrix Agglomeration). We have compared it as a clustering algorithm with Spherical K-Means and Spectral Graph Partitioning. We have also evaluated some hierarchies generated by the algorithm...|$|E

