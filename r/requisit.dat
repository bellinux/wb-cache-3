17|17|Public
5000|$|In {{the midst}} of the Revolution, and with {{financial}} backing from his father and his uncle, Dr. John Phillips, Samuel Phillips Jr. founded Phillips Academy in Andover. It opened April 21, 1778. He was a charter member of the American Academy of Arts and Sciences in 1780. Like the rest of his family and many Massachusetts patriots, Samuel Phillips Jr. was a strict Calvinist, but he was also a practical visionary concerned about the improvement of society. In the preamble to his constitution for the new school, Phillips wrote: [...] "Youth is the important period, on the improvement or neglect of which depend the most important consequences to individuals and the community." [...] He set out [...] "to lay the foundation of a public free School or Academy for the purpose of instructing Youth, not only in English and Latin Grammar, Writing, Arithmetic, and those Sciences, wherein they are commonly taught; but more especially to learn them the Great End and Real Business of Living." [...] From the first, financial aid scholarships were part of the program of Phillips Academy: [...] "This Seminary shall be ever equally open to Youth, with <b>requisit</b> qualification, from every quarter." ...|$|E
40|$|The The developent developent of of an an object-orientated object-orientated {{software}} software prototype {{prototype for}} for a a <b>requisit</b> requisitio <b>requisit</b> requisitio io ions ions ns and and and purc purc purchase purc purc hase order orders order s manag management manag management ement system system syste...|$|E
40|$|Self-assembled DNA {{nanostructures}} {{have been}} recognized {{over the last two}} decades as an interesting construction material in the field of nanotechnology 1. Recently artificially designed self-assembled DNA nanostructures have been reported with various topological structures and functionalities: 1 D and 2 D periodically patterned structures 2 - 5, 3 D polyhedra 6 - 7, nanomechanical devices 8 - 10, and molecular computers 11 - 13. Although DNA possesses <b>requisit...</b>|$|E
40|$|In modern {{business}} correspondingly {{in tourism}} as well, exists the stauning competition that moves market <b>requisits</b> constantously quality management techniques {{are getting more}} and more important. Quality has become crucial surviving factor and competitiveness and profitability must. Surely if quality is to be steadily improved major influential business performance factors have to be obeyed. Practically mostly nothing can be left on its own. Correspondingly it foresees the necessity of Total Quality Management, TQM). 1...|$|R
40|$|Law (1990 : 52) {{with special}} {{provisions}} {{for the care}} of young people (LVU) provides legal requirements that should be met when applying the law. The {{purpose of this study was}} to investigate and analyze LVU judges in two different counties based on section 3 in LVU. The investigation includs four judgments from Stockholm's Administrative Court and four judgments from Uppsala's Administrative Court. The judgement elected for this study were based on Section 3 of the LVU, primarily to be able to analyze the three <b>requisits</b> in the law: abuse, crime and other socially degrading behavior. The judgments were based on all the props contained in the LVU. The method used in the study was a content analysis, in the form of a text analysis. The result of the study shows that there are gender-specific differences in the judgments examined...|$|R
40|$|Added {{engraved}} title-page by Philip Holmes. Advertising: p. [1] at end; final leaf blank. (from title-page) I. Shews {{the drawing of}} men, and other animal creatures, landskips, countries, and figures of various forms [...] II. The way of engraving etching and limning with all their <b>requisits</b> and ornaments [...] III. The way of painting, washing, varnishing, colouring and dying according to the method of the best authors now extant, exemplified in the painting of the antients, washing of maps, globes or pictures, dying of cloth, silks, bones, wood, glass, stones, and metals, together with the way of varnishing thereof according to any purpose or intent. Mode of access: Internet. Bound in old sprinkled calf; edges sprinkled red; title in ink on foot of text-block; extensive notes in a contemporary hand on initial three blank pages; engraved armorial bookplate on recto of added {{engraved title-page}}...|$|R
40|$|Abstract: The {{following}} paper {{chronicles the}} evolution of the author’s thinking on leadership through the course of his work experience. Leadership is viewed as a dynamical process involving both formal and informal roles. The process is initiated as an individual identifies opportunities and feels pulled to respond to emerging patterns and initiate action to enable positive change. The dynamics between formal and informal leadership structures and leadership as a state of mind are discussed. Key words: Adversity, complexity, fundamental state of leadership, leadership, <b>requisit...</b>|$|E
40|$|In the {{perpetual}} dance of signs, semiosis is generally regarded by followers of C. S. Peirce as occupying {{the role of}} “thirdness ” — meaning {{that the relationship between}} object, sign, and interpretant exist as a non-mental mode that cannot be reduced to a binary and self-enclosed relational circuit between two subjects. Bains ’ bold move, bolstered by his careful reading of Poinsot, Deely, Uexküll, and Deleuze, is to grant semiosis primacy. Rather than to rely on a cross-referencing system in a Peircean trirelative formulation, Bains positions semiosis above “the dance ” of signs as a means of explaining how external relations- <b>requisit...</b>|$|E
40|$|We {{say that}} a {{sentence}} A is a permissive consequence {{of a set of}} premises Γ whenever, if all the premises of Γ hold up to some standard, then A holds to some weaker standard. In this paper, we focus on a three-valued version of this notion, which we call strict-to-tolerant consequence, and discuss its fruitfulness toward a unified treatment of the paradoxes of vagueness and self-referential truth. For vagueness, st-consequence supports the principle of tolerance; for truth, it supports the <b>requisit</b> of transparency. Permissive consequence is non-transitive, however, but this feature is argued to be an essential component to the understanding of paradoxical reasoning in cases involving vagueness or self-reference...|$|E
40|$|The {{establishment}} of protectorate over Tuva by Russia in 1914 {{was followed by}} attempts to introduce Russian administrative and judicial system, which did not always take due account of characteristic features of a well-established internal self-governance of Tuvans.   The 1917 revolutions in Russia and the civil war that immediately ensued also had an influence on Tuva, exacerbating the already complicated political situation. The Urga and Peking governments made their contribution to this by taking concerted action to capture the territory of Tuva. The groundwork for military action was laid {{in close proximity to}} border line, and in 1919 Tuva was invaded by armed units of the Chinese and Mongolians, who used foodstuffs and carts <b>requisited</b> from local people to replenish supplies and recruited local population to reinforce their troops. The Omsk Government was unable to provide any substantial help. The article, based on archival studies and a series of contributions of Russian and international scholars, attempts to offer a number of insights into the reasons, course, and outcome of this armed conflict...|$|R
40|$|In {{contrast}} to the ćlassical Islamic tendiẃhere the action {{as well as the}} setting is commonly detached from the environmental context of the Swahili coast, the Liyongo poems show an abundance of detailed descriptions and enumerative reviews of material items crucial and characteristic of the particular East African shares of Swahili culture. Frequently reference is also made to the natural environment as plants and their fruits play a prominent role as <b>requisits</b> of both the Swahili natural and cultural setting. Apart from being exploited as central requisite and being referred to as material source in the poems, plants are also extensively used for similes. The Liyongo poems are full of culturally metaphors which are context-dependent and sometimes render the text rather obscure. Without denying that there is, of course, also contemporary poetry employing plants as subject matter or metaphors, in this article I focus on two thematically close poems which we vaguely have to classify as öldẅhile not being able to give exact dates. Although the article suggests to be a thematic view on Swahili poetry, it is primarily a text edition of two poems, the S̈ong of the Mjemjeänd the S̈hairi la Mtambuu,̈ which are both presented together with a critical apparatus...|$|R
40|$|This bachelor´s thesis {{considers}} a sport club called Sokol in Týn nad Vltavou, {{in the time}} period from 1891 till 1948 with some small time overlaps. The main goal is to show historical development, function and activity of Sokol in Týn nad Vltavou, but also to introduce the organization by itself. At {{the same time it}} tries to sketch the circumstances of the existence of the Tyn´s Union in single districts of its developement and of course their history. I mean, its maternity districts of Žižka and Hus, which it became a part later on. This work also includes the history and origin of the town, which relates to the Tyn´s Union, too. The work called Sokol in Týn nad Vltavou was written on the basis of studying sources of information and literature containging this kind of topic. Most of all I used the information from the fund of Sokol [...] Sport club of Týn nad Vltavou, which is stored in the State district archives in České Budějovice. Furthermore I used two funds of State regional archives in Třeboň, which have apposite names: Sokol´s District of Hus and Sokol´s District of Žižka. If we mention the <b>requisited</b> literature, the main resource which I used were the books concerning the history of Týn nad Vltavou, then the works, which deal with Sokol, its history and founders. And last but not least I browsed the newspapers, both regional and state and I was looking for the continuity with the topic of this bachelor's thesis. This work consists of three parts. The first one is divided into an introduction of the topic of the bachelor's thesis containing target setting and tasks and criticism of the sources and literatures. The history of Týn nad Vltavou and Sokol's history can be both found in the next part. This section is divided into three secondary chapters, the developement of Sokol by itself and presentation of the life of Fügner and Miroslav Tyrš. Following text includes the historical development of Hus´s District and District of Žižka, the history of Sokol in Týn nad Vltavou and funds history. At the end we can find a summing up, which is followed by the list of literature and sources, illustrated adds and list of already worked source...|$|R
40|$|Sports are {{classified}} in several ways, among them exist those sports where {{results can be}} specificly measured. This group of sports includes athletics, cycling skiing and swimming among others. The results in these sports are significantly effected by the coefficiency of drag, so that the logical {{efforts to improve the}} production technology of the <b>requisit</b> sports equipment and for personal sports equipment that they have an adequate coefficient of drag. The paper presents the possibilities for nanotechnology, its impact in the sport of swimming and points to the perspective that it offers to sports performance products, with an emphasis on the development of Speedo suits, including the last generation of suits, the LZR Racer...|$|E
40|$|Water {{is both an}} {{economic}} and social good. Hence a balance needs to be established between access and costs of service delivery. A study carried out by Maxwell and Stamp in 2002 established that the poor did not actually benefit from the subsidized rate at the public stand posts due to the middle man effect. It is also an established fact that the poor pay for water {{at a much higher}} rate than that levied by the utility at the Public Stand Pipes (PSPs). As a consequence National Water and Sewerage Corporation (NWSC) developed a strategy to reduce reliance on standpipes and encourage individual connections by which the poor will get water at the actual utility rates. Prior to the introduction of the new connection policy in National Water and Sewerage Corporation (NWSC), a new customer had to pay a connection fee and also be responsible for procurement and laying of the <b>requisit...</b>|$|E
40|$|The {{current review}} is a {{quantitative}} meta-analysis {{of the available}} empirical evidence related to parent-preschooler reading and several outcome mea-sures. In selecting the studies {{to be included in}} this meta-analysis, we focused on studies examining the frequency of book reading to preschoolers. The results support the hypothesis that parent-preschooler reading is related to outcome measures such as language growth, emergent literacy, and reading achievement. The overall effect size ofd =. 59 indicates that book reading explains about 8 % {{of the variance in the}} outcome measures. The results support the hypothesis that book reading, in particular, affects acqui-sition of the written language register. The effect of parent-preschooler reading is not dependent on the socioeconomic status of the families or on several methodological differences between the studies. However, the effect seems to become smaller as soon as children become conventional readers and are able to read on their own. Interest in the ways in which parents help their children to develop the <b>requisit...</b>|$|E
40|$|The endless {{miniaturization}} of Si-based Metal Oxide Semiconductor Field-Effect Transistors (MOSFETs) has {{the key for}} {{urging the}} electronic uprising. How-ever, scaling of the channel length is the enormous challenge to preserve the per-formance in terms of speed, power, and electrostatic integrity at each technologynodes. From the commencement of CMOS scaling, the simple planar MOSFETs are {{not up to the}} performance because of the increased SCEs and leakage cur-rent. To slacken the SCEs and leakage currents, different types of structures i. e. Multi-Gate MOSFETs like double-gate (DG), triple-gate (TG), FinFETs have in-troduced in the literature. Fully Depleted (FD) Silicon-On-Insulator (SOI) devices have shown potentially significant scalability when compared to bulk MOSFETs. In spite of, the introduced structures in literature are not offering concurrent SCE repression and improved circuit implementation. And some involve tangled processing not suggested for smooth integration into the here and now CMOS technology. The scaling capability of nanoscale ultra-thin (UT) silicon directly on insula-tor (SDOI) single gate (SG) and DG MOSFETs is investigated to overcome SCEs and improve power consumption. Dependence of underlap length on drain cur-rent, Subthreshold Slope (SS), transition frequency, delay, Energy Delay Product (EDP), etc. is studied for DG MOSFET and FinFET, to find the optimum value of underlap length for low power consumption. DG MOSFET is an excellent can-didate for high current drivability whereas FinFET provides better immunity toleakage currents and hence improved delay, EDP over DG MOSFET. Furthermore,FinFET provides a high value of transition frequency which indicates that it is faster than DG MOSFET. III-V channel materials are proposed for the discussed two structures to improve the On current at the same integration density as in Si-based channel FETs. The role of geometry parameters in sub 20 nm SOI Fin-FET is studied to find the optimum value of height and width of Fin for analogand RF circuit design. This work provides the influence of the height and width of Fin disparity on different performance matrices that comprises of static as well as dynamic figures of merit (FoMs). Based on the Aspect Ratio (WF in/HF in),the device can be divided into three parts, i. e., FinFET, Tri-gate, and PlanarMOSFET. CMOS for SG and DG is made using the combination of NMOS and PMOS by engineering the work function in order to have same threshold voltage for N-channel and P-channel MOS. The inverter is without doubt the core of all digital applications. Once its operation and characteristics are understood with clarity,designing more complicated structures such as NAND gates, multipliers, adders, and microprocessors are significantly explained. The performance of CMOS is articulated. All the dimensions are according to the ITRS 2013 datasheet. Thework provided here is <b>requisited</b> to give the purpose for forward experimental in-vestigation...|$|R
40|$|The {{development}} personality {{can suffer}} irreversible damages before traumatical divorces. The separation {{can cause a}} bitterness feeling to children and the teens, victims of a broken marriage. In general, the descendants react to the divorce having a difficult socialization in their environment or presenting some clinical diseases like unconscious’s manifestations. At this moment, the only juridical step to provide the descendants of their needs is the mensal contribution that must be paid for the father in order to adquire feed, cloth and some medicine help. Unfortunately, in many cases, this payment {{is not enough to}} give children the same emotional pleasure and safety that they would have if they were living with their parents. Undoubtedly, for children, it is important having the father and mother getting on well, in spite of living in separated houses. The children and the teens prefer to have the parents at home than a mensal payment. There are many cases found in the psychoanalyzes are decorrent of traumatical situations that happened in childhood and the adolescence. Must of them need a specialized treatment, but the mensal payment it’s not sufficient to cover all these accounts. The Law cannot ignore this situation. There is no reason to defend a philosophy that believes the Law is a statical doctrine or that justice never changes. Instead of this, none of the new theories and researches, like this, could preced and make sense. According to RICASENS SICHES theory, Law is a dynamic and logical science. It’s necessary to know the fundaments of Psychology to averigue the effects of the broken marriages. Nowadays, there are many groups to attend the children and the teens of divorced parents. It was verified that the first and the second years of the separation are the most difficult to the descendants. Commonly, they show relationship problems and they don’t get good scores at school. The most frequent symptoms of the divorced parent’s children are agressivity, hasty, anxious and concentrating problems in the subjects. In addition, they get all kind of sickness and pains like headaches, stomackaches and even diabet. All of this, {{is a result of the}} insecurity feeling before the troubled separation process. Finally, thinking about all the problems involved in the divorce, and mainly that the mensal contribution is not enough to cover the children and the teens emotional treatments, it has been <b>requisiting</b> a indenization to compensate the negative effects that some separations can cause to divorced parent’s descendants. This can be done through a repair like moral damage. A personalidade em formação pode sofrer danos irreversíveis ou de difícil reversão ante fatos como as separações conjugais traumáticas. Elas causam aos filhos menores de casais que passam por isto uma enorme amargura. Estas apresentam geralmente, um quadro de somatização, manifestações do inconsciente, quadros clínicos, dificuldades de socialização. A pensão alimentícia, atualmente único remédio jurídico, não tem como proporcionar o conforto emocional e a segurança que só o convívio com os pais pode transmitir aos filhos. São vários os casos encontrados na psicanálise, motivados por eventos marcantes no período infanto-juvenil. Muitos demandam tratamento especializado. Verifica-se que os dois primeiros anos após a separação são os mais difíceis e as crianças em fase escolar, a partir de 6 a 7 anos, são as que apresentam maiores dificuldades de relacionamento. Os sintomas apresentados são a impulsividade, a agressividade e dificuldades na escola. Como a pensão alimentícia não tem o condão de abranger todos estes particulares, visualiza-se a possibilidade de se compensar os efeitos negativos que algumas separações conjugais trazem aos filhos, mediante o pagamento de indenização a título de danos morais...|$|R
40|$|Digital {{manufacturing}} {{constitutes a}} real industrial revolution that is transforming the production processes {{from the early}} stages of research and development to mass production and marketing. The biggest difference in comparison with old fabrication methods is the possibility to perform changes in the pattern design just by using mouse clicks instead of modifying an already fabricated prototype, which results in faster, cheaper and more efficient fabrication processes. For example, new technologies enabling the production of printed electronic devices on flexible substrates and compatible with roll-to-roll processing methods would result in cheaper fabrication costs than the traditional batch processing of silicon wafers. Such fabrication methods comprise a series of processing steps which are applied to the substrates while they are moving on rolls in the fabrication line. Therefore, it is desired that the new technologies can work at high speeds allowing {{at the same time the}} production of miniaturized features. Lasers are a versatile tool that can meet the demands of flexibility, speed, resolution and compatibility with roll-to-roll processing of digital manufacturing. The main advantages of laser radiation rely in its unique properties: high directionality, coherence and monochromaticity. The combination of such properties allows generating high intensities that can be focused into extremely small volumes, which makes lasers an ideal tool for the processing of materials at the micro- and nano-scale, not only as a subtractive but also as an additive technique. Laser ablation is the best known subtractive technique and it consists in the irradiation of a material with a focused laser beam. In the case of working with transparent materials, surface ablation constitutes a serious challenge since it is necessary to develop new strategies that allow controlling the position where the energy is delivered to ensure that ablation really occurs in the surface without modifying the bulk material. On the other hand, lasers can also be used as additive tools. For example, laser-induced forward transfer (LIFT) allows the transfer of materials in both solid and liquid state with high spatial resolution. In spite of the extensive amount of research on LIFT, some challenges still remain. For instance, the understanding of the particular printing dynamics encountered during the high speed printing of liquids, or the problem of printing uniform, continuous and stable lines with high spatial resolution. The objective of this thesis is to propose and implement feasible solutions to some of the challenges that are associated with both the subtractive and additive laser based techniques presented above. On one side, we study the laser ablation of transparent polymers using femtosecond laser pulses with the aim of achieving spatial resolutions that overcome the diffraction limit, and at the same time solving the problem of the required precise focusing of the laser beam on the materials surface. On the other side, we study the LIFT transfer dynamics during the high speed printing of liquids, and we propose alternative printing strategies to solve the inherent quality defects usually encountered during the formation of printed lines. Finally, two different approaches that are a combination of both subtractive and additive techniques are presented; we implement LIFT for the fabrication of liquid microlenses used for the surface nanopatterning of materials, and on the other side, we create fluidic guides by laser ablation for the printing of high quality continuous lines. La fabricació digital de dispositius tecnològics requereix el desenvolupament de noves i millors tècniques per al microprocessament de materials que al mateix temps siguin compatibles amb mètodes de producció en sèrie a gran escala com el roll-to-roll processing. Aquestes tècniques han de complir certs <b>requisits</b> relacionats amb la possibilitat de realitzar canvis de disseny ràpids durant el procés de fabricació, alta velocitat de processament, i al mateix temps permetre la producció de motius de forma controlada amb altes resolucions espacials. En la present tesi es proposen i implementen solucions viables a alguns dels reptes presents a la microfabricació amb làser tant substractiva com additiva. D'una banda, es presenta un nou mètode d'enfocament del feix làser sobre la mostra per l'ablació superficial de materials transparents que permet obtenir resolucions espacials que superen el límit de difracció del dispositiu òptic. D'altra banda, es duu a terme un estudi de la dinàmica de la impressió de líquids mitjançant làser a alta velocitat, de gran interès de cara a la implementació industrial de la tècnica. A més, es presenten estratègies d'impressió de tintes conductores amb l'objectiu de produir línies contínues amb alta qualitat d'impressió. Finalment s'inclouen dues propostes que són producte de la combinació d’ambues tècniques, la impressió de líquids i l'ablació amb làser...|$|R
40|$|The {{potential}} of Information Age technology to support collaboration {{at a distance}} invites military forces to create agile mission groups, which can form, adapt and re-form rapidly and sympathetically to changing circumstances. Managing such an agile capability will require agile headquarters, {{as part of a}} wider Information Age Command and Control concept. This paper explores the implications of HQ agility from the stand-point of organisational and social science, and presents the results of thinking about how organisational and social factors can be integrated into modelling. The paper draws from social and organisational science literatures, C 2 experimentation, and modelling research, to map out the key factors impacting on the relationship between capability investment and HQ performance and behaviour. It outlines a revised conceptual model capable of addressing a requisite subset of variables and bringing them together into a coherent model implementation. The model requires a judicious synthesis of approaches, striking a practical balance between detailed and abstraction. The paper draws encouragement from existing model implementations, but the synthesis of a <b>requisit...</b>|$|E
40|$|Network {{orchestration}} has intrinsically been {{a thought}} provoking and consuming undertaking for the hub firms which {{happen to be}} the central leading body carrying out responsibilities as a hub firm. The network orchestration comprises three vital orchestration processes Knowledge Mobility, Innovation Appropability and Network Stability which help the network orchestrator to communicate with multiple actors in the network. The research work is based on reflection and analysis of performance of hub firm in perspective of network orchestration and innovation project directed towards betterment of public transportation department. With respect to the domain of study there have been thorough perusal and analysis of several academic articles and resources which have hitherto been contributed for the subject in question. Methodology consists of in depth interview of the researchers of Victoria institute which are currently working on ISET program (Innovation for sustainable everyday travel). Our findings seek to answer the main question, that how a hub firm tackles with its emerging challenges to leverage network innovation, in shape of evidences from Viktoria Institute of research and development. Analysis of data is carried out through strategic management tool and descriptive approach. With all due efforts, the work has been afforded with validity and authenticity employing all the <b>requisit...</b>|$|E
40|$|We are {{entering}} {{an exciting time}} where millimeter-wave (MMW) sys-Presenting a method for tems are encroaching into everyday life, examples being communications, constructing a dedicated auto-navigation, and security. It is instinctive to consider these systems in 200 GHz radar. industrial settings, as well. Given the current energy climate, {{it may be possible}} to apply MMW technology in an effort to improve efficiency in power generation industries. Paper is one such industry, specifically in the Kraft-Recovery process. In the Kraft process, pulping salts and organic compounds, byproducts of extracting fiber from wood, are retrieved through combustion. The process of incinerating the solution generates a surplus of heat that is reclaimed in the form of process- and power generating- steam. Heavy sooting of salt in the heat-exchanger is normally experienced and a MMW imaging system was proposed to measure these deposits to aid in the reduction of maintenance steam consumption. Imaging at 200 GHz is attractive due to the electrical properties of the salts as well as the need for millimeter scale resolution; however, wide-band imaging systems operating at these frequencies are generally built from instrumentation and a need for dedicated hardware exists. To this end, we will present a method for constructing a dedicated 200 GHz radar and the <b>requisit...</b>|$|E
40|$|Els nostres sistemes de salut estan veient qüestionada la seva sostenibilitat arran del canvi demogràfic d'una societat en la qual augmenta la prevalença de cronicitat i discapacitat. El nou model de salut es basa en la Medicina 4 P. Una tecnologia clau per a la Medicina 4 P és el telemonitoratge, és a dir, les TIC per conèixer l'estat de salut d'un pacient a distància i prendre {{decisions}} 4 P. Un repte ambiciós és el telemonitoratge de la Qualitat de Vida (QoL) basat en el coneixement del context. Proposem una metodologia formal per avaluar la QoL mitjançant la categorització de dades d'entrada i sortida i tècniques de fusió de dades. Hem dissenyat i desenvolupat un Sistema de Telemonitoratge i Suport Domiciliari (TMHSS) que implementa aquesta metodologia, integrat al sistema BackHome per un Cas d'Ús concret, el de persones amb discapacitats severes que utilitzen Interfícies Cervell Ordinador (BCI) com a Tecnologia Assistencial (AT) en entorns reals. Hem aplicat Disseny Centrat en l'Usuari amb la finalitat de traslladar els BCIs des del laboratori fins a l'ús domèstic independent. El sistema BackHome ha assolit cinc innovacions fonamentals: (i) una arquitectura que satisfà els <b>requisits</b> d'un BCI multifuncional i amb suport remot; (ii) un dispositiu de BCI lleuger, autònom, còmode i fiable; (iii) 	un programari fàcil d'utilitzar per a manegar diverses aplicacions d'autonomia física i social; (iv) 	Un TMHSS per fer efectiu l'ús independent dels BCIs a la llar; i (v) una estació clínica per a la gestió remota de serveis terapèutics. Hem avaluat el sistema BackHome amb usuaris finals a casa seva, aprenent de la perspectiva de terapeutes i cuidadors no experts amb resultats que mostren bona acceptació i nivells d'usabilitat, satisfacció de l'usuari i nivells de control que demostren que el BCI pugui ja considerar-se una AT alternativa. Hem emprat el TMHSS de BackHome per reconèixer activitats i hàbits dels usuaris a partir de l'anàlisi de dades de sensors, per detectar per exemple si l'usuari està a casa o fora, o si ha rebut una visita. També hem avaluat a continuació amb bona precisió elements de la Qualitat de Vida, com ara mobilitat, son, o estat d'ànim, a partir de les activitats de l'usuari prèviament detectades. Our healthcare {{systems are}} facing sustainability challenges {{caused by a}} demographic shift with ageing, chronicity and disability growing in our society. A novel healthcare paradigm should be founded on 4 P medicine: Preventive, Predictive, Personalized, and Participatory medicine needs new methodologies and tools enabled by Information and Communication Technologies (ICTs). One of the key technology enablers for 4 P medicine is telemonitoring, i. e. ICTs to monitor the health status of a patient from a distance, which may trigger 4 P decision making. A new generation of telemonitoring tools allow prescription and follow-up around the main chronic care strategies, namely, therapeutic adherence and healthy habits promotion. A broader and more ambitious challenge is Quality of Life (QoL) telemonitoring based on the knowledge of context. We are proposing a formal methodology to provide Context-aware QoL assessment, categorizing data inputs, defining outputs, and exploring data fusion techniques. A Telemonitoring and Home Support System (TMHSS) which implements that methodology has been designed, developed and integrated to the BackHome system for a particular Use Case, i. e. severely disabled people using Brain Computer Interfaces (BCI) as an assistive technology (AT) at home. We have applied User Centred Design throughout all development stages of a multi-functional BCI, {{in order to move}} BCIs from the lab towards independent home use. The BackHome system has achieved five key innovations: (i) an architecture able to meet the requirements of BCI multifunctionality and remote home support; (ii) a light, autonomous, comfortable and reliable BCI equipment; (iii) an easy-to-use software to control multiple purpose applications; (iv) a TMHSS for BCI independent home use; and (v) a Therapist station to manage and monitor BCI-based remote services. We have evaluated the BackHome system with end-users at home, also taking the therapists' and non-expert caregivers' perspective into account. The results show good acceptance, usability levels, user satisfaction and levels of control, which demonstrate that BCI can already be considered as an alternative AT. We used the TMHSS of BackHome to recognize activities and habits of users based on the analysis of sensors' data, in order to detect for example whether the user is at home or away or whether has received a visit at home or not. Similarly, and consequently from the previous analysis, results show good accuracies in assessing items of QoL such as Mobility, Sleep, or Mood, based on measures and fusion of detected activities from the user. The assessment of the overall wellbeing of an individual with a multidimensional perspective through processing of data gathered from environmental and personal sensors in a broad and non-intrusive way, will become of great interest to healthcare professionals, policy makers and also for citizens which are called to co-produce and lead the new paradigm of care...|$|R
40|$|Ionic liquids (ILs) are {{a fairly}} new and very {{promising}} group of compounds. They are often considered as environmentally benign substitutes for traditional volatile organic solvents {{due to their}} attractive properties and physicochemical characteristics (e. g. non-volatility, high thermal stability and very good and versatile solving capacity). The ILs are salts composed entirely of ions (cations and anions) with a melting point below 100 °C and they are liquid {{in a wide range}} of temperatures. The ILs are usually described as "green", but they are chemical products, and as such have to fulfill the requirements of the European Community regulation on chemicals and their safe use called Registration, Evaluation, Authorization, and Restriction of Chemical Substances (REACH). Due to their immeasurably low vapor pressure ILs cannot be found in the atmosphere, but their water solubility is often high and they are stable, so they can end up in industrial and laboratory effluents and consequently cause water and soil contamination. The analyzed ILs include representatives of a new family of protic ionic liquids (PILs) derived from mono-, di- and triethanolamine and aliphatic organic acids, and some of the most frequently used imidazolium and pyridinium based aprotic ionic liquids (AILs). In order to evaluate the environmental impact of these ILs, various (eco) toxicity tests were performed. The aquatic ecotoxicity tests included target organisms: marine bacteria Vibrio fischeri, green algae Pseudokirchneriella subcapitata and aquatic plant Lemna minor. The terrestrial ecotoxicity tests evaluated the toxic effects on terrestrial plants (onion Allium cepa, grass Lolium perenne and radish Raphanus sativus) and soil microorganisms involved in carbon and nitrogen transformation. Two additional test systems with an enzyme (acetylcholinesterase inhibition) and isolated leukemia rat cells IPC- 81 (cytotoxicity) were performed in order to provide a more in-depth evaluation of toxicity. Ready biodegradability in water and soil was also studied. The number of combinations of cations and anions forming ionic liquids is practically infinite, so they can be custom designed in order to suite the desired application. But the complete information on their environmental impact is still not available. The quantitative structure-activity relationship (QSAR) modelling can allow reliable prediction of toxicity and it helps to avoid unnecessary animal experiments, which is why the use of in silico models and QSAR is strongly encouraged by European Chemicals Agency (ECHA) and REACH. As it is clearly impossible to analyze the toxicity of so many compounds, the application of QSAR models could speed up the process of ecotoxicological evaluation and indicate the potential toxicity of new ILs before they are considered for commercialization. In this thesis, a group contribution QSAR model was used in order to predict the (eco) toxicity of eight previously untested PILs that belong to the new family. The prediction was made for five (eco) toxicity tests (Microtox®, Pseudokirchneriella subcapitata and Lemna minor growth inhibition test, and Acetylcholinestherase inhibition and Cell viability assay with IPC- 81 cells). The PILs proved to be non-toxic in most of the performed tests. The EC 50 values for AILs are up to several orders of magnitude lower than the ones for the PILs and they show much lower biodegradation potential. The most toxic ILs are the most complex ones in both of the analyzed groups. The findings of the thesis indicate that the PILs with simpler and lineal structure can be considered as environmentally safer than the AILs predominately used up to date, which have bulky organic anions with long alkyl chain substituents. Els líquids iònics (ILs) són un grup de compostos bastant nou i molt prometedor. Sovint són considerats com a substituts ambientalment benignes de dissolvents orgànics volàtils tradicionals a causa de les seves propietats fisicoquímiques atractives. Encara que els ILs tenen un perfil potencialment "verd", són bàsicament productes químics, i com a tal, han de complir amb els <b>requisits</b> de la legislació vigent sobre productes químics de la Unió Europea anomenada Registre, Avaluació, Autorització i Restricció de Substàncies Químiques (REACH). La informació completa sobre l’impacte ambiental d’ILs encara no està disponible. Els líquids iònics analitzats inclouen representants d'una nova família de líquids iònics pròtics (PILs) derivats de mono-, di- i trietanolamina i àcids orgànics alifàtics, i alguns representants freqüentment utilitzats de la família de líquids iònics apròtics (AILs), derivats de l’imidazoli i del piridini. Per tal de determinar l'impacte mediambiental es van realitzar els assaigs d'ecotoxicitat aquàtica (amb Vibrio fischeri, Pseudokirchneriella subcapitata i Lemna minor) i terrestre (amb Allium cepa, Lolium perenne i Raphanus sativus, i amb els microorganismes del sòl participants en els cicles de carboni i nitrogen). Per obtenir una avaluació més detallada de la toxicitat, es van realitzar dues proves de toxicitat addicionals: inhibició de l'acetilcolinesterasa i citotoxicitat. La biodegradabilitat en aigua i sòl es va determinar també. Es va utilitzar un model de relació estructura-activitat quantitativa (QSAR) de contribució de grups per predir l’(eco) toxicitat dels PILs de la nova família que no s’havien analitzat prèviament. Els PILs van resultar ser no tòxics en la majoria de les proves realitzades. Els AILs analitzats van ser més tòxics que els PILs, amb valors de CE 50 diversos ordres de magnitud inferiors i van manifestar un baix potencial de biodegradabilitat. Els ILs amb l’estructura més complexa van ser els més tòxics en ambdós grups analitzats. Els resultats d'aquesta tesi indiquen que els ILs amb estructura més simple i lineal poden ser considerats com a més segurs per al medi ambient que els habitualment utilitzats fins ara, que contenen cations més voluminosos i substituents de cadena alquílica llarga...|$|R
40|$|Formation flying offers space-dependent {{disciplines}} such as astrophysics, astrodynamics, and geodesy, {{to name a}} few, {{the possibility}} of creating large spaceborne sensors from an array of small spacecraft flying in formation. This creates exciting scientific and technical opportunities as the formation could be arranged to work as, for example, an interferometer, thus providing a most unlimited angular resolution or a virtual telescope, thus unrestricted focal distances. Since the first mission including formation flying technology (EO- 1) was selected by NASA, some of the challenges to realize full Formation Flying (FF) capabilities has been {{thought to be the}} definition of suitable algorithms to navigate and control FF missions. The focus of this dissertation is the design and evaluation of algorithms for navigation and control for formation flying missions. Given its importance, extensive research has been already conducted to fulfill the increase of accuracy, autonomy, and other requirements of the Guidance, Navigation, and Control (GNC) systems that derive from novel applications of formation flying missions. To centre the scope of present work, we have mainly focused in three of the present challenges: the difficulties of fusing different non-linear observations for relative navigation; the analysis and extension of behavioural algorithms for controlling a formation of spacecraft; and the design and validation of a control law for formation acquisition and formation keeping of a non-natural relative trajectory. These three interconnected topics cover a wide range of research in formation flying and embody the main algorithm components of formation flying algorithms from the observations to the navigation and to the control. The first challenge consisted, thus, in addressing the difficulties encountered by classical filters to estimate a state vector fusing common observations. We proposed several strategies to improve the robustness of these filters under non-linear conditions. Among these strategies, the modification of the residuals computation for the Unscented Kalman Filter (UKF) deserves special mention due to its excellent results and robustness against nonlinearities. A theoretical basis for these results became, thus, necessary regarding the new update equation of the UKF and has been developed subsequently in the frame of this thesis. This work has been published in Perea et al. (2007) and Perea and Elosegui (2008). The collective motion exhibited by some groups of animals has recently attracted the interest of many research groups who try {{to take advantage of the}} robustness and efficiency of natural patterns. With this aim, we have investigated the possibility of extending an interaction model that has shown emergent behaviour. In particular, the Cucker-Smale (CS) model has been extended for its application on spacecraft formation flying. Numerical simulations of the Darwin mission have proved that this strategy is suitable for loose formation keeping. Of special relevance is the low cost of the controller, specially compared to an alternative strategy, the Zero Relative Radial Acceleration Cones (ZRRAC). The problem of tight formation keeping is addressed previous publications. In these papers, we first study the relative dynamics of a virtual telescope that follows a non-natural relative trajectory driven by the position of an observed body and not by the natural forces in space. This analysis has originated the design of several controls based on different approximations of the relative dynamics. Their performances have been tested and compared through numerical simulations of the PROBA- 3 mission using, first, computer based simulations, and then, a realistic platform with GNSS hardware and operational flight software in the loop. The main conclusions show that simple control definitions, as defined by the Linear Quadratic Regulator (LQR) and Linear Quadratic Regulator with the Integral term (LQRI), can fulfill stringent requirements for formation acquisition and tight formation keeping. KEYWORDS: Filering Theory; Control Theory; Guidance, Navigation and Control Systems; Formation Flying Missions El vol de satèl. lits en formació ofereix a les disciplines de I'espai, com ara I'astrofísica, I'astrodinàmica i la geodesia, per anomenar-ne unes quantes, la possibilitat de crear grans sensors espacials a partir d'un petit grup de satèl·lits en formació. Disposar els satèl·lits per a operar com, per exemple, un interferòmetre, i per tant, oferint una resolució angular gairebe il. limitada, o com a telescopi virtual i aconseguir distàncies focals inimaginables amb un únic satèl·lit, crea grans oportunitats científiques i tècniques. Des del moment en que la NASA va seleccionar la primera missió espacial que incorporava tecnologia de vol en formació (EO- 1), un dels reptes que es preveien per a realitzar autentiques missions de vol en formació es la definició d'algorismes específics per a la navegació i control dels satèl·lits. L'objectiu principal d'aquesta tesis es el disseny i avaluació d'algorismes de navegació i control apropiats per al vol de satèl·lits en formació. Donada la importancia d'aquestes missions, s'ha realitzat una extensa investigació per aconseguir acomplir amb l'increment d'objectius referents a la precisió, l'autonomia, i altres <b>requisits</b> del sistema de Guiat, Navegació i Control (GNC) que resulta de les noves aplicacions d'aquestes missions. El contingut d'aquesta tesis es centra en tres reptes actuals referents al sistema GNC: les dificultats de combinar diferents tipus d'observacions no lineals per a la navegació relativa; l'anàlisi i extensió d'algorismes de comportament per a controlar una formació de satèl. lits; i el disseny i la validació d'una llei de control per a l'adquisició i manteniment d'una formació en trajectòria no natural. Aquests tres temes interconnectats cobreixen una amplia àrea de recerca en el camp del vol en formació i incorpora els principals components dels algorismes de vol en formació, des de les observacions fins a la navegació i el control. </i...|$|R
40|$|T he latter {{years of}} the twentieth century have {{witnessed}} a phenome non unparall eled sin ce the depression of the 19 30 's. Legions of homeless, disadvan-taged, often mentall y ill poor have emerged th ronging cities, crowding pu blic places and presenting perplexing co mp lex, soci a l, pol it ical, economic, and medica l/psychiatric service delivery issues (I). Cou nti ng th e homeless, and among them th e mentally ill homeless, is a task fraugh t with d ifficulty, as some studies ha ve illustrated (2, 3). Estimates of mental illn ess among the nation's homeless range from 10 % to 70 % (4). In the District of Colu mbia, there are an estimated six to sev en thousand homeless. Of th ese, in 1988, 36 % were felt to be mentall y ill (5). The increasing numbers of homeless a nd mentall y ill street people are th e result of a com plex interwea vin g of pol itical a nd economic factors includ ing housing policy, urban gentrification, cha nging <b>requisit</b> e job skills in a changing economy, and deinstitutionalization (6). Regardless of their o r igin, the ch roni-call y mentally ill (CMI) homeless present as a population with d iverse acut...|$|E
40|$|Abstract. Attribute-value based representations, {{standard}} in today’s data mining systems, {{have a limited}} expressiveness. Inductive Logic Programming provides an interesting alternative, particularly for learning from structured examples whose parts, {{each with its own}} attributes, are related to each other by means of first-order predicates. Several subsets of FOL with different expressive power have been proposed in ILP. The challenge {{lies in the fact that}} the more expressive the subset of FOL the learner works with, the more critical the dimensionality of the learning task. The Datalog language is expressive enough to represent realistic learning problems when data is given directly in a relational database, making it a suitable tool for data mining. Consequently, it is important to elaborate techniques that will dynamically decrease the dimensionality of learning tasks expressed in Datalog, just as Feature Subset Selection (FS) techniques do it in attribute-value learning. The idea of re-using these techniques in ILP runs immediately into a problem as ILP examples have variable size and do not share the same set of literals. We propose here the first paradigm that brings Feature Subset Selection to the level of ILP, in languages at least as expressive as Datalog. The main idea is to first perform a change of representation, which approximates the original relational problem by a multi-instance problem. The representation obtained as the result is suitable for FS techniques which we adapted from attribute-value learning by taking into account some of the characteristics of the data due to the change of representation. We present the simple FSS proposed for the task, the <b>requisit...</b>|$|E
40|$|The total nondialyzable solids (TNDS) of nor-mal human urine {{have been}} found to have an ap-proximate {{composition}} of 47 per cent protides, 16. 6 per cent glucides, 9. 7 per cent sialic acid, 6. 2 per cent hexosamine, 3. 3 per cent lipids, 12. 2 per cent bound water and 8. 5 per cent ash (1). The mean TNDS excretion in two series of determina-tions {{has been found to be}} 433 mg. and 505 mg. per 24 hours, with a value of 472 (S. D. ± 108) mg. per 24 hours for the combined series (1, 2). Methods have been described for separation of the TNDS into three reproducible fractions (2). Figure 1 is a flow sheet illustrating the technique and approximate percentage weight distribution of each fraction. Boundary electrophoretic studies, at pH 8. 6, have demonstrated the presence of concentration gradients in the RS-l fraction which have mobilities closely approximating each of the gradients of normal blood plasma under similar conditions (3). The Cohn Method 10 for frac-tionation of plasma proteins has been modified by Lever and co-workers to permit separation of small quantities of plasma proteins (4). The present report concerns the application of this technique to the fractionation of RS-l solids from normal human urine. MATERIALS AND METHODS Subjects. Ten to 12 subjects (seven male and five fe-male) submitted 24 hour urine specimens, which were pooled daily for rapid processing (2). Reagents. The reagents were prepared from stock solutions at room temperature and cooled to- 50 C. immediately before use. The reagents A and A ' of Lever gave an initial precipitation medium of pH 5. 8. r/ 2 of 0. 04 and 19 per cent ethanol when added to the <b>requisit...</b>|$|E
40|$|The next {{generation}} of particle colliders will be characterized by linear lepton colliders, where the collisions between electrons and positrons will allow to study in great detail the new particle discovered at CERN in 2012 (presumably the Higgs boson). At present time, there are two alternative projects underway, namely the ILC (International Linear Collider) and CLIC (Compact LInear Collider). From the detector point of view, the physics aims at these particle colliders impose such extreme requirements, {{that there is no}} sensor technology available in the market that can fulfill all of them. As a result, several new detector systems are being developed in parallel with the accelerator. This thesis presents the development of a GAPD (Geiger-mode Avalanche PhotoDiode) pixel detector aimed mostly at particle tracking at future linear colliders. GAPDs offer outstanding qualities to meet the challenging requirements of ILC and CLIC, such as an extraordinary high sensitivity, virtually infinite gain and ultra-fast response time, apart from compatibility with standard CMOS technologies. In particular, GAPD detectors enable the direct conversion of a single particle event onto a CMOS digital pulse in the sub-nanosecond time scale without the utilization of either preamplifiers or pulse shapers. As a result, GAPDs can be read out after each single bunch crossing, a unique quality that none of its competitors can offer at the moment. In spite of all these advantages, GAPD detectors suffer from two main problems. On the one side, there exist noise phenomena inherent to the sensor, which induce noise pulses that cannot be distinguished from real particle events and also worsen the detector occupancy to unacceptable levels. On the other side, the fill-factor is too low and gives rise to a reduced detection efficiency. Solutions to the two problems commented that are compliant with the severe specifications of the {{next generation}} of particle colliders have been thoroughly investigated. The design and characterization of several single pixels and small arrays that incorporate some elements to reduce the intrinsic noise generated by the sensor are presented. The sensors and the readout circuits have been monolithically integrated in a conventional HV-CMOS 0. 35 μm process. Concerning the readout circuits, both voltage-mode and current-mode options have been considered. Moreover, the time-gated operation has also been explored as an alternative to reduce the detected sensor noise. The design and thorough characterization of a prototype GAPD array, also monolithically integrated in a conventional 0. 35 μm HV-CMOS process, is presented in the thesis as well. The detector consists of 10 rows x 43 columns of pixels, with a total sensitive area of 1 mm x 1 mm. The array is operated in a time-gated mode and read out sequentially by rows. The efficiency of the proposed technique to reduce the detected noise is shown {{with a wide variety of}} measurements. Further improved results are obtained with the reduction of the working temperature. Finally, the suitability of the proposed detector array for particle detection is shown with the results of a beam-test campaign conducted at CERN-SPS (European Organization for Nuclear Research-Super Proton Synchrotron). Apart from that, a series of additional approaches to improve the performance of the GAPD technology are proposed. The benefits of integrating a GAPD pixel array in a 3 D process in terms of overcoming the fill-factor limitation are examined first. The design of a GAPD detector in the Global Foundries 130 nm/Tezzaron 3 D process is also presented. Moreover, the possibility to obtain better results in light detection applications by means of the time-gated operation or correction techniques is analyzed too. Aquesta tesi presenta el desenvolupament d’un detector de píxels de GAPDs (Geiger-mode Avalanche PhotoDiodes) dedicat principalment a rastrejar partícules en futurs col•lisionadors lineals. Els GAPDs ofereixen unes qualitats extraordinàries per satisfer els <b>requisits</b> extremadament exigents d’ILC (International Linear Collider) i CLIC (Compact LInear Collider), els dos projectes per la propera generació de col•lisionadors que s’han proposat fins a dia d’avui. Entre aquestes qualitats es troben una sensibilitat extremadament elevada, un guany virtualment infinit i una resposta molt ràpida, a part de ser compatibles amb les tecnologies CMOS estàndard. En concret, els detectors de GAPDs fan possible la conversió directa d’un esdeveniment generat per una sola partícula en un senyal CMOS digital amb un temps inferior al nanosegon. Com a resultat d’aquest fet, els GAPDs poden ser llegits després de cada bunch crossing (la col•lisió de les partícules), una qualitat única que cap dels seus competidors pot oferir en el moment actual. Malgrat tots aquests avantatges, els detectors de GAPDs pateixen dos grans problemes. D’una banda, existeixen fenòmens de soroll inherents al sensor, els quals indueixen polsos de soroll que no poden ser distingits dels esdeveniments reals generats per partícules i que a més empitjoren l’ocupació del detector a nivells inacceptables. D’altra banda, el fill-factor (és a dir, l’àrea sensible respecte l’àrea total) és molt baix i redueix l’eficiència detectora. En aquesta tesi s’han investigat solucions als dos problemes comentats i que a més compleixen amb les especificacions altament severes dels futurs col•lisionadors lineals. El detector de píxels de GAPDs, el qual ha estat monolíticament integrat en un procés HV-CMOS estàndard de 0. 35 μm, incorpora circuits de lectura en mode voltatge que permeten operar el sensor en l’anomenat mode time-gated per tal de reduir el soroll detectat. L’eficiència de la tècnica proposada queda demostrada amb la gran varietat d’experiments que s’han dut a terme. Els resultats del beam-test dut a terme al CERN indiquen la capacitat del detector de píxels de GAPDs per detectar partícules altament energètiques. A banda d’això, també s’han estudiat els beneficis d’integrar un detector de píxels de GAPDs en un procés 3 D per tal d’incrementar el fill-factor. L’anàlisi realitzat conclou que es poden assolir fill-factors superiors al 90 %...|$|R
40|$|Inland {{waters are}} active {{components}} of the global carbon (C) cycle that transform, store and outgas {{more than half of}} the C they receive from adjacent terrestrial ecosystems. However, fundamental uncertainties regarding the spatiotemporal patterns, controls and sources of C gas fluxes in fluvial networks still exist. For instance, current biogeochemical models addressing C transport and processing in fluvial networks from a continuous perspective, do not integrate the effects of local discontinuities such as river impoundment or stream flow intermittency on the dynamics of C gas fluxes. The present dissertation aims to examine how flow discontinuities (i. e., river impoundment, flow fragmentation and drying) shape the spatiotemporal patterns, the controls and the sources of C gas fluxes in a Mediterranean fluvial network. The study was performed from December 2012 to March 2015 in the Fluvià river (NE Iberian Peninsula), characterized by a high density of impounded waters associated to small water retention structures (SWRS; i. e., weirs and small to very small impoundments with surface area < 0. 1 km 2 and a volume < 0. 2 hm 3) as well as fragmented river sections dominated by isolated water pools and dry riverbeds coinciding with dry periods. Results of this dissertation show that river discontinuities associated to SWRS and flow intermittency modulate the spatiotemporal patterns, controls and sources of C gas fluxes in the studied fluvial network. However, the magnitude of these effects varied depending on the nature of the discontinuity (i. e., river impoundment or flow intermittency), the type of C gas (i. e., carbon dioxide (CO 2) or methane (CH 4)) and the hydrological condition (i. e., high or low flow). The presence of SWRS, despite their relatively small water capacity, attenuated the turbulent conditions occurring in free-flowing river sections. As a consequence, the diffusive CO 2 emissions from impounded waters were significantly lower than from free-flowing river sections. Contrarily, no reduction in CH 4 emissions from impounded river sections associated to the presence of SWRS was detected. This result suggests that the higher internal CH 4 production at the impounded river sections, which remained very stable over time, compensated the attenuated physical effect on CH 4 emissions. Despite potential inaccuracies in capturing the temporal and spatial heterogeneity, the ebullition was the predominant pathway of CH 4 emissions in impounded river sections. Moreover, sources other than internal metabolism (i. e., external inputs, internal geochemical reactions or photochemical mineralization) sustained most of the fluvial network CO 2 emissions. Specifically, the magnitude and sources of CO 2 emissions depended on flow conditions in the free-flowing sections, whereas they remained relatively stable and independent of hydrological variation in the impounded river sections. The channels of temporary rivers remain as active biogeochemical habitats processing and degassing significant amounts of CO 2 to the atmosphere after flow cessation. In contrast, the CH 4 efflux from dry beds was undetectable in almost all cases, most likely due to the high aeration limiting the redox requirements for microbial CH 4 production. Our results also suggest that the source of CO 2 emitted from dry riverbeds remains unclear, although CO 2 produced from biological mineralization of fresh and labile organic matter fractions could be an important source. Future hydrological scenarios considering the combined effects of climate change and human pressures on water resources in the Mediterranean regions show the rather low sensitivity of the annual CO 2, CH 4 and total C emissions to shifts in river discharge. In contrast, they stress the high sensitivity of annual CH 4 and total C emissions to shifts in the surface area of lentic waterbodies associated to SWRS. Overall, the main findings of this dissertation point to the need for a shift away from a continuous and system-centric view to a more inclusive approach that incorporates spatiotemporal discontinuities (i. e., SWRS and flow fragmentation and drying) as a suitable framework to understand the dynamics of C gas fluxes in fluvial networks. Les aigües continentals són uns components molt actius en cicle del carboni (C). Aquests, transformen, emmagatzemen i emeten la meitat de C que reben dels ecosistemes terrestres adjacents. No obstant, encara existeix una elevada incertesa pel que fa als patrons espaciotemporals, factors de control i principals fonts dels fluxos gasosos de C en xarxes fluvials. Els resultats d’aquesta tesi mostren que les estructures de retenció d’aigua de mida petita (ERMP), les quals són molt comuns en rius Mediterranis, van atenuar les condicions turbulents que caracteritzen les seccions del riu amb aigües corrents. Com a conseqüència, les emissions difusives de CO 2 des d’aigües represades van ser inferiors a aquells des d’aigües corrents. Contràriament, la presència de ERMP no va suposar un efecte negatiu sobre les emissions de CH 4. Tanmateix, fonts diferents al metabolisme intern (això és, entrades externes i reaccions geoquímiques o fotoquímiques internes) van sostenir les emissions de CO 2 de la xarxa fluvial. La magnitud i fonts d’aquestes van dependre de les condicions hidrològiques en el cas dels trams d’aigües corrents, mentre que es van mantenir relativament estables i independents de la hidrologia en aquelles seccions de riu reprssades. Les lleres dels rius intermitents romanen actives pel que fa al processat i emissió de CO 2 a l’atmosfera una vegada el flux superficial d’aigua cessa. Per contra, el flux d’emissió de CH 4 des de les lleres seques va ser indetectable en gairebé tots els casos, probablement degut a les condicions d’alta aeració que limiten els <b>requisits</b> redox per a la producció microbiana de CH 4. El flux d’emissió de CO 2 des de les lleres seques va doblar a l’emès des de les lleres amb aigües corrents i va ser comparable a l’emès des dels sòls terrestres adjacents. No obstant, les lleres seques i els sòls terrestres adjacents van resultar ser mol diferents des d’un punt de vista fisicoquímic, mostrant així diferències en els principals factors i fonts que en regulen les emissions de CO 2. En resum, les principals troballes fetes en aquesta tesi apunten cap a una necessitat clara de substituir els models continus i limitats espacialment per aquells models que incorporen discontinuïtats espaciotemporals (això és, represament del riu o intermitència del règim hidrològic) per tal d’entendre en millor mesura les dinàmiques dels fluxos gasos de C en xarxes fluvials...|$|R
40|$|Network {{monitoring}} {{has always}} been a topic of foremost importance for both network operators and researchers for multiple reasons ranging from anomaly detection to tra c classi cation or capacity planning. Nowadays, as networks become more and more complex, tra c increases and security threats reproduce, achieving a deeper understanding of {{what is happening in the}} network has become an essential necessity. In particular, due to the considerable growth of cybercrime, research on the eld of anomaly detection has drawn signi cant attention in recent years and tons of proposals have been made. All the same, when it comes to deploying solutions in real environments, some of them fail to meet some crucial requirements. Taking this into account, this thesis focuses on lling this gap between the research and the non-research world. Prior to the start of this work, we identify several problems. First, there is a clear lack of detailed and updated information on the most common anomalies and their characteristics. Second, unawareness of sampled data is still common although the performance of anomaly detection algorithms is severely a ected. Third, operators currently need to invest many work-hours to manually inspect and also classify detected anomalies to act accordingly and take the appropriate mitigation measures. This is further exacerbated due to the high number of false positives and false negatives and because anomaly detection systems are often perceived as extremely complex black boxes. Analysing an issue is essential to fully comprehend the problem space and to be able to tackle it properly. Accordingly, the rst block of this thesis seeks to obtain detailed and updated real-world information on the most frequent anomalies occurring in backbone networks. It rst reports on the performance of di erent commercial systems for anomaly detection and analyses the types of network nomalies detected. Afterwards, it focuses on further investigating the characteristics of the anomalies found in a backbone network using one of the tools for more than half a year. Among other results, this block con rms the need of applying sampling in an operational environment as well as the unacceptably high number of false positives and false negatives still reported by current commercial tools. On the whole, the presence of ampling in large networks for monitoring purposes has become almost mandatory and, therefore, all anomaly detection algorithms that do not take that into account might report incorrect results. In the second block of this thesis, the dramatic impact of sampling on the performance of well-known anomaly detection techniques is analysed and con rmed. However, we show that the results change signi cantly depending on the sampling technique used and also on the common metric selected to perform the comparison. In particular, we show that, Packet Sampling outperforms Flow Sampling unlike previously reported. Furthermore, we observe that Selective Sampling (SES), a sampling technique that focuses on small ows, obtains much better results than traditional sampling techniques for scan detection. Consequently, we propose Online Selective Sampling, a sampling technique that obtains the same good performance for scan detection than SES but works on a per-packet basis instead of keeping all ows in memory. We validate and evaluate our proposal and show that it can operate online and uses much less resources than SES. Although the literature is plenty of techniques for detecting anomalous events, research on anomaly classi cation and extraction (e. g., to further investigate what happened or to share evidence with third parties involved) is rather marginal. This makes it harder for network operators to analise reported anomalies because they depend solely on their experience to do the job. Furthermore, this task is an extremely time-consuming and error-prone process. The third block of this thesis targets this issue and brings it together with the knowledge acquired in the previous blocks. In particular, it presents a system for automatic anomaly detection, extraction and classi cation with high accuracy and very low false positives. We deploy the system in an operational environment and show its usefulness in practice. The fourth and last block of this thesis presents a generalisation of our system that focuses on analysing all the tra c, not only network anomalies. This new system seeks to further help network operators by summarising the most signi cant tra c patterns in their network. In particular, we generalise our system to deal with big network tra c data. In particular, it deals with src/dst IPs, src/dst ports, protocol, src/dst Autonomous Systems, layer 7 application and src/dst geolocation. We rst deploy a prototype in the European backbone network of G EANT and show that it can process large amounts of data quickly and build highly informative and compact reports that are very useful to help comprehending what is happening in the network. Second, we deploy it in a completely di erent scenario and show how it can also be successfully used in a real-world use case where we analyse the behaviour of highly distributed devices related with a critical infrastructure sector. La monitoritzaci o de xarxa sempre ha estat un tema de gran import ancia per operadors de xarxa i investigadors per m ultiples raons que van des de la detecci o d'anomalies fins a la classi caci o d'aplicacions. Avui en dia, a mesura que les xarxes es tornen m es i m es complexes, augmenta el tr ansit de dades i les amenaces de seguretat segueixen creixent, aconseguir una comprensi o m es profunda del que passa a la xarxa s'ha convertit en una necessitat essencial. Concretament, degut al considerable increment del ciberactivisme, la investigaci o en el camp de la detecci o d'anomalies ha crescut i en els darrers anys s'han fet moltes i diverses propostes. Tot i aix o, quan s'intenten desplegar aquestes solucions en entorns reals, algunes d'elles no compleixen alguns <b>requisits</b> fonamentals. Tenint aix o en compte, aquesta tesi se centra a omplir aquest buit entre la recerca i el m on real. Abans d'iniciar aquest treball es van identi car diversos problemes. En primer lloc, hi ha una clara manca d'informaci o detallada i actualitzada sobre les anomalies m es comuns i les seves caracter stiques. En segona inst ancia, no tenir en compte la possibilitat de treballar amb nom es part de les dades (mostreig de tr ansit) continua sent bastant est es tot i el sever efecte en el rendiment dels algorismes de detecci o d'anomalies. En tercer lloc, els operadors de xarxa actualment han d'invertir moltes hores de feina per classi car i inspeccionar manualment les anomalies detectades per actuar en conseqüencia i prendre les mesures apropiades de mitigaci o. Aquesta situaci o es veu agreujada per l'alt nombre de falsos positius i falsos negatius i perqu e els sistemes de detecci o d'anomalies s on sovint percebuts com caixes negres extremadament complexes. Analitzar un tema es essencial per comprendre plenament l'espai del problema i per poder-hi fer front de forma adequada. Per tant, el primer bloc d'aquesta tesi pret en proporcionar informaci o detallada i actualitzada del m on real sobre les anomalies m es freqüents en una xarxa troncal. Primer es comparen tres eines comercials per a la detecci o d'anomalies i se n'estudien els seus punts forts i febles, aix com els tipus d'anomalies de xarxa detectats. Posteriorment, s'investiguen les caracter stiques de les anomalies que es troben en la mateixa xarxa troncal utilitzant una de les eines durant m es de mig any. Entre d'altres resultats, aquest bloc con rma la necessitat de l'aplicaci o de mostreig de tr ansit en un entorn operacional, aix com el nombre inacceptablement elevat de falsos positius i falsos negatius en eines comercials actuals. En general, el mostreig de tr ansit de dades de xarxa (es a dir, treballar nom es amb una part de les dades) en grans xarxes troncals s'ha convertit en gaireb e obligatori i, per tant, tots els algorismes de detecci o d'anomalies que no ho tenen en compte poden veure seriosament afectats els seus resultats. El segon bloc d'aquesta tesi analitza i confi rma el dram atic impacte de mostreig en el rendiment de t ecniques de detecci o d'anomalies plenament acceptades a l'estat de l'art. No obstant, es mostra que els resultats canvien signi cativament depenent de la t ecnica de mostreig utilitzada i tamb e en funci o de la m etrica usada per a fer la comparativa. Contr ariament als resultats reportats en estudis previs, es mostra que Packet Sampling supera Flow Sampling. A m es, a m es, s'observa que Selective Sampling (SES), una t ecnica de mostreig que se centra en mostrejar fluxes petits, obt e resultats molt millors per a la detecci o d'escanejos que no pas les t ecniques tradicionals de mostreig. En conseqü encia, proposem Online Selective Sampling, una t ecnica de mostreig que obt e el mateix bon rendiment per a la detecci o d'escanejos que SES, per o treballa paquet per paquet enlloc de mantenir tots els fluxes a mem oria. Despr es de validar i evaluar la nostra proposta, demostrem que es capa c de treballar online i utilitza molts menys recursos que SES. Tot i la gran quantitat de tècniques proposades a la literatura per a la detecci o d'esdeveniments an omals, la investigaci o per a la seva posterior classi caci o i extracci o (p. ex., per investigar m es a fons el que va passar o per compartir l'evid encia amb tercers involucrats) es m es aviat marginal. Aix o fa que sigui m es dif cil per als operadors de xarxa analalitzar les anomalies reportades, ja que depenen unicament de la seva experi encia per fer la feina. A m es a m es, aquesta tasca es un proc es extremadament lent i propens a errors. El tercer bloc d'aquesta tesi se centra en aquest tema tenint tamb e en compte els coneixements adquirits en els blocs anteriors. Concretament, presentem un sistema per a la detecci o extracci o i classi caci o autom atica d'anomalies amb una alta precisi o i molt pocs falsos positius. Adicionalment, despleguem el sistema en un entorn operatiu i demostrem la seva utilitat pr actica. El quart i ultim bloc d'aquesta tesi presenta una generalitzaci o del nostre sistema que se centra en l'an alisi de tot el tr ansit, no nom es en les anomalies. Aquest nou sistema pret en ajudar m es als operadors ja que resumeix els patrons de tr ansit m es importants de la seva xarxa. En particular, es generalitza el sistema per fer front al "big data" (una gran quantitat de dades). En particular, el sistema tracta IPs origen i dest i, ports origen i destí, protocol, Sistemes Aut onoms origen i dest, aplicaci o que ha generat el tr ansit i fi nalment, dades de geolocalitzaci o (tamb e per origen i dest). Primer, despleguem un prototip a la xarxa europea per a la recerca i la investigaci o (G EANT) i demostrem que el sistema pot processar grans quantitats de dades r apidament aix com crear informes altament informatius i compactes que s on de gran utilitat per ajudar a comprendre el que est a succeint a la xarxa. En segon lloc, despleguem la nostra eina en un escenari completament diferent i mostrem com tamb e pot ser utilitzat amb exit en un cas d' us en el m on real en el qual s'analitza el comportament de dispositius altament distribuïts. Postprint (published version...|$|R
40|$|Romania {{fits into}} areas with {{relatively}} poor water resources, {{compared to other}} regions of the world, ranked 29 in Europe. Siret River Basin level, water resources are in the same situation still occupies an important place in the total resources of the country. Economic and social development requires the provision of additional water requirements, but wich should be used sensibly. Representing the Water resource taken directly from natural sources of surface and ground water, requirement ensures water supply used in various destinations such as population and industrial and agricultural businesses. The water resource is not evenly distributed in time and space. Also, and its use is done unevenly, with maximum requirement periods, medium or low. There are periods when the water <b>requisit</b> are not covered by unarranged direct sources even though technological processes are equipped with internal water circulation systems or connected external to water networks. In order to ensure water requirements in any situation and in any case with deficite hydroclimatic or with maximum requirements of perspective, on the watercourse are realized hydrotechnics works, according complex planning schemes a hydrographical basins. Thus, the water courses have been furnished with accumulations, derivatives and water intakes which now provides full water requirements. In the Siret River Basin, hydrotechnics works were made in correlation with social and economic development, wich in the decade 1980 - 1990 recorded the largest water requirements. Reducing economic activities correlated to reducing water loss from networks distribution but and with modernization of the technological processes, the last two decades have led to significant reductions in water requirements. Under these conditions some hydrotechnic arrangements with main water alimentation role, have changed initial functions or {{are in the process of}} redevelopment to become profitable and maintain aquatic and adjacent terrestrial ecosystems. In this paper we present some aspects regarding the trends of evolution water requirements and Facilities and hydrotechnic structures with role by water alimentation of the users from the Siret River Basin...|$|E
40|$|ANGLÈS] In recent years, {{the growing}} number of oceanographic {{applications}} that rely on underwater communications has motivated extensive research in the field. These scientific projects usually require data acquisition from sensor networks or the use of unmanned underwater vehicles. One method to establish communication with such underwater systems is through the use of wired links. However, cables are hard to install or repair at certain depths, and can dramatically limit the mobility of both communication ends. Underwater wireless communications do not have such constraints and therefore present a much more attractive approach for underwater data transfer. Electromagnetic waves typically provide higher throughputs than any other wireless communication method. However, they suffer from tremendous attenuation in water mediums. Consequently, underwater radio communications are only applicable to very short range high-speed links. For general purpose communications, acoustic waves are the preferred method. The fact that the wave propagation speed is five orders of magnitude smaller causes serious issues, such as long end-to-end delays and extreme Doppler distortion produced by the relative motion between transmitter and receiver. The underwater channel also suffers from multipath propagation produced by wave refraction, as well as reflections from the surface and the sea bed. The aforementioned issues complicate the design of an underwater acoustic system, which is able to offer both reliability and a reasonable communication speed at the same time. The aim of this work is to increase the robustness of the state-of-the-art underwater communication schemes. We achieve this goal using multiple transmitting and receiving elements, where each transmitter-receiver combination counts as an additional communication channel. The increased number of parallel channels drastically reduces the the error probability of the link, i. e. the probability that all channels are experiencing simultaneous fading. Orthogonal frequency division multiplexing (OFDM) is considered for frequency-selective underwater acoustic (UWA) channels as it offers low complexity of fast Fourier transform-based (FFT) signal processing, and ease of reconfiguration for use with different bandwidths. In addition, by virtue of having a narrowband signal on each carrier, OFDM is easily conducive to multi-input multi-output (MIMO) system configurations. MIMO systems have been considered for UWA channels both for increasing the system throughput via spatial multiplexing and for improving the systems performance via spatial diversity. The focus of our present work is on transmit diversity, which we pursue through the use of Alamouti coding applied across the carriers of an OFDM signal. Space-frequency block coding (SFBC) is chosen over traditional space-time block coding (STBC) as better suited for use with acoustic OFDM signals. Namely, while the Alamouti coherence assumption may be challenged between two adjacent OFDM blocks on a time-varying acoustic channel, it is expected to hold between two adjacent OFDM carriers: frequency coherence assumption coincides with the basic OFDM design principle which calls for carriers to be spaced closely enough that the channel transfer function can be considered flat over each sub-band. Previous studies in radio communications have also revealed situations in which SFBC outperforms STBC. Two types of approaches have been considered for MIMO OFDM acoustic systems: nonadaptive, where each block is processed independently using pilot-assisted channel estimation, and adaptive, where coherence between adjacent blocks is exploited to enable decision-directed operation and reduce the pilot overhead. Both approaches require front-end synchronization for initial Doppler compensation through signal resampling. Front-end processing remains unchanged for multiple transmitters if they are co-located and experience the same gross Doppler effect. Otherwise, multiple resampling branches may be needed to compensate for transmitter-specific Doppler shifting. Leveraging on the adaptive MIMO-OFDM design, we develop a receiver algorithm for the SFBC scenario. Specifically, we decouple the channel distortion into a slowly-varying gain and a faster-varying phase, which enables us to track these parameters at different speeds. For estimating the channel, we use either the orthogonal matching pursuit (OMP) algorithm or a newly developed algorithm based on least squares with adaptive thresholding (LS-AT). This algorithm computes the full-size LS solution to the impulse response (IR) domain channel representation, then truncates it to keep only the significant IR coefficients. However, unlike the typical truncated LS solutions which use a fixed truncation threshold, the threshold is determined adaptively so as to provide a proper level of sparseness. LS-AT is found to perform close to OMP, at a lower computational cost. Once an initial channel estimate is formed, its tracking continues via time-smoothing. Simultaneously, an estimate of the residual Doppler scale is made for each of the two transmitters, and this estimate is used to predict and update the carrier phases in each new OFDM block. The advantages of Alamouti SFBC are contingent upon frequency coherence, which increases as more carriers are packed within a given bandwidth (the bandwidth efficiency simultaneously increases). However, there is a fine line after which inter-carrier interference (ICI) will be generated, and this line should not be crossed if simplicity of Alamouti detection is to be maintained. We assess this trade-off through simulation and experimental data processing, showing the existence of an optimal number of carriers and an accompanying transmit diversity gain. [CASTELLÀ] En los últimos años, el volumen de investigación en el campo de las comunicaciones subacuáticas ha aumentado de forma considerable. La nueva variedad de aplicaciones científicas como, por ejemplo, el control de la polución y las especies marinas autóctonas, la monitorización de movimientos sísmicos del suelo marino o la exploración subacuática del hielo del Ártico, entre otras, han motivado su investigación más allá de las aplicaciones militares. Estas aplicaciones requieren, en la mayoría de casos, el uso de redes de sensores o de vehículos subacuáticos no tripulados, que habitualmente se comunican mediante redes inalámbricas a fin de evitar las restricciones de movilidad y la complejidad que supone la instalación de cableado submarino. La fuerte atenuación que sufren las ondas electromagnéticas en el medio acuático restringe su uso exclusivamente a enlaces de alta capacidad pero corto alcance del orden de centímetros. Las comunicaciones de propósito general se establecen mediante ondas acústicas. En estos casos, la velocidad de propagación de onda es cinco órdenes de magnitud inferior y juega un rol muy importante, debido a que los retrasos de propagación en enlaces de pocos kilómetros son del orden del segundo. Además, el movimiento relativo entre transmisor y receptor genera una severa distorsión por efecto Doppler que requiere procesado de señal adicional en el receptor. El canal subacuático también se caracteriza por la propagación multicamino, provocada por refracción y las reflexiones de la onda con la superficie y el fondo marino. Las dificultades mencionadas complican el diseño de un sistema que sea a la vez fiable y tenga una capacidad de transmisión razonable. El objetivo de este proyecto es diseñar un sistema que transmite códigos espacio-frecuencia, con la finalidad de obtener diversidad en transmisión y mejorar de forma notable la calidad del enlace de comunicaciones. La motivación para investigar los códigos espacio-frecuencia se basa en el hecho que recientemente se han obtenido resultados esperanzadores con el uso de códigos espacio-tiempo. No obstante, la variación de canal limita de forma considerable el rendimiento de los códigos espacio-tiempo, ya que el código se extiende a más de un bloque temporal. El objetivo es evitar este efecto cambiando la dimensión temporal por frecuencia aún manteniendo la estructura y beneficios del código original. Así, las diferentes partes del código son multiplexadas de forma simultánea en diferentes frecuencias y la transmisión completa del código se consigue con un solo uso de canal. En este proyecto se utiliza como modulación el multiplexado en división de frecuencia ortogonal (OFDM), principalmente porqué ofrece un método muy sencillo para ecualizar canales selectivos. La modulación OFDM también ofrece una versatilidad muy interesante para reconfigurar el ancho de banda y el espaciado entre frecuencias portadoras. Además, el uso combinado de OFDM y los sistemas multiple-input multiple-output (MIMO) simplifica notablemente el procesado de señal, ya que cada portadora puede ser tratada como un canal no selectivo. Los sistemas MIMO se usan en canales acústicos subacuáticos tanto para incrementar la velocidad de transmisión como para mejorar el rendimiento de los sistemas aprovechando la diversidad espacial. En nuestro caso, se usa un sistema MIMO con el objetivo de obtener diversidad en transmisión a partir del uso de códigos Alamouti transformados al dominio frecuencial. Los códigos bloque espacio-frecuencia (SFBC) son más adecuados para la modulación OFDM que los códigos espacio-tiempo (STBC). Esto se debe a que los bloques OFDM suelen tener una duración considerable que puede comprometer la condición de coherencia, la cual exige un canal constante durante todos los bloques que conforman el código. Cuando se usan códigos SFBC, la coherencia de canal debe ser respetada de la misma manera pero durante dos portadoras adyacentes. Afortunadamente este requisito coincide con la condición de diseño de la modulación OFDM, en la cual las portadoras adyacentes deben ser suficientemente cercanas como para que el canal pueda considerarse constante. En la literatura encontramos resultados recientes para comunicaciones radioeléctricas que demuestran situaciones en las que los códigos SFBC tienen un rendimiento superior a los códigos STBC. Existen principalmente dos tipos de receptores MIMO-OFDM para comunicaciones subacuáticas: no adaptativos, en los que cada bloque se procesa independientemente de los demás y el canal se estima usando símbolos piloto, y adaptativos, en los que se aprovecha la coherencia del canal entre bloques consecutivos para hacer predicciones del canal futuro y reducir el número total de símbolos piloto. En ambos casos se requiere una etapa de sincronización y corrección de la distorsión Doppler, que se aplica de la misma manera en todos los receptores si estos se encuentran co-localizados. En caso contrario la compensación se realiza con un algoritmo de compensación paralela. El diseño del algoritmo de recepción para códigos SFBC está basado en el receptor MIMO-OFDM adaptativo. El receptor separa el canal en dos factores: la amplitud del canal, que tiene una variación lenta, y una fase de variación rápida. La esencia del receptor es la posibilidad de estimar estos parámetros de forma paralela a diferentes velocidades. Para la estimación de canal se utilizan alternativamente el método OMP, o bien un nuevo algoritmo presentado en este proyecto basado en estimación por mínimos cuadrados con un umbral de truncamiento adaptativo. El nuevo método, que se denomina least squares with adaptive thresholding (LS-AT), trunca la respuesta impulsional del canal con la finalidad de mantener solamente los coeficientes relevantes. En este caso, a diferencia de los métodos habituales de truncamiento con umbral fijo, el umbral se determina de forma adaptativa para ofrecer la mejor separación posible entre canal y ruido. El algoritmo LS-AT ofrece un rendimiento muy cercano al del algoritmo OMP pero requiere una carga computacional considerablemente menor. Los beneficios del uso de códigos espacio-frecuencia se evalúan mediante simulación matemática y también con transmisiones experimentales realizadas en el océano Atlántico. Los beneficios obtenidos están estrechamente ligados a la condición de coherencia en el dominio frecuencial, de modo que la ganancia es mayor cuando se disminuye el espaciado entre portadoras. A la vez que se reduce el espaciado frecuencial, la longitud temporal del bloque OFDM aumenta y se observa la aparición de interferencia inter-portadora (ICI), la cual degrada notablemente el rendimiento. En los resultados se observa que el efecto de este compromiso lleva a la existencia de un número óptimo de portadoras. [CATALÀ] En els últims anys el volum d'investigació en el camp de les comunicacions subaquàtiques ha augmentat considerablement. L'increment en el nombre d'aplicacions científiques, com per exemple el control de la pol·lució i les espècies marines autòctones, la monitorització de moviments sísmics del sòl marí o l'exploració subaquàtica del gel de l'Àrtic, entre d'altres, ha motivat la recerca més enllà del camp militar. Aquestes aplicacions requereixen, en la majoria de casos, l'ús de xarxes de sensors o de vehicles subaquàtics no tripulats, que habitualment es comuniquen utilitzant xarxes sense fils a fi d'evitar les restriccions de mobilitat i la complexitat que suposa la instal·lació de cablejat submarí. La forta atenuació que pateixen les ones electromagnètiques en el medi aquàtic fa que el seu ús es restringeixi només a enllaços d'alta capacitat però curt abast, de l'ordre de centímetres. Les comunicacions de propòsit general s'estableixen mitjançant ones acústiques. En aquests casos, la velocitat de propagació d'ona és cinc ordres de magnitud inferior i juga un paper molt important, a causa que els retards de propagació en enllaços de pocs quilòmetres són de l'ordre de segons. A més, el moviment relatiu entre transmissor i receptor genera una severa distorsió per efecte Doppler que requereix processament de senyal addicional en l'etapa de recepció. El canal subaquàtic també es caracteritza per la propagació multicamí, provocada per les reflexions de l'ona amb la superfície i el fons marí, així com la refracció produïda pel medi. Les dificultats esmentades compliquen molt el disseny d'un sistema que sigui alhora fiable i amb una capacitat de transmissió raonable. L'objectiu d'aquest projecte és el disseny d'un sistema que transmet codis espai-freqüència, amb la finalitat d'obtenir diversitat en transmissió i millorar de forma notable la qualitat de l'enllaç de comunicacions. La motivació per a investigar els codis espai-freqüència recau en el fet que recentment s'han obtingut resultats esperançadors amb l'ús de codis espai-temps. No obstant això, també s'ha comprovat que la variació del canal limita molt el seu rendiment, ja que un sol codi s'estén a més d'un bloc temporal. L'objectiu és evitar aquest efecte canviant la dimensió temporal per la freqüencial però mantenint l'estructura i els beneficis del codi espai-temps. D'aquesta manera, les diferents parts del codi es poden multiplexar simultàniament en diferents freqüències i la transmissió completa s'assoleix en un sol bloc, i. e. un sol ús del canal. En aquest projecte s'utilitza com a modulació la multiplexació en divisió de freqüència ortogonal (OFDM per les seves sigles en anglès), principalment perquè ofereix un mètode molt senzill per equalitzar els canals selectius. La modulació OFDM també ofereix una versatilitat molt interessant pel que fa a la reconfiguració de l'ample de banda i l'espaiat de portadores. A més, l'ús combinat de l'OFDM i els sistemes multiantena (MIMO) simplifica molt el processament de senyal, ja que cada portadora pot ser tractada com un canal no selectiu. Els sistemes MIMO s'utilitzen en canals acústics subaquàtics tant per incrementar la velocitat de transmissió (multiplexatge en espai), com per millorar el rendiment dels sistemes aprofitant la diversitat espacial. En el nostre cas, el sistema MIMO s'utilitza per aconseguir diversitat en transmissió a partir de l'ús del codi d'Alamouti emprat en domini freqüencial. Els codis de bloc en espai-freqüència (SFBC) són més adequats per a la modulació OFDM que els codis espai-temps (STBC). Això és degut a que els blocs OFDM solen tenir una durada considerable que pot comprometre la condició de coherència, la qual requereix que el canal es mantingui constant durant tots els blocs temporals que ocupa el codi. Pel que fa als codis SFBC, aquesta coherència del canal s'ha de respectar per dues freqüències portadores consecutives. Afortunadament, aquest <b>requisit</b> coincideix amb la condició de disseny de la modulació OFDM, en la qual les portadores adjacents han de ser prou properes com perquè el canal es pugui considerar constant entre l'una i l'altra. A la literatura hi trobem resultats recents per comunicacions radioelèctriques que proven que hi ha situacions en les quals els codis SFBC tenen millor rendiment que els STBC. Existeixen principalment dos tipus de receptors MIMO-OFDM en comunicacions subaquàtiques: no adaptatius, en els quals cada bloc rebut és processat independentment dels altres i el canal s'estima mitjançant símbols pilot, i adaptatius, els quals aprofiten la coherència del canal entre blocs consecutius per fer prediccions de la futura funció de transferència i així reduir el nombre de símbols pilot. En tots dos casos cal una primera etapa de sincronització i correcció de la distorsió Doppler, la qual es fa de la mateixa manera en tots els receptors si aquests es troben co-localitzats. En cas contrari, cal un algorisme de compensació paral·lela. El disseny de l'algorisme de recepció per codis SFBC està basat en el receptor MIMO-OFDM adaptatiu. Més concretament, el receptor separa el canal en dos factors: el guany del canal, que té una variació lenta, i una fase que varia ràpidament. L'essència del receptor és que pot estimar aquests dos paràmetres a diferents velocitats. Per a estimar el canal s'utilitza tant el mètode OMP com un nou algorisme que es presenta en aquest treball, el qual està basat en una estimació per mínims quadrats amb un llindar de truncament adaptatiu. Aquest últim, anomenat least squares with adaptive thresholding (LS-AT), pren la resposta impulsional del canal i la trunca a partir d'un llindar amb la finalitat de mantenir només els coeficients rellevants. En aquest cas, a diferència dels mètodes habituals de truncament amb llindar fix, el llindar es determina de forma adaptativa per oferir la millor separació possible entre coeficients significants i soroll. L'algorisme LS-AT ofereix un rendiment molt semblant a l'OMP amb una càrrega computacional molt més baixa. Un cop el receptor obté una primera estimació del canal, fa un seguiment de la variació del guany per millorar l'estimació dels blocs futurs. Al mateix temps, també mesura el factor Doppler de cada un dels transmissors per fer una predicció de la fase per al proper bloc OFDM. Els beneficis de l'ús de codis espai-freqüència s'avaluen en aquest projecte mitjançant simulació matemàtica i transmissions experimentals realitzades a l'oceà Atlàntic. El guany observat es troba estretament lligat amb la condició de coherència en el domini freqüencial, de manera que el guany és major quan es disminueix l'espaiat entre portadores. Paral·lelament, per espaiats freqüencials menors, la longitud del bloc OFDM augmenta i es comença a observar l'aparició d'interferència inter-portadora (ICI), que degrada notablement el rendiment. En els resultats s'observa l'efecte d'aquest compromís entre coherència temporal i freqüencial, el qual porta a l'existència d'un nombre òptim de portadores...|$|E
40|$| del sensor de gas justifica les propietats químiques de la superfície. Per fer-ho, les nanofibres han estat estudiades fent servir la tècnica de Espectroscòpia de Fotoelectrons emesos per raigs X (XPS) per obtenir informació de la composició química de la seva superfície. S’ha descobert que el procés de grafitització elimina totes les impureses de la superfície deixant únicament carboni i oxigen. Aquest últim element és una troballa sorprenent ja que, tot i que la quantitat d’oxigen present és baixa (1 %), això vol dir que tot i el procés de grafitització encara hi ha alguns grups funcionals que sobreviuen al tractament amb altes {{temperatures}} i atmosfera reductora. Bàsicament, els grups funcionals supervivents son àtoms d’oxigen enllaçats amb un enllaç o hidroxils, mentre que els grups carbonils son els que pateixen més reducció durant el tractament. Per fabricar el sensor de gas es necessari de trobar una forma de manipular les nanofibres de carboni. La forma més fàcil és fer servir un solvent com a portador de les nanofibres, però les CNFG no son estables en solvents polars. Amb les mesures de XPS es pot veure com la superfície de les nanofibres es torna més ordenada després de la grafitització (augment dels enllaços sp 2). Una inspecció detallada de la superfície de les nanofibres mitjançant Microscòpia Electrònica de Transmissió (TEM) mostra que les vores de les nanofbires de carboni es tanquen sobre elles mateixes exposant majoritàriament els enllaçoso sp 2 que son menys reactius. S’ha descobert que aplicant un tractament tèrmic en una atmosfera rica en oxigen es possible tornar a obrir aquestes voreres exposant els enllaços sp 3 tornant més reactiva la superfície i permetent la formació de solucions estables de nanofibres de carboni en solvents polars en concentracions de fins 1 mg/ml. Amb aquestes solucions es possible fabricar els sensors de gas utilitzant les nanofibres de carboni com a capa activa. Com que l’objectiu es fabricar un sensor de gas flexible els elèctrodes han estat fabricats mitjançant la tècnica d’impressió ink-jet amb tinta de plata sobre un substrat de kapton. Les nanofibres de carboni son dipositades directament sobre els elèctrodes mitjançant un sistema modificat d’electrospray, formant la capa activa. A part de tindre una major reactivitat i estabilitat en solució, també s’ha estudiat la possibilitat de decorar la superfície de les nanofibres de carboni amb nanopartícules metàl•liques per millorar la seva resposta a determinats gasos. S’ha seguit la estratègia de la mescla directa de sals metàl•liques (AuCl 3 i PdCl 2), fent servir un procés extra de ball-milling per promoure l’adhesió de la sal a la superfície de la nanofibra. Després del procés d’impregnació el material es tractat en un procés de recuit en una atmosfera d’oxigen per descompondre la sal i obtenir les nanopartícules metàl•liques (Au i Pd). La resposta pels diferents tipus de nanofibres (sense modificar i decorades amb Au i Pd) han estat estudiades. En general, les nanofibres responen bé a la humitat inclús a temperatura ambient. A més, amb una humitat relativa del 50 % es poden detectar gasos tal com NH 3 o NO 2 amb un petit efecte de enverinament de la superfície. Si s’aplica temperatura aquest efecte desapareix i es troba que la temperatura òptima d’operació es 110 ºC. Per la seva banda, el grafé està demostrant sent un material prometedor per una gran varietat d’aplicacions. Gràcies a la seva estructura planar i transparència es molt adequat per la fabricació d’elèctrodes transparents, però també pot ser útil per transistors o capes protectores. Tot i això, un dels principals problemes és trobar un mètode estandarditzat per sintetitzar i dipositar grans àrees amb grafé d’alta qualitat. Una de les possibilitats és seguir una ruta química, en que s’oxida fortament el grafit i després es desmunten les plaques mitjançant sonicació, obtenint el que s’anomena grafé oxidat (GO). Després es té que reduir el material per obtenir grafé oxidat reduït (rGO), un material similar al grafé. És necessari que tots aquests tractaments siguin monitoritzats per obtenir el millor material possible. A més, aquest sistema d’anàlisi tindria que ser compatible amb el possible procés industrial de síntesi i dipòsit. L’espectroscòpia Raman compleix aquests <b>requisits,</b> ja que és una tècnica ràpida i fàcil d’utilitzar, a part de que és no destructiva i dona la possibilitat de analitzar directament els dispositius finals. En aquest estudi s’ha proposat fer servir el pic D’’ per analitzar el GO i els seus productes reduïts a partir d’un procés de reducció tèrmic. Hem descobert que el pic D’’ pot ser usat com a marcador per analitzar el estat de la reducció a ja que la seva posició depèn d’aquesta característica. A més a més, s’ha demostrat que fent servir el pic D’’ els altres pics (D, G i D’) segueixen les relacions presentades per altres autors per carbonis desordenats o activats, volent dir que el pic D’’ ajuda a obtenir el grau de desordre real de la mostra...|$|R
40|$| rang de nivells d’oxigenació cel•lular (PmO 2), i a regions del múscul esquelètic amb una major aportació sanguínia en comparació a la capacitat metabòlica, els valors de PmO 2 poden excedir els valors d’oxigenació venosa mixta. Malauradament, la mesura del nivell d’heterogeneïtat funcional al múscul esquelètic és molt insuficient degut a les limitacions tecnològiques. El model indica que la relació entre la capacitat de {{transport}} d’oxigen i utilització d’oxigen determina principalment els valors d’oxigenació cel•lular PmO 2. Aquest fenomen, pot ser molt rellevant després d’un procés d’entrenament d’alta intensitat a pacients MPOC amb limitacions de transport d’oxigen degut a la malaltia pulmonar. Les simulacions utilitzant dades mesurades en subjectes sans realitzant exercici màxim han desvelat que l’altitud desencadena una alta producció de ROS mitocondrial a les regions del múscul esquelètic amb una altra capacitat mitocondrial però amb una limitada capacitat d’aportació d’oxigen. Aquesta observació és evident a partir d’una altitud corresponent a uns 5000 metres sobre el nivell del mar. Per sobre d’aquesta altitud no existeix cap assentament humà permanentment habitat i els humans experimenten una pèrdua inexorable de massa corporal. Però, es conclou que l’ús del model integrat en condicions de malaltia requereix una millor estimació dels paràmetres mitocondrials. Suport TIC per al desplegament de serveis d’atenció integrada (SAI-TIC) i la interacció entre l’atenció sanitària i la investigació biomèdica basada en la medicina de sistemes S’ha desenvolupat una plataforma tecnològica modular que proporciona un conjunt bàsic d’eines i tecnologies per donar suport a la implementació de SAI-TIC per a pacients crònics. Aquesta plataforma tecnològica ha suportat de manera eficient els quatre SAI dissenyats i avaluats en el context del projecte europeu NEXES (2008 - 2013, www. nexeshealth. eu) a un dels districtes sanitaris de Barcelona, amb un total de 540. 000 habitants, i ha mostrat potencial d’escalabilitat a nivell regional. El concepte de “Digital Health Framework (DHF) ” ha estat articulat amb la finalitat d’enllaçar l’atenció sanitària i a la investigació biomèdica basada en la medicina de sistemes. La base de coneixement de Synergy-COPD ha estat desenvolupada com a un component d’investigació del DHF per tal de fomentar la transició envers una medicina 4 P. CONCLUSIONS 1. El model que integra els determinants fisiològics de la cadena de transport d’oxigen i els elements bioquímics moduladors de la formació a nivell mitocondrial de ROS, ha proporcionat, per primera vegada, un anàlisi quantitatiu de la relació entre la oxigenació cel•lular i la producció mitocondrial de ROS. El model genera resultats consistents en salut, però una millor estimació dels paràmetres mitocondrials és necessària quan s’aplica a MPOC. 2. La plataforma tecnològica per al suport de serveis d’atenció integrada (SAI) per a pacients crònics ha cobert de forma efectiva els <b>requisits</b> funcionals per al desplegament d’un entorn amb un únic proveïdor. Els reptes que cal afrontar per a un desplegament a nivell regional de SAI han estat identificats i s’han proposat estratègies per a la seva adopció. 3. El concepte de “Digital Health Framework (DHF) ” representa un escenari on l’enllaç entre l’atenció integrada i la investigació biomèdica de medicina de sistemes han de promoure el desplegament de la medicina 4 P. S’ha proposat les línies estratègiques per a una correcta adopció del DHF. 4. La base del coneixement específica per a MPOC (COPDkb) ha estat desenvolupada i analitzada en aquesta tesi doctoral, constitueix un component principal de la investigació biomèdica basada en la medicina de sistemes. INTRODUCCIÓN La proliferación de enfermedades no transmisibles y la creciente necesidad de contención de costes están desencadenando un profundo rediseño de la atención sanitaria hacia la adopción de un modelo de atención a crónicos, involucrando la implementación de servicios de atención integrada (SAI) con el soporte de las tecnologías de la información y de la comunicación (SAI-TIC). En este escenario, la emergente medicina de sistemas, con una aproximación holística basada en los mecanismos de las enfermedades, juega un papel muy relevante en la evaluación del riesgo para la salud y la estratificación de pacientes. El objetivo principal de Synergy-COPD ha sido la exploración del potencial de una aproximación de medicina de sistemas para mejorar el conocimiento de los mecanismos subyacentes a la heterogeneidad de la enfermedad pulmonar obstructiva crónica (EPOC). Haciendo énfasis en los efectos sistémicos de la enfermedad, así como en la comorbilidad. La transferencia de nuevos conocimiento a la atención sanitaria ha sido también un objetivo principal del proyecto. Por otro lado, Synergy-COPD ha explorado nuevas interacciones entre investigación biomédica y atención sanitaria, con la finalidad última de promover la medicina 4 P (Predictiva, Preventiva, Personalidad y Participativa) para pacientes con enfermedades crónicas. Esta tesis doctoral contribuye con Synergy-COPD en dos aspectos específicos: 1. Un análisis cuantitativo de la relación entre la oxigenación celular y la producción de radicales libres de oxígeno (ROS) a nivel mitocondrial. 2. Diversos desarrollos tecnológicos dirigidos a la trasferencia de conocimiento biomédico a la atención sanitaria y la investigación biomédica. HIPÓTESIS La hipótesis general de esta tesis doctoral es que una personalización de la evaluación del riesgo para la salud y la estratificación, tiene que desencadenar una atención sanitaria más eficiente y orientada al paciente. Específicamente, esta tesis doctoral plantea la hipótesis de que un modelado mecanicista del sistema de transporte y utilización de oxígeno, teniendo en cuenta la función mitocondrial, puede contribuir a evaluar los efectos biológicos de la hipoxia celular y su papel en la disfunción del músculo esquelético en la EPOC. Por otra parte, se plantea la hipótesis de que un diseño holístico basado en las TIC puede contribuir a una implementación exitosa de SAI-TIC para los pacientes crónicos, fomentando la transferencia de los logros de la investigación orientada a sistemas en la asistencia sanitaria. OBJETIVOS La integración del modelado fisiológico del sistema de transporte y utilización de oxígeno con el modelado bioquímico de la generación mitocondrial de ROS, con la finalidad de analizar las relaciones entre la oxigenación del músculo esquelético y la producción mitocondrial de ROS. El desarrollo de herramientas TIC que den soporte a servicios de atención integrada (SAI-TIC) para pacientes crónicos, y que fomenten la interacción entre la investigación biomédica basada en la medicina de sistemas y la atención sanitaria. RESULTADOS PRINCIPALES Análisis cuantitativo de la relación entre oxigenación celular y la generación mitocondrial de ROS El modelaje realizado en esta tesis doctoral analiza todos los factores determinantes de la cadena de transporte de oxígeno. Se ha mostrado que un determinado grado de heterogeneidad en el músculo esquelético reduce la transferencia global de oxígeno más de lo que la reduce la heterogeneidad pulmonar. Sin embargo, la heterogeneidad observada actualmente a nivel pulmonar es mayor que la observada en músculo, por lo tanto, la heterogeneidad pulmonar en general tiene un impacto mayor sobre la transferencia total de oxígeno. Por otra parte, hemos mostrado que la heterogeneidad muscular incrementa el rango de niveles de oxigenación celular (PmO 2), y en regiones del músculo esquelético con un mayor aporte sanguíneo en comparación con la capacidad metabólica, los valores de PmO 2 pueden exceder los correspondientes valores de oxigenación venosa mixta. Desafortunadamente, la medición del nivel de heterogeneidad funcional en músculo esquelético es muy insuficiente {{debido a}} las limitaciones tecnológicas. El modelo indica que la relación entre la capacidad de transporte y utilización de oxígeno determina principalmente los valores de oxigenación celular (PmO 2). Este fenómeno, puede que sea muy relevante después de un proceso de entrenamiento de alta intensidad en pacientes EPOC con limitaciones de transporte de oxígeno debido a la enfermedad pulmonar. Simulaciones utilizando datos medidos en sujetos sanos realizando ejercicio máximo han desvelado que la altitud desencadena una alta producción de ROS mitocondrial en las regiones del músculo esquelético con una alta capacidad metabólica pero con una limitada capacidad de aporte de oxígeno. Esta observación, es evidente a partir de una altitud correspondiente a 5000 metros sobre el nivel del mar. Por encima de esta altitud no existe ningún asentamiento humano permanentemente habitado y los humanos experimentan una perdida inexorable de masa corporal. Sin embargo, se concluye que el uso del modelo integrado en condiciones de enfermedad requiere una mejor estimación de los parámetros mitocondriales. Soporte TIC para el despliegue de servicios de atención integrada (SAI-TIC) y la interacción entre la atención sanitaria y la investigación biomédica basada en la medicina de sistemas Se ha desarrollado una plataforma tecnológica modular que proporciona un conjunto básico de herramientas y tecnologías para dar soporte a la implantación de SAI-TIC para pacientes crónicos. Esta plataforma tecnológica ha soportado de manera eficiente los cuatro SAI diseñados y evaluados en el contexto del proyecto europeo NEXES (2008 - 2013, www. nexeshealth. eu) en uno de los distritos sanitarios de Barcelona, con un total de 540. 000 habitantes, y ha mostrado potencial de escalabilidad a nivel regional. El concepto de “Digital Health Framework (DHF) ” ha sido articulado con el fin de enlazar la atención sanitaria y la investigación biomédica basada en la medicina de sistemas. La basa de conocimiento de Synergy-COPD ha sido desarrollada como un componente de investigación del DHF para fomentar la transición hacia una medicina 4 P. CONCLUSIONES 1. El modelo que integra los determinantes fisiológicos de la cadena de transporte de oxígeno y los elementos bioquímicos moduladores de la formación a nivel mitocondrial de ROS, ha proporcionado, por primera vez, un análisis cuantitativo de la relación entre la oxigenación celular y la producción mitocondrial de ROS. El modelo genera resultados consistentes en salud, pero una mejor estimación de los parámetros mitocondriales es necesaria cuando se aplica en EPOC. 2. La plataforma tecnológica para el soporte de servicios de atención integrada (SAI) pra pacientes crónicos ha cubierto de forma efectiva los requisitos funcionales para el despliegue en un entorno con un único proveedor. Los retos que se han afrontar un despliegue regional de SAI, han sido identificados y se han propuesto estrategias para su adopción. 3. El concepto de “Digital Health Framework (DHF) ” representa un escenario en el que el enlace entre atención integrada e investigación biomédica de medicina de sistemas debe promover el despliegue de la medicina 4 P. Se han propuesto líneas estratégicas para una correcta adopción del DHF. 4. La base de conocimiento específica para EPOC (COPDkb) que ha sido desarrollada y analizada en esta tesis doctoral, constituye un componente principal de la investigación biomédica basada en la medicina de sistemas...|$|R

