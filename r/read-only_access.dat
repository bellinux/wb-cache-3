109|28|Public
5|$|The {{latest version}} of BitLocker, first {{included}} in Windows 7 and Windows Server 2008 R2, adds the ability to encrypt removable drives. On Windows XP or Windows Vista, <b>read-only</b> <b>access</b> to these drives can be achieved through a program called BitLocker To Go Reader, if FAT16, FAT32 or exFAT filesystems are used. In addition, a new command-line tool called manage-bde replaced the old manage-bde.wsf.|$|E
25|$|Manage {{access to}} project data. Access ranges from full-access for team members to {{anonymous}} <b>read-only</b> <b>access</b> for potential reviewers.|$|E
25|$|Windows 9x {{does not}} {{natively}} support NTFS or HPFS, {{but there are}} third-party solutions which allow Windows 9x to have <b>read-only</b> <b>access</b> to NTFS volumes.|$|E
5000|$|<b>Read-only</b> simple public <b>access</b> to implied [...] variableclass Student attr_reader :nameend ...|$|R
50|$|In 2002, Laserfiche 6 {{marked the}} company’s {{first foray into}} MSSQL-based {{document}} management. That year, the company also introduced Quick Fields, an automated document processing module, and WebLink, which provided <b>read-only,</b> Web-based <b>access</b> to documents stored in Laserfiche.|$|R
5000|$|For {{object-oriented}} programming, {{the number}} of method calls invoked is also partly determined by the granularity of the data structures and may thus include many <b>read-only</b> <b>accesses</b> to low level objects that are encapsulated, and thus accessible in no other, more direct, way. Since increased granularity {{is a prerequisite for}} greater code reuse, the tendency is toward fine-grained data structures, and a corresponding increase in {{the number of}} discrete objects (and their methods) and, consequently, subroutine calls. The creation of god objects is actively discouraged. Constructors also add to the count as they are also subroutine calls (unless they are inlined). Performance problems caused by excessive granularity may not become apparent until scalability becomes an issue.|$|R
2500|$|The 68000 {{does not}} meet the Popek and Goldberg {{virtualization}} requirements for full processor virtualization because it has a single unprivileged instruction [...] "MOVE from SR", which allows user-mode software <b>read-only</b> <b>access</b> to a small amount of privileged state.|$|E
2500|$|A {{new system}} known as [...] "Libraries" [...] was added for file management; users can {{aggregate}} files from multiple folders into a [...] "Library". By default, libraries for {{categories such as}} Documents, Pictures, Music, and Video are created, consisting of the user's personal folder and the Public folder for each. The system is also used {{as part of a}} new home networking system known as HomeGroup; devices are added to the network with a password, and files and folders can be shared with all other devices in the HomeGroup, or with specific users. The default libraries, along with printers, are shared by default, but the personal folder is set to <b>read-only</b> <b>access</b> by other users, and the Public folder can be accessed by anyone.|$|E
5000|$|Set {{individual}} user rights, from <b>read-only</b> <b>access</b> to administrator access.|$|E
40|$|Workloads in {{distributed}} database applications {{consist of}} queries and transactions. In {{order to address}} performance requirements, distributed transaction processing systems {{have to deal with}} two related issues: transaction routing and scheduling. Due to the distribution of data objects among nodes and the access cost incurred by remote accesses, efficient transaction routing is an important consideration for overall system performance. Another important consideration is workflow scheduling and routing. Workflows are complex units of work consisting of multiple, possibly interdependent, transactions. In this survey, we discuss a number of different transaction routing mechanisms and their performance. 1. Introduction In database applications, typical workloads that need processing are database queries and transactions that may be issued in different sites of the distributed system. Database queries may be lengthy and resource consuming and result in <b>read-only</b> <b>accesses</b> to the database. [...] ...|$|R
40|$|AbstractUpper bound time-space {{trade-offs}} {{are established}} for sorting and selection in two computational models. For machines with input in <b>read-only</b> random <b>access</b> registers, and for machines with input on a read-only tape, we present algorithms that realize tradeoffs of T·S = O(N 2) for sorting and T log S = O(N log N) for selection, where S is thnumber of workspace registers...|$|R
50|$|<b>Read-only</b> file <b>access</b> can be {{completely}} transparent to applications, {{as long as}} they do not use very large memory-mapped files. Random write access is not possible due to limitations of the protocol. It is possible to copy files to a server, and programs which write files sequentially, as one operation, should not have problems with write access. This program has some support for FTP over SSL and TLS.|$|R
50|$|Developers have <b>read-only</b> <b>access</b> to the {{filesystem}} on App Engine. Applications can {{use only}} virtual filesystems, like gae-filestore.|$|E
5000|$|Manage {{access to}} project data. Access ranges from full-access for team members to {{anonymous}} <b>read-only</b> <b>access</b> for potential reviewers.|$|E
5000|$|VMFSDriver: It enables <b>read-only</b> <b>access</b> {{to files}} and folders on {{partitions}} formatted in the Virtual Machine File System (VMFS) by VMware.|$|E
5000|$|There is a Java port of the MDB tools library named Jackcess. Jackcess adds write {{support for}} Access {{versions}} 2000+, but has <b>read-only</b> support for <b>Access</b> 97. It {{seems to be}} under active development as of 2015.|$|R
40|$|Abstract: As {{a result}} of {{continuous}} innovation in hardware technology, computers are made more and more powerful than their prior models. Modern servers nowadays can possess large main memory capability that can size up to 1 Terabytes (TB) and more. As memory accesses are at least 100 times faster than disk, keeping data in main memory becomes an interesting design principle to increase the performance of data management systems. We design DStore, a document-oriented store residing in main memory to fully exploit high-speed memory accesses for high performance. DStore is able to scale up by increasing memory capability {{and the number of}} CPU-cores rather than scaling horizontally as in distributed data-management systems. This design decision favors DStore in supporting fast and atomic complex transactions, while maintaining high throughput for analytical processing (<b>read-only</b> <b>accesses).</b> This goal is (to our best knowledge) not easy to achieve with high performance in distributed environments. DStore is built with several design principles: single threaded execution model, parallel index generations, delta-indexing and bulk updating, versioning concurrency control and trading freshness for performance of analytical processing. Key-words: In-memory, DStore, NoSQL, vertical scaling, document-oriented store, versionin...|$|R
40|$|The Semantic Web {{today is}} mainly a {{read-only}} Web of Data. Many {{of the data}} sets {{that contribute to the}} Semantic Web are not stored as native RDF, but generated on demand via wrappers. Despite the fact that user contribution is the key success factor in the Web 2. 0, current wrapper approaches and standardization efforts still focus on <b>read-only</b> data <b>access.</b> In this paper, we argue that the Semantic Web should learn from the evolution of the Web 2. 0 and consider write-enabled semantic data wrappers...|$|R
50|$|The first {{program was}} NTFSDOS - a {{freeware}} utility for DOS (NTFSDOS.EXE) that allows <b>read-only</b> <b>access</b> to NTFS formatted drives from a DOS environment.|$|E
5000|$|The {{externals}} clause (...) specifies which {{parts of}} the state can be accessed by the operation; [...] indicating <b>read-only</b> <b>access</b> and [...] being read/write access.|$|E
5000|$|The use of {{exported}} {{variables and}} record fields can {{be restricted to}} <b>read-only</b> <b>access.</b> This is shown with a [...] "-" [...] visibility flag.|$|E
30|$|Different {{types of}} {{personnel}} and public are assigned different access rights. An administrator may alter directly the database’s content, export it and disseminate it as needed. Archaeologists {{should be able}} to interact with content via the modules of the whiteboard. Public is allowed to <b>access</b> <b>read-only</b> content via Dissemination’s web site.|$|R
40|$|When {{dealing with}} massive data sets, {{standard}} algorithms may easily ``run out of memory''. In this thesis, we design efficient algorithms in space-conscious models. In particular, in-place algorithms, multi-pass algorithms, read-only algorithms, and stream-sort algorithms are studied, {{and the focus}} is on fundamental geometric problems, such as 2 D convex hulls, 3 D convex hulls, Voronoi diagrams and nearest neighbor queries, Klee's measure problem, and low-dimensional linear programming. In-place algorithms only use O(1) extra space besides the input array. We present a data structure for 2 D nearest neighbor queries and algorithms for Klee's measure problem in this model. Algorithms in the multi-pass model only make <b>read-only</b> sequential <b>access</b> to the input, and use sublinear working space and small (usually a constant) number of passes on the input. We present algorithms and lower bounds for many problems, including low-dimensional linear programming and convex hulls, in this model. Algorithms in the read-only model only make <b>read-only</b> random <b>access</b> to the input array, and use sublinear working space. We present algorithms for Klee's measure problem and 2 D convex hulls in this model. Algorithms in the stream-sort model use sorting as a primitive operation. Each pass can either sort the data or make sequential access to the data. As in the multi-pass model, these algorithms can only use sublinear working space and a small (usually a constant) number of passes on the data. We present algorithms for constructing convex hulls and polygon triangulation in this model...|$|R
30|$|In {{this paper}} we {{proposed}} an intelligent fragmentation and replication approach for a distributed database system; with this approach, cloud storage {{can be enhanced}} with a semantically-guided flexible query answering mechanism that will provide related but still very relevant answers for the user. The approach combines fragmentation based on a clustering with data replication. For the user, this approach is totally invisible: he can send queries to the database system unchanged. The distributed database system autonomously computes the fragmentation (where the only additional information needed is the clustering backed by a taxonomy specific to {{the domain of the}} anti-instantiation column) and can use an automatic data replication mechanism that relies on the size information of each fragment and generates a bin packing input for an Integer Linear Programming (ILP) solver. As most of the related approaches, we assume a static dataset with mostly <b>read-only</b> <b>accesses.</b> When receiving a user query, the database system can autonomously rewrite the query and redirect subqueries to the appropriate servers based on the maintenance of a root table. The proposed method hence offers novel self-management and self-configuration techniques for a user-friendly query handling. While the user provides the original table and the desired similarity threshold as input, the database system can autonomously distribute the data while minimizing the amount of database servers. Hence we see our approach as a first step towards an intelligent cloud database system. For full applicability in a cloud database, automatic reconfiguration after updates, failure-tolerance as well as parallelization of our clustering approach (for example with map-reduce) will be necessary; these topics will be handled in future work.|$|R
50|$|Windows 9x {{does not}} {{natively}} support NTFS or HPFS, {{but there are}} third-party solutions which allow Windows 9x to have <b>read-only</b> <b>access</b> to NTFS volumes.|$|E
50|$|For some languages, {{a member}} {{intended}} to be readable by other objects can be made modifiable because the language has no convenient construct for <b>read-only</b> <b>access.</b>|$|E
50|$|TOCED {{will also}} allow <b>read-only</b> <b>access</b> to the OS2200 Master File Directory (MFD) {{and the system}} print queues. It also allows access to the TIP file directories.|$|E
40|$|In {{this thesis}} we study {{the problem of}} {{learning}} in belief networks and its application to caching data with repeated <b>read-only</b> <b>accesses</b> in distributed databases. Bayesian Belief Networks (BBNs) have been studied in the literature, and two classes of techniques for constructing BBNs from distributions have been studied. These schemes are methods based on probabilistic-graph models, and Bayesian methods for learning Bayesian networks. In this thesis we first consider methods to build tree structures and use these trees as a basis to build a richer structure, namely a polytree graph. We study the problem of traversing the tree and present a depth first search traversal of the tree in order to orient it so as to yield the polytree. The algorithm to yield the above polytrees uses independence tests between two random variables to detect multiple parents of a given node in the tree structure. Consequently we investigate the use of various independence tests to infer independence of random variables encountered in real-life data. We also present formal techniques to generate random distributions obeying polytree dependence models. The thesis also develops machine learning schemes to detect sequences of repeated queries to remote databases. The answers to these queries (tables) from remote servers are retrieved only once and cached locally in memory. Subsequent {{access to the same}} data or sequence of data is faster as {{there is no need to}} re-fetch it over the network. The learning algorithms we present are based on constructing polytree structures from a set of queries. Once constructed, such networks can provide insight into probabilistic dependencies that exist among the queries and thus enhance distributed query optimization...|$|R
40|$|While the {{gap between}} the “haves ” and “have-nots ” in Internet access is wide, {{the gap between}} the “haves ” and the “almost-haves ” may not be much better. As the first world moves toward user-generated content, social networking, blogs, comment-driven sites, and more participation, having {{anything}} less than full access to the Internet will degrade the Internet user experience. While many people believe that <b>read-only</b> offline <b>access</b> to the Internet is “good enough”, we believe that this approach will hinder developing-world users from sharing information not only with the developed world, but also with each other, which appears to be a largely unaddressed desire [10]. In the longer term, we also believe that offline-only access will fail to spur the kind of Internet growth seen in the first world. While being a second-class Internet citizen is no doubt bette...|$|R
25|$|The {{flash storage}} on Android devices is split into several partitions, such as /system for the {{operating}} system itself, and /data for user data and application installations. In contrast to desktop Linux distributions, Android device owners are not given root access to {{the operating system}} and sensitive partitions such as /system are <b>read-only.</b> However, root <b>access</b> {{can be obtained by}} exploiting security flaws in Android, which is used frequently by the open-source community to enhance the capabilities of their devices, but also by malicious parties to install viruses and malware.|$|R
5000|$|... {{support for}} various {{database}} servers that are operated in a master-slave network or cluster. Separation of the databases for exclusive write access and other databases for <b>read-only</b> <b>access</b> is possible via the backend.|$|E
5000|$|Ability to have <b>read-only</b> <b>access</b> from SQL to a non-SQL (i.e.,core level) database. This means, for example, that {{a remote}} RDM SQL {{application}} can access a non-SQL RDM database {{running on a}} very resource-restricted device.|$|E
5000|$|The 68000 {{does not}} meet the Popek and Goldberg {{virtualization}} requirements for full processor virtualization because it has a single unprivileged instruction [...] "MOVE from SR", which allows user-mode software <b>read-only</b> <b>access</b> to a small amount of privileged state.|$|E
50|$|Hard {{disk drives}} use a {{rotating}} magnetic disk to store data; access time {{is longer than}} for semiconductor memory, but cost per stored data bit is very low, and they provide random access to any location on the disk. Formerly, removable disk packs were common, allowing storage capacity to be expanded. Optical discs store data by altering a pigment layer on a plastic disk, and are similarly random <b>access.</b> <b>Read-only</b> and read-write versions are available; removable media again allows indefinite expansion, and some automated systems were used to retrieve and mount disks under direct program control.|$|R
40|$|The {{recent trends}} of chip {{architectures}} with {{higher number of}} heterogeneous cores, and non-uniform memory/non-coherent caches, brings renewed attention {{to the use of}} Software Transactional Memory (STM) as a fundamental building block for developing parallel applications. Nevertheless, although STM promises to ease concurrent and parallel software development, it relies on the possibility of aborting conflicting transactions to maintain data consistency, which impacts on the responsiveness and timing guarantees required by embedded real-time systems. In these systems, contention delays must be (efficiently) limited so that the response times of tasks executing transactions are upper-bounded and task sets can be feasibly scheduled. In this paper we assess the use of STM in the development of embedded real-time software, defending that the amount of contention can be reduced if <b>read-only</b> transactions <b>access</b> recent consistent data snapshots, progressing in a wait-free manner. We show how the required number of versions of a shared object can be calculated for a set of tasks. We also outline an algorithm to manage conflicts between update transactions that prevents starvation...|$|R
40|$|Abstract. In a {{replicated}} database system, {{copies of}} the database are kept across several sites for fault-tolerance and availability. Data access in such systems is usually done within a transactional framework. A <b>read-only</b> transaction <b>accesses</b> data locally and an update transaction modifies the database at all sites. Total order broadcast primitives have been proposed to support transactions and allow fault-tolerant cooperation between the sites in a distributed system. In this paper, we identify and analyze the problem of formation of deadlocks among conflicting update transactions due to race conditions and outline how a system of total order broadcast prevents deadlocks and transaction failures. Later we outline how a refinement based approach with Event-B {{can be used for}} formal development of the models of total order broadcast. In this approach we begin with the abstract model of a total order broadcast and verify that the required ordering properties are preserved by the system. total order can correctly be implemented by using a notion of sequence number. This technique requires us to discharge proof obligations due to consistency and refinement checking. To discharge the proof obligations we are required to discover invariants that describes the relationship between the abstract total order and the underlying mechanism. ...|$|R
