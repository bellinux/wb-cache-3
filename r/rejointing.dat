1|12|Public
40|$|This {{interdisciplinary}} research develops and puts forward an exploratory analysis of three styles of urban dance: liquid, digitz, and finger tutting using Laban Movement Analysis, a rigorous methodology for analyzing human movement. I suggest that perceptual and cognitive principles, particularly Gestalt laws of perceptual {{organization and the}} spatial cognition principle of ‘structure from motion’, explain and underlie the visual expressive and communicative strength of these styles through a process I describe as dance illusioning. I put forward three dance illusioning modes: spatial tangibilization, <b>rejointing,</b> and spatial quantization. Furthermore, I develop a novel approach to explaining the effects of technology on dance praxis through a close reading of ethnographic and archival data in conjunction with structuralist and cognitive approaches for analyzing urban dance. I provide evidence on how the styles have historical connections with technological aesthetics and how the urban dance community have in part used technological themes to define their bodies and their movement philosophies. I therefore argue that the styles elicit a receptive reading of the dancing body as cyborgean {{in that it is}} simultaneously organic and technological, and of the performance environment as virtually constituted in that it contains invisible, mutable objects and structures that are revealed only through the dancers’ movement. In doing so, I contribute to scholarly perspectives on the historical interactions between technology and dance performance. I conclude by outlining directions for further research and propose that illusion-based dance as a community of practice embodies movement expertise that is of value for technology design...|$|E
5000|$|The Lotus C-01 is {{a concept}} {{motorcycle}} revealed in 2014. It was manufactured by Kodewa under brand license from Group Lotus. It was designed by Daniel Simon, using a carbon fiber monocoque body shell described as [...] "menacingly retro-futuristic", and [...] "la science-fiction <b>rejoint</b> la réalité" [...] or [...] "science fiction joined with reality". A commentator called it [...] "sort of a power cruiser" [...] comparing it to the European exotic Ducati Diavel power cruiser.|$|R
6000|$|... "Si le marechal Grouchy avait ete <b>rejoint</b> par l'officier que Napoleon lui avait expedie la veille a dix heures du soir, toute {{question}} eut disparu. Mais cet officier n'etait point parvenu a sa destination, ainsi que le marechal n'a cesse de l'affirmer toute sa vie, et il faut l'en croire, car autrement il n'aurait eu aucune raison pour hesiter. Cet officier avait-il ete pris? avait-il passe a l'ennemi? C'est ce qu'on a toujours ignore." ...|$|R
50|$|Il y a 49 ans jour pour jour, une embuscade d’une grande envergure et non moins meurtrière à l’armée française a eu lieu à Tizi-Franco, près de Menaceur (Marceau), dans la région de Cherchell. De cette attaque, soigneusement préparée par un vaillant moudjahid de la première heure, en la {{personne}} de Si Hamdane Benmoussa, 70 militaires français ont trouvé la mort sans qu’ils aient {{le temps}} de riposter tant l’assaut les a inopinément acculés. Leurs armes, une soixantaine dont des 12/7 américaines, des fusils-mitrailleurs (FM BAR), des USD 17, des MAT 49 et une carabine ont été récupérés par les moudjahidine avant leur repli. C’est dire que celui qui fut l’artisan de cet exploit n’était âgé que de 25 ans. Sa katiba prendra désormais le nom d’El Hamdania, en hommage à la bravoure de Hamdane Benmoussa. le moudjahid Ezzouaoui Abdelkader, connu sous le nom de guerre de Benaïcha, son cadet de sept ans, a œuvré de plain-pied à ses côtés dans cette embuscade. Dans notre bureau régional où il est venu nous rendre visite, il nous a livré un récit authentique de cette opération qu’il n’est pas près d’oublier de sitôt. “Il fallait coûte que coûte s’approvisionner en armes pour doter les nouvelles recrues de l’ALN, notamment les collégiens et lycéens qui ont observé la grève des étudiants du 19 mai 1956 et qui ont <b>rejoint</b> les maquis de Tamezguida et de Cherchell.|$|R
40|$|Quelles formes prend au XIXe siècle la villégiature dans les proches abords d’une ville de taille moyenne comme Angers ? Le sujet est particulièrement riche durant cette période de forte {{urbanisation}} où s’interpénètrent une campagne de proximité avec son héritage patrimonial et les quartiers suburbains, nouveaux espaces « résidentiels ». La frontière mouvante entre espace rural et urbain, comme la notion floue et évolutive de temporalité qui met à mal la distinction entre résidences permanentes et temporaires, <b>rejoint</b> les désirs de nature du citadin ou de confort moderne du châtelain bien analysés par le théoricien Daly. Ce phénomène sociétal se traduit par des expressions architecturales souvent ambivalentes, que différencie surtout la relation au lieu. Du front urbain au chemin rural, du jardin paysager miniature au parc domanial, le paramètre contextuel est évidemment déterminant dans l’appréhension d’une villégiature de bord de ville. What are {{the forms}} of countryside retreat {{during the nineteenth century}} in the immediate vicinity of a medium-sized town such as Angers? The subject is a remarkably stimulating one during this period which saw the expansion of the town into the surrounding countryside where an existing heritage of country houses was now joined by new ‘residential’ spaces of suburban neighbourhoods. The fluctuating frontier between urban and rural space, along with evolving notions of the occupation of time, making the distinction between a permanent and a holiday residence uncertain, find an echo in the theories of Daly about the town-based desires for modern comfort shared by the class of country house owners. The societal phenomenon finds expression in architectural terms which is often ambivalent, producing differences in relation to specific places. From the urban street front to the rural lane, from the miniature landscaped garden to the estate park, contextual parameters are clearly paramount in understanding the ways of staying in the country {{in the vicinity of the}} town...|$|R
40|$|CE TRAVAIL A POUR BUT D'ECLAIRER LA DEFINITION DE LA LITTERATURE QUE PROPOSE A LA RECHERCHE DU TEMPS PERDU ET ETUDIE LA GENESE DES EXPERIENCES DU TYPE DE CELLE DE LA MADELEINE PRESENTEES PAR PROUST COMME LE PRINCIPE DE LA LITTERATURE. L'ETABLISSEMENT D'UN CORPUS ET D'UNE DENOMINATION STABLES PERMET DE SUBDIVISER CES EPISODES EN TROIS CATEGORIES (REMINISCENCES, IMPRESSIONS OBSCURES ET EXPERIENCES ESTHETIQUES) ET DE LIMITER LA PLACE ACCORDEE A LA MEMOIRE INVOLONTAIRE. UNE APPROCHE COMPARATISTE MONTRE QUE CES EPISODES SONT DES EPIPHANIES LITTERAIRES CE QUI REND POSSIBLE UNE LECTURE EPISTEMOLOGIQUE DE LA RECHERCHE. L'ETUDE DES BROUILLONS ECLAIRE L'EVOLUTION DE LA PENSEE DE PROUST ET LA NAISSANCE DE LA MODERNITE. ELLE REVELE, EN EFFET, QUE JEAN SANTEUIL EST UN ROMAN SUR LA VOCATION FONDEE SUR UNE VISION IMPERSONNELLE ET EXTERIEURE DU GENIE INSPIREE PAR SCHOPENHAUER ET SCHELLING. EN 1908, AU CONTRAIRE, PROUST ELABORE UN ROMAN DE LA VOCATION DONT LE CENTRE EST LE SUJET ET DEVELOPPE UNE CRITIQUE DE L'INTELLIGENCE QUI TEMOIGNE DE LA VOLONTE DE RENDRE L'ART AUTONOME PAR RAPPORT A LA PENSEE SPECULATIVE, QU'ELLE SOIT POSITIVISTE OU IDEALISTE. CETTE EVOLUTION PERMET L'AVENEMENT DE L'ECRITURE AUPARAVANT SUBORDONNEE A LA PHILOSOPHIE ET LA NAISSANCE DES EXPERIENCES PRIVILEGIEES QUI ACCOMPAGNE CELLE DU ROMAN. C'EST A LA FAVEUR DU TRAVAIL DE TRADUCTION DE RUSKIN QUE L'ECRIVAIN SE DEGAGE, EN 1905, DE L'INFLUENCE DE SCHOPENHAUER ET DEFUNT LE GENIE COMME LA RESTITUTION DE LA VISION PERSONNELLE PAR LE STYLE. CETTE CONCEPTION ABOUTIT EN 1909 AUX MATINEES DU CONTRE SAINTE-BEUVE. LE RAPPORT AU MONDE Y EST FONDE SUR L'EFFACEMENT DE LA SENSATION AU PROFIT DE LA PERCEPTION ET SUR LA SAISIE DE LA SCENE DANS SON ENSEMBLE, LE STYLE DEVIENT LE MOYEN DE RESTITUER L'UNITE ORIGINELLE. LA PENSEE DE PROUST <b>REJOINT</b> PAR LA CELLE DES THEORICIENS DE LA FORME ET DE MATISSE. LA GENESE DES EXPERIENCES PRIVILEGIEES RACONTE AINSI LE PASSAGE DU ROMANTISME A LA MODERNITE PAR L'AFFIRMATION DU SUJET ET DE L'UNITE DU STYLEPARIS-EST Marne-la-Vallee-BU (774682101) / SudocSudocFranceF...|$|R
40|$|Le Val des écoliers est un ordre de chanoines réguliers fondé vers mil deux cent un par quatre maîtres en théologie de Paris qui, au siècle de l'université naissante voulaient rappeler le sens primitif du mot écolier, c'est à dire de disciple du christ bien que contemporains des mendiants implantés en ville, ils fuient le milieu urbain pour vivre en ermites dans une vallée isolée aux confins de la Champagne et de la Bourgogne. <b>Rejoints</b> par de nombreux disciples, ils essaiment et s'organisent en un ordre approuvé par le Pape. S’adaptant à l'évolution de leur temps, ils renouent avec la ville et avec les intellectuels. L’ordre compte vingt huit prieurés qui se repartissent {{en trois}} groupes ayant chacun leur originalité : le premier autour de la plus prestigieuse maison Sainte Catherine de Paris et proche du roi, mais aussi de l'université; le second établi dans les pays bas méridionaux est lié aux courants mystiques et aux béguinages et le dernier qui {{correspond}} à l'arc forestier campano-bourguignon reste attaché à un milieu rural traditionnel. The {{valley of the}} scholars was an order of regular canons founded around the year one thousand two hundred and one by four masters of theology in Paris who, {{at the time when}} the university was created, wanted to remind their colleagues of the prime meaning of the word scholar, that is to say a disciple of Christ. Though they were the contemporaries of the mendicant’s established in town, they left the urban environment to live as hermits in a remote valley on the borders of champagne. Joined by many disciples they spread and organized themselves into an order approved by the pope. They adapted themselves to the evolution of their time and renewed with the town and the intellectuals. the order owned twenty eight priories which were divided into three groups having their own originality: the first group depending on the famous house Sainte Catherine of Paris was near the king and the university, the second located in the southern Netherlands had a link with the beguines and the last one which could be found in the forests of champagne and burgundy remained attached to a traditional rural environment...|$|R
40|$|This thesis aims to {{demonstrate}} that message-passing parallel programs can be deployed onto large, heterogeneous distributed systems. This work consists {{in the design and}} development of a proof-of-concept middleware named P 2 P-MPI, released under a public license. P 2 P-MPI alleviates this task by proposing a peer-to-peer based platform in which available resources are dynamically discovered upon job requests, and by providing a fault-tolerant message-passing library for Java programs. The motivation for this project is to offer a programming environment which is: - integrated: its embeds both a middleware layer and a communication library, - in Java (for its "run everywhere" feature), - light-weight to encourage average users to have a good grasp on it: it is contained in only 1 jar, and runs in user space, We have also integrated in P 2 P-MPI contributions to major issues in the field: * Message-passing programming model: P 2 P-MPI integrates an important subset of MPJ (we are able to pass the Java Grande Forum benchmark). In that respect, we faced the same problems as Ibis, or MPJ express. We currently have two implementations: the first implementation uses tcp sockets only and a limited port range (for firewalls concerns). Recently, we decided to offer a more performant implementation using Java NIO. * Fault-tolerance: we provide some fault-tolerance through replication of computations. A number of copies of each process may be asked to run simultaneously at runtime (this mechanism is user-friendly because the user simply chooses the replication degree through a command line argument). So, contrarily to an MPI application that crashes as soon as any of its processes crash, a program using replication will be able to continue as long as at least one copy of each process is running. * Scalability: the goal is to scale to hundreds of nodes, especially over geographically distributed resources. Since the beginning of the project, we have based the middleware on a P 2 P layer to avoid single point of failures concerning resource discovery. Another key design feature is the fault-detection mechanism, based on the principle of failure detectors. A major issue when scaling is the detection time of a failure. We have extensively studied the behavior of these algorithms in P 2 P-MPI and assessed their effectiveness in real experiments. Cette thèse démontre la faisabilité d'un intergiciel destiné aux grilles de calcul, prenant en compte la dynamicité de ce type de plateforme, et les impératifs des programmes parallèles à passage de message. Pour cela, nous mettons en avant l'intérêt d'utiliser une architecture la plus distribuée possible : nous reprenons l'idée d'une infrastructure pair-à-pair pour l'organisation des ressources, qui facilite notamment la découverte des ressources, et nous retenons les détecteurs de défaillance distribués pour gérer la tolérance aux pannes. La dynamicité de ce type d'environnement est également un problème pour le modèle d'exécution sous-jacent à MPI, car la panne d'un seul processus entraine l'arrêt de l'application. La contribution de P 2 P-MPI dans ce domaine est la tolérance aux pannes par réplication. Nous pensons qu'elle est la mieux adaptée à une architecture pair-à-pair, les techniques classiques basées sur le check-point and restart nécessitant un ou des serveurs de sauvegardes. De plus, la réplication est totalement transparente à l'utilisateur et <b>rejoint</b> ainsi l'objectif de simplicité d'utilisation que nous nous sommes fixés. Nous pensons que garder un environnement très simple d'utilisation, entièrement maîtrisable par un utilisateur, est un des facteurs permettant d'augmenter le nombre de ressources disponibles sur la grille. Enfin, la contribution majeure de P 2 P-MPI est la librairie de communication proposée, qui est une implémentation de MPJ (MPI adapté à Java), et qui intègre la réplication des processus. Ce point particulier de notre travail plaide pour une collaboration étroite entre l'intergiciel, qui connaît l'état de la grille (détection des pannes par exemple) et la couche de communication qui peut adapter son comportement en connaissance de cause...|$|R
40|$|The Pacific decadal variability, {{such as the}} low-frequency {{modulation}} of El Niño Southern Oscillation, {{has been}} hypothesized {{to be influenced by}} changes in the strength or water mass properties of the meridional circulation associated with the subtropical cells (STC). The STCs provide a connection between subtropical waters and the equatorial Pacific at thermocline level, by both an interior pathway and by the low latitude boundary currents. The LLWBC branch of the South Pacific STC has been pointed as the main source of the Equatorial Undercurrent and of the Equatorial Cold Tongue by both observational and modeling studies. Those currents transit in the poorly documented Solomon Sea, located in the western boundary of the tropical South Pacific. The very intricate bathymetry of the semi-enclosed Solomon Sea complexifies the STC pathways to the equator. In this study, we characterize the Solomon Sea fine-scale thermocline mean circulation and its annual cycle. As available observations of the region are sparse, our approach is based on modeling. High-resolution is required to realistically represent the complex topography. It is achieved through the implementation of a hierarchy of Ocean General Circulation Models (OGCMs) : a 1 / 12 ° resolution model of the Solomon Sea is interactively into a ¼° regional model of the southwest Pacific, itself embedded through open boundary conditions in a global 1 / 4 ° OGCM. The thermocline circulation involves an inflow from the southern open Solomon Sea which is distributed via WBCs between the three narrow straits that connect this region to the equatorial Pacific. The system of WBCs appears to be complex, with a double system of currents. It provides connections of subtropical water to the EUC at different longitudes, which may be associated to different climate impacts. The seasonal variability of the circulation results from the combination of equatorial dynamics, of remotely-forced Rossby waves north of 10 °S, and of the spinup and -down of the subtropical gyre as a response of Rossby waves forced south of 10 °S. The Solomon Sea is also a highly variable region. Indeed, the highest levels in sea level variability in the entire South Pacific are found in the Solomon Sea. Specifically reprocessed along-track data adapted to coastal areas were used in addition to standard gridded data to explore sea level and western boundary currents in this region. Track data appear especially helpful for documenting the fine structure of surface coastal currents. Sea level anomalies (SLA) in the Solomon Sea principally evolve at seasonal and interannual time scales. The annual variability of the boundary currents that emerged from altimetry is phased by Rossby waves arriving in the Solomon Strait, and it compared quite well with the variability seen at the thermocline level, as based on our numerical simulations. The interannual signature corresponds to the basinscale ENSO mode. The western boundary current interannual transport anomalies counterbalance changes in western equatorial Pacific warm water volume, confirming the phasing of South Pacific western boundary currents to ENSO. Water mass modifications are characterized in our high-resolution model in a Lagrangian quantitative framework. We show that strong diapycnal mixing, partly due to internal tide waves dissipation, is responsible for a reduction of the temperature and salinity vertical gradients. More specifically, diapycnal mixing erodes the high salinities associated with the waters of subtropical origin carried by the STC, and this erosion is associated to a downward heat transfer. Therefore, the Solomon Sea might damp the spiciness anomalies formed in the southeast Pacific and advected equatorward to the EUC by the LLWBC branch of the South Pacific STC, with reduced impact of the STC on the Tropical Pacific climate variability. La mer des Salomon, qui voit transiter les eaux subtropicales alimentant la thermocline du Pacifique équatorial via les courants de bord ouest (WBC), pourrait moduler le climat du Pacifique tropical. Les objectifs de cette thèse sont de caractériser les circulations océaniques en mer des Salomon, notamment dans la thermocline, leurs variabilités, ainsi que les modifications des masses d'eau transitant par la mer des Salomon pour rejoindre l'équateur. Pour cela, une approche parallèle de modélisation haute résolution et d'analyse des observations disponibles a été utilisée. Un double système de WBC est modélisé dans la thermocline. Une partie des eaux du New Guinea Coastal Undercurrent <b>rejoint</b> le New Ireland Coastal Undercurrent, qui se rétroflecte partiellement dans l'Equatorial Undercurrent, produisant ainsi une connexion directe à la thermocline équatoriale. Le cycle saisonnier de cette circulation est forcé par le régime des ondes équatoriales et par le régime des ondes de Rossby. Les WBC sont intensifiés pendant les évènements El Nino et compensent la déplétion du volume d'eau chaude du Pacifique équatorial ouest. Les modifications des masses d'eau transitant en mer des Salomon avant de rejoindre le Pacifique équatorial ont été caractérisées à partir d'une approche lagrangienne. Un fort mélange diapycnal produit un transfert de chaleur vers le fond et une érosion du maximum de salinité présent dans la thermocline...|$|R
40|$|Cet article rend compte d'une expérience d'évaluation d'un {{programme}} de formation offert à l'intention de propriétairesdirigeants de PME québécoises par le ministère de l'Industrie, du Commerce et de la Technologie de la province. La recherche utilise le modèle de Kirkpatrick qui propose d'évaluer un programme déformation selon quatre niveaux distincts: réactions, apprentissage, comportements et résultats. Deux cent quatre-vingt-un participants ont été <b>rejoints</b> par téléphone au moins un an après la tenue de leur séminaire. L'étude documente d'une façon descriptive les différents niveaux d'impact du programme de formation. Elle apporte un éclairage nouveau sur une opération rarement effectuée qui présente de nombreuses difficultés d'ordre théorique et opérationnel. Leaders of Quebec {{small businesses}} {{have access to}} a large number of management training programs offered by private and public agencies. Those who enroll in such programs hope to generate positive results for their business. However, the real impacts of the programs are not well documented. This paper is an account of an empirical evaluation of a training program offered to owner-managers of small businesses by the ministere de l'Industrie, du Commerce et de la Technologie (MICT) of the Province of Quebec. CONTEXT OF THE STUDYIn 1988, the MICT offered 28 different seminars, 18 of which were aimed at owners of industrial firms, and 10 at owners of commercial and service companies. The topics discussed covered a wide range of subjects presented in workshops going from basic seminars (such as, financial and human resources management) to advanced seminars (such as, "just-in-time" management techniques and strategic planning). Seminars are in the form of one-day workshops with 10 to 15 participants. A workshop leader, generally a consultant, university professor or businessman recognized for his competence, is responsible for the transmission of information using audio-visual materials. He introduces many practical examples and encourages communication between the participants, who are then invited to discuss their real-life business problems and to prepare concrete action plans to be implemented when they return to their organization. THE KIRKPATRICK MODELA review of the literature in training program evaluation indicates that this operation is rated as essential by all authors in the field. However, it is only rarely carried out in practice. Even when an evaluation is attempted, it is often limited to measuring the participants' reaction to the seminar since it presents a number of theoretical and operational difficulties. However, our review of the literature enabled us to locate a model which is accepted as an authority by training professionals. The Kirkpatrick model proposes an analysis of the effectiveness of a training program according to four levels: reactions, learning and behaviours of the participant and results for the organization. METHODOLOGYFrom September 1986 to June 1987, the MICT seminars attracted some 3000 people. The sample is made up of about 10 % of the population, namely 189 leaders of industnal businesses and 92 leaders of commercial businesses, making a total of 281 in all. Data was gathered by phone in March 1988, approximately one year after the seminar was held, using a questionnaire based on the Kirkpatrick model. RESULTSThe participants' reactions towards the seminar are the first evaluation level in the Kirkpatrick model. On the whole, the MICT seminars seem to have been well rated by the participants. The satisfaction level is very high with respect to content and format as well as teaching and logistic support for the sessions. The second evaluation level, learning, is an attempt to determine to what extent the information transmitted in the seminars was learned and mastered. The seminars seem to have been well assimilated by the participants, since 86, 9 % of them state that they are completely or moderately in a position to use what they have learned during the session. The third evaluation level aims to shed light on the changes undergone by the participant, new behaviours and projects undertaken {{as a result of the}} new knowledge. Changes in the participant himself as a result of the seminar were identified. Two hundred and thirty-eight participants generated 306 reflections that were classified under three headings: (1) Awakening, Increase in Knowledge and Awareness (33, 7 %), (2) Changes in Values and/or Priorities (33, 3 %), (3) Changes in Behaviour (33 %). The seminars had a concrete impact in terms of new projects. In fact, 51, 2 % of the respondents state that the knowledge acquired gave rise to a concrete project or activity in their enterprise. They mentioned 198 activities or projects which have been classified into nine categories. They are: (1) New Systems or Methods (38, 9 %), (2) Changes to Already Existing Systems or Methods (27, 3 %), (3) Analysis and Planning Activities (8, 6 %), (4) Establishment and Start-up of a New Unit (8, 6 %), (5) Training Activities (6, 1 %), (6) Hiring of Personnel (3, 5 %), (7) Purchase of Equipment or Real Estate (1, 5 %). Three per cent of the respondents were unable to specify the exact nature of their project. The fourth evaluation level of the Kirkpatrick model uses different performance indicators to measure the effects of new projects and behaviour patterns on the organization. One hundred and fourty-four respondents listed 205 consequences for their own enterprise. These consequences were classified according to the type of impact. They are positive for the enterprise in all but a few cases (4). Negative impacts are considered as temporary or compensated by positive ones in other functional spheres of the enterprise. The consequences for the enterprise are: (1) Turnover/ Sales (13, 7 %), (2) Profits (9, 8 %), (3) Costs (12, 7 %), (4) Management/Control (20, 5 %), (5) Personnel (18, 5 %), (6) Product (7, 3 %), (7) Market (6, 3 %), (8) Undefïned or Non-measurable Impact (9, 3 %), (8) Negative Impact (2, 0 %). CONCLUSIONBased on the results of the study as a whole, it is possible to summarize the impacts of the seminars on the participants and their businesses as being positive or even very positive. The program of the management seminars offered by the MICT seems to be a valuable tool for spreading information among small business managers whose need for training has been confirmed by several studies. The Kirkpatrick model was found to be a valuable tool in this evaluation. It is systematic, complete and intuitively logical. Moreover, it was relatively easy to operationalize. The instrument developed for this study is economic and flexible, since the survey may be done by phone. To conclude, the Kirkpatrick model is an adequate response to the theoretical, methodological and practical challenges of training program evaluation...|$|R
40|$|The {{theory of}} {{generation}} that Buffon developed in 1749 in the Histoire naturelle générale et particulière {{was aimed at}} restoring epigenesis against preformation which had up to then prevailed, but {{within the framework of}} a micro-mechanist physiology. Buffon referred to explanatory concepts like "organicmolecule" and "internal mould" which conformed to that methodological trend, but whose purelyconjectural nature was immediately queried by contemporary opponents as well as supporters of epigenesis. In fact, Buffon attempted to unite "by virtue of analogies" the available observational data on reproductive processes and thus reach for general effects expressive of laws governing the phenomena; but, at the same time, he appealed to hypothetical mechanist models to account for the system formed by the induced general effects. This process paralleled the one J. T. Needham would describe in 1750 in the Nouvelles Observations microscopiques. While tradition has tended to include both in the same critique, these systems, based on distinct, if complementary, empirical data, notably diverged. They supposed relatively distinct methodological and theoretical explanatory principles. The way they conceived the forces responsible for the formation, operation and reproduction of living organisms, differed. Buffon and Needham would therefore offer alternative epigenetic frameworks for conceiving the dynamic processes ruling over the production and replication of organic bodies. These alternatives could be related to a certain opposition between mechanist and vitalist models of the living being during the Enlightenment. Starting from the distinct epistemological profiles of Buffon and Needham's theories of generation, might we determine their respective impact on the quest for a unified theory of living beings?The theory of generation that Buffon developed in 1749 in the Histoire naturelle générale et particulière was aimed at restoring epigenesis against preformation which had up to then prevailed, but within the framework of a micro-mechanist physiology. Buffon referred to explanatory concepts like "organicmolecule" and "internal mould" which conformed to that methodological trend, but whose purelyconjectural nature was immediately queried by contemporary opponents as well as supporters of epigenesis. In fact, Buffon attempted to unite "by virtue of analogies" the available observational data on reproductive processes and thus reach for general effects expressive of laws governing the phenomena; but, at the same time, he appealed to hypothetical mechanist models to account for the system formed by the induced general effects. This process paralleled the one J. T. Needham would describe in 1750 in the Nouvelles Observations microscopiques. While tradition has tended to include both in the same critique, these systems, based on distinct, if complementary, empirical data, notably diverged. They supposed relatively distinct methodological and theoretical explanatory principles. The way they conceived the forces responsible for the formation, operation and reproduction of living organisms, differed. Buffon and Needham would therefore offer alternative epigenetic frameworks for conceiving the dynamic processes ruling over the production and replication of organic bodies. These alternatives could be related to a certain opposition between mechanist and vitalist models of the living being during the Enlightenment. Starting from the distinct epistemological profiles of Buffon and Needham's theories of generation, might we determine their respective impact on the quest for a unified theory of living beings?The theory of generation that Buffon developed in 1749 in the Histoire naturelle générale et particulière was aimed at restoring epigenesis against preformation which had up to then prevailed, but within the framework of a micro-mechanist physiology. Buffon referred to explanatory concepts like "organicmolecule" and "internal mould" which conformed to that methodological trend, but whose purelyconjectural nature was immediately queried by contemporary opponents as well as supporters of epigenesis. In fact, Buffon attempted to unite "by virtue of analogies" the available observational data on reproductive processes and thus reach for general effects expressive of laws governing the phenomena; but, at the same time, he appealed to hypothetical mechanist models to account for the system formed by the induced general effects. This process paralleled the one J. T. Needham would describe in 1750 in the Nouvelles Observations microscopiques. While tradition has tended to include both in the same critique, these systems, based on distinct, if complementary, empirical data, notably diverged. They supposed relatively distinct methodological and theoretical explanatory principles. The way they conceived the forces responsible for the formation, operation and reproduction of living organisms, differed. Buffon and Needham would therefore offer alternative epigenetic frameworks for conceiving the dynamic processes ruling over the production and replication of organic bodies. These alternatives could be related to a certain opposition between mechanist and vitalist models of the living being during the Enlightenment. Starting from the distinct epistemological profiles of Buffon and Needham's theories of generation, might we determine their respective impact on the quest for a unified theory of living beings?La théorie de la génération que Buffon développe dès 1749 dans l'Histoire naturelle générale et particulière vise à restaurer l'épigenèse à l'encontre du préformationnisme alors dominant, mais dans le cadre d'une physiologie micro-mécaniste. Buffon se réfère à des concepts explicatifs, tels ceux de " molécule organique " et de " moule intérieur ", qui illustrent cette orientation méthodologique, mais dont le caractère purement conjectural fut rapidement mis en cause par les contemporains, adversaires aussi bien que partisans de l'épigenèse. Buffon entreprend de lier, " par la force des analogies ", les faits d'observation relatifs aux processus de reproduction de façon à remonter à des effets généraux qui exprimeraient les lois régissant ces phénomènes; mais, en même temps, il recourt à des modèles mécanistes hypothétiques pour rendre compte du système que formeraient ces effets. Cette démarche est parallèle à celle que J. T. Needham décrit en 1750 dans les Nouvelles Observations microscopiques. Contrairement à la tradition qui les embrasse dans une même critique, les systèmes explicatifs des deux chercheurs, basés sur des données d'observation distinctes, bien que présumés complémentaires, divergent de notable façon. Ils supposent des fondements méthodologiques et théoriques de l'explication relativement distincts. La façon même de se représenter les forces à l'oeuvre dans la formation, le fonctionnement et la reproduction des organismes vivants y diffère. Par suite, Buffon et Needham nous révèlent une alternative fondamentale dans la façon de concevoir les processus dynamiques régissant la production et la réplication des corps organiques en contexte d'épigenèse. Cette alternative <b>rejoint</b> une certaine opposition entre modèles mécanistes et modèles vitalistes de l'être vivant à l'époque des Lumières. Partant du profil épistémologique des théories de la génération selon Buffon et Needham, pourrait-on en déterminer l'impact respectif sur la recherche d'une théorie unifiée des êtres vivants...|$|R
40|$|This {{document}} {{constitutes a}} synthesis {{in preparation for}} my habilitation degree in computer science. I am now researcher at INRIA Rennes since September 2001. From September 2001 to January 2004, I was a researcher in the Vista project headed by Patrick Bouthemy, {{and moved to the}} Visages project headed by Christian Barillot. In January 2010, I moved to the Serpico team headed by Charles Kervrann that focuses on ”imaging and modeling intracellular dy- namics of molecular architectures”. This document presents part of my work among the Visages team. Actually, this habilitation thesis will focus on image processing aspects of intraoperative ultrasound in neurosurgery. My work on non-rigid registration will not be described here. The work on non-rigid registration began during my PhD thesis, where the three main contributions were the design of a 3 D non-rigid registration method based on optical flow [72], the incorporation of local constraints [74] and the retrospec- tive evaluation of inter-subject registration [71]. I continued working on image registration, with Anne Cuzol and Etienne M ́emin using fluid motion descrip- tion [44], with Nicolas Courty on GPU accelerated registration [42] and on evaluation of non-rigid registration techniques: with Mallar Chakravarty and co-authors [29] for deep-brain stimulation planning; with Arno Klein and co- authors [92] concerning inter-subject brain registration. In the last decade, it has become increasingly common to use image-guided navigating systems to assist surgical procedures [51]. The reported benefits are improved accuracy, reduced intervention time, improved quality of life, reduced morbidity (and perhaps mortality), reduced intensive care and reduced hospital costs. Image-guided systems can help the surgeon plan the operation and provide accurate information about the anatomy during the intervention. Image-guided systems are also useful for minimally invasive surgery, since the intraoperative images can be used interactively as a guide. Current surgical procedures rely on complex preoperative planning, includ- ing various multimodal examinations: anatomical, vascular, functional explo- rations for brain surgery. Once all information has been merged, it can be used for navigation in the operating theatre (OR) using image-guided surgery systems. Image-guided surgery involves the rigid registration of the patient's body with the preoperative data. With an optical tracking system, and Light Emitting Diodes (LED), it is possible to track the patient's body, the micro- scope and the surgical instruments in real time. The preoperative data can then be merged with the surgical field of view displayed in the microscope. This fusion is called “augmented reality”. Unfortunately, the assumption of a rigid registration between the patient's body and the preoperative images only holds {{at the beginning of the}} procedure. This is because soft tissues tend to deform during the intervention. This is a common problem in many image-guided interventions, the particular case of neurosurgical procedures can be considered as a representative case. When dealing with neurosurgery, his phenomenon is called “brain shift”. Although the impact and the magnitude of soft tissue motion have been studied over the last few years, this phenomenon is still poorly understood. Soft tissue deformation can be explained by physiological (steroids, diuretic medication, mechanical ventilation) and mechanical factors (CSF leakage, pa- tient positioning, tumor nature and location, craniotomy size, gravity [117], etc). The magnitude of brain shift shows striking differences at each stage of surgery. Brain shift must be considered as a spatio-temporal phenomenon, and should be estimated continuously, or at least at key moments, to update the preoperative planning. To do so, one possibility is to deform the anatomical and functional images according to the estimated deformation. Ce document constitue une synth`ese de travaux de recherche en vue de l'obten- tion du diplˆome d'habilitation `a diriger les recherches. A la suite ce cette in- troduction r ́edig ́ee en franc ̧ais, le reste de ce document sera en anglais. Je suis actuellement charg ́e de recherches INRIA au centre de Rennes Bretagne Atlantique. J'ai <b>rejoint</b> en Septembre 2001 l' ́equipe Vista dirig ́ee par Patrick Bouthemy, puis l' ́equipe Visages dirig ́ee par Christian Barillot en Janvier 2004. Depuis Janvier 2010, je travaille dans l' ́equipe-projet Serpico dirig ́ee par Charles Kervrann dont l'objet est l'imagerie et la mod ́elisation de la dynamique intra- cellulaire. Parmi mes activit ́es pass ́ees, ce document va se concentrer uniquement sur les activit ́es portant sur la neurochirurgie guid ́ee par l'image. En parti- culier, les travaux effectu ́es sur le recalage non-rigide ne seront pas pr ́esent ́es ici. Concernant le recalage, ces travaux ont commenc ́e pendant ma th`ese avec le d ́eveloppement d'une m ́ethode de recalage 3 D bas ́e sur le flot optique [72], l'incorporation de contraintes locales dans ce processus de recalage [74] et la validation de m ́ethodes de recalage inter-sujets [71]. J'ai poursuivi ces travaux apr`es mon recrutement avec Anne Cuzol et Etienne M ́emin sur la mod ́elisation fluide du recalage [44], avec Nicolas Courty sur l'acc ́el ́eration temps-r ́eel de m ́ethode de recalage [42], et sur l' ́evaluation des m ́ethodes de recalage dans deux contextes : celui de l'implantation d' ́electrodes profondes [29] et le re- calage inter-sujets [92]. L'utilisation de syst`emes dits de neuronavigation est maintenant courante dans les services de neurochirurgie. Les b ́en ́efices, attendus ou report ́es dans la litt ́erature, sont une r ́eduction de la mortalit ́e et de la morbidit ́e, une am ́elio- ration de la pr ́ecision, une r ́eduction de la dur ́ee d'intervention, des couˆts d'hospitalisation. Tous ces b ́en ́efices ne sont pas `a l'heure actuelle d ́emontr ́es `a ma connaissance, mais cette question d ́epasse largement le cadre de ce doc- ument. Ces syst`emes de neuronavigation permettent l'utilisation du planning chirurgical pendant l'intervention, dans la mesure ou` le patient est mis en cor- respondance g ́eom ́etrique avec les images pr ́eop ́eratoires `a partir desquelles est pr ́epar ́ee l'intervention. Ces informations multimodales sont maintenant couramment utilis ́ees, com- prenant des informations anatomiques, vasculaires, fonctionnelles. La fusion de ces informations permet de pr ́eparer le geste chirurgical : ou` est la cible, quelle est la voie d'abord, quelles zones ́eviter. Ces informations peuvent main- tenant ˆetre utilis ́ees en salle d'op ́eration et visualis ́ees dans les oculaires du mi- croscope chirurgical grˆace au syst`eme de neuronavigation. Malheureusement, cela suppose qu'il existe une transformation rigide entre le patient et les im- ages pr ́eop ́eratoires. Alors que cela peut ˆetre consid ́er ́e comme exact avant l'intervention, cette hypoth`ese tombe rapidement sous l'effet de la d ́eformation des tissus mous. Ces d ́eformations, qui doivent ˆetre consid ́er ́ees comme un ph ́enom`ene spatio-temporel, interviennent sous l'effet de plusieurs facteurs, dont la gravit ́e, la perte de liquide c ́ephalo-rachidien, l'administration de pro- duits anesth ́esiants ou diur ́etiques, etc. Ces d ́eformations sont tr`es difficiles `a mod ́eliser et pr ́edire. De plus, il s'agit d'un ph ́enom`ene spatio-temporel, dont l'amplitude peut varier consid ́era- blement en fonction de plusieurs facteurs. Pour corriger ces d ́eformations, l'imagerie intra-op ́eratoire apparait comme la seule piste possible...|$|R
40|$|Des échantillons d’eau et de matière en {{suspension}} ont été prélevés le long de l’oued Moulouya et dans des lacs de carrière {{au niveau}} de l’ancien centre minier de Zeïda (Haute Moulouya, Maroc) en vue d’en évaluer la salubrité. Il est en effet important d’établir le degré et les causes éventuelles de dégradation de la qualité de ces eaux, compte tenu de leur usage à des fins tant domestiques qu’agricoles. Des résidus de traitement ont également été échantillonnés dans les haldes abandonnées. L’analyse des distributions et des variations spatio-temporelles des concentrations de Pb et As a permis de mettre en évidence que le centre minier a véritablement un impact sur la qualité des eaux de surface environnantes, malgré le caractère neutre à alcalin du drainage. Aucune ne <b>rejoint</b> les critères de l’Organisation mondiale de la santé en matière de Pb et As dans l’eau potable (10  µg/L), mais près de la moitié souscrit aux normes marocaines (50  µg/L). L’importance de la dégradation varie selon la saison et la localité, et le contraste entre sites a priori non dégradés et sites dégradés n’est pas toujours très prononcé. On observe même des variations à l’inverse des tendances attendues. Les résultats peuvent cependant être réconciliés en tenant compte de l’importance du transport particulaire par rapport au transport dissous au moment et au lieu de l’échantillonnage. Il appert que les minéralisations et les résidus miniers restés sur place peuvent constituer la principale source de pollution des eaux de surface de la région de Zeïda. The Upper Moulouya Basin was the location of extensive lead mining between 1930 and 1985, with three major operations near Aouli, Mibladen and Zeïda. The Moulouya drains about 7. 5 % of the Moroccan territory and provides drinking and irrigation water to many communities over its more than 500  km path. It is thus important to determine the impact of past mining activities on its water quality, since the mining sites were abandoned {{with little or no}} rehabilitation. This paper focuses on the Zeïda area, the uppermost of these mining centres on the Moulouya. About 630, 172  t of lead concentrates (40 ‑ 70 % Pb) were produced between 1972 and 1985 at Zeïda. Lead was mined from carbonate and sulphide mineral deposits (cerussite, 70 %; galena, 30 %) mixed with barite in stratiform ore bodies hosted by Permo-Triassic arkoses. Mining left 12  Mt and 70  Mt of tailings and wastes in fully exposed piles {{on each side of the}} Moulouya, as well as a dozen water-filled open-stopes. Mine drainage is of neutral pH, thanks to the low content of residual sulphide minerals and the availability of carbonate in the tailings and host rock. The river and some quarry-lakes are tapped to fulfill domestic, agricultural and stock-breeding needs. One lake is used to directly feed Zeïda’s water network (pop. 3, 000), without any water treatment. The Moulouya, upstream and downstream of Zeïda, and four lakes were sampled twice in 2002 (dry period: February; wet period: April). Temperature, electric conductivity (EC), Eh and pH were measured in the field. Samples were filtered through 0. 45  µm membranes. The filtrates were preserved with 4 % HNO 3 and kept at 4 °C until analysis. The filters and their particulate fraction, as well as a composite sample of the tailings, were dried and kept dry until dissolution and analysis. All measurements were performed by ICP-MS and capillary electrophoresis analyses. Lead and arsenic are well above « normal » concentrations in the tailings, at 5, 547  g/t and 192  g/t, respectively. These elements are clear threats to population health, since dust from unstabilized tailings can be dispersed by wind and rain waters, contaminating agricultural soils and surface waters, and eventually leading to cases of saturnism or arsenical intoxication in the population. All Pb and As concentrations measured in the waters sampled are above the World Health Organisation criteria for drinking water (10  µg/L for Pb and As). Nevertheless, about half of these measurements meet the Moroccan criteria (50  µg/L). All samples show near neutral or slightly basic pH values (7. 2 - 8. 9). EC is also high (>  1, 000  µS/cm). As and Pb are largely associated with the particulate fraction (>  80 % of total As and Pb), except for As in two lakes (<  40 %). Overall, their concentrations are higher in the Zeïda area than upstream in the Moulouya. However, this is a tendency rather than a rule, because the differences are often small (<  50 %) and suffer exceptions. For instance, Pb concentrations are 60 % lower than the so-called uncontaminated reference station, in two quarry-lakes sampled during the wet period. The occasional lack of significant and consistent contrast between an obviously degraded environment and a pristine site was unexpected. The results were therefore further investigated, in order to identify possible explanations for the apparent discrepancies. Coherency in the data set emerges when one considers the relative importance of dissolved and particulate transport in the various types of environments sampled. Using this interpretation scheme, EC is considered as an indicator of solute transportation, since EC is a function of dissolved ionic components. Total Pb is regarded as an indicator of particulate transportation, since Pb is strongly adsorbed to particulate substrates at the pH observed. Following these assumptions, particulate transport appears to dominate over dissolved transportation in the Moulouya. Total Pb increases by factors of 3. 4 and 9. 8 from dry to wet periods, whereas EC decreases by 0. 7 - 0. 8, as a result of rain dilution. In two of the four lakes, dissolved transport is comparatively more important, since EC does not change significantly and total Pb shows only a small increase from the dry to the wet period. In these lakes, the dissolved input during the rainy period appears to be large enough to keep EC at its previous value, without significant dilution, as opposed to what is going on in the Moulouya. In the two other lakes, both EC and total Pb decrease from the dry to the wet period, pointing to dilution effects greater than either dissolved or particulate mobilization. Apparent discrepancies in the intensity and direction of variations are explained when prevailing modes of dispersion are taken into account. For instance, the enrichment factor of total Pb in the Moulouya, downstream of Zeïda, jumps from 1. 1 (dry) to 3. 2 (wet), with respect to the reference station. Meanwhile, EC increases only from 1. 2 (dry) to 1. 5 (wet). The greater increase of total Pb over EC is explained by prevalent particulate transport. In another case, the enrichment of EC with respect to the reference station, in two lakes, increases from 14. 2 and 20. 4 (dry) to 20. 1 and 27. 9 (wet) while total Pb enrichment decreases from 2. 0 and 2. 0 (dry) to 1. 6 and 1. 3 (wet). Here, the prevalence of dissolved transport in these two lakes, combined with particulate transport at the reference station, allow for a strong increase in the EC parameter, concurrent with a weak increase in total Pb. Finally, in the lakes where both dissolved and particulate transport are presumably minor, total Pb undergoes enrichment with respect to the reference station, in the dry period (by 3. 4 and 1. 8), whereas depletion characterizes the wet period (0. 6 in both lakes). In this case, enrichment is likely the result of evaporation during the dry season, and depletion the result of dilution by rain during the wet period. These two types of lake behave differently because they are located next to residual mineral deposits (likely with more soluble phases), have short travel distances and thus fewer contacts with adsorbing substrates, which is not the case for the other two lakes...|$|R

