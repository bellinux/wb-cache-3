15|32|Public
25|$|Large {{databases}} {{have historically}} been kept on disk drives. The time to read a record on a disk drive far exceeds {{the time needed to}} compare keys once the record is available. The time to read a record from a disk drive involves a seek time and a <b>rotational</b> <b>delay.</b> The seek time may be 0 to 20 or more milliseconds, and the <b>rotational</b> <b>delay</b> averages about half the rotation period. For a 7200 RPM drive, the rotation period is 8.33 milliseconds. For a drive such as the Seagate ST3500320NS, the track-to-track seek time is 0.8 milliseconds and the average reading seek time is 8.5 milliseconds. For simplicity, assume reading from disk takes about 10 milliseconds.|$|E
50|$|Rotational {{position}} sensing (RPS) {{was implemented}} with two new CCWs, SET SECTOR and READ SECTOR enabled the channel to delay command chaining until the disk rotated to a specified angular track position. RPS permits channel disconnection {{during most of}} the <b>rotational</b> <b>delay</b> period and thus contributes to increased channel utilization. The control unit implements RPS by dividing each track into equal angular segments.|$|E
50|$|Rotational latency (sometimes called <b>{{rotation}}al</b> <b>delay</b> or just latency) is {{the delay}} {{waiting for the}} rotation of the disk to bring the required disk sector under the read-write head. It depends on the rotational speed of a disk (or spindle motor), measured in revolutions per minute (RPM). For most magnetic media-based drives, the average rotational latency is typically based on the empirical relation that the average latency in milliseconds for such a drive is one-half the rotational period. Maximum rotational latency is {{the time it takes to}} do a full rotation excluding any spin-up time (as the relevant part of the disk may have just passed the head when the request arrived). Therefore, the rotational latency and resulting access time can be improved (decreased) by increasing the rotational speed of the disks. This also has the benefit of improving (increasing) the throughput (discussed later in this article).|$|E
40|$|Abstract [...] In {{this work}} we {{investigate}} the implications {{on the energy}} consumption of different popular file systems and propose a novel, log-structured file system aiming at minimized energy consumption by avoiding expensive disk seeks and introduced latencies due to <b>rotational</b> <b>delays.</b> We show that the energy efficiency of file systems is heavily influenced by the underlying data layout and file organization. Guidelines for a low power file system design are developed and evaluated with measurements of the energy consumption of a prototype implementation. As on-going work we investigate different approaches to free space management. We discuss design choices {{for the implementation of}} a family of free space managers and their implications on energy consumption. I...|$|R
40|$|The paper {{considers}} a generalization {{of the well}} known random placement of balls into bins. Given n circular arcs of lengths ff 1, [...] .,ff n we study {{the maximum number of}} overlapping arcs on a circle if the starting points of the arcs are chosen randomly. We give almost exact tail bounds on the maximum overlap of the arcs. These tail bounds yield a characterization of the expected maximum overlap that is tight up to constant factors in the lower order terms. We illustrate the strength of our results by presenting new performance guarantees for several application: Minimizing <b>rotational</b> <b>delays</b> of disks, scheduling accesses to parallel disks and allocating memory to limit cache interference misses...|$|R
40|$|Recent {{technological}} {{advances in the}} development of flashmemory based devices have consolidated their leadership position as the preferred storage media in the embedded systems market and opened new vistas for deployment in enterprise-scale storage systems. Unlike hard disks, flash devices are free from any mechanical moving parts, have no seek or <b>rotational</b> <b>delays</b> and consume lower power. However, the internal idiosyncrasies of flash technology make its performance highly dependent on workload characteristics. The poor performance of random writes has been a cause of major concern which needs to be addressed to better utilize the potential of flash in enterprise-scale environments. We examine one of the important causes of this poor performance: the design of the Flash Translation Laye...|$|R
5000|$|The DEUCE had 1450 {{thermionic}} valves, {{and used}} mercury delay lines for its main memory; {{each of the}} 12 delay lines could store 32 instructions or data words of 32 bits. It adopted the then high 1 megahertz clock rate of the Pilot ACE. Input-output was via Hollerith 80-column punch-card equipment. The reader read cards {{at the rate of}} 200 per minute, while the card punch rate was 100 cards per minute. The DEUCE also had an 8192-word magnetic drum for main storage. To access any of the 256 tracks of 32 words, the drum had one group of 16 read and one group of 16 write heads, each group on independent moveable arms, each capable of moving to one of 16 positions. Access time was 15 milliseconds if the heads were already in position; an additional 35 milliseconds was required if the heads had to be moved. There was no <b>rotational</b> <b>delay</b> incurred when reading from and writing to drum. Data was transferred between drum and one of the 32-word delay lines.|$|E
40|$|The 3390 disks rotated {{faster than}} those in the {{previous}} model 3380. Faster disk rotation reduced <b>rotational</b> <b>delay</b> (ie. the time required for the correct area of the disk surface to move to the point where data could be read or written). In the 3390 's initial models, the average <b>rotational</b> <b>delay</b> was reduced to 7. 1 milliseconds from 8. 3 milliseconds for the 3380 family...|$|E
40|$|Abstract We {{propose a}} new {{approach}} for I/O scheduling that per-forms on-line simulation of the underlying disk. When simulation is integrated within a system, three key chal-lenges must be addressed: first, the simulator must be portable across {{the full range of}} devices; second, all con-figuration must be automatic; third, the computation and memory overheads must be low. Our simulator, the DiskMimic, achieves these goals by building a table-based model of the disk as it observes the times for previousrequests. We show that a shortest-mimicked-time-first (SMTF) scheduler performs nearly as well as an approachwith perfect knowledge of the underlying device and that it is superior to traditional scheduling algorithms such asC-LOOK and SSTF; our results hold as the seek and rotational characteristics of the disk are varied. 1 Introduction High-performance disk schedulers explored in the re-search literature are becoming progressively more tuned to the performance characteristics of the underlying disks. Each generation of disk schedulers has accounted for more of the behavior of storage devices at the time. Forexample, disk schedulers analyzed in the 1970 s and 1980 s focused on minimizing seek time, given that seek timewas often an order of magnitude greater than the expected <b>rotational</b> <b>delay</b> [10, 26, 29]. In the early 1990 s, the fo-cus of disk schedulers shifted to take <b>rotational</b> <b>delay</b> into account, as rotational delays and seek costs became morebalanced [13, 21, 31]...|$|E
40|$|The {{increasing}} number and proportion of aged {{individuals in the}} population warrants knowledge of normal physiological changes of left ventricular (LV) biomechanics with advancing age. LV twist describes the instantaneous circumferential motion of the apex {{with respect to the}} base of the heart and has an important role in LV ejection and filling. This study sought to investigate the biomechanics behind age-related changes in LV twist by determining a broad spectrum of LV rotation parameters in different age groups, using speckle tracking echocardiography (STE). The final study population consisted of 61 healthy volunteers (16 - 35 yr, n = 25; 36 - 55 yr, n = 23; 56 - 75 yr, n = 13; 31 men). LV peak systolic rotation during the isovolumic contraction phase (Rotearly), LV peak systolic rotation during ejection (Rotmax), instantaneous LV peak systolic twist (Twistmax), the time to Rotearly, Rotmax, and Twistmax, and <b>rotational</b> deformation <b>delay</b> (defined as the difference of time to basal Rotmaxand apical Rotmax) were determined by STE using QLAB Advanced Quantification Software (version 6. 0; Philips, Best, The Netherlands). With increasing age, apical Rotmax(P < 0. 05), time to apical Rotmax(P < 0. 01), and Twistmax(P < 0. 01) increased, whereas basal Rotearly(P < 0. 001), time to basal Rotearly(P < 0. 01), and <b>rotational</b> deformation <b>delay</b> (P < 0. 05) decreased. <b>Rotational</b> deformation <b>delay</b> was significantly correlated to Twistmax(R 2 = 0. 20, P < 0. 05). In conclusion, Twistmaxincreased with aging, resulting from both increased apical Rotmaxand decreased <b>rotational</b> deformation <b>delay</b> between the apex and the base of the LV. This may explain the preservation of LV ejection fraction in the elderly. Copyrigh...|$|R
40|$|Abstract—One of {{the biggest}} {{bottlenecks}} in desktop-based computing is the hard disk with I/O write latency being a key contributor. I/O write latency stems from the mechanical nature of hard disks, with seek and <b>rotational</b> <b>delays</b> the major components. Hybrid disk drives place {{a small amount of}} flash memory (NVCache) on the drive itself which can be leveraged by the host and has the potential to increase I/O performance and reduce hard disk power consumption. We present an I/O scheduling algorithm, ”Flash-Backed I/O Requests”, which leverages the on-board flash to reduce write latency. Since flash memory and rotating media have different I/O characteristics, predominantly in random access context, an I/O scheduler can decide which media will most efficiently service I/O requests. Our results show that with Flash-Backed I/O requests, overall write latency can be reduced by up to 70 %. I...|$|R
40|$|This paper {{presents}} the design, implementation, {{and evaluation of}} BORG, a self-optimizing storage system that performs automatic block reorganization based on the observed I/O workload. BORG is motivated by three characteristics of I/O workloads: non-uniform access frequency distribution, temporal locality, and partial determinism in non-sequential accesses. To achieve its objective, BORG manages a small, dedicated partition on the disk drive, {{with the goal of}} servicing a majority of the I/O requests from within this partition with significantly reduced seek and <b>rotational</b> <b>delays.</b> BORG is transparent {{to the rest of the}} storage stack, including applications, file system(s), and I/O schedulers, thereby requiring no or minimal modification to storage stack implementations. We evaluated a Linux implementation of BORG using several real-world workloads, including individual user desktop environments, a web-server, a virtual machine monitor, and an SVN server. These experiments comprehensively demonstrate BORG’s effectiveness in improving I/O performance and its incurred resource overhead. ...|$|R
40|$|Disk {{performance}} is increasingly limited by its head positioning latencies, i. e., seek time and <b>rotational</b> <b>delay.</b> To reduce the head positioning latencies, we propose a novel technique that dynamically places copies of data in file system’s free blocks {{according to the}} disk access patterns observed at runtime. As one or more replicas can now be accessed {{in addition to their}} original data block, choosing the “nearest ” replica that provides fastest access can significantly improve performance for disk I/O operations. We implemented and evaluated a prototype based on the popular Ext 2 file system. In our prototype, since the file system layout is modified only by using the free/unused disk space (hence the name Free Space File System, or FS 2), users are completely oblivious to how the file system layout is modified in the background; they will only notice performance improvements over time. For a wide range of workloads running under Linux, FS 2 is shown to reduce disk access time by 41 – 68 % (as a result of a 37 – 78 % shorter seek time and a 31 – 68 % shorter <b>rotational</b> <b>delay)</b> making a 16 – 34 % overall user-perceived performance improvement. The reduced disk access time also leads to a 40 – 71 % energy savings per access...|$|E
40|$|A {{variety of}} performance-enhancing techniques, such as striping, mirroring, and {{rotational}} data replication, {{exist in the}} disk array literature. Given a fixed budget of disks, one must intelligently choose what combination of these techniques to employ. In this paper, we present a way of designing disk arrays that can flexibly and systematically reduce seek and <b>rotational</b> <b>delay</b> in a balanced manner. We give analytical models that can guide an array designer towards optimal configurations by considering both disk and workload characteristics. We have implemented a prototype disk array that incorporates the configuration models. In the process, we have also developed a robust disk head position prediction mechanism without any hardware support. The resulting prototype demonstrates the e#ectiveness of the configuration models. 1 Introduction In this paper, {{we set out to}} answer a simple question: how do we systematically increase the performance of a disk array by adding more disks? Thi [...] ...|$|E
40|$|We {{show that}} {{clustering}} the active data of a file {{system in the}} center of the disk is a viable and effective means of improving system I/O performance. We demonstrate that it can reduce the average seek delay and in the presence of disk queues it can also reduce the average <b>rotational</b> <b>delay.</b> We also present experimental results which show that file access patterns are strongly skewed, and that file activity levels are relatively stable over time, making them a good predictor of future file activity levels. Using simulations, we investigate two techniques for reorganizing the disk data, and we measure sensitivity to imperfect predictions of future file activity due to drifting file activity levels. We demonstrate significant performance improvements over a full spectrum of file system use, from lightly loaded systems through heavily loaded systems with large disk queues, with performance benefits increasing as the system load increases. 1 Introduction and Motivation iPcres [...] ...|$|E
40|$|One of {{the biggest}} {{bottlenecks}} in desktop-based computing is the hard disk with I/O write latency being a key contributor. I/O write latency stems from the mechanical nature of hard disks, of which seek and <b>rotational</b> <b>delays</b> are the major components. Hybrid disk drives place {{a small amount of}} flash memory (NVCache) on the drive itself which can be leveraged by the host and has the potential to increase I/O performance and reduce hard disk power consumption. In this paper we present an I/O scheduling algorithm, ”Flash-Backed I/O Requests”, which leverages the onboard flash to reduce write latency. Since flash memory and rotating media have different I/O characteristics, predominantly in random access context, an I/O scheduler can decide which media will most efficiently service I/O requests. Our results show that with Flash-Backed I/O requests, overall write latency can be reduced by up to 80 %. Additionally, such a scheme does not require a log-structured file system and associated cleaner overhead. ...|$|R
40|$|CARS {{experiments}} on s-tetrazine vapour {{show that the}} eletronic resonance enhancement in the Q-branch is most effective for the lower J values. This suggests that the radiationless relaxation rate in the excited state increases with <b>rotational</b> quantum number. <b>Delayed</b> picosecond CARS experiments indicate that the rotation-vibration coupling for the 1008 cm- 1 ground-state vibrational mode is approximately 2 MHz. ...|$|R
40|$|During {{concurrent}} I/O workloads, {{sequential access}} to one I/O stream can be interrupted by accesses to other streams in the system. Frequent switching between multiple sequential I/O streams may severely affect I/O efficiency due to long disk seek and <b>rotational</b> <b>delays</b> of disk-based storage devices. Aggressive prefetching {{can improve the}} granularity of sequential data access in such cases, but {{it comes with a}} higher risk of retrieving unneeded data. This paper proposes a competitive prefetching strategy that controls the prefetching depth so that the overhead of disk I/O switch and unnecessary prefetching are balanced. The proposed strategy does not require a-priori information on the data access pattern, and achieves at least half the performance (in terms of I/O throughput) of the optimal offline policy. We also provide analysis on the optimality of our competitiveness result and extend the competitiveness result to capture prefetching in the case of random-access workloads. We have implemented the proposed competitive prefetching policy in Linux 2. 6. 10 and evaluated its performance on both standalone disks and a disk array using a variety of workloads (including two common file utilities, Linux kernel compilation, the TPC-H benchmark, the Apache web server, and index searching). Compared to the original Linux kernel, our competitive prefetching system improves performance by up to 53 %. At the same time, it trails the performance of an oracle prefetching strategy by no more than 42 %...|$|R
40|$|Conventional wisdom {{holds that}} {{reducing}} disk latency leads to higher disk utilization, maximizing disk utilization leads to higher throughput, and employing a faster disk leads to better performance. All {{of this is}} true when building a conventional file or database system. In this paper we show that these principles can be misleading when applied to a media server. To design such a server, we propose a cost-based approach {{that focuses on the}} perstream costs. We give various examples to illustrate the design process. Keywords: multimedia, disk latency, memory utilization, per-stream cost. 1 Introduction Maximizing throughput is a common design objective for a media server. To improve throughput, two approaches have been used: reducing disk latency (i. e., seek overhead and <b>rotational</b> <b>delay)</b> and minimizing the required memory. To reduce disk latency we can either employ efficient disk scheduling [13, 14, 15] or enact intelligent data placement policies [9, 11]. Both methods effectively [...] ...|$|E
40|$|Disk {{performance}} for random access fares significantly worse compared to sequential access. Time required to transfer random blocks {{to or from}} disk is dominated by seeking and <b>rotational</b> <b>delay.</b> To improve the throughput and reduce the latency, one can apply techniques to increase the sequentiality of disk accesses, such as block rearrangement and replication. We introduce an approach to improve read performance by replicating blocks into file system free space at the block level. This makes the replication module independent of the file system and therefore easier to implement and verify. A solution that requires no changes to the file system is also easier to adopt. Supporting a new file system {{is a matter of}} writing a user-space component that understands its free block data structures. We implemented a prototype as a stacked device driver for Linux and evaluated its performance on a number of workloads. ii Table of Contents Abstract [...] . i...|$|E
40|$|In this paper, {{we address}} the problem of {{efficiently}} reading a set of pages from a file which is kept on some cylinders of a magnetic disk. It is assumed that several pages can be read from disk in a single multi-page request without interruption by other requests. First, a simple algorithm is presented for computing a schedule how the required pages are read from disk. Then, the expected cost of the schedules is analyzed by using a pure analytical model. In addition to the disk geometry, the analysis takes into account the three major cost components (seek time, <b>rotational</b> <b>delay</b> and transfer time) which occur when pages are retrieved from magnetic disk. The derived cost function depends on two parameters: the number of required pages and the degree of clustering of the underlying file. The cost function demonstrates that significant performance improvements can be achieved by using multi-page requests when the required pages are read according to a well-computed schedule. In addition [...] ...|$|E
25|$|File fragmentation: {{where there}} is not {{sufficient}} space for a file to be recorded in a contiguous region, it is split into non-contiguous fragments. This does not cause <b>rotational</b> or head-movement <b>delays</b> as with electromechanical hard drives, but may decrease speed; for instance, by requiring additional reads and computation to determine where on the card the file's next fragment is stored.|$|R
40|$|Title {{from first}} page of PDF file (viewed September 10, 2010) Includes bibliographical {{references}} (p. 41 - 43) With recent technological advances and continuously decreasing cost per GB, flash memory based solid state disk (hereafter, flash disk) has already been {{considered to be the}} future replacement of rotating-based hard disk. Unlike hard disk drives, flash disks are less prone to mechanical wear and tear, have no seek or <b>rotational</b> <b>delays,</b> and consume much less power. However, flash memory has limited write endurance as a block becomes unreliable after a finite number of erasure/write cycles. This characteristic hinders flash disks from being readily used for server domain. Consequently, wear-leveling techniques are employed to distribute block erasures and re-writes evenly across the medium. Existing wear-leveling techniques are essentially intra-disk data arrangement and distribution schemes, which organize data within one flash disk. Nevertheless, an inter-disk wear-leveling technique, which can ensure uniform wear-out of blocks across multiple flash disks, is much needed for enterprise-class storage systems where flash disks are organized in a disk array. In this study, we propose an inter-disk wear-leveling strategy called iWell (inter-disk wear leveling) that dynamically and evenly distributes writes across a flash disk array. The proposed iWell technique compliments existing intra-disk wear-leveling techniques to further improve flash disk's reliability while achieving a better performance in most scenarios. Results from a comprehensive simulation study based on both real-world traces and synthetic benchmarks demonstrate that iWell significantly improves the reliability and lifespan of a flash disk array by largely reducing the variance in terms of writes and merge operations among disks...|$|R
40|$|Recent {{technological}} {{advances in the}} development of flash-memory based devices have consolidated their leadership position as the preferred storage media in the embedded systems market and opened new vistas for deployment in enterprise-scale storage systems. Unlike hard disks, flash devices are free from any mechanical moving parts, have no seek or <b>rotational</b> <b>delays</b> and consume lower power. However, the internal idiosyncrasies of flash technology make its performance highly dependent on workload characteristics. The poor performance of random writes has been a cause of major concern which needs to be addressed to better utilize the potential of flash in enterprise-scale environments. We examine one of the important causes of this poor performance: the design of the Flash Translation Layer (FTL) which performs the virtual-to-physical address translations and hides the erase-before-write characteristics of flash. We propose a complete paradigm shift {{in the design of the}} core FTL engine from the existing techniques with our Demand-based Flash Translation Layer (DFTL) which selectively caches page-level address mappings. We develop and validate a flash simulation framework called FlashSim. Our experimental evaluation with realistic enterprise-scale workloads endorses the utility of DFTL in enterprise-scale storage systems by demonstrating: (i) improved performance, (ii) reduced garbage collection overhead and (iii) better overload behavior compared to state-of-the-art FTL schemes. For example, a predominantly random-write dominant I/O trace from an OLTP application running at a large financial institution shows a 78 % improvement in average response time (due to a 3 -fold reduction in operations of the garbage collector), compared to a state-of-the-art FTL scheme. Even for the well-known read-dominant TPC-H benchmark, for which DFTL introduces additional overheads, we improve system response time by 56 %. ...|$|R
40|$|Disk I/O is {{the primary}} {{performance}} bottleneck {{for a wide range}} of workloads due to the relatively large, mechanical seek and <b>rotational</b> <b>delay</b> overheads incurred during I/O operations. Current-day file systems that exclusively manage storage space on disk drives employ static data layouts and do not attempt to optimize for application access patterns. We argue that this lack of application awareness in operating system storage management is one of the key reasons for sub-optimal disk I/O performance. We present the design and implementation of BORG, a self-optimizing block storage layer that performs automatic block reorganization to optimize storage system performance, while remaining oblivious to the file system(s) and application layers above and the I/O scheduling and device driver layers below. BORG optimizes storage system performance in a continuous and online fashion by dynamically reorganizing disk data to best suit common disk access patterns. It successfully addresses the key requirements for a self-optimizing storage solution, incorporating accurate extraction and representation of disk access patterns, file system independence, modularization of storage stack layers, isolation of space management responsibilities, data consistency, online optimization capability, and overhead control. A Linux implementation of BORG demonstrates consistent improvements in disk I/O performance for a variety of workloads ranging from file servers and web servers to development workstations and even individual desktop applications, with acceptable overhead in other resource dimensions. ...|$|E
40|$|Next {{generation}} database {{systems will}} need to provide support for both textual data {{and other types of}} multimedia data (e. g., images, video, audio). These two types of data di er in their characteristics, and hence require different techniques for their organization and management. For example, continuous media data (e. g., video, audio) requires a guaranteed transfer rate. In this paper, we provide an overview of 1) how database systems can be architectured to support multimedia data, and 2) what are the main challenges in devising new algorithms to manage multimedia data. In order to provide rate guarantees for continuous media data, an admission control scheme must be employed that determines, for each client, whether there are sufficient resources available to service that client. To maximize the number of clients that can be admitted concurrently, the various system resources must be allocated and scheduled carefully. In terms of disks, we use algorithms for retrieving/storing data from/to disks that reduce seek latency time and eliminate <b>rotational</b> <b>delay,</b> thereby providing high throughput. In terms of main-memory, we use bu er management schemes that exploit the sequential access patterns for continuous media data, thereby resulting in efficient replacement of buffer pages from the cache. In addition to discussing resource scheduling, we also present schemes for the storage layout of data on disks and schemes that provide fault-tolerance by ensuring uninterrupted service in the presence of disk failures...|$|E
40|$|In {{this work}} we {{investigate}} three approaches to computing on massive data sets. In the first approach, we give a sampling algorithm {{to estimate the}} maximum of a large data set. It gives estimates strictly better than the largest sample for an infinite family of data sets. In addition, the algorithm overshoots the true maximum of the worst case data set with probability at most 1 /e + O(1 /k), where the sample is of size k, which is {{much smaller than the}} size of the data set. Our proof {{is the result of a}} new extremal graph coloring theorem. In the second approach, we consider algorithms which process queries in batches for greater efficiency. We give a batched algorithm for high dimensional hamming nearest neighbors using fast matrix multiplication. In addition, using two techniques, query data structures and presampling, we create batched algorithms for string matching, 1 D nearest neighbor, 2 D 2 -approximate nearest neighbor, 2 D point location, selection, inhull and halfplane intersection. These algorithms answer b queries to an unsorted data set of size n in O(nlogb) time using O(b 2) space and O(n/B) I/O's to the data set, where B is the block size. In the third approach, we consider the problem of designing disk arrays that reduce both read and write latency. We explore the disk array techniques of striping, mirroring, rotational replication, and eager writing. We give analytical models for three disk array combinations that reduce the seek and <b>rotational</b> <b>delays</b> of reads in a balanced fashion. Then we model the dramatic reduction in write latency of eager writing. Finally, we combine the ideas of mirroring, striping and eager writing. We discuss how to analytically model the latency of reads and writes, and how to maintain persistence. Finally we combine algorithms a [...] ...|$|R
40|$|Freeblock {{scheduling}} replaces a disk drive's <b>rotational</b> latency <b>delays</b> with useful background media transfers, potentially allowing background disk I/O {{to occur}} with {{no impact on}} foreground service times. To do so, a freeblock scheduler {{must be able to}} very accurately predict the service time components of any given disk request [...] the necessary accuracy was not previously considered achievable outside of disk firmware. This paper describes the design and implementation of a working external freeblock scheduler running either as a user-level application atop Linux or inside the FreeBSD kernel. This freeblock scheduler can give 15 % of a disk's potential bandwidth (over 3. 1 MB/s) to a background disk scanning task with almost no impact (less than 2 %) on the foreground request response times. This can increase disk bandwidth utilization by over 6 x...|$|R
40|$|We investigate, through simulation, the {{evolution}} of polarization states during atmospheric propagation of high power, ultrashort laser pulses. A <b>delayed</b> <b>rotational</b> response model handling arbitrary, transverse polarization couples both the amplitude and phase of the polarization states. We find that, while circularly and linearly polarized pulses maintain their polarization, elliptically polarized pulses become depolarized due to energy equilibration between left and right circularly polarized states. The depolarization can be detrimental to remote radiation generation schemes and obscures time-integrated polarization measurements...|$|R
40|$|Abstract. The main {{magnetic}} characteristics regarding the domain structure and magnetization processes (axial, circular and Matteucci and inverse Wiedemann effects) of amorphous wires and glass-coated microwires are analysed. Magnetic bistability, spontaneously observed in samples with large enough ratio magneto-elastic anisotropy with axial easy axis to shape anisotropy, {{is the main}} source {{for a number of}} sensor applications in pulse generators, position and field sensors, encoded security tags, <b>rotational</b> counters, magnetostrictive <b>delay</b> lines, and so on. The relevant perspectives of the novel giant magneto-impedance effect recently reported and observed in non-magnetostrictive samples are also introduced. 1...|$|R
40|$|State‐selected delayed pulsed‐field {{threshold}} photoionizationspectra of HCl and DCl {{are recorded}} in double‐resonant transitions through the F ^ 1 Δ, E ^ 1 Σ^+, and g ^ 3 Σ^− {{states of the}} 4 pπ Rydberg configuration. Comparison of observed rotational line strengths with calculated spectra, {{as well as with}} available time‐of‐flight photoelectron spectra, provides useful insight on the influence of spin–orbit and <b>rotational</b> autoionization on <b>delayed</b> pulsed‐field threshold photoionization of HCl. Spin–orbit and rotational autoionization are seen to dramatically reduce the ion rotational intensity associated with the upper spin–orbit level of the ion...|$|R
5000|$|The {{performance}} of a drum with one head per track is determined almost entirely by the rotational latency, whereas in an HDD its performance includes a <b>rotational</b> latency <b>delay</b> plus the time to position the head over the desired track (seek time). In the era when drums were used as main working memory, programmers often did optimum programming—the programmer positioned code on the drum {{in such a way}} as to reduce the amount of time needed for the next instruction to rotate into place under the head. They did this by timing how long it would take after loading an instruction for the computer to be ready to read the next one, then placing that instruction on the drum so that it would arrive under a head just in time. This method of timing-compensation, called the [...] "skip factor" [...] or [...] "interleaving" [...] (interleaving in disk storage), was used for many years in storage memory controllers.|$|R
40|$|Abstract. The main {{objective}} {{of this paper is}} to present the modeling and simulation of open loop dynamics of a rigid body insect-like flapping wing. The most important aerodynamic mechanisms that explain the nature of the flapping flight, including added mass, <b>rotational</b> lift and <b>delayed</b> stall, are modeled. Wing flapping kinematics is described using appropriate reference frames and three degree of freedom for each wing with respect to the insect body. In order to simulate nonlinear differential equations of motion, 6 DOF model of the insect-like flapping wing is developed, followed by an evaluation of the simulation results in hover condition...|$|R
40|$|BACKGROUND: The {{associations}} of left ventricular (LV) systolic torsion with clinical and echocardiographic variables in physiological conditions {{have not been}} fully investigated. We explored the independent determinants of LV systolic torsion in a population of normal subjects. METHODS: In 119 healthy subjects, peak twist angle (LVtw) and torsion (LVtor) during ejection, and the QRS-LVtw interval (time-to-peak LVtw) were measured by speckle tracking. LV twisting rate and <b>rotational</b> deformation <b>delay</b> were also determined. RESULTS: Stepwise multiple regression showed that LVtw was independently associated with indexed end-systolic volume (β=- 0. 200, P < 0. 0001), peak early diastolic mitral annulus velocity (β=- 0. 186, P = 0. 0001), heart rate (β= 0. 178, P = 0. 0003), and male gender (β=- 0. 174, P = 0. 0004). Similar results were found for LVtor. Age was the only parameter, which has demonstrated an independent correlation with time-to-peak LVtw (β= 0. 329, P < 0. 0001). Despite significance of these associations, the proportions of variability explained by regression models were relatively low (range 11 - 26...|$|R
40|$|Much {{attention}} {{has been devoted to}} how playground swing amplitudes are built up by swinger techniques, i. e. body actions. However, very little {{attention has}} been given to the requirements that such swinger techniques place on the swinger himself. The {{purpose of this study was}} to find out whether different swinger techniques yield significantly different maximum torques, endurance and coordinative skills, and also to identify preferable techniques. We modeled the seated swinger as a rigid dumbbell and compared three different techniques. A series of computer simulations was run with each technique, testing performance with different body <b>rotational</b> speeds, <b>delayed</b> onset of body rotation, and different body mass distributions, as swing amplitudes were brought up towards 90 °. One technique was found extremely sensitive to the timing of body actions, limiting swing amplitudes to 50 ° and 8 ° when body action was delayed by 0. 03 s and 0. 3 s, respectively. The two other more robust techniques reached 90 ° even with the largest of these delays, although more time (and endurance) was needed. However, these two methods also differed with respect to maximum torque and endurance, and none was preferable in both these aspects, being dependent on the swinger goals and abilities...|$|R
40|$|The human {{myocardium}} is a metabolic omnivore and utilises fatty acids, glucose, ketones, {{amino acids}} and lactate to produce energy. Altered metabolism results in cardiac muscle dysfunction and {{can play a}} potentially significant role in development of heart failure. Metabolic modulators like Perhexiline are potentially significant new treatments {{in the management of}} heart failure and coronary artery disease. Diabetes is a metabolic disorder that results in altered high energy phosphate kinetics in the myocardium. We demonstrate that microvascular disease plays little {{role in the development of}} impaired cardiac energetics in young patients with uncomplicated type 1 diabetes. We have shown an increase in left ventricular torsion in these patients with normal ejection fraction. Coronary microvascular disease and <b>rotational</b> deformation <b>delay</b> play a significant role in the development of increased torsion in these individuals which counteracts the early diastolic dysfunction. Furthermore the left atrial contribution to left ventricular filling is increased in these individuals. We demonstrate that Perhexiline has a differential action on insulin sensitivity in subjects with and without diabetes. It also increased plasma ketones and triglycerides in these patients. Finally we demonstrate that Perhexiline can be safely used and provides good relief of symptoms when used clinically in subjects with refractory angina and heart failure. ...|$|R
