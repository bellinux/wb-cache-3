10000|10000|Public
5|$|In August 2016, Microsoft {{released}} a refreshed Xbox One model, Xbox One S, {{which has a}} streamlined design, native support for 4K video playback and upscaling, and HDR10 high-dynamic-range color. It was praised for its smaller size, its on-screen visual improvements, and its lack of an external power supply, but its <b>regressions</b> such as {{the lack of a}} native Kinect port were noted. A high-end model, Xbox One X, was unveiled in June 2017 for release in November, which features major hardware upgrades focused on enabling games to be rendered at 4K resolution.|$|E
5|$|Windows 10 {{received}} mostly positive reviews {{upon its}} original release in July 2015; critics praised Microsoft's decision {{to provide a}} desktop-oriented interface in line with previous versions of Windows, contrasting the tablet-oriented approach of 8, although Windows 10's touch-oriented user interface mode was panned for containing <b>regressions</b> upon the touch-oriented interface of Windows 8. Critics also praised the improvements to Windows 10's bundled software over Windows 8.1, Xbox Live integration, {{as well as the}} functionality and capabilities of Cortana personal assistant and the replacement of Internet Explorer with Microsoft Edge. However, media outlets have been critical of changes to operating system behaviors, including mandatory update installation, privacy concerns over data collection performed by the OS for Microsoft and its partners, and the adware-like tactics used to promote the operating system on its release.|$|E
25|$|Additional {{evidence}} for conditional convergence comes from multivariate, cross-country <b>regressions.</b>|$|E
5000|$|<b>Regression</b> analysis: Linear <b>regression,</b> Stepwise <b>regression,</b> Nonlinear <b>regression,</b> logit/probit/gompit, {{logistic}} <b>regression,</b> multinomial logit, Poisson <b>regression,</b> Box-Cox transformation, Cox <b>regression</b> ...|$|R
40|$|<b>Regression</b> Modeling: Methods, Theory, and Computation with SAS {{provides}} {{an introduction to}} a diverse assortment of <b>regression</b> techniques using SAS to solve {{a wide variety of}} <b>regression</b> problems. The author fully documents the SAS programs and thoroughly explains the output produced by the programs. The text presents the popular ordinary least squares (OLS) approach before introducing many alternative <b>regression</b> methods. It covers nonparametric <b>regression,</b> logistic <b>regression</b> (including Poisson <b>regression),</b> Bayesian <b>regression,</b> robust <b>regression,</b> fuzzy <b>regression,</b> random coefficients <b>regression...</b>|$|R
50|$|<b>Regression</b> methods {{continue}} to be an area of active research. In recent decades, new methods {{have been developed for}} robust <b>regression,</b> <b>regression</b> involving correlated responses such as time series and growth curves, <b>regression</b> in which the predictor (independent variable) or response variables are curves, images, graphs, or other complex data objects, <b>regression</b> methods accommodating various types of missing data, nonparametric <b>regression,</b> Bayesian methods for <b>regression,</b> <b>regression</b> in which the predictor variables are measured with error, <b>regression</b> with more predictor variables than observations, and causal inference with <b>regression.</b>|$|R
25|$|CSS level 1 {{is fully}} supported. CSS level 2 is mostly supported, however several {{rendering}} bugs and <b>regressions</b> may affect conformance. CSS level 3 is partially supported.|$|E
25|$|In 2008, Torvalds {{stated that}} he used the Fedora {{distribution}} of Linux because it had fairly good support for the PowerPC processor architecture, which he had favored at the time. His usage of Fedora was confirmed in a later 2012 interview. He has also posted updates about his choice of desktop environment, often in response to perceived feature <b>regressions.</b>|$|E
25|$|In addition, the Chow test {{is used to}} {{test whether}} two subsamples both have the same {{underlying}} true coefficient values. The sum of squared residuals of <b>regressions</b> {{on each of the}} subsets and on the combined data set are compared by computing an F-statistic; if this exceeds a critical value, the null hypothesis of no difference between the two subsets is rejected; otherwise, it is accepted.|$|E
40|$|The {{correlated}} Weibull <b>regression</b> {{model for}} the analysis of correlated binary data is presented. This <b>regression</b> model is based on Bonney 2 ̆ 019 s disposition {{model for the}} <b>regression</b> analysis of correlated binary outcomes. Parameter estimation was done through the maximum likelihood method. The correlated Weibull <b>regression</b> model was contrasted with the correlated logistic <b>regression</b> model. The results showed that both <b>regression</b> models were useful in explaining the familial aggregation of oesophageal cancer. The correlated logistic <b>regression</b> model fitted the oesophageal cancer data better than the correlated Weibull <b>regression</b> model for both the non-nested and nested cases. Furthermore, the correlated logistic <b>regression</b> model was computationally more attractive than the correlated Weibull <b>regression</b> model...|$|R
2500|$|Chapter 2: Linear <b>Regression,</b> Linear <b>Regression</b> with Error Bars and Nonlinear <b>Regression.</b>|$|R
40|$|As cloud {{data center}} consumes {{more and more}} energy, both {{researchers}} and engineers aim to minimize energy consumption while keeping its services available. A good energy model can reflect the relationships between running tasks and the energy consumed by hardware and can be further used to schedule tasks for saving energy. In this paper, we analyzed linear and nonlinear <b>regression</b> energy model based on performance counters and system utilization and proposed a support vector <b>regression</b> energy model. For performance counters, we gave a general linear <b>regression</b> framework and compared three linear <b>regression</b> models. For system utilization, we compared our support vector <b>regression</b> model with linear <b>regression</b> and three nonlinear <b>regression</b> models. The experiments show that linear <b>regression</b> model {{is good enough to}} model performance counters, nonlinear <b>regression</b> is better than linear <b>regression</b> model for modeling system utilization, and support vector <b>regression</b> model is better than polynomial and exponential <b>regression</b> models...|$|R
25|$|Tests can be run at {{any point}} new code is {{introduced}} into a codebase to confirm no <b>regressions</b> within the existing test coverage are introduced. It can be integrated with Selenium and other browser emulators to generate screenshots of failures. Like other BDD frameworks, Behat scenarios {{are a series of}} Given, When, and Then steps that explain a business case. The definition of these steps exist within method annotations of a class that extends the BehatContext.|$|E
25|$|Skilled readers {{move their}} eyes during {{reading on the}} average of every quarter of a second. During {{the time that the}} eye is fixated, new {{information}} is brought into the processing system. Although the average fixation duration is 200–250 ms (thousandths of a second), the range is from 100 ms to over 500 ms. The distance the eye moves in each saccade (or short rapid movement) is between 1 and 20 characters with the average being 7–9 characters. The saccade lasts for 20–40 ms and during this time vision is suppressed so that no new information is acquired. There is considerable variability in fixations (the point at which a saccade jumps to) and saccades between readers and even for the same person reading a single passage of text. Skilled readers make <b>regressions</b> back to material already read about 15 percent of the time. The main difference between faster and slower readers is that the latter group consistently shows longer average fixation durations, shorter saccades, and more <b>regressions.</b> These basic facts about eye movement have been known for almost a hundred years, but only recently have researchers begun to look at eye movement behavior as a reflection of cognitive processing during reading.|$|E
25|$|Ashes of the Singularity was {{the first}} {{publicly}} available game to utilize DirectX 12. Testing by Ars Technica in August 2015 revealed slight performance <b>regressions</b> in DirectX 12 over DirectX 11 mode for the Nvidia GeForce 980 Ti, whereas the AMD Radeon R9 290x achieved consistent performance improvements of up to 70% under DirectX 12, in some scenarios the AMD outperformed the more powerful Nvidia under DirectX 12. The performance discrepancies {{may be due to}} poor Nvidia driver optimizations for DirectX 12, or even hardware limitations of the card which was optimized for DirectX 11 serial execution, however the exact cause remains unclear.|$|E
40|$|This paper studies robust <b>regression</b> in the {{settings}} of Huber's ϵ-contamination models. We consider estimators that are maximizers of multivariate <b>regression</b> depth functions. These estimators are shown to achieve minimax rates in {{the settings}} of ϵ-contamination models for various <b>regression</b> problems including nonparametric <b>regression,</b> sparse linear <b>regression,</b> reduced rank <b>regression,</b> etc. We also discuss a general notion of depth function for linear operators that has potential applications in robust functional linear <b>regression...</b>|$|R
40|$|Abstract—In this paper, {{the sum of}} squares in linear <b>regression</b> {{is reduced}} to sum of squares in semi-parametric <b>regression.</b> We {{indicated}} that different sums of squares in the linear <b>regression</b> are similar to various deviance statements in semi-parametric <b>regression.</b> In addition to, coefficient of the determination derived in linear <b>regression</b> model is easily generalized to coefficient of {{the determination of the}} semi-parametric <b>regression</b> model. Then, it is made an application in order to support the theory of the linear <b>regression</b> and semi-parametric <b>regression.</b> In this way, study is supported with a simulated data example...|$|R
40|$|Using sine and cosine {{terms as}} {{predictors}} in modeling periodic time series {{and other kinds}} of periodic responses is a long-established technique, but it is often overlooked in many courses or textbooks. Such trigonometric <b>regression</b> is straightforward in Stata through applications of existing commands. I give various examples using classic periodic datasets on the motion of the asteroid Pallas and the daily rhythm of birth numbers. I make a brief connection to polynomial-trigonometric <b>regression.</b> circular <b>regression,</b> Fourier <b>regression,</b> harmonic <b>regression,</b> periodic <b>regression,</b> polynomial-trigonometric <b>regression,</b> trigonometric <b>regression,</b> sine, cosine...|$|R
25|$|Hierarchical {{linear models}} (or {{multilevel}} regression) organizes the data into {{a hierarchy of}} <b>regressions,</b> for example where A is regressed on B, and B is regressed on C. It is often used where the variables of interest have a natural hierarchical structure such as in educational statistics, where students are nested in classrooms, classrooms are nested in schools, and schools are nested in some administrative grouping, such as a school district. The response variable might be a measure of student achievement such as a test score, and different covariates would be collected at the classroom, school, and school district levels.|$|E
25|$|Reception to the Nintendo 2DS was mixed; while Nintendo {{was praised}} for how it priced and {{positioned}} the 2DS alongside its higher-end counterparts, {{much of its}} criticism was directed towards its <b>regressions</b> {{in comparison to the}} 3DS, such as a design that some considered less appealing than that of the 3DS, its lower sound quality, and its battery life. However, the 2DS's design was praised by some critics for being more robust and comfortable to hold than the 3DS, especially for its target market. Some critics also felt that the lack of 3D support was an admission by Nintendo that the concept was a fad; however, Nintendo has since stated that autostereoscopic 3D would remain a part of their future plans.|$|E
25|$|While doing fish {{research}} at Scripps, Keys would use <b>regressions</b> {{to determine the}} weight of fish from their length, a pioneering use of biostatistics at the time. Once in Copenhagen (1931), {{he would continue to}} study fish physiology and developed techniques for gill perfusion that provided evidence that fish regulated their sodium by controlling chloride excretion through their gills. He would also use this perfusion method to study the effects of adrenaline and vasopressin ("pitressin") on gill fluid flow and osmotic regulation in fishes. He also designed an improved Kjeldahl apparatus which improved upon Krogh's earlier design and allowed for more rapid determination of nitrogen content in biological samples. This would prove useful for activities as diverse as determining the protein content in grasshopper eggs and anemia in humans.|$|E
40|$|Abstract. <b>Regression</b> methods aim at {{inducing}} {{models of}} numeric data. While most state-of-the-art machine learning methods for <b>regression</b> focus on inducing piecewise <b>regression</b> models (<b>regression</b> and model trees), we investigate the predictive performance of <b>regression</b> models based on polynomial equations. We present Ciper, an efficient method for inducing polynomial equations and empirically evaluate its predictive performance on standard <b>regression</b> tasks. The evaluation shows that polynomials compare favorably to linear and piecewise <b>regression</b> models, induced by standard <b>regression</b> methods, {{in terms of}} degree of fit and complexity. The bias-variance decomposition of predictive error shows that Ciper has lower variance than methods for inducing <b>regression</b> trees. ...|$|R
40|$|The partial <b>regression</b> {{coefficient}} is {{also called}} <b>regression</b> coefficient, <b>regression</b> weight, partial <b>regression</b> weight, slope coefficient or partial slope coefficient. It {{is used in}} the context of multiple linear <b>regression</b> (mlr) analysis and gives the amount by which the dependent variable (DV) increases when on...|$|R
40|$|<b>Regression</b> Analysis is {{a multivariate}} {{statistical}} methodology to investigate relationships and predict outcomes. One type of <b>regression</b> analysis {{is known as}} logistic <b>regression.</b> Logistic <b>regression</b> is appropriate when the predicted outcome is binary (on/off, pass/fail, infected/not infected, etc.). Logistic <b>regression</b> techniques resolve inconsistencies associated wit...|$|R
25|$|Wallace {{attended}} Iowa State College in Ames, Iowa, {{graduating in}} 1910 with a bachelor's degree in animal husbandry. During {{his time at}} Iowa State, Wallace {{was a member of}} the Delta Tau Delta fraternity. He worked on the editorial staff of the family-owned paper Wallaces' Farmer in Des Moines from 1910 to 1924, and took the role of chief editor from 1924 to 1929. Wallace experimented with breeding high-yielding hybrid corn, and wrote a number of publications on agriculture. In 1915, he devised the first corn-hog ratio charts indicating the probable course of markets. Wallace was also a practicing statistician, writing an influential article with pioneering statistician George W. Snedecor of Iowa State University on computational methods for correlations and <b>regressions</b> and publishing sophisticated statistical studies in the pages of Wallaces’ Farmer. Snedecor invited Wallace to teach a graduate course on least squares. It was Wallace, more than any other individual, who introduced econometrics (a form of statistical analysis used by economists) to the field of agriculture.|$|E
500|$|The {{device was}} {{released}} to mostly positive reception; the G2 was universally praised for LG's efforts {{to produce a}} more seamless and compact design, its high performance, {{the quality of its}} display and camera, along with its long-lasting battery. Critics were divided on certain aspects of its design, such as its rear button layout, and its plastic chassis—which was panned for closely resembling recent Samsung Galaxy products and being a regression from the glass-based chassis of the Optimus G. Similarly, while its software and user interface was praised for its usability and large number of customization options, some reviewers felt that the software suffered from feature creep and contained notable usability <b>regressions</b> in comparison to [...] "stock" [...] Android.|$|E
500|$|Nick Pino of TechRadar {{was mostly}} positive, {{considering}} the Xbox One S to be [...] "the pinnacle of what Microsoft {{set out to}} create three years ago", but noting <b>regressions</b> such as the lack of Kinect port (which was interpreted as being [...] "one last kick in the pants for all the gamers forced into buying the more expensive console bundle two short years ago"), {{and the lack of}} 4K content sources beyond Blu-ray, Netflix, and YouTube. Visual improvements were noted on games such as Fallout 4 and Rise of the Tomb Raider when upscaled to 4K. Concerns were shown that the revised hardware and HDR support would lead to fragmentation of Xbox One's ecosystem, as not all users will necessarily experience a game the same way.|$|E
5000|$|Ridge <b>regression</b> or {{principal}} component <b>regression</b> or partial least squares <b>regression</b> can be used.|$|R
40|$|A {{procedure}} for constructing a vector of <b>regression</b> weights is considered. Under the <b>regression</b> superpopulation model, the ridge <b>regression</b> estimator that has minimum model {{mean squared error}} is derived. Through a simulation study, the ridge <b>regression</b> weights, <b>regression</b> weights, quadratic programming weights and raking ratio weights are compared. The ridge <b>regression</b> procedure with weights bounded by zero performed very well...|$|R
40|$|This paper {{studies the}} nonparametric modal <b>regression</b> problem {{systematically}} from a statistical learning view. Originally motivated by pursuing a theoretical {{understanding of the}} maximum correntropy criterion based <b>regression</b> (MCCR), our study reveals that MCCR with a tending-to-zero scale parameter is essentially modal <b>regression.</b> We show that nonparametric modal <b>regression</b> problem can be approached via the classical empirical risk minimization. Some efforts are then made to develop a framework for analyzing and implementing modal <b>regression.</b> For instance, the modal <b>regression</b> function is described, the modal <b>regression</b> risk is defined explicitly and its Bayes rule is characterized; {{for the sake of}} computational tractability, the surrogate modal <b>regression</b> risk, which is termed as the generalization risk in our study, is introduced. On the theoretical side, the excess modal <b>regression</b> risk, the excess generalization risk, the function estimation error, and the relations among the above three quantities are studied rigorously. It turns out that under mild conditions, function estimation consistency and convergence may be pursued in modal <b>regression</b> as in vanilla <b>regression</b> protocols, such as mean <b>regression,</b> median <b>regression,</b> and quantile <b>regression.</b> However, it outperforms these <b>regression</b> models in terms of robustness as shown in our study from a re-descending M-estimation view. This coincides with and in return explains the merits of MCCR on robustness. On the practical side, the implementation issues of modal <b>regression</b> including the computational algorithm and the tuning parameters selection are discussed. Numerical assessments on modal <b>regression</b> are also conducted to verify our findings empirically...|$|R
500|$|Karthik Pasupulate of The Times of India {{gave the}} film 3.5 out of 5 stars and wrote, [...] "You cannot {{appreciate}} the smarts {{in the script}} has been written, and how humorously it all gets translated onscreen without getting unduly melodramatic. Since this is ANR's last film, the cumulative nostalgia and feel goodness of the movie might just paper over the structural issues. It's definitely worth a watch". Suresh Kavirayani of Deccan Chronicle also gave the film 3.5 out of 5 stars and wrote, [...] "Vikram Kumar has {{come out with a}} nice story and screenplay and created a classic masterpiece. Though there are past life <b>regressions</b> and rebirths, the director’s intelligent screenplay makes you to see more comfortably without any confusion. Manam is a good film to watch and a fitting tribute to Akkineni Nageswara Rao." ...|$|E
500|$|Since its discovery, size {{estimates}} {{have varied}} from [...] "larger than a human" [...] to [...] "possibly the largest primate ever". In {{a study by}} Jungers from 1990, the area of its molar teeth predicted a mass of , while the femoral head diameter predicted a mass of [...] [...] In 1995, Laurie Godfrey estimated a mass of [...] using the midshaft circumferences of the humerus and femur. [...] Based on multiple <b>regressions</b> of the cortical area of the femur in 2008, Jungers and colleagues generated the current best estimate of [...] with a possible range of [...] [...] These estimates {{were considered to be}} more accurate since the harder cortical bone in the midshaft of the femur supported an animal's weight, and its thickness better correlated with the animal's mass than the midshaft diameter (which includes both hard cortex and spongy bone). [...] The only fossil primate that was probably larger than Archaeoindris was Gigantopithecus blacki, a close relative of orangutans.|$|E
2500|$|C21 [...] Cross-Sectional Models • Spatial Models • Treatment Effect Models • Quantile <b>Regressions</b> ...|$|E
40|$|<b>Regression</b> {{models are}} popular tool for rate-making {{in the context}} of {{heterogeneous}} portfolios. Nevertheless, classical <b>regression</b> methods have some disadvantages which significantly restrict their sphere of using. The paper is devoted to an alternative approach ? quantile <b>regression.</b> The quantile <b>regression</b> method allows overcome disadvantages of classical <b>regression.</b> ????????????? ?????? ? ?????????? ?????????? ??? ????? ??????????? ? ???????? ???????????? ?????????. ??? ?? ?????, ???????????? ????????????? ?????? ????? ??? ???????????, ??????? ??????????? ???????????? ????? ?? ??????????. ?????? ????????? ??????????????? ??????? ?????????? ??????????? ?????????. ????? ??????????? ????????? ????????? ?????????? ?????????? ???????????? ????????????? ??????...|$|R
40|$|This paper {{considers}} series estimators of additive interactive <b>regression</b> (AIR) models. AIR {{models are}} nonparametric <b>regression</b> models that generalize additive <b>regression</b> models by allowing interactions between different regressor variables. They place more {{restrictions on the}} <b>regression</b> function, however, than do fully nonparametric <b>regression</b> models. By doing so, they attempt to circumvent the curse of dimensionality that afflicts the estimation of fully non-parametric <b>regression</b> models. ...|$|R
50|$|Many {{techniques}} {{for carrying out}} <b>regression</b> analysis have been developed. Familiar methods such as linear <b>regression</b> and ordinary least squares <b>regression</b> are parametric, in that the <b>regression</b> function is {{defined in terms of}} a finite number of unknown parameters that are estimated from the data. Nonparametric <b>regression</b> refers to techniques that allow the <b>regression</b> function to lie in a specified set of functions, which may be infinite-dimensional.|$|R
