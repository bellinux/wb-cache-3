4|70|Public
3000|$|Where k is {{the number}} of repetitions. This value depends on the data traffic on the {{physical}} medium, where in less busy network the <b>repetition</b> <b>value</b> was approximately one repetition per the complete broadcast and this went up to approximately 7 for busy networks. For theoretical estimation, we set [...]...|$|E
40|$|We study {{a special}} kind of bounds (so called {{forbidden}} subgraph bounds, cf. Feige, Verbitsky ' 02) for parallel repetition of multi-prover games. First, we show that forbidden subgraph upper bounds for r > 3 provers imply the same bounds for the density Hales-Jewett theorem for alphabet of size r. As a consequence, this yields a new family of games with slow decrease in the parallel <b>repetition</b> <b>value.</b> Second, we introduce a new technique for proving exponential forbidden subgraph upper bounds and explore its power and limitations. In particular, we obtain exponential upper bounds for two-prover games with question graphs of treewidth at most two and show that our method cannot give exponential bounds for all two-prover graphs...|$|E
40|$|The {{invention}} {{relates to}} {{a method for}} providing a motion parameter set and/or a picture repetition pattern from an input video signal, in particular for de-interlacing a video signal with using a candidate motion parameter set weighted with a picture repetition pattern value for calculating a motion compensated pixel from a pixel value of a first image. To provide motion compensation which accounts for field repetition patterns, minimizing an error criterion between at least one pixel value of a second image and at least the motion compensated pixel value by iterating the calculation of the motion compensated pixel {{with at least two}} candidate motion parameters sets and/or at least two picture repetition values, and putting out the candidate motion parameter set and/or the picture <b>repetition</b> <b>value</b> which provides the minimized error criterion is proposed...|$|E
40|$|The {{purpose of}} this study was to assess the {{effectiveness}} of the estimated one <b>repetition</b> maximal <b>value</b> weight training program. Four healthy young male Judo club athletes participated as the subjects in this study for a period of fifty days. This study was based on the research done by Tanaka and Sasahara (１９９４) of the estimated one <b>repetition</b> maximal <b>value</b> weight training program. The training contents was based on three sets of ten repetitions of seventy percent load intensity of one <b>repetition</b> maximal <b>value.</b> The following results were obtained １. It was indicated that all four subjects in all of the categories showed significant increase of one repetition maximal value; ２. The increase in the mean of one <b>repetition</b> maximal <b>value</b> (deleting the categories prone to measurement error) was ten kilograms, a nearly twenty percent increase; ３. A significant difference in increase in the one <b>repetition</b> maximal <b>value</b> was not indicated between individuals; ４. A significant difference in increase in the one <b>repetition</b> maximal <b>value</b> was indicated between categories. The results conclude that there was a possibility of a mean increase of ten kilograms or approximately twenty percent increase in muscle strength (although this muscle strength increase differed by muscle area) by a training period of fifty days, three times a day. Therefore, this weight training program is effective...|$|R
50|$|The set S is {{the range}} of a {{primitive}} recursive function or empty. Even if S is infinite, <b>repetition</b> of <b>values</b> may be necessary in this case.|$|R
40|$|NarrowBand-Internet of Things (NB-IoT) is a {{radio access}} {{technology}} recently standardized by 3 GPP. To provide reliable connections with extended coverage, a repetition transmission scheme is applied in both Random Access CHannel (RACH) procedure and data transmission. In this letter, we model RACH in the NB-IoT network {{taking into account}} the repeated preamble transmission and collision using stochastic geometry. We derive the exact expression of RACH success probability under time correlated interference, and validate the analysis with different <b>repetition</b> <b>values</b> via independent simulations. Numerical results have shown that the repetition scheme can efficiently improve the RACH success probability in a light traffic scenario, but only slightly improves that performance with very inefficient channel resource utilization in a heavy traffic scenario...|$|R
40|$|This master's thesis {{presents}} {{an evaluation of}} Enhanced Compressed RealTime Protocol (ECRTP). ECRTP an extension to CRTP, is a header compression scheme for real time traffic. ECRTP exploits the hop-by-hop redundancy in a stream of IP/UDP/RTP packets, were virtually the same header is sent over and over again. The header and additional information is saved in a context at the compressor and decompressor. If the context is synchronized, the compressor can send only the differences since the last header and decompressor {{will be able to}} reconstruct the header. ECRTP was developed to overcome the problems of CRTP. CRTP does not perform well over links with long round trip time that lose and reorder packets. ECRTP extends CRTP by repeating context updates and by sending absolute values along with delta values when encoding monotonically increasing header fields to increase robustness. It inserts a header checksum when UDP checksum is missing, to improve error recovery and fail checks for the compression. The evaluation of ECRTP consists of two parts, simulations and a theoretical investigation. With the results of the simulations and the theory in mind, weaknesses and strength are pointed out and suggestions of improvement will be presented. A possible error in the establishment of the <b>repetition</b> <b>value</b> in the decompressor was found. The error can be avoided by sending the <b>repetition</b> <b>value</b> in the compressed header {{at the beginning of a}} session. The investigation shows that ECRTP handles packet loss and large round trip times well. ECRTP can be configured to handle packet reordering by exclusive use of absolute encoding for monotonically increasing header fields, by using most commonly changing fields that is not protected by the checksum as context-defining fields. The checksum-protected RTP fields should, if changed between two consecutive headers, be included in every packet and not compressed on the assumption of in-order delivery. All the suggested changes will decrease the compression efficiency. ECRTP is simulated together with two other schemes: CRTP and ROHC. It is shown that Robust header compression (ROHC) handles reordering better than expected. Especially the least significant bit encoding shows promising results and the handling of CSRC list. But also the handling of the checksum-protected RTP fields show that ROHC with some modifications could possibly be made to handle compression during reordering more efficiently than ECRTP. Validerat; 20101217 (root...|$|E
30|$|The {{simulation}} {{was repeated}} 1000 times for each parameter combination. We use the mean over the 1000 <b>repetitions</b> as the <b>value</b> of each variable in our simulations.|$|R
40|$|Laccase from Trametes versicolor was {{immobilized on}} {{magnetic}} (Fe 3 O 4) nanoparticles and microparticles. Free and immobilized laccase had activities 163 and about 4. 6 nkat mg– 1 respectively. Immobilized was 125. 8 µg enzyme mg– 1 of nanoparticles and 13 µg enzyme mg– 1 of microparticles. The Km were 10. 55, 9. 02 and 11. 14 mmol L– 1 for free laccase, immobilized on nanoparticles and immobilized on microparticles. The pH optimum after immobilization was about 0. 5 pH less than before immobilization. Immobilized laccase retained 55 % (nano) and 47 % (micro) of initial activity after nine <b>repetitions.</b> <b>Values</b> of T 50 were calculated respectively for free laccase, immobilized on nanoparticles and microparticles at 54. 5 °C, 57. 5 °C and 46 °C. Dyes Direct Blue 78, Acid Blue 225, Reactive Red 195, Acid Blue 74, and Phenol Red {{were used for}} decolorization by free and immobilized laccase. Laccase was able to decolorize most of the dyes well...|$|R
40|$|Background The aim of {{the current}} {{investigation}} {{was to examine the}} influence of the front and back squat variants on the hamstring and the quadriceps muscles kinematics. Material/Methods Eighteen male participants were recruited with 1 <b>repetition</b> maximum <b>values</b> of 122. 7 ± 16. 4 and 88. 7 ± 13. 9 kg for the back and front squat lifts. Participants completed both back and front squats at 70...|$|R
40|$|Abstract We have {{extracted}} run-time {{memory access}} traces fromthe Mediabench benchmark set. These traces exhibit {{a high degree}} of repetition. We propose an adaptive bus codingscheme that will reduce transition activity by exploiting <b>value</b> <b>repetition.</b> For this scheme, we introduce an extrabitline similar to bus-invert coding...|$|R
5000|$|The {{heart of}} the {{algorithm}} relies {{on the use of}} unitary operators dependent on [...] angles, where [...] in an input integer. These operators are iteratively applied on the completely mixed state, namely, a state that is an equal-probability mixture of all the possible states in the computational basis. In each iteration, the state is measured in the computational basis and [...] is calculated. After a sufficient number of <b>repetitions,</b> the <b>value</b> of [...] is almost optimal, and the state being measured is close to be optimal as well.|$|R
40|$|This {{research}} {{was carried out}} to find the dyeabilities and mordants effects of cow leather dyed with Lac powder. They were examined by changing dye concentration, dyeing temperature, bath ratio, dyeing time, and dyeing <b>repetition.</b> And K/S <b>values</b> and surface color changes were evaluated by various mordanting conditions. The optimum dyeing conditions of the cow leather dyed with Lac powder were 30 %, 40, 30 : 1,℃ 30 minutes, and 4 <b>repetitions.</b> The K/S <b>values</b> were higher in post mordant than pre mordanting condition. The surface colors of dyed cow leathers were R and RP. The dye fastnesses increased in post Cu and Fe mordanting, as decreased in gallnut and chestnut's skin conditions. Key words: lac 락 염 료 오배 자 율 피 매염powder (), gallnut (), chestnut's skin (), mordant (), 우피cow leather (...|$|R
40|$|International audienceWe study linear-time {{temporal}} logics interpreted over data {{words with}} multiple attributes. We restrict the atomic formulas to equalities of attribute values in successive positions and to <b>repetitions</b> of attribute <b>values</b> {{in the future}} or past. We demonstrate correspondences between satisfiability problems for logics and reachability-like decision problems for counter systems. We show that allowing/disallowing atomic formulas expressing <b>repetitions</b> of <b>values</b> in the past corresponds to the reachability/coverability problem in Petri nets. This gives us 2 expspace upper bounds for several satisfiability problems. We prove matching lower bounds by reduction from a reachability problem for a newly introduced class of counter systems. This new class is a succinct version of vector addition systems with states in which counters are accessed via pointers, a potentially useful feature in other contexts. We strengthen further the correspondences between data logics and counter systems by characterizing the complexity of fragments, extensions and variants of the logic. For instance, we precisely characterize {{the relationship between the}} number of attributes allowed in the logic and the number of counters needed in the counter system...|$|R
40|$|The {{parallel}} repetition theorem {{states that}} for any two-prover game with value smaller than 1, parallel <b>repetition</b> reduces the <b>value</b> {{of the game}} in an exponential rate. We give a short introduction to the problem of parallel repetition of two-prover games and some of its applications in theoretical computer science, mathematics and physics...|$|R
5000|$|His lifelong {{obsession}} with the Sierras would lead him to produce a documentary film, “Sierra Journey”. In 1941 he wrote [...] "Composition of Outdoor Painting", a comprehensive book on composition and composition forms. The book also explains landscape painting techniques, color, <b>repetition,</b> rhythm, and <b>value.</b> The seventh edition printing of the work was completed in 2005.|$|R
40|$|The barbell squat is a {{fundamental}} strength and conditioning exercise, with two principal variants; back and front. Whilst previous {{studies have examined the}} mechanical differences of the front and back squat, there is no information comparing the distributions of muscle forces between these variants. This study aimed to compare estimated forces developed by the primary skeletal muscles used in the front and back squat. Twenty-five male participants were recruited with 6. 24 ± 2. 21 years of experience in squat lifting and 1 <b>repetition</b> maximum <b>values</b> of 127. 5 ± 18. 8 and 90. 6 ± 14. 4 kg for the back and front squat lifts. Participants completed both back and front squats at 70...|$|R
40|$|The {{objective}} {{of this study was}} to evaluate the composting process waste coca leaf with the addition of three biological activators (yogurt, whey and yeast). This work was carried out Kallutaca Experimental Center, Biofertilizers module Career Agricultural Engineering at the Public University of El Alto, La Paz municipality of Laja. Posed treatments were: T 1 (+ Yogurt Coca wastes); T 2 (Coca wastes + whey); T 3 (Coca wastes + yeast) and T 4 (Control). The design was completely randomized with 4 treatments and 3 <b>repetitions.</b> The <b>values</b> in N are classified medium and high levels the quantities of P, K are classified as middle levels. The value obtained 7. 9 pH, EC 12950 µS/cm and 61...|$|R
30|$|For {{counts of}} 0 and 20 values of 0.025 and 0.975 {{were used for}} the {{proportions}} in Eq.  1 to allow the calculation {{of the value of the}} inverse cumulative normal function (Tsukida & Gupta, 2011). Finally, since the resulting values depend on the number of <b>repetitions,</b> the scale <b>values</b> were normalized to the range of 0 (lowest possible value) to 1 (highest possible value), to allow the magnitude values to be directly interpreted.|$|R
40|$|The {{systematic}} {{improvement of}} processes is practically realised {{in the industry}} and economy by operating a Process Management (PcM) System. Many authors also recommend a systematic <b>repetition</b> of <b>Value</b> Stream Mapping (VSM); but the global experiences in applying VSM do more or less indicate a single or punctual application of VSM to improve processes or value streams. The findings discussed in this paper describe the systematic embedding of Value Stream Mapping into {{the life cycle of}} a Process Management System using the principles of "innovation and continuous improvement". Thus the Process Management System enables a systematic, regularly repeating application of VSM by extending its 4 -step-procedure. One suitable way to standardise the application of VSM is specified in this paper on a theoretical base to make this approach international applicable...|$|R
40|$|We propose an {{analytical}} framework for studying parallel repetition, a basic product operation for one-round two-player games. In this framework, we consider a relaxation {{of the value}} of projection games. We show that this relaxation is multiplicative with respect to parallel repetition and that it provides a good approximation to the game value. Based on this relaxation, we prove the following improved parallel repetition bound: For every projection game G with value at most ρ, the k-fold parallel <b>repetition</b> G⊗k has <b>value</b> at most val(G⊗k) 6...|$|R
30|$|A {{range of}} values of the network {{parameters}} (including the number of hidden neurons, the network learning algorithm and the activation functions of different layers for MLPs, and the smoothing parameter for PNNs and GRNNs) is considered in learning multiple ANNs. Different combinations of the network parameters are used in an iterative manner through the GS technique for building the ANN models. Each network is trained using tenfold CV technique for an improved estimation of the generalization error of the network. To eliminate bias of error estimation, CVs are repeated multiple times and the estimated generalization errors are averaged over the <b>repetitions.</b> MSE <b>values</b> are considered as the performance criteria of MLPs and GRNNs, while the misclassification rate is {{used to measure the}} performance of PNN classifiers. Normalized pressure derivative data points are considered as inputs to the networks, while the well-testing variables according to the equations provided in Table  2 are used as the targets.|$|R
40|$|The region {{containing}} ROBO 1 (Chromosome 3 p 12. 3) {{has been}} implicated as a susceptibility gene for reading disorder and language deficit by translocation and linkage data. No association studies have yet been reported supporting any candidate gene. Here we report the first association of this gene with language deficits, specifically with phonological buffer deficits (a phenotype implicated in language acquisition, Specific Language Impairment and Speech Sound Disorder) and dyslexia (reading and spelling ability traits) in an unselected sample of adolescent twins and their siblings. Family-based {{analyses were performed}} on 144 tag SNPs in ROBO 1, typed in 538 families with up to five offspring and tested for association with a developmental marker of language impairment (phonological buffer capacity, assessed using non word repetition). A reading and spelling ability measure-based on validated measures of lexical processing (irregular word) and grapheme-phoneme decoding (pseudo word) -and measures of short-term and working memory were also analysed. Significant association for phonological buffer capacity was observed for 21 of 144 SNPs tested, peaking at 8. 70 x 10 (- 05) and 9. 30 x 10 (- 05) for SNPs rs 6803202 and rs 4535189 respectively for nonword <b>repetition,</b> <b>values</b> that survive correction for multiple testing. Twenty-two SNPs showed significant associations for verbal storage (forward digit span) -a trait linked to phonological span. By contrast, just 5 SNPs reached nominal significance for working-memory, not surviving correction, and, importantly, only one SNP in the 144 tested reached nominal significance (0. 04) for association with reading and spelling ability. These results provide strong support for ROBO 1 as a gene involved in a core trait underpinning language acquisition, with a specific function in supporting a short-term buffer for arbitrary phonological strings. These effects of ROBO 1 appear to be unrelated to brain mechanisms underpinning reading ability, at least by adolescence. While replication will be critical, the present results strongly support ROBO 1 as the first gene discovered {{to be associated with}} language deficits affecting normal variation in language ability. Its functional role in neuronal migration underlying bilateral symmetry and lateralization of neuronal function further suggests a role in the evolution of human language ability...|$|R
50|$|It is an {{extension}} of Napier's Bones, using two sets of rods to achieve multi-digit multiplication. The rods for the multiplicand are similar to Napier's Bones, with <b>repetitions</b> of the <b>values.</b> The set of rods for the multiplier are shutters or masks for each digit placed over the multiplicand rods. The results are then tallied from the digits showing as with other lattice multiplication methods. The final form described by Napier took advantage of symmetries to compact the rods, and used the materials of the day to hold system of metal plates, placed inside a wooden frame.|$|R
40|$|AIM: To {{study the}} {{techniques}} of MR diffusion-weighed imaging (DWI) for normal rabbit liver. METHODS: After 15 normal New Zealand white rabbits and one New Zealand white rabbit implanted with VX- 2 tumor were anesthetized with 3 % soluble pentobarbitone, DWI was performed respectively for different b <b>values,</b> <b>repetition</b> times (TR) or thicknesses, when other parameters were the same and magnetic resonance imaging (MRI) was performed respectively, or with different field of views (FOV) or coil when other parameters were the same. The distinction between groups was analyzed by SPSS 10. 0 with apparent diffusion coefficient (ADC), quality index (QI) or signal-noise ratio (SNR). RESULTS: As b value increased, liver ADC, QI and SN...|$|R
40|$|The thermal and {{mechanical}} characteristics which will ultimately limit {{the performance of}} Nd:BeL at high average power levels were investigated. The output beam characteristics (pulse width, peak power, beam dimensions and collimation) were determined at high repetition rates for both Nd:BeL and Nd:YAG. The output of Nd:BeL was shown to exceed that of Nd:YAG {{by a factor of}} 2. 7 at low Q-switched repetition rates (1 Hz). This result follows from the smaller stimulated emission cross section of x-axis Nb:BeL compared to that of NdYAG by the same factor. At high repetition rates (10 Hz) the output of Nd:Bel falls to a level of three-fifths of its low <b>repetition</b> rate <b>value</b> while under similar tests the output of Nd:YAG remains essentially constant. A comparison of the measured values of the elasto-optic coefficients, the dn/dT values and the linear expansion coefficients for BeL and YAG failed to provide an explanation for the performance of BeL; however, thermal lensing was observed in Nd:BeL. Results imply that the output of a high repetition rate Q-switched Nd:BeL laser (high thermal loading) could be dramatically increased by utilization of a resonator design to compensate for the thermal lensing effects...|$|R
2500|$|The {{banknotes}} {{feature a}} large clear window through which passes a stripe of holographic metallic foil that changes colour based on angle. The holographic foil contains {{an image of}} one of the Parliament buildings at its base and a coloured duplicate of the portrait appearing on the banknote at the top. Both portions of the metallic foil contain the words [...] "BANK OF CANADA", [...] "BANQUE DU CANADA", and several <b>repetitions</b> of the <b>value</b> of the denomination appearing in different colours depending on the viewing angle. The metallic foil portrait {{is the same as the}} larger portrait on the banknote, but shifts colour when the banknote is tilted. The holographic foil is manufactured using a mix of aluminum, polyethylene terephthalate (PET), and adhesives.|$|R
30|$|Means and {{standard}} deviations were calculated for each category for Fran (IM 250 [*]±[*] 106  s; IF 331 [*]±[*] 181  s; MM 311 [*]±[*] 138  s; MF 368 [*]±[*] 138  s; TM 316 [*]±[*] 136  s; and TF 334 [*]±[*] 120  s), Grace (IM 180 [*]±[*] 90  s; IF 213 [*]±[*] 96  s; MM 213 [*]±[*] 93  s; MF 238 [*]±[*] 100  s; TM 228 [*]±[*] 63  s; and TF 223 [*]±[*] 69  s), Helen (IM 9.5 [*]±[*] 1.9  min; IF 11.1 [*]±[*] 2.4  min; MM 10.2 [*]±[*] 2.0  min; MF 11.5 [*]±[*] 2.3  min; TM 9.4 [*]±[*] 1.6  min; and TF 12.7 [*]±[*] 1.9  min), F 50 (IM 24.4 [*]±[*] 5.9  min; IF 27.3 [*]±[*] 6.9  min; MM 26.7 [*]±[*] 6.1  min; MF 28.2 [*]±[*] 6.0  min; TM 25.9 [*]±[*] 7.9  min; and TF 28.3 [*]±[*] 8.1  min), and FGB (IM 335 [*]±[*] 65 repetitions; IF 292 [*]±[*] 62 repetitions; MM 311 [*]±[*] 59 repetitions; MF 280 [*]±[*] 54 repetitions; TM 279 [*]±[*] 44 repetitions; and TF 238 [*]±[*] 35 <b>repetitions).</b> These <b>values</b> were then used to calculate normative percentile (in deciles) values for each category within each workout. Separate, one-way analyses of variance revealed significant (p[*]<[*] 0.05) differences between categories for each workout.|$|R
5000|$|Heath’s theorem {{effectively}} says we {{can pull}} out the values of Y from the big relation R and store them into one, , which has no <b>value</b> <b>repetitions</b> in the row for X and is effectively a lookup table for Y keyed by X and consequently has only one place to update the Y corresponding to each X unlike the [...] "big" [...] relation R where there are potentially many copies of each X, each one with its copy of Y which need to be kept synchronized on updates. (This elimination of redundancy is an advantage in OLTP contexts, where many changes are expected, {{but not so much}} in OLAP contexts, which involve mostly queries.) Heath’s decomposition leaves only X to act as a foreign key in the remainder of the big table [...]|$|R
40|$|We propose an {{analytical}} framework for studying parallel repetition, a basic product operation for one-round two-player games. In this framework, we consider a relaxation {{of the value}} of a game, val+, and prove that for projection games, it is both multiplicative (under parallel repetition) and a good approximation for the true value. These two properties imply a parallel repetition bound as val(G ⊗k) ≈ val+(G ⊗k) = val+(G) k ≈ val(G) k. Using this framework, we can also give a short proof for the NP-hardness of label cover(1, δ) for all δ> 0, starting from the basic PCP theorem. We prove the following new results: – A parallel repetition bound for projection games with low soundness. Previously, it was not known whether parallel <b>repetition</b> decreases the <b>value</b> of such games. This result implies stronger inapproximability bounds for set cover and label cover...|$|R
40|$|The term spacing effect {{refers to}} the {{empirical}} fact that items which are repeated with few other items intervening between the repetitions are remembered worse than items which are repeated with relatively more interventions between the repetitions. The purpose of the set of spacing experiments reported here is to infer a cause of the spacing effect in a judgment of frequency paradigm by trying to discover conditions which will remove it. [...] Following Experiment 1, which compared continuous judgments of frequency of words made on the learning trial with terminal judgments of frequency made {{at the conclusion of}} the learning trial, it was inferred that the spacing effect arose from one or more of three possible origins: (1) a true memory deficit for massed repetitions together with a biassed tendency to overestimate the frequency of words repeated at non-zero spacings; (2) the use of different strategies on continuous and terminal judgments; (3) the deficient processing of <b>repetitions</b> at low <b>values</b> of spacing relative to <b>repetitions</b> at higher <b>values.</b> [...] Experiments 2 and 3 found evidence which was irreconcilable with the first two of these three possible origins of the spacing effect. Experiments 4 and 5 were then carried out to test the relevance of the third possibility. Specifically, the levels of processing hypothesis was contrasted with the variable contextual encoding hypothesis. The former claims that the spacing effect arises because repetitions at long spacings receive deep, reconstructive processing while those at short spacings receive shallow scanning processing. The contextual encoding hypothesis, which enjoys some support elsewhere, attributes the spacing effect to the greater variability among the contents of the repetitions which occur at long spacings. The evidence from Experiments 4 and 5 generally supported the levels of processing hypothesis but in addition indicated that the encoding context is a factor which interacts with the measure of retention. Also the nature of the posited scanning and reconstructive processes still remains a mystery...|$|R
40|$|Thesis (Ph. D.) [...] Memorial University of Newfoundland, 1978. PsychologyBibliography : leaves 129 - 137 The term "spacing effect" {{refers to}} the {{empirical}} fact that items which are repeated with few other items intervening between the repetitions are remembered worse than items which are repeated with relatively more interventions between the repetitions. The purpose of the set of spacing experiments reported here is to infer a cause of the spacing effect in a judgment of frequency paradigm by trying to discover conditions which will remove it. [...] Following Experiment 1, which compared continuous judgments of frequency of words made on the learning trial with terminal judgments of frequency made {{at the conclusion of}} the learning trial, it was inferred that the spacing effect arose from one or more of three possible origins: (1) a true memory deficit for massed repetitions together with a biassed tendency to overestimate the frequency of words repeated at non-zero spacings; (2) the use of different strategies on continuous and terminal judgments; (3) the deficient processing of <b>repetitions</b> at low <b>values</b> of spacing relative to <b>repetitions</b> at higher <b>values.</b> [...] Experiments 2 and 3 found evidence which was irreconcilable with the first two of these three possible origins of the spacing effect. Experiments 4 and 5 were then carried out to test the relevance of the third possibility. Specifically, the levels of processing hypothesis was contrasted with the variable contextual encoding hypothesis. The former claims that the spacing effect arises because repetitions at long spacings receive deep, reconstructive processing while those at short spacings receive shallow scanning processing. The contextual encoding hypothesis, which enjoys some support elsewhere, attributes the spacing effect to the greater variability among the contents of the repetitions which occur at long spacings. The evidence from Experiments 4 and 5 generally supported the levels of processing hypothesis but in addition indicated that the encoding context is a factor which interacts with the measure of retention. Also the nature of the posited scanning and reconstructive processes still remains a mystery...|$|R
40|$|A {{number of}} recent {{publications}} have described various value prediction techniques for exploiting value locality in the data-flow portion of a processor to improve program performance. An examination of the value usage characteristics of programs is appropriate and relevant because it is within the value space that value prediction mechanisms operate. In this paper, we perform an extensive experimental study on value usage patterns of the SPECint 95 benchmark programs, and find that they make very sparse and uneven use of the available value space. Furthermore, we suggest a metric for characterizing the value locality of programs and their data sets. This metric, the <b>Value</b> <b>Repetition</b> (VR) factor, represents the redundant redefinitions performed by a program {{and can be used}} to formulate a new theoretical upper bound on the speedup possible with per-instruction history-based value prediction techniques. 1. Introduction In recent years, designers of modern microprocessors have relied inc [...] ...|$|R
40|$|AbstractWe examine {{numerical}} rounding {{errors of}} some deterministic solvers for systems of ordinary differential equations (ODEs) from a probabilistic viewpoint. We {{show that the}} accumulation of rounding errors results in a solution which is inherently random and we obtain the theoretical distribution of the trajectory {{as a function of}} time, the step size and the numerical precision of the computer. We consider, in particular, systems which amplify the effect of the rounding errors so that over long time periods the solutions exhibit divergent behaviour. By performing multiple <b>repetitions</b> with different <b>values</b> of the time step size, we observe numerically the random distributions predicted theoretically. We mainly focus on the explicit Euler and fourth order Runge–Kutta methods but also briefly consider more complex algorithms such as the implicit solvers VODE and RADAU 5 in order to demonstrate that the observed effects are not specific to a particular method...|$|R
40|$|This {{document}} {{is available to}} the public through the National Technical Information Service, Springfield, VA 22161 This {{document is}} disseminated under the sponsorship of the Department of Transportation in the interest of information exchange. The United Returns from the ground and associated obstacles surrounding a NEXRAD weather radar (i. e., ground clutter) will contaminate the estimates of weather echo spectral features (e. g., reflectivity, mean velocity and spectral width). The ground clutter returns are particularly large at low elevation angles and close range (e. g., within 40 km). Additionally, the pulse <b>repetition</b> frequency (PRF) <b>values</b> necessary to obtain the desired weather Doppler features result in ground clutter contamination at ranges which are multiples of the unambiguous range interval (e. g., 115 - 175 km for a typical NEXRAD). Fortunately, the ground clutter power spectrum is localized around zero velocity so that one can reduce its effect by appropriat...|$|R
40|$|Laser-induced {{breakdown}} spectroscopy {{was used}} to analyze unburned carbon in fly ash. The samples were gotten using fast ashing method and excited by pulse laser and plasma was formed at atmospheric pressure. The emitted signal which contains the information of unburned carbon in fly ash was detected. The calibration curve constructed base on six samples of one kind of coal ash, and two samples of other two kinds of coal ash were analyzed. The experimental results show that calibration curve constructed with the data from same kind of coal ash {{can be used to}} analyze the different kinds of fly ash using proper data processing method. The relative standard deviation of <b>repetition</b> of measured <b>values</b> are less than 8. 08 %, the relative errors are less than 2. 27 %. It is indicated that laser-induced breakdown spectroscopy is suitable for rapidly detect unburned carbon in fly ash with receptible applicability. Peer reviewe...|$|R
