3|8|Public
50|$|On June 17, 1991, the Pioneer began {{splitting}} {{from the}} California Zephyr in Denver, Colorado and proceeding over the Union Pacifics Overland Route in Wyoming, which {{had last seen}} service in 1983. A bus at Ogden provided a connection to Salt Lake City. Two considerations prompted this change. The combined California Zephyr/Desert Wind/Pioneer consisted of 16 Superliner cars, the longest such train Amtrak had ever operated. It required no fewer than four EMD F40PH diesel locomotives to haul the combined train through the Rocky Mountains between Denver and Salt Lake City. Having the Pioneer separate earlier reduced the load. Further, the faster running time over the Overland Route allowed a more <b>reasonable</b> <b>departure</b> time from Seattle. The Pioneer began running thrice-weekly west of Denver on November 4, 1993.|$|E
40|$|In this work, we {{consider}} {{a network of}} cosmic strings to explain possible deviation from Λ CDM behaviour. We use different observational data to constrain the model and show that a small but non zero contribution from the string network is allowed by the observational data which {{can result in a}} <b>reasonable</b> <b>departure</b> from Λ CDM evolution. But by calculating the Bayesian Evidence, we show that the present data still strongly favour the concordance Λ CDM model irrespective of the choice of the prior. Comment: 15 Pages, Latex Style, 4 eps figures, Revised Version, Accepted for publication in European Physical Journal...|$|E
40|$|Bus lane with {{intermittent}} priority (BLIP) is {{an innovative}} method {{to improve the}} reliability of bus services while promoting efficient usage of road resources. Vehicle-to-vehicle (V 2 V) communication is an advanced technology that can greatly enhance the vehicle mobility, improve traffic safety, and alleviate traffic jams. To explore the benefits of BLIP operation under a connected environment, this study proposed a three-lane cellular automata (CA) model under opening boundary condition. In particular, a mandatory BLIP lane-changing rule is developed to analyze special asymmetric lane-changing behaviors. To improve the simulation accuracy, a smaller cell size {{is used in the}} CA model. Through massive numerical simulations, the benefits and influences of BLIP are explored in this paper. They include impacts on neighborhood lanes such as traffic density increasing and average speed decreasing, lane-changing behaviors, lane usage, and the impacts of bus departure interval and clear distance on the road capacity of BLIP. Analysis of traffic flow characteristics of BLIP reveals that there is a strong relationship among bus departure interval, clear distance, and road capacity. Furthermore, setting conditions for deployment of BLIP under the V 2 V environment such as <b>reasonable</b> <b>departure</b> interval, clear distance, and traffic density are obtained...|$|E
40|$|In the {{standard}} cosmological {{framework of the}} 0 th-order FLRW metric {{and the use of}} perfect fluids in the stress-energy tensor, dark energy with an equation-of-state parameter w - 1) do not necessarily have positive kinetic energy categorically. Staying within the confines of observational constraints and general relativity, for which there is good experimental validation, we consider a few <b>reasonable</b> <b>departures</b> from {{the standard}} 0 th-order framework in an attempt to see if negative kinetic energy can be avoided in these settings despite an apparent w- 1 can have negative kinetic energy with perturbations and included a plot showing thi...|$|R
40|$|A {{fundamental}} identification {{problem in}} program evaluation arises when idiosyncratic gains from participation {{and the treatment}} decision depend on each other. Imbens and Angrist (1994) {{were the first to}} exploit a monotonicity condition in order to identify a local aver-age treatment eect parameter using instrumental variables. More recently, Heckman and Vytlacil (1999) suggested estimation of a variety of treatment eect parameters using a local version of their approach. However, identification hinges on the same monotonicity assumption that is fundamentally untestable. We investigate the sensitivity of respective estimates to <b>reasonable</b> <b>departures</b> from monotonicity that are likely to be encountered in practice. Approximations to respective bias terms are derived. In an empirical application the bias is calculated and bias corrected estimates are obtained. The accuracy of the ap-proximation is investigated in a Monte Carlo study. JEL Classification: C 21...|$|R
40|$|Truncation {{selection}} {{is known to}} be the most efficient form of directional selection. When this is modified so that the fitness increases linearly over a range of one or two standard deviations {{of the value of the}} selected character, the efficiency is reduced, but not greatly. When truncation {{selection is}} compared to a system in which fitness is strictly proportional to the character value, the relative efficiency of truncation selection is given by f(c) /σ, in which f(c) is the ordinate of the frequency distribution at the truncation point and σ is the standard deviation of the character. It is shown, for mutations affecting viability in Drosophila, that truncation selection or <b>reasonable</b> <b>departures</b> therefrom can reduce the mutation load greatly. This may be one way to reconcile the very high mutation rate of such genes with a small mutation load. The truncation model with directional selection is appropriate for this situation because of the approximate additivity of these mutations. On the other hand, it is doubtful that this simple model can be applied to all genes affecting fitness, for which there are intermediate optima and antagonistic selection among components with negative correlations. Whether nature ranks and truncates, or approximates this behavior, is an empirical question, yet to be answered...|$|R
40|$|Statisticians {{routinely}} plot ordered observations against expected {{values to}} validate a model using a random sample. In fact, {{it is possible}} to construct a probability plot for a random sample from any continuous distribution function, and this is accommodated by the probability integral transform which facilitates a uniform probability plot of the ordered transformed observations against their expected values. Random variation in the plots is sometimes assessed using point-wise concentration bands. There are two problems with these plots. First, tinder a given distribution, certain points are much more variable than others. For example, when the distribution is normal, the points nearest the middle of the plot have the smallest variance. Second, the order statistics used {{in the construction of the}} plots are correlated. Both problems make the interpretation of the plot difficult. Pointwise concentration bands are, however, inadequate because there will be departures from the expected 45 ° straight line not only from sampling variation but also from the correlation introduced by ordering the observations. To account for this correlation, we construct simultaneous concentration bands which have exact coverage probability. A comparison is made with the pointwise and Bonferroni concentration bands. An empirical study shows that, it is beneficial to construct our exact simultaneous concentration bands, and <b>reasonable</b> <b>departures</b> from the underlying distribution assumption can be detected...|$|R
40|$|Abstract Background There is {{currently}} {{much interest in}} pharmacogenetics: determining variation in genes that regulate drug effects, with a particular emphasis on improving drug safety and efficacy. The ability to determine such variation motivates the application of personalized drug therapies that utilize a patient's genetic makeup to determine a safe and effective drug at the correct dose. To ascertain whether a genotype-guided drug therapy improves patient care, a personalized medicine intervention may be evaluated {{within the framework of}} a randomized controlled trial. The statistical design of this type of personalized medicine intervention requires special considerations: the distribution of relevant allelic variants in the study population; and whether the pharmacogenetic intervention is equally effective across subpopulations defined by allelic variants. Methods The statistical design of the Clarification of Optimal Anticoagulation through Genetics (COAG) trial serves as an illustrative example of a personalized medicine intervention that uses each subject's genotype information. The COAG trial is a multicenter, double blind, randomized clinical trial that will compare two approaches to initiation of warfarin therapy: genotype-guided dosing, the initiation of warfarin therapy based on algorithms using clinical information and genotypes for polymorphisms in CYP 2 C 9 and VKORC 1; and clinical-guided dosing, the initiation of warfarin therapy based on algorithms using only clinical information. Results We determine an absolute minimum detectable difference of 5. 49 % based on an assumed 60 % population prevalence of zero or multiple genetic variants in either CYP 2 C 9 or VKORC 1 and an assumed 15 % relative effectiveness of genotype-guided warfarin initiation for those with zero or multiple genetic variants. Thus we calculate a sample size of 1238 to achieve a power level of 80 % for the primary outcome. We show that <b>reasonable</b> <b>departures</b> from these assumptions may decrease statistical power to 65 %. Conclusions In a personalized medicine intervention, the minimum detectable difference used in sample size calculations is not a known quantity, but rather an unknown quantity that depends on the genetic makeup of the subjects enrolled. Given the possible sensitivity of sample size and power calculations to these key assumptions, we recommend that they be monitored during the conduct of a personalized medicine intervention. Trial Registration clinicaltrials. gov: NCT 00839657 </p...|$|R
40|$|Over {{the last}} decades {{individual}} field data has {{become more and more}} available to researchers. In three self-contained chapters, this thesis is concerned with the analysis of such data and some associated challenges. Chapter 1 contains an introduction. Chapter 2 is concerned with the problem of evaluating the impact of a treatment on an outcome variable, e. g. the effect of on-the-job training on wages. A fundamental identification problem arises in case the treatment decision and the idiosyncratic gains from participation depend on each other. Imbens and Angrist (1994) were the first to exploit monotonicity of the treatment decision in instruments in order to identify an average treatment effect parameter. More recently, Heckman and Vytlacil (1999, 2000 a, 2000 b, 2005) suggested estimation of a variety of treatment effect parameters using a local version of their approach. However, identification hinges on the same monotonicity assumption that is fundamentally untestable. We investigate the sensitivity of respective estimates to <b>reasonable</b> <b>departures</b> from monotonicity that are likely to be encountered in practice and relate it to properties of a structural parameter. One of our results is that the bias vanishes under a testable linearity condition. Our findings are illustrated in a Monte Carlo analysis. Thereafter, in Chapter 3, we propose and implement an estimator for identifiable features of correlated random coefficient models with binary endogenous variables and nonadditive errors in the outcome equation. The estimator we propose is suitable, e. g., for estimation of the average returns to college education if they are heterogeneous across individuals and correlated with the schooling choice. The estimated features are of central interest to economists and are directly linked to the marginal and average treatment effect in policy evaluation. They are identified under assumptions weaker than typical exclusion restrictions used in the context of classical instrumental variables analysis. In our application for the U. K., we relate levels of expected wages to unobserved ability, measured ability, family background, type of secondary school, and the decision whether to attend college. While Chapters 2 and 3 focus on recovering identifiable features of a structural equation, Chapter 4 follows a different approach. It is concerned with feedback mechanisms in electronic markets that allow partners to rate each other after a transaction. These mechanisms are considered crucial for the success of anonymous internet trading platforms. Rather than estimating a system of structural equations we document an asymmetry in the feedback behavior on eBay, propose an explanation based on the micro structure of the feedback mechanism and the time when feedbacks are given, and support this explanation by findings from a large data set. Our analysis implies that the informational content of feedback records is likely to be low. We argue that {{the reason for this is}} that agents leave feedbacks strategically. Negative feedbacks are given late, in the "last minute", or not given at all, most likely because of the fear of retaliative negative feedback. Conversely, positive feedbacks are given early in order to encourage reciprocation. Towards refining our insights into the observed pattern, we look separately at buyers and sellers, and relate the magnitude of the effects to the trading partners' experience...|$|R
40|$|Lexical {{knowledge}} is knowledge {{that can be}} expressed in words. Circular though this may seem, we think it provides a perfectly <b>reasonable</b> point of <b>departure,</b> for, in line with a long-standing philosophical tradition it posits communicability as the most characteristic aspect of lexical knowledge. Knowledge representation systems should be designed so as to fit lexical data {{rather than the other}} way round. A broad view of the possible scope of lexical semantics would thus be one which tries to chart out the systematic, generalizable aspects of word meanings, and of the relations between words, drawing on readily accessible sources of lexical knowledge, such as machine readable dictionaries, encyclopedias, and representative corpora, coupled with the kind of analytic apparatus that is needed to fruitfully explore such sources, for instance custom-built parsers to cope with dictionary definitions (Vossen 1990), statistical programs to deal with the distributional properties of lexical items in large corpora (Church & Hanks 1990) etc. At the same time this kind of massive data-acquisition should be made sensitive to the borders between perceptual experience, lexical knowledge and expert knowledge. ...|$|R
40|$|The SEC Chief Accountant has {{indicated}} that he believes the LIFO Issues Paper, including the advisory conclusions on the issues therein, represents the accounting profession's most current views on last-in, first-out (LIFO) inventory issues. The issue is what implications does the possible use of the LIFO Issues Paper by the SEC's Chief Accountant have for the accounting profession. EITF DISCUSSION No consensus was reached; the discussion was merely informational. Task Force members asked the SEC Observer to clarify what action the SEC staff plans to take regarding the LIFO Issues Paper. The SEC Observer explained that, {{because there is no}} authoritative literature on LIFO financial accounting and reporting issues, the SEC hopes that companies using LIFO will consider the issues addressed in the Issues Paper and justify their use of different principles or make appropriate changes in their accounting. He stated that ASR 293 noted the relaxation of the LIFO conformity requirement and encouraged companies to study Copyright © 1984, Financial Accounting Standards Board Not for redistribution age 1 their application of LIFO accounting for financial reporting purposes. He indicated that the Issues Paper provides an obvious opportunity to do that. Some Task Force members expressed concerns about any enforcement of the advisory conclusions in the Issues Paper because due process on an Issues Paper is limited and does not include public exposure. The SEC Observer stated that the SEC staff does not plan to require all companies on LIFO to change their application of LIFO but will probably raise the issues in situations if the staff has occasion to question LIFO application; the SEC staff would expect companies to have a <b>reasonable</b> basis for <b>departures</b> from recommendations in the Issues Paper...|$|R

