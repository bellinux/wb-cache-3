9|148|Public
40|$|We {{propose a}} simple {{unconventional}} geometric scenario {{to achieve a}} kind of nontrivial multiqubit operation with superconducting charge qubits placed in a microwave cavity. The proposed quantum operations are insensitive {{not only to the}} thermal state of the cavity mode but also to certain <b>random</b> <b>operation</b> errors, and thus may lead to high-fidelity quantum-information processing. By executing the designated quantum operations, a class of highly entangled cluster states may be generated efficiently in the present scalable solid-state system, enabling one to achieve one-way quantum computation. © 2007 The American Physical Society. link_to_subscribed_fulltex...|$|E
40|$|A {{stationary}} generalized random coefficient integer auto-regressive {{model of}} order 1 (Generalized RCINAR(1)), {{based on a}} thinning <b>random</b> <b>operation,</b> is presented. It is proved that the process satisfies a long range condition {{as well as a}} local dependence condition, which are appropriate extensions of the well known D(u_n) and D'(u_n) conditions of Leadbetter. Assuming that the marginal discrete distribution function belongs to Anderson's class, and then it does not belong to the domain of attraction of any max-stable distribution, the limit in distribution of the maximum of k_n random variables, being {k_n} a geometric growing sequence, is obtained. This limit is a discrete max-semistable distribution function usually called discretized Gumbel...|$|E
40|$|Particle swarm {{optimization}} {{comes under}} {{lot of changes}} after James Kennedy and Russell Eberhart first proposes the idea in 1995. The changes has been done mainly on Inertia parameters in velocity updating equation so that the convergence rate will be higher. We are proposing a novel approach where particles movement will not be depend on its velocity rather it will be decided by constrained biased random walk of particles. In random walk every particles movement based on two significant parameters, one is random process like toss of a coin and other is how much displacement a particle should have. In our approach we exploit this idea by performing a biased <b>random</b> <b>operation</b> {{and based on the}} outcome of that <b>random</b> <b>operation,</b> PSO particles choose the direction of the path and move non-uniformly into the solution space. This constrained, non-uniform movement helps the random walking particle to converge quicker then classical PSO. In our constrained biased random walking approach, we no longer needed velocity term (Vi), rather we introduce a new parameter (K) which is a probabilistic function. No global best particle (PGbest), local best particle (PLbest), Constriction parameter (W) are required rather we use a new term called Ptarg which is loosely influenced by PGbest. We test our algorithm on five different benchmark functions, and also compare its performance with classical PSO and Quantum Particle Swarm Optimization (QPSO). This new approach have been shown significantly better than basic PSO and sometime outperform QPSO in terms of convergence, search space, number of iterations...|$|E
50|$|The {{most common}} {{performance}} characteristics measured are sequential and <b>random</b> <b>operations.</b> Sequential operations access locations on the storage device in a contiguous manner and are generally associated with large data transfer sizes, e.g., 128 KB. <b>Random</b> <b>operations</b> access locations on the storage device in a non-contiguous manner and are generally associated with small data transfer sizes, e.g., 4 KB.|$|R
3000|$|... | and therefore, the {{replacement}} operation described above offers no advantage. In this case, we propose a <b>random</b> replacement <b>operation.</b> Note {{that since the}} proposed strategy ensures maximum rendezvous diversity, the random nature of {{the replacement}} operation do not compromise the MCTTR. The <b>random</b> replacement <b>operation</b> is described in Algorithm 4.|$|R
40|$|This paper {{examines}} {{the performance of}} RAID the First, a prototype disk array built by the RAID group at U. C. Berkeley. A hierarchy of bottlenecks was discovered in the system that limit overall performance. The most serious is the memory system contention on the Sun 4 / 280 host CPU, which limits array bandwidth to 2. 3 MBytes/sec. The array performs more successfully on small <b>random</b> <b>operations,</b> achieving nearly 300 I/Os per second before the Sun 4 / 280 becomes CPU-limited. Other bottlenecks in the system are the VME backplane, bandwidth on the disk controller, and overheads associated with the SCSI protocol. All are examined in detail. The main conclusion of this report is that to achieve the potential bandwidth of arrays, more powerful CPUs alone will not suffice. Just as important are adequate host memory bandwidth and support for high bandwidth on disk controllers. Current disk controllers are more often designed to achieve large numbers of small <b>random</b> <b>operations,</b> rather than [...] ...|$|R
40|$|This paper {{proposes a}} neural network-based method for on-line voltage {{stability}} estimation, prediction and monitoring at each power system load bus. The {{training of the}} radial basis function neural network (RBFNN) was accomplished by using load flow voltage magnitude and phase as input information, and fast indicators of voltage stability information covering the whole power system and evaluated at each individual bus as output layer information. The generalization capability of the designed networks under {{a large number of}} <b>random</b> <b>operation</b> conditions and for several power systems has been tested. Fast performance, accurate evaluation and good prediction for the voltage stability margin have been obtained. Results of tests conducted on standard IEEE 14 -bus test system are presented and discusse...|$|E
40|$|Abstract:- Rough sets {{theory is}} an {{effective}} mathematical tool dealing with vagueness and uncertainty. It has been applied {{in a variety of}} fields such as data mining, pattern recognition or process control. It is very important to compute the attribute reduction in real applications of rough set theory. To compute the optimal attribute reduction is NP-hard. Many heuristic attribute reduction algorithms with polynomial-time complexity have been proposed. However, most of them are incomplete for the definition of attribute reduction given by Z. Pawlak. and few of them are able to fully use the expert experience. In this paper, a complete attribute reduction algorithm based on the principle of discernibility matrix is given, which can make full use of the expert experience by defining a partial ordering relation on the set of condition attributes. The completeness of the algorithm is proved. The algorithm includes a <b>random</b> <b>operation</b> leading to different reductions may be obtained by repeating executing. Thus the quasi-optimal reduction can be got...|$|E
40|$|The {{problem of}} the order of the {{fluctuation}} of the Longest Common Subsequence (LCS) of two independent sequences has been open for decades. There exist contradicting conjectures on the topic, due to Chvatal - Sankoff in 1975 and Waterman in 1994. In the present article, we consider a special model of i. i. d. sequences made out of blocks. A block is a contiguous substring consisting only of one type of symbol. Our model allows only three possible block lengths, each been equiprobable picked up. In this context, we introduce a <b>random</b> <b>operation</b> (random modification) on the blocks of one of the sequences. In the present article, we develop the techniques to prove the following: if we suppose that the random modification increases the length of the LCS with high probability, then the order of the fluctuation of the LCS is as conjectured by Waterman. This result is a key technical part {{in the study of the}} size of the fluctuation of the LCS for sequences of i. i. d. blocks, developed by Matzinger and Torres. Comment: 18 page...|$|E
5000|$|Some {{commonly}} accepted averages for <b>random</b> IO <b>operations,</b> {{calculated as}} 1/(seek + latency) = IOPS: ...|$|R
40|$|We {{analyze the}} {{asymptotic}} dynamics of quantum systems resulting from {{large numbers of}} iterations of <b>random</b> unitary <b>operations.</b> Although, in general, these quantum operations cannot be diagonalized it is shown that their resulting asymptotic dynamics is described by a diagonalizable superoperator. We prove that this asymptotic dynamics {{takes place in a}} typically low dimensional attractor space which is independent of the probability distribution of the unitary operations applied. This vector space is spanned by all eigenvectors of the unitary operations involved which are associated with eigenvalues of unit modulus. Implications for possible asymptotic dynamics of iterated <b>random</b> unitary <b>operations</b> are presented and exemplified in an example involving <b>random</b> controlled-not <b>operations</b> acting on two qubits...|$|R
40|$|Abstract. Among several {{countermeasures}} {{suggested for}} thwarting differential analysis are the <b>random</b> ordering of <b>operations,</b> insertion of <b>random</b> <b>operations,</b> and <b>random</b> insertion of <b>operations.</b> This paper presents a phase-substitution technique which {{in combination with}} subsequent time-domain differential analysis is shown {{to be able to}} thwart these three countermeasures in several experiments. Unlike previous techniques for aligning traces, this approach makes use of the phase information. The proposed technique involves: fast fourier transform, phase-substitution, inverse fast fourier transform and time-based differential analysis. Results are demonstrated using electromagnetic traces acquired from a PDA device (representing a complex embedded system including cache misses, operating system events, etc). This research is important for future wireless embedded systems which will increasingly demand higher levels of security. 1 Introduction and Previous Research Security is crucial for today's portable devices especially as more mobile code applications...|$|R
40|$|Robust and Axiomatic design, a property-based {{approach}} in design, is applied and {{integrated into a}} new methodology for developing Functional Requirements (FR) or Design Parameters (DP). The reliability of the design structure and the elementary reliability of the design components are used as a functional requirement of the automotive gearbox, {{in relation to the}} service life and operation conditions, and also as a design constraint in analytical relationships. For this purpose, elementary reliability and allowable stress are defined in a specific way. The automotive gearbox, operating under varying and <b>random</b> <b>operation</b> conditions, is used as a case study. The same design structure has to operate under different operation conditions. In these circumstances, the carrying capacity as a functional requirement is related to the operation conditions and operation regime. The model presented in this paper, as well as a computer program, enable identification of this carrying capacity. This paper discusses an interdisciplinary and multi-methodological integrated approach to the presented task. Experimental data regarding the failure probability of gearbox components and the probability of operation conditions processing, the decomposition of gearbox structure, and the elementary reliability treatment as a component of design property are only some of the methods applied...|$|E
40|$|Manufacturing {{automotive}} powertrain components (engines and transmissions) is {{a complex}} task involving the integration of hundreds of components. Simulation is commonly applied {{in the design and}} implementation of such production systems. Examples of such systems are the crankshaft machining line, engine final assembly and transmission final assembly, to name a few. Invariably, different engine and transmission sub-assemblies are machined and assembled on separate systems. The completed sub-assemblies are then assembled to the engine or transmission main assembly. There are many areas within a powertrain assembly plant that show complicated behavior due to the varying nature of manufacturing processes. Not only the variation in process, but the schedules, availability of workers, and the performance of material handling equipment are only few of the factors contributing to the randomness in operation. Test areas where the final assembly is inspected for functionality present an example of such highly <b>random</b> <b>operation.</b> Simulation is a very useful tool for investigating the behavior of such complicated systems. This paper discusses the need for and uses of discrete event simulation in the design of manufacturing systems for powertrain assemblies. The benefits of such applications of simulation are illustrated by using a sample study of the final engine test and repair area. ...|$|E
40|$|Ground-based facilities, such as clinostats {{and random}} {{positioning}} machines aiming at simulating microgravity conditions, are tools to prepare space experiments and identify gravity-related signaling pathways. A prerequisite {{is that the}} facilities are operated in an appropriate manner and potentially induced non-gravitational effects, such as shearing forces, {{have to be taken}} into account. Dinoflagellates, here P. noctiluca, as fast and sensitive reporter system for shear stress and hydrodynamic gradients, were exposed on a clinostat (constant rotation around one axis, 60 rpm) or in a random positioning machine, that means rotating around two axes, whose velocity and direction were chosen at random. Deformation of the cell membrane of P. noctiluca due to shear stress results in a detectable bioluminescence emission. Our results show that the amount of mechanical stress is higher on an random positioning machine than during constant clinorotation, as revealed by the differences in photon counts. We conclude that one axis clinorotation induced negligible non-gravitational effects in the form of shear forces in contrast to <b>random</b> <b>operation</b> modes tested. For the first time, we clearly visualized the device-dependent occurrence of shear forces by means of a bioassay, which have to be considered during the definition of an appropriate simulation approach and to avoid misinterpretation of results...|$|E
5000|$|The [...] "1089 force" [...] is {{a natural}} that relies on the {{mathematical}} manipulation of three-digit numbers such {{that the answer to}} a series of seemingly <b>random</b> <b>operations</b> will always result in the number 1089. The spectator is then asked to turn to page 108 and read the 9th word. Mathematical forces of this sort, similar to the original [...] "labyrinth" [...] type tests, are no longer common as these are widely known to the audience.|$|R
40|$|The {{performance}} is examined of Redundant Arrays of Inexpensive Disks (RAID) the First, a prototype disk array. A hierarchy of bottlenecks {{was discovered in}} the system that limit overall performance. The most serious is the memory system contention on the Sun 4 / 280 host CPU, which limits array bandwidth to 2. 3 MBytes/sec. The array performs more successfully on small <b>random</b> <b>operations,</b> achieving nearly 300 I/Os per second before the Sun 4 / 280 becomes CPU limited. Other bottlenecks in the system are the VME backplane, bandwidth on the disk controller, and overheads associated with the SCSI protocol. All are examined in detail. The main conclusion is that to achieve the potential bandwidth of arrays, more powerful CPU's alone will not suffice. Just as important are adequate host memory bandwidth and support for high bandwidth on disk controllers. Current disk controllers are more often designed to achieve large numbers of small <b>random</b> <b>operations,</b> rather than high bandwidth. Operating systems also need to change to support high bandwidth from disk arrays. In particular, they should transfer data in larger blocks, and should support asynchronous I/O to improve sequential write performance...|$|R
5000|$|In early 2016 IM Flash {{announced}} that {{the first generation of}} solid-state drives would achieve 95000 IOPS throughput with 9 microsecond latency. [...] This low latency significantly increases IOPS at low queue depths for <b>random</b> <b>operations.</b> At Intel Developer Forum 2016, Intel demonstrated PCI Express (PCIe) 140GB development boards showing 2.4−3× improvement in benchmarks compared to PCIe NAND flash solid-state drives (SSDs), much lower performance than estimated a year before.On March 19, 2017, Intel announced their first product: a PCIe card available {{in the second half of}} 2017.|$|R
40|$|Randomness is an {{essential}} tool in many disciplines of modern sciences, such as cryptography, black hole physics, random matrix theory and Monte Carlo sampling. In quantum systems, <b>random</b> <b>operations</b> can be obtained via random circuits thanks to so-called q-designs, and {{play a central role}} in the fast scrambling conjecture for black holes. Here we consider a more physically motivated way of generating random evolutions by exploiting the many-body dynamics of a quantum system driven with stochastic external pulses. We combine techniques from quantum control, open quantum systems and exactly solvable models (via the Bethe-Ansatz) to generate Haar-uniform <b>random</b> <b>operations</b> in driven many-body systems. We show that any fully controllable system converges to a unitary q-design in the long-time limit. Moreover, we study the convergence time of a driven spin chain by mapping its random evolution into a semigroup with an integrable Liouvillean and finding its gap. Remarkably, we find via Bethe-Ansatz techniques that the gap is independent of q. We use mean-field techniques to argue that this property may be typical for other controllable systems, although we explicitly construct counter-examples via symmetry breaking arguments to show that this is not always the case. Our findings open up new physical methods to transform classical randomness into quantum randomness, via a combination of quantum many-body dynamics and random driving. Comment: 22 pages, 7 figures, accepted version in Phys. Rev. ...|$|R
30|$|The {{reproduced}} strings in {{the mating}} pool are mated under crossover <b>operation</b> at <b>random.</b> Crossover <b>operation</b> is performed {{with a pair}} of substrings in the mated strings for each model [14].|$|R
50|$|Coming from an {{engineering}} background, Henke is {{fascinated by the}} beauty of technical objects. Developing his own instruments and algorithms {{is an integral part}} of his creative process. His materials are computer generated sound and images, field recordings, photography and light; transformed, re-arranged and modulated by mathematical rules, real time interaction and controlled <b>random</b> <b>operations.</b> Many of his works use multiple channels of audio or are specifically conceived for unique locations and their individual properties. For the past few years, he has been exploring the artistic usage of high power lasers in his installations and performances.|$|R
50|$|One of the {{benefits}} of RAID 1E over usual RAID 1 mirrored pairs is that the performance of <b>random</b> read <b>operations</b> remains above the performance of a single drive even in a degraded array.|$|R
5000|$|Liisa McCloy-Kelley - VP and Director of Digital Production <b>Operations,</b> <b>Random</b> House, Inc.|$|R
5000|$|<b>Operation</b> <b>Random</b> Harvest {{sought to}} {{document}} criminal {{activity on the}} part of the IRS.|$|R
40|$|We study two {{problems}} in coding theory, list-decoding and local-decoding. We take a probabilistic approach to these problems, {{in contrast to}} more typical algebraic approaches. In list-decoding, we settle two open problems about the list-decodability of some well-studied ensembles of codes. First, we show that random linear codes are optimally list-decodable, and second, we show that there exist Reed-Solomon codes which are (nearly) optimally list-decodable. Our approach uses high-dimensional probability. We extend this framework to apply to a large family of codes obtained through <b>random</b> <b>operations.</b> In local-decoding, we use expander codes to construct locally-correctible linear codes with rate approaching 1. Until recently, such codes were conjectured not to exist, and before this work the only known constructions relied on algebraic, rather than probabilistic and combinatorial, methods...|$|R
50|$|Pure Storage {{released}} {{a flash memory}} product called FlashArray on August 23, 2011.Deployed in a data center, FlashArray is marketed to accelerate applications like server virtualization, desktop virtualization, database systems and cloud computing that required very high rates of <b>random</b> I/O <b>operations</b> per second.InfiniBand technology connected controllers, and Fibre Channel connected to server computers.|$|R
40|$|A {{method is}} {{proposed}} that provides advance information about unpredictable atmospheric density dispersions {{that must be}} accommodated during <b>random</b> <b>operations</b> of aeroassisted-orbital-transfer vehicles (AOTVs). The principal feature is that a test or 'scout' projectile precedes the AOTV through the same region of the atmosphere {{as that of the}} predicted transatmospheric flight trajectory. The atmospheric density structure is determined from the vehicle's aerodynamic deceleration characteristics by on-board or ground-based tracking equipment. The time lag between passage of the projectile and the AOTV can be adjusted to only that time necessary to implement required guidance, navigation, and control (GN&C) corrections. The various strategies available to control the projectile's flight characteristics are analyzed in detail. The results are correlated with aerothermodynamic heating and materials requirements to ensure the survival of the projectile and, consequently, the capability of the AOTV to navigate a variable upper atmosphere within specified limits...|$|R
40|$|Generating and characterising {{randomness}} {{is fundamentally}} important in both classical and quantum information science. Here we report the experimental demonstration of ensembles of pseudorandom optical processes comprising {{what are known}} as t-designs. We show that in practical scenarios, certain finite ensembles of two-mode transformations [...] - 1 - and 2 -designs [...] -are indistinguishable from truly <b>random</b> <b>operations</b> for 1 - and 2 -photon quantum interference, but they fail to mimic randomness for 2 - and 3 -photon cases, respectively. This provides a novel optical test of pseudo randomness. We make use of the fact that t-photon behaviour is governed by degree- 2 t polynomials in the parameters of the optical process to experimentally verify the ensembles' behaviour for complete bases of polynomials. This ensures that outputs will be uniform for arbitrary configurations, satisfying the strict definition of pseudorandomness implicit in the mathematical definition. Comment: 10 pages, 12 figures (including appendix...|$|R
50|$|Helsinki Airport has {{extensive}} cargo flight activity. There is a {{cargo area}} with cargo terminals and cargo transit {{facilities in the}} southeastern part of the airport area. ASL Airlines Belgium (formerly TNT Airways) and DHL have their own cargo terminals at the airport. At the airport {{there is a new}} cargo terminal under construction for Finnair Cargo that is the largest operator for passenger and cargo operations at the airport. Currently scheduled cargo operating airlines are AirBridgeCargo Airlines operated with Boeing 747 cargo aircraft, ASL Airlines Belgium, DHL Aviation operated by EAT Leipzig and IAG Cargo and FedEx, UPS Airlines. Turkish Airlines operates cargo services to HEL with Airbus A310 and A330 cargo aircraft (sometimes operated by ULS Airlines Cargo and MASkargo). In addition to scheduled cargo operations, many other cargo airlines such as Emirates SkyCargo, Kalitta Air and Lufthansa Cargo have <b>random</b> <b>operations</b> at Helsinki Airport.|$|R
40|$|AbstractGiven inputs x 1,…,xn, {{which are}} {{independent}} identically distributed random variables over a domain D, and an associative operation →;, the probabilistic prefix computation {{problem is to}} compute the product x 1 →; x 2 →; … →; xn and its n - 1 prefixes. Instances of this problem are finite state transductions on random inputs, the addition or subtraction of two random n-bit binary numbers, and the multiplication or division of a random n-bit binary number by a constant. The best known constant fan-in circuits for these arithmetic operations had logarithmic depth, linear size, and produce no errors. Furthermore, matching lower bounds for depth and size (up to constant factors between {{the upper and lower}} bounds) had previously been obtained for the case of constant fan-in circuits with no errors. We give arithmetic circuits for probabilistic prefix computation, which for these <b>random</b> arithmetic <b>operations</b> have constant fan-in, linear size, O(log log n) depth, but error probability less than n−α for any given α > 0. For any constant fan-in circuits computing these <b>random</b> arithmetic <b>operations</b> with error probability n−α, we prove the circuit depth must be bounded from below by Ω(log log n). Hence, we conclude our circuits have asymptotically optimal depth among circuits with error probability n−α. We also give error-free circuits for these <b>random</b> arithmetic <b>operations</b> with constant fan-in at all nodes but one, linear size, and O(log log n) expected delay for their parallel evaluation...|$|R
5000|$|Gail Ruth Rebuck, Baroness Rebuck, DBE (born 10 February 1952) is a British {{publisher}} and Chair {{of the international}} book publishing group Penguin <b>Random</b> House's British <b>operations.</b>|$|R
30|$|Mordvinova et al. (2009) {{showed that}} RAID arrays of USB flash storage drives can be {{purchased}} for less cost, compared with SSDs or HDDs, but like SD cards they usually provide a poor performance for <b>random</b> write <b>operations.</b> Therefore, USB flash storage drives are a useful option mainly for read-mostly applications like storing the content of web servers and for CPU bound applications.|$|R
40|$|Randomness is both {{a useful}} way to model natural systems and {{a useful tool for}} {{engineered}} systems, e. g. in computation, communication and control. Fully random transformations require exponential time for either classical or quantum systems, but in many case pseudorandom operations can emulate certain properties of truly random ones. Indeed in the classical realm there is by now a well-developed theory of such pseudorandom operations. However the construction of such objects turns out to be much harder in the quantum case. Here we show that random quantum circuits are a powerful source of quantum pseudorandomness. This gives the {{for the first time a}} polynomialtime construction of quantum unitary designs, which can replace fully <b>random</b> <b>operations</b> in most applications, and shows that generic quantum dynamics cannot be distinguished from truly random processes. We discuss applications of our result to quantum information science, cryptography and to understanding self-equilibration of closed quantum dynamics. Comment: 6 pages, 1 figure. Short version of [URL]...|$|R
40|$|This paper {{describes}} deterministic communication-efficient algorithms {{for performing}} random data accesses with hot spots on a coarse-grained parallel machine. The general <b>random</b> access read/write <b>operations</b> with hot spots {{can be completed}} in C¯n=p (+ lower order terms) time and is optimal and scalable provided n O(p 3 + p 2 ø=¯) (n {{is the number of}} elements distributed across p processors, ø is the start-up overhead and 1 =¯ is the data transfer rate). C is a small constant between 3 and 4 for the <b>random</b> access write <b>operation,</b> slightly higher for the <b>random</b> access read <b>operation.</b> Monotonic <b>random</b> access reads/writes can be completed with smaller constants and are optimal for smaller n as well. A companion paper [26] deals with the problem of performing dynamic permutations. 1 Introduction Let n be the number of elements distributed across p processors. In a Random Access Read (RAR), each of the n elements may need to read data from another element [23]. The data is available in a [...] ...|$|R
30|$|The {{corresponding}} channel variance can {{be defined}} as (σ_j^(R))^ 2 =E{h^(R)^ 2 }, (σ_i^(1))^ 2 =E{h_i^(1)^ 2 }, and (σ_k^(2))^ 2 =E{h^(2)^ 2 }, where E⋅ represents <b>random</b> variable expectation <b>operation.</b>|$|R
50|$|The {{calculus}} allows integration by {{parts with}} <b>random</b> variables; this <b>operation</b> {{is used in}} mathematical finance to compute the sensitivities of financial derivatives. The calculus has applications for example in stochastic filtering.|$|R
