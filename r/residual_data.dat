182|522|Public
50|$|Transform skip rotation, {{allowing}} the encoder {{to indicate a}} rotation of <b>residual</b> <b>data</b> for 4x4 transform skip blocks.|$|E
50|$|Once {{the marks}} are validated, the tablet {{as well as}} the digital pen does not contain any <b>residual</b> <b>data.</b>|$|E
50|$|Residual DPCM (RDPCM), {{allowing}} a vertical or horizontal spatial-predictive coding of <b>residual</b> <b>data</b> in transform skip and transform-quantization bypass blocks (which can be selected {{for use in}} intra blocks, inter blocks, or both).|$|E
40|$|AbstractThis paper {{presents}} nonparametric {{tests of}} independence {{that can be}} used to test the independence of p random variables, serial independence for time series, or <b>residuals</b> <b>data.</b> These tests are shown to generalize the classical portmanteau statistics. Applications to both time series and regression residuals are discussed...|$|R
30|$|The simple {{least square}} zeroth-order Tikhonov regularization {{solution}} (blue curve in Fig.  2) gives a rather similar solution as the L_ 2 norm solution for these orbits, which also involves a Huber-weighted misfit measure. We prefer, however, {{to use the}} latter since the distribution of <b>residuals</b> (<b>data</b> minus model predictions) is non-Gaussian.|$|R
40|$|This paper {{presents}} nonparametric {{tests of}} independence {{that can be}} used to test the independence of p random variables, serial independence for time series, or <b>residuals</b> <b>data.</b> These tests are shown to generalize the classical portmanteau statistics. Applications to both time series and regression residuals are discussed. independence serial independence empirical processes pseudo-observations residuals weak convergence Cramer-von Mises statistics...|$|R
50|$|PCA is {{a linear}} feature {{learning}} approach since the p singular vectors are linear {{functions of the}} data matrix. The singular vectors can be generated via a simple algorithm with p iterations. In the ith iteration, the projection of the data matrix on the (i-1)th eigenvector is subtracted, and the ith singular vector is found as the right singular vector corresponding to the largest singular of the <b>residual</b> <b>data</b> matrix.|$|E
50|$|RAM can be {{analyzed}} for prior content after power loss, because the electrical charge stored in the memory cells takes time to dissipate, an effect exploited by the cold boot attack. The length of time that data is recoverable is increased by low temperatures and higher cell voltages. Holding unpowered RAM below −60 °C helps preserve <b>residual</b> <b>data</b> by an order of magnitude, improving the chances of successful recovery. However, it can be impractical to do this during a field examination.|$|E
5000|$|For efficiency, {{the process}} of erasing a file from [...] storage usually only erases the file's [...] file-system entry while keeping {{the content of the}} file intact. This {{frequently}} allows commonly available software to recover the [...] "erased" [...] file's data. Even if the file is overwritten, residual magnetic fields may allow data recovery using specialist hardware equipment. To prevent this, shred overwrites the contents of a file multiple times, using patterns chosen to maximize destruction of the <b>residual</b> <b>data.</b>|$|E
30|$|In {{patients}} {{with an initial}} episode of resolving AKI (n =  123), we also examined the association of recurrent AKI with outcomes. Patients were stratified {{according to the presence}} or absence of recurrent AKI. Risk factors for recurrent AKI were examined using standard Cox regression and hazard ratios with 95 % confidence intervals for this analysis, and the assumption of proportional hazards was tested using Schoenfeld <b>residuals</b> (<b>data</b> not shown).|$|R
3000|$|... [...]. I {{conduct a}} least squares fitting to the <b>residual</b> uplift <b>data</b> prior to great {{earthquakes}} to constrain t [...]...|$|R
30|$|In general, the gas {{emissions}} depended on their previous day’s flux. To {{account for the}} correlation between emission flux values, the Autoregressive One, AR(1), structure was used on the <b>residuals.</b> <b>Data</b> were analyzed using Proc Glimmix of SAS [20] using a 5 % level of significance. P values were adjusted by Tukey [21]. When the Type III test of fixed effects indicated no significant (treatment)[*]×[*](time) interaction, the treatment effects were analyzed and compared to the control. When (treatment)[*]×[*](time) interaction was significant, analysis was done based on sampling days.|$|R
5000|$|The Norwegian Consumer Council did an {{investigation}} on {{the terms of}} use and privacy policies on My Friend Cayla and i-Que Intelligent Bot in 2016. They found that the privacy policies do not specifically mention how long the data will be retained after the users stop using the service or deleting the account. Specifically, My Friend Cayla's privacy policy mentions that [...] "it is not always possible to completely remove or delete all of your information from our databases without some <b>residual</b> <b>data</b> because of backups and other reasons." ...|$|E
50|$|In April 2014, SAP {{released}} ASE 16. It included {{support for}} partition locking, CIS Support for HANA, Relaxed Query Limits, Query Plan Optimization with Star Joins, Dynamic Thread Assignment, Sort and Hash Join Operator improvements, Full-Text Auditing, Auditing for Authorization Checks Inside Stored Procedures, create or replace functionality, Query Plan and Execution Statistics in HTML, Index Compression, Full Database Encryption, Locking, Run-time locking, Metadata and Latch enhancements, Multiple Trigger support, <b>Residual</b> <b>Data</b> Removal, Configuration History Tracking, CRC checks for dump database {{and the ability}} to calculate the transaction log growth rate for a specified time period.|$|E
5000|$|According to the DTS-HD White Paper, DTS-HD Master Audio {{contains}} 2 data streams: {{the original}} DTS core stream and the additional [...] "residual" [...] stream which contains the [...] "difference" [...] between the original signal and the lossy compression DTS core stream. The audio signal is {{split into two}} paths at the input to the encoder. One path goes to the core encoder for backwards compatibility and is then decoded. The other path compares the original audio to the decoded core signal and generates residuals, which are data over and above what the core contains {{that is needed to}} restore the original audio as bit-for-bit identical to the original. The <b>residual</b> <b>data</b> is then encoded by a lossless encoder and packed together with the core. The decoding process is simply the reverse.|$|E
40|$|The main {{thrust of}} our work {{in the third year}} of {{contract}} NAG 8 - 759 was the development and analysis of various data processing techniques that may be applicable to <b>residual</b> acceleration <b>data.</b> Our goal is the development of a data processing guide that low gravity principal investigators can use to assess their need for accelerometer data and then formulate an acceleration data analysis strategy. The work focused on the flight of the first International Microgravity Laboratory (IML- 1) mission. We are also developing a data base management system to handle large quantities of <b>residual</b> acceleration <b>data.</b> This type of system should be an integral tool in the detailed analysis of accelerometer data. The system will manage a large graphics data base in the support of supervised and unsupervised pattern recognition. The goal of the pattern recognition phase is to identify specific classes of accelerations so that these classes can be easily recognized in any data base. The data base management system is being tested on the Spacelab 3 (SL 3) <b>residual</b> acceleration <b>data...</b>|$|R
30|$|We {{conclude}} that models B, F and G have smaller <b>data</b> <b>residuals</b> than models A, D, C and E. The case of model A is special as smaller <b>data</b> <b>residuals</b> are obtained by correcting data {{with the associated}} secular variation. (However, an independent spectral analysis showed that the dipole terms of both the main field and secular variation were anomalous; see Finlay et al., 2010).|$|R
40|$|To date, most Spacelab <b>residual</b> {{acceleration}} <b>data</b> collection {{projects have}} resulted in data bases that are overwhelming to the investigator of low-gravity experiments. This paper introduces a simple passive accelerometer system to measure low-frequency accelerations. Model responses for experiments using actual acceleration data are produced and correlations are made between experiment response and the accelerometer time history {{in order to test}} the idea that recorded acceleration data and experimental responses can be usefully correlated. Spacelab 3 accelerometer data are used as input to a variety of experiment models, and sensitivity limits are obtained for particular experiment classes. The modeling results are being used to create experiment-specific <b>residual</b> acceleration <b>data</b> processing schemes for interested investigators...|$|R
5000|$|Photo CD images use three {{forms of}} {{compression}} {{in order to}} reduce image storage requirements. Firstly, chroma subsampling reduces the size of the images by approximately 50%. This subsampling is by a factor of 4 for 4Base images, and a factor of 2 for all other resolutions. Secondly an additional reduction in size is achieved by decomposing the highest-resolution image data, and storing the 4Base, 16Base and 64Base components as residuals (differences from pixels at the previous level of resolution). Thirdly and finally, the Photo CD system employs a form of quantization and Huffman coding to further compress this <b>residual</b> <b>data.</b> This Huffman encoding is performed on an image-row-by-image-row basis. The Huffman tables are encoded into the Photo CD image itself, and have different lengths depending on the compression class. These classes are: ...|$|E
40|$|The paper {{presents}} {{an analysis on}} temporal <b>residual</b> <b>data</b> sub-sampling in the layered depth video format (LDV). First, the LDV format with main view and residual views or data is introduced. Then, the extraction of <b>residual</b> <b>data</b> is presented and its block wise alignment for better coding efficiency. Next, the temporal <b>residual</b> <b>data</b> sub-sampling is shown together with an advanced merging method prior to sub-sampling for preserving the necessary information for good view synthesis results. These synthesis results are shown for intermediate views, generated from the uncoded, as well as coded LDV data with different temporal sub-sampling factors and merging methods for the <b>residual</b> <b>data.</b> The results show, that temporal <b>residual</b> <b>data</b> sub-sampling with data merging can outperform regular LDV without sub-sampling for the coded and uncoded versions...|$|E
3000|$|... [...]. Finally, {{the partial}} state data is {{computed}} as X_Λ,: = F_:,Λ^†M^E and <b>residual</b> <b>data</b> is updated as Y [...]...|$|E
40|$|Various {{aspects of}} <b>residual</b> {{acceleration}} <b>data</b> {{are of interest}} to low-gravity experimenters. Maximum and mean values and various other statistics {{can be obtained from}} data as collected in the time domain. Additional information may be obtained through manipulation of the data. Fourier analysis is discussed as a means of obtaining information about dominant frequency components of a given data window. Transformation of data into different coordinate axes is useful in the analysis of experiments with different orientations and can be achieved by the use of a transformation matrix. Application of such analysis techniques to <b>residual</b> acceleration <b>data</b> provides additional information than what is provided in a time history and increases the effectiveness of post-flight analysis of low-gravity experiments...|$|R
30|$|The {{two-dimensional}} {{residual strain}} distribution beneath the finished surface of hinoki (Chamaecyparis obtusa) in slow-speed orthogonal cutting was analyzed using the DIC method, {{to evaluate the}} subsurface damage. The relation between the subsurface damage and the cutting condition was discussed {{from the viewpoint of}} the <b>residual</b> strain <b>data.</b>|$|R
50|$|A plotter {{designed}} to analyze geophysical data. Data can be {{displayed on a}} 2D axis {{as a function of}} time, frequency, position or tx-rx separation. Measured data can be compared with simulated and inverted data by displaying multiple plots on the same axis or calculating a <b>residual</b> plot. <b>Data</b> can be converted to different properties such as apparent resistivity.|$|R
40|$|There {{have been}} a number of studies {{conducted}} in relation to data remaining on disks purchased on the second hand market. A large number of these studies have indicated that a proportion of these disks contain a degree of <b>residual</b> <b>data</b> placed on the drive by the original owners. The Security Research Centre at BT has sponsored a <b>residual</b> <b>data</b> study over the last five years examining disks sourced around the globe, in the UK, USA, German...|$|E
40|$|As {{the world}} becomes {{increasingly}} dependent on technology, researchers endeavor {{to understand how}} technology is used, the impact it has on everyday life and the life-cycle and span of digital information. In doing so, researchers are increasingly gathering `real-world' or `in the wild' <b>residual</b> <b>data,</b> obtained {{from a variety of}} sources without the explicit consent of the original owners. This data gathering raises significant concerns regarding privacy, ethics and legislation, as well as practical considerations concerning investigator training, data storage, overall security and disposal. This paper surveys recent studies of <b>residual</b> <b>data</b> gathered in the wild and analyses the challenges that were faced. Taking these insights, the paper presents a compendium of practices for addressing the issues that arise in in the wild <b>residual</b> <b>data</b> research. The practices presented in this paper can be used to critique current projects and assess the feasibility of proposed future research...|$|E
30|$|The best MME point {{position}} {{obtained by}} SAD comparator is further employed {{to produce the}} best matched reference block data and <b>residual</b> <b>data</b> which are important to other video encoding functions, such as mathematical transforms and motion compensation, and so forth.|$|E
40|$|The {{comparison}} of different (linear) models, representing different geodetic/geophisic hypothesis, {{on the light}} of observational data leads to a testing procedure based on <b>residuals</b> between <b>data</b> and manifolds in general different positions. This topic has already been mentioned in statistical literature as {{comparison of}} non-nested linear models. The problem is here defined and completely solved by a Bayesian approach...|$|R
40|$|This paper {{presents}} {{nonparametric test}} of independence {{that can be}} use to test the independence of p random vectors, serial independence for time series or <b>residuals</b> <b>data.</b> These tests are shown to generalize the classical portmanteau statistics. Applications to both time series and regression residuals are discussed. AMS 1990 subject classifications: Primary 62 G 10, 60 F 05, Secondary 62 E 20. Key words and phrases: independence, serial independence, empirical processes, pseudo-observations, residuals, weak convergence, Cram'er-von Mises statistics. 2 Proposed running head: Nonparametric test of independence Galley proofs should be sent to: Kilani Ghoudi D'epartement de math'ematiques et d'informatique Universit'e du Qu'ebec `a Trois-Rivi`eres Case postale 500 Trois-Rivi`eres (Qu'ebec) Canada G 9 A 5 H 7 tel: 1 (819) 376 5170 ex. 3814 fax: 1 (819) 376 5185 e-mail: ghoudi@uqtr. uquebec. ca The final manuscript will be submitted electronically in LaTeX format. 3 1. Introduction Testing f [...] ...|$|R
40|$|We {{consider}} {{the problem of}} measuring the eigenvalues of a ran-domly drawn sample of points. We show that these values can be reliably estimated as can {{the sum of the}} tail of eigenvalues. Fur-thermore, the <b>residuals</b> when <b>data</b> is projected into a subspace is shown to be reliably estimated on a random sample. Experiments are presented that confirm the theoretical results. ...|$|R
3000|$|... where TM_R and ITM {{denote the}} tone mapping for <b>residual</b> <b>data</b> and inverse tone mapping for textures, respectively. LBD_MC {{stands for the}} low bit-depth pixel {{intensity}} after performing motion compensation using the MV derived in the high bit-depth layer MB.|$|E
40|$|We mathematically {{analyze and}} {{experimentally}} investigate {{the characteristics of}} subcarrier-modulated (SCM) light. Our investigation shows that the baseband data are also carried on the optical carrier after subcarrier modulation. This <b>residual</b> <b>data</b> introduce crosstalk when the optical carrier is separated from subcarriers and reused for uplink data modulation. The influence of the <b>residual</b> <b>data</b> carried on the optical carrier is studied in three kinds of upstream transmissions based on wavelength-seeded reflective semiconductor optical amplifiers (RSOAs) for carrier-reuse wavelength-division-multiplexed-passive optical networks (WDM-PONs). Results show that the crosstalk can be significantly suppressed with proper selection of the seeding power and operation conditions of downlink Mach-Zehnder modulator (MZM), including driving voltage and bias voltage. Department of Electronic and Information Engineerin...|$|E
40|$|Economical archival and {{retrieval}} of image data {{is becoming increasingly}} important considering the unprecedented data volumes expected from the Earth Observing System (EOS) instruments. For cost effective browsing the image data (possibly from remote site), and retrieving the original image data from the data archive, we suggest an integrated image browse and data archive system employing incremental transmission. We produce our browse image data with the JPEG/DCT lossy compression approach. Image <b>residual</b> <b>data</b> is then obtained by taking the pixel by pixel differences between the original data and the browse image data. We then code the <b>residual</b> <b>data</b> with a form of variable length coding called diagonal coding. In our experiments, the JPEG/DCT is used at different quality factors (Q) to generate the browse and <b>residual</b> <b>data.</b> The algorithm has been tested on band 4 of two Thematic mapper (TM) data sets. The best overall compression ratios (of about 1. 7) were obtained when a quality factor of Q= 50 was used to produce browse data at a compression ratio of 10 to 11. At this quality factor the browse image data has virtually no visible distortions for the images tested...|$|E
40|$|Data {{from five}} {{studies on the}} {{relationships}} between dendrometric measurements and leaf area of Eucalyptus globulus Labill. plantations were pooled and analyzed to develop regression models for the estimation of leaf area of individual trees. The data, collected at two sites in west-central and southwestern Portugal, varied in age from 2 to 19 years and in plant density from 481 to 1560 trees/ha and included both first and second rotation coppice stands. A total of 29 nonlinear regression models were tested and ranked with a multicriteria evaluation (MCE) procedure, based on goodness-of-fit statistics, predictive ability statistics, and collinearity diagnostics. The best models were validated using an independent data set. The final model selection was based on comparisons of prediction <b>residuals</b> <b>data,</b> statistical tests, and silvicultural and physiological considerations. One model is proposed as adequate for leaf area estimation of E. globulus plantation trees. This model contains four parameters and independent variables that quantify stem diameter, crown size, and stand density...|$|R
5000|$|... where c(j,i) {{represents}} simple oscillatory {{modes of}} certain frequencies and r(n,i) is the <b>residual</b> of the <b>data</b> Yi. The {{result of the}} ith MEEMD component Cj is obtained as [...]|$|R
30|$|Purified PepP was {{stored at}} − 80 °C {{over a period}} of 15 [*]days. During this time, aliquoted samples were checked for {{residual}} activities and no significant inactivation of PepP was observed (97 % <b>residual</b> activity; <b>data</b> not shown). Additionally, the influence of 6 alternating cycles of freezing and thawing was observed. The residual activity of PepP was 87 % after these cycles (data not shown).|$|R
