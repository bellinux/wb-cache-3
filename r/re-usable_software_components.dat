6|10000|Public
50|$|As well {{as being}} a biocurator she has co-developed tools to align and visualise protein {{sequences}} and structures, including Ambrosia and CINEMA. The group are building <b>re-usable</b> <b>software</b> <b>components</b> to create useful bioinformatics applications through UTOPIA (Bioinformatics tools), and are developing new approaches for automatic annotation and text mining, like PRECIS, METIS, BioIE, and semantic approaches to data integration, such as the Semantic Biochemical Journal published by Portland Press. The UTOPIA tools underpin both the Semantic Biochemical Journal and a collaborative project with Pfizer and AstraZeneca to develop a 21st-century interface to biomedical literature and data management.|$|E
40|$|Information Retrieval (IR) {{has benefited}} from {{standard}} evaluation practices and <b>re-usable</b> <b>software</b> <b>components,</b> that enable comparability between systems and experiments. However, Interactive IR (IIR) has had only very limited benefit from these developments, in part because experiments are still built using bespoke components and interfaces. In this {{paper we propose a}} flexible workbench for constructing IIR interfaces that will standardise aspects of the IIR experiment process to improve the comparability and reproducibility of IIR experiments...|$|E
40|$|Fresco is a Smalltalk-based {{interactive}} environment {{supporting the}} specification and proven development of <b>re-usable</b> <b>software</b> <b>components.</b> These 'capsules' are deltas to the inheritance hierarchy, {{and form a}} more useful unit of designer-effort than class subhierarchies. Systems are built by composing capsules, which carry both specifications and code. The semantics of capsule composition is elucidated by examining the relationship between 'typ' and 'class'. Type-descrioptions {{take the form of}} model-oriented specifications. The principles discussed here can be applied to other-oriented languages...|$|E
40|$|Abstract. This paper {{presents}} {{some ideas}} {{of how to}} use Web Services {{for the implementation of}} innovative collaborative technologies. A major goal here is the idea to build <b>re-usable</b> collaborative <b>software</b> <b>components</b> to foster knowledge exchange and learning. This paper describes two examples of how we used Web Services to achieve this goal. The first example we will describe implements a digital notice board with large, public displays. Here, we used web service to provide flexible data access. Web services provide the possibility to use our infrastructure with different programming languages and devices. The second example we will present is an application that enables students to construct and model experiments descriptions using a control plant-growth system, the biotube, remotely via Web Services. ...|$|R
40|$|Software reuse {{has long}} been touted as an {{effective}} means to develop software products. But reuse technologies for software have not lived up to expectations. Among the barriers are high costs of building software repositories {{and the need for}} effective tools to help designers locate <b>re-usable</b> <b>software.</b> While many design-forreuse and software classification efforts have been proposed, these methods are cost-intensive and cannot effectively take advantage of large stores of design artifacts that many development organizations have accumulated. Methods are needed that take advantage of these valuable resources in a cost-effective manner. This paper describes an approach to the design of tools to help software designers build repositories of <b>software</b> <b>components</b> and locate potentially <b>re-usable</b> <b>software</b> in those repositories. The approach is investigated with a retrieval tool, named CodeFinder, which supports the process of retrieving <b>software</b> <b>components</b> when information needs are ill-defi [...] ...|$|R
40|$|MeDICi (Middleware for Data Intensive Computing) is a {{platform}} for developing high performance, distributed streaming analytic and scientific applications. Developed at Pacific Northwest National Laboratory (PNNL), MeDICi has been released under an open source license {{and is based on}} enterprise-proven middleware technologies including a widely used Enterprise Service Bus (ESB), the standard Business Process Execution Language (BPEL), and open source message brokers. Wherever possible, we have built on existing open source, standards-based systems and integrated them into a coherent whole by creating simplified graphical programming tools such as a Workflow Designer and an easy to use and well-documented integration API. This software development approach allows us to: avoid re-creating complex service integration and orchestration systems, reap the benefits of continual improvements to the technology base, and focus on creating tools and APIs which allow for the creation of <b>re-usable</b> component-based <b>software</b> <b>components</b> applications and workflows. These aspects have facilitated rapid adoption of the platform within PNNL for demonstration and operational applications. In fact, MeDICi has been used {{for a wide range of}} integration projects including two sensor integration applications described later on in this paper. The remainder of this article white paper is organized as follows: Section 2 provides a high-level description of the MeDICi architecture. In Section 3, the open aspects of the API and tool development are highlighted. Section 4 explains system readiness by presenting relevant demonstrations and deployments. Finally documentation and licensing details are provided in Section...|$|R
40|$|The {{acquisition}} {{community needs}} guidance in long-term management planning for selecting, approving, and upgrading software products, especially commercial off-the-shelf (COTS) and other reusable software products. As {{the mixture of}} these components in systems increases, the demand for a planned way to manage them continues to grow. The COTS and Reusable Software Management Plan (CRSMP) can facilitate acquisition programs 2 Ì† 7 management of COTS and other reusable software products. The CRSMP provides a strategy outline for managing data about component licensing, tracking release schedules, monitoring software interdependencies, choosing specific features and extensions and documenting those choices, and evaluating and mitigating risks associated with deploying COTS and other <b>re-usable</b> <b>software</b> <b>components</b> in a system. The CRSMP presented in this report {{can serve as a}} guide for how to manage multiple COTS and other reusable software components in complex systems...|$|E
40|$|Gerd Hillebrand Polivios Klimathianakis y 1 Introduction The Software Information Base (SIB) [1] was {{developed}} at FORTH as a repository system for <b>re-usable</b> <b>software</b> <b>components.</b> Originally intended {{to support the}} development of very large software systems within the ESPRIT ITHACA project, it has since been adapted to other application domains and in its current version (known as the Semantic Index System) provides a general tool for documenting and indexing large collections of interrelated heterogeneous data such as engineering designs, museum collections, organograms, etc. The SIB consists of a knowledge-base component built upon the TELOS knowledge representation language [5] {{and a collection of}} user and application interfaces, among them a TELOS parser, a graphical browser, static analyzers for various common programming languages, an interface to relational DBMS, and others. Information is entered into the system either automatically, e. g. by loading it from a relational da [...] ...|$|E
40|$|Abstract Background Computational {{methods for}} problem solving need to {{interleave}} information access and algorithm execution in a problem-specific workflow. The structures of these workflows {{are defined by}} a scaffold of syntactic, semantic and algebraic objects capable of representing them. Despite the proliferation of GUIs (Graphic User Interfaces) in bioinformatics, only some of them provide workflow capabilities; surprisingly, no meta-analysis of workflow operators and components in bioinformatics has been reported. Results We present a set of syntactic components and algebraic operators capable of representing analytical workflows in bioinformatics. Iteration, recursion, the use of conditional statements, and management of suspend/resume tasks have traditionally been implemented on an ad hoc basis and hard-coded; by having these operators properly defined {{it is possible to}} use and parameterize them as generic re-usable components. To illustrate how these operations can be orchestrated, we present GPIPE, a prototype graphic pipeline generator for PISE that allows the definition of a pipeline, parameterization of its component methods, and storage of metadata in XML formats. This implementation goes beyond the macro capacities currently in PISE. As the entire analysis protocol is defined in XML, a complete bioinformatic experiment (linked sets of methods, parameters and results) can be reproduced or shared among users. Availability: [URL] (interactive), ftp://ftp. pasteur. fr/pub/GenSoft/unix/misc/Pise/ (download). Conclusion From our meta-analysis we have identified syntactic structures and algebraic operators common to many workflows in bioinformatics. The workflow components and algebraic operators can be assimilated into <b>re-usable</b> <b>software</b> <b>components.</b> GPIPE, a prototype implementation of this framework, provides a GUI builder to facilitate the generation of workflows and integration of heterogeneous analytical tools. </p...|$|E
40|$|The {{principles}} of Service-Oriented Architecture (SOA) {{argue for the}} design of systems composed of <b>re-usable</b> coarse-grained <b>software</b> <b>components</b> which consume and provide services in a service ecosystem. Despite being commonly mentioned in an enterprise context, these are very present in the web - most web applications expose some of their data via APIs, which are then used by other web and mobile applications. The proliferation of user-owned connected devices has brought value to mobile application developers which can make use of locally-available sensors and capabilities and send their information to the web, centralizing the data flows. A more distributed approach would have device capabilities offered directly on the network as services hosted by the user. These pervasive user-hosted services could be made discoverable and available over a public federated service infrastructure. The infrastructure would provide transport over an identity layer, where endpoints are addressed by their identities instead of network identifiers, and on top of which services can be exposed to be consumed by trusted friends or anonymous users, as the hosting user prefers. The work presented in this paper explores the possibility of implementing a distributed social SOA over Extensible Messaging and Presence Protocol (XMPP). It differs from traditional SOA because it attempts to counter relative centralization of the web, in favour of a fully-distributed service ecosystem where each peer can behave both as service consumer and provider. Finally, an analysis is done on how suitable XMPP is to serve as a base protocol for such infrastructure...|$|R
40|$|A <b>software</b> <b>component</b> {{is defined}} as a unit of {{composition}} with contractually specified interfaces and explicit dependencies that may be independently deployed. <b>Components</b> form generic, <b>re-usable</b> <b>software</b> building blocks, which can be composed into applications and deployed by third parties. A good component model therefore must seek to minimize implicit dependencies in order to maximize re-use and composability. The benefits of component models have led to their widespread application in the area of networked embedded systems and particularly Wireless Sensor Networks. This paper first classifies and analyses the types of dependency that a component may be subject to. Next, we assess the success of contemporary component models in eliminating implicit dependencies and promoting re-usability. We then describe our efforts to reduce implicit distributed dependencies in the design of LooCI: the Loosely-coupled Component Infrastructure. We conclude with a call-to-arms for the component-based software engineering community that suggests avenues for future work. status: publishe...|$|R
5000|$|Cataloguing <b>re-usable</b> {{interoperability}} <b>software,</b> taxonomies, vocabularies, code-lists, licences, organisational {{assets and}} guidelines; ...|$|R
40|$|<b>Software</b> <b>component</b> reuse {{is the use}} of {{existing}} <b>software</b> <b>components</b> to build a new software system. Effective storage and retrieval of <b>software</b> <b>components</b> is much essential in <b>software</b> <b>components</b> reuse process. The researchers have developed a number of <b>software</b> <b>components</b> reuse techniques for storage and retrieval of <b>software</b> <b>components.</b> No one technique is complete in its own; every technique has its own merits and demerits. This paper presents a meta-data model and faceted classification for storage and retrieval of <b>software</b> <b>components</b> that considers domain semantic information based on ontologies and texonomies. In contrast to most existing repositories, which only retrieve a limited set of components, the proposed meta-data model makes possible the recommendation of interrelated components, as ontolog...|$|R
40|$|Abstract. Current {{models for}} <b>{{software}}</b> <b>components</b> have made component-based software engineering practical. However, these models {{are limited in}} the sense that their support for the characterization/specification of <b>software</b> <b>components</b> primarily deals with syntactic issues. To avoid mismatch and misuse of components, more comprehensive specification of <b>software</b> <b>components</b> is required, especially in a scenario where components are dynamically discovered and used at run-time over corporate intranets and the Internet. Our approach to <b>software</b> <b>component</b> specification aims at comprehensive interface modelling/packaging for <b>software</b> <b>components.</b> It deals with the semantic, usage, quality as well as syntactic aspects of <b>software</b> <b>component</b> specification...|$|R
40|$|The method {{involves}} determining (110) {{running time}} request of <b>software</b> <b>component</b> (102). The resources required for migration of <b>software</b> <b>component</b> are determined (112) based on running time requests. The {{point of time}} to which determined resources for migration of <b>software</b> <b>component</b> of hardware platform (104 - 1) are obtained on objective hardware platform is determined (114). The <b>software</b> <b>component</b> of hardware platform is migrated (116) on objective hardware platform at predetermined point of time. Independent claims are included for the following: (1) computer program for migrating <b>software</b> <b>component</b> of distributed embedded system; and (2) control device for controlling migration <b>software</b> <b>component</b> of distributed embedded system...|$|R
40|$|In a {{distributed}} component based system, it {{is important}} to model and specify the QoS (quality of services) requirements of <b>software</b> <b>components.</b> In this paper we propose a security specification structure {{that can be used to}} model and specify required and ensured security properties of <b>software</b> <b>components.</b> The specification of security requirements can be an aid to software engineers on two main fronts: (i) to specify security requirements during the development of <b>software</b> <b>components,</b> (ii) with support for introspection, a candidate component can be queried about its required and ensured security properties by other <b>software</b> <b>components</b> or human composers in distributed environments. Our proposed specification structure is intended to capture and model pre and post execution security behaviour of <b>software</b> <b>components.</b> The paper provides a preliminary modelling of security function primitives of <b>software</b> <b>components.</b> Keywords. <b>Software</b> <b>component,</b> <b>software</b> compositional relationship, ensured security properties, required security properties. 1...|$|R
40|$|The {{construction}} of software systems from pre-existing, independently developed <b>software</b> <b>components</b> will only occur when application builders can adapt <b>software</b> <b>components</b> {{to suit their}} needs. Our ADAPT framework [Hein 97] supports both component designers in creating components that can easily be adapted, and application builders in adapting <b>software</b> <b>components.</b> We propose that <b>software</b> <b>components</b> provide two interfaces [...] one for behavior and one for adapting that behavior as needed. In this position paper, we outline some requirements for composing <b>software</b> systems from <b>components</b> and suggest that adaptation {{be recognized as a}} significant factor. 1 Introduction The goal of constructing software applications from reusable <b>software</b> <b>components</b> is proving to be very challenging. We believe that adapting <b>software</b> <b>components</b> for use by a particular application is a key enabling technology towards realizing this goal. Using a <b>software</b> <b>component</b> in a different manner than for which it was [...] ...|$|R
40|$|Abstract â€“ Rapid yet diverse service {{creation}} and deployment will ensure customer {{acceptance of the}} Next Generation Network (NGN). Softswitch architectures, such as Parlay, utilise service logic decomposition to achieve this. These architectures decompose service logic into service-dependent and service-independent parts. In this paper, service logic decomposition {{is applied to the}} functionally rich TINA service components resulting in generic and <b>re-usable</b> <b>software</b> sub-components that enable rapid service creation. The benefit of this decomposition approach is the ability to re-use service logic during service creation thus ensuring rapid deployment of third party services in the NGN or TINA compliant networks...|$|R
50|$|Reusability is an {{important}} characteristic of a high-quality <b>software</b> <b>component.</b> Programmers should design and implement <b>software</b> <b>components</b> {{in such a way}} that many different programs can reuse them. Furthermore, component-based usability testing should be considered when <b>software</b> <b>components</b> directly interact with users.|$|R
40|$|Component-based {{software}} development {{is widely regarded}} as a promising approach to improving productivity and quality. However, progress in component-based {{software development}} has been slower than expected. A possible explanation for this slow progress is that there are not enough <b>software</b> <b>components</b> that can satisfy users (consumers). From this perspective, {{the purpose of this paper}} is to increase our knowledge about consumers of <b>software</b> <b>components</b> and to understand what aspects of <b>software</b> <b>components</b> are likely to affect consumer behavior. Specifically, this paper seeks to establish links between objective features of <b>software</b> <b>components</b> and consumers' preferences and purchasing behavior. The pragmatic utility of using objective features as predictors of consumers' behavior in regard to <b>software</b> <b>components</b> can be high. Since these objective features are under the direct control of producers, by understanding the relationship between the objective features and consumer behavior, producers can more effectively develop <b>software</b> <b>components</b> adapted to consumers' needs. We conducted this research in an artificial environment using a system called SofTrade, which was built for the purpose of teaching and studying the design, production, marketing, and purchasing of <b>software</b> <b>components.</b> Our results suggest that objective features of <b>software</b> <b>components</b> can be effective predictors of consumers' preferences and purchasing behavior, and therefore may provide practical guidance to <b>software</b> <b>component</b> producers regarding how to develop more marketable <b>software</b> <b>components...</b>|$|R
40|$|Abstract. Current {{models for}} <b>{{software}}</b> <b>components</b> have made component-based software engineering practical. However, these models {{are limited in}} the sense that their support for the specification of <b>software</b> <b>components</b> primarily deals with syntactic issues. To facilitate interoperability and proper use of <b>software</b> <b>components,</b> more comprehensive specification of these components is required. In this paper, we present an approach to <b>software</b> <b>component</b> packaging aimed at comprehensive component specification, especially its support for semantic and usage specification. ...|$|R
40|$|Abstract: Today, it is {{important}} for software companies to build software systems in a short time-interval, to reduce costs and to have a good market position. Therefore well organized and systematic development approaches are required. Reusing <b>software</b> <b>components,</b> which are well tested, can be a good solution to develop software applications in effective manner. The reuse of <b>software</b> <b>components</b> is less expensive and less time consuming than a development from scratch. But it is dangerous to think that <b>software</b> <b>components</b> can be match together without any problems. <b>Software</b> <b>components</b> itself are well tested, of course, but even if they composed together problems occur. Most problems are based on interaction respectively communication. Avoiding such errors a framework has to be developed for analysing <b>software</b> <b>components.</b> That framework determines the compatibility of corresponding <b>software</b> <b>components.</b> The promising approach discussed here presents a novel technique for analysing <b>software</b> <b>components</b> by applying an abstract syntax language tree (ASLT). A supportive environment will be designed that checks the compatibility of black-box softwar...|$|R
40|$|Handling of {{reusable}} <b>software</b> <b>components</b> {{will be a}} {{step towards}} creating a discipline {{in the field of}} reusable <b>software</b> <b>components.</b> The concept of handling emerges from the idea that the reusable components should be used, transacted, stimulated, and retrieved by adhering to proper guidelines and standards. As the guidelines and standards are followed while handling with the other entities, the <b>software</b> <b>components</b> should also be dealt with the same way. If the guidelines and standards are not followed while handling the <b>software</b> <b>components,</b> there wonâ€™t be any regularity on the components. Therefore, the study has provided with the standards and guidelines for handling of reusable <b>software</b> <b>components.</b> It would affect the quality of reusable <b>software</b> <b>components.</b> Consequently, the quality of software products composed from these components will be affected. Also, the lack of handling will {{have a negative impact on}} the whole market of reusable components. The study also stated the process and the elements involved in the process of handling of reusable <b>software</b> <b>components...</b>|$|R
50|$|The {{concept of}} the NWDI starts with a product and a <b>software</b> <b>component</b> (SC). The normal case {{is to have a}} {{one-to-one}} relationship between product and <b>software</b> <b>component,</b> one product is being developed and the relations between the components comprising the product are kept within a <b>software</b> <b>component.</b>|$|R
40|$|There {{has been}} an {{increased}} focus in recent years {{on the development of}} <b>re-usable</b> <b>software,</b> in the form of objects and <b>software</b> <b>components.</b> This increase, together with pressures from enterprises conducting transactions on the Web to support all business interactions on all scales, has encouraged research towards the development of easily reconfigurable and highly adaptable Web services. This work investigates the ability of Component-Based Software Development (CBSD) to produce such systems, and proposes a more manageable use of CBSD methodologies. Component-Driven Software Development (CDSD) is introduced to enable better component manageability. Current Web service technologies are also examined to determine their ability to support extensible Web services, and a dynamic Web service architecture is proposed. The work also describes the development of two proof-of-concept systems, DREW Chat and Hamilton Bank. DREW Chat and Hamilton Bank are implementations of Web services that support extension dynamically and at run-time. DREW Chat is implemented on the client side, where the user is given the ability to change the client as required. Hamilton Bank is a server-side implementation, which is run-time customisable by both the user and the party offering the service. In each case, a generic architecture is produced to support dynamic Web services. These architectures are combined to produce CREWS, a Component-driven Runtime Extensible Web Service solution that enables Web services to support the ever changing needs of enterprises. A discussion of similar work is presented, identifying {{the strengths and weaknesses of}} our architecture when compared to other solutions...|$|R
40|$|The paper {{describes}} a software inspection {{process that can}} be used to evaluate the quality of <b>software</b> <b>components.</b> Quality criteria, process application, independent testing of the process and proposed associated tool support are covered. Early results indicate that this technique is well suited for assessing <b>software</b> <b>component</b> quality in a standardized fashion. With automated machine assistance to facilitate both the evaluation and selection of <b>software</b> <b>components,</b> such a technique should promote effective reuse of <b>software</b> <b>components...</b>|$|R
5000|$|A <b>{{software}}</b> <b>component</b> adapter {{is a type}} {{of software}} that is logically located between two <b>software</b> <b>components</b> and reconciles the differences between them.|$|R
40|$|Today, it is {{important}} for software companies to build software systems in a short time-interval, to reduce costs and to have a good market position. Therefore well organized and systematic development approaches are required. Reusing <b>software</b> <b>components,</b> which are well tested, can be a good solution to develop software applications in effective manner. The reuse of <b>software</b> <b>components</b> is less expensive and less time consuming than a development from scratch. But it is dangerous to think that <b>software</b> <b>components</b> can be match together without any problems. <b>Software</b> <b>components</b> itself are well tested, of course, but even if they composed together problems occur. Most problems are based on interaction respectively communication. Avoiding such errors a framework has to be developed for analysing <b>software</b> <b>components.</b> That framework determines the compatibility of corresponding <b>software</b> <b>components.</b> The promising approach discussed here, presents a novel technique for analysing <b>software</b> <b>components</b> by applying an Abstract Syntax Language Tree (ASLT). A supportive environment will be designed that checks the compatibility of black-box <b>software</b> <b>components.</b> This article is concerned to the question how can be coupled <b>software</b> <b>components</b> verified by using an analyzer framework and determines the usage of the ASLT. Black-box <b>Software</b> <b>Components</b> and Abstract Syntax Language Tree are the basis for developing the proposed framework and are discussed here to provide the background knowledge. The practical implementation of this framework is discussed and shows the result by using a test environment. Comment: 20 pages, exposed on 5 th International Conference "Actualities and Perspectives on Hardware and Software" - APHS 2009, Timisoara, Romani...|$|R
40|$|Abstract: The {{globalization}} {{of the software}} market leads to crucial problems for software companies. More competition between software companies arises and leads to the force on companies to develop ever newer software products in ever shortened time interval. Therefore the time to market for software systems is shortened and obviously the product life cycle is shortened too. Thus software companies shortened the time interval for research and development. Due to the fact of competition between software companies software products have to develop low-priced and {{this leads to a}} smaller return on investment. A big challenge for software companies is the use of an effective research and development process to have these problems under control. A way to control these problems can be the reuse of existing <b>software</b> <b>components</b> and adapt those <b>software</b> <b>components</b> to new functionality or accommodate mismatched interfaces. Complete redevelopment of software products is more expensive and time consuming than to develop <b>software</b> <b>components.</b> The approach introduced here presents novel technique together with a supportive environment that enables developers to cope with the adaptability of black-box <b>software</b> <b>components.</b> A supportive environment will be designed that checks the compatibility of black-box <b>software</b> <b>components</b> with the assistance of their specifications. Generated adapter <b>software</b> <b>components</b> can take over the part of adaptation and advance the functionality. Besides, a pool of <b>software</b> <b>components</b> can be used to compose an application to satisfy customer needs. Certainly this pool of <b>software</b> <b>components</b> consists of black-box <b>software</b> <b>components</b> and adapter <b>software</b> <b>components</b> which can be connected on demand. ...|$|R
40|$|Abstract â€” Adapting <b>software</b> <b>components</b> {{to be used}} in a {{particular}} application is a crucial issue in <b>software</b> <b>component</b> based technology. In fact, <b>software</b> <b>components</b> can be used in contexts with characteristics different from those envisaged when designing the component. Centralized or distributed deployment infrastructure can be one of these assumptions. Thus, a component can be designed as a monolithic unit to be deployed on a centralized infrastructure, nevertheless the used infrastructure needs the component to be distributed. In this paper, we propose an approach allowing us to transform a centralized <b>software</b> <b>component</b> into a distributed one. Our technique is based on refactoring and fragmentation of component source-code. Index Terms â€” <b>Software</b> <b>component,</b> adaptation, restructuration, distribution, refactoring...|$|R
40|$|Adapting <b>software</b> <b>components</b> usable by a {{particular}} application is a crucial issue in <b>software</b> <b>component</b> based technology. In fact, <b>software</b> <b>components</b> {{can be used in}} contexts that can be different from the context assumptions made by the component designers. We present in this pa-per a tool aiming at adapting <b>software</b> <b>component</b> structure. Among the motivations of this kind of adaptation, we note its possible application to prepare a flexible deployment of <b>software</b> <b>components</b> according to the available resources (CPU, memory). Our adaptation process is based on refac-toring and fragmentation of component source code. To support this structural adaptation technique, we developed an adaptation process which we have experimented using the Java framework of the Fractal component model. ...|$|R
40|$|This paper {{presents}} and evaluates {{a new approach}} of modeling energy consumption of embedded systems resulted by concurrent <b>software</b> <b>components.</b> The objective is to enable energy estimation within early phases of system development, which allows system designers to compare different allocations of <b>software</b> <b>components</b> within networked systems. The individual elements of the presented model are: energy consumption of <b>software</b> <b>components</b> themselves, energy consumption resulted by any <b>software</b> <b>component,</b> and energy consumption resulted by specific <b>software</b> <b>components.</b> The The developed model was applied within an automotive case study which shows a theoretical energy saving potential of 36. 2 %. This demonstrates the potential and relevance of modeling energy estimation within early development phases...|$|R
40|$|Component-based {{software}} engineering (CBSE) is {{the construction of}} software systems from <b>software</b> <b>components.</b> <b>Software</b> <b>components</b> are independently deployable units of executable code that can be assembled into a system based on their externally visible properties, which are made available to system developers via the <b>components</b> interface specifications. <b>Software</b> <b>components</b> provide a means for large-scale reuse o...|$|R
40|$|Here {{we propose}} a storage and {{retrieval}} approach of reusable <b>software</b> <b>components</b> based on UML diagram, metadata repository and neural network. If we search the repository {{on the basis}} of attributes of MDL file descriptions, the search result would be better and thus giving higher precision, as compared to keyword based search, then apply neural network to searching results of reusable <b>software</b> <b>component</b> for optimizing the searching results. The proposed approach is tested on various reusable <b>software</b> <b>component</b> datasets containing purely continuous or purely categorical or a mix of both types of attributes. Many features used in the analysis of reusable <b>software</b> <b>component.</b> In this paper reusable <b>software</b> <b>component</b> classified using feed forward back propagation Neural Network. One thousand sets of reusable <b>software</b> <b>component</b> obtained by <b>software</b> reusable techniques. The dataset consist of twenty eight features which represent the input layer to the FNN. The FNN will classify the reusable <b>software</b> <b>component</b> into type 4, type 3, type 2 and type 1 reusable <b>software</b> <b>component.</b> The sensitivity, specificity and accuracy were found to be equal 99. 64 %, 98. 54 % and 98. 80 % respectively. It can be concluded that FNN gives fast and accurate classification and it works as promising tool for optimizing the searching results of reusable <b>software</b> <b>component.</b> The overall accuracy of optimizing searching results of the proposed system is 96. 50 %. Thus, this approach is suitable for automated real time reusable software storing and searching...|$|R
40|$|Mobile devices {{can reduce}} their energy {{consumption}} through power aware remote processing. <b>Software</b> <b>components</b> running on battery-operated wireless nodes are migrated to wall-power wired remote servers. To increase {{the efficiency of}} power aware remote processing, we propose a novel integrated estimator for <b>software</b> <b>component's</b> power and energy consumption. This adaptive estimator {{is based on a}} <b>software</b> <b>component</b> interface, which provides power and timing information. The unit {{is one of the main}} components in our framework for power aware remote processing, providing information for efficient internal decision making whether <b>software</b> <b>components</b> are worth for migration or not. Furthermore, we present results from our framework evaluation in Java environment and standard wearable computing hardware, using sample <b>software</b> <b>components</b> for AES encryption and decryption...|$|R
40|$|The paper {{presents}} a <b>software</b> <b>component</b> that enables NetSolve with direct communications between servers in a non-intrusive and incremental way. Non-intrusiveness {{means that the}} <b>software</b> <b>component</b> is supplementary, working {{on top of the}} original system, which does not change at all. Increment means that the <b>software</b> <b>component</b> {{does not have to be}} installed on all computers to enable applications with the new feature. It can be done incrementally, step by step, and the new feature will be enabled in part, with the completeness dependent on how many nodes have been upgraded with the <b>software</b> <b>component.</b> The paper describes the design and implementation of the <b>software</b> <b>component.</b> The paper also reports on experiments with three typical scientific NetSolve applications having different communication structures: (i) protein tertiary structure prediction, (ii) image processing using sequential algorithms, and (iii) the matrix chain product. The presented experimental results show that the performance of these Grid applications can be easily and significantly improved by using the proposed supplementary <b>software</b> <b>component.</b> ...|$|R
