336|2163|Public
5000|$|According to Wullenweber in 2008, TERA {{provides}} an online database International Toxicity Estimates for Risk (ITER) database, which [...] "provides chronic human health risk assessment {{data from a}} variety of organizations worldwide in a side-by-side format, explains differences in <b>risk</b> <b>values</b> derived by different organizations, and links directly to each organization's website for more detailed information. It is also the only database that includes risk information from independent parties whose <b>risk</b> <b>values</b> have undergone independent peer review." ...|$|E
50|$|A {{specific}} {{method was}} developed by Dr. Mehdizadeh in order to: (1) calculate <b>risk</b> <b>values</b> of risk events regarding different project objectives, (2) aggregate the <b>risk</b> <b>values</b> through the RBS branches and also (3) to calculate global risk score of project. The method combines consistently the quantitative and qualitative approaches, allowing the user to choose the best one for risk assessment at any level, based on the available information and required accuracy. In this method, at the first step, the probability and impact factors of risk events are assessed quantitatively or qualitatively. Two concomitant scales are used: a continuous cardinal scale and a discrete ordinal scale ranging from 1 to 5. Each scale has its own advantage. Continuous scale is closer to physical reality and has a more concrete meaning while discrete scale has a strong symbolic value. The assessments based {{on each of these}} scales can be converted to the other one following a defined process. At the second step, the <b>risk</b> <b>values</b> of risk events are calculated and then aggregated through the RBS branches in order to calculate the <b>risk</b> <b>values</b> of risk categories. Finally, application of a multi-criteria decision method allows calculating the global risk score of each category. This method provides a more consistent approach to get more realistic results without suffering from the usual weaknesses of available methods cited in literature.|$|E
50|$|In medicine, small {{effect sizes}} (reflected by small {{relative}} <b>risk</b> <b>values)</b> are usually considered clinically relevant (if {{there is great}} confidence in them) and are frequently used to guide treatment decisions. A relative risk of 1.10 may seem very small, but over {{a large number of}} patients will make a noticeable difference. Whether a given treatment is considered a worthy endeavour is dependent on the risks, benefits and costs.|$|E
40|$|Risk is everywhere, {{especially}} in the capital market of incomplete information, which is full of speculation, so it is particularly important for investors to define risk, identify risks, and control the investment activities with the application of <b>risk</b> <b>value</b> to. It is analyzed quantitatively on <b>risk</b> <b>value</b> in the paper, with the Knowledge of game theory, economics and mathematical statistics, {{on the basis of}} the explanation of <b>risk</b> and <b>risk</b> <b>value...</b>|$|R
30|$|Risk Threshold is {{the range}} of <b>risk</b> <b>value</b> upto which <b>risk</b> is tolerable. <b>Risk</b> {{threshold}} <b>value</b> varies for various systems.|$|R
30|$|In {{order to}} find the number of risks present in each state of a system the <b>risk</b> <b>value</b> is {{calculated}} using the risk metrics.|$|R
50|$|The Hosmer-Lemeshow test is a {{statistical}} test for {{goodness of fit}} for logistic regression models. It is used frequently in risk prediction models. The test assesses {{whether or not the}} observed event rates match expected event rates in subgroups of the model population. The Hosmer-Lemeshow test specifically identifies subgroups as the deciles of fitted <b>risk</b> <b>values.</b> Models for which expected and observed event rates in subgroups are similar are called well calibrated.|$|E
5000|$|It is a {{theoretically}} interesting measure {{because it}} provides different <b>risk</b> <b>values</b> for different individuals whose attitudes toward risk may differ. However, in practice {{it would be difficult}} to use since quantifying the risk aversion for an individual is difficult to do. The entropic risk measure is the prime example of a convex risk measure which is not coherent. [...] Given the connection to utility functions, it can be used in utility maximization problems.|$|E
50|$|The {{focus of}} the Trike {{methodology}} is using threat models as a risk-management tool. Within this framework, threat models are used to satisfy the security auditing process. Threat models {{are based on a}} “requirements model.” The requirements model establishes the stakeholder-defined “acceptable” level of risk assigned to each asset class. Analysis of the requirements model yields a threat model form which threats are enumerated and assigned <b>risk</b> <b>values.</b> The completed threat model is used to construct a risk model based on asset, roles, actions, and calculated risk exposure.|$|E
30|$|Risk Threshold is {{the range}} of <b>risk</b> <b>value</b> up to which risk is tolerable. Risk {{threshold}} helps to identify the states with low, medium and high risks.|$|R
40|$|This paper {{analyses}} {{the drivers}} {{of the credit}} risk transfer market in the credit <b>risk</b> <b>value</b> chain. The central line of my research is {{to explain why the}} credit derivatives market is a case of credit <b>risk</b> <b>value</b> chain disintegration. I examine the determinants that explain the use of credit derivatives by banks in the lending business. Transaction cost economics represents the starting point of my research. Competitive advantages of banking firms, standardization of information and financial instruments, financial regulation and shareholder value view help us understand the creation of credit risk transfer markets...|$|R
40|$|Abstract. DFMEA is a {{significantly}} efficient tool to systematically evaluate risk {{in early stage}} of product design and development but some of knowledge and information are uncertain and imprecise. This research focuses on fuzzy logic approach to diminish weaknesses and applies to launch tube’s DFMEA. The methodology started from determine membership function of severity, occurrence, and detection and provide fuzzy rule base to arranged category of risk. Afterwards, center average index was selected as defuzzifier for <b>risk</b> <b>value</b> representation. Consequently, the prioritization based on <b>risk</b> <b>value</b> was done and chosen the first five <b>risk</b> <b>value</b> of potential failure modes to analyze causes then recommended appropriate actions. After application of fuzzy logic approach, the most vital potential failure mode is damaged launch tube due to detention force which is rated as first and second priority depending on potential cause or mechanism. The third priority is launch tube distortion. The mechanical load calculation and proper material selection are the recommended actions for overcoming those potential failure modes...|$|R
5000|$|According {{to a joint}} {{investigation}} by InsideClimate News and the Center for Public Integrity TERA's risk-assessment database [...] "receives financial and in-kind support from many companies and government agencies." [...] A review of TERA's website shows that funding is approximately 2/3s government and other nonprofit and approximately 1/3 industry and industry related. [...] TERA has conducted over 100 peer-review meetings with approximately 50 percent of the peer-review panels for studies funded by industry groups; <b>risk</b> <b>values</b> that were accepted in, or changed because of, peer review are included in ITER. [...] Risk assessment methods or issues that were peer reviewed are described in separate reports. Highlights of these reviews include risk assessment documents associated with the World Trade Center 2001 disaster and the West Virginia MCHM spill of 2014. [...] TERA has close ties to it sponsors which include government, industries, nonprofits and universities. TERA encourages collaborative work whenever possible.|$|E
40|$|The work {{suggests}} new way {{of handling}} risk management, that combines risk management and data mining. Data mining approach {{is also used to}} mine quantitative <b>risk</b> <b>values.</b> This approach was successfully implemented and tested. Tests showed that this approach is very useful for omitted risk identification. Unfortunately it is also not recommendable for mining quantitative <b>risk</b> <b>values...</b>|$|E
40|$|This {{paper is}} devoted to risk {{management}} and risk measurement methods. The author considers methods of risk measurement and proposes the Inte- gral Sum of Differential Weighted Indexes of Risks (or ISDWIR) method of risk measurement. The method is based on dynamic enterprise risk matri- ces. The matrix describes the changes of corporate <b>risk</b> <b>values</b> over the time. The method assists to choose risk management decision having good effects on corporate <b>risk</b> <b>values.</b> The ISDWIR method is also compared with other risk measurement methods...|$|E
40|$|This study {{presents}} a new early warning evaluating method and decision mechanism for urban emergency {{in which the}} risk factors are assessed by fuzzy numbers. By using the fuzzy preference relation matrix and the extended fuzzy AHP, the relative weight of each risk factor can be estimated. Then we evaluate the total fuzzy <b>risk</b> <b>value</b> by aggregating the severity of loss of risk factor and the relative weight of risk factor. According to the similarity between the fuzzy comprehensive <b>risk</b> <b>value</b> and the pre-established risk grade, the early warning grade of urban significant emergency can be determined for urgent emergency decision-making...|$|R
40|$|Presented are {{the results}} of a study on the risk factors {{associated}} to a specialized library in Lara State, Venezuela. The objective of this research was to analyze the risk factors that may represent sources of hazards in all elements of the organization of information. The research is descriptive, field and quasi-experimental. Was performed identification the of risk factors and risk quantification was performed by the probability (frequency) and intensity (severity) that can produce the harmful effects. The results indicate that 25 of the 32 analyzed risk factors {{may be related to the}} element of information sources, also in the same way 12 of the 32 may be associated risk factors with human talent element, 12 of the 32 risk factors with user element, 12 of the 32 risk factors with the building element and 10 of the 32 risk factors with the equipments element. The study conclusions show that the risk factors that require further attention and priority, are: relative humidity (<b>risk</b> <b>value</b> 45), dust (<b>risk</b> <b>value</b> 45) and technical cleaning preventive (<b>risk</b> <b>value</b> 15) ...|$|R
40|$|Abstract. In {{order to}} realize the hotel online booking price risk measure, this paper puts forward a {{strategy}} of multi-path QoS routing based on target perception, using the market <b>risk</b> <b>value</b> measures the hotel online reservation price risk. Through the wireless Mesh model, the establishment of hotel reservation price client network carries out empirical analysis on the five-star, four-star and Samsung hotel online reservation price index {{as the source of}} data and carries out the related distribution models to test the data, and then using the QoS risk target search calculates market <b>risk</b> <b>value,</b> which improve a reliable computer target search algorithm for the study of hotel online booking price...|$|R
40|$|The paper {{contains}} an analysis pertaining to {{operation of a}} gas compressor unit while applying imitation modeling in which probabilities of adverse events (failures) have been quantitatively evaluated. In order to obtain <b>risk</b> <b>values</b> of failures {{it is necessary to}} carry out an additional analysis of the importance of negative failure consequences (financial losses). The obtained <b>risk</b> <b>values</b> will allow to work out recommendations on reduction of risk by probability reduction of adverse events or by consequence scope of the given events that will allow to increase quality of the services supplied by the main pipeline transport.   </p...|$|E
40|$|During {{the launch}} of a rocket under {{prevailing}} weather conditions, commanders at Cape Canaveral Air Force station evaluate the possibility of whether wind blown toxic emissions might reach civilian and military personnel in the near by area. In our model, we focused mainly on Hydrogen chloride (HCL), Nitrogen oxides (NOx) and Nitric acid (HNO 3), which are non-carcinogenic chemicals as per United States Environmental Protection Agency (USEPA) classification. We have used the hazard quotient model to estimate {{the number of people}} at risk. It is {{based on the number of}} people with exposure above a reference exposure level that is unlikely to cause adverse health effects. The risk to the exposed population is calculated by multiplying the individual risk and the number in exposed population. The <b>risk</b> <b>values</b> are compared against the acceptable <b>risk</b> <b>values</b> and GO or NO-go situation is decided based on <b>risk</b> <b>values</b> for the Shuttle launch. The entire model is simulated over the web and different scenaria can be generated which allows management to choose an optimum decision...|$|E
40|$|This study {{presents}} data on {{the detailed}} evaluation (tier 2) of a site-specific ecological risk assessment (ssERA) in a former smelter area contaminated with metals (Santo Amaro, Bahia, Brazil). Combining information from three lines of evidence (LoE), chemical (Chem-LoE), ecotoxicological (EcotoxLoE) and ecological (EcoLoE), in the Triad approach, inte-grated <b>risk</b> <b>values</b> were calculated to rank sites and confirm the potential risk disclosed with tier 1. <b>Risk</b> <b>values</b> were calculated for the habitat and for the retention functions in each sampling point. Habitat function included the ChemLoE calculated from total metal concen-trations. The EcotoxLoE was based on reproduction tests with terrestrial invertebrates (Fol-somia candida, Enchytraeus crypticus, Eisenia andrei), shoot length and plant biomass (Avena sativa, Brassica rapa). For the EcoLoE, ecological parameters (microbial parame-ters, soil invertebrate community, litter breakdown) were used to derive <b>risk</b> <b>values.</b> Reten-tion function included the ChemLoE, calculated from extractable metal concentrations, and the EcotoxLoE based on eluate tests with aquatic organisms (Daphnia magna reproduction and Pseudokirchneriella subcapitata growth). Results related to the habitat function indi...|$|E
40|$|This GFSI Risk Management Plan (RMP) {{describes}} the strategy for assessing and managing project risks for the Integrated Waste Treatment Unit (IWTU) that are specifically within {{the control and}} purview of the U. S. Department of Energy (DOE), and identifies the risks that {{formed the basis for}} the DOE contingency included in the performance baseline. DOE-held contingency is required to cover cost and schedule impacts of DOE activities. Prior to approval of the performance baseline (Critical Decision- 2) project cost contingency was evaluated during a joint meeting of the Contractor Management Team and the Integrated Project Team for both contractor and DOE risks to schedule and cost. At that time, the contractor cost and schedule <b>risk</b> <b>value</b> was $ 41. 3 M and the DOE cost and schedule <b>risk</b> contingency <b>value</b> is $ 39. 0 M. The contractor cost and schedule <b>risk</b> <b>value</b> of $ 41. 3 M was retained in the performance baseline as the contractor's management reserve for risk contingency. The DOE cost and schedule <b>risk</b> <b>value</b> of $ 39. 0 M has been retained in the performance baseline as the DOE Contingency. The performance baseline for the project was approved in December 2006 (Garman 2006). The project will continue to manage to the performance baseline and change control thresholds identified in PLN- 1963, ''Idaho Cleanup Project Sodium-Bearing Waste Treatment Project Execution Plan'' (PEP) ...|$|R
40|$|In {{order to}} deal with the {{problems}} in P 2 P systems such as unreliability of the Service, security risk and attacks caused by malicious peers, a novel trust model MSL-TM based on the Multinomial Subjective Logic is proposed. The model uses multinomial ratings and Dirichlet distribution to compute the expectation of the subjective opinion and accordingly draws the peer’s reputation <b>value</b> and <b>risk</b> <b>value,</b> and finally gets the trust value. The decay of time, rating credibility and the <b>risk</b> <b>value</b> are introduced to reflect the recent behaviors of the peers and make the system more sensitive to malicious acts. Finally, the effectiveness and feasibility of the model is illustrated by the simulation experiment designed with peersim...|$|R
40|$|Household {{pesticides}} are {{in general}} used continually {{in a closed}} room enabling the occurrence of its accumulation. This accumulation depends on several factors like the pesticide formulation, the route of its exposure into the body and theusers' behaviour. Mostly insecticide exposure comes into human body through inhalation and dermal absorption. Lifetime Average Daily Dose (LADD) of an insecticide is anestimate of the average of daily insecticide concentration exposed on the community in a lifetime. The risk of cancer arising from the accumulation of insecticide in human body can be estimated from this LADD. For propoxur, a <b>risk</b> <b>value</b> less than  1. 10 - 6 is not significant, a value of  1. 10 - 6 - 1. 10 - 4 is marginally significant and a <b>risk</b> <b>value</b> more than 1. 10 - 4 is significant in causing cancer. At present time in Indonesia still lack of evidence based data concerning the <b>risk</b> <b>value</b> of propoxur pesticide. To develop and implement policy {{on the use of}} sprayed propoxur, a study to determine propoxur exposure in household using sprayed insecticide in Jakarta,Bekasi and Depok had been carried out. </p...|$|R
40|$|The {{concentrations}} of haloacetic acids (HAAs) in both {{indoor and outdoor}} swimming pools were assessed for cancer and non-cancer health risks with water samples collected {{during the summer and}} rainy seasons from two sources. Results showed that average {{concentrations of}} HAA 5 (MCAA, DCAA, TCAA, MBAA, and DBAA) in both indoor and outdoor pools ranged from 74. 28 to 163. 05 µg/L which was higher than USEPA and WHO water quality standards. Cancer and non-cancer <b>risk</b> <b>values</b> of HAA 5 exposure from both swimming pool types were acceptable risks based on USEPA recommendation (10 - 6 - 10 - 4 and < 1, respectively). The highest cancer and non-cancer <b>risk</b> <b>values</b> of HAAs exposure were females for indoor pool and children for outdoor pool, respectively. Cancer and non-cancer <b>risk</b> <b>values</b> of HAA 5 exposure from outdoor pool were higher than indoor pool and during the rainy season, respectively. Results indicated that monitoring and control of water quality and accumulated organic substance in swimming pools should be followed to maximize health risk reduction from HAA exposure...|$|E
30|$|Additional file  1 : Table S 4 {{presents}} the mean excess lifetime <b>risk</b> <b>values</b> clustered per cancer site for all patients. Except for the bladder, all other included organs show a maximum risk of 1 per 100, 000 persons. The critical organs (highest <b>risk</b> <b>values)</b> were the bladder, colon, thyroid, lungs, kidneys, and bone marrow. In comparison, Ozasa et al. [20] presented similar results: besides the organs stated above, the breast (female), esophagus, gall bladder, and liver {{were reported as}} organs with the highest excess risk per cancer site. Conversely, the rectum, uterus (female), prostate (male), and kidneys (parenchyma) presented no significant excess risk [20].|$|E
3000|$|... {{receives}} a minimum value 0 {{if all the}} controls related to the vulnerability k are implemented and hence the vulnerability does not impact negatively the <b>risk</b> <b>values.</b> The more controls related to the vulnerability k are not implemented, the higher ε [...]...|$|E
40|$|In {{this article}} {{described}} methodological principles of industrial objects automation based on technogenic <b>risk</b> <b>value.</b> These principles include reliability assessment {{and quality of}} automation system assessment in uncertainty conditions. Using of this method allows optimizing process of technical system automation, with taking to account its reliability. ? ?????? ?????? ???????????? ???????????????? ?????? ?????????? ???????????????? ????????, ? ?????? ???????????? ?????. ???????????? ???????? ???????? ? ???? ?????????? ?????????? ? ???????? ?????????? ??????????????? ????????? ? ???????? ????????????????. ??? ? ???? ???????, ????????? ?????????????? ??????? ?????????? ??????????? ???????? ? ?????? ??? ??????????...|$|R
40|$|Acquisition) Collected for University of Florida's Institutional Repository by the UFIR Self-Submittal tool. Submitted by Ayad Ali. (Publication Status) PublishedSuggested Citation: Ali AK. Lipid-lowering {{therapy with}} statins may be {{associated}} with cataract and cataract operation <b>risks.</b> <b>Value</b> in Health. May 2014; 17 (3) :A 102 [Abstract No. PCV 1]...|$|R
40|$|<b>Risk</b> and <b>Value</b> Management, {{the fifth}} release in the Construction Companion series, offers an {{introductory}} toolbox of techniques for managing <b>risk</b> and <b>value</b> in construction projects for architects and other building professionals. Identifying and assigning risk to deliver good value {{has become an}} increasingly important objective as projects become more complex and non-traditional procurement routes proliferate. This book describes the social and psychological dimensions of <b>risk</b> and <b>value</b> {{through a series of}} fascinating examples, whilst also examining the dominant trend towards partnering and its specific impact upon the assignment of risk and, consequently, upon value...|$|R
30|$|It is {{seen from}} Fig.  2 that {{different}} risk–return measures are better for different weights (w). For lower {{values of the}} weight parameter (w), i.e., when the analyst puts more emphasis on minimizing risk rather than maximizing return, portfolio models with lower semi-variance, i.e., downside risk, show slightly higher <b>risk</b> <b>values</b> than the variance-based portfolio models. For higher weights, i.e., when the analyst emphasizes more on maximizing return, variance-based portfolio models show significantly higher <b>risk</b> <b>values</b> than the lower semi-variance-based portfolio models. In general, the median–variance and median–downside risk models are better than the mean–variance and mean–downside risk models, respectively, in terms of return maximization. Also, the mean–variance and median–variance models are better than the mean–downside risk and median–downside risk models, respectively, in terms of risk minimization.|$|E
40|$|We {{suggested}} some {{methods for}} information security risk factors assessment. These methods {{are based on}} the expert judgments, analytic hierarchy process and fuzzy logic. Implementation of these methods enables quantitative evaluation of <b>risk</b> <b>values</b> under uncertainty, gaps and qualitative character of information about threats and vulnerabilities...|$|E
40|$|Although social {{computing}} (SC) {{has been}} growing phenom-enally, it still lacks an appropriate way of protecting the security and privacy of data shared in the system. Cur-rent access control mechanisms {{in the domain of}} SC mainly rely on pre-defined access control policies to achieve autho-rization statically, which are intrinsically unsuitable for cap-turing the dynamic changes in social environment. In this paper, we explore the approach towards a more flexible and adaptive control through the incorporation of risk aware-ness in SC. In particular, <b>risk</b> <b>values</b> are associated with users and objects; meanwhile, risk thresholds are defined for each of the permissions. <b>Risk</b> <b>values</b> and risk thresholds can be derived from provenance data in a timely manner. Such dynamic computation can be enabled and facilitated with the incorporation of provenance awareness in SC systems...|$|E
40|$|The <b>risks,</b> <b>values,</b> {{and costs}} of the SETI project are {{evaluated}} and {{compared with those of}} the Viking project. Examination of the scientific values, side benefits, {{and costs of}} the two projects reveal that both projects provide equal benefits at equal costs. The probability of scientific and technical success is analyzed...|$|R
40|$|This article deals the {{problems}} of investments in securities. The {{purpose of this study}} is risk optimization and determination within a portfolio of <b>risk</b> <b>value</b> criteria when investments in financial titles are made in condition of undetermined situations. At the end, answers merge into questions mark. This provokes for reflection...|$|R
50|$|Pabrai {{has high}} regards for Warren Buffett and admits that his {{investment}} style is copied from Buffett and others. He {{has written a}} book on his investing style: The Dhandho Investor: The Low - <b>Risk</b> <b>Value</b> Method to High Returns. In June 2007 he made headlines by bidding US$650,100 with Guy Spier for a charity lunch with Warren Buffett.|$|R
