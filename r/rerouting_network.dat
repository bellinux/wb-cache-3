2|25|Public
40|$|In {{the recent}} past {{wireless}} sensor networks have increasingly attracted research interest due to their abilities to perform monitoring tasks. In the ideal case they would allow to be randomly deployed (ad-hoc) wherever they are needed, independent of surrounding terrain. They would constantly adapt to environmental changes and operate without further maintenance while being comparatively cheap. In case of a node failure a wireless sensor network is expected to heal itself by <b>rerouting</b> <b>network</b> traffic and changing network topology, if needed. While al lot of effort {{has been made to}} fulfil theses goals, nearly nothing has been done to preserve data integrity in case of unforeseen malfunctions. This work addresses some problems related to networks where distinct roles for each network member is choosen before deployment...|$|E
40|$|We {{present a}} systems biology view on pseudoenzymes that {{acknowledges}} that genes are not selfish: the genome is. With network {{function as the}} selectable unit, {{there has been an}} evolutionary bonus for recombination of functions of and within proteins. Many proteins house a functionality by which they 'read' the cell's state, and one by which they 'write' and thereby change that state. Should the writer domain lose its cognate function, a 'pseudoenzyme' or 'pseudosignaler' arises. GlnK involved in Escherichia coli ammonia assimilation may well be a pseudosignaler, associating 'reading' the nitrogen state of the cell to 'writing' the ammonium uptake activity. We identify functional pseudosignalers in the cyclin-dependent kinase complexes regulating cell-cycle progression. For the mitogen-activated protein kinase pathway, we illustrate how a 'dead' pseudosignaler could produce potentially selectable functionalities. Four billion years ago, bioenergetics may have shuffled 'electron-writers', producing various networks that all served the same function of anaerobic ATP synthesis and carbon assimilation from hydrogen and carbon dioxide, but at different ATP/acetate ratios. This would have enabled organisms to deal with variable challenges of energy need and substrate supply. The same principle might enable 'gear-shifting' in real time, by dynamically generating different pseudo-redox enzymes, reshuffling their coenzymes, and <b>rerouting</b> <b>network</b> fluxes. Non-stationary pH gradients in thermal vents together with similar such shuffling mechanisms may have produced a first selectable proton-motivated pyrophosphate synthase and subsequent ATP synthase. A combination of functionalities into enzymes, signalers, and the pseudo-versions thereof may offer fitness in terms of plasticity, both in real time and in evolution...|$|E
30|$|Autonomous {{intersection}} management (AIM) {{will allow}} <b>rerouting</b> and <b>network</b> balancing {{to stabilize the}} demand at each intersection. There are some intensive works focusing on autonomous intersection management. The first idea proposed [21, 22] two decades ago before autonomous driving and wireless communication technology are broadly known. They introduced the idea of decentralized intersection collision avoidance using the concept of token ring and communication management of autonomous vehicle-included security. The work has been summarized in [23].|$|R
40|$|This paper {{presents}} {{an approach to}} enhance the usability of anonymizing networks by creating a virtual anonymous IP-network. An anonymization layer is hidden behind the operating system and transparently <b>reroutes</b> all <b>network</b> traffic. This enables the user to perform all IP based network access without adaption of the used programs. The provided IP {{can be used to}} provide services on the network anonymously. The generality of the approach also enables typical IP based services like DNS to be pro-vided to the anonymous hosts. ...|$|R
30|$|To fill in this gap, in a {{previous}} work we proposed NFV-PEAR, a framework for adaptive VNF orchestration [11]. Our goal was to enable (re)arrangement of previously assigned network functions and flow chaining, in parallel to the instantiation of new SFCs, {{in order to deal}} with the dynamic behavior of flows and fluctuations in resource availability in N-PoPs. To this end, we seek to (re)chain flows through VNFs with available bandwidth and computing power, as well as (re)organize VNFs into N-PoPs with more resources available. In this paper, we extend our previous work by providing: (i) a more detailed discussion on the formal model to ensure the best provision of SFCs in face of dynamic changes in demand and/or costs associated with networking equipment (virtual or not); (ii) an overview of the reference architecture and application programming interface for (re)design and deployment of SFCs, agnostic of virtualization and infrastructure technologies; (iii) a description of a proof-of-concept prototypical implementation of NFV-PEAR; and (iv) a more detailed evaluation on the efficacy and effectiveness of NFV-PEAR. From the results obtained via analytical and experimental evaluation, we observed that network resource consumption became evenly distributed among active VNFs, when compared to non-reconfigurable NFV environments. Furthermore, it became possible to <b>reroute</b> <b>network</b> flows with varying bandwidth/computing power demands, paving way for minimizing flow requirement violations.|$|R
40|$|International audienceWe {{introduce}} the process number of a digraph {{as a tool}} to study <b>rerouting</b> issues in <b>networks.</b> This parameter is closely related to the vertex separation (or pathwidth). We consider the recognition and the characterization of (di) graphs with small process number. In particular, we give a linear time algorithm to recognize (and process) graphs with process number at most 2, along with a characterization in terms of forbidden minors, and a structural description. As for digraphs with process number 2, we exhibit a characterization that allows one to recognize (and process) them in polynomial time...|$|R
40|$|Due to the {{difference}} in implementing network topologies in the optical and electronic domain, schemes to tolerate link failures in electronic implementations may not be ‘the most efficient ones for optical implementations of multiprocessor <b>networks.</b> <b>Rerouting</b> messages along alternate paths in the network topology is commonly used in electronically implemented networks to tolerate link failures. In this paper, we propose two schemes that use the properties of wavelength division multiplezing to tolerate link failures in optically interconnected multiprocessor networks. These {{are referred to as}} wavelength reassignment and time division multiplexing. We show that optically implemented networks have better faulttolerance properties than electronic ones. ...|$|R
40|$|Overload in a packet-based network can be {{prevented}} by admitting or blocking new flows depending on its load conditions. However, overload can occur in spite of admission control due to unforseen events, e. g., when admitted traffic is <b>rerouted</b> in the <b>network</b> after a failure. To restore quality of service {{for the majority of}} admitted flows in such cases, flow termination has been proposed as a novel control function. We present several flow termination algorithms that measure so-called pre-congestion notification (PCN) feedback. We analyze their advantages and shortcomings in particular under challenging conditions. The results improve the understanding of PCN technology which is currently being standardized b...|$|R
40|$|Abstract: The {{emerging}} service-based digital {{networks for}} {{applications such as}} Video-on-Demand depend on packet delivery in real-time. The problem is compounded when a number of streams are sent simultaneously. This paper describes a novel connection admission control mechanism that works with smoothed video from our Network Constrained Smoothing algorithm. Our approach is two-pronged: <b>network</b> <b>rerouting</b> of particular smoothed intervals and connection renegotiation. We alter the routing on a per-interval basis when admission control cannot accept new connections that break aggregate network throughput thresholds. We present simulation results that show quantitative benefits- enhanced network performance from improved spatial and temporal load balancing using our admission control and smoothing techniques...|$|R
40|$|In this paper, {{in order}} to {{increase}} the scalability and fault-tolerance of routing solutions the hierarchical method of inter-area fast <b>rerouting</b> in communication <b>networks</b> was presented. The method is based on the decomposed representation of the flow-based routing model with the introduction of the area interaction conditions to ensure connectivity of the inter-area routes. The model includes conditions for border routers protection, adapted for both single path and multipath routing. During the research it was established that the efficiency of the proposed method in terms of the speed of the coordinating procedure convergence was most influenced by the number of border routers and the implemented routing strategy...|$|R
50|$|Network {{survivability}} {{enables the}} network to maintain maximum network connectivity {{and quality of}} service under failure conditions. It {{has been one of}} the critical requirements in network planning and design. It involves design requirements on topology, protocol, bandwidth allocation, etc.. Topology requirement can be maintaining a minimum two-connected network against any failure of a single link or node. Protocol requirements include using dynamic routing protocol to <b>reroute</b> traffic against <b>network</b> dynamics during the transition of network dimensioning or equipment failures. Bandwidth allocation requirements pro-actively allocate extra bandwidth to avoid traffic loss under failure conditions. This topic has been actively studied in conferences, such as the International Workshop on Design of Reliable Communication Networks.|$|R
40|$|Abstract—WSNs are {{inherently}} power constrained {{and are often}} deployed in harsh environments. As such, node death {{is a possibility that}} must be considered while designing protocols for such <b>networks.</b> <b>Rerouting</b> of data is generally necessary so that data from the descendant nodes of the dead node can reach the sink. Since slot allocation in TDMA MAC protocols is generally done based on the routing tree, all the nodes must switch to the new routing tree to avoid collisions. This necessitates disseminating the fault information to all the nodes reliably. We propose a flooding algorithm for disseminating fault info to the network reliably even in a lossy channel. Simulation results show that the proposed flooding scheme consumes lesser energy and converges faster than a simple flooding scheme. I...|$|R
40|$|Abstract 3 D-CGIN is a CGIN {{providing}} {{at least}} 3 disjoint paths between any communicating pair. It uses alternate source for every sender to ensure availability of 3 disjoint paths. 3 D-CGIN {{is compatible with}} distance tag routing and destination tag routing schemes. These methods prove quite useful in 3 D-CGIN. In the presence of faults, the new path is searched from source to destination. In order to tolerate faults, extra processing is required for selection of new path and diverting/resending the packets on that new path. Generally, the extra processing causes increase in processing time or hop count. To gain the advantage of multiple disjoint paths, we must carefully design the routing scheme, such that, it can minimize extra processing while tolerating the faults. We feel that, use of timely updated network status will certainly help in improving the routing. In 3 D-CGIN, we introduce such network status aware strategies. This paper introduces two such schemes, which use pre-computing of routing tags. These methods use the network status to avoid paths with faulty nodes. The paper first discusses the routing in Destination Tag and <b>rerouting.</b> The <b>network</b> 3 D-CGIN can tolerate a maximum of 6 faults in worst case, due to the additional link at initial stage. In this paper, we emphasis on various routing strategies those {{can be used with}} 3 D-CGIN architecture to improve the routing...|$|R
40|$|In {{circuit-switched}} networks it is {{well known}} that dynamic rout- ABSTRACT ing can provide significant throughput gain over fixed routing. Rerouting is the practice of routing calls currently on alternate paths to direct paths or other less congested alternate paths. Previous studies have shown t h a t rerouting can not only increase the throughput of dynamic routing, but also maintain network stability with-out the need for trunk reservation. This article presents a taxonomy of <b>rerouting</b> in circuit-switched <b>networks</b> showing the various ways rerouting can be designed. In addition, a Comoarative studv on a number of reroutina schemes are oerformed in a uniformly load-dynamic routing, a routing deci-sion be made at call arrival based on the network information available at that time. once a sequence of alternate Daths has been chosen, it is final, one ed, iully connectei circuit-switched network-n recent years, a variety of approaches to alter- I nate path routing networks have been dcveloped in the public switched telephone network (PSTN). AT&T ha...|$|R
40|$|The {{high data}} volumes being managed by and {{transferred}} through mobile {{networks in the}} last few years are the main rationale for the upsurge of research aimed at finding efficient technical means to offload exceeding traffic to alternative communication infrastructures with higher transmission bandwidths. This idea is solidly buttressed by the proliferation of short-range wireless communication technologies (e. g. mobile devices with multiple radio interfaces), which can be conceived as available opportunistic hotspots to which the operator can <b>reroute</b> exceeding <b>network</b> traffic depending on the contractual clauses of the owner at hand. Furthermore, by offloading to such hotspots a higher effective coverage can be attained by those operators providing both mobile and fixed telecommunication services. In this context, the operator must decide if data generated by its users will be sent over conventional 4 G+/ 4 G/ 3 G communication links, or if they will instead be offloaded to nearby opportunistic networks assuming a contractual cost penalty. Mathematically speaking, this problem can be formulated as a spanning tree optimization subject to cost-performance criteria and coverage constraints. This paper will elaborate on the efficient solving of this optimization paradigm by means of the Harmony Search meta-heuristic algorithm and the so-called Dandelion solution encoding, the latter allowing for the use of conventional meta-heuristic operators maximally preserving the locality of tree representations. The manuscript will discuss the obtained simulation results over different synthetically modeled setups of the underlying communication scenario and contractual clauses of the users. Ministerio de Economia y Competitividad (MINECO) España, TEC 2013 - 46766 -...|$|R
5000|$|Depending on the {{services}} to be offloaded {{and the business}} model {{there may be a}} need for interworking standardization. Standardization efforts have focused on specifying tightly or loose coupling between the cellular and the Wi-Fi networks, especially in a network-controlled manner. 3GPP based Enhanced Generic Access Network (...) architecture applies tight coupling as it specifies <b>rerouting</b> of cellular <b>network</b> signaling through Wi-Fi access networks. This makes Wi-Fi a de facto 3GPP RAN. 3GPP has also specified an alternative loosely coupled solution for Wi-Fi. The approach is called Interworking Wireless LAN (IWLAN) architecture and it is a solution to transfer IP data between a mobile device and operator’s core network through a Wi-Fi access. In the IWLAN architecture, a mobile device opens a VPN/IPsec tunnel from the device to the dedicated IWLAN server in the operator’s core network to provide the user either an access to the operator’s walled-garden services or to a gateway to the public Internet. With loose coupling between the networks the only integration and interworking point is the common authentication architecture.|$|R
40|$|Pre-congestion {{notification}} (PCN) provides {{feedback about}} load conditions {{in a network}} to its boundary nodes. The PCN working group of the IETF discusses the use of PCN to implement admission control (AC) and flow termination (FT) for prioritized realtime traffic in a DiffServ domain. Admission control (AC) is a well-known flow control function that blocks admission requests of new flows {{when they need to}} be carried over a link whose admitted PCN rate already exceeds an admissible rate. Flow termination (FT) is a new flow control function that terminates some already admitted flows when they are carried over a link whose admitted PCN rate exceeds a supportable rate. The latter condition can occur in spite of AC, e. g., when traffic is <b>rerouted</b> due to <b>network</b> failures. This survey gives an introduction to PCN and is a primer for this new technology. It presents and discusses the multitude of architectural design options in an early stage of the standardization process in a comprehensive and streamlined way before only a subset of them is standardized by the IETF. It brings PCN from the IETF to the research community and serves as historical record...|$|R
40|$|Abstract—Pre-congestion {{notification}} (PCN) provides {{feedback about}} load conditions {{in a network}} to its boundary nodes. The PCN working group of the IETF discusses the use of PCN to implement admission control (AC) and flow termination (FT) for prioritized realtime traffic in a DiffServ domain. Admission control (AC) is a well-known flow control function that blocks admission requests of new flows {{when they need to}} be carried over a link whose admitted PCN rate already exceeds an admissible rate. Flow termination (FT) is a new flow control function that terminates already some admitted flows when they are carried over a link whose admitted PCN rate exceeds a supportable rate. The latter condition can occur in spite of AC, e. g., when traffic is <b>rerouted</b> due to <b>network</b> failures. This survey gives an introduction to PCN in an early stage of the standardization process. It presents and discusses the multitude of architectural design options for PCN in a comprehensive and streamlined way before only a subset of them is standardized by the IETF. It brings PCN from the IETF to the research community and serves as historical record. I...|$|R
40|$|Abstract—Multi-topology routing is an {{increasingly}} popular IP network management concept that allows transport of different traffic types over disjoint network paths. The concept {{is of particular}} interest for implementation of IP fast reroute (IP FRR). First, it can support guaranteed, instantaneous recovery from any link or node failure as well as from many combined failures. Second, different failures result in routing over different network topologies, which gives better control of the traffic distribution in the networks after a failure. Multiple Routing Configurations (MRC) [1] is the state-of-the-art IP FRR scheme based on multi-topology routing today. In this paper we present a new, enhanced IP FRR scheme which we call “relaxed MRC ” (rMRC). rMRC simplifies the topology construction and increases the routing flexibility in each topology. According to our experimental evaluation, rMRC has several benefits compared to MRC. The number of backup topologies required to provide protection against the same set of failures is reduced, hence reducing state in routers. In addition, the backup paths are shorter, and the link utilization is significantly better. The paper also presents how rMRC can provide recovery from multiple correlated failures without compromising much on the number of backup topologies required and the path lengths. Index Terms—IP fast <b>reroute,</b> multi-topology routing, <b>network</b> protection, network utilization, correlated failures, shared risk groups. I...|$|R
40|$|Abstract. We study {{a problem}} {{motivated}} by a scheme for supporting fast restoration in MPLS and optical networks. In this local restoration scheme detour paths are set-up a priori and network resources are pre-reserved exclusively for carrying <b>rerouted</b> traffic under <b>network</b> failures. (i. e. they do not carry any traffic under normal working conditions). The detours are such that failed links can be bypassed locally from the first node that is upstream from the failures. This local bypass activation from the first detection point for failures along with the dedication of network resources for handling failures permits very fast recovery times, a critical requirement for these networks. By allowing sharing of the dedicated resources among different detours the local restoration scheme results in efficient utilization of the pre-reserved network capacity. In this paper {{we are interested in}} the problem of dedicating the least amount of the currently available network capacity for protection, while guaranteeing fast restoration to the existing traffic along with any traffic that may be admitted in the future. We show that the problem is NP-hard, and give a 2 -approximation algorithm for the problem. We also show that the integrality gap of a natural relaxation of our problem is Ω(n), thus establishing that any LP-based approach using this relaxation cannot yield a better approximation algorithm for our problem. ...|$|R
40|$|This paper {{presents}} {{experimental studies}} of several well-known shortestpaths algorithms adapted {{to the task of}} finding the k-successively-shortest link-disjoint replacement paths for restoration in a telecommunications network with n nodes. The implementations range in complexity from O(kn) when based on Dijkstra's original method, through several improvements to an efficient implementation of O(kn[v+logn]) complexity, and finally to an O(kn) implementation for the special case of edge-sparse graphs with small integer edge weights. Here n is the maximum degree of a node in the network. Several alternatives were tested during the course of these studies, particularly with a view to minimizing the number of heap updates. These alternatives are possible because we are searching for several paths between a given pair of nodes, rather than just one path between one or more pairs of nodes. Two fairly straightforward changes yield a decrease in execution time, whereas a more complex heap management strategy consumes as much time in the added code as it releases from the main routine. Experimental results confirm the theoretical complexity of O(kn log n) and demonstrate a speed-up of nearly an order of magnitude over the simpler O(kn) implementation in the largest networks tested. The optimized implementation is recommended for planning and operational applications of k-shortest paths <b>rerouting</b> for telecommunications <b>network</b> restoration and restorable network design. If hop counts or small integer link weights can be used to measure distances, then the O(kn) implementation is recommended, as typical telecommunications networks are edge-spars...|$|R
40|$|The {{advent of}} Internet and the {{globalization}} have modified {{the forms of}} communication {{in the world and}} the enterprises. All this has brought the search of facilities of communications permanents and secures with quality of service to improve the Internet The studies of the news networks with MPLS are in a process that consists in finding news focus to improve the quality of service and rerouting. This thesis consists in analyzing and simulates MPLS with DiffServ to demonstrate that the use of the L-LSP is a good solution to improve the throughput in the network. The other side, it proposes a new method for updating time to <b>rerouting</b> in the <b>network</b> uses OSPF. Finally, it does an analysis and simulation of the network behavior, in case of the fail a link. It is to say the resilence of the network. se realiza; un estudio de las nuevas arquitecturas como IntServ, DiffServ, MPLS, un análisis y simulación el comportamiento de una red MPLS con Servicios Diferenciados con L-LSPs con múltiples rutas en una red. También se propone un algoritmo predictivo para la determinación del ancho de banda disponible para cada enlace en cada nodo de una red MPLS-DiffServ y establecer la mejor ruta de extremo a extremo, durante el periodo de actualización de datos de ancho de banda disponible usando el protocolo OSPF lo que permite mejorar el re-enrutamiento y finalmente se realiza un análisis de la red MPLS-DiffServ para el re-enrutamiento en caso de pérdida de un enlace. Tesi...|$|R
40|$|Cloud Computing {{has seen}} a {{tremendous}} popularity in last several years. A scalable and efficient data center network is essential for a performance capable cloud computing infrastructure. This thesis provides practical solutions to enable an efficient, flexible, multi-tenant network architecture suitable for high-performance cloud computing, using InfiniBand (IB) as a demonstration technology. The work is motivated by {{the needs of the}} future data centers to provide efficient cloud solutions for increasing uptake of the cloud technology for both big data and traditional High-Performance Computing (HPC) applications. Research contributions of this thesis lie within three main categories. First, we propose a set of improvements to the fat-tree routing algorithm to make it suitable for HPC workloads in the cloud. Fat-Tree is a popular network topology in HPC systems. Our proposed improvements to the fat-tree routing make it more efficient, provides performance isolation among tenants in multi-tenant systems, and enable routing of both physical end nodes and virtualized end nodes according to the policies set by the provider. Second, we design new network reconfiguration methods to significantly reduce {{the time it takes to}} <b>reroute</b> the IB <b>network.</b> Reduced network reconfiguration time means that the interconnection network in a HPC cloud can optimize itself quickly to adapt to changing tenant configurations, faults, running workloads, and current network conditions. Last, we demonstrate a self-adaptive network prototype for IB-based HPC clouds, fully equipped with autonomous monitoring and adaptation, and configurable through a high-level condition-action language for the service providers. The research conducted in this thesis has potential impacts on both private cloud infrastructures, such as medium sized clusters used for enterprise HPC, and public clouds offering innovative HPC solutions to the customers at scale. The industrial application of the thesis is reflected by the eight patent applications resulted from this work...|$|R
40|$|Chromosome 22 q 11. 2 {{deletion}} syndrome (22 q 11 DS) is {{a genetic}} disease known {{to lead to}} cerebral structural alterations, which we study using {{the framework of the}} macroscopic white-matter connectome. We create weighted connectomes of 44 patients with 22 q 11 DS and 44 healthy controls using diffusion tensor magnetic resonance imaging, and perform a weighted graph theoretical analysis. After confirming global network integration deficits in 22 q 11 DS (previously identified using binary connectomes), we identify the spatial distribution of regions responsible for global deficits. Next, we further characterize the dysconnectivity of the deficient regions in terms of sub-network properties, and investigate their relevance with respect to clinical profiles. We define the subset of regions with decreased nodal integration (evaluated using the closeness centrality measure) as the affected core (A-core) of the 22 q 11 DS structural connectome. A-core regions are broadly bilaterally symmetric and consist of numerous network hubs - chiefly parietal and frontal cortical, as well as subcortical regions. Using a simulated lesion approach, we demonstrate that these core regions and their connections are particularly important to efficient network communication. Moreover, these regions are generally densely connected, but less so in 22 q 11 DS. These specific disturbances are associated to a <b>rerouting</b> of shortest <b>network</b> paths that circumvent the A-core in 22 q 11 DS, "de-centralizing" the network. Finally, the efficiency and mean connectivity strength of an orbito-frontal/cingulate circuit, included in the affected regions, correlate negatively with the extent of negative symptoms in 22 q 11 DS patients, revealing the clinical relevance of present findings. The identified A-core overlaps numerous regions previously identified as affected in 22 q 11 DS as well as in schizophrenia, which approximately 30 - 40 % of 22 q 11 DS patients develop...|$|R
40|$|In {{this thesis}} we {{considered}} minimizing energy consumption with and providing QoS in WSN {{which is very}} important nowadays. In this work we developed a cross-layer protocol that operated with MAC and network layer, it introduces QoS and wake and sleep states. We evaluate {{to see if this}} new design has an effect on the energy consumption of the wireless sensor network deployment in the simulated environment. In recent years many researches have been done in WSN considering energy consumption which will increase the network lifetime. QoS, which enables reliable data transmissions by providing some guarantees, is also considered. QoS refers to the traffic controlling or traffic shaping by delivering the data in a best effort fashion, such as providing guaranteed packet delay or network throughput. There are several energy consumption protocols being investigated like S-MAC, TMAC, B-MAC, WISEMAC and X-MAC. S-MAC and T-MAC exchange the time schedules of data between nodes. This exchanging of time schedules is a heavy burden on the network and they reduce the life time of the network. B- MAC and WISEMAC depend on low power listening by sending long preamble that is long enough as sleep period of the receiver. This long preamble will create overhearing problem by making the non receivers to stay awake until preamble is fully received. Long preamble is a problem in target receivers because the target receiver must stay idle until the receiving of the preamble is finished, which will waste energy. In X-MAC short preamble is sent instead of long preamble and the time schedules are not exchanged between nodes which will save time and energy in the network. Because of this short preamble the source can get early acknowledgment so the data can be sent immediately and the node can go to sleep early, which is a big advantage compared to other protocols. In this work, we provide an adaptive cross-layer design for energy-efficient wireless communication in sensor networks. We modify and integrate the X-MAC protocol with random <b>rerouting</b> in the <b>network</b> layer to provide QoS in data delivery, while minimizing the energy consumption. We evaluate the performance of our design by extensive simulations in OMNET++ in terms of packet delay and energy consumption...|$|R
40|$|This thesis {{focuses on}} the {{analysis}} of the rerouting times in UNINETT, the Norwegian research <b>network.</b> <b>Rerouting</b> happens in case of a topology change of the network, and the routers have to calculate new paths to all destinations. The downtimes due to rerouting is a major contributor to the overall service unavailability. Because of this it is of interest to study the different components of these downtimes, and propose changes to speed up the rerouting process. The main goal for the thesis is to improve the service availablility in UNINETT. In UNINETT there are measurements of periods of packet loss available. These measurements, as well as the statistics from the network nodes, are analysed and the results are presented in this thesis. UNINETT is a network with IS-IS as the routing protocol, and fault handling by path restoration. Fault handling by path restoration means there is no spare capacity to switch to in case of a link or node failure. All routers in the network have to be updated about the topology change, and find new paths around the failure. The delay to update the network nodes to a common stable view, is called the convergence time. During this period it is observed packet loss, and it is of interest to make this period as short as possible. The reason for the packet loss during the convergence time is the inconsistency in the router's routing and forwarding tables. The construction of transient loops between nodes can happen in this phase. This will impose extra load to the network, delay, and in worst case loss of packets. These loops are called micro loops and increase the downtime during the convergence period. The parametrization in IS-IS is studied, and changes to the parameter values are proposed. Too much tuning of the parameters may introduce instability in the network, which increase the load to the nodes and links. This can lead to even longer convergence time, and periods with packet loss. The recommended values are tested in a small test lab replicating parts of the topology of Northern Norway in UNINETT. The results from the test are compared with a case study of a failure on the Trondheim-Troms?? link in UNINETT. The observations from the case study show a typical delay of up to 10 s for the convergence time. The results from the test lab show {{that it is possible to}} achieve sub-second convergence time, without any compromise on the stability of the network. Due to the small scale of the test lab, the traffic intensity was too low to observe any overload to the nodes or links. This may be a problem in a full scale network like UNINETT, and further testing is recommended before the proposed changes to the parameters are implemented in any production network. The fault handling in UNINETT is also studied, which includes the contribution from the different components to the convergence time. The observations and results from the mentioned case study and test lab are used in this study too. It is observed that the timer delay before the "Shortest Path Tree" computation is run in the routers, is the major contributor to the convergence time. This is improved by tuning the SPT timers, as observed in the results from the test lab. The failure detection and flooding components are also large contributors to the convergence time. The test lab shows that the failure detection is improved by tuning the hello parameters in IS-IS, but a less processor intensive method called BFD is recommended for further study. The parameters triggering the data-link layer timers may also be a possibility to speed up the failure detection, but this is not further investigated in the thesis. The flooding component is reduced by enabling the fast flooding command. The phenomena of micro loops is studied, and the method called oFIB is recommended for implementation in UNINETT. Micro loops are a small contributor to the convergence time in UNINETT today, but the customers' requirements for service availability are increasing, and the necessity of a solution is in near future. In addition to the oFIB method, a fast repair technique like IPFRR may eliminate almost all downtimes during rerouting in UNINETT, but this is subjects for further studies. </p...|$|R

