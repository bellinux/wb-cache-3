30|0|Public
5000|$|... #Subtitle level 2: Post-war {{decommissioning}} and <b>redocumentation</b> ...|$|E
5000|$|Rediscovery by F. R. Taylor, R. R. Miller (the {{original}} describer), J. W. Pedretti, and J. E. Deacon {{documented in}} [...] "Rediscovery of the Shoshone Pupfish Cyprinodon nevadensis shoshone (Cyprinodontidae), at Shoshone Springs, Inyo County, California". published in Bull. Southern California Acad. Sci. 87(2), 1988, pp 67-73. The rediscovery date is 31 July 1986 in which caudal ray count {{differed from the}} original description. Note: although rediscovered, this pupfish does not enjoy ENDANGERED SPECIES STATUS and its present survival is unverified by <b>redocumentation.</b>|$|E
50|$|Reverse {{engineering}} has {{its origins}} {{in the analysis of}} hardware for commercial or military advantage. However, the reverse engineering process in itself is not concerned with creating a copy or changing the artifact in some way; it is only an analysis in order to deduce design features from products with little or no additional knowledge about the procedures involved in their original production. In some cases, the goal of the reverse engineering process can simply be a <b>redocumentation</b> of legacy systems. Even when the product reverse engineered is that of a competitor, the goal may not be to copy them, but to perform competitor analysis. Reverse engineering may also be used to create interoperable products; despite some narrowly tailored US and EU legislation, the legality of using specific reverse engineering techniques for this purpose has been hotly contested in courts worldwide for more than two decades.|$|E
40|$|This paper {{presents}} {{data from}} a long-term (four year) case study {{of the effects of}} incremental software <b>redocumentation</b> of data communications services software that is a part of a check processing system. It presents data on the relative cost and completeness of the incremental <b>redocumentation</b> and its impact on programmer productivity and cost of the software change. The break-even point occurred after 1. 5 years of effort, which means that the extra investment in <b>redocumentation</b> started paying off after 1. 5 years of <b>redocumentation</b> activity. ...|$|E
40|$|This paper {{describes}} an evaluation on software documentation generated using <b>redocumentation</b> approaches and tools. The evaluation {{is based on}} the selected Document Quality Attributes (DQA). Firstly, the paper presents an overview of the software <b>redocumentation</b> and the main components involved in the process for better understanding of the <b>redocumentation.</b> Consequently, several approaches and tools are highlighted in the context of aiding understanding to support the software evolution. Finally, the evaluation identifies some aspects of DQA that might benefit from refinement to better reflect the <b>redocumentation</b> approaches and tools capabilities that support the software maintenance...|$|E
40|$|Redocumentaion {{covers the}} {{understanding}} of the software and record the software comprehension for easier understanding in future. So, <b>redocumentation</b> is the key to software maintainability. This paper describes the comparison among two approaches of <b>redocumentation</b> by comparing their working to regenerate the document of existing system. In Incremental <b>Redocumentation,</b> software comprehension is recorded in hypertext in the style of World Wide Web by using PAS tool where in Model Oriented Redocumentation; generate the documentation based on the models to bridge the gap of a legacy system and evolved system...|$|E
40|$|Abstract. The article {{describes}} the method of <b>redocumentation</b> of legacy software intended for using insoftware reengineering. Documents that are created in <b>redocumentation</b> should meet the requirements ofsoftware development technology {{to be used in}} forward engineering. Software document models located atdifferent abstract levels are proposed: model of software document, meta-model of the document of thedevelopment technology, model of the development technology document. The models created are used in themethod implementation based on the model-driven approach. According to this approach, redocumentationis considered to be the process of creating a set of legacy software documents by transformation models ofdocuments, the documents contents being formed on the basis of legacy software views set. Keywords: legacy software, model-driven approach, model of document, <b>redocumentation...</b>|$|E
40|$|The article {{considers}} development technology oriented {{method of}} legacy software redocumentation; software document model. It is proposed <b>redocumentation</b> document description language RDDL. ? ?????? ??????????????? ????? ?????????????????? ???????????? ???????????? ???????????, ??????????????? ?? ?????????? ??????????; ?????? ????????? ???????????? ???????????. ????????? ???? ???????? ?????????? ??? ?????????????????? RDDL...|$|E
40|$|This paper {{discusses}} {{aspects of}} the <b>redocumentation</b> of legacy systems and proposes a model oriented approach to generating documentation, which is to produce models from existing systems and to generate the documentation based on the models. Since the software models can bridge the gap of a legacy system and an evolved system, the generated documentation covers all the information of system evolution. A prototype software <b>redocumentation</b> tool is presented to semi-automate this process and {{a case study of}} a system in IBM assembler is used for experiments with the approach and the prototype tool...|$|E
40|$|The primary {{aim of this}} {{research}} is to investigate means of improving program comprehension through <b>redocumentation.</b> In particular it will concentrate on using Literate Programming as a method for program <b>redocumentation.</b> Documentation is crucially important as an aid to understanding software systems. The Incremental <b>Redocumentation</b> Using Literate Programming System analyses the existing source code and merges in a range of other information, {{in order to create a}} complete documentation package. This may include not only traditional paper documents, but also hypertext facilities, animated specifications and output from other analysis tools. The status of the documentation is implicitly elevated to that of an integral part of the system, rather than an optional extra. Where a configuration management system is used to manage different versions of a system, the documentation can also be brought under its control. The literate programming paradigm provides the encouragement and capability to produce high quality code and documentation simultaneously. Conceptually, literate programming systems are document preparation systems. The primary goal of a literate program is to be understandable to the programmers who are going to have to read it at some later date - often while involved in maintenance, or perhaps when trying to determine the possibility of reusing parts of the code for later projects. This thesis presents a structures of C programs and literate C programs, and describes the features of captured literate C programs. A method of the capture process and also the functions of the <b>redocumentation</b> process are described. In addition, this thesis outlines how the individual stages in the capture process and the edit process are used to redocument a C program. The results of application of the process are highlighted by way of example programs. The evaluation process is performed by comparing the results of an existing literate program with those resulting from the application of the method described within this thesis. The results have shown that the captured redocumented literate C program is more readable and understandable than source code only, and that it provides a basis for subsequent maintenance and further <b>redocumentation...</b>|$|E
40|$|Most {{approaches}} for recovering objects from procedural code are exclusively based on static information. These approaches {{have the advantage}} to build on information easily available. However, with code that is not built around very strong and ubiquitous data structures, substantial portions of this code cannot be clearly {{assigned to one of}} the objects the object-oriented system is made of. Here, we discuss an approach where the uncertainties that necessarily appear with purely data-structure driven approaches can be reduced by establishing in addition to the static object model a dynamic object model. The merits of the approach extend object recovery though. We consider the creation of event-state diagrams also useful for software <b>redocumentation</b> as well as for general program understanding. keywords: object recovery, program understanding, <b>redocumentation,</b> software reuse 1. Motivation One of the key question that links software maintenance, software reverse engineering, and softwa [...] ...|$|E
40|$|International audienceOur {{activities}} {{are becoming more}} and more computer-mediated. For documenting these activities, it is no longer sufficient to automatically record their traces. In this paper we introduce the <b>redocumentation</b> process of computer-mediated activity as a narrative construction that ties together the content of activity traces and the users’ knowledge in describing their activities in new easily exchangeable documents. We present a generic semi-automatic approach for this process, which is based on rhetorical structure theory. This approach uses formal models for process input and output, and handles the process through two main phases: an automatic phase to generate a fragmented document from traces as a first description of the activity and an interactive phase to allow the user to tailor this first description according to his particular needs and choices. We also present ActRedoc, a tool developed for text-based <b>redocumentation,</b> for which a first evaluation was conducted...|$|E
40|$|In {{this paper}} we present an {{algebraic}} support formalization in a software maintenance method named COMFORM (COnguration Management FORmalization for Maintenance). One of {{the aims of}} COMFORM is <b>redocumentation</b> by keeping the maintenance history and information related to the software modules being maintained. <b>Redocumentation</b> is obtained by lling in pre-dened form templates which {{go hand in hand}} with the phases of the method. The algebraic model formalizes the hierarchically structured form templates of the method. This results in enhanced functionality, including automatic propagation of changes during the manipulation of its form templates as well as dynamic creation of useful views of forms in the maintenance history of a system. Thus COMFORM is able to support a wide range of existing software systems with various proles. 1 Introduction The last two decades have seen the promotion of software development as an engineering activity, encouraging the use of more rigorously dened so [...] ...|$|E
40|$|UML {{diagrams}} {{are widely}} employed for modeling of object-oriented software systems. In {{addition to their}} application in forward engineering, {{it is also possible}} to use them for the <b>redocumentation</b> of existing programs. However, the inherent structure of UML diagrams, which consists of graphical as well as textual information, makes it difficult to read and oversee large diagrams generated from complex systems. The view on such diagrams can be compared with taking a look at a detailed map: the reader has to decide whether to read the fine details or to view the whole structure...|$|E
40|$|Abstract: This {{paper is}} an attempt to define what {{software}} reengineering is and what it has accomplished in the light of 20 years of practical application. The paper points out that reengineering {{is one of the many}} software maintenance activities, i. e. everything done with software once it has been put to use. Reengineering actions are devoted to improving the technical quality of existing software. By accepting this definition, it is possible to distinguish reengineering from other related activities performed on a software product after its first release such as reverse engineering, <b>redocumentation,</b> evolution and migration...|$|E
40|$|One of {{the major}} {{problems}} associated with the maintenance of existing software systems is their lack of documentation. This can make very large, poorly structured programs very difficult to maintain. Nearly all traditional documentation tools are either designed for use in the development stage of the software lifecycle or are report generators such as cross reference generators. The problems of lack of documentation are compounded when applied to third party software maintenance as the staffs are often initially unfamiliar with the code they are maintaining. This thesis describes these problems in detail and evaluates the feasibility of a tool to help with <b>redocumentation</b> based on current hypertext technology...|$|E
40|$|E-commerce systems must {{react in}} {{real-time}} to user inputs and business rules. For {{the purpose of}} <b>redocumentation,</b> static analysis is often adopted to recover business processes implemented in ecommerce systems. However, static analysis fails to recover the complete tasks in business processes due to the dynamic nature of e-commerce systems. To improve the accuracy of recovered business processes, we devise dynamic analysis techniques which trace the execution of processes. We recover usage scenarios from the execution logs {{and use them to}} verify the business processes recovered using static analysis. We verify the effectiveness of our proposed approach through a case study on OFBiz e-commerce applications. 1...|$|E
40|$|Today {{especially}} large {{organizations are}} not only faced {{with the problem of}} replacing their information systems with completely new ones, but they have to maintain and gain control over their legacy applications. Reverse engineering provides the means for this purpose supporting in recapturing lost information, restructuring complex systems or transforming old systems to a new and more maintainable architecture. This paper introduces the basic concepts of reverse engineering, clarifies related terms and indicates important reverse engineering approaches. Furthermore, a particular reverse engineering methodology for re-architecturing legacy applications is introduced and its impact on software engineering is discussed. Keywords: reverse engineering, re-engineering, software engineering, <b>redocumentation,</b> restructuring, design recovery, re-architecturing. INTRODUCTION For many years software engineering primarily concentrated on the development of new applications. Much research as wel [...] ...|$|E
40|$|Software process {{improvement}} is an iterative activity, normally involving measurement, analysis, and change. For most organizations, the existing software process has substantial momentum and is seemingly immovable. Any change to existing process activities causes turbulence in the organization, {{which can be}} a significant barrier to adoption of the quality improvement initiative. This paper presents a quiescent, non-invasive, and adoption-centric approach to {{process improvement}} for software maintenance. The approach realizes the goal of improving the efficiency of existing processes by minimizing changes to existing workflows and focusing on integrating enhancements at the micro-level of the system. By leveraging information buried in existing data, making it explicit, and integrating the results with known facts, more informed decision-making is made possible. The approach is illustrated with a model problem concerning <b>redocumentation</b> of an embedded control system in the context of performing higher-quality software maintenance...|$|E
40|$|Introduction Making {{decisions}} about the destiny of the software portfolio is today one dominant concern for those business organizations that own legacy systems. There is a number of options available in managing legacy systems. Typical solutions include: discarding the system and building a replacement one; freezing the system and {{using it as a}} component of a new larger system; modifying the system to give it another lease of life. Modifications may range from a simplification of the system (reduction of size and complexity) to ordinary preventive maintenance (<b>redocumentation,</b> restructuring and reengineering) or even to an extraordinary process of adaptive maintenance (interface modification, wrapping and migration). These possibilities are not alternative to each other but making decisions on which approach, or combination of approaches, is most suitable for any particular legacy system are usually taken on the basis of conventional wisdom. Like any decision process, it req...|$|E
40|$|The {{importance}} of Reverse Software Engineering (RSE) has increased over recent years [1]. Much of this interest has arisen {{due to the}} requirement to understand existing software {{for the purposes of}} maintenance and development. Often tasks within RSE (for example <b>redocumentation)</b> can be performed effectively using conventional techniques. However, some operations, such as the automatic synthesis of high level abstractions, have proven to be difficult using such techniques. This paper examines the novel application of artificial neural networks (ANN) to the problems presented by RSE. The paper is divided into four sections. The first section briefly outlines RSE and the reader is referred to key papers and review articles. The second section highlights potential areas within RSE that would benefit from the application of ANN based technology. The third section describes a prototype hybrid system incorporating both conventional technology and ANN based technology, and design expertise fro [...] ...|$|E
40|$|Program {{understanding}} tools typically offer built-in visual {{representations of}} the subject software, such as call graphs and class hierarchies, and textual representations, such as cross-reference listings and exact-interface reports. It is useful to bundle {{a number of these}} visual and textual frames, with some annotation, into a view for <b>redocumentation</b> purposes. For large, legacy software systems, however, the abundance of created views can be a major problem. This paper investigates a number of methods for improving the organization of these views for improved usability and scalability. 1 Introduction Many software systems have internal documentation that is often out-of-date and thus unreliable. Even when the documentation exists, it may be dispersed in several places and may not be well structured. Yet accurate, complete, well-organized, and maintainable documentation is critical for soft- This work {{was supported in part by}} the Natural Sciences and Engineering Research Council [...] ...|$|E
40|$|In this thesis, {{two methods}} are {{developed}} in {{an aid to}} help users capture valuable design information and knowledge and reuse them. They are the design pattern recovery (DPR) method and pattern-based <b>redocumentation</b> (PBR) method. The DPR method is for matching up metrics of patterns with patterns themselves in order to capture valuable design information. Patterns are used as a container for storing the information. Two new metrics, i. e., p-value and s-value are introduced. They are obtained by analysing product metrics statistically. Once patterns have been detected from a system, the system can be redocumented using these patterns. Some existing XML (extensible Markup Language) technologies are utilised in order to realise the PRB method. Next, a case study is carried out to validate the soundness and usefulness of the DPR method. Finally, some conclusions drawn from this research are summarised, and further work is suggested for the researchers in software engineering...|$|E
40|$|In {{order to}} {{maintain}} the consistency between sources and documentation, {{while at the same time}} providing documentation at the design level, it is necessary to generate documentation from sources in such a way that it can be integrated with hand-written documentation. In order to simplify the construction of documentation generators, we introduce island grammars, which only define those syntactic structures needed for (re) documentation purposes. We explain how they can be used to obtain various forms of documentation, such as data dependency diagrams for mainframe batch jobs. Moreover, we discuss how the derived information can be made available via a hypertext structure. We conclude with an industrial case study in which a 600, 000 LOC COBOL legacy system is redocumented using the techniques presented in the paper. 1991 ACM Computing Classi#cation System: D. 2. 2, D. 2. 5, D. 2. 7, D. 3. 4 Keywords and Phrases: <b>Redocumentation,</b> legacy systems, documentation generation, source code analy [...] ...|$|E
40|$|The digital world {{enables the}} {{creation}} of personalized documents. In this paper {{we are interested in}} describing a computer mediated activity by a person throughout a semi-automatic <b>redocumentation</b> process. This process uses traces generated automatically, during a user-system interaction, to assist a person in producing a personalized document describing the traced activity. To support that, a general framework for an authoring tool is proposed through two main phases. During the first phase, an automatic and parameterized transformation is applied on the input activity trace to generate a fragmented document. Each fragment describes one or many observed elements of the modeled trace and relations between fragments are deduced from relations between these elements. The second phase consists in interactive transformations on the intermediate produced document until getting the final hypermedia document. Our authoring tool uses composition of personalized document issues and RST principals to interpret user's choices and to maintain the coherence of the produced document...|$|E
40|$|Abstract—Understanding {{source code}} identifiers, by {{identifying}} words composing them, {{is a necessary}} step for many program comprehension, reverse engineering, or <b>redocumentation</b> tasks. To this aim, researchers have proposed several identifier splitting and expansion approaches such as Samurai, TIDIER and more recently GenTest. The ultimate goal of such approaches is to help disambiguating conceptual information encoded in compound (or abbreviated) identifiers. This paper presents TRIS, TRee-based Identifier Splitter, a two-phases approach to split and expand program identifiers. First, TRIS pre-compiles transformed dictionary words into a tree representation, associating a cost to each transformation. In a second phase, it maps the identifier splitting/expansion problem into a minimization problem, i. e., the search of the shortest path (optimal split/expansion) in a weighted graph. We apply TRIS {{to a sample of}} 974 identifiers extracted from JHotDraw, 3, 085 from Lynx, and to a sample of 489 identifiers extracted from 340 C programs. Also, we compare TRIS with GenTest on a set of 2, 663 mixed Java, C and C++ identifiers. We report evidence that TRIS split (and expansion) is more accurate than state-of-the-art approaches and that it is also efficient in terms of computation time...|$|E
40|$|Many {{software}} maintenance and enhancement tasks require considerable developer {{knowledge and experience}} {{in order to be}} efficiently completed on today’s large and complex systems. Preserving explicit forms of documentation that are accessible by large development teams with regular developer turnover is a difficult problem. This problem can result in temporal and spatial miscommunication, an easily lost cognitive work context, and largely unmaintainable software. The research described in this paper hypothesizes that the problem may be addressed by a semi-structured goal-questionevidence methodology for program comprehension that has three primary aspects. First, a <b>redocumentation</b> system should function in parallel with the development process by integrating into the user’s usual tool environment and development workflow. Second, knowledge should be dispersed throughout a development team as soon as it is discovered so that comprehension is not merely confined to the mind of one individual. Finally, the developer should be made peripherally aware of their work objectives and the surrounding collaborative environment, reducing time spent on task reorientation, context reconstruction, and duplicative work. We present an observational study conducted on pair program comprehension and use the analyzed results to drive the formation of tool requirements for a collaborative comprehension tool. A prototype tool has been developed, showing promise for the methodology...|$|E
40|$|Software {{maintenance}} {{has until}} recently been the neglected {{phase in the}} software engineering process, {{despite the fact that}} maintenance of existing software systems may account for over half of all efforts expended by a software organization. Research into software maintenance, compared to other phases of the software engineering process is rare. Moreover, it is widely accepted that current software maintenance methods and techniques are unable to cope with the complexity inherent in maintaining software systems. This thesis is concerned with the development of a method, named Configuration Management Formalization for Maintenance (COMFORM), designed for the maintenance of existing software systems. COMFORM provides guidelines and procedures for carrying out a variety of activities performed during software maintenance. It accommodates a change control framework, around which the Software Configuration Management discipline is applied. <b>Redocumentation</b> is another problem tackled by COMFORM, which gathers together the documentation necessary to improve the maintainability and quality of existing software systems. This is achieved by the use of forms representing the output of each phase of a proposed software maintenance model. The information obtained by filling in forms is formalized according to a data model, which provides a common basis for the representation of the method's functionality. Finally, a prototype of COMFORM has been implemented, so that the procedures and guidelines set up by the method can be enforced and followed by its users...|$|E
40|$|Software reuse {{becomes more}} and more {{important}} in all fields of information management. It is influencing the creation of new tools and development environments as well as the modelling and development of applications and infrastructures. The report introduces this extensive field of software technology, points to important problems and explains typical terms. In this report, software reuse includes all activities realizing a repeated use of software objects. Particularly these are techniques which are named "Re-use" and "Re- engineering". A special issue is the field "Reverse- Engineering" because its methods on the one hand represent a part of Re-engineering {{and on the other hand}} they are independently used to rebuild documentation, design, and specification from an implementation. The main topics of this report are the fields of Re-engineering and Reverse engineering. There are introduced goals, methods and tools, whereby emphasis is given to <b>redocumentation,</b> recycling, renovation, and portability of "old" software. Problems of complexity and quality of software are discussed as well. In addition to these main topics further problems are analysed such as ways and strategies of Reuse, management and use of reusable software components, migration of programs and data and further more social, economical, juridical problems. The problem "Reuse and Software crisis" is critically commented and possibilities of solutions for the software crisis are proposed...|$|E
40|$|Zusammenfassung (dt.) Abstract: Recovering design {{information}} from legacy applications is a complex, expensive, quiet challenging, and time consuming task due to ever increasing complexity of software and advent of modern technology. The {{growing demand for}} maintenance of legacy systems, which can cope with the latest technologies and new business requirements, the reuse of artifacts from the existing legacy applications for new developments become very important and vital for software industry. Due to constant evolution in architecture of legacy systems, they often have incomplete, inconsistent and obsolete documents which do not provide enough information about the structure of these systems. Mostly, source code is the only reliable source of information for recovering artifacts from legacy systems. Extraction of design artifacts from the source code of existing legacy systems supports program comprehension, maintenance, code refactoring, reverse engineering, <b>redocumentation</b> and reengineering methodologies. The objective of approach used in this thesis is to recover {{design information}} from legacy code with particular focus on the recovery of design patterns. Design patterns are key artifacts for recovering design decisions from the legacy source code. Patterns have been extensively tested in different applications and reusing them yield quality software with reduced cost and time frame. Different techniques, methodologies and tools are used to recover patterns from legacy applications in the past. Each technique recovers patterns with different precision and recall rates due to different specifications and implementations of same pattern. The approach used in this thesis is based on customizable and reusable feature types which use static and dynamic parameters to define variant pattern definitions. Each feature type allows user to switch/select between multiple searching techniques (SQL queries, Regular Expressions and Source Code Parsers) which are used to match features of patterns with source code artifacts. The technique focuses on detecting variants of different design patterns by using static, dynamic and semantic analysis techniques. The integrated use of SQL queries, source code parsers, regular expressions and annotations improve the precision and recall for pattern extraction from different legacy systems. The approach has introduced new semantics of annotations {{to be used in}} the source code of legacy applications, which reduce search space and time for detecting patterns. The prototypical implementation of approach, called UDDPRT is used to recognize different design patterns from the source code of multiple languages (Java, C/C++, C#). The prototype is flexible and customizable that novice user can change the SQL queries and regular expressions for detecting implementation variants of design patterns. The approach has improved significant precision and recall of pattern extraction by performing experiments on number of open source systems taken as baselines for comparisons...|$|E

