397|1319|Public
25|$|As {{the stars}} in Westerlund 1 have the same age, {{composition}} and distance, the cluster represents an ideal environment for understanding the evolution of massive stars. The simultaneous presence of stars evolving on to and off of the Main Sequence presents a <b>robust</b> <b>test</b> for stellar evolution models, which are also currently unable to correctly predict the observed distribution of Wolf–Rayet subtypes in Westerlund 1.|$|E
2500|$|At 10:15 pm on July 2, {{a random}} {{sampling}} of 7,263 polling places (out of an original representative sampling of 7,636 polling places) was selected. Three statistical tests {{were performed on}} the sampling. A [...] "robust" [...] test, meant to provide conservative estimates as controls for the other two methods; a classic test; and a Bayesian test. The <b>robust</b> <b>test</b> predicted Calderón would get between 35.25% and 37.4% of the vote, versus 34.24% to 36.38% for López Obrador. The classic test predicted 35.68% to 36.53% for Calderón, versus 34.97% to 35.7% for López Obrador. The Bayesian test predicted Calderón with 35.77% to 36.40% versus López Obrador with 35.07% to 35.63% (see page 24 in the official report). Only the Bayesian test gave definitive results, but with a distance between intervals of less than 0.15%. Around 11 pm Luis Carlos Ugalde announced on live television that the technical committee had concluded the difference too small and that the race {{was too close to}} call. As per the original prior agreement between IFE and all political parties, Ugalde did not divulge the results of the Quick Count. Later that night, the representatives of the PAN and the Coalition For the Good of All requested that the results from the Quick Count be made public, while the representative of the Alliance for Mexico (the PRI and PVEM alliance whose candidate was Roberto Madrazo Pintado, who finished a distant third) requested that the prior agreement of confidentiality be respected. Contradictory rumors of whom the count had favored were beginning to surface, and the official report was released a few days later to the press and through the IFE's website to quash them.|$|E
50|$|As {{the stars}} in Westerlund 1 have the same age, {{composition}} and distance, the cluster represents an ideal environment for understanding the evolution of massive stars. The simultaneous presence of stars evolving on to and off of the Main Sequence presents a <b>robust</b> <b>test</b> for stellar evolution models, which are also currently unable to correctly predict the observed distribution of Wolf-Rayet subtypes in Westerlund 1.|$|E
40|$|An {{experimental}} {{system for}} computing <b>robust</b> <b>tests</b> for stuck-open faults in static CMOS circuits is presented. It constructs <b>robust</b> test-pairs from <b>tests</b> for stuckat faults by identifying several classes of FETs. <b>Robust</b> <b>tests</b> for stuck-open faults in FETs belonging to these classes are constructed from any stuck-at test set by carefully constructing initialization vectors. Initialization vectors are constructed {{by examining the}} "parity" of the paths in the circuit. <b>Robust</b> <b>tests</b> for additional faults are identified using stuck-open fault simulation. Experimental {{results show that the}} system can compute <b>robust</b> <b>tests</b> for a "very large" percentage of the stuck-open faults in a "reasonable" time. Index Terms: <b>Robust</b> <b>Tests,</b> Static CMOS Circuits, Stuck-open Faults, Test Generation. 1 Introduction Tests for stuck-open faults in static CMOS circuits consist of a sequence of two input vectors ! T 1; T 2 ?; an initial vector (T 1) and a final vector (T 2) [14]. Such tests for stuck-open faul [...] ...|$|R
40|$|Exogeneity {{testing is}} {{studied in the}} {{presence}} of outliers in response variables. <b>Robust</b> <b>tests</b> based on least absolute deviations (LAD) and M estimators are proposed and illustrated with an application to Mroz (1987) data. Our simulation results show that the proposed <b>robust</b> <b>tests</b> outperform the traditional Hausman test for exogeneity in terms of empirical power {{in the presence of}} outliers in response variables. Nevertheless, unlike the conventional Hausman test, which is undersized, the empirical size of the LAD-based exogeneity test exceeds its nominal size. Hausman exogeneity <b>test</b> <b>Robust</b> <b>tests</b> LAD estimator M estimator. ...|$|R
40|$|In {{this paper}} we analyze heteroskedasticity-autocorrelation (HAC) <b>robust</b> <b>tests</b> {{constructed}} using the Bartlett kernel without truncation. We show that while such an HAC estimator is not consistent, asymptotically valid testing is still possible. We show that tests using the Bartlett kernel without truncation are exactly equivalent to recent HAC <b>robust</b> <b>tests</b> proposed by Kiefer, Vogelsang and Bunzel (2000, Econometrica, 68, pp 695 - 714). ...|$|R
50|$|This is {{the current}} version. It is based on new {{standards}} for API and content object-to-runtime environment communication, with many ambiguities of previous versions resolved. Includes ability to specify adaptive sequencing of activities that use the content objects. Includes ability to share and use information about the success status for multiple learning objectives or competencies across content objects and across courses for the same learner within the same learning management system. A more <b>robust</b> <b>test</b> suite helps ensure good interoperability.|$|E
5000|$|In October 2010 a {{new company}} - Logica was awarded the {{contract}} for the vote counting system for the 2012 council elections, and since January 2011 testing has been under way to sort out many issues. On the 5 August 2011, A Dummy election {{was set up in}} Perth to test out new [...] "eCounting" [...] system, as part of <b>robust</b> <b>test,</b> in which 160,000 ballot papers run through the machine. This forms third stage of rigorous testing of the system in partition of these elections.|$|E
5000|$|At 10:15 pm on July 2, {{a random}} {{sampling}} of 7,263 polling places (out of an original representative sampling of 7,636 polling places) was selected. Three statistical tests {{were performed on}} the sampling. A [...] "robust" [...] test, meant to provide conservative estimates as controls for the other two methods; a classic test; and a Bayesian test. The <b>robust</b> <b>test</b> predicted Calderón would get between 35.25% and 37.4% of the vote, versus 34.24% to 36.38% for López Obrador. The classic test predicted 35.68% to 36.53% for Calderón, versus 34.97% to 35.7% for López Obrador. The Bayesian test predicted Calderón with 35.77% to 36.40% versus López Obrador with 35.07% to 35.63% (see page 24 in the official report). Only the Bayesian test gave definitive results, but with a distance between intervals of less than 0.15%. Around 11 pm Luis Carlos Ugalde announced on live television that the technical committee had concluded the difference too small and that the race {{was too close to}} call. As per the original prior agreement between IFE and all political parties, Ugalde did not divulge the results of the Quick Count. Later that night, the representatives of the PAN and the Coalition For the Good of All requested that the results from the Quick Count be made public, while the representative of the Alliance for Mexico (the PRI and PVEM alliance whose candidate was Roberto Madrazo Pintado, who finished a distant third) requested that the prior agreement of confidentiality be respected. Contradictory rumors of whom the count had favored were beginning to surface, and the official report was released a few days later to the press and through the IFE's website to quash them.|$|E
40|$|Abstract-Decentralized {{detection}} {{problems are}} studied where the sensor distributions are not specified completely. The sensor distributions {{are assumed to}} belong to known uncertainty classes. It is shown for a broad class of such problems that a set of least favorable distributions exists for minimax <b>robust</b> <b>testing</b> between the hypotheses. It is hence established that the corresponding minimax <b>robust</b> <b>tests</b> are solutions to simple decentralized detection problems for which the sensor distributions are specified {{to be the least}} favorable distributions. Index Terms-Decentralized detection, <b>robust</b> hypothesis <b>testing,</b> least favorable distributions, minimax optimization. T I. INTBODUCTI~N HE design of optimal decision rules in detection (hypothesis testing) problems requires the knowledge of th...|$|R
40|$|<b>Robust</b> {{slippage}} <b>testing</b> {{problems of}} a probability measure P̃ _ 0 against k (k geqq 2) probability measures P̃ _ 1, ldots, P̃ _k are considered. The problems are formulated as ones of testing a neighborhood mathcalp _ 0 of P̃ _ 0 aginst k neighborhoods mathcalp _ 1, ldots, mathcalp_k of tildeP _ 1, ldots, P̃ _k. Three methods for constructing <b>robust</b> <b>tests</b> are proposed and three types of <b>robust</b> <b>tests,</b> {{which are based on}} likelihood ratios of least favorable pairs between mathcalp _ 1 and mathcalp _j(i eq j), are constructed. Each of these three methods is typically applied to the case where mathcalp _i are described in terms of certain special capacities (ε -contamination, total variation). Several examples are also given. This work is a sequel of Kimura (1984) in which we embarked on the <b>robust</b> slippage <b>testing</b> problems...|$|R
40|$|This {{paper is}} devoted to <b>robust</b> {{hypothesis}} <b>testing</b> based on saddlepoint approximations {{in the framework of}} general parametric models. As is known, two main problems can arise when using classical tests. First, the models are approximations of reality and slight deviations from them can lead to unreliable results when using classical tests based on these models. Then, even if a model is correctly chosen, the classical tests are based on first order asymptotic theory. This can lead to inaccurate p-values when the sample size is moderate or small. To overcome these problems, <b>robust</b> <b>tests</b> based on dual divergence estimators and saddlepoint approximations, with good performances in small samples, are proposed. <b>Robust</b> <b>testing</b> Saddlepoint approximations Divergences M-estimators...|$|R
3000|$|... 2) {{significantly}} positive, {{with the}} result of control variables unchanged. 7 The <b>robust</b> <b>test</b> again verified proposition 1, indicating that the study conclusion would not alter due to changes of risk-taking variables in banks.|$|E
40|$|In {{this paper}} we propose a robust version of Cox-type test {{statistics}} for the choice between two non-nested hypotheses. We first show that the influence of small amounts of contamination in the data on the test decision can be very large. Secondly we build a <b>robust</b> <b>test</b> statistic by using the results on robust parametric tests available in the literature and show that the level of the <b>robust</b> <b>test</b> is stable. Finally, we show numerically not only the good property of robustness of this new test statistic, but also that its asymptotic distribution is a good approximation of its sample distribution, unlike for the classical test statistic...|$|E
40|$|In this article, {{a simple}} {{algorithm}} {{is used to}} maximize a family of optimal statistics for hypothesis testing with a nuisance parameter not defined under the null hypothesis. This arises from genetic linkage and association studies and other hypothesis testing problems. The maximum of optimal statistics over the nuisance parameter space {{can be used as}} a <b>robust</b> <b>test</b> in this situation. Here, we use the maximum and minimum statistics to examine the sensitivity of testing results with respect to the unknown nuisance parameter. Examples from genetic linkage analysis using affected sub pairs and a candidate-gene association study in case-parents trio design are studied. Genetic Analysis, Maximal Statistics, Nuisance Parameter, <b>Robust</b> <b>Test,...</b>|$|E
40|$|Submitted {{dissertation}} {{is focused}} on methods of <b>robust</b> normality <b>testing</b> and applications of <b>robust</b> <b>tests</b> in verifying hypothesis of the weak form of efficiency in stock markets. In the dissertation, theory of efficient markets and approaches to verifying the weak form of market efficiency and normality assumption are being discussed. Novel <b>robust</b> <b>testing</b> procedures of testing normality are proposed in this work to overcome shortcomings of classical normality tests {{in the field of}} financial data, which are typical with occurrence of remote data points and additional types of deviations from normality. Results of power simulation study of classical and <b>robust</b> <b>tests</b> of normality against several types of alternative distributions, i. e. symmetric heavy-tailed, symmetric light-tailed, asymmetric heavy-tailed, asymmetric light-tailed, selected mixtures of normal distributions and outlier models, are presented. Based on outcome of the power simulation study, selected normality tests were consequently used to verify the weak form of efficiency in stock markets in the Czech Republic, Hungary, Austria, Germany, Slovakia, United States and Japan during years 2000 - 2009. In addition to selected classical and <b>robust</b> normality <b>tests,</b> Ljung-Box portmanteau test was also used. In conclusion, there is a discussion and comparison of results carried out and future trends of these markets are outlined...|$|R
40|$|High {{breakdown}} point, bounded {{influence and}} high efficiency at the Gaussian model are desired properties of robust regression estimators. Robustness of validity, robustness of efficiency and high breakdown point size and power are the fundamental goals in <b>robust</b> <b>testing.</b> The {{objective of this}} dissertation {{is to examine the}} finite-sample properties of <b>robust</b> estimators and <b>tests,</b> and to find some useful applications for them. This is accomplished by extensive Monte Carlo experiments and other inference techniques in various contamination situations. In the linear regression model with an outlying regressor and deviations from the normal error distribution, robust estimators demonstrate noticeable advantages over the standard LS and maximum likelihood (ML) estimators. Our findings reveal that the finite-sample behavior of the robust estimators is very different from their asymptotic properties. The robust properties of estimators carry over to test statistics based on these estimators. The <b>robust</b> <b>tests</b> we proposed can achieve to the large extent the fundamental goals in <b>robust</b> <b>testing.</b> Economic applications on modelling the household consumption behavior and testing for (G) ARCH effects show that one can capture big gains from the appropriate utilization of the robust methods even at very simple models...|$|R
40|$|This article studies multivariate {{deterministic}} trend function testing {{when there}} are unknown structural changes in the volatility process. Several tests based on least squares estimation are analyzed and compared, and among them, one is robust to unknown nonstationary volatility. It is shown that the standard common trend tests of Vogelsang and Franses (2005) are generally non-pivotal, involving the volatility function in a complicated way. Additional <b>robust</b> <b>tests</b> are suggested by applying residual-based wild bootstrap to the detrended original time series, and are shown to be asymptotically valid under a wide class of nonstationary volatility. Simulations show that the proposed <b>robust</b> <b>tests</b> perform very well in …nite samples. JEL classi…cation: C 12, C 32...|$|R
40|$|Statistical tests {{routinely}} adopted {{for detecting}} nonlinear components in time series {{rely on the}} auxiliary regression of ARMA lagged residuals, and the Lagrange multiplier test to detect ARCH components is an example. The size distortion of such test suggests adopting a weighted test, where the weights are computed through a forward search algorithm. Simulations show that the forward weighted <b>robust</b> <b>test</b> is preferable to the classical Lagrange test and to existing robust tests, {{which are based on}} backward weighted regression or on estimated autocorrelation function. The forward weighted <b>robust</b> <b>test</b> is applied to daily financial and quarterly macroeconomic time series, showing its usefulness in detecting ARCH effects, even when outliers are present. ...|$|E
40|$|For the {{non-parametric}} two-sample location problem, adaptive tests {{based on}} a selector statistic are compared with a maximum and a sum test, respectively. When the class of all continuous distributions is not restricted, the sum test is not a <b>robust</b> <b>test,</b> i. e. {{it does not have}} a relatively high power across the different possible distributions. However, according to our simulation results, the adaptive tests as well as the maximum test are robust. For a small sample size, the maximum test is preferable, whereas for a large sample size the comparison between the adaptive tests and the maximum test does not show a clear winner. Consequently, one may argue in favour of the maximum test since it is a useful test for all sample sizes. Furthermore, it does not need a selector and the specification of which test is to be performed for which values of the selector. When the family of possible distributions is restricted, the maximin efficiency <b>robust</b> <b>test</b> may be a further robust alternative. However, for the family of t distributions this test is not as powerful as the corresponding maximum test. Location-shift model, measures of skewness and tailweight, maximin efficiency <b>robust</b> <b>test,</b> non-parametric tests, two-sample location problem, selector statistic,...|$|E
40|$|We {{propose a}} robust version of Cox-type test {{statistics}} for the choice between two nonnested hypotheses. We first show that the influence of small amounts of contamination in the data on the test decision can be very large. Secondly, we build a <b>robust</b> <b>test</b> statistic by using the results on robust parametric tests that {{are available in the}} literature and show that the level of the <b>robust</b> <b>test</b> is stable. Finally, we show numerically not only the robustness of this new test statistic but also that its asymptotic distribution is a good approximation of its sample distribution, unlike for the classical test statistic. We apply our results to the choice between a Pareto and an exponential distribution as well as between two competing regressors in the simple linear regression model without intercept...|$|E
40|$|A new first-order {{asymptotic}} {{theory for}} heteroskedasticity-autocorrelation (HAC) <b>robust</b> <b>tests</b> based on nonparametric covariance matrix estimators is developed. The bandwidth of the covariance matrix estimator is modeled as a firxed {{proportion of the}} sample size. This leads to a distribution theory for HAC <b>robust</b> <b>tests</b> that explicitly captures the choice of bandwidth and kernel. This contrasts with the traditional asymptotics (where the bandwidth increases slower than the sample size) where the asymptotic distributions of HAC <b>robust</b> <b>tests</b> do {{not depend on the}} bandwidth or kernel. Finite sample simulations show that the new approach is more accurate than the traditional asymptotics. The impact of bandwidth and kernel choice on size and power of t-tests is analyzed. Smaller bandwidths lead to tests with higher power but greater size distortions and large bandwidths lead to tests with lower power but less size distortions. Size distortions across bandwidths increase as the serial correlation in the data becomes stronger. Overall, the results clearly indicate that for bandwidth and kernel choice there is a trade-off between size distortions and power. Finite sample performance using the new asymptotics is comparable to the bootstrap which suggests the asymptotic theory in thi...|$|R
40|$|Description An R {{software}} package on statistical tests widely utilized in biostatistics, {{public policy and}} law. Along with the well known tests for equality of means and variances, randomness,measures of relative variability etc, the package contains new <b>robust</b> <b>tests</b> of symmetry, omnibus and directional tests of normality, and their graphical counterparts such as Robust QQ plot; a <b>robust</b> trend <b>tests</b> for variances etc. All implemented tests and methods are illustrated by simulations and real-life examples from legal statistics, economics, and biostatistics. NeedsCompilation n...|$|R
40|$|This paper {{focuses on}} robust {{inference}} on the shape parameter of a composite transformation model. Large sample <b>robust</b> <b>tests</b> and confidence intervals {{are derived from}} a quasi profile likelihood ratio statistic. This statistic is obtained from a suitable bounded profile estimating function, which defines a robust estimator for the shape parameter, while the remaining parameters of the model are treated as nuisance. This test has desirable robustness properties and leads to more reliable inference then the classical <b>robust</b> Wald <b>test</b> statistic...|$|R
40|$|We propose {{computing}} HAC {{covariance matrix}} estimators based on one-stepahead forecasting errors. It is shown that this estimator is consistent and has smaller bias than other HAC estimators. Moreover, the tests {{that rely on}} this estimator have more accurate sizes without sacrificing its power. forecast error, HAC estimator, kernel estimator, recursive residual, <b>robust</b> <b>test...</b>|$|E
40|$|An {{evaluation}} of a multiplex PCR assay (Bruce-ladder) was performed in seven laboratories using 625 Brucella strains from different animal and geographical origins. This <b>robust</b> <b>test</b> can differentiate in a single step all of the classical Brucella species, including those found in marine mammals and the S 19, RB 51, and Rev. 1 vaccine strains...|$|E
40|$|A wild {{bootstrap}} test of {{the null}} hypothesis that the errors of a panel data model are not correlated over cross-section units is proposed. The new test is more generally applicable than others that use the restrictive assumptions of normality and homoskedasticity. Monte Carlo {{results indicate that the}} new test is reliable. Cross-section correlation; Wild bootstrap; <b>Robust</b> <b>test...</b>|$|E
40|$|Robust statistics, as a concept, {{probably}} {{dates back}} to the prehistory of statistics. It has, however, been formalized in the sixties by the pioneering work of Huber [9, 10] and Hampel [6, 7]. Robust statistics is an extension of classical statistics, which takes into account the fact that models assumed to have generated the data at hand are only approximate. It provides tools to investigate the robustness properties of a statistic T (such as estimators, test statistics) as well as robust estimators and <b>robust</b> <b>testing</b> proce-dures (see <b>Robust</b> <b>Testing</b> Procedures). Although one would easily agree that models can only describe approximately the reality, what is more difficult to understand is the effect of this fact on the properties of classical statistics T for which i...|$|R
40|$|A new 8 ̆ 5 rst order {{asymptotic}} {{theory for}} heteroskedasticity-autocorrelation (HAC) <b>robust</b> <b>tests</b> based on nonparametric covariance matrix estimators is developed. The bandwidth of the covariance matrix estimator is modeled as a 8 ̆ 5 xed {{proportion of the}} sample size. This leads to a distribution theory for HAC <b>robust</b> <b>tests</b> that explicitly captures the choice of bandwidth and kernel. This contrasts with the traditional asymptotics (where the bandwidth increases slower than the sample size) where the asymptotic distributions of HAC <b>robust</b> <b>tests</b> do {{not depend on the}} bandwidth or kernel. Finite sample simulations show that the new approach is more accurate than the traditional asymptotics. The impact of bandwidth and kernel choice on size and power of t-tests is analyzed. Smaller bandwidths lead to tests with higher power but greater size distortions and large bandwidths lead to tests with lower power but less size distortions. Size distortions across bandwidths increase as the serial correlation in the data becomes stronger. A new data dependent bandwidth is proposed in light of these results. Within a group of popular kernels, it shown that the Bartlett kernel has approximately the highest power and the quadratic spectral (QS) kernel has the lowest power regardless of the bandwidth. However, th...|$|R
50|$|Smoke testing {{refers to}} various classes of tests of systems, usually {{intended}} {{to determine whether}} they are ready for more <b>robust</b> <b>testing.</b> The expression probably was first used in plumbing in referring to tests for the detection of cracks, leaks or breaks in closed systems of pipes.|$|R
40|$|<b>Robust</b> <b>Test</b> Generation and Coverage for Hybrid Systems Testing is an {{important}} tool for validation of the system design and its implementation. Model-based test generation allows to systematically ascertain whether the system meets its design requirements, particularly the safety and correctness requirements of the system. In this paper, we develop a framework for generating tests from hybrid systems ’ models. The core idea of the framework {{is to develop a}} notion of <b>robust</b> <b>test,</b> where one nominal test can be guaranteed to yield the same qualitative behavior with any other test that is close to it. Our approach offers three distinct advantages: 1) It allows for computing and formally quantifying the robustness of some properties; 2) it establishes a method to quantify the test coverage for every test case; and 3) the procedure is parallelizable and therefore, very scalable. We demonstrate our framework by generatin...|$|E
40|$|We use recent {{international}} data on cost shares by {{sector to}} conduct the first <b>robust</b> <b>test</b> of Leontief’s hypothesis of factor-specific productivity dif-ferences. We strongly reject this hypothesis. Hence tests of the Heckscher-Ohlin-Vanek paradigm cannot be based upon simple modifications that de-fine factors in efficiency units. We also discuss a theory of productivity differences that describes the factor content of trade well. ...|$|E
40|$|We propose robust {{tests as}} {{alternatives}} to the classical Wilks’ Lambda test in one-way MANOVA. The robust tests use highly robust and efficient multi-sample multivariate S- or MM-estimators instead of the empirical covariances. The properties of several <b>robust</b> <b>test</b> statistics are compared. Under the null hypothesis, {{the distribution of the}} test statistics is proportional to a chi-square distribution. As an alternative to the asymptotic distribution, we develop a fast robust bootstrap method to estimate the distribution under the null hypothesis. We show when it is asymptotically correct to estimate the null distribution in this way and we use simulations to verify the performance of the bootstrap based tests in finite samples. We also investigate the power of the new tests, as well as their robustness against outliers. Finally, we illustrate the use of these <b>robust</b> <b>test</b> statistics on a real data example. Some additional results are provided as supplemental material. status: publishe...|$|E
40|$|We review {{some basic}} {{approaches}} to robust inference {{and discuss the}} role and the place of some key concepts (influence function, breakdown point, robustness versus efficienty, etc.). We then discuss in some detail results on <b>robust</b> <b>testing</b> in linear models, nonlinear regression, and general multivariate parametric models. Statistical Analysis...|$|R
40|$|Under {{complete}} {{linkage disequilibrium}} (LD), <b>robust</b> <b>tests</b> often have greater power than Pearson's chi-square test and trend tests {{for the analysis}} of case-control genetic association studies. Robust statistics have been used in candidate-gene and genome-wide association studies (GWAS) when the genetic model is unknown. We consider here a more general incomplete LD model, and examine the impact of penetrances at the marker locus when the genetic models are defined at the disease locus. Robust statistics are then reviewed and their efficiency and robustness are compared through simulations in GWAS of 300, 000 markers under the incomplete LD model. Applications of several <b>robust</b> <b>tests</b> to the Wellcome Trust Case-Control Consortium [Nature 447 (2007) 661 [...] 678] are presented. Comment: Published in at [URL] the Statistical Science ([URL] by the Institute of Mathematical Statistics ([URL]...|$|R
40|$|We {{studied a}} trend test for genetic {{association}} between {{disease and the}} number of risk alleles using case-control data. When the data are sampled from families, this trend test can be adjusted {{to take into account the}} correlations among family members in complex pedigrees. However, the test depends on the scores based on the underlying genetic model and thus it may have substantial loss of power when the model is misspecified. Since the mode of inheritance will be unknown for complex diseases, we have developed two <b>robust</b> trend <b>tests</b> for case-control studies using family data. These <b>robust</b> <b>tests</b> have relatively good power for a class of possible genetic models. The trend <b>tests</b> and <b>robust</b> trend <b>tests</b> were applied to a dataset of Genetic Analysis Workshop 14 from the Collaborative Study on the Genetics of Alcoholism...|$|R
