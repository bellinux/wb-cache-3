3|68|Public
40|$|Abstract — Delay {{fault testing}} {{has proven to}} be a {{significant}} part of modern manufacturing testing. It has also become a source of overtesting due to detection of functionally untestable faults by invalid transitions that would not occur during functional operation of the chip. There has been previous work in the field that identifies these faults allowing them to be removed from active fault lists from ATPG tools. However, due to the <b>random</b> <b>fill</b> of don’tcare bits in test patterns, incidental detection of functionally untestable faults becomes possible. In this paper, we propose a novel framework that will generate patterns using any commercial ATPG that avoid detection of these functionally untestable transition faults. Previous methods have required modification of the ATPG tool itself or designing a new ATPG to avoid such faults, making the immediate use of these tools very difficult. Our framework builds upon a commercial ATPG tool and modifies the netlist rather than the tool. By using the present functionality of the ATPG tool and a modified netlist, pattern generation is structurally constrained to avoid generating a pattern that will incidentally detect a functionally untestable fault. The proposed minimally affects test coverage of functionally testable faults and does not significantly increase the amount of effort needed by the ATPG tool. I...|$|E
40|$|As {{technology}} scales {{into the}} Deep Sub-Micron (DSM) regime, circuit designs {{have become more}} and more sensitive to power supply noise. Excessive noise can significantly affect the timing performance of DSM designs and cause non-trivial additional delay. In delay test generation, test compaction and test fill techniques can produce excessive power supply noise. This will eventually result in delay test overkill. To reduce this overkill, we propose a low-cost pattern-dependent approach to analyze noise-induced delay variation for each delay test pattern applied to the design. Two noise models have been proposed to address array bond and wire bond power supply networks, and they are experimentally validated and compared. Delay model is then applied to calculate path delay under noise. This analysis approach can be integrated into static test compaction or test fill tools to control supply noise level of delay tests. We also propose an algorithm to predict transition count of a circuit, which can be applied to control switching activity during dynamic compaction. Experiments have been performed on ISCAS 89 benchmark circuits. Results show that compacted delay test patterns generated by our compaction tool can meet a moderate noise or delay constraint with only a small increase in compacted test set size. Take the benchmark circuit s 38417 for example: a 10 % delay increase constraint only results in 1. 6 % increase in compacted test set size in our experiments. In addition, different test fill techniques {{have a significant impact on}} path delay. In our work, a test fill tool with supply noise analysis has been developed to compare several test fill techniques, and results show that the test fill strategy significant affect switching activity, power supply noise and delay. For instance, patterns with minimum transition fill produce less noise-induced delay than <b>random</b> <b>fill.</b> Silicon results also show that test patterns filled in different ways can cause as much as 14 % delay variation on target paths. In conclusion, we must take noise into consideration when delay test patterns are generated...|$|E
40|$|Delay test is an {{essential}} structural manufacturing test {{used to determine the}} maximal frequency at which a chip can run without incurring any functional failures. The central unsolved challenge is achieving high delay correlation with the functional test, which is dominated by power supply noise (PSN). Differences in PSN between functional and structural tests can lead to differences in chip operating frequencies of 30 % or more. Pseudo functional test (PFT), based on a multiple-cycle clocking scheme, has better PSN correlation with functional test compared with traditional two-cycle at-speed test. However, PFT is vulnerable to under-testing when applied to delay test. This work aims to generate high quality PFT patterns, achieving high PSN correlation with functional test. First, a simulation-based don?t-care filling algorithm, Bit-Flip, is proposed to improve the PSN for PFT. It relies on randomly flipping a group of bits in the test pattern to explore the search space and find patterns that stress the circuits with the worst-case, but close to functional PSN. Experimental results on un-compacted patterns show Bit-Flip is able to improve PSN as much as 38. 7 % compared with the best <b>random</b> <b>fill.</b> Second, techniques are developed to improve the efficiency of Bit-Flip. A set of partial patterns, which sensitize transitions on critical cells, are pre-computed and later used to guide the selection of bits to flip. Combining random and deterministic flipping, we achieve similar PSN control as Bit-Flip but with much less simulation time. Third, we address the problem of automatic test pattern generation for extracting circuit timing sensitivity to power supply noise during post-silicon validation. A layout-aware path selection algorithm selects long paths to fully span the power delivery network. The selected patterns are intelligently filled to bring the PSN to a desired level. These patterns can be used to understand timing sensitivity in post-silicon validation by repeatedly applying the path delay test while sweeping the PSN experienced by the path from low to high. Finally, the impacts of compression on power supply noise control are studied. Illinois Scan and embedded deterministic test (EDT) patterns are generated. Then Bit-Flip is extended to incorporate the compression constraints and applied to compressible patterns. The experimental results show that EDT lowers the maximal PSN by 24. 15 % and Illinois Scan lowers it by 2. 77 % on un-compacted patterns...|$|E
50|$|For a {{long time}} the {{non-stoichiometric}} phases {{were believed to be}} disordered with a <b>random</b> <b>filling</b> of the interstices, however short and longer range ordering has been detected.|$|R
50|$|The highest {{possible}} probability of breech presentation of 50% indicates that breech presentation {{is a consequence}} of <b>random</b> <b>filling</b> of the intrauterine space, with the same probability of breech and cephalic presentation in a longitudinally elongated uterus.|$|R
40|$|We {{consider}} the kinetics of processes where {{the sites of}} a Bethe lattice are filled irreversibly and, in general, cooperatively by monomers, dimers, or polyatomics. For nearest neighbor and sometimes more general cooperative effects (including <b>random</b> <b>filling</b> as a special case), we show that the infinite hierarchy of rate equations for probabilities of empty subconfigurations can be exacty truncated and solved using a shielding property of empty sites. We indicate, in certain cases, a connection between these Bethe lattice solutions and certain approximate truncation solutions for corresponding processes on ‘‘physical’’ 2 ‐D and 3 ‐D lattices with the same coordination number...|$|R
40|$|International audienceScan architectures, though {{widely used}} in modern designs, are {{expensive}} in power consumption. In this paper, we discuss the issues of excessive peak power consumption during scan testing. We show that taking care of high current levels during the test cycle (i. e. between launch and capture) is highly relevant to avoid noise phenomena such as IR-drop or ground bounce. We propose a solution based on power-aware assignment of don't care bits in deterministic test patterns. For ISCAS' 89 and ITC' 99 benchmark circuits, this approach reduces peak power during the test cycle up to 89 % compared to a <b>random</b> <b>filling</b> solution...|$|R
5000|$|The current project {{contains}} a main earth-fill dam with an inclined clay core and other <b>random</b> <b>fills,</b> two saddle dams (earth-fill dams) {{at the left}} bank and a 240 m concrete dam (hollow buttress type) at the right bank. The concrete dam includes eight bottom outlets, a spillway and four power intakes and conduits, a stilling basin, headrace and tailrace channels. There is a power house, close to the concrete dam. The Badush Dam's spillway will have a maximum output of each hydro-power unit will have a capacity of [...] {{for a total of}} [...] The bottom outlets, power station and spillway combined afford a discharge capacity of ...|$|R
40|$|AbstractGenerating a {{realistic}} model of subsurface stratigraphy that fits data from multiple well locations is a well-established {{problem in the}} field of aquifer characterisation. This is particularly critical for the alluvial fan-hosted aquifers in northwestern India, as they have some of the highest rates of groundwater extraction in the world and spatially limited subsurface observations. The objective {{of this study is to}} develop a reduced-complexity model that generates probabilistic estimates of aquifer body occurrence within a sedimentary fan, based loosely on the northwestern Indian aquifer system. We propose a parsimonious, inverse-weighted random walk model that reconstructs potential channel belt pathways within a discrete depth range or slice by (i) connecting known aquifer locations with the fan apex, (ii) filling adjacent cells with non-aquifer material based on estimated channel-body dimensions, and (iii) <b>random</b> <b>filling</b> of the remaining cells until the model fraction of aquifer material is comparable to the bulk aquifer fraction observed from well data. Once filled, individual depth slices can be stacked to produce a three-dimensional representation of aquifer-body geometry, allowing informed inference and testable predictions about the configuration of aquifer units in the subsurface. A receiver operating characteristic (ROC) curve shows that the model performs better than fully <b>random</b> <b>filling,</b> both in matching the locations of aquifer material in the subsurface and in reconstructing the geometry of relict channel bodies preserved on the fan surface. The model differs from purely statistical-empirical approaches by incorporating some geomorphic knowledge of fluvial channel belt geometry within the fan system. In contrast to a fully process-based approach, the model is computationally fast and is easily refined as new subsurface data become available...|$|R
40|$|Abstract. This paper {{presents}} {{an attempt to}} unify gravity and electromagnetism associated with «holes » and « bumps » in the covariant density distribution of a real average covariant Dirac aether built with extended <b>random</b> elements <b>filling</b> flat space-time. Some possible experimental tests are also discussed...|$|R
40|$|Abstract: Analysis of CO-OFDM {{single-mode}} {{optical fibre}} transmission system model, studied the timing deviation on the system synchronization performance, and used the Zadoff-Chu pilot sequence to realize the system synchronization, and concludes that the four QAM is to achieve 100 Gbps long distance transmission of the optimal modulation mode. In addition, the Zadoff-Chu pilot frequency sequence also has a constant amplitude, zero auto correlation properties, which can reduce the amplifier nonlinear effects, improve the performance of channel estimation. Based on Optisystem software simulation platform, built based on the CO-OFDM technology transfer rate for 100 Gbps long distance transmission system simulation system, and research the transmission distance for 1000 km error performance {{and the relationship between}} the transmission power. We research in single channel transmission and WDM transmission system of the two cases, <b>random</b> <b>filling</b> and consistent filling effect the performance of the system...|$|R
40|$|A direct model, {{using the}} {{explicit}} geometry of stacked products in boxes, {{was developed and}} used to study the local and average airflow through stacks of horticultural products. The discrete element method was employed to generate a random stacking of spherical products in the box. A computational fluid dynamics model was then applied to study explicitly the airflow through the air gaps in the box and in the voids between the stacks of different random fillings. The flow resistance was affected by the confinement ratio, product size, porosity, box vent hole ratio, and much less by the <b>random</b> <b>filling.</b> The predicted pressure drop over stacks agreed with experimental correlations for porous media. Air velocity profiles inside the boxes compared well to measurements. The methodology was used to obtain more accurate pressure drop correlation for stacks of vented boxes that can now be used in large scale simulations of cool rooms. (c) 2008 Elsevier Ltd. All rights reserved. status: publishe...|$|R
40|$|We {{propose a}} {{temperature}} sensor design based on surface plasmon resonances (SPRs) supported by filling the holes of a six-hole photonic crystal fiber (PCF) {{with a silver}} nanowire. A liquid mixture (ethanol and chloroform) with a large thermo-optic coefficient is filled into the PCF holes as sensing medium. The filled silver nanowires can support resonance peaks and the peak will shift when temperature variations induce changes in the refractive indices of the mixture. By measuring the peak shift, the temperature change can be detected. The resonance peak is extremely sensitive to temperature because the refractive index of the filled mixture is close {{to that of the}} PCF material. Our numerical results indicate that a temperature sensitivity as high as 4 nm/K can be achieved and that the most sensitive range of the sensor can be tuned by changing the volume ratios of ethanol and chloroform. Moreover, the maximal sensitivity is relatively stable with <b>random</b> <b>filled</b> nanowires, which will be very convenient for the sensor fabrication...|$|R
40|$|Irreversible {{adsorption}} of diatomics on crystalline surfaces {{is sometimes}} modeled as <b>random</b> dimer <b>filling</b> of adjacent pairs of sites on a lattice. We {{note that this}} process can be implemented in two distinct ways: (i) randomly pick adjacent pairs of sites, [*]jj’, and fill [*]jj’ only if both are empty (horizontal transition state); or (ii) randomly pick a single site, [*]j, and if [*]j {{and at least one}} neighbor are empty, then fill [*]j and a randomly chosen empty neighbor (vertical transition state). Here it is instructive to consider processes which also include competitive <b>random</b> monomer <b>filling</b> of single sites. We find that although saturation (partial) coverages differ little between the models for pure dimer filling, there is a significant difference for comparable monomer and dimer filling rates. We present exact results for saturation coverage behavior for a linear lattice, and estimates for a square lattice. Ramifications for simple models of CO oxidation on surfaces are indicated...|$|R
40|$|Models where pairs, triples, {{or larger}} (typically connected) sets of sites on a 2 Dlattice ‘‘fill’’ irreversibly (described here as dimer, trimer, [...] . filling or adsorption),either {{randomly}} or cooperatively, {{are required to}} describe many surfaceadsorption and reaction processes. Since filling {{is assumed to be}} irreversible and immobile (species are ‘‘frozen’’ once adsorbed), even the stationary, saturation state, which is nontrivial since the lattice cannot fill completely, is not in equilibrium. The kinetics and statistics of these processes are naturally described by recasting the master equations in hierarchic form for probabilities of subconfigurations of empty sites. These hierarchies are infinite for the infinite lattices considered here, but approximate solutions can be obtained by implementing truncation procedures. Those used here exploit a shielding property of suitable walls of empty sites peculiar to irreversible filling processes. Accurate results, including saturation coverage estimates, are presented for <b>random</b> <b>filling</b> of dimers, and trimers of different shapes, on various infinite 2 Dlattices, and for square tetramers on an infinite square lattice...|$|R
40|$|International audience►Knudsen's formula {{widely used}} in cometary {{research}} is of limited accuracy for modeling the gas transport through short dust channel. As an alternative, Clausing's formula is suggested, accurately describing the kinetics of transport through a single cylindrical capillary. ► Accurate statistical calculations are performed for media formed either by ballistic deposition (RDB) of test particles or by <b>random</b> <b>filling</b> of a control volume (RSP). The medium permeability and the return flow of re-condensed molecules are estimated for the different model parameters. The permeability depends on the medium porosity in a nonlinear way. ► We preserve the overall structure of Clausing's formula and introduce the effective radius of the capillary is an unknown function of porosity. The explicit form of this functional dependence is derived from a nonlinear approximation based on statistical modeling results. ► The retrieved algebraic expression allows us to accurately calculate the permeability of layers whose thickness and porosity vary {{in the range of}} values expected for the near-surface regions of a cometary nucleus. The simplicity of this approach makes it practical to include the block that describes the transport of gas in the overall thermal model of a cometary nucleus...|$|R
40|$|How {{to predict}} and better {{understand}} the effective properties of disordered material mixtures has been a long-standing problem in different research fields, especially in condensed matter physics. In order to address this subject and achieve {{a better understanding of}} the frequency-dependent properties of these systems, a large 2 D L × L square structure of resistors and capacitors was used to calculate the immittance response of a network formed by <b>random</b> <b>filling</b> of binary conductor/insulator phases with 1000 resistors and 10 nF capacitors. The effects of percolating clusters on the immittance response were studied statistically through the generation of 10 000 different random network samples at the percolation threshold. The scattering of the imaginary part of the immittance near the dc limit shows a clear separation between the responses of percolating and non-percolating samples, with the gap between their distributions dependent on both network size and applied frequency. These results could be used to monitor connectivity in composite materials. The effects of the content and structure of the percolating path on the nature of the observed dispersion were investigated, with special attention paid to the geometrical fractal concept of the backbone and its influence on th...|$|R
40|$|Introduction: Inadequate sleep hygiene {{may result}} in {{difficulties}} in daily functioning; therefore, reliable scales are important to measure sleep hygiene. The {{purpose of this study}} was to assess the psychometric properties of the Persian version of Sleep Hygiene Index (SHI) in the male population. Methods: In this study, 787 men, who were selected by cluster <b>random</b> sampling, <b>filled</b> out the SHI, Pittsburgh Sleep Quality Index (PSQI), Epworth Sleepiness Scale (ESS), and Insomnia Severity Index (ISI). A subset of the participants (20...|$|R
40|$|We {{study the}} {{decoherence}} dynamics of dipole-coupled two-level quantum systems in Ramsey-type experiments. We focus on large networks of two-level systems, confined to two spatial dimensions and with positional disorder {{giving rise to}} disordered dipolar couplings. This setting is relevant for modeling the decoherence dynamics of the rotational excitations of polar molecules confined to deep optical lattices, where disorder arises from the <b>random</b> <b>filling</b> of lattice sites with occupation probability p. We show that the decoherence dynamics exhibits a phase transition at a critical filling p_c≃ 0. 15. For pp_c the dipolar interactions dominate the disorder, and the system behaves as a collective spin-ordered phase, representing synchronization of the two-level systems and persistent Ramsey oscillations with divergent T_ 2 for large systems. For {{a finite number of}} two-level systems, N, the spin-ordered phase at p> p_c undergoes a crossover to a collective spin-squeezed state on a timescale τ_ sq∝√(N). We develop a self-consistent mean-field theory that is capable of capturing the synchronization transition at p_c, and provide an intuitive theoretical picture that describes the phase transition in the long-time dynamics. We also show that the decoherence dynamics appear to be ergodic in the vicinity of p_c, the long-time behaviour being well described by the predictions of equilibrium thermodynamics. The results are supported by the results of exact diagonalization studies of small systems...|$|R
40|$|Isotherms {{and free}} energy {{variations}} at equilibnum {{in the case}} of fixed one-to-n adsorption (i. e. the average occupation of n adsorption sites by one adsorbed molecule) are calculated for one-dimensional models and their properties are discussed. It proceeds that no first order transition can be expected between a condensed (one-to-n) disordered phase and the ordered (one-to-one) solid phase. Configurational entropy of an adsorbed two-dimensional one-to-n phase is computed numerically during a <b>random</b> sequential <b>filling</b> simulation. Since in this case, the two-dimensional phase is built in a disordered manner, the system can swing abruptly from disordered to ordered state...|$|R
40|$|Freshly {{harvested}} horticultural produce {{require a}} proper temperature management {{to maintain their}} high economic value. Towards this end, low temperature storage is of crucial importance to maintain a high product quality. Optimizing both the package design of packed produce and the different steps in the postharvest cold chain {{can be achieved by}} numerical modelling of the relevant transport phenomena. This work presents a novel methodology to accurately model both the <b>random</b> <b>filling</b> of produce in a package and the subsequent cooling process. First, a cultivar-specific database of more than 100 realistic CAD models of apple and pear fruit is built with a validated geometrical 3 D shape model generator. To have an accurate representation of a realistic picking season, the model generator also takes into account the biological variability of the produce shape. Next, a discrete element model (DEM) randomly chooses surface meshed bodies from the database to simulate the gravitational filling process of produce in a box or bin, using actual mechanical properties of the fruit. A computational fluid dynamics (CFD) model is then developed with the final stacking arrangement of the produce to study the cooling efficiency of packages under several conditions and configurations. Here, a typical precooling operation is simulated to demonstrate the large differences between using actual 3 D shapes of the fruit and an equivalent spheres approach that simplifies the problem drastically. From this study, it is concluded that using a simplified representation of the actual fruit shape may lead to a severe overestimation of the cooling behaviour. status: accepte...|$|R
40|$|The {{hierarchical}} {{organization of}} dominance relations among animals has wide-ranging implications in social evolution. The structure of dominance relations {{has often been}} measured using indices of linearity (e. g. Landau’s h, Kendall’s K) : {{the degree to which}} dominance relations adhere to a linear hierarchy. An alternative measure is the transitivity of dominance relations among sets of three players that all interact with each other, a measure we call triangle transitivity (ttri). Triangle transitivity and linearity are essentially equivalent when dominance relations of all dyads are known, but such complete observations are rare in empirical studies. Triangle transitivity has two major advantages: it does not require ‘filling in’ of unobserved relations, and its expected value is constant across group sizes. We use a social network perspective to demonstrate a property of transitivity in random directed networks (on average, three-fourths of complete triads are transitive) and show that empirical dominance networks are often significantly more transitive than random networks. Using 101 published dominance matrices we show that published algorithms for assessing linearity underestimate the level of social orderliness, particularly in larger groups, which tend to have more null dyads. Thus, previous puzzlement over the decrease in estimated linearity in larger groups could be due largely to the bias introduced by <b>random</b> <b>filling</b> of null dyads. We argue that triangle transitivity will allow researchers to focus on important processes underlying the dynamics of dominance, such as spatial segregation, avoidance of interactions by certain individuals and detailed temporal patterns in the ontogeny of hierarchy formation. Includes Supplementary Materials...|$|R
5000|$|Educated at Columbia University (where he {{restricted}} {{himself to}} Russian, German, Latin, Greek, Sanskrit and Polish), Urdang was a linguistics lecturer at New York University from 1956 to 1961. Although he never wrote the dissertation {{that would have}} completed his graduate degree, the <b>Random</b> House Dictionary <b>filled</b> the void amply: [...] "He always said he considered the Random House dictionary his dissertation," [...] said Nicole Urdang.|$|R
40|$|Consider {{irreversible}} cooperative filling {{of sites}} on an infinite lattice where the filling rates ki {{depend on the}} number, i, of occupied sites adjacent to the site(s) being filled. If clustering is significantly enhanced relative to nucleation (k 1 /k 0 ≡ρ≫ 1), then the process is {{thought of as a}} competition between nucleation, growth, and (possible) coalescence of clusters. These could be Eden clusters with or without permanent voids, Eden trees, or have modified but compact structure (depending on the ki, i≥ 1). Detailed analysis of the master equations in hierarchial form (exploiting an empty-site shielding property) produces results which are exact (approximate) in one (two or more) dimensions. For linear, square, and (hyper) cubic lattices, we consider the behavior of the average length of linear strings of filled sites, lav=J∞s= 1 sls/J∞s= 1 ls, where ls is the probability of a string of length s [lav=(1 −CTHETA) − 1 for <b>random</b> <b>filling,</b> at coverage CTHETA]. In one dimension, ls=ns gives the cluster size distribution, and we write lav=nav. We consider the scaling lav∼A(CTHETA) ρω as ρ→∞ (with CTHETA fixed), which is elucidated by the introduction of simpler models neglecting fluctuations in cluster growth or cluster interference. For an initially seeded lattice, there exists an upper bounding curve lav+ for lav (as a function of CTHETA), which is naturally obtained by switching off nucleation (setting k 0 = 0). We consider scaling of lav+ as the initial seed coverage ε vanishes. The divergence, lav∼C(1 −CTHETA) − 1 as CTHETA→ 1, is also considered, focusing on the cooperativity dependence of C. Other results concerning single-cluster densities and ls behavior are discussed...|$|R
40|$|This is {{a journal}} article. It was {{published}} in the journal IEEE transactions on components, packaging and manufacturing technology - Part C [© IEEE], and is available from: [URL]. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. This paper presents new results from an experimental and theoretical program to evaluate relevant process parameters in the assembly of a 500 m pitch area array component using anisotropic conductive adhesive (ACA) materials. This experimental configuration has features of micro ball grid array (BGA), chip scale packaging (CSP), and also flip-chip and conventional ball grid array (BGA) package structures. A range of materials combinations have been evaluated, including (<b>random</b> <b>filled)</b> adhesive materials based on both thermoplastic and thermosetting resin systems, combined with both organic and thick-film on ceramic substrate materials. The ACA’s used have all been applied as films, and hence are also known as anisotropic conducting films (ACF). The test assemblies have been constructed using a specially developed instrumented assembly system which allows the measurement of the process temperatures and pressures and the consequent bondline thickness reduction and conductivity development. The effects of the process parameters on the resulting properties, particularly conductivity and yield, are reported. A complementary paper [1] indicates the results of computational fluid dynamics (CFD) models of {{the early stages of the}} assembly process which allow the extrapolation of the present results to finer pitch geometries...|$|R
40|$|Models for {{irreversible}} <b>random</b> or cooperative <b>filling</b> of lattices {{are required}} to describe many processes in chemistry and physics. Since the filling {{is assumed to be}} irreversible, even the stationary, saturation state is not in equilibrium. The kinetics and statistics of these processes are described by recasting the master equations in infinite hierarchial form. Solutions can be obtained by implementing various techniques involving, e. g., truncation or formal density expansions. Refinements in these solution techniques are presented;Problems considered include random dimer, trimer, and tetramer filling of 2 D lattices, <b>random</b> dimer <b>filling</b> of a cubic lattice, competi- tive filling of two or more species, and the effect of a random distribu- tion of inactive sites on the filling. We also consider monomer filling of a linear lattice with nearest neighbor cooperative effects and solve for the exact cluster-size distribution for cluster sizes up to the asymptotic regime. Additionally, we develop a technique to directly determine the asymptotic properties of the cluster-size distribution;Finally, we consider cluster growth via irreversible aggregation involving random walkers. In particular, we provide explicit results for the large-lattice-size asymptotic behavior of trapping probabilities and average walk lengths for a single walker on a lattice with multiple;traps. Procedures for exact calculation of these quantities on finite lattices are also developed; *DOE Report IS-T- 1230. This work was performed under Contract W- 7405 -eng- 82 with the Department of Energy...|$|R
40|$|AbstractThere {{are many}} classifications in {{optimization}} and control (continuous, discrete, integer problems; convex or concave minimization; steepest descent, branch and bound, path following, space <b>filling,</b> <b>random</b> search methods; smooth or non smooth problems; etc.). The {{aim of this}} short note is not to propose yet another classification, but to clarify existing ambiguities and imprecisions in problem formulations and to emphasize certain fundamental distinctions in solution methods currently used...|$|R
30|$|For request senders, we {{can obtain}} their {{profiles}} easily when they send the requests. For the regular {{members of the}} place, we use their membership information to fill the profile, thus some information might be missing such as years of experience, level, and time schedule. A time schedule can be summarized according to check-in records {{of the past few}} months. If someone does not have a regular time schedule, we use the term <b>random</b> to <b>fill</b> it. Also, we can use their years of membership as their estimated years of experience, then use the average values of other members with the same years of experience to fill in other missing items. For these members with estimated items in their profiles, we put an estimated mark on them.|$|R
50|$|This mode has {{attracted}} much criticism, as the randomness {{of the challenges}} and reward system mean that progressing {{is as much a}} matter of luck as it is of skill. In particular, in reference to the seventh challenge listed above, Stuart Campbell wrote in his review that the game doesn't take into account that the <b>random</b> new items <b>filling</b> the places of the captured animals can inadvertently generate new captures, making your challenge impossible.|$|R
40|$|In a haystack-type {{representation}} of a heterogeneous population that is evolving according to a payoff structure of a prisoner's dilemma game, migration is modeled {{as a process of}} 'swapping' individuals between heterogeneous groups of constant size after a <b>random</b> allocation <b>fills</b> the haystacks, but prior to mating. Migration is characterized by two parameters: an exogenous participation-in-migration cost (of search, coordination, movement, and arrangement-making) which measures the migration effort, and an exogenous technology - of coordinating and facilitating movement between populated haystacks and the colonization of currently unpopulated haystacks - which measures the migration intensity. Starting from an initially heterogeneous population that consists of both cooperators and defectors a scenario is postulated under which 'programmed' migration can act as a mechanism that brings about a long-run survival of cooperation...|$|R
50|$|Supposing, however, {{a single}} {{algorithm}} can be envisioned {{to generate a}} realistic-looking tree, the algorithm could be called to generate <b>random</b> trees, thus <b>filling</b> a whole forest at runtime, instead of storing all the vertices required by the various models. This would save storage media space and reduce the burden on artists, while providing a similar level of immersion to the player. This method would require far more processing power, but since CPUs are constantly increasing in speed this is becoming less of a hurdle.|$|R
5000|$|Ether One {{has been}} praised for its {{portrayal}} of dementia. Michael Thomsen, {{in a piece}} for The New Yorker, stated that [...] "As a player, you’re never sure what’s important and what isn’t, so the system encourages you to take everything. This hoarding is repaid with periodic puzzles ... As the game progresses, these puzzles increase in complexity, as does the array of <b>random</b> objects <b>filling</b> the shelves. The collection gradually overwhelms the player’s ability to remember just where {{all of these things}} came from and why they seemed important enough to retrieve. Why did I bring this plate all the way back here? Whose hat is this supposed to be again? It’s a tidy simulation of the cognitive degradation of dementia." [...] Destructoid's Steven Hansen also praised the simulation, stating that the game takes [...] "a sort of reverse Eternal Sunshine of the Spotless Mind approach".|$|R
40|$|We {{develop a}} multifractal <b>random</b> tilling that <b>fills</b> the square. The multifractal is formed by an {{arrangement}} of rectangular blocks of different sizes, areas and number of neighbors. The overall feature of the tilling is an heterogeneous and anisotropic random self-affine object. The multifractal is constructed by an algorithm that makes successive sections of the square. At each n-step there is a random choice of a parameter ρ_i related to the section ratio. For the case of random choice between ρ_ 1 and ρ_ 2 we find analytically {{the full spectrum of}} fractal dimensions...|$|R
40|$|We {{employ the}} numerically exact {{superposition}} T-matrix method to perform extensive computations of electromagnetic scattering by {{a volume of}} discrete <b>random</b> medium densely <b>filled</b> with increasingly absorbing as well as non-absorbing particles. Our numerical data demonstrate that increasing absorption diminishes and nearly extinguishes certain optical effects such as depolarization and coherent backscattering and increases the angular width of coherent backscattering patterns. This result corroborates the multiple-scattering origin of such effects and further demonstrates the heuristic value {{of the concept of}} multiple scattering even in application to densely packed particulate media...|$|R
40|$|We derive a {{model of}} group and {{individual}} selection on a quantitative character {{that is similar to}} the single-locus “metapopulation” models of group selection. Two alternative methods for the colonization of new or vacant habitats are examined and their effects are contrasted. In one model, all populations contribute migrants to a common pool, the “migrant pool,” from which colonists are drawn at <b>random</b> to <b>fill</b> vacant sites. In the migrant pool there is complete mixing of individuals from different populations. This model of colonization is the one used in all previous models of group selection. In the other model, the “propagule pool” model, each propagule is made up of individuals derived from a single population and there is no mixing of colonists from different populations during propagule formation. The analysis shows that much more between-population genetic variance can be maintained with the propagule pool model than with the migrant pool model. Consequently, group selection can be much more effective in natural populations than is commonly supposed...|$|R
40|$|International audienceWe explore nanocavitation {{around the}} crack tip region in a styrene-butadiene <b>random</b> {{copolymer}} <b>filled</b> with typical carbon black (CB) particles {{used in the}} rubber industry for toughening the rubber. Using quasistatic loading conditions and a highly collimated X-ray microbeam scanned around the crack tip, we demonstrate {{the existence of a}} damage zone consisting of nanovoids in a filled elastomer matrix. The existence of voids near the crack tip is demonstrated by a significant increase of the scattering invariant Q/Q 0 in front of both fatigued and fresh cracks. The size of the zone where cavities are present critically depends on the macroscopic strain εm, the loading history, and the maximum energy release rate G applied to accommodate the crack. Our findings show that nanovoiding occurs before fracture in typical CB-filled elastomers and that realistic crack propagation models for such elastomers should take into account a certain level of compressibility near the crack ti...|$|R
