27|9395|Public
2500|$|In 1952, IBM {{publicly}} {{announced the}} IBM 701 Electronic Data Processing Machine, {{the first in}} its successful 700/7000 series and its first IBM mainframe computer. The IBM 704, introduced in 1954, used magnetic core memory, which became the standard for large machines. IBM introduced the first disk storage unit, the IBM 350 RAMAC (<b>Random</b> <b>Access</b> <b>Method</b> of Accounting and Control) in 1956. Using fifty [...] metal disks, with 100tracks per side, {{it was able to}} store 5megabytes of data at a cost of US$10,000 per megabyte ($ as of [...] ).|$|E
2500|$|IBM {{established}} their west coast headquarters in San Jose in 1943. [...] In 1952 they opened {{a research and}} development facility in downtown, where Reynold Johnson and his team invented RAMAC (<b>Random</b> <b>Access</b> <b>Method</b> of Accounting and Control). [...] In 1956 IBM opened its Cottle Road manufacturing facility in the Santa Teresa neighborhood, where disc drives were invented in 1962. It was sold to Hitachi, who in turn sold the property to a developer. IBM still rents two buildings on the campus. IBM moved {{the research and development}} operation out of downtown, opening the Silicon Valley Laboratories in the Coyote Valley in 1976, and the Almaden Research Center in 1986.|$|E
5000|$|... 1956: First {{magnetic}} Hard disk driveIBM {{introduces the}} world's first magnetic hard disk for data storage. The IBM 305 RAMAC (<b>Random</b> <b>Access</b> <b>Method</b> of Accounting and Control) offers unprecedented performance by permitting random access {{to any of}} the million characters distributed over both sides of 50 two-foot-diameter disks. Produced in California, IBM's first hard disk stored about 2,000 bits of data per square inch and cost about $10,000 per megabyte. By 1997, the cost of storing a megabyte had dropped to around ten cents.|$|E
40|$|This paper {{analyses}} {{the performance}} of TCP over <b>random</b> and dedicated <b>access</b> <b>methods</b> {{in the context of}} DVB-RCS 2. <b>Random</b> <b>access</b> <b>methods</b> introduce a lower connection delay compared to dedicated methods. We investigate the poten- tial to improve {{the performance of}} short flows in regards to transmission delay, over <b>random</b> <b>access</b> <b>methods</b> for DVB- RCS 2 that is currently under development. Our simulation experiments show that the transmission of the first ten IP datagrams of each TCP flow can be 500 ms faster with ran- dom access than with dedicated access making the former of interest to carry Internet traffic. Such methods, however, are less efficient in regards to bandwidth usage than dedicated access mecanisms and less reliable in overloaded network conditions. Two aspects of channel usage optimization can be distinguished: reducing the duration of ressource utiliza- tion with <b>random</b> <b>access</b> <b>methods,</b> or increasing the spec- trum efficiency with dedicated <b>access</b> <b>methods.</b> This article argues that service providers may let low-cost users exploit the DVB-RCS 2 to browse the web by introducing different services, which choice is based on the channel <b>access</b> <b>method.</b> Comment: ACMLCDNet 201...|$|R
40|$|International audienceIn {{the context}} of {{satellite}} communications, <b>random</b> <b>access</b> <b>methods</b> can significantly increase throughput and reduce latency over the network. The recent <b>random</b> <b>access</b> <b>methods</b> are based on multi-user multiple access transmission {{at the same time}} and frequency followed by iterative interference cancellation and decoding at the receiver. Generally, it is assumed that perfect knowledge of the interference is available at the receiver. In practice, the interference term has to be accurately estimated to avoid performance degradation. Several estimation techniques have been proposed lately in the case of superimposed signals. In this paper, we present an overview on existing channel estimation methods and we propose an improved channel estimation technique that combines estimation using an autocorrelation based method and the Expectation-Maximization algorithm, and uses pilot symbol assisted modulation to further improve the performance and achieve optimal interference cancellation...|$|R
40|$|The {{specifications}} of Digital Video Broadcasting - Return Channel via Satellite(DVB-RCS 2) {{state that}} the satellite gateway could introduce both <b>random</b> and dedicated <b>access</b> <b>methods</b> to distribute the capacity among the different home users. Before starting an engineering process to design an algorithm allowing to combine both methods, it seems necessary to assess the performance of each. This paper compares <b>random</b> and dedicated <b>access</b> <b>methods</b> by measuring {{their impact on the}} performance of Transmission Control Protocol (TCP) sessions when the home users exploit the DVB-RCS 2 link for regular use (e. g., web browsing or email transmission). In this paper we detail the implementation of an NS- 2 module emulating Physical Channel Access (PCA). This module fills a gap in terms of <b>random</b> and deterministic <b>access</b> <b>methods</b> and allows to model various satellite channel access strategies. Based on NS- 2 simulations using realistic system parameters of the DVB-RCS 2 link, we demonstrate that, compared to dedicated <b>access</b> <b>methods,</b> which generally result in higher levels of transmitted data, <b>random</b> <b>access</b> <b>methods</b> enable faster transmission for short flows. We propose to combine <b>random</b> and dedicated <b>access</b> <b>methods,</b> with the selection of a specific method dependent on the dynamic load of the network and the sequence number of the TCP segments...|$|R
50|$|IBM {{established}} their west coast headquarters in San Jose in 1943. In 1952 they opened {{a research and}} development facility in downtown, where Reynold Johnson and his team invented RAMAC (<b>Random</b> <b>Access</b> <b>Method</b> of Accounting and Control). In 1956 IBM opened its Cottle Road manufacturing facility in the Santa Teresa neighborhood, where disc drives were invented in 1962. It was sold to Hitachi, who in turn sold the property to a developer. IBM still rents two buildings on the campus. IBM moved {{the research and development}} operation out of downtown, opening the Silicon Valley Laboratories in the Coyote Valley in 1976, and the Almaden Research Center in 1986.|$|E
5000|$|The first {{rotating}} drum storage device {{was used in}} the Birkbeck Automatic Relay Computer developed by Andrew Booth and Kathleen Booth in 1948. By 1954, magnetic core memory was rapidly displacing most other forms of temporary storage, including the Williams tube. It went on to dominate the field through the mid-1970s. A key feature of the American UNIVAC I system of 1951 was the implementation of a newly invented type of metal magnetic tape, and a high-speed tape unit, for non-volatile storage. Magnetic tape is still used in many computers.In 1952, IBM publicly announced the IBM 701 Electronic Data Processing Machine, the first in its successful 700/7000 series and its first IBM mainframe computer. The IBM 704, introduced in 1954, used magnetic core memory, which became the standard for large machines. IBM introduced the first disk storage unit, the IBM 350 RAMAC (<b>Random</b> <b>Access</b> <b>Method</b> of Accounting and Control) in 1956. Using fifty 24 in metal disks, with 100 tracks per side, it was able to store 5 megabytes of data at a cost of US$10,000 per megabyte ($ as of [...] ).|$|E
5000|$|The {{first home}} of the AMVER Center was at the New York Custom House in {{downtown}} New York City, {{due to the fact}} that many commercial cargo and passenger lines operating in the Atlantic maintained offices nearby, and AMVER's success would depend on close ties to the merchant fleet. The system's first computer was an IBM RAMAC (<b>Random</b> <b>Access</b> <b>Method</b> Accounting Control), characterized as being able to [...] "evaluate information and determine the position of vessels through dead reckoning." [...] The product of the computer was a [...] "Surface Picture" [...] or [...] "SURPIC" [...] of an area of the ocean, indicating the AMVER participating ships in the vicinity. In 1966, the Coast Guard moved its regional headquarters from the Custom House to Governors Island, in upper New York Bay. The move included the AMVER Center and consolidated all New York area Coast Guard activities, including a Rescue Coordination Center, at one site. One year after the move, AMVER's title was revised to read Automated Merchant VEssel Reporting program. Subsequent homes for the AMVER computer would include Washington, D.C; Governors Island, New York; and now at Martinsburg, West Virginia.In October 1982, the first joint AMVER/satellite-alerting rescue occurred, using the experimental ARGOS and Cospas-Sarsat system. December of that year saw the U.S. Maritime Administration and the Coast Guard sign an agreement making AMVER participation mandatory for U.S.-flag shipping, and suspending the requirement for the filing of reports to the overlapping USMER reporting system. This benefited many U.S. masters, already AMVER participants, who were juggling reports to two parallel systems, and allowed for a consolidated plot of all U.S. shipping worldwide.With the advent of the Global Maritime Distress Safety System (GMDSS), the role of AMVER was redefined to complement the emerging technology. Rescue coordination centers around the world began using Electronic Position Indicating Radio Beacons (EPIRBS), Inmarsat-C and Digital Selective Calling terminal auto-alarms to [...] "take the search out of search and rescue." [...] Then, attention could be turned to AMVER as a tool for the rescue phase of the operation.The beginning of the 1990s saw the need for the entire software package of AMVER to be rewritten in UNIX/Windows technology to keep pace with the evolution of data processing. This new version would provide more capacity; mechanisms for recurrent routings and maintaining ships on station (e.g., research ships or fishing factory ships); graphic plot depiction; and parser capability, once again bringing AMVER current with the state-of-the-art. Home for the AMVER Center was moved to the Operations Systems Center, a new facility designed and built to consolidate many Coast Guard computer systems at Martinsburg, West Virginia. Contracted out to civilian operation, this facility released many staff members for reassignment throughout the Coast Guard.In conjunction with the National Oceanic and Atmospheric Administration (NOAA) and COMSAT (the U.S. signatory to Inmarsat) AMVER has assisted in the development of [...] "compressed message" [...] software to move report data at high speed and low cost to encourage more frequent, user-friendly reporting and thus increase plot accuracy at a time when many shipping companies are removing full-time radio officers from GMDSS-compliant ships.Today, over 22,000 ships from hundreds of nations participate in AMVER. An average of 4,000 ships are on the AMVER plot each day and those numbers continue to increase. The AMVER Center computer receives over 14,000 AMVER messages a day. Over 2,800 lives have been saved by AMVER participating ships since 2000.|$|E
40|$|Abstract—In {{the context}} of {{satellite}} communications, <b>random</b> <b>access</b> <b>methods</b> can significantly increase throughput and reduce latency over the network. The recent <b>random</b> <b>access</b> <b>methods</b> are based on multi-user multiple access transmission {{at the same time}} and frequency followed by iterative interference cancellation and decoding at the receiver. Generally, it is assumed that perfect knowledge of the interference is available at the receiver. In practice, the interference term has to be accurately estimated to avoid performance degradation. Several estimation techniques have been proposed lately in the case of superimposed signals. In this paper, we present an overview on existing channel estima-tion methods and we propose an improved channel estimation technique that combines estimation using an autocorrelation based method and the Expectation-Maximization algorithm, and uses pilot symbol assisted modulation to further improve the performance and achieve optimal interference cancellation. Keywords—Satellite communication, Network coding, Channel estimation, Expectation-maximization algorithm...|$|R
40|$|The {{emergence}} of Machine-to-Machine (M 2 M) communication requires new Medium Access Control (MAC) schemes and physical (PHY) layer concepts {{to support a}} massive number of access requests. The concept of coded <b>random</b> <b>access,</b> introduced recently, greatly outperforms other <b>random</b> <b>access</b> <b>methods</b> and is inherently capable {{to take advantage of}} the capture effect from the PHY layer. Furthermore, at the PHY layer, compressive sensing based multi-user detection (CS-MUD) is a novel technique that exploits sparsity in multi-user detection to achieve a joint activity and data detection. In this paper, we combine coded <b>random</b> <b>access</b> with CS-MUD on the PHY layer and show very promising results for the resulting protocol. Comment: Submitted to Globecom 201...|$|R
30|$|This article proposes such a {{distributed}} mechanism. The {{basic concepts}} are as follows: First, the selection is {{performed in a}} contention-based manner with the goal to obtain low signaling overhead. Two <b>random</b> <b>access</b> <b>methods</b> are proposed as alternatives. The first one maximizes the probability of successful selection; the second one reduces the signaling overhead in terms of reply messages sent by candidate nodes. Second, the selection {{takes into account the}} specific capability of each node to perform a given task. This capability is quantified in terms of a metric maintained by each node. Nodes with a high metric are well-suited to become selected and are thus preferred in the <b>random</b> <b>access</b> process.|$|R
40|$|Abstract—The {{random access}} methods used for support of machine-type {{communications}} (MTC) in current cellular stan-dards are derivatives of traditional framed slotted ALOHA and therefore {{do not support}} high user loads efficiently. Motivated by the <b>random</b> <b>access</b> <b>method</b> employed in LTE, we propose a novel approach that is able to sustain a wide random access load range, while preserving the physical layer unchanged and incurring minor changes in the medium access control layer. The proposed scheme increases the amount of available con-tention resources, without resorting to the increase of system resources, such as contention sub-frames and preambles. This increase is accomplished by expanding the contention space to the code domain, {{through the creation of}} random access codewords. Specifically, in the proposed scheme, users perform random access by transmitting one or none of the available LTE orthogonal preambles in multiple random access sub-frames, thus creating access codewords that are used for contention. In this way, for the same number of random access sub-frames and orthogonal preambles, the amount of available contention resources is drastically increased, enabling the support of an increased number of MTC users. We present the framework and analysis of the proposed code-expanded <b>random</b> <b>access</b> <b>method</b> and show that our approach supports load regions that are beyond the reach of current systems. I...|$|E
40|$|IEEE 802. 16 {{protocols}} for metropolitan {{broadband wireless}} access systems have been standardized recently. According to the standard, a subscriber station can deliver bandwidth request messages to a base station by numerous methods. This paper provides both the simulation and analytical models for the investigation of specified <b>random</b> <b>access</b> <b>method,</b> which is compared with centralized polling and station- grouping mechanisms. Based on the assumptions of Bernoulli request arrival process and ideal channel conditions, the mean delay of a request transmission is evaluated for varying number of transmission opportunities and different arrival rates...|$|E
40|$|The {{random access}} methods used for support of machine-type {{communications}} (MTC) in current cellular standards are derivatives of traditional framed slotted ALOHA and therefore {{do not support}} high user loads efficiently. Motivated by the <b>random</b> <b>access</b> <b>method</b> employed in LTE, we propose a novel approach that is able to sustain a wide random access load range, while preserving the physical layer unchanged and incurring minor changes in the medium access control layer. The proposed scheme increases the amount of available contention resources, without resorting to the increase of system resources, such as contention sub-frames and preambles. This increase is accomplished by expanding the contention space to the code domain, {{through the creation of}} random access codewords. Specifically, in the proposed scheme, users perform random access by transmitting one or none of the available LTE orthogonal preambles in multiple random access sub-frames, thus creating access codewords that are used for contention. In this way, for the same number of random access sub-frames and orthogonal preambles, the amount of available contention resources is drastically increased, enabling the support of an increased number of MTC users. We present the framework and analysis of the proposed code-expanded <b>random</b> <b>access</b> <b>method</b> and show that our approach supports load regions that are beyond the reach of current systems. Comment: 6 Pages, 7 figures, This paper has been submitted to GC' 12 Workshop: Second International Workshop on Machine-to-Machine Communications 'Key' to the Future Internet of Thing...|$|E
40|$|In this paper, {{we propose}} {{efficient}} algorithms for duplicate detection from multiple data sources that are themselves duplicate-free. When developing these algorithms, {{we take the}} full consideration of various possible cases given the workload of data sources to be cleaned and the available memory. These algorithms are memory and I/O efficient, being able {{to reduce the number}} of pair-wise record comparison and minimize the total page access cost involved in the cleaning process. Experimental evaluation demonstrates that the algorithms we propose are efficient and are able to achieve better performance than SNM and <b>random</b> <b>access</b> <b>methods.</b> ...|$|R
50|$|LocalTalk is a {{particular}} implementation of the physical layer of the AppleTalk networking system from Apple Computer. LocalTalk specifies a system of shielded twisted pair cabling, plugged into self-terminating transceivers, running {{at a rate of}} 230.4 kbit/s. CSMA/CA was implemented as a <b>random</b> multiple <b>access</b> <b>method.</b>|$|R
40|$|Abstract — While the {{practical}} coding scheme [1] {{has been shown}} to be able to improve throughput of wireless networks, there still lacks fundamental understanding on how the coding scheme works under realistic settings, namely, when it operates on a realistic physical layer and the medium access is controlled by some <b>random</b> <b>access</b> <b>methods.</b> In this paper, we provide a formal analysis on the performance of {{the practical}} coding scheme under such realistic settings. The key performance measure is the encoding number, i. e., the number of packets that can be encoded by a coding node in each transmission. We provide an upper bound on the encoding number for the general coding topology, and derive the average encoding number and system throughput for a general class of <b>random</b> <b>access</b> mechanisms. Based on the practical coding scheme, we also derive a tighter upper bound on the throughput gain for a general wireless network. Our results can be particularly useful for coding-related MAC/Routing protocol design and analysis. I...|$|R
40|$|Abstract—IEEE 802. 16 {{protocols}} for metropolitan {{broadband wireless}} access systems have been standardized recently. According to the standard, a subscriber station can deliver bandwidth request messages to a base station by numerous methods. This paper provides both the simulation and analytical models for the investigation of specified <b>random</b> <b>access</b> <b>method,</b> which is compared with centralized polling and station-grouping mechanisms. Based on the assumptions of Bernoulli request arrival process and ideal channel conditions, the mean delay of a request transmission is evaluated for varying number of transmission opportunities and different arrival rates. Keywords-random access algorithm; medium access contrrol protocol; bandwidth request; IEEE 802. 16; WiMaX I...|$|E
40|$|A fully automated, <b>random</b> <b>access</b> <b>method</b> for the {{determination}} of cannabinoids (UTHC) was developed for the Dimension AR and XL clinical chemistry systems. The method utilizes Abuscreen ONLINE reagents and a multianalyte liquid calibrator containing 11 -nor-Δ 9 -THC- 9 -carboxylic acid. Within-run and total reproducibility, determined using NCCLS protocol EP 5 - T 2, was less than 0. 6 % and 1. 6 % CV, respectively, at all concentrations. Calibration stability was retained for at least 30 days. An extensive evaluation of non-structurally related drugs and various physiological substances indicated lack of interference in the method. No sample carry-over was observed following a specimen containing 1886 ng/ml 11 -nor-Δ 9 -THC- 9 -carboxylic acid. A 99. 1 % agreement (N = 445 samples) was found between an EMIT based method on the aca discrete clinical analyser and the Dimension UTHC method...|$|E
40|$|Super dense {{wireless}} sensor networks (WSNs) {{have become}} popular {{with the development of}} Internet of Things (IoT), Machine-to-Machine (M 2 M) communications and Vehicular-to-Vehicular (V 2 V) networks. While highly-dense wireless networks provide efficient and sustainable solutions to collect precise environmental information, a new channel access scheme is needed to solve the channel collision problem caused by the large number of competing nodes accessing the channel simultaneously. In this paper, we propose a space-time <b>random</b> <b>access</b> <b>method</b> based on a directional data transmission strategy, by which collisions in the wireless channel are significantly decreased and channel utility efficiency is greatly enhanced. Simulation results show that our proposed method can decrease the packet loss rate to less than 2 % in large scale WSNs and in comparison with other channel access schemes for WSNs, the average network throughput can be doubled...|$|E
40|$|In this paper, a new {{approach}} is proposed to analyze the performance of buffered <b>random</b> multiple <b>access</b> protocols called tagged user analysis (TUA). In TUA, each user is modeled as an independent queueing system, which operates at its own equilibrium probability. As a result, the classical queueing theory can be employed to analyze the queueing behavior of each user. On {{the basis of the}} behavior of the tagged user, the performance of the whole system is analyzed. TUA is a unified method of analyzing most of <b>random</b> <b>access</b> <b>methods</b> including the heterogeneous <b>random</b> multiple <b>access</b> techniques that are difficult to analyze otherwise. Furthermore, TUA can also handle those systems where user terminals may have arbitrary packet size (in slots) distribution, arbitrary arrival processes such as batch packet arrivals in Bernoulli, arbitrary service principle such as priority queueing, last came first served, and random service. In this paper, in addition to analyzing for the distributions of several performance indices, their mean values are obtained...|$|R
40|$|This writing {{looks at}} the {{development}} and evaluation of new computerbased ways to display and interact with film and video. Given traditional ways to store and work with film and video, both became a linear medium, dependent on time. So to {{develop an understanding of}} its contents, one has to view it in full length. We have been showing that, using alternative ways of presentation and more intuitive <b>random</b> <b>access</b> <b>methods,</b> it is possible to overcome these limitations of linearity and time dependency. It is therefore possible to gain a faster understanding and editing of the contents of the film. The tools we present allow for an additional visualization of meta data about the film. (orig.) SIGLEAvailable from TIB Hannover: RR 8957 (1999, 20) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
40|$|Combinatorial and probability-theory {{methods are}} {{employed}} {{to analyze the}} <b>random</b> multiple <b>access</b> <b>method</b> using Bernoulli scheme for resolving conflicts (collisions in transmission). The technique for determining the length of each particular process is described; the average lengths of the processes are established for specified number of parties in conflict, as is the time loss involved in Implementing the given <b>access</b> <b>method.</b> Upper and lower bounds {{for the length of}} the processes are obtained...|$|R
40|$|The {{communication}} channel is a shared resource in networked control systems, and channel access at every instant cannot be guaranteed. In this paper, we propose a novel architecture for control over wireless networks with integrated {{medium access control}} (MAC). We evaluate the impact of constrained channel access {{on the cost of}} controlling a single plant over a network and establish that the separation principle holds under certain conditions on the MAC. We arrive at a classification of random access methods for networked control systems and identify a structure for each method. Then, by evaluating the increase in cost compared to a conventional setup, we identify an adaptive <b>random</b> <b>access</b> <b>method</b> which uses a threshold-based decision criteria on the current data to determine channel access. Finally, we give stability criteria for control applications using these medium access methods. QC 2011111...|$|E
40|$|Abstract — When using a <b>random</b> <b>access</b> <b>method,</b> such as CSMA/CA scheme, {{which is}} defined for IEEE 802. 11 based {{wireless}} ad-hoc networks, a large bandwidth capacity is wasted due to collisions. Therefore, {{to improve the}} channel capacity in wireless ad-hoc networks, we propose a new backoff algorithm named Neighbourhood Backoff Algorithm (NBA). A novel feature of the NBA scheme is its neighbourhood consideration, in which every node modifies its backoff interval according to the number N of its neighbours. In order to find the optimum parameters for NBA, we have studied the backoff intervals as function of different number of active nodes (N) in a single transmission area. We {{have found that the}} minimum contention window is proportional to the number of neighbours. Our experiments show a better behaviour of the NBA scheme in comparison to the BEB (Binary Exponential Backoff) scheme defined in IEEE 802. 11 CSMA/CA. I...|$|E
40|$|New heights {{for hard}} disk drives To this day, hard disk drives (HDDs) remain the only archival mass data storage device in a computer. The first disk drive, called RAMAC (<b>random</b> <b>access</b> <b>method</b> of {{accounting}} and control), {{was developed for}} the IBM 350 computer in 19571. Over the past decade, as the demands for digital data have exploded, the storage capacity of HDDs has grown at a matching rate, if not faster. Today, a 3. 5 ” HDD has a capacity of 160 GB, capable of storing nearly a thousand times more data than a HDD {{of the same size}} just ten years ago. The area storage density of a disk surface in a RAMAC was only 2 kbit/in 2. It is now 60 Gbit/in 2, a 30 million-fold increase over the past 46 years with an average annual growth rate of nearly 80 % during the last ten years. Recent demonstrations have shown area recording densities 2 as high as 150 Gbit/in 2...|$|E
40|$|International audienceIn recent <b>random</b> <b>access</b> <b>methods</b> {{used for}} {{satellite}} communications, collisions between packets {{are not considered}} as destructive. In fact, {{to deal with the}} collision problem, successive interference cancellation is performed at the receiver. Generally, it is assumed that the receiver has perfect knowledge of the interference. In practice, the interference term is affected by the transmission channel parameters, i. e., channel attenuation, timing offsets, frequency offsets and phase shifts, and needs to be accurately estimated and canceled to avoid performance degradation. In this paper, we study the performance of an enhanced channel estimation technique combining estimation using an autocorrelation based method and the Expectation-Maximization algorithm integrated in a joint estimation and decoding scheme. We evaluate the effect of residual estimation errors after successive interference cancellation. To validate our experimental results, we compare them to the Cramer-Rao lower bounds for the estimation of channel parameters in case of superimposed signals...|$|R
40|$|In {{this paper}} we {{investigate}} the capture phenomenon {{and its consequences}} in nonbitsynchronous mobile packet radio networks for BPSK and DPSK modulation. Exact values of the bit error probability for given signal-to-noise ratios of colliding BPSK signals are derived. Packet error rates, which are needed for analysis of slotted <b>random</b> multiple <b>access</b> <b>methods,</b> are gained by simulation. Two kinds of mobile radio channels are considered: the Rayleigh fading channel and the land mobile satellite channel...|$|R
40|$|International audienceMotivated by {{scenario}} {{requirements for}} 5 G cellular networks, we study {{one of the}} candidate protocols for massive random access: the family of <b>random</b> <b>access</b> <b>methods</b> known as Coded Slotted ALOHA (CSA). A recent trend in research has explored aspects of such methods in various contexts, but one aspect has not been fully taken into account: the impact of path loss, which is a major design constraint in long-range wireless networks. In this article, we explore the behavior of CSA, {{by focusing on the}} path loss component correlated to the distance to the base station. Path loss provides opportunities for capture, improving the performance of CSA. We revise methods for estimating CSA behavior, provide bounds of performance, and then, focusing on the achievable throughput, we extensively explore the key parameters, and their associated gain (experimentally). Our results shed light on the behavior of the optimal distribution of repetitions in actual wireless networks...|$|R
40|$|Recent {{advances}} in signal processing techniques have enabled wireless networks to have multi-packet reception (MPR) capability at the physical layer, {{where it is}} possible to receive one or more packets when concurrent transmissions occur. In this paper, we propose the novel multi-reservation multiple access (MRMA) scheme for future wireless multimedia networks based on such an MPR channel model, which fully exploit the channel's MPR capacity while fulfilling the quality of service (QoS) requirements of different multimedia traffic. MRMA employs a centralized reservation mechanism to control the number of simultaneous packets transmitted in each time slot to satisfy a traffic class' packet loss ratio requirement. Moreover, MRMA incorporates an efficient adaptive <b>random</b> <b>access</b> <b>method</b> and a priority control mechanism to provide guaranteed and best-effort services for real time voice/video traffic and connectionless data traffic, respectively. Simulation and analytical results are presented to illustrate the effectiveness of the proposed scheme. Department of ComputingRefereed conference pape...|$|E
40|$|The {{random access}} methods used for support of Machine-to-Machine (M 2 M), also {{referred}} to as Machine-Type Communications (MTC), in current cellular standards are derivatives of traditional framed slotted ALOHA and therefore do not support high user loads efficiently. We propose an approach that is motivated by the <b>random</b> <b>access</b> <b>method</b> employed in LTE, which significantly increases the amount of contention resources without increasing the system resources, such as contention sub-frames and preambles. This is accomplished by a logical, rather than physical, extension of the access method in which the available system resources are interpreted in a novel manner. Specifically, in the proposed scheme, users perform random access by transmitting orthogonal preambles in multiple random access sub-frames, in this way creating access codewords that are used for contention. We show that, for the same number of random access sub-frames and orthogonal preambles, the amount of available contention resources is drastically increased, enabling the massive support of MTC users that is beyond the reach of current systems...|$|E
40|$|We {{present a}} <b>random</b> <b>access</b> <b>method</b> {{inspired}} on Bloom filters that is suited for Machine-Type Communications (MTC). Each accessing device sends a signature during the contention process. A signature is constructed using the Bloom filtering method and contains {{information on the}} device identity and the connection establishment cause. We instantiate the proposed method over the current LTE-A access protocol. However, the method is applicable to a more general class of random access protocols that use preambles or other reservation sequences, as {{expected to be the}} case in 5 G systems. We show that our method utilizes the system resources more efficiently and achieves significantly lower connection establishment latency in case of synchronous arrivals, compared to the variant of the LTE-A access protocol that is optimized for MTC traffic. A dividend of the proposed method is that it allows the base station (BS) to acquire the device identity and the connection establishment cause already in the initial phase of the connection establishment, thereby enabling their differentiated treatment by the BS. Comment: Accepted for presentation on IEEE Globecom 201...|$|E
40|$|AbstractA {{new method}} is given for obtaining a boolean {{expression}} whose satisfiability {{is equivalent to}} the existence of an accepting computation of some nondeterministic machine. Although starting from <b>random</b> <b>access</b> machines, this <b>method</b> gives an expression of the same O(T log T) length as the best reduction from general Turing machines...|$|R
40|$|Abstract—This paper {{focuses on}} {{wireless}} body area networks (WBAN) targeted for medical ICT applications. The studied network follows a typical IEEE 802. 15. 4 beacon-enabled star topology. We simulate {{the collection of}} medical data from patients using wireless sensors. Impulse radio ultra wideband (IR-UWB) is chosen as a physical layer technology, {{in compliance with the}} IEEE 802. 15. 4 a standard. Two <b>random</b> <b>access</b> <b>methods,</b> slotted Aloha (S-Aloha) and preamble sense multiple access (PSMA) are studied in terms of throughput and energy consumption. This paper has two main objectives: 1) to address realistic performance of the two selected MAC protocols, accounting for false alarm, miss-detection and capture effect, when using IR-UWB; 2) to obtain feedback information on the design of medical networks that use the IEEE 802. 15. 4 beacon-enabled star topology. Therefore, the performances are obtained increasing the number of active sensors, varying in parallel typical superframe parameters as beacon order and superframe order to test the reaction of the network at the introduction of an inactive period. I...|$|R
40|$|However, {{the number}} {{and the size of}} the images {{required}} are highly memory demanding. Based on the light field data structure, we propose an improved compression scheme favoring visual appearance and fast <b>random</b> <b>access.</b> Our <b>method</b> relies on vector quantization for preserving access in constant time. 2 D Bounding boxes and masks are used to reduce the number of vectors during quantization. Several light field images are used instead of blocks of 4 D samples, so that image similarities be exploited as much as possible. Psychophysical experiments performed in a room designed according to ITU recommendations validate the quality metrics of our method. ...|$|R
