293|28|Public
2500|$|... "Simultaneous {{communication}} was determined {{as the basic}} communication method {{in the high school}} area. This method employs the media of speech, speechreading (lipreading), amplification through group or individual hearing aids, writing, dramatics, pantomime, finger-spelling and the language of signs. This means that students with little <b>residual</b> <b>hearing</b> can see the manual symbols on the hands; those who are proficient lipreaders can follow oral conversation clues; those who have a usable residue of hearing can follow auditory clues. All conversation is given at a normal rate of speed. The simultaneous method reduces the need for numerous repetitions and augments our traditionally strong program in speech, lipreading, and auditory training. [...] " ...|$|E
50|$|A special {{surgical}} technique {{is the key}} to preserving the <b>residual</b> <b>hearing</b> of the patient. In most routine cochlear implant surgeries, any <b>residual</b> <b>hearing</b> will likely be destroyed.|$|E
5000|$|Use of <b>residual</b> <b>hearing</b> (speaking clearly, hearing aids) or sight (signing {{within a}} {{restricted}} visual field, writing with large print).|$|E
40|$|Attribution License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. In the past, {{it was thought}} that hearing loss patients with <b>residual</b> low-frequency <b>hearing</b> would not be good candidates for cochlear implantation since insertion was expected to induce inner ear trauma. Recent advances in electrode design and surgical techniques havemade the preservation of <b>residual</b> low-frequency <b>hearing</b> achievable and desirable. The importance of preserving <b>residual</b> low-frequency <b>hearing</b> cannot be underestimated in light of the added benefit of hearing in noisy atmospheres and in music quality. The concept of electrical and acoustic stimulation involves electrically stimulating the nonfunctional, high-frequency region of the cochlea with a cochlear implant and applying a hearing aid in the low-frequency range. The principle of preserving low-frequency hearing by a “soft surgery ” cochlear implantation could also be useful to the population of children who might profit from regenerative hair cell therapy in the future. Main aspects of low-frequency hearing preservation surgery are discussed in this review: its brief history, electrode design, principles and advantages of electric-acoustic stimulation, surgical technique, and further implications of this new treatment possibility for hearing impaired patients. 1...|$|R
40|$|With {{the use of}} {{standard}} electrodes in cochlear implantation, <b>residual</b> acoustic <b>hearing</b> is markedly reduced or even lost. Possible reasons for this loss are direct implantation trauma to the inner ear, reaction of the cochlea triggered by the implantation, and change of cochlear mechanics due to the electrode...|$|R
40|$|Although {{cochlear}} implants (CI) {{traditionally have}} been used to treat individuals with bilateral profound sensorineural hearing loss, a recent trend is to implant individuals with <b>residual</b> low-frequency <b>hearing.</b> Patients who retain some <b>residual</b> acoustic <b>hearing</b> after surgery often can benefit from electro-acoustic stimulation (EAS) technologies, which combine conventional acoustic amplification with electrical stimulation. However, interactions between acoustic and electrical stimulation may affect outcomes adversely and are time-consuming and difficult to assess behaviorally. This study demonstrated the feasibility of using the Advanced Bionics HiRes 90 K Advantage implant electronics and HiFocus Mid Scala/ 1 j electrode to measure electrocochleography (ECochG) responses in the presence of electrical stimulation to provide an objective estimate of peripheral physiologic EAS interactions. In general, electrical stimulation reduced ECochG response amplitudes to acoustic stimulation. The degree of peripheral EAS interaction varied as a function of acoustic pure tone frequency and the intra-cochlear location of the electrically stimulated electrode. Further development of this technique may serve to guide and optimize clinical EAS system fittings in the future...|$|R
50|$|There is {{a certain}} patient group that has some degree of <b>residual</b> <b>hearing</b> in the low {{frequencies}} and a severe hearing loss in the high frequencies. This group only receives limited benefits from traditional amplification because {{of the severity of}} the hearing loss in the high frequencies. They suffer from inadequate speech comprehension, even in the best aided condition. Nor are they classic cochlear implant candidates, because of their mostly intact low frequency <b>residual</b> <b>hearing.</b>|$|E
50|$|Electric {{stimulation}} of the auditory system via cochlear implant is a commonly used technique for individuals with a severe to profound sensorineural hearing loss, {{as well as for}} those adults and children with some <b>residual</b> <b>hearing.</b>|$|E
50|$|Auditory-verbal {{therapy is}} a method for {{teaching}} deaf children to listen and speak using their <b>residual</b> <b>hearing</b> {{in addition to the}} constant use of amplification devices such as hearing aids, FM devices, and cochlear implants. Auditory-verbal therapy emphasizes speech and listening.|$|E
40|$|The {{purpose of}} this study was to explore the {{potential}} advantages, both theoretical and applied, of preserving low-frequency acoustic hearing in cochlear implant patients. Several hypotheses are presented that predict that <b>residual</b> low-frequency acoustic <b>hearing</b> along with electric stimulation for high frequencies will provide an advantage over traditional long-electrode cochlear implants for the recognition of speech in competing backgrounds. A simulation experiment in normal-hearing subjects demonstrated a clear advantage for preserving low-frequency <b>residual</b> acoustic <b>hearing</b> for speech recognition in a background of other talkers, but not in steady noise. Three subjects with an implanted "short-electrode" cochlear implant and preserved low-frequency acoustic hearing were also tested on speech recognition in the same competing backgrounds and compared to a larger group of traditional cochlear implant users. Each of the three short-electrode subjects performed better than any of the traditional long-electrode implant subjects for speech recognition in a background of other talkers, but not in steady noise, in general agreement with the simulation studies. When compared to a subgroup of traditional implant users matched according to speech recognition ability in quiet, the short-electrode patients showed a 9 -dB advantage in the multitalker background. These experiments provide strong preliminary support for retaining <b>residual</b> low-frequency acoustic <b>hearing</b> in cochlear implant patients. The results are consistent with the idea that better perception of voice pitch, which can aid in separating voices in a background of other talkers, was responsible for this advantage...|$|R
5000|$|The <b>residual</b> {{knowledge}} that <b>hearing</b> children can access is often lost on deaf children. A hearing child can {{listen in on}} adult conversations, TV, radio and the news to learn {{things that are not}} specifically taught or told to them. This is not the case with the deaf child, who, in a hearing environment, can only learn what is directly communicated to them. This often leads to gaps in general knowledge, which can be both harmful to academic success and social interactions.|$|R
40|$|Hypothesis: The aim of {{this study}} was to {{investigate}} the impact of cochlear implant electrode insertion on middle-ear low frequency function in humans. Background: Preservation of <b>residual</b> low frequency <b>hearing</b> with addition of electrical speech processing can improve the speech perception abilities and hearing in noise of cochlear implant users. Preservation of low frequency hearing requires an intact middle-ear conductive mechanism in addition to intact inner-ear mechanisms. Little is known about the effect of a cochlear implant electrode on middle-ear function. Methods: Stapes displacement was measured in seven patients undergoing cochlear implantation. Measurements were carried out intra-operatively before and after electrode insertion. Each patient acted as his or her own control. Sound was delivered into the external auditory canal via a speaker and calibrated via a probe microphone. The speaker and probe microphone were integrated into an individually custom-made ear mould. Ossicular displacement in response to a multisine stimulus at 80 dB SPL was measured at the incudostapedial joint via the posterior tympanotomy, using an operating microscope mounted laser Doppler vibrometry system. Results: Insertion of a cochlear implant electrode into the scala tympani had a variable effect on stapes displacement. In three patients, there was little change in stapes displacement following electrode insertion. In two patients, there was a significant increase, while in a further two there was a significant reduction in stapes displacement. This variability may reflect alteration of cochlear impedance, possibly due to differing loss of perilymph associated with the electrode insertion. Conclusion: Insertion of a cochlear implant electrode produces a change in stapes displacement at low frequencies, which may have an effect on <b>residual</b> low frequency <b>hearing</b> thresholds...|$|R
50|$|Long-term {{research}} has shown that mechanical flexibility of the electrode array {{is one of the key}} factors for preserving <b>residual</b> <b>hearing.</b> The smaller the force used to insert the electrode, the greater the chance of protecting the fragile structures within the cochlea.|$|E
5000|$|The type of {{intervention}} required depends on several factors. Chief among {{these is the}} degree of impairment. When a child has a fair degree of <b>residual</b> <b>hearing,</b> the correct intervention would be fitting [...] "optimised" [...] hearing aids. [...] "Optimisation" [...] means fitting the child with a hearing aid appropriate to its degree of deafness.|$|E
50|$|This {{being the}} case, {{a single person}} could be {{described}} as hearing by one person and Deaf by another because the first person was thinking simply about the subject's sensitivity to sound whereas the other person was thinking, partially about the persons ability to rely on <b>residual</b> <b>hearing,</b> but also about their personal views, their identity, or perhaps their ignorance of cultural norms.|$|E
40|$|Cochlear implant (CI) {{users have}} {{difficulty}} understanding speech in noisy listening conditions and perceiving music. Aided <b>residual</b> acoustic <b>hearing</b> in the contralateral ear can mitigate these limitations. The present study examined contributions of electric and acoustic hearing to speech understanding in noise and melodic pitch perception. Data was collected with the CI only, {{the hearing aid}} (HA) only, and both devices together (CI+HA). Speech reception thresholds (SRTs) were adaptively measured for simple sentences in speech babble. Melodic contour identification (MCI) was measured with and without a masker instrument; the fundamental frequency of the masker was varied to be overlapping or non-overlapping with the target contour. Results showed that the CI contributes primarily to bimodal speech perception and that the HA contributes primarily to bimodal melodic pitch perception. In general, CI+HA performance was slightly improved relative to the better ear alone (CI-only) for SRTs but not for MCI, with some subjects experiencing a decrease in bimodal MCI performance relative to the better ear alone (HA-only). Individual performance was highly variable, and the contribution of either device to bimodal perception was both subject- and task-dependent. The results suggest that individualized mapping of CIs and HAs may further improve bimodal speech and music perception...|$|R
40|$|Speech {{recognition}} in noise and music perception is especially challenging for current cochlear implant users. The present study utilizes the <b>residual</b> acoustic <b>hearing</b> in the nonimplanted ear in five cochlear implant users to elucidate {{the role of}} temporal fine structure at low frequencies in auditory perception and {{to test the hypothesis}} that combined acoustic and electric hearing produces better performance than either mode alone. The first experiment measured speech {{recognition in}} the presence of competing noise. It was found that, although the residual low-frequency (< 1000 Hz) acoustic hearing produced essentially no recognition for speech recognition in noise, it significantly enhanced performance when combined with the electric hearing. The second experiment measured melody recognition in the same group of subjects and found that, contrary to the speech recognition result, the low-frequency acoustic hearing produced significantly better performance than the electric hearing. It is hypothesized that listeners with combined acoustic and electric hearing might use the correlation between the salient pitch in low-frequency acoustic hearing and the weak pitch in the envelope to enhance segregation between signal and noise. The present study suggests the importance and urgency of accurately encoding the fine-structure cue in cochlear implants. (c) 2005 Acoustical Society of America...|$|R
40|$|Recently, the {{audiometric}} {{criteria for}} cochlear implantation have been relaxed. At present, people with considerable <b>residual</b> low-frequency <b>hearing</b> have become eligible for implantation. The audiogram in this subpopulation {{is characterized by}} a large hearing loss in the high-frequency region, while hearing thresholds at low frequencies are only mildly raised or even normal. The high-frequency hearing loss, however, might be so severe that acoustical amplification has no benefit for speech understanding. These people might be treated by electrical stimulation of the high-frequency part of the cochlea and acoustical amplification of the low frequencies. <b>Residual</b> low-frequency <b>hearing</b> has proven to be useful for speech understanding with a cochlear implant. Especially in noisy environments, low-frequency hearing increases speech understanding. Due to this beneficial effect of low-frequency hearing, hybrid implants have been developed that combine an implant with a conventional hearing aid. Due to the increased interest in combined electrical and acoustical stimulation (EAS), research characterization of the interaction between electrical and acoustical stimulation in the cochlea is important. This thesis contains four different experiments that describe these interactions. The most important research questions were: “What are the effects of electrical stimulation on acoustically evoked responses in the auditory nerve”, and “What are the effects of acoustical stimulation on electrically evoked responses in the auditory nerve?”. The experiments conducted consisted of electrophysiological recordings of cochlear potentials in the cochlea of the guinea pig. Especially acoustically and electrically evoked compound action potentials were important recording parameters. These potentials represent the synchronised activity of many auditory-nerve fibres. We compared responses evoked with electro-acoustical stimulation to the responses evoked with acoustical or electrical stimulation alone. We systematically varied stimulus parameters such as acoustic frequency, acoustic level, electric current level, pulse width and pulse rate. We identified critical parameters that mainly determined electro-acoustical interaction. Low current levels and short pulse widths resulted in minimal interaction between electrical stimulation and low-frequency evoked acoustic responses. Therefore, low current levels and short pulse widths are advisable in EAS strategies to preserve acoustical responses. Furthermore, we found indirect evidence that high pulse rates and short electrodes are probably best to minimize interaction of electrical stimulation on acoustically evoked cochlear responses. We found that acoustic responses recover within milliseconds after electrical stimulation, which might find use in future EAS strategies. Regarding electrically evoked responses, loud acoustic stimuli suppressed electrically evoked auditory nerve activity. Hence, loud acoustic stimuli should probably be avoided in hybrid implants. However, desynchronizing effects of low-level (acoustic) noise may actually be beneficial to electric hearing. The findings that suppression of electrical auditory nerve responses decreased rapidly within a few milliseconds during noise presentation might be useful in future EAS strategy design. Last, the transient increase of the eCAP amplitude after noise offset might be important for EAS strategie...|$|R
50|$|Lip-reading, {{also known}} as lipreading or speechreading, is a {{technique}} of understanding speech by visually interpreting {{the movements of the}} lips, face and tongue when normal sound is not available. It relies also on information provided by the context, knowledge of the language, and any <b>residual</b> <b>hearing.</b> Although ostensibly used by deaf and hard-of-hearing people, most people with normal hearing process some speech information from sight of the moving mouth.|$|E
50|$|The {{topic of}} deaf {{education}} {{has long been}} filled with controversy. There are two strategies for teaching the deaf that exist: an aural/oral approach or a manual approach. Those who use aural-oralism believe {{that children who are}} deaf or hard-of-hearing should be taught through the use of <b>residual</b> <b>hearing,</b> speech and speechreading. Those promoting a manual approach believe the deaf should be taught through the use of signed languages, such as American Sign Language (ASL).|$|E
50|$|Today {{a variety}} of good quality hearing aids are {{available}} - analog or digital body worn (for small children) or ear level for older children. When fitting a hearing aid, a competent audiologist has to assess the child's <b>residual</b> <b>hearing,</b> look at the hearing aid's performance and fit the child with an appropriate instrument. Equally important is the ear mould, which has to be custom made to suit {{the shape of the}} child's ear.|$|E
40|$|Twelve {{patients}} who were treated for ear injuries at Guy's Hospital following the London Bridge bomb blast in February 1992 were reviewed. Among three there were four perforated eardrums, two of which closed spontaneously (50 %). All three patients had a persistent mixed hearing loss. The remaining nine patients had acute sensorineural hearing loss and/or tinnitus only. Four of these had resolved completely by 4 h, another one by 48 h, and two by 4 weeks. Two patients had a <b>residual</b> high frequency <b>hearing</b> loss. In total, five patients (42 %) have a persistent hearing loss. None of the patients suffered from balance problems. In summary, the ear is very susceptible to bomb blast injury, {{but there is a}} high rate of spontaneous closure of perforations and improvement of sensorineural hearing loss and tinnitus...|$|R
40|$|Objectives/Hypothesis: To {{evaluate}} {{the safety and}} efficacy of acoustic and electric sound processing for individuals with significant <b>residual</b> low-frequency <b>hearing</b> and severe-to-profound high-frequency sensorineural hearing loss. Study Design: Prospective, single-arm repeated measures, single-subject design. Methods: Fifty individuals, 18 years old, with low-frequency hearing and severe high-frequency loss were implanted with the Cochlear Nucleus Hybrid L 24 implant at 10 investigational sites. Preoperatively, subjects demonstrated consonant-nucleus-consonant word scores of 10 % through 60 % in the ear to be implanted. Subjects were assessed prospectively, preop-eratively, and postoperatively on coprimary endpoints of consonant-nucleus-consonant words, AzBio sentences in noise, and self-assessment measures. Results: Significant mean improvements were observed for coprimary endpoints: consonant-nucleus-consonant words (35. 8 percentage points) and AzBio sentences in noise (32. 0 percentage points), both at P< 0. 001. Ninety-six percent of sub-jects performed equal or better on speech in quiet and 90 % in noise. Eighty-two percent of subjects showed improved per-formance on speech in quiet and 74 % in noise. Self-assessments were positive, corroborating speech perception results. Conclusion: The Nucleus Hybrid System provides significant improvements in speech intelligibility in quiet and noise for individuals with severe high-frequency loss and some low-frequency hearing. This device expands indications to hearing-impaired individuals who perform poorly with amplification due to bilateral high-frequency hearing loss and who previously were not implant candidates...|$|R
40|$|OBJECTIVE: To monitor {{changes in}} {{cochlear}} function during cochlear implantation using electrocochleography (ECoG) and to correlate changes to postoperative hearing preservation. METHODS: ECoG responses to acoustic stimuli of 250, 500, and 1000 Hz were recorded during cochlear implantation. The recording electrode {{was placed on}} the promontory and stabilized to fix the position during cochlear implantation. Baseline recordings were obtained after completion of the posterior tympanotomy. Changes of the ongoing ECoG response at suprathreshold intensities were analyzed after full insertion of the cochlear implant electrode array. Audiometric tests were conducted before and 4 weeks after surgery and correlated with electrophysiological findings. RESULTS: Ninety-five percent (18 / 19) of cochlear implant subjects had measurable ECoG responses. Under unchanged conditions, recordings showed a high repeatability without significant differences between 2 recordings (p ≤ 0. 01). Ninety-four percent (17 / 18) of subjects showed no relevant changes in ECoG recordings after insertion of the cochlear implant electrode array. One subject showed decreases in responses at all frequencies indicative of cochlear trauma. This was associated with a complete hearing loss 4 weeks after surgery compared with mean presurgical low-frequency hearing of 78 dB HL. CONCLUSION: Extracochlear ECoG is a reliable tool to assess cochlear function during cochlear implantation. Moderate threshold shifts could be caused by postoperative mechanisms or minor cochlear trauma. Detectable changes in extracochlear ECoG recordings, indicating gross cochlear trauma, are probably predictive of complete loss of <b>residual</b> acoustic <b>hearing...</b>|$|R
5000|$|He is {{considered}} {{to be one of the}} founders of modern otology. He focused his attention on the physiology and psycho-physiology of the ear, and researched the influence that head movements had on sound perception. He stressed the significance of <b>residual</b> <b>hearing</b> and developed various diagnostic and rehabilitative methods. He was an early practitioner of electric current as a means of treatment, and also introduced a manual massage technique for the Eustachian tube, ...|$|E
50|$|Hybrid is an electro-acoustic system {{combining}} a {{cochlear implant}} with an acoustic hearing aid, suitable {{for patients who}} have <b>residual</b> <b>hearing</b> at low frequencies. The implant of the Hybrid system is a smaller variant of Nucleus, with an electrode that relays only high frequency sounds, while the acoustic component amplifies low frequency sounds and transmits them to the brain through the ordinary nerve pathway. Hybrid was launched in 2008 and won Australian Engineering Excellence and International Design Awards in 2009.|$|E
50|$|A direct {{acoustic}} {{cochlear implant}} - also DACI - is an acoustic implant which converts sound in mechanical vibrations that stimulate directly the perilymph inside the cochlea. The hearing {{function of the}} external and middle ear is being taken over by a little motor of a cochlear implant, directly stimulating the cochlea. With a DACI, people with no or almost no <b>residual</b> <b>hearing</b> but with a still functioning inner ear, can again perceive speech, sounds and music.DACI is an official product category, {{as indicated by the}} nomenclature of GMDN.|$|E
40|$|Permission is hereby {{granted to}} the University of Alberta Libraries to {{reproduce}} single copies of this thesis and to lend or sell such copies for private, scholarly or scientific research purposes only. Where the thesis is converted to, or otherwise made available in digital form, the University of Alberta will advise potential users of the thesis of these terms. The author reserves all other publication and other rights {{in association with the}} copyright in the thesis and, except as herein before provided, neither the thesis nor any substantial portion thereof may be printed or otherwise reproduced in any material form whatsoever without the author's prior written permission In this study we explored whether differences in sound quality existed between new advanced Bone Anchored Hearing Aids (BAHA). Three groups of subjects were tested. Two groups, those with normal hearing and those with sufficient <b>residual</b> cochlear <b>hearing,</b> were tested with Oticon’s Ponto Pro to Cochlear’s BP 100. The third group had either mixed hearing loss or single-sided deafness and they compared the more powerful devices (Oticon’s Ponto Pro Power and Cochlear’s BP 110). Some differences emerged within the normal hearing listeners and the power user’s. However, no significant differences in sound quality were revealed in the non-power users of the Ponto Pro and BP 100. These limited results most likely reflect a lack of power in the data due to the limited number of subjects per group. Continued data collection is warranted...|$|R
40|$|Purpose: Improved speech {{recognition}} in binaurally combined acoustic–electric stimulation (otherwise known as bimodal hearing) could arise when listeners integrate speech cues from the acoustic and electric hearing. The aims {{of this study}} were (a) to identify speech cues extracted in electric <b>hearing</b> and <b>residual</b> acoustic <b>hearing</b> in the low-frequency region and (b) to investigate cochlear implant (CI) users' ability to integrate speech cues across frequencies. Method: Normal-hearing (NH) and CI subjects participated in consonant and vowel identification tasks. Each subject was tested in 3 listening conditions: CI alone (vocoder speech for NH), hearing aid (HA) alone (low-pass filtered speech for NH), and both. Integration ability for each subject was evaluated using a model of optimal integration—the PreLabeling integration model (Braida, 1991). Results: Only a few CI listeners demonstrated bimodal benefit for phoneme identification in quiet. Speech cues extracted from the CI and the HA were highly redundant for consonants but were complementary for vowels. CI listeners also exhibited reduced integration ability for both consonant and vowel identification compared with their NH counterparts. Conclusion: These findings suggest that reduced bimodal benefits in CI listeners are due to insufficient complementary speech cues across ears, a decrease in integration ability, or both. National Organization for Hearing ResearchNational Institute on Deafness and Other Communication Disorders (U. S.) (Grant R 03 DC 009684 - 01) National Institute on Deafness and Other Communication Disorders (U. S.) (Grant R 01 DC 007152 - 02...|$|R
40|$|This is a publisher’s {{version of}} an article {{published}} in Ear and Hearing 1995. This version is reproduced with permission of Lippincott Wilkins & Williams. Objective: Use of wearable tactile speech perception devices is suggested to help overcome the difficulties in speech production resulting from severe and profound hearing impairment in children. This suggestion {{is based on the assumption}} that subjects can use tactile input in isolation, or in combination with information from <b>residual</b> aided <b>hearing,</b> to monitor and modify their speech. The present study evaluated the benefits to articulation provided through use of a multichannel electrotactile device (“Tickle Talker™”). Design: Six profoundly hearing-impaired children were videotaped speaking with the Tickle Talker on and with the Tickle Talker off during conversations with their audiologist. Five of the subjects also wore their binaural hearing aids during all recorded conversations. The number of vowels, consonants, and overall phonemes correctly articulated by each child in the two conditions were compared. Results: One subject improved articulation of initial consonants and initial phonemes; one subject improved articulation of total vowels, total consonants, initial consonants, total phonemes, and initial phonemes; and a third subject improved articulation of total vowels and medial phonemes. Conclusions: Use of on-line tactile feedback from the Tickle Talker may benefit the articulation accuracy of some children, and the device may therefore be suitable to use with children who have not responded to more traditional speech training techniques. Open Acces...|$|R
50|$|Studies with {{different}} lengths of electrodes {{have shown that}} an insertion depth of 10 mm {{has a good chance}} of preserving <b>residual</b> <b>hearing</b> {{but on the other hand}} yields little benefit in speech understanding in comparison to the hearing aid only condition. Electrodes that can be inserted to a depth of 18-22 mm are a good compromise. The insertion depth also depends on the size of the cochlea of the patient, though a range of 18-22 mm can be used as a general rule of thumb for insertion in most cochleas.|$|E
50|$|Bower's {{deafness}} {{started with}} complications at birth {{which could have}} been fatal, but was not diagnosed until he was five years old. From that age he wore body hearing aids, bulky transistor radio-style devices. He later attended the Mary Hare Grammar School near his home in Berkshire. Although supported by a very caring family, Bower found himself bullied by both hearing children and other deaf children. In 1986, after attending a loud rock music gig he developed tinnitus which affected the nature of his <b>residual</b> <b>hearing.</b> His deafness progressed and years later he became profoundly deaf.|$|E
50|$|In the mid-1800s, Catholic priests {{took the}} {{existing}} LSF and ASL and combined {{the two to}} promote education of deaf children and adolescents. Several decades later, {{under the influence of}} Western thought, oralism became the primary mode of instruction in Quebec and the rest of North America. There, students were subjected to environments that discouraged and often outright banned LSQ use, instead promoting the use of whatever <b>residual</b> <b>hearing</b> the student had if any. Such an approach had varying effects where audism lead to lower literacy rates as well as lower rates of language acquisition seen in children sent to residential schools at an early age.|$|E
40|$|OBJECTIVE: The primary {{objective}} was to report on experiences regarding the safety and efficacy of the Vibrant Soundbridge (VSB) using a floating mass transducer (FMT) -partial/total ossicular replacement prosthesis (PORP/TORP) assembly {{as a treatment for}} conductive and mixed hearing losses of mild-to-moderate/severe degree. The secondary {{objective was to}} gather information regarding device fitting, as well as to refine surgical procedures. PATIENTS: Five German-speaking adults from 2 European study sites were implanted with a VSB using an FMT-PORP/TORP assembly and evaluated before and after surgery for air-and bone-conduction thresholds and speech recognition performance. MAIN OUTCOME MEASURES: Evaluating the safety and efficacy of the VSB in combination with a PORP or TORP to treat conductive and mixed <b>hearing</b> loss. RESULTS: <b>Residual</b> cochlear <b>hearing</b> was unaffected by implantation with the device. Functional gain (measured as the difference between preoperative unaided and postoperative VSB-aided thresholds) could be calculated in 2 of 5 subjects, demonstrating that the VSB is effective in treating bone-conduction hearing losses of moderate/severe degree. Word recognition tests in quiet and noise showed good improvement in 3 of the cases. One patient experienced several other medical problems, making her audiological outcomes limited. One patient was excluded from the study owing to insufficient benefit and subsequently underwent revision surgery with FMT placement at the round window. CONCLUSION: The use of the VSB, implanted using the FMT-PORP/TORP assembly, was safe in all and efficacious in 3 of the 5 cases in this study. These are patients who may have few, if any, other options to manage their hearing loss...|$|R
40|$|BACKGROUND: With {{the use of}} {{standard}} electrodes in cochlear implantation, <b>residual</b> acoustic <b>hearing</b> is markedly reduced or even lost. Possible reasons for this loss are direct implantation trauma to the inner ear, reaction of the cochlea triggered by the implantation, and change of cochlear mechanics due to the electrode. HYPOTHESIS: The introduction of a cochlear implant electrode does not alter the global mechanical behavior of the cochlear fluid as recorded at the stapes and the round window (RW) {{to the point of}} clinical relevance. OBJECTIVES: 1) To assess RW motion in response to acoustic stimulation in live human subjects {{for the first time and}} to compare findings with the published data on similar measurements in human temporal bones; 2) to test the hypothesis by comparing intraoperative measurements of the stapes with the RW before and after cochlear implant. PATIENTS AND METHODS: The study included 18 adult patients with profound bilateral hearing loss. A scanning laser Doppler interferometer system measuring through the facial recess and a calibrated multi-sinewave acoustic stimulation tone in the ear canal were used. Changes in cochlear mechanics were assessed by comparing intraoperative measurements of stapes with RW membrane responses to acoustic signals before and after cochlear implantation. RESULTS: Vibration amplitudes and phase at the stapes and RW were not different in our patient group from published results from temporal bones. No significant changes in amplitude and phase were seen at the stapes and RW after cochlear implantation. CONCLUSION: It was possible to assess RW motion in live human subjects. Our results provide evidence that even a standard electrode does not alter cochlear mechanics to the point of clinical relevance...|$|R
40|$|Publisher’s {{permission}} requested and denied. Many cochlear prostheses employ charge-balanced biphasic current pulses. These pulses {{have little}} energy at low frequencies resulting in limited stimulation of low frequency hearing by mechanical {{responses to the}} electrical stimulus. However, if electro-mechanical transduction within the cochlea is nonlinear, electrical stimulation with asymmetric, charge-balanced current pulses {{may result in a}} mechanical response with significantly more low frequency energy. We estimated the mechanical response at low frequencies to pulsatile electrical stimulation of the cochlea. The auditory nerve compound action potential evoked by low frequency tones was forward-masked by a train of symmetric or asymmetric current pulses. Masking by asymmetric current pulses was not significantly different from masking by symmetric pulses matched for pulse duration and charge. In conclusion, {{there appears to be no}} advantage to using asymmetric current pulses for the mechanical stimulation of <b>residual</b> low frequency <b>hearing</b> by electrical stimulation of the cochlea. Restricted Access: This resource is not available from the Digital Repository for copyright reasons. This is a citation and abstract only record...|$|R
