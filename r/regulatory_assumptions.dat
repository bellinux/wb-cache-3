11|19|Public
40|$|The authors {{examine the}} ways in which the credit crunch has {{simulated}} both immediate regulatory initiatives and more fundamental reflection on consumer credit regulation, with regulation of consumer credit markets remaining on the policy agenda of many countries. This paper assesses how conventional <b>regulatory</b> <b>assumptions</b> - that reputable firms do not place risky products on the market, that innovation is stifled by regulation and that regulators are not as well placed as the market to judge the value of products - have been challenged by the credit crunch...|$|E
40|$|This paper isaimed at {{providing}} {{the reader with}} a descriptive summary of the main international and domestic legal instruments for the prevention and punishment of international traffic of children, specifically focusing on the Inter-American Convention on International Traffic in Minors as the most significant regulation on this matter. The objective is to pose questions regarding some of the <b>regulatory</b> <b>assumptions</b> of this instrument from two core aspects on its legislative design: the technique for the description of criminal offences {{and its impact on}} international cooperation mechanisms in criminal matters. This framework intends to explore the features of this criminal activity based on some materials not usually found in specialized discourse. Finally, {{the purpose of this paper}} is to capture an interdisciplinary synthesis at the intersection of Private International Law and International Criminal Law, just at a cardinal point of regulatory convergence: the best interests of the child. </p...|$|E
40|$|Nowadays, when {{designing}} structural aero-engine components, {{the engineering}} team does not only deal with aerodynamics and structural mechanics criteria. Rather, {{it needs to}} make more informed decisions based on the value and sustainability contribution of a design concept. This paper proposes a novel approach that combines qualitative sustainability assessment techniques, which are Environmental Impact Assessment (EIA) and Strategic Sustainability Assessment (SSA), with Net Present Value (NPV) analysis to facilitate early stage decision-making in design. A case study, related {{to the development of}} a new high-temperature aero-engine component, illustrates how EIA and SSA identify sustainability hotspots for a new product technology, and how NPV is used to assess alternative solution strategies within the hotspot. Within the studied case, the milling process was identified as a sustainability hotspot, therefore two process options - Electro-Chemical Milling (ECM) and Mechanical Milling (MM) - where benchmarked by calculating their NPV in alternative future scenarios, featuring different market and <b>regulatory</b> <b>assumptions.</b> The approach and its constituting models have been preliminarily verified with designers and process owners in co-located industrial workshops. Model Driven Development and Decision Support (MD 3 S...|$|E
30|$|Despite {{the limited}} number of {{analyses}} for glyphosate residues in glyphosate tolerant crops, the few recent tests reported [30, 65] indicate surprisingly high levels of glyphosate residues. Such findings should fundamentally challenge <b>regulatory</b> <b>assumption</b> of substantial equivalence between glyphosate-tolerant varieties and their unmodified comparators.|$|R
30|$|These {{findings}} fundamentally {{challenge the}} basis for <b>regulatory</b> <b>assumption</b> of substantial equivalence between glyphosate-tolerant GM varieties and unmodified comparators. The findings are a strong argument for mandatory inclusion of pesticide analysis data in regulatory assessment of GM crop, notably in assessments of herbicide-tolerant crops. Two of the animal feeding studies performed by independent researchers [86, 87] used GM crop material as well as unmodified comparators supplied by industry. No analysis was performed to control the compositional quality of this material.|$|R
40|$|A {{disturbing}} {{feature of}} the conventional objective function for intertemporal decisions under uncertainty is that the agent’s attitudes toward intertemporal substitution and risk aversion are entangled. This paper shows that, in contrast to common perception, the two attitudes can be completely disentangled under the expected utility theorem (EUT) by modeling each of them successively in two steps. The conventional form is nested as a special case where the functions describing the two attitudes are identical. The proposed framework requires only the standard axioms of the EUT, {{in addition to a}} <b>regulatory</b> <b>assumption.</b> It is flexible in accommodating different combinations of the two attitudes, indifferent to the timing of resolution of uncertainty, intuitive to interpret, and extendable to multiple goods. The objective function under the proposed framework is time inconsistent according to Strotz’s (1955) definition. I argue that Strotz’s notion of time consistency is misguided. It is constructed based on a priori assumption that the agent should continuously forget history as time progresses, which means the agent is either chronically amnesiac or self-contradictory. To be truly consistent, the agent should have one and only one objective function, determine...|$|R
40|$|This Article {{examines}} how insights into limited human rationality can improve financial regulation. The article identifies four categories of limitations—herd behavior, cognitive biases, over reliance on heuristics, and a proclivity to panic—that undermine the perfect-market <b>regulatory</b> <b>assumptions</b> that parties have full information and will act in their rational self-interest. The Article then analyzes how insights into these limitations {{can be used}} to correct resulting market failures. For example, requiring more robust disclosure and due diligence can help to reduce reliance on misleading information cascades that motivate herd behavior. Debiasing through law, such as requiring more specific, poignant, and concrete disclosure of risks and their consequences, can help to correct cognitive biases. Requiring firms to engage in more self-aware operational risk management and reporting can reduce the likelihood that parties will overrely on heuristics. And legislating backstop market liquidity and other stabilizing controls can help to minimize panics. Regulation, however, can only partly overcome these limitations. Effective financial regulation should therefore be designed not only to address these limitations but also to try to mitigate the harm of inevitable financial failures...|$|E
40|$|A {{corporate}} financial/regulatory model, called FINREG, {{is presented}} to simulate a utility's accounting practices, financial policy and constraints, and ratemaking environment. For each year of simulation FINREG will yield as output electricity rates, pro-forma accounting statements, selected accounting ratios, and the accumulated present value of dividends less common stock offerings. The model is used to perform a financial evaluation of two feasible expansion options for Boston Edison Company. The two options are generated by OPTGEN, an MIT Energy Laboratory dynamic programming capacity expansion program. OPTGEN provides the capacity additions and annual fuel costs for each option. For the first plan, OPTGEN added an 800 MW coal unit in 1987 and a 250 MW coal unit in 1992 to the existing Boston Edison system. For the second, a 1000 MW nuclear unit was prespecified to begin operation in 1989, and OPTGEN added a 250 MW coal unit in 1987. Financial and <b>regulatory</b> <b>assumptions</b> were specified for each option. FINREG generated selected statistics for the two options through 1998. The equity value associated with each option is estimated. Under the given assumptions, Boson Edison's shareholders are better off with the two coal unit expansion plan...|$|E
40|$|In this paper, {{we explore}} the ethical and legal {{implications}} of a hypothetical use of artificial gametes (AGs) : that of taking a person's cells, converting them to AGs and using them in reproduction-without that person's knowledge or consent. We note the common reliance on genetic understandings of parenthood in the law and suggest that injustices may arise if unwitting genetic parents are sued for child support. We draw parallels between the hypothetical use of AGs to facilitate unwitting parenthood and real examples of unwitting parenthood following cases of sperm theft. We also look at the harm that might be caused by becoming a genetic parent, independently of financial obligations, and ask whether such harm should {{be understood in terms}} of theft of property. These examples help to highlight some of the current and prospective difficulties for the regulation of genetic and legal parenthood, and show how existing <b>regulatory</b> <b>assumptions</b> are likely to be further challenged by the development of AGs. We conclude by suggesting that the reliance on genetic connections to generate parental responsibility (financial or otherwise) for offspring is flawed and that alternative ways of establishing parental responsibility should be considered...|$|E
40|$|An {{on-going}} {{debate in}} the energy economics and power market community has raised the question if energy-only power markets are increasingly failing due to growing feed-in shares from subsidized renewable energy sources (RES). The short answer to this is: No, they are not failing. Energy-based power markets are, however, facing several market distortions, namely from {{the gap between the}} electricity volume traded at day-ahead markets versus the overall electricity consumption as well as the (wrong) <b>regulatory</b> <b>assumption</b> that variable RES generation, i. e., wind and photovoltaic (PV), truly have zero marginal operation costs. In this paper we show that both effects over-amplify the well-known merit-order effect of RES power feed-in beyond a level that is explainable by underlying physical realities, i. e., thermal power plants being willing to accept negative electricity prices to be able to stay online due to considerations of wear & tear and start-stop constraints. We analyze the impacts of wind and PV power feed-in on the day-ahead market for a region that is already today experiencing significant feed-in tariff (FIT) -subsidized RES power feed-in, the EPEX German-Austrian market zone (≈ 20...|$|R
40|$|European Union (EU) {{regulations}} {{require that}} university programmes are of specified duration. Additional EU regulations apply specifically to university based nurse education, enacted in the UK by the Nursing and Midwifery Council (NMC). However, {{little is known}} about how much time student nurses spend on their studies. In this exploratory study, students undertaking a single module in the pre-registration diploma programme at an English university were asked to keep a log of learning activity {{for the duration of the}} module. Twenty-six students completed the log. These students achieved higher grades and attended more lectures than the average for the module. The mean study time was 128. 4 h against a <b>regulatory</b> <b>assumption</b> that the module should take 200 h. More than half of the 26 students undertook paid work during the module run, though this work was not associated with poorer performance. Problems in regulation for course duration are discussed and it is suggested that undertaking a 4600 h course in 3 years is problematic. More research is required so that patterns of study can be better understood and student centred programmes meeting regulatory requirements developed...|$|R
40|$|In an {{unprecedented}} food monitoring campaign for radionuclides, the Japanese government took action to secure food safety after the Fukushima nuclear accident (Mar. 11, 2011). In this work we analyze {{a part of}} the immense data set, in particular radiocesium contaminations in food from the first year after the accident. Activity concentrations in vegetables peaked immediately after the campaign had commenced, but they decreased quickly, so that by early summer 2011 only a few samples exceeded the regulatory limits. Later, accumulating mushrooms and dried produce led to several exceedances of the limits again. Monitoring of meat started with significant delay, especially outside Fukushima prefecture. After a buildup period, contamination levels of meat peaked by July 2011 (beef). Levels then decreased quickly, but peaked again in September 2011, which was primarily due to boar meat (a known accumulator of radiocesium). Tap water was less contaminated; any restrictions for tap water were canceled by April 1, 2011. Pre-Fukushima (137) Cs and (90) Sr levels (resulting from atmospheric nuclear explosions) in food were typically lower than 0. 5 Bq/kg, whereby meat was typically higher in (137) Cs and vegetarian produce was usually higher in (90) Sr. The correlation of background radiostrontium and radiocesium indicated that the <b>regulatory</b> <b>assumption</b> after the Fukushima accident of a maximum activity of (90) Sr being 10 % of the respective (137) Cs concentrations may soon be at risk, as the (90) Sr/(137) Cs ratio increases with time. This should be taken into account for the current Japanese food policy as the current regulation will soon underestimate the (90) Sr content of Japanese foods. T 42 OH 009229 - 07 /OH/NIOSH CDC HHS/United States 25621976 PMC 435162...|$|R
40|$|This report {{provides}} {{data and}} information needed to support the risk and impact assessments of high-level waste (HLW) management alternatives in the U. S. Department of Energy Waste Management (WM) Programmatic Environmental Impact Statement (PEIS). Available data on the physical form, chemical and isotopic composition, storage locations, and other waste characteristics of interest are presented. High-level waste management follows six implementation phases: current storage, retrieval, pretreatment, treatment, interim canister storage, and geologic repository disposal; pretreatment, treatment, and repository disposal are {{outside the scope of}} the WM PEIS. Brief descriptions of current and planned HLW management facilities are provided, including information on the type of waste managed in the facility, costs, product form, resource requirements, emissions, and current and future status. Data sources and technical and <b>regulatory</b> <b>assumptions</b> are identified. The range of HLW management alternatives (including decentralized, regionalized, and centralized approaches) is described. The required waste management facilities include expanded interim storage facilities under the various alternatives. Resource requirements for construction (e. g., land and materials) and operation (e. g., energy and process chemicals), work force, costs, effluents, design capacities, and emissions are presented for each alternative...|$|E
40|$|This study {{presents}} the results of a preliminary assessment of the feasibility of converting an existing kiln facility, the KILnGAS Commercial Module (KCM) in East Alton, lllinois, to a hazardous waste incinerator. The study examined the RCRA and Superfund waste volumes and characteristics as well as the treatment and disposal capacity of the State of Illinois to identify potential incineration capacity shortfalls. A centerline waste, soils contaminated with PCBs, was selected to provide a reference case to study the facility conversion. A conceptual facility design was developed using the technical and environmental criteria for the selected waste as a design basis. Major process equipment was identified, sized, and priced. A heat and material balance was developed for a centerline mode of operation to forecast performance. Economics for waste treatment were examined based upon a range of competitive tipping fees and other parameters impacting commercial viability. Finally, tentative conclusions regarding the feasibility of the facility conversion are presented and a "next step" action plan is outlined to corroborate the technical, economic, and <b>regulatory</b> <b>assumptions</b> and to examine design alternatives with the potential for reducing facility costs and/or enhancing its performance or siting potential. HWRIC Project No. 88 - 050 published or submitted for publicationis peer reviewe...|$|E
40|$|Abstract This article {{assesses the}} {{economic}} feasibility of capture-based bluefin tuna aquaculture on the US East Coast and examines {{the potential of}} this hybrid form of aquaculture production to increase the net economic value generated in the US East Coast bluefin tuna fishery. A bioeconomic model of an offshore capture-based bluefin tuna aquaculture facility is {{used to evaluate the}} economic feasibility of this form of production on the US East Coast under a variety of economic, biological, and <b>regulatory</b> <b>assumptions.</b> The results suggest that of the three proposed farming sites along the US East Coast, the expected net present value (NPV) of the operation over a 10 -year operating horizon is highest at the Gray’s Reef, GA, site. The second part of this article assesses {{the extent to which the}} opportunity to engage in capture-based bluefin tuna aquaculture production could improve the net economic value gener-ated in the US East Coast bluefin tuna fishery. The results suggest that if the fishery had the opportunity to engage in capture-based bluefin tuna aquaculture production, there would be an increase in the net revenue generated in the fishery. Depending on how the seasonal quota was enforced, economic improvement in the fishery ranged from a 52 – 142 % improvement in net revenue. Even when the cost per fish associated with capture-based bluefin tuna aquaculture production was doubled, the results still indicated that the opportunity to engage in capture-based bluefin tuna aquaculture production would lead to a 12 % increase in net revenue in the fishery. Key words Capture-based aquaculture, bioeconomic modeling, bluefin tuna, fisher-ies management. JEL Classification Codes Q 22, Q 27, Q 28, C 61...|$|E
40|$|An underlyingussumption of {{the partial}} {{preemption}} apprmh {{is the belief}} that minimum federal standmds contribute to the prospective decentralization of environmental protection programs by removing or reducing industry incentives to shop aroundfor states with a more lenient <b>regulatory</b> stance. This <b>assumption</b> was examined through a survey of chief executive oficers of pollution-generating firms. Tlze data suggest that corporate officials see regulatory climate m an important component of overhead ctxits. The author concludes that the desire to retain industries within state boundaries does inhibit the promulgation of strict environmental regulat ions by public officials. Copyright 1992 by The Policy Studies Organization. ...|$|R
40|$|To {{explain the}} {{evolution}} of U. S. deposit institutions and markets in the 1960 sand 1970 s, we feed into the <b>regulatory</b> dialectic <b>assumptions</b> about the objectives of federal banking regulation and about outside forces that disturb the adjustment process. The disturbing exogenous forces are accelerating change in the technological and market environment of commercial banking and increasing uncertainty concerning the future speed of enviromental change. We hypothesize that, {{in the face of}} these environmental changes, the adaptive efficiency shown on average by deposit-institution managers is greater than that shown by managers of the several competing banking agencies. Incorporating this differential adaptive capacity into the regulatory dialectic helps us to understand how increases in the pace of environmental change and in the degree of environmental uncertainty led regulatee responses to come more quickly and regulatory responses to come more slowly. The bottom line is that, when the environment changes rapidly and becomes more uncertain, traditional forms of U. S. banking regulation can be overwhelmed by technological and regulation-induced innovation. ...|$|R
40|$|Activated PHO 5 {{promoter}} chromatin at {{steady state}} represents a statistical ensemble of distinct structures. The extent of promoter nucleosome loss {{depends on the}} strength of the transcriptional activator of PHO 5, indicative of continuous disassembly and reassembly of nucleosomes at the induced promoter. PHO 5 promoter nucleosome loss and expression are exponentially related, pointing at two or more steps of the expression process that are activator controlled. The intrinsic noise profile of PHO 5 expression permits quantitative distinction between alternative <b>regulatory</b> architectures. The <b>assumption</b> of two activator-controlled steps, promoter nucleosome removal and assembly of the transcription machinery, is necessary and sufficient to account for the quantitative relationship between PHO 5 expression, intrinsic noise, and promoter nucleosome loss...|$|R
40|$|MBAC Consulting {{was engaged}} {{by a large}} NSW {{greenhouse}} gas emitter with a {{need to understand the}} practical, economic and financial issues associated with carbon sequestration using environmental plantings. The need was born from an increasing desire to reduce greenhouse gas emissions, the increasing cost of meeting regulatory greenhouse gas emission targets associated with the NSW Government’s Greenhouse Gas Abatement Scheme (NGGAS) and the cost imposts of the Federal Government’s Mandatory Renewable Energy Target (MRET) program. A way forward was seemingly blocked by confusing and sometimes contradictory technical, commercial-in-confidence and proprietary information clouded by jargon, acronyms and ‘apparent secrecy’. The way forward was assisted with the availability of historical data on yield of stem wood collected by foresters {{over long periods of time}} for some species in combination with more recent studies on biomass. The deliverables were a clear and transparent understanding of the cost-drivers for CO 2 -e sequestration as well as a decision support tool. The outcome was the development of an EXCEL®-based model. The model calculated the area requirements and associated costs of CO 2 -e sequestration over time and a range of locations against variation in volume, basic density, proportional allocation of the carbon pool (stem, roots, leaves, branches, bark), carbon fraction and <b>regulatory</b> <b>assumptions.</b> A key component was describing and applying the Independent Pricing and Regulatory Tribunal’s (IPART) conservative carbon-reporting requirements (called the 70 % Rule) that are pivotal to the implementation of NGGAS. The project provided a ‘snap-off-model’, which separated the underlying complex data and algorithms (i. e. the forester’s model) from the simplified input/output model (i. e. the engineer’s model). This gave the emitter the ability to test various scenarios and provided heightened levels of understanding which lead to increased confidence for integration of the work into broader environmental planning within the company...|$|E
40|$|The study {{examines}} {{different approaches to}} the regulation of the capital markets {{with a focus on}} explaining why certain assumptions about markets, actors, and systems came to be embedded in the regulatory practice in the American capital markets. More specifically, I examine <b>regulatory</b> <b>assumptions</b> about the nature of public firm ownership, the distortions that these assumptions introduced into the regulatory framework governing the securities markets, and the epistemological and risk-based implications of these distortions to actors, markets, and the regulatory system. The analysis draws on a number of theoretical approaches and methodologies including legal history, law and economics, comparative law, complexity/systems analysis, socio-legal analysis, and political economy. This study analyzes the performance of the US Securities and Exchange Commission as the principal regulator of the American capital markets. The regulatory framework arguably reflects the Commission's perceptions (of market realities) and preferences (in response to these ""market realities""). The federal proxy rules found in s. 14 (a) of the Securities Exchange Act of 1934, used as a case study in this volume, exemplify this claim. As one of the original responsibilities assigned to the Commission by Congress, s. 14 (a) of the 1934 Act gave the agency near-complete authority to regulate the federal proxy process. Thus, the functioning of the federal proxy regime hints at the Commission's performance as a regulator. Since s. 14 (a) deals with proxy solicitation of shareholder votes, one essential policy consideration is the nature of corporate ownership. To evaluate the Commission's knowledge in relation to ownership, we need to appreciate how the agency evaluated underlying assumptions vis-à-vis ownership; displayed awareness of changing socio-economic realities in the securities markets; and developed responsive regulatory measures accordingly. The analysis highlights how the Commission missed learning opportunities (to varying degrees) over the years vis-à-vis (i) distortions introduced into the regulatory framework in the 1930 s, (ii) implications of these distortions to the stability of the regulatory framework, (iii) demographic changes in the nature of public firm ownership leading to the formation of an ownership structure not previously discussed in the literature, which I call the ""market oriented blockholder model,"" (iv) new forms of endogenous risks relating to the regulatory framework, which I call ""regulatory systemic risk. "" The cumulative impact of these factors have negative implications to the agency's reputation and legitimacy. These findings suggest that the Commission needs to optimize its process to become what I call a ""learning regulator""-an organization displaying adaptability to the evolving environment subject to its oversight through the acquisition, generation, and translation of knowledge and the modification of its behavior to reflect new knowledge and insights. To facilitate such optimization, I develop an organizational learning model tailored to administrative agencies-the ""learning regulator framework. "" Measures adopted pursuant to the model encourage organizational learning, risk reduction, and enhanced efficiency in the regulated environment. These measures, in turn, enhance the regulator's reputation and shield its legitimacy from criticism. ...|$|E
40|$|Nuclear {{power plant}} {{radiation}} protection design features {{are based on}} radionuclide source terms derived from conservative assumptions that envelope expected operating experience. Two parameters that significantly affect the radionuclide concentrations in the source term are failed fuel fraction and effective fission product appearance rate coefficients. Failed fuel fraction may be a <b>regulatory</b> based <b>assumption</b> {{such as in the}} U. S. Appearance rate coefficients are not specified in regulatory requirements, but have been referenced to experimental data that is over 50 years old. No doubt the source terms are conservative as demonstrated by operating experience that has included failed fuel, but it may be too conservative leading to over-designed shielding for normal operations as an example. Design basis source term methodologies for normal operations had not advanced until EPRI published in 2015 an updated ANSI/ANS 18. 1 source term basis document. Our paper revisits the fission product appearance rate coefficients as applied in the derivation source terms following the original U. S. NRC NUREG- 0017 methodology. New coefficients have been calculated based on recent EPRI results which demonstrate the conservatism in nuclear power plant shielding design...|$|R
40|$|Accurate {{assessments}} {{of exposure to}} nitrate in drinking water is {{a crucial part of}} epidemiological studies investigating long-term adverse human health effects. However, since drinking water nitrate measurements are usually collected for <b>regulatory</b> purposes, <b>assumptions</b> on (1) the intra-distribution system variability and (2) short-term (seasonal) concentration variability have to be made. We assess concentration variability in the distribution system of nitrate, nitrite, and ammonium, and seasonal variability in all Danish public waterworks from 2007 to 2016. Nitrate concentrations at the exit of the waterworks are highly correlated with nitrate concentrations within the distribution net or at the consumers’ taps, while nitrite and ammonium concentrations are generally lower within the net compared with the exit of the waterworks due to nitrification. However, nitrification of nitrite and ammonium in the distribution systems only results in a relatively small increase in nitrate concentrations. No seasonal variation for nitrate, nitrite, or ammonium was observed. We conclude that nitrate measurements taken at the exit of the waterworks are suitable to calculate exposures for all consumers connected to that waterworks and that sampling frequencies in the national monitoring programme are sufficient to describe temporal variations in longitudinal studies...|$|R
40|$|Following the 1993 Railways Act, British Rail's {{passenger}} {{business was}} spilt into 25 train operating units, {{which have been}} privatised by a process of franchising. This paper will review the franchising experience to date. First, the results of 38 in-depth interviews with potential bidders for the passenger businesses will be described. Secondly, a hypothetical bidding game, based {{on a series of}} Stated Preference experiments undertaken by our sample of potential bidders, will be described. A model has been established which determines managers' preferences with respect to contract size and length, exclusivity, and the degree of <b>regulatory</b> control. Given <b>assumptions</b> concerning the degree of competition for rail franchises and bidding behaviour, some predictions are made about the likely magnitude of winning bids and these predictions are validated against actual bids. ...|$|R
40|$|This article {{challenges}} the methodological nationalism of the convergence debate {{by arguing that}} multilevel governance destabilizes the coalitions thought to underpin liberal and coordinated varieties of capitalism. Existing efforts to explain how coherent production regimes emerge and persist assume that some dominant social bloc ensures coherence by imposing its interests across all relevant <b>regulatory</b> subspheres. This <b>assumption</b> is not tenable in systems of multilevel governance. Three features of multilevel governance diminish the scope for a uniform social bloc to ensure a tight coupling of complementary regulations. First, the strategic opportunities for playing multilevel games vary across regulatory subspheres. Second, willingness to exploit these opportunities varies, because the transnational scope of legislation adds a constrain-competitor dimension to actors' decision-making that may either strengthen or weaken interest group cohesion. Third, the institutional set-up at the supranational level of Europe's multilevel polity multiplies alignment options. To illustrate these claims, the article draws on case studies of EU company law initiatives concerning takeovers and worker participation...|$|R
40|$|International {{efforts to}} define fair {{information}} practices for global networks derive from two distinct paradigms. Traditionally, regulatory standards have been cast in trade terms. The trade perspective seeks to promote free flows {{of information and}} define standards that balance free flows against human rights values. Fair information practices also draw on another rarely emphasized technical paradigm. This approach seeks to eliminate any technological obstacles to free flows of information by defining standards for system integrity and interoperability. Nevertheless, these technical standards are set in ways that also define fair information practices. While each paradigm provides a basis to establish rules for global electronic highways, the two are surprisingly self-contained and tend not to fit within the broader trends in global information networks and practices. Instead of facilitating the definition of fair information practice standards, the distinct trade and technical perspectives obscure the tendency of global networks to shift norms for the regulation of private sector actors into a combined arena of both national and network jurisdiction. Global information networks challenge <b>regulatory</b> and political <b>assumptions</b> and defy simple regulation of fair information practice. These independent approaches {{to the establishment of}} fair information practice rules suggest that international data flows require complex standards, including overlapping regulation, rather than isolated one-dimensional rules...|$|R
40|$|This article {{discusses}} empirical {{findings and}} conceptual elaborations {{of the last}} 10 years in strategic niche management research (SNM). The SNM approach suggests that sustainable innovation journeys can be facilitated by creating technological niches, i. e. protected spaces that allow the experimentation with the co-evolution of technology, user practices, and <b>regulatory</b> structures. The <b>assumption</b> was that if such niches were constructed appropriately, they would act as building blocks for broader societal changes towards sustainable development. The article shows how concepts and ideas have evolved over time and new complexities were introduced. Research focused {{on the role of}} various niche-internal processes such as learning, networking, visioning and the relationship between local projects and global rule sets that guide actor behaviour. The empirical findings showed that the analysis of these niche-internal dimensions needed to be complemented with attention to niche external processes. In this respect, the multi-level perspective proved useful for contextualising SNM. This contextualisation led to modifications in claims about the dynamics of sustainable innovation journeys. Niches are to be perceived as crucial for bringing about regime shifts, but they cannot do this on their own. Linkages with ongoing external processes are also important. Although substantial insights have been gained, the SNM approach is still an unfinished research programme. We identify various promising research directions, as well as policy implications...|$|R
40|$|Volatile {{substance}} misuse {{has received}} increased public attention {{over the past}} few decades. The misuse of otherwise innocuous domestic products as vehicles to intoxication is considered dangerous and threatening to mainstream users of these substances, and is a clear deviation from their intended purpose (MacLean 2003). However, such perceptions have hampered the formation of innovative and reflexive policy. In Australia, volatile substance misuse is not a criminal offence, and new legislation has been developed in all Australian jurisdictions to allow police and responding agencies greater authority for responding to substance misuse. Although there is an increasing body of literature surrounding volatile substance misuse, there is limited empirical research on the regulatory responses with a focus on drug abuse prevention. Of the literature that does exist, much is concerned with reviewing interventions without empirical analyses or consideration of the conceptual issues that surround volatile substance misuse. Consequentially, this research is concerned with examining the current regulatory responses to volatile substance misuse, with a specific focus on drug abuse prevention. Using a mixed-method case study design, this thesis draws on 34 interviews with four participant groups and five weeks of observation of a responding agency, to examine the assumptions of agency and capacity of regulatory subjects made by policy and regulatory strategies, as well as policy motivations. Further, the thesis considers {{the extent to which the}} findings have implications for the potential success of <b>regulatory</b> programs. These <b>assumptions,</b> although examined in this thesis primarily within the context of volatile substance misuse strategies, are also considered within the broader context of Indigenous policy. By moving beyond general policy discussions and considering issues of empowerment, ownership and community control and how these affect the potential success of regulatory strategies, this thesis contributes to current debates on Indigenous policy. In other words, this thesis argues that Indigenous policy should be based on the <b>assumption</b> that its <b>regulatory</b> subjects are empowered agents, which speaks to the way in which Indigenous policy should be approached across Australia...|$|R
40|$|Canada’s {{regulatory}} system is science-based and relies on risk assessment to inform decisions about which products of biotechnology (and other technologies) are safe enough for commercial application. Since regulation involves {{the loss of}} certain liberties, {{it is imperative that}} any regulatory regime be as objective as possible. Scientific risk assessment seems to {{be a good way to}} produce the information, which guides policy makers since it involves quantitative analysis and the production of seemingly objective data. The view adopted by regulators and in current risk assessment practices is that objective means value-free. Therefore, because risk assessment data is scientific it is thought to be value-free but this is not the case. Risk assessment necessarily involves value assumptions. Assumptions must be made at all stages of the production of risk data. This does not mean, however, that risk assessment is hopelessly subjective. The notion of value-free objectivity can be replaced with the view that genuine objectivity arises through peer review and social discourse. Regulators can adopt this understanding of objectivity to acknowledge the value-ladenness of risk assessment data. At present, the value assumptions made by industry, government and private scientists during risk assessment go largely unnoticed yet have an effect on the outcome of <b>regulatory</b> decisions. Such <b>assumptions</b> must be recognized in order to ensure that the decisions made about the risks society face are not biased. This is particularly true in the case of biotechnology regulation. The development of the science of biotechnology has occurred concurrently with the development of the biotech industry creating the opportunity for industry-biased risk assessments. It is possible to make changes to the existing regulatory regime in Canada in order to avoid some of the major problems associated with unrecognized value assumptions in risk assessment. A complete restructuring of the regime is unnecessary, however. Maintaining the current regulatory structure with some minor changes could address these problems. These changes include: creating an independent review board, making explicit that value assumptions are part of risk assessment in government advisory reports, and enhancing the role of regulators. Canada’s {{regulatory system}} can better address the risks associated with biotechnology if it acknowledges that risk assessment is value-laden...|$|R
40|$|The {{new energy}} {{policy of the}} European Union (EU) with the core {{objectives}} of competitiveness, reliability and sustainability, has driven Europe into a transition towards a low carbon & sustainable electricity supply systems. Under the new policy, the European energy systems are pursing two major objectives. First is to shift the focus from national to regional or (perhaps) a European level with {{the ultimate goal of}} introducing regional markets that facilitates cross-border power trades. Second, is to incorporate large renewable energy sources into the power systems to best exploit the energy resources. In this regards, special attention is oriented towards the development of the offshore gird in the North Sea region where offshore wind is abundant and has potential to become major energy source in the area. This thesis looks into transmission expansion planing in the North Sea region. It presents a market based approach to solve a long-term transmission expansion planning for a meshed VSC-HVDC offshore grid that connect regional markets. The main goal here is to determine the grid design that enables harnessing the offshore wind energy most efficiently, at the same time, creating capacity for conducting cross-border power exchange. Development of an offshore grid in the North Sea can encounter various technical, legal and economic barriers. Consequently advanced planning frameworks are required that enables accounting for these issues. The methodology proposed here provides a framework to investigate the impact of each of these factors on the development of offshore infrastructures. More precisely, the contributions of this thesis can be summarized as follows:  Static Transmission Expansion Planning framework (STEP) In Chapter 5, I have proposed a multiple time-period static transmission expansion planning framework that is applicable to VSC-HVDC meshed grids. I have shown that the analytical solution to the problem gives the pricing mechanism that expresses the relationship between the electricity price of different zones and the congestion charges associated with the interconnectors between them. It is an extension of the work of Schweppe et al. that has been proven for and applied to VSC-HVDC grids. The proposed formulation includes investment recovery through congestion revenues as an implicit strict equality constraint. It, therefore, computes the expansion plan, such that the investment capital will be fully paid off through congestion revenues {{by the end of the}} chosen lifetime of the infrastructure. The framework determines the topology, transmission capacities and the power flows through the offshore grid, and the resulting distribution of social welfare among the price zones. By combining both flow-constraints and investment recovery-constraints and working with historical market data, the framework can deliver useful results that demonstrate how onshore price zones could benefit from an optimal grid design.  Iterative clustering methods for computation feasibility The optimization framework proposed in Chapter 5 was intended to be driven by historical market-data in the form of hourly regional cost curves. The dimensionality of the search space and the computational intensity of the proposed optimization algorithm make the problem intractable. It was desirable to identify and work with only a subset from the total set of operating states. I developed an iterative algorithm that combines an unsupervised clustering technique with the proposed optimization tool to cope with the computational burden of the large-scale optimization problem. Automatic space transformation and clustering were performed to select a subset of representative hourly operating states. The number of samples in the subset was adjusted in order to match the congestion-induced revenues to that of the full data set. This ensured that essential information was not lost. The framework, thus, balances the need for reasonable computation times against the benefits of a model that allows multiple time-periods (as defined by zonal prices and wind power production combinations) and obtains realistic results. Several clustering algorithms (including K-means) and feature reduction techniques (such as Principal Component Analysis (PCA)) have been used in investment planning analysis. Their combination has also been explored in literature. However, this is the first time that an unsupervised PCA/clustering technique has been combined with an optimization tool to refine the clustering results.  StaticWind and Transmission Expansion Planning framework (SWTEP) Chapter 6 describes a novel co-optimization wind and transmission expansion framework applicable to VSC-HVDC meshed grids. This is an extension of the static framework presented in Chapter 5 that adds wind to the TEP formulation, while implementing support schemes, which inherently induce a deviation from perfect competition. This results in a fundamental contradiction between the structure of the competitive market and the nature of support policies. The novelty of the work presented in Chapter 6 is that it has limited the market distortion by excluding the support payments from the market clearing process. To do so, I have proposed a formulation that divides the initial investment of the offshore wind infrastructure into subsidized and unsubsidized parts. Thus, the objective of the optimization problem was to maximize sum of incremental social welfare of all regions at all times, minus the aggregated investment cost of offshore transmission infrastructure and the investment cost of building the offshore wind farms that has not been covered through the support payments. The proposed framework enables the impact of implementing two types of feed-in premium support schemes (i. e., generation-based and capacity-based) to be accounted for in the final development of the grid. The goal of this chapter was to investigate the performance of the two feed-in support policies to verify if investment recovery would be fulfilled under a certain support scheme design. In addition, an ‘optimal’ support level and offshore wind support tariff rate were determined. The analytical solution to the optimization problems confirms the complete recovery of the investment cost of transmission infrastructure. In addition, under the assumption that no offshore wind was curtailed, the revenues collected from market sales of offshore wind farms can pay off the unsubsidized part of the wind farm investment, regardless of the payment basis (generation-based or capacity-based).  Dynamic Transmission Expansion Planning framework (DTEP) In Chapter 7, I have proposed a market-based, multiple stage, multi-time period dynamic transmission expansion planning framework for a meshed offshore grid to connect upcoming offshore wind farms to multiple onshore markets. The main contribution of this framework is that it enables accounting for delays in the construction and implementation of offshore infrastructures, including wind farms and transmission systems. Delays can occur mainly due to legal barriers associated with differing permitting criteria in an international context, but also due to market maturity and supply chain issues. The timing of delays in grid, market and wind farm developments are set exogenously in the model. This is an extension of the work presented in Chapter 5 in which the whole offshore grid was assumed to be built in one instant. The final results include the optimal grid topology, transmission capacities, construction timing and the resulting remuneration and distribution of the social welfare increase and financial benefit among the various onshore price zones. The analytical solution to the optimization problem gives the pricing mechanism that is consistent with the AC onshore counterpart. The proposed market mechanism facilitates the integration of a multi-terminal VSC-HVDC offshore grid into the existing AC grid. In addition, the analytical solution confirms the investment recovery through congestion revenues, regardless of the number of investors that are involved. In the case of multiple investors, an independent financial entity is required that collects the transmission revenues from the grid operators and distributes them appropriately amongst the investors. Under this <b>regulatory</b> <b>assumption,</b> the investment recovery of every cable of every interconnector will be completely fulfilled within the desired economic lifetime...|$|R
40|$|This book {{focuses on}} the current legal {{framework}} for vertical agreements in the EU and the US. Over the last ten years, antitrust rules governing these agreements have undergone thorough reform. In the EU, the old sector-specific block exemptions were replaced by Regulation 2790 / 99, applicable to all sectors of the economy. In addition, changes introduced to the procedural rules {{have led to the}} decentralisation of Article 81 (3) and the removal of the notification requirement. In like manner, in the US the Supreme Court has gradually taken vertical restraints out of the per se illegality rule. What Sylvania achieved in placing non-price vertical restraints under the rule of reason in the late 1970 s, the Khan judgment did for maximum resale price maintenance in 1997, whilst most recently and most significantly in 2007 the Leegin case followed suit for minimum resale price maintenance. [...] Acknowledgements vii	 [...] Note to the Reader ix	 [...] Table of Cases xiii	 [...] Table of Statutes xvii	 [...] Introduction 1 	 [...] I The Significance of Vertical Agreements in the Study of Antitrust Policy and Regulation 1 	 [...] II Competition Law in a Time of Financial Turmoil 6 	 [...] III Competition and Regulation: An Impossible Relationship? The Challenges of Regulating Competition the Challenges of Regulating Competition 8 	 [...] IV Style, Structure and Methodology 11 	 [...] 1 The Enduring Debate on the Nature of Vertical Agreements 		 15 	 [...] I The Intricacies of the Regulation of Vertical Agreements in Competion Law 15 	 [...] II The <b>Regulatory</b> Dilemma: General <b>Assumptions</b> on the 'Double Nature' of Vertical Restraints 19 	 [...] III The Adequacy of Competition Law in Addressing the Regulatory Dilemma 24 	 [...] 2 Theorising Vertical Restraints: The Intellectual Foundations of EC Competition Law and US Antitrust Models 35 	 [...] I The Influence of Economic and Political Theory in the Evolution of the Legal Framework for Vertical Agreements 35 	 [...] II Vertical Restraints and Wider Competition Policy—An Overview 46 	 [...] 3 Questioning the Achievement of an Adequate Economic Analysis 75 	 [...] I The Progressive Disappearance of the Per Se Rule in the US 76 	 [...] II The European Regime for Vertical Agreements Since 1999 92 	 [...] III An Assessment: Inherent Benefits and Dangers in the Extension of the Rule of Reason 145 	 [...] 4 The Impact of Competition Rules on Vertical Contractual Relationships 		 153 	 [...] I The Interaction Between Contract and Competition Law 157 	 [...] II Rebalancing the Dealer—Manufacturer Relationship 169 	 [...] III The Path Towards the Reconciliation of the Evolution of Contract and Competition Law 178 	 [...] Conclusions 183 	 [...] I Explanations: Vertical Agreements and Antitrust Law 183 	 [...] II Predictions and Suggestions 188 	 [...] III Final Evaluation—Assuming the Law's Limits 191 	 [...] Index 195 Published version of EUI PhD thesis, 200...|$|R

