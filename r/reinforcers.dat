1501|3|Public
5|$|Compared to neurotypical children, {{those with}} ADHD {{generally}} demonstrate greater impulsivity by being influenced by reward immediacy and quality more {{than by the}} frequency of reward and effort to obtain it. However, researchers have empirically shown that these impulsive behavior patterns can be changed through {{the implementation of a}} simple self-control training procedure in which reinforcer immediacy competes with the frequency, quantity or saliency of the reward, and the delay is gradually increased. One study demonstrated that any verbal activity while waiting for reinforcement increases delay to gratification in participants with ADHD. In another study, 3 children diagnosed with ADHD and demonstrating impulsivity were trained to prefer reward rate and saliency more than immediacy through manipulation {{of the quality of the}} <b>reinforcers</b> and by systematically increasing the delay with a changing-criterion design. Post-assessment of the children illustrated that self-control can transfer to untrained dimensions of reinforcement; such as an increase in quality over immediacy preference due to direct training resulting in an increase in quantity over immediacy preference.|$|E
5|$|Evidence from {{microelectrode}} recordings {{from the}} brains of animals shows that dopamine neurons in the ventral tegmental area (VTA) and substantia nigra are strongly activated by {{a wide variety of}} rewarding events. These reward-responsive dopamine neurons in the VTA and substantia nigra are crucial for reward-related cognition and serve as the central component of the reward system.The brain reward circuitry that is targeted by addictive drugs normally mediates the pleasure and strengthening of behaviors associated with natural <b>reinforcers,</b> such as food, water, and sexual contact. Dopamine neurons in the VTA are activated by food and water, and dopamine release in the NAc is stimulated by the presence of natural <b>reinforcers,</b> such as food, water, or a sexual partner....The NAc and VTA are central components of the circuitry underlying reward and memory of reward. As previously mentioned, the activity of dopaminergic neurons in the VTA appears to be linked to reward prediction. The NAc is involved in learning associated with reinforcement and the modulation of motoric responses to stimuli that satisfy internal homeostatic needs. The shell of the NAc appears to be particularly important to initial drug actions within reward circuitry; addictive drugs appear to have a greater effect on dopamine release in the shell than in the core of the NAc.... If motivational drive is described in terms of wanting, and hedonic evaluation in terms of liking, it appears that wanting can be dissociated from liking and that dopamine may influence these phenomena differently. Differences between wanting and liking are confirmed in reports by human addicts, who state that their desire for drugs (wanting) increases with continued use even when pleasure (liking) decreases because of tolerance.}} The function of dopamine varies in each axonal projection from the VTA and substantia nigra; for example, the VTA–nucleus accumbens shell projection assigns incentive salience ("want") to rewarding stimuli and its associated cues, the VTA–orbitofrontal cortex projection updates the value of different goals in accordance with their incentive salience, the VTA–amygdala and VTA–hippocampus projections mediate the consolidation of reward-related memories, and both the VTA–nucleus accumbens core and substantia nigra–dorsal striatum pathways are involved in learning motor responses that facilitate the acquisition of rewarding stimuli. Some activity within the VTA dopaminergic projections appears to be associated with reward prediction as well.|$|E
25|$|Similarly, a posterior-anterior {{distinction}} {{was found}} with more complex or abstract <b>reinforcers</b> (such as monetary gain and loss) being represented more anteriorly in the orbitofrontal cortex than less-complex <b>reinforcers</b> such as taste. It has even been proposed that the human OFC has a role in mediating subjective hedonic experience.|$|E
25|$|The {{published}} neuroimaging {{studies have}} found that the reward value, the expected reward value, and even the subjective pleasantness of foods and other <b>reinforcers</b> are represented in the OFC. A large meta-analysis of the existing neuroimaging evidence demonstrated that activity in medial parts of the OFC is related to the monitoring, learning, and memory of the reward value of <b>reinforcers,</b> whereas activity in lateral OFC is related to the evaluation of punishers, which may lead to a change in ongoing behaviour.|$|E
25|$|Empirical {{studies in}} {{criminology}} support behavioural change theories. At the same time, the general theories of behavioural change suggest possible explanations to criminal behaviour {{and methods of}} correcting deviant behaviour. Since deviant behaviour correction entails behavioural change, understanding of behavioural change can facilitate the adoption of effective correctional methods in policy-making. For example, the understanding that deviant behaviour like stealing may be learned behaviour resulting from <b>reinforcers</b> like hunger satisfaction that are unrelated to criminal behaviour can aid the development of social controls that address this underlying issue rather than merely the resultant behaviour.|$|E
25|$|The human OFC {{is among}} the least-understood regions of the human brain; {{but it has been}} {{proposed}} that the OFC is involved in sensory integration, in representing the affective value of <b>reinforcers,</b> and in decision-making and expectation. In particular, the OFC seems to be important in signaling the expected rewards/punishments of an action given the particular details of a situation. In doing this, the brain is capable of comparing the expected reward/punishment with the actual delivery of reward/punishment, thus, making the OFC critical for adaptive learning. This is supported by research in humans, non-human primates, and rodents. Human research has focused on neuroimaging research in healthy participants and neuropsychology research in patients with damage to discrete parts of the OFC. Research at the University of Leipzig shows that the human OFC is activated during intuitive coherence judgements.|$|E
25|$|Benzodiazepines share {{a similar}} {{mechanism}} of action with various sedative compounds that act by enhancing the GABAA receptor. Cross tolerance means that one drug will alleviate the withdrawal effects of another. It also means that tolerance of one drug will result in tolerance of another similarly-acting drug. Benzodiazepines are often used for this reason to detoxify alcohol-dependent patients and can have life-saving properties in preventing or treating severe life-threatening withdrawal syndromes from alcohol, such as delirium tremens. However, although benzodiazepines can be very useful in the acute detoxification of alcoholics, benzodiazepines in themselves act as positive <b>reinforcers</b> in alcoholics, by increasing the desire for alcohol. Low doses of benzodiazepines were found to significantly increase the level of alcohol consumed in alcoholics. Alcoholics dependent on benzodiazepines should not be abruptly withdrawn but be very slowly withdrawn from benzodiazepines, as over-rapid withdrawal is likely to produce severe anxiety or panic, which {{is well known for}} being a relapse risk factor in recovering alcoholics.|$|E
25|$|The first {{scientific}} studies identifying neurons that responded {{in ways that}} suggested they encode for conditioned stimuli came from work by Mahlon deLong and by R.T. Richardson. They showed that nucleus basalis neurons, which release acetylcholine broadly throughout the cerebral cortex, are activated shortly after a conditioned stimulus, or after a primary reward if no conditioned stimulus exists. These neurons are equally active for positive and negative <b>reinforcers,</b> and {{have been shown to}} be related to neuroplasticity in many cortical regions. Evidence also exists that dopamine is activated at similar times. There is considerable evidence that dopamine participates in both reinforcement and aversive learning. Dopamine pathways project much more densely onto frontal cortex regions. Cholinergic projections, in contrast, are dense even in the posterior cortical regions like the primary visual cortex. A study of patients with Parkinson's disease, a condition attributed to the insufficient action of dopamine, further illustrates the role of dopamine in positive reinforcement. It showed that while off their medication, patients learned more readily with aversive consequences than with positive reinforcement. Patients who were on their medication showed the opposite to be the case, positive reinforcement proving to be the more effective form of learning when dopamine activity is high.|$|E
25|$|Prior to {{the seminal}} article on {{functional}} analytic methodology for aberrant behaviors, behaviorists used the behavioral technology {{available to them}} at the time. Instead of treating {{the function of the}} disruptive behavior, behavioral psychologists would instead pre-assume consequences to alter disruptive behaviors. For example, in the past to decrease self-injurious behavior in an individual, behaviorists may have delivered an aversive stimulus contingent on the response, or assume a reinforcer without identifying the reinforcer that would be most motivating to the client (Iwata, 1988). This type of intervention was successful to the individual, but it was not uncommon to see other variations of aberrant behavior begin to appear. When applied behavior analysts let clients choose from a wide array of <b>reinforcers</b> (often determined through data collection and reinforcement assessments) in the mid-1980s, reinforcement was shown to be more effective than punishment contingencies. In general, applied behavior analysis as a field favors reinforcement based interventions over aversive contingencies, but at the time the behavioral technology was not advanced enough and the individuals needing intervention had a right to an effective treatment (Van Houten et al., 1988). Nevertheless, not all behavioral therapies involved the use of aversives prior to the mid-1980s. Some behaviorists (for instance, B.F. Skinner) always preferred reinforcement and extinction contingencies over punishment even during that time.|$|E
2500|$|The {{acquisition}} phase {{of substance abuse}} involves the escalation from single use to regular use. [...] Impulsivity {{may be related to}} the acquisition of substance abuse because [...] of the potential role that instant gratification provided by the substance may offset the larger future benefits of abstaining from the substance, and because people with impaired inhibitory control may not able to overcome motivating environmental cues, such as peer pressure. [...] "Similarly, individuals that discount the value of delayed <b>reinforcers</b> begin to abuse alcohol, marijuana, and cigarettes early in life, while also abusing a wider array of illicit drugs compared to those who discounted delayed <b>reinforcers</b> less." ...|$|E
2500|$|Clicker {{training}} is a nickname given to an animal training method {{based on a}} bridging stimulus (the clicker) in operant conditioning. The system uses conditioned <b>reinforcers,</b> which a trainer can deliver more quickly and more precisely than primary <b>reinforcers</b> such as food. The term [...] "clicker" [...] comes from a small metal cricket noisemaker adapted from a child's toy that the trainer uses to precisely mark the desired behavior. When training a new behavior, the clicker helps the animal to quickly identify the precise behavior that results in the treat. The technique is popular with dog trainers, but {{can be used for}} all kinds of domestic and wild animals and small children.|$|E
2500|$|Positive and {{negative}} reinforcement play central {{roles in the}} development and maintenance of addiction and drug dependence. An addictive drug is intrinsically rewarding; that is, it functions as a primary positive reinforcer of drug use. The brain's reward system assigns it incentive salience (i.e., it is [...] "wanted" [...] or [...] "desired"),An important dimension of reinforcement highly relevant to the addiction process (and particularly relapse) is secondary reinforcement (Stewart, 1992). Secondary <b>reinforcers</b> (in many cases also considered conditioned <b>reinforcers)</b> likely drive the majority of reinforcement processes in humans. In the specific case of drug , cues and contexts that are intimately and repeatedly associated with drug use will often themselves become reinforcing... A fundamental piece of Robinson and Berridge's incentive-sensitization theory of addiction posits that the incentive value or attractive nature of such secondary reinforcement processes, in addition to the primary <b>reinforcers</b> themselves, may persist and even become sensitized over time in league with the development of drug addiction (Robinson and Berridge, 1993)....Negative reinforcement is a special condition associated with a strengthening of behavioral responses that terminate some ongoing (presumably aversive) stimulus. In this case we can define a negative reinforcer as a motivational stimulus that strengthens such an “escape” response. Historically, in relation to drug addiction, this phenomenon has been consistently observed in humans whereby drugs of abuse are self-administered to quench a motivational need in the state of withdrawal (Wikler, 1952).}} so as an addiction develops, deprivation of the drug leads to craving. [...] In addition, stimuli associated with drug use– e.g., the sight of a syringe, and the location of use– become associated with the intense reinforcement induced by the drug. These previously neutral stimuli acquire several properties: their appearance can induce craving, and they can become conditioned positive <b>reinforcers</b> of continued use. Thus, if an addicted individual encounters one of these drug cues, a craving for the associated drug may reappear. For example, anti-drug agencies previously used posters with images of drug paraphernalia as an attempt to show the dangers of drug use. However, such posters are no longer used because of the effects of incentive salience in causing relapse upon sight of the stimuli illustrated in the posters.|$|E
2500|$|... is the {{analysis}} of consumer demand, as indexed {{by the amount of}} a commodity that is purchased. In economics, the degree to which price influences consumption is called [...] "the price elasticity of demand." [...] Certain commodities are more elastic than others; for example, a change in price of certain foods may have a large effect on the amount bought, while gasoline and other essentials may be less affected by price changes. In terms of operant analysis, such effects may be interpreted in terms of motivations of consumers and the relative value of the commodities as <b>reinforcers.</b>|$|E
2500|$|Applied {{behavior}} {{analysis is}} the discipline initiated by B. F. Skinner that applies {{the principles of}} conditioning to the modification of socially significant human behavior. It uses the basic concepts of conditioning theory, including conditioned stimulus (SC), discriminative stimulus (Sd), response (R), and reinforcing stimulus (Srein or Sr for <b>reinforcers,</b> sometimes Save for aversive stimuli). A conditioned stimulus controls behaviors developed through respondent (classical) conditioning, such as emotional reactions. The other three terms combine to form Skinner's [...] "three-term contingency": a discriminative stimulus sets the occasion for responses that lead to reinforcement. Researchers have found the following protocol to be effective when they use the tools of operant conditioning to modify human behavior: ...|$|E
2500|$|The {{reward system}} {{is a group of}} neural {{structures}} responsible for incentive salience (i.e., motivation and [...] "wanting", desire, or craving for a reward), associative learning (primarily positive reinforcement and classical conditioning), and positive emotions, particularly ones which involve pleasure as a core component (e.g., joy, euphoria and ecstasy). Reward is the attractive and motivational property of a stimulus that induces appetitive behavior – also known as approach behavior – and consummatory behavior. In its description of a rewarding stimulus (i.e., [...] "a reward"), a review on reward neuroscience noted, [...] "any stimulus, object, event, activity, or situation that has the potential to make us approach and consume it is by definition a reward." [...] In operant conditioning, rewarding stimuli function as positive reinforcers; however, the converse statement also holds true: positive <b>reinforcers</b> are rewarding.|$|E
2500|$|Skinner’s Walden {{proposal}} is in {{a tradition that}} goes back to Plato’s philosopher king: a ‘legislator’ (monarch) and a set of guardians who are wiser than the common people. [...] The guardians “are to be a class apart, like the Jesuits in old Paraguay, the ecclesiastics in the States of the Church until 1870 and the Communist Party in the U.S.S.R. at the present day,” wrote Bertrand Russell, one of Skinner’s heroes, in 1946. [...] Not too different from Walden Two’s Managers and Planners, and Frazier, Skinner’s avatar and leader of the community. [...] Skinner was quite explicit about the need for technocratic rule: “We must delegate control of the population as a whole to specialists – to police, priests, teachers, therapies, and so on, with their specialized <b>reinforcers</b> and their codified contingencies.” ...|$|E
2500|$|Intertemporal {{choice is}} {{commonly}} {{measured in the}} laboratory using a [...] "delayed discounting" [...] paradigm, which measures the process of devaluing rewards and punishments that happen in the future. In this paradigm, subjects must choose between a smaller reward delivered soon and a larger reward delivered at a delay in the future. [...] Choosing the smaller-sooner reward is considered impulsive. By repeatedly making these choices, indifference points can be estimated. For example, if someone chose $70 now over $100 in a week, but chose the $100 in a week over $60 now, it can be inferred that they are indifferent between $100 in a week and an intermediate value between $60 and $70. [...] A delay discounting curve can be obtained for each participant by plotting their indifference points with different reward amounts and time delays. [...] Individual differences in discounting curves are affected by personality characteristics such as self-reports of impulsivity and locus of control; personal characteristics such as age, gender, IQ, race, and culture; socioeconomic characteristics such as income and education; and many other variables. Lesions of the nucleus accumbens core subregion or basolateral amygdala produce shifts towards choosing the smaller-sooner reward, suggesting the involvement of these brain regions in the preference for delayed <b>reinforcers.</b> [...] There is also evidence that the orbitofrontal cortex is involved in delay discounting, although there is currently debate on whether lesions in this region result in more or less impulsivity.|$|E
5000|$|Tokens have no {{intrinsic}} value, but can {{be exchanged}} for other valued reinforcing events: back-up <b>reinforcers.</b> Most token economies offer a choice of differing back-up <b>reinforcers</b> that can be virtually anything. Some possible <b>reinforcers</b> might be: ...|$|E
50|$|New <b>reinforcers</b> are {{accessible}} and enrich {{the perspective of}} the learner. Additionally these <b>reinforcers</b> may lead to an increase in the variety of behaviors. If the <b>reinforcers</b> are promoting health and social behaviors, they will lead to an improved quality of life.|$|E
50|$|Tokens {{must be used}} as <b>reinforcers</b> to be effective. A token is {{an object}} or symbol that can be {{exchanged}} for material <b>reinforcers,</b> services, or privileges (back-up <b>reinforcers).</b> In applied settings, {{a wide range of}} tokens have been used: coins, checkmarks, images of small suns, phallus pictures, points on a counter. These symbols and objects are comparably worthless outside of the patient-clinician relationship, but their value {{lies in the fact that}} they can be exchanged for other things. Technically speaking, tokens are not primary <b>reinforcers,</b> but secondary or learned <b>reinforcers.</b> Much research has been conducted on token reinforcement, including animal studies.|$|E
50|$|<b>Reinforcers</b> {{serve to}} {{increase}} behaviors whereas punishers serve to decrease behaviors; thus, positive <b>reinforcers</b> are stimuli {{that the subject}} will work to attain, and negative <b>reinforcers</b> are stimuli that the subject will work {{to be rid of}} or to end. The table below illustrates the adding and subtracting of stimuli (pleasant or aversive) in relation to reinforcement vs. punishment.|$|E
50|$|A primary reinforcer, {{sometimes}} called an unconditioned reinforcer, is a stimulus {{that does not}} require pairing with a different stimulus in order {{to function as a}} reinforcer and most likely has obtained this function through the evolution and its role in species' survival. Examples of primary <b>reinforcers</b> include food, water, and sex. Some primary <b>reinforcers,</b> such as certain drugs, may mimic the effects of other primary <b>reinforcers.</b> While these primary <b>reinforcers</b> are fairly stable through life and across individuals, the reinforcing value of different primary <b>reinforcers</b> varies due to multiple factors (e.g., genetics, experience). Thus, one person may prefer one type of food while another avoids it. Or one person may eat lots of food while another eats very little. So even though food is a primary reinforcer for both individuals, the value of food as a reinforcer differs between them.|$|E
5000|$|When {{trying to}} {{distinguish}} {{primary and secondary}} <b>reinforcers</b> in human examples, use the [...] "caveman test." [...] If the stimulus is something that a caveman would naturally find desirable (e.g., candy) then it is a primary reinforcer. If, on the other hand, the caveman would not react to it (e.g., a dollar bill), it is a secondary reinforcer. As with primary <b>reinforcers,</b> an organism can experience satiation and deprivation with secondary <b>reinforcers.</b>|$|E
5000|$|A {{generalized}} reinforcer is a conditioned reinforcer {{that has}} obtained the reinforcing function by pairing {{with many other}} <b>reinforcers</b> and functions as a reinforcer under a wide-variety of motivating operations. (One {{example of this is}} money because it is paired with many other <b>reinforcers).</b>|$|E
50|$|The {{published}} neuroimaging {{studies have}} found that the reward value, the expected reward value, and even the subjective pleasantness of foods and other <b>reinforcers</b> are represented in the OFC. A large meta-analysis of the existing neuroimaging evidence demonstrated that activity in medial parts of the OFC is related to the monitoring, learning, and memory of the reward value of <b>reinforcers,</b> whereas activity in lateral OFC is related to the evaluation of punishers, which may lead to a change in ongoing behaviour.Similarly, a posterior-anterior distinction was found with more complex or abstract <b>reinforcers</b> (such as monetary gain and loss) being represented more anteriorly in the orbitofrontal cortex than less-complex <b>reinforcers</b> such as taste. It has even been proposed that the human OFC has a role in mediating subjective hedonic experience.|$|E
50|$|B.F. Skinner {{was well}} known for his studies of <b>reinforcers</b> on behavior. His studies {{included}} the aspect of contingency, which refers to the connection between a specific action and the following consequence or reinforcement. Skinner described three contingencies: positive reinforcement, negative reinforcement, and punishment. Reinforcements create a positive association between the action and consequence {{in order to promote}} the continuation of the action. This is done in one of two ways, positive <b>reinforcers</b> introduce a rewarding stimulus, whereas negative <b>reinforcers</b> remove an aversive stimulus to make the environment less aversive. Punishments create a negative relationship between the action and the consequence so that the action does not continue.|$|E
50|$|Self-regulation is a {{sub-category}} {{of reinforcement}} contingency theories. Self-regulation theories emphasize {{the role of}} self-implemented <b>reinforcers</b> and environment-dependent <b>reinforcers.</b> These self-implemented <b>reinforcers</b> may explain why some individuals who experience an external loss develop depression and others do not. Self-regulation begins with a self-evaluation in which the person recalls past performances and monitors their actions, followed by a reward or punishment. Individuals with depression may have unrealistic expectations for themselves, resulting in extreme self-punishment, or alternatively, may not engage in self-regulatory behaviors, depending completely on external sources of reinforcement. In either circumstance, the individual limits their experiences of positive enforcers, leading to a preoccupancy with negative feelings and depression.|$|E
5000|$|... "Covert modeling" [...] {{involves}} imagining someone {{engaging in}} the behavior and, optionally, <b>reinforcers</b> taking place.|$|E
5000|$|They are [...] "baited" [...] with {{virtually}} irresistible <b>reinforcers</b> that [...] "lure" [...] {{the student to}} the trap ...|$|E
5000|$|Lewinsohn has {{the theory}} that {{patients}} need <b>reinforcers</b> to feel good. The idea is that patients can get <b>reinforcers</b> from activities, but they [...] "want to wait for their mood to lighten before engaging in activities." [...] So Beck asks clients to perform activities as a behavioral experiment. The patients can then increase systematically the activities with higher ratings of mastery and pleasure and look for new activities.|$|E
50|$|Back-up <b>reinforcers</b> {{are chosen}} in {{function}} of the individual or group for which the token economy is set up, or depending upon the possibilities available to the staff. Prior to starting the staff decides how many tokens {{have to be paid}} for each back-up reinforcer. Often, price lists are exposed or given to the clients. Some back-up <b>reinforcers</b> can be bought anytime, for other exchange times are limited (e.g. opening times of a token shop).|$|E
50|$|New environments are {{geographical}} and/or virtual {{areas of}} potential change (receiving environments). New environments regulate, maintain, {{and set the}} micro-cultural boundaries for <b>reinforcers</b> (and punishers), and their antecedents. They include tools and stakeholders controlling the pace and content of instruction and, as a result, they regulate boundary of what the learner learns (e.g., school curriculum). New environments must contain some of the stakeholders' preferences and <b>reinforcers</b> to create lasting positive reinforcement practices for the learner.|$|E
50|$|Historically, consummatory responses, {{eating and}} drinking, have served {{exclusively}} as <b>reinforcers,</b> but consummatory responses are, {{like any other}} response, subject to reinforcement.|$|E
50|$|After {{the removal}} of <b>reinforcers,</b> the {{affected}} individual begins to interpret their behavior as meaningless {{due to the lack}} of obvious consequences. This interpreted lack of control in a given domain is typically generalized, developing into learned helplessness. Learned helplessness is defined as a sense of having no control over outcomes, regardless of your actions. This may mediate the emergence of the lack of responsiveness and arousal observed in persons with depression after a perceived change in positive <b>reinforcers.</b>|$|E
5000|$|A token {{economy is}} a system of {{contingency}} management based on the systematic reinforcement of target behavior. The <b>reinforcers</b> are symbols or [...] "tokens" [...] that can be exchanged for other <b>reinforcers.</b> A token economy {{is based on the}} principles of operant conditioning and behavioral economics and can be situated within applied behavior analysis. In applied settings token economies are used with children and adults; however, they have been successfully modeled with pigeons in lab settings.|$|E
50|$|Mayo, Liliana (1986) Continuous Access of <b>Reinforcers</b> and Protective Equipment: Reducing {{aberrant}} {{behaviors of}} retarded and autistic children. Thesis Archives: Library of Congress, U.S.A.|$|E
