12|126|Public
30|$|Hierarchical {{clustering}} {{and heat}} map {{was conducted on}} mean centered and standardized data in R (Version 3.0). <b>Replicate</b> <b>values</b> were averaged where appropriate and Ward’s method on Euclidean distance matrix was used for clustering (Asiago et al., 2012).|$|E
30|$|Precision (reproducibility) was ascertained using within-day {{replicate}} {{analysis of}} samples. The Relative Standard Deviation (% RSD[*]=[*]SD/χ of the <b>replicate</b> <b>values</b> X 100 %; χ is mean value) was calculated {{to give an}} indication of sample preparation and analytical precision. Replicates of samples provided an indication of within-day precision. The analytical detection limit was calculated as the concentration of the element which gave a detectable signal above the background noise at greater than the 99 % confidence level, and the detection limit was calculated as the mean of blanks plus 3 times the standard deviation of the mean.|$|E
40|$|Understanding and {{quantifying}} the large, unexplained {{variability in}} soil erosion data {{are critical for}} advancing erosion science, evaluating soil erosion models, and designing erosion experiments, We hypothesized {{that it is possible}} to quantify variability between replicated soil erosion field plots under natural rainfall, and thus determine the principal factor or factors which correlate to the magnitude of the variability: Data from replicated plot pairs for 2061 storms, 797 annual erosion measurements, and 53 multi-year erosion totals were used. Thirteen different soil types and site locations were represented in the data. The relative differences between replicated plot pair data tended to be lesser for greater magnitudes of measured soil loss, thus indicating that soil loss magnitude was a principal factor for explaining variance in the soil loss data. Using this assumption, we estimated the coefficient of variation of within-treatment, plot <b>replicate</b> <b>values</b> of measured soil lass. Variances between replicates decreased as a power function (r(2) = 0. 78) of measured soil loss, and were independent of whether the measurements were event-, annual-, or multi-year values. Coefficients of variation ranged on the order of 14 % for a measured soil loss of 20 kg/m(2) to greater than 150 % for a measured soil loss of less than 0. 01 kg/m(2) These results have important implications for both experimental design and for using erosion data to evaluate prediction capability for erosion models. status: publishe...|$|E
40|$|FIGURE 1. Phylogram of the neighbor-joining-tree {{based on}} 605 bp of the 16 s rRNA gene. Values above the nodes are {{bootstrap}} pseudoreplicates (20000 <b>replicates).</b> <b>Values</b> below the nodes are the corresponding maximum-likelihood bootstrap supports (1000 <b>replicates).</b> Significantly supported <b>values</b> are in bold. Hemidactylus frenatus (AY 517562) {{was used as}} outgroup...|$|R
3000|$|... ∗, which <b>replicates</b> a <b>value</b> {{function}} {{equal to}} the optimal value function such that V(t,x,y)=J(t,x,y,π [...]...|$|R
40|$|FIGURE 2. Main {{mitochondrial}} DNA lineage {{variation in}} Babr. A neighbor-joining tree based on observed (uncorrected) {{differences in the}} sequence of the 600 - bp segment of the COI gene. B. baikali lineages are marked with symbols used in Fig. 1 a. The depth of terminal triangles indicates the deepest intralineage divergence, and width the number of different haplotypes. The numbers at the nodes are support values (%) from 500 bootstrap <b>replicates</b> (<b>values</b> lower then 50 % are not shown) ...|$|R
40|$|There is need {{to develop}} {{reproducible}} methods and experimental models for screening mucosal irritation and toxicity for drugs and pharmaceutical excipients. The {{aim of this study}} was to validate Calu- 3 cell line as a model for screening respiratory irritation and toxicity of drugs and excipients. Eighteen test compounds were selected according to their irritation potential and European Centre for the Validation of Alternative Methods (ECVAM) guidelines. Cell toxicity and irritation was determined using MTT assay. Data analysis and interpretation were done using modified ECVAM approach; where <b>replicate</b> <b>values</b> met acceptance criteria if percent relative standard deviation (RSD) of the raw data is < 18 %. Compounds with mean relative viability values of 50 % and below were classified as irritant (I); those above 50 % were non-irritant (NI). At low concentration (0. 2 % w/v) and 1 h incubation, the Calu- 3 cell culture model accurately predicted the toxicity of most test compounds. The specificity of our proposed model (percentage of in vivo non-irritants correctly predicted), concordance (percentage of compounds correctly predicted) and sensitivity (percentage of in vivo irritants correctly predicted) at 0. 2 % w/v and 60 min exposure were 100 %, 72 %, and 44 %, respectively. In conclusion, the Calu- 3 cell line in conjunction with MTT assay appears to be a potentially useful tool for screening drugs and excipients for respiratory mucosa irritation and toxicity. However, as the data reported in this study were solely based on MTT assay, additional studies are needed using other toxicity-/irritation-indicating methods to confirm the observed trend...|$|E
40|$|Abstract Background Post-genomic {{molecular}} biology {{has resulted in}} an explosion of data, providing measurements for large numbers of genes, proteins and metabolites. Time series experiments have become increasingly common, necessitating the development of novel analysis tools that capture the resulting data structure. Outlier measurements at one or more time points present a significant challenge, while potentially valuable replicate information is often ignored by existing techniques. Results We present a generative model-based Bayesian hierarchical clustering algorithm for microarray time series that employs Gaussian process regression to capture {{the structure of the}} data. By using a mixture model likelihood, our method permits a small proportion of the data to be modelled as outlier measurements, and adopts an empirical Bayes approach which uses replicate observations to inform a prior distribution of the noise variance. The method automatically learns the optimum number of clusters and can incorporate non-uniformly sampled time points. Using a wide variety of experimental data sets, we show that our algorithm consistently yields higher quality and more biologically meaningful clusters than current state-of-the-art methodologies. We highlight the importance of modelling outlier values by demonstrating that noisy genes can be grouped with other genes of similar biological function. We demonstrate the importance of including replicate information, which we find enables the discrimination of additional distinct expression profiles. Conclusions By incorporating outlier measurements and <b>replicate</b> <b>values,</b> this clustering algorithm for time series microarray data provides a step towards a better treatment of the noise inherent in measurements from high-throughput genomic technologies. Timeseries BHC is available as part of the R package 'BHC' (version 1. 5), which is available for download from Bioconductor (version 2. 9 and above) via [URL]. </p...|$|E
40|$|The Three Rivers area of Pittsburgh, Pennsylvania {{has more}} {{combined}} sewer overflow (CSO) release points than any other city in the United States. CSOs and sanitary sewer overflows (SSOs) release untreated waste directly into receiving water during wet weather events such as rain or snow. A wide range of estrogenic agents is contained in municipal wastewater, including pharmaceutical estrogens, plastic additives, pesticides and detergent breakdown products such as nonyl-phenol. The goal of this analysis was to examine estrogenicity of channel catfish fillet tissue in areas significantly impaired by CSO/SSOs compared to store-bought catfish and catfish from up-river areas on the Allegheny River that are less impacted. Estrogenicity {{was based on the}} ability of catfish fillet tissue to proliferate MCF 7 human breast cancer cells. Cell proliferation was quantified using a serial dilution assay. <b>Replicate</b> <b>values</b> for each fish at each dilution were analyzed using a random intercept model. Area effects were quantified in terms of absolute and relative differences, controlling for background. In this study, cell proliferation is higher for catfish sampled from the most contaminated CSO/SSO sites than for catfish sampled from areas on the Allegheny with fewer CSOs/SSOs. The risk information concerning cumulative estrogenicity in channel catfish, in this study may provide a linkage between the ecological compounds contained in wastewaters and human health. Estradiol equivalents could be constructed from the estrogenicity index developed in this paper. These findings are significant to public health because they could help to estimate the risk of estrogenic exposure posed to those who consume channel catfish from the Three Rivers Area of Pittsburgh. The findings could also help describe the impact of estrogenic exposure in wildlife...|$|E
40|$|Figure 1. Quasispecies {{analysis}} of hepatitis C virus (HCV) from cytobrush and blood specimens of 8 women with HIV-HCV coinfection. The phylogenetic tree of HCV nucleotide sequences was obtained using the maximum parsimony method, by applying close neighbor interchange (MEGA package; version 2. 1). Nos. at nodes indicate the frequency (%) of their occurrence in bootstrap analysis based on 500 <b>replicates.</b> <b>Values</b> 80 % are shown. Patients are identified by different colors. Circles, plasma clones; triangles, cytobrush clones. 10. Poss M, Rodrigo AG, Gosink JJ, et al. Evo-lution of envelope sequences from the genital tract and peripheral blood of women infected with clade A human immunodeficiency viru...|$|R
5000|$|In statistics, Tukey's test of additivity, {{named for}} John Tukey, is an {{approach}} used in two-way ANOVA (regression analysis involving two qualitative factors) {{to assess whether}} the factor variables are additively related to the expected value of the response variable. It can be applied {{when there are no}} <b>replicated</b> <b>values</b> in the data set, a situation in which it is impossible to directly estimate a fully general non-additive regression structure and still have information left to estimate the error variance. The test statistic proposed by Tukey has one degree of freedom under the null hypothesis, hence this is often called [...] "Tukey's one-degree-of-freedom test." ...|$|R
40|$|Figure 2 - Maximum {{likelihood}} {{tree for}} the combined mitochondrial COI+ 16 S dataset, 1000 bootstrap <b>replicates,</b> <b>values</b> below 70 not shown. The bootstrap values of ML and posterior probabilities of BI are given {{above and below}} the corresponding branches, respectively, for all major clades. Scale bar = substitutions per site. Coloured blocks indicate species groups. Color of branches refers to the major subregions shown in the map, Tasmanian branches thicker. General differences in male gonopod morphology are shown by sketches of the apical region of the right gonopod not drawn to scale. Coloured lines link those analysed specimens that have similar gonopod morphology. Posterior view = post.; lateral view = lat.; anterior view = ant...|$|R
40|$|Thesis (M. A. (Industrial Psychology)) [...] North-West University, Potchefstroom Campus, 2007. Beliefs {{are social}} in nature. and are widely shared within social groups, such as cultures. Shared beliefs reflect how people {{construct}} their social world {{and how they}} seek meaning and understanding of social realities. and they are context specific. General beliefs are context free and related to {{a wide spectrum of}} social behaviours across diverse contexts, actors, targets and periods. These general beliefs function like axioms in mathematics, thus they are basic premises that people endorse and on which they rely to guide their actions. A better understanding of beliefs can therefore be a useful instrument in managing a diverse workforce, such as the workforce found in South Africa. The objectives of this study were to investigate the replicability of the Social Axioms Survey (SAS) in the South African Police Service (SAPS), to examine the construct equivalence and item bias. and to assess the reliability. A cross-sectional survey design was used. The study population consisted of applicants (N= 1535) who applied for jobs in the SAPS. The SAS instrument was administered. Descriptive statistics, exploratory and confirmatory factor analyses, scale and item level analysis and estimation of reliability were used to analyse the results. An exploratory factor analysis utilising target rotation applied on all 60 items of the SAS revealed four interpretable factors (Factor 1 = Social Cynicism; Factor 2 = Reward for Application; Factor 4 = Fate Control; and Factor 5 = Spirituality Religiosity) congruent with the model of Leung et al. (2002). The third factor, namely Social Complexity did not <b>replicate.</b> <b>Values</b> of Tucker's phi higher than 0. 90 were found for seven culture groups (Zulu, Sotho, Tswana, Swati, Tsonga, Venda and Pedi). This provided a strong indication of the structural equivalence. Analyses of variance showed that item bias was not a major disturbance. Cronbach's alpha reported lower levels of reliability. Recommendations for future research were made. Master...|$|E
40|$|Raw {{male and}} female fitness data for 223 hemiclonal genotypes sampled from the LHM {{laboratory}} adapted population. See Gilks et al (2017; [URL] for full details on how these lines were established. Assays were designed to measure total adult lifetime fitness {{for both males and}} females from each line, under conditions that match as close as possible those experienced by adults in the base population (Chippindale et al., 2001; Rice, 2005; Rice et al., 2006). Male fitness assay 5 hemiclonal males per line were combined in adult competition vials with 10 competitor bw- males and 15 virgin bw- females. After 2 days, each bw- female was isolated into individual oviposition test-tubes (containing the cornmeal-molasses-agar media but with no additional dried yeast) and left to oviposit for 18 hours. On Day 12, progeny were scored for eye-colour, in two observation rounds to allow ensure that as many eclosing offspring were included. Hemiclonal males were assigned paternity to progeny with wild-type red eyes (progeny of competitors are homozygous for the bw- allele and therefore have brown eyes), giving an average fitness score (number of offspring sired) for the 5 hemiclonal males that were assayed per line. This assay was independently replicated 5 times, representing data from a total of 25 hemiclonal males per line. Male fitness was calculated as the proportion of offspring sired per assayed male, which accounts for instances where less than 5 hemiclonal males were included (6 out of 1105 assays). Female fitness assays Assays of female fitness followed a similar protocol to the male assays, again to match as close as possible the timing and conditions experienced by individuals in the base population. In this case, 5 virgin hemiclonal females were combined in adult competition vials with 10 competitor bw- females and 15 bw- males for 2 days. After 2 days, the 5 hemiclonal females were isolated into individual test-tubes and left to oviposit for 18 hrs. The tubes were immediately chilled (4 °C) to halt embryo development and the number of eggs per female was counted to provide a measure of fecundity. Data was excluded for tubes in which the female was either dead or not present. Since unmated females are known to produce eggs at a low rate, we also excluded data from females where egg counts were 0 or 1 as these are likely to represent output from unmated females (see Supplementary figure 1). By averaging fecundity across all 5 females this provided an average female fitness score for that line. This assay was independently replicated 5 times, representing a total of 25 hemiclonal females per line. Dataset Column headings: Male sex - all male (value = 1) rep - <b>replicate</b> (<b>values</b> from 1 to 5) line - hemiclonal line (223 different lines, values from 1 to 230 with 7 lines missing) red_ 1 - number of wild-type red-eyed offspring in first round of counting red_ 2 - number of wild-type red-eyed offspring in second round of counting brown_ 1 - number of brown-eyed offspring in first round of counting brown_ 2 - number of brown-eyed offspring in second round of counting total_red - number of offspring counted with wild-type red eyes (genotype bw+/bw-) total_brown - number of offspring counted with brown eyes (genotype bw-/bw-) male_density - number of hemiclonal males per vial (value usually 5, but may be less due to missing males) note: NA - missing value Female sex - all female (value = 2) rep - <b>replicate</b> (<b>values</b> from 1 to 5) line - hemiclonal line (223 different lines, values from 1 to 230 with 7 lines missing) f 1 - fecundity of female 1 f 2 - fecundity of female 2 f 3 - fecundity of female 3 f 4 - fecundity of female 4 f 5 - fecundity of female 5 note: NA - missing value References Chippindale, A. K., Gibson, J. R. & Rice, W. R. 2001. Negative genetic correlation for adult fitness between sexes reveals ontogenetic conflict in Drosophila. Proc. Natl. Acad. Sci. 98 : 1671 – 1675. Gilks WP, Pennell TM, Flis I et al. Whole genome resequencing of a laboratory-adapted Drosophila melanogaster population sample [version 3; referees: 2 approved]. F 1000 Research 2016, 5 : 2644 (doi: 10. 12688 /f 1000 research. 9912. 3) Rice, W. R. 2005. Inter-locus antagonistic coevolution as an engine of speciation: Assessment with hemiclonal analysis. Proc. Natl. Acad. Sci. 102 : 6527 – 6534. Rice, W. R., Stewart, A. D., Morrow, E. H., Linder, J. E., Orteiza, N. & Byrne, P. G. 2006. Assessing sexual conflict in the Drosophila melanogaster laboratory model system. Philos. Trans. R. Soc. B Biol. Sci. 361 : 287 – 299...|$|E
40|$|Background: A {{number of}} {{international}} research groups have developed DNA quantitation assays {{in order to}} investigate the role of mitochondrial DNA depletion in anti-retroviral therapy-induced toxicities. Objectives: A collaborative study was undertaken to evaluate intra-assay precision and between laboratory concordance of measurements of mitochondrial DNA quantity, {{as a component of}} a comprehensive quality assurance project. Study design: Four laboratories were asked to measure and report mitochondrial DNA and nuclear DNA genome copy number, as well as mitochondrial DNA copy number/cell, for 17 coded aliquots of DNA derived from serial dilutions of pooled DNA from a lymphoblastoid cell line. Samples included masked replicates and five standards. All samples had similar mitochondrial DNA/nuclear DNA ratios. Precision within laboratories was assessed by determining the coefficient of variation of replicates. Concordance between laboratories was assessed by determining the average coefficient of variation of the mean <b>replicate</b> <b>values</b> for each sample. The effect of standardising the assay for these three measurements was also assessed for laboratories A, B and C. Results: Measurements of mitochondrial DNA and nuclear DNA content for replicate samples varied by an average of less than 6 % (based on log 10 values, 72 % non-logged values), and measurements of mitochondrial DNA/cell for replicates varied by less than 12 % (based on log 10 values, 32 % non-logged values), with no improvement of precision after standardisation. Standardisation did significantly improve the concordance of results for measurements of mitochondrial DNA content and mitochondrial DNA/cell. Non-standardised measurements of mitochondrial DNA content for the same sample set varied by 19 % between laboratories (based on log 10 values, 96 % non-logged values), and after standardisation results varied by less than 3 % (based on log 10 values, 54 % non-logged values). There was no significant improvement for concordance of measures of nuclear DNA content after standardisation, with results varying by 4. 56 % between laboratories (based on log 10 values, 45 % non-logged values) before standardisation, and by 2. 49 % (based on log 10 values, 50 % non-logged values) after standardisation. Derived values of mitochondrial DNA/cell varied between laboratories by an average of 91 % (non-logged, 56 % log 10 values) before and by 56 % (non-logged, 13 % log 10 values) after standardisation. Conclusion: All assays demonstrated good precision. The use of common standards is an important step in improving the comparability of data between laboratories...|$|E
40|$|FIGURE 4. Phylogenetic {{position}} of Dujardinascaris madagascariensis in maximum likelihood (ML) tree inferred from the partial sequences (629 bp) of the 18 S rDNA gene. The species Camallanus cotti {{was used as}} outgroup. The numbers above the branches indicate bootstrap values for ML resulting from 500 <b>replicates.</b> Only <b>values</b> exceeding 50 are shown...|$|R
25|$|The {{values are}} stored at several nodes (k of them) {{to allow for}} nodes {{to come and go}} and still have the value {{available}} in some node. Periodically, a node that stores a value will explore the network to find the k nodes that are close to the key <b>value</b> and <b>replicate</b> the <b>value</b> onto them. This compensates for disappeared nodes.|$|R
40|$|Figure 5 - NJ {{dendrogram}} {{based on}} K 2 P pairwise genetic distances. Values at nodes indicate {{the result of}} the bootstrap test (10. 000 pseudo <b>replicates).</b> Only <b>values</b> ≥ 50 are shown. For Ammodytes tobianus (grey box) and Hyperoplus lanceolatus all analysed individuals are shown. In case of Ammodytes marinus and Hyperoplus immaculatus the number of specimens is given in brackets...|$|R
40|$|Carotid Intima-Media Thickness (CIMT) : A Reproducibility Study Mindy Columbus, Brian Wagner, Emma Barinas-Mitchell Implementation of newer {{ultrasound}} {{technology for}} measuring subclinical atherosclerosis {{may increase the}} validity of measurement of carotid artery intima-media thickness (CIMT) cross-sectionally, but {{may prove to be}} a challenge for obtaining valid and reproducible progression data in existing follow-up studies. In the Department of Epidemiology Ultrasound Research Lab (URL), participants of the ERA JUMP study are returning for a five year follow-up visit for CIMT measurements to determine progression rates of subclinical atherosclerosis. A Toshiba 140 A scanner was used for the baseline measurements and the maintenance service will end soon. There is a newer scanner available for use in the laboratory, and {{the question is whether the}} follow-up images that will be taken on this scanner, a Siemens Sonoline® Antares scanner, will provide comparable results to the baseline measurements in order to predict valid progression and not introduce error due to differences in machines. A reproducibility study was conducted to determine whether a Siemens Sonoline® Antares Doppler ultrasound scanner could be used in place of a Toshiba 140 A Doppler ultrasound scanner to conduct follow-up visit measurements in the ERA JUMP study. A five year progression rate of ~ 0. 04 mm (0. 043) was estimated based on the literature. An average difference of 0. 03 mm in CIMT between machines was determined a priori as an acceptable difference as we wanted to detect a difference between machines that was less than the estimated progression rate in order to assess reliability. The study recruited and evaluated 20 volunteers (85 % women, age range: 24 - 77 years) who were scanned on each machine during the same visit by the same technician for between machine reliability. The mean CIMT values for this study population ranged from 0. 488 to 1. 039 mm. Reproducibility was evaluated on mean CIMT with Spearman and intraclass correlations and by the absolute value of the difference between <b>replicate</b> <b>values.</b> The mean difference in mean CIMT between the machines was - 0. 045 and the mean absolute difference was 0. 052 mm. The mean difference in CIMT values between machines ranged from 0. 077 to - 0. 256 mm, with 95 % (19 / 20) of the differences being negative. This demonstrates systematic bias as the images read on the Toshiba machine were thicker (higher) than the Antares machine. This is likely due to the fact that the Antares scanner produces a crisper and clearer image than the Toshiba scanner demonstrating the advancement of digital technology with the newer scanner. Although the correlation for the mean CIMT between machines was high and agreed well, according to the Spearman correlation (r= 0. 93,...|$|E
40|$|Two key {{sources of}} {{uncertainty}} in projections of future runoff for climate change impact assessments are uncertainty between global climate models (GCMs) {{and within a}} GCM. Within-GCM uncertainty is the variability in GCM output that occurs when running a scenario multiple times but each run has slightly different, but equally plausible, initial conditions. The limited number of runs available for each GCM and scenario combination within the Coupled Model Intercomparison Project phase 3 (CMIP 3) and phase 5 (CMIP 5) data sets, limits the assessment of within-GCM uncertainty. In this second of two companion papers, the primary aim is to present a proof-of-concept approximation of within-GCM uncertainty for monthly precipitation and temperature projections and {{to assess the impact}} of within-GCM uncertainty on modelled runoff for climate change impact assessments. A secondary aim is {{to assess the impact of}} between-GCM uncertainty on modelled runoff. Here we approximate within-GCM uncertainty by developing non-stationary stochastic replicates of GCM monthly precipitation and temperature data. These replicates are input to an off-line hydrologic model to assess the impact of within-GCM uncertainty on projected annual runoff and reservoir yield. We adopt stochastic replicates of available GCM runs to approximate within-GCM uncertainty because large ensembles, hundreds of runs, for a given GCM and scenario are unavailable, other than the Climate prediction. net data set for the Hadley Centre GCM. To date within-GCM uncertainty has received little attention in the hydrologic climate change impact literature and this analysis provides an approximation of the uncertainty in projected runoff, and reservoir yield, due to within- and between-GCM uncertainty of precipitation and temperature projections. In the companion paper, McMahon et al. (2015) sought to reduce between-GCM uncertainty by removing poorly performing GCMs, resulting in a selection of five better performing GCMs from CMIP 3 for use in this paper. Here we present within- and between-GCM uncertainty results in mean annual precipitation (MAP), mean annual temperature (MAT), mean annual runoff (MAR), the standard deviation of annual precipitation (SDP), standard deviation of runoff (SDR) and reservoir yield for five CMIP 3 GCMs at 17 worldwide catchments. Based on 100 stochastic replicates of each GCM run at each catchment, within-GCM uncertainty was assessed in relative form as the standard deviation expressed as a percentage of the mean of the 100 <b>replicate</b> <b>values</b> of each variable. The average relative within-GCM uncertainties from the 17 catchments and 5 GCMs for 2015 – 2044 (A 1 B) were MAP 4. 2 %, SDP 14. 2 %, MAT 0. 7 %, MAR 10. 1 % and SDR 17. 6 %. The Gould–Dincer Gamma (G-DG) procedure was applied to each annual runoff time series for hypothetical reservoir capacities of 1 × MAR and 3 × MAR and the average uncertainties in reservoir yield due to within-GCM uncertainty from the 17 catchments and 5 GCMs were 25. 1 % (1 × MAR) and 11. 9 % (3 × MAR). Our approximation of within-GCM uncertainty is expected to be an underestimate due to not replicating the GCM trend. However, our results indicate that within-GCM uncertainty is important when interpreting climate change impact assessments. Approximately 95 % of values of MAP, SDP, MAT, MAR, SDR and reservoir yield from 1 × MAR or 3 × MAR capacity reservoirs are expected to fall within twice their respective relative uncertainty (standard deviation/mean). Within-GCM uncertainty has significant implications for interpreting climate change impact assessments that report future changes within our range of uncertainty for a given variable – these projected changes may be due solely to within-GCM uncertainty. Since within-GCM variability is amplified from precipitation to runoff and then to reservoir yield, climate change impact assessments that do not take into account within-GCM uncertainty risk providing water resources management decision makers with a sense of certainty that is unjustified...|$|E
50|$|The {{values are}} stored at several nodes (k of them) {{to allow for}} nodes {{to come and go}} and still have the value {{available}} in some node. Periodically, a node that stores a value will explore the network to find the k nodes that are close to the key <b>value</b> and <b>replicate</b> the <b>value</b> onto them. This compensates for disappeared nodes.|$|R
40|$|Stratified random {{sampling}} at differential rates {{is commonly used}} in social science surveys to improve the chances of getting sufficiently large samples of subpopulations of interest. Multi-phase sampling {{is often used to}} further target desired populations. The variances of such samples can be estimated using jackknifing, which creates <b>replicated</b> <b>values</b> of the characteristic of interest as if one sampling unit had not been part of the sample, then sums the squared differences between those replicates and the population total. Kim (2000) suggested a method for estimating the variance in a three-phase design in which the first two phases were stratified and the third was a simple random sample from among the sample units in the second phase. In this paper, Kim’s method is extended to a three-phase design in which all three phases are stratified samples at differential rates, but the last phase is stratified by characteristics not related to those used in stratifying the first two phases...|$|R
50|$|Filtering of noisy {{replicates}} is {{a crucial}} part of quality control. Experimental replicates should have similar <b>values.</b> <b>Replicates</b> with noise should be eliminated before analysis; this can be done using the ANOVA statistical method.|$|R
40|$|The {{strategy}} of accumulating valuable assets {{guided by the}} firm’s intellectual right is often not enough to support a significant performance in a rapidly changing environment. Hence, in such an environment, superior performance relies upon {{the ability of a}} firm to integrate, build and reconfigure those resources, the process of which is termed as dynamic capabilities. Hence, {{the purpose of this study}} is to investigate the mediating role of dynamic capabilities on the relationship between intellectual capital and manufacturing firm performance in a turbulent business setting. The data was gathered from 124 manufacturing enterprises in Nigeria and analyzed using the Partial Least Squares Structural Equation Modeling (PLS-SEM). The analyzed data supported all the hypothesized relationships of the study. Hence, the study found that there is positive relationships between all the dimensions of intellectual capital and dynamic capabilities and also dynamic capabilities mediate the relationship between intellectual capital and performance. Consequently, this study concluded that managers need to deploy not only valuable resources but also dynamic capabilities by re configuring their existing resources to conceive of and implement difficult to <b>replicate</b> <b>value</b> adding strategies. Finally, the study outlined some limitations that opened the avenues for future research...|$|R
30|$|The current {{version of}} DCRP is {{inspired}} in Chord [32], {{one of the earliest}} P 2 P algorithm based on a DHT 2. Therefore, DCRP inherits Chord’s key space structure and its rules for storing/mapping keys among the participant nodes. It must be noted that DCRP does not <b>replicate</b> key <b>values</b> over the DHT due to the prohibitive cost of such operation in a wireless environment. This means that only one DHT node with the closest key on the ring will store this value.|$|R
40|$|Natural graphs, such {{as social}} networks, email graphs, or instant {{messaging}} patterns, have become pervasive through the internet. These graphs are massive, often containing {{hundreds of millions of}} nodes and billions of edges. While some theoretical models have been proposed to study such graphs, their analysis is still difficult due to the scale and nature of the data. We propose a framework for large-scale graph decomposition and inference. To resolve the scale, our framework is distributed so that the data are partitioned over a sharednothing set of machines. We propose a novel factorization technique that relies on partitioning a graph so as to minimize the number of neighboring vertices rather than edges across partitions. Our decomposition is based on a streaming algorithm. It is network-aware as it adapts to the network topology of the underlying computational hardware. We use local copies of the variables and an efficient asynchronous communication protocol to synchronize the <b>replicated</b> <b>values</b> in order to perform most of the computation without having to incur the cost of network communication. On a graph of 200 million vertices and 10 billion edges, derived from an email communication network, our algorithm retains convergence properties while allowing for almost linear scalability in the number of computers...|$|R
40|$|Purpose: The {{questions}} that we address in this paper are the following. In {{the context of the}} particular DSGE model with labour market frictions, do animal spirits expectations and rational expectations yield qualitatively and quantitatively different outcomes in the face of supply and demand shocks? Does the optimal monetary policy response differ for the two types of expectation? Does there exist a simple rule such as the Taylor rule that can replicate the outcomes for all variables obtained when monetary policy is set optimally? How do these <b>replicating</b> <b>values</b> depend on the degree of the labour market and expectations imperfections? Under what circumstances should the central bank be targeting inflation and/or economic activity? Should it smooth its interest rate responses? Findings: We find qualitatively different outcomes for an 'animal spirits' expectations heuristic to rational expectations after supply and demand shocks. Provided monetary policy is optimally set, major differences arise only for supply shocks. A Taylor rule can replicate optimal monetary policy outcomes regardless of the degree of imperfections under demand shocks, however this is not true under supply shocks. We argue that the persistence of the interest rate typically found in practice is optimal in the presence of supply shocks, since demand shocks can be perfectly accomodated by changing the interest rate immediately. 2 page(s...|$|R
40|$|The IB {{literature}} {{informs us}} of {{several ways to}} measure firms’ degree of internationalization. In this paper we make the argument that in fact none of the existing indices really measure firms’ degree of "global specialization", that is, to what extent their allocation of resources is multidomestic or global. As argued, all the existing measures may gauge a purely multidomestic firm as having a high degree of internationalization, whereas a truly global firm may be ranked low. In order to remedy this we introduce a complementary index measuring how firms are configuring their value chains – whether they are <b>replicating</b> <b>value</b> chain activities from country to country or locating them in globally specialized units in order to exploit an international division of labor. In addition to mathematical modeling and numerical examples, we examine the relevance of the new index of global specialization on data of Danish MNCs by looking at the correlation between the new global specialization index and existing indices of firms’ degree of internationalization. We find that the index is able to identify a distinct group of firms with significantly higher degrees of global value chain configuration. Key words: Internationalization, value chain, global configuration. JEL Codes: F 02, F 23, L 22, L 2...|$|R
30|$|Another {{important}} {{result is}} that the experimental error is only (2.5  %) when considering the center point <b>replicates.</b> This <b>value</b> is very comparative of what is in found in literature. Aleboyeh et al. (2008) found the experimental error was (2.18  %) by comparing the color removal of C.I. Acid Red 14 using electrocoagulation. Alinsafi et al. (2005) calculated a 2.8  % experimental error when treating blue reactive dye using electrocoagulation, and Bhatti et al. (2009) determined a 3.02  % experimental error. These values indicate that the results from the experiment are precise.|$|R
40|$|Figure 10 - Phylogenetic {{relationship}} of all Kurixalus species from Taiwan. A phylogram showing the phylogenetic relationships {{of the four}} Kurixalus species, obtained by a maximum likelihood search based on 1207 nucleotides from mtDNA CO 1 and 16 S rRNA genes. Feihyla palpebralis and Rhacophorus moltrechti were used as outgroups. The three values on each branch are maximum likelihood (ML), maximum parsimony (MP), and neighbor-joining (NJ) analyses with bootstrapping support based on 2000 <b>replicates.</b> Bootstrapping <b>values</b> below 50 % are not shown. (JP: Ryukyu Islands of Japan; N. TW: northern Taiwan; C. TW: central Taiwan) ...|$|R
40|$|The {{growth rates}} and {{buoyancy}} properties of 3 oceanic diatoms in the genus Rhizosolenia were examined at light levels from 8 to 211 umol quanta m- 2  s- 1. Maximum growth rates ranged from 0. 37 to 0. 78 divisions d- 1  with saturation occurring between 29 and 164 umol quanta m- 2  s- 1. Severe growth rate depressions were noted in R. acuminata and R. formosa at irradiance levels above 50 to 155 umol quanta m- 2  s- 1. In all 3 species {{the percentage of}} positively buoyant cells was inversely related to light intensity. In R. formosa both growth rate and tolerance to high light levels decreased substantially as cell size decreased. Batch culture C:chlorophyll ratios (130 to 261) <b>replicated</b> <b>values</b> found in fieldEthmodiscus and Rhizosolenia mats, and suggest that the elevated C:chlorophyll ratios found in buoyant, oceanic phytoplankton are typical of healthy cells. Calculations suggest that carbohydrate ballasting can account for buoyancy changes and that these reserves are adequate to support dark NO 3 - uptake. Under steady-state conditions in situ, the observed growth and buoyancy properties would lead to subsurface population maxima in all 3 species. However, the dynamic light-related buoyancy changes probably occur on a shorter time scale than these batch culture experiments. These results indicate that vertical migration is a property basic to these diatoms life history strategy, and, like multispecies Rhizosolenia mats, solitary Rhizosolenia chains transport new nitrogen to the euphotic zone in oligotrophic seas...|$|R
40|$|FIGURE 1. Phylogram of {{the tree}} {{recovered}} of the phylogenetic analysis based on 535 bp of the 16 S mtDNA gene. Values above nodes are neighbour-joining bootstrap <b>replicates</b> (20000 replicates; <b>values</b> below 50 % not shown); values below nodes are Bayesian posterior probabilities (values below 0. 85 not shown). Significant values are printed in bold...|$|R
30|$|According to JIS K 7111, the Charpy {{impact test}} {{was carried out}} using a digital impact tester DG-CD (Toyo Seiki Seisaku-sho, Ltd). A {{rectangular}} specimen of 80  ×  10  ×  4 – 6  mm was prepared, and the impact strength in the flatwise direction was measured with 5 unnotched sample <b>replicates.</b> The average <b>value</b> with standard deviation was calculated.|$|R
40|$|It {{is widely}} {{accepted}} {{that due to}} memory failures retrospective survey questions tend {{to be prone to}} measurement error. However, the proportion of studies using such data that attempt to adjust for the measurement problem is shockingly low. Arguably, to a great extent this is due to both the complexity of the methods available and the need to access a subsample containing either a gold standard or <b>replicated</b> <b>values.</b> Here I suggest the implementation of a version of SIMEX capable of adjusting for the types of multiplicative measurement errors associated with memory failures in the retrospective report of durations of life-course events. SIMEX is a method relatively simple to implement and it does not require the use of replicated or validation data so long as the error process can be adequately specified. To assess the effectiveness of the method I use simulated data. I create twelve scenarios based on the combinations of three outcome models (linear, logit and Poisson) and four types of multiplicative errors (non-systematic, systematic negative, systematic positive and heteroscedastic) affecting one of the explanatory variables. I show that SIMEX can be satisfactorily implemented in each of these scenarios. Furthermore, the method can also achieve partial adjustments even in scenarios where the actual distribution and prevalence of the measurement error differs substantially from what is assumed in the adjustment, which makes it an interesting sensitivity tool in those cases where all that is known about the error process is reduced to an educated guess...|$|R
40|$|Abstract__ Overpayment for {{acquisitions}} {{can occur}} if managerial hubris leads bidders to overestimate target standalone values under their control. We provide a unique test {{of this phenomenon}} by analyzing whether bidders overpay for founder CEO targets because they overestimate their ability to <b>replicate</b> the <b>value</b> of the founder CEOs’ firm-specific human capital post-acquisition. We show that the founder CEOs’ human capital is valuable and embedded in the ex-ante targets’ value and is, economically and statistically, negatively associated with bidder gains and synergy returns. Our {{findings are consistent with}} bidders’ overestimating the value of founder CEO targets as stand-alone firms under their control. [version: December 2013...|$|R
3000|$|The {{reported}} aspects {{connected to}} [...] "biological effect" [...] are: stated and quantified effects for all endpoints, concentration-response relationship, {{and whether the}} results have been reproduced by others or are consistent with other findings. Durda and Preziosi [11] have covered all aspects. The OECD guidelines also recommend that calculated response variables for each treatment <b>replicate,</b> with mean <b>values</b> and coefficient of variation for replicates is reported.|$|R
