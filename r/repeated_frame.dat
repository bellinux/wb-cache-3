2|116|Public
30|$|By {{sensing the}} buffer {{fullness}} and keeping {{an estimate of}} the available bit budget, the rate control chooses the quantization step size and seeks to prevent buffer overflow and underflow while maintaining acceptable video quality. If either the remaining bit budget is small or the buffer is getting full, the rate control resorts to coarse quantization. If either the remaining bit budget is large or the buffer is getting empty, the quantization step size is reduced (i.e., fine quantization). A large delay budget for the source encoder allows the use of a large encoder buffer, which tends to result in higher-quality video because the rate control has more freedom. Typically, the increased number of bits resulting from finely encoding a complex scene can be easily accommodated in the large buffer. However, when tight delay constraints exist, the system must operate with a small encoder delay budget, or equivalently a small encoder buffer, which tends to reduce the quality of the video, as the functioning of the rate control is more constrained. In extreme cases, the encoder buffer may fill up several times, leading to loss of data through <b>repeated</b> <b>frame</b> skipping.|$|E
30|$|In {{order to}} obtain PER, the {{classified}} frames must be converted to phonemes. This was done by taking the mode {{of all of the}} SVM classifications for each GMM-HMM-generated boundary, initially produced by the HMM labeler as seen in Fig.  1, thus collapsing <b>repeated</b> <b>frame</b> classifications into single phonemes. In other words, the values of the initial labels are not actually used, just the boundaries so that a decision can be made for each one. Since each boundary contains multiple frames classified by the SVM, a single value is calculated by taking the mode of all frames within the respective boundary. In the case where classifications across boundaries produced the same results, that boundary ceased to exist. The acoustic model used in the HMM labeler is the model trained by [34] on the SCOTUS corpus. Smoothing is an important step because it avoids likely misclassifications from the frame level, for example: a single frame classified as a phoneme A between two frames classified as a phoneme B seems extremely unlikely. Also {{in the case of a}} long co-articulation or heavy aspiration the beginning or ending of a phoneme could be confused with an entirely different sound but as time goes on this should become more clear.|$|E
50|$|IRIG {{time code}} {{is made up}} of <b>repeating</b> <b>frames,</b> each {{containing}} 60 or 100 bits. The bits are numbered from 0 through 59 or 99.|$|R
5000|$|... #Caption: A {{screenshot}} of a Microsoft Windows XP application {{displaying a}} visual artifact with <b>repeated</b> <b>frames.</b> This was fixed {{in the next}} release, Windows Vista [...]|$|R
50|$|DVCPRO HD {{supports}} native progressive recording at 50 or 60 frame/s in 720p mode. To record video acquired at 24, 25 or 30 frame/s <b>frame</b> <b>repeating</b> is used. <b>Frame</b> <b>repeating</b> {{is similar}} to field repeating used in interlaced video, and is also called pulldown sometimes.|$|R
50|$|Bara was one {{of three}} actresses (Pola Negri and Mae Murray were the others) whose eyes were {{combined}} to form the Chicago International Film Festivals logo, a stark, black and white close up of the composite eyes set as <b>repeated</b> <b>frames</b> in a strip of film.|$|R
50|$|Negri, {{along with}} Theda Bara and Mae Murray, were the actresses whose eyes were {{combined}} {{to form the}} Chicago International Film Festival's logo, a stark, black and white close up of the composite eyes set as <b>repeated</b> <b>frames</b> in a strip of film. It was created by Festival Founder and Artistic Director Michael Kutza.|$|R
50|$|The Chicago International Film Festival is {{an annual}} film festival held every fall. Founded in 1964 by Michael Kutza, {{it is the}} longest-running {{competitive}} film festival in North America. Its logo is a stark, black and white close up of the composite eyes of early film actresses Theda Bara, Pola Negri and Mae Murray, set as <b>repeated</b> <b>frames</b> in a strip of film.|$|R
50|$|For her {{contribution}} to the motion picture industry, Mae Murray has a star on the Hollywood Walk of Fame at 6318 Hollywood Blvd. She {{was one of three}} actresses (Pola Negri and Theda Bara were the others) whose eyes were combined to form the Chicago International Film Festival's logo, a stark, black and white close-up of the composite eyes set as <b>repeated</b> <b>frames</b> in a strip of film.|$|R
40|$|Basically, the PFS is an {{independent}} survey that <b>repeats</b> <b>frame</b> update. The survey results are compared with house units frame results, permitting estimates {{to be made of}} : coverage and content errors. Coverage errors refer to house units missed in the census or incorrectly included, while content errors evaluate response quality of selected questions. The PFS allows SESRI to uncover deficiencies in the methodology of the frame update and make adjustments for future censuses...|$|R
30|$|The NR metric {{proposed}} {{in this paper}} is independent from the error concealment techniques implemented in the video player; however, since frame repetition is a very common concealment method, here, {{the assessment of the}} quality loss produced by freezing the video in correspondence of frame losses is specifically addressed. More in details, before applying the NR jerkiness metric proposed by the authors in [56], the played sequence is analyzed in order to detect the presence of <b>repeated</b> <b>frames.</b>|$|R
5000|$|Barbara Crane (born 1928) is an American artist {{photographer}} born in Chicago, IL. Crane {{works with}} a variety of materials including Polaroid, gelatin silver, and platinum prints among others. She is known for her experimental and innovative work that challenges the straight photograph by incorporating sequencing, layered negatives, and <b>repeated</b> <b>frames.</b> Naomi Rosenblum notes that Crane [...] "pioneered the use of repetition to convey the mechanical character of much of contemporary life, even in its recreational aspects." ...|$|R
50|$|At {{the highest}} level, each 192 {{consecutive}} frames are grouped into an audio block. While samples <b>repeat</b> each <b>frame</b> time, metadata is only transmitted once per audio block.|$|R
40|$|Semantic {{contents}} {{are nothing}} but the object, event and concept instances that {{is present in the}} video. The problem is that the semantic contents cannot be easily extracted. The key issue in extracting the semantic content is its representation. In order to expand the modeling capabilities additional rules can be used. The goal {{of this paper is to}} allow the users to retrieve some useful information from large amount of data in a semantically meaningful manner. When the keyframes are being extracted from the video there is a problem of <b>repeated</b> <b>frames.</b> Inorder to avoid this problem homomorphic methodology is used,which makes the system wide domain applicable...|$|R
5000|$|In “The Open Grave”, by Louise Elisabeth Glück, the {{mortuary}} {{phrase is}} <b>repeated</b> as a <b>framing</b> cadence.|$|R
50|$|To {{reduce the}} 625-line signal to 525, less {{expensive}} converters drop 100 lines. These converters maintain picture fidelity by evenly spacing removed lines. (For example, the system might discard every sixth line from each PAL field. After the 50th discard, this process would stop. By then {{the system would}} have passed the viewable area of the field. In the following field, the process would <b>repeat,</b> completing one <b>frame.)</b> To create the five additional <b>frames,</b> the converter <b>repeats</b> every fifth <b>frame.</b>|$|R
50|$|The {{progressive}} 24 fps DVD {{will have}} a unifying effect on PAL and NTSC, just as film does, perhaps requiring conversion {{of the number of}} lines but without a conflict between field and frame rate. The player converts the video to the more-conventional video formats, on the fly, by simply repeating each field. It converts for PAL (referring here to 625 line 575 active line used with PAL as well as the chrominance aspects), by <b>repeating</b> each <b>frame</b> twice with a corresponding interlace, or for NTSC, by <b>repeating</b> some 480p <b>frames</b> 2 times and others 3 times (3:2 pulldown), to make 24 fps material play at 30fps, or 60 fields per second.|$|R
50|$|Since {{the very}} beginning, the AVCHD {{specification}} had supported 720-line progressive recording mode at frame rates of 24 and 60 frames/s for 60 Hz models and 50 frames/s for 50 Hz models. Frame rates of 25 frames/s and 30 frames/s {{are not directly}} available in 720p mode, but can be simulated with <b>frame</b> <b>repeating,</b> when every <b>frame</b> is either <b>repeated</b> twice or a special flag in the video stream instructs a decoder to play every frame twice to adhere to output rate of 50 or 60 frames/s.|$|R
50|$|Return-to-libc attacks {{do not use}} code, {{but rather}} inject fixed width stack frames. Because of this, stack <b>frames</b> have to <b>repeat</b> exactly aligned to 16 bytes. Often a stack frame will be bigger than this, giving <b>repeated</b> stack <b>frame</b> {{payloads}} of the same length as a given NOP sled less of {{an impact on the}} success rate of attacks.|$|R
40|$|Abstract—This paper {{provides}} a flexible way of controlling Variable-Bit-Rate (VBR) of compressed digital video, {{applicable to the}} new H 264 video compression standard. The entire video sequence is assessed in advance and the quantisation level is then set such that bit rate (and thus the frame rate) remains within predetermined limits compatible with the bandwidth of the transmission system and {{the capabilities of the}} remote end, {{while at the same time}} providing constant quality similar to VBR encoding. A process for avoiding buffer starvation by selectively eliminating frames from the encoded output at times when the frame rate is slow (large number of bits per frame) will be also described. Finally, the problem of buffer overflow will be solved by selectively eliminating frames from the received input to the decoder. The decoder detects the omission of the frames and resynchronizes the transmission by monitoring time stamps and <b>repeating</b> <b>frames</b> if necessary...|$|R
50|$|The mid-to-up-tempo {{recording}} {{featured a}} steady drumbeat, synthesizer, and guitar, with a <b>repeated</b> saxophone riff <b>framing</b> the lyrical message. The guitar solo {{is played by}} Frey himself.|$|R
40|$|A {{photographic}} installation {{commissioned by}} CAPTURE (National agency for Dance on Screen) and Arts Council England {{in collaboration with}} choreographer Frauke Requardt. Shot on 35 mm slide film and presented in light boxes with loupes (viewfinders), slide projections and sound track, the work utilised a range of viewing and capture methodologies from early experiments in photographic movement (Muybridge, Marey). The research aim was to interrogate what makes a moving image, physically and emotionally through fictionalised narratives and associated narrative ruptures. Callaghan achieved this through isolating and manipulating pictorial layers (e. g. fixed <b>frames,</b> <b>repeated</b> <b>frames</b> minus elements), installation design (viewer movement as animating images in light boxes) and choreographic performance (non-gestural repeated actions). Underlying research drew on Nietzsche and Heidegger to create narratives of loss, isolation and displacement. Narrative construction {{in the form of}} layering and delayering was drawn from Borges (labyrinths) and Derrida (de-sedimentation) and aesthetically artists Tracey Moffat and Stan Douglas influenced the work. Premiered at FORMAT International Festival of Photography, Derby (2009) ...|$|R
40|$|Abstract: In this paper, a novel motion texture {{approach}} is presented for synthesizing long character motion (e. g., kungfu) {{that is similar}} to the original short input motion. First, a new motion with <b>repeated</b> <b>frames</b> is generated by exploiting the symmetric properties of the frames and reversing the motion sequence playback in a given motion sequence. Then, the order of the above motion sequence is rearranged by putting the start and the end frames together. The graphcut algorithm is used to seamlessly synthesize the transition between the start and the end frames, which is noted as graphcut-based motion-texton. Finally, we utilize the motion-textons to synthesize long motion texture, which can be patched together like the image texture synthesis method using graphcut algorithm, and automatically form a long motion texture endlessly. Our {{approach is}} demonstrated by synthesizing the long kungfu motion texture without visual artifacts, together with post-processing including our new developed graphcut-based motion blending and Poisson-based motion smoothing techniques...|$|R
40|$|To realize {{frame rate}} transcoding, the forward <b>frame</b> <b>repeat</b> {{mechanism}} is usually adopted {{to compensate the}} skipped frames in a video decoder for end-device. However, based on our observation, it is unsuitable for <b>repeating</b> all skipped <b>frames</b> only in the forward direction and sometimes the backward repeat may provide better results. To deal with this issue, we propose a new reference frame selection method to determine the direction of repeat-frame for skipped Predictive (P) and Bidirectional (B) frames. For P-frame, the non-zero transformed coefficients and the magnitude of motion vectors are taken into consideration to determine the use of forward or backward repeat. For B-frame, the magnitude of motion vector and its corresponding reference directions of the blocks in B-frame are selected as the decision criteria. Experimental {{results show that the}} proposed method provides 1. 34 dB and 1. 31 dB PSNR improvements in average for P and B frames, respectively, compared with forward <b>frame</b> <b>repeat...</b>|$|R
40|$|Background: The {{majority}} of institutionalized elderly do not exercise, despite the many health benefits. The current study investigated whether a framed intervention can motivate elderly in assisted living facilities (ALFs) to perform functional resistance exercises. It {{was hypothesized that}} <b>repeated</b> <b>framing</b> of these exercises from a prevention perspective (e. g., to avoid health deterioration) would nurture the development of controlled motivation to exercise. By contrast, <b>repeated</b> <b>framing</b> of the exercises from a promotion perspective (e. g., to improve health) was expected to lead to higher exercise frequencies over time and to foster the development of autonomous motivation. Autonomous motivation was hypothesized to predict higher exercise frequencies over time. Methods: A total of 111 residents, aged 65 + years (M = 81. 4 y; SD = 6. 4 y) participated in the study. These participants received a three-week individual program with a standard session of eight functional resistance exercises. Four weekly sessions were recommended. Participants were semi-randomized into three framing conditions: neutral (i. e., control), prevention or promotion. They received condition-specific written and spoken messages about the exercises {{at the beginning of}} the intervention. The spoken messages were repeated at the end of each week. Participants kept a checklist with their weekly exercise frequency and at corresponding points in time, they completed a questionnaire about their levels of autonomous and controlled motivation to exercise. Results: Across conditions and time points, the exercise frequencies and the levels of autonomous motivation were generally high, whereas the levels of controlled motivation were generally low. Contrary to the expectations, there were no significant framing effects. However, higher levels of autonomous motivation predicted higher exercise frequencies. During the final exercise week, this was especially the case for intrinsic regulation (i. e., for the sake of the activity). Conclusions: This study indicates that elderly who live in ALFs can be motivated to perform functional resistance exercises. Given the importance of intrinsic regulation, we advise to create an exercise atmosphere that allows for immediate, positive experiences and in which the basic psychological needs for autonomy, competence and relatedness are satisfied. status: publishe...|$|R
50|$|The cel is an {{important}} innovation to traditional animation, as it allows some parts of each <b>frame</b> to be <b>repeated</b> from <b>frame</b> to frame, thus saving labor. A simple example would be a scene with two characters on screen, {{one of which is}} talking and the other standing silently. Since the latter character is not moving, it can be displayed in this scene using only one drawing, on one cel, while multiple drawings on multiple cels are used to animate the speaking character.|$|R
40|$|Purpose: To {{demonstrate}} a new imaging method for high resolution spectral domain {{optical coherence tomography}} (SD-OCT) for small animal developmental imaging. Methods: Wildtype zebrafish that were 24, 48, 72, and 120 h post fertilization (hpf) and nok gene mutant (48 hpf) embryos were imaged in vivo. Three additional embryos were imaged twice, once at 72 hpf and again at 120 hpf. Images of the developing eye, brain, heart, whole body, proximal yolk sac, distal yolk sac, and tail were acquired. Three-dimensional OCT data sets (501 × 180 axial scans) were obtained as well as oversampled frames (8, 100 axial scans) and repeated line scans (180 <b>repeated</b> <b>frames).</b> Scan volumes ranged from 750 × 750 µm to 3 × 3 mm, each 1. 8 mm thick. Three-dimenstional data sets allowed construction of C-mode slabs of the embryo. Results: SD-OCT provided ultra-high resolution visualization of the eye, brain, heart, ear, and spine of the developing embryo as early as 24 hpf, and allowed development to be documented {{in each of these}} organ systems in consecutive sessions. Repeated line scanning with averaging optimized the visualization of static and dynamic structures contained in SD-OCT images. Structural defects caused by a mutation in the nok gene were readily observed as impeded ocula...|$|R
40|$|The {{effectiveness}} of speckle reduction using traditional frame averaging technique was limited in ultrahigh speed {{optical coherence tomography}} (OCT). As the motion between <b>repeated</b> <b>frames</b> was very small, the speckle pattern of the frames might be identical. This problem could be solved by averaging frames acquired at slightly different locations. The optimized scan range depended on the spot size of the laser beam, the smoothness of the boundary, and the homogeneity of the tissue. In this study we presented a method to average frames obtained within a narrow range along the slow-axis. A swept-source OCT with 100, 000 Hz axial scan rate was used to scan the retina in vivo. A series of narrow raster scans (0 - 50 micron along the slow axis) were evaluated. Each scan contained 20 image frames evenly distributed in the scan range. The imaging frame rate was 417 HZ. Only frames with high correlation after rigid registration were used in averaging. The result showed that the contrast-to-noise ratio (CNR) increased with the scan range. But the best edge reservation was obtained with 15 micron scan range. Thus, for ultrahigh speed OCT systems, averaging frames from a narrow band along the slow-axis could achieve better speckle reduction than traditional frame averaging techniques...|$|R
40|$|Abstract � Motion capture {{devices have}} been {{utilized}} in producing several contents, such as movies and video games. However, since motion capture devices are expensive and inconvenient to use, motions segmented from captured data was recycled and synthesized to utilize it in another contents, but the motions were generally segmented by contents producers in manual. Therefore, automatic motion segmentation is recently {{getting a lot}} of attentions. Previous approaches are divided into on-line and off-line, where on-line approaches segment motions based on similarities between neighboring frames and off-line approaches segment motions by capturing the global characteristics in feature space. In this paper, we propose a graph-based high-level motion segmentation method. Since high-level motions consist of several <b>repeated</b> <b>frames</b> within temporal distances, we consider all similarities among all frames within the temporal distance. This is achieved by constructing a graph, where each vertex represents a frame and the edges between the frames are weighted by their similarity. Then, normalized cuts algorithm is used to partition the constructed graph into several sub-graphs by globally finding minimum cuts. In the experiments, the results using the proposed method showed better performance than PCA-based method in on-line and GMM-based method in off-line, as the proposed method globally segment motions from the graph constructed based similarities between neighboring frames as well as similarities among all frames within temporal distances...|$|R
40|$|We {{consider}} the well-known Sliding Window Protocol which provides reliable and efficient {{transmission of data}} over unreliable channels. A formal proof of correctness for this protocol faces substantial difficulties caused by {{a high degree of}} parallelism which creates a significant potential for errors. Here we consider a version of the protocol that is based on selective <b>repeat</b> of <b>frames.</b> The specification of the protocol by a state machine and its safety property are represented {{in the language of the}} verification system PVS. Using the PVS system, we give an interactive proof of this property of the Sliding Window Protocol. </p...|$|R
5000|$|One other {{consideration}} {{is the very}} large amount of bandwidth required to feed imagery to a volumetric display. For example, a standard 24 bits per pixel, 1024×768 resolution, flat/2D display requires about 135 MB/s {{to be sent to}} the display hardware to sustain 60 frames per second, whereas a 24 bits per voxel, 1024×768×1024 (1024 [...] "pixel layers" [...] in the Z axis) volumetric display would need to send about three orders of magnitude more (135 GB/s) to the display hardware to sustain 60 volumes per second. As with regular 2D video, one could reduce the bandwidth needed by simply sending fewer volumes per second and letting the display hardware <b>repeat</b> <b>frames</b> in the interim, or by sending only enough data to affect those areas of the display that need to be updated, {{as is the case in}} modern lossy-compression video formats such as MPEG. Furthermore, a 3D volumetric display would require two to three orders of magnitude more CPU and/or GPU power beyond that necessary for 2D imagery of equivalent quality, due at least in part to the sheer amount of data that must be created and sent to the display hardware. However, if only the outer surface of the volume is visible, the number of voxels required would be of the same order as the number of pixels on a conventional display. This would only be the case if the voxels do not have [...] "alpha" [...] or transparency values.|$|R
40|$|In this paper, we {{extend the}} framing of games and {{language}} invariance (Casajus, 2001) to repeated games. Our concept of history invariance in <b>framed</b> <b>repeated</b> games unifies and generalizes the Crawford and Haller (1990) and Blume (2000) approaches for learning in repeated games. As a result, dynamic focal points in repeated coordination games can be supported {{in a general}} fashion...|$|R
50|$|The {{house was}} built in 1836 by two masons, Oren Wardwell and Daniel Trickey. The style of the house, with the {{division}} along the gable, is apparently a peculiarity of Bangor, and was most frequently <b>repeated</b> in wood <b>frame</b> construction. This house is among the best-preserved of those that survive from {{the first half of}} the 19th century, especially its interiors.|$|R
50|$|Dot plots compare two {{sequences}} by organizing one sequence on the x-axis, {{and another}} on the y-axis, of a plot. When the residues of both sequences match at the same location on the plot, a dot is drawn at the corresponding position. Note, that the sequences can be written backwards or forwards, however the sequences on both axes must be written in the same direction. Also note, that {{the direction of the}} sequences on the axes will determine the direction of the line on the dot plot. Once the dots have been plotted, they will combine to form lines. The closeness of the sequences in similarity will determine how close the diagonal line is to what a graph showing a curve demonstrating a direct relationship is. This relationship is affected by certain sequence features such as <b>frame</b> shifts, direct <b>repeats,</b> and inverted <b>repeats.</b> <b>Frame</b> shifts include insertions, deletions, and mutations. The presence of one of these features, or the presence of multiple features, will cause for multiple lines to be plotted in a various possibility of configurations, depending on the features present in the sequences. A feature that will cause a very different result on the dot plot is the presence of low-complexity region/regions. Low-complexity regions are regions in the sequence with only a few amino acids, which in turn, causes redundancy within that small or limited region. These regions are typically found around the diagonal, and {{may or may not have}} a square in the middle of the dot plot.|$|R
40|$|Gold striped black {{cloth binding}} with view of Boston blind stamped on covers and spine printed in gold; light yellow end papers. Three pages of ads for picture books {{published}} by Munroe & Francis at end. Title page decorative <b>frame</b> <b>repeated</b> on every page. "New-York: C. S. Francis and Co. Broadway. " above date on title page. Title vignette. Without music. Mode of access: Internet...|$|R
40|$|Colophon: Van Winkle and Wiley, printers. Engraved {{frontispiece}} facing engraved added t. p. with vignette in each volume. v. 1 : [A]⁴, B-L¹², M⁸; v. 2 : [A]⁶, B-L¹², (A 6 blank). Russell,Mode of access: Internet. Ritter Hopson sale, June 1933. Tan printed boards, with backstrip missing (v. 1) or worn (v. 2), t. p. <b>repeated</b> within decorative <b>frames</b> on upper covers, publisher's advts. within decorative frames {{on lower}} covers, uncut...|$|R
